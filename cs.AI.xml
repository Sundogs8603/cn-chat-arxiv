<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#36825;&#31687;&#35770;&#25991;&#32508;&#36848;&#20102;&#22312;&#29983;&#21629;&#31185;&#23398;&#39046;&#22495;&#20013;&#20351;&#29992;&#30693;&#35782;&#22270;&#35889;&#30340;&#26368;&#26032;&#21457;&#23637;&#21644;&#36827;&#23637;&#65292;&#24182;&#23637;&#26395;&#20102;&#36825;&#20123;&#25216;&#26415;&#22312;&#26410;&#26469;&#23545;&#36825;&#20123;&#39046;&#22495;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2309.17255</link><description>&lt;p&gt;
&#29983;&#21629;&#31185;&#23398;&#39046;&#22495;&#30340;&#30693;&#35782;&#22270;&#35889;&#65306;&#26368;&#26032;&#21457;&#23637;&#12289;&#25361;&#25112;&#21644;&#26426;&#36935;
&lt;/p&gt;
&lt;p&gt;
Knowledge Graphs for the Life Sciences: Recent Developments, Challenges and Opportunities. (arXiv:2309.17255v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.17255
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#32508;&#36848;&#20102;&#22312;&#29983;&#21629;&#31185;&#23398;&#39046;&#22495;&#20013;&#20351;&#29992;&#30693;&#35782;&#22270;&#35889;&#30340;&#26368;&#26032;&#21457;&#23637;&#21644;&#36827;&#23637;&#65292;&#24182;&#23637;&#26395;&#20102;&#36825;&#20123;&#25216;&#26415;&#22312;&#26410;&#26469;&#23545;&#36825;&#20123;&#39046;&#22495;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#21629;&#31185;&#23398;&#26159;&#30740;&#31350;&#29983;&#29289;&#21644;&#29983;&#21629;&#36807;&#31243;&#30340;&#23398;&#31185;&#65292;&#21253;&#25324;&#21270;&#23398;&#12289;&#29983;&#29289;&#23398;&#12289;&#21307;&#23398;&#21644;&#19968;&#31995;&#21015;&#20854;&#20182;&#30456;&#20851;&#23398;&#31185;&#12290;&#29983;&#21629;&#31185;&#23398;&#30340;&#30740;&#31350;&#24037;&#20316;&#38750;&#24120;&#20381;&#36182;&#25968;&#25454;&#65292;&#22240;&#20026;&#23427;&#20204;&#20135;&#29983;&#21644;&#28040;&#36153;&#22823;&#37327;&#31185;&#23398;&#25968;&#25454;&#65292;&#20854;&#20013;&#24456;&#22810;&#25968;&#25454;&#20855;&#26377;&#20851;&#31995;&#21644;&#22270;&#32467;&#26500;&#12290;&#25968;&#25454;&#30340;&#25968;&#37327;&#21644;&#20854;&#20013;&#28041;&#21450;&#30340;&#31185;&#23398;&#27010;&#24565;&#21644;&#20851;&#31995;&#30340;&#22797;&#26434;&#24615;&#25512;&#21160;&#20102;&#24212;&#29992;&#20808;&#36827;&#30340;&#30693;&#35782;&#39537;&#21160;&#25216;&#26415;&#26469;&#31649;&#29702;&#21644;&#35299;&#37322;&#25968;&#25454;&#65292;&#26368;&#32456;&#30446;&#26631;&#26159;&#25512;&#21160;&#31185;&#23398;&#21457;&#29616;&#12290;&#22312;&#36825;&#31687;&#32508;&#36848;&#21644;&#35266;&#28857;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#30693;&#35782;&#22270;&#35889;&#22312;&#29983;&#21629;&#31185;&#23398;&#20013;&#30340;&#26368;&#26032;&#21457;&#23637;&#21644;&#36827;&#23637;&#65292;&#24182;&#23637;&#26395;&#20102;&#36825;&#20123;&#25216;&#26415;&#22312;&#26410;&#26469;&#23545;&#36825;&#20123;&#39046;&#22495;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#37325;&#28857;&#20851;&#27880;&#19977;&#20010;&#20027;&#39064;&#65306;&#30693;&#35782;&#22270;&#35889;&#30340;&#26500;&#24314;&#21644;&#31649;&#29702;&#65292;&#20197;&#21450;&#22312;&#26032;&#21457;&#29616;&#30340;&#36807;&#31243;&#20013;&#20351;&#29992;&#30693;&#35782;&#22270;&#35889;&#21644;&#30456;&#20851;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
The term life sciences refers to the disciplines that study living organisms and life processes, and include chemistry, biology, medicine, and a range of other related disciplines. Research efforts in life sciences are heavily data-driven, as they produce and consume vast amounts of scientific data, much of which is intrinsically relational and graph-structured.  The volume of data and the complexity of scientific concepts and relations referred to therein promote the application of advanced knowledge-driven technologies for managing and interpreting data, with the ultimate aim to advance scientific discovery.  In this survey and position paper, we discuss recent developments and advances in the use of graph-based technologies in life sciences and set out a vision for how these technologies will impact these fields into the future. We focus on three broad topics: the construction and management of Knowledge Graphs (KGs), the use of KGs and associated technologies in the discovery of ne
&lt;/p&gt;</description></item><item><title>MAPTree&#26159;&#19968;&#31181;&#36890;&#36807;&#36125;&#21494;&#26031;&#26041;&#27861;&#23545;&#20915;&#31574;&#26641;&#36827;&#34892;&#24402;&#32435;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;AND/OR&#25628;&#32034;&#23454;&#29616;&#26368;&#22823;&#21518;&#39564;&#26641;&#30340;&#24674;&#22797;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;MAPTree&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#33021;&#22815;&#20197;&#26356;&#23567;&#30340;&#26641;&#26469;&#23454;&#29616;&#21487;&#27604;&#36739;&#30340;&#24615;&#33021;&#12290;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#23454;&#38469;&#22330;&#26223;&#20013;&#65292;MAPTree&#36824;&#23637;&#31034;&#20986;&#26356;&#24378;&#30340;&#25239;&#22122;&#22768;&#33021;&#21147;&#21644;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2309.15312</link><description>&lt;p&gt;
MAPTree: &#29992;&#36125;&#21494;&#26031;&#20915;&#31574;&#26641;&#20987;&#36133;&#8220;&#26368;&#20248;&#8221;&#20915;&#31574;&#26641;
&lt;/p&gt;
&lt;p&gt;
MAPTree: Beating "Optimal" Decision Trees with Bayesian Decision Trees. (arXiv:2309.15312v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15312
&lt;/p&gt;
&lt;p&gt;
MAPTree&#26159;&#19968;&#31181;&#36890;&#36807;&#36125;&#21494;&#26031;&#26041;&#27861;&#23545;&#20915;&#31574;&#26641;&#36827;&#34892;&#24402;&#32435;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;AND/OR&#25628;&#32034;&#23454;&#29616;&#26368;&#22823;&#21518;&#39564;&#26641;&#30340;&#24674;&#22797;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;MAPTree&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#33021;&#22815;&#20197;&#26356;&#23567;&#30340;&#26641;&#26469;&#23454;&#29616;&#21487;&#27604;&#36739;&#30340;&#24615;&#33021;&#12290;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#23454;&#38469;&#22330;&#26223;&#20013;&#65292;MAPTree&#36824;&#23637;&#31034;&#20986;&#26356;&#24378;&#30340;&#25239;&#22122;&#22768;&#33021;&#21147;&#21644;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20915;&#31574;&#26641;&#20173;&#28982;&#26159;&#24403;&#20170;&#26368;&#27969;&#34892;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20043;&#19968;&#65292;&#20027;&#35201;&#26159;&#22240;&#20026;&#20854;&#24320;&#31665;&#21363;&#29992;&#30340;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#23545;&#26641;&#19978;&#30340;&#21518;&#39564;&#20998;&#24067;&#36827;&#34892;&#26368;&#22823;&#21518;&#39564;&#25512;&#29702;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#20915;&#31574;&#26641;&#24402;&#32435;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#20915;&#31574;&#26641;&#30340;&#26368;&#22823;&#21518;&#39564;&#25512;&#29702;&#19982;AND/OR&#25628;&#32034;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;&#21033;&#29992;&#36825;&#19968;&#20851;&#32852;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;MAPTree&#30340;AND/OR&#25628;&#32034;&#31639;&#27861;&#65292;&#33021;&#22815;&#24674;&#22797;&#20986;&#26368;&#22823;&#21518;&#39564;&#26641;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#23454;&#38469;&#19990;&#30028;&#22330;&#26223;&#20013;&#23637;&#31034;&#26368;&#22823;&#21518;&#39564;&#26641;&#30340;&#32463;&#39564;&#24615;&#33021;&#12290;&#22312;16&#20010;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#65292;MAPTree&#35201;&#20040;&#20248;&#20110;&#22522;&#20934;&#32447;&#65292;&#35201;&#20040;&#22312;&#24615;&#33021;&#30456;&#24403;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#26356;&#23567;&#30340;&#26641;&#12290;&#22312;&#19968;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#65292;MAPTree&#34920;&#29616;&#20986;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#24378;&#30340;&#25239;&#22122;&#22768;&#33021;&#21147;&#21644;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#26368;&#21518;&#65292;MAPTree&#27604;&#20854;&#20182;&#26041;&#27861;&#26356;&#24555;&#22320;&#24674;&#22797;&#20986;&#26368;&#22823;&#21518;&#39564;&#26641;&#12290;
&lt;/p&gt;
&lt;p&gt;
Decision trees remain one of the most popular machine learning models today, largely due to their out-of-the-box performance and interpretability. In this work, we present a Bayesian approach to decision tree induction via maximum a posteriori inference of a posterior distribution over trees. We first demonstrate a connection between maximum a posteriori inference of decision trees and AND/OR search. Using this connection, we propose an AND/OR search algorithm, dubbed MAPTree, which is able to recover the maximum a posteriori tree. Lastly, we demonstrate the empirical performance of the maximum a posteriori tree both on synthetic data and in real world settings. On 16 real world datasets, MAPTree either outperforms baselines or demonstrates comparable performance but with much smaller trees. On a synthetic dataset, MAPTree also demonstrates greater robustness to noise and better generalization than existing approaches. Finally, MAPTree recovers the maxiumum a posteriori tree faster tha
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#32842;&#22825;&#26426;&#22120;&#20154;&#22312;&#30740;&#31350;&#29983;&#24037;&#31243;&#25945;&#32946;&#20013;&#26377;&#30528;&#24040;&#22823;&#30340;&#28508;&#21147;&#65292;&#30740;&#31350;&#21457;&#29616;&#23427;&#20204;&#33021;&#22815;&#20934;&#30830;&#22238;&#31572;&#22797;&#26434;&#38382;&#39064;&#65292;&#24182;&#22312;&#35838;&#22530;&#19978;&#24102;&#26469;&#28508;&#22312;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2309.13059</link><description>&lt;p&gt;
&#36229;&#36234;&#20256;&#32479;&#25945;&#23398;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#32842;&#22825;&#26426;&#22120;&#20154;&#22312;&#30740;&#31350;&#29983;&#24037;&#31243;&#25945;&#32946;&#20013;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education. (arXiv:2309.13059v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13059
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#32842;&#22825;&#26426;&#22120;&#20154;&#22312;&#30740;&#31350;&#29983;&#24037;&#31243;&#25945;&#32946;&#20013;&#26377;&#30528;&#24040;&#22823;&#30340;&#28508;&#21147;&#65292;&#30740;&#31350;&#21457;&#29616;&#23427;&#20204;&#33021;&#22815;&#20934;&#30830;&#22238;&#31572;&#22797;&#26434;&#38382;&#39064;&#65292;&#24182;&#22312;&#35838;&#22530;&#19978;&#24102;&#26469;&#28508;&#22312;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25945;&#32946;&#39046;&#22495;&#24555;&#36895;&#21457;&#23637;&#30340;&#29615;&#22659;&#20013;&#65292;&#25968;&#23383;&#25216;&#26415;&#19968;&#20877;&#25171;&#30772;&#20256;&#32479;&#25945;&#23398;&#26041;&#27861;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#26368;&#26032;&#30340;&#36825;&#20123;&#39072;&#35206;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21644;&#32842;&#22825;&#26426;&#22120;&#20154;&#22312;&#30740;&#31350;&#29983;&#24037;&#31243;&#25945;&#32946;&#20013;&#30340;&#28508;&#21147;&#34701;&#21512;&#12290;&#25105;&#20204;&#39318;&#20808;&#36861;&#28335;&#21382;&#21490;&#21644;&#25216;&#26415;&#30340;&#39072;&#35206;&#65292;&#20197;&#25552;&#20379;&#32972;&#26223;&#65292;&#28982;&#21518;&#20171;&#32461;&#20851;&#38190;&#26415;&#35821;&#65292;&#22914;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#65292;&#20197;&#21450;&#26368;&#36817;&#36827;&#23637;&#30340;&#22522;&#26412;&#26426;&#21046;&#65292;&#21363;&#27880;&#24847;&#21147;/&#21464;&#21387;&#22120;&#27169;&#22411;&#21644;&#22270;&#24418;&#22788;&#29702;&#21333;&#20803;&#12290;&#25105;&#20204;&#30740;&#31350;&#30340;&#26680;&#24515;&#26159;&#23558;&#22522;&#20110;LLM&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#24212;&#29992;&#20110;&#30740;&#31350;&#29983;&#27969;&#20307;&#21147;&#23398;&#35838;&#31243;&#12290;&#25105;&#20204;&#20174;&#35838;&#31243;&#26448;&#26009;&#20013;&#26500;&#24314;&#20102;&#19968;&#20010;&#38382;&#39064;&#24211;&#65292;&#24182;&#35780;&#20272;&#20102;&#32842;&#22825;&#26426;&#22120;&#20154;&#25552;&#20379;&#20934;&#30830;&#12289;&#26377;&#35265;&#22320;&#30340;&#22238;&#31572;&#30340;&#33021;&#21147;&#12290;&#32467;&#26524;&#20196;&#20154;&#40723;&#33310;&#65292;&#19981;&#20165;&#23637;&#31034;&#20102;&#26426;&#22120;&#20154;&#22238;&#31572;&#22797;&#26434;&#38382;&#39064;&#30340;&#33021;&#21147;&#65292;&#36824;&#23637;&#31034;&#20102;&#35838;&#22530;&#19978;&#20351;&#29992;&#32842;&#22825;&#26426;&#22120;&#20154;&#30340;&#28508;&#22312;&#20248;&#21183;&#65292;&#20363;&#22914;&#8230;
&lt;/p&gt;
&lt;p&gt;
In the rapidly evolving landscape of education, digital technologies have repeatedly disrupted traditional pedagogical methods. This paper explores the latest of these disruptions: the potential integration of large language models (LLMs) and chatbots into graduate engineering education. We begin by tracing historical and technological disruptions to provide context and then introduce key terms such as machine learning and deep learning and the underlying mechanisms of recent advancements, namely attention/transformer models and graphics processing units. The heart of our investigation lies in the application of an LLM-based chatbot in a graduate fluid mechanics course. We developed a question bank from the course material and assessed the chatbot's ability to provide accurate, insightful responses. The results are encouraging, demonstrating not only the bot's ability to effectively answer complex questions but also the potential advantages of chatbot usage in the classroom, such as th
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#20998;&#26512;Transformer&#27169;&#22411;&#20013;&#30340;&#38544;&#34255;&#29366;&#24577;&#65292;&#21457;&#29616;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#32534;&#30721;&#20102;&#26576;&#20123;&#36890;&#29992;&#30693;&#35782;&#25552;&#21462;&#27169;&#24335;&#65292;&#22240;&#27492;&#22312;&#36827;&#34892;&#27169;&#22411;&#32534;&#36753;&#26102;&#65292;&#19981;&#38656;&#35201;&#26356;&#26032;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#30340;&#26435;&#37325;&#12290;</title><link>http://arxiv.org/abs/2308.08742</link><description>&lt;p&gt;
PMET: &#22312;Transformer&#20013;&#30340;&#31934;&#30830;&#27169;&#22411;&#32534;&#36753;
&lt;/p&gt;
&lt;p&gt;
PMET: Precise Model Editing in a Transformer. (arXiv:2308.08742v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08742
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#20998;&#26512;Transformer&#27169;&#22411;&#20013;&#30340;&#38544;&#34255;&#29366;&#24577;&#65292;&#21457;&#29616;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#32534;&#30721;&#20102;&#26576;&#20123;&#36890;&#29992;&#30693;&#35782;&#25552;&#21462;&#27169;&#24335;&#65292;&#22240;&#27492;&#22312;&#36827;&#34892;&#27169;&#22411;&#32534;&#36753;&#26102;&#65292;&#19981;&#38656;&#35201;&#26356;&#26032;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#30340;&#26435;&#37325;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#32534;&#36753;&#25216;&#26415;&#21487;&#20197;&#20197;&#36739;&#20302;&#30340;&#25104;&#26412;&#20462;&#25913;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#23569;&#37327;&#30693;&#35782;&#65292;&#24182;&#19988;&#24050;&#32463;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#12290;&#29616;&#26377;&#26041;&#27861;&#20551;&#35774;Transformer&#23618;&#38544;&#34255;&#29366;&#24577;&#26159;&#21069;&#39304;&#32593;&#32476;&#30340;&#38190;&#20540;&#20869;&#23384;&#30340;&#20540;&#12290;&#23427;&#20204;&#36890;&#24120;&#20248;&#21270;Transformer&#23618;&#38544;&#34255;&#29366;&#24577;&#26469;&#35760;&#24518;&#30446;&#26631;&#30693;&#35782;&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#26356;&#26032;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#21069;&#39304;&#32593;&#32476;&#30340;&#26435;&#37325;&#12290;&#28982;&#32780;&#65292;Transformer&#23618;&#38544;&#34255;&#29366;&#24577;&#30340;&#20449;&#24687;&#27969;&#26469;&#33258;&#19977;&#20010;&#37096;&#20998;&#65306;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#12289;&#21069;&#39304;&#32593;&#32476;&#21644;&#27531;&#24046;&#36830;&#25509;&#12290;&#29616;&#26377;&#26041;&#27861;&#24573;&#35270;&#20102;Transformer&#23618;&#38544;&#34255;&#29366;&#24577;&#21253;&#21547;&#20102;&#21069;&#39304;&#32593;&#32476;&#29305;&#21035;&#38656;&#35201;&#30340;&#20449;&#24687;&#36825;&#19968;&#20107;&#23454;&#12290;&#22240;&#27492;&#65292;&#27169;&#22411;&#32534;&#36753;&#30340;&#24615;&#33021;&#19979;&#38477;&#12290;&#20026;&#20102;&#23454;&#29616;&#26356;&#31934;&#30830;&#30340;&#27169;&#22411;&#32534;&#36753;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#21644;&#21069;&#39304;&#32593;&#32476;&#30340;&#38544;&#34255;&#29366;&#24577;&#65292;&#21457;&#29616;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#32534;&#30721;&#20102;&#26576;&#20123;&#36890;&#29992;&#30693;&#35782;&#25552;&#21462;&#27169;&#24335;&#12290;&#36825;&#24847;&#21619;&#30528;&#24403;&#24341;&#20837;&#26032;&#30693;&#35782;&#26102;&#65292;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#30340;&#26435;&#37325;&#19981;&#38656;&#35201;&#26356;&#26032;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model editing techniques modify a minor proportion of knowledge in Large Language Models (LLMs) at a relatively low cost, which have demonstrated notable success. Existing methods assume Transformer Layer (TL) hidden states are values of key-value memories of the Feed-Forward Network (FFN). They usually optimize the TL hidden states to memorize target knowledge and use it to update the weights of the FFN in LLMs. However, the information flow of TL hidden states comes from three parts: Multi-Head Self-Attention (MHSA), FFN, and residual connections. Existing methods neglect the fact that the TL hidden states contains information not specifically required for FFN. Consequently, the performance of model editing decreases. To achieve more precise model editing, we analyze hidden states of MHSA and FFN, finding that MHSA encodes certain general knowledge extraction patterns. This implies that MHSA weights do not require updating when new knowledge is introduced. Based on above findings, we
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22870;&#21169;&#26426;&#22120;&#25277;&#35937;&#26469;&#34920;&#31034;&#24403;&#21069;&#20219;&#21153;&#65292;&#24182;&#22312;&#36801;&#31227;&#23398;&#20064;&#20013;&#25552;&#21319;DRL&#20195;&#29702;&#30340;&#24615;&#33021;&#30340;&#26041;&#27861;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#26041;&#27861;&#33021;&#22815;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#24182;&#22312;&#22810;&#20010;&#39046;&#22495;&#20013;&#36827;&#34892;&#23569;&#26679;&#26412;&#36801;&#31227;&#12290;</title><link>http://arxiv.org/abs/2307.05209</link><description>&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20013;&#22522;&#20110;&#22870;&#21169;&#26426;&#22120;&#25277;&#35937;&#30340;&#19978;&#19979;&#25991;&#39044;&#35268;&#21010;&#20197;&#22686;&#24378;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Contextual Pre-Planning on Reward Machine Abstractions for Enhanced Transfer in Deep Reinforcement Learning. (arXiv:2307.05209v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05209
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22870;&#21169;&#26426;&#22120;&#25277;&#35937;&#26469;&#34920;&#31034;&#24403;&#21069;&#20219;&#21153;&#65292;&#24182;&#22312;&#36801;&#31227;&#23398;&#20064;&#20013;&#25552;&#21319;DRL&#20195;&#29702;&#30340;&#24615;&#33021;&#30340;&#26041;&#27861;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#26041;&#27861;&#33021;&#22815;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#24182;&#22312;&#22810;&#20010;&#39046;&#22495;&#20013;&#36827;&#34892;&#23569;&#26679;&#26412;&#36801;&#31227;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#20195;&#29702;&#20542;&#21521;&#20110;&#36807;&#25311;&#21512;&#35757;&#32451;&#20219;&#21153;&#65292;&#24182;&#19988;&#26080;&#27861;&#36866;&#24212;&#36731;&#24494;&#30340;&#29615;&#22659;&#21464;&#21270;&#12290;&#20026;&#20102;&#22312;&#36716;&#31227;&#21040;&#26410;&#35265;&#20219;&#21153;&#26102;&#21152;&#24555;&#23398;&#20064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22870;&#21169;&#26426;&#22120;&#65288;RM&#65289;&#26469;&#34920;&#31034;&#24403;&#21069;&#20219;&#21153;&#30340;&#26032;&#26041;&#27861;&#65292;&#22870;&#21169;&#26426;&#22120;&#26159;&#22522;&#20110;&#24403;&#21069;&#20219;&#21153;&#30340;&#22870;&#21169;&#21644;&#21160;&#24577;&#29983;&#25104;&#23376;&#20219;&#21153;&#30340;&#29366;&#24577;&#26426;&#25277;&#35937;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20026;&#20195;&#29702;&#25552;&#20379;&#20102;&#24403;&#21069;&#25277;&#35937;&#29366;&#24577;&#30340;&#31526;&#21495;&#34920;&#31034;&#65292;&#24182;&#22870;&#21169;&#23427;&#20204;&#36798;&#25104;&#36825;&#20123;&#36716;&#25442;&#12290;&#36825;&#20123;&#34920;&#31034;&#22312;&#20219;&#21153;&#20043;&#38388;&#20849;&#20139;&#65292;&#20351;&#20195;&#29702;&#33021;&#22815;&#21033;&#29992;&#20808;&#21069;&#36935;&#21040;&#30340;&#31526;&#21495;&#21644;&#36716;&#25442;&#30340;&#30693;&#35782;&#65292;&#20174;&#32780;&#22686;&#24378;&#36801;&#31227;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#34920;&#31034;&#22312;&#21508;&#31181;&#39046;&#22495;&#20013;&#25552;&#39640;&#20102;&#26679;&#26412;&#25928;&#29575;&#21644;&#23569;&#26679;&#26412;&#36801;&#31227;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent studies show that deep reinforcement learning (DRL) agents tend to overfit to the task on which they were trained and fail to adapt to minor environment changes. To expedite learning when transferring to unseen tasks, we propose a novel approach to representing the current task using reward machines (RM), state machine abstractions that induce subtasks based on the current task's rewards and dynamics. Our method provides agents with symbolic representations of optimal transitions from their current abstract state and rewards them for achieving these transitions. These representations are shared across tasks, allowing agents to exploit knowledge of previously encountered symbols and transitions, thus enhancing transfer. Our empirical evaluation shows that our representations improve sample efficiency and few-shot transfer in a variety of domains.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#33258;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#65292;&#31616;&#21270;&#20102;&#20250;&#35805;&#25512;&#33616;&#39046;&#22495;&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#30340;&#27169;&#22411;&#30340;&#22797;&#26434;&#24615;&#65292;&#24182;&#25552;&#39640;&#20102;&#25512;&#33616;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.01266</link><description>&lt;p&gt;
&#33258;&#23545;&#27604;&#23398;&#20064;&#29992;&#20110;&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Self Contrastive Learning for Session-based Recommendation. (arXiv:2306.01266v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01266
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#33258;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#65292;&#31616;&#21270;&#20102;&#20250;&#35805;&#25512;&#33616;&#39046;&#22495;&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#30340;&#27169;&#22411;&#30340;&#22797;&#26434;&#24615;&#65292;&#24182;&#25552;&#39640;&#20102;&#25512;&#33616;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20250;&#35805;&#30340;&#25512;&#33616;&#26088;&#22312;&#39044;&#27979;&#29992;&#25143;&#23545;&#29616;&#26377;&#39033;&#30446;&#20132;&#20114;&#24207;&#21015;&#30340;&#19979;&#19968;&#20010;&#24863;&#20852;&#36259;&#30340;&#39033;&#30446;&#65292;&#24050;&#32463;&#21560;&#24341;&#20102;&#36234;&#26469;&#36234;&#22810;&#24212;&#29992;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#65288;CL&#65289;&#25552;&#39640;&#29992;&#25143;&#21644;&#39033;&#30446;&#30340;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#23545;&#27604;&#30446;&#26631;&#65306;&#65288;1&#65289;&#36215;&#21040;&#19982;&#20132;&#21449;&#29109;&#25439;&#22833;&#31867;&#20284;&#30340;&#20316;&#29992;&#65292;&#21516;&#26102;&#24573;&#30053;&#20102;&#39033;&#30446;&#34920;&#31034;&#31354;&#38388;&#20248;&#21270;&#65307;&#65288;2&#65289;&#36890;&#24120;&#38656;&#35201;&#22797;&#26434;&#30340;&#24314;&#27169;&#65292;&#21253;&#25324;&#22797;&#26434;&#30340;&#27491;/&#36127;&#26679;&#26412;&#26500;&#24314;&#21644;&#39069;&#22806;&#30340;&#25968;&#25454;&#22686;&#24378;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#33258;&#23545;&#27604;&#23398;&#20064;&#65288;SCL&#65289;&#65292;&#31616;&#21270;&#20102;&#23545;&#27604;&#23398;&#20064;&#30340;&#24212;&#29992;&#65292;&#24182;&#22686;&#24378;&#20102;&#22522;&#20110;&#29366;&#24577;&#30340;&#25512;&#33616;&#25216;&#26415;&#30340;&#24615;&#33021;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;SCL&#34987;&#21046;&#23450;&#20026;&#19968;&#20010;&#30446;&#26631;&#20989;&#25968;&#65292;&#30452;&#25509;&#20419;&#36827;&#39033;&#30446;&#34920;&#31034;&#20043;&#38388;&#30340;&#22343;&#21248;&#20998;&#24067;&#65292;&#24182;&#26377;&#25928;&#22320;&#26367;&#25442;&#20102;&#25152;&#26377;&#29616;&#26377;&#30340;&#23545;&#27604;&#30446;&#26631;&#32452;&#20214;&#30340;&#29366;&#24577;-&#33402;&#26415;&#27169;&#22411;&#12290;&#19982;&#20197;&#21069;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;SCL&#28040;&#38500;&#20102;&#20219;&#20309;&#27491;&#26679;&#26412;&#25110;&#36127;&#26679;&#26412;&#30340;&#38656;&#27714;&#21644;SCL&#28040;&#38500;&#20102;&#20219;&#20309;&#27491;&#26679;&#26412;&#25110;&#36127;&#26679;&#26412;&#30340;&#38656;&#27714;&#21644;&#25968;&#25454;&#22686;&#24378;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Session-based recommendation, which aims to predict the next item of users' interest as per an existing sequence interaction of items, has attracted growing applications of Contrastive Learning (CL) with improved user and item representations. However, these contrastive objectives: (1) serve a similar role as the cross-entropy loss while ignoring the item representation space optimisation; and (2) commonly require complicated modelling, including complex positive/negative sample constructions and extra data augmentation. In this work, we introduce Self-Contrastive Learning (SCL), which simplifies the application of CL and enhances the performance of state-of-the-art CL-based recommendation techniques. Specifically, SCL is formulated as an objective function that directly promotes a uniform distribution among item representations and efficiently replaces all the existing contrastive objective components of state-of-the-art models. Unlike previous works, SCL eliminates the need for any p
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#25193;&#25955;&#27169;&#22411;MADiff&#65292;&#35299;&#20915;&#20102;&#22810;&#26234;&#33021;&#20307;&#38382;&#39064;&#65292;&#26159;&#31532;&#19968;&#20010;&#25193;&#25955;&#27169;&#22411;&#24212;&#29992;&#20110;&#22810;&#26234;&#33021;&#20307;&#31163;&#32447;RL&#30340;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2305.17330</link><description>&lt;p&gt;
MADiff&#65306;&#31163;&#32447;&#22810;&#26234;&#33021;&#20307;&#23398;&#20064;&#19982;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
MADiff: Offline Multi-agent Learning with Diffusion Models. (arXiv:2305.17330v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17330
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#25193;&#25955;&#27169;&#22411;MADiff&#65292;&#35299;&#20915;&#20102;&#22810;&#26234;&#33021;&#20307;&#38382;&#39064;&#65292;&#26159;&#31532;&#19968;&#20010;&#25193;&#25955;&#27169;&#22411;&#24212;&#29992;&#20110;&#22810;&#26234;&#33021;&#20307;&#31163;&#32447;RL&#30340;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#65288;DM&#65289;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#26368;&#36817;&#22312;&#21253;&#25324;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#22312;&#20869;&#30340;&#21508;&#31181;&#22330;&#26223;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#65292;&#20854;&#20013;&#31574;&#30053;&#36890;&#36807;&#22312;&#22312;&#32447;&#35780;&#20272;&#20013;&#20135;&#29983;&#36712;&#36857;&#26469;&#36827;&#34892;&#35268;&#21010;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#21333;&#26234;&#33021;&#20307;&#23398;&#20064;&#26174;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#65292;&#20294;&#20173;&#19981;&#28165;&#26970;DM&#22914;&#20309;&#22312;&#22810;&#26234;&#33021;&#20307;&#38382;&#39064;&#20013;&#25805;&#20316;&#65292;&#20854;&#20013;&#20195;&#29702;&#21830;&#24456;&#38590;&#22312;&#29420;&#31435;&#24314;&#27169;&#27599;&#20010;&#20195;&#29702;&#21830;&#36712;&#36857;&#30340;&#24773;&#20917;&#19979;&#23436;&#25104;&#22242;&#38431;&#21512;&#20316;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;MADiff&#65292;&#19968;&#31181;&#26032;&#30340;&#29983;&#25104;&#24335;&#22810;&#26234;&#33021;&#20307;&#23398;&#20064;&#26694;&#26550;&#65292;&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;MADiff&#26159;&#36890;&#36807;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#25193;&#25955;&#27169;&#22411;&#26469;&#23454;&#29616;&#23545;&#22810;&#20010;&#25193;&#25955;&#26234;&#33021;&#20307;&#34892;&#20026;&#30340;&#22797;&#26434;&#21327;&#35843;&#24314;&#27169;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;MADiff&#26159;&#31532;&#19968;&#20010;&#22522;&#20110;&#25193;&#25955;&#30340;&#22810;&#26234;&#33021;&#20307;&#31163;&#32447;RL&#26694;&#26550;&#65292;&#23427;&#26082;&#21487;&#20197;&#34892;&#20026;&#20026;&#20998;&#25955;&#30340;&#25919;&#31574;&#65292;&#21448;&#21487;&#20197;&#20026;&#38598;&#20013;&#25511;&#21046;&#22120;&#65292;&#20854;&#20013;&#21253;&#25324;&#23545;&#25163;&#24314;&#27169;&#65292;&#24182;&#21487;&#29992;&#20110;&#22810;&#26234;&#33021;&#20307;&#36712;&#36857;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion model (DM), as a powerful generative model, recently achieved huge success in various scenarios including offline reinforcement learning, where the policy learns to conduct planning by generating trajectory in the online evaluation. However, despite the effectiveness shown for single-agent learning, it remains unclear how DMs can operate in multi-agent problems, where agents can hardly complete teamwork without good coordination by independently modeling each agent's trajectories. In this paper, we propose MADiff, a novel generative multi-agent learning framework to tackle this problem. MADiff is realized with an attention-based diffusion model to model the complex coordination among behaviors of multiple diffusion agents. To the best of our knowledge, MADiff is the first diffusion-based multi-agent offline RL framework, which behaves as both a decentralized policy and a centralized controller, which includes opponent modeling and can be used for multi-agent trajectory predic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102; RewriteLM&#65292;&#19968;&#31181;&#25351;&#20196;&#35843;&#25972;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#29992;&#20110;&#38271;&#31687;&#25991;&#26412;&#37325;&#20889;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026; OpenRewriteEval &#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#35780;&#20272;&#21508;&#31181;&#31867;&#22411;&#30340;&#24320;&#25918;&#24335;&#38271;&#31687;&#25991;&#26412;&#37325;&#20889;&#12290;&#25105;&#20204;&#37319;&#29992;&#26032;&#30340;&#31574;&#30053;&#26469;&#20419;&#36827;&#22810;&#26679;&#30340;&#25351;&#20196;&#21644;&#20559;&#22909;&#25968;&#25454;&#29983;&#25104;&#65292;&#20174;&#32780;&#20026;&#38271;&#31687;&#25991;&#26412;&#37325;&#20889;&#25552;&#20379;&#26356;&#22909;&#30340;&#35780;&#20272;&#25163;&#27573;&#12290;</title><link>http://arxiv.org/abs/2305.15685</link><description>&lt;p&gt;
RewriteLM&#65306;&#19968;&#31181;&#38754;&#21521;&#25991;&#26412;&#37325;&#20889;&#30340;&#25351;&#20196;&#35843;&#25972;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
RewriteLM: An Instruction-Tuned Large Language Model for Text Rewriting. (arXiv:2305.15685v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15685
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102; RewriteLM&#65292;&#19968;&#31181;&#25351;&#20196;&#35843;&#25972;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#29992;&#20110;&#38271;&#31687;&#25991;&#26412;&#37325;&#20889;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026; OpenRewriteEval &#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#35780;&#20272;&#21508;&#31181;&#31867;&#22411;&#30340;&#24320;&#25918;&#24335;&#38271;&#31687;&#25991;&#26412;&#37325;&#20889;&#12290;&#25105;&#20204;&#37319;&#29992;&#26032;&#30340;&#31574;&#30053;&#26469;&#20419;&#36827;&#22810;&#26679;&#30340;&#25351;&#20196;&#21644;&#20559;&#22909;&#25968;&#25454;&#29983;&#25104;&#65292;&#20174;&#32780;&#20026;&#38271;&#31687;&#25991;&#26412;&#37325;&#20889;&#25552;&#20379;&#26356;&#22909;&#30340;&#35780;&#20272;&#25163;&#27573;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24050;&#32463;&#23637;&#29616;&#20986;&#22312;&#38271;&#31687;&#25991;&#26412;&#29983;&#25104;&#20219;&#21153;&#20013;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#25351;&#20196;&#34920;&#36798;&#26469;&#30340;&#24778;&#20154;&#30340;&#38646;-shot&#33021;&#21147;&#65292;&#28982;&#32780;&#29992;&#25143;&#23545;&#20110;&#38271;&#31687;&#25991;&#26412;&#37325;&#20889;&#30340;&#26399;&#26395;&#20540;&#24456;&#39640;&#65292;&#27169;&#22411;&#20135;&#29983;&#30340;&#24847;&#22806;&#37325;&#20889;&#65288;&#8220;&#24187;&#35273;&#8221;&#65289;&#20250;&#23545;&#20854;&#25972;&#20307;&#24615;&#33021;&#20135;&#29983;&#36127;&#38754;&#24433;&#21709;&#12290;&#29616;&#26377;&#30340;&#35780;&#20272;&#22522;&#20934;&#20027;&#35201;&#20851;&#27880;&#26377;&#38480;&#30340;&#37325;&#20889;&#39118;&#26684;&#21644;&#21477;&#23376;&#32423;&#37325;&#20889;&#65292;&#32780;&#19981;&#26159;&#38271;&#31687;&#24320;&#25918;&#24335;&#37325;&#20889;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;OpenRewriteEval&#65292;&#23427;&#28085;&#30422;&#20102;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#25351;&#20196;&#34920;&#36798;&#30340;&#21508;&#31181;&#37325;&#20889;&#31867;&#22411;&#12290;&#23427;&#29305;&#21035;&#35774;&#35745;&#29992;&#20110;&#20419;&#36827;&#38271;&#31687;&#25991;&#26412;&#24320;&#25918;&#24335;&#37325;&#20889;&#30340;&#35780;&#20272;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24378;&#22823;&#30340;&#22522;&#32447;&#27169;&#22411;RewriteLM&#65292;&#19968;&#20010;&#29992;&#20110;&#38271;&#31687;&#25991;&#26412;&#37325;&#20889;&#30340;&#25351;&#20196;&#35843;&#25972;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20123;&#26032;&#31574;&#30053;&#65292;&#20197;&#26368;&#23567;&#20154;&#24037;&#24178;&#39044;&#20419;&#36827;&#29983;&#25104;&#22810;&#26679;&#30340;&#25351;&#20196;&#21644;&#20559;&#22909;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have demonstrated impressive zero-shot capabilities in long-form text generation tasks expressed through natural language instructions. However, user expectations for long-form text rewriting is high, and unintended rewrites (''hallucinations'') produced by the model can negatively impact its overall performance. Existing evaluation benchmarks primarily focus on limited rewriting styles and sentence-level rewriting rather than long-form open-ended rewriting.We introduce OpenRewriteEval, a novel benchmark that covers a wide variety of rewriting types expressed through natural language instructions. It is specifically designed to facilitate the evaluation of open-ended rewriting of long-form texts. In addition, we propose a strong baseline model, RewriteLM, an instruction-tuned large language model for long-form text rewriting. We develop new strategies that facilitate the generation of diverse instructions and preference data with minimal human intervention.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29702;&#35299;&#33021;&#21147;&#30340;&#33539;&#20363;&#65292;&#36890;&#36807;&#35780;&#20272;&#27169;&#22411;&#33258;&#36523;&#29983;&#25104;&#30340;&#19981;&#21516;&#24847;&#20041;&#20043;&#38388;&#30340;&#19968;&#33268;&#24615;&#65292;&#25506;&#35752;&#20102;&#22810;&#35821;&#35328;&#33258;&#25105;&#19968;&#33268;&#24615;&#20316;&#20026;&#27169;&#22411;&#29702;&#35299;&#30340;&#26816;&#39564;&#26041;&#27861;&#65292;&#21516;&#26102;&#35777;&#26126;&#20102;ChatGPT&#22312;&#22810;&#35821;&#35328;&#19968;&#33268;&#24615;&#26041;&#38754;&#30340;&#20248;&#31168;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.11662</link><description>&lt;p&gt;
&#36890;&#36807;&#22810;&#35821;&#35328;&#19968;&#33268;&#24615;&#35780;&#20272;&#20219;&#21153;&#29702;&#35299;&#65306;ChatGPT&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Evaluating task understanding through multilingual consistency: A ChatGPT case study. (arXiv:2305.11662v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11662
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29702;&#35299;&#33021;&#21147;&#30340;&#33539;&#20363;&#65292;&#36890;&#36807;&#35780;&#20272;&#27169;&#22411;&#33258;&#36523;&#29983;&#25104;&#30340;&#19981;&#21516;&#24847;&#20041;&#20043;&#38388;&#30340;&#19968;&#33268;&#24615;&#65292;&#25506;&#35752;&#20102;&#22810;&#35821;&#35328;&#33258;&#25105;&#19968;&#33268;&#24615;&#20316;&#20026;&#27169;&#22411;&#29702;&#35299;&#30340;&#26816;&#39564;&#26041;&#27861;&#65292;&#21516;&#26102;&#35777;&#26126;&#20102;ChatGPT&#22312;&#22810;&#35821;&#35328;&#19968;&#33268;&#24615;&#26041;&#38754;&#30340;&#20248;&#31168;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#21151;&#33021;&#30340;&#24778;&#20154;&#25552;&#21319;&#65292;&#21019;&#24314;&#26410;&#26469;&#21487;&#25345;&#32493;&#30340;&#35780;&#20272;&#38598;&#20197;&#35780;&#20272;&#23427;&#20204;&#30340;&#29702;&#35299;&#21464;&#24471;&#36234;&#26469;&#36234;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35780;&#20272;LLM&#30340;&#33539;&#20363;&#65292;&#35813;&#33539;&#20363;&#21033;&#29992;&#20102;&#27491;&#30830;&#30340;&#19990;&#30028;&#29702;&#35299;&#24212;&#35813;&#22312;&#30456;&#21516;&#21547;&#20041;&#30340;&#19981;&#21516;&#65288;&#24343;&#38647;&#26684;&#65289;&#24847;&#20041;&#19978;&#20445;&#25345;&#19968;&#33268;&#30340;&#24605;&#24819;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#19981;&#26159;&#36890;&#36807;&#27491;&#30830;&#24615;&#26469;&#34913;&#37327;&#29702;&#35299;&#65292;&#32780;&#26159;&#36890;&#36807;&#35780;&#20272;&#27169;&#22411;&#33258;&#36523;&#29983;&#25104;&#30340;&#22810;&#20010;&#24847;&#20041;&#20043;&#38388;&#30340;&#19968;&#33268;&#24615;&#26469;&#34913;&#37327;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#20363;&#21270;&#19968;&#20010;&#27979;&#35797;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#19981;&#21516;&#30340;&#24847;&#20041;&#26159;&#19981;&#21516;&#30340;&#35821;&#35328;&#65292;&#22240;&#27492;&#23558;&#22810;&#35821;&#35328;&#33258;&#25105;&#19968;&#33268;&#24615;&#20316;&#20026;&#27169;&#22411;&#29702;&#35299;&#30340;&#26816;&#39564;&#24182;&#21516;&#26102;&#35299;&#20915;&#22810;&#35821;&#35328;&#30340;&#37325;&#35201;&#20027;&#39064;&#12290;&#25105;&#20204;&#20197;&#26368;&#26032;&#29256;&#26412;&#30340;ChatGPT&#20026;&#25105;&#20204;&#30340;&#30740;&#31350;&#23545;&#35937;&#65292;&#22312;&#19977;&#31181;&#19981;&#21516;&#35821;&#35328;&#20013;&#35780;&#20272;&#20004;&#20010;&#19981;&#21516;&#20219;&#21153;&#30340;&#22810;&#35821;&#35328;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;ChatGPT&#22312;&#22810;&#35821;&#35328;&#19968;&#33268;&#24615;&#26041;&#38754;&#30340;&#20248;&#31168;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
At the staggering pace with which the capabilities of large language models (LLMs) are increasing, creating future-proof evaluation sets to assess their understanding becomes more and more challenging. In this paper, we propose a novel paradigm for evaluating LLMs which leverages the idea that correct world understanding should be consistent across different (Fregean) senses of the same meaning. Accordingly, we measure understanding not in terms of correctness but by evaluating consistency across multiple senses that are generated by the model itself. We showcase our approach by instantiating a test where the different senses are different languages, hence using multilingual self-consistency as a litmus test for the model's understanding and simultaneously addressing the important topic of multilingualism. Taking one of the latest versions of ChatGPT as our object of study, we evaluate multilingual consistency for two different tasks across three different languages. We show that its m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#27010;&#29575;&#30340;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#24230;&#37327;&#22768;&#26126;&#24615;&#36807;&#31243;&#35268;&#33539;&#30340;&#28385;&#36275;&#24230;&#65292;&#24182;&#21487;&#29992;&#20110;&#21457;&#29616;&#12289;&#26816;&#26597;&#21644;&#28418;&#31227;&#26816;&#27979;&#31561;&#26041;&#38754;&#12290;</title><link>http://arxiv.org/abs/2305.05418</link><description>&lt;p&gt;
&#22522;&#20110;&#35268;&#21017;&#30340;LTLf&#27969;&#31243;&#35268;&#33539;&#27979;&#37327;&#65306;&#19968;&#31181;&#27010;&#29575;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Measuring Rule-based LTLf Process Specifications: A Probabilistic Data-driven Approach. (arXiv:2305.05418v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05418
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#27010;&#29575;&#30340;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#24230;&#37327;&#22768;&#26126;&#24615;&#36807;&#31243;&#35268;&#33539;&#30340;&#28385;&#36275;&#24230;&#65292;&#24182;&#21487;&#29992;&#20110;&#21457;&#29616;&#12289;&#26816;&#26597;&#21644;&#28418;&#31227;&#26816;&#27979;&#31561;&#26041;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22768;&#26126;&#24615;&#27969;&#31243;&#35268;&#33539;&#36890;&#36807;&#22522;&#20110;&#26377;&#38480;&#36712;&#36857;&#30340;&#32447;&#24615;&#26102;&#24577;&#36923;&#36753;&#65288;LTLf&#65289;&#35268;&#21017;&#26469;&#23450;&#20041;&#27969;&#31243;&#34892;&#20026;&#12290;&#22312;&#25366;&#25496;&#19978;&#19979;&#25991;&#20013;&#65292;&#36825;&#20123;&#35268;&#33539;&#26159;&#20174;&#20449;&#24687;&#31995;&#32479;&#65288;&#21363;&#20107;&#20214;&#26085;&#24535;&#65289;&#35760;&#24405;&#30340;&#36816;&#34892;&#30340;&#22810;&#37325;&#38598;&#20013;&#25512;&#26029;&#20986;&#24182;&#36827;&#34892;&#26816;&#26597;&#30340;&#12290;&#20026;&#27492;&#65292;&#33021;&#22815;&#34913;&#37327;&#27969;&#31243;&#25968;&#25454;&#31526;&#21512;&#35268;&#33539;&#30340;&#31243;&#24230;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#25366;&#25496;&#21644;&#39564;&#35777;&#25216;&#26415;&#20165;&#20998;&#26512;&#35268;&#21017;&#26412;&#36523;&#65292;&#24573;&#30053;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#26694;&#26550;&#26469;&#35774;&#35745;&#22768;&#26126;&#24615;&#36807;&#31243;&#35268;&#33539;&#30340;&#27010;&#29575;&#24230;&#37327;&#26041;&#24335;&#12290;&#36827;&#32780;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#27979;&#37327;&#20107;&#20214;&#26085;&#24535;&#19978;&#35268;&#33539;&#28385;&#36275;&#24230;&#30340;&#25216;&#26415;&#12290;&#20026;&#20102;&#35780;&#20272;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#20351;&#29992;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;&#23427;&#22312;&#21457;&#29616;&#12289;&#26816;&#26597;&#21644;&#28418;&#31227;&#26816;&#27979;&#26041;&#38754;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Declarative process specifications define the behavior of processes by means of rules based on Linear Temporal Logic on Finite Traces (LTLf). In a mining context, these specifications are inferred from, and checked on, multi-sets of runs recorded by information systems (namely, event logs). To this end, being able to gauge the degree to which process data comply with a specification is key. However, existing mining and verification techniques analyze the rules in isolation, thereby disregarding their interplay. In this paper, we introduce a framework to devise probabilistic measures for declarative process specifications. Thereupon, we propose a technique that measures the degree of satisfaction of specifications over event logs. To assess our approach, we conduct an evaluation with real-world data, evidencing its applicability in discovery, checking, and drift detection contexts.
&lt;/p&gt;</description></item><item><title>LAVA&#26159;&#19968;&#20010;&#23398;&#20064;&#31639;&#27861;&#26080;&#20851;&#30340;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#26041;&#27861;&#65292;&#23427;&#32467;&#21512;&#20102;&#23398;&#20064;&#31639;&#27861;&#30340;&#32479;&#35745;&#29305;&#24615;&#21644;&#35757;&#32451;&#25968;&#25454;&#30340;&#23646;&#24615;&#65292;&#36890;&#36807;&#36845;&#20195;&#20272;&#35745;&#25968;&#25454;&#20540;&#26469;&#23454;&#29616;&#12290;LAVA&#27604;&#29616;&#26377;&#26041;&#27861;&#35745;&#31639;&#36895;&#24230;&#26356;&#24555;&#65292;&#31934;&#24230;&#26356;&#39640;&#65292;&#24182;&#19988;&#21487;&#20197;&#20026;&#19981;&#21516;&#30340;&#24212;&#29992;&#25552;&#20379;&#26377;&#24847;&#20041;&#30340;&#25968;&#25454;&#25490;&#21517;&#12290;</title><link>http://arxiv.org/abs/2305.00054</link><description>&lt;p&gt;
LAVA: &#26080;&#38656;&#39044;&#23450;&#23398;&#20064;&#31639;&#27861;&#30340;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
LAVA: Data Valuation without Pre-Specified Learning Algorithms. (arXiv:2305.00054v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00054
&lt;/p&gt;
&lt;p&gt;
LAVA&#26159;&#19968;&#20010;&#23398;&#20064;&#31639;&#27861;&#26080;&#20851;&#30340;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#26041;&#27861;&#65292;&#23427;&#32467;&#21512;&#20102;&#23398;&#20064;&#31639;&#27861;&#30340;&#32479;&#35745;&#29305;&#24615;&#21644;&#35757;&#32451;&#25968;&#25454;&#30340;&#23646;&#24615;&#65292;&#36890;&#36807;&#36845;&#20195;&#20272;&#35745;&#25968;&#25454;&#20540;&#26469;&#23454;&#29616;&#12290;LAVA&#27604;&#29616;&#26377;&#26041;&#27861;&#35745;&#31639;&#36895;&#24230;&#26356;&#24555;&#65292;&#31934;&#24230;&#26356;&#39640;&#65292;&#24182;&#19988;&#21487;&#20197;&#20026;&#19981;&#21516;&#30340;&#24212;&#29992;&#25552;&#20379;&#26377;&#24847;&#20041;&#30340;&#25968;&#25454;&#25490;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#38382;&#39064;&#26159;&#22914;&#20309;&#20844;&#24179;&#22320;&#20998;&#37197;&#23398;&#20064;&#31639;&#27861;&#30340;&#39564;&#35777;&#24615;&#33021;&#65292;&#33268;&#20351;&#35745;&#31639;&#24471;&#21040;&#30340;&#25968;&#25454;&#20215;&#20540;&#20381;&#36182;&#20110;&#24213;&#23618;&#23398;&#20064;&#31639;&#27861;&#30340;&#35768;&#22810;&#35774;&#35745;&#36873;&#25321;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;LAVA&#65292;&#35813;&#26694;&#26550;&#32467;&#21512;&#20102;&#23398;&#20064;&#31639;&#27861;&#30340;&#32479;&#35745;&#29305;&#24615;&#21644;&#35757;&#32451;&#25968;&#25454;&#30340;&#23646;&#24615;&#65292;&#36845;&#20195;&#20272;&#35745;&#25968;&#25454;&#20540;&#65292;&#20351;&#20854;&#26080;&#35270;&#19979;&#28216;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;LAVA&#27604;&#29616;&#26377;&#26041;&#27861;&#35745;&#31639;&#36895;&#24230;&#26356;&#24555;&#65292;&#31934;&#24230;&#26356;&#39640;&#65292;&#24182;&#19988;&#23427;&#21487;&#20197;&#20026;&#19981;&#21516;&#30340;&#24212;&#29992;&#25552;&#20379;&#26377;&#24847;&#20041;&#30340;&#25968;&#25454;&#25490;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;
Traditionally, data valuation is posed as a problem of equitably splitting the validation performance of a learning algorithm among the training data. As a result, the calculated data values depend on many design choices of the underlying learning algorithm. However, this dependence is undesirable for many use cases of data valuation, such as setting priorities over different data sources in a data acquisition process and informing pricing mechanisms in a data marketplace. In these scenarios, data needs to be valued before the actual analysis and the choice of the learning algorithm is still undetermined then. Another side-effect of the dependence is that to assess the value of individual points, one needs to re-run the learning algorithm with and without a point, which incurs a large computation burden.  This work leapfrogs over the current limits of data valuation methods by introducing a new framework that can value training data in a way that is oblivious to the downstream learning
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#30701;&#25991;&#26412;&#21305;&#37197;&#27169;&#22411;&#65292;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#34917;&#20805;&#21477;&#23376;&#65292;&#32467;&#21512;&#23545;&#27604;&#23398;&#20064;&#21644;&#22806;&#37096;&#30693;&#35782;&#36827;&#34892;&#35821;&#20041;&#21305;&#37197;&#65292;&#24182;&#20351;&#29992;&#20851;&#38190;&#35789;&#36991;&#20813;&#22122;&#22768;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2304.03898</link><description>&lt;p&gt;
&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#21152;&#24378;&#30693;&#35782;&#30340;&#30701;&#25991;&#26412;&#21305;&#37197;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
The Short Text Matching Model Enhanced with Knowledge via Contrastive Learning. (arXiv:2304.03898v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03898
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#30701;&#25991;&#26412;&#21305;&#37197;&#27169;&#22411;&#65292;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#34917;&#20805;&#21477;&#23376;&#65292;&#32467;&#21512;&#23545;&#27604;&#23398;&#20064;&#21644;&#22806;&#37096;&#30693;&#35782;&#36827;&#34892;&#35821;&#20041;&#21305;&#37197;&#65292;&#24182;&#20351;&#29992;&#20851;&#38190;&#35789;&#36991;&#20813;&#22122;&#22768;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#30701;&#25991;&#26412;&#21305;&#37197;&#20219;&#21153;&#22312;&#24191;&#21578;&#25628;&#32034;&#21644;&#25512;&#33616;&#39046;&#22495;&#24471;&#21040;&#20102;&#24191;&#27867;&#24212;&#29992;&#12290;&#30001;&#20110;&#25991;&#26412;&#38271;&#24230;&#30701;&#65292;&#35821;&#20041;&#20449;&#24687;&#21294;&#20047;&#21644;&#21333;&#35789;&#27495;&#20041;&#38382;&#39064;&#25104;&#20026;&#27492;&#31867;&#20219;&#21153;&#30340;&#38590;&#28857;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#24341;&#20837;&#25991;&#26412;&#34917;&#20805;&#21477;&#23376;&#25110;&#30693;&#35782;&#24211;&#26469;&#25552;&#20379;&#38468;&#21152;&#30340;&#29305;&#24449;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#27809;&#26377;&#20805;&#20998;&#22320;&#20132;&#20114;&#21407;&#22987;&#21477;&#23376;&#21644;&#34917;&#20805;&#21477;&#23376;&#65292;&#20063;&#27809;&#26377;&#32771;&#34385;&#21040;&#22806;&#37096;&#30693;&#35782;&#24211;&#24341;&#20837;&#30340;&#22122;&#22768;&#38382;&#39064;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#23545;&#27604;&#23398;&#20064;&#21644;&#22806;&#37096;&#30693;&#35782;&#30340;&#30701;&#25991;&#26412;&#21305;&#37197;&#27169;&#22411;&#12290;&#35813;&#27169;&#22411;&#21033;&#29992;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#23545;&#24212;&#30340;&#34917;&#20805;&#21477;&#23376;&#65292;&#24182;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#25351;&#23548;&#27169;&#22411;&#33719;&#24471;&#26356;&#20855;&#35821;&#20041;&#21305;&#37197;&#24615;&#30340;&#21407;&#22987;&#21477;&#23376;&#32534;&#30721;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#36991;&#20813;&#22122;&#22768;&#65292;&#25105;&#20204;&#20351;&#29992;&#20851;&#38190;&#35789;&#20316;&#20026;&#21407;&#22987;&#21477;&#23376;&#30340;&#20027;&#35201;&#35821;&#20041;&#36827;&#34892;&#26816;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, short Text Matching tasks have been widely applied in the fields ofadvertising search and recommendation. The difficulty lies in the lack of semantic information and word ambiguity caused by the short length of the text. Previous works have introduced complement sentences or knowledge bases to provide additional feature information. However, these methods have not fully interacted between the original sentence and the complement sentence, and have not considered the noise issue that may arise from the introduction of external knowledge bases. Therefore, this paper proposes a short Text Matching model that combines contrastive learning and external knowledge. The model uses a generative model to generate corresponding complement sentences and uses the contrastive learning method to guide the model to obtain more semantically meaningful encoding of the original sentence. In addition, to avoid noise, we use keywords as the main semantics of the original sentence to retrie
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#31995;&#32479;&#35770;&#36807;&#31243;&#20998;&#26512;&#65288;STPA&#65289;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#37319;&#29992;ChatGPT&#23545;&#33258;&#21160;&#32039;&#24613;&#21046;&#21160;&#65288;AEB&#65289;&#31995;&#32479;&#36827;&#34892;&#20102;&#26696;&#20363;&#30740;&#31350;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#37325;&#22797;&#21452;&#24037;&#20132;&#20114;&#26041;&#27861;&#26159;&#26368;&#26377;&#25928;&#30340;&#65292;&#24182;&#26174;&#30528;&#25552;&#39640;&#20102;STPA&#30340;&#36136;&#37327;&#12290;&#26412;&#30740;&#31350;&#35777;&#26126;&#65292;LLMs&#21487;&#20197;&#24212;&#29992;&#20110;&#23433;&#20840;&#20998;&#26512;&#65292;&#24182;&#20026;&#23433;&#20840;&#20851;&#38190;&#31995;&#32479;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2304.01246</link><description>&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#26102;&#20195;&#30340;&#23433;&#20840;&#20998;&#26512;&#65306;&#32842;&#22825;GPT&#22312;STPA&#26696;&#20363;&#30740;&#31350;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Safety Analysis in the Era of Large Language Models: A Case Study of STPA using ChatGPT. (arXiv:2304.01246v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01246
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#31995;&#32479;&#35770;&#36807;&#31243;&#20998;&#26512;&#65288;STPA&#65289;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#37319;&#29992;ChatGPT&#23545;&#33258;&#21160;&#32039;&#24613;&#21046;&#21160;&#65288;AEB&#65289;&#31995;&#32479;&#36827;&#34892;&#20102;&#26696;&#20363;&#30740;&#31350;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#37325;&#22797;&#21452;&#24037;&#20132;&#20114;&#26041;&#27861;&#26159;&#26368;&#26377;&#25928;&#30340;&#65292;&#24182;&#26174;&#30528;&#25552;&#39640;&#20102;STPA&#30340;&#36136;&#37327;&#12290;&#26412;&#30740;&#31350;&#35777;&#26126;&#65292;LLMs&#21487;&#20197;&#24212;&#29992;&#20110;&#23433;&#20840;&#20998;&#26512;&#65292;&#24182;&#20026;&#23433;&#20840;&#20851;&#38190;&#31995;&#32479;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#22914;ChatGPT&#21644;BERT&#65292;&#30001;&#20110;&#20854;&#20855;&#26377;&#31867;&#20284;&#20110;&#20154;&#31867;&#30340;&#23545;&#35805;&#65292;&#22312;&#35768;&#22810;&#30693;&#35782;&#39046;&#22495;&#20013;&#20855;&#26377;&#35814;&#32454;&#21644;&#26126;&#30830;&#30340;&#31572;&#26696;&#65292;&#27491;&#22312;&#24341;&#39046;&#19968;&#22330;&#26032;&#30340;&#20154;&#24037;&#26234;&#33021;&#28909;&#28526;&#12290;&#34429;&#28982;LLMs&#27491;&#22312;&#36805;&#36895;&#24212;&#29992;&#20110;&#35768;&#22810;&#20154;&#24037;&#26234;&#33021;&#24212;&#29992;&#39046;&#22495;&#65292;&#20294;&#25105;&#20204;&#23545;&#20197;&#19979;&#38382;&#39064;&#24863;&#20852;&#36259;&#65306;&#23433;&#20840;&#20851;&#38190;&#31995;&#32479;&#30340;&#23433;&#20840;&#20998;&#26512;&#26159;&#21542;&#21487;&#20197;&#21033;&#29992;LLMs&#65311;&#20026;&#20102;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20351;&#29992;ChatGPT&#23545;&#33258;&#21160;&#32039;&#24613;&#21046;&#21160;&#65288;AEB&#65289;&#31995;&#32479;&#30340;&#31995;&#32479;&#35770;&#36807;&#31243;&#20998;&#26512;&#65288;STPA&#65289;&#36827;&#34892;&#20102;&#26696;&#20363;&#30740;&#31350;&#12290;STPA&#26159;&#26368;&#26222;&#36941;&#30340;&#21361;&#38505;&#20998;&#26512;&#25216;&#26415;&#20043;&#19968;&#65292;&#20294;&#23427;&#23384;&#22312;&#35832;&#22810;&#23616;&#38480;&#24615;&#65292;&#20363;&#22914;&#39640;&#22797;&#26434;&#24615;&#21644;&#20027;&#35266;&#24615;&#65292;&#26412;&#25991;&#26088;&#22312;&#25506;&#35752;ChatGPT&#30340;&#24212;&#29992;&#65292;&#20197;&#35299;&#20915;&#36825;&#20123;&#23616;&#38480;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#36890;&#36807;&#32771;&#34385;&#20854;&#19982;&#20154;&#31867;&#19987;&#23478;&#30340;&#20132;&#20114;&#65292;&#30740;&#31350;&#20102;&#19977;&#31181;&#23558;ChatGPT&#32435;&#20837;STPA&#20013;&#30340;&#26041;&#27861;&#65306;&#19968;&#27425;&#24615;&#21333;&#24037;&#20132;&#20114;&#12289;&#37325;&#22797;&#21333;&#24037;&#20132;&#20114;&#21644;&#37325;&#22797;&#21452;&#24037;&#20132;&#20114;&#12290;&#27604;&#36739;&#32467;&#26524;&#34920;&#26126;&#65306;&#65288;i&#65289;&#22312;&#27809;&#26377;&#20154;&#31867;&#19987;&#23478;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;ChatGPT&#19981;&#33021;&#20026;STPA&#25552;&#20379;&#36275;&#22815;&#30340;&#20449;&#24687;&#65307;&#65288;ii&#65289;&#19968;&#27425;&#24615;&#21333;&#24037;&#20132;&#20114;&#23545;STPA&#26377;&#24110;&#21161;&#65292;&#20294;&#19981;&#22914;&#37325;&#22797;&#20132;&#20114;&#26377;&#25928;&#65307;&#65288;iii&#65289;&#37325;&#22797;&#21452;&#24037;&#20132;&#20114;&#19968;&#33268;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#65292;&#24182;&#26174;&#30528;&#25552;&#39640;&#20102;STPA&#30340;&#36136;&#37327;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;LLMs&#21487;&#20197;&#24212;&#29992;&#20110;&#23433;&#20840;&#20998;&#26512;&#65292;&#24182;&#20026;AEB&#20197;&#22806;&#30340;&#20854;&#20182;&#23433;&#20840;&#20851;&#38190;&#31995;&#32479;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs), such as ChatGPT and BERT, are leading a new AI heatwave due to its human-like conversations with detailed and articulate answers across many domains of knowledge. While LLMs are being quickly applied to many AI application domains, we are interested in the following question: Can safety analysis for safety-critical systems make use of LLMs? To answer, we conduct a case study of Systems Theoretic Process Analysis (STPA) on Automatic Emergency Brake (AEB) systems using ChatGPT. STPA, one of the most prevalent techniques for hazard analysis, is known to have limitations such as high complexity and subjectivity, which this paper aims to explore the use of ChatGPT to address. Specifically, three ways of incorporating ChatGPT into STPA are investigated by considering its interaction with human experts: one-off simplex interaction, recurring simplex interaction, and recurring duplex interaction. Comparative results reveal that: (i) using ChatGPT without human exp
&lt;/p&gt;</description></item><item><title>&#36817;&#24180;&#26469;&#28145;&#24230;&#23398;&#20064;&#22312;&#21307;&#23398;&#22270;&#20687;&#20998;&#26512;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#20294;&#36825;&#31181;&#26041;&#27861;&#30340;&#26631;&#35760;&#20195;&#20215;&#22823;&#65292;&#26631;&#35760;&#19981;&#36275;&#12290;&#22240;&#27492;&#21457;&#23637;&#20102;&#39640;&#25928;&#26631;&#35760;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#20805;&#20998;&#21033;&#29992;&#26410;&#26631;&#35760;&#30340;&#21644;&#24369;&#26631;&#35760;&#30340;&#25968;&#25454;&#12290;&#35813;&#32508;&#36848;&#24635;&#32467;&#20102;&#36825;&#26041;&#38754;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;</title><link>http://arxiv.org/abs/2303.12484</link><description>&lt;p&gt;
&#21307;&#23398;&#22270;&#20687;&#20998;&#26512;&#20013;&#39640;&#25928;&#26631;&#35760;&#28145;&#24230;&#23398;&#20064;&#30340;&#25361;&#25112;&#19982;&#26410;&#26469;&#26041;&#21521;
&lt;/p&gt;
&lt;p&gt;
Label-Efficient Deep Learning in Medical Image Analysis: Challenges and Future Directions. (arXiv:2303.12484v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12484
&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#28145;&#24230;&#23398;&#20064;&#22312;&#21307;&#23398;&#22270;&#20687;&#20998;&#26512;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#20294;&#36825;&#31181;&#26041;&#27861;&#30340;&#26631;&#35760;&#20195;&#20215;&#22823;&#65292;&#26631;&#35760;&#19981;&#36275;&#12290;&#22240;&#27492;&#21457;&#23637;&#20102;&#39640;&#25928;&#26631;&#35760;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#20805;&#20998;&#21033;&#29992;&#26410;&#26631;&#35760;&#30340;&#21644;&#24369;&#26631;&#35760;&#30340;&#25968;&#25454;&#12290;&#35813;&#32508;&#36848;&#24635;&#32467;&#20102;&#36825;&#26041;&#38754;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#36817;&#24180;&#26469;&#24471;&#21040;&#20102;&#36805;&#36895;&#21457;&#23637;&#65292;&#24182;&#22312;&#24191;&#27867;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#20294;&#26159;&#65292;&#35757;&#32451;&#27169;&#22411;&#36890;&#24120;&#38656;&#35201;&#25910;&#38598;&#22823;&#37327;&#26631;&#35760;&#25968;&#25454;&#65292;&#36825;&#38656;&#35201;&#26114;&#36149;&#32791;&#26102;&#12290;&#29305;&#21035;&#26159;&#22312;&#21307;&#23398;&#22270;&#20687;&#20998;&#26512;&#65288;MIA&#65289;&#39046;&#22495;&#65292;&#25968;&#25454;&#26377;&#38480;&#65292;&#26631;&#31614;&#24456;&#38590;&#33719;&#24471;&#12290;&#22240;&#27492;&#65292;&#20154;&#20204;&#24320;&#21457;&#20102;&#39640;&#25928;&#26631;&#35760;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#20805;&#20998;&#21033;&#29992;&#26631;&#35760;&#25968;&#25454;&#20197;&#21450;&#38750;&#26631;&#35760;&#21644;&#24369;&#26631;&#35760;&#25968;&#25454;&#30340;&#20016;&#23500;&#24615;&#12290;&#22312;&#26412;&#35843;&#26597;&#20013;&#65292;&#25105;&#20204;&#23545;&#36817;300&#31687;&#35770;&#25991;&#36827;&#34892;&#20102;&#24191;&#27867;&#35843;&#26597;&#65292;&#20197;&#20840;&#38754;&#27010;&#36848;&#26368;&#26032;&#36827;&#23637;&#30340;&#39640;&#25928;&#26631;&#35760;&#23398;&#20064;&#31574;&#30053;&#22312;MIA&#20013;&#30340;&#30740;&#31350;&#29616;&#29366;&#12290;&#25105;&#20204;&#39318;&#20808;&#20171;&#32461;&#39640;&#25928;&#26631;&#35760;&#23398;&#20064;&#30340;&#32972;&#26223;&#65292;&#24182;&#23558;&#19981;&#21516;&#26041;&#26696;&#30340;&#26041;&#27861;&#24402;&#31867;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#36890;&#36807;&#27599;&#31181;&#26041;&#26696;&#35814;&#32454;&#30740;&#31350;&#20102;&#30446;&#21069;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#28145;&#20837;&#35843;&#26597;&#65292;&#35206;&#30422;&#20102;&#19981;&#20165;&#26159;&#26631;&#20934;&#31574;&#30053;&#65292;&#36824;&#21253;&#25324;&#20351;&#29992;&#21518;&#22788;&#29702;&#21644;&#38598;&#21512;&#26041;&#27861;&#31561;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning has seen rapid growth in recent years and achieved state-of-the-art performance in a wide range of applications. However, training models typically requires expensive and time-consuming collection of large quantities of labeled data. This is particularly true within the scope of medical imaging analysis (MIA), where data are limited and labels are expensive to be acquired. Thus, label-efficient deep learning methods are developed to make comprehensive use of the labeled data as well as the abundance of unlabeled and weak-labeled data. In this survey, we extensively investigated over 300 recent papers to provide a comprehensive overview of recent progress on label-efficient learning strategies in MIA. We first present the background of label-efficient learning and categorize the approaches into different schemes. Next, we examine the current state-of-the-art methods in detail through each scheme. Specifically, we provide an in-depth investigation, covering not only canonic
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#39318;&#27425;&#36890;&#36807;&#25512;&#23548;&#27867;&#21270;&#35823;&#24046;&#19978;&#30028;&#22238;&#31572;&#20102;&#36716;&#25442;&#30340;&#20302;&#31209;&#21442;&#25968;&#21270;&#22914;&#20309;&#24433;&#21709;&#24352;&#37327;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#34892;&#20026;&#65292;&#32467;&#26524;&#26174;&#31034;&#36890;&#36807;&#31934;&#30830;&#30340;&#36716;&#25442;&#20302;&#31209;&#21442;&#25968;&#21270;&#21387;&#32553;&#30340;t-NNs&#21487;&#20197;&#23454;&#29616;&#26356;&#23574;&#38160;&#30340;&#23545;&#25239;&#27867;&#21270;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2303.00196</link><description>&lt;p&gt;
&#36716;&#25442;&#30340;&#20302;&#31209;&#21442;&#25968;&#21270;&#21487;&#20197;&#24110;&#21161;&#24352;&#37327;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#31283;&#20581;&#30340;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Transformed Low-Rank Parameterization Can Help Robust Generalization for Tensor Neural Networks. (arXiv:2303.00196v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.00196
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#39318;&#27425;&#36890;&#36807;&#25512;&#23548;&#27867;&#21270;&#35823;&#24046;&#19978;&#30028;&#22238;&#31572;&#20102;&#36716;&#25442;&#30340;&#20302;&#31209;&#21442;&#25968;&#21270;&#22914;&#20309;&#24433;&#21709;&#24352;&#37327;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#34892;&#20026;&#65292;&#32467;&#26524;&#26174;&#31034;&#36890;&#36807;&#31934;&#30830;&#30340;&#36716;&#25442;&#20302;&#31209;&#21442;&#25968;&#21270;&#21387;&#32553;&#30340;t-NNs&#21487;&#20197;&#23454;&#29616;&#26356;&#23574;&#38160;&#30340;&#23545;&#25239;&#27867;&#21270;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#25454;&#31185;&#23398;&#20013;&#65292;&#23454;&#29616;&#39640;&#25928;&#19988;&#31283;&#20581;&#30340;&#22810;&#36890;&#36947;&#25968;&#25454;&#23398;&#20064;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#36890;&#36807;&#21033;&#29992;&#36716;&#25442;&#22495;&#20013;&#30340;&#20302;&#31209;&#24615;&#65292;&#21363;&#36716;&#25442;&#30340;&#20302;&#31209;&#24615;&#65292;&#24352;&#37327;&#22855;&#24322;&#20540;&#20998;&#35299;&#65288;t-SVD&#65289;&#22312;&#22810;&#36890;&#36947;&#25968;&#25454;&#34920;&#31034;&#26041;&#38754;&#21462;&#24471;&#20102;&#24191;&#27867;&#30340;&#25104;&#21151;&#65292;&#24182;&#26368;&#36817;&#25193;&#23637;&#21040;&#20102;&#20989;&#25968;&#34920;&#31034;&#65292;&#22914;&#20855;&#26377;t-&#20056;&#31215;&#23618;&#65288;t-NNs&#65289;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#28982;&#32780;&#65292;t-SVD&#29702;&#35770;&#19978;&#22914;&#20309;&#24433;&#21709;t-NNs&#30340;&#23398;&#20064;&#34892;&#20026;&#20173;&#19981;&#28165;&#26970;&#12290;&#26412;&#25991;&#31532;&#19968;&#27425;&#36890;&#36807;&#25512;&#23548;&#26631;&#20934;&#21644;&#23545;&#25239;&#35757;&#32451;&#30340;t-NNs&#30340;&#27867;&#21270;&#35823;&#24046;&#19978;&#30028;&#26469;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#12290;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#36890;&#36807;&#31934;&#30830;&#30340;&#36716;&#25442;&#20302;&#31209;&#21442;&#25968;&#21270;&#21387;&#32553;&#30340;t-NNs&#21487;&#20197;&#23454;&#29616;&#26356;&#23574;&#38160;&#30340;&#23545;&#25239;&#27867;&#21270;&#19978;&#30028;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#23613;&#31649;t-NNs&#24456;&#23569;&#20855;&#26377;&#23436;&#20840;&#36716;&#25442;&#30340;&#20302;&#31209;&#26435;&#37325;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#36827;&#19968;&#27493;&#34920;&#26126;&#65292;&#36890;&#36807;&#20351;&#29992;&#26799;&#24230;&#27969;&#65288;GF&#65289;&#36827;&#34892;&#23545;&#25239;&#24615;&#35757;&#32451;&#65292;&#36807;&#21442;&#25968;&#21270;&#30340;t-NNs&#20855;&#26377;ReLU
&lt;/p&gt;
&lt;p&gt;
Achieving efficient and robust multi-channel data learning is a challenging task in data science. By exploiting low-rankness in the transformed domain, i.e., transformed low-rankness, tensor Singular Value Decomposition (t-SVD) has achieved extensive success in multi-channel data representation and has recently been extended to function representation such as Neural Networks with t-product layers (t-NNs). However, it still remains unclear how t-SVD theoretically affects the learning behavior of t-NNs. This paper is the first to answer this question by deriving the upper bounds of the generalization error of both standard and adversarially trained t-NNs. It reveals that the t-NNs compressed by exact transformed low-rank parameterization can achieve a sharper adversarial generalization bound. In practice, although t-NNs rarely have exactly transformed low-rank weights, our analysis further shows that by adversarial training with gradient flow (GF), the over-parameterized t-NNs with ReLU 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#20013;&#20351;&#29992;&#21322;&#30417;&#30563;&#23398;&#20064;&#21644;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#36827;&#34892;&#34394;&#20551;&#26816;&#27979;&#30340;&#26041;&#27861;&#65292;&#23454;&#39564;&#35777;&#26126;&#20165;&#20351;&#29992;100&#20010;&#26631;&#35760;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#65292;&#20934;&#30830;&#29575;&#36798;&#21040;&#20102;91\%&#12290;</title><link>http://arxiv.org/abs/2212.01071</link><description>&lt;p&gt;
&#36890;&#36807;&#21322;&#30417;&#30563;&#23398;&#20064;&#21644;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#22312;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#20013;&#36827;&#34892;&#34394;&#20551;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Fake detection in imbalance dataset by Semi-supervised learning with GAN. (arXiv:2212.01071v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.01071
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#20013;&#20351;&#29992;&#21322;&#30417;&#30563;&#23398;&#20064;&#21644;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#36827;&#34892;&#34394;&#20551;&#26816;&#27979;&#30340;&#26041;&#27861;&#65292;&#23454;&#39564;&#35777;&#26126;&#20165;&#20351;&#29992;100&#20010;&#26631;&#35760;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#65292;&#20934;&#30830;&#29575;&#36798;&#21040;&#20102;91\%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#31038;&#20132;&#23186;&#20307;&#30340;&#24555;&#36895;&#21457;&#23637;&#65292;&#39578;&#25200;&#34892;&#20026;&#21464;&#24471;&#26356;&#21152;&#26222;&#36941;&#65292;&#36825;&#23548;&#33268;&#20102;&#34394;&#20551;&#26816;&#27979;&#25104;&#20026;&#30740;&#31350;&#20154;&#21592;&#20013;&#24341;&#20154;&#27880;&#30446;&#30340;&#39046;&#22495;&#12290;&#25968;&#25454;&#30340;&#22270;&#24418;&#29305;&#24615;&#20197;&#21450;&#22823;&#37327;&#33410;&#28857;&#23548;&#33268;&#20102;&#35768;&#22810;&#38556;&#30861;&#65292;&#21253;&#25324;&#30697;&#38453;&#20013;&#22823;&#37327;&#26080;&#20851;&#29305;&#24449;&#30340;&#39640;&#31163;&#25955;&#24230;&#21644;&#19981;&#24179;&#34913;&#31867;&#21035;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#26412;&#25991;&#37319;&#29992;&#20102;&#33258;&#32534;&#30721;&#22120;&#21644;&#21322;&#30417;&#30563;&#23398;&#20064;&#19982;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#31639;&#27861;&#30340;&#32452;&#21512;&#65292;&#21363;SGAN&#12290;&#26412;&#25991;&#23558;&#23569;&#37327;&#26631;&#31614;&#24212;&#29992;&#20110;SGAN&#20316;&#20026;&#20998;&#31867;&#22120;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#20165;&#20351;&#29992;100&#20010;&#26631;&#35760;&#26679;&#26412;&#65292;&#35813;&#26041;&#27861;&#22312;&#26816;&#27979;&#34394;&#20551;&#36134;&#25143;&#26041;&#38754;&#30340;&#20934;&#30830;&#29575;&#36798;&#21040;&#20102;91\%&#12290;
&lt;/p&gt;
&lt;p&gt;
As social media grows faster, harassment becomes more prevalent which leads to considered fake detection a fascinating field among researchers. The graph nature of data with the large number of nodes caused different obstacles including a considerable amount of unrelated features in matrices as high dispersion and imbalance classes in the dataset. To deal with these issues Auto-encoders and a combination of semi-supervised learning and the GAN algorithm which is called SGAN were used. This paper is deploying a smaller number of labels and applying SGAN as a classifier. The result of this test showed that the accuracy had reached 91\% in detecting fake accounts using only 100 labeled samples.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22810;&#28857;-BAX&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#34394;&#25311;&#30446;&#26631;&#26469;&#39640;&#25928;&#35843;&#25972;&#31890;&#23376;&#21152;&#36895;&#22120;&#30340;&#21457;&#23556;&#24230;&#12290;&#35813;&#26041;&#27861;&#36991;&#20813;&#20102;&#20351;&#29992;&#20256;&#32479;&#30340;&#40657;&#30418;&#20248;&#21270;&#22120;&#36827;&#34892;&#32531;&#24930;&#32780;&#20302;&#25928;&#30340;&#22810;&#28857;&#26597;&#35810;&#65292;&#24182;&#36890;&#36807;&#24555;&#36895;&#23398;&#20064;&#27169;&#22411;&#35745;&#31639;&#21457;&#23556;&#24230;&#30446;&#26631;&#12290;&#35813;&#26041;&#27861;&#22312;Linac&#30456;&#24178;&#20809;&#28304;(LCLS)&#21644;Facility for Adv&#20013;&#26368;&#23567;&#21270;&#21457;&#23556;&#24230;&#12290;</title><link>http://arxiv.org/abs/2209.04587</link><description>&lt;p&gt;
&#22810;&#28857;-BAX: &#19968;&#31181;&#36890;&#36807;&#34394;&#25311;&#30446;&#26631;&#39640;&#25928;&#35843;&#25972;&#31890;&#23376;&#21152;&#36895;&#22120;&#21457;&#23556;&#24230;&#30340;&#26032;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Multipoint-BAX: A New Approach for Efficiently Tuning Particle Accelerator Emittance via Virtual Objectives. (arXiv:2209.04587v4 [physics.acc-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.04587
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22810;&#28857;-BAX&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#34394;&#25311;&#30446;&#26631;&#26469;&#39640;&#25928;&#35843;&#25972;&#31890;&#23376;&#21152;&#36895;&#22120;&#30340;&#21457;&#23556;&#24230;&#12290;&#35813;&#26041;&#27861;&#36991;&#20813;&#20102;&#20351;&#29992;&#20256;&#32479;&#30340;&#40657;&#30418;&#20248;&#21270;&#22120;&#36827;&#34892;&#32531;&#24930;&#32780;&#20302;&#25928;&#30340;&#22810;&#28857;&#26597;&#35810;&#65292;&#24182;&#36890;&#36807;&#24555;&#36895;&#23398;&#20064;&#27169;&#22411;&#35745;&#31639;&#21457;&#23556;&#24230;&#30446;&#26631;&#12290;&#35813;&#26041;&#27861;&#22312;Linac&#30456;&#24178;&#20809;&#28304;(LCLS)&#21644;Facility for Adv&#20013;&#26368;&#23567;&#21270;&#21457;&#23556;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#26463;&#21457;&#23556;&#24230;&#23545;&#20110;&#39640;&#20142;&#24230;&#21152;&#36895;&#22120;&#30340;&#24615;&#33021;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#20248;&#21270;&#36890;&#24120;&#20250;&#21463;&#21040;&#26102;&#38388;&#38480;&#21046;&#65292;&#22240;&#20026;&#21457;&#23556;&#24230;&#35745;&#31639;&#36890;&#24120;&#26159;&#36890;&#36807;&#22235;&#26497;&#25195;&#25551;&#23436;&#25104;&#30340;&#65292;&#32780;&#22235;&#26497;&#25195;&#25551;&#36890;&#24120;&#36739;&#24930;&#12290;&#36825;&#31181;&#35745;&#31639;&#26159;&#19968;&#31181;&#22810;&#28857;&#26597;&#35810;&#65292;&#21363;&#27599;&#20010;&#26597;&#35810;&#37117;&#38656;&#35201;&#22810;&#20010;&#36741;&#21161;&#27979;&#37327;&#12290;&#20256;&#32479;&#30340;&#40657;&#30418;&#20248;&#21270;&#22120;&#65292;&#22914;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#22312;&#22788;&#29702;&#36825;&#26679;&#30340;&#30446;&#26631;&#26102;&#36895;&#24230;&#24930;&#19988;&#25928;&#29575;&#20302;&#19979;&#65292;&#22240;&#20026;&#23427;&#20204;&#24517;&#39035;&#33719;&#21462;&#23436;&#25972;&#30340;&#27979;&#37327;&#24207;&#21015;&#65292;&#20294;&#27599;&#20010;&#26597;&#35810;&#20165;&#36820;&#22238;&#21457;&#23556;&#24230;&#12290;&#25105;&#20204;&#25552;&#20986;&#23558;&#36125;&#21494;&#26031;&#31639;&#27861;&#25191;&#34892;(BAX)&#24212;&#29992;&#20110;&#26597;&#35810;&#21644;&#24314;&#27169;&#21333;&#20010;&#26463;&#27969;&#23610;&#23544;&#27979;&#37327;&#12290;BAX&#36890;&#36807;&#20351;&#29992;&#24555;&#36895;&#23398;&#20064;&#27169;&#22411;&#32780;&#19981;&#26159;&#30452;&#25509;&#20174;&#21152;&#36895;&#22120;&#20013;&#33719;&#21462;&#21457;&#23556;&#24230;&#25351;&#26631;&#26469;&#36991;&#20813;&#22312;&#21152;&#36895;&#22120;&#19978;&#36827;&#34892;&#32531;&#24930;&#30340;&#22810;&#28857;&#26597;&#35810;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20351;&#29992;BAX&#26469;&#26368;&#23567;&#21270;Linac&#30456;&#24178;&#20809;&#28304;(LCLS)&#21644;Facility for Adv&#30340;&#21457;&#23556;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Although beam emittance is critical for the performance of high-brightness accelerators, optimization is often time limited as emittance calculations, commonly done via quadrupole scans, are typically slow. Such calculations are a type of $\textit{multi-point query}$, i.e. each query requires multiple secondary measurements. Traditional black-box optimizers such as Bayesian optimization are slow and inefficient when dealing with such objectives as they must acquire the full series of measurements, but return only the emittance, with each query. We propose applying Bayesian Algorithm Execution (BAX) to instead query and model individual beam-size measurements. BAX avoids the slow multi-point query on the accelerator by acquiring points through a $\textit{virtual objective}$, i.e. calculating the emittance objective from a fast learned model rather than directly from the accelerator. Here, we use BAX to minimize emittance at the Linac Coherent Light Source (LCLS) and the Facility for Adv
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25506;&#31350;&#20102;&#30456;&#20851;&#29305;&#24449;&#23545;&#29992;&#20110;&#39044;&#27979;&#30707;&#27833;&#20844;&#21496;&#32929;&#31080;&#30340;LSTM&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#30340;&#24433;&#21709;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#28155;&#21152;&#19982;&#30707;&#27833;&#32929;&#31080;&#30456;&#20851;&#30340;&#29305;&#24449;&#24182;&#19981;&#20250;&#25552;&#39640;LSTM&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#22240;&#27492;&#24212;&#35880;&#24910;&#20381;&#38752;LSTM&#27169;&#22411;&#36827;&#34892;&#32929;&#31080;&#24066;&#22330;&#20915;&#31574;&#12290;</title><link>http://arxiv.org/abs/2201.00350</link><description>&lt;p&gt;
LSTM&#27169;&#22411;&#29992;&#20110;&#39044;&#27979;&#30707;&#27833;&#20844;&#21496;&#32929;&#31080;&#30340;&#21487;&#35299;&#37322;&#24615;&#65306;&#30456;&#20851;&#29305;&#24449;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
The Interpretability of LSTM Models for Predicting Oil Company Stocks: impacts of correlated features. (arXiv:2201.00350v3 [q-fin.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.00350
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25506;&#31350;&#20102;&#30456;&#20851;&#29305;&#24449;&#23545;&#29992;&#20110;&#39044;&#27979;&#30707;&#27833;&#20844;&#21496;&#32929;&#31080;&#30340;LSTM&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#30340;&#24433;&#21709;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#28155;&#21152;&#19982;&#30707;&#27833;&#32929;&#31080;&#30456;&#20851;&#30340;&#29305;&#24449;&#24182;&#19981;&#20250;&#25552;&#39640;LSTM&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#22240;&#27492;&#24212;&#35880;&#24910;&#20381;&#38752;LSTM&#27169;&#22411;&#36827;&#34892;&#32929;&#31080;&#24066;&#22330;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30707;&#27833;&#20844;&#21496;&#26159;&#20840;&#29699;&#26368;&#22823;&#30340;&#20844;&#21496;&#20043;&#19968;&#65292;&#30001;&#20110;&#19982;&#40644;&#37329;&#12289;&#21407;&#27833;&#21644;&#32654;&#20803;&#30456;&#20851;&#65292;&#20854;&#32463;&#27982;&#25351;&#26631;&#23545;&#20840;&#29699;&#32463;&#27982;&#21644;&#24066;&#22330;&#26377;&#30528;&#24040;&#22823;&#30340;&#24433;&#21709;&#12290;&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#30456;&#20851;&#29305;&#24449;&#23545;&#29992;&#20110;&#39044;&#27979;&#30707;&#27833;&#20844;&#21496;&#32929;&#31080;&#30340;&#38271;&#30701;&#26399;&#35760;&#24518;(LSTM)&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#30340;&#24433;&#21709;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#26631;&#20934;&#30340;LSTM&#32593;&#32476;&#65292;&#24182;&#20351;&#29992;&#21508;&#31181;&#30456;&#20851;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#35757;&#32451;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26088;&#22312;&#36890;&#36807;&#32771;&#34385;&#24433;&#21709;&#24066;&#22330;&#30340;&#22810;&#20010;&#22240;&#32032;&#65292;&#22914;&#21407;&#27833;&#20215;&#26684;&#12289;&#40644;&#37329;&#20215;&#26684;&#21644;&#32654;&#20803;&#65292;&#26469;&#25552;&#39640;&#32929;&#31080;&#20215;&#26684;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#28155;&#21152;&#19982;&#30707;&#27833;&#32929;&#31080;&#30456;&#20851;&#30340;&#29305;&#24449;&#24182;&#19981;&#20250;&#25552;&#39640;LSTM&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;&#36825;&#20123;&#21457;&#29616;&#34920;&#26126;&#65292;&#34429;&#28982;LSTM&#27169;&#22411;&#22312;&#39044;&#27979;&#32929;&#31080;&#20215;&#26684;&#26041;&#38754;&#21487;&#33021;&#26159;&#26377;&#25928;&#30340;&#65292;&#20294;&#20854;&#21487;&#35299;&#37322;&#24615;&#21487;&#33021;&#26377;&#38480;&#12290;&#22312;&#20165;&#20381;&#38752;LSTM&#27169;&#22411;&#36827;&#34892;&#32929;&#31080;&#24066;&#22330;&#20915;&#31574;&#26102;&#24212;&#26684;&#22806;&#35880;&#24910;&#12290;
&lt;/p&gt;
&lt;p&gt;
Oil companies are among the largest companies in the world whose economic indicators in the global stock market have a great impact on the world economy and market due to their relation to gold, crude oil, and the dollar. This study investigates the impact of correlated features on the interpretability of Long Short-Term Memory (LSTM) models for predicting oil company stocks. To achieve this, we designed a Standard Long Short-Term Memory (LSTM) network and trained it using various correlated datasets. Our approach aims to improve the accuracy of stock price prediction by considering the multiple factors affecting the market, such as crude oil prices, gold prices, and the US dollar. The results demonstrate that adding a feature correlated with oil stocks does not improve the interpretability of LSTM models. These findings suggest that while LSTM models may be effective in predicting stock prices, their interpretability may be limited. Caution should be exercised when relying solely on L
&lt;/p&gt;</description></item></channel></rss>