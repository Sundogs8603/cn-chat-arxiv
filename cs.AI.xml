<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33258;&#21160;&#29983;&#25104;&#20010;&#24615;&#21270;&#32534;&#31243;&#21453;&#39304;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#32467;&#21512;GPT-4&#20316;&#20026;&#8220;&#23548;&#24072;&#8221;&#27169;&#22411;&#29983;&#25104;&#25552;&#31034;&#65292;&#21033;&#29992;&#22833;&#36133;&#30340;&#27979;&#35797;&#29992;&#20363;&#30340;&#20449;&#24687;&#21644;&#20462;&#22797;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#26356;&#39640;&#36136;&#37327;&#30340;&#29983;&#25104;&#25552;&#31034;&#12290;&#28982;&#21518;&#65292;&#21033;&#29992;&#36739;&#24369;&#30340;GPT-3.5&#27169;&#22411;&#20316;&#20026;&#8220;&#23398;&#29983;&#8221;&#27169;&#22411;&#36827;&#19968;&#27493;&#39564;&#35777;&#25552;&#31034;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.03780</link><description>&lt;p&gt;
&#33258;&#21160;&#21270;&#20154;&#24037;&#23548;&#24072;&#24335;&#32534;&#31243;&#21453;&#39304;: &#21033;&#29992;GPT-4&#23548;&#24072;&#27169;&#22411;&#29983;&#25104;&#25552;&#31034;&#21644;GPT-3.5&#23398;&#29983;&#27169;&#22411;&#36827;&#34892;&#25552;&#31034;&#39564;&#35777;
&lt;/p&gt;
&lt;p&gt;
Automating Human Tutor-Style Programming Feedback: Leveraging GPT-4 Tutor Model for Hint Generation and GPT-3.5 Student Model for Hint Validation. (arXiv:2310.03780v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03780
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33258;&#21160;&#29983;&#25104;&#20010;&#24615;&#21270;&#32534;&#31243;&#21453;&#39304;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#32467;&#21512;GPT-4&#20316;&#20026;&#8220;&#23548;&#24072;&#8221;&#27169;&#22411;&#29983;&#25104;&#25552;&#31034;&#65292;&#21033;&#29992;&#22833;&#36133;&#30340;&#27979;&#35797;&#29992;&#20363;&#30340;&#20449;&#24687;&#21644;&#20462;&#22797;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#26356;&#39640;&#36136;&#37327;&#30340;&#29983;&#25104;&#25552;&#31034;&#12290;&#28982;&#21518;&#65292;&#21033;&#29992;&#36739;&#24369;&#30340;GPT-3.5&#27169;&#22411;&#20316;&#20026;&#8220;&#23398;&#29983;&#8221;&#27169;&#22411;&#36827;&#19968;&#27493;&#39564;&#35777;&#25552;&#31034;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25552;&#20379;&#20010;&#24615;&#21270;&#32534;&#31243;&#21453;&#39304;&#26041;&#38754;&#20855;&#26377;&#24040;&#22823;&#28508;&#21147;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#22312;&#25552;&#20379;&#20154;&#24037;&#23548;&#24072;&#24335;&#32534;&#31243;&#25552;&#31034;&#26041;&#38754;&#30340;&#20316;&#29992;&#65292;&#20197;&#24110;&#21161;&#23398;&#29983;&#35299;&#20915;&#31243;&#24207;&#20013;&#30340;&#38169;&#35823;&#12290;&#28982;&#32780;&#65292;&#26368;&#26032;&#30340;&#30740;&#31350;&#24037;&#20316;&#34429;&#28982;&#23545;&#21508;&#31181;&#21453;&#39304;&#29983;&#25104;&#22330;&#26223;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#20294;&#20854;&#25972;&#20307;&#36136;&#37327;&#20173;&#36828;&#19981;&#21450;&#20154;&#24037;&#23548;&#24072;&#65292;&#24182;&#19988;&#36824;&#27809;&#26377;&#20934;&#22791;&#22909;&#22312;&#23454;&#38469;&#29615;&#22659;&#20013;&#25237;&#20837;&#20351;&#29992;&#12290;&#20026;&#20102;&#25552;&#39640;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#25552;&#20379;&#39640;&#36136;&#37327;&#32534;&#31243;&#25552;&#31034;&#30340;&#33021;&#21147;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#25216;&#26415;&#65292;&#21517;&#20026;GPT4Hints-GPT3.5Val&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#30340;&#25216;&#26415;&#21033;&#29992;GPT-4&#20316;&#20026;&#8220;&#23548;&#24072;&#8221;&#27169;&#22411;&#29983;&#25104;&#25552;&#31034;&#65292;&#36890;&#36807;&#20351;&#29992;&#22833;&#36133;&#30340;&#27979;&#35797;&#29992;&#20363;&#30340;&#31526;&#21495;&#20449;&#24687;&#21644;&#25552;&#31034;&#20013;&#30340;&#20462;&#22797;&#26041;&#27861;&#65292;&#25552;&#39640;&#20102;&#29983;&#25104;&#36136;&#37327;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#30340;&#25216;&#26415;&#21033;&#29992;&#36739;&#24369;&#30340;GPT-3.5&#27169;&#22411;&#20316;&#20026;&#8220;&#23398;&#29983;&#8221;&#27169;&#22411;&#36827;&#19968;&#27493;&#39564;&#35777;&#25552;&#31034;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative AI and large language models hold great promise in enhancing programming education by automatically generating individualized feedback for students. We investigate the role of generative AI models in providing human tutor-style programming hints to help students resolve errors in their buggy programs. Recent works have benchmarked state-of-the-art models for various feedback generation scenarios; however, their overall quality is still inferior to human tutors and not yet ready for real-world deployment. In this paper, we seek to push the limits of generative AI models toward providing high-quality programming hints and develop a novel technique, GPT4Hints-GPT3.5Val. As a first step, our technique leverages GPT-4 as a ``tutor'' model to generate hints -- it boosts the generative quality by using symbolic information of failing test cases and fixes in prompts. As a next step, our technique leverages GPT-3.5, a weaker model, as a ``student'' model to further validate the hint 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#25193;&#25955;&#29983;&#25104;&#27969;&#37319;&#26679;&#22120;&#65288;DGFS&#65289;&#30340;&#37319;&#26679;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#23398;&#20064;&#36807;&#31243;&#20998;&#35299;&#20026;&#30701;&#30340;&#37096;&#20998;&#36712;&#36857;&#27573;&#65292;&#23454;&#29616;&#20174;&#38590;&#20197;&#22788;&#29702;&#30340;&#39640;&#32500;&#23494;&#24230;&#20989;&#25968;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#23427;&#36890;&#36807;&#21033;&#29992;&#20013;&#38388;&#30340;&#23398;&#20064;&#20449;&#21495;&#21644;&#38750;&#31574;&#30053;&#25506;&#32034;&#33021;&#21147;&#26469;&#25913;&#21892;&#23398;&#20064;&#20449;&#21495;&#30340;&#20998;&#37197;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.02679</link><description>&lt;p&gt;
&#25193;&#25955;&#29983;&#25104;&#27969;&#37319;&#26679;&#22120;&#65306;&#36890;&#36807;&#37096;&#20998;&#36712;&#36857;&#20248;&#21270;&#25913;&#21892;&#23398;&#20064;&#20449;&#21495;
&lt;/p&gt;
&lt;p&gt;
Diffusion Generative Flow Samplers: Improving learning signals through partial trajectory optimization. (arXiv:2310.02679v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02679
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#25193;&#25955;&#29983;&#25104;&#27969;&#37319;&#26679;&#22120;&#65288;DGFS&#65289;&#30340;&#37319;&#26679;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#23398;&#20064;&#36807;&#31243;&#20998;&#35299;&#20026;&#30701;&#30340;&#37096;&#20998;&#36712;&#36857;&#27573;&#65292;&#23454;&#29616;&#20174;&#38590;&#20197;&#22788;&#29702;&#30340;&#39640;&#32500;&#23494;&#24230;&#20989;&#25968;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#23427;&#36890;&#36807;&#21033;&#29992;&#20013;&#38388;&#30340;&#23398;&#20064;&#20449;&#21495;&#21644;&#38750;&#31574;&#30053;&#25506;&#32034;&#33021;&#21147;&#26469;&#25913;&#21892;&#23398;&#20064;&#20449;&#21495;&#30340;&#20998;&#37197;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#20174;&#38590;&#20197;&#22788;&#29702;&#30340;&#39640;&#32500;&#23494;&#24230;&#20989;&#25968;&#20013;&#36827;&#34892;&#37319;&#26679;&#30340;&#38382;&#39064;&#65292;&#36825;&#26159;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#20013;&#32463;&#24120;&#20986;&#29616;&#30340;&#22522;&#26412;&#20219;&#21153;&#12290;&#25105;&#20204;&#25193;&#23637;&#20102;&#26368;&#36817;&#30340;&#22522;&#20110;&#37319;&#26679;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#25511;&#21046;&#30340;&#38543;&#26426;&#36807;&#31243;&#26469;&#27169;&#25311;&#36825;&#20123;&#30446;&#26631;&#23494;&#24230;&#30340;&#36817;&#20284;&#26679;&#26412;&#12290;&#36825;&#20123;&#26041;&#27861;&#30340;&#20027;&#35201;&#32570;&#28857;&#26159;&#35757;&#32451;&#30446;&#26631;&#38656;&#35201;&#35745;&#31639;&#23436;&#25972;&#30340;&#36712;&#36857;&#65292;&#23548;&#33268;&#30001;&#20110;&#20351;&#29992;&#23436;&#25972;&#36712;&#36857;&#21644;&#21482;&#22312;&#32456;&#31471;&#26102;&#38388;&#23384;&#22312;&#30340;&#23398;&#20064;&#20449;&#21495;&#30340;&#20351;&#29992;&#32780;&#20135;&#29983;&#32531;&#24930;&#30340;&#20449;&#29992;&#20998;&#37197;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#25193;&#25955;&#29983;&#25104;&#27969;&#37319;&#26679;&#22120;&#65288;DGFS&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;&#37319;&#26679;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#23558;&#23398;&#20064;&#36807;&#31243;&#21487;&#34892;&#22320;&#20998;&#35299;&#20026;&#30701;&#30340;&#37096;&#20998;&#36712;&#36857;&#27573;&#65292;&#36890;&#36807;&#21442;&#25968;&#21270;&#19968;&#20010;&#39069;&#22806;&#30340;&#8220;&#27969;&#20989;&#25968;&#8221;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20511;&#37492;&#20102;&#29983;&#25104;&#27969;&#32593;&#32476;&#65288;GFlowNets&#65289;&#30340;&#29702;&#35770;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#21033;&#29992;&#20013;&#38388;&#30340;&#23398;&#20064;&#20449;&#21495;&#65292;&#24182;&#20174;&#38750;&#31574;&#30053;&#25506;&#32034;&#33021;&#21147;&#20013;&#21463;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
We tackle the problem of sampling from intractable high-dimensional density functions, a fundamental task that often appears in machine learning and statistics. We extend recent sampling-based approaches that leverage controlled stochastic processes to model approximate samples from these target densities. The main drawback of these approaches is that the training objective requires full trajectories to compute, resulting in sluggish credit assignment issues due to use of entire trajectories and a learning signal present only at the terminal time. In this work, we present Diffusion Generative Flow Samplers (DGFS), a sampling-based framework where the learning process can be tractably broken down into short partial trajectory segments, via parameterizing an additional "flow function". Our method takes inspiration from the theory developed for generative flow networks (GFlowNets), allowing us to make use of intermediate learning signals and benefit from off-policy exploration capabilitie
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35774;&#35745;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;OptGNN&#65292;&#21033;&#29992;&#21322;&#23450;&#35268;&#21010;&#24037;&#20855;&#33719;&#24471;&#22823;&#31867;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#30340;&#26368;&#20248;&#36817;&#20284;&#31639;&#27861;&#12290;&#36890;&#36807;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#36229;&#36807;&#20102;&#31070;&#32463;&#32593;&#32476;&#22522;&#32447;&#31639;&#27861;&#21644;&#20256;&#32479;&#31639;&#27861;&#65292;&#21516;&#26102;&#21033;&#29992;OptGNN&#30340;&#33021;&#21147;&#35774;&#35745;&#20102;&#19968;&#20010;&#20135;&#29983;&#20248;&#21270;&#30340;&#23545;&#20598;&#35777;&#20070;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.00526</link><description>&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#33021;&#21542;&#20316;&#20026;&#26368;&#20248;&#36817;&#20284;&#31639;&#27861;&#65311;
&lt;/p&gt;
&lt;p&gt;
Are Graph Neural Networks Optimal Approximation Algorithms?. (arXiv:2310.00526v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00526
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35774;&#35745;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;OptGNN&#65292;&#21033;&#29992;&#21322;&#23450;&#35268;&#21010;&#24037;&#20855;&#33719;&#24471;&#22823;&#31867;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#30340;&#26368;&#20248;&#36817;&#20284;&#31639;&#27861;&#12290;&#36890;&#36807;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#36229;&#36807;&#20102;&#31070;&#32463;&#32593;&#32476;&#22522;&#32447;&#31639;&#27861;&#21644;&#20256;&#32479;&#31639;&#27861;&#65292;&#21516;&#26102;&#21033;&#29992;OptGNN&#30340;&#33021;&#21147;&#35774;&#35745;&#20102;&#19968;&#20010;&#20135;&#29983;&#20248;&#21270;&#30340;&#23545;&#20598;&#35777;&#20070;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#33021;&#22815;&#20351;&#29992;&#21322;&#23450;&#35268;&#21010;&#65288;SDP&#65289;&#24378;&#22823;&#30340;&#31639;&#27861;&#24037;&#20855;&#26469;&#33719;&#24471;&#22823;&#31867;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#30340;&#26368;&#20248;&#36817;&#20284;&#31639;&#27861;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22810;&#39033;&#24335;&#22823;&#23567;&#30340;&#28040;&#24687;&#20256;&#36882;&#31639;&#27861;&#21487;&#20197;&#34920;&#31034;&#26368;&#24378;&#22823;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#65292;&#21069;&#25552;&#26159;&#20551;&#35774;&#21807;&#19968;&#28216;&#25103;&#29468;&#24819;&#25104;&#31435;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#19968;&#32467;&#26524;&#26500;&#24314;&#20102;&#39640;&#25928;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;OptGNN&#65292;&#23427;&#22312;&#35832;&#22914;&#26368;&#22823;&#21106;&#21644;&#26368;&#22823;&#29420;&#31435;&#38598;&#31561;&#37325;&#35201;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#19978;&#33719;&#24471;&#20102;&#39640;&#36136;&#37327;&#30340;&#36817;&#20284;&#35299;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21508;&#31181;&#30495;&#23454;&#19990;&#30028;&#21644;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#24378;&#22823;&#30340;&#23454;&#35777;&#32467;&#26524;&#65292;&#19981;&#20165;&#36229;&#36807;&#20102;&#31070;&#32463;&#32593;&#32476;&#22522;&#32447;&#31639;&#27861;&#65292;&#36824;&#36229;&#36807;&#20102;&#20256;&#32479;&#31639;&#27861;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;OptGNN&#25429;&#25417;&#20984;&#26494;&#24347;&#30340;&#33021;&#21147;&#65292;&#35774;&#35745;&#20102;&#19968;&#20010;&#20135;&#29983;&#20248;&#21270;&#30340;&#23545;&#20598;&#35777;&#20070;&#65288;&#30830;&#23450;&#24615;&#19978;&#30028;&#65289;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work we design graph neural network architectures that can be used to obtain optimal approximation algorithms for a large class of combinatorial optimization problems using powerful algorithmic tools from semidefinite programming (SDP). Concretely, we prove that polynomial-sized message passing algorithms can represent the most powerful polynomial time algorithms for Max Constraint Satisfaction Problems assuming the Unique Games Conjecture. We leverage this result to construct efficient graph neural network architectures, OptGNN, that obtain high-quality approximate solutions on landmark combinatorial optimization problems such as Max Cut and maximum independent set. Our approach achieves strong empirical results across a wide range of real-world and synthetic datasets against both neural baselines and classical algorithms. Finally, we take advantage of OptGNN's ability to capture convex relaxations to design an algorithm for producing dual certificates of optimality (bounds on
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#20805;&#20998;&#22240;&#32032;&#21644;&#24517;&#35201;&#22240;&#32032;&#30340;&#27010;&#29575;&#65288;PNS&#65289;&#26469;&#25913;&#21892;&#22312;&#26410;&#30693;&#27979;&#35797;&#20998;&#24067;&#19978;&#30340;&#27867;&#21270;&#38382;&#39064;&#65292;&#20197;&#35299;&#20915;&#29616;&#26377;&#26041;&#27861;&#20027;&#35201;&#20851;&#27880;&#22240;&#26524;&#24615;&#30340;&#19981;&#21464;&#24615;&#23646;&#24615;&#32780;&#24573;&#35270;&#20805;&#20998;&#24615;&#21644;&#24517;&#35201;&#24615;&#26465;&#20214;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.12559</link><description>&lt;p&gt;
&#36890;&#36807;&#20805;&#20998;&#22240;&#32032;&#21644;&#24517;&#35201;&#22240;&#32032;&#30340;&#27010;&#29575;&#36827;&#34892;&#19981;&#21464;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Invariant Learning via Probability of Sufficient and Necessary Causes. (arXiv:2309.12559v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12559
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#20805;&#20998;&#22240;&#32032;&#21644;&#24517;&#35201;&#22240;&#32032;&#30340;&#27010;&#29575;&#65288;PNS&#65289;&#26469;&#25913;&#21892;&#22312;&#26410;&#30693;&#27979;&#35797;&#20998;&#24067;&#19978;&#30340;&#27867;&#21270;&#38382;&#39064;&#65292;&#20197;&#35299;&#20915;&#29616;&#26377;&#26041;&#27861;&#20027;&#35201;&#20851;&#27880;&#22240;&#26524;&#24615;&#30340;&#19981;&#21464;&#24615;&#23646;&#24615;&#32780;&#24573;&#35270;&#20805;&#20998;&#24615;&#21644;&#24517;&#35201;&#24615;&#26465;&#20214;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#37326;&#22806;&#23398;&#20064;&#20013;&#65292;&#23545;&#20110;&#26410;&#30693;&#30340;&#12289;&#19982;&#35757;&#32451;&#20998;&#24067;&#19981;&#21516;&#30340;&#27979;&#35797;&#20998;&#24067;&#65292;&#22806;&#37096;&#20998;&#24067;&#65288;OOD&#65289;&#27867;&#21270;&#26159;&#19981;&#21487;&#25110;&#32570;&#30340;&#12290;&#26368;&#36817;&#20174;&#22240;&#26524;&#24615;&#24341;&#21457;&#30340;&#26041;&#27861;&#22312;&#23454;&#29616;OOD&#27867;&#21270;&#26041;&#38754;&#26174;&#31034;&#20986;&#20102;&#24040;&#22823;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#20027;&#35201;&#20851;&#27880;&#22240;&#26524;&#24615;&#30340;&#19981;&#21464;&#24615;&#23646;&#24615;&#65292;&#32780;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#24573;&#35270;&#20102;&#20805;&#20998;&#24615;&#21644;&#24517;&#35201;&#24615;&#26465;&#20214;&#30340;&#23646;&#24615;&#12290;&#25442;&#21477;&#35805;&#35828;&#65292;&#19968;&#20010;&#24517;&#35201;&#20294;&#19981;&#20805;&#20998;&#30340;&#21407;&#22240;&#65288;&#29305;&#24449;&#65289;&#23545;&#20110;&#20998;&#24067;&#36716;&#25442;&#26159;&#19981;&#21464;&#30340;&#65292;&#20294;&#21487;&#33021;&#27809;&#26377;&#25152;&#38656;&#30340;&#20934;&#30830;&#24230;&#12290;&#30456;&#21453;&#65292;&#19968;&#20010;&#20805;&#20998;&#20294;&#19981;&#24517;&#35201;&#30340;&#21407;&#22240;&#65288;&#29305;&#24449;&#65289;&#20542;&#21521;&#20110;&#24456;&#22909;&#22320;&#36866;&#24212;&#29305;&#23450;&#25968;&#25454;&#65292;&#20294;&#21487;&#33021;&#23384;&#22312;&#36866;&#24212;&#26032;&#39046;&#22495;&#30340;&#39118;&#38505;&#12290;&#20026;&#20102;&#25429;&#25417;&#20805;&#20998;&#21644;&#24517;&#35201;&#22240;&#32032;&#30340;&#20449;&#24687;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#32463;&#20856;&#27010;&#24565;&#8212;&#8212;&#20805;&#20998;&#21644;&#24517;&#35201;&#22240;&#32032;&#30340;&#27010;&#29575;&#65288;PNS&#65289;&#65292;&#23427;&#25351;&#31034;&#20102;&#19968;&#20010;&#22240;&#32032;&#26159;&#24517;&#35201;&#21644;&#20805;&#20998;&#21407;&#22240;&#30340;&#27010;&#29575;&#12290;&#20026;&#20102;&#23558;PNS&#19982;OOD&#27867;&#21270;&#32852;&#31995;&#36215;&#26469;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Out-of-distribution (OOD) generalization is indispensable for learning models in the wild, where testing distribution typically unknown and different from the training. Recent methods derived from causality have shown great potential in achieving OOD generalization. However, existing methods mainly focus on the invariance property of causes, while largely overlooking the property of \textit{sufficiency} and \textit{necessity} conditions. Namely, a necessary but insufficient cause (feature) is invariant to distribution shift, yet it may not have required accuracy. By contrast, a sufficient yet unnecessary cause (feature) tends to fit specific data well but may have a risk of adapting to a new domain. To capture the information of sufficient and necessary causes, we employ a classical concept, the probability of sufficiency and necessary causes (PNS), which indicates the probability of whether one is the necessary and sufficient cause. To associate PNS with OOD generalization, we propose
&lt;/p&gt;</description></item><item><title>ChatGPT&#21644;GPT-4&#22312;&#25169;&#20811;&#20013;&#26174;&#31034;&#20986;&#39640;&#32423;&#29702;&#35299;&#65292;&#20294;&#19981;&#26159;&#28216;&#25103;&#35770;&#29702;&#26368;&#20248;&#30340;&#25169;&#20811;&#29609;&#23478;&#12290;&#23545;&#27169;&#22411;&#21442;&#25968;&#21644;&#25552;&#31034;&#30340;&#20248;&#21270;&#21487;&#20197;&#25552;&#39640;&#23427;&#20204;&#22312;&#25169;&#20811;&#20013;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2308.12466</link><description>&lt;p&gt;
ChatGPT&#21644;GPT-4&#26159;&#20248;&#31168;&#30340;&#25169;&#20811;&#29609;&#23478;&#21527;&#65311;&#8212;&#8212;&#19968;&#39033;Pre-Flop&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Are ChatGPT and GPT-4 Good Poker Players? -- A Pre-Flop Analysis. (arXiv:2308.12466v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12466
&lt;/p&gt;
&lt;p&gt;
ChatGPT&#21644;GPT-4&#22312;&#25169;&#20811;&#20013;&#26174;&#31034;&#20986;&#39640;&#32423;&#29702;&#35299;&#65292;&#20294;&#19981;&#26159;&#28216;&#25103;&#35770;&#29702;&#26368;&#20248;&#30340;&#25169;&#20811;&#29609;&#23478;&#12290;&#23545;&#27169;&#22411;&#21442;&#25968;&#21644;&#25552;&#31034;&#30340;&#20248;&#21270;&#21487;&#20197;&#25552;&#39640;&#23427;&#20204;&#22312;&#25169;&#20811;&#20013;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;ChatGPT&#21644;GPT-4&#38382;&#19990;&#20197;&#26469;&#65292;&#36825;&#20123;&#27169;&#22411;&#24050;&#22312;&#35768;&#22810;&#20219;&#21153;&#20013;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;&#23427;&#20204;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#29087;&#32451;&#31243;&#24230;&#26159;&#26174;&#32780;&#26131;&#35265;&#30340;&#65292;&#20294;&#23427;&#20204;&#22312;&#28216;&#25103;&#20013;&#30340;&#33021;&#21147;&#65292;&#29305;&#21035;&#26159;&#22312;&#25169;&#20811;&#39046;&#22495;&#30340;&#33021;&#21147;&#65292;&#36824;&#26410;&#34987;&#25506;&#32034;&#12290;&#25169;&#20811;&#26159;&#19968;&#31181;&#38656;&#35201;&#22312;&#19981;&#30830;&#23450;&#24615;&#21644;&#19981;&#23436;&#20840;&#20449;&#24687;&#19979;&#20570;&#20986;&#20915;&#31574;&#30340;&#28216;&#25103;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23545;ChatGPT&#21644;GPT-4&#36827;&#34892;&#20102;&#25169;&#20811;&#27979;&#35797;&#65292;&#24182;&#35780;&#20272;&#20102;&#23427;&#20204;&#30340;&#25169;&#20811;&#25216;&#33021;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#34429;&#28982;&#36825;&#20004;&#20010;&#27169;&#22411;&#37117;&#23637;&#31034;&#20102;&#23545;&#25169;&#20811;&#30340;&#39640;&#32423;&#29702;&#35299;&#65292;&#21253;&#25324;&#36215;&#22987;&#25163;&#29260;&#30340;&#20272;&#20540;&#12289;&#25171;&#29260;&#20301;&#32622;&#20197;&#21450;&#28216;&#25103;&#35770;&#29702;&#26368;&#20248;(GTO)&#25169;&#20811;&#30340;&#20854;&#20182;&#22797;&#26434;&#24615;&#65292;&#20294;ChatGPT&#21644;GPT-4&#24182;&#19981;&#26159;&#28216;&#25103;&#35770;&#29702;&#26368;&#20248;&#30340;&#25169;&#20811;&#29609;&#23478;&#12290;&#36890;&#36807;&#19968;&#31995;&#21015;&#23454;&#39564;&#65292;&#25105;&#20204;&#39318;&#20808;&#21457;&#29616;&#20102;&#19982;&#20351;&#29992;&#36825;&#20123;&#27169;&#22411;&#29609;&#25169;&#20811;&#30456;&#20851;&#30340;&#26368;&#20339;&#25552;&#31034;&#21644;&#27169;&#22411;&#21442;&#25968;&#30340;&#29305;&#24449;&#12290;&#25509;&#30528;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#20102;&#36825;&#20004;&#20010;&#27169;&#22411;&#20855;&#26377;&#19981;&#21516;&#30340;&#25171;&#29260;&#39118;&#26684;&#12290;&#26368;&#32456;&#65292;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65306;GPT-4&#26159;
&lt;/p&gt;
&lt;p&gt;
Since the introduction of ChatGPT and GPT-4, these models have been tested across a large number of tasks. Their adeptness across domains is evident, but their aptitude in playing games and specifically their aptitude in the realm of poker has remained unexplored. Poker is a game that requires decision making under uncertainty and incomplete information. In this paper, we put ChatGPT and GPT-4 through the poker test and evaluate their poker skills. Our findings reveal that while both models display an advanced understanding of poker, encompassing concepts like the valuation of starting hands, playing positions and other intricacies of game theory optimal (GTO) poker, both ChatGPT and GPT-4 are NOT game theory optimal poker players.  Through a series of experiments, we first discover the characteristics of optimal prompts and model parameters for playing poker with these models. Our observations then unveil the distinct playing personas of the two models. We first conclude that GPT-4 is
&lt;/p&gt;</description></item><item><title>SurgicalSAM&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#25163;&#26415;&#22120;&#26800;&#20998;&#21106;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;SurgicalSAM&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#24212;&#29992;Segment Anything Model (SAM) &#36827;&#34892;&#25163;&#26415;&#22120;&#26800;&#20998;&#21106;&#65292;&#35299;&#20915;&#20102;SAM&#22312;&#25163;&#26415;&#22120;&#26800;&#39046;&#22495;&#30340;&#27867;&#21270;&#33021;&#21147;&#24046;&#21644;&#22797;&#26434;&#22810;&#38454;&#27573;&#27969;&#31243;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.08746</link><description>&lt;p&gt;
SurgicalSAM: &#39640;&#25928;&#30340;&#21487;&#25552;&#31034;&#30340;&#25163;&#26415;&#22120;&#26800;&#20998;&#21106;
&lt;/p&gt;
&lt;p&gt;
SurgicalSAM: Efficient Class Promptable Surgical Instrument Segmentation. (arXiv:2308.08746v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08746
&lt;/p&gt;
&lt;p&gt;
SurgicalSAM&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#25163;&#26415;&#22120;&#26800;&#20998;&#21106;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;SurgicalSAM&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#24212;&#29992;Segment Anything Model (SAM) &#36827;&#34892;&#25163;&#26415;&#22120;&#26800;&#20998;&#21106;&#65292;&#35299;&#20915;&#20102;SAM&#22312;&#25163;&#26415;&#22120;&#26800;&#39046;&#22495;&#30340;&#27867;&#21270;&#33021;&#21147;&#24046;&#21644;&#22797;&#26434;&#22810;&#38454;&#27573;&#27969;&#31243;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Segment Anything Model (SAM) &#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#22522;&#30784;&#27169;&#22411;&#65292;&#24050;&#32463;&#24443;&#24213;&#25913;&#21464;&#20102;&#22270;&#20687;&#20998;&#21106;&#12290;&#20026;&#20102;&#23558;SAM&#24212;&#29992;&#20110;&#25163;&#26415;&#22120;&#26800;&#20998;&#21106;&#65292;&#24120;&#35265;&#30340;&#26041;&#27861;&#26159;&#23450;&#20301;&#22120;&#26800;&#30340;&#31934;&#30830;&#28857;&#25110;&#26694;&#65292;&#24182;&#23558;&#20854;&#29992;&#20316;SAM&#30340;&#25552;&#31034;&#65292;&#20197;&#38646;&#26679;&#26412;&#26041;&#24335;&#36827;&#34892;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#36825;&#31181;&#31616;&#21333;&#30340;&#27969;&#31243;&#23384;&#22312;&#20004;&#20010;&#38382;&#39064;&#65306;&#65288;1&#65289;&#33258;&#28982;&#29289;&#20307;&#21644;&#25163;&#26415;&#22120;&#26800;&#20043;&#38388;&#30340;&#39046;&#22495;&#24046;&#36317;&#23548;&#33268;SAM&#30340;&#27867;&#21270;&#33021;&#21147;&#24046;&#65307;&#65288;2&#65289;SAM&#20381;&#36182;&#20110;&#31934;&#30830;&#30340;&#28857;&#25110;&#26694;&#20301;&#32622;&#36827;&#34892;&#20934;&#30830;&#30340;&#20998;&#21106;&#65292;&#35201;&#27714;&#35201;&#20040;&#32463;&#36807;&#24191;&#27867;&#30340;&#25163;&#21160;&#24341;&#23548;&#65292;&#35201;&#20040;&#20351;&#29992;&#24615;&#33021;&#33391;&#22909;&#30340;&#19987;&#38376;&#26816;&#27979;&#22120;&#36827;&#34892;&#25552;&#31034;&#20934;&#22791;&#65292;&#36825;&#23548;&#33268;&#20102;&#19968;&#20010;&#22797;&#26434;&#30340;&#22810;&#38454;&#27573;&#27969;&#31243;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;SurgicalSAM&#65292;&#19968;&#31181;&#26032;&#30340;&#31471;&#21040;&#31471;&#39640;&#25928;&#35843;&#20248;&#26041;&#27861;&#65292;&#20197;&#26377;&#25928;&#22320;&#23558;&#25163;&#26415;&#29305;&#23450;&#20449;&#24687;&#19982;SAM&#30340;&#39044;&#35757;&#32451;&#30693;&#35782;&#30456;&#32467;&#21512;&#65292;&#20197;&#25913;&#36827;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Segment Anything Model (SAM) is a powerful foundation model that has revolutionised image segmentation. To apply SAM to surgical instrument segmentation, a common approach is to locate precise points or boxes of instruments and then use them as prompts for SAM in a zero-shot manner. However, we observe two problems with this naive pipeline: (1) the domain gap between natural objects and surgical instruments leads to poor generalisation of SAM; and (2) SAM relies on precise point or box locations for accurate segmentation, requiring either extensive manual guidance or a well-performing specialist detector for prompt preparation, which leads to a complex multi-stage pipeline. To address these problems, we introduce SurgicalSAM, a novel end-to-end efficient-tuning approach for SAM to effectively integrate surgical-specific information with SAM's pre-trained knowledge for improved generalisation. Specifically, we propose a lightweight prototype-based class prompt encoder for tuning, wh
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#25968;&#23398;&#20248;&#21270;&#20013;&#24341;&#20837;&#25968;&#25454;&#39537;&#21160;&#21487;&#35299;&#37322;&#24615;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#19982;&#36807;&#21435;&#31867;&#20284;&#24773;&#20917;&#19979;&#30340;&#35299;&#36827;&#34892;&#27604;&#36739;&#26469;&#25214;&#21040;&#20855;&#26377;&#30456;&#20284;&#29305;&#24449;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#23613;&#31649;&#21487;&#35299;&#37322;&#27169;&#22411;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#26159;NP-hard&#30340;&#65292;&#20294;&#22312;&#19968;&#20123;&#22810;&#39033;&#24335;&#21487;&#35299;&#30340;&#24773;&#20917;&#19979;&#21487;&#34892;&#12290;</title><link>http://arxiv.org/abs/2308.08309</link><description>&lt;p&gt;
&#25968;&#25454;&#39537;&#21160;&#21487;&#35299;&#37322;&#24615;&#22312;&#25968;&#23398;&#20248;&#21270;&#20013;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Framework for Data-Driven Explainability in Mathematical Optimization. (arXiv:2308.08309v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08309
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#25968;&#23398;&#20248;&#21270;&#20013;&#24341;&#20837;&#25968;&#25454;&#39537;&#21160;&#21487;&#35299;&#37322;&#24615;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#19982;&#36807;&#21435;&#31867;&#20284;&#24773;&#20917;&#19979;&#30340;&#35299;&#36827;&#34892;&#27604;&#36739;&#26469;&#25214;&#21040;&#20855;&#26377;&#30456;&#20284;&#29305;&#24449;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#23613;&#31649;&#21487;&#35299;&#37322;&#27169;&#22411;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#26159;NP-hard&#30340;&#65292;&#20294;&#22312;&#19968;&#20123;&#22810;&#39033;&#24335;&#21487;&#35299;&#30340;&#24773;&#20917;&#19979;&#21487;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#25968;&#23398;&#35268;&#21010;&#30340;&#36827;&#27493;&#65292;&#25105;&#20204;&#29616;&#22312;&#26377;&#33021;&#21147;&#26377;&#25928;&#22320;&#35299;&#20915;&#20960;&#21313;&#24180;&#21069;&#34987;&#35748;&#20026;&#26080;&#27861;&#35299;&#20915;&#30340;&#22823;&#35268;&#27169;&#23454;&#38469;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20248;&#21270;&#36719;&#20214;&#34987;&#35270;&#20026;&#40657;&#30418;&#23376;&#65292;&#19968;&#20123;&#21487;&#35777;&#26126;&#30340;&#26368;&#20248;&#35299;&#21487;&#33021;&#19981;&#34987;&#25509;&#21463;&#12290;&#34429;&#28982;&#31185;&#23398;&#23478;&#20204;&#23545;&#27492;&#24456;&#20102;&#35299;&#65292;&#20294;&#23545;&#20110;&#23454;&#36341;&#32773;&#26469;&#35828;&#21364;&#24456;&#38590;&#29702;&#35299;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#20027;&#24352;&#23558;&#35299;&#37322;&#24615;&#20316;&#20026;&#21478;&#19968;&#20010;&#35780;&#20272;&#26631;&#20934;&#24341;&#20837;&#35299;&#20915;&#26041;&#26696;&#65292;&#26082;&#21253;&#25324;&#30446;&#26631;&#20540;&#65292;&#20063;&#21253;&#25324;&#21487;&#35299;&#37322;&#24615;&#65292;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#22312;&#36825;&#20004;&#20010;&#26631;&#20934;&#20043;&#38388;&#25214;&#21040;&#26435;&#34913;&#35299;&#12290;&#36890;&#36807;&#23558;&#35299;&#20915;&#26041;&#26696;&#19982;&#36807;&#21435;&#31867;&#20284;&#24773;&#20917;&#19979;&#23454;&#26045;&#30340;&#65288;&#19981;&#19968;&#23450;&#26159;&#26368;&#20248;&#30340;&#65289;&#35299;&#36827;&#34892;&#27604;&#36739;&#65292;&#25105;&#20204;&#36798;&#21040;&#20102;&#21487;&#35299;&#37322;&#24615;&#12290;&#22240;&#27492;&#65292;&#26356;&#21916;&#27426;&#23637;&#29616;&#30456;&#20284;&#29305;&#24449;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#23613;&#31649;&#25105;&#20204;&#35777;&#26126;&#20102;&#21363;&#20351;&#22312;&#31616;&#21333;&#24773;&#20917;&#19979;&#21487;&#35299;&#37322;&#27169;&#22411;&#20063;&#26159;NP-hard&#65292;&#20294;&#25105;&#20204;&#30830;&#23450;&#20102;&#30456;&#20851;&#30340;&#22810;&#39033;&#24335;&#21487;&#35299;&#24773;&#20917;&#65292;&#22914;&#21487;&#35299;&#37322;&#30340;&#26368;&#30701;&#36335;&#24452;&#38382;&#39064;&#12290;&#22312;ar&#30340;&#25968;&#20540;&#23454;&#39564;&#19978;&#20063;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Advancements in mathematical programming have made it possible to efficiently tackle large-scale real-world problems that were deemed intractable just a few decades ago. However, provably optimal solutions may not be accepted due to the perception of optimization software as a black box. Although well understood by scientists, this lacks easy accessibility for practitioners. Hence, we advocate for introducing the explainability of a solution as another evaluation criterion, next to its objective value, which enables us to find trade-off solutions between these two criteria. Explainability is attained by comparing against (not necessarily optimal) solutions that were implemented in similar situations in the past. Thus, solutions are preferred that exhibit similar features. Although we prove that already in simple cases the explainable model is NP-hard, we characterize relevant polynomially solvable cases such as the explainable shortest-path problem. Our numerical experiments on both ar
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377;&#25513;&#30721;&#22256;&#38590;&#23454;&#20363;&#25366;&#25496;&#30340;&#22810;&#31034;&#20363;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#20840;&#20999;&#29255;&#22270;&#20687;&#20998;&#31867;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#20351;&#29992;&#20849;&#20139;&#23398;&#20064;&#32467;&#26500;&#21644;&#19968;&#33268;&#24615;&#32422;&#26463;&#26469;&#25506;&#32034;&#28508;&#22312;&#30340;&#38590;&#20197;&#20998;&#31867;&#30340;&#23454;&#20363;&#65292;&#24182;&#36890;&#36807;&#21160;&#37327;&#25945;&#24072;&#38544;&#24335;&#25366;&#25496;&#36825;&#20123;&#23454;&#20363;&#26469;&#35757;&#32451;&#23398;&#29983;&#27169;&#22411;&#65292;&#20174;&#32780;&#25552;&#39640;&#20998;&#31867;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.15254</link><description>&lt;p&gt;
&#24102;&#26377;&#25513;&#30721;&#22256;&#38590;&#23454;&#20363;&#25366;&#25496;&#30340;&#22810;&#31034;&#20363;&#23398;&#20064;&#26694;&#26550;&#29992;&#20110;&#20840;&#20999;&#29255;&#22270;&#20687;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Multiple Instance Learning Framework with Masked Hard Instance Mining for Whole Slide Image Classification. (arXiv:2307.15254v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15254
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377;&#25513;&#30721;&#22256;&#38590;&#23454;&#20363;&#25366;&#25496;&#30340;&#22810;&#31034;&#20363;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#20840;&#20999;&#29255;&#22270;&#20687;&#20998;&#31867;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#20351;&#29992;&#20849;&#20139;&#23398;&#20064;&#32467;&#26500;&#21644;&#19968;&#33268;&#24615;&#32422;&#26463;&#26469;&#25506;&#32034;&#28508;&#22312;&#30340;&#38590;&#20197;&#20998;&#31867;&#30340;&#23454;&#20363;&#65292;&#24182;&#36890;&#36807;&#21160;&#37327;&#25945;&#24072;&#38544;&#24335;&#25366;&#25496;&#36825;&#20123;&#23454;&#20363;&#26469;&#35757;&#32451;&#23398;&#29983;&#27169;&#22411;&#65292;&#20174;&#32780;&#25552;&#39640;&#20998;&#31867;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20840;&#20999;&#29255;&#22270;&#20687;&#65288;WSI&#65289;&#20998;&#31867;&#36890;&#24120;&#34987;&#24418;&#24335;&#21270;&#20026;&#22810;&#31034;&#20363;&#23398;&#20064;&#65288;MIL&#65289;&#38382;&#39064;&#12290;&#30001;&#20110;&#38451;&#24615;&#32452;&#32455;&#20165;&#21344;&#20102;&#21513;&#27604;&#20687;&#32032;WSI&#30340;&#19968;&#23567;&#37096;&#20998;&#65292;&#29616;&#26377;&#30340;MIL&#26041;&#27861;&#30452;&#35266;&#22320;&#20391;&#37325;&#20110;&#36890;&#36807;&#27880;&#24847;&#21147;&#26426;&#21046;&#35782;&#21035;&#26174;&#33879;&#23454;&#20363;&#12290;&#28982;&#32780;&#65292;&#36825;&#23548;&#33268;&#20559;&#21521;&#26131;&#20110;&#20998;&#31867;&#30340;&#23454;&#20363;&#65292;&#24573;&#35270;&#20102;&#38590;&#20197;&#20998;&#31867;&#30340;&#23454;&#20363;&#12290;&#19968;&#20123;&#25991;&#29486;&#25581;&#31034;&#20102;&#22256;&#38590;&#31034;&#20363;&#23545;&#20110;&#20934;&#30830;&#24314;&#27169;&#36793;&#30028;&#26159;&#26377;&#30410;&#30340;&#12290;&#36890;&#36807;&#23558;&#36825;&#19968;&#24605;&#24819;&#24212;&#29992;&#21040;&#23454;&#20363;&#32423;&#21035;&#65292;&#25105;&#20204;&#35814;&#32454;&#38416;&#36848;&#20102;&#19968;&#31181;&#26032;&#30340;MIL&#26694;&#26550;&#65292;&#21363;&#24102;&#26377;&#25513;&#30721;&#22256;&#38590;&#23454;&#20363;&#25366;&#25496;&#30340;MIL&#65288;MHIM-MIL&#65289;&#65292;&#23427;&#20351;&#29992;&#19968;&#20010;&#20849;&#20139;&#23398;&#20064;&#32467;&#26500;&#65288;&#25945;&#24072;-&#23398;&#29983;&#65289;&#21644;&#19968;&#33268;&#24615;&#32422;&#26463;&#26469;&#25506;&#32034;&#28508;&#22312;&#30340;&#22256;&#38590;&#23454;&#20363;&#12290;&#20351;&#29992;&#22522;&#20110;&#27880;&#24847;&#21147;&#20998;&#25968;&#30340;&#22810;&#20010;&#23454;&#20363;&#25513;&#30721;&#31574;&#30053;&#65292;MHIM-MIL&#37319;&#29992;&#21160;&#37327;&#25945;&#24072;&#26469;&#38544;&#24335;&#25366;&#25496;&#29992;&#20110;&#35757;&#32451;&#23398;&#29983;&#27169;&#22411;&#30340;&#22256;&#38590;&#23454;&#20363;&#65292;&#23398;&#29983;&#27169;&#22411;&#21487;&#20197;&#26159;&#20219;&#20309;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;MIL&#27169;&#22411;&#12290;&#36825;&#20010;&#21453;&#30452;&#35273;&#30340;&#31574;&#30053;&#23545;&#20110;&#25552;&#39640;&#20998;&#31867;&#24615;&#33021;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
The whole slide image (WSI) classification is often formulated as a multiple instance learning (MIL) problem. Since the positive tissue is only a small fraction of the gigapixel WSI,existing MIL methods intuitively focus on identifying salient instances via attention mechanisms. However, this leads to a bias towards easy-to-classify instances while neglecting hard-to-classify instances.Some literature has revealed that hard examples are beneficial for modeling a discriminative boundary accurately.By applying such an idea at the instance level,we elaborate a novel MIL framework with masked hard instance mining (MHIM-MIL), which uses a Siamese structure (Teacher-Student) with a consistency constraint to explore the potential hard instances. With several instance masking strategies based on attention scores, MHIM-MIL employs a momentum teacher to implicitly mine hard instances for training the student model, which can be any attention-based MIL model.This counter-intuitive strategy essent
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#25915;&#20987;&#26041;&#27861;&#65292;&#33021;&#22815;&#20351;&#23545;&#40784;&#30340;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#19981;&#33391;&#34892;&#20026;&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;&#20154;&#24037;&#35774;&#35745;&#65292;&#36890;&#36807;&#33258;&#21160;&#21270;&#26041;&#27861;&#20135;&#29983;&#23545;&#25239;&#24615;&#21518;&#32512;&#65292;&#24182;&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2307.15043</link><description>&lt;p&gt;
&#23545;&#40784;&#35821;&#35328;&#27169;&#22411;&#19978;&#30340;&#36890;&#29992;&#21644;&#21487;&#36801;&#31227;&#23545;&#25239;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Universal and Transferable Adversarial Attacks on Aligned Language Models. (arXiv:2307.15043v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15043
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#25915;&#20987;&#26041;&#27861;&#65292;&#33021;&#22815;&#20351;&#23545;&#40784;&#30340;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#19981;&#33391;&#34892;&#20026;&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;&#20154;&#24037;&#35774;&#35745;&#65292;&#36890;&#36807;&#33258;&#21160;&#21270;&#26041;&#27861;&#20135;&#29983;&#23545;&#25239;&#24615;&#21518;&#32512;&#65292;&#24182;&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#8220;&#24320;&#31665;&#21363;&#29992;&#8221;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#29983;&#25104;&#22823;&#37327;&#24341;&#36215;&#21453;&#24863;&#30340;&#20869;&#23481;&#65292;&#26368;&#26032;&#30340;&#30740;&#31350;&#19987;&#27880;&#20110;&#23545;&#40784;&#36825;&#20123;&#27169;&#22411;&#65292;&#20197;&#38450;&#27490;&#20135;&#29983;&#19981;&#33391;&#29983;&#25104;&#12290;&#23613;&#31649;&#22312;&#35268;&#36991;&#36825;&#20123;&#25514;&#26045;&#19978;&#21462;&#24471;&#20102;&#19968;&#20123;&#25104;&#21151;&#65292;&#25152;&#35859;&#30340;&#23545;LLMs&#30340;&#8220;&#36234;&#29425;&#8221;&#25915;&#20987;&#65292;&#20294;&#36825;&#20123;&#25915;&#20987;&#38656;&#35201;&#20154;&#20026;&#30340;&#24039;&#24605;&#65292;&#23454;&#38469;&#19978;&#24182;&#19981;&#31283;&#23450;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#25915;&#20987;&#26041;&#27861;&#65292;&#20351;&#23545;&#40784;&#30340;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#19981;&#33391;&#34892;&#20026;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#25214;&#21040;&#19968;&#20010;&#21518;&#32512;&#65292;&#24403;&#38468;&#21152;&#21040;&#21508;&#31181;&#26597;&#35810;&#19978;&#65292;&#20379;LLM&#29983;&#25104;&#19981;&#33391;&#20869;&#23481;&#26102;&#65292;&#26088;&#22312;&#26368;&#22823;&#21270;&#27169;&#22411;&#20135;&#29983;&#32943;&#23450;&#22238;&#31572;&#65288;&#32780;&#19981;&#26159;&#25298;&#32477;&#22238;&#31572;&#65289;&#30340;&#27010;&#29575;&#12290;&#28982;&#32780;&#65292;&#19982;&#20854;&#20381;&#36182;&#25163;&#24037;&#35774;&#35745;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#36138;&#23146;&#21644;&#22522;&#20110;&#26799;&#24230;&#30340;&#25628;&#32034;&#25216;&#26415;&#33258;&#21160;&#20135;&#29983;&#36825;&#20123;&#23545;&#25239;&#24615;&#21518;&#32512;&#65292;&#24182;&#19988;&#22312;&#36807;&#21435;&#30340;&#33258;&#21160;&#21270;&#26041;&#27861;&#19978;&#36827;&#34892;&#20102;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Because "out-of-the-box" large language models are capable of generating a great deal of objectionable content, recent work has focused on aligning these models in an attempt to prevent undesirable generation. While there has been some success at circumventing these measures -- so-called "jailbreaks" against LLMs -- these attacks have required significant human ingenuity and are brittle in practice. In this paper, we propose a simple and effective attack method that causes aligned language models to generate objectionable behaviors. Specifically, our approach finds a suffix that, when attached to a wide range of queries for an LLM to produce objectionable content, aims to maximize the probability that the model produces an affirmative response (rather than refusing to answer). However, instead of relying on manual engineering, our approach automatically produces these adversarial suffixes by a combination of greedy and gradient-based search techniques, and also improves over past autom
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#19968;&#20803;&#20851;&#31995;&#30340;&#25968;&#25454;&#27169;&#22411;&#30340;&#30701;&#24067;&#23572;&#20844;&#24335;&#35299;&#37322;&#30340;&#21487;&#34892;&#24615;&#65292;&#25552;&#20986;&#20102;&#23545;&#26399;&#26395;&#38169;&#35823;&#30340;&#23450;&#37327;&#30028;&#38480;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#19977;&#20010;&#20855;&#20307;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#38469;&#24212;&#29992;&#12290;&#36890;&#36807;&#38480;&#21046;&#20844;&#24335;&#38271;&#24230;&#65292;&#21487;&#20197;&#33719;&#24471;&#36991;&#20813;&#36807;&#25311;&#21512;&#19988;&#20934;&#30830;&#19988;&#26131;&#20110;&#29702;&#35299;&#30340;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2307.06971</link><description>&lt;p&gt;
&#23454;&#36341;&#20013;&#30340;&#30701;&#24067;&#23572;&#20844;&#24335;&#20316;&#20026;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Short Boolean Formulas as Explanations in Practice. (arXiv:2307.06971v1 [cs.LO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06971
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#19968;&#20803;&#20851;&#31995;&#30340;&#25968;&#25454;&#27169;&#22411;&#30340;&#30701;&#24067;&#23572;&#20844;&#24335;&#35299;&#37322;&#30340;&#21487;&#34892;&#24615;&#65292;&#25552;&#20986;&#20102;&#23545;&#26399;&#26395;&#38169;&#35823;&#30340;&#23450;&#37327;&#30028;&#38480;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#19977;&#20010;&#20855;&#20307;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#38469;&#24212;&#29992;&#12290;&#36890;&#36807;&#38480;&#21046;&#20844;&#24335;&#38271;&#24230;&#65292;&#21487;&#20197;&#33719;&#24471;&#36991;&#20813;&#36807;&#25311;&#21512;&#19988;&#20934;&#30830;&#19988;&#26131;&#20110;&#29702;&#35299;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#19968;&#20803;&#20851;&#31995;&#30340;&#25968;&#25454;&#27169;&#22411;&#20013;&#36890;&#36807;&#30701;&#24067;&#23572;&#20844;&#24335;&#36827;&#34892;&#35299;&#37322;&#30340;&#21487;&#34892;&#24615;&#12290;&#20316;&#20026;&#38271;&#24230;&#20026;k&#30340;&#35299;&#37322;&#65292;&#25105;&#20204;&#37319;&#29992;&#19968;&#20010;&#38271;&#24230;&#20026;k&#30340;&#24067;&#23572;&#20844;&#24335;&#65292;&#35813;&#20844;&#24335;&#22312;&#35299;&#37322;&#30446;&#26631;&#23646;&#24615;&#26041;&#38754;&#30340;&#38169;&#35823;&#26368;&#23567;&#21270;&#12290;&#25105;&#20204;&#39318;&#20808;&#20026;&#36825;&#31181;&#24773;&#20917;&#25552;&#20379;&#20102;&#26032;&#39062;&#30340;&#26399;&#26395;&#38169;&#35823;&#30340;&#23450;&#37327;&#30028;&#38480;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#30740;&#31350;&#19977;&#20010;&#20855;&#20307;&#30340;&#25968;&#25454;&#38598;&#26469;&#28436;&#31034;&#35813;&#35774;&#32622;&#22312;&#23454;&#36341;&#20013;&#30340;&#36816;&#20316;&#26041;&#24335;&#12290;&#22312;&#27599;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#20351;&#29992;Answer Set Programming&#20013;&#30340;&#32534;&#30721;&#35745;&#31639;&#19981;&#21516;&#38271;&#24230;&#30340;&#35299;&#37322;&#20844;&#24335;&#12290;&#25105;&#20204;&#24471;&#21040;&#30340;&#26368;&#20934;&#30830;&#30340;&#20844;&#24335;&#22312;&#30456;&#21516;&#30340;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#19982;&#20854;&#20182;&#26041;&#27861;&#31867;&#20284;&#30340;&#38169;&#35823;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#36807;&#25311;&#21512;&#30340;&#21407;&#22240;&#65292;&#36825;&#20123;&#20844;&#24335;&#19981;&#19968;&#23450;&#26159;&#29702;&#24819;&#30340;&#35299;&#37322;&#65292;&#22240;&#27492;&#25105;&#20204;&#20351;&#29992;&#20132;&#21449;&#39564;&#35777;&#26469;&#30830;&#23450;&#21512;&#36866;&#30340;&#35299;&#37322;&#38271;&#24230;&#12290;&#36890;&#36807;&#38480;&#21046;&#20026;&#26356;&#30701;&#30340;&#20844;&#24335;&#65292;&#25105;&#20204;&#24471;&#21040;&#30340;&#35299;&#37322;&#19981;&#20165;&#36991;&#20813;&#20102;&#36807;&#25311;&#21512;&#65292;&#32780;&#19988;&#20381;&#28982;&#30456;&#24403;&#20934;&#30830;&#65292;&#24182;&#19988;&#37325;&#35201;&#30340;&#26159;&#65292;&#26131;&#20110;&#20154;&#31867;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate explainability via short Boolean formulas in the data model based on unary relations. As an explanation of length k, we take a Boolean formula of length k that minimizes the error with respect to the target attribute to be explained. We first provide novel quantitative bounds for the expected error in this scenario. We then also demonstrate how the setting works in practice by studying three concrete data sets. In each case, we calculate explanation formulas of different lengths using an encoding in Answer Set Programming. The most accurate formulas we obtain achieve errors similar to other methods on the same data sets. However, due to overfitting, these formulas are not necessarily ideal explanations, so we use cross validation to identify a suitable length for explanations. By limiting to shorter formulas, we obtain explanations that avoid overfitting but are still reasonably accurate and also, importantly, human interpretable.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25506;&#32034;&#20102;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#22312;&#22312;&#32447;&#32844;&#20301;&#25512;&#33616;&#20013;&#23545;&#22270;&#25968;&#25454;&#30340;&#29702;&#35299;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#26694;&#26550;&#26469;&#20998;&#26512;&#34892;&#20026;&#22270;&#65292;&#21457;&#29616;&#20854;&#20013;&#30340;&#28508;&#22312;&#27169;&#24335;&#21644;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2307.05722</link><description>&lt;p&gt;
&#25506;&#32034;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#22312;&#22312;&#32447;&#32844;&#20301;&#25512;&#33616;&#20013;&#23545;&#22270;&#25968;&#25454;&#30340;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Exploring Large Language Model for Graph Data Understanding in Online Job Recommendations. (arXiv:2307.05722v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05722
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25506;&#32034;&#20102;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#22312;&#22312;&#32447;&#32844;&#20301;&#25512;&#33616;&#20013;&#23545;&#22270;&#25968;&#25454;&#30340;&#29702;&#35299;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#26694;&#26550;&#26469;&#20998;&#26512;&#34892;&#20026;&#22270;&#65292;&#21457;&#29616;&#20854;&#20013;&#30340;&#28508;&#22312;&#27169;&#24335;&#21644;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#20010;&#39046;&#22495;&#23637;&#31034;&#20102;&#20854;&#20986;&#33394;&#30340;&#33021;&#21147;&#65292;&#24443;&#24213;&#25913;&#21464;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22312;&#32844;&#20301;&#25512;&#33616;&#20013;&#23545;&#34892;&#20026;&#22270;&#30340;&#29702;&#35299;&#28508;&#21147;&#20173;&#28982;&#26410;&#34987;&#20805;&#20998;&#25506;&#32034;&#12290;&#26412;&#25991;&#26088;&#22312;&#25581;&#31034;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#22312;&#29702;&#35299;&#34892;&#20026;&#22270;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#24182;&#21033;&#29992;&#36825;&#31181;&#29702;&#35299;&#26469;&#25552;&#21319;&#22312;&#32447;&#25307;&#32856;&#20013;&#30340;&#25512;&#33616;&#65292;&#21253;&#25324;&#20419;&#36827;&#38750;&#20998;&#24067;&#24335;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#25552;&#20379;&#30340;&#20016;&#23500;&#19978;&#19979;&#25991;&#20449;&#24687;&#21644;&#35821;&#20041;&#34920;&#31034;&#26469;&#20998;&#26512;&#34892;&#20026;&#22270;&#24182;&#25581;&#31034;&#20854;&#20013;&#30340;&#28508;&#22312;&#27169;&#24335;&#21644;&#20851;&#31995;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20803;&#36335;&#24452;&#25552;&#31034;&#26500;&#36896;&#22120;&#65292;&#21033;&#29992;LLM&#25512;&#33616;&#22120;&#39318;&#27425;&#29702;&#35299;&#34892;&#20026;&#22270;&#65292;&#24182;&#35774;&#35745;&#20102;&#30456;&#24212;&#30340;&#36335;&#24452;&#22686;&#24378;&#27169;&#22359;&#26469;&#32531;&#35299;&#22522;&#20110;&#36335;&#24452;&#30340;&#24207;&#21015;&#36755;&#20837;&#24341;&#20837;&#30340;&#25552;&#31034;&#20559;&#24046;&#12290;&#36890;&#36807;&#21033;&#29992;&#23558;LM&#30340;&#29305;&#28857;&#24341;&#20837;&#21040;&#34892;&#20026;&#22270;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#20998;&#26512;&#20013;&#65292;&#25105;&#20204;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#23454;&#39564;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have revolutionized natural language processing tasks, demonstrating their exceptional capabilities in various domains. However, their potential for behavior graph understanding in job recommendations remains largely unexplored. This paper focuses on unveiling the capability of large language models in understanding behavior graphs and leveraging this understanding to enhance recommendations in online recruitment, including the promotion of out-of-distribution (OOD) application. We present a novel framework that harnesses the rich contextual information and semantic representations provided by large language models to analyze behavior graphs and uncover underlying patterns and relationships. Specifically, we propose a meta-path prompt constructor that leverages LLM recommender to understand behavior graphs for the first time and design a corresponding path augmentation module to alleviate the prompt bias introduced by path-based sequence input. By leveragin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#39044;&#35757;&#32451;&#27169;&#22411;&#21644;&#25968;&#25454;&#27969;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26234;&#33021;&#21512;&#32422;&#30340;&#28304;&#20195;&#30721;&#29305;&#24449;&#65292;&#23454;&#29616;&#26816;&#27979;&#20197;&#22826;&#22346;&#19978;&#30340;&#26234;&#33021;&#24222;&#20857;&#39575;&#23616;&#12290;&#35813;&#26041;&#27861;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#21644;&#38477;&#20302;&#20102;&#25968;&#25454;&#33719;&#21462;&#21644;&#29305;&#24449;&#25552;&#21462;&#30340;&#38590;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.01665</link><description>&lt;p&gt;
SourceP&#65306;&#20351;&#29992;&#39044;&#35757;&#32451;&#27169;&#22411;&#21644;&#25968;&#25454;&#27969;&#26234;&#33021;&#26816;&#27979;&#20197;&#22826;&#22346;&#19978;&#30340;&#26234;&#33021;&#24222;&#20857;&#39575;&#23616;
&lt;/p&gt;
&lt;p&gt;
SourceP: Smart Ponzi Schemes Detection on Ethereum Using Pre-training Model with Data Flow. (arXiv:2306.01665v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01665
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#39044;&#35757;&#32451;&#27169;&#22411;&#21644;&#25968;&#25454;&#27969;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26234;&#33021;&#21512;&#32422;&#30340;&#28304;&#20195;&#30721;&#29305;&#24449;&#65292;&#23454;&#29616;&#26816;&#27979;&#20197;&#22826;&#22346;&#19978;&#30340;&#26234;&#33021;&#24222;&#20857;&#39575;&#23616;&#12290;&#35813;&#26041;&#27861;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#21644;&#38477;&#20302;&#20102;&#25968;&#25454;&#33719;&#21462;&#21644;&#29305;&#24449;&#25552;&#21462;&#30340;&#38590;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#21306;&#22359;&#38142;&#25216;&#26415;&#36234;&#26469;&#36234;&#27969;&#34892;&#65292;&#20856;&#22411;&#30340;&#37329;&#34701;&#39575;&#23616;&#24222;&#20857;&#39575;&#23616;&#20063;&#22312;&#21306;&#22359;&#38142;&#24179;&#21488;&#20197;&#22826;&#22346;&#19978;&#20986;&#29616;&#12290;&#36890;&#36807;&#26234;&#33021;&#21512;&#32422;&#37096;&#32626;&#30340;&#36825;&#31181;&#24222;&#20857;&#39575;&#23616;&#65292;&#20063;&#31216;&#20026;&#26234;&#33021;&#24222;&#20857;&#39575;&#23616;&#65292;&#24050;&#32463;&#36896;&#25104;&#20102;&#22823;&#37327;&#30340;&#32463;&#27982;&#25439;&#22833;&#21644;&#36127;&#38754;&#24433;&#21709;&#12290;&#29616;&#26377;&#30340;&#20197;&#22826;&#22346;&#26234;&#33021;&#24222;&#20857;&#39575;&#23616;&#26816;&#27979;&#26041;&#27861;&#20027;&#35201;&#20381;&#36182;&#20110;&#26234;&#33021;&#21512;&#32422;&#30340;&#23383;&#33410;&#30721;&#29305;&#24449;&#12289;&#25805;&#20316;&#30721;&#29305;&#24449;&#12289;&#36134;&#25143;&#29305;&#24449;&#21644;&#20132;&#26131;&#34892;&#20026;&#29305;&#24449;&#65292;&#36825;&#20123;&#26041;&#27861;&#32570;&#20047;&#21487;&#35299;&#37322;&#24615;&#21644;&#21487;&#25345;&#32493;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;SourceP&#65292;&#19968;&#31181;&#20351;&#29992;&#39044;&#35757;&#32451;&#27169;&#22411;&#21644;&#25968;&#25454;&#27969;&#22312;&#20197;&#22826;&#22346;&#24179;&#21488;&#19978;&#26816;&#27979;&#26234;&#33021;&#24222;&#20857;&#39575;&#23616;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21482;&#38656;&#35201;&#21033;&#29992;&#26234;&#33021;&#21512;&#32422;&#30340;&#28304;&#20195;&#30721;&#20316;&#20026;&#29305;&#24449;&#65292;&#20174;&#21478;&#19968;&#20010;&#35282;&#24230;&#25506;&#32034;&#26816;&#27979;&#26234;&#33021;&#24222;&#20857;&#39575;&#23616;&#30340;&#21487;&#33021;&#24615;&#12290;SourceP&#38477;&#20302;&#20102;&#29616;&#26377;&#26816;&#27979;&#26041;&#27861;&#30340;&#25968;&#25454;&#33719;&#21462;&#21644;&#29305;&#24449;&#25552;&#21462;&#38590;&#24230;&#65292;&#21516;&#26102;&#22686;&#21152;&#20102;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
As blockchain technology becomes more and more popular, a typical financial scam, the Ponzi scheme, has also emerged in the blockchain platform Ethereum. This Ponzi scheme deployed through smart contracts, also known as the smart Ponzi scheme, has caused a lot of economic losses and negative impacts. Existing methods for detecting smart Ponzi schemes on Ethereum mainly rely on bytecode features, opcode features, account features, and transaction behavior features of smart contracts, and such methods lack interpretability and sustainability. In this paper, we propose SourceP, a method to detect smart Ponzi schemes on the Ethereum platform using pre-training models and data flow, which only requires using the source code of smart contracts as features to explore the possibility of detecting smart Ponzi schemes from another direction. SourceP reduces the difficulty of data acquisition and feature extraction of existing detection methods while increasing the interpretability of the model. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#25968;&#25454;&#38598;&#20013;&#30340;&#20998;&#24067;&#21464;&#21270;&#23545;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#32508;&#21512;&#21327;&#35758;&#26469;&#20998;&#26512;&#22810;&#26679;&#24615;&#21464;&#21270;&#21644;&#30456;&#20851;&#24615;&#21464;&#21270;&#12290;&#20351;&#29992;&#30382;&#32932;&#30284;&#20998;&#26512;&#20998;&#31867;&#38382;&#39064;&#30340;&#23454;&#20363;&#65292;&#21457;&#29616;&#27169;&#22411;&#19981;&#20165;&#20250;&#23398;&#20064;&#21644;&#20256;&#25773;&#30456;&#20851;&#24615;&#21464;&#21270;&#65292;&#32780;&#19988;&#21487;&#33021;&#20250;&#20351;&#29992;&#38169;&#35823;&#30340;&#29305;&#24449;&#12290;</title><link>http://arxiv.org/abs/2305.05807</link><description>&lt;p&gt;
&#21363;&#20351;&#24456;&#23567;&#30340;&#30456;&#20851;&#24615;&#21644;&#22810;&#26679;&#24615;&#21464;&#21270;&#20063;&#20250;&#23548;&#33268;&#25968;&#25454;&#38598;&#20559;&#24046;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Even Small Correlation and Diversity Shifts Pose Dataset-Bias Issues. (arXiv:2305.05807v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05807
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25968;&#25454;&#38598;&#20013;&#30340;&#20998;&#24067;&#21464;&#21270;&#23545;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#32508;&#21512;&#21327;&#35758;&#26469;&#20998;&#26512;&#22810;&#26679;&#24615;&#21464;&#21270;&#21644;&#30456;&#20851;&#24615;&#21464;&#21270;&#12290;&#20351;&#29992;&#30382;&#32932;&#30284;&#20998;&#26512;&#20998;&#31867;&#38382;&#39064;&#30340;&#23454;&#20363;&#65292;&#21457;&#29616;&#27169;&#22411;&#19981;&#20165;&#20250;&#23398;&#20064;&#21644;&#20256;&#25773;&#30456;&#20851;&#24615;&#21464;&#21270;&#65292;&#32780;&#19988;&#21487;&#33021;&#20250;&#20351;&#29992;&#38169;&#35823;&#30340;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#21464;&#21270;&#22312;&#23454;&#38469;&#25968;&#25454;&#38598;&#20013;&#24456;&#24120;&#35265;&#65292;&#20250;&#24433;&#21709;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#24615;&#33021;&#21644;&#21487;&#38752;&#24615;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#31181;&#31867;&#22411;&#30340;&#20998;&#24067;&#21464;&#21270;&#65306;&#22810;&#26679;&#24615;&#21464;&#21270;&#21644;&#30456;&#20851;&#24615;&#21464;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32508;&#21512;&#21327;&#35758;&#65292;&#20351;&#29992;&#21516;&#26102;&#23384;&#22312;&#36825;&#20004;&#31181;&#21464;&#21270;&#30340;&#25968;&#25454;&#38598;&#26469;&#20998;&#26512;&#23427;&#20204;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#19968;&#20010;&#30495;&#23454;&#30340;&#30382;&#32932;&#30284;&#20998;&#26512;&#20998;&#31867;&#38382;&#39064;&#20013;&#65292;&#20351;&#29992;&#20102;&#36229;&#20986;&#25968;&#25454;&#38598;&#21644;&#19987;&#38376;&#30340;&#20559;&#24046;&#27880;&#37322;&#12290;&#25105;&#20204;&#30340;&#21327;&#35758;&#25581;&#31034;&#20102;&#19977;&#20010;&#21457;&#29616;&#65306;1&#65289;&#27169;&#22411;&#21363;&#20351;&#36827;&#34892;&#20102;&#20302;&#20559;&#24046;&#35757;&#32451;&#20063;&#20250;&#23398;&#20064;&#24182;&#20256;&#25773;&#30456;&#20851;&#24615;&#21464;&#21270;&#65292;&#36825;&#21487;&#33021;&#20250;&#32047;&#31215;&#21644;&#32467;&#21512;&#38590;&#20197;&#35299;&#37322;&#30340;&#24369;&#20559;&#24046;&#30340;&#39118;&#38505;&#65307;2&#65289;&#27169;&#22411;&#22312;&#39640;&#12289;&#20302;&#20559;&#24046;&#24773;&#20917;&#19979;&#21487;&#20197;&#23398;&#20064;&#21040;&#31283;&#20581;&#30340;&#29305;&#24449;&#65292;&#20294;&#26159;&#22914;&#26524;&#27979;&#35797;&#26679;&#26412;&#26377;&#38169;&#35823;&#30340;&#29305;&#24449;&#23427;&#20204;&#21487;&#33021;&#20250;&#20351;&#29992;&#36825;&#20123;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distribution shifts are common in real-world datasets and can affect the performance and reliability of deep learning models. In this paper, we study two types of distribution shifts: diversity shifts, which occur when test samples exhibit patterns unseen during training, and correlation shifts, which occur when test data present a different correlation between seen invariant and spurious features. We propose an integrated protocol to analyze both types of shifts using datasets where they co-exist in a controllable manner. Finally, we apply our approach to a real-world classification problem of skin cancer analysis, using out-of-distribution datasets and specialized bias annotations. Our protocol reveals three findings: 1) Models learn and propagate correlation shifts even with low-bias training; this poses a risk of accumulating and combining unaccountable weak biases; 2) Models learn robust features in highand low-bias scenarios but use spurious ones if test samples have them; this
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#20559;&#24207;&#25968;&#25454;&#28145;&#24230;&#20989;&#25968;&#30340;&#32972;&#26223;&#19979;Blocher&#31561;&#20154;[2023]&#20013;&#20171;&#32461;&#30340;&#26080;&#20132;&#36890;&#29992;&#38598;&#21512;&#20855;&#26377;&#36830;&#36890;&#24615;&#23646;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.10549</link><description>&lt;p&gt;
&#20851;&#20110;&#26080;&#20132;&#38598;&#20559;&#24207;&#36890;&#29992;&#38598;&#21512;&#30340;&#36830;&#36890;&#24615;&#23646;&#24615;&#30340;&#27880;&#35760;
&lt;/p&gt;
&lt;p&gt;
A note on the connectedness property of union-free generic sets of partial orders. (arXiv:2304.10549v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10549
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#20559;&#24207;&#25968;&#25454;&#28145;&#24230;&#20989;&#25968;&#30340;&#32972;&#26223;&#19979;Blocher&#31561;&#20154;[2023]&#20013;&#20171;&#32461;&#30340;&#26080;&#20132;&#36890;&#29992;&#38598;&#21512;&#20855;&#26377;&#36830;&#36890;&#24615;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30701;&#25991;&#25551;&#36848;&#24182;&#35777;&#26126;&#20102;&#22312;&#20559;&#24207;&#25968;&#25454;&#28145;&#24230;&#20989;&#25968;&#30340;&#32972;&#26223;&#19979;Blocher&#31561;&#20154;[2023]&#24341;&#20837;&#30340;&#36830;&#36890;&#24615;&#23646;&#24615;&#12290; &#36830;&#36890;&#24615;&#23646;&#24615;&#20026;&#26080;&#20132;&#36890;&#29992;&#38598;&#21512;&#25552;&#20379;&#20102;&#32467;&#26500;&#24615;&#30340;&#28145;&#20837;&#35748;&#35782;&#12290;&#36825;&#20123;&#38598;&#21512;&#26159;&#22312;Blocher&#31561;&#20154;[2023]&#20013;&#20171;&#32461;&#30340;&#65292;&#23427;&#20204;&#20351;&#29992;&#22312;&#24418;&#24335;&#27010;&#24565;&#20998;&#26512;&#29702;&#35770;&#20013;&#33258;&#28982;&#20986;&#29616;&#30340;&#25152;&#26377;&#20559;&#24207;&#38598;&#21512;&#19978;&#30340;&#38381;&#21253;&#36816;&#31639;&#36827;&#34892;&#23450;&#20041;&#12290;&#22312;&#24418;&#24335;&#27010;&#24565;&#20998;&#26512;&#30340;&#35821;&#35328;&#20013;&#65292;&#36830;&#36890;&#24615;&#30340;&#23646;&#24615;&#21487;&#20197;&#29983;&#21160;&#22320;&#34987;&#35777;&#26126;&#12290;&#20294;&#26159;&#65292;&#30001;&#20110;&#22312;Blocher&#31561;&#20154;[2023]&#20013;&#25105;&#20204;&#27809;&#26377;&#35752;&#35770;&#24418;&#24335;&#27010;&#24565;&#20998;&#26512;,&#22240;&#27492;&#25105;&#20204;&#25226;&#35777;&#26126;&#25918;&#21040;&#20102;&#36825;&#37324;&#12290;
&lt;/p&gt;
&lt;p&gt;
This short note describes and proves a connectedness property which was introduced in Blocher et al. [2023] in the context of data depth functions for partial orders. The connectedness property gives a structural insight into union-free generic sets. These sets, presented in Blocher et al. [2023], are defined by using a closure operator on the set of all partial orders which naturally appears within the theory of formal concept analysis. In the language of formal concept analysis, the property of connectedness can be vividly proven. However, since within Blocher et al. [2023] we did not discuss formal concept analysis, we outsourced the proof to this note.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;BloombergGPT&#65292;&#19968;&#20010;500&#20159;&#21442;&#25968;&#30340;&#37329;&#34701;&#39046;&#22495;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#20854;&#22522;&#20110;Bloomberg&#30340;&#24191;&#27867;&#25968;&#25454;&#26469;&#28304;&#21644;&#36890;&#29992;&#25968;&#25454;&#38598;&#36827;&#34892;&#35757;&#32451;&#12290;&#36890;&#36807;&#28151;&#21512;&#25968;&#25454;&#38598;&#35757;&#32451;&#65292;&#35813;&#27169;&#22411;&#22312;&#37329;&#34701;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#24182;&#19988;&#19981;&#20250;&#29306;&#29298;&#22312;&#26222;&#36890;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.17564</link><description>&lt;p&gt;
BloombergGPT&#65306;&#37329;&#34701;&#39046;&#22495;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
BloombergGPT: A Large Language Model for Finance. (arXiv:2303.17564v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17564
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;BloombergGPT&#65292;&#19968;&#20010;500&#20159;&#21442;&#25968;&#30340;&#37329;&#34701;&#39046;&#22495;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#20854;&#22522;&#20110;Bloomberg&#30340;&#24191;&#27867;&#25968;&#25454;&#26469;&#28304;&#21644;&#36890;&#29992;&#25968;&#25454;&#38598;&#36827;&#34892;&#35757;&#32451;&#12290;&#36890;&#36807;&#28151;&#21512;&#25968;&#25454;&#38598;&#35757;&#32451;&#65292;&#35813;&#27169;&#22411;&#22312;&#37329;&#34701;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#24182;&#19988;&#19981;&#20250;&#29306;&#29298;&#22312;&#26222;&#36890;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#22312;&#37329;&#34701;&#25216;&#26415;&#39046;&#22495;&#26377;&#30528;&#24191;&#27867;&#32780;&#22797;&#26434;&#30340;&#24212;&#29992;&#65292;&#20174;&#24773;&#24863;&#20998;&#26512;&#21644;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#21040;&#38382;&#31572;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24050;&#34987;&#35777;&#26126;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#38750;&#24120;&#26377;&#25928;&#65307;&#28982;&#32780;&#65292;&#19987;&#20026;&#37329;&#34701;&#39046;&#22495;&#35774;&#35745;&#30340;LLM&#23578;&#26410;&#22312;&#25991;&#29486;&#20013;&#25253;&#21578;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;BloombergGPT&#65292;&#19968;&#20010;&#25317;&#26377;500&#20159;&#20010;&#21442;&#25968;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#23427;&#26159;&#22522;&#20110;&#24191;&#27867;&#30340;&#37329;&#34701;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#30340;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#31181;3630&#20159;&#20010;&#26631;&#35760;&#30340;&#25968;&#25454;&#38598;&#65292;&#35813;&#25968;&#25454;&#38598;&#22522;&#20110;&#24429;&#21338;&#31038;&#30340;&#24191;&#27867;&#25968;&#25454;&#26469;&#28304;&#65292;&#21487;&#33021;&#26159;&#36804;&#20170;&#26368;&#22823;&#30340;&#39046;&#22495;&#29305;&#23450;&#25968;&#25454;&#38598;&#65292;&#21516;&#26102;&#21448;&#22686;&#21152;&#20102;&#26469;&#33258;&#36890;&#29992;&#25968;&#25454;&#38598;&#30340;3450&#20159;&#20010;&#26631;&#35760;&#12290;&#25105;&#20204;&#22312;&#26631;&#20934;LLM&#22522;&#20934;&#12289;&#24320;&#25918;&#24335;&#37329;&#34701;&#22522;&#20934;&#21644;&#19968;&#22871;&#26368;&#33021;&#20934;&#30830;&#21453;&#26144;&#25105;&#20204;&#39044;&#26399;&#29992;&#36884;&#30340;&#20869;&#37096;&#22522;&#20934;&#19978;&#39564;&#35777;&#20102;BloombergGPT&#12290;&#25105;&#20204;&#30340;&#28151;&#21512;&#25968;&#25454;&#38598;&#35757;&#32451;&#20135;&#29983;&#20102;&#19968;&#20010;&#22312;&#37329;&#34701;&#20219;&#21153;&#19978;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#27169;&#22411;&#30340;&#27169;&#22411;&#65292;&#21516;&#26102;&#19981;&#20250;&#29306;&#29298;&#26222;&#36890;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The use of NLP in the realm of financial technology is broad and complex, with applications ranging from sentiment analysis and named entity recognition to question answering. Large Language Models (LLMs) have been shown to be effective on a variety of tasks; however, no LLM specialized for the financial domain has been reported in literature. In this work, we present BloombergGPT, a 50 billion parameter language model that is trained on a wide range of financial data. We construct a 363 billion token dataset based on Bloomberg's extensive data sources, perhaps the largest domain-specific dataset yet, augmented with 345 billion tokens from general purpose datasets. We validate BloombergGPT on standard LLM benchmarks, open financial benchmarks, and a suite of internal benchmarks that most accurately reflect our intended usage. Our mixed dataset training leads to a model that outperforms existing models on financial tasks by significant margins without sacrificing performance on general 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35299;&#37322;&#32422;&#26463;&#19979;&#30340;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;EPAC&#27169;&#22411;&#65292;&#25506;&#35752;&#20102;&#20351;&#29992;&#36825;&#20123;&#35299;&#37322;&#26102;&#27169;&#22411;&#30340;&#30410;&#22788;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#21464;&#20998;&#36817;&#20284;&#30340;&#31639;&#27861;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2303.14496</link><description>&lt;p&gt;
&#35299;&#37322;&#32422;&#26463;&#19979;&#30340;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Learning with Explanation Constraints. (arXiv:2303.14496v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14496
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35299;&#37322;&#32422;&#26463;&#19979;&#30340;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;EPAC&#27169;&#22411;&#65292;&#25506;&#35752;&#20102;&#20351;&#29992;&#36825;&#20123;&#35299;&#37322;&#26102;&#27169;&#22411;&#30340;&#30410;&#22788;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#21464;&#20998;&#36817;&#20284;&#30340;&#31639;&#27861;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#30417;&#30563;&#23398;&#20064;&#20551;&#35774;&#23384;&#22312;&#26631;&#27880;&#25968;&#25454;&#65292;&#20294;&#25105;&#20204;&#21487;&#33021;&#26377;&#20851;&#20110;&#27169;&#22411;&#24212;&#22914;&#20309;&#36816;&#34892;&#30340;&#20808;&#39564;&#20449;&#24687;&#12290;&#26412;&#25991;&#23558;&#20854;&#24418;&#24335;&#21270;&#20026;&#20174;&#35299;&#37322;&#32422;&#26463;&#20013;&#23398;&#20064;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#23398;&#20064;&#29702;&#35770;&#26694;&#26550;&#65292;&#20998;&#26512;&#20102;&#36825;&#20123;&#35299;&#37322;&#22914;&#20309;&#25552;&#39640;&#27169;&#22411;&#30340;&#23398;&#20064;&#33021;&#21147;&#12290;&#26412;&#25991;&#30340;&#31532;&#19968;&#39033;&#20851;&#38190;&#36129;&#29486;&#26159;&#36890;&#36807;&#23450;&#20041;&#25105;&#20204;&#31216;&#20043;&#20026;EPAC&#27169;&#22411;&#65288;&#22312;&#26032;&#25968;&#25454;&#26399;&#26395;&#20013;&#28385;&#36275;&#36825;&#20123;&#32422;&#26463;&#30340;&#27169;&#22411;&#65289;&#26469;&#22238;&#31572;&#21738;&#20123;&#27169;&#22411;&#20250;&#21463;&#30410;&#20110;&#35299;&#37322;&#36825;&#19968;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#26631;&#20934;&#30340;&#23398;&#20064;&#29702;&#35770;&#24037;&#20855;&#20998;&#26512;&#20102;&#36825;&#31867;&#27169;&#22411;&#12290;&#31532;&#20108;&#20010;&#20851;&#38190;&#36129;&#29486;&#26159;&#23545;&#20110;&#30001;&#32447;&#24615;&#27169;&#22411;&#21644;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26799;&#24230;&#20449;&#24687;&#32473;&#20986;&#30340;&#35268;&#33539;&#35299;&#37322;&#30340;&#38480;&#21046;&#65288;&#20197;&#20854;Rademacher&#22797;&#26434;&#24230;&#20026;&#34913;&#37327;&#26631;&#20934;&#65289;&#36827;&#34892;&#20102;&#34920;&#24449;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#31181;&#21464;&#20998;&#36817;&#20284;&#25552;&#20379;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#30340;&#31639;&#27861;&#35299;&#20915;&#26041;&#26696;&#65292;&#23427;&#33021;&#22815;&#23454;&#29616;&#26356;&#22909;&#30340;&#24615;&#33021;&#24182;&#28385;&#36275;&#36825;&#20123;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;
While supervised learning assumes the presence of labeled data, we may have prior information about how models should behave. In this paper, we formalize this notion as learning from explanation constraints and provide a learning theoretic framework to analyze how such explanations can improve the learning of our models. For what models would explanations be helpful? Our first key contribution addresses this question via the definition of what we call EPAC models (models that satisfy these constraints in expectation over new data), and we analyze this class of models using standard learning theoretic tools. Our second key contribution is to characterize these restrictions (in terms of their Rademacher complexities) for a canonical class of explanations given by gradient information for linear models and two layer neural networks. Finally, we provide an algorithmic solution for our framework, via a variational approximation that achieves better performance and satisfies these constraint
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#33945;&#29305;&#21345;&#32599;&#26641;&#25628;&#32034;&#21644;&#35777;&#26126;&#25968;&#25628;&#32034;&#30456;&#32467;&#21512;&#30340;PN-MCTS&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#22810;&#20010;&#28216;&#25103;&#20013;&#22343;&#34920;&#29616;&#20986;&#20248;&#36234;&#30340;&#24615;&#33021;&#65292;&#21487;&#29992;&#20110;&#26368;&#32456;&#36208;&#27493;&#36873;&#25321;&#12289;&#35299;&#20915;&#23376;&#26641;&#20197;&#21450;UCT&#20844;&#24335;&#12290;</title><link>http://arxiv.org/abs/2303.09449</link><description>&lt;p&gt;
&#22522;&#20110;&#35777;&#26126;&#25968;&#30340;&#33945;&#29305;&#21345;&#32599;&#26641;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
Proof Number Based Monte-Carlo Tree Search. (arXiv:2303.09449v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09449
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#33945;&#29305;&#21345;&#32599;&#26641;&#25628;&#32034;&#21644;&#35777;&#26126;&#25968;&#25628;&#32034;&#30456;&#32467;&#21512;&#30340;PN-MCTS&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#22810;&#20010;&#28216;&#25103;&#20013;&#22343;&#34920;&#29616;&#20986;&#20248;&#36234;&#30340;&#24615;&#33021;&#65292;&#21487;&#29992;&#20110;&#26368;&#32456;&#36208;&#27493;&#36873;&#25321;&#12289;&#35299;&#20915;&#23376;&#26641;&#20197;&#21450;UCT&#20844;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28216;&#25103;&#25628;&#32034;&#31639;&#27861;PN-MCTS&#65292;&#23427;&#23558;&#33945;&#29305;&#21345;&#32599;&#26641;&#25628;&#32034;&#65288;MCTS&#65289;&#21644;&#35777;&#26126;&#25968;&#25628;&#32034;&#65288;PNS&#65289;&#30456;&#32467;&#21512;&#12290;&#36825;&#20004;&#31181;&#31639;&#27861;&#24050;&#25104;&#21151;&#24212;&#29992;&#20110;&#21508;&#31181;&#39046;&#22495;&#30340;&#20915;&#31574;&#38382;&#39064;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#19977;&#20010;&#39046;&#22495;&#65292;&#21363;&#26368;&#32456;&#36208;&#27493;&#36873;&#25321;&#65292;&#35299;&#20915;&#23376;&#26641;&#20197;&#21450;UCT&#20844;&#24335;&#65292;&#36825;&#20123;&#39046;&#22495;&#21487;&#20197;&#21033;&#29992;&#22312;MCTS&#26641;&#20013;&#25910;&#38598;&#21040;&#30340;&#35777;&#26126;&#25968;&#21644;&#35777;&#20266;&#25968;&#25552;&#20379;&#30340;&#38468;&#21152;&#30693;&#35782;&#12290;&#25105;&#20204;&#22312;&#19981;&#21516;&#30340;&#26102;&#38388;&#35774;&#32622;&#19979;&#23545;&#25152;&#26377;&#21487;&#33021;&#30340;&#32452;&#21512;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#24182;&#22312;&#20960;&#20010;&#28216;&#25103;&#20013;&#19982;vanilla UCT MCTS&#36827;&#34892;&#23545;&#20915;&#65306;&#21160;&#20316;&#32447;&#65288;$7$$\times$$7$&#21644;$8$$\times$$8$&#65289;&#65292;MiniShogi&#65292; Knightthrough&#65292; Awari&#21644;Gomoku&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;&#35813;&#31639;&#27861;&#36827;&#34892;&#25193;&#23637;&#65292;&#20197;&#36866;&#24403;&#22320;&#22788;&#29702;&#20986;&#29616;&#24179;&#23616;&#30340;&#28216;&#25103;&#65292;&#22914;Awari&#65292;&#36890;&#36807;&#22312;MCTS&#26641;&#30340;&#39030;&#37096;&#28155;&#21152;&#19968;&#20010;&#38468;&#21152;&#30340;PNS&#23618;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;PN-MCTS&#22312;6&#20010;&#28216;&#25103;&#39046;&#22495;&#20013;&#26377;5&#20010;&#30340;&#32988;&#29575;&#20248;&#20110;MCTS&#65288;&#38500;&#20102;Gomoku&#65289;&#65292;&#20854;&#20013;&#22312;&#21160;&#20316;&#32447;&#28216;&#25103;&#20013;&#33719;&#24471;&#20102;&#39640;&#36798;96.2%&#30340;&#32988;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a new game search algorithm, PN-MCTS, that combines Monte-Carlo Tree Search (MCTS) and Proof-Number Search (PNS). These two algorithms have been successfully applied for decision making in a range of domains. We define three areas where the additional knowledge provided by the proof and disproof numbers gathered in MCTS trees might be used: final move selection, solving subtrees, and the UCT formula. We test all possible combinations on different time settings, playing against vanilla UCT MCTS on several games: Lines of Action ($7$$\times$$7$ and $8$$\times$$8$), MiniShogi, Knightthrough, Awari, and Gomoku. Furthermore, we extend this new algorithm to properly address games with draws, like Awari, by adding an additional layer of PNS on top of the MCTS tree. The experiments show that PN-MCTS confidently outperforms MCTS in 5 out of 6 game domains (all except Gomoku), achieving win rates up to 96.2% for Lines of Action.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23545;&#27604;&#21464;&#20998;&#20449;&#24687;&#29942;&#39048;&#26694;&#26550;&#65288;CVIB&#65289;&#65292;&#20197;&#20943;&#23569;&#26041;&#38754;&#24773;&#24863;&#20998;&#26512;&#65288;ABSA&#65289;&#20013;&#30340;&#34394;&#20551;&#30456;&#20851;&#24615;&#12290;&#35813;&#26694;&#26550;&#30001;&#19968;&#20010;&#21407;&#22987;&#32593;&#32476;&#21644;&#19968;&#20010;&#33258;&#21098;&#26525;&#32593;&#32476;&#32452;&#25104;&#65292;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#21516;&#26102;&#36827;&#34892;&#20248;&#21270;&#65292;&#20174;&#32780;&#20002;&#24323;&#20102;&#36755;&#20837;&#29305;&#24449;&#21644;&#39044;&#27979;&#26631;&#31614;&#20043;&#38388;&#30340;&#22810;&#20313;&#27169;&#24335;&#25110;&#34394;&#20551;&#30456;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.02846</link><description>&lt;p&gt;
&#36890;&#36807;&#21464;&#20998;&#20449;&#24687;&#29942;&#39048;&#21644;&#23545;&#27604;&#23398;&#20064;&#20943;&#23569;&#26041;&#38754;&#24773;&#24863;&#20998;&#26512;&#20013;&#30340;&#34394;&#20551;&#30456;&#20851;&#24615;
&lt;/p&gt;
&lt;p&gt;
Reducing Spurious Correlations for Aspect-Based Sentiment Analysis with Variational Information Bottleneck and Contrastive Learning. (arXiv:2303.02846v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.02846
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23545;&#27604;&#21464;&#20998;&#20449;&#24687;&#29942;&#39048;&#26694;&#26550;&#65288;CVIB&#65289;&#65292;&#20197;&#20943;&#23569;&#26041;&#38754;&#24773;&#24863;&#20998;&#26512;&#65288;ABSA&#65289;&#20013;&#30340;&#34394;&#20551;&#30456;&#20851;&#24615;&#12290;&#35813;&#26694;&#26550;&#30001;&#19968;&#20010;&#21407;&#22987;&#32593;&#32476;&#21644;&#19968;&#20010;&#33258;&#21098;&#26525;&#32593;&#32476;&#32452;&#25104;&#65292;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#21516;&#26102;&#36827;&#34892;&#20248;&#21270;&#65292;&#20174;&#32780;&#20002;&#24323;&#20102;&#36755;&#20837;&#29305;&#24449;&#21644;&#39044;&#27979;&#26631;&#31614;&#20043;&#38388;&#30340;&#22810;&#20313;&#27169;&#24335;&#25110;&#34394;&#20551;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a novel Contrastive Variational Information Bottleneck framework (CVIB) to reduce spurious correlations for aspect-based sentiment analysis (ABSA). The proposed CVIB framework is composed of an original network and a self-pruned network, and these two networks are optimized simultaneously via contrastive learning, which discards the superfluous patterns or spurious correlations between input features and prediction labels.
&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#22312;&#26041;&#38754;&#24773;&#24863;&#20998;&#26512;&#65288;ABSA&#65289;&#30340;&#25991;&#29486;&#20013;&#21344;&#25454;&#20027;&#23548;&#22320;&#20301;&#65292;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#28145;&#24230;&#27169;&#22411;&#36890;&#24120;&#22312;&#36755;&#20837;&#29305;&#24449;&#21644;&#36755;&#20986;&#26631;&#31614;&#20043;&#38388;&#23384;&#22312;&#34394;&#20551;&#30456;&#20851;&#24615;&#38382;&#39064;&#65292;&#36825;&#20250;&#32473;&#40065;&#26834;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#24102;&#26469;&#37325;&#22823;&#38556;&#30861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23545;&#27604;&#21464;&#20998;&#20449;&#24687;&#29942;&#39048;&#26694;&#26550;&#65288;&#31216;&#20026;CVIB&#65289;&#65292;&#20197;&#20943;&#23569;ABSA&#20013;&#30340;&#34394;&#20551;&#30456;&#20851;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;CVIB&#26694;&#26550;&#30001;&#19968;&#20010;&#21407;&#22987;&#32593;&#32476;&#21644;&#19968;&#20010;&#33258;&#21098;&#26525;&#32593;&#32476;&#32452;&#25104;&#65292;&#36825;&#20004;&#20010;&#32593;&#32476;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#21516;&#26102;&#36827;&#34892;&#20248;&#21270;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#37319;&#29992;&#21464;&#20998;&#20449;&#24687;&#29942;&#39048;&#65288;VIB&#65289;&#21407;&#21017;&#20174;&#21407;&#22987;&#32593;&#32476;&#20013;&#23398;&#20064;&#19968;&#20010;&#20449;&#24687;&#20016;&#23500;&#19988;&#21387;&#32553;&#30340;&#32593;&#32476;&#65288;&#33258;&#21098;&#26525;&#32593;&#32476;&#65289;&#65292;&#35813;&#32593;&#32476;&#20002;&#24323;&#20102;&#36755;&#20837;&#29305;&#24449;&#21644;&#39044;&#27979;&#26631;&#31614;&#20043;&#38388;&#30340;&#22810;&#20313;&#27169;&#24335;&#25110;&#34394;&#20551;&#30456;&#20851;&#24615;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#33258;&#21098;&#26525;&#23545;&#27604;&#23398;&#20064;&#65292;&#20197;&#23558;&#20004;&#20010;&#32593;&#32476;&#25289;&#22312;&#19968;&#36215;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning techniques have dominated the literature on aspect-based sentiment analysis (ABSA), yielding state-of-the-art results. However, these deep models generally suffer from spurious correlation problems between input features and output labels, which creates significant barriers to robustness and generalization capability. In this paper, we propose a novel Contrastive Variational Information Bottleneck framework (called CVIB) to reduce spurious correlations for ABSA. The proposed CVIB framework is composed of an original network and a self-pruned network, and these two networks are optimized simultaneously via contrastive learning. Concretely, we employ the Variational Information Bottleneck (VIB) principle to learn an informative and compressed network (self-pruned network) from the original network, which discards the superfluous patterns or spurious correlations between input features and prediction labels. Then, self-pruning contrastive learning is devised to pull together
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#21644;&#26234;&#33021;&#25163;&#34920;&#25968;&#25454;&#36827;&#34892;&#35748;&#30693;&#36127;&#33655;&#20272;&#35745;&#65292;&#30740;&#31350;&#21457;&#29616;&#28216;&#25103;&#21270;&#30340;&#33258;&#25105;&#25253;&#21578;&#26041;&#24335;&#19982;&#20256;&#32479;&#26041;&#24335;&#30340;&#35748;&#30693;&#36127;&#33655;&#27809;&#26377;&#24046;&#24322;&#65292;&#20294;&#21442;&#19982;&#32773;&#26356;&#21916;&#27426;&#28216;&#25103;&#21270;&#29256;&#26412;&#12290;</title><link>http://arxiv.org/abs/2302.03616</link><description>&lt;p&gt;
&#28216;&#25103;&#21270;&#33021;&#21542;&#20943;&#36731;mHealth&#24212;&#29992;&#20013;&#33258;&#25105;&#25253;&#21578;&#30340;&#36127;&#25285;&#65311;&#21033;&#29992;&#26234;&#33021;&#25163;&#34920;&#25968;&#25454;&#30340;&#26426;&#22120;&#23398;&#20064;&#36827;&#34892;&#35748;&#30693;&#36127;&#33655;&#20272;&#35745;&#30340;&#21487;&#34892;&#24615;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Can gamification reduce the burden of self-reporting in mHealth applications? A feasibility study using machine learning from smartwatch data to estimate cognitive load. (arXiv:2302.03616v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03616
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#21644;&#26234;&#33021;&#25163;&#34920;&#25968;&#25454;&#36827;&#34892;&#35748;&#30693;&#36127;&#33655;&#20272;&#35745;&#65292;&#30740;&#31350;&#21457;&#29616;&#28216;&#25103;&#21270;&#30340;&#33258;&#25105;&#25253;&#21578;&#26041;&#24335;&#19982;&#20256;&#32479;&#26041;&#24335;&#30340;&#35748;&#30693;&#36127;&#33655;&#27809;&#26377;&#24046;&#24322;&#65292;&#20294;&#21442;&#19982;&#32773;&#26356;&#21916;&#27426;&#28216;&#25103;&#21270;&#29256;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#23383;&#21270;&#27835;&#30103;&#30340;&#26377;&#25928;&#24615;&#21487;&#20197;&#36890;&#36807;&#35201;&#27714;&#24739;&#32773;&#36890;&#36807;&#24212;&#29992;&#31243;&#24207;&#33258;&#25105;&#25253;&#21578;&#20854;&#29366;&#24577;&#26469;&#34913;&#37327;&#65292;&#28982;&#32780;&#65292;&#36825;&#21487;&#33021;&#20250;&#20196;&#20154;&#19981;&#30693;&#25152;&#25514;&#24182;&#23548;&#33268;&#22833;&#21435;&#21442;&#19982;&#24230;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#30740;&#31350;&#65292;&#25506;&#35752;&#28216;&#25103;&#21270;&#23545;&#33258;&#25105;&#25253;&#21578;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#21019;&#24314;&#19968;&#20010;&#31995;&#32479;&#65292;&#36890;&#36807;&#20998;&#26512;&#20809;-&#34880;&#23481;&#31215;&#21464;&#21270;&#20449;&#21495;&#26469;&#35780;&#20272;&#35748;&#30693;&#36127;&#33655;&#65288;CL&#65289;&#12290;&#21033;&#29992;11&#21517;&#21442;&#19982;&#32773;&#30340;&#25968;&#25454;&#26469;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26469;&#26816;&#27979;CL&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#21019;&#24314;&#20102;&#20004;&#20010;&#29256;&#26412;&#30340;&#35843;&#26597;&#38382;&#21367;&#65306;&#19968;&#20010;&#26159;&#28216;&#25103;&#21270;&#29256;&#26412;&#65292;&#19968;&#20010;&#26159;&#20256;&#32479;&#29256;&#26412;&#12290;&#25105;&#20204;&#20272;&#35745;&#20854;&#20182;&#21442;&#19982;&#32773;&#65288;13&#21517;&#65289;&#22312;&#23436;&#25104;&#35843;&#26597;&#38382;&#21367;&#26102;&#32463;&#21382;&#30340;CL&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#36890;&#36807;&#39044;&#20808;&#22312;&#24212;&#28608;&#26816;&#27979;&#20219;&#21153;&#20013;&#36827;&#34892;&#39044;&#35757;&#32451;&#65292;&#21487;&#20197;&#22686;&#24378;CL&#26816;&#27979;&#22120;&#30340;&#24615;&#33021;&#12290;&#23545;&#20110;13&#21517;&#21442;&#19982;&#32773;&#20013;&#30340;10&#21517;&#65292;&#20010;&#24615;&#21270;CL&#26816;&#27979;&#22120;&#21487;&#20197;&#23454;&#29616;&#39640;&#20110;0.7&#30340;F1&#24471;&#20998;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;CL&#26041;&#38754;&#65292;&#28216;&#25103;&#21270;&#21644;&#38750;&#28216;&#25103;&#21270;&#30340;&#35843;&#26597;&#38382;&#21367;&#27809;&#26377;&#21306;&#21035;&#65292;&#20294;&#21442;&#19982;&#32773;&#26356;&#21916;&#27426;&#28216;&#25103;&#21270;&#30340;&#29256;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
The effectiveness of digital treatments can be measured by requiring patients to self-report their state through applications, however, it can be overwhelming and causes disengagement. We conduct a study to explore the impact of gamification on self-reporting. Our approach involves the creation of a system to assess cognitive load (CL) through the analysis of photoplethysmography (PPG) signals. The data from 11 participants is utilized to train a machine learning model to detect CL. Subsequently, we create two versions of surveys: a gamified and a traditional one. We estimate the CL experienced by other participants (13) while completing surveys. We find that CL detector performance can be enhanced via pre-training on stress detection tasks. For 10 out of 13 participants, a personalized CL detector can achieve an F1 score above 0.7. We find no difference between the gamified and non-gamified surveys in terms of CL but participants prefer the gamified version.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28508;&#22312;&#32452;&#21512;&#28216;&#25103;&#35774;&#35745;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#28508;&#21464;&#37327;&#27169;&#22411;&#23558;&#32473;&#23450;&#30340;&#19968;&#32452;&#28216;&#25103;&#28151;&#21512;&#21040;&#25152;&#38656;&#32452;&#21512;&#20013;&#20197;&#29983;&#25104;&#21487;&#29609;&#28216;&#25103;&#65292;&#24182;&#19988;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#25511;&#21046;&#27599;&#20010;&#28216;&#25103;&#22312;&#28151;&#21512;&#28216;&#25103;&#20013;&#30340;&#27604;&#20363;&#12290;</title><link>http://arxiv.org/abs/2206.14203</link><description>&lt;p&gt;
&#28508;&#22312;&#32452;&#21512;&#28216;&#25103;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Latent Combinational Game Design. (arXiv:2206.14203v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.14203
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28508;&#22312;&#32452;&#21512;&#28216;&#25103;&#35774;&#35745;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#28508;&#21464;&#37327;&#27169;&#22411;&#23558;&#32473;&#23450;&#30340;&#19968;&#32452;&#28216;&#25103;&#28151;&#21512;&#21040;&#25152;&#38656;&#32452;&#21512;&#20013;&#20197;&#29983;&#25104;&#21487;&#29609;&#28216;&#25103;&#65292;&#24182;&#19988;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#25511;&#21046;&#27599;&#20010;&#28216;&#25103;&#22312;&#28151;&#21512;&#28216;&#25103;&#20013;&#30340;&#27604;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#28508;&#22312;&#32452;&#21512;&#28216;&#25103;&#35774;&#35745;&#8221;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#28508;&#21464;&#37327;&#27169;&#22411;&#23558;&#32473;&#23450;&#30340;&#19968;&#32452;&#28216;&#25103;&#28151;&#21512;&#21040;&#25152;&#38656;&#32452;&#21512;&#20013;&#20197;&#29983;&#25104;&#21487;&#29609;&#28216;&#25103;&#12290;&#25105;&#20204;&#20351;&#29992;&#39640;&#26031;&#28151;&#21512;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120; (GMVAEs) &#23545; VAE &#28508;&#22312;&#31354;&#38388;&#36827;&#34892;&#24314;&#27169;&#65292;&#36890;&#36807;&#30417;&#30563;&#24335;&#35757;&#32451;&#65292;&#27599;&#20010;&#32452;&#20214;&#23545;&#24212;&#19968;&#20010;&#28216;&#25103;&#30340;&#27700;&#24179;&#65292;&#24182;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;&#28151;&#21512;&#28216;&#25103;&#23450;&#20041;&#20026;&#36825;&#20123;&#32452;&#20214;&#30340;&#32447;&#24615;&#32452;&#21512;&#65292;&#36825;&#20351;&#24471;&#33021;&#22815;&#29983;&#25104;&#26032;&#28216;&#25103;&#65292;&#24182;&#25511;&#21046;&#28151;&#21512;&#20013;&#27599;&#20010;&#28216;&#25103;&#30340;&#27604;&#20363;&#12290;&#25105;&#20204;&#36824;&#20351;&#29992;&#26377;&#26465;&#20214;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#25193;&#23637;&#20197;&#21069;&#30340;&#28151;&#21512;&#24037;&#20316;&#65292;&#24182;&#19982; GMVAE &#36827;&#34892;&#27604;&#36739;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#28151;&#21512;&#26465;&#20214; GMVAE (CGMVAE) &#32467;&#26500;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#29983;&#25104;&#25972;&#20010;&#28151;&#21512;&#27700;&#24179;&#21644;&#24067;&#23616;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#19978;&#36848;&#26041;&#27861;&#21487;&#20197;&#29983;&#25104;&#25353;&#25351;&#23450;&#32452;&#21512;&#28151;&#21512;&#30340;&#21487;&#29609;&#28216;&#25103;&#12290;&#25105;&#20204;&#20351;&#29992;&#24179;&#21488;&#28216;&#25103;&#21644;&#22320;&#19979;&#22478;&#31867;&#28216;&#25103;&#26469;&#23637;&#31034;&#25105;&#20204;&#26041;&#27861;&#30340;&#21487;&#34892;&#24615;&#21644;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present latent combinational game design -- an approach for generating playable games that blend a given set of games in a desired combination using deep generative latent variable models. We use Gaussian Mixture Variational Autoencoders (GMVAEs) which model the VAE latent space via a mixture of Gaussian components. Through supervised training, each component encodes levels from one game and lets us define blended games as linear combinations of these components. This enables generating new games that blend the input games and controlling the relative proportions of each game in the blend. We also extend prior blending work using conditional VAEs and compare against the GMVAE and additionally introduce a hybrid conditional GMVAE (CGMVAE) architecture which lets us generate whole blended levels and layouts. Results show that the above approaches can generate playable games that blend the input games in specified combinations. We use both platformers and dungeon-based games to demonst
&lt;/p&gt;</description></item></channel></rss>