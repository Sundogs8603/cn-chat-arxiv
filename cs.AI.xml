<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.AI</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21033;&#29992;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#22522;&#20110;&#25439;&#22833;&#30340;&#26631;&#31614;&#20462;&#27491;&#26469;&#23398;&#20064;&#22810;&#27880;&#37322;&#32773;&#25968;&#25454;&#30340;&#20934;&#30830;&#34920;&#31034;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#20998;&#31163;&#36190;&#21516;&#21644;&#19981;&#36190;&#21516;&#30340;&#27880;&#37322;&#65292;&#24182;&#19988;&#22312;&#21333;&#19968;&#25110;&#22810;&#27880;&#37322;&#32773;&#35774;&#32622;&#19979;&#25913;&#21892;&#39044;&#27979;&#24615;&#33021;&#12290;&#35813;&#26041;&#27861;&#36824;&#26174;&#31034;&#20986;&#23545;&#20027;&#35266;&#25968;&#25454;&#30340;&#39069;&#22806;&#26631;&#31614;&#22122;&#22768;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.00619</link><description>&lt;p&gt;
&#22810;&#27880;&#37322;&#32773;&#25968;&#25454;&#30340;&#25439;&#22833;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Loss Modeling for Multi-Annotator Datasets. (arXiv:2311.00619v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00619
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21033;&#29992;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#22522;&#20110;&#25439;&#22833;&#30340;&#26631;&#31614;&#20462;&#27491;&#26469;&#23398;&#20064;&#22810;&#27880;&#37322;&#32773;&#25968;&#25454;&#30340;&#20934;&#30830;&#34920;&#31034;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#20998;&#31163;&#36190;&#21516;&#21644;&#19981;&#36190;&#21516;&#30340;&#27880;&#37322;&#65292;&#24182;&#19988;&#22312;&#21333;&#19968;&#25110;&#22810;&#27880;&#37322;&#32773;&#35774;&#32622;&#19979;&#25913;&#21892;&#39044;&#27979;&#24615;&#33021;&#12290;&#35813;&#26041;&#27861;&#36824;&#26174;&#31034;&#20986;&#23545;&#20027;&#35266;&#25968;&#25454;&#30340;&#39069;&#22806;&#26631;&#31614;&#22122;&#22768;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20844;&#27491;&#24615;&#26041;&#38754;&#65292;&#32771;&#34385;&#21040;&#25968;&#25454;&#38598;&#20013;&#25152;&#26377;&#27880;&#37322;&#32773;&#30340;&#24847;&#35265;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#22312;&#27880;&#37322;&#22823;&#22411;&#25968;&#25454;&#38598;&#26102;&#65292;&#20010;&#21035;&#27880;&#37322;&#32773;&#32463;&#24120;&#20250;&#25552;&#20379;&#25968;&#21315;&#20010;&#35780;&#20998;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#30130;&#21171;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#27880;&#37322;&#36807;&#31243;&#21487;&#33021;&#20250;&#25345;&#32493;&#22810;&#22825;&#65292;&#21487;&#33021;&#23548;&#33268;&#23545;&#27880;&#37322;&#32773;&#30340;&#24847;&#35265;&#38543;&#26102;&#38388;&#30340;&#19981;&#20934;&#30830;&#34920;&#31034;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#21033;&#29992;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;&#22522;&#20110;&#25439;&#22833;&#30340;&#26631;&#31614;&#20462;&#27491;&#26469;&#23398;&#20064;&#26356;&#20934;&#30830;&#30340;&#22810;&#26679;&#24847;&#35265;&#34920;&#31034;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#25105;&#20204;&#26032;&#39062;&#30340;&#20844;&#24335;&#65292;&#25105;&#20204;&#21487;&#20197;&#28165;&#26970;&#22320;&#20998;&#31163;&#36190;&#21516;&#21644;&#19981;&#36190;&#21516;&#30340;&#27880;&#37322;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#20462;&#25913;&#21487;&#20197;&#25913;&#21892;&#21333;&#19968;&#25110;&#22810;&#27880;&#37322;&#32773;&#35774;&#32622;&#19979;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#23545;&#24212;&#29992;&#20110;&#20027;&#35266;&#25968;&#25454;&#30340;&#39069;&#22806;&#26631;&#31614;&#22122;&#22768;&#20173;&#28982;&#20855;&#26377;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Accounting for the opinions of all annotators of a dataset is critical for fairness. However, when annotating large datasets, individual annotators will frequently provide thousands of ratings which can lead to fatigue. Additionally, these annotation processes can occur over multiple days which can lead to an inaccurate representation of an annotator's opinion over time. To combat this, we propose to learn a more accurate representation of diverse opinions by utilizing multitask learning in conjunction with loss-based label correction. We show that using our novel formulation, we can cleanly separate agreeing and disagreeing annotations. Furthermore, we demonstrate that this modification can improve prediction performance in a single or multi-annotator setting. Lastly, we show that this method remains robust to additional label noise that is applied to subjective data.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;DEFT&#30340;&#25968;&#25454;&#39640;&#25928;&#24494;&#35843;&#26694;&#26550;&#65292;&#36890;&#36807;&#26080;&#30417;&#30563;&#26680;&#24515;&#38598;&#36873;&#25321;&#26469;&#26368;&#23567;&#21270;&#24494;&#35843;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#25152;&#38656;&#30340;&#25968;&#25454;&#37327;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;DEFT&#27169;&#22411;&#22312;&#20934;&#30830;&#24615;&#19978;&#19982;&#29616;&#26377;&#27169;&#22411;&#30456;&#24403;&#65292;&#24182;&#19988;&#20165;&#20351;&#29992;&#20102;70%&#30340;&#25968;&#25454;&#37327;&#12290;</title><link>http://arxiv.org/abs/2310.16776</link><description>&lt;p&gt;
DEFT&#65306;&#36890;&#36807;&#26080;&#30417;&#30563;&#26680;&#24515;&#38598;&#36873;&#25321;&#23454;&#29616;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#25968;&#25454;&#39640;&#25928;&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
DEFT: Data Efficient Fine-Tuning for Large Language Models via Unsupervised Core-Set Selection. (arXiv:2310.16776v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16776
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;DEFT&#30340;&#25968;&#25454;&#39640;&#25928;&#24494;&#35843;&#26694;&#26550;&#65292;&#36890;&#36807;&#26080;&#30417;&#30563;&#26680;&#24515;&#38598;&#36873;&#25321;&#26469;&#26368;&#23567;&#21270;&#24494;&#35843;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#25152;&#38656;&#30340;&#25968;&#25454;&#37327;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;DEFT&#27169;&#22411;&#22312;&#20934;&#30830;&#24615;&#19978;&#19982;&#29616;&#26377;&#27169;&#22411;&#30456;&#24403;&#65292;&#24182;&#19988;&#20165;&#20351;&#29992;&#20102;70%&#30340;&#25968;&#25454;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#36827;&#23637;&#20351;&#24471;&#35768;&#22810;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#21487;&#20197;&#20351;&#29992;&#65307;&#28982;&#32780;&#65292;&#19968;&#20010;&#20173;&#28982;&#23384;&#22312;&#30340;&#38382;&#39064;&#26159;&#24494;&#35843;PLMs&#20197;&#29992;&#20110;&#19979;&#28216;&#20219;&#21153;&#31350;&#31455;&#38656;&#35201;&#22810;&#23569;&#25968;&#25454;&#65311;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;DEFT&#65292;&#19968;&#31181;&#25968;&#25454;&#39640;&#25928;&#30340;&#24494;&#35843;&#26694;&#26550;&#65292;&#23427;&#21033;&#29992;&#26080;&#30417;&#30563;&#30340;&#26680;&#24515;&#38598;&#36873;&#25321;&#26469;&#26368;&#23567;&#21270;&#24494;&#35843;PLMs&#25152;&#38656;&#30340;&#25968;&#25454;&#37327;&#12290;&#25105;&#20204;&#22312;&#25991;&#26412;&#32534;&#36753;LM&#30340;&#32972;&#26223;&#19979;&#23637;&#31034;&#20102;DEFT&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#19982;&#26368;&#20808;&#36827;&#30340;&#25991;&#26412;&#32534;&#36753;&#27169;&#22411;CoEDIT&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#25105;&#20204;&#30340;&#23450;&#37327;&#21644;&#23450;&#24615;&#32467;&#26524;&#34920;&#26126;&#65292;DEFT&#27169;&#22411;&#22312;&#20934;&#30830;&#24615;&#19978;&#19982;CoEDIT&#19968;&#26679;&#65292;&#32780;&#20351;&#29992;&#30340;&#25968;&#25454;&#37327;&#35201;&#23569;&#32422;70%&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances have led to the availability of many pre-trained language models (PLMs); however, a question that remains is how much data is truly needed to fine-tune PLMs for downstream tasks? In this work, we introduce DEFT, a data-efficient fine-tuning framework that leverages unsupervised core-set selection to minimize the amount of data needed to fine-tune PLMs for downstream tasks. We demonstrate the efficacy of our DEFT framework in the context of text-editing LMs, and compare to the state-of-the art text-editing model, CoEDIT. Our quantitative and qualitative results demonstrate that DEFT models are just as accurate as CoEDIT while being finetuned on ~70% less data.
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#25209;&#21028;&#24615;&#35843;&#26597;&#20998;&#26512;&#20102;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#19982;&#20844;&#24179;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#25351;&#20986;XAI&#22312;&#23454;&#29616;&#20844;&#24179;&#29702;&#24819;&#26041;&#38754;&#23384;&#22312;&#28508;&#21147;&#21644;&#38480;&#21046;&#65292;&#21628;&#21505;&#26356;&#20855;&#20307;&#22320;&#35828;&#26126;XAI&#26041;&#27861;&#22914;&#20309;&#24110;&#21161;&#35299;&#20915;&#20844;&#24179;&#29702;&#24819;&#12290;</title><link>http://arxiv.org/abs/2310.13007</link><description>&lt;p&gt;
XAI&#30340;&#20844;&#24179;&#25928;&#30410;&#30340;&#25209;&#21028;&#24615;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
A Critical Survey on Fairness Benefits of XAI. (arXiv:2310.13007v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13007
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#25209;&#21028;&#24615;&#35843;&#26597;&#20998;&#26512;&#20102;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#19982;&#20844;&#24179;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#25351;&#20986;XAI&#22312;&#23454;&#29616;&#20844;&#24179;&#29702;&#24819;&#26041;&#38754;&#23384;&#22312;&#28508;&#21147;&#21644;&#38480;&#21046;&#65292;&#21628;&#21505;&#26356;&#20855;&#20307;&#22320;&#35828;&#26126;XAI&#26041;&#27861;&#22914;&#20309;&#24110;&#21161;&#35299;&#20915;&#20844;&#24179;&#29702;&#24819;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#20010;&#25209;&#21028;&#24615;&#35843;&#26597;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#20851;&#20110;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#21644;&#20844;&#24179;&#20043;&#38388;&#20851;&#31995;&#30340;&#20856;&#22411;&#35770;&#36848;&#65292;&#20197;&#35299;&#24320;&#36825;&#20004;&#20010;&#27010;&#24565;&#20043;&#38388;&#30340;&#22810;&#32500;&#20851;&#31995;&#12290;&#36890;&#36807;&#31995;&#32479;&#25991;&#29486;&#32508;&#36848;&#21644;&#38543;&#21518;&#30340;&#23450;&#24615;&#20869;&#23481;&#20998;&#26512;&#65292;&#25105;&#20204;&#20174;175&#31687;&#35770;&#25991;&#20013;&#35782;&#21035;&#20986;&#20851;&#20110;XAI&#30340;&#20844;&#24179;&#25928;&#30410;&#30340;&#19971;&#20010;&#20856;&#22411;&#35770;&#26029;&#12290;&#25105;&#20204;&#25552;&#20986;&#20851;&#20110;&#36825;&#20123;&#35770;&#26029;&#30340;&#37325;&#35201;&#35686;&#21578;&#65292;&#24182;&#20026;&#26410;&#26469;&#22260;&#32469;XAI&#22312;&#29305;&#23450;&#20844;&#24179;&#29702;&#24819;&#20013;&#30340;&#28508;&#21147;&#21644;&#38480;&#21046;&#36827;&#34892;&#35752;&#35770;&#25552;&#20379;&#20102;&#19968;&#20010;&#20999;&#20837;&#28857;&#12290;&#34429;&#28982;&#25991;&#29486;&#36890;&#24120;&#35748;&#20026;XAI&#26159;&#23454;&#29616;&#22810;&#20010;&#20844;&#24179;&#29702;&#24819;&#30340;&#19968;&#31181;&#25163;&#27573;&#65292;&#20294;&#25105;&#20204;&#27880;&#24847;&#21040;&#36825;&#20123;&#29702;&#24819;&#19982;XAI&#30340;&#33021;&#21147;&#20043;&#38388;&#23384;&#22312;&#19981;&#19968;&#33268;&#12290;&#25105;&#20204;&#40723;&#21169;&#23558;XAI&#35270;&#20026;&#24212;&#23545;&#31639;&#27861;&#20844;&#24179;&#36825;&#19968;&#22810;&#32500;&#31038;&#20250;&#25216;&#26415;&#25361;&#25112;&#30340;&#20247;&#22810;&#24037;&#20855;&#20043;&#19968;&#65292;&#24182;&#26356;&#20855;&#20307;&#22320;&#35828;&#26126;&#21738;&#31181;XAI&#26041;&#27861;&#22914;&#20309;&#24110;&#21161;&#21738;&#20123;&#20154;&#35299;&#20915;&#21738;&#20123;&#20844;&#24179;&#29702;&#24819;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this critical survey, we analyze typical claims on the relationship between explainable AI (XAI) and fairness to disentangle the multidimensional relationship between these two concepts. Based on a systematic literature review and a subsequent qualitative content analysis, we identify seven archetypal claims from 175 papers on the alleged fairness benefits of XAI. We present crucial caveats with respect to these claims and provide an entry point for future discussions around the potentials and limitations of XAI for specific fairness desiderata. While the literature often suggests XAI to be an enabler for several fairness desiderata, we notice a misalignment between these desiderata and the capabilities of XAI. We encourage to conceive XAI as one of many tools to approach the multidimensional, sociotechnical challenge of algorithmic fairness and to be more specific about how exactly what kind of XAI method enables whom to address which fairness desideratum.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#26500;&#24314;&#19968;&#20010;&#22522;&#20934;&#65292;&#37327;&#21270;&#20102;&#20013;&#25991;&#21307;&#23398;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#19982;&#20581;&#24247;&#30456;&#20851;&#30340;&#21407;&#23376;&#30693;&#35782;&#30340;&#23384;&#20648;&#31243;&#24230;&#65292;&#24182;&#21457;&#29616;&#36890;&#29992;LLMs&#22312;&#21407;&#23376;&#30693;&#35782;&#21644;&#25351;&#20196;&#36981;&#24490;&#33021;&#21147;&#26041;&#38754;&#34920;&#29616;&#26356;&#22909;&#12290;&#20004;&#31181;&#31867;&#22411;&#30340;LLMs&#37117;&#20542;&#21521;&#20110;&#36814;&#21512;&#29992;&#25143;&#35201;&#27714;&#12290;</title><link>http://arxiv.org/abs/2310.11722</link><description>&lt;p&gt;
&#37327;&#21270;&#20013;&#25991;&#21307;&#23398;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#19982;&#20581;&#24247;&#30456;&#20851;&#30340;&#21407;&#23376;&#30693;&#35782;&#65306;&#19968;&#39033;&#35745;&#31639;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Quantify Health-Related Atomic Knowledge in Chinese Medical Large Language Models: A Computational Analysis. (arXiv:2310.11722v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11722
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#26500;&#24314;&#19968;&#20010;&#22522;&#20934;&#65292;&#37327;&#21270;&#20102;&#20013;&#25991;&#21307;&#23398;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#19982;&#20581;&#24247;&#30456;&#20851;&#30340;&#21407;&#23376;&#30693;&#35782;&#30340;&#23384;&#20648;&#31243;&#24230;&#65292;&#24182;&#21457;&#29616;&#36890;&#29992;LLMs&#22312;&#21407;&#23376;&#30693;&#35782;&#21644;&#25351;&#20196;&#36981;&#24490;&#33021;&#21147;&#26041;&#38754;&#34920;&#29616;&#26356;&#22909;&#12290;&#20004;&#31181;&#31867;&#22411;&#30340;LLMs&#37117;&#20542;&#21521;&#20110;&#36814;&#21512;&#29992;&#25143;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26377;&#28508;&#21147;&#36890;&#36807;&#25628;&#32034;&#24341;&#25806;&#30452;&#25509;&#21644;&#39640;&#25928;&#22320;&#25552;&#20379;&#29992;&#25143;&#30340;&#33258;&#35786;&#26029;&#24314;&#35758;&#65292;&#20174;&#32780;&#38761;&#26032;&#29992;&#25143;&#33258;&#35786;&#26029;&#30340;&#26041;&#24335;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#22522;&#20110;GPT-4&#35780;&#20272;LLMs&#30340;&#36136;&#37327;&#25110;&#20854;&#36890;&#36807;&#21307;&#23398;&#32771;&#35797;&#30340;&#33021;&#21147;&#65292;&#20294;&#27809;&#26377;&#30740;&#31350;&#37327;&#21270;&#23384;&#20648;&#22312;LLMs&#35760;&#24518;&#20013;&#30340;&#20581;&#24247;&#30456;&#20851;&#21407;&#23376;&#30693;&#35782;&#30340;&#31243;&#24230;&#65292;&#32780;&#36825;&#26159;LLMs&#25552;&#20379;&#26356;&#20934;&#30830;&#24314;&#35758;&#30340;&#22522;&#30784;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#26500;&#24314;&#20102;&#19968;&#20010;&#22522;&#20934;&#65292;&#21253;&#25324;&#29992;&#25143;&#33258;&#35786;&#26029;&#26597;&#35810;&#20013;&#26368;&#24120;&#35265;&#30340;&#21407;&#23376;&#30693;&#35782;&#31867;&#22411;&#65292;&#20849;17&#31181;&#21407;&#23376;&#31867;&#22411;&#21644;14048&#26465;&#21407;&#23376;&#30693;&#35782;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23545;&#36890;&#29992;&#21644;&#19987;&#19994;LLMs&#22312;&#22522;&#20934;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#21407;&#23376;&#30693;&#35782;&#21644;&#25351;&#20196;&#36981;&#24490;&#33021;&#21147;&#26041;&#38754;&#65292;&#36890;&#29992;LLMs&#30340;&#34920;&#29616;&#20248;&#20110;&#19987;&#19994;LLMs&#12290;&#38169;&#35823;&#20998;&#26512;&#26174;&#31034;&#65292;&#36890;&#29992;&#21644;&#19987;&#19994;LLMs&#37117;&#26159;&#39532;&#23617;&#31934;&#65292;&#21363;&#22312;&#28041;&#21450;&#29992;&#25143;&#35201;&#27714;&#26102;&#24635;&#26159;&#36814;&#21512;&#29992;&#25143;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have the potential to revolutionize the way users self-diagnose through search engines by offering direct and efficient suggestions. Recent studies primarily focused on the quality of LLMs evaluated by GPT-4 or their ability to pass medical exams, no studies have quantified the extent of health-related atomic knowledge stored in LLMs' memory, which is the basis of LLMs to provide more factual suggestions. In this paper, we first constructed a benchmark, including the most common types of atomic knowledge in user self-diagnosis queries, with 17 atomic types and a total of 14, 048 pieces of atomic knowledge. Then, we evaluated both generic and specialized LLMs on the benchmark. The experimental results showcased that generic LLMs perform better than specialized LLMs in terms of atomic knowledge and instruction-following ability. Error analysis revealed that both generic and specialized LLMs are sycophantic, e.g., always catering to users' claims when it comes
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#28145;&#20837;&#35752;&#35770;&#20102;&#22914;&#20309;&#21033;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#26469;&#26816;&#27979;&#20551;&#26032;&#38395;&#65292;&#24182;&#25581;&#31034;&#20102;&#20854;&#20013;&#30340;&#25361;&#25112;&#21644;&#26426;&#36935;&#12290;</title><link>http://arxiv.org/abs/2308.16328</link><description>&lt;p&gt;
&#25581;&#31192;&#20551;&#26032;&#38395;&#65306;&#36816;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#22312;&#25171;&#20987;&#20551;&#26032;&#38395;&#20013;&#30340;&#38761;&#21629;&#24615;&#30495;&#30456; (arXiv:2308.16328v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
Debunking Disinformation: Revolutionizing Truth with NLP in Fake News Detection. (arXiv:2308.16328v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16328
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#28145;&#20837;&#35752;&#35770;&#20102;&#22914;&#20309;&#21033;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#26469;&#26816;&#27979;&#20551;&#26032;&#38395;&#65292;&#24182;&#25581;&#31034;&#20102;&#20854;&#20013;&#30340;&#25361;&#25112;&#21644;&#26426;&#36935;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20114;&#32852;&#32593;&#21644;&#31038;&#20132;&#23186;&#20307;&#25913;&#21464;&#20102;&#20154;&#20204;&#22312;&#21363;&#26102;&#20449;&#24687;&#20256;&#25773;&#26102;&#20195;&#33719;&#21462;&#26032;&#38395;&#30340;&#26041;&#24335;&#12290;&#34429;&#28982;&#36825;&#19968;&#21457;&#23637;&#22686;&#21152;&#20102;&#20449;&#24687;&#33719;&#21462;&#30340;&#26426;&#20250;&#65292;&#20294;&#20063;&#24102;&#26469;&#20102;&#19968;&#20010;&#37325;&#22823;&#38382;&#39064;&#65306;&#20551;&#26032;&#38395;&#21644;&#34394;&#20551;&#20449;&#24687;&#30340;&#20256;&#25773;&#12290;&#20551;&#26032;&#38395;&#27491;&#22312;&#24555;&#36895;&#20256;&#25773;&#20110;&#25968;&#23383;&#24179;&#21488;&#19978;&#65292;&#23545;&#23186;&#20307;&#29983;&#24577;&#31995;&#32479;&#12289;&#33286;&#35770;&#12289;&#20915;&#31574;&#21644;&#31038;&#20250;&#20957;&#32858;&#21147;&#20135;&#29983;&#20102;&#36127;&#38754;&#24433;&#21709;&#12290;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;(NLP)&#20316;&#20026;&#19968;&#31181;&#35782;&#21035;&#20869;&#23481;&#30495;&#23454;&#24615;&#30340;&#22810;&#31181;&#26041;&#27861;&#65292;&#24050;&#32463;&#25104;&#20026;&#19982;&#34394;&#20551;&#20449;&#24687;&#20316;&#26007;&#20105;&#20013;&#30340;&#26377;&#21147;&#27494;&#22120;&#12290;&#26412;&#25991;&#28145;&#20837;&#25506;&#35752;&#20102;&#22914;&#20309;&#36816;&#29992;NLP&#25216;&#26415;&#26469;&#26816;&#27979;&#20551;&#26032;&#38395;&#65292;&#24182;&#25581;&#31034;&#20102;&#20854;&#20013;&#30340;&#25361;&#25112;&#21644;&#26426;&#36935;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Internet and social media have altered how individuals access news in the age of instantaneous information distribution. While this development has increased access to information, it has also created a significant problem: the spread of fake news and information. Fake news is rapidly spreading on digital platforms, which has a negative impact on the media ecosystem, public opinion, decision-making, and social cohesion. Natural Language Processing(NLP), which offers a variety of approaches to identify content as authentic, has emerged as a potent weapon in the growing war against disinformation. This paper takes an in-depth look at how NLP technology can be used to detect fake news and reveals the challenges and opportunities it presents.
&lt;/p&gt;</description></item><item><title>LM-Infinite&#30740;&#31350;&#20102;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#22312;&#38271;&#24207;&#21015;&#19978;&#30340;&#38271;&#24230;&#25512;&#24191;&#22833;&#36133;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#21363;&#26102;&#25512;&#24191;&#26041;&#27861;&#65292;&#20197;&#26356;&#39640;&#25928;&#22320;&#21033;&#29992;&#29616;&#26377;&#27169;&#22411;&#30340;&#29983;&#25104;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2308.16137</link><description>&lt;p&gt;
LM-Infinite: &#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#30340;&#31616;&#21333;&#21363;&#26102;&#38271;&#24230;&#25512;&#24191;
&lt;/p&gt;
&lt;p&gt;
LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models. (arXiv:2308.16137v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16137
&lt;/p&gt;
&lt;p&gt;
LM-Infinite&#30740;&#31350;&#20102;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#22312;&#38271;&#24207;&#21015;&#19978;&#30340;&#38271;&#24230;&#25512;&#24191;&#22833;&#36133;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#21363;&#26102;&#25512;&#24191;&#26041;&#27861;&#65292;&#20197;&#26356;&#39640;&#25928;&#22320;&#21033;&#29992;&#29616;&#26377;&#27169;&#22411;&#30340;&#29983;&#25104;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22312;Transformer-based&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#21508;&#20010;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#36827;&#23637;&#12290;&#38543;&#30528;&#36825;&#20123;LLM&#22312;&#36234;&#26469;&#36234;&#22797;&#26434;&#30340;&#20219;&#21153;&#19978;&#30340;&#37096;&#32626;&#65292;&#23427;&#20204;&#24448;&#24448;&#38754;&#20020;&#30528;&#23545;&#38271;&#26102;&#38388;&#25512;&#29702;&#36807;&#31243;&#25110;&#29702;&#35299;&#26356;&#22823;&#19978;&#19979;&#25991;&#30340;&#38656;&#27714;&#12290;&#22312;&#36825;&#20123;&#24773;&#20917;&#19979;&#65292;LLM&#22312;&#38271;&#24207;&#21015;&#19978;&#30340;&#38271;&#24230;&#25512;&#24191;&#22833;&#36133;&#21464;&#24471;&#26356;&#21152;&#31361;&#20986;&#12290;&#22823;&#22810;&#25968;&#39044;&#35757;&#32451;&#26041;&#26696;&#23558;&#35757;&#32451;&#24207;&#21015;&#25130;&#26029;&#21040;&#22266;&#23450;&#38271;&#24230;&#65288;&#20363;&#22914;LLaMa&#30340;2048&#65289;&#12290;&#21363;&#20351;&#20351;&#29992;&#20102;&#30456;&#23545;&#20301;&#32622;&#32534;&#30721;&#26469;&#24212;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;LLM&#22312;&#26356;&#38271;&#30340;&#19978;&#19979;&#25991;&#20043;&#21518;&#24448;&#24448;&#38590;&#20197;&#29983;&#25104;&#27969;&#30021;&#30340;&#25991;&#26412;&#65292;&#26356;&#19981;&#29992;&#35828;&#36827;&#34892;&#19979;&#28216;&#20219;&#21153;&#20102;&#12290;&#24120;&#35265;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#22914;&#22312;&#26356;&#38271;&#30340;&#35821;&#26009;&#24211;&#19978;&#36827;&#34892;&#24494;&#35843;&#65292;&#24448;&#24448;&#38656;&#35201;&#32791;&#36153;&#22823;&#37327;&#30340;&#30828;&#20214;&#21644;&#26102;&#38388;&#25104;&#26412;&#65292;&#24182;&#38656;&#35201;&#36827;&#34892;&#20180;&#32454;&#30340;&#35757;&#32451;&#36807;&#31243;&#35774;&#35745;&#12290;&#20026;&#20102;&#26356;&#39640;&#25928;&#22320;&#21033;&#29992;&#29616;&#26377;LLM&#30340;&#29983;&#25104;&#33021;&#21147;&#65292;&#25105;&#20204;&#22312;&#29702;&#35770;&#21644;&#23454;&#35777;&#19978;&#30740;&#31350;&#20102;&#20027;&#35201;&#30340;&#20998;&#24067;&#22806;(OOD) f
&lt;/p&gt;
&lt;p&gt;
In recent years, there have been remarkable advancements in the performance of Transformer-based Large Language Models (LLMs) across various domains. As these LLMs are deployed for increasingly complex tasks, they often face the needs to conduct longer reasoning processes or understanding larger contexts. In these situations, the length generalization failure of LLMs on long sequences become more prominent. Most pre-training schemes truncate training sequences to a fixed length (such as 2048 for LLaMa). LLMs often struggle to generate fluent texts, let alone carry out downstream tasks, after longer contexts, even with relative positional encoding which is designed to cope with this problem. Common solutions such as finetuning on longer corpora often involves daunting hardware and time costs and requires careful training process design. To more efficiently leverage the generation capacity of existing LLMs, we theoretically and empirically investigate the main out-of-distribution (OOD) f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35814;&#32454;&#30740;&#31350;&#20102;&#20197;&#20351;&#29992;&#21069;&#21021;&#22987;&#21270;&#38169;&#35823;&#20026;&#26696;&#20363;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36741;&#21161;&#38745;&#24577;&#20998;&#26512;&#30340;&#24320;&#25918;&#31354;&#38388;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#20840;&#33258;&#21160;&#20195;&#29702;&#31243;&#24207;LLift&#65292;&#35813;&#31243;&#24207;&#33021;&#22815;&#20811;&#26381;&#22810;&#20010;&#25361;&#25112;&#65292;&#21253;&#25324;&#38169;&#35823;&#24314;&#27169;&#12290;</title><link>http://arxiv.org/abs/2308.00245</link><description>&lt;p&gt;
&#31243;&#24207;&#20998;&#26512;&#25351;&#21335;&#65306;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20849;&#36827;&#20043;&#26053;
&lt;/p&gt;
&lt;p&gt;
The Hitchhiker's Guide to Program Analysis: A Journey with Large Language Models. (arXiv:2308.00245v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00245
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35814;&#32454;&#30740;&#31350;&#20102;&#20197;&#20351;&#29992;&#21069;&#21021;&#22987;&#21270;&#38169;&#35823;&#20026;&#26696;&#20363;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36741;&#21161;&#38745;&#24577;&#20998;&#26512;&#30340;&#24320;&#25918;&#31354;&#38388;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#20840;&#33258;&#21160;&#20195;&#29702;&#31243;&#24207;LLift&#65292;&#35813;&#31243;&#24207;&#33021;&#22815;&#20811;&#26381;&#22810;&#20010;&#25361;&#25112;&#65292;&#21253;&#25324;&#38169;&#35823;&#24314;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38745;&#24577;&#20998;&#26512;&#26159;&#36719;&#20214;&#24037;&#31243;&#20013;&#24191;&#27867;&#20351;&#29992;&#30340;&#19968;&#31181;&#25216;&#26415;&#65292;&#29992;&#20110;&#35782;&#21035;&#21644;&#20943;&#36731;&#38169;&#35823;&#12290;&#28982;&#32780;&#65292;&#22312;&#31934;&#30830;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#20043;&#38388;&#23454;&#29616;&#24494;&#22937;&#24179;&#34913;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#38556;&#30861;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#24076;&#26395;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#30001;&#20110;&#26368;&#36817;&#30340;&#36827;&#23637;&#22312;&#29702;&#35299;&#12289;&#29983;&#25104;&#29978;&#33267;&#35843;&#35797;&#20195;&#30721;&#26041;&#38754;&#23637;&#31034;&#20986;&#20102;&#26174;&#33879;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#38169;&#35823;&#30340;&#36923;&#36753;&#21487;&#33021;&#24456;&#22797;&#26434;&#65292;&#38656;&#35201;&#22797;&#26434;&#30340;&#25512;&#29702;&#21644;&#36328;&#22810;&#20010;&#20989;&#25968;&#30340;&#22823;&#33539;&#22260;&#20998;&#26512;&#12290;&#22240;&#27492;&#65292;&#22312;&#36825;&#19968;&#28857;&#19978;&#65292;LLM&#26356;&#36866;&#21512;&#22312;&#36741;&#21161;&#35282;&#33394;&#20013;&#19982;&#38745;&#24577;&#20998;&#26512;&#30456;&#34917;&#20805;&#20351;&#29992;&#12290;&#26412;&#25991;&#28145;&#20837;&#30740;&#31350;&#20102;&#20197;&#20351;&#29992;&#21069;&#21021;&#22987;&#21270;&#65288;UBI&#65289;&#38169;&#35823;&#20026;&#26696;&#20363;&#30740;&#31350;&#30340;LLM&#36741;&#21161;&#38745;&#24577;&#20998;&#26512;&#30340;&#24320;&#25918;&#31354;&#38388;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;LLift&#65292;&#19968;&#20010;&#23436;&#20840;&#33258;&#21160;&#21270;&#30340;&#20195;&#29702;&#31243;&#24207;&#65292;&#21487;&#20197;&#19982;&#38745;&#24577;&#20998;&#26512;&#24037;&#20855;&#21644;LLM&#36827;&#34892;&#20132;&#20114;&#12290;&#36890;&#36807;&#31934;&#24515;&#35774;&#35745;&#20195;&#29702;&#31243;&#24207;&#21644;&#25552;&#31034;&#65292;&#25105;&#20204;&#33021;&#22815;&#20811;&#26381;&#35768;&#22810;&#25361;&#25112;&#65292;&#21253;&#25324;&#38024;&#23545;&#20855;&#20307;&#38169;&#35823;&#30340;&#24314;&#27169;&#65292;
&lt;/p&gt;
&lt;p&gt;
Static analysis is a widely used technique in software engineering for identifying and mitigating bugs. However, a significant hurdle lies in achieving a delicate balance between precision and scalability. Large Language Models (LLMs) offer a promising alternative, as recent advances demonstrate remarkable capabilities in comprehending, generating, and even debugging code. Yet, the logic of bugs can be complex and require sophisticated reasoning and a large analysis scope spanning multiple functions. Therefore, at this point, LLMs are better used in an assistive role to complement static analysis. In this paper, we take a deep dive into the open space of LLM-assisted static analysis, using use-before-initialization (UBI) bugs as a case study. To this end, we develop LLift, a fully automated agent that interfaces with both a static analysis tool and an LLM. By carefully designing the agent and the prompts, we are able to overcome a number of challenges, including bug-specific modeling, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#26102;&#38388;&#24120;&#35782;&#25512;&#29702;&#39046;&#22495;&#30340;&#30740;&#31350;&#36827;&#23637;&#65292;&#37325;&#28857;&#20851;&#27880;&#36890;&#36807;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#30340;&#24615;&#33021;&#26469;&#25552;&#39640;&#25512;&#29702;&#33021;&#21147;&#65292;&#24182;&#23545;&#22810;&#20010;&#25968;&#25454;&#38598;&#36827;&#34892;&#35780;&#20272;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#22686;&#24378;&#27169;&#22411;&#20173;&#28982;&#38590;&#20197;&#36798;&#21040;&#20154;&#31867;&#27700;&#24179;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2308.00002</link><description>&lt;p&gt;
&#26102;&#38388;&#24120;&#35782;&#25512;&#29702;&#19982;&#33719;&#21462;&#27010;&#36848;
&lt;/p&gt;
&lt;p&gt;
An Overview Of Temporal Commonsense Reasoning and Acquisition. (arXiv:2308.00002v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00002
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#26102;&#38388;&#24120;&#35782;&#25512;&#29702;&#39046;&#22495;&#30340;&#30740;&#31350;&#36827;&#23637;&#65292;&#37325;&#28857;&#20851;&#27880;&#36890;&#36807;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#30340;&#24615;&#33021;&#26469;&#25552;&#39640;&#25512;&#29702;&#33021;&#21147;&#65292;&#24182;&#23545;&#22810;&#20010;&#25968;&#25454;&#38598;&#36827;&#34892;&#35780;&#20272;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#22686;&#24378;&#27169;&#22411;&#20173;&#28982;&#38590;&#20197;&#36798;&#21040;&#20154;&#31867;&#27700;&#24179;&#30340;&#25512;&#29702;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#24120;&#35782;&#25512;&#29702;&#26159;&#25351;&#29702;&#35299;&#30701;&#35821;&#12289;&#21160;&#20316;&#21644;&#20107;&#20214;&#30340;&#20856;&#22411;&#26102;&#38388;&#32972;&#26223;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#38656;&#35201;&#36825;&#31181;&#30693;&#35782;&#30340;&#38382;&#39064;&#25512;&#29702;&#30340;&#33021;&#21147;&#12290;&#36825;&#31181;&#33021;&#21147;&#22312;&#26102;&#38388;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#33267;&#20851;&#37325;&#35201;&#65292;&#21487;&#33021;&#24212;&#29992;&#20110;&#26102;&#38388;&#32447;&#25688;&#35201;&#12289;&#26102;&#38388;&#38382;&#31572;&#21644;&#26102;&#38388;&#33258;&#28982;&#35821;&#35328;&#25512;&#26029;&#31561;&#26041;&#38754;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#34429;&#28982;&#21892;&#20110;&#29983;&#25104;&#35821;&#27861;&#27491;&#30830;&#30340;&#21477;&#23376;&#21644;&#35299;&#20915;&#20998;&#31867;&#20219;&#21153;&#65292;&#20294;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#24448;&#24448;&#20250;&#37319;&#21462;&#25463;&#24452;&#65292;&#24182;&#38519;&#20837;&#31616;&#21333;&#30340;&#35821;&#35328;&#38519;&#38449;&#12290;&#26412;&#25991;&#31456;&#27010;&#36848;&#20102;&#22312;&#26102;&#38388;&#24120;&#35782;&#25512;&#29702;&#39046;&#22495;&#30340;&#30740;&#31350;&#65292;&#29305;&#21035;&#20851;&#27880;&#36890;&#36807;&#21508;&#31181;&#22686;&#24378;&#26041;&#24335;&#25552;&#39640;&#35821;&#35328;&#27169;&#22411;&#30340;&#24615;&#33021;&#20197;&#21450;&#23545;&#36234;&#26469;&#36234;&#22810;&#25968;&#25454;&#38598;&#30340;&#35780;&#20272;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#22686;&#24378;&#27169;&#22411;&#22312;&#25512;&#29702;&#20219;&#21153;&#19978;&#20173;&#28982;&#38590;&#20197;&#36798;&#21040;&#20154;&#31867;&#30340;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
Temporal commonsense reasoning refers to the ability to understand the typical temporal context of phrases, actions, and events, and use it to reason over problems requiring such knowledge. This trait is essential in temporal natural language processing tasks, with possible applications such as timeline summarization, temporal question answering, and temporal natural language inference. Recent research on the performance of large language models suggests that, although they are adept at generating syntactically correct sentences and solving classification tasks, they often take shortcuts in their reasoning and fall prey to simple linguistic traps. This article provides an overview of research in the domain of temporal commonsense reasoning, particularly focusing on enhancing language model performance through a variety of augmentations and their evaluation across a growing number of datasets. However, these augmented models still struggle to approach human performance on reasoning task
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;DP-SGD&#20998;&#26512;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#23545;&#35768;&#22810;&#25968;&#25454;&#28857;&#30340;&#38544;&#31169;&#27844;&#28431;&#36827;&#34892;&#26356;&#20934;&#30830;&#30340;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2307.00310</link><description>&lt;p&gt;
&#26799;&#24230;&#30456;&#20284;&#65306;&#25935;&#24863;&#24230;&#32463;&#24120;&#34987;&#36807;&#39640;&#20272;&#35745;&#22312;DP-SGD&#20013;
&lt;/p&gt;
&lt;p&gt;
Gradients Look Alike: Sensitivity is Often Overestimated in DP-SGD. (arXiv:2307.00310v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00310
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;DP-SGD&#20998;&#26512;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#23545;&#35768;&#22810;&#25968;&#25454;&#28857;&#30340;&#38544;&#31169;&#27844;&#28431;&#36827;&#34892;&#26356;&#20934;&#30830;&#30340;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;DP-SGD&#65289;&#26159;&#31169;&#26377;&#28145;&#24230;&#23398;&#20064;&#30340;&#26631;&#20934;&#31639;&#27861;&#12290;&#34429;&#28982;&#24050;&#30693;&#20854;&#38544;&#31169;&#20998;&#26512;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#26159;&#32039;&#23494;&#30340;&#65292;&#20294;&#26159;&#19968;&#20123;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#24120;&#35265;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#26102;&#65292;&#25152;&#24471;&#21040;&#30340;&#27169;&#22411;&#23545;&#35768;&#22810;&#25968;&#25454;&#28857;&#30340;&#38544;&#31169;&#27844;&#28431;&#26174;&#33879;&#20943;&#23569;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20026;DP-SGD&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#26041;&#27861;&#65292;&#25429;&#25417;&#21040;&#22312;&#25968;&#25454;&#38598;&#20013;&#20855;&#26377;&#30456;&#20284;&#37051;&#23621;&#30340;&#28857;&#20139;&#21463;&#26356;&#22909;&#38544;&#31169;&#24615;&#30340;&#30452;&#35273;&#12290;&#24418;&#24335;&#19978;&#26469;&#35828;&#65292;&#36825;&#26159;&#36890;&#36807;&#20462;&#25913;&#20174;&#35757;&#32451;&#25968;&#25454;&#38598;&#35745;&#31639;&#24471;&#21040;&#30340;&#27169;&#22411;&#26356;&#26032;&#30340;&#27599;&#27493;&#38544;&#31169;&#24615;&#20998;&#26512;&#26469;&#23454;&#29616;&#30340;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#30340;&#32452;&#21512;&#23450;&#29702;&#65292;&#20197;&#26377;&#25928;&#22320;&#21033;&#29992;&#36825;&#20010;&#26032;&#30340;&#27599;&#27493;&#20998;&#26512;&#26469;&#25512;&#29702;&#25972;&#20010;&#35757;&#32451;&#36807;&#31243;&#12290;&#24635;&#32780;&#35328;&#20043;&#65292;&#25105;&#20204;&#30340;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#31181;&#26032;&#39062;&#30340;DP-SGD&#20998;&#26512;&#20351;&#25105;&#20204;&#33021;&#22815;&#27491;&#24335;&#22320;&#26174;&#31034;DP-SGD&#23545;&#35768;&#22810;&#25968;&#25454;&#28857;&#30340;&#38544;&#31169;&#27844;&#28431;&#26174;&#33879;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differentially private stochastic gradient descent (DP-SGD) is the canonical algorithm for private deep learning. While it is known that its privacy analysis is tight in the worst-case, several empirical results suggest that when training on common benchmark datasets, the models obtained leak significantly less privacy for many datapoints. In this paper, we develop a new analysis for DP-SGD that captures the intuition that points with similar neighbors in the dataset enjoy better privacy than outliers. Formally, this is done by modifying the per-step privacy analysis of DP-SGD to introduce a dependence on the distribution of model updates computed from a training dataset. We further develop a new composition theorem to effectively use this new per-step analysis to reason about an entire training run. Put all together, our evaluation shows that this novel DP-SGD analysis allows us to now formally show that DP-SGD leaks significantly less privacy for many datapoints. In particular, we ob
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21160;&#24577;&#35821;&#26009;&#24211;&#19978;&#30340;&#29983;&#25104;&#26816;&#32034;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#38745;&#24577;&#35774;&#32622;&#19979;&#65292;&#29983;&#25104;&#26816;&#32034;&#25928;&#26524;&#20248;&#20110;&#21452;&#32534;&#30721;&#22120;&#65292;&#20294;&#22312;&#21160;&#24577;&#35774;&#32622;&#19979;&#24773;&#20917;&#30456;&#21453;&#12290;&#36890;&#36807;&#20351;&#29992;&#21442;&#25968;&#39640;&#25928;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;DynamicGR&#22312;&#26032;&#30340;&#35821;&#26009;&#24211;&#19978;&#23637;&#29616;&#20986;&#20102;&#24847;&#22806;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.18952</link><description>&lt;p&gt;
&#22312;&#21160;&#24577;&#35821;&#26009;&#24211;&#19978;&#25345;&#32493;&#26356;&#26032;&#29983;&#25104;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
Continually Updating Generative Retrieval on Dynamic Corpora. (arXiv:2305.18952v2 [cs.IR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18952
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21160;&#24577;&#35821;&#26009;&#24211;&#19978;&#30340;&#29983;&#25104;&#26816;&#32034;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#38745;&#24577;&#35774;&#32622;&#19979;&#65292;&#29983;&#25104;&#26816;&#32034;&#25928;&#26524;&#20248;&#20110;&#21452;&#32534;&#30721;&#22120;&#65292;&#20294;&#22312;&#21160;&#24577;&#35774;&#32622;&#19979;&#24773;&#20917;&#30456;&#21453;&#12290;&#36890;&#36807;&#20351;&#29992;&#21442;&#25968;&#39640;&#25928;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;DynamicGR&#22312;&#26032;&#30340;&#35821;&#26009;&#24211;&#19978;&#23637;&#29616;&#20986;&#20102;&#24847;&#22806;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#20851;&#20110;&#20449;&#24687;&#26816;&#32034;(IR)&#30340;&#22823;&#22810;&#25968;&#30740;&#31350;&#20551;&#35774;&#35821;&#26009;&#24211;&#26159;&#38745;&#24577;&#30340;&#65292;&#32780;&#23454;&#38469;&#19990;&#30028;&#20013;&#30340;&#25991;&#26723;&#26159;&#19981;&#26029;&#26356;&#26032;&#30340;&#12290;&#26412;&#25991;&#23558;&#30693;&#35782;&#30340;&#21160;&#24577;&#24615;&#24341;&#20837;&#26816;&#32034;&#31995;&#32479;&#20013;&#65292;&#23558;&#26816;&#32034;&#35270;&#20026;&#21160;&#24577;&#30340;&#30693;&#35782;&#24211;&#65292;&#26356;&#31526;&#21512;&#30495;&#23454;&#29615;&#22659;&#12290;&#25105;&#20204;&#23545;&#21452;&#32534;&#30721;&#22120;&#21644;&#29983;&#25104;&#26816;&#32034;&#36827;&#34892;&#20840;&#38754;&#35780;&#20272;&#65292;&#21033;&#29992;StreamingQA&#22522;&#20934;&#27979;&#35797;&#29992;&#20110;&#26102;&#24577;&#30693;&#35782;&#26356;&#26032;&#12290;&#25105;&#20204;&#30340;&#21021;&#27493;&#32467;&#26524;&#26174;&#31034;&#65292;&#22312;&#38745;&#24577;&#35774;&#32622;&#19979;&#65292;&#29983;&#25104;&#26816;&#32034;&#20248;&#20110;&#21452;&#32534;&#30721;&#22120;&#65292;&#20294;&#22312;&#21160;&#24577;&#35774;&#32622;&#19979;&#24773;&#20917;&#30456;&#21453;&#12290;&#28982;&#32780;&#65292;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#24403;&#25105;&#20204;&#21033;&#29992;&#21442;&#25968;&#39640;&#25928;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#22686;&#24378;&#29983;&#25104;&#26816;&#32034;&#23545;&#26032;&#35821;&#26009;&#24211;&#30340;&#36866;&#24212;&#24615;&#26102;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;Dynamic Generative Retrieval (DynamicGR)&#23637;&#29616;&#20986;&#24847;&#22806;&#30340;&#21457;&#29616;&#12290;&#23427;&#33021;&#22815;&#22312;&#20854;&#20869;&#37096;&#32034;&#24341;&#20013;&#39640;&#25928;&#21387;&#32553;&#26032;&#30340;&#30693;&#35782;&#65292;
&lt;/p&gt;
&lt;p&gt;
The majority of prior work on information retrieval (IR) assumes that the corpus is static, whereas in the real world, the documents are continually updated. In this paper, we incorporate often overlooked dynamic nature of knowledge into the retrieval systems. Our work treats retrieval not as static archives but as dynamic knowledge bases better aligned with real-world environments. We conduct a comprehensive evaluation of dual encoders and generative retrieval, utilizing the StreamingQA benchmark designed for the temporal knowledge updates. Our initial results show that while generative retrieval outperforms dual encoders in static settings, the opposite is true in dynamic settings. Surprisingly, however, when we utilize a parameter-efficient pre-training method to enhance adaptability of generative retrieval to new corpora, our resulting model, Dynamic Generative Retrieval (DynamicGR), exhibits unexpected findings. It (1) efficiently compresses new knowledge in their internal index, 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22788;&#29702;&#21644;&#29983;&#25104;&#38463;&#25289;&#20271;&#25991;&#26412;&#26102;&#20986;&#29616;&#30340;&#25991;&#21270;&#20559;&#21521;&#35199;&#26041;&#25991;&#21270;&#30340;&#29616;&#35937;&#65292;&#34920;&#26126;&#35821;&#35328;&#27169;&#22411;&#22312;&#20154;&#21517;&#12289;&#39135;&#21697;&#12289;&#26381;&#35013;&#12289;&#22320;&#28857;&#12289;&#25991;&#23398;&#12289;&#39278;&#26009;&#12289;&#23447;&#25945;&#21644;&#20307;&#32946;&#31561;&#20843;&#20010;&#25991;&#21270;&#26041;&#38754;&#23384;&#22312;&#20559;&#35265;&#12290;&#36825;&#20123;&#21457;&#29616;&#24341;&#21457;&#23545;&#20110;&#24403;&#21069;&#35821;&#35328;&#27169;&#22411;&#25991;&#21270;&#30456;&#20851;&#24615;&#30340;&#25285;&#24551;&#12290;</title><link>http://arxiv.org/abs/2305.14456</link><description>&lt;p&gt;
&#22312;&#31048;&#31095;&#20043;&#21518;&#21917;&#21860;&#37202;&#65311;&#27979;&#37327;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#25991;&#21270;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
Having Beer after Prayer? Measuring Cultural Bias in Large Language Models. (arXiv:2305.14456v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14456
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#22788;&#29702;&#21644;&#29983;&#25104;&#38463;&#25289;&#20271;&#25991;&#26412;&#26102;&#20986;&#29616;&#30340;&#25991;&#21270;&#20559;&#21521;&#35199;&#26041;&#25991;&#21270;&#30340;&#29616;&#35937;&#65292;&#34920;&#26126;&#35821;&#35328;&#27169;&#22411;&#22312;&#20154;&#21517;&#12289;&#39135;&#21697;&#12289;&#26381;&#35013;&#12289;&#22320;&#28857;&#12289;&#25991;&#23398;&#12289;&#39278;&#26009;&#12289;&#23447;&#25945;&#21644;&#20307;&#32946;&#31561;&#20843;&#20010;&#25991;&#21270;&#26041;&#38754;&#23384;&#22312;&#20559;&#35265;&#12290;&#36825;&#20123;&#21457;&#29616;&#24341;&#21457;&#23545;&#20110;&#24403;&#21069;&#35821;&#35328;&#27169;&#22411;&#25991;&#21270;&#30456;&#20851;&#24615;&#30340;&#25285;&#24551;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#23384;&#22312;&#25991;&#21270;&#20559;&#35265;&#65311;&#35821;&#35328;&#27169;&#22411;&#31526;&#21512;&#25152;&#26381;&#21153;&#31038;&#21306;&#30340;&#25991;&#21270;&#22240;&#32032;&#24456;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#26412;&#25991;&#34920;&#26126;&#22312;&#22788;&#29702;&#21644;&#29983;&#25104;&#38463;&#25289;&#20271;&#25991;&#26412;&#26102;&#65292;&#35821;&#35328;&#27169;&#22411;&#23384;&#22312;&#26174;&#33879;&#30340;&#20559;&#21521;&#35199;&#26041;&#25991;&#21270;&#30340;&#20559;&#35265;&#65292;&#20542;&#21521;&#20110;&#20135;&#29983;&#35199;&#26041;&#25991;&#21270;&#30456;&#20851;&#20869;&#23481;&#32780;&#38750;&#38463;&#25289;&#20271;&#25991;&#21270;&#30456;&#20851;&#20869;&#23481;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#20174;&#22312;&#32447;&#31038;&#20132;&#23186;&#20307;&#19978;&#25910;&#38598;&#30340;&#33258;&#28982;&#20986;&#29616;&#30340;&#19978;&#19979;&#25991;&#21644;&#22522;&#20110;&#21487;&#33021;&#24615;&#35780;&#20998;&#30340;&#25351;&#26631;&#26469;&#37327;&#21270;&#36825;&#31181;&#20559;&#35265;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#26174;&#31034;&#65292;&#38463;&#25289;&#20271;&#35821;&#21333;&#35821;&#21644;&#22810;&#35821;&#27169;&#22411;&#22312;&#20843;&#20010;&#19981;&#21516;&#30340;&#25991;&#21270;&#26041;&#38754;&#23384;&#22312;&#35199;&#26041;&#25991;&#21270;&#20559;&#35265;&#65292;&#21253;&#25324;&#20154;&#21517;&#12289;&#39135;&#21697;&#12289;&#26381;&#35013;&#12289;&#22320;&#28857;&#12289;&#25991;&#23398;&#12289;&#39278;&#26009;&#12289;&#23447;&#25945;&#21644;&#20307;&#32946;&#12290;&#24403;&#36755;&#20837;&#30340;&#38463;&#25289;&#20271;&#35821;&#21477;&#23376;&#36234;&#25509;&#36817;&#33521;&#35821;&#26102;&#65292;&#27169;&#22411;&#20063;&#26356;&#23481;&#26131;&#34920;&#29616;&#20986;&#20559;&#35265;&#12290;&#36825;&#20123;&#21457;&#29616;&#24341;&#21457;&#20154;&#20204;&#23545;&#24403;&#21069;&#35821;&#35328;&#27169;&#22411;&#25991;&#21270;&#30456;&#20851;&#24615;&#30340;&#25285;&#24551;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#22312;&#27169;&#22411;&#35774;&#35745;&#20013;&#24212;&#26356;&#22810;&#32771;&#34385;&#25991;&#21270;&#22240;&#32032;&#21644;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Are language models culturally biased? It is important that language models conform to the cultural aspects of the communities they serve. However, we show in this paper that language models suffer from a significant bias towards Western culture when handling and generating text in Arabic, often preferring, and producing Western-fitting content as opposed to the relevant Arab content. We quantify this bias through a likelihood scoring-based metric using naturally occurring contexts that we collect from online social media. Our experiments reveal that both Arabic monolingual and multilingual models exhibit bias towards Western culture in eight different cultural aspects: person names, food, clothing, location, literature, beverage, religion, and sports. Models also tend to exhibit more bias when prompted with Arabic sentences that are more linguistically aligned with English. These findings raise concerns about the cultural relevance of current language models. Our analyses show that pr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#22522;&#20110;&#33021;&#25928;&#38543;&#24577;&#30005;&#23481;&#22120;&#30340;&#29289;&#29702;&#20648;&#23618;&#35745;&#31639;&#31995;&#32479;&#65292;&#35299;&#20915;&#20102;&#26102;&#38388;&#25968;&#25454;&#30340;&#20998;&#31867;&#20219;&#21153;&#21644;&#20998;&#26512;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#31995;&#32479;&#33021;&#22815;&#23454;&#29616;&#36739;&#39640;&#30340;&#20934;&#30830;&#29575;&#21644;&#36739;&#23567;&#30340;&#22343;&#26041;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2305.12025</link><description>&lt;p&gt;
&#22522;&#20110;&#33021;&#25928;&#38543;&#24577;&#30005;&#23481;&#22120;&#30340;&#29289;&#29702;&#20648;&#23618;&#35745;&#31639;&#31995;&#32479;&#29992;&#20110;&#26102;&#38388;&#25968;&#25454;&#22788;&#29702;
&lt;/p&gt;
&lt;p&gt;
Energy-efficient memcapacitive physical reservoir computing system for temporal data processing. (arXiv:2305.12025v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12025
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#22522;&#20110;&#33021;&#25928;&#38543;&#24577;&#30005;&#23481;&#22120;&#30340;&#29289;&#29702;&#20648;&#23618;&#35745;&#31639;&#31995;&#32479;&#65292;&#35299;&#20915;&#20102;&#26102;&#38388;&#25968;&#25454;&#30340;&#20998;&#31867;&#20219;&#21153;&#21644;&#20998;&#26512;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#31995;&#32479;&#33021;&#22815;&#23454;&#29616;&#36739;&#39640;&#30340;&#20934;&#30830;&#29575;&#21644;&#36739;&#23567;&#30340;&#22343;&#26041;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20648;&#23618;&#35745;&#31639;&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#20174;&#36755;&#20837;&#20449;&#21495;&#20013;&#25552;&#21462;&#29305;&#24449;&#24182;&#23558;&#20854;&#26144;&#23556;&#21040;&#39640;&#32500;&#31354;&#38388;&#26469;&#22788;&#29702;&#26102;&#38388;&#25968;&#25454;&#12290;&#29289;&#29702;&#20648;&#23618;&#21487;&#20351;&#29992;&#30913;&#26059;&#30005;&#23376;&#12289;&#21407;&#23376;&#24320;&#20851;&#32593;&#32476;&#12289;&#30789;&#20809;&#23398;&#27169;&#22359;&#12289;&#38081;&#30005;&#26230;&#20307;&#31649;&#21644;&#26131;&#22833;&#24615;&#23384;&#20648;&#22120;&#26469;&#23454;&#29616;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#35774;&#22791;&#30001;&#20110;&#20854;&#30005;&#38459;&#24615;&#36136;&#26412;&#36136;&#19978;&#23384;&#22312;&#33021;&#37327;&#32791;&#25955;&#38382;&#39064;&#65292;&#23548;&#33268;&#21151;&#32791;&#22686;&#21152;&#12290;&#22240;&#27492;&#65292;&#37319;&#29992;&#30005;&#23481;&#23384;&#20648;&#22120;&#35774;&#22791;&#21487;&#25552;&#20379;&#26356;&#20026;&#33021;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#21033;&#29992;&#27169;&#25311;&#21644;&#23454;&#39564;&#20013;&#36817;&#20284;&#26576;&#20123;&#30701;&#26399;&#31361;&#35302;&#21487;&#22609;&#24615;&#21151;&#33021;&#30340;&#26131;&#22833;&#29983;&#29289;&#33180;&#22522;&#36136;&#37327;&#20316;&#20026;&#20648;&#23618;&#65292;&#35299;&#20915;&#20998;&#31867;&#20219;&#21153;&#21644;&#20998;&#26512;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#12290;&#25105;&#20204;&#30340;&#31995;&#32479;&#22312;&#21475;&#38899;&#25968;&#23383;&#20998;&#31867;&#20013;&#23454;&#29616;&#20102;98&#65285;&#30340;&#20934;&#30830;&#29575;&#65292;&#22312;&#20108;&#38454;&#38750;&#32447;&#24615;&#22238;&#24402;&#20219;&#21153;&#20013;&#33719;&#24471;&#20102;0.0012&#30340;&#24402;&#19968;&#21270;&#22343;&#26041;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reservoir computing is a highly efficient machine learning framework for processing temporal data by extracting features from the input signal and mapping them into higher dimensional spaces. Physical reservoir layers have been realized using spintronic oscillators, atomic switch networks, silicon photonic modules, ferroelectric transistors, and volatile memristors. However, these devices are intrinsically energy-dissipative due to their resistive nature, which leads to increased power consumption. Therefore, capacitive memory devices can provide a more energy-efficient approach. Here, we leverage volatile biomembrane-based memcapacitors that closely mimic certain short-term synaptic plasticity functions as reservoirs to solve classification tasks and analyze time-series data in simulation and experimentally. Our system achieves a 98% accuracy rate for spoken digit classification and a normalized mean square error of 0.0012 in a second-order non-linear regression task. Further, to demo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#39044;&#27979;&#21333;&#20010;&#26631;&#27880;&#32773;&#30340;&#25171;&#20998;&#65292;&#24182;&#32467;&#21512;&#25991;&#26412;&#30446;&#26631;&#32676;&#20307;&#30340;&#39044;&#27979;&#65292;&#27169;&#25311;&#20102;&#30446;&#26631;&#32676;&#20307;&#25104;&#21592;&#30340;&#24847;&#35265;&#65292;&#36890;&#36807;&#20351;&#29992;&#20182;&#20204;&#30340;&#20154;&#21475;&#32479;&#35745;&#23398;&#25968;&#25454;&#21644;&#22312;&#32447;&#24847;&#35265;&#39044;&#27979;&#26631;&#27880;&#32773;&#30340;&#25171;&#20998;&#65292;&#22312;&#20167;&#24680;&#35328;&#35770;&#26816;&#27979;&#31561;&#20027;&#35266;&#20219;&#21153;&#20013;&#25552;&#39640;&#20102;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.06626</link><description>&lt;p&gt;
&#24403;&#22810;&#25968;&#20154;&#26159;&#38169;&#35823;&#30340;&#65306;&#21033;&#29992;&#26631;&#27880;&#32773;&#19981;&#19968;&#33268;&#24615;&#36827;&#34892;&#20027;&#35266;&#20219;&#21153;
&lt;/p&gt;
&lt;p&gt;
When the Majority is Wrong: Leveraging Annotator Disagreement for Subjective Tasks. (arXiv:2305.06626v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06626
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#39044;&#27979;&#21333;&#20010;&#26631;&#27880;&#32773;&#30340;&#25171;&#20998;&#65292;&#24182;&#32467;&#21512;&#25991;&#26412;&#30446;&#26631;&#32676;&#20307;&#30340;&#39044;&#27979;&#65292;&#27169;&#25311;&#20102;&#30446;&#26631;&#32676;&#20307;&#25104;&#21592;&#30340;&#24847;&#35265;&#65292;&#36890;&#36807;&#20351;&#29992;&#20182;&#20204;&#30340;&#20154;&#21475;&#32479;&#35745;&#23398;&#25968;&#25454;&#21644;&#22312;&#32447;&#24847;&#35265;&#39044;&#27979;&#26631;&#27880;&#32773;&#30340;&#25171;&#20998;&#65292;&#22312;&#20167;&#24680;&#35328;&#35770;&#26816;&#27979;&#31561;&#20027;&#35266;&#20219;&#21153;&#20013;&#25552;&#39640;&#20102;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#65292;&#34429;&#28982;&#36890;&#24120;&#20351;&#29992;&#26631;&#27880;&#32773;&#30340;&#22810;&#25968;&#25237;&#31080;&#26469;&#30830;&#23450;&#26631;&#31614;&#65292;&#20294;&#22312;&#20167;&#24680;&#35328;&#35770;&#26816;&#27979;&#31561;&#20027;&#35266;&#20219;&#21153;&#20013;&#65292;&#26631;&#27880;&#32773;&#20043;&#38388;&#23384;&#22312;&#19981;&#19968;&#33268;&#24615;&#21487;&#33021;&#21453;&#26144;&#20986;&#32676;&#20307;&#35266;&#28857;&#30340;&#24046;&#24322;&#65292;&#32780;&#19981;&#26159;&#22122;&#22768;&#12290;&#22240;&#27492;&#65292;&#20167;&#24680;&#35328;&#35770;&#26816;&#27979;&#30340;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#26159;&#19968;&#20010;&#35821;&#21477;&#26159;&#21542;&#20882;&#29359;&#20102;&#23427;&#25152;&#38024;&#23545;&#30340;&#20154;&#32676;&#65292;&#32780;&#36825;&#21487;&#33021;&#21482;&#21344;&#26631;&#27880;&#32773;&#27744;&#30340;&#19968;&#23567;&#37096;&#20998;&#12290;&#26412;&#25991;&#26500;&#24314;&#20102;&#19968;&#20010;&#27169;&#22411;&#65292;&#39044;&#27979;&#21487;&#33021;&#20855;&#26377;&#20882;&#29359;&#24615;&#25991;&#26412;&#19978;&#27599;&#20010;&#26631;&#27880;&#32773;&#30340;&#25171;&#20998;&#65292;&#24182;&#32467;&#21512;&#25991;&#26412;&#30340;&#39044;&#27979;&#30446;&#26631;&#32676;&#20307;&#26469;&#27169;&#25311;&#30446;&#26631;&#32676;&#20307;&#25104;&#21592;&#30340;&#24847;&#35265;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31995;&#21015;&#30340;&#35780;&#20272;&#25351;&#26631;&#65292;&#21253;&#25324;&#25552;&#39640;&#20102;22&#65285;&#22312;&#39044;&#27979;&#27599;&#20010;&#26631;&#27880;&#32773;&#30340;&#25171;&#20998;&#19978;&#30340;&#24615;&#33021;&#65292;&#25552;&#39640;&#20102;33&#65285;&#22312;&#39044;&#27979;&#26631;&#27880;&#32773;&#20043;&#38388;&#26041;&#24046;&#19978;&#30340;&#24615;&#33021;&#65292;&#36825;&#25552;&#20379;&#20102;&#19979;&#28216;&#29992;&#26469;&#34913;&#37327;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#21457;&#29616;&#21487;&#20197;&#20351;&#29992;&#26631;&#27880;&#32773;&#30340;&#20154;&#21475;&#32479;&#35745;&#20449;&#24687;&#21644;&#20854;&#22312;&#32447;&#24847;&#35265;&#26469;&#39044;&#27979;&#26631;&#27880;&#32773;&#30340;&#25171;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
Though majority vote among annotators is typically used for ground truth labels in natural language processing, annotator disagreement in tasks such as hate speech detection may reflect differences among group opinions, not noise. Thus, a crucial problem in hate speech detection is whether a statement is offensive to the demographic group that it targets, which may constitute a small fraction of the annotator pool. We construct a model that predicts individual annotator ratings on potentially offensive text and combines this information with the predicted target group of the text to model the opinions of target group members. We show gains across a range of metrics, including raising performance over the baseline by 22% at predicting individual annotators' ratings and 33% at predicting variance among annotators, which provides a method of measuring model uncertainty downstream. We find that annotators' ratings can be predicted using their demographic information and opinions on online 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#31350;&#20102;&#22522;&#20110;LLMs&#27169;&#25311;&#20195;&#29702;&#30340;&#34892;&#20026;&#65292;&#31216;&#20043;&#20026;LLM Personas&#65292;&#22312;&#20998;&#37197;&#22823;&#20116;&#20154;&#26684;&#31867;&#22411;&#21644;&#24615;&#21035;&#35282;&#33394;&#26102;&#26159;&#21542;&#21487;&#20197;&#29983;&#25104;&#20855;&#26377;&#19968;&#33268;&#24615;&#30340;&#20010;&#24615;&#21270;&#29305;&#36136;&#30340;&#20869;&#23481;&#12290;</title><link>http://arxiv.org/abs/2305.02547</link><description>&lt;p&gt;
PersonaLLM: &#25506;&#31350;GPT-3.5&#34920;&#36798;&#20010;&#24615;&#29305;&#24449;&#21644;&#24615;&#21035;&#24046;&#24322;&#30340;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
PersonaLLM: Investigating the Ability of GPT-3.5 to Express Personality Traits and Gender Differences. (arXiv:2305.02547v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02547
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#31350;&#20102;&#22522;&#20110;LLMs&#27169;&#25311;&#20195;&#29702;&#30340;&#34892;&#20026;&#65292;&#31216;&#20043;&#20026;LLM Personas&#65292;&#22312;&#20998;&#37197;&#22823;&#20116;&#20154;&#26684;&#31867;&#22411;&#21644;&#24615;&#21035;&#35282;&#33394;&#26102;&#26159;&#21542;&#21487;&#20197;&#29983;&#25104;&#20855;&#26377;&#19968;&#33268;&#24615;&#30340;&#20010;&#24615;&#21270;&#29305;&#36136;&#30340;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#21508;&#20010;&#34892;&#19994;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#35774;&#35745;&#20013;&#26377;&#35768;&#22810;&#29992;&#36884;&#65292;&#24182;&#19988;&#30740;&#31350;&#34920;&#26126;&#20010;&#24615;&#21270;&#32842;&#22825;&#26426;&#22120;&#20154;&#22312;&#28385;&#36275;&#19981;&#21516;&#20154;&#26684;&#29305;&#24449;&#26041;&#38754;&#30340;&#37325;&#35201;&#24615;&#65292;&#20294;&#24456;&#23569;&#26377;&#30740;&#31350;&#35780;&#20272;&#20010;&#24615;&#21270;LLM&#30340;&#34892;&#20026;&#26159;&#21542;&#33021;&#22815;&#20934;&#30830;&#12289;&#19968;&#33268;&#22320;&#21453;&#26144;&#26576;&#20123;&#20154;&#26684;&#29305;&#24449;&#12290;&#25105;&#20204;&#32771;&#34385;&#30740;&#31350;&#22522;&#20110;LLM&#30340;&#27169;&#25311;&#20195;&#29702;&#30340;&#34892;&#20026;&#65292;&#31216;&#20043;&#20026;LLM personas&#65292;&#24182;&#20351;&#29992;GPT-3.5&#65288;text-davinci-003&#65289;&#36827;&#34892;&#26696;&#20363;&#30740;&#31350;&#65292;&#20197;&#30740;&#31350;LLM&#22312;&#20998;&#37197;&#22823;&#20116;&#20154;&#26684;&#31867;&#22411;&#21644;&#24615;&#21035;&#35282;&#33394;&#26102;&#26159;&#21542;&#21487;&#20197;&#29983;&#25104;&#20855;&#26377;&#19968;&#33268;&#24615;&#30340;&#20010;&#24615;&#21270;&#29305;&#36136;&#30340;&#20869;&#23481;&#12290;&#25105;&#20204;&#21019;&#24314;&#20102;320&#20010;LLM personas&#65288;&#27599;&#31181;&#22823;&#20116;&#20154;&#26684;&#31867;&#22411;&#26377;5&#20010;&#22899;&#24615;&#21644;5&#20010;&#30007;&#24615;&#65289;&#65292;&#24182;&#25552;&#31034;&#20182;&#20204;&#23436;&#25104;&#32463;&#20856;&#30340;44&#39033;&#22823;&#20116;&#20154;&#26684;&#38382;&#21367;&#65288;BFI&#65289;&#65292;&#28982;&#21518;&#25776;&#20889;&#19968;&#20010;&#20851;&#20110;&#20182;&#20204;&#31461;&#24180;&#30340;800&#23383;&#25925;&#20107;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;LLM personas&#30340;&#33258;&#25105;&#25253;&#21578;&#30340;BFI&#20998;&#25968;&#19982;&#20182;&#20204;&#20998;&#37197;&#30340;&#20154;&#26684;&#31867;&#22411;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the many use cases for large language models (LLMs) in the design of chatbots in various industries and the research showing the importance of personalizing chatbots to cater to different personality traits, little work has been done to evaluate whether the behaviors of personalized LLMs can reflect certain personality traits accurately and consistently. We consider studying the behavior of LLM-based simulated agents which refer to as LLM personas and present a case study with GPT-3.5 (text-davinci-003) to investigate whether LLMs can generate content with consistent, personalized traits when assigned Big Five personality types and gender roles. We created 320 LLM personas (5 females and 5 males for each of the 32 Big Five personality types) and prompted them to complete the classic 44-item Big Five Inventory (BFI) and then write an 800-word story about their childhood. Results showed that LLM personas' self-reported BFI scores are consistent with their assigned personality typ
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#33258;&#22238;&#24402;&#25991;&#26412;&#29983;&#25104;&#20013;&#20351;&#29992;&#21487;&#25805;&#20316;&#27010;&#29575;&#27169;&#22411;&#26469;&#24378;&#21046;&#23454;&#26045;&#38480;&#21046;&#30340;&#25511;&#21046;&#26041;&#27861;GeLaTo&#65292;&#24182;&#21462;&#24471;&#20102;&#22312;&#24120;&#35265;&#30340;&#32422;&#26463;&#25991;&#26412;&#29983;&#25104;&#27979;&#35797;&#19978;&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.07438</link><description>&lt;p&gt;
&#21487;&#25805;&#20316;&#30340;&#33258;&#22238;&#24402;&#35821;&#35328;&#29983;&#25104;&#25511;&#21046;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Tractable Control for Autoregressive Language Generation. (arXiv:2304.07438v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07438
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#33258;&#22238;&#24402;&#25991;&#26412;&#29983;&#25104;&#20013;&#20351;&#29992;&#21487;&#25805;&#20316;&#27010;&#29575;&#27169;&#22411;&#26469;&#24378;&#21046;&#23454;&#26045;&#38480;&#21046;&#30340;&#25511;&#21046;&#26041;&#27861;GeLaTo&#65292;&#24182;&#21462;&#24471;&#20102;&#22312;&#24120;&#35265;&#30340;&#32422;&#26463;&#25991;&#26412;&#29983;&#25104;&#27979;&#35797;&#19978;&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#33258;&#22238;&#24402;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#25991;&#26412;&#29983;&#25104;&#26041;&#38754;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#29983;&#25104;&#28385;&#36275;&#22797;&#26434;&#38480;&#21046;&#30340;&#25991;&#26412;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#65306;&#21363;&#20351;&#26159;&#26368;&#31616;&#21333;&#30340;&#35789;&#27719;&#38480;&#21046;&#20063;&#20351;&#26465;&#20214;&#20998;&#24067;$\Pr(\text{text} | \alpha)$&#30340;&#37319;&#26679;&#21464;&#24471;&#19981;&#21487;&#35745;&#31639;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#21487;&#25805;&#20316;&#30340;&#27010;&#29575;&#27169;&#22411;&#23558;&#35789;&#27719;&#38480;&#21046;&#24378;&#21152;&#20110;&#33258;&#22238;&#24402;&#25991;&#26412;&#29983;&#25104;&#20013;&#65292;&#25105;&#20204;&#23558;&#20854;&#31216;&#20026; GeLaTo&#12290;&#20026;&#20102;&#35777;&#26126;&#36825;&#20010;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#31934;&#31616;&#30340;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#26469;&#25511;&#21046;&#20174;GPT2&#21040;&#33258;&#22238;&#24402;&#30340;&#29983;&#25104;&#12290;GeLaTo&#22312;&#32422;&#26463;&#25991;&#26412;&#29983;&#25104;&#30340;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22522;&#20934;&#27979;&#35797;CommonGen&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#22823;&#24133;&#20987;&#36133;&#20102;&#21508;&#31181;&#24378;&#22522;&#32447;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#19981;&#20165;&#20026;&#25511;&#21046;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24320;&#36767;&#20102;&#26032;&#30340;&#36884;&#24452;&#65292;&#36824;&#28608;&#21169;&#20154;&#20204;&#24320;&#21457;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;&#21487;&#25805;&#20316;&#27010;&#29575;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the success of autoregressive large language models in text generation, it remains a major challenge to generate text that satisfies complex constraints: sampling from the conditional distribution $\Pr(\text{text} | \alpha)$ is intractable for even the simplest lexical constraints $\alpha$. To overcome this challenge, we propose to use tractable probabilistic models to impose lexical constraints in autoregressive text generation, which we refer to as GeLaTo. To demonstrate the effectiveness of this framework, we use distilled hidden Markov models to control autoregressive generation from GPT2. GeLaTo achieves state-of-the-art performance on CommonGen, a challenging benchmark for constrained text generation, beating a wide range of strong baselines by a large margin. Our work not only opens up new avenues for controlling large language models but also motivates the development of more expressive tractable probabilistic models.
&lt;/p&gt;</description></item><item><title>EvoPrompting&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#33258;&#36866;&#24212;&#21464;&#24322;&#21644;&#20132;&#21449;&#25805;&#20316;&#31526;&#26469;&#36827;&#34892;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#65292;&#22312;MNIST-1D&#25968;&#25454;&#38598;&#21644;CLRS&#31639;&#27861;&#25512;&#29702;&#22522;&#20934;&#19978;&#37117;&#21462;&#24471;&#20102;&#27604;&#20154;&#31867;&#35774;&#35745;&#30340;&#26550;&#26500;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2302.14838</link><description>&lt;p&gt;
EvoPrompting: &#36866;&#29992;&#20110;&#20195;&#30721;&#32423;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#30340;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
EvoPrompting: Language Models for Code-Level Neural Architecture Search. (arXiv:2302.14838v1 [cs.NE] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.14838
&lt;/p&gt;
&lt;p&gt;
EvoPrompting&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#33258;&#36866;&#24212;&#21464;&#24322;&#21644;&#20132;&#21449;&#25805;&#20316;&#31526;&#26469;&#36827;&#34892;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#65292;&#22312;MNIST-1D&#25968;&#25454;&#38598;&#21644;CLRS&#31639;&#27861;&#25512;&#29702;&#22522;&#20934;&#19978;&#37117;&#21462;&#24471;&#20102;&#27604;&#20154;&#31867;&#35774;&#35745;&#30340;&#26550;&#26500;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#35821;&#35328;&#27169;&#22411;&#65288;LM&#65289;&#22312;&#20195;&#30721;&#29983;&#25104;&#26041;&#38754;&#30340;&#26368;&#26032;&#25104;&#23601;&#65292;&#25105;&#20204;&#25506;&#32034;&#23558;LM&#20316;&#20026;&#36827;&#21270;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#65288;NAS&#65289;&#31639;&#27861;&#30340;&#33258;&#36866;&#24212;&#21464;&#24322;&#21644;&#20132;&#21449;&#25805;&#20316;&#31526;&#30340;&#20351;&#29992;&#12290;&#23613;&#31649;NAS&#20173;&#28982;&#36807;&#20110;&#22256;&#38590;&#65292;&#20197;&#33267;&#20110;&#20165;&#20165;&#36890;&#36807;&#25552;&#31034;&#23601;&#38590;&#20197;&#25104;&#21151;&#65292;&#20294;&#25105;&#20204;&#21457;&#29616;&#36827;&#21270;&#25552;&#31034;&#24037;&#31243;&#19982;&#36719;&#25552;&#31034;&#35843;&#25972;&#30340;&#32452;&#21512;&#65292;&#19968;&#31181;&#25105;&#20204;&#31216;&#20043;&#20026;EvoPrompting&#30340;&#26041;&#27861;&#65292;&#22987;&#32456;&#21487;&#20197;&#21457;&#29616;&#22810;&#26679;&#21270;&#19988;&#24615;&#33021;&#39640;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;EvoPrompting&#22312;MNIST-1D&#25968;&#25454;&#38598;&#19978;&#26159;&#26377;&#25928;&#30340;&#65292;&#20854;&#20013;EvoPrompting&#20135;&#29983;&#30340;&#21367;&#31215;&#26550;&#26500;&#21464;&#20307;&#22312;&#20934;&#30830;&#29575;&#21644;&#27169;&#22411;&#22823;&#23567;&#26041;&#38754;&#22343;&#20248;&#20110;&#20154;&#31867;&#19987;&#23478;&#35774;&#35745;&#30340;&#26550;&#26500;&#21644;&#22825;&#30495;&#30340;&#23569;&#25968;&#20808;&#23548;&#25552;&#31034;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#22312;CLRS&#31639;&#27861;&#25512;&#29702;&#22522;&#20934;&#19978;&#25628;&#32034;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#20854;&#20013;EvoPrompting&#33021;&#22815;&#35774;&#35745;&#20986;&#27604;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#26356;&#22909;&#30340;&#26032;&#39062;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given the recent impressive accomplishments of language models (LMs) for code generation, we explore the use of LMs as adaptive mutation and crossover operators for an evolutionary neural architecture search (NAS) algorithm. While NAS still proves too difficult a task for LMs to succeed at solely through prompting, we find that the combination of evolutionary prompt engineering with soft prompt-tuning, a method we term EvoPrompting, consistently finds diverse and high performing models. We first demonstrate that EvoPrompting is effective on the computationally efficient MNIST-1D dataset, where EvoPrompting produces convolutional architecture variants that outperform both those designed by human experts and naive few-shot prompting in terms of accuracy and model size. We then apply our method to searching for graph neural networks on the CLRS Algorithmic Reasoning Benchmark, where EvoPrompting is able to design novel architectures that outperform current state-of-the-art models on 21 ou
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#21033;&#29992;&#26368;&#23567;&#25551;&#36848;&#38271;&#24230;&#21407;&#21017;&#21644;&#32467;&#26500;&#31283;&#23450;&#24615;&#20026;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#25552;&#20379;&#20102;&#19968;&#20010;&#26126;&#30830;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#25351;&#23450;&#20102;&#26368;&#22823;&#31283;&#23450;&#20998;&#27495;&#35299;&#25968;&#30340;&#19979;&#38480;&#21644;&#19978;&#38480;&#12290;</title><link>http://arxiv.org/abs/2207.04876</link><description>&lt;p&gt;
&#22522;&#20110;&#26368;&#23567;&#25551;&#36848;&#38271;&#24230;&#21644;&#32467;&#26500;&#31283;&#23450;&#24615;&#30340;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Generalization of Spiking Neural Networks via Minimum Description Length and Structural Stability. (arXiv:2207.04876v2 [cs.NE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.04876
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#21033;&#29992;&#26368;&#23567;&#25551;&#36848;&#38271;&#24230;&#21407;&#21017;&#21644;&#32467;&#26500;&#31283;&#23450;&#24615;&#20026;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#25552;&#20379;&#20102;&#19968;&#20010;&#26126;&#30830;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#25351;&#23450;&#20102;&#26368;&#22823;&#31283;&#23450;&#20998;&#27495;&#35299;&#25968;&#30340;&#19979;&#38480;&#21644;&#19978;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21435;&#20960;&#21313;&#24180;&#20013;&#65292;&#30001;&#20110;&#20854;&#23545;&#20110;&#24314;&#27169;&#26102;&#38388;&#30456;&#20851;&#25968;&#25454;&#30340;&#28508;&#21147;&#65292;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#35768;&#22810;&#32463;&#39564;&#31639;&#27861;&#21644;&#25216;&#26415;&#24050;&#32463;&#34987;&#24320;&#21457;&#20986;&#26469;&#12290;&#28982;&#32780;&#65292;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;&#35757;&#32451;&#21518;&#30340;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#22312;&#26410;&#35265;&#25968;&#25454;&#19978;&#30340;&#34920;&#29616;&#20173;&#28982;&#26159;&#26410;&#30693;&#30340;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#21033;&#29992;&#26368;&#23567;&#25551;&#36848;&#38271;&#24230;&#21407;&#21017;&#65292;&#20026;&#33033;&#20914;&#31070;&#32463;&#32593;&#32476;&#25552;&#20379;&#19968;&#20010;&#26126;&#30830;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#32467;&#26500;&#31283;&#23450;&#24615;&#23454;&#26045;&#20102;SNN&#30340;&#25551;&#36848;&#38271;&#24230;&#65292;&#24182;&#25351;&#23450;&#20102;&#26368;&#22823;&#31283;&#23450;&#20998;&#27495;&#35299;&#25968;&#30340;&#19979;&#38480;&#21644;&#19978;&#38480;&#65292;&#23558;&#22312;SNN&#20013;&#30830;&#23450;&#32467;&#26500;&#31283;&#23450;&#24615;&#30340;&#25361;&#25112;&#36716;&#21270;&#20026;&#19968;&#20010;&#20855;&#26377;&#23450;&#37327;&#29305;&#24615;&#30340;&#25968;&#23398;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
The past decades have witnessed an increasing interest in spiking neural networks due to their great potential of modeling time-dependent data. Many empirical algorithms and techniques have been developed. However, theoretically, it remains unknown whether and to what extent a trained spiking neural network performs well on unseen data. This work takes one step in this direction by exploiting the minimum description length principle and thus, presents an explicit generalization bound for spiking neural networks. Further, we implement the description length of SNNs through structural stability and specify the lower and upper bounds of the maximum number of stable bifurcation solutions, which convert the challenge of qualifying structural stability in SNNs into a mathematical problem with quantitative properties.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20026;&#20102;&#25903;&#25345;&#19981;&#26029;&#21457;&#23637;&#30340;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#35770;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#27010;&#24565;&#27169;&#22411;&#65292;&#29992;&#20110;&#25551;&#36848;&#30693;&#35782;&#34920;&#31034;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#25512;&#29702;&#20195;&#29702;&#20154;&#36827;&#34892;&#30340;&#20449;&#24687;&#20256;&#36755;&#12290;&#36890;&#36807;&#23545;&#30693;&#35782;&#29366;&#24577;&#21644;&#20854;&#21160;&#24577;&#30340;&#20195;&#25968;&#25551;&#36848;&#65292;&#25105;&#20204;&#33021;&#22815;&#27604;&#36739;&#21644;&#32452;&#21512;&#30693;&#35782;&#29366;&#24577;&#65292;&#20197;&#34920;&#31034;&#26356;&#26032;&#12290;</title><link>http://arxiv.org/abs/2110.11482</link><description>&lt;p&gt;
&#25968;&#25454;&#39537;&#21160;&#20030;&#25514;&#20013;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#30340;&#34920;&#36798;&#21450;&#20854;&#24863;&#30693;
&lt;/p&gt;
&lt;p&gt;
Representations of epistemic uncertainty and its perception in data-driven initiatives. (arXiv:2110.11482v4 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.11482
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20026;&#20102;&#25903;&#25345;&#19981;&#26029;&#21457;&#23637;&#30340;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#35770;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#27010;&#24565;&#27169;&#22411;&#65292;&#29992;&#20110;&#25551;&#36848;&#30693;&#35782;&#34920;&#31034;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#25512;&#29702;&#20195;&#29702;&#20154;&#36827;&#34892;&#30340;&#20449;&#24687;&#20256;&#36755;&#12290;&#36890;&#36807;&#23545;&#30693;&#35782;&#29366;&#24577;&#21644;&#20854;&#21160;&#24577;&#30340;&#20195;&#25968;&#25551;&#36848;&#65292;&#25105;&#20204;&#33021;&#22815;&#27604;&#36739;&#21644;&#32452;&#21512;&#30693;&#35782;&#29366;&#24577;&#65292;&#20197;&#34920;&#31034;&#26356;&#26032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20511;&#21161;&#20154;&#24037;&#26234;&#33021;&#30340;&#20986;&#29616;&#25512;&#21160;&#30340;&#26032;&#20852;&#25968;&#25454;&#39537;&#21160;&#31574;&#30053;&#27491;&#22312;&#37325;&#22609;&#20915;&#31574;&#36807;&#31243;&#65292;&#36828;&#31163;&#23545;&#30452;&#25509;&#25968;&#25454;&#20132;&#20114;&#30340;&#20256;&#32479;&#20381;&#36182;&#12290;&#36825;&#31181;&#33539;&#24335;&#36716;&#21464;&#24341;&#20837;&#20102;&#35780;&#20272;&#25968;&#25454;&#39537;&#21160;&#20030;&#25514;&#24433;&#21709;&#30340;&#26032;&#25361;&#25112;&#12290;&#20026;&#20102;&#25903;&#25345;&#36825;&#20123;&#19981;&#26029;&#21457;&#23637;&#30340;&#26041;&#27861;&#35770;&#65292;&#36843;&#20999;&#38656;&#35201;&#26032;&#30340;&#27169;&#22411;&#65292;&#33021;&#22815;&#25551;&#36848;&#28304;&#20110;&#26377;&#38480;&#25968;&#25454;&#21487;&#35266;&#27979;&#24615;&#20197;&#21450;&#30001;&#27492;&#20135;&#29983;&#30340;&#20915;&#31574;&#20013;&#30340;&#27495;&#20041;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#27010;&#24565;&#27169;&#22411;&#65292;&#26088;&#22312;&#22788;&#29702;&#30693;&#35782;&#34920;&#31034;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#25512;&#29702;&#20195;&#29702;&#20154;&#36827;&#34892;&#20449;&#24687;&#20256;&#36755;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#20511;&#37492;&#30446;&#21069;&#29992;&#20110;&#35780;&#20272;&#25968;&#25454;&#39537;&#21160;&#20030;&#25514;&#20135;&#29983;&#30340;&#20215;&#20540;&#30340;&#22810;&#32500;&#26694;&#26550;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#30693;&#35782;&#29366;&#24577;&#21450;&#20854;&#21160;&#24577;&#30340;&#20195;&#25968;&#25551;&#36848;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36171;&#20104;&#25105;&#20204;&#30340;&#27169;&#22411;&#19968;&#31181;&#24418;&#24335;&#21270;&#32467;&#26500;&#65292;&#29992;&#20110;&#27604;&#36739;&#21644;&#32452;&#21512;&#30693;&#35782;&#29366;&#24577;&#65307;&#36890;&#36807;&#36825;&#20123;&#32452;&#21512;&#26469;&#34920;&#31034;&#26356;&#26032;&#12290;
&lt;/p&gt;
&lt;p&gt;
Emerging data-driven strategies, powered by the advent of AI, are reshaping decision-making processes, moving away from traditional reliance on direct data interaction. This paradigm shift introduces new challenges in assessing the impact of data-driven initiatives. To support these evolving methodologies, there is a crucial need for new models capable of describing the uncertainties stemming from limited data observability and the resulting ambiguities in decision-making. This contribution presents a novel conceptual model designed to deal with uncertainty in knowledge representations and reasoning about information transfer mediated by agents. Drawing from the multidimensional frameworks currently adopted to assess the value generated in data-driven initiatives, we provide an algebraic description of knowledge states and their dynamics. Specifically, we endow our model with a formal structure to compare and combine knowledge states; an update is represented through these combinations
&lt;/p&gt;</description></item></channel></rss>