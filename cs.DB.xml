<rss version="2.0"><channel><title>Chat Arxiv cs.DB</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.DB</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#35745;&#31639;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20998;&#31867;&#20013;Shap&#35299;&#37322;&#20998;&#25968;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#20108;&#36827;&#21046;&#31070;&#32463;&#32593;&#32476;&#36716;&#25442;&#20026;&#24067;&#23572;&#30005;&#36335;&#65292;&#24182;&#20351;&#29992;&#30693;&#35782;&#32534;&#35793;&#25216;&#26415;&#65292;&#23558;&#30005;&#36335;&#35270;&#20026;&#24320;&#25918;&#24335;&#27169;&#22411;&#65292;&#36890;&#36807;&#26368;&#36817;&#30340;&#39640;&#25928;&#31639;&#27861;&#35745;&#31639;Shap&#20998;&#25968;&#65292;&#30456;&#27604;&#20110;&#23558;BNN&#35270;&#20026;&#40657;&#30418;&#27169;&#22411;&#30452;&#25509;&#35745;&#31639;Shap&#65292;&#24615;&#33021;&#26377;&#20102;&#26174;&#33879;&#30340;&#25552;&#39640;&#12290;</title><link>http://arxiv.org/abs/2303.06516</link><description>&lt;p&gt;
&#25171;&#24320;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#20197;&#35745;&#31639;Shap&#20998;&#25968;
&lt;/p&gt;
&lt;p&gt;
Opening Up the Neural Network Classifier for Shap Score Computation. (arXiv:2303.06516v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06516
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#35745;&#31639;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20998;&#31867;&#20013;Shap&#35299;&#37322;&#20998;&#25968;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#20108;&#36827;&#21046;&#31070;&#32463;&#32593;&#32476;&#36716;&#25442;&#20026;&#24067;&#23572;&#30005;&#36335;&#65292;&#24182;&#20351;&#29992;&#30693;&#35782;&#32534;&#35793;&#25216;&#26415;&#65292;&#23558;&#30005;&#36335;&#35270;&#20026;&#24320;&#25918;&#24335;&#27169;&#22411;&#65292;&#36890;&#36807;&#26368;&#36817;&#30340;&#39640;&#25928;&#31639;&#27861;&#35745;&#31639;Shap&#20998;&#25968;&#65292;&#30456;&#27604;&#20110;&#23558;BNN&#35270;&#20026;&#40657;&#30418;&#27169;&#22411;&#30452;&#25509;&#35745;&#31639;Shap&#65292;&#24615;&#33021;&#26377;&#20102;&#26174;&#33879;&#30340;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes an efficient method for computing Shap explanation scores in machine learning model classification by transforming binary neural networks into Boolean circuits and treating the resulting circuit as an open-box model, which leads to a significant improvement in performance compared to computing Shap directly on the BNN treated as a black-box model.
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#20998;&#31867;&#30340;Shap&#35299;&#37322;&#20998;&#25968;&#30340;&#39640;&#25928;&#35745;&#31639;&#38382;&#39064;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23558;&#20108;&#36827;&#21046;&#31070;&#32463;&#32593;&#32476;&#65288;BNN&#65289;&#36716;&#25442;&#20026;&#30830;&#23450;&#24615;&#21644;&#21487;&#20998;&#35299;&#30340;&#24067;&#23572;&#30005;&#36335;&#65292;&#20351;&#29992;&#30693;&#35782;&#32534;&#35793;&#25216;&#26415;&#12290;&#25152;&#24471;&#21040;&#30340;&#30005;&#36335;&#34987;&#35270;&#20026;&#24320;&#25918;&#24335;&#27169;&#22411;&#65292;&#36890;&#36807;&#26368;&#36817;&#30340;&#39640;&#25928;&#31639;&#27861;&#35745;&#31639;Shap&#20998;&#25968;&#12290;&#35814;&#32454;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#19982;&#23558;BNN&#35270;&#20026;&#40657;&#30418;&#27169;&#22411;&#30452;&#25509;&#35745;&#31639;Shap&#30456;&#27604;&#65292;&#24615;&#33021;&#26377;&#20102;&#26174;&#33879;&#30340;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
We address the problem of efficiently computing Shap explanation scores for classifications with machine learning models. With this goal, we show the transformation of binary neural networks (BNNs) for classification into deterministic and decomposable Boolean circuits, for which knowledge compilation techniques are used. The resulting circuit is treated as an open-box model, to compute Shap scores by means of a recent efficient algorithm for this class of circuits. Detailed experiments show a considerable gain in performance in comparison with computing Shap directly on the BNN treated as a black-box model.
&lt;/p&gt;</description></item><item><title>STAIR&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#24322;&#24120;&#20540;&#27719;&#24635;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#19968;&#32452;&#32039;&#20945;&#30340;&#20154;&#31867;&#21487;&#29702;&#35299;&#35268;&#21017;&#65292;&#20197;&#27719;&#24635;&#21644;&#35299;&#37322;&#24322;&#24120;&#26816;&#27979;&#32467;&#26524;&#65292;&#20855;&#26377;&#24378;&#22823;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#20197;&#20934;&#30830;&#22320;&#24635;&#32467;&#26816;&#27979;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2303.06261</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#24322;&#24120;&#20540;&#27719;&#24635;
&lt;/p&gt;
&lt;p&gt;
Interpretable Outlier Summarization. (arXiv:2303.06261v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06261
&lt;/p&gt;
&lt;p&gt;
STAIR&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#24322;&#24120;&#20540;&#27719;&#24635;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#19968;&#32452;&#32039;&#20945;&#30340;&#20154;&#31867;&#21487;&#29702;&#35299;&#35268;&#21017;&#65292;&#20197;&#27719;&#24635;&#21644;&#35299;&#37322;&#24322;&#24120;&#26816;&#27979;&#32467;&#26524;&#65292;&#20855;&#26377;&#24378;&#22823;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#20197;&#20934;&#30830;&#22320;&#24635;&#32467;&#26816;&#27979;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
STAIR proposes an interpretable outlier summarization method by learning a compact set of human understandable rules to summarize and explain the anomaly detection results, which has strong interpretability to accurately summarize the detection results.
&lt;/p&gt;
&lt;p&gt;
&#24322;&#24120;&#20540;&#26816;&#27979;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#65292;&#20197;&#38450;&#27490;&#37329;&#34701;&#27450;&#35784;&#12289;&#38450;&#24481;&#32593;&#32476;&#20837;&#20405;&#25110;&#26816;&#27979;&#21363;&#23558;&#21457;&#29983;&#30340;&#35774;&#22791;&#25925;&#38556;&#12290;&#20026;&#20102;&#20943;&#23569;&#20154;&#21147;&#35780;&#20272;&#24322;&#24120;&#20540;&#26816;&#27979;&#32467;&#26524;&#30340;&#24037;&#20316;&#37327;&#65292;&#24182;&#26377;&#25928;&#22320;&#23558;&#24322;&#24120;&#20540;&#36716;&#21270;&#20026;&#21487;&#25805;&#20316;&#30340;&#35265;&#35299;&#65292;&#29992;&#25143;&#36890;&#24120;&#24076;&#26395;&#31995;&#32479;&#33258;&#21160;&#20135;&#29983;&#21487;&#35299;&#37322;&#30340;&#24322;&#24120;&#20540;&#26816;&#27979;&#32467;&#26524;&#30340;&#23376;&#32452;&#30340;&#27719;&#24635;&#12290;&#28982;&#32780;&#65292;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#27809;&#26377;&#36825;&#26679;&#30340;&#31995;&#32479;&#23384;&#22312;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;STAIR&#65292;&#23427;&#23398;&#20064;&#20102;&#19968;&#32452;&#32039;&#20945;&#30340;&#20154;&#31867;&#21487;&#29702;&#35299;&#35268;&#21017;&#65292;&#20197;&#27719;&#24635;&#21644;&#35299;&#37322;&#24322;&#24120;&#26816;&#27979;&#32467;&#26524;&#12290;STAIR&#19981;&#20351;&#29992;&#32463;&#20856;&#30340;&#20915;&#31574;&#26641;&#31639;&#27861;&#26469;&#20135;&#29983;&#36825;&#20123;&#35268;&#21017;&#65292;&#32780;&#26159;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20248;&#21270;&#30446;&#26631;&#65292;&#20197;&#20135;&#29983;&#23569;&#37327;&#35268;&#21017;&#65292;&#20855;&#26377;&#26368;&#23567;&#30340;&#22797;&#26434;&#24615;&#65292;&#22240;&#27492;&#20855;&#26377;&#24378;&#22823;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#20197;&#20934;&#30830;&#22320;&#24635;&#32467;&#26816;&#27979;&#32467;&#26524;&#12290;STAIR&#30340;&#23398;&#20064;&#31639;&#27861;&#36890;&#36807;&#36845;&#20195;&#20998;&#21106;&#22823;&#35268;&#21017;&#26469;&#20135;&#29983;&#35268;&#21017;&#38598;&#65292;&#24182;&#22312;&#27599;&#20010;i&#20013;&#26368;&#22823;&#21270;&#36825;&#20010;&#30446;&#26631;&#65292;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Outlier detection is critical in real applications to prevent financial fraud, defend network intrusions, or detecting imminent device failures. To reduce the human effort in evaluating outlier detection results and effectively turn the outliers into actionable insights, the users often expect a system to automatically produce interpretable summarizations of subgroups of outlier detection results. Unfortunately, to date no such systems exist. To fill this gap, we propose STAIR which learns a compact set of human understandable rules to summarize and explain the anomaly detection results. Rather than use the classical decision tree algorithms to produce these rules, STAIR proposes a new optimization objective to produce a small number of rules with least complexity, hence strong interpretability, to accurately summarize the detection results. The learning algorithm of STAIR produces a rule set by iteratively splitting the large rules and is optimal in maximizing this objective in each i
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#30001;ASOS&#25910;&#38598;&#30340;&#26032;&#22411;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#35299;&#20915;&#26102;&#23578;&#38646;&#21806;&#29983;&#24577;&#31995;&#32479;&#20013;&#39044;&#27979;&#23458;&#25143;&#36864;&#36135;&#30340;&#25361;&#25112;&#12290;&#30740;&#31350;&#32773;&#20351;&#29992;&#22270;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#25552;&#39640;&#20102;&#36864;&#36135;&#39044;&#27979;&#20998;&#31867;&#20219;&#21153;&#30340;F1&#20998;&#25968;&#33267;0.792&#65292;&#36825;&#27604;&#20854;&#20182;&#27169;&#22411;&#26377;&#25152;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2302.14096</link><description>&lt;p&gt;
&#19968;&#20221;&#29992;&#20110;&#23398;&#20064;&#22270;&#34920;&#31034;&#20197;&#39044;&#27979;&#26102;&#23578;&#38646;&#21806;&#23458;&#25143;&#36864;&#36135;&#30340;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
A Dataset for Learning Graph Representations to Predict Customer Returns in Fashion Retail. (arXiv:2302.14096v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.14096
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#30001;ASOS&#25910;&#38598;&#30340;&#26032;&#22411;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#35299;&#20915;&#26102;&#23578;&#38646;&#21806;&#29983;&#24577;&#31995;&#32479;&#20013;&#39044;&#27979;&#23458;&#25143;&#36864;&#36135;&#30340;&#25361;&#25112;&#12290;&#30740;&#31350;&#32773;&#20351;&#29992;&#22270;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#25552;&#39640;&#20102;&#36864;&#36135;&#39044;&#27979;&#20998;&#31867;&#20219;&#21153;&#30340;F1&#20998;&#25968;&#33267;0.792&#65292;&#36825;&#27604;&#20854;&#20182;&#27169;&#22411;&#26377;&#25152;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a novel dataset collected by ASOS for predicting customer returns in a fashion retail ecosystem. The researchers use Graph Representation Learning to improve the F1-score of the return prediction classification task to 0.792, outperforming other models.
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#30001;ASOS&#65288;&#19968;&#23478;&#20027;&#35201;&#30340;&#22312;&#32447;&#26102;&#23578;&#38646;&#21806;&#21830;&#65289;&#25910;&#38598;&#30340;&#26032;&#22411;&#25968;&#25454;&#38598;&#65292;&#20197;&#35299;&#20915;&#22312;&#26102;&#23578;&#38646;&#21806;&#29983;&#24577;&#31995;&#32479;&#20013;&#39044;&#27979;&#23458;&#25143;&#36864;&#36135;&#30340;&#25361;&#25112;&#12290;&#36890;&#36807;&#21457;&#24067;&#36825;&#20010;&#24222;&#22823;&#30340;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#24076;&#26395;&#28608;&#21457;&#30740;&#31350;&#31038;&#21306;&#21644;&#26102;&#23578;&#34892;&#19994;&#20043;&#38388;&#30340;&#36827;&#19968;&#27493;&#21512;&#20316;&#12290;&#25105;&#20204;&#39318;&#20808;&#25506;&#35752;&#20102;&#36825;&#20010;&#25968;&#25454;&#38598;&#30340;&#32467;&#26500;&#65292;&#37325;&#28857;&#20851;&#27880;&#22270;&#34920;&#31034;&#23398;&#20064;&#30340;&#24212;&#29992;&#65292;&#20197;&#21033;&#29992;&#33258;&#28982;&#25968;&#25454;&#32467;&#26500;&#24182;&#25552;&#20379;&#23545;&#25968;&#25454;&#20013;&#29305;&#23450;&#29305;&#24449;&#30340;&#32479;&#35745;&#27934;&#23519;&#12290;&#38500;&#27492;&#20043;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#36864;&#36135;&#39044;&#27979;&#20998;&#31867;&#20219;&#21153;&#30340;&#31034;&#20363;&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#20123;&#22522;&#32447;&#27169;&#22411;&#65288;&#21363;&#27809;&#26377;&#20013;&#38388;&#34920;&#31034;&#23398;&#20064;&#27493;&#39588;&#65289;&#21644;&#22522;&#20110;&#22270;&#34920;&#31034;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#19979;&#28216;&#36864;&#36135;&#39044;&#27979;&#20998;&#31867;&#20219;&#21153;&#20013;&#65292;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#21487;&#20197;&#25214;&#21040;F1&#20998;&#25968;&#20026;0.792&#65292;&#36825;&#27604;&#26412;&#25991;&#35752;&#35770;&#30340;&#20854;&#20182;&#27169;&#22411;&#26377;&#25152;&#25913;&#36827;&#12290;&#38500;&#20102;&#36825;&#20010;&#22686;&#21152;&#30340;F1&#20998;&#25968;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;l
&lt;/p&gt;
&lt;p&gt;
We present a novel dataset collected by ASOS (a major online fashion retailer) to address the challenge of predicting customer returns in a fashion retail ecosystem. With the release of this substantial dataset we hope to motivate further collaboration between research communities and the fashion industry. We first explore the structure of this dataset with a focus on the application of Graph Representation Learning in order to exploit the natural data structure and provide statistical insights into particular features within the data. In addition to this, we show examples of a return prediction classification task with a selection of baseline models (i.e. with no intermediate representation learning step) and a graph representation based model. We show that in a downstream return prediction classification task, an F1-score of 0.792 can be found using a Graph Neural Network (GNN), improving upon other models discussed in this work. Alongside this increased F1-score, we also present a l
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#31163;&#24449;&#26381;&#30340;&#23545;&#27604;&#38598;&#25366;&#25496;&#31639;&#27861;RuleKit-CS&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#22810;&#27425;&#36890;&#36807;&#20276;&#38543;&#23646;&#24615;&#24809;&#32602;&#26041;&#26696;&#25552;&#20379;&#25551;&#36848;&#20855;&#26377;&#19981;&#21516;&#23646;&#24615;&#30340;&#30456;&#21516;&#31034;&#20363;&#30340;&#23545;&#27604;&#38598;&#65292;&#21306;&#21035;&#20110;&#26631;&#20934;&#30340;&#20998;&#31163;&#24449;&#26381;&#12290;&#35813;&#31639;&#27861;&#36824;&#34987;&#25512;&#24191;&#21040;&#22238;&#24402;&#21644;&#29983;&#23384;&#25968;&#25454;&#65292;&#20801;&#35768;&#35782;&#21035;&#26631;&#31614;&#23646;&#24615;/&#29983;&#23384;&#39044;&#27979;&#19982;&#39044;&#23450;&#20041;&#23545;&#27604;&#32452;&#30340;&#26631;&#31614;/&#39044;&#27979;&#19968;&#33268;&#30340;&#23545;&#27604;&#38598;&#12290;</title><link>http://arxiv.org/abs/2204.00497</link><description>&lt;p&gt;
&#20998;&#31163;&#24449;&#26381;&#21551;&#21457;&#24335;&#31639;&#27861;&#20801;&#35768;&#22312;&#20998;&#31867;&#12289;&#22238;&#24402;&#21644;&#29983;&#23384;&#25968;&#25454;&#20013;&#36827;&#34892;&#24378;&#22823;&#30340;&#23545;&#27604;&#38598;&#25366;&#25496;
&lt;/p&gt;
&lt;p&gt;
Separate and conquer heuristic allows robust mining of contrast sets in classification, regression, and survival data. (arXiv:2204.00497v3 [cs.DB] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.00497
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#31163;&#24449;&#26381;&#30340;&#23545;&#27604;&#38598;&#25366;&#25496;&#31639;&#27861;RuleKit-CS&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#22810;&#27425;&#36890;&#36807;&#20276;&#38543;&#23646;&#24615;&#24809;&#32602;&#26041;&#26696;&#25552;&#20379;&#25551;&#36848;&#20855;&#26377;&#19981;&#21516;&#23646;&#24615;&#30340;&#30456;&#21516;&#31034;&#20363;&#30340;&#23545;&#27604;&#38598;&#65292;&#21306;&#21035;&#20110;&#26631;&#20934;&#30340;&#20998;&#31163;&#24449;&#26381;&#12290;&#35813;&#31639;&#27861;&#36824;&#34987;&#25512;&#24191;&#21040;&#22238;&#24402;&#21644;&#29983;&#23384;&#25968;&#25454;&#65292;&#20801;&#35768;&#35782;&#21035;&#26631;&#31614;&#23646;&#24615;/&#29983;&#23384;&#39044;&#27979;&#19982;&#39044;&#23450;&#20041;&#23545;&#27604;&#32452;&#30340;&#26631;&#31614;/&#39044;&#27979;&#19968;&#33268;&#30340;&#23545;&#27604;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a contrast set mining algorithm, RuleKit-CS, based on the separate and conquer heuristic, which provides contrast sets describing the same examples with different attributes through multiple passes accompanied with an attribute penalization scheme. The algorithm is also generalized for regression and survival data, allowing identification of contrast sets whose label attribute/survival prognosis is consistent with the label/prognosis for the predefined contrast groups.
&lt;/p&gt;
&lt;p&gt;
&#35782;&#21035;&#32676;&#20307;&#20043;&#38388;&#30340;&#24046;&#24322;&#26159;&#26368;&#37325;&#35201;&#30340;&#30693;&#35782;&#21457;&#29616;&#38382;&#39064;&#20043;&#19968;&#12290;&#35813;&#36807;&#31243;&#65292;&#20063;&#31216;&#20026;&#23545;&#27604;&#38598;&#25366;&#25496;&#65292;&#22312;&#21307;&#23398;&#12289;&#24037;&#19994;&#25110;&#32463;&#27982;&#31561;&#24191;&#27867;&#39046;&#22495;&#20013;&#24212;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;RuleKit-CS&#65292;&#19968;&#31181;&#22522;&#20110;&#20998;&#31163;&#24449;&#26381;&#30340;&#23545;&#27604;&#38598;&#25366;&#25496;&#31639;&#27861;&#8212;&#8212;&#19968;&#31181;&#29992;&#20110;&#20915;&#31574;&#35268;&#21017;&#24402;&#32435;&#30340;&#25104;&#29087;&#21551;&#21457;&#24335;&#31639;&#27861;&#12290;&#22810;&#27425;&#36890;&#36807;&#20276;&#38543;&#23646;&#24615;&#24809;&#32602;&#26041;&#26696;&#25552;&#20379;&#25551;&#36848;&#20855;&#26377;&#19981;&#21516;&#23646;&#24615;&#30340;&#30456;&#21516;&#31034;&#20363;&#30340;&#23545;&#27604;&#38598;&#65292;&#21306;&#21035;&#20110;&#26631;&#20934;&#30340;&#20998;&#31163;&#24449;&#26381;&#12290;&#35813;&#31639;&#27861;&#36824;&#34987;&#25512;&#24191;&#21040;&#22238;&#24402;&#21644;&#29983;&#23384;&#25968;&#25454;&#65292;&#20801;&#35768;&#35782;&#21035;&#26631;&#31614;&#23646;&#24615;/&#29983;&#23384;&#39044;&#27979;&#19982;&#39044;&#23450;&#20041;&#23545;&#27604;&#32452;&#30340;&#26631;&#31614;/&#39044;&#27979;&#19968;&#33268;&#30340;&#23545;&#27604;&#38598;&#12290;&#36825;&#20010;&#29305;&#24615;&#65292;&#19981;&#26159;&#29616;&#26377;&#26041;&#27861;&#25152;&#25552;&#20379;&#30340;&#65292;&#36827;&#19968;&#27493;&#25193;&#23637;&#20102;RuleKit-CS&#30340;&#21487;&#29992;&#24615;&#12290;&#22312;&#26469;&#33258;&#21508;&#20010;&#39046;&#22495;&#30340;130&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#21644;&#35814;&#32454;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Identifying differences between groups is one of the most important knowledge discovery problems. The procedure, also known as contrast sets mining, is applied in a wide range of areas like medicine, industry, or economics.  In the paper we present RuleKit-CS, an algorithm for contrast set mining based on separate and conquer - a well established heuristic for decision rule induction. Multiple passes accompanied with an attribute penalization scheme provide contrast sets describing same examples with different attributes, distinguishing presented approach from the standard separate and conquer. The algorithm was also generalized for regression and survival data allowing identification of contrast sets whose label attribute/survival prognosis is consistent with the label/prognosis for the predefined contrast groups. This feature, not provided by the existing approaches, further extends the usability of RuleKit-CS.  Experiments on over 130 data sets from various areas and detailed analys
&lt;/p&gt;</description></item></channel></rss>