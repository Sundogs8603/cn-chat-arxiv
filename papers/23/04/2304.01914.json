{
    "title": "Accelerating and Compressing Deep Neural Networks for Massive MIMO CSI Feedback. (arXiv:2304.01914v1 [cs.NI])",
    "abstract": "The recent advances in machine learning and deep neural networks have made them attractive candidates for wireless communications functions such as channel estimation, decoding, and downlink channel state information (CSI) compression. However, most of these neural networks are large and inefficient making it a barrier for deployment in practical wireless systems that require low-latency and low memory footprints for individual network functions. To mitigate these limitations, we propose accelerated and compressed efficient neural networks for massive MIMO CSI feedback. Specifically, we have thoroughly investigated the adoption of network pruning, post-training dynamic range quantization, and weight clustering to optimize CSI feedback compression for massive MIMO systems. Furthermore, we have deployed the proposed model compression techniques on commodity hardware and demonstrated that in order to achieve inference gains, specialized libraries that accelerate computations for sparse ne",
    "link": "http://arxiv.org/abs/2304.01914",
    "context": "Title: Accelerating and Compressing Deep Neural Networks for Massive MIMO CSI Feedback. (arXiv:2304.01914v1 [cs.NI])\nAbstract: The recent advances in machine learning and deep neural networks have made them attractive candidates for wireless communications functions such as channel estimation, decoding, and downlink channel state information (CSI) compression. However, most of these neural networks are large and inefficient making it a barrier for deployment in practical wireless systems that require low-latency and low memory footprints for individual network functions. To mitigate these limitations, we propose accelerated and compressed efficient neural networks for massive MIMO CSI feedback. Specifically, we have thoroughly investigated the adoption of network pruning, post-training dynamic range quantization, and weight clustering to optimize CSI feedback compression for massive MIMO systems. Furthermore, we have deployed the proposed model compression techniques on commodity hardware and demonstrated that in order to achieve inference gains, specialized libraries that accelerate computations for sparse ne",
    "path": "papers/23/04/2304.01914.json",
    "total_tokens": 879,
    "translated_title": "加速和压缩深度神经网络用于 Massive MIMO CSI 反馈",
    "translated_abstract": "最近机器学习和深度神经网络的进步使得它们成为了无线通信的候选者，如信道估计、解码和下行信道状态信息（CSI）压缩。然而，大多数这些神经网络都是庞大和低效的，这成为它们在需要个别网络功能低延迟和低内存占用的实际无线系统部署中的障碍。为了减轻这些限制，我们提出了用于 Massive MIMO CSI 反馈的加速和压缩有效神经网络。具体来说，我们深入研究了采用网络修剪、训练后动态范围量化和权重聚类来优化 Massive MIMO 系统的 CSI 反馈压缩。此外，我们还在商用硬件上部署了所提出的模型压缩技术，并展示了为实现推理增益，需要加速稀疏网络计算的专用库。",
    "tldr": "本文提出了一种用于 Massive MIMO CSI 反馈的加速和压缩有效神经网络，采用了网络修剪、训练后动态范围量化和权重聚类等优化方法，以缓解神经网络在实际无线系统中的限制。",
    "en_tdlr": "This paper proposes an accelerated and compressed efficient neural network for massive MIMO CSI feedback, utilizing network pruning, post-training dynamic range quantization, and weight clustering to optimize CSI feedback compression. The proposed model compression techniques are deployed on commodity hardware and demonstrate the need for specialized libraries to accelerate computations for sparse networks."
}