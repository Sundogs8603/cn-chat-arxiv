{
    "title": "Efficient Audio Captioning Transformer with Patchout and Text Guidance. (arXiv:2304.02916v1 [cs.SD])",
    "abstract": "Automated audio captioning is multi-modal translation task that aim to generate textual descriptions for a given audio clip. In this paper we propose a full Transformer architecture that utilizes Patchout as proposed in [1], significantly reducing the computational complexity and avoiding overfitting. The caption generation is partly conditioned on textual AudioSet tags extracted by a pre-trained classification model which is fine-tuned to maximize the semantic similarity between AudioSet labels and ground truth captions. To mitigate the data scarcity problem of Automated Audio Captioning we introduce transfer learning from an upstream audio-related task and an enlarged in-domain dataset. Moreover, we propose a method to apply Mixup augmentation for AAC. Ablation studies are carried out to investigate how Patchout and text guidance contribute to the final performance. The results show that the proposed techniques improve the performance of our system and while reducing the computationa",
    "link": "http://arxiv.org/abs/2304.02916",
    "context": "Title: Efficient Audio Captioning Transformer with Patchout and Text Guidance. (arXiv:2304.02916v1 [cs.SD])\nAbstract: Automated audio captioning is multi-modal translation task that aim to generate textual descriptions for a given audio clip. In this paper we propose a full Transformer architecture that utilizes Patchout as proposed in [1], significantly reducing the computational complexity and avoiding overfitting. The caption generation is partly conditioned on textual AudioSet tags extracted by a pre-trained classification model which is fine-tuned to maximize the semantic similarity between AudioSet labels and ground truth captions. To mitigate the data scarcity problem of Automated Audio Captioning we introduce transfer learning from an upstream audio-related task and an enlarged in-domain dataset. Moreover, we propose a method to apply Mixup augmentation for AAC. Ablation studies are carried out to investigate how Patchout and text guidance contribute to the final performance. The results show that the proposed techniques improve the performance of our system and while reducing the computationa",
    "path": "papers/23/04/2304.02916.json",
    "total_tokens": 858,
    "translated_title": "基于Patchout和文本指导的高效音频字幕生成器",
    "translated_abstract": "自动音频字幕生成是一项多模态翻译任务，旨在为给定的音频剪辑生成文本描述。本文提出了一种全面的Transformer架构，利用了[1]中提出的Patchout技术，显著降低了计算复杂度，并避免了过度拟合。字幕生成部分对预训练分类模型提取的文本AudioSet标签进行了某种程度的条件约束，该模型被微调以最大化AudioSet标签与地面真实字幕之间的语义相似度。为了缓解音频字幕生成的数据稀缺性问题，我们引入了来自上游音频相关任务和扩大的领域内数据集的迁移学习。此外，我们还提出了一种应用Mixup增强技术进行音频字幕生成的方法。进行了消融实验来研究Patchout和文本指导对最终性能的贡献。结果表明，所提出的技术改善了我们系统的性能，同时减少了计算量。",
    "tldr": "本文提出了一种使用Patchout和文本指导的高效音频字幕生成器，利用迁移学习和Mixup增强技术解决数据稀缺性问题。",
    "en_tdlr": "This paper proposes an efficient audio captioning transformer with Patchout and textual guidance, utilizing transfer learning and Mixup augmentation to mitigate data scarcity, resulting in improved performance with reduced computational complexity."
}