{
    "title": "Certifiable Black-Box Attack: Ensuring Provably Successful Attack for Adversarial Examples. (arXiv:2304.04343v1 [cs.LG])",
    "abstract": "Black-box adversarial attacks have shown strong potential to subvert machine learning models. Existing black-box adversarial attacks craft the adversarial examples by iteratively querying the target model and/or leveraging the transferability of a local surrogate model. Whether such attack can succeed remains unknown to the adversary when empirically designing the attack. In this paper, to our best knowledge, we take the first step to study a new paradigm of adversarial attacks -- certifiable black-box attack that can guarantee the attack success rate of the crafted adversarial examples. Specifically, we revise the randomized smoothing to establish novel theories for ensuring the attack success rate of the adversarial examples. To craft the adversarial examples with the certifiable attack success rate (CASR) guarantee, we design several novel techniques, including a randomized query method to query the target model, an initialization method with smoothed self-supervised perturbation to",
    "link": "http://arxiv.org/abs/2304.04343",
    "context": "Title: Certifiable Black-Box Attack: Ensuring Provably Successful Attack for Adversarial Examples. (arXiv:2304.04343v1 [cs.LG])\nAbstract: Black-box adversarial attacks have shown strong potential to subvert machine learning models. Existing black-box adversarial attacks craft the adversarial examples by iteratively querying the target model and/or leveraging the transferability of a local surrogate model. Whether such attack can succeed remains unknown to the adversary when empirically designing the attack. In this paper, to our best knowledge, we take the first step to study a new paradigm of adversarial attacks -- certifiable black-box attack that can guarantee the attack success rate of the crafted adversarial examples. Specifically, we revise the randomized smoothing to establish novel theories for ensuring the attack success rate of the adversarial examples. To craft the adversarial examples with the certifiable attack success rate (CASR) guarantee, we design several novel techniques, including a randomized query method to query the target model, an initialization method with smoothed self-supervised perturbation to",
    "path": "papers/23/04/2304.04343.json",
    "total_tokens": 728,
    "translated_title": "可证黑盒攻击：确保对抗性样本的攻击成功率",
    "translated_abstract": "黑盒对抗攻击具有破坏机器学习模型的强大潜力。现有的黑盒对抗攻击通过迭代查询目标模型和/或利用本地代理模型的可转移性来制作对抗样本。当实验设计攻击时，攻击是否成功对攻击者来说仍然是未知的。本文通过修改随机平滑性理论，首次研究了可证黑盒攻击的新范例，能够保证制作的对抗样本的攻击成功率，为此设计了多种新技术。",
    "tldr": "本文提出可证黑盒攻击，能够保证攻击成功率，设计了多种新技术。"
}