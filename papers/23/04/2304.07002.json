{
    "title": "SimpLex: a lexical text simplification architecture. (arXiv:2304.07002v1 [cs.CL])",
    "abstract": "Text simplification (TS) is the process of generating easy-to-understand sentences from a given sentence or piece of text. The aim of TS is to reduce both the lexical (which refers to vocabulary complexity and meaning) and syntactic (which refers to the sentence structure) complexity of a given text or sentence without the loss of meaning or nuance. In this paper, we present \\textsc{SimpLex}, a novel simplification architecture for generating simplified English sentences. To generate a simplified sentence, the proposed architecture uses either word embeddings (i.e., Word2Vec) and perplexity, or sentence transformers (i.e., BERT, RoBERTa, and GPT2) and cosine similarity. The solution is incorporated into a user-friendly and simple-to-use software. We evaluate our system using two metrics, i.e., SARI, and Perplexity Decrease. Experimentally, we observe that the transformer models outperform the other models in terms of the SARI score. However, in terms of Perplexity, the Word-Embeddings-",
    "link": "http://arxiv.org/abs/2304.07002",
    "context": "Title: SimpLex: a lexical text simplification architecture. (arXiv:2304.07002v1 [cs.CL])\nAbstract: Text simplification (TS) is the process of generating easy-to-understand sentences from a given sentence or piece of text. The aim of TS is to reduce both the lexical (which refers to vocabulary complexity and meaning) and syntactic (which refers to the sentence structure) complexity of a given text or sentence without the loss of meaning or nuance. In this paper, we present \\textsc{SimpLex}, a novel simplification architecture for generating simplified English sentences. To generate a simplified sentence, the proposed architecture uses either word embeddings (i.e., Word2Vec) and perplexity, or sentence transformers (i.e., BERT, RoBERTa, and GPT2) and cosine similarity. The solution is incorporated into a user-friendly and simple-to-use software. We evaluate our system using two metrics, i.e., SARI, and Perplexity Decrease. Experimentally, we observe that the transformer models outperform the other models in terms of the SARI score. However, in terms of Perplexity, the Word-Embeddings-",
    "path": "papers/23/04/2304.07002.json",
    "total_tokens": 959,
    "translated_title": "SimpLex：一种词汇文本简化架构",
    "translated_abstract": "文本简化是将给定句子或文本生成易于理解的句子的过程。简化的目的是在不损失含义或细微差别的情况下减少给定文本或句子的词汇和语法复杂性。在本文中，我们介绍了SimpLex，一种用于生成简化英文句子的新型简化架构。为了生成简化句子，所提出的架构使用词嵌入（即Word2Vec）和困惑度或句子转换器（即BERT、RoBERTa和GPT2）和余弦相似度之一。该解决方案集成到一个用户友好的、易于使用的软件中。我们使用两个指标（即SARI和困惑度降低）评估了我们的系统。从实验角度来看，我们观察到变压器模型在SARI得分方面优于其他模型。然而，从困惑度方面来看，基于词嵌入的模型表现更好。",
    "tldr": "SimpLex是一种用于生成简化英文句子的新型简化架构，它使用词嵌入或句子转换器来生成简化句子并集成到易用的软件中。实验结果中发现，变压器模型在SARI得分方面表现优异，而基于词嵌入的模型则在困惑度方面表现更好。",
    "en_tdlr": "SimpLex is a novel simplification architecture for generating simplified English sentences using either word embeddings or sentence transformers, and incorporated into user-friendly software. Experimentally, transformer models perform better in terms of the SARI score, while the word-embeddings-based model performs better in perplexity."
}