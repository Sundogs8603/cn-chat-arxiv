{
    "title": "QuMoS: A Framework for Preserving Security of Quantum Machine Learning Model. (arXiv:2304.11511v1 [quant-ph])",
    "abstract": "Security has always been a critical issue in machine learning (ML) applications. Due to the high cost of model training -- such as collecting relevant samples, labeling data, and consuming computing power -model-stealing attack is one of the most fundamental but vitally important issues. When it comes to quantum computing, such a quantum machine learning (QML) model-stealing attack also exists and it is even more severe because the traditional encryption method can hardly be directly applied to quantum computation. On the other hand, due to the limited quantum computing resources, the monetary cost of training QML model can be even higher than classical ones in the near term. Therefore, a well-tuned QML model developed by a company can be delegated to a quantum cloud provider as a service to be used by ordinary users. In this case, the QML model will be leaked if the cloud provider is under attack. To address such a problem, we propose a novel framework, namely QuMoS, to preserve mod",
    "link": "http://arxiv.org/abs/2304.11511",
    "context": "Title: QuMoS: A Framework for Preserving Security of Quantum Machine Learning Model. (arXiv:2304.11511v1 [quant-ph])\nAbstract: Security has always been a critical issue in machine learning (ML) applications. Due to the high cost of model training -- such as collecting relevant samples, labeling data, and consuming computing power -model-stealing attack is one of the most fundamental but vitally important issues. When it comes to quantum computing, such a quantum machine learning (QML) model-stealing attack also exists and it is even more severe because the traditional encryption method can hardly be directly applied to quantum computation. On the other hand, due to the limited quantum computing resources, the monetary cost of training QML model can be even higher than classical ones in the near term. Therefore, a well-tuned QML model developed by a company can be delegated to a quantum cloud provider as a service to be used by ordinary users. In this case, the QML model will be leaked if the cloud provider is under attack. To address such a problem, we propose a novel framework, namely QuMoS, to preserve mod",
    "path": "papers/23/04/2304.11511.json",
    "total_tokens": 1109,
    "translated_title": "QuMoS: 保护量子机器学习模型安全的框架",
    "translated_abstract": "安全性一直是机器学习应用中的重要问题。由于模型训练的高成本，如收集相关样本、标记数据和消耗计算资源等，模型窃取攻击是最基本但至关重要的问题之一。而在量子计算中，这样的量子机器学习（QML）模型窃取攻击也存在，甚至更加严重，因为传统的加密方法很难直接应用于量子计算。另一方面，由于有限的量子计算资源，近期培训 QML 模型的货币成本甚至可能比经典模型更高。因此，一家公司开发的经过良好调整的 QML 模型可以被委派给量子云提供商作为服务，供普通用户使用。在这种情况下，如果云提供商受到攻击，QML 模型将泄漏。为了解决这个问题，我们提出了一个新的框架，即 QuMoS，用于保护 QML 模型的安全性。QuMoS 包括一系列技术，包括经典加密、量子混淆和诱饵样本，以防止模型窃取攻击。我们还提供了使用 PennyLane 软件库和 Google Cirq 包的具体 QuMoS 实现。模拟结果表明，我们的框架可以有效地防止 QML 模型被盗，同时保持高分类准确性。",
    "tldr": "QuMoS是一个保护 QML 模型安全的框架，通过经典加密、量子混淆和诱饵样本等多种技术来保护模型免受窃取攻击，并具有较高的分类准确性。",
    "en_tdlr": "QuMoS is a framework that protects QML model security by using techniques such as classical encryption, quantum obfuscation, and decoy samples to prevent model stealing attacks, while maintaining high classification accuracy."
}