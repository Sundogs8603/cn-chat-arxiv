{
    "title": "Federated Compositional Deep AUC Maximization. (arXiv:2304.10101v1 [cs.LG])",
    "abstract": "Federated learning has attracted increasing attention due to the promise of balancing privacy and large-scale learning; numerous approaches have been proposed. However, most existing approaches focus on problems with balanced data, and prediction performance is far from satisfactory for many real-world applications where the number of samples in different classes is highly imbalanced. To address this challenging problem, we developed a novel federated learning method for imbalanced data by directly optimizing the area under curve (AUC) score. In particular, we formulate the AUC maximization problem as a federated compositional minimax optimization problem, develop a local stochastic compositional gradient descent ascent with momentum algorithm, and provide bounds on the computational and communication complexities of our algorithm. To the best of our knowledge, this is the first work to achieve such favorable theoretical results. Finally, extensive experimental results confirm the effi",
    "link": "http://arxiv.org/abs/2304.10101",
    "context": "Title: Federated Compositional Deep AUC Maximization. (arXiv:2304.10101v1 [cs.LG])\nAbstract: Federated learning has attracted increasing attention due to the promise of balancing privacy and large-scale learning; numerous approaches have been proposed. However, most existing approaches focus on problems with balanced data, and prediction performance is far from satisfactory for many real-world applications where the number of samples in different classes is highly imbalanced. To address this challenging problem, we developed a novel federated learning method for imbalanced data by directly optimizing the area under curve (AUC) score. In particular, we formulate the AUC maximization problem as a federated compositional minimax optimization problem, develop a local stochastic compositional gradient descent ascent with momentum algorithm, and provide bounds on the computational and communication complexities of our algorithm. To the best of our knowledge, this is the first work to achieve such favorable theoretical results. Finally, extensive experimental results confirm the effi",
    "path": "papers/23/04/2304.10101.json",
    "total_tokens": 899,
    "translated_title": "联邦组合深度AUC最大化",
    "translated_abstract": "联邦学习由于平衡隐私和大规模学习的承诺而引起了越来越多的关注；已经提出了许多方法。然而，大多数现有方法都集中在处理平衡数据问题上，而在许多现实应用中，不同类别中的样本数量高度不平衡，导致预测性能远低于理想水平。为了解决这个具有挑战性的问题，我们开发了一种针对不平衡数据的新型联邦学习方法，通过直接优化曲线下面积（AUC）分数来提高预测性能。具体来说，我们将AUC最大化问题作为联邦组合最小最大优化问题进行了表述，并开发了本地随机组合梯度下降上升动量算法，并提供了我们算法的计算和通信复杂度的界限。据我们所知，这是第一个实现如此有利理论结果的工作。最后，广泛的实验结果证实了我们提出的方法的效率和有效性。",
    "tldr": "本论文介绍了一种通过直接优化AUC分数来解决联邦学习中不平衡数据问题的方法，并开发了一个随机组合梯度下降上升动量算法。通过广泛的实验验证，证实了该方法的效率和有效性。",
    "en_tdlr": "This paper introduces a novel federated learning method for addressing the problem of imbalanced data by directly optimizing the AUC score. A local stochastic compositional gradient descent ascent with momentum algorithm is developed and extensive experimental results confirm its efficiency and effectiveness."
}