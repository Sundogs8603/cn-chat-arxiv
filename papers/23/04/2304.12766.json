{
    "title": "Decoupling Quantile Representations from Loss Functions. (arXiv:2304.12766v1 [cs.LG])",
    "abstract": "The simultaneous quantile regression (SQR) technique has been used to estimate uncertainties for deep learning models, but its application is limited by the requirement that the solution at the median quantile ({\\tau} = 0.5) must minimize the mean absolute error (MAE). In this article, we address this limitation by demonstrating a duality between quantiles and estimated probabilities in the case of simultaneous binary quantile regression (SBQR). This allows us to decouple the construction of quantile representations from the loss function, enabling us to assign an arbitrary classifier f(x) at the median quantile and generate the full spectrum of SBQR quantile representations at different {\\tau} values. We validate our approach through two applications: (i) detecting out-of-distribution samples, where we show that quantile representations outperform standard probability outputs, and (ii) calibrating models, where we demonstrate the robustness of quantile representations to distortions. ",
    "link": "http://arxiv.org/abs/2304.12766",
    "context": "Title: Decoupling Quantile Representations from Loss Functions. (arXiv:2304.12766v1 [cs.LG])\nAbstract: The simultaneous quantile regression (SQR) technique has been used to estimate uncertainties for deep learning models, but its application is limited by the requirement that the solution at the median quantile ({\\tau} = 0.5) must minimize the mean absolute error (MAE). In this article, we address this limitation by demonstrating a duality between quantiles and estimated probabilities in the case of simultaneous binary quantile regression (SBQR). This allows us to decouple the construction of quantile representations from the loss function, enabling us to assign an arbitrary classifier f(x) at the median quantile and generate the full spectrum of SBQR quantile representations at different {\\tau} values. We validate our approach through two applications: (i) detecting out-of-distribution samples, where we show that quantile representations outperform standard probability outputs, and (ii) calibrating models, where we demonstrate the robustness of quantile representations to distortions. ",
    "path": "papers/23/04/2304.12766.json",
    "total_tokens": 878,
    "translated_title": "从损失函数中解耦分位数表达式",
    "translated_abstract": "同时量化回归（SQR）技术用于估计深度学习模型的不确定性，但其应用受限于要求中位数分位数（τ = 0.5）处的解决方案必须最小化平均绝对误差（MAE）。本文通过展示同时二元量化回归（SBQR）中分位数与预测概率的二元对偶性来解决此问题。这使我们能够从损失函数中解耦分位数表达式的构造，使我们能够在中位分位数处分配任意分类器f(x)，并生成不同τ值的完整SBQR分位数表示的全谱。我们通过两个应用程序验证了我们的方法：（i）检测超出分布样本，其中我们显示分位数表示优于标准概率输出；（ii）调整模型，在这里，我们证明了分位数表示对失真的鲁棒性。",
    "tldr": "本文提出了同时二元量化回归（SBQR）中分位数与预测概率的二元对偶性，使分位数表达式在不同tau值下的构造不再依赖于损失函数，从而在处理检测超出分布样本和调整模型方面表现突出。",
    "en_tdlr": "This paper proposes a duality between quantiles and estimated probabilities in simultaneous binary quantile regression, which allows for the construction of quantile representations independent of the loss function and thus achieves better performance in detecting out-of-distribution samples and calibrating models."
}