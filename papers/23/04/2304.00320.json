{
    "title": "Doubly Stochastic Models: Learning with Unbiased Label Noises and Inference Stability. (arXiv:2304.00320v1 [cs.LG])",
    "abstract": "Random label noises (or observational noises) widely exist in practical machine learning settings. While previous studies primarily focus on the affects of label noises to the performance of learning, our work intends to investigate the implicit regularization effects of the label noises, under mini-batch sampling settings of stochastic gradient descent (SGD), with assumptions that label noises are unbiased. Specifically, we analyze the learning dynamics of SGD over the quadratic loss with unbiased label noises, where we model the dynamics of SGD as a stochastic differentiable equation (SDE) with two diffusion terms (namely a Doubly Stochastic Model). While the first diffusion term is caused by mini-batch sampling over the (label-noiseless) loss gradients as many other works on SGD, our model investigates the second noise term of SGD dynamics, which is caused by mini-batch sampling over the label noises, as an implicit regularizer. Our theoretical analysis finds such implicit regulariz",
    "link": "http://arxiv.org/abs/2304.00320",
    "context": "Title: Doubly Stochastic Models: Learning with Unbiased Label Noises and Inference Stability. (arXiv:2304.00320v1 [cs.LG])\nAbstract: Random label noises (or observational noises) widely exist in practical machine learning settings. While previous studies primarily focus on the affects of label noises to the performance of learning, our work intends to investigate the implicit regularization effects of the label noises, under mini-batch sampling settings of stochastic gradient descent (SGD), with assumptions that label noises are unbiased. Specifically, we analyze the learning dynamics of SGD over the quadratic loss with unbiased label noises, where we model the dynamics of SGD as a stochastic differentiable equation (SDE) with two diffusion terms (namely a Doubly Stochastic Model). While the first diffusion term is caused by mini-batch sampling over the (label-noiseless) loss gradients as many other works on SGD, our model investigates the second noise term of SGD dynamics, which is caused by mini-batch sampling over the label noises, as an implicit regularizer. Our theoretical analysis finds such implicit regulariz",
    "path": "papers/23/04/2304.00320.json",
    "total_tokens": 884,
    "translated_title": "双重随机模型：无偏标签噪声的学习与推理稳定",
    "translated_abstract": "随机标签噪声广泛存在于实际机器学习环境中。我们的工作旨在研究标签噪声的隐含正则化效应，假设标签噪声是无偏的，分析了SGD在无偏标签噪声下的学习动态，并将SGD的动态建模为具有两个扩散项的随机可微方程（即双重随机模型）。我们的理论分析发现，这种隐含正则化可以在学到的模型上实施双重随机结构，从而提高鲁棒性和泛化性能。在合成和真实数据集上的实证验证表明，在各种类型和水平的标签噪声下，我们的方法可以实现最先进的性能。",
    "tldr": "本文探讨了无偏标签噪声的隐含正则化效应，提出了一种将SGD的动态建模为双重随机模型的方法，可提高鲁棒性和泛化性能。",
    "en_tdlr": "This paper investigates the implicit regularization effects of unbiased label noises and proposes a method to model the dynamics of stochastic gradient descent as a Doubly Stochastic Model. The proposed approach improves robustness and generalization performance."
}