{
    "title": "Fair-CDA: Continuous and Directional Augmentation for Group Fairness. (arXiv:2304.00295v1 [cs.LG])",
    "abstract": "In this work, we propose {\\it Fair-CDA}, a fine-grained data augmentation strategy for imposing fairness constraints. We use a feature disentanglement method to extract the features highly related to the sensitive attributes. Then we show that group fairness can be achieved by regularizing the models on transition paths of sensitive features between groups. By adjusting the perturbation strength in the direction of the paths, our proposed augmentation is controllable and auditable. To alleviate the accuracy degradation caused by fairness constraints, we further introduce a calibrated model to impute labels for the augmented data. Our proposed method does not assume any data generative model and ensures good generalization for both accuracy and fairness. Experimental results show that Fair-CDA consistently outperforms state-of-the-art methods on widely-used benchmarks, e.g., Adult, CelebA and MovieLens. Especially, Fair-CDA obtains an 86.3\\% relative improvement for fairness while maint",
    "link": "http://arxiv.org/abs/2304.00295",
    "context": "Title: Fair-CDA: Continuous and Directional Augmentation for Group Fairness. (arXiv:2304.00295v1 [cs.LG])\nAbstract: In this work, we propose {\\it Fair-CDA}, a fine-grained data augmentation strategy for imposing fairness constraints. We use a feature disentanglement method to extract the features highly related to the sensitive attributes. Then we show that group fairness can be achieved by regularizing the models on transition paths of sensitive features between groups. By adjusting the perturbation strength in the direction of the paths, our proposed augmentation is controllable and auditable. To alleviate the accuracy degradation caused by fairness constraints, we further introduce a calibrated model to impute labels for the augmented data. Our proposed method does not assume any data generative model and ensures good generalization for both accuracy and fairness. Experimental results show that Fair-CDA consistently outperforms state-of-the-art methods on widely-used benchmarks, e.g., Adult, CelebA and MovieLens. Especially, Fair-CDA obtains an 86.3\\% relative improvement for fairness while maint",
    "path": "papers/23/04/2304.00295.json",
    "total_tokens": 1012,
    "translated_title": "公平连续和定向增强组的完美数据增强策略",
    "translated_abstract": "本文提出了一种细致的数据增强策略——公平连续和定向增强（Fair-CDA），以实现对公平性约束的实施。我们使用特征解缠方法提取与敏感属性高度相关的特征，然后通过在组之间的敏感特征转换路径上正则化模型，展示了可以实现组公平性。通过调整路径方向上的扰动强度，我们的提出的增强方法是可控和可审计的。为了缓解公平性约束导致的准确率下降，我们进一步引入了一个校准模型来为增强数据填补标签。我们的方法不假设任何数据生成模型，并确保对准确性和公平性实现良好的泛化。实验结果表明，Fair-CDA在广泛使用的基准测试中始终优于最先进的方法，如Adult、CelebA和MovieLens。特别是，Fair-CDA在公平方面获得了86.3％的相对改善，同时保持了准确性。",
    "tldr": "本文提出了一种公平连续和定向增强（Fair-CDA）的细致的数据增强策略，通过正则化模型展示了可以实现组公平性，并通过调整路径方向上的扰动强度实现了可控和可审计的增强方法。实验结果表明，Fair-CDA在广泛使用的基准测试中始终优于最先进的方法，如Adult、CelebA和MovieLens。"
}