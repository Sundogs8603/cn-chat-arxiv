{
    "title": "Proto-Value Networks: Scaling Representation Learning with Auxiliary Tasks. (arXiv:2304.12567v1 [cs.LG])",
    "abstract": "Auxiliary tasks improve the representations learned by deep reinforcement learning agents. Analytically, their effect is reasonably well understood; in practice, however, their primary use remains in support of a main learning objective, rather than as a method for learning representations. This is perhaps surprising given that many auxiliary tasks are defined procedurally, and hence can be treated as an essentially infinite source of information about the environment. Based on this observation, we study the effectiveness of auxiliary tasks for learning rich representations, focusing on the setting where the number of tasks and the size of the agent's network are simultaneously increased. For this purpose, we derive a new family of auxiliary tasks based on the successor measure. These tasks are easy to implement and have appealing theoretical properties. Combined with a suitable off-policy learning rule, the result is a representation learning algorithm that can be understood as extend",
    "link": "http://arxiv.org/abs/2304.12567",
    "context": "Title: Proto-Value Networks: Scaling Representation Learning with Auxiliary Tasks. (arXiv:2304.12567v1 [cs.LG])\nAbstract: Auxiliary tasks improve the representations learned by deep reinforcement learning agents. Analytically, their effect is reasonably well understood; in practice, however, their primary use remains in support of a main learning objective, rather than as a method for learning representations. This is perhaps surprising given that many auxiliary tasks are defined procedurally, and hence can be treated as an essentially infinite source of information about the environment. Based on this observation, we study the effectiveness of auxiliary tasks for learning rich representations, focusing on the setting where the number of tasks and the size of the agent's network are simultaneously increased. For this purpose, we derive a new family of auxiliary tasks based on the successor measure. These tasks are easy to implement and have appealing theoretical properties. Combined with a suitable off-policy learning rule, the result is a representation learning algorithm that can be understood as extend",
    "path": "papers/23/04/2304.12567.json",
    "total_tokens": 805,
    "translated_title": "Proto-Value Networks: 通过辅助任务进行表示学习的可扩展性研究",
    "translated_abstract": "辅助任务可以提高深度强化学习代理学到的表示能力。尽管其效果已经被相当充分地理论分析，但在实践中，它们主要被用作主要学习目标的支持，而不是作为表示学习的一种方法。基于这一观察，本文研究了辅助任务在学习复杂表示方面的有效性，重点关注同时增加任务数量和代理网络的大小的设置。为此，我们提出了一种基于后继度量的新型辅助任务家族。这些任务易于实现，具有吸引人的理论性质。与合适的离线学习规则结合使用，结果是一个表示学习算法，可以被理解为 Proto-Value 网络。",
    "tldr": "本文研究了如何通过增加辅助任务的数量和代理网络的大小，提高表示学习的效果。同时，本文还提出了基于后继度量的新型辅助任务家族 Proto-Value 网络。"
}