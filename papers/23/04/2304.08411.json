{
    "title": "Evil from Within: Machine Learning Backdoors through Hardware Trojans. (arXiv:2304.08411v2 [cs.CR] UPDATED)",
    "abstract": "Backdoors pose a serious threat to machine learning, as they can compromise the integrity of security-critical systems, such as self-driving cars. While different defenses have been proposed to address this threat, they all rely on the assumption that the hardware on which the learning models are executed during inference is trusted. In this paper, we challenge this assumption and introduce a backdoor attack that completely resides within a common hardware accelerator for machine learning. Outside of the accelerator, neither the learning model nor the software is manipulated, so that current defenses fail. To make this attack practical, we overcome two challenges: First, as memory on a hardware accelerator is severely limited, we introduce the concept of a minimal backdoor that deviates as little as possible from the original model and is activated by replacing a few model parameters only. Second, we develop a configurable hardware trojan that can be provisioned with the backdoor and p",
    "link": "http://arxiv.org/abs/2304.08411",
    "context": "Title: Evil from Within: Machine Learning Backdoors through Hardware Trojans. (arXiv:2304.08411v2 [cs.CR] UPDATED)\nAbstract: Backdoors pose a serious threat to machine learning, as they can compromise the integrity of security-critical systems, such as self-driving cars. While different defenses have been proposed to address this threat, they all rely on the assumption that the hardware on which the learning models are executed during inference is trusted. In this paper, we challenge this assumption and introduce a backdoor attack that completely resides within a common hardware accelerator for machine learning. Outside of the accelerator, neither the learning model nor the software is manipulated, so that current defenses fail. To make this attack practical, we overcome two challenges: First, as memory on a hardware accelerator is severely limited, we introduce the concept of a minimal backdoor that deviates as little as possible from the original model and is activated by replacing a few model parameters only. Second, we develop a configurable hardware trojan that can be provisioned with the backdoor and p",
    "path": "papers/23/04/2304.08411.json",
    "total_tokens": 804,
    "translated_title": "来自内部的邪恶: 通过硬件木马进行机器学习后门攻击",
    "translated_abstract": "后门会对机器学习造成严重威胁，因为它们可能破坏安全关键的系统，如自动驾驶汽车。本文介绍了一种后门攻击方法，完全居于用于机器学习的常见硬件加速器内，从而对当前防御措施构成挑战。为了使这种攻击实用，我们克服了两个挑战：首先，由于硬件加速器上的存储空间严重受限，因此我们引入了所谓的最小后门概念，只改变少量模型参数即可激活后门。其次，我们开发了一种可配置的硬件木马，可以与后门一起使用。",
    "tldr": "本文介绍了一种在常见机器学习硬件加速器内的后门攻击方法，将最小后门概念和可配置的硬件木马结合使用，从而对目前的防御措施构成挑战。"
}