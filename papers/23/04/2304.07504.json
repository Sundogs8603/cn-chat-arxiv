{
    "title": "Stochastic Distributed Optimization under Average Second-order Similarity: Algorithms and Analysis. (arXiv:2304.07504v1 [cs.LG])",
    "abstract": "We study finite-sum distributed optimization problems with $n$-clients under popular $\\delta$-similarity condition and $\\mu$-strong convexity. We propose two new algorithms: SVRS and AccSVRS motivated by previous works. The non-accelerated SVRS method combines the techniques of gradient-sliding and variance reduction, which achieves superior communication complexity $\\tilde{\\gO}(n {+} \\sqrt{n}\\delta/\\mu)$ compared to existing non-accelerated algorithms. Applying the framework proposed in Katyusha X, we also build a direct accelerated practical version named AccSVRS with totally smoothness-free $\\tilde{\\gO}(n {+} n^{3/4}\\sqrt{\\delta/\\mu})$ communication complexity that improves upon existing algorithms on ill-conditioning cases. Furthermore, we show a nearly matched lower bound to verify the tightness of our AccSVRS method.",
    "link": "http://arxiv.org/abs/2304.07504",
    "context": "Title: Stochastic Distributed Optimization under Average Second-order Similarity: Algorithms and Analysis. (arXiv:2304.07504v1 [cs.LG])\nAbstract: We study finite-sum distributed optimization problems with $n$-clients under popular $\\delta$-similarity condition and $\\mu$-strong convexity. We propose two new algorithms: SVRS and AccSVRS motivated by previous works. The non-accelerated SVRS method combines the techniques of gradient-sliding and variance reduction, which achieves superior communication complexity $\\tilde{\\gO}(n {+} \\sqrt{n}\\delta/\\mu)$ compared to existing non-accelerated algorithms. Applying the framework proposed in Katyusha X, we also build a direct accelerated practical version named AccSVRS with totally smoothness-free $\\tilde{\\gO}(n {+} n^{3/4}\\sqrt{\\delta/\\mu})$ communication complexity that improves upon existing algorithms on ill-conditioning cases. Furthermore, we show a nearly matched lower bound to verify the tightness of our AccSVRS method.",
    "path": "papers/23/04/2304.07504.json",
    "total_tokens": 894,
    "translated_title": "基于平均二阶相似性的随机分布式优化：算法与分析",
    "translated_abstract": "本文研究了具有$n$个客户端的有限和分布式优化问题，满足流行的$\\delta$-相似性条件和$\\mu$-强凸性。我们提出了两种新算法：SVRS和AccSVRS，启发自先前的工作。非加速的SVRS方法结合了梯度滑动和方差缩减技术，实现了卓越的通信复杂度$\\tilde{\\gO}(n {+} \\sqrt{n}\\delta/\\mu)$，与现有的非加速算法相比有所提高。应用Katyusha X提出的框架，我们还建立了一个名为AccSVRS的直接加速实际版本，其完全无平滑性，通信复杂度为$\\tilde{\\gO}(n {+} n^{3/4}\\sqrt{\\delta/\\mu})$，在病态情况下优于现有算法。此外，我们展示了一种接近匹配的下界，以验证我们的AccSVRS方法的紧密程度。",
    "tldr": "本文提出了两种新算法SVRS和AccSVRS，针对分布式优化问题，实现了卓越的通信复杂度。其中，AccSVRS算法实现了完全无平滑性，通信复杂度更是优于现有算法。",
    "en_tdlr": "This paper proposes two new algorithms, SVRS and AccSVRS, for distributed optimization problems with superior communication complexity. The AccSVRS algorithm achieves totally smoothness-free communication complexity, which outperforms existing algorithms, even in ill-conditioning cases."
}