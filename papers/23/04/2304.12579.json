{
    "title": "Learning Trajectories are Generalization Indicators. (arXiv:2304.12579v1 [cs.LG])",
    "abstract": "The aim of this paper is to investigate the connection between learning trajectories of the Deep Neural Networks (DNNs) and their corresponding generalization capabilities when being optimized with broadly used gradient descent and stochastic gradient descent algorithms. In this paper, we construct Linear Approximation Function to model the trajectory information and we propose a new generalization bound with richer trajectory information based on it. Our proposed generalization bound relies on the complexity of learning trajectory and the ratio between the bias and diversity of training set. Experimental results indicate that the proposed method effectively captures the generalization trend across various training steps, learning rates, and label noise levels.",
    "link": "http://arxiv.org/abs/2304.12579",
    "context": "Title: Learning Trajectories are Generalization Indicators. (arXiv:2304.12579v1 [cs.LG])\nAbstract: The aim of this paper is to investigate the connection between learning trajectories of the Deep Neural Networks (DNNs) and their corresponding generalization capabilities when being optimized with broadly used gradient descent and stochastic gradient descent algorithms. In this paper, we construct Linear Approximation Function to model the trajectory information and we propose a new generalization bound with richer trajectory information based on it. Our proposed generalization bound relies on the complexity of learning trajectory and the ratio between the bias and diversity of training set. Experimental results indicate that the proposed method effectively captures the generalization trend across various training steps, learning rates, and label noise levels.",
    "path": "papers/23/04/2304.12579.json",
    "total_tokens": 781,
    "translated_title": "学习轨迹是泛化指标",
    "translated_abstract": "本文旨在研究深度神经网络（DNN）的学习轨迹与其在广泛使用的梯度下降和随机梯度下降算法优化时对应的泛化能力之间的联系。本文构建了线性近似函数来模拟轨迹信息，并在此基础上提出了一种基于更丰富轨迹信息的新的泛化上界。我们提出的泛化上界依赖于学习轨迹的复杂性以及训练集的偏置和多样性比之间的比率。实验结果表明，该方法可以有效地捕捉不同训练步骤、学习率和标签噪声水平下的泛化趋势。",
    "tldr": "本文研究了DNN的学习轨迹与其在优化后的泛化能力的联系，提出了一种基于学习轨迹复杂性和训练集偏置和多样性比率的新的泛化上界，并通过实验验证了其有效性。",
    "en_tdlr": "This paper investigates the relationship between the learning trajectories of Deep Neural Networks (DNNs) and their corresponding generalization capabilities when optimized with gradient descent and stochastic gradient descent algorithms. The authors propose a new generalization bound based on the complexity of the learning trajectory and the ratio between the bias and diversity of the training set. Experimental results demonstrate the effectiveness of the proposed method."
}