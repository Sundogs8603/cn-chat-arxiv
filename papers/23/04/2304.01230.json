{
    "title": "SEENN: Towards Temporal Spiking Early-Exit Neural Networks. (arXiv:2304.01230v1 [cs.NE])",
    "abstract": "Spiking Neural Networks (SNNs) have recently become more popular as a biologically plausible substitute for traditional Artificial Neural Networks (ANNs). SNNs are cost-efficient and deployment-friendly because they process input in both spatial and temporal manners using binary spikes. However, we observe that the information capacity in SNNs is affected by the number of timesteps, leading to an accuracy-efficiency tradeoff. In this work, we study a fine-grained adjustment of the number of timesteps in SNNs. Specifically, we treat the number of timesteps as a variable conditioned on different input samples to reduce redundant timesteps for certain data. We call our method Spiking Early-Exit Neural Networks (SEENNs). To determine the appropriate number of timesteps, we propose SEENN-I which uses a confidence score thresholding to filter out the uncertain predictions, and SEENN-II which determines the number of timesteps by reinforcement learning. Moreover, we demonstrate that SEENN is ",
    "link": "http://arxiv.org/abs/2304.01230",
    "context": "Title: SEENN: Towards Temporal Spiking Early-Exit Neural Networks. (arXiv:2304.01230v1 [cs.NE])\nAbstract: Spiking Neural Networks (SNNs) have recently become more popular as a biologically plausible substitute for traditional Artificial Neural Networks (ANNs). SNNs are cost-efficient and deployment-friendly because they process input in both spatial and temporal manners using binary spikes. However, we observe that the information capacity in SNNs is affected by the number of timesteps, leading to an accuracy-efficiency tradeoff. In this work, we study a fine-grained adjustment of the number of timesteps in SNNs. Specifically, we treat the number of timesteps as a variable conditioned on different input samples to reduce redundant timesteps for certain data. We call our method Spiking Early-Exit Neural Networks (SEENNs). To determine the appropriate number of timesteps, we propose SEENN-I which uses a confidence score thresholding to filter out the uncertain predictions, and SEENN-II which determines the number of timesteps by reinforcement learning. Moreover, we demonstrate that SEENN is ",
    "path": "papers/23/04/2304.01230.json",
    "total_tokens": 961,
    "translated_title": "SEENN: 实现时间编码早期退出神经网络的研究",
    "translated_abstract": "脉冲神经网络（SNNs）因其生物学特性成为传统人工神经网络（ANNs）的替代品，最近变得越来越流行。SNNs既费用效益又易于部署，因为它们可以用二进制脉冲以空间和时间方式处理输入。然而，我们观察到SNNs中的信息容量受到时间步骤数量的影响，导致准确性和效率的权衡。在本研究中，我们研究了SNNs中时间步骤数量的细粒度调整。具体地，我们将时间步数视为一个变量，针对不同的输入样本来减少冗余时间步骤。我们称这种方法为早期退出脉冲神经网络（SEENN）。为了确定适当的时间步数，我们提出了SEENN-I，它使用置信度阈值来过滤不确定的预测，以及SEENN-II，它通过强化学习确定时间步骤的数量。此外，我们证明SEENN比传统SNNs更有效，并在几个基准数据集上实现了最先进的准确性。",
    "tldr": "本研究提出了一种名为SEENN的方法，通过对时间步数进行细粒度调整，以减少不必要的计算并提高有效性。同时，SEENN达到了多个基准数据集的最先进准确度表现。",
    "en_tdlr": "This paper proposes a method named SEENN which fine-tunes the number of timesteps in SNNs to improve efficiency while maintaining high accuracy on benchmark datasets. SEENN achieves state-of-the-art performance and reduces unnecessary computations."
}