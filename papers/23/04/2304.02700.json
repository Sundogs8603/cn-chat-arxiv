{
    "title": "Agnostic proper learning of monotone functions: beyond the black-box correction barrier. (arXiv:2304.02700v1 [cs.DS])",
    "abstract": "We give the first agnostic, efficient, proper learning algorithm for monotone Boolean functions. Given $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$ uniformly random examples of an unknown function $f:\\{\\pm 1\\}^n \\rightarrow \\{\\pm 1\\}$, our algorithm outputs a hypothesis $g:\\{\\pm 1\\}^n \\rightarrow \\{\\pm 1\\}$ that is monotone and $(\\mathrm{opt} + \\varepsilon)$-close to $f$, where $\\mathrm{opt}$ is the distance from $f$ to the closest monotone function. The running time of the algorithm (and consequently the size and evaluation time of the hypothesis) is also $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$, nearly matching the lower bound of Blais et al (RANDOM '15). We also give an algorithm for estimating up to additive error $\\varepsilon$ the distance of an unknown function $f$ to monotone using a run-time of $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$. Previously, for both of these problems, sample-efficient algorithms were known, but these algorithms were not run-time efficient. Our work thus closes this g",
    "link": "http://arxiv.org/abs/2304.02700",
    "context": "Title: Agnostic proper learning of monotone functions: beyond the black-box correction barrier. (arXiv:2304.02700v1 [cs.DS])\nAbstract: We give the first agnostic, efficient, proper learning algorithm for monotone Boolean functions. Given $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$ uniformly random examples of an unknown function $f:\\{\\pm 1\\}^n \\rightarrow \\{\\pm 1\\}$, our algorithm outputs a hypothesis $g:\\{\\pm 1\\}^n \\rightarrow \\{\\pm 1\\}$ that is monotone and $(\\mathrm{opt} + \\varepsilon)$-close to $f$, where $\\mathrm{opt}$ is the distance from $f$ to the closest monotone function. The running time of the algorithm (and consequently the size and evaluation time of the hypothesis) is also $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$, nearly matching the lower bound of Blais et al (RANDOM '15). We also give an algorithm for estimating up to additive error $\\varepsilon$ the distance of an unknown function $f$ to monotone using a run-time of $2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$. Previously, for both of these problems, sample-efficient algorithms were known, but these algorithms were not run-time efficient. Our work thus closes this g",
    "path": "papers/23/04/2304.02700.json",
    "total_tokens": 1068,
    "translated_title": "无偏关于坡度函数的适当学习：越过黑盒修正障碍",
    "translated_abstract": "本文提出了第一个无偏、高效、适当的单调布尔函数学习算法。给定未知函数$f:\\{\\pm 1\\}^n \\rightarrow \\{\\pm 1\\}$的$2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$个均匀随机样本，算法输出一个假设$g:\\{\\pm 1\\}^n \\rightarrow \\{\\pm 1\\}$，该假设是单调的，并且与$f$的距离为$(\\mathrm{opt} + \\varepsilon)$，其中$\\mathrm{opt}$是$f$与最近单调函数之间的距离。算法的运行时间（因此也是假设的大小和评估时间）也是$2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$，几乎与Blais等人（RANDOM '15）的下界相匹配。我们还给出一个算法，用于估计未知函数$f$到单调性的添加误差$\\varepsilon$的距离，其运行时间为$2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$。以前，针对这两个问题，已知有样本有效的算法，但这些算法并不是运行时间有效的。因此，我们的工作解决了这个问题。",
    "tldr": "本文提出了第一个无偏、高效、适当的单调布尔函数学习算法，算法的运行时间和假设的大小和评估时间都为$2^{\\tilde{O}(\\sqrt{n}/\\varepsilon)}$，该算法解决了样本高效算法无法解决的问题。"
}