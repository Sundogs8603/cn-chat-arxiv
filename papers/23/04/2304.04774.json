{
    "title": "DDRF: Denoising Diffusion Model for Remote Sensing Image Fusion. (arXiv:2304.04774v1 [cs.CV])",
    "abstract": "Denosing diffusion model, as a generative model, has received a lot of attention in the field of image generation recently, thanks to its powerful generation capability. However, diffusion models have not yet received sufficient research in the field of image fusion. In this article, we introduce diffusion model to the image fusion field, treating the image fusion task as image-to-image translation and designing two different conditional injection modulation modules (i.e., style transfer modulation and wavelet modulation) to inject coarse-grained style information and fine-grained high-frequency and low-frequency information into the diffusion UNet, thereby generating fused images. In addition, we also discussed the residual learning and the selection of training objectives of the diffusion model in the image fusion task. Extensive experimental results based on quantitative and qualitative assessments compared with benchmarks demonstrates state-of-the-art results and good generalizatio",
    "link": "http://arxiv.org/abs/2304.04774",
    "context": "Title: DDRF: Denoising Diffusion Model for Remote Sensing Image Fusion. (arXiv:2304.04774v1 [cs.CV])\nAbstract: Denosing diffusion model, as a generative model, has received a lot of attention in the field of image generation recently, thanks to its powerful generation capability. However, diffusion models have not yet received sufficient research in the field of image fusion. In this article, we introduce diffusion model to the image fusion field, treating the image fusion task as image-to-image translation and designing two different conditional injection modulation modules (i.e., style transfer modulation and wavelet modulation) to inject coarse-grained style information and fine-grained high-frequency and low-frequency information into the diffusion UNet, thereby generating fused images. In addition, we also discussed the residual learning and the selection of training objectives of the diffusion model in the image fusion task. Extensive experimental results based on quantitative and qualitative assessments compared with benchmarks demonstrates state-of-the-art results and good generalizatio",
    "path": "papers/23/04/2304.04774.json",
    "total_tokens": 886,
    "translated_title": "DDRF: 远程感知图像融合的去噪扩散模型",
    "translated_abstract": "最近，作为一种生成模型，去噪扩散模型因其强大的生成能力，在图像生成领域受到了广泛关注。然而，扩散模型在图像融合领域内研究不足。本文将扩散模型引入到图像融合领域，将图像融合任务视为图像到图像的转换，设计了两种不同的条件注入调制模块（即风格转移调制和小波调制），以将粗粒度的风格信息和细粒度的高频和低频信息注入扩散UNet中，从而生成融合图像。此外，我们还讨论了扩散模型在图像融合任务中的残差学习和训练目标的选择。基于定量和定性评估的广泛实验结果与基准的比较表明了最新技术成果和良好的泛化性能。",
    "tldr": "本研究将去噪扩散模型引入远程感知图像融合，采用条件注入调制模块（风格转移调制和小波调制）将风格信息和频率信息注入扩散UNet，从而生成高质量融合图像。",
    "en_tdlr": "This study introduces the denoising diffusion model to the field of remote sensing image fusion, using conditional injection modulation modules (style transfer modulation and wavelet modulation) to inject style and frequency information into the diffusion UNet for generating high-quality fused images."
}