{
    "title": "Video alignment using unsupervised learning of local and global features. (arXiv:2304.06841v1 [cs.CV])",
    "abstract": "In this paper, we tackle the problem of video alignment, the process of matching the frames of a pair of videos containing similar actions. The main challenge in video alignment is that accurate correspondence should be established despite the differences in the execution processes and appearances between the two videos. We introduce an unsupervised method for alignment that uses global and local features of the frames. In particular, we introduce effective features for each video frame by means of three machine vision tools: person detection, pose estimation, and VGG network. Then the features are processed and combined to construct a multidimensional time series that represent the video. The resulting time series are used to align videos of the same actions using a novel version of dynamic time warping named Diagonalized Dynamic Time Warping(DDTW). The main advantage of our approach is that no training is required, which makes it applicable for any new type of action without any need",
    "link": "http://arxiv.org/abs/2304.06841",
    "context": "Title: Video alignment using unsupervised learning of local and global features. (arXiv:2304.06841v1 [cs.CV])\nAbstract: In this paper, we tackle the problem of video alignment, the process of matching the frames of a pair of videos containing similar actions. The main challenge in video alignment is that accurate correspondence should be established despite the differences in the execution processes and appearances between the two videos. We introduce an unsupervised method for alignment that uses global and local features of the frames. In particular, we introduce effective features for each video frame by means of three machine vision tools: person detection, pose estimation, and VGG network. Then the features are processed and combined to construct a multidimensional time series that represent the video. The resulting time series are used to align videos of the same actions using a novel version of dynamic time warping named Diagonalized Dynamic Time Warping(DDTW). The main advantage of our approach is that no training is required, which makes it applicable for any new type of action without any need",
    "path": "papers/23/04/2304.06841.json",
    "total_tokens": 856,
    "translated_title": "无监督学习局部和全局特征用于视频对齐",
    "translated_abstract": "本文致力于解决视频对齐的问题，即匹配包含相似活动的一对视频的帧。视频对齐的主要挑战在于，尽管两个视频之间的执行过程和外观有所不同，但仍需要建立精确的对应关系。我们提出了一种使用帧的全局和局部特征进行对齐的无监督方法。特别地，我们利用人物检测、姿态估计和VGG网络三种机器视觉工具为每个视频帧引入有效的特征。然后对这些特征进行处理和组合以构建代表视频的多维时间序列。使用一种名为对角化动态时间规整的新版本（Diagonalized Dynamic Time Warping, DDTW）对生成的时间序列进行对齐。我们的方法的主要优点在于不需要任何训练，因此适用于任何新类型的活动而无需处理。",
    "tldr": "本文提出了一种无需训练的视频对齐方法，利用全局和局部特征将帧转化为时间序列并使用对角化动态时间规整算法进行对齐。"
}