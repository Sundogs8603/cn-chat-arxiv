{
    "title": "ConvFormer: Parameter Reduction in Transformer Models for 3D Human Pose Estimation by Leveraging Dynamic Multi-Headed Convolutional Attention. (arXiv:2304.02147v1 [cs.CV])",
    "abstract": "Recently, fully-transformer architectures have replaced the defacto convolutional architecture for the 3D human pose estimation task. In this paper we propose \\textbf{\\textit{ConvFormer}}, a novel convolutional transformer that leverages a new \\textbf{\\textit{dynamic multi-headed convolutional self-attention}} mechanism for monocular 3D human pose estimation. We designed a spatial and temporal convolutional transformer to comprehensively model human joint relations within individual frames and globally across the motion sequence. Moreover, we introduce a novel notion of \\textbf{\\textit{temporal joints profile}} for our temporal ConvFormer that fuses complete temporal information immediately for a local neighborhood of joint features. We have quantitatively and qualitatively validated our method on three common benchmark datasets: Human3.6M, MPI-INF-3DHP, and HumanEva. Extensive experiments have been conducted to identify the optimal hyper-parameter set. These experiments demonstrated t",
    "link": "http://arxiv.org/abs/2304.02147",
    "context": "Title: ConvFormer: Parameter Reduction in Transformer Models for 3D Human Pose Estimation by Leveraging Dynamic Multi-Headed Convolutional Attention. (arXiv:2304.02147v1 [cs.CV])\nAbstract: Recently, fully-transformer architectures have replaced the defacto convolutional architecture for the 3D human pose estimation task. In this paper we propose \\textbf{\\textit{ConvFormer}}, a novel convolutional transformer that leverages a new \\textbf{\\textit{dynamic multi-headed convolutional self-attention}} mechanism for monocular 3D human pose estimation. We designed a spatial and temporal convolutional transformer to comprehensively model human joint relations within individual frames and globally across the motion sequence. Moreover, we introduce a novel notion of \\textbf{\\textit{temporal joints profile}} for our temporal ConvFormer that fuses complete temporal information immediately for a local neighborhood of joint features. We have quantitatively and qualitatively validated our method on three common benchmark datasets: Human3.6M, MPI-INF-3DHP, and HumanEva. Extensive experiments have been conducted to identify the optimal hyper-parameter set. These experiments demonstrated t",
    "path": "papers/23/04/2304.02147.json",
    "total_tokens": 1010,
    "translated_abstract": "最近，完全变压器架构取代了卷积架构成为了3D人体姿态估计任务的标准。在本文中，我们提出了一种新型的卷积变压器ConvFormer，它利用新的动态多头卷积自我注意机制进行单目3D人体姿态估计。我们设计了一个时空卷积变压器，以全面地建模单帧内和整个动作序列中的人体关节关系。此外，我们引入了一种新的“时间关节概要”概念，用于我们的时间ConvFormer，它可以立即将完整的时间信息融合到关节特征的本地邻域中。我们在三个常见的基准数据集Human3.6M，MPI-INF-3DHP和HumanEva上进行了量化和定性验证。大量实验已经进行，以确定最佳的超参数集。这些实验证明了我们的方法在精度和效率方面的优越性。",
    "tldr": "本文提出了ConvFormer，一种新型的卷积变压器，采用了动态多头卷积自我注意机制，实现了3D人体姿态估计任务。方法基于空间和时间卷积变压器，全面建模了单帧内和整个动作序列中的人体关节关系，并引入了新的“时间关节概要”概念。在多个基准数据集上验证了该方法的优越性。",
    "en_tdlr": "This paper proposes a new convolutional transformer, ConvFormer, with dynamic multi-headed convolutional self-attention mechanism for monocular 3D human pose estimation. The method comprehensively models human joint relations within individual frames and globally across the motion sequence, and introduces a novel notion of \"temporal joints profile\". The experiments demonstrate the superiority of the method on multiple benchmark datasets."
}