{
    "title": "Architecture-Preserving Provable Repair of Deep Neural Networks. (arXiv:2304.03496v1 [cs.LG])",
    "abstract": "Deep neural networks (DNNs) are becoming increasingly important components of software, and are considered the state-of-the-art solution for a number of problems, such as image recognition. However, DNNs are far from infallible, and incorrect behavior of DNNs can have disastrous real-world consequences. This paper addresses the problem of architecture-preserving V-polytope provable repair of DNNs. A V-polytope defines a convex bounded polytope using its vertex representation. V-polytope provable repair guarantees that the repaired DNN satisfies the given specification on the infinite set of points in the given V-polytope. An architecture-preserving repair only modifies the parameters of the DNN, without modifying its architecture. The repair has the flexibility to modify multiple layers of the DNN, and runs in polynomial time. It supports DNNs with activation functions that have some linear pieces, as well as fully-connected, convolutional, pooling and residual layers. To the best our ",
    "link": "http://arxiv.org/abs/2304.03496",
    "context": "Title: Architecture-Preserving Provable Repair of Deep Neural Networks. (arXiv:2304.03496v1 [cs.LG])\nAbstract: Deep neural networks (DNNs) are becoming increasingly important components of software, and are considered the state-of-the-art solution for a number of problems, such as image recognition. However, DNNs are far from infallible, and incorrect behavior of DNNs can have disastrous real-world consequences. This paper addresses the problem of architecture-preserving V-polytope provable repair of DNNs. A V-polytope defines a convex bounded polytope using its vertex representation. V-polytope provable repair guarantees that the repaired DNN satisfies the given specification on the infinite set of points in the given V-polytope. An architecture-preserving repair only modifies the parameters of the DNN, without modifying its architecture. The repair has the flexibility to modify multiple layers of the DNN, and runs in polynomial time. It supports DNNs with activation functions that have some linear pieces, as well as fully-connected, convolutional, pooling and residual layers. To the best our ",
    "path": "papers/23/04/2304.03496.json",
    "total_tokens": 969,
    "translated_title": "深度神经网络的保体系结构可证明修复方法",
    "translated_abstract": "深度神经网络（DNNs）成为了软件中越来越重要的组成部分，并被认为是解决许多问题（如图像识别）的最先进解决方案。然而，DNN 远非不可错误，DNN 的不正确行为可能会在现实世界中造成灾难性后果。本文解决了保体系结构 V-多面体可证明修复 DNNs 的问题。V-多面体使用其顶点表示法定义了一个凸约束多面体。V-多面体可证明修复保证修复后的 DNN 满足给定 V-多面体中无限点集上的规范。体系结构保持修复仅修改 DNN 的参数，而不修改其体系结构。修复有灵活性，可以修改 DNN 的多个层，并在多项式时间内运行。它支持具有一些线性部分的激活函数，以及完全连接的、卷积的、池化的和残余层的 DNNs。据我们所知，这是第一篇提供 DNN 体系结构保持可证明修复的正式框架的论文。",
    "tldr": "本文提出了一种保体系结构 V-多面体可证明修复深度神经网络的方法。修复只修改 DNN 的参数，具有灵活性，支持多种类型的层，并在多项式时间内运行。",
    "en_tdlr": "This paper proposes a method for architecture-preserving V-polytope provable repair of deep neural networks, which only modifies the parameters of the DNN and supports various types of layers. It is the first work to provide a formal framework for architecture-preserving provable repair of DNNs."
}