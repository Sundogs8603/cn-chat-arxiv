{
    "title": "Supporting Qualitative Analysis with Large Language Models: Combining Codebook with GPT-3 for Deductive Coding. (arXiv:2304.10548v1 [cs.CL])",
    "abstract": "Qualitative analysis of textual contents unpacks rich and valuable information by assigning labels to the data. However, this process is often labor-intensive, particularly when working with large datasets. While recent AI-based tools demonstrate utility, researchers may not have readily available AI resources and expertise, let alone be challenged by the limited generalizability of those task-specific models. In this study, we explored the use of large language models (LLMs) in supporting deductive coding, a major category of qualitative analysis where researchers use pre-determined codebooks to label the data into a fixed set of codes. Instead of training task-specific models, a pre-trained LLM could be used directly for various tasks without fine-tuning through prompt learning. Using a curiosity-driven questions coding task as a case study, we found, by combining GPT-3 with expert-drafted codebooks, our proposed approach achieved fair to substantial agreements with expert-coded resu",
    "link": "http://arxiv.org/abs/2304.10548",
    "context": "Title: Supporting Qualitative Analysis with Large Language Models: Combining Codebook with GPT-3 for Deductive Coding. (arXiv:2304.10548v1 [cs.CL])\nAbstract: Qualitative analysis of textual contents unpacks rich and valuable information by assigning labels to the data. However, this process is often labor-intensive, particularly when working with large datasets. While recent AI-based tools demonstrate utility, researchers may not have readily available AI resources and expertise, let alone be challenged by the limited generalizability of those task-specific models. In this study, we explored the use of large language models (LLMs) in supporting deductive coding, a major category of qualitative analysis where researchers use pre-determined codebooks to label the data into a fixed set of codes. Instead of training task-specific models, a pre-trained LLM could be used directly for various tasks without fine-tuning through prompt learning. Using a curiosity-driven questions coding task as a case study, we found, by combining GPT-3 with expert-drafted codebooks, our proposed approach achieved fair to substantial agreements with expert-coded resu",
    "path": "papers/23/04/2304.10548.json",
    "total_tokens": 1048,
    "translated_title": "结合编码本和GPT-3支持定性分析的大语言模型",
    "translated_abstract": "对文本内容进行定性分析通过给数据打上标签揭示了丰富而有价值的信息。然而，处理大型数据集时，这个过程往往需要耗费大量人力资源。虽然最近的基于人工智能的工具展示了其实用性，但研究人员可能无法获得现成的人工智能资源和技术，更不必说挑战那些任务特定模型的有限泛化能力了。在本研究中，我们探讨了在支持演绎编码的情况下，使用大型语言模型（LLM）的可能性。演绎编码是定性分析的主要类别之一，研究人员使用预先确定的编码本将数据标记到一组固定的编码中。我们发现，使用基于好奇心驱动的问题编码任务作为案例研究，通过将GPT-3与专家制定的编码本相结合，我们的方法与专家编码结果实现了公平到相当大的一致性，并允许有效地进行编码本的优化。我们的研究发现结合LLM和演绎编码是定性分析的一个有前途的方向，并具有潜在的实践意义。",
    "tldr": "本研究探讨了使用大型语言模型来支持定性分析中的演绎编码。通过结合GPT-3和专家编写的编码本，研究人员成功地实现了与专家编码结果相近的标记结果，并且还允许进行高效和有效的编码本优化。",
    "en_tdlr": "This study explores the use of large language models for supporting deductive coding in qualitative analysis. By combining GPT-3 with expert-drafted codebooks, researchers achieved comparable labeling results to expert-coded results and allowed for efficient and effective codebook refinement. The integration of LLMs with deductive coding suggests promising directions for qualitative analysis with practical implications."
}