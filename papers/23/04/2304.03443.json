{
    "title": "AMS-DRL: Learning Multi-Pursuit Evasion for Safe Targeted Navigation of Drones. (arXiv:2304.03443v1 [cs.RO])",
    "abstract": "Safe navigation of drones in the presence of adversarial physical attacks from multiple pursuers is a challenging task. This paper proposes a novel approach, asynchronous multi-stage deep reinforcement learning (AMS-DRL), to train an adversarial neural network that can learn from the actions of multiple pursuers and adapt quickly to their behavior, enabling the drone to avoid attacks and reach its target. Our approach guarantees convergence by ensuring Nash Equilibrium among agents from the game-theory analysis. We evaluate our method in extensive simulations and show that it outperforms baselines with higher navigation success rates. We also analyze how parameters such as the relative maximum speed affect navigation performance. Furthermore, we have conducted physical experiments and validated the effectiveness of the trained policies in real-time flights. A success rate heatmap is introduced to elucidate how spatial geometry influences navigation outcomes. Project website: https://gi",
    "link": "http://arxiv.org/abs/2304.03443",
    "context": "Title: AMS-DRL: Learning Multi-Pursuit Evasion for Safe Targeted Navigation of Drones. (arXiv:2304.03443v1 [cs.RO])\nAbstract: Safe navigation of drones in the presence of adversarial physical attacks from multiple pursuers is a challenging task. This paper proposes a novel approach, asynchronous multi-stage deep reinforcement learning (AMS-DRL), to train an adversarial neural network that can learn from the actions of multiple pursuers and adapt quickly to their behavior, enabling the drone to avoid attacks and reach its target. Our approach guarantees convergence by ensuring Nash Equilibrium among agents from the game-theory analysis. We evaluate our method in extensive simulations and show that it outperforms baselines with higher navigation success rates. We also analyze how parameters such as the relative maximum speed affect navigation performance. Furthermore, we have conducted physical experiments and validated the effectiveness of the trained policies in real-time flights. A success rate heatmap is introduced to elucidate how spatial geometry influences navigation outcomes. Project website: https://gi",
    "path": "papers/23/04/2304.03443.json",
    "total_tokens": 867,
    "translated_title": "AMS-DRL: 学习多目标逃避以实现无人机安全导航",
    "translated_abstract": "在多个袭击者存在的情况下，无人机的安全导航是一项具有挑战性的任务。本文提出了一种新方法，异步多阶段深度强化学习(AMS-DRL)，来训练对抗性神经网络，该网络可以从多个攻击者的行动中学习和快速适应它们的行为，使无人机能够避免攻击并到达目标。我们的方法通过确保博弈论分析中的代理之间的Nash均衡来保证收敛性。我们在广泛的模拟中评估了我们的方法，并展示了它比基线方法具有更高的导航成功率。我们还分析了一些参数如相对最大速度如何影响导航性能。此外，我们进行了物理实验，并验证了实时飞行中受训策略的有效性。介绍了成功率热图，以说明空间几何对导航结果的影响。项目网站：https://gi",
    "tldr": "本文提出了AMS-DRL方法用于训练对抗性神经网络，以学习和快速适应多个攻击者的行为，从而实现无人机的安全导航和到达目标。",
    "en_tdlr": "This paper proposes the AMS-DRL approach for training an adversarial neural network to learn and quickly adapt to the behavior of multiple attackers, enabling safe navigation and reaching the target of a drone."
}