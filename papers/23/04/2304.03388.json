{
    "title": "EZClone: Improving DNN Model Extraction Attack via Shape Distillation from GPU Execution Profiles. (arXiv:2304.03388v1 [cs.LG])",
    "abstract": "Deep Neural Networks (DNNs) have become ubiquitous due to their performance on prediction and classification problems. However, they face a variety of threats as their usage spreads. Model extraction attacks, which steal DNNs, endanger intellectual property, data privacy, and security. Previous research has shown that system-level side-channels can be used to leak the architecture of a victim DNN, exacerbating these risks. We propose two DNN architecture extraction techniques catering to various threat models. The first technique uses a malicious, dynamically linked version of PyTorch to expose a victim DNN architecture through the PyTorch profiler. The second, called EZClone, exploits aggregate (rather than time-series) GPU profiles as a side-channel to predict DNN architecture, employing a simple approach and assuming little adversary capability as compared to previous work. We investigate the effectiveness of EZClone when minimizing the complexity of the attack, when applied to prun",
    "link": "http://arxiv.org/abs/2304.03388",
    "context": "Title: EZClone: Improving DNN Model Extraction Attack via Shape Distillation from GPU Execution Profiles. (arXiv:2304.03388v1 [cs.LG])\nAbstract: Deep Neural Networks (DNNs) have become ubiquitous due to their performance on prediction and classification problems. However, they face a variety of threats as their usage spreads. Model extraction attacks, which steal DNNs, endanger intellectual property, data privacy, and security. Previous research has shown that system-level side-channels can be used to leak the architecture of a victim DNN, exacerbating these risks. We propose two DNN architecture extraction techniques catering to various threat models. The first technique uses a malicious, dynamically linked version of PyTorch to expose a victim DNN architecture through the PyTorch profiler. The second, called EZClone, exploits aggregate (rather than time-series) GPU profiles as a side-channel to predict DNN architecture, employing a simple approach and assuming little adversary capability as compared to previous work. We investigate the effectiveness of EZClone when minimizing the complexity of the attack, when applied to prun",
    "path": "papers/23/04/2304.03388.json",
    "total_tokens": 956,
    "translated_title": "EZClone：通过GPU执行文件的形状精炼提高DNN模型提取攻击",
    "translated_abstract": "由于在预测和分类问题上表现出色，深度神经网络（DNN）已经变得无处不在。然而，随着它们的使用扩展，它们面临各种威胁。模型提取攻击窃取DNN会危及知识产权、数据隐私和安全。先前的研究表明，系统级侧信道可用于通过暴露受害者DNN的体系结构来泄露模型的细节，从而加剧这些风险。我们提出了两种针对不同威胁模型的DNN结构提取技术。第一种技术使用恶意的、动态链接的PyTorch版本，在通过PyTorch分析器暴露受害者DNN结构。第二种技术称为EZClone，利用聚合（而不是时间序列）GPU文件作为侧信道来预测DNN结构，使用简单的方法，假设攻击者的能力比先前的研究低。我们在最小化攻击复杂性的情况下调查了EZClone的有效性，并在多种模型和数据集上进行了实验。",
    "tldr": "本论文介绍了两种不同威胁模型下的DNN结构提取技术，其中EZClone利用聚合GPU文件作为侧信道来预测DNN结构，并且通过实验验证了其有效性。",
    "en_tdlr": "This paper proposes two DNN architecture extraction techniques catering to different threat models, among which EZClone leverages aggregate GPU profiles as a side-channel to predict DNN architecture, and it was experimentally validated to be effective while minimizing attack complexity."
}