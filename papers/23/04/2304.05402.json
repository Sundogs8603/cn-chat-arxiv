{
    "title": "Boosting Cross-task Transferability of Adversarial Patches with Visual Relations. (arXiv:2304.05402v1 [cs.CV])",
    "abstract": "The transferability of adversarial examples is a crucial aspect of evaluating the robustness of deep learning systems, particularly in black-box scenarios. Although several methods have been proposed to enhance cross-model transferability, little attention has been paid to the transferability of adversarial examples across different tasks. This issue has become increasingly relevant with the emergence of foundational multi-task AI systems such as Visual ChatGPT, rendering the utility of adversarial samples generated by a single task relatively limited. Furthermore, these systems often entail inferential functions beyond mere recognition-like tasks. To address this gap, we propose a novel Visual Relation-based cross-task Adversarial Patch generation method called VRAP, which aims to evaluate the robustness of various visual tasks, especially those involving visual reasoning, such as Visual Question Answering and Image Captioning. VRAP employs scene graphs to combine object recognition-b",
    "link": "http://arxiv.org/abs/2304.05402",
    "context": "Title: Boosting Cross-task Transferability of Adversarial Patches with Visual Relations. (arXiv:2304.05402v1 [cs.CV])\nAbstract: The transferability of adversarial examples is a crucial aspect of evaluating the robustness of deep learning systems, particularly in black-box scenarios. Although several methods have been proposed to enhance cross-model transferability, little attention has been paid to the transferability of adversarial examples across different tasks. This issue has become increasingly relevant with the emergence of foundational multi-task AI systems such as Visual ChatGPT, rendering the utility of adversarial samples generated by a single task relatively limited. Furthermore, these systems often entail inferential functions beyond mere recognition-like tasks. To address this gap, we propose a novel Visual Relation-based cross-task Adversarial Patch generation method called VRAP, which aims to evaluate the robustness of various visual tasks, especially those involving visual reasoning, such as Visual Question Answering and Image Captioning. VRAP employs scene graphs to combine object recognition-b",
    "path": "papers/23/04/2304.05402.json",
    "total_tokens": 939,
    "translated_title": "基于视觉关系的跨任务对抗贴片的转移增强方法",
    "translated_abstract": "对抗性样本的可转移性是评估深度学习系统鲁棒性的关键方面，尤其是在黑盒场景中，目前虽然提出了多种方法来增强跨模型的可转移性，但很少关注对抗样本在不同任务之间的可转移性。为了解决这一问题，我们提出了一种基于视觉关系的跨任务对抗贴片生成方法VRAP，旨在评估各种视觉任务的鲁棒性，特别是那些涉及视觉推理的任务，例如视觉问答和图像字幕生成。VRAP利用场景图将物体识别为基础的对抗贴片组合成更大更复杂的对抗贴片，从而扰乱目标模型的推理过程。实验结果表明，与单一任务贴片相比，VRAP生成的对抗贴片在任务间具有更高的可转移性，即使这些任务涉及不同的推理函数或输入格式。",
    "tldr": "VRAP是一种多任务的对抗贴片生成方法，利用场景图将物体识别为基础的对抗贴片组合成更大更复杂的对抗贴片，从而提高对抗贴片在不同任务之间的转移能力。",
    "en_tdlr": "VRAP is a multi-task adversarial patch generation method that combines object recognition-based adversarial patches into larger and more complex patches using scene graphs. It improves the transferability of adversarial patches between different tasks."
}