{
    "title": "RAPID: Enabling Fast Online Policy Learning in Dynamic Public Cloud Environments. (arXiv:2304.04797v1 [cs.LG])",
    "abstract": "Resource sharing between multiple workloads has become a prominent practice among cloud service providers, motivated by demand for improved resource utilization and reduced cost of ownership. Effective resource sharing, however, remains an open challenge due to the adverse effects that resource contention can have on high-priority, user-facing workloads with strict Quality of Service (QoS) requirements. Although recent approaches have demonstrated promising results, those works remain largely impractical in public cloud environments since workloads are not known in advance and may only run for a brief period, thus prohibiting offline learning and significantly hindering online learning. In this paper, we propose RAPID, a novel framework for fast, fully-online resource allocation policy learning in highly dynamic operating environments. RAPID leverages lightweight QoS predictions, enabled by domain-knowledge-inspired techniques for sample efficiency and bias reduction, to decouple contr",
    "link": "http://arxiv.org/abs/2304.04797",
    "context": "Title: RAPID: Enabling Fast Online Policy Learning in Dynamic Public Cloud Environments. (arXiv:2304.04797v1 [cs.LG])\nAbstract: Resource sharing between multiple workloads has become a prominent practice among cloud service providers, motivated by demand for improved resource utilization and reduced cost of ownership. Effective resource sharing, however, remains an open challenge due to the adverse effects that resource contention can have on high-priority, user-facing workloads with strict Quality of Service (QoS) requirements. Although recent approaches have demonstrated promising results, those works remain largely impractical in public cloud environments since workloads are not known in advance and may only run for a brief period, thus prohibiting offline learning and significantly hindering online learning. In this paper, we propose RAPID, a novel framework for fast, fully-online resource allocation policy learning in highly dynamic operating environments. RAPID leverages lightweight QoS predictions, enabled by domain-knowledge-inspired techniques for sample efficiency and bias reduction, to decouple contr",
    "path": "papers/23/04/2304.04797.json",
    "total_tokens": 965,
    "translated_title": "RAPID: 在动态公共云环境中实现快速在线策略学习",
    "translated_abstract": "多个工作负载之间的资源共享已成为云服务提供商之间的一种突出实践，这是由需求改进资源利用率和降低拥有成本所驱动的。然而，由于资源争用可能会对具有严格服务质量 (QoS) 要求的优先级高、面向用户的负载产生不利影响，因此有效的资源共享仍然是一个开放的挑战。虽然最近的方法已经展示了有希望的结果，但这些工作在公共云环境中仍然很难实践，因为负载事先是未知的，可能仅运行短暂的时间，从而禁止脱机学习，并且显著阻碍在线学习。在本文中，我们提出 RAPID，这是一种新颖的框架，用于在高度动态的操作环境中实现快速、完全在线的资源分配策略学习。RAPID 利用轻量级 QoS 预测，通过领域知识启发的技术实现样本效率和偏差减少，以分离争用检测和分配策略。",
    "tldr": "提出了在动态公共云环境中实现快速在线策略学习的框架RAPID，通过领域知识启发的技术实现样本效率和偏差减少，学习并实时调整资源分配策略，能有效解决资源共享中的问题。"
}