{
    "title": "To be Robust and to be Fair: Aligning Fairness with Robustness. (arXiv:2304.00061v1 [cs.LG])",
    "abstract": "Adversarial training has been shown to be reliable in improving robustness against adversarial samples. However, the problem of adversarial training in terms of fairness has not yet been properly studied, and the relationship between fairness and accuracy attack still remains unclear. Can we simultaneously improve robustness w.r.t. both fairness and accuracy? To tackle this topic, in this paper, we study the problem of adversarial training and adversarial attack w.r.t. both metrics. We propose a unified structure for fairness attack which brings together common notions in group fairness, and we theoretically prove the equivalence of fairness attack against different notions. Moreover, we show the alignment of fairness and accuracy attack, and theoretically demonstrate that robustness w.r.t. one metric benefits from robustness w.r.t. the other metric. Our study suggests a novel way to unify adversarial training and attack w.r.t. fairness and accuracy, and experimental results show that ",
    "link": "http://arxiv.org/abs/2304.00061",
    "context": "Title: To be Robust and to be Fair: Aligning Fairness with Robustness. (arXiv:2304.00061v1 [cs.LG])\nAbstract: Adversarial training has been shown to be reliable in improving robustness against adversarial samples. However, the problem of adversarial training in terms of fairness has not yet been properly studied, and the relationship between fairness and accuracy attack still remains unclear. Can we simultaneously improve robustness w.r.t. both fairness and accuracy? To tackle this topic, in this paper, we study the problem of adversarial training and adversarial attack w.r.t. both metrics. We propose a unified structure for fairness attack which brings together common notions in group fairness, and we theoretically prove the equivalence of fairness attack against different notions. Moreover, we show the alignment of fairness and accuracy attack, and theoretically demonstrate that robustness w.r.t. one metric benefits from robustness w.r.t. the other metric. Our study suggests a novel way to unify adversarial training and attack w.r.t. fairness and accuracy, and experimental results show that ",
    "path": "papers/23/04/2304.00061.json",
    "total_tokens": 905,
    "translated_title": "坚固且公正: 确保公平与鲁棒性相一致",
    "translated_abstract": "对抗训练已经被证明可以可靠地提高对抗样本的鲁棒性。然而，就公平性而言，对抗训练的问题尚未得到适当研究，公平性与准确性攻击之间的关系仍然不清楚。我们是否可以同时提高对公平性和准确性的鲁棒性？为了解决这个问题，本文研究了对抗训练和对抗攻击对这两个指标的问题。我们提出了一种公平性攻击的统一结构，将群体公平中的常见概念汇集在一起，并在理论上证明了不同概念下的公平性攻击等价性。此外，我们展示了公平性和准确性攻击的一致性，并在理论上证明了一种指标的鲁棒性会受到另一种指标鲁棒性的益处。我们的研究提出了一种统一公平与准确性的对抗训练和攻击的新方法，实验结果表明...",
    "tldr": "本研究提出了一种同时考虑公平性和准确性指标的对抗训练和攻击方法，并证明了两个指标之间的一致性以及互相受益的关系。",
    "en_tdlr": "This study proposes a method for adversarial training and attack that takes into account both fairness and accuracy metrics, and demonstrates the alignment and mutual benefit between the two metrics."
}