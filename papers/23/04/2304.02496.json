{
    "title": "Evaluation of ChatGPT Family of Models for Biomedical Reasoning and Classification. (arXiv:2304.02496v1 [cs.CL])",
    "abstract": "Recent advances in large language models (LLMs) have shown impressive ability in biomedical question-answering, but have not been adequately investigated for more specific biomedical applications. This study investigates the performance of LLMs such as the ChatGPT family of models (GPT-3.5s, GPT-4) in biomedical tasks beyond question-answering. Because no patient data can be passed to the OpenAI API public interface, we evaluated model performance with over 10000 samples as proxies for two fundamental tasks in the clinical domain classification and reasoning. The first task is classifying whether statements of clinical and policy recommendations in scientific literature constitute health advice. The second task is causal relation detection from the biomedical literature. We compared LLMs with simpler models, such as bag-of-words (BoW) with logistic regression, and fine-tuned BioBERT models. Despite the excitement around viral ChatGPT, we found that fine-tuning for two fundamental NLP",
    "link": "http://arxiv.org/abs/2304.02496",
    "context": "Title: Evaluation of ChatGPT Family of Models for Biomedical Reasoning and Classification. (arXiv:2304.02496v1 [cs.CL])\nAbstract: Recent advances in large language models (LLMs) have shown impressive ability in biomedical question-answering, but have not been adequately investigated for more specific biomedical applications. This study investigates the performance of LLMs such as the ChatGPT family of models (GPT-3.5s, GPT-4) in biomedical tasks beyond question-answering. Because no patient data can be passed to the OpenAI API public interface, we evaluated model performance with over 10000 samples as proxies for two fundamental tasks in the clinical domain classification and reasoning. The first task is classifying whether statements of clinical and policy recommendations in scientific literature constitute health advice. The second task is causal relation detection from the biomedical literature. We compared LLMs with simpler models, such as bag-of-words (BoW) with logistic regression, and fine-tuned BioBERT models. Despite the excitement around viral ChatGPT, we found that fine-tuning for two fundamental NLP",
    "path": "papers/23/04/2304.02496.json",
    "total_tokens": 1079,
    "translated_title": "ChatGPT家族模型在生物医学推理和分类中的评估",
    "translated_abstract": "最近大型语言模型的不断提升展现了其在生物医学问答方面的卓越能力，但尚未充分研究其在更具体的生物医学应用中的表现。这项研究探讨了ChatGPT家族模型（GPT-3.5s，GPT-4）等大型语言模型在生物医学任务中的性能，在OpenAI API公共接口中不能传递患者数据的情况下，我们使用超过10000个样本作为两个基本临床任务分类和推理的代理进行模型性能评估。第一个任务是将科学文献中的临床和政策建议陈述归类为健康建议。第二个任务是从生物医学文献中检测因果关系。我们将大型语言模型与简单模型（如逻辑回归的词袋模型）和Fine-tuned的BioBERT模型进行了比较。尽管ChatGPT非常受欢迎，但我们发现，Fine-tuned的生物医学NLP任务并未表现出一致的性能增益。然而，本研究揭示了大型语言模型在生物医学应用中超越问答的潜力，强调了需要更定制化的模型设计和Fine-tuning策略。",
    "tldr": "本论文探讨了ChatGPT家族模型在生物医学任务中的性能，虽然Fine-tuned的生物医学NLP任务并未表现出一致的性能增益，但显示出大型语言模型在生物医学应用中超越问答的潜力，需要更定制化的模型设计和Fine-tuning策略。",
    "en_tdlr": "This study investigates the performance of ChatGPT family of models in biomedical tasks beyond question-answering, showing the potential of LLMs in biomedical applications and the need for more tailored model design and fine-tuning strategies."
}