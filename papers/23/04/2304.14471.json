{
    "title": "Controllable One-Shot Face Video Synthesis With Semantic Aware Prior. (arXiv:2304.14471v1 [cs.CV])",
    "abstract": "The one-shot talking-head synthesis task aims to animate a source image to another pose and expression, which is dictated by a driving frame. Recent methods rely on warping the appearance feature extracted from the source, by using motion fields estimated from the sparse keypoints, that are learned in an unsupervised manner. Due to their lightweight formulation, they are suitable for video conferencing with reduced bandwidth. However, based on our study, current methods suffer from two major limitations: 1) unsatisfactory generation quality in the case of large head poses and the existence of observable pose misalignment between the source and the first frame in driving videos. 2) fail to capture fine yet critical face motion details due to the lack of semantic understanding and appropriate face geometry regularization. To address these shortcomings, we propose a novel method that leverages the rich face prior information, the proposed model can generate face videos with improved seman",
    "link": "http://arxiv.org/abs/2304.14471",
    "context": "Title: Controllable One-Shot Face Video Synthesis With Semantic Aware Prior. (arXiv:2304.14471v1 [cs.CV])\nAbstract: The one-shot talking-head synthesis task aims to animate a source image to another pose and expression, which is dictated by a driving frame. Recent methods rely on warping the appearance feature extracted from the source, by using motion fields estimated from the sparse keypoints, that are learned in an unsupervised manner. Due to their lightweight formulation, they are suitable for video conferencing with reduced bandwidth. However, based on our study, current methods suffer from two major limitations: 1) unsatisfactory generation quality in the case of large head poses and the existence of observable pose misalignment between the source and the first frame in driving videos. 2) fail to capture fine yet critical face motion details due to the lack of semantic understanding and appropriate face geometry regularization. To address these shortcomings, we propose a novel method that leverages the rich face prior information, the proposed model can generate face videos with improved seman",
    "path": "papers/23/04/2304.14471.json",
    "total_tokens": 942,
    "translated_title": "具有语义感知先验的可控单次人脸视频合成",
    "translated_abstract": "单次头像合成任务旨在通过使用从驾驶帧中学习的稀疏关键点估计的运动场来扭曲从源提取的外观特征，从而将源图像动画化为另一种姿势和表情。然而，现有方法存在两个主要限制：1）在头部姿势较大时合成质量不佳，源图像和驾驶视频中的第一帧之间存在可观的姿势错配；2）由于缺乏语义理解和适当的脸部几何正则化，因此无法捕捉精细但关键的面部运动细节。为了解决这些缺陷，我们提出了一种新方法，该方法利用丰富的面部先验信息，能够生成具有改进语义一致性和逼真运动细节的面部视频。",
    "tldr": "本文提出一种具有语义感知先验的可控单次人脸视频合成方法，通过可靠的面部分割和新颖的语义感知运动扭曲方案，在保证语义准确和实现真实运动的同时，生成高质量的面部视频。",
    "en_tdlr": "This paper proposes a novel controllable one-shot face video synthesis method with semantic-aware prior, which can generate high-quality face videos with improved semantic consistency and realistic motion details by introducing a reliable face segmentation method and a novel semantic-aware motion warping scheme that accounts for the face geometry and semantics in a principled manner."
}