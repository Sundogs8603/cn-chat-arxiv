{
    "title": "MER 2023: Multi-label Learning, Modality Robustness, and Semi-Supervised Learning. (arXiv:2304.08981v1 [cs.CL])",
    "abstract": "Over the past few decades, multimodal emotion recognition has made remarkable progress with the development of deep learning. However, existing technologies are difficult to meet the demand for practical applications. To improve the robustness, we launch a Multimodal Emotion Recognition Challenge (MER 2023) to motivate global researchers to build innovative technologies that can further accelerate and foster research. For this year's challenge, we present three distinct sub-challenges: (1) MER-MULTI, in which participants recognize both discrete and dimensional emotions; (2) MER-NOISE, in which noise is added to test videos for modality robustness evaluation; (3) MER-SEMI, which provides large amounts of unlabeled samples for semi-supervised learning. In this paper, we test a variety of multimodal features and provide a competitive baseline for each sub-challenge. Our system achieves 77.57% on the F1 score and 0.82 on the mean squared error (MSE) for MER-MULTI, 69.82% on the F1 score a",
    "link": "http://arxiv.org/abs/2304.08981",
    "context": "Title: MER 2023: Multi-label Learning, Modality Robustness, and Semi-Supervised Learning. (arXiv:2304.08981v1 [cs.CL])\nAbstract: Over the past few decades, multimodal emotion recognition has made remarkable progress with the development of deep learning. However, existing technologies are difficult to meet the demand for practical applications. To improve the robustness, we launch a Multimodal Emotion Recognition Challenge (MER 2023) to motivate global researchers to build innovative technologies that can further accelerate and foster research. For this year's challenge, we present three distinct sub-challenges: (1) MER-MULTI, in which participants recognize both discrete and dimensional emotions; (2) MER-NOISE, in which noise is added to test videos for modality robustness evaluation; (3) MER-SEMI, which provides large amounts of unlabeled samples for semi-supervised learning. In this paper, we test a variety of multimodal features and provide a competitive baseline for each sub-challenge. Our system achieves 77.57% on the F1 score and 0.82 on the mean squared error (MSE) for MER-MULTI, 69.82% on the F1 score a",
    "path": "papers/23/04/2304.08981.json",
    "total_tokens": 1211,
    "translated_title": "MER 2023: 多标签学习，模态鲁棒性和半监督学习",
    "translated_abstract": "在过去的几十年中，深度学习的发展使得多模态情感识别取得了显着进展。然而，现有技术难以满足实际应用的需求。为了提高鲁棒性，我们发起了多模态情感识别挑战赛（MER 2023），以激励全球研究人员构建创新技术，进一步加速和促进研究。针对今年的挑战赛，我们提出了三个不同的子挑战：（1）MER-MULTI，参赛者需要识别离散和维度情感；（2）MER-NOISE，在测试视频中添加噪声，以评估模态鲁棒性；（3）MER-SEMI，提供大量未标记的样本，用于半监督学习。在本文中，我们测试了各种多模态特征，并为每个子挑战提供了有竞争力的基线。我们的系统在MER-MULTI上获得了77.57％的F1分数和0.82的均方误差（MSE），在MER-NOISE上获得了69.82％的F1分数和0.75的MSE，在MER-SEMI上获得了69.39％的F1分数和0.80的MSE。我们希望这个挑战赛能够激发更多的研究人员探索多模态情感识别，并促进鲁棒而有效的算法用于实际应用。",
    "tldr": "多模态情感识别挑战赛（MER 2023）提出了三个子挑战：MER-MULTI、MER-NOISE和MER-SEMI，为全球研究人员构建创新技术提供了激励，并测试了各种多模态特征，提供了有竞争力的基线，以促进鲁棒而有效的算法的发展和应用。",
    "en_tdlr": "The Multi-modal Emotion Recognition Challenge (MER 2023) presents three sub-challenges to motivate researchers to build innovative technologies for improving robustness in practical applications. The challenge tests various multimodal features and provides a competitive baseline, hoping to promote the development and application of robust and effective algorithms."
}