{
    "title": "Detecting Out-of-Context Multimodal Misinformation with interpretable neural-symbolic model. (arXiv:2304.07633v1 [cs.CL])",
    "abstract": "Recent years have witnessed the sustained evolution of misinformation that aims at manipulating public opinions. Unlike traditional rumors or fake news editors who mainly rely on generated and/or counterfeited images, text and videos, current misinformation creators now more tend to use out-of-context multimedia contents (e.g. mismatched images and captions) to deceive the public and fake news detection systems. This new type of misinformation increases the difficulty of not only detection but also clarification, because every individual modality is close enough to true information. To address this challenge, in this paper we explore how to achieve interpretable cross-modal de-contextualization detection that simultaneously identifies the mismatched pairs and the cross-modal contradictions, which is helpful for fact-check websites to document clarifications. The proposed model first symbolically disassembles the text-modality information to a set of fact queries based on the Abstract M",
    "link": "http://arxiv.org/abs/2304.07633",
    "context": "Title: Detecting Out-of-Context Multimodal Misinformation with interpretable neural-symbolic model. (arXiv:2304.07633v1 [cs.CL])\nAbstract: Recent years have witnessed the sustained evolution of misinformation that aims at manipulating public opinions. Unlike traditional rumors or fake news editors who mainly rely on generated and/or counterfeited images, text and videos, current misinformation creators now more tend to use out-of-context multimedia contents (e.g. mismatched images and captions) to deceive the public and fake news detection systems. This new type of misinformation increases the difficulty of not only detection but also clarification, because every individual modality is close enough to true information. To address this challenge, in this paper we explore how to achieve interpretable cross-modal de-contextualization detection that simultaneously identifies the mismatched pairs and the cross-modal contradictions, which is helpful for fact-check websites to document clarifications. The proposed model first symbolically disassembles the text-modality information to a set of fact queries based on the Abstract M",
    "path": "papers/23/04/2304.07633.json",
    "total_tokens": 876,
    "translated_title": "采用可解释的符号化神经模型检测上下文不符的多模态谣言",
    "translated_abstract": "近年来，虚假信息的演化持续增长，旨在影响公众舆论。与传统的谣言或虚假新闻编辑主要依赖于生成和/或伪造的图像、文本和视频不同，当前的虚假信息创作者更倾向于使用上下文不匹配的多媒体内容（例如，不匹配的图像和标题）来欺骗公众和虚假新闻检测系统。这种新型的虚假信息不仅增加了检测的难度，也增加了澄清的难度，因为每个单独的模态都足够接近真实信息。为了解决这个问题，在本文中，我们探讨了如何实现可解释的跨模态去上下文检测，同时识别不匹配的对和跨模态矛盾，这对事实检查网站的记录澄清非常有帮助。所提出的模型首先通过抽象多模态信息，基于Abstract M进行符号化分解，得到一组事实查询。",
    "tldr": "本论文提出了一种可解释的神经符号模型，用于检测上下文不符的虚假多模态信息，帮助事实检查网站进行记录澄清。"
}