{
    "title": "Prompt Pre-Training with Twenty-Thousand Classes for Open-Vocabulary Visual Recognition. (arXiv:2304.04704v2 [cs.CV] UPDATED)",
    "abstract": "This work proposes POMP, a prompt pre-training method for vision-language models. Being memory and computation efficient, POMP enables the learned prompt to condense semantic information for a rich set of visual concepts with over twenty-thousand classes. Once pre-trained, the prompt with a strong transferable ability can be directly plugged into a variety of visual recognition tasks including image classification, semantic segmentation, and object detection, to boost recognition performances in a zero-shot manner. Empirical evaluation shows that POMP achieves state-of-the-art performances on 21 datasets, e.g., 67.0% average accuracy on 10 classification datasets (+3.1% compared to CoOp) and 84.4 hIoU on open-vocabulary Pascal VOC segmentation (+6.9 compared to ZSSeg). Our code is available at https://github.com/amazon-science/prompt-pretraining.",
    "link": "http://arxiv.org/abs/2304.04704",
    "context": "Title: Prompt Pre-Training with Twenty-Thousand Classes for Open-Vocabulary Visual Recognition. (arXiv:2304.04704v2 [cs.CV] UPDATED)\nAbstract: This work proposes POMP, a prompt pre-training method for vision-language models. Being memory and computation efficient, POMP enables the learned prompt to condense semantic information for a rich set of visual concepts with over twenty-thousand classes. Once pre-trained, the prompt with a strong transferable ability can be directly plugged into a variety of visual recognition tasks including image classification, semantic segmentation, and object detection, to boost recognition performances in a zero-shot manner. Empirical evaluation shows that POMP achieves state-of-the-art performances on 21 datasets, e.g., 67.0% average accuracy on 10 classification datasets (+3.1% compared to CoOp) and 84.4 hIoU on open-vocabulary Pascal VOC segmentation (+6.9 compared to ZSSeg). Our code is available at https://github.com/amazon-science/prompt-pretraining.",
    "path": "papers/23/04/2304.04704.json",
    "total_tokens": 933,
    "translated_title": "使用两万个类别进行开放词汇视觉识别的提示预训练",
    "translated_abstract": "本研究提出了POMP，一种用于视觉语言模型的提示预训练方法。POMP既具有存储和计算效率，又能够为超过两万个类别的丰富视觉概念压缩语义信息。一旦预训练完成，具有强大的可传递能力的提示可以直接应用于各种视觉识别任务，包括图像分类、语义分割和目标检测，以零-shot的方式提升识别性能。实证评估表明，POMP在21个数据集上达到了最先进的性能，例如在10个分类数据集上的平均准确率为67.0%（比CoOp高出3.1%），在开放词汇的Pascal VOC分割任务上的hIoU为84.4（比ZSSeg高出6.9）。我们的代码可以在https://github.com/amazon-science/prompt-pretraining上找到。",
    "tldr": "本研究提出了一种用于视觉语言模型的提示预训练方法POMP，可以在包括图像分类、语义分割和目标检测在内的各种视觉识别任务中提升识别性能，通过压缩语义信息，支持超过两万个类别的视觉概念。实验结果表明，POMP在多个数据集上达到了最先进的性能水平。"
}