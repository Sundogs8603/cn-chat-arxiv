{
    "title": "TABLET: Learning From Instructions For Tabular Data. (arXiv:2304.13188v1 [cs.LG])",
    "abstract": "Acquiring high-quality data is often a significant challenge in training machine learning (ML) models for tabular prediction, particularly in privacy-sensitive and costly domains like medicine and finance. Providing natural language instructions to large language models (LLMs) offers an alternative solution. However, it is unclear how effectively instructions leverage the knowledge in LLMs for solving tabular prediction problems. To address this gap, we introduce TABLET, a benchmark of 20 diverse tabular datasets annotated with instructions that vary in their phrasing, granularity, and technicality. Additionally, TABLET includes the instructions' logic and structured modifications to the instructions. We find in-context instructions increase zero-shot F1 performance for Flan-T5 11b by 44% on average and 13% for ChatGPT on TABLET. Also, we explore the limitations of using LLMs for tabular prediction in our benchmark by evaluating instruction faithfulness. We find LLMs often ignore instr",
    "link": "http://arxiv.org/abs/2304.13188",
    "context": "Title: TABLET: Learning From Instructions For Tabular Data. (arXiv:2304.13188v1 [cs.LG])\nAbstract: Acquiring high-quality data is often a significant challenge in training machine learning (ML) models for tabular prediction, particularly in privacy-sensitive and costly domains like medicine and finance. Providing natural language instructions to large language models (LLMs) offers an alternative solution. However, it is unclear how effectively instructions leverage the knowledge in LLMs for solving tabular prediction problems. To address this gap, we introduce TABLET, a benchmark of 20 diverse tabular datasets annotated with instructions that vary in their phrasing, granularity, and technicality. Additionally, TABLET includes the instructions' logic and structured modifications to the instructions. We find in-context instructions increase zero-shot F1 performance for Flan-T5 11b by 44% on average and 13% for ChatGPT on TABLET. Also, we explore the limitations of using LLMs for tabular prediction in our benchmark by evaluating instruction faithfulness. We find LLMs often ignore instr",
    "path": "papers/23/04/2304.13188.json",
    "total_tokens": 979,
    "translated_title": "TABLET：基于指令学习表格数据",
    "translated_abstract": "在训练表格预测的机器学习模型时，获取高质量的数据通常是一项重大挑战，特别是在隐私敏感和成本高的领域，比如医学和金融。向大型语言模型（LLM）提供自然语言指令提供了另一种解决方案。然而，指令如何有效地利用LLM中的知识来解决表格预测问题仍不清楚。为了弥补这一差距，我们介绍了TABLET，这是一个由20个不同的包含指令注释的表格数据集组成的基准测试，这些指令在措辞、细节和技术性方面各不相同。此外，TABLET还包括指令的逻辑和结构修改。我们发现，在上下文指令的帮助下，Flan-T5 11b的零示例F1性能平均提高了44％，在TABLET上，ChatGPT的提升为13％。此外，我们评估了指令保真度，探讨了使用LLM进行表格预测的局限性。我们发现LLM通常会忽略指令并依赖于数据中存在的偏差。",
    "tldr": "该论文提出了TABLET，这是一个由20个不同的包含指令注释的表格数据集组成的基准测试，可以提高大型语言模型在表格预测问题上的效果，并评估了指令在保真度和LLM在表格预测方面的局限性。",
    "en_tdlr": "This paper proposes TABLET, a benchmark of 20 diverse tabular datasets annotated with instructions to improve the performance of large language models in tabular prediction problems, as well as evaluating the fidelity of instructions and limitations of LLM in tabular prediction."
}