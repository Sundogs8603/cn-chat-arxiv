{
    "title": "Moderately Distributional Exploration for Domain Generalization. (arXiv:2304.13976v1 [cs.LG])",
    "abstract": "Domain generalization (DG) aims to tackle the distribution shift between training domains and unknown target domains. Generating new domains is one of the most effective approaches, yet its performance gain depends on the distribution discrepancy between the generated and target domains. Distributionally robust optimization is promising to tackle distribution discrepancy by exploring domains in an uncertainty set. However, the uncertainty set may be overwhelmingly large, leading to low-confidence prediction in DG. It is because a large uncertainty set could introduce domains containing semantically different factors from training domains. To address this issue, we propose to perform a $\\textbf{mo}$derately $\\textbf{d}$istributional $\\textbf{e}$xploration (MODE) for domain generalization. Specifically, MODE performs distribution exploration in an uncertainty $\\textit{subset}$ that shares the same semantic factors with the training domains. We show that MODE can endow models with provabl",
    "link": "http://arxiv.org/abs/2304.13976",
    "context": "Title: Moderately Distributional Exploration for Domain Generalization. (arXiv:2304.13976v1 [cs.LG])\nAbstract: Domain generalization (DG) aims to tackle the distribution shift between training domains and unknown target domains. Generating new domains is one of the most effective approaches, yet its performance gain depends on the distribution discrepancy between the generated and target domains. Distributionally robust optimization is promising to tackle distribution discrepancy by exploring domains in an uncertainty set. However, the uncertainty set may be overwhelmingly large, leading to low-confidence prediction in DG. It is because a large uncertainty set could introduce domains containing semantically different factors from training domains. To address this issue, we propose to perform a $\\textbf{mo}$derately $\\textbf{d}$istributional $\\textbf{e}$xploration (MODE) for domain generalization. Specifically, MODE performs distribution exploration in an uncertainty $\\textit{subset}$ that shares the same semantic factors with the training domains. We show that MODE can endow models with provabl",
    "path": "papers/23/04/2304.13976.json",
    "total_tokens": 962,
    "translated_title": "针对领域泛化的中度分布探索",
    "translated_abstract": "领域泛化旨在解决训练领域与未知目标领域之间的分布偏移问题。生成新的领域是最有效的方法之一，然而其性能增益取决于生成的领域与目标领域之间的分布差异。分布鲁棒优化有望通过在不确定性集中探索领域来解决分布偏移问题。然而，不确定性集可能非常庞大，在领域泛化中会导致低置信度预测，因为大的不确定性集可能会引入包含与训练领域语义不同的因素的领域。为了解决这个问题，我们提出了一种针对领域泛化的中度分布探索（MODE）。具体而言，MODE在一个与训练领域共享相同语义因素的不确定性$\\textit{子集}$中进行分布探索。我们证明，MODE可以为模型提供可证明的分布偏移鲁棒性，并在几个基准领域泛化数据集上实现了最先进的性能。",
    "tldr": "本文提出了一种针对领域泛化问题的中度分布探索（MODE）方法，通过在共享相同语义因素的不确定性子集中探索领域，可以提高模型的分布偏移鲁棒性，并在多个基准数据集上实现了最先进的性能。",
    "en_tdlr": "This paper proposes a moderately distributional exploration (MODE) approach for domain generalization, which explores domains in an uncertainty subset sharing the same semantic factors with the training domains to improve the model's robustness to distribution shift, achieving state-of-the-art performance on multiple benchmark datasets."
}