{
    "title": "Towards Explainable and Safe Conversational Agents for Mental Health: A Survey. (arXiv:2304.13191v1 [cs.AI])",
    "abstract": "Virtual Mental Health Assistants (VMHAs) are seeing continual advancements to support the overburdened global healthcare system that gets 60 million primary care visits, and 6 million Emergency Room (ER) visits annually. These systems are built by clinical psychologists, psychiatrists, and Artificial Intelligence (AI) researchers for Cognitive Behavioral Therapy (CBT). At present, the role of VMHAs is to provide emotional support through information, focusing less on developing a reflective conversation with the patient. A more comprehensive, safe and explainable approach is required to build responsible VMHAs to ask follow-up questions or provide a well-informed response. This survey offers a systematic critical review of the existing conversational agents in mental health, followed by new insights into the improvements of VMHAs with contextual knowledge, datasets, and their emerging role in clinical decision support. We also provide new directions toward enriching the user experience",
    "link": "http://arxiv.org/abs/2304.13191",
    "context": "Title: Towards Explainable and Safe Conversational Agents for Mental Health: A Survey. (arXiv:2304.13191v1 [cs.AI])\nAbstract: Virtual Mental Health Assistants (VMHAs) are seeing continual advancements to support the overburdened global healthcare system that gets 60 million primary care visits, and 6 million Emergency Room (ER) visits annually. These systems are built by clinical psychologists, psychiatrists, and Artificial Intelligence (AI) researchers for Cognitive Behavioral Therapy (CBT). At present, the role of VMHAs is to provide emotional support through information, focusing less on developing a reflective conversation with the patient. A more comprehensive, safe and explainable approach is required to build responsible VMHAs to ask follow-up questions or provide a well-informed response. This survey offers a systematic critical review of the existing conversational agents in mental health, followed by new insights into the improvements of VMHAs with contextual knowledge, datasets, and their emerging role in clinical decision support. We also provide new directions toward enriching the user experience",
    "path": "papers/23/04/2304.13191.json",
    "total_tokens": 916,
    "translated_title": "面向心理健康的可解释和安全的会话型智能助手：一项调查",
    "translated_abstract": "虚拟心理健康助手（VMHA）在持续推进，以支持每年6000万次初级医疗保健就诊和600万次急诊室就诊的负担过重的全球医疗保健系统。这些系统是由临床心理学家、精神科医师和人工智能（AI）研究人员为认知行为疗法（CBT）构建的。目前，VMHA的作用是通过信息提供情感支持，重点不在与患者进行深入的反思对话。需要更全面、安全和可解释的方法来构建负责任的VMHA，以提出后续问题或提供知情回应。这项调查对现有的心理健康会话型智能助手进行了系统的批判性审查，随后提出了关于VMHA改进的新见解，包括环境知识、数据集和它们在临床决策支持中的新兴角色。我们还提供了丰富用户体验的新方向。",
    "tldr": "这篇论文调查了现有的心理健康会话型智能助手，提出了改进的新见解，并介绍了如何构建责任VMHA，以提出后续问题或提供知情回应，丰富用户体验。",
    "en_tdlr": "This paper surveys existing conversational agents in mental health, proposes new insights for improving VMHAs, and introduces how to build responsible VMHAs to ask follow-up questions or provide a well-informed response, enhancing user experience."
}