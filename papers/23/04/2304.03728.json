{
    "title": "Interpretable Unified Language Checking. (arXiv:2304.03728v1 [cs.CL])",
    "abstract": "Despite recent concerns about undesirable behaviors generated by large language models (LLMs), including non-factual, biased, and hateful language, we find LLMs are inherent multi-task language checkers based on their latent representations of natural and social knowledge. We present an interpretable, unified, language checking (UniLC) method for both human and machine-generated language that aims to check if language input is factual and fair. While fairness and fact-checking tasks have been handled separately with dedicated models, we find that LLMs can achieve high performance on a combination of fact-checking, stereotype detection, and hate speech detection tasks with a simple, few-shot, unified set of prompts. With the ``1/2-shot'' multi-task language checking method proposed in this work, the GPT3.5-turbo model outperforms fully supervised baselines on several language tasks. The simple approach and results suggest that based on strong latent knowledge representations, an LLM can",
    "link": "http://arxiv.org/abs/2304.03728",
    "context": "Title: Interpretable Unified Language Checking. (arXiv:2304.03728v1 [cs.CL])\nAbstract: Despite recent concerns about undesirable behaviors generated by large language models (LLMs), including non-factual, biased, and hateful language, we find LLMs are inherent multi-task language checkers based on their latent representations of natural and social knowledge. We present an interpretable, unified, language checking (UniLC) method for both human and machine-generated language that aims to check if language input is factual and fair. While fairness and fact-checking tasks have been handled separately with dedicated models, we find that LLMs can achieve high performance on a combination of fact-checking, stereotype detection, and hate speech detection tasks with a simple, few-shot, unified set of prompts. With the ``1/2-shot'' multi-task language checking method proposed in this work, the GPT3.5-turbo model outperforms fully supervised baselines on several language tasks. The simple approach and results suggest that based on strong latent knowledge representations, an LLM can",
    "path": "papers/23/04/2304.03728.json",
    "total_tokens": 956,
    "translated_title": "可解释的统一语言检查",
    "translated_abstract": "尽管最近对大型语言模型（LLM）的不良行为提出了关注，包括非事实性、有偏见和充满仇恨的语言，但我们发现，基于自然和社会知识的潜在表示，LLM本质上是多任务语言检查器。我们提出了一种可解释的统一语言检查（UniLC）方法，旨在检查语言输入的事实和公正性。虽然公平性和事实检查任务以前是由不同的模型处理的，但我们发现LLM可以在一个简单、少量样本的提示集上实现事实检查、陈规陋习检测和仇恨言论检测任务的高性能。本文提出的“一半样本”多任务语言检查方法，使得GPT3.5-turbo模型在多项语言任务上优于完全监督的基准线。这种简单的方法和结果表明，基于强大的潜在知识表示，LLM可能是实现可解释的统一语言检查的有前途的方法。",
    "tldr": "本文提出了一种可解释的统一语言检查（UniLC）方法，旨在检查语言输入的事实和公正性。LLM可以在一个简单、少量样本的提示集上实现事实检查、陈规陋习检测和仇恨言论检测任务的高性能，这为实现可解释的统一语言检查提供了有前途的方法。"
}