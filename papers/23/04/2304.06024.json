{
    "title": "Probabilistic Human Mesh Recovery in 3D Scenes from Egocentric Views. (arXiv:2304.06024v1 [cs.CV])",
    "abstract": "Automatic perception of human behaviors during social interactions is crucial for AR/VR applications, and an essential component is estimation of plausible 3D human pose and shape of our social partners from the egocentric view. One of the biggest challenges of this task is severe body truncation due to close social distances in egocentric scenarios, which brings large pose ambiguities for unseen body parts. To tackle this challenge, we propose a novel scene-conditioned diffusion method to model the body pose distribution. Conditioned on the 3D scene geometry, the diffusion model generates bodies in plausible human-scene interactions, with the sampling guided by a physics-based collision score to further resolve human-scene inter-penetrations. The classifier-free training enables flexible sampling with different conditions and enhanced diversity. A visibility-aware graph convolution model guided by per-joint visibility serves as the diffusion denoiser to incorporate inter-joint depende",
    "link": "http://arxiv.org/abs/2304.06024",
    "context": "Title: Probabilistic Human Mesh Recovery in 3D Scenes from Egocentric Views. (arXiv:2304.06024v1 [cs.CV])\nAbstract: Automatic perception of human behaviors during social interactions is crucial for AR/VR applications, and an essential component is estimation of plausible 3D human pose and shape of our social partners from the egocentric view. One of the biggest challenges of this task is severe body truncation due to close social distances in egocentric scenarios, which brings large pose ambiguities for unseen body parts. To tackle this challenge, we propose a novel scene-conditioned diffusion method to model the body pose distribution. Conditioned on the 3D scene geometry, the diffusion model generates bodies in plausible human-scene interactions, with the sampling guided by a physics-based collision score to further resolve human-scene inter-penetrations. The classifier-free training enables flexible sampling with different conditions and enhanced diversity. A visibility-aware graph convolution model guided by per-joint visibility serves as the diffusion denoiser to incorporate inter-joint depende",
    "path": "papers/23/04/2304.06024.json",
    "total_tokens": 935,
    "translated_title": "从个人角度视图中三维场景中恢复人体网格的概率方法研究",
    "translated_abstract": "在增强现实/虚拟现实应用中，自动感知人类社交互动行为至关重要，而一个重要组成部分是从个人视图中估计合理的3D人体姿态和形态。这项任务最大的挑战之一是由于个人场景中的近距离导致身体被截断严重，从而导致看不见身体部件的大量姿态模糊。为了应对这一挑战，我们提出了一种基于场景条件的扩散方法来模拟身体姿态分布。在3D场景几何条件的约束下，扩散模型生成在合理的人-场景交互中的身体，并通过基于物理碰撞得分的采样来进一步解决人-场景相互渗透问题。无需分类器的训练使得采样具有不同的条件和增强的多样性。一个可见性感知的图卷积模型通过每个关节的可见度来指导扩散去噪器，以合并互关节依赖。",
    "tldr": "本文提出一种基于场景条件的扩散方法来建模身体姿态分布，以解决在个人视角下3D场景中的人类姿态估计的挑战，训练中无需分类器，采样具有不同的条件和增强的多样性。"
}