{
    "title": "RS2G: Data-Driven Scene-Graph Extraction and Embedding for Robust Autonomous Perception and Scenario Understanding. (arXiv:2304.08600v1 [cs.CV])",
    "abstract": "Human drivers naturally reason about interactions between road users to understand and safely navigate through traffic. Thus, developing autonomous vehicles necessitates the ability to mimic such knowledge and model interactions between road users to understand and navigate unpredictable, dynamic environments. However, since real-world scenarios often differ from training datasets, effectively modeling the behavior of various road users in an environment remains a significant research challenge. This reality necessitates models that generalize to a broad range of domains and explicitly model interactions between road users and the environment to improve scenario understanding. Graph learning methods address this problem by modeling interactions using graph representations of scenarios. However, existing methods cannot effectively transfer knowledge gained from the training domain to real-world scenarios. This constraint is caused by the domain-specific rules used for graph extraction t",
    "link": "http://arxiv.org/abs/2304.08600",
    "context": "Title: RS2G: Data-Driven Scene-Graph Extraction and Embedding for Robust Autonomous Perception and Scenario Understanding. (arXiv:2304.08600v1 [cs.CV])\nAbstract: Human drivers naturally reason about interactions between road users to understand and safely navigate through traffic. Thus, developing autonomous vehicles necessitates the ability to mimic such knowledge and model interactions between road users to understand and navigate unpredictable, dynamic environments. However, since real-world scenarios often differ from training datasets, effectively modeling the behavior of various road users in an environment remains a significant research challenge. This reality necessitates models that generalize to a broad range of domains and explicitly model interactions between road users and the environment to improve scenario understanding. Graph learning methods address this problem by modeling interactions using graph representations of scenarios. However, existing methods cannot effectively transfer knowledge gained from the training domain to real-world scenarios. This constraint is caused by the domain-specific rules used for graph extraction t",
    "path": "papers/23/04/2304.08600.json",
    "total_tokens": 873,
    "translated_abstract": "人类驾驶员自然会思考道路用户之间的相互作用，以理解并安全地通过交通。因此，开发自动驾驶车辆需要能够模仿这种知识，并对道路用户之间的相互作用进行建模，以理解和导航不可预测的动态环境。然而，由于真实世界的情境经常与训练数据集不同，有效地对环境中各种道路用户的行为进行建模仍然是一个重要的研究挑战。这种现实需要具有广泛领域泛化能力并明确建模道路用户与环境之间交互的模型，以改善情境理解。图学习方法通过将情境表示成图形来建模交互，从而解决了这个问题。然而，现有方法不能有效地将从训练领域获得的知识转移到真实情境中。这种约束是由于用于图提取的领域特定规则所导致的。",
    "tldr": "本文提出了一种名为RS2G的方法，它可以面向数据驱动地提取和嵌入场景图，以改善自主感知和情境理解中的交互建模问题。",
    "en_tdlr": "This paper presents a method called RS2G which can extract and embed scene graphs driven by data, to address the problem of modeling interactions in autonomous perception and scenario understanding."
}