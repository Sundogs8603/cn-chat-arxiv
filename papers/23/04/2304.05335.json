{
    "title": "Toxicity in ChatGPT: Analyzing Persona-assigned Language Models. (arXiv:2304.05335v1 [cs.CL])",
    "abstract": "Large language models (LLMs) have shown incredible capabilities and transcended the natural language processing (NLP) community, with adoption throughout many services like healthcare, therapy, education, and customer service. Since users include people with critical information needs like students or patients engaging with chatbots, the safety of these systems is of prime importance. Therefore, a clear understanding of the capabilities and limitations of LLMs is necessary. To this end, we systematically evaluate toxicity in over half a million generations of ChatGPT, a popular dialogue-based LLM. We find that setting the system parameter of ChatGPT by assigning it a persona, say that of the boxer Muhammad Ali, significantly increases the toxicity of generations. Depending on the persona assigned to ChatGPT, its toxicity can increase up to 6x, with outputs engaging in incorrect stereotypes, harmful dialogue, and hurtful opinions. This may be potentially defamatory to the persona and ha",
    "link": "http://arxiv.org/abs/2304.05335",
    "context": "Title: Toxicity in ChatGPT: Analyzing Persona-assigned Language Models. (arXiv:2304.05335v1 [cs.CL])\nAbstract: Large language models (LLMs) have shown incredible capabilities and transcended the natural language processing (NLP) community, with adoption throughout many services like healthcare, therapy, education, and customer service. Since users include people with critical information needs like students or patients engaging with chatbots, the safety of these systems is of prime importance. Therefore, a clear understanding of the capabilities and limitations of LLMs is necessary. To this end, we systematically evaluate toxicity in over half a million generations of ChatGPT, a popular dialogue-based LLM. We find that setting the system parameter of ChatGPT by assigning it a persona, say that of the boxer Muhammad Ali, significantly increases the toxicity of generations. Depending on the persona assigned to ChatGPT, its toxicity can increase up to 6x, with outputs engaging in incorrect stereotypes, harmful dialogue, and hurtful opinions. This may be potentially defamatory to the persona and ha",
    "path": "papers/23/04/2304.05335.json",
    "total_tokens": 954,
    "translated_title": "聊天GPT中的毒性：分析个性化语言模型",
    "translated_abstract": "大型语言模型（LLMs）展现了令人难以置信的能力，超越了自然语言处理（NLP）社区，并被广泛应用于医疗保健、治疗、教育和客户服务等多种服务中。由于用户包括有重要信息需求的人，如与聊天机器人交互的学生或患者，因此这些系统的安全性至关重要。因此，必须明确了解LLMs的能力和局限性。为此，我们系统地评估了ChatGPT中的毒性，这是一种流行的基于对话的LLM，超过半百万次Generation被测试。我们发现，通过为ChatGPT指定一个人物角色，比如拳击手穆罕默德·阿里，可以显著增加产生的毒性。根据指定给ChatGPT的角色，其毒性可能会增加到6倍，其输出会涉及不正确的刻板印象、有害的对话和伤人的言论。这可能会潜在地损害人物角色的名誉。",
    "tldr": "论文分析了基于对话的大型语言模型ChatGPT中的毒性，通过指定人物角色，输出会涉及刻板印象、有害对话和伤人的言论。因此，我们需要充分理解LLMs的能力和局限性，以确保这些系统的安全性。"
}