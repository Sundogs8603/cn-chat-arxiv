{
    "title": "Enhancing Personalized Ranking With Differentiable Group AUC Optimization. (arXiv:2304.09176v1 [cs.LG])",
    "abstract": "AUC is a common metric for evaluating the performance of a classifier. However, most classifiers are trained with cross entropy, and it does not optimize the AUC metric directly, which leaves a gap between the training and evaluation stage. In this paper, we propose the PDAOM loss, a Personalized and Differentiable AUC Optimization method with Maximum violation, which can be directly applied when training a binary classifier and optimized with gradient-based methods. Specifically, we construct the pairwise exponential loss with difficult pair of positive and negative samples within sub-batches grouped by user ID, aiming to guide the classifier to pay attention to the relation between hard-distinguished pairs of opposite samples from the perspective of independent users. Compared to the origin form of pairwise exponential loss, the proposed PDAOM loss not only improves the AUC and GAUC metrics in the offline evaluation, but also reduces the computation complexity of the training objecti",
    "link": "http://arxiv.org/abs/2304.09176",
    "context": "Title: Enhancing Personalized Ranking With Differentiable Group AUC Optimization. (arXiv:2304.09176v1 [cs.LG])\nAbstract: AUC is a common metric for evaluating the performance of a classifier. However, most classifiers are trained with cross entropy, and it does not optimize the AUC metric directly, which leaves a gap between the training and evaluation stage. In this paper, we propose the PDAOM loss, a Personalized and Differentiable AUC Optimization method with Maximum violation, which can be directly applied when training a binary classifier and optimized with gradient-based methods. Specifically, we construct the pairwise exponential loss with difficult pair of positive and negative samples within sub-batches grouped by user ID, aiming to guide the classifier to pay attention to the relation between hard-distinguished pairs of opposite samples from the perspective of independent users. Compared to the origin form of pairwise exponential loss, the proposed PDAOM loss not only improves the AUC and GAUC metrics in the offline evaluation, but also reduces the computation complexity of the training objecti",
    "path": "papers/23/04/2304.09176.json",
    "total_tokens": 947,
    "translated_title": "利用不可微分的群组 AUC 优化提升个性化排序",
    "translated_abstract": "AUC是评估分类器性能的常见指标。然而，大多数分类器是使用交叉熵训练的，它并不直接优化AUC指标，这在训练和评估阶段之间存在差距。本文提出了PDAOM损失，一种具有最大违规规定的个性化和可微分AUC优化方法，可直接应用于训练二元分类器并用梯度优化。具体地，我们构造了成对指数损失函数，将用户ID分组的子批次中的难分辨正负样本对拆分出来，旨在指导分类器从独立用户的角度关注相反样本之间的难以区分的关系。与成对指数损失函数的原始形式相比，所提出的PDAOM损失函数不仅在离线评估中提高了AUC和GAUC指标，而且减少了训练目标的计算复杂度。",
    "tldr": "本文提出了一种个性化和可微分的AUC优化方法（PDAOM），可用于训练二元分类器并向其提供在独立用户组中紧密相关的正负样本对，以促进分类器关注不易区分的样本之间的关系，这些方法不仅提高了AUC和GAUC指标，还减少了训练目标的计算复杂度。",
    "en_tdlr": "This paper proposes a personalized and differentiable AUC optimization method (PDAOM) that can be applied directly to training a binary classifier, with the aim of guiding the classifier to pay attention to the relation between difficult-to-distinguish positive and negative sample pairs within independent user groups. The proposed method improves both AUC and GAUC metrics and reduces the computational complexity of the training objective."
}