{
    "title": "MPMQA: Multimodal Question Answering on Product Manuals. (arXiv:2304.09660v1 [cs.CL])",
    "abstract": "Visual contents, such as illustrations and images, play a big role in product manual understanding. Existing Product Manual Question Answering (PMQA) datasets tend to ignore visual contents and only retain textual parts. In this work, to emphasize the importance of multimodal contents, we propose a Multimodal Product Manual Question Answering (MPMQA) task. For each question, MPMQA requires the model not only to process multimodal contents but also to provide multimodal answers. To support MPMQA, a large-scale dataset PM209 is constructed with human annotations, which contains 209 product manuals from 27 well-known consumer electronic brands. Human annotations include 6 types of semantic regions for manual contents and 22,021 pairs of question and answer. Especially, each answer consists of a textual sentence and related visual regions from manuals. Taking into account the length of product manuals and the fact that a question is always related to a small number of pages, MPMQA can be n",
    "link": "http://arxiv.org/abs/2304.09660",
    "context": "Title: MPMQA: Multimodal Question Answering on Product Manuals. (arXiv:2304.09660v1 [cs.CL])\nAbstract: Visual contents, such as illustrations and images, play a big role in product manual understanding. Existing Product Manual Question Answering (PMQA) datasets tend to ignore visual contents and only retain textual parts. In this work, to emphasize the importance of multimodal contents, we propose a Multimodal Product Manual Question Answering (MPMQA) task. For each question, MPMQA requires the model not only to process multimodal contents but also to provide multimodal answers. To support MPMQA, a large-scale dataset PM209 is constructed with human annotations, which contains 209 product manuals from 27 well-known consumer electronic brands. Human annotations include 6 types of semantic regions for manual contents and 22,021 pairs of question and answer. Especially, each answer consists of a textual sentence and related visual regions from manuals. Taking into account the length of product manuals and the fact that a question is always related to a small number of pages, MPMQA can be n",
    "path": "papers/23/04/2304.09660.json",
    "total_tokens": 881,
    "translated_title": "MPMQA：基于产品手册的多模态问答",
    "translated_abstract": "视觉内容，在产品手册理解中扮演着重要的角色。现有的产品手册问答（PMQA）数据集往往忽视了视觉内容，仅保留文本部分。为了强调多模态内容的重要性，本文提出了一个多模态产品手册问答（MPMQA）任务。对于每个问题，MPMQA要求模型不仅要处理多模态内容，还要提供多模态答案。为了支持MPMQA，构建了一个大规模数据集PM209作为人类注释，其中包含来自27个知名消费电子品牌的209个产品手册。人类注释包括手册内容的6种语义区域和22,021对问题和答案。特别地，每个答案都包含一个文本句子和相关的手册视觉区域。考虑到产品手册的长度和一个问题总是与少数页面相关，MPMQA的性能可以很好。",
    "tldr": "本文提出了一个多模态产品手册问答（MPMQA）任务，构建了一个大规模数据集PM209来支持该任务，要求模型不仅处理多模态内容，还提供多模态答案，有望提高产品手册理解效能。",
    "en_tdlr": "This paper proposes a Multimodal Product Manual Question Answering (MPMQA) task, and constructs a large-scale dataset PM209 to support it. The model is required to process multimodal contents and provide multimodal answers, which could improve the understanding efficiency of product manuals."
}