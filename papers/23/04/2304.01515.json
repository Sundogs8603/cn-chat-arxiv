{
    "title": "Text-Conditioned Sampling Framework for Text-to-Image Generation with Masked Generative Models. (arXiv:2304.01515v1 [cs.LG])",
    "abstract": "Token-based masked generative models are gaining popularity for their fast inference time with parallel decoding. While recent token-based approaches achieve competitive performance to diffusion-based models, their generation performance is still suboptimal as they sample multiple tokens simultaneously without considering the dependence among them. We empirically investigate this problem and propose a learnable sampling model, Text-Conditioned Token Selection (TCTS), to select optimal tokens via localized supervision with text information. TCTS improves not only the image quality but also the semantic alignment of the generated images with the given texts. To further improve the image quality, we introduce a cohesive sampling strategy, Frequency Adaptive Sampling (FAS), to each group of tokens divided according to the self-attention maps. We validate the efficacy of TCTS combined with FAS with various generative tasks, demonstrating that it significantly outperforms the baselines in im",
    "link": "http://arxiv.org/abs/2304.01515",
    "context": "Title: Text-Conditioned Sampling Framework for Text-to-Image Generation with Masked Generative Models. (arXiv:2304.01515v1 [cs.LG])\nAbstract: Token-based masked generative models are gaining popularity for their fast inference time with parallel decoding. While recent token-based approaches achieve competitive performance to diffusion-based models, their generation performance is still suboptimal as they sample multiple tokens simultaneously without considering the dependence among them. We empirically investigate this problem and propose a learnable sampling model, Text-Conditioned Token Selection (TCTS), to select optimal tokens via localized supervision with text information. TCTS improves not only the image quality but also the semantic alignment of the generated images with the given texts. To further improve the image quality, we introduce a cohesive sampling strategy, Frequency Adaptive Sampling (FAS), to each group of tokens divided according to the self-attention maps. We validate the efficacy of TCTS combined with FAS with various generative tasks, demonstrating that it significantly outperforms the baselines in im",
    "path": "papers/23/04/2304.01515.json",
    "total_tokens": 912,
    "tldr": "本文提出了一种基于文本辅助的条件选取优化机制和有凝聚力采样策略，能够显著提高生成图像的质量和与文本的语义对齐性能。"
}