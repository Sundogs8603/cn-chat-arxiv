{
    "title": "Detecting Adversarial Faces Using Only Real Face Self-Perturbations. (arXiv:2304.11359v1 [cs.CV])",
    "abstract": "Adversarial attacks aim to disturb the functionality of a target system by adding specific noise to the input samples, bringing potential threats to security and robustness when applied to facial recognition systems. Although existing defense techniques achieve high accuracy in detecting some specific adversarial faces (adv-faces), new attack methods especially GAN-based attacks with completely different noise patterns circumvent them and reach a higher attack success rate. Even worse, existing techniques require attack data before implementing the defense, making it impractical to defend newly emerging attacks that are unseen to defenders. In this paper, we investigate the intrinsic generality of adv-faces and propose to generate pseudo adv-faces by perturbing real faces with three heuristically designed noise patterns. We are the first to train an adv-face detector using only real faces and their self-perturbations, agnostic to victim facial recognition systems, and agnostic to unsee",
    "link": "http://arxiv.org/abs/2304.11359",
    "context": "Title: Detecting Adversarial Faces Using Only Real Face Self-Perturbations. (arXiv:2304.11359v1 [cs.CV])\nAbstract: Adversarial attacks aim to disturb the functionality of a target system by adding specific noise to the input samples, bringing potential threats to security and robustness when applied to facial recognition systems. Although existing defense techniques achieve high accuracy in detecting some specific adversarial faces (adv-faces), new attack methods especially GAN-based attacks with completely different noise patterns circumvent them and reach a higher attack success rate. Even worse, existing techniques require attack data before implementing the defense, making it impractical to defend newly emerging attacks that are unseen to defenders. In this paper, we investigate the intrinsic generality of adv-faces and propose to generate pseudo adv-faces by perturbing real faces with three heuristically designed noise patterns. We are the first to train an adv-face detector using only real faces and their self-perturbations, agnostic to victim facial recognition systems, and agnostic to unsee",
    "path": "papers/23/04/2304.11359.json",
    "total_tokens": 958,
    "translated_title": "仅使用真实人脸自扰动检测对抗性人脸",
    "translated_abstract": "对抗性攻击旨在通过向输入样本添加特定噪声来扰乱目标系统的功能，当应用于人脸识别系统时，对安全性和稳健性带来潜在威胁。虽然现有的防御技术在检测某些特定的对抗性人脸（adv-faces）方面取得了高准确性，但具有完全不同噪声模式的新攻击方法尤其是基于 GAN 的攻击则绕过它们并达到更高的攻击成功率。更糟糕的是，现有技术需要攻击数据才能实现防御，使得防御者无法防御未被发现的新兴攻击。在本文中，我们研究了adv-faces的内在普遍性，通过使用三种启发式设计的噪声模式扰动真实人脸来生成伪对抗性人脸。我们是第一个仅使用真实人脸及其自扰动训练对抗性人脸检测器的研究，不受受害者人脸识别系统影响，也不受未知攻击影响。",
    "tldr": "本文提出了一种使用真实人脸自扰动生成伪对抗性人脸的方法，利用这种方法训练的对抗性人脸检测器不需攻击数据即可检测新型未知攻击。",
    "en_tdlr": "This paper proposes a method of generating pseudo adversarial faces using self-perturbations of real faces and trains a detector using this method that is agnostic to victim facial recognition systems and does not require attack data, making it capable of detecting new and unknown attacks."
}