{
    "title": "Individual Fairness in Bayesian Neural Networks. (arXiv:2304.10828v1 [cs.LG])",
    "abstract": "We study Individual Fairness (IF) for Bayesian neural networks (BNNs). Specifically, we consider the $\\epsilon$-$\\delta$-individual fairness notion, which requires that, for any pair of input points that are $\\epsilon$-similar according to a given similarity metrics, the output of the BNN is within a given tolerance $\\delta>0.$ We leverage bounds on statistical sampling over the input space and the relationship between adversarial robustness and individual fairness to derive a framework for the systematic estimation of $\\epsilon$-$\\delta$-IF, designing Fair-FGSM and Fair-PGD as global,fairness-aware extensions to gradient-based attacks for BNNs. We empirically study IF of a variety of approximately inferred BNNs with different architectures on fairness benchmarks, and compare against deterministic models learnt using frequentist techniques. Interestingly, we find that BNNs trained by means of approximate Bayesian inference consistently tend to be markedly more individually fair than th",
    "link": "http://arxiv.org/abs/2304.10828",
    "context": "Title: Individual Fairness in Bayesian Neural Networks. (arXiv:2304.10828v1 [cs.LG])\nAbstract: We study Individual Fairness (IF) for Bayesian neural networks (BNNs). Specifically, we consider the $\\epsilon$-$\\delta$-individual fairness notion, which requires that, for any pair of input points that are $\\epsilon$-similar according to a given similarity metrics, the output of the BNN is within a given tolerance $\\delta>0.$ We leverage bounds on statistical sampling over the input space and the relationship between adversarial robustness and individual fairness to derive a framework for the systematic estimation of $\\epsilon$-$\\delta$-IF, designing Fair-FGSM and Fair-PGD as global,fairness-aware extensions to gradient-based attacks for BNNs. We empirically study IF of a variety of approximately inferred BNNs with different architectures on fairness benchmarks, and compare against deterministic models learnt using frequentist techniques. Interestingly, we find that BNNs trained by means of approximate Bayesian inference consistently tend to be markedly more individually fair than th",
    "path": "papers/23/04/2304.10828.json",
    "total_tokens": 952,
    "translated_title": "贝叶斯神经网络中的个体公平性研究",
    "translated_abstract": "本文研究了贝叶斯神经网络（BNNs）中的个体公平性（IF）。具体而言，我们考虑了ε-δ-个体公平性概念，该概念要求对于任何一对根据给定相似度度量ε-相似的输入点，BNN的输出在给定容忍度δ>0内。我们利用输入空间上的统计抽样界限以及对抗鲁棒性和个体公平性之间的关系，推导出了$\\epsilon$-$\\delta$-IF的系统估计框架，设计了Fair-FGSM和Fair-PGD作为针对BNN的全局公平度攻击的扩展。我们通过对公平性基准测试的各种不同架构的BNN进行实证研究，与使用频率主义技术学习的确定性模型进行比较。有趣的是，我们发现通过近似的贝叶斯推断训练的BNNs通常比确定性模型更加具有个体公平性。",
    "tldr": "本文研究了贝叶斯神经网络中的个体公平性，提出了一个系统的估计框架，使得网络输出在给定容忍度内的ε-相似的输入点具有相同的结果。实证研究表明，近似贝叶斯推断训练的BNN比确定性模型更具个体公平性。",
    "en_tdlr": "This paper focuses on Individual Fairness (IF) for Bayesian neural networks (BNNs), and proposes a systematic estimation framework that ensures the network outputs the same result for ε-similar input points within a given tolerance. Empirical studies show that BNNs trained by approximate Bayesian inference are more individually fair than deterministic models."
}