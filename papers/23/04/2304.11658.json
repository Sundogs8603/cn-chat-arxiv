{
    "title": "Capturing Fine-grained Semantics in Contrastive Graph Representation Learning. (arXiv:2304.11658v1 [cs.LG])",
    "abstract": "Graph contrastive learning defines a contrastive task to pull similar instances close and push dissimilar instances away. It learns discriminative node embeddings without supervised labels, which has aroused increasing attention in the past few years. Nevertheless, existing methods of graph contrastive learning ignore the differences between diverse semantics existed in graphs, which learn coarse-grained node embeddings and lead to sub-optimal performances on downstream tasks. To bridge this gap, we propose a novel Fine-grained Semantics enhanced Graph Contrastive Learning (FSGCL) in this paper. Concretely, FSGCL first introduces a motif-based graph construction, which employs graph motifs to extract diverse semantics existed in graphs from the perspective of input data. Then, the semantic-level contrastive task is explored to further enhance the utilization of fine-grained semantics from the perspective of model training. Experiments on five real-world datasets demonstrate the superio",
    "link": "http://arxiv.org/abs/2304.11658",
    "context": "Title: Capturing Fine-grained Semantics in Contrastive Graph Representation Learning. (arXiv:2304.11658v1 [cs.LG])\nAbstract: Graph contrastive learning defines a contrastive task to pull similar instances close and push dissimilar instances away. It learns discriminative node embeddings without supervised labels, which has aroused increasing attention in the past few years. Nevertheless, existing methods of graph contrastive learning ignore the differences between diverse semantics existed in graphs, which learn coarse-grained node embeddings and lead to sub-optimal performances on downstream tasks. To bridge this gap, we propose a novel Fine-grained Semantics enhanced Graph Contrastive Learning (FSGCL) in this paper. Concretely, FSGCL first introduces a motif-based graph construction, which employs graph motifs to extract diverse semantics existed in graphs from the perspective of input data. Then, the semantic-level contrastive task is explored to further enhance the utilization of fine-grained semantics from the perspective of model training. Experiments on five real-world datasets demonstrate the superio",
    "path": "papers/23/04/2304.11658.json",
    "total_tokens": 925,
    "translated_title": "捕捉对比图表示学习中的细粒度语义",
    "translated_abstract": "图对比学习定义了一个对比的任务，以将相似的实例拉近，将不相似的实例推远，学习区分性节点嵌入而无需监督标签，这在过去几年中引起了越来越多的关注。然而，现有的图对比学习方法忽略了图中存在的不同语义之间的差异，学习了粗粒度的节点嵌入，导致下游任务表现亚优。为了弥补这一差距，本文提出了一种新颖的增强细粒度语义的对比学习方法（FSGCL）。具体而言，FSGCL首先引入了基于图案的图构造方法，从输入数据的角度利用图案提取了存在于图中的多种语义。然后，从模型训练的角度探索了语义级对比任务，进一步增强了对细粒度语义的利用。在五个真实数据集上的实验证明了FSGCL相比于最先进的图对比学习方法的优越性。",
    "tldr": "本文提出了一种新的增强细粒度语义对比学习方法（FSGCL），首先使用基于图案的图构造方法从输入数据中提取多种语义，在此基础上探索语义级对比任务，从而提高图对比学习的性能。",
    "en_tdlr": "This paper proposes a novel Fine-grained Semantics enhanced Graph Contrastive Learning (FSGCL) method, which first extracts multiple semantics from input data using motif-based graph construction and then explores semantic-level contrastive task to improve graph contrastive learning performance."
}