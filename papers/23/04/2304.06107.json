{
    "title": "PATMAT: Person Aware Tuning of Mask-Aware Transformer for Face Inpainting. (arXiv:2304.06107v1 [cs.CV])",
    "abstract": "Generative models such as StyleGAN2 and Stable Diffusion have achieved state-of-the-art performance in computer vision tasks such as image synthesis, inpainting, and de-noising. However, current generative models for face inpainting often fail to preserve fine facial details and the identity of the person, despite creating aesthetically convincing image structures and textures. In this work, we propose Person Aware Tuning (PAT) of Mask-Aware Transformer (MAT) for face inpainting, which addresses this issue. Our proposed method, PATMAT, effectively preserves identity by incorporating reference images of a subject and fine-tuning a MAT architecture trained on faces. By using ~40 reference images, PATMAT creates anchor points in MAT's style module, and tunes the model using the fixed anchors to adapt the model to a new face identity. Moreover, PATMAT's use of multiple images per anchor during training allows the model to use fewer reference images than competing methods. We demonstrate th",
    "link": "http://arxiv.org/abs/2304.06107",
    "context": "Title: PATMAT: Person Aware Tuning of Mask-Aware Transformer for Face Inpainting. (arXiv:2304.06107v1 [cs.CV])\nAbstract: Generative models such as StyleGAN2 and Stable Diffusion have achieved state-of-the-art performance in computer vision tasks such as image synthesis, inpainting, and de-noising. However, current generative models for face inpainting often fail to preserve fine facial details and the identity of the person, despite creating aesthetically convincing image structures and textures. In this work, we propose Person Aware Tuning (PAT) of Mask-Aware Transformer (MAT) for face inpainting, which addresses this issue. Our proposed method, PATMAT, effectively preserves identity by incorporating reference images of a subject and fine-tuning a MAT architecture trained on faces. By using ~40 reference images, PATMAT creates anchor points in MAT's style module, and tunes the model using the fixed anchors to adapt the model to a new face identity. Moreover, PATMAT's use of multiple images per anchor during training allows the model to use fewer reference images than competing methods. We demonstrate th",
    "path": "papers/23/04/2304.06107.json",
    "total_tokens": 879,
    "translated_title": "PATMAT: 面向个体化的面部修复的遮罩感知Transformer",
    "translated_abstract": "风格生成模型如StyleGAN2和Stable Diffusion已经在计算机视觉任务中取得了最先进的性能，例如图像合成、修复和去噪。但是，当前用于面部修补的生成模型通常无法保留细节和个人的身份，尽管它们能创建出审美上可信的图像结构和纹理。在这项工作中，我们提出了一种Person Aware Tuning (PAT)的Mask-Aware Transformer (MAT)方法，用于解决这个问题。我们的方法PATMAT通过使用一个人的参考图像和微调在面孔上训练过的MAT模型，有效地保留了其身份。PATMAT使用约40个参考图像在MAT的样式模块中创建锚点，并使用锚点来适应新的面部身份。此外，PATMAT利用训练期间每个锚点的多个图像使模型使用比竞争方法更少的参考图像。我们展示了PATMAT在基准数据集上胜过现有的面部修补模型，同时保留了细节和身份。",
    "tldr": "PATMAT使用参考图像和微调技术有效地保留了面部修补中的细节和人物身份。",
    "en_tdlr": "PATMAT effectively preserves fine facial details and identity in face inpainting through the use of reference images and fine-tuning techniques."
}