{
    "title": "Nondeterministic Stacks in Neural Networks. (arXiv:2304.12955v1 [cs.CL])",
    "abstract": "Human language is full of compositional syntactic structures, and although neural networks have contributed to groundbreaking improvements in computer systems that process language, widely-used neural network architectures still exhibit limitations in their ability to process syntax. To address this issue, prior work has proposed adding stack data structures to neural networks, drawing inspiration from theoretical connections between syntax and stacks. However, these methods employ deterministic stacks that are designed to track one parse at a time, whereas syntactic ambiguity, which requires a nondeterministic stack to parse, is extremely common in language. In this dissertation, we remedy this discrepancy by proposing a method of incorporating nondeterministic stacks into neural networks. We develop a differentiable data structure that efficiently simulates a nondeterministic pushdown automaton, representing an exponential number of computations with a dynamic programming algorithm. ",
    "link": "http://arxiv.org/abs/2304.12955",
    "context": "Title: Nondeterministic Stacks in Neural Networks. (arXiv:2304.12955v1 [cs.CL])\nAbstract: Human language is full of compositional syntactic structures, and although neural networks have contributed to groundbreaking improvements in computer systems that process language, widely-used neural network architectures still exhibit limitations in their ability to process syntax. To address this issue, prior work has proposed adding stack data structures to neural networks, drawing inspiration from theoretical connections between syntax and stacks. However, these methods employ deterministic stacks that are designed to track one parse at a time, whereas syntactic ambiguity, which requires a nondeterministic stack to parse, is extremely common in language. In this dissertation, we remedy this discrepancy by proposing a method of incorporating nondeterministic stacks into neural networks. We develop a differentiable data structure that efficiently simulates a nondeterministic pushdown automaton, representing an exponential number of computations with a dynamic programming algorithm. ",
    "path": "papers/23/04/2304.12955.json",
    "total_tokens": 796,
    "translated_title": "神经网络中的非确定性栈",
    "translated_abstract": "人类语言中充满了 组成性句法结构，尽管神经网络在处理语言的计算机系统方面做出了突破性的改进，但是广泛使用的神经网络体系结构在处理语法方面仍存在局限性。为了解决这个问题，之前的工作提出在神经网络中添加栈 数据结构，从语法和栈之间的理论关系中汲取灵感。然而，这些方法采用的是设计用于跟踪一个句法分析的确定性栈，而在语言中需要采用非确定性栈进行解析的句法歧义极其常见。在本论文中，我们通过提出一种将非确定性栈纳入到神经网络中的方法来解决这个差异。我们开发了一种可微分的数据结构，利用动态规划算法高效地模拟了一个非确定性下推自动机，表示一个指数级的计算数量。",
    "tldr": "本论文提出在神经网络中添加了可以处理句法歧义的非确定性栈，有效地模拟一个非确定性下推自动机。",
    "en_tdlr": "This paper proposes adding nondeterministic stacks to neural networks to deal with syntactic ambiguity and efficiently simulating a nondeterministic pushdown automaton through a differentiable data structure."
}