{
    "title": "Trace and Pace: Controllable Pedestrian Animation via Guided Trajectory Diffusion. (arXiv:2304.01893v1 [cs.CV])",
    "abstract": "We introduce a method for generating realistic pedestrian trajectories and full-body animations that can be controlled to meet user-defined goals. We draw on recent advances in guided diffusion modeling to achieve test-time controllability of trajectories, which is normally only associated with rule-based systems. Our guided diffusion model allows users to constrain trajectories through target waypoints, speed, and specified social groups while accounting for the surrounding environment context. This trajectory diffusion model is integrated with a novel physics-based humanoid controller to form a closed-loop, full-body pedestrian animation system capable of placing large crowds in a simulated environment with varying terrains. We further propose utilizing the value function learned during RL training of the animation controller to guide diffusion to produce trajectories better suited for particular scenarios such as collision avoidance and traversing uneven terrain. Video results are a",
    "link": "http://arxiv.org/abs/2304.01893",
    "context": "Title: Trace and Pace: Controllable Pedestrian Animation via Guided Trajectory Diffusion. (arXiv:2304.01893v1 [cs.CV])\nAbstract: We introduce a method for generating realistic pedestrian trajectories and full-body animations that can be controlled to meet user-defined goals. We draw on recent advances in guided diffusion modeling to achieve test-time controllability of trajectories, which is normally only associated with rule-based systems. Our guided diffusion model allows users to constrain trajectories through target waypoints, speed, and specified social groups while accounting for the surrounding environment context. This trajectory diffusion model is integrated with a novel physics-based humanoid controller to form a closed-loop, full-body pedestrian animation system capable of placing large crowds in a simulated environment with varying terrains. We further propose utilizing the value function learned during RL training of the animation controller to guide diffusion to produce trajectories better suited for particular scenarios such as collision avoidance and traversing uneven terrain. Video results are a",
    "path": "papers/23/04/2304.01893.json",
    "total_tokens": 907,
    "translated_title": "通过引导轨迹扩散控制的行人动画生成方法",
    "translated_abstract": "我们引入了一种生成真实行人轨迹和全身动画的方法，可以控制以满足用户定义的目标。我们利用了最近在引导扩散建模方面的进展，实现了在测试时间对轨迹进行可控制，这通常只与基于规则的系统相关。我们的引导扩散模型允许用户通过目标路径点、速度和指定的社交群体来限制轨迹，同时考虑周围环境情况。此轨迹扩散模型与一种新颖的基于物理的人形控制器相结合，形成了一个闭环、全身行人动画系统，能够将大批人群放置在具有不同地形的模拟环境中。我们还提出利用在RL训练动画控制器期间学习到的值函数来引导扩散，以生成更适合特定场景的轨迹，例如避免碰撞和穿越不平地形。视频结果是令人满意的。",
    "tldr": "通过引导轨迹扩散控制的行人动画生成方法，可以实现对行人轨迹和全身动画的精准控制和模拟，为特定场景的处理提供了新的思路。",
    "en_tdlr": "This paper introduces a method for generating realistic pedestrian trajectories and full-body animations that can be controlled to meet user-defined goals through guided trajectory diffusion. It integrates a novel physics-based humanoid controller to form a closed-loop, full-body pedestrian animation system capable of placing large crowds in a simulated environment with varying terrains. The method allows for precise control and simulation of pedestrian trajectories and animations, providing new ideas for handling specific scenarios such as collision avoidance and traversing uneven terrain."
}