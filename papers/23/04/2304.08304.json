{
    "title": "SDVRF: Sparse-to-Dense Voxel Region Fusion for Multi-modal 3D Object Detection. (arXiv:2304.08304v2 [cs.CV] UPDATED)",
    "abstract": "In the perception task of autonomous driving, multi-modal methods have become a trend due to the complementary characteristics of LiDAR point clouds and image data. However, the performance of previous methods is usually limited by the sparsity of the point cloud or the noise problem caused by the misalignment between LiDAR and the camera. To solve these two problems, we present a new concept, Voxel Region (VR), which is obtained by projecting the sparse local point clouds in each voxel dynamically. And we propose a novel fusion method, named Sparse-to-Dense Voxel Region Fusion (SDVRF). Specifically, more pixels of the image feature map inside the VR are gathered to supplement the voxel feature extracted from sparse points and achieve denser fusion. Meanwhile, different from prior methods, which project the size-fixed grids, our strategy of generating dynamic regions achieves better alignment and avoids introducing too much background noise. Furthermore, we propose a multi-scale fusion",
    "link": "http://arxiv.org/abs/2304.08304",
    "context": "Title: SDVRF: Sparse-to-Dense Voxel Region Fusion for Multi-modal 3D Object Detection. (arXiv:2304.08304v2 [cs.CV] UPDATED)\nAbstract: In the perception task of autonomous driving, multi-modal methods have become a trend due to the complementary characteristics of LiDAR point clouds and image data. However, the performance of previous methods is usually limited by the sparsity of the point cloud or the noise problem caused by the misalignment between LiDAR and the camera. To solve these two problems, we present a new concept, Voxel Region (VR), which is obtained by projecting the sparse local point clouds in each voxel dynamically. And we propose a novel fusion method, named Sparse-to-Dense Voxel Region Fusion (SDVRF). Specifically, more pixels of the image feature map inside the VR are gathered to supplement the voxel feature extracted from sparse points and achieve denser fusion. Meanwhile, different from prior methods, which project the size-fixed grids, our strategy of generating dynamic regions achieves better alignment and avoids introducing too much background noise. Furthermore, we propose a multi-scale fusion",
    "path": "papers/23/04/2304.08304.json",
    "total_tokens": 1075,
    "translated_title": "多模态三维物体检测的稀疏到密集体素区域融合方法",
    "translated_abstract": "在自动驾驶感知任务中，多模态方法成为趋势，主要因为LiDAR点云和图像数据的补充特性。然而，以往方法的性能通常受到点云稀疏或者LiDAR和相机之间偏差导致的噪声问题的限制。为了解决这两个问题，我们提出了一个新的概念，Voxel Region (VR)，通过动态投影每个体素中的稀疏局部点云来获得。我们提出了一种新颖的融合方法，称为Sparse-to-Dense Voxel Region Fusion (SDVRF)，具体而言，将VR内部较多的图像特征图像素收集起来，以补充从稀疏点中提取的体素特征，实现更密集的融合。与先前的方法不同，我们的动态区域生成策略实现了更好的对齐，并避免引入太多的背景噪声。此外，我们提出了一种多尺度融合方法来增强我们的方法的性能。在KITTI数据集上的大量实验表明，我们的方法在各种评估指标下显著优于现有最先进方法。",
    "tldr": "提出了一种新的稀疏到密集的体素区域加强融合方法，通过动态投影每个体素内部的稀疏局部点云获得体素区域，更好地对齐和避免背景噪声问题，并通过多尺度融合方法极大地提高了三维物体检测性能。",
    "en_tdlr": "Proposed a novel Sparse-to-Dense Voxel Region Fusion method for multi-modal 3D object detection, which generates Voxel Region (VR) by projecting sparse local point clouds dynamically in each voxel, achieves better alignment and avoids background noise, and enhances the performance through multi-scale fusion approach. Experiment shows it significantly outperforms the state-of-the-art methods on KITTI dataset."
}