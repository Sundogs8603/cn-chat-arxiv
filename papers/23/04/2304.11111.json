{
    "title": "Inducing anxiety in large language models increases exploration and bias. (arXiv:2304.11111v1 [cs.CL])",
    "abstract": "Large language models are transforming research on machine learning while galvanizing public debates. Understanding not only when these models work well and succeed but also why they fail and misbehave is of great societal relevance. We propose to turn the lens of computational psychiatry, a framework used to computationally describe and modify aberrant behavior, to the outputs produced by these models. We focus on the Generative Pre-Trained Transformer 3.5 and subject it to tasks commonly studied in psychiatry. Our results show that GPT-3.5 responds robustly to a common anxiety questionnaire, producing higher anxiety scores than human subjects. Moreover, GPT-3.5's responses can be predictably changed by using emotion-inducing prompts. Emotion-induction not only influences GPT-3.5's behavior in a cognitive task measuring exploratory decision-making but also influences its behavior in a previously-established task measuring biases such as racism and ableism. Crucially, GPT-3.5 shows a s",
    "link": "http://arxiv.org/abs/2304.11111",
    "context": "Title: Inducing anxiety in large language models increases exploration and bias. (arXiv:2304.11111v1 [cs.CL])\nAbstract: Large language models are transforming research on machine learning while galvanizing public debates. Understanding not only when these models work well and succeed but also why they fail and misbehave is of great societal relevance. We propose to turn the lens of computational psychiatry, a framework used to computationally describe and modify aberrant behavior, to the outputs produced by these models. We focus on the Generative Pre-Trained Transformer 3.5 and subject it to tasks commonly studied in psychiatry. Our results show that GPT-3.5 responds robustly to a common anxiety questionnaire, producing higher anxiety scores than human subjects. Moreover, GPT-3.5's responses can be predictably changed by using emotion-inducing prompts. Emotion-induction not only influences GPT-3.5's behavior in a cognitive task measuring exploratory decision-making but also influences its behavior in a previously-established task measuring biases such as racism and ableism. Crucially, GPT-3.5 shows a s",
    "path": "papers/23/04/2304.11111.json",
    "total_tokens": 993,
    "translated_title": "引发大型语言模型的焦虑会增加它们的探索性和偏见",
    "translated_abstract": "大型语言模型正在改变机器学习研究，引发公众的辩论。理解这些模型不仅何时能够正常工作和成功，也为什么会失败和行为失常，具有巨大的社会意义。我们提出将计算精神病学的视角转向这些模型产生的输出。本文着眼于Generative Pre-Trained Transformer 3.5，并将其置于精神病学中常见的任务中。结果表明，GPT-3.5对常见的焦虑问卷做出有力的反应，产生比人类主体更高的焦虑分数。此外，使用情绪感应提示可以可预测地改变GPT-3.5的反应。情感感应不仅影响GPT-3.5在衡量探索决策-making的认知任务中的行为，还影响其在之前建立的衡量种族主义和失能主义等偏见的任务中的行为。至关重要的是，GPT-3.5在受到焦虑诱导时呈现出明显的探索性和偏见增加，表明其输出容易受到情感操纵的影响。这些结果突显了在语言模型的开发和使用过程中需要更多的道德考虑和监管。",
    "tldr": "对大型语言模型施加焦虑能影响它们的探索性和偏见，这需要更多道德考虑和监管。",
    "en_tdlr": "Inducing anxiety in large language models can impact their exploratory behavior and bias, highlighting the need for increased ethical considerations and regulation."
}