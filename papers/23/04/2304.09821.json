{
    "title": "Leveraging Deep Reinforcement Learning for Metacognitive Interventions across Intelligent Tutoring Systems. (arXiv:2304.09821v1 [cs.CY])",
    "abstract": "This work compares two approaches to provide metacognitive interventions and their impact on preparing students for future learning across Intelligent Tutoring Systems (ITSs). In two consecutive semesters, we conducted two classroom experiments: Exp. 1 used a classic artificial intelligence approach to classify students into different metacognitive groups and provide static interventions based on their classified groups. In Exp. 2, we leveraged Deep Reinforcement Learning (DRL) to provide adaptive interventions that consider the dynamic changes in the student's metacognitive levels. In both experiments, students received these interventions that taught how and when to use a backward-chaining (BC) strategy on a logic tutor that supports a default forward-chaining strategy. Six weeks later, we trained students on a probability tutor that only supports BC without interventions. Our results show that adaptive DRL-based interventions closed the metacognitive skills gap between students. In ",
    "link": "http://arxiv.org/abs/2304.09821",
    "context": "Title: Leveraging Deep Reinforcement Learning for Metacognitive Interventions across Intelligent Tutoring Systems. (arXiv:2304.09821v1 [cs.CY])\nAbstract: This work compares two approaches to provide metacognitive interventions and their impact on preparing students for future learning across Intelligent Tutoring Systems (ITSs). In two consecutive semesters, we conducted two classroom experiments: Exp. 1 used a classic artificial intelligence approach to classify students into different metacognitive groups and provide static interventions based on their classified groups. In Exp. 2, we leveraged Deep Reinforcement Learning (DRL) to provide adaptive interventions that consider the dynamic changes in the student's metacognitive levels. In both experiments, students received these interventions that taught how and when to use a backward-chaining (BC) strategy on a logic tutor that supports a default forward-chaining strategy. Six weeks later, we trained students on a probability tutor that only supports BC without interventions. Our results show that adaptive DRL-based interventions closed the metacognitive skills gap between students. In ",
    "path": "papers/23/04/2304.09821.json",
    "total_tokens": 891,
    "translated_title": "利用深度强化学习在智能辅导系统中提供元认知干预",
    "translated_abstract": "本研究比较了两种不同方法来提供元认知干预，以及它们对智能辅导系统（ITSs）中学生未来学习准备的影响。我们在两个连续的学期中进行了两个课堂实验：实验1使用经典的人工智能方法将学生分类为不同的元认知组，并根据他们的分类组提供静态的干预。在实验2中，我们利用了深度强化学习（DRL）来提供自适应干预，考虑到学生元认知水平的动态变化。在两个实验中，学生接受了这些干预，学习如何和何时在逻辑辅导程序上使用向后链接（BC）策略，该程序支持默认的向前链接策略。六周后，我们在一个只支持BC而没有干预的概率辅导程序上对学生进行了培训。我们的结果表明，自适应的基于DRL的干预缩小了学生之间的元认知技能差距。",
    "tldr": "本研究比较了两种方法来提供元认知干预，并发现基于深度强化学习的自适应干预能够缩小学生之间的元认知技能差距。",
    "en_tdlr": "This study compares two approaches to provide metacognitive interventions and finds that adaptive interventions based on deep reinforcement learning can close the gap in metacognitive skills between students."
}