{
    "title": "Thompson Sampling Regret Bounds for Contextual Bandits with sub-Gaussian rewards. (arXiv:2304.13593v1 [stat.ML])",
    "abstract": "In this work, we study the performance of the Thompson Sampling algorithm for Contextual Bandit problems based on the framework introduced by Neu et al. and their concept of lifted information ratio. First, we prove a comprehensive bound on the Thompson Sampling expected cumulative regret that depends on the mutual information of the environment parameters and the history. Then, we introduce new bounds on the lifted information ratio that hold for sub-Gaussian rewards, thus generalizing the results from Neu et al. which analysis requires binary rewards. Finally, we provide explicit regret bounds for the special cases of unstructured bounded contextual bandits, structured bounded contextual bandits with Laplace likelihood, structured Bernoulli bandits, and bounded linear contextual bandits.",
    "link": "http://arxiv.org/abs/2304.13593",
    "context": "Title: Thompson Sampling Regret Bounds for Contextual Bandits with sub-Gaussian rewards. (arXiv:2304.13593v1 [stat.ML])\nAbstract: In this work, we study the performance of the Thompson Sampling algorithm for Contextual Bandit problems based on the framework introduced by Neu et al. and their concept of lifted information ratio. First, we prove a comprehensive bound on the Thompson Sampling expected cumulative regret that depends on the mutual information of the environment parameters and the history. Then, we introduce new bounds on the lifted information ratio that hold for sub-Gaussian rewards, thus generalizing the results from Neu et al. which analysis requires binary rewards. Finally, we provide explicit regret bounds for the special cases of unstructured bounded contextual bandits, structured bounded contextual bandits with Laplace likelihood, structured Bernoulli bandits, and bounded linear contextual bandits.",
    "path": "papers/23/04/2304.13593.json",
    "total_tokens": 761,
    "translated_title": "基于互信息比例的 Thompson 抽样算法在子高斯奖励情境下的遗憾界研究",
    "translated_abstract": "本文研究了基于 Neu et al. 的框架和其提出的互信息比例概念的情境 Bandit 问题中的 Thompson 抽样算法表现。首先，我们证明了 Thompson 抽样期望累计遗憾的全面边界取决于环境参数和历史的互信息。然后，我们引入了对子高斯奖励成立的提高信息比率的新边界，从而推广了 Neu 等人的结果，其分析要求二进制奖励。最后，我们为非结构化有界情境 Bandit、结构化有界情境 Bandit（拉普拉斯似然函数）、结构化 Bernoulli Bandit 和有界线性情境 Bandit 提供了明确的遗憾界。",
    "tldr": "本文研究了子高斯奖励情境下的 Thompson 抽样算法在情境 Bandit 问题中的性能，并引入了提高信息比率的新边界。",
    "en_tdlr": "This paper studies the performance of the Thompson Sampling algorithm in contextual bandit problems with sub-Gaussian rewards, and introduces new bounds on the lifted information ratio."
}