{
    "title": "Sentence-Level Relation Extraction via Contrastive Learning with Descriptive Relation Prompts. (arXiv:2304.04935v1 [cs.CL])",
    "abstract": "Sentence-level relation extraction aims to identify the relation between two entities for a given sentence. The existing works mostly focus on obtaining a better entity representation and adopting a multi-label classifier for relation extraction. A major limitation of these works is that they ignore background relational knowledge and the interrelation between entity types and candidate relations. In this work, we propose a new paradigm, Contrastive Learning with Descriptive Relation Prompts(CTL-DRP), to jointly consider entity information, relational knowledge and entity type restrictions. In particular, we introduce an improved entity marker and descriptive relation prompts when generating contextual embedding, and utilize contrastive learning to rank the restricted candidate relations. The CTL-DRP obtains a competitive F1-score of 76.7% on TACRED. Furthermore, the new presented paradigm achieves F1-scores of 85.8% and 91.6% on TACREV and Re-TACRED respectively, which are both the st",
    "link": "http://arxiv.org/abs/2304.04935",
    "context": "Title: Sentence-Level Relation Extraction via Contrastive Learning with Descriptive Relation Prompts. (arXiv:2304.04935v1 [cs.CL])\nAbstract: Sentence-level relation extraction aims to identify the relation between two entities for a given sentence. The existing works mostly focus on obtaining a better entity representation and adopting a multi-label classifier for relation extraction. A major limitation of these works is that they ignore background relational knowledge and the interrelation between entity types and candidate relations. In this work, we propose a new paradigm, Contrastive Learning with Descriptive Relation Prompts(CTL-DRP), to jointly consider entity information, relational knowledge and entity type restrictions. In particular, we introduce an improved entity marker and descriptive relation prompts when generating contextual embedding, and utilize contrastive learning to rank the restricted candidate relations. The CTL-DRP obtains a competitive F1-score of 76.7% on TACRED. Furthermore, the new presented paradigm achieves F1-scores of 85.8% and 91.6% on TACREV and Re-TACRED respectively, which are both the st",
    "path": "papers/23/04/2304.04935.json",
    "total_tokens": 983,
    "translated_title": "通过具有描述性关系提示的对比学习进行句子级关系抽取",
    "translated_abstract": "句子级关系抽取旨在识别给定句子中两个实体之间的关系。现有的工作主要集中在获得更好的实体表示并采用多标签分类器进行关系抽取。这些工作的主要局限性在于它们忽略了背景关系知识和实体类型与候选关系之间的相互关系。在本文中，我们提出了一种新的范式，即具有描述性关系提示的对比学习(CTL-DRP)，以共同考虑实体信息、关系知识和实体类型限制。具体来说，我们在生成上下文嵌入时引入了改进的实体标记和描述性关系提示，并利用对比学习来对受限候选关系进行排名。CTL-DRP 在 TACRED 上获得了竞争性的 F1 分数为 76.7%。此外，新提出的范式在 TACREV 和 Re-TACRED 上分别取得了 85.8% 和 91.6% 的 F1 分数，两者均为最高。",
    "tldr": "本文提出了一种新的范式，即具有描述性关系提示的对比学习(CTL-DRP)，通过考虑实体信息、关系知识和实体类型限制，显著提高了句子级关系抽取的准确性。在 TACRED、TACREV 和 Re-TACRED 上获得了竞争性的 F1 分数，其中在 Re-TACRED 上表现最好。"
}