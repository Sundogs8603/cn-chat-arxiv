{
    "title": "EC^2: Emergent Communication for Embodied Control. (arXiv:2304.09448v1 [cs.LG])",
    "abstract": "Embodied control requires agents to leverage multi-modal pre-training to quickly learn how to act in new environments, where video demonstrations contain visual and motion details needed for low-level perception and control, and language instructions support generalization with abstract, symbolic structures. While recent approaches apply contrastive learning to force alignment between the two modalities, we hypothesize better modeling their complementary differences can lead to more holistic representations for downstream adaption. To this end, we propose Emergent Communication for Embodied Control (EC^2), a novel scheme to pre-train video-language representations for few-shot embodied control. The key idea is to learn an unsupervised \"language\" of videos via emergent communication, which bridges the semantics of video details and structures of natural language. We learn embodied representations of video trajectories, emergent language, and natural language using a language model, whic",
    "link": "http://arxiv.org/abs/2304.09448",
    "context": "Title: EC^2: Emergent Communication for Embodied Control. (arXiv:2304.09448v1 [cs.LG])\nAbstract: Embodied control requires agents to leverage multi-modal pre-training to quickly learn how to act in new environments, where video demonstrations contain visual and motion details needed for low-level perception and control, and language instructions support generalization with abstract, symbolic structures. While recent approaches apply contrastive learning to force alignment between the two modalities, we hypothesize better modeling their complementary differences can lead to more holistic representations for downstream adaption. To this end, we propose Emergent Communication for Embodied Control (EC^2), a novel scheme to pre-train video-language representations for few-shot embodied control. The key idea is to learn an unsupervised \"language\" of videos via emergent communication, which bridges the semantics of video details and structures of natural language. We learn embodied representations of video trajectories, emergent language, and natural language using a language model, whic",
    "path": "papers/23/04/2304.09448.json",
    "total_tokens": 931,
    "translated_title": "EC^2: 基于身体控制的新型紧急交流方案",
    "translated_abstract": "身体控制需要代理通过多模态预训练快速学习如何在新环境中行动，其中视频演示包含所需的视觉和运动细节以进行低级别知觉和控制，语言指令支持通过抽象符号结构进行泛化。虽然最近的方法应用对比学习来强制两种模式之间的对齐，但我们假设更好地建模它们之间的互补差异可以带来更全面的表示以进行下游适应。为此，我们提出了 Emergent Communication for Embodied Control (EC^2)，这是一种新的方案，用于预训练视频语言表示以进行少样本身体控制。关键思想是通过紧急通信学习视频的“语言”，它桥接了视频细节的语义和自然语言的结构。我们使用语言模型学习视频轨迹，紧急语言和自然语言的身体表示，然后对它们进行微调以进行身体控制任务。我们在 EmbodiedAI 基准测试上评估 EC^2，在三个任务上实现了最先进的少样本性能。",
    "tldr": "EC^2 提出一种新的紧急通信方案，用于视频语言预训练以进行少样本身体控制，实现了在 EmbodiedAI 基准测试上的最先进的少样本性能。",
    "en_tdlr": "EC^2 proposes a novel emergent communication scheme for video-language pre-training for few-shot embodied control, achieving state-of-the-art performance on the EmbodiedAI benchmark."
}