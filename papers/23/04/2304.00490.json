{
    "title": "Infinite-dimensional reservoir computing. (arXiv:2304.00490v1 [cs.LG])",
    "abstract": "Reservoir computing approximation and generalization bounds are proved for a new concept class of input/output systems that extends the so-called generalized Barron functionals to a dynamic context. This new class is characterized by the readouts with a certain integral representation built on infinite-dimensional state-space systems. It is shown that this class is very rich and possesses useful features and universal approximation properties. The reservoir architectures used for the approximation and estimation of elements in the new class are randomly generated echo state networks with either linear or ReLU activation functions. Their readouts are built using randomly generated neural networks in which only the output layer is trained (extreme learning machines or random feature neural networks). The results in the paper yield a fully implementable recurrent neural network-based learning algorithm with provable convergence guarantees that do not suffer from the curse of dimensionalit",
    "link": "http://arxiv.org/abs/2304.00490",
    "context": "Title: Infinite-dimensional reservoir computing. (arXiv:2304.00490v1 [cs.LG])\nAbstract: Reservoir computing approximation and generalization bounds are proved for a new concept class of input/output systems that extends the so-called generalized Barron functionals to a dynamic context. This new class is characterized by the readouts with a certain integral representation built on infinite-dimensional state-space systems. It is shown that this class is very rich and possesses useful features and universal approximation properties. The reservoir architectures used for the approximation and estimation of elements in the new class are randomly generated echo state networks with either linear or ReLU activation functions. Their readouts are built using randomly generated neural networks in which only the output layer is trained (extreme learning machines or random feature neural networks). The results in the paper yield a fully implementable recurrent neural network-based learning algorithm with provable convergence guarantees that do not suffer from the curse of dimensionalit",
    "path": "papers/23/04/2304.00490.json",
    "total_tokens": 650,
    "translated_title": "无限维储备计算",
    "translated_abstract": "本文证明了一类新的概念类别的储备计算逼近和泛化边界，将所谓的广义Barron函数扩展到动态环境。这个新类别的特征是具有某种积分表示的读出，建立在无限维状态空间系统上。结果表明，这个类别非常丰富，并具有有用的特点和全局逼近性质。",
    "tldr": "本文证明了一类新的概念类别的储备计算逼近和泛化边界，使得机器学习算法具有更好的实现性能。",
    "en_tdlr": "This paper proves approximation and generalization bounds for a new concept class of reservoir computing, extending the generalized Barron functionals to a dynamic context. The results provide a fully implementable recurrent neural network-based learning algorithm with improved performance."
}