{
    "title": "Coincidental Generation. (arXiv:2304.01108v2 [cs.CV] UPDATED)",
    "abstract": "Generative A.I. models have emerged as versatile tools across diverse industries, with applications in privacy-preserving data sharing, computational art, personalization of products and services, and immersive entertainment. Here, we introduce a new privacy concern in the adoption and use of generative A.I. models: that of coincidental generation, where a generative model's output is similar enough to an existing entity, beyond those represented in the dataset used to train the model, to be mistaken for it. Consider, for example, synthetic portrait generators, which are today deployed in commercial applications such as virtual modeling agencies and synthetic stock photography. Due to the low intrinsic dimensionality of human face perception, every synthetically generated face will coincidentally resemble an actual person. Such examples of coincidental generation all but guarantee the misappropriation of likeness and expose organizations that use generative A.I. to legal and regulatory",
    "link": "http://arxiv.org/abs/2304.01108",
    "context": "Title: Coincidental Generation. (arXiv:2304.01108v2 [cs.CV] UPDATED)\nAbstract: Generative A.I. models have emerged as versatile tools across diverse industries, with applications in privacy-preserving data sharing, computational art, personalization of products and services, and immersive entertainment. Here, we introduce a new privacy concern in the adoption and use of generative A.I. models: that of coincidental generation, where a generative model's output is similar enough to an existing entity, beyond those represented in the dataset used to train the model, to be mistaken for it. Consider, for example, synthetic portrait generators, which are today deployed in commercial applications such as virtual modeling agencies and synthetic stock photography. Due to the low intrinsic dimensionality of human face perception, every synthetically generated face will coincidentally resemble an actual person. Such examples of coincidental generation all but guarantee the misappropriation of likeness and expose organizations that use generative A.I. to legal and regulatory",
    "path": "papers/23/04/2304.01108.json",
    "total_tokens": 897,
    "translated_title": "偶然生成——生成式人工智能中的隐私风险",
    "translated_abstract": "生成式人工智能模型已经成为跨各行业的多功能工具，可以应用于隐私数据共享、计算艺术、产品和服务的个性化以及沉浸式娱乐等领域。本文提出了在采用和使用生成式人工智能模型中出现的一种新的隐私担忧——偶然生成。在偶然生成中，生成模型的输出与现有实体相似，超出了用于训练模型的数据集所代表的范围，甚至被误认为是某个实体。举个例子，虚拟模特机构和虚拟股票照片等商业应用中常常使用合成肖像图生成器。由于人脸感知的低内在维度，每个合成生成的脸都会偶然地或多或少地类似于真实人物。这样的偶然生成例子几乎可以保证视觉相似性误导法律和监管机构，暴露了使用生成式人工智能的组织面临的法律和监管风险。",
    "tldr": "生成式人工智能的一种新隐私担忧：偶然生成，可能误导法律和监管机构，暴露个人肖像的法律和监管风险。",
    "en_tdlr": "A new privacy concern in the adoption and use of generative AI models - coincidental generation - poses legal and regulatory risks by producing outputs similar enough to existing entities to be mistaken for them, particularly for synthetic portrait generators, and exposes organizations using generative AI to misappropriation of likeness."
}