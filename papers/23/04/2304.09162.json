{
    "title": "Robust Calibrate Proxy Loss for Deep Metric Learning. (arXiv:2304.09162v1 [cs.IR])",
    "abstract": "The mainstream researche in deep metric learning can be divided into two genres: proxy-based and pair-based methods. Proxy-based methods have attracted extensive attention due to the lower training complexity and fast network convergence. However, these methods have limitations as the poxy optimization is done by network, which makes it challenging for the proxy to accurately represent the feature distrubtion of the real class of data. In this paper, we propose a Calibrate Proxy (CP) structure, which uses the real sample information to improve the similarity calculation in proxy-based loss and introduces a calibration loss to constraint the proxy optimization towards the center of the class features. At the same time, we set a small number of proxies for each class to alleviate the impact of intra-class differences on retrieval performance. The effectiveness of our method is evaluated by extensive experiments on three public datasets and multiple synthetic label-noise datasets. The res",
    "link": "http://arxiv.org/abs/2304.09162",
    "context": "Title: Robust Calibrate Proxy Loss for Deep Metric Learning. (arXiv:2304.09162v1 [cs.IR])\nAbstract: The mainstream researche in deep metric learning can be divided into two genres: proxy-based and pair-based methods. Proxy-based methods have attracted extensive attention due to the lower training complexity and fast network convergence. However, these methods have limitations as the poxy optimization is done by network, which makes it challenging for the proxy to accurately represent the feature distrubtion of the real class of data. In this paper, we propose a Calibrate Proxy (CP) structure, which uses the real sample information to improve the similarity calculation in proxy-based loss and introduces a calibration loss to constraint the proxy optimization towards the center of the class features. At the same time, we set a small number of proxies for each class to alleviate the impact of intra-class differences on retrieval performance. The effectiveness of our method is evaluated by extensive experiments on three public datasets and multiple synthetic label-noise datasets. The res",
    "path": "papers/23/04/2304.09162.json",
    "total_tokens": 876,
    "translated_title": "深度度量学习的鲁棒性校准代理损失",
    "translated_abstract": "深度度量学习中，主流研究可分为两种：基于代理的方法和基于成对的方法。基于代理的方法由于训练复杂度低、网络收敛快速而受到广泛关注。然而，这些方法的局限在于代理优化由网络完成，使得难以准确地表示数据实际类别的特征分布情况。本文提出了一种 Calibrate Proxy（CP）结构，利用实际样本信息改善了基于代理的损失的相似度计算，并引入了校准损失来约束代理优化朝向类别特征中心。同时，我们为每个类别设置了少量代理以减轻类内差异对检索性能的影响。通过在三个公共数据集和多个合成标签噪声数据集上进行了广泛的实验评估了我们方法的有效性。",
    "tldr": "本研究提出了一种新的 Calibrate Proxy 结构，通过利用实际样本信息改善了基于代理的损失相似性计算，引入一个校准损失来约束代理优化方向类别特征中心。实验证明了该方法在多个数据集上都取得了较好表现。",
    "en_tdlr": "This paper proposes a new Calibrate Proxy structure, which improves the similarity calculation in proxy-based loss by utilizing real sample information, introduces a calibration loss to constraint the proxy optimization towards the center of the class features, and shows the effectiveness on multiple datasets."
}