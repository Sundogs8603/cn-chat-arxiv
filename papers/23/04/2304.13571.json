{
    "title": "Quantum Natural Policy Gradients: Towards Sample-Efficient Reinforcement Learning. (arXiv:2304.13571v1 [quant-ph] CROSS LISTED)",
    "abstract": "Reinforcement learning is a growing field in AI with a lot of potential. Intelligent behavior is learned automatically through trial and error in interaction with the environment. However, this learning process is often costly. Using variational quantum circuits as function approximators can reduce this cost. In order to implement this, we propose the quantum natural policy gradient (QNPG) algorithm -- a second-order gradient-based routine that takes advantage of an efficient approximation of the quantum Fisher information matrix. We experimentally demonstrate that QNPG outperforms first-order based training on Contextual Bandits environments regarding convergence speed and stability and thereby reduces the sample complexity. Furthermore, we provide evidence for the practical feasibility of our approach by training on a 12-qubit hardware device.",
    "link": "http://arxiv.org/abs/2304.13571",
    "context": "Title: Quantum Natural Policy Gradients: Towards Sample-Efficient Reinforcement Learning. (arXiv:2304.13571v1 [quant-ph] CROSS LISTED)\nAbstract: Reinforcement learning is a growing field in AI with a lot of potential. Intelligent behavior is learned automatically through trial and error in interaction with the environment. However, this learning process is often costly. Using variational quantum circuits as function approximators can reduce this cost. In order to implement this, we propose the quantum natural policy gradient (QNPG) algorithm -- a second-order gradient-based routine that takes advantage of an efficient approximation of the quantum Fisher information matrix. We experimentally demonstrate that QNPG outperforms first-order based training on Contextual Bandits environments regarding convergence speed and stability and thereby reduces the sample complexity. Furthermore, we provide evidence for the practical feasibility of our approach by training on a 12-qubit hardware device.",
    "path": "papers/23/04/2304.13571.json",
    "total_tokens": 888,
    "translated_title": "量子自然策略梯度：向样本高效增强学习迈进",
    "translated_abstract": "强化学习是人工智能领域的一个快速发展的方向，但学习过程通常很耗费资源。使用变分量子电路作为函数逼近器可以减少成本，提高强化学习效率。本文中，我们提出了量子自然策略梯度(QNPG)算法，该算法利用了量子费舍尔信息矩阵的高效近似方法，是一种二阶梯度的基于策略的算法。在Contextual Bandits环境下的实验结果表明，QNPG 比基于一阶梯度的训练具有更快的收敛速度和稳定性，从而减少了样本复杂度，进一步展示了我们方法的实际可行性，并在12量子比特的硬件设备上进行了训练。",
    "tldr": "本文提出了量子自然策略梯度(QNPG)算法，利用了量子费舍尔信息矩阵的高效近似方法，提高了强化学习的效率，实验结果表明，相比基于一阶梯度的训练，QNPG具有更快的收敛速度和稳定性，可以减少样本复杂度。",
    "en_tdlr": "This paper proposes the Quantum Natural Policy Gradients (QNPG) algorithm, which utilizes an efficient approximation of the quantum Fisher information matrix to improve the efficiency of reinforcement learning. Experimental results show that QNPG outperforms first-order-based training in terms of convergence speed and stability, reducing sample complexity. The algorithm was demonstrated to be practically feasible by being trained on a 12-qubit hardware device."
}