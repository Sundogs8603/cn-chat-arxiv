{
    "title": "Cooperative Multi-Agent Reinforcement Learning for Inventory Management. (arXiv:2304.08769v1 [cs.LG])",
    "abstract": "With Reinforcement Learning (RL) for inventory management (IM) being a nascent field of research, approaches tend to be limited to simple, linear environments with implementations that are minor modifications of off-the-shelf RL algorithms. Scaling these simplistic environments to a real-world supply chain comes with a few challenges such as: minimizing the computational requirements of the environment, specifying agent configurations that are representative of dynamics at real world stores and warehouses, and specifying a reward framework that encourages desirable behavior across the whole supply chain. In this work, we present a system with a custom GPU-parallelized environment that consists of one warehouse and multiple stores, a novel architecture for agent-environment dynamics incorporating enhanced state and action spaces, and a shared reward specification that seeks to optimize for a large retailer's supply chain needs. Each vertex in the supply chain graph is an independent age",
    "link": "http://arxiv.org/abs/2304.08769",
    "context": "Title: Cooperative Multi-Agent Reinforcement Learning for Inventory Management. (arXiv:2304.08769v1 [cs.LG])\nAbstract: With Reinforcement Learning (RL) for inventory management (IM) being a nascent field of research, approaches tend to be limited to simple, linear environments with implementations that are minor modifications of off-the-shelf RL algorithms. Scaling these simplistic environments to a real-world supply chain comes with a few challenges such as: minimizing the computational requirements of the environment, specifying agent configurations that are representative of dynamics at real world stores and warehouses, and specifying a reward framework that encourages desirable behavior across the whole supply chain. In this work, we present a system with a custom GPU-parallelized environment that consists of one warehouse and multiple stores, a novel architecture for agent-environment dynamics incorporating enhanced state and action spaces, and a shared reward specification that seeks to optimize for a large retailer's supply chain needs. Each vertex in the supply chain graph is an independent age",
    "path": "papers/23/04/2304.08769.json",
    "total_tokens": 1020,
    "translated_title": "库存管理的合作多智能体强化学习",
    "translated_abstract": "基于强化学习（RL）的库存管理（IM）是一个新兴的研究领域，现有方法往往局限于实现简单、线性环境，并做出些微调整以获得RL算法。将这些简单的环境扩展到实际供应链系统中存在一些挑战，例如：降低环境计算量，定义代理程序配置以代表实际店铺和仓库的动态特性，以及指定奖励框架以鼓励整个供应链中的良好行为。在本文中，我们提出了一个具有自定义GPU并行环境的系统，该环境包括一个仓库和多个商店，提出了一种结构用于代理-环境动态，包括增强状态和操作空间，以及分享奖励机制，以优化大型零售商的供应链需求。供应链图中的每个顶点都是一个独立的智能体，通过分散式Actor-Critic方法进行训练，并通过中央评论家通信来实现合作。我们的结果表明，与传统的单一智能体RL解决方案相比，多智能体系统在供应链场景中具有明显的优势。",
    "tldr": "本文提出了一种用于库存管理的多智能体合作强化学习系统，包括自定义GPU并行环境和分享奖励机制，通过分散式Actor-Critic方法进行培训。在供应链场景中，与传统的单一智能体RL解决方案相比，多智能体系统具有明显的优势。",
    "en_tdlr": "This paper proposes a multi-agent cooperation reinforcement learning system for inventory management, which includes a customized GPU-parallelized environment and a shared reward specification, trained by decentralized Actor-Critic methodology. In the supply chain scenario, the multi-agent system has a clear advantage over traditional single-agent RL solutions."
}