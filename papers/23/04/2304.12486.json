{
    "title": "Evaluating Adversarial Robustness on Document Image Classification. (arXiv:2304.12486v1 [cs.CV])",
    "abstract": "Adversarial attacks and defenses have gained increasing interest on computer vision systems in recent years, but as of today, most investigations are limited to images. However, many artificial intelligence models actually handle documentary data, which is very different from real world images. Hence, in this work, we try to apply the adversarial attack philosophy on documentary and natural data and to protect models against such attacks. We focus our work on untargeted gradient-based, transfer-based and score-based attacks and evaluate the impact of adversarial training, JPEG input compression and grey-scale input transformation on the robustness of ResNet50 and EfficientNetB0 model architectures. To the best of our knowledge, no such work has been conducted by the community in order to study the impact of these attacks on the document image classification task.",
    "link": "http://arxiv.org/abs/2304.12486",
    "context": "Title: Evaluating Adversarial Robustness on Document Image Classification. (arXiv:2304.12486v1 [cs.CV])\nAbstract: Adversarial attacks and defenses have gained increasing interest on computer vision systems in recent years, but as of today, most investigations are limited to images. However, many artificial intelligence models actually handle documentary data, which is very different from real world images. Hence, in this work, we try to apply the adversarial attack philosophy on documentary and natural data and to protect models against such attacks. We focus our work on untargeted gradient-based, transfer-based and score-based attacks and evaluate the impact of adversarial training, JPEG input compression and grey-scale input transformation on the robustness of ResNet50 and EfficientNetB0 model architectures. To the best of our knowledge, no such work has been conducted by the community in order to study the impact of these attacks on the document image classification task.",
    "path": "papers/23/04/2304.12486.json",
    "total_tokens": 848,
    "translated_title": "评估文档图像分类的对抗性鲁棒性",
    "translated_abstract": "近年来，对抗攻击和防御在计算机视觉系统上引起了越来越多的关注，但至今大部分研究仅限于图像。然而，许多人工智能模型实际上处理的是文档数据，这与真实世界的图像非常不同。因此，在本研究中，我们尝试将对抗攻击哲学应用于文献和自然数据，并保护模型免受此类攻击。我们的研究集中在无目标基于梯度、基于转移和基于分数的攻击上，并评估对抗训练、JPEG输入压缩和灰度输入转换对ResNet50和EfficientNetB0模型架构鲁棒性的影响。据我们所知，社区没有进行这样的研究以研究这些攻击对文档图像分类任务的影响。",
    "tldr": "本文对文档图像分类任务中的对抗性攻击进行了研究和评估，通过对ResNet50和EfficientNetB0模型架构进行对抗训练、JPEG输入压缩和灰度输入转换等方法，提高了模型的鲁棒性。",
    "en_tdlr": "This paper evaluates adversarial attacks on document image classification and proposes methods such as adversarial training, JPEG compression, and grayscale input transformation to improve the robustness of models, especially ResNet50 and EfficientNetB0."
}