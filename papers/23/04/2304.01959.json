{
    "title": "Randomized Adversarial Style Perturbations for Domain Generalization. (arXiv:2304.01959v1 [cs.CV])",
    "abstract": "We propose a novel domain generalization technique, referred to as Randomized Adversarial Style Perturbation (RASP), which is motivated by the observation that the characteristics of each domain are captured by the feature statistics corresponding to style. The proposed algorithm perturbs the style of a feature in an adversarial direction towards a randomly selected class, and makes the model learn against being misled by the unexpected styles observed in unseen target domains. While RASP is effective to handle domain shifts, its naive integration into the training procedure might degrade the capability of learning knowledge from source domains because it has no restriction on the perturbations of representations. This challenge is alleviated by Normalized Feature Mixup (NFM), which facilitates the learning of the original features while achieving robustness to perturbed representations via their mixup during training. We evaluate the proposed algorithm via extensive experiments on var",
    "link": "http://arxiv.org/abs/2304.01959",
    "context": "Title: Randomized Adversarial Style Perturbations for Domain Generalization. (arXiv:2304.01959v1 [cs.CV])\nAbstract: We propose a novel domain generalization technique, referred to as Randomized Adversarial Style Perturbation (RASP), which is motivated by the observation that the characteristics of each domain are captured by the feature statistics corresponding to style. The proposed algorithm perturbs the style of a feature in an adversarial direction towards a randomly selected class, and makes the model learn against being misled by the unexpected styles observed in unseen target domains. While RASP is effective to handle domain shifts, its naive integration into the training procedure might degrade the capability of learning knowledge from source domains because it has no restriction on the perturbations of representations. This challenge is alleviated by Normalized Feature Mixup (NFM), which facilitates the learning of the original features while achieving robustness to perturbed representations via their mixup during training. We evaluate the proposed algorithm via extensive experiments on var",
    "path": "papers/23/04/2304.01959.json",
    "total_tokens": 919,
    "translated_title": "随机对抗风格扰动技术用于域泛化",
    "translated_abstract": "本文提出了一种新颖的域泛化技术，称为随机对抗风格扰动技术（RASP），其动机在于特征统计学捕捉到每个域的特征。该算法在对抗性方向上扰动一个特征的风格，朝着一个随机选择的类别方向并使模型学习避免被在未知目标域中观察到的意外风格所误导。虽然RASP能有效处理域漂移，但它的简单融合到训练过程中可能会降低从源域学习知识的能力，因为它并不限制表征的扰动。这个挑战由规一化特征Mixup（NFM）缓解，它通过训练过程中的特征混合来促进原始特征的学习，同时实现了对扰动表示的鲁棒性。我们通过广泛的实验评估了所提出的算法。",
    "tldr": "本文提出了一种随机对抗风格扰动技术，它能够通过对抗性扰动特征风格达到域泛化的效果，同时结合混合原始特征的方法缓解扰动带来的挑战。",
    "en_tdlr": ""
}