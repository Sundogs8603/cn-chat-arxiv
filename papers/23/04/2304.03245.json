{
    "title": "Large language models effectively leverage document-level context for literary translation, but critical errors persist. (arXiv:2304.03245v1 [cs.CL])",
    "abstract": "Large language models (LLMs) are competitive with the state of the art on a wide range of sentence-level translation datasets. However, their ability to translate paragraphs and documents remains unexplored because evaluation in these settings is costly and difficult. We show through a rigorous human evaluation that asking the Gpt-3.5 (text-davinci-003) LLM to translate an entire literary paragraph (e.g., from a novel) at once results in higher-quality translations than standard sentence-by-sentence translation across 18 linguistically-diverse language pairs (e.g., translating into and out of Japanese, Polish, and English). Our evaluation, which took approximately 350 hours of effort for annotation and analysis, is conducted by hiring translators fluent in both the source and target language and asking them to provide both span-level error annotations as well as preference judgments of which system's translations are better. We observe that discourse-level LLM translators commit fewer ",
    "link": "http://arxiv.org/abs/2304.03245",
    "context": "Title: Large language models effectively leverage document-level context for literary translation, but critical errors persist. (arXiv:2304.03245v1 [cs.CL])\nAbstract: Large language models (LLMs) are competitive with the state of the art on a wide range of sentence-level translation datasets. However, their ability to translate paragraphs and documents remains unexplored because evaluation in these settings is costly and difficult. We show through a rigorous human evaluation that asking the Gpt-3.5 (text-davinci-003) LLM to translate an entire literary paragraph (e.g., from a novel) at once results in higher-quality translations than standard sentence-by-sentence translation across 18 linguistically-diverse language pairs (e.g., translating into and out of Japanese, Polish, and English). Our evaluation, which took approximately 350 hours of effort for annotation and analysis, is conducted by hiring translators fluent in both the source and target language and asking them to provide both span-level error annotations as well as preference judgments of which system's translations are better. We observe that discourse-level LLM translators commit fewer ",
    "path": "papers/23/04/2304.03245.json",
    "total_tokens": 978,
    "translated_title": "大型语言模型在文学翻译中高效利用文档级上下文，但关键错误仍然存在",
    "translated_abstract": "大型语言模型（LLMs）在许多句子级别的翻译数据集上与现有技术水平相当。然而，它们在段落和文档翻译方面的能力尚未得到探究，因为这些环境下的评估代价高且困难。通过一项严谨的人工评估，我们展示了要求Gpt-3.5（text-davinci-003）LLM将整个文学段落（例如，从小说中）进行翻译的结果比标准的逐句翻译在18个语言对（例如，日语、波兰语和英语的翻译）上产生更高质量的翻译。我们的评估需要约350个小时的注释和分析工作，通过聘请熟练掌握源语言和目标语言的译者，并要求他们提供跨度级别的错误注释以及哪种系统的翻译更好的偏好判断。我们观察到，篇章级别的LLM翻译在文学段落的翻译中出现的关键错误更少，但仍存在一些与上下文和意义相关的错误。",
    "tldr": "该研究通过人工评估发现，大型语言模型在进行文学段落翻译时会利用更多的文档级上下文，从而减少关键错误。然而，一些与上下文和意义相关的错误仍然存在。",
    "en_tdlr": "This study shows through human evaluation that large language models can better translate literary paragraphs by leveraging document-level context, reducing critical errors, but some errors related to context and meaning still persist."
}