{
    "title": "Multi-View Graph Representation Learning Beyond Homophily. (arXiv:2304.07509v1 [cs.LG])",
    "abstract": "Unsupervised graph representation learning(GRL) aims to distill diverse graph information into task-agnostic embeddings without label supervision. Due to a lack of support from labels, recent representation learning methods usually adopt self-supervised learning, and embeddings are learned by solving a handcrafted auxiliary task(so-called pretext task). However, partially due to the irregular non-Euclidean data in graphs, the pretext tasks are generally designed under homophily assumptions and cornered in the low-frequency signals, which results in significant loss of other signals, especially high-frequency signals widespread in graphs with heterophily. Motivated by this limitation, we propose a multi-view perspective and the usage of diverse pretext tasks to capture different signals in graphs into embeddings. A novel framework, denoted as Multi-view Graph Encoder(MVGE), is proposed, and a set of key designs are identified. More specifically, a set of new pretext tasks are designed t",
    "link": "http://arxiv.org/abs/2304.07509",
    "context": "Title: Multi-View Graph Representation Learning Beyond Homophily. (arXiv:2304.07509v1 [cs.LG])\nAbstract: Unsupervised graph representation learning(GRL) aims to distill diverse graph information into task-agnostic embeddings without label supervision. Due to a lack of support from labels, recent representation learning methods usually adopt self-supervised learning, and embeddings are learned by solving a handcrafted auxiliary task(so-called pretext task). However, partially due to the irregular non-Euclidean data in graphs, the pretext tasks are generally designed under homophily assumptions and cornered in the low-frequency signals, which results in significant loss of other signals, especially high-frequency signals widespread in graphs with heterophily. Motivated by this limitation, we propose a multi-view perspective and the usage of diverse pretext tasks to capture different signals in graphs into embeddings. A novel framework, denoted as Multi-view Graph Encoder(MVGE), is proposed, and a set of key designs are identified. More specifically, a set of new pretext tasks are designed t",
    "path": "papers/23/04/2304.07509.json",
    "total_tokens": 854,
    "translated_abstract": "无监督的图形表示学习旨在在不需要标签监督的情况下提炼出多样的图形信息，并将其转化为任务不可知的嵌入。由于缺乏标签支持，最近的表示学习方法通常采用自我监督学习，并通过解决手工辅助任务（所谓的前文任务）来学习嵌入。然而，由于图形中的不规则非欧几里得数据，前文任务通常在同质性假设下进行设计，并且被局限于低频信号，导致其他信号的显著丢失，尤其是在具有异质性的图形中普遍存在的高频信号。受此限制的启发，我们提出了一个多视角的框架，并使用多种前文任务来捕捉图形中的不同信号以形成嵌入。我们提出了一种新的框架，称为多视角图形编码器（MVGE），并确定了一组关键设计。",
    "tldr": "本论文提出了一种超越同质性的多视角图形表示学习方法，通过使用多任务和多视角，捕捉异质性图形中不同的信号以形成嵌入。"
}