{
    "title": "Unsupervised Synthetic Image Refinement via Contrastive Learning and Consistent Semantic and Structure Constraints. (arXiv:2304.12591v1 [cs.CV])",
    "abstract": "Ensuring the realism of computer-generated synthetic images is crucial to deep neural network (DNN) training. Due to different semantic distributions between synthetic and real-world captured datasets, there exists semantic mismatch between synthetic and refined images, which in turn results in the semantic distortion. Recently, contrastive learning (CL) has been successfully used to pull correlated patches together and push uncorrelated ones apart. In this work, we exploit semantic and structural consistency between synthetic and refined images and adopt CL to reduce the semantic distortion. Besides, we incorporate hard negative mining to improve the performance furthermore. We compare the performance of our method with several other benchmarking methods using qualitative and quantitative measures and show that our method offers the state-of-the-art performance.",
    "link": "http://arxiv.org/abs/2304.12591",
    "context": "Title: Unsupervised Synthetic Image Refinement via Contrastive Learning and Consistent Semantic and Structure Constraints. (arXiv:2304.12591v1 [cs.CV])\nAbstract: Ensuring the realism of computer-generated synthetic images is crucial to deep neural network (DNN) training. Due to different semantic distributions between synthetic and real-world captured datasets, there exists semantic mismatch between synthetic and refined images, which in turn results in the semantic distortion. Recently, contrastive learning (CL) has been successfully used to pull correlated patches together and push uncorrelated ones apart. In this work, we exploit semantic and structural consistency between synthetic and refined images and adopt CL to reduce the semantic distortion. Besides, we incorporate hard negative mining to improve the performance furthermore. We compare the performance of our method with several other benchmarking methods using qualitative and quantitative measures and show that our method offers the state-of-the-art performance.",
    "path": "papers/23/04/2304.12591.json",
    "total_tokens": 769,
    "translated_title": "通过对比学习和一致的语义和结构约束进行无监督合成图像细化",
    "translated_abstract": "确保计算机生成的合成图像的真实性对于深度神经网络（DNN）的训练至关重要。由于合成和真实数据集之间存在不同的语义分布，因此合成和细化图像之间存在语义不匹配，进而导致语义失真。最近，对比学习（CL）已成功地用于将相关补丁拉在一起并将不相关的补丁推开。在这项工作中，我们利用合成和精细图像之间的语义和结构一致性，并采用CL来减少语义失真。此外，我们还采用了硬负采样来进一步提高性能。我们使用定性和定量措施比较了我们方法与几种其他基准方法的性能，并表明我们的方法提供了最先进的性能。",
    "tldr": "本文采用对比学习和一致的语义和结构约束来减少合成和细化图像之间的语义失真，进一步提高了性能。",
    "en_tdlr": "This paper reduces semantic distortion between synthetic and refined images through contrastive learning and consistent semantic and structure constraints, achieving state-of-the-art performance."
}