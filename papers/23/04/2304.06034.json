{
    "title": "Social Biases through the Text-to-Image Generation Lens. (arXiv:2304.06034v1 [cs.CY])",
    "abstract": "Text-to-Image (T2I) generation is enabling new applications that support creators, designers, and general end users of productivity software by generating illustrative content with high photorealism starting from a given descriptive text as a prompt. Such models are however trained on massive amounts of web data, which surfaces the peril of potential harmful biases that may leak in the generation process itself. In this paper, we take a multi-dimensional approach to studying and quantifying common social biases as reflected in the generated images, by focusing on how occupations, personality traits, and everyday situations are depicted across representations of (perceived) gender, age, race, and geographical location. Through an extensive set of both automated and human evaluation experiments we present findings for two popular T2I models: DALLE-v2 and Stable Diffusion. Our results reveal that there exist severe occupational biases of neutral prompts majorly excluding groups of people ",
    "link": "http://arxiv.org/abs/2304.06034",
    "context": "Title: Social Biases through the Text-to-Image Generation Lens. (arXiv:2304.06034v1 [cs.CY])\nAbstract: Text-to-Image (T2I) generation is enabling new applications that support creators, designers, and general end users of productivity software by generating illustrative content with high photorealism starting from a given descriptive text as a prompt. Such models are however trained on massive amounts of web data, which surfaces the peril of potential harmful biases that may leak in the generation process itself. In this paper, we take a multi-dimensional approach to studying and quantifying common social biases as reflected in the generated images, by focusing on how occupations, personality traits, and everyday situations are depicted across representations of (perceived) gender, age, race, and geographical location. Through an extensive set of both automated and human evaluation experiments we present findings for two popular T2I models: DALLE-v2 and Stable Diffusion. Our results reveal that there exist severe occupational biases of neutral prompts majorly excluding groups of people ",
    "path": "papers/23/04/2304.06034.json",
    "total_tokens": 860,
    "translated_title": "从文本到图像生成角度审视社会偏见",
    "translated_abstract": "文本到图像 (T2I) 生成技术通过将给定的文本描述作为提示，生成高逼真度的插图，为创作者、设计师和普通用户提供了新的应用。然而，这些模型是在大量的网络数据上训练的，这也带来了潜在的有害偏见风险。本文通过研究和量化常见的社会偏见，如职业、人格特征和日常情境在（被感知的）性别、年龄、种族和地理位置上的表现，采用多维度方法来探究生成图片中的社会偏见。通过广泛的自动化和人类评估实验，我们展示了两种流行的 T2I 模型 (DALLE-v2 和 Stable Diffusion) 的发现。结果表明，中性提示存在严重的职业偏见，主要是排除某些人群。",
    "tldr": "本文研究了文本到图像生成技术中存在的社会偏见，主要集中在职业、人格特征和日常情境等方面。实验证明，这些模型存在排除特定人群的职业偏见。",
    "en_tdlr": "This paper explores social biases in text-to-image generation technology, specifically focusing on how occupations, personality traits, and everyday situations are depicted across representations of (perceived) gender, age, race, and geographical location. The findings reveal severe occupational biases, which majorly exclude certain groups of people."
}