{
    "title": "LasUIE: Unifying Information Extraction with Latent Adaptive Structure-aware Generative Language Model. (arXiv:2304.06248v1 [cs.CL])",
    "abstract": "Universally modeling all typical information extraction tasks (UIE) with one generative language model (GLM) has revealed great potential by the latest study, where various IE predictions are unified into a linearized hierarchical expression under a GLM. Syntactic structure information, a type of effective feature which has been extensively utilized in IE community, should also be beneficial to UIE. In this work, we propose a novel structure-aware GLM, fully unleashing the power of syntactic knowledge for UIE. A heterogeneous structure inductor is explored to unsupervisedly induce rich heterogeneous structural representations by post-training an existing GLM. In particular, a structural broadcaster is devised to compact various latent trees into explicit high-order forests, helping to guide a better generation during decoding. We finally introduce a task-oriented structure fine-tuning mechanism, further adjusting the learned structures to most coincide with the end-task's need. Over 12",
    "link": "http://arxiv.org/abs/2304.06248",
    "context": "Title: LasUIE: Unifying Information Extraction with Latent Adaptive Structure-aware Generative Language Model. (arXiv:2304.06248v1 [cs.CL])\nAbstract: Universally modeling all typical information extraction tasks (UIE) with one generative language model (GLM) has revealed great potential by the latest study, where various IE predictions are unified into a linearized hierarchical expression under a GLM. Syntactic structure information, a type of effective feature which has been extensively utilized in IE community, should also be beneficial to UIE. In this work, we propose a novel structure-aware GLM, fully unleashing the power of syntactic knowledge for UIE. A heterogeneous structure inductor is explored to unsupervisedly induce rich heterogeneous structural representations by post-training an existing GLM. In particular, a structural broadcaster is devised to compact various latent trees into explicit high-order forests, helping to guide a better generation during decoding. We finally introduce a task-oriented structure fine-tuning mechanism, further adjusting the learned structures to most coincide with the end-task's need. Over 12",
    "path": "papers/23/04/2304.06248.json",
    "total_tokens": 1111,
    "translated_title": "LasUIE:利用潜在自适应结构感知生成语言模型统一信息提取",
    "translated_abstract": "最近的研究通过一个生成语言模型（GLM）普遍地建模所有典型的信息提取任务（UIE），将各种IE预测统一为GLM下的线性分层表达，显示出很大的潜力。句法结构信息是IE社区广泛利用的一种有效特征，也应有益于UIE，本文提出了一种新颖的结构感知GLM，充分释放了句法知识对UIE的影响力。采用异构结构感知器来后训练现有的GLM，无监督地引入了丰富的异构结构表示。特别的，提出一种结构广播器，将各种潜在树压缩成明确的高阶森林，在解码期间有助于引导更好的生成。最后，引入一种面向任务的结构微调机制，进一步调整学习到的结构，使其更符合最终任务的需要。超过12,000个句子进行了注释，构建了三个基准数据集来评估所提出的模型。广泛的实验表明，所提出的模型在所有三个基准数据集上都明显优于现有模型，证明了我们所提出的结构感知方法的有效性。",
    "tldr": "本论文基于已有的生成语言模型，提出了一种结构感知GLM模型，通过异构结构感知器后训练，引入了句法知识，提出了结构广播器引导更好的生成，以及引入了面向任务的结构微调机制。在三个基准数据集上实验表明，该模型优于现有模型，展示了结构感知在信息提取中的有效性。",
    "en_tdlr": "This paper proposes a structure-aware GLM model leveraging existing generative language models, introducing a heterogeneous structure inducer to unsupervisedly induce rich heterogeneous structural representations, proposing a structural broadcaster to guide better generation during decoding, and introducing a task-oriented structure fine-tuning mechanism. Experiments on three benchmark datasets show that the proposed model outperforms existing models, demonstrating the effectiveness of structure-awareness in information extraction."
}