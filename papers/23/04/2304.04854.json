{
    "title": "iPINNs: Incremental learning for Physics-informed neural networks. (arXiv:2304.04854v1 [cs.LG])",
    "abstract": "Physics-informed neural networks (PINNs) have recently become a powerful tool for solving partial differential equations (PDEs). However, finding a set of neural network parameters that lead to fulfilling a PDE can be challenging and non-unique due to the complexity of the loss landscape that needs to be traversed. Although a variety of multi-task learning and transfer learning approaches have been proposed to overcome these issues, there is no incremental training procedure for PINNs that can effectively mitigate such training challenges. We propose incremental PINNs (iPINNs) that can learn multiple tasks (equations) sequentially without additional parameters for new tasks and improve performance for every equation in the sequence. Our approach learns multiple PDEs starting from the simplest one by creating its own subnetwork for each PDE and allowing each subnetwork to overlap with previously learned subnetworks. We demonstrate that previous subnetworks are a good initialization for ",
    "link": "http://arxiv.org/abs/2304.04854",
    "context": "Title: iPINNs: Incremental learning for Physics-informed neural networks. (arXiv:2304.04854v1 [cs.LG])\nAbstract: Physics-informed neural networks (PINNs) have recently become a powerful tool for solving partial differential equations (PDEs). However, finding a set of neural network parameters that lead to fulfilling a PDE can be challenging and non-unique due to the complexity of the loss landscape that needs to be traversed. Although a variety of multi-task learning and transfer learning approaches have been proposed to overcome these issues, there is no incremental training procedure for PINNs that can effectively mitigate such training challenges. We propose incremental PINNs (iPINNs) that can learn multiple tasks (equations) sequentially without additional parameters for new tasks and improve performance for every equation in the sequence. Our approach learns multiple PDEs starting from the simplest one by creating its own subnetwork for each PDE and allowing each subnetwork to overlap with previously learned subnetworks. We demonstrate that previous subnetworks are a good initialization for ",
    "path": "papers/23/04/2304.04854.json",
    "total_tokens": 1035,
    "translated_title": "iPINNs：物理信息神经网络的增量学习",
    "translated_abstract": "物理信息神经网络（PINNs）最近成为解决偏微分方程（PDE）的强大工具。但由于需要遍历复杂的损失函数空间，找到一组满足PDE的神经网络参数可能具有挑战性和不唯一性。虽然已提出了各种多任务学习和转移学习方法来克服这些问题，但目前还没有针对PINNs的增量培训程序，它可以有效地减轻这些培训挑战。我们提出了增量PINNs（iPINNs），它可以顺序学习多个任务（方程），无需为新任务添加额外的参数，并改进序列中每个方程的性能。我们的方法从最简单的PDE开始学习多个PDE，为每个PDE创建自己的子网络，并允许每个子网络与之前学习的子网络重叠。我们证明了之前的子网络是新任务网络的良好初始化，从而提高了训练速度和精度。此外，我们的方法还提供了一种自适应学习的方法，以控制每个子网络的复杂性。在多个测试问题上进行的实验表明，iPINNs比其他PINN方法具有更高的准确性和更快的收敛速度。",
    "tldr": "提出了一种增量学习方法，可以顺序学习多个物理方程，而无需为新任务添加额外参数，在多个测试问题上展现了较高准确性和更快的收敛速度。",
    "en_tdlr": "A new incremental learning method, iPINNs, is proposed to sequentially learn multiple physics equations without the need for additional parameters, and demonstrates higher accuracy and quicker convergence on multiple test problems."
}