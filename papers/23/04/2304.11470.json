{
    "title": "3D-IntPhys: Towards More Generalized 3D-grounded Visual Intuitive Physics under Challenging Scenes. (arXiv:2304.11470v1 [cs.CV])",
    "abstract": "Given a visual scene, humans have strong intuitions about how a scene can evolve over time under given actions. The intuition, often termed visual intuitive physics, is a critical ability that allows us to make effective plans to manipulate the scene to achieve desired outcomes without relying on extensive trial and error. In this paper, we present a framework capable of learning 3D-grounded visual intuitive physics models from videos of complex scenes with fluids. Our method is composed of a conditional Neural Radiance Field (NeRF)-style visual frontend and a 3D point-based dynamics prediction backend, using which we can impose strong relational and structural inductive bias to capture the structure of the underlying environment. Unlike existing intuitive point-based dynamics works that rely on the supervision of dense point trajectory from simulators, we relax the requirements and only assume access to multi-view RGB images and (imperfect) instance masks acquired using color prior. T",
    "link": "http://arxiv.org/abs/2304.11470",
    "context": "Title: 3D-IntPhys: Towards More Generalized 3D-grounded Visual Intuitive Physics under Challenging Scenes. (arXiv:2304.11470v1 [cs.CV])\nAbstract: Given a visual scene, humans have strong intuitions about how a scene can evolve over time under given actions. The intuition, often termed visual intuitive physics, is a critical ability that allows us to make effective plans to manipulate the scene to achieve desired outcomes without relying on extensive trial and error. In this paper, we present a framework capable of learning 3D-grounded visual intuitive physics models from videos of complex scenes with fluids. Our method is composed of a conditional Neural Radiance Field (NeRF)-style visual frontend and a 3D point-based dynamics prediction backend, using which we can impose strong relational and structural inductive bias to capture the structure of the underlying environment. Unlike existing intuitive point-based dynamics works that rely on the supervision of dense point trajectory from simulators, we relax the requirements and only assume access to multi-view RGB images and (imperfect) instance masks acquired using color prior. T",
    "path": "papers/23/04/2304.11470.json",
    "total_tokens": 958,
    "translated_abstract": "人类根据视觉场景，能够对给定的行为下场景的演变有强烈的直觉。这种直觉被称为视觉直觉物理，是我们无需大量试错就可以有效计划操纵场景以达到预期结果的关键能力。本文提出了一种能够从复杂液体场景视频中学习三维视觉直觉物理模型的框架。我们的方法由一个条件神经辐射场（NeRF）风格的视觉前端和一个基于三维点的动态预测后端组成，通过这种方式我们可以施加强有力的关系和结构归纳偏好来捕获潜在环境的结构。与现有的依赖于模拟器中的密集点轨迹监督的直觉基点动力学工作不同，我们放宽了要求，只假设访问多视角RGB图像和（不完美的）实例掩码，其使用色彩优先获得。",
    "tldr": "本文提出了一种学习三维视觉直觉物理模型的框架，能够从复杂液体场景视频中进行训练，并通过强有力的关系和结构归纳偏好来捕获潜在环境的结构，而不需要依赖于模拟器中的密集点轨迹监督。",
    "en_tdlr": "This paper presents a framework that learns 3D visual intuitive physics models from videos of complex scenes, and captures the structure of the underlying environment with strong relational and structural inductive bias, without relying on dense point trajectory supervisions from simulators."
}