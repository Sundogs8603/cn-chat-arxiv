{
    "title": "How Will It Drape Like? Capturing Fabric Mechanics from Depth Images. (arXiv:2304.06704v1 [cs.CV])",
    "abstract": "We propose a method to estimate the mechanical parameters of fabrics using a casual capture setup with a depth camera. Our approach enables to create mechanically-correct digital representations of real-world textile materials, which is a fundamental step for many interactive design and engineering applications. As opposed to existing capture methods, which typically require expensive setups, video sequences, or manual intervention, our solution can capture at scale, is agnostic to the optical appearance of the textile, and facilitates fabric arrangement by non-expert operators. To this end, we propose a sim-to-real strategy to train a learning-based framework that can take as input one or multiple images and outputs a full set of mechanical parameters. Thanks to carefully designed data augmentation and transfer learning protocols, our solution generalizes to real images despite being trained only on synthetic data, hence successfully closing the sim-to-real loop.Key in our work is to ",
    "link": "http://arxiv.org/abs/2304.06704",
    "context": "Title: How Will It Drape Like? Capturing Fabric Mechanics from Depth Images. (arXiv:2304.06704v1 [cs.CV])\nAbstract: We propose a method to estimate the mechanical parameters of fabrics using a casual capture setup with a depth camera. Our approach enables to create mechanically-correct digital representations of real-world textile materials, which is a fundamental step for many interactive design and engineering applications. As opposed to existing capture methods, which typically require expensive setups, video sequences, or manual intervention, our solution can capture at scale, is agnostic to the optical appearance of the textile, and facilitates fabric arrangement by non-expert operators. To this end, we propose a sim-to-real strategy to train a learning-based framework that can take as input one or multiple images and outputs a full set of mechanical parameters. Thanks to carefully designed data augmentation and transfer learning protocols, our solution generalizes to real images despite being trained only on synthetic data, hence successfully closing the sim-to-real loop.Key in our work is to ",
    "path": "papers/23/04/2304.06704.json",
    "total_tokens": 918,
    "translated_title": "如何预测织物的自由落体效应? 通过深度图像捕捉织物力学特性",
    "translated_abstract": "我们提出了一种使用深度相机进行随意捕捉的方法来估计织物的力学参数。我们的方法可以创建真实世界纺织材料的机械正确数字表示，这是许多交互式设计和工程应用的基本步骤。与现有的捕捉方法相比，我们的解决方案可以在规模上进行捕捉，与纺织品的光学外观无关，并且易于由非专业操作者进行织物排列。为此，我们提出了一种模拟到真实的策略，以训练一个基于学习的框架，该框架可以将一个或多个图像作为输入并输出完整的力学参数集。由于经过精心设计的数据增强和转移学习协议，我们的解决方案可以推广到真实图像，尽管只是在合成数据上进行训练，因此成功地关闭了模拟到真实的循环。",
    "tldr": "该论文提出了一种使用深度相机进行随意捕捉的方法来预测织物的自由落体效应，并创新性地提出了一种模拟到真实的策略来训练学习框架，该框架可以输出完整的力学参数集。"
}