{
    "title": "RecUP-FL: Reconciling Utility and Privacy in Federated Learning via User-configurable Privacy Defense. (arXiv:2304.05135v1 [cs.LG])",
    "abstract": "Federated learning (FL) provides a variety of privacy advantages by allowing clients to collaboratively train a model without sharing their private data. However, recent studies have shown that private information can still be leaked through shared gradients. To further minimize the risk of privacy leakage, existing defenses usually require clients to locally modify their gradients (e.g., differential privacy) prior to sharing with the server. While these approaches are effective in certain cases, they regard the entire data as a single entity to protect, which usually comes at a large cost in model utility. In this paper, we seek to reconcile utility and privacy in FL by proposing a user-configurable privacy defense, RecUP-FL, that can better focus on the user-specified sensitive attributes while obtaining significant improvements in utility over traditional defenses. Moreover, we observe that existing inference attacks often rely on a machine learning model to extract the private inf",
    "link": "http://arxiv.org/abs/2304.05135",
    "context": "Title: RecUP-FL: Reconciling Utility and Privacy in Federated Learning via User-configurable Privacy Defense. (arXiv:2304.05135v1 [cs.LG])\nAbstract: Federated learning (FL) provides a variety of privacy advantages by allowing clients to collaboratively train a model without sharing their private data. However, recent studies have shown that private information can still be leaked through shared gradients. To further minimize the risk of privacy leakage, existing defenses usually require clients to locally modify their gradients (e.g., differential privacy) prior to sharing with the server. While these approaches are effective in certain cases, they regard the entire data as a single entity to protect, which usually comes at a large cost in model utility. In this paper, we seek to reconcile utility and privacy in FL by proposing a user-configurable privacy defense, RecUP-FL, that can better focus on the user-specified sensitive attributes while obtaining significant improvements in utility over traditional defenses. Moreover, we observe that existing inference attacks often rely on a machine learning model to extract the private inf",
    "path": "papers/23/04/2304.05135.json",
    "total_tokens": 1029,
    "translated_title": "RecUP-FL: 通过用户可配置的隐私防护实现联邦学习中的效用和隐私的协调",
    "translated_abstract": "联邦学习（FL）通过允许客户端协同训练模型而不共享私人数据，提供了各种隐私优势。然而，最近的研究表明，通过共享的梯度仍然可能泄露私人信息。为了进一步降低隐私泄露的风险，现有的防御通常要求客户端在共享给服务器之前本地修改其梯度（例如，差分隐私）。虽然这些方法在某些情况下是有效的，但它们将整个数据视为单个实体来保护，这通常会付出非常高的模型效用代价。在本文中，我们通过提出一个用户可配置的隐私防护机制RecUP-FL来协调FL中的效用和隐私，可以更好地关注用户指定的敏感属性，并在传统防御方法之上获得显着的模型效用改进。此外，我们观察到现有的推断攻击通常依赖于机器学习模型从共享的梯度中提取私人信息，并提出了一种可有效防御此类攻击的防御机制。我们在两个真实数据集上的实验结果表明，RecUP-FL实现了隐私和效用之间更好的平衡，超过了现有最先进方法。",
    "tldr": "该论文提出了一种名为RecUP-FL的用户可配置隐私防护机制，该机制可以更好地平衡隐私和效用，提高了联邦学习中模型的效果。"
}