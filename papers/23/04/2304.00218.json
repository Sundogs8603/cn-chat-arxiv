{
    "title": "Mask Hierarchical Features For Self-Supervised Learning. (arXiv:2304.00218v1 [cs.CV])",
    "abstract": "This paper shows that Masking the Deep hierarchical features is an efficient self-supervised method, denoted as MaskDeep. MaskDeep treats each patch in the representation space as an independent instance. We mask part of patches in the representation space and then utilize sparse visible patches to reconstruct high semantic image representation. The intuition of MaskDeep lies in the fact that models can reason from sparse visible patches semantic to the global semantic of the image. We further propose three designs in our framework: 1) a Hierarchical Deep-Masking module to concern the hierarchical property of patch representations, 2) a multi-group strategy to improve the efficiency without any extra computing consumption of the encoder and 3) a multi-target strategy to provide more description of the global semantic. Our MaskDeep brings decent improvements. Trained on ResNet50 with 200 epochs, MaskDeep achieves state-of-the-art results of 71.2% Top1 accuracy linear classification on I",
    "link": "http://arxiv.org/abs/2304.00218",
    "context": "Title: Mask Hierarchical Features For Self-Supervised Learning. (arXiv:2304.00218v1 [cs.CV])\nAbstract: This paper shows that Masking the Deep hierarchical features is an efficient self-supervised method, denoted as MaskDeep. MaskDeep treats each patch in the representation space as an independent instance. We mask part of patches in the representation space and then utilize sparse visible patches to reconstruct high semantic image representation. The intuition of MaskDeep lies in the fact that models can reason from sparse visible patches semantic to the global semantic of the image. We further propose three designs in our framework: 1) a Hierarchical Deep-Masking module to concern the hierarchical property of patch representations, 2) a multi-group strategy to improve the efficiency without any extra computing consumption of the encoder and 3) a multi-target strategy to provide more description of the global semantic. Our MaskDeep brings decent improvements. Trained on ResNet50 with 200 epochs, MaskDeep achieves state-of-the-art results of 71.2% Top1 accuracy linear classification on I",
    "path": "papers/23/04/2304.00218.json",
    "total_tokens": 898,
    "translated_title": "遮蔽分层特征的自监督学习",
    "translated_abstract": "本文展示了遮蔽深层分层特征的有效自监督方法，称为MaskDeep。 MaskDeep将表示空间中的每个补丁视为独立的实例。我们在表示空间中遮蔽部分补丁，然后利用稀疏可见补丁重建高语义图像表示。 MaskDeep的直觉在于，模型可以通过从稀疏可见补丁语义到图像的全局语义推理。我们在框架中进一步提出了三个设计：1）层次深层遮蔽模块，以关注补丁表示的分层特性，2）多组策略，以提高编码器的效率而不需要任何额外的计算消耗，3）多目标策略，以提供更多全局语义的描述。我们的MaskDeep带来了不错的改进。在ResNet50上进行200个epoch的训练，MaskDeep在I上实现了71.2％的Top1准确率线性分类，达到了最新的结果。",
    "tldr": "本文提出了MaskDeep这一自监督方法，利用遮蔽分层特征的策略，从稀疏的可见补丁来推理图像的全局语义。本方法相比其它自监督方法取得了不错的改进。"
}