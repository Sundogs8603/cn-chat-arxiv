{
    "title": "A Diffusion-based Method for Multi-turn Compositional Image Generation. (arXiv:2304.02192v1 [cs.CV])",
    "abstract": "Multi-turn compositional image generation (M-CIG) is a challenging task that aims to iteratively manipulate a reference image given a modification text. While most of the existing methods for M-CIG are based on generative adversarial networks (GANs), recent advances in image generation have demonstrated the superiority of diffusion models over GANs. In this paper, we propose a diffusion-based method for M-CIG named conditional denoising diffusion with image compositional matching (CDD-ICM). We leverage CLIP as the backbone of image and text encoders, and incorporate a gated fusion mechanism, originally proposed for question answering, to compositionally fuse the reference image and the modification text at each turn of M-CIG. We introduce a conditioning scheme to generate the target image based on the fusion results. To prioritize the semantic quality of the generated target image, we learn an auxiliary image compositional match (ICM) objective, along with the conditional denoising dif",
    "link": "http://arxiv.org/abs/2304.02192",
    "context": "Title: A Diffusion-based Method for Multi-turn Compositional Image Generation. (arXiv:2304.02192v1 [cs.CV])\nAbstract: Multi-turn compositional image generation (M-CIG) is a challenging task that aims to iteratively manipulate a reference image given a modification text. While most of the existing methods for M-CIG are based on generative adversarial networks (GANs), recent advances in image generation have demonstrated the superiority of diffusion models over GANs. In this paper, we propose a diffusion-based method for M-CIG named conditional denoising diffusion with image compositional matching (CDD-ICM). We leverage CLIP as the backbone of image and text encoders, and incorporate a gated fusion mechanism, originally proposed for question answering, to compositionally fuse the reference image and the modification text at each turn of M-CIG. We introduce a conditioning scheme to generate the target image based on the fusion results. To prioritize the semantic quality of the generated target image, we learn an auxiliary image compositional match (ICM) objective, along with the conditional denoising dif",
    "path": "papers/23/04/2304.02192.json",
    "total_tokens": 862,
    "tldr": "该论文提出了一种基于扩散模型的条件去噪扩散（CDD）方法，在多次迭代的基础上出现了一个新的参考图像，以满足文本修改的需求。这种方法使用CLIP作为骨干节点进行图像和文本编码，并使用门控融合机制对参考图像和修改文本进行组合。同时，它还提出了一个条件调节方案，以生成目标图像并优化语义质量。",
    "en_tdlr": "This paper proposes a diffusion-based method named \"conditional denoising diffusion with image compositional matching\" (CDD-ICM) for multi-turn compositional image generation (M-CIG) by leveraging CLIP as the backbone of image and text encoders, incorporating a gated fusion mechanism to compositionally fuse the reference image and modification text, and introducing a conditioning scheme to generate the target image based on the fusion results. Alongside, an auxiliary image compositional match (ICM) objective is learned to prioritize the semantic quality of generated target images."
}