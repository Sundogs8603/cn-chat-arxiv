{
    "title": "SATIN: A Multi-Task Metadataset for Classifying Satellite Imagery using Vision-Language Models. (arXiv:2304.11619v1 [cs.CV])",
    "abstract": "Interpreting remote sensing imagery enables numerous downstream applications ranging from land-use planning to deforestation monitoring. Robustly classifying this data is challenging due to the Earth's geographic diversity. While many distinct satellite and aerial image classification datasets exist, there is yet to be a benchmark curated that suitably covers this diversity. In this work, we introduce SATellite ImageNet (SATIN), a metadataset curated from 27 existing remotely sensed datasets, and comprehensively evaluate the zero-shot transfer classification capabilities of a broad range of vision-language (VL) models on SATIN. We find SATIN to be a challenging benchmark-the strongest method we evaluate achieves a classification accuracy of 52.0%. We provide a $\\href{https://satinbenchmark.github.io}{\\text{public leaderboard}}$ to guide and track the progress of VL models in this important domain.",
    "link": "http://arxiv.org/abs/2304.11619",
    "context": "Title: SATIN: A Multi-Task Metadataset for Classifying Satellite Imagery using Vision-Language Models. (arXiv:2304.11619v1 [cs.CV])\nAbstract: Interpreting remote sensing imagery enables numerous downstream applications ranging from land-use planning to deforestation monitoring. Robustly classifying this data is challenging due to the Earth's geographic diversity. While many distinct satellite and aerial image classification datasets exist, there is yet to be a benchmark curated that suitably covers this diversity. In this work, we introduce SATellite ImageNet (SATIN), a metadataset curated from 27 existing remotely sensed datasets, and comprehensively evaluate the zero-shot transfer classification capabilities of a broad range of vision-language (VL) models on SATIN. We find SATIN to be a challenging benchmark-the strongest method we evaluate achieves a classification accuracy of 52.0%. We provide a $\\href{https://satinbenchmark.github.io}{\\text{public leaderboard}}$ to guide and track the progress of VL models in this important domain.",
    "path": "papers/23/04/2304.11619.json",
    "total_tokens": 968,
    "translated_title": "SATIN：一个使用视觉-语言模型对卫星图像进行分类的多任务元数据集。",
    "translated_abstract": "解释遥感图像可以实现许多下游应用，从土地利用规划到森林砍伐监测都有可能。由于地球地理多样性的存在，对这些数据进行稳健分类是具有挑战性的。虽然存在许多不同的卫星和航空图像分类数据集，但尚未有一个适合涵盖这种多样性的基准。在这项工作中，我们介绍了来自27个现有遥感数据集的元数据集SATellite ImageNet（SATIN），并全面评估了一系列视觉-语言（VL）模型在SATIN上的零-shot转移分类能力。我们发现SATIN是一个具有挑战性的基准测试-我们评估的最强方法的分类精度为52.0％。我们提供了一个公共排行榜，以指导和跟踪VL模型在这一重要领域的进展。",
    "tldr": "本研究介绍了一个遥感图像元数据集SATIN，它由27个现有的遥感数据集组成，并使用一系列视觉-语言（VL）模型全面评估了它的零-shot转移分类能力。该研究发现SATIN是一个具有挑战性的基准测试，强大方法的分类精度为52.0％，并提供了一个公共排行榜以跟踪模型的进展。",
    "en_tdlr": "This study introduces a satellite image metadataset, SATIN, which is comprised of 27 existing remote sensing datasets, and comprehensively evaluates the zero-shot transfer classification capabilities of a broad range of vision-language (VL) models on SATIN. The research finds SATIN to be a challenging benchmark with the strongest method achieving a classification accuracy of 52.0%, and provides a public leaderboard to track the progress of models in this important domain."
}