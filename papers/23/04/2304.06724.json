{
    "title": "GradMDM: Adversarial Attack on Dynamic Networks. (arXiv:2304.06724v1 [cs.CR])",
    "abstract": "Dynamic neural networks can greatly reduce computation redundancy without compromising accuracy by adapting their structures based on the input. In this paper, we explore the robustness of dynamic neural networks against energy-oriented attacks targeted at reducing their efficiency. Specifically, we attack dynamic models with our novel algorithm GradMDM. GradMDM is a technique that adjusts the direction and the magnitude of the gradients to effectively find a small perturbation for each input, that will activate more computational units of dynamic models during inference. We evaluate GradMDM on multiple datasets and dynamic models, where it outperforms previous energy-oriented attack techniques, significantly increasing computation complexity while reducing the perceptibility of the perturbations.",
    "link": "http://arxiv.org/abs/2304.06724",
    "context": "Title: GradMDM: Adversarial Attack on Dynamic Networks. (arXiv:2304.06724v1 [cs.CR])\nAbstract: Dynamic neural networks can greatly reduce computation redundancy without compromising accuracy by adapting their structures based on the input. In this paper, we explore the robustness of dynamic neural networks against energy-oriented attacks targeted at reducing their efficiency. Specifically, we attack dynamic models with our novel algorithm GradMDM. GradMDM is a technique that adjusts the direction and the magnitude of the gradients to effectively find a small perturbation for each input, that will activate more computational units of dynamic models during inference. We evaluate GradMDM on multiple datasets and dynamic models, where it outperforms previous energy-oriented attack techniques, significantly increasing computation complexity while reducing the perceptibility of the perturbations.",
    "path": "papers/23/04/2304.06724.json",
    "total_tokens": 751,
    "translated_title": "GradMDM：动态网络的对抗攻击",
    "translated_abstract": "动态神经网络可以通过根据输入调整其结构来极大地减少计算冗余，而不会影响精度。 在本文中，我们探讨了针对旨在降低其效率的能量导向攻击的动态神经网络的鲁棒性。 具体而言，我们使用我们的新算法GradMDM攻击动态模型。 GradMDM是一种技术，它调整梯度的方向和大小，有效地为每个输入找到一个小扰动，在推理过程中激活动态模型的更多计算单元。 我们评估了GradMDM在多个数据集和动态模型上的表现，它优于先前的能量导向攻击技术，显着增加了计算复杂性，同时减少了扰动的感知度。",
    "tldr": "本文研究了针对动态神经网络的一种新型能量导向攻击算法GradMDM，其可以有效地增加计算复杂度同时减少扰动的感知度。",
    "en_tdlr": "This paper explores the robustness of dynamic neural networks against energy-oriented attacks with the novel algorithm GradMDM, which efficiently increases the computational complexity while reducing the perceptibility of the perturbations."
}