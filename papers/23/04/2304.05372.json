{
    "title": "Can ChatGPT and Bard Generate Aligned Assessment Items? A Reliability Analysis against Human Performance. (arXiv:2304.05372v1 [cs.CL])",
    "abstract": "ChatGPT and Bard are AI chatbots based on Large Language Models (LLM) that are slated to promise different applications in diverse areas. In education, these AI technologies have been tested for applications in assessment and teaching. In assessment, AI has long been used in automated essay scoring and automated item generation. One psychometric property that these tools must have to assist or replace humans in assessment is high reliability in terms of agreement between AI scores and human raters. In this paper, we measure the reliability of OpenAI ChatGP and Google Bard LLMs tools against experienced and trained humans in perceiving and rating the complexity of writing prompts. Intraclass correlation (ICC) as a performance metric showed that the inter-reliability of both the OpenAI ChatGPT and the Google Bard were low against the gold standard of human ratings.",
    "link": "http://arxiv.org/abs/2304.05372",
    "context": "Title: Can ChatGPT and Bard Generate Aligned Assessment Items? A Reliability Analysis against Human Performance. (arXiv:2304.05372v1 [cs.CL])\nAbstract: ChatGPT and Bard are AI chatbots based on Large Language Models (LLM) that are slated to promise different applications in diverse areas. In education, these AI technologies have been tested for applications in assessment and teaching. In assessment, AI has long been used in automated essay scoring and automated item generation. One psychometric property that these tools must have to assist or replace humans in assessment is high reliability in terms of agreement between AI scores and human raters. In this paper, we measure the reliability of OpenAI ChatGP and Google Bard LLMs tools against experienced and trained humans in perceiving and rating the complexity of writing prompts. Intraclass correlation (ICC) as a performance metric showed that the inter-reliability of both the OpenAI ChatGPT and the Google Bard were low against the gold standard of human ratings.",
    "path": "papers/23/04/2304.05372.json",
    "total_tokens": 850,
    "translated_title": "ChatGPT和Bard能够生成一致的评估项目吗？针对人类表现的可靠性分析。",
    "translated_abstract": "ChatGPT和Bard是基于大语言模型的AI聊天机器人，被认为能够在各种领域中应用。在教育领域，这些AI技术已被用于评估和教学。在评估中，AI长期以来一直用于自动化的论文评分和自动化的项目生成。这些工具必须具备的一项心理测量属性是可靠性高，即AI分数与人类评分者意见一致。本文测量了OpenAI ChatGP和Google Bard的可靠性，以评估这些工具在感知和评估写作提示的复杂性方面与经验丰富的人类评分者的一致性。作为绩效指标的内部相关系数（ICC）显示，OpenAI ChatGPT和Google Bard的互可靠性低于人类评分的金标准。",
    "tldr": "本文通过测量OpenAI ChatGPT和Google Bard等AI聊天机器人的可靠性发现，其在感知和评估写作提示的复杂性方面与经验丰富的人类评分者的一致性较低。",
    "en_tdlr": "This paper measures the reliability of AI chatbots such as OpenAI ChatGPT and Google Bard against experienced human raters in perceiving and rating the complexity of writing prompts, and finds that their inter-reliability is low against the gold standard of human ratings."
}