{
    "title": "Bi-Level Attention Graph Neural Networks. (arXiv:2304.11533v1 [cs.LG])",
    "abstract": "Recent graph neural networks (GNNs) with the attention mechanism have historically been limited to small-scale homogeneous graphs (HoGs). However, GNNs handling heterogeneous graphs (HeGs), which contain several entity and relation types, all have shortcomings in handling attention. Most GNNs that learn graph attention for HeGs learn either node-level or relation-level attention, but not both, limiting their ability to predict both important entities and relations in the HeG. Even the best existing method that learns both levels of attention has the limitation of assuming graph relations are independent and that its learned attention disregards this dependency association. To effectively model both multi-relational and multi-entity large-scale HeGs, we present Bi-Level Attention Graph Neural Networks (BA-GNN), scalable neural networks (NNs) that use a novel bi-level graph attention mechanism. BA-GNN models both node-node and relation-relation interactions in a personalized way, by hier",
    "link": "http://arxiv.org/abs/2304.11533",
    "context": "Title: Bi-Level Attention Graph Neural Networks. (arXiv:2304.11533v1 [cs.LG])\nAbstract: Recent graph neural networks (GNNs) with the attention mechanism have historically been limited to small-scale homogeneous graphs (HoGs). However, GNNs handling heterogeneous graphs (HeGs), which contain several entity and relation types, all have shortcomings in handling attention. Most GNNs that learn graph attention for HeGs learn either node-level or relation-level attention, but not both, limiting their ability to predict both important entities and relations in the HeG. Even the best existing method that learns both levels of attention has the limitation of assuming graph relations are independent and that its learned attention disregards this dependency association. To effectively model both multi-relational and multi-entity large-scale HeGs, we present Bi-Level Attention Graph Neural Networks (BA-GNN), scalable neural networks (NNs) that use a novel bi-level graph attention mechanism. BA-GNN models both node-node and relation-relation interactions in a personalized way, by hier",
    "path": "papers/23/04/2304.11533.json",
    "total_tokens": 934,
    "translated_title": "双层注意力图神经网络",
    "translated_abstract": "最近，具有注意力机制的图神经网络(GNNs)在历史上一直局限于小规模同质图(HoGs)。然而，处理异构图(HeGs)的GNNs，在处理注意力方面存在缺陷。大多数处理HeGs的GNNs只学习节点级别或关系级别的注意力，而不是两者兼备，限制了它们在预测HeGs中的重要实体和关系方面的能力。即使是现有学习两种级别注意力的最佳方法，也存在假定图关系是独立的，并且其学习的注意力忽略了这种依赖关联的限制。为了有效地模拟多关系和多实体的大规模HeGs，我们提出了双层注意力图神经网络(BA-GNN)，这是一种可扩展的神经网络(NNs)，通过基于两个重要性级别的层次图关注机制，以个性化的方式模拟了节点-节点和关系-关系的相互作用，并学会了考虑图关系之间的依赖关联。",
    "tldr": "提出了一种双层注意力图神经网络，用于处理多关系和多实体的大规模异构图。通过基于两个重要性级别的层次图关注机制，以个性化的方式模拟节点-节点和关系-关系的相互作用。",
    "en_tdlr": "Presented is a Bi-Level Attention Graph Neural Network (BA-GNN), which effectively models large-scale heterogeneous graphs with multiple entity and relation types. By utilizing a novel bi-level graph attention mechanism, the BA-GNN learns personalized interactions between nodes and relations at different levels of importance, while considering the dependency association between graph relations."
}