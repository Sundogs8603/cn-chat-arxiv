{
    "title": "SHIELD: Thwarting Code Authorship Attribution. (arXiv:2304.13255v1 [cs.CR])",
    "abstract": "Authorship attribution has become increasingly accurate, posing a serious privacy risk for programmers who wish to remain anonymous. In this paper, we introduce SHIELD to examine the robustness of different code authorship attribution approaches against adversarial code examples. We define four attacks on attribution techniques, which include targeted and non-targeted attacks, and realize them using adversarial code perturbation. We experiment with a dataset of 200 programmers from the Google Code Jam competition to validate our methods targeting six state-of-the-art authorship attribution methods that adopt a variety of techniques for extracting authorship traits from source-code, including RNN, CNN, and code stylometry. Our experiments demonstrate the vulnerability of current authorship attribution methods against adversarial attacks. For the non-targeted attack, our experiments demonstrate the vulnerability of current authorship attribution methods against the attack with an attack ",
    "link": "http://arxiv.org/abs/2304.13255",
    "context": "Title: SHIELD: Thwarting Code Authorship Attribution. (arXiv:2304.13255v1 [cs.CR])\nAbstract: Authorship attribution has become increasingly accurate, posing a serious privacy risk for programmers who wish to remain anonymous. In this paper, we introduce SHIELD to examine the robustness of different code authorship attribution approaches against adversarial code examples. We define four attacks on attribution techniques, which include targeted and non-targeted attacks, and realize them using adversarial code perturbation. We experiment with a dataset of 200 programmers from the Google Code Jam competition to validate our methods targeting six state-of-the-art authorship attribution methods that adopt a variety of techniques for extracting authorship traits from source-code, including RNN, CNN, and code stylometry. Our experiments demonstrate the vulnerability of current authorship attribution methods against adversarial attacks. For the non-targeted attack, our experiments demonstrate the vulnerability of current authorship attribution methods against the attack with an attack ",
    "path": "papers/23/04/2304.13255.json",
    "total_tokens": 833,
    "translated_title": "SHIELD：防御代码作者归属。",
    "translated_abstract": "作者归属的准确性不断提高，这对于希望保持匿名的程序员构成了严重的隐私风险。本文介绍了 SHIELD，用于检查不同的代码作者归属方法对抗性代码示例的鲁棒性。我们定义了四种攻击归属技术的方法，包括有针对性和非有针对性的攻击，并使用对抗性代码扰动来实现它们。我们使用来自 Google Code Jam 竞赛的 200 个程序员的数据集来验证我们的方法，针对采用各种技术从源代码中提取作者属性的六种最新作者归属方法进行攻击，包括 RNN、CNN 和代码样式学。我们的实验证明了当前作者归属方法对于对抗性攻击的漏洞。对于非有针对性攻击，我们的实验表明当前作者归属方法在攻击下的脆弱性。",
    "tldr": "本研究设计了 SHIELD 来检查代码作者归属方法对抗性代码示例的鲁棒性。实验结果表明当前的作者归属方法对于对抗性攻击和扰动具有脆弱性。",
    "en_tdlr": "The paper introduces the SHIELD method to examine code authorship attribution approaches against adversarial code examples, and experimentally demonstrates the vulnerability of current methods to such attacks."
}