{
    "title": "Typical and atypical solutions in non-convex neural networks with discrete and continuous weights. (arXiv:2304.13871v1 [cond-mat.dis-nn])",
    "abstract": "We study the binary and continuous negative-margin perceptrons as simple non-convex neural network models learning random rules and associations. We analyze the geometry of the landscape of solutions in both models and find important similarities and differences. Both models exhibit subdominant minimizers which are extremely flat and wide. These minimizers coexist with a background of dominant solutions which are composed by an exponential number of algorithmically inaccessible small clusters for the binary case (the frozen 1-RSB phase) or a hierarchical structure of clusters of different sizes for the spherical case (the full RSB phase). In both cases, when a certain threshold in constraint density is crossed, the local entropy of the wide flat minima becomes non-monotonic, indicating a break-up of the space of robust solutions into disconnected components. This has a strong impact on the behavior of algorithms in binary models, which cannot access the remaining isolated clusters. For",
    "link": "http://arxiv.org/abs/2304.13871",
    "context": "Title: Typical and atypical solutions in non-convex neural networks with discrete and continuous weights. (arXiv:2304.13871v1 [cond-mat.dis-nn])\nAbstract: We study the binary and continuous negative-margin perceptrons as simple non-convex neural network models learning random rules and associations. We analyze the geometry of the landscape of solutions in both models and find important similarities and differences. Both models exhibit subdominant minimizers which are extremely flat and wide. These minimizers coexist with a background of dominant solutions which are composed by an exponential number of algorithmically inaccessible small clusters for the binary case (the frozen 1-RSB phase) or a hierarchical structure of clusters of different sizes for the spherical case (the full RSB phase). In both cases, when a certain threshold in constraint density is crossed, the local entropy of the wide flat minima becomes non-monotonic, indicating a break-up of the space of robust solutions into disconnected components. This has a strong impact on the behavior of algorithms in binary models, which cannot access the remaining isolated clusters. For",
    "path": "papers/23/04/2304.13871.json",
    "total_tokens": 934,
    "translated_title": "连续和离散权重下非凸神经网络中的典型与非典型解析解",
    "translated_abstract": "本论文研究了二元和连续的负边距感知器作为简单的非凸神经网络模型在学习随机规则和关联时的情况。我们分析了两种模型的解空间几何形态，并找到了重要的相似性和差异性。这两种模型都表现出极为平坦和宽广的亚优解。这些亚优解与二元情况下无法递归算法访问的大量蔓延小集群（冻结1-RSB相）组成的主要解集共存，或者球面情况下不同大小聚类的分层结构（完全RSB相）。在两种情况下，当交叉一定密度约束的阈值时，宽广平坦极小值的局部熵变得非单调，表明鲁棒解的空间被分成了不连通的组件。这对二元模型中算法的行为产生了很强的影响，因为它无法访问剩余的孤立集群。",
    "tldr": "本文研究了二元和连续的负边距感知器作为非凸神经网络模型，发现它们都存在着极为平坦和宽广的亚优解，这对于二元情况中的算法行为有着很强的影响。"
}