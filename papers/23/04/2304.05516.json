{
    "title": "Echo of Neighbors: Privacy Amplification for Personalized Private Federated Learning with Shuffle Model. (arXiv:2304.05516v1 [cs.CR])",
    "abstract": "Federated Learning, as a popular paradigm for collaborative training, is vulnerable against privacy attacks. Different privacy levels regarding users' attitudes need to be satisfied locally, while a strict privacy guarantee for the global model is also required centrally. Personalized Local Differential Privacy (PLDP) is suitable for preserving users' varying local privacy, yet only provides a central privacy guarantee equivalent to the worst-case local privacy level. Thus, achieving strong central privacy as well as personalized local privacy with a utility-promising model is a challenging problem. In this work, a general framework (APES) is built up to strengthen model privacy under personalized local privacy by leveraging the privacy amplification effect of the shuffle model. To tighten the privacy bound, we quantify the heterogeneous contributions to the central privacy user by user. The contributions are characterized by the ability of generating \"echos\" from the perturbation of e",
    "link": "http://arxiv.org/abs/2304.05516",
    "context": "Title: Echo of Neighbors: Privacy Amplification for Personalized Private Federated Learning with Shuffle Model. (arXiv:2304.05516v1 [cs.CR])\nAbstract: Federated Learning, as a popular paradigm for collaborative training, is vulnerable against privacy attacks. Different privacy levels regarding users' attitudes need to be satisfied locally, while a strict privacy guarantee for the global model is also required centrally. Personalized Local Differential Privacy (PLDP) is suitable for preserving users' varying local privacy, yet only provides a central privacy guarantee equivalent to the worst-case local privacy level. Thus, achieving strong central privacy as well as personalized local privacy with a utility-promising model is a challenging problem. In this work, a general framework (APES) is built up to strengthen model privacy under personalized local privacy by leveraging the privacy amplification effect of the shuffle model. To tighten the privacy bound, we quantify the heterogeneous contributions to the central privacy user by user. The contributions are characterized by the ability of generating \"echos\" from the perturbation of e",
    "path": "papers/23/04/2304.05516.json",
    "total_tokens": 822,
    "translated_title": "邻居的回响：基于Shuffle模型的个性化隐私保护联邦学习中的隐私扩增",
    "translated_abstract": "联邦学习是一种流行的协同训练范例，但会受到隐私攻击。为了满足用户对于不同隐私需求的本地需求，需要保留个性化的本地差分隐私，同时还需要为全局模型提供严格的隐私保证。本文提出了一个通用框架（APES）来加强个性化本地隐私保护条件下的模型隐私，利用Shuffle模型的隐私扩增效果。为了增强隐私保证，我们量化每个用户对中心隐私的异构贡献，并通过扰动“回声”来描述用户的特征。在各种数据集上的实验表明了我们的框架的有效性。",
    "tldr": "本文提出了一个个性化隐私保护联邦学习框架，可在保证本地隐私的同时实现强中心隐私保证，并利用Shuffle模型进行隐私扩增。",
    "en_tdlr": "This paper proposes a personalized privacy-preserving federated learning framework that achieves strong central privacy guarantee while ensuring local privacy, and uses the Shuffle model for privacy amplification."
}