{
    "title": "HQP: A Human-Annotated Dataset for Detecting Online Propaganda. (arXiv:2304.14931v1 [cs.CL])",
    "abstract": "Online propaganda poses a severe threat to the integrity of societies. However, existing datasets for detecting online propaganda have a key limitation: they were annotated using weak labels that can be noisy and even incorrect. To address this limitation, our work makes the following contributions: (1) We present \\dataset: a novel dataset (N=30,000) for detecting online propaganda with high-quality labels. To the best of our knowledge, \\dataset is the first dataset for detecting online propaganda that was created through human annotation. (2) We show empirically that state-of-the-art language models fail in detecting online propaganda when trained with weak labels (AUC: 64.03). In contrast, state-of-the-art language models can accurately detect online propaganda when trained with our high-quality labels (AUC: 92.25), which is an improvement of ~44%. (3) To address the cost of labeling, we extend our work to few-shot learning. Specifically, we show that prompt-based learning using a sm",
    "link": "http://arxiv.org/abs/2304.14931",
    "context": "Title: HQP: A Human-Annotated Dataset for Detecting Online Propaganda. (arXiv:2304.14931v1 [cs.CL])\nAbstract: Online propaganda poses a severe threat to the integrity of societies. However, existing datasets for detecting online propaganda have a key limitation: they were annotated using weak labels that can be noisy and even incorrect. To address this limitation, our work makes the following contributions: (1) We present \\dataset: a novel dataset (N=30,000) for detecting online propaganda with high-quality labels. To the best of our knowledge, \\dataset is the first dataset for detecting online propaganda that was created through human annotation. (2) We show empirically that state-of-the-art language models fail in detecting online propaganda when trained with weak labels (AUC: 64.03). In contrast, state-of-the-art language models can accurately detect online propaganda when trained with our high-quality labels (AUC: 92.25), which is an improvement of ~44%. (3) To address the cost of labeling, we extend our work to few-shot learning. Specifically, we show that prompt-based learning using a sm",
    "path": "papers/23/04/2304.14931.json",
    "total_tokens": 904,
    "translated_title": "HQP：一份人工标注的用于检测网络宣传的数据集",
    "translated_abstract": "网络宣传对社会的完整性构成了严重威胁。然而，现有的检测网络宣传的数据集存在一个关键限制：它们是使用弱标签进行注释的，可能存在噪音甚至错误。为了解决这一限制，本研究做出了以下贡献：（1）我们提出了一个新的数据集HQP（N=30,000），用于检测网络宣传，具有高质量的标注。据我们所知，这是第一个通过人工注释而创建的用于检测网络宣传的数据集。（2）我们证明了，在使用弱标签进行训练时，最先进的语言模型在检测网络宣传方面失败（AUC：64.03）。相比之下，当使用我们的高质量标签进行训练时，最先进的语言模型可以准确地检测网络宣传（AUC：92.25），提高了约44%。（3）为了解决标注成本问题，我们将我们的工作扩展到了少样本学习。具体来说，我们展示了使用一个小型数据集进行提示式学习的方法。",
    "tldr": "HQP是一个人工标注的网络宣传检测数据集，与现有的弱标签数据集相比，使用HQP进行训练可以提高44%的准确率。"
}