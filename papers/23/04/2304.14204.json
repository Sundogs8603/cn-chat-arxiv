{
    "title": "Towards Medical Artificial General Intelligence via Knowledge-Enhanced Multimodal Pretraining. (arXiv:2304.14204v1 [cs.AI])",
    "abstract": "Medical artificial general intelligence (MAGI) enables one foundation model to solve different medical tasks, which is very practical in the medical domain. It can significantly reduce the requirement of large amounts of task-specific data by sufficiently sharing medical knowledge among different tasks. However, due to the challenges of designing strongly generalizable models with limited and complex medical data, most existing approaches tend to develop task-specific models. To take a step towards MAGI, we propose a new paradigm called Medical-knOwledge-enhanced mulTimOdal pretRaining (MOTOR). In MOTOR, we combine two kinds of basic medical knowledge, i.e., general and specific knowledge, in a complementary manner to boost the general pretraining process. As a result, the foundation model with comprehensive basic knowledge can learn compact representations from pretraining radiographic data for better cross-modal alignment. MOTOR unifies the understanding and generation, which are two",
    "link": "http://arxiv.org/abs/2304.14204",
    "context": "Title: Towards Medical Artificial General Intelligence via Knowledge-Enhanced Multimodal Pretraining. (arXiv:2304.14204v1 [cs.AI])\nAbstract: Medical artificial general intelligence (MAGI) enables one foundation model to solve different medical tasks, which is very practical in the medical domain. It can significantly reduce the requirement of large amounts of task-specific data by sufficiently sharing medical knowledge among different tasks. However, due to the challenges of designing strongly generalizable models with limited and complex medical data, most existing approaches tend to develop task-specific models. To take a step towards MAGI, we propose a new paradigm called Medical-knOwledge-enhanced mulTimOdal pretRaining (MOTOR). In MOTOR, we combine two kinds of basic medical knowledge, i.e., general and specific knowledge, in a complementary manner to boost the general pretraining process. As a result, the foundation model with comprehensive basic knowledge can learn compact representations from pretraining radiographic data for better cross-modal alignment. MOTOR unifies the understanding and generation, which are two",
    "path": "papers/23/04/2304.14204.json",
    "total_tokens": 895,
    "translated_title": "基于知识增强的多模态预训练方法实现医疗人工通用智能",
    "translated_abstract": "医疗人工通用智能（MAGI）可以利用共享的医疗知识来解决不同的医疗任务，减少大量特定任务的数据需求。然而，由于医疗数据有限且复杂，设计具有强泛化能力的模型十分具有挑战性，因此大多数现有方法都是针对特定任务的模型设计。本文提出了一种名为Medical-knOwledge-enhanced mulTimOdal pretRaining (MOTOR)的新范例，以实现MAGI。在MOTOR中，我们将两种基本医疗知识——通用和特定知识融合，共同促进模型的预训练过程，使其从放射学数据中学习紧凑的表征，以实现更好的交叉模态对齐。MOTOR统一了理解和生成，是实现医疗人工通用智能的一步。",
    "tldr": "本文提出了一种基于医疗知识的多模态预训练方法，名为MOTOR，旨在实现医疗人工通用智能，将通用和特定知识融合，共同促进模型的预训练过程。",
    "en_tdlr": "This paper proposes a knowledge-enhanced multimodal pretraining method, called MOTOR, aiming to achieve medical artificial general intelligence (MAGI) by integrating general and specific medical knowledge. The proposed approach can significantly reduce the requirement of task-specific data and improve cross-modal alignment."
}