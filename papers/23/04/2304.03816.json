{
    "title": "Towards Generating Functionally Correct Code Edits from Natural Language Issue Descriptions. (arXiv:2304.03816v1 [cs.SE])",
    "abstract": "Large language models (LLMs), such as OpenAI's Codex, have demonstrated their potential to generate code from natural language descriptions across a wide range of programming tasks. Several benchmarks have recently emerged to evaluate the ability of LLMs to generate functionally correct code from natural language intent with respect to a set of hidden test cases. This has enabled the research community to identify significant and reproducible advancements in LLM capabilities. However, there is currently a lack of benchmark datasets for assessing the ability of LLMs to generate functionally correct code edits based on natural language descriptions of intended changes. This paper aims to address this gap by motivating the problem NL2Fix of translating natural language descriptions of code changes (namely bug fixes described in Issue reports in repositories) into correct code fixes. To this end, we introduce Defects4J-NL2Fix, a dataset of 283 Java programs from the popular Defects4J datas",
    "link": "http://arxiv.org/abs/2304.03816",
    "context": "Title: Towards Generating Functionally Correct Code Edits from Natural Language Issue Descriptions. (arXiv:2304.03816v1 [cs.SE])\nAbstract: Large language models (LLMs), such as OpenAI's Codex, have demonstrated their potential to generate code from natural language descriptions across a wide range of programming tasks. Several benchmarks have recently emerged to evaluate the ability of LLMs to generate functionally correct code from natural language intent with respect to a set of hidden test cases. This has enabled the research community to identify significant and reproducible advancements in LLM capabilities. However, there is currently a lack of benchmark datasets for assessing the ability of LLMs to generate functionally correct code edits based on natural language descriptions of intended changes. This paper aims to address this gap by motivating the problem NL2Fix of translating natural language descriptions of code changes (namely bug fixes described in Issue reports in repositories) into correct code fixes. To this end, we introduce Defects4J-NL2Fix, a dataset of 283 Java programs from the popular Defects4J datas",
    "path": "papers/23/04/2304.03816.json",
    "total_tokens": 891,
    "translated_title": "从自然语言错误描述中生成功能上正确的代码编辑",
    "translated_abstract": "大型语言模型（LLM），如 OpenAI 的 Codex，在各种编程任务中已经展示了通过自然语言描述生成代码的潜力。最近出现了几个基准测试来评估 LLM 生成与一组隐藏测试用例相对应的自然语言意图的功能上正确的代码的能力。这使得研究社区能够确定 LLM 能力的显著和可重复的进展。但是，目前缺乏基准数据集来评估 LLM 根据预期更改的自然语言描述生成功能性正确的代码编辑的能力。本文旨在通过提出问题 NL2Fix，即将代码更改的自然语言描述（即库中问题报告中描述的错误修复）翻译成正确的代码修复来解决这个问题。为此，我们介绍了 Defects4J-NL2Fix，这是一个由 283 个 Java 程序组成的流行 Defects4J 数据集。",
    "tldr": "本文提出了 NL2Fix 问题，即将代码更改的自然语言描述翻译成正确的代码修复。为此，我们介绍了 Defects4J-NL2Fix，这是一个由 283 个 Java 程序组成的流行 Defects4J 数据集。",
    "en_tdlr": "This paper proposes the NL2Fix problem, which aims to translate natural language descriptions of code changes into correct code fixes. The authors introduce Defects4J-NL2Fix, a dataset of 283 Java programs, as a benchmark for evaluating the ability of large language models to generate functionally correct code edits based on natural language descriptions of intended changes."
}