{
    "title": "CancerGPT: Few-shot Drug Pair Synergy Prediction using Large Pre-trained Language Models. (arXiv:2304.10946v1 [cs.CL])",
    "abstract": "Large pre-trained language models (LLMs) have been shown to have significant potential in few-shot learning across various fields, even with minimal training data. However, their ability to generalize to unseen tasks in more complex fields, such as biology, has yet to be fully evaluated. LLMs can offer a promising alternative approach for biological inference, particularly in cases where structured data and sample size are limited, by extracting prior knowledge from text corpora. Our proposed few-shot learning approach uses LLMs to predict the synergy of drug pairs in rare tissues that lack structured data and features. Our experiments, which involved seven rare tissues from different cancer types, demonstrated that the LLM-based prediction model achieved significant accuracy with very few or zero samples. Our proposed model, the CancerGPT (with $\\sim$ 124M parameters), was even comparable to the larger fine-tuned GPT-3 model (with $\\sim$ 175B parameters). Our research is the first to ",
    "link": "http://arxiv.org/abs/2304.10946",
    "context": "Title: CancerGPT: Few-shot Drug Pair Synergy Prediction using Large Pre-trained Language Models. (arXiv:2304.10946v1 [cs.CL])\nAbstract: Large pre-trained language models (LLMs) have been shown to have significant potential in few-shot learning across various fields, even with minimal training data. However, their ability to generalize to unseen tasks in more complex fields, such as biology, has yet to be fully evaluated. LLMs can offer a promising alternative approach for biological inference, particularly in cases where structured data and sample size are limited, by extracting prior knowledge from text corpora. Our proposed few-shot learning approach uses LLMs to predict the synergy of drug pairs in rare tissues that lack structured data and features. Our experiments, which involved seven rare tissues from different cancer types, demonstrated that the LLM-based prediction model achieved significant accuracy with very few or zero samples. Our proposed model, the CancerGPT (with $\\sim$ 124M parameters), was even comparable to the larger fine-tuned GPT-3 model (with $\\sim$ 175B parameters). Our research is the first to ",
    "path": "papers/23/04/2304.10946.json",
    "total_tokens": 1139,
    "translated_title": "CancerGPT: 基于LLMs的极少样本药物对协同作用预测技术",
    "translated_abstract": "大型预训练语言模型（LLMs）在许多领域中具有显着的远程监控潜力，即使只有极少量的训练数据。但是，它们在更复杂的领域，如生物学领域中对未见过的任务的泛化能力尚未得到充分评估。 LLM可以提供一种有前途的替代方法，特别是在结构化数据和样本大小有限的情况下，通过从文本语料库中提取先验知识。 我们提出了一种基于LLMs的少样本学习方法，用于预测缺乏结构化数据和特征的罕见组织中药物对的协同作用。 实验涉及来自不同癌症类型的七种罕见组织，表明基于LLMs的预测模型在非常少或零样本的情况下也能取得显着的准确性。我们提出的模型CancerGPT（具有$\\sim 124M$参数）甚至可以与更大的微调GPT-3模型（具有$\\sim 175B$参数）相媲美。我们的研究是第一个利用LLMs进行少样本学习的案例，为生物学推断提供了一种有前途的替代方法。",
    "tldr": "CancerGPT 是一种基于LLMs的少样本学习技术，可在生物学推断中预测罕见组织中的药物对协同作用。实验表明该技术准确性高，即使在样本数据非常有限的情况下仍可进行预测。",
    "en_tdlr": "CancerGPT is a few-shot learning technique based on LLMs that predicts drug pair synergy in rare tissues for biological inference. The approach achieves high accuracy even with extremely limited sample data."
}