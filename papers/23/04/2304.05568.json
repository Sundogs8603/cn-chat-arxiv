{
    "title": "Improving Diffusion Models for Scene Text Editing with Dual Encoders. (arXiv:2304.05568v1 [cs.CV])",
    "abstract": "Scene text editing is a challenging task that involves modifying or inserting specified texts in an image while maintaining its natural and realistic appearance. Most previous approaches to this task rely on style-transfer models that crop out text regions and feed them into image transfer models, such as GANs. However, these methods are limited in their ability to change text style and are unable to insert texts into images. Recent advances in diffusion models have shown promise in overcoming these limitations with text-conditional image editing. However, our empirical analysis reveals that state-of-the-art diffusion models struggle with rendering correct text and controlling text style. To address these problems, we propose DIFFSTE to improve pre-trained diffusion models with a dual encoder design, which includes a character encoder for better text legibility and an instruction encoder for better style control. An instruction tuning framework is introduced to train our model to learn",
    "link": "http://arxiv.org/abs/2304.05568",
    "context": "Title: Improving Diffusion Models for Scene Text Editing with Dual Encoders. (arXiv:2304.05568v1 [cs.CV])\nAbstract: Scene text editing is a challenging task that involves modifying or inserting specified texts in an image while maintaining its natural and realistic appearance. Most previous approaches to this task rely on style-transfer models that crop out text regions and feed them into image transfer models, such as GANs. However, these methods are limited in their ability to change text style and are unable to insert texts into images. Recent advances in diffusion models have shown promise in overcoming these limitations with text-conditional image editing. However, our empirical analysis reveals that state-of-the-art diffusion models struggle with rendering correct text and controlling text style. To address these problems, we propose DIFFSTE to improve pre-trained diffusion models with a dual encoder design, which includes a character encoder for better text legibility and an instruction encoder for better style control. An instruction tuning framework is introduced to train our model to learn",
    "path": "papers/23/04/2304.05568.json",
    "total_tokens": 918,
    "translated_title": "通过双编码器改进扩散模型实现场景文字编辑",
    "translated_abstract": "场景文字编辑是一项具有挑战性的任务，它涉及在图像中修改或插入指定的文本，同时保持其自然和逼真的外观。大多数先前的方法依靠风格转移模型，将文本区域裁剪出来并将它们馈入图像转移模型（如GAN）。然而，这些方法在改变文本样式和插入文本到图像中能力方面存在局限性。最近扩散模型的进展展示了在文本条件下进行图像编辑的潜力。然而，我们的经验分析表明，最先进的扩散模型在渲染正确的文本和控制文本样式方面存在困难。为了解决这些问题，我们提出了使用双编码器设计来改善预先训练的扩散模型的 DIFFSTE，其中包括用于更好文本清晰度的字符编码器和用于更好样式控制的指令编码器。引入指令调整框架来训练我们的模型学习",
    "tldr": "DIFFSTE是一种用于改进场景文字编辑的方法，通过使用双编码器设计，包括字符编码器以提高文本清晰度和指令编码器以更好地控制样式，有效解决了现有模型在渲染正确文本和控制文本样式方面的困难"
}