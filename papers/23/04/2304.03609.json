{
    "title": "Revisiting Automated Prompting: Are We Actually Doing Better?. (arXiv:2304.03609v1 [cs.CL])",
    "abstract": "Current literature demonstrates that Large Language Models (LLMs) are great few-shot learners, and prompting significantly increases their performance on a range of downstream tasks in a few-shot learning setting. An attempt to automate human-led prompting followed, with some progress achieved. In particular, subsequent work demonstrates automation can outperform fine-tuning in certain K-shot learning scenarios.  In this paper, we revisit techniques for automated prompting on six different downstream tasks and a larger range of K-shot learning settings. We find that automated prompting does not consistently outperform simple manual prompts. Our work suggests that, in addition to fine-tuning, manual prompts should be used as a baseline in this line of research.",
    "link": "http://arxiv.org/abs/2304.03609",
    "context": "Title: Revisiting Automated Prompting: Are We Actually Doing Better?. (arXiv:2304.03609v1 [cs.CL])\nAbstract: Current literature demonstrates that Large Language Models (LLMs) are great few-shot learners, and prompting significantly increases their performance on a range of downstream tasks in a few-shot learning setting. An attempt to automate human-led prompting followed, with some progress achieved. In particular, subsequent work demonstrates automation can outperform fine-tuning in certain K-shot learning scenarios.  In this paper, we revisit techniques for automated prompting on six different downstream tasks and a larger range of K-shot learning settings. We find that automated prompting does not consistently outperform simple manual prompts. Our work suggests that, in addition to fine-tuning, manual prompts should be used as a baseline in this line of research.",
    "path": "papers/23/04/2304.03609.json",
    "total_tokens": 786,
    "translated_title": "重新审视自动提示：我们真的做得更好吗？",
    "translated_abstract": "当前的文献表明，大型语言模型(LLM)是出色的几乎不用学习的学习者，在几乎不用学习的情况下，提示显着提高了它们在多个下游任务中的表现。随后进行了试图自动化人类提示的尝试，并取得了一定进展。特别是，随后的工作表明，在某些K-shot学习场景中，自动化可以优于微调。在本文中，我们重新审视了自动提示在六个不同的下游任务和更大范围的K-shot学习设置上的技术。我们发现，自动提示不能始终优于简单的手动提示。我们的工作表明，在这一研究领域中，除了微调之外，手动提示应作为基线使用。",
    "tldr": "本文重审自动提示技术在六个不同的任务和更广泛范围的K-shot学习设置上的表现，发现自动提示并不能始终优于手动提示，因此手动提示应该作为自动提示的一个基准线。",
    "en_tdlr": "This paper revisits techniques for automated prompting on six downstream tasks and a larger range of K-shot learning settings, and finds that automated prompting does not consistently outperform simple manual prompts, suggesting that manual prompts should be used as a baseline in this line of research, in addition to fine-tuning."
}