{
    "title": "A baseline on continual learning methods for video action recognition. (arXiv:2304.10335v1 [cs.CV])",
    "abstract": "Continual learning has recently attracted attention from the research community, as it aims to solve long-standing limitations of classic supervisedly-trained models. However, most research on this subject has tackled continual learning in simple image classification scenarios. In this paper, we present a benchmark of state-of-the-art continual learning methods on video action recognition. Besides the increased complexity due to the temporal dimension, the video setting imposes stronger requirements on computing resources for top-performing rehearsal methods. To counteract the increased memory requirements, we present two method-agnostic variants for rehearsal methods, exploiting measures of either model confidence or data information to select memorable samples. Our experiments show that, as expected from the literature, rehearsal methods outperform other approaches; moreover, the proposed memory-efficient variants are shown to be effective at retaining a certain level of performance ",
    "link": "http://arxiv.org/abs/2304.10335",
    "context": "Title: A baseline on continual learning methods for video action recognition. (arXiv:2304.10335v1 [cs.CV])\nAbstract: Continual learning has recently attracted attention from the research community, as it aims to solve long-standing limitations of classic supervisedly-trained models. However, most research on this subject has tackled continual learning in simple image classification scenarios. In this paper, we present a benchmark of state-of-the-art continual learning methods on video action recognition. Besides the increased complexity due to the temporal dimension, the video setting imposes stronger requirements on computing resources for top-performing rehearsal methods. To counteract the increased memory requirements, we present two method-agnostic variants for rehearsal methods, exploiting measures of either model confidence or data information to select memorable samples. Our experiments show that, as expected from the literature, rehearsal methods outperform other approaches; moreover, the proposed memory-efficient variants are shown to be effective at retaining a certain level of performance ",
    "path": "papers/23/04/2304.10335.json",
    "total_tokens": 856,
    "translated_title": "视频动作识别中连续学习方法的基线研究",
    "translated_abstract": "近年来，连续学习吸引了研究界的关注，因为它旨在解决经典监督模型的长期限制。然而，大多数关于这个主题的研究都是针对简单的图像分类场景进行的。在本文中，我们提出了关于视频动作识别状态下最先进的连续学习方法的基准研究。除了由于时间维度而增加的复杂性外，在视频环境中，为了实现最佳性能的回顾方法对计算资源要求更高。为了对抗增加的内存要求，我们提出了两种去方法都通用的回顾方法变体，利用模型置信度或数据信息的指标来选择可记忆的样本。我们的实验表明，与文献中预期的一样，回顾方法优于其他方法；此外，所提出的内存效率变体被证明在保持一定水平的性能方面是有效的。",
    "tldr": "本文基于视频动作识别场景，提出最先进的连续学习方法的基准研究，并证明回顾方法优于其他方法。此外，提出的内存效率变体可有效地保持一定水平的性能。",
    "en_tdlr": "This paper presents a benchmark study on state-of-the-art continual learning methods for video action recognition, showing the superiority of rehearsal methods over other approaches. Also, two memory-efficient variants for rehearsal methods are proposed and validated to retain a certain level of performance."
}