{
    "title": "An Evaluation on Large Language Model Outputs: Discourse and Memorization. (arXiv:2304.08637v1 [cs.CL])",
    "abstract": "We present an empirical evaluation of various outputs generated by nine of the most widely-available large language models (LLMs). Our analysis is done with off-the-shelf, readily-available tools. We find a correlation between percentage of memorized text, percentage of unique text, and overall output quality, when measured with respect to output pathologies such as counterfactual and logically-flawed statements, and general failures like not staying on topic. Overall, 80.0% of the outputs evaluated contained memorized data, but outputs containing the most memorized content were also more likely to be considered of high quality. We discuss and evaluate mitigation strategies, showing that, in the models evaluated, the rate of memorized text being output is reduced. We conclude with a discussion on potential implications around what it means to learn, to memorize, and to evaluate quality text.",
    "link": "http://arxiv.org/abs/2304.08637",
    "context": "Title: An Evaluation on Large Language Model Outputs: Discourse and Memorization. (arXiv:2304.08637v1 [cs.CL])\nAbstract: We present an empirical evaluation of various outputs generated by nine of the most widely-available large language models (LLMs). Our analysis is done with off-the-shelf, readily-available tools. We find a correlation between percentage of memorized text, percentage of unique text, and overall output quality, when measured with respect to output pathologies such as counterfactual and logically-flawed statements, and general failures like not staying on topic. Overall, 80.0% of the outputs evaluated contained memorized data, but outputs containing the most memorized content were also more likely to be considered of high quality. We discuss and evaluate mitigation strategies, showing that, in the models evaluated, the rate of memorized text being output is reduced. We conclude with a discussion on potential implications around what it means to learn, to memorize, and to evaluate quality text.",
    "path": "papers/23/04/2304.08637.json",
    "total_tokens": 829,
    "translated_title": "大型语言模型输出的评估：话语和记忆",
    "translated_abstract": "我们对九个最广泛可用的大型语言模型（LLMs）生成的各种输出进行了经验性评估。我们使用现成的工具进行分析，发现在与输出病态（例如，反事实和逻辑上的错误陈述）以及不保持主题等方面的关系中，记忆文本百分比、独特文本百分比和整体输出质量之间存在相关性。总体而言，80.0％的输出包含记忆数据，但包含最多记忆内容的输出也更有可能被认为具有高质量。我们讨论和评估了缓解策略，并显示，在评估的模型中，输出的记忆文本率有所降低。最后，我们就学习、记忆和评估优质文本的潜在影响进行了讨论。",
    "tldr": "评估了九个大语言模型的输出，发现其中80％包含记忆数据，但包含最多记忆内容的输出更可能是高质量的。提出了缓解策略以降低记忆文本率。",
    "en_tdlr": "This paper evaluates outputs generated by nine large language models, finding that 80% of the outputs contained memorized data and those containing the most memorized content were more likely to be of high quality. Mitigation strategies to reduce the rate of memorized text being output are discussed."
}