{
    "title": "Estimating Joint Probability Distribution With Low-Rank Tensor Decomposition, Radon Transforms and Dictionaries. (arXiv:2304.08740v1 [stat.ML])",
    "abstract": "In this paper, we describe a method for estimating the joint probability density from data samples by assuming that the underlying distribution can be decomposed as a mixture of product densities with few mixture components. Prior works have used such a decomposition to estimate the joint density from lower-dimensional marginals, which can be estimated more reliably with the same number of samples. We combine two key ideas: dictionaries to represent 1-D densities, and random projections to estimate the joint distribution from 1-D marginals, explored separately in prior work. Our algorithm benefits from improved sample complexity over the previous dictionary-based approach by using 1-D marginals for reconstruction. We evaluate the performance of our method on estimating synthetic probability densities and compare it with the previous dictionary-based approach and Gaussian Mixture Models (GMMs). Our algorithm outperforms these other approaches in all the experimental settings.",
    "link": "http://arxiv.org/abs/2304.08740",
    "context": "Title: Estimating Joint Probability Distribution With Low-Rank Tensor Decomposition, Radon Transforms and Dictionaries. (arXiv:2304.08740v1 [stat.ML])\nAbstract: In this paper, we describe a method for estimating the joint probability density from data samples by assuming that the underlying distribution can be decomposed as a mixture of product densities with few mixture components. Prior works have used such a decomposition to estimate the joint density from lower-dimensional marginals, which can be estimated more reliably with the same number of samples. We combine two key ideas: dictionaries to represent 1-D densities, and random projections to estimate the joint distribution from 1-D marginals, explored separately in prior work. Our algorithm benefits from improved sample complexity over the previous dictionary-based approach by using 1-D marginals for reconstruction. We evaluate the performance of our method on estimating synthetic probability densities and compare it with the previous dictionary-based approach and Gaussian Mixture Models (GMMs). Our algorithm outperforms these other approaches in all the experimental settings.",
    "path": "papers/23/04/2304.08740.json",
    "total_tokens": 854,
    "translated_title": "用低秩张量分解、Radon变换和字典估算联合概率分布",
    "translated_abstract": "本文提出了一种估计数据样本中联合概率密度的方法，假设底层分布能够分解为几个混合组分的乘积密度。我们结合了两个关键想法：用于表示1-D密度的字典以及用于估算1-D边际的随机投影，探索了先前的方法。相比基于字典的方法，我们的算法通过使用1-D边际进行重建而获得了更好的样本复杂度。我们在估算合成概率密度方面评估了我们方法的性能，并将其与以前的基于字典的方法和高斯混合模型（GMM）进行了比较。在所有实验设置中，我们的算法表现优于这些其他方法。",
    "tldr": "本文提出了一种用低秩张量分解、Radon变换和字典估算联合概率分布的方法，通过使用1-D边际进行重建获得了更好的样本复杂度，并在实验中表现优于以前的基于字典的方法和高斯混合模型（GMM）。",
    "en_tdlr": "This paper proposes a method for estimating joint probability density from data samples using low-rank tensor decomposition, Radon transforms, and dictionaries. The algorithm benefits from improved sample complexity by using 1-D marginals for reconstruction and outperforms previous dictionary-based approaches and Gaussian Mixture Models (GMMs)."
}