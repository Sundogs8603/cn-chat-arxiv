{
    "title": "A Novel Dual of Shannon Information and Weighting Scheme. (arXiv:2304.12814v1 [cs.CL])",
    "abstract": "Shannon Information theory has achieved great success in not only communication technology where it was originally developed for but also many other science and engineering fields such as machine learning and artificial intelligence. Inspired by the famous weighting scheme TF-IDF, we discovered that information entropy has a natural dual. We complement the classical Shannon information theory by proposing a novel quantity, namely troenpy. Troenpy measures the certainty, commonness and similarity of the underlying distribution. To demonstrate its usefulness, we propose a troenpy based weighting scheme for document with class labels, namely positive class frequency (PCF). On a collection of public datasets we show the PCF based weighting scheme outperforms the classical TF-IDF and a popular Optimal Transportation based word moving distance algorithm in a kNN setting. We further developed a new odds-ratio type feature, namely Expected Class Information Bias(ECIB), which can be regarded as",
    "link": "http://arxiv.org/abs/2304.12814",
    "context": "Title: A Novel Dual of Shannon Information and Weighting Scheme. (arXiv:2304.12814v1 [cs.CL])\nAbstract: Shannon Information theory has achieved great success in not only communication technology where it was originally developed for but also many other science and engineering fields such as machine learning and artificial intelligence. Inspired by the famous weighting scheme TF-IDF, we discovered that information entropy has a natural dual. We complement the classical Shannon information theory by proposing a novel quantity, namely troenpy. Troenpy measures the certainty, commonness and similarity of the underlying distribution. To demonstrate its usefulness, we propose a troenpy based weighting scheme for document with class labels, namely positive class frequency (PCF). On a collection of public datasets we show the PCF based weighting scheme outperforms the classical TF-IDF and a popular Optimal Transportation based word moving distance algorithm in a kNN setting. We further developed a new odds-ratio type feature, namely Expected Class Information Bias(ECIB), which can be regarded as",
    "path": "papers/23/04/2304.12814.json",
    "total_tokens": 798,
    "translated_title": "一种新型的Shannon信息及加权方案的对偶",
    "translated_abstract": "Shannon信息理论不仅在通信技术领域，其应用还拓展至机器学习和人工智能领域。本文发掘信息熵存在自然对偶，并引入了一种新的量troenpy，用于衡量底层分布的确定性、普遍性和相似性。我们提出了基于troenpy的文档加权方案，即正类别频率（PCF），并证明其在公共数据集上的优越性。此外，我们还开发了一种新的类别信息偏差特征ECIB，在监督学习中具有互信息的泛化性质。",
    "tldr": "本文通过发掘信息熵自然对偶，提出了一种新的量troenpy，并应用于提出了基于troenpy的文档加权方案，即正类别频率（PCF），以及一种新的类别信息偏差特征ECIB，在监督学习中具有互信息的泛化性质。",
    "en_tdlr": "This paper proposes a new quantity troenpy, which is the dual of information entropy, and further applies it to propose a novel document weighting scheme PCF and a supervised learning feature ECIB, both showing better performance than classical methods."
}