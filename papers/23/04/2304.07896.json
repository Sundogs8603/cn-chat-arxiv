{
    "title": "Out-of-Variable Generalization. (arXiv:2304.07896v1 [cs.LG])",
    "abstract": "The ability of an agent to perform well in new and unseen environments is a crucial aspect of intelligence. In machine learning, this ability is referred to as strong or out-of-distribution generalization. However, simply considering differences in data distributions is not sufficient to fully capture differences in environments. In the present paper, we assay out-of-variable generalization, which refers to an agent's ability to handle new situations that involve variables never jointly observed before. We expect that such ability is important also for AI-driven scientific discovery: humans, too, explore 'Nature' by probing, observing and measuring subsets of variables at one time. Mathematically, it requires efficient re-use of past marginal knowledge, i.e., knowledge over subsets of variables. We study this problem, focusing on prediction tasks that involve observing overlapping, yet distinct, sets of causal parents. We show that the residual distribution of one environment encodes t",
    "link": "http://arxiv.org/abs/2304.07896",
    "context": "Title: Out-of-Variable Generalization. (arXiv:2304.07896v1 [cs.LG])\nAbstract: The ability of an agent to perform well in new and unseen environments is a crucial aspect of intelligence. In machine learning, this ability is referred to as strong or out-of-distribution generalization. However, simply considering differences in data distributions is not sufficient to fully capture differences in environments. In the present paper, we assay out-of-variable generalization, which refers to an agent's ability to handle new situations that involve variables never jointly observed before. We expect that such ability is important also for AI-driven scientific discovery: humans, too, explore 'Nature' by probing, observing and measuring subsets of variables at one time. Mathematically, it requires efficient re-use of past marginal knowledge, i.e., knowledge over subsets of variables. We study this problem, focusing on prediction tasks that involve observing overlapping, yet distinct, sets of causal parents. We show that the residual distribution of one environment encodes t",
    "path": "papers/23/04/2304.07896.json",
    "total_tokens": 864,
    "translated_abstract": "一个智能体在新的和未知的环境中表现良好的能力是智能的一个关键方面。在机器学习中，这种能力称为强或分布外推广义。然而，仅仅考虑数据分布的差异并不足以完全捕捉环境的差异。在本文中，我们考虑了变量外推广义，这是指智能体处理从未联合观察过的变量的新情况的能力。我们希望这种能力在基于人工智能的科学研究中同样很重要：人类也通过探索、观察和测量一次观察变量子集来探索'大自然'。从数学上讲，这需要有效地重复使用过去的边际知识，即变量子集上的知识。我们研究了这个问题，着重于涉及观察到重叠但不同的因果父项集的预测任务。我们展示了一个环境的残差分布编码了t",
    "tldr": "本文研究了智能体处理从未联合观察过的变量的新情况的能力，即变量外推 generalization。这种能力在基于人工智能的科学研究中很重要。",
    "en_tdlr": "This paper studies the ability of an agent to handle new situations that involve variables never jointly observed before, referred to as out-of-variable generalization. Such ability is important for AI-driven scientific discovery."
}