{
    "title": "FedVS: Straggler-Resilient and Privacy-Preserving Vertical Federated Learning for Split Models. (arXiv:2304.13407v1 [cs.LG])",
    "abstract": "In a vertical federated learning (VFL) system consisting of a central server and many distributed clients, the training data are vertically partitioned such that different features are privately stored on different clients. The problem of split VFL is to train a model split between the server and the clients. This paper aims to address two major challenges in split VFL: 1) performance degradation due to straggling clients during training; and 2) data and model privacy leakage from clients' uploaded data embeddings. We propose FedVS to simultaneously address these two challenges. The key idea of FedVS is to design secret sharing schemes for the local data and models, such that information-theoretical privacy against colluding clients and curious server is guaranteed, and the aggregation of all clients' embeddings is reconstructed losslessly, via decrypting computation shares from the non-straggling clients. Extensive experiments on various types of VFL datasets (including tabular, CV, a",
    "link": "http://arxiv.org/abs/2304.13407",
    "context": "Title: FedVS: Straggler-Resilient and Privacy-Preserving Vertical Federated Learning for Split Models. (arXiv:2304.13407v1 [cs.LG])\nAbstract: In a vertical federated learning (VFL) system consisting of a central server and many distributed clients, the training data are vertically partitioned such that different features are privately stored on different clients. The problem of split VFL is to train a model split between the server and the clients. This paper aims to address two major challenges in split VFL: 1) performance degradation due to straggling clients during training; and 2) data and model privacy leakage from clients' uploaded data embeddings. We propose FedVS to simultaneously address these two challenges. The key idea of FedVS is to design secret sharing schemes for the local data and models, such that information-theoretical privacy against colluding clients and curious server is guaranteed, and the aggregation of all clients' embeddings is reconstructed losslessly, via decrypting computation shares from the non-straggling clients. Extensive experiments on various types of VFL datasets (including tabular, CV, a",
    "path": "papers/23/04/2304.13407.json",
    "total_tokens": 1011,
    "translated_title": "FedVS: 面向分割模型的容错和隐私保护垂直联邦学习",
    "translated_abstract": "在一个由中央服务器和许多分布式客户端组成的垂直联邦学习系统中，训练数据被垂直分割，不同的特征存储在不同的客户端上。分割垂直联邦学习的问题是训练一个在服务器和客户端之间划分的模型。本文旨在解决分割垂直联邦学习中的两个主要挑战：1）由于训练过程中存在迟滞的客户端造成的性能下降；2）客户端上传数据嵌入导致的数据和模型隐私泄露。我们提出了FedVS来同时解决这两个挑战。FedVS的关键思想是设计本地数据和模型的秘密共享方案，从而保证针对勾结客户和好奇服务器的信息理论隐私，并且通过解密计算股份，无损重构所有客户端的嵌入的汇总。在各种类型的VFL数据集（包括表格，CV，图像，NLP）上进行了广泛的实验，证明了FedVS的有效性。",
    "tldr": "该论文提出FedVS，一种同时解决垂直联邦学习中滞后客户端和数据泄露问题的方法，通过设计本地数据和模型的秘密共享方案，以保证信息理论隐私，并通过解密计算股份，无损重构所有客户端的嵌入的汇总。"
}