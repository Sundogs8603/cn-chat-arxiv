{
    "title": "Unified Emulation-Simulation Training Environment for Autonomous Cyber Agents. (arXiv:2304.01244v1 [cs.LG])",
    "abstract": "Autonomous cyber agents may be developed by applying reinforcement and deep reinforcement learning (RL/DRL), where agents are trained in a representative environment. The training environment must simulate with high-fidelity the network Cyber Operations (CyOp) that the agent aims to explore. Given the complexity of net-work CyOps, a good simulator is difficult to achieve. This work presents a systematic solution to automatically generate a high-fidelity simulator in the Cyber Gym for Intelligent Learning (CyGIL). Through representation learning and continuous learning, CyGIL provides a unified CyOp training environment where an emulated CyGIL-E automatically generates a simulated CyGIL-S. The simulator generation is integrated with the agent training process to further reduce the required agent training time. The agent trained in CyGIL-S is transferrable directly to CyGIL-E showing full transferability to the emulated \"real\" network. Experimental results are presented to demonstrate th",
    "link": "http://arxiv.org/abs/2304.01244",
    "context": "Title: Unified Emulation-Simulation Training Environment for Autonomous Cyber Agents. (arXiv:2304.01244v1 [cs.LG])\nAbstract: Autonomous cyber agents may be developed by applying reinforcement and deep reinforcement learning (RL/DRL), where agents are trained in a representative environment. The training environment must simulate with high-fidelity the network Cyber Operations (CyOp) that the agent aims to explore. Given the complexity of net-work CyOps, a good simulator is difficult to achieve. This work presents a systematic solution to automatically generate a high-fidelity simulator in the Cyber Gym for Intelligent Learning (CyGIL). Through representation learning and continuous learning, CyGIL provides a unified CyOp training environment where an emulated CyGIL-E automatically generates a simulated CyGIL-S. The simulator generation is integrated with the agent training process to further reduce the required agent training time. The agent trained in CyGIL-S is transferrable directly to CyGIL-E showing full transferability to the emulated \"real\" network. Experimental results are presented to demonstrate th",
    "path": "papers/23/04/2304.01244.json",
    "total_tokens": 947,
    "translated_title": "自主网络攻击代理的统一仿真模拟训练环境",
    "translated_abstract": "通过强化学习和深度强化学习（RL / DRL），可以开发自主网络攻击代理，并在代表性环境中对代理进行训练。训练环境必须高度真实地模拟代理所要探索的网络Cyber Operations（CyOp）。本文介绍了一种系统解决方案，在智能学习的Cyber Gym for Intelligent Learning（CyGIL）中自动生成高保真度的模拟器。通过表征学习和连续学习，CyGIL提供统一的CyOp培训环境，其中仿真的CyGIL-S由自动生成的CyGIL-E生成。将模拟器生成与代理训练过程集成，以进一步减少所需的代理训练时间。在CyGIL-S中训练的代理可以直接被传输到CyGIL-E，完全可转移至仿真的“真实”网络。实验结果展示了这些解决方案的实际应用。",
    "tldr": "本文提出了一种自动生成高保真度的模拟器解决方案，在智能学习的Cyber Gym for Intelligent Learning（CyGIL）中提供高度真实的网络Cyber Operations（CyOp）训练环境，并通过集成模拟器生成和代理训练过程来降低代理训练时间。",
    "en_tdlr": "The paper proposes a solution to automatically generate high-fidelity simulators for a unified Cyber Operations (CyOp) training environment in the Cyber Gym for Intelligent Learning (CyGIL), which can be used to train autonomous cyber agents using reinforcement and deep reinforcement learning (RL/DRL). The simulator generation is integrated with the agent training process to reduce the required training time, and the trained agent is transferrable to a simulated and \"real\" network."
}