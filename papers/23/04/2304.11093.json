{
    "title": "Hi Sheldon! Creating Deep Personalized Characters from TV Shows. (arXiv:2304.11093v1 [cs.CL])",
    "abstract": "Imagine an interesting multimodal interactive scenario that you can see, hear, and chat with an AI-generated digital character, who is capable of behaving like Sheldon from The Big Bang Theory, as a DEEP copy from appearance to personality. Towards this fantastic multimodal chatting scenario, we propose a novel task, named Deep Personalized Character Creation (DPCC): creating multimodal chat personalized characters from multimodal data such as TV shows. Specifically, given a single- or multi-modality input (text, audio, video), the goal of DPCC is to generate a multi-modality (text, audio, video) response, which should be well-matched the personality of a specific character such as Sheldon, and of high quality as well. To support this novel task, we further collect a character centric multimodal dialogue dataset, named Deep Personalized Character Dataset (DPCD), from TV shows. DPCD contains character-specific multimodal dialogue data of ~10k utterances and ~6 hours of audio/video per c",
    "link": "http://arxiv.org/abs/2304.11093",
    "context": "Title: Hi Sheldon! Creating Deep Personalized Characters from TV Shows. (arXiv:2304.11093v1 [cs.CL])\nAbstract: Imagine an interesting multimodal interactive scenario that you can see, hear, and chat with an AI-generated digital character, who is capable of behaving like Sheldon from The Big Bang Theory, as a DEEP copy from appearance to personality. Towards this fantastic multimodal chatting scenario, we propose a novel task, named Deep Personalized Character Creation (DPCC): creating multimodal chat personalized characters from multimodal data such as TV shows. Specifically, given a single- or multi-modality input (text, audio, video), the goal of DPCC is to generate a multi-modality (text, audio, video) response, which should be well-matched the personality of a specific character such as Sheldon, and of high quality as well. To support this novel task, we further collect a character centric multimodal dialogue dataset, named Deep Personalized Character Dataset (DPCD), from TV shows. DPCD contains character-specific multimodal dialogue data of ~10k utterances and ~6 hours of audio/video per c",
    "path": "papers/23/04/2304.11093.json",
    "total_tokens": 867,
    "translated_title": "Hi Sheldon! 从电视剧中创建深度个性化角色。",
    "translated_abstract": "想象一下，你可以与一个通过人工智能生成的数字角色进行视听交互，其外貌和个性与《生活大爆炸》中的Sheldon几乎一模一样。为了实现这一神奇的视听交互场景，我们提出了一个名为\"Deep Personalized Character Creation（DPCC）\"的创新任务：从电视剧等多模态数据中创造出个性化角色。具体而言，给定单一或多个模式的文本、音频或视频输入，DPCC旨在生成与某个特定角色（如Sheldon）的个性特点非常匹配且质量高的多模态（文本、音频、视频）响应。为了支持这一创新任务，我们进一步收集了一个名为\"Deep Personalized Character Dataset（DPCD）\"的角色中心多模态对话数据集，该数据集包含~10k个话语和~6个小时的音频/视频。",
    "tldr": "从多模态数据中通过DPCC创造出能够与用户进行视听交互的深度个性化数字角色，并收集了一个包含近10k个话语和6个小时音频/视频的角色中心多模态对话数据集。",
    "en_tdlr": "The paper proposes a novel task called Deep Personalized Character Creation (DPCC) aimed at creating multi-modal chat personalized characters well-matched to specific character's personality, and collects a character-centric dataset to support this task."
}