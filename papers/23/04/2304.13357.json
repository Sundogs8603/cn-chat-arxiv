{
    "title": "Deep Lifelong Cross-modal Hashing. (arXiv:2304.13357v1 [cs.CV])",
    "abstract": "Hashing methods have made significant progress in cross-modal retrieval tasks with fast query speed and low storage cost. Among them, deep learning-based hashing achieves better performance on large-scale data due to its excellent extraction and representation ability for nonlinear heterogeneous features. However, there are still two main challenges in catastrophic forgetting when data with new categories arrive continuously, and time-consuming for non-continuous hashing retrieval to retrain for updating. To this end, we, in this paper, propose a novel deep lifelong cross-modal hashing to achieve lifelong hashing retrieval instead of re-training hash function repeatedly when new data arrive. Specifically, we design lifelong learning strategy to update hash functions by directly training the incremental data instead of retraining new hash functions using all the accumulated data, which significantly reduce training time. Then, we propose lifelong hashing loss to enable original hash cod",
    "link": "http://arxiv.org/abs/2304.13357",
    "context": "Title: Deep Lifelong Cross-modal Hashing. (arXiv:2304.13357v1 [cs.CV])\nAbstract: Hashing methods have made significant progress in cross-modal retrieval tasks with fast query speed and low storage cost. Among them, deep learning-based hashing achieves better performance on large-scale data due to its excellent extraction and representation ability for nonlinear heterogeneous features. However, there are still two main challenges in catastrophic forgetting when data with new categories arrive continuously, and time-consuming for non-continuous hashing retrieval to retrain for updating. To this end, we, in this paper, propose a novel deep lifelong cross-modal hashing to achieve lifelong hashing retrieval instead of re-training hash function repeatedly when new data arrive. Specifically, we design lifelong learning strategy to update hash functions by directly training the incremental data instead of retraining new hash functions using all the accumulated data, which significantly reduce training time. Then, we propose lifelong hashing loss to enable original hash cod",
    "path": "papers/23/04/2304.13357.json",
    "total_tokens": 889,
    "translated_title": "深度生命周期跨模态哈希",
    "translated_abstract": "哈希方法在交叉模态检索任务中取得了重大进展，具有快速的查询速度和低存储成本。其中，基于深度学习的哈希由于其出色的非线性异构特征提取和表示能力，在大规模数据上实现了更好的性能。然而，在数据不断到来时，灾难性遗忘和非连续哈希检索更新的耗时仍然是两个主要挑战。为此，我们在本文中提出了一种新颖的深度生命周期跨模态哈希方法，以实现生命周期哈希检索而不是重复训练哈希函数。具体而言，我们设计了终身学习策略，通过直接训练增量数据来更新哈希函数，而不是使用累计数据重新训练新的哈希函数，这显著减少了训练时间。然后，我们提出了生命周期哈希损失函数，以使原始哈希码可以适应新数据。",
    "tldr": "本文提出了一种深度学习的终身学习跨模态哈希方法，可以在不重复训练哈希函数的情况下实现生命周期哈希检索，而且通过直接训练增量数据来更新哈希函数，避免了灾难性遗忘和非连续哈希检索更新的耗时。",
    "en_tdlr": "This paper proposes a novel deep lifelong cross-modal hashing method, which achieves lifelong hashing retrieval without repeatedly training hash functions. By directly training the incremental data to update hash functions, it avoids catastrophic forgetting and time-consuming non-continuous hashing retrieval updates."
}