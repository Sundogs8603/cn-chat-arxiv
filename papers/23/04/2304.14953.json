{
    "title": "CCpdf: Building a High Quality Corpus for Visually Rich Documents from Web Crawl Data. (arXiv:2304.14953v1 [cs.CL])",
    "abstract": "In recent years, the field of document understanding has progressed a lot. A significant part of this progress has been possible thanks to the use of language models pretrained on large amounts of documents. However, pretraining corpora used in the domain of document understanding are single domain, monolingual, or nonpublic. Our goal in this paper is to propose an efficient pipeline for creating a big-scale, diverse, multilingual corpus of PDF files from all over the Internet using Common Crawl, as PDF files are the most canonical types of documents as considered in document understanding. We analysed extensively all of the steps of the pipeline and proposed a solution which is a trade-off between data quality and processing time. We also share a CCpdf corpus in a form or an index of PDF files along with a script for downloading them, which produces a collection useful for language model pretraining. The dataset and tools published with this paper offer researchers the opportunity to ",
    "link": "http://arxiv.org/abs/2304.14953",
    "context": "Title: CCpdf: Building a High Quality Corpus for Visually Rich Documents from Web Crawl Data. (arXiv:2304.14953v1 [cs.CL])\nAbstract: In recent years, the field of document understanding has progressed a lot. A significant part of this progress has been possible thanks to the use of language models pretrained on large amounts of documents. However, pretraining corpora used in the domain of document understanding are single domain, monolingual, or nonpublic. Our goal in this paper is to propose an efficient pipeline for creating a big-scale, diverse, multilingual corpus of PDF files from all over the Internet using Common Crawl, as PDF files are the most canonical types of documents as considered in document understanding. We analysed extensively all of the steps of the pipeline and proposed a solution which is a trade-off between data quality and processing time. We also share a CCpdf corpus in a form or an index of PDF files along with a script for downloading them, which produces a collection useful for language model pretraining. The dataset and tools published with this paper offer researchers the opportunity to ",
    "path": "papers/23/04/2304.14953.json",
    "total_tokens": 915,
    "translated_title": "CCpdf：从网络爬虫数据中构建高质量的视觉丰富文档语料库",
    "translated_abstract": "最近几年，文档理解领域取得了很大进展。这些进展的一部分得益于使用预训练于大量文档的语言模型。然而，文档理解领域中使用的预训练语料库通常单一领域、单语言、或不公开。本文旨在提出一种有效的流程，通过使用Common Crawl，从互联网上收集PDF文件，构建一个大规模、多样化、多语言的语料库。我们对构建流程的所有步骤进行了广泛分析，并提出了一个在数据质量和处理时间之间平衡的解决方案。同时，我们还分享了一个CCpdf语料库，其中包括PDF文件的索引和下载脚本，可以用于语言模型预训练。本文所发布的数据集和工具为研究人员提供了进行视觉丰富文档研究的机会。",
    "tldr": "本文提出了一个流程，通过使用Common Crawl，从互联网上收集PDF文件，构建一个大规模、多样化、多语言的语料库。我们分享了一个CCpdf语料库，为研究人员提供了进行视觉丰富文档研究的机会。"
}