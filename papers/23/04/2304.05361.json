{
    "title": "Asymmetric Polynomial Loss For Multi-Label Classification. (arXiv:2304.05361v1 [cs.LG])",
    "abstract": "Various tasks are reformulated as multi-label classification problems, in which the binary cross-entropy (BCE) loss is frequently utilized for optimizing well-designed models. However, the vanilla BCE loss cannot be tailored for diverse tasks, resulting in a suboptimal performance for different models. Besides, the imbalance between redundant negative samples and rare positive samples could degrade the model performance. In this paper, we propose an effective Asymmetric Polynomial Loss (APL) to mitigate the above issues. Specifically, we first perform Taylor expansion on BCE loss. Then we ameliorate the coefficients of polynomial functions. We further employ the asymmetric focusing mechanism to decouple the gradient contribution from the negative and positive samples. Moreover, we validate that the polynomial coefficients can recalibrate the asymmetric focusing hyperparameters. Experiments on relation extraction, text classification, and image classification show that our APL loss can ",
    "link": "http://arxiv.org/abs/2304.05361",
    "context": "Title: Asymmetric Polynomial Loss For Multi-Label Classification. (arXiv:2304.05361v1 [cs.LG])\nAbstract: Various tasks are reformulated as multi-label classification problems, in which the binary cross-entropy (BCE) loss is frequently utilized for optimizing well-designed models. However, the vanilla BCE loss cannot be tailored for diverse tasks, resulting in a suboptimal performance for different models. Besides, the imbalance between redundant negative samples and rare positive samples could degrade the model performance. In this paper, we propose an effective Asymmetric Polynomial Loss (APL) to mitigate the above issues. Specifically, we first perform Taylor expansion on BCE loss. Then we ameliorate the coefficients of polynomial functions. We further employ the asymmetric focusing mechanism to decouple the gradient contribution from the negative and positive samples. Moreover, we validate that the polynomial coefficients can recalibrate the asymmetric focusing hyperparameters. Experiments on relation extraction, text classification, and image classification show that our APL loss can ",
    "path": "papers/23/04/2304.05361.json",
    "total_tokens": 835,
    "translated_title": "针对多标签分类的非对称多项式损失",
    "translated_abstract": "多种任务被重新构造为多标签分类问题，其中二元交叉熵（BCE）损失经常用于优化设计良好的模型。然而，纯BCE损失无法根据不同任务进行优化，从而导致不同模型的表现亚优。此外，冗余负样品和罕见正样品之间的不平衡可能会降低模型性能。在本文中，我们提出了一种有效的非对称多项式损失（APL）来缓解上述问题。具体而言，我们首先对BCE损失进行泰勒展开，然后改善多项式函数的系数。我们进一步采用非对称聚焦机制来解耦来自负样本和正样本的梯度贡献。此外，我们验证，多项式系数可以重新校准非对称聚焦超参数。在关系提取、文本分类和图像分类上的实验表明，我们的APL损失可以提供更好的性能。",
    "tldr": "本文提出了一种有效的非对称多项式损失（APL），可以根据不同任务优化模型，并在关系提取、文本分类和图像分类上表现良好。"
}