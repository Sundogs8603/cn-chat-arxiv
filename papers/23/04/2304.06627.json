{
    "title": "CoSDA: Continual Source-Free Domain Adaptation. (arXiv:2304.06627v1 [cs.LG])",
    "abstract": "Without access to the source data, source-free domain adaptation (SFDA) transfers knowledge from a source-domain trained model to target domains. Recently, SFDA has gained popularity due to the need to protect the data privacy of the source domain, but it suffers from catastrophic forgetting on the source domain due to the lack of data. To systematically investigate the mechanism of catastrophic forgetting, we first reimplement previous SFDA approaches within a unified framework and evaluate them on four benchmarks. We observe that there is a trade-off between adaptation gain and forgetting loss, which motivates us to design a consistency regularization to mitigate forgetting. In particular, we propose a continual source-free domain adaptation approach named CoSDA, which employs a dual-speed optimized teacher-student model pair and is equipped with consistency learning capability. Our experiments demonstrate that CoSDA outperforms state-of-the-art approaches in continuous adaptation. N",
    "link": "http://arxiv.org/abs/2304.06627",
    "context": "Title: CoSDA: Continual Source-Free Domain Adaptation. (arXiv:2304.06627v1 [cs.LG])\nAbstract: Without access to the source data, source-free domain adaptation (SFDA) transfers knowledge from a source-domain trained model to target domains. Recently, SFDA has gained popularity due to the need to protect the data privacy of the source domain, but it suffers from catastrophic forgetting on the source domain due to the lack of data. To systematically investigate the mechanism of catastrophic forgetting, we first reimplement previous SFDA approaches within a unified framework and evaluate them on four benchmarks. We observe that there is a trade-off between adaptation gain and forgetting loss, which motivates us to design a consistency regularization to mitigate forgetting. In particular, we propose a continual source-free domain adaptation approach named CoSDA, which employs a dual-speed optimized teacher-student model pair and is equipped with consistency learning capability. Our experiments demonstrate that CoSDA outperforms state-of-the-art approaches in continuous adaptation. N",
    "path": "papers/23/04/2304.06627.json",
    "total_tokens": 891,
    "translated_title": "CoSDA: 持续的无源域适应",
    "translated_abstract": "无源域适应（SFDA）是指在没有访问源数据的情况下，将源域训练模型的知识应用于目标域。由于需要保护源域数据的隐私，SFDA最近变得流行起来，但由于缺乏数据，它会在源域上出现灾难性的遗忘现象。为了系统地研究灾难性遗忘的机制，我们首先在统一框架内重新实现了以往的SFDA方法，并在四项基准测试中对它们进行评估。我们观察到，对于适应性增益和遗忘损失之间存在一种权衡，这促使我们设计一种一致性正则化来减轻遗忘。特别地，我们提出了一种名为CoSDA的持续无源域适应方法，采用双速度优化的师生模型对，并配备有一致性学习能力。我们的实验表明，CoSDA在持续适应方面优于现有的方法。",
    "tldr": "提出了一种名为CoSDA的持续无源域适应的方法，采用双速度优化的师生模型对并配备有一致性学习能力，旨在减轻灾难性遗忘的问题，并在实验中取得了较优的表现。"
}