{
    "title": "PMC-LLaMA: Further Finetuning LLaMA on Medical Papers. (arXiv:2304.14454v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs) have showcased remarkable capabilities in natural language understanding in various domains. These models can usually behave well on daily dialog, or question answering scenarios, however, in areas that value precision, for example, in medical applications, they often exhibit unsatisfactory performance due to a lack of domain-specific knowledge. In this report, we introduce PMC-LLaMA, an open-source language model that is acquired by fine-tuning an open-source language model on a total of 4.8 million biomedical academic papers for further injecting medical knowledge, enhancing its capability in medical domain. Our preliminary evaluations are conducted on three biomedical QA datasets, including PubMedQA, MedMCQA, and USMLE, showing that the our model after finetuning, i.e., PMC-LLaMA, demonstrates better understanding of biomedical domain-specific concepts, thus achieving high performance on QA benchmarks. The model and codes, along with an online demo, are ",
    "link": "http://arxiv.org/abs/2304.14454",
    "context": "Title: PMC-LLaMA: Further Finetuning LLaMA on Medical Papers. (arXiv:2304.14454v1 [cs.CL])\nAbstract: Large Language Models (LLMs) have showcased remarkable capabilities in natural language understanding in various domains. These models can usually behave well on daily dialog, or question answering scenarios, however, in areas that value precision, for example, in medical applications, they often exhibit unsatisfactory performance due to a lack of domain-specific knowledge. In this report, we introduce PMC-LLaMA, an open-source language model that is acquired by fine-tuning an open-source language model on a total of 4.8 million biomedical academic papers for further injecting medical knowledge, enhancing its capability in medical domain. Our preliminary evaluations are conducted on three biomedical QA datasets, including PubMedQA, MedMCQA, and USMLE, showing that the our model after finetuning, i.e., PMC-LLaMA, demonstrates better understanding of biomedical domain-specific concepts, thus achieving high performance on QA benchmarks. The model and codes, along with an online demo, are ",
    "path": "papers/23/04/2304.14454.json",
    "total_tokens": 980,
    "translated_title": "PMC-LLaMA: 在医学论文中进行LLaMA的进一步微调",
    "translated_abstract": "大型语言模型(LLM)在各个领域的自然语言理解方面具有出色的能力。这些模型通常在日常对话或问答场景中表现良好，然而，在注重精度的领域，例如医疗应用中，它们往往表现出不尽人意的性能，原因是缺乏特定领域的知识。在本文中，我们介绍了PMC-LLaMA，这是一种开源的语言模型，通过在总共480万篇生物医学论文上微调开源语言模型，以进一步注入医学知识，增强其在医学领域的能力。我们进行了初步评估，包括PubMedQA、MedMCQA和USMLE等三个生物医学问答数据集，结果显示，我们的模型经过微调后，即PMC-LLaMA，对生物医学领域的特定概念有更好的理解，因此在问答基准测试中取得了较高的性能。该模型和代码以及在线演示均可在https://github.com/cstorm125/pmc-llama上找到。",
    "tldr": "本文介绍了一个针对医学领域进一步微调的开源语言模型PMC-LLaMA，其通过增加医学知识提高了在生物医学领域的性能表现，有望在生物医学问答领域有更好的应用表现。",
    "en_tdlr": "This paper introduces an open-source language model, PMC-LLaMA, which is fine-tuned on 4.8 million biomedical academic papers to inject medical knowledge and enhance its performance in the medical domain. The model shows better understanding of biomedical domain-specific concepts and achieves high performance on biomedical QA benchmarks."
}