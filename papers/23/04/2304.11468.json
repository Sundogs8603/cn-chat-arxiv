{
    "title": "Increasing the Scope as You Learn: Adaptive Bayesian Optimization in Nested Subspaces. (arXiv:2304.11468v1 [cs.LG])",
    "abstract": "Recent advances have extended the scope of Bayesian optimization (BO) to expensive-to-evaluate black-box functions with dozens of dimensions, aspiring to unlock impactful applications, for example, in the life sciences, neural architecture search, and robotics. However, a closer examination reveals that the state-of-the-art methods for high-dimensional Bayesian optimization (HDBO) suffer from degrading performance as the number of dimensions increases or even risk failure if certain unverifiable assumptions are not met. This paper proposes BAxUS that leverages a novel family of nested random subspaces to adapt the space it optimizes over to the problem. This ensures high performance while removing the risk of failure, which we assert via theoretical guarantees. A comprehensive evaluation demonstrates that BAxUS achieves better results than the state-of-the-art methods for a broad set of applications.",
    "link": "http://arxiv.org/abs/2304.11468",
    "context": "Title: Increasing the Scope as You Learn: Adaptive Bayesian Optimization in Nested Subspaces. (arXiv:2304.11468v1 [cs.LG])\nAbstract: Recent advances have extended the scope of Bayesian optimization (BO) to expensive-to-evaluate black-box functions with dozens of dimensions, aspiring to unlock impactful applications, for example, in the life sciences, neural architecture search, and robotics. However, a closer examination reveals that the state-of-the-art methods for high-dimensional Bayesian optimization (HDBO) suffer from degrading performance as the number of dimensions increases or even risk failure if certain unverifiable assumptions are not met. This paper proposes BAxUS that leverages a novel family of nested random subspaces to adapt the space it optimizes over to the problem. This ensures high performance while removing the risk of failure, which we assert via theoretical guarantees. A comprehensive evaluation demonstrates that BAxUS achieves better results than the state-of-the-art methods for a broad set of applications.",
    "path": "papers/23/04/2304.11468.json",
    "total_tokens": 872,
    "translated_title": "学习时扩大范围：嵌套子空间中的自适应贝叶斯优化",
    "translated_abstract": "最近的进展将贝叶斯优化（BO）的范围扩展到了具有几十个维度的昂贵黑盒函数，并渴望在生命科学、神经架构搜索和机器人等领域实现重大应用。然而，对高维贝叶斯优化（HDBO）的现有方法的更深入研究表明，随着维度数量的增加，性能会降低，甚至有失败风险，如果不满足某些无法验证的假设。该论文提出了BAxUS，它利用一族新颖的嵌套随机子空间来使其优化的空间适应问题。这确保了高性能，同时通过理论保证消除了失败的风险。全面评估表明，对于广泛的应用，BAxUS比现有的最先进方法取得了更好的结果。",
    "tldr": "该论文提出了一种自适应贝叶斯优化方法BAxUS，通过利用嵌套子空间来避免高维贝叶斯优化中的风险并确保高性能，相对于现有最先进方法在广泛应用中取得更好结果。",
    "en_tdlr": "The paper proposes an adaptive Bayesian optimization method, BAxUS, that leverages nested random subspaces to avoid the risk of high-dimensional Bayesian optimization and ensure high performance, achieving better results than state-of-the-art methods in a broad set of applications."
}