{
    "title": "Metrics for Bayesian Optimal Experiment Design under Model Misspecification. (arXiv:2304.07949v1 [stat.ME])",
    "abstract": "The conventional approach to Bayesian decision-theoretic experiment design involves searching over possible experiments to select a design that maximizes the expected value of a specified utility function. The expectation is over the joint distribution of all unknown variables implied by the statistical model that will be used to analyze the collected data. The utility function defines the objective of the experiment where a common utility function is the information gain. This article introduces an expanded framework for this process, where we go beyond the traditional Expected Information Gain criteria and introduce the Expected General Information Gain which measures robustness to the model discrepancy and Expected Discriminatory Information as a criterion to quantify how well an experiment can detect model discrepancy. The functionality of the framework is showcased through its application to a scenario involving a linearized spring mass damper system and an F-16 model where the mo",
    "link": "http://arxiv.org/abs/2304.07949",
    "context": "Title: Metrics for Bayesian Optimal Experiment Design under Model Misspecification. (arXiv:2304.07949v1 [stat.ME])\nAbstract: The conventional approach to Bayesian decision-theoretic experiment design involves searching over possible experiments to select a design that maximizes the expected value of a specified utility function. The expectation is over the joint distribution of all unknown variables implied by the statistical model that will be used to analyze the collected data. The utility function defines the objective of the experiment where a common utility function is the information gain. This article introduces an expanded framework for this process, where we go beyond the traditional Expected Information Gain criteria and introduce the Expected General Information Gain which measures robustness to the model discrepancy and Expected Discriminatory Information as a criterion to quantify how well an experiment can detect model discrepancy. The functionality of the framework is showcased through its application to a scenario involving a linearized spring mass damper system and an F-16 model where the mo",
    "path": "papers/23/04/2304.07949.json",
    "total_tokens": 832,
    "translated_title": "模型错误下的贝叶斯最优实验设计度量",
    "translated_abstract": "贝叶斯决策理论实验设计的传统方法是在可能的实验中搜索，以选择最大化指定效用函数的设计。期望是对所采集数据的统计模型所蕴含的所有未知变量的联合分布。效用函数定义了实验的目标，其中常见的效用函数是信息增益。本文引入了一个扩展的框架，在此过程中，我们超越了传统的期望信息增益准则，并引入了测量模型差异稳健性的期望一般信息增益和量化实验检测模型差异能力的期望鉴别信息作为准则。该框架的功能通过其在涉及线性弹簧质量阻尼系统和F-16模型的情景中的应用进行了展示。",
    "tldr": "本文提出了一个拓展的框架，其中的期望一般信息增益和期望鉴别信息作为准则，用来度量模型差异稳健性和实验检测模型差异能力。"
}