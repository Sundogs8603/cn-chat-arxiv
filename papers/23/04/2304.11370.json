{
    "title": "SAILER: Structure-aware Pre-trained Language Model for Legal Case Retrieval. (arXiv:2304.11370v1 [cs.IR])",
    "abstract": "Legal case retrieval, which aims to find relevant cases for a query case, plays a core role in the intelligent legal system. Despite the success that pre-training has achieved in ad-hoc retrieval tasks, effective pre-training strategies for legal case retrieval remain to be explored. Compared with general documents, legal case documents are typically long text sequences with intrinsic logical structures. However, most existing language models have difficulty understanding the long-distance dependencies between different structures. Moreover, in contrast to the general retrieval, the relevance in the legal domain is sensitive to key legal elements. Even subtle differences in key legal elements can significantly affect the judgement of relevance. However, existing pre-trained language models designed for general purposes have not been equipped to handle legal elements.  To address these issues, in this paper, we propose SAILER, a new Structure-Aware pre-traIned language model for LEgal c",
    "link": "http://arxiv.org/abs/2304.11370",
    "context": "Title: SAILER: Structure-aware Pre-trained Language Model for Legal Case Retrieval. (arXiv:2304.11370v1 [cs.IR])\nAbstract: Legal case retrieval, which aims to find relevant cases for a query case, plays a core role in the intelligent legal system. Despite the success that pre-training has achieved in ad-hoc retrieval tasks, effective pre-training strategies for legal case retrieval remain to be explored. Compared with general documents, legal case documents are typically long text sequences with intrinsic logical structures. However, most existing language models have difficulty understanding the long-distance dependencies between different structures. Moreover, in contrast to the general retrieval, the relevance in the legal domain is sensitive to key legal elements. Even subtle differences in key legal elements can significantly affect the judgement of relevance. However, existing pre-trained language models designed for general purposes have not been equipped to handle legal elements.  To address these issues, in this paper, we propose SAILER, a new Structure-Aware pre-traIned language model for LEgal c",
    "path": "papers/23/04/2304.11370.json",
    "total_tokens": 940,
    "translated_title": "SAILER: 面向法律案例检索的结构感知预训练语言模型",
    "translated_abstract": "针对智能法律系统中的核心工作——法律案例检索，本文提出了一种新的结构感知预训练语言模型SAILER。与通用文档相比，法律案例文件通常具有固有的逻辑结构，并包含关键的法律要素。SAILER采用多任务预训练策略，包括遮蔽语言建模任务和适用于法律文档的结构感知连贯性预测任务。实验结果表明，SAILER在两个法律案例检索数据集上显著优于几个强基线模型。",
    "tldr": "本文提出了一种结构感知预训练语言模型SAILER，针对法律案例检索中的长文本序列和关键法律要素敏感问题，采用遮蔽语言建模任务和结构感知连贯性预测任务相结合的多任务预训练策略，在两个法律案例检索数据集上实现了显著优于强基线模型的性能表现。",
    "en_tdlr": "This paper proposes a new structure-aware pre-trained language model, SAILER, for legal case retrieval, which adopts a multi-task pre-training approach, including masked language modeling and structure-aware coherence prediction. SAILER outperforms strong baseline models significantly on two legal case retrieval datasets, addressing the sensitivity to long text sequences and key legal elements."
}