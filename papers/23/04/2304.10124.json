{
    "title": "Mastering Asymmetrical Multiplayer Game with Multi-Agent Asymmetric-Evolution Reinforcement Learning. (arXiv:2304.10124v1 [cs.AI])",
    "abstract": "Asymmetrical multiplayer (AMP) game is a popular game genre which involves multiple types of agents competing or collaborating with each other in the game. It is difficult to train powerful agents that can defeat top human players in AMP games by typical self-play training method because of unbalancing characteristics in their asymmetrical environments. We propose asymmetric-evolution training (AET), a novel multi-agent reinforcement learning framework that can train multiple kinds of agents simultaneously in AMP game. We designed adaptive data adjustment (ADA) and environment randomization (ER) to optimize the AET process. We tested our method in a complex AMP game named Tom \\& Jerry, and our AIs trained without using any human data can achieve a win rate of 98.5% against top human players over 65 matches. The ablation experiments indicated that the proposed modules are beneficial to the framework.",
    "link": "http://arxiv.org/abs/2304.10124",
    "context": "Title: Mastering Asymmetrical Multiplayer Game with Multi-Agent Asymmetric-Evolution Reinforcement Learning. (arXiv:2304.10124v1 [cs.AI])\nAbstract: Asymmetrical multiplayer (AMP) game is a popular game genre which involves multiple types of agents competing or collaborating with each other in the game. It is difficult to train powerful agents that can defeat top human players in AMP games by typical self-play training method because of unbalancing characteristics in their asymmetrical environments. We propose asymmetric-evolution training (AET), a novel multi-agent reinforcement learning framework that can train multiple kinds of agents simultaneously in AMP game. We designed adaptive data adjustment (ADA) and environment randomization (ER) to optimize the AET process. We tested our method in a complex AMP game named Tom \\& Jerry, and our AIs trained without using any human data can achieve a win rate of 98.5% against top human players over 65 matches. The ablation experiments indicated that the proposed modules are beneficial to the framework.",
    "path": "papers/23/04/2304.10124.json",
    "total_tokens": 942,
    "translated_title": "用多智能体非对称进化强化学习掌握非对称多人游戏",
    "translated_abstract": "非对称多人游戏（AMP）是一种流行的游戏类型，涉及多种类型的代理在游戏中相互竞争或合作。由于非对称环境中有不平衡的特性，因此使用典型的自我博弈训练方法训练强大的代理以击败顶级人类玩家在AMP游戏中是困难的。我们提出了非对称进化训练（AET），这是一种新颖的多智能体强化学习框架，可以同时训练多种代理在AMP游戏中。我们设计了自适应数据调整（ADA）和环境随机化（ER）来优化AET过程。我们在一个名为Tom＆Jerry的复杂AMP游戏中测试了我们的方法，我们训练出的AI对65个比赛取得了98.5％的胜率，而没有使用任何人类数据。消融实验表明，所提出的模块有益于该框架。",
    "tldr": "该论文提出了一种非对称进化训练（AET）框架，使用自适应数据调整（ADA）和环境随机化（ER）优化AET过程，使得AI可以在复杂的AMP游戏中击败顶级人类玩家，而不需要使用任何人类数据。",
    "en_tdlr": "This paper proposes an asymmetric-evolution training (AET) framework with adaptive data adjustment (ADA) and environment randomization (ER) to optimize the training process of multiple kinds of agents simultaneously in asymmetrical multiplayer (AMP) games. The agents trained with this method achieved a win rate of 98.5% against top human players in a complex AMP game named Tom & Jerry, without using any human data."
}