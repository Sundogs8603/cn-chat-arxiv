{
    "title": "Pre-processing training data improves accuracy and generalisability of convolutional neural network based landscape semantic segmentation. (arXiv:2304.14625v1 [cs.CV] CROSS LISTED)",
    "abstract": "In this paper, we trialled different methods of data preparation for Convolutional Neural Network (CNN) training and semantic segmentation of land use land cover (LULC) features within aerial photography over the Wet Tropics and Atherton Tablelands, Queensland, Australia. This was conducted through trialling and ranking various training patch selection sampling strategies, patch and batch sizes and data augmentations and scaling. We also compared model accuracy through producing the LULC classification using a single pass of a grid of patches and averaging multiple grid passes and three rotated version of each patch. Our results showed: a stratified random sampling approach for producing training patches improved the accuracy of classes with a smaller area while having minimal effect on larger classes; a smaller number of larger patches compared to a larger number of smaller patches improves model accuracy; applying data augmentations and scaling are imperative in creating a generalise",
    "link": "http://arxiv.org/abs/2304.14625",
    "context": "Title: Pre-processing training data improves accuracy and generalisability of convolutional neural network based landscape semantic segmentation. (arXiv:2304.14625v1 [cs.CV] CROSS LISTED)\nAbstract: In this paper, we trialled different methods of data preparation for Convolutional Neural Network (CNN) training and semantic segmentation of land use land cover (LULC) features within aerial photography over the Wet Tropics and Atherton Tablelands, Queensland, Australia. This was conducted through trialling and ranking various training patch selection sampling strategies, patch and batch sizes and data augmentations and scaling. We also compared model accuracy through producing the LULC classification using a single pass of a grid of patches and averaging multiple grid passes and three rotated version of each patch. Our results showed: a stratified random sampling approach for producing training patches improved the accuracy of classes with a smaller area while having minimal effect on larger classes; a smaller number of larger patches compared to a larger number of smaller patches improves model accuracy; applying data augmentations and scaling are imperative in creating a generalise",
    "path": "papers/23/04/2304.14625.json",
    "total_tokens": 975,
    "translated_title": "预处理训练数据改善了基于卷积神经网络的景观语义分割的准确性和可泛化性",
    "translated_abstract": "本文在澳大利亚昆士兰州湿热带和阿瑟顿高原地区的航空摄影中，试验了不同的数据准备方法，用于卷积神经网络（CNN）训练和土地利用土地覆盖（LULC）特征的语义分割。通过试验和排名不同的训练补丁选择采样策略，补丁和批次大小以及数据增强和缩放，我们比较了模型的准确性。通过生成LULC分类，我们还比较了使用一个网格补丁的单次传递和多次传递以及每个补丁的三个旋转版本的模型准确性。我们的结果表明：对于产生训练补丁，分层随机抽样方法改善了面积较小的类别的准确性，对较大类别的影响很小；相较于较多的小补丁，较少的大补丁能提高模型准确性；应用数据增强和缩放对创建一般化模型至关重要。",
    "tldr": "本文研究了卷积神经网络（CNN）训练和景观语义分割中的数据准备方法，并发现分层随机抽样方法和较少的大补丁能改善模型准确性，而数据增强和缩放对创建一般化模型非常重要。",
    "en_tdlr": "This paper investigates data preparation methods for Convolutional Neural Network (CNN) training and landscape semantic segmentation, discovering that stratified random sampling and a smaller number of larger patches improve model accuracy, while data augmentations and scaling are crucial for creating a generalizable model."
}