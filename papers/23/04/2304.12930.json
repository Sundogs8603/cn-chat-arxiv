{
    "title": "User-Centric Federated Learning: Trading off Wireless Resources for Personalization. (arXiv:2304.12930v1 [cs.LG])",
    "abstract": "Statistical heterogeneity across clients in a Federated Learning (FL) system increases the algorithm convergence time and reduces the generalization performance, resulting in a large communication overhead in return for a poor model. To tackle the above problems without violating the privacy constraints that FL imposes, personalized FL methods have to couple statistically similar clients without directly accessing their data in order to guarantee a privacy-preserving transfer. In this work, we design user-centric aggregation rules at the parameter server (PS) that are based on readily available gradient information and are capable of producing personalized models for each FL client. The proposed aggregation rules are inspired by an upper bound of the weighted aggregate empirical risk minimizer. Secondly, we derive a communication-efficient variant based on user clustering which greatly enhances its applicability to communication-constrained systems. Our algorithm outperforms popular pe",
    "link": "http://arxiv.org/abs/2304.12930",
    "context": "Title: User-Centric Federated Learning: Trading off Wireless Resources for Personalization. (arXiv:2304.12930v1 [cs.LG])\nAbstract: Statistical heterogeneity across clients in a Federated Learning (FL) system increases the algorithm convergence time and reduces the generalization performance, resulting in a large communication overhead in return for a poor model. To tackle the above problems without violating the privacy constraints that FL imposes, personalized FL methods have to couple statistically similar clients without directly accessing their data in order to guarantee a privacy-preserving transfer. In this work, we design user-centric aggregation rules at the parameter server (PS) that are based on readily available gradient information and are capable of producing personalized models for each FL client. The proposed aggregation rules are inspired by an upper bound of the weighted aggregate empirical risk minimizer. Secondly, we derive a communication-efficient variant based on user clustering which greatly enhances its applicability to communication-constrained systems. Our algorithm outperforms popular pe",
    "path": "papers/23/04/2304.12930.json",
    "total_tokens": 916,
    "translated_title": "用户中心联邦学习：为个性化而交换无线资源。",
    "translated_abstract": "在联邦学习系统中，客户端之间的统计异质性会增加算法收敛时间并降低泛化性能，导致高通信开销和质量低劣的模型。为了解决上述问题，而不违反联邦学习的隐私约束，个性化联邦学习方法必须将统计相似的客户端耦合在一起，以保证隐私保护的传输。在这项工作中，我们设计了基于可用的梯度信息的参数服务器（PS）的用户中心聚合规则，能够为每个联邦学习客户端生成个性化模型。所提出的聚合规则受加权聚合经验风险最小化的上界启发。其次，我们基于用户聚类导出了一种通信高效的变体，大大增强了其适用于通信受限系统的能力。我们的算法在两个基准数据集上的准确度和通信效率相似或更好地胜过了流行的对比算法。",
    "tldr": "本文提出基于用户中心的联邦学习算法，使用可用的梯度信息和聚合规则，为每个联邦学习客户端生成个性化模型，同时保证隐私保护的传输。在基准数据集上表现出了更好的准确度和通信效率。",
    "en_tdlr": "This paper proposes a user-centric federated learning algorithm that generates personalized models for each client using readily available gradient information and aggregation rules while ensuring privacy-preserving transfer. The algorithm outperforms popular peer algorithms on benchmark datasets in terms of accuracy and communication efficiency."
}