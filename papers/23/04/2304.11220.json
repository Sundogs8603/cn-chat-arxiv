{
    "title": "Learn What NOT to Learn: Towards Generative Safety in Chatbots. (arXiv:2304.11220v1 [cs.CL])",
    "abstract": "Conversational models that are generative and open-domain are particularly susceptible to generating unsafe content since they are trained on web-based social data. Prior approaches to mitigating this issue have drawbacks, such as disrupting the flow of conversation, limited generalization to unseen toxic input contexts, and sacrificing the quality of the dialogue for the sake of safety. In this paper, we present a novel framework, named \"LOT\" (Learn NOT to), that employs a contrastive loss to enhance generalization by learning from both positive and negative training signals. Our approach differs from the standard contrastive learning framework in that it automatically obtains positive and negative signals from the safe and unsafe language distributions that have been learned beforehand. The LOT framework utilizes divergence to steer the generations away from the unsafe subspace and towards the safe subspace while sustaining the flow of conversation. Our approach is memory and time-ef",
    "link": "http://arxiv.org/abs/2304.11220",
    "context": "Title: Learn What NOT to Learn: Towards Generative Safety in Chatbots. (arXiv:2304.11220v1 [cs.CL])\nAbstract: Conversational models that are generative and open-domain are particularly susceptible to generating unsafe content since they are trained on web-based social data. Prior approaches to mitigating this issue have drawbacks, such as disrupting the flow of conversation, limited generalization to unseen toxic input contexts, and sacrificing the quality of the dialogue for the sake of safety. In this paper, we present a novel framework, named \"LOT\" (Learn NOT to), that employs a contrastive loss to enhance generalization by learning from both positive and negative training signals. Our approach differs from the standard contrastive learning framework in that it automatically obtains positive and negative signals from the safe and unsafe language distributions that have been learned beforehand. The LOT framework utilizes divergence to steer the generations away from the unsafe subspace and towards the safe subspace while sustaining the flow of conversation. Our approach is memory and time-ef",
    "path": "papers/23/04/2304.11220.json",
    "total_tokens": 936,
    "translated_title": "学习“不学习”: 朝向聊天机器人中的生成安全",
    "translated_abstract": "生成式、开放领域的对话模型尤其容易生成不安全的内容，因为它们是在基于Web的社交数据上训练的。先前缓解这个问题的方法存在缺点，如打断对话流程、对未见过的有毒输入环境的泛化能力不强、为了安全而牺牲对话质量等。在本文中，我们提出了一种新颖的框架，称为“LOT”（Learn NOT to），它采用对比损失来增强泛化能力，通过同时从正面和负面训练信号中学习来做到这一点。相较于标准的对比学习框架，我们的方法从先前学习的安全和不安全语言分布中自动获得正、负信号。LOT框架利用离散度将生成向量从不安全子空间指向安全子空间，同时维持对话的流程。我们的方法内存和时间效率高，在SafeDialog数据集上实现了最先进的性能。",
    "tldr": "本文提出了一种名为“LOT”的框架，采用对比损失训练聊天机器人以从正面和负面训练信号中增强泛化能力，并使用离散度将生成向量从不安全子空间指向安全子空间，从而避免生成不安全的内容。",
    "en_tdlr": "This paper proposes a framework named \"LOT\" that enhances generative safety in chatbots by using contrastive loss to learn from both positive and negative signals, and steering generations towards the safe subspace using divergence. The approach achieves state-of-the-art performance on the SafeDialog dataset."
}