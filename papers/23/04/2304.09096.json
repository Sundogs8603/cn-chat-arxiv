{
    "title": "Privacy-Preserving Matrix Factorization for Recommendation Systems using Gaussian Mechanism. (arXiv:2304.09096v1 [cs.IR])",
    "abstract": "Building a recommendation system involves analyzing user data, which can potentially leak sensitive information about users. Anonymizing user data is often not sufficient for preserving user privacy. Motivated by this, we propose a privacy-preserving recommendation system based on the differential privacy framework and matrix factorization, which is one of the most popular algorithms for recommendation systems. As differential privacy is a powerful and robust mathematical framework for designing privacy-preserving machine learning algorithms, it is possible to prevent adversaries from extracting sensitive user information even if the adversary possesses their publicly available (auxiliary) information. We implement differential privacy via the Gaussian mechanism in the form of output perturbation and release user profiles that satisfy privacy definitions. We employ R\\'enyi Differential Privacy for a tight characterization of the overall privacy loss. We perform extensive experiments on",
    "link": "http://arxiv.org/abs/2304.09096",
    "context": "Title: Privacy-Preserving Matrix Factorization for Recommendation Systems using Gaussian Mechanism. (arXiv:2304.09096v1 [cs.IR])\nAbstract: Building a recommendation system involves analyzing user data, which can potentially leak sensitive information about users. Anonymizing user data is often not sufficient for preserving user privacy. Motivated by this, we propose a privacy-preserving recommendation system based on the differential privacy framework and matrix factorization, which is one of the most popular algorithms for recommendation systems. As differential privacy is a powerful and robust mathematical framework for designing privacy-preserving machine learning algorithms, it is possible to prevent adversaries from extracting sensitive user information even if the adversary possesses their publicly available (auxiliary) information. We implement differential privacy via the Gaussian mechanism in the form of output perturbation and release user profiles that satisfy privacy definitions. We employ R\\'enyi Differential Privacy for a tight characterization of the overall privacy loss. We perform extensive experiments on",
    "path": "papers/23/04/2304.09096.json",
    "total_tokens": 856,
    "translated_title": "基于高斯机制的保护隐私矩阵分解推荐系统",
    "translated_abstract": "建立推荐系统需要分析用户数据，这可能会泄露用户的个人信息。匿名化用户数据通常不足以保护用户隐私。鉴于此，本文提出了一种基于差分隐私框架和矩阵分解的保护隐私推荐系统，矩阵分解是最流行的推荐系统算法之一。通过差分隐私，即使对手拥有用户的公开信息，也可以防止对手提取敏感用户信息。我们采用输出扰动的高斯机制实现差分隐私并发布满足隐私定义的用户档案。我们使用Rényi差分隐私对整体隐私损失进行了紧密的特征化。我们在实验中进行了广泛的测试。",
    "tldr": "本文提出了一种基于差分隐私框架和矩阵分解的保护隐私推荐系统，采用输出扰动的高斯机制实现差分隐私，通过Rényi差分隐私对整体隐私损失进行特征化，在保护用户隐私的同时实现了推荐系统功能。",
    "en_tdlr": "This paper proposes a privacy-preserving recommendation system based on the differential privacy framework and matrix factorization, which uses the Gaussian mechanism for output perturbation to protect user privacy. The overall privacy loss is characterized by R\\'enyi Differential Privacy. Extensive experiments demonstrate the effectiveness of this approach in achieving both privacy protection and recommendation system functionality."
}