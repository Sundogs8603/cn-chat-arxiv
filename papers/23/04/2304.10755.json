{
    "title": "Interpretable and Robust AI in EEG Systems: A Survey. (arXiv:2304.10755v1 [eess.SP])",
    "abstract": "The close coupling of artificial intelligence (AI) and electroencephalography (EEG) has substantially advanced human-computer interaction (HCI) technologies in the AI era. Different from traditional EEG systems, the interpretability and robustness of AI-based EEG systems are becoming particularly crucial. The interpretability clarifies the inner working mechanisms of AI models and thus can gain the trust of users. The robustness reflects the AI's reliability against attacks and perturbations, which is essential for sensitive and fragile EEG signals. Thus the interpretability and robustness of AI in EEG systems have attracted increasing attention, and their research has achieved great progress recently. However, there is still no survey covering recent advances in this field. In this paper, we present the first comprehensive survey and summarize the interpretable and robust AI techniques for EEG systems. Specifically, we first propose a taxonomy of interpretability by characterizing it ",
    "link": "http://arxiv.org/abs/2304.10755",
    "context": "Title: Interpretable and Robust AI in EEG Systems: A Survey. (arXiv:2304.10755v1 [eess.SP])\nAbstract: The close coupling of artificial intelligence (AI) and electroencephalography (EEG) has substantially advanced human-computer interaction (HCI) technologies in the AI era. Different from traditional EEG systems, the interpretability and robustness of AI-based EEG systems are becoming particularly crucial. The interpretability clarifies the inner working mechanisms of AI models and thus can gain the trust of users. The robustness reflects the AI's reliability against attacks and perturbations, which is essential for sensitive and fragile EEG signals. Thus the interpretability and robustness of AI in EEG systems have attracted increasing attention, and their research has achieved great progress recently. However, there is still no survey covering recent advances in this field. In this paper, we present the first comprehensive survey and summarize the interpretable and robust AI techniques for EEG systems. Specifically, we first propose a taxonomy of interpretability by characterizing it ",
    "path": "papers/23/04/2304.10755.json",
    "total_tokens": 1073,
    "translated_title": "可解释和鲁棒的脑电图AI系统综述",
    "translated_abstract": "在人工智能时代，人工智能（AI）和脑电图（EEG）的密切耦合极大地推动了人机交互（HCI）技术的发展。相较于传统的EEG系统，基于AI的EEG系统的可解释性和鲁棒性变得尤为关键。可解释性能够阐释AI模型的内部工作机制，因此可以获得用户的信任。鲁棒性则反映了AI对抗攻击和扰动的可靠性，这对于敏感和脆弱的EEG信号来说是至关重要的。因此，EEG系统中AI的可解释性和鲁棒性受到越来越多的关注，并且最近的研究取得了巨大进展。然而，关于这一领域的最新进展仍然没有综述。本文首先提出了一种解释性分类法，通过特征化模型、数据和输出解释性，总结了脑电图系统中解释性和鲁棒的AI技术，并详细介绍了鲁棒AI的方法，包括对抗攻击和防御、迁移学习和不确定性建模。最后，我们讨论了这一领域未来的方向和面临的挑战。",
    "tldr": "这篇论文综述了近年来脑电图系统中可解释和鲁棒的AI技术的发展。其中，作者提出了解释性分类法，详细介绍了鲁棒AI的方法，包括对抗攻击和防御、迁移学习和不确定性建模，并讨论了未来的研究方向和挑战。",
    "en_tdlr": "This paper provides a comprehensive survey of recent developments in interpretable and robust AI techniques for EEG systems. The authors propose a taxonomy of interpretability, detail the methodologies of robust AI including adversarial attacks and defenses, transfer learning, and uncertainty modeling, and discuss future directions and challenges in the field."
}