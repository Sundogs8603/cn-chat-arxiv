{
    "title": "Lego-Features: Exporting modular encoder features for streaming and deliberation ASR. (arXiv:2304.00173v1 [cs.CL])",
    "abstract": "In end-to-end (E2E) speech recognition models, a representational tight-coupling inevitably emerges between the encoder and the decoder. We build upon recent work that has begun to explore building encoders with modular encoded representations, such that encoders and decoders from different models can be stitched together in a zero-shot manner without further fine-tuning. While previous research only addresses full-context speech models, we explore the problem in a streaming setting as well. Our framework builds on top of existing encoded representations, converting them to modular features, dubbed as Lego-Features, without modifying the pre-trained model. The features remain interchangeable when the model is retrained with distinct initializations. Though sparse, we show that the Lego-Features are powerful when tested with RNN-T or LAS decoders, maintaining high-quality downstream performance. They are also rich enough to represent the first-pass prediction during two-pass deliberatio",
    "link": "http://arxiv.org/abs/2304.00173",
    "context": "Title: Lego-Features: Exporting modular encoder features for streaming and deliberation ASR. (arXiv:2304.00173v1 [cs.CL])\nAbstract: In end-to-end (E2E) speech recognition models, a representational tight-coupling inevitably emerges between the encoder and the decoder. We build upon recent work that has begun to explore building encoders with modular encoded representations, such that encoders and decoders from different models can be stitched together in a zero-shot manner without further fine-tuning. While previous research only addresses full-context speech models, we explore the problem in a streaming setting as well. Our framework builds on top of existing encoded representations, converting them to modular features, dubbed as Lego-Features, without modifying the pre-trained model. The features remain interchangeable when the model is retrained with distinct initializations. Though sparse, we show that the Lego-Features are powerful when tested with RNN-T or LAS decoders, maintaining high-quality downstream performance. They are also rich enough to represent the first-pass prediction during two-pass deliberatio",
    "path": "papers/23/04/2304.00173.json",
    "total_tokens": 995,
    "translated_title": "Lego-Features：导出模块化编码器特征用于流式和决策ASR",
    "translated_abstract": "在端到端的语音识别模型中，编码器和解码器之间不可避免地出现了一种紧密耦合的表达。我们建立在最近开始探索构建带有模块化编码表示的编码器的工作之上，这样不同模型的编码器和解码器可以在零样本的情况下进行拼接，而无需进行进一步的微调。虽然之前的研究只涉及全上下文语音模型，但我们也在流式环境中探索了这个问题。我们的框架建立在现有编码表示之上，将其转换为模块化特征，称为Lego-Features，而不修改预训练模型。这些特征在用不同的初始化重新训练模型时仍然可以相互替换。尽管稀疏，我们展示了Lego-Features在使用RNN-T或LAS解码器进行测试时具有强大的性能，保持高质量的下游性能。它们也足够丰富，可以代表两个通道决策中的第一遍预测。",
    "tldr": "该论文介绍了一种称为Lego-Features的特征，将现有编码表示转换成模块化特征，而不修改预训练模型，在流式环境中也适用。这些特征性能强大，RNN-T或LAS解码器测试时保持高质量的下游性能，并足够丰富，可以代表两个通道决策中的第一遍预测。",
    "en_tdlr": "The paper presents Lego-Features, a method that converts existing encoded representations to modular features, without modifying the pre-trained model, which shows strong performance and can be used in streaming settings. These features are powerful and maintain high-quality downstream performance when tested with RNN-T or LAS decoder, and are rich enough to represent the first-pass prediction during two-pass deliberation."
}