{
    "title": "LTC-SE: Expanding the Potential of Liquid Time-Constant Neural Networks for Scalable AI and Embedded Systems. (arXiv:2304.08691v1 [cs.LG])",
    "abstract": "We present LTC-SE, an improved version of the Liquid Time-Constant (LTC) neural network algorithm originally proposed by Hasani et al. in 2021. This algorithm unifies the Leaky-Integrate-and-Fire (LIF) spiking neural network model with Continuous-Time Recurrent Neural Networks (CTRNNs), Neural Ordinary Differential Equations (NODEs), and bespoke Gated Recurrent Units (GRUs). The enhancements in LTC-SE focus on augmenting flexibility, compatibility, and code organization, targeting the unique constraints of embedded systems with limited computational resources and strict performance requirements. The updated code serves as a consolidated class library compatible with TensorFlow 2.x, offering comprehensive configuration options for LTCCell, CTRNN, NODE, and CTGRU classes. We evaluate LTC-SE against its predecessors, showcasing the advantages of our optimizations in user experience, Keras function compatibility, and code clarity. These refinements expand the applicability of liquid neural",
    "link": "http://arxiv.org/abs/2304.08691",
    "context": "Title: LTC-SE: Expanding the Potential of Liquid Time-Constant Neural Networks for Scalable AI and Embedded Systems. (arXiv:2304.08691v1 [cs.LG])\nAbstract: We present LTC-SE, an improved version of the Liquid Time-Constant (LTC) neural network algorithm originally proposed by Hasani et al. in 2021. This algorithm unifies the Leaky-Integrate-and-Fire (LIF) spiking neural network model with Continuous-Time Recurrent Neural Networks (CTRNNs), Neural Ordinary Differential Equations (NODEs), and bespoke Gated Recurrent Units (GRUs). The enhancements in LTC-SE focus on augmenting flexibility, compatibility, and code organization, targeting the unique constraints of embedded systems with limited computational resources and strict performance requirements. The updated code serves as a consolidated class library compatible with TensorFlow 2.x, offering comprehensive configuration options for LTCCell, CTRNN, NODE, and CTGRU classes. We evaluate LTC-SE against its predecessors, showcasing the advantages of our optimizations in user experience, Keras function compatibility, and code clarity. These refinements expand the applicability of liquid neural",
    "path": "papers/23/04/2304.08691.json",
    "total_tokens": 980,
    "translated_title": "LTC-SE: 扩展液态时常神经网络在可扩展人工智能和嵌入式系统中的潜力",
    "translated_abstract": "我们提出了LTC-SE，这是Hasani等人于2021年最初提出的液态时常神经网络算法的改进版本。该算法将漏电积分-火神经元模型与连续时间递归神经网络（CTRNN）、神经常微分方程（NODE）和量身定制的门控循环单元（GRU）统一起来。LTC-SE的增强版专注于增强灵活性、兼容性和代码组织，以满足具有有限计算资源和严格性能要求的嵌入式系统的独特约束。更新后的代码是一个与TensorFlow 2.x兼容的综合类库，为LTCCell、CTRNN、NODE和CTGRU类提供了全面的配置选项。我们通过对比以往的版本，展示了我们优化在用户体验、Keras函数兼容性和代码清晰度方面的优势，这些改进扩展了液态神经网络在可扩展人工智能和嵌入式系统中的适用性。",
    "tldr": "LTC-SE是一种液态时常神经网络算法，将多种神经元模型统一，其增强版专注于灵活性、兼容性和代码组织，满足嵌入式系统的性能要求，扩展了液态神经网络在可扩展人工智能和嵌入式系统中的适用性。",
    "en_tdlr": "LTC-SE is an improved version of the liquid time-constant neural network algorithm that unifies multiple neural models, enhancing flexibility, compatibility, and code organization to meet the performance requirements of embedded systems, expanding the applicability of liquid neural networks for scalable AI and embedded systems."
}