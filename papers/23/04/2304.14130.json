{
    "title": "Why not both? Complementing explanations with uncertainty, and the role of self-confidence in Human-AI collaboration. (arXiv:2304.14130v1 [cs.AI])",
    "abstract": "AI and ML models have already found many applications in critical domains, such as healthcare and criminal justice. However, fully automating such high-stakes applications can raise ethical or fairness concerns. Instead, in such cases, humans should be assisted by automated systems so that the two parties reach a joint decision, stemming out of their interaction. In this work we conduct an empirical study to identify how uncertainty estimates and model explanations affect users' reliance, understanding, and trust towards a model, looking for potential benefits of bringing the two together. Moreover, we seek to assess how users' behaviour is affected by their own self-confidence in their abilities to perform a certain task, while we also discuss how the latter may distort the outcome of an analysis based on agreement and switching percentages.",
    "link": "http://arxiv.org/abs/2304.14130",
    "context": "Title: Why not both? Complementing explanations with uncertainty, and the role of self-confidence in Human-AI collaboration. (arXiv:2304.14130v1 [cs.AI])\nAbstract: AI and ML models have already found many applications in critical domains, such as healthcare and criminal justice. However, fully automating such high-stakes applications can raise ethical or fairness concerns. Instead, in such cases, humans should be assisted by automated systems so that the two parties reach a joint decision, stemming out of their interaction. In this work we conduct an empirical study to identify how uncertainty estimates and model explanations affect users' reliance, understanding, and trust towards a model, looking for potential benefits of bringing the two together. Moreover, we seek to assess how users' behaviour is affected by their own self-confidence in their abilities to perform a certain task, while we also discuss how the latter may distort the outcome of an analysis based on agreement and switching percentages.",
    "path": "papers/23/04/2304.14130.json",
    "total_tokens": 839,
    "translated_title": "为什么不并存？不确定性解释及自信心在人工智能协作中的作用",
    "translated_abstract": "人工智能和机器学习模型已经在医疗保健和刑事司法等关键领域找到了许多应用。然而，完全自动化这些高风险应用可能引发道德或公平性的关注。因此，在这些情况下，应该由自动化系统来协助人类，使得双方通过交流达成共同决策。本文通过实证研究来确定不确定性估计和模型解释如何影响用户对模型的依赖性、理解力和信任度，并寻求将二者结合起来带来的潜在优势。此外，我们试图评估用户自信心对他们的任务执行能力的影响，同时讨论后者如何扭曲基于协议和切换百分比的分析结果。",
    "tldr": "本文研究了不确定性估计和模型解释如何影响用户对模型的依赖性、理解力和信任度以及自信心对他们的任务执行能力的影响，并提出了在人工智能协作中将两者结合起来的优势。",
    "en_tdlr": "This paper investigates the effects of uncertainty estimates and model explanations on users' reliance, understanding, and trust towards a model, and the impact of users' self-confidence on their task performance, while proposing the potential benefits of combining the two in Human-AI collaboration."
}