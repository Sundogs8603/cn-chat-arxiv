{
    "title": "CyFormer: Accurate State-of-Health Prediction of Lithium-Ion Batteries via Cyclic Attention. (arXiv:2304.08502v1 [cs.LG])",
    "abstract": "Predicting the State-of-Health (SoH) of lithium-ion batteries is a fundamental task of battery management systems on electric vehicles. It aims at estimating future SoH based on historical aging data. Most existing deep learning methods rely on filter-based feature extractors (e.g., CNN or Kalman filters) and recurrent time sequence models. Though efficient, they generally ignore cyclic features and the domain gap between training and testing batteries. To address this problem, we present CyFormer, a transformer-based cyclic time sequence model for SoH prediction. Instead of the conventional CNN-RNN structure, we adopt an encoder-decoder architecture. In the encoder, row-wise and column-wise attention blocks effectively capture intra-cycle and inter-cycle connections and extract cyclic features. In the decoder, the SoH queries cross-attend to these features to form the final predictions. We further utilize a transfer learning strategy to narrow the domain gap between the training and t",
    "link": "http://arxiv.org/abs/2304.08502",
    "context": "Title: CyFormer: Accurate State-of-Health Prediction of Lithium-Ion Batteries via Cyclic Attention. (arXiv:2304.08502v1 [cs.LG])\nAbstract: Predicting the State-of-Health (SoH) of lithium-ion batteries is a fundamental task of battery management systems on electric vehicles. It aims at estimating future SoH based on historical aging data. Most existing deep learning methods rely on filter-based feature extractors (e.g., CNN or Kalman filters) and recurrent time sequence models. Though efficient, they generally ignore cyclic features and the domain gap between training and testing batteries. To address this problem, we present CyFormer, a transformer-based cyclic time sequence model for SoH prediction. Instead of the conventional CNN-RNN structure, we adopt an encoder-decoder architecture. In the encoder, row-wise and column-wise attention blocks effectively capture intra-cycle and inter-cycle connections and extract cyclic features. In the decoder, the SoH queries cross-attend to these features to form the final predictions. We further utilize a transfer learning strategy to narrow the domain gap between the training and t",
    "path": "papers/23/04/2304.08502.json",
    "total_tokens": 985,
    "translated_abstract": "预测锂离子电池的健康状态是电动汽车电池管理系统的一个基本任务。它旨在基于历史老化数据估计未来的健康状态。大多数现有的深度学习方法依赖于基于滤波器的特征提取器（例如CNN或Kalman滤波器）和循环时间序列模型。虽然高效，但它们通常忽略了循环特征和训练和测试电池之间的领域差距。为了解决这个问题，我们提出了CyFormer，一种基于变压器的循环时间序列模型，用于SoH预测。我们采用了编码器-解码器架构，而不是传统的CNN-RNN结构。在编码器中，逐行和逐列的注意块有效地捕捉了循环内和循环间的连接并提取循环特征。在解码器中，SoH查询交叉参考这些特征以形成最终的预测。我们还利用转移学习策略来缩小训练和测试之间的领域差距。",
    "tldr": "CyFormer是一种基于变压器的循环时间序列模型，用于锂离子电池状态预测，通过逐行和逐列注意块和跨循环交叉参考预测未来的健康状态，缩小训练和测试之间的领域差距。",
    "en_tdlr": "CyFormer is a transformer-based cyclic time sequence model for predicting the state-of-health of lithium-ion batteries. It effectively captures cyclic features through row-wise and column-wise attention blocks and cross-attends to these features to form final predictions. Utilizing transfer learning strategy, it narrows down the domain gap between training and testing."
}