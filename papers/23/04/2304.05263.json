{
    "title": "Prompt Learning for News Recommendation. (arXiv:2304.05263v1 [cs.IR])",
    "abstract": "Some recent \\textit{news recommendation} (NR) methods introduce a Pre-trained Language Model (PLM) to encode news representation by following the vanilla pre-train and fine-tune paradigm with carefully-designed recommendation-specific neural networks and objective functions. Due to the inconsistent task objective with that of PLM, we argue that their modeling paradigm has not well exploited the abundant semantic information and linguistic knowledge embedded in the pre-training process. Recently, the pre-train, prompt, and predict paradigm, called \\textit{prompt learning}, has achieved many successes in natural language processing domain. In this paper, we make the first trial of this new paradigm to develop a \\textit{Prompt Learning for News Recommendation} (Prompt4NR) framework, which transforms the task of predicting whether a user would click a candidate news as a cloze-style mask-prediction task. Specifically, we design a series of prompt templates, including discrete, continuous, ",
    "link": "http://arxiv.org/abs/2304.05263",
    "context": "Title: Prompt Learning for News Recommendation. (arXiv:2304.05263v1 [cs.IR])\nAbstract: Some recent \\textit{news recommendation} (NR) methods introduce a Pre-trained Language Model (PLM) to encode news representation by following the vanilla pre-train and fine-tune paradigm with carefully-designed recommendation-specific neural networks and objective functions. Due to the inconsistent task objective with that of PLM, we argue that their modeling paradigm has not well exploited the abundant semantic information and linguistic knowledge embedded in the pre-training process. Recently, the pre-train, prompt, and predict paradigm, called \\textit{prompt learning}, has achieved many successes in natural language processing domain. In this paper, we make the first trial of this new paradigm to develop a \\textit{Prompt Learning for News Recommendation} (Prompt4NR) framework, which transforms the task of predicting whether a user would click a candidate news as a cloze-style mask-prediction task. Specifically, we design a series of prompt templates, including discrete, continuous, ",
    "path": "papers/23/04/2304.05263.json",
    "total_tokens": 927,
    "translated_title": "新闻推荐中的提示学习",
    "translated_abstract": "最近的一些新闻推荐（NR）方法通过引入预训练语言模型（PLM）来编码新闻表示，采用精心设计的推荐特定神经网络和目标函数来遵循香草预训练和微调范例。由于任务目标与PLM不一致，我们认为他们的建模范式未能充分利用预训练过程中嵌入的丰富语义信息和语言知识。最近，预训练，提示和预测范例在自然语言处理领域取得了许多成功。在本文中，我们第一次尝试使用这种新范例来开发一个新闻推荐中的Prompt Learning (Prompt4NR) 框架，将预测用户是否会点击候选新闻的任务转化为填空式掩码预测任务。具体来说，我们设计了一系列prompt模板，包括离散、连续...",
    "tldr": "本文介绍了在新闻推荐领域首次采用预训练，提示学习和预测范例来开发Prompt4NR框架的实验。该框架将预测点击候选新闻的任务转化为cloze-style填空式掩码预测任务，从而更好地利用预训练过程中的丰富语义信息和语言知识。",
    "en_tdlr": "This paper introduces the first experiment of using the pre-train, prompt, and predict paradigm to develop the Prompt4NR framework in news recommendation field. This framework transforms the task of predicting whether a user would click a candidate news as a cloze-style mask-prediction task, thus better utilizing the abundant semantic information and linguistic knowledge embedded in the pre-training process."
}