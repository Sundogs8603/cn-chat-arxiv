{
    "title": "Leveraging triplet loss for unsupervised action segmentation. (arXiv:2304.06403v1 [cs.CV])",
    "abstract": "In this paper, we propose a novel fully unsupervised framework that learns action representations suitable for the action segmentation task from the single input video itself, without requiring any training data. Our method is a deep metric learning approach rooted in a shallow network with a triplet loss operating on similarity distributions and a novel triplet selection strategy that effectively models temporal and semantic priors to discover actions in the new representational space. Under these circumstances, we successfully recover temporal boundaries in the learned action representations with higher quality compared with existing unsupervised approaches. The proposed method is evaluated on two widely used benchmark datasets for the action segmentation task and it achieves competitive performance by applying a generic clustering algorithm on the learned representations.",
    "link": "http://arxiv.org/abs/2304.06403",
    "context": "Title: Leveraging triplet loss for unsupervised action segmentation. (arXiv:2304.06403v1 [cs.CV])\nAbstract: In this paper, we propose a novel fully unsupervised framework that learns action representations suitable for the action segmentation task from the single input video itself, without requiring any training data. Our method is a deep metric learning approach rooted in a shallow network with a triplet loss operating on similarity distributions and a novel triplet selection strategy that effectively models temporal and semantic priors to discover actions in the new representational space. Under these circumstances, we successfully recover temporal boundaries in the learned action representations with higher quality compared with existing unsupervised approaches. The proposed method is evaluated on two widely used benchmark datasets for the action segmentation task and it achieves competitive performance by applying a generic clustering algorithm on the learned representations.",
    "path": "papers/23/04/2304.06403.json",
    "total_tokens": 841,
    "translated_title": "利用三元组损失进行无监督的动作分割",
    "translated_abstract": "本文提出了一种全新的无监督框架，可以从单个输入视频中学习适用于动作分割任务的动作表示，而无需任何训练数据。我们的方法是一种深度度量学习方法，基于操作相似度分布的三元组损失和一种有效建模时间和语义先验以在新的表示空间中发现动作的三元组选择策略。在这些条件下，与现有的无监督方法相比，我们成功地恢复了学习到的动作表示中的时间边界，质量更高。我们在两个广泛使用的动作分割任务的基准数据集上评估了所提出的方法，通过在学习的表示上应用通用聚类算法，实现了竞争性能。",
    "tldr": "本文提出了一种无监督的框架，可以在不需要任何训练数据的情况下，从单个输入视频中学习适用于动作分割任务的动作表示，并使用三元组选择策略和三元组损失来在新的表示空间中发现动作，相对于现有无监督方法实现了更好的时间边界恢复质量。",
    "en_tdlr": "This paper proposes an unsupervised framework that learns action representations from single input video without any training data for action segmentation task. The approach includes a triplet selection strategy and triplet loss to discover actions in new representational space, achieving higher quality temporal boundary recovery compared to existing unsupervised methods. The proposed method is evaluated on two benchmark datasets and achieves competitive performance using generic clustering algorithm on learned representations."
}