{
    "title": "VISION DIFFMASK: Faithful Interpretation of Vision Transformers with Differentiable Patch Masking. (arXiv:2304.06391v1 [cs.CV])",
    "abstract": "The lack of interpretability of the Vision Transformer may hinder its use in critical real-world applications despite its effectiveness. To overcome this issue, we propose a post-hoc interpretability method called VISION DIFFMASK, which uses the activations of the model's hidden layers to predict the relevant parts of the input that contribute to its final predictions. Our approach uses a gating mechanism to identify the minimal subset of the original input that preserves the predicted distribution over classes. We demonstrate the faithfulness of our method, by introducing a faithfulness task, and comparing it to other state-of-the-art attribution methods on CIFAR-10 and ImageNet-1K, achieving compelling results. To aid reproducibility and further extension of our work, we open source our implementation: https://github.com/AngelosNal/Vision-DiffMask",
    "link": "http://arxiv.org/abs/2304.06391",
    "context": "Title: VISION DIFFMASK: Faithful Interpretation of Vision Transformers with Differentiable Patch Masking. (arXiv:2304.06391v1 [cs.CV])\nAbstract: The lack of interpretability of the Vision Transformer may hinder its use in critical real-world applications despite its effectiveness. To overcome this issue, we propose a post-hoc interpretability method called VISION DIFFMASK, which uses the activations of the model's hidden layers to predict the relevant parts of the input that contribute to its final predictions. Our approach uses a gating mechanism to identify the minimal subset of the original input that preserves the predicted distribution over classes. We demonstrate the faithfulness of our method, by introducing a faithfulness task, and comparing it to other state-of-the-art attribution methods on CIFAR-10 and ImageNet-1K, achieving compelling results. To aid reproducibility and further extension of our work, we open source our implementation: https://github.com/AngelosNal/Vision-DiffMask",
    "path": "papers/23/04/2304.06391.json",
    "total_tokens": 792,
    "translated_title": "VISION DIFFMASK：具有可微分补丁掩码的视觉Transformer的忠实解释",
    "translated_abstract": "尽管具有高效性，但Vision Transformer缺乏可解释性可能会阻碍其在关键实际应用中的使用。为了克服这个问题，我们提出了一种名为VISION DIFFMASK的事后可解释性方法，该方法使用模型隐藏层的激活来预测对其最终预测有贡献的输入部分。我们的方法使用门控机制来识别保留预测类别分布的最小原始输入子集。我们通过引入忠实度任务并在CIFAR-10和ImageNet-1K上与其他最先进的归因方法进行比较，证明了我们方法的忠实度，取得了令人信服的结果。为了促进我们工作的再现性和进一步扩展，我们公开了我们的实现：https://github.com/AngelosNal/Vision-DiffMask",
    "tldr": "VISION DIFFMASK提出了一种可解释性的方法，通过使用门控机制识别最小输入子集来预测对其最终预测有贡献的输入部分。",
    "en_tdlr": "VISION DIFFMASK proposes an interpretable method that predicts the relevant parts of the input contributing to the final predictions by using a gating mechanism to identify the minimal input subset."
}