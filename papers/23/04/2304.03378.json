{
    "title": "Self-Supervised Video Similarity Learning. (arXiv:2304.03378v1 [cs.CV])",
    "abstract": "We introduce S$^2$VS, a video similarity learning approach with self-supervision. Self-Supervised Learning (SSL) is typically used to train deep models on a proxy task so as to have strong transferability on target tasks after fine-tuning. Here, in contrast to prior work, SSL is used to perform video similarity learning and address multiple retrieval and detection tasks at once with no use of labeled data. This is achieved by learning via instance-discrimination with task-tailored augmentations and the widely used InfoNCE loss together with an additional loss operating jointly on self-similarity and hard-negative similarity. We benchmark our method on tasks where video relevance is defined with varying granularity, ranging from video copies to videos depicting the same incident or event. We learn a single universal model that achieves state-of-the-art performance on all tasks, surpassing previously proposed methods that use labeled data. The code and pretrained models are publicly avai",
    "link": "http://arxiv.org/abs/2304.03378",
    "context": "Title: Self-Supervised Video Similarity Learning. (arXiv:2304.03378v1 [cs.CV])\nAbstract: We introduce S$^2$VS, a video similarity learning approach with self-supervision. Self-Supervised Learning (SSL) is typically used to train deep models on a proxy task so as to have strong transferability on target tasks after fine-tuning. Here, in contrast to prior work, SSL is used to perform video similarity learning and address multiple retrieval and detection tasks at once with no use of labeled data. This is achieved by learning via instance-discrimination with task-tailored augmentations and the widely used InfoNCE loss together with an additional loss operating jointly on self-similarity and hard-negative similarity. We benchmark our method on tasks where video relevance is defined with varying granularity, ranging from video copies to videos depicting the same incident or event. We learn a single universal model that achieves state-of-the-art performance on all tasks, surpassing previously proposed methods that use labeled data. The code and pretrained models are publicly avai",
    "path": "papers/23/04/2304.03378.json",
    "total_tokens": 862,
    "translated_title": "自监督视频相似性学习",
    "translated_abstract": "本文介绍了一种基于自监督学习的视频相似性学习方法S$^2$VS。与以往研究不同，这种方法使用自监督学习来实现视频相似性学习，并一次性解决多个检索和检测任务，而不需要使用带标签的数据。通过使用任务定制的增强和InfoNCE损失函数以及在自我相似性和硬负相似性上同时操作的附加损失函数，通过学习实例区分来实现。我们的方法在不同粒度下定义视频相关性的任务上进行了基准测试，涵盖了复制视频到描述相同事件的视频。我们学习了一个单一的通用模型，能够在所有任务上获得最新的表现，超越了以前使用标记数据的方法。代码和预训练模型是公开可用的。",
    "tldr": "本文提出了自监督视频相似性学习的方法S$^2$VS，该方法通过学习实例区分解决多个检索和检测任务，无需用到标注数据，并在各个任务上都达到了最新的性能。",
    "en_tdlr": "The paper introduces S$^2$VS, a self-supervised video similarity learning approach that addresses multiple retrieval and detection tasks without using labeled data. By learning through instance discrimination using task-tailored augmentations and the InfoNCE loss together with additional loss functions, the approach achieves state-of-the-art performance on all tasks with a single universal model."
}