{
    "title": "Lossless Adaptation of Pretrained Vision Models For Robotic Manipulation. (arXiv:2304.06600v1 [cs.LG])",
    "abstract": "Recent works have shown that large models pretrained on common visual learning tasks can provide useful representations for a wide range of specialized perception problems, as well as a variety of robotic manipulation tasks. While prior work on robotic manipulation has predominantly used frozen pretrained features, we demonstrate that in robotics this approach can fail to reach optimal performance, and that fine-tuning of the full model can lead to significantly better results. Unfortunately, fine-tuning disrupts the pretrained visual representation, and causes representational drift towards the fine-tuned task thus leading to a loss of the versatility of the original model. We introduce \"lossless adaptation\" to address this shortcoming of classical fine-tuning. We demonstrate that appropriate placement of our parameter efficient adapters can significantly reduce the performance gap between frozen pretrained representations and full end-to-end fine-tuning without changes to the origina",
    "link": "http://arxiv.org/abs/2304.06600",
    "context": "Title: Lossless Adaptation of Pretrained Vision Models For Robotic Manipulation. (arXiv:2304.06600v1 [cs.LG])\nAbstract: Recent works have shown that large models pretrained on common visual learning tasks can provide useful representations for a wide range of specialized perception problems, as well as a variety of robotic manipulation tasks. While prior work on robotic manipulation has predominantly used frozen pretrained features, we demonstrate that in robotics this approach can fail to reach optimal performance, and that fine-tuning of the full model can lead to significantly better results. Unfortunately, fine-tuning disrupts the pretrained visual representation, and causes representational drift towards the fine-tuned task thus leading to a loss of the versatility of the original model. We introduce \"lossless adaptation\" to address this shortcoming of classical fine-tuning. We demonstrate that appropriate placement of our parameter efficient adapters can significantly reduce the performance gap between frozen pretrained representations and full end-to-end fine-tuning without changes to the origina",
    "path": "papers/23/04/2304.06600.json",
    "total_tokens": 867,
    "translated_title": "无损调整预训练视觉模型以用于机器人操纵",
    "translated_abstract": "最近的研究表明，通常用于视觉学习的大型预训练模型可为各种专门的感知问题以及各种机器人操纵任务提供有用的表示。虽然机器人操纵的先前工作主要使用了冻结的预训练特征，但我们证明，在机器人领域，这种方法可能无法达到最佳性能，全模型微调可以带来显着更好的结果。不幸的是，微调会破坏预先训练的视觉表示，并导致代表性向微调任务的漂移，从而导致原始模型的多用性丢失。我们介绍了“无损适应”来解决经典微调的这个缺点。我们演示了适当放置我们的参数高效适配器可以显着减少性能差距，从而使冻结预训练表示与全端到端微调之间的差距缩小，而不改变原始模型。",
    "tldr": "本文提出了一种“无损适应”的方法，成功地将预训练视觉模型应用于机器人操纵中，并在不改变原始模型的情况下显著提高了性能。",
    "en_tdlr": "This paper proposes a \"lossless adaptation\" method that successfully applies pretrained vision models to robotic manipulation, significantly improving performance without altering the original model."
}