{
    "title": "Feudal Graph Reinforcement Learning. (arXiv:2304.05099v1 [cs.LG])",
    "abstract": "We focus on learning composable policies to control a variety of physical agents with possibly different structures. Among state-of-the-art methods, prominent approaches exploit graph-based representations and weight-sharing modular policies based on the message-passing framework. However, as shown by recent literature, message passing can create bottlenecks in information propagation and hinder global coordination. This drawback can become even more problematic in tasks where high-level planning is crucial. In fact, in similar scenarios, each modular policy - e.g., controlling a joint of a robot - would request to coordinate not only for basic locomotion but also achieve high-level goals, such as navigating a maze. A classical solution to avoid similar pitfalls is to resort to hierarchical decision-making. In this work, we adopt the Feudal Reinforcement Learning paradigm to develop agents where control actions are the outcome of a hierarchical (pyramidal) message-passing process. In t",
    "link": "http://arxiv.org/abs/2304.05099",
    "context": "Title: Feudal Graph Reinforcement Learning. (arXiv:2304.05099v1 [cs.LG])\nAbstract: We focus on learning composable policies to control a variety of physical agents with possibly different structures. Among state-of-the-art methods, prominent approaches exploit graph-based representations and weight-sharing modular policies based on the message-passing framework. However, as shown by recent literature, message passing can create bottlenecks in information propagation and hinder global coordination. This drawback can become even more problematic in tasks where high-level planning is crucial. In fact, in similar scenarios, each modular policy - e.g., controlling a joint of a robot - would request to coordinate not only for basic locomotion but also achieve high-level goals, such as navigating a maze. A classical solution to avoid similar pitfalls is to resort to hierarchical decision-making. In this work, we adopt the Feudal Reinforcement Learning paradigm to develop agents where control actions are the outcome of a hierarchical (pyramidal) message-passing process. In t",
    "path": "papers/23/04/2304.05099.json",
    "total_tokens": 775,
    "translated_abstract": "本论文关注如何学习可组合的策略来控制具有不同结构的各种物理代理。最先进的方法使用基于图的表示和基于信息传递框架的权重共享模块化策略。然而，如最近的文献所示，信息传递可能会在信息传递方面产生瓶颈并妨碍全局协调。在需要高层次规划的任务中，这个缺点可能变得更加棘手。在这项工作中，我们采用封建强化学习范例开发代理，在这些代理中，控制动作是分层（金字塔）信息传递过程的结果。",
    "tldr": "本文介绍了一种基于封建强化学习范例的代理方法来实现控制动作的分层信息传递过程，解决了权重共享模块化策略中信息传递瓶颈和全局协调问题。",
    "en_tdlr": "This paper presents an agent method based on the feudal reinforcement learning paradigm to achieve a hierarchical information passing process for control actions, solving the information propagation bottleneck and global coordination problems in weight-sharing modular policies."
}