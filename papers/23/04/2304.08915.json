{
    "title": "Differentiable Genetic Programming for High-dimensional Symbolic Regression. (arXiv:2304.08915v1 [cs.NE])",
    "abstract": "Symbolic regression (SR) is the process of discovering hidden relationships from data with mathematical expressions, which is considered an effective way to reach interpretable machine learning (ML). Genetic programming (GP) has been the dominator in solving SR problems. However, as the scale of SR problems increases, GP often poorly demonstrates and cannot effectively address the real-world high-dimensional problems. This limitation is mainly caused by the stochastic evolutionary nature of traditional GP in constructing the trees. In this paper, we propose a differentiable approach named DGP to construct GP trees towards high-dimensional SR for the first time. Specifically, a new data structure called differentiable symbolic tree is proposed to relax the discrete structure to be continuous, thus a gradient-based optimizer can be presented for the efficient optimization. In addition, a sampling method is proposed to eliminate the discrepancy caused by the above relaxation for valid sym",
    "link": "http://arxiv.org/abs/2304.08915",
    "context": "Title: Differentiable Genetic Programming for High-dimensional Symbolic Regression. (arXiv:2304.08915v1 [cs.NE])\nAbstract: Symbolic regression (SR) is the process of discovering hidden relationships from data with mathematical expressions, which is considered an effective way to reach interpretable machine learning (ML). Genetic programming (GP) has been the dominator in solving SR problems. However, as the scale of SR problems increases, GP often poorly demonstrates and cannot effectively address the real-world high-dimensional problems. This limitation is mainly caused by the stochastic evolutionary nature of traditional GP in constructing the trees. In this paper, we propose a differentiable approach named DGP to construct GP trees towards high-dimensional SR for the first time. Specifically, a new data structure called differentiable symbolic tree is proposed to relax the discrete structure to be continuous, thus a gradient-based optimizer can be presented for the efficient optimization. In addition, a sampling method is proposed to eliminate the discrepancy caused by the above relaxation for valid sym",
    "path": "papers/23/04/2304.08915.json",
    "total_tokens": 821,
    "translated_title": "高维符号回归的可微分遗传编程",
    "translated_abstract": "符号回归是从数学表达式中发现数据间隐藏关系的过程，被视为实现可解释的机器学习的有效方式。遗传编程是解决符号回归问题的主要方法。然而，随着符号回归问题规模的增加，传统的遗传编程的随机进化性质造成其在解决高维实际问题中表现不佳。本文提出了一种不同iable的方法——DGP，首次构建了用于高维符号回归的遗传编程树。具体而言，提出一种称为可微分符号树的新数据结构，将离散结构松弛到连续结构，因此可以提供基于梯度的优化器来实现高效优化。此外，提出了一种采样方法，用于消除由此松弛引起的不一致性，从而得到有效的符号树。",
    "tldr": "本文首次提出了DGP方法，利用可微分符号树构建遗传编程树，有效解决了高维符号回归问题。",
    "en_tdlr": "This paper proposes a differentiable approach called DGP for high-dimensional symbolic regression, which constructs genetic programming trees using a differentiable symbolic tree structure and eliminates the traditional GP's stochastic evolutionary limitations through a gradient-based optimizer, achieving effective solutions for high-dimensional symbolic regression problems."
}