{
    "title": "Radar-Camera Fusion for Object Detection and Semantic Segmentation in Autonomous Driving: A Comprehensive Review. (arXiv:2304.10410v1 [cs.CV])",
    "abstract": "Driven by deep learning techniques, perception technology in autonomous driving has developed rapidly in recent years. To achieve accurate and robust perception capabilities, autonomous vehicles are often equipped with multiple sensors, making sensor fusion a crucial part of the perception system. Among these fused sensors, radars and cameras enable a complementary and cost-effective perception of the surrounding environment regardless of lighting and weather conditions. This review aims to provide a comprehensive guideline for radar-camera fusion, particularly concentrating on perception tasks related to object detection and semantic segmentation. Based on the principles of the radar and camera sensors, we delve into the data processing process and representations, followed by an in-depth analysis and summary of radar-camera fusion datasets. In the review of methodologies in radar-camera fusion, we address interrogative questions, including \"why to fuse\", \"what to fuse\", \"where to fus",
    "link": "http://arxiv.org/abs/2304.10410",
    "context": "Title: Radar-Camera Fusion for Object Detection and Semantic Segmentation in Autonomous Driving: A Comprehensive Review. (arXiv:2304.10410v1 [cs.CV])\nAbstract: Driven by deep learning techniques, perception technology in autonomous driving has developed rapidly in recent years. To achieve accurate and robust perception capabilities, autonomous vehicles are often equipped with multiple sensors, making sensor fusion a crucial part of the perception system. Among these fused sensors, radars and cameras enable a complementary and cost-effective perception of the surrounding environment regardless of lighting and weather conditions. This review aims to provide a comprehensive guideline for radar-camera fusion, particularly concentrating on perception tasks related to object detection and semantic segmentation. Based on the principles of the radar and camera sensors, we delve into the data processing process and representations, followed by an in-depth analysis and summary of radar-camera fusion datasets. In the review of methodologies in radar-camera fusion, we address interrogative questions, including \"why to fuse\", \"what to fuse\", \"where to fus",
    "path": "papers/23/04/2304.10410.json",
    "total_tokens": 961,
    "translated_title": "自动驾驶中的雷达相机融合：综述与对比",
    "translated_abstract": "受深度学习技术推动，自动驾驶领域的感知技术近年来得到了快速发展。为了实现精准和稳健的感知能力，自动驾驶汽车通常配备多种传感器，使得传感器融合成为感知系统的关键部分。在这些传感器中，雷达和相机通过互补的方式，在任何光照和天气条件下都能够提供成本效益高的周围环境感知。本文旨在提供一份雷达相机融合的综合指南，特别关注与目标检测和语义分割相关的感知任务。基于雷达和相机传感器的原理，我们深入探讨数据处理过程和表示，接着详细分析和总结了雷达相机融合数据集的情况。在探讨雷达相机融合的方法学时，我们回答了许多问题，包括“为什么融合”，“融合什么”，“在哪里融合”",
    "tldr": "本文为雷达相机融合提供了一份综合指南，主要关注感知任务中的目标检测和语义分割。雷达和相机通过互补的方式提供成本效益高的周围环境感知，本综述深入探讨了数据处理和表示，详细总结了雷达相机融合数据集的情况，并解决了许多方法学问题。",
    "en_tdlr": "This review provides a comprehensive guideline for radar-camera fusion in object detection and semantic segmentation for autonomous driving. The complementary nature of radar and camera sensors enables cost-effective perception in any lighting and weather conditions. The review delves into data processing and representations, analyzes and summarizes radar-camera fusion datasets, and addresses important methodological questions."
}