{
    "title": "Centralized control for multi-agent RL in a complex Real-Time-Strategy game. (arXiv:2304.13004v1 [cs.AI])",
    "abstract": "Multi-agent Reinforcement learning (MARL) studies the behaviour of multiple learning agents that coexist in a shared environment. MARL is more challenging than single-agent RL because it involves more complex learning dynamics: the observations and rewards of each agent are functions of all other agents. In the context of MARL, Real-Time Strategy (RTS) games represent very challenging environments where multiple players interact simultaneously and control many units of different natures all at once. In fact, RTS games are so challenging for the current RL methods, that just being able to tackle them with RL is interesting. This project provides the end-to-end experience of applying RL in the Lux AI v2 Kaggle competition, where competitors design agents to control variable-sized fleets of units and tackle a multi-variable optimization, resource gathering, and allocation problem in a 1v1 scenario against other competitors. We use a centralized approach for training the RL agents, and rep",
    "link": "http://arxiv.org/abs/2304.13004",
    "context": "Title: Centralized control for multi-agent RL in a complex Real-Time-Strategy game. (arXiv:2304.13004v1 [cs.AI])\nAbstract: Multi-agent Reinforcement learning (MARL) studies the behaviour of multiple learning agents that coexist in a shared environment. MARL is more challenging than single-agent RL because it involves more complex learning dynamics: the observations and rewards of each agent are functions of all other agents. In the context of MARL, Real-Time Strategy (RTS) games represent very challenging environments where multiple players interact simultaneously and control many units of different natures all at once. In fact, RTS games are so challenging for the current RL methods, that just being able to tackle them with RL is interesting. This project provides the end-to-end experience of applying RL in the Lux AI v2 Kaggle competition, where competitors design agents to control variable-sized fleets of units and tackle a multi-variable optimization, resource gathering, and allocation problem in a 1v1 scenario against other competitors. We use a centralized approach for training the RL agents, and rep",
    "path": "papers/23/04/2304.13004.json",
    "total_tokens": 983,
    "translated_title": "在复杂的实时战略游戏中进行多智能体强化学习的集中化控制",
    "translated_abstract": "多智能体强化学习(MARL)研究多个相互作用的学习智能体在共享环境下的行为。与单一智能体强化学习相比，MARL具有更加复杂的学习动态：每个智能体的观察和奖励都是其他所有智能体的函数。在MARL的背景下，实时战略(RTS)游戏是非常具有挑战性的环境，其中多个玩家同时互动并同时控制不同性质的多个单位。实际上，对于当前的RL方法来说，RTS游戏如此具有挑战性，以至于只是能够用RL应对它们已经很有意义了。本项目提供了在Lux AI v2 Kaggle比赛中应用RL的端到端体验，参赛者设计能够控制可变大小舰队单位并在1v1情况下面对其他参赛者的多变量优化、资源收集和分配问题。我们使用集中式方法来训练RL智能体，并使用全局视图表示游戏状态。我们的方法优于使用独立代理和分散训练的标准基线方法。",
    "tldr": "本文介绍了在Lux AI v2 Kaggle比赛中使用集中式方法来训练RL智能体，在复杂的实时战略游戏中实现多智能体强化学习，并成功提高了性能。",
    "en_tdlr": "This paper introduces the use of a centralized approach to train RL agents in Lux AI v2 Kaggle competition, achieving multi-agent reinforcement learning in a complex Real-Time-Strategy game and demonstrating improved performance compared to the standard baseline methods using independent agents and decentralized training."
}