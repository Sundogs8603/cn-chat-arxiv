{
    "title": "RobCaps: Evaluating the Robustness of Capsule Networks against Affine Transformations and Adversarial Attacks. (arXiv:2304.03973v1 [cs.LG])",
    "abstract": "Capsule Networks (CapsNets) are able to hierarchically preserve the pose relationships between multiple objects for image classification tasks. Other than achieving high accuracy, another relevant factor in deploying CapsNets in safety-critical applications is the robustness against input transformations and malicious adversarial attacks.  In this paper, we systematically analyze and evaluate different factors affecting the robustness of CapsNets, compared to traditional Convolutional Neural Networks (CNNs). Towards a comprehensive comparison, we test two CapsNet models and two CNN models on the MNIST, GTSRB, and CIFAR10 datasets, as well as on the affine-transformed versions of such datasets. With a thorough analysis, we show which properties of these architectures better contribute to increasing the robustness and their limitations. Overall, CapsNets achieve better robustness against adversarial examples and affine transformations, compared to a traditional CNN with a similar number ",
    "link": "http://arxiv.org/abs/2304.03973",
    "context": "Title: RobCaps: Evaluating the Robustness of Capsule Networks against Affine Transformations and Adversarial Attacks. (arXiv:2304.03973v1 [cs.LG])\nAbstract: Capsule Networks (CapsNets) are able to hierarchically preserve the pose relationships between multiple objects for image classification tasks. Other than achieving high accuracy, another relevant factor in deploying CapsNets in safety-critical applications is the robustness against input transformations and malicious adversarial attacks.  In this paper, we systematically analyze and evaluate different factors affecting the robustness of CapsNets, compared to traditional Convolutional Neural Networks (CNNs). Towards a comprehensive comparison, we test two CapsNet models and two CNN models on the MNIST, GTSRB, and CIFAR10 datasets, as well as on the affine-transformed versions of such datasets. With a thorough analysis, we show which properties of these architectures better contribute to increasing the robustness and their limitations. Overall, CapsNets achieve better robustness against adversarial examples and affine transformations, compared to a traditional CNN with a similar number ",
    "path": "papers/23/04/2304.03973.json",
    "total_tokens": 930,
    "translated_title": "RobCaps: 评估胶囊网络在仿射变换和对抗性攻击中的鲁棒性",
    "translated_abstract": "胶囊网络(CapsNet)能够在图像分类任务中分层保持多个对象之间的姿态关系。除了实现高准确性外，在安全关键的应用中部署CapsNet的另一个相关因素是其对输入变换和恶意对抗性攻击的鲁棒性。在本文中，我们系统地分析和评估了影响CapsNet鲁棒性的不同因素，与传统的卷积神经网络(CNNs)进行了比较。为了进行全面比较，我们在MNIST，GTSRB和CIFAR10数据集上测试了两个CapsNet模型和两个CNN模型，以及这些数据集的仿射变换版本。通过深入分析，我们展示了这些架构的哪些特性更有助于增加其鲁棒性以及其局限性。总体而言，与类似数量的传统CNN相比，CapsNet实现了更好的对抗示例和仿射变换鲁棒性。",
    "tldr": "本文评估了CapsNet在仿射变换和对抗性攻击方面的鲁棒性。在MNIST，GTSRB和CIFAR10数据集上的测试结果显示，与传统CNN相比，CapsNet实现了更好的对抗示例和仿射变换鲁棒性。",
    "en_tdlr": "This paper evaluates the robustness of Capsule Networks (CapsNets) against affine transformations and adversarial attacks. The testing on MNIST, GTSRB, and CIFAR10 datasets shows that CapsNets achieve better robustness against adversarial examples and affine transformations compared to traditional CNNs."
}