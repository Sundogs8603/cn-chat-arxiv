{
    "title": "Development of a Trust-Aware User Simulator for Statistical Proactive Dialog Modeling in Human-AI Teams. (arXiv:2304.11913v2 [cs.AI] UPDATED)",
    "abstract": "The concept of a Human-AI team has gained increasing attention in recent years. For effective collaboration between humans and AI teammates, proactivity is crucial for close coordination and effective communication. However, the design of adequate proactivity for AI-based systems to support humans is still an open question and a challenging topic. In this paper, we present the development of a corpus-based user simulator for training and testing proactive dialog policies. The simulator incorporates informed knowledge about proactive dialog and its effect on user trust and simulates user behavior and personal information, including socio-demographic features and personality traits. Two different simulation approaches were compared, and a task-step-based approach yielded better overall results due to enhanced modeling of sequential dependencies. This research presents a promising avenue for exploring and evaluating appropriate proactive strategies in a dialog game setting for improving H",
    "link": "http://arxiv.org/abs/2304.11913",
    "context": "Title: Development of a Trust-Aware User Simulator for Statistical Proactive Dialog Modeling in Human-AI Teams. (arXiv:2304.11913v2 [cs.AI] UPDATED)\nAbstract: The concept of a Human-AI team has gained increasing attention in recent years. For effective collaboration between humans and AI teammates, proactivity is crucial for close coordination and effective communication. However, the design of adequate proactivity for AI-based systems to support humans is still an open question and a challenging topic. In this paper, we present the development of a corpus-based user simulator for training and testing proactive dialog policies. The simulator incorporates informed knowledge about proactive dialog and its effect on user trust and simulates user behavior and personal information, including socio-demographic features and personality traits. Two different simulation approaches were compared, and a task-step-based approach yielded better overall results due to enhanced modeling of sequential dependencies. This research presents a promising avenue for exploring and evaluating appropriate proactive strategies in a dialog game setting for improving H",
    "path": "papers/23/04/2304.11913.json",
    "total_tokens": 902,
    "translated_title": "开发一种信任感感知的用户模拟器，用于统计学的主动式对话建模中的人工智能团队",
    "translated_abstract": "近年来，人工智能团队的概念引起了越来越多的关注。为了实现人类和人工智能队友之间的有效协作，主动性对于紧密协调和有效沟通至关重要。然而，如何为基于人工智能的系统设计适当的主动性仍然是一个开放性问题和具有挑战性的主题。本文介绍了一个基于语料库的用户模拟器的开发，用于训练和测试主动式对话策略。该模拟器以有关主动式对话及其对用户信任度的知识为基础，模拟用户行为和个人信息，包括社会人口特征和人格特征。对比了两种不同的模拟方法，基于任务步骤的方法由于加强了顺序依赖模型，获得了更好的总体结果。这项研究为探索和评估在对话游戏环境中改善人工智能团队表现的适当主动策略提供了一个有前途的途径。",
    "tldr": "本文开发了一种用户模拟器来训练和测试主动对话策略，提供了一种探索和评估人工智能团队表现的适当主动策略的途径。",
    "en_tdlr": "This paper developed a user simulator for training and testing proactive dialog policies to explore and evaluate appropriate proactive strategies for improving human-AI team performance in a dialog game setting."
}