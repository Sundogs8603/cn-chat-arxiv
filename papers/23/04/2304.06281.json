{
    "title": "Model-based Dynamic Shielding for Safe and Efficient Multi-Agent Reinforcement Learning. (arXiv:2304.06281v1 [cs.LG])",
    "abstract": "Multi-Agent Reinforcement Learning (MARL) discovers policies that maximize reward but do not have safety guarantees during the learning and deployment phases. Although shielding with Linear Temporal Logic (LTL) is a promising formal method to ensure safety in single-agent Reinforcement Learning (RL), it results in conservative behaviors when scaling to multi-agent scenarios. Additionally, it poses computational challenges for synthesizing shields in complex multi-agent environments. This work introduces Model-based Dynamic Shielding (MBDS) to support MARL algorithm design. Our algorithm synthesizes distributive shields, which are reactive systems running in parallel with each MARL agent, to monitor and rectify unsafe behaviors. The shields can dynamically split, merge, and recompute based on agents' states. This design enables efficient synthesis of shields to monitor agents in complex environments without coordination overheads. We also propose an algorithm to synthesize shields witho",
    "link": "http://arxiv.org/abs/2304.06281",
    "context": "Title: Model-based Dynamic Shielding for Safe and Efficient Multi-Agent Reinforcement Learning. (arXiv:2304.06281v1 [cs.LG])\nAbstract: Multi-Agent Reinforcement Learning (MARL) discovers policies that maximize reward but do not have safety guarantees during the learning and deployment phases. Although shielding with Linear Temporal Logic (LTL) is a promising formal method to ensure safety in single-agent Reinforcement Learning (RL), it results in conservative behaviors when scaling to multi-agent scenarios. Additionally, it poses computational challenges for synthesizing shields in complex multi-agent environments. This work introduces Model-based Dynamic Shielding (MBDS) to support MARL algorithm design. Our algorithm synthesizes distributive shields, which are reactive systems running in parallel with each MARL agent, to monitor and rectify unsafe behaviors. The shields can dynamically split, merge, and recompute based on agents' states. This design enables efficient synthesis of shields to monitor agents in complex environments without coordination overheads. We also propose an algorithm to synthesize shields witho",
    "path": "papers/23/04/2304.06281.json",
    "total_tokens": 1045,
    "translated_title": "模型驱动的动态盾型保障用于安全和高效的多智能体强化学习",
    "translated_abstract": "多智能体强化学习(MARL)发现最大化回报的策略，但在学习和部署阶段没有安全保障。虽然线性时间逻辑(LTL)的屏蔽是确保单智能体强化学习(RL)安全的有前途的正式方法，但它在扩展到多智能体场景时会导致保守行为。此外，在复杂多智能体环境中合成屏蔽存在计算挑战。本文介绍了MBDS以支持MARL算法设计。我们的算法合成分布式屏蔽器，这些屏蔽器是与每个MARL智能体并行运行的反应系统，用于监控和纠正不安全的行为。这种设计使得在没有协调开销的情况下，能够有效合成屏蔽器以监视复杂环境中的智能体。我们还提出一种算法，在不知道环境的完整转换函数的情况下合成屏障，并展示我们的方法在交通信号控制任务和无人机巡逻任务中优于LTL屏蔽。",
    "tldr": "本论文介绍了模型驱动的动态屏蔽设计用于多智能体强化学习中的安全保障，屏蔽器能够动态分割、合并和重新计算智能体状态，同时支持更加高效的合成屏蔽器以监控复杂环境中的智能体。",
    "en_tdlr": "This paper proposes a model-based dynamic shielding (MBDS) to provide safe and efficient multi-agent reinforcement learning (MARL) algorithm design by synthesizing distributive shields running parallel with each MARL agent to monitor and correct unsafe behaviors. The algorithm can dynamically split, merge, and recompute based on agents' states, and achieves better performance than linear temporal logic (LTL) shielding in traffic signal control and UAV patrolling tasks."
}