{
    "title": "Exploring the Connection between Robust and Generative Models. (arXiv:2304.04033v1 [cs.LG])",
    "abstract": "We offer a study that connects robust discriminative classifiers trained with adversarial training (AT) with generative modeling in the form of Energy-based Models (EBM). We do so by decomposing the loss of a discriminative classifier and showing that the discriminative model is also aware of the input data density. Though a common assumption is that adversarial points leave the manifold of the input data, our study finds out that, surprisingly, untargeted adversarial points in the input space are very likely under the generative model hidden inside the discriminative classifier -- have low energy in the EBM. We present two evidence: untargeted attacks are even more likely than the natural data and their likelihood increases as the attack strength increases. This allows us to easily detect them and craft a novel attack called High-Energy PGD that fools the classifier yet has energy similar to the data set.",
    "link": "http://arxiv.org/abs/2304.04033",
    "context": "Title: Exploring the Connection between Robust and Generative Models. (arXiv:2304.04033v1 [cs.LG])\nAbstract: We offer a study that connects robust discriminative classifiers trained with adversarial training (AT) with generative modeling in the form of Energy-based Models (EBM). We do so by decomposing the loss of a discriminative classifier and showing that the discriminative model is also aware of the input data density. Though a common assumption is that adversarial points leave the manifold of the input data, our study finds out that, surprisingly, untargeted adversarial points in the input space are very likely under the generative model hidden inside the discriminative classifier -- have low energy in the EBM. We present two evidence: untargeted attacks are even more likely than the natural data and their likelihood increases as the attack strength increases. This allows us to easily detect them and craft a novel attack called High-Energy PGD that fools the classifier yet has energy similar to the data set.",
    "path": "papers/23/04/2304.04033.json",
    "total_tokens": 875,
    "translated_title": "探究鲁棒性模型与生成模型之间的联系",
    "translated_abstract": "本研究将通过分解鲁棒性判别分类器的损失函数来探究鲁棒性判别分类器与能量基模型(EBM)形式的生成模型之间的联系。我们发现，尽管常见的假设是对抗点离开了输入数据的流形，但是在输入空间中，非定向对抗点非常可能在鉴别性模型中隐含的生成模型中拥有低能量。我们提出了两个证据:非定向攻击的概率甚至比自然数据还要高，并且随着攻击强度的增加，其概率也会增加。这使我们能够轻松地检测它们并设计一种名为高能量PGD的新攻击，能够欺骗分类器但具有与数据集相似的能量。",
    "tldr": "本文探究鲁棒性判别分类器与生成模型之间的联系，并发现在输入空间中，非定向对抗点非常可能在鉴别性模型中隐含的生成模型中拥有低能量，提出了一种名为高能量PGD的新攻击。",
    "en_tdlr": "This study explores the connection between robust discriminative classifiers and Energy-based Models (EBM) as generative models, and finds that untargeted adversarial points are very likely to have low energy in the EBM hidden inside the discriminative classifier. This allows for the detection and crafting of a novel attack called High-Energy PGD that fools the classifier yet has energy similar to the dataset."
}