{
    "title": "PCR: Proxy-based Contrastive Replay for Online Class-Incremental Continual Learning. (arXiv:2304.04408v1 [cs.CV])",
    "abstract": "Online class-incremental continual learning is a specific task of continual learning. It aims to continuously learn new classes from data stream and the samples of data stream are seen only once, which suffers from the catastrophic forgetting issue, i.e., forgetting historical knowledge of old classes. Existing replay-based methods effectively alleviate this issue by saving and replaying part of old data in a proxy-based or contrastive-based replay manner. Although these two replay manners are effective, the former would incline to new classes due to class imbalance issues, and the latter is unstable and hard to converge because of the limited number of samples. In this paper, we conduct a comprehensive analysis of these two replay manners and find that they can be complementary. Inspired by this finding, we propose a novel replay-based method called proxy-based contrastive replay (PCR). The key operation is to replace the contrastive samples of anchors with corresponding proxies in th",
    "link": "http://arxiv.org/abs/2304.04408",
    "context": "Title: PCR: Proxy-based Contrastive Replay for Online Class-Incremental Continual Learning. (arXiv:2304.04408v1 [cs.CV])\nAbstract: Online class-incremental continual learning is a specific task of continual learning. It aims to continuously learn new classes from data stream and the samples of data stream are seen only once, which suffers from the catastrophic forgetting issue, i.e., forgetting historical knowledge of old classes. Existing replay-based methods effectively alleviate this issue by saving and replaying part of old data in a proxy-based or contrastive-based replay manner. Although these two replay manners are effective, the former would incline to new classes due to class imbalance issues, and the latter is unstable and hard to converge because of the limited number of samples. In this paper, we conduct a comprehensive analysis of these two replay manners and find that they can be complementary. Inspired by this finding, we propose a novel replay-based method called proxy-based contrastive replay (PCR). The key operation is to replace the contrastive samples of anchors with corresponding proxies in th",
    "path": "papers/23/04/2304.04408.json",
    "total_tokens": 1031,
    "translated_title": "PCR: 基于代理的对比式回放在在线类增量连续学习中的应用",
    "translated_abstract": "在线类增量连续学习是连续学习中的一项特定任务。它旨在从数据流中不断学习新的类别，但数据流中的样本仅需观察一次，这容易导致历史类别的知识遗忘问题。现有的基于回放的方法通过以代理为基础或以对比为基础的回放方式有效地缓解了这一问题。尽管这两种回放方式是有效的，但前者会因类别不平衡问题而倾向于新类，后者则由于样本数量有限而不稳定且难以收敛。本文对这两种回放方式进行了全面的分析，发现它们可以互补。在此基础上，我们提出了一种新的回放-based方法，称为基于代理的对比式回放（PCR）。关键操作是将锚定点的对比样本替换为相应代理的对比样本。具体来说，设计并自适应地选择两种代理，即旧代理和新代理，以稳定训练并缓解类别不平衡问题。实验证明，PCR在两个视觉数据集上显著优于现有方法。",
    "tldr": "本文提出了一种名为PCR的基于代理的对比式回放方法，它能够有效地解决在线类增量连续学习中的历史知识遗忘问题。经实验证明，在两个视觉数据集上，PCR能够显著优于现有方法。",
    "en_tdlr": "This paper proposes a novel replay-based method called PCR, which aims to alleviate catastrophic forgetting in online class-incremental continual learning. Two types of proxies, i.e., old proxies and new proxies, are adaptively designed and selected to stabilize training and alleviate class imbalance issues. Empirical studies show that PCR outperforms existing methods on two visual datasets."
}