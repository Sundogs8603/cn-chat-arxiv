{
    "title": "\"HOT\" ChatGPT: The promise of ChatGPT in detecting and discriminating hateful, offensive, and toxic comments on social media. (arXiv:2304.10619v1 [cs.CL])",
    "abstract": "Harmful content is pervasive on social media, poisoning online communities and negatively impacting participation. A common approach to address this issue is to develop detection models that rely on human annotations. However, the tasks required to build such models expose annotators to harmful and offensive content and may require significant time and cost to complete. Generative AI models have the potential to understand and detect harmful content. To investigate this potential, we used ChatGPT and compared its performance with MTurker annotations for three frequently discussed concepts related to harmful content: Hateful, Offensive, and Toxic (HOT). We designed five prompts to interact with ChatGPT and conducted four experiments eliciting HOT classifications. Our results show that ChatGPT can achieve an accuracy of approximately 80% when compared to MTurker annotations. Specifically, the model displays a more consistent classification for non-HOT comments than HOT comments compared ",
    "link": "http://arxiv.org/abs/2304.10619",
    "context": "Title: \"HOT\" ChatGPT: The promise of ChatGPT in detecting and discriminating hateful, offensive, and toxic comments on social media. (arXiv:2304.10619v1 [cs.CL])\nAbstract: Harmful content is pervasive on social media, poisoning online communities and negatively impacting participation. A common approach to address this issue is to develop detection models that rely on human annotations. However, the tasks required to build such models expose annotators to harmful and offensive content and may require significant time and cost to complete. Generative AI models have the potential to understand and detect harmful content. To investigate this potential, we used ChatGPT and compared its performance with MTurker annotations for three frequently discussed concepts related to harmful content: Hateful, Offensive, and Toxic (HOT). We designed five prompts to interact with ChatGPT and conducted four experiments eliciting HOT classifications. Our results show that ChatGPT can achieve an accuracy of approximately 80% when compared to MTurker annotations. Specifically, the model displays a more consistent classification for non-HOT comments than HOT comments compared ",
    "path": "papers/23/04/2304.10619.json",
    "total_tokens": 887,
    "translated_title": "“HOT” ChatGPT：ChatGPT在社交媒体上检测和识别令人讨厌、令人不悦和有害评论的潜力",
    "translated_abstract": "社交媒体上危害性内容的存在对在线社区和参与产生了负面影响。解决这个问题的方法之一是开发需要人工标注的检测模型。然而，构建这样的模型需要曝露标注者于有害和冒犯性内容的任务，可能需要大量的时间和成本。生成式AI模型有潜力理解和检测有害内容。为了研究这个潜力，我们使用ChatGPT，并将其性能与MTurker注释进行了比较，这些注释与有害内容相关的三个经常讨论的概念：令人讨厌、令人不悦和有害（HOT）。我们设计了五个提示与ChatGPT进行交互，并进行了四个实验来引出HOT的分类。我们的结果显示，与MTurker注释相比，ChatGPT可以达到约80％的准确性。具体而言，与HOT评论相比，模型对非HOT评论的分类更加一致。",
    "tldr": "本研究使用ChatGPT探究了生成式AI模型检测社交媒体上有害评论的可行性，结果显示ChatGPT可以达到约80%的准确性。",
    "en_tdlr": "This study explores the feasibility of generative AI models in detecting harmful comments on social media using ChatGPT, achieving an accuracy of approximately 80%."
}