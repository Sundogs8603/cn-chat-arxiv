{
    "title": "UAV Obstacle Avoidance by Human-in-the-Loop Reinforcement in Arbitrary 3D Environment. (arXiv:2304.05959v1 [cs.RO])",
    "abstract": "This paper focuses on the continuous control of the unmanned aerial vehicle (UAV) based on a deep reinforcement learning method for a large-scale 3D complex environment. The purpose is to make the UAV reach any target point from a certain starting point, and the flying height and speed are variable during navigation. In this work, we propose a deep reinforcement learning (DRL)-based method combined with human-in-the-loop, which allows the UAV to avoid obstacles automatically during flying. We design multiple reward functions based on the relevant domain knowledge to guide UAV navigation. The role of human-in-the-loop is to dynamically change the reward function of the UAV in different situations to suit the obstacle avoidance of the UAV better. We verify the success rate and average step size on urban, rural, and forest scenarios, and the experimental results show that the proposed method can reduce the training convergence time and improve the efficiency and accuracy of navigation tas",
    "link": "http://arxiv.org/abs/2304.05959",
    "context": "Title: UAV Obstacle Avoidance by Human-in-the-Loop Reinforcement in Arbitrary 3D Environment. (arXiv:2304.05959v1 [cs.RO])\nAbstract: This paper focuses on the continuous control of the unmanned aerial vehicle (UAV) based on a deep reinforcement learning method for a large-scale 3D complex environment. The purpose is to make the UAV reach any target point from a certain starting point, and the flying height and speed are variable during navigation. In this work, we propose a deep reinforcement learning (DRL)-based method combined with human-in-the-loop, which allows the UAV to avoid obstacles automatically during flying. We design multiple reward functions based on the relevant domain knowledge to guide UAV navigation. The role of human-in-the-loop is to dynamically change the reward function of the UAV in different situations to suit the obstacle avoidance of the UAV better. We verify the success rate and average step size on urban, rural, and forest scenarios, and the experimental results show that the proposed method can reduce the training convergence time and improve the efficiency and accuracy of navigation tas",
    "path": "papers/23/04/2304.05959.json",
    "total_tokens": 864,
    "translated_title": "无人机在任意三维环境中采用人机交互增强避障方法",
    "translated_abstract": "本文探讨了基于深度强化学习的无人机控制方法，旨在在大规模三维复杂环境中使 UAV 达到任意目标点，且在导航过程中飞行高度和速度均可变。我们提出了一种结合人机交互的 DRL 方法，可以使 UAV 在飞行过程中自动避开障碍物。同时，我们设计了多个基于相关领域知识的奖励函数，以指导 UAV 导航。人机交互的作用是在不同情况下动态改变 UAV 的奖励函数，以更好地适应避障。我们在城市、农村和森林场景中验证了成功率和平均步长，实验结果表明该方法可减少训练收敛时间，提高导航任务的效率和准确性。",
    "tldr": "本文提出了一种基于深度强化学习和人机交互的避障方法，可在大规模三维复杂环境中控制无人机实现任意目标点的导航任务。"
}