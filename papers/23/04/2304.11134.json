{
    "title": "Plug-and-Play split Gibbs sampler: embedding deep generative priors in Bayesian inference. (arXiv:2304.11134v1 [stat.ML])",
    "abstract": "This paper introduces a stochastic plug-and-play (PnP) sampling algorithm that leverages variable splitting to efficiently sample from a posterior distribution. The algorithm based on split Gibbs sampling (SGS) draws inspiration from the alternating direction method of multipliers (ADMM). It divides the challenging task of posterior sampling into two simpler sampling problems. The first problem depends on the likelihood function, while the second is interpreted as a Bayesian denoising problem that can be readily carried out by a deep generative model. Specifically, for an illustrative purpose, the proposed method is implemented in this paper using state-of-the-art diffusion-based generative models. Akin to its deterministic PnP-based counterparts, the proposed method exhibits the great advantage of not requiring an explicit choice of the prior distribution, which is rather encoded into a pre-trained generative model. However, unlike optimization methods (e.g., PnP-ADMM) which generally",
    "link": "http://arxiv.org/abs/2304.11134",
    "context": "Title: Plug-and-Play split Gibbs sampler: embedding deep generative priors in Bayesian inference. (arXiv:2304.11134v1 [stat.ML])\nAbstract: This paper introduces a stochastic plug-and-play (PnP) sampling algorithm that leverages variable splitting to efficiently sample from a posterior distribution. The algorithm based on split Gibbs sampling (SGS) draws inspiration from the alternating direction method of multipliers (ADMM). It divides the challenging task of posterior sampling into two simpler sampling problems. The first problem depends on the likelihood function, while the second is interpreted as a Bayesian denoising problem that can be readily carried out by a deep generative model. Specifically, for an illustrative purpose, the proposed method is implemented in this paper using state-of-the-art diffusion-based generative models. Akin to its deterministic PnP-based counterparts, the proposed method exhibits the great advantage of not requiring an explicit choice of the prior distribution, which is rather encoded into a pre-trained generative model. However, unlike optimization methods (e.g., PnP-ADMM) which generally",
    "path": "papers/23/04/2304.11134.json",
    "total_tokens": 1038,
    "translated_title": "插拔式分割 Gibbs 采样: 在贝叶斯推断中嵌入深度生成先验",
    "translated_abstract": "本文介绍了一种基于变量分离的随机插拔式(Plug-and-Play)采样算法，以有效地从后验分布中采样。该算法基于分割Gibbs采样(split Gibbs sampling, SGS)，灵感来自于交替方向乘子法(alternating direction method of multipliers, ADMM)。它将后验采样的挑战任务分为两个较简单的采样问题。第一个问题依赖于似然函数，而第二个问题被解释为一个贝叶斯降噪问题，可以通过深度生成模型轻松地完成。具体而言，为了说明目的，本文所提出的方法使用了最先进的基于扩散的生成模型进行了实现。与其确定性的插拔式(Plug-and-Play)类似，所提出的方法具有不需要显式选择先验分布的巨大优势，而是将其编码到预训练的生成模型中。然而，与需要谨慎调整调整参数的优化方法(PnP-ADMM)不同，所提出的插拔式分割 Gibbs 采样算法可以在采样过程中自动适应后验分布的复杂性。",
    "tldr": "本文介绍一种插拔式分割 Gibbs 采样算法，将后验采样任务分为两个较简单的子问题，其中第二个子问题可以用深度生成模型轻松地解决，从而实现了在贝叶斯推断中嵌入深度生成先验以及自动适应后验分布的复杂性。",
    "en_tdlr": "This paper proposes a plug-and-play split Gibbs sampling algorithm that divides the posterior sampling task into two simpler subproblems, where the second problem can be easily solved by a deep generative model, achieving the embedding of deep generative priors in Bayesian inference and automatic adaptation to the complexity of the posterior distribution."
}