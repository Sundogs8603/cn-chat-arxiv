{
    "title": "X-RLflow: Graph Reinforcement Learning for Neural Network Subgraphs Transformation. (arXiv:2304.14698v1 [cs.LG])",
    "abstract": "Tensor graph superoptimisation systems perform a sequence of subgraph substitution to neural networks, to find the optimal computation graph structure. Such a graph transformation process naturally falls into the framework of sequential decision-making, and existing systems typically employ a greedy search approach, which cannot explore the whole search space as it cannot tolerate a temporary loss of performance. In this paper, we address the tensor graph superoptimisation problem by exploring an alternative search approach, reinforcement learning (RL). Our proposed approach, X-RLflow, can learn to perform neural network dataflow graph rewriting, which substitutes a subgraph one at a time. X-RLflow is based on a model-free RL agent that uses a graph neural network (GNN) to encode the target computation graph and outputs a transformed computation graph iteratively. We show that our approach can outperform state-of-the-art superoptimisation systems over a range of deep learning models an",
    "link": "http://arxiv.org/abs/2304.14698",
    "context": "Title: X-RLflow: Graph Reinforcement Learning for Neural Network Subgraphs Transformation. (arXiv:2304.14698v1 [cs.LG])\nAbstract: Tensor graph superoptimisation systems perform a sequence of subgraph substitution to neural networks, to find the optimal computation graph structure. Such a graph transformation process naturally falls into the framework of sequential decision-making, and existing systems typically employ a greedy search approach, which cannot explore the whole search space as it cannot tolerate a temporary loss of performance. In this paper, we address the tensor graph superoptimisation problem by exploring an alternative search approach, reinforcement learning (RL). Our proposed approach, X-RLflow, can learn to perform neural network dataflow graph rewriting, which substitutes a subgraph one at a time. X-RLflow is based on a model-free RL agent that uses a graph neural network (GNN) to encode the target computation graph and outputs a transformed computation graph iteratively. We show that our approach can outperform state-of-the-art superoptimisation systems over a range of deep learning models an",
    "path": "papers/23/04/2304.14698.json",
    "total_tokens": 873,
    "translated_title": "X-RLflow：面向神经网络子图转换的图形增强学习",
    "translated_abstract": "张量图超优化系统通过神经网络的一系列子图替换来找到最优的计算图结构。这个图转换过程自然而然地落入了序列决策框架中, 现有系统通常采用贪心搜索方法，无法探索整个搜索空间，因为它不能容忍临时的性能损失。本文提出了一种基于强化学习 (RL) 的替代搜索方法来解决张量图超优化问题。我们提出的方法，X-RLflow，可以学习执行神经网络数据流图重写，一次替换一个子图。X-RLflow 基于一种无模型 RL 代理，使用图神经网络 (GNN) 对目标计算图进行编码，并迭代输出转换后的计算图。我们证明，我们的方法可以在各种深度学习模型和基准测试中超越现有技术的超优化系统。",
    "tldr": "本论文提出了一种基于强化学习的方法，X-RLflow，用于替换神经网络的子图，以求得更优的计算图结构，可在各种深度学习模型和基准测试中超越现有技术的超优化系统。"
}