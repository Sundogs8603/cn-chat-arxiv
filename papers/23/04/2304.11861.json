{
    "title": "Towards a Praxis for Intercultural Ethics in Explainable AI. (arXiv:2304.11861v2 [cs.AI] UPDATED)",
    "abstract": "Explainable AI (XAI) is often promoted with the idea of helping users understand how machine learning models function and produce predictions. Still, most of these benefits are reserved for those with specialized domain knowledge, such as machine learning developers. Recent research has argued that making AI explainable can be a viable way of making AI more useful in real-world contexts, especially within low-resource domains in the Global South. While AI has transcended borders, a limited amount of work focuses on democratizing the concept of explainable AI to the \"majority world\", leaving much room to explore and develop new approaches within this space that cater to the distinct needs of users within culturally and socially-diverse regions. This article introduces the concept of an intercultural ethics approach to AI explainability. It examines how cultural nuances impact the adoption and use of technology, the factors that impede how technical concepts such as AI are explained, and",
    "link": "http://arxiv.org/abs/2304.11861",
    "context": "Title: Towards a Praxis for Intercultural Ethics in Explainable AI. (arXiv:2304.11861v2 [cs.AI] UPDATED)\nAbstract: Explainable AI (XAI) is often promoted with the idea of helping users understand how machine learning models function and produce predictions. Still, most of these benefits are reserved for those with specialized domain knowledge, such as machine learning developers. Recent research has argued that making AI explainable can be a viable way of making AI more useful in real-world contexts, especially within low-resource domains in the Global South. While AI has transcended borders, a limited amount of work focuses on democratizing the concept of explainable AI to the \"majority world\", leaving much room to explore and develop new approaches within this space that cater to the distinct needs of users within culturally and socially-diverse regions. This article introduces the concept of an intercultural ethics approach to AI explainability. It examines how cultural nuances impact the adoption and use of technology, the factors that impede how technical concepts such as AI are explained, and",
    "path": "papers/23/04/2304.11861.json",
    "total_tokens": 941,
    "translated_title": "论可解释人工智能的跨文化伦理实践",
    "translated_abstract": "可解释人工智能（XAI）通常被宣传为帮助用户理解机器学习模型的功能和预测产生的原因。但是，这些好处大多为那些具有专业领域知识的人所保留，比如机器学习开发人员。最近的研究认为，使AI可解释可能是在现实世界中使AI更有用的一种可行方式，尤其是在全球南方低资源领域内。尽管AI已经跨越了国界，但很少有研究关注将解释AI概念民主化到“大多数世界”内，这留给我们在这个领域探索和开发新方法的机会，以满足在文化和社交多样化的地区中具有不同需求的用户。本文介绍了一种跨文化伦理实践的AI可解释方法。它研究了文化细微差别如何影响技术采纳和使用，以及阻碍解释技术概念如AI的因素。",
    "tldr": "该论文介绍了一种可解释人工智能的跨文化伦理实践方法，研究了文化差异如何影响技术的采纳和使用，并探讨了解释技术概念如何帮助那些在社会和文化多样性地区中具有不同需求的用户。",
    "en_tdlr": "This paper introduces a cross-cultural ethics approach to explainable AI, exploring how cultural nuances impact the adoption and use of technology, and discussing how explaining technical concepts such as AI can help users in socially and culturally diverse regions with distinct needs."
}