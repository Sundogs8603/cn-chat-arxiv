{
    "title": "Understanding Causality with Large Language Models: Feasibility and Opportunities. (arXiv:2304.05524v1 [cs.LG])",
    "abstract": "We assess the ability of large language models (LLMs) to answer causal questions by analyzing their strengths and weaknesses against three types of causal question. We believe that current LLMs can answer causal questions with existing causal knowledge as combined domain experts. However, they are not yet able to provide satisfactory answers for discovering new knowledge or for high-stakes decision-making tasks with high precision. We discuss possible future directions and opportunities, such as enabling explicit and implicit causal modules as well as deep causal-aware LLMs. These will not only enable LLMs to answer many different types of causal questions for greater impact but also enable LLMs to be more trustworthy and efficient in general.",
    "link": "http://arxiv.org/abs/2304.05524",
    "context": "Title: Understanding Causality with Large Language Models: Feasibility and Opportunities. (arXiv:2304.05524v1 [cs.LG])\nAbstract: We assess the ability of large language models (LLMs) to answer causal questions by analyzing their strengths and weaknesses against three types of causal question. We believe that current LLMs can answer causal questions with existing causal knowledge as combined domain experts. However, they are not yet able to provide satisfactory answers for discovering new knowledge or for high-stakes decision-making tasks with high precision. We discuss possible future directions and opportunities, such as enabling explicit and implicit causal modules as well as deep causal-aware LLMs. These will not only enable LLMs to answer many different types of causal questions for greater impact but also enable LLMs to be more trustworthy and efficient in general.",
    "path": "papers/23/04/2304.05524.json",
    "total_tokens": 823,
    "translated_title": "用大规模语言模型理解因果关系: 可行性和机遇",
    "translated_abstract": "本文通过分析大型语言模型(LLMs)在回答三种类型因果问题时的优缺点，评估了它们回答因果问题的能力。我们认为，当前的LLMs可以像领域专家一样回答基于已有因果知识的因果问题。但是，它们还不能为发现新知识或高精度高风险决策任务提供令人满意的答案。我们讨论了未来可能的方向和机遇，例如启用显式和隐式的因果模块以及深度因果感知的LLMs。这些不仅可以使LLMs回答更多类型的因果问题以实现更大的影响力，还可以使LLMs在一般情况下更加值得信任和高效。",
    "tldr": "本文评估了大型语言模型回答因果问题的能力，发现它们可以回答基于已有因果知识的问题，但对于发现新知识或高风险决策任务的高精度要求不足。未来可以通过启用显式和隐式的因果模块以及深度因果感知的LLMs来解决这些问题。",
    "en_tdlr": "This paper assesses the ability of large language models to answer causal questions, finding that they can answer questions based on existing causal knowledge but have limitations for discovering new knowledge or high-stakes decision-making tasks. Future directions include enabling explicit and implicit causal modules and deep causal-aware LLMs."
}