{
    "title": "Multimodal Garment Designer: Human-Centric Latent Diffusion Models for Fashion Image Editing. (arXiv:2304.02051v1 [cs.CV])",
    "abstract": "Fashion illustration is used by designers to communicate their vision and to bring the design idea from conceptualization to realization, showing how clothes interact with the human body. In this context, computer vision can thus be used to improve the fashion design process. Differently from previous works that mainly focused on the virtual try-on of garments, we propose the task of multimodal-conditioned fashion image editing, guiding the generation of human-centric fashion images by following multimodal prompts, such as text, human body poses, and garment sketches. We tackle this problem by proposing a new architecture based on latent diffusion models, an approach that has not been used before in the fashion domain. Given the lack of existing datasets suitable for the task, we also extend two existing fashion datasets, namely Dress Code and VITON-HD, with multimodal annotations collected in a semi-automatic manner. Experimental results on these new datasets demonstrate the effective",
    "link": "http://arxiv.org/abs/2304.02051",
    "context": "Title: Multimodal Garment Designer: Human-Centric Latent Diffusion Models for Fashion Image Editing. (arXiv:2304.02051v1 [cs.CV])\nAbstract: Fashion illustration is used by designers to communicate their vision and to bring the design idea from conceptualization to realization, showing how clothes interact with the human body. In this context, computer vision can thus be used to improve the fashion design process. Differently from previous works that mainly focused on the virtual try-on of garments, we propose the task of multimodal-conditioned fashion image editing, guiding the generation of human-centric fashion images by following multimodal prompts, such as text, human body poses, and garment sketches. We tackle this problem by proposing a new architecture based on latent diffusion models, an approach that has not been used before in the fashion domain. Given the lack of existing datasets suitable for the task, we also extend two existing fashion datasets, namely Dress Code and VITON-HD, with multimodal annotations collected in a semi-automatic manner. Experimental results on these new datasets demonstrate the effective",
    "path": "papers/23/04/2304.02051.json",
    "total_tokens": 818,
    "translated_title": "多模态服装设计师：面向人的潜在扩散模型用于时尚图像编辑",
    "translated_abstract": "时尚插图是设计师用来传达他们的视觉和将设计理念从构思到实现，展示服装如何与人体交互的方式。在这个背景下，计算机视觉可以用于改进时尚设计过程。本文提出了一个新的架构，基于潜在扩散模型，提出了多模态条件的时尚图像编辑任务，通过跟随多模态提示，如文本、人体姿势和服装草图，指导生成以人为中心的时尚图像。由于缺乏适合这项任务的现有数据集，我们还展开了两个现有时尚数据集 Dress Code 和 VITON-HD，用半自动的方法补充了多模态注释。新数据集上的实验结果表明了该方法的有效性。",
    "tldr": "本文提出了一种基于人体的多模态面部图像编辑方法，通过潜在扩散模型来生成服装设计，实现了时尚插图的自动化。"
}