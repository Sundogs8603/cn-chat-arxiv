{
    "title": "Asymmetrically-powered Neural Image Compression with Shallow Decoders. (arXiv:2304.06244v1 [eess.IV])",
    "abstract": "Neural image compression methods have seen increasingly strong performance in recent years. However, they suffer orders of magnitude higher computational complexity compared to traditional codecs, which stands in the way of real-world deployment. This paper takes a step forward in closing this gap in decoding complexity by adopting shallow or even linear decoding transforms. To compensate for the resulting drop in compression performance, we exploit the often asymmetrical computation budget between encoding and decoding, by adopting more powerful encoder networks and iterative encoding. We theoretically formalize the intuition behind, and our experimental results establish a new frontier in the trade-off between rate-distortion and decoding complexity for neural image compression. Specifically, we achieve rate-distortion performance competitive with the established mean-scale hyperprior architecture of Minnen et al. (2018), while reducing the overall decoding complexity by 80 %, or ove",
    "link": "http://arxiv.org/abs/2304.06244",
    "context": "Title: Asymmetrically-powered Neural Image Compression with Shallow Decoders. (arXiv:2304.06244v1 [eess.IV])\nAbstract: Neural image compression methods have seen increasingly strong performance in recent years. However, they suffer orders of magnitude higher computational complexity compared to traditional codecs, which stands in the way of real-world deployment. This paper takes a step forward in closing this gap in decoding complexity by adopting shallow or even linear decoding transforms. To compensate for the resulting drop in compression performance, we exploit the often asymmetrical computation budget between encoding and decoding, by adopting more powerful encoder networks and iterative encoding. We theoretically formalize the intuition behind, and our experimental results establish a new frontier in the trade-off between rate-distortion and decoding complexity for neural image compression. Specifically, we achieve rate-distortion performance competitive with the established mean-scale hyperprior architecture of Minnen et al. (2018), while reducing the overall decoding complexity by 80 %, or ove",
    "path": "papers/23/04/2304.06244.json",
    "total_tokens": 912,
    "translated_title": "具有浅层解码器的不对称神经图像压缩",
    "translated_abstract": "近年来，神经图像压缩方法表现越来越强。但与传统编解码器相比，它们的计算复杂度高出数个数量级，这成为实际部署的障碍。本文通过采用浅层甚至线性解码转换来缩小解码复杂度的差距迈出了一步。为了弥补由此导致的压缩性能下降，作者利用编码和解码之间通常不对称的计算预算，采用更强大的编码网络和迭代编码。理论上证明了这个想法，实验结果在神经图像压缩的速率失真和解码复杂度的权衡方面开启了新的前沿。具体而言，我们实现了与Minnen等人（2018）的平均比例超先验体系结构相竞争的速率失真性能，同时减小了总体解码复杂度80％，或者超过。",
    "tldr": "采用浅层或线性解码转换来缩小解码复杂度，同时利用通常不对称的计算预算、更强的编码网络和迭代编码来保持压缩性能，实现了速率失真性能与传统方法相竞争，解码复杂度降低80%以上。",
    "en_tdlr": "This paper proposes to reduce the decoding complexity of neural image compression by adopting shallow or even linear decoding transforms, while exploiting the often asymmetrical computation budget between encoding and decoding by using more powerful encoder networks and iterative encoding to compensate for the drop in compression performance. The achieved rate-distortion performance is competitive with traditional methods, and the decoding complexity is reduced by over 80%."
}