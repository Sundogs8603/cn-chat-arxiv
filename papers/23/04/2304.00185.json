{
    "title": "PrefGen: Preference Guided Image Generation with Relative Attributes. (arXiv:2304.00185v1 [cs.CV])",
    "abstract": "Deep generative models have the capacity to render high fidelity images of content like human faces. Recently, there has been substantial progress in conditionally generating images with specific quantitative attributes, like the emotion conveyed by one's face. These methods typically require a user to explicitly quantify the desired intensity of a visual attribute. A limitation of this method is that many attributes, like how \"angry\" a human face looks, are difficult for a user to precisely quantify. However, a user would be able to reliably say which of two faces seems \"angrier\". Following this premise, we develop the $\\textit{PrefGen}$ system, which allows users to control the relative attributes of generated images by presenting them with simple paired comparison queries of the form \"do you prefer image $a$ or image $b$?\" Using information from a sequence of query responses, we can estimate user preferences over a set of image attributes and perform preference-guided image editing ",
    "link": "http://arxiv.org/abs/2304.00185",
    "context": "Title: PrefGen: Preference Guided Image Generation with Relative Attributes. (arXiv:2304.00185v1 [cs.CV])\nAbstract: Deep generative models have the capacity to render high fidelity images of content like human faces. Recently, there has been substantial progress in conditionally generating images with specific quantitative attributes, like the emotion conveyed by one's face. These methods typically require a user to explicitly quantify the desired intensity of a visual attribute. A limitation of this method is that many attributes, like how \"angry\" a human face looks, are difficult for a user to precisely quantify. However, a user would be able to reliably say which of two faces seems \"angrier\". Following this premise, we develop the $\\textit{PrefGen}$ system, which allows users to control the relative attributes of generated images by presenting them with simple paired comparison queries of the form \"do you prefer image $a$ or image $b$?\" Using information from a sequence of query responses, we can estimate user preferences over a set of image attributes and perform preference-guided image editing ",
    "path": "papers/23/04/2304.00185.json",
    "total_tokens": 845,
    "translated_title": "PrefGen：基于偏好的相对属性图像生成",
    "translated_abstract": "深度生成模型可以渲染出高保真的人脸等内容的图像。近年来，在生成具有特定数量属性的图像方面取得了实质性进展，例如情感等。这些方法通常需要用户明确量化所需视觉属性的强度。但是限制在于许多属性，例如面部表情的 \"愤怒\" 程度，用户难以准确量化。然而，用户可以可靠地表达出 \"哪张脸看起来更愤怒\"，基于这个假设，我们开发了 $\\textit{PrefGen}$ 系统，通过呈现用户简单的成对比较查询，如 \"你更喜欢图像 $a$ 还是 $b$？\" 来控制生成图像的相对属性。利用序列化查询响应的信息，我们可以估计用户对一组图像属性的偏好，并进行基于偏好的图像编辑。",
    "tldr": "$\\textit{PrefGen}$ 系统利用简单的成对比较查询，控制生成图像的相对属性。利用这些查询响应的信息，对一组图像属性的偏好进行估计，并进行基于偏好的图像编辑。",
    "en_tdlr": "PrefGen system allows users to control the relative attributes of generated images by presenting them with simple paired comparison queries. Using information from a sequence of query responses, it estimates user preferences over a set of image attributes and performs preference-guided image editing."
}