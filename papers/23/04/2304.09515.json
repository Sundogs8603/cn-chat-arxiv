{
    "title": "Secure Split Learning against Property Inference, Data Reconstruction, and Feature Space Hijacking Attacks. (arXiv:2304.09515v1 [cs.LG])",
    "abstract": "Split learning of deep neural networks (SplitNN) has provided a promising solution to learning jointly for the mutual interest of a guest and a host, which may come from different backgrounds, holding features partitioned vertically. However, SplitNN creates a new attack surface for the adversarial participant, holding back its practical use in the real world. By investigating the adversarial effects of highly threatening attacks, including property inference, data reconstruction, and feature hijacking attacks, we identify the underlying vulnerability of SplitNN and propose a countermeasure. To prevent potential threats and ensure the learning guarantees of SplitNN, we design a privacy-preserving tunnel for information exchange between the guest and the host. The intuition is to perturb the propagation of knowledge in each direction with a controllable unified solution. To this end, we propose a new activation function named R3eLU, transferring private smashed data and partial loss int",
    "link": "http://arxiv.org/abs/2304.09515",
    "context": "Title: Secure Split Learning against Property Inference, Data Reconstruction, and Feature Space Hijacking Attacks. (arXiv:2304.09515v1 [cs.LG])\nAbstract: Split learning of deep neural networks (SplitNN) has provided a promising solution to learning jointly for the mutual interest of a guest and a host, which may come from different backgrounds, holding features partitioned vertically. However, SplitNN creates a new attack surface for the adversarial participant, holding back its practical use in the real world. By investigating the adversarial effects of highly threatening attacks, including property inference, data reconstruction, and feature hijacking attacks, we identify the underlying vulnerability of SplitNN and propose a countermeasure. To prevent potential threats and ensure the learning guarantees of SplitNN, we design a privacy-preserving tunnel for information exchange between the guest and the host. The intuition is to perturb the propagation of knowledge in each direction with a controllable unified solution. To this end, we propose a new activation function named R3eLU, transferring private smashed data and partial loss int",
    "path": "papers/23/04/2304.09515.json",
    "total_tokens": 902,
    "translated_title": "防止属性推断、数据重构和特征空间劫持攻击的安全分布式学习算法",
    "translated_abstract": "分布式学习已经成为一种解决来自不同背景的客户和主机共同学习的有希望的方法。然而，这种方法可能为恶意攻击者创造新的攻击面，使其在实际使用中具有局限性。本文针对分布式学习中可能遭受的属性推断、数据重组和特征劫持等威胁进行研究，并提出了解决方案，以确保分布式学习的学习保障。我们设计了一个隐私保护通道，用于客户和主机之间的信息交换，防止潜在的威胁，并保证了系统的安全稳定性。",
    "tldr": "本论文研究了分布式学习面临的安全问题并提出了一种隐私保护通道，使用新的激活函数R3eLU避免属性推断、数据重组和特征劫持等攻击。实验表明，该方法在保护隐私的同时，性能相当于不保护隐私的最新方法。",
    "en_tdlr": "This paper investigates the security issues faced by split learning and proposes a privacy-preserving tunnel using a new activation function R3eLU to avoid attacks such as property inference, data reconstruction, and feature hijacking. The experiments show that the proposed method achieves comparable performance with state-of-the-art approaches without sacrificing privacy."
}