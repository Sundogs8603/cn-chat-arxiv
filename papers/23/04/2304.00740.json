{
    "title": "Inspecting and Editing Knowledge Representations in Language Models. (arXiv:2304.00740v2 [cs.CL] UPDATED)",
    "abstract": "Neural language models (LMs) represent facts about the world described by text. Sometimes these facts derive from training data (in most LMs, a representation of the word \"banana\" encodes the fact that bananas are fruits). Sometimes facts derive from input text itself (a representation of the sentence \"I poured out the bottle\" encodes the fact that the bottle became empty). We describe REMEDI, a method for learning to map statements in natural language to fact encodings in an LM's internal representation system. REMEDI encodings can be used as knowledge editors: when added to LM hidden representations, they modify downstream generation to be consistent with new facts. REMEDI encodings may also be used as probes: when compared to LM representations, they reveal which properties LMs already attribute to mentioned entities, in some cases making it possible to predict when LMs will generate outputs that conflict with background knowledge or input text. REMEDI thus links work on probing, pr",
    "link": "http://arxiv.org/abs/2304.00740",
    "context": "Title: Inspecting and Editing Knowledge Representations in Language Models. (arXiv:2304.00740v2 [cs.CL] UPDATED)\nAbstract: Neural language models (LMs) represent facts about the world described by text. Sometimes these facts derive from training data (in most LMs, a representation of the word \"banana\" encodes the fact that bananas are fruits). Sometimes facts derive from input text itself (a representation of the sentence \"I poured out the bottle\" encodes the fact that the bottle became empty). We describe REMEDI, a method for learning to map statements in natural language to fact encodings in an LM's internal representation system. REMEDI encodings can be used as knowledge editors: when added to LM hidden representations, they modify downstream generation to be consistent with new facts. REMEDI encodings may also be used as probes: when compared to LM representations, they reveal which properties LMs already attribute to mentioned entities, in some cases making it possible to predict when LMs will generate outputs that conflict with background knowledge or input text. REMEDI thus links work on probing, pr",
    "path": "papers/23/04/2304.00740.json",
    "total_tokens": 914,
    "translated_title": "检查和编辑语言模型中的知识表示",
    "translated_abstract": "神经语言模型（LMs）表示有关文本所描述世界的事实。有时这些事实来自训练数据（在大多数LMs中，“香蕉”一词的表示表示香蕉是水果的事实）。有时事实来自输入文本本身（“我倒出了瓶子”这个句子的表示表示瓶子变空了的事实）。我们描述了REMEDI，一种学习将自然语言中的语句映射到LM的内部表示系统中的事实编码的方法。 REMEDI编码可用作知识编辑器：当添加到LM隐藏表示时，它们会修改下游生成，使其与新事实一致。 REMEDI编码也可以用作探针：与LM表示进行比较时，它们揭示了LM已经将哪些属性归因于提到的实体，在某些情况下，这使得可以预测LM将生成与背景知识或输入文本冲突的输出时。因此，REMEDI链接了有关探测，PR",
    "tldr": "REMEDI是一种将自然语言语句映射到LM内部表示系统中的事实编码的学习方法。 REMEDI编码可用作知识编辑器，也可以用作探针，揭示了LM已经将哪些属性归因于提到的实体，并可以预测LM会生成输出的情况。",
    "en_tdlr": "REMEDI is a learning method for mapping natural language statements to fact encodings in an LM's internal representation system. REMEDI encodings can be used as knowledge editors and probes, revealing which properties LMs attribute to mentioned entities and predicting when LMs will generate conflicting outputs."
}