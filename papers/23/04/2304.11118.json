{
    "title": "BoDiffusion: Diffusing Sparse Observations for Full-Body Human Motion Synthesis. (arXiv:2304.11118v1 [cs.CV])",
    "abstract": "Mixed reality applications require tracking the user's full-body motion to enable an immersive experience. However, typical head-mounted devices can only track head and hand movements, leading to a limited reconstruction of full-body motion due to variability in lower body configurations. We propose BoDiffusion -- a generative diffusion model for motion synthesis to tackle this under-constrained reconstruction problem. We present a time and space conditioning scheme that allows BoDiffusion to leverage sparse tracking inputs while generating smooth and realistic full-body motion sequences. To the best of our knowledge, this is the first approach that uses the reverse diffusion process to model full-body tracking as a conditional sequence generation task. We conduct experiments on the large-scale motion-capture dataset AMASS and show that our approach outperforms the state-of-the-art approaches by a significant margin in terms of full-body motion realism and joint reconstruction error.",
    "link": "http://arxiv.org/abs/2304.11118",
    "context": "Title: BoDiffusion: Diffusing Sparse Observations for Full-Body Human Motion Synthesis. (arXiv:2304.11118v1 [cs.CV])\nAbstract: Mixed reality applications require tracking the user's full-body motion to enable an immersive experience. However, typical head-mounted devices can only track head and hand movements, leading to a limited reconstruction of full-body motion due to variability in lower body configurations. We propose BoDiffusion -- a generative diffusion model for motion synthesis to tackle this under-constrained reconstruction problem. We present a time and space conditioning scheme that allows BoDiffusion to leverage sparse tracking inputs while generating smooth and realistic full-body motion sequences. To the best of our knowledge, this is the first approach that uses the reverse diffusion process to model full-body tracking as a conditional sequence generation task. We conduct experiments on the large-scale motion-capture dataset AMASS and show that our approach outperforms the state-of-the-art approaches by a significant margin in terms of full-body motion realism and joint reconstruction error.",
    "path": "papers/23/04/2304.11118.json",
    "total_tokens": 882,
    "translated_title": "BoDiffusion：应用于全身人体运动合成的稀疏观测扩散",
    "translated_abstract": "混合现实应用需要跟踪用户的全身运动以实现沉浸式体验。然而，典型的头戴式设备只能跟踪头部和手部运动，导致由于下半身姿态的变异性而对完整的全身运动重建存在限制。本文提出了BoDiffusion——一种用于运动合成的生成扩散模型，以应对这种欠约束的重建问题。我们提出了一种时空条件方案，使BoDiffusion能够利用稀疏跟踪输入同时生成平滑、逼真的完整全身运动序列。据我们所知，这是第一种利用反向扩散过程将全身跟踪建模为条件序列生成任务的方法。我们在大规模动作捕捉数据集AMASS上进行实验，并证明我们的方法在全身运动逼真度和关节重建误差方面显著优于现有最先进的方法。",
    "tldr": "BoDiffusion是一种应用于全身人体运动合成的生成扩散模型，可以通过利用稀疏跟踪输入生成平滑逼真的完整全身运动序列，该方法在逼真度和重建误差方面优于现有最先进的方法。",
    "en_tdlr": "BoDiffusion is a generative diffusion model for motion synthesis, which is used to generate smooth and realistic full-body motion sequences by leveraging sparse tracking inputs. This approach outperforms state-of-the-art methods in terms of motion realism and joint reconstruction error."
}