{
    "title": "Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models. (arXiv:2304.08818v1 [cs.CV])",
    "abstract": "Latent Diffusion Models (LDMs) enable high-quality image synthesis while avoiding excessive compute demands by training a diffusion model in a compressed lower-dimensional latent space. Here, we apply the LDM paradigm to high-resolution video generation, a particularly resource-intensive task. We first pre-train an LDM on images only; then, we turn the image generator into a video generator by introducing a temporal dimension to the latent space diffusion model and fine-tuning on encoded image sequences, i.e., videos. Similarly, we temporally align diffusion model upsamplers, turning them into temporally consistent video super resolution models. We focus on two relevant real-world applications: Simulation of in-the-wild driving data and creative content creation with text-to-video modeling. In particular, we validate our Video LDM on real driving videos of resolution 512 x 1024, achieving state-of-the-art performance. Furthermore, our approach can easily leverage off-the-shelf pre-trai",
    "link": "http://arxiv.org/abs/2304.08818",
    "context": "Title: Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models. (arXiv:2304.08818v1 [cs.CV])\nAbstract: Latent Diffusion Models (LDMs) enable high-quality image synthesis while avoiding excessive compute demands by training a diffusion model in a compressed lower-dimensional latent space. Here, we apply the LDM paradigm to high-resolution video generation, a particularly resource-intensive task. We first pre-train an LDM on images only; then, we turn the image generator into a video generator by introducing a temporal dimension to the latent space diffusion model and fine-tuning on encoded image sequences, i.e., videos. Similarly, we temporally align diffusion model upsamplers, turning them into temporally consistent video super resolution models. We focus on two relevant real-world applications: Simulation of in-the-wild driving data and creative content creation with text-to-video modeling. In particular, we validate our Video LDM on real driving videos of resolution 512 x 1024, achieving state-of-the-art performance. Furthermore, our approach can easily leverage off-the-shelf pre-trai",
    "path": "papers/23/04/2304.08818.json",
    "total_tokens": 926,
    "translated_title": "将潜变量对齐：使用潜扩散模型进行高分辨率视频合成",
    "translated_abstract": "潜扩散模型（LDM）通过在压缩的低维潜空间中训练扩散模型，实现高质量的图像合成，同时避免了过多的计算需求。本文将LDM应用于高分辨率视频生成，这是一项特别资源密集型的任务。我们首先对单独的图像进行预训练，然后通过在潜空间扩散模型中引入时间维度，并在编码的图像序列（即视频）上进行微调，将生成器从图像生成器转换为视频生成器。同样，我们在时间上对齐扩散模型上采样器，将其转化为时间一致性的视频超分辨率模型。我们关注两个相关的实际应用：野外驾驶数据的模拟和文本到视频建模的创意内容创作。特别地，我们在分辨率为512 x 1024的真实驾驶视频上验证了我们的视频LDM，并取得了最先进的性能。",
    "tldr": "本文提出了一种高分辨率视频合成方法，通过引入时间维度并在图像序列上微调扩散模型，实现了对实际驾驶数据的模拟和创意内容创作的的良好效果。",
    "en_tdlr": "This paper proposes a high-resolution video synthesis method that applies the Latent Diffusion Model (LDM) paradigm to generate videos with a temporal dimension. By fine-tuning on encoded image sequences, the approach achieves state-of-the-art performance in simulating real-world driving data and creative content creation with text-to-video modeling."
}