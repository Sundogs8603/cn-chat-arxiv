{
    "title": "Improving Image Recognition by Retrieving from Web-Scale Image-Text Data. (arXiv:2304.05173v1 [cs.CV])",
    "abstract": "Retrieval augmented models are becoming increasingly popular for computer vision tasks after their recent success in NLP problems. The goal is to enhance the recognition capabilities of the model by retrieving similar examples for the visual input from an external memory set. In this work, we introduce an attention-based memory module, which learns the importance of each retrieved example from the memory. Compared to existing approaches, our method removes the influence of the irrelevant retrieved examples, and retains those that are beneficial to the input query. We also thoroughly study various ways of constructing the memory dataset. Our experiments show the benefit of using a massive-scale memory dataset of 1B image-text pairs, and demonstrate the performance of different memory representations. We evaluate our method in three different classification tasks, namely long-tailed recognition, learning with noisy labels, and fine-grained classification, and show that it achieves state-",
    "link": "http://arxiv.org/abs/2304.05173",
    "context": "Title: Improving Image Recognition by Retrieving from Web-Scale Image-Text Data. (arXiv:2304.05173v1 [cs.CV])\nAbstract: Retrieval augmented models are becoming increasingly popular for computer vision tasks after their recent success in NLP problems. The goal is to enhance the recognition capabilities of the model by retrieving similar examples for the visual input from an external memory set. In this work, we introduce an attention-based memory module, which learns the importance of each retrieved example from the memory. Compared to existing approaches, our method removes the influence of the irrelevant retrieved examples, and retains those that are beneficial to the input query. We also thoroughly study various ways of constructing the memory dataset. Our experiments show the benefit of using a massive-scale memory dataset of 1B image-text pairs, and demonstrate the performance of different memory representations. We evaluate our method in three different classification tasks, namely long-tailed recognition, learning with noisy labels, and fine-grained classification, and show that it achieves state-",
    "path": "papers/23/04/2304.05173.json",
    "total_tokens": 915,
    "translated_title": "从网络规模的图像-文本数据检索提高图像识别的精度",
    "translated_abstract": "基于检索的增强模型在计算机视觉任务中变得越来越流行，尤其是在自然语言处理问题中的成功后。目标是通过从外部存储器集合中检索相似实例来增强模型的识别能力。在本文中，我们提出了一种基于注意力的记忆模块，该模块学习从存储器检索到的每个实例的重要性。与现有方法相比，我们的方法消除了不相关检索实例的影响，并保留了有益于输入查询的实例。我们还彻底研究了构建记忆数据集的各种方法。我们的实验表明，使用10亿个图像-文本对的大规模记忆数据集具有很大的好处，并展示了不同记忆表示的性能。我们在三个不同的分类任务中评价了我们的方法，即长尾识别、学习嘈杂标签和细粒度分类，并展示了它实现了一流的成果。",
    "tldr": "本论文介绍了一种基于注意力的记忆模块，通过从存储器集合中检索相似实例，消除了不相关实例的影响，保留了有益于输入查询的实例。使用大规模记忆数据集的实验表明该方法在三个不同的分类任务中实现了一流的成果。",
    "en_tdlr": "This paper introduces an attention-based memory module that enhances the recognition capabilities of the model by retrieving similar examples from an external memory set. Experiments using massive-scale memory dataset of 1B image-text pairs demonstrate that this method achieves state-of-the-art results in three different classification tasks."
}