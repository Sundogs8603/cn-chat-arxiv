{
    "title": "Explanations of Black-Box Models based on Directional Feature Interactions. (arXiv:2304.07670v1 [cs.LG])",
    "abstract": "As machine learning algorithms are deployed ubiquitously to a variety of domains, it is imperative to make these often black-box models transparent. Several recent works explain black-box models by capturing the most influential features for prediction per instance; such explanation methods are univariate, as they characterize importance per feature. We extend univariate explanation to a higher-order; this enhances explainability, as bivariate methods can capture feature interactions in black-box models, represented as a directed graph. Analyzing this graph enables us to discover groups of features that are equally important (i.e., interchangeable), while the notion of directionality allows us to identify the most influential features. We apply our bivariate method on Shapley value explanations, and experimentally demonstrate the ability of directional explanations to discover feature interactions. We show the superiority of our method against state-of-the-art on CIFAR10, IMDB, Census,",
    "link": "http://arxiv.org/abs/2304.07670",
    "context": "Title: Explanations of Black-Box Models based on Directional Feature Interactions. (arXiv:2304.07670v1 [cs.LG])\nAbstract: As machine learning algorithms are deployed ubiquitously to a variety of domains, it is imperative to make these often black-box models transparent. Several recent works explain black-box models by capturing the most influential features for prediction per instance; such explanation methods are univariate, as they characterize importance per feature. We extend univariate explanation to a higher-order; this enhances explainability, as bivariate methods can capture feature interactions in black-box models, represented as a directed graph. Analyzing this graph enables us to discover groups of features that are equally important (i.e., interchangeable), while the notion of directionality allows us to identify the most influential features. We apply our bivariate method on Shapley value explanations, and experimentally demonstrate the ability of directional explanations to discover feature interactions. We show the superiority of our method against state-of-the-art on CIFAR10, IMDB, Census,",
    "path": "papers/23/04/2304.07670.json",
    "total_tokens": 885,
    "translated_title": "基于方向特征交互的黑盒模型解释",
    "translated_abstract": "随着机器学习算法在各种领域得到广泛应用，使其常常是黑盒模型变得透明化非常重要。几个最近的工作通过抓取每个实例的最具影响力的预测特征来解释黑盒模型;这种解释方法是单变量的，因为它们表征每个特征的重要性。我们将单变量解释扩展到高阶，通过双变量方法增强了可解释性。这种双变量方法可以捕获黑盒模型中的特征交互，并将其表示为有向图。分析这个图可以发现同等重要的特征组，而方向性的概念使我们能够确定最具影响力的特征。我们将我们的双变量方法应用于Shapley值解释，并实验性地展示了方向性解释发现特征交互的能力。我们证明了我们的方法在CIFAR10、IMDB、Census和CelebA数据集上的优越性。",
    "tldr": "该论文提出了一种双变量解释方法，可以通过方向特征交互捕获黑盒模型中的特征交互。该方法在Shapley值解释中应用，并在多个数据集上证明了其优越性。",
    "en_tdlr": "This paper proposes a bivariate method to explain black-box models by capturing directional feature interactions. The method is applied to Shapley value explanations and experimentally shows superiority over state-of-the-art on several datasets."
}