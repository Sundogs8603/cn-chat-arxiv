{
    "title": "Improving Fast Adversarial Training with Prior-Guided Knowledge. (arXiv:2304.00202v1 [cs.LG])",
    "abstract": "Fast adversarial training (FAT) is an efficient method to improve robustness. However, the original FAT suffers from catastrophic overfitting, which dramatically and suddenly reduces robustness after a few training epochs. Although various FAT variants have been proposed to prevent overfitting, they require high training costs. In this paper, we investigate the relationship between adversarial example quality and catastrophic overfitting by comparing the training processes of standard adversarial training and FAT. We find that catastrophic overfitting occurs when the attack success rate of adversarial examples becomes worse. Based on this observation, we propose a positive prior-guided adversarial initialization to prevent overfitting by improving adversarial example quality without extra training costs. This initialization is generated by using high-quality adversarial perturbations from the historical training process. We provide theoretical analysis for the proposed initialization a",
    "link": "http://arxiv.org/abs/2304.00202",
    "context": "Title: Improving Fast Adversarial Training with Prior-Guided Knowledge. (arXiv:2304.00202v1 [cs.LG])\nAbstract: Fast adversarial training (FAT) is an efficient method to improve robustness. However, the original FAT suffers from catastrophic overfitting, which dramatically and suddenly reduces robustness after a few training epochs. Although various FAT variants have been proposed to prevent overfitting, they require high training costs. In this paper, we investigate the relationship between adversarial example quality and catastrophic overfitting by comparing the training processes of standard adversarial training and FAT. We find that catastrophic overfitting occurs when the attack success rate of adversarial examples becomes worse. Based on this observation, we propose a positive prior-guided adversarial initialization to prevent overfitting by improving adversarial example quality without extra training costs. This initialization is generated by using high-quality adversarial perturbations from the historical training process. We provide theoretical analysis for the proposed initialization a",
    "path": "papers/23/04/2304.00202.json",
    "total_tokens": 902,
    "translated_title": "使用先验引导知识改进快速对抗训练",
    "translated_abstract": "快速对抗训练是提高模型鲁棒性的有效方法。然而，原始的快速对抗训练会遭受灾难性的过度拟合问题，在经过几个训练周期后鲁棒性会急剧下降。虽然已经提出了各种快速对抗训练的变体来防止过度拟合，但它们需要较高的训练成本。本文通过比较标准对抗训练和快速对抗训练的训练过程，研究了对抗样本质量和灾难性过度拟合之间的关系。我们发现，当对抗样本的攻击成功率变差时，就会发生灾难性的过度拟合。基于这一观察，我们提出了一种使用高质量对抗扰动的正面先验引导对抗初始化方法，以提高对抗样本的质量，从而避免额外的训练成本。我们提供了该初始化方法的理论分析。",
    "tldr": "本文提出了一种使用先前训练过程中高质量对抗扰动的正面先验引导对抗初始化方法，以提高对抗样本的质量，从而避免快速对抗训练中的灾难性过度拟合问题。"
}