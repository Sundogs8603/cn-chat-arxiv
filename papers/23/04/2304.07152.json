{
    "title": "Combining Stochastic Explainers and Subgraph Neural Networks can Increase Expressivity and Interpretability. (arXiv:2304.07152v1 [cs.LG])",
    "abstract": "Subgraph-enhanced graph neural networks (SGNN) can increase the expressive power of the standard message-passing framework. This model family represents each graph as a collection of subgraphs, generally extracted by random sampling or with hand-crafted heuristics. Our key observation is that by selecting \"meaningful\" subgraphs, besides improving the expressivity of a GNN, it is also possible to obtain interpretable results. For this purpose, we introduce a novel framework that jointly predicts the class of the graph and a set of explanatory sparse subgraphs, which can be analyzed to understand the decision process of the classifier. We compare the performance of our framework against standard subgraph extraction policies, like random node/edge deletion strategies. The subgraphs produced by our framework allow to achieve comparable performance in terms of accuracy, with the additional benefit of providing explanations.",
    "link": "http://arxiv.org/abs/2304.07152",
    "context": "Title: Combining Stochastic Explainers and Subgraph Neural Networks can Increase Expressivity and Interpretability. (arXiv:2304.07152v1 [cs.LG])\nAbstract: Subgraph-enhanced graph neural networks (SGNN) can increase the expressive power of the standard message-passing framework. This model family represents each graph as a collection of subgraphs, generally extracted by random sampling or with hand-crafted heuristics. Our key observation is that by selecting \"meaningful\" subgraphs, besides improving the expressivity of a GNN, it is also possible to obtain interpretable results. For this purpose, we introduce a novel framework that jointly predicts the class of the graph and a set of explanatory sparse subgraphs, which can be analyzed to understand the decision process of the classifier. We compare the performance of our framework against standard subgraph extraction policies, like random node/edge deletion strategies. The subgraphs produced by our framework allow to achieve comparable performance in terms of accuracy, with the additional benefit of providing explanations.",
    "path": "papers/23/04/2304.07152.json",
    "total_tokens": 919,
    "translated_title": "结合随机解释器和子图神经网络可以增强表达能力和可解释性",
    "translated_abstract": "子图增强图神经网络（SGNN）可以增强标准的消息传递框架的表达能力。该模型家族将每个图表示为一组子图，通常通过随机抽样或手工启发式方法提取。我们的关键观察是，通过选择“有意义”的子图，除了提高GNN的表达能力外，还可以获得可解释的结果。为此，我们引入了一种新的框架，同时预测图的类别和一组解释性稀疏子图，可以分析这些子图来理解分类器的决策过程。我们将我们的框架与标准子图提取策略进行了比较，如随机节点/边缘删除策略。我们的框架产生的子图允许在准确性方面实现可比较的性能，同时提供解释的附加好处。",
    "tldr": "本论文提出了一种结合随机解释器和子图神经网络的新框架，通过挑选有意义的子图来提高图神经网络的表达能力，并提供可解释性结果。与标准子图提取策略相比，该框架产生的子图在准确性方面可达到可比较的性能，同时提供解释的附加好处。",
    "en_tdlr": "This paper proposes a novel framework that combines stochastic explainers and subgraph neural networks to enhance the expressivity and interpretability of graph neural networks. The framework selects meaningful subgraphs to improve the expressivity of GNN and provide interpretable results. The produced subgraphs have comparable performance in accuracy to standard subgraph extraction policies and also provide additional benefits of explanations."
}