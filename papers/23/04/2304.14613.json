{
    "title": "Deep Intellectual Property: A Survey. (arXiv:2304.14613v1 [cs.AI])",
    "abstract": "With the widespread application in industrial manufacturing and commercial services, well-trained deep neural networks (DNNs) are becoming increasingly valuable and crucial assets due to the tremendous training cost and excellent generalization performance. These trained models can be utilized by users without much expert knowledge benefiting from the emerging ''Machine Learning as a Service'' (MLaaS) paradigm. However, this paradigm also exposes the expensive models to various potential threats like model stealing and abuse. As an urgent requirement to defend against these threats, Deep Intellectual Property (DeepIP), to protect private training data, painstakingly-tuned hyperparameters, or costly learned model weights, has been the consensus of both industry and academia. To this end, numerous approaches have been proposed to achieve this goal in recent years, especially to prevent or discover model stealing and unauthorized redistribution. Given this period of rapid evolution, the g",
    "link": "http://arxiv.org/abs/2304.14613",
    "context": "Title: Deep Intellectual Property: A Survey. (arXiv:2304.14613v1 [cs.AI])\nAbstract: With the widespread application in industrial manufacturing and commercial services, well-trained deep neural networks (DNNs) are becoming increasingly valuable and crucial assets due to the tremendous training cost and excellent generalization performance. These trained models can be utilized by users without much expert knowledge benefiting from the emerging ''Machine Learning as a Service'' (MLaaS) paradigm. However, this paradigm also exposes the expensive models to various potential threats like model stealing and abuse. As an urgent requirement to defend against these threats, Deep Intellectual Property (DeepIP), to protect private training data, painstakingly-tuned hyperparameters, or costly learned model weights, has been the consensus of both industry and academia. To this end, numerous approaches have been proposed to achieve this goal in recent years, especially to prevent or discover model stealing and unauthorized redistribution. Given this period of rapid evolution, the g",
    "path": "papers/23/04/2304.14613.json",
    "total_tokens": 874,
    "translated_title": "深度知识产权: 综述",
    "translated_abstract": "随着深度神经网络在工业制造和商业服务中的广泛应用，经过充分训练的深度神经网络(DNNs)由于庞大的训练成本和优秀的泛化性能变得越来越有价值和至关重要。这些训练好的模型可以被用户利用，而无需了解太多专业知识，这得益于新兴的“机器学习即服务”(MLaaS)范式。然而，这种范式也使得昂贵的模型面临许多潜在威胁，例如模型窃取和滥用。为了抵御这些威胁的迫切需求，深度知识产权（Deep Intellectual Property，DeepIP）成为了业界和学术界的共识，以保护私有训练数据、费尽心思调整的超参数或昂贵学习的模型权重。为此，近年来提出了许多方法来实现这一目标，特别是防止或发现模型窃取和未经授权的重新分发。鉴于这一快速演变的时期，",
    "tldr": "这篇综述介绍了利用深度神经网络时所面临的知识产权保护问题，以及近年来防止和发现模型窃取和未经授权重新分发的方法。",
    "en_tdlr": "This survey introduces the issue of intellectual property protection when using deep neural networks, as well as the recent methods to prevent and detect model stealing and unauthorized redistribution."
}