{
    "title": "On Uncertainty Calibration and Selective Generation in Probabilistic Neural Summarization: A Benchmark Study. (arXiv:2304.08653v1 [cs.CL])",
    "abstract": "Modern deep models for summarization attains impressive benchmark performance, but they are prone to generating miscalibrated predictive uncertainty. This means that they assign high confidence to low-quality predictions, leading to compromised reliability and trustworthiness in real-world applications. Probabilistic deep learning methods are common solutions to the miscalibration problem. However, their relative effectiveness in complex autoregressive summarization tasks are not well-understood. In this work, we thoroughly investigate different state-of-the-art probabilistic methods' effectiveness in improving the uncertainty quality of the neural summarization models, across three large-scale benchmarks with varying difficulty. We show that the probabilistic methods consistently improve the model's generation and uncertainty quality, leading to improved selective generation performance (i.e., abstaining from low-quality summaries) in practice. We also reveal notable failure patterns ",
    "link": "http://arxiv.org/abs/2304.08653",
    "context": "Title: On Uncertainty Calibration and Selective Generation in Probabilistic Neural Summarization: A Benchmark Study. (arXiv:2304.08653v1 [cs.CL])\nAbstract: Modern deep models for summarization attains impressive benchmark performance, but they are prone to generating miscalibrated predictive uncertainty. This means that they assign high confidence to low-quality predictions, leading to compromised reliability and trustworthiness in real-world applications. Probabilistic deep learning methods are common solutions to the miscalibration problem. However, their relative effectiveness in complex autoregressive summarization tasks are not well-understood. In this work, we thoroughly investigate different state-of-the-art probabilistic methods' effectiveness in improving the uncertainty quality of the neural summarization models, across three large-scale benchmarks with varying difficulty. We show that the probabilistic methods consistently improve the model's generation and uncertainty quality, leading to improved selective generation performance (i.e., abstaining from low-quality summaries) in practice. We also reveal notable failure patterns ",
    "path": "papers/23/04/2304.08653.json",
    "total_tokens": 961,
    "translated_title": "关于概率神经摘要中的不确定性校准和选择性生成的基准研究",
    "translated_abstract": "现代深度摘要模型在基准性能方面取得了令人印象深刻的成果，但它们往往会生成错误校准的预测不确定性。这意味着它们对质量较低的预测赋予了高信心度，从而在实际应用中导致可靠性和信任度的降低。概率深度学习方法是解决误校准问题的常见方法。然而，它们在复杂自回归摘要任务中的相对有效性尚不清楚。在本工作中，我们彻底调查了不同最先进的概率方法在提高神经摘要模型不确定性质量方面的有效性，跨越了三个难度不同的大规模基准。我们发现，概率方法始终能够提高模型的生成和不确定性质量，从而在实践中实现了高质量生成（即放弃低质量摘要）。我们还揭示了显著的失效模式。",
    "tldr": "本研究对不同最先进的概率学习方法在提高神经摘要模型不确定性质量和生成效果方面进行了调查和对比，结果表明概率方法能够持续提高生成和不确定性质量，实现了高质量生成和放弃低质量摘要，且揭示了显著的失效模式。",
    "en_tdlr": "This benchmark study thoroughly investigates the effectiveness of different state-of-the-art probabilistic learning methods in improving the uncertainty quality and generation performance of neural summarization models. The study shows that the probabilistic methods consistently improve the model's generation and uncertainty quality, leading to improved selective generation performance, and also reveals notable failure patterns."
}