{
    "title": "Text2Time: Transformer-based article time period predictor. (arXiv:2304.10859v1 [cs.CL])",
    "abstract": "We explore the problem of predicting the publication period of text document, such as a news article, using the text from that document. In order to do so, we created our own extensive labeled dataset of over 350,000 news articles published by The New York Times over six decades. We then provide an implementation of a simple Naive Bayes baseline model, which surprisingly achieves decent performance in terms of accuracy.Finally, for our approach, we use a pretrained BERT model fine-tuned for the task of text classification. This model exceeds our expectations and provides some very impressive results in terms of accurately classifying news articles into their respective publication decades. The results beat the performance of the few previously tried models for this relatively unexplored task of time prediction from text.",
    "link": "http://arxiv.org/abs/2304.10859",
    "context": "Title: Text2Time: Transformer-based article time period predictor. (arXiv:2304.10859v1 [cs.CL])\nAbstract: We explore the problem of predicting the publication period of text document, such as a news article, using the text from that document. In order to do so, we created our own extensive labeled dataset of over 350,000 news articles published by The New York Times over six decades. We then provide an implementation of a simple Naive Bayes baseline model, which surprisingly achieves decent performance in terms of accuracy.Finally, for our approach, we use a pretrained BERT model fine-tuned for the task of text classification. This model exceeds our expectations and provides some very impressive results in terms of accurately classifying news articles into their respective publication decades. The results beat the performance of the few previously tried models for this relatively unexplored task of time prediction from text.",
    "path": "papers/23/04/2304.10859.json",
    "total_tokens": 758,
    "translated_title": "Text2Time: 基于Transformer的文章时间段预测器",
    "translated_abstract": "本论文探讨利用文本内容预测文章发表时间段的问题。我们创建了一个包含超过35万篇《纽约时报》历时六十年的标记数据集。我们实现了一个简单的朴素贝叶斯基准模型，它在准确性方面表现出人意料之外的不错性能。最后，我们使用了一个预训练的BERT模型，对其进行了微调以实现文本分类的任务。这个模型的性能超过了我们的预期，并提供了一些非常令人印象深刻的结果，准确地将新闻文章分类至其出版的年代。结果超过了先前尝试的这种相对不受关注的文本预测任务模型的性能。",
    "tldr": "本文提出了一个基于Transformer模型的文章时间段预测器，使用预训练的BERT模型对新闻文章进行分类的结果表现优于先前尝试的模型，具有很高的准确性。",
    "en_tdlr": "This paper proposes a Transformer-based article time period predictor, using a pretrained BERT model for text classification. The results exceed the performance of previous models and achieve high accuracy in classifying news articles into their respective publication decades."
}