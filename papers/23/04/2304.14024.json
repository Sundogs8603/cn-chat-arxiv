{
    "title": "Attacks on Robust Distributed Learning Schemes via Sensitivity Curve Maximization. (arXiv:2304.14024v1 [cs.LG])",
    "abstract": "Distributed learning paradigms, such as federated or decentralized learning, allow a collection of agents to solve global learning and optimization problems through limited local interactions. Most such strategies rely on a mixture of local adaptation and aggregation steps, either among peers or at a central fusion center. Classically, aggregation in distributed learning is based on averaging, which is statistically efficient, but susceptible to attacks by even a small number of malicious agents. This observation has motivated a number of recent works, which develop robust aggregation schemes by employing robust variations of the mean. We present a new attack based on sensitivity curve maximization (SCM), and demonstrate that it is able to disrupt existing robust aggregation schemes by injecting small, but effective perturbations.",
    "link": "http://arxiv.org/abs/2304.14024",
    "context": "Title: Attacks on Robust Distributed Learning Schemes via Sensitivity Curve Maximization. (arXiv:2304.14024v1 [cs.LG])\nAbstract: Distributed learning paradigms, such as federated or decentralized learning, allow a collection of agents to solve global learning and optimization problems through limited local interactions. Most such strategies rely on a mixture of local adaptation and aggregation steps, either among peers or at a central fusion center. Classically, aggregation in distributed learning is based on averaging, which is statistically efficient, but susceptible to attacks by even a small number of malicious agents. This observation has motivated a number of recent works, which develop robust aggregation schemes by employing robust variations of the mean. We present a new attack based on sensitivity curve maximization (SCM), and demonstrate that it is able to disrupt existing robust aggregation schemes by injecting small, but effective perturbations.",
    "path": "papers/23/04/2304.14024.json",
    "total_tokens": 825,
    "translated_title": "通过敏感性曲线最大化对鲁棒分布式学习方案的攻击",
    "translated_abstract": "分布式学习范例，诸如联邦学习或分散式学习，允许集合代理通过有限的局部交互解决全局学习和优化问题。大多数这样的策略依赖于本地适应和聚合步骤的混合，无论是在对等方之间还是在中央融合中心。传统上，分布式学习中的聚合是基于平均值的，这是统计上有效的，但容易受到少数恶意代理的攻击。这一观察促使了最近一些工作的出现，它们采用均值的鲁棒变体来开发健壮的聚合方案。我们提出了一种基于敏感性曲线最大化（SCM）的新攻击，并证明它能够通过注入微小但有效的扰动来破坏现有的鲁棒聚合方案。",
    "tldr": "本论文介绍了一种新的攻击方法——敏感性曲线最大化（SCM），它能够通过注入微小但有效的扰动来破坏现有的鲁棒分布式学习方案。",
    "en_tdlr": "This paper presents a new attack method, sensitivity curve maximization (SCM), which can disrupt existing robust distributed learning schemes by injecting small but effective perturbations."
}