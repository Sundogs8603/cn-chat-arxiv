{
    "title": "Understanding Shared Speech-Text Representations. (arXiv:2304.14514v1 [cs.CL])",
    "abstract": "Recently, a number of approaches to train speech models by incorpo-rating text into end-to-end models have been developed, with Mae-stro advancing state-of-the-art automatic speech recognition (ASR)and Speech Translation (ST) performance. In this paper, we expandour understanding of the resulting shared speech-text representationswith two types of analyses. First we examine the limits of speech-free domain adaptation, finding that a corpus-specific duration modelfor speech-text alignment is the most important component for learn-ing a shared speech-text representation. Second, we inspect the sim-ilarities between activations of unimodal (speech or text) encodersas compared to the activations of a shared encoder. We find that theshared encoder learns a more compact and overlapping speech-textrepresentation than the uni-modal encoders. We hypothesize that thispartially explains the effectiveness of the Maestro shared speech-textrepresentations.",
    "link": "http://arxiv.org/abs/2304.14514",
    "context": "Title: Understanding Shared Speech-Text Representations. (arXiv:2304.14514v1 [cs.CL])\nAbstract: Recently, a number of approaches to train speech models by incorpo-rating text into end-to-end models have been developed, with Mae-stro advancing state-of-the-art automatic speech recognition (ASR)and Speech Translation (ST) performance. In this paper, we expandour understanding of the resulting shared speech-text representationswith two types of analyses. First we examine the limits of speech-free domain adaptation, finding that a corpus-specific duration modelfor speech-text alignment is the most important component for learn-ing a shared speech-text representation. Second, we inspect the sim-ilarities between activations of unimodal (speech or text) encodersas compared to the activations of a shared encoder. We find that theshared encoder learns a more compact and overlapping speech-textrepresentation than the uni-modal encoders. We hypothesize that thispartially explains the effectiveness of the Maestro shared speech-textrepresentations.",
    "path": "papers/23/04/2304.14514.json",
    "total_tokens": 922,
    "translated_title": "理解共享的语音-文本表示",
    "translated_abstract": "最近出现了许多将文本整合到端到端模型中训练语音模型的方法，其中Maestro推进了自动语音识别（ASR）和语音翻译（ST）的最新进展。本文通过两类分析扩展了我们对产生的共享语音-文本表示的理解。首先，我们研究了无语音域自适应的极限，发现为了学习共享的语音-文本表示，具有语音-文本对齐的特定语料库持续模型是最重要的组成部分。其次，我们检查了单模态编码器（语音或文本）的激活与共享编码器的激活之间的相似之处。我们发现，共享编码器学习了一个比单模态编码器更紧凑和重叠的语音-文本表示。我们假设这部分解释了Maestro共享的语音-文本表示的有效性。",
    "tldr": "本文研究了将文本整合进入端到端语音模型中训练的方法，通过研究无语音域自适应和激活的相似性，发现持续模型对共享语音-文本表示很重要，共享编码器学习了一个比单模态更紧凑重叠的语音-文本表示，这部分解释了Maestro共享的语音-文本表示有效的原因。",
    "en_tdlr": "This paper explores integrating text into end-to-end speech models and examines the resulting shared speech-text representations, finding that corpus-specific duration models are crucial for learning a shared representation and that the shared encoder learns a more compact and overlapping speech-text representation than unimodal encoders, potentially explaining the effectiveness of the Maestro shared speech-text representations."
}