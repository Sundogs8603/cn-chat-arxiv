{
    "title": "\"I'm\" Lost in Translation: Pronoun Missteps in Crowdsourced Data Sets. (arXiv:2304.13557v1 [cs.CL])",
    "abstract": "As virtual assistants continue to be taken up globally, there is an ever-greater need for these speech-based systems to communicate naturally in a variety of languages. Crowdsourcing initiatives have focused on multilingual translation of big, open data sets for use in natural language processing (NLP). Yet, language translation is often not one-to-one, and biases can trickle in. In this late-breaking work, we focus on the case of pronouns translated between English and Japanese in the crowdsourced Tatoeba database. We found that masculine pronoun biases were present overall, even though plurality in language was accounted for in other ways. Importantly, we detected biases in the translation process that reflect nuanced reactions to the presence of feminine, neutral, and/or non-binary pronouns. We raise the issue of translation bias for pronouns and offer a practical solution to embed plurality in NLP data sets.",
    "link": "http://arxiv.org/abs/2304.13557",
    "context": "Title: \"I'm\" Lost in Translation: Pronoun Missteps in Crowdsourced Data Sets. (arXiv:2304.13557v1 [cs.CL])\nAbstract: As virtual assistants continue to be taken up globally, there is an ever-greater need for these speech-based systems to communicate naturally in a variety of languages. Crowdsourcing initiatives have focused on multilingual translation of big, open data sets for use in natural language processing (NLP). Yet, language translation is often not one-to-one, and biases can trickle in. In this late-breaking work, we focus on the case of pronouns translated between English and Japanese in the crowdsourced Tatoeba database. We found that masculine pronoun biases were present overall, even though plurality in language was accounted for in other ways. Importantly, we detected biases in the translation process that reflect nuanced reactions to the presence of feminine, neutral, and/or non-binary pronouns. We raise the issue of translation bias for pronouns and offer a practical solution to embed plurality in NLP data sets.",
    "path": "papers/23/04/2304.13557.json",
    "total_tokens": 945,
    "translated_title": "在众包数据集中“我”迷失在翻译中：代词错误步骤的问题",
    "translated_abstract": "随着虚拟助手在全球范围内的普及，越来越需要这些语音系统以各种语言自然地进行交流。众包倡议已经专注于对大型开放数据集进行多语言翻译，以用于自然语言处理（NLP）。然而，语言翻译通常不是一对一的，并且偏见可能会逐渐渗入。在这项最新工作中，我们关注了在众包Tatoeba数据库中英语和日语之间翻译的代词问题。我们发现整体上存在男性代词偏见，即使在其他方式中考虑到语言的复数。重要的是，我们检测到翻译过程中反映了对女性、中性和/或非二元代词存在的微妙反应的偏见。我们提出了代词翻译中的偏见问题，并提供了将复数嵌入NLP数据集的实际解决方案。",
    "tldr": "这项研究发现在英语和日语之间的翻译中存在男性代词偏见，同时也检测到了对女性、中性和/或非二元代词存在的微妙反应的偏见。他们提出了针对代词翻译偏见的问题，并提供了将复数嵌入NLP数据集的解决方案。",
    "en_tdlr": "This paper found that there is a bias towards masculine pronouns in English-Japanese translations, and biases were detected in the translation process that reflect nuanced reactions to feminine, neutral, and/or non-binary pronouns. They raise the issue of translation bias for pronouns and offer a practical solution to embed plurality in NLP data sets."
}