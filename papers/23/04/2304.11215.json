{
    "title": "ChatGPT: More than a Weapon of Mass Deception, Ethical challenges and responses from the Human-Centered Artificial Intelligence (HCAI) perspective. (arXiv:2304.11215v1 [cs.CY])",
    "abstract": "This article explores the ethical problems arising from the use of ChatGPT as a kind of generative AI and suggests responses based on the Human-Centered Artificial Intelligence (HCAI) framework. The HCAI framework is appropriate because it understands technology above all as a tool to empower, augment, and enhance human agency while referring to human wellbeing as a grand challenge, thus perfectly aligning itself with ethics, the science of human flourishing. Further, HCAI provides objectives, principles, procedures, and structures for reliable, safe, and trustworthy AI which we apply to our ChatGPT assessments. The main danger ChatGPT presents is the propensity to be used as a weapon of mass deception (WMD) and an enabler of criminal activities involving deceit. We review technical specifications to better comprehend its potentials and limitations. We then suggest both technical (watermarking, styleme, detectors, and fact-checkers) and non-technical measures (terms of use, transparenc",
    "link": "http://arxiv.org/abs/2304.11215",
    "context": "Title: ChatGPT: More than a Weapon of Mass Deception, Ethical challenges and responses from the Human-Centered Artificial Intelligence (HCAI) perspective. (arXiv:2304.11215v1 [cs.CY])\nAbstract: This article explores the ethical problems arising from the use of ChatGPT as a kind of generative AI and suggests responses based on the Human-Centered Artificial Intelligence (HCAI) framework. The HCAI framework is appropriate because it understands technology above all as a tool to empower, augment, and enhance human agency while referring to human wellbeing as a grand challenge, thus perfectly aligning itself with ethics, the science of human flourishing. Further, HCAI provides objectives, principles, procedures, and structures for reliable, safe, and trustworthy AI which we apply to our ChatGPT assessments. The main danger ChatGPT presents is the propensity to be used as a weapon of mass deception (WMD) and an enabler of criminal activities involving deceit. We review technical specifications to better comprehend its potentials and limitations. We then suggest both technical (watermarking, styleme, detectors, and fact-checkers) and non-technical measures (terms of use, transparenc",
    "path": "papers/23/04/2304.11215.json",
    "total_tokens": 1110,
    "translated_title": "ChatGPT：不只是一种大规模欺骗武器，基于人本主义人工智能（HCAI）视角的伦理挑战与应对",
    "translated_abstract": "本文探讨了将ChatGPT作为一种生成式人工智能所产生的伦理问题，并提出了基于人本主义人工智能框架的应对。该框架理解技术首先是一种赋能、增强和提升人类机能的工具，同时将人类福祉作为一个重大挑战，完全与伦理学，即人类繁荣的科学相一致。此外，HCAI为可靠、安全和值得信赖的人工智能提供了目标、原则、程序和结构，我们将其应用于我们的ChatGPT评估中。ChatGPT所带来的主要危险是成为一种大规模欺骗（WMD）武器和涉及欺诈的犯罪活动的促进因素。我们回顾了技术规格以更好地理解它的潜力和局限性。然后我们建议实施技术措施（数字水印、样式化、检测器和事实核查器）和非技术措施（使用条款、透明度和用户教育）来减轻ChatGPT所带来的伦理挑战。",
    "tldr": "本文探讨了将ChatGPT作为一种生成式人工智能所带来的伦理问题，提出了采取技术（数字水印、样式化、检测器和事实核查器）和非技术措施（使用条款、透明度和用户教育）来减轻其可能成为大规模欺骗武器和促进欺诈犯罪的危险。",
    "en_tdlr": "This article discusses the ethical challenges arising from the use of ChatGPT as a generative AI, and proposes technical (watermarking, styleme, detectors, and fact-checkers) and non-technical measures (terms of use, transparency and user education) to mitigate the risks of ChatGPT being used as a weapon of mass deception and an enabler of criminal activities involving deceit."
}