{
    "title": "Learning Agile Soccer Skills for a Bipedal Robot with Deep Reinforcement Learning. (arXiv:2304.13653v1 [cs.RO])",
    "abstract": "We investigate whether Deep Reinforcement Learning (Deep RL) is able to synthesize sophisticated and safe movement skills for a low-cost, miniature humanoid robot that can be composed into complex behavioral strategies in dynamic environments. We used Deep RL to train a humanoid robot with 20 actuated joints to play a simplified one-versus-one (1v1) soccer game. We first trained individual skills in isolation and then composed those skills end-to-end in a self-play setting. The resulting policy exhibits robust and dynamic movement skills such as rapid fall recovery, walking, turning, kicking and more; and transitions between them in a smooth, stable, and efficient manner - well beyond what is intuitively expected from the robot. The agents also developed a basic strategic understanding of the game, and learned, for instance, to anticipate ball movements and to block opponent shots. The full range of behaviors emerged from a small set of simple rewards. Our agents were trained in simula",
    "link": "http://arxiv.org/abs/2304.13653",
    "context": "Title: Learning Agile Soccer Skills for a Bipedal Robot with Deep Reinforcement Learning. (arXiv:2304.13653v1 [cs.RO])\nAbstract: We investigate whether Deep Reinforcement Learning (Deep RL) is able to synthesize sophisticated and safe movement skills for a low-cost, miniature humanoid robot that can be composed into complex behavioral strategies in dynamic environments. We used Deep RL to train a humanoid robot with 20 actuated joints to play a simplified one-versus-one (1v1) soccer game. We first trained individual skills in isolation and then composed those skills end-to-end in a self-play setting. The resulting policy exhibits robust and dynamic movement skills such as rapid fall recovery, walking, turning, kicking and more; and transitions between them in a smooth, stable, and efficient manner - well beyond what is intuitively expected from the robot. The agents also developed a basic strategic understanding of the game, and learned, for instance, to anticipate ball movements and to block opponent shots. The full range of behaviors emerged from a small set of simple rewards. Our agents were trained in simula",
    "path": "papers/23/04/2304.13653.json",
    "total_tokens": 951,
    "translated_abstract": "本研究调查了深度强化学习是否能够为成本低廉、小型人形机器人合成复杂而安全的运动技能，并将其组合成复杂的行为策略用于动态环境中。我们使用深度强化学习来训练一个具有20个活动关节的人形机器人，在简化的1v1足球比赛中进行学习。我们首先独立地训练单个技能，然后在自我对抗学习中将这些技能组合起来。结果产生了一个具有鲁棒性和动态运动技能的策略，例如快速的摔倒恢复、行走、转向、踢球等，并以平稳、稳定和高效的方式在它们之间转换，超出了机器人的预期。代理还发展出了对游戏的基本战略理解，并学会了预测球的运动和阻挡对手进攻。所有这些行为都是从简单的奖励机制中产生的。我们的代理在模拟中进行了训练。",
    "tldr": "本研究使用深度强化学习训练了一个双足机器人，在简化的1v1足球比赛中学习并成功地合成了多个灵活、鲁棒和动态的运动技能以及基本战略理解。",
    "en_tdlr": "This study uses deep reinforcement learning to train a bipedal robot to learn and successfully synthesize multiple flexible, robust, and dynamic movement skills as well as basic strategic understanding in a simplified 1v1 soccer game."
}