{
    "title": "Testing the Reliability of ChatGPT for Text Annotation and Classification: A Cautionary Remark. (arXiv:2304.11085v1 [cs.CL])",
    "abstract": "Recent studies have demonstrated promising potential of ChatGPT for various text annotation and classification tasks. However, ChatGPT is non-deterministic which means that, as with human coders, identical input can lead to different outputs. Given this, it seems appropriate to test the reliability of ChatGPT. Therefore, this study investigates the consistency of ChatGPT's zero-shot capabilities for text annotation and classification, focusing on different model parameters, prompt variations, and repetitions of identical inputs. Based on the real-world classification task of differentiating website texts into news and not news, results show that consistency in ChatGPT's classification output can fall short of scientific thresholds for reliability. For example, even minor wording alterations in prompts or repeating the identical input can lead to varying outputs. Although pooling outputs from multiple repetitions can improve reliability, this study advises caution when using ChatGPT for",
    "link": "http://arxiv.org/abs/2304.11085",
    "context": "Title: Testing the Reliability of ChatGPT for Text Annotation and Classification: A Cautionary Remark. (arXiv:2304.11085v1 [cs.CL])\nAbstract: Recent studies have demonstrated promising potential of ChatGPT for various text annotation and classification tasks. However, ChatGPT is non-deterministic which means that, as with human coders, identical input can lead to different outputs. Given this, it seems appropriate to test the reliability of ChatGPT. Therefore, this study investigates the consistency of ChatGPT's zero-shot capabilities for text annotation and classification, focusing on different model parameters, prompt variations, and repetitions of identical inputs. Based on the real-world classification task of differentiating website texts into news and not news, results show that consistency in ChatGPT's classification output can fall short of scientific thresholds for reliability. For example, even minor wording alterations in prompts or repeating the identical input can lead to varying outputs. Although pooling outputs from multiple repetitions can improve reliability, this study advises caution when using ChatGPT for",
    "path": "papers/23/04/2304.11085.json",
    "total_tokens": 891,
    "translated_title": "对ChatGPT用于文本标注和分类的可靠性进行测试——一个警告性的说明。",
    "translated_abstract": "最近的研究表明，ChatGPT在各种文本标注和分类任务中具有很大的潜力。然而，ChatGPT是非确定性的，这意味着与人类编码器一样，相同的输入可能导致不同的输出。鉴于此，测试ChatGPT的可靠性似乎是恰当的。因此，本研究调查了ChatGPT在文本标注和分类中的零-shot能力的一致性，重点关注不同的模型参数、提示变化和相同输入的重复。基于对将网站文本区分为新闻和非新闻的实际分类任务，结果显示，ChatGPT的分类输出一致性可能不足以满足科学可靠性的阈值。例如，提示中即使进行微小的措辞改变或重复相同的输入也会导致输出不同。虽然从多次重复的输出中汇总可以提高可靠性，但本研究建议在使用ChatGPT进行文本标注和分类时要谨慎。",
    "tldr": "本研究测试了ChatGPT在文本标注和分类中的可靠性，结果显示输出的一致性不足以满足科学可靠性的阈值，因此使用ChatGPT时需要谨慎。",
    "en_tdlr": "This paper tests the reliability of ChatGPT for text annotation and classification, and finds that its output consistency may fall short of scientific thresholds for reliability, leading to caution when using ChatGPT."
}