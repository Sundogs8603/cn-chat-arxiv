{
    "title": "Divide and Prompt: Chain of Thought Prompting for Text-to-SQL. (arXiv:2304.11556v1 [cs.CL])",
    "abstract": "Chain-of-thought (CoT) prompting combined with large language models (LLMs) have achieved encouraging results on complex reasoning tasks. Text-to-SQL is a critical semantic parsing task that converts natural language questions into SQL statements, involving a complex reasoning process. However, there is little work about using CoT prompting to activate LLM's reasoning capabilities on Text-to-SQL tasks. In this work, we propose a new paradigm for prompting Text-to-SQL tasks, called Divide-and-Prompt, which first divides the task into subtasks, and then approach each subtask through CoT. We present 3 prompting-based methods to enhance the Text-to-SQL ability of LLMs. Experiments show that these prompts guide LLMs to generate Text-to-SQL with higher execution accuracy.",
    "link": "http://arxiv.org/abs/2304.11556",
    "context": "Title: Divide and Prompt: Chain of Thought Prompting for Text-to-SQL. (arXiv:2304.11556v1 [cs.CL])\nAbstract: Chain-of-thought (CoT) prompting combined with large language models (LLMs) have achieved encouraging results on complex reasoning tasks. Text-to-SQL is a critical semantic parsing task that converts natural language questions into SQL statements, involving a complex reasoning process. However, there is little work about using CoT prompting to activate LLM's reasoning capabilities on Text-to-SQL tasks. In this work, we propose a new paradigm for prompting Text-to-SQL tasks, called Divide-and-Prompt, which first divides the task into subtasks, and then approach each subtask through CoT. We present 3 prompting-based methods to enhance the Text-to-SQL ability of LLMs. Experiments show that these prompts guide LLMs to generate Text-to-SQL with higher execution accuracy.",
    "path": "papers/23/04/2304.11556.json",
    "total_tokens": 782,
    "translated_title": "分而治之，思维链指导下的Text-to-SQL",
    "translated_abstract": "链式思维与大型语言模型结合已在复杂推理任务上取得了令人鼓舞的结果。Text-to-SQL是一个将自然语言问题转换为SQL语句的关键语义分析任务，涉及复杂的推理过程。然而，很少有研究使用思维链指导来激活LLM在Text-to-SQL任务中的推理能力。本文提出了一个新的Text-to-SQL提示方法的范式，称为分而治之，通过先将任务分解为子任务，然后通过思维链逐个解决子任务。我们提出了3种基于提示的方法来增强LLM的Text-to-SQL能力。实验证明，这些提示引导LLM生成具有更高执行准确性的Text-to-SQL。",
    "tldr": "本文通过思维链逐个解决子任务的方式，提出了一种新的Text-to-SQL提示方法的范例，运用于LLM模型可以有效地提高其执行准确性。",
    "en_tdlr": "This paper proposes a new paradigm for prompting Text-to-SQL tasks, called Divide-and-Prompt, which uses chain-of-thought prompting to activate LLM's reasoning capabilities on Text-to-SQL tasks. The experiments show that these prompts guide LLMs to generate Text-to-SQL with higher execution accuracy."
}