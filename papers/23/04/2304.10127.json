{
    "title": "Learning Sample Difficulty from Pre-trained Models for Reliable Prediction. (arXiv:2304.10127v1 [cs.LG])",
    "abstract": "Large-scale pre-trained models have achieved remarkable success in a variety of scenarios and applications, but how to leverage them to improve the prediction reliability of downstream models is undesirably under-explored. Moreover, modern neural networks have been found to be poorly calibrated and make overconfident predictions regardless of inherent sample difficulty and data uncertainty. To address this issue, we propose to utilize large-scale pre-trained models to guide downstream model training with sample difficulty-aware entropy regularization. Pre-trained models that have been exposed to large-scale datasets and do not overfit the downstream training classes enable us to measure each training sample difficulty via feature-space Gaussian modeling and relative Mahalanobis distance computation. Importantly, by adaptively penalizing overconfident prediction based on the sample's difficulty, we simultaneously improve accuracy and uncertainty calibration on various challenging benchm",
    "link": "http://arxiv.org/abs/2304.10127",
    "context": "Title: Learning Sample Difficulty from Pre-trained Models for Reliable Prediction. (arXiv:2304.10127v1 [cs.LG])\nAbstract: Large-scale pre-trained models have achieved remarkable success in a variety of scenarios and applications, but how to leverage them to improve the prediction reliability of downstream models is undesirably under-explored. Moreover, modern neural networks have been found to be poorly calibrated and make overconfident predictions regardless of inherent sample difficulty and data uncertainty. To address this issue, we propose to utilize large-scale pre-trained models to guide downstream model training with sample difficulty-aware entropy regularization. Pre-trained models that have been exposed to large-scale datasets and do not overfit the downstream training classes enable us to measure each training sample difficulty via feature-space Gaussian modeling and relative Mahalanobis distance computation. Importantly, by adaptively penalizing overconfident prediction based on the sample's difficulty, we simultaneously improve accuracy and uncertainty calibration on various challenging benchm",
    "path": "papers/23/04/2304.10127.json",
    "total_tokens": 885,
    "translated_title": "从预训练模型中学习样本难度以提高模型可靠性",
    "translated_abstract": "大规模的预训练模型在各种场景和应用中取得了显著的成功，但如何利用它们来提高下游模型的预测可靠性仍未得到充分探索。此外，现代神经网络发现在固有样本难度和数据不确定性方面表现不佳，做出过于自信的预测。为了解决这个问题，我们提出使用大规模预训练模型以样本难度感知的熵正则化来指导下游模型的训练。预训练模型通过大规模数据集的训练，不会过度拟合下游训练集，使我们能够通过特征空间高斯建模和相对马氏距离的计算来测量每个训练样本的难度。重要的是，通过根据样本的难度自适应地惩罚过于自信的预测，我们同时提高各种具有挑战性的基准测试上的准确性和不确定性校准。",
    "tldr": "该论文介绍了如何使用预训练模型通过熵正则化来计算训练样本的难度，并根据样本难度惩罚过于自信的预测，从而提高模型的准确性和不确定性校准。"
}