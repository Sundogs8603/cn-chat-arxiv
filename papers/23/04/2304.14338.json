{
    "title": "An Audit Framework for Adopting AI-Nudging on Children. (arXiv:2304.14338v1 [cs.CY])",
    "abstract": "This is an audit framework for AI-nudging. Unlike the static form of nudging usually discussed in the literature, we focus here on a type of nudging that uses large amounts of data to provide personalized, dynamic feedback and interfaces. We call this AI-nudging (Lanzing, 2019, p. 549; Yeung, 2017). The ultimate goal of the audit outlined here is to ensure that an AI system that uses nudges will maintain a level of moral inertia and neutrality by complying with the recommendations, requirements, or suggestions of the audit (in other words, the criteria of the audit). In the case of unintended negative consequences, the audit suggests risk mitigation mechanisms that can be put in place. In the case of unintended positive consequences, it suggests some reinforcement mechanisms. Sponsored by the IBM-Notre Dame Tech Ethics Lab",
    "link": "http://arxiv.org/abs/2304.14338",
    "context": "Title: An Audit Framework for Adopting AI-Nudging on Children. (arXiv:2304.14338v1 [cs.CY])\nAbstract: This is an audit framework for AI-nudging. Unlike the static form of nudging usually discussed in the literature, we focus here on a type of nudging that uses large amounts of data to provide personalized, dynamic feedback and interfaces. We call this AI-nudging (Lanzing, 2019, p. 549; Yeung, 2017). The ultimate goal of the audit outlined here is to ensure that an AI system that uses nudges will maintain a level of moral inertia and neutrality by complying with the recommendations, requirements, or suggestions of the audit (in other words, the criteria of the audit). In the case of unintended negative consequences, the audit suggests risk mitigation mechanisms that can be put in place. In the case of unintended positive consequences, it suggests some reinforcement mechanisms. Sponsored by the IBM-Notre Dame Tech Ethics Lab",
    "path": "papers/23/04/2304.14338.json",
    "total_tokens": 778,
    "translated_title": "采用AI-Nudging对儿童进行审计的框架",
    "translated_abstract": "本文提出了一种AI-nudging的审计框架。与文献中通常讨论的静态\"nudging\"形式不同，我们在这里专注于一种使用大量数据来提供个性化、动态反馈和界面的nudging类型。我们将其称为AI-nudging。该审计的最终目标是确保使用nudges的AI系统通过遵守审计的建议、要求或建议（换句话说，审计的标准）保持一种道德惯性和中立性。在意外的负面影响的情况下，审计建议设置风险缓解机制。在意外的正面影响情况下，它建议一些强化机制。该研究由IBM-Notre Dame Tech Ethics Lab赞助。",
    "tldr": "本文提出了一个AI-nudging审计框架，以确保使用nudges的AI系统保持道德惯性和中立性。该框架包括风险缓解和强化机制。",
    "en_tdlr": "This paper proposes an audit framework for AI-nudging to ensure that AI systems that use nudges maintain moral inertia and neutrality. The framework includes risk mitigation and reinforcement mechanisms."
}