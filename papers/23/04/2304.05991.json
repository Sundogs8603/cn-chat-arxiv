{
    "title": "Maximum-likelihood Estimators in Physics-Informed Neural Networks for High-dimensional Inverse Problems. (arXiv:2304.05991v1 [cs.LG])",
    "abstract": "Physics-informed neural networks (PINNs) have proven a suitable mathematical scaffold for solving inverse ordinary (ODE) and partial differential equations (PDE). Typical inverse PINNs are formulated as soft-constrained multi-objective optimization problems with several hyperparameters. In this work, we demonstrate that inverse PINNs can be framed in terms of maximum-likelihood estimators (MLE) to allow explicit error propagation from interpolation to the physical model space through Taylor expansion, without the need of hyperparameter tuning. We explore its application to high-dimensional coupled ODEs constrained by differential algebraic equations that are common in transient chemical and biological kinetics. Furthermore, we show that singular-value decomposition (SVD) of the ODE coupling matrices (reaction stoichiometry matrix) provides reduced uncorrelated subspaces in which PINNs solutions can be represented and over which residuals can be projected. Finally, SVD bases serve as pr",
    "link": "http://arxiv.org/abs/2304.05991",
    "context": "Title: Maximum-likelihood Estimators in Physics-Informed Neural Networks for High-dimensional Inverse Problems. (arXiv:2304.05991v1 [cs.LG])\nAbstract: Physics-informed neural networks (PINNs) have proven a suitable mathematical scaffold for solving inverse ordinary (ODE) and partial differential equations (PDE). Typical inverse PINNs are formulated as soft-constrained multi-objective optimization problems with several hyperparameters. In this work, we demonstrate that inverse PINNs can be framed in terms of maximum-likelihood estimators (MLE) to allow explicit error propagation from interpolation to the physical model space through Taylor expansion, without the need of hyperparameter tuning. We explore its application to high-dimensional coupled ODEs constrained by differential algebraic equations that are common in transient chemical and biological kinetics. Furthermore, we show that singular-value decomposition (SVD) of the ODE coupling matrices (reaction stoichiometry matrix) provides reduced uncorrelated subspaces in which PINNs solutions can be represented and over which residuals can be projected. Finally, SVD bases serve as pr",
    "path": "papers/23/04/2304.05991.json",
    "total_tokens": 895,
    "translated_title": "物理信息神经网络中的最大似然估计器用于高维反问题求解",
    "translated_abstract": "物理信息神经网络(PINNs)已被证明是解决反常(ODE)和偏微分方程(PDE)的合适数学框架。典型的反向PINNs被制定为带有几个超参数的软约束多目标优化问题。在本文中，我们证明反向PINNs可以用极大似然估计器(MLE)的形式来表达，通过Taylor展开，将插值误差明确地传播到物理模型空间中，而无需进行超参数调整。我们探讨了其应用于高维耦合ODEs的情况，这些ODEs受到在瞬态化学和生物动力学中常见的微分代数方程的限制。此外，我们还展示了ODE耦合矩阵(反应化学计量矩阵)的奇异值分解(SVD)提供了减少的不相关子空间，在其中可以表示PINNs解，并可以对残差进行投影。最后，SVD基函数作为先验约束增强了预测的稳定性和泛化能力。",
    "tldr": "本论文提出了在PINNs中使用MLE的方法，消除了超参数调整。通过ODE耦合矩阵的SVD分解降维，增加了PINNs预测的稳定性和泛化能力。",
    "en_tdlr": "This paper proposes the use of MLE in PINNs to eliminate hyperparameter tuning. By decomposing the ODE coupling matrix using SVD, the stability and generalization ability of PINNs predictions are enhanced through dimensionality reduction."
}