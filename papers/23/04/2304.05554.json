{
    "title": "Learning Transferable Pedestrian Representation from Multimodal Information Supervision. (arXiv:2304.05554v1 [cs.CV])",
    "abstract": "Recent researches on unsupervised person re-identification~(reID) have demonstrated that pre-training on unlabeled person images achieves superior performance on downstream reID tasks than pre-training on ImageNet. However, those pre-trained methods are specifically designed for reID and suffer flexible adaption to other pedestrian analysis tasks. In this paper, we propose VAL-PAT, a novel framework that learns transferable representations to enhance various pedestrian analysis tasks with multimodal information. To train our framework, we introduce three learning objectives, \\emph{i.e.,} self-supervised contrastive learning, image-text contrastive learning and multi-attribute classification. The self-supervised contrastive learning facilitates the learning of the intrinsic pedestrian properties, while the image-text contrastive learning guides the model to focus on the appearance information of pedestrians.Meanwhile, multi-attribute classification encourages the model to recognize attr",
    "link": "http://arxiv.org/abs/2304.05554",
    "context": "Title: Learning Transferable Pedestrian Representation from Multimodal Information Supervision. (arXiv:2304.05554v1 [cs.CV])\nAbstract: Recent researches on unsupervised person re-identification~(reID) have demonstrated that pre-training on unlabeled person images achieves superior performance on downstream reID tasks than pre-training on ImageNet. However, those pre-trained methods are specifically designed for reID and suffer flexible adaption to other pedestrian analysis tasks. In this paper, we propose VAL-PAT, a novel framework that learns transferable representations to enhance various pedestrian analysis tasks with multimodal information. To train our framework, we introduce three learning objectives, \\emph{i.e.,} self-supervised contrastive learning, image-text contrastive learning and multi-attribute classification. The self-supervised contrastive learning facilitates the learning of the intrinsic pedestrian properties, while the image-text contrastive learning guides the model to focus on the appearance information of pedestrians.Meanwhile, multi-attribute classification encourages the model to recognize attr",
    "path": "papers/23/04/2304.05554.json",
    "total_tokens": 865,
    "translated_title": "从多模态信息监督中学习可转移的行人表示",
    "translated_abstract": "最近的无监督人物重新识别(reID)研究表明，在未标记的人物图像上预训练比在ImageNet上预训练对下游reID任务的性能产生更好的效果。然而，这些预先训练的方法是为reID专门设计的，并且对于其他行人分析任务的灵活适应存在困难。本文提出了一种新的框架VAL-PAT，它学习可转移的表示，以多模态信息增强各种行人分析任务。为了训练我们的框架，我们引入了三个学习目标，即自我监督对比学习、图像-文本对比学习和多属性分类。自我监督的对比学习有助于学习固有的行人特性，而图像-文本对比学习指导模型关注行人的外观信息。同时，多属性分类鼓励模型识别属性。",
    "tldr": "本文提出了一种新框架VAL-PAT，在多模态信息的监督下学习可转移的行人表示，以增强各种行人分析任务，其中包括自我监督对比学习、图像-文本对比学习和多属性分类。",
    "en_tdlr": "This paper proposes a novel framework VAL-PAT for learning transferable pedestrian representations from multimodal information supervision to enhance various pedestrian analysis tasks, with self-supervised contrastive learning, image-text contrastive learning, and multi-attribute classification."
}