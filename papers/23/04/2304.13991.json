{
    "title": "Vision Conformer: Incorporating Convolutions into Vision Transformer Layers. (arXiv:2304.13991v1 [cs.CV])",
    "abstract": "Transformers are popular neural network models that use layers of self-attention and fully-connected nodes with embedded tokens. Vision Transformers (ViT) adapt transformers for image recognition tasks. In order to do this, the images are split into patches and used as tokens. One issue with ViT is the lack of inductive bias toward image structures. Because ViT was adapted for image data from language modeling, the network does not explicitly handle issues such as local translations, pixel information, and information loss in the structures and features shared by multiple patches. Conversely, Convolutional Neural Networks (CNN) incorporate this information. Thus, in this paper, we propose the use of convolutional layers within ViT. Specifically, we propose a model called a Vision Conformer (ViC) which replaces the Multi-Layer Perceptron (MLP) in a ViT layer with a CNN. In addition, to use the CNN, we proposed to reconstruct the image data after the self-attention in a reverse embedding",
    "link": "http://arxiv.org/abs/2304.13991",
    "context": "Title: Vision Conformer: Incorporating Convolutions into Vision Transformer Layers. (arXiv:2304.13991v1 [cs.CV])\nAbstract: Transformers are popular neural network models that use layers of self-attention and fully-connected nodes with embedded tokens. Vision Transformers (ViT) adapt transformers for image recognition tasks. In order to do this, the images are split into patches and used as tokens. One issue with ViT is the lack of inductive bias toward image structures. Because ViT was adapted for image data from language modeling, the network does not explicitly handle issues such as local translations, pixel information, and information loss in the structures and features shared by multiple patches. Conversely, Convolutional Neural Networks (CNN) incorporate this information. Thus, in this paper, we propose the use of convolutional layers within ViT. Specifically, we propose a model called a Vision Conformer (ViC) which replaces the Multi-Layer Perceptron (MLP) in a ViT layer with a CNN. In addition, to use the CNN, we proposed to reconstruct the image data after the self-attention in a reverse embedding",
    "path": "papers/23/04/2304.13991.json",
    "total_tokens": 878,
    "translated_title": "Vision Conformer: 将卷积融入视觉Transformer层",
    "translated_abstract": "Transformer是流行的神经网络模型，使用自注意力层和嵌入式令牌的全连接节点层。视觉Transformer（ViT）将Transformer用于图像识别任务。为了实现这一点，图像被分成补丁并用作令牌。ViT的一个问题是缺乏对图像结构的归纳偏差。因为ViT是从语言建模的图像数据进行改编的，所以网络不能直接处理局部平移、像素信息以及多个补丁共享的结构和特征中的信息损失。相反，卷积神经网络（CNN）则包含了这些信息。因此，在本文中，我们提出在ViT中使用卷积层。具体而言，我们提出了一个名为视觉Conformer（ViC）的模型，它将ViT层中的多层感知机（MLP）替换为CNN。此外，为了使用CNN，我们提出在自我注意力之后反向嵌入重建图像数据。",
    "tldr": "本文提出一种名为ViC的模型，通过在ViT层中使用卷积层来解决ViT缺乏图像结构归纳偏差的问题，改进了图像识别任务的效果。",
    "en_tdlr": "This paper proposes a model called ViC to incorporate convolutional layers into ViT, solving the problem of the lack of inductive bias towards image structures, and improving the effectiveness of image recognition tasks."
}