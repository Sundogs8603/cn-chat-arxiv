{
    "title": "SEA: A Spatially Explicit Architecture for Multi-Agent Reinforcement Learning. (arXiv:2304.12532v1 [cs.MA])",
    "abstract": "Spatial information is essential in various fields. How to explicitly model according to the spatial location of agents is also very important for the multi-agent problem, especially when the number of agents is changing and the scale is enormous. Inspired by the point cloud task in computer vision, we propose a spatial information extraction structure for multi-agent reinforcement learning in this paper. Agents can effectively share the neighborhood and global information through a spatially encoder-decoder structure. Our method follows the centralized training with decentralized execution (CTDE) paradigm. In addition, our structure can be applied to various existing mainstream reinforcement learning algorithms with minor modifications and can deal with the problem with a variable number of agents. The experiments in several multi-agent scenarios show that the existing methods can get convincing results by adding our spatially explicit architecture.",
    "link": "http://arxiv.org/abs/2304.12532",
    "context": "Title: SEA: A Spatially Explicit Architecture for Multi-Agent Reinforcement Learning. (arXiv:2304.12532v1 [cs.MA])\nAbstract: Spatial information is essential in various fields. How to explicitly model according to the spatial location of agents is also very important for the multi-agent problem, especially when the number of agents is changing and the scale is enormous. Inspired by the point cloud task in computer vision, we propose a spatial information extraction structure for multi-agent reinforcement learning in this paper. Agents can effectively share the neighborhood and global information through a spatially encoder-decoder structure. Our method follows the centralized training with decentralized execution (CTDE) paradigm. In addition, our structure can be applied to various existing mainstream reinforcement learning algorithms with minor modifications and can deal with the problem with a variable number of agents. The experiments in several multi-agent scenarios show that the existing methods can get convincing results by adding our spatially explicit architecture.",
    "path": "papers/23/04/2304.12532.json",
    "total_tokens": 834,
    "translated_title": "SEA: 用于多智能体强化学习的空间显式体系结构",
    "translated_abstract": "空间信息在许多领域中都十分重要。针对多智能体问题，如何根据代理的空间位置显式建模也非常重要，尤其是当代理数量变化和规模巨大时。本文受计算机视觉中点云任务的启发，提出了一种用于多智能体强化学习的空间信息提取结构。代理可以通过空间编码器-解码器结构有效地共享邻域和全局信息。我们的方法遵循中心化训练、去中心化执行（CTDE）范式。此外，我们的结构可以应用于各种现有的主流强化学习算法，并能够处理具有可变代理数量的问题。在几个多智能体场景的实验中，通过添加我们的空间显式体系结构，现有方法可以得到令人信服的结果。",
    "tldr": "论文提出了一种针对多智能体问题的空间信息提取结构，能有效地共享邻域和全局信息，并能够处理具有可变代理数量的问题。实验结果表明该结构可以提升现有的强化学习算法的效果。",
    "en_tdlr": "The paper proposes a spatial information extraction structure for the multi-agent reinforcement learning problem, which effectively shares neighborhood and global information and can handle variable numbers of agents. Experimental results show that the structure can improve the performance of existing reinforcement learning algorithms."
}