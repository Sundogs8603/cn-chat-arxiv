{
    "title": "Automaton-Guided Curriculum Generation for Reinforcement Learning Agents. (arXiv:2304.05271v1 [cs.AI])",
    "abstract": "Despite advances in Reinforcement Learning, many sequential decision making tasks remain prohibitively expensive and impractical to learn. Recently, approaches that automatically generate reward functions from logical task specifications have been proposed to mitigate this issue; however, they scale poorly on long-horizon tasks (i.e., tasks where the agent needs to perform a series of correct actions to reach the goal state, considering future transitions while choosing an action). Employing a curriculum (a sequence of increasingly complex tasks) further improves the learning speed of the agent by sequencing intermediate tasks suited to the learning capacity of the agent. However, generating curricula from the logical specification still remains an unsolved problem. To this end, we propose AGCL, Automaton-guided Curriculum Learning, a novel method for automatically generating curricula for the target task in the form of Directed Acyclic Graphs (DAGs). AGCL encodes the specification in ",
    "link": "http://arxiv.org/abs/2304.05271",
    "context": "Title: Automaton-Guided Curriculum Generation for Reinforcement Learning Agents. (arXiv:2304.05271v1 [cs.AI])\nAbstract: Despite advances in Reinforcement Learning, many sequential decision making tasks remain prohibitively expensive and impractical to learn. Recently, approaches that automatically generate reward functions from logical task specifications have been proposed to mitigate this issue; however, they scale poorly on long-horizon tasks (i.e., tasks where the agent needs to perform a series of correct actions to reach the goal state, considering future transitions while choosing an action). Employing a curriculum (a sequence of increasingly complex tasks) further improves the learning speed of the agent by sequencing intermediate tasks suited to the learning capacity of the agent. However, generating curricula from the logical specification still remains an unsolved problem. To this end, we propose AGCL, Automaton-guided Curriculum Learning, a novel method for automatically generating curricula for the target task in the form of Directed Acyclic Graphs (DAGs). AGCL encodes the specification in ",
    "path": "papers/23/04/2304.05271.json",
    "total_tokens": 1096,
    "translated_title": "自动机引导下的强化学习代理课程生成",
    "translated_abstract": "尽管强化学习取得了进展，但许多顺序决策任务仍然难以学习且成本高昂。最近，提出了从逻辑任务规范自动生成奖励函数的方法来缓解这个问题；然而，它们在长时间跨度任务（即代理人需要执行一系列正确的操作以达到目标状态，同时在选择动作时考虑未来的过渡）上的扩展性仍然很差。利用课程（一系列逐渐复杂的任务）进一步提高代理人的学习速度，通过对适合代理人学习能力的中间任务进行序列化。然而，从逻辑规范生成课程仍然是一个尚未解决的问题。为此，我们提出了AGCL，即自动导向课程学习，一种自动以DAG形式生成目标任务课程的新方法。AGCL将规范编码为确定性自动机，探索其中的重复子结构，并通过将这些结构分解为DAG来生成课程。我们在离散和连续控制任务上评估了我们的方法，并将其与现有方法进行了比较。我们的结果表明，AGCL始终优于所有基线方法，并且能够与没有进行课程的方法相比，提供高达5倍的快速学习。",
    "tldr": "提出了自动机引导下的强化学习代理课程生成方法，能够自动生成逐渐递增的适合代理学习的中间任务序列，并能在离散和连续控制任务上比现有方法提供高达5倍的快速学习。",
    "en_tdlr": "AGCL is a novel method for automatically generating a curriculum of increasingly complex tasks suitable for a Reinforcement Learning agent's learning capacity by encoding the task specification into a deterministic automaton and decomposing repetitive substructures into Directed Acyclic Graphs (DAGs), which outperforms all baseline methods and can deliver up to 5x faster learning on both discrete and continuous control tasks."
}