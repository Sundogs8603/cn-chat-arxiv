{
    "title": "Token Imbalance Adaptation for Radiology Report Generation. (arXiv:2304.09185v1 [cs.CL])",
    "abstract": "Imbalanced token distributions naturally exist in text documents, leading neural language models to overfit on frequent tokens. The token imbalance may dampen the robustness of radiology report generators, as complex medical terms appear less frequently but reflect more medical information. In this study, we demonstrate how current state-of-the-art models fail to generate infrequent tokens on two standard benchmark datasets (IU X-RAY and MIMIC-CXR) of radiology report generation. % However, no prior study has proposed methods to adapt infrequent tokens for text generators feeding with medical images. To solve the challenge, we propose the \\textbf{T}oken \\textbf{Im}balance Adapt\\textbf{er} (\\textit{TIMER}), aiming to improve generation robustness on infrequent tokens. The model automatically leverages token imbalance by an unlikelihood loss and dynamically optimizes generation processes to augment infrequent tokens. We compare our approach with multiple state-of-the-art methods on the t",
    "link": "http://arxiv.org/abs/2304.09185",
    "context": "Title: Token Imbalance Adaptation for Radiology Report Generation. (arXiv:2304.09185v1 [cs.CL])\nAbstract: Imbalanced token distributions naturally exist in text documents, leading neural language models to overfit on frequent tokens. The token imbalance may dampen the robustness of radiology report generators, as complex medical terms appear less frequently but reflect more medical information. In this study, we demonstrate how current state-of-the-art models fail to generate infrequent tokens on two standard benchmark datasets (IU X-RAY and MIMIC-CXR) of radiology report generation. % However, no prior study has proposed methods to adapt infrequent tokens for text generators feeding with medical images. To solve the challenge, we propose the \\textbf{T}oken \\textbf{Im}balance Adapt\\textbf{er} (\\textit{TIMER}), aiming to improve generation robustness on infrequent tokens. The model automatically leverages token imbalance by an unlikelihood loss and dynamically optimizes generation processes to augment infrequent tokens. We compare our approach with multiple state-of-the-art methods on the t",
    "path": "papers/23/04/2304.09185.json",
    "total_tokens": 802,
    "translated_abstract": "在文本文档中，标记分布的不平衡自然存在，导致神经语言模型过分拟合常见标记。标记不平衡可能会削弱放射学报告生成器的鲁棒性，因为复杂的医学术语出现较少，却反映更多的医学信息。本研究在放射学报告生成的两个标准基准数据集（IU X-RAY和MIMIC-CXR）上演示了当前最先进模型在生成不常见标记方面失败的情况。为了解决这一挑战，我们提出了Token Imbalance Adapter（TIMER），旨在通过不合理的损失自动利用标记不平衡，并动态优化生成过程来增强不经常出现的标记。",
    "tldr": "本研究提出的TIMER模型通过不合理损失及动态优化生成过程的方法，增强了放射学报告生成器在处理不经常出现的标记时的鲁棒性。",
    "en_tdlr": "The TIMER model proposed in this study improves the robustness of radiology report generators in dealing with infrequent tokens through the method of unlikely losses and dynamically optimized generation processes."
}