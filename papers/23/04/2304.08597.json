{
    "title": "eTOP: Early Termination of Pipelines for Faster Training of AutoML Systems. (arXiv:2304.08597v1 [cs.LG])",
    "abstract": "Recent advancements in software and hardware technologies have enabled the use of AI/ML models in everyday applications has significantly improved the quality of service rendered. However, for a given application, finding the right AI/ML model is a complex and costly process, that involves the generation, training, and evaluation of multiple interlinked steps (called pipelines), such as data pre-processing, feature engineering, selection, and model tuning. These pipelines are complex (in structure) and costly (both in compute resource and time) to execute end-to-end, with a hyper-parameter associated with each step. AutoML systems automate the search of these hyper-parameters but are slow, as they rely on optimizing the pipeline's end output. We propose the eTOP Framework which works on top of any AutoML system and decides whether or not to execute the pipeline to the end or terminate at an intermediate step. Experimental evaluation on 26 benchmark datasets and integration of eTOPwith ",
    "link": "http://arxiv.org/abs/2304.08597",
    "context": "Title: eTOP: Early Termination of Pipelines for Faster Training of AutoML Systems. (arXiv:2304.08597v1 [cs.LG])\nAbstract: Recent advancements in software and hardware technologies have enabled the use of AI/ML models in everyday applications has significantly improved the quality of service rendered. However, for a given application, finding the right AI/ML model is a complex and costly process, that involves the generation, training, and evaluation of multiple interlinked steps (called pipelines), such as data pre-processing, feature engineering, selection, and model tuning. These pipelines are complex (in structure) and costly (both in compute resource and time) to execute end-to-end, with a hyper-parameter associated with each step. AutoML systems automate the search of these hyper-parameters but are slow, as they rely on optimizing the pipeline's end output. We propose the eTOP Framework which works on top of any AutoML system and decides whether or not to execute the pipeline to the end or terminate at an intermediate step. Experimental evaluation on 26 benchmark datasets and integration of eTOPwith ",
    "path": "papers/23/04/2304.08597.json",
    "total_tokens": 847,
    "translated_title": "eTOP：用于更快地训练AutoML系统的管道提前终止",
    "translated_abstract": "软件和硬件技术的最新进展使得AI/ML模型可以应用到日常应用中，极大地提高了所提供服务的质量。但是对于给定的应用程序，找到合适的AI/ML模型是一个复杂而昂贵的过程，涉及多个相互关联的步骤（称为管道），如数据预处理、特征工程、选择和模型调整的生成、训练和评估等。这些管道在结构上是复杂的，在计算资源和时间上都很昂贵，并与每个步骤相关联。AutoML系统自动搜索这些超参数，但速度很慢，因为它们依赖于管道的最终输出进行优化。我们提出了eTOP框架，它可以在任何AutoML系统之上工作，并决定是否将管道执行到最后或在中间步骤终止。在26个基准数据集上的实验评估以及eTOP与",
    "tldr": "eTOP框架可以在任何AutoML系统之上工作，并决定是否将执行管道到最后或在中间步骤终止以更快地训练模型。"
}