{
    "title": "Self-training with dual uncertainty for semi-supervised medical image segmentation. (arXiv:2304.04441v1 [cs.CV])",
    "abstract": "In the field of semi-supervised medical image segmentation, the shortage of labeled data is the fundamental problem. How to effectively learn image features from unlabeled images to improve segmentation accuracy is the main research direction in this field. Traditional self-training methods can partially solve the problem of insufficient labeled data by generating pseudo labels for iterative training. However, noise generated due to the model's uncertainty during training directly affects the segmentation results. Therefore, we added sample-level and pixel-level uncertainty to stabilize the training process based on the self-training framework. Specifically, we saved several moments of the model during pre-training, and used the difference between their predictions on unlabeled samples as the sample-level uncertainty estimate for that sample. Then, we gradually add unlabeled samples from easy to hard during training. At the same time, we added a decoder with different upsampling method",
    "link": "http://arxiv.org/abs/2304.04441",
    "context": "Title: Self-training with dual uncertainty for semi-supervised medical image segmentation. (arXiv:2304.04441v1 [cs.CV])\nAbstract: In the field of semi-supervised medical image segmentation, the shortage of labeled data is the fundamental problem. How to effectively learn image features from unlabeled images to improve segmentation accuracy is the main research direction in this field. Traditional self-training methods can partially solve the problem of insufficient labeled data by generating pseudo labels for iterative training. However, noise generated due to the model's uncertainty during training directly affects the segmentation results. Therefore, we added sample-level and pixel-level uncertainty to stabilize the training process based on the self-training framework. Specifically, we saved several moments of the model during pre-training, and used the difference between their predictions on unlabeled samples as the sample-level uncertainty estimate for that sample. Then, we gradually add unlabeled samples from easy to hard during training. At the same time, we added a decoder with different upsampling method",
    "path": "papers/23/04/2304.04441.json",
    "total_tokens": 864,
    "translated_title": "双重不确定性自训练用于半监督医学图像分割",
    "translated_abstract": "在半监督医学图像分割领域中，标记数据短缺是一个根本性问题。如何有效地从未标记的图像中学习图像特征以提高分割精度是这一领域的主要研究方向。传统的自训练方法可以通过为迭代训练生成伪标签部分解决标记数据不足的问题。然而，在训练过程中由模型不确定性产生的噪声直接影响了分割结果。因此，我们在自训练框架中增加了样本层面和像素层面的不确定性以稳定训练过程。具体来说，我们在预训练期间保存了模型的几个时刻，并使用它们在未标记样本上的预测之间的差异作为该样本的样本层面不确定性估计。然后，我们逐渐添加从易到难的未标记样本进行训练。同时，我们添加了一个带有不同上采样方法的解码器。",
    "tldr": "该论文介绍了在半监督医学图像分割中如何通过双重不确定性的自训练方式来提高分割精度。"
}