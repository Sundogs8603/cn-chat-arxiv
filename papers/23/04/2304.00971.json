{
    "title": "Joint 2D-3D Multi-Task Learning on Cityscapes-3D: 3D Detection, Segmentation, and Depth Estimation. (arXiv:2304.00971v2 [cs.CV] UPDATED)",
    "abstract": "This report serves as a supplementary document for TaskPrompter, detailing its implementation on a new joint 2D-3D multi-task learning benchmark based on Cityscapes-3D. TaskPrompter presents an innovative multi-task prompting framework that unifies the learning of (i) task-generic representations, (ii) task-specific representations, and (iii) cross-task interactions, as opposed to previous approaches that separate these learning objectives into different network modules. This unified approach not only reduces the need for meticulous empirical structure design but also significantly enhances the multi-task network's representation learning capability, as the entire model capacity is devoted to optimizing the three objectives simultaneously. TaskPrompter introduces a new multi-task benchmark based on Cityscapes-3D dataset, which requires the multi-task model to concurrently generate predictions for monocular 3D vehicle detection, semantic segmentation, and monocular depth estimation. The",
    "link": "http://arxiv.org/abs/2304.00971",
    "context": "Title: Joint 2D-3D Multi-Task Learning on Cityscapes-3D: 3D Detection, Segmentation, and Depth Estimation. (arXiv:2304.00971v2 [cs.CV] UPDATED)\nAbstract: This report serves as a supplementary document for TaskPrompter, detailing its implementation on a new joint 2D-3D multi-task learning benchmark based on Cityscapes-3D. TaskPrompter presents an innovative multi-task prompting framework that unifies the learning of (i) task-generic representations, (ii) task-specific representations, and (iii) cross-task interactions, as opposed to previous approaches that separate these learning objectives into different network modules. This unified approach not only reduces the need for meticulous empirical structure design but also significantly enhances the multi-task network's representation learning capability, as the entire model capacity is devoted to optimizing the three objectives simultaneously. TaskPrompter introduces a new multi-task benchmark based on Cityscapes-3D dataset, which requires the multi-task model to concurrently generate predictions for monocular 3D vehicle detection, semantic segmentation, and monocular depth estimation. The",
    "path": "papers/23/04/2304.00971.json",
    "total_tokens": 909,
    "translated_title": "基于Cityscapes-3D的联合2D-3D多任务学习：3D检测、分割和深度估计",
    "translated_abstract": "这份报告是TaskPrompter在基于Cityscapes-3D的新联合2D-3D多任务学习标准上的实现的补充文档。TaskPrompter提出了一个创新的多任务提示框架，将（i）任务通用表示、（ii）任务特定表示和（iii）跨任务交互的学习统一起来，与以往的方法将这些学习目标分别存放在不同的网络模块中相反。这种统一的方法不仅减少了对结构设计的细致经验需求，还显著增强了多任务网络的表示学习能力，因为整个模型容量都致力于同时优化这三个目标。TaskPrompter在Cityscapes-3D数据集上引入了一个新的多任务基准，要求多任务模型同时为单眼3D车辆检测、语义分割和单眼深度估计生成预测。",
    "tldr": "该论文提出了一种基于Cityscapes-3D的联合2D-3D多任务学习方法，旨在同时实现单眼3D车辆检测、语义分割和单眼深度估计，并通过优化多个目标单元，提高了模型性能。"
}