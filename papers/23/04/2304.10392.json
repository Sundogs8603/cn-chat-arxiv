{
    "title": "CKBP v2: An Expert-Annotated Evaluation Set for Commonsense Knowledge Base Population. (arXiv:2304.10392v1 [cs.CL])",
    "abstract": "Populating Commonsense Knowledge Bases (CSKB) is an important yet hard task in NLP, as it tackles knowledge from external sources with unseen events and entities. Fang et al. (2021a) proposed a CSKB Population benchmark with an evaluation set CKBP v1. However, CKBP v1 adopts crowdsourced annotations that suffer from a substantial fraction of incorrect answers, and the evaluation set is not well-aligned with the external knowledge source as a result of random sampling. In this paper, we introduce CKBP v2, a new high-quality CSKB Population benchmark, which addresses the two mentioned problems by using experts instead of crowd-sourced annotation and by adding diversified adversarial samples to make the evaluation set more representative. We conduct extensive experiments comparing state-of-the-art methods for CSKB Population on the new evaluation set for future research comparisons. Empirical results show that the population task is still challenging, even for large language models (LLM) ",
    "link": "http://arxiv.org/abs/2304.10392",
    "context": "Title: CKBP v2: An Expert-Annotated Evaluation Set for Commonsense Knowledge Base Population. (arXiv:2304.10392v1 [cs.CL])\nAbstract: Populating Commonsense Knowledge Bases (CSKB) is an important yet hard task in NLP, as it tackles knowledge from external sources with unseen events and entities. Fang et al. (2021a) proposed a CSKB Population benchmark with an evaluation set CKBP v1. However, CKBP v1 adopts crowdsourced annotations that suffer from a substantial fraction of incorrect answers, and the evaluation set is not well-aligned with the external knowledge source as a result of random sampling. In this paper, we introduce CKBP v2, a new high-quality CSKB Population benchmark, which addresses the two mentioned problems by using experts instead of crowd-sourced annotation and by adding diversified adversarial samples to make the evaluation set more representative. We conduct extensive experiments comparing state-of-the-art methods for CSKB Population on the new evaluation set for future research comparisons. Empirical results show that the population task is still challenging, even for large language models (LLM) ",
    "path": "papers/23/04/2304.10392.json",
    "total_tokens": 977,
    "translated_title": "CKBP v2：一个通识知识库填充的专家注释评估集合",
    "translated_abstract": "填充通识知识库是NLP中一个重要但困难的任务，因为它处理外部来源、未见过的事件和实体的知识。 Fang等人提出了一个通识知识库填充基准，其中包括评估集CKBP v1。但是，CKBP v1采用由众包注释，存在相当大比例的错误答案，并且由于随机抽样，评估集与外部知识来源的对齐效果不佳。在本文中，我们引入了CKBP v2，一个新的高质量的通识知识库填充基准，通过使用专家而不是众包注释，并添加多样化的对抗样本来使评估集更具代表性来解决上述两个问题。我们在新的评估集上进行了各种实验，比较了用于通识知识库填充的最新方法，以用于未来的研究比较。实证结果表明，即使对于大型语言模型（LLM），填充任务仍然具有挑战性。",
    "tldr": "本文介绍了CKBP v2, 一个使用专家注释而囊括对抗样本的高质量通识知识库填充基准，以解决CKBP v1由于众包注释和随机抽样导致的问题。实验结果表明，通识知识库填充任务对于现有技术水平仍然具有挑战性。",
    "en_tdlr": "This paper presents CKBP v2, a high-quality Commonsense Knowledge Base Population benchmark, which uses expert annotation and adversarial samples to solve the problems of CKBP v1 caused by crowdsourced annotation and random sampling. Empirical results show that the population task is still challenging, even for large language models."
}