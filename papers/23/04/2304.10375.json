{
    "title": "Interpretability for Conditional Coordinated Behavior in Multi-Agent Reinforcement Learning. (arXiv:2304.10375v1 [cs.LG])",
    "abstract": "We propose a model-free reinforcement learning architecture, called distributed attentional actor architecture after conditional attention (DA6-X), to provide better interpretability of conditional coordinated behaviors. The underlying principle involves reusing the saliency vector, which represents the conditional states of the environment, such as the global position of agents. Hence, agents with DA6-X flexibility built into their policy exhibit superior performance by considering the additional information in the conditional states during the decision-making process. The effectiveness of the proposed method was experimentally evaluated by comparing it with conventional methods in an objects collection game. By visualizing the attention weights from DA6-X, we confirmed that agents successfully learn situation-dependent coordinated behaviors by correctly identifying various conditional states, leading to improved interpretability of agents along with superior performance.",
    "link": "http://arxiv.org/abs/2304.10375",
    "context": "Title: Interpretability for Conditional Coordinated Behavior in Multi-Agent Reinforcement Learning. (arXiv:2304.10375v1 [cs.LG])\nAbstract: We propose a model-free reinforcement learning architecture, called distributed attentional actor architecture after conditional attention (DA6-X), to provide better interpretability of conditional coordinated behaviors. The underlying principle involves reusing the saliency vector, which represents the conditional states of the environment, such as the global position of agents. Hence, agents with DA6-X flexibility built into their policy exhibit superior performance by considering the additional information in the conditional states during the decision-making process. The effectiveness of the proposed method was experimentally evaluated by comparing it with conventional methods in an objects collection game. By visualizing the attention weights from DA6-X, we confirmed that agents successfully learn situation-dependent coordinated behaviors by correctly identifying various conditional states, leading to improved interpretability of agents along with superior performance.",
    "path": "papers/23/04/2304.10375.json",
    "total_tokens": 836,
    "translated_title": "多智能体强化学习中有条件协同行为的可解释性研究",
    "translated_abstract": "我们提出了一种无模型强化学习架构，称为基于条件注意力(DA6-X)的分布式注意力演员架构，以提供更好的条件协同行为可解释性。其基本原理涉及重用显著性向量，该向量表示环境的条件状态，例如代理的全局位置。因此，具有嵌入其策略中的DA6-X灵活性的代理通过在决策过程中考虑条件状态中的附加信息表现出优越的性能。通过在对象收集游戏中将提出的方法与传统方法进行比较，实验评估了所提出方法的有效性。通过可视化DA6-X的注意权重，我们确认代理成功地学习了情境依赖性协同行为，通过正确识别各种条件状态，提高了代理的可解释性和性能。",
    "tldr": "提出了一种基于条件注意力的分布式注意力演员架构，利用显著性向量重用环境的条件状态来提高条件协同行为的可解释性和代理性能。",
    "en_tdlr": "A model-free reinforcement learning architecture, called DA6-X, was proposed to improve interpretability of conditional coordinated behaviors by reusing the saliency vector representing conditional states. DA6-X showed superior performance in decision making by considering additional information in conditional states. The experiment confirmed that agents successfully learned situation-dependent coordinated behaviors, leading to improved interpretability and performance."
}