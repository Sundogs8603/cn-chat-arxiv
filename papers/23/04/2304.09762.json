{
    "title": "Practical Differentially Private and Byzantine-resilient Federated Learning. (arXiv:2304.09762v1 [cs.LG])",
    "abstract": "Privacy and Byzantine resilience are two indispensable requirements for a federated learning (FL) system. Although there have been extensive studies on privacy and Byzantine security in their own track, solutions that consider both remain sparse. This is due to difficulties in reconciling privacy-preserving and Byzantine-resilient algorithms.  In this work, we propose a solution to such a two-fold issue. We use our version of differentially private stochastic gradient descent (DP-SGD) algorithm to preserve privacy and then apply our Byzantine-resilient algorithms. We note that while existing works follow this general approach, an in-depth analysis on the interplay between DP and Byzantine resilience has been ignored, leading to unsatisfactory performance. Specifically, for the random noise introduced by DP, previous works strive to reduce its impact on the Byzantine aggregation. In contrast, we leverage the random noise to construct an aggregation that effectively rejects many existing",
    "link": "http://arxiv.org/abs/2304.09762",
    "context": "Title: Practical Differentially Private and Byzantine-resilient Federated Learning. (arXiv:2304.09762v1 [cs.LG])\nAbstract: Privacy and Byzantine resilience are two indispensable requirements for a federated learning (FL) system. Although there have been extensive studies on privacy and Byzantine security in their own track, solutions that consider both remain sparse. This is due to difficulties in reconciling privacy-preserving and Byzantine-resilient algorithms.  In this work, we propose a solution to such a two-fold issue. We use our version of differentially private stochastic gradient descent (DP-SGD) algorithm to preserve privacy and then apply our Byzantine-resilient algorithms. We note that while existing works follow this general approach, an in-depth analysis on the interplay between DP and Byzantine resilience has been ignored, leading to unsatisfactory performance. Specifically, for the random noise introduced by DP, previous works strive to reduce its impact on the Byzantine aggregation. In contrast, we leverage the random noise to construct an aggregation that effectively rejects many existing",
    "path": "papers/23/04/2304.09762.json",
    "total_tokens": 1007,
    "translated_title": "实用的差分隐私和拜占庭容错联邦学习",
    "translated_abstract": "隐私和拜占庭容错是联邦学习系统不可或缺的要求。尽管隐私和拜占庭安全都有广泛的研究，但同时考虑这两个要求的解决方案仍然很少。这是由于协调隐私保护和拜占庭容错算法的困难。本文提出了解决这个问题的方法。我们使用差分隐私随机梯度下降算法来保护隐私，然后应用我们的拜占庭容错算法。我们注意到，尽管现有的工作遵循这种通用方法，但对 DP 和拜占庭容错之间的相互作用进行了深入分析，并提出了令人满意的性能，这已被忽略。具体来说，为了减少 DP 引入的随机噪声对 Byzantine 聚合的影响，先前的工作努力。相反，我们利用随机噪声构建一个聚合，有效地拒绝了许多现有的攻击方法，并在具有与当前最先进算法相当的隐私保护水平时，提升了整体 FL 系统的 Byzantine 鲁棒性。",
    "tldr": "本文提出了一种结合了差分隐私和拜占庭容错的联邦学习方法，在保护隐私的同时，提高系统的鲁棒性，拒绝多种攻击方法，具有较高的隐私保护水平。",
    "en_tdlr": "This paper proposes a federated learning method that combines differential privacy and Byzantine fault tolerance to protect privacy and enhance robustness of the system against various attacks with a high level of privacy protection."
}