{
    "title": "A Semi-Supervised Framework for Misinformation Detection. (arXiv:2304.11318v1 [cs.AI])",
    "abstract": "The spread of misinformation in social media outlets has become a prevalent societal problem and is the cause of many kinds of social unrest. Curtailing its prevalence is of great importance and machine learning has shown significant promise. However, there are two main challenges when applying machine learning to this problem. First, while much too prevalent in one respect, misinformation, actually, represents only a minor proportion of all the postings seen on social media. Second, labeling the massive amount of data necessary to train a useful classifier becomes impractical. Considering these challenges, we propose a simple semi-supervised learning framework in order to deal with extreme class imbalances that has the advantage, over other approaches, of using actual rather than simulated data to inflate the minority class. We tested our framework on two sets of Covid-related Twitter data and obtained significant improvement in F1-measure on extremely imbalanced scenarios, as compare",
    "link": "http://arxiv.org/abs/2304.11318",
    "context": "Title: A Semi-Supervised Framework for Misinformation Detection. (arXiv:2304.11318v1 [cs.AI])\nAbstract: The spread of misinformation in social media outlets has become a prevalent societal problem and is the cause of many kinds of social unrest. Curtailing its prevalence is of great importance and machine learning has shown significant promise. However, there are two main challenges when applying machine learning to this problem. First, while much too prevalent in one respect, misinformation, actually, represents only a minor proportion of all the postings seen on social media. Second, labeling the massive amount of data necessary to train a useful classifier becomes impractical. Considering these challenges, we propose a simple semi-supervised learning framework in order to deal with extreme class imbalances that has the advantage, over other approaches, of using actual rather than simulated data to inflate the minority class. We tested our framework on two sets of Covid-related Twitter data and obtained significant improvement in F1-measure on extremely imbalanced scenarios, as compare",
    "path": "papers/23/04/2304.11318.json",
    "total_tokens": 897,
    "translated_title": "一种半监督的虚假信息检测框架",
    "translated_abstract": "社交媒体上虚假信息的传播已成为一种普遍的社会问题，是许多社会不安的原因。机器学习已经显示出显著的应用前景，但是在应用机器学习解决这个问题时存在两个主要挑战。首先，虚假信息在某种程度上的普及性使得它们在社交媒体上只占少数。其次，标记大量数据来训练一个有用的分类器变得不切实际。鉴于这些挑战，我们提出了一种简单的半监督学习框架，以处理极端的类别不平衡，其优点在于使用实际数据而不是模拟数据来增加少数派类别数量，相对于其他方法更优。我们在两组与 Covid 相关的 Twitter 数据上测试了我们的框架，在极度不平衡的情况下获得了显着的 F1 值提升。",
    "tldr": "这篇论文提出了一种半监督学习框架来解决虚假信息检测中的极端类别不平衡问题。这种方法使用实际而不是模拟数据来增加少数派类别数量，在 Covid 相关的 Twitter 数据上实验表明其可以显著提高 F1 值。",
    "en_tdlr": "This paper proposes a semi-supervised learning framework to address extreme class imbalance in misinformation detection. The approach uses actual data rather than simulated data to increase the minority class, and experiments on Covid-related Twitter data show a significant improvement in F1-measure."
}