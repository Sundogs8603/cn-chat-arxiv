{
    "title": "MP-FedCL: Multi-Prototype Federated Contrastive Learning for Edge Intelligence. (arXiv:2304.01950v1 [cs.LG])",
    "abstract": "Federated learning-assisted edge intelligence enables privacy protection in modern intelligent services. However, not Independent and Identically Distributed (non-IID) distribution among edge clients can impair the local model performance. The existing single prototype-based strategy represents a sample by using the mean of the feature space. However, feature spaces are usually not clustered, and a single prototype may not represent a sample well. Motivated by this, this paper proposes a multi-prototype federated contrastive learning approach (MP-FedCL) which demonstrates the effectiveness of using a multi-prototype strategy over a single-prototype under non-IID settings, including both label and feature skewness. Specifically, a multi-prototype computation strategy based on \\textit{k-means} is first proposed to capture different embedding representations for each class space, using multiple prototypes ($k$ centroids) to represent a class in the embedding space. In each global round, t",
    "link": "http://arxiv.org/abs/2304.01950",
    "context": "Title: MP-FedCL: Multi-Prototype Federated Contrastive Learning for Edge Intelligence. (arXiv:2304.01950v1 [cs.LG])\nAbstract: Federated learning-assisted edge intelligence enables privacy protection in modern intelligent services. However, not Independent and Identically Distributed (non-IID) distribution among edge clients can impair the local model performance. The existing single prototype-based strategy represents a sample by using the mean of the feature space. However, feature spaces are usually not clustered, and a single prototype may not represent a sample well. Motivated by this, this paper proposes a multi-prototype federated contrastive learning approach (MP-FedCL) which demonstrates the effectiveness of using a multi-prototype strategy over a single-prototype under non-IID settings, including both label and feature skewness. Specifically, a multi-prototype computation strategy based on \\textit{k-means} is first proposed to capture different embedding representations for each class space, using multiple prototypes ($k$ centroids) to represent a class in the embedding space. In each global round, t",
    "path": "papers/23/04/2304.01950.json",
    "total_tokens": 1000,
    "translated_abstract": "联邦学习辅助的边缘智能能够在现代智能服务中实现隐私保护。然而，边缘客户端间的非独立同分布（non-IID）分布可能会影响本地模型的性能。现有的基于单个原型的策略通过使用特征空间的平均值来表示样本。然而，特征空间通常不是聚类的，单个原型可能无法很好地表示一个样本。在此背景下，本文提出了一种基于多原型的联邦对比学习方法（MP-FedCL），该方法在非IID情况下展示了使用多原型策略比单个原型策略更为有效，包括标签和特征偏斜。具体来说，该方法首先提出了一种基于$k$均值的多原型计算策略，用于在每个类空间中捕获不同的嵌入表示，使用多个原型（$k$个中心点）来表示嵌入空间中的一个类。在每一个全局轮次中，边缘设备在本地进行训练，然后将本地模型上传到服务器端进行全局模型更新。",
    "tldr": "本文提出了一个基于多原型的联邦对比学习方法，旨在解决非独立同分布分布下的边缘智能中单一原型策略的问题。该方法使用基于$k$均值的多原型计算策略，能更好地处理标签和特征偏斜。",
    "en_tdlr": "This paper proposes a multi-prototype federated contrastive learning approach (MP-FedCL) for edge intelligence, which aims to solve the problem of single-prototype strategy under non-IID distribution. The method uses a multi-prototype computation strategy based on k-means to capture different embedding representations for each class space, and can better handle label and feature skewness."
}