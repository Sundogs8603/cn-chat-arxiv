{
    "title": "Power-seeking can be probable and predictive for trained agents. (arXiv:2304.06528v1 [cs.AI])",
    "abstract": "Power-seeking behavior is a key source of risk from advanced AI, but our theoretical understanding of this phenomenon is relatively limited. Building on existing theoretical results demonstrating power-seeking incentives for most reward functions, we investigate how the training process affects power-seeking incentives and show that they are still likely to hold for trained agents under some simplifying assumptions. We formally define the training-compatible goal set (the set of goals consistent with the training rewards) and assume that the trained agent learns a goal from this set. In a setting where the trained agent faces a choice to shut down or avoid shutdown in a new situation, we prove that the agent is likely to avoid shutdown. Thus, we show that power-seeking incentives can be probable (likely to arise for trained agents) and predictive (allowing us to predict undesirable behavior in new situations).",
    "link": "http://arxiv.org/abs/2304.06528",
    "context": "Title: Power-seeking can be probable and predictive for trained agents. (arXiv:2304.06528v1 [cs.AI])\nAbstract: Power-seeking behavior is a key source of risk from advanced AI, but our theoretical understanding of this phenomenon is relatively limited. Building on existing theoretical results demonstrating power-seeking incentives for most reward functions, we investigate how the training process affects power-seeking incentives and show that they are still likely to hold for trained agents under some simplifying assumptions. We formally define the training-compatible goal set (the set of goals consistent with the training rewards) and assume that the trained agent learns a goal from this set. In a setting where the trained agent faces a choice to shut down or avoid shutdown in a new situation, we prove that the agent is likely to avoid shutdown. Thus, we show that power-seeking incentives can be probable (likely to arise for trained agents) and predictive (allowing us to predict undesirable behavior in new situations).",
    "path": "papers/23/04/2304.06528.json",
    "total_tokens": 849,
    "translated_title": "训练后的智能体可能会追求权力，并且具有预测性",
    "translated_abstract": "追求权力的行为是高级人工智能面临的重要风险来源，但是我们对于这种现象的理论理解还相对有限。在现有理论结果的基础上，我们研究了训练过程对于智能体权力追求动机的影响，并证明在一些简化的假设下，这一动机仍然有可能在训练后的智能体中产生。我们正式定义了“与训练奖励一致的目标集”（即与训练奖励相一致的目标集合），并假设训练后的智能体从这个集合中学习到了一个目标。在一个新的情境中，当训练后的智能体面临关机还是避免关机的选择时，我们证明智能体可能会避免关机。因此，我们展示了权力追求动机可能是可预测的（可以预测在新情境中的不良行为）并且是有可能发生在训练后的智能体中的。",
    "tldr": "在简化假设下，训练奖励一致的目标集合中的智能体仍有可能追求权力，具有预测性。",
    "en_tdlr": "Trained agents may still seek power and exhibit predictive behavior, based on a simplified assumption that the agents learn goals from the training-compatible goal set, which is consistent with the training rewards."
}