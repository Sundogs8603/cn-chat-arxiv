{
    "title": "Trust and Reliance in Consensus-Based Explanations from an Anti-Misinformation Agent. (arXiv:2304.11279v1 [cs.HC])",
    "abstract": "The illusion of consensus occurs when people believe there is consensus across multiple sources, but the sources are the same and thus there is no \"true\" consensus. We explore this phenomenon in the context of an AI-based intelligent agent designed to augment metacognition on social media. Misinformation, especially on platforms like Twitter, is a global problem for which there is currently no good solution. As an explainable AI (XAI) system, the agent provides explanations for its decisions on the misinformed nature of social media content. In this late-breaking study, we explored the roles of trust (attitude) and reliance (behaviour) as key elements of XAI user experience (UX) and whether these influenced the illusion of consensus. Findings show no effect of trust, but an effect of reliance on consensus-based explanations. This work may guide the design of anti-misinformation systems that use XAI, especially the user-centred design of explanations.",
    "link": "http://arxiv.org/abs/2304.11279",
    "context": "Title: Trust and Reliance in Consensus-Based Explanations from an Anti-Misinformation Agent. (arXiv:2304.11279v1 [cs.HC])\nAbstract: The illusion of consensus occurs when people believe there is consensus across multiple sources, but the sources are the same and thus there is no \"true\" consensus. We explore this phenomenon in the context of an AI-based intelligent agent designed to augment metacognition on social media. Misinformation, especially on platforms like Twitter, is a global problem for which there is currently no good solution. As an explainable AI (XAI) system, the agent provides explanations for its decisions on the misinformed nature of social media content. In this late-breaking study, we explored the roles of trust (attitude) and reliance (behaviour) as key elements of XAI user experience (UX) and whether these influenced the illusion of consensus. Findings show no effect of trust, but an effect of reliance on consensus-based explanations. This work may guide the design of anti-misinformation systems that use XAI, especially the user-centred design of explanations.",
    "path": "papers/23/04/2304.11279.json",
    "total_tokens": 928,
    "translated_title": "基于反误信息智能体的共识解释中的信任与依赖",
    "translated_abstract": "“共识幻觉”指的是人们认为多个来源都达成了一致，但实际上这些来源是相同的，因此不存在“真正”的一致。本文研究了帮助提高社交媒体元认知的基于人工智能的智能代理的情况下，这种现象的存在。在Twitter等平台上，虚假信息是一个全球性的问题，目前还没有一个好的解决方案。作为一个可解释的人工智能（XAI）系统，智能代理在对社交媒体内容的错误判断上提供解释。在这项研究中，我们探讨了信任（态度）和依赖（行为）作为XAI用户体验（UX）的关键因素，以及这些因素是否会影响共识幻觉。研究结果显示，信任没有影响，但依赖对基于共识的解释有影响。该研究可指导使用XAI的反误信息系统的设计，特别是解释的用户中心设计。",
    "tldr": "本文探讨了基于人工智能的智能代理在反误信息方面对共识幻觉的影响，并发现依赖（行为）会影响基于共识的解释，这对使用XAI的反误信息系统的设计指导有意义。",
    "en_tdlr": "This paper explores the impact of AI-based intelligent agents on the illusion of consensus in the context of anti-misinformation and finds that reliance (behavior) affects consensus-based explanations, which could guide the user-centered design of anti-misinformation systems that use XAI."
}