{
    "title": "Some of the variables, some of the parameters, some of the times, with some physics known: Identification with partial information. (arXiv:2304.14214v1 [cs.LG])",
    "abstract": "Experimental data is often comprised of variables measured independently, at different sampling rates (non-uniform ${\\Delta}$t between successive measurements); and at a specific time point only a subset of all variables may be sampled. Approaches to identifying dynamical systems from such data typically use interpolation, imputation or subsampling to reorganize or modify the training data $\\textit{prior}$ to learning. Partial physical knowledge may also be available $\\textit{a priori}$ (accurately or approximately), and data-driven techniques can complement this knowledge. Here we exploit neural network architectures based on numerical integration methods and $\\textit{a priori}$ physical knowledge to identify the right-hand side of the underlying governing differential equations. Iterates of such neural-network models allow for learning from data sampled at arbitrary time points $\\textit{without}$ data modification. Importantly, we integrate the network with available partial physical",
    "link": "http://arxiv.org/abs/2304.14214",
    "context": "Title: Some of the variables, some of the parameters, some of the times, with some physics known: Identification with partial information. (arXiv:2304.14214v1 [cs.LG])\nAbstract: Experimental data is often comprised of variables measured independently, at different sampling rates (non-uniform ${\\Delta}$t between successive measurements); and at a specific time point only a subset of all variables may be sampled. Approaches to identifying dynamical systems from such data typically use interpolation, imputation or subsampling to reorganize or modify the training data $\\textit{prior}$ to learning. Partial physical knowledge may also be available $\\textit{a priori}$ (accurately or approximately), and data-driven techniques can complement this knowledge. Here we exploit neural network architectures based on numerical integration methods and $\\textit{a priori}$ physical knowledge to identify the right-hand side of the underlying governing differential equations. Iterates of such neural-network models allow for learning from data sampled at arbitrary time points $\\textit{without}$ data modification. Importantly, we integrate the network with available partial physical",
    "path": "papers/23/04/2304.14214.json",
    "total_tokens": 893,
    "translated_title": "论文标题：某些变量，某些参数，某些时间，某些已知物理学：带有部分信息的识别",
    "translated_abstract": "实验数据通常由独立测量的变量组成，在不同的采样率(连续测量之间的非均匀${\\Delta}$t)下，仅在特定时间点才对所有变量的子集进行采样。从这样的数据中识别动力系统的方法通常使用插值、插值或子采样来重新组织或修改训练数据$ \\textit {prior}$ 学习。部分物理知识也可能在$\\textit {a priori}$（精确或近似）中可用，并且数据驱动技术可以补充此知识。在这里，我们利用基于数值积分方法和$\\textit {a priori}$物理知识的神经网络架构来识别基本控制微分方程的右手边。这种神经网络模型的迭代允许从在任意时间点采样的数据中学习$\\textit {without}$数据修改。重要的是，我们将网络与可用的部分物理集成",
    "tldr": "本文介绍了一种利用神经网络识别动力系统的新方法，在不对数据进行修改的情况下，通过数值积分和部分已知物理学，能够从任意时间点的采样数据中学习。",
    "en_tdlr": "This paper presents a new method for identifying dynamical systems using neural networks, which can learn from data sampled at arbitrary time points without modification, by using numerical integration and partial knowledge of physics."
}