{
    "title": "MEMA Runtime Framework: Minimizing External Memory Accesses for TinyML on Microcontrollers. (arXiv:2304.05544v1 [cs.LG])",
    "abstract": "We present the MEMA framework for the easy and quick derivation of efficient inference runtimes that minimize external memory accesses for matrix multiplication on TinyML systems. The framework accounts for hardware resource constraints and problem sizes in analytically determining optimized schedules and kernels that minimize memory accesses. MEMA provides a solution to a well-known problem in the current practice, that is, optimal schedules tend to be found only through a time consuming and heuristic search of a large scheduling space. We compare the performance of runtimes derived from MEMA to existing state-of-the-art libraries on ARM-based TinyML systems. For example, for neural network benchmarks on the ARM Cortex-M4, we achieve up to a 1.8x speedup and 44% energy reduction over CMSIS-NN.",
    "link": "http://arxiv.org/abs/2304.05544",
    "context": "Title: MEMA Runtime Framework: Minimizing External Memory Accesses for TinyML on Microcontrollers. (arXiv:2304.05544v1 [cs.LG])\nAbstract: We present the MEMA framework for the easy and quick derivation of efficient inference runtimes that minimize external memory accesses for matrix multiplication on TinyML systems. The framework accounts for hardware resource constraints and problem sizes in analytically determining optimized schedules and kernels that minimize memory accesses. MEMA provides a solution to a well-known problem in the current practice, that is, optimal schedules tend to be found only through a time consuming and heuristic search of a large scheduling space. We compare the performance of runtimes derived from MEMA to existing state-of-the-art libraries on ARM-based TinyML systems. For example, for neural network benchmarks on the ARM Cortex-M4, we achieve up to a 1.8x speedup and 44% energy reduction over CMSIS-NN.",
    "path": "papers/23/04/2304.05544.json",
    "total_tokens": 858,
    "translated_title": "MEMA运行时框架：在微控制器上实现TinyML时最小化外部内存访问",
    "translated_abstract": "我们提出了MEMA框架，用于在TinyML系统上矩阵乘法的推断运行时快速且容易地推导出最小化外部内存访问的有效运行时。该框架考虑硬件资源限制和问题大小，通过分析确定最优化的调度和内核，以最小化内存访问。MEMA提供了当前实践中已知问题的解决方案，即仅通过耗时且启发式的搜索大量调度空间才能找到最优调度。我们将MEMA推导出的运行时性能与基于ARM的TinyML系统上现有的最先进的库进行了比较。例如在ARM Cortex-M4上进行神经网络基准测试，我们实现了比CMSIS-NN更高达1.8倍的加速和44％的能量减少。",
    "tldr": "我们提出了MEMA框架，可以快速且容易地推导出在微控制器上实现TinyML时最小化外部内存访问的有效运行时，这可以使神经网络基准测试在ARM Cortex-M4上加速高达1.8倍和减少44％的能量消耗。",
    "en_tdlr": "We present the MEMA framework for minimizing external memory accesses for matrix multiplication on TinyML systems. MEMA provides a solution to the problem that optimal schedules tend to be found only through a time-consuming and heuristic search, achieving up to 1.8x speedup and 44% energy reduction over existing state-of-the-art libraries on ARM-based TinyML systems."
}