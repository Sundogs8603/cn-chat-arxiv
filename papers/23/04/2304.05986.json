{
    "title": "Auditing ICU Readmission Rates in an Clinical Database: An Analysis of Risk Factors and Clinical Outcomes. (arXiv:2304.05986v1 [cs.LG])",
    "abstract": "This study presents a machine learning (ML) pipeline for clinical data classification in the context of a 30-day readmission problem, along with a fairness audit on subgroups based on sensitive attributes. A range of ML models are used for classification and the fairness audit is conducted on the model predictions. The fairness audit uncovers disparities in equal opportunity, predictive parity, false positive rate parity, and false negative rate parity criteria on the MIMIC III dataset based on attributes such as gender, ethnicity, language, and insurance group. The results identify disparities in the model's performance across different groups and highlights the need for better fairness and bias mitigation strategies. The study suggests the need for collaborative efforts among researchers, policymakers, and practitioners to address bias and fairness in artificial intelligence (AI) systems.",
    "link": "http://arxiv.org/abs/2304.05986",
    "context": "Title: Auditing ICU Readmission Rates in an Clinical Database: An Analysis of Risk Factors and Clinical Outcomes. (arXiv:2304.05986v1 [cs.LG])\nAbstract: This study presents a machine learning (ML) pipeline for clinical data classification in the context of a 30-day readmission problem, along with a fairness audit on subgroups based on sensitive attributes. A range of ML models are used for classification and the fairness audit is conducted on the model predictions. The fairness audit uncovers disparities in equal opportunity, predictive parity, false positive rate parity, and false negative rate parity criteria on the MIMIC III dataset based on attributes such as gender, ethnicity, language, and insurance group. The results identify disparities in the model's performance across different groups and highlights the need for better fairness and bias mitigation strategies. The study suggests the need for collaborative efforts among researchers, policymakers, and practitioners to address bias and fairness in artificial intelligence (AI) systems.",
    "path": "papers/23/04/2304.05986.json",
    "total_tokens": 853,
    "translated_title": "在临床数据库中审计ICU再入院率：风险因素和临床结果分析",
    "translated_abstract": "本研究提出了一个机器学习（ML）流程用于临床数据分类，目的是解决30天内再入院的问题，并对基于敏感属性的子组进行了公平审计。该分类问题使用了一系列ML模型，并在模型预测上进行了公平审计。针对MIMIC III数据库中的性别、种族、语言和保险组等属性，公平审计发现了机会平等、预测平等、误报率平等和漏报率平等等标准存在差异。结果显示了该模型在不同组别中表现的差异，并强调了建立更好的公正和偏差缓解策略的必要性。本研究建议研究人员、政策制定者和实践者进行合作，解决人工智能系统中的偏差和公正问题。",
    "tldr": "本研究使用机器学习模型解决了30天内再入院的问题，并对基于敏感属性的子组进行了公平审计，结果发现该模型在不同组别中表现出差异，强调了建立更好的公正和偏差缓解策略的必要性。",
    "en_tdlr": "This study presents a machine learning pipeline to classify clinical data for the 30-day readmission problem, and conducts a fairness audit on sensitive subgroups, revealing disparities in model performance and highlighting the need for better fairness and bias mitigation strategies in artificial intelligence systems."
}