{
    "title": "On the Generalization of Learned Structured Representations. (arXiv:2304.13001v1 [cs.LG])",
    "abstract": "Despite tremendous progress over the past decade, deep learning methods generally fall short of human-level systematic generalization. It has been argued that explicitly capturing the underlying structure of data should allow connectionist systems to generalize in a more predictable and systematic manner. Indeed, evidence in humans suggests that interpreting the world in terms of symbol-like compositional entities may be crucial for intelligent behavior and high-level reasoning. Another common limitation of deep learning systems is that they require large amounts of training data, which can be expensive to obtain. In representation learning, large datasets are leveraged to learn generic data representations that may be useful for efficient learning of arbitrary downstream tasks.  This thesis is about structured representation learning. We study methods that learn, with little or no supervision, representations of unstructured data that capture its hidden structure. In the first part of",
    "link": "http://arxiv.org/abs/2304.13001",
    "context": "Title: On the Generalization of Learned Structured Representations. (arXiv:2304.13001v1 [cs.LG])\nAbstract: Despite tremendous progress over the past decade, deep learning methods generally fall short of human-level systematic generalization. It has been argued that explicitly capturing the underlying structure of data should allow connectionist systems to generalize in a more predictable and systematic manner. Indeed, evidence in humans suggests that interpreting the world in terms of symbol-like compositional entities may be crucial for intelligent behavior and high-level reasoning. Another common limitation of deep learning systems is that they require large amounts of training data, which can be expensive to obtain. In representation learning, large datasets are leveraged to learn generic data representations that may be useful for efficient learning of arbitrary downstream tasks.  This thesis is about structured representation learning. We study methods that learn, with little or no supervision, representations of unstructured data that capture its hidden structure. In the first part of",
    "path": "papers/23/04/2304.13001.json",
    "total_tokens": 1088,
    "translated_title": "深度学习中学习结构化表示的泛化问题研究",
    "translated_abstract": "尽管在过去的十年中取得了巨大的进展，但深度学习方法通常无法达到人类级别的系统泛化水平。人们认为明确捕获数据的基础结构应该能够让联结主义系统以更可预测和系统的方式进行泛化。事实上，人类的证据表明，用符号般的组合实体来解释世界可能对智能行为和高级推理至关重要。另一个深度学习系统的常见限制是它们需要大量的训练数据，这可能很昂贵。在表示学习中，利用大型数据集学习通用数据表示，这些表示可以用于有效地学习任意的下游任务。本论文研究了结构化表示学习。我们研究了学习未结构化数据的结构化表示的方法，这些方法需要很少或没有监督，并捕获其隐藏结构。在论文的第一部分中，我们提出了一些新的方法，用于学习结构化表示，可以捕获数据中的局部和全局依赖关系。在第二部分中，我们研究了学习的结构化表示如何提高深度网络在各种下游任务上的泛化性能。我们的实验表明，我们提出的方法在图像分类和物体检测等任务上优于几种最先进的无监督方法。",
    "tldr": "本论文研究了深度学习中学习结构化表示的泛化问题。通过提出能够学习局部和全局依赖关系的结构化表示方法，并在各种下游任务上进行实验验证，证明了该方法在图像分类和物体检测等任务上的有效性。",
    "en_tdlr": "This paper addresses the problem of generalization in structured representation learning in deep learning. By proposing novel methods for learning representations that capture both local and global dependencies, and demonstrating their effectiveness in tasks such as image classification and object detection, the study shows the potential for improving generalization performance of deep networks."
}