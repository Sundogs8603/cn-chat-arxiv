{
    "title": "Reinforcement Learning Approaches for Traffic Signal Control under Missing Data. (arXiv:2304.10722v1 [cs.LG])",
    "abstract": "The emergence of reinforcement learning (RL) methods in traffic signal control tasks has achieved better performance than conventional rule-based approaches. Most RL approaches require the observation of the environment for the agent to decide which action is optimal for a long-term reward. However, in real-world urban scenarios, missing observation of traffic states may frequently occur due to the lack of sensors, which makes existing RL methods inapplicable on road networks with missing observation. In this work, we aim to control the traffic signals in a real-world setting, where some of the intersections in the road network are not installed with sensors and thus with no direct observations around them. To the best of our knowledge, we are the first to use RL methods to tackle the traffic signal control problem in this real-world setting. Specifically, we propose two solutions: the first one imputes the traffic states to enable adaptive control, and the second one imputes both stat",
    "link": "http://arxiv.org/abs/2304.10722",
    "context": "Title: Reinforcement Learning Approaches for Traffic Signal Control under Missing Data. (arXiv:2304.10722v1 [cs.LG])\nAbstract: The emergence of reinforcement learning (RL) methods in traffic signal control tasks has achieved better performance than conventional rule-based approaches. Most RL approaches require the observation of the environment for the agent to decide which action is optimal for a long-term reward. However, in real-world urban scenarios, missing observation of traffic states may frequently occur due to the lack of sensors, which makes existing RL methods inapplicable on road networks with missing observation. In this work, we aim to control the traffic signals in a real-world setting, where some of the intersections in the road network are not installed with sensors and thus with no direct observations around them. To the best of our knowledge, we are the first to use RL methods to tackle the traffic signal control problem in this real-world setting. Specifically, we propose two solutions: the first one imputes the traffic states to enable adaptive control, and the second one imputes both stat",
    "path": "papers/23/04/2304.10722.json",
    "total_tokens": 814,
    "translated_title": "缺失数据下的交通信号控制的强化学习方法",
    "translated_abstract": "强化学习方法在交通信号控制任务中的应用已经取得了比传统的基于规则的方法更好的性能。然而，现实中交通状态的缺失可能经常发生，使得现有的强化学习方法在缺少传感器的路网上无法应用。本文旨在控制交通信号在现实环境下的设置中，其中一些路口没有安装传感器，因此周围没有直接观察数据。在我们所知道的范围内，我们是第一个使用强化学习方法来解决这个现实世界中的交通信号控制问题。具体地，我们提出了两种解决方案：第一种方案补充流量状态以实现自适应控制，第二种方案补充状态和动作以进行条件融合。",
    "tldr": "本文提出了在交通路网中缺少传感器的情况下，使用强化学习方法通过补充流量状态或状态和动作来实现自适应控制和条件融合。",
    "en_tdlr": "This paper proposes reinforcement learning methods for traffic signal control under missing data in road networks, which tackles the problem through imputing traffic states or both states and actions to achieve adaptive control and conditional fusion."
}