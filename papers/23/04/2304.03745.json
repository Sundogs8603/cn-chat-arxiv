{
    "title": "Assessing Perceived Fairness from Machine Learning Developer's Perspective. (arXiv:2304.03745v1 [cs.LG])",
    "abstract": "Fairness in machine learning (ML) applications is an important practice for developers in research and industry. In ML applications, unfairness is triggered due to bias in the data, curation process, erroneous assumptions, and implicit bias rendered within the algorithmic development process. As ML applications come into broader use developing fair ML applications is critical. Literature suggests multiple views on how fairness in ML is described from the users perspective and students as future developers. In particular, ML developers have not been the focus of research relating to perceived fairness. This paper reports on a pilot investigation of ML developers perception of fairness. In describing the perception of fairness, the paper performs an exploratory pilot study to assess the attributes of this construct using a systematic focus group of developers. In the focus group, we asked participants to discuss three questions- 1) What are the characteristics of fairness in ML? 2) What ",
    "link": "http://arxiv.org/abs/2304.03745",
    "context": "Title: Assessing Perceived Fairness from Machine Learning Developer's Perspective. (arXiv:2304.03745v1 [cs.LG])\nAbstract: Fairness in machine learning (ML) applications is an important practice for developers in research and industry. In ML applications, unfairness is triggered due to bias in the data, curation process, erroneous assumptions, and implicit bias rendered within the algorithmic development process. As ML applications come into broader use developing fair ML applications is critical. Literature suggests multiple views on how fairness in ML is described from the users perspective and students as future developers. In particular, ML developers have not been the focus of research relating to perceived fairness. This paper reports on a pilot investigation of ML developers perception of fairness. In describing the perception of fairness, the paper performs an exploratory pilot study to assess the attributes of this construct using a systematic focus group of developers. In the focus group, we asked participants to discuss three questions- 1) What are the characteristics of fairness in ML? 2) What ",
    "path": "papers/23/04/2304.03745.json",
    "total_tokens": 1107,
    "translated_title": "从机器学习开发者的角度评估感知公平性",
    "translated_abstract": "机器学习应用中的公平性对于研究和工业界的开发人员来说是一项重要的实践。在机器学习应用中，不公平是由于数据中的偏见、策划过程中的歧视、错误的假设和算法开发过程中呈现的隐性偏见引起的。随着机器学习应用的广泛应用，开发公平的机器学习应用程序变得至关重要。文献指出了多种关于用户视角和作为未来开发者的学生视角下，机器学习公平性是如何描述的看法。特别地，机器学习开发者的感知公平性还没有得到研究的关注。本文报告了对机器学习开发者感知公平性的初步调查。在描述公平性感知方面，本文使用了一种系统的焦点小组方法来评估该概念的属性。在焦点小组中，我们要求参与者讨论三个问题：1）机器学习公平性的特征是什么？2）开发公平机器学习应用中的挑战是什么？3）机器学习开发者如何缓解机器学习应用中的不公平性？初步结果表明，开发者将准确性、代表性和透明度放在机器学习公平性的优先考虑位置，并面临数据偏见和缺乏明确指导方针等挑战。本研究突显了思考机器学习开发者视角在解决机器学习公平性问题上的重要性。",
    "tldr": "机器学习开发者在公平性中优先考虑准确性、代表性和透明度，同时面临数据偏见和缺乏指导方针等挑战。"
}