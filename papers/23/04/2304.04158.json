{
    "title": "Does Continual Learning Equally Forget All Parameters?. (arXiv:2304.04158v1 [cs.LG])",
    "abstract": "Distribution shift (e.g., task or domain shift) in continual learning (CL) usually results in catastrophic forgetting of neural networks. Although it can be alleviated by repeatedly replaying buffered data, the every-step replay is time-consuming. In this paper, we study which modules in neural networks are more prone to forgetting by investigating their training dynamics during CL. Our proposed metrics show that only a few modules are more task-specific and sensitively alter between tasks, while others can be shared across tasks as common knowledge. Hence, we attribute forgetting mainly to the former and find that finetuning them only on a small buffer at the end of any CL method can bring non-trivial improvement. Due to the small number of finetuned parameters, such ``Forgetting Prioritized Finetuning (FPF)'' is efficient in computation. We further propose a more efficient and simpler method that entirely removes the every-step replay and replaces them by only $k$-times of FPF period",
    "link": "http://arxiv.org/abs/2304.04158",
    "context": "Title: Does Continual Learning Equally Forget All Parameters?. (arXiv:2304.04158v1 [cs.LG])\nAbstract: Distribution shift (e.g., task or domain shift) in continual learning (CL) usually results in catastrophic forgetting of neural networks. Although it can be alleviated by repeatedly replaying buffered data, the every-step replay is time-consuming. In this paper, we study which modules in neural networks are more prone to forgetting by investigating their training dynamics during CL. Our proposed metrics show that only a few modules are more task-specific and sensitively alter between tasks, while others can be shared across tasks as common knowledge. Hence, we attribute forgetting mainly to the former and find that finetuning them only on a small buffer at the end of any CL method can bring non-trivial improvement. Due to the small number of finetuned parameters, such ``Forgetting Prioritized Finetuning (FPF)'' is efficient in computation. We further propose a more efficient and simpler method that entirely removes the every-step replay and replaces them by only $k$-times of FPF period",
    "path": "papers/23/04/2304.04158.json",
    "total_tokens": 977,
    "translated_title": "持续学习中是否所有参数都会同样遗忘？",
    "translated_abstract": "持续学习中的分布变化通常会导致神经网络的灾难性遗忘。尽管通过反复重放缓冲数据可以减轻这种情况，但每次重放非常耗时。本文研究了神经网络中哪些模块更容易被遗忘，并通过研究其持续学习过程中的训练动态来探讨这个问题。我们提出的度量表明，只有少数模块是更加任务特定且在任务之间敏感地改变的，而其他模块可以作为共同知识在任务之间共享。因此，我们将遗忘主要归因于前者，并发现仅在任何持续学习方法的末尾对它们进行微调可以带来非平凡的改进。由于被微调的参数数量很少，因此这种“遗忘优先微调（FPF）”在计算上非常高效。我们进一步提出了一种更高效、更简单的方法，它完全删除了每次重放，并用仅 $k$ 次 FPF 周期来替换它们。",
    "tldr": "本文研究了神经网络中哪些模块更容易遗忘，并发现只有少数模块是更加任务特定且在任务之间敏感地改变的。因此，我们将遗忘主要归因于这些模块，并提出了一种高效的“遗忘优先微调”方法来解决这个问题。",
    "en_tdlr": "This paper studies which modules in neural networks are more prone to forgetting during continual learning and finds that only a few task-specific modules are the main cause of forgetting. The proposed \"Forgetting Prioritized Finetuning\" method focuses on finetuning these modules and brings non-trivial improvement."
}