{
    "title": "A data augmentation perspective on diffusion models and retrieval. (arXiv:2304.10253v1 [cs.CV])",
    "abstract": "Diffusion models excel at generating photorealistic images from text-queries. Naturally, many approaches have been proposed to use these generative abilities to augment training datasets for downstream tasks, such as classification. However, diffusion models are themselves trained on large noisily supervised, but nonetheless, annotated datasets. It is an open question whether the generalization capabilities of diffusion models beyond using the additional data of the pre-training process for augmentation lead to improved downstream performance. We perform a systematic evaluation of existing methods to generate images from diffusion models and study new extensions to assess their benefit for data augmentation. While we find that personalizing diffusion models towards the target data outperforms simpler prompting strategies, we also show that using the training data of the diffusion model alone, via a simple nearest neighbor retrieval procedure, leads to even stronger downstream performan",
    "link": "http://arxiv.org/abs/2304.10253",
    "context": "Title: A data augmentation perspective on diffusion models and retrieval. (arXiv:2304.10253v1 [cs.CV])\nAbstract: Diffusion models excel at generating photorealistic images from text-queries. Naturally, many approaches have been proposed to use these generative abilities to augment training datasets for downstream tasks, such as classification. However, diffusion models are themselves trained on large noisily supervised, but nonetheless, annotated datasets. It is an open question whether the generalization capabilities of diffusion models beyond using the additional data of the pre-training process for augmentation lead to improved downstream performance. We perform a systematic evaluation of existing methods to generate images from diffusion models and study new extensions to assess their benefit for data augmentation. While we find that personalizing diffusion models towards the target data outperforms simpler prompting strategies, we also show that using the training data of the diffusion model alone, via a simple nearest neighbor retrieval procedure, leads to even stronger downstream performan",
    "path": "papers/23/04/2304.10253.json",
    "total_tokens": 822,
    "translated_title": "基于数据增强视角的扩散模型与检索研究",
    "translated_abstract": "扩散模型在从文本查询中生成逼真图像方面表现优异。因此，许多方法已经被提出，以利用这些生成能力来增强用于下游任务（如分类）的训练数据集。然而，扩散模型本身是在大型嘈杂的监督注释数据集上进行训练的。目前尚不清楚，扩散模型在增强过程中使用附加数据是否能够提高下游性能。我们对现有扩散模型图像生成方法进行系统评估，并研究新的扩展方法，以评估其对数据增强的效益。虽然我们发现，针对目标数据个性化的扩散模型优于更简单的提示策略，但我们也表明，仅使用扩散模型的训练数据，通过简单的最近邻检索过程，可以导致更强的下游性能。",
    "tldr": "本研究从数据增强的角度出发，评估了扩散模型图像生成方法，并发现仅使用扩散模型的训练数据可用于最强的数据增强。",
    "en_tdlr": "This study evaluates the methods of generating images from diffusion models from the perspective of data augmentation, and finds that using only the training data of the diffusion model leads to the strongest data augmentation performance."
}