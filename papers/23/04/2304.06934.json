{
    "title": "Classification of social media Toxic comments using Machine learning models. (arXiv:2304.06934v1 [cs.LG])",
    "abstract": "The abstract outlines the problem of toxic comments on social media platforms, where individuals use disrespectful, abusive, and unreasonable language that can drive users away from discussions. This behavior is referred to as anti-social behavior, which occurs during online debates, comments, and fights. The comments containing explicit language can be classified into various categories, such as toxic, severe toxic, obscene, threat, insult, and identity hate. This behavior leads to online harassment and cyberbullying, which forces individuals to stop expressing their opinions and ideas. To protect users from offensive language, companies have started flagging comments and blocking users. The abstract proposes to create a classifier using an Lstm-cnn model that can differentiate between toxic and non-toxic comments with high accuracy. The classifier can help organizations examine the toxicity of the comment section better.",
    "link": "http://arxiv.org/abs/2304.06934",
    "context": "Title: Classification of social media Toxic comments using Machine learning models. (arXiv:2304.06934v1 [cs.LG])\nAbstract: The abstract outlines the problem of toxic comments on social media platforms, where individuals use disrespectful, abusive, and unreasonable language that can drive users away from discussions. This behavior is referred to as anti-social behavior, which occurs during online debates, comments, and fights. The comments containing explicit language can be classified into various categories, such as toxic, severe toxic, obscene, threat, insult, and identity hate. This behavior leads to online harassment and cyberbullying, which forces individuals to stop expressing their opinions and ideas. To protect users from offensive language, companies have started flagging comments and blocking users. The abstract proposes to create a classifier using an Lstm-cnn model that can differentiate between toxic and non-toxic comments with high accuracy. The classifier can help organizations examine the toxicity of the comment section better.",
    "path": "papers/23/04/2304.06934.json",
    "total_tokens": 809,
    "translated_title": "使用机器学习模型分类社交媒体有害评论",
    "translated_abstract": "摘要概述了社交媒体平台上有害评论的问题。个别人使用不尊重、滥用和不合理的语言，可能会驱使用户离开讨论。这种行为被称为反社会行为，经常出现在在线辩论、评论和争斗中。含有明确不良语言的评论可以被归类为多种类型，如有害、严重有害、淫秽、威胁、侮辱和身份仇恨。这种行为导致网络骚扰和网络欺凌，迫使个人停止表达自己的观点和想法。为了保护用户免受冒犯性言论，公司已经开始标记评论和阻止用户。摘要提出了使用Lstm-cnn模型创建分类器，以高准确率区分有害和非有害评论。分类器可以帮助组织更好地检查评论区的有害程度。",
    "tldr": "该论文提出使用Lstm-cnn模型分类器，从而更好地区分社交媒体平台上有害和非有害评论，以解决网络欺凌问题。",
    "en_tdlr": "The paper proposes using an Lstm-cnn model classifier to better differentiate toxic and non-toxic comments on social media platforms in order to address the issue of cyberbullying."
}