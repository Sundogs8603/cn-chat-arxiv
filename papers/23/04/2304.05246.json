{
    "title": "OpenAL: Evaluation and Interpretation of Active Learning Strategies. (arXiv:2304.05246v1 [cs.LG])",
    "abstract": "Despite the vast body of literature on Active Learning (AL), there is no comprehensive and open benchmark allowing for efficient and simple comparison of proposed samplers. Additionally, the variability in experimental settings across the literature makes it difficult to choose a sampling strategy, which is critical due to the one-off nature of AL experiments. To address those limitations, we introduce OpenAL, a flexible and open-source framework to easily run and compare sampling AL strategies on a collection of realistic tasks. The proposed benchmark is augmented with interpretability metrics and statistical analysis methods to understand when and why some samplers outperform others. Last but not least, practitioners can easily extend the benchmark by submitting their own AL samplers.",
    "link": "http://arxiv.org/abs/2304.05246",
    "context": "Title: OpenAL: Evaluation and Interpretation of Active Learning Strategies. (arXiv:2304.05246v1 [cs.LG])\nAbstract: Despite the vast body of literature on Active Learning (AL), there is no comprehensive and open benchmark allowing for efficient and simple comparison of proposed samplers. Additionally, the variability in experimental settings across the literature makes it difficult to choose a sampling strategy, which is critical due to the one-off nature of AL experiments. To address those limitations, we introduce OpenAL, a flexible and open-source framework to easily run and compare sampling AL strategies on a collection of realistic tasks. The proposed benchmark is augmented with interpretability metrics and statistical analysis methods to understand when and why some samplers outperform others. Last but not least, practitioners can easily extend the benchmark by submitting their own AL samplers.",
    "path": "papers/23/04/2304.05246.json",
    "total_tokens": 813,
    "translated_title": "OpenAL: 主动学习策略的评估与解释",
    "translated_abstract": "尽管在主动学习（AL）方面已经有大量的文献，但是还没有一种全面且开放的基准可以有效地比较提出的采样器。此外，文献中实验设置的变异性使得选择采样策略变得困难，这是由于主动学习实验的一次性特性非常重要。为了解决这些限制，我们引入了OpenAL，这是一个灵活且开源的框架，可以在一系列现实任务上轻松运行和比较采样AL策略。该基准测试还加入了可解释性指标和统计分析方法，以了解何时以及为什么一些采样器优于其他采样器。最后，从业人员可以通过提交自己的AL采样器轻松扩展基准测试。",
    "tldr": "OpenAL是一个灵活且开源的框架，可以在一系列现实任务上轻松运行和比较采样AL策略，具有可解释性指标和统计分析方法，针对主动学习的一次性特性，从业人员也可以轻松扩展基准测试。",
    "en_tdlr": "OpenAL is a flexible and open-source framework that allows for easy running and comparison of sampling AL strategies on a collection of realistic tasks, augmented with interpretability metrics and statistical analysis methods, and practitioners can easily extend the benchmark given the one-off nature of AL experiments."
}