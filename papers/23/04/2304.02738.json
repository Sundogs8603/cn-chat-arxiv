{
    "title": "Core Challenges in Embodied Vision-Language Planning. (arXiv:2304.02738v1 [cs.RO])",
    "abstract": "Recent advances in the areas of Multimodal Machine Learning and Artificial Intelligence (AI) have led to the development of challenging tasks at the intersection of Computer Vision, Natural Language Processing, and Robotics. Whereas many approaches and previous survey pursuits have characterised one or two of these dimensions, there has not been a holistic analysis at the center of all three. Moreover, even when combinations of these topics are considered, more focus is placed on describing, e.g., current architectural methods, as opposed to also illustrating high-level challenges and opportunities for the field. In this survey paper, we discuss Embodied Vision-Language Planning (EVLP) tasks, a family of prominent embodied navigation and manipulation problems that jointly leverage computer vision and natural language for interaction in physical environments. We propose a taxonomy to unify these tasks and provide an in-depth analysis and comparison of the current and new algorithmic app",
    "link": "http://arxiv.org/abs/2304.02738",
    "context": "Title: Core Challenges in Embodied Vision-Language Planning. (arXiv:2304.02738v1 [cs.RO])\nAbstract: Recent advances in the areas of Multimodal Machine Learning and Artificial Intelligence (AI) have led to the development of challenging tasks at the intersection of Computer Vision, Natural Language Processing, and Robotics. Whereas many approaches and previous survey pursuits have characterised one or two of these dimensions, there has not been a holistic analysis at the center of all three. Moreover, even when combinations of these topics are considered, more focus is placed on describing, e.g., current architectural methods, as opposed to also illustrating high-level challenges and opportunities for the field. In this survey paper, we discuss Embodied Vision-Language Planning (EVLP) tasks, a family of prominent embodied navigation and manipulation problems that jointly leverage computer vision and natural language for interaction in physical environments. We propose a taxonomy to unify these tasks and provide an in-depth analysis and comparison of the current and new algorithmic app",
    "path": "papers/23/04/2304.02738.json",
    "total_tokens": 823,
    "translated_title": "具身视觉语言规划中的核心挑战",
    "translated_abstract": "多模式机器学习和人工智能领域的最新进展，引发了计算机视觉、自然语言处理和机器人技术交叉领域中的一系列挑战性任务。虽然许多方法和以前的调查追求已将其中一两个维度进行了描述，但还没有对所有三个维度进行全面分析。此外，即使考虑这些主题的组合，更多的关注点放在描述当前的体系结构方法上，而不是说明该领域的高层次挑战和机会。在本次调查中，我们讨论了具身视觉语言规划（EVLP）任务，这是一系列重要的具身导航和操作问题，共同利用计算机视觉和自然语言进行物理环境交互。我们提出了一个分类法来统一这些任务，并对当前的和新的算法应用进行了深入分析和比较。",
    "tldr": "本文讨论了具身视觉语言规划（EVLP）任务领域的挑战和机会，旨在共同利用计算机视觉和自然语言进行物理环境交互。",
    "en_tdlr": "This paper discusses the challenges and opportunities in Embodied Vision-Language Planning (EVLP) tasks, aimed at jointly leveraging computer vision and natural language for interaction in physical environments."
}