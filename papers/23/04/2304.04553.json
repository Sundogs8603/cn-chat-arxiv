{
    "title": "Two Steps Forward and One Behind: Rethinking Time Series Forecasting with Deep Learning. (arXiv:2304.04553v2 [cs.LG] UPDATED)",
    "abstract": "The Transformer is a highly successful deep learning model that has revolutionised the world of artificial neural networks, first in natural language processing and later in computer vision. This model is based on the attention mechanism and is able to capture complex semantic relationships between a variety of patterns present in the input data. Precisely because of these characteristics, the Transformer has recently been exploited for time series forecasting problems, assuming a natural adaptability to the domain of continuous numerical series. Despite the acclaimed results in the literature, some works have raised doubts about the robustness and effectiveness of this approach. In this paper, we further investigate the effectiveness of Transformer-based models applied to the domain of time series forecasting, demonstrate their limitations, and propose a set of alternative models that are better performing and significantly less complex. In particular, we empirically show how simplify",
    "link": "http://arxiv.org/abs/2304.04553",
    "context": "Title: Two Steps Forward and One Behind: Rethinking Time Series Forecasting with Deep Learning. (arXiv:2304.04553v2 [cs.LG] UPDATED)\nAbstract: The Transformer is a highly successful deep learning model that has revolutionised the world of artificial neural networks, first in natural language processing and later in computer vision. This model is based on the attention mechanism and is able to capture complex semantic relationships between a variety of patterns present in the input data. Precisely because of these characteristics, the Transformer has recently been exploited for time series forecasting problems, assuming a natural adaptability to the domain of continuous numerical series. Despite the acclaimed results in the literature, some works have raised doubts about the robustness and effectiveness of this approach. In this paper, we further investigate the effectiveness of Transformer-based models applied to the domain of time series forecasting, demonstrate their limitations, and propose a set of alternative models that are better performing and significantly less complex. In particular, we empirically show how simplify",
    "path": "papers/23/04/2304.04553.json",
    "total_tokens": 1008,
    "tldr": "本文回顾了Transformer在时间序列预测中的应用，探讨了其局限性，提出了一组简单而有效的替代模型，这些替代模型在时间序列预测中表现更好，复杂度更低。",
    "en_tdlr": "This paper reviews the application of Transformer in time series forecasting, explores its limitations, and proposes a set of simple yet effective alternative models that perform better and are less complex in time series forecasting."
}