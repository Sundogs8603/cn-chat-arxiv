{
    "title": "Adversary Aware Continual Learning. (arXiv:2304.14483v1 [cs.LG])",
    "abstract": "Class incremental learning approaches are useful as they help the model to learn new information (classes) sequentially, while also retaining the previously acquired information (classes). However, it has been shown that such approaches are extremely vulnerable to the adversarial backdoor attacks, where an intelligent adversary can introduce small amount of misinformation to the model in the form of imperceptible backdoor pattern during training to cause deliberate forgetting of a specific task or class at test time. In this work, we propose a novel defensive framework to counter such an insidious attack where, we use the attacker's primary strength-hiding the backdoor pattern by making it imperceptible to humans-against it, and propose to learn a perceptible (stronger) pattern (also during the training) that can overpower the attacker's imperceptible (weaker) pattern. We demonstrate the effectiveness of the proposed defensive mechanism through various commonly used Replay-based (both ",
    "link": "http://arxiv.org/abs/2304.14483",
    "context": "Title: Adversary Aware Continual Learning. (arXiv:2304.14483v1 [cs.LG])\nAbstract: Class incremental learning approaches are useful as they help the model to learn new information (classes) sequentially, while also retaining the previously acquired information (classes). However, it has been shown that such approaches are extremely vulnerable to the adversarial backdoor attacks, where an intelligent adversary can introduce small amount of misinformation to the model in the form of imperceptible backdoor pattern during training to cause deliberate forgetting of a specific task or class at test time. In this work, we propose a novel defensive framework to counter such an insidious attack where, we use the attacker's primary strength-hiding the backdoor pattern by making it imperceptible to humans-against it, and propose to learn a perceptible (stronger) pattern (also during the training) that can overpower the attacker's imperceptible (weaker) pattern. We demonstrate the effectiveness of the proposed defensive mechanism through various commonly used Replay-based (both ",
    "path": "papers/23/04/2304.14483.json",
    "total_tokens": 812,
    "translated_title": "对抗感知的迭代学习",
    "translated_abstract": "类别增量学习方法非常有用，因为它们帮助模型按顺序学习新信息（类别），同时保留之前获得的信息（类别）。然而，这样的方法极易受到对抗性后门攻击的影响，在训练期间，智能对手可以通过引入少量的信息误导模型，从而在测试时故意忘记特定的任务或类别。在这项工作中，我们提出了一种新的防御性框架来反击这种潜在攻击。我们利用攻击者的主要优势--使后门模式对人不可感知--并提议在训练期间学习一个可以压倒攻击者的可感知模式以抵消对抗性攻击者的模式。通过各种常用的Replay-based（两者都",
    "tldr": "本文提出了一种新的防御性框架，针对对抗性后门攻击，利用可感知模式压倒攻击者的不可感知模式，提高了模型的稳健性。",
    "en_tdlr": "The paper proposes a new defensive framework to tackle adversarial backdoor attacks on class incremental learning approaches by learning a perceptible pattern to overpower the attacker's imperceptible pattern, thus enhancing the model's robustness."
}