{
    "title": "Recurrent Transformer for Dynamic Graph Representation Learning with Edge Temporal States. (arXiv:2304.10079v1 [cs.LG])",
    "abstract": "Dynamic graph representation learning is growing as a trending yet challenging research task owing to the widespread demand for graph data analysis in real world applications. Despite the encouraging performance of many recent works that build upon recurrent neural networks (RNNs) and graph neural networks (GNNs), they fail to explicitly model the impact of edge temporal states on node features over time slices. Additionally, they are challenging to extract global structural features because of the inherent over-smoothing disadvantage of GNNs, which further restricts the performance. In this paper, we propose a recurrent difference graph transformer (RDGT) framework, which firstly assigns the edges in each snapshot with various types and weights to illustrate their specific temporal states explicitly, then a structure-reinforced graph transformer is employed to capture the temporal node representations by a recurrent learning paradigm. Experimental results on four real-world datasets d",
    "link": "http://arxiv.org/abs/2304.10079",
    "context": "Title: Recurrent Transformer for Dynamic Graph Representation Learning with Edge Temporal States. (arXiv:2304.10079v1 [cs.LG])\nAbstract: Dynamic graph representation learning is growing as a trending yet challenging research task owing to the widespread demand for graph data analysis in real world applications. Despite the encouraging performance of many recent works that build upon recurrent neural networks (RNNs) and graph neural networks (GNNs), they fail to explicitly model the impact of edge temporal states on node features over time slices. Additionally, they are challenging to extract global structural features because of the inherent over-smoothing disadvantage of GNNs, which further restricts the performance. In this paper, we propose a recurrent difference graph transformer (RDGT) framework, which firstly assigns the edges in each snapshot with various types and weights to illustrate their specific temporal states explicitly, then a structure-reinforced graph transformer is employed to capture the temporal node representations by a recurrent learning paradigm. Experimental results on four real-world datasets d",
    "path": "papers/23/04/2304.10079.json",
    "total_tokens": 859,
    "translated_title": "动态图表示学习中带有边时序状态的循环Transformer",
    "translated_abstract": "随着现实世界中对图数据分析的广泛需求，动态图表示学习正成为一项趋势性而具有挑战性的研究任务。尽管许多最近的研究基于循环神经网络（RNNs）和图神经网络（GNNs）展现了令人鼓舞的表现，但它们未能明确地对节点特征随时间片段的边时序状态产生影响进行建模。此外，由于GNNs的内在over-smoothing缺陷，它们很难提取全局结构特征，进一步限制了性能。在本文中，我们提出了一个循环差分图变换器（RDGT）框架，该框架首先为每个快照中的边分配了各种类型和权重，以明确地说明它们的特定时间状态，然后采用增强结构的图变换器来通过循环学习范式捕获时间节点表示。在四个真实的数据集上进行的实验结果表明",
    "tldr": "本文提出了循环差分图变换器框架，旨在解决动态图表示学习中未能明确建模边时序状态和提取全局结构特征的问题。",
    "en_tdlr": "This paper proposes a recurrent difference graph transformer framework to address the challenges of explicit modeling edge temporal states and extracting global structural features in dynamic graph representation learning."
}