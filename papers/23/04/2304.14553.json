{
    "title": "Appropriateness is all you need!. (arXiv:2304.14553v1 [cs.AI])",
    "abstract": "The strive to make AI applications \"safe\" has led to the development of safety-measures as the main or even sole normative requirement of their permissible use. Similar can be attested to the latest version of chatbots, such as chatGPT. In this view, if they are \"safe\", they are supposed to be permissible to deploy. This approach, which we call \"safety-normativity\", is rather limited in solving the emerging issues that chatGPT and other chatbots have caused thus far. In answering this limitation, in this paper we argue for limiting chatbots in the range of topics they can chat about according to the normative concept of appropriateness. We argue that rather than looking for \"safety\" in a chatbot's utterances to determine what they may and may not say, we ought to assess those utterances according to three forms of appropriateness: technical-discursive, social, and moral. We then spell out what requirements for chatbots follow from these forms of appropriateness to avoid the limits of p",
    "link": "http://arxiv.org/abs/2304.14553",
    "context": "Title: Appropriateness is all you need!. (arXiv:2304.14553v1 [cs.AI])\nAbstract: The strive to make AI applications \"safe\" has led to the development of safety-measures as the main or even sole normative requirement of their permissible use. Similar can be attested to the latest version of chatbots, such as chatGPT. In this view, if they are \"safe\", they are supposed to be permissible to deploy. This approach, which we call \"safety-normativity\", is rather limited in solving the emerging issues that chatGPT and other chatbots have caused thus far. In answering this limitation, in this paper we argue for limiting chatbots in the range of topics they can chat about according to the normative concept of appropriateness. We argue that rather than looking for \"safety\" in a chatbot's utterances to determine what they may and may not say, we ought to assess those utterances according to three forms of appropriateness: technical-discursive, social, and moral. We then spell out what requirements for chatbots follow from these forms of appropriateness to avoid the limits of p",
    "path": "papers/23/04/2304.14553.json",
    "total_tokens": 752,
    "translated_title": "适当性是你所需要的一切！",
    "translated_abstract": "保障AI应用程序的“安全性”已成为它们允许使用的主要规范要求，甚至是唯一规范要求。然而，这种“安全性规范性”方法已经显示出在解决chatGPT和其他chatbot引发的问题方面的局限性。本文提出了一种新的限制chatbot话题范围的“适当性规范性”方法，通过对话语的三种适当性（技术交际、社会、道德）进行评估来规定chatbot的语言表达要求，以避免其受约束的范围。",
    "tldr": "在chatbot的使用中，应该依据适当性原则而非纯粹的安全性原则来进行评估，以避免其受限制。",
    "en_tdlr": "This paper argues for evaluating chatbots based on appropriateness, including technical-discursive, social, and moral aspects, rather than solely on safety measures, in order to avoid limitations on their use."
}