{
    "title": "DuETT: Dual Event Time Transformer for Electronic Health Records. (arXiv:2304.13017v1 [cs.LG])",
    "abstract": "Electronic health records (EHRs) recorded in hospital settings typically contain a wide range of numeric time series data that is characterized by high sparsity and irregular observations. Effective modelling for such data must exploit its time series nature, the semantic relationship between different types of observations, and information in the sparsity structure of the data. Self-supervised Transformers have shown outstanding performance in a variety of structured tasks in NLP and computer vision. But multivariate time series data contains structured relationships over two dimensions: time and recorded event type, and straightforward applications of Transformers to time series data do not leverage this distinct structure. The quadratic scaling of self-attention layers can also significantly limit the input sequence length without appropriate input engineering. We introduce the DuETT architecture, an extension of Transformers designed to attend over both time and event type dimensio",
    "link": "http://arxiv.org/abs/2304.13017",
    "context": "Title: DuETT: Dual Event Time Transformer for Electronic Health Records. (arXiv:2304.13017v1 [cs.LG])\nAbstract: Electronic health records (EHRs) recorded in hospital settings typically contain a wide range of numeric time series data that is characterized by high sparsity and irregular observations. Effective modelling for such data must exploit its time series nature, the semantic relationship between different types of observations, and information in the sparsity structure of the data. Self-supervised Transformers have shown outstanding performance in a variety of structured tasks in NLP and computer vision. But multivariate time series data contains structured relationships over two dimensions: time and recorded event type, and straightforward applications of Transformers to time series data do not leverage this distinct structure. The quadratic scaling of self-attention layers can also significantly limit the input sequence length without appropriate input engineering. We introduce the DuETT architecture, an extension of Transformers designed to attend over both time and event type dimensio",
    "path": "papers/23/04/2304.13017.json",
    "total_tokens": 1063,
    "translated_title": "DuETT: 双重事件时间变换器用于电子病历",
    "translated_abstract": "医院设置中记录的电子病历（EHR）通常包含广泛的数字时间序列数据，其特征是高稀疏性和不规则观察。这些数据的有效建模必须利用其时间序列特性，不同类型观察之间的语义关系以及数据中稀疏性结构中的信息。自监督变压器在NLP和计算机视觉中的各种结构化任务中表现出了出色的性能。但是，多元时间序列数据包含两个维度上的结构化关系：时间和记录的事件类型，而直接将变压器应用于时间序列数据则不能利用这种独特的结构。自我注意力层的二次放缩还可以显着限制输入序列长度，而没有适当的输入工程。我们引入了DuETT架构，这是变压器的扩展，设计用于在EHR的时间和事件类型维度上关注。DuETT使用双重注意机制，它可以在不同上下文中学习相同时间步的不同表示。通过引入具有内核方法的自我注意力，DuETT避免了自我注意力的二次放缩，并过滤掉不相关的时间步骤。DuETT在四个基准EHR数据集上优于以前的单一任务最先进方法。",
    "tldr": "DuETT是一个用于EHR的双重事件时间变换器，通过双重注意机制学习不同上下文中相同时间步的不同表示，避免由于时间步伐大而产生的二次放缩问题，并在四个基准EHR数据集上优于以往的单一任务最先进方法。",
    "en_tdlr": "DuETT is a dual-event time transformer for EHR, which learns different representations of the same time step under different contexts by using a dual-attention mechanism, avoids the quadratic scaling problem caused by large time steps, and outperforms previous single-task state-of-the-art approaches on four benchmark EHR datasets."
}