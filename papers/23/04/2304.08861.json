{
    "title": "Impact Of Explainable AI On Cognitive Load: Insights From An Empirical Study. (arXiv:2304.08861v1 [cs.AI])",
    "abstract": "While the emerging research field of explainable artificial intelligence (XAI) claims to address the lack of explainability in high-performance machine learning models, in practice, XAI targets developers rather than actual end-users. Unsurprisingly, end-users are often unwilling to use XAI-based decision support systems. Similarly, there is limited interdisciplinary research on end-users' behavior during XAI explanations usage, rendering it unknown how explanations may impact cognitive load and further affect end-user performance. Therefore, we conducted an empirical study with 271 prospective physicians, measuring their cognitive load, task performance, and task time for distinct implementation-independent XAI explanation types using a COVID-19 use case. We found that these explanation types strongly influence end-users' cognitive load, task performance, and task time. Further, we contextualized a mental efficiency metric, ranking local XAI explanation types best, to provide recommen",
    "link": "http://arxiv.org/abs/2304.08861",
    "context": "Title: Impact Of Explainable AI On Cognitive Load: Insights From An Empirical Study. (arXiv:2304.08861v1 [cs.AI])\nAbstract: While the emerging research field of explainable artificial intelligence (XAI) claims to address the lack of explainability in high-performance machine learning models, in practice, XAI targets developers rather than actual end-users. Unsurprisingly, end-users are often unwilling to use XAI-based decision support systems. Similarly, there is limited interdisciplinary research on end-users' behavior during XAI explanations usage, rendering it unknown how explanations may impact cognitive load and further affect end-user performance. Therefore, we conducted an empirical study with 271 prospective physicians, measuring their cognitive load, task performance, and task time for distinct implementation-independent XAI explanation types using a COVID-19 use case. We found that these explanation types strongly influence end-users' cognitive load, task performance, and task time. Further, we contextualized a mental efficiency metric, ranking local XAI explanation types best, to provide recommen",
    "path": "papers/23/04/2304.08861.json",
    "total_tokens": 867,
    "translated_title": "可解释人工智能对认知负荷的影响：一项实证研究的见解",
    "translated_abstract": "虽然可解释人工智能（XAI）这一新兴研究领域旨在解决高性能机器学习模型解释缺陷的问题，但在实践中，XAI 更多地面向开发人员而非最终用户。因此，最终用户常常不愿意使用基于 XAI 的决策支持系统。同时，关于最终用户在使用 XAI 说明时的行为缺乏跨学科研究，因此我们通过一项 COVID-19 的使用案例，对271名潜在医生进行了实证研究，测量了他们在使用不同的实现无关 XAI 说明类型时的认知负荷，任务表现和任务时间。我们发现，这些说明类型强烈影响了最终用户的认知负荷、任务表现和任务时间。进一步地，我们研究了一个精神效率度量标准，其中地方 XAI 说明类型排名最佳，提供了建议。",
    "tldr": "一项实证研究表明，可解释人工智能对最终用户的认知负荷、任务表现和任务时间有重要影响，推荐使用实现无关的地方 XAI 说明类型。",
    "en_tdlr": "An empirical study shows that explainable artificial intelligence has significant impacts on end-users' cognitive load, task performance, and task time. Local XAI explanations are recommended for better mental efficiency."
}