{
    "title": "Empirical Analysis of the Strengths and Weaknesses of PEFT Techniques for LLMs. (arXiv:2304.14999v1 [cs.CL])",
    "abstract": "As foundation models continue to exponentially scale in size, efficient methods of adaptation become increasingly critical. Parameter-efficient fine-tuning (PEFT), a recent class of techniques that require only modifying a small percentage of the model parameters, is currently the most popular method for adapting large language models (LLMs). Several PEFT techniques have recently been proposed with varying tradeoffs. We provide a comprehensive and uniform benchmark of various PEFT techniques across a representative LLM, the FLAN-T5 model, and evaluate model performance across different data scales of classification and generation datasets. Based on this, we provide a framework for choosing the optimal fine-tuning techniques given the task type and data availability. Contrary to popular belief, we also empirically prove that PEFT techniques converge slower than full tuning in low data scenarios, and posit the amount of data required for PEFT methods to both perform well and converge eff",
    "link": "http://arxiv.org/abs/2304.14999",
    "context": "Title: Empirical Analysis of the Strengths and Weaknesses of PEFT Techniques for LLMs. (arXiv:2304.14999v1 [cs.CL])\nAbstract: As foundation models continue to exponentially scale in size, efficient methods of adaptation become increasingly critical. Parameter-efficient fine-tuning (PEFT), a recent class of techniques that require only modifying a small percentage of the model parameters, is currently the most popular method for adapting large language models (LLMs). Several PEFT techniques have recently been proposed with varying tradeoffs. We provide a comprehensive and uniform benchmark of various PEFT techniques across a representative LLM, the FLAN-T5 model, and evaluate model performance across different data scales of classification and generation datasets. Based on this, we provide a framework for choosing the optimal fine-tuning techniques given the task type and data availability. Contrary to popular belief, we also empirically prove that PEFT techniques converge slower than full tuning in low data scenarios, and posit the amount of data required for PEFT methods to both perform well and converge eff",
    "path": "papers/23/04/2304.14999.json",
    "total_tokens": 882,
    "translated_title": "LLM参数高效微调技术的优势和劣势的实证分析",
    "translated_abstract": "随着基于语言模型的模型规模呈指数级增长，高效的适应方法变得越来越关键。参数高效微调（PEFT）是目前最流行的适用于大型语言模型（LLM）的方法之一，只需要修改模型参数的一小部分，最近提出了几种具有不同权衡的PEFT技术。我们在代表性的LLM FLAN-T5模型上提供各种PEFT技术的全面和统一的基准测试，并评估在分类和生成数据集的不同数据规模下的模型性能。基于此，我们提供了一个框架，根据任务类型和数据可用性选择最佳的微调技术。与传统观念相反，我们通过实证证明PEFT技术在低数据场景下收敛速度比完全微调慢，并提出了PEFT方法需要表现良好和有效收敛所需要的数据量。",
    "tldr": "本文实证分析了参数高效微调技术在大型语言模型中的优势和劣势，提供了选择优化微调技术的框架，同时揭示了在低数据场景下PEFT技术收敛速度较慢的事实。",
    "en_tdlr": "This paper empirically analyzes the strengths and weaknesses of parameter-efficient fine-tuning techniques for large language models, provides a framework for choosing the optimal fine-tuning techniques based on task type and data availability, and reveals that PEFT techniques converge slower than full tuning in low data scenarios."
}