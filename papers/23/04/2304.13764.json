{
    "title": "Phagocytosis Unveiled: A Scalable and Interpretable Deep learning Framework for Neurodegenerative Disease Analysis. (arXiv:2304.13764v1 [eess.IV])",
    "abstract": "Quantifying the phagocytosis of dynamic, unstained cells is essential for evaluating neurodegenerative diseases. However, measuring rapid cell interactions and distinguishing cells from backgrounds make this task challenging when processing time-lapse phase-contrast video microscopy. In this study, we introduce a fully automated, scalable, and versatile realtime framework for quantifying and analyzing phagocytic activity. Our proposed pipeline can process large data-sets and includes a data quality verification module to counteract potential perturbations such as microscope movements and frame blurring. We also propose an explainable cell segmentation module to improve the interpretability of deep learning methods compared to black-box algorithms. This includes two interpretable deep learning capabilities: visual explanation and model simplification. We demonstrate that interpretability in deep learning is not the opposite of high performance, but rather provides essential deep learnin",
    "link": "http://arxiv.org/abs/2304.13764",
    "context": "Title: Phagocytosis Unveiled: A Scalable and Interpretable Deep learning Framework for Neurodegenerative Disease Analysis. (arXiv:2304.13764v1 [eess.IV])\nAbstract: Quantifying the phagocytosis of dynamic, unstained cells is essential for evaluating neurodegenerative diseases. However, measuring rapid cell interactions and distinguishing cells from backgrounds make this task challenging when processing time-lapse phase-contrast video microscopy. In this study, we introduce a fully automated, scalable, and versatile realtime framework for quantifying and analyzing phagocytic activity. Our proposed pipeline can process large data-sets and includes a data quality verification module to counteract potential perturbations such as microscope movements and frame blurring. We also propose an explainable cell segmentation module to improve the interpretability of deep learning methods compared to black-box algorithms. This includes two interpretable deep learning capabilities: visual explanation and model simplification. We demonstrate that interpretability in deep learning is not the opposite of high performance, but rather provides essential deep learnin",
    "path": "papers/23/04/2304.13764.json",
    "total_tokens": 970,
    "translated_title": "揭示巨噬细胞吞噬作用：用于神经退行性疾病分析的可扩展和可解释的深度学习框架",
    "translated_abstract": "量化动态无染色细胞的吞噬作用对于评估神经退行性疾病至关重要。然而，处理时间序列相衬显微镜视频时，测量快速细胞相互作用和区分细胞与背景使得这项任务具有挑战性。在本研究中，我们引入了一种完全自动化、可扩展和多功能的实时框架，用于量化和分析吞噬活性。我们提出的流程可以处理大型数据集，包括数据质量验证模块以抵消可能的显微镜运动和帧模糊等扰动。我们还提出了一个可解释的细胞分割模块，以改善与黑匣子算法相比的深度学习方法的可解释性。这包括两个可解释的深度学习能力：视觉说明和模型简化。我们证明了深度学习中的可解释性不是高性能的对立面，而是提供必要的深度学习能力。",
    "tldr": "本文提出了一种可扩展且可解释的深度学习框架，用于量化和分析吞噬活性以评估神经退行性疾病。流程可以处理大型数据集，包括数据质量验证和可解释的细胞分割模块。",
    "en_tdlr": "This paper proposes a scalable and interpretable deep learning framework for quantifying and analyzing phagocytic activity to evaluate neurodegenerative diseases. The proposed framework can process large datasets and includes a data quality verification module and an explainable cell segmentation module."
}