{
    "title": "AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head. (arXiv:2304.12995v1 [cs.CL])",
    "abstract": "Large language models (LLMs) have exhibited remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. Despite the recent success, current LLMs are not capable of processing complex audio information or conducting spoken conversations (like Siri or Alexa). In this work, we propose a multi-modal AI system named AudioGPT, which complements LLMs (i.e., ChatGPT) with 1) foundation models to process complex audio information and solve numerous understanding and generation tasks; and 2) the input/output interface (ASR, TTS) to support spoken dialogue. With an increasing demand to evaluate multi-modal LLMs of human intention understanding and cooperation with foundation models, we outline the principles and processes and test AudioGPT in terms of consistency, capability, and robustness. Experimental results demonstrate the capabilities of AudioGPT in solving AI tasks with speech, music, sound, and talking head understanding and gene",
    "link": "http://arxiv.org/abs/2304.12995",
    "context": "Title: AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head. (arXiv:2304.12995v1 [cs.CL])\nAbstract: Large language models (LLMs) have exhibited remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. Despite the recent success, current LLMs are not capable of processing complex audio information or conducting spoken conversations (like Siri or Alexa). In this work, we propose a multi-modal AI system named AudioGPT, which complements LLMs (i.e., ChatGPT) with 1) foundation models to process complex audio information and solve numerous understanding and generation tasks; and 2) the input/output interface (ASR, TTS) to support spoken dialogue. With an increasing demand to evaluate multi-modal LLMs of human intention understanding and cooperation with foundation models, we outline the principles and processes and test AudioGPT in terms of consistency, capability, and robustness. Experimental results demonstrate the capabilities of AudioGPT in solving AI tasks with speech, music, sound, and talking head understanding and gene",
    "path": "papers/23/04/2304.12995.json",
    "total_tokens": 904,
    "translated_title": "AudioGPT：理解和生成语音、音乐、声音和人头像",
    "translated_abstract": "大型语言模型（LLM）在各种领域和任务中展现出了卓越的能力，挑战了我们对学习和认知的理解。尽管最近取得了成功，但当前的LLM无法处理复杂的音频信息或进行口语交流（如Siri或Alexa）。在这项工作中，我们提出了一种名为AudioGPT的多模式人工智能系统，它通过以下方式补充了LLM（即ChatGPT）：1）提供基础模型以处理复杂的音频信息并解决众多的理解和生成任务；2）提供输入/输出接口（ASR，TTS）以支持口语对话。随着对人类意图理解和与基础模型协作的多模式LLM的评估需求的增加，我们概述了原则和过程，并测试了AudioGPT的一致性、能力和稳健性。实验结果显示，AudioGPT在解决具有语音、音乐、声音和人头像理解和生成的AI任务方面具有很强的能力。",
    "tldr": "AudioGPT是一种多模式人工智能系统，能够处理复杂的音频信息并支持口语对话，其实验结果表明其在处理语音、音乐、声音和人头像方面有着很强的能力。",
    "en_tdlr": "AudioGPT is a multi-modal AI system that can process complex audio information and support spoken dialogue. Experimental results show that it has strong abilities in handling tasks related to speech, music, sound, and talking head understanding and generation."
}