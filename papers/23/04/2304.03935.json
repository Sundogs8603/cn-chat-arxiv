{
    "title": "Last-Layer Fairness Fine-tuning is Simple and Effective for Neural Networks. (arXiv:2304.03935v1 [cs.LG])",
    "abstract": "As machine learning has been deployed ubiquitously across applications in modern data science, algorithmic fairness has become a great concern and varieties of fairness criteria have been proposed. Among them, imposing fairness constraints during learning, i.e. in-processing fair training, has been a popular type of training method because they don't require accessing sensitive attributes during test time in contrast to post-processing methods. Although imposing fairness constraints have been studied extensively for classical machine learning models, the effect these techniques have on deep neural networks is still unclear. Recent research has shown that adding fairness constraints to the objective function leads to severe over-fitting to fairness criteria in large models, and how to solve this challenge is an important open question. To address this challenge, we leverage the wisdom and power of pre-training and fine-tuning and develop a simple but novel framework to train fair neural",
    "link": "http://arxiv.org/abs/2304.03935",
    "context": "Title: Last-Layer Fairness Fine-tuning is Simple and Effective for Neural Networks. (arXiv:2304.03935v1 [cs.LG])\nAbstract: As machine learning has been deployed ubiquitously across applications in modern data science, algorithmic fairness has become a great concern and varieties of fairness criteria have been proposed. Among them, imposing fairness constraints during learning, i.e. in-processing fair training, has been a popular type of training method because they don't require accessing sensitive attributes during test time in contrast to post-processing methods. Although imposing fairness constraints have been studied extensively for classical machine learning models, the effect these techniques have on deep neural networks is still unclear. Recent research has shown that adding fairness constraints to the objective function leads to severe over-fitting to fairness criteria in large models, and how to solve this challenge is an important open question. To address this challenge, we leverage the wisdom and power of pre-training and fine-tuning and develop a simple but novel framework to train fair neural",
    "path": "papers/23/04/2304.03935.json",
    "total_tokens": 1136,
    "translated_title": "神经网络的最后一层公平微调简单有效",
    "translated_abstract": "随着机器学习在现代数据科学中得到广泛应用，算法公平性已成为一个重要关注点，并且提出了多种公平性标准。其中，在学习过程中施加公平性约束，即进行处理公平性训练，已成为一种流行的训练方法，因为与后处理方法不同，它们不需要在测试期间访问敏感属性。虽然在经典机器学习模型中对施加公平性约束进行了广泛研究，但这些技术对深度神经网络的影响仍不清楚。最近的研究表明，在目标函数中添加公平性约束会导致大型模型过度拟合公平性标准，如何解决这一挑战是一个重要的开放问题。为了解决这个问题，我们利用预训练和微调的智慧和能力，并开发了一种简单而新颖的框架来训练公平的神经网络。我们的方法是在满足感兴趣的公平性约束的少量标记数据上，使用不关注公平性的损失微调已预训练的神经网络。实验证明，我们的方法在基准数据集上实现了高水平的公平性，而不牺牲标准性能指标。此外，我们证明了我们的方法足够灵活，可以纳入任何感兴趣的公平性约束，并且对于高维数据可以进行几乎没有额外计算的扩展。",
    "tldr": "本文提出了一种新颖的公平性微调神经网络的框架，利用已预训练的神经网络和不关注公平性的损失微调神经网络的最后一层。实验证明该方法在基准数据集上实现了高水平的公平性，同时保留标准性能指标。",
    "en_tdlr": "This paper proposes a novel framework for fine-tuning neural networks for fairness, based on pre-trained models and using an unaware loss function. The method achieves high levels of fairness on benchmark datasets while retaining standard performance metrics."
}