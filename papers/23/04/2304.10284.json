{
    "title": "A Meta-heuristic Approach to Estimate and Explain Classifier Uncertainty. (arXiv:2304.10284v1 [cs.LG])",
    "abstract": "Trust is a crucial factor affecting the adoption of machine learning (ML) models. Qualitative studies have revealed that end-users, particularly in the medical domain, need models that can express their uncertainty in decision-making allowing users to know when to ignore the model's recommendations. However, existing approaches for quantifying decision-making uncertainty are not model-agnostic, or they rely on complex statistical derivations that are not easily understood by laypersons or end-users, making them less useful for explaining the model's decision-making process. This work proposes a set of class-independent meta-heuristics that can characterize the complexity of an instance in terms of factors are mutually relevant to both human and ML decision-making. The measures are integrated into a meta-learning framework that estimates the risk of misclassification. The proposed framework outperformed predicted probabilities in identifying instances at risk of being misclassified. The",
    "link": "http://arxiv.org/abs/2304.10284",
    "context": "Title: A Meta-heuristic Approach to Estimate and Explain Classifier Uncertainty. (arXiv:2304.10284v1 [cs.LG])\nAbstract: Trust is a crucial factor affecting the adoption of machine learning (ML) models. Qualitative studies have revealed that end-users, particularly in the medical domain, need models that can express their uncertainty in decision-making allowing users to know when to ignore the model's recommendations. However, existing approaches for quantifying decision-making uncertainty are not model-agnostic, or they rely on complex statistical derivations that are not easily understood by laypersons or end-users, making them less useful for explaining the model's decision-making process. This work proposes a set of class-independent meta-heuristics that can characterize the complexity of an instance in terms of factors are mutually relevant to both human and ML decision-making. The measures are integrated into a meta-learning framework that estimates the risk of misclassification. The proposed framework outperformed predicted probabilities in identifying instances at risk of being misclassified. The",
    "path": "papers/23/04/2304.10284.json",
    "total_tokens": 863,
    "translated_title": "一种估算并解释分类器不确定性的元启发式方法",
    "translated_abstract": "信任是影响机器学习模型采用的重要因素。定性研究表明，终端用户，特别是在医疗领域，需要能够在决策时表达不确定性的模型，以使用户知道何时忽略模型的建议。然而，现有的量化决策不确定性的方法不是模型无关的，就是依赖于不容易让普通人或终端用户理解的复杂统计推导，这使它们在解释模型的决策过程时不太有用。本文提出了一组类独立的元启发式方法，可以以人类和机器学习决策都互相关联的因素来表征一个实例的复杂性。这些度量被集成到一个元学习框架中，该框架估计了分类错误风险。所提出的框架在鉴别那些有可能被错误分类的实例方面，表现优于预测概率。",
    "tldr": "本文提出了一种元启发式方法，它可以以人类和机器学习决策都互相关联的因素来表征一个实例的复杂性，以估计分类错误的风险。",
    "en_tdlr": "This paper proposes a meta-heuristic approach to quantify the complexity of an instance in terms of factors relevant to both human and ML decision-making, and integrates these measures into a meta-learning framework to estimate the risk of misclassification."
}