{
    "title": "ESPT: A Self-Supervised Episodic Spatial Pretext Task for Improving Few-Shot Learning. (arXiv:2304.13287v1 [cs.CV])",
    "abstract": "Self-supervised learning (SSL) techniques have recently been integrated into the few-shot learning (FSL) framework and have shown promising results in improving the few-shot image classification performance. However, existing SSL approaches used in FSL typically seek the supervision signals from the global embedding of every single image. Therefore, during the episodic training of FSL, these methods cannot capture and fully utilize the local visual information in image samples and the data structure information of the whole episode, which are beneficial to FSL. To this end, we propose to augment the few-shot learning objective with a novel self-supervised Episodic Spatial Pretext Task (ESPT). Specifically, for each few-shot episode, we generate its corresponding transformed episode by applying a random geometric transformation to all the images in it. Based on these, our ESPT objective is defined as maximizing the local spatial relationship consistency between the original episode and ",
    "link": "http://arxiv.org/abs/2304.13287",
    "context": "Title: ESPT: A Self-Supervised Episodic Spatial Pretext Task for Improving Few-Shot Learning. (arXiv:2304.13287v1 [cs.CV])\nAbstract: Self-supervised learning (SSL) techniques have recently been integrated into the few-shot learning (FSL) framework and have shown promising results in improving the few-shot image classification performance. However, existing SSL approaches used in FSL typically seek the supervision signals from the global embedding of every single image. Therefore, during the episodic training of FSL, these methods cannot capture and fully utilize the local visual information in image samples and the data structure information of the whole episode, which are beneficial to FSL. To this end, we propose to augment the few-shot learning objective with a novel self-supervised Episodic Spatial Pretext Task (ESPT). Specifically, for each few-shot episode, we generate its corresponding transformed episode by applying a random geometric transformation to all the images in it. Based on these, our ESPT objective is defined as maximizing the local spatial relationship consistency between the original episode and ",
    "path": "papers/23/04/2304.13287.json",
    "total_tokens": 945,
    "tldr": "该论文提出了一种自监督故事情境空间预设任务（ESPT），通过在每个少样本情境中使用随机几何变换生成变化情境来帮助少样本学习，从而最大化原始情境和变化情境之间的局部空间关系一致性。",
    "en_tdlr": "This paper proposes a self-supervised Episodic Spatial Pretext Task (ESPT) to help with few-shot learning by generating transformed episodes through applying random geometric transformations to all images in each few-shot episode, thus maximizing the local spatial relationship consistency between the original and transformed episodes."
}