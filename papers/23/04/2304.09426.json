{
    "title": "Decoupled Training for Long-Tailed Classification With Stochastic Representations. (arXiv:2304.09426v1 [cs.LG])",
    "abstract": "Decoupling representation learning and classifier learning has been shown to be effective in classification with long-tailed data. There are two main ingredients in constructing a decoupled learning scheme; 1) how to train the feature extractor for representation learning so that it provides generalizable representations and 2) how to re-train the classifier that constructs proper decision boundaries by handling class imbalances in long-tailed data. In this work, we first apply Stochastic Weight Averaging (SWA), an optimization technique for improving the generalization of deep neural networks, to obtain better generalizing feature extractors for long-tailed classification. We then propose a novel classifier re-training algorithm based on stochastic representation obtained from the SWA-Gaussian, a Gaussian perturbed SWA, and a self-distillation strategy that can harness the diverse stochastic representations based on uncertainty estimates to build more robust classifiers. Extensive exp",
    "link": "http://arxiv.org/abs/2304.09426",
    "context": "Title: Decoupled Training for Long-Tailed Classification With Stochastic Representations. (arXiv:2304.09426v1 [cs.LG])\nAbstract: Decoupling representation learning and classifier learning has been shown to be effective in classification with long-tailed data. There are two main ingredients in constructing a decoupled learning scheme; 1) how to train the feature extractor for representation learning so that it provides generalizable representations and 2) how to re-train the classifier that constructs proper decision boundaries by handling class imbalances in long-tailed data. In this work, we first apply Stochastic Weight Averaging (SWA), an optimization technique for improving the generalization of deep neural networks, to obtain better generalizing feature extractors for long-tailed classification. We then propose a novel classifier re-training algorithm based on stochastic representation obtained from the SWA-Gaussian, a Gaussian perturbed SWA, and a self-distillation strategy that can harness the diverse stochastic representations based on uncertainty estimates to build more robust classifiers. Extensive exp",
    "path": "papers/23/04/2304.09426.json",
    "total_tokens": 899,
    "translated_title": "长尾分类的解耦训练和随机表示法",
    "translated_abstract": "在长尾数据分类中，解耦表示学习和分类器学习已经被证明是有效的。构建解耦式学习方案有两个主要因素：1）如何训练特征提取器进行表示学习，以便提供可泛化的表示；2）如何重新训练分类器，通过处理长尾数据中的类别不平衡来构建适当的决策边界。 本文首先应用随机权重平均（SWA）优化技术来获得更好的泛化特征提取器，用于长尾分类。然后，我们基于SWA-Gaussian提出了一种新的分类器重新训练算法，该算法利用基于不确定性估计的多样随机表示来构建更强大的分类器。在多个基准数据集上进行的广泛实验表明，所提出的方法有效地解决了长尾分类问题。",
    "tldr": "本文提出了解耦训练和利用随机表示法进行分类的方法来解决长尾分类问题，使用SWA优化技术得到更好的特征提取器，并提出一种基于随机表示进行分类器重新训练的算法。",
    "en_tdlr": "This paper proposes a decoupled training method using stochastic representations for long-tailed classification. They use the SWA optimization technique to obtain better feature extractors and propose a novel classifier re-training algorithm based on stochastic representations obtained from the SWA-Gaussian. The experiments show the effectiveness of the proposed method in addressing the long-tailed classification problem."
}