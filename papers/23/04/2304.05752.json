{
    "title": "Function Space and Critical Points of Linear Convolutional Networks. (arXiv:2304.05752v1 [cs.LG])",
    "abstract": "We study the geometry of linear networks with one-dimensional convolutional layers. The function spaces of these networks can be identified with semi-algebraic families of polynomials admitting sparse factorizations. We analyze the impact of the network's architecture on the function space's dimension, boundary, and singular points. We also describe the critical points of the network's parameterization map. Furthermore, we study the optimization problem of training a network with the squared error loss. We prove that for architectures where all strides are larger than one and generic data, the non-zero critical points of that optimization problem are smooth interior points of the function space. This property is known to be false for dense linear networks and linear convolutional networks with stride one.",
    "link": "http://arxiv.org/abs/2304.05752",
    "context": "Title: Function Space and Critical Points of Linear Convolutional Networks. (arXiv:2304.05752v1 [cs.LG])\nAbstract: We study the geometry of linear networks with one-dimensional convolutional layers. The function spaces of these networks can be identified with semi-algebraic families of polynomials admitting sparse factorizations. We analyze the impact of the network's architecture on the function space's dimension, boundary, and singular points. We also describe the critical points of the network's parameterization map. Furthermore, we study the optimization problem of training a network with the squared error loss. We prove that for architectures where all strides are larger than one and generic data, the non-zero critical points of that optimization problem are smooth interior points of the function space. This property is known to be false for dense linear networks and linear convolutional networks with stride one.",
    "path": "papers/23/04/2304.05752.json",
    "total_tokens": 798,
    "translated_title": "线性卷积网络的函数空间和临界点",
    "translated_abstract": "我们研究了具有一维卷积层的线性网络的几何结构。这些网络的函数空间可以被认为是具有稀疏因子分解的半代数多项式族。我们分析了网络架构对函数空间的维度、边界和奇异点的影响。我们还描述了网络参数化映射的临界点。此外，我们研究了使用平方误差损失训练网络的优化问题。我们证明了对于所有步幅大于一且数据一般的架构，该优化问题的非零临界点是函数空间的平滑内部点。对于稠密的线性网络和步幅为一的线性卷积网络，这种特性被认为是错误的。",
    "tldr": "研究了具有一维卷积层的线性网络的函数空间，分析了网络架构对函数空间的影响并证明了对于步幅大于一且数据一般的架构，该优化问题的非零临界点是函数空间的平滑内部点。",
    "en_tdlr": "The paper studies the function space of linear networks with one-dimensional convolutional layers, analyzing the impact of the network's architecture on the space's dimension, boundary, and singular points, and proving that for specific architectures, non-zero critical points of the optimization problem are smooth interior points of the function space."
}