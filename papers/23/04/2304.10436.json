{
    "title": "Safety Assessment of Chinese Large Language Models. (arXiv:2304.10436v1 [cs.CL])",
    "abstract": "With the rapid popularity of large language models such as ChatGPT and GPT-4, a growing amount of attention is paid to their safety concerns. These models may generate insulting and discriminatory content, reflect incorrect social values, and may be used for malicious purposes such as fraud and dissemination of misleading information. Evaluating and enhancing their safety is particularly essential for the wide application of large language models (LLMs). To further promote the safe deployment of LLMs, we develop a Chinese LLM safety assessment benchmark. Our benchmark explores the comprehensive safety performance of LLMs from two perspectives: 8 kinds of typical safety scenarios and 6 types of more challenging instruction attacks. Our benchmark is based on a straightforward process in which it provides the test prompts and evaluates the safety of the generated responses from the evaluated model. In evaluation, we utilize the LLM's strong evaluation ability and develop it as a safety ev",
    "link": "http://arxiv.org/abs/2304.10436",
    "context": "Title: Safety Assessment of Chinese Large Language Models. (arXiv:2304.10436v1 [cs.CL])\nAbstract: With the rapid popularity of large language models such as ChatGPT and GPT-4, a growing amount of attention is paid to their safety concerns. These models may generate insulting and discriminatory content, reflect incorrect social values, and may be used for malicious purposes such as fraud and dissemination of misleading information. Evaluating and enhancing their safety is particularly essential for the wide application of large language models (LLMs). To further promote the safe deployment of LLMs, we develop a Chinese LLM safety assessment benchmark. Our benchmark explores the comprehensive safety performance of LLMs from two perspectives: 8 kinds of typical safety scenarios and 6 types of more challenging instruction attacks. Our benchmark is based on a straightforward process in which it provides the test prompts and evaluates the safety of the generated responses from the evaluated model. In evaluation, we utilize the LLM's strong evaluation ability and develop it as a safety ev",
    "path": "papers/23/04/2304.10436.json",
    "total_tokens": 1000,
    "translated_title": "中国大型语言模型的安全评估",
    "translated_abstract": "随着诸如ChatGPT和GPT-4等大型语言模型的迅速普及，人们越来越关注它们的安全问题。这些模型可能生成侮辱性和歧视性内容，反映不正确的社会价值观，并可能被用于欺诈和传播误导信息等恶意用途。评估和增强它们的安全性对于广泛应用大型语言模型(LLMs)尤为重要。为进一步促进LLMs的安全部署,我们开发了一个中国LLM安全评估基准。我们的基准从8种典型的安全场景和6种更具挑战性的指令攻击两个方面探索LLMs的综合安全性能。我们的基准是基于一个简单明了的过程，其中它提供测试提示并评估从评估模型产生的响应的安全性。在评估中，我们利用LLMs的强大评估能力，并将其开发为一种安全评估工具，以量化评估模型的安全性能。实验结果表明，我们的基准对于评估和比较不同的中文LLMs的安全性能是有效和可靠的。",
    "tldr": "该论文介绍了中国大型语言模型的安全评估，提出一种基于8种典型安全场景和6种更具挑战性指令攻击的综合安全性能评估基准，利用LLMs的强大评估能力开发并量化了评估模型的安全性能。",
    "en_tdlr": "This paper introduces the safety assessment of Chinese large language models, proposes a comprehensive safety assessment benchmark based on 8 typical safety scenarios and 6 more challenging instruction attacks, and utilizes the powerful evaluation ability of LLMs to develop and quantify the safety performance of evaluated models."
}