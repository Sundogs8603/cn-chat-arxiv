{
    "title": "Multisample Flow Matching: Straightening Flows with Minibatch Couplings. (arXiv:2304.14772v1 [cs.LG])",
    "abstract": "Simulation-free methods for training continuous-time generative models construct probability paths that go between noise distributions and individual data samples. Recent works, such as Flow Matching, derived paths that are optimal for each data sample. However, these algorithms rely on independent data and noise samples, and do not exploit underlying structure in the data distribution for constructing probability paths. We propose Multisample Flow Matching, a more general framework that uses non-trivial couplings between data and noise samples while satisfying the correct marginal constraints. At very small overhead costs, this generalization allows us to (i) reduce gradient variance during training, (ii) obtain straighter flows for the learned vector field, which allows us to generate high-quality samples using fewer function evaluations, and (iii) obtain transport maps with lower cost in high dimensions, which has applications beyond generative modeling. Importantly, we do so in a c",
    "link": "http://arxiv.org/abs/2304.14772",
    "context": "Title: Multisample Flow Matching: Straightening Flows with Minibatch Couplings. (arXiv:2304.14772v1 [cs.LG])\nAbstract: Simulation-free methods for training continuous-time generative models construct probability paths that go between noise distributions and individual data samples. Recent works, such as Flow Matching, derived paths that are optimal for each data sample. However, these algorithms rely on independent data and noise samples, and do not exploit underlying structure in the data distribution for constructing probability paths. We propose Multisample Flow Matching, a more general framework that uses non-trivial couplings between data and noise samples while satisfying the correct marginal constraints. At very small overhead costs, this generalization allows us to (i) reduce gradient variance during training, (ii) obtain straighter flows for the learned vector field, which allows us to generate high-quality samples using fewer function evaluations, and (iii) obtain transport maps with lower cost in high dimensions, which has applications beyond generative modeling. Importantly, we do so in a c",
    "path": "papers/23/04/2304.14772.json",
    "total_tokens": 953,
    "translated_title": "多样本流匹配：利用小批量耦合将流进行矫正",
    "translated_abstract": "无需模拟的连续时间生成模型训练方法构建了从噪声分布到单个数据样本的概率路径。最近的作品，如流匹配，导出了最适合每个数据样本的路径。然而，这些算法依赖于独立的数据和噪声样本，并且不利用数据分布中的基础结构来构建概率路径。我们提出了多样本流匹配，这是一个更通用的框架，使用数据和噪声样本之间的非平凡耦合，同时满足正确的边缘约束。在非常小的开销下，这种泛化使我们能够(i) 在训练过程中降低梯度方差，(ii) 获得更加直接的流，这使我们可以使用更少的函数评估生成高质量的样本，(iii) 获得更低维代价的运输图，这在生成模型之外也有应用。重要的是，我们以概念上简单的方式实现了这一点，基于一种新颖的小批量耦合层。",
    "tldr": "该论文提出了一种多样本流匹配算法，在满足正确的边缘约束的条件下，利用小批量耦合将流进行矫正，从而使生成模型的训练更加高效，并获得更高质量、更低维代价的运输图。",
    "en_tdlr": "This paper proposes a multisample flow matching algorithm that straightens flows with minibatch couplings, which leads to more efficient training of generative models, generates higher-quality samples with fewer function evaluations, and obtains transport maps with lower cost in high dimensions while satisfying the correct marginal constraints."
}