{
    "title": "Exploring the Trade-Offs: Unified Large Language Models vs Local Fine-Tuned Models for Highly-Specific Radiology NLI Task. (arXiv:2304.09138v1 [cs.CL])",
    "abstract": "Recently, ChatGPT and GPT-4 have emerged and gained immense global attention due to their unparalleled performance in language processing. Despite demonstrating impressive capability in various open-domain tasks, their adequacy in highly specific fields like radiology remains untested. Radiology presents unique linguistic phenomena distinct from open-domain data due to its specificity and complexity. Assessing the performance of large language models (LLMs) in such specific domains is crucial not only for a thorough evaluation of their overall performance but also for providing valuable insights into future model design directions: whether model design should be generic or domain-specific. To this end, in this study, we evaluate the performance of ChatGPT/GPT-4 on a radiology NLI task and compare it to other models fine-tuned specifically on task-related data samples. We also conduct a comprehensive investigation on ChatGPT/GPT-4's reasoning ability by introducing varying levels of inf",
    "link": "http://arxiv.org/abs/2304.09138",
    "context": "Title: Exploring the Trade-Offs: Unified Large Language Models vs Local Fine-Tuned Models for Highly-Specific Radiology NLI Task. (arXiv:2304.09138v1 [cs.CL])\nAbstract: Recently, ChatGPT and GPT-4 have emerged and gained immense global attention due to their unparalleled performance in language processing. Despite demonstrating impressive capability in various open-domain tasks, their adequacy in highly specific fields like radiology remains untested. Radiology presents unique linguistic phenomena distinct from open-domain data due to its specificity and complexity. Assessing the performance of large language models (LLMs) in such specific domains is crucial not only for a thorough evaluation of their overall performance but also for providing valuable insights into future model design directions: whether model design should be generic or domain-specific. To this end, in this study, we evaluate the performance of ChatGPT/GPT-4 on a radiology NLI task and compare it to other models fine-tuned specifically on task-related data samples. We also conduct a comprehensive investigation on ChatGPT/GPT-4's reasoning ability by introducing varying levels of inf",
    "path": "papers/23/04/2304.09138.json",
    "total_tokens": 940,
    "translated_title": "探索权衡：统一的大语言模型 vs 专为高度特定的放射学 NLI 任务微调的本地模型",
    "translated_abstract": "最近，ChatGPT 和 GPT-4 凭借其在语言处理方面的无与伦比的性能而崭露头角，并引起了广泛关注。尽管在各种开放领域的任务中展现出了令人印象深刻的能力，但它们在放射学等高度特定领域的足够性尚未得到测试。放射学由于其特异性和复杂性呈现出与开放领域数据不同的独特语言现象。评估大型语言模型（LLMs）在这样的特定领域中的性能对于全面评估它们的整体性能以及为未来的模型设计方向提供有价值的见解是至关重要的：无论模型设计是否应是通用的还是领域特定的。为此，本研究评估了 ChatGPT/GPT-4 在放射学 NLI 任务中的表现，并将其与专为任务相关数据样本微调的其他模型进行比较。我们还通过引入不同级别的推理对 ChatGPT/GPT-4 的推理能力进行了全面的研究。",
    "tldr": "本文评估了大规模语言模型与专为高度特定的放射学自然语言推理任务微调的本地模型之间的表现差异，并探讨了未来的领域特定模型设计方向。",
    "en_tdlr": "This paper evaluates the performance difference between large language models and local models fine-tuned for highly specific radiology natural language inference task, and explores the future direction of domain-specific model design."
}