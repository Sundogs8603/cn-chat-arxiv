{
    "title": "PODIA-3D: Domain Adaptation of 3D Generative Model Across Large Domain Gap Using Pose-Preserved Text-to-Image Diffusion. (arXiv:2304.01900v1 [cs.CV])",
    "abstract": "Recently, significant advancements have been made in 3D generative models, however training these models across diverse domains is challenging and requires an huge amount of training data and knowledge of pose distribution. Text-guided domain adaptation methods have allowed the generator to be adapted to the target domains using text prompts, thereby obviating the need for assembling numerous data. Recently, DATID-3D presents impressive quality of samples in text-guided domain, preserving diversity in text by leveraging text-to-image diffusion. However, adapting 3D generators to domains with significant domain gaps from the source domain still remains challenging due to issues in current text-to-image diffusion models as following: 1) shape-pose trade-off in diffusion-based translation, 2) pose bias, and 3) instance bias in the target domain, resulting in inferior 3D shapes, low text-image correspondence, and low intra-domain diversity in the generated samples. To address these issues,",
    "link": "http://arxiv.org/abs/2304.01900",
    "context": "Title: PODIA-3D: Domain Adaptation of 3D Generative Model Across Large Domain Gap Using Pose-Preserved Text-to-Image Diffusion. (arXiv:2304.01900v1 [cs.CV])\nAbstract: Recently, significant advancements have been made in 3D generative models, however training these models across diverse domains is challenging and requires an huge amount of training data and knowledge of pose distribution. Text-guided domain adaptation methods have allowed the generator to be adapted to the target domains using text prompts, thereby obviating the need for assembling numerous data. Recently, DATID-3D presents impressive quality of samples in text-guided domain, preserving diversity in text by leveraging text-to-image diffusion. However, adapting 3D generators to domains with significant domain gaps from the source domain still remains challenging due to issues in current text-to-image diffusion models as following: 1) shape-pose trade-off in diffusion-based translation, 2) pose bias, and 3) instance bias in the target domain, resulting in inferior 3D shapes, low text-image correspondence, and low intra-domain diversity in the generated samples. To address these issues,",
    "path": "papers/23/04/2304.01900.json",
    "total_tokens": 1195,
    "translated_title": "基于姿态保留的文本图像扩散的PODIA-3D：跨越大领域间隙的3D生成模型的领域自适应",
    "translated_abstract": "最近，3D生成模型取得了显著进展，但跨越不同领域进行训练是具有挑战性的，并需要大量的训练数据和姿态分布知识。通过使用文本提示的文本导向领域自适应方法，使生成器能够适应目标领域，从而省去了组装大量数据的需求。我们提出了一种名为PODIA-3D的领域自适应方法，通过保留姿态的文本图像扩散来跨越大领域间隙训练3D生成模型，以往的方法由于扩散式翻译中的形状 - 姿态权衡，姿态偏见以及目标领域中的实例偏见等问题，导致生成的样本中3D形状较差，文本-图像对应度低，生成样本中内部领域多样性不足的问题得到了解决。",
    "tldr": "文本导向的领域自适应方法在跨越领域差异方面取得了进展，但面向具有显着领域差异的目标领域仍具有挑战性，PODIA-3D提出了一种基于姿态保留的文本图像扩散的方法，以弥补这方面的不足。",
    "en_tdlr": "Text-guided domain adaptation methods have advanced in overcoming domain differences, but significant domain gaps still pose a challenge. PODIA-3D presents a pose-preserved text-to-image diffusion method to train 3D generative models and addresses issues such as shape-pose trade-off, pose and instance bias in target domains."
}