{
    "title": "Estimation of sparse linear regression coefficients under $L$-subexponential covariates. (arXiv:2304.11958v1 [math.ST])",
    "abstract": "We address a task of estimating sparse coefficients in linear regression when the covariates are drawn from an $L$-subexponential random vector, which belongs to a class of distributions having heavier tails than a Gaussian random vector. Prior works have tackled this issue by assuming that the covariates are drawn from an $L$-subexponential random vector and have established error bounds that resemble those derived for Gaussian random vectors. However, these previous methods require stronger conditions to derive error bounds than those employed for Gaussian random vectors. In the present paper, we present an error bound identical to that obtained for Gaussian random vectors, up to constant factors, without requiring stronger conditions, even when the covariates are drawn from an $L$-subexponential random vector. Somewhat interestingly, we utilize an $\\ell_1$-penalized Huber regression, that is recognized for its robustness to heavy-tailed random noises, not covariates. We believe that",
    "link": "http://arxiv.org/abs/2304.11958",
    "context": "Title: Estimation of sparse linear regression coefficients under $L$-subexponential covariates. (arXiv:2304.11958v1 [math.ST])\nAbstract: We address a task of estimating sparse coefficients in linear regression when the covariates are drawn from an $L$-subexponential random vector, which belongs to a class of distributions having heavier tails than a Gaussian random vector. Prior works have tackled this issue by assuming that the covariates are drawn from an $L$-subexponential random vector and have established error bounds that resemble those derived for Gaussian random vectors. However, these previous methods require stronger conditions to derive error bounds than those employed for Gaussian random vectors. In the present paper, we present an error bound identical to that obtained for Gaussian random vectors, up to constant factors, without requiring stronger conditions, even when the covariates are drawn from an $L$-subexponential random vector. Somewhat interestingly, we utilize an $\\ell_1$-penalized Huber regression, that is recognized for its robustness to heavy-tailed random noises, not covariates. We believe that",
    "path": "papers/23/04/2304.11958.json",
    "total_tokens": 999,
    "translated_title": "在 $L$-亚指数协变量下的稀疏线性回归系数估计",
    "translated_abstract": "当协变量来自 $L$-亚指数随机向量时，我们解决了在线性回归中估计稀疏系数的任务，该随机向量属于一类具有比高斯随机向量更重的尾巴的分布。以前的工作通过假设协变量来自 $L$-亚指数随机向量来解决这个问题，并建立了类似于对高斯随机向量导出的误差界限。然而，这些以前的方法要求更强的条件，以导出与高斯随机向量相同的误差界限。在本文中，我们在不需要更强的条件的情况下提出了与高斯随机向量相同（在常数因子下），甚至当协变量来自 $L$-亚指数随机向量时的误差界限。有趣的是，我们利用了 $\\ell_1$-帕伯回归，该回归因其对重尾随机噪声的鲁棒性而被认为是重要的，而不是协变量。我们相信...",
    "tldr": "本文提出了一种方法，在不需要更强条件的情况下，即使在协变量来自 $L$-亚指数随机向量的情况下，使用$\\ell_1$ -帕伯回归进行线性回归，可以得到与高斯随机向量相同（在常数因子下）的误差界限。",
    "en_tdlr": "This paper proposes a method that can estimate sparse coefficients in linear regression without requiring stronger conditions, even when the covariates are drawn from $L$-subexponential random vector. The method uses $\\ell_1$-penalized Huber regression for its robustness to heavy-tailed random noise. The error bound obtained is identical to that for Gaussian random vectors, up to constant factors."
}