{
    "title": "ASL Citizen: A Community-Sourced Dataset for Advancing Isolated Sign Language Recognition. (arXiv:2304.05934v1 [cs.CV])",
    "abstract": "Sign languages are used as a primary language by approximately 70 million D/deaf people world-wide. However, most communication technologies operate in spoken and written languages, creating inequities in access. To help tackle this problem, we release ASL Citizen, the largest Isolated Sign Language Recognition (ISLR) dataset to date, collected with consent and containing 83,912 videos for 2,731 distinct signs filmed by 52 signers in a variety of environments. We propose that this dataset be used for sign language dictionary retrieval for American Sign Language (ASL), where a user demonstrates a sign to their own webcam with the aim of retrieving matching signs from a dictionary. We show that training supervised machine learning classifiers with our dataset greatly advances the state-of-the-art on metrics relevant for dictionary retrieval, achieving, for instance, 62% accuracy and a recall-at-10 of 90%, evaluated entirely on videos of users who are not present in the training or valida",
    "link": "http://arxiv.org/abs/2304.05934",
    "context": "Title: ASL Citizen: A Community-Sourced Dataset for Advancing Isolated Sign Language Recognition. (arXiv:2304.05934v1 [cs.CV])\nAbstract: Sign languages are used as a primary language by approximately 70 million D/deaf people world-wide. However, most communication technologies operate in spoken and written languages, creating inequities in access. To help tackle this problem, we release ASL Citizen, the largest Isolated Sign Language Recognition (ISLR) dataset to date, collected with consent and containing 83,912 videos for 2,731 distinct signs filmed by 52 signers in a variety of environments. We propose that this dataset be used for sign language dictionary retrieval for American Sign Language (ASL), where a user demonstrates a sign to their own webcam with the aim of retrieving matching signs from a dictionary. We show that training supervised machine learning classifiers with our dataset greatly advances the state-of-the-art on metrics relevant for dictionary retrieval, achieving, for instance, 62% accuracy and a recall-at-10 of 90%, evaluated entirely on videos of users who are not present in the training or valida",
    "path": "papers/23/04/2304.05934.json",
    "total_tokens": 986,
    "translated_title": "ASL Citizen: 一个推进独立手语识别的社区数据集",
    "translated_abstract": "手语被全球约7000万聋健人士用作主要语言。然而，大多数交流技术运作在口头和书面语言中，导致获取信息存在不公平。为了解决这个问题，我们发布了ASL Citizen，它是迄今为止最大的独立手语识别 (ISLR) 数据集，经过同意收集，包括52个手语者在各种环境中拍摄的2,731个不同手势的83,912个视频。我们建议将这个数据集用于美国手语 (ASL) 的手语字典检索，用户通过自己的网络摄像头演示手语，从字典中检索相匹配的手语。我们展示了利用我们的数据集对监督机器学习分类器进行训练，在与字典检索相关的度量标准上取得了显著进展，例如在训练或验证中未出现的用户的视频上，实现了62％的准确性和90％的前10项检索召回率。",
    "tldr": "ASL Citizen是目前最大的独立手语识别数据集，可用于手语字典检索，利用该数据集训练的机器学习分类器在度量标准上取得显著进展，例如在训练或验证中未出现的用户的视频上，实现了62％的准确性和90％的前10项检索召回率。",
    "en_tdlr": "ASL Citizen is the largest ISLR dataset to date, containing 83,912 videos for 2,731 signs collected from 52 signers, which can be used for ASL sign language dictionary retrieval. Trained machine learning classifiers with this dataset achieved significant progress on relevant metrics, such as 62% accuracy and a recall-at-10 of 90%, evaluated entirely on videos of users who are not present in the training or validation set."
}