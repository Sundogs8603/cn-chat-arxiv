{
    "title": "A Comprehensive Evaluation of the Copy Mechanism for Natural Language to SPARQL Query Generation. (arXiv:2304.07772v1 [cs.CL])",
    "abstract": "In recent years, the field of neural machine translation (NMT) for SPARQL query generation has witnessed a significant growth. Recently, the incorporation of the copy mechanism with traditional encoder-decoder architectures and the use of pre-trained encoder-decoders have set new performance benchmarks. This paper presents a large variety of experiments that replicate and expand upon recent NMT-based SPARQL generation studies, comparing pre-trained and non-pre-trained models, question annotation formats, and the use of a copy mechanism for non-pre-trained and pre-trained models. Our results show that either adding the copy mechanism or using a question annotation improves performances for nonpre-trained models and for pre-trained models, setting new baselines for three popular datasets.",
    "link": "http://arxiv.org/abs/2304.07772",
    "context": "Title: A Comprehensive Evaluation of the Copy Mechanism for Natural Language to SPARQL Query Generation. (arXiv:2304.07772v1 [cs.CL])\nAbstract: In recent years, the field of neural machine translation (NMT) for SPARQL query generation has witnessed a significant growth. Recently, the incorporation of the copy mechanism with traditional encoder-decoder architectures and the use of pre-trained encoder-decoders have set new performance benchmarks. This paper presents a large variety of experiments that replicate and expand upon recent NMT-based SPARQL generation studies, comparing pre-trained and non-pre-trained models, question annotation formats, and the use of a copy mechanism for non-pre-trained and pre-trained models. Our results show that either adding the copy mechanism or using a question annotation improves performances for nonpre-trained models and for pre-trained models, setting new baselines for three popular datasets.",
    "path": "papers/23/04/2304.07772.json",
    "total_tokens": 824,
    "translated_title": "自然语言到SPARQL查询生成的复制机制综合评估",
    "translated_abstract": "近年来，神经机器翻译（NMT）领域在SPARQL查询生成方面有了显著的增长。最近，将复制机制与传统的编码器-解码器架构相结合，并使用预训练的编码器-解码器，创造了新的性能基准。本文展示了大量的实验，复制并扩展了最近的基于NMT的SPARQL生成研究，比较了预训练和非预训练模型、问题注释格式以及对于非预训练和预训练模型使用复制机制的影响。我们的结果表明，对于非预训练模型和预训练模型，添加复制机制或使用问题注释都可以提高性能，并为三个流行数据集设置了新的基准。",
    "tldr": "本研究综合评估自然语言到SPARQL查询生成中的复制机制，通过大量实验研究预训练和非预训练模型、问题注释格式以及使用复制机制的影响，并证明了在这些方面的优化可以提高性能。",
    "en_tdlr": "This paper comprehensively evaluates the copy mechanism for natural language to SPARQL query generation, and shows through a variety of experiments the benefits of pre-training, the use of question annotations, and the incorporation of the copy mechanism for both pre-trained and non-pretrained models. The study sets new benchmarks for three popular datasets."
}