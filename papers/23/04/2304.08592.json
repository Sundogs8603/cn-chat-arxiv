{
    "title": "Improving Scene Text Recognition for Character-Level Long-Tailed Distribution. (arXiv:2304.08592v1 [cs.CV])",
    "abstract": "Despite the recent remarkable improvements in scene text recognition (STR), the majority of the studies focused mainly on the English language, which only includes few number of characters. However, STR models show a large performance degradation on languages with a numerous number of characters (e.g., Chinese and Korean), especially on characters that rarely appear due to the long-tailed distribution of characters in such languages. To address such an issue, we conducted an empirical analysis using synthetic datasets with different character-level distributions (e.g., balanced and long-tailed distributions). While increasing a substantial number of tail classes without considering the context helps the model to correctly recognize characters individually, training with such a synthetic dataset interferes the model with learning the contextual information (i.e., relation among characters), which is also important for predicting the whole word. Based on this motivation, we propose a nov",
    "link": "http://arxiv.org/abs/2304.08592",
    "context": "Title: Improving Scene Text Recognition for Character-Level Long-Tailed Distribution. (arXiv:2304.08592v1 [cs.CV])\nAbstract: Despite the recent remarkable improvements in scene text recognition (STR), the majority of the studies focused mainly on the English language, which only includes few number of characters. However, STR models show a large performance degradation on languages with a numerous number of characters (e.g., Chinese and Korean), especially on characters that rarely appear due to the long-tailed distribution of characters in such languages. To address such an issue, we conducted an empirical analysis using synthetic datasets with different character-level distributions (e.g., balanced and long-tailed distributions). While increasing a substantial number of tail classes without considering the context helps the model to correctly recognize characters individually, training with such a synthetic dataset interferes the model with learning the contextual information (i.e., relation among characters), which is also important for predicting the whole word. Based on this motivation, we propose a nov",
    "path": "papers/23/04/2304.08592.json",
    "total_tokens": 880,
    "translated_title": "面向字符级长尾分布的场景文本识别的改进",
    "translated_abstract": "尽管场景文本识别（STR）取得了显著进展，但大多数研究主要集中在仅包含少量字符的英语上。然而，STR模型在诸如中文和韩文等字符数量众多的语言中（尤其是因字符长尾分布而很少出现的字符）表现出较大的性能下降。为了解决这个问题，我们使用具有不同字符级分布（例如平衡和长尾分布）的合成数据集进行了实证分析。增加大量尾部类别可以帮助模型正确地单独识别字符，但是，使用这样的合成数据集进行训练会影响模型学习词汇的上下文信息（即字符之间的关系），这对于正确识别整个词汇同样重要。基于此动机，我们提出了一种新方法，在训练过程中利用平衡和长尾分布，同时保留上下文信息，以提高字符级长尾分布上的STR性能。",
    "tldr": "该论文提出一种新方法，使用平衡和长尾分布的数据集进行文本识别训练，同时保留上下文信息，以提高字符级长尾分布上的STR性能。",
    "en_tdlr": "This paper proposes a novel approach to improve scene text recognition on character-level long-tailed distribution by using both balanced and long-tailed distributions during training while preserving contextual information."
}