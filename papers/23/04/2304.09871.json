{
    "title": "A Theory on Adam Instability in Large-Scale Machine Learning. (arXiv:2304.09871v1 [cs.LG])",
    "abstract": "We present a theory for the previously unexplained divergent behavior noticed in the training of large language models. We argue that the phenomenon is an artifact of the dominant optimization algorithm used for training, called Adam. We observe that Adam can enter a state in which the parameter update vector has a relatively large norm and is essentially uncorrelated with the direction of descent on the training loss landscape, leading to divergence. This artifact is more likely to be observed in the training of a deep model with a large batch size, which is the typical setting of large-scale language model training. To argue the theory, we present observations from the training runs of the language models of different scales: 7 billion, 30 billion, 65 billion, and 546 billion parameters.",
    "link": "http://arxiv.org/abs/2304.09871",
    "context": "Title: A Theory on Adam Instability in Large-Scale Machine Learning. (arXiv:2304.09871v1 [cs.LG])\nAbstract: We present a theory for the previously unexplained divergent behavior noticed in the training of large language models. We argue that the phenomenon is an artifact of the dominant optimization algorithm used for training, called Adam. We observe that Adam can enter a state in which the parameter update vector has a relatively large norm and is essentially uncorrelated with the direction of descent on the training loss landscape, leading to divergence. This artifact is more likely to be observed in the training of a deep model with a large batch size, which is the typical setting of large-scale language model training. To argue the theory, we present observations from the training runs of the language models of different scales: 7 billion, 30 billion, 65 billion, and 546 billion parameters.",
    "path": "papers/23/04/2304.09871.json",
    "total_tokens": 771,
    "translated_title": "大规模机器学习中Adam不稳定性的理论研究",
    "translated_abstract": "本文提出了一个之前未被解释的现象的理论，该现象出现在大型语言模型训练时的发散行为中。我们认为这种现象是由于主流的优化算法 Adam 导致的。我们观察到 Adam 可能会进入一种状态，其中参数更新向量有比较大的范数，并且与训练损失景观下的下降方向基本无关，从而导致发散。这种现象更容易在大批量情况下出现，这也是大型语言模型训练的典型设置。为了证明该理论，我们对规模不同的语言模型（70亿，300亿，650亿和5460亿参数）进行了训练运行的观察。",
    "tldr": "Adam优化算法在大批量的训练下容易出现不稳定现象，并导致训练异常，作者提出了该现象的理论解释。",
    "en_tdlr": "The paper presents a theory that explains the divergent behavior observed during the training of large language models, which is caused by the commonly used optimization algorithm Adam. The theory argues that Adam can enter a state that causes divergence when the parameter update vector is large and uncorrelated with the direction of descent."
}