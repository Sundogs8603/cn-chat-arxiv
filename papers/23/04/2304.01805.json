{
    "title": "Exploration of Lightweight Single Image Denoising with Transformers and Truly Fair Training. (arXiv:2304.01805v1 [cs.CV])",
    "abstract": "As multimedia content often contains noise from intrinsic defects of digital devices, image denoising is an important step for high-level vision recognition tasks. Although several studies have developed the denoising field employing advanced Transformers, these networks are too momory-intensive for real-world applications. Additionally, there is a lack of research on lightweight denosing (LWDN) with Transformers. To handle this, this work provides seven comparative baseline Transformers for LWDN, serving as a foundation for future research. We also demonstrate the parts of randomly cropped patches significantly affect the denoising performances during training. While previous studies have overlooked this aspect, we aim to train our baseline Transformers in a truly fair manner. Furthermore, we conduct empirical analyses of various components to determine the key considerations for constructing LWDN Transformers. Codes are available at https://github.com/rami0205/LWDN.",
    "link": "http://arxiv.org/abs/2304.01805",
    "context": "Title: Exploration of Lightweight Single Image Denoising with Transformers and Truly Fair Training. (arXiv:2304.01805v1 [cs.CV])\nAbstract: As multimedia content often contains noise from intrinsic defects of digital devices, image denoising is an important step for high-level vision recognition tasks. Although several studies have developed the denoising field employing advanced Transformers, these networks are too momory-intensive for real-world applications. Additionally, there is a lack of research on lightweight denosing (LWDN) with Transformers. To handle this, this work provides seven comparative baseline Transformers for LWDN, serving as a foundation for future research. We also demonstrate the parts of randomly cropped patches significantly affect the denoising performances during training. While previous studies have overlooked this aspect, we aim to train our baseline Transformers in a truly fair manner. Furthermore, we conduct empirical analyses of various components to determine the key considerations for constructing LWDN Transformers. Codes are available at https://github.com/rami0205/LWDN.",
    "path": "papers/23/04/2304.01805.json",
    "total_tokens": 1035,
    "translated_title": "采用Transformer实现轻量化单图像去噪并进行真正公平训练的探索",
    "translated_abstract": "由于数字设备的固有缺陷，多媒体内容通常包含噪声。因此，在高级视觉识别任务中，图像去噪是重要的预处理步骤。虽然已经有一些研究采用先进的Transformer开发了去噪领域，但是这些网络对于实际应用来说过于占用内存。此外，对于采用Transformer的轻量化去噪领域的研究还缺乏。为应对这一问题，本文提供了七种轻量级去噪的比较基线Transformer，为未来的研究提供了基础。我们还展示了在训练过程中，随机剪裁补丁的部分会显著影响去噪性能，而以前的研究却忽略了这一方面。我们的目标是以真正公平的方式训练基线Transformer。此外，我们还进行了各种组件的实证分析，以确定构建轻量化去噪Transformer的关键考虑因素。代码可在 https://github.com/rami0205/LWDN 上获得。",
    "tldr": "本文研究了采用Transformer实现轻量化单图像去噪的问题，提供了七种比较基线Transformer，并探讨了在训练过程中随机剪裁补丁的部分对去噪性能的影响；而以往的研究忽略了这一问题。此外，本文以真正公平的方式训练基线Transformer，并进行了各种组件的实证分析，以确定构建轻量化去噪Transformer的关键考虑因素。",
    "en_tdlr": "This paper studies the problem of lightweight single image denoising using Transformers, providing seven comparative baseline Transformers and exploring the impact of randomly cropped patches on denoising performance during training. It also trains the baseline Transformers in a truly fair manner and conducts empirical analyses of various components to determine key considerations for constructing lightweight denoising Transformers."
}