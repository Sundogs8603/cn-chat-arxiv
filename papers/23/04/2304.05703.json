{
    "title": "Human-Robot Skill Transfer with Enhanced Compliance via Dynamic Movement Primitives. (arXiv:2304.05703v1 [cs.RO])",
    "abstract": "Finding an efficient way to adapt robot trajectory is a priority to improve overall performance of robots. One approach for trajectory planning is through transferring human-like skills to robots by Learning from Demonstrations (LfD). The human demonstration is considered the target motion to mimic. However, human motion is typically optimal for human embodiment but not for robots because of the differences between human biomechanics and robot dynamics. The Dynamic Movement Primitives (DMP) framework is a viable solution for this limitation of LfD, but it requires tuning the second-order dynamics in the formulation. Our contribution is introducing a systematic method to extract the dynamic features from human demonstration to auto-tune the parameters in the DMP framework. In addition to its use with LfD, another utility of the proposed method is that it can readily be used in conjunction with Reinforcement Learning (RL) for robot training. In this way, the extracted features facilitate",
    "link": "http://arxiv.org/abs/2304.05703",
    "context": "Title: Human-Robot Skill Transfer with Enhanced Compliance via Dynamic Movement Primitives. (arXiv:2304.05703v1 [cs.RO])\nAbstract: Finding an efficient way to adapt robot trajectory is a priority to improve overall performance of robots. One approach for trajectory planning is through transferring human-like skills to robots by Learning from Demonstrations (LfD). The human demonstration is considered the target motion to mimic. However, human motion is typically optimal for human embodiment but not for robots because of the differences between human biomechanics and robot dynamics. The Dynamic Movement Primitives (DMP) framework is a viable solution for this limitation of LfD, but it requires tuning the second-order dynamics in the formulation. Our contribution is introducing a systematic method to extract the dynamic features from human demonstration to auto-tune the parameters in the DMP framework. In addition to its use with LfD, another utility of the proposed method is that it can readily be used in conjunction with Reinforcement Learning (RL) for robot training. In this way, the extracted features facilitate",
    "path": "papers/23/04/2304.05703.json",
    "total_tokens": 844,
    "translated_title": "通过动态运动原理增强的一致性，实现人机技能转移",
    "translated_abstract": "找到一个高效的适应机器人轨迹的方式是提高机器人性能的优先任务，其中通过演示学习（LfD）方法将类似于人的技能传递给机器人是一种轨迹规划的方法。然而，人的动作通常针对人的机体优化而不是机器人，因为人类的生物力学与机器人动力学之间存在差异。动态运动原理（DMP）框架是LfD这一限制的可行解决方案，但需要调节公式中的二阶动态。我们的贡献在于引入一种系统方法，从人的演示中提取动态特征来自动调整DMP框架中的参数。除了与LfD一起使用之外，所提出的方法的另一个用途是，它可以立即与强化学习（RL）一起用于机器人训练。通过这种方式，提取的特征有助于提高机器人训练效果。",
    "tldr": "本文介绍了一种通过提取人的动态特征来自动调整DMP框架参数，以增强机器人轨迹规划性能的方法。",
    "en_tdlr": "This paper introduces a method for enhancing robot trajectory planning performance by extracting dynamic features from human demonstration to auto-tune the parameters in the DMP framework."
}