{
    "title": "Towards Mode Balancing of Generative Models via Diversity Weights. (arXiv:2304.11961v2 [cs.LG] UPDATED)",
    "abstract": "Large data-driven image models are extensively used to support creative and artistic work. Under the currently predominant distribution-fitting paradigm, a dataset is treated as ground truth to be approximated as closely as possible. Yet, many creative applications demand a diverse range of output, and creators often strive to actively diverge from a given data distribution. We argue that an adjustment of modelling objectives, from pure mode coverage towards mode balancing, is necessary to accommodate the goal of higher output diversity. We present diversity weights, a training scheme that increases a model's output diversity by balancing the modes in the training dataset. First experiments in a controlled setting demonstrate the potential of our method. We discuss connections of our approach to diversity, equity, and inclusion in generative machine learning more generally, and computational creativity specifically. An implementation of our algorithm is available at https://github.com/",
    "link": "http://arxiv.org/abs/2304.11961",
    "context": "Title: Towards Mode Balancing of Generative Models via Diversity Weights. (arXiv:2304.11961v2 [cs.LG] UPDATED)\nAbstract: Large data-driven image models are extensively used to support creative and artistic work. Under the currently predominant distribution-fitting paradigm, a dataset is treated as ground truth to be approximated as closely as possible. Yet, many creative applications demand a diverse range of output, and creators often strive to actively diverge from a given data distribution. We argue that an adjustment of modelling objectives, from pure mode coverage towards mode balancing, is necessary to accommodate the goal of higher output diversity. We present diversity weights, a training scheme that increases a model's output diversity by balancing the modes in the training dataset. First experiments in a controlled setting demonstrate the potential of our method. We discuss connections of our approach to diversity, equity, and inclusion in generative machine learning more generally, and computational creativity specifically. An implementation of our algorithm is available at https://github.com/",
    "path": "papers/23/04/2304.11961.json",
    "total_tokens": 892,
    "translated_title": "通过多样性权重实现生成模型的模式平衡",
    "translated_abstract": "大型数据驱动的图像模型被广泛用于支持创意和艺术作品。在当前主导的分布拟合范式下，数据集被视为要尽可能接近的真实值。然而，许多创意应用需要多样化的输出，创作者经常努力从给定的数据分布中积极分离出来。我们认为，从纯模式覆盖转向模式平衡的建模目标调整是必要的，以适应更高的输出多样性目标。我们提出了多样性权重，这是一种通过平衡训练数据集中的模式来增加模型输出多样性的训练方案。在受控环境中进行的初步实验展示了我们方法的潜力。我们讨论了我们方法与多样性、公平和包容在生成式机器学习以及计算机创意中的联系。我们的算法实现可以在https://github.com/找到。",
    "tldr": "本研究提出了通过平衡训练数据集中的模式来增加模型输出多样性的多样性权重训练方案，以更好地适应需要多样化输出的创意应用，并在受控环境中进行的初步实验展示了其潜力。",
    "en_tdlr": "This paper presents diversity weights, a training scheme that increases a model's output diversity by balancing the modes in the training dataset, which is necessary to accommodate the goal of higher output diversity for creative applications. Preliminary experiments demonstrate its potential in a controlled setting and its implications for diversity, equity, and inclusion in generative machine learning and computational creativity are discussed."
}