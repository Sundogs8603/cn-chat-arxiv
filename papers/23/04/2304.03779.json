{
    "title": "A roadmap to fair and trustworthy prediction model validation in healthcare. (arXiv:2304.03779v1 [cs.LG])",
    "abstract": "A prediction model is most useful if it generalizes beyond the development data with external validations, but to what extent should it generalize remains unclear. In practice, prediction models are externally validated using data from very different settings, including populations from other health systems or countries, with predictably poor results. This may not be a fair reflection of the performance of the model which was designed for a specific target population or setting, and may be stretching the expected model generalizability. To address this, we suggest to externally validate a model using new data from the target population to ensure clear implications of validation performance on model reliability, whereas model generalizability to broader settings should be carefully investigated during model development instead of explored post-hoc. Based on this perspective, we propose a roadmap that facilitates the development and application of reliable, fair, and trustworthy artifici",
    "link": "http://arxiv.org/abs/2304.03779",
    "context": "Title: A roadmap to fair and trustworthy prediction model validation in healthcare. (arXiv:2304.03779v1 [cs.LG])\nAbstract: A prediction model is most useful if it generalizes beyond the development data with external validations, but to what extent should it generalize remains unclear. In practice, prediction models are externally validated using data from very different settings, including populations from other health systems or countries, with predictably poor results. This may not be a fair reflection of the performance of the model which was designed for a specific target population or setting, and may be stretching the expected model generalizability. To address this, we suggest to externally validate a model using new data from the target population to ensure clear implications of validation performance on model reliability, whereas model generalizability to broader settings should be carefully investigated during model development instead of explored post-hoc. Based on this perspective, we propose a roadmap that facilitates the development and application of reliable, fair, and trustworthy artifici",
    "path": "papers/23/04/2304.03779.json",
    "total_tokens": 1099,
    "translated_title": "医疗保健中公平和可信预测模型验证的路线图",
    "translated_abstract": "如果一个预测模型能够推广到开发数据以外的数据，并进行外部验证，那么它就是最有用的。但是，在多大程度上它可以推广仍不清楚。实际上，预测模型使用来自其他医疗系统或国家的人口等非常不同的数据进行外部验证，预测结果通常很差。这可能不是对特定目标人群或环境设计的模型表现的公正反映，并且可能会拉伸预期的模型推广性。为了解决这个问题，我们建议使用来自目标人群的新数据来外部验证模型，以确保验证性能对模型可靠性的清晰影响，而模型推广到更广泛的环境应在模型开发期间进行仔细调查，而不是事后探讨。基于这个观点，我们提出了一项路线图，以便在医疗保健中开发和应用可靠、公平、可信的人工智能模型。我们认为这份路线图应该清晰定义公平性和可信性，考虑模型使用的伦理影响，进行亚组分析，并采用严格的验证协议，其中包括在目标人群中进行外部验证。",
    "tldr": "针对医疗保健中预测模型的验证问题，建议使用来自目标人群的新数据进行外部验证，确保验证性能对模型可靠性的影响，并且在模型开发期间认真研究模型在更广泛环境中的拓展性。我们提出了一份路线图，以便在医疗保健中开发和应用可靠、公平、可信的人工智能模型。",
    "en_tdlr": "To address the lack of clear guidelines for external validation of health care prediction models, this paper suggests using new data from the target population for external validation, while thoroughly investigating the model's generalizability during its development. The authors propose a roadmap for the development and application of reliable, fair, and trustworthy artificial intelligence models in healthcare, incorporating clear definitions of fairness and trustworthiness, ethical implications, subgroup analysis, and rigorous validation protocols."
}