{
    "title": "Fairness through Aleatoric Uncertainty. (arXiv:2304.03646v1 [cs.LG])",
    "abstract": "We propose a unique solution to tackle the often-competing goals of fairness and utility in machine learning classification tasks. While fairness ensures that the model's predictions are unbiased and do not discriminate against any particular group, utility focuses on maximizing the accuracy of the model's predictions. Our aim is to investigate the relationship between uncertainty and fairness. Our approach leverages this concept by employing Bayesian learning to estimate the uncertainty in sample predictions where the estimation is independent of confounding effects related to the protected attribute. Through empirical evidence, we show that samples with low classification uncertainty are modeled more accurately and fairly than those with high uncertainty, which may have biased representations and higher prediction errors. To address the challenge of balancing fairness and utility, we propose a novel fairness-utility objective that is defined based on uncertainty quantification. The w",
    "link": "http://arxiv.org/abs/2304.03646",
    "context": "Title: Fairness through Aleatoric Uncertainty. (arXiv:2304.03646v1 [cs.LG])\nAbstract: We propose a unique solution to tackle the often-competing goals of fairness and utility in machine learning classification tasks. While fairness ensures that the model's predictions are unbiased and do not discriminate against any particular group, utility focuses on maximizing the accuracy of the model's predictions. Our aim is to investigate the relationship between uncertainty and fairness. Our approach leverages this concept by employing Bayesian learning to estimate the uncertainty in sample predictions where the estimation is independent of confounding effects related to the protected attribute. Through empirical evidence, we show that samples with low classification uncertainty are modeled more accurately and fairly than those with high uncertainty, which may have biased representations and higher prediction errors. To address the challenge of balancing fairness and utility, we propose a novel fairness-utility objective that is defined based on uncertainty quantification. The w",
    "path": "papers/23/04/2304.03646.json",
    "total_tokens": 838,
    "translated_title": "通过不确定性实现公平性",
    "translated_abstract": "我们提出了一种独特的解决方案，以解决机器学习分类任务中公平性和效用通常相互竞争的目标。 公平性确保模型的预测不带偏见地针对任何特定群体，而效用则专注于最大化模型预测的准确性。我们的目标是研究不确定性与公平性之间的关系。我们的方法利用贝叶斯学习来估算样本预测的不确定性，其中估算与受保护属性相关的混淆效应无关。通过实证证据，我们表明具有低分类不确定性的样本比具有高不确定性的样本更准确和公平地建模，可能具有偏差的表示和更高的预测误差。为了解决平衡公平性和效用的挑战，我们提出了一种基于不确定性量化定义的新的公平性-效用目标。",
    "tldr": "研究不确定性与公平性的关系，通过贝叶斯学习估算样本预测不确定性，发现低不确定性的数据更准确和公平，提出一种基于不确定性量化定义的新的公平性-效用目标。",
    "en_tdlr": "Investigate the relationship between uncertainty and fairness, estimate uncertainty in sample predictions through Bayesian learning, find that data with low uncertainty are more accurate and fair, propose a novel fairness-utility objective that is defined based on uncertainty quantification."
}