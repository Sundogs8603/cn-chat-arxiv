{
    "title": "Characterizing the contribution of dependent features in XAI methods. (arXiv:2304.01717v1 [stat.ML])",
    "abstract": "Explainable Artificial Intelligence (XAI) provides tools to help understanding how the machine learning models work and reach a specific outcome. It helps to increase the interpretability of models and makes the models more trustworthy and transparent. In this context, many XAI methods were proposed being SHAP and LIME the most popular. However, the proposed methods assume that used predictors in the machine learning models are independent which in general is not necessarily true. Such assumption casts shadows on the robustness of the XAI outcomes such as the list of informative predictors. Here, we propose a simple, yet useful proxy that modifies the outcome of any XAI feature ranking method allowing to account for the dependency among the predictors. The proposed approach has the advantage of being model-agnostic as well as simple to calculate the impact of each predictor in the model in presence of collinearity.",
    "link": "http://arxiv.org/abs/2304.01717",
    "context": "Title: Characterizing the contribution of dependent features in XAI methods. (arXiv:2304.01717v1 [stat.ML])\nAbstract: Explainable Artificial Intelligence (XAI) provides tools to help understanding how the machine learning models work and reach a specific outcome. It helps to increase the interpretability of models and makes the models more trustworthy and transparent. In this context, many XAI methods were proposed being SHAP and LIME the most popular. However, the proposed methods assume that used predictors in the machine learning models are independent which in general is not necessarily true. Such assumption casts shadows on the robustness of the XAI outcomes such as the list of informative predictors. Here, we propose a simple, yet useful proxy that modifies the outcome of any XAI feature ranking method allowing to account for the dependency among the predictors. The proposed approach has the advantage of being model-agnostic as well as simple to calculate the impact of each predictor in the model in presence of collinearity.",
    "path": "papers/23/04/2304.01717.json",
    "total_tokens": 821,
    "translated_title": "揭示XAI方法中依赖特征的贡献",
    "translated_abstract": "可解释的人工智能（XAI）提供了工具，帮助理解机器学习模型的工作原理和实现特定结果的方法。它有助于增加模型的可解释性，使得模型更为可信和透明。在这种情况下，许多XAI方法被提出，其中SHAP和LIME最广为人知。然而，这些方法假设机器学习模型中使用的预测变量相互独立，这在一般情况下并不一定成立。这种假设使得XAI结果的稳健性受到影响，比如信息预测变量的列表。在这里，我们提出了一个简单但有用的代理，修改任何XAI特征排名方法的结果，使其能够考虑预测变量之间的相关性。所提出的方法具有模型无关性，并且可以简单地计算在共线性存在的情况下每个预测变量在模型中的影响。",
    "tldr": "该论文探讨了在XAI方法中考虑预测变量的依赖关系，提出了一种简单快速的方法，并证明其模型无关性。",
    "en_tdlr": "This paper explores the consideration of predictor dependencies in XAI methods, proposes a simple and fast method, and proves its model-agnostic property."
}