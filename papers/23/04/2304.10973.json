{
    "title": "LEIA: Linguistic Embeddings for the Identification of Affect. (arXiv:2304.10973v1 [cs.CL])",
    "abstract": "The wealth of text data generated by social media has enabled new kinds of analysis of emotions with language models. These models are often trained on small and costly datasets of text annotations produced by readers who guess the emotions expressed by others in social media posts. This affects the quality of emotion identification methods due to training data size limitations and noise in the production of labels used in model development. We present LEIA, a model for emotion identification in text that has been trained on a dataset of more than 6 million posts with self-annotated emotion labels for happiness, affection, sadness, anger, and fear. LEIA is based on a word masking method that enhances the learning of emotion words during model pre-training. LEIA achieves macro-F1 values of approximately 73 on three in-domain test datasets, outperforming other supervised and unsupervised methods in a strong benchmark that shows that LEIA generalizes across posts, users, and time periods.",
    "link": "http://arxiv.org/abs/2304.10973",
    "context": "Title: LEIA: Linguistic Embeddings for the Identification of Affect. (arXiv:2304.10973v1 [cs.CL])\nAbstract: The wealth of text data generated by social media has enabled new kinds of analysis of emotions with language models. These models are often trained on small and costly datasets of text annotations produced by readers who guess the emotions expressed by others in social media posts. This affects the quality of emotion identification methods due to training data size limitations and noise in the production of labels used in model development. We present LEIA, a model for emotion identification in text that has been trained on a dataset of more than 6 million posts with self-annotated emotion labels for happiness, affection, sadness, anger, and fear. LEIA is based on a word masking method that enhances the learning of emotion words during model pre-training. LEIA achieves macro-F1 values of approximately 73 on three in-domain test datasets, outperforming other supervised and unsupervised methods in a strong benchmark that shows that LEIA generalizes across posts, users, and time periods.",
    "path": "papers/23/04/2304.10973.json",
    "total_tokens": 990,
    "translated_title": "LEIA：语言嵌入用于情感识别",
    "translated_abstract": "社交媒体产生了大量文本数据，使得使用语言模型分析情感变得更加容易。这些模型通常在由读者生成的小型而昂贵的文本注释数据集上进行训练，这些读者猜测社交媒体帖子中表达的情感。这影响了情感识别方法的质量，因为存在训练数据大小限制和用于模型开发的标签生产中的噪声。我们提出了LEIA，这是一种文本情感识别模型，它基于由超过6百万个帖子组成的数据集进行训练，其中这些帖子具有自注释的情感标签，包括快乐、亲情、悲伤、愤怒和恐惧。LEIA基于一种掩蔽单词的方法，增强了模型预训练过程中对情感单词的学习。LEIA在三个测试数据集上实现了约73的宏F1值，优于其他监督和无监督方法，并在强基准测试中表现出LEIA可以概括不同的帖子、用户和时间段。",
    "tldr": "该论文提出了一种名为LEIA的情感识别模型，使用了由超过6百万个自注释文本帖子组成的数据集进行训练，利用掩蔽单词的方法增强模型预训练过程中对情感单词的学习，并在三个测试数据集上实现了约73的宏F1值，优于其他方法。",
    "en_tdlr": "The paper proposes a linguistic model named LEIA for emotion identification, which is trained on a dataset of more than 6 million self-annotated text posts and uses a word masking method to enhance emotion word learning during pre-training. LEIA outperforms other methods with a macro-F1 values of approximately 73 on three test datasets, showing its generalization ability."
}