{
    "title": "Perspectives on Large Language Models for Relevance Judgment. (arXiv:2304.09161v1 [cs.IR])",
    "abstract": "When asked, current large language models (LLMs) like ChatGPT claim that they can assist us with relevance judgments. Many researchers think this would not lead to credible IR research. In this perspective paper, we discuss possible ways for LLMs to assist human experts along with concerns and issues that arise. We devise a human-machine collaboration spectrum that allows categorizing different relevance judgment strategies, based on how much the human relies on the machine. For the extreme point of \"fully automated assessment\", we further include a pilot experiment on whether LLM-based relevance judgments correlate with judgments from trained human assessors. We conclude the paper by providing two opposing perspectives - for and against the use of LLMs for automatic relevance judgments - and a compromise perspective, informed by our analyses of the literature, our preliminary experimental evidence, and our experience as IR researchers.  We hope to start a constructive discussion withi",
    "link": "http://arxiv.org/abs/2304.09161",
    "context": "Title: Perspectives on Large Language Models for Relevance Judgment. (arXiv:2304.09161v1 [cs.IR])\nAbstract: When asked, current large language models (LLMs) like ChatGPT claim that they can assist us with relevance judgments. Many researchers think this would not lead to credible IR research. In this perspective paper, we discuss possible ways for LLMs to assist human experts along with concerns and issues that arise. We devise a human-machine collaboration spectrum that allows categorizing different relevance judgment strategies, based on how much the human relies on the machine. For the extreme point of \"fully automated assessment\", we further include a pilot experiment on whether LLM-based relevance judgments correlate with judgments from trained human assessors. We conclude the paper by providing two opposing perspectives - for and against the use of LLMs for automatic relevance judgments - and a compromise perspective, informed by our analyses of the literature, our preliminary experimental evidence, and our experience as IR researchers.  We hope to start a constructive discussion withi",
    "path": "papers/23/04/2304.09161.json",
    "total_tokens": 943,
    "translated_title": "大型语言模型在相关性评价中的应用",
    "translated_abstract": "当被问及时，像ChatGPT这样的当前大型语言模型（LLMs）声称它们可以协助我们进行相关性判断。许多研究人员认为这不会导致可信的信息检索研究。在本文中，我们讨论了LLMs协助人类专家进行相关性判断的可能方法以及可能出现的问题和关注点。我们制定了一个人机协作谱系，可以将不同的相关性判断策略进行分类，基于人类对机器的依赖程度。针对“完全自动化评估”的极端点，我们进一步进行了基于LLM的相关性判断与经过训练的人类评估者判断的相关性的初步实验。我们通过分析文献、我们的初步实验证据以及我们作为信息检索研究人员的经验，提出了支持和反对使用LLMs进行自动相关性判断的两个对立观点以及妥协的观点。我们希望开始进行建设性的讨论。",
    "tldr": "本文讨论了LLMs协助人类专家进行相关性判断的可能方法和问题，制定了人机协作谱系，提供了一个基于LLM的相关性判断与经过训练的人类评估者判断相关性的初步实验，以及支持和反对使用LLMs进行自动相关性判断的两个对立观点以及妥协的观点。",
    "en_tdlr": "This paper discusses the possible ways and issues for LLMs to assist human experts in relevance judgments, proposes a human-machine collaboration spectrum, provides a preliminary experiment on the correlation between LLM-based judgments and judgments from trained human assessors, and presents two opposing views on using LLMs for automatic relevance judgments, as well as a compromise viewpoint."
}