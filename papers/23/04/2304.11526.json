{
    "title": "How to Control Hydrodynamic Force on Fluidic Pinball via Deep Reinforcement Learning. (arXiv:2304.11526v1 [eess.SY])",
    "abstract": "Deep reinforcement learning (DRL) for fluidic pinball, three individually rotating cylinders in the uniform flow arranged in an equilaterally triangular configuration, can learn the efficient flow control strategies due to the validity of self-learning and data-driven state estimation for complex fluid dynamic problems. In this work, we present a DRL-based real-time feedback strategy to control the hydrodynamic force on fluidic pinball, i.e., force extremum and tracking, from cylinders' rotation. By adequately designing reward functions and encoding historical observations, and after automatic learning of thousands of iterations, the DRL-based control was shown to make reasonable and valid control decisions in nonparametric control parameter space, which is comparable to and even better than the optimal policy found through lengthy brute-force searching. Subsequently, one of these results was analyzed by a machine learning model that enabled us to shed light on the basis of decision-ma",
    "link": "http://arxiv.org/abs/2304.11526",
    "context": "Title: How to Control Hydrodynamic Force on Fluidic Pinball via Deep Reinforcement Learning. (arXiv:2304.11526v1 [eess.SY])\nAbstract: Deep reinforcement learning (DRL) for fluidic pinball, three individually rotating cylinders in the uniform flow arranged in an equilaterally triangular configuration, can learn the efficient flow control strategies due to the validity of self-learning and data-driven state estimation for complex fluid dynamic problems. In this work, we present a DRL-based real-time feedback strategy to control the hydrodynamic force on fluidic pinball, i.e., force extremum and tracking, from cylinders' rotation. By adequately designing reward functions and encoding historical observations, and after automatic learning of thousands of iterations, the DRL-based control was shown to make reasonable and valid control decisions in nonparametric control parameter space, which is comparable to and even better than the optimal policy found through lengthy brute-force searching. Subsequently, one of these results was analyzed by a machine learning model that enabled us to shed light on the basis of decision-ma",
    "path": "papers/23/04/2304.11526.json",
    "total_tokens": 810,
    "translated_title": "利用深度强化学习控制流体弹球的水动力力​​​​​​​",
    "translated_abstract": "本文提出了一种基于深度强化学习的实时反馈策略，以控制流体弹球上的水动力力。通过充分设计奖励函数和编码历史观察结果，自动学习并迭代上千次，该策略可以在非参数控制参数空间内作出合理有效的控制决策，比冗长的暴力搜索找到的最优策略还要好。随后，通过机器学习模型对其中一项结果进行分析，使我们能够以此了解流控过程的基础。",
    "tldr": "本文利用深度强化学习提出了一种实时反馈策略，以控制流体弹球上的水动力力，可在非参数控制参数空间内作出合理有效的控制决策，从而更好地了解流控过程的基础。",
    "en_tdlr": "This paper proposes a real-time feedback strategy for controlling the hydrodynamic force on fluidic pinball using deep reinforcement learning, which can make reasonable and valid control decisions in nonparametric control parameter space and shed light on the underlying physics of the flow control process through machine learning analysis."
}