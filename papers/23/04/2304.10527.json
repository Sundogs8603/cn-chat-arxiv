{
    "title": "Multidimensional Uncertainty Quantification for Deep Neural Networks. (arXiv:2304.10527v1 [cs.LG])",
    "abstract": "Deep neural networks (DNNs) have received tremendous attention and achieved great success in various applications, such as image and video analysis, natural language processing, recommendation systems, and drug discovery. However, inherent uncertainties derived from different root causes have been realized as serious hurdles for DNNs to find robust and trustworthy solutions for real-world problems. A lack of consideration of such uncertainties may lead to unnecessary risk. For example, a self-driving autonomous car can misdetect a human on the road. A deep learning-based medical assistant may misdiagnose cancer as a benign tumor.  In this work, we study how to measure different uncertainty causes for DNNs and use them to solve diverse decision-making problems more effectively. In the first part of this thesis, we develop a general learning framework to quantify multiple types of uncertainties caused by different root causes, such as vacuity (i.e., uncertainty due to a lack of evidence)",
    "link": "http://arxiv.org/abs/2304.10527",
    "context": "Title: Multidimensional Uncertainty Quantification for Deep Neural Networks. (arXiv:2304.10527v1 [cs.LG])\nAbstract: Deep neural networks (DNNs) have received tremendous attention and achieved great success in various applications, such as image and video analysis, natural language processing, recommendation systems, and drug discovery. However, inherent uncertainties derived from different root causes have been realized as serious hurdles for DNNs to find robust and trustworthy solutions for real-world problems. A lack of consideration of such uncertainties may lead to unnecessary risk. For example, a self-driving autonomous car can misdetect a human on the road. A deep learning-based medical assistant may misdiagnose cancer as a benign tumor.  In this work, we study how to measure different uncertainty causes for DNNs and use them to solve diverse decision-making problems more effectively. In the first part of this thesis, we develop a general learning framework to quantify multiple types of uncertainties caused by different root causes, such as vacuity (i.e., uncertainty due to a lack of evidence)",
    "path": "papers/23/04/2304.10527.json",
    "total_tokens": 716,
    "translated_title": "深度神经网络的多维度不确定量化",
    "translated_abstract": "深度神经网络（DNN）在图像和视频分析、自然语言处理、推荐系统和药物研究等许多应用中取得了巨大的成功。然而，由不同根本原因导致的内在不确定性已经被认为是DNN在寻找真实世界问题的稳健和可信解决方案方面的严重障碍。缺乏对这种不确定性的考虑可能会导致不必要的风险。本文研究了如何度量DNN的不同不确定因素，并将它们用于更有效地解决不同的决策问题。",
    "tldr": "研究如何量化DNN的不同不确定性，并将其用于更有效地解决不同的决策问题。",
    "en_tdlr": "This paper studies how to quantify different uncertainties in DNNs and use them to solve various decision-making problems more effectively."
}