{
    "title": "Improving Performance of Private Federated Models in Medical Image Analysis. (arXiv:2304.05127v1 [cs.CR])",
    "abstract": "Federated learning (FL) is a distributed machine learning (ML) approach that allows data to be trained without being centralized. This approach is particularly beneficial for medical applications because it addresses some key challenges associated with medical data, such as privacy, security, and data ownership. On top of that, FL can improve the quality of ML models used in medical applications. Medical data is often diverse and can vary significantly depending on the patient population, making it challenging to develop ML models that are accurate and generalizable. FL allows medical data to be used from multiple sources, which can help to improve the quality and generalizability of ML models. Differential privacy (DP) is a go-to algorithmic tool to make this process secure and private. In this work, we show that the model performance can be further improved by employing local steps, a popular approach to improving the communication efficiency of FL, and tuning the number of communica",
    "link": "http://arxiv.org/abs/2304.05127",
    "context": "Title: Improving Performance of Private Federated Models in Medical Image Analysis. (arXiv:2304.05127v1 [cs.CR])\nAbstract: Federated learning (FL) is a distributed machine learning (ML) approach that allows data to be trained without being centralized. This approach is particularly beneficial for medical applications because it addresses some key challenges associated with medical data, such as privacy, security, and data ownership. On top of that, FL can improve the quality of ML models used in medical applications. Medical data is often diverse and can vary significantly depending on the patient population, making it challenging to develop ML models that are accurate and generalizable. FL allows medical data to be used from multiple sources, which can help to improve the quality and generalizability of ML models. Differential privacy (DP) is a go-to algorithmic tool to make this process secure and private. In this work, we show that the model performance can be further improved by employing local steps, a popular approach to improving the communication efficiency of FL, and tuning the number of communica",
    "path": "papers/23/04/2304.05127.json",
    "total_tokens": 855,
    "translated_title": "提高医学图像分析中私有联邦模型的性能",
    "translated_abstract": "联邦学习（FL）是一种分布式机器学习（ML）方法，允许在不集中数据的情况下进行训练。这种方法对医学应用特别有益，因为它解决了与医疗数据相关的一些关键挑战，如隐私、安全和数据所有权。此外，FL可以提高用于医学应用中的ML模型的质量。医疗数据通常是多样化的，并且可以根据病人群体而有很大变化，这使得开发准确且具有一般性的ML模型具有挑战性。FL允许使用来自多个源的医疗数据，这有助于提高ML模型的质量和一般化能力。差分隐私（DP）是保护该过程安全和私密性的工具。在这项工作中，我们展示了通过采用本地步骤（一种提高FL通信效率的常用方法）和调整通信次数的数量，可以进一步提高模型性能。",
    "tldr": "本论文通过本地步骤和调整功能进一步提高医学影像分析中的联邦学习模型性能。",
    "en_tdlr": "This paper proposes improving the performance of federated models in medical image analysis by employing local steps and tuning communication, thus enhancing the quality and generalizability of ML models in medical applications."
}