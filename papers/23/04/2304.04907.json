{
    "title": "Improving Vision-and-Language Navigation by Generating Future-View Image Semantics. (arXiv:2304.04907v1 [cs.CV])",
    "abstract": "Vision-and-Language Navigation (VLN) is the task that requires an agent to navigate through the environment based on natural language instructions. At each step, the agent takes the next action by selecting from a set of navigable locations. In this paper, we aim to take one step further and explore whether the agent can benefit from generating the potential future view during navigation. Intuitively, humans will have an expectation of how the future environment will look like, based on the natural language instructions and surrounding views, which will aid correct navigation. Hence, to equip the agent with this ability to generate the semantics of future navigation views, we first propose three proxy tasks during the agent's in-domain pre-training: Masked Panorama Modeling (MPM), Masked Trajectory Modeling (MTM), and Action Prediction with Image Generation (APIG). These three objectives teach the model to predict missing views in a panorama (MPM), predict missing steps in the full tra",
    "link": "http://arxiv.org/abs/2304.04907",
    "context": "Title: Improving Vision-and-Language Navigation by Generating Future-View Image Semantics. (arXiv:2304.04907v1 [cs.CV])\nAbstract: Vision-and-Language Navigation (VLN) is the task that requires an agent to navigate through the environment based on natural language instructions. At each step, the agent takes the next action by selecting from a set of navigable locations. In this paper, we aim to take one step further and explore whether the agent can benefit from generating the potential future view during navigation. Intuitively, humans will have an expectation of how the future environment will look like, based on the natural language instructions and surrounding views, which will aid correct navigation. Hence, to equip the agent with this ability to generate the semantics of future navigation views, we first propose three proxy tasks during the agent's in-domain pre-training: Masked Panorama Modeling (MPM), Masked Trajectory Modeling (MTM), and Action Prediction with Image Generation (APIG). These three objectives teach the model to predict missing views in a panorama (MPM), predict missing steps in the full tra",
    "path": "papers/23/04/2304.04907.json",
    "total_tokens": 911,
    "translated_title": "通过生成未来视图图像语义以改善视觉与语言导航",
    "translated_abstract": "视觉与语言导航是一项任务，要求代理根据自然语言指令在环境中进行导航。在每个步骤中，代理通过从可导航位置集合中进行选择来选择下一步动作。在本文中，我们旨在进一步探索代理是否可以受益于在导航期间生成潜在未来视图。直观地说，人类根据自然语言指令和周围的视图会对未来的环境有一个预期，并帮助正确地导航。因此，为了给代理装备这种生成未来导航视图语义的能力，我们首先在代理的领域内预训练过程中提出了三种代理任务: 掩蔽全景建模 (MPM)，掩蔽轨迹建模 (MTM) 和带有图像生成的动作预测 (APIG)。这三个目标教会了模型预测全景中的缺少视图 (MPM)、预测完整轨迹中的缺少步骤 (MTM) 和进行动作预测和图像生成 (APIG)。",
    "tldr": "本文提出了三个代理任务用于在代理的领域内预训练，以帮助模型生成未来视图图像语义，从而在视觉与语言导航任务中提高性能。",
    "en_tdlr": "This paper proposes three proxy tasks for in-domain pre-training of agents, which help the model generate future view image semantics, and thus improve performance in the task of vision-and-language navigation."
}