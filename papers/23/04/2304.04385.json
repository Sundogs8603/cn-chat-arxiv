{
    "title": "On Robustness in Multimodal Learning. (arXiv:2304.04385v1 [cs.LG])",
    "abstract": "Multimodal learning is defined as learning over multiple heterogeneous input modalities such as video, audio, and text. In this work, we are concerned with understanding how models behave as the type of modalities differ between training and deployment, a situation that naturally arises in many applications of multimodal learning to hardware platforms. We present a multimodal robustness framework to provide a systematic analysis of common multimodal representation learning methods. Further, we identify robustness short-comings of these approaches and propose two intervention techniques leading to $1.5\\times$-$4\\times$ robustness improvements on three datasets, AudioSet, Kinetics-400 and ImageNet-Captions. Finally, we demonstrate that these interventions better utilize additional modalities, if present, to achieve competitive results of $44.2$ mAP on AudioSet 20K.",
    "link": "http://arxiv.org/abs/2304.04385",
    "context": "Title: On Robustness in Multimodal Learning. (arXiv:2304.04385v1 [cs.LG])\nAbstract: Multimodal learning is defined as learning over multiple heterogeneous input modalities such as video, audio, and text. In this work, we are concerned with understanding how models behave as the type of modalities differ between training and deployment, a situation that naturally arises in many applications of multimodal learning to hardware platforms. We present a multimodal robustness framework to provide a systematic analysis of common multimodal representation learning methods. Further, we identify robustness short-comings of these approaches and propose two intervention techniques leading to $1.5\\times$-$4\\times$ robustness improvements on three datasets, AudioSet, Kinetics-400 and ImageNet-Captions. Finally, we demonstrate that these interventions better utilize additional modalities, if present, to achieve competitive results of $44.2$ mAP on AudioSet 20K.",
    "path": "papers/23/04/2304.04385.json",
    "total_tokens": 873,
    "translated_title": "关于多模态学习的鲁棒性",
    "translated_abstract": "多模态学习被定义为对多种异构输入模态（如视频、音频和文本等）进行学习。本文关注了解当训练和部署之间的模态类型不同时，模型如何表现，这在许多应用多模态学习应用于硬件平台时会自然发生。我们提出了一个多模态鲁棒性框架来系统分析常见的多模态表示学习方法。此外，我们发现了这些方法的鲁棒性不足，并提出了两种干预技术，在AudioSet、Kinetics-400和ImageNet-Captions三个数据集上实现了1.5倍至4倍的鲁棒性提高。最后，我们展示了这些干预技术可以更好地利用额外的模态，在AudioSet 20K上实现了44.2 mAP的有竞争力结果。",
    "tldr": "本文提出了一个多模态鲁棒性框架，分析了多种多模态学习方法的鲁棒性不足，并提出了两种干预技术，在多个数据集上实现了1.5倍至4倍的鲁棒性提高，同时在AudioSet 20K上实现了44.2 mAP的有竞争力结果。",
    "en_tdlr": "The paper proposes a multimodal robustness framework to analyze the shortcomings of common multimodal representation learning methods and presents two intervention techniques that improve robustness by 1.5x-4x on three datasets. Additionally, the interventions demonstrate better use of additional modalities and achieve competitive results of 44.2 mAP on AudioSet 20K."
}