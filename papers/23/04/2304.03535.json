{
    "title": "CRISP: Curriculum inducing Primitive Informed Subgoal Prediction for Hierarchical Reinforcement Learning. (arXiv:2304.03535v1 [cs.LG])",
    "abstract": "Hierarchical reinforcement learning is a promising approach that uses temporal abstraction to solve complex long horizon problems. However, simultaneously learning a hierarchy of policies is unstable as it is challenging to train higher-level policy when the lower-level primitive is non-stationary. In this paper, we propose a novel hierarchical algorithm by generating a curriculum of achievable subgoals for evolving lower-level primitives using reinforcement learning and imitation learning. The lower level primitive periodically performs data relabeling on a handful of expert demonstrations using our primitive informed parsing approach. We provide expressions to bound the sub-optimality of our method and develop a practical algorithm for hierarchical reinforcement learning. Since our approach uses a handful of expert demonstrations, it is suitable for most robotic control tasks. Experimental evaluation on complex maze navigation and robotic manipulation environments show that inducing ",
    "link": "http://arxiv.org/abs/2304.03535",
    "context": "Title: CRISP: Curriculum inducing Primitive Informed Subgoal Prediction for Hierarchical Reinforcement Learning. (arXiv:2304.03535v1 [cs.LG])\nAbstract: Hierarchical reinforcement learning is a promising approach that uses temporal abstraction to solve complex long horizon problems. However, simultaneously learning a hierarchy of policies is unstable as it is challenging to train higher-level policy when the lower-level primitive is non-stationary. In this paper, we propose a novel hierarchical algorithm by generating a curriculum of achievable subgoals for evolving lower-level primitives using reinforcement learning and imitation learning. The lower level primitive periodically performs data relabeling on a handful of expert demonstrations using our primitive informed parsing approach. We provide expressions to bound the sub-optimality of our method and develop a practical algorithm for hierarchical reinforcement learning. Since our approach uses a handful of expert demonstrations, it is suitable for most robotic control tasks. Experimental evaluation on complex maze navigation and robotic manipulation environments show that inducing ",
    "path": "papers/23/04/2304.03535.json",
    "total_tokens": 950,
    "tldr": "本文介绍了一种名为CRISP的课程化引导下的基于子目标预测的分层强化学习算法，该算法解决了同时学习一系列政策时下层原语非静态所带来的挑战。实验评估表明，该方法优于其他方法。",
    "en_tdlr": "The paper proposes a novel hierarchical algorithm named CRISP for solving the challenge of simultaneously learning a series of policies when the lower-level primitives are non-stationary. The algorithm generates a curriculum of achievable subgoals using reinforcement learning and imitation learning, and evolves lower-level primitives periodically by data relabeling. The evaluation on complex maze navigation and robotic manipulation environments shows that CRISP outperforms other methods."
}