{
    "title": "Quantile Extreme Gradient Boosting for Uncertainty Quantification. (arXiv:2304.11732v1 [stat.ML])",
    "abstract": "As the availability, size and complexity of data have increased in recent years, machine learning (ML) techniques have become popular for modeling. Predictions resulting from applying ML models are often used for inference, decision-making, and downstream applications. A crucial yet often overlooked aspect of ML is uncertainty quantification, which can significantly impact how predictions from models are used and interpreted.  Extreme Gradient Boosting (XGBoost) is one of the most popular ML methods given its simple implementation, fast computation, and sequential learning, which make its predictions highly accurate compared to other methods. However, techniques for uncertainty determination in ML models such as XGBoost have not yet been universally agreed among its varying applications. We propose enhancements to XGBoost whereby a modified quantile regression is used as the objective function to estimate uncertainty (QXGBoost). Specifically, we included the Huber norm in the quantile ",
    "link": "http://arxiv.org/abs/2304.11732",
    "context": "Title: Quantile Extreme Gradient Boosting for Uncertainty Quantification. (arXiv:2304.11732v1 [stat.ML])\nAbstract: As the availability, size and complexity of data have increased in recent years, machine learning (ML) techniques have become popular for modeling. Predictions resulting from applying ML models are often used for inference, decision-making, and downstream applications. A crucial yet often overlooked aspect of ML is uncertainty quantification, which can significantly impact how predictions from models are used and interpreted.  Extreme Gradient Boosting (XGBoost) is one of the most popular ML methods given its simple implementation, fast computation, and sequential learning, which make its predictions highly accurate compared to other methods. However, techniques for uncertainty determination in ML models such as XGBoost have not yet been universally agreed among its varying applications. We propose enhancements to XGBoost whereby a modified quantile regression is used as the objective function to estimate uncertainty (QXGBoost). Specifically, we included the Huber norm in the quantile ",
    "path": "papers/23/04/2304.11732.json",
    "total_tokens": 886,
    "translated_title": "分位数极端梯度提升用于不确定性量化",
    "translated_abstract": "近年来，随着数据的可用性、规模和复杂性的增加，机器学习（ML）技术已经成为建模的热门方法。将ML模型应用于预测的结果经常被用于推理、决策和下游应用。然而，ML模型的不确定性量化是一个至关重要但常常被忽视的方面，它能够显著影响模型预测的使用和解释。极端梯度提升（XGBoost）是最受欢迎的ML方法之一，因为它的实现简单、计算速度快、序列学习等原因，其预测相对于其他方法来说更为准确。然而，对于如XGBoost这样的ML模型的不确定性确定技术，其在不同应用场景中仍然存在争议。我们提出了对XGBoost的增强措施，采用修改后的分位数回归作为目标函数来估计不确定性（QXGBoost）。具体而言，我们在分位数回归中引入了Huber范数。",
    "tldr": "本论文提出了QXGBoost，它是对极端梯度提升（XGBoost）的增强，采用修改后的分位数回归方法估计不确定性。"
}