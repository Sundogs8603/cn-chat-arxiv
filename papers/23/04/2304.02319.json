{
    "title": "Efficient CNNs via Passive Filter Pruning. (arXiv:2304.02319v1 [cs.LG])",
    "abstract": "Convolutional neural networks (CNNs) have shown state-of-the-art performance in various applications. However, CNNs are resource-hungry due to their requirement of high computational complexity and memory storage. Recent efforts toward achieving computational efficiency in CNNs involve filter pruning methods that eliminate some of the filters in CNNs based on the \\enquote{importance} of the filters. The majority of existing filter pruning methods are either \"active\", which use a dataset and generate feature maps to quantify filter importance, or \"passive\", which compute filter importance using entry-wise norm of the filters without involving data. Under a high pruning ratio where large number of filters are to be pruned from the network, the entry-wise norm methods eliminate relatively smaller norm filters without considering the significance of the filters in producing the node output, resulting in degradation in the performance. To address this, we present a passive filter pruning me",
    "link": "http://arxiv.org/abs/2304.02319",
    "context": "Title: Efficient CNNs via Passive Filter Pruning. (arXiv:2304.02319v1 [cs.LG])\nAbstract: Convolutional neural networks (CNNs) have shown state-of-the-art performance in various applications. However, CNNs are resource-hungry due to their requirement of high computational complexity and memory storage. Recent efforts toward achieving computational efficiency in CNNs involve filter pruning methods that eliminate some of the filters in CNNs based on the \\enquote{importance} of the filters. The majority of existing filter pruning methods are either \"active\", which use a dataset and generate feature maps to quantify filter importance, or \"passive\", which compute filter importance using entry-wise norm of the filters without involving data. Under a high pruning ratio where large number of filters are to be pruned from the network, the entry-wise norm methods eliminate relatively smaller norm filters without considering the significance of the filters in producing the node output, resulting in degradation in the performance. To address this, we present a passive filter pruning me",
    "path": "papers/23/04/2304.02319.json",
    "total_tokens": 861,
    "translated_title": "通过被动滤波剪枝实现高效CNN",
    "translated_abstract": "卷积神经网络在各种应用中已经展示出最先进的性能，但是由于对高计算复杂度和存储器的要求，CNN是资源密集型的。最近实现CNN计算效率的努力包括滤波剪枝方法，其根据滤波器的“重要性”消除CNN中的某些滤波器。大多数现有的滤波剪枝方法要么是“主动型”，即使用数据集和生成特征映射来量化滤波器的重要性；要么是“被动型”，即使用滤波器的逐元素范数计算滤波器的重要性而不涉及数据。在高剪枝率下，即需要从网络中剪枝大量的滤波器时，逐元素范数方法消除相对较小的范数滤波器而不考虑滤波器在产生节点输出方面的重要性，导致性能下降。为了解决这个问题，我们提出了一种被动滤波剪枝方法。",
    "tldr": "本论文提出了一种被动滤波剪枝方法来达到高效CNN的目的，解决了高剪枝率下逐元素范数方法存在的性能下降问题。",
    "en_tdlr": "This paper proposes a passive filter pruning method to achieve efficient CNNs and addresses the performance degradation issue of entry-wise norm methods under high pruning ratio."
}