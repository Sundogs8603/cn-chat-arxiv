{
    "title": "Q2ATransformer: Improving Medical VQA via an Answer Querying Decoder. (arXiv:2304.01611v1 [cs.CV])",
    "abstract": "Medical Visual Question Answering (VQA) systems play a supporting role to understand clinic-relevant information carried by medical images. The questions to a medical image include two categories: close-end (such as Yes/No question) and open-end. To obtain answers, the majority of the existing medical VQA methods relies on classification approaches, while a few works attempt to use generation approaches or a mixture of the two. The classification approaches are relatively simple but perform poorly on long open-end questions. To bridge this gap, in this paper, we propose a new Transformer based framework for medical VQA (named as Q2ATransformer), which integrates the advantages of both the classification and the generation approaches and provides a unified treatment for the close-end and open-end questions. Specifically, we introduce an additional Transformer decoder with a set of learnable candidate answer embeddings to query the existence of each answer class to a given image-question",
    "link": "http://arxiv.org/abs/2304.01611",
    "context": "Title: Q2ATransformer: Improving Medical VQA via an Answer Querying Decoder. (arXiv:2304.01611v1 [cs.CV])\nAbstract: Medical Visual Question Answering (VQA) systems play a supporting role to understand clinic-relevant information carried by medical images. The questions to a medical image include two categories: close-end (such as Yes/No question) and open-end. To obtain answers, the majority of the existing medical VQA methods relies on classification approaches, while a few works attempt to use generation approaches or a mixture of the two. The classification approaches are relatively simple but perform poorly on long open-end questions. To bridge this gap, in this paper, we propose a new Transformer based framework for medical VQA (named as Q2ATransformer), which integrates the advantages of both the classification and the generation approaches and provides a unified treatment for the close-end and open-end questions. Specifically, we introduce an additional Transformer decoder with a set of learnable candidate answer embeddings to query the existence of each answer class to a given image-question",
    "path": "papers/23/04/2304.01611.json",
    "total_tokens": 894,
    "tldr": "本文提出了一个医学VQA框架，Q2ATransformer，它整合了分类和生成方法，在关闭式和开放式问题的答案中都表现出色。额外的Transformer解码器可以查询每个答案类是否存在于给定图像-问题中。"
}