{
    "title": "Post-selection Inference for Conformal Prediction: Trading off Coverage for Precision. (arXiv:2304.06158v1 [stat.ME])",
    "abstract": "Conformal inference has played a pivotal role in providing uncertainty quantification for black-box ML prediction algorithms with finite sample guarantees. Traditionally, conformal prediction inference requires a data-independent specification of miscoverage level. In practical applications, one might want to update the miscoverage level after computing the prediction set. For example, in the context of binary classification, the analyst might start with a $95\\%$ prediction sets and see that most prediction sets contain all outcome classes. Prediction sets with both classes being undesirable, the analyst might desire to consider, say $80\\%$ prediction set. Construction of prediction sets that guarantee coverage with data-dependent miscoverage level can be considered as a post-selection inference problem. In this work, we develop uniform conformal inference with finite sample prediction guarantee with arbitrary data-dependent miscoverage levels using distribution-free confidence bands f",
    "link": "http://arxiv.org/abs/2304.06158",
    "context": "Title: Post-selection Inference for Conformal Prediction: Trading off Coverage for Precision. (arXiv:2304.06158v1 [stat.ME])\nAbstract: Conformal inference has played a pivotal role in providing uncertainty quantification for black-box ML prediction algorithms with finite sample guarantees. Traditionally, conformal prediction inference requires a data-independent specification of miscoverage level. In practical applications, one might want to update the miscoverage level after computing the prediction set. For example, in the context of binary classification, the analyst might start with a $95\\%$ prediction sets and see that most prediction sets contain all outcome classes. Prediction sets with both classes being undesirable, the analyst might desire to consider, say $80\\%$ prediction set. Construction of prediction sets that guarantee coverage with data-dependent miscoverage level can be considered as a post-selection inference problem. In this work, we develop uniform conformal inference with finite sample prediction guarantee with arbitrary data-dependent miscoverage levels using distribution-free confidence bands f",
    "path": "papers/23/04/2304.06158.json",
    "total_tokens": 843,
    "translated_title": "为一致性预测的后选推理：权衡精度和覆盖范围",
    "translated_abstract": "一致性推理在为具有有限样本保证的黑盒机器学习预测算法提供不确定性量化上发挥了重要作用。传统上，一致性预测推理需要独立于数据的错误覆盖水平规范。在实际应用中，人们可能会在计算出预测集之后更新错误覆盖水平。例如，在二元分类的情况下，分析人员可能会从一个95％的预测集开始，并发现大多数预测集包含所有输出类别。如果两个类别都不可取，分析人员可能会考虑80％的预测集。具有数据相关的误覆盖水平和保证覆盖范围的预测集的构建可以被认为是一个后选推理问题。在这项工作中，我们使用无分布信赖带，开发了具有任意数据相关误覆盖水平的有限样本预测保证的统一一致性推理。",
    "tldr": "本论文提出一种使用无分布信赖带的 uniform conformal inference 算法，实现任意数据相关误覆盖水平的有限样本预测保证的统一一致性推理。",
    "en_tdlr": "This paper proposes a uniform conformal inference algorithm using distribution-free confidence bands to achieve finite sample prediction guarantee with arbitrary data-dependent miscoverage levels for post-selection inference in practice."
}