{
    "title": "CRN: Camera Radar Net for Accurate, Robust, Efficient 3D Perception. (arXiv:2304.00670v2 [cs.CV] UPDATED)",
    "abstract": "Autonomous driving requires an accurate and fast 3D perception system that includes 3D object detection, tracking, and segmentation. Although recent low-cost camera-based approaches have shown promising results, they are susceptible to poor illumination or bad weather conditions and have a large localization error. Hence, fusing camera with low-cost radar, which provides precise long-range measurement and operates reliably in all environments, is promising but has not yet been thoroughly investigated. In this paper, we propose Camera Radar Net (CRN), a novel camera-radar fusion framework that generates a semantically rich and spatially accurate bird's-eye-view (BEV) feature map for various tasks. To overcome the lack of spatial information in an image, we transform perspective view image features to BEV with the help of sparse but accurate radar points. We further aggregate image and radar feature maps in BEV using multi-modal deformable attention designed to tackle the spatial misalig",
    "link": "http://arxiv.org/abs/2304.00670",
    "context": "Title: CRN: Camera Radar Net for Accurate, Robust, Efficient 3D Perception. (arXiv:2304.00670v2 [cs.CV] UPDATED)\nAbstract: Autonomous driving requires an accurate and fast 3D perception system that includes 3D object detection, tracking, and segmentation. Although recent low-cost camera-based approaches have shown promising results, they are susceptible to poor illumination or bad weather conditions and have a large localization error. Hence, fusing camera with low-cost radar, which provides precise long-range measurement and operates reliably in all environments, is promising but has not yet been thoroughly investigated. In this paper, we propose Camera Radar Net (CRN), a novel camera-radar fusion framework that generates a semantically rich and spatially accurate bird's-eye-view (BEV) feature map for various tasks. To overcome the lack of spatial information in an image, we transform perspective view image features to BEV with the help of sparse but accurate radar points. We further aggregate image and radar feature maps in BEV using multi-modal deformable attention designed to tackle the spatial misalig",
    "path": "papers/23/04/2304.00670.json",
    "total_tokens": 959,
    "translated_title": "CRN：用于准确、稳健、高效的3D感知的相机雷达网络",
    "translated_abstract": "自动驾驶需要一个准确快速的3D感知系统，包括3D物体检测、跟踪和分割。虽然最近的低成本基于相机的方法显示出了有希望的结果，但是它们容易受到糟糕的光照或恶劣的天气条件的影响，并且具有较大的定位误差。因此，将相机与低成本雷达相结合，后者可以在所有环境中提供精确的远程测量并可靠运行，是有希望的，但尚未得到全面的研究。在本文中，我们提出了一个名为Camera Radar Net（CRN）的新颖的相机雷达融合框架，为各种任务生成一个语义丰富、空间精确的鸟瞰特征图（BEV）。为了克服图像中缺乏空间信息的问题，我们使用稀疏但准确的雷达点将透视视图图像特征转换为BEV。我们进一步使用多模态可变形注意力在BEV中聚合图像和雷达特征图，以解决空间对齐错误问题",
    "tldr": "本文提出了CRN，一个新颖的相机雷达融合框架，通过将图像视图特征转换为鸟瞰特征图和使用多模态可变形注意力，实现了准确、稳健、高效的3D感知任务",
    "en_tdlr": "This paper introduces CRN, a novel camera-radar fusion framework that achieves accurate, robust, and efficient 3D perception tasks by transforming image view features into bird's-eye-view features and using multi-modal deformable attention."
}