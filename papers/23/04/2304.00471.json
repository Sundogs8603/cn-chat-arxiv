{
    "title": "A Unified Compression Framework for Efficient Speech-Driven Talking-Face Generation. (arXiv:2304.00471v2 [cs.SD] UPDATED)",
    "abstract": "Virtual humans have gained considerable attention in numerous industries, e.g., entertainment and e-commerce. As a core technology, synthesizing photorealistic face frames from target speech and facial identity has been actively studied with generative adversarial networks. Despite remarkable results of modern talking-face generation models, they often entail high computational burdens, which limit their efficient deployment. This study aims to develop a lightweight model for speech-driven talking-face synthesis. We build a compact generator by removing the residual blocks and reducing the channel width from Wav2Lip, a popular talking-face generator. We also present a knowledge distillation scheme to stably yet effectively train the small-capacity generator without adversarial learning. We reduce the number of parameters and MACs by 28$\\times$ while retaining the performance of the original model. Moreover, to alleviate a severe performance drop when converting the whole generator to I",
    "link": "http://arxiv.org/abs/2304.00471",
    "context": "Title: A Unified Compression Framework for Efficient Speech-Driven Talking-Face Generation. (arXiv:2304.00471v2 [cs.SD] UPDATED)\nAbstract: Virtual humans have gained considerable attention in numerous industries, e.g., entertainment and e-commerce. As a core technology, synthesizing photorealistic face frames from target speech and facial identity has been actively studied with generative adversarial networks. Despite remarkable results of modern talking-face generation models, they often entail high computational burdens, which limit their efficient deployment. This study aims to develop a lightweight model for speech-driven talking-face synthesis. We build a compact generator by removing the residual blocks and reducing the channel width from Wav2Lip, a popular talking-face generator. We also present a knowledge distillation scheme to stably yet effectively train the small-capacity generator without adversarial learning. We reduce the number of parameters and MACs by 28$\\times$ while retaining the performance of the original model. Moreover, to alleviate a severe performance drop when converting the whole generator to I",
    "path": "papers/23/04/2304.00471.json",
    "total_tokens": 1087,
    "translated_title": "一种有效的语音驱动动态生成脸部特征的统一压缩框架",
    "translated_abstract": "虚拟人类已经引起了许多行业的关注，例如娱乐和电子商务。人们积极研究利用生成对抗网络从目标语音和面部身份合成逼真的人脸。尽管现代生成模型的结果显着，但它们往往需要大量计算，限制了它们的有效部署。这项研究旨在开发一种轻量级语音驱动的动态生成脸部特征模型。我们通过从流行的动态生成脸部特征模型Wav2Lip中移除残差块和减少通道宽度来构建一个紧凑的生成器。我们还提出了一种知识蒸馏方案，以稳定而有效地训练小容量生成器而不需要对抗性学习。我们将参数数量和MAC的数量减少了28倍，同时保留了原始模型的性能。此外，为了缓解将整个生成器转换为图像信号处理器时性能严重下降的问题，我们提出了一个端到端的压缩框架，该框架包括ISP感知修剪，量化和Huffman编码。在一个大规模公开数据集上进行的实验表明，我们提出的框架以显著更快的速度生成高质量的动态生成脸部特征，并占用更少的内存。",
    "tldr": "该研究开发了一种轻量级的语音驱动动态生成脸部特征模型，并通过从基于生成对抗网络的原始模型中移除残差块和减少通道宽度以及应用端到端的压缩技术实现了高效的推理和占用更少内存。",
    "en_tdlr": "This study developed a lightweight model for speech-driven talking-face synthesis by removing residual blocks and reducing channel width from the original model, and presented an end-to-end compression framework to achieve efficient inference and occupy less memory."
}