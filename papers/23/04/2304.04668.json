{
    "title": "MERMAIDE: Learning to Align Learners using Model-Based Meta-Learning. (arXiv:2304.04668v2 [cs.LG] UPDATED)",
    "abstract": "We study how a principal can efficiently and effectively intervene on the rewards of a previously unseen learning agent in order to induce desirable outcomes. This is relevant to many real-world settings like auctions or taxation, where the principal may not know the learning behavior nor the rewards of real people. Moreover, the principal should be few-shot adaptable and minimize the number of interventions, because interventions are often costly. We introduce MERMAIDE, a model-based meta-learning framework to train a principal that can quickly adapt to out-of-distribution agents with different learning strategies and reward functions. We validate this approach step-by-step. First, in a Stackelberg setting with a best-response agent, we show that meta-learning enables quick convergence to the theoretically known Stackelberg equilibrium at test time, although noisy observations severely increase the sample complexity. We then show that our model-based meta-learning approach is cost-eff",
    "link": "http://arxiv.org/abs/2304.04668",
    "context": "Title: MERMAIDE: Learning to Align Learners using Model-Based Meta-Learning. (arXiv:2304.04668v2 [cs.LG] UPDATED)\nAbstract: We study how a principal can efficiently and effectively intervene on the rewards of a previously unseen learning agent in order to induce desirable outcomes. This is relevant to many real-world settings like auctions or taxation, where the principal may not know the learning behavior nor the rewards of real people. Moreover, the principal should be few-shot adaptable and minimize the number of interventions, because interventions are often costly. We introduce MERMAIDE, a model-based meta-learning framework to train a principal that can quickly adapt to out-of-distribution agents with different learning strategies and reward functions. We validate this approach step-by-step. First, in a Stackelberg setting with a best-response agent, we show that meta-learning enables quick convergence to the theoretically known Stackelberg equilibrium at test time, although noisy observations severely increase the sample complexity. We then show that our model-based meta-learning approach is cost-eff",
    "path": "papers/23/04/2304.04668.json",
    "total_tokens": 944,
    "translated_title": "MERMAIDE: 使用基于模型的元学习方法来学习对齐学习者",
    "translated_abstract": "我们研究了一个主体如何高效有效地干预之前未见过的学习代理的奖励，以实现理想的结果。这对于许多现实世界的情景（如拍卖或税收）是相关的，因为主体可能不知道真实人的学习行为和奖励。此外，主体应该能够在少量样本中适应，并且尽量减少干预的次数，因为干预通常是昂贵的。我们引入了MERMAIDE，这是一个基于模型的元学习框架，用于训练一个能够快速适应具有不同学习策略和奖励函数的超出分布代理的主体。我们逐步验证了这种方法。首先，在具有最佳响应代理的斯塔克贝格设置中，我们展示了元学习在测试时能够快速收敛到理论已知的斯塔克贝格均衡，尽管噪声观测严重增加了样本复杂性。然后，我们展示了我们的基于模型的元学习方法成本效益高",
    "tldr": "MERMAIDE是一个基于模型的元学习框架，用于训练主体快速适应具有不同学习策略和奖励函数的超出分布代理，以实现理想结果，并且能够在少量样本中适应并减少干预次数。",
    "en_tdlr": "MERMAIDE is a model-based meta-learning framework that trains a principal to quickly adapt to out-of-distribution agents with different learning strategies and reward functions, achieving desirable outcomes and minimizing interventions in a few-shot manner."
}