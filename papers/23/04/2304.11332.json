{
    "title": "Input Augmentation with SAM: Boosting Medical Image Segmentation with Segmentation Foundation Model. (arXiv:2304.11332v1 [cs.CV])",
    "abstract": "The Segment Anything Model (SAM) is a recently developed large model for general-purpose segmentation for computer vision tasks. SAM was trained using 11 million images with over 1 billion masks and can produce segmentation results for a wide range of objects in natural scene images. SAM can be viewed as a general perception model for segmentation (partitioning images into semantically meaningful regions). Thus, how to utilize such a large foundation model for medical image segmentation is an emerging research target. This paper shows that although SAM does not immediately give high-quality segmentation for medical images, its generated masks, features, and stability scores are useful for building and training better medical image segmentation models. In particular, we demonstrate how to use SAM to augment image inputs for a commonly-used medical image segmentation model (e.g., U-Net). Experiments on two datasets show the effectiveness of our proposed method.",
    "link": "http://arxiv.org/abs/2304.11332",
    "context": "Title: Input Augmentation with SAM: Boosting Medical Image Segmentation with Segmentation Foundation Model. (arXiv:2304.11332v1 [cs.CV])\nAbstract: The Segment Anything Model (SAM) is a recently developed large model for general-purpose segmentation for computer vision tasks. SAM was trained using 11 million images with over 1 billion masks and can produce segmentation results for a wide range of objects in natural scene images. SAM can be viewed as a general perception model for segmentation (partitioning images into semantically meaningful regions). Thus, how to utilize such a large foundation model for medical image segmentation is an emerging research target. This paper shows that although SAM does not immediately give high-quality segmentation for medical images, its generated masks, features, and stability scores are useful for building and training better medical image segmentation models. In particular, we demonstrate how to use SAM to augment image inputs for a commonly-used medical image segmentation model (e.g., U-Net). Experiments on two datasets show the effectiveness of our proposed method.",
    "path": "papers/23/04/2304.11332.json",
    "total_tokens": 861,
    "translated_title": "利用SAM的输入增强技术: 以分割基础模型为基础提升医学图像分割",
    "translated_abstract": "Segment Anything Model (SAM)是一个最近发展的通用分割模型，用于计算机视觉任务. SAM使用了超过1亿个掩模的1100万图像进行训练，可以为自然场景图像中的广泛对象生成分割结果。本研究展示了如何利用这样一个大型基础模型来进行医学图像分割，尽管SAM并没有立即为医学图像提供高质量的分割，但其生成的掩模、特征和稳定性分数对于构建和训练更好的医学图像分割模型非常有用。特别地，我们演示了如何使用SAM来增强经典的医学图像分割模型（如U-Net）的图像输入。对两个数据集的实验表明了我们所提出的方法的有效性。",
    "tldr": "本文介绍如何使用大型的通用分割模型SAM来提升医学图像分割，展示了如何通过使用SAM生成的掩模、特征和稳定性分数来构建和训练更好的医学图像分割模型，并在两个数据集上进行了验证。",
    "en_tdlr": "This paper introduces the use of the large general segmentation model SAM to improve medical image segmentation. It demonstrates how to build and train better medical image segmentation models using the masks, features, and stability scores generated by SAM, and validates the proposed method on two datasets."
}