{
    "title": "Deep Transfer Learning for Automatic Speech Recognition: Towards Better Generalization. (arXiv:2304.14535v1 [cs.SD])",
    "abstract": "Automatic speech recognition (ASR) has recently become an important challenge when using deep learning (DL). It requires large-scale training datasets and high computational and storage resources. Moreover, DL techniques and machine learning (ML) approaches in general, hypothesize that training and testing data come from the same domain, with the same input feature space and data distribution characteristics. This assumption, however, is not applicable in some real-world artificial intelligence (AI) applications. Moreover, there are situations where gathering real data is challenging, expensive, or rarely occurring, which can not meet the data requirements of DL models. deep transfer learning (DTL) has been introduced to overcome these issues, which helps develop high-performing models using real datasets that are small or slightly different but related to the training data. This paper presents a comprehensive survey of DTL-based ASR frameworks to shed light on the latest developments ",
    "link": "http://arxiv.org/abs/2304.14535",
    "context": "Title: Deep Transfer Learning for Automatic Speech Recognition: Towards Better Generalization. (arXiv:2304.14535v1 [cs.SD])\nAbstract: Automatic speech recognition (ASR) has recently become an important challenge when using deep learning (DL). It requires large-scale training datasets and high computational and storage resources. Moreover, DL techniques and machine learning (ML) approaches in general, hypothesize that training and testing data come from the same domain, with the same input feature space and data distribution characteristics. This assumption, however, is not applicable in some real-world artificial intelligence (AI) applications. Moreover, there are situations where gathering real data is challenging, expensive, or rarely occurring, which can not meet the data requirements of DL models. deep transfer learning (DTL) has been introduced to overcome these issues, which helps develop high-performing models using real datasets that are small or slightly different but related to the training data. This paper presents a comprehensive survey of DTL-based ASR frameworks to shed light on the latest developments ",
    "path": "papers/23/04/2304.14535.json",
    "total_tokens": 804,
    "translated_title": "基于深度迁移学习的自动语音识别：迈向更好的泛化",
    "translated_abstract": "最近，深度学习在自动语音识别（ASR）方面面临着一个重要的挑战，这需要大规模的训练数据集和高计算和存储资源。此外，机器学习（ML）方法和深度学习技术通常假设训练和测试数据来自相同的域，具有相同的输入特征空间和数据分布特性。然而，在一些现实世界的人工智能（AI）应用中，这种假设是无法适用的。DTL被引入来克服这些问题，它有助于使用实际数据集开发高性能的模型，这些实际数据集即使很小或稍有不同，但与训练数据相关。本文提出了基于DTL的ASR框架的全面调查，以阐明最新的发展。",
    "tldr": "本文Survey了基于DTL的ASR框架，并介绍了如何使用实际数据集进行深度迁移学习以达到更好的泛化性能。",
    "en_tdlr": "This paper presents a comprehensive survey of DTL-based ASR frameworks and introduces how to use actual datasets for deep transfer learning to achieve better generalization performance."
}