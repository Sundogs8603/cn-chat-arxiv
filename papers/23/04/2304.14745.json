{
    "title": "Made of Steel? Learning Plausible Materials for Components in the Vehicle Repair Domain. (arXiv:2304.14745v1 [cs.CL])",
    "abstract": "We propose a novel approach to learn domain-specific plausible materials for components in the vehicle repair domain by probing Pretrained Language Models (PLMs) in a cloze task style setting to overcome the lack of annotated datasets. We devise a new method to aggregate salient predictions from a set of cloze query templates and show that domain-adaptation using either a small, high-quality or a customized Wikipedia corpus boosts performance. When exploring resource-lean alternatives, we find a distilled PLM clearly outperforming a classic pattern-based algorithm. Further, given that 98% of our domain-specific components are multiword expressions, we successfully exploit the compositionality assumption as a way to address data sparsity.",
    "link": "http://arxiv.org/abs/2304.14745",
    "context": "Title: Made of Steel? Learning Plausible Materials for Components in the Vehicle Repair Domain. (arXiv:2304.14745v1 [cs.CL])\nAbstract: We propose a novel approach to learn domain-specific plausible materials for components in the vehicle repair domain by probing Pretrained Language Models (PLMs) in a cloze task style setting to overcome the lack of annotated datasets. We devise a new method to aggregate salient predictions from a set of cloze query templates and show that domain-adaptation using either a small, high-quality or a customized Wikipedia corpus boosts performance. When exploring resource-lean alternatives, we find a distilled PLM clearly outperforming a classic pattern-based algorithm. Further, given that 98% of our domain-specific components are multiword expressions, we successfully exploit the compositionality assumption as a way to address data sparsity.",
    "path": "papers/23/04/2304.14745.json",
    "total_tokens": 790,
    "translated_title": "由什么构成？学习修车领域组件的可信材料",
    "translated_abstract": "我们提出了一种新的方法，通过探索预训练语言模型（PLM）中的cloze任务样式设置来学习车辆维修领域组件的特定材料，以克服缺乏注释数据集的问题。我们设计了一种新方法，聚合了一组cloze查询模板的显著预测，并表明使用小型高质量或定制的维基百科语料库的领域自适应可以提高性能。当探索资源紧缺的替代方案时，我们发现精简的PLM明显优于经典的基于模式的算法。此外，考虑到我们领域特定组件的98％都是多词表达式，我们成功地利用组成性假设来解决数据稀疏性问题。",
    "tldr": "本文提出了一种新方法，通过探索预训练语言模型（PLM）学习车辆维修领域组件的特定材料，成功克服了数据稀疏性问题和缺乏注释数据集的问题。",
    "en_tdlr": "This paper proposes a novel approach to learning domain-specific plausible materials for components in the vehicle repair domain by probing Pretrained Language Models (PLMs) in a cloze task style setting, successfully overcoming data sparsity and lack of annotated datasets."
}