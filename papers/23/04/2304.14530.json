{
    "title": "It is all about where you start: Text-to-image generation with seed selection. (arXiv:2304.14530v1 [cs.CV])",
    "abstract": "Text-to-image diffusion models can synthesize a large variety of concepts in new compositions and scenarios. However, they still struggle with generating uncommon concepts, rare unusual combinations, or structured concepts like hand palms. Their limitation is partly due to the long-tail nature of their training data: web-crawled data sets are strongly unbalanced, causing models to under-represent concepts from the tail of the distribution. Here we characterize the effect of unbalanced training data on text-to-image models and offer a remedy. We show that rare concepts can be correctly generated by carefully selecting suitable generation seeds in the noise space, a technique that we call SeedSelect. SeedSelect is efficient and does not require retraining the diffusion model. We evaluate the benefit of SeedSelect on a series of problems. First, in few-shot semantic data augmentation, where we generate semantically correct images for few-shot and long-tail benchmarks. We show classificati",
    "link": "http://arxiv.org/abs/2304.14530",
    "context": "Title: It is all about where you start: Text-to-image generation with seed selection. (arXiv:2304.14530v1 [cs.CV])\nAbstract: Text-to-image diffusion models can synthesize a large variety of concepts in new compositions and scenarios. However, they still struggle with generating uncommon concepts, rare unusual combinations, or structured concepts like hand palms. Their limitation is partly due to the long-tail nature of their training data: web-crawled data sets are strongly unbalanced, causing models to under-represent concepts from the tail of the distribution. Here we characterize the effect of unbalanced training data on text-to-image models and offer a remedy. We show that rare concepts can be correctly generated by carefully selecting suitable generation seeds in the noise space, a technique that we call SeedSelect. SeedSelect is efficient and does not require retraining the diffusion model. We evaluate the benefit of SeedSelect on a series of problems. First, in few-shot semantic data augmentation, where we generate semantically correct images for few-shot and long-tail benchmarks. We show classificati",
    "path": "papers/23/04/2304.14530.json",
    "total_tokens": 912,
    "translated_title": "文本到图像生成中种子选择的重要性",
    "translated_abstract": "文本到图像扩散模型可以在新的组合和场景中合成大量的概念。然而，它们仍然在生成不常见的概念、罕见的不寻常组合或结构化概念（如手掌）方面有困难。它们的限制部分是由于训练数据的长尾性：网络爬取的数据集严重不平衡，导致模型在分布尾部的概念上表现不足。在这里，我们表征了不平衡训练数据对文本到图像模型的影响，并提出了一个解决方案。我们展示了通过在噪声空间中精心选择适当的生成种子，可以正确生成罕见的概念，这一技术被称为SeedSelect。SeedSelect是高效的，不需要重新训练扩散模型。我们在一系列问题上评估了SeedSelect的效益。首先，在少样本语义数据增强中，我们为少样本和长尾基准生成了语义正确的图像。我们展示了分类",
    "tldr": "该论文研究了文本到图像生成中训练数据不平衡对模型的影响，并提出了一种高效的方法：在噪声空间中选择适当的生成种子。该方法能够正确生成罕见的概念，而不需要重新训练模型。",
    "en_tdlr": "This paper investigates the impact of unbalanced training data on text-to-image generation models and proposes a efficient method called SeedSelect, which selects suitable generation seeds in the noise space to generate rare concepts without retraining the model."
}