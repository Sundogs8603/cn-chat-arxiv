{
    "title": "Spherical Inducing Features for Orthogonally-Decoupled Gaussian Processes. (arXiv:2304.14034v1 [cs.LG])",
    "abstract": "Despite their many desirable properties, Gaussian processes (GPs) are often compared unfavorably to deep neural networks (NNs) for lacking the ability to learn representations. Recent efforts to bridge the gap between GPs and deep NNs have yielded a new class of inter-domain variational GPs in which the inducing variables correspond to hidden units of a feedforward NN. In this work, we examine some practical issues associated with this approach and propose an extension that leverages the orthogonal decomposition of GPs to mitigate these limitations. In particular, we introduce spherical inter-domain features to construct more flexible data-dependent basis functions for both the principal and orthogonal components of the GP approximation and show that incorporating NN activation features under this framework not only alleviates these shortcomings but is more scalable than alternative strategies. Experiments on multiple benchmark datasets demonstrate the effectiveness of our approach.",
    "link": "http://arxiv.org/abs/2304.14034",
    "context": "Title: Spherical Inducing Features for Orthogonally-Decoupled Gaussian Processes. (arXiv:2304.14034v1 [cs.LG])\nAbstract: Despite their many desirable properties, Gaussian processes (GPs) are often compared unfavorably to deep neural networks (NNs) for lacking the ability to learn representations. Recent efforts to bridge the gap between GPs and deep NNs have yielded a new class of inter-domain variational GPs in which the inducing variables correspond to hidden units of a feedforward NN. In this work, we examine some practical issues associated with this approach and propose an extension that leverages the orthogonal decomposition of GPs to mitigate these limitations. In particular, we introduce spherical inter-domain features to construct more flexible data-dependent basis functions for both the principal and orthogonal components of the GP approximation and show that incorporating NN activation features under this framework not only alleviates these shortcomings but is more scalable than alternative strategies. Experiments on multiple benchmark datasets demonstrate the effectiveness of our approach.",
    "path": "papers/23/04/2304.14034.json",
    "total_tokens": 859,
    "translated_title": "正交解耦高斯过程的球形感应特征",
    "translated_abstract": "尽管高斯过程（GPs）具有许多优点，但它们缺乏学习表征的能力，因此经常与深度神经网络（NNs）进行比较。最近的工作通过在诱导变量与前馈NN的隐藏单元之间建立联系的跨域变分GPs来弥合 GPs和深度NN之间的差距。本文在研究此方法与实际应用中的一些实际问题，并提出一种扩展方法，利用GPs的正交分解来减轻这些限制。具体地，我们引入球形跨域特征，构建更灵活的数据依赖基函数，用于GP逼近的主要和正交分量，结果表明在此框架下加入NN激活特征，不仅可以缓解这些问题，而且比其他策略更具有可扩展性。在多个基准数据集上的实验表明了我们方法的有效性。",
    "tldr": "本文研究了解耦高斯过程的正交分解问题，提出了一种扩展方法，即引入球形跨域特征，构建更灵活的数据依赖基函数来缓解限制，并展示了其有效性。",
    "en_tdlr": "This paper studies the problem of orthogonal decomposition in Gaussian processes and proposes an extension method that introduces spherical inter-domain features to construct more flexible data-dependent basis functions to mitigate limitations, and demonstrates its efficacy by experiments on multiple benchmark datasets."
}