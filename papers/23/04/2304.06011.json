{
    "title": "Bi-level Latent Variable Model for Sample-Efficient Multi-Agent Reinforcement Learning. (arXiv:2304.06011v1 [cs.LG])",
    "abstract": "Despite their potential in real-world applications, multi-agent reinforcement learning (MARL) algorithms often suffer from high sample complexity. To address this issue, we present a novel model-based MARL algorithm, BiLL (Bi-Level Latent Variable Model-based Learning), that learns a bi-level latent variable model from high-dimensional inputs. At the top level, the model learns latent representations of the global state, which encode global information relevant to behavior learning. At the bottom level, it learns latent representations for each agent, given the global latent representations from the top level. The model generates latent trajectories to use for policy learning. We evaluate our algorithm on complex multi-agent tasks in the challenging SMAC and Flatland environments. Our algorithm outperforms state-of-the-art model-free and model-based baselines in sample efficiency, including on two extremely challenging Super Hard SMAC maps.",
    "link": "http://arxiv.org/abs/2304.06011",
    "context": "Title: Bi-level Latent Variable Model for Sample-Efficient Multi-Agent Reinforcement Learning. (arXiv:2304.06011v1 [cs.LG])\nAbstract: Despite their potential in real-world applications, multi-agent reinforcement learning (MARL) algorithms often suffer from high sample complexity. To address this issue, we present a novel model-based MARL algorithm, BiLL (Bi-Level Latent Variable Model-based Learning), that learns a bi-level latent variable model from high-dimensional inputs. At the top level, the model learns latent representations of the global state, which encode global information relevant to behavior learning. At the bottom level, it learns latent representations for each agent, given the global latent representations from the top level. The model generates latent trajectories to use for policy learning. We evaluate our algorithm on complex multi-agent tasks in the challenging SMAC and Flatland environments. Our algorithm outperforms state-of-the-art model-free and model-based baselines in sample efficiency, including on two extremely challenging Super Hard SMAC maps.",
    "path": "papers/23/04/2304.06011.json",
    "total_tokens": 1033,
    "translated_title": "多智能体强化学习的双层潜变量模型，提高样本效率",
    "translated_abstract": "多智能体强化学习(MARL)算法在实际应用中具有很大的潜力，但通常具有较高的样本复杂度。为了解决这个问题，我们提出了一种新颖的基于模型的MARL算法：BiLL(双层潜变量模型学习)，该算法从高维度输入中学习双层潜在变量模型。在顶层，该模型学习全局状态的潜在表示，该表示编码与行为学习相关的全局信息。在底层，模型学习每个智能体的潜在表示，给定来自顶层的全局潜在表示。模型生成潜在轨迹以用于策略学习。我们在具有挑战性的SMAC和Flatland环境中评估了我们的算法，结果表明我们的算法在样本效率方面优于现有的无模型和基于模型的基准算法，包括在两个极具挑战性的Super Hard SMAC地图上。",
    "tldr": "提出了一种新颖的基于模型的MARL算法，BiLL，它学习一个双层潜变量模型，以提高样本效率。该模型在顶层学习全局状态的潜在表示，底层学习每个智能体的潜在表示，并生成潜在轨迹用于策略学习。在SMAC和Flatland环境中，我们的算法在样本效率方面优于现有的无模型和基于模型的基准算法，包括在Super Hard SMAC地图上。",
    "en_tdlr": "A novel model-based MARL algorithm, BiLL, is proposed, which learns a bi-level latent variable model to improve sample efficiency. The model learns latent representations of the global state at the top level and latent representations for each agent at the bottom level, and generates latent trajectories for policy learning. Our algorithm outperforms state-of-the-art model-free and model-based baselines in sample efficiency, including on the challenging Super Hard SMAC maps."
}