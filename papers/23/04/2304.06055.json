{
    "title": "Exploiting Symmetry and Heuristic Demonstrations in Off-policy Reinforcement Learning for Robotic Manipulation. (arXiv:2304.06055v1 [cs.RO])",
    "abstract": "Reinforcement learning demonstrates significant potential in automatically building control policies in numerous domains, but shows low efficiency when applied to robot manipulation tasks due to the curse of dimensionality. To facilitate the learning of such tasks, prior knowledge or heuristics that incorporate inherent simplification can effectively improve the learning performance. This paper aims to define and incorporate the natural symmetry present in physical robotic environments. Then, sample-efficient policies are trained by exploiting the expert demonstrations in symmetrical environments through an amalgamation of reinforcement and behavior cloning, which gives the off-policy learning process a diverse yet compact initiation. Furthermore, it presents a rigorous framework for a recent concept and explores its scope for robot manipulation tasks. The proposed method is validated via two point-to-point reaching tasks of an industrial arm, with and without an obstacle, in a simulat",
    "link": "http://arxiv.org/abs/2304.06055",
    "context": "Title: Exploiting Symmetry and Heuristic Demonstrations in Off-policy Reinforcement Learning for Robotic Manipulation. (arXiv:2304.06055v1 [cs.RO])\nAbstract: Reinforcement learning demonstrates significant potential in automatically building control policies in numerous domains, but shows low efficiency when applied to robot manipulation tasks due to the curse of dimensionality. To facilitate the learning of such tasks, prior knowledge or heuristics that incorporate inherent simplification can effectively improve the learning performance. This paper aims to define and incorporate the natural symmetry present in physical robotic environments. Then, sample-efficient policies are trained by exploiting the expert demonstrations in symmetrical environments through an amalgamation of reinforcement and behavior cloning, which gives the off-policy learning process a diverse yet compact initiation. Furthermore, it presents a rigorous framework for a recent concept and explores its scope for robot manipulation tasks. The proposed method is validated via two point-to-point reaching tasks of an industrial arm, with and without an obstacle, in a simulat",
    "path": "papers/23/04/2304.06055.json",
    "total_tokens": 857,
    "translated_title": "利用对称性和启发式演示来进行机器人操作的离线强化学习",
    "translated_abstract": "强化学习在许多领域中自动构建控制策略具有显著潜力，但在应用于机器人操作任务时由于维度的问题，效率较低。为了促进这些任务的学习，先前的知识或启发式方法可以有效地提高学习性能。本文旨在定义和结合物理机器环境中存在的自然对称性，利用对称环境中的专家演示通过强化学习和行为克隆的融合来训练具有高样本效率的策略，从而给离线强化学习过程提供多样化而紧凑的启动。此外，本文提出了一个最近概念的严格框架，并探索了它在机器人操作任务中的范围。该方法通过在模拟环境中进行两个点对点的工业臂到达任务（有障碍和无障碍）的验证。",
    "tldr": "本文提出了一个离线强化学习方法，该方法利用对称环境中的专家演示来进行机器人操作的策略训练，从而提高了学习效率和样本效率。",
    "en_tdlr": "This paper proposes an off-policy reinforcement learning method for robotic manipulation, which trains policies by exploiting expert demonstrations in symmetrical environments, and validates the approach through reaching tasks involving an industrial arm in a simulated environment."
}