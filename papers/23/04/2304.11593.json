{
    "title": "System III: Learning with Domain Knowledge for Safety Constraints. (arXiv:2304.11593v1 [cs.LG])",
    "abstract": "Reinforcement learning agents naturally learn from extensive exploration. Exploration is costly and can be unsafe in $\\textit{safety-critical}$ domains. This paper proposes a novel framework for incorporating domain knowledge to help guide safe exploration and boost sample efficiency. Previous approaches impose constraints, such as regularisation parameters in neural networks, that rely on large sample sets and often are not suitable for safety-critical domains where agents should almost always avoid unsafe actions. In our approach, called $\\textit{System III}$, which is inspired by psychologists' notions of the brain's $\\textit{System I}$ and $\\textit{System II}$, we represent domain expert knowledge of safety in form of first-order logic. We evaluate the satisfaction of these constraints via p-norms in state vector space. In our formulation, constraints are analogous to hazards, objects, and regions of state that have to be avoided during exploration. We evaluated the effectiveness o",
    "link": "http://arxiv.org/abs/2304.11593",
    "context": "Title: System III: Learning with Domain Knowledge for Safety Constraints. (arXiv:2304.11593v1 [cs.LG])\nAbstract: Reinforcement learning agents naturally learn from extensive exploration. Exploration is costly and can be unsafe in $\\textit{safety-critical}$ domains. This paper proposes a novel framework for incorporating domain knowledge to help guide safe exploration and boost sample efficiency. Previous approaches impose constraints, such as regularisation parameters in neural networks, that rely on large sample sets and often are not suitable for safety-critical domains where agents should almost always avoid unsafe actions. In our approach, called $\\textit{System III}$, which is inspired by psychologists' notions of the brain's $\\textit{System I}$ and $\\textit{System II}$, we represent domain expert knowledge of safety in form of first-order logic. We evaluate the satisfaction of these constraints via p-norms in state vector space. In our formulation, constraints are analogous to hazards, objects, and regions of state that have to be avoided during exploration. We evaluated the effectiveness o",
    "path": "papers/23/04/2304.11593.json",
    "total_tokens": 1042,
    "translated_title": "系统III：在安全约束下学习领域知识",
    "translated_abstract": "强化学习代理通过大量探索自然地学习。探索是昂贵的，并且在安全关键领域中可能不安全。本文提出了一种新颖的框架，用于整合领域知识以帮助引导安全探索并提高样本效率。我们的方法被称为System III，受心理学家关于大脑System I和System II的概念启发，我们将安全性的领域专家知识表示为一阶逻辑形式。我们通过状态向量空间中的p范数评估这些约束的满足程度。在我们的公式中，约束类似于在探索过程中必须避免的状态的危险，对象和区域。我们在模拟自主驾驶任务上评估了我们的方法的有效性，其中代理需要在避免与障碍物碰撞的同时安全导航轨迹。实验结果表明，我们的方法成功地整合了专家领域知识，以安全地引导探索并提高样本效率。",
    "tldr": "本文提出了一种称为System III的新颖框架，该框架将安全性的领域专家知识表示为一阶逻辑形式，通过p范数评估约束的满足程度，用于在安全关键领域中整合领域知识以帮助引导安全探索，并提高样本效率。实验证明该方法在一个模拟自主驾驶任务上有效。",
    "en_tdlr": "This paper proposes a novel framework, called System III, which represents expert domain knowledge of safety in first-order logic and evaluates the satisfaction of constraints through p-norms in state vector space. The approach is used to integrate domain knowledge to guide safe exploration and improve sample efficiency in safety-critical domains. Experimental results show its effectiveness in a simulated autonomous driving task."
}