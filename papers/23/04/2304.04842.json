{
    "title": "Deploying Machine Learning Models to Ahead-of-Time Runtime on Edge Using MicroTVM. (arXiv:2304.04842v1 [cs.LG])",
    "abstract": "In the past few years, more and more AI applications have been applied to edge devices. However, models trained by data scientists with machine learning frameworks, such as PyTorch or TensorFlow, can not be seamlessly executed on edge. In this paper, we develop an end-to-end code generator parsing a pre-trained model to C source libraries for the backend using MicroTVM, a machine learning compiler framework extension addressing inference on bare metal devices. An analysis shows that specific compute-intensive operators can be easily offloaded to the dedicated accelerator with a Universal Modular Accelerator (UMA) interface, while others are processed in the CPU cores. By using the automatically generated ahead-of-time C runtime, we conduct a hand gesture recognition experiment on an ARM Cortex M4F core.",
    "link": "http://arxiv.org/abs/2304.04842",
    "context": "Title: Deploying Machine Learning Models to Ahead-of-Time Runtime on Edge Using MicroTVM. (arXiv:2304.04842v1 [cs.LG])\nAbstract: In the past few years, more and more AI applications have been applied to edge devices. However, models trained by data scientists with machine learning frameworks, such as PyTorch or TensorFlow, can not be seamlessly executed on edge. In this paper, we develop an end-to-end code generator parsing a pre-trained model to C source libraries for the backend using MicroTVM, a machine learning compiler framework extension addressing inference on bare metal devices. An analysis shows that specific compute-intensive operators can be easily offloaded to the dedicated accelerator with a Universal Modular Accelerator (UMA) interface, while others are processed in the CPU cores. By using the automatically generated ahead-of-time C runtime, we conduct a hand gesture recognition experiment on an ARM Cortex M4F core.",
    "path": "papers/23/04/2304.04842.json",
    "total_tokens": 830,
    "translated_title": "使用MicroTVM将机器学习模型部署到边缘Ahead-of-Time运行",
    "translated_abstract": "近年来，越来越多的AI应用程序已经应用到边缘设备上。然而，由数据科学家使用机器学习框架（如PyTorch或TensorFlow）训练的模型无法无缝地在边缘上执行。在本文中，我们开发了一个端到端的代码生成器，使用MicroTVM将预训练模型解析为后端的C源代码库，MicroTVM是一种机器学习编译器框架扩展，用于处理裸机设备上的推断。分析表明，特定的计算密集型运算符可以轻松地通过通用模块加速器（UMA）接口卸载到专用加速器上，而其他运算符则在CPU核心中处理。通过使用自动生成的Ahead-of-Time C运行时，在ARM Cortex M4F核心上进行手势识别实验。",
    "tldr": "本文介绍了使用MicroTVM在边缘设备上部署机器学习模型的方法，可以将预训练模型解析为后端的C源代码库，并使用自动生成的Ahead-of-Time C运行时在ARM Cortex M4F核心上进行手势识别实验。",
    "en_tdlr": "This paper introduces a method for deploying machine learning models on edge devices using MicroTVM. The pre-trained model is parsed into C source libraries for the backend and an automatically generated Ahead-of-Time C runtime is used for hand gesture recognition experiments on an ARM Cortex M4F core."
}