{
    "title": "Generating Adversarial Examples with Better Transferability via Masking Unimportant Parameters of Surrogate Model. (arXiv:2304.06908v1 [cs.LG])",
    "abstract": "Deep neural networks (DNNs) have been shown to be vulnerable to adversarial examples. Moreover, the transferability of the adversarial examples has received broad attention in recent years, which means that adversarial examples crafted by a surrogate model can also attack unknown models. This phenomenon gave birth to the transfer-based adversarial attacks, which aim to improve the transferability of the generated adversarial examples. In this paper, we propose to improve the transferability of adversarial examples in the transfer-based attack via masking unimportant parameters (MUP). The key idea in MUP is to refine the pretrained surrogate models to boost the transfer-based attack. Based on this idea, a Taylor expansion-based metric is used to evaluate the parameter importance score and the unimportant parameters are masked during the generation of adversarial examples. This process is simple, yet can be naturally combined with various existing gradient-based optimizers for generating",
    "link": "http://arxiv.org/abs/2304.06908",
    "context": "Title: Generating Adversarial Examples with Better Transferability via Masking Unimportant Parameters of Surrogate Model. (arXiv:2304.06908v1 [cs.LG])\nAbstract: Deep neural networks (DNNs) have been shown to be vulnerable to adversarial examples. Moreover, the transferability of the adversarial examples has received broad attention in recent years, which means that adversarial examples crafted by a surrogate model can also attack unknown models. This phenomenon gave birth to the transfer-based adversarial attacks, which aim to improve the transferability of the generated adversarial examples. In this paper, we propose to improve the transferability of adversarial examples in the transfer-based attack via masking unimportant parameters (MUP). The key idea in MUP is to refine the pretrained surrogate models to boost the transfer-based attack. Based on this idea, a Taylor expansion-based metric is used to evaluate the parameter importance score and the unimportant parameters are masked during the generation of adversarial examples. This process is simple, yet can be naturally combined with various existing gradient-based optimizers for generating",
    "path": "papers/23/04/2304.06908.json",
    "total_tokens": 944,
    "translated_title": "通过掩盖无关参数，生成更具可转移性的对抗样本",
    "translated_abstract": "深度神经网络（DNN）已被证明容易受到对抗性样本的攻击。在近年来，对抗性样本的可转移性也受到广泛关注，这意味着由代理模型生成的对抗性样本也可以攻击未知模型。这一现象产生了基于转移的对抗攻击，旨在提高生成的对抗性样本的转移能力。本文提出了一种掩盖无关参数（MUP）的方法，以提高基于转移攻击的对抗性样本的转移性。MUP的关键思想是通过改进预训练的代理模型来提高基于转移攻击的攻击。基于该思想，使用基于泰勒展开的度量方法评估参数重要性得分，并在生成对抗样本时掩盖无关重要的参数。这个过程简单易行，可以自然地与各种现有的基于梯度的优化器结合使用，以生成对抗性的样本。实验结果表明，我们的MUP方法在各种目标模型上获得了更高的攻击成功率，并增加了对抗性样本的转移能力。",
    "tldr": "本文提出的MUP方法通过掩盖无关参数的方式，从而生成更具可转移性的对抗性样本，提高了攻击成功率和样本的转移能力。",
    "en_tdlr": "The MUP approach proposed in this paper generates more transferable adversarial examples by masking unimportant parameters, which increases the attack success rate and transferability of the generated samples."
}