{
    "title": "Boosted Prompt Ensembles for Large Language Models. (arXiv:2304.05970v1 [cs.CL])",
    "abstract": "Methods such as chain-of-thought prompting and self-consistency have pushed the frontier of language model reasoning performance with no additional training. To further improve performance, we propose a prompt ensembling method for large language models, which uses a small dataset to construct a set of few shot prompts that together comprise a ``boosted prompt ensemble''. The few shot examples for each prompt are chosen in a stepwise fashion to be ``hard'' examples on which the previous step's ensemble is uncertain. We show that this outperforms single-prompt output-space ensembles and bagged prompt-space ensembles on the GSM8k and AQuA datasets, among others. We propose both train-time and test-time versions of boosted prompting that use different levels of available annotation and conduct a detailed empirical study of our algorithm.",
    "link": "http://arxiv.org/abs/2304.05970",
    "context": "Title: Boosted Prompt Ensembles for Large Language Models. (arXiv:2304.05970v1 [cs.CL])\nAbstract: Methods such as chain-of-thought prompting and self-consistency have pushed the frontier of language model reasoning performance with no additional training. To further improve performance, we propose a prompt ensembling method for large language models, which uses a small dataset to construct a set of few shot prompts that together comprise a ``boosted prompt ensemble''. The few shot examples for each prompt are chosen in a stepwise fashion to be ``hard'' examples on which the previous step's ensemble is uncertain. We show that this outperforms single-prompt output-space ensembles and bagged prompt-space ensembles on the GSM8k and AQuA datasets, among others. We propose both train-time and test-time versions of boosted prompting that use different levels of available annotation and conduct a detailed empirical study of our algorithm.",
    "path": "papers/23/04/2304.05970.json",
    "total_tokens": 784,
    "translated_title": "大型语言模型的增强提示集成",
    "translated_abstract": "链式思维提示和自一致性等方法已经推动了语言模型推理性能的前沿，而且没有额外的训练。为了进一步提高性能，我们建议为大型语言模型提供一种提示集成方法，该方法使用小型数据集来构建一组少量的提示，这些提示共同构成了一个“增强的提示集成”。每个提示的少数样例是通过渐进式方式选择的，以便在上一个步骤的集成结果不确定时成为“困难”样例。我们证明这种方法在GSM8k和AQuA数据集等方面优于单提示输出空间集成和袋装提示空间集成。我们提出了训练时间和测试时间版本的增强提示，并使用不同级别的可用注释进行了详细的实证研究。",
    "tldr": "本文提出了一种增强提示集成方法，可以使用小型数据集构建集成提示提高大型语言模型的性能，优于单提示输出空间集成和袋装提示空间集成。",
    "en_tdlr": "The paper proposes an enhanced prompt ensembling method using a small dataset to construct a set of few shot prompts for large language models, outperforms single-prompt output-space ensembles and bagged prompt-space ensembles, and conducts a detailed empirical study of the algorithm."
}