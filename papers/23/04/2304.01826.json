{
    "title": "CGDTest: A Constrained Gradient Descent Algorithm for Testing Neural Networks. (arXiv:2304.01826v1 [cs.LG])",
    "abstract": "In this paper, we propose a new Deep Neural Network (DNN) testing algorithm called the Constrained Gradient Descent (CGD) method, and an implementation we call CGDTest aimed at exposing security and robustness issues such as adversarial robustness and bias in DNNs. Our CGD algorithm is a gradient-descent (GD) method, with the twist that the user can also specify logical properties that characterize the kinds of inputs that the user may want. This functionality sets CGDTest apart from other similar DNN testing tools since it allows users to specify logical constraints to test DNNs not only for $\\ell_p$ ball-based adversarial robustness but, more importantly, includes richer properties such as disguised and flow adversarial constraints, as well as adversarial robustness in the NLP domain. We showcase the utility and power of CGDTest via extensive experimentation in the context of vision and NLP domains, comparing against 32 state-of-the-art methods over these diverse domains. Our results",
    "link": "http://arxiv.org/abs/2304.01826",
    "context": "Title: CGDTest: A Constrained Gradient Descent Algorithm for Testing Neural Networks. (arXiv:2304.01826v1 [cs.LG])\nAbstract: In this paper, we propose a new Deep Neural Network (DNN) testing algorithm called the Constrained Gradient Descent (CGD) method, and an implementation we call CGDTest aimed at exposing security and robustness issues such as adversarial robustness and bias in DNNs. Our CGD algorithm is a gradient-descent (GD) method, with the twist that the user can also specify logical properties that characterize the kinds of inputs that the user may want. This functionality sets CGDTest apart from other similar DNN testing tools since it allows users to specify logical constraints to test DNNs not only for $\\ell_p$ ball-based adversarial robustness but, more importantly, includes richer properties such as disguised and flow adversarial constraints, as well as adversarial robustness in the NLP domain. We showcase the utility and power of CGDTest via extensive experimentation in the context of vision and NLP domains, comparing against 32 state-of-the-art methods over these diverse domains. Our results",
    "path": "papers/23/04/2304.01826.json",
    "total_tokens": 978,
    "tldr": "本文提出了一种约束梯度下降(CGD)算法，用于测试神经网络的安全性和鲁棒性问题，可以测试更丰富的属性，如伪装和流动的对抗约束，以及NLP领域的对抗鲁棒性。"
}