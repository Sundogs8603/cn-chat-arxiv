{
    "title": "WizardLM: Empowering Large Language Models to Follow Complex Instructions. (arXiv:2304.12244v2 [cs.CL] UPDATED)",
    "abstract": "Training large language models (LLMs) with open-domain instruction following data brings colossal success. However, manually creating such instruction data is very time-consuming and labor-intensive. Moreover, humans may struggle to produce high-complexity instructions. In this paper, we show an avenue for creating large amounts of instruction data with varying levels of complexity using LLM instead of humans. Starting with an initial set of instructions, we use our proposed Evol-Instruct to rewrite them step by step into more complex instructions. Then, we mix all generated instruction data to fine-tune LLaMA. We call the resulting model WizardLM. Human evaluations on a complexity-balanced test bed and Vicuna's testset show that instructions from Evol-Instruct are superior to human-created ones. By analyzing the human evaluation results of the high complexity part, we demonstrate that outputs from our WizardLM are preferred to outputs from OpenAI ChatGPT. In GPT-4 automatic evaluation",
    "link": "http://arxiv.org/abs/2304.12244",
    "context": "Title: WizardLM: Empowering Large Language Models to Follow Complex Instructions. (arXiv:2304.12244v2 [cs.CL] UPDATED)\nAbstract: Training large language models (LLMs) with open-domain instruction following data brings colossal success. However, manually creating such instruction data is very time-consuming and labor-intensive. Moreover, humans may struggle to produce high-complexity instructions. In this paper, we show an avenue for creating large amounts of instruction data with varying levels of complexity using LLM instead of humans. Starting with an initial set of instructions, we use our proposed Evol-Instruct to rewrite them step by step into more complex instructions. Then, we mix all generated instruction data to fine-tune LLaMA. We call the resulting model WizardLM. Human evaluations on a complexity-balanced test bed and Vicuna's testset show that instructions from Evol-Instruct are superior to human-created ones. By analyzing the human evaluation results of the high complexity part, we demonstrate that outputs from our WizardLM are preferred to outputs from OpenAI ChatGPT. In GPT-4 automatic evaluation",
    "path": "papers/23/04/2304.12244.json",
    "total_tokens": 929,
    "translated_title": "WizardLM: 增强大型语言模型遵循复杂指令的能力",
    "translated_abstract": "使用开放域指令追踪数据对大型语言模型进行训练带来了巨大的成功。然而，手动创建这样的指令数据非常耗时和劳动密集，且人类可能难以生成高复杂度指令。在本文中，我们展示了使用LLM而不是人类创建大量不同复杂度指令数据的途径。我们从一组初始指令开始，使用我们提出的Evol-Instruct逐步将其重新编写为更复杂的指令。然后，将所有生成的指令数据混合以微调LLaMA。我们称结果模型为WizardLM。针对一个复杂度平衡的测试集和Vicuna的测试集进行的人类评估表明，Evol-Instruct生成的指令优于人工创建的指令。通过分析高复杂性部分的人类评估结果，我们证明了从我们的WizardLM生成的输出比从OpenAI ChatGPT生成的输出更受欢迎。在GPT-4自动评估中，WizardLM产生了最好的结果。",
    "tldr": "本文使用 Evol-Instruct 方法创建了大量不同复杂度的指令数据用于微调 LLaMA 模型，得到了新模型 WizardLM。人类评估结果表明 Evol-Instruct 生成的指令优于人工创建的，而 WizardLM 输出的结果也比 OpenAI ChatGPT 更受欢迎。",
    "en_tdlr": "This paper proposes a method called Evol-Instruct to create a large amount of instruction data with varying levels of complexity for fine-tuning the LLaMA model. The resulting model is called WizardLM and outperforms OpenAI ChatGPT in human evaluation."
}