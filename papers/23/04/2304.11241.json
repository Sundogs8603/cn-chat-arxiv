{
    "title": "AutoNeRF: Training Implicit Scene Representations with Autonomous Agents. (arXiv:2304.11241v1 [cs.CV])",
    "abstract": "Implicit representations such as Neural Radiance Fields (NeRF) have been shown to be very effective at novel view synthesis. However, these models typically require manual and careful human data collection for training. In this paper, we present AutoNeRF, a method to collect data required to train NeRFs using autonomous embodied agents. Our method allows an agent to explore an unseen environment efficiently and use the experience to build an implicit map representation autonomously. We compare the impact of different exploration strategies including handcrafted frontier-based exploration and modular approaches composed of trained high-level planners and classical low-level path followers. We train these models with different reward functions tailored to this problem and evaluate the quality of the learned representations on four different downstream tasks: classical viewpoint rendering, map reconstruction, planning, and pose refinement. Empirical results show that NeRFs can be trained ",
    "link": "http://arxiv.org/abs/2304.11241",
    "context": "Title: AutoNeRF: Training Implicit Scene Representations with Autonomous Agents. (arXiv:2304.11241v1 [cs.CV])\nAbstract: Implicit representations such as Neural Radiance Fields (NeRF) have been shown to be very effective at novel view synthesis. However, these models typically require manual and careful human data collection for training. In this paper, we present AutoNeRF, a method to collect data required to train NeRFs using autonomous embodied agents. Our method allows an agent to explore an unseen environment efficiently and use the experience to build an implicit map representation autonomously. We compare the impact of different exploration strategies including handcrafted frontier-based exploration and modular approaches composed of trained high-level planners and classical low-level path followers. We train these models with different reward functions tailored to this problem and evaluate the quality of the learned representations on four different downstream tasks: classical viewpoint rendering, map reconstruction, planning, and pose refinement. Empirical results show that NeRFs can be trained ",
    "path": "papers/23/04/2304.11241.json",
    "total_tokens": 833,
    "translated_title": "AutoNeRF: 自主代理训练隐式场景表示",
    "translated_abstract": "隐式表示，如神经辐射场（NeRF），已被证明在新视角综合方面非常有效。然而，这些模型通常需要人工收集数据并进行细致的处理。在本文中，我们提出了AutoNeRF，这是一种使用自主体代理收集训练NeRF所需数据的方法。我们的方法允许代理有效地探索未知环境并使用经验自主地构建相应的隐式地图表示。我们比较了不同的探索策略，包括手工设计的基于前沿的探索和由经过训练的高级规划器和经典的低级路径追踪器组成的模块化方法的影响。我们使用针对这个问题量身定制的不同奖励函数来训练这些模型，并在四个不同的下游任务上评估学习表示的质量：经典视角渲染、地图重建、规划和姿态微调。实证结果表明，使用自主代理AutoNeRF可以成功地训练NeRF。",
    "tldr": "本文提出了AutoNeRF方法，使用自主体代理收集训练NeRF所需数据，训练NeRF成功。",
    "en_tdlr": "This paper proposes the AutoNeRF method which uses autonomous agents to collect data required to train NeRFs successfully."
}