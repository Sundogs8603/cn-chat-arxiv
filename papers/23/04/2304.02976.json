{
    "title": "Unconstrained Parametrization of Dissipative and Contracting Neural Ordinary Differential Equations. (arXiv:2304.02976v1 [eess.SY])",
    "abstract": "In this work, we introduce and study a class of Deep Neural Networks (DNNs) in continuous-time. The proposed architecture stems from the combination of Neural Ordinary Differential Equations (Neural ODEs) with the model structure of recently introduced Recurrent Equilibrium Networks (RENs). We show how to endow our proposed NodeRENs with contractivity and dissipativity -- crucial properties for robust learning and control. Most importantly, as for RENs, we derive parametrizations of contractive and dissipative NodeRENs which are unconstrained, hence enabling their learning for a large number of parameters. We validate the properties of NodeRENs, including the possibility of handling irregularly sampled data, in a case study in nonlinear system identification.",
    "link": "http://arxiv.org/abs/2304.02976",
    "context": "Title: Unconstrained Parametrization of Dissipative and Contracting Neural Ordinary Differential Equations. (arXiv:2304.02976v1 [eess.SY])\nAbstract: In this work, we introduce and study a class of Deep Neural Networks (DNNs) in continuous-time. The proposed architecture stems from the combination of Neural Ordinary Differential Equations (Neural ODEs) with the model structure of recently introduced Recurrent Equilibrium Networks (RENs). We show how to endow our proposed NodeRENs with contractivity and dissipativity -- crucial properties for robust learning and control. Most importantly, as for RENs, we derive parametrizations of contractive and dissipative NodeRENs which are unconstrained, hence enabling their learning for a large number of parameters. We validate the properties of NodeRENs, including the possibility of handling irregularly sampled data, in a case study in nonlinear system identification.",
    "path": "papers/23/04/2304.02976.json",
    "total_tokens": 824,
    "translated_title": "无约束参数化的耗散性和收缩性神经常微分方程",
    "translated_abstract": "本文介绍和研究了一类连续时间的深度神经网络，提出的架构源于神经常微分方程和最近引入的循环平衡网络（RENs）的模型结构相结合。我们展示了如何赋予我们提出的NodeRENs收缩和耗散性——对于健壮的学习和控制至关重要的属性。最重要的是，与RENs一样，我们推导了收缩和耗散NodeRENs的参数化，这些参数没有约束，因此能够学习大量的参数。我们在非线性系统识别的案例研究中验证了NodeRENs的属性，包括处理不规则采样数据的可能性。",
    "tldr": "本文介绍了一种连续时间的深度神经网络，通过结合神经常微分方程和循环平衡网络的结构，使得网络具有收缩和耗散性质。此外提出的非约束参数化方法使得该网络学习的参数量得以增加。",
    "en_tdlr": "This paper proposes a continuous-time deep neural network architecture that combines neural ordinary differential equations with the structure of recurrent equilibrium networks to enable the network to have contractive and dissipative properties, and the unconstrained parametrization allows for learning a large number of parameters. The properties of this approach are validated in a case study on nonlinear system identification, including the ability to handle irregularly sampled data."
}