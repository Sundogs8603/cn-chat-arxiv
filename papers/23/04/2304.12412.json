{
    "title": "End-to-End Lidar-Camera Self-Calibration for Autonomous Vehicles. (arXiv:2304.12412v1 [cs.CV])",
    "abstract": "Autonomous vehicles are equipped with a multi-modal sensor setup to enable the car to drive safely. The initial calibration of such perception sensors is a highly matured topic and is routinely done in an automated factory environment. However, an intriguing question arises on how to maintain the calibration quality throughout the vehicle's operating duration. Another challenge is to calibrate multiple sensors jointly to ensure no propagation of systemic errors. In this paper, we propose CaLiCa, an end-to-end deep self-calibration network which addresses the automatic calibration problem for pinhole camera and Lidar. We jointly predict the camera intrinsic parameters (focal length and distortion) as well as Lidar-Camera extrinsic parameters (rotation and translation), by regressing feature correlation between the camera image and the Lidar point cloud. The network is arranged in a Siamese-twin structure to constrain the network features learning to a mutually shared feature in both poi",
    "link": "http://arxiv.org/abs/2304.12412",
    "context": "Title: End-to-End Lidar-Camera Self-Calibration for Autonomous Vehicles. (arXiv:2304.12412v1 [cs.CV])\nAbstract: Autonomous vehicles are equipped with a multi-modal sensor setup to enable the car to drive safely. The initial calibration of such perception sensors is a highly matured topic and is routinely done in an automated factory environment. However, an intriguing question arises on how to maintain the calibration quality throughout the vehicle's operating duration. Another challenge is to calibrate multiple sensors jointly to ensure no propagation of systemic errors. In this paper, we propose CaLiCa, an end-to-end deep self-calibration network which addresses the automatic calibration problem for pinhole camera and Lidar. We jointly predict the camera intrinsic parameters (focal length and distortion) as well as Lidar-Camera extrinsic parameters (rotation and translation), by regressing feature correlation between the camera image and the Lidar point cloud. The network is arranged in a Siamese-twin structure to constrain the network features learning to a mutually shared feature in both poi",
    "path": "papers/23/04/2304.12412.json",
    "total_tokens": 925,
    "translated_title": "用于自动驾驶车辆的激光雷达-相机端到端自标定",
    "translated_abstract": "自动驾驶车辆配备了多模式感知传感器，以确保汽车安全行驶。但是如何在汽车运行期间保持传感器的校准质量成为一个有趣的问题，同时如何联合校准多个传感器以确保系统误差不会传播也是一个挑战。本文提出一种名为CaLiCa的端到端深度自标定网络，针对针孔相机和激光雷达的自动校准问题做出了改进。我们通过回归相机图像和激光点云之间的特征相关性，联合预测相机固有参数(焦距和畸变)以及激光雷达-相机外参参数(旋转和平移)。网络采用孪生结构安排以将网络特征学习约束在点云和相机图像领域的共享特征上。",
    "tldr": "本文提出了一种名为CaLiCa的端到端深度自标定网络，用于联合自动校准针孔相机和激光雷达的固有和外参参数以确保车辆多模式感知传感器的校准质量，同时采用孪生结构以达到领域共享特征的目的。",
    "en_tdlr": "The paper proposes an end-to-end deep self-calibration network named CaLiCa, which jointly predicts the intrinsic and extrinsic parameters of pinhole camera and Lidar for automatic calibration to maintain the calibration quality of multi-modal perception sensors in autonomous vehicles. The network is arranged in a Siamese-twin structure to achieve domain-shared feature learning."
}