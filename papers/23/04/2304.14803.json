{
    "title": "SemEval-2023 Task 11: Learning With Disagreements (LeWiDi). (arXiv:2304.14803v1 [cs.CL])",
    "abstract": "NLP datasets annotated with human judgments are rife with disagreements between the judges. This is especially true for tasks depending on subjective judgments such as sentiment analysis or offensive language detection. Particularly in these latter cases, the NLP community has come to realize that the approach of 'reconciling' these different subjective interpretations is inappropriate. Many NLP researchers have therefore concluded that rather than eliminating disagreements from annotated corpora, we should preserve them-indeed, some argue that corpora should aim to preserve all annotator judgments. But this approach to corpus creation for NLP has not yet been widely accepted. The objective of the LeWiDi series of shared tasks is to promote this approach to developing NLP models by providing a unified framework for training and evaluating with such datasets. We report on the second LeWiDi shared task, which differs from the first edition in three crucial respects: (i) it focuses entire",
    "link": "http://arxiv.org/abs/2304.14803",
    "context": "Title: SemEval-2023 Task 11: Learning With Disagreements (LeWiDi). (arXiv:2304.14803v1 [cs.CL])\nAbstract: NLP datasets annotated with human judgments are rife with disagreements between the judges. This is especially true for tasks depending on subjective judgments such as sentiment analysis or offensive language detection. Particularly in these latter cases, the NLP community has come to realize that the approach of 'reconciling' these different subjective interpretations is inappropriate. Many NLP researchers have therefore concluded that rather than eliminating disagreements from annotated corpora, we should preserve them-indeed, some argue that corpora should aim to preserve all annotator judgments. But this approach to corpus creation for NLP has not yet been widely accepted. The objective of the LeWiDi series of shared tasks is to promote this approach to developing NLP models by providing a unified framework for training and evaluating with such datasets. We report on the second LeWiDi shared task, which differs from the first edition in three crucial respects: (i) it focuses entire",
    "path": "papers/23/04/2304.14803.json",
    "total_tokens": 791,
    "translated_title": "SemEval-2023任务11：学习与分歧（LeWiDi）",
    "translated_abstract": "使用人类判断注释数据的自然语言处理(NLP)数据集之间经常存在着评分者的不同意见，特别是对于依赖主观判断的任务，如情感分析或冒犯性语言检测。针对这些情况，NLP社区已经意识到\"调和\"这些不同的主观解释的方法是不合适的。许多NLP研究人员因此得出结论，对于注释的语料库，我们应该保留它们之间的分歧。LeWiDi系列共享任务的目的是为了通过提供统一的训练和评估框架来促进这种NLP模型开发方法。我们报告第二个LeWiDi共享任务，与第一个版本有三个关键的不同之处。",
    "tldr": "该论文提出利用NLP数据集中评分者的不同意见来培养和评估NLP模型的方法，通过统一的框架来促进这种方法。",
    "en_tdlr": "This paper proposes an approach to training and evaluating NLP models by utilizing disagreements between annotators in NLP datasets, promoting this method through a unified framework in the LeWiDi shared tasks."
}