{
    "title": "Online Learning with Adversaries: A Differential Inclusion Analysis. (arXiv:2304.01525v1 [cs.LG])",
    "abstract": "We consider the measurement model $Y = AX,$ where $X$ and, hence, $Y$ are random variables and $A$ is an a priori known tall matrix. At each time instance, a sample of one of $Y$'s coordinates is available, and the goal is to estimate $\\mu := \\mathbb{E}[X]$ via these samples. However, the challenge is that a small but unknown subset of $Y$'s coordinates are controlled by adversaries with infinite power: they can return any real number each time they are queried for a sample. For such an adversarial setting, we propose the first asynchronous online algorithm that converges to $\\mu$ almost surely. We prove this result using a novel differential inclusion based two-timescale analysis. Two key highlights of our proof include: (a) the use of a novel Lyapunov function for showing that $\\mu$ is the unique global attractor for our algorithm's limiting dynamics, and (b) the use of martingale and stopping time theory to show that our algorithm's iterates are almost surely bounded.",
    "link": "http://arxiv.org/abs/2304.01525",
    "context": "Title: Online Learning with Adversaries: A Differential Inclusion Analysis. (arXiv:2304.01525v1 [cs.LG])\nAbstract: We consider the measurement model $Y = AX,$ where $X$ and, hence, $Y$ are random variables and $A$ is an a priori known tall matrix. At each time instance, a sample of one of $Y$'s coordinates is available, and the goal is to estimate $\\mu := \\mathbb{E}[X]$ via these samples. However, the challenge is that a small but unknown subset of $Y$'s coordinates are controlled by adversaries with infinite power: they can return any real number each time they are queried for a sample. For such an adversarial setting, we propose the first asynchronous online algorithm that converges to $\\mu$ almost surely. We prove this result using a novel differential inclusion based two-timescale analysis. Two key highlights of our proof include: (a) the use of a novel Lyapunov function for showing that $\\mu$ is the unique global attractor for our algorithm's limiting dynamics, and (b) the use of martingale and stopping time theory to show that our algorithm's iterates are almost surely bounded.",
    "path": "papers/23/04/2304.01525.json",
    "total_tokens": 931,
    "translated_title": "带对手的在线学习：微分包容分析",
    "translated_abstract": "我们考虑测量模型 $Y = AX$，其中 $X$ 和 $Y$ 是随机变量，$A$ 是先验已知的高矩阵。在每个时间实例，可以获得 $Y$ 的一个坐标的样本，并且目标是通过这些样本估计 $\\mu := \\mathbb{E}[X]$。然而，挑战在于：小但未知的 $Y$ 的坐标子集由对手控制，并具有无限的能力：每次查询样本时，他们可以返回任何实数。对于这种对抗性环境，我们提出了第一个能够以几乎确定的方式收敛到 $\\mu$ 的异步在线算法。我们使用一种新颖的微分包容基于两个时间尺度的分析来证明这个结果。我们证明的两个关键亮点包括：(a) 使用一种新颖的 Lyapunov 函数来证明 $\\mu$ 是我们算法极限动态的唯一全局吸引子，(b) 使用鞅和停时理论来证明我们算法的迭代几乎必定有界。",
    "tldr": "本文提出了第一个能够以几乎确定的方式收敛到 $\\mu$ 的异步在线算法，应用了微分包容分析，并提供了两个关键亮点。",
    "en_tdlr": "The paper proposes the first asynchronous online algorithm that can converge to $\\mu$ almost surely in an adversarial setting, and applies novel differential inclusion analysis with two-timescale. The paper provides two key highlights, including use of a novel Lyapunov function and martingale and stopping time theory."
}