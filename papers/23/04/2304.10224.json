{
    "title": "Multi-view Vision-Prompt Fusion Network: Can 2D Pre-trained Model Boost 3D Point Cloud Data-scarce Learning?. (arXiv:2304.10224v1 [cs.CV])",
    "abstract": "Point cloud based 3D deep model has wide applications in many applications such as autonomous driving, house robot, and so on. Inspired by the recent prompt learning in natural language processing, this work proposes a novel Multi-view Vision-Prompt Fusion Network (MvNet) for few-shot 3D point cloud classification. MvNet investigates the possibility of leveraging the off-the-shelf 2D pre-trained models to achieve the few-shot classification, which can alleviate the over-dependence issue of the existing baseline models towards the large-scale annotated 3D point cloud data. Specifically, MvNet first encodes a 3D point cloud into multi-view image features for a number of different views. Then, a novel multi-view prompt fusion module is developed to effectively fuse information from different views to bridge the gap between 3D point cloud data and 2D pre-trained models. A set of 2D image prompts can then be derived to better describe the suitable prior knowledge for a large-scale pre-train",
    "link": "http://arxiv.org/abs/2304.10224",
    "context": "Title: Multi-view Vision-Prompt Fusion Network: Can 2D Pre-trained Model Boost 3D Point Cloud Data-scarce Learning?. (arXiv:2304.10224v1 [cs.CV])\nAbstract: Point cloud based 3D deep model has wide applications in many applications such as autonomous driving, house robot, and so on. Inspired by the recent prompt learning in natural language processing, this work proposes a novel Multi-view Vision-Prompt Fusion Network (MvNet) for few-shot 3D point cloud classification. MvNet investigates the possibility of leveraging the off-the-shelf 2D pre-trained models to achieve the few-shot classification, which can alleviate the over-dependence issue of the existing baseline models towards the large-scale annotated 3D point cloud data. Specifically, MvNet first encodes a 3D point cloud into multi-view image features for a number of different views. Then, a novel multi-view prompt fusion module is developed to effectively fuse information from different views to bridge the gap between 3D point cloud data and 2D pre-trained models. A set of 2D image prompts can then be derived to better describe the suitable prior knowledge for a large-scale pre-train",
    "path": "papers/23/04/2304.10224.json",
    "total_tokens": 1010,
    "translated_title": "多视图视觉提示融合网络：2D预训练模型能否增强3D点云数据稀缺学习？",
    "translated_abstract": "基于点云的3D深度模型在许多领域中具有广泛的应用，例如自动驾驶、家庭机器人等。本文提出了一种新颖的多视图视觉提示融合网络（MvNet），用于少样本3D点云分类，灵感源自于最近在自然语言处理中的提示性学习。MvNet 探讨了利用现有2D预训练模型实现少样本分类的可能性，这可以缓解现有基线模型对大规模注释3D点云数据的过度依赖问题。具体而言，MvNet首先将3D点云编码成多视图图像特征，然后开发了一种新的多视图提示融合模块，以有效地融合来自不同视角的信息，以弥合3D点云数据和2D预训练模型之间的差距。然后可以派生一组2D图像提示以更好地描述适当的先验知识以进行大规模预训练。",
    "tldr": "本文提出了一种针对3D点云分类的少样本学习网络MvNet，它能够利用现有的2D预训练模型来缓解现有基线模型对大规模注释3D点云数据的过度依赖问题。",
    "en_tdlr": "This paper proposes a multi-view vision-prompt fusion network (MvNet) for few-shot 3D point cloud classification, which leverages off-the-shelf 2D pre-trained models to alleviate the over-dependence issue of baseline models on large-scale annotated 3D point cloud data. MvNet encodes a 3D point cloud into multi-view image features and develops a novel multi-view prompt fusion module to bridge the gap between 3D point cloud data and 2D pre-trained models."
}