{
    "title": "ImageCaptioner$^2$: Image Captioner for Image Captioning Bias Amplification Assessment. (arXiv:2304.04874v1 [cs.CV])",
    "abstract": "Most pre-trained learning systems are known to suffer from bias, which typically emerges from the data, the model, or both. Measuring and quantifying bias and its sources is a challenging task and has been extensively studied in image captioning. Despite the significant effort in this direction, we observed that existing metrics lack consistency in the inclusion of the visual signal. In this paper, we introduce a new bias assessment metric, dubbed $ImageCaptioner^2$, for image captioning. Instead of measuring the absolute bias in the model or the data, $ImageCaptioner^2$ pay more attention to the bias introduced by the model w.r.t the data bias, termed bias amplification. Unlike the existing methods, which only evaluate the image captioning algorithms based on the generated captions only, $ImageCaptioner^2$ incorporates the image while measuring the bias. In addition, we design a formulation for measuring the bias of generated captions as prompt-based image captioning instead of using ",
    "link": "http://arxiv.org/abs/2304.04874",
    "context": "Title: ImageCaptioner$^2$: Image Captioner for Image Captioning Bias Amplification Assessment. (arXiv:2304.04874v1 [cs.CV])\nAbstract: Most pre-trained learning systems are known to suffer from bias, which typically emerges from the data, the model, or both. Measuring and quantifying bias and its sources is a challenging task and has been extensively studied in image captioning. Despite the significant effort in this direction, we observed that existing metrics lack consistency in the inclusion of the visual signal. In this paper, we introduce a new bias assessment metric, dubbed $ImageCaptioner^2$, for image captioning. Instead of measuring the absolute bias in the model or the data, $ImageCaptioner^2$ pay more attention to the bias introduced by the model w.r.t the data bias, termed bias amplification. Unlike the existing methods, which only evaluate the image captioning algorithms based on the generated captions only, $ImageCaptioner^2$ incorporates the image while measuring the bias. In addition, we design a formulation for measuring the bias of generated captions as prompt-based image captioning instead of using ",
    "path": "papers/23/04/2304.04874.json",
    "total_tokens": 848,
    "translated_title": "ImageCaptioner$^2$: 针对图像字幕偏差放大评估的图像字幕生成器",
    "translated_abstract": "大多数预训练学习系统都会受到偏差的影响，这通常来自数据、模型或两者。衡量和量化偏差及其来源是一项具有挑战性的任务，并在图像字幕生成方面得到了广泛的研究。然而，我们观察到现有评估指标在包括视觉信号方面存在一定不一致性。本文提出了一种新的针对图像字幕生成的偏差评估指标，称为 ImageCaptioner$^2$。与现有方法仅基于生成的字幕评估图像字幕算法不同，ImageCaptioner$^2$在测量偏差时考虑图像。我们还设计了一种公式来作为基于提示的图像字幕生成来测量生成字幕的偏差，而不是使用传统方法。",
    "tldr": "本文提出了一种新的图像字幕生成器 ImageCaptioner$^2$ ，用于针对图像字幕偏差放大进行评估。",
    "en_tdlr": "This paper proposes a new image captioner, called ImageCaptioner$^2$, for bias amplification assessment in image captioning, which incorporates the image while measuring the bias and designs a prompt-based formulation for measuring the bias of generated captions."
}