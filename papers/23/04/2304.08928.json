{
    "title": "ProGAP: Progressive Graph Neural Networks with Differential Privacy Guarantees. (arXiv:2304.08928v1 [cs.LG])",
    "abstract": "Graph Neural Networks (GNNs) have become a popular tool for learning on graphs, but their widespread use raises privacy concerns as graph data can contain personal or sensitive information. Differentially private GNN models have been recently proposed to preserve privacy while still allowing for effective learning over graph-structured datasets. However, achieving an ideal balance between accuracy and privacy in GNNs remains challenging due to the intrinsic structural connectivity of graphs. In this paper, we propose a new differentially private GNN called ProGAP that uses a progressive training scheme to improve such accuracy-privacy trade-offs. Combined with the aggregation perturbation technique to ensure differential privacy, ProGAP splits a GNN into a sequence of overlapping submodels that are trained progressively, expanding from the first submodel to the complete model. Specifically, each submodel is trained over the privately aggregated node embeddings learned and cached by the",
    "link": "http://arxiv.org/abs/2304.08928",
    "context": "Title: ProGAP: Progressive Graph Neural Networks with Differential Privacy Guarantees. (arXiv:2304.08928v1 [cs.LG])\nAbstract: Graph Neural Networks (GNNs) have become a popular tool for learning on graphs, but their widespread use raises privacy concerns as graph data can contain personal or sensitive information. Differentially private GNN models have been recently proposed to preserve privacy while still allowing for effective learning over graph-structured datasets. However, achieving an ideal balance between accuracy and privacy in GNNs remains challenging due to the intrinsic structural connectivity of graphs. In this paper, we propose a new differentially private GNN called ProGAP that uses a progressive training scheme to improve such accuracy-privacy trade-offs. Combined with the aggregation perturbation technique to ensure differential privacy, ProGAP splits a GNN into a sequence of overlapping submodels that are trained progressively, expanding from the first submodel to the complete model. Specifically, each submodel is trained over the privately aggregated node embeddings learned and cached by the",
    "path": "papers/23/04/2304.08928.json",
    "total_tokens": 914,
    "translated_title": "ProGAP: 具有差分隐私保证的渐进图神经网络",
    "translated_abstract": "图神经网络（GNN）已成为学习图形数据的常用工具，但广泛使用引发了隐私问题，因为图形数据可能包含个人或敏感信息。为了保护隐私并允许对图结构数据进行有效处理，最近提出了差分隐私GNN模型。然而，由于图的固有结构连接性，GNN在准确性和隐私之间取得平衡仍然具有挑战性。在本文中，我们提出了一种名为ProGAP的新型差分隐私GNN，采用逐步训练方案来提高准确性和隐私之间的平衡。结合聚合扰动技术以确保差分隐私，ProGAP将GNN分成一系列重叠的子模型，逐步进行训练，从第一个子模型扩展到完整模型。具体而言，每个子模型都是基于通过私有聚合学习和缓存的节点嵌入进行训练的。",
    "tldr": "ProGAP是一种新的差分隐私GNN模型，采用逐步训练方案来提高准确性和隐私之间的平衡，通过将GNN分成一系列重叠的子模型来训练。这种方法可以保护隐私并允许有效学习图形结构数据。",
    "en_tdlr": "ProGAP is a new differentially private GNN model that uses a progressive training scheme to improve the balance between accuracy and privacy by splitting the GNN into a sequence of overlapping submodels. It can protect privacy while allowing effective learning on graph-structured data."
}