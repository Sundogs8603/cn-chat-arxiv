{
    "title": "On the Independence of Association Bias and Empirical Fairness in Language Models. (arXiv:2304.10153v1 [cs.CL])",
    "abstract": "The societal impact of pre-trained language models has prompted researchers to probe them for strong associations between protected attributes and value-loaded terms, from slur to prestigious job titles. Such work is said to probe models for bias or fairness-or such probes 'into representational biases' are said to be 'motivated by fairness'-suggesting an intimate connection between bias and fairness. We provide conceptual clarity by distinguishing between association biases (Caliskan et al., 2022) and empirical fairness (Shen et al., 2022) and show the two can be independent. Our main contribution, however, is showing why this should not come as a surprise. To this end, we first provide a thought experiment, showing how association bias and empirical fairness can be completely orthogonal. Next, we provide empirical evidence that there is no correlation between bias metrics and fairness metrics across the most widely used language models. Finally, we survey the sociological and psychol",
    "link": "http://arxiv.org/abs/2304.10153",
    "context": "Title: On the Independence of Association Bias and Empirical Fairness in Language Models. (arXiv:2304.10153v1 [cs.CL])\nAbstract: The societal impact of pre-trained language models has prompted researchers to probe them for strong associations between protected attributes and value-loaded terms, from slur to prestigious job titles. Such work is said to probe models for bias or fairness-or such probes 'into representational biases' are said to be 'motivated by fairness'-suggesting an intimate connection between bias and fairness. We provide conceptual clarity by distinguishing between association biases (Caliskan et al., 2022) and empirical fairness (Shen et al., 2022) and show the two can be independent. Our main contribution, however, is showing why this should not come as a surprise. To this end, we first provide a thought experiment, showing how association bias and empirical fairness can be completely orthogonal. Next, we provide empirical evidence that there is no correlation between bias metrics and fairness metrics across the most widely used language models. Finally, we survey the sociological and psychol",
    "path": "papers/23/04/2304.10153.json",
    "total_tokens": 1086,
    "translated_title": "论语言模型中的联想偏差与实证公正的独立性",
    "translated_abstract": "预先训练的语言模型的社会影响促使研究人员探索它们之间是否存在受保护属性和价值负载术语之间的强关联，从蔑称到享有声望的职位名称等。这样的工作被认为是探索模型的偏差或公平性，或者这种探测 \"表征偏差 \"的工作被认为是 \"基于公平性的 \"——这表明了偏差和公平性之间的密切联系。我们通过区分联想偏差和实证公正来提供概念上的清晰度，并展示了两者可以是独立的。然而，我们的主要贡献在于展示了为什么这不应该让人感到惊讶。为此，我们首先提供了一个思想实验，展示了联想偏见和实证公正可以完全独立。接下来，我们提供了经验证据，表明在最广泛使用的语言模型中，偏差指标和公平指标之间不存在相关性。最后，我们调查了社会和心理学文献，勾勒出了联想偏差在语言使用中的普遍存在以及解决它们的重要性。我们最后提出呼吁，关注降低表示偏差和采用实证公正模型开发的做法。",
    "tldr": "本文探讨了预先训练的语言模型中联想偏差和实证公正的关系，通过理论实验和实证研究证明了两者可以是独立的。本文呼吁采用实证公正的模型开发方法并减少表示偏差。",
    "en_tdlr": "This paper explores the relationship between association bias and empirical fairness in pre-trained language models, and provides theoretical and empirical evidence to show that the two can be independent. The paper calls for the adoption of empirically fair practices in model development and the mitigation of representation bias."
}