{
    "title": "Probing the Purview of Neural Networks via Gradient Analysis. (arXiv:2304.02834v1 [cs.LG])",
    "abstract": "We analyze the data-dependent capacity of neural networks and assess anomalies in inputs from the perspective of networks during inference. The notion of data-dependent capacity allows for analyzing the knowledge base of a model populated by learned features from training data. We define purview as the additional capacity necessary to characterize inference samples that differ from the training data. To probe the purview of a network, we utilize gradients to measure the amount of change required for the model to characterize the given inputs more accurately. To eliminate the dependency on ground-truth labels in generating gradients, we introduce confounding labels that are formulated by combining multiple categorical labels. We demonstrate that our gradient-based approach can effectively differentiate inputs that cannot be accurately represented with learned features. We utilize our approach in applications of detecting anomalous inputs, including out-of-distribution, adversarial, and ",
    "link": "http://arxiv.org/abs/2304.02834",
    "context": "Title: Probing the Purview of Neural Networks via Gradient Analysis. (arXiv:2304.02834v1 [cs.LG])\nAbstract: We analyze the data-dependent capacity of neural networks and assess anomalies in inputs from the perspective of networks during inference. The notion of data-dependent capacity allows for analyzing the knowledge base of a model populated by learned features from training data. We define purview as the additional capacity necessary to characterize inference samples that differ from the training data. To probe the purview of a network, we utilize gradients to measure the amount of change required for the model to characterize the given inputs more accurately. To eliminate the dependency on ground-truth labels in generating gradients, we introduce confounding labels that are formulated by combining multiple categorical labels. We demonstrate that our gradient-based approach can effectively differentiate inputs that cannot be accurately represented with learned features. We utilize our approach in applications of detecting anomalous inputs, including out-of-distribution, adversarial, and ",
    "path": "papers/23/04/2304.02834.json",
    "total_tokens": 821,
    "tldr": "本论文从梯度分析角度，探究了神经网络的能力范围，用梯度方法有效区分无法精确表示的输入，具有检测异常输入的识别能力。",
    "en_tdlr": "This paper examines the data-dependent capacity of neural networks and uses gradient analysis to probe their purview, effectively identifying inputs that cannot be accurately represented with learned features, and can be used to detect anomalous inputs such as out-of-distribution and adversarial ones."
}