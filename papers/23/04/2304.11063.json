{
    "title": "Think Before You Act: Unified Policy for Interleaving Language Reasoning with Actions. (arXiv:2304.11063v1 [cs.CL])",
    "abstract": "The success of transformer models trained with a language modeling objective brings a promising opportunity to the reinforcement learning framework. Decision Transformer is a step towards this direction, showing how to train transformers with a similar next-step prediction objective on offline data. Another important development in this area is the recent emergence of large-scale datasets collected from the internet, such as the ones composed of tutorial videos with captions where people talk about what they are doing. To take advantage of this language component, we propose a novel method for unifying language reasoning with actions in a single policy. Specifically, we augment a transformer policy with word outputs, so it can generate textual captions interleaved with actions. When tested on the most challenging task in BabyAI, with captions describing next subgoals, our reasoning policy consistently outperforms the caption-free baseline.",
    "link": "http://arxiv.org/abs/2304.11063",
    "context": "Title: Think Before You Act: Unified Policy for Interleaving Language Reasoning with Actions. (arXiv:2304.11063v1 [cs.CL])\nAbstract: The success of transformer models trained with a language modeling objective brings a promising opportunity to the reinforcement learning framework. Decision Transformer is a step towards this direction, showing how to train transformers with a similar next-step prediction objective on offline data. Another important development in this area is the recent emergence of large-scale datasets collected from the internet, such as the ones composed of tutorial videos with captions where people talk about what they are doing. To take advantage of this language component, we propose a novel method for unifying language reasoning with actions in a single policy. Specifically, we augment a transformer policy with word outputs, so it can generate textual captions interleaved with actions. When tested on the most challenging task in BabyAI, with captions describing next subgoals, our reasoning policy consistently outperforms the caption-free baseline.",
    "path": "papers/23/04/2304.11063.json",
    "total_tokens": 880,
    "translated_title": "慎思之后再行动：将语言推理与动作统一的交错策略方法",
    "translated_abstract": "带有语言建模目标的 transformer 模型的成功训练为强化学习框架带来了一个有前途的机会，Decision Transformer 是朝着这个方向迈出的一步，展示了如何在离线数据上训练类似的下一步预测目标的 transformers；而这个领域的另一个重要发展是近期出现了从互联网收集而来的大规模数据集，例如由视频教程和字幕组成的数据集，其中的人们讲述他们正在做的事情。为了利用这种语言组件，我们提出了一种将语言推理和动作统一在单个策略中的新方法。具体来说，我们增加了一个带有单词输出的 transformer 策略，以便它可以生成交替使用动作的文本标题。在最具挑战性的 BabyAI 任务中测试，我们的推理策略在描述下一个子目标的标题上，始终优于没有标题的基准线。",
    "tldr": "本文提出了一种新的方法，将语言推理与动作统一在单个策略中，利用 transformer 模型，能够生成交替使用动作的文本标题。在 BabyAI 任务中测试，我们的推理策略始终优于没有标题的基准线。",
    "en_tdlr": "This paper proposes a novel method for unifying language reasoning with actions in a single policy, using transformer models to generate textual captions interleaved with actions. Tested on the BabyAI task, the proposed reasoning policy consistently outperforms the caption-free baseline."
}