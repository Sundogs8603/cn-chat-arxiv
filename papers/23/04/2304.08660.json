{
    "title": "(LC)$^2$: LiDAR-Camera Loop Constraints For Cross-Modal Place Recognition. (arXiv:2304.08660v1 [cs.RO])",
    "abstract": "Localization has been a challenging task for autonomous navigation. A loop detection algorithm must overcome environmental changes for the place recognition and re-localization of robots. Therefore, deep learning has been extensively studied for the consistent transformation of measurements into localization descriptors. Street view images are easily accessible; however, images are vulnerable to appearance changes. LiDAR can robustly provide precise structural information. However, constructing a point cloud database is expensive, and point clouds exist only in limited places. Different from previous works that train networks to produce shared embedding directly between the 2D image and 3D point cloud, we transform both data into 2.5D depth images for matching. In this work, we propose a novel cross-matching method, called (LC)$^2$, for achieving LiDAR localization without a prior point cloud map. To this end, LiDAR measurements are expressed in the form of range images before matching",
    "link": "http://arxiv.org/abs/2304.08660",
    "context": "Title: (LC)$^2$: LiDAR-Camera Loop Constraints For Cross-Modal Place Recognition. (arXiv:2304.08660v1 [cs.RO])\nAbstract: Localization has been a challenging task for autonomous navigation. A loop detection algorithm must overcome environmental changes for the place recognition and re-localization of robots. Therefore, deep learning has been extensively studied for the consistent transformation of measurements into localization descriptors. Street view images are easily accessible; however, images are vulnerable to appearance changes. LiDAR can robustly provide precise structural information. However, constructing a point cloud database is expensive, and point clouds exist only in limited places. Different from previous works that train networks to produce shared embedding directly between the 2D image and 3D point cloud, we transform both data into 2.5D depth images for matching. In this work, we propose a novel cross-matching method, called (LC)$^2$, for achieving LiDAR localization without a prior point cloud map. To this end, LiDAR measurements are expressed in the form of range images before matching",
    "path": "papers/23/04/2304.08660.json",
    "total_tokens": 850,
    "translated_title": "(LC)$^2$:基于LiDAR-Camera循环约束的跨模态地点识别算法",
    "translated_abstract": "定位一直是自主导航的一个难题，地点识别和重新定位对于机器人的实现至关重要。因此，深度学习被广泛研究用于测量数据到定位描述符的一致转换。街景图像容易获取，但容易受到外观变化的影响。LiDAR能够提供精确的结构信息，但构建点云数据库成本高，点云只在有限的地方存在。与以往的工作不同，我们将2D图像和3D点云数据转换为2.5D深度图像进行匹配，提出了一种新的跨数据匹配方法，称为(LC)$^2$，用于实现没有先验点云地图的LiDAR定位。为此，在匹配之前，将LiDAR测量表示为距离图像的形式。",
    "tldr": "提出了一种新的(LC)$^2$方法，通过将2D图像和3D点云数据转换为2.5D深度图像进行匹配，实现了没有先验点云地图的LiDAR定位。",
    "en_tdlr": "A novel cross-matching method called (LC)$^2$ is proposed for achieving LiDAR localization without a prior point cloud map by converting 2D images and 3D point cloud data into 2.5D depth images for matching."
}