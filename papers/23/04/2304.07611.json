{
    "title": "A CTC Alignment-based Non-autoregressive Transformer for End-to-end Automatic Speech Recognition. (arXiv:2304.07611v1 [cs.CL])",
    "abstract": "Recently, end-to-end models have been widely used in automatic speech recognition (ASR) systems. Two of the most representative approaches are connectionist temporal classification (CTC) and attention-based encoder-decoder (AED) models. Autoregressive transformers, variants of AED, adopt an autoregressive mechanism for token generation and thus are relatively slow during inference. In this paper, we present a comprehensive study of a CTC Alignment-based Single-Step Non-Autoregressive Transformer (CASS-NAT) for end-to-end ASR. In CASS-NAT, word embeddings in the autoregressive transformer (AT) are substituted with token-level acoustic embeddings (TAE) that are extracted from encoder outputs with the acoustical boundary information offered by the CTC alignment. TAE can be obtained in parallel, resulting in a parallel generation of output tokens. During training, Viterbi-alignment is used for TAE generation, and multiple training strategies are further explored to improve the word error r",
    "link": "http://arxiv.org/abs/2304.07611",
    "context": "Title: A CTC Alignment-based Non-autoregressive Transformer for End-to-end Automatic Speech Recognition. (arXiv:2304.07611v1 [cs.CL])\nAbstract: Recently, end-to-end models have been widely used in automatic speech recognition (ASR) systems. Two of the most representative approaches are connectionist temporal classification (CTC) and attention-based encoder-decoder (AED) models. Autoregressive transformers, variants of AED, adopt an autoregressive mechanism for token generation and thus are relatively slow during inference. In this paper, we present a comprehensive study of a CTC Alignment-based Single-Step Non-Autoregressive Transformer (CASS-NAT) for end-to-end ASR. In CASS-NAT, word embeddings in the autoregressive transformer (AT) are substituted with token-level acoustic embeddings (TAE) that are extracted from encoder outputs with the acoustical boundary information offered by the CTC alignment. TAE can be obtained in parallel, resulting in a parallel generation of output tokens. During training, Viterbi-alignment is used for TAE generation, and multiple training strategies are further explored to improve the word error r",
    "path": "papers/23/04/2304.07611.json",
    "total_tokens": 980,
    "translated_title": "基于CTC对齐的非自回归变压器用于端到端自动语音识别",
    "translated_abstract": "近年来，端到端模型已广泛应用于自动语音识别系统。其中最具代表性的两种方法是连接主义时间分类（CTC）和基于注意力的编码器-解码器（AED）模型。自回归变压器是AED的变体，采用自回归机制进行令牌生成，在推理期间相对较慢。在本文中，我们提出了一种基于CTC对齐的单步非自回归变压器（CASS-NAT）来进行端到端自动语音识别的全面研究。在CASS-NAT中，自回归变压器（AT）中的词嵌入被替换为通过CTC对齐提供的音韵边界信息从编码器输出中提取的令牌级声学嵌入（TAE）。TAE可以并行获取，从而产生并行的输出令牌。在训练期间，使用Viterbi对齐进行TAE生成，并进一步探索多种训练策略以提高单词错误率。",
    "tldr": "本文提出了一种基于CTC对齐的单步非自回归变压器（CASS-NAT），将自回归变压器中的词嵌入替换为编码器输出中提取的令牌级声学嵌入（TAE）进行端到端自动语音识别，能够并行产生输出令牌。"
}