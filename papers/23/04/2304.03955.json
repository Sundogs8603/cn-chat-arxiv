{
    "title": "Robust Deep Learning Models Against Semantic-Preserving Adversarial Attack. (arXiv:2304.03955v1 [cs.LG])",
    "abstract": "Deep learning models can be fooled by small $l_p$-norm adversarial perturbations and natural perturbations in terms of attributes. Although the robustness against each perturbation has been explored, it remains a challenge to address the robustness against joint perturbations effectively. In this paper, we study the robustness of deep learning models against joint perturbations by proposing a novel attack mechanism named Semantic-Preserving Adversarial (SPA) attack, which can then be used to enhance adversarial training. Specifically, we introduce an attribute manipulator to generate natural and human-comprehensible perturbations and a noise generator to generate diverse adversarial noises. Based on such combined noises, we optimize both the attribute value and the diversity variable to generate jointly-perturbed samples. For robust training, we adversarially train the deep learning model against the generated joint perturbations. Empirical results on four benchmarks show that the SPA ",
    "link": "http://arxiv.org/abs/2304.03955",
    "context": "Title: Robust Deep Learning Models Against Semantic-Preserving Adversarial Attack. (arXiv:2304.03955v1 [cs.LG])\nAbstract: Deep learning models can be fooled by small $l_p$-norm adversarial perturbations and natural perturbations in terms of attributes. Although the robustness against each perturbation has been explored, it remains a challenge to address the robustness against joint perturbations effectively. In this paper, we study the robustness of deep learning models against joint perturbations by proposing a novel attack mechanism named Semantic-Preserving Adversarial (SPA) attack, which can then be used to enhance adversarial training. Specifically, we introduce an attribute manipulator to generate natural and human-comprehensible perturbations and a noise generator to generate diverse adversarial noises. Based on such combined noises, we optimize both the attribute value and the diversity variable to generate jointly-perturbed samples. For robust training, we adversarially train the deep learning model against the generated joint perturbations. Empirical results on four benchmarks show that the SPA ",
    "path": "papers/23/04/2304.03955.json",
    "total_tokens": 971,
    "translated_title": "鲁棒的深度学习模型对抗语义保持攻击的研究",
    "translated_abstract": "深度学习模型很容易被小的 $l_p$-norm 对抗干扰以及自然干扰所误导。虽然对抗中对每种干扰的鲁棒性已得到探索，但有效地处理对联合干扰的鲁棒性仍是一种挑战。为此，本文提出了一种新的攻击机制，称为语义保持对抗（SPA）攻击，以研究深度学习模型对联合干扰的鲁棒性，并可用于增强对抗训练。具体而言，作者引入了属性操纵器来生成自然且易于被人理解的干扰，以及噪声生成器来生成多样化的对抗噪声。基于这些综合的干扰噪声，优化属性值和多样性变量来生成联合干扰样本。为鲁棒训练，作者对生成联合干扰的样本进行对抗性训练深度学习模型。实验结果在四个基准测试中表明，SPA攻击比其他方法更加具有挑战性。",
    "tldr": "该论文提出了一种新的攻击机制，SPA攻击，用于研究深度学习模型对联合干扰的鲁棒性，并可用于增强对抗训练。实验结果表明，SPA攻击比其他方法更加具有挑战性。",
    "en_tdlr": "This paper proposes a novel attack mechanism named Semantic-Preserving Adversarial (SPA) attack to study the robustness of deep learning models against joint perturbations and enhance adversarial training. The empirical results show that the SPA attack is more challenging than other methods."
}