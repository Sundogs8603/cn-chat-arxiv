{
    "title": "Emergent and Predictable Memorization in Large Language Models. (arXiv:2304.11158v1 [cs.CL])",
    "abstract": "Memorization, or the tendency of large language models (LLMs) to output entire sequences from their training data verbatim, is a key concern for safely deploying language models. In particular, it is vital to minimize a model's memorization of sensitive datapoints such as those containing personal identifiable information (PII). The prevalence of such undesirable memorization can pose issues for model trainers, and may even require discarding an otherwise functional model. We therefore seek to predict which sequences will be memorized before a large model's full train-time by extrapolating the memorization behavior of lower-compute trial runs. We measure memorization of the Pythia model suite, and find that intermediate checkpoints are better predictors of a model's memorization behavior than smaller fully-trained models. We additionally provide further novel discoveries on the distribution of memorization scores across models and data.",
    "link": "http://arxiv.org/abs/2304.11158",
    "context": "Title: Emergent and Predictable Memorization in Large Language Models. (arXiv:2304.11158v1 [cs.CL])\nAbstract: Memorization, or the tendency of large language models (LLMs) to output entire sequences from their training data verbatim, is a key concern for safely deploying language models. In particular, it is vital to minimize a model's memorization of sensitive datapoints such as those containing personal identifiable information (PII). The prevalence of such undesirable memorization can pose issues for model trainers, and may even require discarding an otherwise functional model. We therefore seek to predict which sequences will be memorized before a large model's full train-time by extrapolating the memorization behavior of lower-compute trial runs. We measure memorization of the Pythia model suite, and find that intermediate checkpoints are better predictors of a model's memorization behavior than smaller fully-trained models. We additionally provide further novel discoveries on the distribution of memorization scores across models and data.",
    "path": "papers/23/04/2304.11158.json",
    "total_tokens": 841,
    "translated_title": "大型语言模型中的突现和可预知性记忆",
    "translated_abstract": "记忆化是大型语言模型（LLMs）输出其训练数据完全相同序列的倾向，这是安全部署语言模型的关键问题之一。特别地，最小化模型对包含个人可识别信息（PII）等敏感数据点的记忆化是至关重要的。这种不良的记忆化的普及可能会给模型训练者带来问题，甚至可能需要丢弃否则功能良好的模型。因此，我们试图通过推断低计算力试验运行的记忆化行为来预测哪些序列将在大型模型的全局培训期间进行记忆化。我们测量了Pythia模型套件的记忆化，发现中间检查点比较小的已完全训练模型更好地预测了模型的记忆化行为。此外，我们还提供了有关模型和数据记忆化分数分布的进一步新发现。",
    "tldr": "该论文的研究发现中间检查点比完全训练的模型更好地预测模型的记忆化行为，并且发现了大型语言模型中记忆化得分的分布规律。",
    "en_tdlr": "This paper finds that intermediate checkpoints are better predictors of a model's memorization behavior than smaller fully-trained models, and discovers the distribution pattern of memorization scores in large language models."
}