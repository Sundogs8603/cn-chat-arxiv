{
    "title": "Distinguishing a planetary transit from false positives: a Transformer-based classification for planetary transit signals. (arXiv:2304.14283v1 [astro-ph.EP])",
    "abstract": "Current space-based missions, such as the Transiting Exoplanet Survey Satellite (TESS), provide a large database of light curves that must be analysed efficiently and systematically. In recent years, deep learning (DL) methods, particularly convolutional neural networks (CNN), have been used to classify transit signals of candidate exoplanets automatically. However, CNNs have some drawbacks; for example, they require many layers to capture dependencies on sequential data, such as light curves, making the network so large that it eventually becomes impractical. The self-attention mechanism is a DL technique that attempts to mimic the action of selectively focusing on some relevant things while ignoring others. Models, such as the Transformer architecture, were recently proposed for sequential data with successful results. Based on these successful models, we present a new architecture for the automatic classification of transit signals. Our proposed architecture is designed to capture t",
    "link": "http://arxiv.org/abs/2304.14283",
    "context": "Title: Distinguishing a planetary transit from false positives: a Transformer-based classification for planetary transit signals. (arXiv:2304.14283v1 [astro-ph.EP])\nAbstract: Current space-based missions, such as the Transiting Exoplanet Survey Satellite (TESS), provide a large database of light curves that must be analysed efficiently and systematically. In recent years, deep learning (DL) methods, particularly convolutional neural networks (CNN), have been used to classify transit signals of candidate exoplanets automatically. However, CNNs have some drawbacks; for example, they require many layers to capture dependencies on sequential data, such as light curves, making the network so large that it eventually becomes impractical. The self-attention mechanism is a DL technique that attempts to mimic the action of selectively focusing on some relevant things while ignoring others. Models, such as the Transformer architecture, were recently proposed for sequential data with successful results. Based on these successful models, we present a new architecture for the automatic classification of transit signals. Our proposed architecture is designed to capture t",
    "path": "papers/23/04/2304.14283.json",
    "total_tokens": 1039,
    "translated_title": "用基于Transformer的方法区分行星凌和误判的方法",
    "translated_abstract": "目前，像TESS这样的空间任务提供了大量必须高效、系统地分析的光变曲线数据库。近年来，深度学习（DL）方法，尤其是卷积神经网络（CNN），已被用于自动分类候选外行星的凌变信号。然而，CNN具有一些缺陷，例如，它们需要许多层来捕获序列数据（例如光变曲线）上的依赖关系，使得网络变得过于庞大，最终变得不实用。自注意机制是一种DL技术，试图模仿有选择地聚焦于一些相关事物而忽略其他事物的行为。最近针对序列数据的模型，例如Transformer架构，取得了成功的结果。我们基于这些成功的模型提出了一种新的用于自动分类凌变信号的架构。我们提出的架构旨在高效准确地捕捉凌变信号并将其与误判区分开来。我们采用了一种新的预处理输入数据的方法，使用正弦函数来保留信号的周期性。在模拟数据的评估中，我们的方法在准确性和效率方面优于基于CNN的现有方法。",
    "tldr": "本文介绍了基于Transformer架构的新方法，用于高效准确地区分行星凌和误判。采用一种新的预处理输入数据的方法，使用正弦函数来保留信号的周期性。在模拟数据的评估中，该方法优于已有的基于CNN的方法。",
    "en_tdlr": "This paper presents a new method based on the Transformer architecture for efficiently and accurately distinguishing planetary transit signals from false positives. A novel pre-processing approach is used to preserve signal periodicity with sinusoidal functions. Evaluation on simulated data shows that the proposed method outperforms existing CNN-based methods in terms of accuracy and efficiency."
}