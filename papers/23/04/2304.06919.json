{
    "title": "Interpretability is a Kind of Safety: An Interpreter-based Ensemble for Adversary Defense. (arXiv:2304.06919v1 [cs.LG])",
    "abstract": "While having achieved great success in rich real-life applications, deep neural network (DNN) models have long been criticized for their vulnerability to adversarial attacks. Tremendous research efforts have been dedicated to mitigating the threats of adversarial attacks, but the essential trait of adversarial examples is not yet clear, and most existing methods are yet vulnerable to hybrid attacks and suffer from counterattacks. In light of this, in this paper, we first reveal a gradient-based correlation between sensitivity analysis-based DNN interpreters and the generation process of adversarial examples, which indicates the Achilles's heel of adversarial attacks and sheds light on linking together the two long-standing challenges of DNN: fragility and unexplainability. We then propose an interpreter-based ensemble framework called X-Ensemble for robust adversary defense. X-Ensemble adopts a novel detection-rectification process and features in building multiple sub-detectors and a ",
    "link": "http://arxiv.org/abs/2304.06919",
    "context": "Title: Interpretability is a Kind of Safety: An Interpreter-based Ensemble for Adversary Defense. (arXiv:2304.06919v1 [cs.LG])\nAbstract: While having achieved great success in rich real-life applications, deep neural network (DNN) models have long been criticized for their vulnerability to adversarial attacks. Tremendous research efforts have been dedicated to mitigating the threats of adversarial attacks, but the essential trait of adversarial examples is not yet clear, and most existing methods are yet vulnerable to hybrid attacks and suffer from counterattacks. In light of this, in this paper, we first reveal a gradient-based correlation between sensitivity analysis-based DNN interpreters and the generation process of adversarial examples, which indicates the Achilles's heel of adversarial attacks and sheds light on linking together the two long-standing challenges of DNN: fragility and unexplainability. We then propose an interpreter-based ensemble framework called X-Ensemble for robust adversary defense. X-Ensemble adopts a novel detection-rectification process and features in building multiple sub-detectors and a ",
    "path": "papers/23/04/2304.06919.json",
    "total_tokens": 931,
    "translated_title": "解释性是一种安全：一种基于解释器的集成防御对抗攻击方法",
    "translated_abstract": "深度神经网络在现实应用中取得了巨大成功，然而它们对抗攻击的脆弱性一直受到批评。为了减轻对抗攻击威胁，研究人员已经做出了巨大的努力，但对抗样本的本质特征尚不清楚，大多数现有方法仍然容易受到混合攻击和反制攻击。在这篇论文中，我们首先揭示了敏感性分析型DNN解释器与对抗样本生成过程之间的梯度相关性，这表明了对抗攻击的弱点，并为将DNN的两个长期挑战——脆弱性和不可解释性联系在一起提供了思路。我们提出了一个名为X-Ensemble的基于解释器的集成框架来进行强大的防御。X-Ensemble采用了一种新颖的检测-矫正过程，并在构建多个子检测器和一个检测器集合上具有特色。",
    "tldr": "本论文揭示了解释器与对抗样本生成过程之间的相关性，提出了一种基于解释器的集成框架X-Ensemble，该框架采用了新颖的检测-矫正过程，能够进行强大的防御。"
}