{
    "title": "AdaNPC: Exploring Non-Parametric Classifier for Test-Time Adaptation. (arXiv:2304.12566v1 [cs.LG])",
    "abstract": "Many recent machine learning tasks focus to develop models that can generalize to unseen distributions. Domain generalization (DG) has become one of the key topics in various fields. Several literatures show that DG can be arbitrarily hard without exploiting target domain information. To address this issue, test-time adaptive (TTA) methods are proposed. Existing TTA methods require offline target data or extra sophisticated optimization procedures during the inference stage. In this work, we adopt Non-Parametric Classifier to perform the test-time Adaptation (AdaNPC). In particular, we construct a memory that contains the feature and label pairs from training domains. During inference, given a test instance, AdaNPC first recalls K closed samples from the memory to vote for the prediction, and then the test feature and predicted label are added to the memory. In this way, the sample distribution in the memory can be gradually changed from the training distribution towards the test distr",
    "link": "http://arxiv.org/abs/2304.12566",
    "context": "Title: AdaNPC: Exploring Non-Parametric Classifier for Test-Time Adaptation. (arXiv:2304.12566v1 [cs.LG])\nAbstract: Many recent machine learning tasks focus to develop models that can generalize to unseen distributions. Domain generalization (DG) has become one of the key topics in various fields. Several literatures show that DG can be arbitrarily hard without exploiting target domain information. To address this issue, test-time adaptive (TTA) methods are proposed. Existing TTA methods require offline target data or extra sophisticated optimization procedures during the inference stage. In this work, we adopt Non-Parametric Classifier to perform the test-time Adaptation (AdaNPC). In particular, we construct a memory that contains the feature and label pairs from training domains. During inference, given a test instance, AdaNPC first recalls K closed samples from the memory to vote for the prediction, and then the test feature and predicted label are added to the memory. In this way, the sample distribution in the memory can be gradually changed from the training distribution towards the test distr",
    "path": "papers/23/04/2304.12566.json",
    "total_tokens": 1066,
    "translated_title": "AdaNPC：探索非参数分类器进行测试时间适应性",
    "translated_abstract": "许多最近的机器学习任务都集中在开发能够推广到未见过分布的模型上。域通用性（DG）已成为各个领域中的关键课题之一。几篇文献表明，如果不利用目标域的信息，域通用性可能会变得极其困难。为了解决这个问题，提出了测试时间自适应（TTA）方法。现有的TTA方法需要离线目标数据或在推理阶段使用额外的复杂优化过程。本文采用非参数分类器进行测试时间自适应（AdaNPC）。具体地，在训练过程中构建一个包含特征和标签对的存储器。在推理时，给定一个测试实例，AdaNPC首先从存储器中回顾K个最相似的样本进行投票预测，然后将测试特征和预测标签添加到存储器中。通过这种方式，存储器中的样本分布可以逐渐从训练分布向测试分布变化，从而提高测试域的性能。我们在各种基准数据集上进行了大量实验，结果表明我们的方法优于几种最先进的TTA方法，并取得了与完全监督方法相当的性能。",
    "tldr": "本文提出了一种新的测试时间自适应（TTA）方法AdaNPC，通过利用非参数分类器进行建模从而避免了离线目标数据或在推理时使用额外的复杂优化过程。AdaNPC从存储器中回顾最相似的 K 个样本进行投票预测，逐渐改变存储器中的样本分布以提高测试域性能。",
    "en_tdlr": "This paper proposes a novel test-time adaptive method AdaNPC, which avoids using offline target data or extra sophisticated optimization procedures by utilizing a non-parametric classifier. AdaNPC recalls the K most similar samples from the memory to vote for prediction, and gradually changes the sample distribution in the memory to improve the performance in test domains."
}