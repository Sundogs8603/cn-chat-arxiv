{
    "title": "AI Model Disgorgement: Methods and Choices. (arXiv:2304.03545v1 [cs.LG])",
    "abstract": "Responsible use of data is an indispensable part of any machine learning (ML) implementation. ML developers must carefully collect and curate their datasets, and document their provenance. They must also make sure to respect intellectual property rights, preserve individual privacy, and use data in an ethical way. Over the past few years, ML models have significantly increased in size and complexity. These models require a very large amount of data and compute capacity to train, to the extent that any defects in the training corpus cannot be trivially remedied by retraining the model from scratch. Despite sophisticated controls on training data and a significant amount of effort dedicated to ensuring that training corpora are properly composed, the sheer volume of data required for the models makes it challenging to manually inspect each datum comprising a training corpus. One potential fix for training corpus data defects is model disgorgement -- the elimination of not just the improp",
    "link": "http://arxiv.org/abs/2304.03545",
    "context": "Title: AI Model Disgorgement: Methods and Choices. (arXiv:2304.03545v1 [cs.LG])\nAbstract: Responsible use of data is an indispensable part of any machine learning (ML) implementation. ML developers must carefully collect and curate their datasets, and document their provenance. They must also make sure to respect intellectual property rights, preserve individual privacy, and use data in an ethical way. Over the past few years, ML models have significantly increased in size and complexity. These models require a very large amount of data and compute capacity to train, to the extent that any defects in the training corpus cannot be trivially remedied by retraining the model from scratch. Despite sophisticated controls on training data and a significant amount of effort dedicated to ensuring that training corpora are properly composed, the sheer volume of data required for the models makes it challenging to manually inspect each datum comprising a training corpus. One potential fix for training corpus data defects is model disgorgement -- the elimination of not just the improp",
    "path": "papers/23/04/2304.03545.json",
    "total_tokens": 866,
    "translated_title": "AI模型排除：方法与选择。(arXiv：2304.03545v1 [cs.LG])",
    "translated_abstract": "数据的负责任使用是任何机器学习（ML）实现不可或缺的部分。ML开发人员必须仔细收集和策划他们的数据集，并记录它们的来源。他们还必须确保尊重知识产权，保护个人隐私，并以合法的方式使用数据。近年来，ML模型的大小和复杂性显着增加。这些模型需要大量的数据和计算能力进行训练，以至于训练语料库中的任何缺陷都不能通过从头开始重新训练模型轻松修复。尽管在训练数据上有复杂的控制，并且花费了大量的努力来确保训练语料库被正确组成，但是模型所需数据的大量使得手动检查每个数据都是具有挑战性的。解决训练语料库中数据缺陷的一个潜在方法是模型排除——不仅排除缺陷数据和样本，而将模型权重和训练代码都排除掉。",
    "tldr": "随着机器学习模型的复杂性和数据量的增加，模型错误变得更难以修复，模型排除作为一种解决方案被提出。",
    "en_tdlr": "As machine learning models increase in complexity and data volume, the difficulty of correcting errors in the model has led to the development of model disgorgement as a potential solution."
}