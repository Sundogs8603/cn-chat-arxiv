{
    "title": "TR0N: Translator Networks for 0-Shot Plug-and-Play Conditional Generation. (arXiv:2304.13742v1 [cs.LG])",
    "abstract": "We propose TR0N, a highly general framework to turn pre-trained unconditional generative models, such as GANs and VAEs, into conditional models. The conditioning can be highly arbitrary, and requires only a pre-trained auxiliary model. For example, we show how to turn unconditional models into class-conditional ones with the help of a classifier, and also into text-to-image models by leveraging CLIP. TR0N learns a lightweight stochastic mapping which \"translates\" between the space of conditions and the latent space of the generative model, in such a way that the generated latent corresponds to a data sample satisfying the desired condition. The translated latent samples are then further improved upon through Langevin dynamics, enabling us to obtain higher-quality data samples. TR0N requires no training data nor fine-tuning, yet can achieve a zero-shot FID of 10.9 on MS-COCO, outperforming competing alternatives not only on this metric, but also in sampling speed -- all while retaining ",
    "link": "http://arxiv.org/abs/2304.13742",
    "context": "Title: TR0N: Translator Networks for 0-Shot Plug-and-Play Conditional Generation. (arXiv:2304.13742v1 [cs.LG])\nAbstract: We propose TR0N, a highly general framework to turn pre-trained unconditional generative models, such as GANs and VAEs, into conditional models. The conditioning can be highly arbitrary, and requires only a pre-trained auxiliary model. For example, we show how to turn unconditional models into class-conditional ones with the help of a classifier, and also into text-to-image models by leveraging CLIP. TR0N learns a lightweight stochastic mapping which \"translates\" between the space of conditions and the latent space of the generative model, in such a way that the generated latent corresponds to a data sample satisfying the desired condition. The translated latent samples are then further improved upon through Langevin dynamics, enabling us to obtain higher-quality data samples. TR0N requires no training data nor fine-tuning, yet can achieve a zero-shot FID of 10.9 on MS-COCO, outperforming competing alternatives not only on this metric, but also in sampling speed -- all while retaining ",
    "path": "papers/23/04/2304.13742.json",
    "total_tokens": 975,
    "translated_title": "TR0N：0-Shot即插即用条件生成的翻译网络",
    "translated_abstract": "本文提出了TR0N，一个高度通用的框架，将预训练的无条件生成模型，如GAN和VAE，转换为条件模型。条件可以是高度任意的，并且仅需要预训练的辅助模型。例如，我们展示了如何使用分类器将无条件模型转化为类别条件模型，并利用CLIP将其转化为文本到图像模型。TR0N学习了一种轻量级的随机映射，该映射在条件空间和生成模型的潜在空间之间“翻译”，使得生成的潜在空间对应于满足所需条件的数据样本。然后，通过Langevin动态进一步改进翻译后的潜在样本，使我们能够获得更高质量的数据样本。TR0N不需要训练数据或微调，但可以在MS-COCO上实现零-shot FID 10.9，不仅在这个指标上优于竞品，而且在采样速度上也与其保持了多样性和质量。",
    "tldr": "本文提出了TR0N，将预训练的无条件生成模型转化为高度任意的条件模型。TR0N不需要训练数据或微调，可以在MS-COCO上实现零-shot FID 10.9，并在采样速度上优于竞品，同时保持了多样性和质量。",
    "en_tdlr": "This paper proposes TR0N, a highly general framework that converts pre-trained unconditional generative models into highly arbitrary conditional models without requiring training data or fine-tuning. TR0N achieves a zero-shot FID of 10.9 on MS-COCO and outperforms competing alternatives in sampling speed while retaining diversity and quality."
}