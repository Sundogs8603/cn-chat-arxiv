{
    "title": "Fairness in Visual Clustering: A Novel Transformer Clustering Approach. (arXiv:2304.07408v1 [cs.CV])",
    "abstract": "Promoting fairness for deep clustering models in unsupervised clustering settings to reduce demographic bias is a challenging goal. This is because of the limitation of large-scale balanced data with well-annotated labels for sensitive or protected attributes. In this paper, we first evaluate demographic bias in deep clustering models from the perspective of cluster purity, which is measured by the ratio of positive samples within a cluster to their correlation degree. This measurement is adopted as an indication of demographic bias. Then, a novel loss function is introduced to encourage a purity consistency for all clusters to maintain the fairness aspect of the learned clustering model. Moreover, we present a novel attention mechanism, Cross-attention, to measure correlations between multiple clusters, strengthening faraway positive samples and improving the purity of clusters during the learning process. Experimental results on a large-scale dataset with numerous attribute settings ",
    "link": "http://arxiv.org/abs/2304.07408",
    "context": "Title: Fairness in Visual Clustering: A Novel Transformer Clustering Approach. (arXiv:2304.07408v1 [cs.CV])\nAbstract: Promoting fairness for deep clustering models in unsupervised clustering settings to reduce demographic bias is a challenging goal. This is because of the limitation of large-scale balanced data with well-annotated labels for sensitive or protected attributes. In this paper, we first evaluate demographic bias in deep clustering models from the perspective of cluster purity, which is measured by the ratio of positive samples within a cluster to their correlation degree. This measurement is adopted as an indication of demographic bias. Then, a novel loss function is introduced to encourage a purity consistency for all clusters to maintain the fairness aspect of the learned clustering model. Moreover, we present a novel attention mechanism, Cross-attention, to measure correlations between multiple clusters, strengthening faraway positive samples and improving the purity of clusters during the learning process. Experimental results on a large-scale dataset with numerous attribute settings ",
    "path": "papers/23/04/2304.07408.json",
    "total_tokens": 831,
    "translated_title": "可靠的聚类算法:一种新的Transformer聚类方法",
    "translated_abstract": "在无监督聚类的情景下，为了减少人群偏差而增加深度聚类模型的公平性是一个具有挑战性的目标。本文从聚类纯度的角度评估了深度聚类模型中的人口偏差，聚类纯度是指聚类中正样本与它们的相关程度的比值。我们引入了一种新的损失函数来鼓励所有聚类的纯度一致性以维持学习到的聚类模型的公平性。此外, 我们提出了一种新的Cross-attention机制，用于测量多个聚类之间的相关性，在学习过程中加强远距离的正样本，提高聚类的纯度。在一个大规模的数据集上进行实验，包括多种属性设置。",
    "tldr": "本文提出了一种新的Transformer聚类方法，通过引入聚类纯度作为指标，采用新的损失函数来维持聚类模型的公平性，同时引入Cross-attention机制提高聚类的纯度。",
    "en_tdlr": "This paper proposes a novel Transformer clustering approach to promote fairness in deep clustering models by introducing cluster purity as an indicator and using a new loss function to maintain fairness consistency, as well as a Cross-attention mechanism to improve cluster purity. This approach is validated on a large-scale dataset with various attribute settings."
}