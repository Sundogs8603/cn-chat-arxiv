{
    "title": "Stochastic Parrots Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune and Hard to Detect with other LLMs. (arXiv:2304.08968v1 [cs.CL])",
    "abstract": "The self-attention revolution allowed generative language models to scale and achieve increasingly impressive abilities. Such models - commonly referred to as Large Language Models (LLMs) - have recently gained prominence with the general public, thanks to conversational fine-tuning, putting their behavior in line with public expectations regarding AI. This prominence amplified prior concerns regarding the misuse of LLMs and led to the emergence of numerous tools to detect LLMs in the wild.  Unfortunately, most such tools are critically flawed. While major publications in the LLM detectability field suggested that LLMs were easy to detect with fine-tuned autoencoders, the limitations of their results are easy to overlook. Specifically, they assumed publicly available generative models without fine-tunes or non-trivial prompts. While the importance of these assumptions has been demonstrated, until now, it remained unclear how well such detection could be countered.  Here, we show that a",
    "link": "http://arxiv.org/abs/2304.08968",
    "context": "Title: Stochastic Parrots Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune and Hard to Detect with other LLMs. (arXiv:2304.08968v1 [cs.CL])\nAbstract: The self-attention revolution allowed generative language models to scale and achieve increasingly impressive abilities. Such models - commonly referred to as Large Language Models (LLMs) - have recently gained prominence with the general public, thanks to conversational fine-tuning, putting their behavior in line with public expectations regarding AI. This prominence amplified prior concerns regarding the misuse of LLMs and led to the emergence of numerous tools to detect LLMs in the wild.  Unfortunately, most such tools are critically flawed. While major publications in the LLM detectability field suggested that LLMs were easy to detect with fine-tuned autoencoders, the limitations of their results are easy to overlook. Specifically, they assumed publicly available generative models without fine-tunes or non-trivial prompts. While the importance of these assumptions has been demonstrated, until now, it remained unclear how well such detection could be countered.  Here, we show that a",
    "path": "papers/23/04/2304.08968.json",
    "total_tokens": 830,
    "translated_title": "随机鹦鹉寻找随机鹦鹉：LLMs易于微调且难以被其他LLMs检测到",
    "translated_abstract": "自我注意力革命使生成式语言模型得以扩展并实现越来越惊人的能力。这些模型通常称为大型语言模型（LLMs），最近由于对话微调而在公众中获得了广泛关注，从而使其行为符合公众对于AI的期望。然而，这种突出也加大了关注LLMs误用的先前担忧，并导致出现许多在野外检测LLMs的工具。不幸的是，大多数这样的工具都存在严重缺陷。我们在这里展示了一种新方法，可以大大降低基于微调的自动编码器检测LLMs的成功率，并说明我们的工作涉及的重要细节。",
    "tldr": "LLMs在公众中广泛应用，但是目前大部分检测工具存在严重缺陷。研究发现，LLMs容易微调且难以被其他LLMs检测到。",
    "en_tdlr": "LLMs are widely used but most current detection tools have serious flaws. Research finds that LLMs are easy to fine-tune and hard to detect with other LLMs."
}