{
    "title": "Fairness and Bias in Truth Discovery Algorithms: An Experimental Analysis. (arXiv:2304.12573v1 [cs.LG])",
    "abstract": "Machine learning (ML) based approaches are increasingly being used in a number of applications with societal impact. Training ML models often require vast amounts of labeled data, and crowdsourcing is a dominant paradigm for obtaining labels from multiple workers. Crowd workers may sometimes provide unreliable labels, and to address this, truth discovery (TD) algorithms such as majority voting are applied to determine the consensus labels from conflicting worker responses. However, it is important to note that these consensus labels may still be biased based on sensitive attributes such as gender, race, or political affiliation. Even when sensitive attributes are not involved, the labels can be biased due to different perspectives of subjective aspects such as toxicity. In this paper, we conduct a systematic study of the bias and fairness of TD algorithms. Our findings using two existing crowd-labeled datasets, reveal that a non-trivial proportion of workers provide biased results, and",
    "link": "http://arxiv.org/abs/2304.12573",
    "context": "Title: Fairness and Bias in Truth Discovery Algorithms: An Experimental Analysis. (arXiv:2304.12573v1 [cs.LG])\nAbstract: Machine learning (ML) based approaches are increasingly being used in a number of applications with societal impact. Training ML models often require vast amounts of labeled data, and crowdsourcing is a dominant paradigm for obtaining labels from multiple workers. Crowd workers may sometimes provide unreliable labels, and to address this, truth discovery (TD) algorithms such as majority voting are applied to determine the consensus labels from conflicting worker responses. However, it is important to note that these consensus labels may still be biased based on sensitive attributes such as gender, race, or political affiliation. Even when sensitive attributes are not involved, the labels can be biased due to different perspectives of subjective aspects such as toxicity. In this paper, we conduct a systematic study of the bias and fairness of TD algorithms. Our findings using two existing crowd-labeled datasets, reveal that a non-trivial proportion of workers provide biased results, and",
    "path": "papers/23/04/2304.12573.json",
    "total_tokens": 837,
    "translated_title": "基于真相发现算法的公平性和偏差：实验分析",
    "translated_abstract": "机器学习技术在许多具有社会影响的应用中得到越来越广泛的运用。训练机器学习模型通常需要大量的标记数据，而众包是获取来自多个工作者的标记的主要范例。众包工作者有时会提供不可靠的标记，为了解决这个问题，会使用真相发现算法（例如多数表决）来确定来自冲突工作者响应的共识标记。但是，需要注意的是，这些共识标签可能仍基于敏感属性（如性别、种族或政治派别）而存在偏见。即使没有涉及敏感属性，由于主观方面的不同观点，标签也可能带有偏见，例如毒性等。在本文中，我们对真相发现算法的偏差和公平性进行了系统研究。我们使用两个现有的众包标记数据集，发现一定比例的工作者提供了有偏见的结果。",
    "tldr": "本文研究了真相发现算法的偏差和公平性，发现存在敏感属性偏见和主观偏见。",
    "en_tdlr": "This paper conducts a systematic study of bias and fairness in truth discovery algorithms, revealing the existence of biases based on sensitive attributes and subjective perspectives, using two existing crowd-labeled datasets."
}