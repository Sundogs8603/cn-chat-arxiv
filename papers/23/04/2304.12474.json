{
    "title": "Design optimization for high-performance computing using FPGA. (arXiv:2304.12474v1 [cs.AR])",
    "abstract": "Reconfigurable architectures like Field Programmable Gate Arrays (FPGAs) have been used for accelerating computations in several domains because of their unique combination of flexibility, performance, and power efficiency. However, FPGAs have not been widely used for high-performance computing, primarily because of their programming complexity and difficulties in optimizing performance. We optimize Tensil AI's open-source inference accelerator for maximum performance using ResNet20 trained on CIFAR in this paper in order to gain insight into the use of FPGAs for high-performance computing. In this paper, we show how improving hardware design, using Xilinx Ultra RAM, and using advanced compiler strategies can lead to improved inference performance. We also demonstrate that running the CIFAR test data set shows very little accuracy drop when rounding down from the original 32-bit floating point. The heterogeneous computing model in our platform allows us to achieve a frame rate of 293.5",
    "link": "http://arxiv.org/abs/2304.12474",
    "context": "Title: Design optimization for high-performance computing using FPGA. (arXiv:2304.12474v1 [cs.AR])\nAbstract: Reconfigurable architectures like Field Programmable Gate Arrays (FPGAs) have been used for accelerating computations in several domains because of their unique combination of flexibility, performance, and power efficiency. However, FPGAs have not been widely used for high-performance computing, primarily because of their programming complexity and difficulties in optimizing performance. We optimize Tensil AI's open-source inference accelerator for maximum performance using ResNet20 trained on CIFAR in this paper in order to gain insight into the use of FPGAs for high-performance computing. In this paper, we show how improving hardware design, using Xilinx Ultra RAM, and using advanced compiler strategies can lead to improved inference performance. We also demonstrate that running the CIFAR test data set shows very little accuracy drop when rounding down from the original 32-bit floating point. The heterogeneous computing model in our platform allows us to achieve a frame rate of 293.5",
    "path": "papers/23/04/2304.12474.json",
    "total_tokens": 885,
    "translated_title": "使用FPGA进行高性能计算的设计优化",
    "translated_abstract": "由于其独特的灵活性、性能和功率效率结合，可重构架构如可编程门阵列（FPGA）已经被用于许多领域的加速计算。但是，由于编程复杂性和优化性能的困难，FPGA尚未被广泛用于高性能计算。本文通过优化Tensil AI的开源推理加速器，使用在CIFAR上训练的ResNet20实现最大性能，以便深入了解使用FPGA进行高性能计算的方法。我们展示了如何改进硬件设计，使用Xilinx Ultra RAM和使用先进的编译器策略可以提高推理性能。我们还证明了在从原始32位浮点数向下舍入时运行CIFAR测试数据集时几乎没有准确性下降。我们平台中的异构计算模型使我们能够实现293.5的帧速率。",
    "tldr": "本文中，作者通过优化Tensil AI的开源推理加速器并使用高级编译器策略，改进硬件设计并使用Xilinx Ultra RAM，表明优化FPGA可提高推理性能，为FPGA在高性能计算领域的应用提供了启示。",
    "en_tdlr": "In this paper, the authors optimize Tensil AI's open-source inference accelerator using ResNet20 trained on CIFAR to gain insight into the use of FPGAs for high-performance computing. They demonstrate that improving hardware design, using Xilinx Ultra RAM, and using advanced compiler strategies can lead to improved inference performance, providing inspiration for the application of FPGAs in high-performance computing."
}