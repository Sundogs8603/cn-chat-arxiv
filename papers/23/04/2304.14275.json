{
    "title": "What's in a Name? Evaluating Assembly-Part Semantic Knowledge in Language Models through User-Provided Names in CAD Files. (arXiv:2304.14275v1 [cs.CL])",
    "abstract": "Semantic knowledge of part-part and part-whole relationships in assemblies is useful for a variety of tasks from searching design repositories to the construction of engineering knowledge bases. In this work we propose that the natural language names designers use in Computer Aided Design (CAD) software are a valuable source of such knowledge, and that Large Language Models (LLMs) contain useful domain-specific information for working with this data as well as other CAD and engineering-related tasks.  In particular we extract and clean a large corpus of natural language part, feature and document names and use this to quantitatively demonstrate that a pre-trained language model can outperform numerous benchmarks on three self-supervised tasks, without ever having seen this data before. Moreover, we show that fine-tuning on the text data corpus further boosts the performance on all tasks, thus demonstrating the value of the text data which until now has been largely ignored. We also ide",
    "link": "http://arxiv.org/abs/2304.14275",
    "context": "Title: What's in a Name? Evaluating Assembly-Part Semantic Knowledge in Language Models through User-Provided Names in CAD Files. (arXiv:2304.14275v1 [cs.CL])\nAbstract: Semantic knowledge of part-part and part-whole relationships in assemblies is useful for a variety of tasks from searching design repositories to the construction of engineering knowledge bases. In this work we propose that the natural language names designers use in Computer Aided Design (CAD) software are a valuable source of such knowledge, and that Large Language Models (LLMs) contain useful domain-specific information for working with this data as well as other CAD and engineering-related tasks.  In particular we extract and clean a large corpus of natural language part, feature and document names and use this to quantitatively demonstrate that a pre-trained language model can outperform numerous benchmarks on three self-supervised tasks, without ever having seen this data before. Moreover, we show that fine-tuning on the text data corpus further boosts the performance on all tasks, thus demonstrating the value of the text data which until now has been largely ignored. We also ide",
    "path": "papers/23/04/2304.14275.json",
    "total_tokens": 1122,
    "translated_title": "名字的意义：通过 CAD 文件中用户提供的名称评估语言模型中的装配 - 零件语义知识。",
    "translated_abstract": "装配中零件之间和零件与整体之间的语义知识对于从搜索设计存储库到构建工程知识库等各种任务都非常有用。本文提出，设计师在计算机辅助设计 (CAD) 软件中使用的自然语言名称是这种知识宝贵的来源，并且大型语言模型 (LLM) 包含了用于处理此数据以及其他 CAD 和工程相关任务的有用领域专业知识。我们提取并清理了大量的自然语言零件、特征和文档名称语料库，并使用它来定量证明预训练语言模型可以在三个自监督任务上优于众多基准测试，而且从未见过这些数据。此外，我们展示了对文本数据语料库进行微调可以进一步提高所有任务的性能，从而展示了迄今为止在很大程度上被忽略的文本数据的价值。我们还确定了这个领域需要更多的基准数据集，并提出了一个名为 CAD-120 的新数据集，其中包含 120 个 CAD 装配件，具有手动注释的语义关系。",
    "tldr": "本文提出，计算机辅助设计（CAD）软件中的自然语言名称是部件关联的宝贵来源，大型语言模型（LLM）提供了一种处理这种数据的有用的领域专业知识。通过自然语言名称的预训练模型可在三个自监督任务上表现出色，微调还可以提高所有任务的性能，提高了文本数据的价值。此外，提出了手动注释的新数据集 CAD-120，其中包含 120 个装配，并提供了语义关系注释。",
    "en_tdlr": "This paper proposes that natural language names in Computer Aided Design (CAD) software are a valuable source of semantic knowledge for part-part and part-whole relationships in assemblies, and that Large Language Models (LLMs) can utilize this data to outperform numerous benchmarks on self-supervised tasks. The paper also demonstrates the value of fine-tuning on text data and proposes a new benchmark dataset, CAD-120, consisting of 120 CAD assemblies with manually annotated semantic relationships."
}