{
    "title": "DeepHive: A multi-agent reinforcement learning approach for automated discovery of swarm-based optimization policies. (arXiv:2304.04751v1 [cs.AI])",
    "abstract": "We present an approach for designing swarm-based optimizers for the global optimization of expensive black-box functions. In the proposed approach, the problem of finding efficient optimizers is framed as a reinforcement learning problem, where the goal is to find optimization policies that require a few function evaluations to converge to the global optimum. The state of each agent within the swarm is defined as its current position and function value within a design space and the agents learn to take favorable actions that maximize reward, which is based on the final value of the objective function. The proposed approach is tested on various benchmark optimization functions and compared to the performance of other global optimization strategies. Furthermore, the effect of changing the number of agents, as well as the generalization capabilities of the trained agents are investigated. The results show superior performance compared to the other optimizers, desired scaling when the numb",
    "link": "http://arxiv.org/abs/2304.04751",
    "context": "Title: DeepHive: A multi-agent reinforcement learning approach for automated discovery of swarm-based optimization policies. (arXiv:2304.04751v1 [cs.AI])\nAbstract: We present an approach for designing swarm-based optimizers for the global optimization of expensive black-box functions. In the proposed approach, the problem of finding efficient optimizers is framed as a reinforcement learning problem, where the goal is to find optimization policies that require a few function evaluations to converge to the global optimum. The state of each agent within the swarm is defined as its current position and function value within a design space and the agents learn to take favorable actions that maximize reward, which is based on the final value of the objective function. The proposed approach is tested on various benchmark optimization functions and compared to the performance of other global optimization strategies. Furthermore, the effect of changing the number of agents, as well as the generalization capabilities of the trained agents are investigated. The results show superior performance compared to the other optimizers, desired scaling when the numb",
    "path": "papers/23/04/2304.04751.json",
    "total_tokens": 861,
    "translated_title": "DeepHive: 一种用于自动化发现基于群体优化策略的多智能体强化学习方法",
    "translated_abstract": "本文提出了一种设计群体优化器来全局优化昂贵黑盒函数的方法。在这种方法中，找到高效的优化器的问题被视为一个强化学习问题，目标是找到需要少数函数评估即可收敛到全局最优的优化策略。群体中每个智能体的状态被定义为其在设计空间内的当前位置和函数值，并且这些智能体学会采取最大化奖励的有利行动，该奖励基于目标函数的最终值。该方法在各类基准优化函数上进行了测试，并与其他全局优化策略的性能进行了比较。此外，还研究了更改代理人数量以及训练代理人的泛化能力的影响。结果表明，与其他优化器相比，该方法具有优越的性能和所需的缩放。",
    "tldr": "本文提出了一种多智能体强化学习方法，用于设计群体优化器以全局优化昂贵黑盒函数，并在各类基准优化函数上进行测试，结果表明具有优越的性能和所需的缩放。"
}