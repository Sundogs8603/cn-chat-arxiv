{
    "title": "The Dataset Multiplicity Problem: How Unreliable Data Impacts Predictions. (arXiv:2304.10655v1 [cs.LG])",
    "abstract": "We introduce dataset multiplicity, a way to study how inaccuracies, uncertainty, and social bias in training datasets impact test-time predictions. The dataset multiplicity framework asks a counterfactual question of what the set of resultant models (and associated test-time predictions) would be if we could somehow access all hypothetical, unbiased versions of the dataset. We discuss how to use this framework to encapsulate various sources of uncertainty in datasets' factualness, including systemic social bias, data collection practices, and noisy labels or features. We show how to exactly analyze the impacts of dataset multiplicity for a specific model architecture and type of uncertainty: linear models with label errors. Our empirical analysis shows that real-world datasets, under reasonable assumptions, contain many test samples whose predictions are affected by dataset multiplicity. Furthermore, the choice of domain-specific dataset multiplicity definition determines what samples ",
    "link": "http://arxiv.org/abs/2304.10655",
    "context": "Title: The Dataset Multiplicity Problem: How Unreliable Data Impacts Predictions. (arXiv:2304.10655v1 [cs.LG])\nAbstract: We introduce dataset multiplicity, a way to study how inaccuracies, uncertainty, and social bias in training datasets impact test-time predictions. The dataset multiplicity framework asks a counterfactual question of what the set of resultant models (and associated test-time predictions) would be if we could somehow access all hypothetical, unbiased versions of the dataset. We discuss how to use this framework to encapsulate various sources of uncertainty in datasets' factualness, including systemic social bias, data collection practices, and noisy labels or features. We show how to exactly analyze the impacts of dataset multiplicity for a specific model architecture and type of uncertainty: linear models with label errors. Our empirical analysis shows that real-world datasets, under reasonable assumptions, contain many test samples whose predictions are affected by dataset multiplicity. Furthermore, the choice of domain-specific dataset multiplicity definition determines what samples ",
    "path": "papers/23/04/2304.10655.json",
    "total_tokens": 943,
    "tldr": "本文介绍了数据集多重性的问题，并提出了一个反事实问题来研究如何消除数据集中的不准确性、不确定性和社会偏见的影响。作者已经发现，大多数现实世界的数据集中包含许多受数据集多重性影响的测试样本。",
    "en_tdlr": "This paper introduces the dataset multiplicity problem and proposes a counterfactual method to study the impact of inaccuracies, uncertainty, and social bias in training datasets on test-time predictions. It shows that real-world datasets contain many test samples affected by dataset multiplicity and suggests that domain-specific dataset multiplicity definitions determine the affected samples."
}