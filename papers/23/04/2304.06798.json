{
    "title": "On the Opportunities and Challenges of Foundation Models for Geospatial Artificial Intelligence. (arXiv:2304.06798v1 [cs.AI])",
    "abstract": "Large pre-trained models, also known as foundation models (FMs), are trained in a task-agnostic manner on large-scale data and can be adapted to a wide range of downstream tasks by fine-tuning, few-shot, or even zero-shot learning. Despite their successes in language and vision tasks, we have yet seen an attempt to develop foundation models for geospatial artificial intelligence (GeoAI). In this work, we explore the promises and challenges of developing multimodal foundation models for GeoAI. We first investigate the potential of many existing FMs by testing their performances on seven tasks across multiple geospatial subdomains including Geospatial Semantics, Health Geography, Urban Geography, and Remote Sensing. Our results indicate that on several geospatial tasks that only involve text modality such as toponym recognition, location description recognition, and US state-level/county-level dementia time series forecasting, these task-agnostic LLMs can outperform task-specific fully-s",
    "link": "http://arxiv.org/abs/2304.06798",
    "context": "Title: On the Opportunities and Challenges of Foundation Models for Geospatial Artificial Intelligence. (arXiv:2304.06798v1 [cs.AI])\nAbstract: Large pre-trained models, also known as foundation models (FMs), are trained in a task-agnostic manner on large-scale data and can be adapted to a wide range of downstream tasks by fine-tuning, few-shot, or even zero-shot learning. Despite their successes in language and vision tasks, we have yet seen an attempt to develop foundation models for geospatial artificial intelligence (GeoAI). In this work, we explore the promises and challenges of developing multimodal foundation models for GeoAI. We first investigate the potential of many existing FMs by testing their performances on seven tasks across multiple geospatial subdomains including Geospatial Semantics, Health Geography, Urban Geography, and Remote Sensing. Our results indicate that on several geospatial tasks that only involve text modality such as toponym recognition, location description recognition, and US state-level/county-level dementia time series forecasting, these task-agnostic LLMs can outperform task-specific fully-s",
    "path": "papers/23/04/2304.06798.json",
    "total_tokens": 1134,
    "translated_title": "论基础模型在地理空间AI中的机遇与挑战",
    "translated_abstract": "基础模型（FMs）是指在大规模数据上以任务无关的方式进行训练，并通过微调、少样本甚至零样本学习适用于广泛下游任务的大型预训练模型。虽然在语言和视觉任务中大获成功，但我们尚未见到为地理空间人工智能（GeoAI）开发基础模型的尝试。本文探讨开发多模态基础模型以应对GeoAI的潜力和挑战。我们首先通过在多个地理空间子域中进行七项任务的测试，包括地理语义、健康地理学、城市地理学和遥感等，研究了现有许多FMs的潜力。结果表明，在仅涉及文本模态的一些地理空间任务（例如地名识别、位置描述识别以及美国州级/县级痴呆症时间序列预测）中，这些任务无关的LLM也可以胜任任务特定的完全定制模型。我们进一步讨论了为地理空间AI开发FMs的挑战，包括缺乏大规模地理空间数据集和需要专门的地理空间微调技术。最后，我们确定了多模态FMs的潜在研究方向和应用，以惠及地理空间AI社区。",
    "tldr": "本文研究了在地理空间AI中开发基础模型的机遇和挑战，测试了多种FMs在地理子领域中的表现，发现在文本任务上的表现优于任务特定的定制模型，但在发展中也面临着缺少数据集和需要专业技术微调的挑战。",
    "en_tdlr": "This paper explores the potential and challenges of developing foundation models (FMs) for geospatial artificial intelligence (GeoAI), testing multiple FMs on tasks across various geospatial subdomains and finding that task-agnostic models perform well on text tasks but face challenges such as lack of geospatial datasets and specialized fine-tuning techniques. Potential research and applications for multimodal FMs in GeoAI are also identified."
}