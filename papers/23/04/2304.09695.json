{
    "title": "Big-Little Adaptive Neural Networks on Low-Power Near-Subthreshold Processors. (arXiv:2304.09695v1 [cs.LG])",
    "abstract": "This paper investigates the energy savings that near-subthreshold processors can obtain in edge AI applications and proposes strategies to improve them while maintaining the accuracy of the application. The selected processors deploy adaptive voltage scaling techniques in which the frequency and voltage levels of the processor core are determined at the run-time. In these systems, embedded RAM and flash memory size is typically limited to less than 1 megabyte to save power. This limited memory imposes restrictions on the complexity of the neural networks model that can be mapped to these devices and the required trade-offs between accuracy and battery life. To address these issues, we propose and evaluate alternative 'big-little' neural network strategies to improve battery life while maintaining prediction accuracy. The strategies are applied to a human activity recognition application selected as a demonstrator that shows that compared to the original network, the best configurations",
    "link": "http://arxiv.org/abs/2304.09695",
    "context": "Title: Big-Little Adaptive Neural Networks on Low-Power Near-Subthreshold Processors. (arXiv:2304.09695v1 [cs.LG])\nAbstract: This paper investigates the energy savings that near-subthreshold processors can obtain in edge AI applications and proposes strategies to improve them while maintaining the accuracy of the application. The selected processors deploy adaptive voltage scaling techniques in which the frequency and voltage levels of the processor core are determined at the run-time. In these systems, embedded RAM and flash memory size is typically limited to less than 1 megabyte to save power. This limited memory imposes restrictions on the complexity of the neural networks model that can be mapped to these devices and the required trade-offs between accuracy and battery life. To address these issues, we propose and evaluate alternative 'big-little' neural network strategies to improve battery life while maintaining prediction accuracy. The strategies are applied to a human activity recognition application selected as a demonstrator that shows that compared to the original network, the best configurations",
    "path": "papers/23/04/2304.09695.json",
    "total_tokens": 854,
    "translated_title": "低功耗近阈值处理器上的大-小自适应神经网络",
    "translated_abstract": "本文研究了近阈值处理器在边缘人工智能应用中可以获得的能量节省，并提出了策略来提高它们同时保持应用的准确性。选择的处理器采用自适应电压缩放技术，处理器核的频率和电压级别在运行时确定。在这些系统中，嵌入式RAM和Flash存储器的大小通常限制在不到1兆字节以节省电力。这种有限内存对可以映射到这些设备的神经网络模型的复杂性和精度与电池续航时间之间所需的权衡产生了限制。为了解决这些问题，我们提出并评估了替代的“大-小”神经网络策略，以提高电池寿命同时保持预测准确性。所提出的策略应用于人类活动识别应用程序作为示范，结果显示相比于原始网络，最佳配置",
    "tldr": "本文研究了近阈值处理器在边缘人工智能应用中的能量节省，并提出大-小自适应神经网络策略以提高电池寿命和保持预测准确性。",
    "en_tdlr": "This paper investigates energy savings of near-subthreshold processors in edge AI applications, and proposes big-little adaptive neural network strategies to improve battery life while maintaining prediction accuracy."
}