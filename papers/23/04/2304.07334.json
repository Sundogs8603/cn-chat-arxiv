{
    "title": "HEAT: A Highly Efficient and Affordable Training System for Collaborative Filtering Based Recommendation on CPUs. (arXiv:2304.07334v1 [cs.DC])",
    "abstract": "Collaborative filtering (CF) has been proven to be one of the most effective techniques for recommendation. Among all CF approaches, SimpleX is the state-of-the-art method that adopts a novel loss function and a proper number of negative samples. However, there is no work that optimizes SimpleX on multi-core CPUs, leading to limited performance. To this end, we perform an in-depth profiling and analysis of existing SimpleX implementations and identify their performance bottlenecks including (1) irregular memory accesses, (2) unnecessary memory copies, and (3) redundant computations. To address these issues, we propose an efficient CF training system (called HEAT) that fully enables the multi-level caching and multi-threading capabilities of modern CPUs. Specifically, the optimization of HEAT is threefold: (1) It tiles the embedding matrix to increase data locality and reduce cache misses (thus reduce read latency); (2) It optimizes stochastic gradient descent (SGD) with sampling by par",
    "link": "http://arxiv.org/abs/2304.07334",
    "context": "Title: HEAT: A Highly Efficient and Affordable Training System for Collaborative Filtering Based Recommendation on CPUs. (arXiv:2304.07334v1 [cs.DC])\nAbstract: Collaborative filtering (CF) has been proven to be one of the most effective techniques for recommendation. Among all CF approaches, SimpleX is the state-of-the-art method that adopts a novel loss function and a proper number of negative samples. However, there is no work that optimizes SimpleX on multi-core CPUs, leading to limited performance. To this end, we perform an in-depth profiling and analysis of existing SimpleX implementations and identify their performance bottlenecks including (1) irregular memory accesses, (2) unnecessary memory copies, and (3) redundant computations. To address these issues, we propose an efficient CF training system (called HEAT) that fully enables the multi-level caching and multi-threading capabilities of modern CPUs. Specifically, the optimization of HEAT is threefold: (1) It tiles the embedding matrix to increase data locality and reduce cache misses (thus reduce read latency); (2) It optimizes stochastic gradient descent (SGD) with sampling by par",
    "path": "papers/23/04/2304.07334.json",
    "total_tokens": 924,
    "translated_title": "HEAT：一种高效且经济实惠的基于CPU的协同过滤推荐训练系统",
    "translated_abstract": "协同过滤已被证明是推荐系统中最有效的技术之一。在所有协同过滤方法中，SimpleX是采用了新颖的损失函数和适当数量的负样本的最先进方法。然而，目前还没有对SimpleX在多核CPU上进行了优化，导致性能有限。为了解决这个问题，我们对现有的SimpleX实现进行了深入的分析，并确定了它们的性能瓶颈，包括(1)不规则的内存访问，(2)不必要的内存复制，(3)冗余计算。为了解决这些问题，我们提出了一种高效的CF训练系统(名为HEAT)，它充分发挥了现代CPU的多级缓存和多线程能力。具体而言，HEAT的优化有三个方面：(1)使用瓦片化技术增加数据局部性和减少缓存失效(从而减少读取延迟)；(2)使用随机梯度下降(SGD)和采样优化；(3)使用功能分区优化内存访问和计算",
    "tldr": "这篇论文提出了HEAT训练系统，通过优化SimpleX在CPU上的操作，实现协同过滤的高效率训练",
    "en_tdlr": "HEAT is a highly efficient and affordable CF training system that optimizes SimpleX on multi-core CPUs to enable fast CF training. It achieves this by optimizing memory and computation through tiling, stochastic gradient descent with sampling, and functional partitioning."
}