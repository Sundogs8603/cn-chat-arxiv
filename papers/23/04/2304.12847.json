{
    "title": "NLP-LTU at SemEval-2023 Task 10: The Impact of Data Augmentation and Semi-Supervised Learning Techniques on Text Classification Performance on an Imbalanced Dataset. (arXiv:2304.12847v1 [cs.CL])",
    "abstract": "In this paper, we propose a methodology for task 10 of SemEval23, focusing on detecting and classifying online sexism in social media posts. The task is tackling a serious issue, as detecting harmful content on social media platforms is crucial for mitigating the harm of these posts on users. Our solution for this task is based on an ensemble of fine-tuned transformer-based models (BERTweet, RoBERTa, and DeBERTa). To alleviate problems related to class imbalance, and to improve the generalization capability of our model, we also experiment with data augmentation and semi-supervised learning. In particular, for data augmentation, we use back-translation, either on all classes, or on the underrepresented classes only. We analyze the impact of these strategies on the overall performance of the pipeline through extensive experiments. while for semi-supervised learning, we found that with a substantial amount of unlabelled, in-domain data available, semi-supervised learning can enhance the ",
    "link": "http://arxiv.org/abs/2304.12847",
    "context": "Title: NLP-LTU at SemEval-2023 Task 10: The Impact of Data Augmentation and Semi-Supervised Learning Techniques on Text Classification Performance on an Imbalanced Dataset. (arXiv:2304.12847v1 [cs.CL])\nAbstract: In this paper, we propose a methodology for task 10 of SemEval23, focusing on detecting and classifying online sexism in social media posts. The task is tackling a serious issue, as detecting harmful content on social media platforms is crucial for mitigating the harm of these posts on users. Our solution for this task is based on an ensemble of fine-tuned transformer-based models (BERTweet, RoBERTa, and DeBERTa). To alleviate problems related to class imbalance, and to improve the generalization capability of our model, we also experiment with data augmentation and semi-supervised learning. In particular, for data augmentation, we use back-translation, either on all classes, or on the underrepresented classes only. We analyze the impact of these strategies on the overall performance of the pipeline through extensive experiments. while for semi-supervised learning, we found that with a substantial amount of unlabelled, in-domain data available, semi-supervised learning can enhance the ",
    "path": "papers/23/04/2304.12847.json",
    "total_tokens": 868,
    "translated_title": "NLP-LTU在SemEval-2023任务10中的应用: 数据增强和半监督学习技术对非平衡数据文本分类性能的影响",
    "translated_abstract": "本文提出了一种方法，专注于检测和分类社交媒体帖子中的在线性别歧视，以应对SemEval23任务10的挑战。我们的解决方案基于微调后的transformer模型（BERTweet、RoBERTa和DeBERTa）的集成。为了缓解与类别不平衡相关的问题，并提高模型的泛化能力，我们还尝试了数据增强和半监督学习。具体来说，对于数据增强，我们使用了回译，不是在所有类别上，就是只在欠表示的类别上。我们还通过广泛的实验分析了这些策略对管道整体性能的影响。对于半监督学习，我们发现，如果有大量未标记的领域内数据可用，半监督学习可以增强性能。",
    "tldr": "本文提出应用transformer模型和数据增强、半监督学习技术的方法，以应对文本分类中的类别不平衡问题，从而增强整体性能。",
    "en_tdlr": "This paper proposes a methodology using transformer models and techniques such as data augmentation and semi-supervised learning to address the issue of class imbalance in text classification, achieving improved performance."
}