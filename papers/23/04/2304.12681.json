{
    "title": "Differential Privacy via Distributionally Robust Optimization. (arXiv:2304.12681v1 [cs.CR])",
    "abstract": "In recent years, differential privacy has emerged as the de facto standard for sharing statistics of datasets while limiting the disclosure of private information about the involved individuals. This is achieved by randomly perturbing the statistics to be published, which in turn leads to a privacy-accuracy trade-off: larger perturbations provide stronger privacy guarantees, but they result in less accurate statistics that offer lower utility to the recipients. Of particular interest are therefore optimal mechanisms that provide the highest accuracy for a pre-selected level of privacy. To date, work in this area has focused on specifying families of perturbations a priori and subsequently proving their asymptotic and/or best-in-class optimality. In this paper, we develop a class of mechanisms that enjoy non-asymptotic and unconditional optimality guarantees. To this end, we formulate the mechanism design problem as an infinite-dimensional distributionally robust optimization problem. W",
    "link": "http://arxiv.org/abs/2304.12681",
    "context": "Title: Differential Privacy via Distributionally Robust Optimization. (arXiv:2304.12681v1 [cs.CR])\nAbstract: In recent years, differential privacy has emerged as the de facto standard for sharing statistics of datasets while limiting the disclosure of private information about the involved individuals. This is achieved by randomly perturbing the statistics to be published, which in turn leads to a privacy-accuracy trade-off: larger perturbations provide stronger privacy guarantees, but they result in less accurate statistics that offer lower utility to the recipients. Of particular interest are therefore optimal mechanisms that provide the highest accuracy for a pre-selected level of privacy. To date, work in this area has focused on specifying families of perturbations a priori and subsequently proving their asymptotic and/or best-in-class optimality. In this paper, we develop a class of mechanisms that enjoy non-asymptotic and unconditional optimality guarantees. To this end, we formulate the mechanism design problem as an infinite-dimensional distributionally robust optimization problem. W",
    "path": "papers/23/04/2304.12681.json",
    "total_tokens": 833,
    "translated_title": "分布式鲁棒优化实现差分隐私保护",
    "translated_abstract": "近年来，差分隐私已成为共享数据集统计信息并限制涉及个人的私人信息披露的事实标准。通过对将要发布的统计数据进行随机扰动来实现这一目标，这反过来导致了隐私和准确性之间的权衡：更大的扰动提供更强的隐私保证，但结果是提供较低实用度的统计数据和更低的准确性。因此，特别感兴趣的是在预选隐私水平的情况下提供最高准确性的最佳机制。迄今为止，这一领域的工作集中在事先指定扰动族并随后证明其渐近和/或最佳性上，本文则开发了一类机制，它们具有非渐近和无条件的最佳性保证。为此，我们将机制设计问题制定为无限维分布鲁棒优化问题。",
    "tldr": "本文开发了一类机制，以实现无条件最优性保证的差分隐私。该机制将机制设计问题制定为无限维分布鲁棒优化问题。",
    "en_tdlr": "This paper develops a class of mechanisms for achieving differentially private data access with non-asymptotic and unconditional optimality guarantees, by formulating the mechanism design problem as an infinite-dimensional distributionally robust optimization problem."
}