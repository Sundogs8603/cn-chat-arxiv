{
    "title": "Towards Understanding Feature Learning in Out-of-Distribution Generalization. (arXiv:2304.11327v1 [cs.LG])",
    "abstract": "A common explanation for the failure of out-of-distribution (OOD) generalization is that the model trained with empirical risk minimization (ERM) learns spurious features instead of the desired invariant features. However, several recent studies challenged this explanation and found that deep networks may have already learned sufficiently good features for OOD generalization. The debate extends to the in-distribution and OOD performance correlations along with training or fine-tuning neural nets across a variety of OOD generalization tasks. To understand these seemingly contradicting phenomena, we conduct a theoretical investigation and find that ERM essentially learns both spurious features and invariant features. On the other hand, the quality of learned features during ERM pre-training significantly affects the final OOD performance, as OOD objectives rarely learn new features. Failing to capture all the underlying useful features during pre-training will further limit the final OOD",
    "link": "http://arxiv.org/abs/2304.11327",
    "context": "Title: Towards Understanding Feature Learning in Out-of-Distribution Generalization. (arXiv:2304.11327v1 [cs.LG])\nAbstract: A common explanation for the failure of out-of-distribution (OOD) generalization is that the model trained with empirical risk minimization (ERM) learns spurious features instead of the desired invariant features. However, several recent studies challenged this explanation and found that deep networks may have already learned sufficiently good features for OOD generalization. The debate extends to the in-distribution and OOD performance correlations along with training or fine-tuning neural nets across a variety of OOD generalization tasks. To understand these seemingly contradicting phenomena, we conduct a theoretical investigation and find that ERM essentially learns both spurious features and invariant features. On the other hand, the quality of learned features during ERM pre-training significantly affects the final OOD performance, as OOD objectives rarely learn new features. Failing to capture all the underlying useful features during pre-training will further limit the final OOD",
    "path": "papers/23/04/2304.11327.json",
    "total_tokens": 916,
    "translated_title": "探索外部分布广义化中的特征学习",
    "translated_abstract": "对于外部分布（OOD）广义化的失败，常见的解释是使用经验风险最小化（ERM）模型学习到具有误导性的特征而不是期望的不变特征。然而，最近的几项研究挑战了这种解释，发现深度网络可能已经学到了足够好的特征进行OOD广义化。这场辩论扩展到了许多OOD广义化任务的训练或微调神经网络的内部组织和OOD性能相关性中。为了理解这些似乎相互矛盾的现象，我们进行了理论研究，发现ERM本质上同时学习了具有误导性的特征和不变特征。另一方面，在ERM预训练期间学习到的特征质量显著影响了最终的OOD性能，因为OOD对象很少学习到新功能。未能在预训练期间捕获所有潜在的有用特征将进一步限制最终的OOD性能。",
    "tldr": "研究发现，ERM本质上同时学习了具有误导性的特征和不变特征，在ERM预训练期间学习到的特征质量影响了最终的OOD性能，未能捕获所有潜在的有用特征将限制最终的OOD性能。",
    "en_tdlr": "The study found that ERM essentially learns both spurious features and invariant features, the quality of learned features during ERM pre-training significantly affects the final OOD performance, and failing to capture all the underlying useful features will further limit the final OOD performance."
}