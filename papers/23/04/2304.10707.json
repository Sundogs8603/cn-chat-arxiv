{
    "title": "Persistently Trained, Diffusion-assisted Energy-based Models. (arXiv:2304.10707v1 [stat.ML])",
    "abstract": "Maximum likelihood (ML) learning for energy-based models (EBMs) is challenging, partly due to non-convergence of Markov chain Monte Carlo.Several variations of ML learning have been proposed, but existing methods all fail to achieve both post-training image generation and proper density estimation. We propose to introduce diffusion data and learn a joint EBM, called diffusion assisted-EBMs, through persistent training (i.e., using persistent contrastive divergence) with an enhanced sampling algorithm to properly sample from complex, multimodal distributions. We present results from a 2D illustrative experiment and image experiments and demonstrate that, for the first time for image data, persistently trained EBMs can {\\it simultaneously} achieve long-run stability, post-training image generation, and superior out-of-distribution detection.",
    "link": "http://arxiv.org/abs/2304.10707",
    "context": "Title: Persistently Trained, Diffusion-assisted Energy-based Models. (arXiv:2304.10707v1 [stat.ML])\nAbstract: Maximum likelihood (ML) learning for energy-based models (EBMs) is challenging, partly due to non-convergence of Markov chain Monte Carlo.Several variations of ML learning have been proposed, but existing methods all fail to achieve both post-training image generation and proper density estimation. We propose to introduce diffusion data and learn a joint EBM, called diffusion assisted-EBMs, through persistent training (i.e., using persistent contrastive divergence) with an enhanced sampling algorithm to properly sample from complex, multimodal distributions. We present results from a 2D illustrative experiment and image experiments and demonstrate that, for the first time for image data, persistently trained EBMs can {\\it simultaneously} achieve long-run stability, post-training image generation, and superior out-of-distribution detection.",
    "path": "papers/23/04/2304.10707.json",
    "total_tokens": 845,
    "translated_title": "基于扩散的能量模型的持续训练",
    "translated_abstract": "能量模型 (EBMs) 的最大似然 (ML) 学习很具有挑战性，部分原因在于马尔可夫链蒙特卡罗的不收敛。虽然已经提出了几种 ML 学习的变体，但现有方法都未能同时实现训练后的图像生成和合适的密度估计。我们提出了引入扩散数据，并通过使用增强的采样算法进行持续训练 (即使用持续的对比散度)，来学习一个称为扩散辅助 EBM 的联合 EBM，以便从复杂的、多峰的分布中进行适当的采样。我们在二维的示例实验和图像实验中展示了结果，并证明了针对图像数据，持续训练的 EBM 可以同时实现长期稳定性、训练后的图像生成和优越的越界检测。",
    "tldr": "本文提出了一种新的持续训练方法，命名为扩散辅助 EBM，可以同时实现长期稳定性、训练后的图像生成和优越的越界检测。",
    "en_tdlr": "This paper proposes a new persistently trained method, called diffusion-assisted EBM, to learn joint energy-based models with diffusion data and an enhanced sampling algorithm, which for the first time achieves both long-run stability, post-training image generation, and superior out-of-distribution detection for image data."
}