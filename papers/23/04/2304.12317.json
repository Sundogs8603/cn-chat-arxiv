{
    "title": "Total-Recon: Deformable Scene Reconstruction for Embodied View Synthesis. (arXiv:2304.12317v2 [cs.CV] UPDATED)",
    "abstract": "We explore the task of embodied view synthesis from monocular videos of deformable scenes. Given a minute-long RGBD video of people interacting with their pets, we render the scene from novel camera trajectories derived from the in-scene motion of actors: (1) egocentric cameras that simulate the point of view of a target actor and (2) 3rd-person cameras that follow the actor. Building such a system requires reconstructing the root-body and articulated motion of every actor, as well as a scene representation that supports free-viewpoint synthesis. Longer videos are more likely to capture the scene from diverse viewpoints (which helps reconstruction) but are also more likely to contain larger motions (which complicates reconstruction). To address these challenges, we present Total-Recon, the first method to photorealistically reconstruct deformable scenes from long monocular RGBD videos. Crucially, to scale to long videos, our method hierarchically decomposes the scene into the backgroun",
    "link": "http://arxiv.org/abs/2304.12317",
    "context": "Title: Total-Recon: Deformable Scene Reconstruction for Embodied View Synthesis. (arXiv:2304.12317v2 [cs.CV] UPDATED)\nAbstract: We explore the task of embodied view synthesis from monocular videos of deformable scenes. Given a minute-long RGBD video of people interacting with their pets, we render the scene from novel camera trajectories derived from the in-scene motion of actors: (1) egocentric cameras that simulate the point of view of a target actor and (2) 3rd-person cameras that follow the actor. Building such a system requires reconstructing the root-body and articulated motion of every actor, as well as a scene representation that supports free-viewpoint synthesis. Longer videos are more likely to capture the scene from diverse viewpoints (which helps reconstruction) but are also more likely to contain larger motions (which complicates reconstruction). To address these challenges, we present Total-Recon, the first method to photorealistically reconstruct deformable scenes from long monocular RGBD videos. Crucially, to scale to long videos, our method hierarchically decomposes the scene into the backgroun",
    "path": "papers/23/04/2304.12317.json",
    "total_tokens": 876,
    "translated_title": "Total-Recon: 可变形场景重建用于实体视角合成",
    "translated_abstract": "我们研究了从可变形场景的单目视频中合成实体视角的任务。给定一个长达一分钟的RGBD视频，拍摄了人与他们宠物互动的场景，我们从场景中的运动派生出新的相机轨迹，渲染出该场景：(1)模拟目标演员视角的自我相机和(2)跟随演员的第三人称相机。构建这样的系统需要重建每个演员的根-身体和关节运动，以及支持自由视点合成的场景表示。长视频更有可能从不同的视角捕捉到场景（有助于重建），但也更有可能包含较大的运动（使重建变得复杂）。为了解决这些挑战，我们提出了Total-Recon，这是第一个从长的单目RGBD视频中实现光实感的可变形场景重建方法。关键是，为了适应长视频，我们的方法将场景分层分解为背景和前景，并使用不同的深度估计技术进行重建。",
    "tldr": "本论文介绍了Total-Recon，这是第一个从长的单目RGBD视频中实现光实感的可变形场景重建方法，用于合成实体视角。",
    "en_tdlr": "This paper presents Total-Recon, the first method to photorealistically reconstruct deformable scenes from long monocular RGBD videos for embodied view synthesis."
}