{
    "title": "Introducing MBIB -- the first Media Bias Identification Benchmark Task and Dataset Collection. (arXiv:2304.13148v1 [cs.IR])",
    "abstract": "Although media bias detection is a complex multi-task problem, there is, to date, no unified benchmark grouping these evaluation tasks. We introduce the Media Bias Identification Benchmark (MBIB), a comprehensive benchmark that groups different types of media bias (e.g., linguistic, cognitive, political) under a common framework to test how prospective detection techniques generalize. After reviewing 115 datasets, we select nine tasks and carefully propose 22 associated datasets for evaluating media bias detection techniques. We evaluate MBIB using state-of-the-art Transformer techniques (e.g., T5, BART). Our results suggest that while hate speech, racial bias, and gender bias are easier to detect, models struggle to handle certain bias types, e.g., cognitive and political bias. However, our results show that no single technique can outperform all the others significantly. We also find an uneven distribution of research interest and resource allocation to the individual tasks in media ",
    "link": "http://arxiv.org/abs/2304.13148",
    "context": "Title: Introducing MBIB -- the first Media Bias Identification Benchmark Task and Dataset Collection. (arXiv:2304.13148v1 [cs.IR])\nAbstract: Although media bias detection is a complex multi-task problem, there is, to date, no unified benchmark grouping these evaluation tasks. We introduce the Media Bias Identification Benchmark (MBIB), a comprehensive benchmark that groups different types of media bias (e.g., linguistic, cognitive, political) under a common framework to test how prospective detection techniques generalize. After reviewing 115 datasets, we select nine tasks and carefully propose 22 associated datasets for evaluating media bias detection techniques. We evaluate MBIB using state-of-the-art Transformer techniques (e.g., T5, BART). Our results suggest that while hate speech, racial bias, and gender bias are easier to detect, models struggle to handle certain bias types, e.g., cognitive and political bias. However, our results show that no single technique can outperform all the others significantly. We also find an uneven distribution of research interest and resource allocation to the individual tasks in media ",
    "path": "papers/23/04/2304.13148.json",
    "total_tokens": 992,
    "translated_title": "MBIB--首个媒体偏见识别基准测试任务和数据集集合的介绍",
    "translated_abstract": "尽管媒体偏见检测是一个复杂的多任务问题，但目前还没有一个统一的基准来分组这些评估任务。我们引入了媒体偏见识别基准测试（MBIB），这是一个全面的基准测试，将不同类型的媒体偏见（例如，语言、认知、政治）分为一个共同的框架，以测试预测检测技术的概括化程度。在评估了115个数据集后，我们选择了9个任务，仔细提出了22个相关数据集，以评估媒体偏见检测技术。我们使用最先进的Transformer技术（例如T5、BART）评估MBIB。我们的结果表明，尽管仇恨言论、种族偏见和性别偏见更容易检测，但模型难以处理某些偏见类型，例如，认知和政治偏见。但是，我们的结果表明，没有单一技术可以显着优于其他技术。我们还发现研究兴趣和资源分配在媒体偏见识别的个别任务上存在不均匀分布。",
    "tldr": "这篇论文介绍了MBIB，一个将不同类型媒体偏见分为共同框架的全面基准测试，并提供了相关数据集以评估媒体偏见检测技术，结果显示没有单一技术可以显著优于其他技术，同时发现研究兴趣和资源分配不均匀分布。",
    "en_tdlr": "This paper introduces MBIB, a comprehensive benchmark grouping different types of media bias under a common framework, and proposes relevant datasets for evaluating media bias detection techniques. Results suggest that no single technique outperforms all others significantly, and also highlight an uneven distribution of research interest and resource allocation to individual tasks in media bias identification."
}