{
    "title": "An Adaptive Policy to Employ Sharpness-Aware Minimization. (arXiv:2304.14647v1 [cs.LG])",
    "abstract": "Sharpness-aware minimization (SAM), which searches for flat minima by min-max optimization, has been shown to be useful in improving model generalization. However, since each SAM update requires computing two gradients, its computational cost and training time are both doubled compared to standard empirical risk minimization (ERM). Recent state-of-the-arts reduce the fraction of SAM updates and thus accelerate SAM by switching between SAM and ERM updates randomly or periodically. In this paper, we design an adaptive policy to employ SAM based on the loss landscape geometry. Two efficient algorithms, AE-SAM and AE-LookSAM, are proposed. We theoretically show that AE-SAM has the same convergence rate as SAM. Experimental results on various datasets and architectures demonstrate the efficiency and effectiveness of the adaptive policy.",
    "link": "http://arxiv.org/abs/2304.14647",
    "context": "Title: An Adaptive Policy to Employ Sharpness-Aware Minimization. (arXiv:2304.14647v1 [cs.LG])\nAbstract: Sharpness-aware minimization (SAM), which searches for flat minima by min-max optimization, has been shown to be useful in improving model generalization. However, since each SAM update requires computing two gradients, its computational cost and training time are both doubled compared to standard empirical risk minimization (ERM). Recent state-of-the-arts reduce the fraction of SAM updates and thus accelerate SAM by switching between SAM and ERM updates randomly or periodically. In this paper, we design an adaptive policy to employ SAM based on the loss landscape geometry. Two efficient algorithms, AE-SAM and AE-LookSAM, are proposed. We theoretically show that AE-SAM has the same convergence rate as SAM. Experimental results on various datasets and architectures demonstrate the efficiency and effectiveness of the adaptive policy.",
    "path": "papers/23/04/2304.14647.json",
    "total_tokens": 879,
    "translated_title": "一种自适应策略用于利用SAM算法进行锐度感知型优化",
    "translated_abstract": "研究表明，利用锐度感知型优化(SAM)通过最小化过程中的锐度寻求平坦极小值，在改善模型泛化能力方面具有一定的实用性。但是，与标准经验风险最小化(ERM)相比，每次SAM更新需要计算两个梯度，其计算成本和训练时间都增加了一倍。最近的方法通过随机或定期在SAM更新和ERM更新之间进行切换，从而减少SAM更新的比例，加速SAM。本文设计了一种自适应策略，基于损失函数的几何形状来应用SAM。提出了两种高效的算法，AE-SAM和AE-LookSAM。我们理论上证明了AE-SAM具有与SAM相同的收敛速度。在各种数据集和架构上的实验结果表明了自适应策略的效率和有效性。",
    "tldr": "本研究提出了一种自适应策略，基于损失函数的形状，用于设计高效的锐度感知优化算法SAM。采用AE-SAM和AE-LookSAM两种算法，理论上证明AE-SAM具有与SAM相同的收敛速度。实验结果表明这一策略的高效和有效。",
    "en_tdlr": "This paper proposes an adaptive policy using the sharpness-aware optimization algorithm SAM based on the loss function's geometry. The AE-SAM and AE-LookSAM algorithms are introduced, and it is theoretically shown that AE-SAM has the same convergence rate as SAM. Experimental results demonstrate the efficiency and effectiveness of the adaptive policy."
}