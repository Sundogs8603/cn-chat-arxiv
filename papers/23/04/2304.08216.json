{
    "title": "Context-Dependent Embedding Utterance Representations for Emotion Recognition in Conversations. (arXiv:2304.08216v2 [cs.CL] UPDATED)",
    "abstract": "Emotion Recognition in Conversations (ERC) has been gaining increasing importance as conversational agents become more and more common. Recognizing emotions is key for effective communication, being a crucial component in the development of effective and empathetic conversational agents. Knowledge and understanding of the conversational context are extremely valuable for identifying the emotions of the interlocutor. We thus approach Emotion Recognition in Conversations leveraging the conversational context, i.e., taking into attention previous conversational turns. The usual approach to model the conversational context has been to produce context-independent representations of each utterance and subsequently perform contextual modeling of these. Here we propose context-dependent embedding representations of each utterance by leveraging the contextual representational power of pre-trained transformer language models. In our approach, we feed the conversational context appended to the ut",
    "link": "http://arxiv.org/abs/2304.08216",
    "context": "Title: Context-Dependent Embedding Utterance Representations for Emotion Recognition in Conversations. (arXiv:2304.08216v2 [cs.CL] UPDATED)\nAbstract: Emotion Recognition in Conversations (ERC) has been gaining increasing importance as conversational agents become more and more common. Recognizing emotions is key for effective communication, being a crucial component in the development of effective and empathetic conversational agents. Knowledge and understanding of the conversational context are extremely valuable for identifying the emotions of the interlocutor. We thus approach Emotion Recognition in Conversations leveraging the conversational context, i.e., taking into attention previous conversational turns. The usual approach to model the conversational context has been to produce context-independent representations of each utterance and subsequently perform contextual modeling of these. Here we propose context-dependent embedding representations of each utterance by leveraging the contextual representational power of pre-trained transformer language models. In our approach, we feed the conversational context appended to the ut",
    "path": "papers/23/04/2304.08216.json",
    "total_tokens": 924,
    "translated_title": "上下文依赖性嵌入话语表示在对话情绪识别中的应用",
    "translated_abstract": "随着对话代理变得越来越普遍，对话情绪识别（ERC）越来越重要。识别情感对于有效的交流至关重要，是开发有效并且具有共情能力的对话代理的重要组成部分。对话背景的知识和理解对于识别交流者的情感非常有价值。因此，我们利用对话背景来进行ERC，即关注先前的对话回合。通常，建模对话上下文的方法是产生每个话语的上下文无关表示，然后对这些话语进行上下文模型处理。本文提出了利用预训练变换器语言模型的上下文依赖性嵌入话语表示。在我们的方法中，我们将对话背景追加到话语中，然后将其馈入基于变换器的模型中，该模型将产生相应的上下文嵌入表示。我们在三个公共数据集上评估了我们的方法，并证明在与上下文无关方法和最先进的模型相比中具有很好的效果。",
    "tldr": "本论文利用预训练变换器语言模型的上下文依赖性嵌入话语表示，从而在对话情绪识别中取得了非常良好的效果。",
    "en_tdlr": "This paper proposes a context-dependent embedding representation of utterances using pre-trained transformer language models for Emotion Recognition in Conversations, which outperforms context-independent approaches and state-of-the-art models on three public datasets."
}