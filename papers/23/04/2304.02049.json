{
    "title": "Multi-Class Explainable Unlearning for Image Classification via Weight Filtering. (arXiv:2304.02049v1 [cs.CV])",
    "abstract": "Machine Unlearning has recently been emerging as a paradigm for selectively removing the impact of training datapoints from a network. While existing approaches have focused on unlearning either a small subset of the training data or a single class, in this paper we take a different path and devise a framework that can unlearn all classes of an image classification network in a single untraining round. Our proposed technique learns to modulate the inner components of an image classification network through memory matrices so that, after training, the same network can selectively exhibit an unlearning behavior over any of the classes. By discovering weights which are specific to each of the classes, our approach also recovers a representation of the classes which is explainable by-design. We test the proposed framework, which we name Weight Filtering network (WF-Net), on small-scale and medium-scale image classification datasets, with both CNN and Transformer-based backbones. Our work p",
    "link": "http://arxiv.org/abs/2304.02049",
    "context": "Title: Multi-Class Explainable Unlearning for Image Classification via Weight Filtering. (arXiv:2304.02049v1 [cs.CV])\nAbstract: Machine Unlearning has recently been emerging as a paradigm for selectively removing the impact of training datapoints from a network. While existing approaches have focused on unlearning either a small subset of the training data or a single class, in this paper we take a different path and devise a framework that can unlearn all classes of an image classification network in a single untraining round. Our proposed technique learns to modulate the inner components of an image classification network through memory matrices so that, after training, the same network can selectively exhibit an unlearning behavior over any of the classes. By discovering weights which are specific to each of the classes, our approach also recovers a representation of the classes which is explainable by-design. We test the proposed framework, which we name Weight Filtering network (WF-Net), on small-scale and medium-scale image classification datasets, with both CNN and Transformer-based backbones. Our work p",
    "path": "papers/23/04/2304.02049.json",
    "total_tokens": 870,
    "translated_title": "基于权重滤波的多类可解释性卸载图像分类",
    "translated_abstract": "机器卸载是最近浮现的一种选择性地将训练数据点的影响从网络中删除的范式。尽管现有方法已经集中在卸载训练数据的小子集或单个类别，但在本文中，我们采取了不同的方法，设计了一个框架，可以在单个未训练轮中取消学习图像分类网络的所有类别。我们提出的方法通过内部组件的记忆矩阵来调节图像分类网络，以便在训练后，同一网络可以有选择地展示任何类别的未学习行为。通过发现每个类别特定的权重，我们的方法还通过设计可解释性机制来恢复类别的表示。我们在小规模和中规模图像分类数据集上使用CNN和Transformer-based骨架测试了提出的框架。我们的工作提供了一种多类可解释性卸载的解决方案。",
    "tldr": "本论文提出一种基于权重滤波的多类可解释性卸载图像分类方法，可以在单个未训练轮中取消学习网络的所有类别，并且恢复可解释的类别表示。",
    "en_tdlr": "This paper proposes a multi-class explainable unlearning approach for image classification via weight filtering, which can unlearn all classes of a network in a single round and recover an explainable representation of the classes by discovering specific weights for each class. The proposed framework is tested on small and medium-scale datasets with both CNN and Transformer-based backbones."
}