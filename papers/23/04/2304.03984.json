{
    "title": "DREAM: Adaptive Reinforcement Learning based on Attention Mechanism for Temporal Knowledge Graph Reasoning. (arXiv:2304.03984v1 [cs.AI])",
    "abstract": "Temporal knowledge graphs (TKGs) model the temporal evolution of events and have recently attracted increasing attention. Since TKGs are intrinsically incomplete, it is necessary to reason out missing elements. Although existing TKG reasoning methods have the ability to predict missing future events, they fail to generate explicit reasoning paths and lack explainability. As reinforcement learning (RL) for multi-hop reasoning on traditional knowledge graphs starts showing superior explainability and performance in recent advances, it has opened up opportunities for exploring RL techniques on TKG reasoning. However, the performance of RL-based TKG reasoning methods is limited due to: (1) lack of ability to capture temporal evolution and semantic dependence jointly; (2) excessive reliance on manually designed rewards. To overcome these challenges, we propose an adaptive reinforcement learning model based on attention mechanism (DREAM) to predict missing elements in the future. Specificall",
    "link": "http://arxiv.org/abs/2304.03984",
    "context": "Title: DREAM: Adaptive Reinforcement Learning based on Attention Mechanism for Temporal Knowledge Graph Reasoning. (arXiv:2304.03984v1 [cs.AI])\nAbstract: Temporal knowledge graphs (TKGs) model the temporal evolution of events and have recently attracted increasing attention. Since TKGs are intrinsically incomplete, it is necessary to reason out missing elements. Although existing TKG reasoning methods have the ability to predict missing future events, they fail to generate explicit reasoning paths and lack explainability. As reinforcement learning (RL) for multi-hop reasoning on traditional knowledge graphs starts showing superior explainability and performance in recent advances, it has opened up opportunities for exploring RL techniques on TKG reasoning. However, the performance of RL-based TKG reasoning methods is limited due to: (1) lack of ability to capture temporal evolution and semantic dependence jointly; (2) excessive reliance on manually designed rewards. To overcome these challenges, we propose an adaptive reinforcement learning model based on attention mechanism (DREAM) to predict missing elements in the future. Specificall",
    "path": "papers/23/04/2304.03984.json",
    "total_tokens": 859,
    "translated_title": "DREAM: 自适应注意力机制强化学习用于时间知识图谱推理",
    "translated_abstract": "时间知识图谱（TKG）模型描绘了事件的时间演化，近来备受关注。由于TKG固有的不完备性，需要推理出缺失的元素。虽然现有的TKG推理方法能够预测缺失的未来事件，但是缺乏显式的推理路径和可解释性。由于传统知识图谱上的强化学习（RL）多跳推理在最近的进展中显示出优越的可解释性和性能，因此在TKG推理上探索RL技术的机会已经开启。然而，基于RL的TKG推理方法的性能受到以下限制：（1）缺乏同时捕捉时间演化和语义依赖的能力；（2）过度依赖手动设计的奖励。为了克服这些挑战，我们提出了一种基于注意力机制的自适应强化学习模型（DREAM）来预测未来的缺失元素。具体地说，",
    "tldr": "DREAM提出了一种自适应的强化学习模型，基于注意力机制用于时间知识图谱推理，能够预测未来的缺失元素和理解推理路径。",
    "en_tdlr": "DREAM proposes an adaptive RL model based on attention mechanism for TKG reasoning, which can predict missing future elements and understand reasoning paths."
}