{
    "title": "How to choose your best allies for a transferable attack?. (arXiv:2304.02312v1 [cs.CR])",
    "abstract": "The transferability of adversarial examples is a key issue in the security of deep neural networks. The possibility of an adversarial example crafted for a source model fooling another targeted model makes the threat of adversarial attacks more realistic. Measuring transferability is a crucial problem, but the Attack Success Rate alone does not provide a sound evaluation. This paper proposes a new methodology for evaluating transferability by putting distortion in a central position. This new tool shows that transferable attacks may perform far worse than a black box attack if the attacker randomly picks the source model. To address this issue, we propose a new selection mechanism, called FiT, which aims at choosing the best source model with only a few preliminary queries to the target. Our experimental results show that FiT is highly effective at selecting the best source model for multiple scenarios such as single-model attacks, ensemble-model attacks and multiple attacks (Code avai",
    "link": "http://arxiv.org/abs/2304.02312",
    "context": "Title: How to choose your best allies for a transferable attack?. (arXiv:2304.02312v1 [cs.CR])\nAbstract: The transferability of adversarial examples is a key issue in the security of deep neural networks. The possibility of an adversarial example crafted for a source model fooling another targeted model makes the threat of adversarial attacks more realistic. Measuring transferability is a crucial problem, but the Attack Success Rate alone does not provide a sound evaluation. This paper proposes a new methodology for evaluating transferability by putting distortion in a central position. This new tool shows that transferable attacks may perform far worse than a black box attack if the attacker randomly picks the source model. To address this issue, we propose a new selection mechanism, called FiT, which aims at choosing the best source model with only a few preliminary queries to the target. Our experimental results show that FiT is highly effective at selecting the best source model for multiple scenarios such as single-model attacks, ensemble-model attacks and multiple attacks (Code avai",
    "path": "papers/23/04/2304.02312.json",
    "total_tokens": 899,
    "translated_title": "如何选择最佳的盟友进行可转移攻击？",
    "translated_abstract": "对抗样本的可转移性是深度神经网络安全中的一个关键问题。一个为源模型而制造的对抗样本可以欺骗另一个目标模型，使对抗攻击的威胁更加真实。衡量可转移性是一个关键问题，但攻击成功率本身并不能提供坚实的评估。本文提出了一种评估可转移性的新方法，将畸变放置于中心位置。这个新工具显示，如果攻击者随机选择源模型，那么可转移攻击的表现可能远远不及黑盒攻击。为了解决这个问题，我们提出了一种新的选择机制，称为FiT，该机制旨在通过只进行几个初步查询即可选择最佳的源模型。我们的实验结果表明，FiT在选择多个攻击情境下的最佳源模型方面非常有效，例如单一模型攻击、集成模型攻击和多攻击（代码可在https://github.com/weny1choi/FiT中找到）。",
    "tldr": "本文提出了一种新方法来评估可转移性，通过将畸变放置于中心位置并提出了一种新的选择机制FiT，该机制旨在通过只进行几个初步查询即可选择最佳的源模型。",
    "en_tdlr": "This paper proposes a new methodology for evaluating transferability by putting distortion in a central position and proposes a new selection mechanism named FiT, which aims at choosing the best source model with only a few preliminary queries to the target."
}