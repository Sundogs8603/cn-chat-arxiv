{
    "title": "Uncovering the Representation of Spiking Neural Networks Trained with Surrogate Gradient. (arXiv:2304.13098v1 [cs.LG])",
    "abstract": "Spiking Neural Networks (SNNs) are recognized as the candidate for the next-generation neural networks due to their bio-plausibility and energy efficiency. Recently, researchers have demonstrated that SNNs are able to achieve nearly state-of-the-art performance in image recognition tasks using surrogate gradient training. However, some essential questions exist pertaining to SNNs that are little studied: Do SNNs trained with surrogate gradient learn different representations from traditional Artificial Neural Networks (ANNs)? Does the time dimension in SNNs provide unique representation power? In this paper, we aim to answer these questions by conducting a representation similarity analysis between SNNs and ANNs using Centered Kernel Alignment (CKA). We start by analyzing the spatial dimension of the networks, including both the width and the depth. Furthermore, our analysis of residual connections shows that SNNs learn a periodic pattern, which rectifies the representations in SNNs to",
    "link": "http://arxiv.org/abs/2304.13098",
    "context": "Title: Uncovering the Representation of Spiking Neural Networks Trained with Surrogate Gradient. (arXiv:2304.13098v1 [cs.LG])\nAbstract: Spiking Neural Networks (SNNs) are recognized as the candidate for the next-generation neural networks due to their bio-plausibility and energy efficiency. Recently, researchers have demonstrated that SNNs are able to achieve nearly state-of-the-art performance in image recognition tasks using surrogate gradient training. However, some essential questions exist pertaining to SNNs that are little studied: Do SNNs trained with surrogate gradient learn different representations from traditional Artificial Neural Networks (ANNs)? Does the time dimension in SNNs provide unique representation power? In this paper, we aim to answer these questions by conducting a representation similarity analysis between SNNs and ANNs using Centered Kernel Alignment (CKA). We start by analyzing the spatial dimension of the networks, including both the width and the depth. Furthermore, our analysis of residual connections shows that SNNs learn a periodic pattern, which rectifies the representations in SNNs to",
    "path": "papers/23/04/2304.13098.json",
    "total_tokens": 998,
    "translated_title": "用替代梯度训练的脉冲神经网络的表示学习探究",
    "translated_abstract": "脉冲神经网络（SNN）由于其类生物特性和能量效率而被认为是下一代神经网络的候选者。最近的研究表明，使用替代梯度训练，SNN能够在图像识别任务中实现接近于最先进水平的性能。然而，关于SNN的一些基本问题尚未得到充分研究，如：使用替代梯度训练的SNN是否学习了不同于传统的人工神经网络（ANN）的表示学习？SNN中的时间维度是否提供了独特的表示学习能力？本文旨在通过使用中心核对齐（CKA）进行SNN和ANN之间的表示相似性分析来回答这些问题。我们首先分析网络的空间维度，包括宽度和深度。此外，我们发现SNN学习了周期模式的残差连接，从而使SNN的表示类似于ANN。此外，我们发现SNN中的时间维度提供了在ANN中不存在的独特的表示学习能力。",
    "tldr": "本研究使用中心核对齐分析了使用替代梯度训练的脉冲神经网络（SNN）与传统人工神经网络（ANN）之间的表示相似性，并发现SNN中的时间维度提供了独特的表示学习能力。",
    "en_tdlr": "This paper explores the representation learning of spiking neural networks (SNNs) trained with surrogate gradient, and finds that the time dimension in SNNs provides unique representation power. The findings are based on a representation similarity analysis using Centered Kernel Alignment (CKA), which compares SNNs and traditional Artificial Neural Networks (ANNs)."
}