{
    "title": "A Survey on Biomedical Text Summarization with Pre-trained Language Model. (arXiv:2304.08763v1 [cs.CL])",
    "abstract": "The exponential growth of biomedical texts such as biomedical literature and electronic health records (EHRs), provides a big challenge for clinicians and researchers to access clinical information efficiently. To address the problem, biomedical text summarization has been proposed to support clinical information retrieval and management, aiming at generating concise summaries that distill key information from single or multiple biomedical documents. In recent years, pre-trained language models (PLMs) have been the de facto standard of various natural language processing tasks in the general domain. Most recently, PLMs have been further investigated in the biomedical field and brought new insights into the biomedical text summarization task. In this paper, we systematically summarize recent advances that explore PLMs for biomedical text summarization, to help understand recent progress, challenges, and future directions. We categorize PLMs-based approaches according to how they utilize",
    "link": "http://arxiv.org/abs/2304.08763",
    "context": "Title: A Survey on Biomedical Text Summarization with Pre-trained Language Model. (arXiv:2304.08763v1 [cs.CL])\nAbstract: The exponential growth of biomedical texts such as biomedical literature and electronic health records (EHRs), provides a big challenge for clinicians and researchers to access clinical information efficiently. To address the problem, biomedical text summarization has been proposed to support clinical information retrieval and management, aiming at generating concise summaries that distill key information from single or multiple biomedical documents. In recent years, pre-trained language models (PLMs) have been the de facto standard of various natural language processing tasks in the general domain. Most recently, PLMs have been further investigated in the biomedical field and brought new insights into the biomedical text summarization task. In this paper, we systematically summarize recent advances that explore PLMs for biomedical text summarization, to help understand recent progress, challenges, and future directions. We categorize PLMs-based approaches according to how they utilize",
    "path": "papers/23/04/2304.08763.json",
    "total_tokens": 995,
    "translated_title": "基于预训练语言模型的生物医学文本摘要综述",
    "translated_abstract": "生物医学文献和电子病历等生物医学文本的指数级增长，给临床医生和研究人员高效获取临床信息带来巨大挑战。为解决这一问题，提出了生物医学文本摘要方法，旨在从单个或多个生物医学文档中提炼关键信息生成简洁的摘要。近年来，预训练语言模型（PLMs）已成为多种自然语言处理任务的事实标准，PLMs在生物医学领域中的应用也为生物医学文本摘要任务带来新的启示。本文系统地总结了近期基于PLMs探索生物医学文本摘要的进展，帮助理解最新的进展、挑战和未来方向。我们根据使用PLMs的方式对基于PLMs的方法进行分类，包括微调、基于特征和无监督方法。我们还讨论了潜在的未来研究方向，如融合领域特定知识和开发更适合的评估指标。",
    "tldr": "本文总结了基于预训练语言模型的生物医学文本摘要方法，提炼关键信息生成简洁的摘要，分为微调、基于特征和无监督方法，未来研究方向包括融合领域特定知识和开发更适合的评估指标。",
    "en_tdlr": "This paper systematically summarizes recent advances in biomedical text summarization utilizing pre-trained language models (PLMs) and categorizes PLMs-based approaches into fine-tuning, feature-based, and unsupervised methods. Potential future research directions, such as incorporating domain-specific knowledge and developing more suitable evaluation metrics, are also discussed."
}