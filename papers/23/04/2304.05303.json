{
    "title": "ELVIS: Empowering Locality of Vision Language Pre-training with Intra-modal Similarity. (arXiv:2304.05303v1 [cs.CV])",
    "abstract": "Deep learning has shown great potential in assisting radiologists in reading chest X-ray (CXR) images, but its need for expensive annotations for improving performance prevents widespread clinical application. Visual language pre-training (VLP) can alleviate the burden and cost of annotation by leveraging routinely generated reports for radiographs, which exist in large quantities as well as in paired form (imagetext pairs). Additionally, extensions to localization-aware VLPs are being proposed to address the needs of accurate localization of abnormalities for CAD in CXR. However, we find that the formulation proposed by locality-aware VLP literatures actually leads to loss in spatial relationships required for downstream localization tasks. Therefore, we propose Empowering Locality of VLP with Intra-modal Similarity, ELVIS, a VLP aware of intra-modal locality, to better preserve the locality within radiographs or reports, which enhances the ability to comprehend location references in",
    "link": "http://arxiv.org/abs/2304.05303",
    "context": "Title: ELVIS: Empowering Locality of Vision Language Pre-training with Intra-modal Similarity. (arXiv:2304.05303v1 [cs.CV])\nAbstract: Deep learning has shown great potential in assisting radiologists in reading chest X-ray (CXR) images, but its need for expensive annotations for improving performance prevents widespread clinical application. Visual language pre-training (VLP) can alleviate the burden and cost of annotation by leveraging routinely generated reports for radiographs, which exist in large quantities as well as in paired form (imagetext pairs). Additionally, extensions to localization-aware VLPs are being proposed to address the needs of accurate localization of abnormalities for CAD in CXR. However, we find that the formulation proposed by locality-aware VLP literatures actually leads to loss in spatial relationships required for downstream localization tasks. Therefore, we propose Empowering Locality of VLP with Intra-modal Similarity, ELVIS, a VLP aware of intra-modal locality, to better preserve the locality within radiographs or reports, which enhances the ability to comprehend location references in",
    "path": "papers/23/04/2304.05303.json",
    "total_tokens": 902,
    "translated_title": "ELVIS: 利用模态内相似性增强视觉语言预训练中的局部性能力",
    "translated_abstract": "深度学习在辅助放射科医生阅读胸部 X 射线图像方面表现出巨大潜力，但其需要昂贵的注释来提高性能，这阻碍了其广泛的临床应用。视觉语言预训练（VLP）可以通过利用常规生成的放射学报告进行训练，从而减轻注释的负担和成本，这些报告以成对的形式（图像-文本对）大量存在。此外，正在提出扩展到定位感知VLP，以满足CAD在CXR的准确异常定位需求。然而，我们发现由局部性VLP文献提出的公式实际上导致了下游定位任务所需的空间关系的丢失。因此，我们提出了Empowering Locality of VLP with Intra-modal Similarity（ELVIS），这是一种VLP，可感知模态内部的局部性能力，以更好地保留放射学报告或 X 射线图像中的局部性能力，从而提高了理解位置参考的能力。",
    "tldr": "本文提出了一种新的视觉语言预训练方法，称为ELVIS，可以增强放射学报告或 X 射线图像中的局部性能力，提高了理解位置参考的能力。",
    "en_tdlr": "This paper proposes a new method for visual language pre-training, ELVIS, which enhances the locality within radiographs or reports, and improves the ability to comprehend location references."
}