{
    "title": "Mixed Regression via Approximate Message Passing. (arXiv:2304.02229v1 [stat.ML])",
    "abstract": "We study the problem of regression in a generalized linear model (GLM) with multiple signals and latent variables. This model, which we call a matrix GLM, covers many widely studied problems in statistical learning, including mixed linear regression, max-affine regression, and mixture-of-experts. In mixed linear regression, each observation comes from one of $L$ signal vectors (regressors), but we do not know which one; in max-affine regression, each observation comes from the maximum of $L$ affine functions, each defined via a different signal vector. The goal in all these problems is to estimate the signals, and possibly some of the latent variables, from the observations. We propose a novel approximate message passing (AMP) algorithm for estimation in a matrix GLM and rigorously characterize its performance in the high-dimensional limit. This characterization is in terms of a state evolution recursion, which allows us to precisely compute performance measures such as the asymptotic ",
    "link": "http://arxiv.org/abs/2304.02229",
    "context": "Title: Mixed Regression via Approximate Message Passing. (arXiv:2304.02229v1 [stat.ML])\nAbstract: We study the problem of regression in a generalized linear model (GLM) with multiple signals and latent variables. This model, which we call a matrix GLM, covers many widely studied problems in statistical learning, including mixed linear regression, max-affine regression, and mixture-of-experts. In mixed linear regression, each observation comes from one of $L$ signal vectors (regressors), but we do not know which one; in max-affine regression, each observation comes from the maximum of $L$ affine functions, each defined via a different signal vector. The goal in all these problems is to estimate the signals, and possibly some of the latent variables, from the observations. We propose a novel approximate message passing (AMP) algorithm for estimation in a matrix GLM and rigorously characterize its performance in the high-dimensional limit. This characterization is in terms of a state evolution recursion, which allows us to precisely compute performance measures such as the asymptotic ",
    "path": "papers/23/04/2304.02229.json",
    "total_tokens": 841,
    "translated_title": "通过近似消息传递的混合回归（Mixed Regression via Approximate Message Passing）",
    "translated_abstract": "本文研究了广义线性模型（GLM）中具有多个信号和潜变量的回归问题。该模型被称为矩阵GLM，涵盖了许多在统计学习中广泛研究的问题，包括混合线性回归、最大仿射回归和专家混合模型等。我们提出了一种新的近似消息传递（AMP）算法来估计矩阵GLM中的信号和潜变量，并在高维极限中对其性能进行了严格的表征。该表征是通过状态演化递归来计算的，从而可以精确计算渐近性能度量，例如信噪比下降阈值（threshold）。",
    "tldr": "本文提出了一种新的近似消息传递算法来解决在广义线性模型中的回归问题，该算法适用于混合线性回归、最大仿射回归和专家混合模型等问题。",
    "en_tdlr": "This paper presents a novel approximate message passing algorithm for regression in a generalized linear model with multiple signals and latent variables, which covers many widely studied problems in statistical learning, including mixed linear regression, max-affine regression, and mixture-of-experts. Rigorous characterization of its high-dimensional performance is provided in terms of a state evolution recursion."
}