{
    "title": "Those Aren't Your Memories, They're Somebody Else's: Seeding Misinformation in Chat Bot Memories. (arXiv:2304.05371v1 [cs.CL])",
    "abstract": "One of the new developments in chit-chat bots is a long-term memory mechanism that remembers information from past conversations for increasing engagement and consistency of responses. The bot is designed to extract knowledge of personal nature from their conversation partner, e.g., stating preference for a particular color. In this paper, we show that this memory mechanism can result in unintended behavior. In particular, we found that one can combine a personal statement with an informative statement that would lead the bot to remember the informative statement alongside personal knowledge in its long term memory. This means that the bot can be tricked into remembering misinformation which it would regurgitate as statements of fact when recalling information relevant to the topic of conversation. We demonstrate this vulnerability on the BlenderBot 2 framework implemented on the ParlAI platform and provide examples on the more recent and significantly larger BlenderBot 3 model. We gen",
    "link": "http://arxiv.org/abs/2304.05371",
    "context": "Title: Those Aren't Your Memories, They're Somebody Else's: Seeding Misinformation in Chat Bot Memories. (arXiv:2304.05371v1 [cs.CL])\nAbstract: One of the new developments in chit-chat bots is a long-term memory mechanism that remembers information from past conversations for increasing engagement and consistency of responses. The bot is designed to extract knowledge of personal nature from their conversation partner, e.g., stating preference for a particular color. In this paper, we show that this memory mechanism can result in unintended behavior. In particular, we found that one can combine a personal statement with an informative statement that would lead the bot to remember the informative statement alongside personal knowledge in its long term memory. This means that the bot can be tricked into remembering misinformation which it would regurgitate as statements of fact when recalling information relevant to the topic of conversation. We demonstrate this vulnerability on the BlenderBot 2 framework implemented on the ParlAI platform and provide examples on the more recent and significantly larger BlenderBot 3 model. We gen",
    "path": "papers/23/04/2304.05371.json",
    "total_tokens": 876,
    "translated_title": "那不是你的记忆，它是别人的：在聊天机器人记忆中播撒错误信息",
    "translated_abstract": "聊天机器人的一个新发展是长期记忆机制，可以记住过去对话中的信息，以增加响应的连贯性和一致性。机器人被设计为从其对话伙伴中提取个人性质的知识，例如表明对特定颜色的偏好。在本文中，我们展示了这种记忆机制可能会导致意外行为。具体而言，我们发现一个人可以将个人陈述与信息陈述结合起来，导致机器人将信息陈述与个人知识一起记录在其长期记忆中。这意味着机器人可能被欺骗记住错误信息，并在回忆与对话主题相关的信息时将其作为事实陈述重复。我们在基于ParlAI平台实现的BlenderBot 2框架上展示了这种漏洞，并在更近期、规模更大的BlenderBot 3模型上提供了例子。",
    "tldr": "本文研究了聊天机器人的一个新发展：长期记忆机制。然而，我们发现这种机制可能会导致机器人记住了错误和虚假的信息，并将其作为事实陈述重复。",
    "en_tdlr": "This paper investigates a new development in chit-chat bots: the long-term memory mechanism. However, the study found that this mechanism may lead to bots remembering false and misleading information, which they would then regurgitate as statements of fact."
}