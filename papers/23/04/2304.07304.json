{
    "title": "Explaining, Analyzing, and Probing Representations of Self-Supervised Learning Models for Sensor-based Human Activity Recognition. (arXiv:2304.07304v1 [cs.LG])",
    "abstract": "In recent years, self-supervised learning (SSL) frameworks have been extensively applied to sensor-based Human Activity Recognition (HAR) in order to learn deep representations without data annotations. While SSL frameworks reach performance almost comparable to supervised models, studies on interpreting representations learnt by SSL models are limited. Nevertheless, modern explainability methods could help to unravel the differences between SSL and supervised representations: how they are being learnt, what properties of input data they preserve, and when SSL can be chosen over supervised training. In this paper, we aim to analyze deep representations of two recent SSL frameworks, namely SimCLR and VICReg. Specifically, the emphasis is made on (i) comparing the robustness of supervised and SSL models to corruptions in input data; (ii) explaining predictions of deep learning models using saliency maps and highlighting what input channels are mostly used for predicting various activitie",
    "link": "http://arxiv.org/abs/2304.07304",
    "context": "Title: Explaining, Analyzing, and Probing Representations of Self-Supervised Learning Models for Sensor-based Human Activity Recognition. (arXiv:2304.07304v1 [cs.LG])\nAbstract: In recent years, self-supervised learning (SSL) frameworks have been extensively applied to sensor-based Human Activity Recognition (HAR) in order to learn deep representations without data annotations. While SSL frameworks reach performance almost comparable to supervised models, studies on interpreting representations learnt by SSL models are limited. Nevertheless, modern explainability methods could help to unravel the differences between SSL and supervised representations: how they are being learnt, what properties of input data they preserve, and when SSL can be chosen over supervised training. In this paper, we aim to analyze deep representations of two recent SSL frameworks, namely SimCLR and VICReg. Specifically, the emphasis is made on (i) comparing the robustness of supervised and SSL models to corruptions in input data; (ii) explaining predictions of deep learning models using saliency maps and highlighting what input channels are mostly used for predicting various activitie",
    "path": "papers/23/04/2304.07304.json",
    "total_tokens": 930,
    "translated_title": "自监督学习模型在基于传感器的人类活动识别中的表达解释、分析和探究",
    "translated_abstract": "近年来，自监督学习（SSL）框架被广泛应用于基于传感器的人类活动识别（HAR），以便学习深度表示而不需要数据注释。虽然SSL框架的性能几乎与监督模型相当，但对SSL模型学习的表示进行解释的研究却很有限。然而，现代解释方法可以帮助揭示SSL表示与监督表示之间的差异：它们是如何被学习的、它们保留了哪些输入数据属性，以及何时可以选择SSL进行训练。本文旨在分析两个最近的SSL框架SimCLR和VICReg的深度表示。具体而言，重点放在以下几个方面：(i) 比较监督和SSL模型对输入数据中的破坏的鲁棒性；(ii) 使用显著图解释深度学习模型的预测，并突出显示用于预测各种活动的主要输入通道。",
    "tldr": "本文探究了基于传感器的人类活动识别中自监督学习框架的深度表示，通过解释这些表示与有监督表示的区别，比较它们的鲁棒性，并使用显著图将其应用于预测不同的活动。",
    "en_tdlr": "This paper explores the deep representations of self-supervised learning frameworks in sensor-based human activity recognition. By explaining the differences between these representations and supervised representations, it compares their robustness and applies saliency maps to predict different activities."
}