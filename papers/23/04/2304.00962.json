{
    "title": "RegionPLC: Regional Point-Language Contrastive Learning for Open-World 3D Scene Understanding. (arXiv:2304.00962v2 [cs.CV] UPDATED)",
    "abstract": "Existing 3D scene understanding tasks have achieved high performance on close-set benchmarks but fail to handle novel categories in real-world applications. To this end, we propose a Regional Point-Language Contrastive learning framework, namely RegionPLC, for open-world 3D scene understanding, which equips models trained on closed-set datasets with open-vocabulary recognition capabilities. We propose dense visual prompts to elicit region-level visual-language knowledge from 2D foundation models via captioning, which further allows us to build dense regional point-language associations. Then, we design a point-discriminative contrastive learning objective to enable point-independent learning from captions for dense scene understanding. We conduct extensive experiments on ScanNet, ScanNet200, and nuScenes datasets. Our RegionPLC significantly outperforms previous base-annotated 3D open-world scene understanding approaches by an average of 11.6\\% and 6.6\\% for semantic and instance segme",
    "link": "http://arxiv.org/abs/2304.00962",
    "context": "Title: RegionPLC: Regional Point-Language Contrastive Learning for Open-World 3D Scene Understanding. (arXiv:2304.00962v2 [cs.CV] UPDATED)\nAbstract: Existing 3D scene understanding tasks have achieved high performance on close-set benchmarks but fail to handle novel categories in real-world applications. To this end, we propose a Regional Point-Language Contrastive learning framework, namely RegionPLC, for open-world 3D scene understanding, which equips models trained on closed-set datasets with open-vocabulary recognition capabilities. We propose dense visual prompts to elicit region-level visual-language knowledge from 2D foundation models via captioning, which further allows us to build dense regional point-language associations. Then, we design a point-discriminative contrastive learning objective to enable point-independent learning from captions for dense scene understanding. We conduct extensive experiments on ScanNet, ScanNet200, and nuScenes datasets. Our RegionPLC significantly outperforms previous base-annotated 3D open-world scene understanding approaches by an average of 11.6\\% and 6.6\\% for semantic and instance segme",
    "path": "papers/23/04/2304.00962.json",
    "total_tokens": 923,
    "translated_title": "RegionPLC：用于开放世界3D场景理解的区域点-语言对比学习",
    "translated_abstract": "现有的3D场景理解任务在闭集基准上取得了高性能，但在现实世界应用中无法处理新颖类别。为此，我们提出了一种称为RegionPLC的开放世界3D场景理解的区域点-语言对比学习框架，它使经过封闭集数据集训练的模型具备开放词汇识别能力。我们提出了密集的视觉提示，通过标题生成从2D基础模型中引发区域级视觉-语言知识，进而使我们能够建立密集的区域点-语言关联。然后，我们设计了一种点判别对比学习目标，使得从标题中进行点独立学习以实现密集场景理解。我们在ScanNet、ScanNet200和nuScenes数据集上进行了大量实验。相比之前的基于注释的3D开放世界场景理解方法，我们的RegionPLC在语义和实例分割方面的性能平均提高了11.6%和6.6%。",
    "tldr": "提出了一种用于开放世界3D场景理解的Regional Point-Language Contrastive Learning框架，通过密集的视觉提示和点独立对比学习来实现对新颖类别的识别和密集场景理解。",
    "en_tdlr": "RegionPLC is a framework for open-world 3D scene understanding that utilizes regional point-language contrastive learning. By generating dense visual prompts and utilizing a point-discriminative contrastive learning objective, it enables recognition of novel categories and dense scene understanding."
}