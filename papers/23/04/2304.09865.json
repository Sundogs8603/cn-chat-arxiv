{
    "title": "Safer Conversational AI as a Source of User Delight. (arXiv:2304.09865v1 [cs.HC])",
    "abstract": "This work explores the impact of moderation on users' enjoyment of conversational AI systems. While recent advancements in Large Language Models (LLMs) have led to highly capable conversational AIs that are increasingly deployed in real-world settings, there is a growing concern over AI safety and the need to moderate systems to encourage safe language and prevent harm. However, some users argue that current approaches to moderation limit the technology, compromise free expression, and limit the value delivered by the technology. This study takes an unbiased stance and shows that moderation does not necessarily detract from user enjoyment. Heavy handed moderation does seem to have a nefarious effect, but models that are moderated to be safer can lead to a better user experience. By deploying various conversational AIs in the Chai platform, the study finds that user retention can increase with a level of moderation and safe system design. These results demonstrate the importance of appr",
    "link": "http://arxiv.org/abs/2304.09865",
    "context": "Title: Safer Conversational AI as a Source of User Delight. (arXiv:2304.09865v1 [cs.HC])\nAbstract: This work explores the impact of moderation on users' enjoyment of conversational AI systems. While recent advancements in Large Language Models (LLMs) have led to highly capable conversational AIs that are increasingly deployed in real-world settings, there is a growing concern over AI safety and the need to moderate systems to encourage safe language and prevent harm. However, some users argue that current approaches to moderation limit the technology, compromise free expression, and limit the value delivered by the technology. This study takes an unbiased stance and shows that moderation does not necessarily detract from user enjoyment. Heavy handed moderation does seem to have a nefarious effect, but models that are moderated to be safer can lead to a better user experience. By deploying various conversational AIs in the Chai platform, the study finds that user retention can increase with a level of moderation and safe system design. These results demonstrate the importance of appr",
    "path": "papers/23/04/2304.09865.json",
    "total_tokens": 950,
    "translated_title": "安全的对话型AI作为用户喜悦的源泉",
    "translated_abstract": "本文研究了管理对话型AI系统对用户体验的影响。尽管近期在大规模语言模型的发展已经使得对话型AI系统在现实世界中得到了广泛应用，但对AI安全性的担忧以及需要对系统进行管理以鼓励安全用语和防止危害的需求也随之增加。然而，一些用户认为当前的管理方法限制了技术的发展、妥协了自由表达并且限制了技术所提供的价值。本研究采取客观的立场并显示出管理并不一定会影响到用户体验。粗暴的管理方式确实有负面影响，但是通过管理的方法使AI更安全可以带来更好的用户体验。通过将不同的对话型AI部署在Chai平台中，本研究发现通过适度管理和安全系统设计可以提高用户留存率。这些结果证明了采用AI安全机制构建能让用户喜悦的对话型AI的重要性。",
    "tldr": "本文研究了对话型AI系统管理对用户体验的影响。研究结果表明，通过适度的管理可以提高用户留存率，证明了采用AI安全机制构建能让用户喜悦的对话型AI的重要性。",
    "en_tdlr": "This paper explores the impact of moderation on users' enjoyment of conversational AI systems and demonstrates that moderation can actually improve the user experience. By deploying various conversational AIs in the Chai platform, the study finds that user retention can increase with a level of moderation and safe system design, highlighting the importance of approved AI safety mechanisms to build conversational AIs that can delight their users."
}