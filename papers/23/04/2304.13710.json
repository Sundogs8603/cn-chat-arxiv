{
    "title": "Hopfield model with planted patterns: a teacher-student self-supervised learning model. (arXiv:2304.13710v1 [cond-mat.dis-nn])",
    "abstract": "While Hopfield networks are known as paradigmatic models for memory storage and retrieval, modern artificial intelligence systems mainly stand on the machine learning paradigm. We show that it is possible to formulate a teacher-student self-supervised learning problem with Boltzmann machines in terms of a suitable generalization of the Hopfield model with structured patterns, where the spin variables are the machine weights and patterns correspond to the training set's examples. We analyze the learning performance by studying the phase diagram in terms of the training set size, the dataset noise and the inference temperature (i.e. the weight regularization). With a small but informative dataset the machine can learn by memorization. With a noisy dataset, an extensive number of examples above a critical threshold is needed. In this regime the memory storage limits of the system becomes an opportunity for the occurrence of a learning regime in which the system can generalize.",
    "link": "http://arxiv.org/abs/2304.13710",
    "context": "Title: Hopfield model with planted patterns: a teacher-student self-supervised learning model. (arXiv:2304.13710v1 [cond-mat.dis-nn])\nAbstract: While Hopfield networks are known as paradigmatic models for memory storage and retrieval, modern artificial intelligence systems mainly stand on the machine learning paradigm. We show that it is possible to formulate a teacher-student self-supervised learning problem with Boltzmann machines in terms of a suitable generalization of the Hopfield model with structured patterns, where the spin variables are the machine weights and patterns correspond to the training set's examples. We analyze the learning performance by studying the phase diagram in terms of the training set size, the dataset noise and the inference temperature (i.e. the weight regularization). With a small but informative dataset the machine can learn by memorization. With a noisy dataset, an extensive number of examples above a critical threshold is needed. In this regime the memory storage limits of the system becomes an opportunity for the occurrence of a learning regime in which the system can generalize.",
    "path": "papers/23/04/2304.13710.json",
    "total_tokens": 875,
    "translated_title": "带种植模式的Hopfield模型：一种师生自我监督学习模型",
    "translated_abstract": "尽管Hopfield网络被认为是记忆存储和检索的典型模型，但现代人工智能系统主要基于机器学习范式。我们展示了如何利用具有结构化模式的Hopfield模型的适当推广来构建Boltzmann机的师生自我监督学习问题，其中自旋变量是机器权重，模式对应于训练集的示例。我们通过研究相图来分析学习性能，这些相图是通过训练集大小、数据集噪声和推断温度（即权重正则化）来构建的。使用小而富信息的数据集，机器可以通过记忆来学习。使用嘈杂的数据集，则需要大量的示例数以超过临界阈值。在这个区域，系统的存储限制成为产生一种学习模式的机会，在这种模式下，系统可以进行泛化。",
    "tldr": "该论文提出了一种基于师生自我监督学习问题的Hopfield模型，能够帮助机器利用结构化的模式来学习，虽然一些条件对于学习非常重要，但这种学习模式在特定条件下可以实现泛化。",
    "en_tdlr": "The paper proposes a Hopfield model based on teacher-student self-supervised learning, which helps machines learn using structured patterns. Although certain conditions are important for learning, this learning regime can generalize under specific conditions."
}