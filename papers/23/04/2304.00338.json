{
    "title": "Scientific Computing Algorithms to Learn Enhanced Scalable Surrogates for Mesh Physics. (arXiv:2304.00338v1 [cs.LG])",
    "abstract": "Data-driven modeling approaches can produce fast surrogates to study large-scale physics problems. Among them, graph neural networks (GNNs) that operate on mesh-based data are desirable because they possess inductive biases that promote physical faithfulness, but hardware limitations have precluded their application to large computational domains. We show that it is \\textit{possible} to train a class of GNN surrogates on 3D meshes. We scale MeshGraphNets (MGN), a subclass of GNNs for mesh-based physics modeling, via our domain decomposition approach to facilitate training that is mathematically equivalent to training on the whole domain under certain conditions. With this, we were able to train MGN on meshes with \\textit{millions} of nodes to generate computational fluid dynamics (CFD) simulations. Furthermore, we show how to enhance MGN via higher-order numerical integration, which can reduce MGN's error and training time. We validated our methods on an accompanying dataset of 3D $\\te",
    "link": "http://arxiv.org/abs/2304.00338",
    "context": "Title: Scientific Computing Algorithms to Learn Enhanced Scalable Surrogates for Mesh Physics. (arXiv:2304.00338v1 [cs.LG])\nAbstract: Data-driven modeling approaches can produce fast surrogates to study large-scale physics problems. Among them, graph neural networks (GNNs) that operate on mesh-based data are desirable because they possess inductive biases that promote physical faithfulness, but hardware limitations have precluded their application to large computational domains. We show that it is \\textit{possible} to train a class of GNN surrogates on 3D meshes. We scale MeshGraphNets (MGN), a subclass of GNNs for mesh-based physics modeling, via our domain decomposition approach to facilitate training that is mathematically equivalent to training on the whole domain under certain conditions. With this, we were able to train MGN on meshes with \\textit{millions} of nodes to generate computational fluid dynamics (CFD) simulations. Furthermore, we show how to enhance MGN via higher-order numerical integration, which can reduce MGN's error and training time. We validated our methods on an accompanying dataset of 3D $\\te",
    "path": "papers/23/04/2304.00338.json",
    "total_tokens": 954,
    "translated_title": "学习增强可扩展的网格物理学代理的科学计算算法",
    "translated_abstract": "数据驱动的建模方法能够生成用于研究大规模物理问题的快速代理。其中，操作基于网格的图神经网络（GNN）是理想的选择，因为它们具有促进物理忠实度的归纳偏差，但硬件限制阻止了它们在大型计算域的应用。我们展示了在3D网格上培训一类GNN代理的可能性。我们通过领域分解的方法扩展了MeshGraphNets（MGN）（一种用于基于网格的物理建模的GNN子类），以便在某些条件下数学上等同于在整个域上进行培训。利用这种方法，我们能够在拥有数百万个节点的网格上对MGN进行培训，生成计算流体动力学（CFD）模拟。此外，我们展示了如何通过高阶数值积分来增强MGN，从而能够减少MGN的误差和培训时间。我们在一个附带的三维网格数据集上验证了我们的方法。",
    "tldr": "通过领域分解的方法扩展网格上的MeshGraphNets，了解了如何训练一个可扩展的基于网格的图神经网络代理，进而生成计算流体动力学模拟，同时还展示了如何通过高阶数值积分来增强该代理。",
    "en_tdlr": "This paper explores a domain decomposition approach to scale MeshGraphNets (a subclass of GNNs for mesh-based physics modeling) for training on large computational domains and enhances it through higher-order numerical integration, resulting in an enhanced scalable surrogate for mesh physics."
}