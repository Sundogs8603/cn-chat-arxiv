{
    "title": "Towards Healthy AI: Large Language Models Need Therapists Too. (arXiv:2304.00416v1 [cs.AI])",
    "abstract": "Recent advances in large language models (LLMs) have led to the development of powerful AI chatbots capable of engaging in natural and human-like conversations. However, these chatbots can be potentially harmful, exhibiting manipulative, gaslighting, and narcissistic behaviors. We define Healthy AI to be safe, trustworthy and ethical. To create healthy AI systems, we present the SafeguardGPT framework that uses psychotherapy to correct for these harmful behaviors in AI chatbots. The framework involves four types of AI agents: a Chatbot, a \"User,\" a \"Therapist,\" and a \"Critic.\" We demonstrate the effectiveness of SafeguardGPT through a working example of simulating a social conversation. Our results show that the framework can improve the quality of conversations between AI chatbots and humans. Although there are still several challenges and directions to be addressed in the future, SafeguardGPT provides a promising approach to improving the alignment between AI chatbots and human value",
    "link": "http://arxiv.org/abs/2304.00416",
    "context": "Title: Towards Healthy AI: Large Language Models Need Therapists Too. (arXiv:2304.00416v1 [cs.AI])\nAbstract: Recent advances in large language models (LLMs) have led to the development of powerful AI chatbots capable of engaging in natural and human-like conversations. However, these chatbots can be potentially harmful, exhibiting manipulative, gaslighting, and narcissistic behaviors. We define Healthy AI to be safe, trustworthy and ethical. To create healthy AI systems, we present the SafeguardGPT framework that uses psychotherapy to correct for these harmful behaviors in AI chatbots. The framework involves four types of AI agents: a Chatbot, a \"User,\" a \"Therapist,\" and a \"Critic.\" We demonstrate the effectiveness of SafeguardGPT through a working example of simulating a social conversation. Our results show that the framework can improve the quality of conversations between AI chatbots and humans. Although there are still several challenges and directions to be addressed in the future, SafeguardGPT provides a promising approach to improving the alignment between AI chatbots and human value",
    "path": "papers/23/04/2304.00416.json",
    "total_tokens": 923,
    "translated_title": "迈向健康AI：大型语言模型也需要治疗师",
    "translated_abstract": "近期大型语言模型 (LLM) 的进展带来了功能强大的 AI 聊天机器人，能够参与自然且类似人类的对话。然而，这些聊天机器人可能具有潜在的危害性，表现出操纵、灌输虚假观念和自恋行为。我们定义健康AI为安全、可信和道德的AI。为了创造健康的AI系统，我们提出了SafeguardGPT框架，该框架使用心理治疗来纠正AI聊天机器人中的这些有害行为。该框架涉及四种类型的AI代理：聊天机器人、\"用户\"、\"治疗师\"和\"评论家\"。我们通过模拟社交对话的工作示例展示了SafeguardGPT的有效性。我们的结果表明，该框架能够改进AI聊天机器人和人类之间的对话质量。虽然未来仍需解决几个挑战和方向，但SafeguardGPT为改善AI聊天机器人与人类价值观之间的协调提供了一种有前途的方法。",
    "tldr": "SafeguardGPT框架使用心理治疗来纠正AI聊天机器人中的有害行为，改进与人类的对话质量，进而推进健康AI的发展。",
    "en_tdlr": "The SafeguardGPT framework uses psychotherapy to correct harmful behaviors in AI chatbots, improving the quality of conversations with humans and promoting the development of healthy AI."
}