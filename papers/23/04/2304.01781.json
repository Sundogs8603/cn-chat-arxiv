{
    "title": "Mixing predictions for online metric algorithms. (arXiv:2304.01781v1 [cs.LG])",
    "abstract": "A major technique in learning-augmented online algorithms is combining multiple algorithms or predictors. Since the performance of each predictor may vary over time, it is desirable to use not the single best predictor as a benchmark, but rather a dynamic combination which follows different predictors at different times. We design algorithms that combine predictions and are competitive against such dynamic combinations for a wide class of online problems, namely, metrical task systems. Against the best (in hindsight) unconstrained combination of $\\ell$ predictors, we obtain a competitive ratio of $O(\\ell^2)$, and show that this is best possible. However, for a benchmark with slightly constrained number of switches between different predictors, we can get a $(1+\\epsilon)$-competitive algorithm. Moreover, our algorithms can be adapted to access predictors in a bandit-like fashion, querying only one predictor at a time. An unexpected implication of one of our lower bounds is a new structu",
    "link": "http://arxiv.org/abs/2304.01781",
    "context": "Title: Mixing predictions for online metric algorithms. (arXiv:2304.01781v1 [cs.LG])\nAbstract: A major technique in learning-augmented online algorithms is combining multiple algorithms or predictors. Since the performance of each predictor may vary over time, it is desirable to use not the single best predictor as a benchmark, but rather a dynamic combination which follows different predictors at different times. We design algorithms that combine predictions and are competitive against such dynamic combinations for a wide class of online problems, namely, metrical task systems. Against the best (in hindsight) unconstrained combination of $\\ell$ predictors, we obtain a competitive ratio of $O(\\ell^2)$, and show that this is best possible. However, for a benchmark with slightly constrained number of switches between different predictors, we can get a $(1+\\epsilon)$-competitive algorithm. Moreover, our algorithms can be adapted to access predictors in a bandit-like fashion, querying only one predictor at a time. An unexpected implication of one of our lower bounds is a new structu",
    "path": "papers/23/04/2304.01781.json",
    "total_tokens": 917,
    "translated_title": "在线指标算法的混合预测",
    "translated_abstract": "在学习-增强的在线算法中，主要技术之一是组合多个算法或预测器。由于每个预测器的性能可能随时间变化，因此希望使用动态组合，根据不同的时间跟随不同的预测器，而不是使用单个最佳预测器作为基准。我们设计了一些组合预测并针对广泛的在线问题类别（即度量任务系统）与这样的动态组合进行竞争。针对最佳（事后）无约束组合的$\\ell$个预测器，我们获得了$O(\\ell^2)$的竞争比，并证明这是最优的。然而，对于一个约束在不同预测器之间切换次数的基准，我们可以获得$(1+\\epsilon)$-竞争算法。此外，我们的算法可以适应类似于赌博机式的访问预测器的方式，每次查询一个预测器。我们其中一条下界的一个意外推论是，出现了新的结构。",
    "tldr": "本文提出了一种在线算法的混合预测方法，针对度量任务系统，我们获得了$O(\\ell^2)$的竞争比，可以使算法跟随不同的预测器，对限制切换次数的情况可以获得$(1+\\epsilon)$-竞争算法。"
}