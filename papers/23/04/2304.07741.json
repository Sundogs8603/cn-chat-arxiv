{
    "title": "Canvas: End-to-End Kernel Architecture Search in Neural Networks. (arXiv:2304.07741v1 [cs.LG])",
    "abstract": "The demands for higher performance and accuracy in neural networks (NNs) never end. Existing tensor compilation and Neural Architecture Search (NAS) techniques orthogonally optimize the two goals but actually share many similarities in their concrete strategies. We exploit such opportunities by combining the two into one and make a case for Kernel Architecture Search (KAS). KAS reviews NAS from a system perspective and zooms into a more fine-grained level to generate neural kernels with both high performance and good accuracy. To demonstrate the potential of KAS, we build an end-to-end framework, Canvas, to find high-quality kernels as convolution replacements. Canvas samples from a rich set of fine-grained primitives to stochastically and iteratively construct new kernels and evaluate them according to user-specified constraints. Canvas supports freely adjustable tensor dimension sizes inside the kernel and uses two levels of solvers to satisfy structural legality and fully utilize mo",
    "link": "http://arxiv.org/abs/2304.07741",
    "context": "Title: Canvas: End-to-End Kernel Architecture Search in Neural Networks. (arXiv:2304.07741v1 [cs.LG])\nAbstract: The demands for higher performance and accuracy in neural networks (NNs) never end. Existing tensor compilation and Neural Architecture Search (NAS) techniques orthogonally optimize the two goals but actually share many similarities in their concrete strategies. We exploit such opportunities by combining the two into one and make a case for Kernel Architecture Search (KAS). KAS reviews NAS from a system perspective and zooms into a more fine-grained level to generate neural kernels with both high performance and good accuracy. To demonstrate the potential of KAS, we build an end-to-end framework, Canvas, to find high-quality kernels as convolution replacements. Canvas samples from a rich set of fine-grained primitives to stochastically and iteratively construct new kernels and evaluate them according to user-specified constraints. Canvas supports freely adjustable tensor dimension sizes inside the kernel and uses two levels of solvers to satisfy structural legality and fully utilize mo",
    "path": "papers/23/04/2304.07741.json",
    "total_tokens": 849,
    "translated_abstract": "神经网络（NN）对于更高的性能和准确性的需求永远不会停止。现有的张量编译和神经架构搜索（NAS）技术在优化两个目标时是正交的，但实际上在具体策略上有许多相似之处。我们通过将两者合并成一个，提出了内核架构搜索（KAS）的说法。 KAS从系统角度审查NAS，并放大到更精细的级别以生成具有高性能和良好准确性的神经内核。为展示KAS的潜力，我们构建了一个端到端框架，Canvas，以寻找高质量的内核来替代卷积。Canvas从丰富的细粒度基元中进行采样，以随机和迭代的方式构建新的内核，并根据用户指定的约束条件进行评估。Canvas支持自由调整内核内的张量维度大小，并使用两级求解器以满足结构合法性并充分利用可用硬件。",
    "tldr": "KES使用内核架构搜索（KAS）来生成具有高性能和良好准确性的神经内核，为更高的性能和准确性提供了新的可能性。"
}