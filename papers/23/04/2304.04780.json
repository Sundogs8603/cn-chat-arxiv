{
    "title": "A Review on Explainable Artificial Intelligence for Healthcare: Why, How, and When?. (arXiv:2304.04780v1 [cs.LG])",
    "abstract": "Artificial intelligence (AI) models are increasingly finding applications in the field of medicine. Concerns have been raised about the explainability of the decisions that are made by these AI models. In this article, we give a systematic analysis of explainable artificial intelligence (XAI), with a primary focus on models that are currently being used in the field of healthcare. The literature search is conducted following the preferred reporting items for systematic reviews and meta-analyses (PRISMA) standards for relevant work published from 1 January 2012 to 02 February 2022. The review analyzes the prevailing trends in XAI and lays out the major directions in which research is headed. We investigate the why, how, and when of the uses of these XAI models and their implications. We present a comprehensive examination of XAI methodologies as well as an explanation of how a trustworthy AI can be derived from describing AI models for healthcare fields. The discussion of this work will",
    "link": "http://arxiv.org/abs/2304.04780",
    "context": "Title: A Review on Explainable Artificial Intelligence for Healthcare: Why, How, and When?. (arXiv:2304.04780v1 [cs.LG])\nAbstract: Artificial intelligence (AI) models are increasingly finding applications in the field of medicine. Concerns have been raised about the explainability of the decisions that are made by these AI models. In this article, we give a systematic analysis of explainable artificial intelligence (XAI), with a primary focus on models that are currently being used in the field of healthcare. The literature search is conducted following the preferred reporting items for systematic reviews and meta-analyses (PRISMA) standards for relevant work published from 1 January 2012 to 02 February 2022. The review analyzes the prevailing trends in XAI and lays out the major directions in which research is headed. We investigate the why, how, and when of the uses of these XAI models and their implications. We present a comprehensive examination of XAI methodologies as well as an explanation of how a trustworthy AI can be derived from describing AI models for healthcare fields. The discussion of this work will",
    "path": "papers/23/04/2304.04780.json",
    "total_tokens": 1018,
    "translated_title": "关于可解释人工智能在医疗保健领域的综述：为什么、 如何和何时？",
    "translated_abstract": "人工智能模型在医学领域中的应用越来越广泛。同时也出现了关于这些人工智能模型决策可解释性的担忧。本文系统分析了可解释人工智能（XAI），重点关注目前在医疗保健领域中使用的模型。按照系统性综述和元分析的首选报告项目（PRISMA）标准，检索了2012年1月1日至2022年2月2日期间发表的相关文章。本综述分析了XAI的流行趋势，并阐述了研究的主要方向。我们调查这些XAI模型的使用原因、如何使用以及何时使用以及其影响。我们对XAI方法进行了全面的研究，以及阐述了如何通过描述医疗领域的AI模型来获得可信赖的AI。对本文的讨论将有助于研究人员、临床医生和政策制定者深入了解XAI在医疗保健应用中的重要性。",
    "tldr": "本篇综述系统分析了可解释人工智能（XAI）在医疗保健领域的应用及其流行趋势，阐述了XAI的使用原因、如何使用以及何时使用及其影响，并给出了如何获得可信赖的AI的方法，对研究人员、临床医生和政策制定者有重要的指导作用。"
}