{
    "title": "Analogy-Forming Transformers for Few-Shot 3D Parsing. (arXiv:2304.14382v1 [cs.CV])",
    "abstract": "We present Analogical Networks, a model that encodes domain knowledge explicitly, in a collection of structured labelled 3D scenes, in addition to implicitly, as model parameters, and segments 3D object scenes with analogical reasoning: instead of mapping a scene to part segments directly, our model first retrieves related scenes from memory and their corresponding part structures, and then predicts analogous part structures for the input scene, via an end-to-end learnable modulation mechanism. By conditioning on more than one retrieved memories, compositions of structures are predicted, that mix and match parts across the retrieved memories. One-shot, few-shot or many-shot learning are treated uniformly in Analogical Networks, by conditioning on the appropriate set of memories, whether taken from a single, few or many memory exemplars, and inferring analogous parses. We show Analogical Networks are competitive with state-of-the-art 3D segmentation transformers in many-shot settings, a",
    "link": "http://arxiv.org/abs/2304.14382",
    "context": "Title: Analogy-Forming Transformers for Few-Shot 3D Parsing. (arXiv:2304.14382v1 [cs.CV])\nAbstract: We present Analogical Networks, a model that encodes domain knowledge explicitly, in a collection of structured labelled 3D scenes, in addition to implicitly, as model parameters, and segments 3D object scenes with analogical reasoning: instead of mapping a scene to part segments directly, our model first retrieves related scenes from memory and their corresponding part structures, and then predicts analogous part structures for the input scene, via an end-to-end learnable modulation mechanism. By conditioning on more than one retrieved memories, compositions of structures are predicted, that mix and match parts across the retrieved memories. One-shot, few-shot or many-shot learning are treated uniformly in Analogical Networks, by conditioning on the appropriate set of memories, whether taken from a single, few or many memory exemplars, and inferring analogous parses. We show Analogical Networks are competitive with state-of-the-art 3D segmentation transformers in many-shot settings, a",
    "path": "papers/23/04/2304.14382.json",
    "total_tokens": 928,
    "translated_title": "模拟形式转换器用于少样本3D解析",
    "translated_abstract": "我们提出了一种称为“模拟网络”的模型，它在一组有标记的结构化3D场景中显式地编码领域知识（作为模型参数的一部分），并通过类比推理对3D物体场景进行分割：我们的模型首先从内存中检索相关场景及其相应的部分结构，然后通过端到端可学习的调制机制为输入场景预测类似的部分结构，而不是直接将场景映射到部分分割。通过对多个检索的记忆进行条件控制，预测混合匹配检索记忆的结构合成。在“模拟网络”中，一发、少发或多发学习被一致地处理，通过对适当的记忆集进行条件谓词，无论是从单个、少数还是许多存储实例中继承相似的解析。我们展示了“模拟网络”在许多样本情况下与最新的3D分割变压器模型相竞争。",
    "tldr": "\"模拟网络\"模型在3D物体场景分割中采用类比推理，通过在内存中检索相关场景并预测类似结构进行分割，能够在一发、少发或多发学习中得出相似的解析，与最新的3D分割变压器模型相竞争。",
    "en_tdlr": "Analogical Networks model uses analogical reasoning to segment 3D object scenes by retrieving related scenes from memory and predicting analogous structures for the input scene. It can handle one-shot, few-shot or many-shot learning uniformly and is competitive with state-of-the-art 3D segmentation transformers."
}