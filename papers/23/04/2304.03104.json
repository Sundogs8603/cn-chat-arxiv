{
    "title": "Constrained Exploration in Reinforcement Learning with Optimality Preservation. (arXiv:2304.03104v1 [cs.LG])",
    "abstract": "We consider a class of reinforcement-learning systems in which the agent follows a behavior policy to explore a discrete state-action space to find an optimal policy while adhering to some restriction on its behavior. Such restriction may prevent the agent from visiting some state-action pairs, possibly leading to the agent finding only a sub-optimal policy. To address this problem we introduce the concept of constrained exploration with optimality preservation, whereby the exploration behavior of the agent is constrained to meet a specification while the optimality of the (original) unconstrained learning process is preserved. We first establish a feedback-control structure that models the dynamics of the unconstrained learning process. We then extend this structure by adding a supervisor to ensure that the behavior of the agent meets the specification, and establish (for a class of reinforcement-learning problems with a known deterministic environment) a necessary and sufficient cond",
    "link": "http://arxiv.org/abs/2304.03104",
    "context": "Title: Constrained Exploration in Reinforcement Learning with Optimality Preservation. (arXiv:2304.03104v1 [cs.LG])\nAbstract: We consider a class of reinforcement-learning systems in which the agent follows a behavior policy to explore a discrete state-action space to find an optimal policy while adhering to some restriction on its behavior. Such restriction may prevent the agent from visiting some state-action pairs, possibly leading to the agent finding only a sub-optimal policy. To address this problem we introduce the concept of constrained exploration with optimality preservation, whereby the exploration behavior of the agent is constrained to meet a specification while the optimality of the (original) unconstrained learning process is preserved. We first establish a feedback-control structure that models the dynamics of the unconstrained learning process. We then extend this structure by adding a supervisor to ensure that the behavior of the agent meets the specification, and establish (for a class of reinforcement-learning problems with a known deterministic environment) a necessary and sufficient cond",
    "path": "papers/23/04/2304.03104.json",
    "total_tokens": 818,
    "tldr": "研究如何在强化学习中进行受限探索，以达到理想效果，同时保持原有最优性。",
    "en_tdlr": "This paper explores how to conduct constrained exploration in reinforcement learning to achieve the desired effect while preserving the original optimality."
}