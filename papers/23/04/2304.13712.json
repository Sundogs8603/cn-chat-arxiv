{
    "title": "Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond. (arXiv:2304.13712v1 [cs.CL])",
    "abstract": "This paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs) in their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from the perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and BERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a detailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as knowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities, and considerations for specific tasks.We present various use cases and non-use cases to illustrate the practical applications and limitations of LLMs in real-world scenarios. We also try to understand the importance of dat",
    "link": "http://arxiv.org/abs/2304.13712",
    "context": "Title: Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond. (arXiv:2304.13712v1 [cs.CL])\nAbstract: This paper presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs) in their downstream natural language processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from the perspectives of models, data, and downstream tasks. Firstly, we offer an introduction and brief summary of current GPT- and BERT-style LLMs. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a detailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as knowledge-intensive tasks, traditional natural language understanding tasks, natural language generation tasks, emergent abilities, and considerations for specific tasks.We present various use cases and non-use cases to illustrate the practical applications and limitations of LLMs in real-world scenarios. We also try to understand the importance of dat",
    "path": "papers/23/04/2304.13712.json",
    "total_tokens": 821,
    "translated_title": "发挥LLMs在实践中的力量：ChatGPT及其应用的综述调查",
    "translated_abstract": "本文为从事下游自然语言处理（NLP）任务的从业人员和最终用户提供了一个全面实用的指南，介绍了如何利用Large Language Models（LLMs）。我们从模型、数据和下游任务的角度提供了LLMs的使用讨论和见解。首先，我们介绍了当前的GPT和BERT样式的LLMs。然后，讨论了预训练数据、训练数据和测试数据的影响。最重要的是，我们详细讨论了大型语言模型在各种自然语言处理任务中的使用和非使用情况，例如知识密集型任务、传统自然语言理解任务、自然语言生成任务、紧急能力以及特定任务的考虑。我们呈现了各种使用和非使用情况，以说明LLMs在实际情况下的实际应用和限制。我们还试图了解数据对于LLMs应用的重要性。",
    "tldr": "本文提供了一个LLMs的使用综述，探讨了在各种自然语言处理任务中的使用和限制。",
    "en_tdlr": "This paper provides a survey on the usage of Large Language Models (LLMs) for natural language processing (NLP) tasks, discussing their practical applications and limitations in various tasks."
}