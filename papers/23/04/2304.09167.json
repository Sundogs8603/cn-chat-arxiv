{
    "title": "Optimal PAC Bounds Without Uniform Convergence. (arXiv:2304.09167v1 [cs.LG])",
    "abstract": "In statistical learning theory, determining the sample complexity of realizable binary classification for VC classes was a long-standing open problem. The results of Simon and Hanneke established sharp upper bounds in this setting. However, the reliance of their argument on the uniform convergence principle limits its applicability to more general learning settings such as multiclass classification. In this paper, we address this issue by providing optimal high probability risk bounds through a framework that surpasses the limitations of uniform convergence arguments.  Our framework converts the leave-one-out error of permutation invariant predictors into high probability risk bounds. As an application, by adapting the one-inclusion graph algorithm of Haussler, Littlestone, and Warmuth, we propose an algorithm that achieves an optimal PAC bound for binary classification. Specifically, our result shows that certain aggregations of one-inclusion graph algorithms are optimal, addressing a",
    "link": "http://arxiv.org/abs/2304.09167",
    "context": "Title: Optimal PAC Bounds Without Uniform Convergence. (arXiv:2304.09167v1 [cs.LG])\nAbstract: In statistical learning theory, determining the sample complexity of realizable binary classification for VC classes was a long-standing open problem. The results of Simon and Hanneke established sharp upper bounds in this setting. However, the reliance of their argument on the uniform convergence principle limits its applicability to more general learning settings such as multiclass classification. In this paper, we address this issue by providing optimal high probability risk bounds through a framework that surpasses the limitations of uniform convergence arguments.  Our framework converts the leave-one-out error of permutation invariant predictors into high probability risk bounds. As an application, by adapting the one-inclusion graph algorithm of Haussler, Littlestone, and Warmuth, we propose an algorithm that achieves an optimal PAC bound for binary classification. Specifically, our result shows that certain aggregations of one-inclusion graph algorithms are optimal, addressing a",
    "path": "papers/23/04/2304.09167.json",
    "total_tokens": 809,
    "translated_title": "不需要均匀收敛的最优 PAC 界限",
    "translated_abstract": "在统计学习理论中，确定 VC 类别的可实现二进制分类的样本复杂度一直是一个长期存在的问题。 Simon 和 Hanneke 的结果在这种情况下建立了尖锐的上界。然而，它们的论证依赖于均匀收敛原则，限制了其适用性于更一般的学习设置，例如多类分类。本文通过提供超越均匀收敛论证限制的框架，提供了最优的高概率风险界限。我们的框架将置换不变预测器的留一出错转化为高概率风险界限。作为应用，通过改编 Haussler、Littlestone 和 Warmuth 的一包含图算法，我们提出了一种为二元分类实现最优 PAC 界限的算法。具体而言，我们的结果表明，某些一包含图算法的聚合是最优的，解决了一个问题。",
    "tldr": "本文通过提供框架，将置换不变预测器的留一出错转化为高概率风险界限，实现了为二元分类实现最优 PAC 界限的算法。"
}