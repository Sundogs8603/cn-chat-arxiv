{
    "title": "TinyReptile: TinyML with Federated Meta-Learning. (arXiv:2304.05201v1 [cs.LG])",
    "abstract": "Tiny machine learning (TinyML) is a rapidly growing field aiming to democratize machine learning (ML) for resource-constrained microcontrollers (MCUs). Given the pervasiveness of these tiny devices, it is inherent to ask whether TinyML applications can benefit from aggregating their knowledge. Federated learning (FL) enables decentralized agents to jointly learn a global model without sharing sensitive local data. However, a common global model may not work for all devices due to the complexity of the actual deployment environment and the heterogeneity of the data available on each device. In addition, the deployment of TinyML hardware has significant computational and communication constraints, which traditional ML fails to address. Considering these challenges, we propose TinyReptile, a simple but efficient algorithm inspired by meta-learning and online learning, to collaboratively learn a solid initialization for a neural network (NN) across tiny devices that can be quickly adapted ",
    "link": "http://arxiv.org/abs/2304.05201",
    "context": "Title: TinyReptile: TinyML with Federated Meta-Learning. (arXiv:2304.05201v1 [cs.LG])\nAbstract: Tiny machine learning (TinyML) is a rapidly growing field aiming to democratize machine learning (ML) for resource-constrained microcontrollers (MCUs). Given the pervasiveness of these tiny devices, it is inherent to ask whether TinyML applications can benefit from aggregating their knowledge. Federated learning (FL) enables decentralized agents to jointly learn a global model without sharing sensitive local data. However, a common global model may not work for all devices due to the complexity of the actual deployment environment and the heterogeneity of the data available on each device. In addition, the deployment of TinyML hardware has significant computational and communication constraints, which traditional ML fails to address. Considering these challenges, we propose TinyReptile, a simple but efficient algorithm inspired by meta-learning and online learning, to collaboratively learn a solid initialization for a neural network (NN) across tiny devices that can be quickly adapted ",
    "path": "papers/23/04/2304.05201.json",
    "total_tokens": 1013,
    "translated_title": "TinyReptile：联邦元学习实现的迷你机器学习",
    "translated_abstract": "迷你机器学习（TinyML）是一个迅速发展的领域，旨在为资源受限的微控制器（MCU）民主化机器学习。鉴于这些微型设备的普及性，有必要问是否TinyML应用程序可以从聚合他们的知识中受益。联邦学习（FL）使得分散的代理可以共同学习一个全局模型，而不共享敏感的本地数据。然而，由于实际部署环境的复杂性和每个设备可用数据的异构性，一个常见的全局模型可能不能适用于所有设备。此外， TinyML 硬件的部署具有重要的计算和通信约束，传统机器学习无法解决这些问题。针对这些挑战，我们提出了 TinyReptile，这是一个简单而有效的算法，灵感来源于元学习和在线学习，可以在迷你设备上协作学习神经网络（NN）的坚实初始化，可以快速适应这些设备的本地数据。我们使用 FL 来评估 TinyReptile，结果表明 TinyReptile 可以在保护本地数据隐私的同时，利用全局数据实现快速收敛和精确性能。",
    "tldr": "TinyReptile是一个联邦元学习实现的迷你机器学习算法，可以在迷你设备上协作学习神经网络，并通过使用全局数据实现快速收敛和保护本地数据隐私。"
}