{
    "title": "Multimodal C4: An Open, Billion-scale Corpus of Images Interleaved With Text. (arXiv:2304.06939v1 [cs.CV])",
    "abstract": "In-context vision and language models like Flamingo support arbitrarily interleaved sequences of images and text as input. This format not only enables few-shot learning via interleaving independent supervised (image, text) examples, but also, more complex prompts involving interaction between images, e.g., \"What do image A and image B have in common?\" To support this interface, pretraining occurs over web corpora that similarly contain interleaved images+text. To date, however, large-scale data of this form have not been publicly available.  We release Multimodal C4 (mmc4), an augmentation of the popular text-only c4 corpus with images interleaved. We use a linear assignment algorithm to place images into longer bodies of text using CLIP features, a process that we show outperforms alternatives. mmc4 spans everyday topics like cooking, travel, technology, etc. A manual inspection of a random sample of documents shows that a vast majority (90%) of images are topically relevant, and tha",
    "link": "http://arxiv.org/abs/2304.06939",
    "context": "Title: Multimodal C4: An Open, Billion-scale Corpus of Images Interleaved With Text. (arXiv:2304.06939v1 [cs.CV])\nAbstract: In-context vision and language models like Flamingo support arbitrarily interleaved sequences of images and text as input. This format not only enables few-shot learning via interleaving independent supervised (image, text) examples, but also, more complex prompts involving interaction between images, e.g., \"What do image A and image B have in common?\" To support this interface, pretraining occurs over web corpora that similarly contain interleaved images+text. To date, however, large-scale data of this form have not been publicly available.  We release Multimodal C4 (mmc4), an augmentation of the popular text-only c4 corpus with images interleaved. We use a linear assignment algorithm to place images into longer bodies of text using CLIP features, a process that we show outperforms alternatives. mmc4 spans everyday topics like cooking, travel, technology, etc. A manual inspection of a random sample of documents shows that a vast majority (90%) of images are topically relevant, and tha",
    "path": "papers/23/04/2304.06939.json",
    "total_tokens": 910,
    "translated_title": "多模态C4：一种包含大量图像和文本的开放式数据库",
    "translated_abstract": "上下文视觉和语言模型需要支持任意交替的图像和文本序列作为输入, 这种格式不仅可以通过交替独立监督的(图像,文本)示例来进行低次学习,而且可以应对更复杂的提示, 涉及图像间互动,例如“图像A和图像B有什么共同之处?”现有的预训练模型使用类似于交替图像+文本的web语料库。但是，迄今为止，这种形式的大规模数据还没有公开提供。我们发布了Multimodal C4 (mmc4)，这是一个加强版的c4文本库，其中插入了图像。我们使用一个线性分配算法，使用CLIP特征将图像放到更长的文本体中，此过程优于其他替代方案。mmc4涵盖了诸如烹饪，旅游，技术等日常主题。对随机样本的手动检查表明，绝大多数(90%)的图像与主题相关。",
    "tldr": "Multimodal C4是一个开放的、以图像与文本交替形式存在的数据库，其使用线性分配算法将图像放到长文本段落中，可用于通过少量样本学习和复杂相关度提示的建模。",
    "en_tdlr": "Multimodal C4 is an open, image-text interleaved database, which utilizes linear assignment algorithm to embed images into longer bodies of text, which can be used for few-shot learning and modeling of complex prompts involving image interactions."
}