{
    "title": "Loss minimization yields multicalibration for large neural networks. (arXiv:2304.09424v1 [cs.LG])",
    "abstract": "Multicalibration is a notion of fairness that aims to provide accurate predictions across a large set of groups. Multicalibration is known to be a different goal than loss minimization, even for simple predictors such as linear functions. In this note, we show that for (almost all) large neural network sizes, optimally minimizing squared error leads to multicalibration. Our results are about representational aspects of neural networks, and not about algorithmic or sample complexity considerations. Previous such results were known only for predictors that were nearly Bayes-optimal and were therefore representation independent. We emphasize that our results do not apply to specific algorithms for optimizing neural networks, such as SGD, and they should not be interpreted as \"fairness comes for free from optimizing neural networks\".",
    "link": "http://arxiv.org/abs/2304.09424",
    "context": "Title: Loss minimization yields multicalibration for large neural networks. (arXiv:2304.09424v1 [cs.LG])\nAbstract: Multicalibration is a notion of fairness that aims to provide accurate predictions across a large set of groups. Multicalibration is known to be a different goal than loss minimization, even for simple predictors such as linear functions. In this note, we show that for (almost all) large neural network sizes, optimally minimizing squared error leads to multicalibration. Our results are about representational aspects of neural networks, and not about algorithmic or sample complexity considerations. Previous such results were known only for predictors that were nearly Bayes-optimal and were therefore representation independent. We emphasize that our results do not apply to specific algorithms for optimizing neural networks, such as SGD, and they should not be interpreted as \"fairness comes for free from optimizing neural networks\".",
    "path": "papers/23/04/2304.09424.json",
    "total_tokens": 771,
    "translated_title": "大型神经网络的多校准可最小化损失",
    "translated_abstract": "多校准是一种公平性概念，旨在提供跨大量团体的准确预测。即使对于简单的预测器，如线性函数，多校准也被认为是与最小化损失不同的目标。在本文中，我们展示了对于（几乎所有的）大型神经网络大小，最优地最小化平方误差会导致多校准。我们的结果关于神经网络的表征方面，而不是关于算法或样本复杂性考虑。以前的这样的结果仅适用于几乎贝叶斯最优的预测器，因此是表征无关的。我们强调，我们的结果不适用于优化神经网络的特定算法，如 SGD，并且不应解释为“公平性从优化神经网络中获得免费的好处”。",
    "tldr": "本文展示了对于大型神经网络大小，最优地最小化损失会导致多校准，以提供公平的预测结果。",
    "en_tdlr": "This paper shows that optimally minimizing squared error leads to multicalibration for large neural network sizes, providing fair predictions across a large set of groups."
}