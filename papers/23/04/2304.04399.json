{
    "title": "CAVL: Learning Contrastive and Adaptive Representations of Vision and Language. (arXiv:2304.04399v1 [cs.CV])",
    "abstract": "Visual and linguistic pre-training aims to learn vision and language representations together, which can be transferred to visual-linguistic downstream tasks. However, there exists semantic confusion between language and vision during the pre-training stage. Moreover, current pre-trained models tend to take lots of computation resources for fine-tuning when transferred to downstream tasks. In this work, we present a simple but effective approach for learning Contrastive and Adaptive representations of Vision and Language, namely CAVL. Specifically, we introduce a pair-wise contrastive loss to learn alignments between the whole sentence and each image in the same batch during the pre-training process. At the fine-tuning stage, we introduce two lightweight adaptation networks to reduce model parameters and increase training speed for saving computation resources. We evaluate our CAVL on six main downstream tasks, including Visual Question Answering (VQA), Visual Commonsense Reasoning (VC",
    "link": "http://arxiv.org/abs/2304.04399",
    "context": "Title: CAVL: Learning Contrastive and Adaptive Representations of Vision and Language. (arXiv:2304.04399v1 [cs.CV])\nAbstract: Visual and linguistic pre-training aims to learn vision and language representations together, which can be transferred to visual-linguistic downstream tasks. However, there exists semantic confusion between language and vision during the pre-training stage. Moreover, current pre-trained models tend to take lots of computation resources for fine-tuning when transferred to downstream tasks. In this work, we present a simple but effective approach for learning Contrastive and Adaptive representations of Vision and Language, namely CAVL. Specifically, we introduce a pair-wise contrastive loss to learn alignments between the whole sentence and each image in the same batch during the pre-training process. At the fine-tuning stage, we introduce two lightweight adaptation networks to reduce model parameters and increase training speed for saving computation resources. We evaluate our CAVL on six main downstream tasks, including Visual Question Answering (VQA), Visual Commonsense Reasoning (VC",
    "path": "papers/23/04/2304.04399.json",
    "total_tokens": 1006,
    "translated_title": "CAVL：学习对比和自适应的视觉与语言表示",
    "translated_abstract": "视觉和语言的预训练旨在一起学习视觉和语言表示，并可转移到视觉语言下游任务。然而，在预训练阶段，语言和视觉之间存在语义混淆。此外，当前的预训练模型在转移到下游任务时往往需要大量的计算资源进行微调。在本文中，我们提出了一种简单但有效的方法，用于学习对比和自适应的视觉与语言表示，即CAVL。具体而言，我们在预训练过程中引入了一对一对的对比损失，以学习整个句子和同一批次中每个图像之间的对齐。在微调阶段，我们引入了两个轻量级自适应网络，以减少模型参数并增加训练速度，以节省计算资源。我们在包括视觉问答（VQA）、视觉通识推理（VCL）和图像字幕生成等六个主要下游任务中评估了我们的CAVL。实验结果表明，CAVL在大多数任务上都取得了最先进的性能，证明了我们的方法的有效性。",
    "tldr": "本文提出了一种对比自适应的视觉与语言表示学习方法CAVL，在预训练过程中通过对比损失学习整个句子和图像之间的对齐，并在微调阶段引入轻量级自适应网络，实现在下游任务中的最先进效果。",
    "en_tdlr": "This paper proposes a contrastive and adaptive approach to learn representations of vision and language, named CAVL. Specifically, a pair-wise contrastive loss is introduced to learn alignments between sentence and image, and two lightweight adaptation networks are introduced for reducing parameters and increasing training speed at the fine-tuning stage. Experimental results demonstrate state-of-the-art performance on six main downstream tasks."
}