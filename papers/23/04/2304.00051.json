{
    "title": "Almost Linear Constant-Factor Sketching for $\\ell_1$ and Logistic Regression. (arXiv:2304.00051v1 [cs.DS])",
    "abstract": "We improve upon previous oblivious sketching and turnstile streaming results for $\\ell_1$ and logistic regression, giving a much smaller sketching dimension achieving $O(1)$-approximation and yielding an efficient optimization problem in the sketch space. Namely, we achieve for any constant $c>0$ a sketching dimension of $\\tilde{O}(d^{1+c})$ for $\\ell_1$ regression and $\\tilde{O}(\\mu d^{1+c})$ for logistic regression, where $\\mu$ is a standard measure that captures the complexity of compressing the data. For $\\ell_1$-regression our sketching dimension is near-linear and improves previous work which either required $\\Omega(\\log d)$-approximation with this sketching dimension, or required a larger $\\operatorname{poly}(d)$ number of rows. Similarly, for logistic regression previous work had worse $\\operatorname{poly}(\\mu d)$ factors in its sketching dimension. We also give a tradeoff that yields a $1+\\varepsilon$ approximation in input sparsity time by increasing the total size to $(d\\log",
    "link": "http://arxiv.org/abs/2304.00051",
    "context": "Title: Almost Linear Constant-Factor Sketching for $\\ell_1$ and Logistic Regression. (arXiv:2304.00051v1 [cs.DS])\nAbstract: We improve upon previous oblivious sketching and turnstile streaming results for $\\ell_1$ and logistic regression, giving a much smaller sketching dimension achieving $O(1)$-approximation and yielding an efficient optimization problem in the sketch space. Namely, we achieve for any constant $c>0$ a sketching dimension of $\\tilde{O}(d^{1+c})$ for $\\ell_1$ regression and $\\tilde{O}(\\mu d^{1+c})$ for logistic regression, where $\\mu$ is a standard measure that captures the complexity of compressing the data. For $\\ell_1$-regression our sketching dimension is near-linear and improves previous work which either required $\\Omega(\\log d)$-approximation with this sketching dimension, or required a larger $\\operatorname{poly}(d)$ number of rows. Similarly, for logistic regression previous work had worse $\\operatorname{poly}(\\mu d)$ factors in its sketching dimension. We also give a tradeoff that yields a $1+\\varepsilon$ approximation in input sparsity time by increasing the total size to $(d\\log",
    "path": "papers/23/04/2304.00051.json",
    "total_tokens": 1015,
    "translated_title": "$\\ell_1$和logistic回归的近线性常数因子草图",
    "translated_abstract": "我们改进了以前关于$\\ell_1$和Logistic回归的草图算法结果，得到了更小的草图维度和更高的精度，我们的结果在草图空间内产生了高效的优化问题。特别地，我们对于任何常数$c>0$，实现了$\\ell_1$回归的草图维度为$\\tilde{O}(d^{1+c})$，而对于Logistic回归则为$\\tilde{O}(\\mu d^{1+c})$，其中$\\mu$是一个标准的度量，捕获了压缩数据的复杂性。对于$\\ell_1$回归，我们的草图维度是近线性的，具有比先前的工作更高的精度和更小的草图维度。类似地，对于Logistic回归，以前的工作在其草图维度上有更差的$\\operatorname{poly}(\\mu d)$因子。我们还提供了一种折衷方案，通过增加总大小到$(d\\log$，在输入稀疏性时间内产生了$1+\\varepsilon$的近似值。",
    "tldr": "本文提出了一种近线性、常数因子草图，适用于$\\ell_1$和logistic回归，具有小的草图维度和高精度，这种草图还在草图空间内提供了高效的优化问题求解方法。",
    "en_tdlr": "This paper proposes an almost linear constant-factor sketch for $\\ell_1$ and logistic regression, achieving smaller sketching dimension and higher accuracy, and providing an efficient optimization problem solving method in the sketch space. The sketching dimension for $\\ell_1$ regression is close to linear, and the sketching dimension for logistic regression has a smaller factor. Moreover, a tradeoff is given for achieving a $1+\\varepsilon$ approximation in input sparsity time."
}