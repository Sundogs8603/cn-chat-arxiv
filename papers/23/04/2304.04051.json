{
    "title": "Generating a Graph Colouring Heuristic with Deep Q-Learning and Graph Neural Networks. (arXiv:2304.04051v1 [cs.LG])",
    "abstract": "The graph colouring problem consists of assigning labels, or colours, to the vertices of a graph such that no two adjacent vertices share the same colour. In this work we investigate whether deep reinforcement learning can be used to discover a competitive construction heuristic for graph colouring. Our proposed approach, ReLCol, uses deep Q-learning together with a graph neural network for feature extraction, and employs a novel way of parameterising the graph that results in improved performance. Using standard benchmark graphs with varied topologies, we empirically evaluate the benefits and limitations of the heuristic learned by ReLCol relative to existing construction algorithms, and demonstrate that reinforcement learning is a promising direction for further research on the graph colouring problem.",
    "link": "http://arxiv.org/abs/2304.04051",
    "context": "Title: Generating a Graph Colouring Heuristic with Deep Q-Learning and Graph Neural Networks. (arXiv:2304.04051v1 [cs.LG])\nAbstract: The graph colouring problem consists of assigning labels, or colours, to the vertices of a graph such that no two adjacent vertices share the same colour. In this work we investigate whether deep reinforcement learning can be used to discover a competitive construction heuristic for graph colouring. Our proposed approach, ReLCol, uses deep Q-learning together with a graph neural network for feature extraction, and employs a novel way of parameterising the graph that results in improved performance. Using standard benchmark graphs with varied topologies, we empirically evaluate the benefits and limitations of the heuristic learned by ReLCol relative to existing construction algorithms, and demonstrate that reinforcement learning is a promising direction for further research on the graph colouring problem.",
    "path": "papers/23/04/2304.04051.json",
    "total_tokens": 798,
    "translated_title": "利用深度 Q-Learning 和图神经网络生成图着色启发式算法",
    "translated_abstract": "图着色问题是将标签或颜色分配给图的顶点，以使得相邻的两个顶点不会共享相同的颜色。本文研究了深度强化学习是否可用于发现一个竞争性的图着色构造启发式算法。我们提出的方法，ReLCol，使用深度 Q-Learning 与图神经网络进行特征提取，并采用一种新颖的图参数化方法来提高性能。使用具有不同拓扑结构的标准基准图，我们在实验中评估了 ReLCol 学习到的启发式算法与现有构造算法的优缺点，并证明了强化学习是进一步研究图着色问题的有希望的方向。",
    "tldr": "本文通过使用深度 Q-Learning 和图神经网络生成 ReLCol 启发式算法，解决了图着色问题，且相较于现有算法具有竞争性和优越性能。强化学习是探究图着色问题更有前途的一种方法。",
    "en_tdlr": "This paper proposes the ReLCol heuristic algorithm generated by deep Q-Learning and graph neural networks to solve the graph coloring problem, which outperforms existing algorithms. The study demonstrates that reinforcement learning is a promising direction for further research on this problem."
}