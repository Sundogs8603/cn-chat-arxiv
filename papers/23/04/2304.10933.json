{
    "title": "Self-Attention in Colors: Another Take on Encoding Graph Structure in Transformers. (arXiv:2304.10933v1 [cs.LG])",
    "abstract": "We introduce a novel self-attention mechanism, which we call CSA (Chromatic Self-Attention), which extends the notion of attention scores to attention _filters_, independently modulating the feature channels. We showcase CSA in a fully-attentional graph Transformer CGT (Chromatic Graph Transformer) which integrates both graph structural information and edge features, completely bypassing the need for local message-passing components. Our method flexibly encodes graph structure through node-node interactions, by enriching the original edge features with a relative positional encoding scheme. We propose a new scheme based on random walks that encodes both structural and positional information, and show how to incorporate higher-order topological information, such as rings in molecular graphs. Our approach achieves state-of-the-art results on the ZINC benchmark dataset, while providing a flexible framework for encoding graph structure and incorporating higher-order topology.",
    "link": "http://arxiv.org/abs/2304.10933",
    "context": "Title: Self-Attention in Colors: Another Take on Encoding Graph Structure in Transformers. (arXiv:2304.10933v1 [cs.LG])\nAbstract: We introduce a novel self-attention mechanism, which we call CSA (Chromatic Self-Attention), which extends the notion of attention scores to attention _filters_, independently modulating the feature channels. We showcase CSA in a fully-attentional graph Transformer CGT (Chromatic Graph Transformer) which integrates both graph structural information and edge features, completely bypassing the need for local message-passing components. Our method flexibly encodes graph structure through node-node interactions, by enriching the original edge features with a relative positional encoding scheme. We propose a new scheme based on random walks that encodes both structural and positional information, and show how to incorporate higher-order topological information, such as rings in molecular graphs. Our approach achieves state-of-the-art results on the ZINC benchmark dataset, while providing a flexible framework for encoding graph structure and incorporating higher-order topology.",
    "path": "papers/23/04/2304.10933.json",
    "total_tokens": 876,
    "translated_title": "色彩中的自注意力：transformer中图结构编码的另一种方法",
    "translated_abstract": "我们引入了一种称为CSA（色彩自注意力）的新型自注意机制，将注意力分数的概念扩展到注意力过滤器上，独立调制特征通道。我们在完全注意力的图形Transformer CGT（色彩图形Transformer）中展示了CSA，通过富化原始边特征以及相对位置编码方案，完全绕过了本地消息传递组件的需求，通过节点之间的相互作用灵活地编码图结构。我们提出了一种基于随机游走的新方案，可以编码结构和位置信息，并展示如何纳入更高阶的拓扑信息，例如分子图中的环。我们的方法在ZINC基准数据集上取得了最先进的结果，同时为编码图结构和纳入更高阶的拓扑结构提供了一个灵活的框架。",
    "tldr": "该论文提出了一种新的自注意机制CSA（色彩自注意力），可以将原始边特征富化以及相对位置编码方案来灵活的编码图结构，并在ZINC基准数据集上取得了最先进的结果。",
    "en_tdlr": "This paper proposes a novel self-attention mechanism CSA (Chromatic Self-Attention) which can flexibly encode graph structures by enriching the original edge features and using a relative positional encoding scheme. The approach achieves state-of-the-art results on the ZINC benchmark dataset and provides a flexible framework for encoding graph structure and incorporating higher-order topology with the use of a new scheme based on random walks."
}