{
    "title": "In ChatGPT We Trust? Measuring and Characterizing the Reliability of ChatGPT. (arXiv:2304.08979v1 [cs.CR])",
    "abstract": "The way users acquire information is undergoing a paradigm shift with the advent of ChatGPT. Unlike conventional search engines, ChatGPT retrieves knowledge from the model itself and generates answers for users. ChatGPT's impressive question-answering (QA) capability has attracted more than 100 million users within a short period of time but has also raised concerns regarding its reliability. In this paper, we perform the first large-scale measurement of ChatGPT's reliability in the generic QA scenario with a carefully curated set of 5,695 questions across ten datasets and eight domains. We find that ChatGPT's reliability varies across different domains, especially underperforming in law and science questions. We also demonstrate that system roles, originally designed by OpenAI to allow users to steer ChatGPT's behavior, can impact ChatGPT's reliability. We further show that ChatGPT is vulnerable to adversarial examples, and even a single character change can negatively affect its reli",
    "link": "http://arxiv.org/abs/2304.08979",
    "context": "Title: In ChatGPT We Trust? Measuring and Characterizing the Reliability of ChatGPT. (arXiv:2304.08979v1 [cs.CR])\nAbstract: The way users acquire information is undergoing a paradigm shift with the advent of ChatGPT. Unlike conventional search engines, ChatGPT retrieves knowledge from the model itself and generates answers for users. ChatGPT's impressive question-answering (QA) capability has attracted more than 100 million users within a short period of time but has also raised concerns regarding its reliability. In this paper, we perform the first large-scale measurement of ChatGPT's reliability in the generic QA scenario with a carefully curated set of 5,695 questions across ten datasets and eight domains. We find that ChatGPT's reliability varies across different domains, especially underperforming in law and science questions. We also demonstrate that system roles, originally designed by OpenAI to allow users to steer ChatGPT's behavior, can impact ChatGPT's reliability. We further show that ChatGPT is vulnerable to adversarial examples, and even a single character change can negatively affect its reli",
    "path": "papers/23/04/2304.08979.json",
    "total_tokens": 995,
    "translated_title": "ChatGPT可靠性的测量与特征化",
    "translated_abstract": "随着ChatGPT的出现，用户获取信息的方式正在发生范式转变。与传统的搜索引擎不同，ChatGPT从模型本身检索知识并为用户生成答案。ChatGPT令人印象深刻的问答能力吸引了超过1亿用户，但也引发了人们关于其可靠性的担忧。本文通过精心策划的5695个问题跨越十个数据集和八个领域，首次对ChatGPT在通用问答场景中的可靠性进行了大规模测量。我们发现ChatGPT的可靠性因不同领域而异，尤其在法律和科学问题方面表现不佳。我们还证明了OpenAI设计的系统角色可以影响ChatGPT的可靠性。我们进一步展示了ChatGPT容易受到对抗性示例的影响，即使是单个字符的更改也会对其可靠性产生负面影响。我们的结果揭示了ChatGPT可靠性的局限性，并对其在实际应用中的使用产生影响。",
    "tldr": "本文首次对ChatGPT在通用问答场景中的可靠性进行了大规模测量，发现其在不同领域的可靠性有所差异，尤其在法律和科学问题方面表现不佳，并容易受到对抗性示例的影响，对其在实际应用中的使用产生影响。",
    "en_tdlr": "This paper presents the first large-scale measurement of ChatGPT's reliability in the generic QA scenario, finding its reliability varies across different domains, particularly underperforming in law and science questions, and is vulnerable to adversarial examples, and its results have implications for its practical use in real-world applications."
}