{
    "title": "DoctorGLM: Fine-tuning your Chinese Doctor is not a Herculean Task. (arXiv:2304.01097v2 [cs.CL] UPDATED)",
    "abstract": "The recent progress of large language models (LLMs), including ChatGPT and GPT-4, in comprehending and responding to human instructions has been remarkable. Nevertheless, these models typically perform better in English and have not been explicitly trained for the medical domain, resulting in suboptimal precision in diagnoses, drug recommendations, and other medical advice. Additionally, training and deploying a dialogue model is still believed to be impossible for hospitals, hindering the promotion of LLMs. To tackle these challenges, we have collected databases of medical dialogues in Chinese with ChatGPT's help and adopted several techniques to train an easy-deploy LLM. Remarkably, we were able to fine-tune the ChatGLM-6B on a single A100 80G in 13 hours, which means having a healthcare-purpose LLM can be very affordable. DoctorGLM is currently an early-stage engineering attempt and contain various mistakes. We are sharing it with the broader community to invite feedback and suggest",
    "link": "http://arxiv.org/abs/2304.01097",
    "context": "Title: DoctorGLM: Fine-tuning your Chinese Doctor is not a Herculean Task. (arXiv:2304.01097v2 [cs.CL] UPDATED)\nAbstract: The recent progress of large language models (LLMs), including ChatGPT and GPT-4, in comprehending and responding to human instructions has been remarkable. Nevertheless, these models typically perform better in English and have not been explicitly trained for the medical domain, resulting in suboptimal precision in diagnoses, drug recommendations, and other medical advice. Additionally, training and deploying a dialogue model is still believed to be impossible for hospitals, hindering the promotion of LLMs. To tackle these challenges, we have collected databases of medical dialogues in Chinese with ChatGPT's help and adopted several techniques to train an easy-deploy LLM. Remarkably, we were able to fine-tune the ChatGLM-6B on a single A100 80G in 13 hours, which means having a healthcare-purpose LLM can be very affordable. DoctorGLM is currently an early-stage engineering attempt and contain various mistakes. We are sharing it with the broader community to invite feedback and suggest",
    "path": "papers/23/04/2304.01097.json",
    "total_tokens": 963,
    "translated_title": "DoctorGLM：让中文医生调整不再是一个艰巨的任务",
    "translated_abstract": "近期大型语言模型（LLM），包括ChatGPT和GPT-4，在理解和回应人类指令方面取得了显着进展。然而，这些模型通常在英语方面表现更好，并没有明确地针对医学领域进行训练，导致诊断、药物推荐和其他医疗建议的精度不尽如人意。此外，训练和部署对话模型仍被认为对医院来说是不可能的，这阻碍了LLM的推广。为了解决这些挑战，我们利用ChatGPT的帮助收集了中文的医学对话数据库，并采用了多种技术来训练一个易于部署的LLM。值得注意的是，我们能够在单个A100 80G上以13个小时的时间对ChatGLM-6B进行微调，这意味着拥有一个以医疗为目的的LLM可能非常实惠。DoctorGLM目前是一项早期的工程尝试，包含各种错误。我们与广大社区分享，并邀请反馈和建议改进。",
    "tldr": "使用中文医学对话数据库，微调ChatGLM-6B模型，实现易于部署的以医疗为目的的LLM，从而提高医疗建议的精度和推广LLM的可行性。"
}