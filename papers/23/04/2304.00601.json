{
    "title": "Constructive Assimilation: Boosting Contrastive Learning Performance through View Generation Strategies. (arXiv:2304.00601v2 [cs.CV] UPDATED)",
    "abstract": "Transformations based on domain expertise (expert transformations), such as random-resized-crop and color-jitter, have proven critical to the success of contrastive learning techniques such as SimCLR. Recently, several attempts have been made to replace such domain-specific, human-designed transformations with generated views that are learned. However for imagery data, so far none of these view-generation methods has been able to outperform expert transformations. In this work, we tackle a different question: instead of replacing expert transformations with generated views, can we constructively assimilate generated views with expert transformations? We answer this question in the affirmative and propose a view generation method and a simple, effective assimilation method that together improve the state-of-the-art by up to ~3.6% on three different datasets. Importantly, we conduct a detailed empirical study that systematically analyzes a range of view generation and assimilation method",
    "link": "http://arxiv.org/abs/2304.00601",
    "context": "Title: Constructive Assimilation: Boosting Contrastive Learning Performance through View Generation Strategies. (arXiv:2304.00601v2 [cs.CV] UPDATED)\nAbstract: Transformations based on domain expertise (expert transformations), such as random-resized-crop and color-jitter, have proven critical to the success of contrastive learning techniques such as SimCLR. Recently, several attempts have been made to replace such domain-specific, human-designed transformations with generated views that are learned. However for imagery data, so far none of these view-generation methods has been able to outperform expert transformations. In this work, we tackle a different question: instead of replacing expert transformations with generated views, can we constructively assimilate generated views with expert transformations? We answer this question in the affirmative and propose a view generation method and a simple, effective assimilation method that together improve the state-of-the-art by up to ~3.6% on three different datasets. Importantly, we conduct a detailed empirical study that systematically analyzes a range of view generation and assimilation method",
    "path": "papers/23/04/2304.00601.json",
    "total_tokens": 847,
    "translated_title": "建构性同化：通过视图生成策略提升对比学习性能",
    "translated_abstract": "基于领域专业知识（专家转换）的变换，例如随机裁剪和颜色扰动，已经被证明是对比学习技术（例如SimCLR）成功的关键。最近，有几次尝试用学习的生成视图代替这样的领域特定的、人工设计的转换。然而，到目前为止，针对图像数据，这些视图生成方法都无法胜任专家转换的工作。在本研究中，我们提出了一个不同的问题：我们能否将生成的视图与专家转换建构性地同化，而不是将其替换为专家转换？我们肯定地回答了这个问题，并提出了一个视图生成方法和一个简单有效的同化方法，这两者一起提高了三个不同数据集上的最新水平，最高达到了 ~3.6%。重要的是，我们进行了详细的实证研究，系统地分析了一系列的视图生成和同化方法。",
    "tldr": "本文提出了一种建构性同化方法，结合生成视图和专家转换，提高了对比学习技术在三个数据集上的性能。",
    "en_tdlr": "This paper proposes a constructive assimilation method that combines generated views and expert transformations to improve the performance of contrastive learning techniques on three different datasets by up to ~3.6%."
}