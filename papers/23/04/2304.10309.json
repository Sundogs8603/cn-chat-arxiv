{
    "title": "Improving Speech Translation by Cross-Modal Multi-Grained Contrastive Learning. (arXiv:2304.10309v1 [cs.CL])",
    "abstract": "The end-to-end speech translation (E2E-ST) model has gradually become a mainstream paradigm due to its low latency and less error propagation. However, it is non-trivial to train such a model well due to the task complexity and data scarcity. The speech-and-text modality differences result in the E2E-ST model performance usually inferior to the corresponding machine translation (MT) model. Based on the above observation, existing methods often use sharingmechanisms to carry out implicit knowledge transfer by imposing various constraints. However, the final model often performs worse on the MT task than the MT model trained alone, which means that the knowledge transfer ability of this method is also limited. To deal with these problems, we propose the FCCL (Fine- and Coarse- Granularity Contrastive Learning) approach for E2E-ST, which makes explicit knowledge transfer through cross-modal multi-grained contrastive learning. A key ingredient of our approach is applying contrastive learni",
    "link": "http://arxiv.org/abs/2304.10309",
    "context": "Title: Improving Speech Translation by Cross-Modal Multi-Grained Contrastive Learning. (arXiv:2304.10309v1 [cs.CL])\nAbstract: The end-to-end speech translation (E2E-ST) model has gradually become a mainstream paradigm due to its low latency and less error propagation. However, it is non-trivial to train such a model well due to the task complexity and data scarcity. The speech-and-text modality differences result in the E2E-ST model performance usually inferior to the corresponding machine translation (MT) model. Based on the above observation, existing methods often use sharingmechanisms to carry out implicit knowledge transfer by imposing various constraints. However, the final model often performs worse on the MT task than the MT model trained alone, which means that the knowledge transfer ability of this method is also limited. To deal with these problems, we propose the FCCL (Fine- and Coarse- Granularity Contrastive Learning) approach for E2E-ST, which makes explicit knowledge transfer through cross-modal multi-grained contrastive learning. A key ingredient of our approach is applying contrastive learni",
    "path": "papers/23/04/2304.10309.json",
    "total_tokens": 1194,
    "translated_title": "基于跨模态多粒度对比学习的语音翻译模型优化",
    "translated_abstract": "由于低延迟和误差传播少，端到端语音翻译（E2E-ST）模型已成为主流的范例。然而，由于任务复杂性和数据稀缺性，训练这样的模型并不容易。由于语音和文本MODALITY的差异，E2E-ST模型的性能通常比相应的机器翻译（MT）模型稍逊。现有方法通常通过施加各种约束来使用共享机制进行隐式知识转移。然而，最终的模型在MT任务上的表现往往比单独训练的MT模型还要差，这意味着这种方法的知识转移能力也是有限的。为了解决这些问题，我们提出了适用于E2E-ST的FCCL（Fine- and Coarse- Granularity Contrastive Learning）方法，它通过跨模态多粒度对比学习进行显式知识转移。我们方法的一个关键组成部分是在多个粒度级别上对编码器输出和解码器输入进行对比学习。具体而言，我们对语音编码器输出和文本解码器输入进行精细和粗粒度的对比学习。此外，我们引入了一种支持E2E-ST和MT模型同时优化的多任务学习方案。实验结果表明，我们的方法在E2E-ST任务和MT任务上均取得了显著的改进，并且在MuST-C基准测试中表现优于现有技术水平。",
    "tldr": "本文提出了基于跨模态多粒度对比学习的语音翻译模型优化方法，该方法通过跨模态多粒度对比学习进行显式知识转移，并在E2E-ST和MT任务上都取得了显著的改进。",
    "en_tdlr": "This paper proposes an improved speech translation model based on cross-modal multi-grained contrastive learning. The approach makes explicit knowledge transfer through multi-grained contrastive learning and supports simultaneous optimization of E2E-ST and MT models. Experimental results show significant improvement over existing methods on both E2E-ST and MT tasks, outperforming the state-of-the-art on the MuST-C benchmark."
}