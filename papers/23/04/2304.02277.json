{
    "title": "Rethinking the Trigger-injecting Position in Graph Backdoor Attack. (arXiv:2304.02277v1 [cs.LG])",
    "abstract": "Backdoor attacks have been demonstrated as a security threat for machine learning models. Traditional backdoor attacks intend to inject backdoor functionality into the model such that the backdoored model will perform abnormally on inputs with predefined backdoor triggers and still retain state-of-the-art performance on the clean inputs. While there are already some works on backdoor attacks on Graph Neural Networks (GNNs), the backdoor trigger in the graph domain is mostly injected into random positions of the sample. There is no work analyzing and explaining the backdoor attack performance when injecting triggers into the most important or least important area in the sample, which we refer to as trigger-injecting strategies MIAS and LIAS, respectively. Our results show that, generally, LIAS performs better, and the differences between the LIAS and MIAS performance can be significant. Furthermore, we explain these two strategies' similar (better) attack performance through explanation",
    "link": "http://arxiv.org/abs/2304.02277",
    "context": "Title: Rethinking the Trigger-injecting Position in Graph Backdoor Attack. (arXiv:2304.02277v1 [cs.LG])\nAbstract: Backdoor attacks have been demonstrated as a security threat for machine learning models. Traditional backdoor attacks intend to inject backdoor functionality into the model such that the backdoored model will perform abnormally on inputs with predefined backdoor triggers and still retain state-of-the-art performance on the clean inputs. While there are already some works on backdoor attacks on Graph Neural Networks (GNNs), the backdoor trigger in the graph domain is mostly injected into random positions of the sample. There is no work analyzing and explaining the backdoor attack performance when injecting triggers into the most important or least important area in the sample, which we refer to as trigger-injecting strategies MIAS and LIAS, respectively. Our results show that, generally, LIAS performs better, and the differences between the LIAS and MIAS performance can be significant. Furthermore, we explain these two strategies' similar (better) attack performance through explanation",
    "path": "papers/23/04/2304.02277.json",
    "total_tokens": 895,
    "translated_title": "重新思考图形后门攻击中注入触发器的位置",
    "translated_abstract": "后门攻击已经被证明是机器学习模型的安全威胁。传统的后门攻击意图将后门功能注入模型中，使得带有预定义后门触发器的输入能够出现异常的表现，但是该模型在干净的输入上仍然能够达到最先进的性能。虽然已经有一些关于图神经网络（GNN）背门攻击的研究，但是在图领域中的后门触发器大多被注入到样本的随机位置。尚未有研究分析和解释在样本的最重要或最不重要的区域注入触发器的背门攻击的性能，我们将其称为触发注入策略MIAS和LIAS。我们的研究结果表明，一般来说，LIAS的表现更好，并且LIAS和MIAS表现之间的差异可能是显著的。此外，我们通过解释说明了这两种策略的相似（更好）的攻击性能。",
    "tldr": "论文研究了在图神经网络中的背门攻击，发现在样本的最不重要区域中注入触发器的背门攻击效果更好，对该现象进行了解释。",
    "en_tdlr": "This paper investigates the backdoor attack on graph neural networks and finds that injecting triggers in the least important area of the sample has better attack performance. The phenomenon is explained by the authors."
}