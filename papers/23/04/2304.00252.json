{
    "title": "Recover Triggered States: Protect Model Against Backdoor Attack in Reinforcement Learning. (arXiv:2304.00252v1 [cs.LG])",
    "abstract": "A backdoor attack allows a malicious user to manipulate the environment or corrupt the training data, thus inserting a backdoor into the trained agent. Such attacks compromise the RL system's reliability, leading to potentially catastrophic results in various key fields. In contrast, relatively limited research has investigated effective defenses against backdoor attacks in RL. This paper proposes the Recovery Triggered States (RTS) method, a novel approach that effectively protects the victim agents from backdoor attacks. RTS involves building a surrogate network to approximate the dynamics model. Developers can then recover the environment from the triggered state to a clean state, thereby preventing attackers from activating backdoors hidden in the agent by presenting the trigger. When training the surrogate to predict states, we incorporate agent action information to reduce the discrepancy between the actions taken by the agent on predicted states and the actions taken on real sta",
    "link": "http://arxiv.org/abs/2304.00252",
    "context": "Title: Recover Triggered States: Protect Model Against Backdoor Attack in Reinforcement Learning. (arXiv:2304.00252v1 [cs.LG])\nAbstract: A backdoor attack allows a malicious user to manipulate the environment or corrupt the training data, thus inserting a backdoor into the trained agent. Such attacks compromise the RL system's reliability, leading to potentially catastrophic results in various key fields. In contrast, relatively limited research has investigated effective defenses against backdoor attacks in RL. This paper proposes the Recovery Triggered States (RTS) method, a novel approach that effectively protects the victim agents from backdoor attacks. RTS involves building a surrogate network to approximate the dynamics model. Developers can then recover the environment from the triggered state to a clean state, thereby preventing attackers from activating backdoors hidden in the agent by presenting the trigger. When training the surrogate to predict states, we incorporate agent action information to reduce the discrepancy between the actions taken by the agent on predicted states and the actions taken on real sta",
    "path": "papers/23/04/2304.00252.json",
    "total_tokens": 896,
    "translated_title": "RL中的反向攻击保护：恢复触发状态方法",
    "translated_abstract": "反向攻击可以使恶意用户操纵环境或破坏训练数据，并将一个隐藏的后门插入到训练代理程序中。这种攻击危及RL系统的可靠性，在各个关键领域可能会造成灾难性的影响。与此相比，对于RL中的反向攻击有效的防御措施的研究相对较少。本文提出了一种新颖的方法——恢复触发状态(RTS)，能够有效地保护受害代理免受反向攻击。 RTS需要构建一个替代网络来近似动态模型。开发人员可以通过将触发状态恢复为干净状态来防止攻击者通过触发器激活代理中隐藏的后门。在训练替代网络来预测状态时，我们将代理动作信息并入，减少代理在预测状态上采取的动作和实际状态上采取的动作之间的差异。",
    "tldr": "本文提出了恢复触发状态(RTS)方法，用于保护RL代理免受反向攻击。该方法涉及构建替代网络来近似动态模型，并将触发状态恢复为干净状态来防止攻击者通过触发器激活隐藏在代理中的后门。",
    "en_tdlr": "This paper proposes the Recovery Triggered States (RTS) method to effectively protect RL agents from backdoor attacks by building a surrogate network to approximate the dynamics model and recovering the triggered states to prevent attackers from activating hidden backdoors."
}