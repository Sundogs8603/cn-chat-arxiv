{
    "title": "Multi-Source to Multi-Target Decentralized Federated Domain Adaptation. (arXiv:2304.12422v1 [cs.DC])",
    "abstract": "Heterogeneity across devices in federated learning (FL) typically refers to statistical (e.g., non-i.i.d. data distributions) and resource (e.g., communication bandwidth) dimensions. In this paper, we focus on another important dimension that has received less attention: varying quantities/distributions of labeled and unlabeled data across devices. In order to leverage all data, we develop a decentralized federated domain adaptation methodology which considers the transfer of ML models from devices with high quality labeled data (called sources) to devices with low quality or unlabeled data (called targets). Our methodology, Source-Target Determination and Link Formation (ST-LF), optimizes both (i) classification of devices into sources and targets and (ii) source-target link formation, in a manner that considers the trade-off between ML model accuracy and communication energy efficiency. To obtain a concrete objective function, we derive a measurable generalization error bound that ac",
    "link": "http://arxiv.org/abs/2304.12422",
    "context": "Title: Multi-Source to Multi-Target Decentralized Federated Domain Adaptation. (arXiv:2304.12422v1 [cs.DC])\nAbstract: Heterogeneity across devices in federated learning (FL) typically refers to statistical (e.g., non-i.i.d. data distributions) and resource (e.g., communication bandwidth) dimensions. In this paper, we focus on another important dimension that has received less attention: varying quantities/distributions of labeled and unlabeled data across devices. In order to leverage all data, we develop a decentralized federated domain adaptation methodology which considers the transfer of ML models from devices with high quality labeled data (called sources) to devices with low quality or unlabeled data (called targets). Our methodology, Source-Target Determination and Link Formation (ST-LF), optimizes both (i) classification of devices into sources and targets and (ii) source-target link formation, in a manner that considers the trade-off between ML model accuracy and communication energy efficiency. To obtain a concrete objective function, we derive a measurable generalization error bound that ac",
    "path": "papers/23/04/2304.12422.json",
    "total_tokens": 825,
    "translated_title": "多源到多目标的分布式联邦领域自适应",
    "translated_abstract": "联邦学习中设备间的异质性通常指统计（例如，非独立同分布的数据分布）和资源（例如，通信带宽）维度。本文聚焦另一个重要维度：各设备所拥有的标记和未标记数据数量/分布。为了利用所有数据，我们开发了一种分布式联邦领域适应方法，将机器学习模型从标记数据高质量设备（称为源）转移到低质量或未标记数据设备（称为目标）。我们的方法，“源-目标确定和链接形成”（ST-LF），在考虑模型精度和通信能量效率之间的权衡的同时，优化设备分类和源-目标链接形成。",
    "tldr": "本文提出了一种分布式联邦学习方法，可将机器学习模型从标记数据丰富的设备转移到未标记数据设备以提高数据利用率。该方法考虑了设备分类和源-目标链接形成的权衡。",
    "en_tdlr": "This paper proposes a decentralized federated domain adaptation methodology, ST-LF, that optimizes device classification and source-target link formation to transfer machine learning models from labeled data-rich devices to unlabeled data devices, considering the trade-off between model accuracy and communication energy efficiency."
}