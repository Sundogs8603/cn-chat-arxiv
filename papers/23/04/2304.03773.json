{
    "title": "Safe Explicable Robot Planning. (arXiv:2304.03773v1 [cs.RO])",
    "abstract": "Human expectations stem from their knowledge of the others and the world. Where human-robot interaction is concerned, such knowledge about the robot may be inconsistent with the ground truth, resulting in the robot not meeting its expectations. Explicable planning was previously introduced as a novel planning approach to reconciling human expectations and the optimal robot behavior for more interpretable robot decision-making. One critical issue that remains unaddressed is safety during explicable decision-making which can lead to explicable behaviors that are unsafe. We propose Safe Explicable Planning (SEP), which extends explicable planning to support the specification of a safety bound. The objective of SEP is to find a policy that generates a behavior close to human expectations while satisfying the safety constraints introduced by the bound, which is a special case of multi-objective optimization where the solution to SEP lies on the Pareto frontier. Under such a formulation, we ",
    "link": "http://arxiv.org/abs/2304.03773",
    "context": "Title: Safe Explicable Robot Planning. (arXiv:2304.03773v1 [cs.RO])\nAbstract: Human expectations stem from their knowledge of the others and the world. Where human-robot interaction is concerned, such knowledge about the robot may be inconsistent with the ground truth, resulting in the robot not meeting its expectations. Explicable planning was previously introduced as a novel planning approach to reconciling human expectations and the optimal robot behavior for more interpretable robot decision-making. One critical issue that remains unaddressed is safety during explicable decision-making which can lead to explicable behaviors that are unsafe. We propose Safe Explicable Planning (SEP), which extends explicable planning to support the specification of a safety bound. The objective of SEP is to find a policy that generates a behavior close to human expectations while satisfying the safety constraints introduced by the bound, which is a special case of multi-objective optimization where the solution to SEP lies on the Pareto frontier. Under such a formulation, we ",
    "path": "papers/23/04/2304.03773.json",
    "total_tokens": 900,
    "translated_title": "安全可解释机器人规划",
    "translated_abstract": "人们的期望源自于他们对其他人和世界的了解。在涉及到人机交互的情况下，对机器人的了解可能与现实不符，导致机器人不能满足人们的期望。可解释规划被引入作为一种新颖的规划方法，以协调人类期望和最优机器人行为，进行更可解释的机器人决策。一个关键的问题尚未得到解决，那就是在可解释决策过程中的安全性问题，这可能会导致不安全的可解释行为。我们提出了安全可解释规划（SEP），它扩展了可解释规划，支持安全界限的规定。 SEP的目标是找到一种策略，生成接近于人类期望的行为，同时满足安全约束的要求。这是多目标优化的一种特殊情况，SEP的解决方案位于帕累托前沿，提供了一个切实可行的解决方案，在不牺牲任何方面的重要性的前提下，产生了安全性和解释性之间的一个权衡。",
    "tldr": "安全可解释机器人规划方法（SEP）扩展了可解释规划，支持安全界限的规定，以实现安全和可解释之间的权衡。",
    "en_tdlr": "Safe Explicable Planning (SEP) extends explicable planning to support the specification of a safety bound, providing a tractable solution that produces a compromise between safety and interpretability."
}