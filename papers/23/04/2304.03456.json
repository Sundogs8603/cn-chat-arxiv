{
    "title": "Rethinking Evaluation Protocols of Visual Representations Learned via Self-supervised Learning. (arXiv:2304.03456v1 [cs.CV])",
    "abstract": "Linear probing (LP) (and $k$-NN) on the upstream dataset with labels (e.g., ImageNet) and transfer learning (TL) to various downstream datasets are commonly employed to evaluate the quality of visual representations learned via self-supervised learning (SSL). Although existing SSL methods have shown good performances under those evaluation protocols, we observe that the performances are very sensitive to the hyperparameters involved in LP and TL. We argue that this is an undesirable behavior since truly generic representations should be easily adapted to any other visual recognition task, i.e., the learned representations should be robust to the settings of LP and TL hyperparameters. In this work, we try to figure out the cause of performance sensitivity by conducting extensive experiments with state-of-the-art SSL methods. First, we find that input normalization for LP is crucial to eliminate performance variations according to the hyperparameters. Specifically, batch normalization be",
    "link": "http://arxiv.org/abs/2304.03456",
    "context": "Title: Rethinking Evaluation Protocols of Visual Representations Learned via Self-supervised Learning. (arXiv:2304.03456v1 [cs.CV])\nAbstract: Linear probing (LP) (and $k$-NN) on the upstream dataset with labels (e.g., ImageNet) and transfer learning (TL) to various downstream datasets are commonly employed to evaluate the quality of visual representations learned via self-supervised learning (SSL). Although existing SSL methods have shown good performances under those evaluation protocols, we observe that the performances are very sensitive to the hyperparameters involved in LP and TL. We argue that this is an undesirable behavior since truly generic representations should be easily adapted to any other visual recognition task, i.e., the learned representations should be robust to the settings of LP and TL hyperparameters. In this work, we try to figure out the cause of performance sensitivity by conducting extensive experiments with state-of-the-art SSL methods. First, we find that input normalization for LP is crucial to eliminate performance variations according to the hyperparameters. Specifically, batch normalization be",
    "path": "papers/23/04/2304.03456.json",
    "total_tokens": 771,
    "translated_title": "重新思考基于自监督学习的视觉表示评价协议",
    "translated_abstract": "对学习自监督学习的视觉表示的质量进行评价常常采用在带标注的上游数据集上进行的线性探测和K-NN方法，以及将其迁移到各种下游数据集上的迁移学习。虽然现有的自监督学习方法已经在这些评价协议下表现出良好的性能，但我们观察到这些性能非常敏感于线性探测和迁移学习中涉及的超参数。本文试图通过进行大量实验来找出这种性能敏感性的原因。结果发现，对于线性探测来说，输入归一化是消除性能变化的关键因素。",
    "tldr": "本研究重新思考基于自监督学习的视觉表示的评价协议，发现对于线性探测来说，输入归一化是消除性能变化的关键因素。",
    "en_tdlr": "This paper rethinks the evaluation protocols of visual representations learned via self-supervised learning and finds that input normalization is crucial to eliminate the sensitivity of linear probing."
}