{
    "title": "Make It So: Steering StyleGAN for Any Image Inversion and Editing. (arXiv:2304.14403v1 [cs.CV])",
    "abstract": "StyleGAN's disentangled style representation enables powerful image editing by manipulating the latent variables, but accurately mapping real-world images to their latent variables (GAN inversion) remains a challenge. Existing GAN inversion methods struggle to maintain editing directions and produce realistic results.  To address these limitations, we propose Make It So, a novel GAN inversion method that operates in the $\\mathcal{Z}$ (noise) space rather than the typical $\\mathcal{W}$ (latent style) space. Make It So preserves editing capabilities, even for out-of-domain images. This is a crucial property that was overlooked in prior methods. Our quantitative evaluations demonstrate that Make It So outperforms the state-of-the-art method PTI~\\cite{roich2021pivotal} by a factor of five in inversion accuracy and achieves ten times better edit quality for complex indoor scenes.",
    "link": "http://arxiv.org/abs/2304.14403",
    "context": "Title: Make It So: Steering StyleGAN for Any Image Inversion and Editing. (arXiv:2304.14403v1 [cs.CV])\nAbstract: StyleGAN's disentangled style representation enables powerful image editing by manipulating the latent variables, but accurately mapping real-world images to their latent variables (GAN inversion) remains a challenge. Existing GAN inversion methods struggle to maintain editing directions and produce realistic results.  To address these limitations, we propose Make It So, a novel GAN inversion method that operates in the $\\mathcal{Z}$ (noise) space rather than the typical $\\mathcal{W}$ (latent style) space. Make It So preserves editing capabilities, even for out-of-domain images. This is a crucial property that was overlooked in prior methods. Our quantitative evaluations demonstrate that Make It So outperforms the state-of-the-art method PTI~\\cite{roich2021pivotal} by a factor of five in inversion accuracy and achieves ten times better edit quality for complex indoor scenes.",
    "path": "papers/23/04/2304.14403.json",
    "total_tokens": 924,
    "translated_title": "让它变成现实: 用于任何图像反转和编辑的Steering StyleGAN",
    "translated_abstract": "StyleGAN的分离风格表示使得通过操作潜在变量进行强大的图像编辑成为可能，但准确地将现实世界的图像映射到它们的潜在变量（GAN反演）仍然是一个挑战。现有的GAN反演方法在维持编辑方向和生成逼真结果方面遇到困难。为了解决这些限制，我们提出了Make It So，一种新颖的GAN反演方法，它在$\\mathcal{Z}$（噪声）空间而不是典型的$\\mathcal{W}$（潜在风格）空间中运行。Make It So保留了编辑能力，即使是在域外图像方面。这是以前方法中被忽视的关键属性。我们的定量评估表明，Make It So在反演精度方面比最先进的PTI方法~\\cite{roich2021pivotal}提高了五倍，并且对于复杂的室内场景，实现了十倍更好的编辑质量。",
    "tldr": "本文提出了一种新颖的GAN反演方法Make It So，在噪声空间中操作使得保留了编辑能力，即使是在域外图像方面，比现有方法更准确，反演精度提高五倍，并且对于复杂的室内场景，实现了十倍更好的编辑质量。",
    "en_tdlr": "The paper proposes a novel GAN inversion method called Make It So, which operates in the noise space and preserves editing capabilities even for out-of-domain images. It outperforms the state-of-the-art method PTI in inversion accuracy by a factor of five and achieves ten times better edit quality for complex indoor scenes."
}