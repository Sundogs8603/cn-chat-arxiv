{
    "title": "Communicating Uncertainty in Machine Learning Explanations: A Visualization Analytics Approach for Predictive Process Monitoring. (arXiv:2304.05736v1 [cs.LG])",
    "abstract": "As data-driven intelligent systems advance, the need for reliable and transparent decision-making mechanisms has become increasingly important. Therefore, it is essential to integrate uncertainty quantification and model explainability approaches to foster trustworthy business and operational process analytics. This study explores how model uncertainty can be effectively communicated in global and local post-hoc explanation approaches, such as Partial Dependence Plots (PDP) and Individual Conditional Expectation (ICE) plots. In addition, this study examines appropriate visualization analytics approaches to facilitate such methodological integration. By combining these two research directions, decision-makers can not only justify the plausibility of explanation-driven actionable insights but also validate their reliability. Finally, the study includes expert interviews to assess the suitability of the proposed approach and designed interface for a real-world predictive process monitorin",
    "link": "http://arxiv.org/abs/2304.05736",
    "context": "Title: Communicating Uncertainty in Machine Learning Explanations: A Visualization Analytics Approach for Predictive Process Monitoring. (arXiv:2304.05736v1 [cs.LG])\nAbstract: As data-driven intelligent systems advance, the need for reliable and transparent decision-making mechanisms has become increasingly important. Therefore, it is essential to integrate uncertainty quantification and model explainability approaches to foster trustworthy business and operational process analytics. This study explores how model uncertainty can be effectively communicated in global and local post-hoc explanation approaches, such as Partial Dependence Plots (PDP) and Individual Conditional Expectation (ICE) plots. In addition, this study examines appropriate visualization analytics approaches to facilitate such methodological integration. By combining these two research directions, decision-makers can not only justify the plausibility of explanation-driven actionable insights but also validate their reliability. Finally, the study includes expert interviews to assess the suitability of the proposed approach and designed interface for a real-world predictive process monitorin",
    "path": "papers/23/04/2304.05736.json",
    "total_tokens": 936,
    "tldr": "本研究探讨了如何有效地传达机器学习模型解释中的不确定性，并提出了基于可视化分析的方法，以促进全局和局部后置解释方法的方法学集成，从而促进可信的业务和操作过程分析。",
    "en_tdlr": "This study proposes a visualization analytics approach to communicate uncertainty in machine learning explanations and enable methodological integration, and includes expert interviews to assess its suitability for predictive process monitoring."
}