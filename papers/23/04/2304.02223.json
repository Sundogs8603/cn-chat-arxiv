{
    "title": "Local Intrinsic Dimensional Entropy. (arXiv:2304.02223v1 [cs.LG])",
    "abstract": "Most entropy measures depend on the spread of the probability distribution over the sample space X, and the maximum entropy achievable scales proportionately with the sample space cardinality |X|. For a finite |X|, this yields robust entropy measures which satisfy many important properties, such as invariance to bijections, while the same is not true for continuous spaces (where |X|=infinity). Furthermore, since R and R^d (d in Z+) have the same cardinality (from Cantor's correspondence argument), cardinality-dependent entropy measures cannot encode the data dimensionality. In this work, we question the role of cardinality and distribution spread in defining entropy measures for continuous spaces, which can undergo multiple rounds of transformations and distortions, e.g., in neural networks. We find that the average value of the local intrinsic dimension of a distribution, denoted as ID-Entropy, can serve as a robust entropy measure for continuous spaces, while capturing the data dimen",
    "link": "http://arxiv.org/abs/2304.02223",
    "context": "Title: Local Intrinsic Dimensional Entropy. (arXiv:2304.02223v1 [cs.LG])\nAbstract: Most entropy measures depend on the spread of the probability distribution over the sample space X, and the maximum entropy achievable scales proportionately with the sample space cardinality |X|. For a finite |X|, this yields robust entropy measures which satisfy many important properties, such as invariance to bijections, while the same is not true for continuous spaces (where |X|=infinity). Furthermore, since R and R^d (d in Z+) have the same cardinality (from Cantor's correspondence argument), cardinality-dependent entropy measures cannot encode the data dimensionality. In this work, we question the role of cardinality and distribution spread in defining entropy measures for continuous spaces, which can undergo multiple rounds of transformations and distortions, e.g., in neural networks. We find that the average value of the local intrinsic dimension of a distribution, denoted as ID-Entropy, can serve as a robust entropy measure for continuous spaces, while capturing the data dimen",
    "path": "papers/23/04/2304.02223.json",
    "total_tokens": 876,
    "translated_title": "本地固有维度熵。",
    "translated_abstract": "大多数熵测量依赖于概率分布在样本空间X上的展布情况，最大可实现熵与样本空间基数|X|成比例。对于有限|X|，这产生了满足许多重要属性（如对双射的不变性）的强大熵测量，而同样不能满足连续空间的要求（其中|X|=无穷大）。此外，由于R和R^d（d在Z+中）具有相同的基数（来自Cantor的对应论证），基数依赖性熵测量无法编码数据维度。在本文中，我们质疑了对连续空间定义熵测量中基数和分布展布的作用，这些连续空间可以进行多轮变换和扭曲，例如在神经网络中。我们发现如果用分布的局部固有维度的平均值来表示测量熵，被称为ID-Entropy，那么可以作为连续空间的强大熵测量，同时捕捉数据的维度。",
    "tldr": "本文提出了一种新的在连续空间中测量熵的方法，称为ID-Entropy，它可以用于多轮数据变换和扭曲，同时可以捕捉数据的维度。",
    "en_tdlr": "This paper proposes a novel method, called ID-Entropy, for measuring entropy in continuous spaces, which can be used for multiple rounds of data transformation and distortion, while capturing the data dimensionality."
}