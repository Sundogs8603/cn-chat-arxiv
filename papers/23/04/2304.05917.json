{
    "title": "A Phoneme-Informed Neural Network Model for Note-Level Singing Transcription. (arXiv:2304.05917v1 [cs.SD])",
    "abstract": "Note-level automatic music transcription is one of the most representative music information retrieval (MIR) tasks and has been studied for various instruments to understand music. However, due to the lack of high-quality labeled data, transcription of many instruments is still a challenging task. In particular, in the case of singing, it is difficult to find accurate notes due to its expressiveness in pitch, timbre, and dynamics. In this paper, we propose a method of finding note onsets of singing voice more accurately by leveraging the linguistic characteristics of singing, which are not seen in other instruments. The proposed model uses mel-scaled spectrogram and phonetic posteriorgram (PPG), a frame-wise likelihood of phoneme, as an input of the onset detection network while PPG is generated by the pre-trained network with singing and speech data. To verify how linguistic features affect onset detection, we compare the evaluation results through the dataset with different languages",
    "link": "http://arxiv.org/abs/2304.05917",
    "context": "Title: A Phoneme-Informed Neural Network Model for Note-Level Singing Transcription. (arXiv:2304.05917v1 [cs.SD])\nAbstract: Note-level automatic music transcription is one of the most representative music information retrieval (MIR) tasks and has been studied for various instruments to understand music. However, due to the lack of high-quality labeled data, transcription of many instruments is still a challenging task. In particular, in the case of singing, it is difficult to find accurate notes due to its expressiveness in pitch, timbre, and dynamics. In this paper, we propose a method of finding note onsets of singing voice more accurately by leveraging the linguistic characteristics of singing, which are not seen in other instruments. The proposed model uses mel-scaled spectrogram and phonetic posteriorgram (PPG), a frame-wise likelihood of phoneme, as an input of the onset detection network while PPG is generated by the pre-trained network with singing and speech data. To verify how linguistic features affect onset detection, we compare the evaluation results through the dataset with different languages",
    "path": "papers/23/04/2304.05917.json",
    "total_tokens": 914,
    "translated_title": "一种基于音素的神经网络模型来进行音符级歌唱转录",
    "translated_abstract": "音符级别的自动音乐转录是最具代表性的音乐信息检索（MIR）任务之一，已经研究了各种乐器来理解音乐。然而，由于缺乏高质量的标注数据，许多乐器的转录仍然是一项具有挑战性的任务。特别是对于唱歌，由于其在音高、音色和动态方面的表现力，很难找到准确的音符。在本文中，我们提出了一种方法，通过利用仅在唱歌中可见的语言特征，更准确地找到唱歌声音的音符起点。所提出的模型使用了梅尔尺度谱图和音素后验图（PPG），即音素的帧级似然，作为起始检测网络的输入，而PPG是通过使用唱歌和语音数据进行预训练网络生成的。为了验证语言特征如何影响起始检测，我们通过具有不同语言的数据集比较了评估结果。",
    "tldr": "本文提出了一种在唱歌转录中更准确地找到音符起点的方法，使用了梅尔尺度谱图和音素后验图作为输入，后者是由预先训练的网络生成的，并证明语言特征对起始检测有影响。",
    "en_tdlr": "This paper proposes a method for more accurately finding note onset in singing transcription using mel-scaled spectrogram and phonetic posteriorgram as input, which is generated by a pre-trained network, and proves that linguistic features affect onset detection."
}