{
    "title": "Decentralized gradient descent maximization method for composite nonconvex strongly-concave minimax problems. (arXiv:2304.02441v1 [math.OC])",
    "abstract": "Minimax problems have recently attracted a lot of research interests. A few efforts have been made to solve decentralized nonconvex strongly-concave (NCSC) minimax-structured optimization; however, all of them focus on smooth problems with at most a constraint on the maximization variable. In this paper, we make the first attempt on solving composite NCSC minimax problems that can have convex nonsmooth terms on both minimization and maximization variables. Our algorithm is designed based on a novel reformulation of the decentralized minimax problem that introduces a multiplier to absorb the dual consensus constraint. The removal of dual consensus constraint enables the most aggressive (i.e., local maximization instead of a gradient ascent step) dual update that leads to the benefit of taking a larger primal stepsize and better complexity results. In addition, the decoupling of the nonsmoothness and consensus on the dual variable eases the analysis of a decentralized algorithm; thus our",
    "link": "http://arxiv.org/abs/2304.02441",
    "context": "Title: Decentralized gradient descent maximization method for composite nonconvex strongly-concave minimax problems. (arXiv:2304.02441v1 [math.OC])\nAbstract: Minimax problems have recently attracted a lot of research interests. A few efforts have been made to solve decentralized nonconvex strongly-concave (NCSC) minimax-structured optimization; however, all of them focus on smooth problems with at most a constraint on the maximization variable. In this paper, we make the first attempt on solving composite NCSC minimax problems that can have convex nonsmooth terms on both minimization and maximization variables. Our algorithm is designed based on a novel reformulation of the decentralized minimax problem that introduces a multiplier to absorb the dual consensus constraint. The removal of dual consensus constraint enables the most aggressive (i.e., local maximization instead of a gradient ascent step) dual update that leads to the benefit of taking a larger primal stepsize and better complexity results. In addition, the decoupling of the nonsmoothness and consensus on the dual variable eases the analysis of a decentralized algorithm; thus our",
    "path": "papers/23/04/2304.02441.json",
    "total_tokens": 1165,
    "translated_title": "分布式梯度下降最大化法解决复合非凸强凹极小极大问题",
    "translated_abstract": "极小极大问题近年来备受关注。为了解决分布式非凸强凹极小极大结构优化问题，研究者们尝试了一些努力，但是它们都局限于最多对极大变量施加一个约束的光滑问题。本文第一次尝试解决可以在最小化和最大化变量上都包含凸非光滑项的复合非凸强凹极小极大问题。我们的算法基于一种新颖的分布式极小极大问题重新表述的形式，该形式引入一个乘子来吸收双重共识约束。消除双重共识约束使得最具攻击性的（即本地最大化而不是梯度上升步骤）双重更新变得可能，有助于采用更大的原始步长和更好的复杂性结果。此外，将非光滑性和对双变量上的一致性进行分离，有助于分析分布式算法；因此我们的算法可以应用于更广泛的非凸强凹极小极大问题中。我们理论上证明了，在某些温和的假设下，我们的算法具有高概率的次线性收敛速度。数值仿真证明了我们的方法在收敛速度、解决方案质量和鲁棒性方面的优越性，与现有方法相比。",
    "tldr": "本文提出了一种用于解决分布式非凸强凹极小极大结构优化问题的方法，并在这种新颖的方法下，成功解决了可以在最小化和最大化变量上都包含凸非光滑项的复合非凸强凹极小极大问题；理论证明了本算法具有高概率的次线性收敛速度。",
    "en_tdlr": "This paper proposes a method for solving distributed nonconvex strongly-concave minimax-structured optimization problems, and successfully solves the composite nonconvex strongly-concave minimax problem with convex nonsmooth terms on both minimization and maximization variables. The method achieves a sublinear convergence rate with high probability under mild assumptions."
}