{
    "title": "VNE: An Effective Method for Improving Deep Representation by Manipulating Eigenvalue Distribution. (arXiv:2304.01434v1 [cs.CV])",
    "abstract": "Since the introduction of deep learning, a wide scope of representation properties, such as decorrelation, whitening, disentanglement, rank, isotropy, and mutual information, have been studied to improve the quality of representation. However, manipulating such properties can be challenging in terms of implementational effectiveness and general applicability. To address these limitations, we propose to regularize von Neumann entropy~(VNE) of representation. First, we demonstrate that the mathematical formulation of VNE is superior in effectively manipulating the eigenvalues of the representation autocorrelation matrix. Then, we demonstrate that it is widely applicable in improving state-of-the-art algorithms or popular benchmark algorithms by investigating domain-generalization, meta-learning, self-supervised learning, and generative models. In addition, we formally establish theoretical connections with rank, disentanglement, and isotropy of representation. Finally, we provide discuss",
    "link": "http://arxiv.org/abs/2304.01434",
    "context": "Title: VNE: An Effective Method for Improving Deep Representation by Manipulating Eigenvalue Distribution. (arXiv:2304.01434v1 [cs.CV])\nAbstract: Since the introduction of deep learning, a wide scope of representation properties, such as decorrelation, whitening, disentanglement, rank, isotropy, and mutual information, have been studied to improve the quality of representation. However, manipulating such properties can be challenging in terms of implementational effectiveness and general applicability. To address these limitations, we propose to regularize von Neumann entropy~(VNE) of representation. First, we demonstrate that the mathematical formulation of VNE is superior in effectively manipulating the eigenvalues of the representation autocorrelation matrix. Then, we demonstrate that it is widely applicable in improving state-of-the-art algorithms or popular benchmark algorithms by investigating domain-generalization, meta-learning, self-supervised learning, and generative models. In addition, we formally establish theoretical connections with rank, disentanglement, and isotropy of representation. Finally, we provide discuss",
    "path": "papers/23/04/2304.01434.json",
    "total_tokens": 942,
    "translated_title": "VNE: 通过操纵特征值分布来提高深度表示的有效方法",
    "translated_abstract": "自从深度学习被引入以来，很多表示特性 (如去相关、白化、解缠、秩、等度性和互信息) 已经被研究出来，以提高表示品质。然而，操纵这些特性在实现有效性和普适适用性方面都具有挑战性。为了解决这些限制，我们提出了对表示的von Neumann熵(VNE)进行规范化。首先，我们证明了VNE的数学表述在有效操纵表示自相关矩阵的特征值方面是优越的。然后，我们通过调查领域通用性，元学习，自监督学习和生成模型等方面，证明了它在提高现有先进算法或流行基准算法中的广泛适用性。此外，我们在理论上建立了表示的秩、解缠和等度性的联系。最后，我们提供了讨论。",
    "tldr": "本文提出了通过规范化表示的von Neumann熵( VNE ) 来改善深度表示的方法，通过操纵特征值分布来优化表示品质，广泛适用于不同的算法，可以增强其领域通用性、元学习、自监督学习和生成模型等方面。",
    "en_tdlr": "This paper proposes an effective method for improving deep representation by regularizing the von Neumann entropy of representation, which can manipulate the eigenvalues of the representation autocorrelation matrix and has wide applicability in enhancing the quality of state-of-the-art and popular benchmark algorithms in various areas, such as domain-generalization, meta-learning, self-supervised learning, and generative models, with established theoretical connections to representation rank, disentanglement, and isotropy."
}