{
    "title": "NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers. (arXiv:2304.09116v1 [eess.AS])",
    "abstract": "Scaling text-to-speech (TTS) to large-scale, multi-speaker, and in-the-wild datasets is important to capture the diversity in human speech such as speaker identities, prosodies, and styles (e.g., singing). Current large TTS systems usually quantize speech into discrete tokens and use language models to generate these tokens one by one, which suffer from unstable prosody, word skipping/repeating issue, and poor voice quality. In this paper, we develop NaturalSpeech 2, a TTS system that leverages a neural audio codec with residual vector quantizers to get the quantized latent vectors and uses a diffusion model to generate these latent vectors conditioned on text input. To enhance the zero-shot capability that is important to achieve diverse speech synthesis, we design a speech prompting mechanism to facilitate in-context learning in the diffusion model and the duration/pitch predictor. We scale NaturalSpeech 2 to large-scale datasets with 44K hours of speech and singing data and evaluate",
    "link": "http://arxiv.org/abs/2304.09116",
    "context": "Title: NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers. (arXiv:2304.09116v1 [eess.AS])\nAbstract: Scaling text-to-speech (TTS) to large-scale, multi-speaker, and in-the-wild datasets is important to capture the diversity in human speech such as speaker identities, prosodies, and styles (e.g., singing). Current large TTS systems usually quantize speech into discrete tokens and use language models to generate these tokens one by one, which suffer from unstable prosody, word skipping/repeating issue, and poor voice quality. In this paper, we develop NaturalSpeech 2, a TTS system that leverages a neural audio codec with residual vector quantizers to get the quantized latent vectors and uses a diffusion model to generate these latent vectors conditioned on text input. To enhance the zero-shot capability that is important to achieve diverse speech synthesis, we design a speech prompting mechanism to facilitate in-context learning in the diffusion model and the duration/pitch predictor. We scale NaturalSpeech 2 to large-scale datasets with 44K hours of speech and singing data and evaluate",
    "path": "papers/23/04/2304.09116.json",
    "total_tokens": 989,
    "tldr": "本文介绍了一种名为NaturalSpeech 2的TTS系统，它基于潜在扩散模型实现了自然的语音和歌唱合成，同时克服了传统语言模型合成的不稳定韵律、跳跃或重复单词的问题以及声音质量差的问题。",
    "en_tdlr": "This paper presents a TTS system called NaturalSpeech 2, which achieves natural speech and singing synthesis based on latent diffusion models, overcomes the unstable prosody, word skipping/repeating issue, and poor voice quality of traditional language models. The system also enhances zero-shot capability to achieve diverse speech synthesis through a speech prompting mechanism."
}