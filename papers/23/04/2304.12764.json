{
    "title": "Test-Time Adaptation with Perturbation Consistency Learning. (arXiv:2304.12764v1 [cs.CL])",
    "abstract": "Currently, pre-trained language models (PLMs) do not cope well with the distribution shift problem, resulting in models trained on the training set failing in real test scenarios. To address this problem, the test-time adaptation (TTA) shows great potential, which updates model parameters to suit the test data at the testing time. Existing TTA methods rely on well-designed auxiliary tasks or self-training strategies based on pseudo-label. However, these methods do not achieve good trade-offs regarding performance gains and computational costs. To obtain some insights into such a dilemma, we take two representative TTA methods, i.e., Tent and OIL, for exploration and find that stable prediction is the key to achieving a good balance. Accordingly, in this paper, we propose perturbation consistency learning (PCL), a simple test-time adaptation method to promote the model to make stable predictions for samples with distribution shifts. Extensive experiments on adversarial robustness and cr",
    "link": "http://arxiv.org/abs/2304.12764",
    "context": "Title: Test-Time Adaptation with Perturbation Consistency Learning. (arXiv:2304.12764v1 [cs.CL])\nAbstract: Currently, pre-trained language models (PLMs) do not cope well with the distribution shift problem, resulting in models trained on the training set failing in real test scenarios. To address this problem, the test-time adaptation (TTA) shows great potential, which updates model parameters to suit the test data at the testing time. Existing TTA methods rely on well-designed auxiliary tasks or self-training strategies based on pseudo-label. However, these methods do not achieve good trade-offs regarding performance gains and computational costs. To obtain some insights into such a dilemma, we take two representative TTA methods, i.e., Tent and OIL, for exploration and find that stable prediction is the key to achieving a good balance. Accordingly, in this paper, we propose perturbation consistency learning (PCL), a simple test-time adaptation method to promote the model to make stable predictions for samples with distribution shifts. Extensive experiments on adversarial robustness and cr",
    "path": "papers/23/04/2304.12764.json",
    "total_tokens": 897,
    "translated_title": "带扰动一致性学习的测试时间自适应方法",
    "translated_abstract": "目前，预训练语言模型(PLMs)在应对分布变化问题方面表现不佳，导致训练集上训练的模型在真实测试场景中失败。为解决这个问题，测试时间自适应(TTA)显示出巨大潜力，即在测试时更新模型参数以适应测试数据。现有的TTA方法依赖于经过良好设计的辅助任务或基于伪标签的自训练策略。然而，这些方法在性能提升和计算成本方面并没有达到良好的平衡。为了深入了解这种困境，本文选取了两种典型的TTA方法(Tent和OIL)进行探索，并发现稳定的预测是实现良好平衡的关键。因此，本文提出了扰动一致性学习(PCL)，一种简单的测试时间自适应方法，以促进模型对分布变化的样本进行稳定预测。在对抗攻击和跨域情况下的广泛实验结果表明了该方法的有效性。",
    "tldr": "本文提出了一种测试时间自适应方法PCL，通过促进模型对分布变化的稳定预测，解决了目前PLMs在应对分布变化问题方面表现不佳的难题。",
    "en_tdlr": "This paper proposes a test-time adaptation method called PCL, which addresses the poor performance of pre-trained language models (PLMs) in coping with distribution shift by promoting stable predictions for samples with distribution shifts."
}