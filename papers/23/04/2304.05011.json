{
    "title": "Towards an Understanding and Explanation for Mixed-Initiative Artificial Scientific Text Detection. (arXiv:2304.05011v1 [cs.HC] CROSS LISTED)",
    "abstract": "Large language models (LLMs) have gained popularity in various fields for their exceptional capability of generating human-like text. Their potential misuse has raised social concerns about plagiarism in academic contexts. However, effective artificial scientific text detection is a non-trivial task due to several challenges, including 1) the lack of a clear understanding of the differences between machine-generated and human-written scientific text, 2) the poor generalization performance of existing methods caused by out-of-distribution issues, and 3) the limited support for human-machine collaboration with sufficient interpretability during the detection process. In this paper, we first identify the critical distinctions between machine-generated and human-written scientific text through a quantitative experiment. Then, we propose a mixed-initiative workflow that combines human experts' prior knowledge with machine intelligence, along with a visual analytics prototype to facilitate e",
    "link": "http://arxiv.org/abs/2304.05011",
    "context": "Title: Towards an Understanding and Explanation for Mixed-Initiative Artificial Scientific Text Detection. (arXiv:2304.05011v1 [cs.HC] CROSS LISTED)\nAbstract: Large language models (LLMs) have gained popularity in various fields for their exceptional capability of generating human-like text. Their potential misuse has raised social concerns about plagiarism in academic contexts. However, effective artificial scientific text detection is a non-trivial task due to several challenges, including 1) the lack of a clear understanding of the differences between machine-generated and human-written scientific text, 2) the poor generalization performance of existing methods caused by out-of-distribution issues, and 3) the limited support for human-machine collaboration with sufficient interpretability during the detection process. In this paper, we first identify the critical distinctions between machine-generated and human-written scientific text through a quantitative experiment. Then, we propose a mixed-initiative workflow that combines human experts' prior knowledge with machine intelligence, along with a visual analytics prototype to facilitate e",
    "path": "papers/23/04/2304.05011.json",
    "total_tokens": 867,
    "translated_title": "混合智能科技论文检测的理解与解释",
    "translated_abstract": "大型语言模型（LLM）因其出色的生成人类化文本的能力在各个领域中广受欢迎。然而，其潜在误用引起了社会关注，主要是关于学术抄袭的问题。然而，由于几个挑战，包括：1）缺乏对机器生成和人类撰写的科技论文差异的明确理解、2）由于分布问题导致现有方法的差强人意泛化表现、以及3）检测过程中对人机协作的支持及足够解释性的有限，使得有效的科技论文检测是具有挑战性的。本文首先通过一个定量实验​​​明确了机器生成和人类撰写的科技论文之间的关键差异。然后，我们提出了一种混合智能工作流，结合人类专家的先验知识和机器智能，以及一个可视化分析原型来促进交互。",
    "tldr": "本论文通过定量实验明确了机器生成和人类撰写的科技论文之间的关键差异，并提出了一种混合智能工作流，旨在有效解决科技论文检测中存在的挑战。",
    "en_tdlr": "This paper quantitatively identifies the critical differences between machine-generated and human-written scientific text and proposes a mixed-initiative workflow that combines human experts' prior knowledge with machine intelligence to effectively address the challenges in scientific text detection."
}