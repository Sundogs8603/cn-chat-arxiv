{
    "title": "TC-VAE: Uncovering Out-of-Distribution Data Generative Factors. (arXiv:2304.04103v1 [cs.LG])",
    "abstract": "Uncovering data generative factors is the ultimate goal of disentanglement learning. Although many works proposed disentangling generative models able to uncover the underlying generative factors of a dataset, so far no one was able to uncover OOD generative factors (i.e., factors of variations that are not explicitly shown on the dataset). Moreover, the datasets used to validate these models are synthetically generated using a balanced mixture of some predefined generative factors, implicitly assuming that generative factors are uniformly distributed across the datasets. However, real datasets do not present this property. In this work we analyse the effect of using datasets with unbalanced generative factors, providing qualitative and quantitative results for widely used generative models. Moreover, we propose TC-VAE, a generative model optimized using a lower bound of the joint total correlation between the learned latent representations and the input data. We show that the proposed",
    "link": "http://arxiv.org/abs/2304.04103",
    "context": "Title: TC-VAE: Uncovering Out-of-Distribution Data Generative Factors. (arXiv:2304.04103v1 [cs.LG])\nAbstract: Uncovering data generative factors is the ultimate goal of disentanglement learning. Although many works proposed disentangling generative models able to uncover the underlying generative factors of a dataset, so far no one was able to uncover OOD generative factors (i.e., factors of variations that are not explicitly shown on the dataset). Moreover, the datasets used to validate these models are synthetically generated using a balanced mixture of some predefined generative factors, implicitly assuming that generative factors are uniformly distributed across the datasets. However, real datasets do not present this property. In this work we analyse the effect of using datasets with unbalanced generative factors, providing qualitative and quantitative results for widely used generative models. Moreover, we propose TC-VAE, a generative model optimized using a lower bound of the joint total correlation between the learned latent representations and the input data. We show that the proposed",
    "path": "papers/23/04/2304.04103.json",
    "total_tokens": 774,
    "translated_title": "TC-VAE：揭示数据生成因素中的未知分布数据",
    "translated_abstract": "揭示数据生成因素是解决解缠结学习的最终目标。本文提出了一种生成模型-TC-VAE，它可以基于所学的潜在表征和输入数据之间的总相关性下界进行优化，从而发现不在数据集中显式出现的变化因素。我们分析了在使用具有不平衡的生成因素数据集时，所提出的模型的效果，并在定量和定性实验中表明了TC-VAE的优越性。",
    "tldr": "本文提出了一种基于总相关性的生成模型TC-VAE，可以揭示数据生成因素中的未知分布数据，在处理具有不平衡生成因素的数据集上表现优秀。",
    "en_tdlr": "The paper proposes a generative model called TC-VAE which is optimized based on the lower bound of the joint total correlation between the learned latent representations and input data, and can uncover out-of-distribution generative factors. It outperforms other state-of-the-art generative models in discovering unknown generative factors in datasets with unbalanced generative factors."
}