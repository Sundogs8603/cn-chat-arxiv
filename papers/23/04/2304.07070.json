{
    "title": "Who breaks early, looses: goal oriented training of deep neural networks based on port Hamiltonian dynamics. (arXiv:2304.07070v1 [cs.LG])",
    "abstract": "The highly structured energy landscape of the loss as a function of parameters for deep neural networks makes it necessary to use sophisticated optimization strategies in order to discover (local) minima that guarantee reasonable performance. Overcoming less suitable local minima is an important prerequisite and often momentum methods are employed to achieve this. As in other non local optimization procedures, this however creates the necessity to balance between exploration and exploitation. In this work, we suggest an event based control mechanism for switching from exploration to exploitation based on reaching a predefined reduction of the loss function. As we give the momentum method a port Hamiltonian interpretation, we apply the 'heavy ball with friction' interpretation and trigger breaking (or friction) when achieving certain goals. We benchmark our method against standard stochastic gradient descent and provide experimental evidence for improved performance of deep neural netwo",
    "link": "http://arxiv.org/abs/2304.07070",
    "context": "Title: Who breaks early, looses: goal oriented training of deep neural networks based on port Hamiltonian dynamics. (arXiv:2304.07070v1 [cs.LG])\nAbstract: The highly structured energy landscape of the loss as a function of parameters for deep neural networks makes it necessary to use sophisticated optimization strategies in order to discover (local) minima that guarantee reasonable performance. Overcoming less suitable local minima is an important prerequisite and often momentum methods are employed to achieve this. As in other non local optimization procedures, this however creates the necessity to balance between exploration and exploitation. In this work, we suggest an event based control mechanism for switching from exploration to exploitation based on reaching a predefined reduction of the loss function. As we give the momentum method a port Hamiltonian interpretation, we apply the 'heavy ball with friction' interpretation and trigger breaking (or friction) when achieving certain goals. We benchmark our method against standard stochastic gradient descent and provide experimental evidence for improved performance of deep neural netwo",
    "path": "papers/23/04/2304.07070.json",
    "total_tokens": 931,
    "translated_title": "基于哈密顿动力学的深度神经网络目标导向训练: “谁早退，谁输”",
    "translated_abstract": "由于深度神经网络损失作为参数函数的高度结构化能源景观，因此需要使用精密的优化策略来发现保证合理性能的（局部）最小值。最小化次优解是一个重要的前提，通常使用动量方法来实现。然而，像其他非局部优化过程一样，这创建了在勘探和利用之间平衡的必要性。在本文中，我们提出了一种基于达到预定损失函数减少的事件控制机制，用于从勘探转向利用。由于我们给出了动量法的哈密顿解释，我们应用了“带有摩擦的重球”解释，并在实现某些目标时触发“摩擦”或“断裂”。我们将我们的方法与标准随机梯度下降进行基准测试，并提供了有关在多个标准数据集上改善深度神经网络训练性能的实验证据。",
    "tldr": "本文提出了一种基于哈密顿动力学的深度神经网络目标导向训练方法，通过达到预定的损失函数减少来实现从勘探到利用的转换，与标准随机梯度下降相比，该方法在多个标准数据集上取得了更好的性能。",
    "en_tdlr": "This paper proposes a goal-oriented training method for deep neural networks based on port Hamiltonian dynamics, in which an event-based control mechanism is used to switch from exploration to exploitation by reaching a predefined reduction of the loss function. The method, benchmarked against standard stochastic gradient descent, achieved improved performance on multiple standard datasets."
}