{
    "title": "Rolling Lookahead Learning for Optimal Classification Trees. (arXiv:2304.10830v1 [cs.LG])",
    "abstract": "Classification trees continue to be widely adopted in machine learning applications due to their inherently interpretable nature and scalability. We propose a rolling subtree lookahead algorithm that combines the relative scalability of the myopic approaches with the foresight of the optimal approaches in constructing trees. The limited foresight embedded in our algorithm mitigates the learning pathology observed in optimal approaches. At the heart of our algorithm lies a novel two-depth optimal binary classification tree formulation flexible to handle any loss function. We show that the feasible region of this formulation is an integral polyhedron, yielding the LP relaxation solution optimal. Through extensive computational analyses, we demonstrate that our approach outperforms optimal and myopic approaches in 808 out of 1330 problem instances, improving the out-of-sample accuracy by up to 23.6% and 14.4%, respectively.",
    "link": "http://arxiv.org/abs/2304.10830",
    "context": "Title: Rolling Lookahead Learning for Optimal Classification Trees. (arXiv:2304.10830v1 [cs.LG])\nAbstract: Classification trees continue to be widely adopted in machine learning applications due to their inherently interpretable nature and scalability. We propose a rolling subtree lookahead algorithm that combines the relative scalability of the myopic approaches with the foresight of the optimal approaches in constructing trees. The limited foresight embedded in our algorithm mitigates the learning pathology observed in optimal approaches. At the heart of our algorithm lies a novel two-depth optimal binary classification tree formulation flexible to handle any loss function. We show that the feasible region of this formulation is an integral polyhedron, yielding the LP relaxation solution optimal. Through extensive computational analyses, we demonstrate that our approach outperforms optimal and myopic approaches in 808 out of 1330 problem instances, improving the out-of-sample accuracy by up to 23.6% and 14.4%, respectively.",
    "path": "papers/23/04/2304.10830.json",
    "total_tokens": 838,
    "translated_title": "滚动前瞻学习在分类树中的应用",
    "translated_abstract": "由于其本质可解释性和可扩展性，分类树在机器学习领域中仍被广泛应用。本文提出一种滚动子树前瞻算法，将近视方法的相对可扩展性与构建树的最优方法的预见性结合起来。我们算法中的有限预见降低了最优方法中观察到的学习病理。我们算法的核心是一种新颖的二级最优二叉分类树公式，灵活处理任何损失函数。我们证明了这种公式的可行域是一个整数多面体，从而产生最优的LP松弛解。通过广泛的计算分析，我们证明了我们的方法在1330个问题实例中有808个的性能优于最优和近视方法，分别将外样本精度提高了23.6%和14.4%。",
    "tldr": "本文提出了一种滚动前瞻学习算法，有效地改进了最优分类树的学习病理，灵活处理任何损失函数并在实验中表现出更好的性能。",
    "en_tdlr": "A rolling lookahead learning algorithm is proposed in this paper, which effectively mitigates the learning pathology observed in optimal approaches for classification trees. It is capable of handling any loss function, and outperforms both optimal and myopic approaches in experiments, achieving improvements up to 23.6% and 14.4% in out-of-sample accuracy, respectively."
}