{
    "title": "Towards the Transferable Audio Adversarial Attack via Ensemble Methods. (arXiv:2304.08811v1 [cs.CR])",
    "abstract": "In recent years, deep learning (DL) models have achieved significant progress in many domains, such as autonomous driving, facial recognition, and speech recognition. However, the vulnerability of deep learning models to adversarial attacks has raised serious concerns in the community because of their insufficient robustness and generalization. Also, transferable attacks have become a prominent method for black-box attacks. In this work, we explore the potential factors that impact adversarial examples (AEs) transferability in DL-based speech recognition. We also discuss the vulnerability of different DL systems and the irregular nature of decision boundaries. Our results show a remarkable difference in the transferability of AEs between speech and images, with the data relevance being low in images but opposite in speech recognition. Motivated by dropout-based ensemble approaches, we propose random gradient ensembles and dynamic gradient-weighted ensembles, and we evaluate the impact ",
    "link": "http://arxiv.org/abs/2304.08811",
    "context": "Title: Towards the Transferable Audio Adversarial Attack via Ensemble Methods. (arXiv:2304.08811v1 [cs.CR])\nAbstract: In recent years, deep learning (DL) models have achieved significant progress in many domains, such as autonomous driving, facial recognition, and speech recognition. However, the vulnerability of deep learning models to adversarial attacks has raised serious concerns in the community because of their insufficient robustness and generalization. Also, transferable attacks have become a prominent method for black-box attacks. In this work, we explore the potential factors that impact adversarial examples (AEs) transferability in DL-based speech recognition. We also discuss the vulnerability of different DL systems and the irregular nature of decision boundaries. Our results show a remarkable difference in the transferability of AEs between speech and images, with the data relevance being low in images but opposite in speech recognition. Motivated by dropout-based ensemble approaches, we propose random gradient ensembles and dynamic gradient-weighted ensembles, and we evaluate the impact ",
    "path": "papers/23/04/2304.08811.json",
    "total_tokens": 956,
    "translated_title": "通过集成方法实现可传递音频对抗攻击",
    "translated_abstract": "近年来，深度学习模型在许多领域取得了重大进展，如自动驾驶、面部识别和语音识别。然而，深度学习模型对对抗攻击的脆弱性引起了社区的严重关注，因为它们并不具备足够的鲁棒性和泛化能力。此外，可传递攻击已成为黑盒攻击的一种突出方法。在这项工作中，我们探讨了影响基于深度学习的语音识别中对抗样本（AEs）传递能力的潜在因素。我们还讨论了不同深度学习系统的脆弱性和决策边界的不规则性质。我们的结果表明，在对抗攻击的传递能力方面，语音和图像之间存在显着差异，图像的数据相关性较低而语音识别则相反。受到基于dropout的集成方法的激励，我们提出了随机梯度集成和动态梯度加权集成，并评估了它们对AEs传递能力的影响",
    "tldr": "本文通过研究深度学习语音识别的对抗样本传递能力，提出了随机梯度集成和动态梯度加权集成这两种新的集成方法，并发现语音和图像在对抗攻击传递上存在显着差异。",
    "en_tdlr": "This paper explores the transferability of adversarial examples (AEs) in deep learning-based speech recognition and proposes novel ensemble methods \"random gradient ensembles\" and \"dynamic gradient-weighted ensembles\". Results revealed significant differences in the transferability of AEs between speech and images."
}