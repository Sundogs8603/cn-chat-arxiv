{
    "title": "Calibrated Chaos: Variance Between Runs of Neural Network Training is Harmless and Inevitable. (arXiv:2304.01910v1 [cs.LG])",
    "abstract": "Typical neural network trainings have substantial variance in test-set performance between repeated runs, impeding hyperparameter comparison and training reproducibility. We present the following results towards understanding this variation. (1) Despite having significant variance on their test-sets, we demonstrate that standard CIFAR-10 and ImageNet trainings have very little variance in their performance on the test-distributions from which those test-sets are sampled, suggesting that variance is less of a practical issue than previously thought. (2) We present a simplifying statistical assumption which closely approximates the structure of the test-set accuracy distribution. (3) We argue that test-set variance is inevitable in the following two senses. First, we show that variance is largely caused by high sensitivity of the training process to initial conditions, rather than by specific sources of randomness like the data order and augmentations. Second, we prove that variance is u",
    "link": "http://arxiv.org/abs/2304.01910",
    "context": "Title: Calibrated Chaos: Variance Between Runs of Neural Network Training is Harmless and Inevitable. (arXiv:2304.01910v1 [cs.LG])\nAbstract: Typical neural network trainings have substantial variance in test-set performance between repeated runs, impeding hyperparameter comparison and training reproducibility. We present the following results towards understanding this variation. (1) Despite having significant variance on their test-sets, we demonstrate that standard CIFAR-10 and ImageNet trainings have very little variance in their performance on the test-distributions from which those test-sets are sampled, suggesting that variance is less of a practical issue than previously thought. (2) We present a simplifying statistical assumption which closely approximates the structure of the test-set accuracy distribution. (3) We argue that test-set variance is inevitable in the following two senses. First, we show that variance is largely caused by high sensitivity of the training process to initial conditions, rather than by specific sources of randomness like the data order and augmentations. Second, we prove that variance is u",
    "path": "papers/23/04/2304.01910.json",
    "total_tokens": 902,
    "translated_title": "校准混乱：神经网络训练的运行变化在无意中且无害",
    "translated_abstract": "典型的神经网络训练在重复测试时会有显著的测试集性能差异，影响模型超参数的比较和训练的可重复性。本文通过以下比较来解释这种变化：（1）尽管在测试集上有显著的方差，但标准的CIFAR-10与ImageNet训练在测试分布上的表现却非常一致，这表明方差不像之前想象的那么严重。（2）我们提出了一种简化的统计假设，以紧密近似测试集准确性分布结构。（3）我们认为，在以下两个意义上，测试集方差是不可避免的。首先，我们展示了方差主要是由于训练过程对初始条件的高敏感性而不是特定的随机源（如数据排序和扩充）所导致的。其次，我们证明了方差是频率极限的，但可以通过训练多个模型来减少。",
    "tldr": "神经网络训练的运行变化在实际中更少遇到问题，我们提出了一种简化的统计假设并证明方差主要由于训练过程对初始条件的高敏感性所导致。",
    "en_tdlr": "Variance between runs of neural network training is less problematic in practice than previously thought, and can be mitigated by training multiple models. We propose a simplified statistical assumption and demonstrate that variance is largely caused by the sensitivity of the training process to initial conditions."
}