{
    "title": "Leveraging Social Interactions to Detect Misinformation on Social Media. (arXiv:2304.02983v1 [cs.CL])",
    "abstract": "Detecting misinformation threads is crucial to guarantee a healthy environment on social media. We address the problem using the data set created during the COVID-19 pandemic. It contains cascades of tweets discussing information weakly labeled as reliable or unreliable, based on a previous evaluation of the information source. The models identifying unreliable threads usually rely on textual features. But reliability is not just what is said, but by whom and to whom. We additionally leverage on network information. Following the homophily principle, we hypothesize that users who interact are generally interested in similar topics and spreading similar kind of news, which in turn is generally reliable or not. We test several methods to learn representations of the social interactions within the cascades, combining them with deep neural language models in a Multi-Input (MI) framework. Keeping track of the sequence of the interactions during the time, we improve over previous state-of-th",
    "link": "http://arxiv.org/abs/2304.02983",
    "context": "Title: Leveraging Social Interactions to Detect Misinformation on Social Media. (arXiv:2304.02983v1 [cs.CL])\nAbstract: Detecting misinformation threads is crucial to guarantee a healthy environment on social media. We address the problem using the data set created during the COVID-19 pandemic. It contains cascades of tweets discussing information weakly labeled as reliable or unreliable, based on a previous evaluation of the information source. The models identifying unreliable threads usually rely on textual features. But reliability is not just what is said, but by whom and to whom. We additionally leverage on network information. Following the homophily principle, we hypothesize that users who interact are generally interested in similar topics and spreading similar kind of news, which in turn is generally reliable or not. We test several methods to learn representations of the social interactions within the cascades, combining them with deep neural language models in a Multi-Input (MI) framework. Keeping track of the sequence of the interactions during the time, we improve over previous state-of-th",
    "path": "papers/23/04/2304.02983.json",
    "total_tokens": 1000,
    "translated_title": "利用社交互动检测社交媒体上的虚假信息",
    "translated_abstract": "检测虚假信息是确保社交媒体健康环境的关键。我们使用COVID-19流行期间创建的数据集解决了这个问题。它包含微弱标记为可靠或不可靠的信息级联推文，基于对信息源的先前评估。识别不可靠线程的模型通常依赖于文本特征。但是，可靠性不仅取决于文本内容，还取决于信息的发布者以及发布给谁。我们还利用网络信息。遵循同质性原则，我们假设互动的用户通常对相似的话题感兴趣，并传播类似的新闻，这些新闻通常是可靠的或不可靠的。我们测试了几种方法来学习级联内社交互动的表示，将它们与深度神经语言模型在多输入(MI)框架中结合起来。通过跟踪互动时间序列，我们提高了先前的最新水平，无论是使用纯文本分类器还是没有社交信息的多输入模型。我们展示了添加社交信息可以帮助超越其他解决方案，特别是在信息传播的早期阶段，在那里只有很少的推文可供分析。",
    "tldr": "该论文针对社交媒体上的虚假信息检测问题，结合社交信息和文本特征，利用深度神经网络进行多输入模型，实现了对信息传播的早期阶段的有效检测。"
}