{
    "title": "Moccasin: Efficient Tensor Rematerialization for Neural Networks. (arXiv:2304.14463v1 [cs.LG])",
    "abstract": "The deployment and training of neural networks on edge computing devices pose many challenges. The low memory nature of edge devices is often one of the biggest limiting factors encountered in the deployment of large neural network models. Tensor rematerialization or recompute is a way to address high memory requirements for neural network training and inference. In this paper we consider the problem of execution time minimization of compute graphs subject to a memory budget. In particular, we develop a new constraint programming formulation called \\textsc{Moccasin} with only $O(n)$ integer variables, where $n$ is the number of nodes in the compute graph. This is a significant improvement over the works in the recent literature that propose formulations with $O(n^2)$ Boolean variables. We present numerical studies that show that our approach is up to an order of magnitude faster than recent work especially for large-scale graphs.",
    "link": "http://arxiv.org/abs/2304.14463",
    "context": "Title: Moccasin: Efficient Tensor Rematerialization for Neural Networks. (arXiv:2304.14463v1 [cs.LG])\nAbstract: The deployment and training of neural networks on edge computing devices pose many challenges. The low memory nature of edge devices is often one of the biggest limiting factors encountered in the deployment of large neural network models. Tensor rematerialization or recompute is a way to address high memory requirements for neural network training and inference. In this paper we consider the problem of execution time minimization of compute graphs subject to a memory budget. In particular, we develop a new constraint programming formulation called \\textsc{Moccasin} with only $O(n)$ integer variables, where $n$ is the number of nodes in the compute graph. This is a significant improvement over the works in the recent literature that propose formulations with $O(n^2)$ Boolean variables. We present numerical studies that show that our approach is up to an order of magnitude faster than recent work especially for large-scale graphs.",
    "path": "papers/23/04/2304.14463.json",
    "total_tokens": 840,
    "translated_title": "Moccasin：神经网络的高效张量重算技术",
    "translated_abstract": "在边缘计算设备上部署和训练神经网络面临许多挑战，其中较低的内存是部署大型神经网络模型时经常遇到的最大限制因素之一。张量重算是解决神经网络训练和推理所需高内存需求的一种方式。本文考虑在内存预算下最小化计算图的执行时间问题。具体来说，我们开发了一种新的约束编程形式，称为Moccasin，其中只有$O(n)$个整数变量，$n$是计算图中节点的数量。这相对于最近文献中提出的具有$O(n^2)$布尔变量的公式提出了显着的改进。我们展示了数值研究结果，表明我们的方法在大规模图上比最近的工作快一个数量级。",
    "tldr": "本文提出了一种名为Moccasin的新型约束编程形式，用于实现在内存预算下最小化计算图的执行时间，相较于最近的研究，该方法显著提高了效率，并成功应用于神经网络的高效张量重算。",
    "en_tdlr": "This paper proposes a novel constraint programming method called Moccasin to minimize the execution time of compute graphs under a memory budget, which significantly improves the efficiency compared to recent works and successfully applies to the efficient tensor rematerialization for neural networks."
}