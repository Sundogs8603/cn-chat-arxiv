{
    "title": "Instruction Fusion: Advancing Prompt Evolution through Hybridization",
    "abstract": "The fine-tuning of Large Language Models (LLMs) specialized in code generation has seen notable advancements through the use of open-domain coding queries. Despite the successes, existing methodologies like Evol-Instruct encounter performance limitations, impeding further enhancements in code generation tasks. This paper examines the constraints of existing prompt evolution techniques and introduces a novel approach, Instruction Fusion (IF). IF innovatively combines two distinct prompts through a hybridization process, thereby enhancing the evolution of training prompts for code LLMs. Our experimental results reveal that the proposed novel method effectively addresses the shortcomings of prior methods, significantly improving the performance of Code LLMs across five code generation benchmarks, namely HumanEval, HumanEval+, MBPP, MBPP+ and MultiPL-E, which underscore the effectiveness of Instruction Fusion in advancing the capabilities of LLMs in code generation.",
    "link": "https://arxiv.org/abs/2312.15692",
    "context": "Title: Instruction Fusion: Advancing Prompt Evolution through Hybridization\nAbstract: The fine-tuning of Large Language Models (LLMs) specialized in code generation has seen notable advancements through the use of open-domain coding queries. Despite the successes, existing methodologies like Evol-Instruct encounter performance limitations, impeding further enhancements in code generation tasks. This paper examines the constraints of existing prompt evolution techniques and introduces a novel approach, Instruction Fusion (IF). IF innovatively combines two distinct prompts through a hybridization process, thereby enhancing the evolution of training prompts for code LLMs. Our experimental results reveal that the proposed novel method effectively addresses the shortcomings of prior methods, significantly improving the performance of Code LLMs across five code generation benchmarks, namely HumanEval, HumanEval+, MBPP, MBPP+ and MultiPL-E, which underscore the effectiveness of Instruction Fusion in advancing the capabilities of LLMs in code generation.",
    "path": "papers/23/12/2312.15692.json",
    "total_tokens": 858,
    "translated_title": "指令融合：通过混合化推进提示演化",
    "translated_abstract": "通过使用开放域编码查询，细调专门用于代码生成的大规模语言模型（LLM）已经取得了显着的进展。尽管取得了成功，但现有的方法如Evol-Instruct在性能方面存在限制，阻碍了进一步改进代码生成任务的能力。本文研究了现有提示演化技术的限制，并引入了一种新颖的方法，即指令融合（IF）。IF通过混合化过程创新地结合了两个不同的提示，从而增强了用于代码LLM的训练提示的演化。我们的实验结果表明，该提出的新方法有效地解决了之前方法的缺点，显著提高了代码LLM在人工评估、人工评估+、MBPP、MBPP+和MultiPL-E等五个代码生成基准上的性能，凸显了指令融合在推进LLM在代码生成方面的能力的有效性。",
    "tldr": "本文介绍了一种新颖的方法，指令融合（IF），通过混合化两个不同的提示，改进了用于代码LLM的训练提示的演化。实验结果显示，指令融合有效地改善了代码LLM在多个代码生成任务上的性能。",
    "en_tdlr": "This paper introduces a novel approach, Instruction Fusion (IF), which enhances the evolution of training prompts for code LLMs by combining two distinct prompts through a hybridization process. Experimental results demonstrate that Instruction Fusion effectively improves the performance of code LLMs in multiple code generation tasks."
}