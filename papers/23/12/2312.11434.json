{
    "title": "Factored Online Planning in Many-Agent POMDPs",
    "abstract": "arXiv:2312.11434v3 Announce Type: replace  Abstract: In centralized multi-agent systems, often modeled as multi-agent partially observable Markov decision processes (MPOMDPs), the action and observation spaces grow exponentially with the number of agents, making the value and belief estimation of single-agent online planning ineffective. Prior work partially tackles value estimation by exploiting the inherent structure of multi-agent settings via so-called coordination graphs. Additionally, belief estimation methods have been improved by incorporating the likelihood of observations into the approximation. However, the challenges of value estimation and belief estimation have only been tackled individually, which prevents existing methods from scaling to settings with many agents. Therefore, we address these challenges simultaneously. First, we introduce weighted particle filtering to a sample-based online planner for MPOMDPs. Second, we present a scalable approximation of the belief. T",
    "link": "https://arxiv.org/abs/2312.11434",
    "context": "Title: Factored Online Planning in Many-Agent POMDPs\nAbstract: arXiv:2312.11434v3 Announce Type: replace  Abstract: In centralized multi-agent systems, often modeled as multi-agent partially observable Markov decision processes (MPOMDPs), the action and observation spaces grow exponentially with the number of agents, making the value and belief estimation of single-agent online planning ineffective. Prior work partially tackles value estimation by exploiting the inherent structure of multi-agent settings via so-called coordination graphs. Additionally, belief estimation methods have been improved by incorporating the likelihood of observations into the approximation. However, the challenges of value estimation and belief estimation have only been tackled individually, which prevents existing methods from scaling to settings with many agents. Therefore, we address these challenges simultaneously. First, we introduce weighted particle filtering to a sample-based online planner for MPOMDPs. Second, we present a scalable approximation of the belief. T",
    "path": "papers/23/12/2312.11434.json",
    "total_tokens": 833,
    "translated_title": "许多智能体POMDP中的分解在线规划",
    "translated_abstract": "在集中式多智能体系统中，通常被建模为多智能体部分可观察马尔可夫决策过程（MPOMDPs），动作和观测空间随智能体数量呈指数增长，导致单智能体在线规划的价值和信念估计变得无效。先前的工作通过利用所谓的协调图来部分解决价值估计，进一步通过将观测概率纳入逼近中改进了信念估计方法。然而，价值估计和信念估计的挑战仅被单独处理，这阻止了现有方法扩展到具有许多智能体的情境。因此，我们同时解决了这些挑战。首先，我们将加权粒子滤波引入了用于MPOMDP的基于样本的在线规划器。其次，我们提出了一种可扩展的信念逼近方法。",
    "tldr": "该论文提出了一种针对多智能体POMDP的分解在线规划方法，通过引入加权粒子滤波和可扩展的信念逼近方法解决了值估计和信念估计难题。",
    "en_tdlr": "This paper introduces a factored online planning approach for many-agent POMDPs, tackling the challenges of value estimation and belief estimation simultaneously by introducing weighted particle filtering and a scalable belief approximation method."
}