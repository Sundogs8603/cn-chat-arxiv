{
    "title": "AesFA: An Aesthetic Feature-Aware Arbitrary Neural Style Transfer. (arXiv:2312.05928v2 [cs.CV] UPDATED)",
    "abstract": "Neural style transfer (NST) has evolved significantly in recent years. Yet, despite its rapid progress and advancement, existing NST methods either struggle to transfer aesthetic information from a style effectively or suffer from high computational costs and inefficiencies in feature disentanglement due to using pre-trained models. This work proposes a lightweight but effective model, AesFA -- Aesthetic Feature-Aware NST. The primary idea is to decompose the image via its frequencies to better disentangle aesthetic styles from the reference image while training the entire model in an end-to-end manner to exclude pre-trained models at inference completely. To improve the network's ability to extract more distinct representations and further enhance the stylization quality, this work introduces a new aesthetic feature: contrastive loss. Extensive experiments and ablations show the approach not only outperforms recent NST methods in terms of stylization quality, but it also achieves fast",
    "link": "http://arxiv.org/abs/2312.05928",
    "context": "Title: AesFA: An Aesthetic Feature-Aware Arbitrary Neural Style Transfer. (arXiv:2312.05928v2 [cs.CV] UPDATED)\nAbstract: Neural style transfer (NST) has evolved significantly in recent years. Yet, despite its rapid progress and advancement, existing NST methods either struggle to transfer aesthetic information from a style effectively or suffer from high computational costs and inefficiencies in feature disentanglement due to using pre-trained models. This work proposes a lightweight but effective model, AesFA -- Aesthetic Feature-Aware NST. The primary idea is to decompose the image via its frequencies to better disentangle aesthetic styles from the reference image while training the entire model in an end-to-end manner to exclude pre-trained models at inference completely. To improve the network's ability to extract more distinct representations and further enhance the stylization quality, this work introduces a new aesthetic feature: contrastive loss. Extensive experiments and ablations show the approach not only outperforms recent NST methods in terms of stylization quality, but it also achieves fast",
    "path": "papers/23/12/2312.05928.json",
    "total_tokens": 957,
    "translated_title": "AesFA:一种美学特征感知的任意神经风格转换方法",
    "translated_abstract": "神经风格转换（NST）在近年来取得了显著的发展。然而，尽管其快速进展和改进，现有的NST方法要么在有效转移风格时很难保留美学信息，要么在特征解缠和计算效率方面由于使用预训练模型而存在高计算成本和低效率。本文提出了一种轻量级但有效的模型，AesFA -- 美学特征感知的NST。其主要思想是通过频率对图像进行分解，以更好地从参考图像中解开美学风格，同时以端到端的方式训练整个模型，完全取消了推断时的预训练模型。为了提高网络提取更加独特的表示和进一步增强风格化质量的能力，本文引入了一种新的美学特征：对比损失。广泛的实验和消融研究表明，这种方法不仅在风格化质量方面优于最新的NST方法，而且实现了快速的转换。",
    "tldr": "AesFA是一种轻量级但有效的神经风格转换方法，通过频率分解图像，以更好地解开美学风格，排除了预训练模型。引入了对比损失以提高风格化质量。实验证明，AesFA在stylization quality方面优于其他方法，并实现了快速转换。",
    "en_tdlr": "AesFA is a lightweight but effective neural style transfer method that decomposes the image via frequencies to better disentangle aesthetic styles. It introduces a contrastive loss to enhance the stylization quality and achieves faster transfer while excluding pre-trained models. Experimental results demonstrate that AesFA outperforms other methods in terms of stylization quality."
}