{
    "title": "Hulk: A Universal Knowledge Translator for Human-Centric Tasks",
    "abstract": "arXiv:2312.01697v4 Announce Type: replace-cross  Abstract: Human-centric perception tasks, e.g., pedestrian detection, skeleton-based action recognition, and pose estimation, have wide industrial applications, such as metaverse and sports analysis. There is a recent surge to develop human-centric foundation models that can benefit a broad range of human-centric perception tasks. While many human-centric foundation models have achieved success, they did not explore 3D and vision-language tasks for human-centric and required task-specific finetuning. These limitations restrict their application to more downstream tasks and situations. To tackle these problems, we present Hulk, the first multimodal human-centric generalist model, capable of addressing 2D vision, 3D vision, skeleton-based, and vision-language tasks without task-specific finetuning. The key to achieving this is condensing various task-specific heads into two general heads, one for discrete representations, e.g., languages, ",
    "link": "https://arxiv.org/abs/2312.01697",
    "context": "Title: Hulk: A Universal Knowledge Translator for Human-Centric Tasks\nAbstract: arXiv:2312.01697v4 Announce Type: replace-cross  Abstract: Human-centric perception tasks, e.g., pedestrian detection, skeleton-based action recognition, and pose estimation, have wide industrial applications, such as metaverse and sports analysis. There is a recent surge to develop human-centric foundation models that can benefit a broad range of human-centric perception tasks. While many human-centric foundation models have achieved success, they did not explore 3D and vision-language tasks for human-centric and required task-specific finetuning. These limitations restrict their application to more downstream tasks and situations. To tackle these problems, we present Hulk, the first multimodal human-centric generalist model, capable of addressing 2D vision, 3D vision, skeleton-based, and vision-language tasks without task-specific finetuning. The key to achieving this is condensing various task-specific heads into two general heads, one for discrete representations, e.g., languages, ",
    "path": "papers/23/12/2312.01697.json",
    "total_tokens": 861,
    "translated_title": "Hulk: 一种面向人类中心任务的通用知识翻译器",
    "translated_abstract": "人类中心感知任务，例如行人检测、基于骨架的动作识别和姿态估计，在诸如元宇宙和体育分析等广泛的工业应用中具有重要意义。近来，出现了发展旨在受益于广泛人类中心感知任务的人类中心基础模型的激增。虽然许多人类中心基础模型取得了成功，但它们没有探索用于人类中心及需要任务特定微调的3D和视觉语言任务。这些限制限制了它们在更多下游任务和情境中的应用。为了解决这些问题，我们提出了Hulk，第一个能够在无需任务特定微调的情况下处理2D视觉、3D视觉、基于骨架和视觉语言任务的多模态人类中心通用模型。实现这一目标的关键在于将各种任务特定头部压缩成两个通用头部，一个用于离散表示，如语言，",
    "tldr": "Hulk是第一个多模态人类中心通用模型，能够处理2D视觉、3D视觉、基于骨架和视觉语言任务，无需任务特定微调",
    "en_tdlr": "Hulk is the first multimodal human-centric generalist model that can address 2D vision, 3D vision, skeleton-based, and vision-language tasks without task-specific finetuning."
}