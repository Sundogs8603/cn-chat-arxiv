{
    "title": "Benchmarking Distribution Shift in Tabular Data with TableShift",
    "abstract": "Robustness to distribution shift has become a growing concern for text and image models as they transition from research subjects to deployment in the real world. However, high-quality benchmarks for distribution shift in tabular machine learning tasks are still lacking despite the widespread real-world use of tabular data and differences in the models used for tabular data in comparison to text and images. As a consequence, the robustness of tabular models to distribution shift is poorly understood. To address this issue, we introduce TableShift, a distribution shift benchmark for tabular data. TableShift contains 15 binary classification tasks in total, each with an associated shift, and includes a diverse set of data sources, prediction targets, and distribution shifts. The benchmark covers domains including finance, education, public policy, healthcare, and civic participation, and is accessible using only a few lines of Python code via the TableShift API. We conduct a large-scale ",
    "link": "https://arxiv.org/abs/2312.07577",
    "context": "Title: Benchmarking Distribution Shift in Tabular Data with TableShift\nAbstract: Robustness to distribution shift has become a growing concern for text and image models as they transition from research subjects to deployment in the real world. However, high-quality benchmarks for distribution shift in tabular machine learning tasks are still lacking despite the widespread real-world use of tabular data and differences in the models used for tabular data in comparison to text and images. As a consequence, the robustness of tabular models to distribution shift is poorly understood. To address this issue, we introduce TableShift, a distribution shift benchmark for tabular data. TableShift contains 15 binary classification tasks in total, each with an associated shift, and includes a diverse set of data sources, prediction targets, and distribution shifts. The benchmark covers domains including finance, education, public policy, healthcare, and civic participation, and is accessible using only a few lines of Python code via the TableShift API. We conduct a large-scale ",
    "path": "papers/23/12/2312.07577.json",
    "total_tokens": 900,
    "translated_title": "使用TableShift来评估表格数据的分布漂移",
    "translated_abstract": "随着文本和图像模型从研究对象转向实际部署，对于分布漂移的鲁棒性越来越受关注。然而，尽管表格机器学习任务被广泛应用于现实世界中，但针对表格数据的分布漂移的高质量基准测试仍然缺乏，而且与文本和图像模型的差异进一步加剧了这个问题。因此，对于表格模型在面对分布漂移时的鲁棒性了解甚少。为了解决这个问题，我们引入了TableShift，一个针对表格数据的分布漂移基准测试。TableShift总共包含15个二分类任务，每个任务都有相应的分布漂移，并包含了多样化的数据来源、预测目标和分布漂移。该基准测试涵盖了金融、教育、公共政策、医疗保健和公民参与等领域，并且可以通过仅几行Python代码的TableShift API进行访问。我们进行了大规模的f评估。",
    "tldr": "这篇论文介绍了一个针对表格数据的分布漂移基准测试TableShift，包含15个二分类任务和相应的分布漂移，涵盖了多个领域，并且通过Python代码可以轻松访问。"
}