{
    "title": "Mutual Information as Intrinsic Reward of Reinforcement Learning Agents for On-demand Ride Pooling. (arXiv:2312.15195v2 [cs.AI] UPDATED)",
    "abstract": "The emergence of on-demand ride pooling services allows each vehicle to serve multiple passengers at a time, thus increasing drivers' income and enabling passengers to travel at lower prices than taxi/car on-demand services (only one passenger can be assigned to a car at a time like UberX and Lyft). Although on-demand ride pooling services can bring so many benefits, ride pooling services need a well-defined matching strategy to maximize the benefits for all parties (passengers, drivers, aggregation companies and environment), in which the regional dispatching of vehicles has a significant impact on the matching and revenue. Existing algorithms often only consider revenue maximization, which makes it difficult for requests with unusual distribution to get a ride. How to increase revenue while ensuring a reasonable assignment of requests brings a challenge to ride pooling service companies (aggregation companies). In this paper, we propose a framework for vehicle dispatching for ride po",
    "link": "http://arxiv.org/abs/2312.15195",
    "context": "Title: Mutual Information as Intrinsic Reward of Reinforcement Learning Agents for On-demand Ride Pooling. (arXiv:2312.15195v2 [cs.AI] UPDATED)\nAbstract: The emergence of on-demand ride pooling services allows each vehicle to serve multiple passengers at a time, thus increasing drivers' income and enabling passengers to travel at lower prices than taxi/car on-demand services (only one passenger can be assigned to a car at a time like UberX and Lyft). Although on-demand ride pooling services can bring so many benefits, ride pooling services need a well-defined matching strategy to maximize the benefits for all parties (passengers, drivers, aggregation companies and environment), in which the regional dispatching of vehicles has a significant impact on the matching and revenue. Existing algorithms often only consider revenue maximization, which makes it difficult for requests with unusual distribution to get a ride. How to increase revenue while ensuring a reasonable assignment of requests brings a challenge to ride pooling service companies (aggregation companies). In this paper, we propose a framework for vehicle dispatching for ride po",
    "path": "papers/23/12/2312.15195.json",
    "total_tokens": 908,
    "translated_title": "互信息作为强化学习智能体的内在奖励，用于按需共乘的车辆派遣",
    "translated_abstract": "按需共乘服务的出现允许每辆车同时为多名乘客提供服务，从而增加了司机的收入，并使乘客能以较低的价格旅行，而不像UberX和Lyft等出租车/按需服务只能为一名乘客分配一辆车。尽管按需共乘服务可以带来如此多的好处，但共乘服务需要一个明确定义的匹配策略，以最大程度地为所有各方（乘客，司机，聚合公司和环境）提供利益，其中区域调度车辆对匹配和收入有重要影响。现有算法通常仅考虑收入最大化，这使得请求具有异常分布的乘客难以获得乘车。如何在确保合理请求分配的同时增加收入，对共乘服务公司（聚合公司）提出了挑战。在本文中，我们提出了一个车辆派遣的框架，用于共乘服务。",
    "tldr": "本文提出了一个用于按需共乘车辆派遣的框架，利用互信息作为强化学习智能体的内在奖励，以解决现有算法中只考虑收入最大化而无法满足异常分布请求的问题。",
    "en_tdlr": "This paper proposes a framework for vehicle dispatching in on-demand ride pooling, utilizing mutual information as an intrinsic reward of reinforcement learning agents to address the issue of existing algorithms that only focus on revenue maximization and fail to accommodate requests with unusual distributions."
}