{
    "title": "EQ-Bench: An Emotional Intelligence Benchmark for Large Language Models. (arXiv:2312.06281v2 [cs.CL] UPDATED)",
    "abstract": "We introduce EQ-Bench, a novel benchmark designed to evaluate aspects of emotional intelligence in Large Language Models (LLMs). We assess the ability of LLMs to understand complex emotions and social interactions by asking them to predict the intensity of emotional states of characters in a dialogue. The benchmark is able to discriminate effectively between a wide range of models. We find that EQ-Bench correlates strongly with comprehensive multi-domain benchmarks like MMLU (Hendrycks et al., 2020) (r=0.97), indicating that we may be capturing similar aspects of broad intelligence. Our benchmark produces highly repeatable results using a set of 60 English-language questions. We also provide open-source code for an automated benchmarking pipeline at https://github.com/EQ-bench/EQ-Bench and a leaderboard at https://eqbench.com",
    "link": "http://arxiv.org/abs/2312.06281",
    "context": "Title: EQ-Bench: An Emotional Intelligence Benchmark for Large Language Models. (arXiv:2312.06281v2 [cs.CL] UPDATED)\nAbstract: We introduce EQ-Bench, a novel benchmark designed to evaluate aspects of emotional intelligence in Large Language Models (LLMs). We assess the ability of LLMs to understand complex emotions and social interactions by asking them to predict the intensity of emotional states of characters in a dialogue. The benchmark is able to discriminate effectively between a wide range of models. We find that EQ-Bench correlates strongly with comprehensive multi-domain benchmarks like MMLU (Hendrycks et al., 2020) (r=0.97), indicating that we may be capturing similar aspects of broad intelligence. Our benchmark produces highly repeatable results using a set of 60 English-language questions. We also provide open-source code for an automated benchmarking pipeline at https://github.com/EQ-bench/EQ-Bench and a leaderboard at https://eqbench.com",
    "path": "papers/23/12/2312.06281.json",
    "total_tokens": 874,
    "translated_title": "EQ-Bench:一种用于大型语言模型的情商评估基准",
    "translated_abstract": "我们介绍了EQ-Bench，这是一种用于评估大型语言模型（LLMs）情商方面的新型基准。我们通过要求LLMs预测对话中角色的情绪状态的强度来评估LLMs理解复杂情绪和社交交互的能力。这个基准可以有效地区分不同模型。我们发现EQ-Bench与综合多领域基准（如MMLU）之间存在很强的相关性（r=0.97），这表明我们可能捕捉到了广泛智能的相似方面。我们的基准使用60个英语问题产生高度可重复的结果。我们还在https://github.com/EQ-bench/EQ-Bench上提供了开源代码用于自动化基准测试流程，以及https://eqbench.com上的排行榜。",
    "tldr": "EQ-Bench是一种为评估大型语言模型（LLMs）的情商而设计的新型基准。该基准通过要求模型预测对话中角色的情绪状态强度来评估模型对复杂情绪和社交交互的理解能力。它能够有效区分不同模型，并与其他综合基准相关性很高。",
    "en_tdlr": "EQ-Bench is a novel benchmark designed to evaluate emotional intelligence in Large Language Models (LLMs). It assesses the ability of LLMs to understand complex emotions and social interactions by requiring them to predict the intensity of emotional states in dialogues. EQ-Bench effectively discriminates between different models and correlates strongly with comprehensive benchmarks, indicating its similarity to broader intelligence."
}