{
    "title": "Convergence Rates for Stochastic Approximation: Biased Noise with Unbounded Variance, and Applications. (arXiv:2312.02828v2 [stat.ML] UPDATED)",
    "abstract": "The Stochastic Approximation (SA) algorithm introduced by Robbins and Monro in 1951 has been a standard method for solving equations of the form $\\mathbf{f}({\\boldsymbol {\\theta}}) = \\mathbf{0}$, when only noisy measurements of $\\mathbf{f}(\\cdot)$ are available. If $\\mathbf{f}({\\boldsymbol {\\theta}}) = \\nabla J({\\boldsymbol {\\theta}})$ for some function $J(\\cdot)$, then SA can also be used to find a stationary point of $J(\\cdot)$. At each time $t$, the current guess ${\\boldsymbol {\\theta}}_t$ is updated to ${\\boldsymbol {\\theta}}_{t+1}$ using a noisy measurement of the form $\\mathbf{f}({\\boldsymbol {\\theta}}_t) + {\\boldsymbol {\\xi}}_{t+1}$. In much of the literature, it is assumed that the error term ${\\boldsymbol {\\xi}}_{t+1}$ has zero conditional mean, and/or that its conditional variance is bounded as a function of $t$ (though not necessarily with respect to ${\\boldsymbol {\\theta}}_t$). Over the years, SA has been applied to a variety of areas, out of which the focus in this paper i",
    "link": "http://arxiv.org/abs/2312.02828",
    "context": "Title: Convergence Rates for Stochastic Approximation: Biased Noise with Unbounded Variance, and Applications. (arXiv:2312.02828v2 [stat.ML] UPDATED)\nAbstract: The Stochastic Approximation (SA) algorithm introduced by Robbins and Monro in 1951 has been a standard method for solving equations of the form $\\mathbf{f}({\\boldsymbol {\\theta}}) = \\mathbf{0}$, when only noisy measurements of $\\mathbf{f}(\\cdot)$ are available. If $\\mathbf{f}({\\boldsymbol {\\theta}}) = \\nabla J({\\boldsymbol {\\theta}})$ for some function $J(\\cdot)$, then SA can also be used to find a stationary point of $J(\\cdot)$. At each time $t$, the current guess ${\\boldsymbol {\\theta}}_t$ is updated to ${\\boldsymbol {\\theta}}_{t+1}$ using a noisy measurement of the form $\\mathbf{f}({\\boldsymbol {\\theta}}_t) + {\\boldsymbol {\\xi}}_{t+1}$. In much of the literature, it is assumed that the error term ${\\boldsymbol {\\xi}}_{t+1}$ has zero conditional mean, and/or that its conditional variance is bounded as a function of $t$ (though not necessarily with respect to ${\\boldsymbol {\\theta}}_t$). Over the years, SA has been applied to a variety of areas, out of which the focus in this paper i",
    "path": "papers/23/12/2312.02828.json",
    "total_tokens": 1025,
    "translated_title": "随机逼近的收敛速度：带有无界方差的有偏噪声和应用",
    "translated_abstract": "1951年罗宾斯和莫洛引入的随机逼近（SA）算法已经成为解方程$\\mathbf{f}({\\boldsymbol{\\theta}}) = \\mathbf{0}$的标准方法，当只有$\\mathbf{f}(\\cdot)$的带噪声测量可用时。如果对于某个函数$J(\\cdot)$，$\\mathbf{f}({\\boldsymbol{\\theta}}) = \\nabla J({\\boldsymbol{\\theta}})$，那么SA也可以用来寻找$J(\\cdot)$的一个稳定点。在每个时间$t$，当前的猜测${\\boldsymbol{\\theta}}_t$通过形式为$\\mathbf{f}({\\boldsymbol{\\theta}}_t) + {\\boldsymbol{\\xi}}_{t+1}$的带噪声测量更新为${\\boldsymbol{\\theta}}_{t+1}$。在许多文献中，假设误差项${\\boldsymbol{\\xi}}_{t+1}$的条件均值为零，和/或者它的条件方差随$t$（而不是${\\boldsymbol{\\theta}}_t$）被限制。多年来，SA已经应用于各种领域，本文重点研究其中一个领域。",
    "tldr": "本论文研究了带有无界方差的有偏噪声对随机逼近算法的收敛速度的影响，并介绍了该算法在各个领域的应用。",
    "en_tdlr": "This paper investigates the impact of biased noise with unbounded variance on the convergence rates of the Stochastic Approximation algorithm and explores its applications in various fields."
}