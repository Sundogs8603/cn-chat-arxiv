{
    "title": "Harnessing Inherent Noises for Privacy Preservation in Quantum Machine Learning",
    "abstract": "arXiv:2312.11126v2 Announce Type: replace-cross  Abstract: Quantum computing revolutionizes the way of solving complex problems and handling vast datasets, which shows great potential to accelerate the machine learning process. However, data leakage in quantum machine learning (QML) may present privacy risks. Although differential privacy (DP), which protects privacy through the injection of artificial noise, is a well-established approach, its application in the QML domain remains under-explored. In this paper, we propose to harness inherent quantum noises to protect data privacy in QML. Especially, considering the Noisy Intermediate-Scale Quantum (NISQ) devices, we leverage the unavoidable shot noise and incoherent noise in quantum computing to preserve the privacy of QML models for binary classification. We mathematically analyze that the gradient of quantum circuit parameters in QML satisfies a Gaussian distribution, and derive the upper and lower bounds on its variance, which can ",
    "link": "https://arxiv.org/abs/2312.11126",
    "context": "Title: Harnessing Inherent Noises for Privacy Preservation in Quantum Machine Learning\nAbstract: arXiv:2312.11126v2 Announce Type: replace-cross  Abstract: Quantum computing revolutionizes the way of solving complex problems and handling vast datasets, which shows great potential to accelerate the machine learning process. However, data leakage in quantum machine learning (QML) may present privacy risks. Although differential privacy (DP), which protects privacy through the injection of artificial noise, is a well-established approach, its application in the QML domain remains under-explored. In this paper, we propose to harness inherent quantum noises to protect data privacy in QML. Especially, considering the Noisy Intermediate-Scale Quantum (NISQ) devices, we leverage the unavoidable shot noise and incoherent noise in quantum computing to preserve the privacy of QML models for binary classification. We mathematically analyze that the gradient of quantum circuit parameters in QML satisfies a Gaussian distribution, and derive the upper and lower bounds on its variance, which can ",
    "path": "papers/23/12/2312.11126.json",
    "total_tokens": 854,
    "translated_title": "利用固有噪声保护量子机器学习中的隐私",
    "translated_abstract": "量子计算彻底改变了解决复杂问题和处理海量数据的方式，显示出加速机器学习过程的巨大潜力。然而，在量子机器学习（QML）中的数据泄露可能带来隐私风险。尽管差分隐私（DP）是一种通过注入人工噪声保护隐私的成熟方法，但其在QML领域的应用仍未得到充分探讨。本文提出利用固有的量子噪声保护QML中的数据隐私。尤其是考虑到存在噪声的中等规模量子（NISQ）设备，我们利用量子计算中不可避免的射线噪声和非相干噪声来保护二元分类的QML模型的隐私。我们在数学上分析了QML中量子电路参数的梯度满足高斯分布，并推导了其方差的上下界，",
    "tldr": "本文提出利用固有的量子噪声来保护量子机器学习中的数据隐私，对量子电路参数的梯度进行数学分析，并推导其方差的上下界。",
    "en_tdlr": "This paper proposes leveraging inherent quantum noises to protect data privacy in quantum machine learning, mathematically analyzing the gradient of quantum circuit parameters and deriving the upper and lower bounds on its variance."
}