{
    "title": "Prompt Highlighter: Interactive Control for Multi-Modal LLMs",
    "abstract": "arXiv:2312.04302v2 Announce Type: replace-cross  Abstract: This study targets a critical aspect of multi-modal LLMs' (LLMs&VLMs) inference: explicit controllable text generation. Multi-modal LLMs empower multi-modality understanding with the capability of semantic generation yet bring less explainability and heavier reliance on prompt contents due to their autoregressive generative nature. While manipulating prompt formats could improve outputs, designing specific and precise prompts per task can be challenging and ineffective. To tackle this issue, we introduce a novel inference method, Prompt Highlighter, which enables users to highlight specific prompt spans to interactively control the focus during generation. Motivated by the classifier-free diffusion guidance, we form regular and unconditional context pairs based on highlighted tokens, demonstrating that the autoregressive generation in models can be guided in a classifier-free way. Notably, we find that, during inference, guidin",
    "link": "https://arxiv.org/abs/2312.04302",
    "context": "Title: Prompt Highlighter: Interactive Control for Multi-Modal LLMs\nAbstract: arXiv:2312.04302v2 Announce Type: replace-cross  Abstract: This study targets a critical aspect of multi-modal LLMs' (LLMs&VLMs) inference: explicit controllable text generation. Multi-modal LLMs empower multi-modality understanding with the capability of semantic generation yet bring less explainability and heavier reliance on prompt contents due to their autoregressive generative nature. While manipulating prompt formats could improve outputs, designing specific and precise prompts per task can be challenging and ineffective. To tackle this issue, we introduce a novel inference method, Prompt Highlighter, which enables users to highlight specific prompt spans to interactively control the focus during generation. Motivated by the classifier-free diffusion guidance, we form regular and unconditional context pairs based on highlighted tokens, demonstrating that the autoregressive generation in models can be guided in a classifier-free way. Notably, we find that, during inference, guidin",
    "path": "papers/23/12/2312.04302.json",
    "total_tokens": 917,
    "translated_title": "Prompt Highlighter: 多模态LLM互动控制的研究",
    "translated_abstract": "这项研究关注多模态LLMs（LLMs和VLMs）推理中的一个关键方面：显式可控文本生成。多模态LLMs通过语义生成的能力增强了多模态理解，但由于其自回归生成的特性，解释性较差且更加依赖提示内容。尽管操作提示格式可以改进输出，但设计针对每个任务的具体和精确提示可能具有挑战性且效果不佳。为了解决这一问题，我们引入了一种新颖的推理方法，Prompt Highlighter，使用户能够突出显示特定提示跨度以在生成过程中交互控制焦点。受无分类器扩散引导的启发，我们基于突出显示的标记形成常规和无条件的上下文对，证明了模型中的自回归生成可以以无分类器的方式进行引导。值得注意的是，在推理过程中，我们发现，引导过程可以显著提高输出质量并增强模型的解释能力，同时减轻了对提示内容的依赖。",
    "tldr": "提出了一种称为Prompt Highlighter的新型推理方法，通过突出显示特定提示跨度，实现用户在生成过程中交互控制焦点，并基于高亮标记形成正规且无条件的上下文对，从而在没有分类器的情况下引导模型的自回归生成。",
    "en_tdlr": "Introduced a novel inference method called Prompt Highlighter, which allows users to interactively control the focus during generation by highlighting specific prompt spans, forming regular and unconditional context pairs based on highlighted tokens for guiding autoregressive generation in a classifier-free way during inference."
}