{
    "title": "Scaling Opponent Shaping to High Dimensional Games",
    "abstract": "In multi-agent settings with mixed incentives, methods developed for zero-sum games have been shown to lead to detrimental outcomes. To address this issue, opponent shaping (OS) methods explicitly learn to influence the learning dynamics of co-players and empirically lead to improved individual and collective outcomes. However, OS methods have only been evaluated in low-dimensional environments due to the challenges associated with estimating higher-order derivatives or scaling model-free meta-learning. Alternative methods that scale to more complex settings either converge to undesirable solutions or rely on unrealistic assumptions about the environment or co-players. In this paper, we successfully scale an OS-based approach to general-sum games with temporally-extended actions and long-time horizons for the first time. After analysing the representations of the meta-state and history used by previous algorithms, we propose a simplified version called Shaper. We show empirically that ",
    "link": "https://arxiv.org/abs/2312.12568",
    "context": "Title: Scaling Opponent Shaping to High Dimensional Games\nAbstract: In multi-agent settings with mixed incentives, methods developed for zero-sum games have been shown to lead to detrimental outcomes. To address this issue, opponent shaping (OS) methods explicitly learn to influence the learning dynamics of co-players and empirically lead to improved individual and collective outcomes. However, OS methods have only been evaluated in low-dimensional environments due to the challenges associated with estimating higher-order derivatives or scaling model-free meta-learning. Alternative methods that scale to more complex settings either converge to undesirable solutions or rely on unrealistic assumptions about the environment or co-players. In this paper, we successfully scale an OS-based approach to general-sum games with temporally-extended actions and long-time horizons for the first time. After analysing the representations of the meta-state and history used by previous algorithms, we propose a simplified version called Shaper. We show empirically that ",
    "path": "papers/23/12/2312.12568.json",
    "total_tokens": 851,
    "translated_title": "对高维度游戏的对手塑形进行了扩展",
    "translated_abstract": "在混合动机的多智能体环境中，已经证明了为零和游戏开发的方法会导致不利的结果。为了解决这个问题，对手塑形（OS）方法明确地学习如何影响合作玩家的学习动态，并且在实践中可以改善个体和集体的结果。然而，由于估计更高阶导数或扩展模型无关元学习的挑战，OS方法只在低维环境中进行了评估。能够扩展到复杂环境的替代方法要么收敛于不理想的解决方案，要么依赖于对环境或合作玩家进行了不切实际的假设。在本文中，我们第一次成功地将基于OS的方法扩展到具有时间延长操作和长时间范围的广义游戏中。经过对先前算法使用的元状态和历史的表示进行分析后，我们提出了一个简化版本的方法称为Shaper。经验证明，这种方法能够有效改善个体和集体的结果。",
    "tldr": "本文通过对对手塑形（OS）方法的扩展，成功将其应用于具有时间延长操作和长时间范围的广义游戏，该方法能够改善个体和集体的结果。",
    "en_tdlr": "This paper successfully extends the opponent shaping (OS) method to general-sum games with temporally-extended actions and long-time horizons, resulting in improved individual and collective outcomes."
}