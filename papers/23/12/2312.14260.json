{
    "title": "Elevating Defenses: Bridging Adversarial Training and Watermarking for Model Resilience. (arXiv:2312.14260v2 [cs.LG] UPDATED)",
    "abstract": "Machine learning models are being used in an increasing number of critical applications; thus, securing their integrity and ownership is critical. Recent studies observed that adversarial training and watermarking have a conflicting interaction. This work introduces a novel framework to integrate adversarial training with watermarking techniques to fortify against evasion attacks and provide confident model verification in case of intellectual property theft. We use adversarial training together with adversarial watermarks to train a robust watermarked model. The key intuition is to use a higher perturbation budget to generate adversarial watermarks compared to the budget used for adversarial training, thus avoiding conflict. We use the MNIST and Fashion-MNIST datasets to evaluate our proposed technique on various model stealing attacks. The results obtained consistently outperform the existing baseline in terms of robustness performance and further prove the resilience of this defense",
    "link": "http://arxiv.org/abs/2312.14260",
    "context": "Title: Elevating Defenses: Bridging Adversarial Training and Watermarking for Model Resilience. (arXiv:2312.14260v2 [cs.LG] UPDATED)\nAbstract: Machine learning models are being used in an increasing number of critical applications; thus, securing their integrity and ownership is critical. Recent studies observed that adversarial training and watermarking have a conflicting interaction. This work introduces a novel framework to integrate adversarial training with watermarking techniques to fortify against evasion attacks and provide confident model verification in case of intellectual property theft. We use adversarial training together with adversarial watermarks to train a robust watermarked model. The key intuition is to use a higher perturbation budget to generate adversarial watermarks compared to the budget used for adversarial training, thus avoiding conflict. We use the MNIST and Fashion-MNIST datasets to evaluate our proposed technique on various model stealing attacks. The results obtained consistently outperform the existing baseline in terms of robustness performance and further prove the resilience of this defense",
    "path": "papers/23/12/2312.14260.json",
    "total_tokens": 914,
    "translated_title": "提升防御能力：将对抗训练和水印技术相结合，为模型的弹性提供保护",
    "translated_abstract": "机器学习模型在越来越多的关键应用中被使用，因此确保其完整性和所有权非常重要。最近的研究发现，对抗训练和水印技术存在冲突的相互作用。本文引入了一种新的框架，将对抗训练与水印技术相结合，以增强对规避攻击的防御能力，并在知识产权盗窃案件中提供确凿的模型验证。我们使用对抗训练和对抗水印来训练一个强大的水印模型。关键的方法是在生成对抗水印时使用更高的扰动预算，与用于对抗训练的预算避免冲突。我们使用MNIST和Fashion-MNIST数据集来评估我们提出的技术对各种模型窃取攻击的效果。所得到的结果在鲁棒性性能方面始终优于现有基准，并进一步证明了这种防御的弹性。",
    "tldr": "本研究介绍了一种新的框架，将对抗训练和水印技术相结合，用于提高模型的弹性，防御规避攻击，并在知识产权盗窃案件中提供确凿的模型验证。",
    "en_tdlr": "This paper presents a novel framework that combines adversarial training and watermarking techniques to enhance model resilience, defend against evasion attacks, and provide confident model verification in cases of intellectual property theft."
}