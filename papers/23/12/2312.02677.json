{
    "title": "Contact Energy Based Hindsight Experience Prioritization",
    "abstract": "arXiv:2312.02677v2 Announce Type: replace-cross  Abstract: Multi-goal robot manipulation tasks with sparse rewards are difficult for reinforcement learning (RL) algorithms due to the inefficiency in collecting successful experiences. Recent algorithms such as Hindsight Experience Replay (HER) expedite learning by taking advantage of failed trajectories and replacing the desired goal with one of the achieved states so that any failed trajectory can be utilized as a contribution to learning. However, HER uniformly chooses failed trajectories, without taking into account which ones might be the most valuable for learning. In this paper, we address this problem and propose a novel approach Contact Energy Based Prioritization~(CEBP) to select the samples from the replay buffer based on rich information due to contact, leveraging the touch sensors in the gripper of the robot and object displacement. Our prioritization scheme favors sampling of contact-rich experiences, which are arguably the",
    "link": "https://arxiv.org/abs/2312.02677",
    "context": "Title: Contact Energy Based Hindsight Experience Prioritization\nAbstract: arXiv:2312.02677v2 Announce Type: replace-cross  Abstract: Multi-goal robot manipulation tasks with sparse rewards are difficult for reinforcement learning (RL) algorithms due to the inefficiency in collecting successful experiences. Recent algorithms such as Hindsight Experience Replay (HER) expedite learning by taking advantage of failed trajectories and replacing the desired goal with one of the achieved states so that any failed trajectory can be utilized as a contribution to learning. However, HER uniformly chooses failed trajectories, without taking into account which ones might be the most valuable for learning. In this paper, we address this problem and propose a novel approach Contact Energy Based Prioritization~(CEBP) to select the samples from the replay buffer based on rich information due to contact, leveraging the touch sensors in the gripper of the robot and object displacement. Our prioritization scheme favors sampling of contact-rich experiences, which are arguably the",
    "path": "papers/23/12/2312.02677.json",
    "total_tokens": 833,
    "translated_title": "基于接触能量的事后经验优先级排序",
    "translated_abstract": "具有稀疏奖励的多目标机器人操作任务对于强化学习（RL）算法而言是困难的，原因在于收集成功经验的低效性。最近的算法，如事后经验重放（HER），通过利用失败的轨迹并将期望目标替换为已实现状态之一来加快学习，使得任何失败的轨迹都可以被利用作为学习的一部分。然而，HER会均匀选择失败的轨迹，而不考虑哪些可能对学习最有价值。在本文中，我们解决了这个问题，并提出了一种新颖的方法Contact Energy Based Prioritization~(CEBP)，根据接触的丰富信息从重放缓冲区中选择样本，利用机器人夹爪和物体位移中的触觉传感器。我们的优先级方案偏向于采样接触丰富的经验，这些经验可以被认为是最有价值的。",
    "tldr": "本文提出了一种基于接触能量的优先级排序方法（CEBP），用于解决强化学习算法中选择具有丰富接触信息的样本以提高学习效率的问题。",
    "en_tdlr": "This paper proposes a Contact Energy Based Prioritization (CEBP) method for selecting samples with rich contact information in reinforcement learning algorithms to improve learning efficiency."
}