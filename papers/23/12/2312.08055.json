{
    "title": "Breaking the Silence: the Threats of Using LLMs in Software Engineering. (arXiv:2312.08055v2 [cs.SE] UPDATED)",
    "abstract": "Large Language Models (LLMs) have gained considerable traction within the Software Engineering (SE) community, impacting various SE tasks from code completion to test generation, from program repair to code summarization. Despite their promise, researchers must still be careful as numerous intricate factors can influence the outcomes of experiments involving LLMs. This paper initiates an open discussion on potential threats to the validity of LLM-based research including issues such as closed-source models, possible data leakage between LLM training data and research evaluation, and the reproducibility of LLM-based findings. In response, this paper proposes a set of guidelines tailored for SE researchers and Language Model (LM) providers to mitigate these concerns. The implications of the guidelines are illustrated using existing good practices followed by LLM providers and a practical example for SE researchers in the context of test case generation.",
    "link": "http://arxiv.org/abs/2312.08055",
    "context": "Title: Breaking the Silence: the Threats of Using LLMs in Software Engineering. (arXiv:2312.08055v2 [cs.SE] UPDATED)\nAbstract: Large Language Models (LLMs) have gained considerable traction within the Software Engineering (SE) community, impacting various SE tasks from code completion to test generation, from program repair to code summarization. Despite their promise, researchers must still be careful as numerous intricate factors can influence the outcomes of experiments involving LLMs. This paper initiates an open discussion on potential threats to the validity of LLM-based research including issues such as closed-source models, possible data leakage between LLM training data and research evaluation, and the reproducibility of LLM-based findings. In response, this paper proposes a set of guidelines tailored for SE researchers and Language Model (LM) providers to mitigate these concerns. The implications of the guidelines are illustrated using existing good practices followed by LLM providers and a practical example for SE researchers in the context of test case generation.",
    "path": "papers/23/12/2312.08055.json",
    "total_tokens": 905,
    "translated_title": "打破沉默：在软件工程中使用LLMs的威胁",
    "translated_abstract": "大型语言模型（LLMs）在软件工程领域得到了广泛应用，影响着代码补全、测试生成、程序修复和代码摘要等各种任务。然而，虽然具有很大潜力，但研究者们在涉及LLMs的实验中仍需谨慎，因为许多复杂因素可能会影响实验结果。本文对LLM相关研究的有效性潜在威胁进行了开放讨论，包括闭源模型、LLM训练数据与研究评估之间的可能数据泄漏以及LLM相关研究结果的可重复性。作为回应，本文提出了一套针对软件工程研究人员和语言模型提供商的指南，以减轻这些担忧。指南的影响通过现有的LLM提供商的良好实践和软件工程研究人员在测试用例生成方面的实际示例进行说明。",
    "tldr": "本文讨论了在软件工程中使用LLMs的潜在威胁，包括闭源模型、数据泄漏和研究结果的可重复性，并提出了一套针对软件工程研究人员和语言模型提供商的指南来减轻这些担忧。",
    "en_tdlr": "This paper discusses the potential threats of using LLMs in software engineering, including closed-source models, data leakage, and the reproducibility of research findings. It proposes a set of guidelines for SE researchers and LM providers to mitigate these concerns."
}