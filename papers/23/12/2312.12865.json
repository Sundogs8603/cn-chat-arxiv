{
    "title": "RadEdit: stress-testing biomedical vision models via diffusion image editing",
    "abstract": "arXiv:2312.12865v3 Announce Type: replace-cross  Abstract: Biomedical imaging datasets are often small and biased, meaning that real-world performance of predictive models can be substantially lower than expected from internal testing. This work proposes using generative image editing to simulate dataset shifts and diagnose failure modes of biomedical vision models; this can be used in advance of deployment to assess readiness, potentially reducing cost and patient harm. Existing editing methods can produce undesirable changes, with spurious correlations learned due to the co-occurrence of disease and treatment interventions, limiting practical applicability. To address this, we train a text-to-image diffusion model on multiple chest X-ray datasets and introduce a new editing method RadEdit that uses multiple masks, if present, to constrain changes and ensure consistency in the edited images. We consider three types of dataset shifts: acquisition shift, manifestation shift, and populat",
    "link": "https://arxiv.org/abs/2312.12865",
    "context": "Title: RadEdit: stress-testing biomedical vision models via diffusion image editing\nAbstract: arXiv:2312.12865v3 Announce Type: replace-cross  Abstract: Biomedical imaging datasets are often small and biased, meaning that real-world performance of predictive models can be substantially lower than expected from internal testing. This work proposes using generative image editing to simulate dataset shifts and diagnose failure modes of biomedical vision models; this can be used in advance of deployment to assess readiness, potentially reducing cost and patient harm. Existing editing methods can produce undesirable changes, with spurious correlations learned due to the co-occurrence of disease and treatment interventions, limiting practical applicability. To address this, we train a text-to-image diffusion model on multiple chest X-ray datasets and introduce a new editing method RadEdit that uses multiple masks, if present, to constrain changes and ensure consistency in the edited images. We consider three types of dataset shifts: acquisition shift, manifestation shift, and populat",
    "path": "papers/23/12/2312.12865.json",
    "total_tokens": 897,
    "translated_title": "RadEdit：通过扩散图像编辑对生物医学视觉模型进行压力测试",
    "translated_abstract": "生物医学成像数据集通常规模较小且存在偏见，这意味着预测模型的实际表现往往远低于内部测试所预期的水平。本研究提出使用生成图像编辑来模拟数据集转移，并诊断生物医学视觉模型的失效模式；这可以在部署前用于评估就绪性，可能减少成本和患者危害。现有的编辑方法可能会产生不良变化，由于疾病与治疗干预的共同出现而学到虚假相关性，从而限制了实际应用性。为解决这一问题，我们在多个胸部X射线数据集上训练了一个文本到图像扩散模型，并引入了一种名为RadEdit的新编辑方法，使用多个掩膜（如果存在）来约束更改，并确保编辑图像的一致性。我们考虑三种数据集转移类型：获取转移、表现转移和人口转移",
    "tldr": "该研究提出了一种名为RadEdit的新编辑方法，通过训练文本到图像扩散模型，在多个胸部X射线数据集上对生物医学视觉模型进行压力测试，从而模拟数据集转移，诊断失效模式，并确保编辑图像的一致性。",
    "en_tdlr": "The study introduces a new editing method called RadEdit, which trains a text-to-image diffusion model on multiple chest X-ray datasets to stress-test biomedical vision models, simulate dataset shifts, diagnose failure modes, and ensure consistency in the edited images."
}