{
    "title": "DSPy Assertions: Computational Constraints for Self-Refining Language Model Pipelines",
    "abstract": "Chaining language model (LM) calls as composable modules is fueling a new way of programming, but ensuring LMs adhere to important constraints requires heuristic \"prompt engineering\". We introduce LM Assertions, a programming construct for expressing computational constraints that LMs should satisfy. We integrate our constructs into the recent DSPy programming model for LMs, and present new strategies that allow DSPy to compile programs with LM Assertions into more reliable and accurate systems. We also propose strategies to use assertions at inference time for automatic self-refinement with LMs. We report on four diverse case studies for text generation and find that LM Assertions improve not only compliance with imposed rules but also downstream task performance, passing constraints up to 164% more often and generating up to 37% more higher-quality responses. Our reference implementation of LM Assertions is integrated into DSPy at https://github.com/stanfordnlp/dspy",
    "link": "https://rss.arxiv.org/abs/2312.13382",
    "context": "Title: DSPy Assertions: Computational Constraints for Self-Refining Language Model Pipelines\nAbstract: Chaining language model (LM) calls as composable modules is fueling a new way of programming, but ensuring LMs adhere to important constraints requires heuristic \"prompt engineering\". We introduce LM Assertions, a programming construct for expressing computational constraints that LMs should satisfy. We integrate our constructs into the recent DSPy programming model for LMs, and present new strategies that allow DSPy to compile programs with LM Assertions into more reliable and accurate systems. We also propose strategies to use assertions at inference time for automatic self-refinement with LMs. We report on four diverse case studies for text generation and find that LM Assertions improve not only compliance with imposed rules but also downstream task performance, passing constraints up to 164% more often and generating up to 37% more higher-quality responses. Our reference implementation of LM Assertions is integrated into DSPy at https://github.com/stanfordnlp/dspy",
    "path": "papers/23/12/2312.13382.json",
    "total_tokens": 888,
    "translated_title": "DSPy断言：用于自我调整语言模型流水线的计算约束",
    "translated_abstract": "将语言模型（LM）调用作为可组合模块的链式编程方式正在推动一种新的编程方式，但确保LM遵守重要约束需要启发式的“提示工程”。我们介绍了LM断言，这是一种用于表达LM应满足的计算约束的编程结构。我们将这些结构整合到最近的DSPy LM编程模型中，并提出了新的策略，使得DSPy能够将带有LM断言的程序编译为更可靠和准确的系统。我们还提出了在推断时使用断言进行自动自我修复的策略。我们报告了四个不同的文本生成案例研究，并发现LM断言不仅改善了对规则的遵守，而且提高了下游任务的性能，接受约束的次数增加了164％，生成了37％更高质量的回复。我们的LM断言参考实现已集成到DSPy中，网址为https://github.com/stanfordnlp/dspy",
    "tldr": "DSPy引入了LM断言，用于表达语言模型应满足的计算约束。在四个案例研究中，LM断言不仅提高了对规则的遵守，而且提高了下游任务的性能，增加了对约束的接受次数并生成了更高质量的回复。",
    "en_tdlr": "DSPy introduces LM Assertions as a programming construct to express computational constraints that language models should satisfy. In four case studies, LM Assertions not only improve compliance with rules but also enhance downstream task performance, increasing the acceptance of constraints and generating higher-quality responses."
}