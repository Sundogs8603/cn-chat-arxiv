{
    "title": "Learning to Generate Text in Arbitrary Writing Styles",
    "abstract": "arXiv:2312.17242v2 Announce Type: replace  Abstract: Prior work in style-controlled text generation has focused on tasks such as emulating the style of prolific literary authors, producing formal or informal text, and mitigating toxicity of generated text. Plentiful demonstrations of these styles are available, and as a result modern language models are often able to emulate them, either via prompting or discriminative control. However, in applications such as writing assistants, it is desirable for language models to produce text in an author-specific style on the basis of a potentially small writing sample. For example, someone writing in a particular dialect may prefer writing suggestions that retain the same dialect. We find that instruction-tuned language models can struggle to reproduce author-specific style demonstrated in a prompt. Instead, we propose to guide a language model to generate text in a target style using contrastively-trained representations that capture stylometri",
    "link": "https://arxiv.org/abs/2312.17242",
    "context": "Title: Learning to Generate Text in Arbitrary Writing Styles\nAbstract: arXiv:2312.17242v2 Announce Type: replace  Abstract: Prior work in style-controlled text generation has focused on tasks such as emulating the style of prolific literary authors, producing formal or informal text, and mitigating toxicity of generated text. Plentiful demonstrations of these styles are available, and as a result modern language models are often able to emulate them, either via prompting or discriminative control. However, in applications such as writing assistants, it is desirable for language models to produce text in an author-specific style on the basis of a potentially small writing sample. For example, someone writing in a particular dialect may prefer writing suggestions that retain the same dialect. We find that instruction-tuned language models can struggle to reproduce author-specific style demonstrated in a prompt. Instead, we propose to guide a language model to generate text in a target style using contrastively-trained representations that capture stylometri",
    "path": "papers/23/12/2312.17242.json",
    "total_tokens": 790,
    "translated_title": "在任意书写风格中生成文本的学习",
    "translated_abstract": "先前在风格控制文本生成方面的工作主要集中在任务上，例如模仿多产文学作者的风格，生成正式或非正式文本，并减轻生成文本的有害性。这些风格的丰富展示可用，并且因此现代语言模型通常能够模仿它们，无论是通过提示还是区分控制。然而，在诸如写作助手之类的应用中，期望语言模型能够根据可能很小的写作样本以某位作者特定的风格生成文本。例如，使用特定方言的人可能更喜欢保留相同方言的写作建议。我们发现，通过指导语言模型以对比训练的表示来生成目标风格的文本，可以更好地实现这一目标，这些表示捕捉到了文体的特征。",
    "tldr": "提出了通过引导语言模型使用对比训练的表示来生成目标风格的文本的方法，以解决传统基于指令的模型难以重新现出作者特定风格的问题。"
}