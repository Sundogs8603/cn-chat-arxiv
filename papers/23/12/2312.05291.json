{
    "title": "GlitchBench: Can large multimodal models detect video game glitches?",
    "abstract": "arXiv:2312.05291v2 Announce Type: replace-cross  Abstract: Large multimodal models (LMMs) have evolved from large language models (LLMs) to integrate multiple input modalities, such as visual inputs. This integration augments the capacity of LLMs for tasks requiring visual comprehension and reasoning. However, the extent and limitations of their enhanced abilities are not fully understood, especially when it comes to real-world tasks. To address this gap, we introduce GlitchBench, a novel benchmark derived from video game quality assurance tasks, to test and evaluate the reasoning capabilities of LMMs. Our benchmark is curated from a variety of unusual and glitched scenarios from video games and aims to challenge both the visual and linguistic reasoning powers of LMMs in detecting and interpreting out-of-the-ordinary events. We evaluate multiple state-of-the-art LMMs, and we show that GlitchBench presents a new challenge for these models. Code and data are available at: https://glitchb",
    "link": "https://arxiv.org/abs/2312.05291",
    "context": "Title: GlitchBench: Can large multimodal models detect video game glitches?\nAbstract: arXiv:2312.05291v2 Announce Type: replace-cross  Abstract: Large multimodal models (LMMs) have evolved from large language models (LLMs) to integrate multiple input modalities, such as visual inputs. This integration augments the capacity of LLMs for tasks requiring visual comprehension and reasoning. However, the extent and limitations of their enhanced abilities are not fully understood, especially when it comes to real-world tasks. To address this gap, we introduce GlitchBench, a novel benchmark derived from video game quality assurance tasks, to test and evaluate the reasoning capabilities of LMMs. Our benchmark is curated from a variety of unusual and glitched scenarios from video games and aims to challenge both the visual and linguistic reasoning powers of LMMs in detecting and interpreting out-of-the-ordinary events. We evaluate multiple state-of-the-art LMMs, and we show that GlitchBench presents a new challenge for these models. Code and data are available at: https://glitchb",
    "path": "papers/23/12/2312.05291.json",
    "total_tokens": 886,
    "translated_title": "GlitchBench：大型多模态模型能够检测视频游戏漏洞吗？",
    "translated_abstract": "大型多模态模型（LMMs）已从大型语言模型（LLMs）发展而来，以整合多种输入模态，如视觉输入。这种整合增强了LLMs在需要视觉理解和推理的任务上的能力。然而，尤其是在涉及真实世界任务时，它们增强的能力的程度和限制尚未完全被理解。为了填补这一空白，我们引入了GlitchBench，这是一个新颖的基准，源自于视频游戏质量保证任务，旨在测试和评估LMMs的推理能力。我们的基准是从各种视频游戏中的不寻常和出现故障的场景精心策划而成，旨在挑战LMMs在检测和解释非同寻常事件方面的视觉和语言推理能力。我们评估了多个最先进的LMMs，并展示了GlitchBench为这些模型提出了新挑战。 代码和数据可在以下链接找到：https://glitchb",
    "tldr": "GlitchBench是一个基于视频游戏质量保证任务的新基准，旨在挑战LMMs在检测和解释异常事件方面的视觉和语言推理能力。",
    "en_tdlr": "GlitchBench is a new benchmark derived from video game quality assurance tasks, aiming to challenge the visual and linguistic reasoning capabilities of LMMs in detecting and interpreting anomalous events."
}