{
    "title": "SkillDiffuser: Interpretable Hierarchical Planning via Skill Abstractions in Diffusion-Based Task Execution",
    "abstract": "arXiv:2312.11598v2 Announce Type: replace-cross  Abstract: Diffusion models have demonstrated strong potential for robotic trajectory planning. However, generating coherent trajectories from high-level instructions remains challenging, especially for long-range composition tasks requiring multiple sequential skills. We propose SkillDiffuser, an end-to-end hierarchical planning framework integrating interpretable skill learning with conditional diffusion planning to address this problem. At the higher level, the skill abstraction module learns discrete, human-understandable skill representations from visual observations and language instructions. These learned skill embeddings are then used to condition the diffusion model to generate customized latent trajectories aligned with the skills. This allows generating diverse state trajectories that adhere to the learnable skills. By integrating skill learning with conditional trajectory generation, SkillDiffuser produces coherent behavior fo",
    "link": "https://arxiv.org/abs/2312.11598",
    "context": "Title: SkillDiffuser: Interpretable Hierarchical Planning via Skill Abstractions in Diffusion-Based Task Execution\nAbstract: arXiv:2312.11598v2 Announce Type: replace-cross  Abstract: Diffusion models have demonstrated strong potential for robotic trajectory planning. However, generating coherent trajectories from high-level instructions remains challenging, especially for long-range composition tasks requiring multiple sequential skills. We propose SkillDiffuser, an end-to-end hierarchical planning framework integrating interpretable skill learning with conditional diffusion planning to address this problem. At the higher level, the skill abstraction module learns discrete, human-understandable skill representations from visual observations and language instructions. These learned skill embeddings are then used to condition the diffusion model to generate customized latent trajectories aligned with the skills. This allows generating diverse state trajectories that adhere to the learnable skills. By integrating skill learning with conditional trajectory generation, SkillDiffuser produces coherent behavior fo",
    "path": "papers/23/12/2312.11598.json",
    "total_tokens": 818,
    "translated_title": "SkillDiffuser: 通过技能抽象在基于扩散的任务执行中实现可解释的分层规划",
    "translated_abstract": "扩散模型展示了在机器人轨迹规划方面的强大潜力。然而，从高层指令生成连贯的轨迹仍然具有挑战性，特别是对于需要多个顺序技能的长距离组合任务。我们提出了SkillDiffuser，这是一个端到端的分层规划框架，将可解释的技能学习与条件扩散规划相结合，以解决这一问题。在较高层次，技能抽象模块从视觉观察和语言指令中学习离散的、人类可理解的技能表示。然后，这些学习到的技能嵌入被用来条件化扩散模型，生成与技能对齐的定制潜在轨迹。这允许生成符合可学习技能的多样状态轨迹。通过将技能学习与条件轨迹生成相结合，SkillDiffuser产生连贯的行为",
    "tldr": "SkillDiffuser通过将可解释的技能学习与条件扩散规划相结合，实现了在高层指令下生成连贯轨迹的分层规划。",
    "en_tdlr": "SkillDiffuser achieves hierarchical planning of generating coherent trajectories from high-level instructions by integrating interpretable skill learning with conditional diffusion planning."
}