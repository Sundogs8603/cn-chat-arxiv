{
    "title": "Task-Driven Causal Feature Distillation: Towards Trustworthy Risk Prediction. (arXiv:2312.16113v2 [cs.LG] UPDATED)",
    "abstract": "Since artificial intelligence has seen tremendous recent successes in many areas, it has sparked great interest in its potential for trustworthy and interpretable risk prediction. However, most models lack causal reasoning and struggle with class imbalance, leading to poor precision and recall. To address this, we propose a Task-Driven Causal Feature Distillation model (TDCFD) to transform original feature values into causal feature attributions for the specific risk prediction task. The causal feature attribution helps describe how much contribution the value of this feature can make to the risk prediction result. After the causal feature distillation, a deep neural network is applied to produce trustworthy prediction results with causal interpretability and high precision/recall. We evaluate the performance of our TDCFD method on several synthetic and real datasets, and the results demonstrate its superiority over the state-of-the-art methods regarding precision, recall, interpretabi",
    "link": "http://arxiv.org/abs/2312.16113",
    "context": "Title: Task-Driven Causal Feature Distillation: Towards Trustworthy Risk Prediction. (arXiv:2312.16113v2 [cs.LG] UPDATED)\nAbstract: Since artificial intelligence has seen tremendous recent successes in many areas, it has sparked great interest in its potential for trustworthy and interpretable risk prediction. However, most models lack causal reasoning and struggle with class imbalance, leading to poor precision and recall. To address this, we propose a Task-Driven Causal Feature Distillation model (TDCFD) to transform original feature values into causal feature attributions for the specific risk prediction task. The causal feature attribution helps describe how much contribution the value of this feature can make to the risk prediction result. After the causal feature distillation, a deep neural network is applied to produce trustworthy prediction results with causal interpretability and high precision/recall. We evaluate the performance of our TDCFD method on several synthetic and real datasets, and the results demonstrate its superiority over the state-of-the-art methods regarding precision, recall, interpretabi",
    "path": "papers/23/12/2312.16113.json",
    "total_tokens": 929,
    "translated_title": "任务驱动的因果特征提取：朝着可信的风险预测迈进",
    "translated_abstract": "由于人工智能在许多领域取得了巨大的成功，对其在可信和可解释的风险预测方面的潜力引起了极大的兴趣。然而，大多数模型缺乏因果推理，并且在类别不平衡的情况下难以应对，导致精确度和召回率较低。为了解决这个问题，我们提出了一种任务驱动的因果特征提取模型（TDCFD），将原始特征值转化为特定风险预测任务的因果特征归因。因果特征归因有助于描述该特征的值对风险预测结果的贡献程度。在因果特征提取之后，我们应用深度神经网络生成具有因果可解释性和高精确度/召回率的可信预测结果。我们在几个合成和真实数据集上评估了TDCFD方法的性能，结果表明其在精确度、召回率和可解释性方面优于现有方法。",
    "tldr": "该论文提出了一种任务驱动的因果特征提取模型（TDCFD），通过将原始特征值转化为因果特征归因来实现可信的风险预测。实验证实了该方法在精确度、召回率和可解释性方面的优势。"
}