{
    "title": "pixelSplat: 3D Gaussian Splats from Image Pairs for Scalable Generalizable 3D Reconstruction",
    "abstract": "arXiv:2312.12337v3 Announce Type: replace-cross  Abstract: We introduce pixelSplat, a feed-forward model that learns to reconstruct 3D radiance fields parameterized by 3D Gaussian primitives from pairs of images. Our model features real-time and memory-efficient rendering for scalable training as well as fast 3D reconstruction at inference time. To overcome local minima inherent to sparse and locally supported representations, we predict a dense probability distribution over 3D and sample Gaussian means from that probability distribution. We make this sampling operation differentiable via a reparameterization trick, allowing us to back-propagate gradients through the Gaussian splatting representation. We benchmark our method on wide-baseline novel view synthesis on the real-world RealEstate10k and ACID datasets, where we outperform state-of-the-art light field transformers and accelerate rendering by 2.5 orders of magnitude while reconstructing an interpretable and editable 3D radiance",
    "link": "https://arxiv.org/abs/2312.12337",
    "context": "Title: pixelSplat: 3D Gaussian Splats from Image Pairs for Scalable Generalizable 3D Reconstruction\nAbstract: arXiv:2312.12337v3 Announce Type: replace-cross  Abstract: We introduce pixelSplat, a feed-forward model that learns to reconstruct 3D radiance fields parameterized by 3D Gaussian primitives from pairs of images. Our model features real-time and memory-efficient rendering for scalable training as well as fast 3D reconstruction at inference time. To overcome local minima inherent to sparse and locally supported representations, we predict a dense probability distribution over 3D and sample Gaussian means from that probability distribution. We make this sampling operation differentiable via a reparameterization trick, allowing us to back-propagate gradients through the Gaussian splatting representation. We benchmark our method on wide-baseline novel view synthesis on the real-world RealEstate10k and ACID datasets, where we outperform state-of-the-art light field transformers and accelerate rendering by 2.5 orders of magnitude while reconstructing an interpretable and editable 3D radiance",
    "path": "papers/23/12/2312.12337.json",
    "total_tokens": 924,
    "translated_title": "pixelSplat：来自图像对的三维高斯斑块用于可扩展可泛化三维重建",
    "translated_abstract": "我们介绍了pixelSplat，这是一个前向模型，通过图像对学习重建由三维高斯基元参数化的三维辐射场。我们的模型具有实时和内存高效的渲染，可实现可扩展的训练，同时在推断时实现快速的三维重建。为了克服稀疏和局部支持表示固有的局部极小值问题，我们预测了三维上的密集概率分布，并从该概率分布中采样高斯均值。通过重新参数化技巧，我们使得这个采样操作可微分，从而能够通过高斯斑块表示反向传播梯度。我们在真实世界的RealEstate10k和ACID数据集上对我们的方法进行了广角基线新视图合成基准测试，我们的表现优于最先进的光场变换器，并在重建可解释和可编辑的三维辐射的同时加速渲染2.5个数量级。",
    "tldr": "通过引入像素Splat，我们提出了一种学习从图像对中重建三维辐射场的模型，实现了内存高效渲染、高速3D重建，有效克服了稀疏表示的局部极小值问题，实现了优越的实时渲染性能。",
    "en_tdlr": "Introducing pixelSplat, a model that reconstructs 3D radiance fields from image pairs, providing memory-efficient rendering, fast 3D reconstruction, overcoming local minima issues in sparse representations, and achieving superior real-time rendering performance."
}