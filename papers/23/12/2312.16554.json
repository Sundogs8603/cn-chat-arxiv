{
    "title": "A Theoretical Analysis of Efficiency Constrained Utility-Privacy Bi-Objective Optimization in Federated Learning. (arXiv:2312.16554v2 [cs.LG] UPDATED)",
    "abstract": "Federated learning (FL) enables multiple clients to collaboratively learn a shared model without sharing their individual data. Concerns about utility, privacy, and training efficiency in FL have garnered significant research attention. Differential privacy has emerged as a prevalent technique in FL, safeguarding the privacy of individual user data while impacting utility and training efficiency. Within Differential Privacy Federated Learning (DPFL), previous studies have primarily focused on the utility-privacy trade-off, neglecting training efficiency, which is crucial for timely completion. Moreover, differential privacy achieves privacy by introducing controlled randomness (noise) on selected clients in each communication round. Previous work has mainly examined the impact of noise level ($\\sigma$) and communication rounds ($T$) on the privacy-utility dynamic, overlooking other influential factors like the sample ratio ($q$, the proportion of selected clients). This paper systemati",
    "link": "http://arxiv.org/abs/2312.16554",
    "context": "Title: A Theoretical Analysis of Efficiency Constrained Utility-Privacy Bi-Objective Optimization in Federated Learning. (arXiv:2312.16554v2 [cs.LG] UPDATED)\nAbstract: Federated learning (FL) enables multiple clients to collaboratively learn a shared model without sharing their individual data. Concerns about utility, privacy, and training efficiency in FL have garnered significant research attention. Differential privacy has emerged as a prevalent technique in FL, safeguarding the privacy of individual user data while impacting utility and training efficiency. Within Differential Privacy Federated Learning (DPFL), previous studies have primarily focused on the utility-privacy trade-off, neglecting training efficiency, which is crucial for timely completion. Moreover, differential privacy achieves privacy by introducing controlled randomness (noise) on selected clients in each communication round. Previous work has mainly examined the impact of noise level ($\\sigma$) and communication rounds ($T$) on the privacy-utility dynamic, overlooking other influential factors like the sample ratio ($q$, the proportion of selected clients). This paper systemati",
    "path": "papers/23/12/2312.16554.json",
    "total_tokens": 948,
    "translated_title": "联邦学习中受效率限制的效用-隐私双目标优化的理论分析",
    "translated_abstract": "联邦学习（FL）使多个客户端在不共享个体数据的情况下协同学习共享模型。FL中的效用、隐私和训练效率问题已引起重要的研究关注。差分隐私已成为FL中一种主流技术，保护个体用户数据的隐私同时影响效用和训练效率。在差分隐私联邦学习（DPFL）中，先前的研究主要关注效用-隐私的权衡，而忽视了及时完成所必需的训练效率。此外，差分隐私通过在每轮通信中对选定的客户端引入受控的随机性（噪声）来实现隐私保护。先前的工作主要研究了噪声水平（$\\sigma$）和通信轮数（$T$）对隐私-效用动态的影响，但忽视了其他影响因素，如样本比例（$q$，即选定客户端的比例）。",
    "tldr": "本文从理论上分析了联邦学习中受效率限制的效用-隐私双目标优化。先前的研究主要关注效用-隐私的权衡，忽视了训练效率和其他影响因素。该研究对差分隐私联邦学习中的关键问题进行了系统分析。",
    "en_tdlr": "This paper presents a theoretical analysis of efficiency constrained utility-privacy bi-objective optimization in federated learning. Previous studies have focused on the utility-privacy trade-off, neglecting training efficiency and other influential factors. The research systematically analyzes key issues in differential privacy federated learning."
}