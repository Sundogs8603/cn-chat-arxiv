{
    "title": "Deep Neural Networks and Finite Elements of Any Order on Arbitrary Dimensions. (arXiv:2312.14276v3 [math.NA] UPDATED)",
    "abstract": "In this study, we establish that deep neural networks employing ReLU and ReLU$^2$ activation functions can effectively represent Lagrange finite element functions of any order on various simplicial meshes in arbitrary dimensions. We introduce two novel formulations for globally expressing the basis functions of Lagrange elements, tailored for both specific and arbitrary meshes. These formulations are based on a geometric decomposition of the elements, incorporating several insightful and essential properties of high-dimensional simplicial meshes, barycentric coordinate functions, and global basis functions of linear elements. This representation theory facilitates a natural approximation result for such deep neural networks. Our findings present the first demonstration of how deep neural networks can systematically generate general continuous piecewise polynomial functions on both specific or arbitrary simplicial meshes.",
    "link": "http://arxiv.org/abs/2312.14276",
    "context": "Title: Deep Neural Networks and Finite Elements of Any Order on Arbitrary Dimensions. (arXiv:2312.14276v3 [math.NA] UPDATED)\nAbstract: In this study, we establish that deep neural networks employing ReLU and ReLU$^2$ activation functions can effectively represent Lagrange finite element functions of any order on various simplicial meshes in arbitrary dimensions. We introduce two novel formulations for globally expressing the basis functions of Lagrange elements, tailored for both specific and arbitrary meshes. These formulations are based on a geometric decomposition of the elements, incorporating several insightful and essential properties of high-dimensional simplicial meshes, barycentric coordinate functions, and global basis functions of linear elements. This representation theory facilitates a natural approximation result for such deep neural networks. Our findings present the first demonstration of how deep neural networks can systematically generate general continuous piecewise polynomial functions on both specific or arbitrary simplicial meshes.",
    "path": "papers/23/12/2312.14276.json",
    "total_tokens": 809,
    "translated_title": "深度神经网络和任意维度上的有限元素",
    "translated_abstract": "在这项研究中，我们建立了使用ReLU和ReLU^2激活函数的深度神经网络可以有效地表示任意维度上各种单纯形网格中的Lagrange有限元函数。我们引入了两种新颖的公式，用于全局表达Lagrange元素的基函数，既适用于特定网格，也适用于任意网格。这些公式基于元素的几何分解，结合了高维单纯形网格、重心坐标函数和线性元素的全局基函数的一些见解性和基本性质。这种表示理论为这样的深度神经网络提供了一个自然的逼近结果。我们的发现首次展示了深度神经网络如何系统地在特定或任意单纯形网格上生成一般连续分段多项式函数。",
    "tldr": "本研究表明，使用ReLU和ReLU^2激活函数的深度神经网络可以有效地表示任意维度上的Lagrange有限元函数，并且能够在特定或任意单纯形网格上生成一般连续分段多项式函数。",
    "en_tdlr": "This study demonstrates that deep neural networks with ReLU and ReLU^2 activation functions can effectively represent Lagrange finite element functions of any order in arbitrary dimensions, and can generate general continuous piecewise polynomial functions on specific or arbitrary simplicial meshes."
}