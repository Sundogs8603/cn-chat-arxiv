{
    "title": "Learning from higher-order statistics, efficiently: hypothesis tests, random features, and neural networks",
    "abstract": "arXiv:2312.14922v2 Announce Type: replace-cross  Abstract: Neural networks excel at discovering statistical patterns in high-dimensional data sets. In practice, higher-order cumulants, which quantify the non-Gaussian correlations between three or more variables, are particularly important for the performance of neural networks. But how efficient are neural networks at extracting features from higher-order cumulants? We study this question in the spiked cumulant model, where the statistician needs to recover a privileged direction or \"spike\" from the order-$p\\ge 4$ cumulants of $d$-dimensional inputs. We first characterise the fundamental statistical and computational limits of recovering the spike by analysing the number of samples $n$ required to strongly distinguish between inputs from the spiked cumulant model and isotropic Gaussian inputs. We find that statistical distinguishability requires $n\\gtrsim d$ samples, while distinguishing the two distributions in polynomial time require",
    "link": "https://arxiv.org/abs/2312.14922",
    "context": "Title: Learning from higher-order statistics, efficiently: hypothesis tests, random features, and neural networks\nAbstract: arXiv:2312.14922v2 Announce Type: replace-cross  Abstract: Neural networks excel at discovering statistical patterns in high-dimensional data sets. In practice, higher-order cumulants, which quantify the non-Gaussian correlations between three or more variables, are particularly important for the performance of neural networks. But how efficient are neural networks at extracting features from higher-order cumulants? We study this question in the spiked cumulant model, where the statistician needs to recover a privileged direction or \"spike\" from the order-$p\\ge 4$ cumulants of $d$-dimensional inputs. We first characterise the fundamental statistical and computational limits of recovering the spike by analysing the number of samples $n$ required to strongly distinguish between inputs from the spiked cumulant model and isotropic Gaussian inputs. We find that statistical distinguishability requires $n\\gtrsim d$ samples, while distinguishing the two distributions in polynomial time require",
    "path": "papers/23/12/2312.14922.json",
    "total_tokens": 867,
    "translated_title": "从高阶统计量中高效学习：假设检验、随机特征和神经网络",
    "translated_abstract": "神经网络擅长发现高维数据集中的统计模式。在实践中，度量三个或更多变量间的非高斯相关性的高阶累积量对神经网络的性能特别重要。但神经网络有多有效地从高阶累积量中提取特征？我们在尖峰累积量模型中探讨了这个问题，这里统计学家需要从$d$维输入的阶-$p\\ge 4$累积量中恢复出一个特权方向或“尖峰”。我们首先通过分析所需样本数$n$来表征恢复尖峰的基本统计和计算限制，以强烈区分来自尖峰累积量模型和各向同性高斯输入的输入。我们发现，统计上的可区分性需要$n\\gtrsim d$个样本，而在多项式时间内区分这两个分布则需要",
    "tldr": "神经网络在高维数据中发现统计模式，研究了如何高效地从高阶累积量中提取特征，并探讨了在尖峰累积量模型中的统计和计算限制。",
    "en_tdlr": "Neural networks excel at discovering statistical patterns in high-dimensional data sets, efficiently extracting features from higher-order cumulants is studied, along with exploring the statistical and computational limits in the spiked cumulant model."
}