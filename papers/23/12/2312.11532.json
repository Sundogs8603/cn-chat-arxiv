{
    "title": "Topic-VQ-VAE: Leveraging Latent Codebooks for Flexible Topic-Guided Document Generation. (arXiv:2312.11532v2 [cs.CL] UPDATED)",
    "abstract": "This paper introduces a novel approach for topic modeling utilizing latent codebooks from Vector-Quantized Variational Auto-Encoder~(VQ-VAE), discretely encapsulating the rich information of the pre-trained embeddings such as the pre-trained language model. From the novel interpretation of the latent codebooks and embeddings as conceptual bag-of-words, we propose a new generative topic model called Topic-VQ-VAE~(TVQ-VAE) which inversely generates the original documents related to the respective latent codebook. The TVQ-VAE can visualize the topics with various generative distributions including the traditional BoW distribution and the autoregressive image generation. Our experimental results on document analysis and image generation demonstrate that TVQ-VAE effectively captures the topic context which reveals the underlying structures of the dataset and supports flexible forms of document generation. Official implementation of the proposed TVQ-VAE is available at https://github.com/clo",
    "link": "http://arxiv.org/abs/2312.11532",
    "context": "Title: Topic-VQ-VAE: Leveraging Latent Codebooks for Flexible Topic-Guided Document Generation. (arXiv:2312.11532v2 [cs.CL] UPDATED)\nAbstract: This paper introduces a novel approach for topic modeling utilizing latent codebooks from Vector-Quantized Variational Auto-Encoder~(VQ-VAE), discretely encapsulating the rich information of the pre-trained embeddings such as the pre-trained language model. From the novel interpretation of the latent codebooks and embeddings as conceptual bag-of-words, we propose a new generative topic model called Topic-VQ-VAE~(TVQ-VAE) which inversely generates the original documents related to the respective latent codebook. The TVQ-VAE can visualize the topics with various generative distributions including the traditional BoW distribution and the autoregressive image generation. Our experimental results on document analysis and image generation demonstrate that TVQ-VAE effectively captures the topic context which reveals the underlying structures of the dataset and supports flexible forms of document generation. Official implementation of the proposed TVQ-VAE is available at https://github.com/clo",
    "path": "papers/23/12/2312.11532.json",
    "total_tokens": 905,
    "translated_title": "Topic-VQ-VAE: 利用隐变量码本实现灵活的主题导向文档生成",
    "translated_abstract": "本文介绍了一种利用Vector-Quantized Variational Auto-Encoder（VQ-VAE）中的隐变量码本进行主题建模的新方法，离散地封装了预训练嵌入（例如预训练语言模型）的丰富信息。根据对隐变量码本和嵌入的新解释，我们提出了一种新的生成式主题模型，称为Topic-VQ-VAE（TVQ-VAE），它可以反向生成与相应隐变量码本相关的原始文档。TVQ-VAE可以通过包括传统的词袋（BoW）分布和自回归图像生成在内的各种生成分布来可视化主题。我们在文档分析和图像生成上的实验结果表明，TVQ-VAE可以有效捕捉主题上下文，揭示数据集的潜在结构，并支持灵活形式的文档生成。所提出的TVQ-VAE的官方实现可在https://github.com/clo找到。",
    "tldr": "本文介绍了一种利用隐变量码本实现灵活的主题导向文档生成的新方法，通过名为TVQ-VAE的生成式主题模型，可以有效捕捉主题上下文，并支持灵活形式的文档生成。",
    "en_tdlr": "This paper introduces a novel approach for flexible topic-guided document generation utilizing latent codebooks. The proposed Topic-VQ-VAE (TVQ-VAE) effectively captures the topic context and supports flexible forms of document generation."
}