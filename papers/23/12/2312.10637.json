{
    "title": "An Evaluation of GPT-4V and Gemini in Online VQA",
    "abstract": "arXiv:2312.10637v2 Announce Type: replace-cross Abstract: While there is much excitement about the potential of large multimodal models (LMM), a comprehensive evaluation is critical to establish their true capabilities and limitations. In support of this aim, we evaluate two state-of-the-art LMMs, GPT-4V and Gemini, on a new visual question answering dataset sourced from an authentic online question answering community. We conduct fine-grained analysis by generating seven types of metadata for nearly 2,000 visual questions, such as image type and the required image processing capabilities. Our zero-shot performance analysis highlights the types of questions that are most challenging for both models, including questions related to \"puzzling\" topic, with \"Identification\" user intention, with \"Sheet Music\" image type, or labeled as \"hard\" by GPT-4.",
    "link": "https://arxiv.org/abs/2312.10637",
    "context": "Title: An Evaluation of GPT-4V and Gemini in Online VQA\nAbstract: arXiv:2312.10637v2 Announce Type: replace-cross Abstract: While there is much excitement about the potential of large multimodal models (LMM), a comprehensive evaluation is critical to establish their true capabilities and limitations. In support of this aim, we evaluate two state-of-the-art LMMs, GPT-4V and Gemini, on a new visual question answering dataset sourced from an authentic online question answering community. We conduct fine-grained analysis by generating seven types of metadata for nearly 2,000 visual questions, such as image type and the required image processing capabilities. Our zero-shot performance analysis highlights the types of questions that are most challenging for both models, including questions related to \"puzzling\" topic, with \"Identification\" user intention, with \"Sheet Music\" image type, or labeled as \"hard\" by GPT-4.",
    "path": "papers/23/12/2312.10637.json",
    "total_tokens": 832,
    "translated_title": "在在线视觉问答中评估GPT-4V和Gemini",
    "translated_abstract": "尽管大型多模型模型（LMM）的潜力备受关注，但全面评估它们的能力和限制至关重要。为了支持这一目标，我们在一个来自真实在线问答社区的新视觉问答数据集上评估了两个最先进的LMM模型，GPT-4V和Gemini。我们生成了近2000个视觉问题的七种类型的元数据，如图像类型和所需的图像处理能力，并进行了细粒度分析。我们的零样本性能分析突出了这两个模型最具挑战性的问题类型，包括与“令人困惑”的主题相关的问题，具有“识别”用户意图，具有“乐谱”图像类型或被GPT-4标记为“困难”的问题。",
    "tldr": "该论文将在一个真实的在线问答社区的数据集上评估两个最先进的大型多模型模型（GPT-4V和Gemini），分析了它们的能力和限制，研究了不同类型的问题对模型的挑战性，并提供了零样本性能分析。",
    "en_tdlr": "This paper evaluates two state-of-the-art large multimodal models (GPT-4V and Gemini) on a dataset sourced from an authentic online question answering community, providing a comprehensive analysis of their capabilities and limitations. The study highlights the challenging question types for both models and includes zero-shot performance analysis."
}