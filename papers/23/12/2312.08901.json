{
    "title": "Fewer is More: Boosting LLM Reasoning with Reinforced Context Pruning",
    "abstract": "arXiv:2312.08901v3 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) have shown impressive capabilities, yet they still struggle with math reasoning. In this work, we propose CoT-Influx, a novel approach that pushes the boundary of few-shot Chain-of-Thoughts (CoT) learning to improve LLM mathematical reasoning. Motivated by the observation that adding more concise CoT examples in the prompt can improve LLM reasoning performance, CoT-Influx employs a coarse-to-fine pruner to maximize the input of effective and concise CoT examples. The pruner first selects as many crucial CoT examples as possible and then prunes unimportant tokens to fit the context window. A math reasoning dataset with diverse difficulty levels and reasoning steps is used to train the pruner, along with a math-specialized reinforcement learning approach. As a result, by enabling more CoT examples with double the context window size in tokens, CoT-Influx significantly outperforms various prompting bas",
    "link": "https://arxiv.org/abs/2312.08901",
    "context": "Title: Fewer is More: Boosting LLM Reasoning with Reinforced Context Pruning\nAbstract: arXiv:2312.08901v3 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) have shown impressive capabilities, yet they still struggle with math reasoning. In this work, we propose CoT-Influx, a novel approach that pushes the boundary of few-shot Chain-of-Thoughts (CoT) learning to improve LLM mathematical reasoning. Motivated by the observation that adding more concise CoT examples in the prompt can improve LLM reasoning performance, CoT-Influx employs a coarse-to-fine pruner to maximize the input of effective and concise CoT examples. The pruner first selects as many crucial CoT examples as possible and then prunes unimportant tokens to fit the context window. A math reasoning dataset with diverse difficulty levels and reasoning steps is used to train the pruner, along with a math-specialized reinforcement learning approach. As a result, by enabling more CoT examples with double the context window size in tokens, CoT-Influx significantly outperforms various prompting bas",
    "path": "papers/23/12/2312.08901.json",
    "total_tokens": 896,
    "translated_title": "更少即更多：通过强化上下文修剪提升LLM推理能力",
    "translated_abstract": "大型语言模型（LLM）展现了令人印象深刻的能力，但在数学推理方面仍存在困难。在这项工作中，我们提出了CoT-Influx，一种将少样本链式思维（CoT）学习推向极限以改善LLM数学推理能力的新方法。由于观察到在提示中添加更简明的CoT示例可以提高LLM推理表现，CoT-Influx采用了一种从粗糙到精细的修剪器来最大化有效和简明的CoT示例的输入。修剪器首先选择尽可能多的关键CoT示例，然后修剪无关紧要的标记以适应上下文窗口。使用难度级别和推理步骤多样的数学推理数据集来训练修剪器，同时采用了专门针对数学的强化学习方法。结果是，通过在令牌中启用双倍上下文窗口大小的CoT示例，CoT-Influx在各种提示基准方法上表现显著优于其他方法。",
    "tldr": "CoT-Influx是一种通过强化上下文修剪来提升LLM数学推理能力的方法，通过最大化有效和简明的示例输入，显著优于其他提示方法。",
    "en_tdlr": "CoT-Influx is a method that improves LLM mathematical reasoning by reinforcing context pruning, achieving significantly better performance than other prompting methods by maximizing the input of effective and concise examples."
}