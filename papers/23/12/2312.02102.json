{
    "title": "Mitigating Data Injection Attacks on Federated Learning. (arXiv:2312.02102v3 [cs.LG] UPDATED)",
    "abstract": "Federated learning is a technique that allows multiple entities to collaboratively train models using their data without compromising data privacy. However, despite its advantages, federated learning can be susceptible to false data injection attacks. In these scenarios, a malicious entity with control over specific agents in the network can manipulate the learning process, leading to a suboptimal model. Consequently, addressing these data injection attacks presents a significant research challenge in federated learning systems. In this paper, we propose a novel technique to detect and mitigate data injection attacks on federated learning systems. Our mitigation method is a local scheme, performed during a single instance of training by the coordinating node, allowing the mitigation during the convergence of the algorithm. Whenever an agent is suspected to be an attacker, its data will be ignored for a certain period, this decision will often be re-evaluated. We prove that with probabi",
    "link": "http://arxiv.org/abs/2312.02102",
    "context": "Title: Mitigating Data Injection Attacks on Federated Learning. (arXiv:2312.02102v3 [cs.LG] UPDATED)\nAbstract: Federated learning is a technique that allows multiple entities to collaboratively train models using their data without compromising data privacy. However, despite its advantages, federated learning can be susceptible to false data injection attacks. In these scenarios, a malicious entity with control over specific agents in the network can manipulate the learning process, leading to a suboptimal model. Consequently, addressing these data injection attacks presents a significant research challenge in federated learning systems. In this paper, we propose a novel technique to detect and mitigate data injection attacks on federated learning systems. Our mitigation method is a local scheme, performed during a single instance of training by the coordinating node, allowing the mitigation during the convergence of the algorithm. Whenever an agent is suspected to be an attacker, its data will be ignored for a certain period, this decision will often be re-evaluated. We prove that with probabi",
    "path": "papers/23/12/2312.02102.json",
    "total_tokens": 885,
    "translated_title": "缓解联邦学习中的数据注入攻击",
    "translated_abstract": "联邦学习是一种允许多个实体在不损害数据隐私的情况下，共同训练模型的技术。然而，尽管有其优势，联邦学习容易受到虚假数据注入攻击的影响。在这种情况下，具有对网络中特定代理的控制权的恶意实体可以操纵学习过程，导致模型性能下降。因此，在联邦学习系统中解决这些数据注入攻击是一个重要的研究挑战。本文提出了一种新的技术来检测和缓解联邦学习系统中的数据注入攻击。我们的缓解方法是一种局部方案，在协调节点的单个训练实例中执行，允许在算法收敛期间进行缓解。每当怀疑某个代理是攻击者时，会在一定时间内忽略其数据，此决策经常被重新评估。我们证明概率上能够实现缓解攻击。",
    "tldr": "本文提出了一种新的技术来检测和缓解联邦学习系统中的数据注入攻击，通过在训练过程中忽略被怀疑为攻击者的代理的数据来提高模型的性能。"
}