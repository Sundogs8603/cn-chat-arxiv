{
    "title": "FreqFed: A Frequency Analysis-Based Approach for Mitigating Poisoning Attacks in Federated Learning. (arXiv:2312.04432v2 [cs.CR] UPDATED)",
    "abstract": "Federated learning (FL) is a collaborative learning paradigm allowing multiple clients to jointly train a model without sharing their training data. However, FL is susceptible to poisoning attacks, in which the adversary injects manipulated model updates into the federated model aggregation process to corrupt or destroy predictions (untargeted poisoning) or implant hidden functionalities (targeted poisoning or backdoors). Existing defenses against poisoning attacks in FL have several limitations, such as relying on specific assumptions about attack types and strategies or data distributions or not sufficiently robust against advanced injection techniques and strategies and simultaneously maintaining the utility of the aggregated model. To address the deficiencies of existing defenses, we take a generic and completely different approach to detect poisoning (targeted and untargeted) attacks. We present FreqFed, a novel aggregation mechanism that transforms the model updates (i.e., weight",
    "link": "http://arxiv.org/abs/2312.04432",
    "context": "Title: FreqFed: A Frequency Analysis-Based Approach for Mitigating Poisoning Attacks in Federated Learning. (arXiv:2312.04432v2 [cs.CR] UPDATED)\nAbstract: Federated learning (FL) is a collaborative learning paradigm allowing multiple clients to jointly train a model without sharing their training data. However, FL is susceptible to poisoning attacks, in which the adversary injects manipulated model updates into the federated model aggregation process to corrupt or destroy predictions (untargeted poisoning) or implant hidden functionalities (targeted poisoning or backdoors). Existing defenses against poisoning attacks in FL have several limitations, such as relying on specific assumptions about attack types and strategies or data distributions or not sufficiently robust against advanced injection techniques and strategies and simultaneously maintaining the utility of the aggregated model. To address the deficiencies of existing defenses, we take a generic and completely different approach to detect poisoning (targeted and untargeted) attacks. We present FreqFed, a novel aggregation mechanism that transforms the model updates (i.e., weight",
    "path": "papers/23/12/2312.04432.json",
    "total_tokens": 883,
    "translated_title": "FreqFed:一种基于频谱分析的方法用于减轻联邦学习中的毒化攻击",
    "translated_abstract": "联邦学习 (FL) 是一种协作学习范 Paradigm，允许多个客户端在不共享训练数据的情况下共同训练模型。然而，FL 容易受到毒化攻击的影响，攻击者通过将篡改的模型更新插入联邦模型聚合过程中来破坏或破坏预测（无目标毒化），或者 implant (targeted poisoning or backdoors) 隐含的功能。针对 FL 中的毒化攻击，现有的防御措施存在多种限制，比如依赖于对攻击类型、策略或数据分布的特定假设，或者在高级注入技术和策略方面不够强大, 且同时保持聚合模型的效用。为了解决现有防御措施的不足，我们采用了一种通用且完全不同的方法来检测针对性和非针对性的毒化攻击。我们提出了 FreqFed，一种新的聚合机制，用于将模型更新（即权重）",
    "tldr": "FreqFed是一种基于频谱分析的新方法，用于检测和减轻联邦学习中的针对性和非针对性的毒化攻击。"
}