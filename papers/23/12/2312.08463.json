{
    "title": "How much can change in a year? Revisiting Evaluation in Multi-Agent Reinforcement Learning. (arXiv:2312.08463v2 [cs.AI] UPDATED)",
    "abstract": "Establishing sound experimental standards and rigour is important in any growing field of research. Deep Multi-Agent Reinforcement Learning (MARL) is one such nascent field. Although exciting progress has been made, MARL has recently come under scrutiny for replicability issues and a lack of standardised evaluation methodology, specifically in the cooperative setting. Although protocols have been proposed to help alleviate the issue, it remains important to actively monitor the health of the field. In this work, we extend the database of evaluation methodology previously published by containing meta-data on MARL publications from top-rated conferences and compare the findings extracted from this updated database to the trends identified in their work. Our analysis shows that many of the worrying trends in performance reporting remain. This includes the omission of uncertainty quantification, not reporting all relevant evaluation details and a narrowing of algorithmic development classe",
    "link": "http://arxiv.org/abs/2312.08463",
    "context": "Title: How much can change in a year? Revisiting Evaluation in Multi-Agent Reinforcement Learning. (arXiv:2312.08463v2 [cs.AI] UPDATED)\nAbstract: Establishing sound experimental standards and rigour is important in any growing field of research. Deep Multi-Agent Reinforcement Learning (MARL) is one such nascent field. Although exciting progress has been made, MARL has recently come under scrutiny for replicability issues and a lack of standardised evaluation methodology, specifically in the cooperative setting. Although protocols have been proposed to help alleviate the issue, it remains important to actively monitor the health of the field. In this work, we extend the database of evaluation methodology previously published by containing meta-data on MARL publications from top-rated conferences and compare the findings extracted from this updated database to the trends identified in their work. Our analysis shows that many of the worrying trends in performance reporting remain. This includes the omission of uncertainty quantification, not reporting all relevant evaluation details and a narrowing of algorithmic development classe",
    "path": "papers/23/12/2312.08463.json",
    "total_tokens": 906,
    "translated_title": "一年能发生多大变化？重访多智体强化学习中的评估",
    "translated_abstract": "在任何一个快速发展的研究领域中，建立 sound experimental standards 和 rigour 都是非常重要的。深度多智体强化学习（MARL）就是这样一个新兴领域。尽管取得了令人激动的进展，但MARL最近因为可复制性问题和缺乏标准化评估方法遭到了质疑，尤其是在合作设置中。虽然已经提出了一些协议来帮助缓解这个问题，但积极监测该领域的健康状况仍然是重要的。在本研究中，我们扩展了之前所发表的关于评估方法的数据库，其中包含了来自顶级会议的MARL出版物的元数据，并将从此更新后的数据库中提取的发现与他们的工作中确定的趋势进行比较。我们的分析表明，许多令人担忧的性能报告趋势仍然存在。这包括省略不确定性量化，不报告所有相关的评估细节以及算法开发类别的收窄。",
    "tldr": "本文重访了多智体强化学习（MARL）领域的评估问题，并扩展了之前的数据库，发现许多令人担忧的性能报告趋势仍然存在。",
    "en_tdlr": "This paper revisits the evaluation issues in the field of Multi-Agent Reinforcement Learning (MARL) and expands the previous database, revealing the persistence of worrisome trends in performance reporting."
}