{
    "title": "How Many Validation Labels Do You Need? Exploring the Design Space of Label-Efficient Model Ranking",
    "abstract": "arXiv:2312.01619v3 Announce Type: replace  Abstract: This paper presents LEMR (Label-Efficient Model Ranking) and introduces the MoraBench Benchmark. LEMR is a novel framework that minimizes the need for costly annotations in model selection by strategically annotating instances from an unlabeled validation set. To evaluate LEMR, we leverage the MoraBench Benchmark, a comprehensive collection of model outputs across diverse scenarios. Our extensive evaluation across 23 different NLP tasks in semi-supervised learning, weak supervision, and prompt selection tasks demonstrates LEMR's effectiveness in significantly reducing labeling costs. Key findings highlight the impact of suitable ensemble methods, uncertainty sampling strategies, and model committee selection in enhancing model ranking accuracy. LEMR, supported by the insights from MoraBench, provides a cost-effective and accurate solution for model selection, especially valuable in resource-constrained environments.",
    "link": "https://arxiv.org/abs/2312.01619",
    "context": "Title: How Many Validation Labels Do You Need? Exploring the Design Space of Label-Efficient Model Ranking\nAbstract: arXiv:2312.01619v3 Announce Type: replace  Abstract: This paper presents LEMR (Label-Efficient Model Ranking) and introduces the MoraBench Benchmark. LEMR is a novel framework that minimizes the need for costly annotations in model selection by strategically annotating instances from an unlabeled validation set. To evaluate LEMR, we leverage the MoraBench Benchmark, a comprehensive collection of model outputs across diverse scenarios. Our extensive evaluation across 23 different NLP tasks in semi-supervised learning, weak supervision, and prompt selection tasks demonstrates LEMR's effectiveness in significantly reducing labeling costs. Key findings highlight the impact of suitable ensemble methods, uncertainty sampling strategies, and model committee selection in enhancing model ranking accuracy. LEMR, supported by the insights from MoraBench, provides a cost-effective and accurate solution for model selection, especially valuable in resource-constrained environments.",
    "path": "papers/23/12/2312.01619.json",
    "total_tokens": 868,
    "translated_title": "你需要多少验证标签？探索标签高效模型排名的设计空间",
    "translated_abstract": "本文提出了LEMR（标签高效模型排名）并介绍了MoraBench基准测试。LEMR是一个新颖的框架，通过从未标记的验证集中策略性地标注实例，最大程度地减少了在模型选择中昂贵注释的需求。为了评估LEMR，我们利用了MoraBench基准测试，这是一个涵盖了多种场景的模型输出的综合收集。我们在半监督学习、弱监督和提示选择任务的23个不同自然语言处理任务上进行了广泛评估，结果表明LEMR在显著降低标注成本方面的有效性。关键发现突出了合适的集成方法、不确定性采样策略和模型委员会选择对提高模型排名准确性的影响。LEMR结合了MoraBench的见解，为模型选择提供了一种成本效益高且准确的解决方案，特别适用于资源受限环境。",
    "tldr": "LEMR框架通过在未标记的验证集中策略性地标注实例，显著降低了模型选择中的标注成本，并在各种NLP任务中展现了其高效性。",
    "en_tdlr": "The LEMR framework minimizes the need for costly annotations in model selection by strategically annotating instances from an unlabeled validation set, demonstrating its effectiveness across various NLP tasks."
}