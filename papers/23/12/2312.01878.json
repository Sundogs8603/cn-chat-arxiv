{
    "title": "HGPROMPT: Bridging Homogeneous and Heterogeneous Graphs for Few-shot Prompt Learning. (arXiv:2312.01878v5 [cs.LG] UPDATED)",
    "abstract": "Graph neural networks (GNNs) and heterogeneous graph neural networks (HGNNs) are prominent techniques for homogeneous and heterogeneous graph representation learning, yet their performance in an end-to-end supervised framework greatly depends on the availability of task-specific supervision. To reduce the labeling cost, pre-training on self-supervised pretext tasks has become a popular paradigm,but there is often a gap between the pre-trained model and downstream tasks, stemming from the divergence in their objectives. To bridge the gap, prompt learning has risen as a promising direction especially in few-shot settings, without the need to fully fine-tune the pre-trained model. While there has been some early exploration of prompt-based learning on graphs, they primarily deal with homogeneous graphs, ignoring the heterogeneous graphs that are prevalent in downstream applications. In this paper, we propose HGPROMPT, a novel pre-training and prompting framework to unify not only pre-trai",
    "link": "http://arxiv.org/abs/2312.01878",
    "context": "Title: HGPROMPT: Bridging Homogeneous and Heterogeneous Graphs for Few-shot Prompt Learning. (arXiv:2312.01878v5 [cs.LG] UPDATED)\nAbstract: Graph neural networks (GNNs) and heterogeneous graph neural networks (HGNNs) are prominent techniques for homogeneous and heterogeneous graph representation learning, yet their performance in an end-to-end supervised framework greatly depends on the availability of task-specific supervision. To reduce the labeling cost, pre-training on self-supervised pretext tasks has become a popular paradigm,but there is often a gap between the pre-trained model and downstream tasks, stemming from the divergence in their objectives. To bridge the gap, prompt learning has risen as a promising direction especially in few-shot settings, without the need to fully fine-tune the pre-trained model. While there has been some early exploration of prompt-based learning on graphs, they primarily deal with homogeneous graphs, ignoring the heterogeneous graphs that are prevalent in downstream applications. In this paper, we propose HGPROMPT, a novel pre-training and prompting framework to unify not only pre-trai",
    "path": "papers/23/12/2312.01878.json",
    "total_tokens": 913,
    "translated_title": "HGPROMPT: 少样本提示学习中用于连接同质和异质图的方法",
    "translated_abstract": "图神经网络（GNNs）和异质图神经网络（HGNNs）是同质和异质图表示学习的重要技术，然而它们在端到端的监督框架中的性能很大程度上取决于任务特定监督的可用性。为了减少标注成本，对自我监督预训练的研究成为一种流行的范式，但是预训练模型和下游任务之间常常存在差距，导致目标的不一致。为了弥合这个差距，提示学习作为一种有前景的方法在少样本设置下正在崛起，而不需要对预训练模型进行完全微调。虽然早期已经对图上基于提示的学习进行了一些探索，但它们主要涉及同质图，忽略了在下游应用中普遍存在的异质图。在本文中，我们提出了HGPROMPT，一种新颖的预训练和提示框架，以统一预先训练的同质和异质图，以实现更好的性能提升。",
    "tldr": "此论文提出了一种名为HGPROMPT的方法，用于连接同质和异质图，在少样本设置下进行提示学习，并通过预训练的同质和异质图来提高性能。",
    "en_tdlr": "This paper proposes a method called HGPROMPT, which bridges homogeneous and heterogeneous graphs for few-shot prompt learning, and improves performance by pre-training on both types of graphs."
}