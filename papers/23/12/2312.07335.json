{
    "title": "Momentum Particle Maximum Likelihood",
    "abstract": "Maximum likelihood estimation (MLE) of latent variable models is often recast as an optimization problem over the extended space of parameters and probability distributions. For example, the Expectation Maximization (EM) algorithm can be interpreted as coordinate descent applied to a suitable free energy functional over this space. Recently, this perspective has been combined with insights from optimal transport and Wasserstein gradient flows to develop particle-based algorithms applicable to wider classes of models than standard EM.   Drawing inspiration from prior works which interpret `momentum-enriched' optimisation algorithms as discretizations of ordinary differential equations, we propose an analogous dynamical systems-inspired approach to minimizing the free energy functional over the extended space of parameters and probability distributions. The result is a dynamic system that blends elements of Nesterov's Accelerated Gradient method, the underdamped Langevin diffusion, and p",
    "link": "https://arxiv.org/abs/2312.07335",
    "context": "Title: Momentum Particle Maximum Likelihood\nAbstract: Maximum likelihood estimation (MLE) of latent variable models is often recast as an optimization problem over the extended space of parameters and probability distributions. For example, the Expectation Maximization (EM) algorithm can be interpreted as coordinate descent applied to a suitable free energy functional over this space. Recently, this perspective has been combined with insights from optimal transport and Wasserstein gradient flows to develop particle-based algorithms applicable to wider classes of models than standard EM.   Drawing inspiration from prior works which interpret `momentum-enriched' optimisation algorithms as discretizations of ordinary differential equations, we propose an analogous dynamical systems-inspired approach to minimizing the free energy functional over the extended space of parameters and probability distributions. The result is a dynamic system that blends elements of Nesterov's Accelerated Gradient method, the underdamped Langevin diffusion, and p",
    "path": "papers/23/12/2312.07335.json",
    "total_tokens": 812,
    "translated_title": "动量粒子最大似然",
    "translated_abstract": "最大似然估计(MLE)的潜变量模型通常被重新解释为在参数和概率分布的扩展空间上的优化问题。例如，期望最大化(EM)算法可以解释为在这个空间上适用于合适的自由能函数的坐标下降。最近，这个观点与从最优传输和Wasserstein梯度流中获得的启示相结合，发展出了适用于更广泛模型类的基于粒子的算法，而不是标准的EM。受先前论文的启发，将将动量丰富的优化算法解释为常微分方程的离散化，我们提出了一种类似的动态系统方法，用于最小化在参数和概率分布的扩展空间上的自由能函数。结果是一个动态系统，结合了Nesterov的加速梯度方法、欠阻尼Langevin扩散和p。",
    "tldr": "该论文提出了一种动态系统方法，用于在参数和概率分布的扩展空间上最小化自由能函数，该方法融合了Nesterov的加速梯度方法、欠阻尼Langevin扩散和p。"
}