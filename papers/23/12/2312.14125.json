{
    "title": "VideoPoet: A Large Language Model for Zero-Shot Video Generation",
    "abstract": "arXiv:2312.14125v2 Announce Type: replace-cross  Abstract: We present VideoPoet, a language model capable of synthesizing high-quality video, with matching audio, from a large variety of conditioning signals. VideoPoet employs a decoder-only transformer architecture that processes multimodal inputs -- including images, videos, text, and audio. The training protocol follows that of Large Language Models (LLMs), consisting of two stages: pretraining and task-specific adaptation. During pretraining, VideoPoet incorporates a mixture of multimodal generative objectives within an autoregressive Transformer framework. The pretrained LLM serves as a foundation that can be adapted for a range of video generation tasks. We present empirical results demonstrating the model's state-of-the-art capabilities in zero-shot video generation, specifically highlighting VideoPoet's ability to generate high-fidelity motions. Project page: http://sites.research.google/videopoet/",
    "link": "https://arxiv.org/abs/2312.14125",
    "context": "Title: VideoPoet: A Large Language Model for Zero-Shot Video Generation\nAbstract: arXiv:2312.14125v2 Announce Type: replace-cross  Abstract: We present VideoPoet, a language model capable of synthesizing high-quality video, with matching audio, from a large variety of conditioning signals. VideoPoet employs a decoder-only transformer architecture that processes multimodal inputs -- including images, videos, text, and audio. The training protocol follows that of Large Language Models (LLMs), consisting of two stages: pretraining and task-specific adaptation. During pretraining, VideoPoet incorporates a mixture of multimodal generative objectives within an autoregressive Transformer framework. The pretrained LLM serves as a foundation that can be adapted for a range of video generation tasks. We present empirical results demonstrating the model's state-of-the-art capabilities in zero-shot video generation, specifically highlighting VideoPoet's ability to generate high-fidelity motions. Project page: http://sites.research.google/videopoet/",
    "path": "papers/23/12/2312.14125.json",
    "total_tokens": 798,
    "translated_title": "VideoPoet：用于零样本视频生成的大型语言模型",
    "translated_abstract": "我们提出了VideoPoet，这是一种能够从各种不同的条件信号中合成高质量视频及匹配音频的语言模型。VideoPoet采用解码器-仅Transformer架构，可以处理多模态输入，包括图像、视频、文本和音频。训练协议遵循大型语言模型（LLMs）的方式，包括两个阶段：预训练和特定任务的适应。在预训练阶段，VideoPoet在自回归Transformer框架中结合了多模态生成目标的混合。预训练的LLM作为一个基础，可以为各种视频生成任务进行调整。我们展示了实证结果，展示了该模型在零样本视频生成方面的最新能力，特别突出了VideoPoet生成高保真运动的能力。",
    "tldr": "VideoPoet是一种大型语言模型，能够从多种条件信号中生成高质量视频及匹配音频，并且在零样本视频生成领域展示了最先进的能力。",
    "en_tdlr": "VideoPoet is a large language model capable of generating high-quality videos with matching audio from a variety of conditioning signals, and it demonstrates state-of-the-art capabilities in zero-shot video generation."
}