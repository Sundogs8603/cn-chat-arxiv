{
    "title": "Large Language Models as Zero-Shot Keyphrase Extractors: A Preliminary Empirical Study. (arXiv:2312.15156v2 [cs.CL] UPDATED)",
    "abstract": "Zero-shot keyphrase extraction aims to build a keyphrase extractor without training by human-annotated data, which is challenging due to the limited human intervention involved. Challenging but worthwhile, zero-shot setting efficiently reduces the time and effort that data labeling takes. Recent efforts on pre-trained large language models (e.g., ChatGPT and ChatGLM) show promising performance on zero-shot settings, thus inspiring us to explore prompt-based methods. In this paper, we ask whether strong keyphrase extraction models can be constructed by directly prompting the large language model ChatGPT. Through experimental results, it is found that ChatGPT still has a lot of room for improvement in the keyphrase extraction task compared to existing state-of-the-art unsupervised and supervised models.",
    "link": "http://arxiv.org/abs/2312.15156",
    "context": "Title: Large Language Models as Zero-Shot Keyphrase Extractors: A Preliminary Empirical Study. (arXiv:2312.15156v2 [cs.CL] UPDATED)\nAbstract: Zero-shot keyphrase extraction aims to build a keyphrase extractor without training by human-annotated data, which is challenging due to the limited human intervention involved. Challenging but worthwhile, zero-shot setting efficiently reduces the time and effort that data labeling takes. Recent efforts on pre-trained large language models (e.g., ChatGPT and ChatGLM) show promising performance on zero-shot settings, thus inspiring us to explore prompt-based methods. In this paper, we ask whether strong keyphrase extraction models can be constructed by directly prompting the large language model ChatGPT. Through experimental results, it is found that ChatGPT still has a lot of room for improvement in the keyphrase extraction task compared to existing state-of-the-art unsupervised and supervised models.",
    "path": "papers/23/12/2312.15156.json",
    "total_tokens": 850,
    "translated_title": "作为零-shot关键词提取器的大型语言模型：一项初步的实证研究",
    "translated_abstract": "零-shot关键词提取旨在通过没有人工标注数据的训练来构建关键词提取器，这是一项具有挑战性的任务，因为其中涉及到的人工干预有限。零-shot设置能够高效减少数据标注所需的时间和工作量，因此具有挑战但值得研究。最近，关于预训练的大型语言模型（例如ChatGPT和ChatGLM）在零-shot设置上展现出了有希望的性能，这激发了我们探索基于提示的方法。本文探讨了是否可以通过直接向大型语言模型ChatGPT发出提示来构建强大的关键词提取模型。实验结果发现，与现有最先进的无监督和有监督模型相比，ChatGPT在关键词提取任务中仍有很大的改进空间。",
    "tldr": "该论文探讨了使用大型语言模型ChatGPT作为零-shot关键词提取器的可行性。实验证明，在关键词提取任务中，ChatGPT相对于现有的无监督和有监督模型仍有许多改进空间。",
    "en_tdlr": "This paper investigates the feasibility of using the large language model ChatGPT as a zero-shot keyphrase extractor. Experimental results demonstrate that there is still much room for improvement for ChatGPT in the keyphrase extraction task compared to existing unsupervised and supervised models."
}