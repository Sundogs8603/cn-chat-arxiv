{
    "title": "Divide-and-Conquer Attack: Harnessing the Power of LLM to Bypass Safety Filters of Text-to-Image Models",
    "abstract": "Text-to-image (TTI) models offer many innovative services but also raise ethical concerns due to their potential to generate unethical images. Most public TTI services employ safety filters to prevent unintended images. In this work, we introduce the Divide-and-Conquer Attack to circumvent the safety filters of state-of the-art TTI models, including DALL-E 3 and Midjourney. Our attack leverages LLMs as text transformation agents to create adversarial prompts. We design attack helper prompts that effectively guide LLMs to break down an unethical drawing intent into multiple benign descriptions of individual image elements, allowing them to bypass safety filters while still generating unethical images. Because the latent harmful meaning only becomes apparent when all individual elements are drawn together. Our evaluation demonstrates that our attack successfully circumvents multiple strong closed-box safety filters. The comprehensive success rate of DACA bypassing the safety filters of t",
    "link": "https://arxiv.org/abs/2312.07130",
    "context": "Title: Divide-and-Conquer Attack: Harnessing the Power of LLM to Bypass Safety Filters of Text-to-Image Models\nAbstract: Text-to-image (TTI) models offer many innovative services but also raise ethical concerns due to their potential to generate unethical images. Most public TTI services employ safety filters to prevent unintended images. In this work, we introduce the Divide-and-Conquer Attack to circumvent the safety filters of state-of the-art TTI models, including DALL-E 3 and Midjourney. Our attack leverages LLMs as text transformation agents to create adversarial prompts. We design attack helper prompts that effectively guide LLMs to break down an unethical drawing intent into multiple benign descriptions of individual image elements, allowing them to bypass safety filters while still generating unethical images. Because the latent harmful meaning only becomes apparent when all individual elements are drawn together. Our evaluation demonstrates that our attack successfully circumvents multiple strong closed-box safety filters. The comprehensive success rate of DACA bypassing the safety filters of t",
    "path": "papers/23/12/2312.07130.json",
    "total_tokens": 1010,
    "translated_title": "利用LLM绕过文本到图像模型的安全过滤器的分而治之攻击",
    "translated_abstract": "文本到图像（TTI）模型提供许多创新服务，但也引发了道义关切，因为它们有潜力生成不道德的图像。大多数公共TTI服务采用安全过滤器来防止意外图像的生成。在本研究中，我们引入了分而治之攻击，以绕过最先进的TTI模型（包括DALL-E 3和Midjourney）的安全过滤器。我们的攻击利用LLMs作为文本转换代理来创建对抗性提示。我们设计了攻击辅助提示，有效地引导LLMs将不道德的绘图意图分解为多个个体图像元素的良性描述，从而使它们能够绕过安全过滤器，同时生成不道德的图像。因为只有当所有个体元素都被绘制在一起时，潜在的有害含义才会显现出来。我们的评估表明，我们的攻击成功地绕过了多个强大的封闭式安全过滤器。",
    "tldr": "该论文介绍了一种称为分而治之攻击的方法，利用LLM作为文本转换代理绕过文本到图像模型的安全过滤器。该攻击设计了攻击辅助提示，引导LLM将不道德的绘图意图分解为多个个体图像元素的良性描述，以绕过安全过滤器生成不道德的图像。实验结果表明，该攻击成功地绕过了多个强大的封闭式安全过滤器。",
    "en_tdlr": "This paper introduces a method called Divide-and-Conquer Attack that leverages LLM as a text transformation agent to bypass safety filters of text-to-image models. The attack designs helper prompts that guide LLM to break down unethical drawing intent into benign descriptions of individual image elements, allowing the generation of unethical images while bypassing safety filters. The evaluation demonstrates the success of the attack in circumventing multiple strong closed-box safety filters."
}