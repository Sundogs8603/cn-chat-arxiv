{
    "title": "FoundationPose: Unified 6D Pose Estimation and Tracking of Novel Objects",
    "abstract": "arXiv:2312.08344v2 Announce Type: replace-cross  Abstract: We present FoundationPose, a unified foundation model for 6D object pose estimation and tracking, supporting both model-based and model-free setups. Our approach can be instantly applied at test-time to a novel object without fine-tuning, as long as its CAD model is given, or a small number of reference images are captured. We bridge the gap between these two setups with a neural implicit representation that allows for effective novel view synthesis, keeping the downstream pose estimation modules invariant under the same unified framework. Strong generalizability is achieved via large-scale synthetic training, aided by a large language model (LLM), a novel transformer-based architecture, and contrastive learning formulation. Extensive evaluation on multiple public datasets involving challenging scenarios and objects indicate our unified approach outperforms existing methods specialized for each task by a large margin. In additi",
    "link": "https://arxiv.org/abs/2312.08344",
    "context": "Title: FoundationPose: Unified 6D Pose Estimation and Tracking of Novel Objects\nAbstract: arXiv:2312.08344v2 Announce Type: replace-cross  Abstract: We present FoundationPose, a unified foundation model for 6D object pose estimation and tracking, supporting both model-based and model-free setups. Our approach can be instantly applied at test-time to a novel object without fine-tuning, as long as its CAD model is given, or a small number of reference images are captured. We bridge the gap between these two setups with a neural implicit representation that allows for effective novel view synthesis, keeping the downstream pose estimation modules invariant under the same unified framework. Strong generalizability is achieved via large-scale synthetic training, aided by a large language model (LLM), a novel transformer-based architecture, and contrastive learning formulation. Extensive evaluation on multiple public datasets involving challenging scenarios and objects indicate our unified approach outperforms existing methods specialized for each task by a large margin. In additi",
    "path": "papers/23/12/2312.08344.json",
    "total_tokens": 844,
    "translated_title": "FoundationPose: 统一的新物体6D姿势估计和跟踪",
    "translated_abstract": "我们提出了FoundationPose，这是一个统一的基础模型，用于6D物体姿势估计和跟踪，支持基于模型和无模型的设置。我们的方法可以在测试时立即应用于新物体，无需微调，只要给出其CAD模型，或者捕获少量参考图像。我们通过神经隐式表示来弥合这两种设置之间的差距，该表示允许有效的新视图合成，并使下游姿势估计模块在相同统一框架下保持不变。通过大规模合成训练、大型语言模型（LLM）、一种新颖的基于transformer的架构以及对比学习公式，我们实现了强大的泛化能力。在涉及挑战性场景和物体的多个公共数据集上进行的广泛评估表明，我们的统一方法在很大程度上优于专门针对每个任务的现有方法。",
    "tldr": "提出了FoundationPose，一个统一的基础模型，支持新物体的6D姿势估计和跟踪，通过神经隐式表示和大规模训练实现了强大的泛化能力。",
    "en_tdlr": "Introduced FoundationPose, a unified foundational model for 6D object pose estimation and tracking of novel objects, achieving strong generalizability through neural implicit representation and large-scale training."
}