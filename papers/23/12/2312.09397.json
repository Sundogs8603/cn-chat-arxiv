{
    "title": "Large Language Models for Autonomous Driving: Real-World Experiments",
    "abstract": "Autonomous driving systems are increasingly popular in today's technological landscape, where vehicles with partial automation have already been widely available on the market, and the full automation era with \"driverless\" capabilities is near the horizon. However, accurately understanding humans' commands, particularly for autonomous vehicles that have only passengers instead of drivers, and achieving a high level of personalization remain challenging tasks in the development of autonomous driving systems. In this paper, we introduce a Large Language Model (LLM)-based framework Talk-to-Drive (Talk2Drive) to process verbal commands from humans and make autonomous driving decisions with contextual information, satisfying their personalized preferences for safety, efficiency, and comfort. First, a speech recognition module is developed for Talk2Drive to interpret verbal inputs from humans to textual instructions, which are then sent to LLMs for reasoning. Then, appropriate commands for t",
    "link": "https://arxiv.org/abs/2312.09397",
    "context": "Title: Large Language Models for Autonomous Driving: Real-World Experiments\nAbstract: Autonomous driving systems are increasingly popular in today's technological landscape, where vehicles with partial automation have already been widely available on the market, and the full automation era with \"driverless\" capabilities is near the horizon. However, accurately understanding humans' commands, particularly for autonomous vehicles that have only passengers instead of drivers, and achieving a high level of personalization remain challenging tasks in the development of autonomous driving systems. In this paper, we introduce a Large Language Model (LLM)-based framework Talk-to-Drive (Talk2Drive) to process verbal commands from humans and make autonomous driving decisions with contextual information, satisfying their personalized preferences for safety, efficiency, and comfort. First, a speech recognition module is developed for Talk2Drive to interpret verbal inputs from humans to textual instructions, which are then sent to LLMs for reasoning. Then, appropriate commands for t",
    "path": "papers/23/12/2312.09397.json",
    "total_tokens": 895,
    "translated_title": "用于自动驾驶的大规模语言模型：真实世界实验",
    "translated_abstract": "自动驾驶系统在当今的技术领域日益流行，部分自动化的车辆已经在市场上广泛流通，具备完全自动化和“无人驾驶”能力的时代已经迫在眉睫。然而，准确理解人类的指令，特别是对于只有乘客而没有驾驶员的自动驾驶汽车来说，实现高度个性化仍然是自动驾驶系统开发中的挑战任务。在本文中，我们介绍了一个基于大规模语言模型（LLM）的框架Talk-to-Drive（Talk2Drive），以处理来自人类的口头指令，并根据上下文信息做出自动驾驶决策，满足他们对安全性、效率性和舒适性的个性化偏好。首先，我们开发了一个语音识别模块，用于将人类的口头输入转化为文本指令，然后将这些指令发送给LLMs进行推理。然后，适当的指令被发送给实际的汽车控制系统，进一步实现自动驾驶。",
    "tldr": "该论文介绍了一个基于大规模语言模型的自动驾驶框架，名为Talk2Drive，用于处理来自人类的口头指令，并根据上下文信息实现自动驾驶决策，满足个性化偏好。",
    "en_tdlr": "This paper introduces a Large Language Model-based framework called Talk2Drive for autonomous driving, which processes verbal commands from humans and makes driving decisions based on contextual information, satisfying personalized preferences."
}