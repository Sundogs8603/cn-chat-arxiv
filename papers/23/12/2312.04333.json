{
    "title": "Is Bigger and Deeper Always Better? Probing LLaMA Across Scales and Layers. (arXiv:2312.04333v4 [cs.CL] UPDATED)",
    "abstract": "This paper presents an in-depth analysis of Large Language Models (LLMs), focusing on LLaMA, a prominent open-source foundational model in natural language processing. Instead of assessing LLaMA through its generative output, we design multiple-choice tasks to probe its intrinsic understanding in high-order tasks such as reasoning and computation. We examine the model horizontally, comparing different sizes, and vertically, assessing different layers. We unveil several key and uncommon findings based on the designed probing tasks: (1) Horizontally, enlarging model sizes almost could not automatically impart additional knowledge or computational prowess. Instead, it can enhance reasoning abilities, especially in math problem solving, and helps reduce hallucinations, but only beyond certain size thresholds; (2) In vertical analysis, the lower layers of LLaMA lack substantial arithmetic and factual knowledge, showcasing logical thinking, multilingual and recognitive abilities, with top la",
    "link": "http://arxiv.org/abs/2312.04333",
    "context": "Title: Is Bigger and Deeper Always Better? Probing LLaMA Across Scales and Layers. (arXiv:2312.04333v4 [cs.CL] UPDATED)\nAbstract: This paper presents an in-depth analysis of Large Language Models (LLMs), focusing on LLaMA, a prominent open-source foundational model in natural language processing. Instead of assessing LLaMA through its generative output, we design multiple-choice tasks to probe its intrinsic understanding in high-order tasks such as reasoning and computation. We examine the model horizontally, comparing different sizes, and vertically, assessing different layers. We unveil several key and uncommon findings based on the designed probing tasks: (1) Horizontally, enlarging model sizes almost could not automatically impart additional knowledge or computational prowess. Instead, it can enhance reasoning abilities, especially in math problem solving, and helps reduce hallucinations, but only beyond certain size thresholds; (2) In vertical analysis, the lower layers of LLaMA lack substantial arithmetic and factual knowledge, showcasing logical thinking, multilingual and recognitive abilities, with top la",
    "path": "papers/23/12/2312.04333.json",
    "total_tokens": 1097,
    "translated_title": "大还是深是否总是好的？在不同尺度和层次上探究LLaMA。",
    "translated_abstract": "本文对大型语言模型（LLM）进行了深入分析，重点关注了LLaMA，这是一种在自然语言处理中非常重要的开源基础模型。我们通过设计多项选择任务来评估LLaMA在推理和计算等高阶任务中的内在理解能力，而不是通过其生成的输出来评估LLaMA。我们沿着水平方向对模型进行了比较，比较了不同的尺寸，然后沿着纵向方向评估了不同的层次。根据我们设计的探究任务，我们揭示了几个关键但不常见的发现：（1）在水平方面，增大模型尺寸几乎不能自动地增加额外的知识或计算能力。相反，它可以提高推理能力，特别是在数学问题解决方面，并有助于减少幻觉，但只有在超过某个尺寸门槛时才能实现；（2）在纵向分析中，LLaMA的较低层次缺乏实质性的算术和事实知识，展现了逻辑思维、多语言和识别能力，其顶层层次表现出较强的语言理解能力。",
    "tldr": "本文通过多项选择任务对LLaMA进行了深入分析，揭示了LLaMA在推理和计算等高阶任务中的内在理解能力。研究发现，增大模型尺寸几乎不能自动增加额外的知识或计算能力，但可以提高推理能力和减少幻觉，尤其在数学问题解决方面。此外，LLaMA的较低层次缺乏实质性的算术和事实知识，但顶层层次展现出较强的语言理解能力。",
    "en_tdlr": "This paper provides an in-depth analysis of LLaMA and its understanding in high-order tasks. The study reveals that enlarging model size does not automatically increase knowledge or computational abilities, but it enhances reasoning and reduces hallucinations, especially in math problem solving. Additionally, the lower layers of LLaMA lack substantial arithmetic and factual knowledge, while the top layers exhibit strong language comprehension abilities."
}