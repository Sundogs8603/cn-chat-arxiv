{
    "title": "Age-Based Scheduling for Mobile Edge Computing: A Deep Reinforcement Learning Approach",
    "abstract": "arXiv:2312.00279v2 Announce Type: replace  Abstract: With the rapid development of Mobile Edge Computing (MEC), various real-time applications have been deployed to benefit people's daily lives. The performance of these applications relies heavily on the freshness of collected environmental information, which can be quantified by its Age of Information (AoI). In the traditional definition of AoI, it is assumed that the status information can be actively sampled and directly used. However, for many MEC-enabled applications, the desired status information is updated in an event-driven manner and necessitates data processing. To better serve these applications, we propose a new definition of AoI and, based on the redefined AoI, we formulate an online AoI minimization problem for MEC systems. Notably, the problem can be interpreted as a Markov Decision Process (MDP), thus enabling its solution through Reinforcement Learning (RL) algorithms. Nevertheless, the traditional RL algorithms are d",
    "link": "https://arxiv.org/abs/2312.00279",
    "context": "Title: Age-Based Scheduling for Mobile Edge Computing: A Deep Reinforcement Learning Approach\nAbstract: arXiv:2312.00279v2 Announce Type: replace  Abstract: With the rapid development of Mobile Edge Computing (MEC), various real-time applications have been deployed to benefit people's daily lives. The performance of these applications relies heavily on the freshness of collected environmental information, which can be quantified by its Age of Information (AoI). In the traditional definition of AoI, it is assumed that the status information can be actively sampled and directly used. However, for many MEC-enabled applications, the desired status information is updated in an event-driven manner and necessitates data processing. To better serve these applications, we propose a new definition of AoI and, based on the redefined AoI, we formulate an online AoI minimization problem for MEC systems. Notably, the problem can be interpreted as a Markov Decision Process (MDP), thus enabling its solution through Reinforcement Learning (RL) algorithms. Nevertheless, the traditional RL algorithms are d",
    "path": "papers/23/12/2312.00279.json",
    "total_tokens": 855,
    "translated_title": "基于年龄的移动边缘计算调度：一种深度强化学习方法",
    "translated_abstract": "随着移动边缘计算（MEC）的快速发展，各种实时应用程序已经部署，造福于人们的日常生活。这些应用程序的性能在很大程度上取决于收集的环境信息的新鲜度，这可以通过其信息时代（AoI）来衡量。在传统AoI的定义中，假定状态信息可以被积极采样并直接使用。然而，对于许多MEC启用的应用程序，期望的状态信息以事件驱动的方式更新，并需要数据处理。为了更好地满足这些应用程序的需求，我们提出了一个新的AoI定义，并基于重新定义的AoI，为MEC系统制定了一个在线AoI最小化问题。值得注意的是，该问题可以被解释为马尔可夫决策过程（MDP），从而使其可以通过强化学习（RL）算法来解决。然而，传统的RL算法存在不足",
    "tldr": "基于深度强化学习的移动边缘计算调度方案提出了一种新的信息时代定义，通过最小化信息时代来改善应用程序性能。",
    "en_tdlr": "A new definition of Age of Information is proposed in the context of mobile edge computing, and a solution based on deep reinforcement learning is introduced to minimize the Age of Information for improved application performance."
}