{
    "title": "Retrieval-augmented Multi-modal Chain-of-Thoughts Reasoning for Large Language Models",
    "abstract": "arXiv:2312.01714v2 Announce Type: replace  Abstract: The advancement of Large Language Models (LLMs) has brought substantial attention to the Chain of Thought (CoT) approach, primarily due to its ability to enhance the capability of LLMs on complex reasoning tasks. Moreover, the significance of CoT approaches extends to the application of LLMs for multi-modal tasks. However, the selection of optimal CoT demonstration examples in multi-modal reasoning remains less explored for LLMs due to the inherent complexity of multi-modal examples. In this paper, we introduce a novel approach that addresses this challenge by using retrieval mechanisms to dynamically and automatically select demonstration examples based on cross-modal and intra-modal similarities. Furthermore, we employ a Stratified Sampling method of categorising demonstration examples into groups based on their types and then retrieving examples from different groups respectively to promote the diversity of demonstration examples.",
    "link": "https://arxiv.org/abs/2312.01714",
    "context": "Title: Retrieval-augmented Multi-modal Chain-of-Thoughts Reasoning for Large Language Models\nAbstract: arXiv:2312.01714v2 Announce Type: replace  Abstract: The advancement of Large Language Models (LLMs) has brought substantial attention to the Chain of Thought (CoT) approach, primarily due to its ability to enhance the capability of LLMs on complex reasoning tasks. Moreover, the significance of CoT approaches extends to the application of LLMs for multi-modal tasks. However, the selection of optimal CoT demonstration examples in multi-modal reasoning remains less explored for LLMs due to the inherent complexity of multi-modal examples. In this paper, we introduce a novel approach that addresses this challenge by using retrieval mechanisms to dynamically and automatically select demonstration examples based on cross-modal and intra-modal similarities. Furthermore, we employ a Stratified Sampling method of categorising demonstration examples into groups based on their types and then retrieving examples from different groups respectively to promote the diversity of demonstration examples.",
    "path": "papers/23/12/2312.01714.json",
    "total_tokens": 813,
    "translated_title": "大型语言模型的检索增强多模态思维链推理",
    "translated_abstract": "大型语言模型（LLMs）的进步引起了对思维链（CoT）方法的广泛关注，主要是因为它能够增强LLMs在复杂推理任务上的能力。此外，CoT方法的重要性延伸到LLMs在多模态任务上的应用。然而，在多模态推理中选择最佳的CoT演示示例对于LLMs仍然相对较少探索，这是由于多模态示例的固有复杂性。在本文中，我们通过使用检索机制来动态自动地选择基于跨模态和内模态相似性的演示示例，解决了这一挑战。此外，我们采用分层抽样方法将演示示例分类成不同类型的小组，然后分别从不同组中检索示例，以促进演示示例的多样性。",
    "tldr": "本文引入了一种新颖的方法，通过使用检索机制动态自动选择以跨模态和内模态相似性为基础的演示示例，以提高多模态推理中的大型语言模型的性能。",
    "en_tdlr": "This paper introduces a novel approach that improves the performance of Large Language Models in multi-modal reasoning by dynamically and automatically selecting demonstration examples based on cross-modal and intra-modal similarities through retrieval mechanisms."
}