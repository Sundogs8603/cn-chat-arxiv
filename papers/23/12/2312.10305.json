{
    "title": "Self-Supervised Disentangled Representation Learning for Robust Target Speech Extraction. (arXiv:2312.10305v2 [cs.SD] UPDATED)",
    "abstract": "Speech signals are inherently complex as they encompass both global acoustic characteristics and local semantic information. However, in the task of target speech extraction, certain elements of global and local semantic information in the reference speech, which are irrelevant to speaker identity, can lead to speaker confusion within the speech extraction network. To overcome this challenge, we propose a self-supervised disentangled representation learning method. Our approach tackles this issue through a two-phase process, utilizing a reference speech encoding network and a global information disentanglement network to gradually disentangle the speaker identity information from other irrelevant factors. We exclusively employ the disentangled speaker identity information to guide the speech extraction network. Moreover, we introduce the adaptive modulation Transformer to ensure that the acoustic representation of the mixed signal remains undisturbed by the speaker embeddings. This com",
    "link": "http://arxiv.org/abs/2312.10305",
    "context": "Title: Self-Supervised Disentangled Representation Learning for Robust Target Speech Extraction. (arXiv:2312.10305v2 [cs.SD] UPDATED)\nAbstract: Speech signals are inherently complex as they encompass both global acoustic characteristics and local semantic information. However, in the task of target speech extraction, certain elements of global and local semantic information in the reference speech, which are irrelevant to speaker identity, can lead to speaker confusion within the speech extraction network. To overcome this challenge, we propose a self-supervised disentangled representation learning method. Our approach tackles this issue through a two-phase process, utilizing a reference speech encoding network and a global information disentanglement network to gradually disentangle the speaker identity information from other irrelevant factors. We exclusively employ the disentangled speaker identity information to guide the speech extraction network. Moreover, we introduce the adaptive modulation Transformer to ensure that the acoustic representation of the mixed signal remains undisturbed by the speaker embeddings. This com",
    "path": "papers/23/12/2312.10305.json",
    "total_tokens": 825,
    "translated_title": "自监督分解表示学习用于鲁棒目标语音提取",
    "translated_abstract": "语音信号本质上是复杂的，因为它包含全局声学特征和局部语义信息。然而，在目标语音提取任务中，参考语音中与说话人身份无关的全局和局部语义信息可能导致在语音提取网络中出现说话人混叠问题。为了克服这个挑战，我们提出了一种自监督分解表示学习方法。我们的方法通过一个两阶段过程来解决这个问题，利用参考语音编码网络和全局信息分解网络逐渐分解说话人身份信息和其他不相关因素。我们专门使用分解的说话人身份信息来指导语音提取网络。此外，我们引入自适应调制Transformer来确保混合信号的声学表示不受说话人嵌入的影响。",
    "tldr": "该论文提出了一种自监督分解表示学习方法，通过逐步分离说话人身份信息和其他无关因素，解决了目标语音提取任务中存在的说话人混叠问题，并使用分解的说话人身份信息来指导语音提取网络。"
}