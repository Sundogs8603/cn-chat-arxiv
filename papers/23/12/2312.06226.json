{
    "title": "Invariant Representation via Decoupling Style and Spurious Features from Images",
    "abstract": "arXiv:2312.06226v2 Announce Type: replace-cross  Abstract: This paper considers the out-of-distribution (OOD) generalization problem under the setting that both style distribution shift and spurious features exist and domain labels are missing. This setting frequently arises in real-world applications and is underlooked because previous approaches mainly handle either of these two factors. The critical challenge is decoupling style and spurious features in the absence of domain labels. To address this challenge, we first propose a structural causal model (SCM) for the image generation process, which captures both style distribution shift and spurious features. The proposed SCM enables us to design a new framework called IRSS, which can gradually separate style distribution and spurious features from images by introducing adversarial neural networks and multi-environment optimization, thus achieving OOD generalization. Moreover, it does not require additional supervision (e.g., domain l",
    "link": "https://arxiv.org/abs/2312.06226",
    "context": "Title: Invariant Representation via Decoupling Style and Spurious Features from Images\nAbstract: arXiv:2312.06226v2 Announce Type: replace-cross  Abstract: This paper considers the out-of-distribution (OOD) generalization problem under the setting that both style distribution shift and spurious features exist and domain labels are missing. This setting frequently arises in real-world applications and is underlooked because previous approaches mainly handle either of these two factors. The critical challenge is decoupling style and spurious features in the absence of domain labels. To address this challenge, we first propose a structural causal model (SCM) for the image generation process, which captures both style distribution shift and spurious features. The proposed SCM enables us to design a new framework called IRSS, which can gradually separate style distribution and spurious features from images by introducing adversarial neural networks and multi-environment optimization, thus achieving OOD generalization. Moreover, it does not require additional supervision (e.g., domain l",
    "path": "papers/23/12/2312.06226.json",
    "total_tokens": 724,
    "translated_title": "通过解耦图像的风格和虚假特征来实现不变表示",
    "translated_abstract": "本文考虑当风格分布转移和虚假特征同时存在且缺失域标签的情况下的超出分布（OOD）泛化问题。为应对这一挑战，我们首先提出了一个结构因果模型（SCM）来捕捉风格分布转移和虚假特征，进而设计了一个名为IRSS的新框架，通过引入对抗神经网络和多环境优化逐渐从图像中分离风格分布和虚假特征，实现了OOD泛化。",
    "tldr": "本文提出了一种新的框架IRSS，通过解耦图像的风格和虚假特征，实现了在缺失域标签情况下的超出分布（OOD）泛化。"
}