{
    "title": "Perceptual Musical Features for Interpretable Audio Tagging. (arXiv:2312.11234v2 [cs.SD] UPDATED)",
    "abstract": "In the age of music streaming platforms, the task of automatically tagging music audio has garnered significant attention, driving researchers to devise methods aimed at enhancing performance metrics on standard datasets. Most recent approaches rely on deep neural networks, which, despite their impressive performance, possess opacity, making it challenging to elucidate their output for a given input. While the issue of interpretability has been emphasized in other fields like medicine, it has not received attention in music-related tasks. In this study, we explored the relevance of interpretability in the context of automatic music tagging. We constructed a workflow that incorporates three different information extraction techniques: a) leveraging symbolic knowledge, b) utilizing auxiliary deep neural networks, and c) employing signal processing to extract perceptual features from audio files. These features were subsequently used to train an interpretable machine-learning model for ta",
    "link": "http://arxiv.org/abs/2312.11234",
    "context": "Title: Perceptual Musical Features for Interpretable Audio Tagging. (arXiv:2312.11234v2 [cs.SD] UPDATED)\nAbstract: In the age of music streaming platforms, the task of automatically tagging music audio has garnered significant attention, driving researchers to devise methods aimed at enhancing performance metrics on standard datasets. Most recent approaches rely on deep neural networks, which, despite their impressive performance, possess opacity, making it challenging to elucidate their output for a given input. While the issue of interpretability has been emphasized in other fields like medicine, it has not received attention in music-related tasks. In this study, we explored the relevance of interpretability in the context of automatic music tagging. We constructed a workflow that incorporates three different information extraction techniques: a) leveraging symbolic knowledge, b) utilizing auxiliary deep neural networks, and c) employing signal processing to extract perceptual features from audio files. These features were subsequently used to train an interpretable machine-learning model for ta",
    "path": "papers/23/12/2312.11234.json",
    "total_tokens": 807,
    "translated_title": "可解释的音频标记的感知音乐特征",
    "translated_abstract": "在音乐流媒体平台的时代，自动标记音乐音频的任务引起了重要关注，推动研究人员设计旨在提高标准数据集上性能指标的方法。最近的方法大多依赖于深度神经网络，尽管其表现出色，但也具有不透明性，使得难以解释其对给定输入的输出。然而，解释性问题在其他领域如医学中备受强调，但在音乐相关任务中并未得到关注。本研究中，我们探索了在自动音乐标记的背景下解释性的相关性。我们构建了一个工作流，结合了三种不同的信息提取技术：a）利用符号知识，b）利用辅助深度神经网络，c）利用信号处理从音频文件中提取感知特征。",
    "tldr": "本研究在自动音乐标记中探索了解释性的重要性，并构建了一个工作流来提取音频文件中的感知特征，从而训练出可解释的机器学习模型。",
    "en_tdlr": "This study explores the importance of interpretability in automatic music tagging and constructs a workflow to extract perceptual features from audio files, training an interpretable machine learning model."
}