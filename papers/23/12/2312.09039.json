{
    "title": "TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning",
    "abstract": "arXiv:2312.09039v2 Announce Type: replace-cross  Abstract: Table-based reasoning has shown remarkable progress in combining deep models with discrete reasoning, which requires reasoning over both free-form natural language (NL) questions and semi-structured tabular data. However, previous table reasoning solutions only consider small-sized tables and exhibit limitations in handling larger tables. In addition, most existing methods struggle to reason over complex questions since they lack essential information or they are scattered in different places. To alleviate these challenges, we propose TAP4LLM as a versatile pre-processing toolbox to generate table prompts through (1) table sampling, (2) table augmentation, and (3) table packing while balancing the token allocation trade-off. In each module, we collect and design several common methods for usage in various scenarios (e.g., speed over accuracy). We also provide a comprehensive evaluation on performance of each components inside T",
    "link": "https://arxiv.org/abs/2312.09039",
    "context": "Title: TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning\nAbstract: arXiv:2312.09039v2 Announce Type: replace-cross  Abstract: Table-based reasoning has shown remarkable progress in combining deep models with discrete reasoning, which requires reasoning over both free-form natural language (NL) questions and semi-structured tabular data. However, previous table reasoning solutions only consider small-sized tables and exhibit limitations in handling larger tables. In addition, most existing methods struggle to reason over complex questions since they lack essential information or they are scattered in different places. To alleviate these challenges, we propose TAP4LLM as a versatile pre-processing toolbox to generate table prompts through (1) table sampling, (2) table augmentation, and (3) table packing while balancing the token allocation trade-off. In each module, we collect and design several common methods for usage in various scenarios (e.g., speed over accuracy). We also provide a comprehensive evaluation on performance of each components inside T",
    "path": "papers/23/12/2312.09039.json",
    "total_tokens": 893,
    "translated_title": "TAP4LLM：用于大型语言模型推理的表格提供者在对半结构化数据进行采样、增补和打包",
    "translated_abstract": "基于表格的推理在结合深度模型和离散推理方面取得了显著进展，这需要对自由形式的自然语言（NL）问题和半结构化表格数据进行推理。然而，先前的表格推理解决方案只考虑小型表格，并且在处理更大表格时存在局限性。此外，大多数现有方法难以推理复杂问题，因为它们缺乏基本信息或分散在不同位置。为了解决这些挑战，我们提出了TAP4LLM作为一个多功能的预处理工具箱，通过平衡标记分配权衡来生成表格提示，实现(1) 表格采样，(2) 表格增补和(3) 表格打包。在每个模块中，我们收集和设计了几种在不同情况下使用的常见方法（例如，速度与准确性的平衡）。我们还对T内部每个组件的性能进行了全面评估。",
    "tldr": "TAP4LLM提出了一个用于生成表格提示的多功能预处理工具箱，通过采样、增补和打包半结构化数据，解决了在大型语言模型推理中处理复杂问题和大型表格的挑战。",
    "en_tdlr": "TAP4LLM proposes a versatile pre-processing toolbox for generating table prompts, addressing the challenges of handling complex questions and large tables in large language model reasoning by sampling, augmenting, and packing semi-structured data."
}