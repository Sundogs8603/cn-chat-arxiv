{
    "title": "Language Modeling on a SpiNNaker 2 Neuromorphic Chip. (arXiv:2312.09084v2 [cs.NE] UPDATED)",
    "abstract": "As large language models continue to scale in size rapidly, so too does the computational power required to run them. Event-based networks on neuromorphic devices offer a potential way to reduce energy consumption for inference significantly. However, to date, most event-based networks that can run on neuromorphic hardware, including spiking neural networks (SNNs), have not achieved task performance even on par with LSTM models for language modeling. As a result, language modeling on neuromorphic devices has seemed a distant prospect. In this work, we demonstrate the first-ever implementation of a language model on a neuromorphic device - specifically the SpiNNaker 2 chip based on a recently published event-based architecture called the EGRU. SpiNNaker 2 is a many-core neuromorphic chip designed for large-scale asynchronous processing, while the EGRU is architected to leverage such hardware efficiently while maintaining competitive task performance. This implementation marks the firs",
    "link": "http://arxiv.org/abs/2312.09084",
    "context": "Title: Language Modeling on a SpiNNaker 2 Neuromorphic Chip. (arXiv:2312.09084v2 [cs.NE] UPDATED)\nAbstract: As large language models continue to scale in size rapidly, so too does the computational power required to run them. Event-based networks on neuromorphic devices offer a potential way to reduce energy consumption for inference significantly. However, to date, most event-based networks that can run on neuromorphic hardware, including spiking neural networks (SNNs), have not achieved task performance even on par with LSTM models for language modeling. As a result, language modeling on neuromorphic devices has seemed a distant prospect. In this work, we demonstrate the first-ever implementation of a language model on a neuromorphic device - specifically the SpiNNaker 2 chip based on a recently published event-based architecture called the EGRU. SpiNNaker 2 is a many-core neuromorphic chip designed for large-scale asynchronous processing, while the EGRU is architected to leverage such hardware efficiently while maintaining competitive task performance. This implementation marks the firs",
    "path": "papers/23/12/2312.09084.json",
    "total_tokens": 933,
    "translated_title": "在SpiNNaker 2神经形态芯片上进行语言建模",
    "translated_abstract": "随着大型语言模型的规模迅速增长，所需的计算能力也在增加。基于神经形态设备上的事件驱动网络提供了一种显著降低推理能耗的潜在方式。然而，迄今为止，大多数可以在神经形态硬件上运行的基于事件的网络，包括脉冲神经网络(SNN)，在语言建模方面的任务性能甚至不能与LSTM模型相媲美。因此，在神经形态设备上进行语言建模似乎是一个遥远的可能性。在这项工作中，我们首次在神经形态设备上实现了一个语言模型 - 具体来说是基于最近发布的名为EGRU的基于事件的架构的SpiNNaker 2芯片。SpiNNaker 2是一个设计用于大规模异步处理的众核神经形态芯片，而EGRU是为了在保持竞争任务性能的同时高效利用这种硬件而设计的。这个实现标志着在神经形态设备上进行语言建模的第一个",
    "tldr": "该论文介绍了在SpiNNaker 2神经形态芯片上实现语言建模的首次尝试。通过利用基于事件的架构和大规模异步处理的硬件，该方法有望在减少能耗的同时保持竞争任务性能。",
    "en_tdlr": "This paper presents the first-ever implementation of language modeling on the SpiNNaker 2 neuromorphic chip. By leveraging an event-based architecture and large-scale asynchronous processing hardware, this approach aims to reduce energy consumption while maintaining competitive task performance."
}