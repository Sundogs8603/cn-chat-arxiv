{
    "title": "Jatmo: Prompt Injection Defense by Task-Specific Finetuning. (arXiv:2312.17673v2 [cs.CR] UPDATED)",
    "abstract": "Large Language Models (LLMs) are attracting significant research attention due to their instruction-following abilities, allowing users and developers to leverage LLMs for a variety of tasks. However, LLMs are vulnerable to prompt-injection attacks: a class of attacks that hijack the model's instruction-following abilities, changing responses to prompts to undesired, possibly malicious ones. In this work, we introduce Jatmo, a method for generating task-specific models resilient to prompt-injection attacks. Jatmo leverages the fact that LLMs can only follow instructions once they have undergone instruction tuning. It harnesses a teacher instruction-tuned model to generate a task-specific dataset, which is then used to fine-tune a base model (i.e., a non-instruction-tuned model). Jatmo only needs a task prompt and a dataset of inputs for the task: it uses the teacher model to generate outputs. For situations with no pre-existing datasets, Jatmo can use a single example, or in some cases",
    "link": "http://arxiv.org/abs/2312.17673",
    "context": "Title: Jatmo: Prompt Injection Defense by Task-Specific Finetuning. (arXiv:2312.17673v2 [cs.CR] UPDATED)\nAbstract: Large Language Models (LLMs) are attracting significant research attention due to their instruction-following abilities, allowing users and developers to leverage LLMs for a variety of tasks. However, LLMs are vulnerable to prompt-injection attacks: a class of attacks that hijack the model's instruction-following abilities, changing responses to prompts to undesired, possibly malicious ones. In this work, we introduce Jatmo, a method for generating task-specific models resilient to prompt-injection attacks. Jatmo leverages the fact that LLMs can only follow instructions once they have undergone instruction tuning. It harnesses a teacher instruction-tuned model to generate a task-specific dataset, which is then used to fine-tune a base model (i.e., a non-instruction-tuned model). Jatmo only needs a task prompt and a dataset of inputs for the task: it uses the teacher model to generate outputs. For situations with no pre-existing datasets, Jatmo can use a single example, or in some cases",
    "path": "papers/23/12/2312.17673.json",
    "total_tokens": 864,
    "translated_title": "Jatmo:通过任务特定的微调进行提示注入防御",
    "translated_abstract": "由于其遵循指令的能力，大型语言模型（LLMs）引起了广泛的研究关注，使用户和开发人员能够利用LLMs执行各种任务。然而，LLMs容易受到提示注入攻击的影响：一种攻击方式，通过劫持模型的指令遵循能力，将对提示的响应更改为不需要或可能具有恶意的响应。在这项工作中，我们介绍了Jatmo，一种生成对提示注入攻击具有抗性的任务特定模型的方法。Jatmo利用了LLMs只能在经历过指令调整后才能遵循指令的事实。它利用一个经过指令调整的教师模型生成一个任务特定的数据集，然后用这个数据集对一个基础模型（即非指令调整的模型）进行微调。Jatmo只需要一个任务提示和一个任务输入的数据集：它使用教师模型生成输出。在没有现成数据集的情况下，Jatmo可以使用一个例子，或者在某些情况下可以使用",
    "tldr": "Jatmo是一种生成对提示注入攻击具有抗性的任务特定模型的方法，通过利用教师模型生成任务特定的数据集并对基础模型进行微调。"
}