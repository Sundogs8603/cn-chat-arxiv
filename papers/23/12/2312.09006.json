{
    "title": "FedSSA: Semantic Similarity-based Aggregation for Efficient Model-Heterogeneous Personalized Federated Learning",
    "abstract": "Federated learning (FL) is a privacy-preserving collaboratively machine learning paradigm. Traditional FL requires all data owners (a.k.a. FL clients) to train the same local model. This design is not well-suited for scenarios involving data and/or system heterogeneity. Model-Heterogeneous Personalized FL (MHPFL) has emerged to address this challenge. Existing MHPFL approaches often rely on having a public dataset with the same nature of the learning task, or incur high computation and communication costs. To address these limitations, we propose the Federated Semantic Similarity Aggregation (FedSSA) approach, which splits each client's model into a heterogeneous (structure-different) feature extractor and a homogeneous (structure-same) classification header. It performs local-to-global knowledge transfer via semantic similarity-based header parameter aggregation. In addition, global-to-local knowledge transfer is achieved via an adaptive parameter stabilization strategy which fuses th",
    "link": "https://arxiv.org/abs/2312.09006",
    "context": "Title: FedSSA: Semantic Similarity-based Aggregation for Efficient Model-Heterogeneous Personalized Federated Learning\nAbstract: Federated learning (FL) is a privacy-preserving collaboratively machine learning paradigm. Traditional FL requires all data owners (a.k.a. FL clients) to train the same local model. This design is not well-suited for scenarios involving data and/or system heterogeneity. Model-Heterogeneous Personalized FL (MHPFL) has emerged to address this challenge. Existing MHPFL approaches often rely on having a public dataset with the same nature of the learning task, or incur high computation and communication costs. To address these limitations, we propose the Federated Semantic Similarity Aggregation (FedSSA) approach, which splits each client's model into a heterogeneous (structure-different) feature extractor and a homogeneous (structure-same) classification header. It performs local-to-global knowledge transfer via semantic similarity-based header parameter aggregation. In addition, global-to-local knowledge transfer is achieved via an adaptive parameter stabilization strategy which fuses th",
    "path": "papers/23/12/2312.09006.json",
    "total_tokens": 970,
    "translated_title": "基于语义相似度的聚合的FedSSA: 用于高效模型异构个性化联邦学习",
    "translated_abstract": "联邦学习（FL）是一种保护隐私的协作机器学习范式。传统的FL要求所有数据所有者（即FL客户端）训练相同的本地模型。这种设计并不适用于涉及数据和/或系统异构的场景。模型异构个性化FL（MHPFL）已经出现来解决这个挑战。现有的MHPFL方法通常依赖于具有相同学习任务性质的公共数据集，或者会产生高计算和通信成本。为了解决这些限制，我们提出了一种名为Federated Semantic Similarity Aggregation（FedSSA）的方法，该方法将每个客户端的模型分为异构（结构不同）特征提取器和同质（结构相同）分类头部。它通过基于语义相似度的头部参数聚合实现了本地到全局的知识传输。此外，通过自适应参数稳定策略实现了全局到本地的知识传输。",
    "tldr": "FedSSA是一种基于语义相似度的聚合方法，用于高效模型异构个性化联邦学习。它通过异构 feature extractor 和同质 classification header 将每个客户端的模型拆分，并通过语义相似度进行头部参数聚合实现本地到全局的知识传输。此外，通过自适应参数稳定策略实现了全局到本地的知识传输。",
    "en_tdlr": "FedSSA is an aggregation approach based on semantic similarity for efficient model-heterogeneous personalized federated learning. It splits each client's model into a heterogeneous feature extractor and a homogeneous classification header, and performs local-to-global knowledge transfer through semantic similarity-based header parameter aggregation. In addition, it achieves global-to-local knowledge transfer through an adaptive parameter stabilization strategy."
}