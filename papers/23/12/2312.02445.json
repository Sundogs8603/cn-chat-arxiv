{
    "title": "LLaRA: Aligning Large Language Models with Sequential Recommenders. (arXiv:2312.02445v2 [cs.IR] UPDATED)",
    "abstract": "Sequential recommendation aims to predict the subsequent items matching user preference based on her/his historical interactions. With the development of Large Language Models (LLMs), there is growing interest in exploring the potential of LLMs for sequential recommendation by framing it as a language modeling task. Prior works represent items in the textual prompts using either ID indexing or text indexing and feed the prompts into LLMs, but falling short of either encapsulating comprehensive world knowledge or exhibiting sufficient sequential understanding. To harness the complementary strengths of traditional recommenders (which encode user behavioral knowledge) and LLMs (which possess world knowledge about items), we propose LLaRA -- a Large Language and Recommendation Assistant framework. Specifically, LLaRA represents items in LLM's input prompts using a novel hybrid approach that integrates ID-based item embeddings from traditional recommenders with textual item features. Viewin",
    "link": "http://arxiv.org/abs/2312.02445",
    "context": "Title: LLaRA: Aligning Large Language Models with Sequential Recommenders. (arXiv:2312.02445v2 [cs.IR] UPDATED)\nAbstract: Sequential recommendation aims to predict the subsequent items matching user preference based on her/his historical interactions. With the development of Large Language Models (LLMs), there is growing interest in exploring the potential of LLMs for sequential recommendation by framing it as a language modeling task. Prior works represent items in the textual prompts using either ID indexing or text indexing and feed the prompts into LLMs, but falling short of either encapsulating comprehensive world knowledge or exhibiting sufficient sequential understanding. To harness the complementary strengths of traditional recommenders (which encode user behavioral knowledge) and LLMs (which possess world knowledge about items), we propose LLaRA -- a Large Language and Recommendation Assistant framework. Specifically, LLaRA represents items in LLM's input prompts using a novel hybrid approach that integrates ID-based item embeddings from traditional recommenders with textual item features. Viewin",
    "path": "papers/23/12/2312.02445.json",
    "total_tokens": 872,
    "translated_title": "LLaRA: 使用顺序推荐器对齐大型语言模型",
    "translated_abstract": "顺序推荐旨在根据用户的历史交互预测与用户偏好相匹配的后续项目。随着大型语言模型 (LLMs) 的发展，人们对于将LLMs 应用于顺序推荐并将其视为语言建模任务的潜力越来越感兴趣。之前的工作中，使用ID索引或文本索引来表示文本提示中的项目，并将提示输入LLMs，但无法全面融合世界知识或展示足够的顺序理解能力。为了充分发挥传统推荐器（可以编码用户行为知识）和LLMs（具有项目的世界知识）的互补优势，我们提出了LLaRA - 一种大型语言和推荐助手框架。具体而言，LLaRA使用一种新颖的混合方法，将传统推荐器的基于ID的项目嵌入与文本项目特征整合到LLM的输入提示中。",
    "tldr": "LLaRA是一个将传统推荐器和大型语言模型相结合的框架，通过使用一种新颖的混合方法来代表项目，在顺序推荐中充分利用了传统推荐器的用户行为知识和LLMs的世界知识。",
    "en_tdlr": "LLaRA is a framework that combines traditional recommenders and large language models to fully leverage both user behavioral knowledge from traditional recommenders and world knowledge about items from LLMs in sequential recommendation tasks."
}