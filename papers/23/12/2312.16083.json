{
    "title": "A Variational Autoencoder for Neural Temporal Point Processes with Dynamic Latent Graphs",
    "abstract": "arXiv:2312.16083v2 Announce Type: replace  Abstract: Continuously-observed event occurrences, often exhibit self- and mutually-exciting effects, which can be well modeled using temporal point processes. Beyond that, these event dynamics may also change over time, with certain periodic trends. We propose a novel variational auto-encoder to capture such a mixture of temporal dynamics. More specifically, the whole time interval of the input sequence is partitioned into a set of sub-intervals. The event dynamics are assumed to be stationary within each sub-interval, but could be changing across those sub-intervals. In particular, we use a sequential latent variable model to learn a dependency graph between the observed dimensions, for each sub-interval. The model predicts the future event times, by using the learned dependency graph to remove the noncontributing influences of past events. By doing so, the proposed model demonstrates its higher accuracy in predicting inter-event times and e",
    "link": "https://arxiv.org/abs/2312.16083",
    "context": "Title: A Variational Autoencoder for Neural Temporal Point Processes with Dynamic Latent Graphs\nAbstract: arXiv:2312.16083v2 Announce Type: replace  Abstract: Continuously-observed event occurrences, often exhibit self- and mutually-exciting effects, which can be well modeled using temporal point processes. Beyond that, these event dynamics may also change over time, with certain periodic trends. We propose a novel variational auto-encoder to capture such a mixture of temporal dynamics. More specifically, the whole time interval of the input sequence is partitioned into a set of sub-intervals. The event dynamics are assumed to be stationary within each sub-interval, but could be changing across those sub-intervals. In particular, we use a sequential latent variable model to learn a dependency graph between the observed dimensions, for each sub-interval. The model predicts the future event times, by using the learned dependency graph to remove the noncontributing influences of past events. By doing so, the proposed model demonstrates its higher accuracy in predicting inter-event times and e",
    "path": "papers/23/12/2312.16083.json",
    "total_tokens": 887,
    "translated_title": "用于动态潜在图的神经时序点过程的变分自编码器",
    "translated_abstract": "连续观察到的事件发生往往表现出自激和互激效应，可以很好地用时序点过程模型化。除此之外，这些事件动态也可能随时间变化，具有某种周期性趋势。我们提出了一种新颖的变分自编码器来捕捉这种混合的时间动态。具体而言，输入序列的整个时间间隔被划分为一组子间隔。假设每个子间隔内的事件动态是稳定的，但在这些子间隔之间可能会发生变化。特别地，我们使用一个顺序潜变量模型来学习每个子间隔中观察维度之间的依赖图。该模型通过使用学习到的依赖图来消除过去事件的非贡献影响，预测未来的事件发生时间。通过这样做，提出的模型在预测事件间隔时间上展示出更高的准确度。",
    "tldr": "提出了一种用于捕捉混合时间动态的新颖变分自编码器模型，使用顺序潜变量模型在子间隔内学习事件间的依赖图，提高了在预测事件间隔时间方面的准确性。",
    "en_tdlr": "Proposed a novel variational autoencoder model to capture mixed temporal dynamics, utilizing a sequential latent variable model to learn dependency graphs between events within sub-intervals, resulting in improved accuracy in predicting event interarrival times."
}