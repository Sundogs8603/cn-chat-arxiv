{
    "title": "Dynamic Retrieval-Augmented Generation",
    "abstract": "arXiv:2312.08976v2 Announce Type: replace-cross  Abstract: Current state-of-the-art large language models are effective in generating high-quality text and encapsulating a broad spectrum of world knowledge. These models, however, often hallucinate and lack locally relevant factual data. Retrieval-augmented approaches were introduced to overcome these problems and provide more accurate responses. Typically, the retrieved information is simply appended to the main request, restricting the context window size of the model. We propose a novel approach for the Dynamic Retrieval-Augmented Generation (DRAG), based on the entity-augmented generation, which injects compressed embeddings of the retrieved entities into the generative model. The proposed pipeline was developed for code-generation tasks, yet can be transferred to some domains of natural language processing. To train the model, we collect and publish a new project-level code generation dataset. We use it for the evaluation along wit",
    "link": "https://arxiv.org/abs/2312.08976",
    "context": "Title: Dynamic Retrieval-Augmented Generation\nAbstract: arXiv:2312.08976v2 Announce Type: replace-cross  Abstract: Current state-of-the-art large language models are effective in generating high-quality text and encapsulating a broad spectrum of world knowledge. These models, however, often hallucinate and lack locally relevant factual data. Retrieval-augmented approaches were introduced to overcome these problems and provide more accurate responses. Typically, the retrieved information is simply appended to the main request, restricting the context window size of the model. We propose a novel approach for the Dynamic Retrieval-Augmented Generation (DRAG), based on the entity-augmented generation, which injects compressed embeddings of the retrieved entities into the generative model. The proposed pipeline was developed for code-generation tasks, yet can be transferred to some domains of natural language processing. To train the model, we collect and publish a new project-level code generation dataset. We use it for the evaluation along wit",
    "path": "papers/23/12/2312.08976.json",
    "total_tokens": 807,
    "translated_title": "动态检索增强生成",
    "translated_abstract": "当前最先进的大型语言模型在生成高质量文本和封装广泛世界知识方面非常有效。然而，这些模型往往会产生幻觉并缺乏局部相关事实数据。检索增强方法被引入以克服这些问题并提供更准确的响应。通常，检索到的信息被简单地附加到主请求中，限制了模型的上下文窗口大小。我们提出了一种基于实体增强生成的动态检索增强生成（DRAG）的新方法，将检索到的实体的压缩嵌入注入到生成模型中。所提出的流程是为代码生成任务而开发的，但也可以转移到一些自然语言处理领域。为了训练模型，我们收集并发布了一个新的项目级代码生成数据集。我们将其用于评估。",
    "tldr": "所提出的Dynamic Retrieval-Augmented Generation (DRAG)是一种新颖的方法，通过实体增强生成，将检索到的实体的压缩嵌入注入到生成模型中，从而在代码生成任务中取得较好效果。",
    "en_tdlr": "The proposed Dynamic Retrieval-Augmented Generation (DRAG) is a novel approach that injects compressed embeddings of the retrieved entities into the generative model through entity-augmented generation, achieving better performance in code generation tasks."
}