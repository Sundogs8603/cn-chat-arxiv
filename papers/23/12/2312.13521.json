{
    "title": "Preparing to Integrate Generative Pretrained Transformer Series 4 models into Genetic Variant Assessment Workflows: Assessing Performance, Drift, and Nondeterminism Characteristics Relative to Classifying Functional Evidence in Literature",
    "abstract": "arXiv:2312.13521v2 Announce Type: replace-cross  Abstract: Background. Large Language Models (LLMs) hold promise for improving genetic variant literature review in clinical testing. We assessed Generative Pretrained Transformer 4's (GPT-4) performance, nondeterminism, and drift to inform its suitability for use in complex clinical processes. Methods. A 2-prompt process for classification of functional evidence was optimized using a development set of 45 articles. The prompts asked GPT-4 to supply all functional data present in an article related to a variant or indicate that no functional evidence is present. For articles indicated as containing functional evidence, a second prompt asked GPT-4 to classify the evidence into pathogenic, benign, or intermediate/inconclusive categories. A final test set of 72 manually classified articles was used to test performance. Results. Over a 2.5-month period (Dec 2023-Feb 2024), we observed substantial differences in intraday (nondeterminism) and a",
    "link": "https://arxiv.org/abs/2312.13521",
    "context": "Title: Preparing to Integrate Generative Pretrained Transformer Series 4 models into Genetic Variant Assessment Workflows: Assessing Performance, Drift, and Nondeterminism Characteristics Relative to Classifying Functional Evidence in Literature\nAbstract: arXiv:2312.13521v2 Announce Type: replace-cross  Abstract: Background. Large Language Models (LLMs) hold promise for improving genetic variant literature review in clinical testing. We assessed Generative Pretrained Transformer 4's (GPT-4) performance, nondeterminism, and drift to inform its suitability for use in complex clinical processes. Methods. A 2-prompt process for classification of functional evidence was optimized using a development set of 45 articles. The prompts asked GPT-4 to supply all functional data present in an article related to a variant or indicate that no functional evidence is present. For articles indicated as containing functional evidence, a second prompt asked GPT-4 to classify the evidence into pathogenic, benign, or intermediate/inconclusive categories. A final test set of 72 manually classified articles was used to test performance. Results. Over a 2.5-month period (Dec 2023-Feb 2024), we observed substantial differences in intraday (nondeterminism) and a",
    "path": "papers/23/12/2312.13521.json",
    "total_tokens": 926,
    "translated_title": "准备将生成式预训练变换器系列4模型整合到基因变体评估工作流中：评估性能、漂移和非确定性特征相对于文献中功能性证据的分类",
    "translated_abstract": "背景：大型语言模型（LLMs）有望改善临床测试中基因变体文献回顾。我们评估了生成式预训练变换器4（GPT-4）的性能、非确定性和漂移，以确定其在复杂临床流程中的适用性。方法：使用45篇文章的开发集对用于分类功能性证据的2提示过程进行了优化。提示要求GPT-4提供与变体相关的文章中的所有功能数据，或指示没有功能性证据存在。对于被指示包含功能性证据的文章，第二个提示要求GPT-4将证据分类为致病性、良性或中间/不明确类别。最终的测试集包括72篇手动分类的文章用于测试性能。结果：在2.5个月的时间内（2023年12月至2024年2月），我们观察到一天内的显着差异（非确定性）和a",
    "tldr": "评估了将GPT-4模型整合到基因变体评估工作流程中的性能、非确定性和漂移特征，为其在复杂临床流程中的适用性提供信息。",
    "en_tdlr": "Evaluated the performance, nondeterminism, and drift characteristics of integrating GPT-4 models into genetic variant assessment workflows to inform its suitability for use in complex clinical processes."
}