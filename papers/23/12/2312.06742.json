{
    "title": "Honeybee: Locality-enhanced Projector for Multimodal LLM",
    "abstract": "arXiv:2312.06742v2 Announce Type: replace-cross  Abstract: In Multimodal Large Language Models (MLLMs), a visual projector plays a crucial role in bridging pre-trained vision encoders with LLMs, enabling profound visual understanding while harnessing the LLMs' robust capabilities. Despite the importance of the visual projector, it has been relatively less explored. In this study, we first identify two essential projector properties: (i) flexibility in managing the number of visual tokens, crucial for MLLMs' overall efficiency, and (ii) preservation of local context from visual features, vital for spatial understanding. Based on these findings, we propose a novel projector design that is both flexible and locality-enhanced, effectively satisfying the two desirable properties. Additionally, we present comprehensive strategies to effectively utilize multiple and multifaceted instruction datasets. Through extensive experiments, we examine the impact of individual design choices. Finally, o",
    "link": "https://arxiv.org/abs/2312.06742",
    "context": "Title: Honeybee: Locality-enhanced Projector for Multimodal LLM\nAbstract: arXiv:2312.06742v2 Announce Type: replace-cross  Abstract: In Multimodal Large Language Models (MLLMs), a visual projector plays a crucial role in bridging pre-trained vision encoders with LLMs, enabling profound visual understanding while harnessing the LLMs' robust capabilities. Despite the importance of the visual projector, it has been relatively less explored. In this study, we first identify two essential projector properties: (i) flexibility in managing the number of visual tokens, crucial for MLLMs' overall efficiency, and (ii) preservation of local context from visual features, vital for spatial understanding. Based on these findings, we propose a novel projector design that is both flexible and locality-enhanced, effectively satisfying the two desirable properties. Additionally, we present comprehensive strategies to effectively utilize multiple and multifaceted instruction datasets. Through extensive experiments, we examine the impact of individual design choices. Finally, o",
    "path": "papers/23/12/2312.06742.json",
    "total_tokens": 865,
    "translated_title": "蜜蜂：多模态LLM的增强局部投影仪",
    "translated_abstract": "在多模态大型语言模型（MLLMs）中，视觉投影仪在连接预先训练的视觉编码器与LLMs之间发挥着至关重要的作用，实现深入的视觉理解并利用LLMs的强大能力。尽管视觉投影仪的重要性不言而喻，但研究相对较少。在这项研究中，我们首先确定了两个关键的投影仪属性：（i）灵活性以管理视觉代币的数量，对于MLLMs的整体效率至关重要；（ii）保留来自视觉特征的局部上下文，对于空间理解至关重要。基于这些发现，我们提出了一种既灵活又增强局部性的新型投影仪设计，有效地满足了这两种理想属性。此外，我们提出了全面的策略，以有效利用多个和多方面的指导数据集。通过广泛的实验，我们检验了各种设计选择的影响。",
    "tldr": "该研究提出了一种既灵活又增强局部性的新型投影仪设计，有助于连接视觉编码器和语言模型，提高模型的效率和空间理解。",
    "en_tdlr": "The study proposes a novel projector design that is both flexible and locality-enhanced, aiding in connecting vision encoders with language models to improve model efficiency and spatial understanding."
}