{
    "title": "Directions of Curvature as an Explanation for Loss of Plasticity",
    "abstract": "arXiv:2312.00246v2 Announce Type: replace  Abstract: Loss of plasticity is a phenomenon in which neural networks lose their ability to learn from new experience. Despite being empirically observed in several problem settings, little is understood about the mechanisms that lead to loss of plasticity. In this paper, we offer a consistent explanation for loss of plasticity: Neural networks lose directions of curvature during training and that loss of plasticity can be attributed to this reduction in curvature. To support such a claim, we provide a systematic investigation of loss of plasticity across continual learning tasks using MNIST, CIFAR-10 and ImageNet. Our findings illustrate that loss of curvature directions coincides with loss of plasticity, while also showing that previous explanations are insufficient to explain loss of plasticity in all settings. Lastly, we show that regularizers which mitigate loss of plasticity also preserve curvature, motivating a simple distributional reg",
    "link": "https://arxiv.org/abs/2312.00246",
    "context": "Title: Directions of Curvature as an Explanation for Loss of Plasticity\nAbstract: arXiv:2312.00246v2 Announce Type: replace  Abstract: Loss of plasticity is a phenomenon in which neural networks lose their ability to learn from new experience. Despite being empirically observed in several problem settings, little is understood about the mechanisms that lead to loss of plasticity. In this paper, we offer a consistent explanation for loss of plasticity: Neural networks lose directions of curvature during training and that loss of plasticity can be attributed to this reduction in curvature. To support such a claim, we provide a systematic investigation of loss of plasticity across continual learning tasks using MNIST, CIFAR-10 and ImageNet. Our findings illustrate that loss of curvature directions coincides with loss of plasticity, while also showing that previous explanations are insufficient to explain loss of plasticity in all settings. Lastly, we show that regularizers which mitigate loss of plasticity also preserve curvature, motivating a simple distributional reg",
    "path": "papers/23/12/2312.00246.json",
    "total_tokens": 846,
    "translated_title": "曲率方向作为失去可塑性的解释",
    "translated_abstract": "可塑性的丧失是神经网络丧失从新经验学习能力的现象。尽管在几种问题设置中经验上观察到，但对导致可塑性丧失的机制了解甚少。在本文中，我们提供了对可塑性丧失的一致解释：神经网络在训练过程中丧失了曲率方向，可将可塑性的丧失归因于这种曲率减少。为了支持这样的说法，我们对在MNIST、CIFAR-10和ImageNet中使用的不断学习任务中的可塑性丧失进行了系统调查。我们的研究结果表明，曲率方向的丧失与可塑性的丧失相吻合，同时还表明以前的解释不足以解释所有情况下的可塑性丧失。最后，我们展示了缓解可塑性丧失的正则化器也会保留曲率，促使采用简单的分布式正则化器。",
    "tldr": "曲率方向的丧失被认为是导致神经网络可塑性丧失的一个重要原因，并且我们通过系统调查和在多个任务中的研究结果支持了这一观点。",
    "en_tdlr": "The loss of curvature directions is considered a key factor leading to the loss of plasticity in neural networks, and this claim is supported by systematic investigations across multiple tasks."
}