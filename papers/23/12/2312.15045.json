{
    "title": "Probabilistic Modeling for Sequences of Sets in Continuous-Time. (arXiv:2312.15045v2 [cs.LG] UPDATED)",
    "abstract": "Neural marked temporal point processes have been a valuable addition to the existing toolbox of statistical parametric models for continuous-time event data. These models are useful for sequences where each event is associated with a single item (a single type of event or a \"mark\") -- but such models are not suited for the practical situation where each event is associated with a set of items. In this work, we develop a general framework for modeling set-valued data in continuous-time, compatible with any intensity-based recurrent neural point process model. In addition, we develop inference methods that can use such models to answer probabilistic queries such as \"the probability of item $A$ being observed before item $B$,\" conditioned on sequence history. Computing exact answers for such queries is generally intractable for neural models due to both the continuous-time nature of the problem setting and the combinatorially-large space of potential outcomes for each event. To address th",
    "link": "http://arxiv.org/abs/2312.15045",
    "context": "Title: Probabilistic Modeling for Sequences of Sets in Continuous-Time. (arXiv:2312.15045v2 [cs.LG] UPDATED)\nAbstract: Neural marked temporal point processes have been a valuable addition to the existing toolbox of statistical parametric models for continuous-time event data. These models are useful for sequences where each event is associated with a single item (a single type of event or a \"mark\") -- but such models are not suited for the practical situation where each event is associated with a set of items. In this work, we develop a general framework for modeling set-valued data in continuous-time, compatible with any intensity-based recurrent neural point process model. In addition, we develop inference methods that can use such models to answer probabilistic queries such as \"the probability of item $A$ being observed before item $B$,\" conditioned on sequence history. Computing exact answers for such queries is generally intractable for neural models due to both the continuous-time nature of the problem setting and the combinatorially-large space of potential outcomes for each event. To address th",
    "path": "papers/23/12/2312.15045.json",
    "total_tokens": 898,
    "translated_title": "连续时间序列集合的概率建模",
    "translated_abstract": "在连续时间事件数据的统计参数模型工具箱中，神经标记时间点过程是一个有价值的补充。这些模型适用于每个事件与单个项目（单个事件类型或“标记”）相关联的序列，但不适用于每个事件与一组项目相关联的实际情况。本文中，我们开发了一个通用的连续时间集合数值数据建模框架，与任何基于强度的递归神经点过程模型兼容。此外，我们还开发了推理方法，可使用这些模型回答诸如“在考虑序列历史的条件下，项目A在项目B之前观察到的概率”等概率查询问题。由于问题设置的连续时间性质和每个事件的潜在结果空间的组合极大，对于神经模型来说，计算这些查询的精确答案通常是不可行的。",
    "tldr": "本文提出了一个通用的连续时间序列集合的概率建模框架，适用于处理每个事件与一组项目相关联的情况。引入了适用于任何强度为基础的递归神经点过程模型的推理方法，可用于回答关于序列历史条件下的概率查询问题。",
    "en_tdlr": "This paper presents a general framework for probabilistic modeling of sequences of sets in continuous-time, suitable for cases where each event is associated with a set of items. It introduces inference methods compatible with any intensity-based recurrent neural point process model, which can be used to answer probabilistic queries conditioned on sequence history."
}