{
    "title": "SMILE: Multimodal Dataset for Understanding Laughter in Video with Language Models",
    "abstract": "arXiv:2312.09818v2 Announce Type: replace-cross  Abstract: Despite the recent advances of the artificial intelligence, building social intelligence remains a challenge. Among social signals, laughter is one of the distinctive expressions that occurs during social interactions between humans. In this work, we tackle a new challenge for machines to understand the rationale behind laughter in video, Video Laugh Reasoning. We introduce this new task to explain why people laugh in a particular video and a dataset for this task. Our proposed dataset, SMILE, comprises video clips and language descriptions of why people laugh. We propose a baseline by leveraging the reasoning capacity of large language models (LLMs) with textual video representation. Experiments show that our baseline can generate plausible explanations for laughter. We further investigate the scalability of our baseline by probing other video understanding tasks and in-the-wild videos. We release our dataset, code, and model ",
    "link": "https://arxiv.org/abs/2312.09818",
    "context": "Title: SMILE: Multimodal Dataset for Understanding Laughter in Video with Language Models\nAbstract: arXiv:2312.09818v2 Announce Type: replace-cross  Abstract: Despite the recent advances of the artificial intelligence, building social intelligence remains a challenge. Among social signals, laughter is one of the distinctive expressions that occurs during social interactions between humans. In this work, we tackle a new challenge for machines to understand the rationale behind laughter in video, Video Laugh Reasoning. We introduce this new task to explain why people laugh in a particular video and a dataset for this task. Our proposed dataset, SMILE, comprises video clips and language descriptions of why people laugh. We propose a baseline by leveraging the reasoning capacity of large language models (LLMs) with textual video representation. Experiments show that our baseline can generate plausible explanations for laughter. We further investigate the scalability of our baseline by probing other video understanding tasks and in-the-wild videos. We release our dataset, code, and model ",
    "path": "papers/23/12/2312.09818.json",
    "total_tokens": 827,
    "translated_title": "SMILE：多模态数据集用于语言模型理解视频中的笑声",
    "translated_abstract": "尽管人工智能最近取得了进展，但构建社交智能仍然是一个挑战。其中，笑声是人类社交互动中发生的独特表达之一。在这项工作中，我们面对了机器理解视频中笑声背后理由的新挑战，即视频笑声推理。我们介绍了这一新任务，解释人们在特定视频中为什么会笑的原因，并提出了用于这一任务的数据集SMILE。我们提出了一个基线，通过利用大型语言模型（LLMs）的推理能力和文本视频表示生成合理的笑声解释。实验表明，我们的基线可以生成可信的笑声解释。我们进一步探讨了我们的基线在探测其他视频理解任务和野外视频方面的可扩展性。我们发布了我们的数据集、代码和模型。",
    "tldr": "本论文介绍了一个新任务，即视频笑声推理，旨在解释特定视频中人们笑的原因，并提出了数据集SMILE。通过利用大型语言模型生成文本视频表示，我们的基线能够生成合理的笑声解释。",
    "en_tdlr": "This paper introduces a new task, Video Laugh Reasoning, to explain why people laugh in a specific video, and presents the dataset SMILE. By leveraging large language models to generate textual video representations, our baseline can produce plausible explanations for laughter."
}