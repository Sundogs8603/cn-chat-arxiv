{
    "title": "Reconstruction of Sound Field through Diffusion Models",
    "abstract": "arXiv:2312.08821v2 Announce Type: replace-cross  Abstract: Reconstructing the sound field in a room is an important task for several applications, such as sound control and augmented (AR) or virtual reality (VR). In this paper, we propose a data-driven generative model for reconstructing the magnitude of acoustic fields in rooms with a focus on the modal frequency range. We introduce, for the first time, the use of a conditional Denoising Diffusion Probabilistic Model (DDPM) trained in order to reconstruct the sound field (SF-Diff) over an extended domain. The architecture is devised in order to be conditioned on a set of limited available measurements at different frequencies and generate the sound field in target, unknown, locations. The results show that SF-Diff is able to provide accurate reconstructions, outperforming a state-of-the-art baseline based on kernel interpolation.",
    "link": "https://arxiv.org/abs/2312.08821",
    "context": "Title: Reconstruction of Sound Field through Diffusion Models\nAbstract: arXiv:2312.08821v2 Announce Type: replace-cross  Abstract: Reconstructing the sound field in a room is an important task for several applications, such as sound control and augmented (AR) or virtual reality (VR). In this paper, we propose a data-driven generative model for reconstructing the magnitude of acoustic fields in rooms with a focus on the modal frequency range. We introduce, for the first time, the use of a conditional Denoising Diffusion Probabilistic Model (DDPM) trained in order to reconstruct the sound field (SF-Diff) over an extended domain. The architecture is devised in order to be conditioned on a set of limited available measurements at different frequencies and generate the sound field in target, unknown, locations. The results show that SF-Diff is able to provide accurate reconstructions, outperforming a state-of-the-art baseline based on kernel interpolation.",
    "path": "papers/23/12/2312.08821.json",
    "total_tokens": 760,
    "translated_title": "通过扩散模型重建声场",
    "translated_abstract": "在房间内重建声场是几种应用中的一项重要任务，比如声控、增强现实（AR）或虚拟现实（VR）。本文提出了一种数据驱动的生成模型，用于重建房间内声场的声学场振幅，重点关注模态频率范围。我们首次引入条件化去噪扩散概率模型（DDPM）的使用，经过训练用于在扩展领域内重建声场（SF-Diff）。该架构被设计为在一组不同频率的有限可用测量条件下，生成目标未知位置的声场。结果表明，SF-Diff能够提供准确的重建，优于基于核插值的现有基线模型。",
    "tldr": "本文提出了一种用于在房间内重建声场的数据驱动生成模型，通过条件化去噪扩散概率模型训练和生成声场，实现了准确的重建。"
}