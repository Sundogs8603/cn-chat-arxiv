{
    "title": "TimeChat: A Time-sensitive Multimodal Large Language Model for Long Video Understanding",
    "abstract": "arXiv:2312.02051v2 Announce Type: replace-cross  Abstract: This work proposes TimeChat, a time-sensitive multimodal large language model specifically designed for long video understanding. Our model incorporates two key architectural contributions: (1) a timestamp-aware frame encoder that binds visual content with the timestamp of each frame, and (2) a sliding video Q-Former that produces a video token sequence of varying lengths to accommodate videos of various durations. Additionally, we construct an instruction-tuning dataset, encompassing 6 tasks and a total of 125K instances, to further enhance TimeChat's instruction-following performance. Experiment results across various video understanding tasks, such as dense captioning, temporal grounding, and highlight detection, demonstrate TimeChat's strong zero-shot temporal localization and reasoning capabilities. For example, it achieves +9.2 F1 score and +2.8 CIDEr on YouCook2, +5.8 HIT@1 on QVHighlights, and +27.5 R@1 (IoU=0.5) on Cha",
    "link": "https://arxiv.org/abs/2312.02051",
    "context": "Title: TimeChat: A Time-sensitive Multimodal Large Language Model for Long Video Understanding\nAbstract: arXiv:2312.02051v2 Announce Type: replace-cross  Abstract: This work proposes TimeChat, a time-sensitive multimodal large language model specifically designed for long video understanding. Our model incorporates two key architectural contributions: (1) a timestamp-aware frame encoder that binds visual content with the timestamp of each frame, and (2) a sliding video Q-Former that produces a video token sequence of varying lengths to accommodate videos of various durations. Additionally, we construct an instruction-tuning dataset, encompassing 6 tasks and a total of 125K instances, to further enhance TimeChat's instruction-following performance. Experiment results across various video understanding tasks, such as dense captioning, temporal grounding, and highlight detection, demonstrate TimeChat's strong zero-shot temporal localization and reasoning capabilities. For example, it achieves +9.2 F1 score and +2.8 CIDEr on YouCook2, +5.8 HIT@1 on QVHighlights, and +27.5 R@1 (IoU=0.5) on Cha",
    "path": "papers/23/12/2312.02051.json",
    "total_tokens": 940,
    "translated_title": "TimeChat：一种面向长视频理解的时间敏感多模态大型语言模型",
    "translated_abstract": "这项工作提出了TimeChat，一种专门为长视频理解设计的时间敏感多模态大型语言模型。 我们的模型包含两个关键的架构贡献：(1)一个时间戳感知帧编码器，将视觉内容与每帧的时间戳绑定在一起；(2)一个滑动视频Q-Former，生成各种长度的视频令牌序列，以适应不同持续时间的视频。此外，我们构建了一个指令调优数据集，涵盖6个任务和总计125K个实例，以进一步提升TimeChat在遵循指令方面的性能。在各种视频理解任务上的实验结果，如密集字幕生成、时间定位和精彩片段检测，展示了TimeChat强大的零-shot时间本地化和推理能力。例如，它在YouCook2上实现了+9.2的F1分数和+2.8的CIDEr，在QVHighlights上实现了+5.8的HIT@1，在Cha上实现了+27.5的R@1（IoU=0.5）。",
    "tldr": "TimeChat是一种时间敏感的多模态大型语言模型，包含时间戳感知帧编码器和滑动视频Q-Former，以实现对长视频进行强大的零-shot时间本地化和推理能力。实验结果表明，在各种视频理解任务上表现出色。",
    "en_tdlr": "TimeChat is a time-sensitive multimodal large language model with a timestamp-aware frame encoder and a sliding video Q-Former, enabling strong zero-shot temporal localization and reasoning for long videos. Experimental results demonstrate its excellent performance across various video understanding tasks."
}