{
    "title": "Elijah: Eliminating Backdoors Injected in Diffusion Models via Distribution Shift",
    "abstract": "Diffusion models (DM) have become state-of-the-art generative models because of their capability to generate high-quality images from noises without adversarial training. However, they are vulnerable to backdoor attacks as reported by recent studies. When a data input (e.g., some Gaussian noise) is stamped with a trigger (e.g., a white patch), the backdoored model always generates the target image (e.g., an improper photo). However, effective defense strategies to mitigate backdoors from DMs are underexplored. To bridge this gap, we propose the first backdoor detection and removal framework for DMs. We evaluate our framework Elijah on hundreds of DMs of 3 types including DDPM, NCSN and LDM, with 13 samplers against 3 existing backdoor attacks. Extensive experiments show that our approach can have close to 100% detection accuracy and reduce the backdoor effects to close to zero without significantly sacrificing the model utility.",
    "link": "https://arxiv.org/abs/2312.00050",
    "context": "Title: Elijah: Eliminating Backdoors Injected in Diffusion Models via Distribution Shift\nAbstract: Diffusion models (DM) have become state-of-the-art generative models because of their capability to generate high-quality images from noises without adversarial training. However, they are vulnerable to backdoor attacks as reported by recent studies. When a data input (e.g., some Gaussian noise) is stamped with a trigger (e.g., a white patch), the backdoored model always generates the target image (e.g., an improper photo). However, effective defense strategies to mitigate backdoors from DMs are underexplored. To bridge this gap, we propose the first backdoor detection and removal framework for DMs. We evaluate our framework Elijah on hundreds of DMs of 3 types including DDPM, NCSN and LDM, with 13 samplers against 3 existing backdoor attacks. Extensive experiments show that our approach can have close to 100% detection accuracy and reduce the backdoor effects to close to zero without significantly sacrificing the model utility.",
    "path": "papers/23/12/2312.00050.json",
    "total_tokens": 885,
    "translated_title": "Elijah: 通过分布变化消除扩散模型中的后门注入",
    "translated_abstract": "扩散模型(DM)因其能够从噪声中生成高质量图像而成为最先进的生成模型。然而，最近的研究表明，它们容易受到后门攻击的影响。当一个数据输入（例如一些高斯噪声）被注入触发器（例如一个白色斑点）时，带有后门的模型总是生成目标图像（例如不恰当的照片）。然而，有效的防御策略来减轻DM中的后门问题尚未得到充分探索。为了弥合这一差距，我们提出了第一个适用于DM的后门检测和消除框架。我们使用13种采样器对包括DDPM、NCSN和LDM在内的数百个DM进行评估，针对3种现有的后门攻击。广泛的实验证明，我们的方法可以接近100%的检测准确率，同时将后门效果减少至接近零，而不会显著牺牲模型的实用性。",
    "tldr": "Elijah是一种用于扩散模型的后门检测和消除框架，能够准确检测后门并将其效果减少至接近零，而不会显著牺牲模型的实用性。",
    "en_tdlr": "Elijah is a backdoor detection and removal framework for diffusion models (DMs), which can accurately detect backdoors and reduce their effects to close to zero without significantly sacrificing the model utility."
}