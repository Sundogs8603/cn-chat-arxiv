{
    "title": "Stateful Conformer with Cache-based Inference for Streaming Automatic Speech Recognition. (arXiv:2312.17279v2 [cs.CL] UPDATED)",
    "abstract": "In this paper, we propose an efficient and accurate streaming speech recognition model based on the FastConformer architecture. We adapted the FastConformer architecture for streaming applications through: (1) constraining both the look-ahead and past contexts in the encoder, and (2) introducing an activation caching mechanism to enable the non-autoregressive encoder to operate autoregressively during inference. The proposed model is thoughtfully designed in a way to eliminate the accuracy disparity between the train and inference time which is common for many streaming models. Furthermore, our proposed encoder works with various decoder configurations including Connectionist Temporal Classification (CTC) and RNN-Transducer (RNNT) decoders. Additionally, we introduced a hybrid CTC/RNNT architecture which utilizes a shared encoder with both a CTC and RNNT decoder to boost the accuracy and save computation. We evaluate the proposed model on LibriSpeech dataset and a multi-domain large sc",
    "link": "http://arxiv.org/abs/2312.17279",
    "context": "Title: Stateful Conformer with Cache-based Inference for Streaming Automatic Speech Recognition. (arXiv:2312.17279v2 [cs.CL] UPDATED)\nAbstract: In this paper, we propose an efficient and accurate streaming speech recognition model based on the FastConformer architecture. We adapted the FastConformer architecture for streaming applications through: (1) constraining both the look-ahead and past contexts in the encoder, and (2) introducing an activation caching mechanism to enable the non-autoregressive encoder to operate autoregressively during inference. The proposed model is thoughtfully designed in a way to eliminate the accuracy disparity between the train and inference time which is common for many streaming models. Furthermore, our proposed encoder works with various decoder configurations including Connectionist Temporal Classification (CTC) and RNN-Transducer (RNNT) decoders. Additionally, we introduced a hybrid CTC/RNNT architecture which utilizes a shared encoder with both a CTC and RNNT decoder to boost the accuracy and save computation. We evaluate the proposed model on LibriSpeech dataset and a multi-domain large sc",
    "path": "papers/23/12/2312.17279.json",
    "total_tokens": 932,
    "translated_title": "使用基于缓存推理的带状态Conformer模型的流式自动语音识别",
    "translated_abstract": "本文提出了一种基于FastConformer架构的高效准确的流式语音识别模型。通过对FastConformer架构进行调整，我们适用于流式应用的方式有两个：（1）限制编码器中的前瞻和历史上下文，（2）引入激活缓存机制以使非自回归编码器在推理过程中以自回归方式工作。所提出的模型经过精心设计，消除了许多流式模型在训练和推理时间中的准确度差异。此外，我们的编码器与不同的解码器配置兼容，包括CTC和RNNT解码器。此外，我们还引入了一种混合的CTC/RNNT架构，它利用共享的编码器和CTC和RNNT解码器来提高准确度并节省计算。我们在LibriSpeech数据集和多领域大型数据集上评估了所提出的模型。",
    "tldr": "本文提出一种基于FastConformer架构的流式语音识别模型，通过限制上下文和引入缓存机制，在推理过程中实现非自回归编码器的自回归操作，并消除了训练和推理准确度间的差异。同时，还提出了CTC/RNNT混合架构以提高准确度和节省计算。",
    "en_tdlr": "This paper proposes a streaming speech recognition model based on the FastConformer architecture, which utilizes a constrained encoder with activation caching mechanism to enable autoregressive operation during inference, eliminating the accuracy disparity between training and inference. It also introduces a hybrid CTC/RNNT architecture to improve accuracy and save computation."
}