{
    "title": "M3D: Dataset Condensation by Minimizing Maximum Mean Discrepancy. (arXiv:2312.15927v2 [cs.CV] UPDATED)",
    "abstract": "Training state-of-the-art (SOTA) deep models often requires extensive data, resulting in substantial training and storage costs. To address these challenges, dataset condensation has been developed to learn a small synthetic set that preserves essential information from the original large-scale dataset. Nowadays, optimization-oriented methods have been the primary method in the field of dataset condensation for achieving SOTA results. However, the bi-level optimization process hinders the practical application of such methods to realistic and larger datasets. To enhance condensation efficiency, previous works proposed Distribution-Matching (DM) as an alternative, which significantly reduces the condensation cost. Nonetheless, current DM-based methods have yielded less comparable results to optimization-oriented methods due to their focus on aligning only the first moment of the distributions. In this paper, we present a novel DM-based method named M3D for dataset condensation by Minimi",
    "link": "http://arxiv.org/abs/2312.15927",
    "context": "Title: M3D: Dataset Condensation by Minimizing Maximum Mean Discrepancy. (arXiv:2312.15927v2 [cs.CV] UPDATED)\nAbstract: Training state-of-the-art (SOTA) deep models often requires extensive data, resulting in substantial training and storage costs. To address these challenges, dataset condensation has been developed to learn a small synthetic set that preserves essential information from the original large-scale dataset. Nowadays, optimization-oriented methods have been the primary method in the field of dataset condensation for achieving SOTA results. However, the bi-level optimization process hinders the practical application of such methods to realistic and larger datasets. To enhance condensation efficiency, previous works proposed Distribution-Matching (DM) as an alternative, which significantly reduces the condensation cost. Nonetheless, current DM-based methods have yielded less comparable results to optimization-oriented methods due to their focus on aligning only the first moment of the distributions. In this paper, we present a novel DM-based method named M3D for dataset condensation by Minimi",
    "path": "papers/23/12/2312.15927.json",
    "total_tokens": 885,
    "translated_title": "M3D：通过最小化最大均值差异来进行数据集压缩",
    "translated_abstract": "训练最先进的深度模型通常需要大量的数据，导致训练和存储成本高昂。为了解决这些挑战，提出了数据集压缩方法，通过学习一个小的合成集合来保留原始大规模数据集的关键信息。目前，以优化为导向的方法是数据集压缩领域中实现最先进结果的主要方法。然而，双层优化过程阻碍了这些方法在实际和较大的数据集上的实际应用。为了提高压缩效率，先前的工作提出了分布匹配（DM）作为替代方法，显著减少了压缩成本。然而，由于专注于对齐分布的一阶矩，目前的基于DM的方法与以优化为导向的方法相比，结果不太可比。在本文中，我们介绍了一种名为M3D的新型基于DM的数据集压缩方法。",
    "tldr": "该论文提出了一种名为M3D的新型基于分布匹配的数据集压缩方法，通过最小化最大均值差异来提高压缩效率，克服了优化过程在实际和较大数据集上的应用难题。",
    "en_tdlr": "The paper proposes a novel distribution-matching-based dataset condensation method called M3D, which enhances condensation efficiency by minimizing maximum mean discrepancy, overcoming the challenges of practical application on realistic and larger datasets posed by the optimization process."
}