{
    "title": "Understanding Distributed Representations of Concepts in Deep Neural Networks without Supervision",
    "abstract": "arXiv:2312.17285v2 Announce Type: replace-cross  Abstract: Understanding intermediate representations of the concepts learned by deep learning classifiers is indispensable for interpreting general model behaviors. Existing approaches to reveal learned concepts often rely on human supervision, such as pre-defined concept sets or segmentation processes. In this paper, we propose a novel unsupervised method for discovering distributed representations of concepts by selecting a principal subset of neurons. Our empirical findings demonstrate that instances with similar neuron activation states tend to share coherent concepts. Based on the observations, the proposed method selects principal neurons that construct an interpretable region, namely a Relaxed Decision Region (RDR), encompassing instances with coherent concepts in the feature space. It can be utilized to identify unlabeled subclasses within data and to detect the causes of misclassifications. Furthermore, the applicability of our ",
    "link": "https://arxiv.org/abs/2312.17285",
    "context": "Title: Understanding Distributed Representations of Concepts in Deep Neural Networks without Supervision\nAbstract: arXiv:2312.17285v2 Announce Type: replace-cross  Abstract: Understanding intermediate representations of the concepts learned by deep learning classifiers is indispensable for interpreting general model behaviors. Existing approaches to reveal learned concepts often rely on human supervision, such as pre-defined concept sets or segmentation processes. In this paper, we propose a novel unsupervised method for discovering distributed representations of concepts by selecting a principal subset of neurons. Our empirical findings demonstrate that instances with similar neuron activation states tend to share coherent concepts. Based on the observations, the proposed method selects principal neurons that construct an interpretable region, namely a Relaxed Decision Region (RDR), encompassing instances with coherent concepts in the feature space. It can be utilized to identify unlabeled subclasses within data and to detect the causes of misclassifications. Furthermore, the applicability of our ",
    "path": "papers/23/12/2312.17285.json",
    "total_tokens": 810,
    "translated_title": "无监督学习下理解深度神经网络中概念的分布表示",
    "translated_abstract": "理解深度学习分类器学习的概念的中间表示对解释模型的一般行为至关重要。现有揭示学习概念的方法通常依赖于人类监督，例如预定义的概念集或分割过程。本文提出了一种新颖的无监督方法，通过选择主要子集的神经元来发现概念的分布表示。我们的实证结果表明，具有类似神经元激活状态的实例往往共享一致的概念。根据观察，所提出的方法选择构建可解释区域的主要神经元，即涵盖特征空间中具有一致概念的实例的放松决策区域（RDR）。它可用于识别数据中的未标记子类并检测误分类的原因。此外，我们的方法可应用于",
    "tldr": "本文提出了一种无监督方法，通过选择主要神经元来发现概念的分布表示，可以用于识别数据中的未标记子类和检测误分类的原因。",
    "en_tdlr": "This paper proposes an unsupervised method for discovering distributed representations of concepts by selecting principal neurons, which can be used to identify unlabeled subclasses within data and detect the causes of misclassifications."
}