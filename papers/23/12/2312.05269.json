{
    "title": "LifelongMemory: Leveraging LLMs for Answering Queries in Long-form Egocentric Videos",
    "abstract": "arXiv:2312.05269v2 Announce Type: replace-cross  Abstract: In this paper we introduce LifelongMemory, a new framework for accessing long-form egocentric videographic memory through natural language question answering and retrieval. LifelongMemory generates concise video activity descriptions of the camera wearer and leverages the zero-shot capabilities of pretrained large language models to perform reasoning over long-form video context. Furthermore, Lifelong Memory uses a confidence and explanation module to produce confident, high-quality, and interpretable answers. Our approach achieves state-of-the-art performance on the EgoSchema benchmark for question answering and is highly competitive on the natural language query (NLQ) challenge of Ego4D. Code is available at https://github.com/Agentic-Learning-AI-Lab/lifelong-memory.",
    "link": "https://arxiv.org/abs/2312.05269",
    "context": "Title: LifelongMemory: Leveraging LLMs for Answering Queries in Long-form Egocentric Videos\nAbstract: arXiv:2312.05269v2 Announce Type: replace-cross  Abstract: In this paper we introduce LifelongMemory, a new framework for accessing long-form egocentric videographic memory through natural language question answering and retrieval. LifelongMemory generates concise video activity descriptions of the camera wearer and leverages the zero-shot capabilities of pretrained large language models to perform reasoning over long-form video context. Furthermore, Lifelong Memory uses a confidence and explanation module to produce confident, high-quality, and interpretable answers. Our approach achieves state-of-the-art performance on the EgoSchema benchmark for question answering and is highly competitive on the natural language query (NLQ) challenge of Ego4D. Code is available at https://github.com/Agentic-Learning-AI-Lab/lifelong-memory.",
    "path": "papers/23/12/2312.05269.json",
    "total_tokens": 870,
    "translated_title": "终身记忆：利用LLMs回答长篇自我中心视频中的查询",
    "translated_abstract": "在本文中，我们介绍了终身记忆(LifelongMemory)，这是一个新的框架，通过自然语言问答和检索来访问长篇自我中心视频存储。终身记忆生成摄像机佩戴者的简洁视频活动描述，并利用预训练的大型语言模型的零-shot能力来推理长篇视频内容。此外，终身记忆使用置信度和解释模块来产生自信、高质量和可解释的答案。我们的方法在EgoSchema问题回答基准上实现了最先进的性能，并在Ego4D的自然语言查询(NLQ)挑战中具有很强的竞争力。代码可在https://github.com/Agentic-Learning-AI-Lab/lifelong-memory 中找到。",
    "tldr": "终身记忆是一个新的框架，通过自然语言问答和检索方式访问长篇自我中心视频，利用零-shot能力进行推理，使用置信度和解释模块产生自信、高质量和可解释的答案，在EgoSchema问题回答基准上达到最先进性能，在Ego4D的自然语言查询挑战中具有很强的竞争力",
    "en_tdlr": "LifelongMemory is a new framework for accessing long-form egocentric videographic memory through natural language question answering and retrieval, leveraging zero-shot capabilities for reasoning and producing confident, high-quality, and interpretable answers, achieving state-of-the-art performance on the EgoSchema benchmark and being highly competitive on the Ego4D natural language query challenge."
}