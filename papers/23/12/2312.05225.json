{
    "title": "Neural Spectral Methods: Self-supervised learning in the spectral domain. (arXiv:2312.05225v2 [cs.LG] UPDATED)",
    "abstract": "We present Neural Spectral Methods, a technique to solve parametric Partial Differential Equations (PDEs), grounded in classical spectral methods. Our method uses orthogonal bases to learn PDE solutions as mappings between spectral coefficients. In contrast to current machine learning approaches which enforce PDE constraints by minimizing the numerical quadrature of the residuals in the spatiotemporal domain, we leverage Parseval's identity and introduce a new training strategy through a \\textit{spectral loss}. Our spectral loss enables more efficient differentiation through the neural network, and substantially reduces training complexity. At inference time, the computational cost of our method remains constant, regardless of the spatiotemporal resolution of the domain. Our experimental results demonstrate that our method significantly outperforms previous machine learning approaches in terms of speed and accuracy by one to two orders of magnitude on multiple different problems. When ",
    "link": "http://arxiv.org/abs/2312.05225",
    "context": "Title: Neural Spectral Methods: Self-supervised learning in the spectral domain. (arXiv:2312.05225v2 [cs.LG] UPDATED)\nAbstract: We present Neural Spectral Methods, a technique to solve parametric Partial Differential Equations (PDEs), grounded in classical spectral methods. Our method uses orthogonal bases to learn PDE solutions as mappings between spectral coefficients. In contrast to current machine learning approaches which enforce PDE constraints by minimizing the numerical quadrature of the residuals in the spatiotemporal domain, we leverage Parseval's identity and introduce a new training strategy through a \\textit{spectral loss}. Our spectral loss enables more efficient differentiation through the neural network, and substantially reduces training complexity. At inference time, the computational cost of our method remains constant, regardless of the spatiotemporal resolution of the domain. Our experimental results demonstrate that our method significantly outperforms previous machine learning approaches in terms of speed and accuracy by one to two orders of magnitude on multiple different problems. When ",
    "path": "papers/23/12/2312.05225.json",
    "total_tokens": 869,
    "translated_title": "神经谱方法: 谱域中的自监督学习",
    "translated_abstract": "我们提出了神经谱方法，这是一种在经典谱方法基础上解决参数化偏微分方程（PDE）问题的技术。我们的方法使用正交基来学习PDE解作为谱系数之间的映射。与当前的机器学习方法相比，这些方法通过在时空域中最小化残差的数值积分来强制PDE约束条件，我们利用Parseval恒等式并引入一种新的训练策略，即谱损失。我们的谱损失通过神经网络实现了更高效的求导，并极大地降低了训练复杂度。在推理时间，我们的方法的计算成本保持恒定，不受时空域分辨率的影响。我们的实验结果表明，我们的方法在速度和准确性方面显著优于之前的机器学习方法，多个不同问题上的性能提高了一到两个数量级。",
    "tldr": "神经谱方法将经典谱方法与机器学习相结合，通过谱损失实现更高效的求导，大大降低了训练复杂度，并在速度和准确性方面显著超过之前的机器学习方法。",
    "en_tdlr": "Neural Spectral Methods combine classical spectral methods with machine learning, achieve more efficient differentiation through spectral loss, significantly reduce training complexity, and outperform previous machine learning methods in terms of speed and accuracy."
}