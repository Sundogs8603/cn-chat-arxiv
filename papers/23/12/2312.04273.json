{
    "title": "Invariant Random Forest: Tree-Based Model Solution for OOD Generalization. (arXiv:2312.04273v3 [cs.LG] UPDATED)",
    "abstract": "Out-Of-Distribution (OOD) generalization is an essential topic in machine learning. However, recent research is only focusing on the corresponding methods for neural networks. This paper introduces a novel and effective solution for OOD generalization of decision tree models, named Invariant Decision Tree (IDT). IDT enforces a penalty term with regard to the unstable/varying behavior of a split across different environments during the growth of the tree. Its ensemble version, the Invariant Random Forest (IRF), is constructed. Our proposed method is motivated by a theoretical result under mild conditions, and validated by numerical tests with both synthetic and real datasets. The superior performance compared to non-OOD tree models implies that considering OOD generalization for tree models is absolutely necessary and should be given more attention.",
    "link": "http://arxiv.org/abs/2312.04273",
    "context": "Title: Invariant Random Forest: Tree-Based Model Solution for OOD Generalization. (arXiv:2312.04273v3 [cs.LG] UPDATED)\nAbstract: Out-Of-Distribution (OOD) generalization is an essential topic in machine learning. However, recent research is only focusing on the corresponding methods for neural networks. This paper introduces a novel and effective solution for OOD generalization of decision tree models, named Invariant Decision Tree (IDT). IDT enforces a penalty term with regard to the unstable/varying behavior of a split across different environments during the growth of the tree. Its ensemble version, the Invariant Random Forest (IRF), is constructed. Our proposed method is motivated by a theoretical result under mild conditions, and validated by numerical tests with both synthetic and real datasets. The superior performance compared to non-OOD tree models implies that considering OOD generalization for tree models is absolutely necessary and should be given more attention.",
    "path": "papers/23/12/2312.04273.json",
    "total_tokens": 945,
    "translated_title": "不变随机森林：基于树模型的ODD泛化解决方案",
    "translated_abstract": "在机器学习中，Out-Of-Distribution（OOD）泛化是一个重要的主题。然而，最近的研究只关注神经网络的相应方法。本文引入了一种新颖且有效的解决方案，用于决策树模型的OOD泛化，称为不变决策树（IDT）。IDT通过在树的生长过程中关于在不同环境下分裂的不稳定/变化行为的惩罚项来推动其发展。其集成版本，不变随机森林（IRF）被构建。我们提出的方法受到了一个在温和条件下的理论结果的启发，并通过合成和实际数据集的数值测试进行了验证。与非OOD树模型相比的优越性能意味着，考虑树模型的OOD泛化是绝对必要的，应该给予更多关注。",
    "tldr": "本文引入了一种新颖且有效的解决方案，用于决策树模型的OOD泛化，称为不变决策树（IDT）。该方法通过在树的生长过程中惩罚不同环境下分裂的不稳定行为，构建了不变随机森林（IRF）。验证实验证明，相比非OOD树模型，该方法表现出更好的性能，强调了考虑树模型的OOD泛化的必要性。"
}