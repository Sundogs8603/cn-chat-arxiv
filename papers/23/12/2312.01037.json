{
    "title": "Eliciting Latent Knowledge from Quirky Language Models",
    "abstract": "Eliciting Latent Knowledge (ELK) aims to find patterns in a capable neural network's activations which robustly track the true state of the world, even when the network's overt output is false or misleading. To further ELK research, we introduce 12 datasets and a corresponding suite of \"quirky\" language models that are LoRA finetuned to make systematic errors when answering questions if and only if the keyword \"Bob\" is present in the prompt. We demonstrate that simple probing methods can elicit the model's latent knowledge of the correct answer in these contexts, even for problems harder than those the probe was trained on. This is enabled by context-independent knowledge representations located in middle layer activations. We also find that a mechanistic anomaly detection approach can flag untruthful behavior with 94% AUROC. Our results show promise for eliciting reliable knowledge from capable but untrusted models, and facilitates future research empirically investigating ELK methods",
    "link": "https://arxiv.org/abs/2312.01037",
    "context": "Title: Eliciting Latent Knowledge from Quirky Language Models\nAbstract: Eliciting Latent Knowledge (ELK) aims to find patterns in a capable neural network's activations which robustly track the true state of the world, even when the network's overt output is false or misleading. To further ELK research, we introduce 12 datasets and a corresponding suite of \"quirky\" language models that are LoRA finetuned to make systematic errors when answering questions if and only if the keyword \"Bob\" is present in the prompt. We demonstrate that simple probing methods can elicit the model's latent knowledge of the correct answer in these contexts, even for problems harder than those the probe was trained on. This is enabled by context-independent knowledge representations located in middle layer activations. We also find that a mechanistic anomaly detection approach can flag untruthful behavior with 94% AUROC. Our results show promise for eliciting reliable knowledge from capable but untrusted models, and facilitates future research empirically investigating ELK methods",
    "path": "papers/23/12/2312.01037.json",
    "total_tokens": 893,
    "translated_title": "从古怪的语言模型中调取潜在知识",
    "translated_abstract": "调取潜在知识（ELK）旨在在一个能力强大的神经网络的激活中找到模式，即使网络的明显输出是错误或误导性的，也能稳定跟踪世界的真实状态。为了进一步研究ELK，我们引入了12个数据集和一套相应的“古怪”的语言模型，这些模型在回答问题时，只有在提示中包含关键词“Bob”时才会进行系统性错误的微调。我们证明了简单的探测方法可以调取模型在这些上下文中对正确答案的潜在知识，即使问题比探测器训练的问题更困难。这是由于中间层激活中的上下文无关的知识表示的存在。我们还发现，一种机械的异常检测方法可以以94%的AUROC标识不真实行为。我们的结果显示，从能力强但不受信任的模型中调取可靠的知识，并促进未来研究ELK方法的实证研究是有希望的。",
    "tldr": "本研究通过引入一套“古怪”的语言模型，调取了这些模型在特定上下文中的潜在知识，展示了从可信度低的模型中调取可靠知识的前景。",
    "en_tdlr": "This study presents the potential of eliciting reliable knowledge from untrusted models by introducing a set of \"quirky\" language models and probing their latent knowledge in specific contexts."
}