{
    "title": "Cascade Speculative Drafting for Even Faster LLM Inference",
    "abstract": "arXiv:2312.11462v3 Announce Type: replace-cross  Abstract: Introduced to enhance the efficiency of large language model (LLM) inference, speculative decoding operates by having a smaller model generate a draft. A larger target model then reviews this draft to align with its output, and any acceptance by the target model results in a reduction of the number of the target model runs, ultimately improving efficiency. However, the drafting process in speculative decoding includes slow autoregressive generation and allocates equal time to generating tokens, irrespective of their importance. These inefficiencies collectively contribute to the suboptimal performance of speculative decoding. To further improve LLM inference, we introduce Cascade Speculative Drafting (CS Drafting), a speculative execution algorithm that incorporates two types of cascades. The Vertical Cascade eliminates autoregressive generation from neural models, while the Horizontal Cascade optimizes time allocation in draft",
    "link": "https://arxiv.org/abs/2312.11462",
    "context": "Title: Cascade Speculative Drafting for Even Faster LLM Inference\nAbstract: arXiv:2312.11462v3 Announce Type: replace-cross  Abstract: Introduced to enhance the efficiency of large language model (LLM) inference, speculative decoding operates by having a smaller model generate a draft. A larger target model then reviews this draft to align with its output, and any acceptance by the target model results in a reduction of the number of the target model runs, ultimately improving efficiency. However, the drafting process in speculative decoding includes slow autoregressive generation and allocates equal time to generating tokens, irrespective of their importance. These inefficiencies collectively contribute to the suboptimal performance of speculative decoding. To further improve LLM inference, we introduce Cascade Speculative Drafting (CS Drafting), a speculative execution algorithm that incorporates two types of cascades. The Vertical Cascade eliminates autoregressive generation from neural models, while the Horizontal Cascade optimizes time allocation in draft",
    "path": "papers/23/12/2312.11462.json",
    "total_tokens": 827,
    "translated_title": "用于更快的LLM推理的级联推测草图",
    "translated_abstract": "引入了增强大型语言模型（LLM）推理效率的级联推测草图，通过较小的模型生成草稿来运作。较大的目标模型然后查看这个草稿以与其输出对齐，目标模型的任何接受都将减少目标模型运行的数量，从而提高效率。然而，在级联推测的草图过程中包括缓慢的自回归生成，并为生成的标记分配相同的时间，而不考虑它们的重要性。这些低效性共同导致级联推测的性能不佳。为了进一步改善LLM推理，我们引入了级联推测草图（CS Drafting），这是一种整合了两种级联类型的推测执行算法。垂直级联从神经模型中消除自回归生成，而水平级联优化了草稿中的时间分配",
    "tldr": "引入了Cascade Speculative Drafting（CS Drafting）算法，通过垂直级联消除神经模型的自回归生成，通过水平级联优化草稿中的时间分配，从而进一步提高LLM推理效率。",
    "en_tdlr": "Introduced Cascade Speculative Drafting (CS Drafting) algorithm, which eliminates autoregressive generation from neural models through Vertical Cascade and optimizes time allocation in drafts through Horizontal Cascade, to further improve LLM inference efficiency."
}