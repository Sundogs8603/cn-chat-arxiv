{
    "title": "Less or More From Teacher: Exploiting Trilateral Geometry For Knowledge Distillation",
    "abstract": "arXiv:2312.15112v3 Announce Type: replace  Abstract: Knowledge distillation aims to train a compact student network using soft supervision from a larger teacher network and hard supervision from ground truths. However, determining an optimal knowledge fusion ratio that balances these supervisory signals remains challenging. Prior methods generally resort to a constant or heuristic-based fusion ratio, which often falls short of a proper balance. In this study, we introduce a novel adaptive method for learning a sample-wise knowledge fusion ratio, exploiting both the correctness of teacher and student, as well as how well the student mimics the teacher on each sample. Our method naturally leads to the intra-sample trilateral geometric relations among the student prediction ($S$), teacher prediction ($T$), and ground truth ($G$). To counterbalance the impact of outliers, we further extend to the inter-sample relations, incorporating the teacher's global average prediction $\\bar{T}$ for sa",
    "link": "https://arxiv.org/abs/2312.15112",
    "context": "Title: Less or More From Teacher: Exploiting Trilateral Geometry For Knowledge Distillation\nAbstract: arXiv:2312.15112v3 Announce Type: replace  Abstract: Knowledge distillation aims to train a compact student network using soft supervision from a larger teacher network and hard supervision from ground truths. However, determining an optimal knowledge fusion ratio that balances these supervisory signals remains challenging. Prior methods generally resort to a constant or heuristic-based fusion ratio, which often falls short of a proper balance. In this study, we introduce a novel adaptive method for learning a sample-wise knowledge fusion ratio, exploiting both the correctness of teacher and student, as well as how well the student mimics the teacher on each sample. Our method naturally leads to the intra-sample trilateral geometric relations among the student prediction ($S$), teacher prediction ($T$), and ground truth ($G$). To counterbalance the impact of outliers, we further extend to the inter-sample relations, incorporating the teacher's global average prediction $\\bar{T}$ for sa",
    "path": "papers/23/12/2312.15112.json",
    "total_tokens": 891,
    "translated_title": "从教师那里少或多：利用三边几何进行知识蒸馏",
    "translated_abstract": "知识蒸馏旨在使用来自较大教师网络的软监督和来自真实数据的硬监督来训练一个紧凑的学生网络。然而，确定一个平衡这些监督信号的最佳知识融合比率仍然具有挑战性。在本研究中，我们介绍了一种新颖的自适应方法，用于学习每个样本的知识融合比率，利用教师和学生的正确性，以及学生在每个样本上模仿教师的程度。我们的方法自然地导致了学生预测($S$)、教师预测($T$)和地面真相($G$)之间的样本内三边几何关系。为了抵消异常值的影响，我们进一步扩展到样本间的关系，将教师的全局平均预测$\\bar{T}$纳入考虑。",
    "tldr": "该研究提出了一种新颖的自适应方法，利用教师和学生的正确性以及学生对教师模仿程度来学习每个样本的知识融合比率，从而引入了样本内三边几何关系。"
}