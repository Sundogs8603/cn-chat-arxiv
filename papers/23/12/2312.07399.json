{
    "title": "Large Language Models are Clinical Reasoners: Reasoning-Aware Diagnosis Framework with Prompt-Generated Rationales",
    "abstract": "Machine reasoning has made great progress in recent years owing to large language models (LLMs). In the clinical domain, however, most NLP-driven projects mainly focus on clinical classification or reading comprehension, and under-explore clinical reasoning for disease diagnosis due to the expensive rationale annotation with clinicians. In this work, we present a ``reasoning-aware'' diagnosis framework that rationalizes the diagnostic process via prompt-based learning in a time- and labor-efficient manner, and learns to reason over the prompt-generated rationales. Specifically, we address the clinical reasoning for disease diagnosis, where the LLM generates diagnostic rationales providing its insight on presented patient data and the reasoning path towards the diagnosis, namely Clinical Chain-of-Thought (Clinical CoT). We empirically demonstrate LLMs/LMs' ability of clinical reasoning via extensive experiments and analyses on both rationale generation and disease diagnosis in various s",
    "link": "https://arxiv.org/abs/2312.07399",
    "context": "Title: Large Language Models are Clinical Reasoners: Reasoning-Aware Diagnosis Framework with Prompt-Generated Rationales\nAbstract: Machine reasoning has made great progress in recent years owing to large language models (LLMs). In the clinical domain, however, most NLP-driven projects mainly focus on clinical classification or reading comprehension, and under-explore clinical reasoning for disease diagnosis due to the expensive rationale annotation with clinicians. In this work, we present a ``reasoning-aware'' diagnosis framework that rationalizes the diagnostic process via prompt-based learning in a time- and labor-efficient manner, and learns to reason over the prompt-generated rationales. Specifically, we address the clinical reasoning for disease diagnosis, where the LLM generates diagnostic rationales providing its insight on presented patient data and the reasoning path towards the diagnosis, namely Clinical Chain-of-Thought (Clinical CoT). We empirically demonstrate LLMs/LMs' ability of clinical reasoning via extensive experiments and analyses on both rationale generation and disease diagnosis in various s",
    "path": "papers/23/12/2312.07399.json",
    "total_tokens": 914,
    "translated_title": "大型语言模型是临床推理者：基于提示生成的理由的推理感知诊断框架",
    "translated_abstract": "由于大型语言模型（LLMs）的进展，机器推理在近年来取得了巨大的进展。然而，在临床领域，大多数以自然语言处理为驱动的项目主要集中在临床分类或阅读理解上，并且由于与临床医生的理念注解成本较高，对于疾病诊断的临床推理还未得到充分的研究。在这项工作中，我们提出了一个“推理感知”的诊断框架，通过基于提示的学习以一种高效的时间和劳动方式去理性化诊断过程，并学习对提示生成的理由进行推理。具体而言，我们解决了疾病诊断的临床推理问题，其中LLM生成了诊断性的理由，提供其对呈现的患者数据的见解以及达到诊断的推理路径，即临床思维链（Clinical CoT）。我们通过广泛的实验和分析在理由生成和疾病诊断方面实证了LLMs/LMs的临床推理能力。",
    "tldr": "该论文提出了一种基于提示生成的理由的“推理感知”诊断框架，通过大型语言模型来进行临床推理，实现了在疾病诊断过程中的高效、时间节约和劳动节约的方法。",
    "en_tdlr": "This paper presents a \"reasoning-aware\" diagnosis framework that utilizes prompt-generated rationales and large language models for clinical reasoning, achieving efficient, time-saving, and labor-saving methods in disease diagnosis."
}