{
    "title": "On the Learnability of Watermarks for Language Models. (arXiv:2312.04469v2 [cs.LG] UPDATED)",
    "abstract": "Watermarking of language model outputs enables statistical detection of model-generated text, which has many applications in the responsible deployment of language models. Existing watermarking strategies operate by altering the decoder of an existing language model, and the ability for a language model to directly learn to generate the watermark would have significant implications for the real-world deployment of watermarks. First, learned watermarks could be used to build open models that naturally generate watermarked text, allowing for open models to benefit from watermarking. Second, if watermarking is used to determine the provenance of generated text, an adversary can hurt the reputation of a victim model by spoofing its watermark and generating damaging watermarked text. To investigate the learnability of watermarks, we propose watermark distillation, which trains a student model to behave like a teacher model that uses decoding-based watermarking. We test our approach on three",
    "link": "http://arxiv.org/abs/2312.04469",
    "context": "Title: On the Learnability of Watermarks for Language Models. (arXiv:2312.04469v2 [cs.LG] UPDATED)\nAbstract: Watermarking of language model outputs enables statistical detection of model-generated text, which has many applications in the responsible deployment of language models. Existing watermarking strategies operate by altering the decoder of an existing language model, and the ability for a language model to directly learn to generate the watermark would have significant implications for the real-world deployment of watermarks. First, learned watermarks could be used to build open models that naturally generate watermarked text, allowing for open models to benefit from watermarking. Second, if watermarking is used to determine the provenance of generated text, an adversary can hurt the reputation of a victim model by spoofing its watermark and generating damaging watermarked text. To investigate the learnability of watermarks, we propose watermark distillation, which trains a student model to behave like a teacher model that uses decoding-based watermarking. We test our approach on three",
    "path": "papers/23/12/2312.04469.json",
    "total_tokens": 935,
    "translated_title": "论语言模型的水印可学习性研究",
    "translated_abstract": "语言模型输出的水印可以实现对模型生成文本的统计检测，广泛应用于语言模型的负责任部署中。现有的水印策略通过改变现有语言模型的解码器来操作，而语言模型直接学习生成水印的能力将对水印在实际应用中产生重要影响。首先，学习得到的水印可以用于构建能自然生成带水印文本的开放模型，使开放模型也能从水印中受益。其次，如果水印用于确定生成文本的来源，攻击者可以通过伪造水印并生成有害的带水印文本来损害受害模型的声誉。为了研究水印的可学习性，我们提出了水印蒸馏方法，该方法通过训练学生模型使其行为类似于使用基于解码的水印的教师模型。我们在三个实验数据集上测试了我们的方法。",
    "tldr": "该论文研究了语言模型水印的可学习性，提出了水印蒸馏方法，通过训练学生模型使其模仿使用解码水印的教师模型的行为。结果表明，语言模型具有直接学习生成水印的能力，这对于水印的实际应用具有重要影响。",
    "en_tdlr": "This paper investigates the learnability of watermarks for language models and proposes watermark distillation, a method that trains a student model to mimic the behavior of a teacher model using decoding-based watermarking. The results show that language models have the ability to directly learn to generate watermarks, which has significant implications for the practical application of watermarks."
}