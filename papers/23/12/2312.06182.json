{
    "title": "Why \"classic\" Transformers are shallow and how to make them go deep",
    "abstract": "Since its introduction in 2017, Transformer has emerged as the leading neural network architecture, catalyzing revolutionary advancements in many AI disciplines. The key innovation in Transformer is a Self-Attention (SA) mechanism designed to capture contextual information. However, extending the original Transformer design to models of greater depth has proven exceedingly challenging, if not impossible. Even though various modifications have been proposed in order to stack more layers of SA mechanism into deeper models, a full understanding of this depth problem remains lacking. In this paper, we conduct a comprehensive investigation, both theoretically and empirically, to substantiate the claim that the depth problem is caused by \\emph{token similarity escalation}; that is, tokens grow increasingly alike after repeated applications of the SA mechanism. Our analysis reveals that, driven by the invariant leading eigenspace and large spectral gaps of attention matrices, token similarity",
    "link": "https://rss.arxiv.org/abs/2312.06182",
    "context": "Title: Why \"classic\" Transformers are shallow and how to make them go deep\nAbstract: Since its introduction in 2017, Transformer has emerged as the leading neural network architecture, catalyzing revolutionary advancements in many AI disciplines. The key innovation in Transformer is a Self-Attention (SA) mechanism designed to capture contextual information. However, extending the original Transformer design to models of greater depth has proven exceedingly challenging, if not impossible. Even though various modifications have been proposed in order to stack more layers of SA mechanism into deeper models, a full understanding of this depth problem remains lacking. In this paper, we conduct a comprehensive investigation, both theoretically and empirically, to substantiate the claim that the depth problem is caused by \\emph{token similarity escalation}; that is, tokens grow increasingly alike after repeated applications of the SA mechanism. Our analysis reveals that, driven by the invariant leading eigenspace and large spectral gaps of attention matrices, token similarity",
    "path": "papers/23/12/2312.06182.json",
    "total_tokens": 849,
    "translated_title": "\"为什么“经典”的Transformer模型是肤浅的以及如何使它们变得更深入\"",
    "translated_abstract": "自其在2017年的引入以来，Transformer已成为领先的神经网络架构，在许多人工智能领域实现了革命性的进展。Transformer的关键创新是自注意力（SA）机制，旨在捕捉上下文信息。然而，将原始的Transformer设计扩展为更深层次的模型已被证明极具挑战性，甚至无法实现。尽管已提出各种修改来将更多层的SA机制堆叠到更深层次的模型中，但对于这个深度问题的完全理解仍然缺乏。在本文中，我们进行了全面的理论和实证调查，证实了深度问题是由于“token相似性升级”引起的；也就是说，在重复应用SA机制后，token逐渐变得越来越相似。我们的分析揭示了，受到注意力矩阵不变的特征空间和大的频谱间隙的驱动，token的相似性逐渐增加。",
    "tldr": "这篇论文研究了Transformer模型的深度问题，指出这个问题是由于“token相似性升级”导致的，提供了理论和实证调查的证据。",
    "en_tdlr": "This paper investigates the depth problem of the Transformer model and identifies that it is caused by \"token similarity escalation\", providing theoretical and empirical evidence."
}