{
    "title": "Evolving Reservoirs for Meta Reinforcement Learning. (arXiv:2312.06695v2 [cs.LG] UPDATED)",
    "abstract": "Animals often demonstrate a remarkable ability to adapt to their environments during their lifetime. They do so partly due to the evolution of morphological and neural structures. These structures capture features of environments shared between generations to bias and speed up lifetime learning. In this work, we propose a computational model for studying a mechanism that can enable such a process. We adopt a computational framework based on meta reinforcement learning as a model of the interplay between evolution and development. At the evolutionary scale, we evolve reservoirs, a family of recurrent neural networks that differ from conventional networks in that one optimizes not the synaptic weights, but hyperparameters controlling macro-level properties of the resulting network architecture. At the developmental scale, we employ these evolved reservoirs to facilitate the learning of a behavioral policy through Reinforcement Learning (RL). Within an RL agent, a reservoir encodes the en",
    "link": "http://arxiv.org/abs/2312.06695",
    "context": "Title: Evolving Reservoirs for Meta Reinforcement Learning. (arXiv:2312.06695v2 [cs.LG] UPDATED)\nAbstract: Animals often demonstrate a remarkable ability to adapt to their environments during their lifetime. They do so partly due to the evolution of morphological and neural structures. These structures capture features of environments shared between generations to bias and speed up lifetime learning. In this work, we propose a computational model for studying a mechanism that can enable such a process. We adopt a computational framework based on meta reinforcement learning as a model of the interplay between evolution and development. At the evolutionary scale, we evolve reservoirs, a family of recurrent neural networks that differ from conventional networks in that one optimizes not the synaptic weights, but hyperparameters controlling macro-level properties of the resulting network architecture. At the developmental scale, we employ these evolved reservoirs to facilitate the learning of a behavioral policy through Reinforcement Learning (RL). Within an RL agent, a reservoir encodes the en",
    "path": "papers/23/12/2312.06695.json",
    "total_tokens": 900,
    "translated_title": "进化沉积池用于元增强学习",
    "translated_abstract": "动物在其一生中经常展示出对环境的适应能力，部分原因是由于形态和神经结构的演化。这些结构捕捉到了代际之间共享的环境特征，以加速和引导一生中的学习过程。在这项工作中，我们提出了一个计算模型来研究实现这一过程的机制。我们采用基于元增强学习的计算框架作为演化和发展之间相互作用的模型。在演化尺度上，我们演化沉积池，这是一族循环神经网络，与常规网络不同的是，我们优化的不是突触权重，而是控制结果网络架构的宏观级别属性的超参数。在发展尺度上，我们使用这些进化沉积池来促进通过强化学习来学习行为策略。在强化学习代理中，沉积池编码环境的信息以优化学习过程。",
    "tldr": "本论文提出了一种进化沉积池的计算模型，用于研究动物适应环境的机制。这种模型基于元增强学习框架，通过演化和发展之间的相互作用，利用进化沉积池来加速和引导强化学习过程。"
}