{
    "title": "HybridNeRF: Efficient Neural Rendering via Adaptive Volumetric Surfaces",
    "abstract": "arXiv:2312.03160v2 Announce Type: replace-cross  Abstract: Neural radiance fields provide state-of-the-art view synthesis quality but tend to be slow to render. One reason is that they make use of volume rendering, thus requiring many samples (and model queries) per ray at render time. Although this representation is flexible and easy to optimize, most real-world objects can be modeled more efficiently with surfaces instead of volumes, requiring far fewer samples per ray. This observation has spurred considerable progress in surface representations such as signed distance functions, but these may struggle to model semi-opaque and thin structures. We propose a method, HybridNeRF, that leverages the strengths of both representations by rendering most objects as surfaces while modeling the (typically) small fraction of challenging regions volumetrically. We evaluate HybridNeRF against the challenging Eyeful Tower dataset along with other commonly used view synthesis datasets. When compari",
    "link": "https://arxiv.org/abs/2312.03160",
    "context": "Title: HybridNeRF: Efficient Neural Rendering via Adaptive Volumetric Surfaces\nAbstract: arXiv:2312.03160v2 Announce Type: replace-cross  Abstract: Neural radiance fields provide state-of-the-art view synthesis quality but tend to be slow to render. One reason is that they make use of volume rendering, thus requiring many samples (and model queries) per ray at render time. Although this representation is flexible and easy to optimize, most real-world objects can be modeled more efficiently with surfaces instead of volumes, requiring far fewer samples per ray. This observation has spurred considerable progress in surface representations such as signed distance functions, but these may struggle to model semi-opaque and thin structures. We propose a method, HybridNeRF, that leverages the strengths of both representations by rendering most objects as surfaces while modeling the (typically) small fraction of challenging regions volumetrically. We evaluate HybridNeRF against the challenging Eyeful Tower dataset along with other commonly used view synthesis datasets. When compari",
    "path": "papers/23/12/2312.03160.json",
    "total_tokens": 834,
    "translated_title": "HybridNeRF：通过自适应体积表面实现高效神经渲染",
    "translated_abstract": "神经辐射场提供了最先进的视图合成质量，但渲染速度较慢。一个原因是它们利用体素渲染，在渲染时需要每个光线进行许多采样（和模型查询）。尽管这种表示灵活且易于优化，但大多数现实世界的对象可以更有效地用表面而不是体积建模，从而每个光线需要更少的采样。这一观察促成了对表面表示的实质性进展，如符号距离函数，但这些可能难以建模半透明和薄结构。我们提出了一种方法，HybridNeRF，通过将大多数对象呈现为表面，同时对（通常）小部分具有挑战性的区域进行体积建模，从而利用这两种表示的优势。我们评估了HybridNeRF在具有挑战性的Eyeful Tower数据集以及其他常用视图合成数据集上的性能。",
    "tldr": "HybridNeRF方法将大多数对象呈现为表面，仅对少部分具有挑战性的区域进行体积建模，实现了神经渲染的高效率。",
    "en_tdlr": "HybridNeRF method renders most objects as surfaces and only volumetrically models a small fraction of challenging regions, achieving efficient neural rendering."
}