{
    "title": "Prompting in Autoregressive Large Language Models",
    "abstract": "arXiv:2312.03740v1 Announce Type: cross  Abstract: Autoregressive Large Language Models have transformed the landscape of Natural Language Processing. Pre-train and prompt paradigm has replaced the conventional approach of pre-training and fine-tuning for many downstream NLP tasks. This shift has been possible largely due to LLMs and innovative prompting techniques. LLMs have shown great promise for a variety of downstream tasks owing to their vast parameters and huge datasets that they are pre-trained on. However, in order to fully realize their potential, their outputs must be guided towards the desired outcomes. Prompting, in which a specific input or instruction is provided to guide the LLMs toward the intended output, has become a tool for achieving this goal. In this paper, we discuss the various prompting techniques that have been applied to fully harness the power of LLMs. We present a taxonomy of existing literature on prompting techniques and provide a concise survey based on",
    "link": "https://arxiv.org/abs/2312.03740",
    "context": "Title: Prompting in Autoregressive Large Language Models\nAbstract: arXiv:2312.03740v1 Announce Type: cross  Abstract: Autoregressive Large Language Models have transformed the landscape of Natural Language Processing. Pre-train and prompt paradigm has replaced the conventional approach of pre-training and fine-tuning for many downstream NLP tasks. This shift has been possible largely due to LLMs and innovative prompting techniques. LLMs have shown great promise for a variety of downstream tasks owing to their vast parameters and huge datasets that they are pre-trained on. However, in order to fully realize their potential, their outputs must be guided towards the desired outcomes. Prompting, in which a specific input or instruction is provided to guide the LLMs toward the intended output, has become a tool for achieving this goal. In this paper, we discuss the various prompting techniques that have been applied to fully harness the power of LLMs. We present a taxonomy of existing literature on prompting techniques and provide a concise survey based on",
    "path": "papers/23/12/2312.03740.json",
    "total_tokens": 794,
    "translated_title": "自回归大型语言模型中的提示",
    "translated_abstract": "自回归大型语言模型已经改变了自然语言处理的格局。预训练和提示范式已经取代了许多下游NLP任务常规的预训练和微调方法。这种转变主要得益于LLMs和创新的提示技术。LLMs显示出巨大的潜力用于各种下游任务，这归功于它们在预训练中使用的大量参数和庞大数据集。然而，为了充分发挥它们的潜力，必须引导它们的输出朝着期望的结果。提示，即提供特定的输入或指令来引导LLMs朝着预期输出的方向发展，已成为实现这一目标的工具。本文讨论了已被应用来充分利用LLMs潜力的各种提示技术。我们提出了现有文献中关于提示技术的分类，并根据其进行了简明调查。",
    "tldr": "LLMs通过创新的提示技术实现了预训练和提示范式的转变，以大大提高下游NLP任务的效果。",
    "en_tdlr": "LLMs have shifted the paradigm by utilizing innovative prompting techniques to significantly improve the effectiveness of downstream NLP tasks."
}