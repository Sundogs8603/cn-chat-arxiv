{
    "title": "DTL: Disentangled Transfer Learning for Visual Recognition",
    "abstract": "When pre-trained models become rapidly larger, the cost of fine-tuning on downstream tasks steadily increases, too. To economically fine-tune these models, parameter-efficient transfer learning (PETL) is proposed, which only tunes a tiny subset of trainable parameters to efficiently learn quality representations. However, current PETL methods are facing the dilemma that during training the GPU memory footprint is not effectively reduced as trainable parameters. PETL will likely fail, too, if the full fine-tuning encounters the out-of-GPU-memory issue. This phenomenon happens because trainable parameters from these methods are generally entangled with the backbone, such that a lot of intermediate states have to be stored in GPU memory for gradient propagation. To alleviate this problem, we introduce Disentangled Transfer Learning (DTL), which disentangles the trainable parameters from the backbone using a lightweight Compact Side Network (CSN). By progressively extracting task-specific ",
    "link": "https://rss.arxiv.org/abs/2312.07856",
    "context": "Title: DTL: Disentangled Transfer Learning for Visual Recognition\nAbstract: When pre-trained models become rapidly larger, the cost of fine-tuning on downstream tasks steadily increases, too. To economically fine-tune these models, parameter-efficient transfer learning (PETL) is proposed, which only tunes a tiny subset of trainable parameters to efficiently learn quality representations. However, current PETL methods are facing the dilemma that during training the GPU memory footprint is not effectively reduced as trainable parameters. PETL will likely fail, too, if the full fine-tuning encounters the out-of-GPU-memory issue. This phenomenon happens because trainable parameters from these methods are generally entangled with the backbone, such that a lot of intermediate states have to be stored in GPU memory for gradient propagation. To alleviate this problem, we introduce Disentangled Transfer Learning (DTL), which disentangles the trainable parameters from the backbone using a lightweight Compact Side Network (CSN). By progressively extracting task-specific ",
    "path": "papers/23/12/2312.07856.json",
    "total_tokens": 845,
    "translated_title": "DTL: 视觉识别的解缠式迁移学习",
    "translated_abstract": "当预训练模型变得越来越庞大时，对下游任务进行微调的成本也在稳步增加。为了经济地进行这些模型的微调，我们提出了参数高效的迁移学习（PETL），它只调整了一小部分可训练参数，以有效地学习高质量的表示。然而，当前的PETL方法面临的困境是，在训练过程中，GPU内存占用并没有像可训练参数一样得到有效降低。如果全面进行微调遇到了超出GPU内存的问题，PETL方法很可能也会失败。这种现象的出现是因为这些方法中的可训练参数通常与主干网络纠缠在一起，导致在梯度传播过程中需要在GPU内存中存储大量的中间状态。为了缓解这个问题，我们引入了解缠式迁移学习（DTL），它通过一个轻量级的紧凑侧网络（CSN）将可训练参数从主干网络中解缠出来。",
    "tldr": "DTL通过使用紧凑侧网络（CSN）将可训练参数从主干网络中解缠出来，以缓解在迁移学习中GPU内存占用过多的问题。"
}