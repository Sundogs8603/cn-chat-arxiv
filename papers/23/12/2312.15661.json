{
    "title": "Unlocking the Potential of Large Language Models for Explainable Recommendations. (arXiv:2312.15661v3 [cs.IR] UPDATED)",
    "abstract": "Generating user-friendly explanations regarding why an item is recommended has become increasingly common, largely due to advances in language generation technology, which can enhance user trust and facilitate more informed decision-making when using online services. However, existing explainable recommendation systems focus on using small-size language models. It remains uncertain what impact replacing the explanation generator with the recently emerging large language models (LLMs) would have. Can we expect unprecedented results?  In this study, we propose LLMXRec, a simple yet effective two-stage explainable recommendation framework aimed at further boosting the explanation quality by employing LLMs. Unlike most existing LLM-based recommendation works, a key characteristic of LLMXRec is its emphasis on the close collaboration between previous recommender models and LLM-based explanation generators. Specifically, by adopting several key fine-tuning techniques, including parameter-eff",
    "link": "http://arxiv.org/abs/2312.15661",
    "context": "Title: Unlocking the Potential of Large Language Models for Explainable Recommendations. (arXiv:2312.15661v3 [cs.IR] UPDATED)\nAbstract: Generating user-friendly explanations regarding why an item is recommended has become increasingly common, largely due to advances in language generation technology, which can enhance user trust and facilitate more informed decision-making when using online services. However, existing explainable recommendation systems focus on using small-size language models. It remains uncertain what impact replacing the explanation generator with the recently emerging large language models (LLMs) would have. Can we expect unprecedented results?  In this study, we propose LLMXRec, a simple yet effective two-stage explainable recommendation framework aimed at further boosting the explanation quality by employing LLMs. Unlike most existing LLM-based recommendation works, a key characteristic of LLMXRec is its emphasis on the close collaboration between previous recommender models and LLM-based explanation generators. Specifically, by adopting several key fine-tuning techniques, including parameter-eff",
    "path": "papers/23/12/2312.15661.json",
    "total_tokens": 942,
    "translated_title": "大型语言模型在可解释推荐中的潜力解锁",
    "translated_abstract": "生成关于为何推荐某个项目的用户友好解释已经变得越来越常见，这主要归功于语言生成技术的进步，这可以增强用户的信任并在使用在线服务时促进更明智的决策。然而，现有的可解释推荐系统主要使用小型语言模型。目前尚不清楚将解释生成器替换为最近出现的大型语言模型（LLMs）会产生何种影响。我们能否期望前所未有的结果？在这项研究中，我们提出了LLMXRec，一个简单而有效的两阶段可解释推荐框架，旨在通过使用LLMs进一步提高解释质量。与大多数现有的基于LLM的推荐工作不同，LLMXRec的一个重要特点是它强调先前的推荐模型与基于LLM的解释生成器之间的密切协作。具体而言，通过采用几种关键的微调技术，包括参数调优技术，我们的方法在推荐效果和解释质量方面实现了显著提升。",
    "tldr": "本研究提出了LLMXRec框架，一种简单而有效的两阶段解释推荐方法，利用大型语言模型进一步提升解释质量，通过与先前的推荐模型密切协作，在推荐效果和解释质量方面取得了显著提升。",
    "en_tdlr": "This study proposes LLMXRec, a simple yet effective two-stage explainable recommendation framework, which leverages large language models to enhance the quality of explanations. By closely collaborating with previous recommender models, LLMXRec achieves significant improvements in recommendation performance and explanation quality."
}