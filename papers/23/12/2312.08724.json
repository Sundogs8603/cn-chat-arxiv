{
    "title": "Personalized Path Recourse for Reinforcement Learning Agents",
    "abstract": "arXiv:2312.08724v2 Announce Type: replace-cross  Abstract: This paper introduces Personalized Path Recourse, a novel method that generates recourse paths for a reinforcement learning agent. The goal is to edit a given path of actions to achieve desired goals (e.g., better outcomes compared to the agent's original path) while ensuring a high similarity to the agent's original paths and being personalized to the agent. Personalization refers to the extent to which the new path is tailored to the agent's observed behavior patterns from their policy function. We train a personalized recourse agent to generate such personalized paths, which are obtained using reward functions that consider the goal, similarity, and personalization. The proposed method is applicable to both reinforcement learning and supervised learning settings for correcting or improving sequences of actions or sequences of data to achieve a pre-determined goal. The method is evaluated in various settings. Experiments show",
    "link": "https://arxiv.org/abs/2312.08724",
    "context": "Title: Personalized Path Recourse for Reinforcement Learning Agents\nAbstract: arXiv:2312.08724v2 Announce Type: replace-cross  Abstract: This paper introduces Personalized Path Recourse, a novel method that generates recourse paths for a reinforcement learning agent. The goal is to edit a given path of actions to achieve desired goals (e.g., better outcomes compared to the agent's original path) while ensuring a high similarity to the agent's original paths and being personalized to the agent. Personalization refers to the extent to which the new path is tailored to the agent's observed behavior patterns from their policy function. We train a personalized recourse agent to generate such personalized paths, which are obtained using reward functions that consider the goal, similarity, and personalization. The proposed method is applicable to both reinforcement learning and supervised learning settings for correcting or improving sequences of actions or sequences of data to achieve a pre-determined goal. The method is evaluated in various settings. Experiments show",
    "path": "papers/23/12/2312.08724.json",
    "total_tokens": 881,
    "translated_title": "针对增强学习代理的个性化路径补救方法",
    "translated_abstract": "这篇论文介绍了一种名为个性化路径补救的新方法，用于为增强学习代理生成补救路径。其目标是通过编辑给定的动作路径以达到期望的目标（例如，与代理的原始路径相比取得更好的结果），同时确保与代理的原始路径高度相似并个性化适应代理。个性化是指新路径在从策略函数中观察到的代理行为模式方面的定制程度。我们训练一个个性化的补救代理来生成这样的个性化路径，这些路径是使用考虑目标、相似性和个性化的奖励函数获得的。该方法适用于增强学习和监督学习设置，以纠正或改进动作序列或数据序列以达到预定的目标。该方法在不同的设置中进行了评估。实验证明",
    "tldr": "该论文介绍了一种针对增强学习代理的个性化路径补救方法，该方法通过编辑动作路径来实现期望目标，同时保持与代理的原始路径相似度高，并且个性化适应代理的行为模式。这种方法适用于纠正或改进动作或数据序列以实现预定目标。",
    "en_tdlr": "This paper introduces a novel method called Personalized Path Recourse for reinforcement learning agents, which edits the action paths to achieve desired goals while maintaining high similarity to the original paths and personalization to the agent's behavior patterns. This method is applicable for correcting or improving action or data sequences to achieve predefined goals."
}