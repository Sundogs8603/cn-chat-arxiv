{
    "title": "SAME: Sample Reconstruction against Model Extraction Attacks. (arXiv:2312.10578v2 [cs.CR] UPDATED)",
    "abstract": "While deep learning models have shown significant performance across various domains, their deployment needs extensive resources and advanced computing infrastructure. As a solution, Machine Learning as a Service (MLaaS) has emerged, lowering the barriers for users to release or productize their deep learning models. However, previous studies have highlighted potential privacy and security concerns associated with MLaaS, and one primary threat is model extraction attacks. To address this, there are many defense solutions but they suffer from unrealistic assumptions and generalization issues, making them less practical for reliable protection. Driven by these limitations, we introduce a novel defense mechanism, SAME, based on the concept of sample reconstruction. This strategy imposes minimal prerequisites on the defender's capabilities, eliminating the need for auxiliary Out-of-Distribution (OOD) datasets, user query history, white-box model access, and additional intervention during m",
    "link": "http://arxiv.org/abs/2312.10578",
    "context": "Title: SAME: Sample Reconstruction against Model Extraction Attacks. (arXiv:2312.10578v2 [cs.CR] UPDATED)\nAbstract: While deep learning models have shown significant performance across various domains, their deployment needs extensive resources and advanced computing infrastructure. As a solution, Machine Learning as a Service (MLaaS) has emerged, lowering the barriers for users to release or productize their deep learning models. However, previous studies have highlighted potential privacy and security concerns associated with MLaaS, and one primary threat is model extraction attacks. To address this, there are many defense solutions but they suffer from unrealistic assumptions and generalization issues, making them less practical for reliable protection. Driven by these limitations, we introduce a novel defense mechanism, SAME, based on the concept of sample reconstruction. This strategy imposes minimal prerequisites on the defender's capabilities, eliminating the need for auxiliary Out-of-Distribution (OOD) datasets, user query history, white-box model access, and additional intervention during m",
    "path": "papers/23/12/2312.10578.json",
    "total_tokens": 874,
    "translated_title": "SAME: 防范模型提取攻击的样本重建方法",
    "translated_abstract": "尽管深度学习模型在各个领域中表现出显著的性能，但它们的部署需要大量的资源和先进的计算基础设施。作为解决方案，机器学习即服务（MLaaS）应运而生，降低了用户发布或产品化他们的深度学习模型的门槛。然而，之前的研究已经强调了与MLaaS相关的潜在隐私和安全风险，其中一个主要威胁是模型提取攻击。为了解决这个问题，有许多防御解决方案，但它们都存在不切实际的假设和泛化问题，使它们对可靠的保护不够实用。受到这些限制的驱动，我们引入了一种基于样本重建概念的新型防御机制SAME。该策略对防御者的能力要求最小，消除了对辅助的离群分布（OOD）数据集、用户查询历史、白盒模型访问和额外干预的需求。",
    "tldr": "SAME是一种防御模型提取攻击的新方法，基于样本重建的概念，无需额外的数据集和模型访问，并且具有更实用的保护能力。"
}