{
    "title": "Advancing Abductive Reasoning in Knowledge Graphs through Complex Logical Hypothesis Generation. (arXiv:2312.15643v2 [cs.AI] UPDATED)",
    "abstract": "Abductive reasoning is the process of making educated guesses to provide explanations for observations. Although many applications require the use of knowledge for explanations, the utilization of abductive reasoning in conjunction with structured knowledge, such as a knowledge graph, remains largely unexplored. To fill this gap, this paper introduces the task of complex logical hypothesis generation, as an initial step towards abductive logical reasoning with KG. In this task, we aim to generate a complex logical hypothesis so that it can explain a set of observations. We find that the supervised trained generative model can generate logical hypotheses that are structurally closer to the reference hypothesis. However, when generalized to unseen observations, this training objective does not guarantee better hypothesis generation. To address this, we introduce the Reinforcement Learning from Knowledge Graph (RLF-KG) method, which minimizes differences between observations and conclusio",
    "link": "http://arxiv.org/abs/2312.15643",
    "context": "Title: Advancing Abductive Reasoning in Knowledge Graphs through Complex Logical Hypothesis Generation. (arXiv:2312.15643v2 [cs.AI] UPDATED)\nAbstract: Abductive reasoning is the process of making educated guesses to provide explanations for observations. Although many applications require the use of knowledge for explanations, the utilization of abductive reasoning in conjunction with structured knowledge, such as a knowledge graph, remains largely unexplored. To fill this gap, this paper introduces the task of complex logical hypothesis generation, as an initial step towards abductive logical reasoning with KG. In this task, we aim to generate a complex logical hypothesis so that it can explain a set of observations. We find that the supervised trained generative model can generate logical hypotheses that are structurally closer to the reference hypothesis. However, when generalized to unseen observations, this training objective does not guarantee better hypothesis generation. To address this, we introduce the Reinforcement Learning from Knowledge Graph (RLF-KG) method, which minimizes differences between observations and conclusio",
    "path": "papers/23/12/2312.15643.json",
    "total_tokens": 1022,
    "translated_title": "通过复杂逻辑假设生成在知识图谱中推进诱导推理",
    "translated_abstract": "诱导推理是通过做出有根据的猜测来解释观察结果的过程。尽管许多应用需要使用知识进行解释，但将诱导推理与结构化知识（如知识图谱）结合使用的方法仍然尚未得到广泛探索。为了填补这一空白，本文介绍了复杂逻辑假设生成的任务，作为实现与知识图谱的诱导逻辑推理的初始步骤。在这个任务中，我们的目标是生成一个复杂的逻辑假设，以解释一组观察结果。我们发现，经过监督训练的生成模型可以生成结构上更接近参考假设的逻辑假设。然而，当推广到未见过的观察结果时，这种训练目标并不能保证更好的假设生成。为了解决这个问题，我们引入了基于知识图谱的强化学习方法（RLF-KG），该方法最小化观察结果与结论之间的差异。",
    "tldr": "这篇论文介绍了一种复杂逻辑假设生成的任务，作为实现与知识图谱的诱导逻辑推理的初始步骤。研究发现，过监督训练的生成模型可以生成结构上更接近参考假设的逻辑假设。为了解决推广到未见过观察结果的问题，引入了基于知识图谱的强化学习方法（RLF-KG），最小化观察结果与结论之间的差异。",
    "en_tdlr": "This paper introduces the task of complex logical hypothesis generation as an initial step towards abductive logical reasoning with knowledge graphs. The supervised trained generative model can generate logical hypotheses structurally closer to the reference hypothesis, but this training objective does not guarantee better hypothesis generation when generalized to unseen observations. To address this, the paper proposes the Reinforcement Learning from Knowledge Graph (RLF-KG) method to minimize differences between observations and conclusions."
}