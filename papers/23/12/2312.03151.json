{
    "title": "Multitask Learning Can Improve Worst-Group Outcomes",
    "abstract": "arXiv:2312.03151v2 Announce Type: replace  Abstract: In order to create machine learning systems that serve a variety of users well, it is vital to not only achieve high average performance but also ensure equitable outcomes across diverse groups. However, most machine learning methods are designed to improve a model's average performance on a chosen end task without consideration for their impact on worst group error. Multitask learning (MTL) is one such widely used technique. In this paper, we seek not only to understand the impact of MTL on worst-group accuracy but also to explore its potential as a tool to address the challenge of group-wise fairness. We primarily consider the standard setting of fine-tuning a pre-trained model, where, following recent work \\citep{gururangan2020don, dery2023aang}, we multitask the end task with the pre-training objective constructed from the end task data itself. In settings with few or no group annotations, we find that multitasking often, but not",
    "link": "https://arxiv.org/abs/2312.03151",
    "context": "Title: Multitask Learning Can Improve Worst-Group Outcomes\nAbstract: arXiv:2312.03151v2 Announce Type: replace  Abstract: In order to create machine learning systems that serve a variety of users well, it is vital to not only achieve high average performance but also ensure equitable outcomes across diverse groups. However, most machine learning methods are designed to improve a model's average performance on a chosen end task without consideration for their impact on worst group error. Multitask learning (MTL) is one such widely used technique. In this paper, we seek not only to understand the impact of MTL on worst-group accuracy but also to explore its potential as a tool to address the challenge of group-wise fairness. We primarily consider the standard setting of fine-tuning a pre-trained model, where, following recent work \\citep{gururangan2020don, dery2023aang}, we multitask the end task with the pre-training objective constructed from the end task data itself. In settings with few or no group annotations, we find that multitasking often, but not",
    "path": "papers/23/12/2312.03151.json",
    "total_tokens": 844,
    "translated_title": "多任务学习可以改善最差群体结果",
    "translated_abstract": "为了创建能够为各种用户提供良好服务的机器学习系统，不仅需要实现高平均性能，还需要确保在不同群体之间实现公平结果至关重要。然而，大多数机器学习方法旨在改善模型在选择的最终任务上的平均性能，而不考虑其对最差群体误差的影响。多任务学习（MTL）是一种广泛使用的技术。本文旨在不仅理解MTL对最差群体准确性的影响，而且探讨其作为解决组内公平挑战的工具的潜力。我们主要考虑了微调预训练模型的标准设置，在这个设置中，我们将最终任务与来自最终任务数据本身的预训练目标进行多任务处理。在少量或没有群体注释的环境中，我们发现多任务处理通常，但不总是",
    "tldr": "本文研究了多任务学习对最糟糕群体准确性的影响，并探讨了其作为解决组内公平挑战工具的潜力。",
    "en_tdlr": "This paper investigates the impact of multitask learning on worst-group accuracy and explores its potential as a tool to address the challenge of group-wise fairness."
}