{
    "title": "Uncertainty in GNN Learning Evaluations: A Comparison Between Measures for Quantifying Randomness in GNN Community Detection. (arXiv:2312.09015v2 [cs.LG] UPDATED)",
    "abstract": "(1) The enhanced capability of Graph Neural Networks (GNNs) in unsupervised community detection of clustered nodes is attributed to their capacity to encode both the connectivity and feature information spaces of graphs. The identification of latent communities holds practical significance in various domains, from social networks to genomics. Current real-world performance benchmarks are perplexing due to the multitude of decisions influencing GNN evaluations for this task. (2) Three metrics are compared to assess the consistency of algorithm rankings in the presence of randomness. The consistency and quality of performance between the results under a hyperparameter optimisation with the default hyperparameters is evaluated. (3) The results compare hyperparameter optimisation with default hyperparameters, revealing a significant performance loss when neglecting hyperparameter investigation. A comparison of metrics indicates that ties in ranks can substantially alter the quantification ",
    "link": "http://arxiv.org/abs/2312.09015",
    "context": "Title: Uncertainty in GNN Learning Evaluations: A Comparison Between Measures for Quantifying Randomness in GNN Community Detection. (arXiv:2312.09015v2 [cs.LG] UPDATED)\nAbstract: (1) The enhanced capability of Graph Neural Networks (GNNs) in unsupervised community detection of clustered nodes is attributed to their capacity to encode both the connectivity and feature information spaces of graphs. The identification of latent communities holds practical significance in various domains, from social networks to genomics. Current real-world performance benchmarks are perplexing due to the multitude of decisions influencing GNN evaluations for this task. (2) Three metrics are compared to assess the consistency of algorithm rankings in the presence of randomness. The consistency and quality of performance between the results under a hyperparameter optimisation with the default hyperparameters is evaluated. (3) The results compare hyperparameter optimisation with default hyperparameters, revealing a significant performance loss when neglecting hyperparameter investigation. A comparison of metrics indicates that ties in ranks can substantially alter the quantification ",
    "path": "papers/23/12/2312.09015.json",
    "total_tokens": 841,
    "translated_title": "GNN学习评估中的不确定性：量化GNN社区检测中随机性的度量方法比较",
    "translated_abstract": "(1) 图神经网络(GNN)在无监督社区检测中的增强能力归因于它们能够编码图的连接和特征信息空间。潜在社区的识别在从社交网络到基因组学的各个领域都具有实际意义。由于影响GNN评估的决策众多，当前实际性能基准令人困惑。(2) 比较了三个指标来评估算法排名在存在随机性时的一致性。通过使用默认超参数进行超参数优化的结果的一致性和性能质量进行评估。(3) 结果比较了使用默认超参数进行超参数优化，发现在忽视超参数调查时性能明显下降。指标的比较表明，排名中的并列名次可能会大大改变量化结果。",
    "tldr": "本研究比较了GNN社区检测中不同的度量方法，在考虑随机性的情况下，评估了算法排名的一致性，并发现在忽视超参数调查时性能明显下降。",
    "en_tdlr": "This study compares different measures for quantifying randomness in GNN community detection, evaluates the consistency of algorithm rankings in the presence of randomness, and finds a significant performance loss when neglecting hyperparameter investigation."
}