{
    "title": "Learning to Act without Actions",
    "abstract": "arXiv:2312.10812v2 Announce Type: replace-cross  Abstract: Pre-training large models on vast amounts of web data has proven to be an effective approach for obtaining powerful, general models in domains such as language and vision. However, this paradigm has not yet taken hold in reinforcement learning. This is because videos, the most abundant form of embodied behavioral data on the web, lack the action labels required by existing methods for imitating behavior from demonstrations. We introduce Latent Action Policies (LAPO), a method for recovering latent action information, and thereby latent-action policies, world models, and inverse dynamics models, purely from videos. LAPO is the first method able to recover the structure of the true action space just from observed dynamics, even in challenging procedurally-generated environments. LAPO enables training latent-action policies that can be rapidly fine-tuned into expert-level policies, either offline using a small action-labeled datas",
    "link": "https://arxiv.org/abs/2312.10812",
    "context": "Title: Learning to Act without Actions\nAbstract: arXiv:2312.10812v2 Announce Type: replace-cross  Abstract: Pre-training large models on vast amounts of web data has proven to be an effective approach for obtaining powerful, general models in domains such as language and vision. However, this paradigm has not yet taken hold in reinforcement learning. This is because videos, the most abundant form of embodied behavioral data on the web, lack the action labels required by existing methods for imitating behavior from demonstrations. We introduce Latent Action Policies (LAPO), a method for recovering latent action information, and thereby latent-action policies, world models, and inverse dynamics models, purely from videos. LAPO is the first method able to recover the structure of the true action space just from observed dynamics, even in challenging procedurally-generated environments. LAPO enables training latent-action policies that can be rapidly fine-tuned into expert-level policies, either offline using a small action-labeled datas",
    "path": "papers/23/12/2312.10812.json",
    "total_tokens": 707,
    "translated_title": "无需动作的行为学习",
    "translated_abstract": "在大规模网络数据上进行预训练已被证明是获取强大通用模型的有效方法，例如在语言和视觉领域。但是，这种范式尚未在强化学习中得以推广。我们介绍了Latent Action Policies（LAPO），这是一种从视频中纯粹恢复潜在动作信息的方法，从而产生潜在动作策略、世界模型和逆动力学模型。LAPO是第一个能够仅通过观察到的动态从视频中恢复真实动作空间结构的方法，即使在具有挑战性的过程生成环境中也是如此。",
    "tldr": "通过从视频中恢复潜在动作信息，LAPO能够训练可以迅速微调为专家级策略的潜在动作策略。"
}