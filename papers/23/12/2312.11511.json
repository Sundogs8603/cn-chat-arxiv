{
    "title": "ComplexityNet: Increasing LLM Inference Efficiency by Learning Task Complexity",
    "abstract": "arXiv:2312.11511v2 Announce Type: replace-cross  Abstract: We present ComplexityNet, a streamlined language model designed for assessing task complexity. This model predicts the likelihood of accurate output by various language models, each with different capabilities. Our initial application of ComplexityNet involves the Mostly Basic Python Problems (MBPP) dataset. We pioneered the creation of the first set of labels to define task complexity. ComplexityNet achieved a notable 79% accuracy in determining task complexity, a significant improvement over the 34% accuracy of the original, non fine-tuned model. Furthermore, ComplexityNet effectively reduces computational resource usage by 90% compared to using the highest complexity model, while maintaining a high code generation accuracy of 86.7%. This study demonstrates that fine-tuning smaller models to categorize tasks based on their complexity can lead to a more balanced trade-off between accuracy and efficiency in the use of Large Lan",
    "link": "https://arxiv.org/abs/2312.11511",
    "context": "Title: ComplexityNet: Increasing LLM Inference Efficiency by Learning Task Complexity\nAbstract: arXiv:2312.11511v2 Announce Type: replace-cross  Abstract: We present ComplexityNet, a streamlined language model designed for assessing task complexity. This model predicts the likelihood of accurate output by various language models, each with different capabilities. Our initial application of ComplexityNet involves the Mostly Basic Python Problems (MBPP) dataset. We pioneered the creation of the first set of labels to define task complexity. ComplexityNet achieved a notable 79% accuracy in determining task complexity, a significant improvement over the 34% accuracy of the original, non fine-tuned model. Furthermore, ComplexityNet effectively reduces computational resource usage by 90% compared to using the highest complexity model, while maintaining a high code generation accuracy of 86.7%. This study demonstrates that fine-tuning smaller models to categorize tasks based on their complexity can lead to a more balanced trade-off between accuracy and efficiency in the use of Large Lan",
    "path": "papers/23/12/2312.11511.json",
    "total_tokens": 822,
    "translated_title": "ComplexityNet: 通过学习任务复杂性提高LLM推理效率",
    "translated_abstract": "我们提出了ComplexityNet，这是一个专为评估任务复杂性而设计的简化语言模型。该模型通过不同能力的各种语言模型来预测准确输出的可能性。我们首次在Mostly Basic Python Problems（MBPP）数据集上应用了ComplexityNet。我们开创性地创建了第一组标签来定义任务复杂性。ComplexityNet在确定任务复杂性方面取得了显著的79%准确率，较原始、非微调模型的34%准确率有了显著改进。此外，与使用最高复杂性模型相比，ComplexityNet有效地减少了90%的计算资源使用，同时保持了86.7%的高代码生成准确率。这项研究表明，通过微调较小的模型来对任务进行分类，可以在准确性和效率之间取得更平衡的权衡。",
    "tldr": "ComplexityNet通过学习任务复杂性，提高了LLM推理效率，通过预测任务的准确输出概率，成功降低了90%的计算资源使用，并在任务复杂性确定方面取得了79%准确率。",
    "en_tdlr": "ComplexityNet increases LLM inference efficiency by learning task complexity, successfully reducing 90% of computational resource usage by predicting the likelihood of accurate output, and achieving a 79% accuracy in determining task complexity."
}