{
    "title": "Online Variational Sequential Monte Carlo",
    "abstract": "Being the most classical generative model for serial data, state-space models (SSM) are fundamental in AI and statistical machine learning. In SSM, any form of parameter learning or latent state inference typically involves the computation of complex latent-state posteriors. In this work, we build upon the variational sequential Monte Carlo (VSMC) method, which provides computationally efficient and accurate model parameter estimation and Bayesian latent-state inference by combining particle methods and variational inference. While standard VSMC operates in the offline mode, by re-processing repeatedly a given batch of data, we distribute the approximation of the gradient of the VSMC surrogate ELBO in time using stochastic approximation, allowing for online learning in the presence of streams of data. This results in an algorithm, online VSMC, that is capable of performing efficiently, entirely on-the-fly, both parameter estimation and particle proposal adaptation. In addition, we prov",
    "link": "https://rss.arxiv.org/abs/2312.12616",
    "context": "Title: Online Variational Sequential Monte Carlo\nAbstract: Being the most classical generative model for serial data, state-space models (SSM) are fundamental in AI and statistical machine learning. In SSM, any form of parameter learning or latent state inference typically involves the computation of complex latent-state posteriors. In this work, we build upon the variational sequential Monte Carlo (VSMC) method, which provides computationally efficient and accurate model parameter estimation and Bayesian latent-state inference by combining particle methods and variational inference. While standard VSMC operates in the offline mode, by re-processing repeatedly a given batch of data, we distribute the approximation of the gradient of the VSMC surrogate ELBO in time using stochastic approximation, allowing for online learning in the presence of streams of data. This results in an algorithm, online VSMC, that is capable of performing efficiently, entirely on-the-fly, both parameter estimation and particle proposal adaptation. In addition, we prov",
    "path": "papers/23/12/2312.12616.json",
    "total_tokens": 832,
    "translated_title": "在线变分顺序蒙特卡洛方法",
    "translated_abstract": "状态空间模型（SSM）是AI和统计机器学习中最经典的生成模型，对于任何形式的参数学习或潜在状态推断，通常需要计算复杂的潜在状态后验分布。本文在变分顺序蒙特卡洛（VSMC）方法的基础上进行了研究，该方法通过结合粒子方法和变分推断，提供了计算高效且准确的模型参数估计和贝叶斯潜在状态推断。传统的VSMC方法在离线模式下运行，通过重复处理给定的数据批次，而我们使用随机逼近方法将VSMC代理ELBO的梯度逼近分布到时间上，从而实现了在数据流存在的情况下的在线学习。这导致了一种名为在线VSMC的算法，能够高效地进行参数估计和粒子提议适应，而且完全实时处理数据。",
    "tldr": "本文提出了一种在线学习的算法，名为在线VSMC，它基于变分顺序蒙特卡洛方法，在处理数据流时能够实时进行模型参数估计和粒子提议适应。"
}