{
    "title": "Efficiently Quantifying Individual Agent Importance in Cooperative MARL. (arXiv:2312.08466v2 [cs.AI] UPDATED)",
    "abstract": "Measuring the contribution of individual agents is challenging in cooperative multi-agent reinforcement learning (MARL). In cooperative MARL, team performance is typically inferred from a single shared global reward. Arguably, among the best current approaches to effectively measure individual agent contributions is to use Shapley values. However, calculating these values is expensive as the computational complexity grows exponentially with respect to the number of agents. In this paper, we adapt difference rewards into an efficient method for quantifying the contribution of individual agents, referred to as Agent Importance, offering a linear computational complexity relative to the number of agents. We show empirically that the computed values are strongly correlated with the true Shapley values, as well as the true underlying individual agent rewards, used as the ground truth in environments where these are available. We demonstrate how Agent Importance can be used to help study MAR",
    "link": "http://arxiv.org/abs/2312.08466",
    "context": "Title: Efficiently Quantifying Individual Agent Importance in Cooperative MARL. (arXiv:2312.08466v2 [cs.AI] UPDATED)\nAbstract: Measuring the contribution of individual agents is challenging in cooperative multi-agent reinforcement learning (MARL). In cooperative MARL, team performance is typically inferred from a single shared global reward. Arguably, among the best current approaches to effectively measure individual agent contributions is to use Shapley values. However, calculating these values is expensive as the computational complexity grows exponentially with respect to the number of agents. In this paper, we adapt difference rewards into an efficient method for quantifying the contribution of individual agents, referred to as Agent Importance, offering a linear computational complexity relative to the number of agents. We show empirically that the computed values are strongly correlated with the true Shapley values, as well as the true underlying individual agent rewards, used as the ground truth in environments where these are available. We demonstrate how Agent Importance can be used to help study MAR",
    "path": "papers/23/12/2312.08466.json",
    "total_tokens": 896,
    "translated_title": "高效量化合作多智能体强化学习中个体智能体重要性的方法",
    "translated_abstract": "在合作多智能体强化学习中测量个体智能体的贡献是具有挑战性的。在合作多智能体强化学习中，团队表现通常是通过单一共享的全局奖励推断出来的。目前最好的有效测量个体智能体贡献的方法之一是使用Shapley值。然而，计算这些值的成本很高，因为计算复杂度与智能体数量呈指数增长。在本文中，我们将差异奖励方法改进为一种量化个体智能体贡献的高效方法，称为Agent Importance，它相对于智能体数量具有线性的计算复杂度。我们通过实验证明，计算得到的值与真实的Shapley值以及用作环境中真实个体智能体奖励的基本事实密切相关。我们展示了Agent Importance如何帮助研究MARL。",
    "tldr": "本文提出了一种高效量化合作多智能体强化学习中个体智能体重要性的方法，相对于智能体数量具有线性计算复杂度，并与真实的Shapley值以及真实环境中的个体智能体奖励密切相关。",
    "en_tdlr": "This paper proposes an efficient method for quantifying the importance of individual agents in cooperative multi-agent reinforcement learning (MARL). The method, called Agent Importance, offers linear computational complexity relative to the number of agents and shows strong correlation with the true Shapley values and individual agent rewards in real environments."
}