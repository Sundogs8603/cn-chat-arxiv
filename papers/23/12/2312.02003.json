{
    "title": "A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly. (arXiv:2312.02003v2 [cs.CR] UPDATED)",
    "abstract": "Large Language Models (LLMs), such as ChatGPT and Bard, have revolutionized natural language understanding and generation. They possess deep language comprehension, human-like text generation capabilities, contextual awareness, and robust problem-solving skills, making them invaluable in various domains (e.g., search engines, customer support, translation). In the meantime, LLMs have also gained traction in the security community, revealing security vulnerabilities and showcasing their potential in security-related tasks. This paper explores the intersection of LLMs with security and privacy. Specifically, we investigate how LLMs positively impact security and privacy, potential risks and threats associated with their use, and inherent vulnerabilities within LLMs. Through a comprehensive literature review, the paper categorizes the papers into \"The Good\" (beneficial LLM applications), \"The Bad\" (offensive applications), and \"The Ugly\" (vulnerabilities of LLMs and their defenses). We ha",
    "link": "http://arxiv.org/abs/2312.02003",
    "context": "Title: A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly. (arXiv:2312.02003v2 [cs.CR] UPDATED)\nAbstract: Large Language Models (LLMs), such as ChatGPT and Bard, have revolutionized natural language understanding and generation. They possess deep language comprehension, human-like text generation capabilities, contextual awareness, and robust problem-solving skills, making them invaluable in various domains (e.g., search engines, customer support, translation). In the meantime, LLMs have also gained traction in the security community, revealing security vulnerabilities and showcasing their potential in security-related tasks. This paper explores the intersection of LLMs with security and privacy. Specifically, we investigate how LLMs positively impact security and privacy, potential risks and threats associated with their use, and inherent vulnerabilities within LLMs. Through a comprehensive literature review, the paper categorizes the papers into \"The Good\" (beneficial LLM applications), \"The Bad\" (offensive applications), and \"The Ugly\" (vulnerabilities of LLMs and their defenses). We ha",
    "path": "papers/23/12/2312.02003.json",
    "total_tokens": 971,
    "translated_title": "关于大型语言模型（LLM）的安全与隐私的调研：美好、恶劣和丑陋(arXiv:2312.02003v2 [cs.CR] UPDATED)",
    "translated_abstract": "大型语言模型（LLMs），如ChatGPT和Bard，已经革新了自然语言理解和生成。它们具有深入的语言理解能力、人类般的文本生成能力、语境感知和强大的问题解决能力，在各个领域（如搜索引擎、客户支持、翻译）中具有不可估量的价值。与此同时，LLMs也在安全领域引起了关注，揭示了安全漏洞，并展示了它们在安全相关任务中的潜力。本文探讨了LLMs与安全和隐私的交叉点。具体而言，我们研究了LLMs如何对安全和隐私产生积极影响，它们使用中可能存在的风险和威胁，以及LLMs内在的漏洞。通过综合文献回顾，本文将文献分为“美好”（有益的LLM应用）、“恶劣”（攻击性应用）和“丑陋”（LLMs的漏洞及其防御）。我们发现，",
    "tldr": "该论文调查了大型语言模型（LLM）与安全和隐私的相关性。研究发现LLMs在安全和隐私保护方面具有积极影响，但同时也存在潜在的风险、威胁和漏洞。",
    "en_tdlr": "This paper explores the intersection between large language models (LLMs) and security and privacy. The study found that LLMs have a positive impact on security and privacy but also pose potential risks, threats, and vulnerabilities."
}