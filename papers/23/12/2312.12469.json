{
    "title": "Distilling Autoregressive Models to Obtain High-Performance Non-Autoregressive Solvers for Vehicle Routing Problems with Faster Inference Speed. (arXiv:2312.12469v2 [cs.LG] UPDATED)",
    "abstract": "Neural construction models have shown promising performance for Vehicle Routing Problems (VRPs) by adopting either the Autoregressive (AR) or Non-Autoregressive (NAR) learning approach. While AR models produce high-quality solutions, they generally have a high inference latency due to their sequential generation nature. Conversely, NAR models generate solutions in parallel with a low inference latency but generally exhibit inferior performance. In this paper, we propose a generic Guided Non-Autoregressive Knowledge Distillation (GNARKD) method to obtain high-performance NAR models having a low inference latency. GNARKD removes the constraint of sequential generation in AR models while preserving the learned pivotal components in the network architecture to obtain the corresponding NAR models through knowledge distillation. We evaluate GNARKD by applying it to three widely adopted AR models to obtain NAR VRP solvers for both synthesized and real-world instances. The experimental results",
    "link": "http://arxiv.org/abs/2312.12469",
    "context": "Title: Distilling Autoregressive Models to Obtain High-Performance Non-Autoregressive Solvers for Vehicle Routing Problems with Faster Inference Speed. (arXiv:2312.12469v2 [cs.LG] UPDATED)\nAbstract: Neural construction models have shown promising performance for Vehicle Routing Problems (VRPs) by adopting either the Autoregressive (AR) or Non-Autoregressive (NAR) learning approach. While AR models produce high-quality solutions, they generally have a high inference latency due to their sequential generation nature. Conversely, NAR models generate solutions in parallel with a low inference latency but generally exhibit inferior performance. In this paper, we propose a generic Guided Non-Autoregressive Knowledge Distillation (GNARKD) method to obtain high-performance NAR models having a low inference latency. GNARKD removes the constraint of sequential generation in AR models while preserving the learned pivotal components in the network architecture to obtain the corresponding NAR models through knowledge distillation. We evaluate GNARKD by applying it to three widely adopted AR models to obtain NAR VRP solvers for both synthesized and real-world instances. The experimental results",
    "path": "papers/23/12/2312.12469.json",
    "total_tokens": 967,
    "translated_title": "将自回归模型提炼为具有较快推理速度的高性能非自回归车辆路径问题求解器",
    "translated_abstract": "通过采用自回归（AR）或非自回归（NAR）学习方法，神经构建模型在车辆路径问题（VRP）方面表现出有希望的性能。虽然AR模型能够生成高质量的解决方案，但由于其顺序生成性质，推理延迟通常较高。相反，NAR模型以低推理延迟并行生成解决方案，但通常表现出较低的性能。在本文中，我们提出了一种通用的引导非自回归知识蒸馏（GNARKD）方法，以获得具有低推理延迟的高性能NAR模型。GNARKD通过知识蒸馏，去除AR模型中顺序生成的约束，同时保留网络架构中学到的关键组件，获得相应的NAR模型。我们将GNARKD应用于三种广泛采用的AR模型，并在合成和实际实例上获得NAR VRP求解器，并进行了实验评估。",
    "tldr": "本论文提出了一种通用的引导非自回归知识蒸馏（GNARKD）方法，通过知识蒸馏将自回归模型中的关键组件保留在网络架构中，从而获得具有低推理延迟的高性能非自回归车辆路径问题求解器。"
}