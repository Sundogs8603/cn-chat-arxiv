{
    "title": "Paralinguistics-Enhanced Large Language Modeling of Spoken Dialogue. (arXiv:2312.15316v2 [cs.CL] UPDATED)",
    "abstract": "Large Language Models (LLMs) have demonstrated superior abilities in tasks such as chatting, reasoning, and question-answering. However, standard LLMs may ignore crucial paralinguistic information, such as sentiment, emotion, and speaking style, which are essential for achieving natural, human-like spoken conversation, especially when such information is conveyed by acoustic cues. We therefore propose Paralinguistics-enhanced Generative Pretrained Transformer (ParalinGPT), an LLM that utilizes text and speech modalities to better model the linguistic content and paralinguistic attributes of spoken dialogue. The model takes the conversational context of text, speech embeddings, and paralinguistic attributes as input prompts within a serialized multitasking multimodal framework. Specifically, our framework serializes tasks in the order of current paralinguistic attribute prediction, response paralinguistic attribute prediction, and response text generation with autoregressive conditionin",
    "link": "http://arxiv.org/abs/2312.15316",
    "context": "Title: Paralinguistics-Enhanced Large Language Modeling of Spoken Dialogue. (arXiv:2312.15316v2 [cs.CL] UPDATED)\nAbstract: Large Language Models (LLMs) have demonstrated superior abilities in tasks such as chatting, reasoning, and question-answering. However, standard LLMs may ignore crucial paralinguistic information, such as sentiment, emotion, and speaking style, which are essential for achieving natural, human-like spoken conversation, especially when such information is conveyed by acoustic cues. We therefore propose Paralinguistics-enhanced Generative Pretrained Transformer (ParalinGPT), an LLM that utilizes text and speech modalities to better model the linguistic content and paralinguistic attributes of spoken dialogue. The model takes the conversational context of text, speech embeddings, and paralinguistic attributes as input prompts within a serialized multitasking multimodal framework. Specifically, our framework serializes tasks in the order of current paralinguistic attribute prediction, response paralinguistic attribute prediction, and response text generation with autoregressive conditionin",
    "path": "papers/23/12/2312.15316.json",
    "total_tokens": 831,
    "translated_title": "增强口语对话的声调语言建模",
    "translated_abstract": "大规模语言模型 (LLM) 在聊天、推理和问答等任务中展现出卓越的能力。然而，标准的 LLM 可能忽视了关键的声调语言信息，例如情感、情绪和语言风格，这些信息对于实现自然的、类似人类的口语对话至关重要，尤其是当这些信息通过声学线索传达时。因此，我们提出了增强声调语言的预训练变换器 (ParalinGPT)，它利用文本和语音模态来更好地建模口语对话的语言内容和声调语言属性。该模型将文本的对话上下文、语音嵌入和声调语言属性作为输入提示，放在一个串行多任务多模态框架中。具体而言，我们的框架按照当前声调语言属性预测、回应声调语言属性预测和回应文本生成的顺序进行序列化任务。",
    "tldr": "提出了一种增强声调语言的预训练变换器，利用文本和语音模态来更好地建模口语对话的语言内容和声调语言属性。",
    "en_tdlr": "A paralinguistics-enhanced generative pretrained transformer is proposed to better model the linguistic content and paralinguistic attributes of spoken dialogue using text and speech modalities."
}