{
    "title": "Provable Adversarial Robustness for Group Equivariant Tasks: Graphs, Point Clouds, Molecules, and More. (arXiv:2312.02708v2 [cs.LG] UPDATED)",
    "abstract": "A machine learning model is traditionally considered robust if its prediction remains (almost) constant under input perturbations with small norm. However, real-world tasks like molecular property prediction or point cloud segmentation have inherent equivariances, such as rotation or permutation equivariance. In such tasks, even perturbations with large norm do not necessarily change an input's semantic content. Furthermore, there are perturbations for which a model's prediction explicitly needs to change. For the first time, we propose a sound notion of adversarial robustness that accounts for task equivariance. We then demonstrate that provable robustness can be achieved by (1) choosing a model that matches the task's equivariances (2) certifying traditional adversarial robustness. Certification methods are, however, unavailable for many models, such as those with continuous equivariances. We close this gap by developing the framework of equivariance-preserving randomized smoothing, ",
    "link": "http://arxiv.org/abs/2312.02708",
    "context": "Title: Provable Adversarial Robustness for Group Equivariant Tasks: Graphs, Point Clouds, Molecules, and More. (arXiv:2312.02708v2 [cs.LG] UPDATED)\nAbstract: A machine learning model is traditionally considered robust if its prediction remains (almost) constant under input perturbations with small norm. However, real-world tasks like molecular property prediction or point cloud segmentation have inherent equivariances, such as rotation or permutation equivariance. In such tasks, even perturbations with large norm do not necessarily change an input's semantic content. Furthermore, there are perturbations for which a model's prediction explicitly needs to change. For the first time, we propose a sound notion of adversarial robustness that accounts for task equivariance. We then demonstrate that provable robustness can be achieved by (1) choosing a model that matches the task's equivariances (2) certifying traditional adversarial robustness. Certification methods are, however, unavailable for many models, such as those with continuous equivariances. We close this gap by developing the framework of equivariance-preserving randomized smoothing, ",
    "path": "papers/23/12/2312.02708.json",
    "total_tokens": 956,
    "translated_title": "可证明的对称任务的对抗鲁棒性：图形、点云、分子等",
    "translated_abstract": "传统上，机器学习模型被认为在输入扰动的情况下保持（几乎）恒定的预测是健壮的。然而，现实世界中的任务，如分子性质预测或点云分割，具有固有的对称性，如旋转或置换对称性。在这些任务中，即使是具有大范数的扰动也不一定会改变输入的语义内容。此外，有些扰动需要明确改变模型的预测。我们首次提出了一种考虑任务对称性的可靠对抗鲁棒性概念。然后，我们证明了可以通过选择与任务对称性相匹配的模型和认证传统的对抗鲁棒性来实现可证明的鲁棒性。然而，对于许多具有连续对称性的模型，认证方法不可用。通过开发保持对称性的随机平滑的框架，我们填补了这个空白。",
    "tldr": "本文提出了一种考虑任务对称性的可证明的对抗鲁棒性概念，并通过选择合适的模型和认证方法来实现鲁棒性。同时，通过开发保持对称性的随机平滑的框架，解决了对于具有连续对称性的模型的认证方法不可用的问题。",
    "en_tdlr": "This paper proposes a notion of provable adversarial robustness that takes task equivariance into account, and achieves robustness by selecting appropriate models and certification methods. Additionally, it addresses the unavailability of certification methods for models with continuous equivariances by developing the framework of equivariance-preserving randomized smoothing."
}