{
    "title": "Time-Transformer: Integrating Local and Global Features for Better Time Series Generation. (arXiv:2312.11714v2 [cs.LG] UPDATED)",
    "abstract": "Generating time series data is a promising approach to address data deficiency problems. However, it is also challenging due to the complex temporal properties of time series data, including local correlations as well as global dependencies. Most existing generative models have failed to effectively learn both the local and global properties of time series data. To address this open problem, we propose a novel time series generative model named 'Time-Transformer AAE', which consists of an adversarial autoencoder (AAE) and a newly designed architecture named 'Time-Transformer' within the decoder. The Time-Transformer first simultaneously learns local and global features in a layer-wise parallel design, combining the abilities of Temporal Convolutional Networks and Transformer in extracting local features and global dependencies respectively. Second, a bidirectional cross attention is proposed to provide complementary guidance across the two branches and achieve proper fusion between loc",
    "link": "http://arxiv.org/abs/2312.11714",
    "context": "Title: Time-Transformer: Integrating Local and Global Features for Better Time Series Generation. (arXiv:2312.11714v2 [cs.LG] UPDATED)\nAbstract: Generating time series data is a promising approach to address data deficiency problems. However, it is also challenging due to the complex temporal properties of time series data, including local correlations as well as global dependencies. Most existing generative models have failed to effectively learn both the local and global properties of time series data. To address this open problem, we propose a novel time series generative model named 'Time-Transformer AAE', which consists of an adversarial autoencoder (AAE) and a newly designed architecture named 'Time-Transformer' within the decoder. The Time-Transformer first simultaneously learns local and global features in a layer-wise parallel design, combining the abilities of Temporal Convolutional Networks and Transformer in extracting local features and global dependencies respectively. Second, a bidirectional cross attention is proposed to provide complementary guidance across the two branches and achieve proper fusion between loc",
    "path": "papers/23/12/2312.11714.json",
    "total_tokens": 837,
    "translated_title": "时间变换器：融合本地和全局特征以实现更好的时间序列生成",
    "translated_abstract": "生成时间序列数据是解决数据不足问题的一种有前景的方法。然而，由于时间序列数据的复杂时间特性，包括本地相关性和全局依赖性，使其成为具有挑战性的任务。大多数现有的生成模型未能有效学习时间序列数据的本地和全局特性。为了解决这个问题，我们提出了一种新颖的时间序列生成模型，命名为'时间变换器AAE'，它由一个对抗性自动编码器（AAE）和一个名为'时间变换器'的新设计架构组成。时间变换器首先通过层次并行设计同时学习本地和全局特征，结合了时间卷积网络和Transformer的能力，分别提取本地特征和全局依赖性。其次，提出了一个双向交叉注意力来在两个分支之间提供互补的引导，并实现本地特征和全局特征的合适融合。",
    "tldr": "本文提出了一种新的时间序列生成模型，通过时间变换器同时学习本地和全局特征，实现了对时间序列数据的更好生成能力。",
    "en_tdlr": "This paper proposes a novel time series generative model, which utilizes a time transformer to learn both local and global features, resulting in better generation of time series data."
}