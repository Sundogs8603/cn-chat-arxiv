{
    "title": "Near-Optimal Resilient Aggregation Rules for Distributed Learning Using 1-Center and 1-Mean Clustering with Outliers",
    "abstract": "arXiv:2312.12835v2 Announce Type: replace  Abstract: Byzantine machine learning has garnered considerable attention in light of the unpredictable faults that can occur in large-scale distributed learning systems. The key to secure resilience against Byzantine machines in distributed learning is resilient aggregation mechanisms. Although abundant resilient aggregation rules have been proposed, they are designed in ad-hoc manners, imposing extra barriers on comparing, analyzing, and improving the rules across performance criteria. This paper studies near-optimal aggregation rules using clustering in the presence of outliers. Our outlier-robust clustering approach utilizes geometric properties of the update vectors provided by workers. Our analysis show that constant approximations to the 1-center and 1-mean clustering problems with outliers provide near-optimal resilient aggregators for metric-based criteria, which have been proven to be crucial in the homogeneous and heterogeneous cases",
    "link": "https://arxiv.org/abs/2312.12835",
    "context": "Title: Near-Optimal Resilient Aggregation Rules for Distributed Learning Using 1-Center and 1-Mean Clustering with Outliers\nAbstract: arXiv:2312.12835v2 Announce Type: replace  Abstract: Byzantine machine learning has garnered considerable attention in light of the unpredictable faults that can occur in large-scale distributed learning systems. The key to secure resilience against Byzantine machines in distributed learning is resilient aggregation mechanisms. Although abundant resilient aggregation rules have been proposed, they are designed in ad-hoc manners, imposing extra barriers on comparing, analyzing, and improving the rules across performance criteria. This paper studies near-optimal aggregation rules using clustering in the presence of outliers. Our outlier-robust clustering approach utilizes geometric properties of the update vectors provided by workers. Our analysis show that constant approximations to the 1-center and 1-mean clustering problems with outliers provide near-optimal resilient aggregators for metric-based criteria, which have been proven to be crucial in the homogeneous and heterogeneous cases",
    "path": "papers/23/12/2312.12835.json",
    "total_tokens": 857,
    "translated_title": "使用1中心和1均值聚类处理异常值的分布式学习中近似最优的鲁棒聚合规则",
    "translated_abstract": "近年来，拜占庭机器学习在大规模分布式学习系统中引起了人们的极大关注，因为不可预知的故障可能会导致系统崩溃。在分布式学习中，实现对抗拜占庭机器的安全鲁棒性的关键在于鲁棒聚合机制。本文研究了在存在异常值的情况下使用聚类的近似最优聚合规则。我们提出的抗异常值的聚类方法利用了工作者提供的更新向量的几何属性。我们的分析表明，具有异常值的1中心和1均值聚类问题的恒定近似解提供了在度量标准上近似最优的鲁棒聚合器，这在均匀和非均匀情况下都被证明是至关重要的。",
    "tldr": "本文研究了在分布式学习中使用聚类方法处理异常值的近似最优鲁棒聚合规则，通过恒定近似1中心和1均值聚类问题解决方案，提供了重要的度量标准优化方法",
    "en_tdlr": "This paper investigates near-optimal resilient aggregation rules using clustering in distributed learning to handle outliers and provides important optimization methods for performance criteria by constant approximations to the 1-center and 1-mean clustering problems with outliers."
}