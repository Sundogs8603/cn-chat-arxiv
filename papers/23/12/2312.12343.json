{
    "title": "LatestEval: Addressing Data Contamination in Language Model Evaluation through Dynamic and Time-Sensitive Test Construction",
    "abstract": "arXiv:2312.12343v3 Announce Type: replace-cross  Abstract: Data contamination in evaluation is getting increasingly prevalent with the emergence of language models pre-trained on super large, automatically crawled corpora. This problem leads to significant challenges in the accurate assessment of model capabilities and generalisations. In this paper, we propose LatestEval, an automatic method that leverages the most recent texts to create uncontaminated reading comprehension evaluations. LatestEval avoids data contamination by only using texts published within a recent time window, ensuring no overlap with the training corpora of pre-trained language models. We develop the LatestEval automated pipeline to 1) gather the latest texts; 2) identify key information, and 3) construct questions targeting the information while removing the existing answers from the context. This encourages models to infer the answers themselves based on the remaining context, rather than just copy-paste. Our e",
    "link": "https://arxiv.org/abs/2312.12343",
    "context": "Title: LatestEval: Addressing Data Contamination in Language Model Evaluation through Dynamic and Time-Sensitive Test Construction\nAbstract: arXiv:2312.12343v3 Announce Type: replace-cross  Abstract: Data contamination in evaluation is getting increasingly prevalent with the emergence of language models pre-trained on super large, automatically crawled corpora. This problem leads to significant challenges in the accurate assessment of model capabilities and generalisations. In this paper, we propose LatestEval, an automatic method that leverages the most recent texts to create uncontaminated reading comprehension evaluations. LatestEval avoids data contamination by only using texts published within a recent time window, ensuring no overlap with the training corpora of pre-trained language models. We develop the LatestEval automated pipeline to 1) gather the latest texts; 2) identify key information, and 3) construct questions targeting the information while removing the existing answers from the context. This encourages models to infer the answers themselves based on the remaining context, rather than just copy-paste. Our e",
    "path": "papers/23/12/2312.12343.json",
    "total_tokens": 881,
    "translated_title": "LatestEval: 通过动态和时间敏感的测试构建解决语言模型评估中的数据污染问题",
    "translated_abstract": "随着预先在超大规模自动抓取语料库上进行训练的语言模型的出现，评估中的数据污染越来越普遍。这个问题导致在准确评估模型能力和泛化能力方面存在重大挑战。在本文中，我们提出了LatestEval，这是一种自动方法，利用最近的文本创建不受污染的阅读理解评估。LatestEval通过仅使用在最近时间窗口内发布的文本来避免数据污染，确保不会与预先训练语言模型的训练语料库重叠。我们开发了LatestEval自动化流水线，用于1）收集最新文本；2）识别关键信息，以及3）构建针对该信息的问题，同时从上下文中删除现有答案。这鼓励模型根据剩余上下文推断答案，而不仅是复制粘贴。",
    "tldr": "LatestEval提出了一种自动方法，通过动态和时间敏感的测试构建不受数据污染的阅读理解评估，避免了使用预先训练语言模型的训练语料库，从而鼓励模型更好地推断答案。",
    "en_tdlr": "LatestEval proposes an automatic method to construct uncontaminated reading comprehension evaluations through dynamic and time-sensitive tests, avoiding the usage of pre-trained language models' training corpora, thereby encouraging models to better infer answers."
}