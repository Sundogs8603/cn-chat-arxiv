{
    "title": "Provably Convergent Federated Trilevel Learning. (arXiv:2312.11835v2 [cs.LG] UPDATED)",
    "abstract": "Trilevel learning, also called trilevel optimization (TLO), has been recognized as a powerful modelling tool for hierarchical decision process and widely applied in many machine learning applications, such as robust neural architecture search, hyperparameter optimization, and domain adaptation. Tackling TLO problems has presented a great challenge due to their nested decision-making structure. In addition, existing works on TLO face the following key challenges: 1) they all focus on the non-distributed setting, which may lead to privacy breach; 2) they do not offer any non-asymptotic convergence analysis which characterizes how fast an algorithm converges. To address the aforementioned challenges, this paper proposes an asynchronous federated trilevel optimization method to solve TLO problems. The proposed method utilizes $\\mu$-cuts to construct a hyper-polyhedral approximation for the TLO problem and solve it in an asynchronous manner. We demonstrate that the proposed $\\mu$-cuts are a",
    "link": "http://arxiv.org/abs/2312.11835",
    "context": "Title: Provably Convergent Federated Trilevel Learning. (arXiv:2312.11835v2 [cs.LG] UPDATED)\nAbstract: Trilevel learning, also called trilevel optimization (TLO), has been recognized as a powerful modelling tool for hierarchical decision process and widely applied in many machine learning applications, such as robust neural architecture search, hyperparameter optimization, and domain adaptation. Tackling TLO problems has presented a great challenge due to their nested decision-making structure. In addition, existing works on TLO face the following key challenges: 1) they all focus on the non-distributed setting, which may lead to privacy breach; 2) they do not offer any non-asymptotic convergence analysis which characterizes how fast an algorithm converges. To address the aforementioned challenges, this paper proposes an asynchronous federated trilevel optimization method to solve TLO problems. The proposed method utilizes $\\mu$-cuts to construct a hyper-polyhedral approximation for the TLO problem and solve it in an asynchronous manner. We demonstrate that the proposed $\\mu$-cuts are a",
    "path": "papers/23/12/2312.11835.json",
    "total_tokens": 936,
    "translated_title": "可证明收敛的联邦三层学习",
    "translated_abstract": "三层学习，也称为三层优化（TLO），被认为是层次决策过程的强大建模工具，并广泛应用于许多机器学习应用中，如鲁棒的神经网络架构搜索、超参数优化和领域自适应。解决TLO问题在于其嵌套的决策结构而面临巨大挑战。此外，现有的TLO工作面临以下关键挑战：1）它们都专注于非分布式设置，这可能导致隐私泄露；2）它们没有提供任何非渐进收敛分析，即刻画算法收敛速度的特征。为了解决上述挑战，本文提出了一种异步联邦三层优化方法来解决TLO问题。所提出的方法利用μ剖分构建TLO问题的超多面体近似，并以异步方式解决。我们证明了所提出的μ剖分是对TLO问题的一个有效近似。",
    "tldr": "该论文提出了一种异步联邦三层优化方法来解决层次决策过程中的TLO问题，通过利用μ剖分构建超多面体近似并以异步方式求解，解决了现有TLO工作中的隐私泄露和收敛速度缺乏分析的问题。"
}