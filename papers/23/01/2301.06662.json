{
    "title": "Graph Topology Learning Under Privacy Constraints. (arXiv:2301.06662v2 [cs.LG] UPDATED)",
    "abstract": "We consider the problem of inferring the underlying graph topology from smooth graph signals in a novel but practical scenario where data are located in distributed clients and are privacy-sensitive. The main difficulty of this task lies in how to utilize the potentially heterogeneous data of all isolated clients under privacy constraints. Towards this end, we propose a framework where personalized graphs for local clients as well as a consensus graph are jointly learned. The personalized graphs match local data distributions, thereby mitigating data heterogeneity, while the consensus graph captures the global information. We next devise a tailored algorithm to solve the induced problem without violating privacy constraints, i.e., all private data are processed locally. To further enhance privacy protection, we introduce differential privacy (DP) into the proposed algorithm to resist privacy attacks when transmitting model updates. Theoretically, we establish provable convergence analy",
    "link": "http://arxiv.org/abs/2301.06662",
    "context": "Title: Graph Topology Learning Under Privacy Constraints. (arXiv:2301.06662v2 [cs.LG] UPDATED)\nAbstract: We consider the problem of inferring the underlying graph topology from smooth graph signals in a novel but practical scenario where data are located in distributed clients and are privacy-sensitive. The main difficulty of this task lies in how to utilize the potentially heterogeneous data of all isolated clients under privacy constraints. Towards this end, we propose a framework where personalized graphs for local clients as well as a consensus graph are jointly learned. The personalized graphs match local data distributions, thereby mitigating data heterogeneity, while the consensus graph captures the global information. We next devise a tailored algorithm to solve the induced problem without violating privacy constraints, i.e., all private data are processed locally. To further enhance privacy protection, we introduce differential privacy (DP) into the proposed algorithm to resist privacy attacks when transmitting model updates. Theoretically, we establish provable convergence analy",
    "path": "papers/23/01/2301.06662.json",
    "total_tokens": 874,
    "translated_title": "在隐私约束下的图拓扑学习",
    "translated_abstract": "我们考虑在数据分布于分布式客户端且具有隐私敏感性的新颖实际场景中，通过平滑图信号推断潜在图拓扑的问题。这个任务的主要困难在于如何在隐私约束下利用所有独立客户端的潜在异构数据。为了解决这个问题，我们提出了一个框架，通过联合学习为本地客户端定制的个性化图以及共识图。个性化图匹配本地数据分布，从而减轻数据的异质性，而共识图捕捉全局信息。我们接下来设计了一个定制的算法来解决引入的问题，同时不违反隐私约束，即所有的私有数据都在本地处理。为了进一步增强隐私保护，我们将差分隐私（DP）引入到所提算法中，在传输模型更新时抵御隐私攻击。理论上，我们建立了可证明收敛的分析。",
    "tldr": "在隐私约束下，我们提出了一个框架，联合学习为本地客户定制的个性化图以及共识图，以推断潜在图拓扑，同时在保护隐私的情况下处理分布式客户端的数据。"
}