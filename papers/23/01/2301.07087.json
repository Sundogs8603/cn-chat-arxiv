{
    "title": "MooseNet: A Trainable Metric for Synthesized Speech with a PLDA Module. (arXiv:2301.07087v2 [cs.CL] UPDATED)",
    "abstract": "We present MooseNet, a trainable speech metric that predicts the listeners' Mean Opinion Score (MOS). We propose a novel approach where the Probabilistic Linear Discriminative Analysis (PLDA) generative model is used on top of an embedding obtained from a self-supervised learning (SSL) neural network (NN) model. We show that PLDA works well with a non-finetuned SSL model when trained only on 136 utterances (ca. one minute training time) and that PLDA consistently improves various neural MOS prediction models, even state-of-the-art models with task-specific fine-tuning. Our ablation study shows PLDA training superiority over SSL model fine-tuning in a low-resource scenario. We also improve SSL model fine-tuning using a convenient optimizer choice and additional contrastive and multi-task training objectives. The fine-tuned MooseNet NN with the PLDA module achieves the best results, surpassing the SSL baseline on the VoiceMOS Challenge data.",
    "link": "http://arxiv.org/abs/2301.07087",
    "context": "Title: MooseNet: A Trainable Metric for Synthesized Speech with a PLDA Module. (arXiv:2301.07087v2 [cs.CL] UPDATED)\nAbstract: We present MooseNet, a trainable speech metric that predicts the listeners' Mean Opinion Score (MOS). We propose a novel approach where the Probabilistic Linear Discriminative Analysis (PLDA) generative model is used on top of an embedding obtained from a self-supervised learning (SSL) neural network (NN) model. We show that PLDA works well with a non-finetuned SSL model when trained only on 136 utterances (ca. one minute training time) and that PLDA consistently improves various neural MOS prediction models, even state-of-the-art models with task-specific fine-tuning. Our ablation study shows PLDA training superiority over SSL model fine-tuning in a low-resource scenario. We also improve SSL model fine-tuning using a convenient optimizer choice and additional contrastive and multi-task training objectives. The fine-tuned MooseNet NN with the PLDA module achieves the best results, surpassing the SSL baseline on the VoiceMOS Challenge data.",
    "path": "papers/23/01/2301.07087.json",
    "total_tokens": 1104,
    "translated_title": "MooseNet：一种可训练的合成语音度量学模型与PLDA模块",
    "translated_abstract": "我们提出了一种可训练的语音度量学模型MooseNet，用于预测听众的平均意见分数（MOS）。我们提出了一种新颖的方法，在自监督学习（SSL）神经网络模型中使用基于概率线性判别分析（PLDA）生成模型得到的嵌入层。我们证明，在仅使用136个句子（大约一分钟的训练时间）训练的非微调SSL模型的情况下，PLDA能够取得良好的效果，并且PLDA持续改进各种神经网络的MOS预测模型，甚至包括具有任务特定微调的最先进模型。我们的消融研究表明，在资源有限的情况下，PLDA的训练在SSL模型微调中具有优势。我们还改进了SSL模型微调，采用了合适的优化器选择和额外的对比和多任务训练目标。经过PLDA模块微调的MooseNet神经网络在VoiceMOS Challenge数据集上取得了最好的结果，超过了SSL基线。",
    "tldr": "我们提出了一种可训练的语音度量学模型MooseNet，使用PLDA模块在SSL模型中进行嵌入层生成，能够准确预测听众的平均意见分数（MOS）。通过在低资源情况下对PLDA进行训练，我们证明了它相对于SSL模型微调的优越性。我们还通过选择适当的优化器和额外的训练目标改进了SSL模型的微调效果。经过PLDA模块微调的MooseNet在VoiceMOS Challenge数据集上表现出色，超越了SSL基线模型。"
}