{
    "title": "MQAG: Multiple-choice Question Answering and Generation for Assessing Information Consistency in Summarization. (arXiv:2301.12307v2 [cs.CL] UPDATED)",
    "abstract": "State-of-the-art summarization systems can generate highly fluent summaries. These summaries, however, may contain factual inconsistencies and/or information not present in the source. Hence, an important component of assessing the quality of summaries is to determine whether there is information consistency between the source and the summary. Existing approaches are typically based on lexical matching or representation-based methods. In this work, we introduce an alternative scheme based on standard information-theoretic measures in which the information present in the source and summary is directly compared. We propose a Multiple-choice Question Answering and Generation framework, MQAG, which approximates the information consistency by computing the expected statistical distance between summary and source answer distributions over automatically generated multiple-choice questions. This approach exploits multiple-choice answer probabilities, as predicted answer distributions can be co",
    "link": "http://arxiv.org/abs/2301.12307",
    "context": "Title: MQAG: Multiple-choice Question Answering and Generation for Assessing Information Consistency in Summarization. (arXiv:2301.12307v2 [cs.CL] UPDATED)\nAbstract: State-of-the-art summarization systems can generate highly fluent summaries. These summaries, however, may contain factual inconsistencies and/or information not present in the source. Hence, an important component of assessing the quality of summaries is to determine whether there is information consistency between the source and the summary. Existing approaches are typically based on lexical matching or representation-based methods. In this work, we introduce an alternative scheme based on standard information-theoretic measures in which the information present in the source and summary is directly compared. We propose a Multiple-choice Question Answering and Generation framework, MQAG, which approximates the information consistency by computing the expected statistical distance between summary and source answer distributions over automatically generated multiple-choice questions. This approach exploits multiple-choice answer probabilities, as predicted answer distributions can be co",
    "path": "papers/23/01/2301.12307.json",
    "total_tokens": 849,
    "translated_title": "MQAG: 用于评估摘要中信息一致性的多选题答案生成和回答方法",
    "translated_abstract": "最先进的摘要系统可以生成非常流畅的摘要。然而，这些摘要可能包含事实上的不一致或源文档中不存在的信息。因此，评估摘要质量的一个重要组成部分是确定源文档和摘要之间的信息一致性。现有的方法通常基于词汇匹配或基于表示的方法。在这项工作中，我们引入了一种基于标准信息理论度量的替代方案，直接比较源文档和摘要中的信息。我们提出了一个多选题答案生成和回答框架MQAG，通过计算在自动生成的多选题上摘要和源文档答案分布之间的统计距离来近似信息一致性。该方法利用多选题答案概率，因为预测的答案分布可以共同预测摘要和源文档的信息一致性。",
    "tldr": "MQAG提出了一种基于多选题答案生成和回答的方法来评估摘要中的信息一致性，通过计算预测的答案分布之间的统计距离来近似判断源文档和摘要之间的信息一致性。",
    "en_tdlr": "MQAG introduces a method based on multiple-choice question answering and generation to assess information consistency in summarization, approximating the information consistency between source and summary by calculating the statistical distance between the predicted answer distributions."
}