{
    "title": "Uncertainty Quantification for Local Model Explanations Without Model Access. (arXiv:2301.05761v3 [cs.LG] UPDATED)",
    "abstract": "We present a model-agnostic algorithm for generating post-hoc explanations and uncertainty intervals for a machine learning model when only a static sample of inputs and outputs from the model is available, rather than direct access to the model itself. This situation may arise when model evaluations are expensive; when privacy, security and bandwidth constraints are imposed; or when there is a need for real-time, on-device explanations. Our algorithm uses a bootstrapping approach to quantify the uncertainty that inevitably arises when generating explanations from a finite sample of model queries. Through a simulation study, we show that the uncertainty intervals generated by our algorithm exhibit a favorable trade-off between interval width and coverage probability compared to the naive confidence intervals from classical regression analysis as well as current Bayesian approaches for quantifying explanation uncertainty. We further demonstrate the capabilities of our method by applying",
    "link": "http://arxiv.org/abs/2301.05761",
    "context": "Title: Uncertainty Quantification for Local Model Explanations Without Model Access. (arXiv:2301.05761v3 [cs.LG] UPDATED)\nAbstract: We present a model-agnostic algorithm for generating post-hoc explanations and uncertainty intervals for a machine learning model when only a static sample of inputs and outputs from the model is available, rather than direct access to the model itself. This situation may arise when model evaluations are expensive; when privacy, security and bandwidth constraints are imposed; or when there is a need for real-time, on-device explanations. Our algorithm uses a bootstrapping approach to quantify the uncertainty that inevitably arises when generating explanations from a finite sample of model queries. Through a simulation study, we show that the uncertainty intervals generated by our algorithm exhibit a favorable trade-off between interval width and coverage probability compared to the naive confidence intervals from classical regression analysis as well as current Bayesian approaches for quantifying explanation uncertainty. We further demonstrate the capabilities of our method by applying",
    "path": "papers/23/01/2301.05761.json",
    "total_tokens": 827,
    "translated_title": "无模型访问的本地模型解释的不确定性量化",
    "translated_abstract": "我们提出了一种与模型无关的算法，用于生成后处理解释和不确定性区间，当仅具有模型的静态输入和输出样本时，而不是直接访问模型本身。这种情况可能会在模型评估昂贵、强制实行隐私、安全和带宽限制、或需要实时，设备上的实现时出现。我们的算法使用自举方法来量化不确定性，这种不确定性不可避免地出现在利用有限模型询问的样本生成解释时。通过模拟研究，我们展示了我们算法生成的不确定性区间与经典回归分析的简单置信区间以及当前贝叶斯方法相比，具有有利的区间宽度和覆盖概率的权衡。此外，我们通过应用本方法进一步展示了我们方法的能力。",
    "tldr": "本论文提出了一种无需访问模型本身，通过自举方法量化不确定性的算法，可用于生成后处理解释和不确定性区间，其具有广泛的应用前景和优越的性能。",
    "en_tdlr": "This paper presents a model-agnostic algorithm for generating post-hoc explanations and uncertainty intervals without access to the model itself. The algorithm uses a bootstrapping approach to quantify uncertainty and exhibits favorable trade-offs between interval width and coverage probability compared to current Bayesian approaches."
}