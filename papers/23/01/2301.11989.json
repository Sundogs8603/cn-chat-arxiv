{
    "title": "Practical Differentially Private Hyperparameter Tuning with Subsampling. (arXiv:2301.11989v2 [cs.LG] UPDATED)",
    "abstract": "Tuning the hyperparameters of differentially private (DP) machine learning (ML) algorithms often requires use of sensitive data and this may leak private information via hyperparameter values. Recently, Papernot and Steinke (2022) proposed a certain class of DP hyperparameter tuning algorithms, where the number of random search samples is randomized itself. Commonly, these algorithms still considerably increase the DP privacy parameter $\\varepsilon$ over non-tuned DP ML model training and can be computationally heavy as evaluating each hyperparameter candidate requires a new training run. We focus on lowering both the DP bounds and the computational cost of these methods by using only a random subset of the sensitive data for the hyperparameter tuning and by extrapolating the optimal values to a larger dataset. We provide a R\\'enyi differential privacy analysis for the proposed method and experimentally show that it consistently leads to better privacy-utility trade-off than the baseli",
    "link": "http://arxiv.org/abs/2301.11989",
    "context": "Title: Practical Differentially Private Hyperparameter Tuning with Subsampling. (arXiv:2301.11989v2 [cs.LG] UPDATED)\nAbstract: Tuning the hyperparameters of differentially private (DP) machine learning (ML) algorithms often requires use of sensitive data and this may leak private information via hyperparameter values. Recently, Papernot and Steinke (2022) proposed a certain class of DP hyperparameter tuning algorithms, where the number of random search samples is randomized itself. Commonly, these algorithms still considerably increase the DP privacy parameter $\\varepsilon$ over non-tuned DP ML model training and can be computationally heavy as evaluating each hyperparameter candidate requires a new training run. We focus on lowering both the DP bounds and the computational cost of these methods by using only a random subset of the sensitive data for the hyperparameter tuning and by extrapolating the optimal values to a larger dataset. We provide a R\\'enyi differential privacy analysis for the proposed method and experimentally show that it consistently leads to better privacy-utility trade-off than the baseli",
    "path": "papers/23/01/2301.11989.json",
    "total_tokens": 771,
    "translated_title": "利用子采样实现实用的差分隐私超参数调整",
    "translated_abstract": "调整差分隐私机器学习算法的超参数通常需要使用敏感数据，这可能通过超参数值泄漏私人信息。本文旨在通过仅使用敏感数据的随机子集并将最佳值外推到较大的数据集来降低这些方法的差分隐私界限和计算成本。我们提供了对该方法的 Renyi 差分隐私分析，并证明它在不损失所选超参数的最终评估准确性的情况下，可以始终实现更好的隐私-实用性权衡。",
    "tldr": "本文提出了一种利用子采样实现实用的差分隐私超参数调整的方法，相比基准算法，可以在不损失最终评估结果的情况下提高隐私-实用性权衡。",
    "en_tdlr": "This paper proposes a practical differentially private hyperparameter tuning method using subsampling, which improves the privacy-utility trade-off compared to the baseline algorithm without sacrificing the final evaluation accuracy of the selected hyperparameters."
}