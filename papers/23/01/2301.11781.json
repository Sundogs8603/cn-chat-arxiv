{
    "title": "Aleatoric and Epistemic Discrimination: Fundamental Limits of Fairness Interventions. (arXiv:2301.11781v2 [cs.LG] UPDATED)",
    "abstract": "Machine learning (ML) models can underperform on certain population groups due to choices made during model development and bias inherent in the data. We categorize sources of discrimination in the ML pipeline into two classes: aleatoric discrimination, which is inherent in the data distribution, and epistemic discrimination, which is due to decisions made during model development. We quantify aleatoric discrimination by determining the performance limits of a model under fairness constraints, assuming perfect knowledge of the data distribution. We demonstrate how to characterize aleatoric discrimination by applying Blackwell's results on comparing statistical experiments. We then quantify epistemic discrimination as the gap between a model's accuracy when fairness constraints are applied and the limit posed by aleatoric discrimination. We apply this approach to benchmark existing fairness interventions and investigate fairness risks in data with missing values. Our results indicate th",
    "link": "http://arxiv.org/abs/2301.11781",
    "context": "Title: Aleatoric and Epistemic Discrimination: Fundamental Limits of Fairness Interventions. (arXiv:2301.11781v2 [cs.LG] UPDATED)\nAbstract: Machine learning (ML) models can underperform on certain population groups due to choices made during model development and bias inherent in the data. We categorize sources of discrimination in the ML pipeline into two classes: aleatoric discrimination, which is inherent in the data distribution, and epistemic discrimination, which is due to decisions made during model development. We quantify aleatoric discrimination by determining the performance limits of a model under fairness constraints, assuming perfect knowledge of the data distribution. We demonstrate how to characterize aleatoric discrimination by applying Blackwell's results on comparing statistical experiments. We then quantify epistemic discrimination as the gap between a model's accuracy when fairness constraints are applied and the limit posed by aleatoric discrimination. We apply this approach to benchmark existing fairness interventions and investigate fairness risks in data with missing values. Our results indicate th",
    "path": "papers/23/01/2301.11781.json",
    "total_tokens": 1003,
    "translated_title": "偶然性和认知性歧视：公平干预的基本限制",
    "translated_abstract": "机器学习模型在某些人群中可能表现不佳，原因是在模型开发过程中做出的选择和数据中固有的偏见。我们将机器学习流程中的歧视来源分为两类：偶然性歧视，即数据分布中固有的歧视，和认知性歧视，即模型开发过程中做出的决策导致的歧视。我们通过确定在完全了解数据分布的情况下，在公平约束下模型的性能限制来量化偶然性歧视。我们通过应用布莱克韦尔对比统计实验的结果来刻画偶然性歧视。然后，我们将认知性歧视定义为在应用公平约束时模型的准确性与偶然性歧视所限定的界限之间的差距。我们将这种方法应用于评估现有的公平干预措施，并调查具有缺失值的数据中的公平风险。我们的结果表明...",
    "tldr": "该论文研究了机器学习模型中的偶然性和认知性歧视，将其分类为数据分布中固有的歧视和模型开发过程中的决策导致的歧视。通过量化偶然性歧视的性能限制和刻画认知性歧视，揭示了公平干预的基本限制。研究还应用这种方法评估了现有的公平干预措施，并探究了在存在缺失值的数据中的公平风险。",
    "en_tdlr": "This paper investigates aleatoric and epistemic discrimination in machine learning models, categorizing them as discrimination inherent in the data distribution and discrimination due to decisions made during model development. By quantifying the performance limits of aleatoric discrimination under fairness constraints and characterizing epistemic discrimination, the fundamental limits of fairness interventions are revealed. The study also evaluates existing fairness interventions using this approach and investigates fairness risks in data with missing values."
}