{
    "title": "Why Batch Normalization Damage Federated Learning on Non-IID Data?. (arXiv:2301.02982v2 [cs.LG] UPDATED)",
    "abstract": "As a promising distributed learning paradigm, federated learning (FL) involves training deep neural network (DNN) models at the network edge while protecting the privacy of the edge clients. To train a large-scale DNN model, batch normalization (BN) has been regarded as a simple and effective means to accelerate the training and improve the generalization capability. However, recent findings indicate that BN can significantly impair the performance of FL in the presence of non-i.i.d. data. While several FL algorithms have been proposed to address this issue, their performance still falls significantly when compared to the centralized scheme. Furthermore, none of them have provided a theoretical explanation of how the BN damages the FL convergence. In this paper, we present the first convergence analysis to show that under the non-i.i.d. data, the mismatch between the local and global statistical parameters in BN causes the gradient deviation between the local and global models, which, ",
    "link": "http://arxiv.org/abs/2301.02982",
    "context": "Title: Why Batch Normalization Damage Federated Learning on Non-IID Data?. (arXiv:2301.02982v2 [cs.LG] UPDATED)\nAbstract: As a promising distributed learning paradigm, federated learning (FL) involves training deep neural network (DNN) models at the network edge while protecting the privacy of the edge clients. To train a large-scale DNN model, batch normalization (BN) has been regarded as a simple and effective means to accelerate the training and improve the generalization capability. However, recent findings indicate that BN can significantly impair the performance of FL in the presence of non-i.i.d. data. While several FL algorithms have been proposed to address this issue, their performance still falls significantly when compared to the centralized scheme. Furthermore, none of them have provided a theoretical explanation of how the BN damages the FL convergence. In this paper, we present the first convergence analysis to show that under the non-i.i.d. data, the mismatch between the local and global statistical parameters in BN causes the gradient deviation between the local and global models, which, ",
    "path": "papers/23/01/2301.02982.json",
    "total_tokens": 940,
    "translated_title": "为什么批归一化会损害非独立同分布数据上的联邦学习？",
    "translated_abstract": "作为一种有前景的分布式学习范式，联邦学习（FL）涉及在网络边缘训练深度神经网络（DNN）模型，同时保护边缘客户端的隐私。为了训练大规模的DNN模型，批归一化（BN）被认为是一种简单有效的加速训练和改善泛化能力的方法。然而，最近的研究发现，在非独立同分布数据的情况下，BN会显著损害FL的性能。尽管已经提出了一些FL算法来解决这个问题，但它们的性能仍然明显低于集中式方案。此外，它们没有提供关于BN如何损害FL收敛性的理论解释。在本文中，我们提出了第一个收敛性分析，以展示在非独立同分布数据下，BN中局部和全局统计参数之间的不匹配导致了局部和全局模型之间的梯度偏差，从而影响了联邦学习的收敛性。",
    "tldr": "本文通过首次的收敛性分析发现，非独立同分布数据中，在批归一化中局部和全局统计参数不匹配导致了梯度偏差，从而影响了联邦学习的收敛性。",
    "en_tdlr": "This paper presents the first convergence analysis to show that under non-i.i.d. data, the mismatch between the local and global statistical parameters in batch normalization (BN) causes gradient deviation, impairing the convergence of federated learning (FL)."
}