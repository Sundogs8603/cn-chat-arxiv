{
    "title": "ZegOT: Zero-shot Segmentation Through Optimal Transport of Text Prompts. (arXiv:2301.12171v2 [cs.CV] UPDATED)",
    "abstract": "Recent success of large-scale Contrastive Language-Image Pre-training (CLIP) has led to great promise in zero-shot semantic segmentation by transferring image-text aligned knowledge to pixel-level classification. However, existing methods usually require an additional image encoder or retraining/tuning the CLIP module. Here, we propose a novel Zero-shot segmentation with Optimal Transport (ZegOT) method that matches multiple text prompts with frozen image embeddings through optimal transport. In particular, we introduce a novel Multiple Prompt Optimal Transport Solver (MPOT), which is designed to learn an optimal mapping between multiple text prompts and visual feature maps of the frozen image encoder hidden layers. This unique mapping method facilitates each of the multiple text prompts to effectively focus on distinct visual semantic attributes. Through extensive experiments on benchmark datasets, we show that our method achieves the state-of-the-art (SOTA) performance over existing ",
    "link": "http://arxiv.org/abs/2301.12171",
    "context": "Title: ZegOT: Zero-shot Segmentation Through Optimal Transport of Text Prompts. (arXiv:2301.12171v2 [cs.CV] UPDATED)\nAbstract: Recent success of large-scale Contrastive Language-Image Pre-training (CLIP) has led to great promise in zero-shot semantic segmentation by transferring image-text aligned knowledge to pixel-level classification. However, existing methods usually require an additional image encoder or retraining/tuning the CLIP module. Here, we propose a novel Zero-shot segmentation with Optimal Transport (ZegOT) method that matches multiple text prompts with frozen image embeddings through optimal transport. In particular, we introduce a novel Multiple Prompt Optimal Transport Solver (MPOT), which is designed to learn an optimal mapping between multiple text prompts and visual feature maps of the frozen image encoder hidden layers. This unique mapping method facilitates each of the multiple text prompts to effectively focus on distinct visual semantic attributes. Through extensive experiments on benchmark datasets, we show that our method achieves the state-of-the-art (SOTA) performance over existing ",
    "path": "papers/23/01/2301.12171.json",
    "total_tokens": 944,
    "translated_title": "ZegOT:使用文本提示的最优传输实现零样本分割。",
    "translated_abstract": "通过将图像和文本对齐的方法，利用大规模对比性语言-图像预训练（CLIP）的成功为零样本语义分割带来了很大的希望，然而现有的方法通常需要额外的图像编码器或对CLIP模块进行重新训练或微调。本论文提出了一种新的ZegOT方法，通过最优传输将多个文本提示与冻结的图像嵌入匹配，从而实现零样本分割。特别是，通过引入一种新的多提示最优传输求解器（MPOT），该方法为每个文本提示与冻结的图像编码器隐藏层的视觉特征映射之间学习了一种最优映射。这种独特的映射方法有效地使每个文本提示关注不同的视觉语义属性。通过在基准数据集上进行广泛的实验，我们展示了我们的方法优于现有方法，达到了最先进的性能水平。",
    "tldr": "这篇论文提出了一种通过最优传输的方法，利用多个文本提示来实现零样本分割，达到了最先进的性能水平。",
    "en_tdlr": "This paper proposes a novel method of zero-shot segmentation using optimal transport of multiple text prompts, achieving state-of-the-art performance without requiring an additional image encoder or retraining CLIP module."
}