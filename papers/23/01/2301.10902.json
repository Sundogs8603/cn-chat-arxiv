{
    "title": "Efficient Hyperdimensional Computing. (arXiv:2301.10902v2 [cs.LG] UPDATED)",
    "abstract": "Hyperdimensional computing (HDC) is a method to perform classification that uses binary vectors with high dimensions and the majority rule. This approach has the potential to be energy-efficient and hence deemed suitable for resource-limited platforms due to its simplicity and massive parallelism. However, in order to achieve high accuracy, HDC sometimes uses hypervectors with tens of thousands of dimensions. This potentially negates its efficiency advantage. In this paper, we examine the necessity of such high dimensions and conduct a detailed theoretical analysis of the relationship between hypervector dimensions and accuracy. Our results demonstrate that as the dimension of the hypervectors increases, the worst-case/average-case HDC prediction accuracy with the majority rule decreases. Building on this insight, we develop HDC models that use binary hypervectors with dimensions orders of magnitude lower than those of state-of-the-art HDC models while maintaining equivalent or even im",
    "link": "http://arxiv.org/abs/2301.10902",
    "context": "Title: Efficient Hyperdimensional Computing. (arXiv:2301.10902v2 [cs.LG] UPDATED)\nAbstract: Hyperdimensional computing (HDC) is a method to perform classification that uses binary vectors with high dimensions and the majority rule. This approach has the potential to be energy-efficient and hence deemed suitable for resource-limited platforms due to its simplicity and massive parallelism. However, in order to achieve high accuracy, HDC sometimes uses hypervectors with tens of thousands of dimensions. This potentially negates its efficiency advantage. In this paper, we examine the necessity of such high dimensions and conduct a detailed theoretical analysis of the relationship between hypervector dimensions and accuracy. Our results demonstrate that as the dimension of the hypervectors increases, the worst-case/average-case HDC prediction accuracy with the majority rule decreases. Building on this insight, we develop HDC models that use binary hypervectors with dimensions orders of magnitude lower than those of state-of-the-art HDC models while maintaining equivalent or even im",
    "path": "papers/23/01/2301.10902.json",
    "total_tokens": 911,
    "translated_title": "高效的高维计算",
    "translated_abstract": "高维计算是一种使用高维二进制向量和多数规则进行分类的方法。这种方法由于其简单性和大规模并行性，具有节能的潜力，因此被认为适用于资源受限平台。然而，为了获得高准确度，高维计算有时会使用成千上万维的超向量，这可能抵消了其效率优势。本文研究了这种高维度的必要性，并对超向量维度与准确度之间的关系进行了详细的理论分析。我们的结果表明，随着超向量维度的增加，采用多数规则的高维计算在最坏情况和平均情况下的预测准确度会降低。基于这一观察，我们开发了高维计算模型，使用维度比最先进的模型低几个数量级的二进制超向量，同时保持等效甚至更优的准确度。",
    "tldr": "本论文研究了高维计算中高维度超向量的必要性，并通过理论分析发现，超向量维度的增加会降低高维计算的预测准确度。基于此，研究人员开发了使用维度更低的二进制超向量的高维计算模型，同时保持相等甚至更优的准确度。"
}