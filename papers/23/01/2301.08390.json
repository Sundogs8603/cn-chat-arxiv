{
    "title": "Open-Set Likelihood Maximization for Few-Shot Learning. (arXiv:2301.08390v2 [cs.CV] UPDATED)",
    "abstract": "We tackle the Few-Shot Open-Set Recognition (FSOSR) problem, i.e. classifying instances among a set of classes for which we only have a few labeled samples, while simultaneously detecting instances that do not belong to any known class. We explore the popular transductive setting, which leverages the unlabelled query instances at inference. Motivated by the observation that existing transductive methods perform poorly in open-set scenarios, we propose a generalization of the maximum likelihood principle, in which latent scores down-weighing the influence of potential outliers are introduced alongside the usual parametric model. Our formulation embeds supervision constraints from the support set and additional penalties discouraging overconfident predictions on the query set. We proceed with a block-coordinate descent, with the latent scores and parametric model co-optimized alternately, thereby benefiting from each other. We call our resulting formulation \\textit{Open-Set Likelihood Op",
    "link": "http://arxiv.org/abs/2301.08390",
    "context": "Title: Open-Set Likelihood Maximization for Few-Shot Learning. (arXiv:2301.08390v2 [cs.CV] UPDATED)\nAbstract: We tackle the Few-Shot Open-Set Recognition (FSOSR) problem, i.e. classifying instances among a set of classes for which we only have a few labeled samples, while simultaneously detecting instances that do not belong to any known class. We explore the popular transductive setting, which leverages the unlabelled query instances at inference. Motivated by the observation that existing transductive methods perform poorly in open-set scenarios, we propose a generalization of the maximum likelihood principle, in which latent scores down-weighing the influence of potential outliers are introduced alongside the usual parametric model. Our formulation embeds supervision constraints from the support set and additional penalties discouraging overconfident predictions on the query set. We proceed with a block-coordinate descent, with the latent scores and parametric model co-optimized alternately, thereby benefiting from each other. We call our resulting formulation \\textit{Open-Set Likelihood Op",
    "path": "papers/23/01/2301.08390.json",
    "total_tokens": 908,
    "translated_title": "针对少样本开放集识别问题的开放集似然最大化方法",
    "translated_abstract": "本文研究了少样本开放集识别问题，即在只有很少标记样本的情况下对一组类别中的实例进行分类，并同时检测不属于任何已知类别的实例。我们探索了流行的传导设置，利用推理时未标记的查询实例。由于现有的传导方法在开放集场景下表现不佳，我们提出了一种广义最大似然原则，其中除了通常的参数模型外，还引入了下调潜在异常值影响的潜在得分。我们的公式从支持集嵌入监督约束和附加惩罚，以防止对查询集的过度自信的预测。我们采用块坐标下降，轮流共同优化潜在得分和参数模型，从而互相受益。我们称之为Open-Set Likelihood Optimization（OSLO），并在少样本开放集基准测试中证明了其与基线方法相比的有效性。",
    "tldr": "本文提出了一种针对少样本开放集识别问题的开放集似然最大化方法，可以在利用未标记查询实例进行推理时提高模型的鲁棒性和准确性。",
    "en_tdlr": "This paper proposes an open-set likelihood maximization method for few-shot open-set recognition, which introduces latent scores down-weighting the influence of potential outliers and embeds supervision constraints and additional penalties to improve the robustness and accuracy of models when utilizing unlabelled query instances for inference."
}