{
    "title": "Efficient Online Learning with Memory via Frank-Wolfe Optimization: Algorithms with Bounded Dynamic Regret and Applications to Control. (arXiv:2301.00497v2 [cs.LG] UPDATED)",
    "abstract": "Projection operations are a typical computation bottleneck in online learning. In this paper, we enable projection-free online learning within the framework of Online Convex Optimization with Memory (OCO-M) -- OCO-M captures how the history of decisions affects the current outcome by allowing the online learning loss functions to depend on both current and past decisions. Particularly, we introduce the first projection-free meta-base learning algorithm with memory that minimizes dynamic regret, i.e., that minimizes the suboptimality against any sequence of time-varying decisions. We are motivated by artificial intelligence applications where autonomous agents need to adapt to time-varying environments in real-time, accounting for how past decisions affect the present. Examples of such applications are: online control of dynamical systems; statistical arbitrage; and time series prediction. The algorithm builds on the Online Frank-Wolfe (OFW) and Hedge algorithms. We demonstrate how our ",
    "link": "http://arxiv.org/abs/2301.00497",
    "context": "Title: Efficient Online Learning with Memory via Frank-Wolfe Optimization: Algorithms with Bounded Dynamic Regret and Applications to Control. (arXiv:2301.00497v2 [cs.LG] UPDATED)\nAbstract: Projection operations are a typical computation bottleneck in online learning. In this paper, we enable projection-free online learning within the framework of Online Convex Optimization with Memory (OCO-M) -- OCO-M captures how the history of decisions affects the current outcome by allowing the online learning loss functions to depend on both current and past decisions. Particularly, we introduce the first projection-free meta-base learning algorithm with memory that minimizes dynamic regret, i.e., that minimizes the suboptimality against any sequence of time-varying decisions. We are motivated by artificial intelligence applications where autonomous agents need to adapt to time-varying environments in real-time, accounting for how past decisions affect the present. Examples of such applications are: online control of dynamical systems; statistical arbitrage; and time series prediction. The algorithm builds on the Online Frank-Wolfe (OFW) and Hedge algorithms. We demonstrate how our ",
    "path": "papers/23/01/2301.00497.json",
    "total_tokens": 922,
    "translated_title": "基于Frank-Wolfe优化的高效内存在线学习：具有有界动态遗憾的算法和控制应用",
    "translated_abstract": "投影操作是在线学习中的典型计算瓶颈。本文在在线凸优化的记忆框架中实现了无投影的在线学习。具体地，OCO-M反映了决策历史如何影响当前结果，并允许在线学习损失函数依赖于当前和过去的决策。特别地，我们引入了第一个具有内存的无投影基学习算法，该算法使动态遗憾最小化，即最小化与任何时变决策序列的次优性。本算法以在线Frank-Wolfe（OFW）和Hedge算法为基础，旨在解决人工智能应用中的问题，例如需要在实时中适应时变环境，并考虑过去决策对现在的影响。这些应用包括：动态系统的在线控制，统计套利和时间序列预测。",
    "tldr": "本文介绍了基于Frank-Wolfe优化的高效内存在线学习算法，该算法以历史决策为基础，适应实时时变环境。该算法广泛应用于动态系统的在线控制，统计套利和时间序列预测等人工智能领域。"
}