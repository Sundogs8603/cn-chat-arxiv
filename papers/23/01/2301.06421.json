{
    "title": "AI Alignment Dialogues: An Interactive Approach to AI Alignment in Support Agents. (arXiv:2301.06421v2 [cs.AI] UPDATED)",
    "abstract": "AI alignment is about ensuring AI systems only pursue goals and activities that are beneficial to humans. Most of the current approach to AI alignment is to learn what humans value from their behavioural data. This paper proposes a different way of looking at the notion of alignment, namely by introducing AI Alignment Dialogues: dialogues with which users and agents try to achieve and maintain alignment via interaction. We argue that alignment dialogues have a number of advantages in comparison to data-driven approaches, especially for behaviour support agents, which aim to support users in achieving their desired future behaviours rather than their current behaviours. The advantages of alignment dialogues include allowing the users to directly convey higher-level concepts to the agent, and making the agent more transparent and trustworthy. In this paper we outline the concept and high-level structure of alignment dialogues. Moreover, we conducted a qualitative focus group user study f",
    "link": "http://arxiv.org/abs/2301.06421",
    "context": "Title: AI Alignment Dialogues: An Interactive Approach to AI Alignment in Support Agents. (arXiv:2301.06421v2 [cs.AI] UPDATED)\nAbstract: AI alignment is about ensuring AI systems only pursue goals and activities that are beneficial to humans. Most of the current approach to AI alignment is to learn what humans value from their behavioural data. This paper proposes a different way of looking at the notion of alignment, namely by introducing AI Alignment Dialogues: dialogues with which users and agents try to achieve and maintain alignment via interaction. We argue that alignment dialogues have a number of advantages in comparison to data-driven approaches, especially for behaviour support agents, which aim to support users in achieving their desired future behaviours rather than their current behaviours. The advantages of alignment dialogues include allowing the users to directly convey higher-level concepts to the agent, and making the agent more transparent and trustworthy. In this paper we outline the concept and high-level structure of alignment dialogues. Moreover, we conducted a qualitative focus group user study f",
    "path": "papers/23/01/2301.06421.json",
    "total_tokens": 863,
    "translated_title": "AI对齐对话：一种与支持代理完成AI对齐的交互方法",
    "translated_abstract": "AI对齐是确保AI系统只追求有益于人类的目标和活动。目前大部分AI对齐的方法是通过学习人类的行为数据来了解人类的价值观。本文提出了一种不同的对齐概念，即引入AI对齐对话：用户和代理通过交互努力实现和维持对齐。我们认为，与数据驱动的方法相比，对齐对话具有许多优势，特别适用于行为支持代理，这些代理旨在帮助用户实现他们期望的未来行为，而不仅仅是当前的行为。对齐对话的优势包括允许用户直接传达更高级的概念给代理，并使代理更加透明和可信。在本文中，我们阐述了对齐对话的概念和高层结构。此外，我们进行了定性的焦点小组用户研究。",
    "tldr": "本文介绍了一种名为AI对齐对话的新方法，该方法通过用户和代理的交互努力实现和维持AI对齐，并相比数据驱动的方法在行为支持代理方面具有更多优势。",
    "en_tdlr": "This paper introduces a new approach called AI Alignment Dialogues, where alignment is achieved and maintained through interaction between users and agents, offering more advantages compared to data-driven methods, particularly for behavior support agents."
}