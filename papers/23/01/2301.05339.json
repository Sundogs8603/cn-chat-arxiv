{
    "title": "A Comprehensive Review of Data-Driven Co-Speech Gesture Generation. (arXiv:2301.05339v4 [cs.GR] UPDATED)",
    "abstract": "Gestures that accompany speech are an essential part of natural and efficient embodied human communication. The automatic generation of such co-speech gestures is a long-standing problem in computer animation and is considered an enabling technology in film, games, virtual social spaces, and for interaction with social robots. The problem is made challenging by the idiosyncratic and non-periodic nature of human co-speech gesture motion, and by the great diversity of communicative functions that gestures encompass. Gesture generation has seen surging interest recently, owing to the emergence of more and larger datasets of human gesture motion, combined with strides in deep-learning-based generative models, that benefit from the growing availability of data. This review article summarizes co-speech gesture generation research, with a particular focus on deep generative models. First, we articulate the theory describing human gesticulation and how it complements speech. Next, we briefly d",
    "link": "http://arxiv.org/abs/2301.05339",
    "context": "Title: A Comprehensive Review of Data-Driven Co-Speech Gesture Generation. (arXiv:2301.05339v4 [cs.GR] UPDATED)\nAbstract: Gestures that accompany speech are an essential part of natural and efficient embodied human communication. The automatic generation of such co-speech gestures is a long-standing problem in computer animation and is considered an enabling technology in film, games, virtual social spaces, and for interaction with social robots. The problem is made challenging by the idiosyncratic and non-periodic nature of human co-speech gesture motion, and by the great diversity of communicative functions that gestures encompass. Gesture generation has seen surging interest recently, owing to the emergence of more and larger datasets of human gesture motion, combined with strides in deep-learning-based generative models, that benefit from the growing availability of data. This review article summarizes co-speech gesture generation research, with a particular focus on deep generative models. First, we articulate the theory describing human gesticulation and how it complements speech. Next, we briefly d",
    "path": "papers/23/01/2301.05339.json",
    "total_tokens": 859,
    "translated_title": "基于数据驱动的共语手势生成综述",
    "translated_abstract": "伴随语言的手势是自然而有效的人类交流中不可或缺的一部分。自动生成这种共语手势是计算机动画中长期存在的问题，被认为是电影、游戏、虚拟社交空间以及与社交机器人交互的一种使能技术。由于人类共语手势运动的独特性和非周期性，以及手势所包括的交际功能的多样性，使得该问题难以解决。最近，随着越来越多的人类手势数据集的出现，加上基于深度学习的生成模型的进步，手势生成引起了越来越多的关注。",
    "tldr": "该论文综述了共语手势的生成研究，重点在深度生成模型上。共语手势是自然通信的一部分，对于电影和游戏等领域具有广泛的应用。随着越来越大的手势数据集和深度学习生成模型的进步，该领域有着广阔的研究前景。",
    "en_tdlr": "This paper provides a comprehensive review of co-speech gesture generation research, with a focus on deep generative models. Co-speech gestures are an essential part of natural communication and have broad applications in fields such as film and gaming. The growing availability of larger datasets and advances in deep learning-based generative models have great potential in this area."
}