{
    "title": "Co-manipulation of soft-materials estimating deformation from depth images. (arXiv:2301.05609v3 [cs.RO] UPDATED)",
    "abstract": "Human-robot co-manipulation of soft materials, such as fabrics, composites, and sheets of paper/cardboard, is a challenging operation that presents several relevant industrial applications. Estimating the deformation state of the co-manipulated material is one of the main challenges. Viable methods provide the indirect measure by calculating the human-robot relative distance. In this paper, we develop a data-driven model to estimate the deformation state of the material from a depth image through a Convolutional Neural Network (CNN). First, we define the deformation state of the material as the relative roto-translation from the current robot pose and a human grasping position. The model estimates the current deformation state through a Convolutional Neural Network, specifically a DenseNet-121 pretrained on ImageNet.The delta between the current and the desired deformation state is fed to the robot controller that outputs twist commands. The paper describes the developed approach to ac",
    "link": "http://arxiv.org/abs/2301.05609",
    "context": "Title: Co-manipulation of soft-materials estimating deformation from depth images. (arXiv:2301.05609v3 [cs.RO] UPDATED)\nAbstract: Human-robot co-manipulation of soft materials, such as fabrics, composites, and sheets of paper/cardboard, is a challenging operation that presents several relevant industrial applications. Estimating the deformation state of the co-manipulated material is one of the main challenges. Viable methods provide the indirect measure by calculating the human-robot relative distance. In this paper, we develop a data-driven model to estimate the deformation state of the material from a depth image through a Convolutional Neural Network (CNN). First, we define the deformation state of the material as the relative roto-translation from the current robot pose and a human grasping position. The model estimates the current deformation state through a Convolutional Neural Network, specifically a DenseNet-121 pretrained on ImageNet.The delta between the current and the desired deformation state is fed to the robot controller that outputs twist commands. The paper describes the developed approach to ac",
    "path": "papers/23/01/2301.05609.json",
    "total_tokens": 873,
    "tldr": "本文提出了一种基于深度图像和卷积神经网络的数据驱动模型，通过计算变形状态的相对旋转和平移量估算共同操作软物料的变形状态。这种方法可以在工业应用中发挥重要作用。"
}