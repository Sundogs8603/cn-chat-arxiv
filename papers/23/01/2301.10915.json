{
    "title": "Parameter-Efficient Low-Resource Dialogue State Tracking by Prompt Tuning. (arXiv:2301.10915v2 [cs.CL] UPDATED)",
    "abstract": "Dialogue state tracking (DST) is an important step in dialogue management to keep track of users' beliefs. Existing works fine-tune all language model (LM) parameters to tackle the DST task, which requires significant data and computing resources for training and hosting. The cost grows exponentially in the real-world deployment where dozens of fine-tuned LM are used for different domains and tasks. To reduce parameter size and better utilize cross-task shared information, we propose to use soft prompt token embeddings to learn task properties. Without tuning LM parameters, our method drastically reduces the number of parameters needed to less than 0.5% of prior works while achieves better low-resource DST performance.",
    "link": "http://arxiv.org/abs/2301.10915",
    "context": "Title: Parameter-Efficient Low-Resource Dialogue State Tracking by Prompt Tuning. (arXiv:2301.10915v2 [cs.CL] UPDATED)\nAbstract: Dialogue state tracking (DST) is an important step in dialogue management to keep track of users' beliefs. Existing works fine-tune all language model (LM) parameters to tackle the DST task, which requires significant data and computing resources for training and hosting. The cost grows exponentially in the real-world deployment where dozens of fine-tuned LM are used for different domains and tasks. To reduce parameter size and better utilize cross-task shared information, we propose to use soft prompt token embeddings to learn task properties. Without tuning LM parameters, our method drastically reduces the number of parameters needed to less than 0.5% of prior works while achieves better low-resource DST performance.",
    "path": "papers/23/01/2301.10915.json",
    "total_tokens": 780,
    "translated_title": "通过提示调整实现参数高效的低资源对话状态跟踪",
    "translated_abstract": "对话状态跟踪是对话管理中的一个重要步骤，需要跟踪用户的信念状态。现有的方法需要大量数据和计算资源对所有语言模型参数进行微调来应对对话状态跟踪任务。在实际部署中，需要为不同的领域和任务使用几十个微调了的语言模型，所需的成本呈指数级增长。为了降低参数大小并更好地利用跨任务共享的信息，我们提出使用软提示令牌嵌入来学习任务属性。在不微调语言模型参数的情况下，我们的方法将参数数量大幅减少到少于之前方法的0.5％，同时实现了更好的低资源对话状态跟踪性能。",
    "tldr": "这篇论文提出了一种通过使用软提示令牌嵌入来学习任务属性的方法，以实现参数高效的低资源对话状态跟踪，同时在不微调语言模型参数的情况下，取得了比之前方法更好的性能表现。",
    "en_tdlr": "This paper proposes a method of parameter-efficient low-resource dialogue state tracking by using soft prompt token embeddings to learn task properties, which reduces the number of parameters drastically to less than 0.5% of prior works and achieves better performance without fine-tuning language model parameters."
}