{
    "title": "Optimally-Weighted Estimators of the Maximum Mean Discrepancy for Likelihood-Free Inference. (arXiv:2301.11674v4 [stat.ME] UPDATED)",
    "abstract": "Likelihood-free inference methods typically make use of a distance between simulated and real data. A common example is the maximum mean discrepancy (MMD), which has previously been used for approximate Bayesian computation, minimum distance estimation, generalised Bayesian inference, and within the nonparametric learning framework. The MMD is commonly estimated at a root-$m$ rate, where $m$ is the number of simulated samples. This can lead to significant computational challenges since a large $m$ is required to obtain an accurate estimate, which is crucial for parameter estimation. In this paper, we propose a novel estimator for the MMD with significantly improved sample complexity. The estimator is particularly well suited for computationally expensive smooth simulators with low- to mid-dimensional inputs. This claim is supported through both theoretical results and an extensive simulation study on benchmark simulators.",
    "link": "http://arxiv.org/abs/2301.11674",
    "context": "Title: Optimally-Weighted Estimators of the Maximum Mean Discrepancy for Likelihood-Free Inference. (arXiv:2301.11674v4 [stat.ME] UPDATED)\nAbstract: Likelihood-free inference methods typically make use of a distance between simulated and real data. A common example is the maximum mean discrepancy (MMD), which has previously been used for approximate Bayesian computation, minimum distance estimation, generalised Bayesian inference, and within the nonparametric learning framework. The MMD is commonly estimated at a root-$m$ rate, where $m$ is the number of simulated samples. This can lead to significant computational challenges since a large $m$ is required to obtain an accurate estimate, which is crucial for parameter estimation. In this paper, we propose a novel estimator for the MMD with significantly improved sample complexity. The estimator is particularly well suited for computationally expensive smooth simulators with low- to mid-dimensional inputs. This claim is supported through both theoretical results and an extensive simulation study on benchmark simulators.",
    "path": "papers/23/01/2301.11674.json",
    "total_tokens": 873,
    "translated_title": "无似然推断的最大均值差异的最优加权估计",
    "translated_abstract": "无似然推断方法通常使用模拟数据和真实数据之间的距离。其中一种常见方法是最大均值差异（MMD），其先前已用于近似贝叶斯计算、最小距离估计、广义贝叶斯推断和非参数学习框架中。 MMD通常以根- $m$速率进行估计，其中$ m $是模拟样本数。这可能会导致重大的计算挑战，因为需要大量的$ m $才能获得准确的估计结果，这对于参数估计至关重要。在本文中，我们提出了一种新的MMD估计方法，其样本复杂度显着提高。 这个估计器特别适用于计算昂贵，平滑的模拟器和低维到中维的输入。该论文通过理论结果和对基准模拟器的广泛模拟研究支持该主张。",
    "tldr": "该论文提出了一种新的MMD估计方法，其样本复杂度显着提高，特别适用于计算成本昂贵、平滑的模拟器和低维到中维的输入。",
    "en_tdlr": "This paper proposes a novel estimator for the maximum mean discrepancy (MMD) with significantly improved sample complexity, particularly suited for computationally expensive smooth simulators with low- to mid-dimensional inputs. The claim is supported through theoretical results and simulation studies on benchmark simulators."
}