{
    "title": "gRoMA: a Tool for Measuring Deep Neural Networks Global Robustness. (arXiv:2301.02288v2 [cs.LG] UPDATED)",
    "abstract": "Deep neural networks (DNNs) are at the forefront of cutting-edge technology, and have been achieving remarkable performance in a variety of complex tasks. Nevertheless, their integration into safety-critical systems, such as in the aerospace or automotive domains, poses a significant challenge due to the threat of adversarial inputs: perturbations in inputs that might cause the DNN to make grievous mistakes. Multiple studies have demonstrated that even modern DNNs are susceptible to adversarial inputs; and this risk must thus be measured and mitigated to allow the deployment of DNNs in safety-critical systems.  Here, we present gRoMA (global Robustness Measurement and Assessment), an innovative and scalable tool that implements a probabilistic verification approach to measure the global categorial robustness of a DNN. Specifically, gRoMA measures the probability of encountering adversarial inputs for a specific output category. Our tool operates on pre-trained, black-box classification",
    "link": "http://arxiv.org/abs/2301.02288",
    "context": "Title: gRoMA: a Tool for Measuring Deep Neural Networks Global Robustness. (arXiv:2301.02288v2 [cs.LG] UPDATED)\nAbstract: Deep neural networks (DNNs) are at the forefront of cutting-edge technology, and have been achieving remarkable performance in a variety of complex tasks. Nevertheless, their integration into safety-critical systems, such as in the aerospace or automotive domains, poses a significant challenge due to the threat of adversarial inputs: perturbations in inputs that might cause the DNN to make grievous mistakes. Multiple studies have demonstrated that even modern DNNs are susceptible to adversarial inputs; and this risk must thus be measured and mitigated to allow the deployment of DNNs in safety-critical systems.  Here, we present gRoMA (global Robustness Measurement and Assessment), an innovative and scalable tool that implements a probabilistic verification approach to measure the global categorial robustness of a DNN. Specifically, gRoMA measures the probability of encountering adversarial inputs for a specific output category. Our tool operates on pre-trained, black-box classification",
    "path": "papers/23/01/2301.02288.json",
    "total_tokens": 1078,
    "translated_title": "gRoMA: 一种衡量深度神经网络全局鲁棒性的工具",
    "translated_abstract": "深度神经网络（DNN）是前沿技术的代表，在各种复杂任务中取得了显著的表现。然而，将它们应用于安全关键系统（如航空或汽车领域）时，由于对抗性输入（即可能导致DNN犯错的输入扰动）的威胁，存在重大挑战。多项研究表明即便是现代DNN也容易受到对抗性输入的影响，因此必须测量并降低这种风险才能在安全关键系统中部署DNN。在这里，我们提出了一种创新且可扩展的工具gRoMA（全局鲁棒性测量和评估），它实现了一种概率验证方法来测量DNN的全局分类鲁棒性。具体而言，gRoMA测量特定输出类别遇到对抗性输入的概率。我们的工具基于预训练的黑盒分类模型，产生整个模型和每个输入样本的鲁棒性测量结果。我们通过测量多个最先进的DNN在热门图像数据集上的鲁棒性并分析结果，证明了我们的工具的有效性。",
    "tldr": "gRoMA是一种衡量DNN全局鲁棒性的创新工具，采用概率验证方法评估特定输出类别遭受到对抗性输入的概率。该工具可运行于预训练的黑盒分类模型上，并对整个模型和每个输入样本产生鲁棒性测量结果。",
    "en_tdlr": "gRoMA is an innovative tool for measuring the global robustness of DNNs. It uses a probabilistic verification approach to assess the probability of encountering adversarial inputs for a specific output category. The tool operates on pre-trained, black-box classification models and produces robustness measures for both individual input samples and for the entire model."
}