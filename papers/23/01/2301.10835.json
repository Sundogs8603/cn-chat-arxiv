{
    "title": "When Layers Play the Lottery, all Tickets Win at Initialization",
    "abstract": "arXiv:2301.10835v2 Announce Type: replace  Abstract: Pruning is a standard technique for reducing the computational cost of deep networks. Many advances in pruning leverage concepts from the Lottery Ticket Hypothesis (LTH). LTH reveals that inside a trained dense network exists sparse subnetworks (tickets) able to achieve similar accuracy (i.e., win the lottery - winning tickets). Pruning at initialization focuses on finding winning tickets without training a dense network. Studies on these concepts share the trend that subnetworks come from weight or filter pruning. In this work, we investigate LTH and pruning at initialization from the lens of layer pruning. First, we confirm the existence of winning tickets when the pruning process removes layers. Leveraged by this observation, we propose to discover these winning tickets at initialization, eliminating the requirement of heavy computational resources for training the initial (over-parameterized) dense network. Extensive experiments ",
    "link": "https://arxiv.org/abs/2301.10835",
    "context": "Title: When Layers Play the Lottery, all Tickets Win at Initialization\nAbstract: arXiv:2301.10835v2 Announce Type: replace  Abstract: Pruning is a standard technique for reducing the computational cost of deep networks. Many advances in pruning leverage concepts from the Lottery Ticket Hypothesis (LTH). LTH reveals that inside a trained dense network exists sparse subnetworks (tickets) able to achieve similar accuracy (i.e., win the lottery - winning tickets). Pruning at initialization focuses on finding winning tickets without training a dense network. Studies on these concepts share the trend that subnetworks come from weight or filter pruning. In this work, we investigate LTH and pruning at initialization from the lens of layer pruning. First, we confirm the existence of winning tickets when the pruning process removes layers. Leveraged by this observation, we propose to discover these winning tickets at initialization, eliminating the requirement of heavy computational resources for training the initial (over-parameterized) dense network. Extensive experiments ",
    "path": "papers/23/01/2301.10835.json",
    "total_tokens": 880,
    "translated_title": "当层次抽奖时，所有票据在初始化时都获胜",
    "translated_abstract": "剪枝是减少深度网络计算成本的标准技术。许多剪枝中的进展利用了“彩票假设”（LTH）的概念。LTH揭示了在经过训练的稠密网络内部存在着能够达到类似准确度（即赢得彩票 - 获胜票）的稀疏子网络（票）。在初始化时进行剪枝注重于找到获胜票，而无需训练稠密网络。关于这些概念的研究表明子网络来自权重或滤波器剪枝的趋势。在这项工作中，我们从层次剪枝的视角研究了LTH和初始化时的剪枝。首先，我们确认了当剪枝过程移除层时获胜票的存在。借助这一观察结果，我们提出在初始化时发现这些获胜票，消除了训练初始（过参数化）稠密网络所需的大量计算资源的要求。大量实验...",
    "tldr": "本文从层次剪枝的角度研究了LTH和初始化时的剪枝，在初始化阶段发现了获胜彩票的存在，从而消除了训练稠密网络的大量计算资源需求。",
    "en_tdlr": "This paper investigates the Lottery Ticket Hypothesis (LTH) and pruning at initialization from the perspective of layer pruning, discovering winning tickets at initialization to eliminate the heavy computational resources required for training the dense network."
}