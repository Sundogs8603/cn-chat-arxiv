{
    "title": "Understanding Best Subset Selection: A Tale of Two C(omplex)ities. (arXiv:2301.06259v2 [math.ST] UPDATED)",
    "abstract": "For decades, best subset selection (BSS) has eluded statisticians mainly due to its computational bottleneck. However, until recently, modern computational breakthroughs have rekindled theoretical interest in BSS and have led to new findings. Recently, \\cite{guo2020best} showed that the model selection performance of BSS is governed by a margin quantity that is robust to the design dependence, unlike modern methods such as LASSO, SCAD, MCP, etc. Motivated by their theoretical results, in this paper, we also study the variable selection properties of best subset selection for high-dimensional sparse linear regression setup. We show that apart from the identifiability margin, the following two complexity measures play a fundamental role in characterizing the margin condition for model consistency: (a) complexity of \\emph{residualized features}, (b) complexity of \\emph{spurious projections}. In particular, we establish a simple margin condition that depends only on the identifiability mar",
    "link": "http://arxiv.org/abs/2301.06259",
    "context": "Title: Understanding Best Subset Selection: A Tale of Two C(omplex)ities. (arXiv:2301.06259v2 [math.ST] UPDATED)\nAbstract: For decades, best subset selection (BSS) has eluded statisticians mainly due to its computational bottleneck. However, until recently, modern computational breakthroughs have rekindled theoretical interest in BSS and have led to new findings. Recently, \\cite{guo2020best} showed that the model selection performance of BSS is governed by a margin quantity that is robust to the design dependence, unlike modern methods such as LASSO, SCAD, MCP, etc. Motivated by their theoretical results, in this paper, we also study the variable selection properties of best subset selection for high-dimensional sparse linear regression setup. We show that apart from the identifiability margin, the following two complexity measures play a fundamental role in characterizing the margin condition for model consistency: (a) complexity of \\emph{residualized features}, (b) complexity of \\emph{spurious projections}. In particular, we establish a simple margin condition that depends only on the identifiability mar",
    "path": "papers/23/01/2301.06259.json",
    "total_tokens": 923,
    "translated_title": "了解最佳子集选择: 两种复杂性的故事",
    "translated_abstract": "几十年来，最佳子集选择(BSS)主要由于计算瓶颈而困扰统计学家。然而，直到最近，现代计算突破重新点燃了对BSS的理论兴趣并导致了新的发现。最近，Guo等人表明，BSS的模型选择性能受到了鲁棒性设计依赖的边界量的控制，不像LASSO、SCAD、MCP等现代方法。在他们的理论结果的激励下，本文还研究了高维稀疏线性回归设置下最佳子集选择的变量选择性质。我们展示了除了可辨识性边界以外，下列两种复杂性度量在表征模型一致性边界条件中起着基本的作用：(a)“残差化特征”的复杂性，(b)“虚假投影”的复杂性。特别地，我们建立了一个仅依赖于可辨识性边界的简单边界条件。",
    "tldr": "本文研究了最佳子集选择在高维稀疏线性回归设置中的变量选择性质，通过研究残差化特征和虚假投影的复杂性来揭示模型一致性的边界条件。",
    "en_tdlr": "This paper studies the variable selection properties of best subset selection for high-dimensional sparse linear regression, highlighting the role of complexity measures related to residualized features and spurious projections in characterizing the margin condition for model consistency."
}