{
    "title": "AudioLDM: Text-to-Audio Generation with Latent Diffusion Models. (arXiv:2301.12503v3 [cs.SD] UPDATED)",
    "abstract": "Text-to-audio (TTA) system has recently gained attention for its ability to synthesize general audio based on text descriptions. However, previous studies in TTA have limited generation quality with high computational costs. In this study, we propose AudioLDM, a TTA system that is built on a latent space to learn the continuous audio representations from contrastive language-audio pretraining (CLAP) latents. The pretrained CLAP models enable us to train LDMs with audio embedding while providing text embedding as a condition during sampling. By learning the latent representations of audio signals and their compositions without modeling the cross-modal relationship, AudioLDM is advantageous in both generation quality and computational efficiency. Trained on AudioCaps with a single GPU, AudioLDM achieves state-of-the-art TTA performance measured by both objective and subjective metrics (e.g., frechet distance). Moreover, AudioLDM is the first TTA system that enables various text-guided au",
    "link": "http://arxiv.org/abs/2301.12503",
    "context": "Title: AudioLDM: Text-to-Audio Generation with Latent Diffusion Models. (arXiv:2301.12503v3 [cs.SD] UPDATED)\nAbstract: Text-to-audio (TTA) system has recently gained attention for its ability to synthesize general audio based on text descriptions. However, previous studies in TTA have limited generation quality with high computational costs. In this study, we propose AudioLDM, a TTA system that is built on a latent space to learn the continuous audio representations from contrastive language-audio pretraining (CLAP) latents. The pretrained CLAP models enable us to train LDMs with audio embedding while providing text embedding as a condition during sampling. By learning the latent representations of audio signals and their compositions without modeling the cross-modal relationship, AudioLDM is advantageous in both generation quality and computational efficiency. Trained on AudioCaps with a single GPU, AudioLDM achieves state-of-the-art TTA performance measured by both objective and subjective metrics (e.g., frechet distance). Moreover, AudioLDM is the first TTA system that enables various text-guided au",
    "path": "papers/23/01/2301.12503.json",
    "total_tokens": 965,
    "translated_title": "AudioLDM: 基于潜在扩散模型的文本转音频生成",
    "translated_abstract": "最近，文本到音频（TTA）系统因其能够根据文本描述合成通用音频而引起了关注。然而，以往的TTA研究在生成质量上存在局限性，并且计算成本较高。本研究提出了基于潜在空间的TTA系统AudioLDM，该系统通过对比语言-音频预训练（CLAP）潜变量学习连续音频表示。预训练的CLAP模型使我们能够训练具有音频嵌入的LDM，并在采样过程中提供文本嵌入作为条件。通过学习音频信号及其组合的潜变量表示，而不是建模跨模态关系，AudioLDM在生成质量和计算效率上具有优势。在单个GPU上使用AudioCaps进行训练的结果显示，AudioLDM在客观和主观指标（如Frechet距离）上实现了最先进的TTA性能。此外，AudioLDM是第一个能够实现各种文本引导的音频生成的TTA系统。",
    "tldr": "AudioLDM是一种基于潜在扩散模型的文本到音频生成系统，通过对比语言-音频预训练学习音频的连续表示，从而在生成质量和计算效率上具有优势。它在TTA性能上达到了最先进水平，并且能够实现各种文本引导的音频生成。"
}