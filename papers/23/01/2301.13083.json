{
    "title": "Communication Drives the Emergence of Language Universals in Neural Agents: Evidence from the Word-order/Case-marking Trade-off. (arXiv:2301.13083v2 [cs.CL] UPDATED)",
    "abstract": "Artificial learners often behave differently from human learners in the context of neural agent-based simulations of language emergence and change. A common explanation is the lack of appropriate cognitive biases in these learners. However, it has also been proposed that more naturalistic settings of language learning and use could lead to more human-like results. We investigate this latter account focusing on the word-order/case-marking trade-off, a widely attested language universal that has proven particularly hard to simulate. We propose a new Neural-agent Language Learning and Communication framework (NeLLCom) where pairs of speaking and listening agents first learn a miniature language via supervised learning, and then optimize it for communication via reinforcement learning. Following closely the setup of earlier human experiments, we succeed in replicating the trade-off with the new framework without hard-coding specific biases in the agents. We see this as an essential step to",
    "link": "http://arxiv.org/abs/2301.13083",
    "context": "Title: Communication Drives the Emergence of Language Universals in Neural Agents: Evidence from the Word-order/Case-marking Trade-off. (arXiv:2301.13083v2 [cs.CL] UPDATED)\nAbstract: Artificial learners often behave differently from human learners in the context of neural agent-based simulations of language emergence and change. A common explanation is the lack of appropriate cognitive biases in these learners. However, it has also been proposed that more naturalistic settings of language learning and use could lead to more human-like results. We investigate this latter account focusing on the word-order/case-marking trade-off, a widely attested language universal that has proven particularly hard to simulate. We propose a new Neural-agent Language Learning and Communication framework (NeLLCom) where pairs of speaking and listening agents first learn a miniature language via supervised learning, and then optimize it for communication via reinforcement learning. Following closely the setup of earlier human experiments, we succeed in replicating the trade-off with the new framework without hard-coding specific biases in the agents. We see this as an essential step to",
    "path": "papers/23/01/2301.13083.json",
    "total_tokens": 1043,
    "translated_title": "神经代理通信推动语言普遍规律的出现：以语序/格标交换为例证",
    "translated_abstract": "在基于神经代理的语言演变和变化的模拟中，人工学习者的行为通常与人类学习者不同，这常被归因于这些学习者缺乏适当的认知偏见。然而，也有人提出更自然的语言学习和使用环境可能导致更类似于人类的结果。本文研究了这种后一种说法，重点关注语序/格标交换，一种被广泛证明的语言普遍规律，这种规律在模拟中被证明尤其困难。我们提出了一个新的神经代理语言学习和通信框架（NeLLCom），其中说话和听取的代理首先通过监督学习学习一种小语言，然后通过强化学习对其进行优化以进行沟通。紧密遵循早期人类实验的设置，我们成功复制了这种新框架下的交换，而不是在代理中硬编码特定的偏见。我们认为，这是发展更真实的语言演变模拟和更好地理解影响语言普遍规律的认知和社会因素的重要一步。",
    "tldr": "本文研究了神经代理语言学习与通信框架，成功复制了语序/格标交换这一广泛存在的语言普遍规律，实现了更真实的语言演变模拟，并帮助我们更好地理解影响语言普遍规律的认知和社会因素。",
    "en_tdlr": "This paper investigates a Neural-agent Language Learning and Communication framework (NeLLCom) and successfully replicates the widely-attested language universal of word-order/case-marking trade-off, without hard-coding specific biases in the agents. The framework helps to develop more realistic simulations of language evolution and gain a better understanding of the cognitive and social factors shaping language universals."
}