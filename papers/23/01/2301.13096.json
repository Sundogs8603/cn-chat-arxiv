{
    "title": "Language-Driven Anchors for Zero-Shot Adversarial Robustness. (arXiv:2301.13096v2 [cs.CV] UPDATED)",
    "abstract": "Deep neural networks are known to be susceptible to adversarial attacks. In this work, we focus on improving adversarial robustness in the challenging zero-shot image classification setting. To address this issue, we propose LAAT, a novel Language-driven, Anchor-based Adversarial Training strategy. LAAT utilizes a text encoder to generate fixed anchors (normalized feature embeddings) for each category and then uses these anchors for adversarial training. By leveraging the semantic consistency of the text encoders, LAAT can enhance the adversarial robustness of the image model on novel categories without additional examples. We identify the large cosine similarity problem of recent text encoders and design several effective techniques to address it. The experimental results demonstrate that LAAT significantly improves zero-shot adversarial performance, outperforming previous state-of-the-art adversarially robust one-shot methods. Moreover, our method produces substantial zero-shot adver",
    "link": "http://arxiv.org/abs/2301.13096",
    "context": "Title: Language-Driven Anchors for Zero-Shot Adversarial Robustness. (arXiv:2301.13096v2 [cs.CV] UPDATED)\nAbstract: Deep neural networks are known to be susceptible to adversarial attacks. In this work, we focus on improving adversarial robustness in the challenging zero-shot image classification setting. To address this issue, we propose LAAT, a novel Language-driven, Anchor-based Adversarial Training strategy. LAAT utilizes a text encoder to generate fixed anchors (normalized feature embeddings) for each category and then uses these anchors for adversarial training. By leveraging the semantic consistency of the text encoders, LAAT can enhance the adversarial robustness of the image model on novel categories without additional examples. We identify the large cosine similarity problem of recent text encoders and design several effective techniques to address it. The experimental results demonstrate that LAAT significantly improves zero-shot adversarial performance, outperforming previous state-of-the-art adversarially robust one-shot methods. Moreover, our method produces substantial zero-shot adver",
    "path": "papers/23/01/2301.13096.json",
    "total_tokens": 1060,
    "translated_title": "基于语言驱动的锚点的零样本对抗鲁棒性",
    "translated_abstract": "深度神经网络容易受到对抗性攻击。本文旨在改善具有挑战性的零样本图像分类场景下的对抗鲁棒性。为解决这一问题，我们提出了一种新的基于语言驱动、基于锚点的对抗训练策略LAAT。LAAT利用文本编码器为每个类别生成固定的锚点（归一化特征嵌入），并在对抗训练中使用这些锚点。通过利用文本编码器的语义一致性，LAAT可以增强图像模型在新类别上的对抗鲁棒性，而无需额外的样例。我们发现了最近文本编码器的余弦相似度问题，并设计了几种有效的技术来解决它。实验结果表明，LAAT显著提高了零样本对抗性能，优于先前的最佳状态对抗性一次性方法。此外，我们的方法在几个基准数据集上为流行的图像分类模型（如ResNet-50和DenseNet-121）产生了实质性的零样本对抗性能提升。",
    "tldr": "本文提出了一种基于语言驱动、基于锚点的对抗训练策略LAAT，通过利用文本编码器的语义一致性，在零样本图像分类场景下增强图像模型的对抗鲁棒性。实验结果表明，该方法在零样本对抗性能上优于先前的最佳状态对抗性一次性方法，同时能为流行的图像分类模型带来实质性的零样本对抗性能提升。",
    "en_tdlr": "This paper proposes a novel Language-driven, Anchor-based Adversarial Training (LAAT) strategy to enhance adversarial robustness in zero-shot image classification. By utilizing the semantic consistency of text encoders, LAAT generates fixed anchors for each category and produces substantial zero-shot adversarial performance gains for popular image classification models."
}