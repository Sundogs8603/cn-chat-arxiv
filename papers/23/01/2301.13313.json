{
    "title": "Incorporating Recurrent Reinforcement Learning into Model Predictive Control for Adaptive Control in Autonomous Driving. (arXiv:2301.13313v2 [cs.LG] UPDATED)",
    "abstract": "Model Predictive Control (MPC) is attracting tremendous attention in the autonomous driving task as a powerful control technique. The success of an MPC controller strongly depends on an accurate internal dynamics model. However, the static parameters, usually learned by system identification, often fail to adapt to both internal and external perturbations in real-world scenarios. In this paper, we firstly (1) reformulate the problem as a Partially Observed Markov Decision Process (POMDP) that absorbs the uncertainties into observations and maintains Markov property into hidden states; and (2) learn a recurrent policy continually adapting the parameters of the dynamics model via Recurrent Reinforcement Learning (RRL) for optimal and adaptive control; and (3) finally evaluate the proposed algorithm (referred as $\\textit{MPC-RRL}$) in CARLA simulator and leading to robust behaviours under a wide range of perturbations.",
    "link": "http://arxiv.org/abs/2301.13313",
    "context": "Title: Incorporating Recurrent Reinforcement Learning into Model Predictive Control for Adaptive Control in Autonomous Driving. (arXiv:2301.13313v2 [cs.LG] UPDATED)\nAbstract: Model Predictive Control (MPC) is attracting tremendous attention in the autonomous driving task as a powerful control technique. The success of an MPC controller strongly depends on an accurate internal dynamics model. However, the static parameters, usually learned by system identification, often fail to adapt to both internal and external perturbations in real-world scenarios. In this paper, we firstly (1) reformulate the problem as a Partially Observed Markov Decision Process (POMDP) that absorbs the uncertainties into observations and maintains Markov property into hidden states; and (2) learn a recurrent policy continually adapting the parameters of the dynamics model via Recurrent Reinforcement Learning (RRL) for optimal and adaptive control; and (3) finally evaluate the proposed algorithm (referred as $\\textit{MPC-RRL}$) in CARLA simulator and leading to robust behaviours under a wide range of perturbations.",
    "path": "papers/23/01/2301.13313.json",
    "total_tokens": 916,
    "translated_title": "将循环强化学习纳入模型预测控制中，实现自主驾驶中的自适应控制",
    "translated_abstract": "模型预测控制（MPC）作为一种强大的控制技术，在自主驾驶任务中引起了极大的关注。 MPC控制器的成功强烈依赖于准确的内部动力学模型。 然而，通常通过系统识别学习的静态参数在真实场景中往往无法适应内部和外部干扰。 本文首先将问题重新表述为部分可观察的马尔可夫决策过程（POMDP），将不确定性吸收到观察中并将马尔可夫性质维护到隐藏状态中; 其次，通过循环强化学习（RRL）学习递归策略，持续适应动力学模型的参数以实现最优和自适应控制; 最后，在CARLA模拟器中对所提出的算法（称为 $\\textit{MPC-RRL}$）进行评估，并在广泛的扰动范围内实现鲁棒行为。",
    "tldr": "本文提出了一种基于循环强化学习和部分可观察的马尔可夫决策过程的自适应控制算法 $\\textit{MPC-RRL}$，在CARLA模拟器中得到有效验证。",
    "en_tdlr": "This paper proposes an adaptive control algorithm, MPC-RRL, based on recurrent reinforcement learning and partially observable Markov decision processes, which is evaluated and demonstrated to be robust in CARLA simulator under various perturbations."
}