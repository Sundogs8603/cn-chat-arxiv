{
    "title": "Two Stage Contextual Word Filtering for Context bias in Unified Streaming and Non-streaming Transducer. (arXiv:2301.06735v2 [cs.SD] UPDATED)",
    "abstract": "It is difficult for an E2E ASR system to recognize words such as entities appearing infrequently in the training data. A widely used method to mitigate this issue is feeding contextual information into the acoustic model. Previous works have proven that a compact and accurate contextual list can boost the performance significantly. In this paper, we propose an efficient approach to obtain a high quality contextual list for a unified streaming/non-streaming based E2E model. Specifically, we make use of the phone-level streaming output to first filter the predefined contextual word list then fuse it into non-casual encoder and decoder to generate the final recognition results. Our approach improve the accuracy of the contextual ASR system and speed up the inference process. Experiments on two datasets demonstrates over 20% CERR comparing to the baseline system. Meanwile, the RTF of our system can be stabilized within 0.15 when the size of the contextual word list grows over 6000.",
    "link": "http://arxiv.org/abs/2301.06735",
    "context": "Title: Two Stage Contextual Word Filtering for Context bias in Unified Streaming and Non-streaming Transducer. (arXiv:2301.06735v2 [cs.SD] UPDATED)\nAbstract: It is difficult for an E2E ASR system to recognize words such as entities appearing infrequently in the training data. A widely used method to mitigate this issue is feeding contextual information into the acoustic model. Previous works have proven that a compact and accurate contextual list can boost the performance significantly. In this paper, we propose an efficient approach to obtain a high quality contextual list for a unified streaming/non-streaming based E2E model. Specifically, we make use of the phone-level streaming output to first filter the predefined contextual word list then fuse it into non-casual encoder and decoder to generate the final recognition results. Our approach improve the accuracy of the contextual ASR system and speed up the inference process. Experiments on two datasets demonstrates over 20% CERR comparing to the baseline system. Meanwile, the RTF of our system can be stabilized within 0.15 when the size of the contextual word list grows over 6000.",
    "path": "papers/23/01/2301.06735.json",
    "total_tokens": 970,
    "translated_title": "统一流式和非流式变换器中的上下文偏差双阶段上下文过滤",
    "translated_abstract": "对于一个端对端的自动语音识别系统来说，很难识别像实体这样在训练数据中出现不频繁的单词。缓解这个问题的一种常用方法是将上下文信息输入到声学模型中。之前的研究已经证明了一个紧凑而准确的上下文列表可以显著提高性能。本文提出了一种高效的方法，为统一的流式/非流式的端对端模型得到一个高质量的上下文列表。具体来说，我们利用基于电话级别的流式输出来首先过滤预定义的上下文单词列表，然后将其融合到非因果编码器和解码器中生成最终的识别结果。我们的方法提高了上下文ASR系统的准确性并加快了推理过程。在两个数据集上的实验证明，相比基线系统，CERR提高了20%以上。同时，当上下文单词列表的大小超过6000时，我们的系统的RTF可以稳定在0.15左右。",
    "tldr": "本文提出一种针对上下文偏差的双阶段上下文过滤方法，将流式输出和预定义上下文单词列表相结合，提高了端对端模型的识别准确率，并加快了推理过程。",
    "en_tdlr": "This paper proposes a two-stage contextual word filtering approach to address context bias in E2E ASR systems. By combining phone-level streaming output and a predefined contextual word list, the approach improves the recognition accuracy of the E2E model and speeds up the inference process. Experiments demonstrate over 20% improvement in CERR compared to the baseline system, and a stable RTF within 0.15 when the contextual word list size exceeds 6000."
}