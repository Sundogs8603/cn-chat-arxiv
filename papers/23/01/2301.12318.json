{
    "title": "Gradient Shaping: Enhancing Backdoor Attack Against Reverse Engineering",
    "abstract": "arXiv:2301.12318v2 Announce Type: replace-cross  Abstract: Most existing methods to detect backdoored machine learning (ML) models take one of the two approaches: trigger inversion (aka. reverse engineer) and weight analysis (aka. model diagnosis). In particular, the gradient-based trigger inversion is considered to be among the most effective backdoor detection techniques, as evidenced by the TrojAI competition, Trojan Detection Challenge and backdoorBench. However, little has been done to understand why this technique works so well and, more importantly, whether it raises the bar to the backdoor attack. In this paper, we report the first attempt to answer this question by analyzing the change rate of the backdoored model around its trigger-carrying inputs. Our study shows that existing attacks tend to inject the backdoor characterized by a low change rate around trigger-carrying inputs, which are easy to capture by gradient-based trigger inversion. In the meantime, we found that the ",
    "link": "https://arxiv.org/abs/2301.12318",
    "context": "Title: Gradient Shaping: Enhancing Backdoor Attack Against Reverse Engineering\nAbstract: arXiv:2301.12318v2 Announce Type: replace-cross  Abstract: Most existing methods to detect backdoored machine learning (ML) models take one of the two approaches: trigger inversion (aka. reverse engineer) and weight analysis (aka. model diagnosis). In particular, the gradient-based trigger inversion is considered to be among the most effective backdoor detection techniques, as evidenced by the TrojAI competition, Trojan Detection Challenge and backdoorBench. However, little has been done to understand why this technique works so well and, more importantly, whether it raises the bar to the backdoor attack. In this paper, we report the first attempt to answer this question by analyzing the change rate of the backdoored model around its trigger-carrying inputs. Our study shows that existing attacks tend to inject the backdoor characterized by a low change rate around trigger-carrying inputs, which are easy to capture by gradient-based trigger inversion. In the meantime, we found that the ",
    "path": "papers/23/01/2301.12318.json",
    "total_tokens": 777,
    "translated_title": "梯度塑造：增强反向工程中的后门攻击",
    "translated_abstract": "大多数现有方法检测植入后门机器学习（ML）模型采用触发器反转（也称为反向工程）和权重分析（也称为模型诊断）两种方法之一。本文首次尝试通过分析植入后门模型在触发输入周围的变化率来回答这个问题。研究表明，现有攻击往往在触发输入周围注入具有较低变化率特征的后门，这些后门易于被基于梯度的触发器反转所捕获。",
    "tldr": "本文分析了植入后门模型在触发输入周围的变化率，揭示了现有攻击倾向于在触发输入周围注入具有低变化率特征的后门，易被梯度触发器反转捕获。",
    "en_tdlr": "This paper analyzes the change rate of the backdoored model around its trigger-carrying inputs, revealing that existing attacks tend to inject backdoors with low change rate characteristics around trigger-carrying inputs, which are easily captured by gradient-based trigger inversion."
}