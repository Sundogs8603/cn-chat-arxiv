{
    "title": "Matching Exemplar as Next Sentence Prediction (MeNSP): Zero-shot Prompt Learning for Automatic Scoring in Science Education. (arXiv:2301.08771v3 [cs.CL] UPDATED)",
    "abstract": "Developing models to automatically score students' written responses to science problems is critical for science education. However, collecting and labeling sufficient student responses for training models is time and cost-consuming. Recent studies suggest that pre-trained language models (PLMs) can be adapted to downstream tasks without fine-tuning with prompts. However, no research has employed such a prompt approach in science education. As student responses are presented with natural language, aligning the scoring procedure as the next sentence prediction task using prompts can skip the costly fine-tuning stage. In this study, we developed a zero-shot approach to automatically score student responses via Matching Exemplars as Next Sentence Prediction (MeNSP). This approach employs no training samples. We first apply MeNSP in scoring three assessment tasks of scientific argumentation and found machine-human scoring agreements, Cohen's Kappa ranges from 0.30 to 0.57, and F1 score ran",
    "link": "http://arxiv.org/abs/2301.08771",
    "context": "Title: Matching Exemplar as Next Sentence Prediction (MeNSP): Zero-shot Prompt Learning for Automatic Scoring in Science Education. (arXiv:2301.08771v3 [cs.CL] UPDATED)\nAbstract: Developing models to automatically score students' written responses to science problems is critical for science education. However, collecting and labeling sufficient student responses for training models is time and cost-consuming. Recent studies suggest that pre-trained language models (PLMs) can be adapted to downstream tasks without fine-tuning with prompts. However, no research has employed such a prompt approach in science education. As student responses are presented with natural language, aligning the scoring procedure as the next sentence prediction task using prompts can skip the costly fine-tuning stage. In this study, we developed a zero-shot approach to automatically score student responses via Matching Exemplars as Next Sentence Prediction (MeNSP). This approach employs no training samples. We first apply MeNSP in scoring three assessment tasks of scientific argumentation and found machine-human scoring agreements, Cohen's Kappa ranges from 0.30 to 0.57, and F1 score ran",
    "path": "papers/23/01/2301.08771.json",
    "total_tokens": 960,
    "translated_title": "匹配标本作为下一句预测：自然语言处理科学教育中的零样本学习自动评分",
    "translated_abstract": "开发能够自动评分科学问题的学生书面答案的模型对于科学教育至关重要。然而，收集和标记足够的学生答案以训练模型是耗时和费用高昂的。最近的研究表明，预训练的语言模型（PLMs）可以在不需要prompt调整的情况下适应下游任务。然而，在科学教育中还没有使用过这种提示方法的研究。由于学生的答案是用自然语言呈现的，因此使用提示将评分过程对齐为下一句预测任务可以跳过昂贵的调整阶段。在这项研究中，我们通过匹配标本作为下一句预测（MeNSP）开发了一种零样本自动评分方法。这种方法不需要训练样本。我们首先在评分三个科学论证任务中应用MeNSP，并发现机器-人评分的一致性，Cohen的Kappa系数在0.30到0.57之间，F1分数",
    "tldr": "本研究提出了一种零样本学习自动评分的方法，利用预训练的语言模型配合匹配标本作为下一句预测技术，成功应用于科学教育领域的论证任务，极大地减少了训练成本和时间。",
    "en_tdlr": "This study proposes a zero-shot approach to automatic scoring using pre-trained language models and Matching Exemplars as Next Sentence Prediction (MeNSP) technique, which has been successfully applied to scientific argumentation tasks in education. This greatly reduces the training cost and time."
}