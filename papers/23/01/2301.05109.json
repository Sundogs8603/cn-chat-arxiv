{
    "title": "Explaining $\\mathcal{ELH}$ Concept Descriptions through Counterfactual Reasoning. (arXiv:2301.05109v2 [cs.AI] UPDATED)",
    "abstract": "Knowledge bases are widely used for information management, enabling high-impact applications such as web search, question answering, and natural language processing. They also serve as the backbone for automatic decision systems, e.g., for medical diagnostics and credit scoring. As stakeholders affected by these decisions would like to understand their situation and verify how fair the decisions are, a number of explanation approaches have been proposed. An intrinsically transparent way to do classification is by using concepts in description logics. However, these concepts can become long and difficult to fathom for non-experts, even when verbalized. One solution is to employ counterfactuals to answer the question, ``How must feature values be changed to obtain a different classification?'' By focusing on the minimal feature changes, the explanations are short, human-friendly, and provide a clear path of action regarding the change in prediction. While previous work investigated coun",
    "link": "http://arxiv.org/abs/2301.05109",
    "context": "Title: Explaining $\\mathcal{ELH}$ Concept Descriptions through Counterfactual Reasoning. (arXiv:2301.05109v2 [cs.AI] UPDATED)\nAbstract: Knowledge bases are widely used for information management, enabling high-impact applications such as web search, question answering, and natural language processing. They also serve as the backbone for automatic decision systems, e.g., for medical diagnostics and credit scoring. As stakeholders affected by these decisions would like to understand their situation and verify how fair the decisions are, a number of explanation approaches have been proposed. An intrinsically transparent way to do classification is by using concepts in description logics. However, these concepts can become long and difficult to fathom for non-experts, even when verbalized. One solution is to employ counterfactuals to answer the question, ``How must feature values be changed to obtain a different classification?'' By focusing on the minimal feature changes, the explanations are short, human-friendly, and provide a clear path of action regarding the change in prediction. While previous work investigated coun",
    "path": "papers/23/01/2301.05109.json",
    "total_tokens": 847,
    "translated_title": "用反事实推理解释$\\mathcal{ELH}$概念描述",
    "translated_abstract": "知识库被广泛应用于信息管理，能够支持高影响力的应用程序如网络搜索、问答和自然语言处理。它们也作为自动决策系统的基础，例如医疗诊断和信用评分。由于受到这些决策影响的利益相关者希望了解他们的情况并验证决策的公平性，因此提出了许多解释方法。描述逻辑中使用概念来进行分类是一种固有透明的方式。然而，即使在口头化的情况下，这些概念也会变得冗长且难以理解，特别是对于非专家而言。一种解决方法是使用反事实来回答问题：“为了得到不同的分类，特征值应如何改变？”通过关注最小的特征变化，解释变得短小、易于理解，并提供了关于变化对预测的影响的明确行动路径。",
    "tldr": "本研究提出了一种通过反事实推理来解释概念描述的方法，以提供简洁且易于理解的解释，便于非专家理解和采取行动。",
    "en_tdlr": "This study proposes a method to explain concept descriptions through counterfactual reasoning, providing concise and understandable explanations for non-experts to understand and take actions."
}