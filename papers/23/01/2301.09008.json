{
    "title": "Poor Man's Quality Estimation: Predicting Reference-Based MT Metrics Without the Reference. (arXiv:2301.09008v3 [cs.CL] UPDATED)",
    "abstract": "Machine translation quality estimation (QE) predicts human judgements of a translation hypothesis without seeing the reference. State-of-the-art QE systems based on pretrained language models have been achieving remarkable correlations with human judgements yet they are computationally heavy and require human annotations, which are slow and expensive to create. To address these limitations, we define the problem of metric estimation (ME) where one predicts the automated metric scores also without the reference. We show that even without access to the reference, our model can estimate automated metrics ($\\rho$=60% for BLEU, $\\rho$=51% for other metrics) at the sentence-level. Because automated metrics correlate with human judgements, we can leverage the ME task for pre-training a QE model. For the QE task, we find that pre-training on TER is better ($\\rho$=23%) than training for scratch ($\\rho$=20%).",
    "link": "http://arxiv.org/abs/2301.09008",
    "context": "Title: Poor Man's Quality Estimation: Predicting Reference-Based MT Metrics Without the Reference. (arXiv:2301.09008v3 [cs.CL] UPDATED)\nAbstract: Machine translation quality estimation (QE) predicts human judgements of a translation hypothesis without seeing the reference. State-of-the-art QE systems based on pretrained language models have been achieving remarkable correlations with human judgements yet they are computationally heavy and require human annotations, which are slow and expensive to create. To address these limitations, we define the problem of metric estimation (ME) where one predicts the automated metric scores also without the reference. We show that even without access to the reference, our model can estimate automated metrics ($\\rho$=60% for BLEU, $\\rho$=51% for other metrics) at the sentence-level. Because automated metrics correlate with human judgements, we can leverage the ME task for pre-training a QE model. For the QE task, we find that pre-training on TER is better ($\\rho$=23%) than training for scratch ($\\rho$=20%).",
    "path": "papers/23/01/2301.09008.json",
    "total_tokens": 896,
    "translated_title": "穷人的质量评估：在没有参考的情况下预测基于参考的机器翻译度量",
    "translated_abstract": "机器翻译质量评估（QE）是在不查看参考文献的情况下预测翻译假设的人类判断的方法。基于预先训练的语言模型的最先进QE系统正在实现与人类判断的显着相关性，但它们的计算量大并且需要人类注释，这些注释需要耗费时间和资金。为了解决这些限制，我们定义了指标估计（ME）问题，其中预测自动化度量分数，同样也没有参考文献。我们展示了，即使没有参考文献，我们的模型也能在句子级别上估计自动化度量（$ \\rho = 60 \\% $对于BLEU，$ \\rho = 51 \\% $对于其他度量）。因为自动化度量与人类评估相关，我们可以利用ME任务为预训练QE模型服务。对于QE任务，我们发现在TER上进行预训练（$ \\rho = 23 \\% $）比从头开始训练（$ \\rho = 20 \\% $）更好。",
    "tldr": "该论文提出了一个质量评估的问题，叫做Metric Estimation，它能够在没有参考翻译的情况下，预测自动化评估度量，同时解决了人工注释费时费力的问题。",
    "en_tdlr": "This paper proposes a metric estimation problem, which predicts automated metric scores without the reference, solving the problem of time-consuming human annotations."
}