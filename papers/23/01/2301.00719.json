{
    "title": "Detection of Groups with Biased Representation in Ranking. (arXiv:2301.00719v2 [cs.LG] UPDATED)",
    "abstract": "Real-life tools for decision-making in many critical domains are based on ranking results. With the increasing awareness of algorithmic fairness, recent works have presented measures for fairness in ranking. Many of those definitions consider the representation of different ``protected groups'', in the top-$k$ ranked items, for any reasonable $k$. Given the protected groups, confirming algorithmic fairness is a simple task. However, the groups' definitions may be unknown in advance. In this paper, we study the problem of detecting groups with biased representation in the top-$k$ ranked items, eliminating the need to pre-define protected groups. The number of such groups possible can be exponential, making the problem hard. We propose efficient search algorithms for two different fairness measures: global representation bounds, and proportional representation. Then we propose a method to explain the bias in the representations of groups utilizing the notion of Shapley values. We conclud",
    "link": "http://arxiv.org/abs/2301.00719",
    "context": "Title: Detection of Groups with Biased Representation in Ranking. (arXiv:2301.00719v2 [cs.LG] UPDATED)\nAbstract: Real-life tools for decision-making in many critical domains are based on ranking results. With the increasing awareness of algorithmic fairness, recent works have presented measures for fairness in ranking. Many of those definitions consider the representation of different ``protected groups'', in the top-$k$ ranked items, for any reasonable $k$. Given the protected groups, confirming algorithmic fairness is a simple task. However, the groups' definitions may be unknown in advance. In this paper, we study the problem of detecting groups with biased representation in the top-$k$ ranked items, eliminating the need to pre-define protected groups. The number of such groups possible can be exponential, making the problem hard. We propose efficient search algorithms for two different fairness measures: global representation bounds, and proportional representation. Then we propose a method to explain the bias in the representations of groups utilizing the notion of Shapley values. We conclud",
    "path": "papers/23/01/2301.00719.json",
    "total_tokens": 867,
    "translated_title": "在排名中检测具有偏倚表示的群组",
    "translated_abstract": "许多关键领域的实际决策工具都基于排名结果。随着对算法公平性的日益关注，最近的研究提出了用于排名公平性的度量方法。其中许多定义考虑在任何合理的k值中，不同的“受保护群体”在前k个排名项中的表示。如果已知保护的群体，确认算法的公平性是一个简单的任务。然而，群体的定义可能事先不知道。在本文中，我们研究了在前k个排名项目中检测具有偏倚表示的群体的问题，消除了预定义保护群体的需要。这样的群体数量可能是指数级的，使得问题变得困难。我们提出了高效的搜索算法来解决两种不同的公平度量方法：全局表示边界和比例表示。然后，我们提出了一种利用Shapley值概念解释群体表示偏差的方法。",
    "tldr": "本文研究了在排名中检测具有偏倚表示的群体的问题，并提出了两种公平度量方法的高效搜索算法。同时，提出了一种利用Shapley值解释群体表示偏差的方法。",
    "en_tdlr": "This paper addresses the problem of detecting groups with biased representation in ranking and proposes efficient search algorithms for two fairness measures. Additionally, a method utilizing Shapley values is proposed to explain the bias in group representations."
}