{
    "title": "A Distance-Geometric Method for Recovering Robot Joint Angles From an RGB Image. (arXiv:2301.02051v2 [cs.RO] UPDATED)",
    "abstract": "Autonomous manipulation systems operating in domains where human intervention is difficult or impossible (e.g., underwater, extraterrestrial or hazardous environments) require a high degree of robustness to sensing and communication failures. Crucially, motion planning and control algorithms require a stream of accurate joint angle data provided by joint encoders, the failure of which may result in an unrecoverable loss of functionality. In this paper, we present a novel method for retrieving the joint angles of a robot manipulator using only a single RGB image of its current configuration, opening up an avenue for recovering system functionality when conventional proprioceptive sensing is unavailable. Our approach, based on a distance-geometric representation of the configuration space, exploits the knowledge of a robot's kinematic model with the goal of training a shallow neural network that performs a 2D-to-3D regression of distances associated with detected structural keypoints. It",
    "link": "http://arxiv.org/abs/2301.02051",
    "context": "Title: A Distance-Geometric Method for Recovering Robot Joint Angles From an RGB Image. (arXiv:2301.02051v2 [cs.RO] UPDATED)\nAbstract: Autonomous manipulation systems operating in domains where human intervention is difficult or impossible (e.g., underwater, extraterrestrial or hazardous environments) require a high degree of robustness to sensing and communication failures. Crucially, motion planning and control algorithms require a stream of accurate joint angle data provided by joint encoders, the failure of which may result in an unrecoverable loss of functionality. In this paper, we present a novel method for retrieving the joint angles of a robot manipulator using only a single RGB image of its current configuration, opening up an avenue for recovering system functionality when conventional proprioceptive sensing is unavailable. Our approach, based on a distance-geometric representation of the configuration space, exploits the knowledge of a robot's kinematic model with the goal of training a shallow neural network that performs a 2D-to-3D regression of distances associated with detected structural keypoints. It",
    "path": "papers/23/01/2301.02051.json",
    "total_tokens": 898,
    "translated_title": "从RGB图像中恢复机器人关节角度的距离几何方法",
    "translated_abstract": "在人类干预很难或不可能的领域（例如水下，太空或危险环境）操作的自主操纵系统需要高度强健的感知和通信故障。关键是，运动规划和控制算法需要提供关节编码器提供的准确关节角度数据流，否则可能会导致功能丧失。本文介绍了一种新方法，仅使用机器人当前配置的单个RGB图像就可以检索机器人操纵器的关节角度，为恢复系统功能开辟了一条途径，这时常用的本体感知无法使用。我们的方法基于配置空间的距离几何表示，利用机器人的运动学模型，旨在训练一个浅层神经网络，用于执行与检测到的结构关键点相关的距离的2D到3D回归。",
    "tldr": "本文提出了一种仅使用机器人当前配置的单个RGB图像就可以恢复机器人操纵器关节角度的方法，该方法利用机器人的运动学模型并训练浅层神经网络，可在缺少本体感知时恢复系统功能。",
    "en_tdlr": "This paper proposes a novel method to recover the joint angles of a robot manipulator using only a single RGB image of its current configuration, which is based on a distance-geometric representation of the configuration space, and exploits the knowledge of a robot's kinematic model with the goal of training a shallow neural network that performs a 2D-to-3D regression of distances associated with detected structural keypoints."
}