{
    "title": "TriNet: stabilizing self-supervised learning from complete or slow collapse on ASR. (arXiv:2301.00656v2 [eess.AS] UPDATED)",
    "abstract": "Self-supervised learning (SSL) models confront challenges of abrupt informational collapse or slow dimensional collapse. We propose TriNet, which introduces a novel triple-branch architecture for preventing collapse and stabilizing the pre-training. TriNet learns the SSL latent embedding space and incorporates it to a higher level space for predicting pseudo target vectors generated by a frozen teacher. Our experimental results show that the proposed method notably stabilizes and accelerates pre-training and achieves a relative word error rate reduction (WERR) of 6.06% compared to the state-of-the-art (SOTA) Data2vec for a downstream benchmark ASR task. We will release our code at https://github.com/tencent-ailab/.",
    "link": "http://arxiv.org/abs/2301.00656",
    "context": "Title: TriNet: stabilizing self-supervised learning from complete or slow collapse on ASR. (arXiv:2301.00656v2 [eess.AS] UPDATED)\nAbstract: Self-supervised learning (SSL) models confront challenges of abrupt informational collapse or slow dimensional collapse. We propose TriNet, which introduces a novel triple-branch architecture for preventing collapse and stabilizing the pre-training. TriNet learns the SSL latent embedding space and incorporates it to a higher level space for predicting pseudo target vectors generated by a frozen teacher. Our experimental results show that the proposed method notably stabilizes and accelerates pre-training and achieves a relative word error rate reduction (WERR) of 6.06% compared to the state-of-the-art (SOTA) Data2vec for a downstream benchmark ASR task. We will release our code at https://github.com/tencent-ailab/.",
    "path": "papers/23/01/2301.00656.json",
    "total_tokens": 835,
    "translated_title": "TriNet：防止自监督学习在ASR中完全或缓慢崩溃的稳定方法",
    "translated_abstract": "自监督学习模型面临着突然的信息崩溃或缓慢的维度崩溃的挑战。本文提出了TriNet，通过引入一种新颖的三分支结构来防止崩溃和稳定预训练。TriNet学习自监督学习的潜在嵌入空间，并将其并入到一个更高级别的空间中以预测由冻结的教师生成的虚假目标向量。实验结果显示，所提出的方法显著稳定和加速了预训练，并在下游基准ASR任务中相对于最先进的Data2vec实现了6.06％的相对单词错误率降低（WERR）。我们会在https://github.com/tencent-ailab/ 上发布我们的代码。",
    "tldr": "本文提出的TriNet采用三分支结构，可防止自监督学习在ASR中的崩溃，并在下游ASR任务中比SOTA方法Data2vec实现了6.06%的相对单词错误率降低（WERR）。",
    "en_tdlr": "TriNet, a novel triple-branch architecture, is proposed to prevent the collapse of self-supervised learning (SSL) in automatic speech recognition (ASR). TriNet achieves a 6.06% reduction in relative word error rate compared to Data2vec, the state-of-the-art (SOTA) method, on a downstream ASR task."
}