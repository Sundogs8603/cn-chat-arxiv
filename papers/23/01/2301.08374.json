{
    "title": "Projective Integral Updates for High-Dimensional Variational Inference. (arXiv:2301.08374v2 [cs.LG] UPDATED)",
    "abstract": "Variational inference is an approximation framework for Bayesian inference that seeks to improve quantified uncertainty in predictions by optimizing a simplified distribution over parameters to stand in for the full posterior. Capturing model variations that remain consistent with training data enables more robust predictions by reducing parameter sensitivity. This work introduces a fixed-point optimization for variational inference that is applicable when every feasible log density can be expressed as a linear combination of functions from a given basis. In such cases, the optimizer becomes a fixed-point of projective integral updates. When the basis spans univariate quadratics in each parameter, feasible densities are Gaussian and the projective integral updates yield quasi-Newton variational Bayes (QNVB). Other bases and updates are also possible. As these updates require high-dimensional integration, this work first proposes an efficient quasirandom quadrature sequence for mean-fie",
    "link": "http://arxiv.org/abs/2301.08374",
    "context": "Title: Projective Integral Updates for High-Dimensional Variational Inference. (arXiv:2301.08374v2 [cs.LG] UPDATED)\nAbstract: Variational inference is an approximation framework for Bayesian inference that seeks to improve quantified uncertainty in predictions by optimizing a simplified distribution over parameters to stand in for the full posterior. Capturing model variations that remain consistent with training data enables more robust predictions by reducing parameter sensitivity. This work introduces a fixed-point optimization for variational inference that is applicable when every feasible log density can be expressed as a linear combination of functions from a given basis. In such cases, the optimizer becomes a fixed-point of projective integral updates. When the basis spans univariate quadratics in each parameter, feasible densities are Gaussian and the projective integral updates yield quasi-Newton variational Bayes (QNVB). Other bases and updates are also possible. As these updates require high-dimensional integration, this work first proposes an efficient quasirandom quadrature sequence for mean-fie",
    "path": "papers/23/01/2301.08374.json",
    "total_tokens": 820,
    "translated_title": "高维变分推理的投影积分更新",
    "translated_abstract": "变分推理是一种贝叶斯推理的近似框架，通过优化简化的参数分布来代替完整的后验分布，从而改善预测中的量化不确定性。捕捉与训练数据一致的模型变化可以通过降低参数敏感性来实现更强健的预测。本研究引入了一种适用于变分推理的固定点最优化方法，当每个可行的对数密度可以表示为给定基函数的线性组合时，该方法生效。在这种情况下，优化器成为投影积分更新的一个不动点。当基函数跨越每个参数的二次函数时，可行密度为高斯分布，投影积分更新产生了准牛顿变分贝叶斯 (QNVB)。其他基函数和更新方法也是可能的。由于这些更新需要高维积分，本研究首先提出了一种高效的准随机积分序列用于均匀均匀均匀均匀均匀均匀积分。",
    "tldr": "该论文介绍了一种适用于高维变分推理的投影积分更新方法，并通过降低参数敏感性来实现更强健的预测。"
}