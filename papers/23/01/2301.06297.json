{
    "title": "Inference via robust optimal transportation: theory and methods",
    "abstract": "arXiv:2301.06297v4 Announce Type: replace-cross  Abstract: Optimal transportation theory and the related $p$-Wasserstein distance ($W_p$, $p\\geq 1$) are widely-applied in statistics and machine learning. In spite of their popularity, inference based on these tools has some issues. For instance, it is sensitive to outliers and it may not be even defined when the underlying model has infinite moments. To cope with these problems, first we consider a robust version of the primal transportation problem and show that it defines the {robust Wasserstein distance}, $W^{(\\lambda)}$, depending on a tuning parameter $\\lambda > 0$. Second, we illustrate the link between $W_1$ and $W^{(\\lambda)}$ and study its key measure theoretic aspects. Third, we derive some concentration inequalities for $W^{(\\lambda)}$. Fourth, we use $W^{(\\lambda)}$ to define minimum distance estimators, we provide their statistical guarantees and we illustrate how to apply the derived concentration inequalities for a data d",
    "link": "https://arxiv.org/abs/2301.06297",
    "context": "Title: Inference via robust optimal transportation: theory and methods\nAbstract: arXiv:2301.06297v4 Announce Type: replace-cross  Abstract: Optimal transportation theory and the related $p$-Wasserstein distance ($W_p$, $p\\geq 1$) are widely-applied in statistics and machine learning. In spite of their popularity, inference based on these tools has some issues. For instance, it is sensitive to outliers and it may not be even defined when the underlying model has infinite moments. To cope with these problems, first we consider a robust version of the primal transportation problem and show that it defines the {robust Wasserstein distance}, $W^{(\\lambda)}$, depending on a tuning parameter $\\lambda > 0$. Second, we illustrate the link between $W_1$ and $W^{(\\lambda)}$ and study its key measure theoretic aspects. Third, we derive some concentration inequalities for $W^{(\\lambda)}$. Fourth, we use $W^{(\\lambda)}$ to define minimum distance estimators, we provide their statistical guarantees and we illustrate how to apply the derived concentration inequalities for a data d",
    "path": "papers/23/01/2301.06297.json",
    "total_tokens": 860,
    "translated_title": "经过鲁棒优化输运的推断：理论与方法",
    "translated_abstract": "最优输运理论及相关的$p$-Wasserstein距离（$W_p$，$p\\geq 1$）在统计学和机器学习中被广泛应用。尽管它们很受欢迎，但基于这些工具的推断存在一些问题。 为了应对这些问题，首先我们考虑了原始输运问题的鲁棒版本，并展示其定义了依赖于调节参数$\\lambda > 0$的{鲁棒Wasserstein距离}，$W^{(\\lambda)}$。其次，我们讨论了$W_1$和$W^{(\\lambda)}$之间的联系，并研究了其关键的测度论方面。第三，我们推导了$W^{(\\lambda)}$的一些集中不等式。第四，我们利用$W^{(\\lambda)}$定义了最小距离估计器，提供了它们的统计保证，并说明了如何应用所推导的集中不等式到数据中。",
    "tldr": "通过鲁棒Wasserstein距离处理输运问题，探讨了与$W_1$的关联，推导了集中不等式，并提出最小距离估计器以及其统计保证。"
}