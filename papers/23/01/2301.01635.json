{
    "title": "SPTS v2: Single-Point Scene Text Spotting. (arXiv:2301.01635v2 [cs.CV] UPDATED)",
    "abstract": "End-to-end scene text spotting has made significant progress due to its intrinsic synergy between text detection and recognition. Previous methods commonly regard manual annotations such as horizontal rectangles, rotated rectangles, quadrangles, and polygons as a prerequisite, which are much more expensive than using single-point. For the first time, we demonstrate that training scene text spotting models can be achieved with an extremely low-cost single-point annotation by the proposed framework, termed SPTS v2. SPTS v2 reserves the advantage of the auto-regressive Transformer with an Instance Assignment Decoder (IAD) through sequentially predicting the center points of all text instances inside the same predicting sequence, while with a Parallel Recognition Decoder (PRD) for text recognition in parallel. These two decoders share the same parameters and are interactively connected with a simple but effective information transmission process to pass the gradient and information. Compre",
    "link": "http://arxiv.org/abs/2301.01635",
    "context": "Title: SPTS v2: Single-Point Scene Text Spotting. (arXiv:2301.01635v2 [cs.CV] UPDATED)\nAbstract: End-to-end scene text spotting has made significant progress due to its intrinsic synergy between text detection and recognition. Previous methods commonly regard manual annotations such as horizontal rectangles, rotated rectangles, quadrangles, and polygons as a prerequisite, which are much more expensive than using single-point. For the first time, we demonstrate that training scene text spotting models can be achieved with an extremely low-cost single-point annotation by the proposed framework, termed SPTS v2. SPTS v2 reserves the advantage of the auto-regressive Transformer with an Instance Assignment Decoder (IAD) through sequentially predicting the center points of all text instances inside the same predicting sequence, while with a Parallel Recognition Decoder (PRD) for text recognition in parallel. These two decoders share the same parameters and are interactively connected with a simple but effective information transmission process to pass the gradient and information. Compre",
    "path": "papers/23/01/2301.01635.json",
    "total_tokens": 883,
    "translated_title": "SPTS v2: 单点场景文本定位",
    "translated_abstract": "由于文本检测和识别之间的内在协同作用，端到端的场景文本定位取得了显著的进展。先前的方法通常将手动标注（如水平矩形、旋转矩形、四边形和多边形）视为必要条件，而这比使用单点要昂贵得多。我们首次证明了通过提出的名为SPTS v2的框架，可以使用极低成本的单点注释来训练场景文本定位模型。SPTS v2通过以顺序预测同一预测序列中所有文本实例的中心点，保留了自回归Transformer与实例分配解码器（IAD）的优势，同时使用并行识别解码器（PRD）进行文本识别。这两个解码器共享相同的参数，并通过简单而有效的信息传输过程进行交互连接，以传递梯度和信息。",
    "tldr": "本研究提出的SPTS v2框架，首次证明了可以使用极低成本的单点注释来训练场景文本定位模型，同时保留了自回归Transformer与实例分配解码器（IAD）的优势，并使用并行识别解码器（PRD）进行文本识别。",
    "en_tdlr": "The proposed SPTS v2 framework demonstrates for the first time that training scene text spotting models can be achieved with an extremely low-cost single-point annotation, while preserving the advantages of the auto-regressive Transformer with an Instance Assignment Decoder (IAD) and utilizing a Parallel Recognition Decoder (PRD) for text recognition."
}