{
    "title": "On the Convergence of No-Regret Learning Dynamics in Time-Varying Games. (arXiv:2301.11241v2 [cs.LG] UPDATED)",
    "abstract": "Most of the literature on learning in games has focused on the restrictive setting where the underlying repeated game does not change over time. Much less is known about the convergence of no-regret learning algorithms in dynamic multiagent settings. In this paper, we characterize the convergence of optimistic gradient descent (OGD) in time-varying games. Our framework yields sharp convergence bounds for the equilibrium gap of OGD in zero-sum games parameterized on natural variation measures of the sequence of games, subsuming known results for static games. Furthermore, we establish improved second-order variation bounds under strong convexity-concavity, as long as each game is repeated multiple times. Our results also apply to time-varying general-sum multi-player games via a bilinear formulation of correlated equilibria, which has novel implications for meta-learning and for obtaining refined variation-dependent regret bounds, addressing questions left open in prior papers. Finally,",
    "link": "http://arxiv.org/abs/2301.11241",
    "context": "Title: On the Convergence of No-Regret Learning Dynamics in Time-Varying Games. (arXiv:2301.11241v2 [cs.LG] UPDATED)\nAbstract: Most of the literature on learning in games has focused on the restrictive setting where the underlying repeated game does not change over time. Much less is known about the convergence of no-regret learning algorithms in dynamic multiagent settings. In this paper, we characterize the convergence of optimistic gradient descent (OGD) in time-varying games. Our framework yields sharp convergence bounds for the equilibrium gap of OGD in zero-sum games parameterized on natural variation measures of the sequence of games, subsuming known results for static games. Furthermore, we establish improved second-order variation bounds under strong convexity-concavity, as long as each game is repeated multiple times. Our results also apply to time-varying general-sum multi-player games via a bilinear formulation of correlated equilibria, which has novel implications for meta-learning and for obtaining refined variation-dependent regret bounds, addressing questions left open in prior papers. Finally,",
    "path": "papers/23/01/2301.11241.json",
    "total_tokens": 910,
    "translated_title": "关于时变博弈中无悔学习动态的收敛性问题",
    "translated_abstract": "大多数关于博弈学习的文献都集中于底层重复博弈不发生变化的严格模式下。对于动态多智体游戏中无悔学习算法的收敛性问题，我们知之甚少。在本文中，我们研究了时变博弈中乐观梯度下降法（OGD）的收敛性。我们的框架针对自然变化度量的博弈序列的均衡间隙，为OGD提供了明确的收敛界限，从而涵盖了静态博弈的已知结果。此外，只要每场游戏都进行了多次，我们还通过强凸性-强凹性建立了改进的二阶变化界限。我们的结果还适用于时变的总和多人博弈，通过相关均衡的双线性公式，这对元学习以及获得针对变化依赖性后悔界限的精细需求具有新颖意义。",
    "tldr": "本文研究了时变博弈中乐观梯度下降法（OGD）的收敛性，提出了明确的收敛界限，并建立了适用于时变总和多人博弈和元学习的新型双线性公式。"
}