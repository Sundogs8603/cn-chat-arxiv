{
    "title": "Planning Multiple Epidemic Interventions with Reinforcement Learning. (arXiv:2301.12802v2 [cs.LG] UPDATED)",
    "abstract": "Combating an epidemic entails finding a plan that describes when and how to apply different interventions, such as mask-wearing mandates, vaccinations, school or workplace closures. An optimal plan will curb an epidemic with minimal loss of life, disease burden, and economic cost. Finding an optimal plan is an intractable computational problem in realistic settings. Policy-makers, however, would greatly benefit from tools that can efficiently search for plans that minimize disease and economic costs especially when considering multiple possible interventions over a continuous and complex action space given a continuous and equally complex state space. We formulate this problem as a Markov decision process. Our formulation is unique in its ability to represent multiple continuous interventions over any disease model defined by ordinary differential equations. We illustrate how to effectively apply state-of-the-art actor-critic reinforcement learning algorithms (PPO and SAC) to search fo",
    "link": "http://arxiv.org/abs/2301.12802",
    "context": "Title: Planning Multiple Epidemic Interventions with Reinforcement Learning. (arXiv:2301.12802v2 [cs.LG] UPDATED)\nAbstract: Combating an epidemic entails finding a plan that describes when and how to apply different interventions, such as mask-wearing mandates, vaccinations, school or workplace closures. An optimal plan will curb an epidemic with minimal loss of life, disease burden, and economic cost. Finding an optimal plan is an intractable computational problem in realistic settings. Policy-makers, however, would greatly benefit from tools that can efficiently search for plans that minimize disease and economic costs especially when considering multiple possible interventions over a continuous and complex action space given a continuous and equally complex state space. We formulate this problem as a Markov decision process. Our formulation is unique in its ability to represent multiple continuous interventions over any disease model defined by ordinary differential equations. We illustrate how to effectively apply state-of-the-art actor-critic reinforcement learning algorithms (PPO and SAC) to search fo",
    "path": "papers/23/01/2301.12802.json",
    "total_tokens": 831,
    "translated_title": "利用强化学习规划多种传染病干预方案",
    "translated_abstract": "应对流行病需要制定计划，描述何时以及如何应用不同的干预措施，比如要求佩戴口罩、接种疫苗、关闭学校或工作场所等。最优的计划将以最小的生命损失、疾病负担和经济成本遏制疫情。在现实情况下，寻找最优计划是一个难以解决的计算问题。我们将这个问题表述为马尔可夫决策过程，并提出一种独特的方法，能够表示对于任何由常微分方程定义的疾病模型上的多个连续干预措施。我们展示了如何有效地应用最先进的演员-评论家强化学习算法（PPO和SAC），以在连续和复杂的状态空间中搜索最小化疾病和经济成本的计划。",
    "tldr": "本文将找到最优化的疫情计划转化为马尔可夫决策过程，并利用强化学习算法来搜索最小化疾病和经济成本的计划。",
    "en_tdlr": "This paper formulates finding optimal epidemic plans as a Markov decision process and utilizes reinforcement learning algorithms to search for plans that minimize disease and economic costs."
}