{
    "title": "Faithful Chain-of-Thought Reasoning. (arXiv:2301.13379v3 [cs.CL] UPDATED)",
    "abstract": "While Chain-of-Thought (CoT) prompting boosts Language Models' (LM) performance on a gamut of complex reasoning tasks, the generated reasoning chain does not necessarily reflect how the model arrives at the answer (aka. faithfulness). We propose Faithful CoT, a reasoning framework involving two stages: Translation (Natural Language query $\\rightarrow$ symbolic reasoning chain) and Problem Solving (reasoning chain $\\rightarrow$ answer), using an LM and a deterministic solver respectively. This guarantees that the reasoning chain provides a faithful explanation of the final answer. Aside from interpretability, Faithful CoT also improves empirical performance: it outperforms standard CoT on 9 of 10 benchmarks from 4 diverse domains, with a relative accuracy gain of 6.3% on Math Word Problems (MWP), 3.4% on Planning, 5.5% on Multi-hop Question Answering (QA), and 21.4% on Relational Inference. Furthermore, with GPT-4 and Codex, it sets the new state-of-the-art few-shot performance on 7 dat",
    "link": "http://arxiv.org/abs/2301.13379",
    "context": "Title: Faithful Chain-of-Thought Reasoning. (arXiv:2301.13379v3 [cs.CL] UPDATED)\nAbstract: While Chain-of-Thought (CoT) prompting boosts Language Models' (LM) performance on a gamut of complex reasoning tasks, the generated reasoning chain does not necessarily reflect how the model arrives at the answer (aka. faithfulness). We propose Faithful CoT, a reasoning framework involving two stages: Translation (Natural Language query $\\rightarrow$ symbolic reasoning chain) and Problem Solving (reasoning chain $\\rightarrow$ answer), using an LM and a deterministic solver respectively. This guarantees that the reasoning chain provides a faithful explanation of the final answer. Aside from interpretability, Faithful CoT also improves empirical performance: it outperforms standard CoT on 9 of 10 benchmarks from 4 diverse domains, with a relative accuracy gain of 6.3% on Math Word Problems (MWP), 3.4% on Planning, 5.5% on Multi-hop Question Answering (QA), and 21.4% on Relational Inference. Furthermore, with GPT-4 and Codex, it sets the new state-of-the-art few-shot performance on 7 dat",
    "path": "papers/23/01/2301.13379.json",
    "total_tokens": 910,
    "translated_title": "忠实的推理链思考",
    "translated_abstract": "虽然思考链（CoT）提示可以增强语言模型（LM）在各种复杂推理任务上的性能，但生成的推理链不一定反映模型如何得出答案（即忠实性）。我们提出了忠实的CoT，这是一个涉及两个阶段的推理框架：翻译（自然语言查询$\\rightarrow$符号推理链）和问题求解（推理链$\\rightarrow$答案），分别使用一个语言模型和一个确定性求解器。这保证了推理链提供了对最终答案的忠实解释。除了可解释性外，忠实的CoT还提高了经验性能：它在来自4个不同领域的10个基准测试中，优于标准的CoT，数学问题（MWP）的相对准确性提高了6.3％，规划提高了3.4％，多跳问答（QA）提高了5.5％，关系推理提高了21.4％。此外，借助GPT-4和Codex，在7个数据集上获得了最新的少样本性能.",
    "tldr": "这篇论文提出了一种忠实的推理链思考框架，通过翻译和问题求解两个阶段，确保推理链能忠实解释最终答案。它在复杂推理任务上的性能得到了提升，并在多个基准测试上超过了标准的推理链方法。"
}