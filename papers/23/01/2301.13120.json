{
    "title": "Doubly Optimal No-Regret Learning in Monotone Games. (arXiv:2301.13120v2 [cs.LG] UPDATED)",
    "abstract": "We consider online learning in multi-player smooth monotone games. Existing algorithms have limitations such as (1) being only applicable to strongly monotone games; (2) lacking the no-regret guarantee; (3) having only asymptotic or slow $O(\\frac{1}{\\sqrt{T}})$ last-iterate convergence rate to a Nash equilibrium. While the $O(\\frac{1}{\\sqrt{T}})$ rate is tight for a large class of algorithms including the well-studied extragradient algorithm and optimistic gradient algorithm, it is not optimal for all gradient-based algorithms.  We propose the accelerated optimistic gradient (AOG) algorithm, the first doubly optimal no-regret learning algorithm for smooth monotone games. Namely, our algorithm achieves both (i) the optimal $O(\\sqrt{T})$ regret in the adversarial setting under smooth and convex loss functions and (ii) the optimal $O(\\frac{1}{T})$ last-iterate convergence rate to a Nash equilibrium in multi-player smooth monotone games. As a byproduct of the accelerated last-iterate conve",
    "link": "http://arxiv.org/abs/2301.13120",
    "context": "Title: Doubly Optimal No-Regret Learning in Monotone Games. (arXiv:2301.13120v2 [cs.LG] UPDATED)\nAbstract: We consider online learning in multi-player smooth monotone games. Existing algorithms have limitations such as (1) being only applicable to strongly monotone games; (2) lacking the no-regret guarantee; (3) having only asymptotic or slow $O(\\frac{1}{\\sqrt{T}})$ last-iterate convergence rate to a Nash equilibrium. While the $O(\\frac{1}{\\sqrt{T}})$ rate is tight for a large class of algorithms including the well-studied extragradient algorithm and optimistic gradient algorithm, it is not optimal for all gradient-based algorithms.  We propose the accelerated optimistic gradient (AOG) algorithm, the first doubly optimal no-regret learning algorithm for smooth monotone games. Namely, our algorithm achieves both (i) the optimal $O(\\sqrt{T})$ regret in the adversarial setting under smooth and convex loss functions and (ii) the optimal $O(\\frac{1}{T})$ last-iterate convergence rate to a Nash equilibrium in multi-player smooth monotone games. As a byproduct of the accelerated last-iterate conve",
    "path": "papers/23/01/2301.13120.json",
    "total_tokens": 1031,
    "translated_title": "具有双重最优无遗憾的单调博弈学习",
    "translated_abstract": "我们考虑多人平滑单调博弈中的在线学习。现有算法存在诸如（1）仅适用于强单调博弈；（2）缺乏无遗憾保证；（3）只有渐进或慢速的$O(\\frac{1}{\\sqrt{T}})$最终迭代收敛速率到纳什均衡。虽然对于包括广泛研究的外推梯度算法和乐观梯度算法在内的大类算法，$O(\\frac{1}{\\sqrt{T}})$速率是紧确的，但不是所有基于梯度的算法都是最优的。我们提出了加速乐观梯度（AOG）算法，这是首个在平滑单调博弈中实现双重最优无遗憾学习的算法。即我们的算法同时实现了（i）在对抗环境下，对于平滑凸损失函数具有最优的$O(\\sqrt{T})$遗憾和（ii）在多人平滑单调博弈中，具有最优的$O(\\frac{1}{T})$最终迭代到达纳什均衡的收敛速率。",
    "tldr": "这是首个在平滑单调博弈中实现双重最优无遗憾学习的算法，同时实现了在对抗环境下具有最优的遗憾和在多人平滑单调博弈中具有最优的最终迭代收敛速率到达纳什均衡。",
    "en_tdlr": "We propose the accelerated optimistic gradient (AOG) algorithm, the first doubly optimal no-regret learning algorithm for smooth monotone games, achieving the optimal regret in the adversarial setting under smooth and convex loss functions and the optimal last-iterate convergence rate to a Nash equilibrium in multi-player smooth monotone games."
}