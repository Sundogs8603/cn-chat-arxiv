{
    "title": "Reconstructing Individual Data Points in Federated Learning Hardened with Differential Privacy and Secure Aggregation. (arXiv:2301.04017v2 [cs.CR] UPDATED)",
    "abstract": "Federated learning (FL) is a framework for users to jointly train a machine learning model. FL is promoted as a privacy-enhancing technology (PET) that provides data minimization: data never \"leaves\" personal devices and users share only model updates with a server (e.g., a company) coordinating the distributed training. While prior work showed that in vanilla FL a malicious server can extract users' private data from the model updates, in this work we take it further and demonstrate that a malicious server can reconstruct user data even in hardened versions of the protocol. More precisely, we propose an attack against FL protected with distributed differential privacy (DDP) and secure aggregation (SA). Our attack method is based on the introduction of sybil devices that deviate from the protocol to expose individual users' data for reconstruction by the server. The underlying root cause for the vulnerability to our attack is a power imbalance: the server orchestrates the whole protoco",
    "link": "http://arxiv.org/abs/2301.04017",
    "context": "Title: Reconstructing Individual Data Points in Federated Learning Hardened with Differential Privacy and Secure Aggregation. (arXiv:2301.04017v2 [cs.CR] UPDATED)\nAbstract: Federated learning (FL) is a framework for users to jointly train a machine learning model. FL is promoted as a privacy-enhancing technology (PET) that provides data minimization: data never \"leaves\" personal devices and users share only model updates with a server (e.g., a company) coordinating the distributed training. While prior work showed that in vanilla FL a malicious server can extract users' private data from the model updates, in this work we take it further and demonstrate that a malicious server can reconstruct user data even in hardened versions of the protocol. More precisely, we propose an attack against FL protected with distributed differential privacy (DDP) and secure aggregation (SA). Our attack method is based on the introduction of sybil devices that deviate from the protocol to expose individual users' data for reconstruction by the server. The underlying root cause for the vulnerability to our attack is a power imbalance: the server orchestrates the whole protoco",
    "path": "papers/23/01/2301.04017.json",
    "total_tokens": 858,
    "translated_title": "使用差分隐私和安全聚合的联邦学习的个体数据点重构",
    "translated_abstract": "联邦学习是一种让用户联合训练机器学习模型的框架，并被宣传为一种提供数据最小化的隐私增强技术（PET）。 先前的工作表明，在普通的联邦学习中，恶意服务器可以从模型更新中提取用户的私有数据。 本文进一步证明，在有防护措施的协议中，恶意服务器甚至可以重构用户数据。作者们提出了一种针对使用分布式差分隐私（DDP）和安全聚合（SA）保护的联邦学习的攻击方法。攻击方法基于引入违反协议的Sybil设备，以揭示个人用户的数据，以供服务器重构。导致此漏洞的根本原因是权力不平衡：服务器协调整个协议。",
    "tldr": "本文研究了在联邦学习被差分隐私和安全聚合保护的情况下，恶意服务器可以通过引入 Sybil 设备来重构用户数据的问题，揭示了其中的权力不平衡。",
    "en_tdlr": "This paper investigates the problem that a malicious server can reconstruct user data even in hardened versions of federated learning protected with distributed differential privacy and secure aggregation, and reveals the power imbalance in the protocol by introducing Sybil devices."
}