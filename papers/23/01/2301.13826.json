{
    "title": "Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models. (arXiv:2301.13826v2 [cs.CV] UPDATED)",
    "abstract": "Recent text-to-image generative models have demonstrated an unparalleled ability to generate diverse and creative imagery guided by a target text prompt. While revolutionary, current state-of-the-art diffusion models may still fail in generating images that fully convey the semantics in the given text prompt. We analyze the publicly available Stable Diffusion model and assess the existence of catastrophic neglect, where the model fails to generate one or more of the subjects from the input prompt. Moreover, we find that in some cases the model also fails to correctly bind attributes (e.g., colors) to their corresponding subjects. To help mitigate these failure cases, we introduce the concept of Generative Semantic Nursing (GSN), where we seek to intervene in the generative process on the fly during inference time to improve the faithfulness of the generated images. Using an attention-based formulation of GSN, dubbed Attend-and-Excite, we guide the model to refine the cross-attention un",
    "link": "http://arxiv.org/abs/2301.13826",
    "context": "Title: Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models. (arXiv:2301.13826v2 [cs.CV] UPDATED)\nAbstract: Recent text-to-image generative models have demonstrated an unparalleled ability to generate diverse and creative imagery guided by a target text prompt. While revolutionary, current state-of-the-art diffusion models may still fail in generating images that fully convey the semantics in the given text prompt. We analyze the publicly available Stable Diffusion model and assess the existence of catastrophic neglect, where the model fails to generate one or more of the subjects from the input prompt. Moreover, we find that in some cases the model also fails to correctly bind attributes (e.g., colors) to their corresponding subjects. To help mitigate these failure cases, we introduce the concept of Generative Semantic Nursing (GSN), where we seek to intervene in the generative process on the fly during inference time to improve the faithfulness of the generated images. Using an attention-based formulation of GSN, dubbed Attend-and-Excite, we guide the model to refine the cross-attention un",
    "path": "papers/23/01/2301.13826.json",
    "total_tokens": 936,
    "translated_title": "参与兴奋：一种基于注意力的文本到图像扩散模型的语义引导方法",
    "translated_abstract": "最近的文本到图像生成模型展示了一种无与伦比的通过目标文本提示进行指导生成多种多样和富有创造性的形象的能力。虽然具有革命性，但目前最先进的扩散模型仍可能在生成完全传达给定文本提示中的语义的图像方面失败。我们分析了公开的稳定扩散模型，并评估了灾难性忽视的存在，即模型无法生成输入提示中的一个或多个主题。此外，我们发现在某些情况下，模型还未能将属性（例如颜色）正确绑定到其相应的主题上。为了帮助减轻这些失败情况，我们引入了产生式语义护理（GSN）的概念，在推理时间内寻求干预生成过程以改善所生成图像的信实性。使用基于注意力的 GSN 公式，被称为参与兴奋，我们引导模型改进跨注意力的不确定性。",
    "tldr": "该论文提出了一种基于注意力的文本到图像扩散模型的语义引导方法，名为参与兴奋，在推理时间内干预生成过程以改善生成图像的信实性和完整性，并解决了传统扩散模型在图像语义生成中可能存在的失灵现象。",
    "en_tdlr": "The paper proposes an attention-based semantic guidance method for text-to-image diffusion models, Attend-and-Excite, which intervenes in the generative process during inference time to improve the faithfulness and completeness of the generated images, and solves the potential failures in image semantic generation of traditional diffusion models."
}