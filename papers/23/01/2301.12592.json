{
    "title": "Ensemble Learning for Fusion of Multiview Vision with Occlusion and Missing Information: Framework and Evaluations with Real-World Data and Applications in Driver Hand Activity Recognition. (arXiv:2301.12592v2 [cs.LG] UPDATED)",
    "abstract": "Multi-sensor frameworks provide opportunities for ensemble learning and sensor fusion to make use of redundancy and supplemental information, helpful in real-world safety applications such as continuous driver state monitoring which necessitate predictions even in cases where information may be intermittently missing. We define this problem of intermittent instances of missing information (by occlusion, noise, or sensor failure) and design a learning framework around these data gaps, proposing and analyzing an imputation scheme to handle missing information. We apply these ideas to tasks in camera-based hand activity classification for robust safety during autonomous driving. We show that a late-fusion approach between parallel convolutional neural networks can outperform even the best-placed single camera model in estimating the hands' held objects and positions when validated on within-group subjects, and that our multi-camera framework performs best on average in cross-group validat",
    "link": "http://arxiv.org/abs/2301.12592",
    "context": "Title: Ensemble Learning for Fusion of Multiview Vision with Occlusion and Missing Information: Framework and Evaluations with Real-World Data and Applications in Driver Hand Activity Recognition. (arXiv:2301.12592v2 [cs.LG] UPDATED)\nAbstract: Multi-sensor frameworks provide opportunities for ensemble learning and sensor fusion to make use of redundancy and supplemental information, helpful in real-world safety applications such as continuous driver state monitoring which necessitate predictions even in cases where information may be intermittently missing. We define this problem of intermittent instances of missing information (by occlusion, noise, or sensor failure) and design a learning framework around these data gaps, proposing and analyzing an imputation scheme to handle missing information. We apply these ideas to tasks in camera-based hand activity classification for robust safety during autonomous driving. We show that a late-fusion approach between parallel convolutional neural networks can outperform even the best-placed single camera model in estimating the hands' held objects and positions when validated on within-group subjects, and that our multi-camera framework performs best on average in cross-group validat",
    "path": "papers/23/01/2301.12592.json",
    "total_tokens": 956,
    "translated_title": "多视角视觉融合的集成学习在遮挡和缺失信息情况下的应用：框架和基于真实世界数据的司机手势识别评估",
    "translated_abstract": "多传感器框架为集成学习和传感器融合提供了机会，以利用冗余和补充信息，有助于在真实世界安全应用中进行连续司机状态监测。我们定义了由遮挡、噪声或传感器故障引起的间歇性信息缺失问题，并设计了一个围绕这些数据缺口的学习框架，提出并分析了一种填补信息缺失的插补方案。我们将这些思想应用于基于摄像头的手势活动分类任务，以实现自动驾驶的安全性。我们表明，基于并行卷积神经网络的后期融合方法，在同组受试者验证时，甚至可以超过最佳单一摄像头模型在估计手中物体的位置时，我们的多摄像头框架表现最好，而且在跨组验证时也表现出色。",
    "tldr": "本研究提出了一种集成学习的多视角视觉融合方法，用于处理在真实世界应用中可能存在的间歇性信息缺失问题。通过设计学习框架和提出的插补方案，实现了对驾驶员手势活动的准确分类和位置估计，提高了自动驾驶的安全性能。"
}