{
    "title": "Finding Regions of Counterfactual Explanations via Robust Optimization. (arXiv:2301.11113v2 [cs.LG] UPDATED)",
    "abstract": "Counterfactual explanations play an important role in detecting bias and improving the explainability of data-driven classification models. A counterfactual explanation (CE) is a minimal perturbed data point for which the decision of the model changes. Most of the existing methods can only provide one CE, which may not be achievable for the user. In this work we derive an iterative method to calculate robust CEs, i.e. CEs that remain valid even after the features are slightly perturbed. To this end, our method provides a whole region of CEs allowing the user to choose a suitable recourse to obtain a desired outcome. We use algorithmic ideas from robust optimization and prove convergence results for the most common machine learning methods including logistic regression, decision trees, random forests, and neural networks. Our experiments show that our method can efficiently generate globally optimal robust CEs for a variety of common data sets and classification models.",
    "link": "http://arxiv.org/abs/2301.11113",
    "context": "Title: Finding Regions of Counterfactual Explanations via Robust Optimization. (arXiv:2301.11113v2 [cs.LG] UPDATED)\nAbstract: Counterfactual explanations play an important role in detecting bias and improving the explainability of data-driven classification models. A counterfactual explanation (CE) is a minimal perturbed data point for which the decision of the model changes. Most of the existing methods can only provide one CE, which may not be achievable for the user. In this work we derive an iterative method to calculate robust CEs, i.e. CEs that remain valid even after the features are slightly perturbed. To this end, our method provides a whole region of CEs allowing the user to choose a suitable recourse to obtain a desired outcome. We use algorithmic ideas from robust optimization and prove convergence results for the most common machine learning methods including logistic regression, decision trees, random forests, and neural networks. Our experiments show that our method can efficiently generate globally optimal robust CEs for a variety of common data sets and classification models.",
    "path": "papers/23/01/2301.11113.json",
    "total_tokens": 947,
    "translated_title": "通过稳健优化找出反事实解释的区域",
    "translated_abstract": "反事实解释在检测偏见和提高数据驱动分类模型的可解释性方面发挥着重要作用。一个反事实解释（CE）是一个最小的扰动数据点，使得模型的决策发生变化。现有大多数方法只能提供一个CE，可能对于用户来说是难以实现的。在这项工作中，我们推导出一种迭代方法来计算稳健CE，即在特征轻微扰动后仍然有效的CE。为此，我们的方法提供了整个CE区域，使用户能够选择适当的措施以获得所需的结果。我们使用了稳健优化的算法思想，并证明了最常见的机器学习方法（包括逻辑回归、决策树、随机森林和神经网络）的收敛结果。我们的实验结果表明，我们的方法可以有效地为各种常见数据集和分类模型生成全局最佳的稳健CE。",
    "tldr": "该论文提出了一种通过稳健优化计算反事实解释（CE）区域的方法，使用户能够选择适当的措施以获得所需的结果，此方法在逻辑回归、决策树、随机森林和神经网络等最常见的机器学习方法上证明了收敛结果。",
    "en_tdlr": "This paper proposes a method for calculating a region of counterfactual explanations (CEs) via robust optimization, which allows the user to choose a suitable recourse to obtain a desired outcome. The method's convergence results are proven for common machine learning methods, including logistic regression, decision trees, random forests, and neural networks. It is demonstrated that the method efficiently generates globally optimal robust CEs for various common datasets and classification models."
}