{
    "title": "Rethinking Explaining Graph Neural Networks via Non-parametric Subgraph Matching. (arXiv:2301.02780v2 [cs.LG] UPDATED)",
    "abstract": "The success of graph neural networks (GNNs) provokes the question about explainability: ``Which fraction of the input graph is the most determinant of the prediction?'' Particularly, parametric explainers prevail in existing approaches because of their more robust capability to decipher the black-box (i.e., target GNNs). In this paper, based on the observation that graphs typically share some common motif patterns, we propose a novel non-parametric subgraph matching framework, dubbed MatchExplainer, to explore explanatory subgraphs. It couples the target graph with other counterpart instances and identifies the most crucial joint substructure by minimizing the node corresponding-based distance. Moreover, we note that present graph sampling or node-dropping methods usually suffer from the false positive sampling problem. To alleviate this issue, we designed a new augmentation paradigm named MatchDrop. It takes advantage of MatchExplainer to fix the most informative portion of the graph ",
    "link": "http://arxiv.org/abs/2301.02780",
    "context": "Title: Rethinking Explaining Graph Neural Networks via Non-parametric Subgraph Matching. (arXiv:2301.02780v2 [cs.LG] UPDATED)\nAbstract: The success of graph neural networks (GNNs) provokes the question about explainability: ``Which fraction of the input graph is the most determinant of the prediction?'' Particularly, parametric explainers prevail in existing approaches because of their more robust capability to decipher the black-box (i.e., target GNNs). In this paper, based on the observation that graphs typically share some common motif patterns, we propose a novel non-parametric subgraph matching framework, dubbed MatchExplainer, to explore explanatory subgraphs. It couples the target graph with other counterpart instances and identifies the most crucial joint substructure by minimizing the node corresponding-based distance. Moreover, we note that present graph sampling or node-dropping methods usually suffer from the false positive sampling problem. To alleviate this issue, we designed a new augmentation paradigm named MatchDrop. It takes advantage of MatchExplainer to fix the most informative portion of the graph ",
    "path": "papers/23/01/2301.02780.json",
    "total_tokens": 912,
    "translated_title": "通过非参数子图匹配重新思考解释图神经网络",
    "translated_abstract": "图神经网络（GNNs）的成功引发了关于可解释性的问题：“输入图的哪一部分对预测最为决定性？”特别是，由于其更强大的解读黑箱（即目标GNNs）能力，参数化解释器在现有方法中占据主导地位。基于观察到图通常共享某些常见的模式，本文提出了一种新颖的非参数子图匹配框架MatchExplainer来探索解释性子图。它将目标图与其他相应实例结合起来，通过最小化基于节点对应的距离来识别最关键的联合子结构。此外，我们注意到现有的图采样或节点删除方法通常会遇到误报采样问题。为了缓解这个问题，我们设计了一种名为MatchDrop的新增方案，它利用了MatchExplainer来修复图的最信息丰富部分。",
    "tldr": "本文通过提出一种非参数子图匹配框架MatchExplainer，可以解决图神经网络的解释性问题。此框架将目标图与其他实例结合起来，通过最小化节点对应的距离来鉴别最关键的联合子结构，并提出了一种新的增强范式MatchDrop来解决误报采样问题。"
}