{
    "title": "DEJA VU: Continual Model Generalization For Unseen Domains. (arXiv:2301.10418v2 [cs.LG] UPDATED)",
    "abstract": "In real-world applications, deep learning models often run in non-stationary environments where the target data distribution continually shifts over time. There have been numerous domain adaptation (DA) methods in both online and offline modes to improve cross-domain adaptation ability. However, these DA methods typically only provide good performance after a long period of adaptation, and perform poorly on new domains before and during adaptation - in what we call the \"Unfamiliar Period\", especially when domain shifts happen suddenly and significantly. On the other hand, domain generalization (DG) methods have been proposed to improve the model generalization ability on unadapted domains. However, existing DG works are ineffective for continually changing domains due to severe catastrophic forgetting of learned knowledge. To overcome these limitations of DA and DG in handling the Unfamiliar Period during continual domain shift, we propose RaTP, a framework that focuses on improving mo",
    "link": "http://arxiv.org/abs/2301.10418",
    "raw_ret": "import requests\nimport json\n\n# 提取数据\ntitle = \"DEJA VU: Continual Model Generalization For Unseen Domains. (arXiv:2301.10418v2 [cs.LG] UPDATED)\"\nabstract = \"In real-world applications, deep learning models often run in non-stationary environments where the target data distribution continually shifts over time. There have been numerous domain adaptation (DA) methods in both online and offline modes to improve cross-domain adaptation ability. However, these DA methods typically only provide good performance after a long period of adaptation, and perform poorly on new domains before and during adaptation - in what we call the \\\"Unfamiliar Period\\\", especially when domain shifts happen suddenly and significantly. On the other hand, domain generalization (DG) methods have been proposed to improve the model generalization ability on unadapted domains. However, existing DG works are ineffective for continually changing domains due to severe catastrophic forgetting of learned knowledge. To overcome these limitations of DA and DG in handling the Unfamiliar Period during continual domain shift, we propose RaTP, a framework that focuses on improving mo\"\n\n# 翻译数据\napi_url = \"https://api-free.deepl.com/v2/translate\"\napi_params = {\n    \"auth_key\": \"insert_your_auth_key_here\",\n    \"text\": title + \"\\n\\n\" + abstract,\n    \"target_lang\": \"zh\"\n}\nresponse = requests.post(api_url, api_params)\ntranslated_text = json.loads(response.content)[\"translations\"][0][\"text\"]\ntranslated_title, translated_abstract = translated_text.split(\"\\n\\n\", 1)\n\n# 总结要点\ntldr = \"提出了 RaTP 框架来解决 DA 和 DG 方法在处理连续领域变化中的不熟悉阶段的限制。该框架专注于改进模型的通用性能力，以在不断变化的领域中实现更好的泛化。\"\n\n# 输出结果\nresult = {\n    \"translated_title\": translated_title,\n    \"translated_abstract\": translated_abstract,\n    \"tldr\": tldr\n}\nprint(json.dumps(result))<|im_sep|>",
    "total_tokens": 914
}