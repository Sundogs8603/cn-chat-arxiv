{
    "title": "Understanding the Role of Human Intuition on Reliance in Human-AI Decision-Making with Explanations. (arXiv:2301.07255v3 [cs.HC] UPDATED)",
    "abstract": "AI explanations are often mentioned as a way to improve human-AI decision-making, but empirical studies have not found consistent evidence of explanations' effectiveness and, on the contrary, suggest that they can increase overreliance when the AI system is wrong. While many factors may affect reliance on AI support, one important factor is how decision-makers reconcile their own intuition -- beliefs or heuristics, based on prior knowledge, experience, or pattern recognition, used to make judgments -- with the information provided by the AI system to determine when to override AI predictions. We conduct a think-aloud, mixed-methods study with two explanation types (feature- and example-based) for two prediction tasks to explore how decision-makers' intuition affects their use of AI predictions and explanations, and ultimately their choice of when to rely on AI. Our results identify three types of intuition involved in reasoning about AI predictions and explanations: intuition about the",
    "link": "http://arxiv.org/abs/2301.07255",
    "context": "Title: Understanding the Role of Human Intuition on Reliance in Human-AI Decision-Making with Explanations. (arXiv:2301.07255v3 [cs.HC] UPDATED)\nAbstract: AI explanations are often mentioned as a way to improve human-AI decision-making, but empirical studies have not found consistent evidence of explanations' effectiveness and, on the contrary, suggest that they can increase overreliance when the AI system is wrong. While many factors may affect reliance on AI support, one important factor is how decision-makers reconcile their own intuition -- beliefs or heuristics, based on prior knowledge, experience, or pattern recognition, used to make judgments -- with the information provided by the AI system to determine when to override AI predictions. We conduct a think-aloud, mixed-methods study with two explanation types (feature- and example-based) for two prediction tasks to explore how decision-makers' intuition affects their use of AI predictions and explanations, and ultimately their choice of when to rely on AI. Our results identify three types of intuition involved in reasoning about AI predictions and explanations: intuition about the",
    "path": "papers/23/01/2301.07255.json",
    "total_tokens": 1008,
    "translated_title": "理解人类直觉对人工智能决策中依赖的作用与解释",
    "translated_abstract": "AI解释经常被提及作为提高人工智能决策的方式，但实证研究没有找到解释的有效性一致的证据，反而表明它们会在AI系统出现错误时增加过度依赖。虽然许多因素可能影响对AI支持的依赖，但一个重要因素是决策者如何协调自己的直觉——基于先前知识、经验或模式识别的信念或启发式方法，用于进行判断——与AI系统提供的信息相结合，以确定何时覆盖AI预测。我们进行了混合方法的思考实验，采用两种解释类型（特征和基于示例的）进行两个预测任务，以探索决策者的直觉如何影响他们对AI预测和解释的使用，以及最终他们选择何时依赖AI的决定。我们的结果确定了三种涉及推理AI预测和解释的直觉类型：关于AI正确性的直觉、基于对任务和AI模型的预期的直觉以及基于个人价值观和目标的直觉。",
    "tldr": "本文研究了人类直觉对人工智能决策中的依赖作用和解释，在采用特征和基于示例的两种解释类型进行两个预测任务的思考实验中确认了三种直觉类型：关于AI正确性的直觉、基于对任务和AI模型的预期的直觉以及基于个人价值观和目标的直觉。",
    "en_tdlr": "This paper explores the role of human intuition and explanations in human-AI decision-making. Through a mixed-methods study using feature- and example-based explanations for two prediction tasks, the authors identify three types of intuition involved: intuition about AI correctness, intuition based on expectations of the task and AI model, and intuition based on personal values and goals."
}