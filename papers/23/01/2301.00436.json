{
    "title": "Hierarchical Explanations for Video Action Recognition. (arXiv:2301.00436v3 [cs.CV] UPDATED)",
    "abstract": "To interpret deep neural networks, one main approach is to dissect the visual input and find the prototypical parts responsible for the classification. However, existing methods often ignore the hierarchical relationship between these prototypes, and thus can not explain semantic concepts at both higher level (e.g., water sports) and lower level (e.g., swimming). In this paper inspired by human cognition system, we leverage hierarchal information to deal with uncertainty: When we observe water and human activity, but no definitive action it can be recognized as the water sports parent class. Only after observing a person swimming can we definitively refine it to the swimming action. To this end, we propose HIerarchical Prototype Explainer (HIPE) to build hierarchical relations between prototypes and classes. HIPE enables a reasoning process for video action classification by dissecting the input video frames on multiple levels of the class hierarchy, our method is also applicable to ot",
    "link": "http://arxiv.org/abs/2301.00436",
    "context": "Title: Hierarchical Explanations for Video Action Recognition. (arXiv:2301.00436v3 [cs.CV] UPDATED)\nAbstract: To interpret deep neural networks, one main approach is to dissect the visual input and find the prototypical parts responsible for the classification. However, existing methods often ignore the hierarchical relationship between these prototypes, and thus can not explain semantic concepts at both higher level (e.g., water sports) and lower level (e.g., swimming). In this paper inspired by human cognition system, we leverage hierarchal information to deal with uncertainty: When we observe water and human activity, but no definitive action it can be recognized as the water sports parent class. Only after observing a person swimming can we definitively refine it to the swimming action. To this end, we propose HIerarchical Prototype Explainer (HIPE) to build hierarchical relations between prototypes and classes. HIPE enables a reasoning process for video action classification by dissecting the input video frames on multiple levels of the class hierarchy, our method is also applicable to ot",
    "path": "papers/23/01/2301.00436.json",
    "total_tokens": 879,
    "translated_title": "视频动作识别的分层解释",
    "translated_abstract": "解释深度神经网络的主要方法之一是分解视觉输入并找到负责分类的典型部分。然而，现有方法通常忽略这些原型之间的分层关系，因此无法在更高层次（例如，水上运动）和更低层次（例如，游泳）上解释语义概念。在本文中，我们受到人类认知系统的启发，利用分层信息处理不确定性：当我们观察到水和人类活动，但没有明确的动作时，可以将其识别为水上运动的父类。只有观察到一个人在游泳后，我们才能明确将其细分为游泳动作。为此，我们提出了分层原型解释器（HIPE）来建立原型和类之间的分层关系。 HIPE通过在类层次结构的多个级别上分解输入视频帧，实现了视频动作分类的推理过程，我们的方法也适用于视频动作识别之外的其他识别任务。",
    "tldr": "本文提出了分层原型解释器，能够解释深度神经网络对视频动作的分类，同时能够将类和原型建立成更有层次的关系，可以处理不确定性。",
    "en_tdlr": "This paper proposes a hierarchical prototype explainer for video action recognition, which can establish a more hierarchical relationship between classes and prototypes to deal with uncertainty. The method dissects input video frames on multiple levels of the class hierarchy to enable a reasoning process for video action classification."
}