{
    "title": "Towards Flexibility and Interpretability of Gaussian Process State-Space Model. (arXiv:2301.08843v2 [cs.LG] UPDATED)",
    "abstract": "The Gaussian process state-space model (GPSSM) has attracted much attention over the past decade. However, the model representation power of the GPSSM is far from satisfactory. Most GPSSM studies rely on the standard Gaussian process (GP) with a preliminary kernel, such as the squared exponential (SE) kernel or Mat\\'{e}rn kernel, which limits the model representation power and its application in complex scenarios. To address this issue, this paper proposes a novel class of probabilistic state-space models, called TGPSSMs. By leveraging a parametric normalizing flow, the TGPSSMs enrich the GP priors in the standard GPSSM, rendering the state-space model more flexible and expressive. Additionally, we present a scalable variational inference algorithm for learning and inference in TGPSSMs, which provides a flexible and optimal structure for the variational distribution of latent states. The algorithm is interpretable and computationally efficient owing to the sparse representation of GP a",
    "link": "http://arxiv.org/abs/2301.08843",
    "context": "Title: Towards Flexibility and Interpretability of Gaussian Process State-Space Model. (arXiv:2301.08843v2 [cs.LG] UPDATED)\nAbstract: The Gaussian process state-space model (GPSSM) has attracted much attention over the past decade. However, the model representation power of the GPSSM is far from satisfactory. Most GPSSM studies rely on the standard Gaussian process (GP) with a preliminary kernel, such as the squared exponential (SE) kernel or Mat\\'{e}rn kernel, which limits the model representation power and its application in complex scenarios. To address this issue, this paper proposes a novel class of probabilistic state-space models, called TGPSSMs. By leveraging a parametric normalizing flow, the TGPSSMs enrich the GP priors in the standard GPSSM, rendering the state-space model more flexible and expressive. Additionally, we present a scalable variational inference algorithm for learning and inference in TGPSSMs, which provides a flexible and optimal structure for the variational distribution of latent states. The algorithm is interpretable and computationally efficient owing to the sparse representation of GP a",
    "path": "papers/23/01/2301.08843.json",
    "total_tokens": 970,
    "translated_title": "面向高斯过程状态空间模型的灵活性和可解释性的探索",
    "translated_abstract": "过去十年中，高斯过程状态空间模型（GPSSM）备受关注。然而，GPSSM的模型表达能力远非令人满意。大多数GPSSM研究依赖于标准高斯过程（GP）和预先设置的核心，例如平方指数（SE）核心或Matern核心，这限制了模型的表达能力和在复杂场景中的应用。针对这个问题，本文提出了一种新的概率状态空间模型类，称为TGPSSM。通过利用一个参数化的正规化流，TGPSSM增加了标准GPSSM中的GP先验概率，使状态空间模型更具灵活性和表现力。此外，我们提出了一种可扩展的变分推理算法，用于在TGPSSM中进行学习和推理，为潜在状态的变分分布提供灵活和最优的结构。由于GP的稀疏表示，该算法是可解释和计算高效的。",
    "tldr": "本文提出了一种新的状态空间模型类TGPSSM，利用正规化流增加了标准GPSSM中的GP先验概率，从而增强模型的灵活性和表现力。同时提出了可扩展的变分推理算法，为潜在状态的变分分布提供灵活和最优的结构。",
    "en_tdlr": "This paper proposes a new type of state-space model, TGPSSM, which enriches the GP priors in standard GPSSM using a parametric normalizing flow to enhance the flexibility and expressiveness of the model. The paper also presents a scalable variational inference algorithm for learning and inference in TGPSSMs, providing a flexible and optimal structure for the variational distribution of latent states."
}