{
    "title": "Exploring Image Augmentations for Siamese Representation Learning with Chest X-Rays. (arXiv:2301.12636v2 [eess.IV] UPDATED)",
    "abstract": "Image augmentations are quintessential for effective visual representation learning across self-supervised learning techniques. While augmentation strategies for natural imaging have been studied extensively, medical images are vastly different from their natural counterparts. Thus, it is unknown whether common augmentation strategies employed in Siamese representation learning generalize to medical images and to what extent. To address this challenge, in this study, we systematically assess the effect of various augmentations on the quality and robustness of the learned representations. We train and evaluate Siamese Networks for abnormality detection on chest X-Rays across three large datasets (MIMIC-CXR, CheXpert and VinDR-CXR). We investigate the efficacy of the learned representations through experiments involving linear probing, fine-tuning, zero-shot transfer, and data efficiency. Finally, we identify a set of augmentations that yield robust representations that generalize well t",
    "link": "http://arxiv.org/abs/2301.12636",
    "context": "Title: Exploring Image Augmentations for Siamese Representation Learning with Chest X-Rays. (arXiv:2301.12636v2 [eess.IV] UPDATED)\nAbstract: Image augmentations are quintessential for effective visual representation learning across self-supervised learning techniques. While augmentation strategies for natural imaging have been studied extensively, medical images are vastly different from their natural counterparts. Thus, it is unknown whether common augmentation strategies employed in Siamese representation learning generalize to medical images and to what extent. To address this challenge, in this study, we systematically assess the effect of various augmentations on the quality and robustness of the learned representations. We train and evaluate Siamese Networks for abnormality detection on chest X-Rays across three large datasets (MIMIC-CXR, CheXpert and VinDR-CXR). We investigate the efficacy of the learned representations through experiments involving linear probing, fine-tuning, zero-shot transfer, and data efficiency. Finally, we identify a set of augmentations that yield robust representations that generalize well t",
    "path": "papers/23/01/2301.12636.json",
    "total_tokens": 925,
    "translated_title": "探究用于胸部 X 光片的孪生表示学习的图像增强方法",
    "translated_abstract": "图像增强对于有效的自监督学习技术的视觉表示学习至关重要。虽然自然图像的增强策略已经得到了广泛研究，但医学图像与自然图像有很大的不同。因此，我们不清楚在孪生表示学习中常用的增强策略是否适用于医学图像，以及适用的程度。为了解决这个挑战，在本研究中，我们系统地评估了各种增强方法对学习到的表示的质量和鲁棒性的影响。我们在三个大型数据集（MIMIC-CXR、CheXpert 和 VinDR-CXR）上训练和评估了用于胸部 X 光片异常检测的孪生网络。我们通过线性探测、微调、零样本迁移和数据效率的实验来研究学习到的表示的有效性。最后，我们确定了一组增强方法，可以得到具有良好泛化能力的鲁棒表示。",
    "tldr": "本研究系统地评估了不同的增强方法对学习到的胸部 X 光片异常检测的孪生表示的质量和鲁棒性的影响。结果显示，我们找到了一组能够产生良好泛化效果的鲁棒表示的增强方法。"
}