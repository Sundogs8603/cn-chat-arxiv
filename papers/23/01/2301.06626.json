{
    "title": "Masked Vector Quantization",
    "abstract": "arXiv:2301.06626v2 Announce Type: replace  Abstract: Generative models with discrete latent representations have recently demonstrated an impressive ability to learn complex high-dimensional data distributions. However, their performance relies on a long sequence of tokens per instance and a large number of codebook entries, resulting in long sampling times and considerable computation to fit the categorical posterior. To address these issues, we propose the Masked Vector Quantization (MVQ) framework which increases the representational capacity of each code vector by learning mask configurations via a stochastic winner-takes-all training regime called Multiple Hypothese Dropout (MH-Dropout). On ImageNet 64$\\times$64, MVQ reduces FID in existing vector quantization architectures by up to $68\\%$ at 2 tokens per instance and $57\\%$ at 5 tokens. These improvements widen as codebook entries is reduced and allows for $7\\textit{--}45\\times$ speed-up in token sampling during inference. As an ",
    "link": "https://arxiv.org/abs/2301.06626",
    "context": "Title: Masked Vector Quantization\nAbstract: arXiv:2301.06626v2 Announce Type: replace  Abstract: Generative models with discrete latent representations have recently demonstrated an impressive ability to learn complex high-dimensional data distributions. However, their performance relies on a long sequence of tokens per instance and a large number of codebook entries, resulting in long sampling times and considerable computation to fit the categorical posterior. To address these issues, we propose the Masked Vector Quantization (MVQ) framework which increases the representational capacity of each code vector by learning mask configurations via a stochastic winner-takes-all training regime called Multiple Hypothese Dropout (MH-Dropout). On ImageNet 64$\\times$64, MVQ reduces FID in existing vector quantization architectures by up to $68\\%$ at 2 tokens per instance and $57\\%$ at 5 tokens. These improvements widen as codebook entries is reduced and allows for $7\\textit{--}45\\times$ speed-up in token sampling during inference. As an ",
    "path": "papers/23/01/2301.06626.json",
    "total_tokens": 876,
    "translated_title": "掩码向量量化",
    "translated_abstract": "具有离散潜在表示的生成模型最近展示了学习复杂高维数据分布的令人印象深刻的能力。然而，它们的性能依赖于每个实例的长序列标记和大量码书条目，导致长采样时间和相当大的计算来拟合分类后验。为了解决这些问题，我们提出了掩码向量量化（MVQ）框架，通过学习掩码配置，通过称为多假设丢失（MH-Dropout）的随机胜者通吃训练制度，增加每个代码向量的表示能力。在ImageNet 64×64上，MVQ将现有向量量化架构中的FID降低了高达68%（每实例2个标记）和57%（每实例5个标记）。这些改进随着减少码书条目的代码条目而扩大，并且在推断过程中可以实现7-45倍的标记采样加速。",
    "tldr": "提出了一种Masked Vector Quantization（MVQ）框架，通过学习掩码配置并使用Multiple Hypothese Dropout（MH-Dropout）训练制度，增加了每个代码向量的表示能力，在图像数据集上取得了显著的性能提升。"
}