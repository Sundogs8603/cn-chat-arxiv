{
    "title": "Knockoffs-SPR: Clean Sample Selection in Learning with Noisy Labels. (arXiv:2301.00545v3 [cs.LG] UPDATED)",
    "abstract": "A noisy training set usually leads to the degradation of the generalization and robustness of neural networks. In this paper, we propose a novel theoretically guaranteed clean sample selection framework for learning with noisy labels. Specifically, we first present a Scalable Penalized Regression (SPR) method, to model the linear relation between network features and one-hot labels. In SPR, the clean data are identified by the zero mean-shift parameters solved in the regression model. We theoretically show that SPR can recover clean data under some conditions. Under general scenarios, the conditions may be no longer satisfied; and some noisy data are falsely selected as clean data. To solve this problem, we propose a data-adaptive method for Scalable Penalized Regression with Knockoff filters (Knockoffs-SPR), which is provable to control the False-Selection-Rate (FSR) in the selected clean data. To improve the efficiency, we further present a split algorithm that divides the whole trai",
    "link": "http://arxiv.org/abs/2301.00545",
    "context": "Title: Knockoffs-SPR: Clean Sample Selection in Learning with Noisy Labels. (arXiv:2301.00545v3 [cs.LG] UPDATED)\nAbstract: A noisy training set usually leads to the degradation of the generalization and robustness of neural networks. In this paper, we propose a novel theoretically guaranteed clean sample selection framework for learning with noisy labels. Specifically, we first present a Scalable Penalized Regression (SPR) method, to model the linear relation between network features and one-hot labels. In SPR, the clean data are identified by the zero mean-shift parameters solved in the regression model. We theoretically show that SPR can recover clean data under some conditions. Under general scenarios, the conditions may be no longer satisfied; and some noisy data are falsely selected as clean data. To solve this problem, we propose a data-adaptive method for Scalable Penalized Regression with Knockoff filters (Knockoffs-SPR), which is provable to control the False-Selection-Rate (FSR) in the selected clean data. To improve the efficiency, we further present a split algorithm that divides the whole trai",
    "path": "papers/23/01/2301.00545.json",
    "total_tokens": 980,
    "translated_title": "Knockoffs-SPR: 无噪声标签学习中的干净样本选择",
    "translated_abstract": "噪声训练集通常会导致神经网络的泛化能力和鲁棒性的降低。本文提出了一种新颖的在带有噪声标签的学习中，理论上保证的干净样本选择框架。具体地，我们首先提出了一种可扩展的惩罚回归（SPR）方法，用于建模网络特征和独热标签之间的线性关系。在SPR中，通过在回归模型中求解的零均值漂移参数来确定干净数据。我们理论上证明了在一些条件下SPR能够恢复干净数据。在一般情况下，这些条件可能不再满足；并且一些噪声数据被错误地选择为干净数据。为了解决这个问题，我们提出了一种基于Knockoff过滤器的数据自适应方法来控制选取的干净数据的误选择率（FSR）的Knockoffs-SPR。为了提高效率，我们进一步提出了一种分割算法，将整个训练集分割为多个子集。",
    "tldr": "本文提出了一种理论上保证的在学习中选择干净样本的框架Knockoffs-SPR，通过Scalable Penalized Regression（SPR）方法模型化网络特征和标签之间的线性关系，并且通过Knockoff过滤器控制了干净数据的误选择率。",
    "en_tdlr": "This paper presents a theoretically guaranteed framework, Knockoffs-SPR, for selecting clean samples in learning, which models the linear relation between network features and labels using the Scalable Penalized Regression (SPR) method and controls the False-Selection-Rate (FSR) of clean data through Knockoff filters."
}