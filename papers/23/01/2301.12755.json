{
    "title": "Efficient Node Selection in Private Personalized Decentralized Learning. (arXiv:2301.12755v2 [cs.LG] UPDATED)",
    "abstract": "Personalized decentralized learning is a promising paradigm for distributed learning, enabling each node to train a local model on its own data and collaborate with other nodes to improve without sharing any data. However, this approach poses significant privacy risks, as nodes may inadvertently disclose sensitive information about their data or preferences through their collaboration choices. In this paper, we propose Private Personalized Decentralized Learning (PPDL), a novel approach that combines secure aggregation and correlated adversarial multi-armed bandit optimization to protect node privacy while facilitating efficient node selection. By leveraging dependencies between different arms, represented by potential collaborators, we demonstrate that PPDL can effectively identify suitable collaborators solely based on aggregated models. Additionally, we show that PPDL surpasses previous non-private methods in model performance on standard benchmarks under label and covariate shift s",
    "link": "http://arxiv.org/abs/2301.12755",
    "context": "Title: Efficient Node Selection in Private Personalized Decentralized Learning. (arXiv:2301.12755v2 [cs.LG] UPDATED)\nAbstract: Personalized decentralized learning is a promising paradigm for distributed learning, enabling each node to train a local model on its own data and collaborate with other nodes to improve without sharing any data. However, this approach poses significant privacy risks, as nodes may inadvertently disclose sensitive information about their data or preferences through their collaboration choices. In this paper, we propose Private Personalized Decentralized Learning (PPDL), a novel approach that combines secure aggregation and correlated adversarial multi-armed bandit optimization to protect node privacy while facilitating efficient node selection. By leveraging dependencies between different arms, represented by potential collaborators, we demonstrate that PPDL can effectively identify suitable collaborators solely based on aggregated models. Additionally, we show that PPDL surpasses previous non-private methods in model performance on standard benchmarks under label and covariate shift s",
    "path": "papers/23/01/2301.12755.json",
    "total_tokens": 938,
    "translated_title": "高效的私人个性化分散学习中节点选择",
    "translated_abstract": "个性化分散学习是一种有前途的分布式学习范式，使每个节点能够在自己的数据上训练本地模型，并与其他节点合作以改进而不共享任何数据。然而，这种方法存在着重大的隐私风险，因为节点可能会通过其合作选择无意中披露有关其数据或偏好的敏感信息。在本文中，我们提出了私人个性化分散学习（PPDL），这是一种结合了安全聚合和相关对抗式多臂老虎机优化的新方法，旨在保护节点的隐私同时实现高效的节点选择。通过利用不同臂之间的依赖关系，即潜在的合作者，我们证明PPDL可以仅基于聚合模型有效地识别合适的合作者。此外，我们展示了PPDL在标签和协变量偏移下的模型性能优于先前的非私密方法。",
    "tldr": "这篇论文提出了私人个性化分散学习（PPDL）的方法，利用安全聚合和相关对抗式多臂老虎机优化来实现高效的节点选择，并保护节点的隐私。作者通过利用不同合作者之间的依赖关系，仅基于聚合模型就能够有效地识别合适的合作者。实验证明PPDL在标签和协变量偏移下的模型性能优于先前的非私密方法。",
    "en_tdlr": "This paper proposes a method called Private Personalized Decentralized Learning (PPDL) that protects node privacy while facilitating efficient node selection in decentralized learning. By leveraging dependencies between potential collaborators, PPDL effectively identifies suitable collaborators solely based on aggregated models. The experimental results show that PPDL outperforms previous non-private methods in model performance under label and covariate shift."
}