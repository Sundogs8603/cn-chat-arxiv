{
    "title": "Separate And Diffuse: Using a Pretrained Diffusion Model for Improving Source Separation. (arXiv:2301.10752v2 [eess.AS] UPDATED)",
    "abstract": "The problem of speech separation, also known as the cocktail party problem, refers to the task of isolating a single speech signal from a mixture of speech signals. Previous work on source separation derived an upper bound for the source separation task in the domain of human speech. This bound is derived for deterministic models. Recent advancements in generative models challenge this bound. We show how the upper bound can be generalized to the case of random generative models. Applying a diffusion model Vocoder that was pretrained to model single-speaker voices on the output of a deterministic separation model leads to state-of-the-art separation results. It is shown that this requires one to combine the output of the separation model with that of the diffusion model. In our method, a linear combination is performed, in the frequency domain, using weights that are inferred by a learned model. We show state-of-the-art results on 2, 3, 5, 10, and 20 speakers on multiple benchmarks. In ",
    "link": "http://arxiv.org/abs/2301.10752",
    "context": "Title: Separate And Diffuse: Using a Pretrained Diffusion Model for Improving Source Separation. (arXiv:2301.10752v2 [eess.AS] UPDATED)\nAbstract: The problem of speech separation, also known as the cocktail party problem, refers to the task of isolating a single speech signal from a mixture of speech signals. Previous work on source separation derived an upper bound for the source separation task in the domain of human speech. This bound is derived for deterministic models. Recent advancements in generative models challenge this bound. We show how the upper bound can be generalized to the case of random generative models. Applying a diffusion model Vocoder that was pretrained to model single-speaker voices on the output of a deterministic separation model leads to state-of-the-art separation results. It is shown that this requires one to combine the output of the separation model with that of the diffusion model. In our method, a linear combination is performed, in the frequency domain, using weights that are inferred by a learned model. We show state-of-the-art results on 2, 3, 5, 10, and 20 speakers on multiple benchmarks. In ",
    "path": "papers/23/01/2301.10752.json",
    "total_tokens": 896,
    "translated_title": "分离与扩散：使用预训练的扩散模型提高源分离",
    "translated_abstract": "语音分离问题，也被称为鸡尾酒会问题，指的是从多个混合的语音信号中隔离出单个语音信号的任务。先前的源分离工作在人类语音领域推导出了源分离任务的上限，该上限是针对确定性模型而推导的。最近生成模型的进展挑战了该限制。我们展示了如何将上限推广到随机生成模型的情况。将预先训练对单一说话者声音进行建模的扩散模型 Vocoder 应用于确定性分离模型的输出，可实现最先进的分离结果。我们的方法需要将分离模型的输出与扩散模型的输出进行组合，使用一个学习模型推断出的权重，在频率域内进行线性组合。我们在多个基准测试中展示了对于2、3、5、10和20个说话者的最先进结果。",
    "tldr": "该论文使用预训练的扩散模型和确定性模型的输出进行线性组合，取得了在多个基准测试中对于2、3、5、10和20个说话者的最先进结果。",
    "en_tdlr": "This paper achieves state-of-the-art results for separating 2, 3, 5, 10, and 20 speakers on multiple benchmarks by linearly combining the output of a pretrained diffusion model with that of a deterministic model, using weights inferred by a learned model in the frequency domain."
}