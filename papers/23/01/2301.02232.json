{
    "title": "CA$^2$T-Net: Category-Agnostic 3D Articulation Transfer from Single Image. (arXiv:2301.02232v2 [cs.CV] UPDATED)",
    "abstract": "We present a neural network approach to transfer the motion from a single image of an articulated object to a rest-state (i.e., unarticulated) 3D model. Our network learns to predict the object's pose, part segmentation, and corresponding motion parameters to reproduce the articulation shown in the input image. The network is composed of three distinct branches that take a shared joint image-shape embedding and is trained end-to-end. Unlike previous methods, our approach is independent of the topology of the object and can work with objects from arbitrary categories. Our method, trained with only synthetic data, can be used to automatically animate a mesh, infer motion from real images, and transfer articulation to functionally similar but geometrically distinct 3D models at test time.",
    "link": "http://arxiv.org/abs/2301.02232",
    "context": "Title: CA$^2$T-Net: Category-Agnostic 3D Articulation Transfer from Single Image. (arXiv:2301.02232v2 [cs.CV] UPDATED)\nAbstract: We present a neural network approach to transfer the motion from a single image of an articulated object to a rest-state (i.e., unarticulated) 3D model. Our network learns to predict the object's pose, part segmentation, and corresponding motion parameters to reproduce the articulation shown in the input image. The network is composed of three distinct branches that take a shared joint image-shape embedding and is trained end-to-end. Unlike previous methods, our approach is independent of the topology of the object and can work with objects from arbitrary categories. Our method, trained with only synthetic data, can be used to automatically animate a mesh, infer motion from real images, and transfer articulation to functionally similar but geometrically distinct 3D models at test time.",
    "path": "papers/23/01/2301.02232.json",
    "total_tokens": 800,
    "translated_title": "单张图像无类别3D关节转移的CA$^2$T-Net网络",
    "translated_abstract": "本文介绍了一种神经网络方法，可以将单帧图像中关节物体的运动转移到未经调整的3D模型中。我们的网络学习预测物体的姿态、部分分割和相应的运动参数，以重现输入图像中显示的关节运动。网络由三个不同的分支组成，它们采用共享的联合图像形状嵌入，并进行端到端的训练。与以往的方法不同，我们的方法不依赖于对象的拓扑结构，并且可以处理来自任意类别的对象。我们的方法仅使用合成数据进行训练，可以自动地为网格添加动画，从真实图像中推断运动，并在测试时间将运动转移到功能上相似但几何上不同的3D模型。",
    "tldr": "本文介绍了一种可以将单张图像中物体的运动转移到未调整的3D模型中的神经网络方法，可以处理任意类别的对象，训练时只使用合成数据。"
}