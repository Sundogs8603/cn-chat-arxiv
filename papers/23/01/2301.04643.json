{
    "title": "tieval: An Evaluation Framework for Temporal Information Extraction Systems. (arXiv:2301.04643v2 [cs.CL] UPDATED)",
    "abstract": "Temporal information extraction (TIE) has attracted a great deal of interest over the last two decades, leading to the development of a significant number of datasets. Despite its benefits, having access to a large volume of corpora makes it difficult when it comes to benchmark TIE systems. On the one hand, different datasets have different annotation schemes, thus hindering the comparison between competitors across different corpora. On the other hand, the fact that each corpus is commonly disseminated in a different format requires a considerable engineering effort for a researcher/practitioner to develop parsers for all of them. This constraint forces researchers to select a limited amount of datasets to evaluate their systems which consequently limits the comparability of the systems. Yet another obstacle that hinders the comparability of the TIE systems is the evaluation metric employed. While most research works adopt traditional metrics such as precision, recall, and $F_1$, a fe",
    "link": "http://arxiv.org/abs/2301.04643",
    "context": "Title: tieval: An Evaluation Framework for Temporal Information Extraction Systems. (arXiv:2301.04643v2 [cs.CL] UPDATED)\nAbstract: Temporal information extraction (TIE) has attracted a great deal of interest over the last two decades, leading to the development of a significant number of datasets. Despite its benefits, having access to a large volume of corpora makes it difficult when it comes to benchmark TIE systems. On the one hand, different datasets have different annotation schemes, thus hindering the comparison between competitors across different corpora. On the other hand, the fact that each corpus is commonly disseminated in a different format requires a considerable engineering effort for a researcher/practitioner to develop parsers for all of them. This constraint forces researchers to select a limited amount of datasets to evaluate their systems which consequently limits the comparability of the systems. Yet another obstacle that hinders the comparability of the TIE systems is the evaluation metric employed. While most research works adopt traditional metrics such as precision, recall, and $F_1$, a fe",
    "path": "papers/23/01/2301.04643.json",
    "total_tokens": 1085,
    "translated_title": "tieval：一种用于时间信息抽取系统评估的评估框架",
    "translated_abstract": "近二十年来，时间信息抽取(TIE)引起了广泛关注，推动了大量数据集的开发。然而，拥有大量语料库的好处与此同时也使得对TIE系统进行基准测试变得困难。不同数据集具有不同的注释体系，这使得比较不同语料库中的竞争对手变得困难。此外，每个语料库通常采用不同的格式进行传播，因此需要研究人员/从业人员在开发所有语料库的解析器时付出大量的工程努力。这种限制迫使研究人员选择有限的数据集来评估他们的系统，从而限制了系统的比较。另一个阻碍TIE系统可比性的障碍是评估指标的采用。本文提出了tieval，一种TIE系统的评估框架，为语料库访问、黄金标准表示和评估指标提供了标准接口。我们还展示了如何使用tieval评估TIE系统，并对TIE社区中使用的两个黄金标准的几个TIE系统的结果进行了广泛的分析。",
    "tldr": "本文提出了tieval，一种用于时间信息抽取系统的评估框架，它提供了标准的接口和评估指标，以克服不同数据集注释体系的差异、解析不同语料库的格式和不同的评估指标等限制。本文通过分析几个TIE系统在不同数据集上的结果，证明了tieval的有效性。",
    "en_tdlr": "This paper presents tieval, an evaluation framework for temporal information extraction (TIE) systems that provides a standard interface and evaluation metrics to overcome the differences in annotation schemes, formats of corpora and evaluation metrics. The effectiveness of tieval is demonstrated by an extensive analysis of the results of several TIE systems on different datasets."
}