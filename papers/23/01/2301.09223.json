{
    "title": "Doubly Adversarial Federated Bandits. (arXiv:2301.09223v2 [stat.ML] UPDATED)",
    "abstract": "We study a new non-stochastic federated multi-armed bandit problem with multiple agents collaborating via a communication network. The losses of the arms are assigned by an oblivious adversary that specifies the loss of each arm not only for each time step but also for each agent, which we call ``doubly adversarial\". In this setting, different agents may choose the same arm in the same time step but observe different feedback. The goal of each agent is to find a globally best arm in hindsight that has the lowest cumulative loss averaged over all agents, which necessities the communication among agents. We provide regret lower bounds for any federated bandit algorithm under different settings, when agents have access to full-information feedback, or the bandit feedback. For the bandit feedback setting, we propose a near-optimal federated bandit algorithm called FEDEXP3. Our algorithm gives a positive answer to an open question proposed in Cesa-Bianchi et al. (2016): FEDEXP3 can guarante",
    "link": "http://arxiv.org/abs/2301.09223",
    "context": "Title: Doubly Adversarial Federated Bandits. (arXiv:2301.09223v2 [stat.ML] UPDATED)\nAbstract: We study a new non-stochastic federated multi-armed bandit problem with multiple agents collaborating via a communication network. The losses of the arms are assigned by an oblivious adversary that specifies the loss of each arm not only for each time step but also for each agent, which we call ``doubly adversarial\". In this setting, different agents may choose the same arm in the same time step but observe different feedback. The goal of each agent is to find a globally best arm in hindsight that has the lowest cumulative loss averaged over all agents, which necessities the communication among agents. We provide regret lower bounds for any federated bandit algorithm under different settings, when agents have access to full-information feedback, or the bandit feedback. For the bandit feedback setting, we propose a near-optimal federated bandit algorithm called FEDEXP3. Our algorithm gives a positive answer to an open question proposed in Cesa-Bianchi et al. (2016): FEDEXP3 can guarante",
    "path": "papers/23/01/2301.09223.json",
    "total_tokens": 956,
    "translated_title": "双重对抗性联邦多臂赌博问题研究",
    "translated_abstract": "我们研究了一种新的非随机联邦多臂赌博问题，多个代理通过通信网络进行协作。臂的损失由一个无意识的对手分配，该对手不仅指定每个时间步和每个代理的每个臂的损失，还具有“双重对抗性”。在这种设置下，不同的代理可能在同一时间步选择相同的臂，但观察到不同的反馈。每个代理的目标是找到一个全局最好的臂，使得在所有代理上平均累积损失最低，这需要代理之间的通信。我们针对不同设置提供了任何联邦赌博算法的遗憾下界，当代理有完全信息反馈或赌博反馈时。对于赌博反馈设置，我们提出了一种接近最优的联邦赌博算法称为FEDEXP3。我们的算法对Cesa-Bianchi等人（2016）提出的一个开放性问题给出了正面答案：FEDEXP3可以保证...",
    "tldr": "我们研究了一种新的非随机联邦多臂赌博问题，考虑了具有双重对抗性的设置。我们提供了任何联邦赌博算法的遗憾下界，并提出了一种接近最优的算法FEDEXP3。该算法解决了之前的开放性问题。",
    "en_tdlr": "We study a new non-stochastic federated multi-armed bandit problem with doubly adversarial setting. We provide regret lower bounds for any federated bandit algorithm and propose a near-optimal algorithm called FEDEXP3, which answers an open question proposed before."
}