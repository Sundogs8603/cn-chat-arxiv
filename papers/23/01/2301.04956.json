{
    "title": "Graph Laplacian for Semi-Supervised Learning. (arXiv:2301.04956v2 [cs.CV] UPDATED)",
    "abstract": "Semi-supervised learning is highly useful in common scenarios where labeled data is scarce but unlabeled data is abundant. The graph (or nonlocal) Laplacian is a fundamental smoothing operator for solving various learning tasks. For unsupervised clustering, a spectral embedding is often used, based on graph-Laplacian eigenvectors. For semi-supervised problems, the common approach is to solve a constrained optimization problem, regularized by a Dirichlet energy, based on the graph-Laplacian. However, as supervision decreases, Dirichlet optimization becomes suboptimal. We therefore would like to obtain a smooth transition between unsupervised clustering and low-supervised graph-based classification. In this paper, we propose a new type of graph-Laplacian which is adapted for Semi-Supervised Learning (SSL) problems. It is based on both density and contrastive measures and allows the encoding of the labeled data directly in the operator. Thus, we can perform successfully semi-supervised le",
    "link": "http://arxiv.org/abs/2301.04956",
    "context": "Title: Graph Laplacian for Semi-Supervised Learning. (arXiv:2301.04956v2 [cs.CV] UPDATED)\nAbstract: Semi-supervised learning is highly useful in common scenarios where labeled data is scarce but unlabeled data is abundant. The graph (or nonlocal) Laplacian is a fundamental smoothing operator for solving various learning tasks. For unsupervised clustering, a spectral embedding is often used, based on graph-Laplacian eigenvectors. For semi-supervised problems, the common approach is to solve a constrained optimization problem, regularized by a Dirichlet energy, based on the graph-Laplacian. However, as supervision decreases, Dirichlet optimization becomes suboptimal. We therefore would like to obtain a smooth transition between unsupervised clustering and low-supervised graph-based classification. In this paper, we propose a new type of graph-Laplacian which is adapted for Semi-Supervised Learning (SSL) problems. It is based on both density and contrastive measures and allows the encoding of the labeled data directly in the operator. Thus, we can perform successfully semi-supervised le",
    "path": "papers/23/01/2301.04956.json",
    "total_tokens": 998,
    "translated_title": "半监督学习的图拉普拉斯算子",
    "translated_abstract": "半监督学习在标记数据稀缺但未标记数据丰富的常见场景中非常有用。图（或非本地）拉普拉斯算子是解决各种学习任务的基本平滑算子。对于无监督聚类，通常使用基于图拉普拉斯特征向量的谱嵌入。对于半监督问题，常见的方法是通过图拉普拉斯算子基于Dirichlet能量来解决约束优化问题。然而，随着监督减少，Dirichlet优化变得次优。因此，我们希望在无监督聚类和低监督基于图的分类之间获得平滑的过渡。在本文中，我们提出了一种适用于半监督学习问题的新型图拉普拉斯算子。它基于密度和对比度度量，并允许直接在运算符中对标记数据进行编码。 因此，我们可以成功地通过最小化所提出的平滑SSL图拉普拉斯算子，而无需单独使用Dirichlet正则化或基于核的方法，来进行半监督学习。",
    "tldr": "本文提出了一种新型图拉普拉斯算子，旨在平稳无监督聚类和低监督基于图的分类之间的过渡，并且无需使用Dirichlet正则化或者基于核的方法。",
    "en_tdlr": "This paper proposes a new graph Laplacian adapted for semi-supervised learning problems, based on both density and contrastive measures, allowing direct encoding of labeled data in the operator. The proposed smooth SSL graph-Laplacian can successfully perform semi-supervised learning without separate Dirichlet regularization or kernel-based approaches, achieving a smooth transition between unsupervised clustering and low-supervised graph-based classification."
}