{
    "title": "SIRL: Similarity-based Implicit Representation Learning. (arXiv:2301.00810v3 [cs.RO] UPDATED)",
    "abstract": "When robots learn reward functions using high capacity models that take raw state directly as input, they need to both learn a representation for what matters in the task -- the task ``features\" -- as well as how to combine these features into a single objective. If they try to do both at once from input designed to teach the full reward function, it is easy to end up with a representation that contains spurious correlations in the data, which fails to generalize to new settings. Instead, our ultimate goal is to enable robots to identify and isolate the causal features that people actually care about and use when they represent states and behavior. Our idea is that we can tune into this representation by asking users what behaviors they consider similar: behaviors will be similar if the features that matter are similar, even if low-level behavior is different; conversely, behaviors will be different if even one of the features that matter differs. This, in turn, is what enables the rob",
    "link": "http://arxiv.org/abs/2301.00810",
    "context": "Title: SIRL: Similarity-based Implicit Representation Learning. (arXiv:2301.00810v3 [cs.RO] UPDATED)\nAbstract: When robots learn reward functions using high capacity models that take raw state directly as input, they need to both learn a representation for what matters in the task -- the task ``features\" -- as well as how to combine these features into a single objective. If they try to do both at once from input designed to teach the full reward function, it is easy to end up with a representation that contains spurious correlations in the data, which fails to generalize to new settings. Instead, our ultimate goal is to enable robots to identify and isolate the causal features that people actually care about and use when they represent states and behavior. Our idea is that we can tune into this representation by asking users what behaviors they consider similar: behaviors will be similar if the features that matter are similar, even if low-level behavior is different; conversely, behaviors will be different if even one of the features that matter differs. This, in turn, is what enables the rob",
    "path": "papers/23/01/2301.00810.json",
    "total_tokens": 1048,
    "translated_title": "SIRL: 基于相似度的隐式表示学习",
    "translated_abstract": "当机器人使用高容量模型以原始状态作为输入学习奖励函数时，他们需要同时学习任务的“特征”表示及如何将这些特征组合成一个目标。如果他们尝试从用于教授完整奖励函数的输入中同时学习两者，很容易产生包含数据中假相关性的表示，导致不能推广到新的环境中。我们的最终目标是使机器人能够识别和隔离人们实际关心和使用的因果特征，当表示状态和行为时。我们的想法是，我们可以通过询问用户认为相似的行为来调整这种表示：如果关键特征相似，这些行为将相似，即使低层行为有所不同；相反，如果即使有一个关键特征不同，那么这些行为就会有所不同。这正是使机器人能够学习任务目标并生成适当行为的关键。为了实现这一目标，我们提出了基于相似度的隐式表示学习（SIRL）方法，该方法使用由人提供的相似性判断来学习隐式任务表示。我们在各种机器人任务上评估SIRL，并展示它在最终任务性能和泛化能力方面胜过其他表示学习方法。",
    "tldr": "SIRL是基于人提供相似度判断的任务表示学习方法，能够帮助机器人识别和隔离因果特征并生成适当行为，在各种机器人任务上表现优秀。",
    "en_tdlr": "SIRL is a task representation learning method based on human-provided similarity judgments that helps robots identify and isolate causal features and generate appropriate behavior, and outperforms other representation learning methods in various robotic tasks."
}