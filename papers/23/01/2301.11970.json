{
    "title": "Even if Explanations: Prior Work, Desiderata & Benchmarks for Semi-Factual XAI. (arXiv:2301.11970v2 [cs.AI] UPDATED)",
    "abstract": "Recently, eXplainable AI (XAI) research has focused on counterfactual explanations as post-hoc justifications for AI-system decisions (e.g. a customer refused a loan might be told: If you asked for a loan with a shorter term, it would have been approved). Counterfactuals explain what changes to the input-features of an AI system change the output-decision. However, there is a sub-type of counterfactual, semi-factuals, that have received less attention in AI (though the Cognitive Sciences have studied them extensively). This paper surveys these literatures to summarise historical and recent breakthroughs in this area. It defines key desiderata for semi-factual XAI and reports benchmark tests of historical algorithms (along with a novel, naieve method) to provide a solid basis for future algorithmic developments.",
    "link": "http://arxiv.org/abs/2301.11970",
    "context": "Title: Even if Explanations: Prior Work, Desiderata & Benchmarks for Semi-Factual XAI. (arXiv:2301.11970v2 [cs.AI] UPDATED)\nAbstract: Recently, eXplainable AI (XAI) research has focused on counterfactual explanations as post-hoc justifications for AI-system decisions (e.g. a customer refused a loan might be told: If you asked for a loan with a shorter term, it would have been approved). Counterfactuals explain what changes to the input-features of an AI system change the output-decision. However, there is a sub-type of counterfactual, semi-factuals, that have received less attention in AI (though the Cognitive Sciences have studied them extensively). This paper surveys these literatures to summarise historical and recent breakthroughs in this area. It defines key desiderata for semi-factual XAI and reports benchmark tests of historical algorithms (along with a novel, naieve method) to provide a solid basis for future algorithmic developments.",
    "path": "papers/23/01/2301.11970.json",
    "total_tokens": 908,
    "translated_title": "即使解释：半事实可解释人工智能（Semi-Factual XAI）的先前工作、期望和基准",
    "translated_abstract": "最近，“可解释人工智能”（XAI）研究专注于反事实解释作为对人工智能系统决策的后评价（例如，可能告诉一个被拒绝贷款的客户：如果您要求一个更短期限的贷款，就会被批准）。反事实解释说明了对AI系统输入特征的更改如何改变输出决策。然而，还有一种类型的反事实称为半事实，虽然认知科学已经广泛研究了它们，但在人工智能领域却受到了较少关注。本文调查了这些文献，总结了这一领域的历史和最新突破。它为半事实可解释人工智能定义了关键期望，并报告了历史算法的基准测试（以及一个新颖的幼稚方法），以为未来的算法开发提供坚实的基础。",
    "tldr": "本文总结了反事实解释在AI系统中的应用，其中特别关注半事实解释，提出了半事实可解释人工智能的期望，并对历史算法进行了基准测试，为未来算法的发展提供了坚实的基础。",
    "en_tdlr": "This paper summarizes the use of counterfactual explanations in AI systems, with a focus on semi-factual explanations. It defines key desiderata for Semi-Factual XAI and reports benchmark tests of historical algorithms to provide a solid basis for future algorithmic developments."
}