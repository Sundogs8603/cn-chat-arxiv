{
    "title": "Towards the Identifiability in Noisy Label Learning: A Multinomial Mixture Approach. (arXiv:2301.01405v2 [cs.LG] UPDATED)",
    "abstract": "Learning from noisy labels (LNL) plays a crucial role in deep learning. The most promising LNL methods rely on identifying clean-label samples from a dataset with noisy annotations. Such an identification is challenging because the conventional LNL problem, which assumes a single noisy label per instance, is non-identifiable, i.e., clean labels cannot be estimated theoretically without additional heuristics. In this paper, we aim to formally investigate this identifiability issue using multinomial mixture models to determine the constraints that make the problem identifiable. Specifically, we discover that the LNL problem becomes identifiable if there are at least $2C - 1$ noisy labels per instance, where $C$ is the number of classes. To meet this requirement without relying on additional $2C - 2$ manual annotations per instance, we propose a method that automatically generates additional noisy labels by estimating the noisy label distribution based on nearest neighbours. These additio",
    "link": "http://arxiv.org/abs/2301.01405",
    "context": "Title: Towards the Identifiability in Noisy Label Learning: A Multinomial Mixture Approach. (arXiv:2301.01405v2 [cs.LG] UPDATED)\nAbstract: Learning from noisy labels (LNL) plays a crucial role in deep learning. The most promising LNL methods rely on identifying clean-label samples from a dataset with noisy annotations. Such an identification is challenging because the conventional LNL problem, which assumes a single noisy label per instance, is non-identifiable, i.e., clean labels cannot be estimated theoretically without additional heuristics. In this paper, we aim to formally investigate this identifiability issue using multinomial mixture models to determine the constraints that make the problem identifiable. Specifically, we discover that the LNL problem becomes identifiable if there are at least $2C - 1$ noisy labels per instance, where $C$ is the number of classes. To meet this requirement without relying on additional $2C - 2$ manual annotations per instance, we propose a method that automatically generates additional noisy labels by estimating the noisy label distribution based on nearest neighbours. These additio",
    "path": "papers/23/01/2301.01405.json",
    "total_tokens": 1150,
    "translated_title": "面向有噪声标签学习的可识别性：多项式混合方法研究",
    "translated_abstract": "从有噪声标签中进行学习在深度学习中扮演着至关重要的角色。最有前途的有噪声标签学习方法依赖于从带有噪声注释的数据集中识别出干净标签样本。这种识别具有挑战性，因为传统的有噪声标签学习问题假定每个实例只有一个有噪声标签，是不可识别的，也就是说，没有附加的启发式方法理论上无法估计出干净标签。在本文中，我们旨在使用多项式混合模型正式调查这个可识别性问题，以确定使问题可识别的约束条件。具体来说，我们发现，如果每个实例有至少 $2C-1$ 个有噪声标签，其中 C 是类的数量，则该有噪声标签学习问题就变得可识别。为了满足这个要求，而不依赖于每个实例额外的 $2C-2$ 手动注释，我们提出了一种方法，通过估计基于最近邻的噪声标签分布来自动生成额外的噪声标签。这些额外的噪声标签提高了可识别性，使得可以无需任何其他假设来估计干净标签。我们在各种基准和应用程序上验证了我们的方法的有效性。",
    "tldr": "本文使用多项式混合模型研究了在有噪声标签学习过程中如何识别出干净标签样本，发现每个实例有至少 $2C-1$ 个有噪声标签时，该问题才是可识别的。为了满足这个要求，提出了一种方法，通过估计噪声标签分布自动生成额外的噪声标签以提高可识别性，无需额外的假设。",
    "en_tdlr": "This paper investigates the identifiability issue in the learning from noisy labels problem using multinomial mixture models and proposes a method to automatically generate additional noisy labels to boost the identifiability without additional assumptions. The method requires at least $2C-1$ noisy labels per instance and is effective in various benchmarks and applications."
}