{
    "title": "SMDP-Based Dynamic Batching for Efficient Inference on GPU-Based Platforms. (arXiv:2301.12865v2 [cs.LG] UPDATED)",
    "abstract": "In up-to-date machine learning (ML) applications on cloud or edge computing platforms, batching is an important technique for providing efficient and economical services at scale. In particular, parallel computing resources on the platforms, such as graphics processing units (GPUs), have higher computational and energy efficiency with larger batch sizes. However, larger batch sizes may also result in longer response time, and thus it requires a judicious design. This paper aims to provide a dynamic batching policy that strikes a balance between efficiency and latency. The GPU-based inference service is modeled as a batch service queue with batch-size dependent processing time. Then, the design of dynamic batching is a continuous-time average-cost problem, and is formulated as a semi-Markov decision process (SMDP) with the objective of minimizing the weighted sum of average response time and average power consumption. The optimal policy is acquired by solving an associated discrete-time",
    "link": "http://arxiv.org/abs/2301.12865",
    "context": "Title: SMDP-Based Dynamic Batching for Efficient Inference on GPU-Based Platforms. (arXiv:2301.12865v2 [cs.LG] UPDATED)\nAbstract: In up-to-date machine learning (ML) applications on cloud or edge computing platforms, batching is an important technique for providing efficient and economical services at scale. In particular, parallel computing resources on the platforms, such as graphics processing units (GPUs), have higher computational and energy efficiency with larger batch sizes. However, larger batch sizes may also result in longer response time, and thus it requires a judicious design. This paper aims to provide a dynamic batching policy that strikes a balance between efficiency and latency. The GPU-based inference service is modeled as a batch service queue with batch-size dependent processing time. Then, the design of dynamic batching is a continuous-time average-cost problem, and is formulated as a semi-Markov decision process (SMDP) with the objective of minimizing the weighted sum of average response time and average power consumption. The optimal policy is acquired by solving an associated discrete-time",
    "path": "papers/23/01/2301.12865.json",
    "total_tokens": 780,
    "translated_title": "基于SMDP的GPU动态批处理优化推断效率",
    "translated_abstract": "在云计算或边缘计算平台上，批处理是提供高效和经济服务的重要技术，本文提出了一种动态批处理策略，旨在在效率和延迟之间取得平衡。将基于GPU的推断服务建模为批处理服务队列，并将其设计为一个连续时间平均成本问题，制定了一个半马尔可夫决策过程（SMDP），并以最小化平均响应时间和平均功耗之和为目标。最优策略通过解决相关的离散时间贝尔曼方程获得。",
    "tldr": "本文提出了一种动态批处理策略，采用基于GPU的批处理服务队列进行建模，通过半马尔可夫决策过程的方法最小化平均响应时间和功耗。",
    "en_tdlr": "This paper proposes a dynamic batching policy for efficient and economical services on cloud or edge computing platforms, with a focus on balancing efficiency and latency. It models the GPU-based inference service as a batch service queue and uses a semi-Markov decision process to minimize the weighted sum of average response time and average power consumption."
}