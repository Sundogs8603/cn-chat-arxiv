{
    "title": "Towards AI-controlled FES-restoration of arm movements: Controlling for progressive muscular fatigue with Gaussian state-space models. (arXiv:2301.04005v2 [eess.SY] UPDATED)",
    "abstract": "Reaching disability limits an individual's ability in performing daily tasks. Surface Functional Electrical Stimulation (FES) offers a non-invasive solution to restore the lost abilities. However, inducing desired movements using FES is still an open engineering problem. This problem is accentuated by the complexities of human arms' neuromechanics and the variations across individuals. Reinforcement Learning (RL) emerges as a promising approach to govern customised control rules for different subjects and settings. Yet, one remaining challenge of using RL to control FES is unobservable muscle fatigue that progressively changes as an unknown function of the stimulation, breaking the Markovian assumption of RL. In this work, we present a method to address the unobservable muscle fatigue issue, allowing our RL controller to achieve higher control performances. Our method is based on a Gaussian State-Space Model (GSSM) that utilizes recurrent neural networks to learn Markovian state-spaces",
    "link": "http://arxiv.org/abs/2301.04005",
    "context": "Title: Towards AI-controlled FES-restoration of arm movements: Controlling for progressive muscular fatigue with Gaussian state-space models. (arXiv:2301.04005v2 [eess.SY] UPDATED)\nAbstract: Reaching disability limits an individual's ability in performing daily tasks. Surface Functional Electrical Stimulation (FES) offers a non-invasive solution to restore the lost abilities. However, inducing desired movements using FES is still an open engineering problem. This problem is accentuated by the complexities of human arms' neuromechanics and the variations across individuals. Reinforcement Learning (RL) emerges as a promising approach to govern customised control rules for different subjects and settings. Yet, one remaining challenge of using RL to control FES is unobservable muscle fatigue that progressively changes as an unknown function of the stimulation, breaking the Markovian assumption of RL. In this work, we present a method to address the unobservable muscle fatigue issue, allowing our RL controller to achieve higher control performances. Our method is based on a Gaussian State-Space Model (GSSM) that utilizes recurrent neural networks to learn Markovian state-spaces",
    "path": "papers/23/01/2301.04005.json",
    "total_tokens": 992,
    "translated_title": "人工智能控制的表面肌肉电刺激臂部运动恢复：利用高斯状态空间模型控制逐渐加重的肌肉疲劳（arXiv:2301.04005v2 [eess.SY] 已更新）",
    "translated_abstract": "运动障碍会限制个体完成日常任务的能力。表面肌肉电刺激（FES）提供了一种非侵入式的解决方案来恢复失去的能力。然而，使用FES诱导期望的运动仍然是一个开放的工程问题。这个问题由人类臂部神经机械复杂性和个体间差异引起的。强化学习（RL）是一种有希望的方法，可以为不同的受试者和场景制定定制化的控制规则。然而，使用RL控制FES的一个尚未解决的挑战是逐渐变化的肌肉疲劳，它作为刺激的未知函数不断改变，打破了RL的马尔可夫假设。在这项研究中，我们提出了一种方法来解决无法观测到的肌肉疲劳问题，使我们的RL控制器可以实现更高的控制性能。我们的方法基于一个利用循环神经网络学习马尔可夫状态空间的高斯状态空间模型（GSSM）。",
    "tldr": "本研究利用高斯状态空间模型与循环神经网络处理FES控制中无法观测到的肌肉疲劳问题，提高了强化学习控制器的控制性能。",
    "en_tdlr": "This study utilizes Gaussian state-space models and recurrent neural networks to address the issue of unobservable muscle fatigue in FES control, improving the performance of reinforcement learning controller."
}