{
    "title": "Universal Detection of Backdoor Attacks via Density-based Clustering and Centroids Analysis. (arXiv:2301.04554v2 [cs.CV] UPDATED)",
    "abstract": "We propose a Universal Defence against backdoor attacks based on Clustering and Centroids Analysis (CCA-UD). The goal of the defence is to reveal whether a Deep Neural Network model is subject to a backdoor attack by inspecting the training dataset. CCA-UD first clusters the samples of the training set by means of density-based clustering. Then, it applies a novel strategy to detect the presence of poisoned clusters. The proposed strategy is based on a general misclassification behaviour observed when the features of a representative example of the analysed cluster are added to benign samples. The capability of inducing a misclassification error is a general characteristic of poisoned samples, hence the proposed defence is attack-agnostic. This marks a significant difference with respect to existing defences, that, either can defend against only some types of backdoor attacks, or are effective only when some conditions on the poisoning ratio or the kind of triggering signal used by the",
    "link": "http://arxiv.org/abs/2301.04554",
    "context": "Title: Universal Detection of Backdoor Attacks via Density-based Clustering and Centroids Analysis. (arXiv:2301.04554v2 [cs.CV] UPDATED)\nAbstract: We propose a Universal Defence against backdoor attacks based on Clustering and Centroids Analysis (CCA-UD). The goal of the defence is to reveal whether a Deep Neural Network model is subject to a backdoor attack by inspecting the training dataset. CCA-UD first clusters the samples of the training set by means of density-based clustering. Then, it applies a novel strategy to detect the presence of poisoned clusters. The proposed strategy is based on a general misclassification behaviour observed when the features of a representative example of the analysed cluster are added to benign samples. The capability of inducing a misclassification error is a general characteristic of poisoned samples, hence the proposed defence is attack-agnostic. This marks a significant difference with respect to existing defences, that, either can defend against only some types of backdoor attacks, or are effective only when some conditions on the poisoning ratio or the kind of triggering signal used by the",
    "path": "papers/23/01/2301.04554.json",
    "total_tokens": 920,
    "translated_title": "通过基于密度聚类和质心分析的方法进行反向攻击的通用检测",
    "translated_abstract": "我们提出了一种基于聚类和质心分析的通用防御方法（CCA-UD），旨在通过检查训练数据集来揭示深度神经网络模型是否受到反向攻击的影响。CCA-UD首先通过密度聚类的方法对训练集样本进行聚类，然后应用一种新颖的策略来检测是否存在被污染的聚类。所提出的策略基于一个观察到的常规误分类行为，即当被分析聚类的代表性示例的特征添加到良性样本中时产生误分类。诱导误分类错误的能力是被污染样本的普遍特征，因此所提出的防御方法是攻击无关的，与现有的防御方法有明显的不同，要么只能防御某些类型的反向攻击，要么只在某些关于污染比例或触发信号类型的条件下有效。",
    "tldr": "该论文提出了一种通用防御方法，通过基于密度聚类和质心分析的策略，检测深度神经网络模型是否受到反向攻击的影响，该方法与现有的防御方法相比具有攻击无关性。"
}