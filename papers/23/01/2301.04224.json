{
    "title": "Pix2Map: Cross-modal Retrieval for Inferring Street Maps from Images. (arXiv:2301.04224v2 [cs.CV] UPDATED)",
    "abstract": "Self-driving vehicles rely on urban street maps for autonomous navigation. In this paper, we introduce Pix2Map, a method for inferring urban street map topology directly from ego-view images, as needed to continually update and expand existing maps. This is a challenging task, as we need to infer a complex urban road topology directly from raw image data. The main insight of this paper is that this problem can be posed as cross-modal retrieval by learning a joint, cross-modal embedding space for images and existing maps, represented as discrete graphs that encode the topological layout of the visual surroundings. We conduct our experimental evaluation using the Argoverse dataset and show that it is indeed possible to accurately retrieve street maps corresponding to both seen and unseen roads solely from image data. Moreover, we show that our retrieved maps can be used to update or expand existing maps and even show proof-of-concept results for visual localization and image retrieval fr",
    "link": "http://arxiv.org/abs/2301.04224",
    "context": "Title: Pix2Map: Cross-modal Retrieval for Inferring Street Maps from Images. (arXiv:2301.04224v2 [cs.CV] UPDATED)\nAbstract: Self-driving vehicles rely on urban street maps for autonomous navigation. In this paper, we introduce Pix2Map, a method for inferring urban street map topology directly from ego-view images, as needed to continually update and expand existing maps. This is a challenging task, as we need to infer a complex urban road topology directly from raw image data. The main insight of this paper is that this problem can be posed as cross-modal retrieval by learning a joint, cross-modal embedding space for images and existing maps, represented as discrete graphs that encode the topological layout of the visual surroundings. We conduct our experimental evaluation using the Argoverse dataset and show that it is indeed possible to accurately retrieve street maps corresponding to both seen and unseen roads solely from image data. Moreover, we show that our retrieved maps can be used to update or expand existing maps and even show proof-of-concept results for visual localization and image retrieval fr",
    "path": "papers/23/01/2301.04224.json",
    "total_tokens": 881,
    "translated_title": "Pix2Map: 从图像中推断街道地图的跨模态检索方法",
    "translated_abstract": "自动驾驶车辆依赖城市街道地图进行自主导航。本文介绍了Pix2Map，一种从自我视角图像中推断城市街道地图拓扑结构的方法，以不断更新和扩展现有地图。这是一项具有挑战性的任务，因为我们需要直接从原始图像数据推断复杂的城市道路拓扑结构。本文的主要思路是可以通过学习图像和现有地图的联合、跨模态嵌入空间，将这个问题形式化为跨模态检索。我们使用Argoverse数据集进行实验评估，并展示了仅从图像数据中准确检索对应已知和未知道路的街道地图的可行性。此外，我们还展示了我们检索到的地图可以用于更新或扩展现有地图，并展示了视觉定位和图像检索的概念证明结果。",
    "tldr": "本论文提出了一种名为Pix2Map的跨模态检索方法，可以从自我视角图像中推断城市街道地图的拓扑结构，并可以用于更新或扩展现有地图。使用Argoverse数据集进行实验，证明了这种方法的可行性。",
    "en_tdlr": "This paper proposes a cross-modal retrieval method called Pix2Map, which can infer the topology of urban street maps directly from ego-view images and be used to update or expand existing maps. The feasibility of the method is demonstrated through experiments with the Argoverse dataset."
}