{
    "title": "A Reinforcement Learning Framework for Dynamic Mediation Analysis. (arXiv:2301.13348v2 [stat.ML] UPDATED)",
    "abstract": "Mediation analysis learns the causal effect transmitted via mediator variables between treatments and outcomes and receives increasing attention in various scientific domains to elucidate causal relations. Most existing works focus on point-exposure studies where each subject only receives one treatment at a single time point. However, there are a number of applications (e.g., mobile health) where the treatments are sequentially assigned over time and the dynamic mediation effects are of primary interest. Proposing a reinforcement learning (RL) framework, we are the first to evaluate dynamic mediation effects in settings with infinite horizons. We decompose the average treatment effect into an immediate direct effect, an immediate mediation effect, a delayed direct effect, and a delayed mediation effect. Upon the identification of each effect component, we further develop robust and semi-parametrically efficient estimators under the RL framework to infer these causal effects. The super",
    "link": "http://arxiv.org/abs/2301.13348",
    "context": "Title: A Reinforcement Learning Framework for Dynamic Mediation Analysis. (arXiv:2301.13348v2 [stat.ML] UPDATED)\nAbstract: Mediation analysis learns the causal effect transmitted via mediator variables between treatments and outcomes and receives increasing attention in various scientific domains to elucidate causal relations. Most existing works focus on point-exposure studies where each subject only receives one treatment at a single time point. However, there are a number of applications (e.g., mobile health) where the treatments are sequentially assigned over time and the dynamic mediation effects are of primary interest. Proposing a reinforcement learning (RL) framework, we are the first to evaluate dynamic mediation effects in settings with infinite horizons. We decompose the average treatment effect into an immediate direct effect, an immediate mediation effect, a delayed direct effect, and a delayed mediation effect. Upon the identification of each effect component, we further develop robust and semi-parametrically efficient estimators under the RL framework to infer these causal effects. The super",
    "path": "papers/23/01/2301.13348.json",
    "total_tokens": 855,
    "translated_title": "一个强化学习框架用于动态中介分析",
    "translated_abstract": "中介分析通过学习介导变量在治疗和结果之间传递的因果效应，在各个科学领域中受到越来越多的关注，以阐明因果关系。大多数现有研究集中在点暴露研究中，其中每个受试者只在一个时间点接受一种治疗。然而，有许多应用（例如移动健康）在这些应用中，治疗是按顺序分配的，动态中介效应是主要关注的对象。通过提出一个强化学习（RL）框架，我们首次评估在无限时间范围内的动态中介效应。我们将平均治疗效应分解为直接效应、中介效应、延迟直接效应和延迟中介效应。在确定每个效应成分后，我们进一步在RL框架下开发鲁棒和半参数有效的估计器来推断这些因果效应。",
    "tldr": "这项研究提出了一个强化学习框架，首次评估了在无限时间范围内的动态中介效应，并开发了鲁棒和半参数有效的估计方法来推断这些因果效应。",
    "en_tdlr": "This study proposes a reinforcement learning framework to evaluate dynamic mediation effects in settings with infinite horizons, and develops robust and semi-parametrically efficient estimators to infer these causal effects."
}