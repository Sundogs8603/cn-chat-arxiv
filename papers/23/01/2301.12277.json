{
    "title": "Node Injection for Class-specific Network Poisoning. (arXiv:2301.12277v2 [cs.LG] UPDATED)",
    "abstract": "Graph Neural Networks (GNNs) are powerful in learning rich network representations that aid the performance of downstream tasks. However, recent studies showed that GNNs are vulnerable to adversarial attacks involving node injection and network perturbation. Among these, node injection attacks are more practical as they don't require manipulation in the existing network and can be performed more realistically. In this paper, we propose a novel problem statement - a class-specific poison attack on graphs in which the attacker aims to misclassify specific nodes in the target class into a different class using node injection. Additionally, nodes are injected in such a way that they camouflage as benign nodes. We propose NICKI, a novel attacking strategy that utilizes an optimization-based approach to sabotage the performance of GNN-based node classifiers. NICKI works in two phases - it first learns the node representation and then generates the features and edges of the injected nodes. Ex",
    "link": "http://arxiv.org/abs/2301.12277",
    "context": "Title: Node Injection for Class-specific Network Poisoning. (arXiv:2301.12277v2 [cs.LG] UPDATED)\nAbstract: Graph Neural Networks (GNNs) are powerful in learning rich network representations that aid the performance of downstream tasks. However, recent studies showed that GNNs are vulnerable to adversarial attacks involving node injection and network perturbation. Among these, node injection attacks are more practical as they don't require manipulation in the existing network and can be performed more realistically. In this paper, we propose a novel problem statement - a class-specific poison attack on graphs in which the attacker aims to misclassify specific nodes in the target class into a different class using node injection. Additionally, nodes are injected in such a way that they camouflage as benign nodes. We propose NICKI, a novel attacking strategy that utilizes an optimization-based approach to sabotage the performance of GNN-based node classifiers. NICKI works in two phases - it first learns the node representation and then generates the features and edges of the injected nodes. Ex",
    "path": "papers/23/01/2301.12277.json",
    "total_tokens": 850,
    "translated_title": "类特定网络中节点注入的研究",
    "translated_abstract": "图神经网络（GNNs）在学习丰富的网络表示方面具有强大的能力，有助于下游任务的性能。然而，最近的研究表明，GNNs容易受到节点注入和网络扰动等对抗性攻击的影响。其中，节点注入攻击更加实际，因为它们不需要对现有网络进行操纵，可以更真实地执行。在本文中，我们提出了一个新的问题陈述 - 在图中进行类特定的毒素攻击，攻击者旨在将目标类中的特定节点误分类为不同的类，使用节点注入。此外，节点以一种伪装成良性节点的方式注入。我们提出了一种新的攻击策略NICKI，它利用基于优化的方法破坏基于GNN的节点分类器的性能。NICKI分为两个阶段工作，首先学习节点表示，然后生成注入节点的特征和边。",
    "tldr": "本文介绍了一种节点注入攻击的方法，针对图中的特定节点进行误分类，通过伪装成良性节点的方式进行注入。这种攻击方法可以破坏基于GNN的节点分类器的性能。"
}