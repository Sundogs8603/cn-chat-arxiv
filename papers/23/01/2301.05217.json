{
    "title": "Progress measures for grokking via mechanistic interpretability. (arXiv:2301.05217v3 [cs.LG] UPDATED)",
    "abstract": "Neural networks often exhibit emergent behavior, where qualitatively new capabilities arise from scaling up the amount of parameters, training data, or training steps. One approach to understanding emergence is to find continuous \\textit{progress measures} that underlie the seemingly discontinuous qualitative changes. We argue that progress measures can be found via mechanistic interpretability: reverse-engineering learned behaviors into their individual components. As a case study, we investigate the recently-discovered phenomenon of ``grokking'' exhibited by small transformers trained on modular addition tasks. We fully reverse engineer the algorithm learned by these networks, which uses discrete Fourier transforms and trigonometric identities to convert addition to rotation about a circle. We confirm the algorithm by analyzing the activations and weights and by performing ablations in Fourier space. Based on this understanding, we define progress measures that allow us to study the ",
    "link": "http://arxiv.org/abs/2301.05217",
    "context": "Title: Progress measures for grokking via mechanistic interpretability. (arXiv:2301.05217v3 [cs.LG] UPDATED)\nAbstract: Neural networks often exhibit emergent behavior, where qualitatively new capabilities arise from scaling up the amount of parameters, training data, or training steps. One approach to understanding emergence is to find continuous \\textit{progress measures} that underlie the seemingly discontinuous qualitative changes. We argue that progress measures can be found via mechanistic interpretability: reverse-engineering learned behaviors into their individual components. As a case study, we investigate the recently-discovered phenomenon of ``grokking'' exhibited by small transformers trained on modular addition tasks. We fully reverse engineer the algorithm learned by these networks, which uses discrete Fourier transforms and trigonometric identities to convert addition to rotation about a circle. We confirm the algorithm by analyzing the activations and weights and by performing ablations in Fourier space. Based on this understanding, we define progress measures that allow us to study the ",
    "path": "papers/23/01/2301.05217.json",
    "total_tokens": 942,
    "translated_title": "通过机械解释性的进展测量来理解\"grokking\"",
    "translated_abstract": "神经网络经常表现出新兴行为，也就是通过增加参数、训练数据或训练步骤来产生质的变化。理解新兴行为的一种方法是找到连续的“进展测量”，这些测量是看似不连续的质的变化的基础。我们认为，可以通过机械解释性来找到进展测量：将学到的行为逆向工程成其各个组成部分。作为一个案例研究，我们调查了小型transformer训练模块化加法任务时出现的“grokking”现象。我们完全逆向工程了这些网络学到的算法，该算法使用离散傅里叶变换和三角恒等式将加法转换为圆周旋转。我们通过分析激活和权重，并在傅里叶空间进行消融实验证实了这个算法。基于这种理解，我们定义了进展测量，使我们能够研究这个现象的进展性质。",
    "tldr": "该论文通过机械解释性的方法找到了连续的进展测量，以理解神经网络中 emergent behavior 的产生原因。其中，作者以“grokking”现象为案例，通过逆向工程的方式完全理解了小型transformer网络在模块化加法任务中的算法，并定义了进展测量来研究这个现象的进展性质。",
    "en_tdlr": "This paper finds continuous progress measures through mechanistic interpretability to understand the emergence of behavior in neural networks. Using the phenomenon of \"grokking\" as a case study, the authors reverse engineer the algorithm learned by small transformers in modular addition tasks and define progress measures to study the nature of progress in this phenomenon."
}