{
    "title": "Label Inference Attack against Split Learning under Regression Setting. (arXiv:2301.07284v2 [cs.CR] UPDATED)",
    "abstract": "As a crucial building block in vertical Federated Learning (vFL), Split Learning (SL) has demonstrated its practice in the two-party model training collaboration, where one party holds the features of data samples and another party holds the corresponding labels. Such method is claimed to be private considering the shared information is only the embedding vectors and gradients instead of private raw data and labels. However, some recent works have shown that the private labels could be leaked by the gradients. These existing attack only works under the classification setting where the private labels are discrete. In this work, we step further to study the leakage in the scenario of the regression model, where the private labels are continuous numbers (instead of discrete labels in classification). This makes previous attacks harder to infer the continuous labels due to the unbounded output range. To address the limitation, we propose a novel learning-based attack that integrates gradie",
    "link": "http://arxiv.org/abs/2301.07284",
    "context": "Title: Label Inference Attack against Split Learning under Regression Setting. (arXiv:2301.07284v2 [cs.CR] UPDATED)\nAbstract: As a crucial building block in vertical Federated Learning (vFL), Split Learning (SL) has demonstrated its practice in the two-party model training collaboration, where one party holds the features of data samples and another party holds the corresponding labels. Such method is claimed to be private considering the shared information is only the embedding vectors and gradients instead of private raw data and labels. However, some recent works have shown that the private labels could be leaked by the gradients. These existing attack only works under the classification setting where the private labels are discrete. In this work, we step further to study the leakage in the scenario of the regression model, where the private labels are continuous numbers (instead of discrete labels in classification). This makes previous attacks harder to infer the continuous labels due to the unbounded output range. To address the limitation, we propose a novel learning-based attack that integrates gradie",
    "path": "papers/23/01/2301.07284.json",
    "total_tokens": 908,
    "translated_title": "基于回归设置下的分裂学习中标签推断攻击研究",
    "translated_abstract": "作为垂直联邦学习中的关键构建模块，分裂学习(SL)已经在两方模型训练协作中证明了其实践性，其中一方拥有数据样本的特征，另一方拥有相应的标签。这种方法被认为是私有的，因为共享信息仅是嵌入向量和梯度，而不是私有原始数据和标签。但是，一些最近的研究表明，私有标签可以通过梯度泄漏。这些现有的攻击仅适用于分类设置，其中私有标签是离散的。在这项工作中，我们进一步研究了回归模型的情况下泄漏的问题，其中私有标签是连续的数字（而不是分类中的离散标签）。由于输出范围无限，这使得先前的攻击更难推断连续标签。为了解决这个问题，我们提出了一种新颖的基于学习的攻击策略，它整合了梯度。",
    "tldr": "本文研究了在回归模型下分裂学习中标签推断攻击的问题。现有的攻击只适用于离散标签的分类模型，而本文提出了一种新的攻击策略以推断连续标签。",
    "en_tdlr": "This paper studies the label inference attack against split learning under regression setting. The existing attacks only work under the classification setting with discrete labels, while this paper proposes a novel attack strategy to infer continuous labels."
}