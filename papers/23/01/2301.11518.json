{
    "title": "Online Learning in Stackelberg Games with an Omniscient Follower. (arXiv:2301.11518v2 [cs.LG] UPDATED)",
    "abstract": "We study the problem of online learning in a two-player decentralized cooperative Stackelberg game. In each round, the leader first takes an action, followed by the follower who takes their action after observing the leader's move. The goal of the leader is to learn to minimize the cumulative regret based on the history of interactions. Differing from the traditional formulation of repeated Stackelberg games, we assume the follower is omniscient, with full knowledge of the true reward, and that they always best-respond to the leader's actions. We analyze the sample complexity of regret minimization in this repeated Stackelberg game. We show that depending on the reward structure, the existence of the omniscient follower may change the sample complexity drastically, from constant to exponential, even for linear cooperative Stackelberg games. This poses unique challenges for the learning process of the leader and the subsequent regret analysis.",
    "link": "http://arxiv.org/abs/2301.11518",
    "context": "Title: Online Learning in Stackelberg Games with an Omniscient Follower. (arXiv:2301.11518v2 [cs.LG] UPDATED)\nAbstract: We study the problem of online learning in a two-player decentralized cooperative Stackelberg game. In each round, the leader first takes an action, followed by the follower who takes their action after observing the leader's move. The goal of the leader is to learn to minimize the cumulative regret based on the history of interactions. Differing from the traditional formulation of repeated Stackelberg games, we assume the follower is omniscient, with full knowledge of the true reward, and that they always best-respond to the leader's actions. We analyze the sample complexity of regret minimization in this repeated Stackelberg game. We show that depending on the reward structure, the existence of the omniscient follower may change the sample complexity drastically, from constant to exponential, even for linear cooperative Stackelberg games. This poses unique challenges for the learning process of the leader and the subsequent regret analysis.",
    "path": "papers/23/01/2301.11518.json",
    "total_tokens": 926,
    "translated_title": "具有全知追随者的Stackelberg Games中的在线学习",
    "translated_abstract": "本文研究了两个玩家的分散合作Stackelberg博弈中的在线学习问题。在每一轮中，领导者首先采取行动，之后追随者在观察领导者的行动后采取他们的行动。领导者的目标是通过互动历史来学习如何最小化累积遗憾。不同于传统的重复Stackelberg博弈的表述，我们假设追随者是全知的，具有真实奖励的全部知识，他们总是最佳响应领导者的行动。我们分析了该重复Stackelberg博弈中遗憾最小化的样本复杂度。我们表明，根据奖励结构，全知追随者的存在可能会使样本复杂度从常数到指数级发生巨大变化，即使是对于线性合作Stackelberg博弈也是如此。这为领导者的学习过程和随后的遗憾分析带来了独特的挑战。",
    "tldr": "本文研究了在线学习在两个玩家的分散合作Stackelberg博弈中的应用，假设追随者具有全知，结果表明其存在可以从常数到指数级地改变遗憾最小化的样本复杂度，存在独特挑战。",
    "en_tdlr": "This paper studies the application of online learning in a decentralized cooperative Stackelberg game with an omniscient follower, and shows that the existence of such follower can drastically change the sample complexity of regret minimization, posing unique challenges."
}