{
    "title": "On the Expressive Power of Geometric Graph Neural Networks. (arXiv:2301.09308v2 [cs.LG] UPDATED)",
    "abstract": "The expressive power of Graph Neural Networks (GNNs) has been studied extensively through the Weisfeiler-Leman (WL) graph isomorphism test. However, standard GNNs and the WL framework are inapplicable for geometric graphs embedded in Euclidean space, such as biomolecules, materials, and other physical systems. In this work, we propose a geometric version of the WL test (GWL) for discriminating geometric graphs while respecting the underlying physical symmetries: permutations, rotation, reflection, and translation. We use GWL to characterise the expressive power of geometric GNNs that are invariant or equivariant to physical symmetries in terms of distinguishing geometric graphs. GWL unpacks how key design choices influence geometric GNN expressivity: (1) Invariant layers have limited expressivity as they cannot distinguish one-hop identical geometric graphs; (2) Equivariant layers distinguish a larger class of graphs by propagating geometric information beyond local neighbourhoods; (3)",
    "link": "http://arxiv.org/abs/2301.09308",
    "context": "Title: On the Expressive Power of Geometric Graph Neural Networks. (arXiv:2301.09308v2 [cs.LG] UPDATED)\nAbstract: The expressive power of Graph Neural Networks (GNNs) has been studied extensively through the Weisfeiler-Leman (WL) graph isomorphism test. However, standard GNNs and the WL framework are inapplicable for geometric graphs embedded in Euclidean space, such as biomolecules, materials, and other physical systems. In this work, we propose a geometric version of the WL test (GWL) for discriminating geometric graphs while respecting the underlying physical symmetries: permutations, rotation, reflection, and translation. We use GWL to characterise the expressive power of geometric GNNs that are invariant or equivariant to physical symmetries in terms of distinguishing geometric graphs. GWL unpacks how key design choices influence geometric GNN expressivity: (1) Invariant layers have limited expressivity as they cannot distinguish one-hop identical geometric graphs; (2) Equivariant layers distinguish a larger class of graphs by propagating geometric information beyond local neighbourhoods; (3)",
    "path": "papers/23/01/2301.09308.json",
    "total_tokens": 876,
    "translated_title": "论几何图神经网络表现力的研究",
    "translated_abstract": "通过 Weisfeiler-Leman (WL) 图同构测试，已经广泛研究了图神经网络 (GNNs) 的表现力。然而，标准的 GNNs 和 WL 框架不适用于嵌入欧几里得空间的几何图形，例如生物分子、材料和其他物理系统。在本文中，我们提出了 WL 测试的几何版本 (GWL)，以区分几何图形，同时尊重底层物理对称性：排列、旋转、反射和平移。我们使用 GWL 来表征具有不变或等变于物理对称性的几何 GNN 的表现力，以区分几何图形。GWL 揭示了关键设计选择如何影响几何 GNN 的表现力：(1) 不变层表现力有限，因为它们无法区分一跳相同的几何图形；(2) 等变层通过传播局部邻域之外的几何信息，区分更大类别的图形；(3)",
    "tldr": "本文提出了几何版本的Weisfeiler-Leman测试(GWL)，可以区分几何图形，揭示了关键设计选择如何影响几何GNN的表现力",
    "en_tdlr": "This paper proposes a geometric version of the Weisfeiler-Leman test (GWL) to distinguish geometric graphs and uncover how key design choices influence the expressive power of geometric GNNs."
}