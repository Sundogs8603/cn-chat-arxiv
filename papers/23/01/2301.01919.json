{
    "title": "Scalable Communication for Multi-Agent Reinforcement Learning via Transformer-Based Email Mechanism. (arXiv:2301.01919v2 [cs.MA] UPDATED)",
    "abstract": "Communication can impressively improve cooperation in multi-agent reinforcement learning (MARL), especially for partially-observed tasks. However, existing works either broadcast the messages leading to information redundancy, or learn targeted communication by modeling all the other agents as targets, which is not scalable when the number of agents varies. In this work, to tackle the scalability problem of MARL communication for partially-observed tasks, we propose a novel framework Transformer-based Email Mechanism (TEM). The agents adopt local communication to send messages only to the ones that can be observed without modeling all the agents. Inspired by human cooperation with email forwarding, we design message chains to forward information to cooperate with the agents outside the observation range. We introduce Transformer to encode and decode the message chain to choose the next receiver selectively. Empirically, TEM outperforms the baselines on multiple cooperative MARL benchma",
    "link": "http://arxiv.org/abs/2301.01919",
    "context": "Title: Scalable Communication for Multi-Agent Reinforcement Learning via Transformer-Based Email Mechanism. (arXiv:2301.01919v2 [cs.MA] UPDATED)\nAbstract: Communication can impressively improve cooperation in multi-agent reinforcement learning (MARL), especially for partially-observed tasks. However, existing works either broadcast the messages leading to information redundancy, or learn targeted communication by modeling all the other agents as targets, which is not scalable when the number of agents varies. In this work, to tackle the scalability problem of MARL communication for partially-observed tasks, we propose a novel framework Transformer-based Email Mechanism (TEM). The agents adopt local communication to send messages only to the ones that can be observed without modeling all the agents. Inspired by human cooperation with email forwarding, we design message chains to forward information to cooperate with the agents outside the observation range. We introduce Transformer to encode and decode the message chain to choose the next receiver selectively. Empirically, TEM outperforms the baselines on multiple cooperative MARL benchma",
    "path": "papers/23/01/2301.01919.json",
    "total_tokens": 891,
    "translated_title": "基于Transformer邮件机制的多智能体强化学习可扩展沟通方法",
    "translated_abstract": "在多智能体强化学习中，通讯可以极大地改善合作，尤其是对于部分可观测的任务。然而，现有方法要么广播信息导致信息冗余，要么通过将所有其他智能体模拟成目标来学习有针对性的通信，但是当智能体数量变化时，这种方法无法扩展。为了解决部分可观察任务的可扩展性问题，我们提出了一种新的框架Transformer-based Email Mechanism（TEM）。智能体采用本地通信，仅向可以观察到的智能体发送消息，无需模拟所有智能体。受到人类电子邮件转发合作的启发，我们设计了消息链以将信息转发给观察范围之外的智能体。我们引入Transformer来编码和解码消息链，以选择下一个接收者。在多个合作的MARL基准测试中，实验证明TEM优于基线方法。",
    "tldr": "本文提出了一种基于Transformer的邮件机制（TEM），解决了多智能体强化学习中的可扩展性问题，它采用本地通信和消息链转发的方式进行通信，而不需要模拟所有智能体。",
    "en_tdlr": "This paper proposes a Transformer-based Email Mechanism (TEM) to solve the scalability problem of multi-agent reinforcement learning. TEM uses local communication and message chain forwarding to communicate without the need to model all the agents. Empirical results show that TEM outperforms baselines in multiple cooperative MARL benchmarks."
}