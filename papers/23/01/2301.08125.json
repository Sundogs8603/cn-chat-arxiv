{
    "title": "Diagnose Like a Pathologist: Transformer-Enabled Hierarchical Attention-Guided Multiple Instance Learning for Whole Slide Image Classification. (arXiv:2301.08125v2 [cs.CV] UPDATED)",
    "abstract": "Multiple Instance Learning (MIL) and transformers are increasingly popular in histopathology Whole Slide Image (WSI) classification. However, unlike human pathologists who selectively observe specific regions of histopathology tissues under different magnifications, most methods do not incorporate multiple resolutions of the WSIs, hierarchically and attentively, thereby leading to a loss of focus on the WSIs and information from other resolutions. To resolve this issue, we propose a Hierarchical Attention-Guided Multiple Instance Learning framework to fully exploit the WSIs. This framework can dynamically and attentively discover the discriminative regions across multiple resolutions of the WSIs. Within this framework, an Integrated Attention Transformer is proposed to further enhance the performance of the transformer and obtain a more holistic WSI (bag) representation. This transformer consists of multiple Integrated Attention Modules, which is the combination of a transformer layer ",
    "link": "http://arxiv.org/abs/2301.08125",
    "context": "Title: Diagnose Like a Pathologist: Transformer-Enabled Hierarchical Attention-Guided Multiple Instance Learning for Whole Slide Image Classification. (arXiv:2301.08125v2 [cs.CV] UPDATED)\nAbstract: Multiple Instance Learning (MIL) and transformers are increasingly popular in histopathology Whole Slide Image (WSI) classification. However, unlike human pathologists who selectively observe specific regions of histopathology tissues under different magnifications, most methods do not incorporate multiple resolutions of the WSIs, hierarchically and attentively, thereby leading to a loss of focus on the WSIs and information from other resolutions. To resolve this issue, we propose a Hierarchical Attention-Guided Multiple Instance Learning framework to fully exploit the WSIs. This framework can dynamically and attentively discover the discriminative regions across multiple resolutions of the WSIs. Within this framework, an Integrated Attention Transformer is proposed to further enhance the performance of the transformer and obtain a more holistic WSI (bag) representation. This transformer consists of multiple Integrated Attention Modules, which is the combination of a transformer layer ",
    "path": "papers/23/01/2301.08125.json",
    "total_tokens": 919,
    "translated_title": "路径学家式诊断: 基于Transformer的层次注意力引导多实例学习用于全切片图像分类",
    "translated_abstract": "多实例学习（MIL）和transformers在组织病理学全切片图像（WSI）分类中越来越受欢迎。然而，与人类病理学家在不同放大倍率下选择性观察组织病理学组织的特定区域不同，大多数方法不会层次化和注重地结合WSI的多分辨率，导致对WSI和其他分辨率信息的关注丧失。为了解决这个问题，我们提出了一个层次注意力引导的多实例学习框架，充分利用WSI。该框架可以动态地和关注地发现跨WSI的多个分辨率的区分性区域。在该框架内，提出了一个集成注意力转换器来进一步提高transformer的性能，并获得更全面的WSI（bag）表示。该transformer由多个集成注意力模块组成，其中包括一个transformer层。",
    "tldr": "这项研究提出了一种基于Transformer的层次注意力引导多实例学习框架，用于组织病理学全切片图像分类。该框架可以动态和关注地发现并利用WSI的多个分辨率的区分性区域，提高了分类性能。",
    "en_tdlr": "This study proposes a Transformer-enabled Hierarchical Attention-Guided Multiple Instance Learning framework for histopathology Whole Slide Image (WSI) classification, which dynamically and attentively discovers and utilizes discriminative regions across multiple resolutions of WSIs, enhancing classification performance."
}