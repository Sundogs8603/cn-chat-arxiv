{
    "title": "MedKLIP: Medical Knowledge Enhanced Language-Image Pre-Training in Radiology. (arXiv:2301.02228v3 [eess.IV] UPDATED)",
    "abstract": "In this paper, we consider enhancing medical visual-language pre-training (VLP) with domain-specific knowledge, by exploiting the paired image-text reports from the radiological daily practice. In particular, we make the following contributions: First, unlike existing works that directly process the raw reports, we adopt a novel triplet extraction module to extract the medical-related information, avoiding unnecessary complexity from language grammar and enhancing the supervision signals; Second, we propose a novel triplet encoding module with entity translation by querying a knowledge base, to exploit the rich domain knowledge in medical field, and implicitly build relationships between medical entities in the language embedding space; Third, we propose to use a Transformer-based fusion model for spatially aligning the entity description with visual signals at the image patch level, enabling the ability for medical diagnosis; Fourth, we conduct thorough experiments to validate the eff",
    "link": "http://arxiv.org/abs/2301.02228",
    "context": "Title: MedKLIP: Medical Knowledge Enhanced Language-Image Pre-Training in Radiology. (arXiv:2301.02228v3 [eess.IV] UPDATED)\nAbstract: In this paper, we consider enhancing medical visual-language pre-training (VLP) with domain-specific knowledge, by exploiting the paired image-text reports from the radiological daily practice. In particular, we make the following contributions: First, unlike existing works that directly process the raw reports, we adopt a novel triplet extraction module to extract the medical-related information, avoiding unnecessary complexity from language grammar and enhancing the supervision signals; Second, we propose a novel triplet encoding module with entity translation by querying a knowledge base, to exploit the rich domain knowledge in medical field, and implicitly build relationships between medical entities in the language embedding space; Third, we propose to use a Transformer-based fusion model for spatially aligning the entity description with visual signals at the image patch level, enabling the ability for medical diagnosis; Fourth, we conduct thorough experiments to validate the eff",
    "path": "papers/23/01/2301.02228.json",
    "total_tokens": 902,
    "translated_title": "MedKLIP：基于医学知识增强的放射学语言-图像预训练",
    "translated_abstract": "本文考虑利用放射学日常实践中成对的图像-文字报告增强医学视觉语言预训练（VLP）中的领域特定知识。我们提出了以下贡献：首先，不同于直接处理原始报告的现有工作，我们采用三元组提取模块提取医学相关信息，避免语言语法中的不必要复杂性并增强监督信号；其次，我们提出一种新的三元组编码模块，通过查询知识库进行实体翻译，利用医学领域丰富的领域知识，并在语言嵌入空间中隐含地建立医学实体之间的关系；第三，我们提出使用基于Transformer的融合模型，在图像补丁级别上空间对齐实体描述和视觉信号，实现医学诊断的能力；第四，我们进行了全面的实验证明，以验证该方法的有效性。",
    "tldr": "本文提出了一种基于医学知识增强的放射学语言-图像预训练方法，利用三元组提取模块和医学知识库查询实体翻译等技术，实现了医学实体之间的关系隐含以及医学诊断的能力。",
    "en_tdlr": "This paper proposes a medical knowledge enhanced language-image pre-training method for radiology, which utilizes triplet extraction module, knowledge base entity translation and Transformer-based fusion model to implicitly build relationships between medical entities and enable medical diagnosis."
}