{
    "title": "PECAN: Leveraging Policy Ensemble for Context-Aware Zero-Shot Human-AI Coordination. (arXiv:2301.06387v4 [cs.AI] UPDATED)",
    "abstract": "Zero-shot human-AI coordination holds the promise of collaborating with humans without human data. Prevailing methods try to train the ego agent with a population of partners via self-play. However, these methods suffer from two problems: 1) The diversity of a population with finite partners is limited, thereby limiting the capacity of the trained ego agent to collaborate with a novel human; 2) Current methods only provide a common best response for every partner in the population, which may result in poor zero-shot coordination performance with a novel partner or humans. To address these issues, we first propose the policy ensemble method to increase the diversity of partners in the population, and then develop a context-aware method enabling the ego agent to analyze and identify the partner's potential policy primitives so that it can take different actions accordingly. In this way, the ego agent is able to learn more universal cooperative behaviors for collaborating with diverse par",
    "link": "http://arxiv.org/abs/2301.06387",
    "context": "Title: PECAN: Leveraging Policy Ensemble for Context-Aware Zero-Shot Human-AI Coordination. (arXiv:2301.06387v4 [cs.AI] UPDATED)\nAbstract: Zero-shot human-AI coordination holds the promise of collaborating with humans without human data. Prevailing methods try to train the ego agent with a population of partners via self-play. However, these methods suffer from two problems: 1) The diversity of a population with finite partners is limited, thereby limiting the capacity of the trained ego agent to collaborate with a novel human; 2) Current methods only provide a common best response for every partner in the population, which may result in poor zero-shot coordination performance with a novel partner or humans. To address these issues, we first propose the policy ensemble method to increase the diversity of partners in the population, and then develop a context-aware method enabling the ego agent to analyze and identify the partner's potential policy primitives so that it can take different actions accordingly. In this way, the ego agent is able to learn more universal cooperative behaviors for collaborating with diverse par",
    "path": "papers/23/01/2301.06387.json",
    "total_tokens": 924,
    "translated_title": "PECAN：利用策略合奏实现上下文感知的零样本人机协同",
    "translated_abstract": "无需人类数据即可与人类合作的零样本人机协同大有前途。目前的方法通常通过自我对弈训练智能体，以训练出能够与多种人类伙伴协同的智能体。然而这样做存在两个问题：1）有限的伙伴数量会限制训练出的智能体的协作能力；2）当前的方法只能针对众多伙伴提供一个公共的最佳答案，导致在面对新伙伴或人类时零样本协同表现不佳。为解决这些问题，本文首先提出了策略合奏的方法，以增加伙伴的多样性，然后使用一种上下文感知的方法，使得智能体能够分析并识别伙伴的潜在策略基元，从而采取不同的动作。通过这种方式，智能体将能够学习更加普遍的合作行为，与不同的伙伴协同。",
    "tldr": "本文提出了一种策略合奏的方法，以增加伙伴的多样性，结合上下文感知的方法使得智能体能够分析并识别伙伴的潜在策略基元，从而通过零样本学习更广泛的协作行为。",
    "en_tdlr": "This paper proposes a policy ensemble method to increase diversity of partners in population, and a context-aware method to enable ego agent to analyze and identify partner's potential policy primitives for zero-shot learning of more universal cooperative behaviors."
}