{
    "title": "Simplistic Collection and Labeling Practices Limit the Utility of Benchmark Datasets for Twitter Bot Detection. (arXiv:2301.07015v2 [cs.LG] UPDATED)",
    "abstract": "Accurate bot detection is necessary for the safety and integrity of online platforms. It is also crucial for research on the influence of bots in elections, the spread of misinformation, and financial market manipulation. Platforms deploy infrastructure to flag or remove automated accounts, but their tools and data are not publicly available. Thus, the public must rely on third-party bot detection. These tools employ machine learning and often achieve near perfect performance for classification on existing datasets, suggesting bot detection is accurate, reliable and fit for use in downstream applications. We provide evidence that this is not the case and show that high performance is attributable to limitations in dataset collection and labeling rather than sophistication of the tools. Specifically, we show that simple decision rules -- shallow decision trees trained on a small number of features -- achieve near-state-of-the-art performance on most available datasets and that bot detec",
    "link": "http://arxiv.org/abs/2301.07015",
    "context": "Title: Simplistic Collection and Labeling Practices Limit the Utility of Benchmark Datasets for Twitter Bot Detection. (arXiv:2301.07015v2 [cs.LG] UPDATED)\nAbstract: Accurate bot detection is necessary for the safety and integrity of online platforms. It is also crucial for research on the influence of bots in elections, the spread of misinformation, and financial market manipulation. Platforms deploy infrastructure to flag or remove automated accounts, but their tools and data are not publicly available. Thus, the public must rely on third-party bot detection. These tools employ machine learning and often achieve near perfect performance for classification on existing datasets, suggesting bot detection is accurate, reliable and fit for use in downstream applications. We provide evidence that this is not the case and show that high performance is attributable to limitations in dataset collection and labeling rather than sophistication of the tools. Specifically, we show that simple decision rules -- shallow decision trees trained on a small number of features -- achieve near-state-of-the-art performance on most available datasets and that bot detec",
    "path": "papers/23/01/2301.07015.json",
    "total_tokens": 690,
    "translated_title": "简单的数据收集和标记方法限制了Twitter机器人检测基准数据集的实用性。",
    "translated_abstract": "准确的机器人检测对于在线平台的安全和完整性至关重要。本论文提出了机器学习工具检测机器人的问题，特别关注现有数据集标注问题。通过研究现有数据集的局限性，本文提出了简单的决策规则，展示了数据集收集和标记的限制对机器人检测的影响。",
    "tldr": "本论文研究了机器人检测中现有数据集的局限性，并提出了简单的决策规则，进一步揭示了数据集收集和标记的限制对机器人检测准确性的影响。",
    "en_tdlr": "This paper examines the limitations of existing datasets for bot detection and proposes simple decision rules to highlight the impact of dataset collection and labeling on bot detection accuracy."
}