{
    "title": "STEERING: Stein Information Directed Exploration for Model-Based Reinforcement Learning. (arXiv:2301.12038v2 [cs.LG] UPDATED)",
    "abstract": "Directed Exploration is a crucial challenge in reinforcement learning (RL), especially when rewards are sparse. Information-directed sampling (IDS), which optimizes the information ratio, seeks to do so by augmenting regret with information gain. However, estimating information gain is computationally intractable or relies on restrictive assumptions which prohibit its use in many practical instances. In this work, we posit an alternative exploration incentive in terms of the integral probability metric (IPM) between a current estimate of the transition model and the unknown optimal, which under suitable conditions, can be computed in closed form with the kernelized Stein discrepancy (KSD). Based on KSD, we develop a novel algorithm \\algo: \\textbf{STE}in information dir\\textbf{E}cted exploration for model-based \\textbf{R}einforcement Learn\\textbf{ING}. To enable its derivation, we develop fundamentally new variants of KSD for discrete conditional distributions. {We further establish tha",
    "link": "http://arxiv.org/abs/2301.12038",
    "context": "Title: STEERING: Stein Information Directed Exploration for Model-Based Reinforcement Learning. (arXiv:2301.12038v2 [cs.LG] UPDATED)\nAbstract: Directed Exploration is a crucial challenge in reinforcement learning (RL), especially when rewards are sparse. Information-directed sampling (IDS), which optimizes the information ratio, seeks to do so by augmenting regret with information gain. However, estimating information gain is computationally intractable or relies on restrictive assumptions which prohibit its use in many practical instances. In this work, we posit an alternative exploration incentive in terms of the integral probability metric (IPM) between a current estimate of the transition model and the unknown optimal, which under suitable conditions, can be computed in closed form with the kernelized Stein discrepancy (KSD). Based on KSD, we develop a novel algorithm \\algo: \\textbf{STE}in information dir\\textbf{E}cted exploration for model-based \\textbf{R}einforcement Learn\\textbf{ING}. To enable its derivation, we develop fundamentally new variants of KSD for discrete conditional distributions. {We further establish tha",
    "path": "papers/23/01/2301.12038.json",
    "total_tokens": 913,
    "translated_title": "STEERING: Stein信息导向的模型驱动增强学习的探索",
    "tldr": "本论文提出了一种名为STEERING的算法，该算法使用信息导向采样（IDS）来解决强化学习中的有向探索问题。通过使用核化Stein差异（KSD）以及新的离散条件分布变体，STEERING能够计算转移模型的当前估计与未知最优模型之间的积分概率度量（IPM），从而提供了一种计算上可行的估计信息增益的方法。"
}