{
    "title": "Input Perturbation Reduces Exposure Bias in Diffusion Models. (arXiv:2301.11706v3 [cs.LG] UPDATED)",
    "abstract": "Denoising Diffusion Probabilistic Models have shown an impressive generation quality, although their long sampling chain leads to high computational costs. In this paper, we observe that a long sampling chain also leads to an error accumulation phenomenon, which is similar to the exposure bias problem in autoregressive text generation. Specifically, we note that there is a discrepancy between training and testing, since the former is conditioned on the ground truth samples, while the latter is conditioned on the previously generated results. To alleviate this problem, we propose a very simple but effective training regularization, consisting in perturbing the ground truth samples to simulate the inference time prediction errors. We empirically show that, without affecting the recall and precision, the proposed input perturbation leads to a significant improvement in the sample quality while reducing both the training and the inference times. For instance, on CelebA 64$\\times$64, we ach",
    "link": "http://arxiv.org/abs/2301.11706",
    "context": "Title: Input Perturbation Reduces Exposure Bias in Diffusion Models. (arXiv:2301.11706v3 [cs.LG] UPDATED)\nAbstract: Denoising Diffusion Probabilistic Models have shown an impressive generation quality, although their long sampling chain leads to high computational costs. In this paper, we observe that a long sampling chain also leads to an error accumulation phenomenon, which is similar to the exposure bias problem in autoregressive text generation. Specifically, we note that there is a discrepancy between training and testing, since the former is conditioned on the ground truth samples, while the latter is conditioned on the previously generated results. To alleviate this problem, we propose a very simple but effective training regularization, consisting in perturbing the ground truth samples to simulate the inference time prediction errors. We empirically show that, without affecting the recall and precision, the proposed input perturbation leads to a significant improvement in the sample quality while reducing both the training and the inference times. For instance, on CelebA 64$\\times$64, we ach",
    "path": "papers/23/01/2301.11706.json",
    "total_tokens": 938,
    "translated_title": "输入扰动降低扩散模型的暴露偏差",
    "translated_abstract": "去噪扩散概率模型显示出了令人印象深刻的生成质量，但是它们长的抽样链导致了高计算成本。本文观察到长时间的抽样链也会导致一种错误积累现象，类似于自回归文本生成中的曝光偏差问题。具体来说，我们注意到训练和测试之间存在差异，因为前者是基于真实样本进行条件训练，而后者是基于之前生成的结果进行条件的。为了缓解这个问题，我们提出了一种非常简单但有效的训练规则，即通过扰动真实样本来模拟推断时间的预测误差。我们经验证明，采用这种输入扰动方式，不会影响模型的召回率和精确率，却能显著提高样本质量，同时减少训练和推断时间。例如，在CelebA 64$\\times$64上，我们实现了36.74的Fréchet Inception Distance，优于其他最先进的模型。",
    "tldr": "本文提出了一种输入扰动方法来缓解扩散模型中的曝光偏差问题，该方法不影响模型性能，能显著提高生成样本的质量并减少训练和推断时间。",
    "en_tdlr": "This paper proposes an input perturbation method to mitigate the exposure bias problem in diffusion models. The perturbation does not affect model performance, but significantly improves the quality of generated samples and reduces training and inference time."
}