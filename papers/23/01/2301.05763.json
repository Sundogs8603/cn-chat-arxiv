{
    "title": "A Rigorous Uncertainty-Aware Quantification Framework Is Essential for Reproducible and Replicable Machine Learning Workflows. (arXiv:2301.05763v2 [cs.LG] UPDATED)",
    "abstract": "The ability to replicate predictions by machine learning (ML) or artificial intelligence (AI) models and results in scientific workflows that incorporate such ML/AI predictions is driven by numerous factors. An uncertainty-aware metric that can quantitatively assess the reproducibility of quantities of interest (QoI) would contribute to the trustworthiness of results obtained from scientific workflows involving ML/AI models. In this article, we discuss how uncertainty quantification (UQ) in a Bayesian paradigm can provide a general and rigorous framework for quantifying reproducibility for complex scientific workflows. Such as framework has the potential to fill a critical gap that currently exists in ML/AI for scientific workflows, as it will enable researchers to determine the impact of ML/AI model prediction variability on the predictive outcomes of ML/AI-powered workflows. We expect that the envisioned framework will contribute to the design of more reproducible and trustworthy wor",
    "link": "http://arxiv.org/abs/2301.05763",
    "context": "Title: A Rigorous Uncertainty-Aware Quantification Framework Is Essential for Reproducible and Replicable Machine Learning Workflows. (arXiv:2301.05763v2 [cs.LG] UPDATED)\nAbstract: The ability to replicate predictions by machine learning (ML) or artificial intelligence (AI) models and results in scientific workflows that incorporate such ML/AI predictions is driven by numerous factors. An uncertainty-aware metric that can quantitatively assess the reproducibility of quantities of interest (QoI) would contribute to the trustworthiness of results obtained from scientific workflows involving ML/AI models. In this article, we discuss how uncertainty quantification (UQ) in a Bayesian paradigm can provide a general and rigorous framework for quantifying reproducibility for complex scientific workflows. Such as framework has the potential to fill a critical gap that currently exists in ML/AI for scientific workflows, as it will enable researchers to determine the impact of ML/AI model prediction variability on the predictive outcomes of ML/AI-powered workflows. We expect that the envisioned framework will contribute to the design of more reproducible and trustworthy wor",
    "path": "papers/23/01/2301.05763.json",
    "total_tokens": 911,
    "translated_title": "一种严格的不确定性感知量化框架对机器学习工作流之可重复再现性至关重要",
    "translated_abstract": "机器学习或人工智能模型的预测和科学工作流程中包含的结果复现能力受多种因素影响。一种能够定量评估感兴趣量（QoI）复制性的不确定度感知度量标准，将有助于科学工作流程中应用机器学习和人工智能获得的结果具有更好的可信度。本文讨论了贝叶斯范式中的不确定性量化如何提供一种广泛和严格的框架，定量地评估复杂科学工作流程的可重复性。这样的框架将填补机器学习或人工智能在科学工作流程中的关键缺陷，因为它将使研究人员能够确定机器学习或人工智能模型预测变异对工作流程中预测的影响。我们期望这个框架将有助于设计更具重复性和可信度的工作流程。",
    "tldr": "这篇论文讨论了一个基于贝叶斯范式的不确定性量化框架，可以提供一个广泛而严格的方法来评估机器学习和人工智能在科学工作流程中的可重复性和可信度。",
    "en_tdlr": "This article discusses a Bayesian uncertainty quantification framework that provides a broad and rigorous approach for evaluating the reproducibility and trustworthiness of machine learning and artificial intelligence in scientific workflows."
}