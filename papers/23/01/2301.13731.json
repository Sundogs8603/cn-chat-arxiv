{
    "title": "A relaxed proximal gradient descent algorithm for convergent plug-and-play with proximal denoiser. (arXiv:2301.13731v2 [stat.ML] UPDATED)",
    "abstract": "This paper presents a new convergent Plug-and-Play (PnP) algorithm. PnP methods are efficient iterative algorithms for solving image inverse problems formulated as the minimization of the sum of a data-fidelity term and a regularization term. PnP methods perform regularization by plugging a pre-trained denoiser in a proximal algorithm, such as Proximal Gradient Descent (PGD). To ensure convergence of PnP schemes, many works study specific parametrizations of deep denoisers. However, existing results require either unverifiable or suboptimal hypotheses on the denoiser, or assume restrictive conditions on the parameters of the inverse problem. Observing that these limitations can be due to the proximal algorithm in use, we study a relaxed version of the PGD algorithm for minimizing the sum of a convex function and a weakly convex one. When plugged with a relaxed proximal denoiser, we show that the proposed PnP-$\\alpha$PGD algorithm converges for a wider range of regularization parameters",
    "link": "http://arxiv.org/abs/2301.13731",
    "context": "Title: A relaxed proximal gradient descent algorithm for convergent plug-and-play with proximal denoiser. (arXiv:2301.13731v2 [stat.ML] UPDATED)\nAbstract: This paper presents a new convergent Plug-and-Play (PnP) algorithm. PnP methods are efficient iterative algorithms for solving image inverse problems formulated as the minimization of the sum of a data-fidelity term and a regularization term. PnP methods perform regularization by plugging a pre-trained denoiser in a proximal algorithm, such as Proximal Gradient Descent (PGD). To ensure convergence of PnP schemes, many works study specific parametrizations of deep denoisers. However, existing results require either unverifiable or suboptimal hypotheses on the denoiser, or assume restrictive conditions on the parameters of the inverse problem. Observing that these limitations can be due to the proximal algorithm in use, we study a relaxed version of the PGD algorithm for minimizing the sum of a convex function and a weakly convex one. When plugged with a relaxed proximal denoiser, we show that the proposed PnP-$\\alpha$PGD algorithm converges for a wider range of regularization parameters",
    "path": "papers/23/01/2301.13731.json",
    "total_tokens": 946,
    "translated_title": "一种松弛的近端梯度下降算法用于带有近端去噪器的收敛插入-播放算法",
    "translated_abstract": "本文提出了一种新的收敛插入播放算法。插入播放方法是一种有效的迭代算法，用于解决被表述为数据适应项和正则化项之和的图像反问题的最小化问题。插入播放方法通过在近端算法（如近端梯度下降）中插入一个预先训练好的去噪器来执行正则化。为确保PnP方案的收敛，许多工作研究深度去噪器的特定参数化。然而，现有结果要么需要无法验证的假设或次优假设，要么在逆问题的参数上假设限制性条件。观察到这些限制可能是由于使用的近端算法，因此，我们研究了一种松弛版本的PGD算法（用于最小化凸函数和弱凸函数之和）。当与一个松弛的近端去噪器插入时，我们展示了所提出的PnP-$\\alpha$PGD算法能够收敛于更广泛的正则化参数范围内。",
    "tldr": "本文提出了一种新的收敛插入播放算法，使用一个松弛的近端去噪器和一个松弛的PGD算法，能够收敛于更广泛的正则化参数范围内。",
    "en_tdlr": "This paper presents a new convergent Plug-and-Play algorithm, which utilizes a relaxed proximal denoiser and a relaxed PGD algorithm to converge for a wider range of regularization parameters."
}