{
    "title": "The Fair Value of Data Under Heterogeneous Privacy Constraints in Federated Learning",
    "abstract": "Modern data aggregation often involves a platform collecting data from a network of users with various privacy options. Platforms must solve the problem of how to allocate incentives to users to convince them to share their data. This paper puts forth an idea for a \\textit{fair} amount to compensate users for their data at a given privacy level based on an axiomatic definition of fairness, along the lines of the celebrated Shapley value. To the best of our knowledge, these are the first fairness concepts for data that explicitly consider privacy constraints. We also formulate a heterogeneous federated learning problem for the platform with privacy level options for users. By studying this problem, we investigate the amount of compensation users receive under fair allocations with different privacy levels, amounts of data, and degrees of heterogeneity. We also discuss what happens when the platform is forced to design fair incentives. Under certain conditions we find that when privacy s",
    "link": "https://arxiv.org/abs/2301.13336",
    "context": "Title: The Fair Value of Data Under Heterogeneous Privacy Constraints in Federated Learning\nAbstract: Modern data aggregation often involves a platform collecting data from a network of users with various privacy options. Platforms must solve the problem of how to allocate incentives to users to convince them to share their data. This paper puts forth an idea for a \\textit{fair} amount to compensate users for their data at a given privacy level based on an axiomatic definition of fairness, along the lines of the celebrated Shapley value. To the best of our knowledge, these are the first fairness concepts for data that explicitly consider privacy constraints. We also formulate a heterogeneous federated learning problem for the platform with privacy level options for users. By studying this problem, we investigate the amount of compensation users receive under fair allocations with different privacy levels, amounts of data, and degrees of heterogeneity. We also discuss what happens when the platform is forced to design fair incentives. Under certain conditions we find that when privacy s",
    "path": "papers/23/01/2301.13336.json",
    "total_tokens": 961,
    "translated_title": "在异质隐私约束下的联邦学习中数据的公允价值",
    "translated_abstract": "现代数据聚合通常涉及平台从多个具有不同隐私选项的用户收集数据。平台必须解决如何向用户分配激励的问题，以说服他们共享他们的数据。本文根据一个公平的金额来补偿用户的数据，基于一个公平定义的公平概念，类似于著名的Shapley值。据我们所知，这是第一个明确考虑隐私约束的数据公平概念。我们还为平台制定了一个具有用户隐私级别选项的异质联邦学习问题。通过研究这个问题，我们研究了在不同隐私级别、数据量和异质程度下公平分配下用户获得的补偿金额。我们还讨论了当平台被迫设计公平激励措施时会发生什么。在一定的条件下，我们发现当隐私程度",
    "tldr": "本文提出了一种在给定隐私级别下基于公正定义的公平补偿用户数据的方法，并且考虑了隐私约束，是第一个明确考虑隐私约束的数据公平概念。同时，本文还研究了具有不同隐私级别、数据量和异质程度的公平分配下用户获得的补偿金额，并且讨论了平台被迫设计公平激励措施时的情况。",
    "en_tdlr": "This paper proposes a method to fairly compensate users for their data at a given privacy level based on an axiomatic definition of fairness, considering privacy constraints. It is the first paper to explicitly consider privacy constraints in fairness concepts for data. Additionally, it explores the amount of compensation users receive under fair allocations with different privacy levels, amounts of data, and degrees of heterogeneity, and discusses the scenario when the platform is forced to design fair incentives."
}