{
    "title": "Online Hyperparameter Optimization for Class-Incremental Learning. (arXiv:2301.05032v2 [cs.LG] UPDATED)",
    "abstract": "Class-incremental learning (CIL) aims to train a classification model while the number of classes increases phase-by-phase. An inherent challenge of CIL is the stability-plasticity tradeoff, i.e., CIL models should keep stable to retain old knowledge and keep plastic to absorb new knowledge. However, none of the existing CIL models can achieve the optimal tradeoff in different data-receiving settings--where typically the training-from-half (TFH) setting needs more stability, but the training-from-scratch (TFS) needs more plasticity. To this end, we design an online learning method that can adaptively optimize the tradeoff without knowing the setting as a priori. Specifically, we first introduce the key hyperparameters that influence the trade-off, e.g., knowledge distillation (KD) loss weights, learning rates, and classifier types. Then, we formulate the hyperparameter optimization process as an online Markov Decision Process (MDP) problem and propose a specific algorithm to solve it. ",
    "link": "http://arxiv.org/abs/2301.05032",
    "context": "Title: Online Hyperparameter Optimization for Class-Incremental Learning. (arXiv:2301.05032v2 [cs.LG] UPDATED)\nAbstract: Class-incremental learning (CIL) aims to train a classification model while the number of classes increases phase-by-phase. An inherent challenge of CIL is the stability-plasticity tradeoff, i.e., CIL models should keep stable to retain old knowledge and keep plastic to absorb new knowledge. However, none of the existing CIL models can achieve the optimal tradeoff in different data-receiving settings--where typically the training-from-half (TFH) setting needs more stability, but the training-from-scratch (TFS) needs more plasticity. To this end, we design an online learning method that can adaptively optimize the tradeoff without knowing the setting as a priori. Specifically, we first introduce the key hyperparameters that influence the trade-off, e.g., knowledge distillation (KD) loss weights, learning rates, and classifier types. Then, we formulate the hyperparameter optimization process as an online Markov Decision Process (MDP) problem and propose a specific algorithm to solve it. ",
    "path": "papers/23/01/2301.05032.json",
    "total_tokens": 919,
    "translated_title": "面向增量学习的在线超参数优化",
    "translated_abstract": "逐步增加类别时，分类增量学习（CIL）旨在训练分类模型。CIL的固有挑战是稳定性和可塑性的权衡，即CIL模型应保持稳定以保留旧知识并保持可塑性以吸收新知识。但是，目前没有任何一种现有的CIL模型能够在不同的接收数据设置下实现最佳的权衡——通常情况下，从一半开始（TFH）的设置需要更多的稳定性，而从头开始（TFS）的设置需要更多的可塑性。为此，我们设计了一种在线学习方法，可以自适应地优化权衡，而不需要事先了解设置。具体而言，我们首先介绍了影响权衡的关键超参数，例如，知识蒸馏（KD）损失权重、学习率和分类器类型。然后，我们将超参数优化过程 形式化为在线马尔可夫决策过程（MDP）问题，并提出了一种特定的算法来解决它。",
    "tldr": "本文提出了一种能够自适应优化稳定性和可塑性权衡的在线增量学习方法，并将超参数优化过程形式化为在线MDP问题。",
    "en_tdlr": "This paper proposes an online incremental learning method that can adaptively optimize the tradeoff between stability and plasticity, formulates the hyperparameter optimization process as an online MDP problem, and introduces key hyperparameters that influence the trade-off, such as knowledge distillation (KD) loss weights, learning rates, and classifier types."
}