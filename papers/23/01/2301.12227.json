{
    "title": "Deep Operator Learning Lessens the Curse of Dimensionality for PDEs. (arXiv:2301.12227v2 [cs.LG] UPDATED)",
    "abstract": "Deep neural networks (DNNs) have achieved remarkable success in numerous domains, and their application to PDE-related problems has been rapidly advancing. This paper provides an estimate for the generalization error of learning Lipschitz operators over Banach spaces using DNNs with applications to various PDE solution operators. The goal is to specify DNN width, depth, and the number of training samples needed to guarantee a certain testing error. Under mild assumptions on data distributions or operator structures, our analysis shows that deep operator learning can have a relaxed dependence on the discretization resolution of PDEs and, hence, lessen the curse of dimensionality in many PDE-related problems including elliptic equations, parabolic equations, and Burgers equations. Our results are also applied to give insights about discretization-invariant in operator learning.",
    "link": "http://arxiv.org/abs/2301.12227",
    "context": "Title: Deep Operator Learning Lessens the Curse of Dimensionality for PDEs. (arXiv:2301.12227v2 [cs.LG] UPDATED)\nAbstract: Deep neural networks (DNNs) have achieved remarkable success in numerous domains, and their application to PDE-related problems has been rapidly advancing. This paper provides an estimate for the generalization error of learning Lipschitz operators over Banach spaces using DNNs with applications to various PDE solution operators. The goal is to specify DNN width, depth, and the number of training samples needed to guarantee a certain testing error. Under mild assumptions on data distributions or operator structures, our analysis shows that deep operator learning can have a relaxed dependence on the discretization resolution of PDEs and, hence, lessen the curse of dimensionality in many PDE-related problems including elliptic equations, parabolic equations, and Burgers equations. Our results are also applied to give insights about discretization-invariant in operator learning.",
    "path": "papers/23/01/2301.12227.json",
    "total_tokens": 881,
    "translated_title": "深度算子学习减轻了PDE中维数灾难",
    "translated_abstract": "深度神经网络在许多领域均已获得显著成功，并且它们在PDE相关问题中的应用正在迅速发展。本文利用DNNs估计了在Banach空间上学习Lipschitz算子的泛化误差，并应用于各种PDE解算子。我们的目标是指定DNN的宽度、深度和需要训练样本的数量，以保证一定的测试误差。在对数据分布或算子结构进行温和的假设下，我们的分析表明，深度算子学习可以放松对PDE离散化分辨率的依赖，从而减轻许多与PDE相关的问题中的维数灾难，包括椭圆方程、抛物线方程和Burgers方程。我们的结果也应用于提供算子学习中的离散化不变性的见解。",
    "tldr": "本文指出，利用DNN对Banach空间上的Lipschitz算子进行深度算子学习可以减轻PDE中的维数灾难，包括椭圆方程、抛物线方程和Burgers方程，并可用于提供算子学习中的离散化不变性的见解。"
}