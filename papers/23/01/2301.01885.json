{
    "title": "Enhancement attacks in biomedical machine learning. (arXiv:2301.01885v2 [stat.ML] UPDATED)",
    "abstract": "The prevalence of machine learning in biomedical research is rapidly growing, yet the trustworthiness of such research is often overlooked. While some previous works have investigated the ability of adversarial attacks to degrade model performance in medical imaging, the ability to falsely improve performance via recently-developed \"enhancement attacks\" may be a greater threat to biomedical machine learning. In the spirit of developing attacks to better understand trustworthiness, we developed two techniques to drastically enhance prediction performance of classifiers with minimal changes to features: 1) general enhancement of prediction performance, and 2) enhancement of a particular method over another. Our enhancement framework falsely improved classifiers' accuracy from 50% to almost 100% while maintaining high feature similarities between original and enhanced data (Pearson's r's>0.99). Similarly, the method-specific enhancement framework was effective in falsely improving the per",
    "link": "http://arxiv.org/abs/2301.01885",
    "context": "Title: Enhancement attacks in biomedical machine learning. (arXiv:2301.01885v2 [stat.ML] UPDATED)\nAbstract: The prevalence of machine learning in biomedical research is rapidly growing, yet the trustworthiness of such research is often overlooked. While some previous works have investigated the ability of adversarial attacks to degrade model performance in medical imaging, the ability to falsely improve performance via recently-developed \"enhancement attacks\" may be a greater threat to biomedical machine learning. In the spirit of developing attacks to better understand trustworthiness, we developed two techniques to drastically enhance prediction performance of classifiers with minimal changes to features: 1) general enhancement of prediction performance, and 2) enhancement of a particular method over another. Our enhancement framework falsely improved classifiers' accuracy from 50% to almost 100% while maintaining high feature similarities between original and enhanced data (Pearson's r's>0.99). Similarly, the method-specific enhancement framework was effective in falsely improving the per",
    "path": "papers/23/01/2301.01885.json",
    "total_tokens": 908,
    "translated_title": "生物医学机器学习中的增强攻击",
    "translated_abstract": "机器学习在生物医学研究中的应用日益增多，然而对于这些研究可信度的关注却往往被忽视。尽管一些先前的研究探讨了对医学图像模型性能进行破坏的对抗攻击的能力，但最近出现的“增强攻击”通过误导地提高模型性能可能会对生物医学机器学习构成更大的威胁。为了更好地了解可信度，我们开发了两种技术，可以通过极小的特征改变显著提高分类器的预测性能：1）普遍性能增强和2）某种方法相对于其他方法的增强。我们的增强框架可以将分类器的准确率从50％虚假提高到接近100％，同时保持原始数据和增强数据之间的高特征相似性（Pearson's r>0.99）。类似地，基于方法的增强框架有效地虚假提高了某种方法的预测性能。",
    "tldr": "本研究针对生物医学机器学习中的可信度问题，通过开发增强攻击技术，成功地能够通过最小的特征改变显著提高分类器的预测性能，并保持原始数据和增强数据之间的高特征相似性。"
}