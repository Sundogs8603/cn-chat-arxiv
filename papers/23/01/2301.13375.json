{
    "title": "Optimal Transport Perturbations for Safe Reinforcement Learning with Robustness Guarantees",
    "abstract": "arXiv:2301.13375v2 Announce Type: replace-cross  Abstract: Robustness and safety are critical for the trustworthy deployment of deep reinforcement learning. Real-world decision making applications require algorithms that can guarantee robust performance and safety in the presence of general environment disturbances, while making limited assumptions on the data collection process during training. In order to accomplish this goal, we introduce a safe reinforcement learning framework that incorporates robustness through the use of an optimal transport cost uncertainty set. We provide an efficient implementation based on applying Optimal Transport Perturbations to construct worst-case virtual state transitions, which does not impact data collection during training and does not require detailed simulator access. In experiments on continuous control tasks with safety constraints, our approach demonstrates robust performance while significantly improving safety at deployment time compared to ",
    "link": "https://arxiv.org/abs/2301.13375",
    "context": "Title: Optimal Transport Perturbations for Safe Reinforcement Learning with Robustness Guarantees\nAbstract: arXiv:2301.13375v2 Announce Type: replace-cross  Abstract: Robustness and safety are critical for the trustworthy deployment of deep reinforcement learning. Real-world decision making applications require algorithms that can guarantee robust performance and safety in the presence of general environment disturbances, while making limited assumptions on the data collection process during training. In order to accomplish this goal, we introduce a safe reinforcement learning framework that incorporates robustness through the use of an optimal transport cost uncertainty set. We provide an efficient implementation based on applying Optimal Transport Perturbations to construct worst-case virtual state transitions, which does not impact data collection during training and does not require detailed simulator access. In experiments on continuous control tasks with safety constraints, our approach demonstrates robust performance while significantly improving safety at deployment time compared to ",
    "path": "papers/23/01/2301.13375.json",
    "total_tokens": 644,
    "translated_title": "使用带有鲁棒性保证的最优输运扰动进行安全强化学习",
    "translated_abstract": "基于最优输运成本不确定性集，引入了一个安全强化学习框架，通过应用最优输运扰动来构建最坏情况的虚拟状态转换，提供了一种有效的实现方法。在连续控制任务的实验中，我们的方法展示了鲁棒性能，并显著提高了部署时的安全性。",
    "tldr": "引入了基于最优输运扰动的安全强化学习框架，通过构建最坏情况的虚拟状态转换以提升鲁棒性能和安全性。",
    "en_tdlr": "Introduced a safe reinforcement learning framework based on optimal transport perturbations to construct worst-case virtual state transitions, improving robust performance and safety."
}