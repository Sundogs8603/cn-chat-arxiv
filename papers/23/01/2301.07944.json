{
    "title": "Revisiting the Spatial and Temporal Modeling for Few-shot Action Recognition. (arXiv:2301.07944v2 [cs.CV] UPDATED)",
    "abstract": "Spatial and temporal modeling is one of the most core aspects of few-shot action recognition. Most previous works mainly focus on long-term temporal relation modeling based on high-level spatial representations, without considering the crucial low-level spatial features and short-term temporal relations. Actually, the former feature could bring rich local semantic information, and the latter feature could represent motion characteristics of adjacent frames, respectively. In this paper, we propose SloshNet, a new framework that revisits the spatial and temporal modeling for few-shot action recognition in a finer manner. First, to exploit the low-level spatial features, we design a feature fusion architecture search module to automatically search for the best combination of the low-level and high-level spatial features. Next, inspired by the recent transformer, we introduce a long-term temporal modeling module to model the global temporal relations based on the extracted spatial appearan",
    "link": "http://arxiv.org/abs/2301.07944",
    "context": "Title: Revisiting the Spatial and Temporal Modeling for Few-shot Action Recognition. (arXiv:2301.07944v2 [cs.CV] UPDATED)\nAbstract: Spatial and temporal modeling is one of the most core aspects of few-shot action recognition. Most previous works mainly focus on long-term temporal relation modeling based on high-level spatial representations, without considering the crucial low-level spatial features and short-term temporal relations. Actually, the former feature could bring rich local semantic information, and the latter feature could represent motion characteristics of adjacent frames, respectively. In this paper, we propose SloshNet, a new framework that revisits the spatial and temporal modeling for few-shot action recognition in a finer manner. First, to exploit the low-level spatial features, we design a feature fusion architecture search module to automatically search for the best combination of the low-level and high-level spatial features. Next, inspired by the recent transformer, we introduce a long-term temporal modeling module to model the global temporal relations based on the extracted spatial appearan",
    "path": "papers/23/01/2301.07944.json",
    "total_tokens": 845,
    "translated_title": "重新审视少样本动作识别中的空间和时间建模",
    "translated_abstract": "空间和时间建模是少样本动作识别中最核心的方面之一。大多数以前的研究主要集中在基于高层次空间表示的长期时间关系建模上，而没有考虑至关重要的低级空间特征和短期时间关系。实际上，前者可以带来丰富的局部语义信息，而后者可以分别表示相邻帧的运动特征。在本文中，我们提出了SloshNet，一种重新审视少样本动作识别中空间和时间建模的新框架。首先，为了利用低级空间特征，我们设计了一个特征融合架构搜索模块，自动搜索低级和高级空间特征的最佳组合。接下来，受最近的Transformer的启发，我们引入了一个长期时间建模模块，基于提取的空间外观建模全局时间关系。",
    "tldr": "SloshNet是一个重新审视少样本动作识别的新框架，它在空间和时间建模方面进行了精细化的探索，利用特征融合和长期时间建模模块来提高动作识别性能。",
    "en_tdlr": "SloshNet is a new framework that revisits the spatial and temporal modeling for few-shot action recognition in a finer manner, using feature fusion and long-term temporal modeling modules to improve the recognition performance."
}