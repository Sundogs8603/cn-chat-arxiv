{
    "title": "Backpropagation of Unrolled Solvers with Folded Optimization. (arXiv:2301.12047v2 [cs.LG] UPDATED)",
    "abstract": "The integration of constrained optimization models as components in deep networks has led to promising advances on many specialized learning tasks. A central challenge in this setting is backpropagation through the solution of an optimization problem, which typically lacks a closed form. One typical strategy is algorithm unrolling, which relies on automatic differentiation through the operations of an iterative solver. While flexible and general, unrolling can encounter accuracy and efficiency issues in practice. These issues can be avoided by analytical differentiation of the optimization, but current frameworks impose rigid requirements on the optimization problem's form. This paper provides theoretical insights into the backward pass of unrolled optimization, leading to a system for generating efficiently solvable analytical models of backpropagation. Additionally, it proposes a unifying view of unrolling and analytical differentiation through optimization mappings. Experiments over",
    "link": "http://arxiv.org/abs/2301.12047",
    "context": "Title: Backpropagation of Unrolled Solvers with Folded Optimization. (arXiv:2301.12047v2 [cs.LG] UPDATED)\nAbstract: The integration of constrained optimization models as components in deep networks has led to promising advances on many specialized learning tasks. A central challenge in this setting is backpropagation through the solution of an optimization problem, which typically lacks a closed form. One typical strategy is algorithm unrolling, which relies on automatic differentiation through the operations of an iterative solver. While flexible and general, unrolling can encounter accuracy and efficiency issues in practice. These issues can be avoided by analytical differentiation of the optimization, but current frameworks impose rigid requirements on the optimization problem's form. This paper provides theoretical insights into the backward pass of unrolled optimization, leading to a system for generating efficiently solvable analytical models of backpropagation. Additionally, it proposes a unifying view of unrolling and analytical differentiation through optimization mappings. Experiments over",
    "path": "papers/23/01/2301.12047.json",
    "total_tokens": 862,
    "translated_title": "反向传播展开的折叠优化求解器",
    "translated_abstract": "在深度网络中将约束优化模型作为组件集成，可以在许多专门的学习任务上取得有希望的进展。在这种情况下的一个核心挑战是通过优化问题的解来进行反向传播，而该解通常缺乏闭合的形式。一种典型的策略是算法展开，它依赖于迭代求解器的自动微分操作。虽然灵活且通用，但在实际中，展开可能遇到精度和效率问题。通过优化的解析微分可以避免这些问题，但当前的框架对于优化问题的形式施加了严格的要求。本文提供了关于展开优化后向传递的理论见解，从而提出了一个生成高效可解析的反向传播优化模型的系统。此外，本文还提出了通过优化映射统一展开和解析微分的视角。在实验上进行测试",
    "tldr": "本文提出了一种通过解析优化的方法来解决反向传播中的精度和效率问题，并提供了生成高效可解析的反向传播优化模型的系统。此外，本文还提出了通过优化映射统一展开和解析微分的视角。",
    "en_tdlr": "This paper proposes a method to address the accuracy and efficiency issues in backpropagation by analytical differentiation of the optimization, and presents a system for generating efficiently solvable analytical models of backpropagation. Additionally, it proposes a unifying view of unrolling and analytical differentiation through optimization mappings."
}