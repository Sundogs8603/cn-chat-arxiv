{
    "title": "Learning Near-Optimal Intrusion Responses Against Dynamic Attackers. (arXiv:2301.06085v2 [cs.GT] UPDATED)",
    "abstract": "We study automated intrusion response and formulate the interaction between an attacker and a defender as an optimal stopping game where attack and defense strategies evolve through reinforcement learning and self-play. The game-theoretic modeling enables us to find defender strategies that are effective against a dynamic attacker, i.e. an attacker that adapts its strategy in response to the defender strategy. Further, the optimal stopping formulation allows us to prove that optimal strategies have threshold properties. To obtain near-optimal defender strategies, we develop Threshold Fictitious Self-Play (T-FP), a fictitious self-play algorithm that learns Nash equilibria through stochastic approximation. We show that T-FP outperforms a state-of-the-art algorithm for our use case. The experimental part of this investigation includes two systems: a simulation system where defender strategies are incrementally learned and an emulation system where statistics are collected that drive simu",
    "link": "http://arxiv.org/abs/2301.06085",
    "context": "Title: Learning Near-Optimal Intrusion Responses Against Dynamic Attackers. (arXiv:2301.06085v2 [cs.GT] UPDATED)\nAbstract: We study automated intrusion response and formulate the interaction between an attacker and a defender as an optimal stopping game where attack and defense strategies evolve through reinforcement learning and self-play. The game-theoretic modeling enables us to find defender strategies that are effective against a dynamic attacker, i.e. an attacker that adapts its strategy in response to the defender strategy. Further, the optimal stopping formulation allows us to prove that optimal strategies have threshold properties. To obtain near-optimal defender strategies, we develop Threshold Fictitious Self-Play (T-FP), a fictitious self-play algorithm that learns Nash equilibria through stochastic approximation. We show that T-FP outperforms a state-of-the-art algorithm for our use case. The experimental part of this investigation includes two systems: a simulation system where defender strategies are incrementally learned and an emulation system where statistics are collected that drive simu",
    "path": "papers/23/01/2301.06085.json",
    "total_tokens": 939,
    "translated_title": "学习动态攻击下的近似最优入侵响应",
    "translated_abstract": "本文研究自动化入侵响应，并将攻击者与防御者之间的交互形式建模为一种最优停止博弈，攻击和防御策略通过强化学习和自我博弈发展。博弈论建模使我们能够找到针对动态攻击者有效的防御者策略，即攻击者根据防御者策略进行反应来自适应的攻击者。此外，最优停止公式使我们能够证明最优策略具有阈值特性。为了获得近似最优的防御者策略，我们开发了 Threshold Fictitious Self-Play (T-FP)，这是一种虚构自我博弈算法，通过随机逼近学习纳什均衡 。我们证明了 T-FP 在我们的用例中优于现有算法。该研究的实验部分包括两个系统：一个模拟系统，其中防御策略是逐步学习的，以及一个仿真系统，收集了驱动模拟的统计数据。",
    "tldr": "本文通过博弈论建模，开发一种防御策略，以应对自主适应攻击者，在阈值特性证明的基础上，使用 Threshold Fictitious Self-Play (T-FP) 算法学习纳什均衡，实现近似最优解。",
    "en_tdlr": "This paper develops a defense strategy against dynamically adaptive attackers through game-theoretic modeling and proposes Threshold Fictitious Self-Play (T-FP) algorithm to learn near-optimal Nash equilibria. The demonstrated approach proves the threshold properties of optimal stopping strategies."
}