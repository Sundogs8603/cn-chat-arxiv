{
    "title": "Scaling Evidence-based Instructional Design Expertise through Large Language Models. (arXiv:2306.01006v1 [cs.CL])",
    "abstract": "This paper presents a comprehensive exploration of leveraging Large Language Models (LLMs), specifically GPT-4, in the field of instructional design. With a focus on scaling evidence-based instructional design expertise, our research aims to bridge the gap between theoretical educational studies and practical implementation. We discuss the benefits and limitations of AI-driven content generation, emphasizing the necessity of human oversight in ensuring the quality of educational materials. This work is elucidated through two detailed case studies where we applied GPT-4 in creating complex higher-order assessments and active learning components for different courses. From our experiences, we provide best practices for effectively using LLMs in instructional design tasks, such as utilizing templates, fine-tuning, handling unexpected output, implementing LLM chains, citing references, evaluating output, creating rubrics, grading, and generating distractors. We also share our vision of a f",
    "link": "http://arxiv.org/abs/2306.01006",
    "context": "Title: Scaling Evidence-based Instructional Design Expertise through Large Language Models. (arXiv:2306.01006v1 [cs.CL])\nAbstract: This paper presents a comprehensive exploration of leveraging Large Language Models (LLMs), specifically GPT-4, in the field of instructional design. With a focus on scaling evidence-based instructional design expertise, our research aims to bridge the gap between theoretical educational studies and practical implementation. We discuss the benefits and limitations of AI-driven content generation, emphasizing the necessity of human oversight in ensuring the quality of educational materials. This work is elucidated through two detailed case studies where we applied GPT-4 in creating complex higher-order assessments and active learning components for different courses. From our experiences, we provide best practices for effectively using LLMs in instructional design tasks, such as utilizing templates, fine-tuning, handling unexpected output, implementing LLM chains, citing references, evaluating output, creating rubrics, grading, and generating distractors. We also share our vision of a f",
    "path": "papers/23/06/2306.01006.json",
    "total_tokens": 963,
    "translated_title": "通过大型语言模型扩展基于证据的教学设计专业知识",
    "translated_abstract": "本文探讨了如何利用大型语言模型（LLMs），特别是GPT-4，来拓展教学设计领域的基于证据的专业知识。我们致力于弥合理论教育研究和实际实施之间的差距，探讨了AI驱动内容生成的优缺点，并强调了人工监督来确保教育材料的质量的必要性。通过两个详细的案例研究，我们展示了如何使用GPT-4创建不同课程的复杂高阶评估和积极学习组件。从我们的经验中，我们提供了在教学设计任务中有效使用LLMs的最佳实践，如利用模板，微调，处理意外的输出，实现LLM链，引用参考文献，评估输出，创建评分标准和生成干扰项。我们还分享了一个愿景，未来LLMs可以为所有背景和水平的学习者提供易于接受和个性化的教育内容。",
    "tldr": "本文探讨了如何利用大型语言模型扩展基于证据的教学设计专业知识，通过两个案例研究展示了GPT-4在教学设计中的应用，并提供了使用LLMs的最佳实践和未来LLMs为所有学习者提供个性化教育内容的愿景。",
    "en_tdlr": "This paper discusses how to leverage Large Language Models (LLMs), specifically GPT-4, to scale evidence-based instructional design expertise, presents case studies on GPT-4 applied in instructional design, provides best practices for effectively using LLMs, and shares a vision where LLMs provide personalized educational content to learners of all backgrounds and levels."
}