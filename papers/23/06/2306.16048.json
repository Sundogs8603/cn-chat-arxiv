{
    "title": "Challenges of Zero-Shot Recognition with Vision-Language Models: Granularity and Correctness. (arXiv:2306.16048v1 [cs.CV])",
    "abstract": "This paper investigates the challenges of applying vision-language models (VLMs) to zero-shot visual recognition tasks in an open-world setting, with a focus on contrastive vision-language models such as CLIP. We first examine the performance of VLMs on concepts of different granularity levels. We propose a way to fairly evaluate the performance discrepancy under two experimental setups and find that VLMs are better at recognizing fine-grained concepts. Furthermore, we find that the similarity scores from VLMs do not strictly reflect the correctness of the textual inputs given visual input. We propose an evaluation protocol to test our hypothesis that the scores can be biased towards more informative descriptions, and the nature of the similarity score between embedding makes it challenging for VLMs to recognize the correctness between similar but wrong descriptions. Our study highlights the challenges of using VLMs in open-world settings and suggests directions for future research to ",
    "link": "http://arxiv.org/abs/2306.16048",
    "context": "Title: Challenges of Zero-Shot Recognition with Vision-Language Models: Granularity and Correctness. (arXiv:2306.16048v1 [cs.CV])\nAbstract: This paper investigates the challenges of applying vision-language models (VLMs) to zero-shot visual recognition tasks in an open-world setting, with a focus on contrastive vision-language models such as CLIP. We first examine the performance of VLMs on concepts of different granularity levels. We propose a way to fairly evaluate the performance discrepancy under two experimental setups and find that VLMs are better at recognizing fine-grained concepts. Furthermore, we find that the similarity scores from VLMs do not strictly reflect the correctness of the textual inputs given visual input. We propose an evaluation protocol to test our hypothesis that the scores can be biased towards more informative descriptions, and the nature of the similarity score between embedding makes it challenging for VLMs to recognize the correctness between similar but wrong descriptions. Our study highlights the challenges of using VLMs in open-world settings and suggests directions for future research to ",
    "path": "papers/23/06/2306.16048.json",
    "total_tokens": 955,
    "translated_title": "零样本识别中的视觉-语言模型的挑战：粒度和正确性",
    "translated_abstract": "本文研究了将视觉-语言模型（VLMs）应用于开放世界环境下的零样本视觉识别任务所面临的挑战，重点关注对比视觉-语言模型（如CLIP）的应用。我们首先检查了VLMs在不同粒度概念上的表现。我们提出了一种公正评估两种实验设置下性能差异的方法，并发现VLMs在识别细粒度概念方面表现更好。此外，我们发现VLMs产生的相似度分数并不能严格反映文本输入在视觉输入下的正确性。我们提出了一种评估协议来测试我们的假设，即分数可能会偏向更具信息的描述，并且由于嵌入之间的相似度分数的性质，对于VLMs来说识别相似但错误的描述之间的正确性是具有挑战性的。我们的研究强调了在开放世界环境中使用VLMs的挑战，并提出了未来研究的方向。",
    "tldr": "本文研究了将视觉-语言模型应用于零样本视觉识别任务所面临的挑战，发现VLMs在识别细粒度概念方面表现更好，并指出了VLMs中相似度分数不能严格反映正确性的问题，提出了未来研究方向。",
    "en_tdlr": "This paper investigates the challenges of applying vision-language models to zero-shot visual recognition tasks and finds that VLMs perform better in recognizing fine-grained concepts. It highlights the issue of similarity scores not strictly reflecting correctness and suggests directions for future research."
}