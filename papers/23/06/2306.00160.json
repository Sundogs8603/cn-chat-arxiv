{
    "title": "Audio-Visual Speech Separation in Noisy Environments with a Lightweight Iterative Model. (arXiv:2306.00160v1 [eess.AS])",
    "abstract": "We propose Audio-Visual Lightweight ITerative model (AVLIT), an effective and lightweight neural network that uses Progressive Learning (PL) to perform audio-visual speech separation in noisy environments. To this end, we adopt the Asynchronous Fully Recurrent Convolutional Neural Network (A-FRCNN), which has shown successful results in audio-only speech separation. Our architecture consists of an audio branch and a video branch, with iterative A-FRCNN blocks sharing weights for each modality. We evaluated our model in a controlled environment using the NTCD-TIMIT dataset and in-the-wild using a synthetic dataset that combines LRS3 and WHAM!. The experiments demonstrate the superiority of our model in both settings with respect to various audio-only and audio-visual baselines. Furthermore, the reduced footprint of our model makes it suitable for low resource applications.",
    "link": "http://arxiv.org/abs/2306.00160",
    "context": "Title: Audio-Visual Speech Separation in Noisy Environments with a Lightweight Iterative Model. (arXiv:2306.00160v1 [eess.AS])\nAbstract: We propose Audio-Visual Lightweight ITerative model (AVLIT), an effective and lightweight neural network that uses Progressive Learning (PL) to perform audio-visual speech separation in noisy environments. To this end, we adopt the Asynchronous Fully Recurrent Convolutional Neural Network (A-FRCNN), which has shown successful results in audio-only speech separation. Our architecture consists of an audio branch and a video branch, with iterative A-FRCNN blocks sharing weights for each modality. We evaluated our model in a controlled environment using the NTCD-TIMIT dataset and in-the-wild using a synthetic dataset that combines LRS3 and WHAM!. The experiments demonstrate the superiority of our model in both settings with respect to various audio-only and audio-visual baselines. Furthermore, the reduced footprint of our model makes it suitable for low resource applications.",
    "path": "papers/23/06/2306.00160.json",
    "total_tokens": 898,
    "translated_title": "在嘈杂环境下利用轻量级迭代模型进行音视频语音分离",
    "translated_abstract": "我们提出了一种名为 AVLIT 的音视频轻量级迭代模型，它使用渐进式学习来在嘈杂环境中进行音视频语音分离。为此，我们采用了异步全循环卷积神经网络（A-FRCNN），它在仅利用音频进行语音分离方面已经取得了成功的结果。我们的架构由音频分支和视频分支组成，每个模态的迭代 A-FRCNN 块共享权重。我们使用 NTCD-TIMIT 数据集在受控环境中进行了模型评估，并使用合成数据集 LRS3 和 WHAM! 进行了野外测试。实验表明，与各种音频分离和音视频基线方法相比，我们的模型在两种情况下均具有优越性。此外，我们模型的减少的占用空间使其适用于低资源应用场景。",
    "tldr": "本文提出名称为AVLIT的轻量级迭代模型，采用渐进式学习在嘈杂环境中实现音视频语音的分离。实验证明该模型在两种情境下的音频分离和音视频基线方法相比具有优越性，同时其减小的模型大小使得其适用于低资源应用场景。",
    "en_tdlr": "This paper proposes a lightweight iterative model named AVLIT, which uses progressive learning to perform audio-visual speech separation in noisy environments. Experiments show that the model outperforms various baselines and is suitable for low resource applications due to its reduced footprint."
}