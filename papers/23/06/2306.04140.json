{
    "title": "Increasing Diversity While Maintaining Accuracy: Text Data Generation with Large Language Models and Human Interventions. (arXiv:2306.04140v1 [cs.CL])",
    "abstract": "Large language models (LLMs) can be used to generate text data for training and evaluating other models. However, creating high-quality datasets with LLMs can be challenging. In this work, we explore human-AI partnerships to facilitate high diversity and accuracy in LLM-based text data generation. We first examine two approaches to diversify text generation: 1) logit suppression, which minimizes the generation of languages that have already been frequently generated, and 2) temperature sampling, which flattens the token sampling probability. We found that diversification approaches can increase data diversity but often at the cost of data accuracy (i.e., text and labels being appropriate for the target domain). To address this issue, we examined two human interventions, 1) label replacement (LR), correcting misaligned labels, and 2) out-of-scope filtering (OOSF), removing instances that are out of the user's domain of interest or to which no considered label applies. With oracle studie",
    "link": "http://arxiv.org/abs/2306.04140",
    "context": "Title: Increasing Diversity While Maintaining Accuracy: Text Data Generation with Large Language Models and Human Interventions. (arXiv:2306.04140v1 [cs.CL])\nAbstract: Large language models (LLMs) can be used to generate text data for training and evaluating other models. However, creating high-quality datasets with LLMs can be challenging. In this work, we explore human-AI partnerships to facilitate high diversity and accuracy in LLM-based text data generation. We first examine two approaches to diversify text generation: 1) logit suppression, which minimizes the generation of languages that have already been frequently generated, and 2) temperature sampling, which flattens the token sampling probability. We found that diversification approaches can increase data diversity but often at the cost of data accuracy (i.e., text and labels being appropriate for the target domain). To address this issue, we examined two human interventions, 1) label replacement (LR), correcting misaligned labels, and 2) out-of-scope filtering (OOSF), removing instances that are out of the user's domain of interest or to which no considered label applies. With oracle studie",
    "path": "papers/23/06/2306.04140.json",
    "total_tokens": 1146,
    "translated_title": "在保持准确性的同时增加多样性：基于大语言模型和人工干扰的文本数据生成",
    "translated_abstract": "大语言模型（LLM）可用于生成用于训练和评估其他模型的文本数据。然而，使用LLM创建高质量数据集可能具有挑战性。在本研究中，我们探讨了人工智能合作以促进基于LLM的文本数据生成的高多样性和高准确性。我们首先研究了两种增加文本生成多样性的方法：1）logit抑制，减少已经生成频繁的语言的生成，和2）温度采样，平坦化令牌采样概率。我们发现多样化方法可以增加数据多样性，但往往以数据准确性（即文本和标签适用于目标领域）为代价。为解决这个问题，我们研究了两种人工干预方法：1）标签替换（LR），纠正错位的标签，和2）超出范围过滤（OOSF），删除超出用户兴趣范围或没有考虑标签适用的实例。通过oracle研究，我们发现将logit抑制与LR和OOSF结合起来能够产生最好的多样性-准确性权衡。我们还展示了一项用户研究，评估了人工智能数据生成管道的定性判断。我们的研究表明人工智能合作可以产生平衡多样性和准确性的高质量数据集。",
    "tldr": "本研究探讨了通过结合logit抑制、标签替换和超出范围过滤等人工干预方法和大型语言模型，生成高质量、高多样性的文本数据的解决方案，并通过用户研究验证了该方案的可行性。",
    "en_tdlr": "This work explores solutions for generating high-quality and diverse text data by combining large language models with human interventions such as logit suppression, label replacement, and out-of-scope filtering. The study finds that the combination of these interventions results in the highest diversity-accuracy trade-off and presents a user study to validate the feasibility of the solution."
}