{
    "title": "On information captured by neural networks: connections with memorization and generalization. (arXiv:2306.15918v1 [cs.LG])",
    "abstract": "Despite the popularity and success of deep learning, there is limited understanding of when, how, and why neural networks generalize to unseen examples. Since learning can be seen as extracting information from data, we formally study information captured by neural networks during training. Specifically, we start with viewing learning in presence of noisy labels from an information-theoretic perspective and derive a learning algorithm that limits label noise information in weights. We then define a notion of unique information that an individual sample provides to the training of a deep network, shedding some light on the behavior of neural networks on examples that are atypical, ambiguous, or belong to underrepresented subpopulations. We relate example informativeness to generalization by deriving nonvacuous generalization gap bounds. Finally, by studying knowledge distillation, we highlight the important role of data and label complexity in generalization. Overall, our findings contr",
    "link": "http://arxiv.org/abs/2306.15918",
    "context": "Title: On information captured by neural networks: connections with memorization and generalization. (arXiv:2306.15918v1 [cs.LG])\nAbstract: Despite the popularity and success of deep learning, there is limited understanding of when, how, and why neural networks generalize to unseen examples. Since learning can be seen as extracting information from data, we formally study information captured by neural networks during training. Specifically, we start with viewing learning in presence of noisy labels from an information-theoretic perspective and derive a learning algorithm that limits label noise information in weights. We then define a notion of unique information that an individual sample provides to the training of a deep network, shedding some light on the behavior of neural networks on examples that are atypical, ambiguous, or belong to underrepresented subpopulations. We relate example informativeness to generalization by deriving nonvacuous generalization gap bounds. Finally, by studying knowledge distillation, we highlight the important role of data and label complexity in generalization. Overall, our findings contr",
    "path": "papers/23/06/2306.15918.json",
    "total_tokens": 921,
    "translated_title": "关于神经网络所捕获的信息：与记忆和泛化的联系",
    "translated_abstract": "尽管深度学习很受欢迎并取得了成功，但对于神经网络何时、如何以及为什么能够泛化到未见示例的情况下，人们的理解仍然有限。因为学习可以被看作是从数据中提取信息，所以我们正式研究了神经网络在训练过程中捕获的信息。具体而言，我们从信息论的角度出发，从噪声标签的存在下观察学习，并导出了将标签噪声信息限制在权重中的学习算法。然后，我们定义了一个个体样本对深度网络训练提供的唯一信息的概念，为神经网络在非典型、模糊或属于少数子群体的示例上的行为提供了一些启示。我们通过导出非平凡的泛化差距界限，将示例信息性与泛化联系起来。最后，通过研究知识提取，我们强调了数据和标签复杂性在泛化中的重要作用。总的来说，我们的发现有助于理解神经网络的创新和贡献。",
    "tldr": "研究了神经网络在训练过程中捕获的信息，探讨了神经网络在特殊、模糊或少数子群体示例上的行为，在泛化中提供了重要的信息和理解。",
    "en_tdlr": "Explored the information captured by neural networks during training, investigating the behavior of neural networks on atypical, ambiguous, or underrepresented examples, providing important insights and understandings for generalization."
}