{
    "title": "ChatLaw: Open-Source Legal Large Language Model with Integrated External Knowledge Bases. (arXiv:2306.16092v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs) have shown the potential to revolutionize natural language processing tasks in various domains, sparking great interest in vertical-specific large models. However, unlike proprietary models such as BloombergGPT and FinGPT, which have leveraged their unique data accumulations to make strides in the finance domain, there hasn't not many similar large language models in the Chinese legal domain to facilitate its digital transformation.  In this paper, we propose an open-source legal large language model named ChatLaw. Due to the importance of data quality, we carefully designed a legal domain fine-tuning dataset. Additionally, to overcome the problem of model hallucinations in legal data screening during reference data retrieval, we introduce a method that combines vector database retrieval with keyword retrieval to effectively reduce the inaccuracy of relying solely on vector database retrieval. Furthermore, we propose a self-attention method to enhance the a",
    "link": "http://arxiv.org/abs/2306.16092",
    "context": "Title: ChatLaw: Open-Source Legal Large Language Model with Integrated External Knowledge Bases. (arXiv:2306.16092v1 [cs.CL])\nAbstract: Large Language Models (LLMs) have shown the potential to revolutionize natural language processing tasks in various domains, sparking great interest in vertical-specific large models. However, unlike proprietary models such as BloombergGPT and FinGPT, which have leveraged their unique data accumulations to make strides in the finance domain, there hasn't not many similar large language models in the Chinese legal domain to facilitate its digital transformation.  In this paper, we propose an open-source legal large language model named ChatLaw. Due to the importance of data quality, we carefully designed a legal domain fine-tuning dataset. Additionally, to overcome the problem of model hallucinations in legal data screening during reference data retrieval, we introduce a method that combines vector database retrieval with keyword retrieval to effectively reduce the inaccuracy of relying solely on vector database retrieval. Furthermore, we propose a self-attention method to enhance the a",
    "path": "papers/23/06/2306.16092.json",
    "total_tokens": 1005,
    "translated_title": "ChatLaw: 基于开源法律大型语言模型的综合外部知识库",
    "translated_abstract": "大型语言模型（LLM）已经展示出在各个领域中改变自然语言处理任务的潜力，引发了对垂直特定大模型的极大兴趣。然而，与像BloombergGPT和FinGPT这样利用其独特数据积累在金融领域取得进展的专有模型不同，中国法律领域中没有类似的大型语言模型来促进数字化转型。在本文中，我们提出了一个名为ChatLaw的开源法律大型语言模型。由于数据质量的重要性，我们精心设计了一个法律领域微调数据集。此外，为了解决在参考数据检索过程中法律数据筛选中的模型幻觉问题，我们引入了一种将向量数据库检索与关键词检索相结合的方法，以有效减少只依靠向量数据库检索的不准确性。此外，我们提出了一种自注意力方法来增强模型的对文本中关键信息的注意。",
    "tldr": "本论文介绍了一个基于开源的法律大型语言模型ChatLaw，它通过综合外部知识库为中国法律领域的数字化转型提供支持。该模型采用了精心设计的法律领域微调数据集，并通过将向量数据库检索与关键词检索相结合的方法解决了法律数据筛选中的模型幻觉问题。同时，引入了一种自注意力方法以增强对文本中关键信息的注意力。"
}