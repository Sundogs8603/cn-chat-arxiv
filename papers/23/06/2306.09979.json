{
    "title": "Evaluation of Speech Representations for MOS prediction. (arXiv:2306.09979v1 [cs.SD])",
    "abstract": "In this paper, we evaluate feature extraction models for predicting speech quality. We also propose a model architecture to compare embeddings of supervised learning and self-supervised learning models with embeddings of speaker verification models to predict the metric MOS. Our experiments were performed on the VCC2018 dataset and a Brazilian-Portuguese dataset called BRSpeechMOS, which was created for this work. The results show that the Whisper model is appropriate in all scenarios: with both the VCC2018 and BRSpeech- MOS datasets. Among the supervised and self-supervised learning models using BRSpeechMOS, Whisper-Small achieved the best linear correlation of 0.6980, and the speaker verification model, SpeakerNet, had linear correlation of 0.6963. Using VCC2018, the best supervised and self-supervised learning model, Whisper-Large, achieved linear correlation of 0.7274, and the best model speaker verification, TitaNet, achieved a linear correlation of 0.6933. Although the results of",
    "link": "http://arxiv.org/abs/2306.09979",
    "context": "Title: Evaluation of Speech Representations for MOS prediction. (arXiv:2306.09979v1 [cs.SD])\nAbstract: In this paper, we evaluate feature extraction models for predicting speech quality. We also propose a model architecture to compare embeddings of supervised learning and self-supervised learning models with embeddings of speaker verification models to predict the metric MOS. Our experiments were performed on the VCC2018 dataset and a Brazilian-Portuguese dataset called BRSpeechMOS, which was created for this work. The results show that the Whisper model is appropriate in all scenarios: with both the VCC2018 and BRSpeech- MOS datasets. Among the supervised and self-supervised learning models using BRSpeechMOS, Whisper-Small achieved the best linear correlation of 0.6980, and the speaker verification model, SpeakerNet, had linear correlation of 0.6963. Using VCC2018, the best supervised and self-supervised learning model, Whisper-Large, achieved linear correlation of 0.7274, and the best model speaker verification, TitaNet, achieved a linear correlation of 0.6933. Although the results of",
    "path": "papers/23/06/2306.09979.json",
    "total_tokens": 909,
    "translated_title": "评估语音表征对MOS预测的影响",
    "translated_abstract": "本文评估了用于预测语音质量的特征提取模型，并提出了一种模型结构来比较受监督和自监督学习模型的嵌入与说话人验证模型的嵌入来预测度量MOS。我们在VCC2018数据集和为这项工作创建的巴西葡萄牙语数据集BRSpeechMOS上进行了实验。结果显示Whisper模型在所有场景下都是合适的：使用VCC2018和BRSpeechMOS数据集。在使用BRSpeechMOS的受监督和自监督学习模型中，Whisper-Small获得了最佳的线性相关性0.6980，说话人验证模型SpeakerNet的线性相关性为0.6963。在使用VCC2018时，最佳的受监督和自监督学习模型Whisper-Large获得了0.7274的线性相关性，而最好的模型说话人验证模型TitaNet获得了0.6933的线性相关性。",
    "tldr": "本文评估了语音表征的特征提取模型，并提出了一种模型通过比较受监督和自监督学习模型的嵌入与说话人验证模型的嵌入来预测MOS，表明Whisper模型是最为合适的。",
    "en_tdlr": "This paper evaluates feature extraction models for predicting speech quality, proposes a model architecture comparing embeddings of supervised and self-supervised learning models with speaker verification models to predict MOS, and finds Whisper model to be the most suitable."
}