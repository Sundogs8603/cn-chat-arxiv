{
    "title": "MFCCGAN: A Novel MFCC-Based Speech Synthesizer Using Adversarial Learning. (arXiv:2306.12785v1 [cs.SD])",
    "abstract": "In this paper, we introduce MFCCGAN as a novel speech synthesizer based on adversarial learning that adopts MFCCs as input and generates raw speech waveforms. Benefiting the GAN model capabilities, it produces speech with higher intelligibility than a rule-based MFCC-based speech synthesizer WORLD. We evaluated the model based on a popular intrusive objective speech intelligibility measure (STOI) and quality (NISQA score). Experimental results show that our proposed system outperforms Librosa MFCC- inversion (by an increase of about 26% up to 53% in STOI and 16% up to 78% in NISQA score) and a rise of about 10% in intelligibility and about 4% in naturalness in comparison with conventional rule-based vocoder WORLD that used in the CycleGAN-VC family. However, WORLD needs additional data like F0. Finally, using perceptual loss in discriminators based on STOI could improve the quality more. WebMUSHRA-based subjective tests also show the quality of the proposed approach.",
    "link": "http://arxiv.org/abs/2306.12785",
    "context": "Title: MFCCGAN: A Novel MFCC-Based Speech Synthesizer Using Adversarial Learning. (arXiv:2306.12785v1 [cs.SD])\nAbstract: In this paper, we introduce MFCCGAN as a novel speech synthesizer based on adversarial learning that adopts MFCCs as input and generates raw speech waveforms. Benefiting the GAN model capabilities, it produces speech with higher intelligibility than a rule-based MFCC-based speech synthesizer WORLD. We evaluated the model based on a popular intrusive objective speech intelligibility measure (STOI) and quality (NISQA score). Experimental results show that our proposed system outperforms Librosa MFCC- inversion (by an increase of about 26% up to 53% in STOI and 16% up to 78% in NISQA score) and a rise of about 10% in intelligibility and about 4% in naturalness in comparison with conventional rule-based vocoder WORLD that used in the CycleGAN-VC family. However, WORLD needs additional data like F0. Finally, using perceptual loss in discriminators based on STOI could improve the quality more. WebMUSHRA-based subjective tests also show the quality of the proposed approach.",
    "path": "papers/23/06/2306.12785.json",
    "total_tokens": 969,
    "translated_title": "MFCCGAN：一种基于MFCC和对抗学习的语音合成器",
    "translated_abstract": "本文介绍了一种基于对抗学习的新型语音合成器MFCCGAN，采用MFCC作为输入并生成原始语音波形。受益于GAN模型的能力，它产生的语音比基于规则的MFCC的语音合成器WORLD具有更高的清晰度。我们根据流行的侵入式客观语音可懂度测量（STOI）和质量（NISQA得分）进行了模型评估。实验结果表明，我们提出的系统优于Librosa MFCC- inversion（在STOI和NISQA得分中增加了约26％至53％和16％至78％），与传统的基于规则的编码器WORLD相比，可辨度提高约10％，自然度提高约4％。然而，WORLD需要额外的F0数据。最后，对基于STOI的鉴别器使用感知损失可以进一步提高质量。基于WebMUSHRA的主观测试也显示了所提出方法的质量。",
    "tldr": "本文提出了一种采用对抗学习的新型语音合成器MFCCGAN，使用MFCC作为输入，产生比传统规则MFCC的WORLD语音合成器更高清晰度、更好理解度的语音。",
    "en_tdlr": "This paper introduces a novel speech synthesizer MFCCGAN using adversarial learning and MFCCs as input, producing speech with higher intelligibility than traditional rule-based synthesizer WORLD. It outperforms Librosa MFCC-inversion and shows improvement in intelligibility and naturalness compared with conventional vocoder WORLD used in CycleGAN-VC family. MFCCGAN also uses fewer additional data and improves quality further with perceptual loss in discriminators based on STOI."
}