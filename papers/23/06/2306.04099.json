{
    "title": "NTKCPL: Active Learning on Top of Self-Supervised Model by Estimating True Coverage. (arXiv:2306.04099v1 [cs.LG])",
    "abstract": "High annotation cost for training machine learning classifiers has driven extensive research in active learning and self-supervised learning. Recent research has shown that in the context of supervised learning different active learning strategies need to be applied at various stages of the training process to ensure improved performance over the random baseline. We refer to the point where the number of available annotations changes the suitable active learning strategy as the phase transition point. In this paper, we establish that when combining active learning with self-supervised models to achieve improved performance, the phase transition point occurs earlier. It becomes challenging to determine which strategy should be used for previously unseen datasets. We argue that existing active learning algorithms are heavily influenced by the phase transition because the empirical risk over the entire active learning pool estimated by these algorithms is inaccurate and influenced by the ",
    "link": "http://arxiv.org/abs/2306.04099",
    "context": "Title: NTKCPL: Active Learning on Top of Self-Supervised Model by Estimating True Coverage. (arXiv:2306.04099v1 [cs.LG])\nAbstract: High annotation cost for training machine learning classifiers has driven extensive research in active learning and self-supervised learning. Recent research has shown that in the context of supervised learning different active learning strategies need to be applied at various stages of the training process to ensure improved performance over the random baseline. We refer to the point where the number of available annotations changes the suitable active learning strategy as the phase transition point. In this paper, we establish that when combining active learning with self-supervised models to achieve improved performance, the phase transition point occurs earlier. It becomes challenging to determine which strategy should be used for previously unseen datasets. We argue that existing active learning algorithms are heavily influenced by the phase transition because the empirical risk over the entire active learning pool estimated by these algorithms is inaccurate and influenced by the ",
    "path": "papers/23/06/2306.04099.json",
    "total_tokens": 865,
    "tldr": "本文研究如何在自监督模型基础上进行主动学习，发现相变点会更早出现，这就导致了现有的算法难以应用于以前未见过的数据集。",
    "en_tdlr": "This paper investigates how to perform active learning on top of self-supervised models and finds that the phase transition point occurs earlier, which makes it challenging for existing algorithms to apply to previously unseen datasets."
}