{
    "title": "Taqyim: Evaluating Arabic NLP Tasks Using ChatGPT Models. (arXiv:2306.16322v1 [cs.CL])",
    "abstract": "Large language models (LLMs) have demonstrated impressive performance on various downstream tasks without requiring fine-tuning, including ChatGPT, a chat-based model built on top of LLMs such as GPT-3.5 and GPT-4. Despite having a lower training proportion compared to English, these models also exhibit remarkable capabilities in other languages. In this study, we assess the performance of GPT-3.5 and GPT-4 models on seven distinct Arabic NLP tasks: sentiment analysis, translation, transliteration, paraphrasing, part of speech tagging, summarization, and diacritization. Our findings reveal that GPT-4 outperforms GPT-3.5 on five out of the seven tasks. Furthermore, we conduct an extensive analysis of the sentiment analysis task, providing insights into how LLMs achieve exceptional results on a challenging dialectal dataset. Additionally, we introduce a new Python interface https://github.com/ARBML/Taqyim that facilitates the evaluation of these tasks effortlessly.",
    "link": "http://arxiv.org/abs/2306.16322",
    "context": "Title: Taqyim: Evaluating Arabic NLP Tasks Using ChatGPT Models. (arXiv:2306.16322v1 [cs.CL])\nAbstract: Large language models (LLMs) have demonstrated impressive performance on various downstream tasks without requiring fine-tuning, including ChatGPT, a chat-based model built on top of LLMs such as GPT-3.5 and GPT-4. Despite having a lower training proportion compared to English, these models also exhibit remarkable capabilities in other languages. In this study, we assess the performance of GPT-3.5 and GPT-4 models on seven distinct Arabic NLP tasks: sentiment analysis, translation, transliteration, paraphrasing, part of speech tagging, summarization, and diacritization. Our findings reveal that GPT-4 outperforms GPT-3.5 on five out of the seven tasks. Furthermore, we conduct an extensive analysis of the sentiment analysis task, providing insights into how LLMs achieve exceptional results on a challenging dialectal dataset. Additionally, we introduce a new Python interface https://github.com/ARBML/Taqyim that facilitates the evaluation of these tasks effortlessly.",
    "path": "papers/23/06/2306.16322.json",
    "total_tokens": 1058,
    "translated_title": "Taqyim: 使用ChatGPT模型评估阿拉伯语NLP任务",
    "translated_abstract": "大型语言模型（LLM）在各种下游任务上表现出令人印象深刻的性能，无需细调，并且包括ChatGPT，一种构建在诸如GPT-3.5和GPT-4等LLMs之上的聊天型模型。尽管与英语相比，这些模型的训练比例较低，但它们在其他语言中也展现出了出色的能力。在本研究中，我们评估了GPT-3.5和GPT-4模型在七个不同的阿拉伯语NLP任务上的性能：情感分析、翻译、音译、改写、词性标注、摘要提取和音素标注。我们的研究结果显示，GPT-4在这七个任务中有五个的表现优于GPT-3.5。此外，我们对情感分析任务进行了广泛分析，揭示了LLMs在具有挑战性的方言数据集上取得优异结果的原因。此外，我们还引入了一个新的Python接口https://github.com/ARBML/Taqyim，以便轻松评估这些任务。",
    "tldr": "该论文评估了GPT-3.5和GPT-4模型在七个阿拉伯语NLP任务上的性能，并发现GPT-4在五个任务上的表现优于GPT-3.5。研究还对挑战性的方言数据集上的情感分析任务进行了深入分析，提供了LLMs在该任务上取得卓越结果的见解。同时介绍了一个方便评估这些任务的新的Python接口。",
    "en_tdlr": "The paper evaluates the performance of GPT-3.5 and GPT-4 models on seven Arabic NLP tasks and finds that GPT-4 outperforms GPT-3.5 on five of them. The authors also conduct a detailed analysis of the sentiment analysis task on a challenging dialectal dataset, providing insights into the exceptional results achieved by LLMs. Additionally, a new Python interface for easy evaluation of these tasks is introduced."
}