{
    "title": "Learning from Pixels with Expert Observations. (arXiv:2306.13872v2 [cs.RO] CROSS LISTED)",
    "abstract": "In reinforcement learning (RL), sparse rewards can present a significant challenge. Fortunately, expert actions can be utilized to overcome this issue. However, acquiring explicit expert actions can be costly, and expert observations are often more readily available. This paper presents a new approach that uses expert observations for learning in robot manipulation tasks with sparse rewards from pixel observations. Specifically, our technique involves using expert observations as intermediate visual goals for a goal-conditioned RL agent, enabling it to complete a task by successively reaching a series of goals. We demonstrate the efficacy of our method in five challenging block construction tasks in simulation and show that when combined with two state-of-the-art agents, our approach can significantly improve their performance while requiring 4-20 times fewer expert actions during training. Moreover, our method is also superior to a hierarchical baseline.",
    "link": "http://arxiv.org/abs/2306.13872",
    "context": "Title: Learning from Pixels with Expert Observations. (arXiv:2306.13872v2 [cs.RO] CROSS LISTED)\nAbstract: In reinforcement learning (RL), sparse rewards can present a significant challenge. Fortunately, expert actions can be utilized to overcome this issue. However, acquiring explicit expert actions can be costly, and expert observations are often more readily available. This paper presents a new approach that uses expert observations for learning in robot manipulation tasks with sparse rewards from pixel observations. Specifically, our technique involves using expert observations as intermediate visual goals for a goal-conditioned RL agent, enabling it to complete a task by successively reaching a series of goals. We demonstrate the efficacy of our method in five challenging block construction tasks in simulation and show that when combined with two state-of-the-art agents, our approach can significantly improve their performance while requiring 4-20 times fewer expert actions during training. Moreover, our method is also superior to a hierarchical baseline.",
    "path": "papers/23/06/2306.13872.json",
    "total_tokens": 948,
    "translated_title": "使用专家观察数据进行像素学习",
    "translated_abstract": "在强化学习中，稀疏奖励可能是一个重要的挑战。幸运的是，可以利用专家行为来克服这个问题。然而，获取明确的专家行动可能是昂贵的，而专家观察数据通常更容易获得。本文提出了一种新的方法，利用专家观察数据在稀疏奖励的像素观测中进行机器人操作任务的学习。具体而言，我们的技术将专家观察数据作为目标条件的强化学习智能体的中间视觉目标，使其通过连续达到一系列目标来完成任务。我们在仿真中展示了我们方法在五个具有挑战性的块堆叠任务中的有效性，并且实验证明，当与两种最先进的智能体相结合时，我们的方法可以显著提高它们的性能，同时在训练过程中需要的专家行动次数减少了4-20倍。此外，我们的方法也优于一个分层的基线模型。",
    "tldr": "本文提出了一种使用专家观察数据的新方法，在像素观测中进行稀疏奖励的机器人操作任务学习。通过使用专家观察数据作为目标条件，该方法能显著改进两种最先进的智能体的性能，同时训练过程中所需的专家行动次数减少了4-20倍，并且优于分层基线模型。",
    "en_tdlr": "This paper presents a new approach that uses expert observations for learning in robot manipulation tasks with sparse rewards from pixel observations. By using expert observations as intermediate visual goals, this method significantly improves the performance of two state-of-the-art agents, reduces the number of expert actions required during training by 4-20 times, and outperforms a hierarchical baseline model."
}