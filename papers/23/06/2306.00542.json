{
    "title": "Nonparametric Identifiability of Causal Representations from Unknown Interventions. (arXiv:2306.00542v1 [stat.ML])",
    "abstract": "We study causal representation learning, the task of inferring latent causal variables and their causal relations from high-dimensional functions (\"mixtures\") of the variables. Prior work relies on weak supervision, in the form of counterfactual pre- and post-intervention views or temporal structure; places restrictive assumptions, such as linearity, on the mixing function or latent causal model; or requires partial knowledge of the generative process, such as the causal graph or the intervention targets. We instead consider the general setting in which both the causal model and the mixing function are nonparametric. The learning signal takes the form of multiple datasets, or environments, arising from unknown interventions in the underlying causal model. Our goal is to identify both the ground truth latents and their causal graph up to a set of ambiguities which we show to be irresolvable from interventional data. We study the fundamental setting of two causal variables and prove that",
    "link": "http://arxiv.org/abs/2306.00542",
    "context": "Title: Nonparametric Identifiability of Causal Representations from Unknown Interventions. (arXiv:2306.00542v1 [stat.ML])\nAbstract: We study causal representation learning, the task of inferring latent causal variables and their causal relations from high-dimensional functions (\"mixtures\") of the variables. Prior work relies on weak supervision, in the form of counterfactual pre- and post-intervention views or temporal structure; places restrictive assumptions, such as linearity, on the mixing function or latent causal model; or requires partial knowledge of the generative process, such as the causal graph or the intervention targets. We instead consider the general setting in which both the causal model and the mixing function are nonparametric. The learning signal takes the form of multiple datasets, or environments, arising from unknown interventions in the underlying causal model. Our goal is to identify both the ground truth latents and their causal graph up to a set of ambiguities which we show to be irresolvable from interventional data. We study the fundamental setting of two causal variables and prove that",
    "path": "papers/23/06/2306.00542.json",
    "total_tokens": 846,
    "translated_title": "未知干预的因果表达式的非参数识别",
    "translated_abstract": "我们研究因果表达式学习，即从变量的高维函数（“混合物”）中推断潜在的因果变量及其因果关系的任务。以前的工作依赖于弱监督，如反事实的干预观察或时间结构；对混合函数或潜在因果模型施加限制，如线性；或需要部分了解生成过程，如因果图或干预目标。我们考虑到因果模型和混合函数都是非参数的一般情况。学习信号采用来自基础因果模型中未知干预的多个数据集或环境的形式。我们的目标是将地面真实潜变量及其因果图鉴定出来，同时解决一组从干预数据无法消除的歧义问题。我们研究了两个因果变量的基本设置，并证明了...",
    "tldr": "本文提出了一种新方法用于从未知干预数据中推断非参数因果表达式学习，并且证明了在两个因果变量的基本设置中，无法消除一些由干预数据引起的歧义问题。"
}