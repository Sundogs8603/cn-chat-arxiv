{
    "title": "Enhancing naive classifier for positive unlabeled data based on logistic regression approach. (arXiv:2306.02798v1 [stat.ML])",
    "abstract": "We argue that for analysis of Positive Unlabeled (PU) data under Selected Completely At Random (SCAR) assumption it is fruitful to view the problem as fitting of misspecified model to the data. Namely, we show that the results on misspecified fit imply that in the case when posterior probability of the response is modelled by logistic regression, fitting the logistic regression to the observable PU data which {\\it does not} follow this model, still yields the vector of estimated parameters approximately colinear with the true vector of parameters. This observation together with choosing the intercept of the classifier based on optimisation of analogue of F1 measure yields a classifier which performs on par or better than its competitors on several real data sets considered.",
    "link": "http://arxiv.org/abs/2306.02798",
    "context": "Title: Enhancing naive classifier for positive unlabeled data based on logistic regression approach. (arXiv:2306.02798v1 [stat.ML])\nAbstract: We argue that for analysis of Positive Unlabeled (PU) data under Selected Completely At Random (SCAR) assumption it is fruitful to view the problem as fitting of misspecified model to the data. Namely, we show that the results on misspecified fit imply that in the case when posterior probability of the response is modelled by logistic regression, fitting the logistic regression to the observable PU data which {\\it does not} follow this model, still yields the vector of estimated parameters approximately colinear with the true vector of parameters. This observation together with choosing the intercept of the classifier based on optimisation of analogue of F1 measure yields a classifier which performs on par or better than its competitors on several real data sets considered.",
    "path": "papers/23/06/2306.02798.json",
    "total_tokens": 754,
    "translated_title": "基于逻辑回归方法增强正无标记数据的朴素分类器",
    "translated_abstract": "我们认为，在选择完全随机（SCAR）假设下分析正无标记（PU）数据时，将问题视为对数据拟合错误规范模型将是有益的。换句话说，我们展示了在拟合逻辑回归模型时，即使拟合的PU数据并不符合该模型，拟合结果也意味着得到的参数向量与真实参数向量近似共线。这一观察结果与基于类似于F1度量的优化选择分类器的截距相结合，可在几个实际数据集上获得与竞争对手相当或更好的结果。",
    "tldr": "通过基于逻辑回归方法的朴素分类器并优化选择分类器的截距，即使拟合的PU数据并不符合该模型，也能获得与竞争对手相当或更好的结果。",
    "en_tdlr": "By using a naive classifier based on logistic regression and optimizing the intercept of the classifier using an analogue of F1 measure, this paper shows that even when fitting PU data that does not follow the logistic regression model, the resulting estimated parameters are approximately colinear with the true parameters, leading to comparable or better performance than competitors on several real datasets."
}