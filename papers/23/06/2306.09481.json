{
    "title": "Leveraging Residue Number System for Designing High-Precision Analog Deep Neural Network Accelerators. (arXiv:2306.09481v1 [cs.AR])",
    "abstract": "Achieving high accuracy, while maintaining good energy efficiency, in analog DNN accelerators is challenging as high-precision data converters are expensive. In this paper, we overcome this challenge by using the residue number system (RNS) to compose high-precision operations from multiple low-precision operations. This enables us to eliminate the information loss caused by the limited precision of the ADCs. Our study shows that RNS can achieve 99% FP32 accuracy for state-of-the-art DNN inference using data converters with only $6$-bit precision. We propose using redundant RNS to achieve a fault-tolerant analog accelerator. In addition, we show that RNS can reduce the energy consumption of the data converters within an analog accelerator by several orders of magnitude compared to a regular fixed-point approach.",
    "link": "http://arxiv.org/abs/2306.09481",
    "context": "Title: Leveraging Residue Number System for Designing High-Precision Analog Deep Neural Network Accelerators. (arXiv:2306.09481v1 [cs.AR])\nAbstract: Achieving high accuracy, while maintaining good energy efficiency, in analog DNN accelerators is challenging as high-precision data converters are expensive. In this paper, we overcome this challenge by using the residue number system (RNS) to compose high-precision operations from multiple low-precision operations. This enables us to eliminate the information loss caused by the limited precision of the ADCs. Our study shows that RNS can achieve 99% FP32 accuracy for state-of-the-art DNN inference using data converters with only $6$-bit precision. We propose using redundant RNS to achieve a fault-tolerant analog accelerator. In addition, we show that RNS can reduce the energy consumption of the data converters within an analog accelerator by several orders of magnitude compared to a regular fixed-point approach.",
    "path": "papers/23/06/2306.09481.json",
    "total_tokens": 893,
    "translated_title": "基于余数系统设计高精度模拟深度神经网络加速器的研究",
    "translated_abstract": "模拟DNN加速器的高精度数据转换器成本高，同时要保持良好的能源效率和高准确性是具有挑战性的。本文利用余数系统（RNS）从多个低精度运算组成高精度运算，克服了这一挑战。这使我们能够消除由ADC有限精度引起的信息丢失。我们的研究表明，RNS可使用仅具有6比特精度的数据转换器来实现最新DNN推理的99％FP32准确度，并建议使用冗余的RNS来实现容错的模拟加速器。此外，我们还显示RNS相对于常规的定点方法，可以将模拟加速器中数据转换器的能耗降低数个数量级。",
    "tldr": "本文提出使用余数系统（RNS）来消除ADC有限精度带来的信息丢失，从多个低精度运算组成高精度运算，实现高准确性和良好能源效率的模拟DNN加速器，并建议使用冗余的RNS来实现容错性。同时RNS相对于常规定点方法能够将数据转换器的能耗降低数个数量级。",
    "en_tdlr": "This paper proposes using the residue number system (RNS) to eliminate information loss caused by the limited precision of ADCs in analog DNN accelerators, achieving high accuracy and good energy efficiency. The redundant RNS is suggested to achieve a fault-tolerant analog accelerator. Moreover, the energy consumption of the data converters can be reduced by several orders of magnitude compared to a regular fixed-point approach."
}