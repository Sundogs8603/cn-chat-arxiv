{
    "title": "Thompson sampling for improved exploration in GFlowNets. (arXiv:2306.17693v1 [cs.LG])",
    "abstract": "Generative flow networks (GFlowNets) are amortized variational inference algorithms that treat sampling from a distribution over compositional objects as a sequential decision-making problem with a learnable action policy. Unlike other algorithms for hierarchical sampling that optimize a variational bound, GFlowNet algorithms can stably run off-policy, which can be advantageous for discovering modes of the target distribution. Despite this flexibility in the choice of behaviour policy, the optimal way of efficiently selecting trajectories for training has not yet been systematically explored. In this paper, we view the choice of trajectories for training as an active learning problem and approach it using Bayesian techniques inspired by methods for multi-armed bandits. The proposed algorithm, Thompson sampling GFlowNets (TS-GFN), maintains an approximate posterior distribution over policies and samples trajectories from this posterior for training. We show in two domains that TS-GFN yi",
    "link": "http://arxiv.org/abs/2306.17693",
    "context": "Title: Thompson sampling for improved exploration in GFlowNets. (arXiv:2306.17693v1 [cs.LG])\nAbstract: Generative flow networks (GFlowNets) are amortized variational inference algorithms that treat sampling from a distribution over compositional objects as a sequential decision-making problem with a learnable action policy. Unlike other algorithms for hierarchical sampling that optimize a variational bound, GFlowNet algorithms can stably run off-policy, which can be advantageous for discovering modes of the target distribution. Despite this flexibility in the choice of behaviour policy, the optimal way of efficiently selecting trajectories for training has not yet been systematically explored. In this paper, we view the choice of trajectories for training as an active learning problem and approach it using Bayesian techniques inspired by methods for multi-armed bandits. The proposed algorithm, Thompson sampling GFlowNets (TS-GFN), maintains an approximate posterior distribution over policies and samples trajectories from this posterior for training. We show in two domains that TS-GFN yi",
    "path": "papers/23/06/2306.17693.json",
    "total_tokens": 868,
    "translated_title": "GFlowNets中的Thompson抽样用于改进探索",
    "translated_abstract": "生成流网络（GFlowNets）是一种用于组合对象分布采样的变分推理算法，将其视为可学习的动作策略的顺序决策问题。与其他优化变分界限的分层采样算法不同，GFlowNet算法可以稳定地进行离策略运行，这在发现目标分布的模式时有优势。尽管在行为策略的选择上存在灵活性，但目前还没有系统地探索有效选择轨迹进行训练的最佳方式。在本文中，我们将训练轨迹的选择视为主动学习问题，并使用受多臂老虎机方法启发的贝叶斯技术来处理。提出的算法Thompson采样GFlowNets（TS-GFN）通过维护策略的近似后验分布，并从该后验中采样轨迹进行训练。我们在两个领域的实验证明TS-GFN可以改进探索性能。",
    "tldr": "本文介绍了一种将生成流网络（GFlowNets）中的采样问题视为主动学习问题，并使用贝叶斯技术中的Thompson采样方法来解决的算法。实验结果表明该算法可以有效改进探索性能。"
}