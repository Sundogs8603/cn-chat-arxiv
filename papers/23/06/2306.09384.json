{
    "title": "MobileASR: A resource-aware on-device personalisation framework for automatic speech recognition in mobile phones. (arXiv:2306.09384v1 [eess.AS])",
    "abstract": "We describe a comprehensive methodology for developing user-voice personalised ASR models by effectively training models on mobile phones, allowing user data and models to be stored and used locally. To achieve this, we propose a resource-aware sub-model based training approach that considers the RAM, and battery capabilities of mobile phones. We also investigate the relationship between available resources and training time, highlighting the effectiveness of using sub-models in such scenarios. By taking into account the evaluation metric and battery constraints of the mobile phones, we are able to perform efficient training and halt the process accordingly. To simulate real users, we use speakers with various accents. The entire on-device training and evaluation framework was then tested on various mobile phones across brands. We show that fine-tuning the models and selecting the right hyperparameter values is a trade-off between the lowest achievable performance metric, on-device tra",
    "link": "http://arxiv.org/abs/2306.09384",
    "context": "Title: MobileASR: A resource-aware on-device personalisation framework for automatic speech recognition in mobile phones. (arXiv:2306.09384v1 [eess.AS])\nAbstract: We describe a comprehensive methodology for developing user-voice personalised ASR models by effectively training models on mobile phones, allowing user data and models to be stored and used locally. To achieve this, we propose a resource-aware sub-model based training approach that considers the RAM, and battery capabilities of mobile phones. We also investigate the relationship between available resources and training time, highlighting the effectiveness of using sub-models in such scenarios. By taking into account the evaluation metric and battery constraints of the mobile phones, we are able to perform efficient training and halt the process accordingly. To simulate real users, we use speakers with various accents. The entire on-device training and evaluation framework was then tested on various mobile phones across brands. We show that fine-tuning the models and selecting the right hyperparameter values is a trade-off between the lowest achievable performance metric, on-device tra",
    "path": "papers/23/06/2306.09384.json",
    "total_tokens": 935,
    "translated_title": "MobileASR: 一种面向移动电话的资源感知本地个性化自动语音识别框架",
    "translated_abstract": "本文提出了一种综合方法，通过在移动设备上进行有效的模型训练，使用户数据和模型在本地存储和使用，从而开发用户语音个性化的ASR模型。为实现这一目标，我们提出了一种资源感知的子模型训练方法，考虑了移动设备的RAM和电池容量，并探讨了可用资源与训练时间之间的关系，突出了在这种情况下使用子模型的有效性。通过考虑移动设备的评估指标和电池限制，我们能够进行有效的训练并相应地停止该过程。为了模拟真实用户，我们使用具有各种口音的发言者。然后，在各个品牌的各种移动设备上测试整个本地训练和评估框架。我们展示了微调模型和选择正确的超参数值是性能度量最低的可达到性和本地训练时间之间的权衡。",
    "tldr": "本文提出了一种资源感知的子模型训练方法，能够在移动设备上有效训练用户语音个性化的ASR模型，同时考虑了移动设备的评估指标和电池限制。在实验中发现，微调模型和选择超参数值需要在性能度量和本地训练时间之间进行权衡。",
    "en_tdlr": "This paper proposes a resource-aware sub-model training method that can effectively train user-voice personalized ASR models on mobile devices, while considering the evaluation metrics and battery constraints of the device. It is found in experiments that fine-tuning the model and selecting hyperparameter values require a trade-off between achievable performance metric and local training time."
}