{
    "title": "Zero and Few-shot Semantic Parsing with Ambiguous Inputs. (arXiv:2306.00824v2 [cs.CL] UPDATED)",
    "abstract": "Despite the frequent challenges posed by ambiguity when representing meaning via natural language, it is often ignored or deliberately removed in tasks mapping language to formally-designed representations, which generally assume a one-to-one mapping between linguistic and formal representations. We attempt to address this shortcoming by introducing AmP, a framework, dataset, and challenge for translating ambiguous natural language to formal representations like logic and code. We define templates and generate data for five well-documented linguistic ambiguities. Using AmP, we investigate how several few-shot text-to-code systems handle ambiguity, introducing three new metrics. We find that large pre-trained models perform poorly at capturing the distribution of possible meanings without deliberate instruction. However, models are able to capture the distribution well when ambiguity is attested in their inputs. These results motivate a call for including ambiguity explicitly in dataset",
    "link": "http://arxiv.org/abs/2306.00824",
    "context": "Title: Zero and Few-shot Semantic Parsing with Ambiguous Inputs. (arXiv:2306.00824v2 [cs.CL] UPDATED)\nAbstract: Despite the frequent challenges posed by ambiguity when representing meaning via natural language, it is often ignored or deliberately removed in tasks mapping language to formally-designed representations, which generally assume a one-to-one mapping between linguistic and formal representations. We attempt to address this shortcoming by introducing AmP, a framework, dataset, and challenge for translating ambiguous natural language to formal representations like logic and code. We define templates and generate data for five well-documented linguistic ambiguities. Using AmP, we investigate how several few-shot text-to-code systems handle ambiguity, introducing three new metrics. We find that large pre-trained models perform poorly at capturing the distribution of possible meanings without deliberate instruction. However, models are able to capture the distribution well when ambiguity is attested in their inputs. These results motivate a call for including ambiguity explicitly in dataset",
    "path": "papers/23/06/2306.00824.json",
    "total_tokens": 939,
    "translated_title": "具有模糊输入的零和少样本语义解析",
    "translated_abstract": "尽管用自然语言表示意思时常常会遇到模糊性的挑战，但在将语言映射到形式化设计的表示时，这种模糊性经常被忽略或故意删除，这些任务通常假设语言和形式化表示之间有一对一的映射。我们尝试通过引入 AmP，一个将模糊自然语言翻译成逻辑和代码等形式化表示的框架、数据集和挑战，来解决这个问题。我们定义了模板并生成了五个明确记录的语言模糊性的数据。使用 AmP，我们研究了几个零样本文本到代码系统如何处理模糊性，并引入了三个新的指标。我们发现，大型预训练模型在没有明确指示的情况下很难捕捉到可能意义的分布。然而，当输入中存在模糊性时，模型能够很好地捕捉到分布。这些结果呼吁在数据集中明确包含模糊性。",
    "tldr": "该论文提出了一个名为AmP的框架、数据集和挑战，用于将模糊自然语言翻译成形式化表示，如逻辑和代码。研究发现，大型预训练模型在没有明确指示的情况下难以捕捉到可能的意义分布，但当输入中存在模糊性时，模型能够很好地捕捉到分布。",
    "en_tdlr": "This paper introduces a framework, dataset, and challenge called AmP for translating ambiguous natural language to formal representations such as logic and code. The study finds that large pre-trained models struggle to capture the distribution of possible meanings without explicit instruction, but perform well when ambiguity is present in the inputs."
}