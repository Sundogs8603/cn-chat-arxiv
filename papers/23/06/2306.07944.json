{
    "title": "Speech-to-Text Adapter and Speech-to-Entity Retriever Augmented LLMs for Speech Understanding. (arXiv:2306.07944v1 [eess.AS])",
    "abstract": "Large Language Models (LLMs) have been applied in the speech domain, often incurring a performance drop due to misaligned between speech and language representations. To bridge this gap, we propose a joint speech and language model (SLM) using a Speech2Text adapter, which maps speech into text token embedding space without speech information loss. Additionally, using a CTC-based blank-filtering, we can reduce the speech sequence length to that of text. In speech MultiWoz dataset (DSTC11 challenge), SLM largely improves the dialog state tracking (DST) performance (24.7% to 28.4% accuracy). Further to address errors on rare entities, we augment SLM with a Speech2Entity retriever, which uses speech to retrieve relevant entities, and then adds them to the original SLM input as a prefix. With this retrieval-augmented SLM (ReSLM), the DST performance jumps to 34.6% accuracy. Moreover, augmenting the ASR task with the dialog understanding task improves the ASR performance from 9.4% to 8.5% WE",
    "link": "http://arxiv.org/abs/2306.07944",
    "context": "Title: Speech-to-Text Adapter and Speech-to-Entity Retriever Augmented LLMs for Speech Understanding. (arXiv:2306.07944v1 [eess.AS])\nAbstract: Large Language Models (LLMs) have been applied in the speech domain, often incurring a performance drop due to misaligned between speech and language representations. To bridge this gap, we propose a joint speech and language model (SLM) using a Speech2Text adapter, which maps speech into text token embedding space without speech information loss. Additionally, using a CTC-based blank-filtering, we can reduce the speech sequence length to that of text. In speech MultiWoz dataset (DSTC11 challenge), SLM largely improves the dialog state tracking (DST) performance (24.7% to 28.4% accuracy). Further to address errors on rare entities, we augment SLM with a Speech2Entity retriever, which uses speech to retrieve relevant entities, and then adds them to the original SLM input as a prefix. With this retrieval-augmented SLM (ReSLM), the DST performance jumps to 34.6% accuracy. Moreover, augmenting the ASR task with the dialog understanding task improves the ASR performance from 9.4% to 8.5% WE",
    "path": "papers/23/06/2306.07944.json",
    "total_tokens": 1136,
    "translated_title": "使用Speech2Text适配器和Speech2Entity检索增强LLM的语音理解模型",
    "translated_abstract": "大型语言模型（LLM）已应用于语音领域，但往往由于音频和语言表示不匹配而导致性能下降。为了弥补这一缺陷，本文提出了一种联合语音和语言模型（SLM），采用Speech2Text适配器将声音映射到文本嵌入式空间，避免声音信息丢失。此外，使用基于CTC的空白过滤器可以将语音序列长度缩短至文本长度。在DSTC11挑战赛的语音MultiWoz数据集中，SLM显着提高了对话状态跟踪（DST）性能（从24.7％提高到28.4％的准确率）。为了解决稀有实体的错误，我们采用Speech2Entity检索器增强SLM，该检索器使用语音检索相关实体，并将它们添加到原始SLM输入中作为前缀。使用这种检索-augmented SLM（ReSLM），DST的性能提高至34.6％的准确率。此外，以对话理解任务增强ASR任务可以将ASR性能从9.4％提高到8.5％的词错误率。",
    "tldr": "本文提出了一种联合语音和语言模型（SLM），将声音映射到文本嵌入式空间，使用基于CTC的空白过滤器来缩短语音序列长度。在语音MultiWoz数据集中，SLM提高了对话状态跟踪（DST）性能。为了解决稀有实体的错误，我们采用Speech2Entity检索器增强SLM。使用此检索-augmented SLM（ReSLM），DST性能得到进一步提高。该研究表明，增强ASR任务可以提高其性能。",
    "en_tdlr": "This paper proposes a joint speech and language model (SLM) that maps speech into text token embedding space and reduces speech sequence length using blank-filtering. SLM improves dialog state tracking (DST) performance on the speech MultiWoz dataset, and the proposed Speech2Entity retriever further enhances the model's performance on rare entities. Augmenting the ASR task with dialog understanding also improves its performance."
}