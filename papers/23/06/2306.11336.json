{
    "title": "Cooperative Multi-Agent Learning for Navigation via Structured State Abstraction",
    "abstract": "Cooperative multi-agent reinforcement learning (MARL) for navigation enables agents to cooperate to achieve their navigation goals. Using emergent communication, agents learn a communication protocol to coordinate and share information that is needed to achieve their navigation tasks. In emergent communication, symbols with no pre-specified usage rules are exchanged, in which the meaning and syntax emerge through training. Learning a navigation policy along with a communication protocol in a MARL environment is highly complex due to the huge state space to be explored. To cope with this complexity, this work proposes a novel neural network architecture, for jointly learning an adaptive state space abstraction and a communication protocol among agents participating in navigation tasks. The goal is to come up with an adaptive abstractor that significantly reduces the size of the state space to be explored, without degradation in the policy performance. Simulation results show that the pr",
    "link": "https://arxiv.org/abs/2306.11336",
    "context": "Title: Cooperative Multi-Agent Learning for Navigation via Structured State Abstraction\nAbstract: Cooperative multi-agent reinforcement learning (MARL) for navigation enables agents to cooperate to achieve their navigation goals. Using emergent communication, agents learn a communication protocol to coordinate and share information that is needed to achieve their navigation tasks. In emergent communication, symbols with no pre-specified usage rules are exchanged, in which the meaning and syntax emerge through training. Learning a navigation policy along with a communication protocol in a MARL environment is highly complex due to the huge state space to be explored. To cope with this complexity, this work proposes a novel neural network architecture, for jointly learning an adaptive state space abstraction and a communication protocol among agents participating in navigation tasks. The goal is to come up with an adaptive abstractor that significantly reduces the size of the state space to be explored, without degradation in the policy performance. Simulation results show that the pr",
    "path": "papers/23/06/2306.11336.json",
    "total_tokens": 935,
    "translated_title": "基于结构化状态抽象的协同多智能体导航学习",
    "translated_abstract": "协同多智能体强化学习（MARL）用于导航，使得智能体能够合作实现导航目标。通过应急通信，智能体学习协调和共享信息的通信协议以实现导航任务。在应急通信中，没有预先指定使用规则的符号被交换，其中的含义和语法通过训练逐渐形成。在MARL环境中同时学习导航策略和通信协议非常复杂，因为需要探索的状态空间非常庞大。为了应对这种复杂性，本研究提出了一种新颖的神经网络架构，用于联合学习参与导航任务的智能体之间的自适应状态空间抽象和通信协议。目标是设计一个自适应的抽象器，显著减少需要探索的状态空间的大小，同时保持策略性能不受影响。仿真结果表明，该方法能够提高导航性能并减少状态空间的探索。",
    "tldr": "本文提出了一种基于结构化状态抽象的协同多智能体导航学习方法，通过应急通信实现智能体之间的协作和信息共享，同时使用神经网络架构来学习自适应的状态空间抽象和通信协议。仿真结果表明，该方法能够显著减少状态空间的大小并提升导航性能。",
    "en_tdlr": "This paper proposes a cooperative multi-agent learning approach for navigation using structured state abstraction and emergent communication. It introduces a neural network architecture to jointly learn an adaptive state space abstraction and a communication protocol. The method significantly reduces the state space size while improving navigation performance."
}