{
    "title": "Expanding Explainability Horizons: A Unified Concept-Based System for Local, Global, and Misclassification Explanations. (arXiv:2306.03531v1 [cs.CV])",
    "abstract": "Explainability of intelligent models has been garnering increasing attention in recent years. Of the various explainability approaches, concept-based techniques are notable for utilizing a set of human-meaningful concepts instead of focusing on individual pixels. However, there is a scarcity of methods that consistently provide both local and global explanations. Moreover, most of the methods have no offer to explain misclassification cases. To address these challenges, our study follows a straightforward yet effective approach. We propose a unified concept-based system, which inputs a number of super-pixelated images into the networks, allowing them to learn better representations of the target's objects as well as the target's concepts. This method automatically learns, scores, and extracts local and global concepts. Our experiments revealed that, in addition to enhancing performance, the models could provide deeper insights into predictions and elucidate false classifications.",
    "link": "http://arxiv.org/abs/2306.03531",
    "context": "Title: Expanding Explainability Horizons: A Unified Concept-Based System for Local, Global, and Misclassification Explanations. (arXiv:2306.03531v1 [cs.CV])\nAbstract: Explainability of intelligent models has been garnering increasing attention in recent years. Of the various explainability approaches, concept-based techniques are notable for utilizing a set of human-meaningful concepts instead of focusing on individual pixels. However, there is a scarcity of methods that consistently provide both local and global explanations. Moreover, most of the methods have no offer to explain misclassification cases. To address these challenges, our study follows a straightforward yet effective approach. We propose a unified concept-based system, which inputs a number of super-pixelated images into the networks, allowing them to learn better representations of the target's objects as well as the target's concepts. This method automatically learns, scores, and extracts local and global concepts. Our experiments revealed that, in addition to enhancing performance, the models could provide deeper insights into predictions and elucidate false classifications.",
    "path": "papers/23/06/2306.03531.json",
    "total_tokens": 851,
    "translated_title": "拓展可解释性视野：一种统一的基于概念的系统用于局部、全局和错误分类解释。",
    "translated_abstract": "近年来，智能模型的可解释性越来越受到关注。在各种可解释性方法中，基于概念的技术以利用一组人类可理解的概念为特点，而不是关注于单个像素。然而，很少有方法能够同时提供局部和全局解释，并能解释错误分类情况。为了解决这些挑战，我们提出了一种简单而有效的方法。我们提出一个统一的基于概念的系统，将多个超像素图像输入网络中，使其能够更好地学习目标对象以及目标概念的表示。该方法可以自动学习、评分和提取局部和全局概念。我们的实验证明，除了提高性能外，该模型还可以深入了解预测，并阐明错误分类。",
    "tldr": "本文提出了一种新的统一的基于概念的系统，旨在解决当前基于概念的可解释性方法不足的局部、全局和错误分类解释问题，该系统可以自动学习、评分和提取局部和全局概念。",
    "en_tdlr": "This paper proposes a new unified concept-based system to address the limitation of local, global, and misclassification explanations in current concept-based explainability methods. The system can automatically learn, score, and extract local and global concepts."
}