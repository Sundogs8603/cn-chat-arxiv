{
    "title": "Adversarial-Aware Deep Learning System based on a Secondary Classical Machine Learning Verification Approach. (arXiv:2306.00314v1 [cs.CR])",
    "abstract": "Deep learning models have been used in creating various effective image classification applications. However, they are vulnerable to adversarial attacks that seek to misguide the models into predicting incorrect classes. Our study of major adversarial attack models shows that they all specifically target and exploit the neural networking structures in their designs. This understanding makes us develop a hypothesis that most classical machine learning models, such as Random Forest (RF), are immune to adversarial attack models because they do not rely on neural network design at all. Our experimental study of classical machine learning models against popular adversarial attacks supports this hypothesis. Based on this hypothesis, we propose a new adversarial-aware deep learning system by using a classical machine learning model as the secondary verification system to complement the primary deep learning model in image classification. Although the secondary classical machine learning model",
    "link": "http://arxiv.org/abs/2306.00314",
    "context": "Title: Adversarial-Aware Deep Learning System based on a Secondary Classical Machine Learning Verification Approach. (arXiv:2306.00314v1 [cs.CR])\nAbstract: Deep learning models have been used in creating various effective image classification applications. However, they are vulnerable to adversarial attacks that seek to misguide the models into predicting incorrect classes. Our study of major adversarial attack models shows that they all specifically target and exploit the neural networking structures in their designs. This understanding makes us develop a hypothesis that most classical machine learning models, such as Random Forest (RF), are immune to adversarial attack models because they do not rely on neural network design at all. Our experimental study of classical machine learning models against popular adversarial attacks supports this hypothesis. Based on this hypothesis, we propose a new adversarial-aware deep learning system by using a classical machine learning model as the secondary verification system to complement the primary deep learning model in image classification. Although the secondary classical machine learning model",
    "path": "papers/23/06/2306.00314.json",
    "total_tokens": 957,
    "translated_title": "基于第二类传统机器学习验证方法的对抗感知深度学习系统",
    "translated_abstract": "深度学习模型已经被用于创建各种有效的图像分类应用程序。然而，它们容易受到对抗攻击，这些攻击试图将模型引导到预测错误的类别。我们研究了主要的对抗攻击模型，发现它们都特别针对和利用其设计中的神经网络结构。这种理解使我们发展了一种假设，认为大多数传统机器学习模型，如随机森林(RF)，对抗攻击模型免疫，因为它们根本不依赖于神经网络设计。我们对受欢迎的对抗攻击进行的传统机器学习模型的实验研究支持了这一假设。基于这个假设，我们提出了一种新的对抗感知深度学习系统，通过使用传统机器学习模型作为辅助验证系统来补充图像分类中的主要深度学习模型。虽然第二个传统机器学习模型的准确率不如深度学习模型高，但它作为强有力的防御措施，对抗攻击的成功率高达97.32%。",
    "tldr": "传统机器学习模型可以作为深度学习模型的辅助验证系统，可以有效防御各种对抗攻击，成功率高达97.32%。",
    "en_tdlr": "Traditional machine learning models can serve as a secondary verification system for deep learning models to effectively defend against various adversarial attacks with a success rate of up to 97.32%."
}