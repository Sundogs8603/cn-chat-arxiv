{
    "title": "Beyond Probability Partitions: Calibrating Neural Networks with Semantic Aware Grouping. (arXiv:2306.04985v1 [cs.LG])",
    "abstract": "Research has shown that deep networks tend to be overly optimistic about their predictions, leading to an underestimation of prediction errors. Due to the limited nature of data, existing studies have proposed various methods based on model prediction probabilities to bin the data and evaluate calibration error. We propose a more generalized definition of calibration error called Partitioned Calibration Error (PCE), revealing that the key difference among these calibration error metrics lies in how the data space is partitioned. We put forth an intuitive proposition that an accurate model should be calibrated across any partition, suggesting that the input space partitioning can extend beyond just the partitioning of prediction probabilities, and include partitions directly related to the input. Through semantic-related partitioning functions, we demonstrate that the relationship between model accuracy and calibration lies in the granularity of the partitioning function. This highlight",
    "link": "http://arxiv.org/abs/2306.04985",
    "context": "Title: Beyond Probability Partitions: Calibrating Neural Networks with Semantic Aware Grouping. (arXiv:2306.04985v1 [cs.LG])\nAbstract: Research has shown that deep networks tend to be overly optimistic about their predictions, leading to an underestimation of prediction errors. Due to the limited nature of data, existing studies have proposed various methods based on model prediction probabilities to bin the data and evaluate calibration error. We propose a more generalized definition of calibration error called Partitioned Calibration Error (PCE), revealing that the key difference among these calibration error metrics lies in how the data space is partitioned. We put forth an intuitive proposition that an accurate model should be calibrated across any partition, suggesting that the input space partitioning can extend beyond just the partitioning of prediction probabilities, and include partitions directly related to the input. Through semantic-related partitioning functions, we demonstrate that the relationship between model accuracy and calibration lies in the granularity of the partitioning function. This highlight",
    "path": "papers/23/06/2306.04985.json",
    "total_tokens": 1291,
    "translated_title": "超越概率划分：语义感知分组校准神经网络",
    "translated_abstract": "研究表明，深度网络往往对其预测过于乐观，导致预测误差被低估。由于数据的有限性，现有研究已经提出了各种基于模型预测概率的方法来对数据进行分组并评估校准误差。本文提出了一种更加通用的校准误差定义，称为分区校准误差（PCE），揭示了这些校准误差指标之间的关键区别在于如何将数据空间划分。我们提出了一个直观的命题，即准确的模型应该在任何分区上都具有校准性，这表明输入空间分区可以扩展到不仅仅是预测概率分区，还可以包括与输入直接相关的分区。通过语义相关的分区函数，我们证明了模型准确性和校准之间的关系在于分区函数的粒度。",
    "tldr": "这篇论文提出了一种更为普适的校准误差定义——分区校准误差（PCE），指出了分区划分是各种校准误差指标之间的关键区别。作者提出了一个命题：准确的模型应该在任何分区上都具有校准性，而不仅仅是预测概率分区。通过语义相关的分区函数，作者证明了分区函数的粒度与模型准确性和校准之间的关系。"
}