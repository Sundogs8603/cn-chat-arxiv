{
    "title": "Youku-mPLUG: A 10 Million Large-scale Chinese Video-Language Dataset for Pre-training and Benchmarks. (arXiv:2306.04362v1 [cs.CV])",
    "abstract": "To promote the development of Vision-Language Pre-training (VLP) and multimodal Large Language Model (LLM) in the Chinese community, we firstly release the largest public Chinese high-quality video-language dataset named Youku-mPLUG, which is collected from Youku, a well-known Chinese video-sharing website, with strict criteria of safety, diversity, and quality. Youku-mPLUG contains 10 million Chinese video-text pairs filtered from 400 million raw videos across a wide range of 45 diverse categories for large-scale pre-training. In addition, to facilitate a comprehensive evaluation of video-language models, we carefully build the largest human-annotated Chinese benchmarks covering three popular video-language tasks of cross-modal retrieval, video captioning, and video category classification. Youku-mPLUG can enable researchers to conduct more in-depth multimodal research and develop better applications in the future. Furthermore, we release popular video-language pre-training models, AL",
    "link": "http://arxiv.org/abs/2306.04362",
    "context": "Title: Youku-mPLUG: A 10 Million Large-scale Chinese Video-Language Dataset for Pre-training and Benchmarks. (arXiv:2306.04362v1 [cs.CV])\nAbstract: To promote the development of Vision-Language Pre-training (VLP) and multimodal Large Language Model (LLM) in the Chinese community, we firstly release the largest public Chinese high-quality video-language dataset named Youku-mPLUG, which is collected from Youku, a well-known Chinese video-sharing website, with strict criteria of safety, diversity, and quality. Youku-mPLUG contains 10 million Chinese video-text pairs filtered from 400 million raw videos across a wide range of 45 diverse categories for large-scale pre-training. In addition, to facilitate a comprehensive evaluation of video-language models, we carefully build the largest human-annotated Chinese benchmarks covering three popular video-language tasks of cross-modal retrieval, video captioning, and video category classification. Youku-mPLUG can enable researchers to conduct more in-depth multimodal research and develop better applications in the future. Furthermore, we release popular video-language pre-training models, AL",
    "path": "papers/23/06/2306.04362.json",
    "total_tokens": 924,
    "translated_title": "Youku-mPLUG：一份1000万大规模的中文视频语言预训练数据集和基准",
    "translated_abstract": "为了促进中国社区中的视觉-语言预训练（VLP）和多模态大型语言模型（LLM）的发展，我们首先发布了最大的公共中文高质量视频语言数据集Youku-mPLUG。它从优酷中收集，具有严格的安全、多样性和质量标准。Youku-mPLUG包含1000万篇中文视频文本对，是从45种不同的类别中筛选出的400万个原始视频中提取出来的。此外，为了便于全面评估视频语言模型，我们认真构建了最大的人工注释中文基准，涵盖三个流行的视频语言任务：跨模态检索、视频字幕和视频分类。Youku-mPLUG可以使研究人员在未来进行更深入的多模态研究和开发更好的应用程序。此外，我们还发布了流行的视频语言预训练模型AL。",
    "tldr": "Youku-mPLUG为研究人员提供了一份10M的中文视频-文本对预训练数据集，覆盖45种不同的类别，并构建了最大的人工注释中文基准以涵盖三个流行的视频语言任务：跨模态检索、视频字幕和视频分类。",
    "en_tdlr": "Youku-mPLUG provides researchers with a 10 million large-scale Chinese video-text pairs pre-training dataset, covering 45 diverse categories, and builds the largest human-annotated Chinese benchmarks to cover three popular video-language tasks: cross-modal retrieval, video captioning, and video category classification."
}