{
    "title": "IERL: Interpretable Ensemble Representation Learning -- Combining CrowdSourced Knowledge and Distributed Semantic Representations. (arXiv:2306.13865v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs) encode meanings of words in the form of distributed semantics. Distributed semantics capture common statistical patterns among language tokens (words, phrases, and sentences) from large amounts of data. LLMs perform exceedingly well across General Language Understanding Evaluation (GLUE) tasks designed to test a model's understanding of the meanings of the input tokens. However, recent studies have shown that LLMs tend to generate unintended, inconsistent, or wrong texts as outputs when processing inputs that were seen rarely during training, or inputs that are associated with diverse contexts (e.g., well-known hallucination phenomenon in language generation tasks). Crowdsourced and expert-curated knowledge graphs such as ConceptNet are designed to capture the meaning of words from a compact set of well-defined contexts. Thus LLMs may benefit from leveraging such knowledge contexts to reduce inconsistencies in outputs. We propose a novel ensemble learning m",
    "link": "http://arxiv.org/abs/2306.13865",
    "context": "Title: IERL: Interpretable Ensemble Representation Learning -- Combining CrowdSourced Knowledge and Distributed Semantic Representations. (arXiv:2306.13865v1 [cs.CL])\nAbstract: Large Language Models (LLMs) encode meanings of words in the form of distributed semantics. Distributed semantics capture common statistical patterns among language tokens (words, phrases, and sentences) from large amounts of data. LLMs perform exceedingly well across General Language Understanding Evaluation (GLUE) tasks designed to test a model's understanding of the meanings of the input tokens. However, recent studies have shown that LLMs tend to generate unintended, inconsistent, or wrong texts as outputs when processing inputs that were seen rarely during training, or inputs that are associated with diverse contexts (e.g., well-known hallucination phenomenon in language generation tasks). Crowdsourced and expert-curated knowledge graphs such as ConceptNet are designed to capture the meaning of words from a compact set of well-defined contexts. Thus LLMs may benefit from leveraging such knowledge contexts to reduce inconsistencies in outputs. We propose a novel ensemble learning m",
    "path": "papers/23/06/2306.13865.json",
    "total_tokens": 902,
    "translated_title": "IERL: 可解释的集成表示学习--结合众包知识与分布式语义表示",
    "translated_abstract": "大型语言模型（LLMs）以分布式语义的形式编码单词的含义。分布式语义从大量数据中捕捉语言标记（单词、短语和句子）之间的共同统计模式。LLMs在用于测试模型对输入标记的含义理解的通用语言理解评估（GLUE）任务中表现卓越。然而，最近的研究表明，当处理很少在训练中出现过的输入，或与不同语境相关的输入（例如，在语言生成任务中出现的已知幻觉现象）时，LLMs往往会产生意外、不一致或错误的文本输出。众包和专家策划的知识图谱（如ConceptNet）旨在从一组紧密定义的上下文中捕捉单词的含义。因此，LLMs可以受益于利用这样的知识上下文来减少输出中的不一致性。我们提出了一种新颖的集成学习方法，将众包知识与LLMs的分布式语义表示相结合，以产生可解释的集成表示。",
    "tldr": "该论文提出了一种利用众包知识与分布式语义表示相结合的方法，以产生可解释的集成表示，从而减少语言模型产生不一致性输出的问题。"
}