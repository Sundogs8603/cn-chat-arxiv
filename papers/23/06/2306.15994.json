{
    "title": "Systematic analysis of the impact of label noise correction on ML Fairness. (arXiv:2306.15994v1 [cs.LG])",
    "abstract": "Arbitrary, inconsistent, or faulty decision-making raises serious concerns, and preventing unfair models is an increasingly important challenge in Machine Learning. Data often reflect past discriminatory behavior, and models trained on such data may reflect bias on sensitive attributes, such as gender, race, or age. One approach to developing fair models is to preprocess the training data to remove the underlying biases while preserving the relevant information, for example, by correcting biased labels. While multiple label noise correction methods are available, the information about their behavior in identifying discrimination is very limited. In this work, we develop an empirical methodology to systematically evaluate the effectiveness of label noise correction techniques in ensuring the fairness of models trained on biased datasets. Our methodology involves manipulating the amount of label noise and can be used with fairness benchmarks but also with standard ML datasets. We apply t",
    "link": "http://arxiv.org/abs/2306.15994",
    "context": "Title: Systematic analysis of the impact of label noise correction on ML Fairness. (arXiv:2306.15994v1 [cs.LG])\nAbstract: Arbitrary, inconsistent, or faulty decision-making raises serious concerns, and preventing unfair models is an increasingly important challenge in Machine Learning. Data often reflect past discriminatory behavior, and models trained on such data may reflect bias on sensitive attributes, such as gender, race, or age. One approach to developing fair models is to preprocess the training data to remove the underlying biases while preserving the relevant information, for example, by correcting biased labels. While multiple label noise correction methods are available, the information about their behavior in identifying discrimination is very limited. In this work, we develop an empirical methodology to systematically evaluate the effectiveness of label noise correction techniques in ensuring the fairness of models trained on biased datasets. Our methodology involves manipulating the amount of label noise and can be used with fairness benchmarks but also with standard ML datasets. We apply t",
    "path": "papers/23/06/2306.15994.json",
    "total_tokens": 912,
    "translated_title": "标签噪声修正对机器学习公平性影响的系统分析",
    "translated_abstract": "任意、不一致或错误的决策引发了严重关切，防止不公平模型是机器学习中一个日益重要的挑战。数据经常反映了过去的歧视行为，训练在此类数据上的模型可能反映了对敏感属性（如性别、种族、年龄）的偏见。开发公平模型的一种方法是对训练数据进行预处理，去除潜在的偏见并保留相关信息，例如通过纠正有偏见的标签。虽然有多种标签噪声修正方法可用，但对于它们在识别歧视方面的行为的信息非常有限。在本工作中，我们开发了一种经验方法来系统评估标签噪声修正技术在确保训练于有偏数据集上的模型公平性方面的有效性。我们的方法涉及操纵标签噪声的程度，可用于公平性基准测试以及标准机器学习数据集。我们应用了该方法来评估几种常见的标签噪声修正方法，并通过公平性评估指标评估这些修正方法的性能。",
    "tldr": "本论文对标签噪声修正技术在保证机器学习模型公平性方面的有效性进行了系统分析，通过开发经验方法来评估这些修正方法对修正有偏数据集上的模型的影响。",
    "en_tdlr": "This paper systematically analyzes the effectiveness of label noise correction techniques in ensuring the fairness of machine learning models trained on biased datasets. It develops an empirical methodology to evaluate these techniques and their impact on correcting biased models."
}