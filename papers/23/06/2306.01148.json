{
    "title": "Addressing Discrepancies in Semantic and Visual Alignment in Neural Networks. (arXiv:2306.01148v1 [cs.CV])",
    "abstract": "For the task of image classification, neural networks primarily rely on visual patterns. In robust networks, we would expect for visually similar classes to be represented similarly. We consider the problem of when semantically similar classes are visually dissimilar, and when visual similarity is present among non-similar classes. We propose a data augmentation technique with the goal of better aligning semantically similar classes with arbitrary (non-visual) semantic relationships. We leverage recent work in diffusion-based semantic mixing to generate semantic hybrids of two classes, and these hybrids are added to the training set as augmented data. We evaluate whether the method increases semantic alignment by evaluating model performance on adversarially perturbed data, with the idea that it should be easier for an adversary to switch one class to a similarly represented class. Results demonstrate that there is an increase in alignment of semantically similar classes when using our",
    "link": "http://arxiv.org/abs/2306.01148",
    "context": "Title: Addressing Discrepancies in Semantic and Visual Alignment in Neural Networks. (arXiv:2306.01148v1 [cs.CV])\nAbstract: For the task of image classification, neural networks primarily rely on visual patterns. In robust networks, we would expect for visually similar classes to be represented similarly. We consider the problem of when semantically similar classes are visually dissimilar, and when visual similarity is present among non-similar classes. We propose a data augmentation technique with the goal of better aligning semantically similar classes with arbitrary (non-visual) semantic relationships. We leverage recent work in diffusion-based semantic mixing to generate semantic hybrids of two classes, and these hybrids are added to the training set as augmented data. We evaluate whether the method increases semantic alignment by evaluating model performance on adversarially perturbed data, with the idea that it should be easier for an adversary to switch one class to a similarly represented class. Results demonstrate that there is an increase in alignment of semantically similar classes when using our",
    "path": "papers/23/06/2306.01148.json",
    "total_tokens": 851,
    "translated_title": "神经网络中语义和视觉对齐的差异问题解决方法研究",
    "translated_abstract": "在图像分类任务中，神经网络主要依赖视觉模式。在强健的网络中，我们期望视觉相似的类别具有相似的表示形式。本文考虑当语义类别相似而视觉类别不同，以及当视觉类别相似但语义类别不同的情况。我们提出一种数据增强技术，旨在更好地将语义类别与任意（非视觉）语义相关性对齐。我们利用最近的基于扩散的语义混合工作来生成两个类别的语义混合体，并将这些混合体作为增强数据添加到训练集中。我们评估该方法是否增加了语义对齐，通过在对抗扰动数据上评估模型性能，即一位攻击者可以更容易地将一个类别转换为相似表示的类别。结果表明，使用我们的方法会增加语义类别的对齐度。",
    "tldr": "本文提出了一种数据增强技术，通过语义混合实现了更好地将语义类别与非视觉语义相关性对齐，提高了神经网络中语义类别的对齐度。"
}