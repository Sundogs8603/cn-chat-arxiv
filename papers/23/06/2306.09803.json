{
    "title": "Framework and Benchmarks for Combinatorial and Mixed-variable Bayesian Optimization. (arXiv:2306.09803v1 [cs.LG])",
    "abstract": "This paper introduces a modular framework for Mixed-variable and Combinatorial Bayesian Optimization (MCBO) to address the lack of systematic benchmarking and standardized evaluation in the field. Current MCBO papers often introduce non-diverse or non-standard benchmarks to evaluate their methods, impeding the proper assessment of different MCBO primitives and their combinations. Additionally, papers introducing a solution for a single MCBO primitive often omit benchmarking against baselines that utilize the same methods for the remaining primitives. This omission is primarily due to the significant implementation overhead involved, resulting in a lack of controlled assessments and an inability to showcase the merits of a contribution effectively. To overcome these challenges, our proposed framework enables an effortless combination of Bayesian Optimization components, and provides a diverse set of synthetic and real-world benchmarking tasks. Leveraging this flexibility, we implement 4",
    "link": "http://arxiv.org/abs/2306.09803",
    "context": "Title: Framework and Benchmarks for Combinatorial and Mixed-variable Bayesian Optimization. (arXiv:2306.09803v1 [cs.LG])\nAbstract: This paper introduces a modular framework for Mixed-variable and Combinatorial Bayesian Optimization (MCBO) to address the lack of systematic benchmarking and standardized evaluation in the field. Current MCBO papers often introduce non-diverse or non-standard benchmarks to evaluate their methods, impeding the proper assessment of different MCBO primitives and their combinations. Additionally, papers introducing a solution for a single MCBO primitive often omit benchmarking against baselines that utilize the same methods for the remaining primitives. This omission is primarily due to the significant implementation overhead involved, resulting in a lack of controlled assessments and an inability to showcase the merits of a contribution effectively. To overcome these challenges, our proposed framework enables an effortless combination of Bayesian Optimization components, and provides a diverse set of synthetic and real-world benchmarking tasks. Leveraging this flexibility, we implement 4",
    "path": "papers/23/06/2306.09803.json",
    "total_tokens": 924,
    "translated_title": "组合和混合变量贝叶斯优化的框架和基准。 (arXiv:2306.09803v1 [cs.LG])",
    "translated_abstract": "本文介绍了一种模块化框架，用于混合变量和组合贝叶斯优化(MCBO)来解决领域中缺乏系统化基准和标准化评估的问题。目前的MCBO论文通常引入非多样性或非标准基准来评估其方法，阻碍了不同MCBO原语及其组合的正确评估。此外，介绍单个MCBO原语的论文通常省略了针对使用相同方法进行剩余原语的基线进行基准测试。这种省略主要是由于涉及的实现工作量非常大，导致缺乏控制评估并无法有效展示贡献的优点。为了克服这些挑战，我们提出的框架使贝叶斯优化组件的组合轻松易行，并提供了多样的合成和真实世界的基准测试任务。利用这种灵活性，我们实现了4种常见的MCBO技术，并在各种合成和真实基准测试中进行了评估。",
    "tldr": "本文介绍了一个模块化框架和基准，用于组合和混合变量贝叶斯优化，并提供多样的合成和真实世界基准测试。通过此框架，作者展示了4种常见的MCBO技术。"
}