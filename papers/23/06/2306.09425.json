{
    "title": "Arbitrariness Lies Beyond the Fairness-Accuracy Frontier. (arXiv:2306.09425v1 [cs.LG])",
    "abstract": "Machine learning tasks may admit multiple competing models that achieve similar performance yet produce conflicting outputs for individual samples -- a phenomenon known as predictive multiplicity. We demonstrate that fairness interventions in machine learning optimized solely for group fairness and accuracy can exacerbate predictive multiplicity. Consequently, state-of-the-art fairness interventions can mask high predictive multiplicity behind favorable group fairness and accuracy metrics. We argue that a third axis of ``arbitrariness'' should be considered when deploying models to aid decision-making in applications of individual-level impact. To address this challenge, we propose an ensemble algorithm applicable to any fairness intervention that provably ensures more consistent predictions.",
    "link": "http://arxiv.org/abs/2306.09425",
    "context": "Title: Arbitrariness Lies Beyond the Fairness-Accuracy Frontier. (arXiv:2306.09425v1 [cs.LG])\nAbstract: Machine learning tasks may admit multiple competing models that achieve similar performance yet produce conflicting outputs for individual samples -- a phenomenon known as predictive multiplicity. We demonstrate that fairness interventions in machine learning optimized solely for group fairness and accuracy can exacerbate predictive multiplicity. Consequently, state-of-the-art fairness interventions can mask high predictive multiplicity behind favorable group fairness and accuracy metrics. We argue that a third axis of ``arbitrariness'' should be considered when deploying models to aid decision-making in applications of individual-level impact. To address this challenge, we propose an ensemble algorithm applicable to any fairness intervention that provably ensures more consistent predictions.",
    "path": "papers/23/06/2306.09425.json",
    "total_tokens": 774,
    "translated_title": "公平性-准确性前沿之外存在任意性",
    "translated_abstract": "机器学习任务可能会有多个具有类似表现但产生不同输出的竞争模型，这被称为预测多样性。我们证明了仅针对组公平性和准确性进行优化的机器学习公平性干预可能会加剧预测多样性。因此，最先进的公平性干预可以掩盖高预测多样性背后的有利组公平性和准确性度量。我们认为，在部署模型以协助个体级影响应用程序时，应考虑第三个“任意性”轴。为了解决这一挑战，我们提出了一种适用于任何公平性干预的集成算法，可证明提供更一致的预测。",
    "tldr": "研究表明，仅考虑组公平性和准确性的机器学习公平性干预可能加剧预测多样性。因此，应考虑第三个“任意性”轴，提出了一种集成算法可提供更一致的预测。",
    "en_tdlr": "The study shows that fairness interventions in machine learning optimized solely for group fairness and accuracy can exacerbate predictive multiplicity. As a result, a third axis of \"arbitrariness\" should be considered when deploying models to aid decision-making, and an ensemble algorithm is proposed to provide more consistent predictions."
}