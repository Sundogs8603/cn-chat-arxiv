{
    "title": "Top-Down Network Combines Back-Propagation with Attention. (arXiv:2306.02415v2 [cs.AI] UPDATED)",
    "abstract": "Cortical processing, in vision and other domains, combines bottom-up (BU) with extensive top-down (TD) processing. Two primary goals attributed to TD processing are learning and directing attention. These two roles are accomplished in current network models through distinct mechanisms. Attention guidance is often implemented by extending the model's architecture, while learning is typically accomplished by an external learning algorithm such as back-propagation. In the current work, we present an integration of the two functions above, which appear unrelated, using a single unified mechanism inspired by the human brain. We propose a novel symmetric bottom-up top-down network structure that can integrate conventional bottom-up networks with a symmetric top-down counterpart, allowing each network to recurrently guide and influence the other. For example, during multi-task learning, the same top-down network is being used for both learning, via propagating feedback signals, and at the sam",
    "link": "http://arxiv.org/abs/2306.02415",
    "context": "Title: Top-Down Network Combines Back-Propagation with Attention. (arXiv:2306.02415v2 [cs.AI] UPDATED)\nAbstract: Cortical processing, in vision and other domains, combines bottom-up (BU) with extensive top-down (TD) processing. Two primary goals attributed to TD processing are learning and directing attention. These two roles are accomplished in current network models through distinct mechanisms. Attention guidance is often implemented by extending the model's architecture, while learning is typically accomplished by an external learning algorithm such as back-propagation. In the current work, we present an integration of the two functions above, which appear unrelated, using a single unified mechanism inspired by the human brain. We propose a novel symmetric bottom-up top-down network structure that can integrate conventional bottom-up networks with a symmetric top-down counterpart, allowing each network to recurrently guide and influence the other. For example, during multi-task learning, the same top-down network is being used for both learning, via propagating feedback signals, and at the sam",
    "path": "papers/23/06/2306.02415.json",
    "total_tokens": 815,
    "translated_title": "自顶向下网络将反向传播与注意力相结合",
    "translated_abstract": "大脑在视觉和其他领域中的皮层处理将自下而上的处理与广泛的自顶向下处理相结合。自顶向下处理的两个主要目标是学习和引导注意力。目前的网络模型通过不同的机制实现这两个作用。注意力引导通常通过扩展模型的结构来实现，而学习通常通过外部学习算法（如反向传播）来实现。在这项工作中，我们提出了一个综合上述两个看似无关的功能的方法，该方法受人脑启发。我们提出了一种新颖的对称自下而上自顶向下网络结构，可以将传统的自下而上网络与对称的自顶向下网络结合起来，使每个网络可以互相循环地引导和影响对方。例如，在多任务学习中，同一个自顶向下网络被用于学习和通过传递反馈信号进行引导。",
    "tldr": "本研究提出了一种新颖的自顶向下网络结构，将反向传播和注意力相结合，使网络能够同时进行学习和引导注意力。",
    "en_tdlr": "This study proposes a novel top-down network structure that combines back-propagation with attention, allowing the network to simultaneously learn and direct attention."
}