{
    "title": "Fusing Multimodal Signals on Hyper-complex Space for Extreme Abstractive Text Summarization (TL;DR) of Scientific Contents. (arXiv:2306.13968v1 [cs.CL])",
    "abstract": "The realm of scientific text summarization has experienced remarkable progress due to the availability of annotated brief summaries and ample data. However, the utilization of multiple input modalities, such as videos and audio, has yet to be thoroughly explored. At present, scientific multimodal-input-based text summarization systems tend to employ longer target summaries like abstracts, leading to an underwhelming performance in the task of text summarization.  In this paper, we deal with a novel task of extreme abstractive text summarization (aka TL;DR generation) by leveraging multiple input modalities. To this end, we introduce mTLDR, a first-of-its-kind dataset for the aforementioned task, comprising videos, audio, and text, along with both author-composed summaries and expert-annotated summaries. The mTLDR dataset accompanies a total of 4,182 instances collected from various academic conference proceedings, such as ICLR, ACL, and CVPR. Subsequently, we present mTLDRgen, an encod",
    "link": "http://arxiv.org/abs/2306.13968",
    "context": "Title: Fusing Multimodal Signals on Hyper-complex Space for Extreme Abstractive Text Summarization (TL;DR) of Scientific Contents. (arXiv:2306.13968v1 [cs.CL])\nAbstract: The realm of scientific text summarization has experienced remarkable progress due to the availability of annotated brief summaries and ample data. However, the utilization of multiple input modalities, such as videos and audio, has yet to be thoroughly explored. At present, scientific multimodal-input-based text summarization systems tend to employ longer target summaries like abstracts, leading to an underwhelming performance in the task of text summarization.  In this paper, we deal with a novel task of extreme abstractive text summarization (aka TL;DR generation) by leveraging multiple input modalities. To this end, we introduce mTLDR, a first-of-its-kind dataset for the aforementioned task, comprising videos, audio, and text, along with both author-composed summaries and expert-annotated summaries. The mTLDR dataset accompanies a total of 4,182 instances collected from various academic conference proceedings, such as ICLR, ACL, and CVPR. Subsequently, we present mTLDRgen, an encod",
    "path": "papers/23/06/2306.13968.json",
    "total_tokens": 1042,
    "translated_title": "利用超复空间上融合多模态信号进行极端抽象文本摘要",
    "translated_abstract": "在已有注释摘要和丰富数据的基础上，科学文本摘要领域已经取得了显著的进展。然而，多个输入模态（例如视频和音频）的利用尚未得到彻底探索。目前，科学多模态输入的文本摘要系统往往采用较长的目标摘要，如摘要，在文本摘要任务中表现不佳。在本文中，我们通过利用多个输入模态来处理极端抽象文本摘要（即TL;DR生成）的新任务。为此，我们介绍了mTLDR，这是一个首创的数据集，包括视频、音频和文本，以及作者撰写的摘要和专家注释的摘要。mTLDR数据集搜集了来自不同学术会议记录总共4182个实例，如ICLR、ACL和CVPR。随后，我们提出了mTLDRgen，这是一种适用于超复杂空间上极端抽象摘要的编码解码深度神经网络架构。我们在mTLDR数据集上获得了显著的结果，并报告了首个成功实施TL;DR生成的多模态系统的结果。",
    "tldr": "本文介绍了mTLDR数据集，这是一个多模态数据集，利用超复空间上融合多模态信号进行极端抽象文本摘要的任务。mTLDRgen模型成功实现了TL;DR生成的多模态系统。",
    "en_tdlr": "This paper introduces mTLDR, a multi-modal dataset for extreme abstractive text summarization that leverages hyper-complex space fusion of multiple input modalities. The mTLDRgen model achieved impressive results, making it the first successful implementation of a multimodal system for TL;DR generation."
}