{
    "title": "Robot Learning with Sensorimotor Pre-training. (arXiv:2306.10007v1 [cs.RO])",
    "abstract": "We present a self-supervised sensorimotor pre-training approach for robotics. Our model, called RPT, is a Transformer that operates on sequences of sensorimotor tokens. Given a sequence of camera images, proprioceptive robot states, and past actions, we encode the interleaved sequence into tokens, mask out a random subset, and train a model to predict the masked-out content. We hypothesize that if the robot can predict the missing content it has acquired a good model of the physical world that can enable it to act. RPT is designed to operate on latent visual representations which makes prediction tractable, enables scaling to 10x larger models, and 10 Hz inference on a real robot. To evaluate our approach, we collect a dataset of 20,000 real-world trajectories over 9 months using a combination of motion planning and model-based grasping algorithms. We find that pre-training on this data consistently outperforms training from scratch, leads to 2x improvements in the block stacking task,",
    "link": "http://arxiv.org/abs/2306.10007",
    "context": "Title: Robot Learning with Sensorimotor Pre-training. (arXiv:2306.10007v1 [cs.RO])\nAbstract: We present a self-supervised sensorimotor pre-training approach for robotics. Our model, called RPT, is a Transformer that operates on sequences of sensorimotor tokens. Given a sequence of camera images, proprioceptive robot states, and past actions, we encode the interleaved sequence into tokens, mask out a random subset, and train a model to predict the masked-out content. We hypothesize that if the robot can predict the missing content it has acquired a good model of the physical world that can enable it to act. RPT is designed to operate on latent visual representations which makes prediction tractable, enables scaling to 10x larger models, and 10 Hz inference on a real robot. To evaluate our approach, we collect a dataset of 20,000 real-world trajectories over 9 months using a combination of motion planning and model-based grasping algorithms. We find that pre-training on this data consistently outperforms training from scratch, leads to 2x improvements in the block stacking task,",
    "path": "papers/23/06/2306.10007.json",
    "total_tokens": 1039,
    "translated_title": "具有感觉运动预训练的机器人学习",
    "translated_abstract": "我们提出了一种自监督的感觉运动预训练方法，用于机器人学习。我们的模型称为 RPT，是一种 Transformer，它对感觉运动令牌序列进行操作。给定一系列相机图像、本体感觉机器人状态和过去的动作，我们将交错的序列编码为令牌，掩模出随机子集，并训练模型来预测掩模的内容。我们假设如果机器人能够预测缺失的内容，它已经获得了一个可以使其行动的物理世界的良好模型。RPT 的设计是在潜在的视觉表示上进行操作，从而使预测变得可行，能够实现 10 倍的模型扩展，并能在实际机器人上进行每秒 10 次的推理。为了评估我们的方法，我们使用运动规划和基于模型的抓取算法，收集了 9 个月内的 20,000 条真实世界轨迹数据集。我们发现，对这些数据进行预训练始终优于从头开始训练，在堆积方块任务中导致 2 倍的性能提高，并使机器人能够更快地学习新任务。",
    "tldr": "本论文介绍了一种针对机器人学习的自监督感觉运动预训练方法，使用 Transformer 模型在视觉表示上进行操作，通过 20,000 条真实世界轨迹数据集的预训练可以使机器人在堆积方块任务中性能提高 2 倍，并使其能够更快地学习新任务。",
    "en_tdlr": "This paper presents a self-supervised sensorimotor pre-training approach for robotics using a Transformer model that operates on latent visual representations. Pre-training on a dataset of 20,000 real-world trajectories leads to 2x improvements in the block stacking task and enables the robot to learn new tasks much faster."
}