{
    "title": "Investigating Poor Performance Regions of Black Boxes: LIME-based Exploration in Sepsis Detection. (arXiv:2306.12507v1 [cs.LG])",
    "abstract": "Interpreting machine learning models remains a challenge, hindering their adoption in clinical settings. This paper proposes leveraging Local Interpretable Model-Agnostic Explanations (LIME) to provide interpretable descriptions of black box classification models in high-stakes sepsis detection. By analyzing misclassified instances, significant features contributing to suboptimal performance are identified. The analysis reveals regions where the classifier performs poorly, allowing the calculation of error rates within these regions. This knowledge is crucial for cautious decision-making in sepsis detection and other critical applications. The proposed approach is demonstrated using the eICU dataset, effectively identifying and visualizing regions where the classifier underperforms. By enhancing interpretability, our method promotes the adoption of machine learning models in clinical practice, empowering informed decision-making and mitigating risks in critical scenarios.",
    "link": "http://arxiv.org/abs/2306.12507",
    "context": "Title: Investigating Poor Performance Regions of Black Boxes: LIME-based Exploration in Sepsis Detection. (arXiv:2306.12507v1 [cs.LG])\nAbstract: Interpreting machine learning models remains a challenge, hindering their adoption in clinical settings. This paper proposes leveraging Local Interpretable Model-Agnostic Explanations (LIME) to provide interpretable descriptions of black box classification models in high-stakes sepsis detection. By analyzing misclassified instances, significant features contributing to suboptimal performance are identified. The analysis reveals regions where the classifier performs poorly, allowing the calculation of error rates within these regions. This knowledge is crucial for cautious decision-making in sepsis detection and other critical applications. The proposed approach is demonstrated using the eICU dataset, effectively identifying and visualizing regions where the classifier underperforms. By enhancing interpretability, our method promotes the adoption of machine learning models in clinical practice, empowering informed decision-making and mitigating risks in critical scenarios.",
    "path": "papers/23/06/2306.12507.json",
    "total_tokens": 1027,
    "translated_title": "基于LIME的探索方法研究黑匣子的性能不佳区域：以败血症检测为例",
    "translated_abstract": "解释机器学习模型仍然是一个挑战，阻碍了它们在临床环境中的应用。本文提出利用局部可解释的模型不可知解释（LIME）来提供解释性地描述高风险败血症检测黑盒分类模型。通过分析被错误分类的实例，识别贡献于次优性能的重要特征。分析揭示出分类器性能不佳的区域，从而计算出这些区域内的错误率，这对于在败血症检测等关键应用场景下进行谨慎决策至关重要。本文使用eICU数据集展示了所提出方法的有效性，能够识别和可视化分类器性能不佳的区域。通过增强可解释性，我们的方法促进了机器学习模型在临床实践中的应用，实现了明智的决策，并在关键时刻降低风险。",
    "tldr": "本文提出了一种利用LIME方法探索黑盒分类模型不佳性能区域的方法，并应用于高风险的败血症检测中。通过分析错误分类实例，确定造成模型性能差的重要特征，并识别出分类器性能不佳的区域，并计算出其错误率，这对于实现谨慎的决策具有重要意义，同时增强了机器学习模型在临床实践中的可解释性，降低关键应用场景下的风险。",
    "en_tdlr": "This paper proposes a LIME-based method for exploring poor performance regions of black box models, and applies it to high-stakes sepsis detection. By analyzing misclassified instances, significant features contributing to suboptimal performance are identified, and regions where the classifier performs poorly are visualized and their error rates calculated. The method enhances interpretability and promotes adoption of machine learning models in clinical practice for informed decision-making and risk mitigation."
}