{
    "title": "Large Language Models as Annotators: Enhancing Generalization of NLP Models at Minimal Cost. (arXiv:2306.15766v1 [cs.CL])",
    "abstract": "State-of-the-art supervised NLP models achieve high accuracy but are also susceptible to failures on inputs from low-data regimes, such as domains that are not represented in training data. As an approximation to collecting ground-truth labels for the specific domain, we study the use of large language models (LLMs) for annotating inputs and improving the generalization of NLP models. Specifically, given a budget for LLM annotations, we present an algorithm for sampling the most informative inputs to annotate and retrain the NLP model. We find that popular active learning strategies such as uncertainty-based sampling do not work well. Instead, we propose a sampling strategy based on the difference in prediction scores between the base model and the finetuned NLP model, utilizing the fact that most NLP models are finetuned from a base model. Experiments with classification (semantic similarity) and ranking (semantic search) tasks show that our sampling strategy leads to significant gain",
    "link": "http://arxiv.org/abs/2306.15766",
    "context": "Title: Large Language Models as Annotators: Enhancing Generalization of NLP Models at Minimal Cost. (arXiv:2306.15766v1 [cs.CL])\nAbstract: State-of-the-art supervised NLP models achieve high accuracy but are also susceptible to failures on inputs from low-data regimes, such as domains that are not represented in training data. As an approximation to collecting ground-truth labels for the specific domain, we study the use of large language models (LLMs) for annotating inputs and improving the generalization of NLP models. Specifically, given a budget for LLM annotations, we present an algorithm for sampling the most informative inputs to annotate and retrain the NLP model. We find that popular active learning strategies such as uncertainty-based sampling do not work well. Instead, we propose a sampling strategy based on the difference in prediction scores between the base model and the finetuned NLP model, utilizing the fact that most NLP models are finetuned from a base model. Experiments with classification (semantic similarity) and ranking (semantic search) tasks show that our sampling strategy leads to significant gain",
    "path": "papers/23/06/2306.15766.json",
    "total_tokens": 933,
    "translated_title": "大型语言模型作为标注者：以最小成本增强NLP模型的泛化能力",
    "translated_abstract": "最先进的监督式NLP模型能够达到很高的准确度，但对于低数据领域的输入也容易出现失败，例如训练数据中未包含的领域。作为收集特定领域的真实标签的近似方法，我们研究了使用大型语言模型(LLM)对输入进行标注并提升NLP模型的泛化能力。具体而言，给定LLM标注的预算，我们提出了一种算法来选择最具信息量的输入进行标注和重新训练NLP模型。我们发现流行的基于不确定性采样的主动学习策略效果不佳。相反，我们提出了一种基于基础模型和微调NLP模型之间预测分数差异的采样策略，利用了大多数NLP模型都是从基础模型微调而来的事实。分类(语义相似度)和排序(语义搜索)任务的实验证明我们的采样策略带来了显著的收益。",
    "tldr": "本研究提出了一种利用大型语言模型进行标注的方法，以最小成本提升NLP模型的泛化能力。通过差异性采样策略，我们证明了这种方法在分类和排序任务上能够显著改善模型效果。",
    "en_tdlr": "This study proposes a method of using large language models for annotation to enhance the generalization of NLP models at minimal cost. By utilizing a sampling strategy based on prediction score differences, the approach significantly improves the performance of the models in classification and ranking tasks."
}