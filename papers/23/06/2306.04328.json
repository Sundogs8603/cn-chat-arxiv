{
    "title": "IUTEAM1 at MEDIQA-Chat 2023: Is simple fine tuning effective for multilayer summarization of clinical conversations?. (arXiv:2306.04328v1 [cs.CL])",
    "abstract": "Clinical conversation summarization has become an important application of Natural language Processing. In this work, we intend to analyze summarization model ensembling approaches, that can be utilized to improve the overall accuracy of the generated medical report called chart note. The work starts with a single summarization model creating the baseline. Then leads to an ensemble of summarization models trained on a separate section of the chart note. This leads to the final approach of passing the generated results to another summarization model in a multi-layer/stage fashion for better coherency of the generated text. Our results indicate that although an ensemble of models specialized in each section produces better results, the multi-layer/stage approach does not improve accuracy. The code for the above paper is available at https://github.com/dhananjay-srivastava/MEDIQA-Chat-2023-iuteam1.git",
    "link": "http://arxiv.org/abs/2306.04328",
    "context": "Title: IUTEAM1 at MEDIQA-Chat 2023: Is simple fine tuning effective for multilayer summarization of clinical conversations?. (arXiv:2306.04328v1 [cs.CL])\nAbstract: Clinical conversation summarization has become an important application of Natural language Processing. In this work, we intend to analyze summarization model ensembling approaches, that can be utilized to improve the overall accuracy of the generated medical report called chart note. The work starts with a single summarization model creating the baseline. Then leads to an ensemble of summarization models trained on a separate section of the chart note. This leads to the final approach of passing the generated results to another summarization model in a multi-layer/stage fashion for better coherency of the generated text. Our results indicate that although an ensemble of models specialized in each section produces better results, the multi-layer/stage approach does not improve accuracy. The code for the above paper is available at https://github.com/dhananjay-srivastava/MEDIQA-Chat-2023-iuteam1.git",
    "path": "papers/23/06/2306.04328.json",
    "total_tokens": 824,
    "translated_title": "IUTEAM1在MEDIQA-Chat 2023比赛中：简单微调对临床对话的多层次摘要有效吗？",
    "translated_abstract": "临床对话的摘要已经成为自然语言处理领域的一个重要应用。本文旨在分析摘要模型集成方法，以提高生成的医学报告“病历摘要”的整体准确性。研究从单个的摘要模型创建基线开始，然后导致许多针对病历摘要的模型集成，最终采用多层/阶段方式将生成的结果传递给另一个摘要模型，以获得更好的生成文本连贯性。我们的结果表明，虽然每个部分专用的摘要模型集成会产生更好的结果，但多层/阶段方法并不会改善准确性。",
    "tldr": "本文研究了临床对话的多层次摘要方法，发现针对每个部分使用单独摘要模型的集成方法可以提高准确性，但是多层/阶段方法并不会改善准确性。",
    "en_tdlr": "This article investigates multi-layer summarization methods for clinical conversations and finds that utilizing ensembles of separately trained summarization models for each section can improve accuracy, but multi-layer/stage approaches do not improve accuracy."
}