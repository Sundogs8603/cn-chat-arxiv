{
    "title": "Information-Computation Tradeoffs for Learning Margin Halfspaces with Random Classification Noise. (arXiv:2306.16352v1 [cs.LG])",
    "abstract": "We study the problem of PAC learning $\\gamma$-margin halfspaces with Random Classification Noise. We establish an information-computation tradeoff suggesting an inherent gap between the sample complexity of the problem and the sample complexity of computationally efficient algorithms. Concretely, the sample complexity of the problem is $\\widetilde{\\Theta}(1/(\\gamma^2 \\epsilon))$. We start by giving a simple efficient algorithm with sample complexity $\\widetilde{O}(1/(\\gamma^2 \\epsilon^2))$. Our main result is a lower bound for Statistical Query (SQ) algorithms and low-degree polynomial tests suggesting that the quadratic dependence on $1/\\epsilon$ in the sample complexity is inherent for computationally efficient algorithms. Specifically, our results imply a lower bound of $\\widetilde{\\Omega}(1/(\\gamma^{1/2} \\epsilon^2))$ on the sample complexity of any efficient SQ learner or low-degree test.",
    "link": "http://arxiv.org/abs/2306.16352",
    "context": "Title: Information-Computation Tradeoffs for Learning Margin Halfspaces with Random Classification Noise. (arXiv:2306.16352v1 [cs.LG])\nAbstract: We study the problem of PAC learning $\\gamma$-margin halfspaces with Random Classification Noise. We establish an information-computation tradeoff suggesting an inherent gap between the sample complexity of the problem and the sample complexity of computationally efficient algorithms. Concretely, the sample complexity of the problem is $\\widetilde{\\Theta}(1/(\\gamma^2 \\epsilon))$. We start by giving a simple efficient algorithm with sample complexity $\\widetilde{O}(1/(\\gamma^2 \\epsilon^2))$. Our main result is a lower bound for Statistical Query (SQ) algorithms and low-degree polynomial tests suggesting that the quadratic dependence on $1/\\epsilon$ in the sample complexity is inherent for computationally efficient algorithms. Specifically, our results imply a lower bound of $\\widetilde{\\Omega}(1/(\\gamma^{1/2} \\epsilon^2))$ on the sample complexity of any efficient SQ learner or low-degree test.",
    "path": "papers/23/06/2306.16352.json",
    "total_tokens": 890,
    "translated_title": "学习具有随机分类噪声的边界半空间的信息-计算权衡",
    "translated_abstract": "我们研究了使用随机分类噪声学习γ-边界半空间的问题。我们建立了一个信息-计算权衡，表明了问题的样本复杂性与计算效率算法的样本复杂性之间存在固有差距。具体而言，问题的样本复杂性为Θ(1/ (γ^2 ε))。我们首先给出了一个简单高效的算法，其样本复杂性为O(1/ (γ^2 ε^2))。我们的主要结果是统计查询（SQ）算法和低次多项式测试的下界，这表明在计算效率算法中，样本复杂性对1/ε的二次依赖是固有的。具体而言，我们的结果暗示了任何有效的SQ学习器或低次测试的样本复杂性的下界为Ω(1/ (γ^(1/2) ε^2))。",
    "tldr": "本文研究了学习具有随机分类噪声的边界半空间的信息-计算权衡问题，发现了样本复杂性和计算效率算法之间的固有差距，并给出了相应的样本复杂性下界。"
}