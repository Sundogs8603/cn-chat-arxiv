{
    "title": "Understanding Pathologies of Deep Heteroskedastic Regression. (arXiv:2306.16717v1 [stat.ML])",
    "abstract": "Several recent studies have reported negative results when using heteroskedastic neural regression models to model real-world data. In particular, for overparameterized models, the mean and variance networks are powerful enough to either fit every single data point (while shrinking the predicted variances to zero), or to learn a constant prediction with an output variance exactly matching every predicted residual (i.e., explaining the targets as pure noise). This paper studies these difficulties from the perspective of statistical physics. We show that the observed instabilities are not specific to any neural network architecture but are already present in a field theory of an overparameterized conditional Gaussian likelihood model. Under light assumptions, we derive a nonparametric free energy that can be solved numerically. The resulting solutions show excellent qualitative agreement with empirical model fits on real-world data and, in particular, prove the existence of phase transit",
    "link": "http://arxiv.org/abs/2306.16717",
    "context": "Title: Understanding Pathologies of Deep Heteroskedastic Regression. (arXiv:2306.16717v1 [stat.ML])\nAbstract: Several recent studies have reported negative results when using heteroskedastic neural regression models to model real-world data. In particular, for overparameterized models, the mean and variance networks are powerful enough to either fit every single data point (while shrinking the predicted variances to zero), or to learn a constant prediction with an output variance exactly matching every predicted residual (i.e., explaining the targets as pure noise). This paper studies these difficulties from the perspective of statistical physics. We show that the observed instabilities are not specific to any neural network architecture but are already present in a field theory of an overparameterized conditional Gaussian likelihood model. Under light assumptions, we derive a nonparametric free energy that can be solved numerically. The resulting solutions show excellent qualitative agreement with empirical model fits on real-world data and, in particular, prove the existence of phase transit",
    "path": "papers/23/06/2306.16717.json",
    "total_tokens": 954,
    "translated_title": "理解深度异方差回归的病态",
    "translated_abstract": "近期的研究报告了在使用异方差神经回归模型对真实世界数据建模时出现的负面结果。特别是，对于过参数化模型，均值网络和方差网络足够强大，可以拟合每个数据点（同时将预测的方差收缩到零），或者学习一个恒定的预测，输出方差恰好匹配每个预测残差（即将目标解释为纯噪声）。本文从统计物理的角度研究了这些困难。我们证明了观察到的不稳定性不特定于任何神经网络结构，而是已经存在于过参数化条件高斯似然模型的场论中。在轻微的假设下，我们推导出一个可以通过数值求解的非参数自由能。得到的解与真实世界数据上的实证模型拟合具有良好的定性一致性，并且特别证明了相变的存在。",
    "tldr": "该论文研究了利用异方差神经回归模型对真实世界数据进行建模时的困难，并从统计物理的角度提供了解释。作者证明了这些不稳定性不仅适用于神经网络结构，而且已经在过参数化条件高斯似然模型的场论中存在。数值求解结果与实证模型拟合的定性一致性证明了相变的存在。",
    "en_tdlr": "This paper investigates the challenges encountered when using heteroskedastic neural regression models to model real-world data from the perspective of statistical physics. The authors demonstrate that these instabilities are not specific to any neural network architecture but are present in a field theory of an overparameterized conditional Gaussian likelihood model. Numerical solutions show qualitative agreement with empirical model fits and confirm the existence of phase transition."
}