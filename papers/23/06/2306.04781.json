{
    "title": "Learning to Navigate in Turbulent Flows with Aerial Robot Swarms: A Cooperative Deep Reinforcement Learning Approach. (arXiv:2306.04781v1 [cs.RO])",
    "abstract": "Aerial operation in turbulent environments is a challenging problem due to the chaotic behavior of the flow. This problem is made even more complex when a team of aerial robots is trying to achieve coordinated motion in turbulent wind conditions. In this paper, we present a novel multi-robot controller to navigate in turbulent flows, decoupling the trajectory-tracking control from the turbulence compensation via a nested control architecture. Unlike previous works, our method does not learn to compensate for the air-flow at a specific time and space. Instead, our method learns to compensate for the flow based on its effect on the team. This is made possible via a deep reinforcement learning approach, implemented via a Graph Convolutional Neural Network (GCNN)-based architecture, which enables robots to achieve better wind compensation by processing the spatial-temporal correlation of wind flows across the team. Our approach scales well to large robot teams -- as each robot only uses in",
    "link": "http://arxiv.org/abs/2306.04781",
    "context": "Title: Learning to Navigate in Turbulent Flows with Aerial Robot Swarms: A Cooperative Deep Reinforcement Learning Approach. (arXiv:2306.04781v1 [cs.RO])\nAbstract: Aerial operation in turbulent environments is a challenging problem due to the chaotic behavior of the flow. This problem is made even more complex when a team of aerial robots is trying to achieve coordinated motion in turbulent wind conditions. In this paper, we present a novel multi-robot controller to navigate in turbulent flows, decoupling the trajectory-tracking control from the turbulence compensation via a nested control architecture. Unlike previous works, our method does not learn to compensate for the air-flow at a specific time and space. Instead, our method learns to compensate for the flow based on its effect on the team. This is made possible via a deep reinforcement learning approach, implemented via a Graph Convolutional Neural Network (GCNN)-based architecture, which enables robots to achieve better wind compensation by processing the spatial-temporal correlation of wind flows across the team. Our approach scales well to large robot teams -- as each robot only uses in",
    "path": "papers/23/06/2306.04781.json",
    "total_tokens": 964,
    "translated_title": "无人机群体学习协同导航在湍流中的应用：一种基于深度强化学习的合作方法",
    "translated_abstract": "在湍流环境中的空中操作是一个具有挑战性的问题，由于气流的混沌行为，这个问题变得更加复杂，特别是当一组无人机试图在湍流风况下实现协调运动时。本文提出了一种新的多机器人控制器来在湍流中导航，通过嵌套控制架构将轨迹跟踪控制与湍流补偿分离。与以往的方法不同的是，我们的方法不会在特定的时间和空间学习补偿空气流动。相反，我们的方法基于湍流对团队的影响来学习补偿空气流动，在实现过程中采用了基于图卷积神经网络（GCNN）的深度强化学习方法，可以通过处理团队中风流的时空相关性来实现更好的风力补偿效果。我们的方法可以很好地适用于大型机器人团队，因为每个机器人只使用局部信息。",
    "tldr": "本文提出了一种基于深度强化学习的多机器人控制器，通过嵌套控制架构将轨迹跟踪控制与湍流补偿分离，以解决在湍流风况下无人机群组协同运动的问题。",
    "en_tdlr": "This paper proposes a novel multi-robot controller based on deep reinforcement learning to navigate in turbulent flows, which decouples the trajectory-tracking control from the turbulence compensation via a nested control architecture. The method learns to compensate for the flow based on its effect on the team and scales well to large robot teams."
}