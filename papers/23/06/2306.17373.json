{
    "title": "HVTSurv: Hierarchical Vision Transformer for Patient-Level Survival Prediction from Whole Slide Image. (arXiv:2306.17373v1 [cs.CV])",
    "abstract": "Survival prediction based on whole slide images (WSIs) is a challenging task for patient-level multiple instance learning (MIL). Due to the vast amount of data for a patient (one or multiple gigapixels WSIs) and the irregularly shaped property of WSI, it is difficult to fully explore spatial, contextual, and hierarchical interaction in the patient-level bag. Many studies adopt random sampling pre-processing strategy and WSI-level aggregation models, which inevitably lose critical prognostic information in the patient-level bag. In this work, we propose a hierarchical vision Transformer framework named HVTSurv, which can encode the local-level relative spatial information, strengthen WSI-level context-aware communication, and establish patient-level hierarchical interaction. Firstly, we design a feature pre-processing strategy, including feature rearrangement and random window masking. Then, we devise three layers to progressively obtain patient-level representation, including a local-l",
    "link": "http://arxiv.org/abs/2306.17373",
    "context": "Title: HVTSurv: Hierarchical Vision Transformer for Patient-Level Survival Prediction from Whole Slide Image. (arXiv:2306.17373v1 [cs.CV])\nAbstract: Survival prediction based on whole slide images (WSIs) is a challenging task for patient-level multiple instance learning (MIL). Due to the vast amount of data for a patient (one or multiple gigapixels WSIs) and the irregularly shaped property of WSI, it is difficult to fully explore spatial, contextual, and hierarchical interaction in the patient-level bag. Many studies adopt random sampling pre-processing strategy and WSI-level aggregation models, which inevitably lose critical prognostic information in the patient-level bag. In this work, we propose a hierarchical vision Transformer framework named HVTSurv, which can encode the local-level relative spatial information, strengthen WSI-level context-aware communication, and establish patient-level hierarchical interaction. Firstly, we design a feature pre-processing strategy, including feature rearrangement and random window masking. Then, we devise three layers to progressively obtain patient-level representation, including a local-l",
    "path": "papers/23/06/2306.17373.json",
    "total_tokens": 890,
    "translated_title": "HVTSurv: 基于层次化视觉Transformer的全幻灯图像患者水平生存预测",
    "translated_abstract": "基于全幻灯图像（WSIs）进行患者水平的生存预测是一项具有挑战性的任务，涉及到患者的大量数据（单个或多个千兆像素WSIs）和WSI的不规则形状特性，因此很难完全探索患者水平背包中的空间、上下文和层次交互。许多研究采用随机采样预处理策略和WSI级别的聚合模型，但不可避免地丢失了患者水平背包中的关键预后信息。在本文中，我们提出了一种名为HVTSurv的层次化视觉Transformer框架，可以编码局部级别的相对空间信息，增强WSI级别的上下文感知通信，并建立患者级别的层次交互。",
    "tldr": "HVTSurv是一种基于层次化视觉Transformer的方法，用于从全幻灯图像预测患者的生存情况。其通过特征预处理和逐层编码的方式，能够捕捉到局部空间信息、增强上下文感知，建立患者级别的层次交互。",
    "en_tdlr": "HVTSurv is a hierarchical vision Transformer method for patient-level survival prediction from whole slide images (WSIs). It encodes local-level relative spatial information, strengthens WSI-level context-aware communication, and establishes patient-level hierarchical interaction through feature pre-processing and progressive encoding."
}