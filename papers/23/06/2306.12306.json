{
    "title": "Beyond Deep Ensembles -- A Large-Scale Evaluation of Bayesian Deep Learning under Distribution Shift. (arXiv:2306.12306v1 [cs.LG])",
    "abstract": "Bayesian deep learning (BDL) is a promising approach to achieve well-calibrated predictions on distribution-shifted data. Nevertheless, there exists no large-scale survey that evaluates recent SOTA methods on diverse, realistic, and challenging benchmark tasks in a systematic manner. To provide a clear picture of the current state of BDL research, we evaluate modern BDL algorithms on real-world datasets from the WILDS collection containing challenging classification and regression tasks, with a focus on generalization capability and calibration under distribution shift. We compare the algorithms on a wide range of large, convolutional and transformer-based neural network architectures. In particular, we investigate a signed version of the expected calibration error that reveals whether the methods are over- or under-confident, providing further insight into the behavior of the methods. Further, we provide the first systematic evaluation of BDL for fine-tuning large pre-trained models, ",
    "link": "http://arxiv.org/abs/2306.12306",
    "context": "Title: Beyond Deep Ensembles -- A Large-Scale Evaluation of Bayesian Deep Learning under Distribution Shift. (arXiv:2306.12306v1 [cs.LG])\nAbstract: Bayesian deep learning (BDL) is a promising approach to achieve well-calibrated predictions on distribution-shifted data. Nevertheless, there exists no large-scale survey that evaluates recent SOTA methods on diverse, realistic, and challenging benchmark tasks in a systematic manner. To provide a clear picture of the current state of BDL research, we evaluate modern BDL algorithms on real-world datasets from the WILDS collection containing challenging classification and regression tasks, with a focus on generalization capability and calibration under distribution shift. We compare the algorithms on a wide range of large, convolutional and transformer-based neural network architectures. In particular, we investigate a signed version of the expected calibration error that reveals whether the methods are over- or under-confident, providing further insight into the behavior of the methods. Further, we provide the first systematic evaluation of BDL for fine-tuning large pre-trained models, ",
    "path": "papers/23/06/2306.12306.json",
    "total_tokens": 953,
    "translated_title": "超越深度集成——基于分布偏移下贝叶斯深度学习的大规模评估",
    "translated_abstract": "贝叶斯深度学习（BDL）是实现在分布偏移数据上进行良好校准预测的有前途的方法。然而，缺乏大规模调查，以系统方式评估最近的 SOTA 方法在多样、现实和具有挑战性的基准任务上的表现。为了清晰了解BDL研究的当前状况，我们在来自WILDS集合的现实世界数据集上评估现代BDL算法，包含具有挑战性的分类和回归任务，重点关注在分布偏移下的泛化性能和校准能力。我们比较了一系列大型，卷积和基于 transformer 的神经网络结构上的算法，并研究了一个带符号的期望校准误差版本，揭示出方法是过度自信还是低振幅，进一步深入研究方法的行为。此外，我们为了首次系统评估BDL在微调大型预训练模型上表现，做了更多的工作。",
    "tldr": "该论文在多个具有挑战性的分类和回归任务上对现代BDL算法进行了系统性评估，重点关注了在分布偏移下的泛化能力和校准能力，并研究了一种带符号的期望校准误差版本。"
}