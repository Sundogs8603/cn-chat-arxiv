{
    "title": "Guiding Language Models of Code with Global Context using Monitors. (arXiv:2306.10763v2 [cs.CL] UPDATED)",
    "abstract": "Language models of code (LMs) work well when the surrounding code provides sufficient context. This is not true when it becomes necessary to use types, functionality or APIs defined elsewhere in the repository or a linked library, especially those not seen during training. LMs suffer from limited awareness of such global context and end up hallucinating.  Integrated development environments (IDEs) assist developers in understanding repository context using static analysis. We extend this assistance, enjoyed by developers, to LMs. We propose monitor-guided decoding (MGD) where a monitor uses static analysis to guide the decoding. We construct a repository-level dataset PragmaticCode for method-completion in Java and evaluate MGD on it. On models of varying parameter scale, by monitoring for type-consistent object dereferences, MGD consistently improves compilation rates and agreement with ground truth. Further, LMs with fewer parameters, when augmented with MGD, can outperform larger LM",
    "link": "http://arxiv.org/abs/2306.10763",
    "context": "Title: Guiding Language Models of Code with Global Context using Monitors. (arXiv:2306.10763v2 [cs.CL] UPDATED)\nAbstract: Language models of code (LMs) work well when the surrounding code provides sufficient context. This is not true when it becomes necessary to use types, functionality or APIs defined elsewhere in the repository or a linked library, especially those not seen during training. LMs suffer from limited awareness of such global context and end up hallucinating.  Integrated development environments (IDEs) assist developers in understanding repository context using static analysis. We extend this assistance, enjoyed by developers, to LMs. We propose monitor-guided decoding (MGD) where a monitor uses static analysis to guide the decoding. We construct a repository-level dataset PragmaticCode for method-completion in Java and evaluate MGD on it. On models of varying parameter scale, by monitoring for type-consistent object dereferences, MGD consistently improves compilation rates and agreement with ground truth. Further, LMs with fewer parameters, when augmented with MGD, can outperform larger LM",
    "path": "papers/23/06/2306.10763.json",
    "total_tokens": 888,
    "translated_title": "使用监视器引导全局上下文指导代码语言模型",
    "translated_abstract": "代码语言模型（LMs）在周围代码提供足够上下文时效果很好。但当需要在存储库或链接库中使用在训练过程中未见过的类型、功能或API时，这种情况就不再成立。LMs在对这种全局上下文的意识有限时会出现错误预测的情况。集成开发环境（IDEs）通过静态分析帮助开发人员了解存储库上下文。我们将开发人员享受到的这种帮助扩展到了LMs。我们提出了监视器引导解码（MGD）的方法，其中监视器使用静态分析来引导解码过程。我们构建了一个用于Java方法补全的存储库级数据集PragmaticCode，并在其上评估了MGD。在不同参数规模的模型上，通过监视类型一致的对象解引用，MGD能够持续提高编译率并与真实结果达成一致。此外，具有更少参数的LMs，在与MGD相结合时能够超越更大的LMs的性能。",
    "tldr": "本文提出了一种使用监视器引导全局上下文的方法来指导代码语言模型，在处理类型、功能或API等全局上下文时，能够提高代码语言模型的性能和准确性。",
    "en_tdlr": "This paper presents a method of using monitors to guide language models of code with global context, improving their performance and accuracy when dealing with global context elements such as types, functionality or APIs."
}