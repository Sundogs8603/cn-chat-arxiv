{
    "title": "Training-free Diffusion Model Adaptation for Variable-Sized Text-to-Image Synthesis. (arXiv:2306.08645v2 [cs.CV] UPDATED)",
    "abstract": "Diffusion models (DMs) have recently gained attention with state-of-the-art performance in text-to-image synthesis. Abiding by the tradition in deep learning, DMs are trained and evaluated on the images with fixed sizes. However, users are demanding for various images with specific sizes and various aspect ratio. This paper focuses on adapting text-to-image diffusion models to handle such variety while maintaining visual fidelity. First we observe that, during the synthesis, lower resolution images suffer from incomplete object portrayal, while higher resolution images exhibit repetitively disordered presentation. Next, we establish a statistical relationship indicating that attention entropy changes with token quantity, suggesting that models aggregate spatial information in proportion to image resolution. The subsequent interpretation on our observations is that objects are incompletely depicted due to limited spatial information for low resolutions, while repetitively disorganized p",
    "link": "http://arxiv.org/abs/2306.08645",
    "context": "Title: Training-free Diffusion Model Adaptation for Variable-Sized Text-to-Image Synthesis. (arXiv:2306.08645v2 [cs.CV] UPDATED)\nAbstract: Diffusion models (DMs) have recently gained attention with state-of-the-art performance in text-to-image synthesis. Abiding by the tradition in deep learning, DMs are trained and evaluated on the images with fixed sizes. However, users are demanding for various images with specific sizes and various aspect ratio. This paper focuses on adapting text-to-image diffusion models to handle such variety while maintaining visual fidelity. First we observe that, during the synthesis, lower resolution images suffer from incomplete object portrayal, while higher resolution images exhibit repetitively disordered presentation. Next, we establish a statistical relationship indicating that attention entropy changes with token quantity, suggesting that models aggregate spatial information in proportion to image resolution. The subsequent interpretation on our observations is that objects are incompletely depicted due to limited spatial information for low resolutions, while repetitively disorganized p",
    "path": "papers/23/06/2306.08645.json",
    "total_tokens": 1028,
    "translated_title": "针对变尺寸文本到图像合成的无需训练的扩散模型适应",
    "translated_abstract": "近期，扩散模型（DMs）在文本到图像合成中表现出了最先进的性能，并引起了广泛关注。然而，遵循深度学习的传统，DMs在固定尺寸的图像上进行训练和评估。然而，用户需要不同尺寸和不同长宽比的各种图像。本文重点研究了如何在保持视觉保真度的同时，使文本到图像扩散模型能够处理这种多样性。首先，我们观察到，在合成过程中，低分辨率的图像会因为对象描绘不完整，而高分辨率的图像则会出现重复无序的呈现。接下来，我们建立了一个统计关系，该关系表明注意力熵随令牌数量变化而变化，这表明模型会按照图像分辨率的比例聚合空间信息。我们对观察结果的后续解释是，由于低分辨率的图像有限的空间信息，对象被不完整地描绘，而高分辨率的图像则会出现重复无序的表示。",
    "tldr": "本研究提出了一种无需训练的扩散模型适应方法，用于处理变尺寸文本到图像合成。通过观察低分辨率图像的不完整对象描绘和高分辨率图像的重复无序呈现，提出了注意力熵与令牌数量变化的统计关系。这项工作实现了在保持视觉保真度的同时适应不同尺寸和长宽比的图像合成需求。"
}