{
    "title": "Enhancing Fault Resilience of QNNs by Selective Neuron Splitting. (arXiv:2306.09973v1 [cs.LG])",
    "abstract": "The superior performance of Deep Neural Networks (DNNs) has led to their application in various aspects of human life. Safety-critical applications are no exception and impose rigorous reliability requirements on DNNs. Quantized Neural Networks (QNNs) have emerged to tackle the complexity of DNN accelerators, however, they are more prone to reliability issues.  In this paper, a recent analytical resilience assessment method is adapted for QNNs to identify critical neurons based on a Neuron Vulnerability Factor (NVF). Thereafter, a novel method for splitting the critical neurons is proposed that enables the design of a Lightweight Correction Unit (LCU) in the accelerator without redesigning its computational part.  The method is validated by experiments on different QNNs and datasets. The results demonstrate that the proposed method for correcting the faults has a twice smaller overhead than a selective Triple Modular Redundancy (TMR) while achieving a similar level of fault resiliency.",
    "link": "http://arxiv.org/abs/2306.09973",
    "context": "Title: Enhancing Fault Resilience of QNNs by Selective Neuron Splitting. (arXiv:2306.09973v1 [cs.LG])\nAbstract: The superior performance of Deep Neural Networks (DNNs) has led to their application in various aspects of human life. Safety-critical applications are no exception and impose rigorous reliability requirements on DNNs. Quantized Neural Networks (QNNs) have emerged to tackle the complexity of DNN accelerators, however, they are more prone to reliability issues.  In this paper, a recent analytical resilience assessment method is adapted for QNNs to identify critical neurons based on a Neuron Vulnerability Factor (NVF). Thereafter, a novel method for splitting the critical neurons is proposed that enables the design of a Lightweight Correction Unit (LCU) in the accelerator without redesigning its computational part.  The method is validated by experiments on different QNNs and datasets. The results demonstrate that the proposed method for correcting the faults has a twice smaller overhead than a selective Triple Modular Redundancy (TMR) while achieving a similar level of fault resiliency.",
    "path": "papers/23/06/2306.09973.json",
    "total_tokens": 907,
    "translated_title": "通过选择性神经元分裂增强QNN的容错性",
    "translated_abstract": "深度神经网络（DNN）的出色性能导致它们在人类生活的各个方面得到应用。安全关键的应用程序也不例外，并对DNN提出了严格的可靠性要求。Quantized Neural Networks（QNN）已经出现，以应对DNN加速器的复杂性，然而，它们更容易出现可靠性问题。本文将最近的分析容错评估方法用于QNN，基于神经元易损因子（NVF）识别关键神经元。然后提出了一种新方法来分裂关键神经元，从而在加速器中设计轻量级纠错单元（LCU）而不需要重新设计其计算部分。该方法通过不同的QNN和数据集的实验进行了验证。结果表明，相对于选择性三重模块冗余（TMR），所提出的故障修正方法具有两倍小的开销，同时实现了类似的故障容错水平。",
    "tldr": "本文提出一种选择性神经元分裂方法，增强QNN的容错性，可以在加速器中设计轻量级纠错单元，相对于选择性三重模块冗余具有更小的开销，同时实现了类似的故障容错水平。",
    "en_tdlr": "This paper proposes a selective neuron splitting method to enhance the fault resilience of QNNs, which enables the design of a lightweight correction unit in the accelerator and has a smaller overhead than selective Triple Modular Redundancy (TMR) while achieving a similar level of fault resilience."
}