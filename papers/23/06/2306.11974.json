{
    "title": "Universal adversarial perturbations for multiple classification tasks with quantum classifiers. (arXiv:2306.11974v1 [quant-ph])",
    "abstract": "Quantum adversarial machine learning is an emerging field that studies the vulnerability of quantum learning systems against adversarial perturbations and develops possible defense strategies. Quantum universal adversarial perturbations are small perturbations, which can make different input samples into adversarial examples that may deceive a given quantum classifier. This is a field that was rarely looked into but worthwhile investigating because universal perturbations might simplify malicious attacks to a large extent, causing unexpected devastation to quantum machine learning models. In this paper, we take a step forward and explore the quantum universal perturbations in the context of heterogeneous classification tasks. In particular, we find that quantum classifiers that achieve almost state-of-the-art accuracy on two different classification tasks can be both conclusively deceived by one carefully-crafted universal perturbation. This result is explicitly demonstrated with well-",
    "link": "http://arxiv.org/abs/2306.11974",
    "context": "Title: Universal adversarial perturbations for multiple classification tasks with quantum classifiers. (arXiv:2306.11974v1 [quant-ph])\nAbstract: Quantum adversarial machine learning is an emerging field that studies the vulnerability of quantum learning systems against adversarial perturbations and develops possible defense strategies. Quantum universal adversarial perturbations are small perturbations, which can make different input samples into adversarial examples that may deceive a given quantum classifier. This is a field that was rarely looked into but worthwhile investigating because universal perturbations might simplify malicious attacks to a large extent, causing unexpected devastation to quantum machine learning models. In this paper, we take a step forward and explore the quantum universal perturbations in the context of heterogeneous classification tasks. In particular, we find that quantum classifiers that achieve almost state-of-the-art accuracy on two different classification tasks can be both conclusively deceived by one carefully-crafted universal perturbation. This result is explicitly demonstrated with well-",
    "path": "papers/23/06/2306.11974.json",
    "total_tokens": 1023,
    "translated_title": "用于多分类任务的量子分类器的通用对抗扰动",
    "translated_abstract": "量子对抗机器学习是一门新兴的领域，它研究了量子学习系统对抗扰动的脆弱性并开发了可能的防御策略。量子通用对抗扰动是一种小的扰动，可以使不同的输入样本成为误导给定量子分类器的对抗示例。尽管此领域之前鲜有探究，但是通用扰动可能极大地简化恶意攻击，对量子机器学习模型造成意想不到的破坏。本文在异构分类任务的背景下，进一步探讨量子通用对抗扰动。特别地，我们发现，几乎在两个不同分类任务上达到最先进准确性的量子分类器，都可以被一个精心制作的通用扰动所诱导成功地欺骗。这一结果已经在计算机视觉和量子机器学习社区中广泛使用的数据集CIFAR-10和Iris中得到明确的证明。我们的发现表明，通用对抗扰动是量子机器学习模型的潜在威胁，并可能给构建安全的量子机器学习系统带来巨大挑战。",
    "tldr": "本文探讨了量子通用对抗扰动，并发现一个精心制作的通用扰动可以成功地欺骗两个不同分类任务上达到最先进准确性的量子分类器，这为构建安全的量子机器学习系统带来潜在威胁。"
}