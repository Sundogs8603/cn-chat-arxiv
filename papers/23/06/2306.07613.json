{
    "title": "Rethinking Adversarial Training with A Simple Baseline. (arXiv:2306.07613v1 [cs.CV])",
    "abstract": "We report competitive results on RobustBench for CIFAR and SVHN using a simple yet effective baseline approach. Our approach involves a training protocol that integrates rescaled square loss, cyclic learning rates, and erasing-based data augmentation. The outcomes we have achieved are comparable to those of the model trained with state-of-the-art techniques, which is currently the predominant choice for adversarial training. Our baseline, referred to as SimpleAT, yields three novel empirical insights. (i) By switching to square loss, the accuracy is comparable to that obtained by using both de-facto training protocol plus data augmentation. (ii) One cyclic learning rate is a good scheduler, which can effectively reduce the risk of robust overfitting. (iii) Employing rescaled square loss during model training can yield a favorable balance between adversarial and natural accuracy. In general, our experimental results show that SimpleAT effectively mitigates robust overfitting and consist",
    "link": "http://arxiv.org/abs/2306.07613",
    "context": "Title: Rethinking Adversarial Training with A Simple Baseline. (arXiv:2306.07613v1 [cs.CV])\nAbstract: We report competitive results on RobustBench for CIFAR and SVHN using a simple yet effective baseline approach. Our approach involves a training protocol that integrates rescaled square loss, cyclic learning rates, and erasing-based data augmentation. The outcomes we have achieved are comparable to those of the model trained with state-of-the-art techniques, which is currently the predominant choice for adversarial training. Our baseline, referred to as SimpleAT, yields three novel empirical insights. (i) By switching to square loss, the accuracy is comparable to that obtained by using both de-facto training protocol plus data augmentation. (ii) One cyclic learning rate is a good scheduler, which can effectively reduce the risk of robust overfitting. (iii) Employing rescaled square loss during model training can yield a favorable balance between adversarial and natural accuracy. In general, our experimental results show that SimpleAT effectively mitigates robust overfitting and consist",
    "path": "papers/23/06/2306.07613.json",
    "total_tokens": 1008,
    "translated_title": "用一个简单baseline重新思考对抗训练",
    "translated_abstract": "我们使用了一种简单但有效的baseline方法，针对CIFAR和SVHN数据集在RobustBench上获得了有竞争力的结果。我们的方法包括一个训练协议，该协议集成了重新调整的平方损失，循环学习率和基于擦除的数据增强。我们实现的结果可与使用最先进技术训练的模型相媲美，这目前是对抗训练的主要选择。我们的baseline被称为SimpleAT，产生了三个新颖的经验洞察：(i) 通过转换为平方损失，准确度可与使用事实上的训练协议加数据增强所获得的准确度相当。 (ii) 一个循环学习率是一个很好的scheduler，可以有效降低robust overfitting的风险。 (iii) 在模型训练过程中使用重新调整的平方损失可以在对抗和自然准确度之间产生良好的平衡。总的来说，我们的实验结果表明，SimpleAT有效地缓解了robust overfitting，并始终实现了与对抗训练最先进方法相媲美的竞争表现。",
    "tldr": "这篇论文提出了一种简单的对抗训练baseline，使用了重新调整的平方损失、循环学习率和基于擦除的数据增强等方法，在对抗和自然准确度之间产生了良好的平衡，并可有效降低robust overfitting风险，表现与最先进方法媲美。",
    "en_tdlr": "This paper proposes a simple adversarial training baseline, which integrates rescaled square loss, cyclic learning rates, and erasing-based data augmentation, achieving a favorable balance between adversarial and natural accuracy and effectively mitigating robust overfitting risk, with competitive performance comparable to state-of-the-art methods."
}