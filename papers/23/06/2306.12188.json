{
    "title": "Facial Expression Re-targeting from a Single Character. (arXiv:2306.12188v1 [cs.GR])",
    "abstract": "Video retargeting for digital face animation is used in virtual reality, social media, gaming, movies, and video conference, aiming to animate avatars' facial expressions based on videos of human faces. The standard method to represent facial expressions for 3D characters is by blendshapes, a vector of weights representing the avatar's neutral shape and its variations under facial expressions, e.g., smile, puff, blinking. Datasets of paired frames with blendshape vectors are rare, and labeling can be laborious, time-consuming, and subjective. In this work, we developed an approach that handles the lack of appropriate datasets. Instead, we used a synthetic dataset of only one character. To generalize various characters, we re-represented each frame to face landmarks. We developed a unique deep-learning architecture that groups landmarks for each facial organ and connects them to relevant blendshape weights. Additionally, we incorporated complementary methods for facial expressions that ",
    "link": "http://arxiv.org/abs/2306.12188",
    "context": "Title: Facial Expression Re-targeting from a Single Character. (arXiv:2306.12188v1 [cs.GR])\nAbstract: Video retargeting for digital face animation is used in virtual reality, social media, gaming, movies, and video conference, aiming to animate avatars' facial expressions based on videos of human faces. The standard method to represent facial expressions for 3D characters is by blendshapes, a vector of weights representing the avatar's neutral shape and its variations under facial expressions, e.g., smile, puff, blinking. Datasets of paired frames with blendshape vectors are rare, and labeling can be laborious, time-consuming, and subjective. In this work, we developed an approach that handles the lack of appropriate datasets. Instead, we used a synthetic dataset of only one character. To generalize various characters, we re-represented each frame to face landmarks. We developed a unique deep-learning architecture that groups landmarks for each facial organ and connects them to relevant blendshape weights. Additionally, we incorporated complementary methods for facial expressions that ",
    "path": "papers/23/06/2306.12188.json",
    "total_tokens": 815,
    "translated_title": "单个角色的面部表情重定向研究",
    "translated_abstract": "数字化面部动画中的视频重定向是虚拟现实、社交媒体、游戏、电影和视频会议中常用的技术，旨在根据人脸视频激活角色的面部表情。本文中提出的方法解决了面部表情数据集稀少、标注困难等问题。我们使用只有一个角色的合成数据集，将每帧图像重新表示为面部标志点，并开发出一种新颖的深度学习架构。该方法分组组织每个面部器官的标志点，并将它们连接到相关的表情权重上。此外，我们还使用了其他方法增强面部表情的表达效果。",
    "tldr": "本研究使用只有一个角色的合成数据集解决了面部表情数据集稀少、标注困难等问题。开发了一种新颖的深度学习架构，能够将面部器官的标志点分组组织，并将它们连接到相关的表情权重上。"
}