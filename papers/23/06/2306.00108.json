{
    "title": "Majority Rule: better patching via Self-Consistency. (arXiv:2306.00108v1 [cs.SE])",
    "abstract": "Large Language models (LLMs) can be induced to solve non-trivial problems with \"few-shot\" prompts including illustrative problem-solution examples. Now if the few-shots also include \"chain of thought\" (CoT) explanations, which are of the form problem-explanation-solution, LLMs will generate a \"explained\" solution, and perform even better. Recently an exciting, substantially better technique, self-consistency [1] (S-C) has emerged, based on the intuition that there are many plausible explanations for the right solution; when the LLM is sampled repeatedly to generate a pool of explanation-solution pairs, for a given problem, the most frequently occurring solutions in the pool (ignoring the explanations) tend to be even more likely to be correct! Unfortunately, the use of this highly-performant S-C (or even CoT) approach in software engineering settings is hampered by the lack of explanations; most software datasets lack explanations. In this paper, we describe an application of the S-C a",
    "link": "http://arxiv.org/abs/2306.00108",
    "context": "Title: Majority Rule: better patching via Self-Consistency. (arXiv:2306.00108v1 [cs.SE])\nAbstract: Large Language models (LLMs) can be induced to solve non-trivial problems with \"few-shot\" prompts including illustrative problem-solution examples. Now if the few-shots also include \"chain of thought\" (CoT) explanations, which are of the form problem-explanation-solution, LLMs will generate a \"explained\" solution, and perform even better. Recently an exciting, substantially better technique, self-consistency [1] (S-C) has emerged, based on the intuition that there are many plausible explanations for the right solution; when the LLM is sampled repeatedly to generate a pool of explanation-solution pairs, for a given problem, the most frequently occurring solutions in the pool (ignoring the explanations) tend to be even more likely to be correct! Unfortunately, the use of this highly-performant S-C (or even CoT) approach in software engineering settings is hampered by the lack of explanations; most software datasets lack explanations. In this paper, we describe an application of the S-C a",
    "path": "papers/23/06/2306.00108.json",
    "total_tokens": 904,
    "translated_title": "多数规则：通过自洽性实现更好的修补",
    "translated_abstract": "大型语言模型（LLMs）可以被引导解决一些需要“少量提示”的问题，包括示例问题-解决方案对。现在，如果少量提示也包括“思维链”（CoT）解释，形式为问题-解释-解决方案，LLMs将会产生一个“解释”的解决方案，并表现得更好。最近，一项更出色的技术“自洽性”（S-C）出现了，基于这样一种直觉：正确的解决方案有许多可能的解释。当LLM被反复采样以生成问题的解释-解决方案对时，对于给定的问题，池中最常发生的解决方案（忽略解释）更有可能是正确的！但是，这种高性能的S-C（甚至CoT）方法在软件工程环境中的使用受到解释的缺乏的限制；大多数软件数据集都缺乏解释。在本文中，我们描述了一个S-C算法的应用，该算法不需要解释，因此可以用于软件补丁选择。",
    "tldr": "本文提出了一种无需解释的算法，基于自洽性和大型语言模型（LLMs）来进行软件补丁选择，从而解决当前缺乏解释的软件数据集的问题。",
    "en_tdlr": "This paper proposes a self-consistent algorithm based on large language models (LLMs) for software patch selection, which does not require explanations and solves the problem of current software datasets lacking explanations."
}