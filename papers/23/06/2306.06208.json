{
    "title": "A Differential Testing Framework to Evaluate Image Recognition Model Robustness. (arXiv:2306.06208v1 [cs.CV])",
    "abstract": "Image recognition tasks typically use deep learning and require enormous processing power, thus relying on hardware accelerators like GPUs and TPUs for fast, timely processing. Failure in real-time image recognition tasks can occur due to sub-optimal mapping on hardware accelerators during model deployment, which may lead to timing uncertainty and erroneous behavior. Mapping on hardware accelerators is done through multiple software components like deep learning frameworks, compilers, device libraries, that we refer to as the computational environment. Owing to the increased use of image recognition tasks in safety-critical applications like autonomous driving and medical imaging, it is imperative to assess their robustness to changes in the computational environment, as the impact of parameters like deep learning frameworks, compiler optimizations, and hardware devices on model performance and correctness is not well understood.  In this paper we present a differential testing framewo",
    "link": "http://arxiv.org/abs/2306.06208",
    "context": "Title: A Differential Testing Framework to Evaluate Image Recognition Model Robustness. (arXiv:2306.06208v1 [cs.CV])\nAbstract: Image recognition tasks typically use deep learning and require enormous processing power, thus relying on hardware accelerators like GPUs and TPUs for fast, timely processing. Failure in real-time image recognition tasks can occur due to sub-optimal mapping on hardware accelerators during model deployment, which may lead to timing uncertainty and erroneous behavior. Mapping on hardware accelerators is done through multiple software components like deep learning frameworks, compilers, device libraries, that we refer to as the computational environment. Owing to the increased use of image recognition tasks in safety-critical applications like autonomous driving and medical imaging, it is imperative to assess their robustness to changes in the computational environment, as the impact of parameters like deep learning frameworks, compiler optimizations, and hardware devices on model performance and correctness is not well understood.  In this paper we present a differential testing framewo",
    "path": "papers/23/06/2306.06208.json",
    "total_tokens": 1183,
    "translated_title": "一种用于评估图像识别模型鲁棒性的差分测试框架",
    "translated_abstract": "图像识别任务通常使用深度学习，并需要巨大的处理能力，因此依赖于GPU和TPU等硬件加速器进行快速、及时的处理。在模型部署过程中，硬件加速器上的子优映射可能会导致实时图像识别任务失败，从而导致时间不确定性和错误行为。硬件加速器上的映射是通过多个软件组件进行的，例如深度学习框架、编译器、设备库等，我们称之为计算环境。随着图像识别任务在自动驾驶和医疗成像等安全关键应用中的增加，评估它们对计算环境变化的鲁棒性至关重要，因为深度学习框架、编译器优化和硬件设备等参数对模型性能和正确性的影响还不太清楚。在本文中，我们提出了一种差分测试框架，用于评估图像识别模型对计算环境变化的鲁棒性。我们的框架使用一组参考图像，并通过更改软件组件来扰动计算环境，生成具有已知预测输出差异的图像。通过比较原始图像和扰动图像的预测输出，我们可以确定模型性能是否受到计算环境变化的影响。我们通过测试三个图像识别模型的鲁棒性来证明我们框架的有效性，并确定其在计算环境变化下的性能受到影响的情况。",
    "tldr": "本文提出了一种差分测试框架，用于评估图像识别模型鲁棒性。该框架通过使用一组参考图像并扰动计算环境，可确定模型性能是否受到计算环境变化的影响。",
    "en_tdlr": "This paper proposes a differential testing framework to evaluate the robustness of image recognition models to changes in the computational environment. The framework uses a set of reference images and perturbs the computational environment by changing software components, allowing the identification of whether a model's performance is impacted by changes in the computational environment."
}