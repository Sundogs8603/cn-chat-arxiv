{
    "title": "Scaling Model Checking for DNN Analysis via State-Space Reduction and Input Segmentation (Extended Version). (arXiv:2306.17323v1 [cs.LG])",
    "abstract": "Owing to their remarkable learning capabilities and performance in real-world applications, the use of machine learning systems based on Neural Networks (NNs) has been continuously increasing. However, various case studies and empirical findings in the literature suggest that slight variations to NN inputs can lead to erroneous and undesirable NN behavior. This has led to considerable interest in their formal analysis, aiming to provide guarantees regarding a given NN's behavior. Existing frameworks provide robustness and/or safety guarantees for the trained NNs, using satisfiability solving and linear programming. We proposed FANNet, the first model checking-based framework for analyzing a broader range of NN properties. However, the state-space explosion associated with model checking entails a scalability problem, making the FANNet applicable only to small NNs. This work develops state-space reduction and input segmentation approaches, to improve the scalability and timing efficienc",
    "link": "http://arxiv.org/abs/2306.17323",
    "context": "Title: Scaling Model Checking for DNN Analysis via State-Space Reduction and Input Segmentation (Extended Version). (arXiv:2306.17323v1 [cs.LG])\nAbstract: Owing to their remarkable learning capabilities and performance in real-world applications, the use of machine learning systems based on Neural Networks (NNs) has been continuously increasing. However, various case studies and empirical findings in the literature suggest that slight variations to NN inputs can lead to erroneous and undesirable NN behavior. This has led to considerable interest in their formal analysis, aiming to provide guarantees regarding a given NN's behavior. Existing frameworks provide robustness and/or safety guarantees for the trained NNs, using satisfiability solving and linear programming. We proposed FANNet, the first model checking-based framework for analyzing a broader range of NN properties. However, the state-space explosion associated with model checking entails a scalability problem, making the FANNet applicable only to small NNs. This work develops state-space reduction and input segmentation approaches, to improve the scalability and timing efficienc",
    "path": "papers/23/06/2306.17323.json",
    "total_tokens": 849,
    "translated_title": "通过状态空间缩减和输入分割来扩展DNN分析的模型检验",
    "translated_abstract": "鉴于神经网络（NN）在真实世界应用中表现出的学习能力和性能，基于NN的机器学习系统的使用持续增长。然而，文献中的各种案例研究和经验发现表明，微小的NN输入变化可能导致错误和不可取的NN行为。这引起了对其形式分析的广泛兴趣，旨在提供关于给定NN行为的保证。现有的框架使用可满足性求解和线性规划为训练的NN提供了稳健性和/或安全性保证。我们提出了FANNet，这是第一个基于模型检验的框架，用于分析更广泛范围的NN属性。然而，与模型检验相关的状态空间爆炸导致了可扩展性问题，使得FANNet只适用于小型NN。本工作开发了状态空间缩减和输入分割方法，以提高可扩展性和计时效率。",
    "tldr": "该论文通过状态空间缩减和输入分割提出了一个扩展DNN分析的模型检验框架，解决了模型检验的可扩展性问题。"
}