{
    "title": "Randomized Quantization is All You Need for Differential Privacy in Federated Learning. (arXiv:2306.11913v1 [cs.LG])",
    "abstract": "Federated learning (FL) is a common and practical framework for learning a machine model in a decentralized fashion. A primary motivation behind this decentralized approach is data privacy, ensuring that the learner never sees the data of each local source itself. Federated learning then comes with two majors challenges: one is handling potentially complex model updates between a server and a large number of data sources; the other is that de-centralization may, in fact, be insufficient for privacy, as the local updates themselves can reveal information about the sources' data. To address these issues, we consider an approach to federated learning that combines quantization and differential privacy. Absent privacy, Federated Learning often relies on quantization to reduce communication complexity. We build upon this approach and develop a new algorithm called the \\textbf{R}andomized \\textbf{Q}uantization \\textbf{M}echanism (RQM), which obtains privacy through a two-levels of randomizat",
    "link": "http://arxiv.org/abs/2306.11913",
    "context": "Title: Randomized Quantization is All You Need for Differential Privacy in Federated Learning. (arXiv:2306.11913v1 [cs.LG])\nAbstract: Federated learning (FL) is a common and practical framework for learning a machine model in a decentralized fashion. A primary motivation behind this decentralized approach is data privacy, ensuring that the learner never sees the data of each local source itself. Federated learning then comes with two majors challenges: one is handling potentially complex model updates between a server and a large number of data sources; the other is that de-centralization may, in fact, be insufficient for privacy, as the local updates themselves can reveal information about the sources' data. To address these issues, we consider an approach to federated learning that combines quantization and differential privacy. Absent privacy, Federated Learning often relies on quantization to reduce communication complexity. We build upon this approach and develop a new algorithm called the \\textbf{R}andomized \\textbf{Q}uantization \\textbf{M}echanism (RQM), which obtains privacy through a two-levels of randomizat",
    "path": "papers/23/06/2306.11913.json",
    "total_tokens": 973,
    "translated_title": "随机量化，是联邦学习中实现差分隐私的唯一所需。",
    "translated_abstract": "联邦学习是一种常见和实用的机器学习模型，用于在分散的环境中学习。分散学习的一个主要动机是数据隐私，保证学习者永远不会查看每个本地源的数据。最大的挑战是处理服务器和大量数据源之间的可能复杂的模型更新，以及本地更新本身可能会泄露有关数据源的信息。为了解决这些问题，我们考虑将量化和差分隐私相结合的联邦学习方法。我们开发了一种新的算法RQM，通过两个级别的随机量化获得隐私性。该机制为传输的更新和每个数据源的局部差分隐私提供差分隐私保证。我们进一步为在FL中执行RQM的总隐私成本提供了上限，并表明该机制在隐私效用平衡方面实现了接近最优的结果。",
    "tldr": "该论文提出了一种基于随机量化的机制，通过两级量化实现了差分隐私的保证，这可以用于处理联邦学习中的隐私问题，并实现了接近最优的隐私效用平衡。"
}