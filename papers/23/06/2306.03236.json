{
    "title": "A Study of Global and Episodic Bonuses for Exploration in Contextual MDPs. (arXiv:2306.03236v1 [cs.AI])",
    "abstract": "Exploration in environments which differ across episodes has received increasing attention in recent years. Current methods use some combination of global novelty bonuses, computed using the agent's entire training experience, and \\textit{episodic novelty bonuses}, computed using only experience from the current episode. However, the use of these two types of bonuses has been ad-hoc and poorly understood. In this work, we shed light on the behavior of these two types of bonuses through controlled experiments on easily interpretable tasks as well as challenging pixel-based settings. We find that the two types of bonuses succeed in different settings, with episodic bonuses being most effective when there is little shared structure across episodes and global bonuses being effective when more structure is shared. We develop a conceptual framework which makes this notion of shared structure precise by considering the variance of the value function across contexts, and which provides a unify",
    "link": "http://arxiv.org/abs/2306.03236",
    "context": "Title: A Study of Global and Episodic Bonuses for Exploration in Contextual MDPs. (arXiv:2306.03236v1 [cs.AI])\nAbstract: Exploration in environments which differ across episodes has received increasing attention in recent years. Current methods use some combination of global novelty bonuses, computed using the agent's entire training experience, and \\textit{episodic novelty bonuses}, computed using only experience from the current episode. However, the use of these two types of bonuses has been ad-hoc and poorly understood. In this work, we shed light on the behavior of these two types of bonuses through controlled experiments on easily interpretable tasks as well as challenging pixel-based settings. We find that the two types of bonuses succeed in different settings, with episodic bonuses being most effective when there is little shared structure across episodes and global bonuses being effective when more structure is shared. We develop a conceptual framework which makes this notion of shared structure precise by considering the variance of the value function across contexts, and which provides a unify",
    "path": "papers/23/06/2306.03236.json",
    "total_tokens": 1244,
    "translated_title": "全局及情境奖励对于上下文MDPs中的探索的研究",
    "translated_abstract": "近年来，探索不同情境下的环境引起了越来越多的关注。目前的方法使用全局新奇奖励和情境新奇奖励的某种组合，使用代理的整个训练经验进行计算，以及仅使用当前情节的经验进行计算。然而，这两种奖励的使用是不成体系和不理解的。在这项工作中，我们通过对易于解释的任务和具有挑战性的像素设置进行控制实验，揭示了这两种奖励的行为。我们发现，这两种奖励在不同的设置中成功，情境奖励在情节之间共享结构很少的情况下最为有效，而全局奖励在共享结构更多的情况下有效。我们开发了一个概念性框架，通过考虑上下文中的值函数方差，使这种共享结构的概念明确，并提供了一种统一方法。",
    "tldr": "本研究探讨了利用全局和情境奖励进行探索的研究，发现情境奖励在共享结构很少的情况下更有效，而全局奖励则在共享结构更多的情况下更有效，并开发了一个框架以更好地理解共享结构。",
    "en_tdlr": "This study explores using global and episodic bonuses for exploration and finds that episodic bonuses are more effective when there is little shared structure, while global bonuses are more effective when there is more shared structure. A framework is developed to better understand shared structure by considering the variance of the value function across contexts."
}