{
    "title": "Efficient Alternating Minimization with Applications to Weighted Low Rank Approximation. (arXiv:2306.04169v1 [cs.LG])",
    "abstract": "Weighted low rank approximation is a fundamental problem in numerical linear algebra, and it has many applications in machine learning. Given a matrix $M \\in \\mathbb{R}^{n \\times n}$, a weight matrix $W \\in \\mathbb{R}_{\\geq 0}^{n \\times n}$, a parameter $k$, the goal is to output two matrices $U, V \\in \\mathbb{R}^{n \\times k}$ such that $\\| W \\circ (M - U V) \\|_F$ is minimized, where $\\circ$ denotes the Hadamard product. Such a problem is known to be NP-hard and even hard to approximate [RSW16]. Meanwhile, alternating minimization is a good heuristic solution for approximating weighted low rank approximation. The work [LLR16] shows that, under mild assumptions, alternating minimization does provide provable guarantees. In this work, we develop an efficient and robust framework for alternating minimization. For weighted low rank approximation, this improves the runtime of [LLR16] from $n^2 k^2$ to $n^2k$. At the heart of our work framework is a high-accuracy multiple response regression",
    "link": "http://arxiv.org/abs/2306.04169",
    "context": "Title: Efficient Alternating Minimization with Applications to Weighted Low Rank Approximation. (arXiv:2306.04169v1 [cs.LG])\nAbstract: Weighted low rank approximation is a fundamental problem in numerical linear algebra, and it has many applications in machine learning. Given a matrix $M \\in \\mathbb{R}^{n \\times n}$, a weight matrix $W \\in \\mathbb{R}_{\\geq 0}^{n \\times n}$, a parameter $k$, the goal is to output two matrices $U, V \\in \\mathbb{R}^{n \\times k}$ such that $\\| W \\circ (M - U V) \\|_F$ is minimized, where $\\circ$ denotes the Hadamard product. Such a problem is known to be NP-hard and even hard to approximate [RSW16]. Meanwhile, alternating minimization is a good heuristic solution for approximating weighted low rank approximation. The work [LLR16] shows that, under mild assumptions, alternating minimization does provide provable guarantees. In this work, we develop an efficient and robust framework for alternating minimization. For weighted low rank approximation, this improves the runtime of [LLR16] from $n^2 k^2$ to $n^2k$. At the heart of our work framework is a high-accuracy multiple response regression",
    "path": "papers/23/06/2306.04169.json",
    "total_tokens": 783,
    "translated_title": "高效交替最小化及其在加权低秩逼近中的应用",
    "translated_abstract": "加权低秩逼近是数值线性代数中的一个基本问题，在机器学习中有许多应用。本文提出了一种高效且鲁棒的交替最小化框架，用于求解该问题，并将运行时间从 n^2k^2 优化到了 n^2k。在我们的框架的核心是一种高精度的多响应回归方法。",
    "tldr": "本文提出了一种高效的求解加权低秩逼近问题的交替最小化框架，运行时间优化到了 n^2k，核心方法是一种高精度的多响应回归方法。",
    "en_tdlr": "This paper proposes an efficient alternating minimization framework to solve the problem of weighted low rank approximation, with runtime optimization from n^2k^2 to n^2k, and introduces a high-accuracy multiple response regression method as the core approach of the framework."
}