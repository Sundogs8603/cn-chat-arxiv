{
    "title": "Comparing a composite model versus chained models to locate a nearest visual object. (arXiv:2306.01551v1 [cs.CL])",
    "abstract": "Extracting information from geographic images and text is crucial for autonomous vehicles to determine in advance the best cell stations to connect to along their future path. Multiple artificial neural network models can address this challenge; however, there is no definitive guidance on the selection of an appropriate model for such use cases. Therefore, we experimented two architectures to solve such a task: a first architecture with chained models where each model in the chain addresses a sub-task of the task; and a second architecture with a single model that addresses the whole task. Our results showed that these two architectures achieved the same level performance with a root mean square error (RMSE) of 0.055 and 0.056; The findings further revealed that when the task can be decomposed into sub-tasks, the chain architecture exhibits a twelve-fold increase in training speed compared to the composite model. Nevertheless, the composite model significantly alleviates the burden of ",
    "link": "http://arxiv.org/abs/2306.01551",
    "context": "Title: Comparing a composite model versus chained models to locate a nearest visual object. (arXiv:2306.01551v1 [cs.CL])\nAbstract: Extracting information from geographic images and text is crucial for autonomous vehicles to determine in advance the best cell stations to connect to along their future path. Multiple artificial neural network models can address this challenge; however, there is no definitive guidance on the selection of an appropriate model for such use cases. Therefore, we experimented two architectures to solve such a task: a first architecture with chained models where each model in the chain addresses a sub-task of the task; and a second architecture with a single model that addresses the whole task. Our results showed that these two architectures achieved the same level performance with a root mean square error (RMSE) of 0.055 and 0.056; The findings further revealed that when the task can be decomposed into sub-tasks, the chain architecture exhibits a twelve-fold increase in training speed compared to the composite model. Nevertheless, the composite model significantly alleviates the burden of ",
    "path": "papers/23/06/2306.01551.json",
    "total_tokens": 921,
    "translated_title": "比较组合模型和链式模型来定位最近的视觉对象",
    "translated_abstract": "从地理图像和文本中提取信息对于自动驾驶车辆事先确定沿其未来路径连接到的最佳小区站点至关重要。多个人工神经网络模型可以解决这个挑战，但对于此类用例的选择适当模型没有明确定义的指导意见。因此，我们试验了两种架构来解决这样的任务：第一种链式模型架构，其中链中的每个模型都处理任务的子任务; 第二种是单个模型架构，可处理整个任务。我们的结果表明，这两种架构的表现水平相同，均为0.055和0.056的均方根误差(RMSE)；研究结果进一步显示，当任务可以分解成子任务时，链式架构的训练速度比组合模型提高了12倍。然而，组合模型显著减轻了用户在配置链式模型时的负担。",
    "tldr": "该研究比较了两种架构（链式模型和组合模型）在定位最近的视觉对象方面的表现，结果显示两种架构的均方根误差（RMSE）都相同，但当任务可以分解成子任务时，链式架构的训练速度提高了12倍。"
}