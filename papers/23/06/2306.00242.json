{
    "title": "Combinatorial Neural Bandits. (arXiv:2306.00242v1 [stat.ML])",
    "abstract": "We consider a contextual combinatorial bandit problem where in each round a learning agent selects a subset of arms and receives feedback on the selected arms according to their scores. The score of an arm is an unknown function of the arm's feature. Approximating this unknown score function with deep neural networks, we propose algorithms: Combinatorial Neural UCB ($\\texttt{CN-UCB}$) and Combinatorial Neural Thompson Sampling ($\\texttt{CN-TS}$). We prove that $\\texttt{CN-UCB}$ achieves $\\tilde{\\mathcal{O}}(\\tilde{d} \\sqrt{T})$ or $\\tilde{\\mathcal{O}}(\\sqrt{\\tilde{d} T K})$ regret, where $\\tilde{d}$ is the effective dimension of a neural tangent kernel matrix, $K$ is the size of a subset of arms, and $T$ is the time horizon. For $\\texttt{CN-TS}$, we adapt an optimistic sampling technique to ensure the optimism of the sampled combinatorial action, achieving a worst-case (frequentist) regret of $\\tilde{\\mathcal{O}}(\\tilde{d} \\sqrt{TK})$. To the best of our knowledge, these are the first ",
    "link": "http://arxiv.org/abs/2306.00242",
    "context": "Title: Combinatorial Neural Bandits. (arXiv:2306.00242v1 [stat.ML])\nAbstract: We consider a contextual combinatorial bandit problem where in each round a learning agent selects a subset of arms and receives feedback on the selected arms according to their scores. The score of an arm is an unknown function of the arm's feature. Approximating this unknown score function with deep neural networks, we propose algorithms: Combinatorial Neural UCB ($\\texttt{CN-UCB}$) and Combinatorial Neural Thompson Sampling ($\\texttt{CN-TS}$). We prove that $\\texttt{CN-UCB}$ achieves $\\tilde{\\mathcal{O}}(\\tilde{d} \\sqrt{T})$ or $\\tilde{\\mathcal{O}}(\\sqrt{\\tilde{d} T K})$ regret, where $\\tilde{d}$ is the effective dimension of a neural tangent kernel matrix, $K$ is the size of a subset of arms, and $T$ is the time horizon. For $\\texttt{CN-TS}$, we adapt an optimistic sampling technique to ensure the optimism of the sampled combinatorial action, achieving a worst-case (frequentist) regret of $\\tilde{\\mathcal{O}}(\\tilde{d} \\sqrt{TK})$. To the best of our knowledge, these are the first ",
    "path": "papers/23/06/2306.00242.json",
    "total_tokens": 970,
    "translated_title": "组合神经臂的研究",
    "translated_abstract": "我们研究了一种上下文组合臂问题，其中学习代理在每一轮选择一组臂并根据其分数接收反馈。臂的得分是臂特征的未知函数。通过使用深度神经网络来近似这个未知的得分函数，我们提出了算法：组合神经UCB（CN-UCB）和组合神经汤普森抽样（CN-TS）。我们证明，CN-UCB可以达到$\\tilde{\\mathcal{O}}(\\tilde{d} \\sqrt{T})$或 $\\tilde{\\mathcal{O}}(\\sqrt{\\tilde{d} T K})$遗憾值，其中$\\tilde{d}$是神经切向核矩阵的有效维度，$K$是一组臂的大小，$T$是时间跨度。对于CN-TS，我们采用一种乐观抽样技术来确保组合动作的乐观性，达到最差情况（频率学派）遗憾为$\\tilde{\\mathcal{O}}(\\tilde{d} \\sqrt{TK})$。据我们所知，这是第一个解决此类组合臂问题的算法框架。",
    "tldr": "该论文提出了两个组合神经臂算法，通过使用深度神经网络来近似未知得分函数，这是处理类似问题的第一个算法框架。",
    "en_tdlr": "This paper proposes two combinatorial neural bandit algorithms that approximate unknown score functions using deep neural networks, and provides the first algorithmic framework to address such combinatorial bandit problem."
}