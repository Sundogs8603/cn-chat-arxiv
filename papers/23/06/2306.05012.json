{
    "title": "Sequence-to-Sequence Model with Transformer-based Attention Mechanism and Temporal Pooling for Non-Intrusive Load Monitoring. (arXiv:2306.05012v1 [eess.SP])",
    "abstract": "This paper presents a novel Sequence-to-Sequence (Seq2Seq) model based on a transformer-based attention mechanism and temporal pooling for Non-Intrusive Load Monitoring (NILM) of smart buildings. The paper aims to improve the accuracy of NILM by using a deep learning-based method. The proposed method uses a Seq2Seq model with a transformer-based attention mechanism to capture the long-term dependencies of NILM data. Additionally, temporal pooling is used to improve the model's accuracy by capturing both the steady-state and transient behavior of appliances. The paper evaluates the proposed method on a publicly available dataset and compares the results with other state-of-the-art NILM techniques. The results demonstrate that the proposed method outperforms the existing methods in terms of both accuracy and computational efficiency.",
    "link": "http://arxiv.org/abs/2306.05012",
    "context": "Title: Sequence-to-Sequence Model with Transformer-based Attention Mechanism and Temporal Pooling for Non-Intrusive Load Monitoring. (arXiv:2306.05012v1 [eess.SP])\nAbstract: This paper presents a novel Sequence-to-Sequence (Seq2Seq) model based on a transformer-based attention mechanism and temporal pooling for Non-Intrusive Load Monitoring (NILM) of smart buildings. The paper aims to improve the accuracy of NILM by using a deep learning-based method. The proposed method uses a Seq2Seq model with a transformer-based attention mechanism to capture the long-term dependencies of NILM data. Additionally, temporal pooling is used to improve the model's accuracy by capturing both the steady-state and transient behavior of appliances. The paper evaluates the proposed method on a publicly available dataset and compares the results with other state-of-the-art NILM techniques. The results demonstrate that the proposed method outperforms the existing methods in terms of both accuracy and computational efficiency.",
    "path": "papers/23/06/2306.05012.json",
    "total_tokens": 855,
    "translated_title": "基于Transformer注意机制和时间池化的序列到序列模型用于非侵入性负荷监测",
    "translated_abstract": "本文提出了一种新的基于Transformer注意机制和时间池化的序列到序列(Seq2Seq)模型，用于智能建筑的非侵入式负载监测(NILM)。该方法旨在通过深度学习方法提高NILM的准确性。所提出的方法利用Seq2Seq模型和Transformer注意机制捕捉NILM数据的长期依赖关系。此外，采用时间池化来通过捕捉电器的稳态和瞬态行为来提高模型的准确性。本文在公开数据集上评估了所提出的方法，并将结果与其他最先进的NILM技术进行了比较。结果表明，该方法在准确性和计算效率方面优于现有方法。",
    "tldr": "本文提出了一种新的基于Transformer注意机制和时间池化的Seq2Seq模型，用于智能建筑的非侵入式负载监测。该方法利用深度学习方法提高NILM的准确性，并通过时间池化来提高模型的准确性，最终优于现有方法。",
    "en_tdlr": "This paper proposes a novel Seq2Seq model based on a transformer-based attention mechanism and temporal pooling for Non-Intrusive Load Monitoring (NILM) in smart buildings. The proposed method captures the long-term dependencies of NILM data and improves model accuracy by using deep learning-based methods and temporal pooling. The results show that this method outperforms existing techniques in both accuracy and computational efficiency."
}