{
    "title": "Long-form analogies generated by chatGPT lack human-like psycholinguistic properties. (arXiv:2306.04537v1 [cs.CL])",
    "abstract": "Psycholinguistic analyses provide a means of evaluating large language model (LLM) output and making systematic comparisons to human-generated text. These methods can be used to characterize the psycholinguistic properties of LLM output and illustrate areas where LLMs fall short in comparison to human-generated text. In this work, we apply psycholinguistic methods to evaluate individual sentences from long-form analogies about biochemical concepts. We compare analogies generated by human subjects enrolled in introductory biochemistry courses to analogies generated by chatGPT. We perform a supervised classification analysis using 78 features extracted from Coh-metrix that analyze text cohesion, language, and readability (Graesser et. al., 2004). Results illustrate high performance for classifying student-generated and chatGPT-generated analogies. To evaluate which features contribute most to model performance, we use a hierarchical clustering approach. Results from this analysis illustr",
    "link": "http://arxiv.org/abs/2306.04537",
    "context": "Title: Long-form analogies generated by chatGPT lack human-like psycholinguistic properties. (arXiv:2306.04537v1 [cs.CL])\nAbstract: Psycholinguistic analyses provide a means of evaluating large language model (LLM) output and making systematic comparisons to human-generated text. These methods can be used to characterize the psycholinguistic properties of LLM output and illustrate areas where LLMs fall short in comparison to human-generated text. In this work, we apply psycholinguistic methods to evaluate individual sentences from long-form analogies about biochemical concepts. We compare analogies generated by human subjects enrolled in introductory biochemistry courses to analogies generated by chatGPT. We perform a supervised classification analysis using 78 features extracted from Coh-metrix that analyze text cohesion, language, and readability (Graesser et. al., 2004). Results illustrate high performance for classifying student-generated and chatGPT-generated analogies. To evaluate which features contribute most to model performance, we use a hierarchical clustering approach. Results from this analysis illustr",
    "path": "papers/23/06/2306.04537.json",
    "total_tokens": 887,
    "translated_title": "ChatGPT 生成的长形比喻缺乏类人的心理语言学特性",
    "translated_abstract": "心理语言学分析提供了一种评估大型语言模型（LLM）输出并将其与人类生成文本进行系统比较的手段。这些方法可用于表征LLM输出的心理语言学特性，并说明LLM在哪些领域与人类生成文本相比存在不足。本文在生物化学概念的长形比喻中应用心理语言学方法来评估单个句子。我们将入门生物化学课程中的人类对象生成的比喻与chatGPT生成的比喻进行比较。我们使用从Coh-metrix中提取的78个特征进行监督分类分析，分析文本的连贯性，语言和可读性（Graesser等，2004）。结果表明，分类学生生成的比喻和chatGPT生成的比喻的性能很高。为了评估哪些特征对模型性能做出了最大贡献，我们使用分层聚类方法。从这个分析中得出的结果说明了chatGPT生成的比喻缺乏人的心理语言学特性。",
    "tldr": "本研究使用心理语言学方法评估了来自 chatGPT 和人类的长形比喻，发现 chatGPT 生成的比喻缺乏人的心理语言学特性。",
    "en_tdlr": "This study evaluates long-form analogies about biochemical concepts generated by chatGPT and humans using psycholinguistic methods. Results show that chatGPT-generated analogies lack human-like psycholinguistic properties."
}