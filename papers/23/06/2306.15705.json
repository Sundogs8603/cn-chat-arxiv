{
    "title": "On the Universal Adversarial Perturbations for Efficient Data-free Adversarial Detection. (arXiv:2306.15705v1 [cs.CL])",
    "abstract": "Detecting adversarial samples that are carefully crafted to fool the model is a critical step to socially-secure applications. However, existing adversarial detection methods require access to sufficient training data, which brings noteworthy concerns regarding privacy leakage and generalizability. In this work, we validate that the adversarial sample generated by attack algorithms is strongly related to a specific vector in the high-dimensional inputs. Such vectors, namely UAPs (Universal Adversarial Perturbations), can be calculated without original training data. Based on this discovery, we propose a data-agnostic adversarial detection framework, which induces different responses between normal and adversarial samples to UAPs. Experimental results show that our method achieves competitive detection performance on various text classification tasks, and maintains an equivalent time consumption to normal inference.",
    "link": "http://arxiv.org/abs/2306.15705",
    "context": "Title: On the Universal Adversarial Perturbations for Efficient Data-free Adversarial Detection. (arXiv:2306.15705v1 [cs.CL])\nAbstract: Detecting adversarial samples that are carefully crafted to fool the model is a critical step to socially-secure applications. However, existing adversarial detection methods require access to sufficient training data, which brings noteworthy concerns regarding privacy leakage and generalizability. In this work, we validate that the adversarial sample generated by attack algorithms is strongly related to a specific vector in the high-dimensional inputs. Such vectors, namely UAPs (Universal Adversarial Perturbations), can be calculated without original training data. Based on this discovery, we propose a data-agnostic adversarial detection framework, which induces different responses between normal and adversarial samples to UAPs. Experimental results show that our method achieves competitive detection performance on various text classification tasks, and maintains an equivalent time consumption to normal inference.",
    "path": "papers/23/06/2306.15705.json",
    "total_tokens": 987,
    "translated_title": "关于用于高效的无数据对抗检测的通用对抗扰动",
    "translated_abstract": "检测经过精心设计的对抗样本以欺骗模型是确保社交安全应用的关键步骤。然而，现有的对抗检测方法需要访问足够的训练数据，这引发了与隐私泄露和通用性相关的明显关注。在这项工作中，我们验证了攻击算法产生的对抗样本与高维输入中的特定向量密切相关。这些向量称为通用对抗扰动（UAPs），可以在没有原始训练数据的情况下计算得出。基于这一发现，我们提出了一个无数据对抗检测框架，该框架通过对通用对抗扰动对正常样本和对抗样本产生不同的反应。实验结果显示，我们的方法在各种文本分类任务上具有竞争力的检测性能，并且维持了与正常推断相等的时间消耗。",
    "tldr": "本论文提出了一个用于高效的无数据对抗检测的通用对抗扰动方法，通过发现对抗样本与高维输入中的特定向量的关系，计算出通用对抗扰动（UAPs）。基于此，提出了一个无数据对抗检测框架，通过对UAPs对正常样本和对抗样本的反应产生不同的结果，从而实现了在各种文本分类任务上具有竞争力的检测性能。具体实验结果显示，该方法维持了与正常推断相等的时间消耗。"
}