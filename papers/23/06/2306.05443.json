{
    "title": "PIXIU: A Large Language Model, Instruction Data and Evaluation Benchmark for Finance. (arXiv:2306.05443v1 [cs.CL])",
    "abstract": "Although large language models (LLMs) has shown great performance on natural language processing (NLP) in the financial domain, there are no publicly available financial tailtored LLMs, instruction tuning datasets, and evaluation benchmarks, which is critical for continually pushing forward the open-source development of financial artificial intelligence (AI). This paper introduces PIXIU, a comprehensive framework including the first financial LLM based on fine-tuning LLaMA with instruction data, the first instruction data with 136K data samples to support the fine-tuning, and an evaluation benchmark with 5 tasks and 9 datasets. We first construct the large-scale multi-task instruction data considering a variety of financial tasks, financial document types, and financial data modalities. We then propose a financial LLM called FinMA by fine-tuning LLaMA with the constructed dataset to be able to follow instructions for various financial tasks. To support the evaluation of financial LLMs",
    "link": "http://arxiv.org/abs/2306.05443",
    "context": "Title: PIXIU: A Large Language Model, Instruction Data and Evaluation Benchmark for Finance. (arXiv:2306.05443v1 [cs.CL])\nAbstract: Although large language models (LLMs) has shown great performance on natural language processing (NLP) in the financial domain, there are no publicly available financial tailtored LLMs, instruction tuning datasets, and evaluation benchmarks, which is critical for continually pushing forward the open-source development of financial artificial intelligence (AI). This paper introduces PIXIU, a comprehensive framework including the first financial LLM based on fine-tuning LLaMA with instruction data, the first instruction data with 136K data samples to support the fine-tuning, and an evaluation benchmark with 5 tasks and 9 datasets. We first construct the large-scale multi-task instruction data considering a variety of financial tasks, financial document types, and financial data modalities. We then propose a financial LLM called FinMA by fine-tuning LLaMA with the constructed dataset to be able to follow instructions for various financial tasks. To support the evaluation of financial LLMs",
    "path": "papers/23/06/2306.05443.json",
    "total_tokens": 1037,
    "translated_title": "PIXIU：面向金融领域的大型语言模型、指令数据和评估基准",
    "translated_abstract": "虽然大型语言模型在金融领域的自然语言处理方面表现出色，但缺乏公开的面向金融的语言模型、指令调优数据集和评估基准，这对于不断推进金融人工智能开源发展至关重要。本文提出了PIXIU框架，其中包括基于Fine-tuning LLaMA的第一个金融语言模型、包含136K数据样本用于Fine-tuning的第一个指令数据，以及具有5个任务和9个数据集的评估基准。我们首先考虑各种金融任务、金融文档类型和金融数据模态，构建了大规模的多任务指令数据集。然后，我们利用构建的数据集通过Fine-tuning LLaMA提出了名为FinMA的金融语言模型，以便对各种金融任务进行指令跟随。为了支持金融语言模型的评估",
    "tldr": "本文介绍了PIXIU框架，其中包括基于Fine-tuning LLaMA的第一个金融语言模型、包含136K数据样本用于Fine-tuning的第一个指令数据，以及具有5个任务和9个数据集的评估基准。通过对各种金融任务、金融文档类型和金融数据模态考虑，构建了大规模的多任务指令数据集，利用该数据集提出了名为FinMA的金融语言模型，以便对各种金融任务进行指令跟随。",
    "en_tdlr": "This paper introduces the PIXIU framework, which includes the first financial language model based on fine-tuning LLaMA with instruction data, the first instruction data with 136K data samples, and an evaluation benchmark with 5 tasks and 9 datasets to support the development of financial AI. The large-scale multi-task instruction dataset was constructed considering various financial tasks, document types, and data modalities, and the FinMA model was proposed for following instructions for various financial tasks."
}