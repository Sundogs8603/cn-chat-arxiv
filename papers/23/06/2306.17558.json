{
    "title": "Towards the extraction of robust sign embeddings for low resource sign language recognition. (arXiv:2306.17558v1 [cs.CV])",
    "abstract": "Isolated Sign Language Recognition (SLR) has mostly been applied on relatively large datasets containing signs executed slowly and clearly by a limited group of signers. In real-world scenarios, however, we are met with challenging visual conditions, coarticulated signing, small datasets, and the need for signer independent models. To tackle this difficult problem, we require a robust feature extractor to process the sign language videos. One could expect human pose estimators to be ideal candidates. However, due to a domain mismatch with their training sets and challenging poses in sign language, they lack robustness on sign language data and image based models often still outperform keypoint based models. Furthermore, whereas the common practice of transfer learning with image based models yields even higher accuracy, keypoint based models are typically trained from scratch on every SLR dataset. These factors limit their usefulness for SLR. From the existing literature, it is also no",
    "link": "http://arxiv.org/abs/2306.17558",
    "context": "Title: Towards the extraction of robust sign embeddings for low resource sign language recognition. (arXiv:2306.17558v1 [cs.CV])\nAbstract: Isolated Sign Language Recognition (SLR) has mostly been applied on relatively large datasets containing signs executed slowly and clearly by a limited group of signers. In real-world scenarios, however, we are met with challenging visual conditions, coarticulated signing, small datasets, and the need for signer independent models. To tackle this difficult problem, we require a robust feature extractor to process the sign language videos. One could expect human pose estimators to be ideal candidates. However, due to a domain mismatch with their training sets and challenging poses in sign language, they lack robustness on sign language data and image based models often still outperform keypoint based models. Furthermore, whereas the common practice of transfer learning with image based models yields even higher accuracy, keypoint based models are typically trained from scratch on every SLR dataset. These factors limit their usefulness for SLR. From the existing literature, it is also no",
    "path": "papers/23/06/2306.17558.json",
    "total_tokens": 1070,
    "translated_title": "实现对低资源手势语言识别的稳健手势嵌入提取",
    "translated_abstract": "孤立的手势语言识别通常应用于包含由一组有限手势执行者缓慢而清晰执行的相对大规模数据集。然而，在现实世界的场景中，我们面临着具有挑战性的视觉条件、共同发音的手势、小数据集以及对独立演讲者模型的需求。为了解决这个困难的问题，我们需要一个稳健的特征提取器来处理手势语言视频。人体姿势估计器可以被认为是理想的候选者。然而，由于其训练集与手势语言中具有挑战性的姿势之间存在领域不匹配，它们在手势语言数据和基于图像的模型上仍然缺乏稳健性，关键点基于的模型通常仍然优于基于图像的模型。此外，虽然与基于图像的模型进行迁移学习的常见实践可以获得更高的准确性，但关键点基于的模型通常在每个手势语言识别数据集上都是从头开始训练的。这些因素限制了它们在手势语言识别中的实用性。",
    "tldr": "本研究的目标是实现对低资源手势语言识别的稳健手势嵌入提取。针对当前存在的问题，人体姿势估计器虽然是理想的选择，但由于域不匹配和手势语言中的挑战性姿势，其在手势语言数据上的稳健性有所欠缺。关键点基于的模型仍然优于图像基于的模型，但其训练方式限制了其在手势语言识别中的应用。",
    "en_tdlr": "The aim of this study is to extract robust sign embeddings for low resource sign language recognition. While human pose estimators are ideal candidates, their performance on sign language data is limited due to domain mismatch and challenging poses. Keypoint based models outperform image based models but are limited by the requirement of training from scratch on each dataset"
}