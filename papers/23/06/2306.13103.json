{
    "title": "Evaluating the Robustness of Text-to-image Diffusion Models against Real-world Attacks. (arXiv:2306.13103v1 [cs.CR])",
    "abstract": "Text-to-image (T2I) diffusion models (DMs) have shown promise in generating high-quality images from textual descriptions. The real-world applications of these models require particular attention to their safety and fidelity, but this has not been sufficiently explored. One fundamental question is whether existing T2I DMs are robust against variations over input texts. To answer it, this work provides the first robustness evaluation of T2I DMs against real-world attacks. Unlike prior studies that focus on malicious attacks involving apocryphal alterations to the input texts, we consider an attack space spanned by realistic errors (e.g., typo, glyph, phonetic) that humans can make, to ensure semantic consistency. Given the inherent randomness of the generation process, we develop novel distribution-based attack objectives to mislead T2I DMs. We perform attacks in a black-box manner without any knowledge of the model. Extensive experiments demonstrate the effectiveness of our method for ",
    "link": "http://arxiv.org/abs/2306.13103",
    "context": "Title: Evaluating the Robustness of Text-to-image Diffusion Models against Real-world Attacks. (arXiv:2306.13103v1 [cs.CR])\nAbstract: Text-to-image (T2I) diffusion models (DMs) have shown promise in generating high-quality images from textual descriptions. The real-world applications of these models require particular attention to their safety and fidelity, but this has not been sufficiently explored. One fundamental question is whether existing T2I DMs are robust against variations over input texts. To answer it, this work provides the first robustness evaluation of T2I DMs against real-world attacks. Unlike prior studies that focus on malicious attacks involving apocryphal alterations to the input texts, we consider an attack space spanned by realistic errors (e.g., typo, glyph, phonetic) that humans can make, to ensure semantic consistency. Given the inherent randomness of the generation process, we develop novel distribution-based attack objectives to mislead T2I DMs. We perform attacks in a black-box manner without any knowledge of the model. Extensive experiments demonstrate the effectiveness of our method for ",
    "path": "papers/23/06/2306.13103.json",
    "total_tokens": 981,
    "translated_title": "对抗现实世界攻击下文本到图像扩散模型的鲁棒性评估",
    "translated_abstract": "文本到图像（T2I）扩散模型（DM）展示了从文本描述生成高质量图像的潜力。这些模型的实际应用需要特别关注它们的安全性和保真度，但这方面的研究还不够。一个基本问题是现有的T2I DM是否具有对输入文本的变化鲁棒性。为了回答这个问题，本研究提供了第一个针对现实攻击的T2I DM鲁棒性评估。与以往关注涉及输入文本的虚假修改的恶意攻击的研究不同，我们考虑由人类可以产生的现实误差（例如，打字错误、字符、语音）所构成的攻击范围，以确保语义一致性。考虑到生成过程的固有随机性，我们提出了新的基于分布的攻击目标以误导T2I DM。我们以黑盒方式进行攻击，不需要了解模型的任何信息。大量实验表明了我们的方法在攻击效果上的有效性。",
    "tldr": "本研究对于文本到图像扩散模型（T2I DMs）进行了第一个针对现实攻击的鲁棒性评估，考虑由人类可以产生的现实误差所构成的攻击范围以确保语义一致性。研究表明，我们提出的攻击目标具有较好的攻击效果。"
}