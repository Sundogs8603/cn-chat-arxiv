{
    "title": "Open-Domain Text Evaluation via Meta Distribution Modeling. (arXiv:2306.11879v1 [cs.CL])",
    "abstract": "Recent advances in open-domain text generation models powered by large pre-trained language models (LLMs) have achieved remarkable performance. However, evaluating and controlling these models for desired attributes remains a challenge, as traditional reference-based metrics such as BLEU, ROUGE, and METEOR are insufficient for open-ended generation tasks. Similarly, while trainable discriminator-based evaluation metrics show promise, obtaining high-quality training data is a non-trivial task. In this paper, we introduce a novel approach to evaluate open-domain generation - the Meta-Distribution Methods (MDM). Drawing on the correlation between the rising parameter counts and the improving performance of LLMs, MDM creates a mapping from the contrast of two probabilistic distributions -- one known to be superior to the other -to quality measures, which can be viewed as a distribution of distributions i.e. Meta-Distribution. We investigate MDM for open-domain text generation evaluation ",
    "link": "http://arxiv.org/abs/2306.11879",
    "context": "Title: Open-Domain Text Evaluation via Meta Distribution Modeling. (arXiv:2306.11879v1 [cs.CL])\nAbstract: Recent advances in open-domain text generation models powered by large pre-trained language models (LLMs) have achieved remarkable performance. However, evaluating and controlling these models for desired attributes remains a challenge, as traditional reference-based metrics such as BLEU, ROUGE, and METEOR are insufficient for open-ended generation tasks. Similarly, while trainable discriminator-based evaluation metrics show promise, obtaining high-quality training data is a non-trivial task. In this paper, we introduce a novel approach to evaluate open-domain generation - the Meta-Distribution Methods (MDM). Drawing on the correlation between the rising parameter counts and the improving performance of LLMs, MDM creates a mapping from the contrast of two probabilistic distributions -- one known to be superior to the other -to quality measures, which can be viewed as a distribution of distributions i.e. Meta-Distribution. We investigate MDM for open-domain text generation evaluation ",
    "path": "papers/23/06/2306.11879.json",
    "total_tokens": 934,
    "translated_title": "基于元分布建模的开放领域文本评估",
    "translated_abstract": "最近，基于大型预训练语言模型（LLMs）的开放领域文本生成模型取得了显著的性能提升。然而，为了控制和评估这些模型是否达到所需属性仍然是一个挑战，因为传统的基于参考文本的度量标准如BLEU、ROUGE和METEOR对于开放式生成任务来说是不足够的。同样地，虽然具备训练鉴别器的度量标准表现出了希望的前景，但是获取高质量的训练数据则是一项非常困难的任务。本文提出了一种新颖的方法来评估开放领域文本生成——元分布方法（MDM）。通过考虑LLMs参数数量上升和性能提升之间的相关性，MDM 创造了一个映射，将两个概率分布的对比（一个已知优于另一个）映射到质量度量上，该度量可以视为分布的分布，即元分布。我们研究了MDM在评估开放领域文本生成中的应用。",
    "tldr": "本文提出了一种新颖的开放领域文本生成模型评估方法——元分布方法（MDM），该方法将两个概率分布的对比映射到质量度量上，可以视为分布的分布，其可用于开放领域文本生成的评估。",
    "en_tdlr": "This paper proposes a novel open-domain text generation evaluation method - the Meta-Distribution Methods (MDM), which maps the contrast of two probabilistic distributions to quality measures, viewed as a distribution of distributions, and can be used for evaluating open-domain text generation."
}