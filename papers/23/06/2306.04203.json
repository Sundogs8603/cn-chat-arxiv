{
    "title": "Leveraging Knowledge Graph Embeddings to Enhance Contextual Representations for Relation Extraction. (arXiv:2306.04203v1 [cs.CL])",
    "abstract": "Relation extraction task is a crucial and challenging aspect of Natural Language Processing. Several methods have surfaced as of late, exhibiting notable performance in addressing the task; however, most of these approaches rely on vast amounts of data from large-scale knowledge graphs or language models pretrained on voluminous corpora. In this paper, we hone in on the effective utilization of solely the knowledge supplied by a corpus to create a high-performing model. Our objective is to showcase that by leveraging the hierarchical structure and relational distribution of entities within a corpus without introducing external knowledge, a relation extraction model can achieve significantly enhanced performance. We therefore proposed a relation extraction approach based on the incorporation of pretrained knowledge graph embeddings at the corpus scale into the sentence-level contextual representation. We conducted a series of experiments which revealed promising and very interesting res",
    "link": "http://arxiv.org/abs/2306.04203",
    "context": "Title: Leveraging Knowledge Graph Embeddings to Enhance Contextual Representations for Relation Extraction. (arXiv:2306.04203v1 [cs.CL])\nAbstract: Relation extraction task is a crucial and challenging aspect of Natural Language Processing. Several methods have surfaced as of late, exhibiting notable performance in addressing the task; however, most of these approaches rely on vast amounts of data from large-scale knowledge graphs or language models pretrained on voluminous corpora. In this paper, we hone in on the effective utilization of solely the knowledge supplied by a corpus to create a high-performing model. Our objective is to showcase that by leveraging the hierarchical structure and relational distribution of entities within a corpus without introducing external knowledge, a relation extraction model can achieve significantly enhanced performance. We therefore proposed a relation extraction approach based on the incorporation of pretrained knowledge graph embeddings at the corpus scale into the sentence-level contextual representation. We conducted a series of experiments which revealed promising and very interesting res",
    "path": "papers/23/06/2306.04203.json",
    "total_tokens": 874,
    "translated_title": "利用知识图谱嵌入增强关系提取的上下文表示",
    "translated_abstract": "关系提取是自然语言处理中至关重要且具有挑战性的任务。近年来出现了多种方法，表现出在解决任务方面的显着性能；然而，这些方法中大多数依赖于大规模知识图谱或预先训练在海量语料库上的语言模型的大量数据。本文关注如何有效利用语料库提供的知识来创建高性能模型。我们的目标是展示，在不引入外部知识的情况下，通过利用语料库中实体的分层结构和关系分布，可以显著提高关系提取模型的性能。因此，本文提出了一种基于将预先训练的知识图谱嵌入到句子级上下文表示中的关系提取方法。我们进行了一系列实验，发现结果令人兴奋且很有意思。",
    "tldr": "本论文提出了一种不依赖于大规模知识图谱或预训练语言模型的关系提取方法，通过利用语料库中实体的分层结构和关系分布，将预先训练的知识图谱嵌入到句子级上下文表示中，可以显著提高模型性能。",
    "en_tdlr": "This paper proposes a relation extraction approach that does not rely on large-scale knowledge graphs or pre-trained language models. By leveraging the hierarchical structure and relational distribution of entities within a corpus, pretrained knowledge graph embeddings are incorporated into the sentence-level contextual representation, leading to significantly enhanced model performance."
}