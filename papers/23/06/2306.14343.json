{
    "title": "TCE: A Test-Based Approach to Measuring Calibration Error. (arXiv:2306.14343v1 [stat.ML])",
    "abstract": "This paper proposes a new metric to measure the calibration error of probabilistic binary classifiers, called test-based calibration error (TCE). TCE incorporates a novel loss function based on a statistical test to examine the extent to which model predictions differ from probabilities estimated from data. It offers (i) a clear interpretation, (ii) a consistent scale that is unaffected by class imbalance, and (iii) an enhanced visual representation with repect to the standard reliability diagram. In addition, we introduce an optimality criterion for the binning procedure of calibration error metrics based on a minimal estimation error of the empirical probabilities. We provide a novel computational algorithm for optimal bins under bin-size constraints. We demonstrate properties of TCE through a range of experiments, including multiple real-world imbalanced datasets and ImageNet 1000.",
    "link": "http://arxiv.org/abs/2306.14343",
    "context": "Title: TCE: A Test-Based Approach to Measuring Calibration Error. (arXiv:2306.14343v1 [stat.ML])\nAbstract: This paper proposes a new metric to measure the calibration error of probabilistic binary classifiers, called test-based calibration error (TCE). TCE incorporates a novel loss function based on a statistical test to examine the extent to which model predictions differ from probabilities estimated from data. It offers (i) a clear interpretation, (ii) a consistent scale that is unaffected by class imbalance, and (iii) an enhanced visual representation with repect to the standard reliability diagram. In addition, we introduce an optimality criterion for the binning procedure of calibration error metrics based on a minimal estimation error of the empirical probabilities. We provide a novel computational algorithm for optimal bins under bin-size constraints. We demonstrate properties of TCE through a range of experiments, including multiple real-world imbalanced datasets and ImageNet 1000.",
    "path": "papers/23/06/2306.14343.json",
    "total_tokens": 903,
    "translated_title": "一种基于测试的方法来测量校准误差",
    "translated_abstract": "本文提出了一种用于测量概率二元分类器的校准误差的新指标，称为基于测试的校准误差 (TCE)。TCE采用一种基于统计测试的损失函数来检查模型预测与从数据估计的概率之间的差异程度。它提供了清晰的解释、一个不受类别不平衡影响的一致刻度以及相对于标准可靠性图的增强视觉表示。此外，我们还引入了一个基于经验概率最小估计误差的校准误差分箱程序的最优性准则，提供了一个新的针对限制箱子大小的最优箱子的计算算法。我们通过多个真实世界的不平衡数据集和ImageNet 1000等验证了TCE的特性。",
    "tldr": "本文提出基于测试的校准误差 （TCE）指标，使用了一种新颖的基于统计检验的损失函数来衡量模型预测与数据预估概率之间的差异，相对标准校准误差表示，具有解释清晰、一致刻度和增强视觉表示等优点。",
    "en_tdlr": "This paper proposes a new metric, test-based calibration error (TCE), which uses a novel loss function based on statistical testing to measure the difference between model predictions and probabilities estimated from data. Compared to standard calibration error metrics, TCE offers a clear interpretation, a consistent scale, and an enhanced visual representation. The paper also introduces an optimal binning procedure for calibration error metrics based on minimal estimation error of empirical probabilities. The properties of TCE are demonstrated in experiments with various imbalanced datasets and ImageNet 1000."
}