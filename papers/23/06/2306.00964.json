{
    "title": "Cocktail: Mixing Multi-Modality Controls for Text-Conditional Image Generation",
    "abstract": "arXiv:2306.00964v1 Announce Type: cross  Abstract: Text-conditional diffusion models are able to generate high-fidelity images with diverse contents. However, linguistic representations frequently exhibit ambiguous descriptions of the envisioned objective imagery, requiring the incorporation of additional control signals to bolster the efficacy of text-guided diffusion models. In this work, we propose Cocktail, a pipeline to mix various modalities into one embedding, amalgamated with a generalized ControlNet (gControlNet), a controllable normalisation (ControlNorm), and a spatial guidance sampling method, to actualize multi-modal and spatially-refined control for text-conditional diffusion models. Specifically, we introduce a hyper-network gControlNet, dedicated to the alignment and infusion of the control signals from disparate modalities into the pre-trained diffusion model. gControlNet is capable of accepting flexible modality signals, encompassing the simultaneous reception of any ",
    "link": "https://arxiv.org/abs/2306.00964",
    "context": "Title: Cocktail: Mixing Multi-Modality Controls for Text-Conditional Image Generation\nAbstract: arXiv:2306.00964v1 Announce Type: cross  Abstract: Text-conditional diffusion models are able to generate high-fidelity images with diverse contents. However, linguistic representations frequently exhibit ambiguous descriptions of the envisioned objective imagery, requiring the incorporation of additional control signals to bolster the efficacy of text-guided diffusion models. In this work, we propose Cocktail, a pipeline to mix various modalities into one embedding, amalgamated with a generalized ControlNet (gControlNet), a controllable normalisation (ControlNorm), and a spatial guidance sampling method, to actualize multi-modal and spatially-refined control for text-conditional diffusion models. Specifically, we introduce a hyper-network gControlNet, dedicated to the alignment and infusion of the control signals from disparate modalities into the pre-trained diffusion model. gControlNet is capable of accepting flexible modality signals, encompassing the simultaneous reception of any ",
    "path": "papers/23/06/2306.00964.json",
    "total_tokens": 882,
    "translated_title": "鸡尾酒：混合多模态控制以进行文本条件图像生成",
    "translated_abstract": "arXiv:2306.00964v1 公告类型：交叉 摘要：文本条件扩散模型能够生成具有不同内容的高保真图像。然而，语言表示经常展示对所设想目标图像的模棱两可描述，需要引入额外的控制信号来增强文本引导扩散模型的功效。在这项工作中，我们提出了鸡尾酒，这是一个将各种模态混合为一个嵌入的流水线，与通用控制网络（gControlNet）、可控归一化（ControlNorm）和空间引导采样方法相结合，以实现文本条件扩散模型的多模态和空间精细控制。具体而言，我们引入了一个超网络gControlNet，专门用于将来自不同模态的控制信号与预训练扩散模型进行对齐和融合。gControlNet能够接受灵活的模态信号，包括同时接收任何",
    "tldr": "提出了鸡尾酒方法，将不同模态混合到一个嵌入中，结合通用控制网络、可控归一化和空间引导采样方法，实现了对文本条件扩散模型的多模态和空间精细控制。",
    "en_tdlr": "Introduced Cocktail, a method that mixes different modalities into one embedding, combined with a generalized ControlNet, controllable normalization, and spatial guidance sampling method, achieving multi-modal and spatially refined control for text-conditional diffusion models."
}