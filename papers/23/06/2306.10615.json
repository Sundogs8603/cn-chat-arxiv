{
    "title": "Agnostically Learning Single-Index Models using Omnipredictors. (arXiv:2306.10615v1 [cs.LG])",
    "abstract": "We give the first result for agnostically learning Single-Index Models (SIMs) with arbitrary monotone and Lipschitz activations. All prior work either held only in the realizable setting or required the activation to be known. Moreover, we only require the marginal to have bounded second moments, whereas all prior work required stronger distributional assumptions (such as anticoncentration or boundedness). Our algorithm is based on recent work by [GHK$^+$23] on omniprediction using predictors satisfying calibrated multiaccuracy. Our analysis is simple and relies on the relationship between Bregman divergences (or matching losses) and $\\ell_p$ distances. We also provide new guarantees for standard algorithms like GLMtron and logistic regression in the agnostic setting.",
    "link": "http://arxiv.org/abs/2306.10615",
    "context": "Title: Agnostically Learning Single-Index Models using Omnipredictors. (arXiv:2306.10615v1 [cs.LG])\nAbstract: We give the first result for agnostically learning Single-Index Models (SIMs) with arbitrary monotone and Lipschitz activations. All prior work either held only in the realizable setting or required the activation to be known. Moreover, we only require the marginal to have bounded second moments, whereas all prior work required stronger distributional assumptions (such as anticoncentration or boundedness). Our algorithm is based on recent work by [GHK$^+$23] on omniprediction using predictors satisfying calibrated multiaccuracy. Our analysis is simple and relies on the relationship between Bregman divergences (or matching losses) and $\\ell_p$ distances. We also provide new guarantees for standard algorithms like GLMtron and logistic regression in the agnostic setting.",
    "path": "papers/23/06/2306.10615.json",
    "total_tokens": 927,
    "translated_title": "使用全能预测器对单指数模型进行自主学习",
    "translated_abstract": "我们给出了第一个结果，即在具有任意单调和利普希茨激活的单指数模型（SIM）中进行自主学习。所有之前的工作要么仅适用于可以实现的设置，要么需要知道激活函数。此外，我们仅需要边缘具有有界的二阶矩，而所有之前的工作都需要更强的分布假设（如反浓度或有界性）。我们的算法基于[GHK＋23]最近的全能预测使用符合校准的观察精度的预测器方案。我们的分析简单且依赖于Bregman距离（或匹配损失）与$\\ell_p$距离之间的关系。我们还为GLMtron和逻辑回归等标准算法在不可知设置中提供了新的保证。",
    "tldr": "本文提出了使用全能预测器对单指数模型进行自主学习的方法，且仅需要边缘具有有界的二阶矩。该方法可适用于任意单调和利普希茨激活，并且过往方法中所需的更强分布假设不再需要。研究者们通过匹配损失与$\\ell_p$距离的关系，提供了一种简单的分析方式，并在不可知设置中为标准算法提供了新的保证。",
    "en_tdlr": "This paper proposes a method for agnostic learning of Single-Index Models using omnipredictors with arbitrary monotone and Lipschitz activations, without requiring stronger distributional assumptions, only bounding the marginal's second moments. The analysis is simple and correlates Bregman divergences with $\\ell_p$ distances, and new guarantees for standard algorithms like GLMtron and logistic regression are provided in the agnostic setting."
}