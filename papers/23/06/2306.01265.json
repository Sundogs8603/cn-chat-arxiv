{
    "title": "Calibrating Multimodal Learning. (arXiv:2306.01265v1 [cs.LG])",
    "abstract": "Multimodal machine learning has achieved remarkable progress in a wide range of scenarios. However, the reliability of multimodal learning remains largely unexplored. In this paper, through extensive empirical studies, we identify current multimodal classification methods suffer from unreliable predictive confidence that tend to rely on partial modalities when estimating confidence. Specifically, we find that the confidence estimated by current models could even increase when some modalities are corrupted. To address the issue, we introduce an intuitive principle for multimodal learning, i.e., the confidence should not increase when one modality is removed. Accordingly, we propose a novel regularization technique, i.e., Calibrating Multimodal Learning (CML) regularization, to calibrate the predictive confidence of previous methods. This technique could be flexibly equipped by existing models and improve the performance in terms of confidence calibration, classification accuracy, and mo",
    "link": "http://arxiv.org/abs/2306.01265",
    "context": "Title: Calibrating Multimodal Learning. (arXiv:2306.01265v1 [cs.LG])\nAbstract: Multimodal machine learning has achieved remarkable progress in a wide range of scenarios. However, the reliability of multimodal learning remains largely unexplored. In this paper, through extensive empirical studies, we identify current multimodal classification methods suffer from unreliable predictive confidence that tend to rely on partial modalities when estimating confidence. Specifically, we find that the confidence estimated by current models could even increase when some modalities are corrupted. To address the issue, we introduce an intuitive principle for multimodal learning, i.e., the confidence should not increase when one modality is removed. Accordingly, we propose a novel regularization technique, i.e., Calibrating Multimodal Learning (CML) regularization, to calibrate the predictive confidence of previous methods. This technique could be flexibly equipped by existing models and improve the performance in terms of confidence calibration, classification accuracy, and mo",
    "path": "papers/23/06/2306.01265.json",
    "total_tokens": 853,
    "translated_title": "多模态学习的校准。 （arXiv：2306.01265v1 [cs.LG]）",
    "translated_abstract": "多模态机器学习在各种场景中取得了显着的进展。然而，多模态学习的可靠性仍然大部分未被探索。通过广泛的实证研究，本文发现当前的多模态分类方法存在预测置信度不可靠的问题，往往在估计置信度时依赖于部分模态。具体而言，我们发现当前模型估计的置信度甚至可以增加当某些模态受到损坏时。为了解决这个问题，我们引入一个直观的多模态学习原则，即当去除一个模态时，置信度不应该增加。因此，我们提出了一种新的正则化技术，即校准多模态学习（CML）正则化，来校准先前方法的预测置信度。这种技术可以通过现有模型进行灵活配置，并提高置信度校准、分类准确性和多模态集成学习的性能。",
    "tldr": "本文提出了一个多模态学习的校准方法，可以解决当前方法在预测置信度不可靠的问题，提高模型的分类准确性和置信度校准能力。"
}