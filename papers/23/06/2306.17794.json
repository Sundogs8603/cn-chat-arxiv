{
    "title": "Vision Through the Veil: Differential Privacy in Federated Learning for Medical Image Classification. (arXiv:2306.17794v1 [cs.LG])",
    "abstract": "The proliferation of deep learning applications in healthcare calls for data aggregation across various institutions, a practice often associated with significant privacy concerns. This concern intensifies in medical image analysis, where privacy-preserving mechanisms are paramount due to the data being sensitive in nature. Federated learning, which enables cooperative model training without direct data exchange, presents a promising solution. Nevertheless, the inherent vulnerabilities of federated learning necessitate further privacy safeguards. This study addresses this need by integrating differential privacy, a leading privacy-preserving technique, into a federated learning framework for medical image classification. We introduce a novel differentially private federated learning model and meticulously examine its impacts on privacy preservation and model performance. Our research confirms the existence of a trade-off between model accuracy and privacy settings. However, we demonstr",
    "link": "http://arxiv.org/abs/2306.17794",
    "context": "Title: Vision Through the Veil: Differential Privacy in Federated Learning for Medical Image Classification. (arXiv:2306.17794v1 [cs.LG])\nAbstract: The proliferation of deep learning applications in healthcare calls for data aggregation across various institutions, a practice often associated with significant privacy concerns. This concern intensifies in medical image analysis, where privacy-preserving mechanisms are paramount due to the data being sensitive in nature. Federated learning, which enables cooperative model training without direct data exchange, presents a promising solution. Nevertheless, the inherent vulnerabilities of federated learning necessitate further privacy safeguards. This study addresses this need by integrating differential privacy, a leading privacy-preserving technique, into a federated learning framework for medical image classification. We introduce a novel differentially private federated learning model and meticulously examine its impacts on privacy preservation and model performance. Our research confirms the existence of a trade-off between model accuracy and privacy settings. However, we demonstr",
    "path": "papers/23/06/2306.17794.json",
    "total_tokens": 952,
    "translated_title": "透过面纱看“视觉”：差分隐私在医学图像分类的联邦学习中的应用",
    "translated_abstract": "在医疗保健领域深度学习应用的普及需要跨多个机构进行数据聚合，这常常涉及严重的隐私问题。在医学图像分析中，隐私保护机制至关重要，因为数据具有敏感性。联邦学习使得合作模型训练成为可能，而无需直接交换数据，提供了一个有希望的解决方案。然而，联邦学习的固有漏洞需要更多的隐私保护措施。本研究通过将差分隐私，一种领先的隐私保护技术，整合进医学图像分类的联邦学习框架中，解决了这一需求。我们引入了一种新颖的差分隐私联邦学习模型，并详细研究了其对隐私保护和模型性能的影响。我们的研究证实了模型准确性与隐私设置之间存在权衡。然而，我们也证明了通过合适的隐私设置，仍然可以在医学图像分类中实现较高的模型性能。",
    "tldr": "本研究将差分隐私技术应用于医学图像分类的联邦学习中，通过引入一种新颖的差分隐私联邦学习模型，平衡模型准确性与隐私设置，为医疗保健领域的深度学习应用提供了隐私保护解决方案。",
    "en_tdlr": "This study integrates differential privacy technique into federated learning for medical image classification, balancing model accuracy and privacy settings, and providing a privacy-preserving solution for deep learning applications in healthcare."
}