{
    "title": "Deceptive AI Ecosystems: The Case of ChatGPT. (arXiv:2306.13671v1 [cs.CY])",
    "abstract": "ChatGPT, an AI chatbot, has gained popularity for its capability in generating human-like responses. However, this feature carries several risks, most notably due to its deceptive behaviour such as offering users misleading or fabricated information that could further cause ethical issues. To better understand the impact of ChatGPT on our social, cultural, economic, and political interactions, it is crucial to investigate how ChatGPT operates in the real world where various societal pressures influence its development and deployment. This paper emphasizes the need to study ChatGPT \"in the wild\", as part of the ecosystem it is embedded in, with a strong focus on user involvement. We examine the ethical challenges stemming from ChatGPT's deceptive human-like interactions and propose a roadmap for developing more transparent and trustworthy chatbots. Central to our approach is the importance of proactive risk assessment and user participation in shaping the future of chatbot technology.",
    "link": "http://arxiv.org/abs/2306.13671",
    "context": "Title: Deceptive AI Ecosystems: The Case of ChatGPT. (arXiv:2306.13671v1 [cs.CY])\nAbstract: ChatGPT, an AI chatbot, has gained popularity for its capability in generating human-like responses. However, this feature carries several risks, most notably due to its deceptive behaviour such as offering users misleading or fabricated information that could further cause ethical issues. To better understand the impact of ChatGPT on our social, cultural, economic, and political interactions, it is crucial to investigate how ChatGPT operates in the real world where various societal pressures influence its development and deployment. This paper emphasizes the need to study ChatGPT \"in the wild\", as part of the ecosystem it is embedded in, with a strong focus on user involvement. We examine the ethical challenges stemming from ChatGPT's deceptive human-like interactions and propose a roadmap for developing more transparent and trustworthy chatbots. Central to our approach is the importance of proactive risk assessment and user participation in shaping the future of chatbot technology.",
    "path": "papers/23/06/2306.13671.json",
    "total_tokens": 893,
    "translated_title": "欺骗性人工智能生态系统：以ChatGPT为例",
    "translated_abstract": "ChatGPT是一款人工智能聊天机器人，因其生成类人回复的能力而备受欢迎。然而，该功能存在多种风险，尤其是由于其欺骗性行为，例如向用户提供误导或虚假信息，可能会引起伦理问题。为了更好地理解ChatGPT对我们的社会、文化、经济和政治互动的影响，有必要调查ChatGPT在现实世界中的运作方式，各种社会压力影响着它的发展和部署。本文强调了在ChatGPT所处的生态系统中“野外”研究ChatGPT的必要性，着重于用户参与。我们研究了ChatGPT的欺骗性类人交互所带来的伦理挑战，并提出了一个制定更透明、可信的聊天机器人的路线图。我们方法的核心是积极的风险评估和用户参与塑造聊天机器人技术的未来。",
    "tldr": "本文探讨以ChatGPT为例的人工智能聊天机器人中的欺骗行为所带来的伦理挑战，提出了进行积极风险评估和用户参与塑造技术发展的可行性方案。",
    "en_tdlr": "This paper examines the ethical challenges brought by deceptive behavior in AI chatbots using ChatGPT as an example, and proposes a feasible solution of proactive risk assessment and user participation in shaping technological development."
}