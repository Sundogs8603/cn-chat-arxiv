{
    "title": "BatchGFN: Generative Flow Networks for Batch Active Learning. (arXiv:2306.15058v1 [cs.LG])",
    "abstract": "We introduce BatchGFN -- a novel approach for pool-based active learning that uses generative flow networks to sample sets of data points proportional to a batch reward. With an appropriate reward function to quantify the utility of acquiring a batch, such as the joint mutual information between the batch and the model parameters, BatchGFN is able to construct highly informative batches for active learning in a principled way. We show our approach enables sampling near-optimal utility batches at inference time with a single forward pass per point in the batch in toy regression problems. This alleviates the computational complexity of batch-aware algorithms and removes the need for greedy approximations to find maximizers for the batch reward. We also present early results for amortizing training across acquisition steps, which will enable scaling to real-world tasks.",
    "link": "http://arxiv.org/abs/2306.15058",
    "context": "Title: BatchGFN: Generative Flow Networks for Batch Active Learning. (arXiv:2306.15058v1 [cs.LG])\nAbstract: We introduce BatchGFN -- a novel approach for pool-based active learning that uses generative flow networks to sample sets of data points proportional to a batch reward. With an appropriate reward function to quantify the utility of acquiring a batch, such as the joint mutual information between the batch and the model parameters, BatchGFN is able to construct highly informative batches for active learning in a principled way. We show our approach enables sampling near-optimal utility batches at inference time with a single forward pass per point in the batch in toy regression problems. This alleviates the computational complexity of batch-aware algorithms and removes the need for greedy approximations to find maximizers for the batch reward. We also present early results for amortizing training across acquisition steps, which will enable scaling to real-world tasks.",
    "path": "papers/23/06/2306.15058.json",
    "total_tokens": 960,
    "translated_title": "BatchGFN: 用于批量主动学习的生成流网络",
    "translated_abstract": "我们引入了BatchGFN - 一种新颖的基于池的主动学习方法，该方法使用生成流网络根据批量奖励采样数据点集合。通过适当的奖励函数来量化获取批量的效用，如批量与模型参数之间的联合互信息，BatchGFN能够以原则性的方式构建高度信息量的批量，用于主动学习。我们展示了我们的方法在玩具回归问题中可以在推理时间内通过对批量中每个点进行单次前向传递来采样近乎最优效用的批量，这减轻了面向批量的算法的计算复杂性，并消除了寻找批量奖励最大化器的贪婪近似的需求。我们还提出了跨获取步骤分摊训练的早期结果，这将实现对实际任务的扩展。",
    "tldr": "BatchGFN是一种用于批量主动学习的新颖方法，通过使用生成流网络根据批量奖励采样数据点集合，能够以原则性的方式构建高度信息量的批量，用于主动学习。通过在推理时间内进行单次前向传递来采样近乎最优效用的批量，减轻了面向批量的算法的计算复杂性，并消除了贪婪近似的需求。提出了跨获取步骤分摊训练的早期结果，实现了对实际任务的扩展。",
    "en_tdlr": "BatchGFN is a novel method for batch active learning that constructs highly informative batches using generative flow networks based on batch rewards. It alleviates the computational complexity of batch-aware algorithms by sampling near-optimal utility batches with a single forward pass per point in the batch, and eliminates the need for greedy approximations. Early results on amortizing training across acquisition steps enable scaling to real-world tasks."
}