{
    "title": "Optimal Sets and Solution Paths of ReLU Networks. (arXiv:2306.00119v1 [cs.LG])",
    "abstract": "We develop an analytical framework to characterize the set of optimal ReLU neural networks by reformulating the non-convex training problem as a convex program. We show that the global optima of the convex parameterization are given by a polyhedral set and then extend this characterization to the optimal set of the non-convex training objective. Since all stationary points of the ReLU training problem can be represented as optima of sub-sampled convex programs, our work provides a general expression for all critical points of the non-convex objective. We then leverage our results to provide an optimal pruning algorithm for computing minimal networks, establish conditions for the regularization path of ReLU networks to be continuous, and develop sensitivity results for minimal ReLU networks.",
    "link": "http://arxiv.org/abs/2306.00119",
    "context": "Title: Optimal Sets and Solution Paths of ReLU Networks. (arXiv:2306.00119v1 [cs.LG])\nAbstract: We develop an analytical framework to characterize the set of optimal ReLU neural networks by reformulating the non-convex training problem as a convex program. We show that the global optima of the convex parameterization are given by a polyhedral set and then extend this characterization to the optimal set of the non-convex training objective. Since all stationary points of the ReLU training problem can be represented as optima of sub-sampled convex programs, our work provides a general expression for all critical points of the non-convex objective. We then leverage our results to provide an optimal pruning algorithm for computing minimal networks, establish conditions for the regularization path of ReLU networks to be continuous, and develop sensitivity results for minimal ReLU networks.",
    "path": "papers/23/06/2306.00119.json",
    "total_tokens": 779,
    "translated_title": "ReLU网络的最优集合和解路径",
    "translated_abstract": "我们开发了一个分析框架，通过将非凸训练问题重新定义为凸规划问题，来刻画最优ReLU神经网络集合。我们证明了凸参数化的全局最优解由一个多面体集合给出，并将这个表征扩展到了非凸训练目标的最优集。由于ReLU训练问题的所有稳定点都可以表示为子采样凸规划的最优解，因此我们的工作为所有非凸目标的临界点提供了通用表达式。然后，我们利用我们的结果提供了计算最小网络的最优剪枝算法，建立了ReLU网络正则化路径连续的条件，并为最小ReLU网络提供了灵敏度结果。",
    "tldr": "本研究开发了一个分析框架，通过凸规划表征所有ReLU网络的最优集合和解路径，并提供了最小网络的最优剪枝算法，建立了ReLU网络正则化路径连续的条件，并为最小ReLU网络提供了灵敏度结果。",
    "en_tdlr": "This research develops an analytical framework to characterize the optimal set and solution paths of all ReLU networks using convex parameterization. It provides an optimal pruning algorithm for computing minimal networks, establishes conditions for the regularization path of ReLU networks to be continuous, and develops sensitivity results for minimal ReLU networks."
}