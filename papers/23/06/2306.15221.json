{
    "title": "[Re] Double Sampling Randomized Smoothing. (arXiv:2306.15221v1 [cs.LG])",
    "abstract": "This paper is a contribution to the reproducibility challenge in the field of machine learning, specifically addressing the issue of certifying the robustness of neural networks (NNs) against adversarial perturbations. The proposed Double Sampling Randomized Smoothing (DSRS) framework overcomes the limitations of existing methods by using an additional smoothing distribution to improve the robustness certification. The paper provides a clear manifestation of DSRS for a generalized family of Gaussian smoothing and a computationally efficient method for implementation. The experiments on MNIST and CIFAR-10 demonstrate the effectiveness of DSRS, consistently certifying larger robust radii compared to other methods. Also various ablations studies are conducted to further analyze the hyperparameters and effect of adversarial training methods on the certified radius by the proposed framework.",
    "link": "http://arxiv.org/abs/2306.15221",
    "context": "Title: [Re] Double Sampling Randomized Smoothing. (arXiv:2306.15221v1 [cs.LG])\nAbstract: This paper is a contribution to the reproducibility challenge in the field of machine learning, specifically addressing the issue of certifying the robustness of neural networks (NNs) against adversarial perturbations. The proposed Double Sampling Randomized Smoothing (DSRS) framework overcomes the limitations of existing methods by using an additional smoothing distribution to improve the robustness certification. The paper provides a clear manifestation of DSRS for a generalized family of Gaussian smoothing and a computationally efficient method for implementation. The experiments on MNIST and CIFAR-10 demonstrate the effectiveness of DSRS, consistently certifying larger robust radii compared to other methods. Also various ablations studies are conducted to further analyze the hyperparameters and effect of adversarial training methods on the certified radius by the proposed framework.",
    "path": "papers/23/06/2306.15221.json",
    "total_tokens": 801,
    "translated_title": "[Re]双抽样随机平滑方法",
    "translated_abstract": "本文是机器学习领域可重复性挑战的一个贡献，特别针对神经网络(NNs)对抗扰动的鲁棒性认证问题。提出的双抽样随机平滑(DSRS)框架通过使用额外的平滑分布来改善鲁棒性认证，克服了现有方法的局限性。本文清晰地阐述了DSRS在广义高斯平滑族的案例，并提供了一种计算高效的实现方法。在MNIST和CIFAR-10上的实验证明了DSRS的有效性，相比其他方法，始终证明了更大的鲁棒半径。此外，还进行了各种消融研究，以进一步分析超参数和对抗训练方法对所提出框架所认证半径的影响。",
    "tldr": "该论文提出了一种名为双抽样随机平滑的方法，通过使用额外的平滑分布改善了神经网络对抗扰动的鲁棒性认证，实验证明了该方法的有效性。",
    "en_tdlr": "This paper proposes a method called Double Sampling Randomized Smoothing (DSRS) that improves the robustness certification of neural networks against adversarial perturbations by using an additional smoothing distribution, and its effectiveness is demonstrated through experiments."
}