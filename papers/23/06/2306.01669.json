{
    "title": "Enhancing CLIP with CLIP: Exploring Pseudolabeling for Limited-Label Prompt Tuning. (arXiv:2306.01669v1 [cs.CV])",
    "abstract": "Fine-tuning vision-language models (VLMs) like CLIP to downstream tasks is often necessary to optimize their performance. However, a major obstacle is the limited availability of labeled data. We study the use of pseudolabels, i.e., heuristic labels for unlabeled data, to enhance CLIP via prompt tuning. Conventional pseudolabeling trains a model on labeled data and then generates labels for unlabeled data. VLMs' zero-shot capabilities enable a ``second generation'' of pseudolabeling approaches that do not require task-specific training on labeled data. By using zero-shot pseudolabels as a source of supervision, we observe that learning paradigms such as semi-supervised, transductive zero-shot, and unsupervised learning can all be seen as optimizing the same loss function. This unified view enables the development of versatile training strategies that are applicable across learning paradigms. We investigate them on image classification tasks where CLIP exhibits limitations, by varying p",
    "link": "http://arxiv.org/abs/2306.01669",
    "context": "Title: Enhancing CLIP with CLIP: Exploring Pseudolabeling for Limited-Label Prompt Tuning. (arXiv:2306.01669v1 [cs.CV])\nAbstract: Fine-tuning vision-language models (VLMs) like CLIP to downstream tasks is often necessary to optimize their performance. However, a major obstacle is the limited availability of labeled data. We study the use of pseudolabels, i.e., heuristic labels for unlabeled data, to enhance CLIP via prompt tuning. Conventional pseudolabeling trains a model on labeled data and then generates labels for unlabeled data. VLMs' zero-shot capabilities enable a ``second generation'' of pseudolabeling approaches that do not require task-specific training on labeled data. By using zero-shot pseudolabels as a source of supervision, we observe that learning paradigms such as semi-supervised, transductive zero-shot, and unsupervised learning can all be seen as optimizing the same loss function. This unified view enables the development of versatile training strategies that are applicable across learning paradigms. We investigate them on image classification tasks where CLIP exhibits limitations, by varying p",
    "path": "papers/23/06/2306.01669.json",
    "total_tokens": 910,
    "translated_title": "用CLIP增强CLIP: 探索有限标注提示调参的伪标注方法",
    "translated_abstract": "微调视觉-语言模型（VLMs），如CLIP，以优化其性能往往是必要的。然而，主要障碍是有限数量的标注数据。本文研究使用伪标注（即非标注数据的启发式标签）通过提示调参改进CLIP的方法。传统伪标注方法会在有标注数据上训练模型，然后为无标注数据生成标签。VLM的零样本能力使“第二代”伪标注方法不需要在有标注数据上进行任务特定的训练。通过使用零样本伪标签作为监督来源，我们发现可以将半监督、过渡零样本和无监督学习等学习范式视为优化相同损失函数。这种统一的视角能够实现适用于各种学习范式的多功能培训策略的发展。我们通过改变提示的方式来探索这些培训策略，以解决 CLIP 在图像分类任务中存在的局限性。",
    "tldr": "本文探索使用伪标注方法通过提示调参改进CLIP的方法，通过使用零样本伪标签来优化图像分类任务中有限标注数据的问题。",
    "en_tdlr": "This paper explores the use of pseudolabeling through prompt tuning to enhance CLIP by using zero-shot pseudolabels as a source of supervision, which enables the development of versatile training strategies that are applicable across different learning paradigms, and solves the problem of limited labeled data in image classification tasks."
}