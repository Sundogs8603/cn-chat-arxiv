{
    "title": "Instruction Tuned Models are Quick Learners. (arXiv:2306.05539v1 [cs.CL])",
    "abstract": "Instruction tuning of language models has demonstrated the ability to enhance model generalization to unseen tasks via in-context learning using a few examples. However, typical supervised learning still requires a plethora of downstream training data for finetuning. Often in real-world situations, there is a scarcity of data available for finetuning, falling somewhere between few shot inference and fully supervised finetuning. In this work, we demonstrate the sample efficiency of instruction tuned models over various tasks by estimating the minimal downstream training data required by them to perform transfer learning and match the performance of state-of-the-art (SOTA) supervised models. We conduct experiments on 119 tasks from Super Natural Instructions (SuperNI) in both the single task learning (STL) and multi task learning (MTL) settings. Our findings reveal that, in the STL setting, instruction tuned models equipped with 25% of the downstream train data surpass the SOTA performan",
    "link": "http://arxiv.org/abs/2306.05539",
    "context": "Title: Instruction Tuned Models are Quick Learners. (arXiv:2306.05539v1 [cs.CL])\nAbstract: Instruction tuning of language models has demonstrated the ability to enhance model generalization to unseen tasks via in-context learning using a few examples. However, typical supervised learning still requires a plethora of downstream training data for finetuning. Often in real-world situations, there is a scarcity of data available for finetuning, falling somewhere between few shot inference and fully supervised finetuning. In this work, we demonstrate the sample efficiency of instruction tuned models over various tasks by estimating the minimal downstream training data required by them to perform transfer learning and match the performance of state-of-the-art (SOTA) supervised models. We conduct experiments on 119 tasks from Super Natural Instructions (SuperNI) in both the single task learning (STL) and multi task learning (MTL) settings. Our findings reveal that, in the STL setting, instruction tuned models equipped with 25% of the downstream train data surpass the SOTA performan",
    "path": "papers/23/06/2306.05539.json",
    "total_tokens": 889,
    "translated_title": "指令调节模型是快速学习者",
    "translated_abstract": "通过在上下文学习中使用少量示例展示了语言模型的指令调节如何增强模型对未见任务的概括能力。然而，通常的监督学习仍需要大量的下游训练数据进行微调。在现实世界的情况下，微调往往仅有少量数据可用，介于少样本推理和完全监督微调之间。在本文中，我们展示了指令调节模型在各种任务中的效率，通过估计其执行转移学习并匹配最先进监督模型所需的最小下游训练数据。我们在单任务学习（STL）和多任务学习（MTL）设置下，在来自超级自然指令（SuperNI）的119个任务上进行了实验。我们的发现表明，在STL设置下，配备25％下游训练数据的指令调节模型超过了最先进的监督性能。",
    "tldr": "本文研究了指令调节模型在各种任务中的效率，结果表明，在单任务学习（STL）设置下，配备25％下游训练数据的指令调节模型超过了最先进的监督性能。",
    "en_tdlr": "This paper demonstrates the sample efficiency of instruction tuned models over various tasks by estimating the minimal downstream training data required by them to perform transfer learning and match the performance of state-of-the-art (SOTA) supervised models. The findings reveal that, in the single task learning (STL) setting, instruction tuned models equipped with 25% of the downstream train data surpass the SOTA performance."
}