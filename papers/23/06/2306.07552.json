{
    "title": "Galactic: Scaling End-to-End Reinforcement Learning for Rearrangement at 100k Steps-Per-Second. (arXiv:2306.07552v1 [cs.LG])",
    "abstract": "We present Galactic, a large-scale simulation and reinforcement-learning (RL) framework for robotic mobile manipulation in indoor environments. Specifically, a Fetch robot (equipped with a mobile base, 7DoF arm, RGBD camera, egomotion, and onboard sensing) is spawned in a home environment and asked to rearrange objects - by navigating to an object, picking it up, navigating to a target location, and then placing the object at the target location.  Galactic is fast. In terms of simulation speed (rendering + physics), Galactic achieves over 421,000 steps-per-second (SPS) on an 8-GPU node, which is 54x faster than Habitat 2.0 (7699 SPS). More importantly, Galactic was designed to optimize the entire rendering + physics + RL interplay since any bottleneck in the interplay slows down training. In terms of simulation+RL speed (rendering + physics + inference + learning), Galactic achieves over 108,000 SPS, which 88x faster than Habitat 2.0 (1243 SPS).  These massive speed-ups not only drasti",
    "link": "http://arxiv.org/abs/2306.07552",
    "context": "Title: Galactic: Scaling End-to-End Reinforcement Learning for Rearrangement at 100k Steps-Per-Second. (arXiv:2306.07552v1 [cs.LG])\nAbstract: We present Galactic, a large-scale simulation and reinforcement-learning (RL) framework for robotic mobile manipulation in indoor environments. Specifically, a Fetch robot (equipped with a mobile base, 7DoF arm, RGBD camera, egomotion, and onboard sensing) is spawned in a home environment and asked to rearrange objects - by navigating to an object, picking it up, navigating to a target location, and then placing the object at the target location.  Galactic is fast. In terms of simulation speed (rendering + physics), Galactic achieves over 421,000 steps-per-second (SPS) on an 8-GPU node, which is 54x faster than Habitat 2.0 (7699 SPS). More importantly, Galactic was designed to optimize the entire rendering + physics + RL interplay since any bottleneck in the interplay slows down training. In terms of simulation+RL speed (rendering + physics + inference + learning), Galactic achieves over 108,000 SPS, which 88x faster than Habitat 2.0 (1243 SPS).  These massive speed-ups not only drasti",
    "path": "papers/23/06/2306.07552.json",
    "total_tokens": 1054,
    "translated_title": "Galactic: 将端到端强化学习扩展到每秒 100k 步的重组问题的规模化研究",
    "translated_abstract": "我们提出了 Galactic，一个用于室内环境中机器人移动操作的大规模仿真和强化学习（RL）框架。具体来说，我们在一个家用环境中生成 Fetch 机器人（带有移动基座、7 自由度机械臂、RGBD 相机、自运动和板载传感器），并要求它重新排列物体 - 通过导航到物体、拾取它、导航到目标位置，然后将物体放置在目标位置上。Galactic 速度快。在仿真速度（渲染+物理）方面，Galactic 在 8-GPU 节点上实现了每秒 421,000 步（SPS），比 Habitat 2.0 快了 54 倍（7699 SPS）。更重要的是，Galactic 被设计用于优化整个渲染+物理+RL 的相互作用，因为相互作用中的任何瓶颈都会减慢训练。在仿真+RL 速度（渲染+物理+推理+学习）方面，Galactic 实现了每秒超过 108,000 SPS，比 Habitat 2.0 快了 88 倍（1243 SPS）。这些巨大的加速不仅显著加快了训练速度，还使 RL 能够在未来的机器人操作任务中实现更高的成功率和效率。",
    "tldr": "Galactic是一个针对室内物体重排问题的大规模仿真和强化学习框架。这个框架可以在每秒 100k 步上运行，比其他相似框架快很多。",
    "en_tdlr": "Galactic is a large-scale simulation and reinforcement-learning (RL) framework for robotic mobile manipulation in indoor environments. It can run at 100k steps-per-second, which is much faster than other similar frameworks."
}