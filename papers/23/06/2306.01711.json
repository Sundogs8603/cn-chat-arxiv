{
    "title": "OMNI: Open-endedness via Models of human Notions of Interestingness. (arXiv:2306.01711v1 [cs.AI])",
    "abstract": "Open-ended algorithms aim to learn new, interesting behaviors forever. That requires a vast environment search space, but there are thus infinitely many possible tasks. Even after filtering for tasks the current agent can learn (i.e., learning progress), countless learnable yet uninteresting tasks remain (e.g., minor variations of previously learned tasks). An Achilles Heel of open-endedness research is the inability to quantify (and thus prioritize) tasks that are not just learnable, but also $\\textit{interesting}$ (e.g., worthwhile and novel). We propose solving this problem by $\\textit{Open-endedness via Models of human Notions of Interestingness}$ (OMNI). The insight is that we can utilize large (language) models (LMs) as a model of interestingness (MoI), because they $\\textit{already}$ internalize human concepts of interestingness from training on vast amounts of human-generated data, where humans naturally write about what they find interesting or boring. We show that LM-based Mo",
    "link": "http://arxiv.org/abs/2306.01711",
    "context": "Title: OMNI: Open-endedness via Models of human Notions of Interestingness. (arXiv:2306.01711v1 [cs.AI])\nAbstract: Open-ended algorithms aim to learn new, interesting behaviors forever. That requires a vast environment search space, but there are thus infinitely many possible tasks. Even after filtering for tasks the current agent can learn (i.e., learning progress), countless learnable yet uninteresting tasks remain (e.g., minor variations of previously learned tasks). An Achilles Heel of open-endedness research is the inability to quantify (and thus prioritize) tasks that are not just learnable, but also $\\textit{interesting}$ (e.g., worthwhile and novel). We propose solving this problem by $\\textit{Open-endedness via Models of human Notions of Interestingness}$ (OMNI). The insight is that we can utilize large (language) models (LMs) as a model of interestingness (MoI), because they $\\textit{already}$ internalize human concepts of interestingness from training on vast amounts of human-generated data, where humans naturally write about what they find interesting or boring. We show that LM-based Mo",
    "path": "papers/23/06/2306.01711.json",
    "total_tokens": 941,
    "tldr": "本论文提出了OMNI算法，该算法利用了语言模型作为有趣性的模型，从而可以量化待学习的有趣任务，为无尽探索提供了一个新的方向。",
    "en_tdlr": "The paper proposes the OMNI algorithm that uses language models as a model of interestingness to quantify and prioritize interesting and learnable tasks, thus offering a new direction for open-ended exploration."
}