{
    "title": "Delphic Offline Reinforcement Learning under Nonidentifiable Hidden Confounding. (arXiv:2306.01157v1 [cs.LG])",
    "abstract": "A prominent challenge of offline reinforcement learning (RL) is the issue of hidden confounding: unobserved variables may influence both the actions taken by the agent and the observed outcomes. Hidden confounding can compromise the validity of any causal conclusion drawn from data and presents a major obstacle to effective offline RL. In the present paper, we tackle the problem of hidden confounding in the nonidentifiable setting. We propose a definition of uncertainty due to hidden confounding bias, termed delphic uncertainty, which uses variation over world models compatible with the observations, and differentiate it from the well-known epistemic and aleatoric uncertainties. We derive a practical method for estimating the three types of uncertainties, and construct a pessimistic offline RL algorithm to account for them. Our method does not assume identifiability of the unobserved confounders, and attempts to reduce the amount of confounding bias. We demonstrate through extensive ex",
    "link": "http://arxiv.org/abs/2306.01157",
    "context": "Title: Delphic Offline Reinforcement Learning under Nonidentifiable Hidden Confounding. (arXiv:2306.01157v1 [cs.LG])\nAbstract: A prominent challenge of offline reinforcement learning (RL) is the issue of hidden confounding: unobserved variables may influence both the actions taken by the agent and the observed outcomes. Hidden confounding can compromise the validity of any causal conclusion drawn from data and presents a major obstacle to effective offline RL. In the present paper, we tackle the problem of hidden confounding in the nonidentifiable setting. We propose a definition of uncertainty due to hidden confounding bias, termed delphic uncertainty, which uses variation over world models compatible with the observations, and differentiate it from the well-known epistemic and aleatoric uncertainties. We derive a practical method for estimating the three types of uncertainties, and construct a pessimistic offline RL algorithm to account for them. Our method does not assume identifiability of the unobserved confounders, and attempts to reduce the amount of confounding bias. We demonstrate through extensive ex",
    "path": "papers/23/06/2306.01157.json",
    "total_tokens": 975,
    "translated_title": "非可识别的隐变量下的Delphic离线强化学习",
    "translated_abstract": "离线强化学习中的一个突出挑战是隐藏的混淆问题：未观察到的变量可能影响到智能体采取的行动和观察到的结果。隐藏的混淆可能损害从数据中得出的任何因果结论的有效性，并且是有效的离线强化学习的一个主要障碍。在这篇论文中，我们解决了非可识别设置中的隐藏混淆问题。我们提出了一种基于与观察兼容的世界模型的差异来定义由隐藏混淆偏差引起的不确定性，称为Delphic不确定性，并将其与众所周知的认知和随机不确定性区分开来。我们导出了一种实际方法来估计这三种类型的不确定性，并构建了一种悲观的离线强化学习算法来解决它们。我们的方法不假定未观察到的混淆因子是可识别的，并且试图减少混淆偏差的量。通过广泛的实验表明，我们的方法在存在非可识别的隐藏混淆时优于现有的离线强化学习算法。",
    "tldr": "本文提出了一种名为Delphic不确定性的方法来解决离线强化学习中的隐藏混淆问题，并通过实验表明该方法在非可识别的隐藏混淆情况下优于现有算法。",
    "en_tdlr": "This paper proposes a method called Delphic uncertainty to address hidden confounding in offline reinforcement learning, and demonstrates through experiments that the method outperforms existing algorithms in the presence of nonidentifiable hidden confounding."
}