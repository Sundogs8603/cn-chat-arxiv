{
    "title": "PriorBand: Practical Hyperparameter Optimization in the Age of Deep Learning. (arXiv:2306.12370v1 [cs.LG])",
    "abstract": "Hyperparameters of Deep Learning (DL) pipelines are crucial for their downstream performance. While a large number of methods for Hyperparameter Optimization (HPO) have been developed, their incurred costs are often untenable for modern DL. Consequently, manual experimentation is still the most prevalent approach to optimize hyperparameters, relying on the researcher's intuition, domain knowledge, and cheap preliminary explorations. To resolve this misalignment between HPO algorithms and DL researchers, we propose PriorBand, an HPO algorithm tailored to DL, able to utilize both expert beliefs and cheap proxy tasks. Empirically, we demonstrate PriorBand's efficiency across a range of DL benchmarks and show its gains under informative expert input and robustness against poor expert beliefs",
    "link": "http://arxiv.org/abs/2306.12370",
    "context": "Title: PriorBand: Practical Hyperparameter Optimization in the Age of Deep Learning. (arXiv:2306.12370v1 [cs.LG])\nAbstract: Hyperparameters of Deep Learning (DL) pipelines are crucial for their downstream performance. While a large number of methods for Hyperparameter Optimization (HPO) have been developed, their incurred costs are often untenable for modern DL. Consequently, manual experimentation is still the most prevalent approach to optimize hyperparameters, relying on the researcher's intuition, domain knowledge, and cheap preliminary explorations. To resolve this misalignment between HPO algorithms and DL researchers, we propose PriorBand, an HPO algorithm tailored to DL, able to utilize both expert beliefs and cheap proxy tasks. Empirically, we demonstrate PriorBand's efficiency across a range of DL benchmarks and show its gains under informative expert input and robustness against poor expert beliefs",
    "path": "papers/23/06/2306.12370.json",
    "total_tokens": 762,
    "translated_title": "PriorBand: 深度学习下的实用超参数优化方法。",
    "translated_abstract": "深度学习（DL）流程中的超参数对其下游性能至关重要。尽管已经开发了许多超参数优化方法，但其代价往往对现代深度学习不可行。因此，手动实验仍是优化超参数的主要方法，依赖于研究人员的直觉、领域知识和廉价的初步探索。为了解决HPO算法和DL研究人员之间的这种不匹配，我们提出了PriorBand，这是一种针对DL量身定制的HPO算法，能够利用专家信念和廉价的代理任务。实验证明，PriorBand在一系列DL基准测试中的效率，以及在提供有效专家输入和抗击不良专家信念方面的收益。",
    "tldr": "提出了一种针对深度学习量身定制的超参数优化算法PriorBand，能够同时利用专家信念和廉价的代理任务，具有高效性和抗干扰能力。",
    "en_tdlr": "PriorBand is a hyperparameter optimization algorithm specifically designed for deep learning, which can utilize both expert beliefs and cheap proxy tasks to improve its efficiency and robustness."
}