{
    "title": "Relevant Entity Selection: Knowledge Graph Bootstrapping via Zero-Shot Analogical Pruning. (arXiv:2306.16296v1 [cs.AI])",
    "abstract": "Knowledge Graph Construction (KGC) can be seen as an iterative process starting from a high quality nucleus that is refined by knowledge extraction approaches in a virtuous loop. Such a nucleus can be obtained from knowledge existing in an open KG like Wikidata. However, due to the size of such generic KGs, integrating them as a whole may entail irrelevant content and scalability issues. We propose an analogy-based approach that starts from seed entities of interest in a generic KG, and keeps or prunes their neighboring entities. We evaluate our approach on Wikidata through two manually labeled datasets that contain either domain-homogeneous or -heterogeneous seed entities. We empirically show that our analogy-based approach outperforms LSTM, Random Forest, SVM, and MLP, with a drastically lower number of parameters. We also evaluate its generalization potential in a transfer learning setting. These results advocate for the further integration of analogy-based inference in tasks relate",
    "link": "http://arxiv.org/abs/2306.16296",
    "context": "Title: Relevant Entity Selection: Knowledge Graph Bootstrapping via Zero-Shot Analogical Pruning. (arXiv:2306.16296v1 [cs.AI])\nAbstract: Knowledge Graph Construction (KGC) can be seen as an iterative process starting from a high quality nucleus that is refined by knowledge extraction approaches in a virtuous loop. Such a nucleus can be obtained from knowledge existing in an open KG like Wikidata. However, due to the size of such generic KGs, integrating them as a whole may entail irrelevant content and scalability issues. We propose an analogy-based approach that starts from seed entities of interest in a generic KG, and keeps or prunes their neighboring entities. We evaluate our approach on Wikidata through two manually labeled datasets that contain either domain-homogeneous or -heterogeneous seed entities. We empirically show that our analogy-based approach outperforms LSTM, Random Forest, SVM, and MLP, with a drastically lower number of parameters. We also evaluate its generalization potential in a transfer learning setting. These results advocate for the further integration of analogy-based inference in tasks relate",
    "path": "papers/23/06/2306.16296.json",
    "total_tokens": 963,
    "translated_title": "相关实体选择：通过零样本类比修剪进行知识图谱引导",
    "translated_abstract": "知识图谱构建可以被视为一个迭代过程，从高质量的核心开始，通过知识提取方法不断改进。这样的核心可以从像Wikidata这样的开放式知识图谱中获得。然而，由于这种通用知识图谱的规模，将其作为整体集成可能会包含无关内容和可扩展性问题。我们提出了一种基于类比的方法，从通用知识图谱中的感兴趣种子实体开始，并保留或修剪其相邻实体。我们通过两个手动标记的数据集 在Wikidata上评估了我们的方法，这些数据集包含领域同质或异质的种子实体。我们从实证上证明了我们的基于类比的方法优于LSTM，随机森林，支持向量机和多层感知器，且参数数量大大减少。我们还在迁移学习环境中评估了其泛化能力。这些结果对于进一步将基于类比的推理集成到相关任务中提供了支持。",
    "tldr": "本文提出了一种基于类比的方法，通过选择和修剪相关实体，从而引导知识图谱的构建。实证结果显示，这种方法在两个领域和异质种子实体的数据集上优于其他机器学习方法，并具有较低的参数数量。这些结果支持在相关任务中进一步应用类比推理。",
    "en_tdlr": "This paper proposes an analogy-based approach to guide the construction of knowledge graphs by selecting and pruning relevant entities. Experimental results show that this method outperforms other machine learning methods on datasets with domain-homogeneous and -heterogeneous seed entities, with a lower number of parameters. These results support the further application of analogy inference in related tasks."
}