{
    "title": "Fix Fairness, Don't Ruin Accuracy: Performance Aware Fairness Repair using AutoML. (arXiv:2306.09297v2 [cs.SE] UPDATED)",
    "abstract": "Machine learning (ML) is increasingly being used in critical decision-making software, but incidents have raised questions about the fairness of ML predictions. To address this issue, new tools and methods are needed to mitigate bias in ML-based software. Previous studies have proposed bias mitigation algorithms that only work in specific situations and often result in a loss of accuracy. Our proposed solution is a novel approach that utilizes automated machine learning (AutoML) techniques to mitigate bias. Our approach includes two key innovations: a novel optimization function and a fairness-aware search space. By improving the default optimization function of AutoML and incorporating fairness objectives, we are able to mitigate bias with little to no loss of accuracy. Additionally, we propose a fairness-aware search space pruning method for AutoML to reduce computational cost and repair time. Our approach, built on the state-of-the-art Auto-Sklearn tool, is designed to reduce bias i",
    "link": "http://arxiv.org/abs/2306.09297",
    "context": "Title: Fix Fairness, Don't Ruin Accuracy: Performance Aware Fairness Repair using AutoML. (arXiv:2306.09297v2 [cs.SE] UPDATED)\nAbstract: Machine learning (ML) is increasingly being used in critical decision-making software, but incidents have raised questions about the fairness of ML predictions. To address this issue, new tools and methods are needed to mitigate bias in ML-based software. Previous studies have proposed bias mitigation algorithms that only work in specific situations and often result in a loss of accuracy. Our proposed solution is a novel approach that utilizes automated machine learning (AutoML) techniques to mitigate bias. Our approach includes two key innovations: a novel optimization function and a fairness-aware search space. By improving the default optimization function of AutoML and incorporating fairness objectives, we are able to mitigate bias with little to no loss of accuracy. Additionally, we propose a fairness-aware search space pruning method for AutoML to reduce computational cost and repair time. Our approach, built on the state-of-the-art Auto-Sklearn tool, is designed to reduce bias i",
    "path": "papers/23/06/2306.09297.json",
    "total_tokens": 981,
    "translated_title": "修复公平性，而不是破坏准确性：使用AutoML的性能感知公平修复",
    "translated_abstract": "机器学习（ML）越来越多地被用于关键决策软件中，但事故引发了关于ML预测公平性的质疑。为了解决这个问题，需要新的工具和方法来减少基于ML的软件中的偏见。先前的研究提出了偏见缓解算法，但这些算法只能在特定情况下工作，并且通常会导致准确性损失。我们提出了一种新颖的方法，利用自动机器学习（AutoML）技术来减少偏见。我们的方法包括两个关键创新：一种新颖的优化函数和一个公平感知的搜索空间。通过改进AutoML的默认优化函数并结合公平目标，我们能够在几乎不损失准确性的情况下减少偏见。此外，我们还提出了一种适用于AutoML的公平感知搜索空间修剪方法，以减少计算成本和修复时间。我们的方法建立在最先进的Auto-Sklearn工具上，旨在减少偏见。",
    "tldr": "本文提出了一个使用AutoML技术来减少偏见的新方法，该方法通过改进优化函数和搜索空间，并结合公平目标，在几乎不损失准确性的情况下减少基于ML的软件中的偏见。同时提出了一个适用于AutoML的公平感知搜索空间修剪方法，以减少计算成本和修复时间。",
    "en_tdlr": "This paper proposes a novel approach using AutoML techniques to mitigate bias in ML-based software with little to no loss of accuracy. By improving the optimization function and incorporating fairness objectives, it reduces bias and introduces a fairness-aware search space. Additionally, it suggests a search space pruning method to reduce computational cost and repair time."
}