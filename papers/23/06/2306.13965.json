{
    "title": "Boosting Model Inversion Attacks with Adversarial Examples. (arXiv:2306.13965v1 [cs.CR])",
    "abstract": "Model inversion attacks involve reconstructing the training data of a target model, which raises serious privacy concerns for machine learning models. However, these attacks, especially learning-based methods, are likely to suffer from low attack accuracy, i.e., low classification accuracy of these reconstructed data by machine learning classifiers. Recent studies showed an alternative strategy of model inversion attacks, GAN-based optimization, can improve the attack accuracy effectively. However, these series of GAN-based attacks reconstruct only class-representative training data for a class, whereas learning-based attacks can reconstruct diverse data for different training data in each class. Hence, in this paper, we propose a new training paradigm for a learning-based model inversion attack that can achieve higher attack accuracy in a black-box setting. First, we regularize the training process of the attack model with an added semantic loss function and, second, we inject adversa",
    "link": "http://arxiv.org/abs/2306.13965",
    "context": "Title: Boosting Model Inversion Attacks with Adversarial Examples. (arXiv:2306.13965v1 [cs.CR])\nAbstract: Model inversion attacks involve reconstructing the training data of a target model, which raises serious privacy concerns for machine learning models. However, these attacks, especially learning-based methods, are likely to suffer from low attack accuracy, i.e., low classification accuracy of these reconstructed data by machine learning classifiers. Recent studies showed an alternative strategy of model inversion attacks, GAN-based optimization, can improve the attack accuracy effectively. However, these series of GAN-based attacks reconstruct only class-representative training data for a class, whereas learning-based attacks can reconstruct diverse data for different training data in each class. Hence, in this paper, we propose a new training paradigm for a learning-based model inversion attack that can achieve higher attack accuracy in a black-box setting. First, we regularize the training process of the attack model with an added semantic loss function and, second, we inject adversa",
    "path": "papers/23/06/2306.13965.json",
    "total_tokens": 965,
    "translated_title": "用对抗样本提升模型反演攻击能力",
    "translated_abstract": "模型反演攻击指恢复目标模型的训练数据，这对机器学习模型的隐私构成严重威胁。然而，这些攻击尤其是基于学习的方法，通常会面临低攻击精度的问题，即机器学习分类器对这些恢复数据的分类精度较低。对此，最近的研究表明，基于 GAN 的模型反演攻击可以有效提高攻击精度。然而，这些基于 GAN 的攻击只重构每类的类代表性训练数据，而基于学习的攻击可以重构不同类别中多样化的训练数据。因此，在本文中，我们提出了一种新的基于学习的模型反演攻击训练范式，可以在黑盒设置下实现更高的攻击精度。具体而言，我们通过添加语义损失函数来规范化攻击模型的训练过程，其次，我们在攻击模型训练数据中注入对抗样本，使其对抗性攻击更加鲁棒。实验结果表明，我们的方法在攻击精度和成功率方面优于现有方法。",
    "tldr": "本文提出了一种新的基于学习的模型反演攻击训练方法，通过添加语义损失函数和注入对抗样本，可以在黑盒设置下提高攻击精度和成功率。",
    "en_tdlr": "This paper proposes a new learning-based training method for model inversion attacks, which improves attack accuracy and success rate in black-box settings by adding a semantic loss function and injecting adversarial examples into the attack model training data."
}