{
    "title": "Optimal Exploration for Model-Based RL in Nonlinear Systems. (arXiv:2306.09210v1 [cs.LG])",
    "abstract": "Learning to control unknown nonlinear dynamical systems is a fundamental problem in reinforcement learning and control theory. A commonly applied approach is to first explore the environment (exploration), learn an accurate model of it (system identification), and then compute an optimal controller with the minimum cost on this estimated system (policy optimization). While existing work has shown that it is possible to learn a uniformly good model of the system~\\citep{mania2020active}, in practice, if we aim to learn a good controller with a low cost on the actual system, certain system parameters may be significantly more critical than others, and we therefore ought to focus our exploration on learning such parameters.  In this work, we consider the setting of nonlinear dynamical systems and seek to formally quantify, in such settings, (a) which parameters are most relevant to learning a good controller, and (b) how we can best explore so as to minimize uncertainty in such parameters.",
    "link": "http://arxiv.org/abs/2306.09210",
    "context": "Title: Optimal Exploration for Model-Based RL in Nonlinear Systems. (arXiv:2306.09210v1 [cs.LG])\nAbstract: Learning to control unknown nonlinear dynamical systems is a fundamental problem in reinforcement learning and control theory. A commonly applied approach is to first explore the environment (exploration), learn an accurate model of it (system identification), and then compute an optimal controller with the minimum cost on this estimated system (policy optimization). While existing work has shown that it is possible to learn a uniformly good model of the system~\\citep{mania2020active}, in practice, if we aim to learn a good controller with a low cost on the actual system, certain system parameters may be significantly more critical than others, and we therefore ought to focus our exploration on learning such parameters.  In this work, we consider the setting of nonlinear dynamical systems and seek to formally quantify, in such settings, (a) which parameters are most relevant to learning a good controller, and (b) how we can best explore so as to minimize uncertainty in such parameters.",
    "path": "papers/23/06/2306.09210.json",
    "total_tokens": 865,
    "translated_title": "非线性系统模型下的模型基RL优化探索",
    "translated_abstract": "在强化学习和控制理论中，学习控制未知的非线性动态系统是一个根本性的问题。一种常用的方法是首先探索环境（探索），学习准确的模型（系统识别），然后在此估计的系统上计算最小成本的最优控制器（策略优化）。虽然现有的工作已经表明学习得到一致好的系统模型是可能的 ~\\citep{mania2020active}~ ，但是在实践中，如果我们的目标是在实际系统上学习一个低成本的优秀控制器，则某些系统参数可能比其他参数更为关键，因此我们需要将探索集中在学习这些参数上。",
    "tldr": "本论文研究控制未知的非线性动态系统的model-based RL问题，需要找出哪些参数最关键，并针对这些参数最优化探索策略来最小化不确定性。"
}