{
    "title": "Effective Transfer of Pretrained Large Visual Model for Fabric Defect Segmentation via Specifc Knowledge Injection. (arXiv:2306.16186v1 [cs.CV])",
    "abstract": "Fabric defect segmentation is integral to textile quality control. Despite this, the scarcity of high-quality annotated data and the diversity of fabric defects present significant challenges to the application of deep learning in this field. These factors limit the generalization and segmentation performance of existing models, impeding their ability to handle the complexity of diverse fabric types and defects. To overcome these obstacles, this study introduces an innovative method to infuse specialized knowledge of fabric defects into the Segment Anything Model (SAM), a large-scale visual model. By introducing and training a unique set of fabric defect-related parameters, this approach seamlessly integrates domain-specific knowledge into SAM without the need for extensive modifications to the pre-existing model parameters. The revamped SAM model leverages generalized image understanding learned from large-scale natural image datasets while incorporating fabric defect-specific knowled",
    "link": "http://arxiv.org/abs/2306.16186",
    "context": "Title: Effective Transfer of Pretrained Large Visual Model for Fabric Defect Segmentation via Specifc Knowledge Injection. (arXiv:2306.16186v1 [cs.CV])\nAbstract: Fabric defect segmentation is integral to textile quality control. Despite this, the scarcity of high-quality annotated data and the diversity of fabric defects present significant challenges to the application of deep learning in this field. These factors limit the generalization and segmentation performance of existing models, impeding their ability to handle the complexity of diverse fabric types and defects. To overcome these obstacles, this study introduces an innovative method to infuse specialized knowledge of fabric defects into the Segment Anything Model (SAM), a large-scale visual model. By introducing and training a unique set of fabric defect-related parameters, this approach seamlessly integrates domain-specific knowledge into SAM without the need for extensive modifications to the pre-existing model parameters. The revamped SAM model leverages generalized image understanding learned from large-scale natural image datasets while incorporating fabric defect-specific knowled",
    "path": "papers/23/06/2306.16186.json",
    "total_tokens": 904,
    "translated_title": "通过特定的知识注入，有效地将预训练的大型视觉模型转移到面料缺陷分割中",
    "translated_abstract": "面料缺陷分割是纺织品质量控制中不可或缺的一部分。然而，高质量标注数据的稀缺性和面料缺陷的多样性对深度学习在这一领域的应用提出了重大挑战。这些因素限制了现有模型的泛化和分割性能，阻碍了它们处理各种不同面料类型和缺陷的复杂性的能力。为了克服这些障碍，本研究引入了一种创新的方法，将面料缺陷的专业知识注入到Segment Anything Model (SAM) 这个大型视觉模型中。通过引入并训练一组独特的与面料缺陷相关的参数，这种方法在不需要对预先存在的模型参数进行大量修改的情况下，无缝地将领域特定的知识整合到SAM中。改进后的SAM模型利用从大规模自然图像数据集中学到的广义图像理解能力，同时结合了面料缺陷特定的知识。",
    "tldr": "本研究通过在Segment Anything Model (SAM)中引入和训练一组面料缺陷相关的参数，无缝地将专业知识注入到大型视觉模型中，从而提高了面料缺陷分割的性能和泛化能力。"
}