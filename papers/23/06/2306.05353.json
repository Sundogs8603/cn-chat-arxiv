{
    "title": "Negotiated Reasoning: On Provably Addressing Relative Over-Generalization. (arXiv:2306.05353v1 [cs.AI])",
    "abstract": "Over-generalization is a thorny issue in cognitive science, where people may become overly cautious due to past experiences. Agents in multi-agent reinforcement learning (MARL) also have been found to suffer relative over-generalization (RO) as people do and stuck to sub-optimal cooperation. Recent methods have shown that assigning reasoning ability to agents can mitigate RO algorithmically and empirically, but there has been a lack of theoretical understanding of RO, let alone designing provably RO-free methods. This paper first proves that RO can be avoided when the MARL method satisfies a consistent reasoning requirement under certain conditions. Then we introduce a novel reasoning framework, called negotiated reasoning, that first builds the connection between reasoning and RO with theoretical justifications. After that, we propose an instantiated algorithm, Stein variational negotiated reasoning (SVNR), which uses Stein variational gradient descent to derive a negotiation policy t",
    "link": "http://arxiv.org/abs/2306.05353",
    "context": "Title: Negotiated Reasoning: On Provably Addressing Relative Over-Generalization. (arXiv:2306.05353v1 [cs.AI])\nAbstract: Over-generalization is a thorny issue in cognitive science, where people may become overly cautious due to past experiences. Agents in multi-agent reinforcement learning (MARL) also have been found to suffer relative over-generalization (RO) as people do and stuck to sub-optimal cooperation. Recent methods have shown that assigning reasoning ability to agents can mitigate RO algorithmically and empirically, but there has been a lack of theoretical understanding of RO, let alone designing provably RO-free methods. This paper first proves that RO can be avoided when the MARL method satisfies a consistent reasoning requirement under certain conditions. Then we introduce a novel reasoning framework, called negotiated reasoning, that first builds the connection between reasoning and RO with theoretical justifications. After that, we propose an instantiated algorithm, Stein variational negotiated reasoning (SVNR), which uses Stein variational gradient descent to derive a negotiation policy t",
    "path": "papers/23/06/2306.05353.json",
    "total_tokens": 918,
    "translated_abstract": "相对过度泛化是认知科学中的一个棘手问题，人们可能会因过去的经验而变得过于谨慎。多代理强化学习（MARL）中的代理也被发现会像人一样遭受相对过度泛化（RO），并会停滞于次优合作。最近的方法表明，将推理能力分配给代理可以在算法和实证上缓解RO，但目前还缺乏关于RO的理论理解，更不用说设计可证明RO-free方法了。该论文首先证明了当MARL方法在特定条件下满足一致的推理要求时，可以避免RO。然后，我们介绍了一种新的推理框架，称为协商推理，并通过理论证明建立了推理和RO之间的联系。随后，我们提出了一个实例算法，称为Stein变分协商推理（SVNR），该算法使用Stein变分梯度下降来推导协商政策。",
    "tldr": "本文提出了一种新颖的推理框架（协商推理），证明了在符合一致推理要求的特定条件下可以避免相对过度泛化（RO），并提出了一种实例算法（Stein变分协商推理（SVNR）），通过Stein变分梯度下降来推导协商政策。",
    "en_tdlr": "This paper proposes a novel reasoning framework (negotiated reasoning), proves that relative over-generalization (RO) can be avoided under certain consistent reasoning requirements, and introduces an instantiated algorithm (Stein variational negotiated reasoning - SVNR) that derives negotiation policies through Stein variational gradient descent."
}