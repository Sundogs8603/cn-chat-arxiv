{
    "title": "Diffusion-Jump GNNs: Homophiliation via Learnable Metric Filters. (arXiv:2306.16976v1 [cs.LG])",
    "abstract": "High-order Graph Neural Networks (HO-GNNs) have been developed to infer consistent latent spaces in the heterophilic regime, where the label distribution is not correlated with the graph structure. However, most of the existing HO-GNNs are hop-based, i.e., they rely on the powers of the transition matrix. As a result, these architectures are not fully reactive to the classification loss and the achieved structural filters have static supports. In other words, neither the filters' supports nor their coefficients can be learned with these networks. They are confined, instead, to learn combinations of filters. To address the above concerns, we propose Diffusion-jump GNNs a method relying on asymptotic diffusion distances that operates on jumps. A diffusion-pump generates pairwise distances whose projections determine both the support and coefficients of each structural filter. These filters are called jumps because they explore a wide range of scales in order to find bonds between scatter",
    "link": "http://arxiv.org/abs/2306.16976",
    "context": "Title: Diffusion-Jump GNNs: Homophiliation via Learnable Metric Filters. (arXiv:2306.16976v1 [cs.LG])\nAbstract: High-order Graph Neural Networks (HO-GNNs) have been developed to infer consistent latent spaces in the heterophilic regime, where the label distribution is not correlated with the graph structure. However, most of the existing HO-GNNs are hop-based, i.e., they rely on the powers of the transition matrix. As a result, these architectures are not fully reactive to the classification loss and the achieved structural filters have static supports. In other words, neither the filters' supports nor their coefficients can be learned with these networks. They are confined, instead, to learn combinations of filters. To address the above concerns, we propose Diffusion-jump GNNs a method relying on asymptotic diffusion distances that operates on jumps. A diffusion-pump generates pairwise distances whose projections determine both the support and coefficients of each structural filter. These filters are called jumps because they explore a wide range of scales in order to find bonds between scatter",
    "path": "papers/23/06/2306.16976.json",
    "total_tokens": 942,
    "translated_title": "Diffusion-Jump GNNs: 可学习度量过滤器的同质化",
    "translated_abstract": "高阶图神经网络（HO-GNNs）被开发用于在异质性范围中推断一致的潜在空间，其中标签分布与图结构无关。然而，大多数现有的HO-GNNs是基于跳数的，即它们依赖于转移矩阵的幂次。因此，这些结构对分类损失的反应不完全，并且所达到的结构化过滤器具有静态支持。换句话说，这些网络不能学习过滤器的支持或系数，而只能学习过滤器的组合。为了解决上述问题，我们提出了基于渐进扩散距离的跳跃扩散GNNs方法。扩散跳跃生成一对一的距离，其投影确定每个结构化过滤器的支持和系数。这些过滤器称为跳跃，因为它们在广泛的尺度范围内探索以找到散点之间的联系。",
    "tldr": "提出了一种名为Diffusion-Jump GNNs的新方法，通过学习可调节的度量过滤器，来提高高阶图神经网络在异质化场景下的效果。这种方法通过跳跃式的渐进扩散距离生成过滤器的支持和系数，以寻找散点之间的联系。"
}