{
    "title": "Weighted Automata Extraction and Explanation of Recurrent Neural Networks for Natural Language Tasks. (arXiv:2306.14040v1 [cs.CL])",
    "abstract": "Recurrent Neural Networks (RNNs) have achieved tremendous success in processing sequential data, yet understanding and analyzing their behaviours remains a significant challenge. To this end, many efforts have been made to extract finite automata from RNNs, which are more amenable for analysis and explanation. However, existing approaches like exact learning and compositional approaches for model extraction have limitations in either scalability or precision. In this paper, we propose a novel framework of Weighted Finite Automata (WFA) extraction and explanation to tackle the limitations for natural language tasks. First, to address the transition sparsity and context loss problems we identified in WFA extraction for natural language tasks, we propose an empirical method to complement missing rules in the transition diagram, and adjust transition matrices to enhance the context-awareness of the WFA. We also propose two data augmentation tactics to track more dynamic behaviours of RNN, ",
    "link": "http://arxiv.org/abs/2306.14040",
    "context": "Title: Weighted Automata Extraction and Explanation of Recurrent Neural Networks for Natural Language Tasks. (arXiv:2306.14040v1 [cs.CL])\nAbstract: Recurrent Neural Networks (RNNs) have achieved tremendous success in processing sequential data, yet understanding and analyzing their behaviours remains a significant challenge. To this end, many efforts have been made to extract finite automata from RNNs, which are more amenable for analysis and explanation. However, existing approaches like exact learning and compositional approaches for model extraction have limitations in either scalability or precision. In this paper, we propose a novel framework of Weighted Finite Automata (WFA) extraction and explanation to tackle the limitations for natural language tasks. First, to address the transition sparsity and context loss problems we identified in WFA extraction for natural language tasks, we propose an empirical method to complement missing rules in the transition diagram, and adjust transition matrices to enhance the context-awareness of the WFA. We also propose two data augmentation tactics to track more dynamic behaviours of RNN, ",
    "path": "papers/23/06/2306.14040.json",
    "total_tokens": 739,
    "translated_title": "自然语言任务中的加权自动机提取与递归神经网络解释",
    "translated_abstract": "循环神经网络（RNN）在处理序列数据方面取得了巨大成功，但理解和分析它们的行为仍然是一个重大挑战。为此，许多人致力于从RNN中提取有限自动机，这对于分析和解释更方便。然而，现有的方法如精确学习和组合方法在可扩展性或精度方面存在局限性。因此，我们提出了一种新的加权有限状态自动机（WFA）提取和解释框架来解决自然语言任务中的局限性。",
    "tldr": "本文提出了一种新的加权有限状态自动机（WFA）提取和解释框架来处理自然语言任务中的局限性，从而解决了精度和可扩展性方面的限制。",
    "en_tdlr": "This paper proposes a novel framework of Weighted Finite Automata (WFA) extraction and explanation to tackle limitations in natural language tasks, addressing limitations in accuracy and scalability."
}