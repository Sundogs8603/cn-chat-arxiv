{
    "title": "TextFormer: A Query-based End-to-End Text Spotter with Mixed Supervision",
    "abstract": "arXiv:2306.03377v2 Announce Type: replace-cross  Abstract: End-to-end text spotting is a vital computer vision task that aims to integrate scene text detection and recognition into a unified framework. Typical methods heavily rely on Region-of-Interest (RoI) operations to extract local features and complex post-processing steps to produce final predictions. To address these limitations, we propose TextFormer, a query-based end-to-end text spotter with Transformer architecture. Specifically, using query embedding per text instance, TextFormer builds upon an image encoder and a text decoder to learn a joint semantic understanding for multi-task modeling. It allows for mutual training and optimization of classification, segmentation, and recognition branches, resulting in deeper feature sharing without sacrificing flexibility or simplicity. Additionally, we design an Adaptive Global aGgregation (AGG) module to transfer global features into sequential features for reading arbitrarily-shape",
    "link": "https://arxiv.org/abs/2306.03377",
    "context": "Title: TextFormer: A Query-based End-to-End Text Spotter with Mixed Supervision\nAbstract: arXiv:2306.03377v2 Announce Type: replace-cross  Abstract: End-to-end text spotting is a vital computer vision task that aims to integrate scene text detection and recognition into a unified framework. Typical methods heavily rely on Region-of-Interest (RoI) operations to extract local features and complex post-processing steps to produce final predictions. To address these limitations, we propose TextFormer, a query-based end-to-end text spotter with Transformer architecture. Specifically, using query embedding per text instance, TextFormer builds upon an image encoder and a text decoder to learn a joint semantic understanding for multi-task modeling. It allows for mutual training and optimization of classification, segmentation, and recognition branches, resulting in deeper feature sharing without sacrificing flexibility or simplicity. Additionally, we design an Adaptive Global aGgregation (AGG) module to transfer global features into sequential features for reading arbitrarily-shape",
    "path": "papers/23/06/2306.03377.json",
    "total_tokens": 911,
    "translated_title": "TextFormer：基于查询的端到端文本识别器与混合监督",
    "translated_abstract": "端到端文本识别是一个重要的计算机视觉任务，旨在将场景文本检测和识别整合到一个统一的框架中。典型方法严重依赖于感兴趣区域（RoI）操作来提取局部特征，并使用复杂的后处理步骤生成最终预测。为了解决这些限制，我们提出了TextFormer，这是一个基于Transformer架构的基于查询的端到端文本识别器。具体而言，使用每个文本实例的查询嵌入，TextFormer在图像编码器和文本解码器之上构建，以学习用于多任务建模的联合语义理解。它允许对分类、分割和识别分支进行相互训练和优化，实现更深的特征共享，而不会牺牲灵活性或简单性。此外，我们设计了一个自适应全局聚合（AGG）模块，将全局特征转换为顺序特征，以读取任意形状的文本。",
    "tldr": "TextFormer提出了基于查询的端到端文本识别器，采用Transformer架构，通过查询嵌入实现了联合语义理解，允许多任务建模中的深层特征共享，并设计了自适应全局聚合（AGG）模块用于读取任意形状的文本。",
    "en_tdlr": "TextFormer introduces a query-based end-to-end text spotter with Transformer architecture, enabling joint semantic understanding through query embedding, facilitating deep feature sharing in multi-task modeling, and incorporating an Adaptive Global Aggregation (AGG) module for reading text of arbitrary shapes."
}