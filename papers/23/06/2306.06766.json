{
    "title": "Zero-Shot Wireless Indoor Navigation through Physics-Informed Reinforcement Learning. (arXiv:2306.06766v2 [cs.RO] UPDATED)",
    "abstract": "The growing focus on indoor robot navigation utilizing wireless signals has stemmed from the capability of these signals to capture high-resolution angular and temporal measurements. Prior heuristic-based methods, based on radio frequency propagation, are intuitive and generalizable across simple scenarios, yet fail to navigate in complex environments. On the other hand, end-to-end (e2e) deep reinforcement learning (RL), powered by advanced computing machinery, can explore the entire state space, delivering surprising performance when facing complex wireless environments. However, the price to pay is the astronomical amount of training samples, and the resulting policy, without fine-tuning (zero-shot), is unable to navigate efficiently in new scenarios unseen in the training phase. To equip the navigation agent with sample-efficient learning and {zero-shot} generalization, this work proposes a novel physics-informed RL (PIRL) where a distance-to-target-based cost (standard in e2e) is a",
    "link": "http://arxiv.org/abs/2306.06766",
    "context": "Title: Zero-Shot Wireless Indoor Navigation through Physics-Informed Reinforcement Learning. (arXiv:2306.06766v2 [cs.RO] UPDATED)\nAbstract: The growing focus on indoor robot navigation utilizing wireless signals has stemmed from the capability of these signals to capture high-resolution angular and temporal measurements. Prior heuristic-based methods, based on radio frequency propagation, are intuitive and generalizable across simple scenarios, yet fail to navigate in complex environments. On the other hand, end-to-end (e2e) deep reinforcement learning (RL), powered by advanced computing machinery, can explore the entire state space, delivering surprising performance when facing complex wireless environments. However, the price to pay is the astronomical amount of training samples, and the resulting policy, without fine-tuning (zero-shot), is unable to navigate efficiently in new scenarios unseen in the training phase. To equip the navigation agent with sample-efficient learning and {zero-shot} generalization, this work proposes a novel physics-informed RL (PIRL) where a distance-to-target-based cost (standard in e2e) is a",
    "path": "papers/23/06/2306.06766.json",
    "total_tokens": 819,
    "translated_title": "零样本无线室内导航通过物理信息强化学习",
    "translated_abstract": "针对室内机器人导航利用无线信号的不断关注，该论文提出了一种基于物理信息强化学习（PIRL）的方法，以实现高效的样本学习和零样本泛化。相对于基于启发式方法的传统方法，基于射频传播的方法直观且能够适应简单的场景，但在复杂环境下难以导航。而基于端到端深度强化学习（RL）的方法可以通过使用先进的计算机技术来探索整个状态空间，在面对复杂的无线环境时表现出令人惊讶的性能。然而，这种方法需要大量的训练样本，而且得到的策略在未进行微调的情况下无法在训练阶段未见过的新场景中有效导航。",
    "tldr": "该论文提出了一种基于物理信息强化学习的零样本无线室内导航方法，通过样本高效学习和零样本泛化来提高导航效率。",
    "en_tdlr": "This paper proposes a zero-shot wireless indoor navigation method based on physics-informed reinforcement learning, aiming to improve navigation efficiency through sample-efficient learning and zero-shot generalization."
}