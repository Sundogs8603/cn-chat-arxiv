{
    "title": "Normalization Layers Are All That Sharpness-Aware Minimization Needs. (arXiv:2306.04226v1 [cs.LG])",
    "abstract": "Sharpness-aware minimization (SAM) was proposed to reduce sharpness of minima and has been shown to enhance generalization performance in various settings. In this work we show that perturbing only the affine normalization parameters (comprising less than 0.1% of the total parameters) in the adversarial step of SAM outperforms perturbing all of the parameters. This finding generalizes to different SAM variants and both ResNet (Batch Normalization) and Vision Transformer (Layer Normalization) architectures. We consider alternative sparse perturbation approaches and find that these do not achieve similar performance enhancement at such extreme sparsity levels, showing that this behaviour is unique to the normalization layers. Although our findings reaffirm the effectiveness of SAM in improving generalization performance, they cast doubt on whether this is solely caused by reduced sharpness. The code for our experiments is publicly available at https://github.com/mueller-mp/SAM-ON.",
    "link": "http://arxiv.org/abs/2306.04226",
    "context": "Title: Normalization Layers Are All That Sharpness-Aware Minimization Needs. (arXiv:2306.04226v1 [cs.LG])\nAbstract: Sharpness-aware minimization (SAM) was proposed to reduce sharpness of minima and has been shown to enhance generalization performance in various settings. In this work we show that perturbing only the affine normalization parameters (comprising less than 0.1% of the total parameters) in the adversarial step of SAM outperforms perturbing all of the parameters. This finding generalizes to different SAM variants and both ResNet (Batch Normalization) and Vision Transformer (Layer Normalization) architectures. We consider alternative sparse perturbation approaches and find that these do not achieve similar performance enhancement at such extreme sparsity levels, showing that this behaviour is unique to the normalization layers. Although our findings reaffirm the effectiveness of SAM in improving generalization performance, they cast doubt on whether this is solely caused by reduced sharpness. The code for our experiments is publicly available at https://github.com/mueller-mp/SAM-ON.",
    "path": "papers/23/06/2306.04226.json",
    "total_tokens": 918,
    "translated_title": "规范化层是锐度感知最小化所需的一切",
    "translated_abstract": "锐度感知最小化（SAM）旨在减少最小值的锐度，并已被证明在各种情况下提高了泛化性能。在这项工作中，我们证明在SAM的对抗步骤中只扰动仿射规范化参数（仅占总参数的0.1%以下）优于扰动所有参数。这一发现适用于不同的SAM变体和ResNet（批量归一化）以及Vision Transformer（层归一化）架构。我们考虑了替代的稀疏扰动方法，并发现这些方法在如此极端的稀疏水平下无法实现类似的性能提升，表明这种行为是规范化层特有的。虽然我们的发现重新证实了SAM在提高泛化性能方面的有效性，但它们对减少锐度是否唯一导致性能提高产生了怀疑。我们的实验代码可在 https://github.com/mueller-mp/SAM-ON 上公开获取。",
    "tldr": "SAM算法中，仅扰动规范化层可优化模型性能，在不同的网络架构中都适用，稀疏扰动方法不行。这发现对SAM算法的有效性产生怀疑。",
    "en_tdlr": "Perturbing only the normalization layers, which comprise less than 0.1% of the total parameters, in the adversarial step of SAM algorithm can optimize model performance, regardless of network architecture, while alternative sparse perturbation methods do not achieve similar performance enhancement. However, this finding raises doubts about whether the improved generalization performance in SAM is solely due to reduced sharpness."
}