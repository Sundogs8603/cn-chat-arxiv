{
    "title": "Increasing Performance And Sample Efficiency With Model-agnostic Interactive Feature Attributions. (arXiv:2306.16431v1 [cs.LG])",
    "abstract": "Model-agnostic feature attributions can provide local insights in complex ML models. If the explanation is correct, a domain expert can validate and trust the model's decision. However, if it contradicts the expert's knowledge, related work only corrects irrelevant features to improve the model. To allow for unlimited interaction, in this paper we provide model-agnostic implementations for two popular explanation methods (Occlusion and Shapley values) to enforce entirely different attributions in the complex model. For a particular set of samples, we use the corrected feature attributions to generate extra local data, which is used to retrain the model to have the right explanation for the samples. Through simulated and real data experiments on a variety of models we show how our proposed approach can significantly improve the model's performance only by augmenting its training dataset based on corrected explanations. Adding our interactive explanations to active learning settings incr",
    "link": "http://arxiv.org/abs/2306.16431",
    "context": "Title: Increasing Performance And Sample Efficiency With Model-agnostic Interactive Feature Attributions. (arXiv:2306.16431v1 [cs.LG])\nAbstract: Model-agnostic feature attributions can provide local insights in complex ML models. If the explanation is correct, a domain expert can validate and trust the model's decision. However, if it contradicts the expert's knowledge, related work only corrects irrelevant features to improve the model. To allow for unlimited interaction, in this paper we provide model-agnostic implementations for two popular explanation methods (Occlusion and Shapley values) to enforce entirely different attributions in the complex model. For a particular set of samples, we use the corrected feature attributions to generate extra local data, which is used to retrain the model to have the right explanation for the samples. Through simulated and real data experiments on a variety of models we show how our proposed approach can significantly improve the model's performance only by augmenting its training dataset based on corrected explanations. Adding our interactive explanations to active learning settings incr",
    "path": "papers/23/06/2306.16431.json",
    "total_tokens": 896,
    "translated_title": "增强模型普适的交互式特征归因提高性能和样本效率",
    "translated_abstract": "模型普适的特征归因可以为复杂的机器学习模型提供局部洞察力。如果解释是正确的，领域专家可以验证和信任模型的决策。然而，如果它与专家的知识相矛盾，相关工作只纠正了无关的特征以改进模型。为了允许无限的交互，本文针对两种流行的解释方法（遮蔽法和沙普利值）提供了模型普适的实现，以在复杂模型中强制执行完全不同的归因。对于特定的样本集，我们使用纠正的特征归因来生成额外的局部数据，用于重新训练模型以对样本进行正确解释。通过在各种模型上进行模拟和真实数据实验，我们展示了我们提出的方法如何通过基于纠正的解释来扩充训练数据集，从而显著提高模型的性能。将我们的交互式解释添加到主动学习设置中可以增加样本效率。",
    "tldr": "本文提出了一种增强模型普适的交互式特征归因方法，通过纠正特征归因并重新训练模型，显著提高了模型的性能和样本效率。",
    "en_tdlr": "This paper proposes an approach to enhance model-agnostic interactive feature attributions, which significantly improves the model's performance and sample efficiency by correcting feature attributions and retraining the model."
}