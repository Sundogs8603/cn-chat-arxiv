{
    "title": "Coupling parameter and particle dynamics for adaptive sampling in Neural Galerkin schemes. (arXiv:2306.15630v1 [math.NA])",
    "abstract": "Training nonlinear parametrizations such as deep neural networks to numerically approximate solutions of partial differential equations is often based on minimizing a loss that includes the residual, which is analytically available in limited settings only. At the same time, empirically estimating the training loss is challenging because residuals and related quantities can have high variance, especially for transport-dominated and high-dimensional problems that exhibit local features such as waves and coherent structures. Thus, estimators based on data samples from un-informed, uniform distributions are inefficient. This work introduces Neural Galerkin schemes that estimate the training loss with data from adaptive distributions, which are empirically represented via ensembles of particles. The ensembles are actively adapted by evolving the particles with dynamics coupled to the nonlinear parametrizations of the solution fields so that the ensembles remain informative for estimating t",
    "link": "http://arxiv.org/abs/2306.15630",
    "context": "Title: Coupling parameter and particle dynamics for adaptive sampling in Neural Galerkin schemes. (arXiv:2306.15630v1 [math.NA])\nAbstract: Training nonlinear parametrizations such as deep neural networks to numerically approximate solutions of partial differential equations is often based on minimizing a loss that includes the residual, which is analytically available in limited settings only. At the same time, empirically estimating the training loss is challenging because residuals and related quantities can have high variance, especially for transport-dominated and high-dimensional problems that exhibit local features such as waves and coherent structures. Thus, estimators based on data samples from un-informed, uniform distributions are inefficient. This work introduces Neural Galerkin schemes that estimate the training loss with data from adaptive distributions, which are empirically represented via ensembles of particles. The ensembles are actively adapted by evolving the particles with dynamics coupled to the nonlinear parametrizations of the solution fields so that the ensembles remain informative for estimating t",
    "path": "papers/23/06/2306.15630.json",
    "total_tokens": 918,
    "translated_title": "神经Galerkin方案中自适应采样的耦合参数和粒子动力学",
    "translated_abstract": "训练非线性参数化，如深度神经网络，以数值逼近偏微分方程的解通常基于最小化包括残差的损失，该残差在有限的情况下是可以解析得到的。同时，由于存在局部特征(如波和相干结构)的以输运为主的高维问题的残差和相关量可能具有较高的方差，因此经验估计训练损失是具有挑战性的。因此，基于来自无信息均匀分布的数据样本的估计器是低效的。本研究引入了神经Galerkin方案，该方案使用来自自适应分布的数据来估计训练损失，这些分布通过粒子集合进行经验表示。粒子集合通过与解场的非线性参数化耦合的动力学演化来主动调整，使得粒子集合保持信息丰富以用于估计...",
    "tldr": "本研究引入了神经Galerkin方案，通过使用自适应分布的数据来估计训练损失，以应对具有局部特征和高方差的输运主导的高维问题。粒子集合通过与解场的非线性参数化耦合的动力学演化来主动调整，以保持信息丰富。"
}