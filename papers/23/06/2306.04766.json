{
    "title": "Enabling tabular deep learning when $d \\gg n$ with an auxiliary knowledge graph. (arXiv:2306.04766v1 [cs.LG])",
    "abstract": "Machine learning models exhibit strong performance on datasets with abundant labeled samples. However, for tabular datasets with extremely high $d$-dimensional features but limited $n$ samples (i.e. $d \\gg n$), machine learning models struggle to achieve strong performance due to the risk of overfitting. Here, our key insight is that there is often abundant, auxiliary domain information describing input features which can be structured as a heterogeneous knowledge graph (KG). We propose PLATO, a method that achieves strong performance on tabular data with $d \\gg n$ by using an auxiliary KG describing input features to regularize a multilayer perceptron (MLP). In PLATO, each input feature corresponds to a node in the auxiliary KG. In the MLP's first layer, each input feature also corresponds to a weight vector. PLATO is based on the inductive bias that two input features corresponding to similar nodes in the auxiliary KG should have similar weight vectors in the MLP's first layer. PLATO",
    "link": "http://arxiv.org/abs/2306.04766",
    "context": "Title: Enabling tabular deep learning when $d \\gg n$ with an auxiliary knowledge graph. (arXiv:2306.04766v1 [cs.LG])\nAbstract: Machine learning models exhibit strong performance on datasets with abundant labeled samples. However, for tabular datasets with extremely high $d$-dimensional features but limited $n$ samples (i.e. $d \\gg n$), machine learning models struggle to achieve strong performance due to the risk of overfitting. Here, our key insight is that there is often abundant, auxiliary domain information describing input features which can be structured as a heterogeneous knowledge graph (KG). We propose PLATO, a method that achieves strong performance on tabular data with $d \\gg n$ by using an auxiliary KG describing input features to regularize a multilayer perceptron (MLP). In PLATO, each input feature corresponds to a node in the auxiliary KG. In the MLP's first layer, each input feature also corresponds to a weight vector. PLATO is based on the inductive bias that two input features corresponding to similar nodes in the auxiliary KG should have similar weight vectors in the MLP's first layer. PLATO",
    "path": "papers/23/06/2306.04766.json",
    "total_tokens": 905,
    "translated_title": "用辅助知识图谱实现在 $d \\gg n$ 情况下的表格深度学习",
    "translated_abstract": "机器学习模型在具有丰富标记样本的数据集上表现出很强的性能，但对于具有非常高维特征但样本数有限（即 $d \\gg n$ 的表格数据），机器学习模型很难实现强大的性能。在这里，作者的主要洞见在于输入特征通常具有丰富的辅助领域信息，这些信息可以被组织成异构的知识图谱。作者提出了 PLATO 方法，使用描述输入特征的辅助 KG 来规范一个 MLP，在 $d \\gg n$ 的表格数据上实现了强大的性能。",
    "tldr": "该论文提出了 PLATO 方法，通过使用描述输入特征的辅助 KG 来规范 MLP，在 $d \\gg n$ 的表格数据上实现了强大的性能。",
    "en_tdlr": "The paper proposes the PLATO method, which uses an auxiliary knowledge graph to regularize a multilayer perceptron (MLP) on tabular data with $d \\gg n$, achieving strong performance."
}