{
    "title": "VisualGPTScore: Visio-Linguistic Reasoning with Multimodal Generative Pre-Training Scores. (arXiv:2306.01879v1 [cs.CV])",
    "abstract": "Vision-language models (VLMs) discriminatively pre-trained with contrastive image-text matching losses such as $P(\\text{match}|\\text{text}, \\text{image})$ have been criticized for lacking compositional understanding. This means they might output similar scores even if the original caption is rearranged into a different semantic statement. To address this, we propose to use the ${\\bf V}$isual ${\\bf G}$enerative ${\\bf P}$re-${\\bf T}$raining Score (${\\bf VisualGPTScore}$) of $P(\\text{text}|\\text{image})$, a $\\textit{multimodal generative}$ score that captures the likelihood of a text caption conditioned on an image using an image-conditioned language model. Contrary to the belief that VLMs are mere bag-of-words models, our off-the-shelf VisualGPTScore demonstrates top-tier performance on recently proposed image-text retrieval benchmarks like ARO and Crepe that assess compositional reasoning. Furthermore, we factorize VisualGPTScore into a product of the $\\textit{marginal}$ P(text) and the",
    "link": "http://arxiv.org/abs/2306.01879",
    "context": "Title: VisualGPTScore: Visio-Linguistic Reasoning with Multimodal Generative Pre-Training Scores. (arXiv:2306.01879v1 [cs.CV])\nAbstract: Vision-language models (VLMs) discriminatively pre-trained with contrastive image-text matching losses such as $P(\\text{match}|\\text{text}, \\text{image})$ have been criticized for lacking compositional understanding. This means they might output similar scores even if the original caption is rearranged into a different semantic statement. To address this, we propose to use the ${\\bf V}$isual ${\\bf G}$enerative ${\\bf P}$re-${\\bf T}$raining Score (${\\bf VisualGPTScore}$) of $P(\\text{text}|\\text{image})$, a $\\textit{multimodal generative}$ score that captures the likelihood of a text caption conditioned on an image using an image-conditioned language model. Contrary to the belief that VLMs are mere bag-of-words models, our off-the-shelf VisualGPTScore demonstrates top-tier performance on recently proposed image-text retrieval benchmarks like ARO and Crepe that assess compositional reasoning. Furthermore, we factorize VisualGPTScore into a product of the $\\textit{marginal}$ P(text) and the",
    "path": "papers/23/06/2306.01879.json",
    "total_tokens": 795,
    "translated_title": "VisualGPTScore: 多模态生成预训练分数的视觉语义推理。",
    "translated_abstract": "本文提出了一种名为 VisualGPTScore 的方法，使用多模态生成分数来捕捉文本标题可能性，并使用图像条件语言模型在图像上运算。与传统观点认为的VLM只是无意义的单词袋模型不同，我们的 VisualGPTScore 在 ARO 和 Crepe 等最近提出的图像文本检索基准测试中展现了顶尖的性能，证明了其具备组合推理能力。",
    "tldr": "我们提出了VisualGPTScore方法，能够使用多模态生成分数捕捉文本标题可能性，并在图像条件语言模型上进行计算，具备组合推理能力。",
    "en_tdlr": "We propose a method called VisualGPTScore, which uses multimodal generative scores to capture the likelihood of text captions conditioned on an image using an image-conditioned language model, and demonstrates top-tier performance on image-text retrieval benchmarks, showing its compositional reasoning ability."
}