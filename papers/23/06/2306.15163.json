{
    "title": "Wasserstein Generative Regression. (arXiv:2306.15163v1 [stat.ML])",
    "abstract": "In this paper, we propose a new and unified approach for nonparametric regression and conditional distribution learning. Our approach simultaneously estimates a regression function and a conditional generator using a generative learning framework, where a conditional generator is a function that can generate samples from a conditional distribution. The main idea is to estimate a conditional generator that satisfies the constraint that it produces a good regression function estimator. We use deep neural networks to model the conditional generator. Our approach can handle problems with multivariate outcomes and covariates, and can be used to construct prediction intervals. We provide theoretical guarantees by deriving non-asymptotic error bounds and the distributional consistency of our approach under suitable assumptions. We also perform numerical experiments with simulated and real data to demonstrate the effectiveness and superiority of our approach over some existing approaches in va",
    "link": "http://arxiv.org/abs/2306.15163",
    "context": "Title: Wasserstein Generative Regression. (arXiv:2306.15163v1 [stat.ML])\nAbstract: In this paper, we propose a new and unified approach for nonparametric regression and conditional distribution learning. Our approach simultaneously estimates a regression function and a conditional generator using a generative learning framework, where a conditional generator is a function that can generate samples from a conditional distribution. The main idea is to estimate a conditional generator that satisfies the constraint that it produces a good regression function estimator. We use deep neural networks to model the conditional generator. Our approach can handle problems with multivariate outcomes and covariates, and can be used to construct prediction intervals. We provide theoretical guarantees by deriving non-asymptotic error bounds and the distributional consistency of our approach under suitable assumptions. We also perform numerical experiments with simulated and real data to demonstrate the effectiveness and superiority of our approach over some existing approaches in va",
    "path": "papers/23/06/2306.15163.json",
    "total_tokens": 834,
    "translated_title": "Wasserstein生成回归",
    "translated_abstract": "在这篇论文中，我们提出了一种新的统一的非参数回归和条件分布学习方法。我们的方法同时估计回归函数和条件生成器，使用生成学习框架，其中条件生成器是一个可以从条件分布生成样本的函数。主要思想是估计一个满足产生良好回归函数估计的约束条件的条件生成器。我们使用深度神经网络来建模条件生成器。我们的方法可以处理具有多元输出和协变量的问题，并且可以用来构建预测区间。我们通过得出非渐近误差界和在适当的假设下我们方法的分布一致性来提供理论保证。我们还使用模拟和实际数据进行数值实验，以展示我们的方法在某些现有方法上的有效性和优越性。",
    "tldr": "我们提出了一种新的统一的非参数回归和条件分布学习方法，使用生成学习框架同时估计回归函数和条件生成器，并使用深度神经网络建模条件生成器。我们的方法可以处理具有多元输出和协变量的问题，可以构建预测区间，并通过理论保证和数值实验证明了方法的有效性和优越性。"
}