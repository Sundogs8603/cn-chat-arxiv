{
    "title": "Practical Equivariances via Relational Conditional Neural Processes. (arXiv:2306.10915v1 [stat.ML])",
    "abstract": "Conditional Neural Processes (CNPs) are a class of metalearning models popular for combining the runtime efficiency of amortized inference with reliable uncertainty quantification. Many relevant machine learning tasks, such as spatio-temporal modeling, Bayesian Optimization and continuous control, contain equivariances -- for example to translation -- which the model can exploit for maximal performance. However, prior attempts to include equivariances in CNPs do not scale effectively beyond two input dimensions. In this work, we propose Relational Conditional Neural Processes (RCNPs), an effective approach to incorporate equivariances into any neural process model. Our proposed method extends the applicability and impact of equivariant neural processes to higher dimensions. We empirically demonstrate the competitive performance of RCNPs on a large array of tasks naturally containing equivariances.",
    "link": "http://arxiv.org/abs/2306.10915",
    "context": "Title: Practical Equivariances via Relational Conditional Neural Processes. (arXiv:2306.10915v1 [stat.ML])\nAbstract: Conditional Neural Processes (CNPs) are a class of metalearning models popular for combining the runtime efficiency of amortized inference with reliable uncertainty quantification. Many relevant machine learning tasks, such as spatio-temporal modeling, Bayesian Optimization and continuous control, contain equivariances -- for example to translation -- which the model can exploit for maximal performance. However, prior attempts to include equivariances in CNPs do not scale effectively beyond two input dimensions. In this work, we propose Relational Conditional Neural Processes (RCNPs), an effective approach to incorporate equivariances into any neural process model. Our proposed method extends the applicability and impact of equivariant neural processes to higher dimensions. We empirically demonstrate the competitive performance of RCNPs on a large array of tasks naturally containing equivariances.",
    "path": "papers/23/06/2306.10915.json",
    "total_tokens": 814,
    "translated_title": "通过关系条件神经过程实现实用的等变性",
    "translated_abstract": "条件神经过程（CNPs）是一类元学习模型，以其综合运行时效率和可靠的不确定性量化而受欢迎。许多相关的机器学习任务，例如时空建模、贝叶斯优化和连续控制，包含等变性，例如对于平移，模型可以利用最大的性能。然而，先前试图在CNPs中包含等变性在超过两个输入维度之外的尺度上无法有效扩展。在本文中，我们提出了关系条件神经过程（RCNPs），这是一种有效将等变性纳入任何神经过程模型的方法。我们提出的方法扩展了等变神经过程的适用性和影响力到更高的维度。我们在自然包含等变性任务的大量任务上经验证实了RCNPs的竞争性能。",
    "tldr": "本文提出的关系条件神经过程（RCNPs）是一种有效将等变性纳入任何神经过程模型的方法，并扩展了等变神经过程的适用性和影响力到更高的维度。"
}