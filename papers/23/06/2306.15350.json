{
    "title": "CellViT: Vision Transformers for Precise Cell Segmentation and Classification. (arXiv:2306.15350v1 [eess.IV])",
    "abstract": "Nuclei detection and segmentation in hematoxylin and eosin-stained (H&E) tissue images are important clinical tasks and crucial for a wide range of applications. However, it is a challenging task due to nuclei variances in staining and size, overlapping boundaries, and nuclei clustering. While convolutional neural networks have been extensively used for this task, we explore the potential of Transformer-based networks in this domain. Therefore, we introduce a new method for automated instance segmentation of cell nuclei in digitized tissue samples using a deep learning architecture based on Vision Transformer called CellViT. CellViT is trained and evaluated on the PanNuke dataset, which is one of the most challenging nuclei instance segmentation datasets, consisting of nearly 200,000 annotated Nuclei into 5 clinically important classes in 19 tissue types. We demonstrate the superiority of large-scale in-domain and out-of-domain pre-trained Vision Transformers by leveraging the recently",
    "link": "http://arxiv.org/abs/2306.15350",
    "context": "Title: CellViT: Vision Transformers for Precise Cell Segmentation and Classification. (arXiv:2306.15350v1 [eess.IV])\nAbstract: Nuclei detection and segmentation in hematoxylin and eosin-stained (H&E) tissue images are important clinical tasks and crucial for a wide range of applications. However, it is a challenging task due to nuclei variances in staining and size, overlapping boundaries, and nuclei clustering. While convolutional neural networks have been extensively used for this task, we explore the potential of Transformer-based networks in this domain. Therefore, we introduce a new method for automated instance segmentation of cell nuclei in digitized tissue samples using a deep learning architecture based on Vision Transformer called CellViT. CellViT is trained and evaluated on the PanNuke dataset, which is one of the most challenging nuclei instance segmentation datasets, consisting of nearly 200,000 annotated Nuclei into 5 clinically important classes in 19 tissue types. We demonstrate the superiority of large-scale in-domain and out-of-domain pre-trained Vision Transformers by leveraging the recently",
    "path": "papers/23/06/2306.15350.json",
    "total_tokens": 934,
    "translated_title": "CellViT:用于精确细胞分割和分类的视觉Transformer",
    "translated_abstract": "细胞核在苏木精和伊红染色的组织图像中的检测和分割是重要的临床任务，并且对各种应用至关重要。然而，由于细胞核染色和大小的差异、边界重叠和核聚集，这是一项具有挑战性的任务。虽然卷积神经网络在这个任务中已经被广泛使用，但我们探索了Transformer-based网络在这个领域的潜力。因此，我们引入了一种使用基于Vision Transformer的深度学习架构CellViT对数字化组织样本中的细胞核进行自动实例分割的新方法。CellViT在PanNuke数据集上进行训练和评估，该数据集是一个最具挑战性的细胞核实例分割数据集，包含了近20万个注释的细胞核，分为19种组织类型的5个临床重要类别。我们通过利用最近提出的大规模领域内和领域外预训练的Vision Transformer，展示了其优越性。",
    "tldr": "CellViT是一种基于Vision Transformer的深度学习架构，用于自动实例分割苏木精和伊红染色的组织样本中的细胞核。通过在PanNuke数据集上训练和评估，CellViT展示了其优越性。"
}