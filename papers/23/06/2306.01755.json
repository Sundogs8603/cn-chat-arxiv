{
    "title": "Training Priors Predict Text-To-Image Model Performance. (arXiv:2306.01755v1 [cs.CV])",
    "abstract": "Text-to-image models can often generate some relations, i.e., \"astronaut riding horse\", but fail to generate other relations composed of the same basic parts, i.e., \"horse riding astronaut\". These failures are often taken as evidence that the models rely on training priors rather than constructing novel images compositionally. This paper tests this intuition directly on the stablediffusion 2.1 text-to-image model. By looking at the subject-verb-object (SVO) triads that form the backbone of these prompts (e.g., \"astronaut\", \"ride\", \"horse\"), we find that the more often an SVO triad appears in the training data, the better the model can generate an image aligned with that triad. Here, by aligned we mean that each of the terms appears in the generated image in the proper relation to each other. However, this increased frequency also diminishes how well the model can generate an image aligned with the flipped triad. For example, if \"astronaut riding horse\" appears frequently in the trainin",
    "link": "http://arxiv.org/abs/2306.01755",
    "context": "Title: Training Priors Predict Text-To-Image Model Performance. (arXiv:2306.01755v1 [cs.CV])\nAbstract: Text-to-image models can often generate some relations, i.e., \"astronaut riding horse\", but fail to generate other relations composed of the same basic parts, i.e., \"horse riding astronaut\". These failures are often taken as evidence that the models rely on training priors rather than constructing novel images compositionally. This paper tests this intuition directly on the stablediffusion 2.1 text-to-image model. By looking at the subject-verb-object (SVO) triads that form the backbone of these prompts (e.g., \"astronaut\", \"ride\", \"horse\"), we find that the more often an SVO triad appears in the training data, the better the model can generate an image aligned with that triad. Here, by aligned we mean that each of the terms appears in the generated image in the proper relation to each other. However, this increased frequency also diminishes how well the model can generate an image aligned with the flipped triad. For example, if \"astronaut riding horse\" appears frequently in the trainin",
    "path": "papers/23/06/2306.01755.json",
    "total_tokens": 992,
    "translated_title": "训练先验影响文本到图像模型性能",
    "translated_abstract": "文本到图像的模型能够生成一些关系，比如“宇航员骑马”，但却不能生成由相同基本部分组成的其他关系，比如“马骑宇航员”。这些失败通常被视为模型依赖训练先验而不是构建新颖的图像组合的证据。本文直接在稳定扩散2.1文本到图像模型上进行了测试。通过观察组成这些提示的主语-谓语-宾语 (SVO) 三元组（例如，“宇航员”，“骑”，“马”），我们发现，SVO三元组在训练数据中出现的次数越多，该模型就能生成与该三元组对齐的图像就越好。在这里，通过对齐，我们的意思是每个术语在生成的图像中以正确的关系出现。然而，这种增加的频率也会减少模型能够生成与翻转三元组对齐的图像的能力。例如，如果“宇航员骑马”在训练数据中频繁出现，那么“马骑宇航员”的对齐质量就会降低。",
    "tldr": "本文测试了文本到图像模型对于训练先验的依赖程度，发现模型能够更好地生成与训练数据中出现频率更高的三元组对齐的图像，但这也会降低其生成以翻转三元组为基础的图像质量。",
    "en_tdlr": "This paper examines the extent to which text-to-image models rely on training priors and found that the models can better generate images aligned with more frequent subject-verb-object triplets, but the quality of the generated images based on flipped triplets decreases."
}