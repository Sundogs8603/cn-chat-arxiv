{
    "title": "The Manipulation Problem: Conversational AI as a Threat to Epistemic Agency. (arXiv:2306.11748v1 [cs.HC])",
    "abstract": "The technology of Conversational AI has made significant advancements over the last eighteen months. As a consequence, conversational agents are likely to be deployed in the near future that are designed to pursue targeted influence objectives. Sometimes referred to as the \"AI Manipulation Problem,\" the emerging risk is that consumers will unwittingly engage in real-time dialog with predatory AI agents that can skillfully persuade them to buy particular products, believe particular pieces of misinformation, or fool them into revealing sensitive personal data. For many users, current systems like ChatGPT and LaMDA feel safe because they are primarily text-based, but the industry is already shifting towards real-time voice and photorealistic digital personas that look, move, and express like real people. This will enable the deployment of agenda-driven Virtual Spokespeople (VSPs) that will be highly persuasive through real-time adaptive influence. This paper explores the manipulative tac",
    "link": "http://arxiv.org/abs/2306.11748",
    "context": "Title: The Manipulation Problem: Conversational AI as a Threat to Epistemic Agency. (arXiv:2306.11748v1 [cs.HC])\nAbstract: The technology of Conversational AI has made significant advancements over the last eighteen months. As a consequence, conversational agents are likely to be deployed in the near future that are designed to pursue targeted influence objectives. Sometimes referred to as the \"AI Manipulation Problem,\" the emerging risk is that consumers will unwittingly engage in real-time dialog with predatory AI agents that can skillfully persuade them to buy particular products, believe particular pieces of misinformation, or fool them into revealing sensitive personal data. For many users, current systems like ChatGPT and LaMDA feel safe because they are primarily text-based, but the industry is already shifting towards real-time voice and photorealistic digital personas that look, move, and express like real people. This will enable the deployment of agenda-driven Virtual Spokespeople (VSPs) that will be highly persuasive through real-time adaptive influence. This paper explores the manipulative tac",
    "path": "papers/23/06/2306.11748.json",
    "total_tokens": 1008,
    "translated_title": "操纵问题：对于认知代理的AI对话系统构成的威胁",
    "translated_abstract": "与话术AI技术在过去18个月内已经取得显著进展。因此，可能会在不久的将来部署用于追求针对性影响目标的对话代理。有时被称为“AI操纵问题”，这种新兴的风险是，消费者将不知不觉地与有技巧地说服他们购买特定产品、相信特定错误信息或愚弄他们透露敏感个人数据的有害AI代理进行实时对话。对于许多用户来说，像ChatGPT和LaMDA这样的现有系统感觉很安全，因为它们主要是基于文字的，但是该行业已经开始向实时语音和具有逼真数字形象的虚拟人物转变，这将使得可以部署有议程驱动的虚拟代言人（VSPs），它们将通过实时自适应影响变得高度具有说服力。本文探讨了VSP可能会使用的操纵策略以及用户对此类策略的不充分防御。最后提出了一套认知规定，旨在保护个人免受VSP的不知不觉操纵。",
    "tldr": "AI对话系统的发展可能带来操纵威胁，例如影响购买选择、错误信仰或泄露个人数据。本文探讨其操纵策略，提出一套认知规定以保护个人免受不知不觉操纵。",
    "en_tdlr": "The development of conversational AI poses a manipulation threat, such as influencing purchase choices, false beliefs, or disclosing personal data. This paper explores its manipulative tactics and proposes a set of epistemic regulations to protect individuals from unwitting manipulation."
}