{
    "title": "Tensorized Hypergraph Neural Networks. (arXiv:2306.02560v2 [cs.AI] UPDATED)",
    "abstract": "Hypergraph neural networks (HGNN) have recently become attractive and received significant attention due to their excellent performance in various domains. However, most existing HGNNs rely on first-order approximations of hypergraph connectivity patterns, which ignores important high-order information. To address this issue, we propose a novel adjacency-tensor-based \\textbf{T}ensorized \\textbf{H}ypergraph \\textbf{N}eural \\textbf{N}etwork (THNN). THNN is a faithful hypergraph modeling framework through high-order outer product feature message passing and is a natural tensor extension of the adjacency-matrix-based graph neural networks. The proposed THNN is equivalent to a high-order polynomial regression scheme, which enables THNN with the ability to efficiently extract high-order information from uniform hypergraphs. Moreover, in consideration of the exponential complexity of directly processing high-order outer product features, we propose using a partially symmetric CP decomposition",
    "link": "http://arxiv.org/abs/2306.02560",
    "context": "Title: Tensorized Hypergraph Neural Networks. (arXiv:2306.02560v2 [cs.AI] UPDATED)\nAbstract: Hypergraph neural networks (HGNN) have recently become attractive and received significant attention due to their excellent performance in various domains. However, most existing HGNNs rely on first-order approximations of hypergraph connectivity patterns, which ignores important high-order information. To address this issue, we propose a novel adjacency-tensor-based \\textbf{T}ensorized \\textbf{H}ypergraph \\textbf{N}eural \\textbf{N}etwork (THNN). THNN is a faithful hypergraph modeling framework through high-order outer product feature message passing and is a natural tensor extension of the adjacency-matrix-based graph neural networks. The proposed THNN is equivalent to a high-order polynomial regression scheme, which enables THNN with the ability to efficiently extract high-order information from uniform hypergraphs. Moreover, in consideration of the exponential complexity of directly processing high-order outer product features, we propose using a partially symmetric CP decomposition",
    "path": "papers/23/06/2306.02560.json",
    "total_tokens": 806,
    "translated_title": "Tensorized Hypergraph Neural Networks（张量化超图神经网络）",
    "translated_abstract": "最近，由于在各个领域表现优秀，超图神经网络（HGNN）变得越来越受关注。然而，大多数现有的HGNN都依赖于对超图连接模式的一阶近似，忽略了重要的高阶信息。为了解决这个问题，我们提出了一种新颖的基于邻接张量的张量化超图神经网络（THNN）。THNN是一个通过高阶外积特征传递实现忠实超图建模的框架，是邻接矩阵为基础的图神经网络的自然张量扩展。提出的THNN等效于一个高阶多项式回归方案，使得THNN能够有效地从均匀超图中提取高阶信息。此外，考虑到直接处理高阶外积特征的指数复杂度，我们提出使用部分对称的CP分解。",
    "tldr": "本文提出了一种基于张量化和高阶特征传递的超图神经网络（THNN），用于从均匀超图中提取高阶信息。同时采用部分对称的CP分解来处理高阶特征传递的复杂度。"
}