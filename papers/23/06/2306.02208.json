{
    "title": "Tight Regret Bounds for Single-pass Streaming Multi-armed Bandits. (arXiv:2306.02208v1 [cs.LG])",
    "abstract": "Regret minimization in streaming multi-armed bandits (MABs) has been studied extensively in recent years. In the single-pass setting with $K$ arms and $T$ trials, a regret lower bound of $\\Omega(T^{2/3})$ has been proved for any algorithm with $o(K)$ memory (Maiti et al. [NeurIPS'21]; Agarwal at al. [COLT'22]). On the other hand, however, the previous best regret upper bound is still $O(K^{1/3} T^{2/3}\\log^{1/3}(T))$, which is achieved by the streaming implementation of the simple uniform exploration. The $O(K^{1/3}\\log^{1/3}(T))$ gap leaves the open question of the tight regret bound in the single-pass MABs with sublinear arm memory.  In this paper, we answer this open problem and complete the picture of regret minimization in single-pass streaming MABs. We first improve the regret lower bound to $\\Omega(K^{1/3}T^{2/3})$ for algorithms with $o(K)$ memory, which matches the uniform exploration regret up to a logarithm factor in $T$. We then show that the $\\log^{1/3}(T)$ factor is not n",
    "link": "http://arxiv.org/abs/2306.02208",
    "context": "Title: Tight Regret Bounds for Single-pass Streaming Multi-armed Bandits. (arXiv:2306.02208v1 [cs.LG])\nAbstract: Regret minimization in streaming multi-armed bandits (MABs) has been studied extensively in recent years. In the single-pass setting with $K$ arms and $T$ trials, a regret lower bound of $\\Omega(T^{2/3})$ has been proved for any algorithm with $o(K)$ memory (Maiti et al. [NeurIPS'21]; Agarwal at al. [COLT'22]). On the other hand, however, the previous best regret upper bound is still $O(K^{1/3} T^{2/3}\\log^{1/3}(T))$, which is achieved by the streaming implementation of the simple uniform exploration. The $O(K^{1/3}\\log^{1/3}(T))$ gap leaves the open question of the tight regret bound in the single-pass MABs with sublinear arm memory.  In this paper, we answer this open problem and complete the picture of regret minimization in single-pass streaming MABs. We first improve the regret lower bound to $\\Omega(K^{1/3}T^{2/3})$ for algorithms with $o(K)$ memory, which matches the uniform exploration regret up to a logarithm factor in $T$. We then show that the $\\log^{1/3}(T)$ factor is not n",
    "path": "papers/23/06/2306.02208.json",
    "total_tokens": 1204,
    "translated_title": "单遍流式多臂赌博机的紧凑遗憾界",
    "translated_abstract": "近年来，流式多臂赌博机(MABs) 的遗憾最小化得到了广泛的研究。在 $K$ 臂和 $T$ 次试验的单遍设置中，已经证明了任何具有 $o(K)$ 内存的算法的遗憾下限为 $\\Omega(T^{2/3})$ (Maiti等人 [NeurIPS'21]; Agarwal等人 [COLT'22])。另一方面，之前最好的遗憾上限仍然是 $O(K^{1/3} T^{2/3}\\log^{1/3}(T))$，这是通过简单均匀探索的流式实现实现的。$O(K^{1/3}\\log^{1/3}(T))$ 的差距留下了单遍 MABs 的最紧凑的遗憾界的问题。在本文中，我们回答了这个开放性问题，并完成了单遍流式 MABs 的遗憾最小化图景。我们首先将具有 $o(K)$ 内存的算法的遗憾下限改进为 $\\Omega(K^{1/3}T^{2/3})$，这与 $T$ 的对数因子匹配均匀探索的遗憾。然后，我们证明了 $\\log^{1/3}(T)$ 因子是不必要的，并为任何 $T$ 值提供了遗憾上界为 $O(K^{1/3} T^{2/3})$ 的算法。我们的结果意味着在所有具有次线性内存的算法中，均匀探索是本质上最优秀的。",
    "tldr": "本文回答了单遍流式多臂赌博机的遗憾最小化问题，并展示了一个遗憾上界为$O(K^{1/3} T^{2/3})$ 的算法，说明均匀探索是最优的算法。",
    "en_tdlr": "This paper answers the question of regret minimization in single-pass streaming multi-armed bandits and presents an algorithm with a regret upper bound of $O(K^{1/3} T^{2/3})$. The result shows that uniform exploration is essentially the optimal algorithm."
}