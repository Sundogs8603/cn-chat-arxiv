{
    "title": "Spectral gap-based deterministic tensor completion. (arXiv:2306.06262v1 [stat.ML])",
    "abstract": "Tensor completion is a core machine learning algorithm used in recommender systems and other domains with missing data. While the matrix case is well-understood, theoretical results for tensor problems are limited, particularly when the sampling patterns are deterministic. Here we bound the generalization error of the solutions of two tensor completion methods, Poisson loss and atomic norm minimization, providing tighter bounds in terms of the target tensor rank. If the ground-truth tensor is order $t$ with CP-rank $r$, the dependence on $r$ is improved from $r^{2(t-1)(t^2-t-1)}$ in arXiv:1910.10692 to $r^{2(t-1)(3t-5)}$. The error in our bounds is deterministically controlled by the spectral gap of the sampling sparsity pattern. We also prove several new properties for the atomic tensor norm, reducing the rank dependence from $r^{3t-3}$ in arXiv:1711.04965 to $r^{3t-5}$ under random sampling schemes. A limitation is that atomic norm minimization, while theoretically interesting, leads",
    "link": "http://arxiv.org/abs/2306.06262",
    "context": "Title: Spectral gap-based deterministic tensor completion. (arXiv:2306.06262v1 [stat.ML])\nAbstract: Tensor completion is a core machine learning algorithm used in recommender systems and other domains with missing data. While the matrix case is well-understood, theoretical results for tensor problems are limited, particularly when the sampling patterns are deterministic. Here we bound the generalization error of the solutions of two tensor completion methods, Poisson loss and atomic norm minimization, providing tighter bounds in terms of the target tensor rank. If the ground-truth tensor is order $t$ with CP-rank $r$, the dependence on $r$ is improved from $r^{2(t-1)(t^2-t-1)}$ in arXiv:1910.10692 to $r^{2(t-1)(3t-5)}$. The error in our bounds is deterministically controlled by the spectral gap of the sampling sparsity pattern. We also prove several new properties for the atomic tensor norm, reducing the rank dependence from $r^{3t-3}$ in arXiv:1711.04965 to $r^{3t-5}$ under random sampling schemes. A limitation is that atomic norm minimization, while theoretically interesting, leads",
    "path": "papers/23/06/2306.06262.json",
    "total_tokens": 1194,
    "translated_title": "基于谱间隔的确定性张量补全",
    "translated_abstract": "张量补全是一个核心的机器学习算法，用于推荐系统和其他带有缺失数据的领域。虽然对于矩阵情况已有深入研究，但针对张量问题的理论结果仍然有限，特别是当采样模式是确定性的时候。在本文中，我们对两种张量补全方法的解的泛化误差进行了界定，分别是Poisson loss和原子范数最小化，用目标张量秩作为判断依据，提供了更紧的界限。如果目标张量的阶数为$t$，CP秩为$r$，则我们的界限中针对$r$的依赖性从arXiv:1910.10692的$r^{2(t-1)(t^2-t-1)}$改进为$r^{2(t-1)(3t-5)}$。我们的误差界是由采样稀疏模式的谱间隔决定的。我们还证明了原子张量范数的几个新属性，在随机采样方案下将秩的依赖性从arXiv:1711.04965的$r^{3t-3}$减少到$r^{3t-5}$。然而，原子范数最小化的一个局限性是，虽然在理论上很有趣，但会导致计算上的挑战。",
    "tldr": "本文界定了Poisson loss和原子范数最小化两种张量补全方法的解的泛化误差，提供了更紧的界限，针对$r$的依赖性从之前的$r^{2(t-1)(t^2-t-1)}$改进为$r^{2(t-1)(3t-5)}$。根据采样稀疏模式的谱间隔控制误差界限，同时证明了原子张量范数的几个新属性，但原子范数最小化存在计算挑战。"
}