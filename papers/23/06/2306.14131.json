{
    "title": "Safety-Critical Scenario Generation Via Reinforcement Learning Based Editing. (arXiv:2306.14131v2 [cs.LG] UPDATED)",
    "abstract": "Generating safety-critical scenarios is essential for testing and verifying the safety of autonomous vehicles. Traditional optimization techniques suffer from the curse of dimensionality and limit the search space to fixed parameter spaces. To address these challenges, we propose a deep reinforcement learning approach that generates scenarios by sequential editing, such as adding new agents or modifying the trajectories of the existing agents. Our framework employs a reward function consisting of both risk and plausibility objectives. The plausibility objective leverages generative models, such as a variational autoencoder, to learn the likelihood of the generated parameters from the training datasets; It penalizes the generation of unlikely scenarios. Our approach overcomes the dimensionality challenge and explores a wide range of safety-critical scenarios. Our evaluation demonstrates that the proposed method generates safety-critical scenarios of higher quality compared with previous",
    "link": "http://arxiv.org/abs/2306.14131",
    "context": "Title: Safety-Critical Scenario Generation Via Reinforcement Learning Based Editing. (arXiv:2306.14131v2 [cs.LG] UPDATED)\nAbstract: Generating safety-critical scenarios is essential for testing and verifying the safety of autonomous vehicles. Traditional optimization techniques suffer from the curse of dimensionality and limit the search space to fixed parameter spaces. To address these challenges, we propose a deep reinforcement learning approach that generates scenarios by sequential editing, such as adding new agents or modifying the trajectories of the existing agents. Our framework employs a reward function consisting of both risk and plausibility objectives. The plausibility objective leverages generative models, such as a variational autoencoder, to learn the likelihood of the generated parameters from the training datasets; It penalizes the generation of unlikely scenarios. Our approach overcomes the dimensionality challenge and explores a wide range of safety-critical scenarios. Our evaluation demonstrates that the proposed method generates safety-critical scenarios of higher quality compared with previous",
    "path": "papers/23/06/2306.14131.json",
    "total_tokens": 758,
    "translated_title": "通过强化学习的编辑生成安全关键场景",
    "translated_abstract": "生成安全关键场景对于测试和验证自动驾驶汽车的安全性至关重要。传统的优化技术在维度诅咒和搜索空间的限制上存在问题。为了解决这些挑战，我们提出了一种基于深度强化学习的方法，通过顺序编辑生成场景，例如添加新的代理或修改现有代理的轨迹。我们的框架采用了包含风险和可行性目标的奖励函数。可行性目标利用生成模型，如变分自动编码器，从训练数据集中学习生成参数的可能性；它惩罚生成不太可能的场景。我们的方法克服了维度挑战，并探索了广泛的安全关键场景。我们的评估表明，与以前的方法相比，所提出的方法生成了质量更高的安全关键场景。",
    "tldr": "提出了一种基于强化学习的场景生成方法，通过顺序编辑生成安全关键场景，克服了维度挑战，并生成了质量更高的场景。"
}