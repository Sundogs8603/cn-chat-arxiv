{
    "title": "Improved Training for End-to-End Streaming Automatic Speech Recognition Model with Punctuation. (arXiv:2306.01296v1 [eess.AS])",
    "abstract": "Punctuated text prediction is crucial for automatic speech recognition as it enhances readability and impacts downstream natural language processing tasks. In streaming scenarios, the ability to predict punctuation in real-time is particularly desirable but presents a difficult technical challenge. In this work, we propose a method for predicting punctuated text from input speech using a chunk-based Transformer encoder trained with Connectionist Temporal Classification (CTC) loss. The acoustic model trained with long sequences by concatenating the input and target sequences can learn punctuation marks attached to the end of sentences more effectively. Additionally, by combining CTC losses on the chunks and utterances, we achieved both the improved F1 score of punctuation prediction and Word Error Rate (WER).",
    "link": "http://arxiv.org/abs/2306.01296",
    "context": "Title: Improved Training for End-to-End Streaming Automatic Speech Recognition Model with Punctuation. (arXiv:2306.01296v1 [eess.AS])\nAbstract: Punctuated text prediction is crucial for automatic speech recognition as it enhances readability and impacts downstream natural language processing tasks. In streaming scenarios, the ability to predict punctuation in real-time is particularly desirable but presents a difficult technical challenge. In this work, we propose a method for predicting punctuated text from input speech using a chunk-based Transformer encoder trained with Connectionist Temporal Classification (CTC) loss. The acoustic model trained with long sequences by concatenating the input and target sequences can learn punctuation marks attached to the end of sentences more effectively. Additionally, by combining CTC losses on the chunks and utterances, we achieved both the improved F1 score of punctuation prediction and Word Error Rate (WER).",
    "path": "papers/23/06/2306.01296.json",
    "total_tokens": 786,
    "translated_title": "带标点的端到端流式自动语音识别模型的改进训练",
    "translated_abstract": "在自动语音识别中，标点文本预测对提高可读性和影响下游自然语言处理任务至关重要。在流媒体场景下，实时预测标点的能力尤为重要，但也带来了困难的技术挑战。本文提出了一种使用基于块的Transformer编码器预测标点文本的方法，该编码器使用连续时间分类（CTC）损失进行训练。通过将输入序列和目标序列连接起来训练长序列的声学模型可以更有效地学习附加在句子末尾的标点符号。此外，通过结合块和话语的CTC损失，我们实现了标点预测的改进F1得分和词错误率（WER）的双重目标。",
    "tldr": "本文提出了一种使用块状Transformer编码器进行训练以实现标点预测的方法，并通过联合使用块和话语的CTC损失来获得较好的预测效果。",
    "en_tdlr": "The paper proposes a method for predicting punctuated text from input speech using a chunk-based Transformer encoder trained with Connectionist Temporal Classification (CTC) loss, and achieves improved punctuation prediction and Word Error Rate (WER) by combining CTC losses on the chunks and utterances."
}