{
    "title": "Vector-Quantized Graph Auto-Encoder. (arXiv:2306.07735v1 [cs.LG])",
    "abstract": "In this work, we addresses the problem of modeling distributions of graphs. We introduce the Vector-Quantized Graph Auto-Encoder (VQ-GAE), a permutation-equivariant discrete auto-encoder and designed to model the distribution of graphs. By exploiting the permutation-equivariance of graph neural networks (GNNs), our autoencoder circumvents the problem of the ordering of the graph representation. We leverage the capability of GNNs to capture local structures of graphs while employing vector-quantization to prevent the mapping of discrete objects to a continuous latent space. Furthermore, the use of autoregressive models enables us to capture the global structure of graphs via the latent representation. We evaluate our model on standard datasets used for graph generation and observe that it achieves excellent performance on some of the most salient evaluation metrics compared to the state-of-the-art.",
    "link": "http://arxiv.org/abs/2306.07735",
    "context": "Title: Vector-Quantized Graph Auto-Encoder. (arXiv:2306.07735v1 [cs.LG])\nAbstract: In this work, we addresses the problem of modeling distributions of graphs. We introduce the Vector-Quantized Graph Auto-Encoder (VQ-GAE), a permutation-equivariant discrete auto-encoder and designed to model the distribution of graphs. By exploiting the permutation-equivariance of graph neural networks (GNNs), our autoencoder circumvents the problem of the ordering of the graph representation. We leverage the capability of GNNs to capture local structures of graphs while employing vector-quantization to prevent the mapping of discrete objects to a continuous latent space. Furthermore, the use of autoregressive models enables us to capture the global structure of graphs via the latent representation. We evaluate our model on standard datasets used for graph generation and observe that it achieves excellent performance on some of the most salient evaluation metrics compared to the state-of-the-art.",
    "path": "papers/23/06/2306.07735.json",
    "total_tokens": 867,
    "translated_title": "向量量化图自编码器",
    "translated_abstract": "本文研究了建模图的分布的问题。文章介绍了一种置换等变离散自编码器(VQ-GAE)，旨在设计用于建模图的分布。通过利用图神经网络(GNN)的置换等变性，我们的自编码器绕过了图表示的排序问题。我们利用GNN捕捉图的局部结构的能力，同时采用向量量化来防止将离散对象映射到连续的潜在空间中。此外，自回归模型的使用使我们能够通过潜在表示捕获图的全局结构。我们在用于图生成的标准数据集上评估了我们的模型，并观察到与现有最先进方法相比，在一些最突出的评估指标上取得了出色的性能。",
    "tldr": "本文介绍了一种用于建模图分布的置换等变离散自编码器(VQ-GAE)，它采用向量量化防止将离散对象映射到连续潜在空间中，并利用自回归模型捕获了图的全局结构，实验表明具有优异性能。",
    "en_tdlr": "This paper introduces a permutation-equivariant discrete auto-encoder (VQ-GAE) for modeling distributions of graphs. It circumvents the ordering problem of graph representation and prevents mapping of discrete objects to a continuous latent space by exploiting permutation-equivariance of graph neural networks and leveraging vector-quantization. The use of autoregressive models captures the global structure of graphs via latent representation. Results show excellent performance compared to state-of-the-art on standard datasets used for graph generation."
}