{
    "title": "Additive Causal Bandits with Unknown Graph. (arXiv:2306.07858v1 [cs.LG])",
    "abstract": "We explore algorithms to select actions in the causal bandit setting where the learner can choose to intervene on a set of random variables related by a causal graph, and the learner sequentially chooses interventions and observes a sample from the interventional distribution. The learner's goal is to quickly find the intervention, among all interventions on observable variables, that maximizes the expectation of an outcome variable. We depart from previous literature by assuming no knowledge of the causal graph except that latent confounders between the outcome and its ancestors are not present. We first show that the unknown graph problem can be exponentially hard in the parents of the outcome. To remedy this, we adopt an additional additive assumption on the outcome which allows us to solve the problem by casting it as an additive combinatorial linear bandit problem with full-bandit feedback. We propose a novel action-elimination algorithm for this setting, show how to apply this al",
    "link": "http://arxiv.org/abs/2306.07858",
    "context": "Title: Additive Causal Bandits with Unknown Graph. (arXiv:2306.07858v1 [cs.LG])\nAbstract: We explore algorithms to select actions in the causal bandit setting where the learner can choose to intervene on a set of random variables related by a causal graph, and the learner sequentially chooses interventions and observes a sample from the interventional distribution. The learner's goal is to quickly find the intervention, among all interventions on observable variables, that maximizes the expectation of an outcome variable. We depart from previous literature by assuming no knowledge of the causal graph except that latent confounders between the outcome and its ancestors are not present. We first show that the unknown graph problem can be exponentially hard in the parents of the outcome. To remedy this, we adopt an additional additive assumption on the outcome which allows us to solve the problem by casting it as an additive combinatorial linear bandit problem with full-bandit feedback. We propose a novel action-elimination algorithm for this setting, show how to apply this al",
    "path": "papers/23/06/2306.07858.json",
    "total_tokens": 836,
    "translated_title": "带未知图谱的加性因果赌博机",
    "translated_abstract": "我们探讨了选择行动的算法，在因果赌博设置下，学习者可以选择干预一组由因果图相关的随机变量，学习者顺序选择干预，并从干预分布中观察样本。学习者的目标是快速找到最大化结果变量期望的，所有可观察变量干预中的干预。我们假设没有关于因果图的任何知识，除了结果和其祖先之间的潜在混淆因素不存在。我们首先展示了未知图问题在结果的父母中可以是指数级难以解决。为了解决这个问题，我们对结果采取额外的加性假设，通过将问题建模为具有全赌博反馈的加性组合线性赌博问题来解决。我们提出了一种新的行动消除算法，展示了如何将此算法应用于这个设置。",
    "tldr": "该论文讨论了因果赌博机中选择行动的算法问题，提出了一种基于加性组合线性赌博问题的解决方法以解决未知图谱问题。",
    "en_tdlr": "This paper discusses the algorithm problems of selecting actions in causal bandits and proposes a solution based on additive combinatorial linear bandit problem to solve the unknown graph problem."
}