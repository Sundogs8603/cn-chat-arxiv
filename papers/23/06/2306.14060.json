{
    "title": "DesCo: Learning Object Recognition with Rich Language Descriptions. (arXiv:2306.14060v1 [cs.CV])",
    "abstract": "Recent development in vision-language approaches has instigated a paradigm shift in learning visual recognition models from language supervision. These approaches align objects with language queries (e.g. \"a photo of a cat\") and improve the models' adaptability to identify novel objects and domains. Recently, several studies have attempted to query these models with complex language expressions that include specifications of fine-grained semantic details, such as attributes, shapes, textures, and relations. However, simply incorporating language descriptions as queries does not guarantee accurate interpretation by the models. In fact, our experiments show that GLIP, the state-of-the-art vision-language model for object detection, often disregards contextual information in the language descriptions and instead relies heavily on detecting objects solely by their names. To tackle the challenges, we propose a new description-conditioned (DesCo) paradigm of learning object recognition model",
    "link": "http://arxiv.org/abs/2306.14060",
    "context": "Title: DesCo: Learning Object Recognition with Rich Language Descriptions. (arXiv:2306.14060v1 [cs.CV])\nAbstract: Recent development in vision-language approaches has instigated a paradigm shift in learning visual recognition models from language supervision. These approaches align objects with language queries (e.g. \"a photo of a cat\") and improve the models' adaptability to identify novel objects and domains. Recently, several studies have attempted to query these models with complex language expressions that include specifications of fine-grained semantic details, such as attributes, shapes, textures, and relations. However, simply incorporating language descriptions as queries does not guarantee accurate interpretation by the models. In fact, our experiments show that GLIP, the state-of-the-art vision-language model for object detection, often disregards contextual information in the language descriptions and instead relies heavily on detecting objects solely by their names. To tackle the challenges, we propose a new description-conditioned (DesCo) paradigm of learning object recognition model",
    "path": "papers/23/06/2306.14060.json",
    "total_tokens": 806,
    "translated_title": "DesCo: 利用详尽的语言描述学习物体识别",
    "translated_abstract": "最近视觉语言方法的发展引起了学习视觉识别模型从语言监督的范式转变。这些方法将对象与语言查询（例如，“一张猫的照片”）对齐，并提高了模型识别新对象和域的适应性。最近，几项研究尝试使用包括属性，形状，纹理和关系等细粒度语义细节规范的复杂语言表达式查询这些模型。然而，仅仅将语言描述作为查询加入并不能保证模型对其进行精确解释。事实上，我们的实验表明，用于物体检测的视觉语言模型GLIP常常忽略语言描述中的上下文信息，而是过于依赖仅凭名称检测物体。为了解决这些挑战，我们提出了一种新的“描述条件（DesCo）”物体识别模型学习范式。",
    "tldr": "DesCo是一种新的物体识别模型学习范式，旨在通过详尽的语言描述提高对新对象和域的适应性。",
    "en_tdlr": "DesCo is a new paradigm for learning object recognition models that aims to improve adaptability to novel objects and domains through detailed language descriptions."
}