{
    "title": "Anticipatory Music Transformer. (arXiv:2306.08620v1 [cs.SD])",
    "abstract": "We introduce anticipation: a method for constructing a controllable generative model of a temporal point process (the event process) conditioned asynchronously on realizations of a second, correlated process (the control process). We achieve this by interleaving sequences of events and controls, such that controls appear following stopping times in the event sequence. This work is motivated by problems arising in the control of symbolic music generation. We focus on infilling control tasks, whereby the controls are a subset of the events themselves, and conditional generation completes a sequence of events given the fixed control events. We train anticipatory infilling models using the large and diverse Lakh MIDI music dataset. These models match the performance of autoregressive models for prompted music generation, with the additional capability to perform infilling control tasks, including accompaniment. Human evaluators report that an anticipatory model produces accompaniments with",
    "link": "http://arxiv.org/abs/2306.08620",
    "context": "Title: Anticipatory Music Transformer. (arXiv:2306.08620v1 [cs.SD])\nAbstract: We introduce anticipation: a method for constructing a controllable generative model of a temporal point process (the event process) conditioned asynchronously on realizations of a second, correlated process (the control process). We achieve this by interleaving sequences of events and controls, such that controls appear following stopping times in the event sequence. This work is motivated by problems arising in the control of symbolic music generation. We focus on infilling control tasks, whereby the controls are a subset of the events themselves, and conditional generation completes a sequence of events given the fixed control events. We train anticipatory infilling models using the large and diverse Lakh MIDI music dataset. These models match the performance of autoregressive models for prompted music generation, with the additional capability to perform infilling control tasks, including accompaniment. Human evaluators report that an anticipatory model produces accompaniments with",
    "path": "papers/23/06/2306.08620.json",
    "total_tokens": 837,
    "translated_title": "预测音乐转换器",
    "translated_abstract": "我们引入了anticipation（预测）：一种构建生成模型的方法，该模型基于事件过程（时间点过程）的实现，以异步地控制与第二个相关过程（控制过程）的相关性。我们通过交错事件和控件序列来实现这一目标，使控件出现在事件序列的停止时间之后。这项工作的动机来自符号音乐生成控制中出现的问题。我们专注于infiling（补全）控制任务，其中控制事件是事件本身的子集，并且条件生成完成给定固定控制事件的事件序列。我们使用大型多样的Lakh MIDI音乐数据集训练预测infiling模型。这些模型与提示音乐生成的自回归模型性能相当，并具有执行infilling控制任务的附加能力，包括伴奏。人工评估员报告说，预测模型产生的伴奏具有高可辨性和优美性。",
    "tldr": "该论文提出一种预测音乐转换器，它能够实现在符号音乐生成的过程中进行控制，包括补全控制任务和伴奏，并且在大型且多样的数据集上表现出色。",
    "en_tdlr": "This paper proposes an anticipatory music transformer which enables control in symbolic music generation, including infilling control tasks and accompaniment, and performs well on a large and diverse dataset."
}