{
    "title": "Impact of Noise on Calibration and Generalisation of Neural Networks. (arXiv:2306.17630v1 [cs.LG])",
    "abstract": "Noise injection and data augmentation strategies have been effective for enhancing the generalisation and robustness of neural networks (NNs). Certain types of noise such as label smoothing and MixUp have also been shown to improve calibration. Since noise can be added in various stages of the NN's training, it motivates the question of when and where the noise is the most effective. We study a variety of noise types to determine how much they improve calibration and generalisation, and under what conditions. More specifically we evaluate various noise-injection strategies in both in-distribution (ID) and out-of-distribution (OOD) scenarios. The findings highlight that activation noise was the most transferable and effective in improving generalisation, while input augmentation noise was prominent in improving calibration on OOD but not necessarily ID data.",
    "link": "http://arxiv.org/abs/2306.17630",
    "context": "Title: Impact of Noise on Calibration and Generalisation of Neural Networks. (arXiv:2306.17630v1 [cs.LG])\nAbstract: Noise injection and data augmentation strategies have been effective for enhancing the generalisation and robustness of neural networks (NNs). Certain types of noise such as label smoothing and MixUp have also been shown to improve calibration. Since noise can be added in various stages of the NN's training, it motivates the question of when and where the noise is the most effective. We study a variety of noise types to determine how much they improve calibration and generalisation, and under what conditions. More specifically we evaluate various noise-injection strategies in both in-distribution (ID) and out-of-distribution (OOD) scenarios. The findings highlight that activation noise was the most transferable and effective in improving generalisation, while input augmentation noise was prominent in improving calibration on OOD but not necessarily ID data.",
    "path": "papers/23/06/2306.17630.json",
    "total_tokens": 863,
    "translated_title": "噪声对神经网络的校准和泛化的影响",
    "translated_abstract": "噪声注入和数据增强策略对提升神经网络的泛化性能和鲁棒性有效。某些类型的噪声，如标签平滑和MixUp，也被证明能改善校准。由于噪声可以在神经网络的训练的不同阶段添加，这引发了噪声在何时何地最有效的问题。我们研究了各种噪声类型，以确定它们对校准和泛化的改进程度以及在什么条件下起作用。具体而言，我们评估了在分布内（ID）和分布外（OOD）场景中的各种噪声注入策略。研究结果表明，激活噪声对于提高泛化性能是最具传递性和有效性的，而输入增强噪声在改善分布外校准上很显著，但不一定适用于分布内数据。",
    "tldr": "本研究研究了不同类型噪声对神经网络的校准和泛化的影响，发现激活噪声能最有效地提高泛化性能，而输入增强噪声则能显著改善分布外的校准。",
    "en_tdlr": "This study investigates the impact of different types of noise on the calibration and generalization of neural networks. The findings show that activation noise is most effective in improving generalization, while input augmentation noise significantly improves calibration on out-of-distribution data."
}