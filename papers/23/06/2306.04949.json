{
    "title": "Robust Learning with Progressive Data Expansion Against Spurious Correlation. (arXiv:2306.04949v1 [cs.LG])",
    "abstract": "While deep learning models have shown remarkable performance in various tasks, they are susceptible to learning non-generalizable spurious features rather than the core features that are genuinely correlated to the true label. In this paper, beyond existing analyses of linear models, we theoretically examine the learning process of a two-layer nonlinear convolutional neural network in the presence of spurious features. Our analysis suggests that imbalanced data groups and easily learnable spurious features can lead to the dominance of spurious features during the learning process. In light of this, we propose a new training algorithm called PDE that efficiently enhances the model's robustness for a better worst-group performance. PDE begins with a group-balanced subset of training data and progressively expands it to facilitate the learning of the core features. Experiments on synthetic and real-world benchmark datasets confirm the superior performance of our method on models such as R",
    "link": "http://arxiv.org/abs/2306.04949",
    "context": "Title: Robust Learning with Progressive Data Expansion Against Spurious Correlation. (arXiv:2306.04949v1 [cs.LG])\nAbstract: While deep learning models have shown remarkable performance in various tasks, they are susceptible to learning non-generalizable spurious features rather than the core features that are genuinely correlated to the true label. In this paper, beyond existing analyses of linear models, we theoretically examine the learning process of a two-layer nonlinear convolutional neural network in the presence of spurious features. Our analysis suggests that imbalanced data groups and easily learnable spurious features can lead to the dominance of spurious features during the learning process. In light of this, we propose a new training algorithm called PDE that efficiently enhances the model's robustness for a better worst-group performance. PDE begins with a group-balanced subset of training data and progressively expands it to facilitate the learning of the core features. Experiments on synthetic and real-world benchmark datasets confirm the superior performance of our method on models such as R",
    "path": "papers/23/06/2306.04949.json",
    "total_tokens": 1007,
    "translated_title": "通过逐步扩展数据对抗虚假相关性的鲁棒学习",
    "translated_abstract": "虽然深度学习模型在各种任务中表现出了卓越的性能，但它们易于学习与真实标签无关的虚假特征，而不是真正与标签相关的核心特征。在本文中，我们在已有线性模型分析的基础上，从理论上检查了存在虚假特征时两层非线性卷积神经网络的学习过程。我们的分析表明，数据组不平衡和易于学习的虚假特征可能在学习过程中导致虚假特征的支配。基于此，我们提出了一种名为PDE的新的训练算法，该算法有效地增强了模型的鲁棒性，以获得更好的最差组性能。PDE从一组平衡的训练数据子集开始，并逐步扩展其大小以促进核心特征的学习。在合成和真实世界基准数据集上的实验证明了我们的方法在模型（例如R）上的优异性能。",
    "tldr": "本文通过理论分析和实验证明了，在存在虚假特征的情况下，数据组的不平衡和易于学习的虚假特征可能导致模型学习虚假特征。作者提出了一种新的训练算法PDE，它逐步扩展训练数据的大小可以提高了模型鲁棒性，有效地增强了其最劣组性能，实验证实在合成和真实世界的基准数据集上的超越了R模型等其它模型。",
    "en_tdlr": "This paper theoretically analyses the learning process of a two-layer nonlinear CNN in the presence of spurious features and proposes a new training algorithm PDE to enhance the model's robustness by progressively expanding the size of the training data. Experiments on synthetic and real-world data confirm the superior performance compared to other models such as R in terms of worst-group performance."
}