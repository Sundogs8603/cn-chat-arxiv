{
    "title": "Geometry-Aware Approaches for Balancing Performance and Theoretical Guarantees in Linear Bandits. (arXiv:2306.14872v1 [cs.LG])",
    "abstract": "This paper is motivated by recent developments in the linear bandit literature, which have revealed a discrepancy between the promising empirical performance of algorithms such as Thompson sampling and Greedy, when compared to their pessimistic theoretical regret bounds. The challenge arises from the fact that while these algorithms may perform poorly in certain problem instances, they generally excel in typical instances. To address this, we propose a new data-driven technique that tracks the geometry of the uncertainty ellipsoid, enabling us to establish an instance-dependent frequentist regret bound for a broad class of algorithms, including Greedy, OFUL, and Thompson sampling. This result empowers us to identify and ``course-correct\" instances in which the base algorithms perform poorly. The course-corrected algorithms achieve the minimax optimal regret of order $\\tilde{\\mathcal{O}}(d\\sqrt{T})$, while retaining most of the desirable properties of the base algorithms. We present sim",
    "link": "http://arxiv.org/abs/2306.14872",
    "context": "Title: Geometry-Aware Approaches for Balancing Performance and Theoretical Guarantees in Linear Bandits. (arXiv:2306.14872v1 [cs.LG])\nAbstract: This paper is motivated by recent developments in the linear bandit literature, which have revealed a discrepancy between the promising empirical performance of algorithms such as Thompson sampling and Greedy, when compared to their pessimistic theoretical regret bounds. The challenge arises from the fact that while these algorithms may perform poorly in certain problem instances, they generally excel in typical instances. To address this, we propose a new data-driven technique that tracks the geometry of the uncertainty ellipsoid, enabling us to establish an instance-dependent frequentist regret bound for a broad class of algorithms, including Greedy, OFUL, and Thompson sampling. This result empowers us to identify and ``course-correct\" instances in which the base algorithms perform poorly. The course-corrected algorithms achieve the minimax optimal regret of order $\\tilde{\\mathcal{O}}(d\\sqrt{T})$, while retaining most of the desirable properties of the base algorithms. We present sim",
    "path": "papers/23/06/2306.14872.json",
    "total_tokens": 812,
    "translated_title": "线性赌博机中平衡性能与理论保证的几何感知方法",
    "translated_abstract": "本文受线性赌博机算法表现良好的实证性能与悲观理论后悔界之间的不一致性启发，提出一种新的数据驱动技术，跟踪不确定度椭球体的几何形状，为包括贪心、OFUL和汤普森抽样算法在内的广泛算法类建立实例相关的频率后悔界，在保留基本算法大部分优良特性的同时“校正”基本算法在某些实例中表现差的问题，实现了渐近最优后悔界。我们通过仿真实验验证了该方法的有效性。",
    "tldr": "本文提出了一种新的数据驱动技术，跟踪不确定度椭球体的几何形状，为线性赌博机算法建立实例相关的频率后悔界，并实现了平衡算法性能与理论保证的效果。",
    "en_tdlr": "This paper proposes a new data-driven technique that tracks the geometry of the uncertainty ellipsoid to establish an instance-dependent frequentist regret bound for a broad class of algorithms in linear bandit problems, and achieves a balance between algorithm performance and theoretical guarantees."
}