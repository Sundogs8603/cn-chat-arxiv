{
    "title": "Divide, Conquer, and Combine: Mixture of Semantic-Independent Experts for Zero-Shot Dialogue State Tracking. (arXiv:2306.00434v1 [cs.CL])",
    "abstract": "Zero-shot transfer learning for Dialogue State Tracking (DST) helps to handle a variety of task-oriented dialogue domains without the cost of collecting in-domain data. Existing works mainly study common data- or model-level augmentation methods to enhance the generalization but fail to effectively decouple the semantics of samples, limiting the zero-shot performance of DST. In this paper, we present a simple and effective \"divide, conquer and combine\" solution, which explicitly disentangles the semantics of seen data, and leverages the performance and robustness with the mixture-of-experts mechanism. Specifically, we divide the seen data into semantically independent subsets and train corresponding experts, the newly unseen samples are mapped and inferred with mixture-of-experts with our designed ensemble inference. Extensive experiments on MultiWOZ2.1 upon the T5-Adapter show our schema significantly and consistently improves the zero-shot performance, achieving the SOTA on settings ",
    "link": "http://arxiv.org/abs/2306.00434",
    "context": "Title: Divide, Conquer, and Combine: Mixture of Semantic-Independent Experts for Zero-Shot Dialogue State Tracking. (arXiv:2306.00434v1 [cs.CL])\nAbstract: Zero-shot transfer learning for Dialogue State Tracking (DST) helps to handle a variety of task-oriented dialogue domains without the cost of collecting in-domain data. Existing works mainly study common data- or model-level augmentation methods to enhance the generalization but fail to effectively decouple the semantics of samples, limiting the zero-shot performance of DST. In this paper, we present a simple and effective \"divide, conquer and combine\" solution, which explicitly disentangles the semantics of seen data, and leverages the performance and robustness with the mixture-of-experts mechanism. Specifically, we divide the seen data into semantically independent subsets and train corresponding experts, the newly unseen samples are mapped and inferred with mixture-of-experts with our designed ensemble inference. Extensive experiments on MultiWOZ2.1 upon the T5-Adapter show our schema significantly and consistently improves the zero-shot performance, achieving the SOTA on settings ",
    "path": "papers/23/06/2306.00434.json",
    "total_tokens": 922,
    "translated_title": "分解、征服和组合：面向零样本对话状态追踪的混合无语义专家",
    "translated_abstract": "对话状态追踪（DST）的零样本迁移学习有助于处理各种面向任务的对话领域，而无需收集领域内数据的成本。现有的工作主要研究常见的数据或模型级别的增强方法来增强泛化性能，但未能有效地解耦样本语义，限制了DST的零样本性能。本文提出了一种简单有效的“分解、征服和组合”解决方案，明确地解耦了已知数据的语义，并利用专家混合机制的性能和鲁棒性。具体地，我们将已知数据划分为语义独立子集，并训练相应的专家，在我们设计的集合推理下，将新的未见样本映射并推断出混合型专家。在T5-Adapter上对MultiWOZ2.1进行了大量实验，结果表明我们的方案显著且一致地提高了零样本性能，在设置上实现了SOTA水平。",
    "tldr": "本文提出了一种通过“分解、征服和组合”解耦语义的方法，利用专家混合机制的性能和鲁棒性，从而显著并一致地提高了面向零样本对话状态追踪的性能。",
    "en_tdlr": "The paper proposes a method of decoupling semantics by \"dividing, conquering, and combining\", leveraging the performance and robustness of the mixture-of-experts mechanism, which significantly and consistently improves the performance of zero-shot dialogue state tracking."
}