{
    "title": "Explaining CLIP through Co-Creative Drawings and Interaction. (arXiv:2306.07429v1 [cs.AI])",
    "abstract": "This paper analyses a visual archive of drawings produced by an interactive robotic art installation where audience members narrated their dreams into a system powered by CLIPdraw deep learning (DL) model that interpreted and transformed their dreams into images. The resulting archive of prompt-image pairs were examined and clustered based on concept representation accuracy. As a result of the analysis, the paper proposes four groupings for describing and explaining CLIP-generated results: clear concept, text-to-text as image, indeterminacy and confusion, and lost in translation. This article offers a glimpse into a collection of dreams interpreted, mediated and given form by Artificial Intelligence (AI), showcasing oftentimes unexpected, visually compelling or, indeed, the dream-like output of the system, with the emphasis on processes and results of translations between languages, sign-systems and various modules of the installation. In the end, the paper argues that proposed cluster",
    "link": "http://arxiv.org/abs/2306.07429",
    "context": "Title: Explaining CLIP through Co-Creative Drawings and Interaction. (arXiv:2306.07429v1 [cs.AI])\nAbstract: This paper analyses a visual archive of drawings produced by an interactive robotic art installation where audience members narrated their dreams into a system powered by CLIPdraw deep learning (DL) model that interpreted and transformed their dreams into images. The resulting archive of prompt-image pairs were examined and clustered based on concept representation accuracy. As a result of the analysis, the paper proposes four groupings for describing and explaining CLIP-generated results: clear concept, text-to-text as image, indeterminacy and confusion, and lost in translation. This article offers a glimpse into a collection of dreams interpreted, mediated and given form by Artificial Intelligence (AI), showcasing oftentimes unexpected, visually compelling or, indeed, the dream-like output of the system, with the emphasis on processes and results of translations between languages, sign-systems and various modules of the installation. In the end, the paper argues that proposed cluster",
    "path": "papers/23/06/2306.07429.json",
    "total_tokens": 876,
    "translated_title": "通过共创图画和互动解释CLIP",
    "translated_abstract": "本文分析了一个视觉存档，其中包括由交互式机器人艺术装置产生的绘画，观众通过CLIPdraw深度学习模型，将自己的梦想讲述给一个解释和转换梦想的系统。文中讨论并聚类了这些图画，其中包括基于概念表述准确性的四个分类，以描述和解释CLIP生成的结果。本文强调语言、符号系统和装置各模块之间的翻译过程和结果，展示了由人工智能解释、中介和赋形的梦想集合，强调这个系统产生了意想不到、视觉吸引人、梦境般的输出。",
    "tldr": "本文分析了一个由CLIP深度学习模型解析梦境并将其转化为图像的系统所产生的绘画存档，提出了四个分类以解释和描述CLIP生成的结果。本文关注于跨语言、符号系统和装置各模块之间的翻译过程和结果，展示了意想不到、视觉吸引人、梦境般的CLIP生成的结果。",
    "en_tdlr": "This paper analyzes a visual archive of drawings produced by an interactive robotic art installation where audience members narrated their dreams into a deep learning model that interpreted and transformed their dreams into images. It proposes four groupings for describing and explaining CLIP-generated results and emphasizes translation processes and unexpected dream-like outputs across different languages, sign-systems, and installation modules."
}