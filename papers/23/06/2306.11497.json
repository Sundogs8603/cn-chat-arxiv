{
    "title": "Convergence and concentration properties of constant step-size SGD through Markov chains. (arXiv:2306.11497v1 [stat.ML])",
    "abstract": "We consider the optimization of a smooth and strongly convex objective using constant step-size stochastic gradient descent (SGD) and study its properties through the prism of Markov chains. We show that, for unbiased gradient estimates with mildly controlled variance, the iteration converges to an invariant distribution in total variation distance. We also establish this convergence in Wasserstein-2 distance under a relaxed assumption on the gradient noise distribution compared to previous work. Thanks to the invariance property of the limit distribution, our analysis shows that the latter inherits sub-Gaussian or sub-exponential concentration properties when these hold true for the gradient. This allows the derivation of high-confidence bounds for the final estimate. Finally, under such conditions in the linear case, we obtain a dimension-free deviation bound for the Polyak-Ruppert average of a tail sequence. All our results are non-asymptotic and their consequences are discussed thr",
    "link": "http://arxiv.org/abs/2306.11497",
    "context": "Title: Convergence and concentration properties of constant step-size SGD through Markov chains. (arXiv:2306.11497v1 [stat.ML])\nAbstract: We consider the optimization of a smooth and strongly convex objective using constant step-size stochastic gradient descent (SGD) and study its properties through the prism of Markov chains. We show that, for unbiased gradient estimates with mildly controlled variance, the iteration converges to an invariant distribution in total variation distance. We also establish this convergence in Wasserstein-2 distance under a relaxed assumption on the gradient noise distribution compared to previous work. Thanks to the invariance property of the limit distribution, our analysis shows that the latter inherits sub-Gaussian or sub-exponential concentration properties when these hold true for the gradient. This allows the derivation of high-confidence bounds for the final estimate. Finally, under such conditions in the linear case, we obtain a dimension-free deviation bound for the Polyak-Ruppert average of a tail sequence. All our results are non-asymptotic and their consequences are discussed thr",
    "path": "papers/23/06/2306.11497.json",
    "total_tokens": 879,
    "translated_title": "基于马尔科夫链的常步长SGD的收敛和集中性质",
    "translated_abstract": "本文考虑使用常步长随机梯度下降（SGD）优化平滑且强凸的目标，并通过马尔科夫链研究其性质。我们证明，对于具有轻微受控方差的无偏梯度估计，迭代以总变差距离收敛于一个不变分布。我们还在与以前工作相比梯度噪声分布的放宽假设下，在Wasserstein-2距离下建立了这种收敛性。由于极限分布的不变性质，我们的分析表明，当这些对于梯度成立时，后者继承了亚高斯或亚指数浓度特性。这允许推导出对于最终估计的高置信度边界。最后，在这种条件下，在线性情况下，对于Polyak-Ruppert序列的尾部，我们获得了一个无维度偏差限制。所有结果均为非渐近性质，并讨论了其后果。",
    "tldr": "本文通过马尔科夫链研究了常步长随机梯度下降的性质，证明了迭代收敛于一个不变分布，并获得了高置信度边界。"
}