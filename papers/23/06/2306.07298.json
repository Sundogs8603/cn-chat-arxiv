{
    "title": "Referring to Screen Texts with Voice Assistants. (arXiv:2306.07298v1 [cs.HC])",
    "abstract": "Voice assistants help users make phone calls, send messages, create events, navigate, and do a lot more. However, assistants have limited capacity to understand their users' context. In this work, we aim to take a step in this direction. Our work dives into a new experience for users to refer to phone numbers, addresses, email addresses, URLs, and dates on their phone screens. Our focus lies in reference understanding, which becomes particularly interesting when multiple similar texts are present on screen, similar to visual grounding. We collect a dataset and propose a lightweight general-purpose model for this novel experience. Due to the high cost of consuming pixels directly, our system is designed to rely on the extracted text from the UI. Our model is modular, thus offering flexibility, improved interpretability, and efficient runtime memory utilization.",
    "link": "http://arxiv.org/abs/2306.07298",
    "context": "Title: Referring to Screen Texts with Voice Assistants. (arXiv:2306.07298v1 [cs.HC])\nAbstract: Voice assistants help users make phone calls, send messages, create events, navigate, and do a lot more. However, assistants have limited capacity to understand their users' context. In this work, we aim to take a step in this direction. Our work dives into a new experience for users to refer to phone numbers, addresses, email addresses, URLs, and dates on their phone screens. Our focus lies in reference understanding, which becomes particularly interesting when multiple similar texts are present on screen, similar to visual grounding. We collect a dataset and propose a lightweight general-purpose model for this novel experience. Due to the high cost of consuming pixels directly, our system is designed to rely on the extracted text from the UI. Our model is modular, thus offering flexibility, improved interpretability, and efficient runtime memory utilization.",
    "path": "papers/23/06/2306.07298.json",
    "total_tokens": 855,
    "translated_title": "用语音助手指引屏幕文本",
    "translated_abstract": "语音助手可以帮助用户打电话、发送消息、创建事件、导航等等，但助手能够理解用户的背景是有限的。本文旨在向这个方向迈进一步。我们的工作探索了一种新的体验，让用户可以指出他们手机屏幕上的电话号码、地址、电子邮件地址、URL和日期。我们的重点在于参考理解，当屏幕上存在多个相似的文本时，类似于视觉基础的情况，这变得特别有趣。我们收集了一个数据集，并为这种新颖体验提出了一个轻量级的通用模型。由于直接消耗像素成本高昂，我们的系统设计依赖于从UI中提取的文本。我们的模型是模块化的，因此提供了灵活性、改进的可解释性和高效的运行时内存利用率。",
    "tldr": "本文提出了一种新的体验，使用户可以通过语音助手引用他们手机屏幕上的电话号码、地址、电子邮件地址、URL和日期。我们设计了一个轻量级的模型，并收集了一个数据集。该模型是模块化的，提供了灵活性、改进的可解释性和高效的运行时内存利用率。",
    "en_tdlr": "The paper proposes a new experience for users to refer to phone numbers, addresses, email addresses, URLs, and dates on their phone screens using voice assistants and presents a lightweight modular model and dataset for reference understanding in such a scenario."
}