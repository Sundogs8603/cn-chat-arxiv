{
    "title": "Evaluating the overall sensitivity of saliency-based explanation methods. (arXiv:2306.13682v1 [cs.LG])",
    "abstract": "We address the need to generate faithful explanations of \"black box\" Deep Learning models. Several tests have been proposed to determine aspects of faithfulness of explanation methods, but they lack cross-domain applicability and a rigorous methodology. Hence, we select an existing test that is model agnostic and is well-suited for comparing one aspect of faithfulness (i.e., sensitivity) of multiple explanation methods, and extend it by specifying formal thresh-olds and building criteria to determine the over-all sensitivity of the explanation method. We present examples of how multiple explanation methods for Convolutional Neural Networks can be compared using this extended methodology. Finally, we discuss the relationship between sensitivity and faithfulness and consider how the test can be adapted to assess different explanation methods in other domains.",
    "link": "http://arxiv.org/abs/2306.13682",
    "context": "Title: Evaluating the overall sensitivity of saliency-based explanation methods. (arXiv:2306.13682v1 [cs.LG])\nAbstract: We address the need to generate faithful explanations of \"black box\" Deep Learning models. Several tests have been proposed to determine aspects of faithfulness of explanation methods, but they lack cross-domain applicability and a rigorous methodology. Hence, we select an existing test that is model agnostic and is well-suited for comparing one aspect of faithfulness (i.e., sensitivity) of multiple explanation methods, and extend it by specifying formal thresh-olds and building criteria to determine the over-all sensitivity of the explanation method. We present examples of how multiple explanation methods for Convolutional Neural Networks can be compared using this extended methodology. Finally, we discuss the relationship between sensitivity and faithfulness and consider how the test can be adapted to assess different explanation methods in other domains.",
    "path": "papers/23/06/2306.13682.json",
    "total_tokens": 818,
    "translated_title": "评估基于显著性的解释方法的总体敏感性",
    "translated_abstract": "我们着眼于生成对\"黑匣子\"深度学习模型的忠实解释的需求。已经提出了几种测试来确定解释方法的忠实程度，但它们缺乏跨领域的适用性和严谨的方法论。因此，我们选择了一个现有的不依赖特定模型，并且非常适合比较多个解释方法的忠实程度的测试，并通过指定正式的阈值和建立标准来扩展它，以确定解释方法的总体敏感性。我们通过例子展示了如何使用这个扩展方法来比较卷积神经网络的多个解释方法。最后，我们讨论了敏感性和忠实程度之间的关系，并考虑如何调整测试来评估其他领域的不同解释方法。",
    "tldr": "本文研究了如何生成对“黑匣子”深度学习模型的忠实解释，提出了一个扩展的测试方法来确定解释方法的总体敏感性，并通过例子展示了如何使用这个方法比较卷积神经网络的多个解释方法。",
    "en_tdlr": "This paper investigates the generation of faithful explanations for \"black box\" deep learning models, proposes an extended testing method to determine the overall sensitivity of explanation methods, and demonstrates how to compare multiple explanation methods for convolutional neural networks using this method."
}