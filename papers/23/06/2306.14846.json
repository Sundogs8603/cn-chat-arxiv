{
    "title": "ViNT: A Foundation Model for Visual Navigation. (arXiv:2306.14846v2 [cs.RO] UPDATED)",
    "abstract": "General-purpose pre-trained models (\"foundation models\") have enabled practitioners to produce generalizable solutions for individual machine learning problems with datasets that are significantly smaller than those required for learning from scratch. Such models are typically trained on large and diverse datasets with weak supervision, consuming much more training data than is available for any individual downstream application. In this paper, we describe the Visual Navigation Transformer (ViNT), a foundation model that aims to bring the success of general-purpose pre-trained models to vision-based robotic navigation. ViNT is trained with a general goal-reaching objective that can be used with any navigation dataset, and employs a flexible Transformer-based architecture to learn navigational affordances and enable efficient adaptation to a variety of downstream navigational tasks. ViNT is trained on a number of existing navigation datasets, comprising hundreds of hours of robotic navi",
    "link": "http://arxiv.org/abs/2306.14846",
    "context": "Title: ViNT: A Foundation Model for Visual Navigation. (arXiv:2306.14846v2 [cs.RO] UPDATED)\nAbstract: General-purpose pre-trained models (\"foundation models\") have enabled practitioners to produce generalizable solutions for individual machine learning problems with datasets that are significantly smaller than those required for learning from scratch. Such models are typically trained on large and diverse datasets with weak supervision, consuming much more training data than is available for any individual downstream application. In this paper, we describe the Visual Navigation Transformer (ViNT), a foundation model that aims to bring the success of general-purpose pre-trained models to vision-based robotic navigation. ViNT is trained with a general goal-reaching objective that can be used with any navigation dataset, and employs a flexible Transformer-based architecture to learn navigational affordances and enable efficient adaptation to a variety of downstream navigational tasks. ViNT is trained on a number of existing navigation datasets, comprising hundreds of hours of robotic navi",
    "path": "papers/23/06/2306.14846.json",
    "total_tokens": 909,
    "translated_title": "ViNT:一种用于视觉导航的基础模型",
    "translated_abstract": "通用预训练模型（\"基础模型\"）使从事机器学习问题的从业者能够使用比学习自零开始所需数据集小得多的数据，提供可泛化的解决方案。这些模型通常在大型和多样化的数据集上进行训练，使用弱监督进行学习，消耗比任何单个下游应用程序可用的训练数据要多得多。本文中，我们介绍了一种名为Visual Navigation Transformer（ViNT）的基础模型，旨在将通用预训练模型的成功应用于基于视觉的机器人导航。ViNT通过使用适用于任何导航数据集的通用目标达成目标来进行训练，并采用灵活的基于Transformer的架构来学习导航功能，并实现对各种下游导航任务的高效适应。ViNT在多个现有的导航数据集上进行了训练，涵盖数百小时的机器人导航数据。",
    "tldr": "该论文介绍了一种名为ViNT的基础模型，旨在将通用预训练模型的成功应用于视觉导航领域。ViNT通过通用目标达成目标进行训练，并采用灵活的Transformer架构来学习导航功能和实现对各种导航任务的高效适应。"
}