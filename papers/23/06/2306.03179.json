{
    "title": "Fair Patient Model: Mitigating Bias in the Patient Representation Learned from the Electronic Health Records. (arXiv:2306.03179v1 [cs.LG])",
    "abstract": "Objective: To pre-train fair and unbiased patient representations from Electronic Health Records (EHRs) using a novel weighted loss function that reduces bias and improves fairness in deep representation learning models.  Methods: We defined a new loss function, called weighted loss function, in the deep representation learning model to balance the importance of different groups of patients and features. We applied the proposed model, called Fair Patient Model (FPM), to a sample of 34,739 patients from the MIMIC-III dataset and learned patient representations for four clinical outcome prediction tasks.  Results: FPM outperformed the baseline models in terms of three fairness metrics: demographic parity, equality of opportunity difference, and equalized odds ratio. FPM also achieved comparable predictive performance with the baselines, with an average accuracy of 0.7912. Feature analysis revealed that FPM captured more information from clinical features than the baselines.  Conclusion: ",
    "link": "http://arxiv.org/abs/2306.03179",
    "context": "Title: Fair Patient Model: Mitigating Bias in the Patient Representation Learned from the Electronic Health Records. (arXiv:2306.03179v1 [cs.LG])\nAbstract: Objective: To pre-train fair and unbiased patient representations from Electronic Health Records (EHRs) using a novel weighted loss function that reduces bias and improves fairness in deep representation learning models.  Methods: We defined a new loss function, called weighted loss function, in the deep representation learning model to balance the importance of different groups of patients and features. We applied the proposed model, called Fair Patient Model (FPM), to a sample of 34,739 patients from the MIMIC-III dataset and learned patient representations for four clinical outcome prediction tasks.  Results: FPM outperformed the baseline models in terms of three fairness metrics: demographic parity, equality of opportunity difference, and equalized odds ratio. FPM also achieved comparable predictive performance with the baselines, with an average accuracy of 0.7912. Feature analysis revealed that FPM captured more information from clinical features than the baselines.  Conclusion: ",
    "path": "papers/23/06/2306.03179.json",
    "total_tokens": 937,
    "tldr": "研究提出了一种名为公平患者模型的新型加权损失函数，用于从电子健康记录中学习患者表示，以减少偏见和提高公平性。该模型实现了比基线模型更好的公平性指标，并表现出相当的预测性能。",
    "en_tdlr": "The study proposes a novel weighted loss function called Fair Patient Model (FPM) to pre-train fair and unbiased patient representations from Electronic Health Records (EHRs). FPM outperforms the baseline models in terms of fairness metrics and achieves comparable predictive performance."
}