{
    "title": "Improving Panoptic Segmentation for Nighttime or Low-Illumination Urban Driving Scenes. (arXiv:2306.13725v1 [cs.CV])",
    "abstract": "Autonomous vehicles and driving systems use scene parsing as an essential tool to understand the surrounding environment. Panoptic segmentation is a state-of-the-art technique which proves to be pivotal in this use case. Deep learning-based architectures have been utilized for effective and efficient Panoptic Segmentation in recent times. However, when it comes to adverse conditions like dark scenes with poor illumination or nighttime images, existing methods perform poorly in comparison to daytime images. One of the main factors for poor results is the lack of sufficient and accurately annotated nighttime images for urban driving scenes. In this work, we propose two new methods, first to improve the performance, and second to improve the robustness of panoptic segmentation in nighttime or poor illumination urban driving scenes using a domain translation approach. The proposed approach makes use of CycleGAN (Zhu et al., 2017) to translate daytime images with existing panoptic annotatio",
    "link": "http://arxiv.org/abs/2306.13725",
    "context": "Title: Improving Panoptic Segmentation for Nighttime or Low-Illumination Urban Driving Scenes. (arXiv:2306.13725v1 [cs.CV])\nAbstract: Autonomous vehicles and driving systems use scene parsing as an essential tool to understand the surrounding environment. Panoptic segmentation is a state-of-the-art technique which proves to be pivotal in this use case. Deep learning-based architectures have been utilized for effective and efficient Panoptic Segmentation in recent times. However, when it comes to adverse conditions like dark scenes with poor illumination or nighttime images, existing methods perform poorly in comparison to daytime images. One of the main factors for poor results is the lack of sufficient and accurately annotated nighttime images for urban driving scenes. In this work, we propose two new methods, first to improve the performance, and second to improve the robustness of panoptic segmentation in nighttime or poor illumination urban driving scenes using a domain translation approach. The proposed approach makes use of CycleGAN (Zhu et al., 2017) to translate daytime images with existing panoptic annotatio",
    "path": "papers/23/06/2306.13725.json",
    "total_tokens": 941,
    "translated_title": "改善夜间或低照度城市驾驶场景的全景分割",
    "translated_abstract": "自主驾驶汽车和驾驶系统使用场景解析作为了解环境的基本工具。全景分割是一种最先进的技术，在这种情况下被证明是至关重要的。近年来，基于深度学习的架构已被用于全景分割的有效和高效实现。然而，当面对黑暗、光照不足或夜间图像等恶劣条件时，现有方法的表现比白天图像的表现差。造成结果不佳的主要因素之一是缺乏足够和准确标注的城市驾驶夜间图像。在这项工作中，我们提出了两种新方法，一种是通过域翻译方法，提高全景分割在夜间或低照度城市驾驶场景中的性能和鲁棒性。所提出的方法利用CycleGAN（Zhu et al.，2017）将有现有全景注释的白天图像转换为其夜间版本。然后使用修改后的图像训练全景分割模型，该模型能够准确地在低照度场景下分割物体。",
    "tldr": "本文提出了两种新的方法，通过域翻译来提高全景分割在夜间或低照度城市驾驶场景中的性能和鲁棒性。",
    "en_tdlr": "This paper proposes two new methods to improve the performance and robustness of panoptic segmentation in nighttime or low-illumination urban driving scenes by using a domain translation approach."
}