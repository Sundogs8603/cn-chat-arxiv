{
    "title": "DCT: Dual Channel Training of Action Embeddings for Reinforcement Learning with Large Discrete Action Spaces. (arXiv:2306.15913v1 [cs.LG])",
    "abstract": "The ability to learn robust policies while generalizing over large discrete action spaces is an open challenge for intelligent systems, especially in noisy environments that face the curse of dimensionality. In this paper, we present a novel framework to efficiently learn action embeddings that simultaneously allow us to reconstruct the original action as well as to predict the expected future state. We describe an encoder-decoder architecture for action embeddings with a dual channel loss that balances between action reconstruction and state prediction accuracy. We use the trained decoder in conjunction with a standard reinforcement learning algorithm that produces actions in the embedding space. Our architecture is able to outperform two competitive baselines in two diverse environments: a 2D maze environment with more than 4000 discrete noisy actions, and a product recommendation task that uses real-world e-commerce transaction data. Empirical results show that the model results in ",
    "link": "http://arxiv.org/abs/2306.15913",
    "context": "Title: DCT: Dual Channel Training of Action Embeddings for Reinforcement Learning with Large Discrete Action Spaces. (arXiv:2306.15913v1 [cs.LG])\nAbstract: The ability to learn robust policies while generalizing over large discrete action spaces is an open challenge for intelligent systems, especially in noisy environments that face the curse of dimensionality. In this paper, we present a novel framework to efficiently learn action embeddings that simultaneously allow us to reconstruct the original action as well as to predict the expected future state. We describe an encoder-decoder architecture for action embeddings with a dual channel loss that balances between action reconstruction and state prediction accuracy. We use the trained decoder in conjunction with a standard reinforcement learning algorithm that produces actions in the embedding space. Our architecture is able to outperform two competitive baselines in two diverse environments: a 2D maze environment with more than 4000 discrete noisy actions, and a product recommendation task that uses real-world e-commerce transaction data. Empirical results show that the model results in ",
    "path": "papers/23/06/2306.15913.json",
    "total_tokens": 872,
    "translated_title": "DCT: 大离散动作空间强化学习的双通道动作嵌入训练",
    "translated_abstract": "在面临维度灾难的嘈杂环境中，学习稳健策略并广义化大离散动作空间是智能系统面临的一个挑战。本文提出了一种新颖的框架，能够高效地学习动作嵌入，同时实现对原始动作的重构以及对未来状态的预测。我们使用编码器-解码器架构进行动作嵌入，并通过双通道损失来平衡动作重构和状态预测精度。我们将训练好的解码器与标准强化学习算法结合使用，以在嵌入空间中生成动作。实验结果表明，我们的架构在一个具有4000多个离散噪声动作的2D迷宫环境和使用真实世界电子商务交易数据的产品推荐任务中能够胜过两个竞争基线模型。",
    "tldr": "本文提出了一个双通道动作嵌入训练的框架，能够在大离散动作空间中学习稳健策略，并成功应用在2D迷宫环境和真实世界电子商务任务中。",
    "en_tdlr": "A novel framework for dual channel training of action embeddings is proposed in this paper, which can learn robust policies in large discrete action spaces and achieve good performance in 2D maze environment and real-world e-commerce tasks."
}