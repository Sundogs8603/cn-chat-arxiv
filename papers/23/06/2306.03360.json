{
    "title": "Vid2Act: Activate Offline Videos for Visual RL. (arXiv:2306.03360v1 [cs.LG])",
    "abstract": "Pretraining RL models on offline video datasets is a promising way to improve their training efficiency in online tasks, but challenging due to the inherent mismatch in tasks, dynamics, and behaviors across domains. A recent model, APV, sidesteps the accompanied action records in offline datasets and instead focuses on pretraining a task-irrelevant, action-free world model within the source domains. We present Vid2Act, a model-based RL method that learns to transfer valuable action-conditioned dynamics and potentially useful action demonstrations from offline to online settings. The main idea is to use the world models not only as simulators for behavior learning but also as tools to measure the domain relevance for both dynamics representation transfer and policy transfer. Specifically, we train the world models to generate a set of time-varying task similarities using a domain-selective knowledge distillation loss. These similarities serve two purposes: (i) adaptively transferring th",
    "link": "http://arxiv.org/abs/2306.03360",
    "context": "Title: Vid2Act: Activate Offline Videos for Visual RL. (arXiv:2306.03360v1 [cs.LG])\nAbstract: Pretraining RL models on offline video datasets is a promising way to improve their training efficiency in online tasks, but challenging due to the inherent mismatch in tasks, dynamics, and behaviors across domains. A recent model, APV, sidesteps the accompanied action records in offline datasets and instead focuses on pretraining a task-irrelevant, action-free world model within the source domains. We present Vid2Act, a model-based RL method that learns to transfer valuable action-conditioned dynamics and potentially useful action demonstrations from offline to online settings. The main idea is to use the world models not only as simulators for behavior learning but also as tools to measure the domain relevance for both dynamics representation transfer and policy transfer. Specifically, we train the world models to generate a set of time-varying task similarities using a domain-selective knowledge distillation loss. These similarities serve two purposes: (i) adaptively transferring th",
    "path": "papers/23/06/2306.03360.json",
    "total_tokens": 1045,
    "translated_title": "Vid2Act：为视觉强化学习激活离线视频",
    "translated_abstract": "在离线视频数据集上预训练强化学习模型是提高其在线任务效率的有前途的方法，但由于跨域中任务、动态和行为的固有不匹配性而具有挑战性。最近，一种名为APV的模型避免了离线数据集中的伴随动作记录，而是专注于在源域内预训练与任务无关的、不涉及操作的世界模型。我们提出了Vid2Act，一种基于模型的强化学习方法，它学习从离线到在线环境中传输有价值的动作条件动态和潜在有用的动作演示。其主要思想是不仅将世界模型用作行为学习的模拟器，还将其用作测量领域相关性的工具，以便进行动态表示传输和策略传输。具体地，我们通过域选择知识蒸馏损失训练世界模型生成一组时间变化的任务相似度。这些相似度有两个目的：（i）自适应地将最相关的领域的动态传输到在线环境，和（ii）在在线环境中指导代理集中执行任务相关的动作。在Atari和DMControl连续控制任务上的实验结果表明了我们方法的有效性，其在样本效率方面大大优于之前的最先进的离线强化学习方法。",
    "tldr": "Vid2Act是一种基于模型的强化学习方法，它通过使用世界模型来传输领域相关的动态和策略，从而显著提高了样本效率。",
    "en_tdlr": "Vid2Act is a model-based RL method that significantly improves sample efficiency by transferring domain-relevant dynamics and policy using world models."
}