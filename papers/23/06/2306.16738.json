{
    "title": "Towards Optimal Randomized Strategies in Adversarial Example Game. (arXiv:2306.16738v1 [cs.LG])",
    "abstract": "The vulnerability of deep neural network models to adversarial example attacks is a practical challenge in many artificial intelligence applications. A recent line of work shows that the use of randomization in adversarial training is the key to find optimal strategies against adversarial example attacks. However, in a fully randomized setting where both the defender and the attacker can use randomized strategies, there are no efficient algorithm for finding such an optimal strategy. To fill the gap, we propose the first algorithm of its kind, called FRAT, which models the problem with a new infinite-dimensional continuous-time flow on probability distribution spaces. FRAT maintains a lightweight mixture of models for the defender, with flexibility to efficiently update mixing weights and model parameters at each iteration. Furthermore, FRAT utilizes lightweight sampling subroutines to construct a random strategy for the attacker. We prove that the continuous-time limit of FRAT converg",
    "link": "http://arxiv.org/abs/2306.16738",
    "context": "Title: Towards Optimal Randomized Strategies in Adversarial Example Game. (arXiv:2306.16738v1 [cs.LG])\nAbstract: The vulnerability of deep neural network models to adversarial example attacks is a practical challenge in many artificial intelligence applications. A recent line of work shows that the use of randomization in adversarial training is the key to find optimal strategies against adversarial example attacks. However, in a fully randomized setting where both the defender and the attacker can use randomized strategies, there are no efficient algorithm for finding such an optimal strategy. To fill the gap, we propose the first algorithm of its kind, called FRAT, which models the problem with a new infinite-dimensional continuous-time flow on probability distribution spaces. FRAT maintains a lightweight mixture of models for the defender, with flexibility to efficiently update mixing weights and model parameters at each iteration. Furthermore, FRAT utilizes lightweight sampling subroutines to construct a random strategy for the attacker. We prove that the continuous-time limit of FRAT converg",
    "path": "papers/23/06/2306.16738.json",
    "total_tokens": 880,
    "translated_title": "在对抗性样本对抗中优化随机策略",
    "translated_abstract": "深度神经网络模型对抗性样本攻击的脆弱性是许多人工智能应用中的实际挑战。最近的研究表明，在对抗性训练中使用随机化是找到对抗性样本攻击的最优策略的关键。然而，在一个完全随机化的情况下，防守者和攻击者都可以使用随机策略，目前没有有效的算法来找到这样一个最优策略。为了填补这个空白，我们提出了一种新的算法FRAT，它采用了一个新的无限维连续时间概率分布空间上的流来建模问题。FRAT为防守者维护了一个轻量级模型混合，具有在每次迭代中有效更新混合权重和模型参数的灵活性。此外，FRAT利用轻量级的采样子例程来构建攻击者的随机策略。我们证明了FRAT的连续时间极限的收敛性。",
    "tldr": "该论文提出了一种新算法FRAT，用于在对抗性样本攻击中优化随机策略。该算法通过在概率分布空间上建模问题，并维护轻量级的模型混合来达到目的。"
}