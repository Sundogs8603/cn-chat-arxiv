{
    "title": "Surrogate Model Extension (SME): A Fast and Accurate Weight Update Attack on Federated Learning. (arXiv:2306.00127v1 [cs.LG])",
    "abstract": "In Federated Learning (FL) and many other distributed training frameworks, collaborators can hold their private data locally and only share the network weights trained with the local data after multiple iterations. Gradient inversion is a family of privacy attacks that recovers data from its generated gradients. Seemingly, FL can provide a degree of protection against gradient inversion attacks on weight updates, since the gradient of a single step is concealed by the accumulation of gradients over multiple local iterations. In this work, we propose a principled way to extend gradient inversion attacks to weight updates in FL, thereby better exposing weaknesses in the presumed privacy protection inherent in FL. In particular, we propose a surrogate model method based on the characteristic of two-dimensional gradient flow and low-rank property of local updates. Our method largely boosts the ability of gradient inversion attacks on weight updates containing many iterations and achieves s",
    "link": "http://arxiv.org/abs/2306.00127",
    "context": "Title: Surrogate Model Extension (SME): A Fast and Accurate Weight Update Attack on Federated Learning. (arXiv:2306.00127v1 [cs.LG])\nAbstract: In Federated Learning (FL) and many other distributed training frameworks, collaborators can hold their private data locally and only share the network weights trained with the local data after multiple iterations. Gradient inversion is a family of privacy attacks that recovers data from its generated gradients. Seemingly, FL can provide a degree of protection against gradient inversion attacks on weight updates, since the gradient of a single step is concealed by the accumulation of gradients over multiple local iterations. In this work, we propose a principled way to extend gradient inversion attacks to weight updates in FL, thereby better exposing weaknesses in the presumed privacy protection inherent in FL. In particular, we propose a surrogate model method based on the characteristic of two-dimensional gradient flow and low-rank property of local updates. Our method largely boosts the ability of gradient inversion attacks on weight updates containing many iterations and achieves s",
    "path": "papers/23/06/2306.00127.json",
    "total_tokens": 923,
    "translated_title": "Surrogate Model Extension (SME): 一种快速准确的联邦学习权重更新攻击方法",
    "translated_abstract": "在联邦学习（FL）和分布式训练框架中，合作者可以在本地保存其私有数据，并在多次迭代后仅分享使用本地数据训练的网络权重。梯度反演是一类从生成的梯度中恢复数据的隐私攻击方法。在FL中，单个步骤的梯度被多次本地迭代的梯度积累所遮盖，似乎可以提供一定的保护，防止梯度反演攻击权重更新。本文提出了一种合理的方法，将梯度反演攻击扩展到FL权重更新中，从而更好地暴露FL本身所假定的隐私保护弱点。特别地，我们提出了一种基于二维梯度流特征和本地更新低秩性质的替代模型方法。我们的方法极大地提升了包含多次迭代的权重更新受梯度反演攻击的能力，并实现了非常高的攻击成功率。",
    "tldr": "本文提出了一种称为 Surrogate Model Extension (SME) 的方法，使得在联邦学习中，攻击者可以使用比之前更加高效和准确的方法对权重更新进行隐私攻击，进一步暴露了联邦学习中的隐私保护弱点。",
    "en_tdlr": "This paper introduces a method called Surrogate Model Extension (SME), which enables attackers to use more efficient and accurate methods to launch privacy attacks on weight updates in Federated Learning, further exposing the privacy protection weaknesses in Federated Learning."
}