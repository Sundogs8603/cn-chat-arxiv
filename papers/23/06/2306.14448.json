{
    "title": "Progressive Energy-Based Cooperative Learning for Multi-Domain Image-to-Image Translation. (arXiv:2306.14448v3 [cs.CV] UPDATED)",
    "abstract": "This paper studies a novel energy-based cooperative learning framework for multi-domain image-to-image translation. The framework consists of four components: descriptor, translator, style encoder, and style generator. The descriptor is a multi-head energy-based model that represents a multi-domain image distribution. The components of translator, style encoder, and style generator constitute a diversified image generator. Specifically, given an input image from a source domain, the translator turns it into a stylised output image of the target domain according to a style code, which can be inferred by the style encoder from a reference image or produced by the style generator from a random noise. Since the style generator is represented as an domain-specific distribution of style codes, the translator can provide a one-to-many transformation (i.e., diversified generation) between source domain and target domain. To train our framework, we propose a likelihood-based multi-domain cooper",
    "link": "http://arxiv.org/abs/2306.14448",
    "context": "Title: Progressive Energy-Based Cooperative Learning for Multi-Domain Image-to-Image Translation. (arXiv:2306.14448v3 [cs.CV] UPDATED)\nAbstract: This paper studies a novel energy-based cooperative learning framework for multi-domain image-to-image translation. The framework consists of four components: descriptor, translator, style encoder, and style generator. The descriptor is a multi-head energy-based model that represents a multi-domain image distribution. The components of translator, style encoder, and style generator constitute a diversified image generator. Specifically, given an input image from a source domain, the translator turns it into a stylised output image of the target domain according to a style code, which can be inferred by the style encoder from a reference image or produced by the style generator from a random noise. Since the style generator is represented as an domain-specific distribution of style codes, the translator can provide a one-to-many transformation (i.e., diversified generation) between source domain and target domain. To train our framework, we propose a likelihood-based multi-domain cooper",
    "path": "papers/23/06/2306.14448.json",
    "total_tokens": 868,
    "translated_title": "渐进能量协作学习用于多域图像到图像的转换",
    "translated_abstract": "本文研究了一种新颖的基于能量的合作学习框架，用于多域图像到图像的转换。该框架由四个组件组成：描述器、翻译器、风格编码器和风格生成器。描述器是一个多头能量模型，表示多域图像分布。翻译器、风格编码器和风格生成器的组件构成了一个多样化图像生成器。具体而言，给定一个来自源域的输入图像，翻译器根据风格代码将其转换为目标域的风格化输出图像，风格代码可以由风格编码器从参考图像推断出或由风格生成器从随机噪声生成。由于风格生成器被表示为特定于域的风格代码分布，翻译器可以在源域和目标域之间提供一对多的转换（即多样化生成）。为了训练我们的框架，我们提出了一个基于似然的多域合作学习方法。",
    "tldr": "本文提出了一种渐进能量协作学习框架，用于多域图像到图像的转换。该框架包含描述器、翻译器、风格编码器和风格生成器四个组件。通过这种框架，可以实现多样化的图像生成和一对多的转换。"
}