{
    "title": "Solving and Generating NPR Sunday Puzzles with Large Language Models. (arXiv:2306.12255v1 [cs.CL])",
    "abstract": "We explore the ability of large language models to solve and generate puzzles from the NPR Sunday Puzzle game show using PUZZLEQA, a dataset comprising 15 years of on-air puzzles. We evaluate four large language models using PUZZLEQA, in both multiple choice and free response formats, and explore two prompt engineering techniques to improve free response performance: chain-of-thought reasoning and prompt summarization. We find that state-of-the-art large language models can solve many PUZZLEQA puzzles: the best model, GPT-3.5, achieves 50.2% loose accuracy. However, in our few-shot puzzle generation experiment, we find no evidence that models can generate puzzles: GPT-3.5 generates puzzles with answers that do not conform to the generated rules. Puzzle generation remains a challenging task for future work.",
    "link": "http://arxiv.org/abs/2306.12255",
    "context": "Title: Solving and Generating NPR Sunday Puzzles with Large Language Models. (arXiv:2306.12255v1 [cs.CL])\nAbstract: We explore the ability of large language models to solve and generate puzzles from the NPR Sunday Puzzle game show using PUZZLEQA, a dataset comprising 15 years of on-air puzzles. We evaluate four large language models using PUZZLEQA, in both multiple choice and free response formats, and explore two prompt engineering techniques to improve free response performance: chain-of-thought reasoning and prompt summarization. We find that state-of-the-art large language models can solve many PUZZLEQA puzzles: the best model, GPT-3.5, achieves 50.2% loose accuracy. However, in our few-shot puzzle generation experiment, we find no evidence that models can generate puzzles: GPT-3.5 generates puzzles with answers that do not conform to the generated rules. Puzzle generation remains a challenging task for future work.",
    "path": "papers/23/06/2306.12255.json",
    "total_tokens": 830,
    "translated_title": "用大型语言模型解决和生成 NPR Sunday Puzzles。",
    "translated_abstract": "我们使用 PUZZLEQA 数据集探究了大型语言模型解决和生成 NPR Sunday Puzzle 游戏节目谜题的能力，该数据集包含 15 年的节目谜题。我们使用四个大型语言模型在 PUZZLEQA 上进行了评估，包括多项选择和自由回答格式，并探讨了两种提示工程技术以提高自由回答表现：思维链推理和提示摘要。我们发现，最先进的大型语言模型可以解决许多 PUZZLEQA 谜题：最好的模型 GPT-3.5 达到了 50.2% 的松散准确率。然而，在我们的少量样本谜题生成实验中，我们发现模型无法生成谜题：GPT-3.5 生成的谜题答案不符合生成的规则。谜题生成仍然是未来工作的一项挑战性任务。",
    "tldr": "本文探究了大型语言模型用于解决和生成 NPR Sunday Puzzles 的能力。研究表明，大型语言模型可以有效解决许多 PUZZLEQA 谜题，但目前尚无法生成谜题。"
}