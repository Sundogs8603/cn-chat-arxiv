{
    "title": "On the Convergence of Coordinate Ascent Variational Inference. (arXiv:2306.01122v1 [stat.ML])",
    "abstract": "As a computational alternative to Markov chain Monte Carlo approaches, variational inference (VI) is becoming more and more popular for approximating intractable posterior distributions in large-scale Bayesian models due to its comparable efficacy and superior efficiency. Several recent works provide theoretical justifications of VI by proving its statistical optimality for parameter estimation under various settings; meanwhile, formal analysis on the algorithmic convergence aspects of VI is still largely lacking. In this paper, we consider the common coordinate ascent variational inference (CAVI) algorithm for implementing the mean-field (MF) VI towards optimizing a Kullback--Leibler divergence objective functional over the space of all factorized distributions. Focusing on the two-block case, we analyze the convergence of CAVI by leveraging the extensive toolbox from functional analysis and optimization. We provide general conditions for certifying global or local exponential converg",
    "link": "http://arxiv.org/abs/2306.01122",
    "context": "Title: On the Convergence of Coordinate Ascent Variational Inference. (arXiv:2306.01122v1 [stat.ML])\nAbstract: As a computational alternative to Markov chain Monte Carlo approaches, variational inference (VI) is becoming more and more popular for approximating intractable posterior distributions in large-scale Bayesian models due to its comparable efficacy and superior efficiency. Several recent works provide theoretical justifications of VI by proving its statistical optimality for parameter estimation under various settings; meanwhile, formal analysis on the algorithmic convergence aspects of VI is still largely lacking. In this paper, we consider the common coordinate ascent variational inference (CAVI) algorithm for implementing the mean-field (MF) VI towards optimizing a Kullback--Leibler divergence objective functional over the space of all factorized distributions. Focusing on the two-block case, we analyze the convergence of CAVI by leveraging the extensive toolbox from functional analysis and optimization. We provide general conditions for certifying global or local exponential converg",
    "path": "papers/23/06/2306.01122.json",
    "total_tokens": 871,
    "translated_title": "论坐标上升变分推断的收敛性问题",
    "translated_abstract": "变分推断（VI）作为马尔科夫链蒙特卡洛方法的一种计算替代方法，由于其可比较的功效和卓越的效率，在大规模贝叶斯模型中用于近似难以计算的后验分布越来越受欢迎。尽管有几项最近的工作通过证明在不同设置下VI在参数估计方面的统计最优性，为VI提供了理论证据，但对VI算法收敛性方面的形式化分析仍然缺乏。在本文中，我们考虑了常见的坐标上升变分推断（CAVI）算法，以实现均值场（MF）VI，并优化所有分解分布空间上的KL散度目标功能。我们通过利用函数分析和优化的广泛工具箱，重点关注两个块的情况，分析CAVI的收敛性。我们提供了证明全局或局部指数收敛的一般条件。",
    "tldr": "本文通过分析常见的坐标上升变分推断（CAVI）算法在两个块的情况下的收敛性，提供了证明全局或局部指数收敛的一般条件。",
    "en_tdlr": "This paper provides general conditions for certifying global or local exponential convergence by analyzing the convergence of the common coordinate ascent variational inference (CAVI) algorithm in the two-block case for implementing the mean-field (MF) VI towards optimizing a Kullback-Leibler divergence objective functional over the space of all factorized distributions."
}