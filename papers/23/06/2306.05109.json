{
    "title": "Yet Another ICU Benchmark: A Flexible Multi-Center Framework for Clinical ML. (arXiv:2306.05109v1 [cs.LG])",
    "abstract": "Medical applications of machine learning (ML) have experienced a surge in popularity in recent years. The intensive care unit (ICU) is a natural habitat for ML given the abundance of available data from electronic health records. Models have been proposed to address numerous ICU prediction tasks like the early detection of complications. While authors frequently report state-of-the-art performance, it is challenging to verify claims of superiority. Datasets and code are not always published, and cohort definitions, preprocessing pipelines, and training setups are difficult to reproduce. This work introduces Yet Another ICU Benchmark (YAIB), a modular framework that allows researchers to define reproducible and comparable clinical ML experiments; we offer an end-to-end solution from cohort definition to model evaluation. The framework natively supports most open-access ICU datasets (MIMIC III/IV, eICU, HiRID, AUMCdb) and is easily adaptable to future ICU datasets. Combined with a transp",
    "link": "http://arxiv.org/abs/2306.05109",
    "context": "Title: Yet Another ICU Benchmark: A Flexible Multi-Center Framework for Clinical ML. (arXiv:2306.05109v1 [cs.LG])\nAbstract: Medical applications of machine learning (ML) have experienced a surge in popularity in recent years. The intensive care unit (ICU) is a natural habitat for ML given the abundance of available data from electronic health records. Models have been proposed to address numerous ICU prediction tasks like the early detection of complications. While authors frequently report state-of-the-art performance, it is challenging to verify claims of superiority. Datasets and code are not always published, and cohort definitions, preprocessing pipelines, and training setups are difficult to reproduce. This work introduces Yet Another ICU Benchmark (YAIB), a modular framework that allows researchers to define reproducible and comparable clinical ML experiments; we offer an end-to-end solution from cohort definition to model evaluation. The framework natively supports most open-access ICU datasets (MIMIC III/IV, eICU, HiRID, AUMCdb) and is easily adaptable to future ICU datasets. Combined with a transp",
    "path": "papers/23/06/2306.05109.json",
    "total_tokens": 985,
    "translated_abstract": "最近几年，机器学习在医疗应用方面变得越来越受欢迎。由于电子健康记录中可用数据的丰富，重症监护室（ICU）是机器学习的天然栖息地。已经提出了许多模型来解决ICU预测任务，如并发症的早期检测。虽然作者经常报告最新的表现结果，但要验证优越性的声明是具有挑战性的。数据集和代码并不总是公开发布，且难以复制队列定义、预处理管道和训练设置。本研究介绍了一个名为“Yet Another ICU Benchmark”的模块化框架，允许研究人员定义可重复和可比较的临床机器学习实验; 我们提供了从队列定义到模型评估的端到端解决方案。该框架本地支持大多数公开访问的ICU数据集（MIMIC III / IV、eICU、HiRID、AUMCdb），并且易于适应未来的ICU数据集。结合透明约定和开放源代码的灵活性，YAIB支持ICU ML领域的科学实证。",
    "tldr": "本研究提出了名为“Yet Another ICU Benchmark”的模块化框架，支持多个公开访问的ICU数据集，并提供从队列定义到模型评估的端到端解决方案，旨在解决临床机器学习领域中数据不可复制的问题。",
    "en_tdlr": "This study introduces a modular framework called \"Yet Another ICU Benchmark\" which supports multiple open-access ICU datasets and provides an end-to-end solution from cohort definition to model evaluation, addressing the issue of irreproducibility in clinical ML."
}