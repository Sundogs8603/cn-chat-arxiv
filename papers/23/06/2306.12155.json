{
    "title": "Joint Dense-Point Representation for Contour-Aware Graph Segmentation. (arXiv:2306.12155v1 [cs.CV])",
    "abstract": "We present a novel methodology that combines graph and dense segmentation techniques by jointly learning both point and pixel contour representations, thereby leveraging the benefits of each approach. This addresses deficiencies in typical graph segmentation methods where misaligned objectives restrict the network from learning discriminative vertex and contour features. Our joint learning strategy allows for rich and diverse semantic features to be encoded, while alleviating common contour stability issues in dense-based approaches, where pixel-level objectives can lead to anatomically implausible topologies. In addition, we identify scenarios where correct predictions that fall on the contour boundary are penalised and address this with a novel hybrid contour distance loss. Our approach is validated on several Chest X-ray datasets, demonstrating clear improvements in segmentation stability and accuracy against a variety of dense- and point-based methods. Our source code is freely ava",
    "link": "http://arxiv.org/abs/2306.12155",
    "context": "Title: Joint Dense-Point Representation for Contour-Aware Graph Segmentation. (arXiv:2306.12155v1 [cs.CV])\nAbstract: We present a novel methodology that combines graph and dense segmentation techniques by jointly learning both point and pixel contour representations, thereby leveraging the benefits of each approach. This addresses deficiencies in typical graph segmentation methods where misaligned objectives restrict the network from learning discriminative vertex and contour features. Our joint learning strategy allows for rich and diverse semantic features to be encoded, while alleviating common contour stability issues in dense-based approaches, where pixel-level objectives can lead to anatomically implausible topologies. In addition, we identify scenarios where correct predictions that fall on the contour boundary are penalised and address this with a novel hybrid contour distance loss. Our approach is validated on several Chest X-ray datasets, demonstrating clear improvements in segmentation stability and accuracy against a variety of dense- and point-based methods. Our source code is freely ava",
    "path": "papers/23/06/2306.12155.json",
    "total_tokens": 851,
    "translated_title": "基于密集点表示的轮廓感知图形分割方法",
    "translated_abstract": "我们提出了一种新的方法，通过联合学习点和像素轮廓表示，将图形和密集分割技术相结合，从而发挥每种方法的优点。这样可以解决典型图形分割方法中目标错位限制网络学习区分性顶点和轮廓特征的问题。我们的联合学习策略允许编码丰富和多样的语义特征，同时缓解了在基于密集方法中常见的轮廓不稳定性问题，其中像素级目标可能会导致解剖学上不合理的拓扑结构。此外，我们确定了正确预测仍落在轮廓边界上的情况，并通过新的混合轮廓距离损失来解决这个问题。我们的方法在多个胸部X线数据集上进行验证，对比了多种密集和点检测方法，证明了分割稳定性和准确性的明显改善。我们的源代码是免费提供的。",
    "tldr": "该论文提出了一种利用点检测和像素分割技术联合学习的图形分割方法，从而克服了传统方法中的一些缺陷，提高了分割的稳定性和准确性。",
    "en_tdlr": "The paper proposes a joint learning approach that combines point and pixel contour representations for graph segmentation, which overcomes deficiencies in traditional methods and improves segmentation stability and accuracy."
}