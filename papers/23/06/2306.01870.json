{
    "title": "Layer-Wise Feedback Alignment is Conserved in Deep Neural Networks. (arXiv:2306.01870v1 [cs.LG])",
    "abstract": "In the quest to enhance the efficiency and bio-plausibility of training deep neural networks, Feedback Alignment (FA), which replaces the backward pass weights with random matrices in the training process, has emerged as an alternative to traditional backpropagation. While the appeal of FA lies in its circumvention of computational challenges and its plausible biological alignment, the theoretical understanding of this learning rule remains partial. This paper uncovers a set of conservation laws underpinning the learning dynamics of FA, revealing intriguing parallels between FA and Gradient Descent (GD). Our analysis reveals that FA harbors implicit biases akin to those exhibited by GD, challenging the prevailing narrative that these learning algorithms are fundamentally different. Moreover, we demonstrate that these conservation laws elucidate sufficient conditions for layer-wise alignment with feedback matrices in ReLU networks. We further show that this implies over-parameterized tw",
    "link": "http://arxiv.org/abs/2306.01870",
    "context": "Title: Layer-Wise Feedback Alignment is Conserved in Deep Neural Networks. (arXiv:2306.01870v1 [cs.LG])\nAbstract: In the quest to enhance the efficiency and bio-plausibility of training deep neural networks, Feedback Alignment (FA), which replaces the backward pass weights with random matrices in the training process, has emerged as an alternative to traditional backpropagation. While the appeal of FA lies in its circumvention of computational challenges and its plausible biological alignment, the theoretical understanding of this learning rule remains partial. This paper uncovers a set of conservation laws underpinning the learning dynamics of FA, revealing intriguing parallels between FA and Gradient Descent (GD). Our analysis reveals that FA harbors implicit biases akin to those exhibited by GD, challenging the prevailing narrative that these learning algorithms are fundamentally different. Moreover, we demonstrate that these conservation laws elucidate sufficient conditions for layer-wise alignment with feedback matrices in ReLU networks. We further show that this implies over-parameterized tw",
    "path": "papers/23/06/2306.01870.json",
    "total_tokens": 937,
    "translated_title": "层间反馈对齐在深度神经网络中的保守性",
    "translated_abstract": "为了提高深度神经网络的效率和生物可塑性，反馈对齐（FA）作为传统反向传播的替代方法应运而生，它将训练过程中的反向传输权重替换为随机矩阵。虽然FA的吸引力在于它能够绕过计算挑战和其可信的生物对齐性，但对于这种学习规则的理解还是有所欠缺的。本文揭示了支撑FA学习动态的一组守恒定律，揭示了FA和梯度下降（GD）之间的有趣相似之处。我们的分析表明，FA具有与GD表现出的隐式偏差相似的隐式偏差，挑战了现有的这些学习算法之间根本不同的流行说法。此外，我们证明，这些守恒定律阐明了ReLU网络中与反馈矩阵对齐的充分条件。我们进一步展示，这意味着过参数化的双线性网络中可以实现线性地代替后向权重。",
    "tldr": "本论文揭示了层间反馈对齐在深度神经网络中的保守性，并发现FA与GD之间存在隐式偏差的相似之处，同时阐明了ReLU网络中与反馈矩阵对齐的充分条件。",
    "en_tdlr": "This paper reveals the conservation laws underlying the learning dynamics of Feedback Alignment (FA) in deep neural networks. The authors discovered intriguing similarities between FA and Gradient Descent (GD) and showed that sufficient conditions for layer-wise alignment with feedback matrices in ReLU networks can be elucidated by these conservation laws."
}