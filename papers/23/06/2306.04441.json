{
    "title": "STEPS: A Benchmark for Order Reasoning in Sequential Tasks. (arXiv:2306.04441v1 [cs.CL])",
    "abstract": "Various human activities can be abstracted into a sequence of actions in natural text, i.e. cooking, repairing, manufacturing, etc. Such action sequences heavily depend on the executing order, while disorder in action sequences leads to failure of further task execution by robots or AI agents. Therefore, to verify the order reasoning capability of current neural models in sequential tasks, we propose a challenging benchmark , named STEPS. STEPS involves two subtask settings, focusing on determining the rationality of given next step in recipes and selecting the reasonable step from the multi-choice question, respectively. We describe the data construction and task formulations, and benchmark most of significant Large Language Models (LLMs). The experimental results demonstrate 1) The commonsense reasoning of action orders in sequential tasks are challenging to resolve via zero-shot prompting or few-shot in-context learning for LLMs; 2) Prompting method still significantly lags behind t",
    "link": "http://arxiv.org/abs/2306.04441",
    "context": "Title: STEPS: A Benchmark for Order Reasoning in Sequential Tasks. (arXiv:2306.04441v1 [cs.CL])\nAbstract: Various human activities can be abstracted into a sequence of actions in natural text, i.e. cooking, repairing, manufacturing, etc. Such action sequences heavily depend on the executing order, while disorder in action sequences leads to failure of further task execution by robots or AI agents. Therefore, to verify the order reasoning capability of current neural models in sequential tasks, we propose a challenging benchmark , named STEPS. STEPS involves two subtask settings, focusing on determining the rationality of given next step in recipes and selecting the reasonable step from the multi-choice question, respectively. We describe the data construction and task formulations, and benchmark most of significant Large Language Models (LLMs). The experimental results demonstrate 1) The commonsense reasoning of action orders in sequential tasks are challenging to resolve via zero-shot prompting or few-shot in-context learning for LLMs; 2) Prompting method still significantly lags behind t",
    "path": "papers/23/06/2306.04441.json",
    "total_tokens": 924,
    "translated_title": "STEPS：顺序任务中顺序推理的基准测试",
    "translated_abstract": "各种人类活动可以抽象为自然文本中的一系列行动，例如烹饪，维修，制造等。这样的行动序列很大程度上取决于执行顺序，而序列中的混乱会导致机器人或AI代理无法进一步执行任务失败。因此，为了验证当前神经模型在顺序任务中的顺序推理能力，我们提出了一个具有挑战性的基准测试，名为STEPS。STEPS包括两个子任务设置，分别关注确定给定食谱中下一个步骤的合理性和从多项选择题中选择合理的步骤。我们描述了数据构建和任务公式，并基准测试了大部分显著的大型语言模型（LLM）。实验结果表明：1）解决顺序任务中的常识推理挑战需要使用LLMs的零-shot提示或少量上下文学习；2）提示方法仍然明显落后于上下文方法。",
    "tldr": "STEPS是一个具有挑战性的顺序推理任务基准测试，用于验证当前神经模型在顺序任务中的顺序推理能力。实验结果表明，解决顺序任务中的常识推理挑战需要使用LLMs的零-shot提示或少量上下文学习，而提示方法仍然明显落后于上下文方法。",
    "en_tdlr": "STEPS is a challenging benchmark for order reasoning in sequential tasks that verifies the order reasoning capability of current neural models. The experimental results demonstrate that solving the common-sense reasoning challenge in sequential tasks requires zero-shot prompting or few-shot in-context learning for LLMs, while prompting methods still significantly lag behind contextual methods."
}