{
    "title": "Representation and decomposition of functions in DAG-DNNs and structural network pruning. (arXiv:2306.09707v1 [cs.LG])",
    "abstract": "The conclusions provided by deep neural networks (DNNs) must be carefully scrutinized to determine whether they are universal or architecture dependent. The term DAG-DNN refers to a graphical representation of a DNN in which the architecture is expressed as a direct-acyclic graph (DAG), on which arcs are associated with functions. The level of a node denotes the maximum number of hops between the input node and the node of interest. In the current study, we demonstrate that DAG-DNNs can be used to derive all functions defined on various sub-architectures of the DNN. We also demonstrate that the functions defined in a DAG-DNN can be derived via a sequence of lower-triangular matrices, each of which provides the transition of functions defined in sub-graphs up to nodes at a specified level. The lifting structure associated with lower-triangular matrices makes it possible to perform the structural pruning of a network in a systematic manner. The fact that decomposition is universally appl",
    "link": "http://arxiv.org/abs/2306.09707",
    "context": "Title: Representation and decomposition of functions in DAG-DNNs and structural network pruning. (arXiv:2306.09707v1 [cs.LG])\nAbstract: The conclusions provided by deep neural networks (DNNs) must be carefully scrutinized to determine whether they are universal or architecture dependent. The term DAG-DNN refers to a graphical representation of a DNN in which the architecture is expressed as a direct-acyclic graph (DAG), on which arcs are associated with functions. The level of a node denotes the maximum number of hops between the input node and the node of interest. In the current study, we demonstrate that DAG-DNNs can be used to derive all functions defined on various sub-architectures of the DNN. We also demonstrate that the functions defined in a DAG-DNN can be derived via a sequence of lower-triangular matrices, each of which provides the transition of functions defined in sub-graphs up to nodes at a specified level. The lifting structure associated with lower-triangular matrices makes it possible to perform the structural pruning of a network in a systematic manner. The fact that decomposition is universally appl",
    "path": "papers/23/06/2306.09707.json",
    "total_tokens": 869,
    "translated_title": "DAG-DNN中函数的表示和分解以及结构网络剪枝",
    "translated_abstract": "必须仔细检查深度神经网络（DNN）提供的结论是普适的还是依赖于架构的。术语DAG-DNN指的是用直接无环图（DAG）表示架构的DNN的图形表示，其中弧与函数相关联。节点的级别表示输入节点和感兴趣节点之间的最大跳数。在当前研究中，我们演示了DAG-DNN可用于推导在DNN各个子架构上定义的所有函数。我们还演示了在DAG-DNN中定义的函数可以通过一系列下三角矩阵导出，其中每个矩阵提供了将子图中定义的函数过渡到指定级别节点的转换。与下三角矩阵相关联的lifting结构使得可以以系统化的方式执行网络的结构剪枝。分解是普遍适用的事实。",
    "tldr": "本研究提出了一种新的DNN表示方法DAG-DNN，利用下三角矩阵分解的方法对其进行结构网络剪枝，同时证明DAG-DNN可以推导出DNN各个子架构上定义的所有函数。"
}