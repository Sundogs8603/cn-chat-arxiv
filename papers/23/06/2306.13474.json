{
    "title": "Efficient Online Processing with Deep Neural Networks. (arXiv:2306.13474v1 [cs.LG])",
    "abstract": "The capabilities and adoption of deep neural networks (DNNs) grow at an exhilarating pace: Vision models accurately classify human actions in videos and identify cancerous tissue in medical scans as precisely than human experts; large language models answer wide-ranging questions, generate code, and write prose, becoming the topic of everyday dinner-table conversations. Even though their uses are exhilarating, the continually increasing model sizes and computational complexities have a dark side. The economic cost and negative environmental externalities of training and serving models is in evident disharmony with financial viability and climate action goals.  Instead of pursuing yet another increase in predictive performance, this dissertation is dedicated to the improvement of neural network efficiency. Specifically, a core contribution addresses the efficiency aspects during online inference. Here, the concept of Continual Inference Networks (CINs) is proposed and explored across fo",
    "link": "http://arxiv.org/abs/2306.13474",
    "context": "Title: Efficient Online Processing with Deep Neural Networks. (arXiv:2306.13474v1 [cs.LG])\nAbstract: The capabilities and adoption of deep neural networks (DNNs) grow at an exhilarating pace: Vision models accurately classify human actions in videos and identify cancerous tissue in medical scans as precisely than human experts; large language models answer wide-ranging questions, generate code, and write prose, becoming the topic of everyday dinner-table conversations. Even though their uses are exhilarating, the continually increasing model sizes and computational complexities have a dark side. The economic cost and negative environmental externalities of training and serving models is in evident disharmony with financial viability and climate action goals.  Instead of pursuing yet another increase in predictive performance, this dissertation is dedicated to the improvement of neural network efficiency. Specifically, a core contribution addresses the efficiency aspects during online inference. Here, the concept of Continual Inference Networks (CINs) is proposed and explored across fo",
    "path": "papers/23/06/2306.13474.json",
    "total_tokens": 844,
    "translated_title": "高效的深度神经网络在线处理",
    "translated_abstract": "深度神经网络的能力和应用正在以惊人的速度增长：视觉模型准确分类人类在视频中的动作，并像人类专家一样准确地识别医学扫描中的癌细胞组织；大型语言模型可以回答各种问题、生成代码和写作，成为日常餐桌谈论的主题。尽管它们的用途令人振奋，但不断增加的模型大小和计算复杂度也有负面影响。训练和服务模型的经济成本和负面环境外部性与财务可行性和气候行动目标不相协调。本论文致力于提高神经网络的效率，而不是追求预测性能的进一步提高。具体地，本论文的一个核心贡献是解决了在线推断过程中的效率问题。在这里，提出并研究了连续推断网络（CINs）的概念。",
    "tldr": "该论文致力于提高神经网络的效率，提出并研究了连续推断网络（CINs）的概念，重点讨论在线推理的效率问题。",
    "en_tdlr": "This paper is dedicated to improving the efficiency of neural networks. It proposes and explores the concept of Continual Inference Networks (CINs) to address efficiency during online inference, instead of pursuing further increases in predictive performance."
}