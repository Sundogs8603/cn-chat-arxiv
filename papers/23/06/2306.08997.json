{
    "title": "Exploring the MIT Mathematics and EECS Curriculum Using Large Language Models. (arXiv:2306.08997v2 [cs.CL] UPDATED)",
    "abstract": "We curate a comprehensive dataset of 4,550 questions and solutions from problem sets, midterm exams, and final exams across all MIT Mathematics and Electrical Engineering and Computer Science (EECS) courses required for obtaining a degree. We evaluate the ability of large language models to fulfill the graduation requirements for any MIT major in Mathematics and EECS. Our results demonstrate that GPT-3.5 successfully solves a third of the entire MIT curriculum, while GPT-4, with prompt engineering, achieves a perfect solve rate on a test set excluding questions based on images. We fine-tune an open-source large language model on this dataset. We employ GPT-4 to automatically grade model responses, providing a detailed performance breakdown by course, question, and answer type. By embedding questions in a low-dimensional space, we explore the relationships between questions, topics, and classes and discover which questions and classes are required for solving other questions and classes",
    "link": "http://arxiv.org/abs/2306.08997",
    "context": "Title: Exploring the MIT Mathematics and EECS Curriculum Using Large Language Models. (arXiv:2306.08997v2 [cs.CL] UPDATED)\nAbstract: We curate a comprehensive dataset of 4,550 questions and solutions from problem sets, midterm exams, and final exams across all MIT Mathematics and Electrical Engineering and Computer Science (EECS) courses required for obtaining a degree. We evaluate the ability of large language models to fulfill the graduation requirements for any MIT major in Mathematics and EECS. Our results demonstrate that GPT-3.5 successfully solves a third of the entire MIT curriculum, while GPT-4, with prompt engineering, achieves a perfect solve rate on a test set excluding questions based on images. We fine-tune an open-source large language model on this dataset. We employ GPT-4 to automatically grade model responses, providing a detailed performance breakdown by course, question, and answer type. By embedding questions in a low-dimensional space, we explore the relationships between questions, topics, and classes and discover which questions and classes are required for solving other questions and classes",
    "path": "papers/23/06/2306.08997.json",
    "total_tokens": 860,
    "translated_title": "使用大型语言模型探索MIT数学和EECS课程",
    "translated_abstract": "我们整理了一个综合性数据集，包括了获取学位所需的所有MIT数学和电气工程及计算机科学（EECS）课程的题目集、期中考试和期末考试中的4550个问题和解决方案。我们评估了大型语言模型实现任何MIT数学和EECS专业毕业要求的能力。我们的结果表明，GPT-3.5成功解决了整个MIT课程的三分之一，而GPT-4在题目中不包含图像的测试集上经过提示工程后达到了完美的解决率。我们在此数据集上对开源大型语言模型进行了微调。我们采用GPT-4自动评分，提供了课程、问题和答案类型的详细性能分析。通过将问题嵌入低维空间，我们探索了问题、主题和课程之间的关系，并发现哪些问题和课程是解决其他问题和课程所必需的。",
    "tldr": "通过使用大型语言模型，翻译了MIT数学和EECS课程中的4550个题目，开发出一个可以自动评分的模型，并探索了课程、问题和答案之间的关系。",
    "en_tdlr": "Using large language models, we translated 4,550 questions from MIT Mathematics and EECS courses, developed a model for automatic grading, and explored the relationships between courses, questions, and answers."
}