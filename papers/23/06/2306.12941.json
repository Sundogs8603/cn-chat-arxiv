{
    "title": "Robust Semantic Segmentation: Strong Adversarial Attacks and Fast Training of Robust Models. (arXiv:2306.12941v1 [cs.CV])",
    "abstract": "While a large amount of work has focused on designing adversarial attacks against image classifiers, only a few methods exist to attack semantic segmentation models. We show that attacking segmentation models presents task-specific challenges, for which we propose novel solutions. Our final evaluation protocol outperforms existing methods, and shows that those can overestimate the robustness of the models. Additionally, so far adversarial training, the most successful way for obtaining robust image classifiers, could not be successfully applied to semantic segmentation. We argue that this is because the task to be learned is more challenging, and requires significantly higher computational effort than for image classification. As a remedy, we show that by taking advantage of recent advances in robust ImageNet classifiers, one can train adversarially robust segmentation models at limited computational cost by fine-tuning robust backbones.",
    "link": "http://arxiv.org/abs/2306.12941",
    "context": "Title: Robust Semantic Segmentation: Strong Adversarial Attacks and Fast Training of Robust Models. (arXiv:2306.12941v1 [cs.CV])\nAbstract: While a large amount of work has focused on designing adversarial attacks against image classifiers, only a few methods exist to attack semantic segmentation models. We show that attacking segmentation models presents task-specific challenges, for which we propose novel solutions. Our final evaluation protocol outperforms existing methods, and shows that those can overestimate the robustness of the models. Additionally, so far adversarial training, the most successful way for obtaining robust image classifiers, could not be successfully applied to semantic segmentation. We argue that this is because the task to be learned is more challenging, and requires significantly higher computational effort than for image classification. As a remedy, we show that by taking advantage of recent advances in robust ImageNet classifiers, one can train adversarially robust segmentation models at limited computational cost by fine-tuning robust backbones.",
    "path": "papers/23/06/2306.12941.json",
    "total_tokens": 868,
    "translated_title": "鲁棒语义分割：强鲁棒性攻击和快速训练鲁棒性模型",
    "translated_abstract": "虽然大量的工作已经集中在设计针对图像分类器的对抗性攻击上，但只有少数方法存在用于攻击语义分割模型。我们展示了攻击分割模型的任务特定挑战，并提出了新的解决方案。我们的最终评估协议优于现有方法，并表明这些方法可能高估了模型的鲁棒性。此外，至今最成功的获得鲁棒图像分类器的对抗性训练无法成功应用于语义分割。我们认为这是因为要学习的任务更具挑战性，需要比图像分类更高的计算量。作为解决方法，我们展示了通过利用最近在鲁棒ImageNet分类器方面的进展，可以通过微调鲁棒的主干，以有限的计算代价训练对抗性鲁棒的分割模型。",
    "tldr": "本文提出了针对语义分割模型的解决方案，使得可以对其进行攻击并提供了更好的评估协议。同时，通过微调鲁棒的主干，可以有限的计算代价训练对抗性鲁棒的分割模型。",
    "en_tdlr": "This paper proposes solutions to attack semantic segmentation models and provides a better evaluation protocol. Additionally, by fine-tuning robust backbones, adversarially robust segmentation models can be trained at limited computational cost."
}