{
    "title": "RE-centric Recommendations for the Development of Trustworthy(er) Autonomous Systems. (arXiv:2306.01774v1 [cs.CY])",
    "abstract": "Complying with the EU AI Act (AIA) guidelines while developing and implementing AI systems will soon be mandatory within the EU. However, practitioners lack actionable instructions to operationalise ethics during AI systems development. A literature review of different ethical guidelines revealed inconsistencies in the principles addressed and the terminology used to describe them. Furthermore, requirements engineering (RE), which is identified to foster trustworthiness in the AI development process from the early stages was observed to be absent in a lot of frameworks that support the development of ethical and trustworthy AI. This incongruous phrasing combined with a lack of concrete development practices makes trustworthy AI development harder. To address this concern, we formulated a comparison table for the terminology used and the coverage of the ethical AI principles in major ethical AI guidelines. We then examined the applicability of ethical AI development frameworks for perfo",
    "link": "http://arxiv.org/abs/2306.01774",
    "context": "Title: RE-centric Recommendations for the Development of Trustworthy(er) Autonomous Systems. (arXiv:2306.01774v1 [cs.CY])\nAbstract: Complying with the EU AI Act (AIA) guidelines while developing and implementing AI systems will soon be mandatory within the EU. However, practitioners lack actionable instructions to operationalise ethics during AI systems development. A literature review of different ethical guidelines revealed inconsistencies in the principles addressed and the terminology used to describe them. Furthermore, requirements engineering (RE), which is identified to foster trustworthiness in the AI development process from the early stages was observed to be absent in a lot of frameworks that support the development of ethical and trustworthy AI. This incongruous phrasing combined with a lack of concrete development practices makes trustworthy AI development harder. To address this concern, we formulated a comparison table for the terminology used and the coverage of the ethical AI principles in major ethical AI guidelines. We then examined the applicability of ethical AI development frameworks for perfo",
    "path": "papers/23/06/2306.01774.json",
    "total_tokens": 909,
    "translated_title": "面向可信自动系统开发的RE中心化建议",
    "translated_abstract": "在欧盟内开发和实施人工智能系统时符合欧盟AI法案（AIA）指南将很快是强制性的。然而，从行动指南方面，实践者缺乏在AI系统开发期间实施伦理的可操作说明。对不同伦理指南的文献综述揭示了所涉及原则和术语描述的不一致性。此外，要在AI开发过程的早期阶段培养信任的要求工程（RE）被证明在许多支持道德和可信AI开发的框架中缺失。这种不协调的措辞加上缺乏具体的开发实践使可信AI开发更加困难。为解决此问题，我们制定了一个术语表，用于比较主要伦理AI指南中使用的术语和伦理AI原则的覆盖范围。然后，我们研究了伦理AI开发框架在执行RE方面的适用性。",
    "tldr": "本研究发现目前AI系统开发中缺少要求工程（RE）这一环节且伦理指南术语和原则覆盖的不一致性，为解决该问题我们制定了一个术语表并研究了伦理AI开发框架在执行RE方面的适用性。",
    "en_tdlr": "This study found that there is currently a lack of Requirements Engineering (RE) in AI system development, and inconsistencies in the terminology and principles covered in ethical guidelines. To address this issue, a comparison table was formulated and the applicability of ethical AI development frameworks for performing RE was studied."
}