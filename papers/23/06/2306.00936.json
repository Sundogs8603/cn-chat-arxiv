{
    "title": "AMR4NLI: Interpretable and robust NLI measures from semantic graphs. (arXiv:2306.00936v2 [cs.CL] UPDATED)",
    "abstract": "The task of natural language inference (NLI) asks whether a given premise (expressed in NL) entails a given NL hypothesis. NLI benchmarks contain human ratings of entailment, but the meaning relationships driving these ratings are not formalized. Can the underlying sentence pair relationships be made more explicit in an interpretable yet robust fashion? We compare semantic structures to represent premise and hypothesis, including sets of contextualized embeddings and semantic graphs (Abstract Meaning Representations), and measure whether the hypothesis is a semantic substructure of the premise, utilizing interpretable metrics. Our evaluation on three English benchmarks finds value in both contextualized embeddings and semantic graphs; moreover, they provide complementary signals, and can be leveraged together in a hybrid model.",
    "link": "http://arxiv.org/abs/2306.00936",
    "context": "Title: AMR4NLI: Interpretable and robust NLI measures from semantic graphs. (arXiv:2306.00936v2 [cs.CL] UPDATED)\nAbstract: The task of natural language inference (NLI) asks whether a given premise (expressed in NL) entails a given NL hypothesis. NLI benchmarks contain human ratings of entailment, but the meaning relationships driving these ratings are not formalized. Can the underlying sentence pair relationships be made more explicit in an interpretable yet robust fashion? We compare semantic structures to represent premise and hypothesis, including sets of contextualized embeddings and semantic graphs (Abstract Meaning Representations), and measure whether the hypothesis is a semantic substructure of the premise, utilizing interpretable metrics. Our evaluation on three English benchmarks finds value in both contextualized embeddings and semantic graphs; moreover, they provide complementary signals, and can be leveraged together in a hybrid model.",
    "path": "papers/23/06/2306.00936.json",
    "total_tokens": 787,
    "translated_title": "AMR4NLI: 从语义图中获得可解释和鲁棒的NLI度量",
    "translated_abstract": "自然语言推理（NLI）任务要求判断给定的前提（用自然语言表达）是否蕴含给定的假设。NLI基准包含了蕴含性的人工评分，但是驱动这些评分的意义关系并未形式化。是否可以以一种可解释且鲁棒的方式更明确地表示句子对之间的关系？我们比较了表示前提和假设的语义结构，包括一组上下文化嵌入和语义图（抽象意义表示），并使用可解释的度量方法来衡量假设是否是前提的语义子结构。在三个英语基准测试中的评估发现，上下文化嵌入和语义图都有其价值；而且它们提供了互补的信号，并可以在混合模型中一起利用。",
    "tldr": "该论文提出了一种从语义图中获取可解释和鲁棒的NLI度量方法，与使用上下文嵌入的方法相比具有补充性，可以在混合模型中结合使用。"
}