{
    "title": "FedVal: Different good or different bad in federated learning. (arXiv:2306.04040v1 [cs.LG])",
    "abstract": "Federated learning (FL) systems are susceptible to attacks from malicious actors who might attempt to corrupt the training model through various poisoning attacks. FL also poses new challenges in addressing group bias, such as ensuring fair performance for different demographic groups. Traditional methods used to address such biases require centralized access to the data, which FL systems do not have. In this paper, we present a novel approach FedVal for both robustness and fairness that does not require any additional information from clients that could raise privacy concerns and consequently compromise the integrity of the FL system. To this end, we propose an innovative score function based on a server-side validation method that assesses client updates and determines the optimal aggregation balance between locally-trained models. Our research shows that this approach not only provides solid protection against poisoning attacks but can also be used to reduce group bias and subsequen",
    "link": "http://arxiv.org/abs/2306.04040",
    "context": "Title: FedVal: Different good or different bad in federated learning. (arXiv:2306.04040v1 [cs.LG])\nAbstract: Federated learning (FL) systems are susceptible to attacks from malicious actors who might attempt to corrupt the training model through various poisoning attacks. FL also poses new challenges in addressing group bias, such as ensuring fair performance for different demographic groups. Traditional methods used to address such biases require centralized access to the data, which FL systems do not have. In this paper, we present a novel approach FedVal for both robustness and fairness that does not require any additional information from clients that could raise privacy concerns and consequently compromise the integrity of the FL system. To this end, we propose an innovative score function based on a server-side validation method that assesses client updates and determines the optimal aggregation balance between locally-trained models. Our research shows that this approach not only provides solid protection against poisoning attacks but can also be used to reduce group bias and subsequen",
    "path": "papers/23/06/2306.04040.json",
    "total_tokens": 882,
    "translated_title": "FedVal：联邦学习中的不同好坏",
    "translated_abstract": "联邦学习系统容易受到恶意攻击的影响，攻击者可能会通过各种毒化攻击来破坏训练模型。此外，FL在解决团体偏见方面也面临新的挑战，例如确保不同人口群体的公平性能。传统方法需要对数据进行集中处理，而FL系统并没有这个功能。本文提出了一个名为FedVal的全新方法，既具有稳健性又具有公平性，其不需要从客户端获取任何可能引发隐私问题并危及FL系统完整性的附加信息。为此，我们提出了一个基于服务器端验证方法的创新评分函数，该方法评估客户端更新并确定本地训练模型之间的最佳聚合平衡。我们的研究表明，这种方法不仅能够有效保护模型免受毒化攻击，而且还可用于减少群体偏见和随后的问题。",
    "tldr": "本文提出了FedVal方法，它是一个不需要从客户端获取任何附加信息的全新方法，可同时具有稳健和公平性，并通过评分函数在服务器端验证客户端更新，以确定本地训练模型之间的最佳聚合平衡。",
    "en_tdlr": "FedVal is a novel approach for robustness and fairness in federated learning that does not rely on any additional client information, offering solid protection against poisoning attacks and reducing group bias by using a score function based on server-side validation of client updates to determine the optimal aggregation balance between locally-trained models."
}