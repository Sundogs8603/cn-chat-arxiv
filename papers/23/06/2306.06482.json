{
    "title": "TensorNet: Cartesian Tensor Representations for Efficient Learning of Molecular Potentials. (arXiv:2306.06482v2 [cs.LG] UPDATED)",
    "abstract": "The development of efficient machine learning models for molecular systems representation is becoming crucial in scientific research. We introduce TensorNet, an innovative O(3)-equivariant message-passing neural network architecture that leverages Cartesian tensor representations. By using Cartesian tensor atomic embeddings, feature mixing is simplified through matrix product operations. Furthermore, the cost-effective decomposition of these tensors into rotation group irreducible representations allows for the separate processing of scalars, vectors, and tensors when necessary. Compared to higher-rank spherical tensor models, TensorNet demonstrates state-of-the-art performance with significantly fewer parameters. For small molecule potential energies, this can be achieved even with a single interaction layer. As a result of all these properties, the model's computational cost is substantially decreased. Moreover, the accurate prediction of vector and tensor molecular quantities on top",
    "link": "http://arxiv.org/abs/2306.06482",
    "context": "Title: TensorNet: Cartesian Tensor Representations for Efficient Learning of Molecular Potentials. (arXiv:2306.06482v2 [cs.LG] UPDATED)\nAbstract: The development of efficient machine learning models for molecular systems representation is becoming crucial in scientific research. We introduce TensorNet, an innovative O(3)-equivariant message-passing neural network architecture that leverages Cartesian tensor representations. By using Cartesian tensor atomic embeddings, feature mixing is simplified through matrix product operations. Furthermore, the cost-effective decomposition of these tensors into rotation group irreducible representations allows for the separate processing of scalars, vectors, and tensors when necessary. Compared to higher-rank spherical tensor models, TensorNet demonstrates state-of-the-art performance with significantly fewer parameters. For small molecule potential energies, this can be achieved even with a single interaction layer. As a result of all these properties, the model's computational cost is substantially decreased. Moreover, the accurate prediction of vector and tensor molecular quantities on top",
    "path": "papers/23/06/2306.06482.json",
    "total_tokens": 846,
    "tldr": "TensorNet是一种基于笛卡尔张量表示的创新神经网络架构，具有高效学习分子势能的能力，较高阶球形张量模型具有更好的性能，并且参数更少，降低了计算成本。",
    "en_tdlr": "TensorNet is an innovative neural network architecture based on Cartesian tensor representations, which efficiently learns the potential energy of molecules. It outperforms higher-rank spherical tensor models with fewer parameters, reducing computational cost."
}