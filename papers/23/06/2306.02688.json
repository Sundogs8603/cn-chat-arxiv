{
    "title": "Meta-SAGE: Scale Meta-Learning Scheduled Adaptation with Guided Exploration for Mitigating Scale Shift on Combinatorial Optimization. (arXiv:2306.02688v1 [cs.LG])",
    "abstract": "This paper proposes Meta-SAGE, a novel approach for improving the scalability of deep reinforcement learning models for combinatorial optimization (CO) tasks. Our method adapts pre-trained models to larger-scale problems in test time by suggesting two components: a scale meta-learner (SML) and scheduled adaptation with guided exploration (SAGE). First, SML transforms the context embedding for subsequent adaptation of SAGE based on scale information. Then, SAGE adjusts the model parameters dedicated to the context embedding for a specific instance. SAGE introduces locality bias, which encourages selecting nearby locations to determine the next location. The locality bias gradually decays as the model is adapted to the target instance. Results show that Meta-SAGE outperforms previous adaptation methods and significantly improves scalability in representative CO tasks. Our source code is available at https://github.com/kaist-silab/meta-sage",
    "link": "http://arxiv.org/abs/2306.02688",
    "context": "Title: Meta-SAGE: Scale Meta-Learning Scheduled Adaptation with Guided Exploration for Mitigating Scale Shift on Combinatorial Optimization. (arXiv:2306.02688v1 [cs.LG])\nAbstract: This paper proposes Meta-SAGE, a novel approach for improving the scalability of deep reinforcement learning models for combinatorial optimization (CO) tasks. Our method adapts pre-trained models to larger-scale problems in test time by suggesting two components: a scale meta-learner (SML) and scheduled adaptation with guided exploration (SAGE). First, SML transforms the context embedding for subsequent adaptation of SAGE based on scale information. Then, SAGE adjusts the model parameters dedicated to the context embedding for a specific instance. SAGE introduces locality bias, which encourages selecting nearby locations to determine the next location. The locality bias gradually decays as the model is adapted to the target instance. Results show that Meta-SAGE outperforms previous adaptation methods and significantly improves scalability in representative CO tasks. Our source code is available at https://github.com/kaist-silab/meta-sage",
    "path": "papers/23/06/2306.02688.json",
    "total_tokens": 811,
    "translated_title": "Meta-SAGE：用引导探索的规划方法和比例一元学习进行协同优化规模偏移问题",
    "translated_abstract": "本文提出了一种称之为Meta-SAGE的新方法，旨在改善组合优化（CO）任务的深度强化学习模型的可扩展性。本方法通过建议两个组件来在测试时间适应预训练模型以解决规模问题：一个是比例元学习器（SML），另一个是具有引导探索和时间表调整功能的scheduled adaptation with guided exploration（SAGE）。实验结果表明，Meta-SAGE优于以前的适应方法，并显著提高了代表性CO任务的可扩展性。",
    "tldr": "本研究提出了一种名为Meta-SAGE的新方法，用于解决组合优化任务中深度强化学习模型可扩展性的问题。该方法通过比例元学习和时间表调整来适应模型，并真实地优化了相关任务的性能表现。",
    "en_tdlr": "This paper proposes a novel method, called Meta-SAGE, to improve the scalability of deep reinforcement learning models for combinatorial optimization tasks, which adapts pre-trained models using scale meta-learning and scheduled adaptation with guided exploration to mitigate the scale shift problem. Results demonstrate the outperformance of Meta-SAGE over previous adaptation methods and its significant improvement in scalability in CO tasks."
}