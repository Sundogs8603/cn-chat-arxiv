{
    "title": "Cross-Lingual Transfer Learning for Low-Resource Speech Translation. (arXiv:2306.00789v3 [cs.CL] UPDATED)",
    "abstract": "The paper presents a novel three-step transfer learning framework for enhancing cross-lingual transfer from high- to low-resource languages in the downstream application of Automatic Speech Translation. The approach integrates a semantic knowledge-distillation step into the existing two-step cross-lingual transfer learning framework XLS-R. This extra step aims to encode semantic knowledge in the multilingual speech encoder pre-trained via Self-Supervised Learning using unlabeled speech. Our proposed three-step cross-lingual transfer learning framework addresses the large cross-lingual transfer gap (TRFGap) observed in the XLS-R framework between high-resource and low-resource languages. We validate our proposal through extensive experiments and comparisons on the CoVoST-2 benchmark, showing significant improvements in translation performance, especially for low-resource languages, and a notable reduction in the TRFGap.",
    "link": "http://arxiv.org/abs/2306.00789",
    "context": "Title: Cross-Lingual Transfer Learning for Low-Resource Speech Translation. (arXiv:2306.00789v3 [cs.CL] UPDATED)\nAbstract: The paper presents a novel three-step transfer learning framework for enhancing cross-lingual transfer from high- to low-resource languages in the downstream application of Automatic Speech Translation. The approach integrates a semantic knowledge-distillation step into the existing two-step cross-lingual transfer learning framework XLS-R. This extra step aims to encode semantic knowledge in the multilingual speech encoder pre-trained via Self-Supervised Learning using unlabeled speech. Our proposed three-step cross-lingual transfer learning framework addresses the large cross-lingual transfer gap (TRFGap) observed in the XLS-R framework between high-resource and low-resource languages. We validate our proposal through extensive experiments and comparisons on the CoVoST-2 benchmark, showing significant improvements in translation performance, especially for low-resource languages, and a notable reduction in the TRFGap.",
    "path": "papers/23/06/2306.00789.json",
    "total_tokens": 962,
    "translated_title": "低资源语音翻译的跨语言迁移学习",
    "translated_abstract": "本文提出了一种新颖的三步跨语言迁移学习框架，用于增强自动语音翻译中从高资源语言到低资源语言的跨语言迁移能力。该方法将语义知识蒸馏步骤集成到现有的两步跨语言迁移学习框架XLS-R中。这一额外的步骤旨在通过使用无标签语音进行自监督学习来对多语言语音编码器进行预训练以编码语义知识。我们提出的三步跨语言迁移学习框架解决了XLS-R框架中高资源语言和低资源语言之间存在的大的跨语言迁移差距。我们通过在CoVoST-2基准测试上进行广泛实验和比较来验证我们的提议，结果显示在翻译性能方面取得了显著改进，特别是对于低资源语言，并且跨语言迁移间隙(TRFGap)有明显减少。",
    "tldr": "提出了一种三步跨语言迁移学习框架，通过在现有框架中增加一步语义知识蒸馏，该方法有效地增强了自动语音翻译中从高资源语言到低资源语言的跨语言迁移能力，显著改善了翻译性能，特别是对于低资源语言，并减少了跨语言迁移间隙(TRFGap)。",
    "en_tdlr": "A novel three-step cross-lingual transfer learning framework is proposed to enhance cross-lingual transfer from high-resource to low-resource languages in automatic speech translation, by adding a semantic knowledge-distillation step. This approach significantly improves translation performance, particularly for low-resource languages, and reduces the cross-lingual transfer gap (TRFGap)."
}