{
    "title": "Neural Fields with Hard Constraints of Arbitrary Differential Order. (arXiv:2306.08943v2 [cs.LG] UPDATED)",
    "abstract": "While deep learning techniques have become extremely popular for solving a broad range of optimization problems, methods to enforce hard constraints during optimization, particularly on deep neural networks, remain underdeveloped. Inspired by the rich literature on meshless interpolation and its extension to spectral collocation methods in scientific computing, we develop a series of approaches for enforcing hard constraints on neural fields, which we refer to as Constrained Neural Fields (CNF). The constraints can be specified as a linear operator applied to the neural field and its derivatives. We also design specific model representations and training strategies for problems where standard models may encounter difficulties, such as conditioning of the system, memory consumption, and capacity of the network when being constrained. Our approaches are demonstrated in a wide range of real-world applications. Additionally, we develop a framework that enables highly efficient model and co",
    "link": "http://arxiv.org/abs/2306.08943",
    "context": "Title: Neural Fields with Hard Constraints of Arbitrary Differential Order. (arXiv:2306.08943v2 [cs.LG] UPDATED)\nAbstract: While deep learning techniques have become extremely popular for solving a broad range of optimization problems, methods to enforce hard constraints during optimization, particularly on deep neural networks, remain underdeveloped. Inspired by the rich literature on meshless interpolation and its extension to spectral collocation methods in scientific computing, we develop a series of approaches for enforcing hard constraints on neural fields, which we refer to as Constrained Neural Fields (CNF). The constraints can be specified as a linear operator applied to the neural field and its derivatives. We also design specific model representations and training strategies for problems where standard models may encounter difficulties, such as conditioning of the system, memory consumption, and capacity of the network when being constrained. Our approaches are demonstrated in a wide range of real-world applications. Additionally, we develop a framework that enables highly efficient model and co",
    "path": "papers/23/06/2306.08943.json",
    "total_tokens": 898,
    "translated_title": "具有任意微分阶硬约束的神经场",
    "translated_abstract": "尽管深度学习技术在解决各种优化问题方面变得非常流行，但在优化过程中强制施加硬约束的方法，特别是在深度神经网络上，仍然不太成熟。受到网格无约束插值和其在科学计算中的光谱色散方法的丰富文献启发，我们开发了一系列用于在神经场上强制施加硬约束的方法，我们将其称为约束神经场（CNF）。约束可以指定为应用于神经场及其导数的线性算子。我们还设计了特定的模型表示和训练策略，用于解决标准模型可能遇到的困难，如系统的条件、内存消耗和在受限制时网络的容量。我们的方法在各种实际应用中得到了验证。此外，我们还开发了一个能够实现高效模型和协作的框架。",
    "tldr": "本文提出了一种名为约束神经场的方法，用于在神经网络中实施任意微分阶的硬约束。通过应用线性算子到神经场及其导数，我们能够解决标准模型在受限制情况下遇到的问题，并在各种实际应用中验证了该方法的有效性。",
    "en_tdlr": "This paper proposes a method called Constrained Neural Fields (CNF) for enforcing hard constraints of arbitrary differential order on neural networks. By applying linear operators to the neural field and its derivatives, standard model difficulties when being constrained can be overcome. The effectiveness of the method is demonstrated in various real-world applications."
}