{
    "title": "Deep Learning Method for Object Tracking, Velocity Estimation and Projection of Sensor Data over Time. (arXiv:2306.06126v1 [cs.CV])",
    "abstract": "Current Deep Learning methods for environment segmentation and velocity estimation rely on Convolutional Recurrent Neural Networks to exploit spatio-temporal relationships within obtained sensor data. These approaches derive scene dynamics implicitly by correlating novel input and memorized data utilizing ConvNets. We show how ConvNets suffer from architectural restrictions for this task. Based on these findings, we then provide solutions to various issues on exploiting spatio-temporal correlations in a sequence of sensor recordings by presenting a novel Recurrent Neural Network unit utilizing Transformer mechanisms. Within this unit, object encodings are tracked across consecutive frames by correlating key-query pairs derived from sensor inputs and memory states, respectively. We then use resulting tracking patterns to obtain scene dynamics and regress velocities. In a last step, the memory state of the Recurrent Neural Network is projected based on extracted velocity estimates to res",
    "link": "http://arxiv.org/abs/2306.06126",
    "context": "Title: Deep Learning Method for Object Tracking, Velocity Estimation and Projection of Sensor Data over Time. (arXiv:2306.06126v1 [cs.CV])\nAbstract: Current Deep Learning methods for environment segmentation and velocity estimation rely on Convolutional Recurrent Neural Networks to exploit spatio-temporal relationships within obtained sensor data. These approaches derive scene dynamics implicitly by correlating novel input and memorized data utilizing ConvNets. We show how ConvNets suffer from architectural restrictions for this task. Based on these findings, we then provide solutions to various issues on exploiting spatio-temporal correlations in a sequence of sensor recordings by presenting a novel Recurrent Neural Network unit utilizing Transformer mechanisms. Within this unit, object encodings are tracked across consecutive frames by correlating key-query pairs derived from sensor inputs and memory states, respectively. We then use resulting tracking patterns to obtain scene dynamics and regress velocities. In a last step, the memory state of the Recurrent Neural Network is projected based on extracted velocity estimates to res",
    "path": "papers/23/06/2306.06126.json",
    "total_tokens": 857,
    "translated_title": "基于深度学习的目标跟踪、速度估计和传感器数据的时间投影方法",
    "translated_abstract": "目前环境分割和速度估计的深度学习方法依赖于卷积循环神经网络，以利用所获取的传感器数据中的时空关系。这些方法通过将新输入和记忆数据相关联来隐式地推导场景动态，利用卷积神经网络。本文发现卷积神经网络在这个任务上存在架构限制，因此提出了利用Transformer机制的新型循环神经网络单元来解决利用一系列传感器记录中的时空相关性所面临的各种问题。在该单元中，通过将基于传感器输入和记忆状态分别导出的关键-查询对相关联，跟踪对象编码在连续帧上的位置。然后利用得到的跟踪模式来获取场景动态和回归速度。最后，基于提取的速度估计将循环神经网络的记忆状态进行投影。",
    "tldr": "本文提出了一种利用Transformer机制的新型循环神经网络单元，实现了利用传感器记录中的时空相关性来实现目标跟踪和速度估计，并将记忆状态进行投影。",
    "en_tdlr": "This paper proposes a novel recurrent neural network unit utilizing Transformer mechanisms, which exploits spatio-temporal correlations in a sequence of sensor recordings for object tracking and velocity estimation, and projects the memory state based on extracted velocity estimates."
}