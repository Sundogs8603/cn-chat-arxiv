{
    "title": "Building blocks for complex tasks: Robust generative event extraction for radiology reports under domain shifts. (arXiv:2306.09544v1 [cs.CL])",
    "abstract": "This paper explores methods for extracting information from radiology reports that generalize across exam modalities to reduce requirements for annotated data. We demonstrate that multi-pass T5-based text-to-text generative models exhibit better generalization across exam modalities compared to approaches that employ BERT-based task-specific classification layers. We then develop methods that reduce the inference cost of the model, making large-scale corpus processing more feasible for clinical applications. Specifically, we introduce a generative technique that decomposes complex tasks into smaller subtask blocks, which improves a single-pass model when combined with multitask training. In addition, we leverage target-domain contexts during inference to enhance domain adaptation, enabling use of smaller models. Analyses offer insights into the benefits of different cost reduction strategies.",
    "link": "http://arxiv.org/abs/2306.09544",
    "context": "Title: Building blocks for complex tasks: Robust generative event extraction for radiology reports under domain shifts. (arXiv:2306.09544v1 [cs.CL])\nAbstract: This paper explores methods for extracting information from radiology reports that generalize across exam modalities to reduce requirements for annotated data. We demonstrate that multi-pass T5-based text-to-text generative models exhibit better generalization across exam modalities compared to approaches that employ BERT-based task-specific classification layers. We then develop methods that reduce the inference cost of the model, making large-scale corpus processing more feasible for clinical applications. Specifically, we introduce a generative technique that decomposes complex tasks into smaller subtask blocks, which improves a single-pass model when combined with multitask training. In addition, we leverage target-domain contexts during inference to enhance domain adaptation, enabling use of smaller models. Analyses offer insights into the benefits of different cost reduction strategies.",
    "path": "papers/23/06/2306.09544.json",
    "total_tokens": 904,
    "translated_title": "复杂任务的构建模块：领域转移下的放射学报告的生成性事件提取的鲁棒性研究。",
    "translated_abstract": "本文探讨了从放射学报告中提取信息的方法，通过这些方法可以在考试模式之间实现泛化，从而减少了注释数据的要求。我们证明了多次T5基于文本的生成模型比使用基于BERT的任务特定分类层的方法在考试方式之间表现更上佳。然后，我们开发了一种减少模型推理成本的方法，使得临床应用的大规模语料库处理变得更加可行。具体来说，我们引入一种生成技术，将复杂任务分解为更小的子任务块，当与多任务训练相结合时，可以提高单遍模型的性能。此外，在推理期间，我们利用目标域上下文来增强领域适应性，从而实现使用更小的模型。分析提供了有关不同成本降低策略的见解。",
    "tldr": "本文介绍了一个在放射学报告中提取信息的鲁棒性生成式模型，具有良好的泛化性。通过将复杂任务分解为更小的子任务块，与多任务训练相结合，可以提高单遍模型的性能，并通过利用目标域上下文来增强领域适应性，实现使用更小的模型。",
    "en_tdlr": "This paper presents a robust generative model for extracting information from radiology reports with good generalization. By decomposing complex tasks into smaller subtask blocks, combined with multitask training, the performance of a single-pass model is improved, and domain adaptation enhanced with the use of target-domain contexts, enabling the use of smaller models."
}