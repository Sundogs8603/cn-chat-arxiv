{
    "title": "Complex Preferences for Different Convergent Priors in Discrete Graph Diffusion. (arXiv:2306.02957v1 [cs.LG])",
    "abstract": "Diffusion models have achieved state-of-the-art performance in generating many different kinds of data, including images, text, and videos. Despite their success, there has been limited research on how the underlying diffusion process and the final convergent prior can affect generative performance; this research has also been limited to continuous data types and a score-based diffusion framework. To fill this gap, we explore how different discrete diffusion kernels (which converge to different prior distributions) affect the performance of diffusion models for graphs. To this end, we developed a novel formulation of a family of discrete diffusion kernels which are easily adjustable to converge to different Bernoulli priors, and we study the effect of these different kernels on generative performance. We show that the quality of generated graphs is sensitive to the prior used, and that the optimal choice cannot be explained by obvious statistics or metrics, which challenges the intuiti",
    "link": "http://arxiv.org/abs/2306.02957",
    "context": "Title: Complex Preferences for Different Convergent Priors in Discrete Graph Diffusion. (arXiv:2306.02957v1 [cs.LG])\nAbstract: Diffusion models have achieved state-of-the-art performance in generating many different kinds of data, including images, text, and videos. Despite their success, there has been limited research on how the underlying diffusion process and the final convergent prior can affect generative performance; this research has also been limited to continuous data types and a score-based diffusion framework. To fill this gap, we explore how different discrete diffusion kernels (which converge to different prior distributions) affect the performance of diffusion models for graphs. To this end, we developed a novel formulation of a family of discrete diffusion kernels which are easily adjustable to converge to different Bernoulli priors, and we study the effect of these different kernels on generative performance. We show that the quality of generated graphs is sensitive to the prior used, and that the optimal choice cannot be explained by obvious statistics or metrics, which challenges the intuiti",
    "path": "papers/23/06/2306.02957.json",
    "total_tokens": 940,
    "translated_title": "离散图扩散中不同收敛先验的复杂偏好",
    "translated_abstract": "扩散模型已经取得了在生成许多不同类型的数据，包括图像、文本和视频方面的最先进表现。尽管它们很成功，但对于基础扩散过程和最终收敛先验如何影响生成的性能进行的研究有限；此研究也仅限于连续数据类型和基于分数的扩散框架。我们探讨了不同离散扩散核（收敛到不同的先验分布）如何影响图的扩散模型的性能。为此，我们开发了一种新的离散扩散核系列公式，可以轻松调整以收敛到不同的伯努利先验，并研究这些不同的核对生成性能的影响。我们表明，生成的图的质量对使用的先验很敏感，最优选择不能用明显的统计数据或指标来解释，这挑战了扩散模型的直觉假设。我们的结果表明，在离散数据上，选择正确的收敛先验对于扩散模型的生成性能至关重要。",
    "tldr": "本研究探讨了离散扩散核如何影响图的扩散模型的性能，结果表明选择正确的收敛先验对于扩散模型的生成性能至关重要。",
    "en_tdlr": "This study explores how different discrete diffusion kernels affect the performance of diffusion models for graphs and suggests that choosing the right convergent prior is critical for the generative performance of diffusion models on discrete data."
}