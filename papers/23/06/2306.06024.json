{
    "title": "Self-Interpretable Time Series Prediction with Counterfactual Explanations. (arXiv:2306.06024v1 [cs.LG])",
    "abstract": "Interpretable time series prediction is crucial for safety-critical areas such as healthcare and autonomous driving. Most existing methods focus on interpreting predictions by assigning important scores to segments of time series. In this paper, we take a different and more challenging route and aim at developing a self-interpretable model, dubbed Counterfactual Time Series (CounTS), which generates counterfactual and actionable explanations for time series predictions. Specifically, we formalize the problem of time series counterfactual explanations, establish associated evaluation protocols, and propose a variational Bayesian deep learning model equipped with counterfactual inference capability of time series abduction, action, and prediction. Compared with state-of-the-art baselines, our self-interpretable model can generate better counterfactual explanations while maintaining comparable prediction accuracy.",
    "link": "http://arxiv.org/abs/2306.06024",
    "context": "Title: Self-Interpretable Time Series Prediction with Counterfactual Explanations. (arXiv:2306.06024v1 [cs.LG])\nAbstract: Interpretable time series prediction is crucial for safety-critical areas such as healthcare and autonomous driving. Most existing methods focus on interpreting predictions by assigning important scores to segments of time series. In this paper, we take a different and more challenging route and aim at developing a self-interpretable model, dubbed Counterfactual Time Series (CounTS), which generates counterfactual and actionable explanations for time series predictions. Specifically, we formalize the problem of time series counterfactual explanations, establish associated evaluation protocols, and propose a variational Bayesian deep learning model equipped with counterfactual inference capability of time series abduction, action, and prediction. Compared with state-of-the-art baselines, our self-interpretable model can generate better counterfactual explanations while maintaining comparable prediction accuracy.",
    "path": "papers/23/06/2306.06024.json",
    "total_tokens": 821,
    "translated_title": "可自我解释的时间序列预测与反事实解释",
    "translated_abstract": "可解释的时间序列预测对于像医疗和自动驾驶等安全关键领域至关重要。本文提出了一种不同于现有方法的思路，旨在开发出一种自我解释的模型，被称为Counterfactual Time Series（CounTS），该模型针对时间序列预测生成反事实和可操作的解释。具体而言，我们形式化了时间序列反事实解释的问题，建立了相应的评估协议，并提出了一种带有时间序列绑架、行动和预测反事实推理能力的变分贝叶斯深度学习模型。与最先进的基线相比，我们的自我解释模型可以生成更好的反事实解释，同时保持相当的预测准确性。",
    "tldr": "本文提出了一种自我解释的时间序列预测模型CounTS，该模型可以生成反事实和可操作的解释，适用于关键领域如医疗和自动驾驶等。与现有方法不同，该模型为可解释性建模做出了贡献。",
    "en_tdlr": "This paper presents a self-interpretable time series prediction model, CounTS, which generates counterfactual and actionable explanations for time series predictions, making a contribution to interpretability modeling. It is suitable for critical areas such as healthcare and autonomous driving."
}