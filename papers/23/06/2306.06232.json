{
    "title": "Probing self-supervised speech models for phonetic and phonemic information: a case study in aspiration. (arXiv:2306.06232v1 [cs.CL])",
    "abstract": "Textless self-supervised speech models have grown in capabilities in recent years, but the nature of the linguistic information they encode has not yet been thoroughly examined. We evaluate the extent to which these models' learned representations align with basic representational distinctions made by humans, focusing on a set of phonetic (low-level) and phonemic (more abstract) contrasts instantiated in word-initial stops. We find that robust representations of both phonetic and phonemic distinctions emerge in early layers of these models' architectures, and are preserved in the principal components of deeper layer representations. Our analyses suggest two sources for this success: some can only be explained by the optimization of the models on speech data, while some can be attributed to these models' high-dimensional architectures. Our findings show that speech-trained HuBERT derives a low-noise and low-dimensional subspace corresponding to abstract phonological distinctions.",
    "link": "http://arxiv.org/abs/2306.06232",
    "context": "Title: Probing self-supervised speech models for phonetic and phonemic information: a case study in aspiration. (arXiv:2306.06232v1 [cs.CL])\nAbstract: Textless self-supervised speech models have grown in capabilities in recent years, but the nature of the linguistic information they encode has not yet been thoroughly examined. We evaluate the extent to which these models' learned representations align with basic representational distinctions made by humans, focusing on a set of phonetic (low-level) and phonemic (more abstract) contrasts instantiated in word-initial stops. We find that robust representations of both phonetic and phonemic distinctions emerge in early layers of these models' architectures, and are preserved in the principal components of deeper layer representations. Our analyses suggest two sources for this success: some can only be explained by the optimization of the models on speech data, while some can be attributed to these models' high-dimensional architectures. Our findings show that speech-trained HuBERT derives a low-noise and low-dimensional subspace corresponding to abstract phonological distinctions.",
    "path": "papers/23/06/2306.06232.json",
    "total_tokens": 956,
    "translated_title": "探究自监督语音模型中的音素和音位信息：以送气现象为例",
    "translated_abstract": "近年来，无需文本的自监督语音模型的能力不断提高，但它们所编码的语言信息的本质还未得到彻底研究。本文评估了这些模型学习表示与人类基本表示区别之间的一致性，并集中研究了一组初始词停顿中具体表现的音素（低层）和音位（更抽象）对比。我们发现，在这些模型的体系结构的早期层中，出现了关于音素和音位区别的强大表示，并在更深层的主要成分表示中保留。我们的分析表明，这一成功的原因在于两方面：一些可归因于模型在语音数据上的优化，而另一些可归因于这些模型高维度的体系结构。我们的发现表明，经过语音训练的 HuBERT 得出了与抽象的音位区别相应的低噪声和低维度子空间。",
    "tldr": "本文研究了自监督语音模型中的音素和音位信息，并发现这些模型在早期层就能够很好地表示这些区别，并且这种表示在更深层的表示中得以保留，是由于模型在语音数据上的优化和高维度的体系结构的共同作用所致。",
    "en_tdlr": "The paper studies phonetic and phonemic information in self-supervised speech models and finds that robust representations of these distinctions emerge in early layers and are preserved in the principal components of deeper layers, due to both the optimization of the models on speech data and the high-dimensional architectures of the models. The findings demonstrate that speech-trained HuBERT derives a low-noise and low-dimensional subspace corresponding to abstract phonological distinctions."
}