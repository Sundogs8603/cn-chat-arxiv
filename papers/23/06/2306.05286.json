{
    "title": "JGAT: a joint spatio-temporal graph attention model for brain decoding. (arXiv:2306.05286v1 [q-bio.NC])",
    "abstract": "The decoding of brain neural networks has been an intriguing topic in neuroscience for a well-rounded understanding of different types of brain disorders and cognitive stimuli. Integrating different types of connectivity, e.g., Functional Connectivity (FC) and Structural Connectivity (SC), from multi-modal imaging techniques can take their complementary information into account and therefore have the potential to get better decoding capability. However, traditional approaches for integrating FC and SC overlook the dynamical variations, which stand a great chance to over-generalize the brain neural network. In this paper, we propose a Joint kernel Graph Attention Network (JGAT), which is a new multi-modal temporal graph attention network framework. It integrates the data from functional Magnetic Resonance Images (fMRI) and Diffusion Weighted Imaging (DWI) while preserving the dynamic information at the same time. We conduct brain-decoding tasks with our JGAT on four independent datasets",
    "link": "http://arxiv.org/abs/2306.05286",
    "context": "Title: JGAT: a joint spatio-temporal graph attention model for brain decoding. (arXiv:2306.05286v1 [q-bio.NC])\nAbstract: The decoding of brain neural networks has been an intriguing topic in neuroscience for a well-rounded understanding of different types of brain disorders and cognitive stimuli. Integrating different types of connectivity, e.g., Functional Connectivity (FC) and Structural Connectivity (SC), from multi-modal imaging techniques can take their complementary information into account and therefore have the potential to get better decoding capability. However, traditional approaches for integrating FC and SC overlook the dynamical variations, which stand a great chance to over-generalize the brain neural network. In this paper, we propose a Joint kernel Graph Attention Network (JGAT), which is a new multi-modal temporal graph attention network framework. It integrates the data from functional Magnetic Resonance Images (fMRI) and Diffusion Weighted Imaging (DWI) while preserving the dynamic information at the same time. We conduct brain-decoding tasks with our JGAT on four independent datasets",
    "path": "papers/23/06/2306.05286.json",
    "total_tokens": 891,
    "translated_title": "JGAT: 一种用于大脑解码的联合时空图形注意力模型",
    "translated_abstract": "大脑神经网络的解码一直是神经科学中令人着迷的课题，可以更全面地理解不同类型的脑部疾病和认知刺激。结合来自多模态成像技术的不同类型的连接（例如功能连接和结构连接）可以考虑它们的互补信息，因此具有更好的解码能力的潜力。然而，传统的整合功能连接和结构连接的方法忽略了动态变化，这很可能导致过度概括大脑神经网络。在本文中，我们提出了一种联合核图形注意力网络（JGAT），这是一种新的多模态时空图形注意力网络框架，同时保留动态信息，集成了功能磁共振成像（fMRI）和扩散加权成像（DWI）数据。我们使用JGAT在四个独立数据集上进行了脑解码任务。",
    "tldr": "本文提出了一种联合时空图形注意力网络框架JGAT，集成了来自功能磁共振成像（fMRI）和扩散加权成像(DWI)的多模态数据，并保留动态信息，可用于大脑解码任务。",
    "en_tdlr": "This paper proposes a joint spatio-temporal graph attention network framework, JGAT, which integrates multi-modal data from functional Magnetic Resonance Images (fMRI) and Diffusion Weighted Imaging (DWI), while preserving the dynamic information. It can be used for brain decoding tasks."
}