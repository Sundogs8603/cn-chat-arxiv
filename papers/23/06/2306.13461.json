{
    "title": "Understanding quantum machine learning also requires rethinking generalization. (arXiv:2306.13461v1 [quant-ph])",
    "abstract": "Quantum machine learning models have shown successful generalization performance even when trained with few data. In this work, through systematic randomization experiments, we show that traditional approaches to understanding generalization fail to explain the behavior of such quantum models. Our experiments reveal that state-of-the-art quantum neural networks accurately fit random states and random labeling of training data. This ability to memorize random data defies current notions of small generalization error, problematizing approaches that build on complexity measures such as the VC dimension, the Rademacher complexity, and all their uniform relatives. We complement our empirical results with a theoretical construction showing that quantum neural networks can fit arbitrary labels to quantum states, hinting at their memorization ability. Our results do not preclude the possibility of good generalization with few training data but rather rule out any possible guarantees based only",
    "link": "http://arxiv.org/abs/2306.13461",
    "context": "Title: Understanding quantum machine learning also requires rethinking generalization. (arXiv:2306.13461v1 [quant-ph])\nAbstract: Quantum machine learning models have shown successful generalization performance even when trained with few data. In this work, through systematic randomization experiments, we show that traditional approaches to understanding generalization fail to explain the behavior of such quantum models. Our experiments reveal that state-of-the-art quantum neural networks accurately fit random states and random labeling of training data. This ability to memorize random data defies current notions of small generalization error, problematizing approaches that build on complexity measures such as the VC dimension, the Rademacher complexity, and all their uniform relatives. We complement our empirical results with a theoretical construction showing that quantum neural networks can fit arbitrary labels to quantum states, hinting at their memorization ability. Our results do not preclude the possibility of good generalization with few training data but rather rule out any possible guarantees based only",
    "path": "papers/23/06/2306.13461.json",
    "total_tokens": 1051,
    "translated_title": "理解量子机器学习需要重新思考泛化问题",
    "translated_abstract": "量子机器学习模型在只用少量数据训练的情况下也能表现出成功的泛化性能。本文通过系统的随机化实验，展示传统的理解泛化的方法无法解释这些量子模型的行为。我们的实验揭示了最先进的量子神经网络能够准确地拟合随机状态和随机训练数据的标记。这种记忆随机数据的能力违反了当前小泛化误差的概念，使得建立在VC维、Rademacher复杂度和所有均匀相关性度量基础上的方法有些棘手。我们还通过理论构建补充了我们的实证结果，表明量子神经网络能够将任意标记拟合到量子状态上，暗示了它们的记忆能力。我们的结果并不排除只用少量训练数据就能获得良好泛化的可能性，但是排除了单单基于经典复杂度度量的所有可能保证。",
    "tldr": "本文通过实验认为，传统方法无法解释量子机器学习模型在只使用少量数据训练的情况下表现出成功的泛化性能，该模型可以准确拟合随机状态及随机标记的训练数据，这种记忆随机数据的能力违反了当前小泛化误差的概念，我们通过理论构建补充实证结果，表明量子神经网络可将任意标记拟合到量子状态上，暗示了它们的记忆能力，这些结果排除了单单基于经典复杂度度量的所有可能保证。"
}