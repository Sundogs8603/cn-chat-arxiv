{
    "title": "Class-Adaptive Self-Training for Relation Extraction with Incompletely Annotated Training Data. (arXiv:2306.09697v1 [cs.CL])",
    "abstract": "Relation extraction (RE) aims to extract relations from sentences and documents. Existing relation extraction models typically rely on supervised machine learning. However, recent studies showed that many RE datasets are incompletely annotated. This is known as the false negative problem in which valid relations are falsely annotated as 'no_relation'. Models trained with such data inevitably make similar mistakes during the inference stage. Self-training has been proven effective in alleviating the false negative problem. However, traditional self-training is vulnerable to confirmation bias and exhibits poor performance in minority classes. To overcome this limitation, we proposed a novel class-adaptive re-sampling self-training framework. Specifically, we re-sampled the pseudo-labels for each class by precision and recall scores. Our re-sampling strategy favored the pseudo-labels of classes with high precision and low recall, which improved the overall recall without significantly com",
    "link": "http://arxiv.org/abs/2306.09697",
    "context": "Title: Class-Adaptive Self-Training for Relation Extraction with Incompletely Annotated Training Data. (arXiv:2306.09697v1 [cs.CL])\nAbstract: Relation extraction (RE) aims to extract relations from sentences and documents. Existing relation extraction models typically rely on supervised machine learning. However, recent studies showed that many RE datasets are incompletely annotated. This is known as the false negative problem in which valid relations are falsely annotated as 'no_relation'. Models trained with such data inevitably make similar mistakes during the inference stage. Self-training has been proven effective in alleviating the false negative problem. However, traditional self-training is vulnerable to confirmation bias and exhibits poor performance in minority classes. To overcome this limitation, we proposed a novel class-adaptive re-sampling self-training framework. Specifically, we re-sampled the pseudo-labels for each class by precision and recall scores. Our re-sampling strategy favored the pseudo-labels of classes with high precision and low recall, which improved the overall recall without significantly com",
    "path": "papers/23/06/2306.09697.json",
    "total_tokens": 1008,
    "translated_title": "基于类适应的自训练模型用于不完全标注的关系提取",
    "translated_abstract": "关系提取旨在从句子和文档中提取关系。现有的关系提取模型通常依赖于监督机器学习。然而，最近的研究表明许多关系提取数据集是不完全注释的。这被称为错误否定问题，即将有效的关系错误地注释为“无关系”。使用这种数据训练的模型在推理阶段不可避免地会犯类似的错误。自训练已被证明在缓解错误否定问题方面非常有效。然而，传统的自训练容易受到确认偏差影响，并且在少数类中表现不佳。为了克服这个限制，我们提出了一种新的基于类别自适应重新采样自训练框架。具体来说，我们通过准确率和召回率分数重新对每个类别的伪标签进行了重新采样。我们的重新采样策略利于高准确率和低召回率的类别的伪标签，从而提高了总体召回率，而不会显着降低准确率。对广泛使用的数据集进行的实验结果表明，我们的方法在F1得分方面实现了最先进的性能，特别是在少数类中。",
    "tldr": "本研究提出了一种新的基于类别自适应重新采样自训练框架，能够显著改善在少数类别中的总体召回率，而不会明显降低准确率，从而实现了关系提取的最先进性能。",
    "en_tdlr": "This study proposes a novel class-adaptive re-sampling self-training framework to improve overall recall in minority classes without significantly compromising precision, achieving state-of-the-art performance in relation extraction."
}