{
    "title": "PWSHAP: A Path-Wise Explanation Model for Targeted Variables. (arXiv:2306.14672v1 [stat.ML])",
    "abstract": "Predictive black-box models can exhibit high accuracy but their opaque nature hinders their uptake in safety-critical deployment environments. Explanation methods (XAI) can provide confidence for decision-making through increased transparency. However, existing XAI methods are not tailored towards models in sensitive domains where one predictor is of special interest, such as a treatment effect in a clinical model, or ethnicity in policy models. We introduce Path-Wise Shapley effects (PWSHAP), a framework for assessing the targeted effect of a binary (e.g.~treatment) variable from a complex outcome model. Our approach augments the predictive model with a user-defined directed acyclic graph (DAG). The method then uses the graph alongside on-manifold Shapley values to identify effects along causal pathways whilst maintaining robustness to adversarial attacks. We establish error bounds for the identified path-wise Shapley effects and for Shapley values. We show PWSHAP can perform local bi",
    "link": "http://arxiv.org/abs/2306.14672",
    "context": "Title: PWSHAP: A Path-Wise Explanation Model for Targeted Variables. (arXiv:2306.14672v1 [stat.ML])\nAbstract: Predictive black-box models can exhibit high accuracy but their opaque nature hinders their uptake in safety-critical deployment environments. Explanation methods (XAI) can provide confidence for decision-making through increased transparency. However, existing XAI methods are not tailored towards models in sensitive domains where one predictor is of special interest, such as a treatment effect in a clinical model, or ethnicity in policy models. We introduce Path-Wise Shapley effects (PWSHAP), a framework for assessing the targeted effect of a binary (e.g.~treatment) variable from a complex outcome model. Our approach augments the predictive model with a user-defined directed acyclic graph (DAG). The method then uses the graph alongside on-manifold Shapley values to identify effects along causal pathways whilst maintaining robustness to adversarial attacks. We establish error bounds for the identified path-wise Shapley effects and for Shapley values. We show PWSHAP can perform local bi",
    "path": "papers/23/06/2306.14672.json",
    "total_tokens": 955,
    "translated_title": "PWSHAP：一种针对目标变量的路径解释模型",
    "translated_abstract": "预测性黑盒模型可能表现出很高的准确性，但它们的不透明性阻碍了它们在安全关键的计算环境中的应用。解释方法（XAI）可以通过增加透明度来提高决策的信心。然而，现有的XAI方法并不是针对敏感领域中对于特定预测变量的解释，例如临床模型中的治疗效果或政策模型中的种族。我们引入了Path-Wise Shapley Effects (PWSHAP)，这是一种框架，用于评估复杂结果模型的二进制（例如治疗）变量的目标效应。我们的方法利用用户定义的有向无环图（DAG）来扩充预测模型。该方法与on-manifold Shapley值一起使用图形来识别沿因果路径的效应，同时保持对对抗性攻击的稳健性。我们确定了识别的路径Shapley效应和Shapley值的误差界限。我们展示了PWSHAP可以执行局部双...",
    "tldr": "PWSHAP是一种用于敏感领域中评估特定二进制变量目标效应的框架，使用用户定义的DAG和on-manifold Shapley值识别因果路径中的效应，同时对对抗性攻击保持稳健性，具有良好的准确性和可解释性。",
    "en_tdlr": "PWSHAP is a framework for evaluating the targeted effect of a specific binary variable in sensitive domains. It uses a user-defined DAG and on-manifold Shapley values to identify effects along causal pathways while maintaining robustness to adversarial attacks. PWSHAP provides good accuracy and interpretability."
}