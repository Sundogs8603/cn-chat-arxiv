{
    "title": "M$^3$Fair: Mitigating Bias in Healthcare Data through Multi-Level and Multi-Sensitive-Attribute Reweighting Method. (arXiv:2306.04118v1 [cs.LG])",
    "abstract": "In the data-driven artificial intelligence paradigm, models heavily rely on large amounts of training data. However, factors like sampling distribution imbalance can lead to issues of bias and unfairness in healthcare data. Sensitive attributes, such as race, gender, age, and medical condition, are characteristics of individuals that are commonly associated with discrimination or bias. In healthcare AI, these attributes can play a significant role in determining the quality of care that individuals receive. For example, minority groups often receive fewer procedures and poorer-quality medical care than white individuals in US. Therefore, detecting and mitigating bias in data is crucial to enhancing health equity. Bias mitigation methods include pre-processing, in-processing, and post-processing. Among them, Reweighting (RW) is a widely used pre-processing method that performs well in balancing machine learning performance and fairness performance. RW adjusts the weights for samples wit",
    "link": "http://arxiv.org/abs/2306.04118",
    "context": "Title: M$^3$Fair: Mitigating Bias in Healthcare Data through Multi-Level and Multi-Sensitive-Attribute Reweighting Method. (arXiv:2306.04118v1 [cs.LG])\nAbstract: In the data-driven artificial intelligence paradigm, models heavily rely on large amounts of training data. However, factors like sampling distribution imbalance can lead to issues of bias and unfairness in healthcare data. Sensitive attributes, such as race, gender, age, and medical condition, are characteristics of individuals that are commonly associated with discrimination or bias. In healthcare AI, these attributes can play a significant role in determining the quality of care that individuals receive. For example, minority groups often receive fewer procedures and poorer-quality medical care than white individuals in US. Therefore, detecting and mitigating bias in data is crucial to enhancing health equity. Bias mitigation methods include pre-processing, in-processing, and post-processing. Among them, Reweighting (RW) is a widely used pre-processing method that performs well in balancing machine learning performance and fairness performance. RW adjusts the weights for samples wit",
    "path": "papers/23/06/2306.04118.json",
    "total_tokens": 1189,
    "translated_title": "M$^3$Fair：多层次多敏感属性加权方法减轻医疗数据中的偏见",
    "translated_abstract": "在数据驱动的人工智能范式中，模型严重依赖于大量的训练数据。然而，样本分布失衡等因素可能导致医疗数据中的偏见和不公平问题。在医疗人工智能中，如种族、性别、年龄和医疗状况等敏感属性通常与歧视或偏见有关。这些属性在医疗保健中可能对个人获得的护理质量产生重大影响。因此，检测和减轻数据中的偏差对于提高健康公平至关重要。偏差缓解方法包括前处理、中处理和后处理。其中，加权（RW）是一种广泛使用的前处理方法，能够在平衡机器学习性能和公平性能方面表现良好。RW调整特定敏感属性的样本权重以解决偏差问题。然而，现有的RW方法在平衡多个敏感属性和处理多层次数据方面效果有限。本文提出了 M$^3$Fair，一种新颖的多层次多敏感属性加权方法，可以平衡不同数据层次上多个敏感属性的分布。M$^3$Fair在维持机器学习性能的同时有效平衡了不同敏感属性的公平性能。在基准医疗数据集上的实验表明，M$^3$Fair在公平性和准确性方面优于现有方法。",
    "tldr": "本文提出了一种名为M$^3$Fair的新方法，可以在多个数据层面和多个敏感属性的情况下平衡训练数据分布，缓解医疗数据中的偏见和不公平现象，提高机器学习模型的公平性能和准确性能。",
    "en_tdlr": "This paper proposes a novel approach called M$^3$Fair, which can balance the distribution of training data across multiple levels and multiple sensitive attributes to mitigate bias and unfairness in healthcare data, thus improving the fairness and accuracy of machine learning models."
}