{
    "title": "Safety-Aware Task Composition for Discrete and Continuous Reinforcement Learning. (arXiv:2306.17033v1 [cs.LG])",
    "abstract": "Compositionality is a critical aspect of scalable system design. Reinforcement learning (RL) has recently shown substantial success in task learning, but has only recently begun to truly leverage composition. In this paper, we focus on Boolean composition of learned tasks as opposed to functional or sequential composition. Existing Boolean composition for RL focuses on reaching a satisfying absorbing state in environments with discrete action spaces, but does not support composable safety (i.e., avoidance) constraints. We advance the state of the art in Boolean composition of learned tasks with three contributions: i) introduce two distinct notions of safety in this framework; ii) show how to enforce either safety semantics, prove correctness (under some assumptions), and analyze the trade-offs between the two safety notions; and iii) extend Boolean composition from discrete action spaces to continuous action spaces. We demonstrate these techniques using modified versions of value iter",
    "link": "http://arxiv.org/abs/2306.17033",
    "context": "Title: Safety-Aware Task Composition for Discrete and Continuous Reinforcement Learning. (arXiv:2306.17033v1 [cs.LG])\nAbstract: Compositionality is a critical aspect of scalable system design. Reinforcement learning (RL) has recently shown substantial success in task learning, but has only recently begun to truly leverage composition. In this paper, we focus on Boolean composition of learned tasks as opposed to functional or sequential composition. Existing Boolean composition for RL focuses on reaching a satisfying absorbing state in environments with discrete action spaces, but does not support composable safety (i.e., avoidance) constraints. We advance the state of the art in Boolean composition of learned tasks with three contributions: i) introduce two distinct notions of safety in this framework; ii) show how to enforce either safety semantics, prove correctness (under some assumptions), and analyze the trade-offs between the two safety notions; and iii) extend Boolean composition from discrete action spaces to continuous action spaces. We demonstrate these techniques using modified versions of value iter",
    "path": "papers/23/06/2306.17033.json",
    "total_tokens": 857,
    "translated_title": "面向离散和连续强化学习的安全感知任务组合",
    "translated_abstract": "组合性是可扩展系统设计的关键方面。强化学习（RL）最近在任务学习方面取得了重大成功，但是在真正利用组合方面才刚刚开始。在本文中，我们关注学习任务的布尔组合，而不是功能性或顺序性组合。现有的RL布尔组合侧重于在具有离散行动空间的环境中达到一个令人满意的吸收状态，但不支持可组合的安全性（即避免）约束。我们通过三个贡献推进了学习任务布尔组合的最新技术：i）在此框架中引入了两种不同的安全性概念；ii）展示如何强制执行安全语义，证明正确性（在一些假设下），并分析两种安全性概念之间的权衡；iii）将布尔组合从离散行动空间扩展到连续行动空间。我们使用修改版的价值迭代算法来演示这些技术。",
    "tldr": "本文研究了布尔组合在强化学习中的应用，通过引入两种安全性概念和拓展到连续行动空间，实现了任务的安全感知组合。",
    "en_tdlr": "This paper investigates the application of Boolean composition in reinforcement learning, achieving safety-aware task composition by introducing two safety notions and extending to continuous action spaces."
}