{
    "title": "Matching Latent Encoding for Audio-Text based Keyword Spotting. (arXiv:2306.05245v1 [eess.AS])",
    "abstract": "Using audio and text embeddings jointly for Keyword Spotting (KWS) has shown high-quality results, but the key challenge of how to semantically align two embeddings for multi-word keywords of different sequence lengths remains largely unsolved. In this paper, we propose an audio-text-based end-to-end model architecture for flexible keyword spotting (KWS), which builds upon learned audio and text embeddings. Our architecture uses a novel dynamic programming-based algorithm, Dynamic Sequence Partitioning (DSP), to optimally partition the audio sequence into the same length as the word-based text sequence using the monotonic alignment of spoken content. Our proposed model consists of an encoder block to get audio and text embeddings, a projector block to project individual embeddings to a common latent space, and an audio-text aligner containing a novel DSP algorithm, which aligns the audio and text embeddings to determine if the spoken content is the same as the text. Experimental result",
    "link": "http://arxiv.org/abs/2306.05245",
    "context": "Title: Matching Latent Encoding for Audio-Text based Keyword Spotting. (arXiv:2306.05245v1 [eess.AS])\nAbstract: Using audio and text embeddings jointly for Keyword Spotting (KWS) has shown high-quality results, but the key challenge of how to semantically align two embeddings for multi-word keywords of different sequence lengths remains largely unsolved. In this paper, we propose an audio-text-based end-to-end model architecture for flexible keyword spotting (KWS), which builds upon learned audio and text embeddings. Our architecture uses a novel dynamic programming-based algorithm, Dynamic Sequence Partitioning (DSP), to optimally partition the audio sequence into the same length as the word-based text sequence using the monotonic alignment of spoken content. Our proposed model consists of an encoder block to get audio and text embeddings, a projector block to project individual embeddings to a common latent space, and an audio-text aligner containing a novel DSP algorithm, which aligns the audio and text embeddings to determine if the spoken content is the same as the text. Experimental result",
    "path": "papers/23/06/2306.05245.json",
    "total_tokens": 940,
    "translated_title": "基于音频文本匹配的关键词检测",
    "translated_abstract": "结合音频与文本嵌入进行关键词检测已经取得了高质量的结果，但如何对不同序列长度的多词关键词进行语义对齐仍然是一个挑战。本文提出了一种基于音频文本的端到端模型，使用学习到的音频和文本嵌入来进行灵活的关键词检测。我们的架构使用一种新型的动态规划算法Dynamic Sequence Partitioning（DSP），通过口语内容的单调对齐将音频序列最优地分割成与基于单词的文本序列相同的长度。我们的模型由一个编码器块来获取音频和文本嵌入，一个投影器块将各自的嵌入投影到一个共同的潜在空间，和一个音频文本匹配器，其中包含一种新颖的DSP算法，用于将音频和文本嵌入对齐，以确定口语内容是否与文本相同。",
    "tldr": "本文提出了一种基于音频文本的端到端模型来进行灵活的关键词检测，使用一种新型的动态规划算法来将音频序列最优地分割成与基于单词的文本序列相同的长度，以实现不同长度多词关键词的语义对齐。",
    "en_tdlr": "This paper proposes an end-to-end model for flexible keyword spotting using audio and text embeddings, and a novel dynamic programming algorithm called Dynamic Sequence Partitioning (DSP) to optimally partition the audio sequence into the same length as the text sequence based on monotonic alignment. The proposed model consists of an encoder block, a projector block, and an audio-text aligner containing the DSP algorithm to align audio and text embeddings for detecting multi-word keywords of different sequence lengths."
}