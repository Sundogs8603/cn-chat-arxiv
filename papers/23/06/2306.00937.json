{
    "title": "STEVE-1: A Generative Model for Text-to-Behavior in Minecraft. (arXiv:2306.00937v2 [cs.AI] UPDATED)",
    "abstract": "Constructing AI models that respond to text instructions is challenging, especially for sequential decision-making tasks. This work introduces an instruction-tuned Video Pretraining (VPT) model for Minecraft called STEVE-1, demonstrating that the unCLIP approach, utilized in DALL-E 2, is also effective for creating instruction-following sequential decision-making agents. STEVE-1 is trained in two steps: adapting the pretrained VPT model to follow commands in MineCLIP's latent space, then training a prior to predict latent codes from text. This allows us to finetune VPT through self-supervised behavioral cloning and hindsight relabeling, bypassing the need for costly human text annotations. By leveraging pretrained models like VPT and MineCLIP and employing best practices from text-conditioned image generation, STEVE-1 costs just $60 to train and can follow a wide range of short-horizon open-ended text and visual instructions in Minecraft. STEVE-1 sets a new bar for open-ended instructi",
    "link": "http://arxiv.org/abs/2306.00937",
    "context": "Title: STEVE-1: A Generative Model for Text-to-Behavior in Minecraft. (arXiv:2306.00937v2 [cs.AI] UPDATED)\nAbstract: Constructing AI models that respond to text instructions is challenging, especially for sequential decision-making tasks. This work introduces an instruction-tuned Video Pretraining (VPT) model for Minecraft called STEVE-1, demonstrating that the unCLIP approach, utilized in DALL-E 2, is also effective for creating instruction-following sequential decision-making agents. STEVE-1 is trained in two steps: adapting the pretrained VPT model to follow commands in MineCLIP's latent space, then training a prior to predict latent codes from text. This allows us to finetune VPT through self-supervised behavioral cloning and hindsight relabeling, bypassing the need for costly human text annotations. By leveraging pretrained models like VPT and MineCLIP and employing best practices from text-conditioned image generation, STEVE-1 costs just $60 to train and can follow a wide range of short-horizon open-ended text and visual instructions in Minecraft. STEVE-1 sets a new bar for open-ended instructi",
    "path": "papers/23/06/2306.00937.json",
    "total_tokens": 1032,
    "translated_title": "STEVE-1: 一个用于Minecraft中文本-行为生成的生成模型",
    "translated_abstract": "建立对文本指令做出响应的AI模型对于连续性决策任务来说是具有挑战性的。本文介绍了一种名为STEVE-1的Minecraft指令调整型视频预训练模型，展示了DALL-E 2中使用的unCLIP方法也对创建指令跟随连续决策代理非常有效。STEVE-1分为两个步骤进行训练：首先是将预先训练的VPT模型适应MineCLIP的潜在空间中的指令，然后训练一个先验模型以从文本预测潜在代码。这使我们能够通过自监督的行为克隆和回顾重新标记来微调VPT，避免需要昂贵的人工文本注释。通过利用VPT和MineCLIP等预先训练的模型，并采用文本条件的图像生成的最佳实践，STEVE-1的训练成本仅为60美元，并且可以在Minecraft中遵循各种短期开放型文本和视觉指令。STEVE-1为开放的指令跟随连续决策代理设定了一个新的标准。",
    "tldr": "STEVE-1 是一种新的生成模型，能够在Minecraft中跟随各种短期开放型文本和视觉指令。STEVE-1利用预先训练的模型和最佳实践，通过自监督的行为克隆和回顾重新标记来微调，避免了昂贵的人工注释。",
    "en_tdlr": "STEVE-1 is a novel generative model that can follow a wide range of short-horizon open-ended text and visual instructions in Minecraft. It leverages pretrained models and best practices from text-conditioned image generation, and is fine-tuned through self-supervised behavioral cloning and hindsight relabeling, bypassing the need for costly human text annotations."
}