{
    "title": "Multi-modal Pre-training for Medical Vision-language Understanding and Generation: An Empirical Study with A New Benchmark. (arXiv:2306.06494v2 [cs.CV] UPDATED)",
    "abstract": "With the availability of large-scale, comprehensive, and general-purpose vision-language (VL) datasets such as MSCOCO, vision-language pre-training (VLP) has become an active area of research and proven to be effective for various VL tasks such as visual-question answering. However, studies on VLP in the medical domain have so far been scanty. To provide a comprehensive perspective on VLP for medical VL tasks, we conduct a thorough experimental analysis to study key factors that may affect the performance of VLP with a unified vision-language Transformer. To allow making sound and quick pre-training decisions, we propose RadioGraphy Captions (RGC), a high-quality, multi-modality radiographic dataset containing 18,434 image-caption pairs collected from an open-access online database MedPix. RGC can be used as a pre-training dataset or a new benchmark for medical report generation and medical image-text retrieval. By utilizing RGC and other available datasets for pre-training, we develop",
    "link": "http://arxiv.org/abs/2306.06494",
    "context": "Title: Multi-modal Pre-training for Medical Vision-language Understanding and Generation: An Empirical Study with A New Benchmark. (arXiv:2306.06494v2 [cs.CV] UPDATED)\nAbstract: With the availability of large-scale, comprehensive, and general-purpose vision-language (VL) datasets such as MSCOCO, vision-language pre-training (VLP) has become an active area of research and proven to be effective for various VL tasks such as visual-question answering. However, studies on VLP in the medical domain have so far been scanty. To provide a comprehensive perspective on VLP for medical VL tasks, we conduct a thorough experimental analysis to study key factors that may affect the performance of VLP with a unified vision-language Transformer. To allow making sound and quick pre-training decisions, we propose RadioGraphy Captions (RGC), a high-quality, multi-modality radiographic dataset containing 18,434 image-caption pairs collected from an open-access online database MedPix. RGC can be used as a pre-training dataset or a new benchmark for medical report generation and medical image-text retrieval. By utilizing RGC and other available datasets for pre-training, we develop",
    "path": "papers/23/06/2306.06494.json",
    "total_tokens": 975,
    "translated_title": "医疗视觉语言理解与生成的多模态预训练：一项新基准的实证研究",
    "translated_abstract": "随着大规模、全面和通用的视觉语言（VL）数据集（如MSCOCO）的可用性，视觉语言预训练（VLP）已成为一个活跃的研究领域，并被证明在各种VL任务（如视觉问答）中非常有效。然而，目前在医疗领域对VLP的研究还很少。为了为医疗VL任务提供全面的视角，我们进行了一项全面的实证分析，研究可能影响统一视觉语言Transformer性能的关键因素。为了能够进行明智和快速的预训练决策，我们提出了RadioGraphy Captions（RGC），一个高质量的多模态放射图像数据集，其中包含18,434个来自开放获取在线数据库MedPix的图像-标题对。RGC可以用作预训练数据集，也可以作为医学报告生成和医学图像-文本检索的新基准。通过利用RGC和其他可用数据集进行预训练，我们开发了新的医疗VL模型。",
    "tldr": "本文通过研究关键因素，提供了医疗视觉语言预训练的全面实证分析，并提出了一个新的医学图像-文本数据集作为预训练数据或新的基准，为医学报告生成和图像-文本检索任务提供了强有力的支持。",
    "en_tdlr": "This paper provides a comprehensive empirical analysis of multi-modal pre-training for medical vision-language understanding and generation, and proposes a new benchmark dataset for medical image-text tasks, which offers strong support for medical report generation and image-text retrieval."
}