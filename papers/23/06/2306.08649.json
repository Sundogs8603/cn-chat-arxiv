{
    "title": "OCAtari: Object-Centric Atari 2600 Reinforcement Learning Environments",
    "abstract": "arXiv:2306.08649v2 Announce Type: replace-cross  Abstract: Cognitive science and psychology suggest that object-centric representations of complex scenes are a promising step towards enabling efficient abstract reasoning from low-level perceptual features. Yet, most deep reinforcement learning approaches only rely on pixel-based representations that do not capture the compositional properties of natural scenes. For this, we need environments and datasets that allow us to work and evaluate object-centric approaches. In our work, we extend the Atari Learning Environments, the most-used evaluation framework for deep RL approaches, by introducing OCAtari, that performs resource-efficient extractions of the object-centric states for these games. Our framework allows for object discovery, object representation learning, as well as object-centric RL. We evaluate OCAtari's detection capabilities and resource efficiency. Our source code is available at github.com/k4ntz/OC_Atari.",
    "link": "https://arxiv.org/abs/2306.08649",
    "context": "Title: OCAtari: Object-Centric Atari 2600 Reinforcement Learning Environments\nAbstract: arXiv:2306.08649v2 Announce Type: replace-cross  Abstract: Cognitive science and psychology suggest that object-centric representations of complex scenes are a promising step towards enabling efficient abstract reasoning from low-level perceptual features. Yet, most deep reinforcement learning approaches only rely on pixel-based representations that do not capture the compositional properties of natural scenes. For this, we need environments and datasets that allow us to work and evaluate object-centric approaches. In our work, we extend the Atari Learning Environments, the most-used evaluation framework for deep RL approaches, by introducing OCAtari, that performs resource-efficient extractions of the object-centric states for these games. Our framework allows for object discovery, object representation learning, as well as object-centric RL. We evaluate OCAtari's detection capabilities and resource efficiency. Our source code is available at github.com/k4ntz/OC_Atari.",
    "path": "papers/23/06/2306.08649.json",
    "total_tokens": 852,
    "translated_title": "OCAtari: 以对象为中心的Atari 2600强化学习环境",
    "translated_abstract": "认知科学和心理学表明，复杂场景的以对象为中心的表征是实现从低级感知特征有效抽象推理的一个有希望的步骤。然而，大多数深度强化学习方法只依赖于像素级表示，无法捕捉自然场景的组合特性。因此，我们需要允许我们处理和评估以对象为中心方法的环境和数据集。在我们的工作中，我们通过引入OCAtari来扩展Atari学习环境，这是深度RL方法最常用的评估框架，OCAtari对这些游戏进行了资源高效的对象中心状态提取。我们的框架允许对象发现、对象表征学习以及对象为中心的RL。我们评估了OCAtari的检测能力和资源效率。我们的源代码可在github.com/k4ntz/OC_Atari上找到。",
    "tldr": "以对象为中心的Atari 2600强化学习环境OCAtari扩展了Atari Learning Environments框架，实现了对游戏中基于对象的状态进行资源高效提取，并允许对象发现、对象表征学习以及对象为中心的强化学习。",
    "en_tdlr": "The OCAtari framework extends the Atari Learning Environments by enabling resource-efficient extraction of object-centric states in Atari 2600 games, allowing for object discovery, object representation learning, and object-centric reinforcement learning."
}