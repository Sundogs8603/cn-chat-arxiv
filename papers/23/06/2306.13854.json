{
    "title": "Similarity Preserving Adversarial Graph Contrastive Learning. (arXiv:2306.13854v1 [cs.LG])",
    "abstract": "Recent works demonstrate that GNN models are vulnerable to adversarial attacks, which refer to imperceptible perturbation on the graph structure and node features. Among various GNN models, graph contrastive learning (GCL) based methods specifically suffer from adversarial attacks due to their inherent design that highly depends on the self-supervision signals derived from the original graph, which however already contains noise when the graph is attacked. To achieve adversarial robustness against such attacks, existing methods adopt adversarial training (AT) to the GCL framework, which considers the attacked graph as an augmentation under the GCL framework. However, we find that existing adversarially trained GCL methods achieve robustness at the expense of not being able to preserve the node feature similarity. In this paper, we propose a similarity-preserving adversarial graph contrastive learning (SP-AGCL) framework that contrasts the clean graph with two auxiliary views of differe",
    "link": "http://arxiv.org/abs/2306.13854",
    "context": "Title: Similarity Preserving Adversarial Graph Contrastive Learning. (arXiv:2306.13854v1 [cs.LG])\nAbstract: Recent works demonstrate that GNN models are vulnerable to adversarial attacks, which refer to imperceptible perturbation on the graph structure and node features. Among various GNN models, graph contrastive learning (GCL) based methods specifically suffer from adversarial attacks due to their inherent design that highly depends on the self-supervision signals derived from the original graph, which however already contains noise when the graph is attacked. To achieve adversarial robustness against such attacks, existing methods adopt adversarial training (AT) to the GCL framework, which considers the attacked graph as an augmentation under the GCL framework. However, we find that existing adversarially trained GCL methods achieve robustness at the expense of not being able to preserve the node feature similarity. In this paper, we propose a similarity-preserving adversarial graph contrastive learning (SP-AGCL) framework that contrasts the clean graph with two auxiliary views of differe",
    "path": "papers/23/06/2306.13854.json",
    "total_tokens": 882,
    "translated_title": "相似性保持对抗图对比学习",
    "translated_abstract": "最近的研究表明，图神经网络模型易受到对抗攻击，即对图结构和节点特征进行微小扰动。在各种图神经网络模型中，基于图对比学习（GCL）的方法特别容易受到对抗攻击，因为它们的固有设计高度依赖于从原始图派生出的自监督信号，然而当图受到攻击时，原始图中已经包含了噪声。为了实现对这种攻击的对抗鲁棒性，现有方法将对抗训练（AT）应用于GCL框架，将攻击的图作为GCL框架下的增强。然而，我们发现现有的经过对抗训练的GCL方法在保持节点特征相似性方面付出了代价。在本文中，我们提出了一种相似性保持的对抗图对比学习（SP-AGCL）框架，将干净的图与两个不同视图的辅助图进行对比。",
    "tldr": "本文提出了一种相似性保持的对抗图对比学习（SP-AGCL）框架，可以实现对抗攻击的对抗鲁棒性，同时保持节点特征相似性。",
    "en_tdlr": "The paper proposes a similarity-preserving adversarial graph contrastive learning (SP-AGCL) framework that achieves adversarial robustness against attacks and preserves node feature similarity."
}