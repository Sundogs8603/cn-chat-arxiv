{
    "title": "Towards Understanding What Code Language Models Learned. (arXiv:2306.11943v1 [cs.SE])",
    "abstract": "Pre-trained language models are effective in a variety of natural language tasks, but it has been argued their capabilities fall short of fully learning meaning or understanding language. To understand the extent to which language models can learn some form of meaning, we investigate their ability to capture semantics of code beyond superficial frequency and co-occurrence. In contrast to previous research on probing models for linguistic features, we study pre-trained models in a setting that allows for objective and straightforward evaluation of a model's ability to learn semantics. In this paper, we examine whether such models capture the semantics of code, which is precisely and formally defined. Through experiments involving the manipulation of code fragments, we show that code pre-trained models of code learn a robust representation of the computational semantics of code that goes beyond superficial features of form alone",
    "link": "http://arxiv.org/abs/2306.11943",
    "context": "Title: Towards Understanding What Code Language Models Learned. (arXiv:2306.11943v1 [cs.SE])\nAbstract: Pre-trained language models are effective in a variety of natural language tasks, but it has been argued their capabilities fall short of fully learning meaning or understanding language. To understand the extent to which language models can learn some form of meaning, we investigate their ability to capture semantics of code beyond superficial frequency and co-occurrence. In contrast to previous research on probing models for linguistic features, we study pre-trained models in a setting that allows for objective and straightforward evaluation of a model's ability to learn semantics. In this paper, we examine whether such models capture the semantics of code, which is precisely and formally defined. Through experiments involving the manipulation of code fragments, we show that code pre-trained models of code learn a robust representation of the computational semantics of code that goes beyond superficial features of form alone",
    "path": "papers/23/06/2306.11943.json",
    "total_tokens": 803,
    "translated_title": "探究代码语言模型所学习的内容",
    "translated_abstract": "预先训练的语言模型在各种自然语言任务中都非常有效，但有人认为它们的能力不足以完全学习语言的意义或理解语言。为了了解语言模型能够学习某种形式的意义的程度，我们研究它们捕捉代码语义的能力，超越表层频率和共现的限制。与以往研究模型语言特征的探究相比，我们在一种可以客观地、简单明了地评估模型学习语义能力的环境下研究预训练模型。本文研究了这样的模型是否能捕捉精确而形式化定义的代码的语义。通过对代码片段的操纵实验，我们展示了代码预先训练模型学习了代码的计算语义的强有力的表征，超越了代码表面特征。",
    "tldr": "本研究探究了预先训练的代码语言模型的能力，证明其能够超越表面形式特征，学习精确而形式化定义的代码的计算语义。",
    "en_tdlr": "This study investigates the capability of pre-trained code language models and demonstrates that they are able to learn the computational semantics of formally defined code beyond superficial features."
}