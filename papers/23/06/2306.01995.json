{
    "title": "Asymptotically Optimal Pure Exploration for Infinite-Armed Bandits. (arXiv:2306.01995v1 [cs.LG])",
    "abstract": "We study pure exploration with infinitely many bandit arms generated i.i.d. from an unknown distribution. Our goal is to efficiently select a single high quality arm whose average reward is, with probability $1-\\delta$, within $\\varepsilon$ of being among the top $\\eta$-fraction of arms; this is a natural adaptation of the classical PAC guarantee for infinite action sets. We consider both the fixed confidence and fixed budget settings, aiming respectively for minimal expected and fixed sample complexity.  For fixed confidence, we give an algorithm with expected sample complexity $O\\left(\\frac{\\log (1/\\eta)\\log (1/\\delta)}{\\eta\\varepsilon^2}\\right)$. This is optimal except for the $\\log (1/\\eta)$ factor, and the $\\delta$-dependence closes a quadratic gap in the literature. For fixed budget, we show the asymptotically optimal sample complexity as $\\delta\\to 0$ is $c^{-1}\\log(1/\\delta)\\big(\\log\\log(1/\\delta)\\big)^2$ to leading order. Equivalently, the optimal failure probability given exa",
    "link": "http://arxiv.org/abs/2306.01995",
    "context": "Title: Asymptotically Optimal Pure Exploration for Infinite-Armed Bandits. (arXiv:2306.01995v1 [cs.LG])\nAbstract: We study pure exploration with infinitely many bandit arms generated i.i.d. from an unknown distribution. Our goal is to efficiently select a single high quality arm whose average reward is, with probability $1-\\delta$, within $\\varepsilon$ of being among the top $\\eta$-fraction of arms; this is a natural adaptation of the classical PAC guarantee for infinite action sets. We consider both the fixed confidence and fixed budget settings, aiming respectively for minimal expected and fixed sample complexity.  For fixed confidence, we give an algorithm with expected sample complexity $O\\left(\\frac{\\log (1/\\eta)\\log (1/\\delta)}{\\eta\\varepsilon^2}\\right)$. This is optimal except for the $\\log (1/\\eta)$ factor, and the $\\delta$-dependence closes a quadratic gap in the literature. For fixed budget, we show the asymptotically optimal sample complexity as $\\delta\\to 0$ is $c^{-1}\\log(1/\\delta)\\big(\\log\\log(1/\\delta)\\big)^2$ to leading order. Equivalently, the optimal failure probability given exa",
    "path": "papers/23/06/2306.01995.json",
    "total_tokens": 1044,
    "translated_title": "无限臂老虎机的渐进最优纯探索",
    "translated_abstract": "我们研究了从未知分布中生成的无限多老虎机臂的纯探索问题。我们的目标是有效地选择单个高质量臂，其平均奖励在概率为$1-\\delta$的情况下与前$\\eta$等分的臂中，相差不超过$\\varepsilon$；这是对无限行动集的经典实现可能性保证的自然调整。我们考虑固定置信度和固定预算两种情况，分别旨在实现最小期望和固定样本复杂度。对于固定置信度，我们提出了一种算法，其期望样本复杂度为$O\\left(\\frac{\\log (1/\\eta)\\log (1/\\delta)}{\\eta\\varepsilon^2}\\right)$。这是除了$\\log (1/\\eta)$因子以外的最优解，并且$\\delta$的依赖关系填补了文献中二次差距。对于固定预算，我们发现当$\\delta\\to 0$时，渐进最优样本复杂度是$c^{-1}\\log(1/\\delta)\\big(\\log\\log(1/\\delta)\\big)^2$。等价的，给定精确的样本复杂度时，最优失效概率是一个$\\log(1/\\delta)$阶的函数。",
    "tldr": "本文研究了从未知分布中生成的无限多臂老虎机的纯探索问题，旨在有效地选择单个高质量臂，并证明了在固定置信度和固定预算情况下算法的期望或渐进最优样本复杂度以及最优失效概率函数。"
}