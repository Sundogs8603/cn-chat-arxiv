{
    "title": "Has the Machine Learning Review Process Become More Arbitrary as the Field Has Grown? The NeurIPS 2021 Consistency Experiment. (arXiv:2306.03262v1 [cs.LG])",
    "abstract": "We present the NeurIPS 2021 consistency experiment, a larger-scale variant of the 2014 NeurIPS experiment in which 10% of conference submissions were reviewed by two independent committees to quantify the randomness in the review process. We observe that the two committees disagree on their accept/reject recommendations for 23% of the papers and that, consistent with the results from 2014, approximately half of the list of accepted papers would change if the review process were randomly rerun. Our analysis suggests that making the conference more selective would increase the arbitrariness of the process. Taken together with previous research, our results highlight the inherent difficulty of objectively measuring the quality of research, and suggest that authors should not be excessively discouraged by rejected work.",
    "link": "http://arxiv.org/abs/2306.03262",
    "context": "Title: Has the Machine Learning Review Process Become More Arbitrary as the Field Has Grown? The NeurIPS 2021 Consistency Experiment. (arXiv:2306.03262v1 [cs.LG])\nAbstract: We present the NeurIPS 2021 consistency experiment, a larger-scale variant of the 2014 NeurIPS experiment in which 10% of conference submissions were reviewed by two independent committees to quantify the randomness in the review process. We observe that the two committees disagree on their accept/reject recommendations for 23% of the papers and that, consistent with the results from 2014, approximately half of the list of accepted papers would change if the review process were randomly rerun. Our analysis suggests that making the conference more selective would increase the arbitrariness of the process. Taken together with previous research, our results highlight the inherent difficulty of objectively measuring the quality of research, and suggest that authors should not be excessively discouraged by rejected work.",
    "path": "papers/23/06/2306.03262.json",
    "total_tokens": 970,
    "translated_title": "机器学习审稿过程是否随着该领域的发展变得更加随意性？NeurIPS 2021一致性实验。",
    "translated_abstract": "我们提出了NeurIPS 2021一致性实验，这是2014年NeurIPS实验的更大规模变体，在该实验中，10%的会议投稿由两个独立委员会评审，以量化审稿过程中的随机性。我们发现，两个委员会在23%的论文的接受/拒绝推荐上存在分歧，并且与2014年的结果一致，如果重新随机运行审稿过程，接受论文清单中约有一半的论文将会改变。我们的分析表明，使会议更具选择性会增加这一过程的随意性。结合先前的研究，我们的结果凸显了客观衡量研究质量的困难，并表明作者不应因拒绝的作品而过分沮丧。",
    "tldr": "本研究展示了 NeurIPS 2021 一致性实验结果，该实验发现机器学习审稿过程中的随意性较高，两个委员会对于 23% 的论文存在不同的接受/拒绝推荐，如果重新随机运行审稿过程，接受论文清单中约有一半的论文将会改变。因此，本文强调客观衡量研究质量的困难，建议作者不应因拒绝的作品而过分沮丧。",
    "en_tdlr": "This study presents the results of the NeurIPS 2021 consistency experiment, which found a high level of arbitrariness in the machine learning review process. The two independent committees disagreed on the accept/reject recommendations for 23% of the papers, and approximately half of the accepted papers would change if the review process were randomly rerun. The study highlights the inherent difficulty of objectively measuring research quality and suggests that authors should not be excessively discouraged by rejected work."
}