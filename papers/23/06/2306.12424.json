{
    "title": "VisoGender: A dataset for benchmarking gender bias in image-text pronoun resolution. (arXiv:2306.12424v1 [cs.CV])",
    "abstract": "We introduce VisoGender, a novel dataset for benchmarking gender bias in vision-language models. We focus on occupation-related gender biases, inspired by Winograd and Winogender schemas, where each image is associated with a caption containing a pronoun relationship of subjects and objects in the scene. VisoGender is balanced by gender representation in professional roles, supporting bias evaluation in two ways: i) resolution bias, where we evaluate the difference between gender resolution accuracies for men and women and ii) retrieval bias, where we compare ratios of male and female professionals retrieved for a gender-neutral search query. We benchmark several state-of-the-art vision-language models and find that they lack the reasoning abilities to correctly resolve gender in complex scenes. While the direction and magnitude of gender bias depends on the task and the model being evaluated, captioning models generally are more accurate and less biased than CLIP-like models. Dataset ",
    "link": "http://arxiv.org/abs/2306.12424",
    "context": "Title: VisoGender: A dataset for benchmarking gender bias in image-text pronoun resolution. (arXiv:2306.12424v1 [cs.CV])\nAbstract: We introduce VisoGender, a novel dataset for benchmarking gender bias in vision-language models. We focus on occupation-related gender biases, inspired by Winograd and Winogender schemas, where each image is associated with a caption containing a pronoun relationship of subjects and objects in the scene. VisoGender is balanced by gender representation in professional roles, supporting bias evaluation in two ways: i) resolution bias, where we evaluate the difference between gender resolution accuracies for men and women and ii) retrieval bias, where we compare ratios of male and female professionals retrieved for a gender-neutral search query. We benchmark several state-of-the-art vision-language models and find that they lack the reasoning abilities to correctly resolve gender in complex scenes. While the direction and magnitude of gender bias depends on the task and the model being evaluated, captioning models generally are more accurate and less biased than CLIP-like models. Dataset ",
    "path": "papers/23/06/2306.12424.json",
    "total_tokens": 928,
    "translated_title": "VisoGender：一份用于评估图像-文本代词解析中性别偏见的数据集",
    "translated_abstract": "我们介绍了一个新的数据集VisoGender，用于评估视觉语言模型中的性别偏见。我们专注于职业相关的性别偏见，受Winograd和Winogender模式的启发，其中每个图像都与包含场景中主语和宾语代词关系的标题相关联。VisoGender在职业角色中平衡了性别代表，支持两种偏见评估方式：i）解决偏见，我们评估男性和女性解决准确性之间的差异；ii）检索偏见，我们比较在性别中立的搜索查询中检索到的男性和女性专业人员的比例。我们对几种最先进的视觉语言模型进行了基准测试，并发现它们缺乏正确解析复杂场景中性别的推理能力。虽然性别偏见的方向和幅度取决于任务和评估的模型，但生成字幕的模型通常比类似CLIP的模型更精确和更少偏见。",
    "tldr": "VisoGender是一个用于评估视觉语言模型中职业相关性别偏见的数据集。研究显示，最先进的模型缺乏正确解析复杂场景中性别的推理能力，生成字幕的模型通常比类似CLIP的模型更精确和更少偏见。",
    "en_tdlr": "VisoGender is a dataset for evaluating occupational gender bias in vision-language models. The research shows that state-of-the-art models lack the reasoning abilities to correctly resolve gender in complex scenes, and captioning models are generally more accurate and less biased than CLIP-like models."
}