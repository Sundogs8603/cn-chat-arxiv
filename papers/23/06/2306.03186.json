{
    "title": "Flipping Coins to Estimate Pseudocounts for Exploration in Reinforcement Learning. (arXiv:2306.03186v1 [cs.LG])",
    "abstract": "We propose a new method for count-based exploration in high-dimensional state spaces. Unlike previous work which relies on density models, we show that counts can be derived by averaging samples from the Rademacher distribution (or coin flips). This insight is used to set up a simple supervised learning objective which, when optimized, yields a state's visitation count. We show that our method is significantly more effective at deducing ground-truth visitation counts than previous work; when used as an exploration bonus for a model-free reinforcement learning algorithm, it outperforms existing approaches on most of 9 challenging exploration tasks, including the Atari game Montezuma's Revenge.",
    "link": "http://arxiv.org/abs/2306.03186",
    "context": "Title: Flipping Coins to Estimate Pseudocounts for Exploration in Reinforcement Learning. (arXiv:2306.03186v1 [cs.LG])\nAbstract: We propose a new method for count-based exploration in high-dimensional state spaces. Unlike previous work which relies on density models, we show that counts can be derived by averaging samples from the Rademacher distribution (or coin flips). This insight is used to set up a simple supervised learning objective which, when optimized, yields a state's visitation count. We show that our method is significantly more effective at deducing ground-truth visitation counts than previous work; when used as an exploration bonus for a model-free reinforcement learning algorithm, it outperforms existing approaches on most of 9 challenging exploration tasks, including the Atari game Montezuma's Revenge.",
    "path": "papers/23/06/2306.03186.json",
    "total_tokens": 768,
    "translated_title": "翻转硬币来估计强化学习中探索的伪计数",
    "translated_abstract": "我们提出了一种在高维状态空间中基于计数的探索新方法。与依赖密度模型的以往研究不同，我们展示了计数可以通过从Rademacher分布（或硬币翻转）中平均样本得到。利用这一见解，我们设置了一个简单的监督学习目标，当优化时，会产生一个状态的访问计数。我们展示了我们的方法比以前的工作更能有效地推导出真正的访问计数。当作为模型无关强化学习算法的探索奖励时，我们的方法在包括Atari游戏Montezuma's Revenge在内的9个具有挑战性的探索任务中优于现有方法。",
    "tldr": "研究提出了利用硬币翻转来推导状态的访问计数，并将其作为强化学习探索奖励，相比以往的方法在多个具有挑战性的任务上表现更好。"
}