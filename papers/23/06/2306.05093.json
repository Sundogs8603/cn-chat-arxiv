{
    "title": "Re-aligning Shadow Models can Improve White-box Membership Inference Attacks. (arXiv:2306.05093v1 [cs.CR])",
    "abstract": "Machine learning models have been shown to leak sensitive information about their training datasets. As models are being increasingly used, on devices, to automate tasks and power new applications, there have been concerns that such white-box access to its parameters, as opposed to the black-box setting which only provides query access to the model, increases the attack surface. Directly extending the shadow modelling technique from the black-box to the white-box setting has been shown, in general, not to perform better than black-box only attacks. A key reason is misalignment, a known characteristic of deep neural networks. We here present the first systematic analysis of the causes of misalignment in shadow models and show the use of a different weight initialisation to be the main cause of shadow model misalignment. Second, we extend several re-alignment techniques, previously developed in the model fusion literature, to the shadow modelling context, where the goal is to re-align th",
    "link": "http://arxiv.org/abs/2306.05093",
    "context": "Title: Re-aligning Shadow Models can Improve White-box Membership Inference Attacks. (arXiv:2306.05093v1 [cs.CR])\nAbstract: Machine learning models have been shown to leak sensitive information about their training datasets. As models are being increasingly used, on devices, to automate tasks and power new applications, there have been concerns that such white-box access to its parameters, as opposed to the black-box setting which only provides query access to the model, increases the attack surface. Directly extending the shadow modelling technique from the black-box to the white-box setting has been shown, in general, not to perform better than black-box only attacks. A key reason is misalignment, a known characteristic of deep neural networks. We here present the first systematic analysis of the causes of misalignment in shadow models and show the use of a different weight initialisation to be the main cause of shadow model misalignment. Second, we extend several re-alignment techniques, previously developed in the model fusion literature, to the shadow modelling context, where the goal is to re-align th",
    "path": "papers/23/06/2306.05093.json",
    "total_tokens": 873,
    "translated_title": "重新对齐影子模型能够提高白盒成员隐私攻击的效果。",
    "translated_abstract": "机器学习模型已被证明泄露了有关其训练数据集的敏感信息。随着模型的日益普及，被用于设备上，自动化任务和驱动新应用，人们开始关注白盒访问模型参数，而不是仅提供对模型的查询访问的黑盒设置，这增加了攻击面。将黑盒到白盒设置的影子建模技术直接扩展到白盒设置中，通常表现不如仅进行黑盒攻击。其中一个关键原因是深度神经网络的已知特征——不对齐。本文首次对影子模型不对齐的原因进行了系统分析，并表明采用不同的权重初始化是影子模型不对齐的主要原因。其次，我们将模型融合文献中先前开发的多种重新对齐技术扩展到影子建模上下文中，目标是重新对齐......",
    "tldr": "系统分析了影子模型不对齐问题的原因，并通过对抗性训练或实例加权方法重新对齐影子模型，从而提高了白盒成员隐私攻击的效果。",
    "en_tdlr": "This paper systematically analyzes the causes of misalignment in shadow models and proposes re-aligning shadow models using adversarial training or instance weighting methods, thereby improving the effectiveness of white-box membership inference attacks."
}