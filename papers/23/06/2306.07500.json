{
    "title": "Adding guardrails to advanced chatbots. (arXiv:2306.07500v1 [cs.CY])",
    "abstract": "Generative AI models continue to become more powerful. The launch of ChatGPT in November 2022 has ushered in a new era of AI. ChatGPT and other similar chatbots have a range of capabilities, from answering student homework questions to creating music and art. There are already concerns that humans may be replaced by chatbots for a variety of jobs. Because of the wide spectrum of data chatbots are built on, we know that they will have human errors and human biases built into them. These biases may cause significant harm and/or inequity toward different subpopulations. To understand the strengths and weakness of chatbot responses, we present a position paper that explores different use cases of ChatGPT to determine the types of questions that are answered fairly and the types that still need improvement. We find that ChatGPT is a fair search engine for the tasks we tested; however, it has biases on both text generation and code generation. We find that ChatGPT is very sensitive to change",
    "link": "http://arxiv.org/abs/2306.07500",
    "context": "Title: Adding guardrails to advanced chatbots. (arXiv:2306.07500v1 [cs.CY])\nAbstract: Generative AI models continue to become more powerful. The launch of ChatGPT in November 2022 has ushered in a new era of AI. ChatGPT and other similar chatbots have a range of capabilities, from answering student homework questions to creating music and art. There are already concerns that humans may be replaced by chatbots for a variety of jobs. Because of the wide spectrum of data chatbots are built on, we know that they will have human errors and human biases built into them. These biases may cause significant harm and/or inequity toward different subpopulations. To understand the strengths and weakness of chatbot responses, we present a position paper that explores different use cases of ChatGPT to determine the types of questions that are answered fairly and the types that still need improvement. We find that ChatGPT is a fair search engine for the tasks we tested; however, it has biases on both text generation and code generation. We find that ChatGPT is very sensitive to change",
    "path": "papers/23/06/2306.07500.json",
    "total_tokens": 899,
    "translated_title": "在先进聊天机器人中添加护栏",
    "translated_abstract": "生成式 AI 模型不断变得更加强大。2022 年 11 月 ChatGPT 的推出迎来了 AI 的新时代。ChatGPT 和其他类似的聊天机器人具有一系列的能力，从回答学生家庭作业问题到创造音乐和艺术。已经有人担心 chatbot 可能会取代人类进行各种工作。由于聊天机器人构建在广泛的数据体系上，我们知道它们会带有人类错误和偏见。这些偏见可能对不同人群造成重大伤害和/或不公平。为了了解聊天机器人响应的优势和局限性，我们提出了一篇位论文，探讨了 ChatGPT 的不同用例，以确定公平回答的问题类型和仍然需要改进的类型。我们发现 ChatGPT 对于我们测试的任务而言是一个公平的搜索引擎；然而，在文本生成和代码生成上它存在偏见。我们发现 ChatGPT 对于变化非常敏感。",
    "tldr": "研究探讨了 ChatGPT 不同用例对于公平回答问题的能力，并发现它对于测试任务而言是公平的搜索引擎，但在文本生成和代码生成上有偏见，并且对于变化非常敏感。",
    "en_tdlr": "The paper explores different use cases of ChatGPT to determine fair question answering capabilities and finds it to be a fair search engine for tested tasks, but with biases in text and code generation, and sensitivity to changes."
}