{
    "title": "Requirements for Explainability and Acceptance of Artificial Intelligence in Collaborative Work. (arXiv:2306.15394v1 [cs.CY])",
    "abstract": "The increasing prevalence of Artificial Intelligence (AI) in safety-critical contexts such as air-traffic control leads to systems that are practical and efficient, and to some extent explainable to humans to be trusted and accepted. The present structured literature analysis examines n = 236 articles on the requirements for the explainability and acceptance of AI. Results include a comprehensive review of n = 48 articles on information people need to perceive an AI as explainable, the information needed to accept an AI, and representation and interaction methods promoting trust in an AI. Results indicate that the two main groups of users are developers who require information about the internal operations of the model and end users who require information about AI results or behavior. Users' information needs vary in specificity, complexity, and urgency and must consider context, domain knowledge, and the user's cognitive resources. The acceptance of AI systems depends on information ",
    "link": "http://arxiv.org/abs/2306.15394",
    "context": "Title: Requirements for Explainability and Acceptance of Artificial Intelligence in Collaborative Work. (arXiv:2306.15394v1 [cs.CY])\nAbstract: The increasing prevalence of Artificial Intelligence (AI) in safety-critical contexts such as air-traffic control leads to systems that are practical and efficient, and to some extent explainable to humans to be trusted and accepted. The present structured literature analysis examines n = 236 articles on the requirements for the explainability and acceptance of AI. Results include a comprehensive review of n = 48 articles on information people need to perceive an AI as explainable, the information needed to accept an AI, and representation and interaction methods promoting trust in an AI. Results indicate that the two main groups of users are developers who require information about the internal operations of the model and end users who require information about AI results or behavior. Users' information needs vary in specificity, complexity, and urgency and must consider context, domain knowledge, and the user's cognitive resources. The acceptance of AI systems depends on information ",
    "path": "papers/23/06/2306.15394.json",
    "total_tokens": 916,
    "translated_title": "人工智能在协同工作中应具备可解释性和可接受性的要求",
    "translated_abstract": "人工智能（AI）在诸如空中交通管制等安全关键环境中的普及导致了需要被人类信任和接受的实用高效且在某种程度上可解释的系统。本研究对关于AI可解释性和接受性要求的236篇文章进行了结构化文献分析。结果包括关于人们需要知道的使AI可解释的信息、接受AI所需的信息以及促进对AI信任的表示和交互方法的48篇文章的综合回顾。结果表明，主要的用户群体是需要了解模型内部运作信息的开发者和需要了解AI结果或行为信息的最终用户。用户的信息需求在具体性、复杂性和紧迫性上存在差异，并且必须考虑到上下文、领域知识和用户的认知资源。AI系统的接受程度取决于信息的提供方式。",
    "tldr": "AI在协同工作中应具备可解释性和可接受性的要求越来越重要。开发者需要了解模型内部运作，最终用户需要了解AI的结果或行为。用户的信息需求因上下文、领域知识和认知资源而有所差异。接受AI系统取决于提供的信息方式。",
    "en_tdlr": "The requirements for explainability and acceptability of AI in collaborative work are becoming increasingly important. Developers need to understand the internal operations of the model, while end users require information about AI results or behavior. Users' information needs vary based on context, domain knowledge, and cognitive resources. The acceptance of AI systems depends on the manner of information provision."
}