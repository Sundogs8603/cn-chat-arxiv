{
    "title": "ZeroGen: Zero-shot Multimodal Controllable Text Generation with Multiple Oracles. (arXiv:2306.16649v1 [cs.CL])",
    "abstract": "Automatically generating textual content with desired attributes is an ambitious task that people have pursued long. Existing works have made a series of progress in incorporating unimodal controls into language models (LMs), whereas how to generate controllable sentences with multimodal signals and high efficiency remains an open question. To tackle the puzzle, we propose a new paradigm of zero-shot controllable text generation with multimodal signals (\\textsc{ZeroGen}). Specifically, \\textsc{ZeroGen} leverages controls of text and image successively from token-level to sentence-level and maps them into a unified probability space at decoding, which customizes the LM outputs by weighted addition without extra training. To achieve better inter-modal trade-offs, we further introduce an effective dynamic weighting mechanism to regulate all control weights. Moreover, we conduct substantial experiments to probe the relationship of being in-depth or in-width between signals from distinct mo",
    "link": "http://arxiv.org/abs/2306.16649",
    "context": "Title: ZeroGen: Zero-shot Multimodal Controllable Text Generation with Multiple Oracles. (arXiv:2306.16649v1 [cs.CL])\nAbstract: Automatically generating textual content with desired attributes is an ambitious task that people have pursued long. Existing works have made a series of progress in incorporating unimodal controls into language models (LMs), whereas how to generate controllable sentences with multimodal signals and high efficiency remains an open question. To tackle the puzzle, we propose a new paradigm of zero-shot controllable text generation with multimodal signals (\\textsc{ZeroGen}). Specifically, \\textsc{ZeroGen} leverages controls of text and image successively from token-level to sentence-level and maps them into a unified probability space at decoding, which customizes the LM outputs by weighted addition without extra training. To achieve better inter-modal trade-offs, we further introduce an effective dynamic weighting mechanism to regulate all control weights. Moreover, we conduct substantial experiments to probe the relationship of being in-depth or in-width between signals from distinct mo",
    "path": "papers/23/06/2306.16649.json",
    "total_tokens": 932,
    "translated_title": "ZeroGen: 零射击多模态可控文本生成与多个标准",
    "translated_abstract": "自动生成带有所需属性的文本内容是一个雄心勃勃的任务，人们一直在追求这一目标。现有的工作在将单模态控制引入语言模型(LMs)方面取得了一系列进展，然而如何使用多模态信号和高效地生成可控句子仍然是一个开放的问题。为了解决这个难题，我们提出了一种新的零射击多模态可控文本生成范式(ZeroGen)。具体而言，ZeroGen从令牌级别到句子级别连续利用文本和图像的控制，并在解码时将它们映射到统一的概率空间中，通过加权添加自定义LM输出，无需额外训练。为了实现更好的跨模态权衡，我们进一步引入了一种有效的动态加权机制来调节所有控制权重。此外，我们进行了大量实验证明来自不同模式信号之间的深度与宽度之间的关系。",
    "tldr": "ZeroGen是一种零射击的多模态可控文本生成方法，通过在解码过程中利用文本和图像信号的控制，将它们映射到统一的概率空间并通过加权添加自定义LM输出实现高效率的文本生成。实验证明了来自不同模式信号之间的深度与宽度之间的关系。",
    "en_tdlr": "ZeroGen is a zero-shot multimodal controllable text generation method that leverages the controls of text and image signals to map them into a unified probability space at decoding and achieve efficient text generation through weighted addition for customized language model outputs. Experiments show the relationship between the depth and width of signals from different modes."
}