{
    "title": "Evolution of Efficient Symbolic Communication Codes. (arXiv:2306.02383v2 [cs.CL] UPDATED)",
    "abstract": "The paper explores how the human natural language structure can be seen as a product of evolution of inter-personal communication code, targeting maximisation of such culture-agnostic and cross-lingual metrics such as anti-entropy, compression factor and cross-split F1 score. The exploration is done as part of a larger unsupervised language learning effort, the attempt is made to perform meta-learning in a space of hyper-parameters maximising F1 score based on the \"ground truth\" language structure, by means of maximising the metrics mentioned above. The paper presents preliminary results of cross-lingual word-level segmentation tokenisation study for Russian, Chinese and English as well as subword segmentation or morphological parsing study for English. It is found that language structure form the word-level segmentation or tokenisation can be found as driven by all of these metrics, anti-entropy being more relevant to English and Russian while compression factor more specific for Chin",
    "link": "http://arxiv.org/abs/2306.02383",
    "context": "Title: Evolution of Efficient Symbolic Communication Codes. (arXiv:2306.02383v2 [cs.CL] UPDATED)\nAbstract: The paper explores how the human natural language structure can be seen as a product of evolution of inter-personal communication code, targeting maximisation of such culture-agnostic and cross-lingual metrics such as anti-entropy, compression factor and cross-split F1 score. The exploration is done as part of a larger unsupervised language learning effort, the attempt is made to perform meta-learning in a space of hyper-parameters maximising F1 score based on the \"ground truth\" language structure, by means of maximising the metrics mentioned above. The paper presents preliminary results of cross-lingual word-level segmentation tokenisation study for Russian, Chinese and English as well as subword segmentation or morphological parsing study for English. It is found that language structure form the word-level segmentation or tokenisation can be found as driven by all of these metrics, anti-entropy being more relevant to English and Russian while compression factor more specific for Chin",
    "path": "papers/23/06/2306.02383.json",
    "total_tokens": 828,
    "translated_title": "高效象征交流编码的演变",
    "translated_abstract": "本文探讨人类自然语言结构如何被看作是人际交流代码的演变产物，旨在最大化文化无关和跨语言度量标准，如反熵、压缩因子和跨分裂F1分数。探索是作为更大的无监督语言学习努力的一部分完成的，试图在基于“基本语言结构”的超参数空间中执行元学习，通过最大化上述指标来实现。本文提出了针对俄语、中文和英语的跨语言词级分词标记化研究以及针对英语的子词分割或形态分析研究的初步结果。发现语言结构形成词级分割或标记化可以通过所有这些度量来驱动，反熵对英语和俄语更相关，而压缩因子对中文更具特定性。",
    "tldr": "本文探讨了通过反熵、压缩因子和跨分裂F1分数为目标的交流代码演变产物，发现语言结构形成可以通过这些度量来驱动。",
    "en_tdlr": "This paper explores the evolution of communication codes through maximizing metrics such as anti-entropy, compression factor, and cross-split F1 score, showing that language structure is driven by these metrics."
}