{
    "title": "FAIRER: Fairness as Decision Rationale Alignment. (arXiv:2306.15299v1 [cs.LG])",
    "abstract": "Deep neural networks (DNNs) have made significant progress, but often suffer from fairness issues, as deep models typically show distinct accuracy differences among certain subgroups (e.g., males and females). Existing research addresses this critical issue by employing fairness-aware loss functions to constrain the last-layer outputs and directly regularize DNNs. Although the fairness of DNNs is improved, it is unclear how the trained network makes a fair prediction, which limits future fairness improvements. In this paper, we investigate fairness from the perspective of decision rationale and define the parameter parity score to characterize the fair decision process of networks by analyzing neuron influence in various subgroups. Extensive empirical studies show that the unfair issue could arise from the unaligned decision rationales of subgroups. Existing fairness regularization terms fail to achieve decision rationale alignment because they only constrain last-layer outputs while i",
    "link": "http://arxiv.org/abs/2306.15299",
    "context": "Title: FAIRER: Fairness as Decision Rationale Alignment. (arXiv:2306.15299v1 [cs.LG])\nAbstract: Deep neural networks (DNNs) have made significant progress, but often suffer from fairness issues, as deep models typically show distinct accuracy differences among certain subgroups (e.g., males and females). Existing research addresses this critical issue by employing fairness-aware loss functions to constrain the last-layer outputs and directly regularize DNNs. Although the fairness of DNNs is improved, it is unclear how the trained network makes a fair prediction, which limits future fairness improvements. In this paper, we investigate fairness from the perspective of decision rationale and define the parameter parity score to characterize the fair decision process of networks by analyzing neuron influence in various subgroups. Extensive empirical studies show that the unfair issue could arise from the unaligned decision rationales of subgroups. Existing fairness regularization terms fail to achieve decision rationale alignment because they only constrain last-layer outputs while i",
    "path": "papers/23/06/2306.15299.json",
    "total_tokens": 926,
    "translated_title": "FAIRER: 公平作为决策合理性对齐原则",
    "translated_abstract": "深度神经网络(DNNs)取得了显著的进展，但往往存在公平性问题，因为深度模型通常在某些子群体（例如男性和女性）之间显示出明显的准确性差异。现有研究通过使用公平感知损失函数来约束最后一层的输出并直接规范化DNNs来解决这个关键问题。虽然DNN的公平性得到了改善，但不清楚经过训练的网络如何进行公平预测，这限制了未来的公平性改进。在本文中，我们从决策合理性的角度研究了公平性，并通过分析各个子群体中的神经元影响来定义参数平等得分来表征网络的公平决策过程。广泛的实证研究表明，不公平问题可能源于子群体的不对齐决策合理性。现有的公平性规范项无法实现决策合理性的对齐，因为它们只约束最后一层的输出，而忽视了之前的层次。",
    "tldr": "本文针对深度神经网络中的公平性问题，从决策合理性的角度研究，并定义了参数平等得分来表征公平决策过程。实证研究表明现有的公平性规范项无法实现决策合理性的对齐。",
    "en_tdlr": "This paper investigates fairness in deep neural networks from the perspective of decision rationale and proposes a parameter parity score to characterize the fair decision process. The empirical studies show that existing fairness regularization terms fail to achieve decision rationale alignment."
}