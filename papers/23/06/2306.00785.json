{
    "title": "Data Interpolants -- That's What Discriminators in Higher-order Gradient-regularized GANs Are. (arXiv:2306.00785v1 [stat.ML])",
    "abstract": "We consider the problem of optimizing the discriminator in generative adversarial networks (GANs) subject to higher-order gradient regularization. We show analytically, via the least-squares (LSGAN) and Wasserstein (WGAN) GAN variants, that the discriminator optimization problem is one of interpolation in $n$-dimensions. The optimal discriminator, derived using variational Calculus, turns out to be the solution to a partial differential equation involving the iterated Laplacian or the polyharmonic operator. The solution is implementable in closed-form via polyharmonic radial basis function (RBF) interpolation. In view of the polyharmonic connection, we refer to the corresponding GANs as Poly-LSGAN and Poly-WGAN. Through experimental validation on multivariate Gaussians, we show that implementing the optimal RBF discriminator in closed-form, with penalty orders $m \\approx\\lceil \\frac{n}{2} \\rceil $, results in superior performance, compared to training GAN with arbitrarily chosen discri",
    "link": "http://arxiv.org/abs/2306.00785",
    "context": "Title: Data Interpolants -- That's What Discriminators in Higher-order Gradient-regularized GANs Are. (arXiv:2306.00785v1 [stat.ML])\nAbstract: We consider the problem of optimizing the discriminator in generative adversarial networks (GANs) subject to higher-order gradient regularization. We show analytically, via the least-squares (LSGAN) and Wasserstein (WGAN) GAN variants, that the discriminator optimization problem is one of interpolation in $n$-dimensions. The optimal discriminator, derived using variational Calculus, turns out to be the solution to a partial differential equation involving the iterated Laplacian or the polyharmonic operator. The solution is implementable in closed-form via polyharmonic radial basis function (RBF) interpolation. In view of the polyharmonic connection, we refer to the corresponding GANs as Poly-LSGAN and Poly-WGAN. Through experimental validation on multivariate Gaussians, we show that implementing the optimal RBF discriminator in closed-form, with penalty orders $m \\approx\\lceil \\frac{n}{2} \\rceil $, results in superior performance, compared to training GAN with arbitrarily chosen discri",
    "path": "papers/23/06/2306.00785.json",
    "total_tokens": 939,
    "translated_title": "数据内插器——高阶梯度正则化生成对抗网络中的辨别器",
    "translated_abstract": "本文考虑了在生成对抗网络（GAN）中对辨别器进行高阶梯度正则化优化的问题。通过最小二乘（LSGAN）和Wasserstein（WGAN） GAN变体的分析，我们证明了辨别器优化问题是n维内插问题。通过变分微积分导出的最优辨别器，实际上成为涉及迭代的Laplacian或polyharmonic算子的偏微分方程的解。通过polyharmonic算子的联系，我们称对应的GAN为Poly-LSGAN和Poly-WGAN，并通过在多元高斯上的实验验证表明，使用闭式RBF内插实现最优辨别器，惩罚阶数$m \\approx\\lceil \\frac{n}{2} \\rceil$，可以获得更优异的性能，相比于用任意选择的辨别器进行训练的GAN。",
    "tldr": "本文讨论了在高阶梯度正则化生成对抗网络中优化辨别器的问题，发现最优辨别器问题是$n$维内插问题，并使用多项RBF内插闭式求解，实现更优的性能。",
    "en_tdlr": "This paper discusses the optimization of the discriminator in higher-order gradient-regularized generative adversarial networks (GANs) and finds that the optimal discriminator is an n-dimensional interpolant, which can be solved using closed-form polyharmonic radial basis function (RBF) interpolation with penalty orders $m \\approx\\lceil \\frac{n}{2} \\rceil$. The proposed Poly-LSGAN and Poly-WGAN achieve superior performance compared to GANs with arbitrarily chosen discriminators, as demonstrated experimentally with multivariate Gaussians."
}