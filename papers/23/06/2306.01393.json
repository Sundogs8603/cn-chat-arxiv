{
    "title": "Assessing the Importance of Frequency versus Compositionality for Subword-based Tokenization in NMT. (arXiv:2306.01393v1 [cs.CL])",
    "abstract": "Subword tokenization is the de facto standard for tokenization in neural language models and machine translation systems. Three advantages are frequently cited in favor of subwords: shorter encoding of frequent tokens, compositionality of subwords, and ability to deal with unknown words. As their relative importance is not entirely clear yet, we propose a tokenization approach that enables us to separate frequency (the first advantage) from compositionality. The approach uses Huffman coding to tokenize words, by order of frequency, using a fixed amount of symbols. Experiments with CS-DE, EN-FR and EN-DE NMT show that frequency alone accounts for 90%-95% of the scores reached by BPE, hence compositionality has less importance than previously thought.",
    "link": "http://arxiv.org/abs/2306.01393",
    "context": "Title: Assessing the Importance of Frequency versus Compositionality for Subword-based Tokenization in NMT. (arXiv:2306.01393v1 [cs.CL])\nAbstract: Subword tokenization is the de facto standard for tokenization in neural language models and machine translation systems. Three advantages are frequently cited in favor of subwords: shorter encoding of frequent tokens, compositionality of subwords, and ability to deal with unknown words. As their relative importance is not entirely clear yet, we propose a tokenization approach that enables us to separate frequency (the first advantage) from compositionality. The approach uses Huffman coding to tokenize words, by order of frequency, using a fixed amount of symbols. Experiments with CS-DE, EN-FR and EN-DE NMT show that frequency alone accounts for 90%-95% of the scores reached by BPE, hence compositionality has less importance than previously thought.",
    "path": "papers/23/06/2306.01393.json",
    "total_tokens": 778,
    "translated_title": "NMT中基于子词的分词中，频率和组合性的重要性评估",
    "translated_abstract": "子词分词是神经语言模型和机器翻译系统中的默认标准。频繁引用子词的优点有：对频繁词语进行更短编码，子词组合性强以及处理未知词语的能力。然而，它们的相对重要性尚不太清楚。本文提出了一种分词方法，可以将频率（第一个优点）与组合性分离开来，使用霍夫曼编码对单词进行分词，按频率顺序，使用固定数量的符号。实验表明，在CS-DE、EN-FR和EN-DE NMT中，仅频率就占了BPE得分的90%-95%，因此组合性并不像以前认为的那么重要。",
    "tldr": "本文通过实验发现，在NMT中基于子词的分词方法中，频率对于模型的表现贡献占据了90%-95%，因此相对于组合性，频率更为重要。",
    "en_tdlr": "This paper proposes a subword tokenization approach that separates frequency from compositionality and experiments show that frequency accounts for 90%-95% of the scores reached by BPE in NMT, indicating its greater importance compared to compositionality."
}