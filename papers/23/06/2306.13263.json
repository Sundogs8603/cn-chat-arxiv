{
    "title": "Synthetic data shuffling accelerates the convergence of federated learning under data heterogeneity. (arXiv:2306.13263v1 [cs.LG])",
    "abstract": "In federated learning, data heterogeneity is a critical challenge. A straightforward solution is to shuffle the clients' data to homogenize the distribution. However, this may violate data access rights, and how and when shuffling can accelerate the convergence of a federated optimization algorithm is not theoretically well understood. In this paper, we establish a precise and quantifiable correspondence between data heterogeneity and parameters in the convergence rate when a fraction of data is shuffled across clients. We prove that shuffling can quadratically reduce the gradient dissimilarity with respect to the shuffling percentage, accelerating convergence. Inspired by the theory, we propose a practical approach that addresses the data access rights issue by shuffling locally generated synthetic data. The experimental results show that shuffling synthetic data improves the performance of multiple existing federated learning algorithms by a large margin.",
    "link": "http://arxiv.org/abs/2306.13263",
    "context": "Title: Synthetic data shuffling accelerates the convergence of federated learning under data heterogeneity. (arXiv:2306.13263v1 [cs.LG])\nAbstract: In federated learning, data heterogeneity is a critical challenge. A straightforward solution is to shuffle the clients' data to homogenize the distribution. However, this may violate data access rights, and how and when shuffling can accelerate the convergence of a federated optimization algorithm is not theoretically well understood. In this paper, we establish a precise and quantifiable correspondence between data heterogeneity and parameters in the convergence rate when a fraction of data is shuffled across clients. We prove that shuffling can quadratically reduce the gradient dissimilarity with respect to the shuffling percentage, accelerating convergence. Inspired by the theory, we propose a practical approach that addresses the data access rights issue by shuffling locally generated synthetic data. The experimental results show that shuffling synthetic data improves the performance of multiple existing federated learning algorithms by a large margin.",
    "path": "papers/23/06/2306.13263.json",
    "total_tokens": 846,
    "translated_title": "合成数据重排加速异构数据下联邦学习的收敛(arXiv:2306.13263v1 [cs.LG])",
    "translated_abstract": "在联邦学习中，数据异构性是一个关键的挑战。一个简单的解决方案是对客户端的数据进行洗牌，以同质化分布。然而，这可能会违反数据访问权利，而对于在何时以及如何重排可以加速联邦优化算法的收敛，目前尚未在理论上得到很好的理解。本文建立了数据异构性与收敛速率参数之间的精确可量化的对应关系，证明了重排可以按百分比平方减少梯度差异，从而加速收敛。受理论启发，我们提出了一种通过对本地生成的合成数据进行重排来解决数据访问权问题的实用方法。实验结果表明，对合成数据进行重排可以大幅提高现有多个联邦学习算法的性能。",
    "tldr": "本文提出了一种通过对本地生成的合成数据进行重排来加速异构数据下联邦学习的收敛的方法，实验表明，对合成数据进行重排可以大幅提高现有多个联邦学习算法的性能。",
    "en_tdlr": "This paper proposes a practical approach to accelerate the convergence of federated learning under data heterogeneity by shuffling locally generated synthetic data, and the experimental results show that shuffling synthetic data can significantly improve the performance of multiple existing federated learning algorithms."
}