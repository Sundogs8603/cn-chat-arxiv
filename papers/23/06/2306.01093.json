{
    "title": "UCAS-IIE-NLP at SemEval-2023 Task 12: Enhancing Generalization of Multilingual BERT for Low-resource Sentiment Analysis. (arXiv:2306.01093v1 [cs.CL])",
    "abstract": "This paper describes our system designed for SemEval-2023 Task 12: Sentiment analysis for African languages. The challenge faced by this task is the scarcity of labeled data and linguistic resources in low-resource settings. To alleviate these, we propose a generalized multilingual system SACL-XLMR for sentiment analysis on low-resource languages. Specifically, we design a lexicon-based multilingual BERT to facilitate language adaptation and sentiment-aware representation learning. Besides, we apply a supervised adversarial contrastive learning technique to learn sentiment-spread structured representations and enhance model generalization. Our system achieved competitive results, largely outperforming baselines on both multilingual and zero-shot sentiment classification subtasks. Notably, the system obtained the 1st rank on the zero-shot classification subtask in the official ranking. Extensive experiments demonstrate the effectiveness of our system.",
    "link": "http://arxiv.org/abs/2306.01093",
    "context": "Title: UCAS-IIE-NLP at SemEval-2023 Task 12: Enhancing Generalization of Multilingual BERT for Low-resource Sentiment Analysis. (arXiv:2306.01093v1 [cs.CL])\nAbstract: This paper describes our system designed for SemEval-2023 Task 12: Sentiment analysis for African languages. The challenge faced by this task is the scarcity of labeled data and linguistic resources in low-resource settings. To alleviate these, we propose a generalized multilingual system SACL-XLMR for sentiment analysis on low-resource languages. Specifically, we design a lexicon-based multilingual BERT to facilitate language adaptation and sentiment-aware representation learning. Besides, we apply a supervised adversarial contrastive learning technique to learn sentiment-spread structured representations and enhance model generalization. Our system achieved competitive results, largely outperforming baselines on both multilingual and zero-shot sentiment classification subtasks. Notably, the system obtained the 1st rank on the zero-shot classification subtask in the official ranking. Extensive experiments demonstrate the effectiveness of our system.",
    "path": "papers/23/06/2306.01093.json",
    "total_tokens": 977,
    "translated_title": "UCAS-IIE-NLP在SemEval-2023任务12中的应用：增强低资源情感分析的多语言BERT泛化能力",
    "translated_abstract": "本文描述了我们为SemEval-2023任务12设计的系统：非洲语言的情感分析。该任务面临的挑战是在低资源环境下标注数据和语言资源的稀缺性。为了缓解这些问题，我们提出了一个名为SACL-XLMR的通用多语言系统，用于低资源语言的情感分析。具体而言，我们设计了一个基于词典的多语言BERT，以便进行语言适应和情感感知表示学习。此外，我们采用一个监督性的对抗式对比学习技术来学习情感传播结构化表示并增强模型的泛化能力。我们的系统在多语言和零样本情感分类子任务中表现出色，远远超过基线。值得注意的是，在官方排名中，该系统在零样本分类子任务中获得了第一名。广泛的实验表明了我们系统的有效性。",
    "tldr": "本文介绍了 UCAS-IIE-NLP 设计的 SACL-XLMR 系统，它利用词典式多语言BERT进行情感感知表示学习，使用监督性对抗式对比学习技术进行情感传播结构化表示学习，用于低资源情感分析，且在多语言和零样本情感分类子任务中表现出色，并且在零样本分类子任务中获得了第一名。",
    "en_tdlr": "This paper presents the UCAS-IIE-NLP designed SACL-XLMR system for low-resource sentiment analysis, which employs a lexicon-based multilingual BERT for language adaptation and sentiment-aware representation learning, and uses supervised adversarial contrastive learning technique for sentiment-spread structured representations to enhance model generalization. The system achieved competitive results and obtained the 1st rank on the zero-shot classification subtask."
}