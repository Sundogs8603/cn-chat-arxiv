{
    "title": "Learning Fair Classifiers via Min-Max F-divergence Regularization. (arXiv:2306.16552v1 [cs.LG])",
    "abstract": "As machine learning (ML) based systems are adopted in domains such as law enforcement, criminal justice, finance, hiring and admissions, ensuring the fairness of ML aided decision-making is becoming increasingly important. In this paper, we focus on the problem of fair classification, and introduce a novel min-max F-divergence regularization framework for learning fair classification models while preserving high accuracy. Our framework consists of two trainable networks, namely, a classifier network and a bias/fairness estimator network, where the fairness is measured using the statistical notion of F-divergence. We show that F-divergence measures possess convexity and differentiability properties, and their variational representation make them widely applicable in practical gradient based training methods. The proposed framework can be readily adapted to multiple sensitive attributes and for high dimensional datasets. We study the F-divergence based training paradigm for two types of ",
    "link": "http://arxiv.org/abs/2306.16552",
    "context": "Title: Learning Fair Classifiers via Min-Max F-divergence Regularization. (arXiv:2306.16552v1 [cs.LG])\nAbstract: As machine learning (ML) based systems are adopted in domains such as law enforcement, criminal justice, finance, hiring and admissions, ensuring the fairness of ML aided decision-making is becoming increasingly important. In this paper, we focus on the problem of fair classification, and introduce a novel min-max F-divergence regularization framework for learning fair classification models while preserving high accuracy. Our framework consists of two trainable networks, namely, a classifier network and a bias/fairness estimator network, where the fairness is measured using the statistical notion of F-divergence. We show that F-divergence measures possess convexity and differentiability properties, and their variational representation make them widely applicable in practical gradient based training methods. The proposed framework can be readily adapted to multiple sensitive attributes and for high dimensional datasets. We study the F-divergence based training paradigm for two types of ",
    "path": "papers/23/06/2306.16552.json",
    "total_tokens": 904,
    "translated_title": "通过最小-最大F-散度正则化学习公平分类器",
    "translated_abstract": "随着机器学习（ML）系统在执法、刑事司法、金融、招聘和录取等领域得到应用，确保ML辅助决策的公平性变得越来越重要。本文关注公平分类问题，提出一种新颖的最小-最大F-散度正则化框架，用于学习公平分类模型并保持高准确性。我们的框架由两个可训练的网络组成，即分类器网络和偏差/公平性估计器网络，其中公平性使用统计概念的F-散度进行衡量。我们展示了F-散度度量具有凸性和可微性的特性，并且它们的变分表示使它们在实际的基于梯度的训练方法中具有广泛的适用性。所提出的框架可以方便地适应多个敏感属性和高维数据集。我们研究了基于F-散度的训练范式在两种类型的问题上的性能。",
    "tldr": "本文提出了一种通过最小-最大F-散度正则化学习公平分类器的框架，该框架通过使用F-散度衡量公平性，并保持高准确性。该框架可以适用于多个敏感属性和高维数据集。"
}