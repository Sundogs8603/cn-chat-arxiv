{
    "title": "FunQA: Towards Surprising Video Comprehension",
    "abstract": "arXiv:2306.14899v2 Announce Type: replace-cross  Abstract: Surprising videos, such as funny clips, creative performances, or visual illusions, attract significant attention. Enjoyment of these videos is not simply a response to visual stimuli; rather, it hinges on the human capacity to understand (and appreciate) commonsense violations depicted in these videos. We introduce FunQA, a challenging video question-answering (QA) dataset specifically designed to evaluate and enhance the depth of video reasoning based on counter-intuitive and fun videos. Unlike most video QA benchmarks which focus on less surprising contexts, e.g., cooking or instructional videos, FunQA covers three previously unexplored types of surprising videos: 1) HumorQA, 2) CreativeQA, and 3) MagicQA. For each subset, we establish rigorous QA tasks designed to assess the model's capability in counter-intuitive timestamp localization, detailed video description, and reasoning around counter-intuitiveness. We also pose hi",
    "link": "https://arxiv.org/abs/2306.14899",
    "context": "Title: FunQA: Towards Surprising Video Comprehension\nAbstract: arXiv:2306.14899v2 Announce Type: replace-cross  Abstract: Surprising videos, such as funny clips, creative performances, or visual illusions, attract significant attention. Enjoyment of these videos is not simply a response to visual stimuli; rather, it hinges on the human capacity to understand (and appreciate) commonsense violations depicted in these videos. We introduce FunQA, a challenging video question-answering (QA) dataset specifically designed to evaluate and enhance the depth of video reasoning based on counter-intuitive and fun videos. Unlike most video QA benchmarks which focus on less surprising contexts, e.g., cooking or instructional videos, FunQA covers three previously unexplored types of surprising videos: 1) HumorQA, 2) CreativeQA, and 3) MagicQA. For each subset, we establish rigorous QA tasks designed to assess the model's capability in counter-intuitive timestamp localization, detailed video description, and reasoning around counter-intuitiveness. We also pose hi",
    "path": "papers/23/06/2306.14899.json",
    "total_tokens": 900,
    "translated_title": "FunQA：迈向令人惊讶的视频理解",
    "translated_abstract": "令人惊讶的视频，比如有趣的片段、创意演出或视觉幻象，吸引了相当多的关注。对这些视频的欣赏不仅仅是对视觉刺激的反应；相反，它取决于人类理解（以及欣赏）这些视频中所描绘的常识违反的能力。我们引入了FunQA，这是一个具有挑战性的视频问答（QA）数据集，专门设计用来评估和提高基于反直觉和有趣视频的视频推理深度。与大多数侧重于不太惊讶的背景（例如烹饪或说明视频）的视频QA基准不同，FunQA涵盖了三种以前未被探索的类型的惊喜视频：1）HumorQA，2）CreativeQA和3）MagicQA。对于每个子集，我们建立了严格的QA任务，旨在评估模型在反直觉时间戳定位、详细视频描述以及围绕反直觉进行推理的能力。",
    "tldr": "FunQA是一个旨在评估和提高基于反直觉和有趣视频的视频推理深度的数据集，涵盖了HumorQA、CreativeQA和MagicQA三种以前未被探索的惊喜视频类型。",
    "en_tdlr": "FunQA is a dataset designed to assess and improve the depth of video reasoning based on counter-intuitive and fun videos, covering three previously unexplored types of surprising videos: 1) HumorQA, 2) CreativeQA, and 3) MagicQA."
}