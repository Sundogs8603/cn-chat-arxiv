{
    "title": "TACOformer:Token-channel compounded Cross Attention for Multimodal Emotion Recognition. (arXiv:2306.13592v1 [cs.MM])",
    "abstract": "Recently, emotion recognition based on physiological signals has emerged as a field with intensive research. The utilization of multi-modal, multi-channel physiological signals has significantly improved the performance of emotion recognition systems, due to their complementarity. However, effectively integrating emotion-related semantic information from different modalities and capturing inter-modal dependencies remains a challenging issue. Many existing multimodal fusion methods ignore either token-to-token or channel-to-channel correlations of multichannel signals from different modalities, which limits the classification capability of the models to some extent. In this paper, we propose a comprehensive perspective of multimodal fusion that integrates channel-level and token-level cross-modal interactions. Specifically, we introduce a unified cross attention module called Token-chAnnel COmpound (TACO) Cross Attention to perform multimodal fusion, which simultaneously models channel-",
    "link": "http://arxiv.org/abs/2306.13592",
    "context": "Title: TACOformer:Token-channel compounded Cross Attention for Multimodal Emotion Recognition. (arXiv:2306.13592v1 [cs.MM])\nAbstract: Recently, emotion recognition based on physiological signals has emerged as a field with intensive research. The utilization of multi-modal, multi-channel physiological signals has significantly improved the performance of emotion recognition systems, due to their complementarity. However, effectively integrating emotion-related semantic information from different modalities and capturing inter-modal dependencies remains a challenging issue. Many existing multimodal fusion methods ignore either token-to-token or channel-to-channel correlations of multichannel signals from different modalities, which limits the classification capability of the models to some extent. In this paper, we propose a comprehensive perspective of multimodal fusion that integrates channel-level and token-level cross-modal interactions. Specifically, we introduce a unified cross attention module called Token-chAnnel COmpound (TACO) Cross Attention to perform multimodal fusion, which simultaneously models channel-",
    "path": "papers/23/06/2306.13592.json",
    "total_tokens": 996,
    "translated_title": "TACOformer: 多模态情感识别中的令牌通道复合交叉注意力模型",
    "translated_abstract": "最近，基于生理信号的情感识别成为了一个进行深入研究的领域。利用多模态、多通道的生理信号显著提高了情感识别系统的性能，因为它们具有互补性。然而，有效地整合来自不同模态的与情感相关的语义信息并捕获跨模态的依赖关系仍然是一个具有挑战性的问题。许多现有的多模态融合方法忽略了多个通道信号之间的令牌到令牌或通道到通道的相关性，这在一定程度上限制了模型的分类能力。在本文中，我们提出了一种综合性的多模态融合视角，它整合了通道级别和令牌级别的跨模态交互，采用复合机制进行跨通道处理。特别是，我们引入了一种统一的交叉注意力模块，称为 Token-chAnnel COmpound（TACO）Cross Attention，用于执行多模态融合。实验结果表明，TACOformer 方法在多模态情感识别任务上具有先进性能。",
    "tldr": "TACOformer 提出了一种综合性的多模态融合视角，利用 Token-chAnnel COmpound（TACO）Cross Attention 模块，同时建模通道级别和令牌级别的跨模态交互，实现了在多模态情感识别任务上具有先进性能。",
    "en_tdlr": "TACOformer proposes a comprehensive perspective of multimodal fusion, utilizes Token-chAnnel COmpound (TACO) Cross Attention module to model channel-level and token-level cross-modal interactions, achieving advanced performance in multimodal emotion recognition task."
}