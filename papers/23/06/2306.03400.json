{
    "title": "G-CAME: Gaussian-Class Activation Mapping Explainer for Object Detectors. (arXiv:2306.03400v1 [cs.CV])",
    "abstract": "Nowadays, deep neural networks for object detection in images are very prevalent. However, due to the complexity of these networks, users find it hard to understand why these objects are detected by models. We proposed Gaussian Class Activation Mapping Explainer (G-CAME), which generates a saliency map as the explanation for object detection models. G-CAME can be considered a CAM-based method that uses the activation maps of selected layers combined with the Gaussian kernel to highlight the important regions in the image for the predicted box. Compared with other Region-based methods, G-CAME can transcend time constraints as it takes a very short time to explain an object. We also evaluated our method qualitatively and quantitatively with YOLOX on the MS-COCO 2017 dataset and guided to apply G-CAME into the two-stage Faster-RCNN model.",
    "link": "http://arxiv.org/abs/2306.03400",
    "context": "Title: G-CAME: Gaussian-Class Activation Mapping Explainer for Object Detectors. (arXiv:2306.03400v1 [cs.CV])\nAbstract: Nowadays, deep neural networks for object detection in images are very prevalent. However, due to the complexity of these networks, users find it hard to understand why these objects are detected by models. We proposed Gaussian Class Activation Mapping Explainer (G-CAME), which generates a saliency map as the explanation for object detection models. G-CAME can be considered a CAM-based method that uses the activation maps of selected layers combined with the Gaussian kernel to highlight the important regions in the image for the predicted box. Compared with other Region-based methods, G-CAME can transcend time constraints as it takes a very short time to explain an object. We also evaluated our method qualitatively and quantitatively with YOLOX on the MS-COCO 2017 dataset and guided to apply G-CAME into the two-stage Faster-RCNN model.",
    "path": "papers/23/06/2306.03400.json",
    "total_tokens": 934,
    "translated_title": "G-CAME: 面向目标检测的高斯类激活映射解释器",
    "translated_abstract": "当今，图像目标检测的深度神经网络非常普及。然而，由于这些网络的复杂性，用户很难理解模型为什么会检测出这些对象。我们提出了高斯类激活映射解释器（G-CAME），它生成显著性图作为目标检测模型的说明。 G-CAME 可以被认为是一种基于 CAM 的方法，它使用选择层的激活映射与高斯核来突出显示图像中与预测框相关的重要区域。与其他基于区域的方法相比，G-CAME 可以超越时间限制，因为它只需要很短时间就能解释一个对象。我们还在 MS-COCO 2017 数据集上使用 YOLOX 定量和定性地评估了我们的方法，并指导将 G-CAME 应用于两阶段 Faster-RCNN 模型。",
    "tldr": "G-CAME 提出了一种面向目标检测的高斯类激活映射解释器，通过使用激活映射与高斯核生成显著性图来突出显示图像中与预测框相关的重要区域，具有很短时间解释对象等优点。",
    "en_tdlr": "G-CAME proposed a Gaussian-Class Activation Mapping explainer for object detectors, which generates a saliency map using activation maps with the Gaussian kernel to highlight important regions related to the predicted box in images, and can transcend time constraints, etc. Compared with other region-based methods, G-CAME has the advantage of short explanation time. The method was qualitatively and quantitatively evaluated with YOLOX on MS-COCO 2017, and guided the application of G-CAME into the two-stage Faster-RCNN model."
}