{
    "title": "Simple and Controllable Music Generation. (arXiv:2306.05284v1 [cs.SD])",
    "abstract": "We tackle the task of conditional music generation. We introduce MusicGen, a single Language Model (LM) that operates over several streams of compressed discrete music representation, i.e., tokens. Unlike prior work, MusicGen is comprised of a single-stage transformer LM together with efficient token interleaving patterns, which eliminates the need for cascading several models, e.g., hierarchically or upsampling. Following this approach, we demonstrate how MusicGen can generate high-quality samples, while being conditioned on textual description or melodic features, allowing better controls over the generated output. We conduct extensive empirical evaluation, considering both automatic and human studies, showing the proposed approach is superior to the evaluated baselines on a standard text-to-music benchmark. Through ablation studies, we shed light over the importance of each of the components comprising MusicGen. Music samples, code, and models are available at https://github.com/fac",
    "link": "http://arxiv.org/abs/2306.05284",
    "context": "Title: Simple and Controllable Music Generation. (arXiv:2306.05284v1 [cs.SD])\nAbstract: We tackle the task of conditional music generation. We introduce MusicGen, a single Language Model (LM) that operates over several streams of compressed discrete music representation, i.e., tokens. Unlike prior work, MusicGen is comprised of a single-stage transformer LM together with efficient token interleaving patterns, which eliminates the need for cascading several models, e.g., hierarchically or upsampling. Following this approach, we demonstrate how MusicGen can generate high-quality samples, while being conditioned on textual description or melodic features, allowing better controls over the generated output. We conduct extensive empirical evaluation, considering both automatic and human studies, showing the proposed approach is superior to the evaluated baselines on a standard text-to-music benchmark. Through ablation studies, we shed light over the importance of each of the components comprising MusicGen. Music samples, code, and models are available at https://github.com/fac",
    "path": "papers/23/06/2306.05284.json",
    "total_tokens": 843,
    "translated_title": "简单且可控的音乐生成",
    "translated_abstract": "本研究解决了条件音乐生成的问题。我们介绍了MusicGen，它是一个单一的语言模型，可以操作多个压缩离散音乐表示流，即令牌。与以往的工作不同，MusicGen由一个单一阶段的Transformer LM和高效的令牌交错模式组成，消除了级联多个模型的需要，例如分层或上采样。采用这种方法，我们展示了MusicGen如何在条件描述或旋律特征的控制下生成高质量的样本。我们进行了广泛的实证评估，考虑了自动和人为研究，展示了所提出的方法优于标准文本到音乐基准上评估的基线。通过消融研究，我们阐明了MusicGen所包含组件的重要性。音乐样本、代码和模型可以在https://github.com/fac找到。",
    "tldr": "本文提出了 MusicGen，一个单一的语言模型，可以在条件描述或旋律特征控制下生成高质量的样本，并且在标准的文本到音乐基准上的实证研究中，该方法优于其他基线模型。",
    "en_tdlr": "This paper proposes MusicGen, a single language model that can generate high-quality music samples under controlled conditions, and empirically shows its superiority to other baselines in a standard text-to-music benchmark."
}