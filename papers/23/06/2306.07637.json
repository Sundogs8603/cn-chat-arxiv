{
    "title": "For Better or Worse: The Impact of Counterfactual Explanations' Directionality on User Behavior in xAI. (arXiv:2306.07637v1 [cs.AI])",
    "abstract": "Counterfactual explanations (CFEs) are a popular approach in explainable artificial intelligence (xAI), highlighting changes to input data necessary for altering a model's output. A CFE can either describe a scenario that is better than the factual state (upward CFE), or a scenario that is worse than the factual state (downward CFE). However, potential benefits and drawbacks of the directionality of CFEs for user behavior in xAI remain unclear. The current user study (N=161) compares the impact of CFE directionality on behavior and experience of participants tasked to extract new knowledge from an automated system based on model predictions and CFEs. Results suggest that upward CFEs provide a significant performance advantage over other forms of counterfactual feedback. Moreover, the study highlights potential benefits of mixed CFEs improving user performance compared to downward CFEs or no explanations. In line with the performance results, users' explicit knowledge of the system is s",
    "link": "http://arxiv.org/abs/2306.07637",
    "context": "Title: For Better or Worse: The Impact of Counterfactual Explanations' Directionality on User Behavior in xAI. (arXiv:2306.07637v1 [cs.AI])\nAbstract: Counterfactual explanations (CFEs) are a popular approach in explainable artificial intelligence (xAI), highlighting changes to input data necessary for altering a model's output. A CFE can either describe a scenario that is better than the factual state (upward CFE), or a scenario that is worse than the factual state (downward CFE). However, potential benefits and drawbacks of the directionality of CFEs for user behavior in xAI remain unclear. The current user study (N=161) compares the impact of CFE directionality on behavior and experience of participants tasked to extract new knowledge from an automated system based on model predictions and CFEs. Results suggest that upward CFEs provide a significant performance advantage over other forms of counterfactual feedback. Moreover, the study highlights potential benefits of mixed CFEs improving user performance compared to downward CFEs or no explanations. In line with the performance results, users' explicit knowledge of the system is s",
    "path": "papers/23/06/2306.07637.json",
    "total_tokens": 875,
    "translated_title": "论反事实解释的方向对xAI用户行为的影响",
    "translated_abstract": "反事实解释（CFE）是可解释人工智能（xAI）中的一种常用方法，突出显示改变输入数据以改变模型输出所需的变化。CFE可以描述比实际状态更好的情境（向上CFE）或比实际状态更差的情境（向下CFE）。然而，CFE方向性对xAI用户的行为潜在利益和缺点仍不清楚。这项研究比较了CFE方向性对用户行为和体验的影响，结果表明向上CFE比其他形式的反事实反馈提供了显著的性能优势。此外，该研究强调了混合CFE相对于向下CFE或没有解释可以提高用户表现的潜在好处。与表现结果一致，用户对系统的明确知识也得到了增强。",
    "tldr": "本文研究了反事实解释（CFE）的方向对xAI用户行为的影响，结果显示向上CFE相对于向下CFE或无解释可以提高用户表现的潜在好处。",
    "en_tdlr": "This paper investigates the impact of the directionality of counterfactual explanations (CFEs) on user behavior in xAI. The study finds that upward CFEs provide a significant performance advantage over other forms of CFEs, and highlights potential benefits of mixed CFEs improving user performance compared to downward CFEs or no explanations."
}