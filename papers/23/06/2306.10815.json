{
    "title": "Practical First-Order Bayesian Optimization Algorithms. (arXiv:2306.10815v1 [cs.LG])",
    "abstract": "First Order Bayesian Optimization (FOBO) is a sample efficient sequential approach to find the global maxima of an expensive-to-evaluate black-box objective function by suitably querying for the function and its gradient evaluations. Such methods assume Gaussian process (GP) models for both, the function and its gradient, and use them to construct an acquisition function that identifies the next query point. In this paper, we propose a class of practical FOBO algorithms that efficiently utilizes the information from the gradient GP to identify potential query points with zero gradients. We construct a multi-level acquisition function where in the first step, we optimize a lower level acquisition function with multiple restarts to identify potential query points with zero gradient value. We then use the upper level acquisition function to rank these query points based on their function values to potentially identify the global maxima. As a final step, the potential point of maxima is ch",
    "link": "http://arxiv.org/abs/2306.10815",
    "context": "Title: Practical First-Order Bayesian Optimization Algorithms. (arXiv:2306.10815v1 [cs.LG])\nAbstract: First Order Bayesian Optimization (FOBO) is a sample efficient sequential approach to find the global maxima of an expensive-to-evaluate black-box objective function by suitably querying for the function and its gradient evaluations. Such methods assume Gaussian process (GP) models for both, the function and its gradient, and use them to construct an acquisition function that identifies the next query point. In this paper, we propose a class of practical FOBO algorithms that efficiently utilizes the information from the gradient GP to identify potential query points with zero gradients. We construct a multi-level acquisition function where in the first step, we optimize a lower level acquisition function with multiple restarts to identify potential query points with zero gradient value. We then use the upper level acquisition function to rank these query points based on their function values to potentially identify the global maxima. As a final step, the potential point of maxima is ch",
    "path": "papers/23/06/2306.10815.json",
    "total_tokens": 848,
    "translated_title": "实用的一阶贝叶斯优化算法",
    "translated_abstract": "第一阶贝叶斯优化(FOBO)是一种有效的顺序方法，通过适当地查询函数及其梯度评估，来寻找昂贵的黑盒子目标函数的全局极值。这种方法假设函数和其梯度的高斯过程(GP)模型，并使用它们构建一个获取函数，以识别下一个查询点。在本文中，我们提出了一类实用的FOBO算法，它有效利用了梯度GP的信息，以识别具有零梯度的潜在查询点。我们构建了一个多级采集函数，在第一步中，我们使用多重重启来优化较低级别的采集函数，以识别具有零梯度值的潜在查询点。然后，我们使用上层获取函数根据它们的函数值对这些查询点进行排序，以潜在地确定全局最大值。作为最后一步，最大值的潜在点被选择。",
    "tldr": "本文提出了一种实用的FOBO算法，通过利用梯度GP的信息，有效地识别具有零梯度的潜在查询点，采用多级采集函数来潜在确定全局最大值。",
    "en_tdlr": "This paper proposes a practical FOBO algorithm that identifies potential query points with zero gradients by efficiently utilizing information from the gradient GP, and constructs a multi-level acquisition function to potentially determine the global maxima."
}