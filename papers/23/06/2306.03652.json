{
    "title": "Injecting knowledge into language generation: a case study in auto-charting after-visit care instructions from medical dialogue. (arXiv:2306.03652v1 [cs.CL])",
    "abstract": "Factual correctness is often the limiting factor in practical applications of natural language generation in high-stakes domains such as healthcare. An essential requirement for maintaining factuality is the ability to deal with rare tokens. This paper focuses on rare tokens that appear in both the source and the reference sequences, and which, when missed during generation, decrease the factual correctness of the output text. For high-stake domains that are also knowledge-rich, we show how to use knowledge to (a) identify which rare tokens that appear in both source and reference are important and (b) uplift their conditional probability. We introduce the ``utilization rate'' that encodes knowledge and serves as a regularizer by maximizing the marginal probability of selected tokens. We present a study in a knowledge-rich domain of healthcare, where we tackle the problem of generating after-visit care instructions based on patient-doctor dialogues. We verify that, in our dataset, spec",
    "link": "http://arxiv.org/abs/2306.03652",
    "context": "Title: Injecting knowledge into language generation: a case study in auto-charting after-visit care instructions from medical dialogue. (arXiv:2306.03652v1 [cs.CL])\nAbstract: Factual correctness is often the limiting factor in practical applications of natural language generation in high-stakes domains such as healthcare. An essential requirement for maintaining factuality is the ability to deal with rare tokens. This paper focuses on rare tokens that appear in both the source and the reference sequences, and which, when missed during generation, decrease the factual correctness of the output text. For high-stake domains that are also knowledge-rich, we show how to use knowledge to (a) identify which rare tokens that appear in both source and reference are important and (b) uplift their conditional probability. We introduce the ``utilization rate'' that encodes knowledge and serves as a regularizer by maximizing the marginal probability of selected tokens. We present a study in a knowledge-rich domain of healthcare, where we tackle the problem of generating after-visit care instructions based on patient-doctor dialogues. We verify that, in our dataset, spec",
    "path": "papers/23/06/2306.03652.json",
    "total_tokens": 779,
    "translated_title": "将知识注入语言生成：医学对话中自动生成复诊护理指南的案例研究",
    "translated_abstract": "在高风险领域如医疗保健中，事实正确性经常是自然语言生成实际应用的局限性。保持事实正确性的基本要求是处理罕见标记的能力。本文重点介绍了源序列和参考序列中出现的罕见标记，如果在生成过程中漏掉，则会降低输出文本的事实正确性。对于知识丰富的高风险领域，我们展示如何利用知识来识别出重要的出现在源和参考中的罕见标记，并提高它们的条件概率，从而提高生成结果的事实正确性。",
    "tldr": "文章介绍了如何在自然语言生成中注入医学知识，提高事实正确性，并通过生成复诊护理指南的案例研究验证了该方法。",
    "en_tdlr": "This paper introduces how to inject medical knowledge into natural language generation to improve factual correctness, and verifies this method through a case study of generating after-visit care instructions based on patient-doctor dialogues."
}