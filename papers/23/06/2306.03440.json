{
    "title": "Quantifying the Variability Collapse of Neural Networks. (arXiv:2306.03440v1 [cs.LG])",
    "abstract": "Recent studies empirically demonstrate the positive relationship between the transferability of neural networks and the within-class variation of the last layer features. The recently discovered Neural Collapse (NC) phenomenon provides a new perspective of understanding such last layer geometry of neural networks. In this paper, we propose a novel metric, named Variability Collapse Index (VCI), to quantify the variability collapse phenomenon in the NC paradigm. The VCI metric is well-motivated and intrinsically related to the linear probing loss on the last layer features. Moreover, it enjoys desired theoretical and empirical properties, including invariance under invertible linear transformations and numerical stability, that distinguishes it from previous metrics. Our experiments verify that VCI is indicative of the variability collapse and the transferability of pretrained neural networks.",
    "link": "http://arxiv.org/abs/2306.03440",
    "context": "Title: Quantifying the Variability Collapse of Neural Networks. (arXiv:2306.03440v1 [cs.LG])\nAbstract: Recent studies empirically demonstrate the positive relationship between the transferability of neural networks and the within-class variation of the last layer features. The recently discovered Neural Collapse (NC) phenomenon provides a new perspective of understanding such last layer geometry of neural networks. In this paper, we propose a novel metric, named Variability Collapse Index (VCI), to quantify the variability collapse phenomenon in the NC paradigm. The VCI metric is well-motivated and intrinsically related to the linear probing loss on the last layer features. Moreover, it enjoys desired theoretical and empirical properties, including invariance under invertible linear transformations and numerical stability, that distinguishes it from previous metrics. Our experiments verify that VCI is indicative of the variability collapse and the transferability of pretrained neural networks.",
    "path": "papers/23/06/2306.03440.json",
    "total_tokens": 896,
    "translated_title": "神经网络的可变性崩溃的量化",
    "translated_abstract": "最近的研究从实证上展示了神经网络的可转移性和最后一层特征的内类变化之间的正相关关系。最近发现的神经崩溃（NC）现象提供了一种新的视角，以理解神经网络的最后一层几何特征。在本文中，我们提出了一种新的指标，称为可变性崩溃指数（VCI），用于量化NC范式中的可变性崩溃现象。VCI指标具有很强的动机性，并且本质上与最后一层特征的线性探测损失有关。此外，它具有理论上和实证上的优越性质，包括在可逆线性变换下的不变性和数值稳定性，这与之前的指标有所区别。我们的实验验证了VCI在预训练神经网络中指示可变性崩溃和可转移性的能力。",
    "tldr": "本文提出了一种叫做可变性崩溃指数（VCI）的新指标，用于量化神经网络的可变性崩溃现象，其优越性质包括在可逆线性变换下的不变性和数值稳定性，此指标可以指示预训练神经网络中的可变性崩溃和可转移性。",
    "en_tdlr": "This paper proposes a novel metric, Variability Collapse Index (VCI), to quantify the variability collapse phenomenon in neural networks, which enjoys desirable theoretical and empirical properties, including invariance under invertible linear transformations and numerical stability. The VCI metric can indicate the variability collapse and transferability in pretrained neural networks."
}