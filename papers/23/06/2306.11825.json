{
    "title": "On Compositionality and Improved Training of NADO. (arXiv:2306.11825v1 [cs.CL])",
    "abstract": "NeurAlly-Decomposed Oracle (NADO) is a powerful approach for controllable generation with large language models. Differentiating from finetuning/prompt tuning, it has the potential to avoid catastrophic forgetting of the large base model and achieve guaranteed convergence to an entropy-maximized closed-form solution without significantly limiting the model capacity. Despite its success, several challenges arise when applying NADO to more complex scenarios. First, the best practice of using NADO for the composition of multiple control signals is under-explored. Second, vanilla NADO suffers from gradient vanishing for low-probability control signals and is highly reliant on the forward-consistency regularization. In this paper, we study the aforementioned challenges when using NADO theoretically and empirically. We show we can achieve guaranteed compositional generalization of NADO with a certain practice, and propose a novel alternative parameterization of NADO to perfectly guarantee th",
    "link": "http://arxiv.org/abs/2306.11825",
    "context": "Title: On Compositionality and Improved Training of NADO. (arXiv:2306.11825v1 [cs.CL])\nAbstract: NeurAlly-Decomposed Oracle (NADO) is a powerful approach for controllable generation with large language models. Differentiating from finetuning/prompt tuning, it has the potential to avoid catastrophic forgetting of the large base model and achieve guaranteed convergence to an entropy-maximized closed-form solution without significantly limiting the model capacity. Despite its success, several challenges arise when applying NADO to more complex scenarios. First, the best practice of using NADO for the composition of multiple control signals is under-explored. Second, vanilla NADO suffers from gradient vanishing for low-probability control signals and is highly reliant on the forward-consistency regularization. In this paper, we study the aforementioned challenges when using NADO theoretically and empirically. We show we can achieve guaranteed compositional generalization of NADO with a certain practice, and propose a novel alternative parameterization of NADO to perfectly guarantee th",
    "path": "papers/23/06/2306.11825.json",
    "total_tokens": 935,
    "translated_abstract": "NeurAlly-Decomposed Oracle (NADO) 是用于控制生成的大型语言模型的一种强大方法。与微调/提示微调不同，它有潜力避免大型基础模型的灾难性遗忘，并在不显着限制模型容量的情况下实现对熵最大化闭合形式解的收敛保证。尽管它成功了，但在将NADO应用于更复杂的场景时，还会出现一些挑战。首先，使用NADO组合多个控制信号的最佳实践尚未得到充分探讨。其次，纯NADO对于低概率控制信号存在梯度消失的问题，并且高度依赖正向一致性正则化。本文在理论和实证方面研究了使用NADO时所遇到的挑战。我们展示了我们可以通过某些实践实现对NADO的组合泛化的保证，并提出了一种新的替代参数化方式，以完美保证NADO的泛化性和梯度稳定性。",
    "tldr": "本文探讨了在大型语言模型上使用 NADO 生成更复杂场景时所遇到的挑战。我们提出了一些措施，如通过特定实践来实现对NADO的组合泛化的保证，并提出了一种新的参数化方式，以完美保证NADO的泛化性和梯度稳定性。"
}