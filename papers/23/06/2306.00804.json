{
    "title": "Adaptive Contextual Biasing for Transducer Based Streaming Speech Recognition. (arXiv:2306.00804v2 [cs.SD] UPDATED)",
    "abstract": "By incorporating additional contextual information, deep biasing methods have emerged as a promising solution for speech recognition of personalized words. However, for real-world voice assistants, always biasing on such personalized words with high prediction scores can significantly degrade the performance of recognizing common words. To address this issue, we propose an adaptive contextual biasing method based on Context-Aware Transformer Transducer (CATT) that utilizes the biased encoder and predictor embeddings to perform streaming prediction of contextual phrase occurrences. Such prediction is then used to dynamically switch the bias list on and off, enabling the model to adapt to both personalized and common scenarios. Experiments on Librispeech and internal voice assistant datasets show that our approach can achieve up to 6.7% and 20.7% relative reduction in WER and CER compared to the baseline respectively, mitigating up to 96.7% and 84.9% of the relative WER and CER increase ",
    "link": "http://arxiv.org/abs/2306.00804",
    "context": "Title: Adaptive Contextual Biasing for Transducer Based Streaming Speech Recognition. (arXiv:2306.00804v2 [cs.SD] UPDATED)\nAbstract: By incorporating additional contextual information, deep biasing methods have emerged as a promising solution for speech recognition of personalized words. However, for real-world voice assistants, always biasing on such personalized words with high prediction scores can significantly degrade the performance of recognizing common words. To address this issue, we propose an adaptive contextual biasing method based on Context-Aware Transformer Transducer (CATT) that utilizes the biased encoder and predictor embeddings to perform streaming prediction of contextual phrase occurrences. Such prediction is then used to dynamically switch the bias list on and off, enabling the model to adapt to both personalized and common scenarios. Experiments on Librispeech and internal voice assistant datasets show that our approach can achieve up to 6.7% and 20.7% relative reduction in WER and CER compared to the baseline respectively, mitigating up to 96.7% and 84.9% of the relative WER and CER increase ",
    "path": "papers/23/06/2306.00804.json",
    "total_tokens": 978,
    "translated_title": "自适应上下文偏置的基于Transducer的流式语音识别",
    "translated_abstract": "通过加入额外的上下文信息，深度偏置方法已经成为解决个性化话语识别的有希望的解决方案。然而，在实际的语音助手中，总是将高预测分数的个性化词语进行偏置处理会显著降低对常见词语的识别性能。为了解决这个问题，我们提出了一种基于上下文感知Transformer Transducer（CATT）的自适应上下文偏置方法，该方法利用偏置编码器和预测器嵌入来执行上下文短语出现的流式预测。这种预测然后被用来动态地切换偏置列表的开关，使模型适应个性化和常见情景。在Librispeech和内部语音助手数据集上的实验证明，与基线相比，我们的方法在WER和CER上分别可以达到6.7%和20.7%的相对降低，将相对WER和CER的增加减少到96.7%和84.9%。",
    "tldr": "该论文提出了一种自适应上下文偏置方法，基于Context-Aware Transformer Transducer (CATT) 来进行流式语音识别的预测。实验结果表明，与基线相比，该方法在 WER 和 CER 上可以分别减少6.7%和20.7%，减少了96.7%和84.9% 的相对 WER 和 CER 增加。"
}