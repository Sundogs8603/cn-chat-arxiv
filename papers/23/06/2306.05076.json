{
    "title": "DLAMA: A Framework for Curating Culturally Diverse Facts for Probing the Knowledge of Pretrained Language Models. (arXiv:2306.05076v1 [cs.CL])",
    "abstract": "A few benchmarking datasets have been released to evaluate the factual knowledge of pretrained language models. These benchmarks (e.g., LAMA, and ParaRel) are mainly developed in English and later are translated to form new multilingual versions (e.g., mLAMA, and mParaRel). Results on these multilingual benchmarks suggest that using English prompts to recall the facts from multilingual models usually yields significantly better and more consistent performance than using non-English prompts. Our analysis shows that mLAMA is biased toward facts from Western countries, which might affect the fairness of probing models. We propose a new framework for curating factual triples from Wikidata that are culturally diverse. A new benchmark DLAMA-v1 is built of factual triples from three pairs of contrasting cultures having a total of 78,259 triples from 20 relation predicates. The three pairs comprise facts representing the (Arab and Western), (Asian and Western), and (South American and Western)",
    "link": "http://arxiv.org/abs/2306.05076",
    "context": "Title: DLAMA: A Framework for Curating Culturally Diverse Facts for Probing the Knowledge of Pretrained Language Models. (arXiv:2306.05076v1 [cs.CL])\nAbstract: A few benchmarking datasets have been released to evaluate the factual knowledge of pretrained language models. These benchmarks (e.g., LAMA, and ParaRel) are mainly developed in English and later are translated to form new multilingual versions (e.g., mLAMA, and mParaRel). Results on these multilingual benchmarks suggest that using English prompts to recall the facts from multilingual models usually yields significantly better and more consistent performance than using non-English prompts. Our analysis shows that mLAMA is biased toward facts from Western countries, which might affect the fairness of probing models. We propose a new framework for curating factual triples from Wikidata that are culturally diverse. A new benchmark DLAMA-v1 is built of factual triples from three pairs of contrasting cultures having a total of 78,259 triples from 20 relation predicates. The three pairs comprise facts representing the (Arab and Western), (Asian and Western), and (South American and Western)",
    "path": "papers/23/06/2306.05076.json",
    "total_tokens": 903,
    "translated_title": "DLAMA: 一个用于为探究预训练语言模型知识筛选多元文化事实的框架",
    "translated_abstract": "已经发布了一些基准数据集来评估预训练语言模型的事实知识。这些基准数据集（例如LAMA和ParaRel）主要是用英语开发的，然后被翻译成新的多语言版本（例如mLAMA和mParaRel）。对这些多语言基准数据集的结果表明，使用英语提示从多语言模型中回忆事实通常比使用非英语提示产生更好且更一致的性能。我们的分析表明，mLAMA偏向于来自西方国家的事实，这可能影响探测模型的公平性。我们提出了一个新的框架，用于筛选来自Wikidata的具有文化多样性的事实三元组。由三对对比文化的实际三元组组成一个新的基准数据集DLAMA-v1，共有20个关系谓词的78259个三元组。这三对包括代表（阿拉伯和西方）、（亚洲和西方）以及（南美洲和西方）的事实。",
    "tldr": "提出了一个新的框架DLAMA-v1，用于筛选来自不同文化背景的事实三元组，解决在多语言模型上使用英语提示更具有一致性的问题。",
    "en_tdlr": "DLAMA-v1 is a framework that addresses the issue of inconsistent performance of multilingual models when using non-English prompts, by curating diverse factual triples from three pairs of contrasting cultures."
}