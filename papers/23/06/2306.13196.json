{
    "title": "DiMSam: Diffusion Models as Samplers for Task and Motion Planning under Partial Observability. (arXiv:2306.13196v1 [cs.RO])",
    "abstract": "Task and Motion Planning (TAMP) approaches are effective at planning long-horizon autonomous robot manipulation. However, because they require a planning model, it can be difficult to apply them to domains where the environment and its dynamics are not fully known. We propose to overcome these limitations by leveraging deep generative modeling, specifically diffusion models, to learn constraints and samplers that capture these difficult-to-engineer aspects of the planning model. These learned samplers are composed and combined within a TAMP solver in order to find action parameter values jointly that satisfy the constraints along a plan. To tractably make predictions for unseen objects in the environment, we define these samplers on low-dimensional learned latent embeddings of changing object state. We evaluate our approach in an articulated object manipulation domain and show how the combination of classical TAMP, generative learning, and latent embeddings enables long-horizon constra",
    "link": "http://arxiv.org/abs/2306.13196",
    "context": "Title: DiMSam: Diffusion Models as Samplers for Task and Motion Planning under Partial Observability. (arXiv:2306.13196v1 [cs.RO])\nAbstract: Task and Motion Planning (TAMP) approaches are effective at planning long-horizon autonomous robot manipulation. However, because they require a planning model, it can be difficult to apply them to domains where the environment and its dynamics are not fully known. We propose to overcome these limitations by leveraging deep generative modeling, specifically diffusion models, to learn constraints and samplers that capture these difficult-to-engineer aspects of the planning model. These learned samplers are composed and combined within a TAMP solver in order to find action parameter values jointly that satisfy the constraints along a plan. To tractably make predictions for unseen objects in the environment, we define these samplers on low-dimensional learned latent embeddings of changing object state. We evaluate our approach in an articulated object manipulation domain and show how the combination of classical TAMP, generative learning, and latent embeddings enables long-horizon constra",
    "path": "papers/23/06/2306.13196.json",
    "total_tokens": 877,
    "translated_title": "DiMSam:扩散模型作为部分可观测任务与动作规划中的采样器。",
    "translated_abstract": "任务和动作规划（TAMP）方法非常有效地计划长周期自主机器人操作。但是，由于它们需要一个规划模型，因此在环境和其动态不完全了解的领域中应用它们可能非常困难。我们提出通过利用深度生成建模，特别是扩散模型来克服这些限制，学习捕获规划模型中难以设计的约束和采样器。这些学习采样器在TAMP求解器中组合和合并，以联合找到满足规划中约束的行动参数值。为了便于对环境中未知对象进行预测，我们将这些采样器定义为学习的低维潜变量嵌入的可变对象状态。我们在关节式物体操作领域评估了我们的方法，并展示了经典TAMP、生成学习和潜在嵌入的组合如何使得在部分可观测下进行长周期受约束的操作计划。",
    "tldr": "本文提出了一种使用扩散模型作为采样器的任务和动作规划方法，在部分可观测下能够实现长周期受约束的操作计划。",
    "en_tdlr": "This paper proposes a task and motion planning approach using diffusion models as samplers, which can realize long-horizon constrained manipulation planning under partial observability."
}