{
    "title": "Verifying Safety of Neural Networks from Topological Perspectives. (arXiv:2306.15403v1 [cs.LG])",
    "abstract": "Neural networks (NNs) are increasingly applied in safety-critical systems such as autonomous vehicles. However, they are fragile and are often ill-behaved. Consequently, their behaviors should undergo rigorous guarantees before deployment in practice. In this paper, we propose a set-boundary reachability method to investigate the safety verification problem of NNs from a topological perspective. Given an NN with an input set and a safe set, the safety verification problem is to determine whether all outputs of the NN resulting from the input set fall within the safe set. In our method, the homeomorphism property and the open map property of NNs are mainly exploited, which establish rigorous guarantees between the boundaries of the input set and the boundaries of the output set. The exploitation of these two properties facilitates reachability computations via extracting subsets of the input set rather than the entire input set, thus controlling the wrapping effect in reachability analy",
    "link": "http://arxiv.org/abs/2306.15403",
    "context": "Title: Verifying Safety of Neural Networks from Topological Perspectives. (arXiv:2306.15403v1 [cs.LG])\nAbstract: Neural networks (NNs) are increasingly applied in safety-critical systems such as autonomous vehicles. However, they are fragile and are often ill-behaved. Consequently, their behaviors should undergo rigorous guarantees before deployment in practice. In this paper, we propose a set-boundary reachability method to investigate the safety verification problem of NNs from a topological perspective. Given an NN with an input set and a safe set, the safety verification problem is to determine whether all outputs of the NN resulting from the input set fall within the safe set. In our method, the homeomorphism property and the open map property of NNs are mainly exploited, which establish rigorous guarantees between the boundaries of the input set and the boundaries of the output set. The exploitation of these two properties facilitates reachability computations via extracting subsets of the input set rather than the entire input set, thus controlling the wrapping effect in reachability analy",
    "path": "papers/23/06/2306.15403.json",
    "total_tokens": 878,
    "translated_title": "从拓扑角度验证神经网络的安全性",
    "translated_abstract": "神经网络越来越多地应用于自动驾驶等安全关键系统中，然而它们易受损并且常常表现不良。因此，在实际部署之前，它们的行为应该经过严格的保证。在本文中，我们提出了一种从拓扑角度研究神经网络安全验证问题的集边界可达性方法。给定一个具有输入集和安全集的神经网络，安全验证问题是确定所有来自输入集的神经网络输出是否落在安全集中。在我们的方法中，主要利用了神经网络的同胚性质和开映射性质，这些性质在输入集的边界和输出集的边界之间建立了严格的保证。利用这两个性质可以通过提取输入集的子集而不是整个输入集来进行可达性计算，从而控制可达性分析中的包裹效应。",
    "tldr": "本研究提出了一种从拓扑角度研究神经网络安全性的方法，利用神经网络的同胚性质和开映射性质建立了输入集和输出集之间的严格保证，从而解决了神经网络在安全验证中的不确定性问题。",
    "en_tdlr": "This study proposes a method to verify the safety of neural networks from a topological perspective, exploiting the homeomorphism and open map properties to establish rigorous guarantees between the input and output sets, addressing the uncertainty issue in safety verification of neural networks."
}