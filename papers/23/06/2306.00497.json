{
    "title": "The Risks of Recourse in Binary Classification. (arXiv:2306.00497v1 [cs.LG])",
    "abstract": "Algorithmic recourse provides explanations that help users overturn an unfavorable decision by a machine learning system. But so far very little attention has been paid to whether providing recourse is beneficial or not. We introduce an abstract learning-theoretic framework that compares the risks (i.e. expected losses) for classification with and without algorithmic recourse. This allows us to answer the question of when providing recourse is beneficial or harmful at the population level. Surprisingly, we find that there are many plausible scenarios in which providing recourse turns out to be harmful, because it pushes users to regions of higher class uncertainty and therefore leads to more mistakes. We further study whether the party deploying the classifier has an incentive to strategize in anticipation of having to provide recourse, and we find that sometimes they do, to the detriment of their users. Providing algorithmic recourse may therefore also be harmful at the systemic level",
    "link": "http://arxiv.org/abs/2306.00497",
    "context": "Title: The Risks of Recourse in Binary Classification. (arXiv:2306.00497v1 [cs.LG])\nAbstract: Algorithmic recourse provides explanations that help users overturn an unfavorable decision by a machine learning system. But so far very little attention has been paid to whether providing recourse is beneficial or not. We introduce an abstract learning-theoretic framework that compares the risks (i.e. expected losses) for classification with and without algorithmic recourse. This allows us to answer the question of when providing recourse is beneficial or harmful at the population level. Surprisingly, we find that there are many plausible scenarios in which providing recourse turns out to be harmful, because it pushes users to regions of higher class uncertainty and therefore leads to more mistakes. We further study whether the party deploying the classifier has an incentive to strategize in anticipation of having to provide recourse, and we find that sometimes they do, to the detriment of their users. Providing algorithmic recourse may therefore also be harmful at the systemic level",
    "path": "papers/23/06/2306.00497.json",
    "total_tokens": 838,
    "translated_title": "二分分类中追索权的风险",
    "translated_abstract": "算法追索权提供解释，以帮助用户推翻机器学习系统的不利决策。但到目前为止，很少有人关注提供追索权是否有益。我们引入了一个抽象的学习理论框架，比较了具有和没有算法追索权的分类的风险（即期望损失）。这使我们能够回答在整个人群水平上提供追索权何时有益或有害的问题。令人惊讶的是，我们发现在许多可信的情况下，提供追索权反而会有害，因为它将用户推向更高类别不确定性的区域，因此会导致更多的错误。我们进一步研究了部署分类器的一方是否有动机针对提供追索权的情况进行策略规划，我们发现有时候确实存在这种现象，这对他们的用户不利。因此，提供算法追索权在系统级别上可能也是有害的。",
    "tldr": "研究发现，在二分分类中提供追索权会增加错误率，导致更多错误的发生。提供算法追索权可能也会在系统级别上给予不利。",
    "en_tdlr": "Providing recourse in binary classification may result in higher error rate and be harmful at the systemic level, according to the research findings."
}