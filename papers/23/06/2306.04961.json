{
    "title": "Recovering Simultaneously Structured Data via Non-Convex Iteratively Reweighted Least Squares. (arXiv:2306.04961v1 [cs.LG])",
    "abstract": "We propose a new algorithm for the problem of recovering data that adheres to multiple, heterogeneous low-dimensional structures from linear observations. Focusing on data matrices that are simultaneously row-sparse and low-rank, we propose and analyze an iteratively reweighted least squares (IRLS) algorithm that is able to leverage both structures. In particular, it optimizes a combination of non-convex surrogates for row-sparsity and rank, a balancing of which is built into the algorithm. We prove locally quadratic convergence of the iterates to a simultaneously structured data matrix in a regime of minimal sample complexity (up to constants and a logarithmic factor), which is known to be impossible for a combination of convex surrogates. In experiments, we show that the IRLS method exhibits favorable empirical convergence, identifying simultaneously row-sparse and low-rank matrices from fewer measurements than state-of-the-art methods.",
    "link": "http://arxiv.org/abs/2306.04961",
    "context": "Title: Recovering Simultaneously Structured Data via Non-Convex Iteratively Reweighted Least Squares. (arXiv:2306.04961v1 [cs.LG])\nAbstract: We propose a new algorithm for the problem of recovering data that adheres to multiple, heterogeneous low-dimensional structures from linear observations. Focusing on data matrices that are simultaneously row-sparse and low-rank, we propose and analyze an iteratively reweighted least squares (IRLS) algorithm that is able to leverage both structures. In particular, it optimizes a combination of non-convex surrogates for row-sparsity and rank, a balancing of which is built into the algorithm. We prove locally quadratic convergence of the iterates to a simultaneously structured data matrix in a regime of minimal sample complexity (up to constants and a logarithmic factor), which is known to be impossible for a combination of convex surrogates. In experiments, we show that the IRLS method exhibits favorable empirical convergence, identifying simultaneously row-sparse and low-rank matrices from fewer measurements than state-of-the-art methods.",
    "path": "papers/23/06/2306.04961.json",
    "total_tokens": 959,
    "translated_title": "通过非凸迭代加权最小二乘法同时恢复结构化数据",
    "translated_abstract": "我们提出了一种新的算法，用于从线性观测中恢复遵循多个异构低维结构的数据。针对同时行稀疏和低秩的数据矩阵，我们提出并分析了一种迭代加权最小二乘（IRLS）算法，能够利用这两种结构。特别地，它优化了一种非凸稀疏性和秩的组合代理，其中平衡被建入到算法中。我们证明了在最小样本复杂度的情况下（最多常数和一个对数因子），迭代方式局部二次收敛到同时结构化数据矩阵，这对于组合凸代理而言是不可能的。在实验中，我们展示了IRLS方法表现出了有利的经验收敛性，从比最先进的方法更少的测量中确定了同时行稀疏和低秩矩阵。",
    "tldr": "该论文提出了一种非凸迭代加权最小二乘法用于同时恢复行稀疏和低秩的数据矩阵，能够在最小样本复杂度的情况下局部二次收敛到同时结构化的数据矩阵，并在实验中表现出有利的经验收敛性。",
    "en_tdlr": "This paper proposes a new non-convex iteratively reweighted least squares algorithm for recovering simultaneously row-sparse and low-rank data matrices from linear observations. The algorithm optimizes a combination of non-convex surrogates for row-sparsity and rank, and achieves locally quadratic convergence to simultaneously structured data matrix in a regime of minimal sample complexity. The proposed IRLS method shows favorable empirical convergence, outperforming state-of-the-art methods in identifying simultaneously row-sparse and low-rank matrices from fewer measurements."
}