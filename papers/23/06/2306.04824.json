{
    "title": "Sparse Linear Centroid-Encoder: A Convex Method for Feature Selection. (arXiv:2306.04824v1 [cs.LG])",
    "abstract": "We present a novel feature selection technique, Sparse Linear Centroid-Encoder (SLCE). The algorithm uses a linear transformation to reconstruct a point as its class centroid and, at the same time, uses the $\\ell_1$-norm penalty to filter out unnecessary features from the input data. The original formulation of the optimization problem is nonconvex, but we propose a two-step approach, where each step is convex. In the first step, we solve the linear Centroid-Encoder, a convex optimization problem over a matrix $A$. In the second step, we only search for a sparse solution over a diagonal matrix $B$ while keeping $A$ fixed. Unlike other linear methods, e.g., Sparse Support Vector Machines and Lasso, Sparse Linear Centroid-Encoder uses a single model for multi-class data. We present an in-depth empirical analysis of the proposed model and show that it promotes sparsity on various data sets, including high-dimensional biological data. Our experimental results show that SLCE has a performan",
    "link": "http://arxiv.org/abs/2306.04824",
    "context": "Title: Sparse Linear Centroid-Encoder: A Convex Method for Feature Selection. (arXiv:2306.04824v1 [cs.LG])\nAbstract: We present a novel feature selection technique, Sparse Linear Centroid-Encoder (SLCE). The algorithm uses a linear transformation to reconstruct a point as its class centroid and, at the same time, uses the $\\ell_1$-norm penalty to filter out unnecessary features from the input data. The original formulation of the optimization problem is nonconvex, but we propose a two-step approach, where each step is convex. In the first step, we solve the linear Centroid-Encoder, a convex optimization problem over a matrix $A$. In the second step, we only search for a sparse solution over a diagonal matrix $B$ while keeping $A$ fixed. Unlike other linear methods, e.g., Sparse Support Vector Machines and Lasso, Sparse Linear Centroid-Encoder uses a single model for multi-class data. We present an in-depth empirical analysis of the proposed model and show that it promotes sparsity on various data sets, including high-dimensional biological data. Our experimental results show that SLCE has a performan",
    "path": "papers/23/06/2306.04824.json",
    "total_tokens": 1032,
    "translated_title": "稀疏线性质心编码器：一种特征选择的凸方法",
    "translated_abstract": "我们提出了一种新的特征选择技术，称为稀疏线性质心编码器（SLCE）。该算法使用一个线性变换将一个点重构为其类别的质心，并同时使用$\\ell_1$范数惩罚从输入数据中滤除不必要的特征。优化问题的原始公式是非凸的，但我们提出了一个两步法，其中每一步都是凸的。在第一步中，我们解决线性质心编码器，它是一个矩阵$A$上的凸优化问题。在第二步中，我们只在对角线矩阵$B$上搜索稀疏解，同时保持$A$不变。与其他线性方法（例如稀疏支持向量机和Lasso）不同，稀疏线性质心编码器对于多类数据使用单个模型。我们对所提出的模型进行了深入的实证分析，并表明它促进了各种数据集（包括高维生物数据）上的稀疏性。我们的实验结果表明，SLCE在分类准确率方面具有与最先进方法相当的性能，同时具有显着较少的特征数。",
    "tldr": "SLCE是用线性变换将点重构为类别质心并使用$\\ell_1$范数惩罚从输入数据中滤除不必要特征的特征选择新方法。该方法为多类数据使用单个模型，具有与最先进方法相当的性能，同时具有显着较少的特征数。",
    "en_tdlr": "SLCE is a novel feature selection technique that reconstructs a point as its class centroid through linear transformation and filters out unnecessary features from input data using $\\ell_1$-norm penalty. It uses a single model for multi-class data, and has comparable performance to state-of-the-art methods in terms of classification accuracy with significantly smaller number of features."
}