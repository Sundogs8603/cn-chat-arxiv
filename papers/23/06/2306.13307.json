{
    "title": "Towards Effective and Compact Contextual Representation for Conformer Transducer Speech Recognition Systems. (arXiv:2306.13307v1 [eess.AS])",
    "abstract": "Current ASR systems are mainly trained and evaluated at the utterance level. Long range cross utterance context can be incorporated. A key task is to derive a suitable compact representation of the most relevant history contexts. In contrast to previous researches based on either LSTM-RNN encoded histories that attenuate the information from longer range contexts, or frame level concatenation of transformer context embeddings, in this paper compact low-dimensional cross utterance contextual features are learned in the Conformer-Transducer Encoder using specially designed attention pooling layers that are applied over efficiently cached preceding utterances history vectors. Experiments on the 1000-hr Gigaspeech corpus demonstrate that the proposed contextualized streaming Conformer-Transducers outperform the baseline using utterance internal context only with statistically significant WER reductions of 0.7% to 0.5% absolute (4.3% to 3.1% relative) on the dev and test data.",
    "link": "http://arxiv.org/abs/2306.13307",
    "context": "Title: Towards Effective and Compact Contextual Representation for Conformer Transducer Speech Recognition Systems. (arXiv:2306.13307v1 [eess.AS])\nAbstract: Current ASR systems are mainly trained and evaluated at the utterance level. Long range cross utterance context can be incorporated. A key task is to derive a suitable compact representation of the most relevant history contexts. In contrast to previous researches based on either LSTM-RNN encoded histories that attenuate the information from longer range contexts, or frame level concatenation of transformer context embeddings, in this paper compact low-dimensional cross utterance contextual features are learned in the Conformer-Transducer Encoder using specially designed attention pooling layers that are applied over efficiently cached preceding utterances history vectors. Experiments on the 1000-hr Gigaspeech corpus demonstrate that the proposed contextualized streaming Conformer-Transducers outperform the baseline using utterance internal context only with statistically significant WER reductions of 0.7% to 0.5% absolute (4.3% to 3.1% relative) on the dev and test data.",
    "path": "papers/23/06/2306.13307.json",
    "total_tokens": 829,
    "translated_title": "为Conformer Transducer语音识别系统建立高效紧凑的上下文表示",
    "translated_abstract": "当前的自动语音识别系统主要在话语级别进行训练和评估。可以纳入长范围的跨话语上下文信息。本文提出，在Conformer-Transducer编码器中使用特殊设计的注意力汇聚层，通过高效缓存的前面话语历史向量，学习了紧凑的低维跨话语上下文特征。在1000小时的Gigaspeech语料库上的实验表明，所提出的上下文化流Conformer-Transducer在开发和测试数据上都比仅使用话语内部上下文的基线模型具有显著的字错率降低（0.7％到0.5％绝对，4.3％到3.1％相对）。",
    "tldr": "本研究旨在为Conformer Transducer语音识别系统建立高效紧凑的上下文表示，通过特定的注意力汇聚层实现跨话语的信息集成，取得了显著的性能提升。",
    "en_tdlr": "This paper aims to establish an efficient and compact contextual representation for Conformer Transducer speech recognition systems. By using specially designed attention pooling layers, the model integrates cross-utterance information and achieves significant performance improvement over the baseline model using only the internal context of utterances."
}