{
    "title": "SARC: Soft Actor Retrospective Critic. (arXiv:2306.16503v1 [cs.LG])",
    "abstract": "The two-time scale nature of SAC, which is an actor-critic algorithm, is characterised by the fact that the critic estimate has not converged for the actor at any given time, but since the critic learns faster than the actor, it ensures eventual consistency between the two. Various strategies have been introduced in literature to learn better gradient estimates to help achieve better convergence. Since gradient estimates depend upon the critic, we posit that improving the critic can provide a better gradient estimate for the actor at each time. Utilizing this, we propose Soft Actor Retrospective Critic (SARC), where we augment the SAC critic loss with another loss term retrospective loss - leading to faster critic convergence and consequently, better policy gradient estimates for the actor. An existing implementation of SAC can be easily adapted to SARC with minimal modifications. Through extensive experimentation and analysis, we show that SARC provides consistent improvement over S",
    "link": "http://arxiv.org/abs/2306.16503",
    "context": "Title: SARC: Soft Actor Retrospective Critic. (arXiv:2306.16503v1 [cs.LG])\nAbstract: The two-time scale nature of SAC, which is an actor-critic algorithm, is characterised by the fact that the critic estimate has not converged for the actor at any given time, but since the critic learns faster than the actor, it ensures eventual consistency between the two. Various strategies have been introduced in literature to learn better gradient estimates to help achieve better convergence. Since gradient estimates depend upon the critic, we posit that improving the critic can provide a better gradient estimate for the actor at each time. Utilizing this, we propose Soft Actor Retrospective Critic (SARC), where we augment the SAC critic loss with another loss term retrospective loss - leading to faster critic convergence and consequently, better policy gradient estimates for the actor. An existing implementation of SAC can be easily adapted to SARC with minimal modifications. Through extensive experimentation and analysis, we show that SARC provides consistent improvement over S",
    "path": "papers/23/06/2306.16503.json",
    "total_tokens": 848,
    "translated_title": "SARC: 软参演者回顾评论者",
    "translated_abstract": "SAC是一个演员评论者算法，其两个时间尺度的特性在于评论者估计在任何给定时间都没有收敛于演员，但由于评论者学习速度比演员快，它确保了两者之间的最终一致性。文献中引入了各种策略来学习更好的梯度估计，以帮助实现更好的收敛性。由于梯度估计依赖于评论者，我们认为改进评论者可以为每个时间点的演员提供更好的梯度估计。基于此，我们提出了软参演者回顾评论者(SARC)，其中我们将SAC评论者损失与另一个损失项回顾损失相结合 - 实现了更快的评论者收敛和更好的演员策略梯度估计。现有的SAC实现可以很容易地适应SARC，只需进行微小的修改。通过大量的实验和分析，我们展示了SARC相比S的一致改进。",
    "tldr": "SARC是一个基于SAC算法的新方法，通过改进评论者实现更好的收敛性和梯度估计，为演员提供了更好的策略梯度估计。"
}