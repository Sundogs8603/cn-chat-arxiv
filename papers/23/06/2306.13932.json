{
    "title": "Tuning structure learning algorithms with out-of-sample and resampling strategies. (arXiv:2306.13932v1 [cs.LG])",
    "abstract": "One of the challenges practitioners face when applying structure learning algorithms to their data involves determining a set of hyperparameters; otherwise, a set of hyperparameter defaults is assumed. The optimal hyperparameter configuration often depends on multiple factors, including the size and density of the usually unknown underlying true graph, the sample size of the input data, and the structure learning algorithm. We propose a novel hyperparameter tuning method, called the Out-of-sample Tuning for Structure Learning (OTSL), that employs out-of-sample and resampling strategies to estimate the optimal hyperparameter configuration for structure learning, given the input data set and structure learning algorithm. Synthetic experiments show that employing OTSL as a means to tune the hyperparameters of hybrid and score-based structure learning algorithms leads to improvements in graphical accuracy compared to the state-of-the-art. We also illustrate the applicability of this approa",
    "link": "http://arxiv.org/abs/2306.13932",
    "context": "Title: Tuning structure learning algorithms with out-of-sample and resampling strategies. (arXiv:2306.13932v1 [cs.LG])\nAbstract: One of the challenges practitioners face when applying structure learning algorithms to their data involves determining a set of hyperparameters; otherwise, a set of hyperparameter defaults is assumed. The optimal hyperparameter configuration often depends on multiple factors, including the size and density of the usually unknown underlying true graph, the sample size of the input data, and the structure learning algorithm. We propose a novel hyperparameter tuning method, called the Out-of-sample Tuning for Structure Learning (OTSL), that employs out-of-sample and resampling strategies to estimate the optimal hyperparameter configuration for structure learning, given the input data set and structure learning algorithm. Synthetic experiments show that employing OTSL as a means to tune the hyperparameters of hybrid and score-based structure learning algorithms leads to improvements in graphical accuracy compared to the state-of-the-art. We also illustrate the applicability of this approa",
    "path": "papers/23/06/2306.13932.json",
    "total_tokens": 897,
    "translated_title": "利用外样本和重抽样策略优化结构学习算法的超参数调整方法",
    "translated_abstract": "当实践者将结构学习算法应用于其数据时，面临的挑战之一是确定一组超参数；否则，假定一组超参数默认值。最佳超参数配置常常取决于多种因素，包括通常未知的真实底层图的大小和密度、输入数据的样本大小和结构学习算法等。我们提出了一种新的超参数调整方法，名为Out-of-sample Tuning for Structure Learning（OTSL），它采用外样本和重抽样策略来估算给定输入数据集和结构学习算法的最佳超参数配置。合成实验表明，使用OTSL作为混合和基于分数的结构学习算法的超参数调整手段，相对于现有技术，能够提高图形准确性。我们还演示了该方法在几个真实数据集中的适用性。",
    "tldr": "本文提出了一种新的超参数调整方法 OTSL，它采用外样本和重抽样策略来估算给定输入数据集和结构学习算法的最佳超参数配置。实验表明，该方法优于现有技术，可提高结构学习算法的图形准确性。",
    "en_tdlr": "The paper proposes a novel hyperparameter tuning method, called Out-of-sample Tuning for Structure Learning (OTSL), employing out-of-sample and resampling strategies to estimate the optimal hyperparameter configuration. Synthetic experiments show that employing OTSL to tune the hyperparameters of hybrid and score-based structure learning algorithms leads to improvements in graphical accuracy compared to the state-of-the-art."
}