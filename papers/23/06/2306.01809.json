{
    "title": "Adversarial Attack Based on Prediction-Correction. (arXiv:2306.01809v1 [cs.CR])",
    "abstract": "Deep neural networks (DNNs) are vulnerable to adversarial examples obtained by adding small perturbations to original examples. The added perturbations in existing attacks are mainly determined by the gradient of the loss function with respect to the inputs. In this paper, the close relationship between gradient-based attacks and the numerical methods for solving ordinary differential equation (ODE) is studied for the first time. Inspired by the numerical solution of ODE, a new prediction-correction (PC) based adversarial attack is proposed. In our proposed PC-based attack, some existing attack can be selected to produce a predicted example first, and then the predicted example and the current example are combined together to determine the added perturbations. The proposed method possesses good extensibility and can be applied to all available gradient-based attacks easily. Extensive experiments demonstrate that compared with the state-of-the-art gradient-based adversarial attacks, our",
    "link": "http://arxiv.org/abs/2306.01809",
    "context": "Title: Adversarial Attack Based on Prediction-Correction. (arXiv:2306.01809v1 [cs.CR])\nAbstract: Deep neural networks (DNNs) are vulnerable to adversarial examples obtained by adding small perturbations to original examples. The added perturbations in existing attacks are mainly determined by the gradient of the loss function with respect to the inputs. In this paper, the close relationship between gradient-based attacks and the numerical methods for solving ordinary differential equation (ODE) is studied for the first time. Inspired by the numerical solution of ODE, a new prediction-correction (PC) based adversarial attack is proposed. In our proposed PC-based attack, some existing attack can be selected to produce a predicted example first, and then the predicted example and the current example are combined together to determine the added perturbations. The proposed method possesses good extensibility and can be applied to all available gradient-based attacks easily. Extensive experiments demonstrate that compared with the state-of-the-art gradient-based adversarial attacks, our",
    "path": "papers/23/06/2306.01809.json",
    "total_tokens": 855,
    "translated_title": "基于预测-校正的对抗攻击",
    "translated_abstract": "深度神经网络(DNNs)容易受到对抗样本的攻击，攻击者将微小的扰动添加到原本的样本中。现有攻击方法中，添加的扰动主要由损失函数对输入的梯度决定。本文首次研究了梯度攻击与求解普通微分方程 (ODE) 数值方法之间的密切关系。受ODE数值解的启发，提出了基于预测-校正(PC)的新型对抗攻击。在我们提出的PC-based攻击中，可以先选择一些现有的攻击方法生成一个预测的样本，然后将预测样本和当前样本组合在一起，以确定所添加的扰动。所提出的方法具有良好的可扩展性，能够轻松应用于所有可用的梯度攻击。广泛的实验证明，与最先进的梯度对抗攻击相比，我们的方法可以更有效地比较进行压缩和加速计算。",
    "tldr": "本论文介绍了一种基于预测-校正的对抗攻击方法，该方法能够有效对抗深度神经网络中的梯度攻击，并具有较好的可扩展性。",
    "en_tdlr": "This paper introduces a prediction-correction based adversarial attack method that can effectively counter gradient-based attacks in deep neural networks and has good scalability."
}