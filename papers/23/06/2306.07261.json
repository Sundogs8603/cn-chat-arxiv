{
    "title": "Unprocessing Seven Years of Algorithmic Fairness. (arXiv:2306.07261v2 [cs.LG] UPDATED)",
    "abstract": "Seven years ago, researchers proposed a postprocessing method to equalize the error rates of a model across different demographic groups. The work launched hundreds of papers purporting to improve over the postprocessing baseline. We empirically evaluate these claims through thousands of model evaluations on several tabular datasets. We find that the fairness-accuracy Pareto frontier achieved by postprocessing contains all other methods we were feasibly able to evaluate. In doing so, we address two common methodological errors that have confounded previous observations. One relates to the comparison of methods with different unconstrained base models. The other concerns methods achieving different levels of constraint relaxation. At the heart of our study is a simple idea we call unprocessing that roughly corresponds to the inverse of postprocessing. Unprocessing allows for a direct comparison of methods using different underlying models and levels of relaxation. Interpreting our findi",
    "link": "http://arxiv.org/abs/2306.07261",
    "context": "Title: Unprocessing Seven Years of Algorithmic Fairness. (arXiv:2306.07261v2 [cs.LG] UPDATED)\nAbstract: Seven years ago, researchers proposed a postprocessing method to equalize the error rates of a model across different demographic groups. The work launched hundreds of papers purporting to improve over the postprocessing baseline. We empirically evaluate these claims through thousands of model evaluations on several tabular datasets. We find that the fairness-accuracy Pareto frontier achieved by postprocessing contains all other methods we were feasibly able to evaluate. In doing so, we address two common methodological errors that have confounded previous observations. One relates to the comparison of methods with different unconstrained base models. The other concerns methods achieving different levels of constraint relaxation. At the heart of our study is a simple idea we call unprocessing that roughly corresponds to the inverse of postprocessing. Unprocessing allows for a direct comparison of methods using different underlying models and levels of relaxation. Interpreting our findi",
    "path": "papers/23/06/2306.07261.json",
    "total_tokens": 831,
    "translated_title": "取消七年的算法公平性后处理",
    "translated_abstract": "七年前，研究人员提出了一种后处理方法，以使模型在不同人口群体中的误差率相等。这项工作启动了数百篇论文，声称能够改进后处理基线。我们通过对几个表格数据集上数千个模型评估的实证评估来评估这些声明。我们发现，后处理实现的公平性-准确性Pareto边界包含我们可以评估的所有其他方法。这样做，我们解决了两个常见的方法论错误，这些错误困扰了以前的观察结果。一个与使用不同的无约束基础模型比较方法有关。另一个涉及实现不同的约束放松水平的方法。我们研究的核心是一种简单的想法，我们称之为取消处理，大致对应于后处理的反演。取消处理允许直接比较使用不同基础模型和放松级别的方法。解读我们的发现。",
    "tldr": "该论文取消了算法公平性中的后处理方法，并发现后处理实现的公平性-准确性Pareto边界包含了可评估的所有其他方法。",
    "en_tdlr": "This paper unprocesses algorithmic fairness by canceling the postprocessing method and finds that the fairness-accuracy Pareto frontier achieved by postprocessing contains all other feasibly evaluatable methods."
}