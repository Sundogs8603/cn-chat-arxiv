{
    "title": "Adversarial Training for Graph Neural Networks. (arXiv:2306.15427v1 [cs.LG])",
    "abstract": "Despite its success in the image domain, adversarial training does not (yet) stand out as an effective defense for Graph Neural Networks (GNNs) against graph structure perturbations. In the pursuit of fixing adversarial training (1) we show and overcome fundamental theoretical as well as practical limitations of the adopted graph learning setting in prior work; (2) we reveal that more flexible GNNs based on learnable graph diffusion are able to adjust to adversarial perturbations, while the learned message passing scheme is naturally interpretable; (3) we introduce the first attack for structure perturbations that, while targeting multiple nodes at once, is capable of handling global (graph-level) as well as local (node-level) constraints. Including these contributions, we demonstrate that adversarial training is a state-of-the-art defense against adversarial structure perturbations.",
    "link": "http://arxiv.org/abs/2306.15427",
    "context": "Title: Adversarial Training for Graph Neural Networks. (arXiv:2306.15427v1 [cs.LG])\nAbstract: Despite its success in the image domain, adversarial training does not (yet) stand out as an effective defense for Graph Neural Networks (GNNs) against graph structure perturbations. In the pursuit of fixing adversarial training (1) we show and overcome fundamental theoretical as well as practical limitations of the adopted graph learning setting in prior work; (2) we reveal that more flexible GNNs based on learnable graph diffusion are able to adjust to adversarial perturbations, while the learned message passing scheme is naturally interpretable; (3) we introduce the first attack for structure perturbations that, while targeting multiple nodes at once, is capable of handling global (graph-level) as well as local (node-level) constraints. Including these contributions, we demonstrate that adversarial training is a state-of-the-art defense against adversarial structure perturbations.",
    "path": "papers/23/06/2306.15427.json",
    "total_tokens": 841,
    "translated_title": "针对图神经网络的对抗训练",
    "translated_abstract": "尽管在图像领域取得了成功，但对抗训练在图神经网络（GNNs）对抗图结构扰动方面并没有明显效果。在修复对抗训练的过程中，我们发现并克服了之前工作中采用的图学习设置的基本理论和实际限制；我们揭示了基于可学习图扩散的更灵活 GNNs 能够适应对抗扰动，同时学习到的消息传递方案具有自然的可解释性；我们还引入了第一种针对结构扰动的攻击方法，能够同时对多个节点进行攻击，并能处理全局（图级别）和局部（节点级别）的约束。通过这些贡献，我们证明对抗训练是对抗结构扰动的最先进防御方法。",
    "tldr": "该论文通过克服图学习设置的限制，引入可学习图扩散的灵活GNNs以及针对结构扰动的攻击方法，证明了对抗训练是针对对抗结构扰动的最先进防御方法。",
    "en_tdlr": "This paper demonstrates that adversarial training is a state-of-the-art defense against adversarial structure perturbations by overcoming limitations in graph learning settings, introducing flexible GNNs based on learnable graph diffusion, and presenting an attack method for structure perturbations."
}