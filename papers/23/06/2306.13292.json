{
    "title": "Variance-Covariance Regularization Improves Representation Learning. (arXiv:2306.13292v1 [cs.LG])",
    "abstract": "Transfer learning has emerged as a key approach in the machine learning domain, enabling the application of knowledge derived from one domain to improve performance on subsequent tasks. Given the often limited information about these subsequent tasks, a strong transfer learning approach calls for the model to capture a diverse range of features during the initial pretraining stage. However, recent research suggests that, without sufficient regularization, the network tends to concentrate on features that primarily reduce the pretraining loss function. This tendency can result in inadequate feature learning and impaired generalization capability for target tasks. To address this issue, we propose Variance-Covariance Regularization (VCR), a regularization technique aimed at fostering diversity in the learned network features. Drawing inspiration from recent advancements in the self-supervised learning approach, our approach promotes learned representations that exhibit high variance and ",
    "link": "http://arxiv.org/abs/2306.13292",
    "context": "Title: Variance-Covariance Regularization Improves Representation Learning. (arXiv:2306.13292v1 [cs.LG])\nAbstract: Transfer learning has emerged as a key approach in the machine learning domain, enabling the application of knowledge derived from one domain to improve performance on subsequent tasks. Given the often limited information about these subsequent tasks, a strong transfer learning approach calls for the model to capture a diverse range of features during the initial pretraining stage. However, recent research suggests that, without sufficient regularization, the network tends to concentrate on features that primarily reduce the pretraining loss function. This tendency can result in inadequate feature learning and impaired generalization capability for target tasks. To address this issue, we propose Variance-Covariance Regularization (VCR), a regularization technique aimed at fostering diversity in the learned network features. Drawing inspiration from recent advancements in the self-supervised learning approach, our approach promotes learned representations that exhibit high variance and ",
    "path": "papers/23/06/2306.13292.json",
    "total_tokens": 824,
    "translated_title": "方差-协方差正则化改进表示学习",
    "translated_abstract": "迁移学习已成为机器学习领域的一个关键方法，能够将从一个领域获得的知识应用于提高后续任务的性能。然而，缺乏关于这些后续任务的足够信息，强有力的迁移学习方法要求在初始预训练阶段捕获各种特征。然而，最近的研究表明，在没有足够的正则化的情况下，网络往往会集中于主要减少预训练损失函数的特征。这种趋势可能导致不充分的特征学习和目标任务的受损泛化能力。为了解决这个问题，我们提出了方差-协方差正则化（VCR）技术，旨在促进学习网络特征的多样性。借鉴最近自监督学习方法的进展，我们的方法促进了表现出高方差和高相关性的学习表示。",
    "tldr": "提出了方差-协方差正则化方法，旨在促进学习网络特征的多样性，改善表示学习和迁移学习的性能。"
}