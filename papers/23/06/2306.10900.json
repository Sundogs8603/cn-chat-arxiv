{
    "title": "MotionGPT: Finetuned LLMs Are General-Purpose Motion Generators",
    "abstract": "arXiv:2306.10900v2 Announce Type: replace-cross  Abstract: Generating realistic human motion from given action descriptions has experienced significant advancements because of the emerging requirement of digital humans. While recent works have achieved impressive results in generating motion directly from textual action descriptions, they often support only a single modality of the control signal, which limits their application in the real digital human industry. This paper presents a Motion General-Purpose generaTor (MotionGPT) that can use multimodal control signals, e.g., text and single-frame poses, for generating consecutive human motions by treating multimodal signals as special input tokens in large language models (LLMs). Specifically, we first quantize multimodal control signals into discrete codes and then formulate them in a unified prompt instruction to ask the LLMs to generate the motion answer. Our MotionGPT demonstrates a unified human motion generation model with multim",
    "link": "https://arxiv.org/abs/2306.10900",
    "context": "Title: MotionGPT: Finetuned LLMs Are General-Purpose Motion Generators\nAbstract: arXiv:2306.10900v2 Announce Type: replace-cross  Abstract: Generating realistic human motion from given action descriptions has experienced significant advancements because of the emerging requirement of digital humans. While recent works have achieved impressive results in generating motion directly from textual action descriptions, they often support only a single modality of the control signal, which limits their application in the real digital human industry. This paper presents a Motion General-Purpose generaTor (MotionGPT) that can use multimodal control signals, e.g., text and single-frame poses, for generating consecutive human motions by treating multimodal signals as special input tokens in large language models (LLMs). Specifically, we first quantize multimodal control signals into discrete codes and then formulate them in a unified prompt instruction to ask the LLMs to generate the motion answer. Our MotionGPT demonstrates a unified human motion generation model with multim",
    "path": "papers/23/06/2306.10900.json",
    "total_tokens": 788,
    "translated_title": "MotionGPT: 微调的LLM是通用的运动生成器",
    "translated_abstract": "由于数字人类的新兴需求，从给定动作描述生成逼真的人类动作已经取得了显著进展。然而，最近的作品在直接从文本动作描述生成动作方面取得了令人印象深刻的成果，但通常只支持单一控制信号模态，这限制了它们在真实数字人类行业中的应用。本文提出了一种 Motion General-Purpose generaTor (MotionGPT)，它可以使用多模态控制信号（例如文本和单帧姿势）来通过将多模态信号视为大型语言模型（LLMs）中的特殊输入标记，生成连续的人类动作。具体来说，我们首先将多模态控制信号量化为离散码，然后将它们制定为统一的提示指令，要求LLMs生成动作答案。我们的 MotionGPT 展示了一个统一的人类动作生成模型，具有多模态支持。",
    "tldr": "MotionGPT是一款能够利用多模态控制信号生成连续人类动作的通用运动生成器。",
    "en_tdlr": "MotionGPT is a general-purpose motion generator that can utilize multimodal control signals to generate consecutive human motions."
}