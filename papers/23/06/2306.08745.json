{
    "title": "PLAN: Variance-Aware Private Mean Estimation. (arXiv:2306.08745v2 [cs.CR] UPDATED)",
    "abstract": "Differentially private mean estimation is an important building block in privacy-preserving algorithms for data analysis and machine learning. Though the trade-off between privacy and utility is well understood in the worst case, many datasets exhibit structure that could potentially be exploited to yield better algorithms. In this paper we present $\\textit{Private Limit Adapted Noise}$ (PLAN), a family of differentially private algorithms for mean estimation in the setting where inputs are independently sampled from a distribution $\\mathcal{D}$ over $\\mathbf{R}^d$, with coordinate-wise standard deviations $\\boldsymbol{\\sigma} \\in \\mathbf{R}^d$. Similar to mean estimation under Mahalanobis distance, PLAN tailors the shape of the noise to the shape of the data, but unlike previous algorithms the privacy budget is spent non-uniformly over the coordinates. Under a concentration assumption on $\\mathcal{D}$, we show how to exploit skew in the vector $\\boldsymbol{\\sigma}$, obtaining a (zero-",
    "link": "http://arxiv.org/abs/2306.08745",
    "context": "Title: PLAN: Variance-Aware Private Mean Estimation. (arXiv:2306.08745v2 [cs.CR] UPDATED)\nAbstract: Differentially private mean estimation is an important building block in privacy-preserving algorithms for data analysis and machine learning. Though the trade-off between privacy and utility is well understood in the worst case, many datasets exhibit structure that could potentially be exploited to yield better algorithms. In this paper we present $\\textit{Private Limit Adapted Noise}$ (PLAN), a family of differentially private algorithms for mean estimation in the setting where inputs are independently sampled from a distribution $\\mathcal{D}$ over $\\mathbf{R}^d$, with coordinate-wise standard deviations $\\boldsymbol{\\sigma} \\in \\mathbf{R}^d$. Similar to mean estimation under Mahalanobis distance, PLAN tailors the shape of the noise to the shape of the data, but unlike previous algorithms the privacy budget is spent non-uniformly over the coordinates. Under a concentration assumption on $\\mathcal{D}$, we show how to exploit skew in the vector $\\boldsymbol{\\sigma}$, obtaining a (zero-",
    "path": "papers/23/06/2306.08745.json",
    "total_tokens": 1033,
    "translated_title": "PLAN: 方差感知的差分隐私均值估计",
    "translated_abstract": "差分隐私均值估计是数据分析和机器学习中保护隐私的算法的重要组成部分。然而，虽然在最坏情况下隐私和效用之间的权衡已经被很好地理解，但许多数据集展示了可能被利用以产生更好算法的结构。在本文中，我们提出了“隐私限制适应噪声”（PLAN）。PLAN是一组差分隐私算法，用于在独立采样于分布$\\mathcal{D}$的输入的设置中进行均值估计，其中分布的坐标标准差$\\boldsymbol{\\sigma}\\in \\mathbf{R}^d$。与Mahalanobis距离下的均值估计类似，PLAN将噪声的形状量身定制为数据的形状，但与以前的算法不同，隐私预算不是均匀地花费在各个坐标上。在对$\\mathcal{D}$的集中性假设下，我们展示了如何利用向量$\\boldsymbol{\\sigma}$中的偏斜，从而获得接近零平均均方误差（MSE）的估计。",
    "tldr": "本文提出了“隐私限制适应噪声”（PLAN），是一组差分隐私算法，用于在输入的数据集结构中进行更好的均值估计。PLAN将噪声的形状量身定制为数据的形状，不同于以往的均值估计算法，而且可以在一些集中分布的情况下，通过利用标准差的偏斜来获得接近零平均均方误差（MSE）的估计。",
    "en_tdlr": "This paper proposes PLAN, a family of differentially private algorithms for mean estimation, tailored noise shape to data shape, and can achieve almost zero mean square error (MSE) estimation by exploiting the skew of standard deviation under concentration assumption on the distribution."
}