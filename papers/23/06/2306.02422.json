{
    "title": "A Generalized Alternating Method for Bilevel Learning under the Polyak-{\\L}ojasiewicz Condition. (arXiv:2306.02422v2 [math.OC] UPDATED)",
    "abstract": "Bilevel optimization has recently regained interest owing to its applications in emerging machine learning fields such as hyperparameter optimization, meta-learning, and reinforcement learning. Recent results have shown that simple alternating (implicit) gradient-based algorithms can achieve the same convergence rate of single-level gradient descent (GD) for bilevel problems with a strongly convex lower-level objective. However, it remains unclear whether this result can be generalized to bilevel problems beyond this basic setting. In this paper, we propose a Generalized ALternating mEthod for bilevel opTimization (GALET) with a nonconvex lower-level objective that satisfies the Polyak-{\\L}ojasiewicz (PL) condition. We first introduce a stationary metric for the considered bilevel problems, which generalizes the existing metric. We then establish that GALET achieves an $\\epsilon$-stationary metric for the considered problem within $\\tilde{\\cal O}(\\epsilon^{-1})$ iterations, which match",
    "link": "http://arxiv.org/abs/2306.02422",
    "context": "Title: A Generalized Alternating Method for Bilevel Learning under the Polyak-{\\L}ojasiewicz Condition. (arXiv:2306.02422v2 [math.OC] UPDATED)\nAbstract: Bilevel optimization has recently regained interest owing to its applications in emerging machine learning fields such as hyperparameter optimization, meta-learning, and reinforcement learning. Recent results have shown that simple alternating (implicit) gradient-based algorithms can achieve the same convergence rate of single-level gradient descent (GD) for bilevel problems with a strongly convex lower-level objective. However, it remains unclear whether this result can be generalized to bilevel problems beyond this basic setting. In this paper, we propose a Generalized ALternating mEthod for bilevel opTimization (GALET) with a nonconvex lower-level objective that satisfies the Polyak-{\\L}ojasiewicz (PL) condition. We first introduce a stationary metric for the considered bilevel problems, which generalizes the existing metric. We then establish that GALET achieves an $\\epsilon$-stationary metric for the considered problem within $\\tilde{\\cal O}(\\epsilon^{-1})$ iterations, which match",
    "path": "papers/23/06/2306.02422.json",
    "total_tokens": 980,
    "translated_title": "一种基于Polyak-{\\L}ojasiewicz条件的双层学习的广义交替方法",
    "translated_abstract": "双层优化近年来因其在超参数优化、元学习和强化学习等新兴机器学习领域中的应用而重新引起人们的关注。最近的结果显示，对于具有强凸下层目标的双层问题，简单的交替（隐式）基于梯度的算法可以实现与单层梯度下降（GD）相同的收敛速率。然而，对于超出此基本设置的双层问题，尚不清楚是否可以推广该结果。在本文中，我们提出了一种基于满足Polyak-{\\L}ojasiewicz (PL)条件的非凸下层目标的双层优化的广义交替方法（GALET）。我们首先介绍了所考虑的双层问题的一个静态度量，它推广了现有的度量。然后我们证明GALET在$\\tilde{\\cal O}(\\epsilon^{-1})$迭代次数内实现了所考虑问题的$\\epsilon$-静态度量。",
    "tldr": "本研究提出了一种基于Polyak-{\\L}ojasiewicz条件的双层学习的广义交替方法，即GALET，可以用于解决非凸下层目标的双层问题。该方法可以在$\\tilde{\\cal O}(\\epsilon^{-1})$迭代次数内实现问题的$\\epsilon$-静态度量。",
    "en_tdlr": "This paper proposes a generalized alternating method, GALET, for bilevel optimization with a nonconvex lower-level objective that satisfies the Polyak-{\\L}ojasiewicz (PL) condition. The proposed method achieves an $\\epsilon$-stationary metric for the considered problem within $\\tilde{\\cal O}(\\epsilon^{-1})$ iterations."
}