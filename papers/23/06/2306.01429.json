{
    "title": "A Closer Look at the Adversarial Robustness of Deep Equilibrium Models. (arXiv:2306.01429v1 [cs.LG])",
    "abstract": "Deep equilibrium models (DEQs) refrain from the traditional layer-stacking paradigm and turn to find the fixed point of a single layer. DEQs have achieved promising performance on different applications with featured memory efficiency. At the same time, the adversarial vulnerability of DEQs raises concerns. Several works propose to certify robustness for monotone DEQs. However, limited efforts are devoted to studying empirical robustness for general DEQs. To this end, we observe that an adversarially trained DEQ requires more forward steps to arrive at the equilibrium state, or even violates its fixed-point structure. Besides, the forward and backward tracks of DEQs are misaligned due to the black-box solvers. These facts cause gradient obfuscation when applying the ready-made attacks to evaluate or adversarially train DEQs. Given this, we develop approaches to estimate the intermediate gradients of DEQs and integrate them into the attacking pipelines. Our approaches facilitate fully w",
    "link": "http://arxiv.org/abs/2306.01429",
    "context": "Title: A Closer Look at the Adversarial Robustness of Deep Equilibrium Models. (arXiv:2306.01429v1 [cs.LG])\nAbstract: Deep equilibrium models (DEQs) refrain from the traditional layer-stacking paradigm and turn to find the fixed point of a single layer. DEQs have achieved promising performance on different applications with featured memory efficiency. At the same time, the adversarial vulnerability of DEQs raises concerns. Several works propose to certify robustness for monotone DEQs. However, limited efforts are devoted to studying empirical robustness for general DEQs. To this end, we observe that an adversarially trained DEQ requires more forward steps to arrive at the equilibrium state, or even violates its fixed-point structure. Besides, the forward and backward tracks of DEQs are misaligned due to the black-box solvers. These facts cause gradient obfuscation when applying the ready-made attacks to evaluate or adversarially train DEQs. Given this, we develop approaches to estimate the intermediate gradients of DEQs and integrate them into the attacking pipelines. Our approaches facilitate fully w",
    "path": "papers/23/06/2306.01429.json",
    "total_tokens": 900,
    "translated_title": "深度平衡模型的对抗鲁棒性再研究",
    "translated_abstract": "深度平衡模型（DEQ）摒弃了传统的层叠方法，转而寻找单一层的固定点。DEQ在不同应用中表现出卓越的性能和特征的内存效率。同时，DEQ的对抗性漏洞引起了人们的关注。一些工作提出了对单调DEQ进行鲁棒性验证的方法。然而，目前对于一般DEQ的经验鲁棒性的研究还很有限。为此，我们观察到，对抗训练的DEQ需要更多的前向步骤才能达到平衡状态，甚至可能违反其固定点结构。此外，黑盒求解器导致DEQ的前向和后向轨迹不对齐。这些事实在评估或对抗性训练DEQ时会导致梯度混淆。因此，我们开发了一些方法来估计DEQ的中间梯度，并将其集成到攻击流程中。我们的方法有助于充分评估DEQ的鲁棒性。",
    "tldr": "本研究探究了深度平衡模型的对抗鲁棒性问题，提出了估计中间梯度以改进攻击流程的方法。",
    "en_tdlr": "This study investigates the adversarial robustness of deep equilibrium models (DEQs) and proposes approaches to estimate intermediate gradients to improve attack pipelines."
}