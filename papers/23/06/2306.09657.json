{
    "title": "Online Distillation for Pseudo-Relevance Feedback. (arXiv:2306.09657v1 [cs.IR])",
    "abstract": "Model distillation has emerged as a prominent technique to improve neural search models. To date, distillation taken an offline approach, wherein a new neural model is trained to predict relevance scores between arbitrary queries and documents. In this paper, we explore a departure from this offline distillation strategy by investigating whether a model for a specific query can be effectively distilled from neural re-ranking results (i.e., distilling in an online setting). Indeed, we find that a lexical model distilled online can reasonably replicate the re-ranking of a neural model. More importantly, these models can be used as queries that execute efficiently on indexes. This second retrieval stage can enrich the pool of documents for re-ranking by identifying documents that were missed in the first retrieval stage. Empirically, we show that this approach performs favourably when compared with established pseudo relevance feedback techniques, dense retrieval methods, and sparse-dense",
    "link": "http://arxiv.org/abs/2306.09657",
    "context": "Title: Online Distillation for Pseudo-Relevance Feedback. (arXiv:2306.09657v1 [cs.IR])\nAbstract: Model distillation has emerged as a prominent technique to improve neural search models. To date, distillation taken an offline approach, wherein a new neural model is trained to predict relevance scores between arbitrary queries and documents. In this paper, we explore a departure from this offline distillation strategy by investigating whether a model for a specific query can be effectively distilled from neural re-ranking results (i.e., distilling in an online setting). Indeed, we find that a lexical model distilled online can reasonably replicate the re-ranking of a neural model. More importantly, these models can be used as queries that execute efficiently on indexes. This second retrieval stage can enrich the pool of documents for re-ranking by identifying documents that were missed in the first retrieval stage. Empirically, we show that this approach performs favourably when compared with established pseudo relevance feedback techniques, dense retrieval methods, and sparse-dense",
    "path": "papers/23/06/2306.09657.json",
    "total_tokens": 763,
    "translated_title": "Online Distillation for Pseudo-Relevance Feedback（伪相关反馈的在线蒸馏技术）",
    "translated_abstract": "模型蒸馏是一种提高神经搜索模型效果的重要方法。当前，传统的蒸馏方法采用离线学习的方式，即训练一个新的神经模型预测任意查询与文档之间的相关得分。本文提出一种新的蒸馏方法，通过在线蒸馏逐步建立模型，以此来预测某一查询与文档之间的相关得分，并在索引中执行出色。该技术不仅可以扩大重新排序的文档数量，还能识别在第一阶段检索中被忽略的文档，以优化整体检索效果。",
    "tldr": "本文提出了一种伪相关反馈的在线蒸馏技术，通过在线逐步建立模型，预测查询与文档的相关得分，并在索引中高效执行，以优化整体检索效果。",
    "en_tdlr": "This paper proposes an online distillation technique for pseudo-relevance feedback, which gradually establishes a model to predict the relevance scores between queries and documents, and executes efficiently in the index to optimize the overall retrieval performance."
}