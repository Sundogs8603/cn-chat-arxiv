{
    "title": "More efficient manual review of automatically transcribed tabular data. (arXiv:2306.16126v1 [cs.LG])",
    "abstract": "Machine learning methods have proven useful in transcribing historical data. However, results from even highly accurate methods require manual verification and correction. Such manual review can be time-consuming and expensive, therefore the objective of this paper was to make it more efficient. Previously, we used machine learning to transcribe 2.3 million handwritten occupation codes from the Norwegian 1950 census with high accuracy (97%). We manually reviewed the 90,000 (3%) codes with the lowest model confidence. We allocated those 90,000 codes to human reviewers, who used our annotation tool to review the codes. To assess reviewer agreement, some codes were assigned to multiple reviewers. We then analyzed the review results to understand the relationship between accuracy improvements and effort. Additionally, we interviewed the reviewers to improve the workflow. The reviewers corrected 62.8% of the labels and agreed with the model label in 31.9% of cases. About 0.2% of the images ",
    "link": "http://arxiv.org/abs/2306.16126",
    "context": "Title: More efficient manual review of automatically transcribed tabular data. (arXiv:2306.16126v1 [cs.LG])\nAbstract: Machine learning methods have proven useful in transcribing historical data. However, results from even highly accurate methods require manual verification and correction. Such manual review can be time-consuming and expensive, therefore the objective of this paper was to make it more efficient. Previously, we used machine learning to transcribe 2.3 million handwritten occupation codes from the Norwegian 1950 census with high accuracy (97%). We manually reviewed the 90,000 (3%) codes with the lowest model confidence. We allocated those 90,000 codes to human reviewers, who used our annotation tool to review the codes. To assess reviewer agreement, some codes were assigned to multiple reviewers. We then analyzed the review results to understand the relationship between accuracy improvements and effort. Additionally, we interviewed the reviewers to improve the workflow. The reviewers corrected 62.8% of the labels and agreed with the model label in 31.9% of cases. About 0.2% of the images ",
    "path": "papers/23/06/2306.16126.json",
    "total_tokens": 888,
    "translated_title": "更高效的自动转录表格数据的人工审核方法",
    "translated_abstract": "机器学习方法在转录历史数据方面已经证明其有效性。然而，即使是高精度的方法的结果也需要手动验证和纠正。这样的人工审核可能耗时且昂贵，因此本文的目标是提高其效率。我们先前使用机器学习方法的高精度转录了挪威 1950 年人口普查中的 230 万份手写职业代码，然后手动审核了 3%（9 万份）置信度最低的代码。我们将这 9 万份代码分配给人工审核员，并使用我们的注释工具进行审核。为了评估审核员之间的一致性，部分代码被分配给多位审核员。然后，我们分析了审核结果以了解准确性改进与工作量之间的关系。此外，我们还采访了审核员以改善工作流程。审核员更正了 62.8% 的标签，并在 31.9% 的案例中与模型的标签达成一致。约 0.2% 的图片需要进一步的人工审核。",
    "tldr": "本文提出了一种更高效的自动转录表格数据的人工审核方法，通过使用机器学习方法转录大量的手写职业代码并进行手动审核，达到了准确性的提升和工作流程的改善。",
    "en_tdlr": "This paper presents a more efficient method for manual review of automatically transcribed tabular data, achieving improved accuracy and workflow by utilizing machine learning for transcribing handwritten occupation codes and conducting manual verification."
}