{
    "title": "Improving Knowledge Extraction from LLMs for Robotic Task Learning through Agent Analysis. (arXiv:2306.06770v2 [cs.AI] UPDATED)",
    "abstract": "Large language models (LLMs) offer significant promise as a knowledge source for robotic task learning. Prompt engineering has been shown to be effective for eliciting knowledge from an LLM but alone is insufficient for acquiring relevant, situationally grounded knowledge for an embodied robotic agent learning novel tasks. We describe a cognitive-agent approach that extends and complements prompt engineering, mitigating its limitations, and thus enabling a robot to acquire new task knowledge matched to its native language capabilities, embodiment, environment, and user preferences. The approach is to increase the response space of LLMs and deploy general strategies, embedded within the autonomous robot, to evaluate, repair, and select among candidate responses produced by the LLM. We describe the approach and experiments that show how a robot, by retrieving and evaluating a breadth of responses from the LLM, can achieve >75% task completion in one-shot learning without user oversight. ",
    "link": "http://arxiv.org/abs/2306.06770",
    "context": "Title: Improving Knowledge Extraction from LLMs for Robotic Task Learning through Agent Analysis. (arXiv:2306.06770v2 [cs.AI] UPDATED)\nAbstract: Large language models (LLMs) offer significant promise as a knowledge source for robotic task learning. Prompt engineering has been shown to be effective for eliciting knowledge from an LLM but alone is insufficient for acquiring relevant, situationally grounded knowledge for an embodied robotic agent learning novel tasks. We describe a cognitive-agent approach that extends and complements prompt engineering, mitigating its limitations, and thus enabling a robot to acquire new task knowledge matched to its native language capabilities, embodiment, environment, and user preferences. The approach is to increase the response space of LLMs and deploy general strategies, embedded within the autonomous robot, to evaluate, repair, and select among candidate responses produced by the LLM. We describe the approach and experiments that show how a robot, by retrieving and evaluating a breadth of responses from the LLM, can achieve >75% task completion in one-shot learning without user oversight. ",
    "path": "papers/23/06/2306.06770.json",
    "total_tokens": 915,
    "translated_title": "通过代理分析提高 LLM 对机器人任务学习的知识提取",
    "translated_abstract": "大型语言模型（LLMs）被视为机器人任务学习的知识来源，但是单独的提示工程并不能为机器人获取与其语言能力、体现能力、环境和用户偏好相匹配的情境相关知识。本文提出了一种认知代理方法，扩展和补充提示工程，缓解其局限性，以此使机器人能够获取新的任务知识。该方法是通过增加 LLMs 的响应空间，并部署通用策略，嵌入自主机器人内部，对 LLMs 产生的候选响应进行评估、修复和选择，实现一次学习即可完成任务。通过实验表明，机器人从 LLM 中检索和评估一系列不同响应后可以达到>75% 的任务完成率，无需用户监督。",
    "tldr": "本文提出了一种认知代理方法，通过增加 LLMs 的响应空间，并部署通用策略，嵌入自主机器人内部，从而使机器人能够获取与其语言能力、体现能力、环境和用户偏好相匹配的新的任务知识，实现一次学习即可完成任务。",
    "en_tdlr": "This paper proposes a cognitive-agent approach to improve knowledge extraction from LLMs for robotic task learning, which increases the response space of LLMs and deploys general strategies embedded within the autonomous robot to evaluate, repair, and select among candidate responses produced by the LLM. The experiments show that the robot can achieve >75% task completion in one-shot learning without user oversight, matched to its native language capabilities, embodiment, environment, and user preferences."
}