{
    "title": "An adaptive augmented Lagrangian method for training physics and equality constrained artificial neural networks. (arXiv:2306.04904v1 [cs.LG])",
    "abstract": "Physics and equality constrained artificial neural networks (PECANN) are grounded in methods of constrained optimization to properly constrain the solution of partial differential equations (PDEs) with their boundary and initial conditions and any high-fidelity data that may be available. To this end, adoption of the augmented Lagrangian method within the PECANN framework is paramount for learning the solution of PDEs without manually balancing the individual loss terms in the objective function used for determining the parameters of the neural network. Generally speaking, ALM combines the merits of the penalty and Lagrange multiplier methods while avoiding the ill conditioning and convergence issues associated singly with these methods . In the present work, we apply our PECANN framework to solve forward and inverse problems that have an expanded and diverse set of constraints. We show that ALM with its conventional formulation to update its penalty parameter and Lagrange multipliers ",
    "link": "http://arxiv.org/abs/2306.04904",
    "context": "Title: An adaptive augmented Lagrangian method for training physics and equality constrained artificial neural networks. (arXiv:2306.04904v1 [cs.LG])\nAbstract: Physics and equality constrained artificial neural networks (PECANN) are grounded in methods of constrained optimization to properly constrain the solution of partial differential equations (PDEs) with their boundary and initial conditions and any high-fidelity data that may be available. To this end, adoption of the augmented Lagrangian method within the PECANN framework is paramount for learning the solution of PDEs without manually balancing the individual loss terms in the objective function used for determining the parameters of the neural network. Generally speaking, ALM combines the merits of the penalty and Lagrange multiplier methods while avoiding the ill conditioning and convergence issues associated singly with these methods . In the present work, we apply our PECANN framework to solve forward and inverse problems that have an expanded and diverse set of constraints. We show that ALM with its conventional formulation to update its penalty parameter and Lagrange multipliers ",
    "path": "papers/23/06/2306.04904.json",
    "total_tokens": 853,
    "tldr": "本文提出了一种自适应增广Lagrange方法，通过约束优化方法对物理和等式约束的人工神经网络（PECANN）进行训练，解决正向和反向问题。该方法避免了惩罚和Lagrange乘数方法的问题。"
}