{
    "title": "No Strong Feelings One Way or Another: Re-operationalizing Neutrality in Natural Language Inference. (arXiv:2306.09918v1 [cs.CL])",
    "abstract": "Natural Language Inference (NLI) has been a cornerstone task in evaluating language models' inferential reasoning capabilities. However, the standard three-way classification scheme used in NLI has well-known shortcomings in evaluating models' ability to capture the nuances of natural human reasoning. In this paper, we argue that the operationalization of the neutral label in current NLI datasets has low validity, is interpreted inconsistently, and that at least one important sense of neutrality is often ignored. We uncover the detrimental impact of these shortcomings, which in some cases leads to annotation datasets that actually decrease performance on downstream tasks. We compare approaches of handling annotator disagreement and identify flaws in a recent NLI dataset that designs an annotator study based on a problematic operationalization. Our findings highlight the need for a more refined evaluation framework for NLI, and we hope to spark further discussion and action in the NLP c",
    "link": "http://arxiv.org/abs/2306.09918",
    "context": "Title: No Strong Feelings One Way or Another: Re-operationalizing Neutrality in Natural Language Inference. (arXiv:2306.09918v1 [cs.CL])\nAbstract: Natural Language Inference (NLI) has been a cornerstone task in evaluating language models' inferential reasoning capabilities. However, the standard three-way classification scheme used in NLI has well-known shortcomings in evaluating models' ability to capture the nuances of natural human reasoning. In this paper, we argue that the operationalization of the neutral label in current NLI datasets has low validity, is interpreted inconsistently, and that at least one important sense of neutrality is often ignored. We uncover the detrimental impact of these shortcomings, which in some cases leads to annotation datasets that actually decrease performance on downstream tasks. We compare approaches of handling annotator disagreement and identify flaws in a recent NLI dataset that designs an annotator study based on a problematic operationalization. Our findings highlight the need for a more refined evaluation framework for NLI, and we hope to spark further discussion and action in the NLP c",
    "path": "papers/23/06/2306.09918.json",
    "total_tokens": 882,
    "translated_title": "理性一无所感：在自然语言推理中重新操作中立性",
    "translated_abstract": "自然语言推理(NLI)一直是评估语言模型推理能力的基石任务。然而，NLI中使用的标准三分类模式在评估模型捕捉人类推理的微妙之处方面存在已知缺点。在本文中，我们认为当前NLI数据集中中立标签的操作化效度很低，解释不一致，并且通常忽略至少一个重要的中立意义。我们揭示了这些缺点的有害影响，在某些情况下导致注释数据集实际上降低了下游任务的性能。我们比较了处理注释者不一致的方法，并确定了最近的一个NLI数据集中存在的问题操作化的注释者研究的缺陷。我们的研究结果凸显了NLI需要更精细的评估框架，我们希望引发NLP社区对于改善语言模型评估的讨论和行动。",
    "tldr": "本文讨论了自然语言推理(NLI)中标签操作存在的缺点，提出了NLI需要更精细的评价体系的观点，并比较了处理注释者一致性的方法。",
    "en_tdlr": "This paper discusses the shortcomings of the current operationalization of the neutral label in Natural Language Inference (NLI), proposes a need for a more refined evaluation framework for NLI, compares approaches of handling annotator disagreement, and uncovers the detrimental impact of these shortcomings."
}