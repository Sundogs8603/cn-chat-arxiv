{
    "title": "Spike-based computation using classical recurrent neural networks. (arXiv:2306.03623v1 [cs.NE])",
    "abstract": "Spiking neural networks are a type of artificial neural networks in which communication between neurons is only made of events, also called spikes. This property allows neural networks to make asynchronous and sparse computations and therefore to drastically decrease energy consumption when run on specialized hardware. However, training such networks is known to be difficult, mainly due to the non-differentiability of the spike activation, which prevents the use of classical backpropagation. This is because state-of-the-art spiking neural networks are usually derived from biologically-inspired neuron models, to which are applied machine learning methods for training. Nowadays, research about spiking neural networks focuses on the design of training algorithms whose goal is to obtain networks that compete with their non-spiking version on specific tasks. In this paper, we attempt the symmetrical approach: we modify the dynamics of a well-known, easily trainable type of recurrent neural ",
    "link": "http://arxiv.org/abs/2306.03623",
    "context": "Title: Spike-based computation using classical recurrent neural networks. (arXiv:2306.03623v1 [cs.NE])\nAbstract: Spiking neural networks are a type of artificial neural networks in which communication between neurons is only made of events, also called spikes. This property allows neural networks to make asynchronous and sparse computations and therefore to drastically decrease energy consumption when run on specialized hardware. However, training such networks is known to be difficult, mainly due to the non-differentiability of the spike activation, which prevents the use of classical backpropagation. This is because state-of-the-art spiking neural networks are usually derived from biologically-inspired neuron models, to which are applied machine learning methods for training. Nowadays, research about spiking neural networks focuses on the design of training algorithms whose goal is to obtain networks that compete with their non-spiking version on specific tasks. In this paper, we attempt the symmetrical approach: we modify the dynamics of a well-known, easily trainable type of recurrent neural ",
    "path": "papers/23/06/2306.03623.json",
    "total_tokens": 916,
    "translated_title": "经典循环神经网络的脉冲计算",
    "translated_abstract": "脉冲神经网络是一种人工神经网络，其中神经元之间的通信仅由事件或所谓的脉冲组成。这种特性使得神经网络能够进行异步和稀疏计算，并因此在专用硬件上运行时大幅减少能源消耗。本文中，我们尝试采用一种对称的方法：修改一种已知的、易于训练的循环神经网络的动态特性，使其产生基于脉冲的计算。通过明确引入脉冲阈值和重置机制，我们使网络能够仅使用脉冲来执行前向和循环计算。然后，我们展示了这种修改后的构架既可以实现，同时在两个基准数据集上实现了最先进的性能，包括具有挑战性的ImageNet数据集。",
    "tldr": "本文提出了一种新的脉冲神经网络方法，通过修改一种易于训练的循环神经网络的动态特性，使其产生基于脉冲的计算，并在进行了脉冲网络的训练后，在多个数据集上取得了最先进的性能。",
    "en_tdlr": "This paper proposes a novel spiking neural network approach by modifying the dynamics of a well-known and easily trainable type of recurrent neural network, enabling it to perform spike-based computations and achieving state-of-the-art performance on benchmark datasets after training."
}