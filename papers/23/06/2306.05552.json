{
    "title": "ChatGPT for Us: Preserving Data Privacy in ChatGPT via Dialogue Text Ambiguation to Expand Mental Health Care Delivery. (arXiv:2306.05552v1 [cs.CL])",
    "abstract": "Large language models have been useful in expanding mental health care delivery. ChatGPT, in particular, has gained popularity for its ability to generate human-like dialogue. However, data-sensitive domains -- including but not limited to healthcare -- face challenges in using ChatGPT due to privacy and data-ownership concerns. To enable its utilization, we propose a text ambiguation framework that preserves user privacy. We ground this in the task of addressing stress prompted by user-provided texts to demonstrate the viability and helpfulness of privacy-preserved generations. Our results suggest that chatGPT recommendations are still able to be moderately helpful and relevant, even when the original user text is not provided.",
    "link": "http://arxiv.org/abs/2306.05552",
    "context": "Title: ChatGPT for Us: Preserving Data Privacy in ChatGPT via Dialogue Text Ambiguation to Expand Mental Health Care Delivery. (arXiv:2306.05552v1 [cs.CL])\nAbstract: Large language models have been useful in expanding mental health care delivery. ChatGPT, in particular, has gained popularity for its ability to generate human-like dialogue. However, data-sensitive domains -- including but not limited to healthcare -- face challenges in using ChatGPT due to privacy and data-ownership concerns. To enable its utilization, we propose a text ambiguation framework that preserves user privacy. We ground this in the task of addressing stress prompted by user-provided texts to demonstrate the viability and helpfulness of privacy-preserved generations. Our results suggest that chatGPT recommendations are still able to be moderately helpful and relevant, even when the original user text is not provided.",
    "path": "papers/23/06/2306.05552.json",
    "total_tokens": 796,
    "translated_title": "ChatGPT for Us: 通过对话文本模糊化扩展心理保健交付以保护数据隐私",
    "translated_abstract": "大型语言模型对于扩展心理保健交付非常有用。尤其是ChatGPT因其生成人类对话的能力而备受欢迎。然而，数据敏感的领域，包括但不限于医疗保健，由于隐私和数据所有权问题，无法使用ChatGPT。为了使其得到利用，我们提出了一个文本模糊化框架，以保护用户的隐私。我们把这个框架用于解决用户提供的压力问题，以展示这种隐私保护生成的可行性和有益性。我们的结果表明，即使不提供原始用户文本，ChatGPT的建议仍然能够适度地有帮助和相关性。",
    "tldr": "本研究提出了一个文本模糊化框架，以保护用户隐私并扩展心理保健交付。结果表明即使不提供原始用户文本，ChatGPT的建议仍然能够适度地有帮助和相关性。",
    "en_tdlr": "This study proposes a text ambiguation framework to preserve user privacy and expand mental health care delivery. Results suggest that chatGPT recommendations are still able to be moderately helpful and relevant, even when the original user text is not provided."
}