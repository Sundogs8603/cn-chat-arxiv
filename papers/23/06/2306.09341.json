{
    "title": "Human Preference Score v2: A Solid Benchmark for Evaluating Human Preferences of Text-to-Image Synthesis. (arXiv:2306.09341v2 [cs.CV] UPDATED)",
    "abstract": "Recent text-to-image generative models can generate high-fidelity images from text inputs, but the quality of these generated images cannot be accurately evaluated by existing evaluation metrics. To address this issue, we introduce Human Preference Dataset v2 (HPD v2), a large-scale dataset that captures human preferences on images from a wide range of sources. HPD v2 comprises 798,090 human preference choices on 433,760 pairs of images, making it the largest dataset of its kind. The text prompts and images are deliberately collected to eliminate potential bias, which is a common issue in previous datasets. By fine-tuning CLIP on HPD v2, we obtain Human Preference Score v2 (HPS v2), a scoring model that can more accurately predict human preferences on generated images. Our experiments demonstrate that HPS v2 generalizes better than previous metrics across various image distributions and is responsive to algorithmic improvements of text-to-image generative models, making it a preferable",
    "link": "http://arxiv.org/abs/2306.09341",
    "context": "Title: Human Preference Score v2: A Solid Benchmark for Evaluating Human Preferences of Text-to-Image Synthesis. (arXiv:2306.09341v2 [cs.CV] UPDATED)\nAbstract: Recent text-to-image generative models can generate high-fidelity images from text inputs, but the quality of these generated images cannot be accurately evaluated by existing evaluation metrics. To address this issue, we introduce Human Preference Dataset v2 (HPD v2), a large-scale dataset that captures human preferences on images from a wide range of sources. HPD v2 comprises 798,090 human preference choices on 433,760 pairs of images, making it the largest dataset of its kind. The text prompts and images are deliberately collected to eliminate potential bias, which is a common issue in previous datasets. By fine-tuning CLIP on HPD v2, we obtain Human Preference Score v2 (HPS v2), a scoring model that can more accurately predict human preferences on generated images. Our experiments demonstrate that HPS v2 generalizes better than previous metrics across various image distributions and is responsive to algorithmic improvements of text-to-image generative models, making it a preferable",
    "path": "papers/23/06/2306.09341.json",
    "total_tokens": 1040,
    "translated_title": "人类偏好分数v2：用于评估文本到图像合成的人类偏好的可靠基准",
    "translated_abstract": "最近的文本到图像生成模型可以从文本输入中生成高保真度的图像，但是这些生成图像的质量无法通过现有的评估指标准确评估。为解决这个问题，我们引入了人类偏好数据集v2（HPD v2），这是一个大规模数据集，捕捉了来自各种来源的图像的人类偏好。HPD v2包括798,090个人类偏好选择，涉及433,760对图像，是同类数据集中最大的数据集。文本提示和图像是经过精心收集的，以消除潜在的偏见，这是先前数据集中经常出现的问题。通过在HPD v2上微调CLIP，我们获得了人类偏好分数v2（HPS v2），这是一个可以更准确预测生成图像人类偏好的评分模型。我们的实验表明，HPS v2在各种图像分布中具有更好的泛化能力，对于文本到图像生成模型的算法改进具有响应性，使其成为更可取的选择。",
    "tldr": "该论文提出了一个可以准确评估文本到图像合成中生成图像质量的可靠基准——人类偏好分数v2。通过引入人类偏好数据集v2（HPD v2）和微调CLIP，研究者们成功获得了更能预测人类偏好的评分模型HPS v2，其在各种图像分布中具有更好的泛化能力，并对文本到图像生成模型的算法改进具有响应性。",
    "en_tdlr": "This paper introduces a reliable benchmark, Human Preference Score v2, for accurately evaluating the quality of generated images in text-to-image synthesis. By introducing the Human Preference Dataset v2 and fine-tuning CLIP, the authors developed the scoring model HPS v2, which has better generalization across various image distributions and is responsive to algorithmic improvements in text-to-image generative models."
}