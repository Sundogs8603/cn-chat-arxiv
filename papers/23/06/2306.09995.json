{
    "title": "Fairness in Preference-based Reinforcement Learning. (arXiv:2306.09995v1 [cs.LG])",
    "abstract": "In this paper, we address the issue of fairness in preference-based reinforcement learning (PbRL) in the presence of multiple objectives. The main objective is to design control policies that can optimize multiple objectives while treating each objective fairly. Toward this objective, we design a new fairness-induced preference-based reinforcement learning or FPbRL. The main idea of FPbRL is to learn vector reward functions associated with multiple objectives via new welfare-based preferences rather than reward-based preference in PbRL, coupled with policy learning via maximizing a generalized Gini welfare function. Finally, we provide experiment studies on three different environments to show that the proposed FPbRL approach can achieve both efficiency and equity for learning effective and fair policies.",
    "link": "http://arxiv.org/abs/2306.09995",
    "context": "Title: Fairness in Preference-based Reinforcement Learning. (arXiv:2306.09995v1 [cs.LG])\nAbstract: In this paper, we address the issue of fairness in preference-based reinforcement learning (PbRL) in the presence of multiple objectives. The main objective is to design control policies that can optimize multiple objectives while treating each objective fairly. Toward this objective, we design a new fairness-induced preference-based reinforcement learning or FPbRL. The main idea of FPbRL is to learn vector reward functions associated with multiple objectives via new welfare-based preferences rather than reward-based preference in PbRL, coupled with policy learning via maximizing a generalized Gini welfare function. Finally, we provide experiment studies on three different environments to show that the proposed FPbRL approach can achieve both efficiency and equity for learning effective and fair policies.",
    "path": "papers/23/06/2306.09995.json",
    "total_tokens": 801,
    "translated_title": "基于偏好的强化学习中的公平性",
    "translated_abstract": "本文研究了在多目标情况下偏好强化学习(PbRL)中的公平性问题。主要目标是设计控制策略，既能够优化多个目标，又能够公平地处理每个目标。为实现这一目标，我们设计了一种新的公平偏好强化学习(FPbRL)方法。FPbRL的主要思想是通过新的福利偏好而不是PbRL中的基于奖励的偏好来学习与多目标关联的向量奖励函数，并通过最大化广义Gini福利函数进行策略学习。最后，在三个不同的环境上进行实验研究，展示了所提出的FPbRL方法能够实现有效和公平的控制策略的学习。",
    "tldr": "该论文提出了一种名为FPbRL的新的公平偏好强化学习方法，旨在通过广义Gini福利函数最大化策略学习来实现多目标优化并处理每个目标的公平性。",
    "en_tdlr": "This paper proposes a novel fairness-induced preference-based reinforcement learning (FPbRL) method that optimizes multiple objectives while treating each objective fairly through learning vector reward functions associated with multiple objectives via welfare-based preferences and maximizing a generalized Gini welfare function during policy learning. Experiment studies demonstrate the effectiveness and fairness of the proposed method in learning control policies."
}