{
    "title": "Enlighten-anything:When Segment Anything Model Meets Low-light Image Enhancement. (arXiv:2306.10286v2 [cs.CV] UPDATED)",
    "abstract": "Image restoration is a low-level visual task, and most CNN methods are designed as black boxes, lacking transparency and intrinsic aesthetics. Many unsupervised approaches ignore the degradation of visible information in low-light scenes, which will seriously affect the aggregation of complementary information and also make the fusion algorithm unable to produce satisfactory fusion results under extreme conditions. In this paper, we propose Enlighten-anything, which is able to enhance and fuse the semantic intent of SAM segmentation with low-light images to obtain fused images with good visual perception. The generalization ability of unsupervised learning is greatly improved, and experiments on LOL dataset are conducted to show that our method improves 3db in PSNR over baseline and 8 in SSIM. zero-shot learning of SAM introduces a powerful aid for unsupervised low-light enhancement. The source code of Enlighten-anything can be obtained from https://github.com/zhangbaijin/enlighten-any",
    "link": "http://arxiv.org/abs/2306.10286",
    "context": "Title: Enlighten-anything:When Segment Anything Model Meets Low-light Image Enhancement. (arXiv:2306.10286v2 [cs.CV] UPDATED)\nAbstract: Image restoration is a low-level visual task, and most CNN methods are designed as black boxes, lacking transparency and intrinsic aesthetics. Many unsupervised approaches ignore the degradation of visible information in low-light scenes, which will seriously affect the aggregation of complementary information and also make the fusion algorithm unable to produce satisfactory fusion results under extreme conditions. In this paper, we propose Enlighten-anything, which is able to enhance and fuse the semantic intent of SAM segmentation with low-light images to obtain fused images with good visual perception. The generalization ability of unsupervised learning is greatly improved, and experiments on LOL dataset are conducted to show that our method improves 3db in PSNR over baseline and 8 in SSIM. zero-shot learning of SAM introduces a powerful aid for unsupervised low-light enhancement. The source code of Enlighten-anything can be obtained from https://github.com/zhangbaijin/enlighten-any",
    "path": "papers/23/06/2306.10286.json",
    "total_tokens": 855,
    "translated_title": "Enlighten-anything: 当分段模型遇见低光图像增强",
    "translated_abstract": "图像恢复是一项低级别视觉任务，大多数CNN方法都是作为黑盒子设计的，缺乏透明度和固有美学。许多无监督方法忽略了低光场景中可见信息的退化，这会严重影响补充信息的聚合，并使融合算法无法在极端情况下产生令人满意的融合结果。本文提出了Enlighten-anything，能够将SAM分段的语义意图与低光图像增强相结合，获得具有良好视觉感知的融合图像。无监督学习的泛化能力得到了极大提高，对LOL数据集的实验表明，我们的方法在PSNR上比基线提高了3dB，在SSIM上提高了8。 SAM的零样本学习为无监督低光增强提供了有力的帮助。Enlighten-anything的源代码可以从 https://github.com/zhangbaijin/enlighten-any 获得。",
    "tldr": "本文提出了Enlighten-anything，在低光图像增强中将分段模型与SAM融合，实现了良好视觉感知的融合图像。",
    "en_tdlr": "The paper proposes Enlighten-anything, which combines the segmentation model with SAM in low-light image enhancement, achieving fused images with good visual perception."
}