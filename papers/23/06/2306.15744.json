{
    "title": "Ticketed Learning-Unlearning Schemes. (arXiv:2306.15744v1 [cs.LG])",
    "abstract": "We consider the learning--unlearning paradigm defined as follows. First given a dataset, the goal is to learn a good predictor, such as one minimizing a certain loss. Subsequently, given any subset of examples that wish to be unlearnt, the goal is to learn, without the knowledge of the original training dataset, a good predictor that is identical to the predictor that would have been produced when learning from scratch on the surviving examples.  We propose a new ticketed model for learning--unlearning wherein the learning algorithm can send back additional information in the form of a small-sized (encrypted) ``ticket'' to each participating training example, in addition to retaining a small amount of ``central'' information for later. Subsequently, the examples that wish to be unlearnt present their tickets to the unlearning algorithm, which additionally uses the central information to return a new predictor. We provide space-efficient ticketed learning--unlearning schemes for a broad",
    "link": "http://arxiv.org/abs/2306.15744",
    "context": "Title: Ticketed Learning-Unlearning Schemes. (arXiv:2306.15744v1 [cs.LG])\nAbstract: We consider the learning--unlearning paradigm defined as follows. First given a dataset, the goal is to learn a good predictor, such as one minimizing a certain loss. Subsequently, given any subset of examples that wish to be unlearnt, the goal is to learn, without the knowledge of the original training dataset, a good predictor that is identical to the predictor that would have been produced when learning from scratch on the surviving examples.  We propose a new ticketed model for learning--unlearning wherein the learning algorithm can send back additional information in the form of a small-sized (encrypted) ``ticket'' to each participating training example, in addition to retaining a small amount of ``central'' information for later. Subsequently, the examples that wish to be unlearnt present their tickets to the unlearning algorithm, which additionally uses the central information to return a new predictor. We provide space-efficient ticketed learning--unlearning schemes for a broad",
    "path": "papers/23/06/2306.15744.json",
    "total_tokens": 907,
    "translated_title": "票据化学习-遗忘方案",
    "translated_abstract": "我们考虑所定义的学习-遗忘范式。首先，给定一个数据集，目标是学习一个好的预测器，例如最小化某个损失函数的预测器。随后，给定任何希望遗忘的示例子集，目标是在不知道原始训练数据集的情况下，学习一个与在幸存示例上从头开始学习时所生成的预测器完全相同的好的预测器。我们提出了一种新的票据化学习-遗忘模型，其中学习算法可以通过一个小型（加密的）“票据”向每个参与训练示例发送额外的信息，并保留一小部分“中央”信息以供以后使用。随后，希望遗忘的示例将其票据提交给遗忘算法，该算法还使用中央信息返回一个新的预测器。我们提供了一种高效的票据化学习-遗忘方案，用于广泛的场景。",
    "tldr": "提出了一种新的票据化学习-遗忘模型，其中学习算法通过向每个参与训练示例发送额外信息并保留一部分中央信息，实现了学习和遗忘。我们提供了一种高效的票据化学习-遗忘方案，用于广泛的场景。",
    "en_tdlr": "A new ticketed model for learning-unlearning is proposed, where the learning algorithm sends additional information to each training example and retains central information, enabling learning and unlearning. Efficient ticketed learning-unlearning schemes are provided for various scenarios."
}