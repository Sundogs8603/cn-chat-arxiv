{
    "title": "Memorization Capacity of Multi-Head Attention in Transformers. (arXiv:2306.02010v2 [cs.LG] UPDATED)",
    "abstract": "Transformers have become the go-to architecture for language and vision tasks, yet their theoretical properties, especially memorization capacity, remain elusive. This paper investigates the memorization abilities of multi-head attention mechanisms, examining how many example sequences they can memorize, as a function of the number of heads and sequence length. Motivated by experimental findings on vision transformers, we introduce novel assumptions about the linear independence of input data, distinct from the commonly used general-position assumption. Under these assumptions, we demonstrate that an attention layer with $H$ heads, dimension $d$, and context size $n < d$, featuring $\\Theta(Hd^2)$ parameters, can memorize $\\Omega(Hn)$ examples. Our analysis sheds light on how different attention heads handle various example sequences, aided by the softmax operator's saturation property. We validate our findings through experiments on synthetic data.",
    "link": "http://arxiv.org/abs/2306.02010",
    "context": "Title: Memorization Capacity of Multi-Head Attention in Transformers. (arXiv:2306.02010v2 [cs.LG] UPDATED)\nAbstract: Transformers have become the go-to architecture for language and vision tasks, yet their theoretical properties, especially memorization capacity, remain elusive. This paper investigates the memorization abilities of multi-head attention mechanisms, examining how many example sequences they can memorize, as a function of the number of heads and sequence length. Motivated by experimental findings on vision transformers, we introduce novel assumptions about the linear independence of input data, distinct from the commonly used general-position assumption. Under these assumptions, we demonstrate that an attention layer with $H$ heads, dimension $d$, and context size $n < d$, featuring $\\Theta(Hd^2)$ parameters, can memorize $\\Omega(Hn)$ examples. Our analysis sheds light on how different attention heads handle various example sequences, aided by the softmax operator's saturation property. We validate our findings through experiments on synthetic data.",
    "path": "papers/23/06/2306.02010.json",
    "total_tokens": 836,
    "translated_title": "Transformers中多头注意力的记忆容量",
    "translated_abstract": "Transformers已成为语言和视觉任务的首选架构，但其理论属性，特别是记忆容量，仍然难以捉摸。本文研究了多头注意力机制的记忆能力，研究了它们能够记忆多少个示例序列，作为头数和序列长度的函数。在对视觉transformers的实验结果的启发下，我们引入了关于输入数据线性独立性的新假设，不同于通常使用的一般位置假设。在这些假设下，我们证明了具有H个头，维度d，上下文大小n < d的注意力层，具有Θ(Hd^2)个参数，可以记住Ω(Hn)个示例。我们的分析揭示了不同的注意力头如何处理不同的示例序列，受到softmax运算符的饱和特性的帮助。我们通过合成数据的实验验证了我们的发现。",
    "tldr": "本文研究了多头注意力机制的记忆能力，发现在特定的假设下，注意力层可以记忆Ω(Hn)个示例序列，这对于理解transformers的记忆容量有重要意义。"
}