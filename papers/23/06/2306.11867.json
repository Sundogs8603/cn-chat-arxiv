{
    "title": "Personalized Federated Learning with Feature Alignment and Classifier Collaboration. (arXiv:2306.11867v1 [cs.LG])",
    "abstract": "Data heterogeneity is one of the most challenging issues in federated learning, which motivates a variety of approaches to learn personalized models for participating clients. One such approach in deep neural networks based tasks is employing a shared feature representation and learning a customized classifier head for each client. However, previous works do not utilize the global knowledge during local representation learning and also neglect the fine-grained collaboration between local classifier heads, which limit the model generalization ability. In this work, we conduct explicit local-global feature alignment by leveraging global semantic knowledge for learning a better representation. Moreover, we quantify the benefit of classifier combination for each client as a function of the combining weights and derive an optimization problem for estimating optimal weights. Finally, extensive evaluation results on benchmark datasets with various heterogeneous data scenarios demonstrate the ",
    "link": "http://arxiv.org/abs/2306.11867",
    "context": "Title: Personalized Federated Learning with Feature Alignment and Classifier Collaboration. (arXiv:2306.11867v1 [cs.LG])\nAbstract: Data heterogeneity is one of the most challenging issues in federated learning, which motivates a variety of approaches to learn personalized models for participating clients. One such approach in deep neural networks based tasks is employing a shared feature representation and learning a customized classifier head for each client. However, previous works do not utilize the global knowledge during local representation learning and also neglect the fine-grained collaboration between local classifier heads, which limit the model generalization ability. In this work, we conduct explicit local-global feature alignment by leveraging global semantic knowledge for learning a better representation. Moreover, we quantify the benefit of classifier combination for each client as a function of the combining weights and derive an optimization problem for estimating optimal weights. Finally, extensive evaluation results on benchmark datasets with various heterogeneous data scenarios demonstrate the ",
    "path": "papers/23/06/2306.11867.json",
    "total_tokens": 906,
    "translated_title": "带特征对齐和分类器协作的个性化联邦学习",
    "translated_abstract": "数据异构性是联邦学习中最具挑战性的问题之一，这促使人们采用各种方法为参与客户端学习个性化模型。在深度神经网络任务中，一种方法是使用共享特征表示，并为每个客户端学习定制分类器。然而，先前的工作在本地表示学习期间未利用全局知识，也忽略了本地分类器之间的细粒度协作，这限制了模型的泛化能力。在本文中，我们通过利用全球语义知识进行显式的局部-全局特征对齐，实现了更好的表示学习。此外，我们量化了每个客户端分类器组合的收益，作为组合权重的函数，并导出估计最优权重的优化问题。最后，对各种异构数据情形的基准数据集进行广泛评估结果证明了方法的有效性。",
    "tldr": "该研究提出了一种带有特征对齐和分类器协作的个性化联邦学习方法，通过利用全局语义知识进行显式的局部-全局特征对齐，并量化了每个客户端分类器组合的收益，作为组合权重的函数，对各种异构数据情形的基准数据集进行了广泛的评估。",
    "en_tdlr": "This paper proposes a personalized federated learning approach with feature alignment and classifier collaboration. The method leverages global semantic knowledge for explicit local-global feature alignment, quantifies the benefit of classifier combination for each client, and optimizes the combining weights. The extensive evaluation results on benchmark datasets with various heterogeneous data scenarios demonstrate the effectiveness of the proposed method."
}