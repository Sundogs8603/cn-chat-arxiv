{
    "title": "Multi-Task Training with In-Domain Language Models for Diagnostic Reasoning. (arXiv:2306.04551v1 [cs.CL])",
    "abstract": "Generative artificial intelligence (AI) is a promising direction for augmenting clinical diagnostic decision support and reducing diagnostic errors, a leading contributor to medical errors. To further the development of clinical AI systems, the Diagnostic Reasoning Benchmark (DR.BENCH) was introduced as a comprehensive generative AI framework, comprised of six tasks representing key components in clinical reasoning. We present a comparative analysis of in-domain versus out-of-domain language models as well as multi-task versus single task training with a focus on the problem summarization task in DR.BENCH (Gao et al., 2023). We demonstrate that a multi-task, clinically trained language model outperforms its general domain counterpart by a large margin, establishing a new state-of-the-art performance, with a ROUGE-L score of 28.55. This research underscores the value of domain-specific training for optimizing clinical diagnostic reasoning tasks.",
    "link": "http://arxiv.org/abs/2306.04551",
    "context": "Title: Multi-Task Training with In-Domain Language Models for Diagnostic Reasoning. (arXiv:2306.04551v1 [cs.CL])\nAbstract: Generative artificial intelligence (AI) is a promising direction for augmenting clinical diagnostic decision support and reducing diagnostic errors, a leading contributor to medical errors. To further the development of clinical AI systems, the Diagnostic Reasoning Benchmark (DR.BENCH) was introduced as a comprehensive generative AI framework, comprised of six tasks representing key components in clinical reasoning. We present a comparative analysis of in-domain versus out-of-domain language models as well as multi-task versus single task training with a focus on the problem summarization task in DR.BENCH (Gao et al., 2023). We demonstrate that a multi-task, clinically trained language model outperforms its general domain counterpart by a large margin, establishing a new state-of-the-art performance, with a ROUGE-L score of 28.55. This research underscores the value of domain-specific training for optimizing clinical diagnostic reasoning tasks.",
    "path": "papers/23/06/2306.04551.json",
    "total_tokens": 880,
    "translated_title": "多任务训练结合领域内语言模型进行诊断推理",
    "translated_abstract": "生成人工智能是增强临床诊断决策支持和减少诊断错误的一种有前途的方向。为进一步发展临床人工智能系统，引入了诊断推理基准（DR.BENCH）作为全面的生成人工智能框架，由六个任务组成，代表临床推理的关键组成部分。本文进行了领域内与领域外语言模型以及多任务与单任务训练的比较分析，重点关注 DR.BENCH 的问题总结任务（Gao 等，2023）。我们证明，通过临床训练的多任务语言模型大幅优于其一般领域的对应模型，建立了新的最优性能， ROUGE-L 得分为 28.55。这项研究强调了领域特定训练在优化临床诊断推理任务中的价值。",
    "tldr": "本文研究了领域内与领域外语言模型以及多任务与单任务训练的比较，并证明了通过临床训练的多任务语言模型在临床诊断推理任务中表现优异，建立了新的最优性能。",
    "en_tdlr": "This study compared in-domain and out-of-domain language models as well as multi-task vs single-task training, and demonstrated that a clinically trained, multi-task language model outperforms its general domain counterpart in clinical diagnostic reasoning tasks, establishing a new state-of-the-art performance."
}