{
    "title": "Sampling Individually-Fair Rankings that are Always Group Fair. (arXiv:2306.11964v1 [cs.CY])",
    "abstract": "Rankings on online platforms help their end-users find the relevant information -- people, news, media, and products -- quickly. Fair ranking tasks, which ask to rank a set of items to maximize utility subject to satisfying group-fairness constraints, have gained significant interest in the Algorithmic Fairness, Information Retrieval, and Machine Learning literature. Recent works, however, identify uncertainty in the utilities of items as a primary cause of unfairness and propose introducing randomness in the output. This randomness is carefully chosen to guarantee an adequate representation of each item (while accounting for the uncertainty). However, due to this randomness, the output rankings may violate group fairness constraints. We give an efficient algorithm that samples rankings from an individually-fair distribution while ensuring that every output ranking is group fair. The expected utility of the output ranking is at least $\\alpha$ times the utility of the optimal fair solut",
    "link": "http://arxiv.org/abs/2306.11964",
    "context": "Title: Sampling Individually-Fair Rankings that are Always Group Fair. (arXiv:2306.11964v1 [cs.CY])\nAbstract: Rankings on online platforms help their end-users find the relevant information -- people, news, media, and products -- quickly. Fair ranking tasks, which ask to rank a set of items to maximize utility subject to satisfying group-fairness constraints, have gained significant interest in the Algorithmic Fairness, Information Retrieval, and Machine Learning literature. Recent works, however, identify uncertainty in the utilities of items as a primary cause of unfairness and propose introducing randomness in the output. This randomness is carefully chosen to guarantee an adequate representation of each item (while accounting for the uncertainty). However, due to this randomness, the output rankings may violate group fairness constraints. We give an efficient algorithm that samples rankings from an individually-fair distribution while ensuring that every output ranking is group fair. The expected utility of the output ranking is at least $\\alpha$ times the utility of the optimal fair solut",
    "path": "papers/23/06/2306.11964.json",
    "total_tokens": 1010,
    "translated_title": "采样个体公平且满足群体公平的排名",
    "translated_abstract": "在线平台上的排名可以帮助用户快速找到相关信息，如人物、新闻、媒体和产品。公平排名是一种为了满足群体公平性约束而优化一组项目排名的任务，已经在算法公平性、信息检索和机器学习领域引起了广泛关注。然而，近期的研究表明项目效用的不确定性是不公平的主要原因，并建议在输出中引入随机性。这种随机性经过仔细选择，以确保对每个项目进行充分且合理的代表（同时考虑不确定性）。然而，由于这种随机性，输出的排名可能会违反群体公平性约束。我们提出了一个有效的算法，从一个个体公平分布中抽样排名，同时确保每个输出的排名都满足群体公平性约束。输出排名的期望效用至少是最优公平解的效用的 $\\alpha$ 倍，其中 $\\alpha$ 是一个量化公平约束紧度的参数。我们在真实世界数据集上进行实验，证明了我们算法的高效性和有效性。",
    "tldr": "该论文提出了一种有效算法，从个体公平分布中采样排名，同时确保每个输出的排名都满足群体公平性约束。输出排名的期望效用至少是最优公平解的效用的$\\alpha$倍，其中$\\alpha$是一个量化公平约束紧度的参数。",
    "en_tdlr": "This paper proposes an efficient algorithm to sample rankings from an individually-fair distribution while ensuring that every output ranking is group fair. The expected utility of the output ranking is at least $\\alpha$ times the utility of the optimal fair solution, where $\\alpha$ is a parameter that quantifies the tightness of the fairness constraint. Experiments on real-world datasets demonstrate the effectiveness and efficiency of the proposed algorithm."
}