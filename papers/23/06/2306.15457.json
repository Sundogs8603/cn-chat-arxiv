{
    "title": "Robust Proxy: Improving Adversarial Robustness by Robust Proxy Learning. (arXiv:2306.15457v1 [cs.CV])",
    "abstract": "Recently, it has been widely known that deep neural networks are highly vulnerable and easily broken by adversarial attacks. To mitigate the adversarial vulnerability, many defense algorithms have been proposed. Recently, to improve adversarial robustness, many works try to enhance feature representation by imposing more direct supervision on the discriminative feature. However, existing approaches lack an understanding of learning adversarially robust feature representation. In this paper, we propose a novel training framework called Robust Proxy Learning. In the proposed method, the model explicitly learns robust feature representations with robust proxies. To this end, firstly, we demonstrate that we can generate class-representative robust features by adding class-wise robust perturbations. Then, we use the class representative features as robust proxies. With the class-wise robust features, the model explicitly learns adversarially robust features through the proposed robust proxy",
    "link": "http://arxiv.org/abs/2306.15457",
    "context": "Title: Robust Proxy: Improving Adversarial Robustness by Robust Proxy Learning. (arXiv:2306.15457v1 [cs.CV])\nAbstract: Recently, it has been widely known that deep neural networks are highly vulnerable and easily broken by adversarial attacks. To mitigate the adversarial vulnerability, many defense algorithms have been proposed. Recently, to improve adversarial robustness, many works try to enhance feature representation by imposing more direct supervision on the discriminative feature. However, existing approaches lack an understanding of learning adversarially robust feature representation. In this paper, we propose a novel training framework called Robust Proxy Learning. In the proposed method, the model explicitly learns robust feature representations with robust proxies. To this end, firstly, we demonstrate that we can generate class-representative robust features by adding class-wise robust perturbations. Then, we use the class representative features as robust proxies. With the class-wise robust features, the model explicitly learns adversarially robust features through the proposed robust proxy",
    "path": "papers/23/06/2306.15457.json",
    "total_tokens": 938,
    "translated_title": "鲁棒代理学习: 提高对抗鲁棒性的方法",
    "translated_abstract": "最近，深度神经网络容易受到对抗攻击而容易被破坏，为了减轻对抗性的脆弱性，很多防御算法被提出。最近，为了提高对抗鲁棒性，许多研究试图通过对判别特征进行更多直接监督来增强特征表示。然而，现有的方法缺乏对对抗鲁棒特征表示的理解。在本文中，我们提出了一种新的训练框架，称为鲁棒代理学习。在提出的方法中，模型通过鲁棒代理显式学习鲁棒的特征表示。为此，首先，我们证明可以通过添加类别鲁棒扰动来生成代表类别的鲁棒特征。然后，我们使用类别代表特征作为鲁棒代理。通过类别鲁棒特征，模型显式地学习对抗性鲁棒特征。",
    "tldr": "该论文提出了一种名为鲁棒代理学习的训练框架，通过显式学习鲁棒的特征表示来提高对抗鲁棒性。通过添加类别鲁棒扰动生成代表类别的鲁棒特征，并将其作为鲁棒代理来学习对抗性鲁棒特征。",
    "en_tdlr": "This paper proposes a training framework called Robust Proxy Learning to improve adversarial robustness by explicitly learning robust feature representations. Class-representative robust features are generated by adding class-wise robust perturbations, and are used as robust proxies to learn adversarial robust features."
}