{
    "title": "Gradient-free optimization of highly smooth functions: improved analysis and a new algorithm. (arXiv:2306.02159v1 [math.ST])",
    "abstract": "This work studies minimization problems with zero-order noisy oracle information under the assumption that the objective function is highly smooth and possibly satisfies additional properties. We consider two kinds of zero-order projected gradient descent algorithms, which differ in the form of the gradient estimator. The first algorithm uses a gradient estimator based on randomization over the $\\ell_2$ sphere due to Bach and Perchet (2016). We present an improved analysis of this algorithm on the class of highly smooth and strongly convex functions studied in the prior work, and we derive rates of convergence for two more general classes of non-convex functions. Namely, we consider highly smooth functions satisfying the Polyak-{\\L}ojasiewicz condition and the class of highly smooth functions with no additional property. The second algorithm is based on randomization over the $\\ell_1$ sphere, and it extends to the highly smooth setting the algorithm that was recently proposed for Lipsc",
    "link": "http://arxiv.org/abs/2306.02159",
    "context": "Title: Gradient-free optimization of highly smooth functions: improved analysis and a new algorithm. (arXiv:2306.02159v1 [math.ST])\nAbstract: This work studies minimization problems with zero-order noisy oracle information under the assumption that the objective function is highly smooth and possibly satisfies additional properties. We consider two kinds of zero-order projected gradient descent algorithms, which differ in the form of the gradient estimator. The first algorithm uses a gradient estimator based on randomization over the $\\ell_2$ sphere due to Bach and Perchet (2016). We present an improved analysis of this algorithm on the class of highly smooth and strongly convex functions studied in the prior work, and we derive rates of convergence for two more general classes of non-convex functions. Namely, we consider highly smooth functions satisfying the Polyak-{\\L}ojasiewicz condition and the class of highly smooth functions with no additional property. The second algorithm is based on randomization over the $\\ell_1$ sphere, and it extends to the highly smooth setting the algorithm that was recently proposed for Lipsc",
    "path": "papers/23/06/2306.02159.json",
    "total_tokens": 907,
    "translated_title": "高光滑函数的无梯度优化：改进分析与新算法",
    "translated_abstract": "本文研究具有零阶嘈杂正则信息的最小化问题，假设目标函数高度光滑且可能满足附加属性。我们考虑两种零阶投影梯度下降算法，其梯度估计器形式不同。第一个算法使用基于Bach和Perchet（2016）的L2球上随机化的梯度估计器。我们在先前工作中研究的高光滑和强凸函数类上呈现了该算法的改进分析，并针对两个更一般的非凸函数类推导了收敛速率。即，我们考虑满足Polyak-Lojasiewicz条件的高光滑函数和没有附加属性的高光滑函数类。第二个算法基于L1球上的随机化，并将最近为Lipschitz函数提出的算法扩展到高光滑设置中。",
    "tldr": "本文研究了具有零阶嘈杂正则信息的最小化问题，针对高光滑函数类推导了两种零阶投影梯度下降算法的收敛速率。",
    "en_tdlr": "This work explores minimization problems where the objective function is highly smooth and may have additional properties, using two kinds of zero-order projected gradient descent algorithms. The article presents improved analysis for the first algorithm based on randomization over the l2 sphere, and introduces the second algorithm based on randomization over the l1 sphere. Rates of convergence are derived for highly smooth functions satisfying the Polyak-Lojasiewicz condition and the class of highly smooth functions with no additional property."
}