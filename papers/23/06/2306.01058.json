{
    "title": "Are Layout-Infused Language Models Robust to Layout Distribution Shifts? A Case Study with Scientific Documents. (arXiv:2306.01058v1 [cs.CL])",
    "abstract": "Recent work has shown that infusing layout features into language models (LMs) improves processing of visually-rich documents such as scientific papers. Layout-infused LMs are often evaluated on documents with familiar layout features (e.g., papers from the same publisher), but in practice models encounter documents with unfamiliar distributions of layout features, such as new combinations of text sizes and styles, or new spatial configurations of textual elements. In this work we test whether layout-infused LMs are robust to layout distribution shifts. As a case study we use the task of scientific document structure recovery, segmenting a scientific paper into its structural categories (e.g., \"title\", \"caption\", \"reference\"). To emulate distribution shifts that occur in practice we re-partition the GROTOAP2 dataset. We find that under layout distribution shifts model performance degrades by up to 20 F1. Simple training strategies, such as increasing training diversity, can reduce this",
    "link": "http://arxiv.org/abs/2306.01058",
    "context": "Title: Are Layout-Infused Language Models Robust to Layout Distribution Shifts? A Case Study with Scientific Documents. (arXiv:2306.01058v1 [cs.CL])\nAbstract: Recent work has shown that infusing layout features into language models (LMs) improves processing of visually-rich documents such as scientific papers. Layout-infused LMs are often evaluated on documents with familiar layout features (e.g., papers from the same publisher), but in practice models encounter documents with unfamiliar distributions of layout features, such as new combinations of text sizes and styles, or new spatial configurations of textual elements. In this work we test whether layout-infused LMs are robust to layout distribution shifts. As a case study we use the task of scientific document structure recovery, segmenting a scientific paper into its structural categories (e.g., \"title\", \"caption\", \"reference\"). To emulate distribution shifts that occur in practice we re-partition the GROTOAP2 dataset. We find that under layout distribution shifts model performance degrades by up to 20 F1. Simple training strategies, such as increasing training diversity, can reduce this",
    "path": "papers/23/06/2306.01058.json",
    "total_tokens": 973,
    "tldr": "本文测试了布局嵌入语言模型在处理布局不同的文档时的鲁棒性，并以科学文件结构恢复任务为例进行案例研究，结果发现模型性能在布局分布变化时下降多达20 F1，但增加训练多样性可以减少这种下降。"
}