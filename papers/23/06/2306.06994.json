{
    "title": "Correlated Time Series Self-Supervised Representation Learning via Spatiotemporal Bootstrapping. (arXiv:2306.06994v2 [cs.LG] UPDATED)",
    "abstract": "Correlated time series analysis plays an important role in many real-world industries. Learning an efficient representation of this large-scale data for further downstream tasks is necessary but challenging. In this paper, we propose a time-step-level representation learning framework for individual instances via bootstrapped spatiotemporal representation prediction. We evaluated the effectiveness and flexibility of our representation learning framework on correlated time series forecasting and cold-start transferring the forecasting model to new instances with limited data. A linear regression model trained on top of the learned representations demonstrates our model performs best in most cases. Especially compared to representation learning models, we reduce the RMSE, MAE, and MAPE by 37%, 49%, and 48% on the PeMS-BAY dataset, respectively. Furthermore, in real-world metro passenger flow data, our framework demonstrates the ability to transfer to infer future information of new cold-",
    "link": "http://arxiv.org/abs/2306.06994",
    "context": "Title: Correlated Time Series Self-Supervised Representation Learning via Spatiotemporal Bootstrapping. (arXiv:2306.06994v2 [cs.LG] UPDATED)\nAbstract: Correlated time series analysis plays an important role in many real-world industries. Learning an efficient representation of this large-scale data for further downstream tasks is necessary but challenging. In this paper, we propose a time-step-level representation learning framework for individual instances via bootstrapped spatiotemporal representation prediction. We evaluated the effectiveness and flexibility of our representation learning framework on correlated time series forecasting and cold-start transferring the forecasting model to new instances with limited data. A linear regression model trained on top of the learned representations demonstrates our model performs best in most cases. Especially compared to representation learning models, we reduce the RMSE, MAE, and MAPE by 37%, 49%, and 48% on the PeMS-BAY dataset, respectively. Furthermore, in real-world metro passenger flow data, our framework demonstrates the ability to transfer to infer future information of new cold-",
    "path": "papers/23/06/2306.06994.json",
    "total_tokens": 945,
    "translated_title": "基于时空自举的相关时间序列自监督表示学习",
    "translated_abstract": "相关时间序列分析在许多实际工业中起着重要作用。对大规模数据进行高效降维表示以便进行下游任务是必要但具有挑战性的。本文提出了一种基于时空自举表示预测的时间步级表示学习框架，以便为个体实例进行表示学习。我们在相关时间序列预测和将预测模型冷启动转移到数据受限的新实例方面评估了该表示学习框架的有效性和灵活性。经过训练在学习表示上的线性回归模型证明了在大多数情况下我们的模型表现最佳。特别地，在与表示学习模型的比较中，我们在PeMS-BAY数据集上将RMSE、MAE和MAPE分别减少了37％、49％和48％。在实际的地铁客流数据中，我们的框架展示了将预测能力转移到新的冷启动情况下的能力。",
    "tldr": "该论文提出了一种基于时空自举的时间步级表示学习框架，能为相关时间序列分析提供高效降维表示，并通过在PeMS-BAY数据集上的测试取得了较好的效果。"
}