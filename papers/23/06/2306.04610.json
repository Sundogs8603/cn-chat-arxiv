{
    "title": "The Two Word Test: A Semantic Benchmark for Large Language Models. (arXiv:2306.04610v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs) have shown remarkable abilities recently, including passing advanced professional exams and demanding benchmark tests. This performance has led many to suggest that they are close to achieving humanlike or 'true' understanding of language, and even Artificial General Intelligence (AGI). Here, we provide a new open-source benchmark that can assess semantic abilities of LLMs using two-word phrases using a task that can be performed relatively easily by humans without advanced training. Combining multiple words into a single concept is a fundamental aspect of human language and intelligence. The test requires meaningfulness judgments of 1768 noun-noun combinations that have been rated as meaningful (e.g., baby boy) or not meaningful (e.g., goat sky). by 150 human raters. We provide versions of the task that probe meaningfulness ratings on a 0-4 scale as well as binary judgments. We conducted a series of experiments using the TWT on GPT-4, GPT-3.5, and Bard, wi",
    "link": "http://arxiv.org/abs/2306.04610",
    "context": "Title: The Two Word Test: A Semantic Benchmark for Large Language Models. (arXiv:2306.04610v1 [cs.CL])\nAbstract: Large Language Models (LLMs) have shown remarkable abilities recently, including passing advanced professional exams and demanding benchmark tests. This performance has led many to suggest that they are close to achieving humanlike or 'true' understanding of language, and even Artificial General Intelligence (AGI). Here, we provide a new open-source benchmark that can assess semantic abilities of LLMs using two-word phrases using a task that can be performed relatively easily by humans without advanced training. Combining multiple words into a single concept is a fundamental aspect of human language and intelligence. The test requires meaningfulness judgments of 1768 noun-noun combinations that have been rated as meaningful (e.g., baby boy) or not meaningful (e.g., goat sky). by 150 human raters. We provide versions of the task that probe meaningfulness ratings on a 0-4 scale as well as binary judgments. We conducted a series of experiments using the TWT on GPT-4, GPT-3.5, and Bard, wi",
    "path": "papers/23/06/2306.04610.json",
    "total_tokens": 959,
    "translated_title": "一个语义基准测试：用于大型语言模型的两个词测试",
    "translated_abstract": "大型语言模型（LLM）近来表现出了令人瞩目的能力，包括通过高级专业考试和苛刻的基准测试。这种性能使许多人认为它们接近于实现人类或“真正的”语言理解，甚至人工通用智能（AGI）。在这里，我们提供了一个新的开源基准测试，可以使用两个单词短语评估LLMs的语义能力，该任务可以相对容易地由没有高级培训的人类完成。将多个词组合成一个概念是人类语言和智能的基本方面。该测试需要对1768个评为有意义（例如baby boy）或不具有意义（例如goat sky）的名词组合进行有意义性判断，由150个人类评定者进行评定。我们提供了在0-4量表上探测有意义评分以及二进制判断的任务版本。我们使用TWT在GPT-4、GPT-3.5和Bard上进行了一系列实验。",
    "tldr": "这篇论文提出了一个新的开源基准测试——“两个词测试”，用于评估大型语言模型的语义能力。测试需要对1768个名词组合进行意义性判断，并可用于评估0-4量表上的有意义评分和二进制判断。",
    "en_tdlr": "This paper proposes a new open-source benchmark called the \"Two Word Test\" (TWT) to assess the semantic abilities of large language models (LLMs) using two-word phrases, which can be evaluated by humans without advanced training. The test requires meaningfulness judgments of 1768 noun-noun combinations, and can be used to evaluate meaningfulness ratings on a 0-4 scale as well as binary judgments."
}