{
    "title": "How Many Answers Should I Give? An Empirical Study of Multi-Answer Reading Comprehension. (arXiv:2306.00435v1 [cs.CL])",
    "abstract": "The multi-answer phenomenon, where a question may have multiple answers scattered in the document, can be well handled by humans but is challenging enough for machine reading comprehension (MRC) systems. Despite recent progress in multi-answer MRC, there lacks a systematic analysis of how this phenomenon arises and how to better address it. In this work, we design a taxonomy to categorize commonly-seen multi-answer MRC instances, with which we inspect three multi-answer datasets and analyze where the multi-answer challenge comes from. We further analyze how well different paradigms of current multi-answer MRC models deal with different types of multi-answer instances. We find that some paradigms capture well the key information in the questions while others better model the relationship between questions and contexts. We thus explore strategies to make the best of the strengths of different paradigms. Experiments show that generation models can be a promising platform to incorporate di",
    "link": "http://arxiv.org/abs/2306.00435",
    "context": "Title: How Many Answers Should I Give? An Empirical Study of Multi-Answer Reading Comprehension. (arXiv:2306.00435v1 [cs.CL])\nAbstract: The multi-answer phenomenon, where a question may have multiple answers scattered in the document, can be well handled by humans but is challenging enough for machine reading comprehension (MRC) systems. Despite recent progress in multi-answer MRC, there lacks a systematic analysis of how this phenomenon arises and how to better address it. In this work, we design a taxonomy to categorize commonly-seen multi-answer MRC instances, with which we inspect three multi-answer datasets and analyze where the multi-answer challenge comes from. We further analyze how well different paradigms of current multi-answer MRC models deal with different types of multi-answer instances. We find that some paradigms capture well the key information in the questions while others better model the relationship between questions and contexts. We thus explore strategies to make the best of the strengths of different paradigms. Experiments show that generation models can be a promising platform to incorporate di",
    "path": "papers/23/06/2306.00435.json",
    "total_tokens": 877,
    "translated_title": "我应该给几个答案？多答案阅读理解的实证研究",
    "translated_abstract": "多答案现象意味着问题可能在文档中有多个答案，人类可以处理得很好，但对于机器阅读理解系统来说很具有挑战性。本研究设计了一个分类法来分类常见的多答案阅读理解实例，并分析多答案挑战的来源，同时分析了不同模型范例如何处理不同类型的多答案实例。我们发现，某些范例很好地捕获了问题中的关键信息，而另一些范例则更好地建立了问题和上下文之间的关系。因此，我们探索了利用不同模型范例的优势的策略。实验结果表明，生成模型是整合不同模型范例的有前途的平台。",
    "tldr": "研究设计分类法来分类常见多答案阅读理解实例，分析模型范例处理不同类型多答案实例的效果，发现某些模型范例更擅长捕获问题关键信息，而其他范例则更适合建立问题和上下文之间的关系。生成模型整合不同范例的优势，具有前景。",
    "en_tdlr": "This work presents a taxonomy to categorize multi-answer reading comprehension instances and analyzes the challenges they present to machine reading comprehension systems. The authors explore strategies to combine the strengths of different model paradigms and find that generation models show promise for integrating different model approaches."
}