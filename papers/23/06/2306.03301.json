{
    "title": "Estimating Conditional Mutual Information for Dynamic Feature Selection. (arXiv:2306.03301v1 [cs.LG])",
    "abstract": "Dynamic feature selection, where we sequentially query features to make accurate predictions with a minimal budget, is a promising paradigm to reduce feature acquisition costs and provide transparency into the prediction process. The problem is challenging, however, as it requires both making predictions with arbitrary feature sets and learning a policy to identify the most valuable selections. Here, we take an information-theoretic perspective and prioritize features based on their mutual information with the response variable. The main challenge is learning this selection policy, and we design a straightforward new modeling approach that estimates the mutual information in a discriminative rather than generative fashion. Building on our learning approach, we introduce several further improvements: allowing variable feature budgets across samples, enabling non-uniform costs between features, incorporating prior information, and exploring modern architectures to handle partial input in",
    "link": "http://arxiv.org/abs/2306.03301",
    "context": "Title: Estimating Conditional Mutual Information for Dynamic Feature Selection. (arXiv:2306.03301v1 [cs.LG])\nAbstract: Dynamic feature selection, where we sequentially query features to make accurate predictions with a minimal budget, is a promising paradigm to reduce feature acquisition costs and provide transparency into the prediction process. The problem is challenging, however, as it requires both making predictions with arbitrary feature sets and learning a policy to identify the most valuable selections. Here, we take an information-theoretic perspective and prioritize features based on their mutual information with the response variable. The main challenge is learning this selection policy, and we design a straightforward new modeling approach that estimates the mutual information in a discriminative rather than generative fashion. Building on our learning approach, we introduce several further improvements: allowing variable feature budgets across samples, enabling non-uniform costs between features, incorporating prior information, and exploring modern architectures to handle partial input in",
    "path": "papers/23/06/2306.03301.json",
    "total_tokens": 851,
    "translated_title": "动态特征选择中条件互信息的估计",
    "translated_abstract": "动态特征选择是一种有前途的范例，它通过顺序查询特征以在最小的预算内进行准确预测，以减少特征获取成本，并为预测过程提供透明度。尽管如此，这个问题很具有挑战性，因为它要求使用任意特征集进行预测，并学习策略以确定最有价值的选择。本文从信息理论的角度出发，根据特征与响应变量的互信息对特征进行优先级排序。其中的主要挑战是学习此选择策略，我们设计了一个直接新的建模方法，以判别而非生成模式估计互信息。建立在我们的学习方法之上，我们引入了几个进一步的改进：允许在样本之间进行可变的特征预算、支持不同特征之间的非均匀成本、结合先前的信息和探究现代架构以处理部分输入。",
    "tldr": "本文提出了一种动态特征选择方法，该方法基于特征与响应变量的互信息进行优先级排序，并设计了估计互信息的判别式方法。同时，本文还引入了多项改进措施以应对更多场景。",
    "en_tdlr": "This paper proposes a dynamic feature selection method that prioritizes features based on their mutual information with the response variable, and designs a discriminative approach to estimate mutual information. Meanwhile, several further improvements are introduced to deal with more scenarios."
}