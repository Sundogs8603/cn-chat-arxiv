{
    "title": "Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation. (arXiv:2306.07306v1 [cs.CV])",
    "abstract": "Explainability poses a major challenge to artificial intelligence (AI) techniques. Current studies on explainable AI (XAI) lack the efficiency of extracting global knowledge about the learning task, thus suffer deficiencies such as imprecise saliency, context-aware absence and vague meaning. In this paper, we propose the class association embedding (CAE) approach to address these issues. We employ an encoder-decoder architecture to embed sample features and separate them into class-related and individual-related style vectors simultaneously. Recombining the individual-style code of a given sample with the class-style code of another leads to a synthetic sample with preserved individual characters but changed class assignment, following a cyclic adversarial learning strategy. Class association embedding distills the global class-related features of all instances into a unified domain with well separation between classes. The transition rules between different classes can be then extract",
    "link": "http://arxiv.org/abs/2306.07306",
    "context": "Title: Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation. (arXiv:2306.07306v1 [cs.CV])\nAbstract: Explainability poses a major challenge to artificial intelligence (AI) techniques. Current studies on explainable AI (XAI) lack the efficiency of extracting global knowledge about the learning task, thus suffer deficiencies such as imprecise saliency, context-aware absence and vague meaning. In this paper, we propose the class association embedding (CAE) approach to address these issues. We employ an encoder-decoder architecture to embed sample features and separate them into class-related and individual-related style vectors simultaneously. Recombining the individual-style code of a given sample with the class-style code of another leads to a synthetic sample with preserved individual characters but changed class assignment, following a cyclic adversarial learning strategy. Class association embedding distills the global class-related features of all instances into a unified domain with well separation between classes. The transition rules between different classes can be then extract",
    "path": "papers/23/06/2306.07306.json",
    "total_tokens": 1001,
    "translated_title": "基于类别关联嵌入和循环对抗生成的医学图像全局可解释学习",
    "translated_abstract": "可解释性是人工智能技术面临的主要挑战。当前关于可解释人工智能（XAI）的研究缺乏提取关于学习任务的全局知识的效率，因此存在精度不确定、缺乏上下文信息和定义模糊等缺陷。本文提出了类别关联嵌入（CAE）方法来解决这些问题。我们采用编码器-解码器结构，同时将样本特征分离成与类别相关的和个体相关的风格向量。将给定样本的个体风格码与另一个类别风格码重新组合，按照循环对抗学习策略得到一个保留个体特征但改变了类别指定的合成样本。类别关联嵌入将所有实例的全局类相关特征提炼到一个统一的域中，不同类之间的转换规则可以更好地提取和可视化，以获得更好的透明度。我们在医学图像数据集上进行实验，比现有技术获得更优异的性能，并提供全局可解释的可视化结果以便于诊断过程。",
    "tldr": "本文提出了一种类别关联嵌入（CAE）方法，采用编码器-解码器结构将样本特征分离成与类别相关的风格向量，实现了医学图像全局可解释的学习。"
}