{
    "title": "Balancing of competitive two-player Game Levels with Reinforcement Learning. (arXiv:2306.04429v1 [cs.LG])",
    "abstract": "The balancing process for game levels in a competitive two-player context involves a lot of manual work and testing, particularly in non-symmetrical game levels. In this paper, we propose an architecture for automated balancing of tile-based levels within the recently introduced PCGRL framework (procedural content generation via reinforcement learning). Our architecture is divided into three parts: (1) a level generator, (2) a balancing agent and, (3) a reward modeling simulation. By playing the level in a simulation repeatedly, the balancing agent is rewarded for modifying it towards the same win rates for all players. To this end, we introduce a novel family of swap-based representations to increase robustness towards playability. We show that this approach is capable to teach an agent how to alter a level for balancing better and faster than plain PCGRL. In addition, by analyzing the agent's swapping behavior, we can draw conclusions about which tile types influence the balancing mo",
    "link": "http://arxiv.org/abs/2306.04429",
    "context": "Title: Balancing of competitive two-player Game Levels with Reinforcement Learning. (arXiv:2306.04429v1 [cs.LG])\nAbstract: The balancing process for game levels in a competitive two-player context involves a lot of manual work and testing, particularly in non-symmetrical game levels. In this paper, we propose an architecture for automated balancing of tile-based levels within the recently introduced PCGRL framework (procedural content generation via reinforcement learning). Our architecture is divided into three parts: (1) a level generator, (2) a balancing agent and, (3) a reward modeling simulation. By playing the level in a simulation repeatedly, the balancing agent is rewarded for modifying it towards the same win rates for all players. To this end, we introduce a novel family of swap-based representations to increase robustness towards playability. We show that this approach is capable to teach an agent how to alter a level for balancing better and faster than plain PCGRL. In addition, by analyzing the agent's swapping behavior, we can draw conclusions about which tile types influence the balancing mo",
    "path": "papers/23/06/2306.04429.json",
    "total_tokens": 921,
    "translated_title": "使用强化学习平衡竞争双人游戏水平",
    "translated_abstract": "在竞争性的双人游戏中，游戏水平的平衡需要大量手动工作和测试，特别是在非对称的游戏水平中。本文提出了一种在最近推出的PCGRL框架中自动平衡基于图块的级别的架构。我们的架构分为三个部分：(1)级别生成器，(2)平衡代理和(3)奖励建模模拟。通过在模拟中反复玩游戏水平，平衡代理会根据所有玩家的相同胜率对其进行修改而受到奖励。为此，我们引入了一种新颖的基于交换的表示方法，以增加对可玩性的健壮性。我们表明，这种方法能够教会代理更好、更快地改变平衡级别，而不是简单的PCGRL。此外，通过分析代理的交换行为，我们可以得出哪些图块类型影响了平衡。",
    "tldr": "本研究使用PCGRL框架和强化学习算法，提出了一种自动平衡基于图块的竞争性双人游戏级别的架构，其中引入了新型基于交换的表示方法，并通过分析代理的交换行为来判断哪些图块类型影响平衡。"
}