{
    "title": "Unveiling the Potential of Sentiment: Can Large Language Models Predict Chinese Stock Price Movements?. (arXiv:2306.14222v1 [cs.CL])",
    "abstract": "The rapid advancement of Large Language Models (LLMs) has led to extensive discourse regarding their potential to boost the return of quantitative stock trading strategies. This discourse primarily revolves around harnessing the remarkable comprehension capabilities of LLMs to extract sentiment factors which facilitate informed and high-frequency investment portfolio adjustments. To ensure successful implementations of these LLMs into the analysis of Chinese financial texts and the subsequent trading strategy development within the Chinese stock market, we provide a rigorous and encompassing benchmark as well as a standardized back-testing framework aiming at objectively assessing the efficacy of various types of LLMs in the specialized domain of sentiment factor extraction from Chinese news text data. To illustrate how our benchmark works, we reference three distinctive models: 1) the generative LLM (ChatGPT), 2) the Chinese language-specific pre-trained LLM (Erlangshen-RoBERTa), and ",
    "link": "http://arxiv.org/abs/2306.14222",
    "context": "Title: Unveiling the Potential of Sentiment: Can Large Language Models Predict Chinese Stock Price Movements?. (arXiv:2306.14222v1 [cs.CL])\nAbstract: The rapid advancement of Large Language Models (LLMs) has led to extensive discourse regarding their potential to boost the return of quantitative stock trading strategies. This discourse primarily revolves around harnessing the remarkable comprehension capabilities of LLMs to extract sentiment factors which facilitate informed and high-frequency investment portfolio adjustments. To ensure successful implementations of these LLMs into the analysis of Chinese financial texts and the subsequent trading strategy development within the Chinese stock market, we provide a rigorous and encompassing benchmark as well as a standardized back-testing framework aiming at objectively assessing the efficacy of various types of LLMs in the specialized domain of sentiment factor extraction from Chinese news text data. To illustrate how our benchmark works, we reference three distinctive models: 1) the generative LLM (ChatGPT), 2) the Chinese language-specific pre-trained LLM (Erlangshen-RoBERTa), and ",
    "path": "papers/23/06/2306.14222.json",
    "total_tokens": 937,
    "translated_title": "揭示情感的潜力：大型语言模型能否预测中国股票价格波动？",
    "translated_abstract": "大型语言模型 (LLMs) 的快速发展已引发了广泛的讨论，其中包括它们将如何提高量化股票交易策略的回报的潜力。这些讨论主要围绕着利用 LLMs 的出色理解能力来提取情感因素，从而促进知情和高频的投资组合调整。为了确保这些 LLMs 成功地应用于中国金融文本分析和随后的中国股票市场交易策略开发中，我们提供了一个严格和全面的基准测试以及一个标准化的回测框架，旨在客观评估不同类型 LLMs 在中文新闻文本数据的情感因素提取中的效果。为了说明我们基准测试的工作方式，我们引用了三个不同模型：1）生成式 LLM (ChatGPT)，2）中文语言特定的预训练 LLM (二郎神 RoBERTa)，以及……",
    "tldr": "本篇论文研究如何运用大型语言模型提取中文新闻文本信息的情感因素，以期促进知情和高频的投资组合调整。通过建立严格和全面的基准测试与标准化的回测框架，作者对不同类型 LLMs 在该领域内的效果进行了客观评估。",
    "en_tdlr": "This paper discusses how to use large language models to extract sentiment factors from Chinese news text data to facilitate informed and high-frequency investment portfolio adjustments. By establishing a rigorous and comprehensive benchmark and a standardized back-testing framework, the authors objectively evaluate the efficacy of various types of LLMs in this domain."
}