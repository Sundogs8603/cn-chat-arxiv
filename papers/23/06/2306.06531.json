{
    "title": "AutoTAMP: Autoregressive Task and Motion Planning with LLMs as Translators and Checkers. (arXiv:2306.06531v2 [cs.RO] UPDATED)",
    "abstract": "For effective human-robot interaction, robots need to understand, plan, and execute complex, long-horizon tasks described by natural language. Recent advances in large language models (LLMs) have shown promise for translating natural language into robot action sequences for complex tasks. However, existing approaches either translate the natural language directly into robot trajectories or factor the inference process by decomposing language into task sub-goals and relying on a motion planner to execute each sub-goal. When complex environmental and temporal constraints are involved, inference over planning tasks must be performed jointly with motion plans using traditional task-and-motion planning (TAMP) algorithms, making factorization into subgoals untenable. Rather than using LLMs to directly plan task sub-goals, we instead perform few-shot translation from natural language task descriptions to an intermediate task representation that can then be consumed by a TAMP algorithm to join",
    "link": "http://arxiv.org/abs/2306.06531",
    "context": "Title: AutoTAMP: Autoregressive Task and Motion Planning with LLMs as Translators and Checkers. (arXiv:2306.06531v2 [cs.RO] UPDATED)\nAbstract: For effective human-robot interaction, robots need to understand, plan, and execute complex, long-horizon tasks described by natural language. Recent advances in large language models (LLMs) have shown promise for translating natural language into robot action sequences for complex tasks. However, existing approaches either translate the natural language directly into robot trajectories or factor the inference process by decomposing language into task sub-goals and relying on a motion planner to execute each sub-goal. When complex environmental and temporal constraints are involved, inference over planning tasks must be performed jointly with motion plans using traditional task-and-motion planning (TAMP) algorithms, making factorization into subgoals untenable. Rather than using LLMs to directly plan task sub-goals, we instead perform few-shot translation from natural language task descriptions to an intermediate task representation that can then be consumed by a TAMP algorithm to join",
    "path": "papers/23/06/2306.06531.json",
    "total_tokens": 891,
    "translated_title": "AutoTAMP: 使用LLMs作为翻译器和检查器的自回归任务和动作规划",
    "translated_abstract": "为了实现有效的人机交互，机器人需要理解、规划和执行由自然语言描述的复杂、长期任务。最近大型语言模型（LLMs）的进展已经显示出了将自然语言翻译为机器人行动序列的潜力，用于复杂任务。然而，现有的方法要么直接将自然语言翻译为机器人轨迹，要么通过将语言分解为任务子目标并依靠动作规划器执行每个子目标来分解推理过程。当涉及复杂的环境和时间约束时，必须使用传统的任务和动作规划（TAMP）算法来联合进行规划任务的推理和动作规划，使得分解为子目标成为不可行的。我们使用LLMs来直接规划任务子目标，而是从自然语言任务描述中进行少样本翻译，生成一个中间任务表示，然后可以由TAMP算法消化该表示来进行规划。",
    "tldr": "AutoTAMP提出了一种使用LLMs作为翻译器和检查器的自回归任务和动作规划方法，通过少样本翻译将自然语言任务描述转换为中间任务表示，以实现对复杂任务的规划和执行。"
}