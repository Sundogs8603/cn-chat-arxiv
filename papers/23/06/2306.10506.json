{
    "title": "Fast Conditional Mixing of MCMC Algorithms for Non-log-concave Distributions. (arXiv:2306.10506v2 [cs.LG] UPDATED)",
    "abstract": "MCMC algorithms offer empirically efficient tools for sampling from a target distribution $\\pi(x) \\propto \\exp(-V(x))$. However, on the theory side, MCMC algorithms suffer from slow mixing rate when $\\pi(x)$ is non-log-concave. Our work examines this gap and shows that when Poincar\\'e-style inequality holds on a subset $\\mathcal{X}$ of the state space, the conditional distribution of MCMC iterates over $\\mathcal{X}$ mixes fast to the true conditional distribution. This fast mixing guarantee can hold in cases when global mixing is provably slow. We formalize the statement and quantify the conditional mixing rate. We further show that conditional mixing can have interesting implications for sampling from mixtures of Gaussians, parameter estimation for Gaussian mixture models and Gibbs-sampling with well-connected local minima.",
    "link": "http://arxiv.org/abs/2306.10506",
    "context": "Title: Fast Conditional Mixing of MCMC Algorithms for Non-log-concave Distributions. (arXiv:2306.10506v2 [cs.LG] UPDATED)\nAbstract: MCMC algorithms offer empirically efficient tools for sampling from a target distribution $\\pi(x) \\propto \\exp(-V(x))$. However, on the theory side, MCMC algorithms suffer from slow mixing rate when $\\pi(x)$ is non-log-concave. Our work examines this gap and shows that when Poincar\\'e-style inequality holds on a subset $\\mathcal{X}$ of the state space, the conditional distribution of MCMC iterates over $\\mathcal{X}$ mixes fast to the true conditional distribution. This fast mixing guarantee can hold in cases when global mixing is provably slow. We formalize the statement and quantify the conditional mixing rate. We further show that conditional mixing can have interesting implications for sampling from mixtures of Gaussians, parameter estimation for Gaussian mixture models and Gibbs-sampling with well-connected local minima.",
    "path": "papers/23/06/2306.10506.json",
    "total_tokens": 959,
    "translated_title": "针对非对数凹分布的MCMC算法快速条件混合",
    "translated_abstract": "MCMC算法为从目标分布$\\pi(x) \\propto \\exp(-V(x))$中采样提供了经验高效的工具。然而，在理论方面，当$\\pi(x)$是非对数凹时，MCMC算法的混合速度较慢。我们的工作研究了这一差距，并表明当Poincar\\'e型不等式成立时，状态空间子集$\\mathcal{X}$上的MCMC迭代的条件分布混合快速收敛到真实的条件分布。这种快速混合保证可以在全局混合已被证明较慢的情况下成立。我们将该声明形式化并量化了条件混合率。此外，我们还展示了条件混合对于从高斯混合物中采样、高斯混合模型的参数估计以及具有良好连接的局部极小值的吉布斯采样会产生有趣的影响。",
    "tldr": "本论文研究了针对非对数凹分布的MCMC算法的条件混合问题，通过分析Poincar\\'e型不等式在状态空间子集上的成立情况，发现条件分布的混合速度快于全局混合速度，对于方差混合模型的采样、参数估计以及具有良好连接的局部极小值的吉布斯采样等问题具有重要影响。",
    "en_tdlr": "This paper examines the problem of conditional mixing in MCMC algorithms for non-log-concave distributions. By analyzing the validity of the Poincar\\'e-style inequality on a subset of the state space, it shows that the conditional distribution mixes faster than the global mixing rate, which has important implications for sampling from mixture models, parameter estimation, and Gibbs sampling with well-connected local minima."
}