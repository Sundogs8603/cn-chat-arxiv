{
    "title": "MO-VLN: A Multi-Task Benchmark for Open-set Zero-Shot Vision-and-Language Navigation. (arXiv:2306.10322v2 [cs.CV] UPDATED)",
    "abstract": "Given a natural language, a general robot has to comprehend the instruction and find the target object or location based on visual observations even in unexplored environments. Most agents rely on massive diverse training data to achieve better generalization, which requires expensive labor. These agents often focus on common objects and fewer tasks, thus are not intelligent enough to handle different types of instructions. To facilitate research in open-set vision-and-language navigation, we propose a benchmark named MO-VLN, aiming at testing the effectiveness and generalization of the agent in the multi-task setting. First, we develop a 3D simulator rendered by realistic scenarios using Unreal Engine 5, containing more realistic lights and details. The simulator contains three scenes, i.e., cafe, restaurant, and nursing house, of high value in the industry. Besides, our simulator involves multiple uncommon objects, such as takeaway cup and medical adhesive tape, which are more compli",
    "link": "http://arxiv.org/abs/2306.10322",
    "context": "Title: MO-VLN: A Multi-Task Benchmark for Open-set Zero-Shot Vision-and-Language Navigation. (arXiv:2306.10322v2 [cs.CV] UPDATED)\nAbstract: Given a natural language, a general robot has to comprehend the instruction and find the target object or location based on visual observations even in unexplored environments. Most agents rely on massive diverse training data to achieve better generalization, which requires expensive labor. These agents often focus on common objects and fewer tasks, thus are not intelligent enough to handle different types of instructions. To facilitate research in open-set vision-and-language navigation, we propose a benchmark named MO-VLN, aiming at testing the effectiveness and generalization of the agent in the multi-task setting. First, we develop a 3D simulator rendered by realistic scenarios using Unreal Engine 5, containing more realistic lights and details. The simulator contains three scenes, i.e., cafe, restaurant, and nursing house, of high value in the industry. Besides, our simulator involves multiple uncommon objects, such as takeaway cup and medical adhesive tape, which are more compli",
    "path": "papers/23/06/2306.10322.json",
    "total_tokens": 967,
    "translated_title": "MO-VLN:一个用于开放集合零样本视觉和语言导航的多任务基准 (arXiv:2306.10322v2 [cs.CV] 更新)",
    "translated_abstract": "给定一个自然语言，一个通用的机器人必须理解指令并根据视觉观察找到目标对象或位置，即使在未探索的环境中也能做到。大多数代理依赖于大量多样的训练数据以实现更好的泛化，这需要昂贵的劳动力。这些代理通常只关注常见的对象和较少的任务，因此不足以处理不同类型的指令。为了促进开放集合视觉和语言导航的研究，我们提出了一个名为MO-VLN的基准，旨在测试代理在多任务设置中的有效性和泛化能力。首先，我们使用虚幻引擎5开发了一个3D模拟器，渲染了逼真的场景，包含更真实的光照和细节。模拟器包含三个场景，即咖啡馆、餐厅和养老院，这些场景在工业中具有很高的价值。此外，我们的模拟器涉及多种不常见的物体，如外卖杯和医用胶带，这些物体更加复杂。",
    "tldr": "MO-VLN是一个用于评估通用机器人在多任务环境中的视觉和语言导航的基准，通过使用虚幻引擎5开发逼真的场景和包含多种不常见物体来测试其效果和泛化能力。"
}