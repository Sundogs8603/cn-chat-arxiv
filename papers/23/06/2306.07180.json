{
    "title": "Diffusion Models for Black-Box Optimization. (arXiv:2306.07180v2 [cs.LG] UPDATED)",
    "abstract": "The goal of offline black-box optimization (BBO) is to optimize an expensive black-box function using a fixed dataset of function evaluations. Prior works consider forward approaches that learn surrogates to the black-box function and inverse approaches that directly map function values to corresponding points in the input domain of the black-box function. These approaches are limited by the quality of the offline dataset and the difficulty in learning one-to-many mappings in high dimensions, respectively. We propose Denoising Diffusion Optimization Models (DDOM), a new inverse approach for offline black-box optimization based on diffusion models. Given an offline dataset, DDOM learns a conditional generative model over the domain of the black-box function conditioned on the function values. We investigate several design choices in DDOM, such as re-weighting the dataset to focus on high function values and the use of classifier-free guidance at test-time to enable generalization to fun",
    "link": "http://arxiv.org/abs/2306.07180",
    "context": "Title: Diffusion Models for Black-Box Optimization. (arXiv:2306.07180v2 [cs.LG] UPDATED)\nAbstract: The goal of offline black-box optimization (BBO) is to optimize an expensive black-box function using a fixed dataset of function evaluations. Prior works consider forward approaches that learn surrogates to the black-box function and inverse approaches that directly map function values to corresponding points in the input domain of the black-box function. These approaches are limited by the quality of the offline dataset and the difficulty in learning one-to-many mappings in high dimensions, respectively. We propose Denoising Diffusion Optimization Models (DDOM), a new inverse approach for offline black-box optimization based on diffusion models. Given an offline dataset, DDOM learns a conditional generative model over the domain of the black-box function conditioned on the function values. We investigate several design choices in DDOM, such as re-weighting the dataset to focus on high function values and the use of classifier-free guidance at test-time to enable generalization to fun",
    "path": "papers/23/06/2306.07180.json",
    "total_tokens": 899,
    "translated_title": "黑盒优化的扩散模型",
    "translated_abstract": "离线黑盒优化的目标是利用固定的函数评估数据集来优化一个昂贵的黑盒函数。过去的工作考虑了前向方法和反向方法。前向方法学习黑盒函数的替代模型，而反向方法直接将函数值映射到输入域的相应点。然而，这些方法受限于离线数据集的质量和在高维度中学习一对多映射的困难。我们提出了一种基于扩散模型的离线黑盒优化的新的反向方法，称为去噪扩散优化模型（DDOM）。给定一个离线数据集，DDOM学习一个基于黑盒函数域上的条件生成模型，该模型以函数值为条件。我们研究了DDOM中的几种设计选择，例如对数据集进行重新加权以便重点关注高函数值，以及在测试时使用无分类器指导以实现泛化能力。",
    "tldr": "提出了一种基于扩散模型的离线黑盒优化的反向方法，称为去噪扩散优化模型（DDOM）。DDOM通过学习黑盒函数值条件下的生成模型来优化黑盒函数，克服了数据集质量和高维度下一对多映射困难的限制。",
    "en_tdlr": "A new inverse approach called Denoising Diffusion Optimization Models (DDOM) is proposed for offline black-box optimization. DDOM overcomes the limitations of dataset quality and difficulty in learning one-to-many mappings in high dimensions by learning a conditional generative model over the domain of the black-box function conditioned on the function values."
}