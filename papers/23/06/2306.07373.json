{
    "title": "EriBERTa: A Bilingual Pre-Trained Language Model for Clinical Natural Language Processing. (arXiv:2306.07373v1 [cs.CL])",
    "abstract": "The utilization of clinical reports for various secondary purposes, including health research and treatment monitoring, is crucial for enhancing patient care. Natural Language Processing (NLP) tools have emerged as valuable assets for extracting and processing relevant information from these reports. However, the availability of specialized language models for the clinical domain in Spanish has been limited.  In this paper, we introduce EriBERTa, a bilingual domain-specific language model pre-trained on extensive medical and clinical corpora. We demonstrate that EriBERTa outperforms previous Spanish language models in the clinical domain, showcasing its superior capabilities in understanding medical texts and extracting meaningful information. Moreover, EriBERTa exhibits promising transfer learning abilities, allowing for knowledge transfer from one language to another. This aspect is particularly beneficial given the scarcity of Spanish clinical data.",
    "link": "http://arxiv.org/abs/2306.07373",
    "context": "Title: EriBERTa: A Bilingual Pre-Trained Language Model for Clinical Natural Language Processing. (arXiv:2306.07373v1 [cs.CL])\nAbstract: The utilization of clinical reports for various secondary purposes, including health research and treatment monitoring, is crucial for enhancing patient care. Natural Language Processing (NLP) tools have emerged as valuable assets for extracting and processing relevant information from these reports. However, the availability of specialized language models for the clinical domain in Spanish has been limited.  In this paper, we introduce EriBERTa, a bilingual domain-specific language model pre-trained on extensive medical and clinical corpora. We demonstrate that EriBERTa outperforms previous Spanish language models in the clinical domain, showcasing its superior capabilities in understanding medical texts and extracting meaningful information. Moreover, EriBERTa exhibits promising transfer learning abilities, allowing for knowledge transfer from one language to another. This aspect is particularly beneficial given the scarcity of Spanish clinical data.",
    "path": "papers/23/06/2306.07373.json",
    "total_tokens": 912,
    "translated_title": "EriBERTa：用于临床自然语言处理的双语预训练语言模型",
    "translated_abstract": "临床报告的使用对于提高患者护理至关重要，包括健康研究和治疗监控等多个次要用途。自然语言处理工具已成为从这些报告中提取和处理相关信息的有价值资产。然而，专门针对西班牙语临床领域的语言模型的可用性有限。在本文中，我们介绍EriBERTa，这是一个在广泛的医疗和临床语料库上预训练的双语领域特定语言模型。我们展示了EriBERTa在临床领域中胜过先前的西班牙语语言模型，展示了它在理解医学文本和提取有意义信息方面的强大能力。此外，EriBERTa展现出有希望的迁移学习能力，允许从一种语言向另一种语言进行知识转移。鉴于西班牙语临床数据的稀缺性，这一方面特别有益。",
    "tldr": "EriBERTa是一个针对临床领域预训练的双语语言模型，展示了在理解医学文本和提取有意义信息方面的强大能力，并具有从一种语言向另一种语言进行知识转移的迁移学习能力。"
}