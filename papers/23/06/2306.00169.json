{
    "title": "Inconsistency, Instability, and Generalization Gap of Deep Neural Network Training. (arXiv:2306.00169v1 [cs.LG])",
    "abstract": "As deep neural networks are highly expressive, it is important to find solutions with small generalization gap (the difference between the performance on the training data and unseen data). Focusing on the stochastic nature of training, we first present a theoretical analysis in which the bound of generalization gap depends on what we call inconsistency and instability of model outputs, which can be estimated on unlabeled data. Our empirical study based on this analysis shows that instability and inconsistency are strongly predictive of generalization gap in various settings. In particular, our finding indicates that inconsistency is a more reliable indicator of generalization gap than the sharpness of the loss landscape. Furthermore, we show that algorithmic reduction of inconsistency leads to superior performance. The results also provide a theoretical basis for existing methods such as co-distillation and ensemble.",
    "link": "http://arxiv.org/abs/2306.00169",
    "context": "Title: Inconsistency, Instability, and Generalization Gap of Deep Neural Network Training. (arXiv:2306.00169v1 [cs.LG])\nAbstract: As deep neural networks are highly expressive, it is important to find solutions with small generalization gap (the difference between the performance on the training data and unseen data). Focusing on the stochastic nature of training, we first present a theoretical analysis in which the bound of generalization gap depends on what we call inconsistency and instability of model outputs, which can be estimated on unlabeled data. Our empirical study based on this analysis shows that instability and inconsistency are strongly predictive of generalization gap in various settings. In particular, our finding indicates that inconsistency is a more reliable indicator of generalization gap than the sharpness of the loss landscape. Furthermore, we show that algorithmic reduction of inconsistency leads to superior performance. The results also provide a theoretical basis for existing methods such as co-distillation and ensemble.",
    "path": "papers/23/06/2306.00169.json",
    "total_tokens": 882,
    "translated_title": "深度神经网络训练的不一致性、不稳定性和泛化差距",
    "translated_abstract": "随着深度神经网络具有很高的表现力，寻找具有小泛化差距的解决方案变得很重要（即在训练数据和未见数据之间的性能差异）。本文通过关注训练的随机性，首先提出了一个理论分析，其中泛化间隙的界限取决于我们称之为模型输出的不一致性和不稳定性，这可以在未标记的数据上进行估计。我们的实证研究基于这个分析，表明在各种设置中，不稳定性和不一致性强烈预示着泛化间隙。特别地，我们的发现表明，不一致性比损失变化的锐度更可靠地指示着泛化间隙。此外，我们还展示了消除不一致性的算法可以带来更优异的表现。这些结果还为现有的方法提供了理论基础，如共同蒸馏和集成。",
    "tldr": "本文的理论分析与实证研究表明，深度神经网络训练中模型输出的不一致性和不稳定性可以作为估计泛化间隙的重要指标，消除不一致性的算法能够提高模型性能。",
    "en_tdlr": "This paper shows through theoretical analysis and empirical research that the inconsistency and instability of model outputs in deep neural network training can serve as important indicators for estimating the generalization gap, and algorithms that reduce inconsistency can improve model performance."
}