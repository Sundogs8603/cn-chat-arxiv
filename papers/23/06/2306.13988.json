{
    "title": "SAM++: Enhancing Anatomic Matching using Semantic Information and Structural Inference. (arXiv:2306.13988v1 [cs.CV])",
    "abstract": "Medical images like CT and MRI provide detailed information about the internal structure of the body, and identifying key anatomical structures from these images plays a crucial role in clinical workflows. Current methods treat it as a registration or key-point regression task, which has limitations in accurate matching and can only handle predefined landmarks. Recently, some methods have been introduced to address these limitations. One such method, called SAM, proposes using a dense self-supervised approach to learn a distinct embedding for each point on the CT image and achieving promising results. Nonetheless, SAM may still face difficulties when dealing with structures that have similar appearances but different semantic meanings or similar semantic meanings but different appearances. To overcome these limitations, we propose SAM++, a framework that simultaneously learns appearance and semantic embeddings with a novel fixed-points matching mechanism. We tested the SAM++ framework ",
    "link": "http://arxiv.org/abs/2306.13988",
    "context": "Title: SAM++: Enhancing Anatomic Matching using Semantic Information and Structural Inference. (arXiv:2306.13988v1 [cs.CV])\nAbstract: Medical images like CT and MRI provide detailed information about the internal structure of the body, and identifying key anatomical structures from these images plays a crucial role in clinical workflows. Current methods treat it as a registration or key-point regression task, which has limitations in accurate matching and can only handle predefined landmarks. Recently, some methods have been introduced to address these limitations. One such method, called SAM, proposes using a dense self-supervised approach to learn a distinct embedding for each point on the CT image and achieving promising results. Nonetheless, SAM may still face difficulties when dealing with structures that have similar appearances but different semantic meanings or similar semantic meanings but different appearances. To overcome these limitations, we propose SAM++, a framework that simultaneously learns appearance and semantic embeddings with a novel fixed-points matching mechanism. We tested the SAM++ framework ",
    "path": "papers/23/06/2306.13988.json",
    "total_tokens": 867,
    "translated_title": "SAM++: 利用语义信息和结构推理增强解剖匹配",
    "translated_abstract": "医学影像例如 CT 和 MRI 提供了有关身体内部结构的详细信息，从这些图像中识别关键解剖结构在临床工作流程中起着至关重要的作用。目前的方法将此视为配准或关键点回归任务，具有准确匹配的局限性，并且只能处理预定义的地标。最近，一些方法已被引入以解决这些局限性，其中之一称为 SAM，提出使用密集的自我监督方法学习 CT 图像上每个点的独特嵌入，并取得了良好的结果。然而，SAM 在处理外观相似但语义不同或语义相似但外观不同的结构时仍可能面临困难。为了解决这些限制，我们提出了 SAM++，一个框架，通过一种新颖的固定点匹配机制同时学习外观和语义嵌入。我们测试了 SAM++ 框架。",
    "tldr": "SAM++是一个医学影像解剖匹配框架，用于学习外观和语义嵌入，并且通过固定点匹配机制同时解决外观相似但语义不同或语义相似但外观不同的结构匹配问题。",
    "en_tdlr": "SAM++ is a framework for anatomical matching in medical imaging that simultaneously learns appearance and semantic embeddings and solves the problem of matching structures with similar appearances but different semantics or similar semantics but different appearances through a novel fixed-points matching mechanism."
}