{
    "title": "FLAG: Finding Line Anomalies (in code) with Generative AI. (arXiv:2306.12643v1 [cs.CR])",
    "abstract": "Code contains security and functional bugs. The process of identifying and localizing them is difficult and relies on human labor. In this work, we present a novel approach (FLAG) to assist human debuggers. FLAG is based on the lexical capabilities of generative AI, specifically, Large Language Models (LLMs). Here, we input a code file then extract and regenerate each line within that file for self-comparison. By comparing the original code with an LLM-generated alternative, we can flag notable differences as anomalies for further inspection, with features such as distance from comments and LLM confidence also aiding this classification. This reduces the inspection search space for the designer. Unlike other automated approaches in this area, FLAG is language-agnostic, can work on incomplete (and even non-compiling) code and requires no creation of security properties, functional tests or definition of rules. In this work, we explore the features that help LLMs in this classification a",
    "link": "http://arxiv.org/abs/2306.12643",
    "context": "Title: FLAG: Finding Line Anomalies (in code) with Generative AI. (arXiv:2306.12643v1 [cs.CR])\nAbstract: Code contains security and functional bugs. The process of identifying and localizing them is difficult and relies on human labor. In this work, we present a novel approach (FLAG) to assist human debuggers. FLAG is based on the lexical capabilities of generative AI, specifically, Large Language Models (LLMs). Here, we input a code file then extract and regenerate each line within that file for self-comparison. By comparing the original code with an LLM-generated alternative, we can flag notable differences as anomalies for further inspection, with features such as distance from comments and LLM confidence also aiding this classification. This reduces the inspection search space for the designer. Unlike other automated approaches in this area, FLAG is language-agnostic, can work on incomplete (and even non-compiling) code and requires no creation of security properties, functional tests or definition of rules. In this work, we explore the features that help LLMs in this classification a",
    "path": "papers/23/06/2306.12643.json",
    "total_tokens": 856,
    "translated_title": "利用生成AI发现代码中的行异常（FLAG）",
    "translated_abstract": "代码中存在安全性和功能性缺陷，识别和定位它们的过程困难且依赖于人力。在这项工作中，我们提出了一种新的方法（FLAG）来辅助人类调试者。 FLAG基于生成AI的词汇能力，特别是大型语言模型（LLM）。我们输入代码文件，然后提取并重新生成该文件中的每一行以进行自我比较。通过将原始代码与LLM生成的替代方案进行比较，我们可以将显着差异标记为异常以进行进一步检查，同时距离注释和LLM置信度等特征也有助于该分类。这减少了设计人员的检查搜索空间。与此领域中的其他自动化方法不同，FLAG是语言无关的，可以处理不完整（甚至非编译）的代码，并且不需要创建安全属性、功能测试或规则定义。在这项工作中，我们探讨了帮助LLM进行分类的特征。",
    "tldr": "FLAG是一种利用生成AI发现代码中行异常的语言无关方法，能够处理不完整（甚至非编译）的代码，有助于减少设计人员的检查搜索空间。"
}