{
    "title": "Deep neural networks architectures from the perspective of manifold learning. (arXiv:2306.03406v1 [cs.LG])",
    "abstract": "Despite significant advances in the field of deep learning in ap-plications to various areas, an explanation of the learning pro-cess of neural network models remains an important open ques-tion. The purpose of this paper is a comprehensive comparison and description of neural network architectures in terms of ge-ometry and topology. We focus on the internal representation of neural networks and on the dynamics of changes in the topology and geometry of a data manifold on different layers. In this paper, we use the concepts of topological data analysis (TDA) and persistent homological fractal dimension. We present a wide range of experiments with various datasets and configurations of convolutional neural network (CNNs) architectures and Transformers in CV and NLP tasks. Our work is a contribution to the development of the important field of explainable and interpretable AI within the framework of geometrical deep learning.",
    "link": "http://arxiv.org/abs/2306.03406",
    "context": "Title: Deep neural networks architectures from the perspective of manifold learning. (arXiv:2306.03406v1 [cs.LG])\nAbstract: Despite significant advances in the field of deep learning in ap-plications to various areas, an explanation of the learning pro-cess of neural network models remains an important open ques-tion. The purpose of this paper is a comprehensive comparison and description of neural network architectures in terms of ge-ometry and topology. We focus on the internal representation of neural networks and on the dynamics of changes in the topology and geometry of a data manifold on different layers. In this paper, we use the concepts of topological data analysis (TDA) and persistent homological fractal dimension. We present a wide range of experiments with various datasets and configurations of convolutional neural network (CNNs) architectures and Transformers in CV and NLP tasks. Our work is a contribution to the development of the important field of explainable and interpretable AI within the framework of geometrical deep learning.",
    "path": "papers/23/06/2306.03406.json",
    "total_tokens": 865,
    "translated_title": "从流形学习的角度分析深度神经网络结构",
    "translated_abstract": "虽然深度学习在各个领域得到了显著进展，但神经网络模型的学习过程仍是一个重要的开放问题。本文旨在从几何学和拓扑学的角度全面比较和描述神经网络体系结构。我们关注神经网络的内部表示以及在不同层上数据流形的拓扑和几何结构的动态变化。在本文中，我们使用了拓扑数据分析（TDA）和持久同调分形维度的概念。我们使用各种数据集和卷积神经网络（CNN）结构以及在计算机视觉和自然语言处理任务中使用的变压器进行了广泛的实验。我们的工作是在几何深度学习的框架内为可解释和可解释的人工智能的发展做出贡献。",
    "tldr": "本文从几何学和拓扑学的角度，使用拓扑数据分析和持久同调分形维度对神经网络体系结构进行全面比较和描述，旨在为可解释和可解释的人工智能的发展做出贡献。",
    "en_tdlr": "This paper comprehensively compares and describes neural network architectures in terms of geometry and topology from the perspective of manifold learning, using the concepts of topological data analysis and persistent homological fractal dimension, and aims to contribute to the development of explainable and interpretable AI within the framework of geometrical deep learning."
}