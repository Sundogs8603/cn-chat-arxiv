{
    "title": "Implicit spoken language diarization. (arXiv:2306.12913v1 [eess.AS])",
    "abstract": "Spoken language diarization (LD) and related tasks are mostly explored using the phonotactic approach. Phonotactic approaches mostly use explicit way of language modeling, hence requiring intermediate phoneme modeling and transcribed data. Alternatively, the ability of deep learning approaches to model temporal dynamics may help for the implicit modeling of language information through deep embedding vectors. Hence this work initially explores the available speaker diarization frameworks that capture speaker information implicitly to perform LD tasks. The performance of the LD system on synthetic code-switch data using the end-to-end x-vector approach is 6.78% and 7.06%, and for practical data is 22.50% and 60.38%, in terms of diarization error rate and Jaccard error rate (JER), respectively. The performance degradation is due to the data imbalance and resolved to some extent by using pre-trained wave2vec embeddings that provide a relative improvement of 30.74% in terms of JER.",
    "link": "http://arxiv.org/abs/2306.12913",
    "context": "Title: Implicit spoken language diarization. (arXiv:2306.12913v1 [eess.AS])\nAbstract: Spoken language diarization (LD) and related tasks are mostly explored using the phonotactic approach. Phonotactic approaches mostly use explicit way of language modeling, hence requiring intermediate phoneme modeling and transcribed data. Alternatively, the ability of deep learning approaches to model temporal dynamics may help for the implicit modeling of language information through deep embedding vectors. Hence this work initially explores the available speaker diarization frameworks that capture speaker information implicitly to perform LD tasks. The performance of the LD system on synthetic code-switch data using the end-to-end x-vector approach is 6.78% and 7.06%, and for practical data is 22.50% and 60.38%, in terms of diarization error rate and Jaccard error rate (JER), respectively. The performance degradation is due to the data imbalance and resolved to some extent by using pre-trained wave2vec embeddings that provide a relative improvement of 30.74% in terms of JER.",
    "path": "papers/23/06/2306.12913.json",
    "total_tokens": 775,
    "translated_title": "隐式语音语言日志分离",
    "translated_abstract": "语音语言日志分离（LD）及相关任务主要使用音位法进行研究。音位法主要使用显式的语言建模方法，因此需要中间的音素建模和转录数据。另一方面，深度学习方法建模时间动态性的能力可能有助于通过深度嵌入向量隐式地建模语言信息。",
    "tldr": "该论文研究了使用深度学习方法进行隐式语言信息建模的语音语言日志分离任务，使用 x-vector 方法进行分离时在合成数据和实际数据上的表现分别为 6.78%/7.06% 和 22.50%/60.38%，使用预训练的 wave2vec 嵌入向量可在一定程度上提高性能。",
    "en_tdlr": "This paper explores the use of deep learning for implicit language information modeling in spoken language diarization tasks. The end-to-end x-vector approach achieved diarization error rates of 6.78%/7.06% on synthetic and 22.50%/60.38% on practical data, with a relative improvement of 30.74% in the Jaccard error rate when using pre-trained wave2vec embeddings."
}