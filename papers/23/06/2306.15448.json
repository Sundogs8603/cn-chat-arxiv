{
    "title": "Understanding Social Reasoning in Language Models with Language Models. (arXiv:2306.15448v1 [cs.CL])",
    "abstract": "As Large Language Models (LLMs) become increasingly integrated into our everyday lives, understanding their ability to comprehend human mental states becomes critical for ensuring effective interactions. However, despite the recent attempts to assess the Theory-of-Mind (ToM) reasoning capabilities of LLMs, the degree to which these models can align with human ToM remains a nuanced topic of exploration. This is primarily due to two distinct challenges: (1) the presence of inconsistent results from previous evaluations, and (2) concerns surrounding the validity of existing evaluation methodologies. To address these challenges, we present a novel framework for procedurally generating evaluations with LLMs by populating causal templates. Using our framework, we create a new social reasoning benchmark (BigToM) for LLMs which consists of 25 controls and 5,000 model-written evaluations. We find that human participants rate the quality of our benchmark higher than previous crowd-sourced evalua",
    "link": "http://arxiv.org/abs/2306.15448",
    "context": "Title: Understanding Social Reasoning in Language Models with Language Models. (arXiv:2306.15448v1 [cs.CL])\nAbstract: As Large Language Models (LLMs) become increasingly integrated into our everyday lives, understanding their ability to comprehend human mental states becomes critical for ensuring effective interactions. However, despite the recent attempts to assess the Theory-of-Mind (ToM) reasoning capabilities of LLMs, the degree to which these models can align with human ToM remains a nuanced topic of exploration. This is primarily due to two distinct challenges: (1) the presence of inconsistent results from previous evaluations, and (2) concerns surrounding the validity of existing evaluation methodologies. To address these challenges, we present a novel framework for procedurally generating evaluations with LLMs by populating causal templates. Using our framework, we create a new social reasoning benchmark (BigToM) for LLMs which consists of 25 controls and 5,000 model-written evaluations. We find that human participants rate the quality of our benchmark higher than previous crowd-sourced evalua",
    "path": "papers/23/06/2306.15448.json",
    "total_tokens": 899,
    "translated_title": "通过语言模型理解语言模型中的社交推理",
    "translated_abstract": "随着大型语言模型（LLM）越来越多地融入到我们的日常生活中，了解它们理解人类心理状态的能力对于确保有效的交互变得至关重要。然而，尽管最近有人尝试评估LLM的理论心智（ToM）推理能力，但这些模型与人类ToM的一致程度仍然是一个复杂的探索主题。这主要是因为存在两个不同的挑战：（1）之前评估结果不一致，（2）现有评估方法的有效性存在疑虑。为了解决这些挑战，我们提出了一个新的框架，通过填充因果模板来生成与LLM的评估。使用我们的框架，我们为LLM创建了一个新的社交推理基准（BigToM），其中包含25个控制和5000个模型写的评估。我们发现，与之前众包评估相比，人类参与者对我们的基准的质量评价更高。",
    "tldr": "这项研究提出了一种新的框架，通过填充因果模板来生成对大型语言模型（LLMs）进行评估，从而解决了之前评估结果不一致和现有评估方法的有效性存在疑虑的挑战。使用这个框架，他们创建了一个新的社交推理基准（BigToM），并发现人类参与者评价这个基准的质量更高。"
}