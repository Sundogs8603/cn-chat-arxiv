{
    "title": "Implementing contextual biasing in GPU decoder for online ASR. (arXiv:2306.15685v1 [eess.AS])",
    "abstract": "GPU decoding significantly accelerates the output of ASR predictions. While GPUs are already being used for online ASR decoding, post-processing and rescoring on GPUs have not been properly investigated yet. Rescoring with available contextual information can considerably improve ASR predictions. Previous studies have proven the viability of lattice rescoring in decoding and biasing language model (LM) weights in offline and online CPU scenarios. In real-time GPU decoding, partial recognition hypotheses are produced without lattice generation, which makes the implementation of biasing more complex. The paper proposes and describes an approach to integrate contextual biasing in real-time GPU decoding while exploiting the standard Kaldi GPU decoder. Besides the biasing of partial ASR predictions, our approach also permits dynamic context switching allowing a flexible rescoring per each speech segment directly on GPU. The code is publicly released and tested with open-sourced test sets.",
    "link": "http://arxiv.org/abs/2306.15685",
    "context": "Title: Implementing contextual biasing in GPU decoder for online ASR. (arXiv:2306.15685v1 [eess.AS])\nAbstract: GPU decoding significantly accelerates the output of ASR predictions. While GPUs are already being used for online ASR decoding, post-processing and rescoring on GPUs have not been properly investigated yet. Rescoring with available contextual information can considerably improve ASR predictions. Previous studies have proven the viability of lattice rescoring in decoding and biasing language model (LM) weights in offline and online CPU scenarios. In real-time GPU decoding, partial recognition hypotheses are produced without lattice generation, which makes the implementation of biasing more complex. The paper proposes and describes an approach to integrate contextual biasing in real-time GPU decoding while exploiting the standard Kaldi GPU decoder. Besides the biasing of partial ASR predictions, our approach also permits dynamic context switching allowing a flexible rescoring per each speech segment directly on GPU. The code is publicly released and tested with open-sourced test sets.",
    "path": "papers/23/06/2306.15685.json",
    "total_tokens": 802,
    "translated_title": "在GPU解码器中实现上下文偏置用于在线ASR",
    "translated_abstract": "GPU解码显著加速了ASR预测的输出。虽然已经在在线ASR解码中使用了GPU，但是尚未对GPU上的后处理和重新评分进行适当的研究。利用可用的上下文信息进行重新评分可以大大提高ASR预测的准确性。之前的研究已经证明了在离线和在线CPU场景中，在解码和对语言模型（LM）权重进行偏置方面使用格子重新评分的可行性。在实时GPU解码中，会生成部分识别假设而不生成格子，这使得偏置的实现更加复杂。本文提出并描述了一种在实时GPU解码中集成上下文偏置的方法，同时利用了标准的Kaldi GPU解码器。除了对部分ASR预测进行偏置外，我们的方法还允许动态上下文切换，直接在GPU上对每个语音段进行灵活的重新评分。代码已经公开发布并使用了开源测试数据集进行了测试。",
    "tldr": "本论文提出了一种在实时GPU解码中集成上下文偏置的方法，以提高ASR预测的准确性，并允许动态上下文切换。"
}