{
    "title": "Fast Training of Diffusion Models with Masked Transformers",
    "abstract": "arXiv:2306.09305v2 Announce Type: replace-cross  Abstract: We propose an efficient approach to train large diffusion models with masked transformers. While masked transformers have been extensively explored for representation learning, their application to generative learning is less explored in the vision domain. Our work is the first to exploit masked training to reduce the training cost of diffusion models significantly. Specifically, we randomly mask out a high proportion (e.g., 50%) of patches in diffused input images during training. For masked training, we introduce an asymmetric encoder-decoder architecture consisting of a transformer encoder that operates only on unmasked patches and a lightweight transformer decoder on full patches. To promote a long-range understanding of full patches, we add an auxiliary task of reconstructing masked patches to the denoising score matching objective that learns the score of unmasked patches. Experiments on ImageNet-256x256 and ImageNet-512x",
    "link": "https://arxiv.org/abs/2306.09305",
    "context": "Title: Fast Training of Diffusion Models with Masked Transformers\nAbstract: arXiv:2306.09305v2 Announce Type: replace-cross  Abstract: We propose an efficient approach to train large diffusion models with masked transformers. While masked transformers have been extensively explored for representation learning, their application to generative learning is less explored in the vision domain. Our work is the first to exploit masked training to reduce the training cost of diffusion models significantly. Specifically, we randomly mask out a high proportion (e.g., 50%) of patches in diffused input images during training. For masked training, we introduce an asymmetric encoder-decoder architecture consisting of a transformer encoder that operates only on unmasked patches and a lightweight transformer decoder on full patches. To promote a long-range understanding of full patches, we add an auxiliary task of reconstructing masked patches to the denoising score matching objective that learns the score of unmasked patches. Experiments on ImageNet-256x256 and ImageNet-512x",
    "path": "papers/23/06/2306.09305.json",
    "total_tokens": 898,
    "translated_title": "使用Masked Transformers快速训练扩散模型",
    "translated_abstract": "我们提出了一种有效的方法，使用Masked Transformers来训练大型扩散模型。尽管Masked Transformers已经被广泛探索用于表示学习，在视觉领域中，它们在生成学习方面的应用却较少被探讨。我们的工作是第一个利用Masked training显著降低扩散模型的训练成本。具体地，在训练过程中，我们随机屏蔽扩散输入图像中高比例（例如50%）的patches。为了进行Masked training，我们引入了一个不对称的编码器-解码器架构，其中包括仅在未屏蔽patches上运行的transformer编码器和在全部patches上运行的轻量级transformer解码器。为了提升对全patches的长程理解，我们加入了一个辅助任务，即重构屏蔽patches，这是为了denoising score matching目标学习未屏蔽patches的score。我们在ImageNet-256x256和ImageNet-512x...上进行了实验。",
    "tldr": "该论文提出了一种使用Masked Transformers快速训练扩散模型的方法，首次利用Masked training显著降低了模型的训练成本，并引入了不对称的编码器-解码器架构和辅助任务，以提升对全patches的长程理解。",
    "en_tdlr": "This paper proposes a method to train diffusion models efficiently using Masked Transformers, significantly reducing training cost for the first time, by introducing an asymmetric encoder-decoder architecture and an auxiliary task to promote long-range understanding of the full patches."
}