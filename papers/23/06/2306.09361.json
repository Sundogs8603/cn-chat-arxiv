{
    "title": "MFAS: Emotion Recognition through Multiple Perspectives Fusion Architecture Search Emulating Human Cognition. (arXiv:2306.09361v1 [eess.AS])",
    "abstract": "Speech emotion recognition aims to identify and analyze emotional states in target speech similar to humans. Perfect emotion recognition can greatly benefit a wide range of human-machine interaction tasks. Inspired by the human process of understanding emotions, we demonstrate that compared to quantized modeling, understanding speech content from a continuous perspective, akin to human-like comprehension, enables the model to capture more comprehensive emotional information. Additionally, considering that humans adjust their perception of emotional words in textual semantic based on certain cues present in speech, we design a novel search space and search for the optimal fusion strategy for the two types of information. Experimental results further validate the significance of this perception adjustment. Building on these observations, we propose a novel framework called Multiple perspectives Fusion Architecture Search (MFAS). Specifically, we utilize continuous-based knowledge to capt",
    "link": "http://arxiv.org/abs/2306.09361",
    "context": "Title: MFAS: Emotion Recognition through Multiple Perspectives Fusion Architecture Search Emulating Human Cognition. (arXiv:2306.09361v1 [eess.AS])\nAbstract: Speech emotion recognition aims to identify and analyze emotional states in target speech similar to humans. Perfect emotion recognition can greatly benefit a wide range of human-machine interaction tasks. Inspired by the human process of understanding emotions, we demonstrate that compared to quantized modeling, understanding speech content from a continuous perspective, akin to human-like comprehension, enables the model to capture more comprehensive emotional information. Additionally, considering that humans adjust their perception of emotional words in textual semantic based on certain cues present in speech, we design a novel search space and search for the optimal fusion strategy for the two types of information. Experimental results further validate the significance of this perception adjustment. Building on these observations, we propose a novel framework called Multiple perspectives Fusion Architecture Search (MFAS). Specifically, we utilize continuous-based knowledge to capt",
    "path": "papers/23/06/2306.09361.json",
    "total_tokens": 819,
    "translated_title": "MFAS: 基于多角度融合结构搜索的情感识别，模拟人类认知",
    "translated_abstract": "语音情感识别旨在识别和分析与人类类似的情绪状态。完美的情感识别可以极大地改善各种人机交互任务。受人类理解情感的过程的启发，我们证明了与量化建模相比，从连续的角度理解语音内容，类似于人类的理解，能够使模型捕捉更全面的情感信息。此外，考虑到人类根据语音中存在的某些线索调整情感单词的文本语义的感知，我们设计了一个新的搜索空间并搜索两种信息的最佳融合策略。实验结果进一步验证了调整感知的重要性。基于这些观察结果，我们提出了一种新的框架，称为Multiple perspectives Fusion Architecture Search(MFAS)。",
    "tldr": "该论文提出了一种基于多角度融合结构搜索的情感识别框架，模拟人类的认知过程，能够从连续的角度捕捉更全面的情感信息。",
    "en_tdlr": "This paper proposes a novel emotion recognition framework called MFAS, which is based on a multiple perspectives fusion architecture search that emulates human cognition. It captures more comprehensive emotional information by utilizing continuous-based knowledge and adjusts the perception of emotional words in textual semantic based on certain cues present in speech."
}