{
    "title": "Optimizing Credit Limit Adjustments Under Adversarial Goals Using Reinforcement Learning. (arXiv:2306.15585v1 [q-fin.GN])",
    "abstract": "Reinforcement learning has been explored for many problems, from video games with deterministic environments to portfolio and operations management in which scenarios are stochastic; however, there have been few attempts to test these methods in banking problems. In this study, we sought to find and automatize an optimal credit card limit adjustment policy by employing reinforcement learning techniques. In particular, because of the historical data available, we considered two possible actions per customer, namely increasing or maintaining an individual's current credit limit. To find this policy, we first formulated this decision-making question as an optimization problem in which the expected profit was maximized; therefore, we balanced two adversarial goals: maximizing the portfolio's revenue and minimizing the portfolio's provisions. Second, given the particularities of our problem, we used an offline learning strategy to simulate the impact of the action based on historical data f",
    "link": "http://arxiv.org/abs/2306.15585",
    "context": "Title: Optimizing Credit Limit Adjustments Under Adversarial Goals Using Reinforcement Learning. (arXiv:2306.15585v1 [q-fin.GN])\nAbstract: Reinforcement learning has been explored for many problems, from video games with deterministic environments to portfolio and operations management in which scenarios are stochastic; however, there have been few attempts to test these methods in banking problems. In this study, we sought to find and automatize an optimal credit card limit adjustment policy by employing reinforcement learning techniques. In particular, because of the historical data available, we considered two possible actions per customer, namely increasing or maintaining an individual's current credit limit. To find this policy, we first formulated this decision-making question as an optimization problem in which the expected profit was maximized; therefore, we balanced two adversarial goals: maximizing the portfolio's revenue and minimizing the portfolio's provisions. Second, given the particularities of our problem, we used an offline learning strategy to simulate the impact of the action based on historical data f",
    "path": "papers/23/06/2306.15585.json",
    "total_tokens": 841,
    "translated_title": "使用强化学习优化对抗目标下的信用额度调整",
    "translated_abstract": "强化学习已经在很多问题中得到应用，从具有确定性环境的视频游戏到具有随机场景的投资组合和运营管理；然而，在银行问题中对这些方法的测试尝试很少。在本研究中，我们试图通过使用强化学习技术找到并自动化最优信用卡额度调整策略。具体而言，由于有历史数据可用，我们考虑每个客户的两种可能操作，即增加或保持个人当前的信用额度。为了找到这个策略，我们首先将这个决策问题形式化为一个优化问题，在其中最大化预期利润；因此，我们平衡了两个对抗目标：最大化投资组合的收入和最小化投资组合的准备金。其次，考虑到我们问题的特殊性，我们使用了离线学习策略，以基于历史数据模拟行动的影响。",
    "tldr": "本研究使用强化学习技术，通过平衡最大化投资组合收入和最小化准备金的对抗目标，自动化寻找最优信用卡额度调整策略。",
    "en_tdlr": "This study utilizes reinforcement learning techniques to automatically find an optimal credit card limit adjustment policy by balancing the adversarial goals of maximizing portfolio revenue and minimizing provisions."
}