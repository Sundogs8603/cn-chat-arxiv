{
    "title": "Phoenix: A Federated Generative Diffusion Model. (arXiv:2306.04098v1 [cs.LG])",
    "abstract": "Generative AI has made impressive strides in enabling users to create diverse and realistic visual content such as images, videos, and audio. However, training generative models on large centralized datasets can pose challenges in terms of data privacy, security, and accessibility. Federated learning (FL) is an approach that uses decentralized techniques to collaboratively train a shared deep learning model while retaining the training data on individual edge devices to preserve data privacy. This paper proposes a novel method for training a Denoising Diffusion Probabilistic Model (DDPM) across multiple data sources using FL techniques. Diffusion models, a newly emerging generative model, show promising results in achieving superior quality images than Generative Adversarial Networks (GANs). Our proposed method Phoenix is an unconditional diffusion model that leverages strategies to improve the data diversity of generated samples even when trained on data with statistical heterogeneity",
    "link": "http://arxiv.org/abs/2306.04098",
    "context": "Title: Phoenix: A Federated Generative Diffusion Model. (arXiv:2306.04098v1 [cs.LG])\nAbstract: Generative AI has made impressive strides in enabling users to create diverse and realistic visual content such as images, videos, and audio. However, training generative models on large centralized datasets can pose challenges in terms of data privacy, security, and accessibility. Federated learning (FL) is an approach that uses decentralized techniques to collaboratively train a shared deep learning model while retaining the training data on individual edge devices to preserve data privacy. This paper proposes a novel method for training a Denoising Diffusion Probabilistic Model (DDPM) across multiple data sources using FL techniques. Diffusion models, a newly emerging generative model, show promising results in achieving superior quality images than Generative Adversarial Networks (GANs). Our proposed method Phoenix is an unconditional diffusion model that leverages strategies to improve the data diversity of generated samples even when trained on data with statistical heterogeneity",
    "path": "papers/23/06/2306.04098.json",
    "total_tokens": 895,
    "translated_title": "Phoenix：一种联邦式生成扩散模型",
    "translated_abstract": "生成人工智能在实现图像、视频和音频等多样且逼真的视觉内容方面取得了惊人的进展。然而，对大型集中式数据集进行生成模型的训练可能会在数据隐私、安全和可访问性方面带来挑战。联邦学习是一种使用分散技术协作训练共享深度学习模型的方法，同时保留个体边缘设备上的训练数据以保护数据隐私。本文提出了一种使用联邦学习技术跨多个数据源训练去噪扩散概率模型（DDPM）的新方法。扩散模型是一种新兴的生成模型，在实现优质图像方面比生成对抗网络（GANs）具有更好的效果。我们提出的 Phoenix 方法是一种无条件的扩散模型，利用策略改进了生成样本的数据多样性，即使是在训练统计杂质数据的情况下。",
    "tldr": "本文提出了 Phoenix 一种联邦式生成扩散模型，利用联邦学习技术跨多个数据源进行训练，实现生成质量更好的图像。该模型在保护数据隐私的前提下，提高了生成样本的数据多样性。",
    "en_tdlr": "This paper proposes Phoenix, a federated generative diffusion model, which trains on multiple data sources using FL techniques and achieves higher quality image generation while preserving data privacy. Phoenix leverages strategies to improve the data diversity of generated samples even when trained on data with statistical heterogeneity."
}