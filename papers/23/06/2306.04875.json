{
    "title": "Instructed Diffuser with Temporal Condition Guidance for Offline Reinforcement Learning. (arXiv:2306.04875v1 [cs.LG])",
    "abstract": "Recent works have shown the potential of diffusion models in computer vision and natural language processing. Apart from the classical supervised learning fields, diffusion models have also shown strong competitiveness in reinforcement learning (RL) by formulating decision-making as sequential generation. However, incorporating temporal information of sequential data and utilizing it to guide diffusion models to perform better generation is still an open challenge. In this paper, we take one step forward to investigate controllable generation with temporal conditions that are refined from temporal information. We observe the importance of temporal conditions in sequential generation in sufficient explorative scenarios and provide a comprehensive discussion and comparison of different temporal conditions. Based on the observations, we propose an effective temporally-conditional diffusion model coined Temporally-Composable Diffuser (TCD), which extracts temporal information from interact",
    "link": "http://arxiv.org/abs/2306.04875",
    "context": "Title: Instructed Diffuser with Temporal Condition Guidance for Offline Reinforcement Learning. (arXiv:2306.04875v1 [cs.LG])\nAbstract: Recent works have shown the potential of diffusion models in computer vision and natural language processing. Apart from the classical supervised learning fields, diffusion models have also shown strong competitiveness in reinforcement learning (RL) by formulating decision-making as sequential generation. However, incorporating temporal information of sequential data and utilizing it to guide diffusion models to perform better generation is still an open challenge. In this paper, we take one step forward to investigate controllable generation with temporal conditions that are refined from temporal information. We observe the importance of temporal conditions in sequential generation in sufficient explorative scenarios and provide a comprehensive discussion and comparison of different temporal conditions. Based on the observations, we propose an effective temporally-conditional diffusion model coined Temporally-Composable Diffuser (TCD), which extracts temporal information from interact",
    "path": "papers/23/06/2306.04875.json",
    "total_tokens": 760,
    "translated_title": "指导扩散器结合时间条件的离线强化学习",
    "translated_abstract": "最近的研究表明了扩散模型在计算机视觉和自然语言处理领域的潜力。除了传统的监督学习领域，扩散模型还通过将决策制定为序列生成的方式，在强化学习中表现出强大的竞争力。然而，将顺序数据的时间信息纳入扩散模型，并利用它来指导更好的生成仍然是一个开放性的挑战。本文提出了一个有效的时间条件扩散模型，称为 Temporally-Composable Diffuser (TCD)，它从交互中提取时间信息，通过细化时间条件进行控制生成，并比较了不同时间条件的全面讨论。",
    "tldr": "本文提出一种有效的时间条件扩散模型 TCD，通过提取序列数据中的时间信息并将其用于生成，实现了更好的控制生成效果。",
    "en_tdlr": "This paper proposes an effective temporally-conditional diffusion model TCD, which utilizes temporal information extracted from sequential data to guide better generation, and achieves better controlled generation by refining the temporal conditions, with a comprehensive discussion and comparison of different temporal conditions."
}