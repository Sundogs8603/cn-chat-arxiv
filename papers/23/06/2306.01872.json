{
    "title": "Probabilistic Adaptation of Text-to-Video Models. (arXiv:2306.01872v1 [cs.AI])",
    "abstract": "Large text-to-video models trained on internet-scale data have demonstrated exceptional capabilities in generating high-fidelity videos from arbitrary textual descriptions. However, adapting these models to tasks with limited domain-specific data, such as animation or robotics videos, poses a significant computational challenge, since finetuning a pretrained large model can be prohibitively expensive. Inspired by how a small modifiable component (e.g., prompts, prefix-tuning) can adapt a large language model to perform new tasks without requiring access to the model weights, we investigate how to adapt a large pretrained text-to-video model to a variety of downstream domains and tasks without finetuning. In answering this question, we propose Video Adapter, which leverages the score function of a large pretrained video diffusion model as a probabilistic prior to guide the generation of a task-specific small video model. Our experiments show that Video Adapter is capable of incorporatin",
    "link": "http://arxiv.org/abs/2306.01872",
    "context": "Title: Probabilistic Adaptation of Text-to-Video Models. (arXiv:2306.01872v1 [cs.AI])\nAbstract: Large text-to-video models trained on internet-scale data have demonstrated exceptional capabilities in generating high-fidelity videos from arbitrary textual descriptions. However, adapting these models to tasks with limited domain-specific data, such as animation or robotics videos, poses a significant computational challenge, since finetuning a pretrained large model can be prohibitively expensive. Inspired by how a small modifiable component (e.g., prompts, prefix-tuning) can adapt a large language model to perform new tasks without requiring access to the model weights, we investigate how to adapt a large pretrained text-to-video model to a variety of downstream domains and tasks without finetuning. In answering this question, we propose Video Adapter, which leverages the score function of a large pretrained video diffusion model as a probabilistic prior to guide the generation of a task-specific small video model. Our experiments show that Video Adapter is capable of incorporatin",
    "path": "papers/23/06/2306.01872.json",
    "total_tokens": 987,
    "translated_title": "文本到视频模型的概率自适应研究",
    "translated_abstract": "在互联网规模的数据集上训练的大型文本到视频模型已经表现出从任意文本描述生成高保真视频的出色能力，但将这些模型适应于具有有限领域特定数据的任务，例如动画或机器人视频，会带来重大的计算挑战，因为微调预先训练好的大模型可能代价高昂。在获得灵感于小型可修改组件（例如提示语、前缀调整）如何使大型语言模型适应执行新任务而无需访问模型权重的情况下，我们探索了如何在不进行微调的情况下将大型预先训练好的文本到视频模型适应于各种下游领域和任务。在回答这个问题的同时，我们提出了Video Adapter，利用大型预先训练的视频扩散模型的分数函数作为概率先验来指导任务特定小型视频模型的生成。我们的实验表明，Video Adapter能够集成具有复杂结构的任务特定模型，并能够适应多种视频领域和任务，与其他方法相比具有优异性能。",
    "tldr": "本论文针对将大型预先训练好的文本到视频模型适应于具有有限领域特定数据的任务，提出了一种基于概率自适应的方法，名为Video Adapter，通过利用大型预先训练的视频扩散模型的分数函数作为概率先验，来指导生成任务特定小型视频模型。实验结果表明，该方法具有优异性能。",
    "en_tdlr": "This paper proposes a probabilistic adaptation method called Video Adapter to adapt large pretrained text-to-video models to tasks with limited domain-specific data, which leverages score function of a large pretrained video diffusion model as a probabilistic prior to guide the generation of task-specific small video models. Experimental results show that Video Adapter achieves outstanding performance compared with other methods."
}