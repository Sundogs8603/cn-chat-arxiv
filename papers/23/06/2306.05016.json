{
    "title": "Progression Cognition Reinforcement Learning with Prioritized Experience for Multi-Vehicle Pursuit. (arXiv:2306.05016v1 [cs.AI])",
    "abstract": "Multi-vehicle pursuit (MVP) such as autonomous police vehicles pursuing suspects is important but very challenging due to its mission and safety critical nature. While multi-agent reinforcement learning (MARL) algorithms have been proposed for MVP problem in structured grid-pattern roads, the existing algorithms use randomly training samples in centralized learning, which leads to homogeneous agents showing low collaboration performance. For the more challenging problem of pursuing multiple evading vehicles, these algorithms typically select a fixed target evading vehicle for pursuing vehicles without considering dynamic traffic situation, which significantly reduces pursuing success rate. To address the above problems, this paper proposes a Progression Cognition Reinforcement Learning with Prioritized Experience for MVP (PEPCRL-MVP) in urban multi-intersection dynamic traffic scenes. PEPCRL-MVP uses a prioritization network to assess the transitions in the global experience replay buf",
    "link": "http://arxiv.org/abs/2306.05016",
    "context": "Title: Progression Cognition Reinforcement Learning with Prioritized Experience for Multi-Vehicle Pursuit. (arXiv:2306.05016v1 [cs.AI])\nAbstract: Multi-vehicle pursuit (MVP) such as autonomous police vehicles pursuing suspects is important but very challenging due to its mission and safety critical nature. While multi-agent reinforcement learning (MARL) algorithms have been proposed for MVP problem in structured grid-pattern roads, the existing algorithms use randomly training samples in centralized learning, which leads to homogeneous agents showing low collaboration performance. For the more challenging problem of pursuing multiple evading vehicles, these algorithms typically select a fixed target evading vehicle for pursuing vehicles without considering dynamic traffic situation, which significantly reduces pursuing success rate. To address the above problems, this paper proposes a Progression Cognition Reinforcement Learning with Prioritized Experience for MVP (PEPCRL-MVP) in urban multi-intersection dynamic traffic scenes. PEPCRL-MVP uses a prioritization network to assess the transitions in the global experience replay buf",
    "path": "papers/23/06/2306.05016.json",
    "total_tokens": 921,
    "translated_title": "基于优先经验的渐进认知强化学习在多车辆追逐中的应用",
    "translated_abstract": "多车辆追逐（MVP），如自主警车追逐嫌疑人，由于其使命和安全重要性而显得很重要，但非常具有挑战性。尽管已经提出了多智能体强化学习（MARL）算法以解决结构化网格模式道路上MVP问题，但现有算法在集中式学习中使用随机训练样本，导致表现出低协作性的同质化智能体。针对更具挑战性的追逐多个逃避车辆的问题，这些算法通常会选择固定的逃避目标车辆，而不考虑动态交通情况，这会显著降低追逐成功率。为解决以上问题，本文在城市多交叉口动态交通场景中提出了一种基于优先经验的渐进认知强化学习PEPCRL-MVP技术。PEPCRL-MVP使用优先级网络来评估全局经验回放缓冲区中的转换。",
    "tldr": "本文提出了一种基于优先经验的渐进认知强化学习方法，在城市多交叉口动态交通场景下解决了多车辆追逐问题，并显著提高了追逐成功率。"
}