{
    "title": "LLM-Assisted Content Analysis: Using Large Language Models to Support Deductive Coding. (arXiv:2306.14924v1 [cs.CL])",
    "abstract": "Deductive coding is a widely used qualitative research method for determining the prevalence of themes across documents. While useful, deductive coding is often burdensome and time consuming since it requires researchers to read, interpret, and reliably categorize a large body of unstructured text documents. Large language models (LLMs), like ChatGPT, are a class of quickly evolving AI tools that can perform a range of natural language processing and reasoning tasks. In this study, we explore the use of LLMs to reduce the time it takes for deductive coding while retaining the flexibility of a traditional content analysis. We outline the proposed approach, called LLM-assisted content analysis (LACA), along with an in-depth case study using GPT-3.5 for LACA on a publicly available deductive coding data set. Additionally, we conduct an empirical benchmark using LACA on 4 publicly available data sets to assess the broader question of how well GPT-3.5 performs across a range of deductive co",
    "link": "http://arxiv.org/abs/2306.14924",
    "context": "Title: LLM-Assisted Content Analysis: Using Large Language Models to Support Deductive Coding. (arXiv:2306.14924v1 [cs.CL])\nAbstract: Deductive coding is a widely used qualitative research method for determining the prevalence of themes across documents. While useful, deductive coding is often burdensome and time consuming since it requires researchers to read, interpret, and reliably categorize a large body of unstructured text documents. Large language models (LLMs), like ChatGPT, are a class of quickly evolving AI tools that can perform a range of natural language processing and reasoning tasks. In this study, we explore the use of LLMs to reduce the time it takes for deductive coding while retaining the flexibility of a traditional content analysis. We outline the proposed approach, called LLM-assisted content analysis (LACA), along with an in-depth case study using GPT-3.5 for LACA on a publicly available deductive coding data set. Additionally, we conduct an empirical benchmark using LACA on 4 publicly available data sets to assess the broader question of how well GPT-3.5 performs across a range of deductive co",
    "path": "papers/23/06/2306.14924.json",
    "total_tokens": 984,
    "translated_title": "LLM辅助内容分析：利用大型语言模型支持演绎编码",
    "translated_abstract": "演绎编码是一种广泛使用的定性研究方法，用于确定文档中主题的普遍性。尽管有用，演绎编码通常是繁琐且耗时的，因为它要求研究人员阅读、解释并可靠地对大量非结构化文本进行分类。大型语言模型（LLMs），如ChatGPT，是一类快速发展的人工智能工具，可以执行各种自然语言处理和推理任务。在这项研究中，我们探索了使用LLMs来减少演绎编码所需的时间，同时保留传统内容分析的灵活性。我们概述了所提出的方法，称为LLM辅助内容分析（LACA），并使用GPT-3.5在一个公开可用的演绎编码数据集上进行了深入案例研究。此外，我们还进行了一个经验基准测试，使用LACA在4个公开可用的数据集上评估GPT-3.5在不同演绎编码任务上的表现。",
    "tldr": "本研究探索了使用大型语言模型（LLMs）来减少演绎编码所需时间的方法，同时保留传统内容分析的灵活性。通过一个案例研究和经验基准测试，证明了在不同演绎编码任务上，GPT-3.5在LLM辅助内容分析（LACA）中的有效性。"
}