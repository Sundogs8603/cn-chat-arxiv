{
    "title": "Advancing Adversarial Training by Injecting Booster Signal. (arXiv:2306.15451v1 [cs.CV])",
    "abstract": "Recent works have demonstrated that deep neural networks (DNNs) are highly vulnerable to adversarial attacks. To defend against adversarial attacks, many defense strategies have been proposed, among which adversarial training has been demonstrated to be the most effective strategy. However, it has been known that adversarial training sometimes hurts natural accuracy. Then, many works focus on optimizing model parameters to handle the problem. Different from the previous approaches, in this paper, we propose a new approach to improve the adversarial robustness by using an external signal rather than model parameters. In the proposed method, a well-optimized universal external signal called a booster signal is injected into the outside of the image which does not overlap with the original content. Then, it boosts both adversarial robustness and natural accuracy. The booster signal is optimized in parallel to model parameters step by step collaboratively. Experimental results show that th",
    "link": "http://arxiv.org/abs/2306.15451",
    "context": "Title: Advancing Adversarial Training by Injecting Booster Signal. (arXiv:2306.15451v1 [cs.CV])\nAbstract: Recent works have demonstrated that deep neural networks (DNNs) are highly vulnerable to adversarial attacks. To defend against adversarial attacks, many defense strategies have been proposed, among which adversarial training has been demonstrated to be the most effective strategy. However, it has been known that adversarial training sometimes hurts natural accuracy. Then, many works focus on optimizing model parameters to handle the problem. Different from the previous approaches, in this paper, we propose a new approach to improve the adversarial robustness by using an external signal rather than model parameters. In the proposed method, a well-optimized universal external signal called a booster signal is injected into the outside of the image which does not overlap with the original content. Then, it boosts both adversarial robustness and natural accuracy. The booster signal is optimized in parallel to model parameters step by step collaboratively. Experimental results show that th",
    "path": "papers/23/06/2306.15451.json",
    "total_tokens": 871,
    "translated_title": "通过注入增强信号来推进对抗性训练",
    "translated_abstract": "最近的研究表明，深度神经网络（DNN）对于对抗攻击非常脆弱。为了抵御对抗攻击，已经提出了许多防御策略，其中对抗性训练被证明是最有效的策略。然而，众所周知，对抗性训练有时会损害自然准确性。因此，许多工作集中在优化模型参数以解决这个问题。与以前的方法不同，本文提出了一种新的方法，通过使用外部信号而不是模型参数来提高对抗性鲁棒性。在提出的方法中，注入了一个经过优化的通用外部信号，称为增强信号，该信号被注入到与原始内容不重叠的图像外部。然后，它提高了对抗性鲁棒性和自然准确性。增强信号与模型参数并行逐步进行优化。实验结果表明，该方法可以显著改善对抗性训练的效果。",
    "tldr": "本文提出了一种通过注入增强信号来提高对抗性训练的方法，其使用外部信号而不是模型参数来提高对抗性鲁棒性和自然准确性。",
    "en_tdlr": "This paper proposes a method to improve adversarial training by injecting a booster signal, which enhances adversarial robustness and natural accuracy using an external signal instead of model parameters."
}