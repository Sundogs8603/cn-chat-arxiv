{
    "title": "Blended-NeRF: Zero-Shot Object Generation and Blending in Existing Neural Radiance Fields. (arXiv:2306.12760v1 [cs.CV])",
    "abstract": "Editing a local region or a specific object in a 3D scene represented by a NeRF is challenging, mainly due to the implicit nature of the scene representation. Consistently blending a new realistic object into the scene adds an additional level of difficulty. We present Blended-NeRF, a robust and flexible framework for editing a specific region of interest in an existing NeRF scene, based on text prompts or image patches, along with a 3D ROI box. Our method leverages a pretrained language-image model to steer the synthesis towards a user-provided text prompt or image patch, along with a 3D MLP model initialized on an existing NeRF scene to generate the object and blend it into a specified region in the original scene. We allow local editing by localizing a 3D ROI box in the input scene, and seamlessly blend the content synthesized inside the ROI with the existing scene using a novel volumetric blending technique. To obtain natural looking and view-consistent results, we leverage existin",
    "link": "http://arxiv.org/abs/2306.12760",
    "context": "Title: Blended-NeRF: Zero-Shot Object Generation and Blending in Existing Neural Radiance Fields. (arXiv:2306.12760v1 [cs.CV])\nAbstract: Editing a local region or a specific object in a 3D scene represented by a NeRF is challenging, mainly due to the implicit nature of the scene representation. Consistently blending a new realistic object into the scene adds an additional level of difficulty. We present Blended-NeRF, a robust and flexible framework for editing a specific region of interest in an existing NeRF scene, based on text prompts or image patches, along with a 3D ROI box. Our method leverages a pretrained language-image model to steer the synthesis towards a user-provided text prompt or image patch, along with a 3D MLP model initialized on an existing NeRF scene to generate the object and blend it into a specified region in the original scene. We allow local editing by localizing a 3D ROI box in the input scene, and seamlessly blend the content synthesized inside the ROI with the existing scene using a novel volumetric blending technique. To obtain natural looking and view-consistent results, we leverage existin",
    "path": "papers/23/06/2306.12760.json",
    "total_tokens": 908,
    "translated_title": "混合式神经辐射场：零样本物体生成与混合",
    "translated_abstract": "在3D场景中编辑局部区域或特定物体并混合到已有的NeRF场景中，由于场景表示的隐式属性，这是一个具有挑战性的问题。我们提出了Blended-NeRF，一种基于文本提示或图像补丁以及3D ROI包围盒的NeRF场景中感兴趣的区域的编辑的鲁棒而灵活的框架。我们的方法利用预先训练的语言-图像模型来引导合成朝向用户提供的文本提示或图像补丁，还利用一个已存在的NeRF场景上初始化的3D MLP模型来生成物体并将其混合到原始场景中的指定区域。我们通过将3D ROI盒局部化以实现局部编辑，并利用新颖的体积混合技术将内部合成内容无缝混合到现有场景中，以获得自然而一致的结果。",
    "tldr": "Blended-NeRF是一种鲁棒而灵活的编辑NeRF场景中感兴趣的区域的框架，在保持自然性与一致性的情况下，它可以将用户提供的文本提示或图像补丁的物体合成并混合到原始场景中。",
    "en_tdlr": "Blended-NeRF is a robust and flexible framework for editing a specific region in a NeRF scene based on text prompts or image patches, which can generate the object and blend it into the original scene while maintaining naturalness and consistency."
}