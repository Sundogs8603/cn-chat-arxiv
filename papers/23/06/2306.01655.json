{
    "title": "Poisoning Network Flow Classifiers. (arXiv:2306.01655v1 [cs.CR])",
    "abstract": "As machine learning (ML) classifiers increasingly oversee the automated monitoring of network traffic, studying their resilience against adversarial attacks becomes critical. This paper focuses on poisoning attacks, specifically backdoor attacks, against network traffic flow classifiers. We investigate the challenging scenario of clean-label poisoning where the adversary's capabilities are constrained to tampering only with the training data - without the ability to arbitrarily modify the training labels or any other component of the training process. We describe a trigger crafting strategy that leverages model interpretability techniques to generate trigger patterns that are effective even at very low poisoning rates. Finally, we design novel strategies to generate stealthy triggers, including an approach based on generative Bayesian network models, with the goal of minimizing the conspicuousness of the trigger, and thus making detection of an ongoing poisoning campaign more challengi",
    "link": "http://arxiv.org/abs/2306.01655",
    "context": "Title: Poisoning Network Flow Classifiers. (arXiv:2306.01655v1 [cs.CR])\nAbstract: As machine learning (ML) classifiers increasingly oversee the automated monitoring of network traffic, studying their resilience against adversarial attacks becomes critical. This paper focuses on poisoning attacks, specifically backdoor attacks, against network traffic flow classifiers. We investigate the challenging scenario of clean-label poisoning where the adversary's capabilities are constrained to tampering only with the training data - without the ability to arbitrarily modify the training labels or any other component of the training process. We describe a trigger crafting strategy that leverages model interpretability techniques to generate trigger patterns that are effective even at very low poisoning rates. Finally, we design novel strategies to generate stealthy triggers, including an approach based on generative Bayesian network models, with the goal of minimizing the conspicuousness of the trigger, and thus making detection of an ongoing poisoning campaign more challengi",
    "path": "papers/23/06/2306.01655.json",
    "total_tokens": 853,
    "translated_title": "网络流分类器的危害攻击研究",
    "translated_abstract": "随着机器学习分类器越来越多地监控网络流量，研究它们对抗攻击的韧性就变得至关重要。本文重点研究危害攻击，特别是针对网络流量分类器的后门攻击。我们研究了一个具有挑战性的干净标签污染场景，其中对手的能力受限于仅干扰训练数据，无法任意修改训练标签或训练过程的任何其他组件。我们描述了一种触发器制作策略，利用模型可解释性技术生成即使在极低的污染率下也有效的触发器模式。最后，我们设计了生成隐秘触发器的新策略，包括基于生成贝叶斯网络模型的方法，旨在最小化触发器的显著性，从而使正在进行的危害攻击更加具有挑战性。",
    "tldr": "研究了网络流分类器的后门攻击，提出了利用模型可解释性技术生成有效触发器模式和生成隐秘触发器的新策略，以应对对手干扰训练数据的挑战。",
    "en_tdlr": "Investigated backdoor attacks against network traffic flow classifiers, proposed trigger crafting strategy utilizing model interpretability techniques, and designed novel strategies for generating stealthy triggers to combat adversary's tampering with training data."
}