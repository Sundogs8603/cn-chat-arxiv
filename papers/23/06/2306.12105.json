{
    "title": "Mass-Producing Failures of Multimodal Systems with Language Models. (arXiv:2306.12105v1 [cs.LG])",
    "abstract": "Deployed multimodal systems can fail in ways that evaluators did not anticipate. In order to find these failures before deployment, we introduce MultiMon, a system that automatically identifies systematic failures -generalizable, natural-language descriptions of patterns of model failures. To uncover systematic failures, MultiMon scrapes a corpus for examples of erroneous agreement: inputs that produce the same output, but should not. It then prompts a language model (e.g., GPT-4) to find systematic patterns of failure and describe them in natural language. We use MultiMon to find 14 systematic failures (e.g., \"ignores quantifiers\") of the CLIP text-encoder, each comprising hundreds of distinct inputs (e.g., \"a shelf with a few/many books\"). Because CLIP is the backbone for most state-of-the-art multimodal systems, these inputs produce failures in Midjourney 5.1, DALL-E, VideoFusion, and others. MultiMon can also steer towards failures relevant to specific use cases, such as self-dri",
    "link": "http://arxiv.org/abs/2306.12105",
    "context": "Title: Mass-Producing Failures of Multimodal Systems with Language Models. (arXiv:2306.12105v1 [cs.LG])\nAbstract: Deployed multimodal systems can fail in ways that evaluators did not anticipate. In order to find these failures before deployment, we introduce MultiMon, a system that automatically identifies systematic failures -generalizable, natural-language descriptions of patterns of model failures. To uncover systematic failures, MultiMon scrapes a corpus for examples of erroneous agreement: inputs that produce the same output, but should not. It then prompts a language model (e.g., GPT-4) to find systematic patterns of failure and describe them in natural language. We use MultiMon to find 14 systematic failures (e.g., \"ignores quantifiers\") of the CLIP text-encoder, each comprising hundreds of distinct inputs (e.g., \"a shelf with a few/many books\"). Because CLIP is the backbone for most state-of-the-art multimodal systems, these inputs produce failures in Midjourney 5.1, DALL-E, VideoFusion, and others. MultiMon can also steer towards failures relevant to specific use cases, such as self-dri",
    "path": "papers/23/06/2306.12105.json",
    "total_tokens": 941,
    "translated_title": "通过语言模型批量生产多模态系统的失败",
    "translated_abstract": "部署的多模态系统可能以评估人员未曾预见的方式失败。为了在部署前找到这些失败，我们介绍了MultiMon，这是一个能够自动识别系统性失败的系统，能够提供可推广的、自然语言描述模型失败模式的例子。为了揭示系统性失败，MultiMon从语料库中抓取错误协议的示例：输入产生相同的输出，但不应该如此。然后它会激活一个语言模型（例如GPT-4）来查找系统性失败的模式并用自然语言描述它们。我们使用MultiMon找到了CLIP文本编码器的14个系统性失败（例如“忽略量词”，每个都由数百个不同的输入组成（例如“一个带有一些/许多书的书架”）。因为CLIP是大多数最先进的多模态系统的基础，这些输入会导致Midjourney 5.1、DALL-E、VideoFusion等系统失败。MultiMon也可以指导针对特定用例的相关故障，例如自驾车系统。",
    "tldr": "本文介绍了一种MultiMon系统，可以自动识别多模态系统中的系统性失败，揭示CLIP文本编码器的14个系统性失败，每个都由数百个不同的输入组成，这些输入会导致其他大多数最先进的多模态系统的失败。",
    "en_tdlr": "This paper presents a MultiMon system that automatically identifies systematic failures in multimodal systems and reveals 14 systematic failures of the CLIP text-encoder, each comprising hundreds of distinct inputs, which can cause failures in most state-of-the-art multimodal systems."
}