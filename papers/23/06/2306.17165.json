{
    "title": "An Efficient General-Purpose Modular Vision Model via Multi-Task Heterogeneous Training. (arXiv:2306.17165v1 [cs.CV])",
    "abstract": "We present a model that can perform multiple vision tasks and can be adapted to other downstream tasks efficiently. Despite considerable progress in multi-task learning, most efforts focus on learning from multi-label data: a single image set with multiple task labels. Such multi-label data sets are rare, small, and expensive. We say heterogeneous to refer to image sets with different task labels, or to combinations of single-task datasets. Few have explored training on such heterogeneous datasets. General-purpose vision models are still dominated by single-task pretraining, and it remains unclear how to scale up multi-task models by leveraging mainstream vision datasets designed for different purposes. The challenges lie in managing large intrinsic differences among vision tasks, including data distribution, architectures, task-specific modules, dataset scales, and sampling strategies. To address these challenges, we propose to modify and scale up mixture-of-experts (MoE) vision trans",
    "link": "http://arxiv.org/abs/2306.17165",
    "context": "Title: An Efficient General-Purpose Modular Vision Model via Multi-Task Heterogeneous Training. (arXiv:2306.17165v1 [cs.CV])\nAbstract: We present a model that can perform multiple vision tasks and can be adapted to other downstream tasks efficiently. Despite considerable progress in multi-task learning, most efforts focus on learning from multi-label data: a single image set with multiple task labels. Such multi-label data sets are rare, small, and expensive. We say heterogeneous to refer to image sets with different task labels, or to combinations of single-task datasets. Few have explored training on such heterogeneous datasets. General-purpose vision models are still dominated by single-task pretraining, and it remains unclear how to scale up multi-task models by leveraging mainstream vision datasets designed for different purposes. The challenges lie in managing large intrinsic differences among vision tasks, including data distribution, architectures, task-specific modules, dataset scales, and sampling strategies. To address these challenges, we propose to modify and scale up mixture-of-experts (MoE) vision trans",
    "path": "papers/23/06/2306.17165.json",
    "total_tokens": 898,
    "translated_title": "一种通过多任务异构训练实现高效通用模块化视觉模型的研究",
    "translated_abstract": "我们提出了一种模型，可以执行多个视觉任务，并且可以高效地适应其他后续任务。尽管在多任务学习方面取得了相当大的进展，但大多数工作都集中在从多标签数据中学习：即单个图像集合具有多个任务标签。这种多标签数据集很少、规模小且昂贵。我们将异构指的是具有不同任务标签的图像集，或者是单一任务数据集的组合。很少有人研究在这种异构数据集上进行训练。通用视觉模型仍然以单一任务预训练为主导，如何通过利用设计用于不同目的的主流视觉数据集来扩展多任务模型仍然不清楚。挑战在于管理视觉任务之间的大量内在差异，包括数据分布、架构、任务特定模块、数据集规模和采样策略。为了解决这些挑战，我们提出了修改和扩展专家混合(MoE)视觉转换的方法。",
    "tldr": "本文提出了一种通过多任务异构训练实现高效通用模块化视觉模型的方法，以应对在视觉任务之间的大量内在差异，并解决多任务模型扩展的挑战。"
}