{
    "title": "Equitable Multi-task Learning. (arXiv:2306.09373v1 [cs.LG])",
    "abstract": "Multi-task learning (MTL) has achieved great success in various research domains, such as CV, NLP and IR etc. Due to the complex and competing task correlation, na\\\"ive training all tasks may lead to inequitable learning, \\textit{i.e.} some tasks are learned well while others are overlooked. Multi-task optimization (MTO) aims to improve all tasks at same time, but conventional methods often perform poor when tasks with large loss scale or gradient norm magnitude difference. To solve the issue, we in-depth investigate the equity problem for MTL and find that regularizing relative contribution of different tasks (\\textit{i.e.} value of task-specific loss divides its raw gradient norm) in updating shared parameter can improve generalization performance of MTL. Based on our theoretical analysis, we propose a novel multi-task optimization method, named \\textit{EMTL}, to achieve equitable MTL. Specifically, we efficiently add variance regularization to make different tasks' relative contribu",
    "link": "http://arxiv.org/abs/2306.09373",
    "context": "Title: Equitable Multi-task Learning. (arXiv:2306.09373v1 [cs.LG])\nAbstract: Multi-task learning (MTL) has achieved great success in various research domains, such as CV, NLP and IR etc. Due to the complex and competing task correlation, na\\\"ive training all tasks may lead to inequitable learning, \\textit{i.e.} some tasks are learned well while others are overlooked. Multi-task optimization (MTO) aims to improve all tasks at same time, but conventional methods often perform poor when tasks with large loss scale or gradient norm magnitude difference. To solve the issue, we in-depth investigate the equity problem for MTL and find that regularizing relative contribution of different tasks (\\textit{i.e.} value of task-specific loss divides its raw gradient norm) in updating shared parameter can improve generalization performance of MTL. Based on our theoretical analysis, we propose a novel multi-task optimization method, named \\textit{EMTL}, to achieve equitable MTL. Specifically, we efficiently add variance regularization to make different tasks' relative contribu",
    "path": "papers/23/06/2306.09373.json",
    "total_tokens": 1082,
    "translated_title": "公平的多任务学习",
    "translated_abstract": "多任务学习（MTL）在各个研究领域（如计算机视觉、自然语言处理和信息检索等）中取得了巨大成功。但是，由于任务之间存在复杂且相互竞争的相关性，单纯地训练所有任务可能会导致不公平的学习，即一些任务被很好地学习，而其他任务则被忽视。多任务优化（MTO）旨在同时提高所有任务的表现，但传统方法往往在任务损失规模或梯度范数差异较大的情况下表现不佳。为了解决这个问题，我们深入研究了MTL的公平性问题，并发现在更新共享参数时，规范化不同任务的相对贡献（即任务特定损失值除以其原始梯度范数的值）可以提高MTL的泛化性能。基于我们的理论分析，我们提出了一种新的多任务优化方法，名为EMTL，以实现公平的MTL。具体来说，我们有效地添加了方差正则化，使不同任务的相对贡献更具可比性，并开发了一种高效的优化算法来保证收敛。我们在合成和真实数据集上进行了大量实验，结果表明了我们方法的有效性和优越性。",
    "tldr": "该论文提出了一种名为EMTL的多任务优化方法，以实现公平的多任务学习。通过规范化不同任务的相对贡献，可以提高MTL的泛化性能，并利用方差正则化和高效的优化算法保证收敛。实验证明，该方法在合成和真实数据集上均表现出了更好的性能。",
    "en_tdlr": "The paper proposes a novel multi-task optimization method, named EMTL, to achieve equitable multi-task learning. By regularizing the relative contribution of different tasks and using variance regularization and an efficient optimization algorithm, the method improves the generalization performance of multi-task learning. The experiments on both synthetic and real-world benchmarks demonstrate the effectiveness and superiority of the proposed method."
}