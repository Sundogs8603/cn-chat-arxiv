{
    "title": "Prefer to Classify: Improving Text Classifiers via Auxiliary Preference Learning. (arXiv:2306.04925v1 [cs.CL])",
    "abstract": "The development of largely human-annotated benchmarks has driven the success of deep neural networks in various NLP tasks. To enhance the effectiveness of existing benchmarks, collecting new additional input-output pairs is often too costly and challenging, particularly considering their marginal impact on improving the current model accuracy. Instead, additional or complementary annotations on the existing input texts in the benchmarks can be preferable as an efficient way to pay the additional human cost. In this paper, we investigate task-specific preferences between pairs of input texts as a new alternative way for such auxiliary data annotation. From 'pair-wise' comparisons with respect to the task, the auxiliary preference learning enables the model to learn an additional informative training signal that cannot be captured with 'instance-wise' task labels. To this end, we propose a novel multi-task learning framework, called prefer-to-classify (P2C), which can enjoy the cooperati",
    "link": "http://arxiv.org/abs/2306.04925",
    "context": "Title: Prefer to Classify: Improving Text Classifiers via Auxiliary Preference Learning. (arXiv:2306.04925v1 [cs.CL])\nAbstract: The development of largely human-annotated benchmarks has driven the success of deep neural networks in various NLP tasks. To enhance the effectiveness of existing benchmarks, collecting new additional input-output pairs is often too costly and challenging, particularly considering their marginal impact on improving the current model accuracy. Instead, additional or complementary annotations on the existing input texts in the benchmarks can be preferable as an efficient way to pay the additional human cost. In this paper, we investigate task-specific preferences between pairs of input texts as a new alternative way for such auxiliary data annotation. From 'pair-wise' comparisons with respect to the task, the auxiliary preference learning enables the model to learn an additional informative training signal that cannot be captured with 'instance-wise' task labels. To this end, we propose a novel multi-task learning framework, called prefer-to-classify (P2C), which can enjoy the cooperati",
    "path": "papers/23/06/2306.04925.json",
    "total_tokens": 887,
    "translated_title": "偏好分类：通过辅助偏好学习改进文本分类器",
    "translated_abstract": "大量人工标注的基准数据集推动了深度神经网络在各种自然语言处理任务中的成功。为了增强现有基准数据集的效果，收集新的输入输出对通常过于昂贵和具有挑战性，特别是考虑到它们对提高当前模型精度的边际影响。相反，对基准数据集中现有输入文本的附加或补充标注可能是一种有效的额外人工成本支付方式。本文研究了任务特定的输入文本对之间的偏好关系作为这种辅助数据标注的新替代方式。从任务相关的“成对”比较中，辅助偏好学习使模型学习到一种额外的信息性训练信号，这种信号无法通过“实例级”的任务标签来捕捉。为此，我们提出了一种新的多任务学习框架，称为prefer-to-classify （P2C），它可以同时享受实例级和偏好级任务。",
    "tldr": "本文提出了一种新的文本分类方法，使用偏好分类学习辅助数据来提高模型准确性。通过比较输入文本对之间的偏好关系，这种方法能够为模型提供额外的训练信号。",
    "en_tdlr": "This paper proposes a new text classification method that improves model accuracy by using auxiliary preference learning. By comparing preferences between pairs of input texts, this method provides additional training signals that cannot be captured with instance-wise task labels."
}