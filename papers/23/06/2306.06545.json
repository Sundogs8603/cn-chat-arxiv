{
    "title": "A Probabilistic Framework for Modular Continual Learning. (arXiv:2306.06545v1 [cs.LG])",
    "abstract": "Modular approaches, which use a different composition of modules for each problem and avoid forgetting by design, have been shown to be a promising direction in continual learning (CL). However, searching through the large, discrete space of possible module compositions is a challenge because evaluating a composition's performance requires a round of neural network training. To address this challenge, we develop a modular CL framework, called PICLE, that accelerates search by using a probabilistic model to cheaply compute the fitness of each composition. The model combines prior knowledge about good module compositions with dataset-specific information. Its use is complemented by splitting up the search space into subsets, such as perceptual and latent subsets. We show that PICLE is the first modular CL algorithm to achieve different types of transfer while scaling to large search spaces. We evaluate it on two benchmark suites designed to capture different desiderata of CL techniques. ",
    "link": "http://arxiv.org/abs/2306.06545",
    "context": "Title: A Probabilistic Framework for Modular Continual Learning. (arXiv:2306.06545v1 [cs.LG])\nAbstract: Modular approaches, which use a different composition of modules for each problem and avoid forgetting by design, have been shown to be a promising direction in continual learning (CL). However, searching through the large, discrete space of possible module compositions is a challenge because evaluating a composition's performance requires a round of neural network training. To address this challenge, we develop a modular CL framework, called PICLE, that accelerates search by using a probabilistic model to cheaply compute the fitness of each composition. The model combines prior knowledge about good module compositions with dataset-specific information. Its use is complemented by splitting up the search space into subsets, such as perceptual and latent subsets. We show that PICLE is the first modular CL algorithm to achieve different types of transfer while scaling to large search spaces. We evaluate it on two benchmark suites designed to capture different desiderata of CL techniques. ",
    "path": "papers/23/06/2306.06545.json",
    "total_tokens": 886,
    "translated_title": "一种基于概率框架的模块化增量学习方法",
    "translated_abstract": "模块化方法是增量学习领域的有前途方向，每个问题使用不同的模块组合且避免遗忘。然而，搜索可能的模块组合是一个挑战，因为评估组合性能需要一轮神经网络训练。为了解决这个问题，我们发展了一种名为PICLE的模块化增量学习框架，通过使用概率模型来快速计算每个组合的适应度来加速搜索。模型结合先前关于良好模块组合的知识与数据集特定信息。它的使用被分为感知和潜在子集等子集的搜索空间加以补充。我们展示了PICLE是第一个可以实现不同类型的转移的模块化增量学习算法，同时还能扩展到大型搜索空间。我们在两个基准套件上对其进行评估，这些套件旨在捕捉增量学习技术的不同要求。",
    "tldr": "本文提出了一种名为PICLE的模块化增量学习框架，利用概率模型快速计算每个组合的适应度来加速搜索，是第一个可以实现不同类型的转移的模块化增量学习算法。"
}