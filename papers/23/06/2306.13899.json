{
    "title": "Math Word Problem Solving by Generating Linguistic Variants of Problem Statements. (arXiv:2306.13899v1 [cs.CL])",
    "abstract": "The art of mathematical reasoning stands as a fundamental pillar of intellectual progress and is a central catalyst in cultivating human ingenuity. Researchers have recently published a plethora of works centered around the task of solving Math Word Problems (MWP) $-$ a crucial stride towards general AI. These existing models are susceptible to dependency on shallow heuristics and spurious correlations to derive the solution expressions. In order to ameliorate this issue, in this paper, we propose a framework for MWP solvers based on the generation of linguistic variants of the problem text. The approach involves solving each of the variant problems and electing the predicted expression with the majority of the votes. We use DeBERTa (Decoding-enhanced BERT with disentangled attention) as the encoder to leverage its rich textual representations and enhanced mask decoder to construct the solution expressions. Furthermore, we introduce a challenging dataset, $\\mathrm{P\\small{ARA}\\normalsi",
    "link": "http://arxiv.org/abs/2306.13899",
    "context": "Title: Math Word Problem Solving by Generating Linguistic Variants of Problem Statements. (arXiv:2306.13899v1 [cs.CL])\nAbstract: The art of mathematical reasoning stands as a fundamental pillar of intellectual progress and is a central catalyst in cultivating human ingenuity. Researchers have recently published a plethora of works centered around the task of solving Math Word Problems (MWP) $-$ a crucial stride towards general AI. These existing models are susceptible to dependency on shallow heuristics and spurious correlations to derive the solution expressions. In order to ameliorate this issue, in this paper, we propose a framework for MWP solvers based on the generation of linguistic variants of the problem text. The approach involves solving each of the variant problems and electing the predicted expression with the majority of the votes. We use DeBERTa (Decoding-enhanced BERT with disentangled attention) as the encoder to leverage its rich textual representations and enhanced mask decoder to construct the solution expressions. Furthermore, we introduce a challenging dataset, $\\mathrm{P\\small{ARA}\\normalsi",
    "path": "papers/23/06/2306.13899.json",
    "total_tokens": 1208,
    "translated_title": "通过生成问题陈述的语言变体解决数学问题",
    "translated_abstract": "数学推理艺术是智力进展的基本支柱，是培养人类独创性的核心催化剂。最近，研究人员已发表了大量围绕解决数学语言问题（MWP）的作品，这是迈向通用AI的重要步骤。这些现有模型容易依赖于肤浅的启发式和虚假的相关性来推导解决方案表达式。为了改善这一问题，在本文中，我们提出了一个基于生成问题文本语言变体的MWP求解器框架。该方法涉及解决每个不同变体的问题并选择得票最多的预测表达式。我们使用DeBERTa（具有解码增强的BERT和分离注意力）作为编码器，以利用其丰富的文本表示和增强的遮罩解码器来构造解决方案表达式。此外，我们引入了一个具有挑战性的数据集$\\mathrm{P\\small{ARA}\\normalsize}_\\mathrm{gen}$-MWP，以评估模型在生成和解析变体问题方面的性能。我们的结果显示，所提出的框架在两个基准数据集和我们提出的$\\mathrm{P\\small{ARA}\\normalsize}_\\mathrm{gen}$-MWP上都优于现有技术水平的模型，证明了其通过理解和推理问题文本的语义细微差别来推导正确的解决方案表达式的能力。",
    "tldr": "该论文提出了一个通过生成问题文本语言变体的方法来解决数学问题，该方法利用DeBERTa作为编码器，同时引入了一个挑战性的数据集用于评估模型性能。结果表明，该框架在两个基准数据集以及作者提出的数据集上优于现有技术水平的模型，证明了其推导正确的解决方案表达式的能力。",
    "en_tdlr": "This paper proposes a method for solving math word problems by generating linguistic variants of problem statements. The approach involves solving each variant problem and electing the predicted expression with the majority of the votes. The authors use DeBERTa as the encoder and introduce a challenging dataset for evaluating model performance. Results show that the proposed framework surpasses state-of-the-art models on benchmark datasets and the proposed dataset, indicating its ability to reason about semantic nuances and derive correct solution expressions."
}