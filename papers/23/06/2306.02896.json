{
    "title": "Representational Strengths and Limitations of Transformers. (arXiv:2306.02896v1 [cs.LG])",
    "abstract": "Attention layers, as commonly used in transformers, form the backbone of modern deep learning, yet there is no mathematical description of their benefits and deficiencies as compared with other architectures. In this work we establish both positive and negative results on the representation power of attention layers, with a focus on intrinsic complexity parameters such as width, depth, and embedding dimension. On the positive side, we present a sparse averaging task, where recurrent networks and feedforward networks all have complexity scaling polynomially in the input size, whereas transformers scale merely logarithmically in the input size; furthermore, we use the same construction to show the necessity and role of a large embedding dimension in a transformer. On the negative side, we present a triple detection task, where attention layers in turn have complexity scaling linearly in the input size; as this scenario seems rare in practice, we also present natural variants that can be ",
    "link": "http://arxiv.org/abs/2306.02896",
    "context": "Title: Representational Strengths and Limitations of Transformers. (arXiv:2306.02896v1 [cs.LG])\nAbstract: Attention layers, as commonly used in transformers, form the backbone of modern deep learning, yet there is no mathematical description of their benefits and deficiencies as compared with other architectures. In this work we establish both positive and negative results on the representation power of attention layers, with a focus on intrinsic complexity parameters such as width, depth, and embedding dimension. On the positive side, we present a sparse averaging task, where recurrent networks and feedforward networks all have complexity scaling polynomially in the input size, whereas transformers scale merely logarithmically in the input size; furthermore, we use the same construction to show the necessity and role of a large embedding dimension in a transformer. On the negative side, we present a triple detection task, where attention layers in turn have complexity scaling linearly in the input size; as this scenario seems rare in practice, we also present natural variants that can be ",
    "path": "papers/23/06/2306.02896.json",
    "total_tokens": 930,
    "translated_title": "Transformer的代表性优势和局限性",
    "translated_abstract": "注意力层常用于transformer中，是现代深度学习的支柱之一，但与其他网络结构相比，它们的好处和缺陷没有数学描述。在本研究中，我们对注意力层的表示能力进行了正面和负面的研究，并聚焦于内在复杂度参数，如宽度、深度和嵌入维度。在正面方面，我们提出了一项稀疏平均任务，其中循环网络和前馈网络的复杂度都随输入大小呈多项式缩放，而transformer仅呈对数缩放；此外，我们使用相同的构造来展示transformer中大嵌入维度的必要性和作用。在负面方面，我们提出了一个三元检测任务，其中注意力层的复杂度随输入大小呈线性缩放；由于这种情况在实践中似乎很少发生，因此我们还提出了可以替代的变体。",
    "tldr": "本文研究了transformer的表示能力，正面说明了transformer在稀疏平均任务中的效率比循环网络和前馈网络更高，并展示了大嵌入维度在transformer中的必要性和作用；负面说明了注意力层的复杂度随输入大小线性缩放，但这种情况在实践中很少发生，可以使用替代的变体。",
    "en_tdlr": "This paper investigates the representational power of transformers, showing on the positive side that they are more efficient than recurrent and feedforward networks in a sparse averaging task and highlighting the necessity of a large embedding dimension. On the negative side, attention layers have linear complexity scaling in a triple detection task, but rare in practice and with potential alternative variants."
}