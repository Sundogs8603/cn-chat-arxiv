{
    "title": "Topic-Centric Explanations for News Recommendation. (arXiv:2306.07506v1 [cs.IR])",
    "abstract": "News recommender systems (NRS) have been widely applied for online news websites to help users find relevant articles based on their interests. Recent methods have demonstrated considerable success in terms of recommendation performance. However, the lack of explanation for these recommendations can lead to mistrust among users and lack of acceptance of recommendations. To address this issue, we propose a new explainable news model to construct a topic-aware explainable recommendation approach that can both accurately identify relevant articles and explain why they have been recommended, using information from associated topics. Additionally, our model incorporates two coherence metrics applied to assess topic quality, providing measure of the interpretability of these explanations. The results of our experiments on the MIND dataset indicate that the proposed explainable NRS outperforms several other baseline systems, while it is also capable of producing interpretable topics compared ",
    "link": "http://arxiv.org/abs/2306.07506",
    "context": "Title: Topic-Centric Explanations for News Recommendation. (arXiv:2306.07506v1 [cs.IR])\nAbstract: News recommender systems (NRS) have been widely applied for online news websites to help users find relevant articles based on their interests. Recent methods have demonstrated considerable success in terms of recommendation performance. However, the lack of explanation for these recommendations can lead to mistrust among users and lack of acceptance of recommendations. To address this issue, we propose a new explainable news model to construct a topic-aware explainable recommendation approach that can both accurately identify relevant articles and explain why they have been recommended, using information from associated topics. Additionally, our model incorporates two coherence metrics applied to assess topic quality, providing measure of the interpretability of these explanations. The results of our experiments on the MIND dataset indicate that the proposed explainable NRS outperforms several other baseline systems, while it is also capable of producing interpretable topics compared ",
    "path": "papers/23/06/2306.07506.json",
    "total_tokens": 803,
    "translated_title": "基于主题的新闻推荐的解释性方法",
    "translated_abstract": "新闻推荐系统被广泛应用于在线新闻网站，以帮助用户根据他们的兴趣找到相关文章。然而，推荐缺乏解释会导致用户的不信任和推荐的缺乏接受度。为了解决这个问题，我们提出了一种新的可解释的新闻模型，构建了一个基于主题的解释性推荐方法，可以准确地识别相关文章并解释为什么推荐这些文章，利用相关主题的信息。此外，我们的模型结合了两种用于评估主题质量的一致性度量，提供了这些解释的可解释性的度量。我们在MIND数据集上的实验结果表明，所提出的可解释性NRS优于其他几个基线系统，同时还能够产生可解释的主题。",
    "tldr": "提出了一种基于主题的解释性新闻推荐模型，可以准确地识别相关文章并解释为什么推荐这些文章，同时提高了解释的可解释性度量。"
}