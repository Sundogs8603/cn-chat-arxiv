{
    "title": "InstructZero: Efficient Instruction Optimization for Black-Box Large Language Models. (arXiv:2306.03082v2 [cs.AI] UPDATED)",
    "abstract": "Large language models~(LLMs) are instruction followers, but it can be challenging to find the best instruction for different situations, especially for black-box LLMs on which backpropagation is forbidden. Instead of directly optimizing the discrete instruction, we optimize a low-dimensional soft prompt applied to an open-source LLM to generate the instruction for the black-box LLM. On each iteration of the proposed method, which we call InstructZero, a soft prompt is converted into an instruction using the open-source LLM, which is then submitted to the black-box LLM for zero-shot evaluation, and the performance is sent to Bayesian optimization to produce new soft prompts improving the zero-shot performance. We evaluate InstructZero on different combinations of open-source LLMs and APIs including Vicuna and ChatGPT. Our results show that InstructZero outperforms SOTA auto-instruction methods across a variety of downstream tasks. Our code and data are publicly available at https://gith",
    "link": "http://arxiv.org/abs/2306.03082",
    "context": "Title: InstructZero: Efficient Instruction Optimization for Black-Box Large Language Models. (arXiv:2306.03082v2 [cs.AI] UPDATED)\nAbstract: Large language models~(LLMs) are instruction followers, but it can be challenging to find the best instruction for different situations, especially for black-box LLMs on which backpropagation is forbidden. Instead of directly optimizing the discrete instruction, we optimize a low-dimensional soft prompt applied to an open-source LLM to generate the instruction for the black-box LLM. On each iteration of the proposed method, which we call InstructZero, a soft prompt is converted into an instruction using the open-source LLM, which is then submitted to the black-box LLM for zero-shot evaluation, and the performance is sent to Bayesian optimization to produce new soft prompts improving the zero-shot performance. We evaluate InstructZero on different combinations of open-source LLMs and APIs including Vicuna and ChatGPT. Our results show that InstructZero outperforms SOTA auto-instruction methods across a variety of downstream tasks. Our code and data are publicly available at https://gith",
    "path": "papers/23/06/2306.03082.json",
    "total_tokens": 897,
    "translated_title": "《InstructZero: 针对黑盒大型语言模型的高效指令优化》",
    "translated_abstract": "大型语言模型是指令跟随者，但对于不同情况下最佳指令的选择可能面临挑战，特别是对于禁止反向传播的黑盒语言模型。我们不直接优化离散指令，而是优化一个应用于开源语言模型的低维软提示，以生成黑盒语言模型的指令。在所提出的InstructZero方法的每个迭代中，软提示被转换为一个指令，然后通过开源语言模型提交给黑盒语言模型进行零样本评估，并将性能发送给贝叶斯优化以生成改善零样本性能的新软提示。我们在不同的开源语言模型和API组合上评估了InstructZero，包括Vicuna和ChatGPT。我们的结果显示，在各种下游任务中，InstructZero优于现有自动指令方法。我们的代码和数据公开可用于https://gith。",
    "tldr": "InstructZero通过优化低维软提示而非离散指令，实现了对黑盒语言模型的高效指令优化，通过贝叶斯优化生成改善零样本性能的新软提示，并在不同任务上优于现有自动指令方法。"
}