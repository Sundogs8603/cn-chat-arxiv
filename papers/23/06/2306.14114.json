{
    "title": "TNPAR: Topological Neural Poisson Auto-Regressive Model for Learning Granger Causal Structure from Event Sequences. (arXiv:2306.14114v1 [cs.LG])",
    "abstract": "Learning Granger causality from event sequences is a challenging but essential task across various applications. Most existing methods rely on the assumption that event sequences are independent and identically distributed (i.i.d.). However, this i.i.d. assumption is often violated due to the inherent dependencies among the event sequences. Fortunately, in practice, we find these dependencies can be modeled by a topological network, suggesting a potential solution to the non-i.i.d. problem by introducing the prior topological network into Granger causal discovery. This observation prompts us to tackle two ensuing challenges: 1) how to model the event sequences while incorporating both the prior topological network and the latent Granger causal structure, and 2) how to learn the Granger causal structure. To this end, we devise a two-stage unified topological neural Poisson auto-regressive model. During the generation stage, we employ a variant of the neural Poisson process to model the ",
    "link": "http://arxiv.org/abs/2306.14114",
    "context": "Title: TNPAR: Topological Neural Poisson Auto-Regressive Model for Learning Granger Causal Structure from Event Sequences. (arXiv:2306.14114v1 [cs.LG])\nAbstract: Learning Granger causality from event sequences is a challenging but essential task across various applications. Most existing methods rely on the assumption that event sequences are independent and identically distributed (i.i.d.). However, this i.i.d. assumption is often violated due to the inherent dependencies among the event sequences. Fortunately, in practice, we find these dependencies can be modeled by a topological network, suggesting a potential solution to the non-i.i.d. problem by introducing the prior topological network into Granger causal discovery. This observation prompts us to tackle two ensuing challenges: 1) how to model the event sequences while incorporating both the prior topological network and the latent Granger causal structure, and 2) how to learn the Granger causal structure. To this end, we devise a two-stage unified topological neural Poisson auto-regressive model. During the generation stage, we employ a variant of the neural Poisson process to model the ",
    "path": "papers/23/06/2306.14114.json",
    "total_tokens": 1002,
    "translated_title": "TNPAR: 基于拓扑神经泊松自回归模型的事件序列Granger因果结构学习",
    "translated_abstract": "从事件序列中学习Granger因果关系是各种应用中具有挑战性但又至关重要的任务。大多数现有方法都依赖于事件序列独立同分布 (i.i.d.) 的假设。然而，由于事件序列之间的固有依赖关系，这一 i.i.d. 假设经常被违反。幸运的是，在实践中，我们发现这些依赖关系可以被建模成一个拓扑网络，因此可以通过将先验拓扑网络引入Granger因果发现来解决非 i.i.d. 问题。这一发现促使我们解决两个问题：1) 如何在模型事件序列时同时考虑先验拓扑网络和潜在的Granger因果结构；2) 如何学习Granger因果结构。为此，我们设计了一个两阶段的统一拓扑神经泊松自回归模型。在生成阶段，我们采用神经泊松过程的一种变体来建模事件发生的时刻，并通过拓扑关系和现有事件序列推断因果关系。",
    "tldr": "该论文提出了一种基于拓扑神经泊松自回归模型的方法，同时考虑先验拓扑网络和潜在的Granger因果结构来学习事件序列中的Granger因果关系，该方法通过推断因果关系来解决序列数据中的非 i.i.d. 问题",
    "en_tdlr": "This paper proposes a topological neural Poisson auto-regressive model (TNPAR) that considers both the prior topological network and the latent Granger causal structure to learn Granger causality from event sequences. By introducing the prior topological network, TNPAR tackles the violation of the i.i.d. assumption in sequence data and infers Granger causal relationships through causal discovery."
}