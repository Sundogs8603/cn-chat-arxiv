{
    "title": "Improving the Robustness of Summarization Systems with Dual Augmentation. (arXiv:2306.01090v1 [cs.CL])",
    "abstract": "A robust summarization system should be able to capture the gist of the document, regardless of the specific word choices or noise in the input. In this work, we first explore the summarization models' robustness against perturbations including word-level synonym substitution and noise. To create semantic-consistent substitutes, we propose a SummAttacker, which is an efficient approach to generating adversarial samples based on language models. Experimental results show that state-of-the-art summarization models have a significant decrease in performance on adversarial and noisy test sets. Next, we analyze the vulnerability of the summarization systems and explore improving the robustness by data augmentation. Specifically, the first brittleness factor we found is the poor understanding of infrequent words in the input. Correspondingly, we feed the encoder with more diverse cases created by SummAttacker in the input space. The other factor is in the latent space, where the attacked inp",
    "link": "http://arxiv.org/abs/2306.01090",
    "context": "Title: Improving the Robustness of Summarization Systems with Dual Augmentation. (arXiv:2306.01090v1 [cs.CL])\nAbstract: A robust summarization system should be able to capture the gist of the document, regardless of the specific word choices or noise in the input. In this work, we first explore the summarization models' robustness against perturbations including word-level synonym substitution and noise. To create semantic-consistent substitutes, we propose a SummAttacker, which is an efficient approach to generating adversarial samples based on language models. Experimental results show that state-of-the-art summarization models have a significant decrease in performance on adversarial and noisy test sets. Next, we analyze the vulnerability of the summarization systems and explore improving the robustness by data augmentation. Specifically, the first brittleness factor we found is the poor understanding of infrequent words in the input. Correspondingly, we feed the encoder with more diverse cases created by SummAttacker in the input space. The other factor is in the latent space, where the attacked inp",
    "path": "papers/23/06/2306.01090.json",
    "total_tokens": 1105,
    "translated_title": "用双重数据增强技术提高摘要系统的鲁棒性",
    "translated_abstract": "一个鲁棒的摘要系统应该能够捕捉到文档的要点，而不受特定单词选择或输入中的噪音的影响。在本文中，我们首先探索了摘要模型在包括单词级同义词替换和噪音在内的扰动下的鲁棒性。为了创建语义一致的替代词，我们提出了一种名为SummAttacker的方法，它是一种基于语言模型生成对抗样本的高效方法。实验结果显示，最先进的摘要模型在对抗性和噪音测试集上的性能显著下降。接下来，我们分析了摘要系统的弱点，并通过数据增强探索提高其鲁棒性的方法。具体来说，我们发现第一个脆弱性因素是摘要模型对输入中不常见单词的理解能力较差。相应地，我们将更多由SummAttacker在输入空间中创建的多样化案例馈入编码器。另一个因素在潜在空间中，攻击的输入会为解码器产生噪声表示。为了解决这个问题，我们提出了一种双重增强方法，该方法在训练阶段教摘要模型对随机噪声具有不变性。实验结果表明，双重增强可以显著提高摘要模型在对抗性和噪音测试集上的性能。",
    "tldr": "本文通过数据增强和对抗样本生成技术提出了一种用于提高摘要系统鲁棒性的双重增强方法，该方法可以有效提高模型在对抗性和噪音测试集上的性能。",
    "en_tdlr": "This paper proposes a dual augmentation approach to improve the robustness of summarization systems against adversarial and noisy inputs, by feeding the encoder with more diverse cases and teaching the summarization model to be invariant to random noise during training. The approach significantly improves the performance of summarization models on such test sets."
}