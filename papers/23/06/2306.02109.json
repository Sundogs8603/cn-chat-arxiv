{
    "title": "Encoding Time-Series Explanations through Self-Supervised Model Behavior Consistency. (arXiv:2306.02109v2 [cs.LG] UPDATED)",
    "abstract": "Interpreting time series models is uniquely challenging because it requires identifying both the location of time series signals that drive model predictions and their matching to an interpretable temporal pattern. While explainers from other modalities can be applied to time series, their inductive biases do not transfer well to the inherently challenging interpretation of time series. We present TimeX, a time series consistency model for training explainers. TimeX trains an interpretable surrogate to mimic the behavior of a pretrained time series model. It addresses the issue of model faithfulness by introducing model behavior consistency, a novel formulation that preserves relations in the latent space induced by the pretrained model with relations in the latent space induced by TimeX. TimeX provides discrete attribution maps and, unlike existing interpretability methods, it learns a latent space of explanations that can be used in various ways, such as to provide landmarks to visua",
    "link": "http://arxiv.org/abs/2306.02109",
    "context": "Title: Encoding Time-Series Explanations through Self-Supervised Model Behavior Consistency. (arXiv:2306.02109v2 [cs.LG] UPDATED)\nAbstract: Interpreting time series models is uniquely challenging because it requires identifying both the location of time series signals that drive model predictions and their matching to an interpretable temporal pattern. While explainers from other modalities can be applied to time series, their inductive biases do not transfer well to the inherently challenging interpretation of time series. We present TimeX, a time series consistency model for training explainers. TimeX trains an interpretable surrogate to mimic the behavior of a pretrained time series model. It addresses the issue of model faithfulness by introducing model behavior consistency, a novel formulation that preserves relations in the latent space induced by the pretrained model with relations in the latent space induced by TimeX. TimeX provides discrete attribution maps and, unlike existing interpretability methods, it learns a latent space of explanations that can be used in various ways, such as to provide landmarks to visua",
    "path": "papers/23/06/2306.02109.json",
    "total_tokens": 874,
    "translated_title": "通过自监督模型行为一致性对时间序列解释进行编码",
    "translated_abstract": "解释时间序列模型是一项独特的挑战，因为它需要确定驱动模型预测的时间序列信号的位置以及它们与可解释的时间模式的匹配。尽管可以应用其他形式的解释器来解释时间序列，但它们的归纳偏差不适用于时间序列的挑战性解释。我们提出了TimeX，一种用于训练解释器的时间序列一致性模型。TimeX训练一个可解释的代理模型来模仿预训练时间序列模型的行为。它通过引入模型行为一致性来解决模型的忠实度问题，这是一种新颖的公式，它保留了由预训练模型引起的潜在空间中的关系与由TimeX引起的潜在空间中的关系。TimeX提供离散的归因图，不同于现有的可解释性方法，它学习了一种可以以各种方式使用的解释的潜在空间，例如，用于提供可视化的地标。",
    "tldr": "通过自监督模型行为一致性编码时间序列解释，提供离散的归因图，并学习了一种可用于各种方式的解释的潜在空间。",
    "en_tdlr": "Encoding time-series explanations through self-supervised model behavior consistency, providing discrete attribution maps, and learning a latent space of explanations that can be used in various ways."
}