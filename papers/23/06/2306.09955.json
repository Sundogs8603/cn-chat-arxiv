{
    "title": "Training shallow ReLU networks on noisy data using hinge loss: when do we overfit and is it benign?. (arXiv:2306.09955v1 [cs.LG])",
    "abstract": "We study benign overfitting in two-layer ReLU networks trained using gradient descent and hinge loss on noisy data for binary classification. In particular, we consider linearly separable data for which a relatively small proportion of labels are corrupted or flipped. We identify conditions on the margin of the clean data that give rise to three distinct training outcomes: benign overfitting, in which zero loss is achieved and with high probability test data is classified correctly; overfitting, in which zero loss is achieved but test data is misclassified with probability lower bounded by a constant; and non-overfitting, in which clean points, but not corrupt points, achieve zero loss and again with high probability test data is classified correctly. Our analysis provides a fine-grained description of the dynamics of neurons throughout training and reveals two distinct phases: in the first phase clean points achieve close to zero loss, in the second phase clean points oscillate on the",
    "link": "http://arxiv.org/abs/2306.09955",
    "context": "Title: Training shallow ReLU networks on noisy data using hinge loss: when do we overfit and is it benign?. (arXiv:2306.09955v1 [cs.LG])\nAbstract: We study benign overfitting in two-layer ReLU networks trained using gradient descent and hinge loss on noisy data for binary classification. In particular, we consider linearly separable data for which a relatively small proportion of labels are corrupted or flipped. We identify conditions on the margin of the clean data that give rise to three distinct training outcomes: benign overfitting, in which zero loss is achieved and with high probability test data is classified correctly; overfitting, in which zero loss is achieved but test data is misclassified with probability lower bounded by a constant; and non-overfitting, in which clean points, but not corrupt points, achieve zero loss and again with high probability test data is classified correctly. Our analysis provides a fine-grained description of the dynamics of neurons throughout training and reveals two distinct phases: in the first phase clean points achieve close to zero loss, in the second phase clean points oscillate on the",
    "path": "papers/23/06/2306.09955.json",
    "total_tokens": 1043,
    "translated_title": "使用合页损失在噪声数据上训练浅层ReLU网络：我们何时过度拟合且其是否良性？",
    "translated_abstract": "我们研究了使用梯度下降和合页损失在噪声数据上训练的二层ReLU网络在二分类中的良性过拟合现象。我们特别考虑了线性可分数据，其中相对较小比例的标签被损坏或翻转。我们确定了干净数据余量的条件，产生了三种不同的训练结果：良性过拟合，在这种情况下将达到零损失，并且具有很高的概率测试数据被正确分类；过拟合，在这种情况下将达到零损失，但测试数据被错误分类的概率受到常数下限的约束；以及不过拟合，在这种情况下干净的点可以达到零损失，并且具有很高的概率测试数据被正确分类，但是不干净的点无法做出同样的预测。我们的分析提供了对神经元在训练过程中动态变化的一种精细描述，并揭示了两个不同的阶段：在第一个阶段中，干净点接近达到零损失，在第二个阶段中，干净点会振荡。",
    "tldr": "本论文研究了二层ReLU网络在使用梯度下降和合页损失处理噪声数据进行二分类中的良性过拟合，通过对干净数据余量的条件的确定，得出了三种不同的训练结果，能够在训练过程中对神经元动态变化做出精细描述，并发现了两个不同的训练阶段。",
    "en_tdlr": "This paper investigates benign overfitting in two-layer ReLU networks trained using gradient descent and hinge loss on noisy data for binary classification, and identifies conditions on the margin of the clean data that give rise to three distinct training outcomes. The analysis provides a fine-grained description of the dynamics of neurons throughout training and reveals two distinct phases."
}