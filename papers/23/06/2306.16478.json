{
    "title": "Pre-Training Multi-Modal Dense Retrievers for Outside-Knowledge Visual Question Answering. (arXiv:2306.16478v1 [cs.IR])",
    "abstract": "This paper studies a category of visual question answering tasks, in which accessing external knowledge is necessary for answering the questions. This category is called outside-knowledge visual question answering (OK-VQA). A major step in developing OK-VQA systems is to retrieve relevant documents for the given multi-modal query. Current state-of-the-art asymmetric dense retrieval model for this task uses an architecture with a multi-modal query encoder and a uni-modal document encoder. Such an architecture requires a large amount of training data for effective performance. We propose an automatic data generation pipeline for pre-training passage retrieval models for OK-VQA tasks. The proposed approach leads to 26.9% Precision@5 improvements compared to the current state-of-the-art asymmetric architecture. Additionally, the proposed pre-training approach exhibits a good ability in zero-shot retrieval scenarios.",
    "link": "http://arxiv.org/abs/2306.16478",
    "context": "Title: Pre-Training Multi-Modal Dense Retrievers for Outside-Knowledge Visual Question Answering. (arXiv:2306.16478v1 [cs.IR])\nAbstract: This paper studies a category of visual question answering tasks, in which accessing external knowledge is necessary for answering the questions. This category is called outside-knowledge visual question answering (OK-VQA). A major step in developing OK-VQA systems is to retrieve relevant documents for the given multi-modal query. Current state-of-the-art asymmetric dense retrieval model for this task uses an architecture with a multi-modal query encoder and a uni-modal document encoder. Such an architecture requires a large amount of training data for effective performance. We propose an automatic data generation pipeline for pre-training passage retrieval models for OK-VQA tasks. The proposed approach leads to 26.9% Precision@5 improvements compared to the current state-of-the-art asymmetric architecture. Additionally, the proposed pre-training approach exhibits a good ability in zero-shot retrieval scenarios.",
    "path": "papers/23/06/2306.16478.json",
    "total_tokens": 870,
    "translated_title": "为外部知识视觉问答预训练多模态稠密检索器",
    "translated_abstract": "本文研究了一类视觉问答任务，其中访问外部知识对于回答问题是必要的。这个类别被称为外部知识视觉问答（OK-VQA）。开发OK-VQA系统的一个重要步骤是为给定的多模态查询检索相关文档。目前此任务的最先进的非对称稠密检索模型使用了一个多模态查询编码器和一个单模态文档编码器的架构。这样的架构需要大量的训练数据才能实现有效的性能。我们提出了一个用于预训练OK-VQA任务的段落检索模型的自动数据生成管道。与当前最先进的非对称架构相比，所提出的方法使Precision@5提升了26.9%。此外，所提出的预训练方法在零样本检索场景中展示了良好的能力。",
    "tldr": "本文提出了一个为外部知识视觉问答任务预训练的段落检索模型的自动数据生成管道，相较于最先进的架构实现了更好的Precision@5。此外，所提出的预训练方法在零样本检索场景中展示了良好的能力。",
    "en_tdlr": "This paper proposes an automatic data generation pipeline for pre-training passage retrieval models for outside-knowledge visual question answering (OK-VQA) tasks, achieving better Precision@5 compared to the state-of-the-art architecture. Additionally, the proposed pre-training approach exhibits good performance in zero-shot retrieval scenarios."
}