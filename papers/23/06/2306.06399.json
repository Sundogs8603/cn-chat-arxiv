{
    "title": "Personalized Graph Federated Learning with Differential Privacy. (arXiv:2306.06399v1 [cs.LG])",
    "abstract": "This paper presents a personalized graph federated learning (PGFL) framework in which distributedly connected servers and their respective edge devices collaboratively learn device or cluster-specific models while maintaining the privacy of every individual device. The proposed approach exploits similarities among different models to provide a more relevant experience for each device, even in situations with diverse data distributions and disproportionate datasets. Furthermore, to ensure a secure and efficient approach to collaborative personalized learning, we study a variant of the PGFL implementation that utilizes differential privacy, specifically zero-concentrated differential privacy, where a noise sequence perturbs model exchanges. Our mathematical analysis shows that the proposed privacy-preserving PGFL algorithm converges to the optimal cluster-specific solution for each cluster in linear time. It also shows that exploiting similarities among clusters leads to an alternative o",
    "link": "http://arxiv.org/abs/2306.06399",
    "context": "Title: Personalized Graph Federated Learning with Differential Privacy. (arXiv:2306.06399v1 [cs.LG])\nAbstract: This paper presents a personalized graph federated learning (PGFL) framework in which distributedly connected servers and their respective edge devices collaboratively learn device or cluster-specific models while maintaining the privacy of every individual device. The proposed approach exploits similarities among different models to provide a more relevant experience for each device, even in situations with diverse data distributions and disproportionate datasets. Furthermore, to ensure a secure and efficient approach to collaborative personalized learning, we study a variant of the PGFL implementation that utilizes differential privacy, specifically zero-concentrated differential privacy, where a noise sequence perturbs model exchanges. Our mathematical analysis shows that the proposed privacy-preserving PGFL algorithm converges to the optimal cluster-specific solution for each cluster in linear time. It also shows that exploiting similarities among clusters leads to an alternative o",
    "path": "papers/23/06/2306.06399.json",
    "total_tokens": 853,
    "translated_title": "差分隐私下的个性化图像联邦学习",
    "translated_abstract": "本文提出了一种个性化图像联邦学习框架，其中分布式连接的服务器和它们各自的边缘设备在保持每个单独设备隐私的同时，协同学习设备或集群特定的模型。该方法利用不同模型之间的相似性，为每个设备提供更相关的体验，即使在数据分布不均和数据集不成比例的情况下也能实现。此外，为了确保安全和高效的协作式个性化学习方法，我们研究了一种利用差分隐私的PGFL实现变体，具体而言就是使用了零聚焦差分隐私，其中噪声序列扰动了模型交换。我们的数学分析表明，所提出的具有隐私保护的PGFL算法在线性时间内收敛于每个簇的最优簇特定解。同时，利用簇之间的相似性也能够导致另一种优秀的解决方案。",
    "tldr": "本文提出了一种差分隐私下的个性化图像联邦学习框架，它能够协同学习设备或集群特定的模型，保护每个设备的隐私并提高学习效果。",
    "en_tdlr": "This paper proposes a personalized graph federated learning framework with differential privacy, which collaboratively learns device or cluster-specific models while maintaining individual device privacy and enhancing learning performance."
}