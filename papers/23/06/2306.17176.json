{
    "title": "News Verifiers Showdown: A Comparative Performance Evaluation of ChatGPT 3.5, ChatGPT 4.0, Bing AI, and Bard in News Fact-Checking. (arXiv:2306.17176v1 [cs.CL])",
    "abstract": "This study aimed to evaluate the proficiency of prominent Large Language Models (LLMs), namely OpenAI's ChatGPT 3.5 and 4.0, Google's Bard(LaMDA), and Microsoft's Bing AI in discerning the truthfulness of news items using black box testing. A total of 100 fact-checked news items, all sourced from independent fact-checking agencies, were presented to each of these LLMs under controlled conditions. Their responses were classified into one of three categories: True, False, and Partially True/False. The effectiveness of the LLMs was gauged based on the accuracy of their classifications against the verified facts provided by the independent agencies. The results showed a moderate proficiency across all models, with an average score of 65.25 out of 100. Among the models, OpenAI's GPT-4.0 stood out with a score of 71, suggesting an edge in newer LLMs' abilities to differentiate fact from deception. However, when juxtaposed against the performance of human fact-checkers, the AI models, despite",
    "link": "http://arxiv.org/abs/2306.17176",
    "context": "Title: News Verifiers Showdown: A Comparative Performance Evaluation of ChatGPT 3.5, ChatGPT 4.0, Bing AI, and Bard in News Fact-Checking. (arXiv:2306.17176v1 [cs.CL])\nAbstract: This study aimed to evaluate the proficiency of prominent Large Language Models (LLMs), namely OpenAI's ChatGPT 3.5 and 4.0, Google's Bard(LaMDA), and Microsoft's Bing AI in discerning the truthfulness of news items using black box testing. A total of 100 fact-checked news items, all sourced from independent fact-checking agencies, were presented to each of these LLMs under controlled conditions. Their responses were classified into one of three categories: True, False, and Partially True/False. The effectiveness of the LLMs was gauged based on the accuracy of their classifications against the verified facts provided by the independent agencies. The results showed a moderate proficiency across all models, with an average score of 65.25 out of 100. Among the models, OpenAI's GPT-4.0 stood out with a score of 71, suggesting an edge in newer LLMs' abilities to differentiate fact from deception. However, when juxtaposed against the performance of human fact-checkers, the AI models, despite",
    "path": "papers/23/06/2306.17176.json",
    "total_tokens": 1063,
    "translated_title": "新闻验证者的对决：ChatGPT 3.5、ChatGPT 4.0、Bing AI和Bard在新闻事实检查中的比较性能评估",
    "translated_abstract": "本研究旨在评估知名大型语言模型（LLMs），包括OpenAI的ChatGPT 3.5和4.0、谷歌的Bard（LaMDA）和微软的Bing AI，在使用黑盒测试区分新闻真实性方面的熟练程度。总共提供了100条经过事实核查的新闻，所有新闻均来自独立的事实核查机构，在受控条件下向每个LLMs提供。它们的回答被归类为三类：真实、错误和部分真实/错误。基于独立机构提供的核实事实，评估了LLMs的分类准确性来衡量其有效性。结果显示，所有模型的熟练程度都属于中等水平，平均得分为65.25/100。在这些模型中，OpenAI的GPT-4.0以71分的得分脱颖而出，表明较新的LLMs在区分真相和欺骗方面具有优势。然而，与人类事实核查员的表现相比，尽管AI模型表现出一定的熟练度，但仍有改进空间。",
    "tldr": "本研究通过对比实验评估了ChatGPT 3.5、ChatGPT 4.0、Bing AI和Bard在新闻事实检查中的表现，结果显示它们的熟练程度普遍居中，其中OpenAI的GPT-4.0在区分真相和欺骗方面具有一定优势。",
    "en_tdlr": "This study evaluated the performance of ChatGPT 3.5, ChatGPT 4.0, Bing AI, and Bard in news fact-checking. The results showed moderate proficiency across all models, with OpenAI's GPT-4.0 demonstrating an edge in differentiating fact from deception."
}