{
    "title": "Risk-Aware Reward Shaping of Reinforcement Learning Agents for Autonomous Driving. (arXiv:2306.03220v1 [cs.RO])",
    "abstract": "Reinforcement learning (RL) is an effective approach to motion planning in autonomous driving, where an optimal driving policy can be automatically learned using the interaction data with the environment. Nevertheless, the reward function for an RL agent, which is significant to its performance, is challenging to be determined. The conventional work mainly focuses on rewarding safe driving states but does not incorporate the awareness of risky driving behaviors of the vehicles. In this paper, we investigate how to use risk-aware reward shaping to leverage the training and test performance of RL agents in autonomous driving. Based on the essential requirements that prescribe the safety specifications for general autonomous driving in practice, we propose additional reshaped reward terms that encourage exploration and penalize risky driving behaviors. A simulation study in OpenAI Gym indicates the advantage of risk-aware reward shaping for various RL agents. Also, we point out that proxi",
    "link": "http://arxiv.org/abs/2306.03220",
    "context": "Title: Risk-Aware Reward Shaping of Reinforcement Learning Agents for Autonomous Driving. (arXiv:2306.03220v1 [cs.RO])\nAbstract: Reinforcement learning (RL) is an effective approach to motion planning in autonomous driving, where an optimal driving policy can be automatically learned using the interaction data with the environment. Nevertheless, the reward function for an RL agent, which is significant to its performance, is challenging to be determined. The conventional work mainly focuses on rewarding safe driving states but does not incorporate the awareness of risky driving behaviors of the vehicles. In this paper, we investigate how to use risk-aware reward shaping to leverage the training and test performance of RL agents in autonomous driving. Based on the essential requirements that prescribe the safety specifications for general autonomous driving in practice, we propose additional reshaped reward terms that encourage exploration and penalize risky driving behaviors. A simulation study in OpenAI Gym indicates the advantage of risk-aware reward shaping for various RL agents. Also, we point out that proxi",
    "path": "papers/23/06/2306.03220.json",
    "total_tokens": 961,
    "translated_title": "面向自动驾驶的风险感知奖励形成的强化学习代理",
    "translated_abstract": "强化学习是自动驾驶中有效的运动规划方法，可以通过与环境的交互数据自动学习最优驾驶策略。然而，对于RL代理的奖励函数，其对于性能的影响很大，但是很难确定。传统的研究主要关注安全驾驶状态的奖励，但并未纳入车辆风险驾驶行为的感知。本文研究如何使用风险感知的奖励形成来提高自动驾驶中RL代理的训练和测试性能。根据实践中规定的一般自动驾驶的安全要求，我们提出了额外的重塑奖励项，以鼓励探索并惩罚风险驾驶行为。 OpenAI Gym中的模拟研究表明了风险感知奖励形成在各种RL代理中的优势。同时，我们指出代理转移的方式对风险感知奖励形成影响的现实潜力。",
    "tldr": "本研究针对自动驾驶中RL代理的安全性问题，提出了一种增加风险感知的奖励形成方法来提高其训练和测试性能。该方法通过额外的重塑奖励项来鼓励探索并惩罚风险驾驶行为，证明其在各种RL代理中具有优势。",
    "en_tdlr": "This study proposes an approach to improve the training and testing performance of RL agents in autonomous driving by introducing risk-aware reward shaping. By reshaping reward terms to encourage exploration and penalize risky driving behaviors, the proposed approach demonstrates its advantages for various RL agents in a simulation study."
}