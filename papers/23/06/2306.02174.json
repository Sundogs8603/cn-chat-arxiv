{
    "title": "Training Data Attribution for Diffusion Models. (arXiv:2306.02174v1 [stat.ML])",
    "abstract": "Diffusion models have become increasingly popular for synthesizing high-quality samples based on training datasets. However, given the oftentimes enormous sizes of the training datasets, it is difficult to assess how training data impact the samples produced by a trained diffusion model. The difficulty of relating diffusion model inputs and outputs poses significant challenges to model explainability and training data attribution. Here we propose a novel solution that reveals how training data influence the output of diffusion models through the use of ensembles. In our approach individual models in an encoded ensemble are trained on carefully engineered splits of the overall training data to permit the identification of influential training examples. The resulting model ensembles enable efficient ablation of training data influence, allowing us to assess the impact of training data on model outputs. We demonstrate the viability of these ensembles as generative models and the validity ",
    "link": "http://arxiv.org/abs/2306.02174",
    "context": "Title: Training Data Attribution for Diffusion Models. (arXiv:2306.02174v1 [stat.ML])\nAbstract: Diffusion models have become increasingly popular for synthesizing high-quality samples based on training datasets. However, given the oftentimes enormous sizes of the training datasets, it is difficult to assess how training data impact the samples produced by a trained diffusion model. The difficulty of relating diffusion model inputs and outputs poses significant challenges to model explainability and training data attribution. Here we propose a novel solution that reveals how training data influence the output of diffusion models through the use of ensembles. In our approach individual models in an encoded ensemble are trained on carefully engineered splits of the overall training data to permit the identification of influential training examples. The resulting model ensembles enable efficient ablation of training data influence, allowing us to assess the impact of training data on model outputs. We demonstrate the viability of these ensembles as generative models and the validity ",
    "path": "papers/23/06/2306.02174.json",
    "total_tokens": 833,
    "translated_title": "神经扩散模型的训练数据归因",
    "translated_abstract": "随着神经扩散模型越来越受欢迎，用于合成高质量样本的训练数据集大小也不断增加，评估训练数据对训练后的模型生成样本的影响变得困难。为解决这一问题，本文提出了一种通过集成方法揭示训练数据对扩散模型输出的影响的新方法。在这种方法中，对整个训练数据集进行了精心设计的分裂，并在编码集合中训练单个模型，以允许识别有影响力的训练示例。由此产生的模型集合可以有效减弱训练数据的影响，使我们能够评估训练数据对模型输出的影响。我们证明了这些集合作为生成模型的可行性和有效性。",
    "tldr": "本文提出了一种使用集成方法揭示训练数据对扩散模型输出影响的方法，这些模型集合可以有效减弱训练数据的影响，使我们能够评估训练数据对模型输出的影响。",
    "en_tdlr": "This paper proposes a novel solution for training data attribution in diffusion models, which uses ensembles to reveal the impact of training data on model outputs. The resulting model ensembles enable efficient ablation of training data influence, allowing for the assessment of the impact of training data on model outputs."
}