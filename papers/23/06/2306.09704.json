{
    "title": "Cross-corpus Readability Compatibility Assessment for English Texts. (arXiv:2306.09704v1 [cs.CL])",
    "abstract": "Text readability assessment has gained significant attention from researchers in various domains. However, the lack of exploration into corpus compatibility poses a challenge as different research groups utilize different corpora. In this study, we propose a novel evaluation framework, Cross-corpus text Readability Compatibility Assessment (CRCA), to address this issue. The framework encompasses three key components: (1) Corpus: CEFR, CLEC, CLOTH, NES, OSP, and RACE. Linguistic features, GloVe word vector representations, and their fusion features were extracted. (2) Classification models: Machine learning methods (XGBoost, SVM) and deep learning methods (BiLSTM, Attention-BiLSTM) were employed. (3) Compatibility metrics: RJSD, RRNSS, and NDCG metrics. Our findings revealed: (1) Validated corpus compatibility, with OSP standing out as significantly different from other datasets. (2) An adaptation effect among corpora, feature representations, and classification methods. (3) Consistent ",
    "link": "http://arxiv.org/abs/2306.09704",
    "context": "Title: Cross-corpus Readability Compatibility Assessment for English Texts. (arXiv:2306.09704v1 [cs.CL])\nAbstract: Text readability assessment has gained significant attention from researchers in various domains. However, the lack of exploration into corpus compatibility poses a challenge as different research groups utilize different corpora. In this study, we propose a novel evaluation framework, Cross-corpus text Readability Compatibility Assessment (CRCA), to address this issue. The framework encompasses three key components: (1) Corpus: CEFR, CLEC, CLOTH, NES, OSP, and RACE. Linguistic features, GloVe word vector representations, and their fusion features were extracted. (2) Classification models: Machine learning methods (XGBoost, SVM) and deep learning methods (BiLSTM, Attention-BiLSTM) were employed. (3) Compatibility metrics: RJSD, RRNSS, and NDCG metrics. Our findings revealed: (1) Validated corpus compatibility, with OSP standing out as significantly different from other datasets. (2) An adaptation effect among corpora, feature representations, and classification methods. (3) Consistent ",
    "path": "papers/23/06/2306.09704.json",
    "total_tokens": 1041,
    "translated_title": "跨语料阅读性兼容性评估：英文文本",
    "translated_abstract": "文本的可读性评估在各个领域的研究人员中受到了重视。然而，对语料库兼容性的缺乏探索构成了一项挑战，因为不同的研究小组使用不同的语料库。本研究提出了一个新的评估框架，Cross-corpus text Readability Compatibility Assessment (CRCA)，来解决这个问题。该框架包括三个关键组成部分：(1) 语料库：CEFR，CLEC，CLOTH，NES，OSP和RACE。提取了语言特征、GloVe词向量表示和它们的融合特征。(2) 分类模型：采用了机器学习方法（XGBoost，SVM）和深度学习方法（BiLSTM，Attention-BiLSTM）。(3) 兼容性指标：RJSD，RRNSS和NDCG指标。我们的研究结果表明：(1) OSP表现显著不同于其他数据集的证实了语料兼容性。(2) 兼容性、特征表示和分类方法之间有适应性效应。(3) 在不同兼容性指标下得到了一致的评估结果，这表明了我们的框架的效果。",
    "tldr": "本文提出了一个新的评估框架，Cross-corpus text Readability Compatibility Assessment (CRCA)，用于解决不同语料库之间的可读性兼容性的问题。研究结果表明该框架具有显著的兼容性，并适用于不同的特征表示和分类方法。",
    "en_tdlr": "This paper proposes a new evaluation framework, Cross-corpus text Readability Compatibility Assessment (CRCA), to address the issue of compatibility among different corpora for readability assessment. The framework includes language features, GloVe word vector representations, and fusion features from multiple corpora, as well as machine learning and deep learning models for classification. The effectiveness of the framework is demonstrated through consistent evaluation results under different compatibility metrics."
}