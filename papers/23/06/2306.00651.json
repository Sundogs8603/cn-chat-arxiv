{
    "title": "Learning Prescriptive ReLU Networks. (arXiv:2306.00651v1 [cs.LG])",
    "abstract": "We study the problem of learning optimal policy from a set of discrete treatment options using observational data. We propose a piecewise linear neural network model that can balance strong prescriptive performance and interpretability, which we refer to as the prescriptive ReLU network, or P-ReLU. We show analytically that this model (i) partitions the input space into disjoint polyhedra, where all instances that belong to the same partition receive the same treatment, and (ii) can be converted into an equivalent prescriptive tree with hyperplane splits for interpretability. We demonstrate the flexibility of the P-ReLU network as constraints can be easily incorporated with minor modifications to the architecture. Through experiments, we validate the superior prescriptive accuracy of P-ReLU against competing benchmarks. Lastly, we present examples of interpretable prescriptive trees extracted from trained P-ReLUs using a real-world dataset, for both the unconstrained and constrained sc",
    "link": "http://arxiv.org/abs/2306.00651",
    "context": "Title: Learning Prescriptive ReLU Networks. (arXiv:2306.00651v1 [cs.LG])\nAbstract: We study the problem of learning optimal policy from a set of discrete treatment options using observational data. We propose a piecewise linear neural network model that can balance strong prescriptive performance and interpretability, which we refer to as the prescriptive ReLU network, or P-ReLU. We show analytically that this model (i) partitions the input space into disjoint polyhedra, where all instances that belong to the same partition receive the same treatment, and (ii) can be converted into an equivalent prescriptive tree with hyperplane splits for interpretability. We demonstrate the flexibility of the P-ReLU network as constraints can be easily incorporated with minor modifications to the architecture. Through experiments, we validate the superior prescriptive accuracy of P-ReLU against competing benchmarks. Lastly, we present examples of interpretable prescriptive trees extracted from trained P-ReLUs using a real-world dataset, for both the unconstrained and constrained sc",
    "path": "papers/23/06/2306.00651.json",
    "total_tokens": 891,
    "translated_title": "学习指导型ReLU神经网络",
    "translated_abstract": "本文研究使用观测数据从一组离散治疗选择中学习最佳策略的问题。我们提出了一种分段线性神经网络模型，可以平衡强大的指导性能和可解释性，我们称之为指导型ReLU网络或P-ReLU。我们在理论上展示了这个模型: (i) 将输入空间分成不相交的多面体，属于同一分区的所有实例接受相同的治疗方法；(ii) 可以转化为具有可解释性的具有超平面分裂的等效指导树。我们证明了P-ReLU网络的灵活性，因为可以通过对体系结构进行小的修改来轻松地合并约束条件。通过实验证明，P-ReLU相对于竞争基准模型具有更好的指导精度。最后，我们在使用真实世界数据集训练的P-ReLU中提取可解释的指导树的示例中，展示了无约束和约束情况下可解释性。",
    "tldr": "本文提出了一种名为P-ReLU的神经网络模型，用于从观测数据中学习最佳策略。该模型可平衡指导性能和可解释性，具有灵活性和有效性，在多个基准测试中均达到最佳精度。",
    "en_tdlr": "This paper proposes a neural network model called the P-ReLU for learning optimal policy from observational data with a balance between prescriptive performance and interpretability, achieving superior accuracy in multiple benchmarks and presenting examples of interpretable prescriptive trees extracted from the model."
}