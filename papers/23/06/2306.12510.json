{
    "title": "Comparative Analysis of Segment Anything Model and U-Net for Breast Tumor Detection in Ultrasound and Mammography Images. (arXiv:2306.12510v1 [eess.IV])",
    "abstract": "In this study, the main objective is to develop an algorithm capable of identifying and delineating tumor regions in breast ultrasound (BUS) and mammographic images. The technique employs two advanced deep learning architectures, namely U-Net and pretrained SAM, for tumor segmentation. The U-Net model is specifically designed for medical image segmentation and leverages its deep convolutional neural network framework to extract meaningful features from input images. On the other hand, the pretrained SAM architecture incorporates a mechanism to capture spatial dependencies and generate segmentation results. Evaluation is conducted on a diverse dataset containing annotated tumor regions in BUS and mammographic images, covering both benign and malignant tumors. This dataset enables a comprehensive assessment of the algorithm's performance across different tumor types. Results demonstrate that the U-Net model outperforms the pretrained SAM architecture in accurately identifying and segment",
    "link": "http://arxiv.org/abs/2306.12510",
    "context": "Title: Comparative Analysis of Segment Anything Model and U-Net for Breast Tumor Detection in Ultrasound and Mammography Images. (arXiv:2306.12510v1 [eess.IV])\nAbstract: In this study, the main objective is to develop an algorithm capable of identifying and delineating tumor regions in breast ultrasound (BUS) and mammographic images. The technique employs two advanced deep learning architectures, namely U-Net and pretrained SAM, for tumor segmentation. The U-Net model is specifically designed for medical image segmentation and leverages its deep convolutional neural network framework to extract meaningful features from input images. On the other hand, the pretrained SAM architecture incorporates a mechanism to capture spatial dependencies and generate segmentation results. Evaluation is conducted on a diverse dataset containing annotated tumor regions in BUS and mammographic images, covering both benign and malignant tumors. This dataset enables a comprehensive assessment of the algorithm's performance across different tumor types. Results demonstrate that the U-Net model outperforms the pretrained SAM architecture in accurately identifying and segment",
    "path": "papers/23/06/2306.12510.json",
    "total_tokens": 940,
    "translated_title": "基于U-Net和Segment Anything Model的乳腺肿瘤在超声和乳腺X线图像中的对比分析",
    "translated_abstract": "本研究的主要目标是开发一种能够在乳腺超声（BUS）和乳腺X线图像中识别和描绘肿瘤区域的算法。该技术采用了两种先进的深度学习架构，即U-Net和pretrained SAM，用于肿瘤分割。U-Net模型专门设计用于医学图像分割，利用其深卷积神经网络框架从输入图像中提取有意义的特征。另一方面，pretrained SAM架构引入了一种机制来捕捉空间依赖关系并生成分割结果。评估在不同良性和恶性肿瘤的注释肿瘤区域的多样化数据集上进行。结果表明，U-Net模型能够在BUS和乳腺X线图像中准确地识别和分割乳腺肿瘤，且优于pretrained SAM架构。",
    "tldr": "研究采用U-Net和pretrained SAM两种深度学习架构，针对乳腺超声和乳腺X线图像，进行肿瘤区域的识别和分割。结果表明，U-Net模型对于不同类型的良性和恶性肿瘤的识别和分割效果更好。",
    "en_tdlr": "The study uses two deep learning architectures, U-Net and pretrained SAM, to identify and segment tumor regions in breast ultrasound and mammography images, with U-Net model outperforming pretrained SAM in accurately identifying and segmenting breast tumors of different types."
}