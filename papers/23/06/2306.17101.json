{
    "title": "Identifying Important Sensory Feedback for Learning Locomotion Skills. (arXiv:2306.17101v1 [cs.RO])",
    "abstract": "Robot motor skills can be learned through deep reinforcement learning (DRL) by neural networks as state-action mappings. While the selection of state observations is crucial, there has been a lack of quantitative analysis to date. Here, we present a systematic saliency analysis that quantitatively evaluates the relative importance of different feedback states for motor skills learned through DRL. Our approach can identify the most essential feedback states for locomotion skills, including balance recovery, trotting, bounding, pacing and galloping. By using only key states including joint positions, gravity vector, base linear and angular velocities, we demonstrate that a simulated quadruped robot can achieve robust performance in various test scenarios across these distinct skills. The benchmarks using task performance metrics show that locomotion skills learned with key states can achieve comparable performance to those with all states, and the task performance or learning success rat",
    "link": "http://arxiv.org/abs/2306.17101",
    "context": "Title: Identifying Important Sensory Feedback for Learning Locomotion Skills. (arXiv:2306.17101v1 [cs.RO])\nAbstract: Robot motor skills can be learned through deep reinforcement learning (DRL) by neural networks as state-action mappings. While the selection of state observations is crucial, there has been a lack of quantitative analysis to date. Here, we present a systematic saliency analysis that quantitatively evaluates the relative importance of different feedback states for motor skills learned through DRL. Our approach can identify the most essential feedback states for locomotion skills, including balance recovery, trotting, bounding, pacing and galloping. By using only key states including joint positions, gravity vector, base linear and angular velocities, we demonstrate that a simulated quadruped robot can achieve robust performance in various test scenarios across these distinct skills. The benchmarks using task performance metrics show that locomotion skills learned with key states can achieve comparable performance to those with all states, and the task performance or learning success rat",
    "path": "papers/23/06/2306.17101.json",
    "total_tokens": 898,
    "translated_title": "鉴定学习动作技能中重要的感觉反馈",
    "translated_abstract": "通过神经网络作为状态-动作映射的深度强化学习(DRL)可以学习机器人的运动技能。虽然状态观测的选择至关重要，但目前缺乏定量分析。在这里，我们提供了一种系统的显著性分析方法，定量评估通过DRL学习到的各种反馈状态的相对重要性。我们的方法可以确定对于步态技能（包括平衡恢复、小跑、跳跃、步速和奔腾）最重要的反馈状态。通过仅使用关键状态，包括关节位置、重力向量、基座的线性和角速度，我们证明了虚拟四足机器人在各种测试场景中可以实现稳健的性能。使用任务性能指标来进行基准测试表明，使用关键状态学习到的步态技能可以达到与使用所有状态学习到的技能相当的性能，以及任务性能或学习成功率。",
    "tldr": "通过深度强化学习学习机器人运动技能时，我们通过一种显著性分析方法定量评估了不同反馈状态的相对重要性。我们发现关节位置、重力向量和速度等关键状态可以实现与使用所有状态相当的步态技能性能。",
    "en_tdlr": "The relative importance of different feedback states in learning robot motor skills through deep reinforcement learning (DRL) was quantitatively evaluated using a saliency analysis. It was found that key states such as joint positions, gravity vector, and velocities can achieve comparable locomotion skills performance to using all states."
}