{
    "title": "Multi-Loss Convolutional Network with Time-Frequency Attention for Speech Enhancement. (arXiv:2306.08956v1 [cs.SD])",
    "abstract": "The Dual-Path Convolution Recurrent Network (DPCRN) was proposed to effectively exploit time-frequency domain information. By combining the DPRNN module with Convolution Recurrent Network (CRN), the DPCRN obtained a promising performance in speech separation with a limited model size. In this paper, we explore self-attention in the DPCRN module and design a model called Multi-Loss Convolutional Network with Time-Frequency Attention(MNTFA) for speech enhancement. We use self-attention modules to exploit the long-time information, where the intra-chunk self-attentions are used to model the spectrum pattern and the inter-chunk self-attention are used to model the dependence between consecutive frames. Compared to DPRNN, axial self-attention greatly reduces the need for memory and computation, which is more suitable for long sequences of speech signals. In addition, we propose a joint training method of a multi-resolution STFT loss and a WavLM loss using a pre-trained WavLM network. Experi",
    "link": "http://arxiv.org/abs/2306.08956",
    "context": "Title: Multi-Loss Convolutional Network with Time-Frequency Attention for Speech Enhancement. (arXiv:2306.08956v1 [cs.SD])\nAbstract: The Dual-Path Convolution Recurrent Network (DPCRN) was proposed to effectively exploit time-frequency domain information. By combining the DPRNN module with Convolution Recurrent Network (CRN), the DPCRN obtained a promising performance in speech separation with a limited model size. In this paper, we explore self-attention in the DPCRN module and design a model called Multi-Loss Convolutional Network with Time-Frequency Attention(MNTFA) for speech enhancement. We use self-attention modules to exploit the long-time information, where the intra-chunk self-attentions are used to model the spectrum pattern and the inter-chunk self-attention are used to model the dependence between consecutive frames. Compared to DPRNN, axial self-attention greatly reduces the need for memory and computation, which is more suitable for long sequences of speech signals. In addition, we propose a joint training method of a multi-resolution STFT loss and a WavLM loss using a pre-trained WavLM network. Experi",
    "path": "papers/23/06/2306.08956.json",
    "total_tokens": 914,
    "translated_title": "利用时频注意力的多损失卷积网络用于语音增强",
    "translated_abstract": "本文提出了一种称为多损失卷积网络与时频注意力（MNTFA）的模型，用于语音增强。该模型利用了自注意力模块来挖掘长时间信息，其中 intra-chunk 自注意力用于建模频谱模式，而 inter-chunk 自注意力用于建模连续帧之间的依赖关系。相比于 DPRNN，轴向自注意力大大降低了内存和计算的需求，更适合处理长语音序列。此外，作者还提出了一种使用预训练 WavLM 网络的多分辨率 STFT 损失和 WavLM 损失的联合训练方法。在 DNS-Challenge 数据集上的实验证明了所提出的 MNTFA 在 PESQ 和 STOI 指标方面的性能均达到了当前最先进水平。",
    "tldr": "本文提出了利用自注意力模块的多损失卷积网络与时频注意力（MNTFA）模型，用于语音增强，实验结果表明该模型在 PESQ 和 STOI 指标方面达到了当前最先进水平。",
    "en_tdlr": "This paper proposes a Multi-Loss Convolutional Network with Time-Frequency Attention (MNTFA) model that utilizes self-attention modules to exploit long-time information for speech enhancement. Experimental results show that the proposed model achieves state-of-the-art performance in terms of PESQ and STOI metrics on the DNS-Challenge dataset."
}