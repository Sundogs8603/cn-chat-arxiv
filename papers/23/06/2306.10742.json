{
    "title": "BNN-DP: Robustness Certification of Bayesian Neural Networks via Dynamic Programming. (arXiv:2306.10742v1 [cs.LG])",
    "abstract": "In this paper, we introduce BNN-DP, an efficient algorithmic framework for analysis of adversarial robustness of Bayesian Neural Networks (BNNs). Given a compact set of input points $T\\subset \\mathbb{R}^n$, BNN-DP computes lower and upper bounds on the BNN's predictions for all the points in $T$. The framework is based on an interpretation of BNNs as stochastic dynamical systems, which enables the use of Dynamic Programming (DP) algorithms to bound the prediction range along the layers of the network. Specifically, the method uses bound propagation techniques and convex relaxations to derive a backward recursion procedure to over-approximate the prediction range of the BNN with piecewise affine functions. The algorithm is general and can handle both regression and classification tasks. On a set of experiments on various regression and classification tasks and BNN architectures, we show that BNN-DP outperforms state-of-the-art methods by up to four orders of magnitude in both tightness ",
    "link": "http://arxiv.org/abs/2306.10742",
    "context": "Title: BNN-DP: Robustness Certification of Bayesian Neural Networks via Dynamic Programming. (arXiv:2306.10742v1 [cs.LG])\nAbstract: In this paper, we introduce BNN-DP, an efficient algorithmic framework for analysis of adversarial robustness of Bayesian Neural Networks (BNNs). Given a compact set of input points $T\\subset \\mathbb{R}^n$, BNN-DP computes lower and upper bounds on the BNN's predictions for all the points in $T$. The framework is based on an interpretation of BNNs as stochastic dynamical systems, which enables the use of Dynamic Programming (DP) algorithms to bound the prediction range along the layers of the network. Specifically, the method uses bound propagation techniques and convex relaxations to derive a backward recursion procedure to over-approximate the prediction range of the BNN with piecewise affine functions. The algorithm is general and can handle both regression and classification tasks. On a set of experiments on various regression and classification tasks and BNN architectures, we show that BNN-DP outperforms state-of-the-art methods by up to four orders of magnitude in both tightness ",
    "path": "papers/23/06/2306.10742.json",
    "total_tokens": 901,
    "translated_title": "BNN-DP: 通过动态规划对贝叶斯神经网络进行鲁棒性认证",
    "translated_abstract": "本文提出了一种高效的算法框架BNN-DP，用于分析贝叶斯神经网络（BNN）的对抗性鲁棒性。该框架基于将BNN视为随机动态系统的解释，利用动态规划算法沿着网络层次边界估计BNN的预测范围。具体而言，该方法使用边界传播技术和凸松弛来导出反向递归过程，利用分段仿射函数来优化BNN的预测范围。该算法是通用的，可以处理回归和分类任务。在对各种回归和分类任务以及BNN体系结构进行的一系列实验中，我们证明了BNN-DP优于现有方法四个数量级，同时具有更高的精度和时间效率。",
    "tldr": "本文提出了一个高效算法框架BNN-DP，使用动态规划算法来保证贝叶斯神经网络的鲁棒性。在多个实验中，该算法框架的精度和时间效率均高于现有方法。",
    "en_tdlr": "This paper proposes an efficient algorithmic framework, BNN-DP, for analyzing the adversarial robustness of Bayesian Neural Networks through dynamic programming. The method computes lower and upper bounds on BNN's predictions using bound propagation techniques and convex relaxations, achieving higher accuracy and time efficiency compared to state-of-the-art methods in various experiments."
}