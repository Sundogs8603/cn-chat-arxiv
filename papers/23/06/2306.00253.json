{
    "title": "AfriNames: Most ASR models \"butcher\" African Names. (arXiv:2306.00253v1 [cs.CL])",
    "abstract": "Useful conversational agents must accurately capture named entities to minimize error for downstream tasks, for example, asking a voice assistant to play a track from a certain artist, initiating navigation to a specific location, or documenting a laboratory result for a patient. However, where named entities such as ``Ukachukwu`` (Igbo), ``Lakicia`` (Swahili), or ``Ingabire`` (Rwandan) are spoken, automatic speech recognition (ASR) models' performance degrades significantly, propagating errors to downstream systems. We model this problem as a distribution shift and demonstrate that such model bias can be mitigated through multilingual pre-training, intelligent data augmentation strategies to increase the representation of African-named entities, and fine-tuning multilingual ASR models on multiple African accents. The resulting fine-tuned models show an 81.5\\% relative WER improvement compared with the baseline on samples with African-named entities.",
    "link": "http://arxiv.org/abs/2306.00253",
    "context": "Title: AfriNames: Most ASR models \"butcher\" African Names. (arXiv:2306.00253v1 [cs.CL])\nAbstract: Useful conversational agents must accurately capture named entities to minimize error for downstream tasks, for example, asking a voice assistant to play a track from a certain artist, initiating navigation to a specific location, or documenting a laboratory result for a patient. However, where named entities such as ``Ukachukwu`` (Igbo), ``Lakicia`` (Swahili), or ``Ingabire`` (Rwandan) are spoken, automatic speech recognition (ASR) models' performance degrades significantly, propagating errors to downstream systems. We model this problem as a distribution shift and demonstrate that such model bias can be mitigated through multilingual pre-training, intelligent data augmentation strategies to increase the representation of African-named entities, and fine-tuning multilingual ASR models on multiple African accents. The resulting fine-tuned models show an 81.5\\% relative WER improvement compared with the baseline on samples with African-named entities.",
    "path": "papers/23/06/2306.00253.json",
    "total_tokens": 962,
    "translated_title": "AfriNames：大多数ASR模型“屠戮”非洲人的名字",
    "translated_abstract": "有效的对话代理必须准确捕捉命名实体，以最小化下游任务的错误，例如，要求语音助手播放特定艺术家的音轨，启动导航到特定位置，或为患者记录实验室结果。但是，当出现诸如“Ukachukwu”（伊博语）、“Lakicia”（斯瓦希里语）或“Ingabire”（卢旺达语）等命名实体时，自动语音识别（ASR）模型的性能显著降低，将错误传递到下游系统。我们将这个问题建模为分布偏移，并演示了通过多语言预训练、智能数据增强策略来增加非洲命名实体的表示，并在多个非洲口音上微调多语言ASR模型可以减轻模型偏差。结果表明，与基线相比，经过微调的模型在包含非洲命名实体的样本上相对WER改进了81.5％。",
    "tldr": "该论文探讨了自动语音识别模型在处理非洲名字时的性能问题，并提出了多语言预训练和数据增强等策略，通过微调ASR模型在多个非洲口音上，显著减少了模型误差，相对WER提高了81.5％。",
    "en_tdlr": "This paper explores performance issues of automatic speech recognition (ASR) models when dealing with African names and proposes strategies such as multilingual pre-training and data augmentation to mitigate model bias. Fine-tuning multilingual ASR models on African accents leads to a significant improvement in recognition rate for African-named entities, with an 81.5\\% relative improvement in word error rate (WER) compared to the baseline."
}