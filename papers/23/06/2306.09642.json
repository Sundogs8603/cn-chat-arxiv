{
    "title": "Cross-Domain Toxic Spans Detection. (arXiv:2306.09642v1 [cs.CL])",
    "abstract": "Given the dynamic nature of toxic language use, automated methods for detecting toxic spans are likely to encounter distributional shift. To explore this phenomenon, we evaluate three approaches for detecting toxic spans under cross-domain conditions: lexicon-based, rationale extraction, and fine-tuned language models. Our findings indicate that a simple method using off-the-shelf lexicons performs best in the cross-domain setup. The cross-domain error analysis suggests that (1) rationale extraction methods are prone to false negatives, while (2) language models, despite performing best for the in-domain case, recall fewer explicitly toxic words than lexicons and are prone to certain types of false positives. Our code is publicly available at: https://github.com/sfschouten/toxic-cross-domain.",
    "link": "http://arxiv.org/abs/2306.09642",
    "context": "Title: Cross-Domain Toxic Spans Detection. (arXiv:2306.09642v1 [cs.CL])\nAbstract: Given the dynamic nature of toxic language use, automated methods for detecting toxic spans are likely to encounter distributional shift. To explore this phenomenon, we evaluate three approaches for detecting toxic spans under cross-domain conditions: lexicon-based, rationale extraction, and fine-tuned language models. Our findings indicate that a simple method using off-the-shelf lexicons performs best in the cross-domain setup. The cross-domain error analysis suggests that (1) rationale extraction methods are prone to false negatives, while (2) language models, despite performing best for the in-domain case, recall fewer explicitly toxic words than lexicons and are prone to certain types of false positives. Our code is publicly available at: https://github.com/sfschouten/toxic-cross-domain.",
    "path": "papers/23/06/2306.09642.json",
    "total_tokens": 800,
    "translated_title": "跨域毒性片段检测",
    "translated_abstract": "鉴于毒性语言的动态性，自动检测毒性片段的方法可能会遭遇分布转移。为了探索这种现象，我们评估了三种检测跨域条件下毒性片段的方法：基于词典、根因抽取和微调语言模型。我们的研究发现，使用现成的词典的简单方法在跨域设置中表现最佳。跨领域误差分析表明：（1）根因提取方法容易出现假负结果，而（2）语言模型尽管在领域内的情况下表现最佳，但其明确提取毒性单词的数量比词典少，并且容易出现某些类型的假阳性。我们的代码公开在https://github.com/sfschouten/toxic-cross-domain 。",
    "tldr": "本研究评估了三种跨域条件下检测毒性片段的方法，结果表明使用现成的词典的简单方法在跨域设置中表现最佳，而用于领域内的语言模型容易出现某些类型的假阳性。",
    "en_tdlr": "This paper evaluates three approaches for detecting toxic spans under cross-domain conditions and finds that a simple method using off-the-shelf lexicons performs best. Language models that perform best in the in-domain case are prone to certain types of false positives."
}