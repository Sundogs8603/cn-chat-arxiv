{
    "title": "Your Room is not Private: Gradient Inversion Attack on Reinforcement Learning. (arXiv:2306.09273v2 [cs.RO] UPDATED)",
    "abstract": "The prominence of embodied Artificial Intelligence (AI), which empowers robots to navigate, perceive, and engage within virtual environments, has attracted significant attention, owing to the remarkable advancements in computer vision and large language models. Privacy emerges as a pivotal concern within the realm of embodied AI, as the robot accesses substantial personal information. However, the issue of privacy leakage in embodied AI tasks, particularly in relation to reinforcement learning algorithms, has not received adequate consideration in research. This paper aims to address this gap by proposing an attack on the value-based algorithm and the gradient-based algorithm, utilizing gradient inversion to reconstruct states, actions, and supervision signals. The choice of using gradients for the attack is motivated by the fact that commonly employed federated learning techniques solely utilize gradients computed based on private user data to optimize models, without storing or trans",
    "link": "http://arxiv.org/abs/2306.09273",
    "context": "Title: Your Room is not Private: Gradient Inversion Attack on Reinforcement Learning. (arXiv:2306.09273v2 [cs.RO] UPDATED)\nAbstract: The prominence of embodied Artificial Intelligence (AI), which empowers robots to navigate, perceive, and engage within virtual environments, has attracted significant attention, owing to the remarkable advancements in computer vision and large language models. Privacy emerges as a pivotal concern within the realm of embodied AI, as the robot accesses substantial personal information. However, the issue of privacy leakage in embodied AI tasks, particularly in relation to reinforcement learning algorithms, has not received adequate consideration in research. This paper aims to address this gap by proposing an attack on the value-based algorithm and the gradient-based algorithm, utilizing gradient inversion to reconstruct states, actions, and supervision signals. The choice of using gradients for the attack is motivated by the fact that commonly employed federated learning techniques solely utilize gradients computed based on private user data to optimize models, without storing or trans",
    "path": "papers/23/06/2306.09273.json",
    "total_tokens": 836,
    "translated_title": "你的房间不是私密的：关于强化学习的梯度反转攻击",
    "translated_abstract": "嵌入式人工智能的显著发展吸引了人们的极大关注，该技术使得机器人可以在虚拟环境中导航、感知和互动。由于计算机视觉和大型语言模型方面的显著进展，隐私问题在嵌入式人工智能领域变得至关重要，因为机器人可以访问大量个人信息。然而，关于强化学习算法中的隐私泄露问题，尤其是关于值函数算法和梯度算法的问题，在研究中尚未得到充分考虑。本文旨在通过提出一种攻击值函数算法和梯度算法的方法，利用梯度反转重建状态、动作和监督信号，来解决这一问题。选择使用梯度进行攻击是因为常用的联邦学习技术仅利用基于私人用户数据计算的梯度来优化模型，而不存储或传输用户数据。",
    "tldr": "这篇论文提出了一种针对值函数算法和梯度算法的攻击方法，利用梯度反转重建状态、动作和监督信号，以解决嵌入式人工智能中的隐私泄露问题。"
}