{
    "title": "Transformer Training Strategies for Forecasting Multiple Load Time Series. (arXiv:2306.10891v2 [cs.LG] UPDATED)",
    "abstract": "In the smart grid of the future, accurate load forecasts on the level of individual clients can help to balance supply and demand locally and to prevent grid outages. While the number of monitored clients will increase with the ongoing smart meter rollout, the amount of data per client will always be limited. We evaluate whether a Transformer load forecasting model benefits from a transfer learning strategy, where a global univariate model is trained on the load time series from multiple clients. In experiments with two datasets containing load time series from several hundred clients, we find that the global training strategy is superior to the multivariate and local training strategies used in related work. On average, the global training strategy results in 21.8% and 12.8% lower forecasting errors than the two other strategies, measured across forecasting horizons from one day to one month into the future. A comparison to linear models, multi-layer perceptrons and LSTMs shows that T",
    "link": "http://arxiv.org/abs/2306.10891",
    "context": "Title: Transformer Training Strategies for Forecasting Multiple Load Time Series. (arXiv:2306.10891v2 [cs.LG] UPDATED)\nAbstract: In the smart grid of the future, accurate load forecasts on the level of individual clients can help to balance supply and demand locally and to prevent grid outages. While the number of monitored clients will increase with the ongoing smart meter rollout, the amount of data per client will always be limited. We evaluate whether a Transformer load forecasting model benefits from a transfer learning strategy, where a global univariate model is trained on the load time series from multiple clients. In experiments with two datasets containing load time series from several hundred clients, we find that the global training strategy is superior to the multivariate and local training strategies used in related work. On average, the global training strategy results in 21.8% and 12.8% lower forecasting errors than the two other strategies, measured across forecasting horizons from one day to one month into the future. A comparison to linear models, multi-layer perceptrons and LSTMs shows that T",
    "path": "papers/23/06/2306.10891.json",
    "total_tokens": 921,
    "translated_title": "转换器训练策略用于预测多个负载时间序列",
    "translated_abstract": "在未来的智能电网中，准确的负载预测可以帮助在本地平衡供需，并防止电网故障。尽管被监测的客户数量将随着不断推进的智能电表安装而增加，但每个客户的数据量始终是有限的。我们评估了转换器负载预测模型是否受益于转移学习策略，即在多个客户的负载时间序列上训练全局的单变量模型。在使用两个包含数百个客户的数据集进行的实验中，我们发现全局训练策略优于相关工作中使用的多变量和本地训练策略。平均而言，与其他两种策略相比，全局训练策略在从未来一天到一个月的预测时间范围内，预测误差降低了21.8%和12.8%。与线性模型、多层感知机和LSTM模型的比较显示，转换器训练策略效果更好。",
    "tldr": "转换器模型在预测多负载时间序列方面使用全局训练策略比多变量和本地训练策略具有更好的性能，平均降低了21.8%和12.8%的预测误差。",
    "en_tdlr": "Transformer model using a global training strategy outperforms multivariate and local training strategies in forecasting multiple load time series, resulting in an average decrease of 21.8% and 12.8% in forecasting errors across different time horizons."
}