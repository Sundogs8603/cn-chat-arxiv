{
    "title": "Neural Algorithmic Reasoning Without Intermediate Supervision. (arXiv:2306.13411v1 [cs.LG])",
    "abstract": "Neural Algorithmic Reasoning is an emerging area of machine learning focusing on building models which can imitate the execution of classic algorithms, such as sorting, shortest paths, etc. One of the main challenges is to learn algorithms that are able to generalize to out-of-distribution data, in particular with significantly larger input sizes. Recent work on this problem has demonstrated the advantages of learning algorithms step-by-step, giving models access to all intermediate steps of the original algorithm. In this work, we instead focus on learning neural algorithmic reasoning only from the input-output pairs without appealing to the intermediate supervision. We propose simple but effective architectural improvements and also build a self-supervised objective that can regularise intermediate computations of the model without access to the algorithm trajectory. We demonstrate that our approach is competitive to its trajectory-supervised counterpart on tasks from the CLRS Algori",
    "link": "http://arxiv.org/abs/2306.13411",
    "context": "Title: Neural Algorithmic Reasoning Without Intermediate Supervision. (arXiv:2306.13411v1 [cs.LG])\nAbstract: Neural Algorithmic Reasoning is an emerging area of machine learning focusing on building models which can imitate the execution of classic algorithms, such as sorting, shortest paths, etc. One of the main challenges is to learn algorithms that are able to generalize to out-of-distribution data, in particular with significantly larger input sizes. Recent work on this problem has demonstrated the advantages of learning algorithms step-by-step, giving models access to all intermediate steps of the original algorithm. In this work, we instead focus on learning neural algorithmic reasoning only from the input-output pairs without appealing to the intermediate supervision. We propose simple but effective architectural improvements and also build a self-supervised objective that can regularise intermediate computations of the model without access to the algorithm trajectory. We demonstrate that our approach is competitive to its trajectory-supervised counterpart on tasks from the CLRS Algori",
    "path": "papers/23/06/2306.13411.json",
    "total_tokens": 828,
    "translated_title": "没有中间监督的神经算法推理",
    "translated_abstract": "神经算法推理是机器学习中的新兴领域，侧重于构建能够模仿经典算法（如排序、最短路径等）执行的模型。其中一个主要挑战是学习能够推广到超出分布数据且输入规模显著更大的算法。最近针对这个问题的工作表明，逐步学习算法具有优势，使模型能够访问原始算法的所有中间步骤。在这项工作中，我们不使用中间监督专注于仅从输入输出对学习神经算法推理。我们提出了简单但有效的结构改进，并构建了一种自我监督目标，可以规范模型的中间计算，而不需要访问算法轨迹。我们证明了我们的方法在来自CLRS算法的任务上与其轨迹监督对应物相当竞争力。",
    "tldr": "神经算法推理最近的变革点是逐步学习算法，但我们提出了一种不需要中间监督的新方法，并在不牺牲性能的情况下规范模型的中间计算。",
    "en_tdlr": "The recent revolution in Neural Algorithmic Reasoning is to learn algorithms step-by-step. However, we propose a novel method that does not require intermediate supervision and regulates the intermediate computation of the model without sacrificing performance."
}