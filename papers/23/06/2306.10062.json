{
    "title": "Revealing the structure of language model capabilities. (arXiv:2306.10062v1 [cs.CL])",
    "abstract": "Building a theoretical understanding of the capabilities of large language models (LLMs) is vital for our ability to predict and explain the behavior of these systems. Here, we investigate the structure of LLM capabilities by extracting latent capabilities from patterns of individual differences across a varied population of LLMs. Using a combination of Bayesian and frequentist factor analysis, we analyzed data from 29 different LLMs across 27 cognitive tasks. We found evidence that LLM capabilities are not monolithic. Instead, they are better explained by three well-delineated factors that represent reasoning, comprehension and core language modeling. Moreover, we found that these three factors can explain a high proportion of the variance in model performance. These results reveal a consistent structure in the capabilities of different LLMs and demonstrate the multifaceted nature of these capabilities. We also found that the three abilities show different relationships to model prope",
    "link": "http://arxiv.org/abs/2306.10062",
    "context": "Title: Revealing the structure of language model capabilities. (arXiv:2306.10062v1 [cs.CL])\nAbstract: Building a theoretical understanding of the capabilities of large language models (LLMs) is vital for our ability to predict and explain the behavior of these systems. Here, we investigate the structure of LLM capabilities by extracting latent capabilities from patterns of individual differences across a varied population of LLMs. Using a combination of Bayesian and frequentist factor analysis, we analyzed data from 29 different LLMs across 27 cognitive tasks. We found evidence that LLM capabilities are not monolithic. Instead, they are better explained by three well-delineated factors that represent reasoning, comprehension and core language modeling. Moreover, we found that these three factors can explain a high proportion of the variance in model performance. These results reveal a consistent structure in the capabilities of different LLMs and demonstrate the multifaceted nature of these capabilities. We also found that the three abilities show different relationships to model prope",
    "path": "papers/23/06/2306.10062.json",
    "total_tokens": 851,
    "translated_title": "揭示语言模型能力的结构",
    "translated_abstract": "建立大规模语言模型（LLMs）能力的理论理解对于我们预测和解释这些系统的行为至关重要。在这里，我们通过从各种LLMs的个体差异模式中提取潜在能力来调查LLMs能力的结构。使用贝叶斯和频率因子分析的组合，我们分析了来自29个不同LLMs的27种认知任务的数据。我们发现，LLMs能力并非单一的，相反，它们更好地由三个明确定义的因素解释，分别代表推理、理解和核心语言建模。此外，我们发现这三个因素可以解释模型性能中的高比例方差。这些结果揭示了不同LLMs能力的一致结构，并展示了这些能力的多方面性质。我们还发现这三个功能与模型属性具有不同的关系。",
    "tldr": "本文研究了大规模语言模型的能力结构，发现这些模型不是单一能力，而是由推理、理解和核心语言建模等三个明确定义的因素组成，并且这三个能力可以解释模型性能中的大部分方差。",
    "en_tdlr": "This article investigates the capability structure of large language models (LLMs) and discovers that these models are not characterized by a single ability, but rather by three well-delineated factors: reasoning, comprehension, and core language modeling. These three abilities can explain a high proportion of the variance in model performance."
}