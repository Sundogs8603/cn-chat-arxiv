{
    "title": "bgGLUE: A Bulgarian General Language Understanding Evaluation Benchmark. (arXiv:2306.02349v2 [cs.CL] UPDATED)",
    "abstract": "We present bgGLUE(Bulgarian General Language Understanding Evaluation), a benchmark for evaluating language models on Natural Language Understanding (NLU) tasks in Bulgarian. Our benchmark includes NLU tasks targeting a variety of NLP problems (e.g., natural language inference, fact-checking, named entity recognition, sentiment analysis, question answering, etc.) and machine learning tasks (sequence labeling, document-level classification, and regression). We run the first systematic evaluation of pre-trained language models for Bulgarian, comparing and contrasting results across the nine tasks in the benchmark. The evaluation results show strong performance on sequence labeling tasks, but there is a lot of room for improvement for tasks that require more complex reasoning. We make bgGLUE publicly available together with the fine-tuning and the evaluation code, as well as a public leaderboard at https://bgglue.github.io/, and we hope that it will enable further advancements in developi",
    "link": "http://arxiv.org/abs/2306.02349",
    "context": "Title: bgGLUE: A Bulgarian General Language Understanding Evaluation Benchmark. (arXiv:2306.02349v2 [cs.CL] UPDATED)\nAbstract: We present bgGLUE(Bulgarian General Language Understanding Evaluation), a benchmark for evaluating language models on Natural Language Understanding (NLU) tasks in Bulgarian. Our benchmark includes NLU tasks targeting a variety of NLP problems (e.g., natural language inference, fact-checking, named entity recognition, sentiment analysis, question answering, etc.) and machine learning tasks (sequence labeling, document-level classification, and regression). We run the first systematic evaluation of pre-trained language models for Bulgarian, comparing and contrasting results across the nine tasks in the benchmark. The evaluation results show strong performance on sequence labeling tasks, but there is a lot of room for improvement for tasks that require more complex reasoning. We make bgGLUE publicly available together with the fine-tuning and the evaluation code, as well as a public leaderboard at https://bgglue.github.io/, and we hope that it will enable further advancements in developi",
    "path": "papers/23/06/2306.02349.json",
    "total_tokens": 1001,
    "translated_title": "bgGLUE：保加利亚通用语言理解评估基准",
    "translated_abstract": "我们提出了bgGLUE（保加利亚通用语言理解评估），这是一个用于在保加利亚语上评估语言模型在自然语言理解（NLU）任务上的基准。我们的基准包括针对各种自然语言处理问题（例如，自然语言推理、事实检查、命名实体识别、情感分析、问答等）和机器学习任务（序列标记、文档级分类和回归）的NLU任务。我们进行了首次系统评估保加利亚语预训练语言模型，在基准测试中跨足了九个任务，比较和对比了结果。评估结果表明，在序列标记任务方面表现强劲，但需要更复杂的推理任务还有很大的提升空间。我们将bgGLUE与微调和评估代码一起公开提供，以及在https://bgglue.github.io/上提供公共排行榜，希望它能促进更进一步的发展。",
    "tldr": "提出了bgGLUE，这是一个用于在保加利亚语上评估语言模型在自然语言理解（NLU）任务上的基准。该基准测试包括针对各种自然语言处理问题（例如，自然语言推理、事实检查、命名实体识别、情感分析、问答等）和机器学习任务的NLU任务，评估结果表明，在序列标记任务方面表现强劲，但需要更复杂的推理任务还有很大的提升空间。"
}