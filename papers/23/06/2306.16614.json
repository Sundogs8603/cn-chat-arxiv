{
    "title": "Group-based Robustness: A General Framework for Customized Robustness in the Real World. (arXiv:2306.16614v1 [cs.LG])",
    "abstract": "Machine-learning models are known to be vulnerable to evasion attacks that perturb model inputs to induce misclassifications. In this work, we identify real-world scenarios where the true threat cannot be assessed accurately by existing attacks. Specifically, we find that conventional metrics measuring targeted and untargeted robustness do not appropriately reflect a model's ability to withstand attacks from one set of source classes to another set of target classes. To address the shortcomings of existing methods, we formally define a new metric, termed group-based robustness, that complements existing metrics and is better-suited for evaluating model performance in certain attack scenarios. We show empirically that group-based robustness allows us to distinguish between models' vulnerability against specific threat models in situations where traditional robustness metrics do not apply. Moreover, to measure group-based robustness efficiently and accurately, we 1) propose two loss func",
    "link": "http://arxiv.org/abs/2306.16614",
    "context": "Title: Group-based Robustness: A General Framework for Customized Robustness in the Real World. (arXiv:2306.16614v1 [cs.LG])\nAbstract: Machine-learning models are known to be vulnerable to evasion attacks that perturb model inputs to induce misclassifications. In this work, we identify real-world scenarios where the true threat cannot be assessed accurately by existing attacks. Specifically, we find that conventional metrics measuring targeted and untargeted robustness do not appropriately reflect a model's ability to withstand attacks from one set of source classes to another set of target classes. To address the shortcomings of existing methods, we formally define a new metric, termed group-based robustness, that complements existing metrics and is better-suited for evaluating model performance in certain attack scenarios. We show empirically that group-based robustness allows us to distinguish between models' vulnerability against specific threat models in situations where traditional robustness metrics do not apply. Moreover, to measure group-based robustness efficiently and accurately, we 1) propose two loss func",
    "path": "papers/23/06/2306.16614.json",
    "total_tokens": 902,
    "translated_title": "基于群体的鲁棒性：现实世界中定制鲁棒性的通用框架",
    "translated_abstract": "众所周知，机器学习模型容易受到逃避攻击的影响，即通过扰动模型输入来引起错误分类。本研究中，我们发现传统的度量目标和非目标鲁棒性的指标无法准确评估现实世界中的真实威胁。为了解决现有方法的缺陷，我们正式定义了一种新的指标，称为基于群体的鲁棒性，它补充了现有的度量标准，并更适合评估特定攻击场景下的模型性能。我们通过实验证明，基于群体的鲁棒性能够在传统的鲁棒性指标不适用的情况下区分模型对特定威胁模型的脆弱性。此外，为了有效准确地衡量基于群体的鲁棒性，我们提出了两个损失函数。",
    "tldr": "本研究提出了一种基于群体的鲁棒性指标，可以更好地评估机器学习模型在现实世界中抵抗攻击的能力，弥补了传统指标的不足。实验证明，该指标能够区分模型对特定威胁的脆弱性。"
}