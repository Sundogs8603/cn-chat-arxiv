{
    "title": "Explaining and Adapting Graph Conditional Shift. (arXiv:2306.03256v1 [cs.LG])",
    "abstract": "Graph Neural Networks (GNNs) have shown remarkable performance on graph-structured data. However, recent empirical studies suggest that GNNs are very susceptible to distribution shift. There is still significant ambiguity about why graph-based models seem more vulnerable to these shifts. In this work we provide a thorough theoretical analysis on it by quantifying the magnitude of conditional shift between the input features and the output label. Our findings show that both graph heterophily and model architecture exacerbate conditional shifts, leading to performance degradation. To address this, we propose an approach that involves estimating and minimizing the conditional shift for unsupervised domain adaptation on graphs. In our controlled synthetic experiments, our algorithm demonstrates robustness towards distribution shift, resulting in up to 10% absolute ROC AUC improvement versus the second-best algorithm. Furthermore, comprehensive experiments on both node classification and gr",
    "link": "http://arxiv.org/abs/2306.03256",
    "context": "Title: Explaining and Adapting Graph Conditional Shift. (arXiv:2306.03256v1 [cs.LG])\nAbstract: Graph Neural Networks (GNNs) have shown remarkable performance on graph-structured data. However, recent empirical studies suggest that GNNs are very susceptible to distribution shift. There is still significant ambiguity about why graph-based models seem more vulnerable to these shifts. In this work we provide a thorough theoretical analysis on it by quantifying the magnitude of conditional shift between the input features and the output label. Our findings show that both graph heterophily and model architecture exacerbate conditional shifts, leading to performance degradation. To address this, we propose an approach that involves estimating and minimizing the conditional shift for unsupervised domain adaptation on graphs. In our controlled synthetic experiments, our algorithm demonstrates robustness towards distribution shift, resulting in up to 10% absolute ROC AUC improvement versus the second-best algorithm. Furthermore, comprehensive experiments on both node classification and gr",
    "path": "papers/23/06/2306.03256.json",
    "total_tokens": 981,
    "translated_title": "解释与调整图形条件转移",
    "translated_abstract": "图神经网络在图结构数据上表现出卓越的性能。然而，最近的实证研究表明，GNN非常容易受到分布偏移的影响。目前关于为什么基于图形的模型似乎更容易受到这些偏移影响的问题还存在显著的歧义。在这项工作中，我们通过量化输入特征和输出标签之间的条件偏移量，对它进行了彻底的理论分析。我们的研究结果表明，图形异质性和模型架构都加剧了条件偏移，导致性能下降。为了应对这一问题，我们提出了一种方法，涉及对图形上的无监督域适应性进行条件偏移的估计和最小化。在我们的控制性综合实验中，我们的算法表现出对分布偏移的鲁棒性，相对第二优算法实现了高达10%的ROC AUC绝对改善。此外，对节点分类和图分类任务的全面实验表明，我们的方法始终优于最先进的域适应方法。",
    "tldr": "本研究通过量化输入特征和输出标签之间的条件偏移量，对图神经网络易受分布偏移影响的问题进行理论分析。研究发现，图形异质性和模型架构都会导致条件偏移，影响性能。作者提出了一种方法，通过条件偏移的估计和最小化来应对这一问题，该方法在节点分类和图分类任务上表现更优。",
    "en_tdlr": "This paper provides a theoretical analysis on why Graph Neural Networks (GNNs) are susceptible to distribution shift and proposes an approach to address this issue through estimating and minimizing conditional shift. The approach consistently outperforms state-of-the-art domain adaptation methods on node and graph classification tasks."
}