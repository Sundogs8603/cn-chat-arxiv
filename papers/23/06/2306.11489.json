{
    "title": "Give Us the Facts: Enhancing Large Language Models with Knowledge Graphs for Fact-aware Language Modeling. (arXiv:2306.11489v2 [cs.CL] UPDATED)",
    "abstract": "Recently, ChatGPT, a representative large language model (LLM), has gained considerable attention due to its powerful emergent abilities. Some researchers suggest that LLMs could potentially replace structured knowledge bases like knowledge graphs (KGs) and function as parameterized knowledge bases. However, while LLMs are proficient at learning probabilistic language patterns based on large corpus and engaging in conversations with humans, they, like previous smaller pre-trained language models (PLMs), still have difficulty in recalling facts while generating knowledge-grounded contents. To overcome these limitations, researchers have proposed enhancing data-driven PLMs with knowledge-based KGs to incorporate explicit factual knowledge into PLMs, thus improving their performance to generate texts requiring factual knowledge and providing more informed responses to user queries. This paper reviews the studies on enhancing PLMs with KGs, detailing existing knowledge graph enhanced pre-t",
    "link": "http://arxiv.org/abs/2306.11489",
    "context": "Title: Give Us the Facts: Enhancing Large Language Models with Knowledge Graphs for Fact-aware Language Modeling. (arXiv:2306.11489v2 [cs.CL] UPDATED)\nAbstract: Recently, ChatGPT, a representative large language model (LLM), has gained considerable attention due to its powerful emergent abilities. Some researchers suggest that LLMs could potentially replace structured knowledge bases like knowledge graphs (KGs) and function as parameterized knowledge bases. However, while LLMs are proficient at learning probabilistic language patterns based on large corpus and engaging in conversations with humans, they, like previous smaller pre-trained language models (PLMs), still have difficulty in recalling facts while generating knowledge-grounded contents. To overcome these limitations, researchers have proposed enhancing data-driven PLMs with knowledge-based KGs to incorporate explicit factual knowledge into PLMs, thus improving their performance to generate texts requiring factual knowledge and providing more informed responses to user queries. This paper reviews the studies on enhancing PLMs with KGs, detailing existing knowledge graph enhanced pre-t",
    "path": "papers/23/06/2306.11489.json",
    "total_tokens": 865,
    "translated_title": "为事实感知语言建模增强大型语言模型的知识图谱",
    "translated_abstract": "最近，ChatGPT作为一个代表性的大型语言模型（LLM），因其强大的新兴能力而受到了相当大的关注。一些研究人员认为，LLMs有可能取代知识图谱（KGs）这样的结构化知识库，成为参数化知识库。然而，虽然LLMs擅长基于大语料库学习概率语言模式，并与人类进行对话，但它们与之前较小的预训练语言模型（PLMs）一样，在生成基于知识的内容时仍然难以回忆事实。为了克服这些局限性，研究人员提出了通过知识图谱增强数据驱动的PLMs，将明确的事实知识融入PLMs，从而提高其生成需要事实知识的文本的性能，并为用户查询提供更多见解的回复。本文回顾了有关使用KG增强PLMs的研究，详细介绍了现有的知识图谱增强预训练模型PLM的方法。",
    "tldr": "这篇论文研究了如何通过知识图谱增强大型语言模型，提高其生成内容的准确性和对用户查询的回复能力。",
    "en_tdlr": "This paper explores the enhancement of large language models using knowledge graphs to improve the accuracy of generated content and the ability to respond to user queries."
}