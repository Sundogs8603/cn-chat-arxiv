{
    "title": "Discovering Causality for Efficient Cooperation in Multi-Agent Environments. (arXiv:2306.11846v1 [cs.AI])",
    "abstract": "In cooperative Multi-Agent Reinforcement Learning (MARL) agents are required to learn behaviours as a team to achieve a common goal. However, while learning a task, some agents may end up learning sub-optimal policies, not contributing to the objective of the team. Such agents are called lazy agents due to their non-cooperative behaviours that may arise from failing to understand whether they caused the rewards. As a consequence, we observe that the emergence of cooperative behaviours is not necessarily a byproduct of being able to solve a task as a team. In this paper, we investigate the applications of causality in MARL and how it can be applied in MARL to penalise these lazy agents. We observe that causality estimations can be used to improve the credit assignment to the agents and show how it can be leveraged to improve independent learning in MARL. Furthermore, we investigate how Amortized Causal Discovery can be used to automate causality detection within MARL environments. The r",
    "link": "http://arxiv.org/abs/2306.11846",
    "context": "Title: Discovering Causality for Efficient Cooperation in Multi-Agent Environments. (arXiv:2306.11846v1 [cs.AI])\nAbstract: In cooperative Multi-Agent Reinforcement Learning (MARL) agents are required to learn behaviours as a team to achieve a common goal. However, while learning a task, some agents may end up learning sub-optimal policies, not contributing to the objective of the team. Such agents are called lazy agents due to their non-cooperative behaviours that may arise from failing to understand whether they caused the rewards. As a consequence, we observe that the emergence of cooperative behaviours is not necessarily a byproduct of being able to solve a task as a team. In this paper, we investigate the applications of causality in MARL and how it can be applied in MARL to penalise these lazy agents. We observe that causality estimations can be used to improve the credit assignment to the agents and show how it can be leveraged to improve independent learning in MARL. Furthermore, we investigate how Amortized Causal Discovery can be used to automate causality detection within MARL environments. The r",
    "path": "papers/23/06/2306.11846.json",
    "total_tokens": 966,
    "translated_title": "在多智能体环境下发现因果关系以实现高效协作",
    "translated_abstract": "在合作的多智能体强化学习中，智能体需要作为一个团队学习行为以实现共同的目标。然而，在学习任务的过程中，一些智能体可能会学习到次优策略，从而未能对团队目标做出贡献。这些智能体被称为“懒惰智能体”，因为它们的非合作性行为可能来自于未能理解是否导致回报。本文中，我们调查了因果关系在合作学习中的应用，以及如何应用它来惩罚这些懒惰的智能体。我们观察到，因果关系估计可用于改进对智能体的信用分配，并展示了如何利用它来改进多智能体独立学习。此外，我们还研究了如何使用分摊因果发现来自动检测多智能体环境中的因果关系。",
    "tldr": "本文研究了因果关系在多智能体强化学习中的应用，通过对懒惰智能体进行惩罚以帮助团队取得更好的效果。此外，研究了如何利用因果关系估计改善对智能体的信用分配，以及如何使用Amortized Causal Discovery自动检测多智能体环境中的因果关系。",
    "en_tdlr": "This paper investigates the use of causality in cooperative multi-agent reinforcement learning to penalize non-contributing agents. The study shows that causality estimations can improve credit assignment to agents, and also explores how Amortized Causal Discovery can automate causality detection in multi-agent environments."
}