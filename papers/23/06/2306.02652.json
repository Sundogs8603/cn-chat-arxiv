{
    "title": "Towards Anytime Classification in Early-Exit Architectures by Enforcing Conditional Monotonicity. (arXiv:2306.02652v1 [cs.LG])",
    "abstract": "Modern predictive models are often deployed to environments in which computational budgets are dynamic. Anytime algorithms are well-suited to such environments as, at any point during computation, they can output a prediction whose quality is a function of computation time. Early-exit neural networks have garnered attention in the context of anytime computation due to their capability to provide intermediate predictions at various stages throughout the network. However, we demonstrate that current early-exit networks are not directly applicable to anytime settings, as the quality of predictions for individual data points is not guaranteed to improve with longer computation. To address this shortcoming, we propose an elegant post-hoc modification, based on the Product-of-Experts, that encourages an early-exit network to become gradually confident. This gives our deep models the property of conditional monotonicity in the prediction quality -- an essential stepping stone towards truly an",
    "link": "http://arxiv.org/abs/2306.02652",
    "context": "Title: Towards Anytime Classification in Early-Exit Architectures by Enforcing Conditional Monotonicity. (arXiv:2306.02652v1 [cs.LG])\nAbstract: Modern predictive models are often deployed to environments in which computational budgets are dynamic. Anytime algorithms are well-suited to such environments as, at any point during computation, they can output a prediction whose quality is a function of computation time. Early-exit neural networks have garnered attention in the context of anytime computation due to their capability to provide intermediate predictions at various stages throughout the network. However, we demonstrate that current early-exit networks are not directly applicable to anytime settings, as the quality of predictions for individual data points is not guaranteed to improve with longer computation. To address this shortcoming, we propose an elegant post-hoc modification, based on the Product-of-Experts, that encourages an early-exit network to become gradually confident. This gives our deep models the property of conditional monotonicity in the prediction quality -- an essential stepping stone towards truly an",
    "path": "papers/23/06/2306.02652.json",
    "total_tokens": 811,
    "translated_title": "通过强制条件单调性在Early-Exit结构中实现随时分类",
    "translated_abstract": "现代预测模型通常部署在计算预算动态的环境中。随时算法非常适用于这种环境，因为它们在计算的任何时候都可以输出预测值，其质量是计算时间的函数。由于其能够在网络各个阶段提供中间预测结果的能力，Early-Exit神经网络在随时计算的背景下引起了人们的关注。然而，我们证明当前的Early-Exit网络并不直接适用于任何时候的设置，因为单个数据点的预测质量不能保证随着计算时间的增加而提高。为了解决这个缺陷，我们提出了一种优雅的事后修改，基于专家乘积，鼓励Early-Exit网络逐渐变得自信。这赋予了我们的深度模型条件单调性的特性——这是实现真正随时分类的重要基石。",
    "tldr": "本文提出了一种在Early-Exit网络中实现条件单调性的方法，将深度模型转化为真正的随时分类器。",
    "en_tdlr": "This paper proposes a method to achieve conditional monotonicity in Early-Exit networks, which turns deep models into real anytime classifiers."
}