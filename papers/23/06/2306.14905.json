{
    "title": "PRISMA-DFLLM: An Extension of PRISMA for Systematic Literature Reviews using Domain-specific Finetuned Large Language Models. (arXiv:2306.14905v1 [cs.CL])",
    "abstract": "With the proliferation of open-sourced Large Language Models (LLMs) and efficient finetuning techniques, we are on the cusp of the emergence of numerous domain-specific LLMs that have been finetuned for expertise across specialized fields and applications for which the current general-purpose LLMs are unsuitable. In academia, this technology has the potential to revolutionize the way we conduct systematic literature reviews (SLRs), access knowledge and generate new insights. This paper proposes an AI-enabled methodological framework that combines the power of LLMs with the rigorous reporting guidelines of the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA). By finetuning LLMs on domain-specific academic papers that have been selected as a result of a rigorous SLR process, the proposed PRISMA-DFLLM (for Domain-specific Finetuned LLMs) reporting guidelines offer the potential to achieve greater efficiency, reusability and scalability, while also opening the po",
    "link": "http://arxiv.org/abs/2306.14905",
    "context": "Title: PRISMA-DFLLM: An Extension of PRISMA for Systematic Literature Reviews using Domain-specific Finetuned Large Language Models. (arXiv:2306.14905v1 [cs.CL])\nAbstract: With the proliferation of open-sourced Large Language Models (LLMs) and efficient finetuning techniques, we are on the cusp of the emergence of numerous domain-specific LLMs that have been finetuned for expertise across specialized fields and applications for which the current general-purpose LLMs are unsuitable. In academia, this technology has the potential to revolutionize the way we conduct systematic literature reviews (SLRs), access knowledge and generate new insights. This paper proposes an AI-enabled methodological framework that combines the power of LLMs with the rigorous reporting guidelines of the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA). By finetuning LLMs on domain-specific academic papers that have been selected as a result of a rigorous SLR process, the proposed PRISMA-DFLLM (for Domain-specific Finetuned LLMs) reporting guidelines offer the potential to achieve greater efficiency, reusability and scalability, while also opening the po",
    "path": "papers/23/06/2306.14905.json",
    "total_tokens": 952,
    "translated_title": "PRISMA-DFLLM：PRISMA的一种扩展，使用领域特定的大型语言模型进行系统文献综述",
    "translated_abstract": "随着开源大型语言模型（LLMs）的普及和高效的微调技术，我们正处于涌现出许多针对专业领域和应用的特定领域LLMs的阶段，这些LLMs已经针对当前通用LLMs无法适应的专业领域进行了微调。在学术界，这项技术有潜力改变我们进行系统文献综述（SLRs）的方式，获取知识和生成新见解。本文提出了一种结合LLMs强大能力和Preferred Reporting Items for Systematic Reviews and Meta-Analyses（PRISMA）的严格报告指南的AI-Enabled方法框架。通过对通过严格SLR过程选定的领域特定学术论文进行LLMs微调，提出的PRISMA-DFLLM（用于领域特定的LLMs微调）报告指南具有更高的效率、可重复性和可扩展性，并同时开启了一系列新的研究机遇。",
    "tldr": "PRISMA-DFLLM是将大型语言模型(LLMs)与PRISMA的严格报告指南相结合，通过在领域特定的学术论文上进行微调，提高了系统文献综述的效率和可扩展性，同时开启了新的研究机遇。",
    "en_tdlr": "PRISMA-DFLLM combines large language models (LLMs) with the rigorous reporting guidelines of PRISMA, enabling efficient and scalable systematic literature reviews by finetuning LLMs on domain-specific academic papers, while also opening up new research opportunities."
}