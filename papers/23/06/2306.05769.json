{
    "title": "Self-Paced Absolute Learning Progress as a Regularized Approach to Curriculum Learning. (arXiv:2306.05769v1 [cs.LG])",
    "abstract": "The usability of Reinforcement Learning is restricted by the large computation times it requires. Curriculum Reinforcement Learning speeds up learning by defining a helpful order in which an agent encounters tasks, i.e. from simple to hard. Curricula based on Absolute Learning Progress (ALP) have proven successful in different environments, but waste computation on repeating already learned behaviour in new tasks. We solve this problem by introducing a new regularization method based on Self-Paced (Deep) Learning, called Self-Paced Absolute Learning Progress (SPALP). We evaluate our method in three different environments. Our method achieves performance comparable to original ALP in all cases, and reaches it quicker than ALP in two of them. We illustrate possibilities to further improve the efficiency and performance of SPALP.",
    "link": "http://arxiv.org/abs/2306.05769",
    "context": "Title: Self-Paced Absolute Learning Progress as a Regularized Approach to Curriculum Learning. (arXiv:2306.05769v1 [cs.LG])\nAbstract: The usability of Reinforcement Learning is restricted by the large computation times it requires. Curriculum Reinforcement Learning speeds up learning by defining a helpful order in which an agent encounters tasks, i.e. from simple to hard. Curricula based on Absolute Learning Progress (ALP) have proven successful in different environments, but waste computation on repeating already learned behaviour in new tasks. We solve this problem by introducing a new regularization method based on Self-Paced (Deep) Learning, called Self-Paced Absolute Learning Progress (SPALP). We evaluate our method in three different environments. Our method achieves performance comparable to original ALP in all cases, and reaches it quicker than ALP in two of them. We illustrate possibilities to further improve the efficiency and performance of SPALP.",
    "path": "papers/23/06/2306.05769.json",
    "total_tokens": 867,
    "translated_title": "自定进度绝对学习作为课程学习的规则方法",
    "translated_abstract": "强化学习的可用性受到其所需的大量计算时间的限制。课程强化学习通过定义帮助智能体遇到任务的有用顺序（即从简单到难），加速学习。基于绝对学习进展（ALP）的课程在不同环境中已被证明成功，但浪费计算资源在新任务中重复已学习的行为。我们通过引入基于自定进度（深度）学习的新正则化方法，称为自定进度绝对学习进展（SPALP），解决了这个问题。我们在三个不同的环境中评估了我们的方法。在所有情况下，我们的方法的效果与原始ALP相当，并且在其中两种情况下更快地达到了ALP的效果。我们还阐述了进一步提高SPALP效率和性能的可能性。",
    "tldr": "自定进度绝对学习作为课程学习的规则方法，通过引入基于自定进度（深度）学习的新正则化方法，称为自定进度绝对学习进展（SPALP），解决了绝对学习进展（ALP）在重复已学习的行为上浪费计算资源的问题。",
    "en_tdlr": "A new regularization method, Self-Paced Absolute Learning Progress (SPALP), is introduced for curriculum reinforcement learning, which solves the problem of Waste computation on repeating already learned behavior in new tasks caused by Absolute Learning Progress (ALP) methods, and achieve comparable or better performance with quicker convergence in most cases."
}