{
    "title": "Few-Shot Continual Learning via Flat-to-Wide Approaches. (arXiv:2306.14369v2 [cs.LG] UPDATED)",
    "abstract": "Existing approaches on continual learning call for a lot of samples in their training processes. Such approaches are impractical for many real-world problems having limited samples because of the overfitting problem. This paper proposes a few-shot continual learning approach, termed FLat-tO-WidE AppRoach (FLOWER), where a flat-to-wide learning process finding the flat-wide minima is proposed to address the catastrophic forgetting problem. The issue of data scarcity is overcome with a data augmentation approach making use of a ball generator concept to restrict the sampling space into the smallest enclosing ball. Our numerical studies demonstrate the advantage of FLOWER achieving significantly improved performances over prior arts notably in the small base tasks. For further study, source codes of FLOWER, competitor algorithms and experimental logs are shared publicly in \\url{https://github.com/anwarmaxsum/FLOWER}.",
    "link": "http://arxiv.org/abs/2306.14369",
    "context": "Title: Few-Shot Continual Learning via Flat-to-Wide Approaches. (arXiv:2306.14369v2 [cs.LG] UPDATED)\nAbstract: Existing approaches on continual learning call for a lot of samples in their training processes. Such approaches are impractical for many real-world problems having limited samples because of the overfitting problem. This paper proposes a few-shot continual learning approach, termed FLat-tO-WidE AppRoach (FLOWER), where a flat-to-wide learning process finding the flat-wide minima is proposed to address the catastrophic forgetting problem. The issue of data scarcity is overcome with a data augmentation approach making use of a ball generator concept to restrict the sampling space into the smallest enclosing ball. Our numerical studies demonstrate the advantage of FLOWER achieving significantly improved performances over prior arts notably in the small base tasks. For further study, source codes of FLOWER, competitor algorithms and experimental logs are shared publicly in \\url{https://github.com/anwarmaxsum/FLOWER}.",
    "path": "papers/23/06/2306.14369.json",
    "total_tokens": 914,
    "translated_title": "利用扁平化到宽化方法进行少样本持续学习",
    "translated_abstract": "现有的持续学习方法在训练过程中需要大量的样本。由于过拟合问题，这些方法在拥有有限样本的许多实际问题中是不现实的。本文提出了一种少样本持续学习方法，称为FLat-tO-WidE AppRoach (FLOWER)，其中提出了一种寻找扁平化宽化极小值的扁平化到宽化学习过程，以解决灾难性遗忘问题。通过使用球体生成器概念进行数据增强方法来克服数据稀缺性问题，将采样空间限制在最小外接球内。我们的数值研究表明，FLOWER相比先前的方法在小型基础任务中实现了显著改进的性能。为了进一步研究，FLOWER的源代码，竞争算法和实验日志公开共享在\\url{https://github.com/anwarmaxsum/FLOWER}。",
    "tldr": "本文提出了一种少样本持续学习方法，名为FLat-tO-WidE AppRoach (FLOWER)，通过寻找扁平化宽化极小值的过程来解决灾难性遗忘问题，利用球体生成器概念进行数据增强方法来克服数据稀缺性问题。在小型基础任务中，FLOWER表现出显著改进的性能。",
    "en_tdlr": "This paper proposes a few-shot continual learning approach, named FLOWER, which addresses the catastrophic forgetting problem by finding the flat-wide minima and overcomes the issue of data scarcity with a data augmentation approach using a ball generator concept. FLOWER achieves significantly improved performance in small base tasks."
}