{
    "title": "Unlocking the Potential of User Feedback: Leveraging Large Language Model as User Simulator to Enhance Dialogue System. (arXiv:2306.09821v1 [cs.CL])",
    "abstract": "Dialogue systems and large language models (LLMs) have gained considerable attention. However, the direct utilization of LLMs as task-oriented dialogue (TOD) models has been found to underperform compared to smaller task-specific models. Nonetheless, it is crucial to acknowledge the significant potential of LLMs and explore improved approaches for leveraging their impressive abilities. Motivated by the goal of leveraging LLMs, we propose an alternative approach called User-Guided Response Optimization (UGRO) to combine it with a smaller TOD model. This approach uses LLM as annotation-free user simulator to assess dialogue responses, combining them with smaller fine-tuned end-to-end TOD models. By utilizing the satisfaction feedback generated by LLMs, UGRO further optimizes the supervised fine-tuned TOD model. Specifically, the TOD model takes the dialogue history as input and, with the assistance of the user simulator's feedback, generates high-satisfaction responses that meet the user",
    "link": "http://arxiv.org/abs/2306.09821",
    "context": "Title: Unlocking the Potential of User Feedback: Leveraging Large Language Model as User Simulator to Enhance Dialogue System. (arXiv:2306.09821v1 [cs.CL])\nAbstract: Dialogue systems and large language models (LLMs) have gained considerable attention. However, the direct utilization of LLMs as task-oriented dialogue (TOD) models has been found to underperform compared to smaller task-specific models. Nonetheless, it is crucial to acknowledge the significant potential of LLMs and explore improved approaches for leveraging their impressive abilities. Motivated by the goal of leveraging LLMs, we propose an alternative approach called User-Guided Response Optimization (UGRO) to combine it with a smaller TOD model. This approach uses LLM as annotation-free user simulator to assess dialogue responses, combining them with smaller fine-tuned end-to-end TOD models. By utilizing the satisfaction feedback generated by LLMs, UGRO further optimizes the supervised fine-tuned TOD model. Specifically, the TOD model takes the dialogue history as input and, with the assistance of the user simulator's feedback, generates high-satisfaction responses that meet the user",
    "path": "papers/23/06/2306.09821.json",
    "total_tokens": 1120,
    "translated_title": "开发用户反馈的潜力：利用大型语言模型作为用户模拟器以增强对话系统",
    "translated_abstract": "对话系统和大型语言模型（LLMs）已经引起了人们的极大关注。然而，与较小的任务特定模型相比，直接利用LLMs作为任务导向对话（TOD）模型的性能较差。尽管如此，承认LLMs的重大潜力并探索利用它们的惊人能力的改进方法非常重要。为了利用LLMs，我们提出了一种名为用户引导响应优化（UGRO）的替代方法，将LLM与较小的TOD模型结合起来。该方法使用LLM作为无注释的用户模拟器来评估对话响应，将其与较小的经过微调的端到端TOD模型相结合。通过利用LLMs生成的满意度反馈，UGRO进一步优化了监督式经过微调的TOD模型。具体而言，TOD模型以对话历史记录作为输入，并在用户模拟器反馈的帮助下生成符合用户需求的高满意度响应。实验结果表明，基于UGRO的方法相比现有最先进模型取得了显著的改进，为利用LLMs增强对话系统提供了洞察力。",
    "tldr": "该论文提出了一种名为用户引导响应优化（UGRO）的方法，使用大型语言模型作为无注释的用户模拟器，以评估对话响应并优化监督式经过微调的端到端任务导向对话模型。该方法利用了大型语言模型在提供满意度反馈方面的潜力，取得了显著的改进，为利用大型语言模型增强对话系统提供了新的思路。",
    "en_tdlr": "This paper proposes an alternative approach called User-Guided Response Optimization (UGRO) to enhance task-oriented dialogue (TOD) models by using large language models (LLMs) as annotation-free user simulators. By utilizing satisfaction feedback generated by LLMs, UGRO optimizes a supervised fine-tuned TOD model and has achieved significant improvements over state-of-the-art models, providing new insights into the potential of LLMs in enhancing dialogue systems."
}