{
    "title": "Good Data, Large Data, or No Data? Comparing Three Approaches in Developing Research Aspect Classifiers for Biomedical Papers. (arXiv:2306.04820v1 [cs.CL])",
    "abstract": "The rapid growth of scientific publications, particularly during the COVID-19 pandemic, emphasizes the need for tools to help researchers efficiently comprehend the latest advancements. One essential part of understanding scientific literature is research aspect classification, which categorizes sentences in abstracts to Background, Purpose, Method, and Finding. In this study, we investigate the impact of different datasets on model performance for the crowd-annotated CODA-19 research aspect classification task. Specifically, we explore the potential benefits of using the large, automatically curated PubMed 200K RCT dataset and evaluate the effectiveness of large language models (LLMs), such as LLaMA, GPT-3, ChatGPT, and GPT-4. Our results indicate that using the PubMed 200K RCT dataset does not improve performance for the CODA-19 task. We also observe that while GPT-4 performs well, it does not outperform the SciBERT model fine-tuned on the CODA-19 dataset, emphasizing the importance ",
    "link": "http://arxiv.org/abs/2306.04820",
    "context": "Title: Good Data, Large Data, or No Data? Comparing Three Approaches in Developing Research Aspect Classifiers for Biomedical Papers. (arXiv:2306.04820v1 [cs.CL])\nAbstract: The rapid growth of scientific publications, particularly during the COVID-19 pandemic, emphasizes the need for tools to help researchers efficiently comprehend the latest advancements. One essential part of understanding scientific literature is research aspect classification, which categorizes sentences in abstracts to Background, Purpose, Method, and Finding. In this study, we investigate the impact of different datasets on model performance for the crowd-annotated CODA-19 research aspect classification task. Specifically, we explore the potential benefits of using the large, automatically curated PubMed 200K RCT dataset and evaluate the effectiveness of large language models (LLMs), such as LLaMA, GPT-3, ChatGPT, and GPT-4. Our results indicate that using the PubMed 200K RCT dataset does not improve performance for the CODA-19 task. We also observe that while GPT-4 performs well, it does not outperform the SciBERT model fine-tuned on the CODA-19 dataset, emphasizing the importance ",
    "path": "papers/23/06/2306.04820.json",
    "total_tokens": 1044,
    "translated_title": "好数据、大数据还是无数据？——在开发生物医学论文研究方面分类器方面比较三种方法",
    "translated_abstract": "科学出版物的快速增长，特别是在COVID-19大流行期间，强调了需要帮助研究人员有效理解最新进展的工具。了解科学文献的一个关键部分是研究方面分类，它将摘要中的句子分类为背景、目的、方法和发现。在这项研究中，我们研究了不同数据集对众包注释的CODA-19研究方面分类任务模型性能的影响。具体来说，我们探讨了使用大规模的、自动策划的PubMed 200K RCT数据集的潜在优点，并评估了大型语言模型（LLMs）如LLaMA、GPT-3、ChatGPT和GPT-4的效果。我们的结果表明，对于CODA-19任务，使用PubMed 200K RCT数据集并不能改善性能。我们还观察到，尽管GPT-4表现良好，但它并没有超越fine-tuned在CODA-19数据集上的SciBERT模型，这强调了LLMs的重要性。",
    "tldr": "本研究探讨了使用不同数据集和大型语言模型在生物医学论文研究方面分类中的作用。结果表明，使用PubMed 200K RCT数据集并不能改善性能。与此同时，尽管GPT-4表现良好，但它并没有超越fine-tuned在CODA-19数据集上的SciBERT模型，这强调了LLMs的重要性。",
    "en_tdlr": "This study investigates the role of different datasets and Large Language Models (LLMs) in developing research aspect classifiers for biomedical papers, and finds that using the large, automatically curated PubMed 200K RCT dataset does not improve performance for the CODA-19 task. Although GPT-4 performs well, it does not outperform the SciBERT model fine-tuned on the CODA-19 dataset, emphasizing the importance of LLMs."
}