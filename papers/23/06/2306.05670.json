{
    "title": "One-Shot Machine Unlearning with Mnemonic Code. (arXiv:2306.05670v1 [cs.LG])",
    "abstract": "Deep learning has achieved significant improvements in accuracy and has been applied to various fields. With the spread of deep learning, a new problem has also emerged; deep learning models can sometimes have undesirable information from an ethical standpoint. This problem must be resolved if deep learning is to make sensitive decisions such as hiring and prison sentencing. Machine unlearning (MU) is the research area that responds to such demands. MU aims at forgetting about undesirable training data from a trained deep learning model. A naive MU approach is to re-train the whole model with the training data from which the undesirable data has been removed. However, re-training the whole model can take a huge amount of time and consumes significant computer resources. To make MU even more practical, a simple-yet-effective MU method is required. In this paper, we propose a one-shot MU method, which does not need additional training. To design one-shot MU, we add noise to the model par",
    "link": "http://arxiv.org/abs/2306.05670",
    "context": "Title: One-Shot Machine Unlearning with Mnemonic Code. (arXiv:2306.05670v1 [cs.LG])\nAbstract: Deep learning has achieved significant improvements in accuracy and has been applied to various fields. With the spread of deep learning, a new problem has also emerged; deep learning models can sometimes have undesirable information from an ethical standpoint. This problem must be resolved if deep learning is to make sensitive decisions such as hiring and prison sentencing. Machine unlearning (MU) is the research area that responds to such demands. MU aims at forgetting about undesirable training data from a trained deep learning model. A naive MU approach is to re-train the whole model with the training data from which the undesirable data has been removed. However, re-training the whole model can take a huge amount of time and consumes significant computer resources. To make MU even more practical, a simple-yet-effective MU method is required. In this paper, we propose a one-shot MU method, which does not need additional training. To design one-shot MU, we add noise to the model par",
    "path": "papers/23/06/2306.05670.json",
    "total_tokens": 871,
    "tldr": "本文提出了一种使用助记码的单次机器遗忘方法, 可以使深度学习模型忘记不良数据同时节约大量计算机资源。"
}