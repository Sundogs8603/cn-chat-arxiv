{
    "title": "EMO: Episodic Memory Optimization for Few-Shot Meta-Learning. (arXiv:2306.05189v1 [cs.LG])",
    "abstract": "Few-shot meta-learning presents a challenge for gradient descent optimization due to the limited number of training samples per task. To address this issue, we propose an episodic memory optimization for meta-learning, we call \\emph{EMO}, which is inspired by the human ability to recall past learning experiences from the brain's memory. EMO retains the gradient history of past experienced tasks in external memory, enabling few-shot learning in a memory-augmented way. By learning to retain and recall the learning process of past training tasks, EMO nudges parameter updates in the right direction, even when the gradients provided by a limited number of examples are uninformative. We prove theoretically that our algorithm converges for smooth, strongly convex objectives. EMO is generic, flexible, and model-agnostic, making it a simple plug-and-play optimizer that can be seamlessly embedded into existing optimization-based few-shot meta-learning approaches. Empirical results show that EMO ",
    "link": "http://arxiv.org/abs/2306.05189",
    "context": "Title: EMO: Episodic Memory Optimization for Few-Shot Meta-Learning. (arXiv:2306.05189v1 [cs.LG])\nAbstract: Few-shot meta-learning presents a challenge for gradient descent optimization due to the limited number of training samples per task. To address this issue, we propose an episodic memory optimization for meta-learning, we call \\emph{EMO}, which is inspired by the human ability to recall past learning experiences from the brain's memory. EMO retains the gradient history of past experienced tasks in external memory, enabling few-shot learning in a memory-augmented way. By learning to retain and recall the learning process of past training tasks, EMO nudges parameter updates in the right direction, even when the gradients provided by a limited number of examples are uninformative. We prove theoretically that our algorithm converges for smooth, strongly convex objectives. EMO is generic, flexible, and model-agnostic, making it a simple plug-and-play optimizer that can be seamlessly embedded into existing optimization-based few-shot meta-learning approaches. Empirical results show that EMO ",
    "path": "papers/23/06/2306.05189.json",
    "total_tokens": 946,
    "translated_title": "EMO：用于小样本元学习的情节记忆优化",
    "translated_abstract": "小样本元学习由于任务训练样本数量的限制对梯度下降优化提出了挑战。为了解决这个问题，本文提出了一种元学习的情节记忆优化方案，称为EMO。EMO受到人类从脑内记忆中回忆过去学习经验的能力的启发，将过去任务的梯度历史记录在外部存储器中，以增强记忆的方式进行小样本学习。通过学习保留和回忆过去训练任务的学习过程，即使仅有有限数量的示例提供了不可靠的梯度，EMO也可以推动参数更新朝着正确的方向前进。我们在理论上证明了该算法对于平滑、强凸目标函数会收敛。EMO是通用的、灵活的、与模型无关的优化器，可无缝嵌入现有的基于优化的小样本元学习方法。实证结果表明EMO可以提高准确性和收敛速度。",
    "tldr": "EMO是一种元学习的情节记忆优化方案，通过在外部存储器中记录过去任务的梯度历史，实现小样本学习，无论提供的梯度信息是否可靠，都可以推动参数更新朝着正确的方向前进。",
    "en_tdlr": "EMO is an episodic memory optimization for meta-learning, which retains the gradient history of past experienced tasks in external memory to enable few-shot learning. It is a generic, flexible, and model-agnostic optimizer that improves accuracy and convergence speed by nudging parameter updates in the right direction, even when the gradients provided by a limited number of examples are uninformative."
}