{
    "title": "Improving Long-Horizon Imitation Through Instruction Prediction. (arXiv:2306.12554v1 [cs.LG])",
    "abstract": "Complex, long-horizon planning and its combinatorial nature pose steep challenges for learning-based agents. Difficulties in such settings are exacerbated in low data regimes where over-fitting stifles generalization and compounding errors hurt accuracy. In this work, we explore the use of an often unused source of auxiliary supervision: language. Inspired by recent advances in transformer-based models, we train agents with an instruction prediction loss that encourages learning temporally extended representations that operate at a high level of abstraction. Concretely, we demonstrate that instruction modeling significantly improves performance in planning environments when training with a limited number of demonstrations on the BabyAI and Crafter benchmarks. In further analysis we find that instruction modeling is most important for tasks that require complex reasoning, while understandably offering smaller gains in environments that require simple plans. More details and code can be ",
    "link": "http://arxiv.org/abs/2306.12554",
    "context": "Title: Improving Long-Horizon Imitation Through Instruction Prediction. (arXiv:2306.12554v1 [cs.LG])\nAbstract: Complex, long-horizon planning and its combinatorial nature pose steep challenges for learning-based agents. Difficulties in such settings are exacerbated in low data regimes where over-fitting stifles generalization and compounding errors hurt accuracy. In this work, we explore the use of an often unused source of auxiliary supervision: language. Inspired by recent advances in transformer-based models, we train agents with an instruction prediction loss that encourages learning temporally extended representations that operate at a high level of abstraction. Concretely, we demonstrate that instruction modeling significantly improves performance in planning environments when training with a limited number of demonstrations on the BabyAI and Crafter benchmarks. In further analysis we find that instruction modeling is most important for tasks that require complex reasoning, while understandably offering smaller gains in environments that require simple plans. More details and code can be ",
    "path": "papers/23/06/2306.12554.json",
    "total_tokens": 890,
    "translated_title": "通过指令预测提高长期模仿的表现",
    "translated_abstract": "复杂的长期计划及其组合性质对于基于学习的智能体来说是巨大的挑战。在低数据环境中，过度拟合抑制了泛化，并且累积误差损害了准确性。本文中，我们探讨了一种通常未使用的辅助监督方式：语言。受最近基于Transformer模型的进展的启发，我们使用指令预测损失来训练代理，以鼓励学习在高层次上操作的具有时间扩展的表示。具体而言，我们证明了在BabyAI和Crafter基准测试中，指令建模显著提高了规划环境中受限的演示数量时的表现。在进一步的分析中，我们发现指令建模对需要复杂推理的任务最为重要，而在需要简单计划的环境中则可以理解地获得更小的收益。更多细节和代码可在[https://github.com/facebookresearch/long-term-fairness]中找到。",
    "tldr": "本文探讨了基于语言的指令预测损失的辅助监督方式，展示了在演示数量受限的情况下，指令建模在复杂推理任务中提高了表现。",
    "en_tdlr": "This paper explores the use of language-based instruction prediction loss as auxiliary supervision to train agents with high-level, temporally extended representations, and demonstrates that instruction modeling significantly improves performance in complex reasoning tasks with limited demonstrations."
}