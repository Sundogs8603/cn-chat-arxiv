{
    "title": "On Emergence of Clean-Priority Learning in Early Stopped Neural Networks. (arXiv:2306.02533v1 [cs.LG])",
    "abstract": "When random label noise is added to a training dataset, the prediction error of a neural network on a label-noise-free test dataset initially improves during early training but eventually deteriorates, following a U-shaped dependence on training time. This behaviour is believed to be a result of neural networks learning the pattern of clean data first and fitting the noise later in the training, a phenomenon that we refer to as clean-priority learning. In this study, we aim to explore the learning dynamics underlying this phenomenon. We theoretically demonstrate that, in the early stage of training, the update direction of gradient descent is determined by the clean subset of training data, leaving the noisy subset has minimal to no impact, resulting in a prioritization of clean learning. Moreover, we show both theoretically and experimentally, as the clean-priority learning goes on, the dominance of the gradients of clean samples over those of noisy samples diminishes, and finally res",
    "link": "http://arxiv.org/abs/2306.02533",
    "context": "Title: On Emergence of Clean-Priority Learning in Early Stopped Neural Networks. (arXiv:2306.02533v1 [cs.LG])\nAbstract: When random label noise is added to a training dataset, the prediction error of a neural network on a label-noise-free test dataset initially improves during early training but eventually deteriorates, following a U-shaped dependence on training time. This behaviour is believed to be a result of neural networks learning the pattern of clean data first and fitting the noise later in the training, a phenomenon that we refer to as clean-priority learning. In this study, we aim to explore the learning dynamics underlying this phenomenon. We theoretically demonstrate that, in the early stage of training, the update direction of gradient descent is determined by the clean subset of training data, leaving the noisy subset has minimal to no impact, resulting in a prioritization of clean learning. Moreover, we show both theoretically and experimentally, as the clean-priority learning goes on, the dominance of the gradients of clean samples over those of noisy samples diminishes, and finally res",
    "path": "papers/23/06/2306.02533.json",
    "total_tokens": 1103,
    "translated_title": "早期停止的神经网络中的清洁优先学习现象的出现",
    "translated_abstract": "当训练数据集中添加随机标签噪声时，神经网络在没有噪声的测试数据集上的预测误差在早期训练过程中会先改善后恶化，呈现出一个U形的依赖于训练时间的曲线。我们认为，这种行为是神经网络在训练中先学习干净数据的模式，然后再逐渐拟合噪声的结果。我们称之为清洁优先学习现象。本研究旨在探索该现象背后的学习动态。我们在理论上证明了，在训练的早期阶段，梯度下降的更新方向由训练数据的干净子集决定，噪声子集的影响是最小的或没有的，导致了优先进行干净数据的学习。此外，我们理论上和实验上都显示，在进行清洁优先学习的过程中，清洁样本的梯度在嘈杂样本的梯度之上的优势逐渐减小，最终形成了预测误差的U形曲线。我们的发现为清洁优先学习现象的出现提供了深入的洞察，并提出了提高神经网络对标签噪声的鲁棒性的潜在策略。",
    "tldr": "当训练数据集中添加随机标签噪声时，神经网络会先学习干净数据再学习噪声，导致预测误差呈现U形曲线。本研究探索了这种清洁优先学习的学习动态，并提出了提高神经网络对标签噪声鲁棒性的潜在策略。",
    "en_tdlr": "When label noise is added to training data, neural networks first learn the clean data pattern before fitting the noise, resulting in a U-shaped dependence of prediction error on training time. This study explores the dynamics underlying this clean-priority learning phenomenon and suggests potential strategies for improving neural network robustness to label noise."
}