{
    "title": "You Don't Need Robust Machine Learning to Manage Adversarial Attack Risks. (arXiv:2306.09951v1 [cs.LG])",
    "abstract": "The robustness of modern machine learning (ML) models has become an increasing concern within the community. The ability to subvert a model into making errant predictions using seemingly inconsequential changes to input is startling, as is our lack of success in building models robust to this concern. Existing research shows progress, but current mitigations come with a high cost and simultaneously reduce the model's accuracy. However, such trade-offs may not be necessary when other design choices could subvert the risk. In this survey we review the current literature on attacks and their real-world occurrences, or limited evidence thereof, to critically evaluate the real-world risks of adversarial machine learning (AML) for the average entity. This is done with an eye toward how one would then mitigate these attacks in practice, the risks for production deployment, and how those risks could be managed. In doing so we elucidate that many AML threats do not warrant the cost and trade-of",
    "link": "http://arxiv.org/abs/2306.09951",
    "context": "Title: You Don't Need Robust Machine Learning to Manage Adversarial Attack Risks. (arXiv:2306.09951v1 [cs.LG])\nAbstract: The robustness of modern machine learning (ML) models has become an increasing concern within the community. The ability to subvert a model into making errant predictions using seemingly inconsequential changes to input is startling, as is our lack of success in building models robust to this concern. Existing research shows progress, but current mitigations come with a high cost and simultaneously reduce the model's accuracy. However, such trade-offs may not be necessary when other design choices could subvert the risk. In this survey we review the current literature on attacks and their real-world occurrences, or limited evidence thereof, to critically evaluate the real-world risks of adversarial machine learning (AML) for the average entity. This is done with an eye toward how one would then mitigate these attacks in practice, the risks for production deployment, and how those risks could be managed. In doing so we elucidate that many AML threats do not warrant the cost and trade-of",
    "path": "papers/23/06/2306.09951.json",
    "total_tokens": 884,
    "translated_title": "不需要强鲁棒机器学习来管理对抗攻击风险",
    "translated_abstract": "现代机器学习（ML）模型的鲁棒性已成为社区内日益关注的问题。能够通过对输入进行貌似无关的更改来破坏模型，从而导致错误预测的能力令人震惊，而我们在构建具有鲁棒性的模型方面的成效也不容乐观。现有研究取得了一定的进展，但当前的缓解措施带来了很高的成本，同时也降低了模型的准确性。然而，当存在其他设计选择可以避免这种风险时，这样的权衡可能并不必要。在本调查中，我们通过眼光关注实践中如何缓解这些攻击，生产部署的风险以及管理这些风险。在此过程中，我们阐明了许多AML威胁不足以证明这种成本和权衡的必要性。",
    "tldr": "本文对现代机器学习中的鲁棒性问题和对抗攻击进行了调查，发现不必要采用高成本的强鲁棒机器学习，可以通过其他设计选择来缓解对抗攻击的风险。",
    "en_tdlr": "This paper investigates the robustness issue and adversarial attacks in modern machine learning and suggests that it is not necessary to use costly robust machine learning, but other design choices could mitigate the risks of adversarial attacks."
}