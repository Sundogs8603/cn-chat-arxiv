{
    "title": "Interpretable Alzheimer's Disease Classification Via a Contrastive Diffusion Autoencoder. (arXiv:2306.03022v2 [cs.CV] UPDATED)",
    "abstract": "In visual object classification, humans often justify their choices by comparing objects to prototypical examples within that class. We may therefore increase the interpretability of deep learning models by imbuing them with a similar style of reasoning. In this work, we apply this principle by classifying Alzheimer's Disease based on the similarity of images to training examples within the latent space. We use a contrastive loss combined with a diffusion autoencoder backbone, to produce a semantically meaningful latent space, such that neighbouring latents have similar image-level features. We achieve a classification accuracy comparable to black box approaches on a dataset of 2D MRI images, whilst producing human interpretable model explanations. Therefore, this work stands as a contribution to the pertinent development of accurate and interpretable deep learning within medical imaging.",
    "link": "http://arxiv.org/abs/2306.03022",
    "context": "Title: Interpretable Alzheimer's Disease Classification Via a Contrastive Diffusion Autoencoder. (arXiv:2306.03022v2 [cs.CV] UPDATED)\nAbstract: In visual object classification, humans often justify their choices by comparing objects to prototypical examples within that class. We may therefore increase the interpretability of deep learning models by imbuing them with a similar style of reasoning. In this work, we apply this principle by classifying Alzheimer's Disease based on the similarity of images to training examples within the latent space. We use a contrastive loss combined with a diffusion autoencoder backbone, to produce a semantically meaningful latent space, such that neighbouring latents have similar image-level features. We achieve a classification accuracy comparable to black box approaches on a dataset of 2D MRI images, whilst producing human interpretable model explanations. Therefore, this work stands as a contribution to the pertinent development of accurate and interpretable deep learning within medical imaging.",
    "path": "papers/23/06/2306.03022.json",
    "total_tokens": 838,
    "translated_title": "通过对比扩散自编码器实现可解释的阿尔茨海默病分类",
    "translated_abstract": "在可视化对象分类中，人类经常通过将对象与类别内的典型示例进行比较来证明他们的选择。因此，我们可以通过赋予深度学习模型类似的推理方式来增加其可解释性。在这项工作中，我们通过将影像与潜在空间中的训练样本的相似性来对阿尔茨海默病进行分类。我们使用对比损失结合扩散自编码器骨干，生成一个语义有意义的潜在空间，使相邻的潜在空间具有类似的图像级特征。我们在一个2D MRI图像数据集上实现了与黑盒方法相当的分类准确性，同时产生人类可解释的模型解释。因此，这项工作对于在医学影像中准确且可解释的深度学习的相关发展是一项贡献。",
    "tldr": "本研究通过使用对比扩散自编码器实现了对阿尔茨海默病的可解释分类，达到了与黑盒方法相当的分类准确性，并产生人类可解释的模型解释。"
}