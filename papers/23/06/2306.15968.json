{
    "title": "Action and Trajectory Planning for Urban Autonomous Driving with Hierarchical Reinforcement Learning. (arXiv:2306.15968v1 [cs.RO])",
    "abstract": "Reinforcement Learning (RL) has made promising progress in planning and decision-making for Autonomous Vehicles (AVs) in simple driving scenarios. However, existing RL algorithms for AVs fail to learn critical driving skills in complex urban scenarios. First, urban driving scenarios require AVs to handle multiple driving tasks of which conventional RL algorithms are incapable. Second, the presence of other vehicles in urban scenarios results in a dynamically changing environment, which challenges RL algorithms to plan the action and trajectory of the AV. In this work, we propose an action and trajectory planner using Hierarchical Reinforcement Learning (atHRL) method, which models the agent behavior in a hierarchical model by using the perception of the lidar and birdeye view. The proposed atHRL method learns to make decisions about the agent's future trajectory and computes target waypoints under continuous settings based on a hierarchical DDPG algorithm. The waypoints planned by the ",
    "link": "http://arxiv.org/abs/2306.15968",
    "context": "Title: Action and Trajectory Planning for Urban Autonomous Driving with Hierarchical Reinforcement Learning. (arXiv:2306.15968v1 [cs.RO])\nAbstract: Reinforcement Learning (RL) has made promising progress in planning and decision-making for Autonomous Vehicles (AVs) in simple driving scenarios. However, existing RL algorithms for AVs fail to learn critical driving skills in complex urban scenarios. First, urban driving scenarios require AVs to handle multiple driving tasks of which conventional RL algorithms are incapable. Second, the presence of other vehicles in urban scenarios results in a dynamically changing environment, which challenges RL algorithms to plan the action and trajectory of the AV. In this work, we propose an action and trajectory planner using Hierarchical Reinforcement Learning (atHRL) method, which models the agent behavior in a hierarchical model by using the perception of the lidar and birdeye view. The proposed atHRL method learns to make decisions about the agent's future trajectory and computes target waypoints under continuous settings based on a hierarchical DDPG algorithm. The waypoints planned by the ",
    "path": "papers/23/06/2306.15968.json",
    "total_tokens": 940,
    "translated_title": "基于分层强化学习的城市自动驾驶行动和轨迹规划",
    "translated_abstract": "强化学习在简单驾驶场景中为自动驾驶车辆的规划和决策取得了可观的进展。然而，现有的强化学习算法在复杂的城市场景中无法学习关键的驾驶技能。首先，城市驾驶场景要求自动驾驶车辆处理多个驾驶任务，而传统的强化学习算法无法胜任。其次，城市场景中其他车辆的存在导致环境不断变化，这对强化学习算法来规划自动驾驶车辆的行动和轨迹构成了挑战。在这项工作中，我们提出了一种使用分层强化学习方法的行动和轨迹规划器(atHRL)，该方法通过使用激光雷达和鸟瞰图的感知来建模代理行为。所提出的atHRL方法通过使用分层DDPG算法，在连续情况下学习做出关于代理未来轨迹的决策，并基于此计算目标路径点。",
    "tldr": "本文提出了一种使用分层强化学习方法的城市自动驾驶行动和轨迹规划器，通过感知信息和分层模型来学习和规划自动驾驶车辆行为，并解决复杂城市场景下的行驶任务和动态环境变化的挑战。",
    "en_tdlr": "This paper proposes a hierarchical reinforcement learning approach for action and trajectory planning in urban autonomous driving, which addresses the challenges of handling multiple driving tasks and dynamically changing environments in complex urban scenarios."
}