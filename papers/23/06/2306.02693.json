{
    "title": "CELDA: Leveraging Black-box Language Model as Enhanced Classifier without Labels. (arXiv:2306.02693v2 [cs.CL] UPDATED)",
    "abstract": "Utilizing language models (LMs) without internal access is becoming an attractive paradigm in the field of NLP as many cutting-edge LMs are released through APIs and boast a massive scale. The de-facto method in this type of black-box scenario is known as prompting, which has shown progressive performance enhancements in situations where data labels are scarce or unavailable. Despite their efficacy, they still fall short in comparison to fully supervised counterparts and are generally brittle to slight modifications. In this paper, we propose Clustering-enhanced Linear Discriminative Analysis, a novel approach that improves the text classification accuracy with a very weak-supervision signal (i.e., name of the labels). Our framework draws a precise decision boundary without accessing weights or gradients of the LM model or data labels. The core ideas of CELDA are twofold: (1) extracting a refined pseudo-labeled dataset from an unlabeled dataset, and (2) training a lightweight and robus",
    "link": "http://arxiv.org/abs/2306.02693",
    "context": "Title: CELDA: Leveraging Black-box Language Model as Enhanced Classifier without Labels. (arXiv:2306.02693v2 [cs.CL] UPDATED)\nAbstract: Utilizing language models (LMs) without internal access is becoming an attractive paradigm in the field of NLP as many cutting-edge LMs are released through APIs and boast a massive scale. The de-facto method in this type of black-box scenario is known as prompting, which has shown progressive performance enhancements in situations where data labels are scarce or unavailable. Despite their efficacy, they still fall short in comparison to fully supervised counterparts and are generally brittle to slight modifications. In this paper, we propose Clustering-enhanced Linear Discriminative Analysis, a novel approach that improves the text classification accuracy with a very weak-supervision signal (i.e., name of the labels). Our framework draws a precise decision boundary without accessing weights or gradients of the LM model or data labels. The core ideas of CELDA are twofold: (1) extracting a refined pseudo-labeled dataset from an unlabeled dataset, and (2) training a lightweight and robus",
    "path": "papers/23/06/2306.02693.json",
    "total_tokens": 809,
    "translated_title": "CELDA: 在没有标签的情况下利用黑匣子语言模型进行增强分类的方法",
    "translated_abstract": "利用API公开的现代化语言模型进行文本分类的任务正在受到研究人员的广泛关注。在标签数据稀缺或不可用的情况下，已有的提示方法可以提高分类性能，但其效果仍不如完全监督的分类器，并且在数据微小变化下表现欠佳。本文提出一种新颖的方法，Clustering-enhanced Linear Discriminative Analysis，通过提取精细的伪标签数据集并利用聚类增强的判别学习算法进行训练，实现了在非常弱的监督信号条件下（即标签名）提高文本分类准确性的目的。",
    "tldr": "本文提出 CELDA 方法，通过提取精细的伪标签数据集并利用聚类增强的判别学习算法进行训练，在没有标签的情况下提高文本分类效果。",
    "en_tdlr": "The paper proposes the CELDA method, which trains a classification model on a refined pseudo-labeled dataset using a clustering-enhanced discriminative learning algorithm and achieves improved text classification accuracy without access to data labels."
}