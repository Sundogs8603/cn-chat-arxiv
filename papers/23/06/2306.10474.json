{
    "title": "A Universal Semantic-Geometric Representation for Robotic Manipulation. (arXiv:2306.10474v2 [cs.RO] UPDATED)",
    "abstract": "Robots rely heavily on sensors, especially RGB and depth cameras, to perceive and interact with the world. RGB cameras record 2D images with rich semantic information while missing precise spatial information. On the other side, depth cameras offer critical 3D geometry data but capture limited semantics. Therefore, integrating both modalities is crucial for learning representations for robotic perception and control. However, current research predominantly focuses on only one of these modalities, neglecting the benefits of incorporating both. To this end, we present $\\textbf{Semantic-Geometric Representation} (\\textbf{SGR})$, a universal perception module for robotics that leverages the rich semantic information of large-scale pre-trained 2D models and inherits the merits of 3D spatial reasoning. Our experiments demonstrate that SGR empowers the agent to successfully complete a diverse range of simulated and real-world robotic manipulation tasks, outperforming state-of-the-art methods ",
    "link": "http://arxiv.org/abs/2306.10474",
    "context": "Title: A Universal Semantic-Geometric Representation for Robotic Manipulation. (arXiv:2306.10474v2 [cs.RO] UPDATED)\nAbstract: Robots rely heavily on sensors, especially RGB and depth cameras, to perceive and interact with the world. RGB cameras record 2D images with rich semantic information while missing precise spatial information. On the other side, depth cameras offer critical 3D geometry data but capture limited semantics. Therefore, integrating both modalities is crucial for learning representations for robotic perception and control. However, current research predominantly focuses on only one of these modalities, neglecting the benefits of incorporating both. To this end, we present $\\textbf{Semantic-Geometric Representation} (\\textbf{SGR})$, a universal perception module for robotics that leverages the rich semantic information of large-scale pre-trained 2D models and inherits the merits of 3D spatial reasoning. Our experiments demonstrate that SGR empowers the agent to successfully complete a diverse range of simulated and real-world robotic manipulation tasks, outperforming state-of-the-art methods ",
    "path": "papers/23/06/2306.10474.json",
    "total_tokens": 878,
    "translated_title": "机器人操纵的通用语义几何表示",
    "translated_abstract": "机器人在感知和与世界互动时 heavily relies 传感器，特别是RGB和深度相机。RGB相机记录了具有丰富语义信息的2D图像，但缺乏精确的空间信息。另一方面，深度相机提供了关键的3D几何数据，但捕捉到的语义有限。因此，整合两种模态对于学习机器人感知和控制的表示是至关重要的。然而，当前的研究主要集中在其中一种模态上，并忽略了结合两者的好处。为此，我们提出了$\\textbf{语义几何表示} (\\textbf{SGR})$，这是一个用于机器人的通用感知模块，它利用了大规模预训练的2D模型的丰富语义信息，并承继了3D空间推理的优点。我们的实验表明，SGR使机器人能够成功完成各种模拟和真实世界的机器人操纵任务，胜过了最先进的方法。",
    "tldr": "这篇论文提出了一种通用的机器人感知模块，称为语义几何表示（SGR），该模块结合了大规模预训练的2D模型的丰富语义信息和3D空间推理的优势，能够在各种模拟和真实世界的机器人操纵任务中胜过最先进的方法。"
}