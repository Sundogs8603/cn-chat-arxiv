{
    "title": "Reference Matters: Benchmarking Factual Error Correction for Dialogue Summarization with Fine-grained Evaluation Framework. (arXiv:2306.05119v1 [cs.CL])",
    "abstract": "Factuality is important to dialogue summarization. Factual error correction (FEC) of model-generated summaries is one way to improve factuality. Current FEC evaluation that relies on factuality metrics is not reliable and detailed enough. To address this problem, we are the first to manually annotate a FEC dataset for dialogue summarization containing 4000 items and propose FERRANTI, a fine-grained evaluation framework based on reference correction that automatically evaluates the performance of FEC models on different error categories. Using this evaluation framework, we conduct sufficient experiments with FEC approaches under a variety of settings and find the best training modes and significant differences in the performance of the existing approaches on different factual error categories.",
    "link": "http://arxiv.org/abs/2306.05119",
    "context": "Title: Reference Matters: Benchmarking Factual Error Correction for Dialogue Summarization with Fine-grained Evaluation Framework. (arXiv:2306.05119v1 [cs.CL])\nAbstract: Factuality is important to dialogue summarization. Factual error correction (FEC) of model-generated summaries is one way to improve factuality. Current FEC evaluation that relies on factuality metrics is not reliable and detailed enough. To address this problem, we are the first to manually annotate a FEC dataset for dialogue summarization containing 4000 items and propose FERRANTI, a fine-grained evaluation framework based on reference correction that automatically evaluates the performance of FEC models on different error categories. Using this evaluation framework, we conduct sufficient experiments with FEC approaches under a variety of settings and find the best training modes and significant differences in the performance of the existing approaches on different factual error categories.",
    "path": "papers/23/06/2306.05119.json",
    "total_tokens": 807,
    "translated_title": "参考文献至上：基于细粒度评估框架的对话摘要事实误差校正基准测试",
    "translated_abstract": "在对话摘要中，事实性很重要。对于模型生成的摘要进行事实误差校正（FEC）是提高事实性的一种方式。当前依赖于事实性指标的FEC评估不够可靠和详细。为了解决这个问题，我们首次手动注释了一个包含4000个项目的对话摘要FEC数据集，并提出了基于参考校正的细粒度评估框架FERRANTI，该框架自动评估FEC模型在不同错误类别上的表现。使用这个评估框架，在各种设置下进行了足够的FEC方法实验，并在不同的事实误差类别上找到了最佳的训练模式和现有方法的显著性差异。",
    "tldr": "该论文提出了基于参考校正的细粒度FEC评估框架，并在使用该框架进行实验的过程中发现了不同事实误差类别下的最佳训练模式和现有方法之间的显著性差异。",
    "en_tdlr": "This paper proposes a fine-grained FEC evaluation framework based on reference correction and discovers significant differences in the performance of existing methods and the best training modes for different factual error categories through experiments using this framework."
}