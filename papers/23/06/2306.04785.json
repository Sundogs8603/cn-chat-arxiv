{
    "title": "Interpretable Deep Clustering. (arXiv:2306.04785v1 [cs.LG])",
    "abstract": "Clustering is a fundamental learning task widely used as a first step in data analysis. For example, biologists often use cluster assignments to analyze genome sequences, medical records, or images. Since downstream analysis is typically performed at the cluster level, practitioners seek reliable and interpretable clustering models. We propose a new deep-learning framework that predicts interpretable cluster assignments at the instance and cluster levels. First, we present a self-supervised procedure to identify a subset of informative features from each data point. Then, we design a model that predicts cluster assignments and a gate matrix that leads to cluster-level feature selection. We show that the proposed method can reliably predict cluster assignments using synthetic and real data. Furthermore, we verify that our model leads to interpretable results at a sample and cluster level.",
    "link": "http://arxiv.org/abs/2306.04785",
    "context": "Title: Interpretable Deep Clustering. (arXiv:2306.04785v1 [cs.LG])\nAbstract: Clustering is a fundamental learning task widely used as a first step in data analysis. For example, biologists often use cluster assignments to analyze genome sequences, medical records, or images. Since downstream analysis is typically performed at the cluster level, practitioners seek reliable and interpretable clustering models. We propose a new deep-learning framework that predicts interpretable cluster assignments at the instance and cluster levels. First, we present a self-supervised procedure to identify a subset of informative features from each data point. Then, we design a model that predicts cluster assignments and a gate matrix that leads to cluster-level feature selection. We show that the proposed method can reliably predict cluster assignments using synthetic and real data. Furthermore, we verify that our model leads to interpretable results at a sample and cluster level.",
    "path": "papers/23/06/2306.04785.json",
    "total_tokens": 870,
    "translated_title": "可解释的深度聚类",
    "translated_abstract": "聚类是一项广泛应用于数据分析中的基础学习任务。例如，生物学家经常使用聚类分配来分析基因组序列、医疗记录或图像。由于下游分析通常在聚类级别上执行，因此从业者寻求可靠且可解释的聚类模型。本文提出了一种新的深度学习框架，它可以预测可解释的实例和聚类级别的聚类分配。首先，我们提出一个自我监督的过程来从每个数据点中标识出一组信息量丰富的特征子集。然后，我们设计了一个模型，用于预测聚类分配和一个门矩阵，用于引导聚类级别的特征选择。我们证明了所提出的方法可以使用合成和实际数据可靠地预测聚类分配。此外，我们验证了我们的模型可以在实例和聚类级别上产生可解释的结果。",
    "tldr": "本文提出了一种可解释的深度学习框架，通过自我监督的方式从数据点中标识信息量丰富的特征，设计了一个模型和门矩阵来预测可解释的实例和聚类级别的聚类分配，并在合成和实际数据中验证了其可靠性和可解释性。",
    "en_tdlr": "This paper proposes an interpretable deep-learning framework for clustering, which identifies informative features from data points through a self-supervised process, predicts interpretable cluster assignments at instance and cluster levels, and produces reliable and interpretable results on synthetic and real data."
}