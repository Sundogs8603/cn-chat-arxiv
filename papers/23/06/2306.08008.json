{
    "title": "Dynamic Interval Restrictions on Action Spaces in Deep Reinforcement Learning for Obstacle Avoidance. (arXiv:2306.08008v1 [cs.LG])",
    "abstract": "Deep reinforcement learning algorithms typically act on the same set of actions. However, this is not sufficient for a wide range of real-world applications where different subsets are available at each step. In this thesis, we consider the problem of interval restrictions as they occur in pathfinding with dynamic obstacles. When actions that lead to collisions are avoided, the continuous action space is split into variable parts. Recent research learns with strong assumptions on the number of intervals, is limited to convex subsets, and the available actions are learned from the observations. Therefore, we propose two approaches that are independent of the state of the environment by extending parameterized reinforcement learning and ConstraintNet to handle an arbitrary number of intervals. We demonstrate their performance in an obstacle avoidance task and compare the methods to penalties, projection, replacement, as well as discrete and continuous masking from the literature. The res",
    "link": "http://arxiv.org/abs/2306.08008",
    "context": "Title: Dynamic Interval Restrictions on Action Spaces in Deep Reinforcement Learning for Obstacle Avoidance. (arXiv:2306.08008v1 [cs.LG])\nAbstract: Deep reinforcement learning algorithms typically act on the same set of actions. However, this is not sufficient for a wide range of real-world applications where different subsets are available at each step. In this thesis, we consider the problem of interval restrictions as they occur in pathfinding with dynamic obstacles. When actions that lead to collisions are avoided, the continuous action space is split into variable parts. Recent research learns with strong assumptions on the number of intervals, is limited to convex subsets, and the available actions are learned from the observations. Therefore, we propose two approaches that are independent of the state of the environment by extending parameterized reinforcement learning and ConstraintNet to handle an arbitrary number of intervals. We demonstrate their performance in an obstacle avoidance task and compare the methods to penalties, projection, replacement, as well as discrete and continuous masking from the literature. The res",
    "path": "papers/23/06/2306.08008.json",
    "total_tokens": 835,
    "translated_title": "基于动态区间限制的深度强化学习在避障中的应用",
    "translated_abstract": "深度强化学习算法通常在同一组动作上执行，但这在许多真实场景下都不够充分，因为每个步骤可用的动作组不同。本文考虑了动态障碍物场景中出现的区间限制问题。当需要避免导致碰撞的动作时，连续动作空间将被划分为变量部分。最近的研究对区间数量做出了较强假设，仅限于凸子集，并且可用的动作是根据观察结果学习的。因此，本文提出了两种方法，基于参数化强化学习和ConstraintNet，能处理任意数量的区间而不会受环境状态的影响。我们将这两种方法应用于避障任务，并将它们与文献中的惩罚、投影、替换以及离散和连续屏蔽方法进行比较。",
    "tldr": "本文提出两种在动态障碍物场景下处理任意数量区间限制的方法，能较好地完成避障任务，表现优于现有方法。",
    "en_tdlr": "This paper proposes two methods for handling dynamic interval restrictions in obstacle avoidance with arbitrary number of intervals. The methods, based on parameterized reinforcement learning and ConstraintNet, show better performance than existing methods."
}