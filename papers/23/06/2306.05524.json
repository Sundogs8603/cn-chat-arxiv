{
    "title": "Check Me If You Can: Detecting ChatGPT-Generated Academic Writing using CheckGPT. (arXiv:2306.05524v1 [cs.CL])",
    "abstract": "With ChatGPT under the spotlight, utilizing large language models (LLMs) for academic writing has drawn a significant amount of discussions and concerns in the community. While substantial research efforts have been stimulated for detecting LLM-Generated Content (LLM-content), most of the attempts are still in the early stage of exploration. In this paper, we present a holistic investigation of detecting LLM-generate academic writing, by providing a dataset, evidence, and algorithms, in order to inspire more community effort to address the concern of LLM academic misuse. We first present GPABenchmark, a benchmarking dataset of 600,000 samples of human-written, GPT-written, GPT-completed, and GPT-polished abstracts of research papers in CS, physics, and humanities and social sciences (HSS). We show that existing open-source and commercial GPT detectors provide unsatisfactory performance on GPABenchmark, especially for GPT-polished text. Moreover, through a user study of 150+ participant",
    "link": "http://arxiv.org/abs/2306.05524",
    "context": "Title: Check Me If You Can: Detecting ChatGPT-Generated Academic Writing using CheckGPT. (arXiv:2306.05524v1 [cs.CL])\nAbstract: With ChatGPT under the spotlight, utilizing large language models (LLMs) for academic writing has drawn a significant amount of discussions and concerns in the community. While substantial research efforts have been stimulated for detecting LLM-Generated Content (LLM-content), most of the attempts are still in the early stage of exploration. In this paper, we present a holistic investigation of detecting LLM-generate academic writing, by providing a dataset, evidence, and algorithms, in order to inspire more community effort to address the concern of LLM academic misuse. We first present GPABenchmark, a benchmarking dataset of 600,000 samples of human-written, GPT-written, GPT-completed, and GPT-polished abstracts of research papers in CS, physics, and humanities and social sciences (HSS). We show that existing open-source and commercial GPT detectors provide unsatisfactory performance on GPABenchmark, especially for GPT-polished text. Moreover, through a user study of 150+ participant",
    "path": "papers/23/06/2306.05524.json",
    "total_tokens": 930,
    "tldr": "本研究提供了一个数据集、证据和算法，全面调查检测LLM生成的学术写作，其中GPT polish这一环节的检测尤其具有挑战性。"
}