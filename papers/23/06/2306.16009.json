{
    "title": "Accelerating Transducers through Adjacent Token Merging. (arXiv:2306.16009v1 [cs.CL])",
    "abstract": "Recent end-to-end automatic speech recognition (ASR) systems often utilize a Transformer-based acoustic encoder that generates embedding at a high frame rate. However, this design is inefficient, particularly for long speech signals due to the quadratic computation of self-attention. To address this, we propose a new method, Adjacent Token Merging (A-ToMe), which gradually combines adjacent tokens with high similarity scores between their key values. In this way, the total time step could be reduced, and the inference of both the encoder and joint network is accelerated. Experiments on LibriSpeech show that our method can reduce 57% of tokens and improve the inference speed on GPU by 70% without any notable loss of accuracy. Additionally, we demonstrate that A-ToMe is also an effective solution to reduce tokens in long-form ASR, where the input speech consists of multiple utterances.",
    "link": "http://arxiv.org/abs/2306.16009",
    "context": "Title: Accelerating Transducers through Adjacent Token Merging. (arXiv:2306.16009v1 [cs.CL])\nAbstract: Recent end-to-end automatic speech recognition (ASR) systems often utilize a Transformer-based acoustic encoder that generates embedding at a high frame rate. However, this design is inefficient, particularly for long speech signals due to the quadratic computation of self-attention. To address this, we propose a new method, Adjacent Token Merging (A-ToMe), which gradually combines adjacent tokens with high similarity scores between their key values. In this way, the total time step could be reduced, and the inference of both the encoder and joint network is accelerated. Experiments on LibriSpeech show that our method can reduce 57% of tokens and improve the inference speed on GPU by 70% without any notable loss of accuracy. Additionally, we demonstrate that A-ToMe is also an effective solution to reduce tokens in long-form ASR, where the input speech consists of multiple utterances.",
    "path": "papers/23/06/2306.16009.json",
    "total_tokens": 891,
    "translated_title": "加速传感器通过相邻令牌合并",
    "translated_abstract": "最近的端到端自动语音识别（ASR）系统通常利用基于Transformer的声学编码器，在高帧率下生成嵌入。然而，由于自注意力的二次计算，这种设计在处理长音频信号时效率低下。为了解决这个问题，我们提出了一种新的方法，即相邻令牌合并（A-ToMe），它逐渐合并具有相似关键值的相邻令牌。通过这种方式，可以减少总的时间步长，并加快编码器和联合网络的推理速度。在LibriSpeech上的实验证明，我们的方法可以减少57%的令牌，并在GPU上提高70%的推理速度，而几乎没有损失准确性。此外，我们还证明A-ToMe也是一种减少长形式ASR令牌的有效解决方案，其中输入语音由多个话语组成。",
    "tldr": "提出了一种相邻令牌合并（A-ToMe）的新方法，通过逐渐合并具有相似关键值的相邻令牌，减少了总的时间步长，并加快了语音识别系统的推理速度。实验证明，该方法可以显著减少令牌数量并提高推理速度，同时准确性损失微乎其微。",
    "en_tdlr": "A new method called Adjacent Token Merging (A-ToMe) is proposed to reduce the total time step and accelerate the inference speed of speech recognition systems by gradually combining adjacent tokens with high similarity scores. Experimental results demonstrate that this method significantly reduces the number of tokens and improves the inference speed with minimal loss of accuracy."
}