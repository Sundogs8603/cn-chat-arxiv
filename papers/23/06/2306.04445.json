{
    "title": "Multi-modal Latent Diffusion. (arXiv:2306.04445v1 [cs.LG])",
    "abstract": "Multi-modal data-sets are ubiquitous in modern applications, and multi-modal Variational Autoencoders are a popular family of models that aim to learn a joint representation of the different modalities. However, existing approaches suffer from a coherence-quality tradeoff, where models with good generation quality lack generative coherence across modalities, and vice versa. We discuss the limitations underlying the unsatisfactory performance of existing methods, to motivate the need for a different approach. We propose a novel method that uses a set of independently trained, uni-modal, deterministic autoencoders. Individual latent variables are concatenated into a common latent space, which is fed to a masked diffusion model to enable generative modeling. We also introduce a new multi-time training method to learn the conditional score network for multi-modal diffusion. Our methodology substantially outperforms competitors in both generation quality and coherence, as shown through an e",
    "link": "http://arxiv.org/abs/2306.04445",
    "context": "Title: Multi-modal Latent Diffusion. (arXiv:2306.04445v1 [cs.LG])\nAbstract: Multi-modal data-sets are ubiquitous in modern applications, and multi-modal Variational Autoencoders are a popular family of models that aim to learn a joint representation of the different modalities. However, existing approaches suffer from a coherence-quality tradeoff, where models with good generation quality lack generative coherence across modalities, and vice versa. We discuss the limitations underlying the unsatisfactory performance of existing methods, to motivate the need for a different approach. We propose a novel method that uses a set of independently trained, uni-modal, deterministic autoencoders. Individual latent variables are concatenated into a common latent space, which is fed to a masked diffusion model to enable generative modeling. We also introduce a new multi-time training method to learn the conditional score network for multi-modal diffusion. Our methodology substantially outperforms competitors in both generation quality and coherence, as shown through an e",
    "path": "papers/23/06/2306.04445.json",
    "total_tokens": 889,
    "translated_title": "多模态潜在扩散",
    "translated_abstract": "在现代应用中，多模态数据集无处不在，多模态变分自编码器是一类流行的模型，旨在学习不同模态的联合表示。然而，现有方法存在连贯性 - 质量折衷的问题，具有良好生成质量的模型缺乏模态间的生成连贯性，反之亦然。我们讨论现有方法的局限性，从而说明需要不同的方法。我们提出了一种新方法，该方法使用一组独立训练的单模态确定性自编码器，将单个潜在变量连接到公共潜在空间中，然后将其输入到掩蔽扩散模型中以实现生成建模。我们还引入了一种新的多时间训练方法，用于学习多模态扩散的条件得分网络。通过对几个多模态数据集的评估，我们的方法在生成质量和连贯性方面都明显优于竞争对手。",
    "tldr": "该论文提出一个新的方法来处理多模态数据，该方法使用了一组独立训练的单模态确定性自编码器，将单个潜在变量连接到公共潜在空间中，并通过掩蔽扩散模型实现了良好的生成质量和模态间连贯性。",
    "en_tdlr": "This paper proposes a novel method for handling multi-modal data by using a set of independently trained, uni-modal, deterministic autoencoders, concatenating individual latent variables into a common latent space, and utilizing a masked diffusion model, which achieves both good generation quality and inter-modality coherence."
}