{
    "title": "Segment Any Point Cloud Sequences by Distilling Vision Foundation Models. (arXiv:2306.09347v2 [cs.CV] UPDATED)",
    "abstract": "Recent advancements in vision foundation models (VFMs) have opened up new possibilities for versatile and efficient visual perception. In this work, we introduce Seal, a novel framework that harnesses VFMs for segmenting diverse automotive point cloud sequences. Seal exhibits three appealing properties: i) Scalability: VFMs are directly distilled into point clouds, obviating the need for annotations in either 2D or 3D during pretraining. ii) Consistency: Spatial and temporal relationships are enforced at both the camera-to-LiDAR and point-to-segment regularization stages, facilitating cross-modal representation learning. iii) Generalizability: Seal enables knowledge transfer in an off-the-shelf manner to downstream tasks involving diverse point clouds, including those from real/synthetic, low/high-resolution, large/small-scale, and clean/corrupted datasets. Extensive experiments conducted on eleven different point cloud datasets showcase the effectiveness and superiority of Seal. Notab",
    "link": "http://arxiv.org/abs/2306.09347",
    "context": "Title: Segment Any Point Cloud Sequences by Distilling Vision Foundation Models. (arXiv:2306.09347v2 [cs.CV] UPDATED)\nAbstract: Recent advancements in vision foundation models (VFMs) have opened up new possibilities for versatile and efficient visual perception. In this work, we introduce Seal, a novel framework that harnesses VFMs for segmenting diverse automotive point cloud sequences. Seal exhibits three appealing properties: i) Scalability: VFMs are directly distilled into point clouds, obviating the need for annotations in either 2D or 3D during pretraining. ii) Consistency: Spatial and temporal relationships are enforced at both the camera-to-LiDAR and point-to-segment regularization stages, facilitating cross-modal representation learning. iii) Generalizability: Seal enables knowledge transfer in an off-the-shelf manner to downstream tasks involving diverse point clouds, including those from real/synthetic, low/high-resolution, large/small-scale, and clean/corrupted datasets. Extensive experiments conducted on eleven different point cloud datasets showcase the effectiveness and superiority of Seal. Notab",
    "path": "papers/23/06/2306.09347.json",
    "total_tokens": 944,
    "translated_title": "通过提炼视觉基础模型将任意点云序列进行分割",
    "translated_abstract": "最近对视觉基础模型(VFMs)的进展为多样化和高效率的视觉感知开辟了新的可能性。在这项工作中，我们介绍了一种名为Seal的新型框架，利用VFMs对各种汽车点云序列进行分割。Seal具有三个吸引人的特点：i）可伸缩性：VFMs直接被提取到点云中，避免了预训练期间2D或3D注释的需求。ii）一致性：在相机到激光雷达和点到分割规则化阶段都强制执行了空间和时间关系，促进了跨模态表示学习。iii）泛化能力：Seal以即插即用的方式实现知识传递到涉及多样化点云的下游任务中，包括来自真实/合成、低/高分辨率、大/小规模以及干净/破损数据集的点云。在对十一个不同点云数据集进行的大量实验中，展示了Seal的有效性和优越性。",
    "tldr": "本研究引入了一种名为Seal的新型框架，利用视觉基础模型(VFMs)对汽车点云序列进行分割。Seal具有可伸缩性、一致性和泛化能力等优势，并通过大量实验展示了其有效性和优越性。",
    "en_tdlr": "This paper introduces a novel framework called Seal, which utilizes vision foundation models (VFMs) to segment automotive point cloud sequences. Seal exhibits advantages such as scalability, consistency, and generalizability, and its effectiveness and superiority are showcased through extensive experiments."
}