{
    "title": "Learning Multilingual Expressive Speech Representation for Prosody Prediction without Parallel Data. (arXiv:2306.17199v1 [eess.AS])",
    "abstract": "We propose a method for speech-to-speech emotionpreserving translation that operates at the level of discrete speech units. Our approach relies on the use of multilingual emotion embedding that can capture affective information in a language-independent manner. We show that this embedding can be used to predict the pitch and duration of speech units in a target language, allowing us to resynthesize the source speech signal with the same emotional content. We evaluate our approach to English and French speech signals and show that it outperforms a baseline method that does not use emotional information, including when the emotion embedding is extracted from a different language. Even if this preliminary study does not address directly the machine translation issue, our results demonstrate the effectiveness of our approach for cross-lingual emotion preservation in the context of speech resynthesis.",
    "link": "http://arxiv.org/abs/2306.17199",
    "context": "Title: Learning Multilingual Expressive Speech Representation for Prosody Prediction without Parallel Data. (arXiv:2306.17199v1 [eess.AS])\nAbstract: We propose a method for speech-to-speech emotionpreserving translation that operates at the level of discrete speech units. Our approach relies on the use of multilingual emotion embedding that can capture affective information in a language-independent manner. We show that this embedding can be used to predict the pitch and duration of speech units in a target language, allowing us to resynthesize the source speech signal with the same emotional content. We evaluate our approach to English and French speech signals and show that it outperforms a baseline method that does not use emotional information, including when the emotion embedding is extracted from a different language. Even if this preliminary study does not address directly the machine translation issue, our results demonstrate the effectiveness of our approach for cross-lingual emotion preservation in the context of speech resynthesis.",
    "path": "papers/23/06/2306.17199.json",
    "total_tokens": 852,
    "translated_title": "学习多语言表达性语音表示以实现无需平行数据的韵律预测",
    "translated_abstract": "我们提出了一种在离散语音单元级别上进行语音情感保留翻译的方法。我们的方法依赖于使用多语言情感嵌入，可以以一种语言无关的方式捕捉情感信息。我们展示了这种嵌入可以用于预测目标语言中语音单元的音高和持续时间，从而使我们能够用相同的情感内容重新合成源语音信号。我们评估了我们的方法对英语和法语语音信号的效果，并展示了它优于不使用情感信息的基线方法，即使情感嵌入是从不同语言提取的。尽管这个初步研究并未直接解决机器翻译问题，但我们的结果表明了我们的方法在语音重合成的跨语言情感保留方面的有效性。",
    "tldr": "我们提出了一种在离散语音单元级别上进行语音情感保留翻译的方法，该方法使用多语言情感嵌入来预测目标语言中语音单元的音高和持续时间，并成功地以相同的情感内容重新合成源语音信号。"
}