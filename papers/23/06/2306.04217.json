{
    "title": "Effective Neural Topic Modeling with Embedding Clustering Regularization. (arXiv:2306.04217v1 [cs.CL])",
    "abstract": "Topic models have been prevalent for decades with various applications. However, existing topic models commonly suffer from the notorious topic collapsing: discovered topics semantically collapse towards each other, leading to highly repetitive topics, insufficient topic discovery, and damaged model interpretability. In this paper, we propose a new neural topic model, Embedding Clustering Regularization Topic Model (ECRTM). Besides the existing reconstruction error, we propose a novel Embedding Clustering Regularization (ECR), which forces each topic embedding to be the center of a separately aggregated word embedding cluster in the semantic space. This enables each produced topic to contain distinct word semantics, which alleviates topic collapsing. Regularized by ECR, our ECRTM generates diverse and coherent topics together with high-quality topic distributions of documents. Extensive experiments on benchmark datasets demonstrate that ECRTM effectively addresses the topic collapsing ",
    "link": "http://arxiv.org/abs/2306.04217",
    "context": "Title: Effective Neural Topic Modeling with Embedding Clustering Regularization. (arXiv:2306.04217v1 [cs.CL])\nAbstract: Topic models have been prevalent for decades with various applications. However, existing topic models commonly suffer from the notorious topic collapsing: discovered topics semantically collapse towards each other, leading to highly repetitive topics, insufficient topic discovery, and damaged model interpretability. In this paper, we propose a new neural topic model, Embedding Clustering Regularization Topic Model (ECRTM). Besides the existing reconstruction error, we propose a novel Embedding Clustering Regularization (ECR), which forces each topic embedding to be the center of a separately aggregated word embedding cluster in the semantic space. This enables each produced topic to contain distinct word semantics, which alleviates topic collapsing. Regularized by ECR, our ECRTM generates diverse and coherent topics together with high-quality topic distributions of documents. Extensive experiments on benchmark datasets demonstrate that ECRTM effectively addresses the topic collapsing ",
    "path": "papers/23/06/2306.04217.json",
    "total_tokens": 936,
    "translated_title": "带有嵌入聚类正则化的有效神经主题建模",
    "translated_abstract": "主题模型在各种应用中普遍存在，然而现有的主题模型通常存在恶名昭彰的主题崩塌：发现的主题在语义上向彼此折叠，导致高度重复的主题、不足的主题发现和损坏的模型可解释性。本文提出了一种新的神经主题模型，即嵌入聚类正则化主题模型 (ECRTM)。除了现有的重构误差之外，我们提出了一种新的嵌入聚类正则化(ECR)，它强制每个主题嵌入成为语义空间中单独聚合的单词嵌入集群的中心。这使得每个产生的主题都包含不同的单词语义，从而缓解了主题崩塌。在ECR的正则化下，我们的ECRTM生成了多样化和连贯的主题，以及高质量的文档主题分布。在基准数据集上的广泛实验表明，ECRTM有效地解决了主题崩塌问题。",
    "tldr": "ECRTM模型通过引入嵌入聚类正则化（ECR）来解决主题崩塌问题，使得每个产生的主题都包含不同的单词语义，从而生成多样化和连贯的主题以及高质量的文档主题分布。",
    "en_tdlr": "The ECRTM model effectively addresses the issue of topic collapsing by introducing Embedding Clustering Regularization (ECR), which ensures each produced topic contains distinct word semantics, resulting in diverse and coherent topics and high-quality topic distributions of documents."
}