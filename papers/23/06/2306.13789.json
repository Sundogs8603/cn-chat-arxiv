{
    "title": "Deconstructing Classifiers: Towards A Data Reconstruction Attack Against Text Classification Models. (arXiv:2306.13789v1 [cs.CL])",
    "abstract": "Natural language processing (NLP) models have become increasingly popular in real-world applications, such as text classification. However, they are vulnerable to privacy attacks, including data reconstruction attacks that aim to extract the data used to train the model. Most previous studies on data reconstruction attacks have focused on LLM, while classification models were assumed to be more secure. In this work, we propose a new targeted data reconstruction attack called the Mix And Match attack, which takes advantage of the fact that most classification models are based on LLM. The Mix And Match attack uses the base model of the target model to generate candidate tokens and then prunes them using the classification head. We extensively demonstrate the effectiveness of the attack using both random and organic canaries. This work highlights the importance of considering the privacy risks associated with data reconstruction attacks in classification models and offers insights into po",
    "link": "http://arxiv.org/abs/2306.13789",
    "context": "Title: Deconstructing Classifiers: Towards A Data Reconstruction Attack Against Text Classification Models. (arXiv:2306.13789v1 [cs.CL])\nAbstract: Natural language processing (NLP) models have become increasingly popular in real-world applications, such as text classification. However, they are vulnerable to privacy attacks, including data reconstruction attacks that aim to extract the data used to train the model. Most previous studies on data reconstruction attacks have focused on LLM, while classification models were assumed to be more secure. In this work, we propose a new targeted data reconstruction attack called the Mix And Match attack, which takes advantage of the fact that most classification models are based on LLM. The Mix And Match attack uses the base model of the target model to generate candidate tokens and then prunes them using the classification head. We extensively demonstrate the effectiveness of the attack using both random and organic canaries. This work highlights the importance of considering the privacy risks associated with data reconstruction attacks in classification models and offers insights into po",
    "path": "papers/23/06/2306.13789.json",
    "total_tokens": 910,
    "translated_title": "解构分类器：针对文本分类模型的数据重构攻击",
    "translated_abstract": "自然语言处理（NLP）模型越来越受到现实世界应用的青睐，如文本分类。然而，它们对隐私攻击是脆弱的，包括旨在提取用于训练模型的数据的数据重构攻击。大多数以前关于数据重构攻击的研究都集中在LLM上，而分类模型被认为更安全。在这项工作中，我们提出了一种新的有针对性的数据重构攻击称为Mix And Match攻击，它利用了大多数分类模型基于LLM的事实。Mix And Match攻击使用目标模型的基础模型生成候选令牌，然后使用分类头修剪它们。我们广泛展示了攻击的有效性，使用了随机与有机的金丝雀。这项工作突出了在分类模型中考虑与数据重构攻击相关的隐私风险的重要性，并提供了有关如何提高模型的隐私保护的见解。",
    "tldr": "本文提出了一种针对文本分类模型的数据重构攻击，称为Mix And Match攻击，该攻击利用了分类模型基于LLM的特点，该攻击已被证明在随机和有机测试数据集上是有效的。"
}