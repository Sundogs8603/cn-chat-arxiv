{
    "title": "3D-Speaker: A Large-Scale Multi-Device, Multi-Distance, and Multi-Dialect Corpus for Speech Representation Disentanglement. (arXiv:2306.15354v1 [cs.CL])",
    "abstract": "Disentangling uncorrelated information in speech utterances is a crucial research topic within speech community. Different speech-related tasks focus on extracting distinct speech representations while minimizing the affects of other uncorrelated information. We present a large-scale speech corpus to facilitate the research of speech representation disentanglement. 3D-Speaker contains over 10,000 speakers, each of whom are simultaneously recorded by multiple Devices, locating at different Distances, and some speakers are speaking multiple Dialects. The controlled combinations of multi-dimensional audio data yield a matrix of a diverse blend of speech representation entanglement, thereby motivating intriguing methods to untangle them. The multi-domain nature of 3D-Speaker also makes it a suitable resource to evaluate large universal speech models and experiment methods of out-of-domain learning and self-supervised learning. https://3dspeaker.github.io/",
    "link": "http://arxiv.org/abs/2306.15354",
    "context": "Title: 3D-Speaker: A Large-Scale Multi-Device, Multi-Distance, and Multi-Dialect Corpus for Speech Representation Disentanglement. (arXiv:2306.15354v1 [cs.CL])\nAbstract: Disentangling uncorrelated information in speech utterances is a crucial research topic within speech community. Different speech-related tasks focus on extracting distinct speech representations while minimizing the affects of other uncorrelated information. We present a large-scale speech corpus to facilitate the research of speech representation disentanglement. 3D-Speaker contains over 10,000 speakers, each of whom are simultaneously recorded by multiple Devices, locating at different Distances, and some speakers are speaking multiple Dialects. The controlled combinations of multi-dimensional audio data yield a matrix of a diverse blend of speech representation entanglement, thereby motivating intriguing methods to untangle them. The multi-domain nature of 3D-Speaker also makes it a suitable resource to evaluate large universal speech models and experiment methods of out-of-domain learning and self-supervised learning. https://3dspeaker.github.io/",
    "path": "papers/23/06/2306.15354.json",
    "total_tokens": 903,
    "translated_title": "3D-Speaker：用于语音表示解缠的大规模多设备、多距离和多方言语料库",
    "translated_abstract": "在语音社区中，分离语音话语中的不相关信息是一个关键的研究课题。不同的语音相关任务专注于提取不同的语音表示，同时最小化其他不相关信息的影响。我们提出了一个大规模的语音语料库，以促进语音表示解缠的研究。3D-Speaker包含超过10,000个说话人，每个说话人同时由多个设备录制，在不同的距离上，并且一些说话人会讲多种方言。多维音频数据的受控组合产生了一个多样的混合语音表示纠缠矩阵，从而激发出解开它们的有趣方法。3D-Speaker的多领域性质还使其成为评估大型通用语音模型和实验域外学习和自监督学习方法的合适资源。",
    "tldr": "3D-Speaker是一个大规模的多设备、多距离和多方言语音语料库，用于研究语音表示解缠。它包含了10,000多个说话人的数据，可以用来评估大型通用语音模型和探索域外学习和自监督学习方法。",
    "en_tdlr": "3D-Speaker is a large-scale multi-device, multi-distance, and multi-dialect speech corpus for researching speech representation disentanglement. It contains data from over 10,000 speakers and can be used to evaluate large universal speech models and explore methods of out-of-domain learning and self-supervised learning."
}