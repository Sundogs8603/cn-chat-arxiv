{
    "title": "Re-Benchmarking Pool-Based Active Learning for Binary Classification. (arXiv:2306.08954v2 [cs.LG] UPDATED)",
    "abstract": "Active learning is a paradigm that significantly enhances the performance of machine learning models when acquiring labeled data is expensive. While several benchmarks exist for evaluating active learning strategies, their findings exhibit some misalignment. This discrepancy motivates us to develop a transparent and reproducible benchmark for the community. Our efforts result in an open-sourced implementation (https://github.com/ariapoy/active-learning-benchmark) that is reliable and extensible for future research. By conducting thorough re-benchmarking experiments, we have not only rectified misconfigurations in existing benchmark but also shed light on the under-explored issue of model compatibility, which directly causes the observed discrepancy. Resolving the discrepancy reassures that the uncertainty sampling strategy of active learning remains an effective and preferred choice for most datasets. Our experience highlights the importance of dedicating research efforts towards re-be",
    "link": "http://arxiv.org/abs/2306.08954",
    "context": "Title: Re-Benchmarking Pool-Based Active Learning for Binary Classification. (arXiv:2306.08954v2 [cs.LG] UPDATED)\nAbstract: Active learning is a paradigm that significantly enhances the performance of machine learning models when acquiring labeled data is expensive. While several benchmarks exist for evaluating active learning strategies, their findings exhibit some misalignment. This discrepancy motivates us to develop a transparent and reproducible benchmark for the community. Our efforts result in an open-sourced implementation (https://github.com/ariapoy/active-learning-benchmark) that is reliable and extensible for future research. By conducting thorough re-benchmarking experiments, we have not only rectified misconfigurations in existing benchmark but also shed light on the under-explored issue of model compatibility, which directly causes the observed discrepancy. Resolving the discrepancy reassures that the uncertainty sampling strategy of active learning remains an effective and preferred choice for most datasets. Our experience highlights the importance of dedicating research efforts towards re-be",
    "path": "papers/23/06/2306.08954.json",
    "total_tokens": 855,
    "translated_title": "重新基准化面向二分类的基于池的主动学习",
    "translated_abstract": "主动学习是一种显著提升机器学习模型性能的范式，当获取标记数据代价昂贵时特别有用。尽管存在多个用于评估主动学习策略的基准测试，但它们的发现存在一定的不一致性。这种差异激发我们为社区开发一个透明且可复现的基准测试。我们的努力结果是一个可靠且可扩展用于未来研究的开源实现（https://github.com/ariapoy/active-learning-benchmark）。通过进行彻底的重新基准化实验，我们不仅纠正了现有基准测试中的误配置问题，还揭示了模型兼容性这个未被充分探索的问题，这直接导致了观察到的不一致性。解决这个差异使得不确定性采样策略保持了在大多数数据集上是一个有效且首选的选择。我们的经验强调了将研究努力投入到重新基准化上的重要性。",
    "tldr": "本论文通过重新基准化实验证明了不确定性采样策略仍然是大多数数据集上有效和首选的选择，并揭示了模型兼容性问题的重要性。",
    "en_tdlr": "This paper demonstrates through re-benchmarking experiments that uncertainty sampling strategy remains effective and preferred on most datasets, while highlighting the importance of model compatibility."
}