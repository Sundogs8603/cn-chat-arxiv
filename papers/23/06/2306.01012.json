{
    "title": "Graph-Level Embedding for Time-Evolving Graphs. (arXiv:2306.01012v1 [cs.LG])",
    "abstract": "Graph representation learning (also known as network embedding) has been extensively researched with varying levels of granularity, ranging from nodes to graphs. While most prior work in this area focuses on node-level representation, limited research has been conducted on graph-level embedding, particularly for dynamic or temporal networks. However, learning low-dimensional graph-level representations for dynamic networks is critical for various downstream graph retrieval tasks such as temporal graph similarity ranking, temporal graph isomorphism, and anomaly detection. In this paper, we present a novel method for temporal graph-level embedding that addresses this gap. Our approach involves constructing a multilayer graph and using a modified random walk with temporal backtracking to generate temporal contexts for the graph's nodes. We then train a \"document-level\" language model on these contexts to generate graph-level embeddings. We evaluate our proposed model on five publicly avai",
    "link": "http://arxiv.org/abs/2306.01012",
    "context": "Title: Graph-Level Embedding for Time-Evolving Graphs. (arXiv:2306.01012v1 [cs.LG])\nAbstract: Graph representation learning (also known as network embedding) has been extensively researched with varying levels of granularity, ranging from nodes to graphs. While most prior work in this area focuses on node-level representation, limited research has been conducted on graph-level embedding, particularly for dynamic or temporal networks. However, learning low-dimensional graph-level representations for dynamic networks is critical for various downstream graph retrieval tasks such as temporal graph similarity ranking, temporal graph isomorphism, and anomaly detection. In this paper, we present a novel method for temporal graph-level embedding that addresses this gap. Our approach involves constructing a multilayer graph and using a modified random walk with temporal backtracking to generate temporal contexts for the graph's nodes. We then train a \"document-level\" language model on these contexts to generate graph-level embeddings. We evaluate our proposed model on five publicly avai",
    "path": "papers/23/06/2306.01012.json",
    "total_tokens": 843,
    "translated_title": "时间演化图的图级嵌入",
    "translated_abstract": "图表示学习已经得到广泛的研究，从节点到图的粒度各不相同。虽然在节点级别表示方面的大部分工作都已经被研究，但是对于动态或时态网络的图级嵌入却鲜有研究。然而，在动态网络中学习低维度的图级表示对各种下游图检索任务非常重要，例如时间图相似性排序、时间图同构和异常检测。本文提出了一种新颖的方法来解决这个问题，即建立一个多层图并使用具有时间回溯的修改后随机游走生成节点的时间上下文，然后在这些上下文上训练“文档级”语言模型以生成图级嵌入。我们将所提出的模型在五个公开可用的数据集上进行了评估。",
    "tldr": "本论文提出了一种针对动态网络的图级嵌入方法，并通过生成节点的时间上下文来训练语言模型，以生成低维度的图级表示，对于下游的图形相似性排序、图形同构和异常检测等任务具有重要的意义。",
    "en_tdlr": "This paper proposes a novel method for graph-level embedding for dynamic networks by generating temporal contexts for nodes and training a \"document-level\" language model to produce low-dimensional graph-level representations, which is important for downstream graph retrieval tasks such as temporal graph similarity ranking, temporal graph isomorphism, and anomaly detection."
}