{
    "title": "Towards Robust Aspect-based Sentiment Analysis through Non-counterfactual Augmentations. (arXiv:2306.13971v1 [cs.CL])",
    "abstract": "While state-of-the-art NLP models have demonstrated excellent performance for aspect based sentiment analysis (ABSA), substantial evidence has been presented on their lack of robustness. This is especially manifested as significant degradation in performance when faced with out-of-distribution data. Recent solutions that rely on counterfactually augmented datasets show promising results, but they are inherently limited because of the lack of access to explicit causal structure. In this paper, we present an alternative approach that relies on non-counterfactual data augmentation. Our proposal instead relies on using noisy, cost-efficient data augmentations that preserve semantics associated with the target aspect. Our approach then relies on modelling invariances between different versions of the data to improve robustness. A comprehensive suite of experiments shows that our proposal significantly improves upon strong pre-trained baselines on both standard and robustness-specific datase",
    "link": "http://arxiv.org/abs/2306.13971",
    "context": "Title: Towards Robust Aspect-based Sentiment Analysis through Non-counterfactual Augmentations. (arXiv:2306.13971v1 [cs.CL])\nAbstract: While state-of-the-art NLP models have demonstrated excellent performance for aspect based sentiment analysis (ABSA), substantial evidence has been presented on their lack of robustness. This is especially manifested as significant degradation in performance when faced with out-of-distribution data. Recent solutions that rely on counterfactually augmented datasets show promising results, but they are inherently limited because of the lack of access to explicit causal structure. In this paper, we present an alternative approach that relies on non-counterfactual data augmentation. Our proposal instead relies on using noisy, cost-efficient data augmentations that preserve semantics associated with the target aspect. Our approach then relies on modelling invariances between different versions of the data to improve robustness. A comprehensive suite of experiments shows that our proposal significantly improves upon strong pre-trained baselines on both standard and robustness-specific datase",
    "path": "papers/23/06/2306.13971.json",
    "total_tokens": 964,
    "translated_title": "非反事实增强在强健性方面对基于方面的情感分析的改进",
    "translated_abstract": "尽管最先进的自然语言处理模型在基于方面的情感分析（ABSA）方面表现出色，但有大量证据表明它们缺乏鲁棒性。特别是在面对分布外数据时，其性能显著降低。最近的解决方案依赖于反事实增强数据集展现了良好的结果，但由于无法访问显式的因果结构，它们本质上是有限的。在本文中，我们提出了一种替代方法，该方法依赖于非反事实数据增强。我们的提议依赖于使用带有噪声的，成本效益较高的数据增强来保留与目标方面相关联的语义。然后，我们的方法依赖于对数据的不同版本之间的不变性进行建模，从而提高其鲁棒性。一组全面的实验表明，我们的提议在标准和强度特定数据集上都显著改进了强预训练基线的性能。",
    "tldr": "本研究提出了一种非反事实数据增强的替代方法，该方法使用保留目标方面相关语义的有噪声、成本效益较高的数据增强，通过对数据的不同版本之间的不变性进行建模以提高其鲁棒性，在标准和强度特定数据集上都显著改进了强预训练基线的性能。",
    "en_tdlr": "The paper proposes a non-counterfactual data augmentation approach for aspect-based sentiment analysis, which improves the robustness of pre-trained models by preserving semantics associated with the target aspect through noise and cost-efficient augmentation, and modelling invariances between different versions of data. It outperforms strong pre-trained baselines on both standard and robustness-specific datasets."
}