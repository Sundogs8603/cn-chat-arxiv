{
    "title": "GRAFENNE: Learning on Graphs with Heterogeneous and Dynamic Feature Sets. (arXiv:2306.03447v1 [cs.LG])",
    "abstract": "Graph neural networks (GNNs), in general, are built on the assumption of a static set of features characterizing each node in a graph. This assumption is often violated in practice. Existing methods partly address this issue through feature imputation. However, these techniques (i) assume uniformity of feature set across nodes, (ii) are transductive by nature, and (iii) fail to work when features are added or removed over time. In this work, we address these limitations through a novel GNN framework called GRAFENNE. GRAFENNE performs a novel allotropic transformation on the original graph, wherein the nodes and features are decoupled through a bipartite encoding. Through a carefully chosen message passing framework on the allotropic transformation, we make the model parameter size independent of the number of features and thereby inductive to both unseen nodes and features. We prove that GRAFENNE is at least as expressive as any of the existing message-passing GNNs in terms of Weisfeil",
    "link": "http://arxiv.org/abs/2306.03447",
    "context": "Title: GRAFENNE: Learning on Graphs with Heterogeneous and Dynamic Feature Sets. (arXiv:2306.03447v1 [cs.LG])\nAbstract: Graph neural networks (GNNs), in general, are built on the assumption of a static set of features characterizing each node in a graph. This assumption is often violated in practice. Existing methods partly address this issue through feature imputation. However, these techniques (i) assume uniformity of feature set across nodes, (ii) are transductive by nature, and (iii) fail to work when features are added or removed over time. In this work, we address these limitations through a novel GNN framework called GRAFENNE. GRAFENNE performs a novel allotropic transformation on the original graph, wherein the nodes and features are decoupled through a bipartite encoding. Through a carefully chosen message passing framework on the allotropic transformation, we make the model parameter size independent of the number of features and thereby inductive to both unseen nodes and features. We prove that GRAFENNE is at least as expressive as any of the existing message-passing GNNs in terms of Weisfeil",
    "path": "papers/23/06/2306.03447.json",
    "total_tokens": 1003,
    "translated_title": "GRAFENNE：在具有异质和动态特征集的图上进行学习",
    "translated_abstract": "图神经网络（GNN）通常基于对图中每个节点的静态特征集的假设来构建。然而在实践中这一假设经常被违反，现有方法通过特征插补部分解决了这个问题，但是这些方法存在特征集均一、转移误差、无法适应动态特征等局限。本文提出了一种新的GNN框架GRAFENNE来应对这些限制，通过在原图上进行异构转化，将节点和特征解耦，通过精心设计的信息传递方法使得模型参数大小与特征数量无关，能够适用于未知节点和特征。我们证明了GRAFENNE在Weisfeil方程性能上至少与现有的信息传递GNN一样具有表现力。",
    "tldr": "GRAFENNE是一种新的图神经网络框架，通过在原图上进行异构转化，将节点和特征解耦，解决了现有方法普遍存在的特征静态、转移误差等问题，并且能适用于未知节点和特征。",
    "en_tdlr": "GRAFENNE is a novel GNN framework that decouples nodes and features through an allotropic transformation, making the model parameter size independent of the number of features and thereby addressing the limitations of existing methods, such as feature staticness and transition errors, and also applicable to unknown nodes and features."
}