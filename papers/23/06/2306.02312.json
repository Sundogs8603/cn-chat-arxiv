{
    "title": "(Un)reasonable Allure of Ante-hoc Interpretability for High-stakes Domains: Transparency Is Necessary but Insufficient for Comprehensibility. (arXiv:2306.02312v2 [cs.LG] UPDATED)",
    "abstract": "Ante-hoc interpretability has become the holy grail of explainable artificial intelligence for high-stakes domains such as healthcare; however, this notion is elusive, lacks a widely-accepted definition and depends on the operational context. It can refer to predictive models whose structure adheres to domain-specific constraints, or ones that are inherently transparent. The latter conceptualisation assumes observers who judge this quality, whereas the former presupposes them to have technical and domain expertise (thus alienating other groups of explainees). Additionally, the distinction between ante-hoc interpretability and the less desirable post-hoc explainability, which refers to methods that construct a separate explanatory model, is vague given that transparent predictive models may still require (post-)processing to yield suitable explanatory insights. Ante-hoc interpretability is thus an overloaded concept that comprises a range of implicit properties, which we unpack in this ",
    "link": "http://arxiv.org/abs/2306.02312",
    "context": "Title: (Un)reasonable Allure of Ante-hoc Interpretability for High-stakes Domains: Transparency Is Necessary but Insufficient for Comprehensibility. (arXiv:2306.02312v2 [cs.LG] UPDATED)\nAbstract: Ante-hoc interpretability has become the holy grail of explainable artificial intelligence for high-stakes domains such as healthcare; however, this notion is elusive, lacks a widely-accepted definition and depends on the operational context. It can refer to predictive models whose structure adheres to domain-specific constraints, or ones that are inherently transparent. The latter conceptualisation assumes observers who judge this quality, whereas the former presupposes them to have technical and domain expertise (thus alienating other groups of explainees). Additionally, the distinction between ante-hoc interpretability and the less desirable post-hoc explainability, which refers to methods that construct a separate explanatory model, is vague given that transparent predictive models may still require (post-)processing to yield suitable explanatory insights. Ante-hoc interpretability is thus an overloaded concept that comprises a range of implicit properties, which we unpack in this ",
    "path": "papers/23/06/2306.02312.json",
    "total_tokens": 1032,
    "translated_title": "高风险领域对于前文解释性吸引力的（不）合理吸引力：透明度对于可理解性来说是必要但不足够的。",
    "translated_abstract": "前文解释性已成为可解释的人工智能在高风险领域（如医疗保健）中的追求，然而，这个概念很难捉摸，缺乏广泛接受的定义，并且取决于操作环境。它可以指的是那些结构符合特定领域约束的预测模型，或者是本质上透明的模型。后一种观念假设观察者对此质量进行判断，而前一种观念则假设他们具有技术和领域专业知识（从而使其他解释对象群体感到陌生）。此外，前文解释性与较不理想的后文可解释性之间的区别模糊，后者是指构建一个单独的解释模型的方法，而透明的预测模型仍可能需要（后续）处理才能产生适当的解释性洞见。因此，前文解释性是一个超负荷的概念，它包含一系列隐含的属性，我们将在本文中详细阐述。",
    "tldr": "高风险领域对于前文解释性的追求是重要的，但该概念自身含义模糊不清，取决于操作环境和观察者判断。透明的预测模型可能仍需后续处理才能提供合适的解释性洞见，因此传统的前文解释性概念仍需要进一步明确和探索。",
    "en_tdlr": "The pursuit of ante-hoc interpretability is important for high-stakes domains, but the concept itself is elusive and dependent on operational context and observer judgment. Transparent predictive models may still require post-processing for suitable explanatory insights, highlighting the need for further clarification and exploration of the traditional concept of ante-hoc interpretability."
}