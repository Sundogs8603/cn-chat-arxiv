{
    "title": "Context-Aware Self-Supervised Learning of Whole Slide Images. (arXiv:2306.04763v1 [eess.IV])",
    "abstract": "Presenting whole slide images (WSIs) as graph will enable a more efficient and accurate learning framework for cancer diagnosis. Due to the fact that a single WSI consists of billions of pixels and there is a lack of vast annotated datasets required for computational pathology, the problem of learning from WSIs using typical deep learning approaches such as convolutional neural network (CNN) is challenging. Additionally, WSIs down-sampling may lead to the loss of data that is essential for cancer detection. A novel two-stage learning technique is presented in this work. Since context, such as topological features in the tumor surroundings, may hold important information for cancer grading and diagnosis, a graph representation capturing all dependencies among regions in the WSI is very intuitive. Graph convolutional network (GCN) is deployed to include context from the tumor and adjacent tissues, and self-supervised learning is used to enhance training through unlabeled data. More speci",
    "link": "http://arxiv.org/abs/2306.04763",
    "context": "Title: Context-Aware Self-Supervised Learning of Whole Slide Images. (arXiv:2306.04763v1 [eess.IV])\nAbstract: Presenting whole slide images (WSIs) as graph will enable a more efficient and accurate learning framework for cancer diagnosis. Due to the fact that a single WSI consists of billions of pixels and there is a lack of vast annotated datasets required for computational pathology, the problem of learning from WSIs using typical deep learning approaches such as convolutional neural network (CNN) is challenging. Additionally, WSIs down-sampling may lead to the loss of data that is essential for cancer detection. A novel two-stage learning technique is presented in this work. Since context, such as topological features in the tumor surroundings, may hold important information for cancer grading and diagnosis, a graph representation capturing all dependencies among regions in the WSI is very intuitive. Graph convolutional network (GCN) is deployed to include context from the tumor and adjacent tissues, and self-supervised learning is used to enhance training through unlabeled data. More speci",
    "path": "papers/23/06/2306.04763.json",
    "total_tokens": 979,
    "translated_title": "全切片图像的上下文感知自监督学习",
    "translated_abstract": "把全切片图像 (WSIs) 呈现为图形，将为癌症诊断提供更高效和准确的学习框架。 由于单个WSI由数十亿像素组成，而计算病理学所需的广泛注释的数据集不足，因此使用典型的深度学习方法，如卷积神经网络 (CNN)，从WSIs中学习是具有挑战性的。此外，WSIs下采样可能导致丢失对癌症检测至关重要的数据。 本文提出了一种新的两阶段学习技术。 鉴于上下文（例如瘤周围的拓扑特征）可能持有癌症分级和诊断的重要信息，因此捕捉WSI中所有区域之间的依赖关系的图形表示非常直观。使用图卷积网络(GCN)从肿瘤和相邻组织中捕捉上下文，并使用自我监督学习通过未标记的数据来增强训练。更具体地说，该方法是使用GCN的WSIs上下文感知自监督学习，可实现高效和准确的癌症诊断。",
    "tldr": "本文提出了一种全切片图像使用图卷积网络进行上下文感知自监督学习的新的两阶段学习技术，该技术可提高癌症诊断的效率和准确性。",
    "en_tdlr": "This paper proposes a novel two-stage learning technique for whole slide images (WSIs) using a graph convolutional network (GCN) for context-aware self-supervised learning, which improves the efficiency and accuracy of cancer diagnosis."
}