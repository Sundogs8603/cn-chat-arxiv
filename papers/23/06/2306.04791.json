{
    "title": "XInsight: Revealing Model Insights for GNNs with Flow-based Explanations. (arXiv:2306.04791v1 [cs.LG])",
    "abstract": "Progress in graph neural networks has grown rapidly in recent years, with many new developments in drug discovery, medical diagnosis, and recommender systems. While this progress is significant, many networks are `black boxes' with little understanding of the `what' exactly the network is learning. Many high-stakes applications, such as drug discovery, require human-intelligible explanations from the models so that users can recognize errors and discover new knowledge. Therefore, the development of explainable AI algorithms is essential for us to reap the benefits of AI.  We propose an explainability algorithm for GNNs called eXplainable Insight (XInsight) that generates a distribution of model explanations using GFlowNets. Since GFlowNets generate objects with probabilities proportional to a reward, XInsight can generate a diverse set of explanations, compared to previous methods that only learn the maximum reward sample. We demonstrate XInsight by generating explanations for GNNs tra",
    "link": "http://arxiv.org/abs/2306.04791",
    "context": "Title: XInsight: Revealing Model Insights for GNNs with Flow-based Explanations. (arXiv:2306.04791v1 [cs.LG])\nAbstract: Progress in graph neural networks has grown rapidly in recent years, with many new developments in drug discovery, medical diagnosis, and recommender systems. While this progress is significant, many networks are `black boxes' with little understanding of the `what' exactly the network is learning. Many high-stakes applications, such as drug discovery, require human-intelligible explanations from the models so that users can recognize errors and discover new knowledge. Therefore, the development of explainable AI algorithms is essential for us to reap the benefits of AI.  We propose an explainability algorithm for GNNs called eXplainable Insight (XInsight) that generates a distribution of model explanations using GFlowNets. Since GFlowNets generate objects with probabilities proportional to a reward, XInsight can generate a diverse set of explanations, compared to previous methods that only learn the maximum reward sample. We demonstrate XInsight by generating explanations for GNNs tra",
    "path": "papers/23/06/2306.04791.json",
    "total_tokens": 866,
    "translated_abstract": "近年来，图神经网络的发展迅速，涉及到众多领域，如药物发现、医学诊断和推荐系统。但是，许多网络是“黑盒子”，我们对于网络究竟学到了什么一无所知。对于高风险应用（如药物发现），人类可以理解的解释对于用户发现错误和新知识至关重要。因此，开发可解释的 AI 算法对于我们利用人工智能的益处是至关重要的。我们提出了一种适用于 GNN 的解释算法，名为 eXplainable Insight（XInsight），该算法使用 GFlowNets 生成模型解释的分布。由于 GFlowNets 生成的对象的概率与奖励成正比，与仅学习最大奖励样本的先前方法相比，XInsight 可以生成多样化的解释集。我们通过为 GNN 生成解释展示了 XInsight。",
    "tldr": "XInsight 是一种解释算法，可用于生成模型解释分布，以揭示 GNN 的模型洞见。相比于以前的方法，XInsight 可以生成多样化的解释集。",
    "en_tdlr": "XInsight is an explainability algorithm for generating a distribution of model explanations to reveal the model insights of GNNs. Compared to previous methods, XInsight can generate a diverse set of explanations."
}