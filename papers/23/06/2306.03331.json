{
    "title": "A Robust Likelihood Model for Novelty Detection. (arXiv:2306.03331v1 [cs.CV])",
    "abstract": "Current approaches to novelty or anomaly detection are based on deep neural networks. Despite their effectiveness, neural networks are also vulnerable to imperceptible deformations of the input data. This is a serious issue in critical applications, or when data alterations are generated by an adversarial attack. While this is a known problem that has been studied in recent years for the case of supervised learning, the case of novelty detection has received very limited attention. Indeed, in this latter setting the learning is typically unsupervised because outlier data is not available during training, and new approaches for this case need to be investigated. We propose a new prior that aims at learning a robust likelihood for the novelty test, as a defense against attacks. We also integrate the same prior with a state-of-the-art novelty detection approach. Because of the geometric properties of that approach, the resulting robust training is computationally very efficient. An initia",
    "link": "http://arxiv.org/abs/2306.03331",
    "context": "Title: A Robust Likelihood Model for Novelty Detection. (arXiv:2306.03331v1 [cs.CV])\nAbstract: Current approaches to novelty or anomaly detection are based on deep neural networks. Despite their effectiveness, neural networks are also vulnerable to imperceptible deformations of the input data. This is a serious issue in critical applications, or when data alterations are generated by an adversarial attack. While this is a known problem that has been studied in recent years for the case of supervised learning, the case of novelty detection has received very limited attention. Indeed, in this latter setting the learning is typically unsupervised because outlier data is not available during training, and new approaches for this case need to be investigated. We propose a new prior that aims at learning a robust likelihood for the novelty test, as a defense against attacks. We also integrate the same prior with a state-of-the-art novelty detection approach. Because of the geometric properties of that approach, the resulting robust training is computationally very efficient. An initia",
    "path": "papers/23/06/2306.03331.json",
    "total_tokens": 807,
    "translated_title": "一种鲁棒性高的新颖性检测似然模型",
    "translated_abstract": "当前的新颖性或异常检测方法基于深度神经网络。然而，尽管它们很有效，神经网络也容易受到输入数据微小变形的影响。这在关键应用或数据被对抗性攻击改变的情况下是一个严重问题。目前有一些针对监督学习的解决方案，但是在新颖性检测中接受的关注很有限。我们提出了一种新的先验，旨在学习一个鲁棒的似然度，以防御攻击。我们还将相同的先验与一种先进的新颖性检测方法结合使用。由于该方法的几何特性，所得到的鲁棒性训练非常有效。初步的理论分析突显了我们方法的潜在优势，随后得到了实验结果的确认。",
    "tldr": "提出了一种鲁棒性高的新颖性检测似然模型，以防御攻击，并取得了优秀的实验结果。",
    "en_tdlr": "A robust likelihood model for novelty detection is proposed to defend against attacks and achieve excellent experimental results."
}