{
    "title": "Machine Learning needs its own Randomness Standard: Randomised Smoothing and PRNG-based attacks. (arXiv:2306.14043v1 [cs.LG])",
    "abstract": "Randomness supports many critical functions in the field of machine learning (ML) including optimisation, data selection, privacy, and security. ML systems outsource the task of generating or harvesting randomness to the compiler, the cloud service provider or elsewhere in the toolchain. Yet there is a long history of attackers exploiting poor randomness, or even creating it -- as when the NSA put backdoors in random number generators to break cryptography. In this paper we consider whether attackers can compromise an ML system using only the randomness on which they commonly rely. We focus our effort on Randomised Smoothing, a popular approach to train certifiably robust models, and to certify specific input datapoints of an arbitrary model. We choose Randomised Smoothing since it is used for both security and safety -- to counteract adversarial examples and quantify uncertainty respectively. Under the hood, it relies on sampling Gaussian noise to explore the volume around a data poin",
    "link": "http://arxiv.org/abs/2306.14043",
    "context": "Title: Machine Learning needs its own Randomness Standard: Randomised Smoothing and PRNG-based attacks. (arXiv:2306.14043v1 [cs.LG])\nAbstract: Randomness supports many critical functions in the field of machine learning (ML) including optimisation, data selection, privacy, and security. ML systems outsource the task of generating or harvesting randomness to the compiler, the cloud service provider or elsewhere in the toolchain. Yet there is a long history of attackers exploiting poor randomness, or even creating it -- as when the NSA put backdoors in random number generators to break cryptography. In this paper we consider whether attackers can compromise an ML system using only the randomness on which they commonly rely. We focus our effort on Randomised Smoothing, a popular approach to train certifiably robust models, and to certify specific input datapoints of an arbitrary model. We choose Randomised Smoothing since it is used for both security and safety -- to counteract adversarial examples and quantify uncertainty respectively. Under the hood, it relies on sampling Gaussian noise to explore the volume around a data poin",
    "path": "papers/23/06/2306.14043.json",
    "total_tokens": 951,
    "translated_title": "机器学习需要自己的随机标准：随机平滑和基于PRNG的攻击。",
    "translated_abstract": "随机性支持机器学习中的许多关键功能，包括优化、数据选择、隐私和安全。机器学习系统将生成或收集随机性的任务外包给了编译器、云服务提供商或工具链中的其他地方。但是，攻击者利用不良随机性甚至创建随机性的历史悠久，就像NSA放置后门在随机数生成器中以破解加密一样。本文考虑是否能够仅利用攻击者通常依赖的随机性来危害机器学习系统。我们将重点放在随机平滑上，这是一种流行的方法，用于训练可证明鲁棒性的模型，并为任意模型的特定输入数据点提供认证。我们选择随机平滑是因为它用于安全和安全（用于对抗对抗性示例和量化不确定性，分别）。在幕后，它依赖于采样高斯噪声来探索围绕数据点的体积。",
    "tldr": "本文研究了机器学习中随机性可被攻击者利用的问题，主要关注流行的随机平滑方法。该方法用于训练可证明鲁棒性的模型和量化不确定性，但其随机性可能导致系统被攻击。",
    "en_tdlr": "This paper studies the vulnerability of machine learning systems to attacks that exploit poor randomness, focusing on the popular Randomised Smoothing approach. Despite being used for training certifiably robust models and quantifying uncertainty, the randomness in this method may lead to security issues if exploited by attackers."
}