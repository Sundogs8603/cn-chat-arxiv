{
    "title": "Optimizer's Information Criterion: Dissecting and Correcting Bias in Data-Driven Optimization. (arXiv:2306.10081v2 [cs.LG] UPDATED)",
    "abstract": "In data-driven optimization, the sample performance of the obtained decision typically incurs an optimistic bias against the true performance, a phenomenon commonly known as the Optimizer's Curse and intimately related to overfitting in machine learning. Common techniques to correct this bias, such as cross-validation, require repeatedly solving additional optimization problems and are therefore computationally expensive. We develop a general bias correction approach, building on what we call Optimizer's Information Criterion (OIC), that directly approximates the first-order bias and does not require solving any additional optimization problems. Our OIC generalizes the celebrated Akaike Information Criterion to evaluate the objective performance in data-driven optimization, which crucially involves not only model fitting but also its interplay with the downstream optimization. As such it can be used for decision selection instead of only model selection. We apply our approach to a rang",
    "link": "http://arxiv.org/abs/2306.10081",
    "context": "Title: Optimizer's Information Criterion: Dissecting and Correcting Bias in Data-Driven Optimization. (arXiv:2306.10081v2 [cs.LG] UPDATED)\nAbstract: In data-driven optimization, the sample performance of the obtained decision typically incurs an optimistic bias against the true performance, a phenomenon commonly known as the Optimizer's Curse and intimately related to overfitting in machine learning. Common techniques to correct this bias, such as cross-validation, require repeatedly solving additional optimization problems and are therefore computationally expensive. We develop a general bias correction approach, building on what we call Optimizer's Information Criterion (OIC), that directly approximates the first-order bias and does not require solving any additional optimization problems. Our OIC generalizes the celebrated Akaike Information Criterion to evaluate the objective performance in data-driven optimization, which crucially involves not only model fitting but also its interplay with the downstream optimization. As such it can be used for decision selection instead of only model selection. We apply our approach to a rang",
    "path": "papers/23/06/2306.10081.json",
    "total_tokens": 940,
    "translated_title": "优化器的信息准则：剖析和纠正数据驱动优化中的偏差",
    "translated_abstract": "在数据驱动的优化中，所得决策的样本表现通常存在着对真实表现的乐观偏差，这种现象通常被称为优化器的诅咒，与机器学习中的过拟合密切相关。传统的纠正这种偏差的技术，如交叉验证，需要反复解决额外的优化问题，因此计算代价很高。我们开发了一种通用的偏差校正方法，建立在我们称之为优化器的信息准则（OIC）的基础上，直接近似一阶偏差，不需要解决任何额外的优化问题。我们的OIC将著名的赤池信息准则推广到数据驱动优化中，关键是评估客观表现，不仅涉及模型拟合，还涉及其与下游优化的相互作用。因此，它可以用于决策选择而不仅仅是模型选择。我们将我们的方法应用于一系列问题的数据驱动优化。",
    "tldr": "这项研究提出了一个称为优化器的信息准则(OIC)的通用偏差校正方法，帮助解决数据驱动优化中的乐观偏差问题。该方法直接近似一阶偏差，并且不需要解决额外的优化问题，是在决策选择方面的一个创新。",
    "en_tdlr": "This research presents a general bias correction approach called Optimizer's Information Criterion (OIC) to address the optimistic bias in data-driven optimization. The OIC approximates the first-order bias directly and does not require solving additional optimization problems, making it an innovative solution in decision selection."
}