{
    "title": "Reconstructing Human Expressiveness in Piano Performances with a Transformer Network. (arXiv:2306.06040v1 [cs.SD])",
    "abstract": "Capturing intricate and subtle variations in human expressiveness in music performance using computational approaches is challenging. In this paper, we propose a novel approach for reconstructing human expressiveness in piano performance with a multi-layer bi-directional Transformer encoder. To address the needs for large amounts of accurately captured and score-aligned performance data in training neural networks, we use transcribed scores obtained from an existing transcription model to train our model. We integrate pianist identities to control the sampling process and explore the ability of our system to model variations in expressiveness for different pianists. The system is evaluated through statistical analysis of generated expressive performances and a listening test. Overall, the results suggest that our method achieves state-of-the-art in generating human-like piano performances from transcribed scores, while fully and consistently reconstructing human expressiveness poses fu",
    "link": "http://arxiv.org/abs/2306.06040",
    "context": "Title: Reconstructing Human Expressiveness in Piano Performances with a Transformer Network. (arXiv:2306.06040v1 [cs.SD])\nAbstract: Capturing intricate and subtle variations in human expressiveness in music performance using computational approaches is challenging. In this paper, we propose a novel approach for reconstructing human expressiveness in piano performance with a multi-layer bi-directional Transformer encoder. To address the needs for large amounts of accurately captured and score-aligned performance data in training neural networks, we use transcribed scores obtained from an existing transcription model to train our model. We integrate pianist identities to control the sampling process and explore the ability of our system to model variations in expressiveness for different pianists. The system is evaluated through statistical analysis of generated expressive performances and a listening test. Overall, the results suggest that our method achieves state-of-the-art in generating human-like piano performances from transcribed scores, while fully and consistently reconstructing human expressiveness poses fu",
    "path": "papers/23/06/2306.06040.json",
    "total_tokens": 874,
    "translated_title": "利用Transformer网络重建钢琴演奏中人类表现力",
    "translated_abstract": "利用计算方法捕捉人类音乐演奏中复杂微妙的表现力变化是一项具有挑战性的任务。本文提出了一种新颖的方法，利用多层双向Transformer编码器重建钢琴演奏中的人类表现力。为了解决训练神经网络需要大量准确捕捉和得分对齐的演奏数据的需求，我们使用从现有转录模型获取的转录乐谱来训练我们的模型。我们整合了钢琴家身份以控制采样过程，并探讨了我们的系统模拟不同钢琴家表现力变化的能力。通过生成的表现力演奏的统计分析和听力测试对系统进行评估。总体而言，结果表明我们的方法在从转录的乐谱中生成类人钢琴演奏方面达到了最先进的水平，同时充分和一致地重建了人类表现力。",
    "tldr": "本文提出了一种利用Transformer网络来重建钢琴演奏中人类表现力的方法，使用转录乐谱来训练模型，整合钢琴家身份以控制采样过程，并成功生成了高度类人的钢琴表演。"
}