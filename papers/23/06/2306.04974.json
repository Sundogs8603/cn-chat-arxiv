{
    "title": "Conservative Prediction via Data-Driven Confidence Minimization. (arXiv:2306.04974v1 [cs.LG])",
    "abstract": "Errors of machine learning models are costly, especially in safety-critical domains such as healthcare, where such mistakes can prevent the deployment of machine learning altogether. In these settings, conservative models -- models which can defer to human judgment when they are likely to make an error -- may offer a solution. However, detecting unusual or difficult examples is notably challenging, as it is impossible to anticipate all potential inputs at test time. To address this issue, prior work has proposed to minimize the model's confidence on an auxiliary pseudo-OOD dataset. We theoretically analyze the effect of confidence minimization and show that the choice of auxiliary dataset is critical. Specifically, if the auxiliary dataset includes samples from the OOD region of interest, confidence minimization provably separates ID and OOD inputs by predictive confidence. Taking inspiration from this result, we present data-driven confidence minimization (DCM), which minimizes confid",
    "link": "http://arxiv.org/abs/2306.04974",
    "context": "Title: Conservative Prediction via Data-Driven Confidence Minimization. (arXiv:2306.04974v1 [cs.LG])\nAbstract: Errors of machine learning models are costly, especially in safety-critical domains such as healthcare, where such mistakes can prevent the deployment of machine learning altogether. In these settings, conservative models -- models which can defer to human judgment when they are likely to make an error -- may offer a solution. However, detecting unusual or difficult examples is notably challenging, as it is impossible to anticipate all potential inputs at test time. To address this issue, prior work has proposed to minimize the model's confidence on an auxiliary pseudo-OOD dataset. We theoretically analyze the effect of confidence minimization and show that the choice of auxiliary dataset is critical. Specifically, if the auxiliary dataset includes samples from the OOD region of interest, confidence minimization provably separates ID and OOD inputs by predictive confidence. Taking inspiration from this result, we present data-driven confidence minimization (DCM), which minimizes confid",
    "path": "papers/23/06/2306.04974.json",
    "total_tokens": 939,
    "translated_title": "基于数据驱动置信度最小化的保守预测",
    "translated_abstract": "机器学习模型的错误代价很高，特别是在诸如医疗保健等安全关键领域，这种错误可能会阻止机器学习的部署。在这些情况下，具有保守性的模型——当它们可能出现错误时可以推迟到人类判断——可能会提供解决方案。然而，检测异常或复杂示例明显具有挑战性，因为无法预测所有可能的测试输入。为了解决这个问题，先前的工作提出了在辅助伪OOD数据集上最小化模型置信度的方法。我们在理论上分析了置信度最小化的影响，并表明辅助数据集的选择是关键的。具体而言，如果辅助数据集包括来自感兴趣的OOD区域的样本，置信度最小化可以通过预测置信度可靠地分离ID和OOD输入。受到这一结果的启示，我们提出了基于数据驱动置信度最小化（DCM）的算法。",
    "tldr": "该论文提出了一种可以在处理不常见样本时推迟到人类判断的保守模型方法。该方法使用基于数据驱动置信度最小化（DCM）的算法，在辅助数据集中选择感兴趣的OOD（Out-of-Distribution）区域的样本，进而实现可靠地分离ID（In-Distribution）和OOD输入。",
    "en_tdlr": "This paper proposes a conservative model approach that can defer to human judgment when dealing with uncommon samples. The method uses a data-driven confidence minimization (DCM) algorithm that selects samples from the Out-of-Distribution (OOD) region of interest in the auxiliary dataset to reliably separate In-Distribution (ID) and OOD inputs."
}