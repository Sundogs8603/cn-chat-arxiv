{
    "title": "Improving Visual Prompt Tuning for Self-supervised Vision Transformers. (arXiv:2306.05067v1 [cs.LG])",
    "abstract": "Visual Prompt Tuning (VPT) is an effective tuning method for adapting pretrained Vision Transformers (ViTs) to downstream tasks. It leverages extra learnable tokens, known as prompts, which steer the frozen pretrained ViTs. Although VPT has demonstrated its applicability with supervised vision transformers, it often underperforms with self-supervised ones. Through empirical observations, we deduce that the effectiveness of VPT hinges largely on the ViT blocks with which the prompt tokens interact. Specifically, VPT shows improved performance on image classification tasks for MAE and MoCo v3 when the prompt tokens are inserted into later blocks rather than the first block. These observations suggest that there exists an optimal location of blocks for the insertion of prompt tokens. Unfortunately, identifying the optimal blocks for prompts within each self-supervised ViT for diverse future scenarios is a costly process. To mitigate this problem, we propose a simple yet effective method t",
    "link": "http://arxiv.org/abs/2306.05067",
    "context": "Title: Improving Visual Prompt Tuning for Self-supervised Vision Transformers. (arXiv:2306.05067v1 [cs.LG])\nAbstract: Visual Prompt Tuning (VPT) is an effective tuning method for adapting pretrained Vision Transformers (ViTs) to downstream tasks. It leverages extra learnable tokens, known as prompts, which steer the frozen pretrained ViTs. Although VPT has demonstrated its applicability with supervised vision transformers, it often underperforms with self-supervised ones. Through empirical observations, we deduce that the effectiveness of VPT hinges largely on the ViT blocks with which the prompt tokens interact. Specifically, VPT shows improved performance on image classification tasks for MAE and MoCo v3 when the prompt tokens are inserted into later blocks rather than the first block. These observations suggest that there exists an optimal location of blocks for the insertion of prompt tokens. Unfortunately, identifying the optimal blocks for prompts within each self-supervised ViT for diverse future scenarios is a costly process. To mitigate this problem, we propose a simple yet effective method t",
    "path": "papers/23/06/2306.05067.json",
    "total_tokens": 916,
    "translated_title": "提高自监督视觉Transformer可视化提示调整的方法",
    "translated_abstract": "视觉提示调整（VPT）是一种适用于下游任务的预训练视觉Transformer（ViTs）的有效调整方法。它利用额外的可学习记号，称为提示，来指导冻结的预训练ViTs。虽然VPT在受监督的视觉Transformer中显示了其适用性，但在自监督情况下常常表现不佳。通过实证观察，我们推断VPT的有效性在很大程度上取决于提示记号与ViT图块相互作用的方式。具体来说，当提示记号插入后续图块而不是第一个图块时，VPT在MAE和MoCo v3图像分类任务中显示出了改进的性能。这些观察表明，存在适用于插入提示记号的最佳块的位置。不幸的是，确定每个自监督ViT内用于不同未来场景的提示的最佳块是一个昂贵的过程。为了缓解这个问题，我们提出了一种简单而有效的方法。",
    "tldr": "本文研究了自监督视觉Transformer中视觉提示调整方法的提升，并确定了提示记号插入后续图块而非第一个图块的最佳位置。提出的方法能有效地减少确定最佳提示记号块位置的成本。",
    "en_tdlr": "This paper investigates the improvement of Visual Prompt Tuning (VPT) for self-supervised vision transformers and identifies the optimal location of prompt token insertion. A simple yet effective method is proposed to reduce the cost of determining the optimal block for prompt insertion in each self-supervised ViT for diverse future scenarios."
}