{
    "title": "A Cover Time Study of a non-Markovian Algorithm. (arXiv:2306.04902v1 [cs.DS])",
    "abstract": "Given a traversal algorithm, cover time is the expected number of steps needed to visit all nodes in a given graph. A smaller cover time means a higher exploration efficiency of traversal algorithm. Although random walk algorithms have been studied extensively in the existing literature, there has been no cover time result for any non-Markovian method. In this work, we stand on a theoretical perspective and show that the negative feedback strategy (a count-based exploration method) is better than the naive random walk search. In particular, the former strategy can locally improve the search efficiency for an arbitrary graph. It also achieves smaller cover times for special but important graphs, including clique graphs, tree graphs, etc. Moreover, we make connections between our results and reinforcement learning literature to give new insights on why classical UCB and MCTS algorithms are so useful. Various numerical results corroborate our theoretical findings.",
    "link": "http://arxiv.org/abs/2306.04902",
    "context": "Title: A Cover Time Study of a non-Markovian Algorithm. (arXiv:2306.04902v1 [cs.DS])\nAbstract: Given a traversal algorithm, cover time is the expected number of steps needed to visit all nodes in a given graph. A smaller cover time means a higher exploration efficiency of traversal algorithm. Although random walk algorithms have been studied extensively in the existing literature, there has been no cover time result for any non-Markovian method. In this work, we stand on a theoretical perspective and show that the negative feedback strategy (a count-based exploration method) is better than the naive random walk search. In particular, the former strategy can locally improve the search efficiency for an arbitrary graph. It also achieves smaller cover times for special but important graphs, including clique graphs, tree graphs, etc. Moreover, we make connections between our results and reinforcement learning literature to give new insights on why classical UCB and MCTS algorithms are so useful. Various numerical results corroborate our theoretical findings.",
    "path": "papers/23/06/2306.04902.json",
    "total_tokens": 865,
    "translated_title": "一种非马尔可夫算法的覆盖时间研究",
    "translated_abstract": "在给定的图中，覆盖时间是访问所有节点所需的期望步数。更小的覆盖时间意味着遍历算法的探索效率更高。尽管对于随机游走算法已有大量研究，但对于任何非马尔可夫方法尚无覆盖时间结果。本研究从理论角度出发，表明负反馈策略（一种基于计数的探索方法）比朴素的随机漫步搜索策略更好。特别地，前者可以在任意图中局部提高搜索效率。它还可以在特殊但重要的图形中实现更小的覆盖时间，包括团簇图和树图等。此外，我们将结果与强化学习文献联系起来，以揭示为什么经典的UCB和MCTS算法如此有用。各种数值结果证实了我们的理论发现。",
    "tldr": "本文研究了一个遍历算法中的覆盖时间问题，通过一种基于计数的负反馈策略，实现在任意图中局部提高搜索效率，并在特殊的图形中实现更小的覆盖时间。"
}