{
    "title": "Theoretical Foundations of Adversarially Robust Learning. (arXiv:2306.07723v1 [cs.LG])",
    "abstract": "Despite extraordinary progress, current machine learning systems have been shown to be brittle against adversarial examples: seemingly innocuous but carefully crafted perturbations of test examples that cause machine learning predictors to misclassify. Can we learn predictors robust to adversarial examples? and how? There has been much empirical interest in this contemporary challenge in machine learning, and in this thesis, we address it from a theoretical perspective.  In this thesis, we explore what robustness properties can we hope to guarantee against adversarial examples and develop an understanding of how to algorithmically guarantee them. We illustrate the need to go beyond traditional approaches and principles such as empirical risk minimization and uniform convergence, and make contributions that can be categorized as follows: (1) introducing problem formulations capturing aspects of emerging practical challenges in robust learning, (2) designing new learning algorithms with ",
    "link": "http://arxiv.org/abs/2306.07723",
    "context": "Title: Theoretical Foundations of Adversarially Robust Learning. (arXiv:2306.07723v1 [cs.LG])\nAbstract: Despite extraordinary progress, current machine learning systems have been shown to be brittle against adversarial examples: seemingly innocuous but carefully crafted perturbations of test examples that cause machine learning predictors to misclassify. Can we learn predictors robust to adversarial examples? and how? There has been much empirical interest in this contemporary challenge in machine learning, and in this thesis, we address it from a theoretical perspective.  In this thesis, we explore what robustness properties can we hope to guarantee against adversarial examples and develop an understanding of how to algorithmically guarantee them. We illustrate the need to go beyond traditional approaches and principles such as empirical risk minimization and uniform convergence, and make contributions that can be categorized as follows: (1) introducing problem formulations capturing aspects of emerging practical challenges in robust learning, (2) designing new learning algorithms with ",
    "path": "papers/23/06/2306.07723.json",
    "total_tokens": 731,
    "translated_title": "对抗鲁棒性学习的理论基础",
    "translated_abstract": "尽管机器学习系统取得了非凡的进展，但已经证明它们对于对抗样本是脆弱的：对测试样本进行细微但有意的扰动，就会导致机器学习模型错误分类。本论文旨在从理论角度解决这一具有挑战性的问题，探讨我们可以希望保证什么样的鲁棒性性质，并提供可实现算法保证这些性质的方法。",
    "tldr": "本论文从理论角度探讨了对抗鲁棒性学习的问题，提出了新的学习算法，并分析了其鲁棒性和泛化性能。",
    "en_tdlr": "This paper tackles the challenge of adversarial robustness learning from a theoretical perspective by introducing new learning algorithms with provable robustness guarantees and analyzing their generalization properties."
}