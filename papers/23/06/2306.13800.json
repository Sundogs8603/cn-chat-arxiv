{
    "title": "A First Order Meta Stackelberg Method for Robust Federated Learning. (arXiv:2306.13800v1 [cs.LG])",
    "abstract": "Previous research has shown that federated learning (FL) systems are exposed to an array of security risks. Despite the proposal of several defensive strategies, they tend to be non-adaptive and specific to certain types of attacks, rendering them ineffective against unpredictable or adaptive threats. This work models adversarial federated learning as a Bayesian Stackelberg Markov game (BSMG) to capture the defender's incomplete information of various attack types. We propose meta-Stackelberg learning (meta-SL), a provably efficient meta-learning algorithm, to solve the equilibrium strategy in BSMG, leading to an adaptable FL defense. We demonstrate that meta-SL converges to the first-order $\\varepsilon$-equilibrium point in $O(\\varepsilon^{-2})$ gradient iterations, with $O(\\varepsilon^{-4})$ samples needed per iteration, matching the state of the art. Empirical evidence indicates that our meta-Stackelberg framework performs exceptionally well against potent model poisoning and backdo",
    "link": "http://arxiv.org/abs/2306.13800",
    "context": "Title: A First Order Meta Stackelberg Method for Robust Federated Learning. (arXiv:2306.13800v1 [cs.LG])\nAbstract: Previous research has shown that federated learning (FL) systems are exposed to an array of security risks. Despite the proposal of several defensive strategies, they tend to be non-adaptive and specific to certain types of attacks, rendering them ineffective against unpredictable or adaptive threats. This work models adversarial federated learning as a Bayesian Stackelberg Markov game (BSMG) to capture the defender's incomplete information of various attack types. We propose meta-Stackelberg learning (meta-SL), a provably efficient meta-learning algorithm, to solve the equilibrium strategy in BSMG, leading to an adaptable FL defense. We demonstrate that meta-SL converges to the first-order $\\varepsilon$-equilibrium point in $O(\\varepsilon^{-2})$ gradient iterations, with $O(\\varepsilon^{-4})$ samples needed per iteration, matching the state of the art. Empirical evidence indicates that our meta-Stackelberg framework performs exceptionally well against potent model poisoning and backdo",
    "path": "papers/23/06/2306.13800.json",
    "total_tokens": 997,
    "translated_title": "一种鲁棒联邦学习的一阶Meta Stackelberg方法",
    "translated_abstract": "先前的研究表明，联邦学习系统面临着各种安全风险。尽管提出了多种防御策略，但它们往往是非自适应的，只针对某些类型的攻击，从而无法抵御不可预测或自适应的威胁。本研究将对抗性联邦学习建模为贝叶斯Stackelberg马尔科夫博弈(BSMG)以捕捉防御者对各种攻击类型的不完全信息。我们提出了元Stackelberg学习(meta-SL)，这是一种可证明有效的元学习算法，用于解决BSMG中的均衡策略，从而实现自适应的FL防御。我们证明，meta-SL在$O(\\varepsilon^{-2})$梯度迭代中收敛于一阶$\\varepsilon$-均衡点，每次迭代需要$O(\\varepsilon^{-4})$个样本，与现有技术相匹配。经验证据表明，我们的元Stackelberg框架在强大的模型污染和后门攻击方面表现出色。",
    "tldr": "本研究提出了一种鲁棒的联邦学习防御方法，使用元Stackelberg学习算法解决贝叶斯Stackelberg马尔科夫博弈，实现自适应防御，与现有技术相匹配并在实验中表现出色。",
    "en_tdlr": "This paper proposes a robust defense method for federated learning using the meta-Stackelberg learning algorithm to solve Bayesian Stackelberg Markov game and achieve adaptive defense against various attacks. The proposed method matches the state of the art and demonstrates excellent performance against model poisoning and backdoor attacks."
}