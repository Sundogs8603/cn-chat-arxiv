{
    "title": "(Amplified) Banded Matrix Factorization: A unified approach to private training. (arXiv:2306.08153v1 [cs.LG])",
    "abstract": "Matrix factorization (MF) mechanisms for differential privacy (DP) have substantially improved the state-of-the-art in privacy-utility-computation tradeoffs for ML applications in a variety of scenarios, but in both the centralized and federated settings there remain instances where either MF cannot be easily applied, or other algorithms provide better tradeoffs (typically, as $\\epsilon$ becomes small).  In this work, we show how MF can subsume prior state-of-the-art algorithms in both federated and centralized training settings, across all privacy budgets. The key technique throughout is the construction of MF mechanisms with banded matrices. For cross-device federated learning (FL), this enables multiple-participations with a relaxed device participation schema compatible with practical FL infrastructure (as demonstrated by a production deployment). In the centralized setting, we prove that banded matrices enjoy the same privacy amplification results as for the ubiquitous DP-SGD algo",
    "link": "http://arxiv.org/abs/2306.08153",
    "context": "Title: (Amplified) Banded Matrix Factorization: A unified approach to private training. (arXiv:2306.08153v1 [cs.LG])\nAbstract: Matrix factorization (MF) mechanisms for differential privacy (DP) have substantially improved the state-of-the-art in privacy-utility-computation tradeoffs for ML applications in a variety of scenarios, but in both the centralized and federated settings there remain instances where either MF cannot be easily applied, or other algorithms provide better tradeoffs (typically, as $\\epsilon$ becomes small).  In this work, we show how MF can subsume prior state-of-the-art algorithms in both federated and centralized training settings, across all privacy budgets. The key technique throughout is the construction of MF mechanisms with banded matrices. For cross-device federated learning (FL), this enables multiple-participations with a relaxed device participation schema compatible with practical FL infrastructure (as demonstrated by a production deployment). In the centralized setting, we prove that banded matrices enjoy the same privacy amplification results as for the ubiquitous DP-SGD algo",
    "path": "papers/23/06/2306.08153.json",
    "total_tokens": 997,
    "translated_title": "（扩大）带状矩阵分解：一种统一的隐私训练方法。",
    "translated_abstract": "差分隐私（DP）下的矩阵分解（MF）机制在许多场景下显著改进了隐私-效用-计算折衷的最新技术。但是在分散和联合设置中，仍存在MF不易适用的实例，或者其他算法提供更好的折衷（通常随着 ε 变小）。在这项工作中，我们展示了如何使用带状矩阵构建MF机制，在所有隐私预算中将先前最先进的算法纳入分散和联合训练设置中。关键技术是带状矩阵的构造。对于跨设备联合学习（FL），这使得多个设备可以使用一种放松的设备参与模式，与实际的FL基础设施相容（如产品部署所示）。在集中式设置中，我们证明带状矩阵具有与 ubiquitous DP-SGD algorithm 相同的隐私放大结果。",
    "tldr": "本文提出了利用带状矩阵构建的矩阵分解机制，该机制能够在所有隐私预算中将先前最先进的算法纳入分散和联合训练设置中。对于跨设备联合学习，这意味着可以使用一种放松的设备参与模式，与实际的FL基础设施相容。在集中式设置中，带状矩阵具有与 ubiquitous DP-SGD algorithm 相同的隐私放大结果。",
    "en_tdlr": "This paper proposes a matrix factorization mechanism using banded matrices, which can subsume prior state-of-the-art algorithms in both federated and centralized training settings, across all privacy budgets. It enables relaxed device participation schema for cross-device federated learning and enjoys the same privacy amplification results as the ubiquitous DP-SGD algorithm in centralized setting."
}