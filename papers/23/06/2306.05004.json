{
    "title": "VIFS: An End-to-End Variational Inference for Foley Sound Synthesis. (arXiv:2306.05004v1 [eess.AS])",
    "abstract": "The goal of DCASE 2023 Challenge Task 7 is to generate various sound clips for Foley sound synthesis (FSS) by \"category-to-sound\" approach. \"Category\" is expressed by a single index while corresponding \"sound\" covers diverse and different sound examples. To generate diverse sounds for a given category, we adopt VITS, a text-to-speech (TTS) model with variational inference. In addition, we apply various techniques from speech synthesis including PhaseAug and Avocodo. Different from TTS models which generate short pronunciation from phonemes and speaker identity, the category-to-sound problem requires generating diverse sounds just from a category index. To compensate for the difference while maintaining consistency within each audio clip, we heavily modified the prior encoder to enhance consistency with posterior latent variables. This introduced additional Gaussian on the prior encoder which promotes variance within the category. With these modifications, we propose VIFS, variational i",
    "link": "http://arxiv.org/abs/2306.05004",
    "context": "Title: VIFS: An End-to-End Variational Inference for Foley Sound Synthesis. (arXiv:2306.05004v1 [eess.AS])\nAbstract: The goal of DCASE 2023 Challenge Task 7 is to generate various sound clips for Foley sound synthesis (FSS) by \"category-to-sound\" approach. \"Category\" is expressed by a single index while corresponding \"sound\" covers diverse and different sound examples. To generate diverse sounds for a given category, we adopt VITS, a text-to-speech (TTS) model with variational inference. In addition, we apply various techniques from speech synthesis including PhaseAug and Avocodo. Different from TTS models which generate short pronunciation from phonemes and speaker identity, the category-to-sound problem requires generating diverse sounds just from a category index. To compensate for the difference while maintaining consistency within each audio clip, we heavily modified the prior encoder to enhance consistency with posterior latent variables. This introduced additional Gaussian on the prior encoder which promotes variance within the category. With these modifications, we propose VIFS, variational i",
    "path": "papers/23/06/2306.05004.json",
    "total_tokens": 872,
    "translated_title": "VIFS：一种端到端的变分推理用于Foley音效合成。",
    "translated_abstract": "DCASE 2023挑战任务7的目标是通过“类别到声音”的方法为Foley声音合成（FSS）生成各种声音剪辑。我们采用具有变分推理的文本到语音（TTS）模型VITS来生成给定类别的多样化声音，并应用了来自语音合成的各种技术，包括PhaseAug和Avocado。与TTS模型不同，类别到声音问题需要仅从类别索引生成多样化的声音。为了弥补这种差异，同时保持每个音频剪辑的一致性，我们大幅修改了先前的编码器以增强与后验潜在变量的一致性。这引入了额外的高斯分布，以促进类别内的方差。通过这些修改，我们提出了VIFS，即变分推理的端到端方法用于Foley音效合成。",
    "tldr": "本文提出了一种名为VIFS的端到端变分推理用于Foley音效合成的问题，通过一个“类别到声音”的方法生成多样化声音，并应用各种技术进行改良，包括PhaseAug和Avocado。",
    "en_tdlr": "This paper proposes an end-to-end variational inference method, called VIFS, for Foley sound synthesis. The method generates diverse audio clips using a \"category-to-sound\" approach and applies various speech synthesis techniques, including PhaseAug and Avocado, to enhance consistency within each clip."
}