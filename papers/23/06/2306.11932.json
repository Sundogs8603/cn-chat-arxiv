{
    "title": "Opportunities and Risks of LLMs for Scalable Deliberation with Polis. (arXiv:2306.11932v1 [cs.SI])",
    "abstract": "Polis is a platform that leverages machine intelligence to scale up deliberative processes. In this paper, we explore the opportunities and risks associated with applying Large Language Models (LLMs) towards challenges with facilitating, moderating and summarizing the results of Polis engagements. In particular, we demonstrate with pilot experiments using Anthropic's Claude that LLMs can indeed augment human intelligence to help more efficiently run Polis conversations. In particular, we find that summarization capabilities enable categorically new methods with immense promise to empower the public in collective meaning-making exercises. And notably, LLM context limitations have a significant impact on insight and quality of these results.  However, these opportunities come with risks. We discuss some of these risks, as well as principles and techniques for characterizing and mitigating them, and the implications for other deliberative or political systems that may employ LLMs. Finally",
    "link": "http://arxiv.org/abs/2306.11932",
    "context": "Title: Opportunities and Risks of LLMs for Scalable Deliberation with Polis. (arXiv:2306.11932v1 [cs.SI])\nAbstract: Polis is a platform that leverages machine intelligence to scale up deliberative processes. In this paper, we explore the opportunities and risks associated with applying Large Language Models (LLMs) towards challenges with facilitating, moderating and summarizing the results of Polis engagements. In particular, we demonstrate with pilot experiments using Anthropic's Claude that LLMs can indeed augment human intelligence to help more efficiently run Polis conversations. In particular, we find that summarization capabilities enable categorically new methods with immense promise to empower the public in collective meaning-making exercises. And notably, LLM context limitations have a significant impact on insight and quality of these results.  However, these opportunities come with risks. We discuss some of these risks, as well as principles and techniques for characterizing and mitigating them, and the implications for other deliberative or political systems that may employ LLMs. Finally",
    "path": "papers/23/06/2306.11932.json",
    "total_tokens": 1013,
    "translated_title": "LLMs在Polis可扩展协商中的机会与风险",
    "translated_abstract": "Polis是一个利用机器智能扩大协商过程的平台。本文探讨了将大型语言模型（LLMs）应用于促进、调节和总结Polis参与过程中面临的机会和风险。特别是，通过使用Anthropic的Claude进行试点实验，我们证明LLMs确实可以增强人类智能，帮助更有效地运行Polis对话。我们发现，总结能力使得集体意义形成练习中的公共参与具有巨大的潜力。然而，LLMs的上下文限制对结果的洞见和质量有重要影响。但是，这些机会也伴随着风险。我们讨论了其中一些风险，以及表征和减轻这些风险的原则和技术，以及可能采用LLMs的其他协商或政治系统的影响。最后，我们概述了未来研究的途径，包括开发结合人类和LLM智能的混合方法以实现更好的结果。",
    "tldr": "本文探讨了LLMs在促进、调节和总结Polis可扩展协商中的机会和风险，试验表明总结能力使得公共参与具有巨大潜力，但是LLMs的上下文限制对结果的影响很大。同时，我们讨论了原则和技术来表征和减轻这些风险。",
    "en_tdlr": "This paper explores the opportunities and risks of Large Language Models (LLMs) in facilitating, moderating, and summarizing Polis engagements, with pilot experiments showing immense promise in the summarization capabilities. However, the context limitations of LLMs have a significant impact on the quality of results, and the paper discusses techniques and principles to characterize and mitigate these risks. The paper also outlines potential avenues for future research, including hybrid approaches that combine human and LLM intelligence."
}