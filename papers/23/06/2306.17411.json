{
    "title": "Decentralized Motor Skill Learning for Complex Robotic Systems. (arXiv:2306.17411v1 [cs.RO])",
    "abstract": "Reinforcement learning (RL) has achieved remarkable success in complex robotic systems (eg. quadruped locomotion). In previous works, the RL-based controller was typically implemented as a single neural network with concatenated observation input. However, the corresponding learned policy is highly task-specific. Since all motors are controlled in a centralized way, out-of-distribution local observations can impact global motors through the single coupled neural network policy. In contrast, animals and humans can control their limbs separately. Inspired by this biological phenomenon, we propose a Decentralized motor skill (DEMOS) learning algorithm to automatically discover motor groups that can be decoupled from each other while preserving essential connections and then learn a decentralized motor control policy. Our method improves the robustness and generalization of the policy without sacrificing performance. Experiments on quadruped and humanoid robots demonstrate that the learned",
    "link": "http://arxiv.org/abs/2306.17411",
    "context": "Title: Decentralized Motor Skill Learning for Complex Robotic Systems. (arXiv:2306.17411v1 [cs.RO])\nAbstract: Reinforcement learning (RL) has achieved remarkable success in complex robotic systems (eg. quadruped locomotion). In previous works, the RL-based controller was typically implemented as a single neural network with concatenated observation input. However, the corresponding learned policy is highly task-specific. Since all motors are controlled in a centralized way, out-of-distribution local observations can impact global motors through the single coupled neural network policy. In contrast, animals and humans can control their limbs separately. Inspired by this biological phenomenon, we propose a Decentralized motor skill (DEMOS) learning algorithm to automatically discover motor groups that can be decoupled from each other while preserving essential connections and then learn a decentralized motor control policy. Our method improves the robustness and generalization of the policy without sacrificing performance. Experiments on quadruped and humanoid robots demonstrate that the learned",
    "path": "papers/23/06/2306.17411.json",
    "total_tokens": 882,
    "translated_title": "复杂机器人系统的去中心化运动技能学习",
    "translated_abstract": "强化学习在复杂机器人系统（例如四足动作）中取得了显著的成功。在以前的研究中，基于强化学习的控制器通常被实现为一个具有连接观察输入的单一神经网络。然而，所对应的学习策略高度依赖于特定任务。由于所有电机以集中的方式进行控制，超出分布范围的局部观察可以通过单一耦合的神经网络策略影响全局电机。相反，动物和人类可以分别控制他们的肢体。受到这一生物现象的启发，我们提出了一种名为分散式运动技能（DEMOS）学习算法，自动发现可以相互解耦的电机组，并学习一个去中心化的运动控制策略。我们的方法提高了策略的鲁棒性和泛化能力，同时不牺牲性能。对四足和人形机器人的实验表明，学习到的策略在性能上得到了改进。",
    "tldr": "这项研究提出了一种去中心化运动技能（DEMOS）学习算法，通过分散控制电机组来提高机器人策略的鲁棒性和泛化能力，而不降低性能。"
}