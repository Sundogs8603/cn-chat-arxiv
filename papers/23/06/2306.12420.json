{
    "title": "LMFlow: An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. (arXiv:2306.12420v1 [cs.CL])",
    "abstract": "Large foundation models have demonstrated a great ability to achieve general human-level intelligence far beyond traditional approaches. As the technique keeps attracting attention from the AI community, more and more large foundation models have become publically available. However, most of those models exhibit a major deficiency in specialized-task applications, where the step of finetuning is still required for obtaining satisfactory performance. As the number of available models and specialized tasks keeps growing, the job of general finetuning becomes highly nontrivial. In this paper, we take the first step to address this issue. We introduce an extensible and lightweight toolkit, LMFlow, which aims to simplify the finetuning and inference of general large foundation models. LMFlow offers a complete finetuning workflow for a large foundation model to support personalized training with limited computing resources. Furthermore, it supports continuous pretraining, instruction tuning,",
    "link": "http://arxiv.org/abs/2306.12420",
    "context": "Title: LMFlow: An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. (arXiv:2306.12420v1 [cs.CL])\nAbstract: Large foundation models have demonstrated a great ability to achieve general human-level intelligence far beyond traditional approaches. As the technique keeps attracting attention from the AI community, more and more large foundation models have become publically available. However, most of those models exhibit a major deficiency in specialized-task applications, where the step of finetuning is still required for obtaining satisfactory performance. As the number of available models and specialized tasks keeps growing, the job of general finetuning becomes highly nontrivial. In this paper, we take the first step to address this issue. We introduce an extensible and lightweight toolkit, LMFlow, which aims to simplify the finetuning and inference of general large foundation models. LMFlow offers a complete finetuning workflow for a large foundation model to support personalized training with limited computing resources. Furthermore, it supports continuous pretraining, instruction tuning,",
    "path": "papers/23/06/2306.12420.json",
    "total_tokens": 865,
    "translated_title": "LMFlow：用于大型基础模型微调和推理的可扩展工具包",
    "translated_abstract": "大型基础模型展现出比传统方法更接近人类智能的能力，已经引起了人工智能界的广泛关注。然而，大部分模型在专业任务应用中仍然表现出明显的缺陷，需要微调才能获得令人满意的性能。随着可用模型和专业任务数量的增加，通用微调的工作变得非常棘手。在本文中，我们采取了第一步解决这个问题。我们介绍了一个可扩展和轻量级的工具包LMFlow，旨在简化大型基础模型的微调和推理。LMFlow为大型基础模型提供了完整的微调工作流程，支持在有限的计算资源下进行个性化训练。此外，它还支持连续预训练、指令微调等功能，以更好地适应不同的专业任务。",
    "tldr": "LMFlow是一个可扩展和轻量级的工具包，为大型基础模型提供完整的微调工作流程，以支持在有限的计算资源下进行个性化训练，并支持连续预训练和指令微调以适应不同的专业任务。",
    "en_tdlr": "LMFlow is an extensible and lightweight toolkit that offers a complete finetuning workflow for large foundation models. It supports personalized training with limited compute resources and features continuous pretraining and instruction tuning to adapt to different specialized tasks."
}