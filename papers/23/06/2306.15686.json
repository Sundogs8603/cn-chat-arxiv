{
    "title": "Master-ASR: Achieving Multilingual Scalability and Low-Resource Adaptation in ASR with Modular Learning. (arXiv:2306.15686v1 [eess.AS])",
    "abstract": "Despite the impressive performance recently achieved by automatic speech recognition (ASR), we observe two primary challenges that hinder its broader applications: (1) The difficulty of introducing scalability into the model to support more languages with limited training, inference, and storage overhead; (2) The low-resource adaptation ability that enables effective low-resource adaptation while avoiding over-fitting and catastrophic forgetting issues. Inspired by recent findings, we hypothesize that we can address the above challenges with modules widely shared across languages. To this end, we propose an ASR framework, dubbed \\METHODNS, that, \\textit{for the first time}, simultaneously achieves strong multilingual scalability and low-resource adaptation ability thanks to its modularize-then-assemble strategy. Specifically, \\METHOD learns a small set of generalizable sub-modules and adaptively assembles them for different languages to reduce the multilingual overhead and enable effec",
    "link": "http://arxiv.org/abs/2306.15686",
    "context": "Title: Master-ASR: Achieving Multilingual Scalability and Low-Resource Adaptation in ASR with Modular Learning. (arXiv:2306.15686v1 [eess.AS])\nAbstract: Despite the impressive performance recently achieved by automatic speech recognition (ASR), we observe two primary challenges that hinder its broader applications: (1) The difficulty of introducing scalability into the model to support more languages with limited training, inference, and storage overhead; (2) The low-resource adaptation ability that enables effective low-resource adaptation while avoiding over-fitting and catastrophic forgetting issues. Inspired by recent findings, we hypothesize that we can address the above challenges with modules widely shared across languages. To this end, we propose an ASR framework, dubbed \\METHODNS, that, \\textit{for the first time}, simultaneously achieves strong multilingual scalability and low-resource adaptation ability thanks to its modularize-then-assemble strategy. Specifically, \\METHOD learns a small set of generalizable sub-modules and adaptively assembles them for different languages to reduce the multilingual overhead and enable effec",
    "path": "papers/23/06/2306.15686.json",
    "total_tokens": 935,
    "translated_title": "Master-ASR: 实现ASR的多语言可扩展性和低资源适应性的模块化学习方法",
    "translated_abstract": "尽管自动语音识别(ASR)最近取得了令人印象深刻的性能，但我们观察到两个主要挑战阻碍其更广泛的应用：(1)难以引入可扩展性模型，支持有限的训练、推理和存储开销的更多语言；(2)低资源适应能力，能够在避免过拟合和灾难性遗忘问题的同时实现有效的低资源适应。受到最近的研究结果的启发，我们假设我们可以通过跨语言广泛共享的模块来解决上述挑战。为此，我们提出了一种ASR框架，称为\\METHODNS，\\textit{首次}同时实现了强大的多语言可扩展性和低资源适应能力，这得益于它的模块化即装配策略。具体地，\\METHOD学习了一小组通用的子模块，并自适应地将它们组装到不同的语言中，以降低多语言开销并实现有效的适应性。",
    "tldr": "Master-ASR是一个基于模块化学习的ASR框架，通过共享模块来实现多语言可扩展性和低资源适应能力，解决了ASR面临的可扩展性和低资源适应的挑战。",
    "en_tdlr": "Master-ASR is an ASR framework based on modular learning that addresses the challenges of scalability and low-resource adaptation by sharing modules, achieving multilingual scalability and low-resource adaptation ability in ASR."
}