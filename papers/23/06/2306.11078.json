{
    "title": "Beyond Normal: On the Evaluation of Mutual Information Estimators. (arXiv:2306.11078v1 [stat.ML])",
    "abstract": "Mutual information is a general statistical dependency measure which has found applications in representation learning, causality, domain generalization and computational biology. However, mutual information estimators are typically evaluated on simple families of probability distributions, namely multivariate normal distribution and selected distributions with one-dimensional random variables. In this paper, we show how to construct a diverse family of distributions with known ground-truth mutual information and propose a language-independent benchmarking platform for mutual information estimators. We discuss the general applicability and limitations of classical and neural estimators in settings involving high dimensions, sparse interactions, long-tailed distributions, and high mutual information. Finally, we provide guidelines for practitioners on how to select appropriate estimator adapted to the difficulty of problem considered and issues one needs to consider when applying an est",
    "link": "http://arxiv.org/abs/2306.11078",
    "context": "Title: Beyond Normal: On the Evaluation of Mutual Information Estimators. (arXiv:2306.11078v1 [stat.ML])\nAbstract: Mutual information is a general statistical dependency measure which has found applications in representation learning, causality, domain generalization and computational biology. However, mutual information estimators are typically evaluated on simple families of probability distributions, namely multivariate normal distribution and selected distributions with one-dimensional random variables. In this paper, we show how to construct a diverse family of distributions with known ground-truth mutual information and propose a language-independent benchmarking platform for mutual information estimators. We discuss the general applicability and limitations of classical and neural estimators in settings involving high dimensions, sparse interactions, long-tailed distributions, and high mutual information. Finally, we provide guidelines for practitioners on how to select appropriate estimator adapted to the difficulty of problem considered and issues one needs to consider when applying an est",
    "path": "papers/23/06/2306.11078.json",
    "total_tokens": 828,
    "translated_title": "超越正常：关于互信息估计的评估",
    "translated_abstract": "互信息是一种常用的统计相关度量，已在表示学习、因果性、域泛化和计算生物学等领域得到应用。然而，互信息估计通常只在简单的概率分布族类（即多元正态分布和具有一维随机变量的选择分布）上进行评估。在本文中，我们展示了如何构建具有已知基准互信息的各种分布族，并提出了一种语言无关的互信息估计基准平台。我们讨论了经典和神经网络估计器在涉及高维度、稀疏相互作用、长尾分布和高互信息的情境中的普适性和局限性。最后，我们为从业人员提供了选择适当的估计器以适应所考虑问题难度和应用估计互信息时需要考虑的问题的指南。",
    "tldr": "本文提出了一种语言无关的互信息估计基准平台，并讨论了经典和神经估计器在处理高维数据、长尾分布和高互信息时的普适性和局限性。",
    "en_tdlr": "This paper proposes a language-independent benchmark platform for mutual information estimators and discusses the general applicability and limitations of classical and neural estimators in settings involving high dimensions, sparse interactions, long-tailed distributions, and high mutual information."
}