{
    "title": "Optimal Transport Model Distributional Robustness. (arXiv:2306.04178v1 [cs.LG])",
    "abstract": "Distributional robustness is a promising framework for training deep learning models that are less vulnerable to adversarial examples and data distribution shifts. Previous works have mainly focused on exploiting distributional robustness in data space. In this work, we explore an optimal transport-based distributional robustness framework on model spaces. Specifically, we examine a model distribution in a Wasserstein ball of a given center model distribution that maximizes the loss. We have developed theories that allow us to learn the optimal robust center model distribution. Interestingly, through our developed theories, we can flexibly incorporate the concept of sharpness awareness into training a single model, ensemble models, and Bayesian Neural Networks by considering specific forms of the center model distribution, such as a Dirac delta distribution over a single model, a uniform distribution over several models, and a general Bayesian Neural Network. Furthermore, we demonstrat",
    "link": "http://arxiv.org/abs/2306.04178",
    "context": "Title: Optimal Transport Model Distributional Robustness. (arXiv:2306.04178v1 [cs.LG])\nAbstract: Distributional robustness is a promising framework for training deep learning models that are less vulnerable to adversarial examples and data distribution shifts. Previous works have mainly focused on exploiting distributional robustness in data space. In this work, we explore an optimal transport-based distributional robustness framework on model spaces. Specifically, we examine a model distribution in a Wasserstein ball of a given center model distribution that maximizes the loss. We have developed theories that allow us to learn the optimal robust center model distribution. Interestingly, through our developed theories, we can flexibly incorporate the concept of sharpness awareness into training a single model, ensemble models, and Bayesian Neural Networks by considering specific forms of the center model distribution, such as a Dirac delta distribution over a single model, a uniform distribution over several models, and a general Bayesian Neural Network. Furthermore, we demonstrat",
    "path": "papers/23/06/2306.04178.json",
    "total_tokens": 990,
    "translated_title": "优化输运模型的分布鲁棒性",
    "translated_abstract": "分布鲁棒性是一种有希望的框架，用于训练深度学习模型，使其对抗性例子和数据分布变化的影响更小。先前的工作主要集中在利用数据空间的分布鲁棒性上。在本文中，我们探讨了一种基于最优输运的模型空间分布鲁棒性框架。具体而言，我们研究了在给定中心模型分布的Wasserstein球中的模型分布，该模型分布最大化了损失。我们开发出了理论，允许我们学习最佳的鲁棒中心模型分布。有趣的是，通过我们开发的理论，我们可以通过考虑特定形式的中心模型分布（如单个模型上的Dirac delta分布，多个模型上的均匀分布和一般的贝叶斯神经网络）来灵活地将锐度感知的概念纳入到单个模型、集成模型和贝叶斯神经网络的训练中。此外，我们证明了所提出的框架显著提高了在各种基准数据集上的深度学习模型的分布鲁棒性。",
    "tldr": "本文提出了一种优化输运模型的分布鲁棒性框架，能够显著提高深度学习模型的鲁棒性，可灵活地将锐度感知纳入到单个模型、集成模型和贝叶斯神经网络的训练中。",
    "en_tdlr": "This paper proposes an optimal transport-based distributional robustness framework on model spaces, which significantly improves the distributional robustness of deep learning models and can flexibly incorporate the concept of sharpness awareness into training a single model, ensemble models, and Bayesian Neural Networks."
}