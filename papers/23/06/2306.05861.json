{
    "title": "Efficient Encoder-Decoder and Dual-Path Conformer for Comprehensive Feature Learning in Speech Enhancement. (arXiv:2306.05861v1 [eess.AS])",
    "abstract": "Current speech enhancement (SE) research has largely neglected channel attention and spatial attention, and encoder-decoder architecture-based networks have not adequately considered how to provide efficient inputs to the intermediate enhancement layer. To address these issues, this paper proposes a time-frequency (T-F) domain SE network (DPCFCS-Net) that incorporates improved densely connected blocks, dual-path modules, convolution-augmented transformers (conformers), channel attention, and spatial attention. Compared with previous models, our proposed model has a more efficient encoder-decoder and can learn comprehensive features. Experimental results on the VCTK+DEMAND dataset demonstrate that our method outperforms existing techniques in SE performance. Furthermore, the improved densely connected block and two dimensions attention module developed in this work are highly adaptable and easily integrated into existing networks.",
    "link": "http://arxiv.org/abs/2306.05861",
    "context": "Title: Efficient Encoder-Decoder and Dual-Path Conformer for Comprehensive Feature Learning in Speech Enhancement. (arXiv:2306.05861v1 [eess.AS])\nAbstract: Current speech enhancement (SE) research has largely neglected channel attention and spatial attention, and encoder-decoder architecture-based networks have not adequately considered how to provide efficient inputs to the intermediate enhancement layer. To address these issues, this paper proposes a time-frequency (T-F) domain SE network (DPCFCS-Net) that incorporates improved densely connected blocks, dual-path modules, convolution-augmented transformers (conformers), channel attention, and spatial attention. Compared with previous models, our proposed model has a more efficient encoder-decoder and can learn comprehensive features. Experimental results on the VCTK+DEMAND dataset demonstrate that our method outperforms existing techniques in SE performance. Furthermore, the improved densely connected block and two dimensions attention module developed in this work are highly adaptable and easily integrated into existing networks.",
    "path": "papers/23/06/2306.05861.json",
    "total_tokens": 942,
    "translated_title": "高效编码-解码和双通路Conformer用于语音增强中的综合特征学习",
    "translated_abstract": "当前的语音增强(SE)研究很大程度上忽略了通道关注和空间关注，基于编码器-解码器的网络也没有充分考虑如何为中间的增强层提供高效的输入。为了解决这些问题，本文提出了一个时频(T-F)领域的SE网络(DPCFCS-Net)，它包含了改进的密集连接块、双通路模块、卷积增强变压器(conformers)、通道关注和空间关注。与之前的模型相比，我们提出的模型具有更高效的编码器-解码器并能够学习综合特征。在VCTK+DEMAND数据集上的实验结果表明，我们的方法在SE性能方面优于现有技术。此外，本研究发展的改进的密集连接块和二维关注模块非常适应，易于集成到现有网络中。",
    "tldr": "本文提出了一个具有高效编码-解码和全面特征学习能力的语音增强模型，该模型使用改进的密集连接块、双通路模块、卷积增强变压器、通道关注和空间关注等技术。实验结果表明，在VCTK+DEMAND数据集上，该模型比现有技术表现更好。",
    "en_tdlr": "This paper proposes a speech enhancement model with efficient encoder-decoder and comprehensive feature learning using improved densely connected blocks, dual-path modules, convolution-augmented transformers, channel attention, and spatial attention. Experimental results on the VCTK+DEMAND dataset show that the proposed model outperforms existing techniques in SE performance. Improved densely connected blocks and two dimensions attention module developed in this work are highly adaptable and easily integrated into existing networks."
}