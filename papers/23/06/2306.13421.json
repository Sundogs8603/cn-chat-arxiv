{
    "title": "Long-range Language Modeling with Self-retrieval. (arXiv:2306.13421v1 [cs.CL])",
    "abstract": "Retrieval-augmented language models (LMs) have received much attention recently. However, typically the retriever is not trained jointly as a native component of the LM, but added to an already-pretrained LM, which limits the ability of the LM and the retriever to adapt to one another. In this work, we propose the Retrieval-Pretrained Transformer (RPT), an architecture and training procedure for jointly training a retrieval-augmented LM from scratch for the task of modeling long texts. Given a recently generated text chunk in a long document, the LM computes query representations, which are then used to retrieve earlier chunks in the document, located potentially tens of thousands of tokens before. Information from retrieved chunks is fused into the LM representations to predict the next target chunk. We train the retriever component with a semantic objective, where the goal is to retrieve chunks that increase the probability of the next chunk, according to a reference LM. We evaluate ",
    "link": "http://arxiv.org/abs/2306.13421",
    "context": "Title: Long-range Language Modeling with Self-retrieval. (arXiv:2306.13421v1 [cs.CL])\nAbstract: Retrieval-augmented language models (LMs) have received much attention recently. However, typically the retriever is not trained jointly as a native component of the LM, but added to an already-pretrained LM, which limits the ability of the LM and the retriever to adapt to one another. In this work, we propose the Retrieval-Pretrained Transformer (RPT), an architecture and training procedure for jointly training a retrieval-augmented LM from scratch for the task of modeling long texts. Given a recently generated text chunk in a long document, the LM computes query representations, which are then used to retrieve earlier chunks in the document, located potentially tens of thousands of tokens before. Information from retrieved chunks is fused into the LM representations to predict the next target chunk. We train the retriever component with a semantic objective, where the goal is to retrieve chunks that increase the probability of the next chunk, according to a reference LM. We evaluate ",
    "path": "papers/23/06/2306.13421.json",
    "total_tokens": 984,
    "translated_title": "自检索的长文本语言模型",
    "translated_abstract": "近期，基于检索辅助的语言模型受到了广泛关注。但是，通常检索器并不是作为语言模型的本地组件进行联合训练的，而是被添加到已经预训练好的语言模型中，这限制了语言模型和检索器相互适应的能力。在本文中，我们提出了Retrieval-Pretrained Transformer (RPT)，一种从头开始训练检索辅助的语言模型的架构和训练方法，用于模拟长文本。给定一个最近在长文档中生成的文本块，语言模型计算查询表示，然后用它来检索文档中更早的块，这些块可能跨越数万个标记。检索到的块中的信息被融合到语言模型表示中，以预测下一个目标块。我们用一个语义目标来训练检索器组件，该目标的目的是检索增加下一个块概率的块，根据参考语言模型。我们评估了...",
    "tldr": "本论文提出了一种名为Retrieval-Pretrained Transformer的模型，可以从头开始联合训练语言模型和检索器来模拟长文本。模型可以计算文本块的查询表示，并将其用于检索前面的块，从而融合信息以预测下一个目标块。检索器使用一个语义目标进行训练，目标是检索那些增加下一个块概率的块。",
    "en_tdlr": "This paper proposes a model called Retrieval-Pretrained Transformer, which can jointly train a language model and retriever from scratch to model long texts. The model can compute query representations for text chunks and use them to retrieve previous chunks, and then fuse the information to predict the next target chunk. The retriever is trained with a semantic objective of retrieving chunks that increase the probability of the next chunk."
}