{
    "title": "Differentially Private Domain Adaptation with Theoretical Guarantees. (arXiv:2306.08838v1 [cs.LG])",
    "abstract": "In many applications, the labeled data at the learner's disposal is subject to privacy constraints and is relatively limited. To derive a more accurate predictor for the target domain, it is often beneficial to leverage publicly available labeled data from an alternative domain, somewhat close to the target domain. This is the modern problem of supervised domain adaptation from a public source to a private target domain. We present two $(\\epsilon, \\delta)$-differentially private adaptation algorithms for supervised adaptation, for which we make use of a general optimization problem, recently shown to benefit from favorable theoretical learning guarantees. Our first algorithm is designed for regression with linear predictors and shown to solve a convex optimization problem. Our second algorithm is a more general solution for loss functions that may be non-convex but Lipschitz and smooth. While our main objective is a theoretical analysis, we also report the results of several experiment",
    "link": "http://arxiv.org/abs/2306.08838",
    "context": "Title: Differentially Private Domain Adaptation with Theoretical Guarantees. (arXiv:2306.08838v1 [cs.LG])\nAbstract: In many applications, the labeled data at the learner's disposal is subject to privacy constraints and is relatively limited. To derive a more accurate predictor for the target domain, it is often beneficial to leverage publicly available labeled data from an alternative domain, somewhat close to the target domain. This is the modern problem of supervised domain adaptation from a public source to a private target domain. We present two $(\\epsilon, \\delta)$-differentially private adaptation algorithms for supervised adaptation, for which we make use of a general optimization problem, recently shown to benefit from favorable theoretical learning guarantees. Our first algorithm is designed for regression with linear predictors and shown to solve a convex optimization problem. Our second algorithm is a more general solution for loss functions that may be non-convex but Lipschitz and smooth. While our main objective is a theoretical analysis, we also report the results of several experiment",
    "path": "papers/23/06/2306.08838.json",
    "total_tokens": 939,
    "translated_title": "具有理论保障的差分隐私域自适应算法",
    "translated_abstract": "在许多应用中，学习者可用的标记数据受到隐私约束并相对有限。为了为目标领域导出更准确的预测器，通常有利于利用来自与目标领域相近的另一领域的公开标记数据。这是从公共源领域到私有目标领域的现代监督域自适应问题。我们提出了两种 $(\\epsilon, \\delta)$-差分隐私自适应算法，用于监督性自适应。对于其我们使用了一般的优化问题，该优化问题最近被证明具有有利的理论学习保证。我们的第一个算法是为具有线性预测器的回归设计的，并显示为解决凸优化问题。我们的第二个算法是一种更一般的解决方案，用于可能是非凸但Lipschitz和平滑的损失函数。虽然我们的主要目标是进行理论分析，但我们也报告了几个实验的结果。",
    "tldr": "该论文提出了两种具有差分隐私保障的自适应算法，用于在受隐私约束且有限标记数据条件下，从公开源领域到目标领域进行监督域自适应。该算法能够解决一般的优化问题，并具有有利的理论学习保证。",
    "en_tdlr": "This paper proposes two differentially private adaptive algorithms for supervised domain adaptation from a public source to a private target domain, under the constraints of privacy and limited labeled data. The algorithms can solve a general optimization problem with favorable theoretical learning guarantees, including regression with linear predictors and loss functions that may be non-convex but Lipschitz and smooth."
}