{
    "title": "Simple and Fast Group Robustness by Automatic Feature Reweighting. (arXiv:2306.11074v1 [cs.LG])",
    "abstract": "A major challenge to out-of-distribution generalization is reliance on spurious features -- patterns that are predictive of the class label in the training data distribution, but not causally related to the target. Standard methods for reducing the reliance on spurious features typically assume that we know what the spurious feature is, which is rarely true in the real world. Methods that attempt to alleviate this limitation are complex, hard to tune, and lead to a significant computational overhead compared to standard training. In this paper, we propose Automatic Feature Reweighting (AFR), an extremely simple and fast method for updating the model to reduce the reliance on spurious features. AFR retrains the last layer of a standard ERM-trained base model with a weighted loss that emphasizes the examples where the ERM model predicts poorly, automatically upweighting the minority group without group labels. With this simple procedure, we improve upon the best reported results among co",
    "link": "http://arxiv.org/abs/2306.11074",
    "context": "Title: Simple and Fast Group Robustness by Automatic Feature Reweighting. (arXiv:2306.11074v1 [cs.LG])\nAbstract: A major challenge to out-of-distribution generalization is reliance on spurious features -- patterns that are predictive of the class label in the training data distribution, but not causally related to the target. Standard methods for reducing the reliance on spurious features typically assume that we know what the spurious feature is, which is rarely true in the real world. Methods that attempt to alleviate this limitation are complex, hard to tune, and lead to a significant computational overhead compared to standard training. In this paper, we propose Automatic Feature Reweighting (AFR), an extremely simple and fast method for updating the model to reduce the reliance on spurious features. AFR retrains the last layer of a standard ERM-trained base model with a weighted loss that emphasizes the examples where the ERM model predicts poorly, automatically upweighting the minority group without group labels. With this simple procedure, we improve upon the best reported results among co",
    "path": "papers/23/06/2306.11074.json",
    "total_tokens": 950,
    "translated_title": "自动特征重新加权实现简单快速的组鲁棒性",
    "translated_abstract": "对于越界泛化的主要挑战是依赖于虚假特征--它们是在训练数据分布中预测类标签的模式，但与目标不具有因果关系。减少对虚假特征的依赖的标准方法通常假设我们知道虚假特征是什么，在现实世界中很少是真实的。试图减轻这种限制的方法复杂，难以调整，与标准训练相比具有显著的计算开销。在本文中，我们提出了一种称为自动特征重新加权（AFR）的极其简单快速的方法来更新模型以减少对虚假特征的依赖。AFR使用加权损失重新训练标准ERM训练的基本模型的最后一层，强调ERM模型预测不佳的示例，自动提高少数群体的权重，而无需组标签。通过这个简单的过程，我们改进了最佳报告结果中的许多群体鲁棒性的性能。",
    "tldr": "本文提出了一个自动特征重新加权（AFR）的简单快速方法，使用加权损失重新训练ERC模型的最后一层来减少对虚假特征的依赖，从而提高了多个群体的鲁棒性表现。",
    "en_tdlr": "This paper proposes a simple and fast method called Automatic Feature Reweighting (AFR) that uses a weighted loss to retrain the last layer of a standard ERC-trained model, emphasizing examples where the ERC model predicts poorly to automatically upweight minority groups without group labels, improving robustness performance for multiple groups."
}