{
    "title": "Are Neurons Actually Collapsed? On the Fine-Grained Structure in Neural Representations. (arXiv:2306.17105v1 [cs.LG])",
    "abstract": "Recent work has observed an intriguing ''Neural Collapse'' phenomenon in well-trained neural networks, where the last-layer representations of training samples with the same label collapse into each other. This appears to suggest that the last-layer representations are completely determined by the labels, and do not depend on the intrinsic structure of input distribution. We provide evidence that this is not a complete description, and that the apparent collapse hides important fine-grained structure in the representations. Specifically, even when representations apparently collapse, the small amount of remaining variation can still faithfully and accurately captures the intrinsic structure of input distribution. As an example, if we train on CIFAR-10 using only 5 coarse-grained labels (by combining two classes into one super-class) until convergence, we can reconstruct the original 10-class labels from the learned representations via unsupervised clustering. The reconstructed labels a",
    "link": "http://arxiv.org/abs/2306.17105",
    "context": "Title: Are Neurons Actually Collapsed? On the Fine-Grained Structure in Neural Representations. (arXiv:2306.17105v1 [cs.LG])\nAbstract: Recent work has observed an intriguing ''Neural Collapse'' phenomenon in well-trained neural networks, where the last-layer representations of training samples with the same label collapse into each other. This appears to suggest that the last-layer representations are completely determined by the labels, and do not depend on the intrinsic structure of input distribution. We provide evidence that this is not a complete description, and that the apparent collapse hides important fine-grained structure in the representations. Specifically, even when representations apparently collapse, the small amount of remaining variation can still faithfully and accurately captures the intrinsic structure of input distribution. As an example, if we train on CIFAR-10 using only 5 coarse-grained labels (by combining two classes into one super-class) until convergence, we can reconstruct the original 10-class labels from the learned representations via unsupervised clustering. The reconstructed labels a",
    "path": "papers/23/06/2306.17105.json",
    "total_tokens": 878,
    "translated_title": "神经元实际上是折叠的吗？关于神经表示中的细粒度结构的研究",
    "translated_abstract": "最近的研究观察到在训练充分的神经网络中出现了一个有趣的“神经折叠”现象，即具有相同标签的训练样本的最后一层表示互相折叠在一起。这似乎表明最后一层的表示完全由标签决定，并且不依赖于输入分布的内在结构。我们提供证据表明这不是一个完全的描述，表面上的折叠隐藏了表示中的重要的细粒度结构。具体而言，即使表示表面上折叠在一起，仍然存在一小部分剩余的变异性能够忠实而准确地捕捉到输入分布的内在结构。例如，如果我们只使用5个粗粒度标签（将两个类别组合成一个超类）对CIFAR-10进行训练直到收敛，我们可以通过无监督聚类从学习到的表示中重构出原始的10个类别标签。",
    "tldr": "这篇论文研究了神经网络中的“神经折叠”现象，提出了表面上折叠的表示实际上仍隐藏有重要的细粒度结构，并通过实验证据证明了这一点。",
    "en_tdlr": "This paper investigates the \"Neural Collapse\" phenomenon in neural networks and argues that collapsed representations still contain important fine-grained structure, which is supported by empirical evidence."
}