{
    "title": "Understanding Unfairness via Training Concept Influence. (arXiv:2306.17828v1 [cs.LG])",
    "abstract": "Knowing the causes of a model's unfairness helps practitioners better understand their data and algorithms. This is an important yet relatively unexplored task. We look into this problem through the lens of the training data - one of the major sources of unfairness. We ask the following questions: how would a model's fairness performance change if, in its training data, some samples (1) were collected from a different (e.g. demographic) group, (2) were labeled differently, or (3) some features were changed? In other words, we quantify the fairness influence of training samples by counterfactually intervening and changing samples based on predefined concepts, i.e. data attributes such as features (X), labels (Y), or sensitive attributes (A). To calculate a training sample's influence on the model's unfairness w.r.t a concept, we first generate counterfactual samples based on the concept, i.e. the counterfactual versions of the sample if the concept were changed. We then calculate the re",
    "link": "http://arxiv.org/abs/2306.17828",
    "context": "Title: Understanding Unfairness via Training Concept Influence. (arXiv:2306.17828v1 [cs.LG])\nAbstract: Knowing the causes of a model's unfairness helps practitioners better understand their data and algorithms. This is an important yet relatively unexplored task. We look into this problem through the lens of the training data - one of the major sources of unfairness. We ask the following questions: how would a model's fairness performance change if, in its training data, some samples (1) were collected from a different (e.g. demographic) group, (2) were labeled differently, or (3) some features were changed? In other words, we quantify the fairness influence of training samples by counterfactually intervening and changing samples based on predefined concepts, i.e. data attributes such as features (X), labels (Y), or sensitive attributes (A). To calculate a training sample's influence on the model's unfairness w.r.t a concept, we first generate counterfactual samples based on the concept, i.e. the counterfactual versions of the sample if the concept were changed. We then calculate the re",
    "path": "papers/23/06/2306.17828.json",
    "total_tokens": 852,
    "translated_title": "通过训练概念影响理解不公平性",
    "translated_abstract": "了解模型不公平性的原因有助于从业人员更好地理解他们的数据和算法。我们通过培训数据这一主要不公平来源的视角来研究这个问题。我们提出以下问题：如果在训练数据中有些样本（1）来自不同的（例如人口统计学）群体，（2）标记方式不同，或者（3）某些特征发生了变化，那么模型的公平性表现会发生怎样的变化？换句话说，我们通过反事实地对基于预定义概念的样本进行干预和改变，量化训练样本对模型的不公平性的影响。计算训练样本对模型相对于概念的不公平性的影响时，我们首先基于概念生成反事实版本的样本，即如果概念发生变化，样本的反事实版本。然后我们计算重新",
    "tldr": "通过观察训练数据的作用，研究模型不公平性的来源和影响，并通过改变样本的属性来计算训练样本对模型的不公平性的影响。"
}