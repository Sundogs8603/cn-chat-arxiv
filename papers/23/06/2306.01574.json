{
    "title": "Probabilistic Concept Bottleneck Models. (arXiv:2306.01574v1 [cs.LG])",
    "abstract": "Interpretable models are designed to make decisions in a human-interpretable manner. Representatively, Concept Bottleneck Models (CBM) follow a two-step process of concept prediction and class prediction based on the predicted concepts. CBM provides explanations with high-level concepts derived from concept predictions; thus, reliable concept predictions are important for trustworthiness. In this study, we address the ambiguity issue that can harm reliability. While the existence of a concept can often be ambiguous in the data, CBM predicts concepts deterministically without considering this ambiguity. To provide a reliable interpretation against this ambiguity, we propose Probabilistic Concept Bottleneck Models (ProbCBM). By leveraging probabilistic concept embeddings, ProbCBM models uncertainty in concept prediction and provides explanations based on the concept and its corresponding uncertainty. This uncertainty enhances the reliability of the explanations. Furthermore, as class unc",
    "link": "http://arxiv.org/abs/2306.01574",
    "context": "Title: Probabilistic Concept Bottleneck Models. (arXiv:2306.01574v1 [cs.LG])\nAbstract: Interpretable models are designed to make decisions in a human-interpretable manner. Representatively, Concept Bottleneck Models (CBM) follow a two-step process of concept prediction and class prediction based on the predicted concepts. CBM provides explanations with high-level concepts derived from concept predictions; thus, reliable concept predictions are important for trustworthiness. In this study, we address the ambiguity issue that can harm reliability. While the existence of a concept can often be ambiguous in the data, CBM predicts concepts deterministically without considering this ambiguity. To provide a reliable interpretation against this ambiguity, we propose Probabilistic Concept Bottleneck Models (ProbCBM). By leveraging probabilistic concept embeddings, ProbCBM models uncertainty in concept prediction and provides explanations based on the concept and its corresponding uncertainty. This uncertainty enhances the reliability of the explanations. Furthermore, as class unc",
    "path": "papers/23/06/2306.01574.json",
    "total_tokens": 952,
    "translated_title": "概率概念瓶颈模型",
    "translated_abstract": "可解释的模型旨在以可读的方式做出决策。其中，概念瓶颈模型（CBM）根据预测的概念进行概念预测和类预测两步骤。CBM使用从概念预测中得出的高级概念提供解释；因此，可靠的概念预测对于可信度非常重要。在本研究中，我们解决了可能损害可靠性的模糊性问题。虽然数据中概念的存在往往是模糊的，但CBM在不考虑此模糊性的情况下使用确定性方法预测概念。为了针对这种模糊性提供可靠的解释，我们提出了概率概念瓶颈模型（ProbCBM）。通过利用概率概念嵌入，ProbCBM对概念预测中的不确定性进行建模，并基于概念及其相应的不确定性提供解释。这种不确定性提高了解释的可靠性。此外，由于类别预测的概率性质，ProbCBM还提供了类别预测的不确定度估计。",
    "tldr": "本文提出了概率概念瓶颈模型（ProbCBM），通过建立概率概念嵌入来解决数据中概念存在模糊性的问题，提高了CBM模型的可靠性及解释的可信度。"
}