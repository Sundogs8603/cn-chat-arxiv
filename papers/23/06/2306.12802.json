{
    "title": "Otter-Knowledge: benchmarks of multimodal knowledge graph representation learning from different sources for drug discovery. (arXiv:2306.12802v1 [cs.LG])",
    "abstract": "Recent research in representation learning utilizes large databases of proteins or molecules to acquire knowledge of drug and protein structures through unsupervised learning techniques. These pre-trained representations have proven to significantly enhance the accuracy of subsequent tasks, such as predicting the affinity between drugs and target proteins. In this study, we demonstrate that by incorporating knowledge graphs from diverse sources and modalities into the sequences or SMILES representation, we can further enrich the representation and achieve state-of-the-art results on established benchmark datasets. We provide preprocessed and integrated data obtained from 7 public sources, which encompass over 30M triples. Additionally, we make available the pre-trained models based on this data, along with the reported outcomes of their performance on three widely-used benchmark datasets for drug-target binding affinity prediction found in the Therapeutic Data Commons (TDC) benchmarks.",
    "link": "http://arxiv.org/abs/2306.12802",
    "context": "Title: Otter-Knowledge: benchmarks of multimodal knowledge graph representation learning from different sources for drug discovery. (arXiv:2306.12802v1 [cs.LG])\nAbstract: Recent research in representation learning utilizes large databases of proteins or molecules to acquire knowledge of drug and protein structures through unsupervised learning techniques. These pre-trained representations have proven to significantly enhance the accuracy of subsequent tasks, such as predicting the affinity between drugs and target proteins. In this study, we demonstrate that by incorporating knowledge graphs from diverse sources and modalities into the sequences or SMILES representation, we can further enrich the representation and achieve state-of-the-art results on established benchmark datasets. We provide preprocessed and integrated data obtained from 7 public sources, which encompass over 30M triples. Additionally, we make available the pre-trained models based on this data, along with the reported outcomes of their performance on three widely-used benchmark datasets for drug-target binding affinity prediction found in the Therapeutic Data Commons (TDC) benchmarks.",
    "path": "papers/23/06/2306.12802.json",
    "total_tokens": 844,
    "translated_title": "Otter-Knowledge：不同来源的多模态知识图谱表示学习在药物发现中的基准测试。",
    "translated_abstract": "最近，表示学习的研究利用大量的蛋白质或分子数据库，通过无监督学习技术获得药物和蛋白质结构的知识。这些预训练表示已被证明可以显著提高后续任务的准确性，如预测药物和靶蛋白之间的亲和力。在本研究中，我们展示了通过将来自不同来源和模态的知识图谱整合到序列或SMILES表示中，可以进一步丰富表示，并在已建立的基准测试数据集上实现最先进的结果。我们提供了来自7个公共来源的预处理和整合数据，其中包括超过30M个三元组。此外，我们还提供了基于这些数据的预训练模型，以及它们在Therapeutic Data Commons (TDC)基准测试中性能报告的结果。",
    "tldr": "本研究在药物发现方面使用了多模态知识图谱表示学习，获得了最先进的结果。他们整合了来自不同来源的数据，并提供了基于这些数据的预训练模型。"
}