{
    "title": "Improving Frame-level Classifier for Word Timings with Non-peaky CTC in End-to-End Automatic Speech Recognition. (arXiv:2306.07949v1 [eess.AS])",
    "abstract": "End-to-end (E2E) systems have shown comparable performance to hybrid systems for automatic speech recognition (ASR). Word timings, as a by-product of ASR, are essential in many applications, especially for subtitling and computer-aided pronunciation training. In this paper, we improve the frame-level classifier for word timings in E2E system by introducing label priors in connectionist temporal classification (CTC) loss, which is adopted from prior works, and combining low-level Mel-scale filter banks with high-level ASR encoder output as input feature. On the internal Chinese corpus, the proposed method achieves 95.68%/94.18% compared to the hybrid system 93.0%/90.22% on the word timing accuracy metrics. It also surpass a previous E2E approach with an absolute increase of 4.80%/8.02% on the metrics on 7 languages. In addition, we further improve word timing accuracy by delaying CTC peaks with frame-wise knowledge distillation, though only experimenting on LibriSpeech.",
    "link": "http://arxiv.org/abs/2306.07949",
    "context": "Title: Improving Frame-level Classifier for Word Timings with Non-peaky CTC in End-to-End Automatic Speech Recognition. (arXiv:2306.07949v1 [eess.AS])\nAbstract: End-to-end (E2E) systems have shown comparable performance to hybrid systems for automatic speech recognition (ASR). Word timings, as a by-product of ASR, are essential in many applications, especially for subtitling and computer-aided pronunciation training. In this paper, we improve the frame-level classifier for word timings in E2E system by introducing label priors in connectionist temporal classification (CTC) loss, which is adopted from prior works, and combining low-level Mel-scale filter banks with high-level ASR encoder output as input feature. On the internal Chinese corpus, the proposed method achieves 95.68%/94.18% compared to the hybrid system 93.0%/90.22% on the word timing accuracy metrics. It also surpass a previous E2E approach with an absolute increase of 4.80%/8.02% on the metrics on 7 languages. In addition, we further improve word timing accuracy by delaying CTC peaks with frame-wise knowledge distillation, though only experimenting on LibriSpeech.",
    "path": "papers/23/06/2306.07949.json",
    "total_tokens": 973,
    "translated_title": "非峰值CTC提升端到端自动语音识别中词时分类器的帧级分类器",
    "translated_abstract": "端到端系统已经显示出与混合系统相当的自动语音识别（ASR）性能。作为ASR的副产品，词的定时对于许多应用程序至关重要，特别是字幕和计算机辅助发音训练。本文通过在连接时序分类（CTC）损失中引入标签先验，并将低层Mel-scale滤波器和高层ASR编码器输出组合作为输入特征，改进了E2E系统中用于词时的帧级分类器。在内部汉语语料库上，所提出的方法相比混合系统在单词时序准确性度量上实现了 95.68% / 94.18% 的性能，而且在7种语言的指标上绝对提高了4.80% / 8.02% 的分数，超越了先前的E2E方法。此外，我们通过延迟CTC峰值和基于帧的知识蒸馏进一步提高了词时准确性，但仅在LibriSpeech上进行了实验。",
    "tldr": "本文提出通过在连接时序分类（CTC）损失中引入标签先验，并将低层Mel-scale滤波器和高层ASR编码器输出组合作为输入特征来改进E2E系统中用于词时的帧级分类器，实现了更高的词时准确性。"
}