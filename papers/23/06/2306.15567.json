{
    "title": "A Three-Way Knot: Privacy, Fairness, and Predictive Performance Dynamics. (arXiv:2306.15567v1 [cs.LG])",
    "abstract": "As the frontier of machine learning applications moves further into human interaction, multiple concerns arise regarding automated decision-making. Two of the most critical issues are fairness and data privacy. On the one hand, one must guarantee that automated decisions are not biased against certain groups, especially those unprotected or marginalized. On the other hand, one must ensure that the use of personal information fully abides by privacy regulations and that user identities are kept safe. The balance between privacy, fairness, and predictive performance is complex. However, despite their potential societal impact, we still demonstrate a poor understanding of the dynamics between these optimization vectors. In this paper, we study this three-way tension and how the optimization of each vector impacts others, aiming to inform the future development of safe applications. In light of claims that predictive performance and fairness can be jointly optimized, we find this is only p",
    "link": "http://arxiv.org/abs/2306.15567",
    "context": "Title: A Three-Way Knot: Privacy, Fairness, and Predictive Performance Dynamics. (arXiv:2306.15567v1 [cs.LG])\nAbstract: As the frontier of machine learning applications moves further into human interaction, multiple concerns arise regarding automated decision-making. Two of the most critical issues are fairness and data privacy. On the one hand, one must guarantee that automated decisions are not biased against certain groups, especially those unprotected or marginalized. On the other hand, one must ensure that the use of personal information fully abides by privacy regulations and that user identities are kept safe. The balance between privacy, fairness, and predictive performance is complex. However, despite their potential societal impact, we still demonstrate a poor understanding of the dynamics between these optimization vectors. In this paper, we study this three-way tension and how the optimization of each vector impacts others, aiming to inform the future development of safe applications. In light of claims that predictive performance and fairness can be jointly optimized, we find this is only p",
    "path": "papers/23/06/2306.15567.json",
    "total_tokens": 888,
    "translated_title": "一个三重纠结：隐私、公平性和预测性能动态",
    "translated_abstract": "随着机器学习应用的边界进一步向人类互动领域推进，关于自动决策的多个问题引起了人们的关注。其中最重要的两个问题是公平性和数据隐私。一方面，必须确保自动决策没有对特定群体，尤其是那些没有保护或被边缘化的群体产生偏见。另一方面，必须确保个人信息的使用完全遵守隐私法规，并确保用户身份的安全。隐私、公平性和预测性能之间的平衡非常复杂。然而，尽管它们可能对社会产生重要影响，我们对这些优化向量之间的动态关系仍然了解甚少。在本文中，我们研究了这种三重张力以及每个向量的优化如何影响其他向量，旨在为未来安全应用的发展提供信息。在考虑到预测性能和公平性可以共同优化的观点的基础上，我们发现这只是部分实现可能性。",
    "tldr": "本文研究了隐私、公平性和预测性能之间的复杂平衡关系，并发现了它们之间的优化相互影响，为未来安全应用的发展提供了有价值的信息。"
}