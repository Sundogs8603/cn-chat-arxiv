{
    "title": "Towards Improving the Performance of Pre-Trained Speech Models for Low-Resource Languages Through Lateral Inhibition. (arXiv:2306.17792v1 [cs.CL])",
    "abstract": "With the rise of bidirectional encoder representations from Transformer models in natural language processing, the speech community has adopted some of their development methodologies. Therefore, the Wav2Vec models were introduced to reduce the data required to obtain state-of-the-art results. This work leverages this knowledge and improves the performance of the pre-trained speech models by simply replacing the fine-tuning dense layer with a lateral inhibition layer inspired by the biological process. Our experiments on Romanian, a low-resource language, show an average improvement of 12.5% word error rate (WER) using the lateral inhibition layer. In addition, we obtain state-of-the-art results on both the Romanian Speech Corpus and the Robin Technical Acquisition Corpus with 1.78% WER and 29.64% WER, respectively.",
    "link": "http://arxiv.org/abs/2306.17792",
    "context": "Title: Towards Improving the Performance of Pre-Trained Speech Models for Low-Resource Languages Through Lateral Inhibition. (arXiv:2306.17792v1 [cs.CL])\nAbstract: With the rise of bidirectional encoder representations from Transformer models in natural language processing, the speech community has adopted some of their development methodologies. Therefore, the Wav2Vec models were introduced to reduce the data required to obtain state-of-the-art results. This work leverages this knowledge and improves the performance of the pre-trained speech models by simply replacing the fine-tuning dense layer with a lateral inhibition layer inspired by the biological process. Our experiments on Romanian, a low-resource language, show an average improvement of 12.5% word error rate (WER) using the lateral inhibition layer. In addition, we obtain state-of-the-art results on both the Romanian Speech Corpus and the Robin Technical Acquisition Corpus with 1.78% WER and 29.64% WER, respectively.",
    "path": "papers/23/06/2306.17792.json",
    "total_tokens": 863,
    "translated_title": "通过侧抑制方法提高低资源语言的预训练语音模型性能",
    "translated_abstract": "随着双向编码器Transformer模型在自然语言处理领域的兴起，语音领域采用了其中一些开发方法。因此，Wav2Vec模型被引入以减少获取最先进结果所需的数据量。本研究利用这些知识，通过将微调密集层替换为受生物过程启发的侧抑制层来提高预训练语音模型的性能。我们在罗马尼亚语这种低资源语言上的实验表明，使用侧抑制层的平均字错误率（WER）提高了12.5%。此外，我们在罗马尼亚语语音语料库和Robin技术采集语料库上获得了最先进的结果，分别为1.78% WER和29.64% WER。",
    "tldr": "本研究通过将微调密集层替换为侧抑制层，提高了低资源语言的预训练语音模型性能，并在罗马尼亚语语料库和Robin技术采集语料库上实现了最先进的结果。"
}