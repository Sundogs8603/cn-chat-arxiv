{
    "title": "Enhancing In-Context Learning with Answer Feedback for Multi-Span Question Answering. (arXiv:2306.04508v1 [cs.CL])",
    "abstract": "Whereas the recent emergence of large language models (LLMs) like ChatGPT has exhibited impressive general performance, it still has a large gap with fully-supervised models on specific tasks such as multi-span question answering. Previous researches found that in-context learning is an effective approach to exploiting LLM, by using a few task-related labeled data as demonstration examples to construct a few-shot prompt for answering new questions. A popular implementation is to concatenate a few questions and their correct answers through simple templates, informing LLM of the desired output. In this paper, we propose a novel way of employing labeled data such that it also informs LLM of some undesired output, by extending demonstration examples with feedback about answers predicted by an off-the-shelf model, e.g., correct, incorrect, or incomplete. Experiments on three multi-span question answering datasets as well as a keyphrase extraction dataset show that our new prompting strateg",
    "link": "http://arxiv.org/abs/2306.04508",
    "context": "Title: Enhancing In-Context Learning with Answer Feedback for Multi-Span Question Answering. (arXiv:2306.04508v1 [cs.CL])\nAbstract: Whereas the recent emergence of large language models (LLMs) like ChatGPT has exhibited impressive general performance, it still has a large gap with fully-supervised models on specific tasks such as multi-span question answering. Previous researches found that in-context learning is an effective approach to exploiting LLM, by using a few task-related labeled data as demonstration examples to construct a few-shot prompt for answering new questions. A popular implementation is to concatenate a few questions and their correct answers through simple templates, informing LLM of the desired output. In this paper, we propose a novel way of employing labeled data such that it also informs LLM of some undesired output, by extending demonstration examples with feedback about answers predicted by an off-the-shelf model, e.g., correct, incorrect, or incomplete. Experiments on three multi-span question answering datasets as well as a keyphrase extraction dataset show that our new prompting strateg",
    "path": "papers/23/06/2306.04508.json",
    "total_tokens": 867,
    "translated_title": "通过答案反馈增强多跨度问答的上下文学习",
    "translated_abstract": "最近，大型语言模型（LLM）如ChatGPT的出现展示了令人印象深刻的通用性能力，但在特定任务（如多跨度问答）上仍存在较大差距。先前的研究发现，通过使用少量任务相关的标记数据作为演示示例构建少量追问提示，可以利用上下文学习有效地利用LLM。一种流行的实现方式是通过简单的模板将几个问题及其正确答案进行连接，通知LLM所需的输出。在本文中，我们提出了一种新颖的利用标记数据的方法，使之也提供对LLM一些不期望的输出的提示，通过扩展演示示例以反馈预测模型预测的答案，例如，正确、不正确或不完整。在三个多跨度问答数据集以及一个关键词提取数据集上的实验证明，我们的新提示策略显著优于现有方法。",
    "tldr": "本文提出了一种使用答案反馈来增强多跨度问答的上下文学习方法，将传统的演示示例扩展了反馈信息，可以有效地提高模型的预测性能。",
    "en_tdlr": "This paper proposes a novel way of enhancing in-context learning for multi-span question answering by extending demonstration examples with feedback about answers predicted by an off-the-shelf model, and experiments show significant performance improvement."
}