{
    "title": "Class Anchor Margin Loss for Content-Based Image Retrieval. (arXiv:2306.00630v2 [cs.CV] UPDATED)",
    "abstract": "The performance of neural networks in content-based image retrieval (CBIR) is highly influenced by the chosen loss (objective) function. The majority of objective functions for neural models can be divided into metric learning and statistical learning. Metric learning approaches require a pair mining strategy that often lacks efficiency, while statistical learning approaches are not generating highly compact features due to their indirect feature optimization. To this end, we propose a novel repeller-attractor loss that falls in the metric learning paradigm, yet directly optimizes for the L2 metric without the need of generating pairs. Our loss is formed of three components. One leading objective ensures that the learned features are attracted to each designated learnable class anchor. The second loss component regulates the anchors and forces them to be separable by a margin, while the third objective ensures that the anchors do not collapse to zero. Furthermore, we develop a more eff",
    "link": "http://arxiv.org/abs/2306.00630",
    "context": "Title: Class Anchor Margin Loss for Content-Based Image Retrieval. (arXiv:2306.00630v2 [cs.CV] UPDATED)\nAbstract: The performance of neural networks in content-based image retrieval (CBIR) is highly influenced by the chosen loss (objective) function. The majority of objective functions for neural models can be divided into metric learning and statistical learning. Metric learning approaches require a pair mining strategy that often lacks efficiency, while statistical learning approaches are not generating highly compact features due to their indirect feature optimization. To this end, we propose a novel repeller-attractor loss that falls in the metric learning paradigm, yet directly optimizes for the L2 metric without the need of generating pairs. Our loss is formed of three components. One leading objective ensures that the learned features are attracted to each designated learnable class anchor. The second loss component regulates the anchors and forces them to be separable by a margin, while the third objective ensures that the anchors do not collapse to zero. Furthermore, we develop a more eff",
    "path": "papers/23/06/2306.00630.json",
    "total_tokens": 1027,
    "translated_title": "基于内容的图像检索的类锚点边距损失",
    "translated_abstract": "神经网络在内容为基础的图像检索（CBIR）中的性能受所选的损失（目标）函数的影响很大。神经模型的大多数目标函数可以分为度量学习和统计学习两类。度量学习方法需要成对挖掘策略，这往往缺乏效率，而统计学习方法由于其间接特征优化而无法生成高度压缩的特征。为此，我们提出了一种新颖的斥力-吸引力损失函数，位于度量学习范式中，却可以直接优化L2度量，无需生成成对。我们的损失由三个组成部分组成。一个主要目标确保学习到的特征被吸引到各自指定的可学习类锚点。第二个损失组分对锚点进行调节，强制它们相互之间有一定间隔，而第三个目标确保锚点不会崩溃为零。此外，我们开发了一种更高效的变体，它不需要计算完整的成对距离矩阵。我们在多个数据集上的实验表明，我们提出的损失在检索准确性和效率方面优于现有技术。",
    "tldr": "本论文提出一种新颖的斥力-吸引力损失函数，该函数位于度量学习范式中，可以直接优化L2度量，无需生成成对，在多个数据集上的实验表明，在检索准确性和效率方面，该方法优于现有技术。",
    "en_tdlr": "This paper proposes a novel repeller-attractor loss function falling in the metric learning paradigm, which optimizes for the L2 metric without the need of generating pairs. Experiments on multiple datasets demonstrate the superiority of the proposed method over state-of-the-art methods in terms of retrieval accuracy and efficiency."
}