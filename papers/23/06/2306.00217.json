{
    "title": "FEED PETs: Further Experimentation and Expansion on the Disambiguation of Potentially Euphemistic Terms. (arXiv:2306.00217v1 [cs.CL])",
    "abstract": "Transformers have been shown to work well for the task of English euphemism disambiguation, in which a potentially euphemistic term (PET) is classified as euphemistic or non-euphemistic in a particular context. In this study, we expand on the task in two ways. First, we annotate PETs for vagueness, a linguistic property associated with euphemisms, and find that transformers are generally better at classifying vague PETs, suggesting linguistic differences in the data that impact performance. Second, we present novel euphemism corpora in three different languages: Yoruba, Spanish, and Mandarin Chinese. We perform euphemism disambiguation experiments in each language using multilingual transformer models mBERT and XLM-RoBERTa, establishing preliminary results from which to launch future work.",
    "link": "http://arxiv.org/abs/2306.00217",
    "context": "Title: FEED PETs: Further Experimentation and Expansion on the Disambiguation of Potentially Euphemistic Terms. (arXiv:2306.00217v1 [cs.CL])\nAbstract: Transformers have been shown to work well for the task of English euphemism disambiguation, in which a potentially euphemistic term (PET) is classified as euphemistic or non-euphemistic in a particular context. In this study, we expand on the task in two ways. First, we annotate PETs for vagueness, a linguistic property associated with euphemisms, and find that transformers are generally better at classifying vague PETs, suggesting linguistic differences in the data that impact performance. Second, we present novel euphemism corpora in three different languages: Yoruba, Spanish, and Mandarin Chinese. We perform euphemism disambiguation experiments in each language using multilingual transformer models mBERT and XLM-RoBERTa, establishing preliminary results from which to launch future work.",
    "path": "papers/23/06/2306.00217.json",
    "total_tokens": 895,
    "translated_title": "FEED PETs：关于潜在委婉说语的消歧更多实验与扩展",
    "translated_abstract": "研究表明Transformer在英语委婉语消歧任务中表现良好，即在特定语境中将潜在的委婉语（PET）分类为委婉语或非委婉语。本研究从两个方面扩展任务。首先，我们为模糊性注释PET，这是与委婉语相关的语言属性，并发现Transformer通常更擅长分类模糊的PET，这表明影响性能的数据中存在语言差异。其次，我们提供了三种不同语言的新颖委婉语语料库：约鲁巴语、西班牙语和中文普通话。我们使用多语言Transformer模型mBERT和XLM-RoBERTa在每种语言中执行委婉语消歧实验，建立初步结果，为未来工作提供了基础和参考。",
    "tldr": "本研究扩展了潜在委婉语消歧任务，首先注释了模糊性对性能的影响，并在三种不同的语言中提供了新颖的委婉语语料库。通过使用多语言Transformer模型，该研究建立了初步的结果，为未来的工作提供了基础。",
    "en_tdlr": "This study expands on euphemism disambiguation task by annotating vagueness for PETs and presenting novel euphemism corpora in three different languages. Preliminary results are established through euphemism disambiguation experiments using multilingual transformer models, providing a foundation for future work."
}