{
    "title": "Controlling Text-to-Image Diffusion by Orthogonal Finetuning. (arXiv:2306.07280v2 [cs.CV] UPDATED)",
    "abstract": "Large text-to-image diffusion models have impressive capabilities in generating photorealistic images from text prompts. How to effectively guide or control these powerful models to perform different downstream tasks becomes an important open problem. To tackle this challenge, we introduce a principled finetuning method -- Orthogonal Finetuning (OFT), for adapting text-to-image diffusion models to downstream tasks. Unlike existing methods, OFT can provably preserve hyperspherical energy which characterizes the pairwise neuron relationship on the unit hypersphere. We find that this property is crucial for preserving the semantic generation ability of text-to-image diffusion models. To improve finetuning stability, we further propose Constrained Orthogonal Finetuning (COFT) which imposes an additional radius constraint to the hypersphere. Specifically, we consider two important finetuning text-to-image tasks: subject-driven generation where the goal is to generate subject-specific images",
    "link": "http://arxiv.org/abs/2306.07280",
    "context": "Title: Controlling Text-to-Image Diffusion by Orthogonal Finetuning. (arXiv:2306.07280v2 [cs.CV] UPDATED)\nAbstract: Large text-to-image diffusion models have impressive capabilities in generating photorealistic images from text prompts. How to effectively guide or control these powerful models to perform different downstream tasks becomes an important open problem. To tackle this challenge, we introduce a principled finetuning method -- Orthogonal Finetuning (OFT), for adapting text-to-image diffusion models to downstream tasks. Unlike existing methods, OFT can provably preserve hyperspherical energy which characterizes the pairwise neuron relationship on the unit hypersphere. We find that this property is crucial for preserving the semantic generation ability of text-to-image diffusion models. To improve finetuning stability, we further propose Constrained Orthogonal Finetuning (COFT) which imposes an additional radius constraint to the hypersphere. Specifically, we consider two important finetuning text-to-image tasks: subject-driven generation where the goal is to generate subject-specific images",
    "path": "papers/23/06/2306.07280.json",
    "total_tokens": 925,
    "translated_title": "通过正交微调控制文本到图像的扩散",
    "translated_abstract": "大型文本到图像扩散模型在生成真实感图像方面有很强的能力。如何有效地引导或控制这些强大的模型以执行不同的下游任务成为一个重要的开放性问题。为了解决这个挑战，我们引入了一种基于原则的微调方法——正交微调（OFT），用于将文本到图像扩散模型调整到下游任务中。与现有方法不同，OFT可以证明地保持特征对神经元在单位超球面上的关系所表征的超球形能量。我们发现，这种属性对于保持文本到图像扩散模型的语义生成能力非常关键。为了提高微调的稳定性，我们进一步提出了约束正交微调（COFT），它对超球面施加了额外的半径约束。具体来说，我们考虑了两个重要的微调文本到图像任务：主题驱动生成，目标是生成特定主题的图像",
    "tldr": "本文介绍了一种名为正交微调（OFT）的方法，可以有效地引导和控制大型文本到图像扩散模型，以执行不同的下游任务。我们还提出了约束正交微调（COFT），来提高微调的稳定性。这些方法能够保持语义生成能力并生成特定主题的图像。"
}