{
    "title": "Federated Multi-Sequence Stochastic Approximation with Local Hypergradient Estimation. (arXiv:2306.01648v1 [cs.LG])",
    "abstract": "Stochastic approximation with multiple coupled sequences (MSA) has found broad applications in machine learning as it encompasses a rich class of problems including bilevel optimization (BLO), multi-level compositional optimization (MCO), and reinforcement learning (specifically, actor-critic methods). However, designing provably-efficient federated algorithms for MSA has been an elusive question even for the special case of double sequence approximation (DSA). Towards this goal, we develop FedMSA which is the first federated algorithm for MSA, and establish its near-optimal communication complexity. As core novelties, (i) FedMSA enables the provable estimation of hypergradients in BLO and MCO via local client updates, which has been a notable bottleneck in prior theory, and (ii) our convergence guarantees are sensitive to the heterogeneity-level of the problem. We also incorporate momentum and variance reduction techniques to achieve further acceleration leading to near-optimal rates.",
    "link": "http://arxiv.org/abs/2306.01648",
    "context": "Title: Federated Multi-Sequence Stochastic Approximation with Local Hypergradient Estimation. (arXiv:2306.01648v1 [cs.LG])\nAbstract: Stochastic approximation with multiple coupled sequences (MSA) has found broad applications in machine learning as it encompasses a rich class of problems including bilevel optimization (BLO), multi-level compositional optimization (MCO), and reinforcement learning (specifically, actor-critic methods). However, designing provably-efficient federated algorithms for MSA has been an elusive question even for the special case of double sequence approximation (DSA). Towards this goal, we develop FedMSA which is the first federated algorithm for MSA, and establish its near-optimal communication complexity. As core novelties, (i) FedMSA enables the provable estimation of hypergradients in BLO and MCO via local client updates, which has been a notable bottleneck in prior theory, and (ii) our convergence guarantees are sensitive to the heterogeneity-level of the problem. We also incorporate momentum and variance reduction techniques to achieve further acceleration leading to near-optimal rates.",
    "path": "papers/23/06/2306.01648.json",
    "total_tokens": 994,
    "translated_title": "用本地超梯度估计的联邦多序列随机逼近",
    "translated_abstract": "多序列随机逼近（MSA）已经被广泛应用于机器学习中，因为它包含了许多问题的丰富类别，包括双层优化、多层组合优化和强化学习（特别是演员-评论家方法）。然而，即使对于双序列逼近（DSA）的特殊情况，设计出经过证明的有效联邦算法也一直是一个难以捉摸的问题。为了实现这个目标，我们开发了FedMSA，这是第一个针对MSA的联邦算法，并建立了其近乎最优的通信复杂度。作为核心创新，(i) FedMSA通过本地客户端更新实现了BLO和MCO中超梯度的可证估计，这在以前的理论中是一个显著的瓶颈， (ii) 我们的收敛性保证对问题的异质性水平是敏感的。我们还结合动量和方差缩减技术来实现进一步的加速，导致接近最优的速率。",
    "tldr": "本文提出了FedMSA，这是第一个针对多序列随机逼近（MSA）的联邦算法，并建立了其近乎最优的通信复杂度。通过本地客户端更新，FedMSA实现了BLO和MCO中超梯度的可证估计。文中还结合动量和方差缩减技术来加速，导致接近最优的速率。",
    "en_tdlr": "This paper proposes FedMSA, the first federated algorithm for Multi-Sequence Stochastic Approximation (MSA) with near-optimal communication complexity. FedMSA enables provable estimation of hypergradients in Bilevel Optimization and Multi-Level Compositional Optimization via local client updates and incorporates momentum and variance reduction techniques to achieve near-optimal rates."
}