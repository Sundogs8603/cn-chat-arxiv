{
    "title": "Re-Rank - Expand - Repeat: Adaptive Query Expansion for Document Retrieval Using Words and Entities. (arXiv:2306.17082v1 [cs.IR])",
    "abstract": "Sparse and dense pseudo-relevance feedback (PRF) approaches perform poorly on challenging queries due to low precision in first-pass retrieval. However, recent advances in neural language models (NLMs) can re-rank relevant documents to top ranks, even when few are in the re-ranking pool. This paper first addresses the problem of poor pseudo-relevance feedback by simply applying re-ranking prior to query expansion and re-executing this query. We find that this change alone can improve the retrieval effectiveness of sparse and dense PRF approaches by 5-8%. Going further, we propose a new expansion model, Latent Entity Expansion (LEE), a fine-grained word and entity-based relevance modelling incorporating localized features. Finally, we include an \"adaptive\" component to the retrieval process, which iteratively refines the re-ranking pool during scoring using the expansion model, i.e. we \"re-rank - expand repeat\". Using LEE, we achieve (to our knowledge) the best NDCG, MAP and R@1000 re",
    "link": "http://arxiv.org/abs/2306.17082",
    "context": "Title: Re-Rank - Expand - Repeat: Adaptive Query Expansion for Document Retrieval Using Words and Entities. (arXiv:2306.17082v1 [cs.IR])\nAbstract: Sparse and dense pseudo-relevance feedback (PRF) approaches perform poorly on challenging queries due to low precision in first-pass retrieval. However, recent advances in neural language models (NLMs) can re-rank relevant documents to top ranks, even when few are in the re-ranking pool. This paper first addresses the problem of poor pseudo-relevance feedback by simply applying re-ranking prior to query expansion and re-executing this query. We find that this change alone can improve the retrieval effectiveness of sparse and dense PRF approaches by 5-8%. Going further, we propose a new expansion model, Latent Entity Expansion (LEE), a fine-grained word and entity-based relevance modelling incorporating localized features. Finally, we include an \"adaptive\" component to the retrieval process, which iteratively refines the re-ranking pool during scoring using the expansion model, i.e. we \"re-rank - expand repeat\". Using LEE, we achieve (to our knowledge) the best NDCG, MAP and R@1000 re",
    "path": "papers/23/06/2306.17082.json",
    "total_tokens": 984,
    "translated_title": "重新排序-扩展-重复：使用单词和实体的自适应查询扩展的文档检索",
    "translated_abstract": "稀疏和密集的伪相关反馈(PRf)方法在挑战性查询中表现不佳，原因是在第一次检索中的低准确率。然而，最近的神经语言模型(NLMs)的进展可以将相关文档重新排名到前几名，即使重新排名池中只有很少的文档。本文首先通过简单地在查询扩展之前应用重新排序并重新执行查询来解决伪相关反馈的问题。我们发现仅凭这个改变就可以将稀疏和密集PRF方法的检索效果提升5-8%。进一步地，我们提出了一种新的扩展模型，潜在实体扩展(LEE)，它是一种细粒度的基于词和实体的相关性建模，包括局部特征。最后，我们在检索过程中引入了一个“自适应”组件，它在评分过程中使用扩展模型迭代地调整重新排名池，即“重新排序-扩展-重复”。使用LEE，我们实现了(据我们所知)最好的NDCG、MAP和R@1000。",
    "tldr": "本文提出了一种自适应查询扩展的文档检索方法，通过先重新排序再进行查询扩展，以及引入新的扩展模型和自适应组件来提高检索效果。使用该方法，我们在NDCG、MAP和R@1000等指标上取得了最好的结果。"
}