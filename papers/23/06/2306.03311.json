{
    "title": "Learning Embeddings for Sequential Tasks Using Population of Agents. (arXiv:2306.03311v1 [cs.LG])",
    "abstract": "We present an information-theoretic framework to learn fixed-dimensional embeddings for tasks in reinforcement learning. We leverage the idea that two tasks are similar to each other if observing an agent's performance on one task reduces our uncertainty about its performance on the other. This intuition is captured by our information-theoretic criterion which uses a diverse population of agents to measure similarity between tasks in sequential decision-making settings. In addition to qualitative assessment, we empirically demonstrate the effectiveness of our techniques based on task embeddings by quantitative comparisons against strong baselines on two application scenarios: predicting an agent's performance on a test task by observing its performance on a small quiz of tasks, and selecting tasks with desired characteristics from a given set of options.",
    "link": "http://arxiv.org/abs/2306.03311",
    "context": "Title: Learning Embeddings for Sequential Tasks Using Population of Agents. (arXiv:2306.03311v1 [cs.LG])\nAbstract: We present an information-theoretic framework to learn fixed-dimensional embeddings for tasks in reinforcement learning. We leverage the idea that two tasks are similar to each other if observing an agent's performance on one task reduces our uncertainty about its performance on the other. This intuition is captured by our information-theoretic criterion which uses a diverse population of agents to measure similarity between tasks in sequential decision-making settings. In addition to qualitative assessment, we empirically demonstrate the effectiveness of our techniques based on task embeddings by quantitative comparisons against strong baselines on two application scenarios: predicting an agent's performance on a test task by observing its performance on a small quiz of tasks, and selecting tasks with desired characteristics from a given set of options.",
    "path": "papers/23/06/2306.03311.json",
    "total_tokens": 832,
    "translated_title": "使用代理人群体学习序列任务的嵌入",
    "translated_abstract": "我们提出了一个信息理论框架，用于在强化学习任务中学习固定维度的嵌入。我们利用这样的想法：如果观察一个代理在一个任务上的表现减少了我们关于他在另一个任务上表现的不确定性，那么两个任务就相似。我们的信息理论准则捕捉了这种直觉，使用多样化的代理人群体来测量序列决策环境中任务之间的相似性。除了定性评估，我们还通过对两个应用场景进行量化比较，基于任务嵌入展示了我们技术的有效性：通过观察代理在一小组任务上的表现，来预测其在测试任务上的表现；从给定的任务选项中选择具有所需特征的任务。",
    "tldr": "该研究基于代理人群体提出了一个信息理论框架，用于在强化学习任务中学习固定维度的嵌入，可以通过观察代理在一小组任务上的表现，来预测其在测试任务上的表现，并且可以从给定的任务选项中选择具有所需特征的任务。",
    "en_tdlr": "This study proposes an information-theoretic framework based on a population of agents for learning fixed-dimensional embeddings in reinforcement learning tasks. It can predict an agent's performance on a test task by observing its performance on a small set of tasks, and select tasks with desired characteristics from a given set of options."
}