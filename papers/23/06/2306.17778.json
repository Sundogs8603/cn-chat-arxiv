{
    "title": "Look, Remember and Reason: Visual Reasoning with Grounded Rationales. (arXiv:2306.17778v1 [cs.CV])",
    "abstract": "Large language models have recently shown human level performance on a variety of reasoning tasks. However, the ability of these models to perform complex visual reasoning has not been studied in detail yet. A key challenge in many visual reasoning tasks is that the visual information needs to be tightly integrated in the reasoning process. We propose to address this challenge by drawing inspiration from human visual problem solving which depends on a variety of low-level visual capabilities. It can often be cast as the three step-process of ``Look, Remember, Reason'': visual information is incrementally extracted using low-level visual routines in a step-by-step fashion until a final answer is reached. We follow the same paradigm to enable existing large language models, with minimal changes to the architecture, to solve visual reasoning problems. To this end, we introduce rationales over the visual input that allow us to integrate low-level visual capabilities, such as object recogni",
    "link": "http://arxiv.org/abs/2306.17778",
    "context": "Title: Look, Remember and Reason: Visual Reasoning with Grounded Rationales. (arXiv:2306.17778v1 [cs.CV])\nAbstract: Large language models have recently shown human level performance on a variety of reasoning tasks. However, the ability of these models to perform complex visual reasoning has not been studied in detail yet. A key challenge in many visual reasoning tasks is that the visual information needs to be tightly integrated in the reasoning process. We propose to address this challenge by drawing inspiration from human visual problem solving which depends on a variety of low-level visual capabilities. It can often be cast as the three step-process of ``Look, Remember, Reason'': visual information is incrementally extracted using low-level visual routines in a step-by-step fashion until a final answer is reached. We follow the same paradigm to enable existing large language models, with minimal changes to the architecture, to solve visual reasoning problems. To this end, we introduce rationales over the visual input that allow us to integrate low-level visual capabilities, such as object recogni",
    "path": "papers/23/06/2306.17778.json",
    "total_tokens": 900,
    "translated_title": "看看、记住和推理：基于机理的视觉推理",
    "translated_abstract": "近期，大型语言模型在各种推理任务上展示了与人类水平的表现。然而，这些模型在进行复杂的视觉推理方面的能力尚未得到详细研究。在许多视觉推理任务中，一个关键挑战是需要将视觉信息紧密融合到推理过程中。我们提出通过借鉴人类视觉问题解决的方法来解决这个挑战，这个方法依赖于多种低级视觉能力。它通常可以被看作是“看，记住，推理”的三个步骤过程：通过逐步进行低级视觉过程提取视觉信息，直到得出最终答案。我们遵循相同的范例，通过最小的架构更改，使现有的大型语言模型能够解决视觉推理问题。为此，我们引入了基于视觉输入的原理，允许我们集成低级视觉能力，如对象识别。",
    "tldr": "在这项研究中，我们借鉴了人类视觉问题解决的方法，通过三个步骤（看、记住、推理）逐步提取视觉信息来解决复杂的视觉推理问题，从而使大型语言模型能够有效解决这些问题。",
    "en_tdlr": "In this study, we drew inspiration from human visual problem solving and proposed a three-step approach (Look, Remember, Reason) to incrementally extract visual information, enabling large language models to effectively solve complex visual reasoning problems."
}