{
    "title": "Globally Interpretable Graph Learning via Distribution Matching",
    "abstract": "arXiv:2306.10447v2 Announce Type: replace  Abstract: Graph neural networks (GNNs) have emerged as a powerful model to capture critical graph patterns. Instead of treating them as black boxes in an end-to-end fashion, attempts are arising to explain the model behavior. Existing works mainly focus on local interpretation to reveal the discriminative pattern for each individual instance, which however cannot directly reflect the high-level model behavior across instances. To gain global insights, we aim to answer an important question that is not yet well studied: how to provide a global interpretation for the graph learning procedure? We formulate this problem as globally interpretable graph learning, which targets on distilling high-level and human-intelligible patterns that dominate the learning procedure, such that training on this pattern can recover a similar model. As a start, we propose a novel model fidelity metric, tailored for evaluating the fidelity of the resulting model trai",
    "link": "https://arxiv.org/abs/2306.10447",
    "context": "Title: Globally Interpretable Graph Learning via Distribution Matching\nAbstract: arXiv:2306.10447v2 Announce Type: replace  Abstract: Graph neural networks (GNNs) have emerged as a powerful model to capture critical graph patterns. Instead of treating them as black boxes in an end-to-end fashion, attempts are arising to explain the model behavior. Existing works mainly focus on local interpretation to reveal the discriminative pattern for each individual instance, which however cannot directly reflect the high-level model behavior across instances. To gain global insights, we aim to answer an important question that is not yet well studied: how to provide a global interpretation for the graph learning procedure? We formulate this problem as globally interpretable graph learning, which targets on distilling high-level and human-intelligible patterns that dominate the learning procedure, such that training on this pattern can recover a similar model. As a start, we propose a novel model fidelity metric, tailored for evaluating the fidelity of the resulting model trai",
    "path": "papers/23/06/2306.10447.json",
    "total_tokens": 802,
    "translated_title": "通过分布匹配实现全局可解释的图学习",
    "translated_abstract": "图神经网络（GNNs）已经成为捕捉关键图模式的强大模型。现在，人们正在试图解释模型行为而不是将其视为黑盒子。现有的工作主要集中在本地解释，揭示每个个体实例的区分模式，但这不能直接反映实例之间的高层模型行为。为了获得全局见解，我们旨在回答一个尚未得到很好研究的重要问题：如何为图学习过程提供全局解释？我们将这个问题制定为全局可解释的图学习，旨在提取主导学习过程的高级和人类可解读的模式，这样在这种模式上训练可以恢复类似的模型。作为一个开始，我们提出了一个新颖的模型保真度度量标准，用于评估所得到的模型的保真度。",
    "tldr": "该论文提出了通过分布匹配实现全局可解释的图学习的方法，旨在提取主导学习过程的高级模式，以实现全局解释。",
    "en_tdlr": "The paper introduces a method for achieving globally interpretable graph learning through distribution matching, targeting to extract high-level patterns dominating the learning process for global interpretation."
}