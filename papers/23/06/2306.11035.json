{
    "title": "Adversarial Training Should Be Cast as a Non-Zero-Sum Game. (arXiv:2306.11035v1 [cs.LG])",
    "abstract": "One prominent approach toward resolving the adversarial vulnerability of deep neural networks is the two-player zero-sum paradigm of adversarial training, in which predictors are trained against adversarially-chosen perturbations of data. Despite the promise of this approach, algorithms based on this paradigm have not engendered sufficient levels of robustness, and suffer from pathological behavior like robust overfitting. To understand this shortcoming, we first show that the commonly used surrogate-based relaxation used in adversarial training algorithms voids all guarantees on the robustness of trained classifiers. The identification of this pitfall informs a novel non-zero-sum bilevel formulation of adversarial training, wherein each player optimizes a different objective function. Our formulation naturally yields a simple algorithmic framework that matches and in some cases outperforms state-of-the-art attacks, attains comparable levels of robustness to standard adversarial traini",
    "link": "http://arxiv.org/abs/2306.11035",
    "context": "Title: Adversarial Training Should Be Cast as a Non-Zero-Sum Game. (arXiv:2306.11035v1 [cs.LG])\nAbstract: One prominent approach toward resolving the adversarial vulnerability of deep neural networks is the two-player zero-sum paradigm of adversarial training, in which predictors are trained against adversarially-chosen perturbations of data. Despite the promise of this approach, algorithms based on this paradigm have not engendered sufficient levels of robustness, and suffer from pathological behavior like robust overfitting. To understand this shortcoming, we first show that the commonly used surrogate-based relaxation used in adversarial training algorithms voids all guarantees on the robustness of trained classifiers. The identification of this pitfall informs a novel non-zero-sum bilevel formulation of adversarial training, wherein each player optimizes a different objective function. Our formulation naturally yields a simple algorithmic framework that matches and in some cases outperforms state-of-the-art attacks, attains comparable levels of robustness to standard adversarial traini",
    "path": "papers/23/06/2306.11035.json",
    "total_tokens": 903,
    "translated_title": "对抗训练应被视为一个非零和博弈",
    "translated_abstract": "解决深度神经网络对抗性脆弱性的一个突出方法是采用对抗性训练的两个玩家零和范式，其中预测器被训练以对抗性选择的数据扰动。虽然这种方法很有前途，但是基于这种范式的算法并没有产生足够的鲁棒性，并且遭受病态行为，如强健的过拟合。为了理解这种缺陷，我们首先展示了在对抗训练算法中使用的常见基于代理的松弛方法使所训练分类器的稳健性没有任何保证。我们发现这个问题后，提出了一个新的非零和双层对抗训练公式，其中每个玩家优化不同的目标函数，我们的公式自然地产生了一个简单的算法框架，可以与最先进的攻击相匹配，并且在一些情况下，能够达到与标准对抗性训练相当的鲁棒性水平。",
    "tldr": "本论文提出了一种新的针对对抗性训练的非零和双层公式，实现了与最先进攻击相匹配并且能够达到与标准对抗性训练相同的鲁棒性水平。",
    "en_tdlr": "This paper proposes a novel non-zero-sum bilevel formulation for adversarial training, which matches state-of-the-art attacks and achieves comparable levels of robustness to standard adversarial training."
}