{
    "title": "Intensity-free Convolutional Temporal Point Process: Incorporating Local and Global Event Contexts. (arXiv:2306.14072v1 [cs.LG])",
    "abstract": "Event prediction in the continuous-time domain is a crucial but rather difficult task. Temporal point process (TPP) learning models have shown great advantages in this area. Existing models mainly focus on encoding global contexts of events using techniques like recurrent neural networks (RNNs) or self-attention mechanisms. However, local event contexts also play an important role in the occurrences of events, which has been largely ignored. Popular convolutional neural networks, which are designated for local context capturing, have never been applied to TPP modelling due to their incapability of modelling in continuous time. In this work, we propose a novel TPP modelling approach that combines local and global contexts by integrating a continuous-time convolutional event encoder with an RNN. The presented framework is flexible and scalable to handle large datasets with long sequences and complex latent patterns. The experimental result shows that the proposed model improves the perfo",
    "link": "http://arxiv.org/abs/2306.14072",
    "context": "Title: Intensity-free Convolutional Temporal Point Process: Incorporating Local and Global Event Contexts. (arXiv:2306.14072v1 [cs.LG])\nAbstract: Event prediction in the continuous-time domain is a crucial but rather difficult task. Temporal point process (TPP) learning models have shown great advantages in this area. Existing models mainly focus on encoding global contexts of events using techniques like recurrent neural networks (RNNs) or self-attention mechanisms. However, local event contexts also play an important role in the occurrences of events, which has been largely ignored. Popular convolutional neural networks, which are designated for local context capturing, have never been applied to TPP modelling due to their incapability of modelling in continuous time. In this work, we propose a novel TPP modelling approach that combines local and global contexts by integrating a continuous-time convolutional event encoder with an RNN. The presented framework is flexible and scalable to handle large datasets with long sequences and complex latent patterns. The experimental result shows that the proposed model improves the perfo",
    "path": "papers/23/06/2306.14072.json",
    "total_tokens": 892,
    "translated_title": "无强度卷积时空点过程: 融合局部与全局事件语境",
    "translated_abstract": "连续时间领域的事件预测是一项至关重要但相当困难的任务。时间点过程(TPP)学习模型在这个领域中表现出了巨大的优势。现有的模型主要集中于使用像循环神经网络(RNN)或自我注意机制之类的技术来编码事件的全局上下文。但是，局部事件上下文对事件的发生也起着重要作用，但这方面却很少被关注。流行的卷积神经网络专为捕获局部上下文而设计，但由于无法在连续时间模型化，因此从未应用于TPP建模。本研究提出了一种将局部和全局上下文相结合的新型TPP建模方法，即将连续时间卷积事件编码器与RNN集成。所提出的框架具有灵活性和可扩展性，可以处理具有长序列和复杂潜在模式的大型数据集。实验结果表明，所提出的模型改善了性能。",
    "tldr": "本文提出了一种TPP建模方法，将连续时间卷积事件编码器与RNN集成，以融合局部和全局上下文。实验结果表明，该模型具有较好的性能表现。",
    "en_tdlr": "This paper proposes a TPP modeling approach that integrates a continuous-time convolutional event encoder with an RNN to combine local and global context. The model shows promising performance according to experiment results."
}