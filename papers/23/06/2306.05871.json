{
    "title": "Towards a Robust Detection of Language Model Generated Text: Is ChatGPT that Easy to Detect?. (arXiv:2306.05871v1 [cs.CL])",
    "abstract": "Recent advances in natural language processing (NLP) have led to the development of large language models (LLMs) such as ChatGPT. This paper proposes a methodology for developing and evaluating ChatGPT detectors for French text, with a focus on investigating their robustness on out-of-domain data and against common attack schemes. The proposed method involves translating an English dataset into French and training a classifier on the translated data. Results show that the detectors can effectively detect ChatGPT-generated text, with a degree of robustness against basic attack techniques in in-domain settings. However, vulnerabilities are evident in out-of-domain contexts, highlighting the challenge of detecting adversarial text. The study emphasizes caution when applying in-domain testing results to a wider variety of content. We provide our translated datasets and models as open-source resources. https://gitlab.inria.fr/wantoun/robust-chatgpt-detection",
    "link": "http://arxiv.org/abs/2306.05871",
    "context": "Title: Towards a Robust Detection of Language Model Generated Text: Is ChatGPT that Easy to Detect?. (arXiv:2306.05871v1 [cs.CL])\nAbstract: Recent advances in natural language processing (NLP) have led to the development of large language models (LLMs) such as ChatGPT. This paper proposes a methodology for developing and evaluating ChatGPT detectors for French text, with a focus on investigating their robustness on out-of-domain data and against common attack schemes. The proposed method involves translating an English dataset into French and training a classifier on the translated data. Results show that the detectors can effectively detect ChatGPT-generated text, with a degree of robustness against basic attack techniques in in-domain settings. However, vulnerabilities are evident in out-of-domain contexts, highlighting the challenge of detecting adversarial text. The study emphasizes caution when applying in-domain testing results to a wider variety of content. We provide our translated datasets and models as open-source resources. https://gitlab.inria.fr/wantoun/robust-chatgpt-detection",
    "path": "papers/23/06/2306.05871.json",
    "total_tokens": 924,
    "translated_title": "实现对语言模型生成文本的鲁棒检测：ChatGPT 容易被发现吗？",
    "translated_abstract": "自然语言处理 (NLP) 的最新进展推动了大型语言模型 (LLM) 的发展，例如 ChatGPT。本文提出了一种针对法语文本开发和评估 ChatGPT 检测器的方法，重点研究它们对域外数据和常见攻击方案的鲁棒性。所提出的方法包括将英语数据集翻译为法语并在翻译数据上训练分类器。结果表明，检测器可以有效地检测 ChatGPT 生成的文本，在域内环境下具有一定的抗攻击技术的鲁棒性。然而，在域外环境中存在明显的漏洞，凸显了检测对抗性文本的挑战性。该研究强调了谨慎将域内测试结果应用于更广泛的内容上。我们提供了翻译的数据集和模型作为开源资源。",
    "tldr": "本文提出了一种针对法语文本的 ChatGPT 检测器开发和评估方法，结果表明这些检测器可以有效地检测 ChatGPT 生成的文本，在域内环境下具有一定的抗攻击技术的鲁棒性，但在域外环境中存在明显的漏洞。",
    "en_tdlr": "This paper proposes a methodology for developing and evaluating ChatGPT detectors for French text, which shows that the detectors can effectively detect ChatGPT-generated text, with a degree of robustness against basic attack techniques in in-domain settings. However, vulnerabilities are evident in out-of-domain contexts."
}