{
    "title": "OBELISC: An Open Web-Scale Filtered Dataset of Interleaved Image-Text Documents. (arXiv:2306.16527v1 [cs.IR])",
    "abstract": "Large multimodal models trained on natural documents, which interleave images and text, outperform models trained on image-text pairs on various multimodal benchmarks that require reasoning over one or multiple images to generate a text. However, the datasets used to train these models have not been released, and the collection process has not been fully specified. We introduce the OBELISC dataset, an open web-scale filtered dataset of interleaved image-text documents comprising 141 million web pages extracted from Common Crawl, 353 million associated images, and 115 billion text tokens. We describe the dataset creation process, present comprehensive filtering rules, and provide an analysis of the dataset's content. To show the viability of OBELISC, we train an 80 billion parameters vision and language model on the dataset and obtain competitive performance on various multimodal benchmarks. We release the code to reproduce the dataset along with the dataset itself.",
    "link": "http://arxiv.org/abs/2306.16527",
    "context": "Title: OBELISC: An Open Web-Scale Filtered Dataset of Interleaved Image-Text Documents. (arXiv:2306.16527v1 [cs.IR])\nAbstract: Large multimodal models trained on natural documents, which interleave images and text, outperform models trained on image-text pairs on various multimodal benchmarks that require reasoning over one or multiple images to generate a text. However, the datasets used to train these models have not been released, and the collection process has not been fully specified. We introduce the OBELISC dataset, an open web-scale filtered dataset of interleaved image-text documents comprising 141 million web pages extracted from Common Crawl, 353 million associated images, and 115 billion text tokens. We describe the dataset creation process, present comprehensive filtering rules, and provide an analysis of the dataset's content. To show the viability of OBELISC, we train an 80 billion parameters vision and language model on the dataset and obtain competitive performance on various multimodal benchmarks. We release the code to reproduce the dataset along with the dataset itself.",
    "path": "papers/23/06/2306.16527.json",
    "total_tokens": 910,
    "translated_title": "OBELISC：一个开放的网页规模筛选图像文档数据集",
    "translated_abstract": "在要求对一个或多个图片进行推理生成文本的各种多模态基准测试中，基于自然文档的大规模多模态模型（图像与文本交错）的表现优于基于图像-文本对训练的模型。然而，用于训练这些模型的数据集尚未发布，并且收集过程尚未完全明确。我们介绍了OBELISC数据集，一个由141亿个从Common Crawl提取的网页，3.53亿个相关图像和1150亿个文本标记组成的开放式网页规模筛选的图像文本交错的数据集。我们描述了数据集的创建过程，提供了全面的过滤规则，并对数据集的内容进行了分析。为了展示OBELISC的可行性，我们在数据集上训练了一个80亿参数的视觉和语言模型，并在各种多模态基准测试中获得了有竞争力的性能。我们发布了用于重现数据集的代码以及数据集本身。",
    "tldr": "OBELISC是一个开放的网页规模筛选图像文本数据集，包含141亿个网页，3.53亿个图像和1150亿个文本标记。通过在此数据集上训练一个80亿参数的模型，取得了在多模态基准测试中有竞争力的性能。",
    "en_tdlr": "OBELISC is an open web-scale filtered dataset of interleaved image-text documents, comprising 141 million web pages, 353 million associated images, and 115 billion text tokens. By training a vision and language model with 80 billion parameters on this dataset, competitive performance on various multimodal benchmarks is achieved."
}