{
    "title": "Seeing Seeds Beyond Weeds: Green Teaming Generative AI for Beneficial Uses. (arXiv:2306.03097v1 [cs.HC])",
    "abstract": "Large generative AI models (GMs) like GPT and DALL-E are trained to generate content for general, wide-ranging purposes. GM content filters are generalized to filter out content which has a risk of harm in many cases, e.g., hate speech. However, prohibited content is not always harmful -- there are instances where generating prohibited content can be beneficial. So, when GMs filter out content, they preclude beneficial use cases along with harmful ones. Which use cases are precluded reflects the values embedded in GM content filtering. Recent work on red teaming proposes methods to bypass GM content filters to generate harmful content. We coin the term green teaming to describe methods of bypassing GM content filters to design for beneficial use cases. We showcase green teaming by: 1) Using ChatGPT as a virtual patient to simulate a person experiencing suicidal ideation, for suicide support training; 2) Using Codex to intentionally generate buggy solutions to train students on debuggin",
    "link": "http://arxiv.org/abs/2306.03097",
    "context": "Title: Seeing Seeds Beyond Weeds: Green Teaming Generative AI for Beneficial Uses. (arXiv:2306.03097v1 [cs.HC])\nAbstract: Large generative AI models (GMs) like GPT and DALL-E are trained to generate content for general, wide-ranging purposes. GM content filters are generalized to filter out content which has a risk of harm in many cases, e.g., hate speech. However, prohibited content is not always harmful -- there are instances where generating prohibited content can be beneficial. So, when GMs filter out content, they preclude beneficial use cases along with harmful ones. Which use cases are precluded reflects the values embedded in GM content filtering. Recent work on red teaming proposes methods to bypass GM content filters to generate harmful content. We coin the term green teaming to describe methods of bypassing GM content filters to design for beneficial use cases. We showcase green teaming by: 1) Using ChatGPT as a virtual patient to simulate a person experiencing suicidal ideation, for suicide support training; 2) Using Codex to intentionally generate buggy solutions to train students on debuggin",
    "path": "papers/23/06/2306.03097.json",
    "total_tokens": 987,
    "translated_title": "超越杂草，利用生成式AI的“绿色团队”进行有益的应用",
    "translated_abstract": "大型生成式AI模型（GMs）如GPT和DALL-E的训练目的是为了普遍、广泛的目的生成内容。GM内容过滤器是通用的，可以过滤出在很多情况下存在危害风险的内容，例如仇恨言论。然而，被禁止的内容并不总是有害的——在某些情况下，生成被禁止的内容可能是有益的。因此，当GMs过滤内容时，它们不仅会排除有害的用例，也会排除有益的用例。被排除的用例反映了GM内容过滤中嵌入的价值观。最近的红队工作提出了绕过GM内容过滤器生成有害内容的方法。我们创造了绿色团队这一术语，用来描述绕过GM内容过滤器为有益用例设计的方法。我们通过以下实例展示了绿色团队的应用：1）使用ChatGPT作为虚拟患者，通过模拟患有自杀倾向的人来进行自杀支持培训；2）使用Codex有意地生成有缺陷的解决方法，用于培训学生进行调试。",
    "tldr": "本文介绍了“绿色团队”的概念，旨在用来通过绕过GM内容过滤器设计有益用例。实际应用包括使用ChatGPT进行自杀支持培训以及使用Codex进行有缺陷的解决方案培训。",
    "en_tdlr": "The paper introduces the concept of \"green teaming\" as a method to bypass GM content filters to design beneficial use cases. The practical applications include using ChatGPT for suicide support training and using Codex for buggy solution training."
}