{
    "title": "Latent Dynamical Implicit Diffusion Processes. (arXiv:2306.07077v1 [cs.LG])",
    "abstract": "Latent dynamical models are commonly used to learn the distribution of a latent dynamical process that represents a sequence of noisy data samples. However, producing samples from such models with high fidelity is challenging due to the complexity and variability of latent and observation dynamics. Recent advances in diffusion-based generative models, such as DDPM and NCSN, have shown promising alternatives to state-of-the-art latent generative models, such as Neural ODEs, RNNs, and Normalizing flow networks, for generating high-quality sequential samples from a prior distribution. However, their application in modeling sequential data with latent dynamical models is yet to be explored. Here, we propose a novel latent variable model named latent dynamical implicit diffusion processes (LDIDPs), which utilizes implicit diffusion processes to sample from dynamical latent processes and generate sequential observation samples accordingly. We tested LDIDPs on synthetic and simulated neural d",
    "link": "http://arxiv.org/abs/2306.07077",
    "context": "Title: Latent Dynamical Implicit Diffusion Processes. (arXiv:2306.07077v1 [cs.LG])\nAbstract: Latent dynamical models are commonly used to learn the distribution of a latent dynamical process that represents a sequence of noisy data samples. However, producing samples from such models with high fidelity is challenging due to the complexity and variability of latent and observation dynamics. Recent advances in diffusion-based generative models, such as DDPM and NCSN, have shown promising alternatives to state-of-the-art latent generative models, such as Neural ODEs, RNNs, and Normalizing flow networks, for generating high-quality sequential samples from a prior distribution. However, their application in modeling sequential data with latent dynamical models is yet to be explored. Here, we propose a novel latent variable model named latent dynamical implicit diffusion processes (LDIDPs), which utilizes implicit diffusion processes to sample from dynamical latent processes and generate sequential observation samples accordingly. We tested LDIDPs on synthetic and simulated neural d",
    "path": "papers/23/06/2306.07077.json",
    "total_tokens": 960,
    "translated_title": "潜在动态隐式扩散过程",
    "translated_abstract": "潜在动态模型常被用来学习代表一系列噪声数据样本的潜在动态过程的分布。然而，由于潜在的和观测动态的复杂性和变异性，产生具有高保真度的样本具有挑战性。最近，在基于扩散的生成模型（例如DDPM和NCSN）方面取得的进展，展示了一些有前景的替代方法，适用于从先验分布中生成高质量的序列样本，相较于先进的潜在生成模型（如神经ODE、RNN和正则化流网络）。然而，将它们应用于建模具有潜在动态模型的序列数据尚未被探索。因此，本文提出了一种名为潜在动态隐式扩散过程（LDIDPs）的新型潜在变量模型，利用隐式扩散过程从动态潜在过程中进行采样，然后生成相应的顺序观察样本。我们在合成和模拟神经数据上测试了LDIDPs，并证明它优于最先进的顺序生成模型。",
    "tldr": "本文提出了一种新型的潜在变量模型 LDIDPs，利用隐式扩散过程从动态潜在过程中进行采样，然后生成相应的顺序观察样本，相较于最先进的顺序生成模型有更好的性能。",
    "en_tdlr": "This research proposes a new approach, called Latent Dynamical Implicit Diffusion Processes (LDIDPs), to generate sequential observation samples from a prior distribution using implicit diffusion processes. This outperforms state-of-the-art sequential generative models and can be applied to modeling sequential data with latent dynamical models."
}