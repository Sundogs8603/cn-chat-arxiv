{
    "title": "Fake the Real: Backdoor Attack on Deep Speech Classification via Voice Conversion. (arXiv:2306.15875v1 [cs.SD])",
    "abstract": "Deep speech classification has achieved tremendous success and greatly promoted the emergence of many real-world applications. However, backdoor attacks present a new security threat to it, particularly with untrustworthy third-party platforms, as pre-defined triggers set by the attacker can activate the backdoor. Most of the triggers in existing speech backdoor attacks are sample-agnostic, and even if the triggers are designed to be unnoticeable, they can still be audible. This work explores a backdoor attack that utilizes sample-specific triggers based on voice conversion. Specifically, we adopt a pre-trained voice conversion model to generate the trigger, ensuring that the poisoned samples does not introduce any additional audible noise. Extensive experiments on two speech classification tasks demonstrate the effectiveness of our attack. Furthermore, we analyzed the specific scenarios that activated the proposed backdoor and verified its resistance against fine-tuning.",
    "link": "http://arxiv.org/abs/2306.15875",
    "context": "Title: Fake the Real: Backdoor Attack on Deep Speech Classification via Voice Conversion. (arXiv:2306.15875v1 [cs.SD])\nAbstract: Deep speech classification has achieved tremendous success and greatly promoted the emergence of many real-world applications. However, backdoor attacks present a new security threat to it, particularly with untrustworthy third-party platforms, as pre-defined triggers set by the attacker can activate the backdoor. Most of the triggers in existing speech backdoor attacks are sample-agnostic, and even if the triggers are designed to be unnoticeable, they can still be audible. This work explores a backdoor attack that utilizes sample-specific triggers based on voice conversion. Specifically, we adopt a pre-trained voice conversion model to generate the trigger, ensuring that the poisoned samples does not introduce any additional audible noise. Extensive experiments on two speech classification tasks demonstrate the effectiveness of our attack. Furthermore, we analyzed the specific scenarios that activated the proposed backdoor and verified its resistance against fine-tuning.",
    "path": "papers/23/06/2306.15875.json",
    "total_tokens": 867,
    "translated_title": "通过声音转换对深度语音分类进行后门攻击，真实与虚假之间的较量",
    "translated_abstract": "深度语音分类取得了巨大的成功，并在很大程度上推动了许多现实世界应用的出现。然而，后门攻击对其造成了新的安全威胁，特别是在不可信任的第三方平台上，攻击者预定义的触发器可以激活后门。现有语音后门攻击中的大多数触发器都是与样本无关的，即使这些触发器设计得不可察觉，它们仍然可以听到。本文探索了一种利用基于声音转换的样本特定触发器的后门攻击。具体来说，我们采用预训练的声音转换模型生成触发器，确保毒化样本不引入任何额外的可听噪音。两个语音分类任务上的大量实验证明了我们攻击的有效性。此外，我们分析了激活提出的后门攻击的具体场景，并验证了其对微调的抵抗能力。",
    "tldr": "本文描述了一种使用声音转换生成样本特定触发器的后门攻击方法，有效地绕过了深度语音分类中存在的安全防护措施，并且不会引入额外的可听噪音。",
    "en_tdlr": "This paper presents a backdoor attack method in deep speech classification using sample-specific triggers generated through voice conversion, effectively bypassing existing security measures and without introducing additional audible noise."
}