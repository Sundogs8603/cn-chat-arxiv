{
    "title": "Friend or Foe? Exploring the Implications of Large Language Models on the Science System. (arXiv:2306.09928v1 [cs.CY])",
    "abstract": "The advent of ChatGPT by OpenAI has prompted extensive discourse on its potential implications for science and higher education. While the impact on education has been a primary focus, there is limited empirical research on the effects of large language models (LLMs) and LLM-based chatbots on science and scientific practice. To investigate this further, we conducted a Delphi study involving 72 experts specialising in research and AI. The study focused on applications and limitations of LLMs, their effects on the science system, ethical and legal considerations, and the required competencies for their effective use. Our findings highlight the transformative potential of LLMs in science, particularly in administrative, creative, and analytical tasks. However, risks related to bias, misinformation, and quality assurance need to be addressed through proactive regulation and science education. This research contributes to informed discussions on the impact of generative AI in science and he",
    "link": "http://arxiv.org/abs/2306.09928",
    "context": "Title: Friend or Foe? Exploring the Implications of Large Language Models on the Science System. (arXiv:2306.09928v1 [cs.CY])\nAbstract: The advent of ChatGPT by OpenAI has prompted extensive discourse on its potential implications for science and higher education. While the impact on education has been a primary focus, there is limited empirical research on the effects of large language models (LLMs) and LLM-based chatbots on science and scientific practice. To investigate this further, we conducted a Delphi study involving 72 experts specialising in research and AI. The study focused on applications and limitations of LLMs, their effects on the science system, ethical and legal considerations, and the required competencies for their effective use. Our findings highlight the transformative potential of LLMs in science, particularly in administrative, creative, and analytical tasks. However, risks related to bias, misinformation, and quality assurance need to be addressed through proactive regulation and science education. This research contributes to informed discussions on the impact of generative AI in science and he",
    "path": "papers/23/06/2306.09928.json",
    "total_tokens": 948,
    "translated_title": "是友还是敌？探讨大型语言模型对科学系统的影响。",
    "translated_abstract": "OpenAI开发的ChatGPT的出现引起了广泛的讨论，特别是对于它对科学和高等教育的潜在影响。虽然对教育的影响一直是主要关注的焦点，但对大型语言模型（LLMs）和基于LLMs的聊天机器人对科学和科学实践的影响的实证研究有限。为了进一步调查这个问题，我们进行了一个Delphi研究，涉及72位专门从事研究和人工智能的专家。该研究重点关注LLMs的应用和限制，以及它们对科学系统、伦理和法律考虑因素的影响，以及其有效使用所需的能力。我们的发现突出了LLMs在科学中的变革潜力，特别是在行政、创造性和分析任务方面。然而，与偏见、错误信息和质量保证有关的风险需要通过积极的监管和科学教育加以解决。这项研究为有关生成性人工智能在科学和高等教育中的影响的知情讨论做出了贡献。",
    "tldr": "LLMs有潜力在行政、创造性和分析任务方面对科学做出变革，但需要通过积极的监管和科学教育来解决与偏见、错误信息和质量保证有关的风险。"
}