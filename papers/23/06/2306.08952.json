{
    "title": "Towards Benchmarking and Improving the Temporal Reasoning Capability of Large Language Models. (arXiv:2306.08952v2 [cs.CL] UPDATED)",
    "abstract": "Reasoning about time is of fundamental importance. Many facts are time-dependent. For example, athletes change teams from time to time, and different government officials are elected periodically. Previous time-dependent question answering (QA) datasets tend to be biased in either their coverage of time spans or question types. In this paper, we introduce a comprehensive probing dataset \\tempreason to evaluate the temporal reasoning capability of large language models. Our dataset includes questions of three temporal reasoning levels. In addition, we also propose a novel learning framework to improve the temporal reasoning capability of large language models, based on temporal span extraction and time-sensitive reinforcement learning. We conducted experiments in closed book QA, open book QA, and reasoning QA settings and demonstrated the effectiveness of our approach. Our code and data are released on https://github.com/DAMO-NLP-SG/TempReason.",
    "link": "http://arxiv.org/abs/2306.08952",
    "context": "Title: Towards Benchmarking and Improving the Temporal Reasoning Capability of Large Language Models. (arXiv:2306.08952v2 [cs.CL] UPDATED)\nAbstract: Reasoning about time is of fundamental importance. Many facts are time-dependent. For example, athletes change teams from time to time, and different government officials are elected periodically. Previous time-dependent question answering (QA) datasets tend to be biased in either their coverage of time spans or question types. In this paper, we introduce a comprehensive probing dataset \\tempreason to evaluate the temporal reasoning capability of large language models. Our dataset includes questions of three temporal reasoning levels. In addition, we also propose a novel learning framework to improve the temporal reasoning capability of large language models, based on temporal span extraction and time-sensitive reinforcement learning. We conducted experiments in closed book QA, open book QA, and reasoning QA settings and demonstrated the effectiveness of our approach. Our code and data are released on https://github.com/DAMO-NLP-SG/TempReason.",
    "path": "papers/23/06/2306.08952.json",
    "total_tokens": 874,
    "translated_title": "评估和改进大型语言模型的时间推理能力的基准研究",
    "translated_abstract": "时间推理是非常重要的。许多事实是与时间相关的。例如，运动员会不时地更换球队，不同的政府官员会定期进行选举。先前的时间相关问题回答（QA）数据集往往在时间跨度或问题类型的涵盖上存在偏见。在本文中，我们介绍了一个全面的探测数据集\\tempreason，用于评估大型语言模型的时间推理能力。我们的数据集包括三个时间推理级别的问题。此外，我们还提出了一种基于时间跨度提取和时敏性强化学习的新型学习框架，以改进大型语言模型的时间推理能力。我们在封闭书式QA、开放书式QA和推理QA设置中进行了实验，并证明了我们方法的有效性。我们的代码和数据已在https://github.com/DAMO-NLP-SG/TempReason上发布。",
    "tldr": "本研究提出了一个全面的探测数据集来评估大型语言模型的时间推理能力，并提出了一种使用时间跨度提取和时敏性强化学习的新型学习框架来改进大型语言模型的时间推理能力。实验结果表明该方法的有效性。",
    "en_tdlr": "This study introduces a comprehensive probing dataset to evaluate the temporal reasoning capability of large language models and proposes a novel learning framework using temporal span extraction and time-sensitive reinforcement learning to improve their temporal reasoning ability. Experimental results demonstrate the effectiveness of this approach."
}