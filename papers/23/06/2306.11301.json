{
    "title": "Adversarial Search and Tracking with Multiagent Reinforcement Learning in Sparsely Observable Environment. (arXiv:2306.11301v2 [cs.LG] UPDATED)",
    "abstract": "We study a search and tracking (S&T) problem where a team of dynamic search agents must collaborate to track an adversarial, evasive agent. The heterogeneous search team may only have access to a limited number of past adversary trajectories within a large search space. This problem is challenging for both model-based searching and reinforcement learning (RL) methods since the adversary exhibits reactionary and deceptive evasive behaviors in a large space leading to sparse detections for the search agents. To address this challenge, we propose a novel Multi-Agent RL (MARL) framework that leverages the estimated adversary location from our learnable filtering model. We show that our MARL architecture can outperform all baselines and achieves a 46% increase in detection rate.",
    "link": "http://arxiv.org/abs/2306.11301",
    "context": "Title: Adversarial Search and Tracking with Multiagent Reinforcement Learning in Sparsely Observable Environment. (arXiv:2306.11301v2 [cs.LG] UPDATED)\nAbstract: We study a search and tracking (S&T) problem where a team of dynamic search agents must collaborate to track an adversarial, evasive agent. The heterogeneous search team may only have access to a limited number of past adversary trajectories within a large search space. This problem is challenging for both model-based searching and reinforcement learning (RL) methods since the adversary exhibits reactionary and deceptive evasive behaviors in a large space leading to sparse detections for the search agents. To address this challenge, we propose a novel Multi-Agent RL (MARL) framework that leverages the estimated adversary location from our learnable filtering model. We show that our MARL architecture can outperform all baselines and achieves a 46% increase in detection rate.",
    "path": "papers/23/06/2306.11301.json",
    "total_tokens": 837,
    "translated_title": "在稀疏可观测环境中，使用多智能体强化学习进行对抗搜索和追踪",
    "translated_abstract": "我们研究了一个搜索和追踪问题，其中一个动态搜索团队必须合作追踪一个对抗性的、难以捕捉的代理。异构的搜索团队可能只能在一个大的搜索空间内访问有限数量的过去对手轨迹。由于对手在大空间内表现出反应性和欺骗性的逃避行为，导致搜索代理的检测变得稀疏。为了解决这个挑战，我们提出了一个新颖的多智能体强化学习（MARL）框架，利用我们可学习的过滤模型对对手位置进行估计。我们展示了我们的MARL架构可以超越所有基线方法，并实现了46%的检测率提高。",
    "tldr": "本论文研究了在稀疏可观测环境中的对抗搜索和追踪问题，提出了一个基于多智能体强化学习的框架，利用可学习的过滤模型来估计对手位置，取得了显著的检测率提高。"
}