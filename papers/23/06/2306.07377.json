{
    "title": "Lost in Translation: Large Language Models in Non-English Content Analysis. (arXiv:2306.07377v1 [cs.CL])",
    "abstract": "In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa, Google's PaLM) have become the dominant approach for building AI systems to analyze and generate language online. However, the automated systems that increasingly mediate our interactions online -- such as chatbots, content moderation systems, and search engines -- are primarily designed for and work far more effectively in English than in the world's other 7,000 languages. Recently, researchers and technology companies have attempted to extend the capabilities of large language models into languages other than English by building what are called multilingual language models.  In this paper, we explain how these multilingual language models work and explore their capabilities and limits. Part I provides a simple technical explanation of how large language models work, why there is a gap in available data between English and other languages, and how multilingual language models attempt to bridge that gap. Part ",
    "link": "http://arxiv.org/abs/2306.07377",
    "context": "Title: Lost in Translation: Large Language Models in Non-English Content Analysis. (arXiv:2306.07377v1 [cs.CL])\nAbstract: In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa, Google's PaLM) have become the dominant approach for building AI systems to analyze and generate language online. However, the automated systems that increasingly mediate our interactions online -- such as chatbots, content moderation systems, and search engines -- are primarily designed for and work far more effectively in English than in the world's other 7,000 languages. Recently, researchers and technology companies have attempted to extend the capabilities of large language models into languages other than English by building what are called multilingual language models.  In this paper, we explain how these multilingual language models work and explore their capabilities and limits. Part I provides a simple technical explanation of how large language models work, why there is a gap in available data between English and other languages, and how multilingual language models attempt to bridge that gap. Part ",
    "path": "papers/23/06/2306.07377.json",
    "total_tokens": 1181,
    "translated_title": "语言模型在非英语内容分析中的应用问题",
    "translated_abstract": "近年来，大型语言模型（例如Open AI的GPT-4，Meta的LLaMa，Google的PaLM）已成为构建在线语言智能分析和生成AI系统的主要方法。然而，越来越多的自动化系统中介我们在网上的交互，例如聊天机器人，内容审核系统和搜索引擎，主要是为英语而设计的，而在其他世界上的7000种语言中的效果远远不如英语。近期，研究人员和技术公司试图通过构建多语言语言模型来扩展大型语言模型的能力。本文将解释这些多语言模型的工作方式以及探索它们的能力和局限性。其中，第一部分提供了关于大型语言模型的简单技术解释，英语和其他语言之间可用数据的差距以及多语言语言模型如何试图弥合这一差距。第二部分回顾了最近的研究，探索了多语言模型在实践中的有效性，包括低资源语言应用的案例研究。最后，我们考虑了AI支持的语言技术在世界上许多语言中的传播的伦理学意义，并强调在设计和部署AI系统时需要特别注意权力、不平等和文化差异等问题。",
    "tldr": "大型语言模型目前主要运用于英语内容的智能分析中，多语言模型的发展旨在弥补其他语言数据匮乏的情况。研究人员和技术公司通过构建多语言语言模型尝试解决这一问题并拓展大型语言模型的能力。多语言模型在低资源语言应用中的实践效果也进行研究。总体而言，AI支持的语言技术的设计和部署需要注意权力、不平等和文化差异。",
    "en_tdlr": "Large language models are currently primarily used for analyzing English content, however, multilingual language models are being developed to address the lack of data for other languages. Researchers and technology companies are building multilingual language models to expand the capabilities of large language models and their effectiveness in low-resourced languages have been studied. The ethical implications of AI-powered language technologies across different languages should also be carefully considered."
}