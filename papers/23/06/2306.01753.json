{
    "title": "Preconditioned Visual Language Inference with Weak Supervision. (arXiv:2306.01753v1 [cs.CL])",
    "abstract": "Humans can infer the affordance of objects by extracting related contextual preconditions for each scenario. For example, upon seeing an image of a broken cup, we can infer that this precondition prevents the cup from being used for drinking. Reasoning with preconditions of commonsense is studied in NLP where the model explicitly gets the contextual precondition. However, it is unclear if SOTA visual language models (VLMs) can extract such preconditions and infer the affordance of objects with them. In this work, we introduce the task of preconditioned visual language inference and rationalization (PVLIR). We propose a learning resource based on three strategies to retrieve weak supervision signals for the task and develop a human-verified test set for evaluation. Our results reveal the shortcomings of SOTA VLM models in the task and draw a road map to address the challenges ahead in improving them.",
    "link": "http://arxiv.org/abs/2306.01753",
    "context": "Title: Preconditioned Visual Language Inference with Weak Supervision. (arXiv:2306.01753v1 [cs.CL])\nAbstract: Humans can infer the affordance of objects by extracting related contextual preconditions for each scenario. For example, upon seeing an image of a broken cup, we can infer that this precondition prevents the cup from being used for drinking. Reasoning with preconditions of commonsense is studied in NLP where the model explicitly gets the contextual precondition. However, it is unclear if SOTA visual language models (VLMs) can extract such preconditions and infer the affordance of objects with them. In this work, we introduce the task of preconditioned visual language inference and rationalization (PVLIR). We propose a learning resource based on three strategies to retrieve weak supervision signals for the task and develop a human-verified test set for evaluation. Our results reveal the shortcomings of SOTA VLM models in the task and draw a road map to address the challenges ahead in improving them.",
    "path": "papers/23/06/2306.01753.json",
    "total_tokens": 846,
    "translated_title": "弱监督下的预处理视觉语言推理",
    "translated_abstract": "人类可以通过提取每种情境下相关的前提条件来推断物体的可供性。例如，看到一张破碎杯子的照片，我们可以推断这个前提条件阻止了杯子用于饮用。自然语言处理领域研究中，模型明确获取上下文前提条件来推理常识。但是，目前最先进的视觉语言模型是否能够提取这样的前提条件并推断物体的可供性尚不清楚。本文提出了一个名为PVLIR的预处理视觉语言推理和合理化任务，并开发了三个策略的学习资源来检索该任务的弱监督信号，并制定了经过人工验证的测试集进行评估。我们的结果揭示了最先进的视觉语言模型在这项任务上的缺陷，并绘制了未来改进这些模型面临的挑战的路线图。",
    "tldr": "本文提出了一个名为PVLIR的预处理视觉语言推理和合理化任务，结果揭示了当前最先进的视觉语言模型在此项任务上的缺陷，并提出了改进这些模型的挑战。",
    "en_tdlr": "This paper introduces the task of preconditioned visual language inference and rationalization (PVLIR), reveals the shortcomings of current state-of-the-art visual language models in this task, and presents a roadmap for addressing the challenges of improving these models."
}