{
    "title": "The Survey, Taxonomy, and Future Directions of Trustworthy AI: A Meta Decision of Strategic Decisions. (arXiv:2306.00380v1 [cs.AI])",
    "abstract": "When making strategic decisions, we are often confronted with overwhelming information to process. The situation can be further complicated when some pieces of evidence are contradicted each other or paradoxical. The challenge then becomes how to determine which information is useful and which ones should be eliminated. This process is known as meta-decision. Likewise, when it comes to using Artificial Intelligence (AI) systems for strategic decision-making, placing trust in the AI itself becomes a meta-decision, given that many AI systems are viewed as opaque \"black boxes\" that process large amounts of data. Trusting an opaque system involves deciding on the level of Trustworthy AI (TAI). We propose a new approach to address this issue by introducing a novel taxonomy or framework of TAI, which encompasses three crucial domains: articulate, authentic, and basic for different levels of trust. To underpin these domains, we create ten dimensions to measure trust: explainability/transparen",
    "link": "http://arxiv.org/abs/2306.00380",
    "context": "Title: The Survey, Taxonomy, and Future Directions of Trustworthy AI: A Meta Decision of Strategic Decisions. (arXiv:2306.00380v1 [cs.AI])\nAbstract: When making strategic decisions, we are often confronted with overwhelming information to process. The situation can be further complicated when some pieces of evidence are contradicted each other or paradoxical. The challenge then becomes how to determine which information is useful and which ones should be eliminated. This process is known as meta-decision. Likewise, when it comes to using Artificial Intelligence (AI) systems for strategic decision-making, placing trust in the AI itself becomes a meta-decision, given that many AI systems are viewed as opaque \"black boxes\" that process large amounts of data. Trusting an opaque system involves deciding on the level of Trustworthy AI (TAI). We propose a new approach to address this issue by introducing a novel taxonomy or framework of TAI, which encompasses three crucial domains: articulate, authentic, and basic for different levels of trust. To underpin these domains, we create ten dimensions to measure trust: explainability/transparen",
    "path": "papers/23/06/2306.00380.json",
    "total_tokens": 1215,
    "translated_title": "可信人工智能的调查、分类及未来方向：元决策的战略决策元分析",
    "translated_abstract": "在制定战略决策时，我们常常面临着大量需要处理的信息。当一些证据相互矛盾或自相矛盾时，情况可能会更加复杂。此时，问题在于如何确定哪些信息是有用的，哪些应该被排除。这个过程被称为元决策。同样，在使用人工智能（AI）系统进行战略决策时，对AI本身的信任就成为了一个元决策，因为许多AI系统被视为处理大量数据的不透明“黑匣子”。信任一个不透明的系统涉及决定什么样的可信人工智能（TAI）水平。我们提出了一种新方法来解决这个问题，即引入一个新颖的TAI分类系统或框架，该框架包括三个关键领域：表达、真实和基本水平的不同信任级别。为了支撑这些领域，我们创建了十个维度来衡量信任：可解释性/透明性、无偏性、问责制、准确性、可靠性、隐私、安全、公平性和人类控制。在本文中，我们提供了一个现有TAI研究的调查和元分析，以全面了解这一新兴领域的研究现状。我们还确定了TAI研究的未来方向，并提出了一些潜在应用，这些应用可能从TAI的使用中受益。",
    "tldr": "本文提出了一个新方法来解决在使用AI系统进行决策时的可信问题。该方法引入了一个包括表达、真实和基本水平的不同信任级别的TAI分类系统或框架，使用十个维度来衡量信任，并提供了现有TAI研究的调查和元分析，还确定了TAI研究的未来方向和潜在应用。",
    "en_tdlr": "This paper proposes a new approach to address the issue of trust in AI systems for decision-making by introducing a novel taxonomy or framework of Trustworthy AI (TAI) which encompasses articulate, authentic, and basic domains for different levels of trust. The paper presents a survey and meta-analysis of existing TAI research, identifies future research directions and potential applications that could benefit from TAI."
}