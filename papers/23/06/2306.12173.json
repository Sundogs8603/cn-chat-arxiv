{
    "title": "Mixture Encoder for Joint Speech Separation and Recognition. (arXiv:2306.12173v1 [cs.CL])",
    "abstract": "Multi-speaker automatic speech recognition (ASR) is crucial for many real-world applications, but it requires dedicated modeling techniques. Existing approaches can be divided into modular and end-to-end methods. Modular approaches separate speakers and recognize each of them with a single-speaker ASR system. End-to-end models process overlapped speech directly in a single, powerful neural network. This work proposes a middle-ground approach that leverages explicit speech separation similarly to the modular approach but also incorporates mixture speech information directly into the ASR module in order to mitigate the propagation of errors made by the speech separator. We also explore a way to exchange cross-speaker context information through a layer that combines information of the individual speakers. Our system is optimized through separate and joint training stages and achieves a relative improvement of 7% in word error rate over a purely modular setup on the SMS-WSJ task.",
    "link": "http://arxiv.org/abs/2306.12173",
    "context": "Title: Mixture Encoder for Joint Speech Separation and Recognition. (arXiv:2306.12173v1 [cs.CL])\nAbstract: Multi-speaker automatic speech recognition (ASR) is crucial for many real-world applications, but it requires dedicated modeling techniques. Existing approaches can be divided into modular and end-to-end methods. Modular approaches separate speakers and recognize each of them with a single-speaker ASR system. End-to-end models process overlapped speech directly in a single, powerful neural network. This work proposes a middle-ground approach that leverages explicit speech separation similarly to the modular approach but also incorporates mixture speech information directly into the ASR module in order to mitigate the propagation of errors made by the speech separator. We also explore a way to exchange cross-speaker context information through a layer that combines information of the individual speakers. Our system is optimized through separate and joint training stages and achieves a relative improvement of 7% in word error rate over a purely modular setup on the SMS-WSJ task.",
    "path": "papers/23/06/2306.12173.json",
    "total_tokens": 895,
    "translated_title": "联合语音分离与识别的混合编码器",
    "translated_abstract": "多说话人自动语音识别对于许多现实世界的应用程序至关重要，但需要特定的建模技术。现有的方法可以分为模块化和端到端方法。模块化方法使用单说话人ASR系统分离说话人并识别他们。端到端模型直接在一个强大的神经网络中处理重叠的语音。本文提出了一种介于两者之间的方法，利用类似于模块化方法的显式语音分离，但也直接在ASR模块中合并混合语音信息，以减轻语音分离器造成的错误传播。我们还探索了一种通过结合个体说话人信息的层来交换跨说话者上下文信息的方法。我们的系统通过单独和联合训练阶段进行优化，在SMS-WSJ任务上相对于纯模块化设置的单词错误率实现了7%的相对改进。",
    "tldr": "本论文提出了一种中间方法，同时利用显式语音分离和直接在ASR模块中合并混合语音信息，通过交换跨说话者上下文信息的层，实现了在SMS-WSJ任务上相对于纯模块化设置的单词错误率7%的相对改进。",
    "en_tdlr": "This paper proposes a middle-ground approach that utilizes both explicit speech separation and direct merging of mixed speech information in the ASR module to achieve a relative improvement of 7% in word error rate over a purely modular setup on the SMS-WSJ task, by exchanging cross-speaker context information through a layer that combines information of the individual speakers."
}