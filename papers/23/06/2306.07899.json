{
    "title": "Artificial Artificial Artificial Intelligence: Crowd Workers Widely Use Large Language Models for Text Production Tasks. (arXiv:2306.07899v1 [cs.CL])",
    "abstract": "Large language models (LLMs) are remarkable data annotators. They can be used to generate high-fidelity supervised training data, as well as survey and experimental data. With the widespread adoption of LLMs, human gold--standard annotations are key to understanding the capabilities of LLMs and the validity of their results. However, crowdsourcing, an important, inexpensive way to obtain human annotations, may itself be impacted by LLMs, as crowd workers have financial incentives to use LLMs to increase their productivity and income. To investigate this concern, we conducted a case study on the prevalence of LLM usage by crowd workers. We reran an abstract summarization task from the literature on Amazon Mechanical Turk and, through a combination of keystroke detection and synthetic text classification, estimate that 33-46% of crowd workers used LLMs when completing the task. Although generalization to other, less LLM-friendly tasks is unclear, our results call for platforms, researche",
    "link": "http://arxiv.org/abs/2306.07899",
    "context": "Title: Artificial Artificial Artificial Intelligence: Crowd Workers Widely Use Large Language Models for Text Production Tasks. (arXiv:2306.07899v1 [cs.CL])\nAbstract: Large language models (LLMs) are remarkable data annotators. They can be used to generate high-fidelity supervised training data, as well as survey and experimental data. With the widespread adoption of LLMs, human gold--standard annotations are key to understanding the capabilities of LLMs and the validity of their results. However, crowdsourcing, an important, inexpensive way to obtain human annotations, may itself be impacted by LLMs, as crowd workers have financial incentives to use LLMs to increase their productivity and income. To investigate this concern, we conducted a case study on the prevalence of LLM usage by crowd workers. We reran an abstract summarization task from the literature on Amazon Mechanical Turk and, through a combination of keystroke detection and synthetic text classification, estimate that 33-46% of crowd workers used LLMs when completing the task. Although generalization to other, less LLM-friendly tasks is unclear, our results call for platforms, researche",
    "path": "papers/23/06/2306.07899.json",
    "total_tokens": 922,
    "translated_title": "人工人工智能：众包工人广泛使用大型语言模型进行文本生成任务",
    "translated_abstract": "大型语言模型（LLMs）是非常出色的数据标注工具，它们可以用于生成高保真度的监督式训练数据，以及调查和实验数据。随着LLMs的广泛采用，人类黄金标准注释对于理解LLMs的能力和其结果的有效性至关重要。然而，众包是获取人类注释的一种重要、廉价的方式，但众包工人有通过使用LLMs来增加其生产率和收入的财务激励，这可能会影响他们的注释。为了调查这个问题，我们对众包工人使用LLMs的普遍性进行了案例研究。我们在Amazon Mechanical Turk上重新运行了一项文摘任务，并通过击键检测和合成文本分类的组合，估计33-46%的众包工人在完成任务时使用了LLMs。尽管对于其他不太友好的LLM任务的泛化尚不清楚，我们的结果呼吁平台、研究人员和从事标注的人们更加警惕LLM相关的问题。",
    "tldr": "该研究调查了众包工人使用大型语言模型的普遍性，结果发现33-46%的众包工人在完成任务时使用了LLMs，我们需要更加警惕这类问题。",
    "en_tdlr": "This study investigates the prevalence of the use of large language models (LLMs) by crowd workers and finds that 33-46% of workers use LLMs to complete tasks, highlighting the need to be cautious about this issue."
}