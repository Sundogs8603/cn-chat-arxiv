{
    "title": "Input-sensitive dense-sparse primitive compositions for GNN acceleration. (arXiv:2306.15155v1 [cs.LG])",
    "abstract": "Graph neural networks (GNN) have become an important class of neural network models that have gained popularity in domains such as social and financial network analysis. Different phases of GNN computations can be modeled using both dense and sparse matrix operations. There have been many frameworks and optimization techniques proposed in the literature to accelerate GNNs. However, getting consistently high performance across many input graphs with different sparsity patterns and GNN embedding sizes has remained difficult.  In this paper, we propose different algebraic reassociations of GNN computations that lead to novel dense and sparse matrix primitive selections and compositions. We show that the profitability of these compositions depends on the input graph, embedding size, and the target hardware. We developed SENSEi, a system that uses a data-driven adaptive strategy to select the best composition given the input graph and GNN embedding sizes. Our evaluations on a wide range of ",
    "link": "http://arxiv.org/abs/2306.15155",
    "context": "Title: Input-sensitive dense-sparse primitive compositions for GNN acceleration. (arXiv:2306.15155v1 [cs.LG])\nAbstract: Graph neural networks (GNN) have become an important class of neural network models that have gained popularity in domains such as social and financial network analysis. Different phases of GNN computations can be modeled using both dense and sparse matrix operations. There have been many frameworks and optimization techniques proposed in the literature to accelerate GNNs. However, getting consistently high performance across many input graphs with different sparsity patterns and GNN embedding sizes has remained difficult.  In this paper, we propose different algebraic reassociations of GNN computations that lead to novel dense and sparse matrix primitive selections and compositions. We show that the profitability of these compositions depends on the input graph, embedding size, and the target hardware. We developed SENSEi, a system that uses a data-driven adaptive strategy to select the best composition given the input graph and GNN embedding sizes. Our evaluations on a wide range of ",
    "path": "papers/23/06/2306.15155.json",
    "total_tokens": 858,
    "translated_title": "针对GNN加速的输入敏感的稠密-稀疏基本组成元素",
    "translated_abstract": "图神经网络（GNN）已成为一类重要的神经网络模型，在社交和金融网络分析等领域越来越受欢迎。GNN计算的不同阶段可以使用稠密和稀疏矩阵运算来建模。文献中已经提出了许多框架和优化技术来加速GNN。然而，在许多具有不同稀疏模式和GNN嵌入大小的输入图上实现一致高性能仍然困难。在本文中，我们提出了对GNN计算进行不同的代数重组，导致了新的密集和稀疏矩阵基本选择和组合。我们表明，这些组合的盈利能力取决于输入图、嵌入大小和目标硬件。我们开发了一个名为SENSEi的系统，它使用数据驱动的自适应策略来选择给定输入图和GNN嵌入大小的最佳组合。我们在广泛的范围上进行了评估。",
    "tldr": "本文提出了一种在不同的输入图和GNN嵌入大小上使用代数重组的方法，通过选择最佳组合来提高GNN加速的性能。"
}