{
    "title": "Exploring the Responses of Large Language Models to Beginner Programmers' Help Requests. (arXiv:2306.05715v1 [cs.CY])",
    "abstract": "Background and Context: Over the past year, large language models (LLMs) have taken the world by storm. In computing education, like in other walks of life, many opportunities and threats have emerged as a consequence.  Objectives: In this article, we explore such opportunities and threats in a specific area: responding to student programmers' help requests. More specifically, we assess how good LLMs are at identifying issues in problematic code that students request help on.  Method: We collected a sample of help requests and code from an online programming course. We then prompted two different LLMs (OpenAI Codex and GPT-3.5) to identify and explain the issues in the students' code and assessed the LLM-generated answers both quantitatively and qualitatively.  Findings: GPT-3.5 outperforms Codex in most respects. Both LLMs frequently find at least one actual issue in each student program (GPT-3.5 in 90% of the cases). Neither LLM excels at finding all the issues (GPT-3.5 finding them ",
    "link": "http://arxiv.org/abs/2306.05715",
    "context": "Title: Exploring the Responses of Large Language Models to Beginner Programmers' Help Requests. (arXiv:2306.05715v1 [cs.CY])\nAbstract: Background and Context: Over the past year, large language models (LLMs) have taken the world by storm. In computing education, like in other walks of life, many opportunities and threats have emerged as a consequence.  Objectives: In this article, we explore such opportunities and threats in a specific area: responding to student programmers' help requests. More specifically, we assess how good LLMs are at identifying issues in problematic code that students request help on.  Method: We collected a sample of help requests and code from an online programming course. We then prompted two different LLMs (OpenAI Codex and GPT-3.5) to identify and explain the issues in the students' code and assessed the LLM-generated answers both quantitatively and qualitatively.  Findings: GPT-3.5 outperforms Codex in most respects. Both LLMs frequently find at least one actual issue in each student program (GPT-3.5 in 90% of the cases). Neither LLM excels at finding all the issues (GPT-3.5 finding them ",
    "path": "papers/23/06/2306.05715.json",
    "total_tokens": 984,
    "translated_title": "探究大型语言模型对初学者程序员求助请求的回应",
    "translated_abstract": "背景和背景：在过去的一年中，大型语言模型（LLM）席卷全球。在计算机教育中，就像在生活的其他方面一样，许多机遇和威胁出现了。目标：本文中，我们探讨了一个特定领域中的机遇和威胁：回应学生程序员的求助请求。更具体地说，我们评估了LLM在识别学生请求帮助的问题代码方面的能力。方法：我们从在线编程课程中收集了求助请求和代码样本。然后促使两个不同的LLM（OpenAI Codex和GPT-3.5）识别和解释学生代码中的问题，并定量和定性评估了LLM生成的答案。发现：GPT-3.5在大多数方面表现优于Codex。两个LLM经常在每个学生程序中找到至少一个实际问题（GPT-3.5在90％的情况下） 。",
    "tldr": "研究探究了大型语言模型（LLMs）对学生程序员求助请求的回应能力，评估了其在识别学生问题代码方面的表现。GPT-3.5在大多数方面表现优于Codex，两个LLM经常在每个学生程序中找到至少一个实际问题，但都未能找到全部问题。",
    "en_tdlr": "This paper explores the response capabilities of large language models (LLMs) to student programmer help requests and evaluates their ability to identify issues in problematic code. GPT-3.5 outperforms Codex in most respects and both LLMs frequently find at least one actual issue in each student program, but neither excels at finding all issues."
}