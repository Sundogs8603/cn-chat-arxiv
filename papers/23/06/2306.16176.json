{
    "title": "SkillNet-X: A Multilingual Multitask Model with Sparsely Activated Skills. (arXiv:2306.16176v1 [cs.CL])",
    "abstract": "Traditional multitask learning methods basically can only exploit common knowledge in task- or language-wise, which lose either cross-language or cross-task knowledge. This paper proposes a general multilingual multitask model, named SkillNet-X, which enables a single model to tackle many different tasks from different languages. To this end, we define several language-specific skills and task-specific skills, each of which corresponds to a skill module. SkillNet-X sparsely activates parts of the skill modules which are relevant either to the target task or the target language. Acting as knowledge transit hubs, skill modules are capable of absorbing task-related knowledge and language-related knowledge consecutively. Based on Transformer, we modify the multi-head attention layer and the feed forward network layer to accommodate skill modules. We evaluate SkillNet-X on eleven natural language understanding datasets in four languages. Results show that SkillNet-X performs better than tas",
    "link": "http://arxiv.org/abs/2306.16176",
    "context": "Title: SkillNet-X: A Multilingual Multitask Model with Sparsely Activated Skills. (arXiv:2306.16176v1 [cs.CL])\nAbstract: Traditional multitask learning methods basically can only exploit common knowledge in task- or language-wise, which lose either cross-language or cross-task knowledge. This paper proposes a general multilingual multitask model, named SkillNet-X, which enables a single model to tackle many different tasks from different languages. To this end, we define several language-specific skills and task-specific skills, each of which corresponds to a skill module. SkillNet-X sparsely activates parts of the skill modules which are relevant either to the target task or the target language. Acting as knowledge transit hubs, skill modules are capable of absorbing task-related knowledge and language-related knowledge consecutively. Based on Transformer, we modify the multi-head attention layer and the feed forward network layer to accommodate skill modules. We evaluate SkillNet-X on eleven natural language understanding datasets in four languages. Results show that SkillNet-X performs better than tas",
    "path": "papers/23/06/2306.16176.json",
    "total_tokens": 851,
    "translated_title": "SkillNet-X：一种具有稀疏激活技能的多语言多任务模型",
    "translated_abstract": "传统的多任务学习方法只能在任务或语言上利用通用知识，即失去了跨语言或跨任务的知识。本文提出了一种名为SkillNet-X的通用多语言多任务模型，能够通过单一模型处理来自不同语言的多个不同任务。为此，我们定义了几个语言特定的技能和任务特定的技能，每个技能对应一个技能模块。SkillNet-X稀疏激活与目标任务或目标语言相关的技能模块的部分。作为知识传递中心，技能模块能够连续吸收与任务相关的知识和语言相关的知识。基于Transformer，我们修改了多头注意力层和前馈网络层以适应技能模块。我们在四种语言的十一个自然语言理解数据集上评估了SkillNet-X。结果表明，SkillNet-X的性能优于单独针对每个任务的多任务学习方法。",
    "tldr": "学术论文提出了一种名为SkillNet-X的多语言多任务模型，通过稀疏激活相关的技能模块，能够在不同语言的多个任务上表现出更好的性能。"
}