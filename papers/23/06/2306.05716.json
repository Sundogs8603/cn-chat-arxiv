{
    "title": "Pave the Way to Grasp Anything: Transferring Foundation Models for Universal Pick-Place Robots. (arXiv:2306.05716v1 [cs.RO])",
    "abstract": "Improving the generalization capabilities of general-purpose robotic agents has long been a significant challenge actively pursued by research communities. Existing approaches often rely on collecting large-scale real-world robotic data, such as the RT-1 dataset. However, these approaches typically suffer from low efficiency, limiting their capability in open-domain scenarios with new objects, and diverse backgrounds. In this paper, we propose a novel paradigm that effectively leverages language-grounded segmentation masks generated by state-of-the-art foundation models, to address a wide range of pick-and-place robot manipulation tasks in everyday scenarios. By integrating precise semantics and geometries conveyed from masks into our multi-view policy model, our approach can perceive accurate object poses and enable sample-efficient learning. Besides, such design facilitates effective generalization for grasping new objects with similar shapes observed during training. Our approach co",
    "link": "http://arxiv.org/abs/2306.05716",
    "context": "Title: Pave the Way to Grasp Anything: Transferring Foundation Models for Universal Pick-Place Robots. (arXiv:2306.05716v1 [cs.RO])\nAbstract: Improving the generalization capabilities of general-purpose robotic agents has long been a significant challenge actively pursued by research communities. Existing approaches often rely on collecting large-scale real-world robotic data, such as the RT-1 dataset. However, these approaches typically suffer from low efficiency, limiting their capability in open-domain scenarios with new objects, and diverse backgrounds. In this paper, we propose a novel paradigm that effectively leverages language-grounded segmentation masks generated by state-of-the-art foundation models, to address a wide range of pick-and-place robot manipulation tasks in everyday scenarios. By integrating precise semantics and geometries conveyed from masks into our multi-view policy model, our approach can perceive accurate object poses and enable sample-efficient learning. Besides, such design facilitates effective generalization for grasping new objects with similar shapes observed during training. Our approach co",
    "path": "papers/23/06/2306.05716.json",
    "total_tokens": 876,
    "translated_title": "为抓住任何物品铺平道路：基于迁移学习的通用抓取放置机器人模型",
    "translated_abstract": "提高通用型机器人的泛化能力一直是研究社区长期追求的重要挑战。现有的方法通常依赖于收集大规模现实世界机器人数据，如 RT-1 数据集。然而，这些方法通常效率低下，限制了它们在具有新对象和多样背景的开放域场景中的能力。本文提出了一种新的范例，有效地利用最先进的基础模型生成的基于语言的分割掩模，以解决日常场景中广泛的拾放机器人操作任务。通过将掩模传达的精确语义和几何形状集成到我们的多视角策略模型中，我们的方法可以感知准确的物体姿态并实现高效学习，同时也有助于有效的新对象的推广。我们的方法同时可以实现在训练时观察到相似形状的新物体的抓取操作。",
    "tldr": "本研究提出了一种基于语言分割掩模的新方法，用于解决通用型机器人的泛化能力问题，提高了在开放域场景中新对象的抓取操作的学习效率和推广效果。",
    "en_tdlr": "This study proposes a novel approach based on language-grounded segmentation masks to address the generalization capability issues of general-purpose robotic agents, improving the learning efficiency and generalization effect for grasping new objects in open-domain scenarios."
}