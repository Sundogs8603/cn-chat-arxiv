{
    "title": "Efficient Contextformer: Spatio-Channel Window Attention for Fast Context Modeling in Learned Image Compression",
    "abstract": "arXiv:2306.14287v2 Announce Type: replace-cross  Abstract: Entropy estimation is essential for the performance of learned image compression. It has been demonstrated that a transformer-based entropy model is of critical importance for achieving a high compression ratio, however, at the expense of a significant computational effort. In this work, we introduce the Efficient Contextformer (eContextformer) - a computationally efficient transformer-based autoregressive context model for learned image compression. The eContextformer efficiently fuses the patch-wise, checkered, and channel-wise grouping techniques for parallel context modeling, and introduces a shifted window spatio-channel attention mechanism. We explore better training strategies and architectural designs and introduce additional complexity optimizations. During decoding, the proposed optimization techniques dynamically scale the attention span and cache the previous attention computations, drastically reducing the model an",
    "link": "https://arxiv.org/abs/2306.14287",
    "context": "Title: Efficient Contextformer: Spatio-Channel Window Attention for Fast Context Modeling in Learned Image Compression\nAbstract: arXiv:2306.14287v2 Announce Type: replace-cross  Abstract: Entropy estimation is essential for the performance of learned image compression. It has been demonstrated that a transformer-based entropy model is of critical importance for achieving a high compression ratio, however, at the expense of a significant computational effort. In this work, we introduce the Efficient Contextformer (eContextformer) - a computationally efficient transformer-based autoregressive context model for learned image compression. The eContextformer efficiently fuses the patch-wise, checkered, and channel-wise grouping techniques for parallel context modeling, and introduces a shifted window spatio-channel attention mechanism. We explore better training strategies and architectural designs and introduce additional complexity optimizations. During decoding, the proposed optimization techniques dynamically scale the attention span and cache the previous attention computations, drastically reducing the model an",
    "path": "papers/23/06/2306.14287.json",
    "total_tokens": 821,
    "translated_title": "高效Contextformer：用于学习图像压缩中快速上下文建模的时空通道窗口注意力",
    "translated_abstract": "熵估计对于学习图像压缩的性能至关重要。已经证明，基于Transformer的熵模型对于实现高压缩比至关重要，但是需要付出巨大的计算代价。在本研究中，我们引入了高效Contextformer（eContextformer）- 一种用于学习图像压缩的计算效率高的基于Transformer的自回归上下文模型。eContextformer有效地融合了基于块、棋盘格和通道的分组技术，用于并行上下文建模，并引入了一种移位窗口时空通道注意力机制。我们探索了更好的训练策略和架构设计，并引入了额外的复杂性优化。在解码过程中，所提出的优化技术动态调整注意力范围并缓存先前的注意力计算，极大地减少了模型的计算成本。",
    "tldr": "提出了高效Contextformer，采用了时空通道窗口注意力机制，用于学习图像压缩中快速上下文建模，并引入了优化技术来降低计算成本",
    "en_tdlr": "Introduced the Efficient Contextformer with spatio-channel window attention for fast context modeling in learned image compression, along with optimization techniques to reduce computational cost."
}