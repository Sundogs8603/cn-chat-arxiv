{
    "title": "AI Transparency in the Age of LLMs: A Human-Centered Research Roadmap. (arXiv:2306.01941v2 [cs.HC] UPDATED)",
    "abstract": "The rise of powerful large language models (LLMs) brings about tremendous opportunities for innovation but also looming risks for individuals and society at large. We have reached a pivotal moment for ensuring that LLMs and LLM-infused applications are developed and deployed responsibly. However, a central pillar of responsible AI -- transparency -- is largely missing from the current discourse around LLMs. It is paramount to pursue new approaches to provide transparency for LLMs, and years of research at the intersection of AI and human-computer interaction (HCI) highlight that we must do so with a human-centered perspective: Transparency is fundamentally about supporting appropriate human understanding, and this understanding is sought by different stakeholders with different goals in different contexts. In this new era of LLMs, we must develop and design approaches to transparency by considering the needs of stakeholders in the emerging LLM ecosystem, the novel types of LLM-infused ",
    "link": "http://arxiv.org/abs/2306.01941",
    "context": "Title: AI Transparency in the Age of LLMs: A Human-Centered Research Roadmap. (arXiv:2306.01941v2 [cs.HC] UPDATED)\nAbstract: The rise of powerful large language models (LLMs) brings about tremendous opportunities for innovation but also looming risks for individuals and society at large. We have reached a pivotal moment for ensuring that LLMs and LLM-infused applications are developed and deployed responsibly. However, a central pillar of responsible AI -- transparency -- is largely missing from the current discourse around LLMs. It is paramount to pursue new approaches to provide transparency for LLMs, and years of research at the intersection of AI and human-computer interaction (HCI) highlight that we must do so with a human-centered perspective: Transparency is fundamentally about supporting appropriate human understanding, and this understanding is sought by different stakeholders with different goals in different contexts. In this new era of LLMs, we must develop and design approaches to transparency by considering the needs of stakeholders in the emerging LLM ecosystem, the novel types of LLM-infused ",
    "path": "papers/23/06/2306.01941.json",
    "total_tokens": 903,
    "translated_title": "LLM时代的人工智能透明度：以人为中心的研究路线图",
    "translated_abstract": "强大的大型语言模型(LLMs)的兴起带来了巨大的创新机会，但也存在着对个人和社会的潜在风险。确保负责任地开发和部署LLMs和基于LLMs的应用程序变得至关重要。然而，负责任人工智能的核心支柱--透明度--在当前关于LLMs的讨论中大部分都缺失了。追求新的透明度方法对于LLMs至关重要，多年来在人工智能和人机交互(HCI)交叉领域的研究表明，我们必须以人为中心的视角来做到这一点：透明度基本上是支持适当人类理解的问题，不同利益相关者在不同环境下追求不同目标的理解。在这个新的LLM时代，我们必须考虑新兴LLM生态系统中利益相关者的需求，开发和设计透明度的方法。",
    "tldr": "在当前LLMs话题的讨论中，负责任人工智能的关键要素--透明度--被忽视了。这篇论文提出了在以人为中心的视角下，追求LLMs的透明度对于支持适当的人类理解是至关重要的。",
    "en_tdlr": "In the current discourse around LLMs, the key element of responsible AI - transparency - is being overlooked. This paper emphasizes the importance of pursuing transparency in LLMs from a human-centered perspective to support appropriate human understanding."
}