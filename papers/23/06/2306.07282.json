{
    "title": "Waffling around for Performance: Visual Classification with Random Words and Broad Concepts. (arXiv:2306.07282v2 [cs.CV] UPDATED)",
    "abstract": "The visual classification performance of vision-language models such as CLIP has been shown to benefit from additional semantic knowledge from large language models (LLMs) such as GPT-3. In particular, averaging over LLM-generated class descriptors, e.g. \"waffle, which has a round shape\", can notably improve generalization performance. In this work, we critically study this behavior and propose WaffleCLIP, a framework for zero-shot visual classification which simply replaces LLM-generated descriptors with random character and word descriptors. Without querying external models, we achieve comparable performance gains on a large number of visual classification tasks. This allows WaffleCLIP to both serve as a low-cost alternative, as well as a sanity check for any future LLM-based vision-language model extensions. We conduct an extensive experimental study on the impact and shortcomings of additional semantics introduced with LLM-generated descriptors, and showcase how - if available - se",
    "link": "http://arxiv.org/abs/2306.07282",
    "context": "Title: Waffling around for Performance: Visual Classification with Random Words and Broad Concepts. (arXiv:2306.07282v2 [cs.CV] UPDATED)\nAbstract: The visual classification performance of vision-language models such as CLIP has been shown to benefit from additional semantic knowledge from large language models (LLMs) such as GPT-3. In particular, averaging over LLM-generated class descriptors, e.g. \"waffle, which has a round shape\", can notably improve generalization performance. In this work, we critically study this behavior and propose WaffleCLIP, a framework for zero-shot visual classification which simply replaces LLM-generated descriptors with random character and word descriptors. Without querying external models, we achieve comparable performance gains on a large number of visual classification tasks. This allows WaffleCLIP to both serve as a low-cost alternative, as well as a sanity check for any future LLM-based vision-language model extensions. We conduct an extensive experimental study on the impact and shortcomings of additional semantics introduced with LLM-generated descriptors, and showcase how - if available - se",
    "path": "papers/23/06/2306.07282.json",
    "total_tokens": 988,
    "translated_title": "在性能方面摇摆不定：使用随机单词和广义概念进行视觉分类",
    "translated_abstract": "已经证明，诸如CLIP之类的视觉语言模型的视觉分类性能可以受益于大型语言模型（LLM）（如GPT-3）的额外语义知识。特别是在LLM生成的类别描述符中进行平均，例如“具有圆形形状的华夫饼”，可以显著提高泛化性能。在这项工作中，我们对这种行为进行了批判性研究，并提出了WaffleCLIP，这是一个零样本视觉分类框架，它仅用随机字符和单词描述符替换LLM生成的描述符。在不查询外部模型的情况下，我们在大量视觉分类任务上实现了可比较的性能增益。这使得WaffleCLIP既可以作为一种低成本替代，也可以作为未来基于LLM的视觉语言模型扩展的一种合理检查。我们对引入LLM生成的描述符的附加语义的影响和缺陷进行了广泛的实验研究，并展示了如果可用，se的能动性可以作为解释这些缺陷的一种方法。",
    "tldr": "本研究提出了WaffleCLIP，一个使用随机字符和单词描述符进行零样本视觉分类的框架，它取代了使用大型语言模型生成的描述符。该方法不仅能够实现可比较的性能提升，而且可以作为基于语言模型的视觉分类模型扩展的替代选择和验证方法。",
    "en_tdlr": "This paper proposes WaffleCLIP, a framework for zero-shot visual classification that replaces class descriptors generated by language models with random character and word descriptors. It achieves comparable performance gains without querying external models, serving as an alternative and sanity check for language model-based vision-language model extensions."
}