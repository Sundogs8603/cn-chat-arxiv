{
    "title": "RePaint-NeRF: NeRF Editting via Semantic Masks and Diffusion Models. (arXiv:2306.05668v1 [cs.CV])",
    "abstract": "The emergence of Neural Radiance Fields (NeRF) has promoted the development of synthesized high-fidelity views of the intricate real world. However, it is still a very demanding task to repaint the content in NeRF. In this paper, we propose a novel framework that can take RGB images as input and alter the 3D content in neural scenes. Our work leverages existing diffusion models to guide changes in the designated 3D content. Specifically, we semantically select the target object and a pre-trained diffusion model will guide the NeRF model to generate new 3D objects, which can improve the editability, diversity, and application range of NeRF. Experiment results show that our algorithm is effective for editing 3D objects in NeRF under different text prompts, including editing appearance, shape, and more. We validate our method on both real-world datasets and synthetic-world datasets for these editing tasks. Please visit https://repaintnerf.github.io for a better view of our results.",
    "link": "http://arxiv.org/abs/2306.05668",
    "context": "Title: RePaint-NeRF: NeRF Editting via Semantic Masks and Diffusion Models. (arXiv:2306.05668v1 [cs.CV])\nAbstract: The emergence of Neural Radiance Fields (NeRF) has promoted the development of synthesized high-fidelity views of the intricate real world. However, it is still a very demanding task to repaint the content in NeRF. In this paper, we propose a novel framework that can take RGB images as input and alter the 3D content in neural scenes. Our work leverages existing diffusion models to guide changes in the designated 3D content. Specifically, we semantically select the target object and a pre-trained diffusion model will guide the NeRF model to generate new 3D objects, which can improve the editability, diversity, and application range of NeRF. Experiment results show that our algorithm is effective for editing 3D objects in NeRF under different text prompts, including editing appearance, shape, and more. We validate our method on both real-world datasets and synthetic-world datasets for these editing tasks. Please visit https://repaintnerf.github.io for a better view of our results.",
    "path": "papers/23/06/2306.05668.json",
    "total_tokens": 915,
    "translated_title": "RePaint-NeRF：基于语义掩码和扩散模型的 NeRF 编辑.",
    "translated_abstract": "神经辐射场（NeRF）的出现促进了对复杂真实世界的高保真视图的合成的发展。然而，在 NeRF 中重新绘制内容仍然是一项非常苛刻的任务。在本文中，我们提出了一个能够接受 RGB 图像作为输入并改变神经场景中的 3D 内容的新颖框架。我们的工作利用现有的扩散模型来指导指定的 3D 内容的变化。具体而言，我们语义地选择目标对象，预先训练的扩散模型将指导 NeRF 模型生成新的 3D 对象，这可以提高 NeRF 的可编辑性，多样性和应用范围。实验结果表明，我们的算法对于在不同的文本提示下编辑 NeRF 中的 3D 对象是有效的，包括编辑外观、形状等。我们在真实世界数据集和合成世界数据集上验证了我们的方法以完成这些编辑任务。请访问 https://repaintnerf.github.io 以查看更好的结果。",
    "tldr": "本文提出了一个新框架，利用现有的扩散模型来指导指定的 3D 内容的变化，并能够接受 RGB 图像作为输入并改变神经场景中的 3D 内容。",
    "en_tdlr": "This paper proposes a novel framework that utilizes existing diffusion models to guide changes in designated 3D content in neural scenes and can take RGB images as input to alter the 3D content in the scene."
}