{
    "title": "Semantic HELM: An Interpretable Memory for Reinforcement Learning. (arXiv:2306.09312v1 [cs.LG])",
    "abstract": "Reinforcement learning agents deployed in the real world often have to cope with partially observable environments. Therefore, most agents employ memory mechanisms to approximate the state of the environment. Recently, there have been impressive success stories in mastering partially observable environments, mostly in the realm of computer games like Dota 2, StarCraft II, or MineCraft. However, none of these methods are interpretable in the sense that it is not comprehensible for humans how the agent decides which actions to take based on its inputs. Yet, human understanding is necessary in order to deploy such methods in high-stake domains like autonomous driving or medical applications. We propose a novel memory mechanism that operates on human language to illuminate the decision-making process. First, we use CLIP to associate visual inputs with language tokens. Then we feed these tokens to a pretrained language model that serves the agent as memory and provides it with a coherent an",
    "link": "http://arxiv.org/abs/2306.09312",
    "context": "Title: Semantic HELM: An Interpretable Memory for Reinforcement Learning. (arXiv:2306.09312v1 [cs.LG])\nAbstract: Reinforcement learning agents deployed in the real world often have to cope with partially observable environments. Therefore, most agents employ memory mechanisms to approximate the state of the environment. Recently, there have been impressive success stories in mastering partially observable environments, mostly in the realm of computer games like Dota 2, StarCraft II, or MineCraft. However, none of these methods are interpretable in the sense that it is not comprehensible for humans how the agent decides which actions to take based on its inputs. Yet, human understanding is necessary in order to deploy such methods in high-stake domains like autonomous driving or medical applications. We propose a novel memory mechanism that operates on human language to illuminate the decision-making process. First, we use CLIP to associate visual inputs with language tokens. Then we feed these tokens to a pretrained language model that serves the agent as memory and provides it with a coherent an",
    "path": "papers/23/06/2306.09312.json",
    "total_tokens": 901,
    "tldr": "本论文提出了一种基于CLIP和预训练语言模型的记忆机制，使强化学习智能体的决策过程变得可解释，有利于其在高风险领域中的应用。"
}