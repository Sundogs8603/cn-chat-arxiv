{
    "title": "Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How. (arXiv:2306.03828v2 [cs.LG] UPDATED)",
    "abstract": "With the ever-increasing number of pretrained models, machine learning practitioners are continuously faced with which pretrained model to use, and how to finetune it for a new dataset. In this paper, we propose a methodology that jointly searches for the optimal pretrained model and the hyperparameters for finetuning it. Our method transfers knowledge about the performance of many pretrained models with multiple hyperparameter configurations on a series of datasets. To this aim, we evaluated over 20k hyperparameter configurations for finetuning 24 pretrained image classification models on 87 datasets to generate a large-scale meta-dataset. We meta-learn a multi-fidelity performance predictor on the learning curves of this meta-dataset and use it for fast hyperparameter optimization on new datasets. We empirically demonstrate that our resulting approach can quickly select an accurate pretrained model for a new dataset together with its optimal hyperparameters.",
    "link": "http://arxiv.org/abs/2306.03828",
    "context": "Title: Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How. (arXiv:2306.03828v2 [cs.LG] UPDATED)\nAbstract: With the ever-increasing number of pretrained models, machine learning practitioners are continuously faced with which pretrained model to use, and how to finetune it for a new dataset. In this paper, we propose a methodology that jointly searches for the optimal pretrained model and the hyperparameters for finetuning it. Our method transfers knowledge about the performance of many pretrained models with multiple hyperparameter configurations on a series of datasets. To this aim, we evaluated over 20k hyperparameter configurations for finetuning 24 pretrained image classification models on 87 datasets to generate a large-scale meta-dataset. We meta-learn a multi-fidelity performance predictor on the learning curves of this meta-dataset and use it for fast hyperparameter optimization on new datasets. We empirically demonstrate that our resulting approach can quickly select an accurate pretrained model for a new dataset together with its optimal hyperparameters.",
    "path": "papers/23/06/2306.03828.json",
    "total_tokens": 862,
    "translated_title": "Quick-Tune：快速学习应该使用哪个预训练模型以及如何微调它",
    "translated_abstract": "随着预训练模型数量的不断增加，机器学习从业者不断面临一个问题：应该使用哪个预训练模型以及该如何微调它以适应新的数据集。本文提出了一种方法，联合搜索最佳的预训练模型和微调超参数。我们的方法通过评估超过20k个超参数配置在87个数据集上微调24个预训练图像分类模型来生成大规模元数据集，并在其学习曲线上元学习多保真度性能预测器，以用于快速超参数优化。我们的实证研究表明，我们的方法能够快速选择一个准确的预训练模型并找到它的最佳超参数。",
    "tldr": "本文提出一种方法快速选择最佳的预训练模型和微调超参数，通过生成大规模元数据集并元学习多保真度性能预测器，并在学习新数据集时使用该预测器进行超参数优化，可以快速实现此目标。",
    "en_tdlr": "This paper proposes a methodology for quickly selecting the optimal pretrained model and hyperparameters for finetuning it. It generates a large-scale meta-dataset by evaluating over 20k hyperparameter configurations for finetuning 24 pretrained image classification models on 87 datasets, and meta-learns a multi-fidelity performance predictor on the learning curves of this meta-dataset for fast hyperparameter optimization on new datasets."
}