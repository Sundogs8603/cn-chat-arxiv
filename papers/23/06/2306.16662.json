{
    "title": "Joint Level Generation and Translation Using Gameplay Videos. (arXiv:2306.16662v1 [cs.CV])",
    "abstract": "Procedural Content Generation via Machine Learning (PCGML) faces a significant hurdle that sets it apart from other fields, such as image or text generation, which is limited annotated data. Many existing methods for procedural level generation via machine learning require a secondary representation besides level images. However, the current methods for obtaining such representations are laborious and time-consuming, which contributes to this problem. In this work, we aim to address this problem by utilizing gameplay videos of two human-annotated games to develop a novel multi-tail framework that learns to perform simultaneous level translation and generation. The translation tail of our framework can convert gameplay video frames to an equivalent secondary representation, while its generation tail can produce novel level segments. Evaluation results and comparisons between our framework and baselines suggest that combining the level generation and translation tasks can lead to an over",
    "link": "http://arxiv.org/abs/2306.16662",
    "context": "Title: Joint Level Generation and Translation Using Gameplay Videos. (arXiv:2306.16662v1 [cs.CV])\nAbstract: Procedural Content Generation via Machine Learning (PCGML) faces a significant hurdle that sets it apart from other fields, such as image or text generation, which is limited annotated data. Many existing methods for procedural level generation via machine learning require a secondary representation besides level images. However, the current methods for obtaining such representations are laborious and time-consuming, which contributes to this problem. In this work, we aim to address this problem by utilizing gameplay videos of two human-annotated games to develop a novel multi-tail framework that learns to perform simultaneous level translation and generation. The translation tail of our framework can convert gameplay video frames to an equivalent secondary representation, while its generation tail can produce novel level segments. Evaluation results and comparisons between our framework and baselines suggest that combining the level generation and translation tasks can lead to an over",
    "path": "papers/23/06/2306.16662.json",
    "total_tokens": 838,
    "translated_title": "利用游戏视频进行关卡生成和翻译的联合模型",
    "translated_abstract": "利用机器学习的程序生成技术面临着一个与其他领域（如图像或文本生成）不同的显著障碍，即受限的注释数据。许多现有的机器学习关卡生成方法需要除了关卡图像之外的辅助表示。然而，获取这些表示的当前方法是费时费力的，这导致了这个问题的存在。在这项工作中，我们旨在通过利用两个人工注释游戏的游戏视频来开发一种新的多目标框架，学习同时进行关卡翻译和生成。我们的框架的翻译部分可以将游戏视频帧转换为等效的辅助表示，而生成部分可以产生新的关卡段落。评估结果和与基准方法的比较表明，结合关卡生成和翻译任务可以实现更好的效果。",
    "tldr": "该论文提出了一种利用游戏视频进行关卡生成和翻译的联合模型，通过学习同时进行关卡翻译和生成，解决了机器学习关卡生成技术中受限注释数据的问题。",
    "en_tdlr": "This paper proposes a joint model for level generation and translation using gameplay videos, which addresses the limited annotated data issue in procedural content generation via machine learning. By simultaneously learning to translate and generate levels, the approach improves the efficiency of level generation methods."
}