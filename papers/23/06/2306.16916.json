{
    "title": "Obeying the Order: Introducing Ordered Transfer Hyperparameter Optimisation. (arXiv:2306.16916v1 [cs.LG])",
    "abstract": "We introduce ordered transfer hyperparameter optimisation (OTHPO), a version of transfer learning for hyperparameter optimisation (HPO) where the tasks follow a sequential order. Unlike for state-of-the-art transfer HPO, the assumption is that each task is most correlated to those immediately before it. This matches many deployed settings, where hyperparameters are retuned as more data is collected; for instance tuning a sequence of movie recommendation systems as more movies and ratings are added. We propose a formal definition, outline the differences to related problems and propose a basic OTHPO method that outperforms state-of-the-art transfer HPO. We empirically show the importance of taking order into account using ten benchmarks. The benchmarks are in the setting of gradually accumulating data, and span XGBoost, random forest, approximate k-nearest neighbor, elastic net, support vector machines and a separate real-world motivated optimisation problem. We open source the benchmar",
    "link": "http://arxiv.org/abs/2306.16916",
    "context": "Title: Obeying the Order: Introducing Ordered Transfer Hyperparameter Optimisation. (arXiv:2306.16916v1 [cs.LG])\nAbstract: We introduce ordered transfer hyperparameter optimisation (OTHPO), a version of transfer learning for hyperparameter optimisation (HPO) where the tasks follow a sequential order. Unlike for state-of-the-art transfer HPO, the assumption is that each task is most correlated to those immediately before it. This matches many deployed settings, where hyperparameters are retuned as more data is collected; for instance tuning a sequence of movie recommendation systems as more movies and ratings are added. We propose a formal definition, outline the differences to related problems and propose a basic OTHPO method that outperforms state-of-the-art transfer HPO. We empirically show the importance of taking order into account using ten benchmarks. The benchmarks are in the setting of gradually accumulating data, and span XGBoost, random forest, approximate k-nearest neighbor, elastic net, support vector machines and a separate real-world motivated optimisation problem. We open source the benchmar",
    "path": "papers/23/06/2306.16916.json",
    "total_tokens": 883,
    "translated_title": "遵守订单：引入有序传输超参数优化",
    "translated_abstract": "我们引入了有序传输超参数优化（OTHPO），这是超参数优化（HPO）的迁移学习版本，其中任务按顺序进行。与最先进的迁移HPO不同，我们假设每个任务与之前的任务最相关。这符合许多部署设置，其中随着收集更多数据，超参数会重新调整；例如，调整一系列电影推荐系统，随着添加更多电影和评级。我们提出了一个形式定义，概述了与相关问题的区别，并提出了一个基本的OTHPO方法，该方法胜过最先进的迁移HPO。我们通过十个基准测试实证地展示了考虑顺序的重要性。这些基准测试涉及逐渐累积数据的设置，并涵盖了XGBoost，随机森林，近似k最近邻，弹性网络，支持向量机和一个独立的现实世界动机驱动的优化问题。我们开源了这些基准测试。",
    "tldr": "引入有序传输超参数优化（OTHPO）方法，解决了超参数优化问题中任务顺序相关的挑战，并通过十个基准测试证明了其重要性，该方法胜过当前最先进的迁移超参数优化方法。",
    "en_tdlr": "Introducing Ordered Transfer Hyperparameter Optimisation (OTHPO), a method that addresses the challenge of task order correlation in hyperparameter optimisation (HPO) and outperforms the state-of-the-art transfer HPO method, as demonstrated through ten benchmarks."
}