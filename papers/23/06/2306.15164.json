{
    "title": "DSRM: Boost Textual Adversarial Training with Distribution Shift Risk Minimization. (arXiv:2306.15164v1 [cs.CL])",
    "abstract": "Adversarial training is one of the best-performing methods in improving the robustness of deep language models. However, robust models come at the cost of high time consumption, as they require multi-step gradient ascents or word substitutions to obtain adversarial samples. In addition, these generated samples are deficient in grammatical quality and semantic consistency, which impairs the effectiveness of adversarial training. To address these problems, we introduce a novel, effective procedure for instead adversarial training with only clean data. Our procedure, distribution shift risk minimization (DSRM), estimates the adversarial loss by perturbing the input data's probability distribution rather than their embeddings. This formulation results in a robust model that minimizes the expected global loss under adversarial attacks. Our approach requires zero adversarial samples for training and reduces time consumption by up to 70\\% compared to current best-performing adversarial traini",
    "link": "http://arxiv.org/abs/2306.15164",
    "context": "Title: DSRM: Boost Textual Adversarial Training with Distribution Shift Risk Minimization. (arXiv:2306.15164v1 [cs.CL])\nAbstract: Adversarial training is one of the best-performing methods in improving the robustness of deep language models. However, robust models come at the cost of high time consumption, as they require multi-step gradient ascents or word substitutions to obtain adversarial samples. In addition, these generated samples are deficient in grammatical quality and semantic consistency, which impairs the effectiveness of adversarial training. To address these problems, we introduce a novel, effective procedure for instead adversarial training with only clean data. Our procedure, distribution shift risk minimization (DSRM), estimates the adversarial loss by perturbing the input data's probability distribution rather than their embeddings. This formulation results in a robust model that minimizes the expected global loss under adversarial attacks. Our approach requires zero adversarial samples for training and reduces time consumption by up to 70\\% compared to current best-performing adversarial traini",
    "path": "papers/23/06/2306.15164.json",
    "total_tokens": 889,
    "translated_title": "用分布偏移风险最小化增强文本对抗训练（DSRM）",
    "translated_abstract": "对抗训练是改善深度语言模型鲁棒性的最佳方法之一。然而，鲁棒模型的代价是时间消耗高，因为它们需要多步梯度上升或单词替换来获取对抗样本。此外，这些生成的样本在语法质量和语义一致性方面存在缺陷，影响了对抗训练的有效性。为了解决这些问题，我们引入了一种新颖、有效的过程，将对抗训练改为只使用干净数据。我们的方法DSRM通过扰动输入数据的概率分布而不是它们的嵌入来估计对抗损失。这种公式化结果导致了一个在对抗攻击下最小化期望全局损失的鲁棒模型。我们的方法在训练过程中不需要对抗样本，并且与当前最佳对抗训练相比，减少了高达70\\%的时间消耗。",
    "tldr": "本论文介绍了一种新颖的方法DSRM，通过最小化分布偏移风险而不是使用对抗样本来对抗训练，从而提高了深度语言模型的鲁棒性，减少了时间消耗。",
    "en_tdlr": "This paper introduces a novel method DSRM which enhances the robustness of deep language models by minimizing the distribution shift risk instead of using adversarial samples, leading to reduced time consumption."
}