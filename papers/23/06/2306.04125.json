{
    "title": "Multimodal Fusion Interactions: A Study of Human and Automatic Quantification. (arXiv:2306.04125v1 [cs.LG])",
    "abstract": "Multimodal fusion of multiple heterogeneous and interconnected signals is a fundamental challenge in almost all multimodal problems and applications. In order to perform multimodal fusion, we need to understand the types of interactions that modalities can exhibit: how each modality individually provides information useful for a task and how this information changes in the presence of other modalities. In this paper, we perform a comparative study of how human annotators can be leveraged to annotate two categorizations of multimodal interactions: (1) partial labels, where different randomly assigned annotators annotate the label given the first, second, and both modalities, and (2) counterfactual labels, where the same annotator is tasked to annotate the label given the first modality before giving them the second modality and asking them to explicitly reason about how their answer changes, before proposing an alternative taxonomy based on (3) information decomposition, where annotator",
    "link": "http://arxiv.org/abs/2306.04125",
    "context": "Title: Multimodal Fusion Interactions: A Study of Human and Automatic Quantification. (arXiv:2306.04125v1 [cs.LG])\nAbstract: Multimodal fusion of multiple heterogeneous and interconnected signals is a fundamental challenge in almost all multimodal problems and applications. In order to perform multimodal fusion, we need to understand the types of interactions that modalities can exhibit: how each modality individually provides information useful for a task and how this information changes in the presence of other modalities. In this paper, we perform a comparative study of how human annotators can be leveraged to annotate two categorizations of multimodal interactions: (1) partial labels, where different randomly assigned annotators annotate the label given the first, second, and both modalities, and (2) counterfactual labels, where the same annotator is tasked to annotate the label given the first modality before giving them the second modality and asking them to explicitly reason about how their answer changes, before proposing an alternative taxonomy based on (3) information decomposition, where annotator",
    "path": "papers/23/06/2306.04125.json",
    "total_tokens": 1050,
    "translated_title": "多模态融合交互: 人类和自动量化研究",
    "translated_abstract": "在几乎所有多模态问题和应用中，多模态融合多种异构和互联的信号是一个基本挑战。为了进行多模态融合，我们需要理解模态可以展现的交互类型：每种模态如何单独提供对任务有用的信息，以及当存在其他模态时这些信息如何变化。在本文中，我们对人类注释者如何被利用来注释多模态交互的两种分类进行了比较研究：(1) 部分标签，其中不同随机分配的注释者注释给定第一个、第二个和两个模态的标签，以及(2) 反事实标签，其中同一注释者被要求在给出第一个模态之前注释标签，然后给出第二个模态，并要求他们明确地推理他们的答案如何改变，然后提出基于信息分解的另一种分类学。",
    "tldr": "本文比较研究了两种人类注释者可以用于注释多模态交互的分类，并提出了一种基于信息分解的分类学。"
}