{
    "title": "Mixed-TD: Efficient Neural Network Accelerator with Layer-Specific Tensor Decomposition. (arXiv:2306.05021v1 [cs.LG])",
    "abstract": "Neural Network designs are quite diverse, from VGG-style to ResNet-style, and from Convolutional Neural Networks to Transformers. Towards the design of efficient accelerators, many works have adopted a dataflow-based, inter-layer pipelined architecture, with a customised hardware towards each layer, achieving ultra high throughput and low latency. The deployment of neural networks to such dataflow architecture accelerators is usually hindered by the available on-chip memory as it is desirable to preload the weights of neural networks on-chip to maximise the system performance. To address this, networks are usually compressed before the deployment through methods such as pruning, quantization and tensor decomposition. In this paper, a framework for mapping CNNs onto FPGAs based on a novel tensor decomposition method called Mixed-TD is proposed. The proposed method applies layer-specific Singular Value Decomposition (SVD) and Canonical Polyadic Decomposition (CPD) in a mixed manner, achi",
    "link": "http://arxiv.org/abs/2306.05021",
    "context": "Title: Mixed-TD: Efficient Neural Network Accelerator with Layer-Specific Tensor Decomposition. (arXiv:2306.05021v1 [cs.LG])\nAbstract: Neural Network designs are quite diverse, from VGG-style to ResNet-style, and from Convolutional Neural Networks to Transformers. Towards the design of efficient accelerators, many works have adopted a dataflow-based, inter-layer pipelined architecture, with a customised hardware towards each layer, achieving ultra high throughput and low latency. The deployment of neural networks to such dataflow architecture accelerators is usually hindered by the available on-chip memory as it is desirable to preload the weights of neural networks on-chip to maximise the system performance. To address this, networks are usually compressed before the deployment through methods such as pruning, quantization and tensor decomposition. In this paper, a framework for mapping CNNs onto FPGAs based on a novel tensor decomposition method called Mixed-TD is proposed. The proposed method applies layer-specific Singular Value Decomposition (SVD) and Canonical Polyadic Decomposition (CPD) in a mixed manner, achi",
    "path": "papers/23/06/2306.05021.json",
    "total_tokens": 1157,
    "translated_title": "Mixed-TD: 基于层特定张量分解的高效神经网络加速器",
    "translated_abstract": "神经网络设计相当多样化，从VGG到ResNet，从卷积神经网络到变换器。为了设计效率高的加速器，许多工作采用了基于数据流的、层间流水线结构的体系结构，针对每一层进行了自定义硬件设计，实现了超高的吞吐量和低延迟。神经网络部署到此类数据流体系结构加速器上通常受可用片上内存的限制，因为预加载神经网络的权重到片上以最大化系统性能是理想的。为了解决这个问题，网络通常会通过修剪、量化和张量分解等方法进行压缩。本文提出了一种将CNN映射到FPGA上的框架，基于一种新颖的张量分解方法Mixed-TD。该方法采用了混合方式的层特定奇异值分解（SVD）和典型多项式分解（CPD），在保持原始神经网络准确性的同时实现了高压缩率。Mixed-TD框架采用动态映射方法，以实现有效地利用可用的片上存储器和计算资源。实验结果表明，Mixed-TD框架在减少内存占用和计算周期方面能够显著提高性能，同时保持与原始未压缩神经网络相似的准确性。",
    "tldr": "本文提出了一种基于层特定张量分解的神经网络加速器Mixed-TD，采用混合方式的SVD和CPD方法，实现了高压缩率，同时保持了与原始神经网络类似的准确性，并通过动态映射方法实现了对可用片上存储器和计算资源的有效利用。",
    "en_tdlr": "This paper proposes Mixed-TD, an efficient neural network accelerator based on layer-specific tensor decomposition. It achieves high compression rates while maintaining accuracy through a mixed approach of SVD and CPD, and employs a dynamic mapping strategy to effectively utilize available on-chip memory and computation resources. Experimental results demonstrate significant reductions in memory footprint and computation cycles while maintaining similar accuracy to the original uncompressed neural networks."
}