{
    "title": "Explaining Hate Speech Classification with Model Agnostic Methods. (arXiv:2306.00021v1 [cs.CL])",
    "abstract": "There have been remarkable breakthroughs in Machine Learning and Artificial Intelligence, notably in the areas of Natural Language Processing and Deep Learning. Additionally, hate speech detection in dialogues has been gaining popularity among Natural Language Processing researchers with the increased use of social media. However, as evidenced by the recent trends, the need for the dimensions of explainability and interpretability in AI models has been deeply realised. Taking note of the factors above, the research goal of this paper is to bridge the gap between hate speech prediction and the explanations generated by the system to support its decision. This has been achieved by first predicting the classification of a text and then providing a posthoc, model agnostic and surrogate interpretability approach for explainability and to prevent model bias. The bidirectional transformer model BERT has been used for prediction because of its state of the art efficiency over other Machine Lea",
    "link": "http://arxiv.org/abs/2306.00021",
    "context": "Title: Explaining Hate Speech Classification with Model Agnostic Methods. (arXiv:2306.00021v1 [cs.CL])\nAbstract: There have been remarkable breakthroughs in Machine Learning and Artificial Intelligence, notably in the areas of Natural Language Processing and Deep Learning. Additionally, hate speech detection in dialogues has been gaining popularity among Natural Language Processing researchers with the increased use of social media. However, as evidenced by the recent trends, the need for the dimensions of explainability and interpretability in AI models has been deeply realised. Taking note of the factors above, the research goal of this paper is to bridge the gap between hate speech prediction and the explanations generated by the system to support its decision. This has been achieved by first predicting the classification of a text and then providing a posthoc, model agnostic and surrogate interpretability approach for explainability and to prevent model bias. The bidirectional transformer model BERT has been used for prediction because of its state of the art efficiency over other Machine Lea",
    "path": "papers/23/06/2306.00021.json",
    "total_tokens": 876,
    "translated_title": "采用模型无关方法解释仇恨言论分类",
    "translated_abstract": "机器学习和人工智能在自然语言处理和深度学习领域取得了显著突破。随着社交媒体的广泛使用，对话中的仇恨言论检测也在自然语言处理研究人员中变得越来越受欢迎。然而，正如最近的趋势所表明的那样，在AI模型中加入可解释性和可解释性维度的需求已经得到深刻的认识。本文的研究目标是要在仇恨言论预测与系统生成的解释之间搭建桥梁。通过首先预测文本的分类，然后提供一个后验的模型无关和代理可解释性方法来支持模型的解释性并防止模型偏差。采用双向变形器模型BERT进行预测，因为它在自然语言处理的机器学习模型中具有最先进的效率。",
    "tldr": "本文旨在解释仇恨言论分类，采用双向变形器模型BERT进行预测，并提供后验的模型无关和代理可解释性方法，以支持模型的解释性并防止模型偏差。",
    "en_tdlr": "This paper aims to explain hate speech classification using a model agnostic approach. The bidirectional transformer model BERT is used for prediction, while a posthoc, model agnostic and surrogate interpretability approach is provided for explanations to support model interpretability and prevent bias."
}