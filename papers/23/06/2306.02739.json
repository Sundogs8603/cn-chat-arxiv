{
    "title": "Knowledge-Driven Robot Program Synthesis from Human VR Demonstrations. (arXiv:2306.02739v2 [cs.RO] UPDATED)",
    "abstract": "Aging societies, labor shortages and increasing wage costs call for assistance robots capable of autonomously performing a wide array of real-world tasks. Such open-ended robotic manipulation requires not only powerful knowledge representations and reasoning (KR&R) algorithms, but also methods for humans to instruct robots what tasks to perform and how to perform them. In this paper, we present a system for automatically generating executable robot control programs from human task demonstrations in virtual reality (VR). We leverage common-sense knowledge and game engine-based physics to semantically interpret human VR demonstrations, as well as an expressive and general task representation and automatic path planning and code generation, embedded into a state-of-the-art cognitive architecture. We demonstrate our approach in the context of force-sensitive fetch-and-place for a robotic shopping assistant. The source code is available at https://github.com/ease-crc/vr-program-synthesis.",
    "link": "http://arxiv.org/abs/2306.02739",
    "context": "Title: Knowledge-Driven Robot Program Synthesis from Human VR Demonstrations. (arXiv:2306.02739v2 [cs.RO] UPDATED)\nAbstract: Aging societies, labor shortages and increasing wage costs call for assistance robots capable of autonomously performing a wide array of real-world tasks. Such open-ended robotic manipulation requires not only powerful knowledge representations and reasoning (KR&R) algorithms, but also methods for humans to instruct robots what tasks to perform and how to perform them. In this paper, we present a system for automatically generating executable robot control programs from human task demonstrations in virtual reality (VR). We leverage common-sense knowledge and game engine-based physics to semantically interpret human VR demonstrations, as well as an expressive and general task representation and automatic path planning and code generation, embedded into a state-of-the-art cognitive architecture. We demonstrate our approach in the context of force-sensitive fetch-and-place for a robotic shopping assistant. The source code is available at https://github.com/ease-crc/vr-program-synthesis.",
    "path": "papers/23/06/2306.02739.json",
    "total_tokens": 914,
    "translated_title": "从人类虚拟现实演示中驱动的机器人程序综合",
    "translated_abstract": "人口老化、劳动力短缺和不断增加的工资成本需要能够自主执行各种真实世界任务的辅助机器人。这种开放式机器人操作不仅需要强大的知识表示和推理（KR＆R）算法，还需要人们教导机器人执行任务和如何执行任务的方法。本文提出了一种从人类虚拟现实（VR）任务演示中自动生成可执行机器人控制程序的系统。我们利用常识知识和基于游戏引擎的物理学来语义化解释人类虚拟现实演示，以及用于表达和自动路径规划和代码生成的通用任务表示和最先进认知架构上的嵌入。我们在机器人购物助手的力敏抓取和放置环境中演示了我们的方法。源代码可在https://github.com/ease-crc/vr-program-synthesis找到。",
    "tldr": "本文提出了一种从人类虚拟现实（VR）任务演示中自动生成可执行机器人控制程序的系统。通过利用常识知识和基于游戏引擎的物理学进行语义解释，并结合通用任务表示和自动路径规划和代码生成算法，实现了机器人购物助手的力敏抓取和放置任务。",
    "en_tdlr": "This paper presents a system for automatically generating executable robot control programs from human task demonstrations in virtual reality (VR). It leverages common-sense knowledge and game engine-based physics to semantically interpret human VR demonstrations, and combines with a general task representation and automatic path planning and code generation algorithms to achieve force-sensitive fetch-and-place tasks for a robotic shopping assistant."
}