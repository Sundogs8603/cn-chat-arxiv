{
    "title": "Certified Reasoning with Language Models. (arXiv:2306.04031v1 [cs.AI])",
    "abstract": "Language models often achieve higher accuracy when reasoning step-by-step in complex tasks. However, their reasoning can be unsound, inconsistent, or rely on undesirable prior assumptions. To tackle these issues, we introduce a class of tools for language models called guides that use state and incremental constraints to guide generation. A guide can be invoked by the model to constrain its own generation to a set of valid statements given by the tool. In turn, the model's choices can change the guide's state. We show how a general system for logical reasoning can be used as a guide, which we call LogicGuide. Given a reasoning problem in natural language, a model can formalize its assumptions for LogicGuide and then guarantee that its reasoning steps are sound. In experiments with the PrOntoQA and ProofWriter reasoning datasets, LogicGuide significantly improves the performance of GPT-3, GPT-3.5 Turbo and LLaMA (accuracy gains up to 35%). LogicGuide also drastically reduces content eff",
    "link": "http://arxiv.org/abs/2306.04031",
    "context": "Title: Certified Reasoning with Language Models. (arXiv:2306.04031v1 [cs.AI])\nAbstract: Language models often achieve higher accuracy when reasoning step-by-step in complex tasks. However, their reasoning can be unsound, inconsistent, or rely on undesirable prior assumptions. To tackle these issues, we introduce a class of tools for language models called guides that use state and incremental constraints to guide generation. A guide can be invoked by the model to constrain its own generation to a set of valid statements given by the tool. In turn, the model's choices can change the guide's state. We show how a general system for logical reasoning can be used as a guide, which we call LogicGuide. Given a reasoning problem in natural language, a model can formalize its assumptions for LogicGuide and then guarantee that its reasoning steps are sound. In experiments with the PrOntoQA and ProofWriter reasoning datasets, LogicGuide significantly improves the performance of GPT-3, GPT-3.5 Turbo and LLaMA (accuracy gains up to 35%). LogicGuide also drastically reduces content eff",
    "path": "papers/23/06/2306.04031.json",
    "total_tokens": 872,
    "translated_title": "带有“指南”的语言模型的合规推理。",
    "translated_abstract": "在复杂任务中，语言模型往往通过逐步推理实现更高的精度。然而，它们的推理可以是不完备的、不一致的或者依赖于不良的优先假设。为了解决这些问题，我们引入了一种称为“指南”的语言模型工具类，利用状态和递增约束来指导生成。模型可以调用指南，将其自己的生成限制在一组工具给出的有效陈述之内。反过来，模型的选择可以改变指南的状态。我们展示了一个通用的系统来进行逻辑推理，可以被用作指南，我们称之为LogicGuide。给定自然语言的推理问题，模型可以为LogicGuide形式化它的假设，从而保证其推理步骤是完备的。在PrOntoQA和ProofWriter推理数据集的实验中，LogicGuide显著提高了GPT-3、GPT-3.5 Turbo和LLaMA的性能（精度提高了35%）。LogicGuide也大大减少了内容效果的波动。",
    "tldr": "该论文提出了一种称为“指南”的语言模型工具类，它使用状态和增量约束来指导生成，可以显著提高语言模型的逻辑推理精度。",
    "en_tdlr": "The paper introduces a tool called guides for language models, which use state and incremental constraints to guide generation and can significantly improve the accuracy of logical reasoning in language models."
}