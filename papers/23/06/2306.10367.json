{
    "title": "Query2GMM: Learning Representation with Gaussian Mixture Model for Reasoning over Knowledge Graphs",
    "abstract": "arXiv:2306.10367v2 Announce Type: replace  Abstract: Logical query answering over Knowledge Graphs (KGs) is a fundamental yet complex task. A promising approach to achieve this is to embed queries and entities jointly into the same embedding space. Research along this line suggests that using multi-modal distribution to represent answer entities is more suitable than uni-modal distribution, as a single query may contain multiple disjoint answer subsets due to the compositional nature of multi-hop queries and the varying latent semantics of relations. However, existing methods based on multi-modal distribution roughly represent each subset without capturing its accurate cardinality, or even degenerate into uni-modal distribution learning during the reasoning process due to the lack of an effective similarity measure. To better model queries with diversified answers, we propose Query2GMM for answering logical queries over knowledge graphs. In Query2GMM, we present the GMM embedding to re",
    "link": "https://arxiv.org/abs/2306.10367",
    "context": "Title: Query2GMM: Learning Representation with Gaussian Mixture Model for Reasoning over Knowledge Graphs\nAbstract: arXiv:2306.10367v2 Announce Type: replace  Abstract: Logical query answering over Knowledge Graphs (KGs) is a fundamental yet complex task. A promising approach to achieve this is to embed queries and entities jointly into the same embedding space. Research along this line suggests that using multi-modal distribution to represent answer entities is more suitable than uni-modal distribution, as a single query may contain multiple disjoint answer subsets due to the compositional nature of multi-hop queries and the varying latent semantics of relations. However, existing methods based on multi-modal distribution roughly represent each subset without capturing its accurate cardinality, or even degenerate into uni-modal distribution learning during the reasoning process due to the lack of an effective similarity measure. To better model queries with diversified answers, we propose Query2GMM for answering logical queries over knowledge graphs. In Query2GMM, we present the GMM embedding to re",
    "path": "papers/23/06/2306.10367.json",
    "total_tokens": 618,
    "translated_title": "Query2GMM：使用高斯混合模型学习知识图谱推理表示",
    "translated_abstract": "逻辑查询答案是知识图谱中一个基础且复杂的任务。本文提出Query2GMM来回答知识图谱上的逻辑查询，通过将查询和实体共同嵌入到同一嵌入空间中，以更好地模拟具有多样化答案的查询。",
    "tldr": "使用高斯混合模型学习表示，以更好地模拟知识图谱中具有多样化答案的逻辑查询",
    "en_tdlr": "Learning representation with Gaussian Mixture Model to better model logical queries with diversified answers over knowledge graphs."
}