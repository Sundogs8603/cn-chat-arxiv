{
    "title": "Off-Policy Evaluation of Ranking Policies under Diverse User Behavior. (arXiv:2306.15098v1 [stat.ML])",
    "abstract": "Ranking interfaces are everywhere in online platforms. There is thus an ever growing interest in their Off-Policy Evaluation (OPE), aiming towards an accurate performance evaluation of ranking policies using logged data. A de-facto approach for OPE is Inverse Propensity Scoring (IPS), which provides an unbiased and consistent value estimate. However, it becomes extremely inaccurate in the ranking setup due to its high variance under large action spaces. To deal with this problem, previous studies assume either independent or cascade user behavior, resulting in some ranking versions of IPS. While these estimators are somewhat effective in reducing the variance, all existing estimators apply a single universal assumption to every user, causing excessive bias and variance. Therefore, this work explores a far more general formulation where user behavior is diverse and can vary depending on the user context. We show that the resulting estimator, which we call Adaptive IPS (AIPS), can be unb",
    "link": "http://arxiv.org/abs/2306.15098",
    "context": "Title: Off-Policy Evaluation of Ranking Policies under Diverse User Behavior. (arXiv:2306.15098v1 [stat.ML])\nAbstract: Ranking interfaces are everywhere in online platforms. There is thus an ever growing interest in their Off-Policy Evaluation (OPE), aiming towards an accurate performance evaluation of ranking policies using logged data. A de-facto approach for OPE is Inverse Propensity Scoring (IPS), which provides an unbiased and consistent value estimate. However, it becomes extremely inaccurate in the ranking setup due to its high variance under large action spaces. To deal with this problem, previous studies assume either independent or cascade user behavior, resulting in some ranking versions of IPS. While these estimators are somewhat effective in reducing the variance, all existing estimators apply a single universal assumption to every user, causing excessive bias and variance. Therefore, this work explores a far more general formulation where user behavior is diverse and can vary depending on the user context. We show that the resulting estimator, which we call Adaptive IPS (AIPS), can be unb",
    "path": "papers/23/06/2306.15098.json",
    "total_tokens": 958,
    "translated_title": "不同用户行为下的排名策略的离策略评估",
    "translated_abstract": "在线平台上到处都是排名界面。因此，对于使用记录数据进行排名策略的准确性能评估的离策略评估（OPE）越来越感兴趣。OPE的一种事实上的方法是倒数倾向得分法（IPS），它提供了一个无偏且一致的值估计。然而，在排名设置中，由于在大型行为空间下具有较高的方差，它变得极其不准确。为了解决这个问题，先前的研究假设用户行为是独立的或级联的，从而产生了一些IPS的排名版本。尽管这些估计器在减少方差方面有一定的效果，但所有现有的估计器都对每个用户应用了一个单一的通用假设，导致过度的偏差和方差。因此，这项工作探索了更通用的公式，其中用户行为是多样的，并且可以根据用户上下文的不同而变化。我们展示出由此产生的估计器，我们称之为自适应IPS（AIPS），可以更准确地进行离策略评估和排名策略。",
    "tldr": "本文提出了一种新的离策略评估方法Adaptive IPS (AIPS)，针对排名策略的离策略评估问题，通过考虑用户行为的多样性和上下文的变化，有效降低了估计中的偏差和方差。",
    "en_tdlr": "This paper introduces a new off-policy evaluation method called Adaptive IPS (AIPS) for evaluating ranking policies, which takes into account the diversity of user behavior and the variability of user context, effectively reducing bias and variance in the estimation process."
}