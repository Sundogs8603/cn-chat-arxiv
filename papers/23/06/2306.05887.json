{
    "title": "An Efficient Speech Separation Network Based on Recurrent Fusion Dilated Convolution and Channel Attention. (arXiv:2306.05887v1 [eess.AS])",
    "abstract": "We present an efficient speech separation neural network, ARFDCN, which combines dilated convolutions, multi-scale fusion (MSF), and channel attention to overcome the limited receptive field of convolution-based networks and the high computational cost of transformer-based networks. The suggested network architecture is encoder-decoder based. By using dilated convolutions with gradually increasing dilation value to learn local and global features and fusing them at adjacent stages, the model can learn rich feature content. Meanwhile, by adding channel attention modules to the network, the model can extract channel weights, learn more important features, and thus improve its expressive power and robustness. Experimental results indicate that the model achieves a decent balance between performance and computational efficiency, making it a promising alternative to current mainstream models for practical applications.",
    "link": "http://arxiv.org/abs/2306.05887",
    "context": "Title: An Efficient Speech Separation Network Based on Recurrent Fusion Dilated Convolution and Channel Attention. (arXiv:2306.05887v1 [eess.AS])\nAbstract: We present an efficient speech separation neural network, ARFDCN, which combines dilated convolutions, multi-scale fusion (MSF), and channel attention to overcome the limited receptive field of convolution-based networks and the high computational cost of transformer-based networks. The suggested network architecture is encoder-decoder based. By using dilated convolutions with gradually increasing dilation value to learn local and global features and fusing them at adjacent stages, the model can learn rich feature content. Meanwhile, by adding channel attention modules to the network, the model can extract channel weights, learn more important features, and thus improve its expressive power and robustness. Experimental results indicate that the model achieves a decent balance between performance and computational efficiency, making it a promising alternative to current mainstream models for practical applications.",
    "path": "papers/23/06/2306.05887.json",
    "total_tokens": 882,
    "translated_title": "基于循环融合扩张卷积和通道注意力的高效语音分离神经网络",
    "translated_abstract": "我们提出了一种高效的语音分离神经网络，ARFDCN，它结合了扩张卷积，多尺度融合（MSF）和通道注意力，以克服基于卷积的网络的有限感受野和基于transformer的网络的高计算成本。所提出的网络结构是编码器-解码器结构。通过使用逐渐增加的扩张值的扩张卷积来学习局部和全局特征并在相邻阶段进行融合，模型可以学习到丰富的特征内容。同时，通过将通道注意力模块添加到网络中，模型可以提取通道权重，学习更重要的特征，从而提高其表现力和鲁棒性。实验结果表明，该模型在性能和计算效率之间达到了不错的平衡，成为当前实际应用中有前景的替代模型。",
    "tldr": "本文提出了一种使用循环融合扩张卷积和通道注意力的高效语音分离神经网络，其结构为编码器-解码器结构，具有较高的表现力和鲁棒性，可作为当前主流模型的有效替代模型。"
}