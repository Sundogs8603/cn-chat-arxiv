{
    "title": "Measuring and Modifying Factual Knowledge in Large Language Models. (arXiv:2306.06264v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs) store an extensive amount of factual knowledge obtained from vast collections of text. To effectively utilize these models for downstream tasks, it is crucial to have reliable methods for measuring their knowledge. However, existing approaches for knowledge measurement have certain limitations, and despite recent efforts, they fail to provide accurate measurements and the necessary insights for modifying the knowledge within LLMs. In this work, we employ information theory-based measurements to provide a framework estimating the factual knowledge contained within large language models. More specifically, we measure knowledge by analyzing the LLM's prediction probability distribution before and after instilling the target knowledge, employing metrics such as entropy and KL-divergence. Introducing our metrics, we first assess their accuracy in comparison to previous ranking-based methods, surpassing them by over $35\\%$ in a synthetic experiment. Then, we expl",
    "link": "http://arxiv.org/abs/2306.06264",
    "context": "Title: Measuring and Modifying Factual Knowledge in Large Language Models. (arXiv:2306.06264v1 [cs.CL])\nAbstract: Large Language Models (LLMs) store an extensive amount of factual knowledge obtained from vast collections of text. To effectively utilize these models for downstream tasks, it is crucial to have reliable methods for measuring their knowledge. However, existing approaches for knowledge measurement have certain limitations, and despite recent efforts, they fail to provide accurate measurements and the necessary insights for modifying the knowledge within LLMs. In this work, we employ information theory-based measurements to provide a framework estimating the factual knowledge contained within large language models. More specifically, we measure knowledge by analyzing the LLM's prediction probability distribution before and after instilling the target knowledge, employing metrics such as entropy and KL-divergence. Introducing our metrics, we first assess their accuracy in comparison to previous ranking-based methods, surpassing them by over $35\\%$ in a synthetic experiment. Then, we expl",
    "path": "papers/23/06/2306.06264.json",
    "total_tokens": 1054,
    "translated_title": "在大型语言模型中测量和修改事实知识",
    "translated_abstract": "大型语言模型（LLMs）存储着从大量文本中获取的广泛的事实知识。为了有效地利用这些模型进行下游任务，有可靠的方法来衡量它们的知识是至关重要的。然而，现有的知识测量方法存在某些限制，尽管最近有不少努力，但它们不能提供准确的测量和修改LLMs中所需的洞察力。在这项工作中，我们采用基于信息理论的测量方法来提供一个框架来估计大型语言模型中包含的事实知识。具体而言，我们通过分析LLM在注入目标知识前后的预测概率分布来衡量知识，使用熵和KL-散度等度量标准。首先介绍我们的指标，我们通过一项合成实验，在准确性方面与以前的排名方法进行比较，超过了它们35％以上。然后，我们解释了这些指标如何用于知识修改，提出了一种选择性修改大型语言模型中的实际知识的方法。总的来说，我们的方法提供了一个宝贵的工具，用于测量和修改LLMs中的大量事实知识。",
    "tldr": "这项研究提出了一种基于信息论的测量框架，可用于衡量大型语言模型中的事实知识，并通过熵及KL散度等度量指标进行知识修改，超越了以前的排名方法，并提供了一种有价值的工具，用于测量和修改LLMs中的大量事实知识。",
    "en_tdlr": "This study proposes an information theory-based measurement framework for estimating the factual knowledge contained within large language models (LLMs) and introduces a method to selectively modify the factual knowledge within LLMs using metrics such as entropy and KL-divergence. The approach surpasses previous ranking-based methods and provides a valuable tool for measuring and modifying the vast amounts of factual knowledge within LLMs."
}