{
    "title": "Skill Disentanglement for Imitation Learning from Suboptimal Demonstrations. (arXiv:2306.07919v1 [cs.LG])",
    "abstract": "Imitation learning has achieved great success in many sequential decision-making tasks, in which a neural agent is learned by imitating collected human demonstrations. However, existing algorithms typically require a large number of high-quality demonstrations that are difficult and expensive to collect. Usually, a trade-off needs to be made between demonstration quality and quantity in practice. Targeting this problem, in this work we consider the imitation of sub-optimal demonstrations, with both a small clean demonstration set and a large noisy set. Some pioneering works have been proposed, but they suffer from many limitations, e.g., assuming a demonstration to be of the same optimality throughout time steps and failing to provide any interpretation w.r.t knowledge learned from the noisy set. Addressing these problems, we propose {\\method} by evaluating and imitating at the sub-demonstration level, encoding action primitives of varying quality into different skills. Concretely, {\\m",
    "link": "http://arxiv.org/abs/2306.07919",
    "context": "Title: Skill Disentanglement for Imitation Learning from Suboptimal Demonstrations. (arXiv:2306.07919v1 [cs.LG])\nAbstract: Imitation learning has achieved great success in many sequential decision-making tasks, in which a neural agent is learned by imitating collected human demonstrations. However, existing algorithms typically require a large number of high-quality demonstrations that are difficult and expensive to collect. Usually, a trade-off needs to be made between demonstration quality and quantity in practice. Targeting this problem, in this work we consider the imitation of sub-optimal demonstrations, with both a small clean demonstration set and a large noisy set. Some pioneering works have been proposed, but they suffer from many limitations, e.g., assuming a demonstration to be of the same optimality throughout time steps and failing to provide any interpretation w.r.t knowledge learned from the noisy set. Addressing these problems, we propose {\\method} by evaluating and imitating at the sub-demonstration level, encoding action primitives of varying quality into different skills. Concretely, {\\m",
    "path": "papers/23/06/2306.07919.json",
    "total_tokens": 1091,
    "translated_title": "从次最优演示中进行模仿学习的技能解缠",
    "translated_abstract": "在许多序列决策任务中，模仿学习已经取得了巨大的成功，其中神经代理通过模仿收集的人类演示来进行学习。然而，现有算法通常需要大量难以收集的高质量演示。通常，需要在演示质量和数量之间做出权衡。针对这个问题，本文考虑使用次优演示进行模仿学习，其中包括一个小的干净演示集和一个大的有噪声集。一些先驱性的工作已经被提出，但它们存在许多限制，例如，假设演示在时间步骤中具有相同的最优性，并且未能提供任何关于从噪声集中学到的知识的解释。为了解决这些问题，我们提出了一个名为“{\\method}”的算法，通过在子演示级别上进行评估和模仿，将具有不同质量的操作原语编码为不同的技能，帮助机器分离出子技能，得益于一种基于多目标优化的新型规则化器。我们的实验结果表明，{\\method}可以有效地从少量的干净演示中学习，同时利用包含在大量有噪声演示中的补充信息。",
    "tldr": "该论文提出了一种名为“{\\method}”的算法，可以从少量的干净演示中高效学习，同时利用包含在大量有噪声演示中的补充信息，通过在子演示级别上进行评估和模仿，将具有不同质量的操作原语编码为不同的技能来帮助机器分离出子技能。",
    "en_tdlr": "This paper proposes a method called \"{\\method}\" that can efficiently learn from a small set of clean demonstrations while leveraging the complementary information contained in a large set of noisy demonstrations by evaluating and imitating at the sub-demonstration level, encoding action primitives of varying quality into different skills."
}