{
    "title": "Probabilistic Linguistic Knowledge and Token-level Text Augmentation. (arXiv:2306.16644v1 [cs.CL])",
    "abstract": "This paper investigates the effectiveness of token-level text augmentation and the role of probabilistic linguistic knowledge within a linguistically-motivated evaluation context. Two text augmentation programs, REDA and REDA$_{NG}$, were developed, both implementing five token-level text editing operations: Synonym Replacement (SR), Random Swap (RS), Random Insertion (RI), Random Deletion (RD), and Random Mix (RM). REDA$_{NG}$ leverages pretrained $n$-gram language models to select the most likely augmented texts from REDA's output. Comprehensive and fine-grained experiments were conducted on a binary question matching classification task in both Chinese and English. The results strongly refute the general effectiveness of the five token-level text augmentation techniques under investigation, whether applied together or separately, and irrespective of various common classification model types used, including transformers. Furthermore, the role of probabilistic linguistic knowledge is ",
    "link": "http://arxiv.org/abs/2306.16644",
    "context": "Title: Probabilistic Linguistic Knowledge and Token-level Text Augmentation. (arXiv:2306.16644v1 [cs.CL])\nAbstract: This paper investigates the effectiveness of token-level text augmentation and the role of probabilistic linguistic knowledge within a linguistically-motivated evaluation context. Two text augmentation programs, REDA and REDA$_{NG}$, were developed, both implementing five token-level text editing operations: Synonym Replacement (SR), Random Swap (RS), Random Insertion (RI), Random Deletion (RD), and Random Mix (RM). REDA$_{NG}$ leverages pretrained $n$-gram language models to select the most likely augmented texts from REDA's output. Comprehensive and fine-grained experiments were conducted on a binary question matching classification task in both Chinese and English. The results strongly refute the general effectiveness of the five token-level text augmentation techniques under investigation, whether applied together or separately, and irrespective of various common classification model types used, including transformers. Furthermore, the role of probabilistic linguistic knowledge is ",
    "path": "papers/23/06/2306.16644.json",
    "total_tokens": 892,
    "translated_title": "概率语言知识与标记级文本增强",
    "translated_abstract": "本文研究了在语言学驱动的评估环境下，标记级文本增强的有效性以及概率语言知识的作用。我们开发了两个文本增强程序REDA和REDA$_{NG}$，它们都实现了五种标记级文本编辑操作：同义词替换(SR)、随机交换(RS)、随机插入(RI)、随机删除(RD)和随机混合(RM)。REDA$_{NG}$利用预训练的n-gram语言模型从REDA的输出中选择最可能的增强文本。我们对中文和英文的二元问题匹配分类任务进行了全面和细致的实验。结果强烈否定了所研究的五种标记级文本增强技术的普遍有效性，无论是同时应用还是分别应用，也无论使用了哪种常见的分类模型类型，包括transformers。此外，概率语言知识的作用是...",
    "tldr": "研究了标记级文本增强的有效性和概率语言知识的作用，实验证明了所研究的五种标记级文本增强技术在语言评估环境下不具备普遍有效性，而且与不同分类模型类型无关。",
    "en_tdlr": "Investigated the effectiveness of token-level text augmentation and the role of probabilistic linguistic knowledge, the experiments showed that the five token-level text augmentation techniques under investigation do not have general effectiveness in a linguistically-motivated evaluation context, regardless of the classification model type used."
}