{
    "title": "HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine. (arXiv:2306.06029v1 [cs.CL])",
    "abstract": "Providing high quality explanations for AI predictions based on machine learning is a challenging and complex task. To work well it requires, among other factors: selecting a proper level of generality/specificity of the explanation; considering assumptions about the familiarity of the explanation beneficiary with the AI task under consideration; referring to specific elements that have contributed to the decision; making use of additional knowledge (e.g. expert evidence) which might not be part of the prediction process; and providing evidence supporting negative hypothesis. Finally, the system needs to formulate the explanation in a clearly interpretable, and possibly convincing, way. Given these considerations, ANTIDOTE fosters an integrated vision of explainable AI, where low-level characteristics of the deep learning process are combined with higher level schemes proper of the human argumentation capacity. ANTIDOTE will exploit cross-disciplinary competences in deep learning and a",
    "link": "http://arxiv.org/abs/2306.06029",
    "context": "Title: HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine. (arXiv:2306.06029v1 [cs.CL])\nAbstract: Providing high quality explanations for AI predictions based on machine learning is a challenging and complex task. To work well it requires, among other factors: selecting a proper level of generality/specificity of the explanation; considering assumptions about the familiarity of the explanation beneficiary with the AI task under consideration; referring to specific elements that have contributed to the decision; making use of additional knowledge (e.g. expert evidence) which might not be part of the prediction process; and providing evidence supporting negative hypothesis. Finally, the system needs to formulate the explanation in a clearly interpretable, and possibly convincing, way. Given these considerations, ANTIDOTE fosters an integrated vision of explainable AI, where low-level characteristics of the deep learning process are combined with higher level schemes proper of the human argumentation capacity. ANTIDOTE will exploit cross-disciplinary competences in deep learning and a",
    "path": "papers/23/06/2306.06029.json",
    "total_tokens": 868,
    "translated_title": "HiTZ@Antidote: 面向数字医疗的基于论证的可解释人工智能",
    "translated_abstract": "基于机器学习的AI预测提供高质量的解释是一个具有挑战性和复杂性的任务。要使其正常工作，需要选择适当的解释泛化/细化水平；考虑解释受益者对所考虑的AI任务的熟悉程度的假设；涉及到对促成决策的具体元素的引用；利用可能不是预测过程的一部分的其他知识（例如专家证据）；并以清晰易懂、可能具说服力的方式表述解释。鉴于这些考虑因素，ANTIDOTE在可解释AI方面培育了一个综合的视角，将深度学习过程的低级特征与人类论证能力的更高级别方案相结合。ANTIDOTE将利用深度学习和论证理论的跨学科竞争优势，解决数字医学领域提供高质量AI预测解释的挑战。",
    "tldr": "HiTZ@Antidote采用深度学习和论证理论，提供数字医疗领域高质量的可解释AI预测解释。"
}