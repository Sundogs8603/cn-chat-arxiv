{
    "title": "Sound Explanation for Trustworthy Machine Learning. (arXiv:2306.06134v1 [cs.LG])",
    "abstract": "We take a formal approach to the explainability problem of machine learning systems. We argue against the practice of interpreting black-box models via attributing scores to input components due to inherently conflicting goals of attribution-based interpretation. We prove that no attribution algorithm satisfies specificity, additivity, completeness, and baseline invariance. We then formalize the concept, sound explanation, that has been informally adopted in prior work. A sound explanation entails providing sufficient information to causally explain the predictions made by a system. Finally, we present the application of feature selection as a sound explanation for cancer prediction models to cultivate trust among clinicians.",
    "link": "http://arxiv.org/abs/2306.06134",
    "context": "Title: Sound Explanation for Trustworthy Machine Learning. (arXiv:2306.06134v1 [cs.LG])\nAbstract: We take a formal approach to the explainability problem of machine learning systems. We argue against the practice of interpreting black-box models via attributing scores to input components due to inherently conflicting goals of attribution-based interpretation. We prove that no attribution algorithm satisfies specificity, additivity, completeness, and baseline invariance. We then formalize the concept, sound explanation, that has been informally adopted in prior work. A sound explanation entails providing sufficient information to causally explain the predictions made by a system. Finally, we present the application of feature selection as a sound explanation for cancer prediction models to cultivate trust among clinicians.",
    "path": "papers/23/06/2306.06134.json",
    "total_tokens": 791,
    "translated_title": "可信机器学习的声音解释",
    "translated_abstract": "我们采用正式的方法来解决机器学习系统的可解释性问题。我们反对通过将分数归因于输入组件来解释黑盒模型的惯例，因为这种解释方法的目标存在内在的冲突。我们证明没有任何归因算法能够满足特异性、可加性、完整性和基线不变性。然后，我们正式定义了在以前的工作中不正式采用的概念——声音解释。一个声音的解释需要提供足够的信息来因果解释系统所进行的预测。最后，我们提出应用特征选择作为癌症预测模型的声音解释，以建立临床医生之间的信任。",
    "tldr": "本篇论文提出了声音解释的概念，以提供足够的信息来因果解释机器学习系统进行的预测，反对通过将分数归因于输入组件来解释黑盒模型的惯例，并且提出应用特征选择作为癌症预测模型的声音解释，以建立临床医生之间的信任。",
    "en_tdlr": "This paper proposes the concept of sound explanation, which provides sufficient information to causally explain the predictions made by machine learning systems, while arguing against the practice of interpreting black-box models via attributing scores to input components. The paper also presents the application of feature selection as a sound explanation for cancer prediction models to cultivate trust among clinicians."
}