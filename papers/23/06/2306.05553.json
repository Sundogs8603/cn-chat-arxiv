{
    "title": "Equivariant vs. Invariant Layers: A Comparison of Backbone and Pooling for Point Cloud Classification. (arXiv:2306.05553v1 [cs.CV])",
    "abstract": "Learning from set-structured data, such as point clouds, has gained significant attention from the community. Geometric deep learning provides a blueprint for designing effective set neural networks by incorporating permutation symmetry. Of our interest are permutation invariant networks, which are composed of a permutation equivariant backbone, permutation invariant global pooling, and regression/classification head. While existing literature has focused on improving permutation equivariant backbones, the impact of global pooling is often overlooked. In this paper, we examine the interplay between permutation equivariant backbones and permutation invariant global pooling on three benchmark point cloud classification datasets. Our findings reveal that: 1) complex pooling methods, such as transport-based or attention-based poolings, can significantly boost the performance of simple backbones, but the benefits diminish for more complex backbones, 2) even complex backbones can benefit fro",
    "link": "http://arxiv.org/abs/2306.05553",
    "context": "Title: Equivariant vs. Invariant Layers: A Comparison of Backbone and Pooling for Point Cloud Classification. (arXiv:2306.05553v1 [cs.CV])\nAbstract: Learning from set-structured data, such as point clouds, has gained significant attention from the community. Geometric deep learning provides a blueprint for designing effective set neural networks by incorporating permutation symmetry. Of our interest are permutation invariant networks, which are composed of a permutation equivariant backbone, permutation invariant global pooling, and regression/classification head. While existing literature has focused on improving permutation equivariant backbones, the impact of global pooling is often overlooked. In this paper, we examine the interplay between permutation equivariant backbones and permutation invariant global pooling on three benchmark point cloud classification datasets. Our findings reveal that: 1) complex pooling methods, such as transport-based or attention-based poolings, can significantly boost the performance of simple backbones, but the benefits diminish for more complex backbones, 2) even complex backbones can benefit fro",
    "path": "papers/23/06/2306.05553.json",
    "total_tokens": 1084,
    "translated_title": "等变层与不变层的对比：点云分类中骨干网络和池化的比较",
    "translated_abstract": "学习点云等集合结构数据已受到学术界的广泛关注。几何深度学习通过整合置换对称性，为设计有效的点云神经网络提供了蓝本。我们感兴趣的是置换不变网络，该网络由置换等变骨干、置换不变全局池化和回归/分类头组成。尽管现有文献侧重于改善置换等变骨干，但全局池化的影响往往被忽视。在本文中，我们研究了置换等变骨干和置换不变全局池化在三个基准点云分类数据集上的相互作用。我们的研究结果表明：1）诸如基于传输或注意力的复杂池化方法可以显著提高简单骨干的性能，但对于更复杂的骨干，这些方法的收益会减弱。2）甚至复杂的骨干也可以受益于更复杂的池化方法，这些方法明确地编码置换不变性。3）使用置换不变池化对于在点云分类数据集上获得最先进的结果至关重要。",
    "tldr": "本文研究了置换等变骨干和置换不变全局池化在点云分类中的相互作用，揭示了使用复杂池化方法可以显著提高简单骨干的性能，但即使是复杂的骨干也可以受益于更复杂的、明确编码置换不变性的池化方法，使用置换不变池化是获得最先进结果的关键。"
}