{
    "title": "Action Q-Transformer: Visual Explanation in Deep Reinforcement Learning with Encoder-Decoder Model using Action Query. (arXiv:2306.13879v1 [cs.LG])",
    "abstract": "The excellent performance of Transformer in supervised learning has led to growing interest in its potential application to deep reinforcement learning (DRL) to achieve high performance on a wide variety of problems. However, the decision making of a DRL agent is a black box, which greatly hinders the application of the agent to real-world problems. To address this problem, we propose the Action Q-Transformer (AQT), which introduces a transformer encoder-decoder structure to Q-learning based DRL methods. In AQT, the encoder calculates the state value function and the decoder calculates the advantage function to promote the acquisition of different attentions indicating the agent's decision-making. The decoder in AQT utilizes action queries, which represent the information of each action, as queries. This enables us to obtain the attentions for the state value and for each action. By acquiring and visualizing these attentions that detail the agent's decision-making, we achieve a DRL mod",
    "link": "http://arxiv.org/abs/2306.13879",
    "context": "Title: Action Q-Transformer: Visual Explanation in Deep Reinforcement Learning with Encoder-Decoder Model using Action Query. (arXiv:2306.13879v1 [cs.LG])\nAbstract: The excellent performance of Transformer in supervised learning has led to growing interest in its potential application to deep reinforcement learning (DRL) to achieve high performance on a wide variety of problems. However, the decision making of a DRL agent is a black box, which greatly hinders the application of the agent to real-world problems. To address this problem, we propose the Action Q-Transformer (AQT), which introduces a transformer encoder-decoder structure to Q-learning based DRL methods. In AQT, the encoder calculates the state value function and the decoder calculates the advantage function to promote the acquisition of different attentions indicating the agent's decision-making. The decoder in AQT utilizes action queries, which represent the information of each action, as queries. This enables us to obtain the attentions for the state value and for each action. By acquiring and visualizing these attentions that detail the agent's decision-making, we achieve a DRL mod",
    "path": "papers/23/06/2306.13879.json",
    "total_tokens": 906,
    "translated_title": "基于行为查询的Transformer在深度强化学习中的可视化解释",
    "translated_abstract": "Transformer在监督学习中的出色表现引起了人们对其在深度强化学习(DRL)中应用的日益关注，以在各种问题上实现高性能。然而，DRL智能体的决策过程是一个黑盒子，极大地阻碍了应用智能体到实际问题的发展。为了解决这个问题，我们提出了Action Q-Transformer (AQT)，它引入了一个Transformer编码器-解码器结构到基于Q-学习的DRL方法中。在AQT中，编码器计算状态值函数，解码器计算优势函数，以促进学习特定行为的不同注意力的获取。AQT中的解码器使用行为查询作为查询，代表每个行为的信息。这使我们能够获得表示状态值和每个行为的注意力。通过获取和可视化这些注意力，我们实现了更解释性和透明的DRL模型，并详细描述了智能体的决策过程。",
    "tldr": "该论文提出了一个基于行为查询的Transformer编码器-解码器结构方法（AQT），用于生成深度强化学习模型，该模型更具可解释性，可以具体描述智能体的决策过程。",
    "en_tdlr": "The paper proposes an Action Q-Transformer (AQT) approach, a transformer encoder-decoder model using action query, for generating deep reinforcement learning (DRL) models with higher interpretability and transparency that detail the decision-making process of an agent."
}