{
    "title": "ViP: A Differentially Private Foundation Model for Computer Vision. (arXiv:2306.08842v2 [cs.CV] UPDATED)",
    "abstract": "Artificial intelligence (AI) has seen a tremendous surge in capabilities thanks to the use of foundation models trained on internet-scale data. On the flip side, the uncurated nature of internet-scale data also poses significant privacy and legal risks, as they often contain personal information or copyrighted material that should not be trained on without permission. In this work, we propose as a mitigation measure a recipe to train foundation vision models with differential privacy (DP) guarantee. We identify masked autoencoders as a suitable learning algorithm that aligns well with DP-SGD, and train ViP -- a Vision transformer with differential Privacy -- under a strict privacy budget of $\\epsilon=8$ on the LAION400M dataset. We evaluate the quality of representation learned by ViP using standard downstream vision tasks; in particular, ViP achieves a (non-private) linear probing accuracy of $55.7\\%$ on ImageNet, comparable to that of end-to-end trained AlexNet (trained and evaluated",
    "link": "http://arxiv.org/abs/2306.08842",
    "context": "Title: ViP: A Differentially Private Foundation Model for Computer Vision. (arXiv:2306.08842v2 [cs.CV] UPDATED)\nAbstract: Artificial intelligence (AI) has seen a tremendous surge in capabilities thanks to the use of foundation models trained on internet-scale data. On the flip side, the uncurated nature of internet-scale data also poses significant privacy and legal risks, as they often contain personal information or copyrighted material that should not be trained on without permission. In this work, we propose as a mitigation measure a recipe to train foundation vision models with differential privacy (DP) guarantee. We identify masked autoencoders as a suitable learning algorithm that aligns well with DP-SGD, and train ViP -- a Vision transformer with differential Privacy -- under a strict privacy budget of $\\epsilon=8$ on the LAION400M dataset. We evaluate the quality of representation learned by ViP using standard downstream vision tasks; in particular, ViP achieves a (non-private) linear probing accuracy of $55.7\\%$ on ImageNet, comparable to that of end-to-end trained AlexNet (trained and evaluated",
    "path": "papers/23/06/2306.08842.json",
    "total_tokens": 979,
    "translated_title": "ViP：一个用于计算机视觉的差分隐私基础模型",
    "translated_abstract": "由于使用互联网规模数据训练的基础模型，人工智能（AI）在能力上取得了巨大的突破。然而，互联网规模数据的非筛选性质也带来了重大的隐私和法律风险，因为它们往往包含个人信息或受版权保护的材料，未经许可不应该进行训练。在这项工作中，我们提出了一种缓解措施，即使用差分隐私（DP）保证训练基础视觉模型的方法。我们确定了掩码自编码器作为适合与DP-SGD相匹配的学习算法，并在LAION400M数据集上使用$\\epsilon=8$的严格隐私预算训练了ViP - 一种具有差分隐私的视觉变压器。我们使用标准的下游视觉任务评估了ViP学到的表示质量；特别地，ViP在ImageNet上实现了$55.7\\%$的（非私有）线性探测准确率，与端到端训练的AlexNet相当。",
    "tldr": "本论文提出了ViP，一个使用差分隐私保证的计算机视觉基础模型。通过使用掩码自编码器和DP-SGD算法，我们在LAION400M数据集上训练了ViP。ViP在标准的视觉任务中学到了高质量的表示，并且在ImageNet上达到了与AlexNet相当的准确率。"
}