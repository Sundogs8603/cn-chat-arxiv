{
    "title": "Improving the generalizability and robustness of large-scale traffic signal control. (arXiv:2306.01925v2 [cs.LG] UPDATED)",
    "abstract": "A number of deep reinforcement-learning (RL) approaches propose to control traffic signals. In this work, we study the robustness of such methods along two axes. First, sensor failures and GPS occlusions create missing-data challenges and we show that recent methods remain brittle in the face of these missing data. Second, we provide a more systematic study of the generalization ability of RL methods to new networks with different traffic regimes. Again, we identify the limitations of recent approaches. We then propose using a combination of distributional and vanilla reinforcement learning through a policy ensemble. Building upon the state-of-the-art previous model which uses a decentralized approach for large-scale traffic signal control with graph convolutional networks (GCNs), we first learn models using a distributional reinforcement learning (DisRL) approach. In particular, we use implicit quantile networks (IQN) to model the state-action return distribution with quantile regress",
    "link": "http://arxiv.org/abs/2306.01925",
    "context": "Title: Improving the generalizability and robustness of large-scale traffic signal control. (arXiv:2306.01925v2 [cs.LG] UPDATED)\nAbstract: A number of deep reinforcement-learning (RL) approaches propose to control traffic signals. In this work, we study the robustness of such methods along two axes. First, sensor failures and GPS occlusions create missing-data challenges and we show that recent methods remain brittle in the face of these missing data. Second, we provide a more systematic study of the generalization ability of RL methods to new networks with different traffic regimes. Again, we identify the limitations of recent approaches. We then propose using a combination of distributional and vanilla reinforcement learning through a policy ensemble. Building upon the state-of-the-art previous model which uses a decentralized approach for large-scale traffic signal control with graph convolutional networks (GCNs), we first learn models using a distributional reinforcement learning (DisRL) approach. In particular, we use implicit quantile networks (IQN) to model the state-action return distribution with quantile regress",
    "path": "papers/23/06/2306.01925.json",
    "total_tokens": 877,
    "translated_title": "改善大规模交通信号控制的泛化能力和鲁棒性",
    "translated_abstract": "许多基于深度强化学习的方法被提出来进行交通信号控制。本研究对这些方法的鲁棒性进行了研究。首先，传感器失效和GPS遮挡会产生缺失数据挑战，而我们发现现有方法在面对这些缺失数据时仍然脆弱不堪。其次，我们对强化学习方法在具有不同交通的新网络中的泛化能力进行了更系统的研究，也发现了现有方法的局限性。我们提议使用分布式和普通强化学习的策略组合。本研究在先前的基于图卷积网络的分散式方法的基础上进行，首先采用分布式强化学习方法学习模型，并使用隐式分位数网络(IQN)来建模状态-动作回报分布。",
    "tldr": "本研究以交通信号控制为应用背景，研究了基于深度强化学习的方法在缺失数据和新网络中的鲁棒性和泛化能力，并提出使用分布式和普通强化学习的策略组合来改善这些问题。"
}