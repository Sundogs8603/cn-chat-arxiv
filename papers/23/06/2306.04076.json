{
    "title": "Text-only Domain Adaptation using Unified Speech-Text Representation in Transducer. (arXiv:2306.04076v1 [cs.CL])",
    "abstract": "Domain adaptation using text-only corpus is challenging in end-to-end(E2E) speech recognition. Adaptation by synthesizing audio from text through TTS is resource-consuming. We present a method to learn Unified Speech-Text Representation in Conformer Transducer(USTR-CT) to enable fast domain adaptation using the text-only corpus. Different from the previous textogram method, an extra text encoder is introduced in our work to learn text representation and is removed during inference, so there is no modification for online deployment. To improve the efficiency of adaptation, single-step and multi-step adaptations are also explored. The experiments on adapting LibriSpeech to SPGISpeech show the proposed method reduces the word error rate(WER) by relatively 44% on the target domain, which is better than those of TTS method and textogram method. Also, it is shown the proposed method can be combined with internal language model estimation(ILME) to further improve the performance.",
    "link": "http://arxiv.org/abs/2306.04076",
    "context": "Title: Text-only Domain Adaptation using Unified Speech-Text Representation in Transducer. (arXiv:2306.04076v1 [cs.CL])\nAbstract: Domain adaptation using text-only corpus is challenging in end-to-end(E2E) speech recognition. Adaptation by synthesizing audio from text through TTS is resource-consuming. We present a method to learn Unified Speech-Text Representation in Conformer Transducer(USTR-CT) to enable fast domain adaptation using the text-only corpus. Different from the previous textogram method, an extra text encoder is introduced in our work to learn text representation and is removed during inference, so there is no modification for online deployment. To improve the efficiency of adaptation, single-step and multi-step adaptations are also explored. The experiments on adapting LibriSpeech to SPGISpeech show the proposed method reduces the word error rate(WER) by relatively 44% on the target domain, which is better than those of TTS method and textogram method. Also, it is shown the proposed method can be combined with internal language model estimation(ILME) to further improve the performance.",
    "path": "papers/23/06/2306.04076.json",
    "total_tokens": 930,
    "translated_title": "使用统一的语音-文本表示在转换器中进行纯文本领域自适应",
    "translated_abstract": "在端到端语音识别中，使用纯文本语料的领域自适应是具有挑战性的。通过TTS从文本中合成音频的自适应方法是耗费资源的。我们提出了一种方法来学习统一语音-文本表示在Conformer Transducer（USTR-CT）中以实现使用纯文本语料的快速领域自适应。与之前的文本图方法不同，我们的方法引入了额外的文本编码器来学习文本表示，并在推理过程中将其移除，因此不需要在线部署时修改。为了提高自适应效率，还探索了单步和多步自适应。将LibriSpeech自适应到SPGISpeech的实验表明，所提出的方法在目标领域将词错误率（WER）相对减少了44％，比TTS方法和文本图方法更好地实现了自适应。此外，结果显示所提出的方法可以与内部语言模型估计（ILME）相结合以进一步提高性能。",
    "tldr": "本文提出了一种使用统一语音-文本表示在转换器中进行使用纯文本语料的快速领域自适应的方法，相对于TTS方法和文本图方法，能将目标领域的词错误率相对减少44％。",
    "en_tdlr": "This paper proposes a method using unified speech-text representation in transducer for fast domain adaptation using text-only corpus. The proposed method reduces the word error rate by relatively 44% on the target domain compared to TTS method and textogram method. The method can be combined with internal language model estimation to further improve the performance."
}