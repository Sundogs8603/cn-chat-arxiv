{
    "title": "Which Spurious Correlations Impact Reasoning in NLI Models? A Visual Interactive Diagnosis through Data-Constrained Counterfactuals. (arXiv:2306.12146v1 [cs.CL])",
    "abstract": "We present a human-in-the-loop dashboard tailored to diagnosing potential spurious features that NLI models rely on for predictions. The dashboard enables users to generate diverse and challenging examples by drawing inspiration from GPT-3 suggestions. Additionally, users can receive feedback from a trained NLI model on how challenging the newly created example is and make refinements based on the feedback. Through our investigation, we discover several categories of spurious correlations that impact the reasoning of NLI models, which we group into three categories: Semantic Relevance, Logical Fallacies, and Bias. Based on our findings, we identify and describe various research opportunities, including diversifying training data and assessing NLI models' robustness by creating adversarial test suites.",
    "link": "http://arxiv.org/abs/2306.12146",
    "context": "Title: Which Spurious Correlations Impact Reasoning in NLI Models? A Visual Interactive Diagnosis through Data-Constrained Counterfactuals. (arXiv:2306.12146v1 [cs.CL])\nAbstract: We present a human-in-the-loop dashboard tailored to diagnosing potential spurious features that NLI models rely on for predictions. The dashboard enables users to generate diverse and challenging examples by drawing inspiration from GPT-3 suggestions. Additionally, users can receive feedback from a trained NLI model on how challenging the newly created example is and make refinements based on the feedback. Through our investigation, we discover several categories of spurious correlations that impact the reasoning of NLI models, which we group into three categories: Semantic Relevance, Logical Fallacies, and Bias. Based on our findings, we identify and describe various research opportunities, including diversifying training data and assessing NLI models' robustness by creating adversarial test suites.",
    "path": "papers/23/06/2306.12146.json",
    "total_tokens": 862,
    "translated_title": "哪些伪相关对NLI模型的推理产生影响？基于数据限制的反事实推理的视觉交互式诊断。",
    "translated_abstract": "我们提出了一个人机交互的仪表板，用于诊断NLI模型依赖于进行预测的潜在伪特征。该仪表板使用户能够通过受GPT-3建议启发而生成不同的和具有挑战性的例子。此外，用户可以从经过训练的NLI模型中获得有关新生成的示例的挑战性的反馈，并根据反馈进行改进。通过我们的调查，我们发现了几类影响NLI模型推理的伪相关性，我们将其分为三类：语义相关性、逻辑谬误和偏见。基于我们的发现，我们确定和描述了各种研究机会，包括增加训练数据和创建对抗测试套件来评估NLI模型的鲁棒性。",
    "tldr": "该论文提出了一种针对NLI模型进行推理的人机交互的仪表板，发现了几类伪相关性并将其分为三类：语义相关性、逻辑谬误和偏见，其中包括增加训练数据和创建对抗测试套件来评估NLI模型的鲁棒性。",
    "en_tdlr": "This paper presents a human-in-the-loop dashboard to diagnose potential spurious features in NLI models, discovers several categories of spurious correlations that impact their reasoning, and identifies research opportunities including diversifying training data and assessing their robustness with adversarial test suites."
}