{
    "title": "Penalty Gradient Normalization for Generative Adversarial Networks. (arXiv:2306.13576v1 [cs.CV])",
    "abstract": "In this paper, we propose a novel normalization method called penalty gradient normalization (PGN) to tackle the training instability of Generative Adversarial Networks (GANs) caused by the sharp gradient space. Unlike existing work such as gradient penalty and spectral normalization, the proposed PGN only imposes a penalty gradient norm constraint on the discriminator function, which increases the capacity of the discriminator. Moreover, the proposed penalty gradient normalization can be applied to different GAN architectures with little modification. Extensive experiments on three datasets show that GANs trained with penalty gradient normalization outperform existing methods in terms of both Frechet Inception and Distance and Inception Score.",
    "link": "http://arxiv.org/abs/2306.13576",
    "context": "Title: Penalty Gradient Normalization for Generative Adversarial Networks. (arXiv:2306.13576v1 [cs.CV])\nAbstract: In this paper, we propose a novel normalization method called penalty gradient normalization (PGN) to tackle the training instability of Generative Adversarial Networks (GANs) caused by the sharp gradient space. Unlike existing work such as gradient penalty and spectral normalization, the proposed PGN only imposes a penalty gradient norm constraint on the discriminator function, which increases the capacity of the discriminator. Moreover, the proposed penalty gradient normalization can be applied to different GAN architectures with little modification. Extensive experiments on three datasets show that GANs trained with penalty gradient normalization outperform existing methods in terms of both Frechet Inception and Distance and Inception Score.",
    "path": "papers/23/06/2306.13576.json",
    "total_tokens": 899,
    "translated_title": "生成对抗网络的罚分梯度归一化方法",
    "translated_abstract": "本文提出一种罚分梯度归一化（PGN）的新的归一化方法来解决生成对抗网络（GANs）训练不稳定的问题，该问题是由尖锐的梯度空间引起的。与梯度惩罚和谱归一化等现有方法不同，所提出的PGN仅对鉴别器函数施加罚分梯度范数约束，从而提高了鉴别器的容量。此外，所提出的罚分梯度归一化方法可以应用于不同的GAN体系结构，只需进行少量修改。在三个数据集的大量实验中，使用罚分梯度归一化训练的GAN优于现有方法，无论是在Frechet Inception距离还是Inception Score上都有同样的表现。",
    "tldr": "本文提出一种名为罚分梯度归一化的方法，用于解决生成对抗网络（GANs）训练不稳定的问题。新方法仅对鉴别器函数施加罚分梯度范数约束，提高了鉴别器的容量，并且可以应用于不同的GAN体系结构。实验结果表明，使用罚分梯度归一化进行训练的GAN优于现有方法，无论是在Frechet Inception距离还是Inception Score上都有同样的表现。",
    "en_tdlr": "This paper proposes a penalty gradient normalization (PGN) method to tackle the training instability of Generative Adversarial Networks (GANs). PGN only imposes a penalty gradient norm constraint on the discriminator function, increasing its capacity. The approach can be applied to different GAN architectures with little modification and has been proven to outperform existing methods in terms of Frechet Inception and Distance as well as Inception Score on three datasets."
}