{
    "title": "On the Identification and Optimization of Nonsmooth Superposition Operators in Semilinear Elliptic PDEs. (arXiv:2306.05185v1 [math.OC])",
    "abstract": "We study an infinite-dimensional optimization problem that aims to identify the Nemytskii operator in the nonlinear part of a prototypical semilinear elliptic partial differential equation (PDE) which minimizes the distance between the PDE-solution and a given desired state. In contrast to previous works, we consider this identification problem in a low-regularity regime in which the function inducing the Nemytskii operator is a-priori only known to be an element of $H^1_{loc}(\\mathbb{R})$. This makes the studied problem class a suitable point of departure for the rigorous analysis of training problems for learning-informed PDEs in which an unknown superposition operator is approximated by means of a neural network with nonsmooth activation functions (ReLU, leaky-ReLU, etc.). We establish that, despite the low regularity of the controls, it is possible to derive a classical stationarity system for local minimizers and to solve the considered problem by means of a gradient projection me",
    "link": "http://arxiv.org/abs/2306.05185",
    "context": "Title: On the Identification and Optimization of Nonsmooth Superposition Operators in Semilinear Elliptic PDEs. (arXiv:2306.05185v1 [math.OC])\nAbstract: We study an infinite-dimensional optimization problem that aims to identify the Nemytskii operator in the nonlinear part of a prototypical semilinear elliptic partial differential equation (PDE) which minimizes the distance between the PDE-solution and a given desired state. In contrast to previous works, we consider this identification problem in a low-regularity regime in which the function inducing the Nemytskii operator is a-priori only known to be an element of $H^1_{loc}(\\mathbb{R})$. This makes the studied problem class a suitable point of departure for the rigorous analysis of training problems for learning-informed PDEs in which an unknown superposition operator is approximated by means of a neural network with nonsmooth activation functions (ReLU, leaky-ReLU, etc.). We establish that, despite the low regularity of the controls, it is possible to derive a classical stationarity system for local minimizers and to solve the considered problem by means of a gradient projection me",
    "path": "papers/23/06/2306.05185.json",
    "total_tokens": 957,
    "translated_title": "关于半线性椭圆PDE中非光滑超定算子的识别和优化",
    "translated_abstract": "我们研究了一个无限维优化问题，目的是识别半线性椭圆偏微分方程(PDE)非线性部分中的Nemytskii算子，该算子将PDE解与给定的期望状态之间的距离最小化。与以前的工作不同，我们在低正则性情况下考虑了这个识别问题，在这种情况下引起Nemytskii算子函数先验仅被认为是H^1_{loc}(\\mathbb{R})的元素。这使得研究的问题类成为一种适合从严格分析的角度来处理学习有关PDE的培训问题的出发点，其中未知的超定算子是通过使用非光滑激活函数(ReLU，leaky-ReLU等)的神经网络逼近的。我们证明，尽管控制的正则性较低，但可以为局部极小值导出经典的站点系统，并通过梯度投影法解决所考虑的问题。",
    "tldr": "本文研究了在低正则性情况下，如何识别半线性椭圆PDE中的Nemytskii算子以及如何解决这个优化问题。这对于进行有关PDE的神经网络训练问题有很好的启示作用。",
    "en_tdlr": "This paper studies how to identify the Nemytskii operator in semilinear elliptic partial differential equations (PDEs) with low regularity and solve the optimization problem. This work provides insights for neural network training on PDEs with unknown superposition operator approximated by nonsmooth activation functions."
}