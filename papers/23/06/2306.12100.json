{
    "title": "Efficient ResNets: Residual Network Design. (arXiv:2306.12100v1 [cs.CV])",
    "abstract": "ResNets (or Residual Networks) are one of the most commonly used models for image classification tasks. In this project, we design and train a modified ResNet model for CIFAR-10 image classification. In particular, we aimed at maximizing the test accuracy on the CIFAR-10 benchmark while keeping the size of our ResNet model under the specified fixed budget of 5 million trainable parameters. Model size, typically measured as the number of trainable parameters, is important when models need to be stored on devices with limited storage capacity (e.g. IoT/edge devices). In this article, we present our residual network design which has less than 5 million parameters. We show that our ResNet achieves a test accuracy of 96.04% on CIFAR-10 which is much higher than ResNet18 (which has greater than 11 million trainable parameters) when equipped with a number of training strategies and suitable ResNet hyperparameters. Models and code are available at https://github.com/Nikunj-Gupta/Efficient_ResN",
    "link": "http://arxiv.org/abs/2306.12100",
    "context": "Title: Efficient ResNets: Residual Network Design. (arXiv:2306.12100v1 [cs.CV])\nAbstract: ResNets (or Residual Networks) are one of the most commonly used models for image classification tasks. In this project, we design and train a modified ResNet model for CIFAR-10 image classification. In particular, we aimed at maximizing the test accuracy on the CIFAR-10 benchmark while keeping the size of our ResNet model under the specified fixed budget of 5 million trainable parameters. Model size, typically measured as the number of trainable parameters, is important when models need to be stored on devices with limited storage capacity (e.g. IoT/edge devices). In this article, we present our residual network design which has less than 5 million parameters. We show that our ResNet achieves a test accuracy of 96.04% on CIFAR-10 which is much higher than ResNet18 (which has greater than 11 million trainable parameters) when equipped with a number of training strategies and suitable ResNet hyperparameters. Models and code are available at https://github.com/Nikunj-Gupta/Efficient_ResN",
    "path": "papers/23/06/2306.12100.json",
    "total_tokens": 921,
    "translated_title": "高效ResNets: 残差网络设计",
    "translated_abstract": "ResNets（残差网络）是最常用的图像分类模型之一。本项目设计和训练了一个修改后的ResNet模型，用于CIFAR-10图像分类。特别地，我们旨在在将我们的ResNet模型大小保持在指定的5百万可训练参数的固定预算以下的同时，最大化在CIFAR-10基准测试上的测试准确性。模型大小通常作为可训练参数的数量进行衡量，当模型需要存储在存储容量有限的设备上时（例如IoT/edge设备），这一点很重要。在本文中，我们介绍了低于5百万参数的残差网络设计。我们展示了我们的ResNet在CIFAR-10上达到了96.04%的测试准确率，这比ResNet18（可训练参数大于1100万）高得多，当配备了一些训练策略和合适的ResNet超参数时。模型和代码可在https://github.com/Nikunj-Gupta/Efficient_ResN上获得。",
    "tldr": "本文介绍了一个在CIFAR-10图像分类任务上可训练参数小于5百万的改进版ResNet模型，达到了96.04%的测试准确率，远优于其可训练参数大于1100万的基准架构ResNet18。",
    "en_tdlr": "This paper presents a modified ResNet model with less than 5 million trainable parameters for CIFAR-10 image classification task, achieving a test accuracy of 96.04%, which is much higher than the benchmark architecture ResNet18 with over 11 million trainable parameters."
}