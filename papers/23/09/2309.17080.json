{
    "title": "GAIA-1: A Generative World Model for Autonomous Driving. (arXiv:2309.17080v1 [cs.CV])",
    "abstract": "Autonomous driving promises transformative improvements to transportation, but building systems capable of safely navigating the unstructured complexity of real-world scenarios remains challenging. A critical problem lies in effectively predicting the various potential outcomes that may emerge in response to the vehicle's actions as the world evolves.  To address this challenge, we introduce GAIA-1 ('Generative AI for Autonomy'), a generative world model that leverages video, text, and action inputs to generate realistic driving scenarios while offering fine-grained control over ego-vehicle behavior and scene features. Our approach casts world modeling as an unsupervised sequence modeling problem by mapping the inputs to discrete tokens, and predicting the next token in the sequence. Emerging properties from our model include learning high-level structures and scene dynamics, contextual awareness, generalization, and understanding of geometry. The power of GAIA-1's learned representati",
    "link": "http://arxiv.org/abs/2309.17080",
    "context": "Title: GAIA-1: A Generative World Model for Autonomous Driving. (arXiv:2309.17080v1 [cs.CV])\nAbstract: Autonomous driving promises transformative improvements to transportation, but building systems capable of safely navigating the unstructured complexity of real-world scenarios remains challenging. A critical problem lies in effectively predicting the various potential outcomes that may emerge in response to the vehicle's actions as the world evolves.  To address this challenge, we introduce GAIA-1 ('Generative AI for Autonomy'), a generative world model that leverages video, text, and action inputs to generate realistic driving scenarios while offering fine-grained control over ego-vehicle behavior and scene features. Our approach casts world modeling as an unsupervised sequence modeling problem by mapping the inputs to discrete tokens, and predicting the next token in the sequence. Emerging properties from our model include learning high-level structures and scene dynamics, contextual awareness, generalization, and understanding of geometry. The power of GAIA-1's learned representati",
    "path": "papers/23/09/2309.17080.json",
    "total_tokens": 897,
    "translated_title": "GAIA-1: 一种用于自动驾驶的生成世界模型",
    "translated_abstract": "自动驾驶承诺为交通带来变革性的改进，但构建能够安全导航真实世界场景的系统仍然具有挑战性。一个关键问题在于有效预测世界随着车辆行为的演变可能出现的各种潜在结果。为了解决这个挑战，我们介绍了GAIA-1（生成智能与自主驾驶），一种生成世界模型，它利用视频、文本和动作输入生成逼真的驾驶场景，同时对自车行为和场景特征提供精细控制。我们的方法将世界建模视为一个无监督的序列建模问题，通过将输入映射到离散标记，并预测序列中的下一个标记来进行。我们的模型从中获得的特征包括学习高级结构和场景动态、上下文感知、泛化能力和几何理解。GAIA-1学到的表示的威力",
    "tldr": "GAIA-1是一个使用视频、文本和动作输入生成逼真驾驶场景的生成世界模型，能够精细控制自车行为和场景特征，并在学习上下文感知、泛化能力和几何理解方面取得了显著成果。",
    "en_tdlr": "GAIA-1 is a generative world model that uses video, text, and action inputs to generate realistic driving scenarios, offering fine-grained control over ego-vehicle behavior and scene features. It achieves significant advancements in contextual awareness, generalization, and understanding of geometry."
}