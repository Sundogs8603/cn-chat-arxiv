{
    "title": "Updated Corpora and Benchmarks for Long-Form Speech Recognition. (arXiv:2309.15013v1 [cs.CL])",
    "abstract": "The vast majority of ASR research uses corpora in which both the training and test data have been pre-segmented into utterances. In most real-word ASR use-cases, however, test audio is not segmented, leading to a mismatch between inference-time conditions and models trained on segmented utterances. In this paper, we re-release three standard ASR corpora - TED-LIUM 3, Gigapeech, and VoxPopuli-en - with updated transcription and alignments to enable their use for long-form ASR research. We use these reconstituted corpora to study the train-test mismatch problem for transducers and attention-based encoder-decoders (AEDs), confirming that AEDs are more susceptible to this issue. Finally, we benchmark a simple long-form training for these models, showing its efficacy for model robustness under this domain shift.",
    "link": "http://arxiv.org/abs/2309.15013",
    "context": "Title: Updated Corpora and Benchmarks for Long-Form Speech Recognition. (arXiv:2309.15013v1 [cs.CL])\nAbstract: The vast majority of ASR research uses corpora in which both the training and test data have been pre-segmented into utterances. In most real-word ASR use-cases, however, test audio is not segmented, leading to a mismatch between inference-time conditions and models trained on segmented utterances. In this paper, we re-release three standard ASR corpora - TED-LIUM 3, Gigapeech, and VoxPopuli-en - with updated transcription and alignments to enable their use for long-form ASR research. We use these reconstituted corpora to study the train-test mismatch problem for transducers and attention-based encoder-decoders (AEDs), confirming that AEDs are more susceptible to this issue. Finally, we benchmark a simple long-form training for these models, showing its efficacy for model robustness under this domain shift.",
    "path": "papers/23/09/2309.15013.json",
    "total_tokens": 900,
    "translated_title": "长篇语音识别的更新语料库和基准",
    "translated_abstract": "绝大多数ASR研究使用预先分割为语句的语料库进行训练和测试。然而，在大多数实际ASR应用场景中，测试音频并没有分割，从而导致推理时条件和训练在分割语句上的模型之间存在不匹配。本文重新发布了三个标准ASR语料库-TED-LIUM 3，Gigapeech和VoxPopuli-en，并更新了转录和对齐，以便将其用于长篇语音识别研究。我们使用这些重组的语料库研究了转录器和基于注意力的编码器-解码器(AEDs)的训练-测试不匹配问题，并确认AEDs对此问题更为敏感。最后，我们为这些模型进行了简单的长篇训练的基准测试，展示了其在此领域转变下的模型稳健性。",
    "tldr": "本研究重新发布了三个标准的ASR语料库，并更新了转录和对齐，以用于长篇语音识别研究。对于转录器和基于注意力的编码器-解码器，我们发现AEDs对于训练-测试不匹配问题更为敏感。在领域转变下，简单的长篇训练可以提高模型的稳健性。"
}