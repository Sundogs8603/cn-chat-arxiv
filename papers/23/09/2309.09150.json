{
    "title": "Can Large Language Models Understand Real-World Complex Instructions?. (arXiv:2309.09150v2 [cs.CL] UPDATED)",
    "abstract": "Large language models (LLMs) can understand human instructions, showing their potential for pragmatic applications beyond traditional NLP tasks. However, they still struggle with complex instructions, which can be either complex task descriptions that require multiple tasks and constraints, or complex input that contains long context, noise, heterogeneous information and multi-turn format. Due to these features, LLMs often ignore semantic constraints from task descriptions, generate incorrect formats, violate length or sample count constraints, and be unfaithful to the input text. Existing benchmarks are insufficient to assess LLMs' ability to understand complex instructions, as they are close-ended and simple. To bridge this gap, we propose CELLO, a benchmark for evaluating LLMs' ability to follow complex instructions systematically. We design eight features for complex instructions and construct a comprehensive evaluation dataset from real-world scenarios. We also establish four crit",
    "link": "http://arxiv.org/abs/2309.09150",
    "context": "Title: Can Large Language Models Understand Real-World Complex Instructions?. (arXiv:2309.09150v2 [cs.CL] UPDATED)\nAbstract: Large language models (LLMs) can understand human instructions, showing their potential for pragmatic applications beyond traditional NLP tasks. However, they still struggle with complex instructions, which can be either complex task descriptions that require multiple tasks and constraints, or complex input that contains long context, noise, heterogeneous information and multi-turn format. Due to these features, LLMs often ignore semantic constraints from task descriptions, generate incorrect formats, violate length or sample count constraints, and be unfaithful to the input text. Existing benchmarks are insufficient to assess LLMs' ability to understand complex instructions, as they are close-ended and simple. To bridge this gap, we propose CELLO, a benchmark for evaluating LLMs' ability to follow complex instructions systematically. We design eight features for complex instructions and construct a comprehensive evaluation dataset from real-world scenarios. We also establish four crit",
    "path": "papers/23/09/2309.09150.json",
    "total_tokens": 843,
    "translated_title": "大规模语言模型能够理解真实世界复杂指令吗？",
    "translated_abstract": "大规模语言模型（LLMs）能够理解人类指令，展示了它们在传统NLP任务之外的实用应用潜力。然而，它们仍然在复杂指令上存在困难，这些指令可以是需要多个任务和约束的复杂任务描述，或者包含长篇背景、噪声、异构信息和多轮格式的复杂输入。由于这些特点，LLMs常常忽略任务描述中的语义约束，产生错误的格式，违反长度或样本计数的约束，对输入文本不忠实。现有的基准不足以评估LLMs理解复杂指令的能力，因为它们是封闭式和简单的。为了弥补这一间隙，我们提出了CELLO，一个用于系统评估LLMs遵循复杂指令能力的基准。我们为复杂指令设计了八个特征，并从现实场景中构建了一个全面的评估数据集。我们还建立了四个评价标准。",
    "tldr": "本论文提出了一个用于评估大规模语言模型理解复杂指令能力的基准——CELLO。通过设计复杂指令的八个特征并构建全面的评估数据集，可以解决现有基准的不足。"
}