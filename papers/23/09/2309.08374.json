{
    "title": "Understanding the limitations of self-supervised learning for tabular anomaly detection. (arXiv:2309.08374v1 [cs.LG])",
    "abstract": "While self-supervised learning has improved anomaly detection in computer vision and natural language processing, it is unclear whether tabular data can benefit from it. This paper explores the limitations of self-supervision for tabular anomaly detection. We conduct several experiments spanning various pretext tasks on 26 benchmark datasets to understand why this is the case. Our results confirm representations derived from self-supervision do not improve tabular anomaly detection performance compared to using the raw representations of the data. We show this is due to neural networks introducing irrelevant features, which reduces the effectiveness of anomaly detectors. However, we demonstrate that using a subspace of the neural network's representation can recover performance.",
    "link": "http://arxiv.org/abs/2309.08374",
    "context": "Title: Understanding the limitations of self-supervised learning for tabular anomaly detection. (arXiv:2309.08374v1 [cs.LG])\nAbstract: While self-supervised learning has improved anomaly detection in computer vision and natural language processing, it is unclear whether tabular data can benefit from it. This paper explores the limitations of self-supervision for tabular anomaly detection. We conduct several experiments spanning various pretext tasks on 26 benchmark datasets to understand why this is the case. Our results confirm representations derived from self-supervision do not improve tabular anomaly detection performance compared to using the raw representations of the data. We show this is due to neural networks introducing irrelevant features, which reduces the effectiveness of anomaly detectors. However, we demonstrate that using a subspace of the neural network's representation can recover performance.",
    "path": "papers/23/09/2309.08374.json",
    "total_tokens": 812,
    "translated_title": "理解自监督学习在表格异常检测中的限制",
    "translated_abstract": "尽管自监督学习已经改进了计算机视觉和自然语言处理中的异常检测，但表格数据是否可以从中受益尚不清楚。本文探讨了自监督学习在表格异常检测中的限制。我们在26个基准数据集上进行了多个实验，涉及各种预训练任务，以了解这种情况的原因。我们的结果证实，与使用原始数据表示相比，通过自监督学习得到的表征并不能提高表格异常检测的性能。我们展示了这是由于神经网络引入了无关的特征，从而降低了异常检测器的有效性。然而，我们证明了使用神经网络表示的子空间可以恢复性能。",
    "tldr": "本研究探讨了自监督学习在表格异常检测中的限制。通过多个实验发现，自监督学习得到的表征并不能提高表格异常检测的性能，这是由于神经网络引入了无关的特征。然而，使用神经网络表示的子空间可以恢复性能。",
    "en_tdlr": "This study explores the limitations of self-supervised learning for tabular anomaly detection. Multiple experiments reveal that representations derived from self-supervision do not improve the performance of anomaly detection, mainly due to the introduction of irrelevant features by neural networks. However, using a subspace of the neural network's representation can recover performance."
}