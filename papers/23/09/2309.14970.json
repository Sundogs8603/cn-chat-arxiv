{
    "title": "Recurrent Hypernetworks are Surprisingly Strong in Meta-RL. (arXiv:2309.14970v1 [cs.LG])",
    "abstract": "Deep reinforcement learning (RL) is notoriously impractical to deploy due to sample inefficiency. Meta-RL directly addresses this sample inefficiency by learning to perform few-shot learning when a distribution of related tasks is available for meta-training. While many specialized meta-RL methods have been proposed, recent work suggests that end-to-end learning in conjunction with an off-the-shelf sequential model, such as a recurrent network, is a surprisingly strong baseline. However, such claims have been controversial due to limited supporting evidence, particularly in the face of prior work establishing precisely the opposite. In this paper, we conduct an empirical investigation. While we likewise find that a recurrent network can achieve strong performance, we demonstrate that the use of hypernetworks is crucial to maximizing their potential. Surprisingly, when combined with hypernetworks, the recurrent baselines that are far simpler than existing specialized methods actually ac",
    "link": "http://arxiv.org/abs/2309.14970",
    "context": "Title: Recurrent Hypernetworks are Surprisingly Strong in Meta-RL. (arXiv:2309.14970v1 [cs.LG])\nAbstract: Deep reinforcement learning (RL) is notoriously impractical to deploy due to sample inefficiency. Meta-RL directly addresses this sample inefficiency by learning to perform few-shot learning when a distribution of related tasks is available for meta-training. While many specialized meta-RL methods have been proposed, recent work suggests that end-to-end learning in conjunction with an off-the-shelf sequential model, such as a recurrent network, is a surprisingly strong baseline. However, such claims have been controversial due to limited supporting evidence, particularly in the face of prior work establishing precisely the opposite. In this paper, we conduct an empirical investigation. While we likewise find that a recurrent network can achieve strong performance, we demonstrate that the use of hypernetworks is crucial to maximizing their potential. Surprisingly, when combined with hypernetworks, the recurrent baselines that are far simpler than existing specialized methods actually ac",
    "path": "papers/23/09/2309.14970.json",
    "total_tokens": 881,
    "translated_title": "递归超网络在元强化学习中表现出惊人的强大性能",
    "translated_abstract": "深度强化学习在实际应用时因样本效率低而不易部署。元强化学习通过学习在元训练时利用相关任务的分布来实现少样本学习，直接解决了这个样本效率问题。最近的研究表明，与专门的元强化学习方法相比，与一个通用的序列模型（如循环神经网络）结合的端到端学习是一个令人惊讶的强基准。然而，这样的观点由于有限的支持证据而引起了争议，特别是在之前的研究中确立了完全相反的观点。在本文中，我们进行了实证研究。虽然我们同样发现循环网络可以达到强大的性能，但我们证明了超网络的使用对于发挥循环基线的潜力至关重要。令人惊讶的是，与超网络相结合时，这种远比现有专门方法简单的循环基准实际上能取得更好的表现。",
    "tldr": "递归超网络和循环神经网络在元强化学习中的端到端学习表现出惊人的强大性能，相比于现有专门方法更为简单但效果更好。"
}