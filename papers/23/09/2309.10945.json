{
    "title": "Benchmarks for Pir\\'a 2.0, a Reading Comprehension Dataset about the Ocean, the Brazilian Coast, and Climate Change. (arXiv:2309.10945v1 [cs.CL])",
    "abstract": "Pir\\'a is a reading comprehension dataset focused on the ocean, the Brazilian coast, and climate change, built from a collection of scientific abstracts and reports on these topics. This dataset represents a versatile language resource, particularly useful for testing the ability of current machine learning models to acquire expert scientific knowledge. Despite its potential, a detailed set of baselines has not yet been developed for Pir\\'a. By creating these baselines, researchers can more easily utilize Pir\\'a as a resource for testing machine learning models across a wide range of question answering tasks. In this paper, we define six benchmarks over the Pir\\'a dataset, covering closed generative question answering, machine reading comprehension, information retrieval, open question answering, answer triggering, and multiple choice question answering. As part of this effort, we have also produced a curated version of the original dataset, where we fixed a number of grammar issues, r",
    "link": "http://arxiv.org/abs/2309.10945",
    "context": "Title: Benchmarks for Pir\\'a 2.0, a Reading Comprehension Dataset about the Ocean, the Brazilian Coast, and Climate Change. (arXiv:2309.10945v1 [cs.CL])\nAbstract: Pir\\'a is a reading comprehension dataset focused on the ocean, the Brazilian coast, and climate change, built from a collection of scientific abstracts and reports on these topics. This dataset represents a versatile language resource, particularly useful for testing the ability of current machine learning models to acquire expert scientific knowledge. Despite its potential, a detailed set of baselines has not yet been developed for Pir\\'a. By creating these baselines, researchers can more easily utilize Pir\\'a as a resource for testing machine learning models across a wide range of question answering tasks. In this paper, we define six benchmarks over the Pir\\'a dataset, covering closed generative question answering, machine reading comprehension, information retrieval, open question answering, answer triggering, and multiple choice question answering. As part of this effort, we have also produced a curated version of the original dataset, where we fixed a number of grammar issues, r",
    "path": "papers/23/09/2309.10945.json",
    "total_tokens": 892,
    "translated_title": "Pir\\'a 2.0的基准测试：一个关于海洋、巴西海岸和气候变化的阅读理解数据集",
    "translated_abstract": "Pir\\'a是一个专注于海洋、巴西海岸和气候变化的阅读理解数据集，该数据集是从有关这些主题的科学摘要和报告的收藏中构建而成的。该数据集代表了一种通用的语言资源，特别适用于测试当前机器学习模型获取专家科学知识的能力。尽管具有潜力，但Pir\\'a尚未开发出详细的基准测试。通过创建这些基准测试，研究人员可以更轻松地利用Pir\\'a作为测试各种问答任务的机器学习模型的资源。在本文中，我们为Pir\\'a数据集定义了六个基准测试，涵盖封闭生成问答、机器阅读理解、信息检索、开放式问答、答案触发和多项选择问答。作为这一努力的一部分，我们还制作了原始数据集的精选版本，其中修正了一些语法问题。",
    "tldr": "通过创建基准测试，我们为Pir\\'a 2.0数据集定义了六个不同的问答任务的测试，可以更好地利用该数据集来评估当前机器学习模型在阅读理解方面的能力。"
}