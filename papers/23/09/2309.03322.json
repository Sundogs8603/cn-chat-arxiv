{
    "title": "REBOOT: Reuse Data for Bootstrapping Efficient Real-World Dexterous Manipulation. (arXiv:2309.03322v1 [cs.LG])",
    "abstract": "Dexterous manipulation tasks involving contact-rich interactions pose a significant challenge for both model-based control systems and imitation learning algorithms. The complexity arises from the need for multi-fingered robotic hands to dynamically establish and break contacts, balance non-prehensile forces, and control large degrees of freedom. Reinforcement learning (RL) offers a promising approach due to its general applicability and capacity to autonomously acquire optimal manipulation strategies. However, its real-world application is often hindered by the necessity to generate a large number of samples, reset the environment, and obtain reward signals. In this work, we introduce an efficient system for learning dexterous manipulation skills with RL to alleviate these challenges. The main idea of our approach is the integration of recent advances in sample-efficient RL and replay buffer bootstrapping. This combination allows us to utilize data from different tasks or objects as a",
    "link": "http://arxiv.org/abs/2309.03322",
    "context": "Title: REBOOT: Reuse Data for Bootstrapping Efficient Real-World Dexterous Manipulation. (arXiv:2309.03322v1 [cs.LG])\nAbstract: Dexterous manipulation tasks involving contact-rich interactions pose a significant challenge for both model-based control systems and imitation learning algorithms. The complexity arises from the need for multi-fingered robotic hands to dynamically establish and break contacts, balance non-prehensile forces, and control large degrees of freedom. Reinforcement learning (RL) offers a promising approach due to its general applicability and capacity to autonomously acquire optimal manipulation strategies. However, its real-world application is often hindered by the necessity to generate a large number of samples, reset the environment, and obtain reward signals. In this work, we introduce an efficient system for learning dexterous manipulation skills with RL to alleviate these challenges. The main idea of our approach is the integration of recent advances in sample-efficient RL and replay buffer bootstrapping. This combination allows us to utilize data from different tasks or objects as a",
    "path": "papers/23/09/2309.03322.json",
    "total_tokens": 899,
    "translated_title": "REBOOT: 重用数据以引导高效的现实世界灵巧操纵",
    "translated_abstract": "对于涉及接触密集交互的灵巧操纵任务，模型驱动的控制系统和模仿学习算法都面临着巨大的挑战。复杂性来自于多指机器人手需要动态建立和断开接触、平衡非伸手持力并控制大量自由度。强化学习（RL）由于其广泛适用性和自主获取最佳操纵策略的能力而具有很大的潜力。然而，它在真实世界的应用常常受到生成大量样本、重置环境和获取奖励信号的限制。在这项工作中，我们引入了一种用于学习具有RL的灵巧操纵技能的高效系统，以解决这些挑战。我们方法的主要思想是将最近在样本高效RL和回放缓冲区引导方面的进展相结合。这种组合使我们能够利用来自不同任务或物体的数据作为输入。",
    "tldr": "本论文介绍了一种使用强化学习学习灵巧操纵技能的高效系统，通过结合样本高效强化学习和回放缓冲区引导，实现了重用数据以降低真实世界应用中的挑战。",
    "en_tdlr": "This paper introduces an efficient system for learning dexterous manipulation skills using reinforcement learning by combining recent advances in sample-efficient RL and replay buffer bootstrapping, enabling the reuse of data to alleviate challenges in real-world applications."
}