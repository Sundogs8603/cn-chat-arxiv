{
    "title": "AV-CPL: Continuous Pseudo-Labeling for Audio-Visual Speech Recognition. (arXiv:2309.17395v1 [cs.LG])",
    "abstract": "Audio-visual speech contains synchronized audio and visual information that provides cross-modal supervision to learn representations for both automatic speech recognition (ASR) and visual speech recognition (VSR). We introduce continuous pseudo-labeling for audio-visual speech recognition (AV-CPL), a semi-supervised method to train an audio-visual speech recognition (AVSR) model on a combination of labeled and unlabeled videos with continuously regenerated pseudo-labels. Our models are trained for speech recognition from audio-visual inputs and can perform speech recognition using both audio and visual modalities, or only one modality. Our method uses the same audio-visual model for both supervised training and pseudo-label generation, mitigating the need for external speech recognition models to generate pseudo-labels. AV-CPL obtains significant improvements in VSR performance on the LRS3 dataset while maintaining practical ASR and AVSR performance. Finally, using visual-only speech ",
    "link": "http://arxiv.org/abs/2309.17395",
    "context": "Title: AV-CPL: Continuous Pseudo-Labeling for Audio-Visual Speech Recognition. (arXiv:2309.17395v1 [cs.LG])\nAbstract: Audio-visual speech contains synchronized audio and visual information that provides cross-modal supervision to learn representations for both automatic speech recognition (ASR) and visual speech recognition (VSR). We introduce continuous pseudo-labeling for audio-visual speech recognition (AV-CPL), a semi-supervised method to train an audio-visual speech recognition (AVSR) model on a combination of labeled and unlabeled videos with continuously regenerated pseudo-labels. Our models are trained for speech recognition from audio-visual inputs and can perform speech recognition using both audio and visual modalities, or only one modality. Our method uses the same audio-visual model for both supervised training and pseudo-label generation, mitigating the need for external speech recognition models to generate pseudo-labels. AV-CPL obtains significant improvements in VSR performance on the LRS3 dataset while maintaining practical ASR and AVSR performance. Finally, using visual-only speech ",
    "path": "papers/23/09/2309.17395.json",
    "total_tokens": 872,
    "translated_title": "AV-CPL：用于音频-视觉语音识别的连续伪标记方法",
    "translated_abstract": "音频-视觉语音包含了提供跨模态监督的同步音频和视觉信息，用于学习自动语音识别（ASR）和视觉语音识别（VSR）的表示。我们引入了连续伪标记方法（AV-CPL）用于音频-视觉语音识别，这是一种半监督的方法，通过对标记和未标记视频进行持续生成伪标签来训练音频-视觉语音识别模型（AVSR）。我们的模型从音频-视觉输入中训练语音识别，并可以使用音频和视觉模态进行语音识别，或者只使用一种模态。我们的方法使用相同的音频-视觉模型进行监督训练和伪标签生成，减轻了需要外部语音识别模型生成伪标签的需求。AV-CPL在LRS3数据集上显著提高了VSR性能，同时保持了实用的ASR和AVSR性能。",
    "tldr": "AV-CPL是一种用于音频-视觉语音识别的连续伪标记方法，通过使用同一个模型进行监督训练和伪标签生成，提高了VSR性能并保持了实用性能。"
}