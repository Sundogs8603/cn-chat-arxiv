{
    "title": "Interpretable Medical Imagery Diagnosis with Self-Attentive Transformers: A Review of Explainable AI for Health Care. (arXiv:2309.00252v1 [cs.CV])",
    "abstract": "Recent advancements in artificial intelligence (AI) have facilitated its widespread adoption in primary medical services, addressing the demand-supply imbalance in healthcare. Vision Transformers (ViT) have emerged as state-of-the-art computer vision models, benefiting from self-attention modules. However, compared to traditional machine-learning approaches, deep-learning models are complex and are often treated as a \"black box\" that can cause uncertainty regarding how they operate. Explainable Artificial Intelligence (XAI) refers to methods that explain and interpret machine learning models' inner workings and how they come to decisions, which is especially important in the medical domain to guide the healthcare decision-making process. This review summarises recent ViT advancements and interpretative approaches to understanding the decision-making process of ViT, enabling transparency in medical diagnosis applications.",
    "link": "http://arxiv.org/abs/2309.00252",
    "context": "Title: Interpretable Medical Imagery Diagnosis with Self-Attentive Transformers: A Review of Explainable AI for Health Care. (arXiv:2309.00252v1 [cs.CV])\nAbstract: Recent advancements in artificial intelligence (AI) have facilitated its widespread adoption in primary medical services, addressing the demand-supply imbalance in healthcare. Vision Transformers (ViT) have emerged as state-of-the-art computer vision models, benefiting from self-attention modules. However, compared to traditional machine-learning approaches, deep-learning models are complex and are often treated as a \"black box\" that can cause uncertainty regarding how they operate. Explainable Artificial Intelligence (XAI) refers to methods that explain and interpret machine learning models' inner workings and how they come to decisions, which is especially important in the medical domain to guide the healthcare decision-making process. This review summarises recent ViT advancements and interpretative approaches to understanding the decision-making process of ViT, enabling transparency in medical diagnosis applications.",
    "path": "papers/23/09/2309.00252.json",
    "total_tokens": 788,
    "translated_title": "使用自注意力变换器的可解释医学图像诊断：一个关于可解释人工智能在医疗保健中的综述",
    "translated_abstract": "最近人工智能的进展促使其在初级医疗服务中得到广泛应用，解决了医疗保健中的供需不平衡问题。视觉变换器（ViT）作为最先进的计算机视觉模型出现，受益于自注意力模块。然而，与传统的机器学习方法相比，深度学习模型复杂且常常被看作是一个“黑盒子”，这可能导致对其运作方式的不确定性。可解释的人工智能（XAI）是指解释和解读机器学习模型内部运作方式和决策过程的方法，这在医学领域尤为重要，以指导医疗决策过程。本综述总结了最近ViT的进展和解释性方法，以理解ViT的决策过程，实现医学诊断应用的透明化。",
    "tldr": "本文综述了最近ViT的进展以及对其决策过程的解释性方法，为医学诊断应用提供透明度。"
}