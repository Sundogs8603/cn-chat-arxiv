{
    "title": "Evaluating Transformer's Ability to Learn Mildly Context-Sensitive Languages. (arXiv:2309.00857v2 [cs.CL] UPDATED)",
    "abstract": "Despite the fact that Transformers perform well in NLP tasks, recent studies suggest that self-attention is theoretically limited in learning even some regular and context-free languages. These findings motivated us to think about their implications in modeling natural language, which is hypothesized to be mildly context-sensitive. We test the Transformer's ability to learn mildly context-sensitive languages of varying complexities, and find that they generalize well to unseen in-distribution data, but their ability to extrapolate to longer strings is worse than that of LSTMs. Our analyses show that the learned self-attention patterns and representations modeled dependency relations and demonstrated counting behavior, which may have helped the models solve the languages.",
    "link": "http://arxiv.org/abs/2309.00857",
    "context": "Title: Evaluating Transformer's Ability to Learn Mildly Context-Sensitive Languages. (arXiv:2309.00857v2 [cs.CL] UPDATED)\nAbstract: Despite the fact that Transformers perform well in NLP tasks, recent studies suggest that self-attention is theoretically limited in learning even some regular and context-free languages. These findings motivated us to think about their implications in modeling natural language, which is hypothesized to be mildly context-sensitive. We test the Transformer's ability to learn mildly context-sensitive languages of varying complexities, and find that they generalize well to unseen in-distribution data, but their ability to extrapolate to longer strings is worse than that of LSTMs. Our analyses show that the learned self-attention patterns and representations modeled dependency relations and demonstrated counting behavior, which may have helped the models solve the languages.",
    "path": "papers/23/09/2309.00857.json",
    "total_tokens": 815,
    "translated_title": "评估Transformer学习轻度上下文敏感语言的能力",
    "translated_abstract": "尽管Transformer在自然语言处理任务中表现出色，但最近的研究表明，自注意力在学习一些规则和无上下文语言方面在理论上存在限制。这些发现激发我们思考它们在建模自然语言中的影响，自然语言被假设为轻度上下文敏感。我们测试了Transformer学习多种复杂程度的轻度上下文敏感语言的能力，并发现它们在未见过的分布数据上具有良好的泛化能力，但其对于更长字符串的外推能力低于LSTMs。我们的分析显示，学习到的自注意力模式和表示模型化了依赖关系，并展示了计数行为，这可能有助于模型解决这些语言。",
    "tldr": "本文评估了Transformer学习轻度上下文敏感语言的能力，发现其在泛化到未见过的数据上表现良好，但在外推到较长字符串上的能力不如LSTMs。分析结果显示，Transformer学习到的自注意力模式和表示能够捕捉依赖关系并表现出计数行为。"
}