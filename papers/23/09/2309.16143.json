{
    "title": "Generative Semi-supervised Learning with Meta-Optimized Synthetic Samples. (arXiv:2309.16143v1 [cs.LG])",
    "abstract": "Semi-supervised learning (SSL) is a promising approach for training deep classification models using labeled and unlabeled datasets. However, existing SSL methods rely on a large unlabeled dataset, which may not always be available in many real-world applications due to legal constraints (e.g., GDPR). In this paper, we investigate the research question: Can we train SSL models without real unlabeled datasets? Instead of using real unlabeled datasets, we propose an SSL method using synthetic datasets generated from generative foundation models trained on datasets containing millions of samples in diverse domains (e.g., ImageNet). Our main concepts are identifying synthetic samples that emulate unlabeled samples from generative foundation models and training classifiers using these synthetic samples. To achieve this, our method is formulated as an alternating optimization problem: (i) meta-learning of generative foundation models and (ii) SSL of classifiers using real labeled and synthet",
    "link": "http://arxiv.org/abs/2309.16143",
    "context": "Title: Generative Semi-supervised Learning with Meta-Optimized Synthetic Samples. (arXiv:2309.16143v1 [cs.LG])\nAbstract: Semi-supervised learning (SSL) is a promising approach for training deep classification models using labeled and unlabeled datasets. However, existing SSL methods rely on a large unlabeled dataset, which may not always be available in many real-world applications due to legal constraints (e.g., GDPR). In this paper, we investigate the research question: Can we train SSL models without real unlabeled datasets? Instead of using real unlabeled datasets, we propose an SSL method using synthetic datasets generated from generative foundation models trained on datasets containing millions of samples in diverse domains (e.g., ImageNet). Our main concepts are identifying synthetic samples that emulate unlabeled samples from generative foundation models and training classifiers using these synthetic samples. To achieve this, our method is formulated as an alternating optimization problem: (i) meta-learning of generative foundation models and (ii) SSL of classifiers using real labeled and synthet",
    "path": "papers/23/09/2309.16143.json",
    "total_tokens": 871,
    "translated_title": "基于元优化合成样本的生成式半监督学习",
    "translated_abstract": "半监督学习是使用有标签和无标签数据集来训练深度分类模型的一种有前景的方法。然而，现有的半监督学习方法依赖于大规模的无标签数据集，在许多实际应用中由于法律限制（例如，GDPR）可能无法获取。本文研究一个问题：我们能否在没有实际无标签数据集的情况下训练半监督学习模型？我们提出了一种使用从包含数百万样本的多样领域数据集（例如ImageNet）训练的生成基础模型生成的合成数据集的半监督学习方法。我们的主要思想是识别生成基础模型中仿真无标签样本的合成样本，并使用这些合成样本来训练分类器。为了实现这一点，我们的方法被构建为一个交替优化问题：（i）元学习生成基础模型和（ii）使用真实标记样本和合成样本进行半监督学习的分类器。",
    "tldr": "本文提出了一种基于生成基础模型生成的合成样本进行半监督学习的方法，旨在解决实际应用中无法获取大规模无标签数据集的问题。",
    "en_tdlr": "This paper proposes a semi-supervised learning method using synthetic samples generated from generative foundation models, aiming to address the issue of unavailability of large unlabeled datasets in real-world applications."
}