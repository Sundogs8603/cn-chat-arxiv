{
    "title": "Leveraging Large Language Models for Automated Dialogue Analysis. (arXiv:2309.06490v1 [cs.CL])",
    "abstract": "Developing high-performing dialogue systems benefits from the automatic identification of undesirable behaviors in system responses. However, detecting such behaviors remains challenging, as it draws on a breadth of general knowledge and understanding of conversational practices. Although recent research has focused on building specialized classifiers for detecting specific dialogue behaviors, the behavior coverage is still incomplete and there is a lack of testing on real-world human-bot interactions. This paper investigates the ability of a state-of-the-art large language model (LLM), ChatGPT-3.5, to perform dialogue behavior detection for nine categories in real human-bot dialogues. We aim to assess whether ChatGPT can match specialized models and approximate human performance, thereby reducing the cost of behavior detection tasks. Our findings reveal that neither specialized models nor ChatGPT have yet achieved satisfactory results for this task, falling short of human performance.",
    "link": "http://arxiv.org/abs/2309.06490",
    "context": "Title: Leveraging Large Language Models for Automated Dialogue Analysis. (arXiv:2309.06490v1 [cs.CL])\nAbstract: Developing high-performing dialogue systems benefits from the automatic identification of undesirable behaviors in system responses. However, detecting such behaviors remains challenging, as it draws on a breadth of general knowledge and understanding of conversational practices. Although recent research has focused on building specialized classifiers for detecting specific dialogue behaviors, the behavior coverage is still incomplete and there is a lack of testing on real-world human-bot interactions. This paper investigates the ability of a state-of-the-art large language model (LLM), ChatGPT-3.5, to perform dialogue behavior detection for nine categories in real human-bot dialogues. We aim to assess whether ChatGPT can match specialized models and approximate human performance, thereby reducing the cost of behavior detection tasks. Our findings reveal that neither specialized models nor ChatGPT have yet achieved satisfactory results for this task, falling short of human performance.",
    "path": "papers/23/09/2309.06490.json",
    "total_tokens": 893,
    "translated_title": "利用大型语言模型进行自动对话分析",
    "translated_abstract": "开发高性能对话系统需要自动识别系统回应中的不良行为。然而，由于需要广泛的常识和对话实践的理解，这种行为的检测仍然具有挑战性。尽管最近的研究专注于构建用于检测特定对话行为的特殊分类器，但行为覆盖仍然不完整，并且缺乏对真实人机交互的测试。本文研究了最先进的大型语言模型（LLM）ChatGPT-3.5在真实人机对话中执行九个类别的对话行为检测的能力。我们旨在评估ChatGPT是否能够与专门模型相匹配并接近人类表现，从而降低行为检测任务的成本。我们的研究结果显示，无论是专门模型还是ChatGPT都尚未达到该任务的令人满意的结果，未能达到人类表现水平。",
    "tldr": "本文研究了利用大型语言模型ChatGPT-3.5进行自动对话行为检测的能力，并评估了其与专门模型和人类表现的匹配度。研究结果显示，目前还没有一种模型能够令人满意地实现这一任务，达到人类的性能水平。",
    "en_tdlr": "This paper investigates the ability of a large language model (LLM), ChatGPT-3.5, to perform automated dialogue behavior detection and evaluates its matching with specialized models and human performance. The findings suggest that there is currently no model that can satisfactorily achieve this task at the level of human performance."
}