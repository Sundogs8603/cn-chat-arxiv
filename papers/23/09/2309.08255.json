{
    "title": "Cross-lingual Knowledge Distillation via Flow-based Voice Conversion for Robust Polyglot Text-To-Speech. (arXiv:2309.08255v1 [eess.AS])",
    "abstract": "In this work, we introduce a framework for cross-lingual speech synthesis, which involves an upstream Voice Conversion (VC) model and a downstream Text-To-Speech (TTS) model. The proposed framework consists of 4 stages. In the first two stages, we use a VC model to convert utterances in the target locale to the voice of the target speaker. In the third stage, the converted data is combined with the linguistic features and durations from recordings in the target language, which are then used to train a single-speaker acoustic model. Finally, the last stage entails the training of a locale-independent vocoder. Our evaluations show that the proposed paradigm outperforms state-of-the-art approaches which are based on training a large multilingual TTS model. In addition, our experiments demonstrate the robustness of our approach with different model architectures, languages, speakers and amounts of data. Moreover, our solution is especially beneficial in low-resource settings.",
    "link": "http://arxiv.org/abs/2309.08255",
    "context": "Title: Cross-lingual Knowledge Distillation via Flow-based Voice Conversion for Robust Polyglot Text-To-Speech. (arXiv:2309.08255v1 [eess.AS])\nAbstract: In this work, we introduce a framework for cross-lingual speech synthesis, which involves an upstream Voice Conversion (VC) model and a downstream Text-To-Speech (TTS) model. The proposed framework consists of 4 stages. In the first two stages, we use a VC model to convert utterances in the target locale to the voice of the target speaker. In the third stage, the converted data is combined with the linguistic features and durations from recordings in the target language, which are then used to train a single-speaker acoustic model. Finally, the last stage entails the training of a locale-independent vocoder. Our evaluations show that the proposed paradigm outperforms state-of-the-art approaches which are based on training a large multilingual TTS model. In addition, our experiments demonstrate the robustness of our approach with different model architectures, languages, speakers and amounts of data. Moreover, our solution is especially beneficial in low-resource settings.",
    "path": "papers/23/09/2309.08255.json",
    "total_tokens": 911,
    "translated_title": "通过基于流的语音转换实现跨语言知识蒸馏，用于鲁棒的多语种语音合成",
    "translated_abstract": "在这项工作中，我们引入了一个跨语言语音合成的框架，其中包括一个上游语音转换（VC）模型和一个下游文本到语音（TTS）模型。我们的框架包括4个阶段。在前两个阶段中，我们使用VC模型将目标区域的话语转换为目标说话者的声音。在第三个阶段，将转换后的数据与目标语言录音中的语言特征和持续时间结合起来，然后用于训练一个单说话人声学模型。最后，最后一个阶段将训练一个与语言无关的声码器。我们的评估结果显示，这种提出的范例优于基于训练大型多语种TTS模型的最先进方法。此外，我们的实验证明了我们的方法在不同的模型架构、语言、说话者和数据量方面的鲁棒性。此外，我们的解决方案在资源匮乏的情况下特别有益。",
    "tldr": "本文提出了一个跨语言语音合成的框架，使用语音转换和文本到语音模型，优于基于多语种模型的最先进方法，特别适用于资源匮乏的情况。",
    "en_tdlr": "This paper proposes a framework for cross-lingual speech synthesis using voice conversion and text-to-speech models, which outperforms state-of-the-art approaches based on multilingual models and is particularly beneficial in low-resource settings."
}