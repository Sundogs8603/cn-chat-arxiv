{
    "title": "Markov Chain Mirror Descent On Data Federation. (arXiv:2309.14775v1 [cs.LG])",
    "abstract": "Stochastic optimization methods such as mirror descent have wide applications due to low computational cost. Those methods have been well studied under assumption of the independent and identical distribution, and usually achieve sublinear rate of convergence. However, this assumption may be too strong and unpractical in real application scenarios. Recent researches investigate stochastic gradient descent when instances are sampled from a Markov chain. Unfortunately, few results are known for stochastic mirror descent. In the paper, we propose a new version of stochastic mirror descent termed by MarchOn in the scenario of the federated learning. Given a distributed network, the model iteratively travels from a node to one of its neighbours randomly. Furthermore, we propose a new framework to analyze MarchOn, which yields best rates of convergence for convex, strongly convex, and non-convex loss. Finally, we conduct empirical studies to evaluate the convergence of MarchOn, and validate ",
    "link": "http://arxiv.org/abs/2309.14775",
    "context": "Title: Markov Chain Mirror Descent On Data Federation. (arXiv:2309.14775v1 [cs.LG])\nAbstract: Stochastic optimization methods such as mirror descent have wide applications due to low computational cost. Those methods have been well studied under assumption of the independent and identical distribution, and usually achieve sublinear rate of convergence. However, this assumption may be too strong and unpractical in real application scenarios. Recent researches investigate stochastic gradient descent when instances are sampled from a Markov chain. Unfortunately, few results are known for stochastic mirror descent. In the paper, we propose a new version of stochastic mirror descent termed by MarchOn in the scenario of the federated learning. Given a distributed network, the model iteratively travels from a node to one of its neighbours randomly. Furthermore, we propose a new framework to analyze MarchOn, which yields best rates of convergence for convex, strongly convex, and non-convex loss. Finally, we conduct empirical studies to evaluate the convergence of MarchOn, and validate ",
    "path": "papers/23/09/2309.14775.json",
    "total_tokens": 906,
    "translated_title": "数据联合上的马尔科夫链镜像下降",
    "translated_abstract": "由于计算成本低，随机优化方法如镜像下降具有广泛应用。这些方法在独立同分布的假设下得到了深入研究，并通常达到了亚线性收敛率。然而，这个假设在实际应用场景中可能过于强大和不切实际。最近的研究探究了从马尔科夫链中抽取实例时的随机梯度下降。不幸的是，对于随机镜像下降来说，知之甚少。本文中，我们在联邦学习场景中提出了一种新版本的随机镜像下降，称之为MarchOn。在一个分布式网络中，模型会从一个节点迭代地随机移动到其邻居节点之一。此外，我们还提出了一个新的框架来分析MarchOn，为凸、强凸和非凸损失提供了最佳收敛率。最后，我们进行了实证研究，评估了MarchOn的收敛性，并验证了其性能。",
    "tldr": "本文在联邦学习场景中提出了一种新的随机镜像下降方法MarchOn，在这种方法中，模型通过马尔科夫链进行迭代，具有最佳的收敛性能。",
    "en_tdlr": "In this paper, we propose a new version of stochastic mirror descent called MarchOn in the scenario of federated learning. The model iteratively travels from a node to one of its neighbors randomly using a Markov chain, and achieves the best convergence rates for convex, strongly convex, and non-convex losses."
}