{
    "title": "Dynamic-SUPERB: Towards A Dynamic, Collaborative, and Comprehensive Instruction-Tuning Benchmark for Speech",
    "abstract": "arXiv:2309.09510v2 Announce Type: replace-cross  Abstract: Text language models have shown remarkable zero-shot capability in generalizing to unseen tasks when provided with well-formulated instructions. However, existing studies in speech processing primarily focus on limited or specific tasks. Moreover, the lack of standardized benchmarks hinders a fair comparison across different approaches. Thus, we present Dynamic-SUPERB, a benchmark designed for building universal speech models capable of leveraging instruction tuning to perform multiple tasks in a zero-shot fashion. To achieve comprehensive coverage of diverse speech tasks and harness instruction tuning, we invite the community to collaborate and contribute, facilitating the dynamic growth of the benchmark. To initiate, Dynamic-SUPERB features 55 evaluation instances by combining 33 tasks and 22 datasets. This spans a broad spectrum of dimensions, providing a comprehensive platform for evaluation. Additionally, we propose severa",
    "link": "https://arxiv.org/abs/2309.09510",
    "context": "Title: Dynamic-SUPERB: Towards A Dynamic, Collaborative, and Comprehensive Instruction-Tuning Benchmark for Speech\nAbstract: arXiv:2309.09510v2 Announce Type: replace-cross  Abstract: Text language models have shown remarkable zero-shot capability in generalizing to unseen tasks when provided with well-formulated instructions. However, existing studies in speech processing primarily focus on limited or specific tasks. Moreover, the lack of standardized benchmarks hinders a fair comparison across different approaches. Thus, we present Dynamic-SUPERB, a benchmark designed for building universal speech models capable of leveraging instruction tuning to perform multiple tasks in a zero-shot fashion. To achieve comprehensive coverage of diverse speech tasks and harness instruction tuning, we invite the community to collaborate and contribute, facilitating the dynamic growth of the benchmark. To initiate, Dynamic-SUPERB features 55 evaluation instances by combining 33 tasks and 22 datasets. This spans a broad spectrum of dimensions, providing a comprehensive platform for evaluation. Additionally, we propose severa",
    "path": "papers/23/09/2309.09510.json",
    "total_tokens": 838,
    "translated_title": "Dynamic-SUPERB: 面向动态、协作和全面指令调优的语音基准",
    "translated_abstract": "文本语言模型在提供良好制定的指令时，展示出了在泛化到未见任务时的卓越零-shot能力。然而，目前关于语音处理的研究主要集中在有限或特定任务上。此外，缺乏标准化的基准测试妨碍了在不同方法之间进行公平比较。因此，我们提出Dynamic-SUPERB，这是一个专为构建能够利用指令调优以零-shot方式执行多项任务的通用语音模型而设计的基准测试。为了实现对多样的语音任务的全面覆盖并利用指令调优，我们邀请社区合作和贡献，促进基准测试的动态增长。作为开端，Dynamic-SUPERB通过结合33个任务和22个数据集，提供了55个评估实例。这涵盖了广泛的维度，为评估提供了全面的平台。此外，我们提出了一些",
    "tldr": "提出了 Dynamic-SUPERB 基准测试，旨在构建通用语音模型，利用指令调优实现零-shot执行多任务，通过合作和贡献动态增长基准。",
    "en_tdlr": "Proposed Dynamic-SUPERB benchmark for building universal speech models capable of leveraging instruction tuning to perform multiple tasks in a zero-shot fashion, facilitating dynamic growth through collaboration and contribution."
}