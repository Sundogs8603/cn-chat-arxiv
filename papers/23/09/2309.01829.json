{
    "title": "A Post-Training Approach for Mitigating Overfitting in Quantum Convolutional Neural Networks",
    "abstract": "arXiv:2309.01829v2 Announce Type: replace-cross  Abstract: Quantum convolutional neural network (QCNN), an early application for quantum computers in the NISQ era, has been consistently proven successful as a machine learning (ML) algorithm for several tasks with significant accuracy. Derived from its classical counterpart, QCNN is prone to overfitting. Overfitting is a typical shortcoming of ML models that are trained too closely to the availed training dataset and perform relatively poorly on unseen datasets for a similar problem. In this work we study post-training approaches for mitigating overfitting in QCNNs. We find that a straightforward adaptation of a classical post-training method, known as neuron dropout, to the quantum setting leads to a significant and undesirable consequence: a substantial decrease in success probability of the QCNN. We argue that this effect exposes the crucial role of entanglement in QCNNs and the vulnerability of QCNNs to entanglement loss. Hence, we ",
    "link": "https://arxiv.org/abs/2309.01829",
    "context": "Title: A Post-Training Approach for Mitigating Overfitting in Quantum Convolutional Neural Networks\nAbstract: arXiv:2309.01829v2 Announce Type: replace-cross  Abstract: Quantum convolutional neural network (QCNN), an early application for quantum computers in the NISQ era, has been consistently proven successful as a machine learning (ML) algorithm for several tasks with significant accuracy. Derived from its classical counterpart, QCNN is prone to overfitting. Overfitting is a typical shortcoming of ML models that are trained too closely to the availed training dataset and perform relatively poorly on unseen datasets for a similar problem. In this work we study post-training approaches for mitigating overfitting in QCNNs. We find that a straightforward adaptation of a classical post-training method, known as neuron dropout, to the quantum setting leads to a significant and undesirable consequence: a substantial decrease in success probability of the QCNN. We argue that this effect exposes the crucial role of entanglement in QCNNs and the vulnerability of QCNNs to entanglement loss. Hence, we ",
    "path": "papers/23/09/2309.01829.json",
    "total_tokens": 918,
    "translated_title": "量子卷积神经网络中缓解过拟合的后训练方法",
    "translated_abstract": "量子卷积神经网络（QCNN）作为量子计算机在NISQ时代的早期应用，一直被证明在多个任务中取得显著准确度，作为机器学习（ML）算法一直表现成功。然而，受其经典对应物的影响，QCNN容易出现过拟合问题。本文研究了用于减轻QCNN过拟合的后训练方法。我们发现，简单地将一种称为神经元丢弃的经典后训练方法适应到量子设置中，会导致一个显著且不希望的结果：QCNN的成功概率显著下降。我们认为，这一效果暴露出了纠缠在QCNN中的关键作用，以及QCNN对纠缠丢失的脆弱性。",
    "tldr": "研究了用于减轻量子卷积神经网络过拟合的后训练方法，并发现将经典后训练方法神经元丢弃直接应用到量子设置中会导致成功概率显著下降，揭示了纠缠在QCNN中的关键作用和其对纠缠丢失的脆弱性。",
    "en_tdlr": "Investigated a post-training approach to mitigate overfitting in quantum convolutional neural networks, revealing that directly applying the classical post-training method of neuron dropout to the quantum setting leads to a significant decrease in success probability, emphasizing the crucial role of entanglement in QCNNs and their vulnerability to entanglement loss."
}