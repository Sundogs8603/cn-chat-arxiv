{
    "title": "Prompt-and-Align: Prompt-Based Social Alignment for Few-Shot Fake News Detection. (arXiv:2309.16424v1 [cs.CL])",
    "abstract": "Despite considerable advances in automated fake news detection, due to the timely nature of news, it remains a critical open question how to effectively predict the veracity of news articles based on limited fact-checks. Existing approaches typically follow a \"Train-from-Scratch\" paradigm, which is fundamentally bounded by the availability of large-scale annotated data. While expressive pre-trained language models (PLMs) have been adapted in a \"Pre-Train-and-Fine-Tune\" manner, the inconsistency between pre-training and downstream objectives also requires costly task-specific supervision. In this paper, we propose \"Prompt-and-Align\" (P&A), a novel prompt-based paradigm for few-shot fake news detection that jointly leverages the pre-trained knowledge in PLMs and the social context topology. Our approach mitigates label scarcity by wrapping the news article in a task-related textual prompt, which is then processed by the PLM to directly elicit task-specific knowledge. To supplement the PL",
    "link": "http://arxiv.org/abs/2309.16424",
    "context": "Title: Prompt-and-Align: Prompt-Based Social Alignment for Few-Shot Fake News Detection. (arXiv:2309.16424v1 [cs.CL])\nAbstract: Despite considerable advances in automated fake news detection, due to the timely nature of news, it remains a critical open question how to effectively predict the veracity of news articles based on limited fact-checks. Existing approaches typically follow a \"Train-from-Scratch\" paradigm, which is fundamentally bounded by the availability of large-scale annotated data. While expressive pre-trained language models (PLMs) have been adapted in a \"Pre-Train-and-Fine-Tune\" manner, the inconsistency between pre-training and downstream objectives also requires costly task-specific supervision. In this paper, we propose \"Prompt-and-Align\" (P&A), a novel prompt-based paradigm for few-shot fake news detection that jointly leverages the pre-trained knowledge in PLMs and the social context topology. Our approach mitigates label scarcity by wrapping the news article in a task-related textual prompt, which is then processed by the PLM to directly elicit task-specific knowledge. To supplement the PL",
    "path": "papers/23/09/2309.16424.json",
    "total_tokens": 908,
    "translated_title": "Prompt-and-Align: 基于提示的社交调整用于少样本虚假新闻检测",
    "translated_abstract": "尽管自动检测虚假新闻取得了相当大的进展，但由于新闻的及时性，如何有效地根据有限的事实核对信息来预测新闻文章的真实性仍然是一个关键的未解决问题。现有方法通常遵循“从头训练”的范例，这在根本上受到大规模注释数据的可用性的限制。尽管已经以“预训练和微调”的方式适应了表达能力强的预训练语言模型（PLM），但预训练与下游目标之间的不一致也需要昂贵的任务特定监督。在本文中，我们提出了“Prompt-and-Align”（P&A），一种基于提示的少样本虚假新闻检测新范例，联合利用了PLM中的预训练知识和社交语境拓扑。我们的方法通过将新闻文章包裹在一个与任务相关的文本提示中来缓解标签稀缺性，然后通过PLM处理来直接引出任务特定的知识。",
    "tldr": "这项研究提出了一种基于提示的少样本虚假新闻检测方法，通过结合预训练语言模型和社交语境拓扑，有效地减少了标签稀缺性问题。",
    "en_tdlr": "This research proposes a prompt-based approach for few-shot fake news detection, which effectively mitigates the issue of label scarcity by leveraging pre-trained language models and social context topology."
}