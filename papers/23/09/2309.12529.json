{
    "title": "Curriculum Reinforcement Learning via Morphology-Environment Co-Evolution. (arXiv:2309.12529v1 [cs.AI])",
    "abstract": "Throughout long history, natural species have learned to survive by evolving their physical structures adaptive to the environment changes. In contrast, current reinforcement learning (RL) studies mainly focus on training an agent with a fixed morphology (e.g., skeletal structure and joint attributes) in a fixed environment, which can hardly generalize to changing environments or new tasks. In this paper, we optimize an RL agent and its morphology through ``morphology-environment co-evolution (MECE)'', in which the morphology keeps being updated to adapt to the changing environment, while the environment is modified progressively to bring new challenges and stimulate the improvement of the morphology. This leads to a curriculum to train generalizable RL, whose morphology and policy are optimized for different environments. Instead of hand-crafting the curriculum, we train two policies to automatically change the morphology and the environment. To this end, (1) we develop two novel and ",
    "link": "http://arxiv.org/abs/2309.12529",
    "context": "Title: Curriculum Reinforcement Learning via Morphology-Environment Co-Evolution. (arXiv:2309.12529v1 [cs.AI])\nAbstract: Throughout long history, natural species have learned to survive by evolving their physical structures adaptive to the environment changes. In contrast, current reinforcement learning (RL) studies mainly focus on training an agent with a fixed morphology (e.g., skeletal structure and joint attributes) in a fixed environment, which can hardly generalize to changing environments or new tasks. In this paper, we optimize an RL agent and its morphology through ``morphology-environment co-evolution (MECE)'', in which the morphology keeps being updated to adapt to the changing environment, while the environment is modified progressively to bring new challenges and stimulate the improvement of the morphology. This leads to a curriculum to train generalizable RL, whose morphology and policy are optimized for different environments. Instead of hand-crafting the curriculum, we train two policies to automatically change the morphology and the environment. To this end, (1) we develop two novel and ",
    "path": "papers/23/09/2309.12529.json",
    "total_tokens": 828,
    "translated_title": "通过形态-环境共同进化的课程强化学习",
    "translated_abstract": "在长时间的演化过程中，自然物种通过进化其身体结构以适应环境变化来学会生存。相比之下，当前的强化学习研究主要集中在训练具有固定形态（如骨架结构和关节属性）的代理在固定环境中学习，很难推广到变化的环境或新任务。本文通过“形态-环境共同进化（MECE）”来优化强化学习代理和其形态，其中形态不断更新以适应变化的环境，同时环境逐渐修改以带来新的挑战并促进形态的改善。这导致了一个训练具有泛化性的强化学习的课程，其形态和策略针对不同的环境进行优化。我们通过训练两种策略来自动改变形态和环境，而不是手工设计课程。为此，（1）我们开发了两种新颖的方法。",
    "tldr": "本文通过形态-环境共同进化的方式，优化了强化学习代理和形态，实现了一个训练具有泛化性的强化学习课程，并自动改变环境和形态。"
}