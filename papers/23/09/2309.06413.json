{
    "title": "On Computationally Efficient Learning of Exponential Family Distributions. (arXiv:2309.06413v1 [cs.LG])",
    "abstract": "We consider the classical problem of learning, with arbitrary accuracy, the natural parameters of a $k$-parameter truncated \\textit{minimal} exponential family from i.i.d. samples in a computationally and statistically efficient manner. We focus on the setting where the support as well as the natural parameters are appropriately bounded. While the traditional maximum likelihood estimator for this class of exponential family is consistent, asymptotically normal, and asymptotically efficient, evaluating it is computationally hard. In this work, we propose a novel loss function and a computationally efficient estimator that is consistent as well as asymptotically normal under mild conditions. We show that, at the population level, our method can be viewed as the maximum likelihood estimation of a re-parameterized distribution belonging to the same class of exponential family. Further, we show that our estimator can be interpreted as a solution to minimizing a particular Bregman score as w",
    "link": "http://arxiv.org/abs/2309.06413",
    "context": "Title: On Computationally Efficient Learning of Exponential Family Distributions. (arXiv:2309.06413v1 [cs.LG])\nAbstract: We consider the classical problem of learning, with arbitrary accuracy, the natural parameters of a $k$-parameter truncated \\textit{minimal} exponential family from i.i.d. samples in a computationally and statistically efficient manner. We focus on the setting where the support as well as the natural parameters are appropriately bounded. While the traditional maximum likelihood estimator for this class of exponential family is consistent, asymptotically normal, and asymptotically efficient, evaluating it is computationally hard. In this work, we propose a novel loss function and a computationally efficient estimator that is consistent as well as asymptotically normal under mild conditions. We show that, at the population level, our method can be viewed as the maximum likelihood estimation of a re-parameterized distribution belonging to the same class of exponential family. Further, we show that our estimator can be interpreted as a solution to minimizing a particular Bregman score as w",
    "path": "papers/23/09/2309.06413.json",
    "total_tokens": 851,
    "translated_title": "计算有效学习指数族分布",
    "translated_abstract": "本研究考虑了以计算和统计的高效方式，准确学习具有任意精度的自然参数的$k$参数截断\\textit{最小}指数族分布。我们关注的是支持和自然参数适当有界的情况。虽然传统的最大似然估计器对于这类指数族分布是一致的、渐近正态的和渐近有效的，但其计算复杂度很高。在这项工作中，我们提出了一种新的损失函数和计算高效的估计器，在温和条件下一致且渐近正态。我们证明，在总体水平上，我们的方法可以被看作是同一类指数族分布的参数化分布的最大似然估计。此外，我们还证明了我们的估计器可以解释为最小化特定Bregman得分的解决方案。",
    "tldr": "本研究提出了一种计算高效的估计器，用于准确学习具有任意精度的自然参数的指数族分布。该估计器是一致的、渐近正态的，并可视为最大似然估计的重新参数化分布。",
    "en_tdlr": "This study proposes a computationally efficient estimator for learning exponential family distributions with arbitrary accuracy in estimating natural parameters. The estimator is consistent, asymptotically normal, and can be viewed as maximum likelihood estimation of a re-parameterized distribution in the same exponential family."
}