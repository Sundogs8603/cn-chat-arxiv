{
    "title": "L1-aware Multilingual Mispronunciation Detection Framework. (arXiv:2309.07719v1 [cs.CL])",
    "abstract": "The phonological discrepancies between a speaker's native (L1) and the non-native language (L2) serves as a major factor for mispronunciation. This paper introduces a novel multilingual MDD architecture, L1-MultiMDD, enriched with L1-aware speech representation. An end-to-end speech encoder is trained on the input signal and its corresponding reference phoneme sequence. First, an attention mechanism is deployed to align the input audio with the reference phoneme sequence. Afterwards, the L1-L2-speech embedding are extracted from an auxiliary model, pretrained in a multi-task setup identifying L1 and L2 language, and are infused with the primary network. Finally, the L1-MultiMDD is then optimized for a unified multilingual phoneme recognition task using connectionist temporal classification (CTC) loss for the target languages: English, Arabic, and Mandarin. Our experiments demonstrate the effectiveness of the proposed L1-MultiMDD framework on both seen -- L2-ARTIC, LATIC, and AraVoiceL2",
    "link": "http://arxiv.org/abs/2309.07719",
    "context": "Title: L1-aware Multilingual Mispronunciation Detection Framework. (arXiv:2309.07719v1 [cs.CL])\nAbstract: The phonological discrepancies between a speaker's native (L1) and the non-native language (L2) serves as a major factor for mispronunciation. This paper introduces a novel multilingual MDD architecture, L1-MultiMDD, enriched with L1-aware speech representation. An end-to-end speech encoder is trained on the input signal and its corresponding reference phoneme sequence. First, an attention mechanism is deployed to align the input audio with the reference phoneme sequence. Afterwards, the L1-L2-speech embedding are extracted from an auxiliary model, pretrained in a multi-task setup identifying L1 and L2 language, and are infused with the primary network. Finally, the L1-MultiMDD is then optimized for a unified multilingual phoneme recognition task using connectionist temporal classification (CTC) loss for the target languages: English, Arabic, and Mandarin. Our experiments demonstrate the effectiveness of the proposed L1-MultiMDD framework on both seen -- L2-ARTIC, LATIC, and AraVoiceL2",
    "path": "papers/23/09/2309.07719.json",
    "total_tokens": 950,
    "translated_title": "L1感知多语言发音错误检测框架",
    "translated_abstract": "说话者的母语(L1)和非母语(L2)之间的语音差异是发音错误的主要因素。本文介绍了一种新颖的多语言MDD架构——L1-MultiMDD框架，该框架通过L1感知的语音表示进行增强。首先，通过注意力机制将输入音频与参考音素序列进行对齐。然后，从在多任务设置中预先训练的辅助模型中提取L1-L2语音嵌入，并将其与主要网络进行融合。最后，通过连接时序分类(CTC)损失优化L1-MultiMDD框架，用于目标语言英文、阿拉伯语和普通话的统一多语言音素识别任务。实验证明了所提出的L1-MultiMDD框架在已见数据集L2-ARTIC、LATIC和AraVoiceL2上的有效性。",
    "tldr": "本文介绍了一种L1感知的多语言发音错误检测框架，该框架通过注意力机制对齐输入音频和参考音素序列，并将预训练的辅助模型提取的L1-L2语音嵌入与主要网络进行融合。该框架在英文、阿拉伯语和普通话上的统一多语言音素识别任务中取得了良好的效果。",
    "en_tdlr": "This paper presents an L1-aware multilingual mispronunciation detection framework which aligns input audio with reference phoneme sequence using an attention mechanism, and incorporates L1-L2 speech embedding extracted from a pretrained auxiliary model. It achieved good results in a unified multilingual phoneme recognition task for English, Arabic, and Mandarin."
}