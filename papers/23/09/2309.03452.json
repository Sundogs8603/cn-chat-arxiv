{
    "title": "Multi-Modality Guidance Network For Missing Modality Inference. (arXiv:2309.03452v1 [cs.CV])",
    "abstract": "Multimodal models have gained significant success in recent years. Standard multimodal approaches often assume unchanged modalities from training stage to inference stage. In practice, however, many scenarios fail to satisfy such assumptions with missing modalities during inference, leading to limitations on where multimodal models can be applied. While existing methods mitigate the problem through reconstructing the missing modalities, it increases unnecessary computational cost, which could be just as critical, especially for large, deployed systems. To solve the problem from both sides, we propose a novel guidance network that promotes knowledge sharing during training, taking advantage of the multimodal representations to train better single-modality models for inference. Real-life experiment in violence detection shows that our proposed framework trains single-modality models that significantly outperform its traditionally trained counterparts while maintaining the same inference ",
    "link": "http://arxiv.org/abs/2309.03452",
    "context": "Title: Multi-Modality Guidance Network For Missing Modality Inference. (arXiv:2309.03452v1 [cs.CV])\nAbstract: Multimodal models have gained significant success in recent years. Standard multimodal approaches often assume unchanged modalities from training stage to inference stage. In practice, however, many scenarios fail to satisfy such assumptions with missing modalities during inference, leading to limitations on where multimodal models can be applied. While existing methods mitigate the problem through reconstructing the missing modalities, it increases unnecessary computational cost, which could be just as critical, especially for large, deployed systems. To solve the problem from both sides, we propose a novel guidance network that promotes knowledge sharing during training, taking advantage of the multimodal representations to train better single-modality models for inference. Real-life experiment in violence detection shows that our proposed framework trains single-modality models that significantly outperform its traditionally trained counterparts while maintaining the same inference ",
    "path": "papers/23/09/2309.03452.json",
    "total_tokens": 881,
    "translated_title": "多模态辅助网络用于推断缺失模态",
    "translated_abstract": "多模态模型在最近几年取得了显著的成功。标准多模态方法通常假设在训练阶段和推断阶段模态保持不变。然而在实践中，许多场景无法满足这样的假设，推断过程中会出现缺失模态，从而限制了多模态模型的应用范围。现有的方法通过重建缺失模态来缓解这个问题，但这增加了不必要的计算成本，尤其对于大型部署系统而言可能是至关重要的。为了从两个方面解决这个问题，我们提出了一种新颖的辅助网络，在训练过程中促进知识共享，利用多模态表示来训练更好的单模态模型进行推断。在暴力检测的现实生活实验中，我们提出的框架训练的单模态模型在性能上显著优于传统训练的模型，同时保持相同的推断能力。",
    "tldr": "我们提出了一种多模态辅助网络，在训练过程中利用多模态表示来训练更好的单模态模型进行推断，解决了推断过程中模态缺失的问题。实验结果表明，我们的方法在性能上显著优于传统方法。"
}