{
    "title": "Verifiable Fairness: Privacy-preserving Computation of Fairness for Machine Learning Systems. (arXiv:2309.06061v1 [cs.CR])",
    "abstract": "Fair machine learning is a thriving and vibrant research topic. In this paper, we propose Fairness as a Service (FaaS), a secure, verifiable and privacy-preserving protocol to computes and verify the fairness of any machine learning (ML) model. In the deisgn of FaaS, the data and outcomes are represented through cryptograms to ensure privacy. Also, zero knowledge proofs guarantee the well-formedness of the cryptograms and underlying data. FaaS is model--agnostic and can support various fairness metrics; hence, it can be used as a service to audit the fairness of any ML model. Our solution requires no trusted third party or private channels for the computation of the fairness metric. The security guarantees and commitments are implemented in a way that every step is securely transparent and verifiable from the start to the end of the process. The cryptograms of all input data are publicly available for everyone, e.g., auditors, social activists and experts, to verify the correctness of ",
    "link": "http://arxiv.org/abs/2309.06061",
    "context": "Title: Verifiable Fairness: Privacy-preserving Computation of Fairness for Machine Learning Systems. (arXiv:2309.06061v1 [cs.CR])\nAbstract: Fair machine learning is a thriving and vibrant research topic. In this paper, we propose Fairness as a Service (FaaS), a secure, verifiable and privacy-preserving protocol to computes and verify the fairness of any machine learning (ML) model. In the deisgn of FaaS, the data and outcomes are represented through cryptograms to ensure privacy. Also, zero knowledge proofs guarantee the well-formedness of the cryptograms and underlying data. FaaS is model--agnostic and can support various fairness metrics; hence, it can be used as a service to audit the fairness of any ML model. Our solution requires no trusted third party or private channels for the computation of the fairness metric. The security guarantees and commitments are implemented in a way that every step is securely transparent and verifiable from the start to the end of the process. The cryptograms of all input data are publicly available for everyone, e.g., auditors, social activists and experts, to verify the correctness of ",
    "path": "papers/23/09/2309.06061.json",
    "total_tokens": 863,
    "translated_title": "验证公平性：隐私保护的机器学习系统公平性计算",
    "translated_abstract": "公平机器学习是一个蓬勃发展且充满活力的研究课题。本文提出了公平性即服务（FaaS）的安全、可验证和隐私保护协议，用于计算和验证任何机器学习（ML）模型的公平性。在FaaS的设计中，通过密文表示数据和结果，以确保隐私。此外，零知识证明保证了密文和底层数据的良好性。FaaS是模型无关的，可以支持多种公平性指标；因此，它可以用作审计任何ML模型的服务。我们的解决方案不需要可信任的第三方或私密通道来计算公平度量。安全保证和承诺以确保每个步骤都是安全透明的，并且整个过程从开始到结束都可以进行验证。所有输入数据的密文对于每个人，例如审计员、社会活动家和专家来说都是公开可用的，以验证其正确性。",
    "tldr": "提出了公平性即服务（FaaS）的安全、可验证和隐私保护协议，用于计算和验证任何机器学习（ML）模型的公平性。FaaS是模型无关的，可以支持多种公平性指标；因此，它可以用作审计任何ML模型的服务。"
}