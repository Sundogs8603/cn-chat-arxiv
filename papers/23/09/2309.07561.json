{
    "title": "Adaptive Prompt Learning with Distilled Connective Knowledge for Implicit Discourse Relation Recognition. (arXiv:2309.07561v1 [cs.CL])",
    "abstract": "Implicit discourse relation recognition (IDRR) aims at recognizing the discourse relation between two text segments without an explicit connective. Recently, the prompt learning has just been applied to the IDRR task with great performance improvements over various neural network-based approaches. However, the discrete nature of the state-art-of-art prompting approach requires manual design of templates and answers, a big hurdle for its practical applications. In this paper, we propose a continuous version of prompt learning together with connective knowledge distillation, called AdaptPrompt, to reduce manual design efforts via continuous prompting while further improving performance via knowledge transfer. In particular, we design and train a few virtual tokens to form continuous templates and automatically select the most suitable one by gradient search in the embedding space. We also design an answer-relation mapping rule to generate a few virtual answers as the answer space. Furthe",
    "link": "http://arxiv.org/abs/2309.07561",
    "context": "Title: Adaptive Prompt Learning with Distilled Connective Knowledge for Implicit Discourse Relation Recognition. (arXiv:2309.07561v1 [cs.CL])\nAbstract: Implicit discourse relation recognition (IDRR) aims at recognizing the discourse relation between two text segments without an explicit connective. Recently, the prompt learning has just been applied to the IDRR task with great performance improvements over various neural network-based approaches. However, the discrete nature of the state-art-of-art prompting approach requires manual design of templates and answers, a big hurdle for its practical applications. In this paper, we propose a continuous version of prompt learning together with connective knowledge distillation, called AdaptPrompt, to reduce manual design efforts via continuous prompting while further improving performance via knowledge transfer. In particular, we design and train a few virtual tokens to form continuous templates and automatically select the most suitable one by gradient search in the embedding space. We also design an answer-relation mapping rule to generate a few virtual answers as the answer space. Furthe",
    "path": "papers/23/09/2309.07561.json",
    "total_tokens": 870,
    "translated_title": "自适应提示学习与蒸馏连贯知识在隐含篇章关系识别中的应用",
    "translated_abstract": "隐含篇章关系识别(IDRR)旨在识别两个文本片段之间的篇章关系，而无需显式的连接词。最近，提示学习被应用于IDRR任务，并取得了比基于神经网络的方法更好的性能。然而，现有的提示学习方法需要手动设计模板和答案，这对于实际应用来说是一个巨大的障碍。本文提出了一种连续版本的提示学习方法，结合连贯知识蒸馏，称为AdaptPrompt，通过连续的提示减少手动设计工作，并通过知识传递进一步改进性能。具体而言，我们设计和训练了一些虚拟标记来形成连续的模板，并通过在嵌入空间中进行梯度搜索自动选择最合适的模板。我们还设计了一个答案关系映射规则来生成一些虚拟答案作为答案空间。",
    "tldr": "本文提出了一种连续版本的提示学习方法AdaptPrompt，在隐含篇章关系识别中应用连贯知识蒸馏，通过连续提示和知识传递改进性能，减少手动设计工作。",
    "en_tdlr": "This paper introduces a continuous version of prompt learning method called AdaptPrompt, which applies connective knowledge distillation in implicit discourse relation recognition. It reduces manual design efforts through continuous prompting and improves performance via knowledge transfer."
}