{
    "title": "SCREWS: A Modular Framework for Reasoning with Revisions. (arXiv:2309.13075v1 [cs.AI])",
    "abstract": "Large language models (LLMs) can improve their accuracy on various tasks through iteratively refining and revising their output based on feedback. We observe that these revisions can introduce errors, in which case it is better to roll back to a previous result. Further, revisions are typically homogeneous: they use the same reasoning method that produced the initial answer, which may not correct errors. To enable exploration in this space, we present SCREWS, a modular framework for reasoning with revisions. It is comprised of three main modules: Sampling, Conditional Resampling, and Selection, each consisting of sub-modules that can be hand-selected per task. We show that SCREWS not only unifies several previous approaches under a common framework, but also reveals several novel strategies for identifying improved reasoning chains. We evaluate our framework with state-of-the-art LLMs (ChatGPT and GPT-4) on a diverse set of reasoning tasks and uncover useful new reasoning strategies fo",
    "link": "http://arxiv.org/abs/2309.13075",
    "context": "Title: SCREWS: A Modular Framework for Reasoning with Revisions. (arXiv:2309.13075v1 [cs.AI])\nAbstract: Large language models (LLMs) can improve their accuracy on various tasks through iteratively refining and revising their output based on feedback. We observe that these revisions can introduce errors, in which case it is better to roll back to a previous result. Further, revisions are typically homogeneous: they use the same reasoning method that produced the initial answer, which may not correct errors. To enable exploration in this space, we present SCREWS, a modular framework for reasoning with revisions. It is comprised of three main modules: Sampling, Conditional Resampling, and Selection, each consisting of sub-modules that can be hand-selected per task. We show that SCREWS not only unifies several previous approaches under a common framework, but also reveals several novel strategies for identifying improved reasoning chains. We evaluate our framework with state-of-the-art LLMs (ChatGPT and GPT-4) on a diverse set of reasoning tasks and uncover useful new reasoning strategies fo",
    "path": "papers/23/09/2309.13075.json",
    "total_tokens": 962,
    "translated_title": "SCREWS: 一种用于推理修订的模块化框架",
    "translated_abstract": "大型语言模型 (LLMs) 可以通过根据反馈不断改进和修订其输出来提高在各种任务上的准确性。我们观察到这些修订可能会引入错误，如果是这样的话，最好回滚到先前的结果。此外，修订通常是同质的：它们使用与产生初始答案的相同推理方法，这可能无法纠正错误。为了在这个领域中进行探索，我们提出了 SCREWS，一种用于推理修订的模块化框架。它由三个主要模块组成: 采样、条件重新采样和选择，每个模块都包含可以根据任务手动选择的子模块。我们展示了 SCREWS 不仅将几个先前的方法统一到一个共同的框架中，还揭示了几种用于识别改进的推理链的新策略。我们使用最先进的LLMs （ChatGPT 和 GPT-4）在多样的推理任务上评估我们的框架，并揭示了有用的新的推理策略。",
    "tldr": "SCREWS是一个模块化框架，用于推理修订。它能够统一先前的方法并提供新的策略来识别改进的推理链。在多样的推理任务上，使用最先进的LLMs（ChatGPT和GPT-4）评估SCREWS的性能，并发现了有用的新的推理策略。"
}