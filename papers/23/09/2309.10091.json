{
    "title": "Unified Coarse-to-Fine Alignment for Video-Text Retrieval. (arXiv:2309.10091v1 [cs.CV])",
    "abstract": "The canonical approach to video-text retrieval leverages a coarse-grained or fine-grained alignment between visual and textual information. However, retrieving the correct video according to the text query is often challenging as it requires the ability to reason about both high-level (scene) and low-level (object) visual clues and how they relate to the text query. To this end, we propose a Unified Coarse-to-fine Alignment model, dubbed UCoFiA. Specifically, our model captures the cross-modal similarity information at different granularity levels. To alleviate the effect of irrelevant visual clues, we also apply an Interactive Similarity Aggregation module (ISA) to consider the importance of different visual features while aggregating the cross-modal similarity to obtain a similarity score for each granularity. Finally, we apply the Sinkhorn-Knopp algorithm to normalize the similarities of each level before summing them, alleviating over- and under-representation issues at different l",
    "link": "http://arxiv.org/abs/2309.10091",
    "context": "Title: Unified Coarse-to-Fine Alignment for Video-Text Retrieval. (arXiv:2309.10091v1 [cs.CV])\nAbstract: The canonical approach to video-text retrieval leverages a coarse-grained or fine-grained alignment between visual and textual information. However, retrieving the correct video according to the text query is often challenging as it requires the ability to reason about both high-level (scene) and low-level (object) visual clues and how they relate to the text query. To this end, we propose a Unified Coarse-to-fine Alignment model, dubbed UCoFiA. Specifically, our model captures the cross-modal similarity information at different granularity levels. To alleviate the effect of irrelevant visual clues, we also apply an Interactive Similarity Aggregation module (ISA) to consider the importance of different visual features while aggregating the cross-modal similarity to obtain a similarity score for each granularity. Finally, we apply the Sinkhorn-Knopp algorithm to normalize the similarities of each level before summing them, alleviating over- and under-representation issues at different l",
    "path": "papers/23/09/2309.10091.json",
    "total_tokens": 952,
    "translated_title": "视频-文本检索的统一粗到细对齐方法",
    "translated_abstract": "视频-文本检索通常利用视觉和文本信息之间的粗粒度或细粒度对齐。然而，根据文本查询检索正确的视频通常具有挑战性，因为它需要能够推理出高级（场景）和低级（对象）视觉线索及其与文本查询的关系。为此，我们提出了一种名为UCoFiA的统一粗到细对齐模型。具体而言，我们的模型在不同粒度级别上捕捉跨模态相似性信息。为减轻无关视觉线索的影响，我们还应用了交互式相似性聚合模块（ISA）来考虑不同视觉特征的重要性，同时聚合跨模态相似性以获得每个粒度的相似度得分。最后，我们应用Sinkhorn-Knopp算法对每个级别的相似性进行标准化，以减轻不同级别上的过度或不足表示问题。",
    "tldr": "提出了一种统一粗到细对齐模型UCoFiA，用于视频-文本检索，该模型能够在不同粒度级别上捕捉跨模态相似性信息，并通过交互式相似性聚合模块有效考虑不同视觉特征的重要性，最终解决了视频-文本检索中的精确匹配问题。"
}