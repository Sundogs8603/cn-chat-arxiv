{
    "title": "Towards Visual Taxonomy Expansion. (arXiv:2309.06105v1 [cs.CV])",
    "abstract": "Taxonomy expansion task is essential in organizing the ever-increasing volume of new concepts into existing taxonomies. Most existing methods focus exclusively on using textual semantics, leading to an inability to generalize to unseen terms and the \"Prototypical Hypernym Problem.\" In this paper, we propose Visual Taxonomy Expansion (VTE), introducing visual features into the taxonomy expansion task. We propose a textual hypernymy learning task and a visual prototype learning task to cluster textual and visual semantics. In addition to the tasks on respective modalities, we introduce a hyper-proto constraint that integrates textual and visual semantics to produce fine-grained visual semantics. Our method is evaluated on two datasets, where we obtain compelling results. Specifically, on the Chinese taxonomy dataset, our method significantly improves accuracy by 8.75 %. Additionally, our approach performs better than ChatGPT on the Chinese taxonomy dataset.",
    "link": "http://arxiv.org/abs/2309.06105",
    "context": "Title: Towards Visual Taxonomy Expansion. (arXiv:2309.06105v1 [cs.CV])\nAbstract: Taxonomy expansion task is essential in organizing the ever-increasing volume of new concepts into existing taxonomies. Most existing methods focus exclusively on using textual semantics, leading to an inability to generalize to unseen terms and the \"Prototypical Hypernym Problem.\" In this paper, we propose Visual Taxonomy Expansion (VTE), introducing visual features into the taxonomy expansion task. We propose a textual hypernymy learning task and a visual prototype learning task to cluster textual and visual semantics. In addition to the tasks on respective modalities, we introduce a hyper-proto constraint that integrates textual and visual semantics to produce fine-grained visual semantics. Our method is evaluated on two datasets, where we obtain compelling results. Specifically, on the Chinese taxonomy dataset, our method significantly improves accuracy by 8.75 %. Additionally, our approach performs better than ChatGPT on the Chinese taxonomy dataset.",
    "path": "papers/23/09/2309.06105.json",
    "total_tokens": 905,
    "translated_title": "实现视觉分类扩展",
    "translated_abstract": "分类扩展任务非常重要，可以将新概念的不断增加的数量组织到现有分类中。大多数现有方法只关注使用文本语义，导致无法推广到未见术语和“典型超义问题”。本文提出了视觉分类扩展（VTE），将视觉特征引入到分类扩展任务中。我们提出了文本上义词学习任务和视觉原型学习任务，以聚类文本和视觉语义。除了各自模态的任务之外，我们引入了一个超-原型约束，将文本和视觉语义结合起来产生细粒度的视觉语义。我们的方法在两个数据集上进行了评估，取得了令人信服的结果。具体而言，对于中文分类数据集，我们的方法将准确度显著提高了8.75％。此外，我们的方法在中文分类数据集上的表现优于ChatGPT.",
    "tldr": "本文提出了一种视觉分类扩展（VTE）方法，将视觉特征引入到分类扩展任务中，并通过文本上义词学习任务和视觉原型学习任务，结合文本和视觉语义，产生了细粒度的视觉语义。在实验中，我们的方法在中文分类数据集上显著提高了准确度，表现优于ChatGPT."
}