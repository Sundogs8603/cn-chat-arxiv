{
    "title": "STAG: Enabling Low Latency and Low Staleness of GNN-based Services with Dynamic Graphs. (arXiv:2309.15875v1 [cs.LG])",
    "abstract": "Many emerging user-facing services adopt Graph Neural Networks (GNNs) to improve serving accuracy. When the graph used by a GNN model changes, representations (embedding) of nodes in the graph should be updated accordingly. However, the node representation update is too slow, resulting in either long response latency of user queries (the inference is performed after the update completes) or high staleness problem (the inference is performed based on stale data). Our in-depth analysis shows that the slow update is mainly due to neighbor explosion problem in graphs and duplicated computation. Based on such findings, we propose STAG, a GNN serving framework that enables low latency and low staleness of GNN-based services. It comprises a collaborative serving mechanism and an additivity-based incremental propagation strategy. With the collaborative serving mechanism, only part of node representations are updated during the update phase, and the final representations are calculated in the i",
    "link": "http://arxiv.org/abs/2309.15875",
    "context": "Title: STAG: Enabling Low Latency and Low Staleness of GNN-based Services with Dynamic Graphs. (arXiv:2309.15875v1 [cs.LG])\nAbstract: Many emerging user-facing services adopt Graph Neural Networks (GNNs) to improve serving accuracy. When the graph used by a GNN model changes, representations (embedding) of nodes in the graph should be updated accordingly. However, the node representation update is too slow, resulting in either long response latency of user queries (the inference is performed after the update completes) or high staleness problem (the inference is performed based on stale data). Our in-depth analysis shows that the slow update is mainly due to neighbor explosion problem in graphs and duplicated computation. Based on such findings, we propose STAG, a GNN serving framework that enables low latency and low staleness of GNN-based services. It comprises a collaborative serving mechanism and an additivity-based incremental propagation strategy. With the collaborative serving mechanism, only part of node representations are updated during the update phase, and the final representations are calculated in the i",
    "path": "papers/23/09/2309.15875.json",
    "total_tokens": 891,
    "translated_title": "STAG: 实现动态图中基于GNN的服务低延迟和低陈旧度",
    "translated_abstract": "许多新兴的用户面向服务采用图神经网络（GNN）来提高服务准确性。当GNN模型使用的图发生变化时，图中节点的表示（嵌入）应相应更新。然而，节点表示的更新速度过慢，导致用户查询的响应延迟较长（更新完成后进行推理）或存在较高的陈旧度问题（基于陈旧数据进行推理）。我们的深入分析表明，更新过慢主要是由于图中的邻居爆炸问题和重复计算。基于这些发现，我们提出了STAG，这是一个能够实现基于GNN的服务低延迟和低陈旧度的GNN服务框架。它包括协同服务机制和基于可加性的增量传播策略。通过协同服务机制，只有部分节点表示在更新阶段进行更新，最终的表示是在增量传播策略中计算得到的。",
    "tldr": "STAG是一个GNN服务框架，用于解决动态图中基于GNN的服务中的低延迟和低陈旧度问题。它采用协同服务机制和增量传播策略来优化节点表示的更新过程。",
    "en_tdlr": "STAG is a GNN serving framework that addresses the issues of low latency and low staleness in GNN-based services on dynamic graphs. It utilizes collaborative serving mechanism and an additivity-based incremental propagation strategy to optimize the node representation update process."
}