{
    "title": "JoTR: A Joint Transformer and Reinforcement Learning Framework for Dialog Policy Learning. (arXiv:2309.00230v1 [cs.CL])",
    "abstract": "Dialogue policy learning (DPL) is a crucial component of dialogue modelling. Its primary role is to determine the appropriate abstract response, commonly referred to as the \"dialogue action\". Traditional DPL methodologies have treated this as a sequential decision problem, using pre-defined action candidates extracted from a corpus. However, these incomplete candidates can significantly limit the diversity of responses and pose challenges when dealing with edge cases, which are scenarios that occur only at extreme operating parameters. To address these limitations, we introduce a novel framework, JoTR. This framework is unique as it leverages a text-to-text Transformer-based model to generate flexible dialogue actions. Unlike traditional methods, JoTR formulates a word-level policy that allows for a more dynamic and adaptable dialogue action generation, without the need for any action templates. This setting enhances the diversity of responses and improves the system's ability to handl",
    "link": "http://arxiv.org/abs/2309.00230",
    "context": "Title: JoTR: A Joint Transformer and Reinforcement Learning Framework for Dialog Policy Learning. (arXiv:2309.00230v1 [cs.CL])\nAbstract: Dialogue policy learning (DPL) is a crucial component of dialogue modelling. Its primary role is to determine the appropriate abstract response, commonly referred to as the \"dialogue action\". Traditional DPL methodologies have treated this as a sequential decision problem, using pre-defined action candidates extracted from a corpus. However, these incomplete candidates can significantly limit the diversity of responses and pose challenges when dealing with edge cases, which are scenarios that occur only at extreme operating parameters. To address these limitations, we introduce a novel framework, JoTR. This framework is unique as it leverages a text-to-text Transformer-based model to generate flexible dialogue actions. Unlike traditional methods, JoTR formulates a word-level policy that allows for a more dynamic and adaptable dialogue action generation, without the need for any action templates. This setting enhances the diversity of responses and improves the system's ability to handl",
    "path": "papers/23/09/2309.00230.json",
    "total_tokens": 863,
    "translated_title": "JoTR: 一种基于联合Transformer和强化学习的对话策略学习框架",
    "translated_abstract": "对话策略学习是对话建模的关键组成部分，其主要作用是确定合适的抽象回应，通常称为\"对话动作\"。传统的对话策略学习方法将其视为一个顺序决策问题，使用从语料库中提取的预定义动作候选项。然而，这些不完整的候选项可能会显著限制响应的多样性，并在处理极端操作参数下出现挑战性情况时造成困难。为了解决这些限制，我们引入了一种新颖的框架，JoTR。该框架独特之处在于利用基于文本到文本的Transformer模型生成灵活的对话动作。与传统方法不同，JoTR制定了一个词级策略，允许更动态和适应性的对话动作生成，无需任何动作模板。这种设置增强了响应的多样性，并提高了系统处理极端情况的能力。",
    "tldr": "JoTR是一种新颖的对话策略学习框架，利用基于Transformer的模型生成灵活的对话动作，提高了响应多样性和系统处理极端情况的能力。",
    "en_tdlr": "JoTR is a novel framework for dialog policy learning that leverages a Transformer-based model to generate flexible dialogue actions, enhancing response diversity and the system's ability to handle extreme scenarios."
}