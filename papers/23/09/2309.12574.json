{
    "title": "Classification of Alzheimers Disease with Deep Learning on Eye-tracking Data. (arXiv:2309.12574v1 [cs.CV])",
    "abstract": "Existing research has shown the potential of classifying Alzheimers Disease (AD) from eye-tracking (ET) data with classifiers that rely on task-specific engineered features. In this paper, we investigate whether we can improve on existing results by using a Deep-Learning classifier trained end-to-end on raw ET data. This classifier (VTNet) uses a GRU and a CNN in parallel to leverage both visual (V) and temporal (T) representations of ET data and was previously used to detect user confusion while processing visual displays. A main challenge in applying VTNet to our target AD classification task is that the available ET data sequences are much longer than those used in the previous confusion detection task, pushing the limits of what is manageable by LSTM-based models. We discuss how we address this challenge and show that VTNet outperforms the state-of-the-art approaches in AD classification, providing encouraging evidence on the generality of this model to make predictions from ET dat",
    "link": "http://arxiv.org/abs/2309.12574",
    "context": "Title: Classification of Alzheimers Disease with Deep Learning on Eye-tracking Data. (arXiv:2309.12574v1 [cs.CV])\nAbstract: Existing research has shown the potential of classifying Alzheimers Disease (AD) from eye-tracking (ET) data with classifiers that rely on task-specific engineered features. In this paper, we investigate whether we can improve on existing results by using a Deep-Learning classifier trained end-to-end on raw ET data. This classifier (VTNet) uses a GRU and a CNN in parallel to leverage both visual (V) and temporal (T) representations of ET data and was previously used to detect user confusion while processing visual displays. A main challenge in applying VTNet to our target AD classification task is that the available ET data sequences are much longer than those used in the previous confusion detection task, pushing the limits of what is manageable by LSTM-based models. We discuss how we address this challenge and show that VTNet outperforms the state-of-the-art approaches in AD classification, providing encouraging evidence on the generality of this model to make predictions from ET dat",
    "path": "papers/23/09/2309.12574.json",
    "total_tokens": 932,
    "translated_title": "用深度学习在眼动数据上对阿尔茨海默病进行分类",
    "translated_abstract": "现有研究表明，使用依赖于任务特定特征的分类器对眼动数据进行阿尔茨海默病 (AD) 分类具有潜力。本文探讨是否可以通过使用以原始眼动数据为训练数据的端到端深度学习分类器来改进现有结果。该分类器 (VTNet) 同时利用 GRU 和 CNN 来利用眼动数据的视觉 (V) 和时间 (T) 表示，并且先前被用于检测用户在处理视觉显示时的困惑。将VTNet应用于AD分类任务的一个主要挑战是可用的眼动数据序列比先前的困惑检测任务中使用的序列要长得多，这将LSTM-based模型的可处理性推向极限。我们讨论了如何应对这个挑战，并展示了VTNet在AD分类方面优于现有方法的性能，为这个模型从眼动数据中进行预测的普适性提供了鼓舞人心的证据。",
    "tldr": "该论文研究了使用深度学习模型在原始眼动数据上进行阿尔茨海默病分类的方法，称为VTNet。研究表明，VTNet在AD分类任务中的性能优于现有方法，显示了该模型从眼动数据进行预测的潜力。"
}