{
    "title": "Revisiting Neural Program Smoothing for Fuzzing. (arXiv:2309.16618v1 [cs.SE])",
    "abstract": "Testing with randomly generated inputs (fuzzing) has gained significant traction due to its capacity to expose program vulnerabilities automatically. Fuzz testing campaigns generate large amounts of data, making them ideal for the application of machine learning (ML). Neural program smoothing (NPS), a specific family of ML-guided fuzzers, aims to use a neural network as a smooth approximation of the program target for new test case generation.  In this paper, we conduct the most extensive evaluation of NPS fuzzers against standard gray-box fuzzers (>11 CPU years and >5.5 GPU years), and make the following contributions: (1) We find that the original performance claims for NPS fuzzers do not hold; a gap we relate to fundamental, implementation, and experimental limitations of prior works. (2) We contribute the first in-depth analysis of the contribution of machine learning and gradient-based mutations in NPS. (3) We implement Neuzz++, which shows that addressing the practical limitation",
    "link": "http://arxiv.org/abs/2309.16618",
    "context": "Title: Revisiting Neural Program Smoothing for Fuzzing. (arXiv:2309.16618v1 [cs.SE])\nAbstract: Testing with randomly generated inputs (fuzzing) has gained significant traction due to its capacity to expose program vulnerabilities automatically. Fuzz testing campaigns generate large amounts of data, making them ideal for the application of machine learning (ML). Neural program smoothing (NPS), a specific family of ML-guided fuzzers, aims to use a neural network as a smooth approximation of the program target for new test case generation.  In this paper, we conduct the most extensive evaluation of NPS fuzzers against standard gray-box fuzzers (>11 CPU years and >5.5 GPU years), and make the following contributions: (1) We find that the original performance claims for NPS fuzzers do not hold; a gap we relate to fundamental, implementation, and experimental limitations of prior works. (2) We contribute the first in-depth analysis of the contribution of machine learning and gradient-based mutations in NPS. (3) We implement Neuzz++, which shows that addressing the practical limitation",
    "path": "papers/23/09/2309.16618.json",
    "total_tokens": 910,
    "translated_title": "重访神经程序平滑技术用于模糊测试",
    "translated_abstract": "随机生成输入进行测试（模糊测试）由于能够自动暴露程序的漏洞而受到广泛关注。模糊测试生成了大量的数据，使其非常适合应用机器学习（ML）方法。神经程序平滑（NPS）是一种特定的基于ML的模糊测试方法，旨在将神经网络用作程序目标的平滑近似，以生成新的测试用例。在本文中，我们对NPS模糊测试方法进行了最广泛的评估，并与标准的灰盒模糊测试方法进行了比较（>11个CPU年和>5.5个GPU年），并做出了以下贡献：(1)我们发现NPS模糊测试方法的原始性能声明不成立；我们将这个差距与先前工作的基本、实施和实验限制相关联。(2)我们首次深入分析了ML和基于梯度的变异在NPS中的贡献。(3)我们实现了新的模糊测试方法Neuzz++，它解决了实际限制问题。",
    "tldr": "本文对神经程序平滑（NPS）模糊测试方法进行了最广泛的评估，发现其原始性能声明不成立，并提出了解决实际限制问题的新模糊测试方法Neuzz++。",
    "en_tdlr": "This paper presents the most extensive evaluation of Neural Program Smoothing (NPS) fuzzing methods, finding that the original performance claims are not valid and proposing a new fuzzing method called Neuzz++ to address practical limitations."
}