{
    "title": "Leveraging Contextual Information for Effective Entity Salience Detection. (arXiv:2309.07990v1 [cs.CL])",
    "abstract": "In text documents such as news articles, the content and key events usually revolve around a subset of all the entities mentioned in a document. These entities, often deemed as salient entities, provide useful cues of the aboutness of a document to a reader. Identifying the salience of entities was found helpful in several downstream applications such as search, ranking, and entity-centric summarization, among others. Prior work on salient entity detection mainly focused on machine learning models that require heavy feature engineering. We show that fine-tuning medium-sized language models with a cross-encoder style architecture yields substantial performance gains over feature engineering approaches. To this end, we conduct a comprehensive benchmarking of four publicly available datasets using models representative of the medium-sized pre-trained language model family. Additionally, we show that zero-shot prompting of instruction-tuned language models yields inferior results, indicati",
    "link": "http://arxiv.org/abs/2309.07990",
    "context": "Title: Leveraging Contextual Information for Effective Entity Salience Detection. (arXiv:2309.07990v1 [cs.CL])\nAbstract: In text documents such as news articles, the content and key events usually revolve around a subset of all the entities mentioned in a document. These entities, often deemed as salient entities, provide useful cues of the aboutness of a document to a reader. Identifying the salience of entities was found helpful in several downstream applications such as search, ranking, and entity-centric summarization, among others. Prior work on salient entity detection mainly focused on machine learning models that require heavy feature engineering. We show that fine-tuning medium-sized language models with a cross-encoder style architecture yields substantial performance gains over feature engineering approaches. To this end, we conduct a comprehensive benchmarking of four publicly available datasets using models representative of the medium-sized pre-trained language model family. Additionally, we show that zero-shot prompting of instruction-tuned language models yields inferior results, indicati",
    "path": "papers/23/09/2309.07990.json",
    "total_tokens": 890,
    "translated_title": "利用语境信息实现有效的实体重要性检测",
    "translated_abstract": "在新闻文章等文本文档中，内容和关键事件通常围绕着文档中提到的一部分实体展开。这些实体通常被认为是重要的实体，对于读者来说，它们提供了关于文档内容的有用线索。识别实体的重要性在搜索、排名和基于实体的摘要等多个下游应用中都有帮助。先前的工作主要集中在需要进行大量特征工程的机器学习模型上。我们表明，使用交叉编码器风格架构对中等规模的语言模型进行微调，比特征工程方法获得了显著的性能提升。为此，我们对四个公开可用的数据集使用代表中等预训练语言模型家族的模型进行了全面的基准测试。此外，我们还表明，使用指令调校的语言模型进行零样本提示会产生较差的结果，表明指令调校的语言模型回答的问题数量过少。",
    "tldr": "本文研究了有效的实体重要性检测方法，通过对中等规模的语言模型进行微调，比传统的特征工程方法获得了更好的性能。研究还发现使用指令调校的语言模型进行零样本提示效果较差。",
    "en_tdlr": "This paper investigates effective entity salience detection by fine-tuning medium-sized language models, which outperform traditional feature engineering approaches. The study also finds that zero-shot prompting with instruction-tuned language models yields inferior results."
}