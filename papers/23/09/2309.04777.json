{
    "title": "Towards Robust Model Watermark via Reducing Parametric Vulnerability. (arXiv:2309.04777v1 [cs.CR])",
    "abstract": "Deep neural networks are valuable assets considering their commercial benefits and huge demands for costly annotation and computation resources. To protect the copyright of DNNs, backdoor-based ownership verification becomes popular recently, in which the model owner can watermark the model by embedding a specific backdoor behavior before releasing it. The defenders (usually the model owners) can identify whether a suspicious third-party model is ``stolen'' from them based on the presence of the behavior. Unfortunately, these watermarks are proven to be vulnerable to removal attacks even like fine-tuning. To further explore this vulnerability, we investigate the parameter space and find there exist many watermark-removed models in the vicinity of the watermarked one, which may be easily used by removal attacks. Inspired by this finding, we propose a mini-max formulation to find these watermark-removed models and recover their watermark behavior. Extensive experiments demonstrate that o",
    "link": "http://arxiv.org/abs/2309.04777",
    "context": "Title: Towards Robust Model Watermark via Reducing Parametric Vulnerability. (arXiv:2309.04777v1 [cs.CR])\nAbstract: Deep neural networks are valuable assets considering their commercial benefits and huge demands for costly annotation and computation resources. To protect the copyright of DNNs, backdoor-based ownership verification becomes popular recently, in which the model owner can watermark the model by embedding a specific backdoor behavior before releasing it. The defenders (usually the model owners) can identify whether a suspicious third-party model is ``stolen'' from them based on the presence of the behavior. Unfortunately, these watermarks are proven to be vulnerable to removal attacks even like fine-tuning. To further explore this vulnerability, we investigate the parameter space and find there exist many watermark-removed models in the vicinity of the watermarked one, which may be easily used by removal attacks. Inspired by this finding, we propose a mini-max formulation to find these watermark-removed models and recover their watermark behavior. Extensive experiments demonstrate that o",
    "path": "papers/23/09/2309.04777.json",
    "total_tokens": 912,
    "translated_title": "通过减少参数的弱点 改进稳健模型数",
    "translated_abstract": "深度神经网络由于其商业价值和对资源的巨大需求而成为宝贵的资产，然而为了保护深度神经网络的版权，最近基于后门的拥有权验证变得流行起来。在这种验证方式中，模型所有者可以在发布之前通过嵌入特定的后门行为对模型进行水印标记。防御方（通常是模型所有者）可以根据行为的存在来判断可疑的第三方模型是否是从他们那里“偷”来的。不幸的是，这些水印已经被证明对移除攻击（甚至如微调）非常脆弱。为了进一步探索这种脆弱性，我们对参数空间进行了研究，并发现存在许多在水印模型附近的去水印模型，这些模型可能很容易被用于移除攻击。受到这一发现的启发，我们提出了一个迷你最大化最小化问题来找到这些去水印模型并恢复它们的水印行为。大量实验表明，我们的方法可以找到并恢复去水印模型的水印行为。",
    "tldr": "这篇论文提出了一种通过减少参数弱点来改进模型水印的方法，实验结果表明这种方法可以在近邻中找到并恢复去水印模型的水印行为。",
    "en_tdlr": "This paper proposes a method to improve model watermarking by reducing the vulnerability of parameters, and experiments show that this method can find and recover the watermark behavior of watermark-removed models in the vicinity."
}