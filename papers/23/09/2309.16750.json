{
    "title": "Memory in Plain Sight: A Survey of the Uncanny Resemblances between Diffusion Models and Associative Memories. (arXiv:2309.16750v1 [cs.LG])",
    "abstract": "Diffusion Models (DMs) have recently set state-of-the-art on many generation benchmarks. However, there are myriad ways to describe them mathematically, which makes it difficult to develop a simple understanding of how they work. In this survey, we provide a concise overview of DMs from the perspective of dynamical systems and Ordinary Differential Equations (ODEs) which exposes a mathematical connection to the highly related yet often overlooked class of energy-based models, called Associative Memories (AMs). Energy-based AMs are a theoretical framework that behave much like denoising DMs, but they enable us to directly compute a Lyapunov energy function on which we can perform gradient descent to denoise data. We then summarize the 40 year history of energy-based AMs, beginning with the original Hopfield Network, and discuss new research directions for AMs and DMs that are revealed by characterizing the extent of their similarities and differences",
    "link": "http://arxiv.org/abs/2309.16750",
    "context": "Title: Memory in Plain Sight: A Survey of the Uncanny Resemblances between Diffusion Models and Associative Memories. (arXiv:2309.16750v1 [cs.LG])\nAbstract: Diffusion Models (DMs) have recently set state-of-the-art on many generation benchmarks. However, there are myriad ways to describe them mathematically, which makes it difficult to develop a simple understanding of how they work. In this survey, we provide a concise overview of DMs from the perspective of dynamical systems and Ordinary Differential Equations (ODEs) which exposes a mathematical connection to the highly related yet often overlooked class of energy-based models, called Associative Memories (AMs). Energy-based AMs are a theoretical framework that behave much like denoising DMs, but they enable us to directly compute a Lyapunov energy function on which we can perform gradient descent to denoise data. We then summarize the 40 year history of energy-based AMs, beginning with the original Hopfield Network, and discuss new research directions for AMs and DMs that are revealed by characterizing the extent of their similarities and differences",
    "path": "papers/23/09/2309.16750.json",
    "total_tokens": 896,
    "translated_title": "眼中记忆：扩散模型和关联记忆之间的神秘相似之处的调查",
    "translated_abstract": "扩散模型（DMs）最近在许多生成基准测试中取得了最新的成果。然而，对它们的数学描述有很多种方式，这使得人们很难对其工作原理进行简单理解。在这项调查中，我们从动力系统和常微分方程（ODE）的角度提供了DMs的简明概述，揭示了一种与其高度相关但常常被忽视的能量模型类别，称为关联记忆（AMs）的数学联系。基于能量的AMs是一个理论框架，其行为与去噪DMs非常相似，但它们使我们能够直接计算一个Lyapunov能量函数，在其上可以执行梯度下降以去噪数据。然后，我们总结了能量AMs的40年历史，从最初的Hopfield网络开始，并讨论了通过描述它们的相似性和差异程度揭示出来的AMs和DMs的新研究方向。",
    "tldr": "本调查综述了扩散模型（DMs）和关联记忆（AMs）之间的数学联系，揭示了DMs是如何利用能量函数进行去噪数据的，并讨论了未来研究方向。",
    "en_tdlr": "This survey explores the mathematical connection between diffusion models (DMs) and associative memories (AMs), revealing how DMs utilize energy functions for denoising data and discussing future research directions."
}