{
    "title": "Self-supervised Cross-view Representation Reconstruction for Change Captioning. (arXiv:2309.16283v1 [cs.CV])",
    "abstract": "Change captioning aims to describe the difference between a pair of similar images. Its key challenge is how to learn a stable difference representation under pseudo changes caused by viewpoint change. In this paper, we address this by proposing a self-supervised cross-view representation reconstruction (SCORER) network. Concretely, we first design a multi-head token-wise matching to model relationships between cross-view features from similar/dissimilar images. Then, by maximizing cross-view contrastive alignment of two similar images, SCORER learns two view-invariant image representations in a self-supervised way. Based on these, we reconstruct the representations of unchanged objects by cross-attention, thus learning a stable difference representation for caption generation. Further, we devise a cross-modal backward reasoning to improve the quality of caption. This module reversely models a ``hallucination'' representation with the caption and ``before'' representation. By pushing i",
    "link": "http://arxiv.org/abs/2309.16283",
    "context": "Title: Self-supervised Cross-view Representation Reconstruction for Change Captioning. (arXiv:2309.16283v1 [cs.CV])\nAbstract: Change captioning aims to describe the difference between a pair of similar images. Its key challenge is how to learn a stable difference representation under pseudo changes caused by viewpoint change. In this paper, we address this by proposing a self-supervised cross-view representation reconstruction (SCORER) network. Concretely, we first design a multi-head token-wise matching to model relationships between cross-view features from similar/dissimilar images. Then, by maximizing cross-view contrastive alignment of two similar images, SCORER learns two view-invariant image representations in a self-supervised way. Based on these, we reconstruct the representations of unchanged objects by cross-attention, thus learning a stable difference representation for caption generation. Further, we devise a cross-modal backward reasoning to improve the quality of caption. This module reversely models a ``hallucination'' representation with the caption and ``before'' representation. By pushing i",
    "path": "papers/23/09/2309.16283.json",
    "total_tokens": 908,
    "translated_title": "自监督的跨视图表示重建用于变化描述",
    "translated_abstract": "变化描述旨在描述一对相似图像之间的差异。其关键挑战是如何在由视角变化引起的伪变化下学习稳定的差异表示。本文通过提出一种自监督的跨视图表示重建（SCORER）网络来解决这个问题。具体而言，我们首先设计了一个多头逐标记匹配来建模相似/不相似图像之间的跨视图特征关系。然后，通过最大化两个相似图像的跨视图对比对齐，SCORER以自监督的方式学习了两个视图不变的图像表示。基于这些表示，我们通过交叉注意力重建未改变对象的表示，从而学习到稳定的差异表示用于生成标题。此外，我们设计了一个跨模态的向后推理来改进标题的质量。该模块通过标题和“before”表示反向建模一个“幻觉”表示。通过推动和调整这个幻觉表示，我们实现了更好的标题生成。",
    "tldr": "本论文提出了一种自监督的跨视图表示重建网络（SCORER）来解决变化描述中的差异表示学习问题。该网络通过多头逐标记匹配和跨视图对比对齐来学习稳定的差异表示，进而生成更好的标题。"
}