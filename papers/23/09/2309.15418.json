{
    "title": "Automatic Feature Fairness in Recommendation via Adversaries. (arXiv:2309.15418v1 [cs.IR])",
    "abstract": "Fairness is a widely discussed topic in recommender systems, but its practical implementation faces challenges in defining sensitive features while maintaining recommendation accuracy. We propose feature fairness as the foundation to achieve equitable treatment across diverse groups defined by various feature combinations. This improves overall accuracy through balanced feature generalizability. We introduce unbiased feature learning through adversarial training, using adversarial perturbation to enhance feature representation. The adversaries improve model generalization for under-represented features. We adapt adversaries automatically based on two forms of feature biases: frequency and combination variety of feature values. This allows us to dynamically adjust perturbation strengths and adversarial training weights. Stronger perturbations are applied to feature values with fewer combination varieties to improve generalization, while higher weights for low-frequency features address ",
    "link": "http://arxiv.org/abs/2309.15418",
    "context": "Title: Automatic Feature Fairness in Recommendation via Adversaries. (arXiv:2309.15418v1 [cs.IR])\nAbstract: Fairness is a widely discussed topic in recommender systems, but its practical implementation faces challenges in defining sensitive features while maintaining recommendation accuracy. We propose feature fairness as the foundation to achieve equitable treatment across diverse groups defined by various feature combinations. This improves overall accuracy through balanced feature generalizability. We introduce unbiased feature learning through adversarial training, using adversarial perturbation to enhance feature representation. The adversaries improve model generalization for under-represented features. We adapt adversaries automatically based on two forms of feature biases: frequency and combination variety of feature values. This allows us to dynamically adjust perturbation strengths and adversarial training weights. Stronger perturbations are applied to feature values with fewer combination varieties to improve generalization, while higher weights for low-frequency features address ",
    "path": "papers/23/09/2309.15418.json",
    "total_tokens": 796,
    "translated_title": "通过对手对推荐系统中的特征公平性的自动处理",
    "translated_abstract": "公平性是推荐系统中广泛讨论的一个主题，但其实践实现在定义敏感特征的同时保持推荐准确性方面面临挑战。我们提出将特征公平性作为实现各个由不同特征组合定义的多样群体之间的公平待遇的基础。通过平衡特征的泛化能力，可以提高整体准确性。我们通过对手训练引入了无偏特征学习，使用对手扰动增强特征表示。对手改进了模型对少数特征的泛化能力。我们根据特征偏差的两种形式自动适应对手：特征值的频率和组合多样性。这使我们能够动态调整扰动强度和对手训练权重。更强的扰动适用于组合变化少的特征值，以改善泛化能力，而对于低频特征，较高的权重可以解决...",
    "tldr": "通过对手训练实现推荐系统中的特征公平性，提高整体准确性和泛化能力",
    "en_tdlr": "Improving fairness and generalizability in recommender systems by incorporating adversarial training, which enhances feature fairness and overall accuracy."
}