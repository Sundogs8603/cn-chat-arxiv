{
    "title": "BayesDLL: Bayesian Deep Learning Library. (arXiv:2309.12928v1 [cs.LG])",
    "abstract": "We release a new Bayesian neural network library for PyTorch for large-scale deep networks. Our library implements mainstream approximate Bayesian inference algorithms: variational inference, MC-dropout, stochastic-gradient MCMC, and Laplace approximation. The main differences from other existing Bayesian neural network libraries are as follows: 1) Our library can deal with very large-scale deep networks including Vision Transformers (ViTs). 2) We need virtually zero code modifications for users (e.g., the backbone network definition codes do not neet to be modified at all). 3) Our library also allows the pre-trained model weights to serve as a prior mean, which is very useful for performing Bayesian inference with the large-scale foundation models like ViTs that are hard to optimise from scratch with the downstream data alone. Our code is publicly available at: \\url{https://github.com/SamsungLabs/BayesDLL}\\footnote{A mirror repository is also available at: \\url{https://github.com/miny",
    "link": "http://arxiv.org/abs/2309.12928",
    "context": "Title: BayesDLL: Bayesian Deep Learning Library. (arXiv:2309.12928v1 [cs.LG])\nAbstract: We release a new Bayesian neural network library for PyTorch for large-scale deep networks. Our library implements mainstream approximate Bayesian inference algorithms: variational inference, MC-dropout, stochastic-gradient MCMC, and Laplace approximation. The main differences from other existing Bayesian neural network libraries are as follows: 1) Our library can deal with very large-scale deep networks including Vision Transformers (ViTs). 2) We need virtually zero code modifications for users (e.g., the backbone network definition codes do not neet to be modified at all). 3) Our library also allows the pre-trained model weights to serve as a prior mean, which is very useful for performing Bayesian inference with the large-scale foundation models like ViTs that are hard to optimise from scratch with the downstream data alone. Our code is publicly available at: \\url{https://github.com/SamsungLabs/BayesDLL}\\footnote{A mirror repository is also available at: \\url{https://github.com/miny",
    "path": "papers/23/09/2309.12928.json",
    "total_tokens": 916,
    "translated_title": "BayesDLL: 贝叶斯深度学习库",
    "translated_abstract": "我们发布了一个新的用于PyTorch的贝叶斯神经网络库，用于大规模深度网络。我们的库实现了主流的近似贝叶斯推断算法：变分推断、MC-dropout、随机梯度MCMC和拉普拉斯近似。与其他现有的贝叶斯神经网络库相比，我们的库有以下主要区别：1）我们的库可以处理包括视觉变换器（ViTs）在内的非常大规模的深度网络。2）用户几乎不需要修改代码（例如，骨干网络定义代码根本不需要修改）。3）我们的库还允许预训练模型权重作为先验均值，这对于使用仅仅依靠下游数据难以从头开始优化的大规模基础模型（如ViTs）进行贝叶斯推断非常有用。我们的代码公开可用于: \\url{https://github.com/SamsungLabs/BayesDLL}（备用存储库也可在此处找到：\\url{https://github.com/miny})",
    "tldr": "BayesDLL是一个用于PyTorch的贝叶斯深度学习库，与其他现有库相比，它可以处理非常大规模的深度网络，无需修改用户代码，并且可以使用预训练模型权重作为先验均值，适用于贝叶斯推断。",
    "en_tdlr": "BayesDLL is a Bayesian deep learning library for PyTorch that can handle large-scale deep networks without code modifications, and allows the use of pre-trained model weights as prior mean for Bayesian inference."
}