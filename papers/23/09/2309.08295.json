{
    "title": "A Real-Time Active Speaker Detection System Integrating an Audio-Visual Signal with a Spatial Querying Mechanism. (arXiv:2309.08295v1 [eess.AS])",
    "abstract": "We introduce a distinctive real-time, causal, neural network-based active speaker detection system optimized for low-power edge computing. This system drives a virtual cinematography module and is deployed on a commercial device. The system uses data originating from a microphone array and a 360-degree camera. Our network requires only 127 MFLOPs per participant, for a meeting with 14 participants. Unlike previous work, we examine the error rate of our network when the computational budget is exhausted, and find that it exhibits graceful degradation, allowing the system to operate reasonably well even in this case. Departing from conventional DOA estimation approaches, our network learns to query the available acoustic data, considering the detected head locations. We train and evaluate our algorithm on a realistic meetings dataset featuring up to 14 participants in the same meeting, overlapped speech, and other challenging scenarios.",
    "link": "http://arxiv.org/abs/2309.08295",
    "context": "Title: A Real-Time Active Speaker Detection System Integrating an Audio-Visual Signal with a Spatial Querying Mechanism. (arXiv:2309.08295v1 [eess.AS])\nAbstract: We introduce a distinctive real-time, causal, neural network-based active speaker detection system optimized for low-power edge computing. This system drives a virtual cinematography module and is deployed on a commercial device. The system uses data originating from a microphone array and a 360-degree camera. Our network requires only 127 MFLOPs per participant, for a meeting with 14 participants. Unlike previous work, we examine the error rate of our network when the computational budget is exhausted, and find that it exhibits graceful degradation, allowing the system to operate reasonably well even in this case. Departing from conventional DOA estimation approaches, our network learns to query the available acoustic data, considering the detected head locations. We train and evaluate our algorithm on a realistic meetings dataset featuring up to 14 participants in the same meeting, overlapped speech, and other challenging scenarios.",
    "path": "papers/23/09/2309.08295.json",
    "total_tokens": 931,
    "translated_title": "一个实时活动说话人检测系统，将音频-视觉信号与空间查询机制整合在一起",
    "translated_abstract": "我们介绍了一种独特的实时、因果关系的基于神经网络的活动说话人检测系统，经过低功耗边缘计算优化。该系统驱动一个虚拟影视模块，并且部署在商业设备上。该系统使用来自麦克风阵列和360度相机的数据。我们的网络每个参与者只需要127MFLOPs，对于一个有14个参与者的会议。与以前的工作不同，当计算预算耗尽时，我们检查了我们的网络的错误率，并发现它表现出了优雅的退化，即使在这种情况下，系统仍然能够运行得相当好。与传统的方向估计方法不同，我们的网络学习查询可用的声学数据，并考虑到检测到的头部位置。我们在一个包含最多14个参与者、重叠的语音和其他挑战性场景的真实会议数据集上训练和评估我们的算法。",
    "tldr": "本文介绍了一个实时活动说话人检测系统，通过将音频-视觉信号与空间查询机制整合，利用低功耗边缘计算实现。该系统具有优雅的退化性能，能够在计算预算耗尽的情况下仍然有效运行，并在真实会议数据集上表现出良好的性能。",
    "en_tdlr": "This paper presents a real-time active speaker detection system that integrates audio-visual signals with a spatial querying mechanism, optimized for low-power edge computing. The system exhibits graceful degradation and performs well even when the computational budget is exhausted, demonstrating good performance on a realistic meetings dataset."
}