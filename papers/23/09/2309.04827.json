{
    "title": "Neurons in Large Language Models: Dead, N-gram, Positional. (arXiv:2309.04827v1 [cs.CL])",
    "abstract": "We analyze a family of large language models in such a lightweight manner that can be done on a single GPU. Specifically, we focus on the OPT family of models ranging from 125m to 66b parameters and rely only on whether an FFN neuron is activated or not. First, we find that the early part of the network is sparse and represents many discrete features. Here, many neurons (more than 70% in some layers of the 66b model) are \"dead\", i.e. they never activate on a large collection of diverse data. At the same time, many of the alive neurons are reserved for discrete features and act as token and n-gram detectors. Interestingly, their corresponding FFN updates not only promote next token candidates as could be expected, but also explicitly focus on removing the information about triggering them tokens, i.e., current input. To the best of our knowledge, this is the first example of mechanisms specialized at removing (rather than adding) information from the residual stream. With scale, models ",
    "link": "http://arxiv.org/abs/2309.04827",
    "context": "Title: Neurons in Large Language Models: Dead, N-gram, Positional. (arXiv:2309.04827v1 [cs.CL])\nAbstract: We analyze a family of large language models in such a lightweight manner that can be done on a single GPU. Specifically, we focus on the OPT family of models ranging from 125m to 66b parameters and rely only on whether an FFN neuron is activated or not. First, we find that the early part of the network is sparse and represents many discrete features. Here, many neurons (more than 70% in some layers of the 66b model) are \"dead\", i.e. they never activate on a large collection of diverse data. At the same time, many of the alive neurons are reserved for discrete features and act as token and n-gram detectors. Interestingly, their corresponding FFN updates not only promote next token candidates as could be expected, but also explicitly focus on removing the information about triggering them tokens, i.e., current input. To the best of our knowledge, this is the first example of mechanisms specialized at removing (rather than adding) information from the residual stream. With scale, models ",
    "path": "papers/23/09/2309.04827.json",
    "total_tokens": 993,
    "translated_title": "大型语言模型中的神经元：不活跃，N-gram，位置",
    "translated_abstract": "我们以一种轻量级的方式分析了一类大型语言模型，这可以在单个GPU上进行。具体而言，我们关注的是OPT系列模型，参数范围从125m到66b，并且仅依赖于FFN神经元是否被激活。首先，我们发现网络的早期部分是稀疏的，表示许多离散特征。在这里，许多神经元（在66b模型的某些层中超过70%）是“不活跃的”，即它们在大量多样化的数据上从不激活。同时，许多活跃的神经元专用于离散特征，并且充当标记和n-gram检测器。有趣的是，它们对应的FFN更新不仅促进了下一个标记的候选，这是可以预期的，而且还明确地专注于移除与触发它们的标记（即当前输入）相关的信息。据我们所知，这是第一个在残差流中专门用于移除（而不是添加）信息的机制的例子。",
    "tldr": "该论文分析了大型语言模型中的神经元行为，发现网络的早期部分是稀疏的，包含许多死亡神经元和专门用于离散特征的活跃神经元。这些活跃神经元的更新不仅推动下一个标记的生成，还专注于移除与触发它们的标记相关的信息。",
    "en_tdlr": "This paper analyzes the behavior of neurons in large language models and finds that the early part of the network is sparse, with many dead neurons and active neurons dedicated to discrete features. The updates of these active neurons not only promote the generation of the next token, but also focus on removing information related to triggering tokens."
}