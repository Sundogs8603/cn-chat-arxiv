{
    "title": "Adaptive Priority Reweighing for Generalizing Fairness Improvement. (arXiv:2309.08375v1 [cs.LG])",
    "abstract": "With the increasing penetration of machine learning applications in critical decision-making areas, calls for algorithmic fairness are more prominent. Although there have been various modalities to improve algorithmic fairness through learning with fairness constraints, their performance does not generalize well in the test set. A performance-promising fair algorithm with better generalizability is needed. This paper proposes a novel adaptive reweighing method to eliminate the impact of the distribution shifts between training and test data on model generalizability. Most previous reweighing methods propose to assign a unified weight for each (sub)group. Rather, our method granularly models the distance from the sample predictions to the decision boundary. Our adaptive reweighing method prioritizes samples closer to the decision boundary and assigns a higher weight to improve the generalizability of fair classifiers. Extensive experiments are performed to validate the generalizability ",
    "link": "http://arxiv.org/abs/2309.08375",
    "context": "Title: Adaptive Priority Reweighing for Generalizing Fairness Improvement. (arXiv:2309.08375v1 [cs.LG])\nAbstract: With the increasing penetration of machine learning applications in critical decision-making areas, calls for algorithmic fairness are more prominent. Although there have been various modalities to improve algorithmic fairness through learning with fairness constraints, their performance does not generalize well in the test set. A performance-promising fair algorithm with better generalizability is needed. This paper proposes a novel adaptive reweighing method to eliminate the impact of the distribution shifts between training and test data on model generalizability. Most previous reweighing methods propose to assign a unified weight for each (sub)group. Rather, our method granularly models the distance from the sample predictions to the decision boundary. Our adaptive reweighing method prioritizes samples closer to the decision boundary and assigns a higher weight to improve the generalizability of fair classifiers. Extensive experiments are performed to validate the generalizability ",
    "path": "papers/23/09/2309.08375.json",
    "total_tokens": 852,
    "translated_title": "自适应优先级重新加权以提高公平性泛化能力",
    "translated_abstract": "随着机器学习应用在关键决策领域的普及，对算法公平性的呼声越来越大。尽管已经通过学习公平约束来改善算法的公平性的各种方式，但它们在测试集上的性能并不能很好地推广。需要一种性能有前景且具有更好泛化能力的公平算法。本文提出了一种新颖的自适应重新加权方法，以消除训练数据和测试数据之间分布偏移对模型泛化能力的影响。大多数先前的重新加权方法提议为每个（子）组分配一个统一的权重。相反，我们的方法细粒度地建模了样本预测与决策边界的距离。我们的自适应重新加权方法优先考虑靠近决策边界的样本，并分配较高的权重来提高公平分类器的泛化能力。进行了大量实验验证了其泛化能力。",
    "tldr": "本文提出了一种新颖的自适应重新加权方法，通过优先考虑靠近决策边界的样本并分配较高的权重，提高了公平分类器的泛化能力。"
}