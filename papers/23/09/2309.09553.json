{
    "title": "Causal-Story: Local Causal Attention Utilizing Parameter-Efficient Tuning For Visual Story Synthesis. (arXiv:2309.09553v2 [cs.CV] UPDATED)",
    "abstract": "The excellent text-to-image synthesis capability of diffusion models has driven progress in synthesizing coherent visual stories. The current state-of-the-art method combines the features of historical captions, historical frames, and the current captions as conditions for generating the current frame. However, this method treats each historical frame and caption as the same contribution. It connects them in order with equal weights, ignoring that not all historical conditions are associated with the generation of the current frame. To address this issue, we propose Causal-Story. This model incorporates a local causal attention mechanism that considers the causal relationship between previous captions, frames, and current captions. By assigning weights based on this relationship, Causal-Story generates the current frame, thereby improving the global consistency of story generation. We evaluated our model on the PororoSV and FlintstonesSV datasets and obtained state-of-the-art FID score",
    "link": "http://arxiv.org/abs/2309.09553",
    "context": "Title: Causal-Story: Local Causal Attention Utilizing Parameter-Efficient Tuning For Visual Story Synthesis. (arXiv:2309.09553v2 [cs.CV] UPDATED)\nAbstract: The excellent text-to-image synthesis capability of diffusion models has driven progress in synthesizing coherent visual stories. The current state-of-the-art method combines the features of historical captions, historical frames, and the current captions as conditions for generating the current frame. However, this method treats each historical frame and caption as the same contribution. It connects them in order with equal weights, ignoring that not all historical conditions are associated with the generation of the current frame. To address this issue, we propose Causal-Story. This model incorporates a local causal attention mechanism that considers the causal relationship between previous captions, frames, and current captions. By assigning weights based on this relationship, Causal-Story generates the current frame, thereby improving the global consistency of story generation. We evaluated our model on the PororoSV and FlintstonesSV datasets and obtained state-of-the-art FID score",
    "path": "papers/23/09/2309.09553.json",
    "total_tokens": 872,
    "translated_title": "因果故事：利用参数高效调整的局部因果注意力实现视觉故事合成",
    "translated_abstract": "演化模型在文本到图像合成方面具有出色的能力，推动了连贯视觉故事的合成进展。目前最先进的方法将历史标题、历史帧和当前标题的特征作为生成当前帧的条件进行组合。然而，该方法将每个历史帧和标题都视为同样的贡献，并以相等的权重将它们连接起来，忽视了并非所有历史条件都与生成当前帧相关。为了解决这个问题，我们提出了因果故事。该模型引入了一种考虑先前标题、帧和当前标题之间因果关系的局部因果注意机制。通过根据这种关系分配权重，因果故事生成当前帧，从而提高了故事生成的全局一致性。我们在PororoSV和FlintstonesSV数据集上评估了我们的模型，并获得了最先进的FID分数。",
    "tldr": "提出了一种称为因果故事的新模型，利用局部因果注意力机制来改进视觉故事合成的全局一致性，该模型考虑了历史标题、帧和当前标题之间的因果关系，实现了更好的生成效果。"
}