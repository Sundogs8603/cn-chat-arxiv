{
    "title": "Code Representation Pre-training with Complements from Program Executions. (arXiv:2309.09980v1 [cs.SE])",
    "abstract": "Large language models (LLMs) for natural language processing have been grafted onto programming language modeling for advancing code intelligence. Although it can be represented in the text format, code is syntactically more rigorous in order to be properly compiled or interpreted to perform a desired set of behaviors given any inputs. In this case, existing works benefit from syntactic representations to learn from code less ambiguously in the forms of abstract syntax tree, control-flow graph, etc. However, programs with the same purpose can be implemented in various ways showing different syntactic representations while the ones with similar implementations can have distinct behaviors. Though trivially demonstrated during executions, such semantics about functionality are challenging to be learned directly from code, especially in an unsupervised manner. Hence, in this paper, we propose FuzzPretrain to explore the dynamic information of programs revealed by their test cases and embed",
    "link": "http://arxiv.org/abs/2309.09980",
    "context": "Title: Code Representation Pre-training with Complements from Program Executions. (arXiv:2309.09980v1 [cs.SE])\nAbstract: Large language models (LLMs) for natural language processing have been grafted onto programming language modeling for advancing code intelligence. Although it can be represented in the text format, code is syntactically more rigorous in order to be properly compiled or interpreted to perform a desired set of behaviors given any inputs. In this case, existing works benefit from syntactic representations to learn from code less ambiguously in the forms of abstract syntax tree, control-flow graph, etc. However, programs with the same purpose can be implemented in various ways showing different syntactic representations while the ones with similar implementations can have distinct behaviors. Though trivially demonstrated during executions, such semantics about functionality are challenging to be learned directly from code, especially in an unsupervised manner. Hence, in this paper, we propose FuzzPretrain to explore the dynamic information of programs revealed by their test cases and embed",
    "path": "papers/23/09/2309.09980.json",
    "total_tokens": 838,
    "translated_title": "通过程序执行补充进行代码表示预训练",
    "translated_abstract": "大型语言模型（LLMs）已被应用于编程语言建模，以推进代码智能化。尽管代码可以以文本格式表示，但为了正确编译或解释以执行一组期望的行为，代码在语法上更加严格。在这种情况下，现有的工作通过抽象语法树、控制流图等形式的句法表示，从代码中以较少的歧义性学习。然而，具有相同目的的程序可以用各种方式实现，显示出不同的句法表示，而具有类似实现的程序可能具有不同的行为。虽然在执行过程中可以轻易地演示这种语义，但功能上的这些语义很难直接从代码中学习，特别是在无监督的情况下。因此，在本文中，我们提出了FuzzPretrain来探索由测试用例揭示的程序的动态信息，并嵌入到代码表示的预训练中。",
    "tldr": "本论文提出了一种名为FuzzPretrain的方法，用于在代码表示预训练中探索由程序的测试用例揭示的动态信息，并解决从代码中直接学习功能语义的挑战。"
}