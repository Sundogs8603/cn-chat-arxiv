{
    "title": "I Wish to Have an Argument: Argumentative Reasoning in Large Language Models. (arXiv:2309.16938v1 [cs.CL])",
    "abstract": "We evaluate the ability of contemporary large language models (LLMs) to perform argumentative reasoning. We frame our experiments in terms of the argument mining (AM) and argument pair extraction (APE) tasks, and evaluate their ability to perform reasoning at increasing levels of abstraction in the input and output representations (e.g., arbitrary label sets, semantic graphs). We find that, although LLMs are able to match or surpass the state-of-the-art in AM and APE, their argumentative reasoning performance is very dependent on the input and output representation. We also find an \"exemplar effect\", where too many exemplars increasingly become detrimental for task performance, and about 4-5 being the optimal amount. Neither result extends to chain-of-thought (CoT) prompting: we find the exemplar effect to be nullified, and our results suggest that CoT allows for better performance under ill-conditioned problems. We hope that the work reported contributes to the improvement of argument",
    "link": "http://arxiv.org/abs/2309.16938",
    "context": "Title: I Wish to Have an Argument: Argumentative Reasoning in Large Language Models. (arXiv:2309.16938v1 [cs.CL])\nAbstract: We evaluate the ability of contemporary large language models (LLMs) to perform argumentative reasoning. We frame our experiments in terms of the argument mining (AM) and argument pair extraction (APE) tasks, and evaluate their ability to perform reasoning at increasing levels of abstraction in the input and output representations (e.g., arbitrary label sets, semantic graphs). We find that, although LLMs are able to match or surpass the state-of-the-art in AM and APE, their argumentative reasoning performance is very dependent on the input and output representation. We also find an \"exemplar effect\", where too many exemplars increasingly become detrimental for task performance, and about 4-5 being the optimal amount. Neither result extends to chain-of-thought (CoT) prompting: we find the exemplar effect to be nullified, and our results suggest that CoT allows for better performance under ill-conditioned problems. We hope that the work reported contributes to the improvement of argument",
    "path": "papers/23/09/2309.16938.json",
    "total_tokens": 925,
    "translated_title": "我希望争论：大型语言模型中的争论性推理",
    "translated_abstract": "我们评估当代大型语言模型（LLMs）进行争论性推理的能力。我们将实验框架定为争论挖掘（AM）和争论对提取（APE）任务，并评估它们在输入和输出表示的抽象级别上执行推理的能力（例如，任意标签集，语义图）。我们发现，尽管 LLMs 在 AM 和 APE 上能够与或超过最先进的水平，但它们的争论性推理性能非常依赖于输入和输出表示。我们还发现了一个“典型效应”，过多的典型实例会对任务性能产生负面影响，最佳数量约为4-5个。然而，这些结果并不适用于思维链（CoT）提示：我们发现典型效应被抵消，我们的结果表明在病态问题下，CoT 可以实现更好的性能。我们希望所报告的工作能够促进争论性推理的改进。",
    "tldr": "该论文评估了当代大型语言模型在争论性推理方面的能力，并发现其争论性推理性能与输入和输出表示密切相关。研究还发现了“典型效应”，并探讨了在思维链提示下解决病态问题时的性能优势。"
}