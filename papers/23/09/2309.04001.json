{
    "title": "Multimodal Transformer for Material Segmentation. (arXiv:2309.04001v1 [cs.CV])",
    "abstract": "Leveraging information across diverse modalities is known to enhance performance on multimodal segmentation tasks. However, effectively fusing information from different modalities remains challenging due to the unique characteristics of each modality. In this paper, we propose a novel fusion strategy that can effectively fuse information from different combinations of four different modalities: RGB, Angle of Linear Polarization (AoLP), Degree of Linear Polarization (DoLP) and Near-Infrared (NIR). We also propose a new model named Multi-Modal Segmentation Transformer (MMSFormer) that incorporates the proposed fusion strategy to perform multimodal material segmentation. MMSFormer achieves 52.05% mIoU outperforming the current state-of-the-art on Multimodal Material Segmentation (MCubeS) dataset. For instance, our method provides significant improvement in detecting gravel (+10.4%) and human (+9.1%) classes. Ablation studies show that different modules in the fusion block are crucial for",
    "link": "http://arxiv.org/abs/2309.04001",
    "context": "Title: Multimodal Transformer for Material Segmentation. (arXiv:2309.04001v1 [cs.CV])\nAbstract: Leveraging information across diverse modalities is known to enhance performance on multimodal segmentation tasks. However, effectively fusing information from different modalities remains challenging due to the unique characteristics of each modality. In this paper, we propose a novel fusion strategy that can effectively fuse information from different combinations of four different modalities: RGB, Angle of Linear Polarization (AoLP), Degree of Linear Polarization (DoLP) and Near-Infrared (NIR). We also propose a new model named Multi-Modal Segmentation Transformer (MMSFormer) that incorporates the proposed fusion strategy to perform multimodal material segmentation. MMSFormer achieves 52.05% mIoU outperforming the current state-of-the-art on Multimodal Material Segmentation (MCubeS) dataset. For instance, our method provides significant improvement in detecting gravel (+10.4%) and human (+9.1%) classes. Ablation studies show that different modules in the fusion block are crucial for",
    "path": "papers/23/09/2309.04001.json",
    "total_tokens": 880,
    "translated_title": "多模态变换器用于材料分割",
    "translated_abstract": "利用不同模态的信息可以提高多模态分割任务的性能。然而，由于每个模态的独特特性，有效地融合不同模态的信息仍然具有挑战性。在本文中，我们提出了一种新的融合策略，可以有效地融合四种不同模态的信息：RGB、线性偏振角（AoLP）、线性偏振度（DoLP）和近红外（NIR）。我们还提出了一种名为多模态分割变换器（MMSFormer）的新模型，该模型将所提出的融合策略结合起来进行多模态材料分割。MMSFormer在多模态材料分割（MCubeS）数据集上取得了52.05％的mIoU，超过了当前最先进的方法。例如，我们的方法在检测砾石（+10.4％）和人类（+9.1％）类上提供了显着的改进。消融研究表明融合块中的不同模块对结果至关重要。",
    "tldr": "本文提出了一种新的多模态分割方法MMSFormer，该方法有效地融合四种不同模态的信息，并在MCubeS数据集上取得了显著的性能提升。",
    "en_tdlr": "This paper proposes a novel multimodal segmentation method called MMSFormer, which effectively fuses information from four different modalities and achieves significant performance improvement on the MCubeS dataset."
}