{
    "title": "User-Level Differential Privacy With Few Examples Per User. (arXiv:2309.12500v1 [cs.DS])",
    "abstract": "Previous work on user-level differential privacy (DP) [Ghazi et al. NeurIPS 2021, Bun et al. STOC 2023] obtained generic algorithms that work for various learning tasks. However, their focus was on the example-rich regime, where the users have so many examples that each user could themselves solve the problem. In this work we consider the example-scarce regime, where each user has only a few examples, and obtain the following results:  1. For approximate-DP, we give a generic transformation of any item-level DP algorithm to a user-level DP algorithm. Roughly speaking, the latter gives a (multiplicative) savings of $O_{\\varepsilon,\\delta}(\\sqrt{m})$ in terms of the number of users required for achieving the same utility, where $m$ is the number of examples per user. This algorithm, while recovering most known bounds for specific problems, also gives new bounds, e.g., for PAC learning.  2. For pure-DP, we present a simple technique for adapting the exponential mechanism [McSherry, Talwar",
    "link": "http://arxiv.org/abs/2309.12500",
    "context": "Title: User-Level Differential Privacy With Few Examples Per User. (arXiv:2309.12500v1 [cs.DS])\nAbstract: Previous work on user-level differential privacy (DP) [Ghazi et al. NeurIPS 2021, Bun et al. STOC 2023] obtained generic algorithms that work for various learning tasks. However, their focus was on the example-rich regime, where the users have so many examples that each user could themselves solve the problem. In this work we consider the example-scarce regime, where each user has only a few examples, and obtain the following results:  1. For approximate-DP, we give a generic transformation of any item-level DP algorithm to a user-level DP algorithm. Roughly speaking, the latter gives a (multiplicative) savings of $O_{\\varepsilon,\\delta}(\\sqrt{m})$ in terms of the number of users required for achieving the same utility, where $m$ is the number of examples per user. This algorithm, while recovering most known bounds for specific problems, also gives new bounds, e.g., for PAC learning.  2. For pure-DP, we present a simple technique for adapting the exponential mechanism [McSherry, Talwar",
    "path": "papers/23/09/2309.12500.json",
    "total_tokens": 924,
    "translated_title": "用户级差分隐私在少量用户示例下的应用",
    "translated_abstract": "以前关于用户级差分隐私的研究主要针对示例丰富的场景，即每个用户都有足够多的示例，可以自行解决问题。本文考虑了示例稀缺的情况，即每个用户只有少量示例，并得到以下结果：1. 对于近似差分隐私，我们提供了一种通用的转换方法，将任何项级差分隐私算法转换为用户级差分隐私算法。粗略地说，后者在达到相同效用时，所需的用户数量相对于示例数量$m$以$O_{\\varepsilon,\\delta}(\\sqrt{m})$的速度减少，其中$m$是每个用户的示例数量。这个算法在恢复大多数已知问题的界限的同时，还给出了新的界限，例如对于PAC学习。2. 对于纯差分隐私，我们提出了一种简单的技术，用于调整指数机制[McSherry，Talwar",
    "tldr": "本论文研究了用户级差分隐私在少量示例的情况下的应用。对于近似差分隐私，提供了一种转换方法来将项级差分隐私算法转换为用户级差分隐私算法，可以在保持相同效用的前提下减少所需的用户数量。对于纯差分隐私，提出了一种简单的技术来适应指数机制。"
}