{
    "title": "A Differentiable Framework for End-to-End Learning of Hybrid Structured Compression. (arXiv:2309.13077v1 [cs.LG])",
    "abstract": "Filter pruning and low-rank decomposition are two of the foundational techniques for structured compression. Although recent efforts have explored hybrid approaches aiming to integrate the advantages of both techniques, their performance gains have been modest at best. In this study, we develop a \\textit{Differentiable Framework~(DF)} that can express filter selection, rank selection, and budget constraint into a single analytical formulation. Within the framework, we introduce DML-S for filter selection, integrating scheduling into existing mask learning techniques. Additionally, we present DTL-S for rank selection, utilizing a singular value thresholding operator. The framework with DML-S and DTL-S offers a hybrid structured compression methodology that facilitates end-to-end learning through gradient-base optimization. Experimental results demonstrate the efficacy of DF, surpassing state-of-the-art structured compression methods. Our work establishes a robust and versatile avenue fo",
    "link": "http://arxiv.org/abs/2309.13077",
    "context": "Title: A Differentiable Framework for End-to-End Learning of Hybrid Structured Compression. (arXiv:2309.13077v1 [cs.LG])\nAbstract: Filter pruning and low-rank decomposition are two of the foundational techniques for structured compression. Although recent efforts have explored hybrid approaches aiming to integrate the advantages of both techniques, their performance gains have been modest at best. In this study, we develop a \\textit{Differentiable Framework~(DF)} that can express filter selection, rank selection, and budget constraint into a single analytical formulation. Within the framework, we introduce DML-S for filter selection, integrating scheduling into existing mask learning techniques. Additionally, we present DTL-S for rank selection, utilizing a singular value thresholding operator. The framework with DML-S and DTL-S offers a hybrid structured compression methodology that facilitates end-to-end learning through gradient-base optimization. Experimental results demonstrate the efficacy of DF, surpassing state-of-the-art structured compression methods. Our work establishes a robust and versatile avenue fo",
    "path": "papers/23/09/2309.13077.json",
    "total_tokens": 948,
    "translated_title": "一种可微分的端到端混合结构压缩学习框架",
    "translated_abstract": "滤波器剪枝和低秩分解是结构化压缩的两个基本技术。虽然最近的研究尝试了整合这两种技术优势的混合方法，但性能提升一直很有限。本研究提出了一个称为Differentiable Framework (DF)的框架，它能够将滤波器选择、秩选择和预算约束融合成一个单一的分析公式。在该框架下，我们引入了用于滤波器选择的DML-S，将调度集成到现有的掩码学习技术中。此外，我们还提出了用于秩选择的DTL-S，利用奇异值阈值运算符。DF框架结合DML-S和DTL-S提供了一种混合结构压缩方法，在梯度优化的过程中实现了端到端学习。实验证明了DF的有效性，超过了现有的结构化压缩方法。我们的工作为建立一个强大而通用的研究方向奠定了基础。",
    "tldr": "提出了一个可微分的端到端混合结构压缩学习框架，该框架能够在单一的分析公式中融合滤波器选择、秩选择和预算约束，并通过梯度优化实现端到端学习。实验证明了该框架的有效性，超过了现有的结构化压缩方法。",
    "en_tdlr": "A differentiable framework for end-to-end learning of hybrid structured compression is proposed, which integrates filter selection, rank selection, and budget constraint into a single analytical formulation and achieves end-to-end learning through gradient optimization. Experimental results demonstrate the efficacy of the framework, surpassing existing structured compression methods."
}