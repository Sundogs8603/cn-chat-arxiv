{
    "title": "Encoding Multi-Domain Scientific Papers by Ensembling Multiple CLS Tokens. (arXiv:2309.04333v1 [cs.CL])",
    "abstract": "Many useful tasks on scientific documents, such as topic classification and citation prediction, involve corpora that span multiple scientific domains. Typically, such tasks are accomplished by representing the text with a vector embedding obtained from a Transformer's single CLS token. In this paper, we argue that using multiple CLS tokens could make a Transformer better specialize to multiple scientific domains. We present Multi2SPE: it encourages each of multiple CLS tokens to learn diverse ways of aggregating token embeddings, then sums them up together to create a single vector representation. We also propose our new multi-domain benchmark, Multi-SciDocs, to test scientific paper vector encoders under multi-domain settings. We show that Multi2SPE reduces error by up to 25 percent in multi-domain citation prediction, while requiring only a negligible amount of computation in addition to one BERT forward pass.",
    "link": "http://arxiv.org/abs/2309.04333",
    "context": "Title: Encoding Multi-Domain Scientific Papers by Ensembling Multiple CLS Tokens. (arXiv:2309.04333v1 [cs.CL])\nAbstract: Many useful tasks on scientific documents, such as topic classification and citation prediction, involve corpora that span multiple scientific domains. Typically, such tasks are accomplished by representing the text with a vector embedding obtained from a Transformer's single CLS token. In this paper, we argue that using multiple CLS tokens could make a Transformer better specialize to multiple scientific domains. We present Multi2SPE: it encourages each of multiple CLS tokens to learn diverse ways of aggregating token embeddings, then sums them up together to create a single vector representation. We also propose our new multi-domain benchmark, Multi-SciDocs, to test scientific paper vector encoders under multi-domain settings. We show that Multi2SPE reduces error by up to 25 percent in multi-domain citation prediction, while requiring only a negligible amount of computation in addition to one BERT forward pass.",
    "path": "papers/23/09/2309.04333.json",
    "total_tokens": 839,
    "translated_title": "使用多个CLS标记集合对多领域科学论文进行编码",
    "translated_abstract": "许多科学文档上的有用任务，如主题分类和引文预测，涉及跨越多个科学领域的语料库。通常，这些任务通过使用来自Transformer的单个CLS标记的向量嵌入来完成。在本文中，我们认为使用多个CLS标记可以使Transformer更好地专注于多个科学领域。我们提出了Multi2SPE：它鼓励多个CLS标记学习聚合标记嵌入的不同方式，然后将它们相加以创建单个向量表示。我们还提出了我们的新的多领域基准测试数据集Multi-SciDocs，以测试多领域设置下的科学论文向量编码器。我们证明Multi2SPE在多领域引文预测中减少了多达25％的误差，同时除了一次BERT前向传递之外，只需要极少量的计算量。",
    "tldr": "本研究提出了Multi2SPE方法，通过使用多个CLS标记来编码多领域科学论文，能够更好地适应不同的科学领域，并在引文预测任务中减少了多达25％的误差。"
}