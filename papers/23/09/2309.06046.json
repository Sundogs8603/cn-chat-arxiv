{
    "title": "BatMan-CLR: Making Few-shots Meta-Learners Resilient Against Label Noise. (arXiv:2309.06046v1 [cs.LG])",
    "abstract": "The negative impact of label noise is well studied in classical supervised learning yet remains an open research question in meta-learning. Meta-learners aim to adapt to unseen learning tasks by learning a good initial model in meta-training and consecutively fine-tuning it according to new tasks during meta-testing. In this paper, we present the first extensive analysis of the impact of varying levels of label noise on the performance of state-of-the-art meta-learners, specifically gradient-based $N$-way $K$-shot learners. We show that the accuracy of Reptile, iMAML, and foMAML drops by up to 42% on the Omniglot and CifarFS datasets when meta-training is affected by label noise. To strengthen the resilience against label noise, we propose two sampling techniques, namely manifold (Man) and batch manifold (BatMan), which transform the noisy supervised learners into semi-supervised ones to increase the utility of noisy labels. We first construct manifold samples of $N$-way $2$-contrastiv",
    "link": "http://arxiv.org/abs/2309.06046",
    "context": "Title: BatMan-CLR: Making Few-shots Meta-Learners Resilient Against Label Noise. (arXiv:2309.06046v1 [cs.LG])\nAbstract: The negative impact of label noise is well studied in classical supervised learning yet remains an open research question in meta-learning. Meta-learners aim to adapt to unseen learning tasks by learning a good initial model in meta-training and consecutively fine-tuning it according to new tasks during meta-testing. In this paper, we present the first extensive analysis of the impact of varying levels of label noise on the performance of state-of-the-art meta-learners, specifically gradient-based $N$-way $K$-shot learners. We show that the accuracy of Reptile, iMAML, and foMAML drops by up to 42% on the Omniglot and CifarFS datasets when meta-training is affected by label noise. To strengthen the resilience against label noise, we propose two sampling techniques, namely manifold (Man) and batch manifold (BatMan), which transform the noisy supervised learners into semi-supervised ones to increase the utility of noisy labels. We first construct manifold samples of $N$-way $2$-contrastiv",
    "path": "papers/23/09/2309.06046.json",
    "total_tokens": 1106,
    "translated_title": "BatMan-CLR: 使得少样本元学习器对标签噪声具有鲁棒性",
    "translated_abstract": "标签噪声对于经典的监督学习已经有了深入研究，但是在元学习领域仍然是一个开放的研究问题。元学习器旨在通过在元训练中学习一个良好的初始模型，并在元测试期间根据新任务进行连续微调，以适应未知的学习任务。本文首次全面分析了不同程度的标签噪声对最先进的元学习器（特别是基于梯度的N-way K-shot学习器）性能的影响。结果表明，当元训练受到标签噪声的影响时，Reptile、iMAML和foMAML在Omniglot和CifarFS数据集上的准确性下降了最高达42%。为了增强对标签噪声的鲁棒性，我们提出了两种采样技术，即流形（Man）和批次流形（BatMan），将有噪声的有监督学习器转变为半监督学习器，以增加噪声标签的效用。我们首先构建了N-way 2-contrastiv的流形样本",
    "tldr": "本研究对少样本元学习器受标签噪声影响的性能进行了全面分析，发现在受到标签噪声影响的元训练中，Reptile、iMAML和foMAML在Omniglot和CifarFS数据集上的准确性下降了最高达42%。为了增强对标签噪声的鲁棒性，提出了Man和BatMan两种采样技术，将有噪声的有监督学习器转变为半监督学习器。",
    "en_tdlr": "This study provides an extensive analysis of the impact of label noise on the performance of few-shot meta-learners, showing that Reptile, iMAML, and foMAML experience up to a 42% drop in accuracy on Omniglot and CifarFS datasets. To enhance resilience against label noise, the authors propose two sampling techniques, Man and BatMan, which transform noisy supervised learners into semi-supervised ones."
}