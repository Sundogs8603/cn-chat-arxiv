{
    "title": "Towards Contrastive Learning in Music Video Domain. (arXiv:2309.00347v1 [cs.IR])",
    "abstract": "Contrastive learning is a powerful way of learning multimodal representations across various domains such as image-caption retrieval and audio-visual representation learning. In this work, we investigate if these findings generalize to the domain of music videos. Specifically, we create a dual en-coder for the audio and video modalities and train it using a bidirectional contrastive loss. For the experiments, we use an industry dataset containing 550 000 music videos as well as the public Million Song Dataset, and evaluate the quality of learned representations on the downstream tasks of music tagging and genre classification. Our results indicate that pre-trained networks without contrastive fine-tuning outperform our contrastive learning approach when evaluated on both tasks. To gain a better understanding of the reasons contrastive learning was not successful for music videos, we perform a qualitative analysis of the learned representations, revealing why contrastive learning might ",
    "link": "http://arxiv.org/abs/2309.00347",
    "context": "Title: Towards Contrastive Learning in Music Video Domain. (arXiv:2309.00347v1 [cs.IR])\nAbstract: Contrastive learning is a powerful way of learning multimodal representations across various domains such as image-caption retrieval and audio-visual representation learning. In this work, we investigate if these findings generalize to the domain of music videos. Specifically, we create a dual en-coder for the audio and video modalities and train it using a bidirectional contrastive loss. For the experiments, we use an industry dataset containing 550 000 music videos as well as the public Million Song Dataset, and evaluate the quality of learned representations on the downstream tasks of music tagging and genre classification. Our results indicate that pre-trained networks without contrastive fine-tuning outperform our contrastive learning approach when evaluated on both tasks. To gain a better understanding of the reasons contrastive learning was not successful for music videos, we perform a qualitative analysis of the learned representations, revealing why contrastive learning might ",
    "path": "papers/23/09/2309.00347.json",
    "total_tokens": 969,
    "translated_title": "面向音乐视频领域的对比学习",
    "translated_abstract": "对比学习是一种学习多模态表示的强大方法，可以应用于图像-文本检索、音频-视觉表示学习等各种领域。在本文中，我们研究了这些发现在音乐视频领域是否适用。具体而言，我们为音频和视频模态创建了一个双向编码器，并使用双向对比损失进行训练。在实验中，我们使用了包含55万个音乐视频的工业数据集以及公共的百万歌曲数据集，并在音乐标签和流派分类的下游任务上评估了学习表示的质量。我们的结果表明，当在两个任务上评估时，无对比微调的预训练网络优于我们的对比学习方法。为了更好地理解对比学习在音乐视频中失败的原因，我们对学习表示进行了定性分析，揭示了为什么对比学习可能不适合音乐视频。",
    "tldr": "本研究探究了对比学习在音乐视频领域的应用，通过创建音频和视频模态的双向编码器并采用对比损失进行训练。研究结果表明，在音乐标签和流派分类任务中，与无对比微调的预训练网络相比，对比学习方法并不显示出优势。通过对学习表示进行定性分析，揭示了对比学习在音乐视频中可能不适用的原因。",
    "en_tdlr": "This study investigates the application of contrastive learning in the domain of music videos, training a dual encoder for audio and video modalities using a bidirectional contrastive loss. The results indicate that contrastive learning does not outperform pre-trained networks without fine-tuning when evaluated on music tagging and genre classification tasks. A qualitative analysis of the learned representations reveals the possible reasons why contrastive learning may not be suitable for music videos."
}