{
    "title": "Privacy Preserving Machine Learning for Behavioral Authentication Systems. (arXiv:2309.13046v1 [cs.IR])",
    "abstract": "A behavioral authentication (BA) system uses the behavioral characteristics of users to verify their identity claims. A BA verification algorithm can be constructed by training a neural network (NN) classifier on users' profiles. The trained NN model classifies the presented verification data, and if the classification matches the claimed identity, the verification algorithm accepts the claim. This classification-based approach removes the need to maintain a profile database. However, similar to other NN architectures, the NN classifier of the BA system is vulnerable to privacy attacks. To protect the privacy of training and test data used in an NN different techniques are widely used. In this paper, our focus is on a non-crypto-based approach, and we used random projection (RP) to ensure data privacy in an NN model. RP is a distance-preserving transformation based on a random matrix. Before sharing the profiles with the verifier, users will transform their profiles by RP and keep thei",
    "link": "http://arxiv.org/abs/2309.13046",
    "context": "Title: Privacy Preserving Machine Learning for Behavioral Authentication Systems. (arXiv:2309.13046v1 [cs.IR])\nAbstract: A behavioral authentication (BA) system uses the behavioral characteristics of users to verify their identity claims. A BA verification algorithm can be constructed by training a neural network (NN) classifier on users' profiles. The trained NN model classifies the presented verification data, and if the classification matches the claimed identity, the verification algorithm accepts the claim. This classification-based approach removes the need to maintain a profile database. However, similar to other NN architectures, the NN classifier of the BA system is vulnerable to privacy attacks. To protect the privacy of training and test data used in an NN different techniques are widely used. In this paper, our focus is on a non-crypto-based approach, and we used random projection (RP) to ensure data privacy in an NN model. RP is a distance-preserving transformation based on a random matrix. Before sharing the profiles with the verifier, users will transform their profiles by RP and keep thei",
    "path": "papers/23/09/2309.13046.json",
    "total_tokens": 898,
    "translated_title": "针对行为认证系统的隐私保护机器学习",
    "translated_abstract": "行为认证系统使用用户的行为特征来验证其身份。通过在用户个人资料上训练神经网络分类器，可以构建一个行为认证验证算法。训练好的神经网络模型对呈现的验证数据进行分类，如果分类结果与声明的身份匹配，则接受该声明。这种基于分类的方法消除了维护个人资料数据库的需求。然而，类似于其他神经网络结构，行为认证系统的神经网络分类器容易受到隐私攻击。为了保护神经网络中使用的训练和测试数据的隐私，广泛使用各种不同的技术。本文主要关注一种非加密的方法，我们使用随机投影来确保神经网络模型中的数据隐私。随机投影是一种基于随机矩阵的距离保持转换。在与验证者共享个人资料之前，用户将通过随机投影对其个人资料进行转换，并保持其隐私性。",
    "tldr": "本文研究了针对行为认证系统的隐私保护机器学习。我们使用随机投影技术来确保神经网络模型中的数据隐私，以防止隐私攻击。这种方法可以消除个人资料数据库的需求，并能有效验证用户的身份。",
    "en_tdlr": "This paper investigates privacy-preserving machine learning for behavioral authentication systems. Random projection technique is used to protect data privacy in the neural network model, preventing privacy attacks. This approach eliminates the need for a profile database and enables efficient verification of user identity."
}