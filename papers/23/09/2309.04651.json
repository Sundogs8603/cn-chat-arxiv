{
    "title": "Video and Synthetic MRI Pre-training of 3D Vision Architectures for Neuroimage Analysis. (arXiv:2309.04651v1 [eess.IV])",
    "abstract": "Transfer learning represents a recent paradigm shift in the way we build artificial intelligence (AI) systems. In contrast to training task-specific models, transfer learning involves pre-training deep learning models on a large corpus of data and minimally fine-tuning them for adaptation to specific tasks. Even so, for 3D medical imaging tasks, we do not know if it is best to pre-train models on natural images, medical images, or even synthetically generated MRI scans or video data. To evaluate these alternatives, here we benchmarked vision transformers (ViTs) and convolutional neural networks (CNNs), initialized with varied upstream pre-training approaches. These methods were then adapted to three unique downstream neuroimaging tasks with a range of difficulty: Alzheimer's disease (AD) and Parkinson's disease (PD) classification, \"brain age\" prediction. Experimental tests led to the following key observations: 1. Pre-training improved performance across all tasks including a boost of",
    "link": "http://arxiv.org/abs/2309.04651",
    "context": "Title: Video and Synthetic MRI Pre-training of 3D Vision Architectures for Neuroimage Analysis. (arXiv:2309.04651v1 [eess.IV])\nAbstract: Transfer learning represents a recent paradigm shift in the way we build artificial intelligence (AI) systems. In contrast to training task-specific models, transfer learning involves pre-training deep learning models on a large corpus of data and minimally fine-tuning them for adaptation to specific tasks. Even so, for 3D medical imaging tasks, we do not know if it is best to pre-train models on natural images, medical images, or even synthetically generated MRI scans or video data. To evaluate these alternatives, here we benchmarked vision transformers (ViTs) and convolutional neural networks (CNNs), initialized with varied upstream pre-training approaches. These methods were then adapted to three unique downstream neuroimaging tasks with a range of difficulty: Alzheimer's disease (AD) and Parkinson's disease (PD) classification, \"brain age\" prediction. Experimental tests led to the following key observations: 1. Pre-training improved performance across all tasks including a boost of",
    "path": "papers/23/09/2309.04651.json",
    "total_tokens": 902,
    "translated_title": "视频和合成磁共振成像预训练的3D视觉架构用于神经影像分析",
    "translated_abstract": "转移学习代表了我们构建人工智能系统的一种最新范式转变。与训练特定任务的模型不同，转移学习涉及在大型数据集上预训练深度学习模型，然后最小限度地微调它们以适应特定任务。然而，对于3D医学影像任务，我们不知道最佳的预训练方法是在自然图像、医学图像还是合成的MRI扫描或视频数据上。为了评估这些替代方法，我们在具有不同上游预训练方法的视觉转换器（ViTs）和卷积神经网络（CNNs）上进行了基准测试，并将其适应于三个独特的下游神经影像任务，难易程度各异：阿尔茨海默病（AD）和帕金森病（PD）分类，“脑龄”预测。实验测试得出以下重要观察结果：1.预训练改善了所有任务的性能，包括一个提升.",
    "tldr": "本研究评估了不同的预训练方法对于3D医学影像任务的适用性，并发现预训练在改善任务性能方面具有积极影响。",
    "en_tdlr": "This study evaluates the suitability of different pre-training methods for 3D medical imaging tasks and finds that pre-training has a positive impact on improving task performance."
}