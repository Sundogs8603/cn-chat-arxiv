{
    "title": "Efficient Interpretable Nonlinear Modeling for Multiple Time Series. (arXiv:2309.17154v1 [cs.LG])",
    "abstract": "Predictive linear and nonlinear models based on kernel machines or deep neural networks have been used to discover dependencies among time series. This paper proposes an efficient nonlinear modeling approach for multiple time series, with a complexity comparable to linear vector autoregressive (VAR) models while still incorporating nonlinear interactions among different time-series variables. The modeling assumption is that the set of time series is generated in two steps: first, a linear VAR process in a latent space, and second, a set of invertible and Lipschitz continuous nonlinear mappings that are applied per sensor, that is, a component-wise mapping from each latent variable to a variable in the measurement space. The VAR coefficient identification provides a topology representation of the dependencies among the aforementioned variables. The proposed approach models each component-wise nonlinearity using an invertible neural network and imposes sparsity on the VAR coefficients to",
    "link": "http://arxiv.org/abs/2309.17154",
    "context": "Title: Efficient Interpretable Nonlinear Modeling for Multiple Time Series. (arXiv:2309.17154v1 [cs.LG])\nAbstract: Predictive linear and nonlinear models based on kernel machines or deep neural networks have been used to discover dependencies among time series. This paper proposes an efficient nonlinear modeling approach for multiple time series, with a complexity comparable to linear vector autoregressive (VAR) models while still incorporating nonlinear interactions among different time-series variables. The modeling assumption is that the set of time series is generated in two steps: first, a linear VAR process in a latent space, and second, a set of invertible and Lipschitz continuous nonlinear mappings that are applied per sensor, that is, a component-wise mapping from each latent variable to a variable in the measurement space. The VAR coefficient identification provides a topology representation of the dependencies among the aforementioned variables. The proposed approach models each component-wise nonlinearity using an invertible neural network and imposes sparsity on the VAR coefficients to",
    "path": "papers/23/09/2309.17154.json",
    "total_tokens": 794,
    "translated_title": "高效可解释多时间序列非线性建模",
    "translated_abstract": "本文提出了一种高效的非线性建模方法，用于多时间序列，其复杂度与线性向量自回归（VAR）模型相当，同时还考虑了不同时间序列变量之间的非线性相互作用。该方法假设时间序列集合是在两个步骤中生成的：首先是在潜在空间中的线性VAR过程，然后是一组可逆且Lipschitz连续的非线性映射，这些映射应用于每个传感器，即从每个潜在变量到测量空间中的变量的分量映射。VAR系数识别提供了所述变量之间依赖关系的拓扑表示。所提出的方法使用可逆神经网络对每个分量的非线性进行建模，并对VAR系数施加稀疏性。",
    "tldr": "本文提出了一种高效的非线性建模方法，用于多时间序列，其将线性VAR过程和可逆神经网络相结合，以实现对多变量之间的非线性依赖关系进行建模。",
    "en_tdlr": "This paper proposes an efficient nonlinear modeling approach for multiple time series, which combines linear VAR process with invertible neural networks to model the nonlinear dependencies among multiple variables."
}