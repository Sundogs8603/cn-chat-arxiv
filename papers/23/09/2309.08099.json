{
    "title": "Characterizing the temporal dynamics of universal speech representations for generalizable deepfake detection. (arXiv:2309.08099v1 [cs.SD])",
    "abstract": "Existing deepfake speech detection systems lack generalizability to unseen attacks (i.e., samples generated by generative algorithms not seen during training). Recent studies have explored the use of universal speech representations to tackle this issue and have obtained inspiring results. These works, however, have focused on innovating downstream classifiers while leaving the representation itself untouched. In this study, we argue that characterizing the long-term temporal dynamics of these representations is crucial for generalizability and propose a new method to assess representation dynamics. Indeed, we show that different generative models generate similar representation dynamics patterns with our proposed method. Experiments on the ASVspoof 2019 and 2021 datasets validate the benefits of the proposed method to detect deepfakes from methods unseen during training, significantly improving on several benchmark methods.",
    "link": "http://arxiv.org/abs/2309.08099",
    "context": "Title: Characterizing the temporal dynamics of universal speech representations for generalizable deepfake detection. (arXiv:2309.08099v1 [cs.SD])\nAbstract: Existing deepfake speech detection systems lack generalizability to unseen attacks (i.e., samples generated by generative algorithms not seen during training). Recent studies have explored the use of universal speech representations to tackle this issue and have obtained inspiring results. These works, however, have focused on innovating downstream classifiers while leaving the representation itself untouched. In this study, we argue that characterizing the long-term temporal dynamics of these representations is crucial for generalizability and propose a new method to assess representation dynamics. Indeed, we show that different generative models generate similar representation dynamics patterns with our proposed method. Experiments on the ASVspoof 2019 and 2021 datasets validate the benefits of the proposed method to detect deepfakes from methods unseen during training, significantly improving on several benchmark methods.",
    "path": "papers/23/09/2309.08099.json",
    "total_tokens": 845,
    "translated_title": "刻画通用语音表示的时序动态，实现可推广的深度伪造检测",
    "translated_abstract": "现有的深度伪造语音检测系统在面对未见过的攻击样本（即由训练中未见过的生成算法生成的样本）时缺乏可推广性。最近的研究探索了使用通用语音表示来解决这个问题，并取得了令人鼓舞的结果。然而，这些工作主要集中在创新下游分类器，而对表示本身几乎没有改进。在本研究中，我们认为揭示这些表示的长期时序动态对于提高可推广性至关重要，并提出了一种评估表示动态的新方法。实验表明，不同的生成模型在我们提出的方法下生成了类似的表示动态模式。在ASVspoof 2019和2021数据集上的实验验证了所提方法在检测训练中未见过的深度伪造方法方面的优势，并显著改进了多个基准方法。",
    "tldr": "本研究刻画了通用语音表示的时序动态，提出了一种评估表示动态的新方法，该方法能够提高深度伪造检测的可推广性并在实验中取得了显著改进。",
    "en_tdlr": "This study characterizes the temporal dynamics of universal speech representations and proposes a new method to assess representation dynamics, which improves the generalizability of deepfake detection and achieves significant improvements in experiments."
}