{
    "title": "Data Augmentation via Subgroup Mixup for Improving Fairness. (arXiv:2309.07110v1 [stat.ML])",
    "abstract": "In this work, we propose data augmentation via pairwise mixup across subgroups to improve group fairness. Many real-world applications of machine learning systems exhibit biases across certain groups due to under-representation or training data that reflects societal biases. Inspired by the successes of mixup for improving classification performance, we develop a pairwise mixup scheme to augment training data and encourage fair and accurate decision boundaries for all subgroups. Data augmentation for group fairness allows us to add new samples of underrepresented groups to balance subpopulations. Furthermore, our method allows us to use the generalization ability of mixup to improve both fairness and accuracy. We compare our proposed mixup to existing data augmentation and bias mitigation approaches on both synthetic simulations and real-world benchmark fair classification data, demonstrating that we are able to achieve fair outcomes with robust if not improved accuracy.",
    "link": "http://arxiv.org/abs/2309.07110",
    "context": "Title: Data Augmentation via Subgroup Mixup for Improving Fairness. (arXiv:2309.07110v1 [stat.ML])\nAbstract: In this work, we propose data augmentation via pairwise mixup across subgroups to improve group fairness. Many real-world applications of machine learning systems exhibit biases across certain groups due to under-representation or training data that reflects societal biases. Inspired by the successes of mixup for improving classification performance, we develop a pairwise mixup scheme to augment training data and encourage fair and accurate decision boundaries for all subgroups. Data augmentation for group fairness allows us to add new samples of underrepresented groups to balance subpopulations. Furthermore, our method allows us to use the generalization ability of mixup to improve both fairness and accuracy. We compare our proposed mixup to existing data augmentation and bias mitigation approaches on both synthetic simulations and real-world benchmark fair classification data, demonstrating that we are able to achieve fair outcomes with robust if not improved accuracy.",
    "path": "papers/23/09/2309.07110.json",
    "total_tokens": 904,
    "translated_title": "通过子组混合实现数据增强以提高公平性",
    "translated_abstract": "在这项工作中，我们提出了通过子组间混合来增强数据以提高群体公平性。许多现实世界中的机器学习系统应用都存在着某些群体的偏见，这是由于训练数据的不平衡或反映了社会偏见。受到mixup在提高分类性能方面的成功启发，我们开发了一种对数据进行两两混合的方案，以增强训练数据，并鼓励为所有子组实现公平和准确的决策边界。针对群体公平性进行数据增强允许我们添加新的代表低比例群体的样本，以平衡亚群体。此外，我们的方法允许我们利用mixup的泛化能力来提高公平性和准确性。我们将我们提出的混合方法与现有的数据增强和偏见缓解方法在合成模拟和实际基准公平分类数据上进行比较，结果表明我们能够实现公平的结果，并且在准确性上具有鲁棒性，甚至有所提高。",
    "tldr": "本论文提出了一种通过子组混合的数据增强方法，以提高机器学习系统的群体公平性。通过添加代表低比例群体的新样本，我们可以实现数据的平衡，并且利用该方法提高公平性和准确性。",
    "en_tdlr": "This paper proposes a data augmentation method using subgroup mixup to improve group fairness in machine learning systems. By adding new samples representing underrepresented groups, the data can be balanced and fairness and accuracy can be improved using this method."
}