{
    "title": "Unleashing Potential of Evidence in Knowledge-Intensive Dialogue Generation. (arXiv:2309.08380v1 [cs.CL])",
    "abstract": "Incorporating external knowledge into dialogue generation (KIDG) is crucial for improving the correctness of response, where evidence fragments serve as knowledgeable snippets supporting the factual dialogue replies. However, introducing irrelevant content often adversely impacts reply quality and easily leads to hallucinated responses. Prior work on evidence retrieval and integration in dialogue systems falls short of fully leveraging existing evidence since the model fails to locate useful fragments accurately and overlooks hidden evidence labels within the KIDG dataset. To fully Unleash the potential of evidence, we propose a framework to effectively incorporate Evidence in knowledge-Intensive Dialogue Generation (u-EIDG). Specifically, we introduce an automatic evidence generation framework that harnesses the power of Large Language Models (LLMs) to mine reliable evidence veracity labels from unlabeled data. By utilizing these evidence labels, we train a reliable evidence indicator",
    "link": "http://arxiv.org/abs/2309.08380",
    "context": "Title: Unleashing Potential of Evidence in Knowledge-Intensive Dialogue Generation. (arXiv:2309.08380v1 [cs.CL])\nAbstract: Incorporating external knowledge into dialogue generation (KIDG) is crucial for improving the correctness of response, where evidence fragments serve as knowledgeable snippets supporting the factual dialogue replies. However, introducing irrelevant content often adversely impacts reply quality and easily leads to hallucinated responses. Prior work on evidence retrieval and integration in dialogue systems falls short of fully leveraging existing evidence since the model fails to locate useful fragments accurately and overlooks hidden evidence labels within the KIDG dataset. To fully Unleash the potential of evidence, we propose a framework to effectively incorporate Evidence in knowledge-Intensive Dialogue Generation (u-EIDG). Specifically, we introduce an automatic evidence generation framework that harnesses the power of Large Language Models (LLMs) to mine reliable evidence veracity labels from unlabeled data. By utilizing these evidence labels, we train a reliable evidence indicator",
    "path": "papers/23/09/2309.08380.json",
    "total_tokens": 887,
    "translated_title": "发掘知识密集型对话生成中证据的潜力",
    "translated_abstract": "将外部知识纳入对话生成的过程对于提高回答的准确性至关重要，其中证据片段作为知识性的支撑支持对话回复的事实。然而，引入无关内容往往会对回复质量产生负面影响，并容易导致虚构的回应。先前关于证据检索与整合的对话系统的工作没有充分利用现有证据，因为模型无法准确地定位有用的片段，并忽视了KIDG数据集中的隐藏证据标签。为了充分发掘证据的潜力，我们提出了一个有效地将证据纳入知识密集型对话生成中的框架（u-EIDG）。具体而言，我们引入了一个自动证据生成的框架，利用大型语言模型（LLMs）的强大能力从无标签数据中挖掘可靠的证据真实性标签。通过利用这些证据标签，我们训练了一个可靠的证据指示器。",
    "tldr": "本研究提出了一种有效地将证据纳入知识密集型对话生成的框架 (u-EIDG)，通过引入自动证据生成框架，从无标签数据中挖掘可靠的证据真实性标签，以提高对话回答的准确性。",
    "en_tdlr": "This study proposes a framework (u-EIDG) to effectively incorporate evidence into knowledge-intensive dialogue generation by introducing an automatic evidence generation framework to mine reliable evidence veracity labels from unlabeled data, aiming to improve the accuracy of dialogue responses."
}