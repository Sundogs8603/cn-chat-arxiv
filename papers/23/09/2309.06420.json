{
    "title": "Verifiable Reinforcement Learning Systems via Compositionality. (arXiv:2309.06420v1 [eess.SY])",
    "abstract": "We propose a framework for verifiable and compositional reinforcement learning (RL) in which a collection of RL subsystems, each of which learns to accomplish a separate subtask, are composed to achieve an overall task. The framework consists of a high-level model, represented as a parametric Markov decision process, which is used to plan and analyze compositions of subsystems, and of the collection of low-level subsystems themselves. The subsystems are implemented as deep RL agents operating under partial observability. By defining interfaces between the subsystems, the framework enables automatic decompositions of task specifications, e.g., reach a target set of states with a probability of at least 0.95, into individual subtask specifications, i.e. achieve the subsystem's exit conditions with at least some minimum probability, given that its entry conditions are met. This in turn allows for the independent training and testing of the subsystems. We present theoretical results guaran",
    "link": "http://arxiv.org/abs/2309.06420",
    "context": "Title: Verifiable Reinforcement Learning Systems via Compositionality. (arXiv:2309.06420v1 [eess.SY])\nAbstract: We propose a framework for verifiable and compositional reinforcement learning (RL) in which a collection of RL subsystems, each of which learns to accomplish a separate subtask, are composed to achieve an overall task. The framework consists of a high-level model, represented as a parametric Markov decision process, which is used to plan and analyze compositions of subsystems, and of the collection of low-level subsystems themselves. The subsystems are implemented as deep RL agents operating under partial observability. By defining interfaces between the subsystems, the framework enables automatic decompositions of task specifications, e.g., reach a target set of states with a probability of at least 0.95, into individual subtask specifications, i.e. achieve the subsystem's exit conditions with at least some minimum probability, given that its entry conditions are met. This in turn allows for the independent training and testing of the subsystems. We present theoretical results guaran",
    "path": "papers/23/09/2309.06420.json",
    "total_tokens": 804,
    "translated_title": "可验证的组合强化学习系统",
    "translated_abstract": "我们提出了一个可验证和组合的强化学习（RL）框架，其中一组RL子系统被组合在一起以完成一个整体任务。该框架由一个高级模型和一组低级子系统组成。高级模型作为参数化的马尔可夫决策过程用于规划和分析子系统的组合，而低级子系统则作为部分可观测性下操作的深度RL代理实现。通过定义子系统之间的接口，该框架能够自动分解任务规范成独立的子任务规范，并允许子系统的独立训练和测试。我们提出了理论结果保证了",
    "tldr": "本研究提出了一个可验证和组合的强化学习框架，通过将多个强化学习子系统组合起来实现整体任务。通过定义子系统之间的接口，实现了任务规范的自动分解，并允许子系统的独立训练和测试。",
    "en_tdlr": "This research proposes a verifiable and compositional reinforcement learning framework by combining multiple reinforcement learning subsystems to achieve an overall task. By defining interfaces between subsystems, the framework enables automatic decomposition of task specifications and allows for independent training and testing of subsystems."
}