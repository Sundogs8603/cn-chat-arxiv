{
    "title": "Big model only for hard audios: Sample dependent Whisper model selection for efficient inferences. (arXiv:2309.12712v1 [eess.AS])",
    "abstract": "Recent progress in Automatic Speech Recognition (ASR) has been coupled with a substantial increase in the model sizes, which may now contain billions of parameters, leading to slow inferences even with adapted hardware. In this context, several ASR models exist in various sizes, with different inference costs leading to different performance levels. Based on the observation that smaller models perform optimally on large parts of testing corpora, we propose to train a decision module, that would allow, given an audio sample, to use the smallest sufficient model leading to a good transcription. We apply our approach to two Whisper models with different sizes. By keeping the decision process computationally efficient, we build a decision module that allows substantial computational savings with reduced performance drops.",
    "link": "http://arxiv.org/abs/2309.12712",
    "context": "Title: Big model only for hard audios: Sample dependent Whisper model selection for efficient inferences. (arXiv:2309.12712v1 [eess.AS])\nAbstract: Recent progress in Automatic Speech Recognition (ASR) has been coupled with a substantial increase in the model sizes, which may now contain billions of parameters, leading to slow inferences even with adapted hardware. In this context, several ASR models exist in various sizes, with different inference costs leading to different performance levels. Based on the observation that smaller models perform optimally on large parts of testing corpora, we propose to train a decision module, that would allow, given an audio sample, to use the smallest sufficient model leading to a good transcription. We apply our approach to two Whisper models with different sizes. By keeping the decision process computationally efficient, we build a decision module that allows substantial computational savings with reduced performance drops.",
    "path": "papers/23/09/2309.12712.json",
    "total_tokens": 769,
    "translated_title": "只针对困难音频的大型模型：基于样本依赖的Whisper模型选择用于高效的推断",
    "translated_abstract": "自动语音识别（ASR）领域的最新进展已经伴随着模型大小的大幅增加，现在可能包含数十亿个参数，即使在适应的硬件上也会导致推断速度缓慢。在这种情况下，存在不同大小、推断成本不同导致性能水平不同的ASR模型。基于一个观察结果，即较小的模型在大部分测试语料库上表现最佳，我们提出训练一个决策模块，可以根据音频样本使用最小的足够模型来获得良好的转录。我们将我们的方法应用于两个不同大小的Whisper模型。通过保持决策过程的计算效率，我们构建了一个决策模块，可以在减小性能损失的同时实现大幅度的计算节约。",
    "tldr": "提出了一个决策模块来选择最小的足够模型用于音频转录，可以实现大幅度的计算节约。"
}