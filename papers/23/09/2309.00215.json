{
    "title": "Towards Addressing the Misalignment of Object Proposal Evaluation for Vision-Language Tasks via Semantic Grounding. (arXiv:2309.00215v1 [cs.CV])",
    "abstract": "Object proposal generation serves as a standard pre-processing step in Vision-Language (VL) tasks (image captioning, visual question answering, etc.). The performance of object proposals generated for VL tasks is currently evaluated across all available annotations, a protocol that we show is misaligned - higher scores do not necessarily correspond to improved performance on downstream VL tasks. Our work serves as a study of this phenomenon and explores the effectiveness of semantic grounding to mitigate its effects. To this end, we propose evaluating object proposals against only a subset of available annotations, selected by thresholding an annotation importance score. Importance of object annotations to VL tasks is quantified by extracting relevant semantic information from text describing the image. We show that our method is consistent and demonstrates greatly improved alignment with annotations selected by image captioning metrics and human annotation when compared against existi",
    "link": "http://arxiv.org/abs/2309.00215",
    "context": "Title: Towards Addressing the Misalignment of Object Proposal Evaluation for Vision-Language Tasks via Semantic Grounding. (arXiv:2309.00215v1 [cs.CV])\nAbstract: Object proposal generation serves as a standard pre-processing step in Vision-Language (VL) tasks (image captioning, visual question answering, etc.). The performance of object proposals generated for VL tasks is currently evaluated across all available annotations, a protocol that we show is misaligned - higher scores do not necessarily correspond to improved performance on downstream VL tasks. Our work serves as a study of this phenomenon and explores the effectiveness of semantic grounding to mitigate its effects. To this end, we propose evaluating object proposals against only a subset of available annotations, selected by thresholding an annotation importance score. Importance of object annotations to VL tasks is quantified by extracting relevant semantic information from text describing the image. We show that our method is consistent and demonstrates greatly improved alignment with annotations selected by image captioning metrics and human annotation when compared against existi",
    "path": "papers/23/09/2309.00215.json",
    "total_tokens": 891,
    "translated_title": "通过语义引地来解决视觉语言任务中对象提议评估的不对齐问题",
    "translated_abstract": "对象提议生成作为视觉语言任务（图像字幕、视觉问答等）的标准预处理步骤。目前，对于视觉语言任务生成的对象提议的性能是通过所有可用的注释进行评估的，我们发现这种评估方法存在不对齐的问题 - 更高的分数不一定对应下游视觉语言任务的改进性能。本研究探讨了语义引地的有效性以减轻这一影响，并建议仅针对一部分通过阈值选择注释重要性得分的可用注释来评估对象提议。通过从描述图像的文本中提取相关语义信息来量化对象注释对视觉语言任务的重要性。我们证明了我们的方法是一致的，并且与现有方法相比，在与图像字幕度量和人工注释选择的注释上表现出了极大的改进性对齐。",
    "tldr": "本研究通过语义引地解决了视觉语言任务中对象提议评估不对齐的问题，提出了通过阈值选择注释重要性得分来评估对象提议的方法，并证明了与现有方法相比，在与图像字幕度量和人工注释选择的注释上表现出了极大的改进性对齐。",
    "en_tdlr": "This study addresses the misalignment of object proposal evaluation for Vision-Language tasks by proposing a method to evaluate object proposals based on the importance score of annotations, which is quantified using semantic grounding. It demonstrates significant improvement in alignment with image captioning metrics and human annotation compared to existing methods."
}