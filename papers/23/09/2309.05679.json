{
    "title": "Good-looking but Lacking Faithfulness: Understanding Local Explanation Methods through Trend-based Testing. (arXiv:2309.05679v1 [cs.LG])",
    "abstract": "While enjoying the great achievements brought by deep learning (DL), people are also worried about the decision made by DL models, since the high degree of non-linearity of DL models makes the decision extremely difficult to understand. Consequently, attacks such as adversarial attacks are easy to carry out, but difficult to detect and explain, which has led to a boom in the research on local explanation methods for explaining model decisions. In this paper, we evaluate the faithfulness of explanation methods and find that traditional tests on faithfulness encounter the random dominance problem, \\ie, the random selection performs the best, especially for complex data. To further solve this problem, we propose three trend-based faithfulness tests and empirically demonstrate that the new trend tests can better assess faithfulness than traditional tests on image, natural language and security tasks. We implement the assessment system and evaluate ten popular explanation methods. Benefitin",
    "link": "http://arxiv.org/abs/2309.05679",
    "context": "Title: Good-looking but Lacking Faithfulness: Understanding Local Explanation Methods through Trend-based Testing. (arXiv:2309.05679v1 [cs.LG])\nAbstract: While enjoying the great achievements brought by deep learning (DL), people are also worried about the decision made by DL models, since the high degree of non-linearity of DL models makes the decision extremely difficult to understand. Consequently, attacks such as adversarial attacks are easy to carry out, but difficult to detect and explain, which has led to a boom in the research on local explanation methods for explaining model decisions. In this paper, we evaluate the faithfulness of explanation methods and find that traditional tests on faithfulness encounter the random dominance problem, \\ie, the random selection performs the best, especially for complex data. To further solve this problem, we propose three trend-based faithfulness tests and empirically demonstrate that the new trend tests can better assess faithfulness than traditional tests on image, natural language and security tasks. We implement the assessment system and evaluate ten popular explanation methods. Benefitin",
    "path": "papers/23/09/2309.05679.json",
    "total_tokens": 894,
    "translated_title": "外表优美但缺乏忠诚度：通过基于趋势的测试理解局部解释方法",
    "translated_abstract": "尽管深度学习（DL）带来了巨大的成就，但人们也对DL模型的决策感到担忧，因为DL模型的高度非线性使得决策极其难以理解。因此，攻击（如对抗攻击）很容易进行，但很难检测和解释，这导致了局部解释方法的研究激增，以解释模型决策。在本文中，我们评估了解释方法的忠诚度，并发现传统的忠诚度测试遇到了随机优势问题，即随机选择效果最好，尤其是对于复杂的数据。为了进一步解决这个问题，我们提出了三种基于趋势的忠诚度测试，并从实证上证明了新的趋势测试可以比传统的图像、自然语言和安全任务的测试更好地评估忠诚度。我们实现了评估系统，并评估了十种流行的解释方法。",
    "tldr": "本文通过基于趋势的测试方法评估了解释模型决策的忠诚度，并提出了三种新的趋势测试方法，从实证结果来看，这些新测试方法在图像、自然语言和安全任务中可以更好地评估解释模型的忠诚度。",
    "en_tdlr": "This paper evaluates the fidelity of explainability methods for model decisions and proposes three trend-based tests that provide better assessments of fidelity in image, natural language, and security tasks."
}