{
    "title": "An Efficient Approach to Unsupervised Out-of-Distribution Detection with Variational Autoencoders. (arXiv:2309.02084v2 [cs.LG] UPDATED)",
    "abstract": "This paper is concerned with deep generative models (DGMs) for unsupervised out-of-distribution (OOD) detection. In particular, we focus on vanilla Variational Autoencoders (VAE) that use a standard normal prior distribution for the latent variables. These models have a smaller model size, enabling faster training and inference, making them well-suited for resource-limited applications compared to more complex DGMs. We propose a novel OOD score called Error Reduction (ER) specifically designed for vanilla VAE. ER incorporate the idea of reconstructing image inputs from their lossy counterparts and takes into account the Kolmogorov complexity of the images. Experimental results on diverse datasets demonstrate the superiority of our approach over baseline methods. Our code is available at: https://github.com/ZJLAB-AMMI/VAE4OOD.",
    "link": "http://arxiv.org/abs/2309.02084",
    "context": "Title: An Efficient Approach to Unsupervised Out-of-Distribution Detection with Variational Autoencoders. (arXiv:2309.02084v2 [cs.LG] UPDATED)\nAbstract: This paper is concerned with deep generative models (DGMs) for unsupervised out-of-distribution (OOD) detection. In particular, we focus on vanilla Variational Autoencoders (VAE) that use a standard normal prior distribution for the latent variables. These models have a smaller model size, enabling faster training and inference, making them well-suited for resource-limited applications compared to more complex DGMs. We propose a novel OOD score called Error Reduction (ER) specifically designed for vanilla VAE. ER incorporate the idea of reconstructing image inputs from their lossy counterparts and takes into account the Kolmogorov complexity of the images. Experimental results on diverse datasets demonstrate the superiority of our approach over baseline methods. Our code is available at: https://github.com/ZJLAB-AMMI/VAE4OOD.",
    "path": "papers/23/09/2309.02084.json",
    "total_tokens": 855,
    "translated_title": "一种利用变分自动编码器进行无监督的离群检测的高效方法",
    "translated_abstract": "本文关注深度生成模型(DGMs)在无监督的离群检测中的应用。具体来说，我们专注于使用标准正态分布作为潜在变量的普通变分自动编码器(VAE)。这些模型具有较小的模型大小，可以更快地进行训练和推断，与更复杂的DGMs相比，使它们非常适用于资源有限的应用。我们提出了一种新的离群得分称为误差减少(ER)，专门为普通VAE设计。ER融合了从有损图像输入中重建图像的思想，并考虑了图像的科尔莫戈洛夫复杂性。对各种数据集的实验结果表明，我们的方法优于基准方法。我们的代码可在此处获取：https://github.com/ZJLAB-AMMI/VAE4OOD。",
    "tldr": "本文提出了一种利用变分自动编码器进行无监督的离群检测的高效方法，通过引入误差减少(ER)离群得分来改进普通VAE，在各种数据集上得到了优于基准方法的实验结果。",
    "en_tdlr": "This paper proposes an efficient approach to unsupervised out-of-distribution detection using variational autoencoders (VAE), where the introduced error reduction (ER) outperforms baseline methods in various datasets."
}