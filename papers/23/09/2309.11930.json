{
    "title": "Bridging the Gap: Learning Pace Synchronization for Open-World Semi-Supervised Learning. (arXiv:2309.11930v1 [cs.LG])",
    "abstract": "In open-world semi-supervised learning, a machine learning model is tasked with uncovering novel categories from unlabeled data while maintaining performance on seen categories from labeled data. The central challenge is the substantial learning gap between seen and novel categories, as the model learns the former faster due to accurate supervisory information. To address this, we introduce 1) an adaptive margin loss based on estimated class distribution, which encourages a large negative margin for samples in seen classes, to synchronize learning paces, and 2) pseudo-label contrastive clustering, which pulls together samples which are likely from the same class in the output space, to enhance novel class discovery. Our extensive evaluations on multiple datasets demonstrate that existing models still hinder novel class learning, whereas our approach strikingly balances both seen and novel classes, achieving a remarkable 3% average accuracy increase on the ImageNet dataset compared to t",
    "link": "http://arxiv.org/abs/2309.11930",
    "context": "Title: Bridging the Gap: Learning Pace Synchronization for Open-World Semi-Supervised Learning. (arXiv:2309.11930v1 [cs.LG])\nAbstract: In open-world semi-supervised learning, a machine learning model is tasked with uncovering novel categories from unlabeled data while maintaining performance on seen categories from labeled data. The central challenge is the substantial learning gap between seen and novel categories, as the model learns the former faster due to accurate supervisory information. To address this, we introduce 1) an adaptive margin loss based on estimated class distribution, which encourages a large negative margin for samples in seen classes, to synchronize learning paces, and 2) pseudo-label contrastive clustering, which pulls together samples which are likely from the same class in the output space, to enhance novel class discovery. Our extensive evaluations on multiple datasets demonstrate that existing models still hinder novel class learning, whereas our approach strikingly balances both seen and novel classes, achieving a remarkable 3% average accuracy increase on the ImageNet dataset compared to t",
    "path": "papers/23/09/2309.11930.json",
    "total_tokens": 959,
    "translated_title": "弥合差距：针对开放世界半监督学习的学习速度同步",
    "translated_abstract": "在开放世界半监督学习中，一个机器学习模型被要求从无标签数据中发现新的类别，同时在有标签数据中保持对已见类别的表现。其中的核心挑战是已见和新类别之间存在巨大的学习差距，因为由于准确的监督信息，模型学习已见类别的速度更快。为了解决这个问题，我们引入以下两个方法：1）基于估计类别分布的自适应边界损失，鼓励对已见类别样本使用较大的负边界，以同步学习速度；2）伪标签对比聚类，将可能来自同一类别的样本在输出空间中聚集在一起，增强新类别发现。我们在多个数据集上进行了广泛的评估，结果表明现有模型仍然阻碍新类别的学习，而我们的方法明显平衡了已见和新类别，与ImageNet数据集相比，平均准确率提高了3%。",
    "tldr": "本论文提出了两个方法，一个是自适应边界损失，通过调整边界来同步学习速度；另一个是伪标签对比聚类，通过聚集样本来增强新类别的发现。实验证明，该方法能够平衡已见和新类别，相比现有模型，在ImageNet数据集上提高了3%的平均准确率。",
    "en_tdlr": "This paper proposes two methods: adaptive margin loss to synchronize learning pace and pseudo-label contrastive clustering to enhance novel class discovery. Experimental results demonstrate that this approach balances both seen and novel classes, achieving a remarkable 3% average accuracy increase on the ImageNet dataset compared to existing models."
}