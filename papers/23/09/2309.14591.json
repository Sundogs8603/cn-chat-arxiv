{
    "title": "Applications of Sequential Learning for Medical Image Classification. (arXiv:2309.14591v1 [eess.IV])",
    "abstract": "Purpose: The aim of this work is to develop a neural network training framework for continual training of small amounts of medical imaging data and create heuristics to assess training in the absence of a hold-out validation or test set.  Materials and Methods: We formulated a retrospective sequential learning approach that would train and consistently update a model on mini-batches of medical images over time. We address problems that impede sequential learning such as overfitting, catastrophic forgetting, and concept drift through PyTorch convolutional neural networks (CNN) and publicly available Medical MNIST and NIH Chest X-Ray imaging datasets. We begin by comparing two methods for a sequentially trained CNN with and without base pre-training. We then transition to two methods of unique training and validation data recruitment to estimate full information extraction without overfitting. Lastly, we consider an example of real-life data that shows how our approach would see mainstre",
    "link": "http://arxiv.org/abs/2309.14591",
    "context": "Title: Applications of Sequential Learning for Medical Image Classification. (arXiv:2309.14591v1 [eess.IV])\nAbstract: Purpose: The aim of this work is to develop a neural network training framework for continual training of small amounts of medical imaging data and create heuristics to assess training in the absence of a hold-out validation or test set.  Materials and Methods: We formulated a retrospective sequential learning approach that would train and consistently update a model on mini-batches of medical images over time. We address problems that impede sequential learning such as overfitting, catastrophic forgetting, and concept drift through PyTorch convolutional neural networks (CNN) and publicly available Medical MNIST and NIH Chest X-Ray imaging datasets. We begin by comparing two methods for a sequentially trained CNN with and without base pre-training. We then transition to two methods of unique training and validation data recruitment to estimate full information extraction without overfitting. Lastly, we consider an example of real-life data that shows how our approach would see mainstre",
    "path": "papers/23/09/2309.14591.json",
    "total_tokens": 967,
    "translated_title": "应用顺序学习的医学图像分类",
    "translated_abstract": "目的：本研究的目标是开发一个神经网络训练框架，用于对少量医学图像数据进行持续训练，并创建在缺乏验证集或测试集的情况下评估训练的启发式方法。材料和方法：我们制定了一个回顾性的顺序学习方法，该方法可以随着时间的推移对医学图像的小批量进行训练和持续更新模型。我们通过PyTorch卷积神经网络（CNN）和公开可用的医学MNIST和NIH胸部X射线成像数据集来解决顺序学习中出现的过拟合、灾难性遗忘和概念漂移等问题。我们首先比较了两种顺序训练的CNN方法：有基础预训练和无基础预训练。然后，我们转向两种独特的训练和验证数据招募方法，以估计完整信息的提取而不会过拟合。最后，我们考虑了一个显示我们的方法如何看待现实生活数据的示例。",
    "tldr": "该论文介绍了一种应用顺序学习的医学图像分类方法，通过开发神经网络训练框架对少量的医学图像数据进行持续训练，并提供了评估训练的启发式方法。通过解决过拟合、灾难性遗忘和概念漂移等问题，该方法能够有效地进行医学图像分类。",
    "en_tdlr": "This paper presents an application of sequential learning for medical image classification, utilizing a neural network training framework to continually train on small amounts of medical imaging data and providing heuristics for assessing training. By addressing issues such as overfitting, catastrophic forgetting, and concept drift, the method allows for effective medical image classification."
}