{
    "title": "Analyzing the Efficacy of an LLM-Only Approach for Image-based Document Question Answering. (arXiv:2309.14389v1 [cs.CV])",
    "abstract": "Recent document question answering models consist of two key components: the vision encoder, which captures layout and visual elements in images, and a Large Language Model (LLM) that helps contextualize questions to the image and supplements them with external world knowledge to generate accurate answers. However, the relative contributions of the vision encoder and the language model in these tasks remain unclear. This is especially interesting given the effectiveness of instruction-tuned LLMs, which exhibit remarkable adaptability to new tasks. To this end, we explore the following aspects in this work: (1) The efficacy of an LLM-only approach on document question answering tasks (2) strategies for serializing textual information within document images and feeding it directly to an instruction-tuned LLM, thus bypassing the need for an explicit vision encoder (3) thorough quantitative analysis on the feasibility of such an approach. Our comprehensive analysis encompasses six diverse ",
    "link": "http://arxiv.org/abs/2309.14389",
    "context": "Title: Analyzing the Efficacy of an LLM-Only Approach for Image-based Document Question Answering. (arXiv:2309.14389v1 [cs.CV])\nAbstract: Recent document question answering models consist of two key components: the vision encoder, which captures layout and visual elements in images, and a Large Language Model (LLM) that helps contextualize questions to the image and supplements them with external world knowledge to generate accurate answers. However, the relative contributions of the vision encoder and the language model in these tasks remain unclear. This is especially interesting given the effectiveness of instruction-tuned LLMs, which exhibit remarkable adaptability to new tasks. To this end, we explore the following aspects in this work: (1) The efficacy of an LLM-only approach on document question answering tasks (2) strategies for serializing textual information within document images and feeding it directly to an instruction-tuned LLM, thus bypassing the need for an explicit vision encoder (3) thorough quantitative analysis on the feasibility of such an approach. Our comprehensive analysis encompasses six diverse ",
    "path": "papers/23/09/2309.14389.json",
    "total_tokens": 925,
    "translated_title": "分析仅使用LLM方法在基于图像的文档问答中的有效性",
    "translated_abstract": "最近的文档问答模型由两个关键组件组成：视觉编码器，用于捕获图像中的布局和视觉元素，以及一个大型语言模型（LLM），帮助将问题与图像进行语境化，并通过外部世界知识补充以生成准确的答案。然而，这些任务中视觉编码器和语言模型的相对贡献仍不清楚。考虑到针对指令调整的LLM的有效性，这尤其有趣，因为它们表现出对新任务的卓越适应性。为此，我们在这项工作中探索以下方面：（1）仅使用LLM方法在文档问答任务中的有效性、（2）在文档图像中序列化文本信息并直接将其馈送给指令调整的LLM，从而绕过显式视觉编码器的需要、（3）对这种方法的可行性进行彻底的定量分析。我们的综合分析涵盖了六个不同的场景。",
    "tldr": "本论文分析了仅使用LLM方法在基于图像的文档问答中的有效性，探讨了在文档图像中序列化文本信息并直接使用指令调整的LLM的策略，以及对这种方法的可行性进行了全面的定量分析。",
    "en_tdlr": "This paper analyzes the efficacy of an LLM-only approach for image-based document question answering, explores strategies for serializing textual information within document images and feeding it directly to an instruction-tuned LLM, and provides a comprehensive quantitative analysis on the feasibility of such an approach."
}