{
    "title": "Efficient Biologically Plausible Adversarial Training. (arXiv:2309.17348v1 [cs.LG])",
    "abstract": "Artificial Neural Networks (ANNs) trained with Backpropagation (BP) show astounding performance and are increasingly often used in performing our daily life tasks. However, ANNs are highly vulnerable to adversarial attacks, which alter inputs with small targeted perturbations that drastically disrupt the models' performance. The most effective method to make ANNs robust against these attacks is adversarial training, in which the training dataset is augmented with exemplary adversarial samples. Unfortunately, this approach has the drawback of increased training complexity since generating adversarial samples is very computationally demanding. In contrast to ANNs, humans are not susceptible to adversarial attacks. Therefore, in this work, we investigate whether biologically-plausible learning algorithms are more robust against adversarial attacks than BP. In particular, we present an extensive comparative analysis of the adversarial robustness of BP and \\textit{Present the Error to Pertu",
    "link": "http://arxiv.org/abs/2309.17348",
    "context": "Title: Efficient Biologically Plausible Adversarial Training. (arXiv:2309.17348v1 [cs.LG])\nAbstract: Artificial Neural Networks (ANNs) trained with Backpropagation (BP) show astounding performance and are increasingly often used in performing our daily life tasks. However, ANNs are highly vulnerable to adversarial attacks, which alter inputs with small targeted perturbations that drastically disrupt the models' performance. The most effective method to make ANNs robust against these attacks is adversarial training, in which the training dataset is augmented with exemplary adversarial samples. Unfortunately, this approach has the drawback of increased training complexity since generating adversarial samples is very computationally demanding. In contrast to ANNs, humans are not susceptible to adversarial attacks. Therefore, in this work, we investigate whether biologically-plausible learning algorithms are more robust against adversarial attacks than BP. In particular, we present an extensive comparative analysis of the adversarial robustness of BP and \\textit{Present the Error to Pertu",
    "path": "papers/23/09/2309.17348.json",
    "total_tokens": 860,
    "translated_title": "高效的生物合理对抗训练",
    "translated_abstract": "用反向传播训练的人工神经网络(ANNs)表现出令人惊讶的性能，并且越来越多地被用于执行我们日常生活中的任务。然而，ANNs极易受到对抗攻击的影响，这些攻击通过微小的有针对性的扰动来改变输入，从而严重破坏模型的性能。使ANNs对这些攻击具有鲁棒性最有效的方法是对抗训练，其中训练数据集被添加了样本用于对抗攻击。不幸的是，这种方法的缺点是增加了训练复杂性，因为生成对抗样本是非常计算消耗高的。与ANNs不同，人类不容易受到对抗攻击的影响。因此，在这项工作中，我们研究了生物合理的学习算法是否比BP更具有对抗攻击的鲁棒性。具体而言，我们对BP和“Error to Pertu\"的对抗鲁棒性进行了广泛的比较分析。",
    "tldr": "本文研究了生物合理的学习算法是否比反向传播更具有对抗攻击的鲁棒性，并进行了广泛的比较分析。",
    "en_tdlr": "This paper investigates whether biologically-plausible learning algorithms are more robust against adversarial attacks than Backpropagation, and presents an extensive comparative analysis."
}