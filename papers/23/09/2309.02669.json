{
    "title": "Marketing Budget Allocation with Offline Constrained Deep Reinforcement Learning. (arXiv:2309.02669v1 [cs.LG])",
    "abstract": "We study the budget allocation problem in online marketing campaigns that utilize previously collected offline data. We first discuss the long-term effect of optimizing marketing budget allocation decisions in the offline setting. To overcome the challenge, we propose a novel game-theoretic offline value-based reinforcement learning method using mixed policies. The proposed method reduces the need to store infinitely many policies in previous methods to only constantly many policies, which achieves nearly optimal policy efficiency, making it practical and favorable for industrial usage. We further show that this method is guaranteed to converge to the optimal policy, which cannot be achieved by previous value-based reinforcement learning methods for marketing budget allocation. Our experiments on a large-scale marketing campaign with tens-of-millions users and more than one billion budget verify the theoretical results and show that the proposed method outperforms various baseline meth",
    "link": "http://arxiv.org/abs/2309.02669",
    "context": "Title: Marketing Budget Allocation with Offline Constrained Deep Reinforcement Learning. (arXiv:2309.02669v1 [cs.LG])\nAbstract: We study the budget allocation problem in online marketing campaigns that utilize previously collected offline data. We first discuss the long-term effect of optimizing marketing budget allocation decisions in the offline setting. To overcome the challenge, we propose a novel game-theoretic offline value-based reinforcement learning method using mixed policies. The proposed method reduces the need to store infinitely many policies in previous methods to only constantly many policies, which achieves nearly optimal policy efficiency, making it practical and favorable for industrial usage. We further show that this method is guaranteed to converge to the optimal policy, which cannot be achieved by previous value-based reinforcement learning methods for marketing budget allocation. Our experiments on a large-scale marketing campaign with tens-of-millions users and more than one billion budget verify the theoretical results and show that the proposed method outperforms various baseline meth",
    "path": "papers/23/09/2309.02669.json",
    "total_tokens": 858,
    "translated_title": "使用离线约束深度强化学习的营销预算分配",
    "translated_abstract": "我们研究了在利用先前收集的离线数据的在线营销活动中的预算分配问题。我们首先讨论了在离线环境中优化营销预算分配决策的长期效应。为了克服这一挑战，我们提出了一种新颖的基于混合策略的博弈论离线价值强化学习方法。该方法将以前的方法中存储无数策略减少到只有恒定的策略，实现了近乎最优的策略效率，使其对工业使用实际和有利。我们进一步展示了该方法保证收敛到最优策略，这是以前的基于价值的强化学习方法对于营销预算分配无法实现的。我们在一个规模庞大的营销活动中进行了实验，涉及数千万用户和超过十亿的预算，验证了理论结果并表明所提出的方法优于各种基线方法。",
    "tldr": "我们提出了一种基于混合策略的离线值强化学习方法，有效解决了在线营销活动中的预算分配问题。该方法实现了近乎最优的策略效率，并保证收敛到最优策略。",
    "en_tdlr": "We propose a novel offline value-based reinforcement learning method using mixed policies to solve the budget allocation problem in online marketing campaigns. Our method achieves nearly optimal policy efficiency and guarantees convergence to the optimal policy."
}