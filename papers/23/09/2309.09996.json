{
    "title": "Improving Speech Recognition for African American English With Audio Classification. (arXiv:2309.09996v1 [eess.AS])",
    "abstract": "Automatic speech recognition (ASR) systems have been shown to have large quality disparities between the language varieties they are intended or expected to recognize. One way to mitigate this is to train or fine-tune models with more representative datasets. But this approach can be hindered by limited in-domain data for training and evaluation. We propose a new way to improve the robustness of a US English short-form speech recognizer using a small amount of out-of-domain (long-form) African American English (AAE) data. We use CORAAL, YouTube and Mozilla Common Voice to train an audio classifier to approximately output whether an utterance is AAE or some other variety including Mainstream American English (MAE). By combining the classifier output with coarse geographic information, we can select a subset of utterances from a large corpus of untranscribed short-form queries for semi-supervised learning at scale. Fine-tuning on this data results in a 38.5% relative word error rate disp",
    "link": "http://arxiv.org/abs/2309.09996",
    "context": "Title: Improving Speech Recognition for African American English With Audio Classification. (arXiv:2309.09996v1 [eess.AS])\nAbstract: Automatic speech recognition (ASR) systems have been shown to have large quality disparities between the language varieties they are intended or expected to recognize. One way to mitigate this is to train or fine-tune models with more representative datasets. But this approach can be hindered by limited in-domain data for training and evaluation. We propose a new way to improve the robustness of a US English short-form speech recognizer using a small amount of out-of-domain (long-form) African American English (AAE) data. We use CORAAL, YouTube and Mozilla Common Voice to train an audio classifier to approximately output whether an utterance is AAE or some other variety including Mainstream American English (MAE). By combining the classifier output with coarse geographic information, we can select a subset of utterances from a large corpus of untranscribed short-form queries for semi-supervised learning at scale. Fine-tuning on this data results in a 38.5% relative word error rate disp",
    "path": "papers/23/09/2309.09996.json",
    "total_tokens": 895,
    "translated_title": "用音频分类改进非洲裔美国英语的语音识别",
    "translated_abstract": "自动语音识别(ASR)系统在识别不同语言变种时存在较大的质量差异。为了缓解这个问题，一种方法是使用更具代表性的数据集来训练或微调模型。但是有时候在领域内数据的数量有限，这会使该方法受到限制。我们提出了一种新的方法，利用少量领域外数据(长篇形式的非洲裔美国英语)来提高美国英语短篇语音识别器的鲁棒性。我们使用CORAAL、YouTube和Mozilla Common Voice来训练一个音频分类器，该分类器可以大致判断一句话是非洲裔美国英语还是其他变种，包括主流美国英语。通过将分类器输出与粗略的地理信息结合起来，我们可以从大量未翻译的短篇查询语料库中选择一部分语句进行半监督学习。在此数据上进行微调结果显示相对词错误率减少了38.5%。",
    "tldr": "通过使用少量非洲裔美国英语的数据，结合音频分类器和地理信息，我们提出了一种改进美国英语语音识别的方法，相对词错误率减少了38.5%。",
    "en_tdlr": "By utilizing a small amount of African American English data and combining it with an audio classifier and geographic information, we propose a method to improve speech recognition for US English, resulting in a 38.5% decrease in relative word error rate."
}