{
    "title": "MoEController: Instruction-based Arbitrary Image Manipulation with Mixture-of-Expert Controllers. (arXiv:2309.04372v1 [cs.CV])",
    "abstract": "Diffusion-model-based text-guided image generation has recently made astounding progress, producing fascinating results in open-domain image manipulation tasks. Few models, however, currently have complete zero-shot capabilities for both global and local image editing due to the complexity and diversity of image manipulation tasks. In this work, we propose a method with a mixture-of-expert (MOE) controllers to align the text-guided capacity of diffusion models with different kinds of human instructions, enabling our model to handle various open-domain image manipulation tasks with natural language instructions. First, we use large language models (ChatGPT) and conditional image synthesis models (ControlNet) to generate a large number of global image transfer dataset in addition to the instruction-based local image editing dataset. Then, using an MOE technique and task-specific adaptation training on a large-scale dataset, our conditional diffusion model can edit images globally and loc",
    "link": "http://arxiv.org/abs/2309.04372",
    "context": "Title: MoEController: Instruction-based Arbitrary Image Manipulation with Mixture-of-Expert Controllers. (arXiv:2309.04372v1 [cs.CV])\nAbstract: Diffusion-model-based text-guided image generation has recently made astounding progress, producing fascinating results in open-domain image manipulation tasks. Few models, however, currently have complete zero-shot capabilities for both global and local image editing due to the complexity and diversity of image manipulation tasks. In this work, we propose a method with a mixture-of-expert (MOE) controllers to align the text-guided capacity of diffusion models with different kinds of human instructions, enabling our model to handle various open-domain image manipulation tasks with natural language instructions. First, we use large language models (ChatGPT) and conditional image synthesis models (ControlNet) to generate a large number of global image transfer dataset in addition to the instruction-based local image editing dataset. Then, using an MOE technique and task-specific adaptation training on a large-scale dataset, our conditional diffusion model can edit images globally and loc",
    "path": "papers/23/09/2309.04372.json",
    "total_tokens": 968,
    "translated_title": "MoEController: 使用混合专家控制器的基于指令的任意图像操作",
    "translated_abstract": "最近，基于扩散模型的文本引导图像生成取得了惊人的进展，在开放域图像操作任务中产生了令人着迷的结果。 然而，由于图像操作任务的复杂性和多样性，目前很少有模型具有完全的零样本能力，既可以进行全局操作，又可以进行局部图像编辑。 在这项工作中，我们提出了一种使用混合专家控制器（MOE）的方法，将扩散模型的文本引导能力与不同类型的人类指令相对齐，使我们的模型能够使用自然语言指令处理各种开放域图像操作任务。 首先，我们使用大型语言模型（ChatGPT）和条件图像合成模型（ControlNet）生成大量全局图像转换数据集，以及基于指令的局部图像编辑数据集。 然后，使用MOE技术和任务特定的适应性训练对大规模数据集进行训练，我们的条件扩散模型可以对图像进行全局和局部编辑。",
    "tldr": "本论文提出了一种基于混合专家控制器(MoEController)的指令驱动任意图像操作方法，通过对不同类型的人类指令进行适配，使得模型能够处理各种开放域图像操作任务。使用大型语言模型和条件图像合成模型生成训练数据集，并采用MOE技术和任务特定的适应性训练对模型进行训练。",
    "en_tdlr": "This paper proposes a method called MoEController, which utilizes mixture-of-expert controllers to align diffusion models with human instructions, enabling various open-domain image manipulation tasks. The model is trained using large language models and conditional image synthesis models, and utilizes MOE technique and task-specific adaptation training."
}