{
    "title": "Bias of AI-Generated Content: An Examination of News Produced by Large Language Models. (arXiv:2309.09825v2 [cs.AI] UPDATED)",
    "abstract": "Large language models (LLMs) have the potential to transform our lives and work through the content they generate, known as AI-Generated Content (AIGC). To harness this transformation, we need to understand the limitations of LLMs. Here, we investigate the bias of AIGC produced by seven representative LLMs, including ChatGPT and LLaMA. We collect news articles from The New York Times and Reuters, both known for their dedication to provide unbiased news. We then apply each examined LLM to generate news content with headlines of these news articles as prompts, and evaluate the gender and racial biases of the AIGC produced by the LLM by comparing the AIGC and the original news articles. We further analyze the gender bias of each LLM under biased prompts by adding gender-biased messages to prompts constructed from these news headlines. Our study reveals that the AIGC produced by each examined LLM demonstrates substantial gender and racial biases. Moreover, the AIGC generated by each LLM ex",
    "link": "http://arxiv.org/abs/2309.09825",
    "context": "Title: Bias of AI-Generated Content: An Examination of News Produced by Large Language Models. (arXiv:2309.09825v2 [cs.AI] UPDATED)\nAbstract: Large language models (LLMs) have the potential to transform our lives and work through the content they generate, known as AI-Generated Content (AIGC). To harness this transformation, we need to understand the limitations of LLMs. Here, we investigate the bias of AIGC produced by seven representative LLMs, including ChatGPT and LLaMA. We collect news articles from The New York Times and Reuters, both known for their dedication to provide unbiased news. We then apply each examined LLM to generate news content with headlines of these news articles as prompts, and evaluate the gender and racial biases of the AIGC produced by the LLM by comparing the AIGC and the original news articles. We further analyze the gender bias of each LLM under biased prompts by adding gender-biased messages to prompts constructed from these news headlines. Our study reveals that the AIGC produced by each examined LLM demonstrates substantial gender and racial biases. Moreover, the AIGC generated by each LLM ex",
    "path": "papers/23/09/2309.09825.json",
    "total_tokens": 906,
    "translated_title": "AI生成内容的偏见：对大型语言模型生成的新闻的考察",
    "translated_abstract": "大型语言模型（LLM）通过生成的内容（即AI生成内容）具有改变我们生活和工作的潜力。为了利用这种转变，我们需要了解LLM的局限性。在这里，我们调查了由七种代表性LLM（包括ChatGPT和LLaMA）生成的AIGC的偏见。我们收集了《纽约时报》和路透社的新闻文章，这两家媒体以提供公正无偏的新闻而闻名。然后，我们将每个被调查的LLM应用于生成新闻内容，以这些新闻文章的标题作为提示，并通过比较AIGC与原始新闻文章来评估LLM生成的AIGC的性别和种族偏见。我们进一步分析了各个LLM在带有偏见的提示下的性别偏见，通过向从这些新闻标题构建的提示中添加性别偏见信息。我们的研究揭示了每个被调查的LLM生成的AIGC存在明显的性别和种族偏见。",
    "tldr": "这项研究调查了七个代表性大型语言模型生成的AI生成内容的偏见。研究发现这些模型生成的内容存在显著的性别和种族偏见。"
}