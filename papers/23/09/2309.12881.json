{
    "title": "Affect Recognition in Conversations Using Large Language Models. (arXiv:2309.12881v1 [cs.CL])",
    "abstract": "Affect recognition, encompassing emotions, moods, and feelings, plays a pivotal role in human communication. In the realm of conversational artificial intelligence (AI), the ability to discern and respond to human affective cues is a critical factor for creating engaging and empathetic interactions. This study delves into the capacity of large language models (LLMs) to recognise human affect in conversations, with a focus on both open-domain chit-chat dialogues and task-oriented dialogues. Leveraging three diverse datasets, namely IEMOCAP, EmoWOZ, and DAIC-WOZ, covering a spectrum of dialogues from casual conversations to clinical interviews, we evaluated and compared LLMs' performance in affect recognition. Our investigation explores the zero-shot and few-shot capabilities of LLMs through in-context learning (ICL) as well as their model capacities through task-specific fine-tuning. Additionally, this study takes into account the potential impact of automatic speech recognition (ASR) e",
    "link": "http://arxiv.org/abs/2309.12881",
    "context": "Title: Affect Recognition in Conversations Using Large Language Models. (arXiv:2309.12881v1 [cs.CL])\nAbstract: Affect recognition, encompassing emotions, moods, and feelings, plays a pivotal role in human communication. In the realm of conversational artificial intelligence (AI), the ability to discern and respond to human affective cues is a critical factor for creating engaging and empathetic interactions. This study delves into the capacity of large language models (LLMs) to recognise human affect in conversations, with a focus on both open-domain chit-chat dialogues and task-oriented dialogues. Leveraging three diverse datasets, namely IEMOCAP, EmoWOZ, and DAIC-WOZ, covering a spectrum of dialogues from casual conversations to clinical interviews, we evaluated and compared LLMs' performance in affect recognition. Our investigation explores the zero-shot and few-shot capabilities of LLMs through in-context learning (ICL) as well as their model capacities through task-specific fine-tuning. Additionally, this study takes into account the potential impact of automatic speech recognition (ASR) e",
    "path": "papers/23/09/2309.12881.json",
    "total_tokens": 967,
    "translated_title": "使用大型语言模型进行对话中的情感识别",
    "translated_abstract": "情感识别在人类交流中起着关键作用，涵盖情绪、心情和感受。在会话型人工智能领域，识别和回应人类情感线索的能力对于创建引人入胜且富有同理心的互动至关重要。本研究深入探讨了大型语言模型（LLMs）在对话中识别人类情感的能力，重点关注开放领域闲聊对话和任务导向对话。利用三个不同的数据集，包括IEMOCAP、EmoWOZ和DAIC-WOZ，涵盖了从日常对话到临床面试的不同类型对话，我们评估并比较了LLMs在情感识别方面的性能。我们的研究探讨了LLMs的零样本和少样本能力，通过上下文学习（ICL）以及任务特定微调来提高模型能力。此外，本研究还考虑了自动语音识别（ASR）的潜在影响。",
    "tldr": "本研究探讨了使用大型语言模型（LLMs）识别对话中人类情感的能力，并对开放领域闲聊对话和任务导向对话进行了评估。研究结果表明，LLMs具有零样本和少样本能力，并且通过上下文学习和任务特定微调可以提高模型性能。"
}