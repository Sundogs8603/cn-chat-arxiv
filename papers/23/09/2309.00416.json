{
    "title": "Advancing Personalized Federated Learning: Group Privacy, Fairness, and Beyond. (arXiv:2309.00416v1 [cs.LG])",
    "abstract": "Federated learning (FL) is a framework for training machine learning models in a distributed and collaborative manner. During training, a set of participating clients process their data stored locally, sharing only the model updates obtained by minimizing a cost function over their local inputs. FL was proposed as a stepping-stone towards privacy-preserving machine learning, but it has been shown vulnerable to issues such as leakage of private information, lack of personalization of the model, and the possibility of having a trained model that is fairer to some groups than to others. In this paper, we address the triadic interaction among personalization, privacy guarantees, and fairness attained by models trained within the FL framework. Differential privacy and its variants have been studied and applied as cutting-edge standards for providing formal privacy guarantees. However, clients in FL often hold very diverse datasets representing heterogeneous communities, making it important ",
    "link": "http://arxiv.org/abs/2309.00416",
    "context": "Title: Advancing Personalized Federated Learning: Group Privacy, Fairness, and Beyond. (arXiv:2309.00416v1 [cs.LG])\nAbstract: Federated learning (FL) is a framework for training machine learning models in a distributed and collaborative manner. During training, a set of participating clients process their data stored locally, sharing only the model updates obtained by minimizing a cost function over their local inputs. FL was proposed as a stepping-stone towards privacy-preserving machine learning, but it has been shown vulnerable to issues such as leakage of private information, lack of personalization of the model, and the possibility of having a trained model that is fairer to some groups than to others. In this paper, we address the triadic interaction among personalization, privacy guarantees, and fairness attained by models trained within the FL framework. Differential privacy and its variants have been studied and applied as cutting-edge standards for providing formal privacy guarantees. However, clients in FL often hold very diverse datasets representing heterogeneous communities, making it important ",
    "path": "papers/23/09/2309.00416.json",
    "total_tokens": 926,
    "translated_title": "推进个性化联邦学习：团体隐私、公平性等方面的突破",
    "translated_abstract": "联邦学习 (FL) 是一种在分布式和协作方式下训练机器学习模型的框架。在训练过程中，一组参与的客户端处理本地存储的数据，仅共享通过最小化其本地输入的成本函数获得的模型更新。FL被提出作为隐私保护机器学习的一种途径，但已被证明易受私人信息泄露、模型个性化缺失以及可能导致某些群体比其他群体更公平的训练模型等问题的影响。在本文中，我们解决了在FL框架中训练的模型在个性化、隐私保证和公平性之间的三元交互作用。差分隐私及其变体已被研究和应用为提供正式隐私保证的前沿标准。然而，FL中的客户端往往拥有非常多样化的数据集，代表着异质的社区，这使得保证公平性变得重要。",
    "tldr": "本研究在个性化、隐私保证和公平性之间解决了联邦学习模型的三元交互作用。差分隐私及其变体被应用为提供正式隐私保证的前沿标准。在多样化的数据集中寻求公平性变得重要。",
    "en_tdlr": "This paper addresses the triadic interaction among personalization, privacy guarantees, and fairness in federated learning models. Differential privacy and its variants are applied as cutting-edge standards for providing formal privacy guarantees. Seeking fairness in diverse datasets becomes crucial."
}