{
    "title": "Safe and Accelerated Deep Reinforcement Learning-based O-RAN Slicing: A Hybrid Transfer Learning Approach. (arXiv:2309.07265v1 [cs.NI])",
    "abstract": "The open radio access network (O-RAN) architecture supports intelligent network control algorithms as one of its core capabilities. Data-driven applications incorporate such algorithms to optimize radio access network (RAN) functions via RAN intelligent controllers (RICs). Deep reinforcement learning (DRL) algorithms are among the main approaches adopted in the O-RAN literature to solve dynamic radio resource management problems. However, despite the benefits introduced by the O-RAN RICs, the practical adoption of DRL algorithms in real network deployments falls behind. This is primarily due to the slow convergence and unstable performance exhibited by DRL agents upon deployment and when facing previously unseen network conditions. In this paper, we address these challenges by proposing transfer learning (TL) as a core component of the training and deployment workflows for the DRL-based closed-loop control of O-RAN functionalities. To this end, we propose and design a hybrid TL-aided a",
    "link": "http://arxiv.org/abs/2309.07265",
    "context": "Title: Safe and Accelerated Deep Reinforcement Learning-based O-RAN Slicing: A Hybrid Transfer Learning Approach. (arXiv:2309.07265v1 [cs.NI])\nAbstract: The open radio access network (O-RAN) architecture supports intelligent network control algorithms as one of its core capabilities. Data-driven applications incorporate such algorithms to optimize radio access network (RAN) functions via RAN intelligent controllers (RICs). Deep reinforcement learning (DRL) algorithms are among the main approaches adopted in the O-RAN literature to solve dynamic radio resource management problems. However, despite the benefits introduced by the O-RAN RICs, the practical adoption of DRL algorithms in real network deployments falls behind. This is primarily due to the slow convergence and unstable performance exhibited by DRL agents upon deployment and when facing previously unseen network conditions. In this paper, we address these challenges by proposing transfer learning (TL) as a core component of the training and deployment workflows for the DRL-based closed-loop control of O-RAN functionalities. To this end, we propose and design a hybrid TL-aided a",
    "path": "papers/23/09/2309.07265.json",
    "total_tokens": 886,
    "translated_title": "安全且加速的基于深度强化学习的O-RAN切片: 一种混合迁移学习方法",
    "translated_abstract": "开放无线接入网络（O-RAN）架构支持智能网络控制算法作为其核心能力之一。数据驱动应用程序利用这些算法通过无线接入网络智能控制器（RIC）来优化无线接入网络（RAN）功能。在O-RAN文献中，深度强化学习（DRL）算法是解决动态无线资源管理问题的主要方法之一。然而，尽管O-RAN RIC引入了诸多好处，但在真实网络部署中，DRL算法的实际采用却落后。这主要是因为DRL代理在部署和面对之前未见过的网络条件时收敛速度慢、性能不稳定。在本文中，我们通过将迁移学习（TL）作为O-RAN功能的DRL基于闭环控制的训练和部署流程的核心组成部分来解决这些挑战。为此，我们提出并设计了一个混合TL辅助的方法",
    "tldr": "本文提出了一种混合迁移学习方法，用于解决在O-RAN网络中使用DRL算法进行闭环控制时遇到的收敛速度慢和性能不稳定的问题。",
    "en_tdlr": "This paper proposes a hybrid transfer learning approach to address the issues of slow convergence and unstable performance when using DRL algorithms for closed-loop control in O-RAN networks."
}