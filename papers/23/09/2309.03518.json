{
    "title": "Learning Compact Compositional Embeddings via Regularized Pruning for Recommendation. (arXiv:2309.03518v1 [cs.IR])",
    "abstract": "Latent factor models are the dominant backbones of contemporary recommender systems (RSs) given their performance advantages, where a unique vector embedding with a fixed dimensionality (e.g., 128) is required to represent each entity (commonly a user/item). Due to the large number of users and items on e-commerce sites, the embedding table is arguably the least memory-efficient component of RSs. For any lightweight recommender that aims to efficiently scale with the growing size of users/items or to remain applicable in resource-constrained settings, existing solutions either reduce the number of embeddings needed via hashing, or sparsify the full embedding table to switch off selected embedding dimensions. However, as hash collision arises or embeddings become overly sparse, especially when adapting to a tighter memory budget, those lightweight recommenders inevitably have to compromise their accuracy. To this end, we propose a novel compact embedding framework for RSs, namely Compos",
    "link": "http://arxiv.org/abs/2309.03518",
    "context": "Title: Learning Compact Compositional Embeddings via Regularized Pruning for Recommendation. (arXiv:2309.03518v1 [cs.IR])\nAbstract: Latent factor models are the dominant backbones of contemporary recommender systems (RSs) given their performance advantages, where a unique vector embedding with a fixed dimensionality (e.g., 128) is required to represent each entity (commonly a user/item). Due to the large number of users and items on e-commerce sites, the embedding table is arguably the least memory-efficient component of RSs. For any lightweight recommender that aims to efficiently scale with the growing size of users/items or to remain applicable in resource-constrained settings, existing solutions either reduce the number of embeddings needed via hashing, or sparsify the full embedding table to switch off selected embedding dimensions. However, as hash collision arises or embeddings become overly sparse, especially when adapting to a tighter memory budget, those lightweight recommenders inevitably have to compromise their accuracy. To this end, we propose a novel compact embedding framework for RSs, namely Compos",
    "path": "papers/23/09/2309.03518.json",
    "total_tokens": 943,
    "translated_title": "通过正则化修剪来学习紧凑的组合嵌入以用于推荐",
    "translated_abstract": "潜在因素模型是当代推荐系统的主要支柱，由于它们的性能优势，在这些模型中，每个实体（通常是用户/物品）需要用一个固定维度（例如128）的唯一向量嵌入来表示。由于电子商务网站上用户和物品的数量巨大，嵌入表格可以说是推荐系统中最不节省内存的组件。对于任何希望能够有效地按比例扩展到不断增长的用户/物品数量或在资源受限环境中仍然适用的轻量级推荐系统，现有的解决方案要么通过哈希减少所需的嵌入数量，要么通过稀疏化完整的嵌入表格以关闭选定的嵌入维度。然而，由于哈希冲突或嵌入过于稀疏，尤其是在适应更紧凑的内存预算时，这些轻量级推荐器不可避免地会牺牲其准确性。因此，我们提出了一种新颖的紧凑嵌入框架用于推荐系统，称为Compos。",
    "tldr": "本研究提出了一种用于推荐系统的新型紧凑嵌入框架，该框架通过正则化修剪的方式在资源受限的环境中实现了更高的内存效率，从而提供了高准确度的推荐。",
    "en_tdlr": "This study proposes a novel compact embedding framework for recommender systems, Compos, that achieves higher memory efficiency in resource-constrained settings through regularized pruning, thus providing accurate recommendations."
}