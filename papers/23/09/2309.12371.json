{
    "title": "Fairness Hub Technical Briefs: AUC Gap. (arXiv:2309.12371v1 [cs.LG])",
    "abstract": "To measure bias, we encourage teams to consider using AUC Gap: the absolute difference between the highest and lowest test AUC for subgroups (e.g., gender, race, SES, prior knowledge). It is agnostic to the AI/ML algorithm used and it captures the disparity in model performance for any number of subgroups, which enables non-binary fairness assessments such as for intersectional identity groups. The LEVI teams use a wide range of AI/ML models in pursuit of a common goal of doubling math achievement in low-income middle schools. Ensuring that the models, which are trained on datasets collected in many different contexts, do not introduce or amplify biases is important for achieving the LEVI goal. We offer here a versatile and easy-to-compute measure of model bias for all LEVI teams in order to create a common benchmark and an analytical basis for sharing what strategies have worked for different teams.",
    "link": "http://arxiv.org/abs/2309.12371",
    "context": "Title: Fairness Hub Technical Briefs: AUC Gap. (arXiv:2309.12371v1 [cs.LG])\nAbstract: To measure bias, we encourage teams to consider using AUC Gap: the absolute difference between the highest and lowest test AUC for subgroups (e.g., gender, race, SES, prior knowledge). It is agnostic to the AI/ML algorithm used and it captures the disparity in model performance for any number of subgroups, which enables non-binary fairness assessments such as for intersectional identity groups. The LEVI teams use a wide range of AI/ML models in pursuit of a common goal of doubling math achievement in low-income middle schools. Ensuring that the models, which are trained on datasets collected in many different contexts, do not introduce or amplify biases is important for achieving the LEVI goal. We offer here a versatile and easy-to-compute measure of model bias for all LEVI teams in order to create a common benchmark and an analytical basis for sharing what strategies have worked for different teams.",
    "path": "papers/23/09/2309.12371.json",
    "total_tokens": 873,
    "translated_title": "Fairness Hub技术简报: AUC Gap",
    "translated_abstract": "为了测量偏见，我们鼓励团队考虑使用AUC Gap：子群体（例如性别、种族、SES、先前知识）的最高和最低测试AUC的绝对差异。它不依赖于AI/ML算法，并捕捉模型在任意数量的子群体中的性能差异，从而实现了非二元的公平评估，例如针对交叉身份群体。LEVI团队在追求在低收入中学中将数学成就翻倍的共同目标时，使用各种AI/ML模型。确保这些模型在许多不同背景下收集的数据集上训练时不引入或放大偏见，对于实现LEVI目标非常重要。我们在此提供了一种灵活且易于计算的模型偏见度量方法，供所有LEVI团队使用，以创建一个共同的基准和分析基础，用于共享不同团队已经采取的策略。",
    "tldr": "本论文介绍了一种称为AUC Gap的指标，它可以测量AI/ML模型在不同子群体中的性能差异，从而实现非二元的公平评估，为实现共同目标提供了基准和策略分享的基础。",
    "en_tdlr": "This paper introduces a metric called AUC Gap, which measures the disparity in model performance for different subgroups, enabling non-binary fairness assessments and providing a benchmark and basis for sharing strategies towards a common goal."
}