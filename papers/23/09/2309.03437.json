{
    "title": "Byzantine-Robust Federated Learning with Variance Reduction and Differential Privacy. (arXiv:2309.03437v1 [cs.LG])",
    "abstract": "Federated learning (FL) is designed to preserve data privacy during model training, where the data remains on the client side (i.e., IoT devices), and only model updates of clients are shared iteratively for collaborative learning. However, this process is vulnerable to privacy attacks and Byzantine attacks: the local model updates shared throughout the FL network will leak private information about the local training data, and they can also be maliciously crafted by Byzantine attackers to disturb the learning. In this paper, we propose a new FL scheme that guarantees rigorous privacy and simultaneously enhances system robustness against Byzantine attacks. Our approach introduces sparsification- and momentum-driven variance reduction into the client-level differential privacy (DP) mechanism, to defend against Byzantine attackers. The security design does not violate the privacy guarantee of the client-level DP mechanism; hence, our approach achieves the same client-level DP guarantee a",
    "link": "http://arxiv.org/abs/2309.03437",
    "context": "Title: Byzantine-Robust Federated Learning with Variance Reduction and Differential Privacy. (arXiv:2309.03437v1 [cs.LG])\nAbstract: Federated learning (FL) is designed to preserve data privacy during model training, where the data remains on the client side (i.e., IoT devices), and only model updates of clients are shared iteratively for collaborative learning. However, this process is vulnerable to privacy attacks and Byzantine attacks: the local model updates shared throughout the FL network will leak private information about the local training data, and they can also be maliciously crafted by Byzantine attackers to disturb the learning. In this paper, we propose a new FL scheme that guarantees rigorous privacy and simultaneously enhances system robustness against Byzantine attacks. Our approach introduces sparsification- and momentum-driven variance reduction into the client-level differential privacy (DP) mechanism, to defend against Byzantine attackers. The security design does not violate the privacy guarantee of the client-level DP mechanism; hence, our approach achieves the same client-level DP guarantee a",
    "path": "papers/23/09/2309.03437.json",
    "total_tokens": 918,
    "translated_title": "具有方差减少和差分隐私的拜占庭鲁棒联邦学习",
    "translated_abstract": "联邦学习旨在在模型训练过程中保护数据隐私，其中数据保留在客户端（即物联网设备）上，仅通过共同学习的迭代过程共享客户端的模型更新。然而，这个过程容易受到隐私攻击和拜占庭攻击的影响：在整个联邦学习网络中共享的本地模型更新将泄露有关本地训练数据的私人信息，并且它们还可以被拜占庭攻击者恶意制作以干扰学习过程。本文提出了一种新的联邦学习方案，旨在保证严格的隐私性同时提高系统对拜占庭攻击的鲁棒性。我们的方法将稀疏化和动量驱动的方差减少引入到客户端级别的差分隐私机制中，以防止拜占庭攻击。安全设计不会违反客户端级别的差分隐私机制的隐私保证，因此我们的方法实现了相同的客户端级别的差分隐私保证。",
    "tldr": "该论文提出了一种新的联邦学习方案，具有方差减少和差分隐私技术，旨在保护数据隐私，并提高对拜占庭攻击的鲁棒性。",
    "en_tdlr": "This paper introduces a new federated learning scheme with variance reduction and differential privacy techniques to protect data privacy and enhance robustness against Byzantine attacks."
}