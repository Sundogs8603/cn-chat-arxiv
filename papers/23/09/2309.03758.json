{
    "title": "Hybrid of representation learning and reinforcement learning for dynamic and complex robotic motion planning. (arXiv:2309.03758v1 [cs.RO])",
    "abstract": "Motion planning is the soul of robot decision making. Classical planning algorithms like graph search and reaction-based algorithms face challenges in cases of dense and dynamic obstacles. Deep learning algorithms generate suboptimal one-step predictions that cause many collisions. Reinforcement learning algorithms generate optimal or near-optimal time-sequential predictions. However, they suffer from slow convergence, suboptimal converged results, and overfittings. This paper introduces a hybrid algorithm for robotic motion planning: long short-term memory (LSTM) pooling and skip connection for attention-based discrete soft actor critic (LSA-DSAC). First, graph network (relational graph) and attention network (attention weight) interpret the environmental state for the learning of the discrete soft actor critic algorithm. The expressive power of attention network outperforms that of graph in our task by difference analysis of these two representation methods. However, attention based ",
    "link": "http://arxiv.org/abs/2309.03758",
    "context": "Title: Hybrid of representation learning and reinforcement learning for dynamic and complex robotic motion planning. (arXiv:2309.03758v1 [cs.RO])\nAbstract: Motion planning is the soul of robot decision making. Classical planning algorithms like graph search and reaction-based algorithms face challenges in cases of dense and dynamic obstacles. Deep learning algorithms generate suboptimal one-step predictions that cause many collisions. Reinforcement learning algorithms generate optimal or near-optimal time-sequential predictions. However, they suffer from slow convergence, suboptimal converged results, and overfittings. This paper introduces a hybrid algorithm for robotic motion planning: long short-term memory (LSTM) pooling and skip connection for attention-based discrete soft actor critic (LSA-DSAC). First, graph network (relational graph) and attention network (attention weight) interpret the environmental state for the learning of the discrete soft actor critic algorithm. The expressive power of attention network outperforms that of graph in our task by difference analysis of these two representation methods. However, attention based ",
    "path": "papers/23/09/2309.03758.json",
    "total_tokens": 955,
    "translated_title": "表示学习和强化学习的混合算法用于动态和复杂的机器人运动规划",
    "translated_abstract": "运动规划是机器人决策的核心。传统的规划算法如图搜索和基于反应的算法在密集和动态障碍物的情况下面临挑战。深度学习算法产生次优的一步预测，导致许多碰撞。强化学习算法生成最优或接近最优的时间序列预测。然而，它们面临收敛速度慢、收敛结果次优和过拟合的问题。本文介绍了一个用于机器人运动规划的混合算法：长短期记忆（LSTM）汇聚和跳跃连接用于基于注意力的离散软演员-评论家算法（LSA-DSAC）。首先，图网络（关系图）和注意力网络（注意力权重）解释环境状态，用于学习离散软演员-评论家算法。通过对这两种表示方法的差异分析，注意力网络的表达能力优于图网络在我们的任务中。",
    "tldr": "这项研究提出了一种混合算法，将表示学习和强化学习结合应用于动态和复杂的机器人运动规划。其中使用了长短期记忆（LSTM）汇聚和跳跃连接来改进离散软演员-评论家算法，并通过比较不同的表示方法得出注意力网络在任务中的优势。",
    "en_tdlr": "This research presents a hybrid algorithm that combines representation learning and reinforcement learning for dynamic and complex robotic motion planning. It utilizes long short-term memory (LSTM) pooling and skip connection to improve the performance of the discrete soft actor critic algorithm, and demonstrates the superiority of attention network compared to graph network through analysis of different representation methods."
}