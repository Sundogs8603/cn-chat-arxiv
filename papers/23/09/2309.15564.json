{
    "title": "Jointly Training Large Autoregressive Multimodal Models. (arXiv:2309.15564v1 [cs.LG])",
    "abstract": "In recent years, advances in the large-scale pretraining of language and text-to-image models have revolutionized the field of machine learning. Yet, integrating these two modalities into a single, robust model capable of generating seamless multimodal outputs remains a significant challenge. To address this gap, we present the Joint Autoregressive Mixture (JAM) framework, a modular approach that systematically fuses existing text and image generation models. We also introduce a specialized, data-efficient instruction-tuning strategy, tailored for mixed-modal generation tasks. Our final instruct-tuned model demonstrates unparalleled performance in generating high-quality multimodal outputs and represents the first model explicitly designed for this purpose.",
    "link": "http://arxiv.org/abs/2309.15564",
    "context": "Title: Jointly Training Large Autoregressive Multimodal Models. (arXiv:2309.15564v1 [cs.LG])\nAbstract: In recent years, advances in the large-scale pretraining of language and text-to-image models have revolutionized the field of machine learning. Yet, integrating these two modalities into a single, robust model capable of generating seamless multimodal outputs remains a significant challenge. To address this gap, we present the Joint Autoregressive Mixture (JAM) framework, a modular approach that systematically fuses existing text and image generation models. We also introduce a specialized, data-efficient instruction-tuning strategy, tailored for mixed-modal generation tasks. Our final instruct-tuned model demonstrates unparalleled performance in generating high-quality multimodal outputs and represents the first model explicitly designed for this purpose.",
    "path": "papers/23/09/2309.15564.json",
    "total_tokens": 804,
    "translated_title": "共同训练大型自回归多模态模型",
    "translated_abstract": "最近几年，语言和文本到图像模型的大规模预训练取得了重大突破，彻底改变了机器学习领域。然而，将这两种模态集成到一个能够生成无缝多模态输出的单一强大模型仍然是一个重大挑战。为了解决这一问题，我们提出了联合自回归混合（JAM）框架，一种系统融合现有文本和图像生成模型的模块化方法。我们还引入了一种专门的、数据高效的指令调优策略，针对混合模态生成任务进行了优化。我们最终的调优模型在生成高质量多模态输出方面表现出无与伦比的性能，并代表了第一个明确为此目的而设计的模型。",
    "tldr": "本研究提出了共同训练大型自回归多模态模型的方法，通过模块化的方式融合语言和图像生成模型，同时引入了数据高效的指令调优策略，使得该模型在生成高质量多模态输出方面表现出卓越的性能。",
    "en_tdlr": "This research presents a method of jointly training large autoregressive multimodal models, which systematically fuses language and image generation models through a modular approach. The model also introduces a data-efficient instruction-tuning strategy, leading to unparalleled performance in generating high-quality multimodal outputs."
}