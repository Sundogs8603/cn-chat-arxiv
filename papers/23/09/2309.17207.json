{
    "title": "Memory Gym: Partially Observable Challenges to Memory-Based Agents in Endless Episodes. (arXiv:2309.17207v1 [cs.LG])",
    "abstract": "Memory Gym introduces a unique benchmark designed to test Deep Reinforcement Learning agents, specifically comparing Gated Recurrent Unit (GRU) against Transformer-XL (TrXL), on their ability to memorize long sequences, withstand noise, and generalize. It features partially observable 2D environments with discrete controls, namely Mortar Mayhem, Mystery Path, and Searing Spotlights. These originally finite environments are extrapolated to novel endless tasks that act as an automatic curriculum, drawing inspiration from the car game ``I packed my bag\". These endless tasks are not only beneficial for evaluating efficiency but also intriguingly valuable for assessing the effectiveness of approaches in memory-based agents. Given the scarcity of publicly available memory baselines, we contribute an implementation driven by TrXL and Proximal Policy Optimization. This implementation leverages TrXL as episodic memory using a sliding window approach. In our experiments on the finite environment",
    "link": "http://arxiv.org/abs/2309.17207",
    "context": "Title: Memory Gym: Partially Observable Challenges to Memory-Based Agents in Endless Episodes. (arXiv:2309.17207v1 [cs.LG])\nAbstract: Memory Gym introduces a unique benchmark designed to test Deep Reinforcement Learning agents, specifically comparing Gated Recurrent Unit (GRU) against Transformer-XL (TrXL), on their ability to memorize long sequences, withstand noise, and generalize. It features partially observable 2D environments with discrete controls, namely Mortar Mayhem, Mystery Path, and Searing Spotlights. These originally finite environments are extrapolated to novel endless tasks that act as an automatic curriculum, drawing inspiration from the car game ``I packed my bag\". These endless tasks are not only beneficial for evaluating efficiency but also intriguingly valuable for assessing the effectiveness of approaches in memory-based agents. Given the scarcity of publicly available memory baselines, we contribute an implementation driven by TrXL and Proximal Policy Optimization. This implementation leverages TrXL as episodic memory using a sliding window approach. In our experiments on the finite environment",
    "path": "papers/23/09/2309.17207.json",
    "total_tokens": 1010,
    "translated_title": "记忆健身房：对内存为基础的智能体在无尽任务中的部分可观察挑战",
    "translated_abstract": "记忆健身房介绍了一个独特的基准测试，旨在测试深度强化学习智能体，特别是将门循环单元(GRU)与Transformer-XL(TrXL)相比，它们对于记忆长序列的能力、抗噪声和泛化能力。它采用了部分可观察的二维环境和离散控制，即Mortar Mayhem、Mystery Path和Searing Spotlights。这些最初是有限的环境被推广为新颖的无尽任务，作为一种自动课程，从车游戏\"I packed my bag\"中汲取灵感。这些无尽任务不仅有助于评估效率，而且有趣地评估了记忆为基础的方法的有效性。鉴于现有公开可用的记忆基准的稀缺性，我们提供了一个由TrXL和Proximal Policy Optimization驱动的实现。本实现利用TrXL作为以滑动窗口方法使用的情节性记忆。在有限环境的实验中，我们发现...",
    "tldr": "本研究提出了记忆健身房，一种用于测试利用记忆为基础的深度强化学习智能体能力的基准。它包括部分可观察的二维环境和离散控制，并通过无尽任务对记忆能力、噪声抗性和泛化能力进行评估。研究还提供了一个使用Transformer-XL和Proximal Policy Optimization驱动的实现。",
    "en_tdlr": "This study introduces Memory Gym, a benchmark designed to test the abilities of memory-based deep reinforcement learning agents. It includes partially observable 2D environments with discrete controls and evaluates memory capacity, noise resistance, and generalization through endless tasks. The study also provides an implementation driven by Transformer-XL and Proximal Policy Optimization."
}