{
    "title": "Prime and Modulate Learning: Generation of forward models with signed back-propagation and environmental cues. (arXiv:2309.03825v1 [cs.LG])",
    "abstract": "Deep neural networks employing error back-propagation for learning can suffer from exploding and vanishing gradient problems. Numerous solutions have been proposed such as normalisation techniques or limiting activation functions to linear rectifying units. In this work we follow a different approach which is particularly applicable to closed-loop learning of forward models where back-propagation makes exclusive use of the sign of the error signal to prime the learning, whilst a global relevance signal modulates the rate of learning. This is inspired by the interaction between local plasticity and a global neuromodulation. For example, whilst driving on an empty road, one can allow for slow step-wise optimisation of actions, whereas, at a busy junction, an error must be corrected at once. Hence, the error is the priming signal and the intensity of the experience is a modulating factor in the weight change. The advantages of this Prime and Modulate paradigm is twofold: it is free from n",
    "link": "http://arxiv.org/abs/2309.03825",
    "context": "Title: Prime and Modulate Learning: Generation of forward models with signed back-propagation and environmental cues. (arXiv:2309.03825v1 [cs.LG])\nAbstract: Deep neural networks employing error back-propagation for learning can suffer from exploding and vanishing gradient problems. Numerous solutions have been proposed such as normalisation techniques or limiting activation functions to linear rectifying units. In this work we follow a different approach which is particularly applicable to closed-loop learning of forward models where back-propagation makes exclusive use of the sign of the error signal to prime the learning, whilst a global relevance signal modulates the rate of learning. This is inspired by the interaction between local plasticity and a global neuromodulation. For example, whilst driving on an empty road, one can allow for slow step-wise optimisation of actions, whereas, at a busy junction, an error must be corrected at once. Hence, the error is the priming signal and the intensity of the experience is a modulating factor in the weight change. The advantages of this Prime and Modulate paradigm is twofold: it is free from n",
    "path": "papers/23/09/2309.03825.json",
    "total_tokens": 880,
    "translated_title": "Prime和Modulate学习：通过带符号反向传播和环境线索生成前向模型",
    "translated_abstract": "深度神经网络在学习中使用的误差反向传播可能面临梯度爆炸和梯度消失的问题。许多解决方案已经被提出，例如规范化技术或将激活函数限制为线性整流单元。在这项工作中，我们采用了一种不同的方法，该方法特别适用于前向模型的闭环学习，其中反向传播仅使用误差信号的符号来引导学习，而全局相关信号调节学习速率。这受到局部可塑性与全局神经调节之间的相互作用的启发。例如，在空旷的道路上行驶时，可以允许对行动进行缓慢逐步的优化，而在繁忙的十字路口，必须立即纠正错误。因此，错误就是引导信号，经历的强度是权重变化的调节因素。这种Prime和Modulate范式的优点是双重的：",
    "tldr": "采用Prime和Modulate方法，通过带符号的反向传播和全局相关信号，实现了前向模型的闭环学习，解决了梯度爆炸和梯度消失问题。",
    "en_tdlr": "This work introduces the Prime and Modulate paradigm for closed-loop learning of forward models, utilizing signed back-propagation and a global relevance signal to address the issues of exploding and vanishing gradients."
}