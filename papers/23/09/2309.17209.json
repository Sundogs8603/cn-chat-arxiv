{
    "title": "Robots That Can See: Leveraging Human Pose for Trajectory Prediction. (arXiv:2309.17209v1 [cs.RO])",
    "abstract": "Anticipating the motion of all humans in dynamic environments such as homes and offices is critical to enable safe and effective robot navigation. Such spaces remain challenging as humans do not follow strict rules of motion and there are often multiple occluded entry points such as corners and doors that create opportunities for sudden encounters. In this work, we present a Transformer based architecture to predict human future trajectories in human-centric environments from input features including human positions, head orientations, and 3D skeletal keypoints from onboard in-the-wild sensory information. The resulting model captures the inherent uncertainty for future human trajectory prediction and achieves state-of-the-art performance on common prediction benchmarks and a human tracking dataset captured from a mobile robot adapted for the prediction task. Furthermore, we identify new agents with limited historical data as a major contributor to error and demonstrate the complementa",
    "link": "http://arxiv.org/abs/2309.17209",
    "context": "Title: Robots That Can See: Leveraging Human Pose for Trajectory Prediction. (arXiv:2309.17209v1 [cs.RO])\nAbstract: Anticipating the motion of all humans in dynamic environments such as homes and offices is critical to enable safe and effective robot navigation. Such spaces remain challenging as humans do not follow strict rules of motion and there are often multiple occluded entry points such as corners and doors that create opportunities for sudden encounters. In this work, we present a Transformer based architecture to predict human future trajectories in human-centric environments from input features including human positions, head orientations, and 3D skeletal keypoints from onboard in-the-wild sensory information. The resulting model captures the inherent uncertainty for future human trajectory prediction and achieves state-of-the-art performance on common prediction benchmarks and a human tracking dataset captured from a mobile robot adapted for the prediction task. Furthermore, we identify new agents with limited historical data as a major contributor to error and demonstrate the complementa",
    "path": "papers/23/09/2309.17209.json",
    "total_tokens": 923,
    "translated_title": "能够看见的机器人：利用人体姿势进行轨迹预测",
    "translated_abstract": "在诸如家庭和办公室等动态环境中，预测所有人类的运动对于实现安全有效的机器人导航至关重要。这样的空间仍然具有挑战性，因为人类不遵循严格的运动规则，而且通常存在多个被遮挡的入口点，如拐角和门，在这些地方容易发生突然相遇的情况。在这项工作中，我们提出了一种基于Transformer的架构，从包括人类位置、头部方向和三维骨骼关键点在内的输入特征中，预测人类在以人为中心的环境中的未来轨迹。所得模型捕捉到了未来人类轨迹预测的固有不确定性，并在常见的预测基准和适用于预测任务的移动机器人捕获的人类跟踪数据集上实现了最先进的性能。此外，我们确定了历史数据有限的新代理是错误的主要贡献因素，并展示了补充解决方案。",
    "tldr": "该论文提出了一种利用Transformer架构预测人类未来轨迹的方法，可以应用于以人为中心的动态环境。模型在常见的预测基准和移动机器人捕获的数据集上表现出色，并解决了历史数据有限的新代理导致的误差问题。",
    "en_tdlr": "This paper presents a Transformer based architecture for predicting human future trajectories in human-centric environments. The model achieves state-of-the-art performance on common prediction benchmarks and addresses the error caused by new agents with limited historical data."
}