{
    "title": "Bold but Cautious: Unlocking the Potential of Personalized Federated Learning through Cautiously Aggressive Collaboration. (arXiv:2309.11103v1 [cs.LG])",
    "abstract": "Personalized federated learning (PFL) reduces the impact of non-independent and identically distributed (non-IID) data among clients by allowing each client to train a personalized model when collaborating with others. A key question in PFL is to decide which parameters of a client should be localized or shared with others. In current mainstream approaches, all layers that are sensitive to non-IID data (such as classifier layers) are generally personalized. The reasoning behind this approach is understandable, as localizing parameters that are easily influenced by non-IID data can prevent the potential negative effect of collaboration. However, we believe that this approach is too conservative for collaboration. For example, for a certain client, even if its parameters are easily influenced by non-IID data, it can still benefit by sharing these parameters with clients having similar data distribution. This observation emphasizes the importance of considering not only the sensitivity to",
    "link": "http://arxiv.org/abs/2309.11103",
    "context": "Title: Bold but Cautious: Unlocking the Potential of Personalized Federated Learning through Cautiously Aggressive Collaboration. (arXiv:2309.11103v1 [cs.LG])\nAbstract: Personalized federated learning (PFL) reduces the impact of non-independent and identically distributed (non-IID) data among clients by allowing each client to train a personalized model when collaborating with others. A key question in PFL is to decide which parameters of a client should be localized or shared with others. In current mainstream approaches, all layers that are sensitive to non-IID data (such as classifier layers) are generally personalized. The reasoning behind this approach is understandable, as localizing parameters that are easily influenced by non-IID data can prevent the potential negative effect of collaboration. However, we believe that this approach is too conservative for collaboration. For example, for a certain client, even if its parameters are easily influenced by non-IID data, it can still benefit by sharing these parameters with clients having similar data distribution. This observation emphasizes the importance of considering not only the sensitivity to",
    "path": "papers/23/09/2309.11103.json",
    "total_tokens": 1006,
    "translated_title": "大胆而谨慎：通过谨慎而积极的合作释放个性化联邦学习的潜力",
    "translated_abstract": "个性化联邦学习（PFL）通过允许每个客户端在与其他人合作时训练个性化模型，以减少非独立同分布（non-IID）数据对客户端的影响。PFL中的一个关键问题是决定客户端的哪些参数应该本地化或与其他人共享。在当前主流方法中，通常会个性化与非IID数据敏感的所有层（如分类器层）的参数。这种方法的理由是可以理解的，因为本地化易受非IID数据影响的参数可以防止合作的潜在负面影响。然而，我们认为这种方法对于合作来说过于保守。例如，对于某个客户端，即使其参数容易受非IID数据影响，与具有相似数据分布的客户端共享这些参数仍然可以带来收益。这一观察强调了不仅要考虑对非IID数据的敏感性，而且要考虑与其他客户端进行合作所带来的潜在好处的重要性。",
    "tldr": "个性化联邦学习中的一个关键问题是决定哪些参数应该本地化或共享。传统方法中通常个性化与非IID数据敏感的所有层的参数，但这种方法过于保守。本论文提出在合作中要考虑与其他客户端的潜在好处，即使参数容易受非IID数据影响的情况下，也仍可以通过共享这些参数来获益。",
    "en_tdlr": "A key question in personalized federated learning is deciding which parameters should be localized or shared. Traditional approaches typically personalize parameters of all layers sensitive to non-IID data, but this approach is too conservative. This paper proposes considering the potential benefits of collaboration with other clients, even in cases where parameters are easily influenced by non-IID data, by sharing these parameters."
}