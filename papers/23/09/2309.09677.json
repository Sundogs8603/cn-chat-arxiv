{
    "title": "Single and Few-step Diffusion for Generative Speech Enhancement. (arXiv:2309.09677v2 [eess.AS] UPDATED)",
    "abstract": "Diffusion models have shown promising results in speech enhancement, using a task-adapted diffusion process for the conditional generation of clean speech given a noisy mixture. However, at test time, the neural network used for score estimation is called multiple times to solve the iterative reverse process. This results in a slow inference process and causes discretization errors that accumulate over the sampling trajectory. In this paper, we address these limitations through a two-stage training approach. In the first stage, we train the diffusion model the usual way using the generative denoising score matching loss. In the second stage, we compute the enhanced signal by solving the reverse process and compare the resulting estimate to the clean speech target using a predictive loss. We show that using this second training stage enables achieving the same performance as the baseline model using only 5 function evaluations instead of 60 function evaluations. While the performance of",
    "link": "http://arxiv.org/abs/2309.09677",
    "context": "Title: Single and Few-step Diffusion for Generative Speech Enhancement. (arXiv:2309.09677v2 [eess.AS] UPDATED)\nAbstract: Diffusion models have shown promising results in speech enhancement, using a task-adapted diffusion process for the conditional generation of clean speech given a noisy mixture. However, at test time, the neural network used for score estimation is called multiple times to solve the iterative reverse process. This results in a slow inference process and causes discretization errors that accumulate over the sampling trajectory. In this paper, we address these limitations through a two-stage training approach. In the first stage, we train the diffusion model the usual way using the generative denoising score matching loss. In the second stage, we compute the enhanced signal by solving the reverse process and compare the resulting estimate to the clean speech target using a predictive loss. We show that using this second training stage enables achieving the same performance as the baseline model using only 5 function evaluations instead of 60 function evaluations. While the performance of",
    "path": "papers/23/09/2309.09677.json",
    "total_tokens": 997,
    "translated_title": "单步和少步扩散用于生成式语音增强",
    "translated_abstract": "扩散模型在语音增强方面展示了有希望的结果，利用任务适应性扩散过程来生成给定嘈杂混合声音的纯净语音。然而，在测试时，用于评分估计的神经网络被多次调用以解决迭代的反向过程。这导致推理过程缓慢，并导致在采样轨迹中积累离散化误差。在本文中，我们通过两阶段训练方法解决了这些限制。在第一阶段，我们用生成去噪评分匹配损失的常规方式训练扩散模型。在第二阶段，我们通过解决反向过程来计算增强信号，并使用预测损失将结果估计与纯净语音目标进行比较。我们证明使用这个第二训练阶段只需要5个函数评估，就能达到与基准模型相同的性能，而不是60个函数评估。虽然基准模型的性能可能",
    "tldr": "本文提出了一种通过两阶段训练的方法来解决扩散模型在语音增强中的限制。第一阶段使用生成去噪评分匹配损失训练扩散模型，第二阶段通过解决反向过程来计算增强信号，并使用预测损失进行比较。这种方法只需要5个函数评估就能达到与基准模型相同的性能，而不是60个函数评估。",
    "en_tdlr": "This paper proposes a two-stage training approach to address limitations in diffusion models for speech enhancement. The first stage trains the diffusion model using generative denoising score matching loss, and the second stage computes the enhanced signal by solving the reverse process and compares it to the clean speech target using a predictive loss. This approach achieves the same performance as the baseline model using only 5 function evaluations instead of 60 function evaluations."
}