{
    "title": "Posterior sampling algorithms for unsupervised speech enhancement with recurrent variational autoencoder. (arXiv:2309.10439v1 [cs.CV])",
    "abstract": "In this paper, we address the unsupervised speech enhancement problem based on recurrent variational autoencoder (RVAE). This approach offers promising generalization performance over the supervised counterpart. Nevertheless, the involved iterative variational expectation-maximization (VEM) process at test time, which relies on a variational inference method, results in high computational complexity. To tackle this issue, we present efficient sampling techniques based on Langevin dynamics and Metropolis-Hasting algorithms, adapted to the EM-based speech enhancement with RVAE. By directly sampling from the intractable posterior distribution within the EM process, we circumvent the intricacies of variational inference. We conduct a series of experiments, comparing the proposed methods with VEM and a state-of-the-art supervised speech enhancement approach based on diffusion models. The results reveal that our sampling-based algorithms significantly outperform VEM, not only in terms of com",
    "link": "http://arxiv.org/abs/2309.10439",
    "context": "Title: Posterior sampling algorithms for unsupervised speech enhancement with recurrent variational autoencoder. (arXiv:2309.10439v1 [cs.CV])\nAbstract: In this paper, we address the unsupervised speech enhancement problem based on recurrent variational autoencoder (RVAE). This approach offers promising generalization performance over the supervised counterpart. Nevertheless, the involved iterative variational expectation-maximization (VEM) process at test time, which relies on a variational inference method, results in high computational complexity. To tackle this issue, we present efficient sampling techniques based on Langevin dynamics and Metropolis-Hasting algorithms, adapted to the EM-based speech enhancement with RVAE. By directly sampling from the intractable posterior distribution within the EM process, we circumvent the intricacies of variational inference. We conduct a series of experiments, comparing the proposed methods with VEM and a state-of-the-art supervised speech enhancement approach based on diffusion models. The results reveal that our sampling-based algorithms significantly outperform VEM, not only in terms of com",
    "path": "papers/23/09/2309.10439.json",
    "total_tokens": 912,
    "translated_title": "基于递归变分自动编码器的无监督语音增强的后采样算法",
    "translated_abstract": "本文针对基于递归变分自动编码器（RVAE）的无监督语音增强问题进行了研究。该方法在泛化性能上相较于有监督方法有着良好的表现。然而，测试时涉及到的迭代变分期望最大化（VEM）过程，依赖于变分推理方法，导致了高计算复杂性。为了解决这个问题，我们提出了一种基于朗格朗日动力学和Metropolis-Hasting算法的有效采样技术，用于基于EM的语音增强和RVAE。通过直接对EM过程中的难以计算的后验分布进行采样，我们绕过了变分推理的复杂性。我们进行了一系列实验，将我们提出的方法与VEM以及基于扩散模型的最先进的有监督语音增强方法进行了对比。结果表明，我们基于采样的算法在性能上明显优于VEM，不仅在计算效率上，而且在语音增强效果上也提升了很多。",
    "tldr": "本文提出了一种基于递归变分自动编码器的后采样算法用于无监督语音增强，该算法通过采样后验分布来提高计算效率并获得更好的语音增强效果。",
    "en_tdlr": "This paper presents a posterior sampling algorithm based on recurrent variational autoencoder for unsupervised speech enhancement. By sampling from the posterior distribution, the algorithm improves computational efficiency and achieves better speech enhancement results."
}