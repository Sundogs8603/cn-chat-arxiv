{
    "title": "Implicit Gaussian process representation of vector fields over arbitrary latent manifolds. (arXiv:2309.16746v1 [cs.LG])",
    "abstract": "Gaussian processes (GPs) are popular nonparametric statistical models for learning unknown functions and quantifying the spatiotemporal uncertainty in data. Recent works have extended GPs to model scalar and vector quantities distributed over non-Euclidean domains, including smooth manifolds appearing in numerous fields such as computer vision, dynamical systems, and neuroscience. However, these approaches assume that the manifold underlying the data is known, limiting their practical utility. We introduce RVGP, a generalisation of GPs for learning vector signals over latent Riemannian manifolds. Our method uses positional encoding with eigenfunctions of the connection Laplacian, associated with the tangent bundle, readily derived from common graph-based approximation of data. We demonstrate that RVGP possesses global regularity over the manifold, which allows it to super-resolve and inpaint vector fields while preserving singularities. Furthermore, we use RVGP to reconstruct high-dens",
    "link": "http://arxiv.org/abs/2309.16746",
    "context": "Title: Implicit Gaussian process representation of vector fields over arbitrary latent manifolds. (arXiv:2309.16746v1 [cs.LG])\nAbstract: Gaussian processes (GPs) are popular nonparametric statistical models for learning unknown functions and quantifying the spatiotemporal uncertainty in data. Recent works have extended GPs to model scalar and vector quantities distributed over non-Euclidean domains, including smooth manifolds appearing in numerous fields such as computer vision, dynamical systems, and neuroscience. However, these approaches assume that the manifold underlying the data is known, limiting their practical utility. We introduce RVGP, a generalisation of GPs for learning vector signals over latent Riemannian manifolds. Our method uses positional encoding with eigenfunctions of the connection Laplacian, associated with the tangent bundle, readily derived from common graph-based approximation of data. We demonstrate that RVGP possesses global regularity over the manifold, which allows it to super-resolve and inpaint vector fields while preserving singularities. Furthermore, we use RVGP to reconstruct high-dens",
    "path": "papers/23/09/2309.16746.json",
    "total_tokens": 910,
    "translated_title": "隐性高斯过程表示任意潜在流形上的向量场",
    "translated_abstract": "高斯过程（GPs）是用于学习未知函数和量化数据中的时空不确定性的流行非参数统计模型。最近的研究扩展了GPs，用于建模分布在非欧几里得域上的标量和向量数据，包括出现在计算机视觉、动力系统和神经科学等众多领域中的平滑流形。然而，这些方法假设数据的潜在流形是已知的，限制了它们的实际效用。我们引入了RVGP，一种用于学习潜在黎曼流形上的向量信号的GP的推广。我们的方法使用与切向丛关联的连接Laplacian的特征函数进行位置编码，这些特征函数可以从基于图的常见数据近似中轻松推导出来。我们证明了RVGP在流形上具有全局规律性，使得其能够在保留奇异性的同时超分辨率和修复向量场。此外，我们使用RVGP来重构高密度数据。",
    "tldr": "这项研究通过引入RVGP方法，结合基于图的数据逼近方法对潜在流形上的向量信号进行学习，实现了超分辨率和修复向量场，并且在实验中证明了其具有全局规律性。"
}