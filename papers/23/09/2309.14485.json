{
    "title": "Explainable and Accurate Natural Language Understanding for Voice Assistants and Beyond. (arXiv:2309.14485v1 [cs.LG])",
    "abstract": "Joint intent detection and slot filling, which is also termed as joint NLU (Natural Language Understanding) is invaluable for smart voice assistants. Recent advancements in this area have been heavily focusing on improving accuracy using various techniques. Explainability is undoubtedly an important aspect for deep learning-based models including joint NLU models. Without explainability, their decisions are opaque to the outside world and hence, have tendency to lack user trust. Therefore to bridge this gap, we transform the full joint NLU model to be `inherently' explainable at granular levels without compromising on accuracy. Further, as we enable the full joint NLU model explainable, we show that our extension can be successfully used in other general classification tasks. We demonstrate this using sentiment analysis and named entity recognition.",
    "link": "http://arxiv.org/abs/2309.14485",
    "context": "Title: Explainable and Accurate Natural Language Understanding for Voice Assistants and Beyond. (arXiv:2309.14485v1 [cs.LG])\nAbstract: Joint intent detection and slot filling, which is also termed as joint NLU (Natural Language Understanding) is invaluable for smart voice assistants. Recent advancements in this area have been heavily focusing on improving accuracy using various techniques. Explainability is undoubtedly an important aspect for deep learning-based models including joint NLU models. Without explainability, their decisions are opaque to the outside world and hence, have tendency to lack user trust. Therefore to bridge this gap, we transform the full joint NLU model to be `inherently' explainable at granular levels without compromising on accuracy. Further, as we enable the full joint NLU model explainable, we show that our extension can be successfully used in other general classification tasks. We demonstrate this using sentiment analysis and named entity recognition.",
    "path": "papers/23/09/2309.14485.json",
    "total_tokens": 791,
    "translated_title": "可解释和准确的语音助手及其它领域的自然语言理解",
    "translated_abstract": "联合意图检测和槽填充，也称为联合自然语言理解（NLU），对于智能语音助手非常重要。最近在这个领域的进展主要集中在使用各种技术提高准确性上。可解释性无疑是基于深度学习模型的模型的一个重要方面，包括联合NLU模型。如果没有解释性，它们的决策对外界来说是不透明的，因此容易缺乏用户的信任。因此，为了弥合这一差距，我们将完整的联合NLU模型转化为在细粒度上“内在地”可解释的，同时不影响准确性。此外，通过使完整的联合NLU模型具有可解释性，我们展示了我们的扩展可以成功应用于其他一般分类任务。我们使用情感分析和命名实体识别来证明这一点。",
    "tldr": "这项研究改进了联合NLU模型的准确性，并使其可解释，同时扩展适用于其他分类任务。"
}