{
    "title": "Self-Explanation Prompting Improves Dialogue Understanding in Large Language Models. (arXiv:2309.12940v1 [cs.CL])",
    "abstract": "Task-oriented dialogue (TOD) systems facilitate users in executing various activities via multi-turn dialogues, but Large Language Models (LLMs) often struggle to comprehend these intricate contexts. In this study, we propose a novel \"Self-Explanation\" prompting strategy to enhance the comprehension abilities of LLMs in multi-turn dialogues. This task-agnostic approach requires the model to analyze each dialogue utterance before task execution, thereby improving performance across various dialogue-centric tasks. Experimental results from six benchmark datasets confirm that our method consistently outperforms other zero-shot prompts and matches or exceeds the efficacy of few-shot prompts, demonstrating its potential as a powerful tool in enhancing LLMs' comprehension in complex dialogue tasks.",
    "link": "http://arxiv.org/abs/2309.12940",
    "context": "Title: Self-Explanation Prompting Improves Dialogue Understanding in Large Language Models. (arXiv:2309.12940v1 [cs.CL])\nAbstract: Task-oriented dialogue (TOD) systems facilitate users in executing various activities via multi-turn dialogues, but Large Language Models (LLMs) often struggle to comprehend these intricate contexts. In this study, we propose a novel \"Self-Explanation\" prompting strategy to enhance the comprehension abilities of LLMs in multi-turn dialogues. This task-agnostic approach requires the model to analyze each dialogue utterance before task execution, thereby improving performance across various dialogue-centric tasks. Experimental results from six benchmark datasets confirm that our method consistently outperforms other zero-shot prompts and matches or exceeds the efficacy of few-shot prompts, demonstrating its potential as a powerful tool in enhancing LLMs' comprehension in complex dialogue tasks.",
    "path": "papers/23/09/2309.12940.json",
    "total_tokens": 748,
    "translated_title": "自解释提示在大型语言模型中提高对话理解能力",
    "translated_abstract": "任务导向的对话系统通过多轮对话帮助用户执行各种活动，但是大型语言模型（LLMs）往往难以理解这些复杂的语境。在本研究中，我们提出了一种新的“自解释”提示策略，以增强LLMs在多轮对话中的理解能力。这种任务无关的方法要求模型在执行任务之前分析每个对话话语，从而改善各种对话中心任务的性能。来自六个基准数据集的实验证据证实，我们的方法始终优于其他零样本提示，并且与少样本提示的有效性相当或超过，展示了它在提高LLMs在复杂对话任务中的理解能力方面的潜力。",
    "tldr": "本研究提出了一种自解释提示策略，可显著提高大型语言模型在多轮对话中的理解能力，实验证实其在复杂对话任务中的有效性。",
    "en_tdlr": "This study proposes a self-explanation prompting strategy that significantly improves the comprehension abilities of large language models in multi-turn dialogues, and experimental results confirm its effectiveness in complex dialogue tasks."
}