{
    "title": "Rethinking Evaluation Metric for Probability Estimation Models Using Esports Data. (arXiv:2309.06248v1 [cs.LG])",
    "abstract": "Probability estimation models play an important role in various fields, such as weather forecasting, recommendation systems, and sports analysis. Among several models estimating probabilities, it is difficult to evaluate which model gives reliable probabilities since the ground-truth probabilities are not available. The win probability estimation model for esports, which calculates the win probability under a certain game state, is also one of the fields being actively studied in probability estimation. However, most of the previous works evaluated their models using accuracy, a metric that only can measure the performance of discrimination. In this work, we firstly investigate the Brier score and the Expected Calibration Error (ECE) as a replacement of accuracy used as a performance evaluation metric for win probability estimation models in esports field. Based on the analysis, we propose a novel metric called Balance score which is a simple yet effective metric in terms of six good p",
    "link": "http://arxiv.org/abs/2309.06248",
    "context": "Title: Rethinking Evaluation Metric for Probability Estimation Models Using Esports Data. (arXiv:2309.06248v1 [cs.LG])\nAbstract: Probability estimation models play an important role in various fields, such as weather forecasting, recommendation systems, and sports analysis. Among several models estimating probabilities, it is difficult to evaluate which model gives reliable probabilities since the ground-truth probabilities are not available. The win probability estimation model for esports, which calculates the win probability under a certain game state, is also one of the fields being actively studied in probability estimation. However, most of the previous works evaluated their models using accuracy, a metric that only can measure the performance of discrimination. In this work, we firstly investigate the Brier score and the Expected Calibration Error (ECE) as a replacement of accuracy used as a performance evaluation metric for win probability estimation models in esports field. Based on the analysis, we propose a novel metric called Balance score which is a simple yet effective metric in terms of six good p",
    "path": "papers/23/09/2309.06248.json",
    "total_tokens": 874,
    "translated_title": "重新思考使用电竞数据评估概率估计模型的评价指标",
    "translated_abstract": "概率估计模型在天气预报、推荐系统和体育分析等领域发挥着重要作用。在众多概率估计模型中，由于没有真实概率数据可用，很难评估哪个模型提供可靠的概率。电竞中的胜率估计模型是概率估计领域中一个正在被积极研究的领域，其计算在特定游戏状态下的胜率。然而，大多数之前的研究使用准确率作为评估模型的指标，准确率只能衡量区分性能。在这项工作中，我们首次研究了布里尔分数和预期校准误差（ECE）作为替代准确性的评估指标，用于电竞领域中胜率估计模型的性能评估。基于分析，我们提出了一种名为平衡分数的新指标，它在六个好属性方面是简单而有效的指标。",
    "tldr": "本研究首次提出了使用布里尔分数和预期校准误差作为评估电竞领域胜率估计模型性能的指标，并且提出了一种新的平衡分数指标。",
    "en_tdlr": "This study proposes to use Brier score and Expected Calibration Error as evaluation metrics for win probability estimation models in esports field, and introduces a novel metric called Balance score."
}