{
    "title": "Probabilistic Safety Regions Via Finite Families of Scalable Classifiers. (arXiv:2309.04627v1 [stat.ML])",
    "abstract": "Supervised classification recognizes patterns in the data to separate classes of behaviours. Canonical solutions contain misclassification errors that are intrinsic to the numerical approximating nature of machine learning. The data analyst may minimize the classification error on a class at the expense of increasing the error of the other classes. The error control of such a design phase is often done in a heuristic manner. In this context, it is key to develop theoretical foundations capable of providing probabilistic certifications to the obtained classifiers. In this perspective, we introduce the concept of probabilistic safety region to describe a subset of the input space in which the number of misclassified instances is probabilistically controlled. The notion of scalable classifiers is then exploited to link the tuning of machine learning with error control. Several tests corroborate the approach. They are provided through synthetic data in order to highlight all the steps invo",
    "link": "http://arxiv.org/abs/2309.04627",
    "context": "Title: Probabilistic Safety Regions Via Finite Families of Scalable Classifiers. (arXiv:2309.04627v1 [stat.ML])\nAbstract: Supervised classification recognizes patterns in the data to separate classes of behaviours. Canonical solutions contain misclassification errors that are intrinsic to the numerical approximating nature of machine learning. The data analyst may minimize the classification error on a class at the expense of increasing the error of the other classes. The error control of such a design phase is often done in a heuristic manner. In this context, it is key to develop theoretical foundations capable of providing probabilistic certifications to the obtained classifiers. In this perspective, we introduce the concept of probabilistic safety region to describe a subset of the input space in which the number of misclassified instances is probabilistically controlled. The notion of scalable classifiers is then exploited to link the tuning of machine learning with error control. Several tests corroborate the approach. They are provided through synthetic data in order to highlight all the steps invo",
    "path": "papers/23/09/2309.04627.json",
    "total_tokens": 839,
    "translated_title": "使用可伸缩分类器的概率安全区域",
    "translated_abstract": "监督分类可以识别数据中的模式以分离不同的行为类别。然而，机器学习的数值逼近性质决定了分类算法上的误差问题。数据分析师可能会通过减小某个类别的错误来增加其他类别的错误。然而，这种设计阶段的误差控制通常以启发式的方式进行。因此，有必要发展一种理论基础，能够对获得的分类器进行概率证明。在这个视角下，我们引入了概率安全区域的概念，用来描述一个输入空间子集，其中误分类实例的数量可以概率上得到控制。然后，我们利用可伸缩分类器来将机器学习的调参与误差控制相结合。通过合成数据提供了多种测试来验证该方法，以突出所有步骤。",
    "tldr": "本论文提出了概率安全区域的概念，用于描述一个输入空间子集，在这个子集中，误分类实例的数量可以被概率上得到控制。同时，利用可伸缩分类器来将机器学习的调参与误差控制相结合。"
}