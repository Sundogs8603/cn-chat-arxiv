{
    "title": "Learning of Generalizable and Interpretable Knowledge in Grid-Based Reinforcement Learning Environments. (arXiv:2309.03651v1 [cs.AI])",
    "abstract": "Understanding the interactions of agents trained with deep reinforcement learning is crucial for deploying agents in games or the real world. In the former, unreasonable actions confuse players. In the latter, that effect is even more significant, as unexpected behavior cause accidents with potentially grave and long-lasting consequences for the involved individuals. In this work, we propose using program synthesis to imitate reinforcement learning policies after seeing a trajectory of the action sequence. Programs have the advantage that they are inherently interpretable and verifiable for correctness. We adapt the state-of-the-art program synthesis system DreamCoder for learning concepts in grid-based environments, specifically, a navigation task and two miniature versions of Atari games, Space Invaders and Asterix. By inspecting the generated libraries, we can make inferences about the concepts the black-box agent has learned and better understand the agent's behavior. We achieve th",
    "link": "http://arxiv.org/abs/2309.03651",
    "context": "Title: Learning of Generalizable and Interpretable Knowledge in Grid-Based Reinforcement Learning Environments. (arXiv:2309.03651v1 [cs.AI])\nAbstract: Understanding the interactions of agents trained with deep reinforcement learning is crucial for deploying agents in games or the real world. In the former, unreasonable actions confuse players. In the latter, that effect is even more significant, as unexpected behavior cause accidents with potentially grave and long-lasting consequences for the involved individuals. In this work, we propose using program synthesis to imitate reinforcement learning policies after seeing a trajectory of the action sequence. Programs have the advantage that they are inherently interpretable and verifiable for correctness. We adapt the state-of-the-art program synthesis system DreamCoder for learning concepts in grid-based environments, specifically, a navigation task and two miniature versions of Atari games, Space Invaders and Asterix. By inspecting the generated libraries, we can make inferences about the concepts the black-box agent has learned and better understand the agent's behavior. We achieve th",
    "path": "papers/23/09/2309.03651.json",
    "total_tokens": 833,
    "translated_title": "在基于网格的强化学习环境中学习通用和可解释的知识",
    "translated_abstract": "对于在游戏或现实世界中部署经过深度强化学习训练的智能体来说，理解其交互是非常重要的。在游戏中，不合理的动作会困惑玩家。在现实世界中，这种影响更加显著，因为意外行为可能导致事故，对相关人员可能产生严重而长远的后果。本文提出使用程序合成在观察到一系列动作轨迹后模仿强化学习策略。程序具有固有的可解释性和正确性可验证性的优势。我们针对基于网格的环境（包括导航任务和两个迷你版的Atari游戏：Space Invaders和Asterix）改造了先进的程序合成系统DreamCoder，通过检查生成的库，我们可以推断出黑盒智能体学习的概念，并更好地理解智能体的行为。",
    "tldr": "本文提出了在基于网格的强化学习环境中使用程序合成来学习通用和可解释的知识，以解决智能体行为理解的问题。",
    "en_tdlr": "This paper proposes using program synthesis to learn generalizable and interpretable knowledge in grid-based reinforcement learning environments, addressing the issue of understanding agent behavior."
}