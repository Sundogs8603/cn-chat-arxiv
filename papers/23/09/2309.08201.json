{
    "title": "Gaussian Processes with Linear Multiple Kernel: Spectrum Design and Distributed Learning for Multi-Dimensional Data. (arXiv:2309.08201v1 [cs.LG])",
    "abstract": "Gaussian processes (GPs) have emerged as a prominent technique for machine learning and signal processing. A key component in GP modeling is the choice of kernel, and linear multiple kernels (LMKs) have become an attractive kernel class due to their powerful modeling capacity and interpretability. This paper focuses on the grid spectral mixture (GSM) kernel, an LMK that can approximate arbitrary stationary kernels. Specifically, we propose a novel GSM kernel formulation for multi-dimensional data that reduces the number of hyper-parameters compared to existing formulations, while also retaining a favorable optimization structure and approximation capability. In addition, to make the large-scale hyper-parameter optimization in the GSM kernel tractable, we first introduce the distributed SCA (DSCA) algorithm. Building on this, we propose the doubly distributed SCA (D$^2$SCA) algorithm based on the alternating direction method of multipliers (ADMM) framework, which allows us to cooperativ",
    "link": "http://arxiv.org/abs/2309.08201",
    "context": "Title: Gaussian Processes with Linear Multiple Kernel: Spectrum Design and Distributed Learning for Multi-Dimensional Data. (arXiv:2309.08201v1 [cs.LG])\nAbstract: Gaussian processes (GPs) have emerged as a prominent technique for machine learning and signal processing. A key component in GP modeling is the choice of kernel, and linear multiple kernels (LMKs) have become an attractive kernel class due to their powerful modeling capacity and interpretability. This paper focuses on the grid spectral mixture (GSM) kernel, an LMK that can approximate arbitrary stationary kernels. Specifically, we propose a novel GSM kernel formulation for multi-dimensional data that reduces the number of hyper-parameters compared to existing formulations, while also retaining a favorable optimization structure and approximation capability. In addition, to make the large-scale hyper-parameter optimization in the GSM kernel tractable, we first introduce the distributed SCA (DSCA) algorithm. Building on this, we propose the doubly distributed SCA (D$^2$SCA) algorithm based on the alternating direction method of multipliers (ADMM) framework, which allows us to cooperativ",
    "path": "papers/23/09/2309.08201.json",
    "total_tokens": 921,
    "translated_title": "高斯过程与线性多核：频谱设计和多维数据的分布式学习",
    "translated_abstract": "高斯过程（GPs）已成为机器学习和信号处理的重要技术。GP建模的关键组成部分是核函数的选择，线性多核（LMKs）因其强大的建模能力和可解释性而成为一个吸引人的核函数类。本文重点研究格点谱混合（GSM）核，它是一种可以近似任意平稳核的LMK。具体来说，我们提出了一种新的GSM核公式，用于多维数据，相比现有公式减少了超参数的数量，同时保留了有利的优化结构和逼近能力。此外，为了使GSM核中的大规模超参数优化变得可行，我们首先引入了分布式SCA（DSCA）算法。在此基础上，我们基于交替方向乘子法（ADMM）框架提出了双重分布式SCA（D$^2$SCA）算法，使我们能够合作地进行优化。",
    "tldr": "本文研究了高斯过程与线性多核在多维数据上的应用，提出了一种新的格点谱混合核公式，减少了超参数数量，同时保留了优化结构和逼近能力。通过引入分布式算法，使大规模超参数优化变得可行。",
    "en_tdlr": "This paper investigates the application of Gaussian processes with linear multiple kernel in multi-dimensional data, proposing a new grid spectral mixture kernel formulation that reduces the number of hyper-parameters while retaining the optimization structure and approximation capability. By introducing distributed algorithms, large-scale hyper-parameter optimization becomes feasible."
}