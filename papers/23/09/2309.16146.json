{
    "title": "T-COL: Generating Counterfactual Explanations for General User Preferences on Variable Machine Learning Systems. (arXiv:2309.16146v1 [cs.AI])",
    "abstract": "Machine learning (ML) based systems have been suffering a lack of interpretability. To address this problem, counterfactual explanations (CEs) have been proposed. CEs are unique as they provide workable suggestions to users, in addition to explaining why a certain outcome was predicted. However, the application of CEs has been hindered by two main challenges, namely general user preferences and variable ML systems. User preferences, in particular, tend to be general rather than specific feature values. Additionally, CEs need to be customized to suit the variability of ML models, while also maintaining robustness even when these validation models change. To overcome these challenges, we propose several possible general user preferences that have been validated by user research and map them to the properties of CEs. We also introduce a new method called \\uline{T}ree-based \\uline{C}onditions \\uline{O}ptional \\uline{L}inks (T-COL), which has two optional structures and several groups of co",
    "link": "http://arxiv.org/abs/2309.16146",
    "context": "Title: T-COL: Generating Counterfactual Explanations for General User Preferences on Variable Machine Learning Systems. (arXiv:2309.16146v1 [cs.AI])\nAbstract: Machine learning (ML) based systems have been suffering a lack of interpretability. To address this problem, counterfactual explanations (CEs) have been proposed. CEs are unique as they provide workable suggestions to users, in addition to explaining why a certain outcome was predicted. However, the application of CEs has been hindered by two main challenges, namely general user preferences and variable ML systems. User preferences, in particular, tend to be general rather than specific feature values. Additionally, CEs need to be customized to suit the variability of ML models, while also maintaining robustness even when these validation models change. To overcome these challenges, we propose several possible general user preferences that have been validated by user research and map them to the properties of CEs. We also introduce a new method called \\uline{T}ree-based \\uline{C}onditions \\uline{O}ptional \\uline{L}inks (T-COL), which has two optional structures and several groups of co",
    "path": "papers/23/09/2309.16146.json",
    "total_tokens": 1012,
    "translated_title": "T-COL: 为可变机器学习系统生成一般用户偏好的反事实解释",
    "translated_abstract": "基于机器学习的系统缺乏可解释性。为了解决这个问题，提出了反事实解释（CEs）。CEs独特之处在于它们不仅解释为什么会预测某个特定结果，还提供可操作的建议给用户。然而，CEs的应用受到了两个主要挑战的限制，即一般用户偏好和可变的机器学习系统。特别是，用户偏好往往是一般性的而不是特定的特征值。此外，CEs需要根据机器学习模型的可变性进行定制，并且在这些验证模型发生变化时仍然保持健壮性。为了克服这些挑战，我们提出了几个可能验证的一般用户偏好，并将它们映射到CEs的属性上。我们还引入了一种名为T-COL的新方法，它具有两种可选结构和几组协同操作。",
    "tldr": "该论文提出了一个名为T-COL的方法，针对可变的机器学习系统和一般用户偏好生成反事实解释。这些解释不仅能够解释预测结果的原因，还提供了可操作的建议给用户。通过将一般用户偏好映射到CEs的属性上，以及采用定制化的方式来适应可变的机器学习模型，T-COL能够克服现有挑战并保持健壮性。",
    "en_tdlr": "This paper proposes a method called T-COL that generates counterfactual explanations for variable machine learning systems and general user preferences. These explanations not only explain the reasons for predicted outcomes but also provide actionable suggestions to users. By mapping general user preferences to the properties of counterfactual explanations and employing customization to adapt to variable machine learning models, T-COL overcomes existing challenges and maintains robustness."
}