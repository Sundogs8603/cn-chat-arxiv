{
    "title": "Coreset selection can accelerate quantum machine learning models with provable generalization. (arXiv:2309.10441v1 [quant-ph])",
    "abstract": "Quantum neural networks (QNNs) and quantum kernels stand as prominent figures in the realm of quantum machine learning, poised to leverage the nascent capabilities of near-term quantum computers to surmount classical machine learning challenges. Nonetheless, the training efficiency challenge poses a limitation on both QNNs and quantum kernels, curbing their efficacy when applied to extensive datasets. To confront this concern, we present a unified approach: coreset selection, aimed at expediting the training of QNNs and quantum kernels by distilling a judicious subset from the original training dataset. Furthermore, we analyze the generalization error bounds of QNNs and quantum kernels when trained on such coresets, unveiling the comparable performance with those training on the complete original dataset. Through systematic numerical simulations, we illuminate the potential of coreset selection in expediting tasks encompassing synthetic data classification, identification of quantum co",
    "link": "http://arxiv.org/abs/2309.10441",
    "context": "Title: Coreset selection can accelerate quantum machine learning models with provable generalization. (arXiv:2309.10441v1 [quant-ph])\nAbstract: Quantum neural networks (QNNs) and quantum kernels stand as prominent figures in the realm of quantum machine learning, poised to leverage the nascent capabilities of near-term quantum computers to surmount classical machine learning challenges. Nonetheless, the training efficiency challenge poses a limitation on both QNNs and quantum kernels, curbing their efficacy when applied to extensive datasets. To confront this concern, we present a unified approach: coreset selection, aimed at expediting the training of QNNs and quantum kernels by distilling a judicious subset from the original training dataset. Furthermore, we analyze the generalization error bounds of QNNs and quantum kernels when trained on such coresets, unveiling the comparable performance with those training on the complete original dataset. Through systematic numerical simulations, we illuminate the potential of coreset selection in expediting tasks encompassing synthetic data classification, identification of quantum co",
    "path": "papers/23/09/2309.10441.json",
    "total_tokens": 917,
    "translated_title": "通过可证明的泛化加速量子机器学习模型的核心集选取",
    "translated_abstract": "量子神经网络和量子核在量子机器学习领域中具有突出地位，利用即将到来的近期量子计算机的能力来克服经典机器学习的挑战。然而，训练效率的挑战限制了量子神经网络和量子核在应用于大规模数据集时的效果。为了解决这个问题，我们提出了一种统一的方法：核心集选择，旨在通过从原始训练数据集中提取出一个合理的子集来加速量子神经网络和量子核的训练。此外，当在这些核心集上训练时，我们分析了量子神经网络和量子核的泛化误差界限，并揭示了与在完整原始数据集上训练相比具有可比性的性能。通过系统的数值模拟，我们展示了核心集选择在加速涵盖合成数据分类、量子协议鉴定等任务中的潜力。",
    "tldr": "本论文提出了一种统一的方法，通过从原始训练数据集中选取一个合理的子集，加速量子神经网络和量子核的训练，并分析了它们在这些核心集上训练时的泛化误差界限，揭示了与在完整原始数据集上训练相比具有可比性的性能。",
    "en_tdlr": "This paper proposes a unified approach to accelerate the training of quantum neural networks and quantum kernels by selecting a subset from the original training dataset. It analyzes the generalization error bounds of these models trained on the selected subset, revealing comparable performance with training on the complete original dataset."
}