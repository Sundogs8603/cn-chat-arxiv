{
    "title": "Neural lasso: a unifying approach of lasso and neural networks. (arXiv:2309.03770v1 [stat.ML])",
    "abstract": "In recent years, there is a growing interest in combining techniques attributed to the areas of Statistics and Machine Learning in order to obtain the benefits of both approaches. In this article, the statistical technique lasso for variable selection is represented through a neural network. It is observed that, although both the statistical approach and its neural version have the same objective function, they differ due to their optimization. In particular, the neural version is usually optimized in one-step using a single validation set, while the statistical counterpart uses a two-step optimization based on cross-validation. The more elaborated optimization of the statistical method results in more accurate parameter estimation, especially when the training set is small. For this reason, a modification of the standard approach for training neural networks, that mimics the statistical framework, is proposed. During the development of the above modification, a new optimization algori",
    "link": "http://arxiv.org/abs/2309.03770",
    "context": "Title: Neural lasso: a unifying approach of lasso and neural networks. (arXiv:2309.03770v1 [stat.ML])\nAbstract: In recent years, there is a growing interest in combining techniques attributed to the areas of Statistics and Machine Learning in order to obtain the benefits of both approaches. In this article, the statistical technique lasso for variable selection is represented through a neural network. It is observed that, although both the statistical approach and its neural version have the same objective function, they differ due to their optimization. In particular, the neural version is usually optimized in one-step using a single validation set, while the statistical counterpart uses a two-step optimization based on cross-validation. The more elaborated optimization of the statistical method results in more accurate parameter estimation, especially when the training set is small. For this reason, a modification of the standard approach for training neural networks, that mimics the statistical framework, is proposed. During the development of the above modification, a new optimization algori",
    "path": "papers/23/09/2309.03770.json",
    "total_tokens": 821,
    "translated_title": "神经套索：一种将套索和神经网络相结合的统一方法",
    "translated_abstract": "近年来，将统计和机器学习领域的技术相结合以获得两种方法的优点已经成为研究热点。本文通过神经网络来表示变量选择的统计技术套索。观察发现，尽管统计方法和神经网络版本具有相同的目标函数，但由于优化方法不同而存在差异。特别是，神经网络版本通常使用单个验证集进行一步优化，而统计对应方法基于交叉验证进行两步优化。统计方法更为精细的优化导致更准确的参数估计，尤其是在训练集较小的情况下。因此，本文提出了一种修改标准神经网络训练方法的方法，模仿统计框架。在开发上述修改的过程中，提出了一种新的优化算法。",
    "tldr": "本文提出了一种神经套索方法，将套索和神经网络相结合，通过模仿统计框架进行修改的方式，在变量选择中提供更准确的参数估计。"
}