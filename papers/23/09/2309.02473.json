{
    "title": "A Survey of Imitation Learning: Algorithms, Recent Developments, and Challenges. (arXiv:2309.02473v1 [cs.LG])",
    "abstract": "In recent years, the development of robotics and artificial intelligence (AI) systems has been nothing short of remarkable. As these systems continue to evolve, they are being utilized in increasingly complex and unstructured environments, such as autonomous driving, aerial robotics, and natural language processing. As a consequence, programming their behaviors manually or defining their behavior through reward functions (as done in reinforcement learning (RL)) has become exceedingly difficult. This is because such environments require a high degree of flexibility and adaptability, making it challenging to specify an optimal set of rules or reward signals that can account for all possible situations. In such environments, learning from an expert's behavior through imitation is often more appealing. This is where imitation learning (IL) comes into play - a process where desired behavior is learned by imitating an expert's behavior, which is provided through demonstrations.  This paper a",
    "link": "http://arxiv.org/abs/2309.02473",
    "context": "Title: A Survey of Imitation Learning: Algorithms, Recent Developments, and Challenges. (arXiv:2309.02473v1 [cs.LG])\nAbstract: In recent years, the development of robotics and artificial intelligence (AI) systems has been nothing short of remarkable. As these systems continue to evolve, they are being utilized in increasingly complex and unstructured environments, such as autonomous driving, aerial robotics, and natural language processing. As a consequence, programming their behaviors manually or defining their behavior through reward functions (as done in reinforcement learning (RL)) has become exceedingly difficult. This is because such environments require a high degree of flexibility and adaptability, making it challenging to specify an optimal set of rules or reward signals that can account for all possible situations. In such environments, learning from an expert's behavior through imitation is often more appealing. This is where imitation learning (IL) comes into play - a process where desired behavior is learned by imitating an expert's behavior, which is provided through demonstrations.  This paper a",
    "path": "papers/23/09/2309.02473.json",
    "total_tokens": 800,
    "translated_title": "模仿学习综述：算法、最新进展与挑战",
    "translated_abstract": "近年来，机器人和人工智能系统的发展令人瞩目。随着这些系统的不断演进，它们越来越被应用于复杂和非结构化的环境中，如自动驾驶、空中机器人和自然语言处理。由于这些环境需要高度的灵活性和适应性，因此手动编程行为或通过奖励函数来定义行为（如强化学习中的做法）变得非常困难。在这样的环境中，通过模仿专家行为来学习更具吸引力。这就是模仿学习的作用 - 通过模仿专家的行为来学习所期望的行为，而这些行为是通过演示提供的。",
    "tldr": "这篇论文综述了模仿学习的算法、最新进展和挑战，指出在复杂和非结构化的环境中，通过模仿专家行为来学习所需行为更具吸引力。",
    "en_tdlr": "This paper provides a survey of imitation learning, discussing algorithms, recent developments, and challenges. It highlights that learning desired behavior by imitating an expert's behavior is more appealing in complex and unstructured environments."
}