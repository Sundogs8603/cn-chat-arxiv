{
    "title": "Learning to Transform for Generalizable Instance-wise Invariance. (arXiv:2309.16672v1 [cs.CV])",
    "abstract": "Computer vision research has long aimed to build systems that are robust to spatial transformations found in natural data. Traditionally, this is done using data augmentation or hard-coding invariances into the architecture. However, too much or too little invariance can hurt, and the correct amount is unknown a priori and dependent on the instance. Ideally, the appropriate invariance would be learned from data and inferred at test-time.  We treat invariance as a prediction problem. Given any image, we use a normalizing flow to predict a distribution over transformations and average the predictions over them. Since this distribution only depends on the instance, we can align instances before classifying them and generalize invariance across classes. The same distribution can also be used to adapt to out-of-distribution poses. This normalizing flow is trained end-to-end and can learn a much larger range of transformations than Augerino and InstaAug. When used as data augmentation, our m",
    "link": "http://arxiv.org/abs/2309.16672",
    "context": "Title: Learning to Transform for Generalizable Instance-wise Invariance. (arXiv:2309.16672v1 [cs.CV])\nAbstract: Computer vision research has long aimed to build systems that are robust to spatial transformations found in natural data. Traditionally, this is done using data augmentation or hard-coding invariances into the architecture. However, too much or too little invariance can hurt, and the correct amount is unknown a priori and dependent on the instance. Ideally, the appropriate invariance would be learned from data and inferred at test-time.  We treat invariance as a prediction problem. Given any image, we use a normalizing flow to predict a distribution over transformations and average the predictions over them. Since this distribution only depends on the instance, we can align instances before classifying them and generalize invariance across classes. The same distribution can also be used to adapt to out-of-distribution poses. This normalizing flow is trained end-to-end and can learn a much larger range of transformations than Augerino and InstaAug. When used as data augmentation, our m",
    "path": "papers/23/09/2309.16672.json",
    "total_tokens": 989,
    "translated_title": "学习转换以实现通用的实例不变性",
    "translated_abstract": "计算机视觉研究一直致力于构建对自然数据中的空间变换具有强鲁棒性的系统。传统上，可以通过数据增强或将不变性硬编码到架构中来实现这一点。然而，过多或过少的不变性都可能会影响结果，正确的不变性程度在先验中是未知的，并且依赖于实例。理想情况下，应该从数据中学习适当的不变性，并在测试时推断。我们将不变性视为一个预测问题。给定任何图像，我们使用一个归一化流来预测变换的分布，并对它们的预测进行平均。由于这个分布仅取决于实例，我们可以在分类之前对实例进行对齐，并在类别之间推广不变性。同样的分布也可以用于适应超出分布的姿势。这个归一化流是端到端训练的，并且可以学习比Augerino和InstaAug更多范围的变换。当用作数据增强时，我们的m",
    "tldr": "该论文提出了一种学习转换以实现通用的实例不变性的方法。通过使用归一化流来预测图像的变换分布，并对预测结果进行平均，可以实现对不同实例之间的对齐，从而推广不变性的类别间的应用。这种方法还可以适应超出分布范围的姿势，并且可以学习更广泛的变换范围。",
    "en_tdlr": "This paper proposes a method for learning transformations to achieve generalizable instance-wise invariance. By using a normalizing flow to predict the distribution of transformations and averaging the predictions, it enables alignment between different instances and generalization of invariance across classes. The method can also adapt to out-of-distribution poses and learn a larger range of transformations."
}