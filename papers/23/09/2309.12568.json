{
    "title": "A Study on Learning Social Robot Navigation with Multimodal Perception. (arXiv:2309.12568v1 [cs.RO])",
    "abstract": "Autonomous mobile robots need to perceive the environments with their onboard sensors (e.g., LiDARs and RGB cameras) and then make appropriate navigation decisions. In order to navigate human-inhabited public spaces, such a navigation task becomes more than only obstacle avoidance, but also requires considering surrounding humans and their intentions to somewhat change the navigation behavior in response to the underlying social norms, i.e., being socially compliant. Machine learning methods are shown to be effective in capturing those complex and subtle social interactions in a data-driven manner, without explicitly hand-crafting simplified models or cost functions. Considering multiple available sensor modalities and the efficiency of learning methods, this paper presents a comprehensive study on learning social robot navigation with multimodal perception using a large-scale real-world dataset. The study investigates social robot navigation decision making on both the global and loca",
    "link": "http://arxiv.org/abs/2309.12568",
    "context": "Title: A Study on Learning Social Robot Navigation with Multimodal Perception. (arXiv:2309.12568v1 [cs.RO])\nAbstract: Autonomous mobile robots need to perceive the environments with their onboard sensors (e.g., LiDARs and RGB cameras) and then make appropriate navigation decisions. In order to navigate human-inhabited public spaces, such a navigation task becomes more than only obstacle avoidance, but also requires considering surrounding humans and their intentions to somewhat change the navigation behavior in response to the underlying social norms, i.e., being socially compliant. Machine learning methods are shown to be effective in capturing those complex and subtle social interactions in a data-driven manner, without explicitly hand-crafting simplified models or cost functions. Considering multiple available sensor modalities and the efficiency of learning methods, this paper presents a comprehensive study on learning social robot navigation with multimodal perception using a large-scale real-world dataset. The study investigates social robot navigation decision making on both the global and loca",
    "path": "papers/23/09/2309.12568.json",
    "total_tokens": 926,
    "translated_title": "一项关于利用多模态感知学习社交机器人导航的研究",
    "translated_abstract": "自主移动机器人需要利用其搭载的传感器（如LiDAR和RGB摄像头）感知环境，然后做出适当的导航决策。为了在人类居住的公共空间中进行导航任务，这样的导航任务不仅仅是避开障碍物，还需要考虑周围的人和他们的意图，以在对底层社会规范的响应中改变导航行为，即社会合规性。机器学习方法已被证明在以数据驱动方式捕捉这些复杂而微妙的社交互动方面是有效的，而无需显式手工制作简化模型或成本函数。考虑到多种可用的传感器模态和学习方法的效率，本文提出了一项利用大规模真实世界数据集进行多模态感知学习社交机器人导航的综合研究。该研究在全局和局部层面上探讨了社交机器人导航决策制定的问题。",
    "tldr": "本文通过利用大规模真实世界数据集，综合研究了利用多模态感知学习社交机器人导航的方法。研究结果发现，机器学习方法可以有效地捕捉复杂而微妙的社交互动，而无需手工制作简化模型或成本函数。"
}