{
    "title": "Seeing and hearing what has not been said; A multimodal client behavior classifier in Motivational Interviewing with interpretable fusion. (arXiv:2309.14398v1 [cs.LG])",
    "abstract": "Motivational Interviewing (MI) is an approach to therapy that emphasizes collaboration and encourages behavioral change. To evaluate the quality of an MI conversation, client utterances can be classified using the MISC code as either change talk, sustain talk, or follow/neutral talk. The proportion of change talk in a MI conversation is positively correlated with therapy outcomes, making accurate classification of client utterances essential. In this paper, we present a classifier that accurately distinguishes between the three MISC classes (change talk, sustain talk, and follow/neutral talk) leveraging multimodal features such as text, prosody, facial expressivity, and body expressivity. To train our model, we perform annotations on the publicly available AnnoMI dataset to collect multimodal information, including text, audio, facial expressivity, and body expressivity. Furthermore, we identify the most important modalities in the decision-making process, providing valuable insights i",
    "link": "http://arxiv.org/abs/2309.14398",
    "context": "Title: Seeing and hearing what has not been said; A multimodal client behavior classifier in Motivational Interviewing with interpretable fusion. (arXiv:2309.14398v1 [cs.LG])\nAbstract: Motivational Interviewing (MI) is an approach to therapy that emphasizes collaboration and encourages behavioral change. To evaluate the quality of an MI conversation, client utterances can be classified using the MISC code as either change talk, sustain talk, or follow/neutral talk. The proportion of change talk in a MI conversation is positively correlated with therapy outcomes, making accurate classification of client utterances essential. In this paper, we present a classifier that accurately distinguishes between the three MISC classes (change talk, sustain talk, and follow/neutral talk) leveraging multimodal features such as text, prosody, facial expressivity, and body expressivity. To train our model, we perform annotations on the publicly available AnnoMI dataset to collect multimodal information, including text, audio, facial expressivity, and body expressivity. Furthermore, we identify the most important modalities in the decision-making process, providing valuable insights i",
    "path": "papers/23/09/2309.14398.json",
    "total_tokens": 981,
    "translated_title": "看见和听到没被说的话：可解释融合的多模态动机性访谈客户行为分类器",
    "translated_abstract": "动机性访谈（MI）是一种强调合作并鼓励行为改变的治疗方法。为了评估MI对话的质量，可以利用MISC代码将客户话语分类为变化话语、持续话语或跟随/中立话语。MI对话中变化话语的比例与治疗结果呈正相关，因此准确分类客户话语至关重要。本文提出了一个分类器，利用文本、声调、面部表情和身体表现等多模态特征准确区分三个MISC类别（变化话语、持续话语和跟随/中立话语）。为了训练我们的模型，我们对公开可用的AnnoMI数据集进行注释，收集了文本、音频、面部表情和身体表现等多模态信息。此外，我们还确定了决策过程中最重要的模态，提供了宝贵的洞察。",
    "tldr": "本文提出了一个多模态分类器，在动机性访谈中准确区分了变化话语、持续话语和跟随/中立话语三种类别。该分类器利用文本、声调、面部表情和身体表现等多模态特征，并对AnnoMI数据集进行了注释和训练。研究还找到了决策过程中最重要的模态，提供了宝贵的洞察。",
    "en_tdlr": "This paper presents a multimodal classifier that accurately distinguishes between change talk, sustain talk, and follow/neutral talk in Motivational Interviewing. The classifier utilizes text, prosody, facial expressivity, and body expressivity as features, and is trained on the annotated AnnoMI dataset. The study also identifies the most important modalities in the decision-making process, providing valuable insights."
}