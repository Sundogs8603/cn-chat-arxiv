{
    "title": "ModelGiF: Gradient Fields for Model Functional Distance. (arXiv:2309.11013v1 [cs.LG])",
    "abstract": "The last decade has witnessed the success of deep learning and the surge of publicly released trained models, which necessitates the quantification of the model functional distance for various purposes. However, quantifying the model functional distance is always challenging due to the opacity in inner workings and the heterogeneity in architectures or tasks. Inspired by the concept of \"field\" in physics, in this work we introduce Model Gradient Field (abbr. ModelGiF) to extract homogeneous representations from the heterogeneous pre-trained models. Our main assumption underlying ModelGiF is that each pre-trained deep model uniquely determines a ModelGiF over the input space. The distance between models can thus be measured by the similarity between their ModelGiFs. We validate the effectiveness of the proposed ModelGiF with a suite of testbeds, including task relatedness estimation, intellectual property protection, and model unlearning verification. Experimental results demonstrate th",
    "link": "http://arxiv.org/abs/2309.11013",
    "context": "Title: ModelGiF: Gradient Fields for Model Functional Distance. (arXiv:2309.11013v1 [cs.LG])\nAbstract: The last decade has witnessed the success of deep learning and the surge of publicly released trained models, which necessitates the quantification of the model functional distance for various purposes. However, quantifying the model functional distance is always challenging due to the opacity in inner workings and the heterogeneity in architectures or tasks. Inspired by the concept of \"field\" in physics, in this work we introduce Model Gradient Field (abbr. ModelGiF) to extract homogeneous representations from the heterogeneous pre-trained models. Our main assumption underlying ModelGiF is that each pre-trained deep model uniquely determines a ModelGiF over the input space. The distance between models can thus be measured by the similarity between their ModelGiFs. We validate the effectiveness of the proposed ModelGiF with a suite of testbeds, including task relatedness estimation, intellectual property protection, and model unlearning verification. Experimental results demonstrate th",
    "path": "papers/23/09/2309.11013.json",
    "total_tokens": 921,
    "translated_title": "ModelGiF: 模型功能距离的梯度场",
    "translated_abstract": "过去十年见证了深度学习的成功和公开发布的训练模型的激增，这就需要对各种目的的模型功能距离进行量化。然而，由于内部工作的不透明性和体系结构或任务的异质性，量化模型功能距离始终具有挑战性。受物理学中“场”概念的启发，本文引入了模型梯度场（简称ModelGiF），从异构的预训练模型中提取同质的表示。我们的主要假设是，每个预训练深度模型在输入空间上唯一确定一个ModelGiF。因此，模型之间的距离可以通过它们的ModelGiF的相似性来衡量。我们使用一系列实验验证了所提出的ModelGiF的有效性，包括任务相关性估计、知识产权保护和模型遗忘验证。实验结果证明了其有效性。",
    "tldr": "本文介绍了一种用于测量模型功能距离的方法，称为ModelGiF。通过在异构的预训练模型中提取同质的表示，ModelGiF可通过模型之间的相似性来衡量它们之间的距离。实验证实了该方法在任务相关性估计、知识产权保护和模型遗忘验证等方面的有效性。"
}