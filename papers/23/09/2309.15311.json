{
    "title": "The Importance of Multimodal Emotion Conditioning and Affect Consistency for Embodied Conversational Agents. (arXiv:2309.15311v1 [cs.HC])",
    "abstract": "Previous studies regarding the perception of emotions for embodied virtual agents have shown the effectiveness of using virtual characters in conveying emotions through interactions with humans. However, creating an autonomous embodied conversational agent with expressive behaviors presents two major challenges. The first challenge is the difficulty of synthesizing the conversational behaviors for each modality that are as expressive as real human behaviors. The second challenge is that the affects are modeled independently, which makes it difficult to generate multimodal responses with consistent emotions across all modalities. In this work, we propose a conceptual framework, ACTOR (Affect-Consistent mulTimodal behaviOR generation), that aims to increase the perception of affects by generating multimodal behaviors conditioned on a consistent driving affect. We have conducted a user study with 199 participants to assess how the average person judges the affects perceived from multimoda",
    "link": "http://arxiv.org/abs/2309.15311",
    "context": "Title: The Importance of Multimodal Emotion Conditioning and Affect Consistency for Embodied Conversational Agents. (arXiv:2309.15311v1 [cs.HC])\nAbstract: Previous studies regarding the perception of emotions for embodied virtual agents have shown the effectiveness of using virtual characters in conveying emotions through interactions with humans. However, creating an autonomous embodied conversational agent with expressive behaviors presents two major challenges. The first challenge is the difficulty of synthesizing the conversational behaviors for each modality that are as expressive as real human behaviors. The second challenge is that the affects are modeled independently, which makes it difficult to generate multimodal responses with consistent emotions across all modalities. In this work, we propose a conceptual framework, ACTOR (Affect-Consistent mulTimodal behaviOR generation), that aims to increase the perception of affects by generating multimodal behaviors conditioned on a consistent driving affect. We have conducted a user study with 199 participants to assess how the average person judges the affects perceived from multimoda",
    "path": "papers/23/09/2309.15311.json",
    "total_tokens": 912,
    "translated_title": "多模态情感调节和情感一致性对于具身对话智能体的重要性",
    "translated_abstract": "先前有关对于具身虚拟智能体情感感知的研究表明，使用虚拟角色通过与人类的互动传达情感的有效性。然而，创建一个具有表达行为的自主具身对话智能体面临着两个主要挑战。第一个挑战是合成每种模态的对话行为非常表达性，像真实人类行为一样具有表达性的困难。第二个挑战是情感被独立建模，这使得难以生成在所有模态上具有一致情感的多模态响应。在这项工作中，我们提出了一个概念性框架ACTOR（一致性情感多模态行为生成），旨在通过生成以一致驱动情感为条件的多模态行为来增强情感感知。我们进行了一项用户研究，并招募了199名参与者，以评估普通人如何判断从多模态状态下感知到的情感。",
    "tldr": "本研究提出了一个概念性框架ACTOR，通过生成以一致驱动情感为条件的多模态行为，旨在增强感知情感。研究发现，在具备表达行为的具身对话智能体中，多模态情感调节和情感一致性至关重要。",
    "en_tdlr": "This study proposes a conceptual framework, ACTOR, for enhancing affect perception in embodied conversational agents by generating multimodal behaviors conditioned on a consistent driving affect. The study finds that multimodal emotion conditioning and affect consistency are crucial for embodied conversational agents with expressive behaviors."
}