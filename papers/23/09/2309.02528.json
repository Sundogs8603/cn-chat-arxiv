{
    "title": "Adaptive Adversarial Training Does Not Increase Recourse Costs. (arXiv:2309.02528v1 [cs.LG])",
    "abstract": "Recent work has connected adversarial attack methods and algorithmic recourse methods: both seek minimal changes to an input instance which alter a model's classification decision. It has been shown that traditional adversarial training, which seeks to minimize a classifier's susceptibility to malicious perturbations, increases the cost of generated recourse; with larger adversarial training radii correlating with higher recourse costs. From the perspective of algorithmic recourse, however, the appropriate adversarial training radius has always been unknown. Another recent line of work has motivated adversarial training with adaptive training radii to address the issue of instance-wise variable adversarial vulnerability, showing success in domains with unknown attack radii. This work studies the effects of adaptive adversarial training on algorithmic recourse costs. We establish that the improvements in model robustness induced by adaptive adversarial training show little effect on alg",
    "link": "http://arxiv.org/abs/2309.02528",
    "context": "Title: Adaptive Adversarial Training Does Not Increase Recourse Costs. (arXiv:2309.02528v1 [cs.LG])\nAbstract: Recent work has connected adversarial attack methods and algorithmic recourse methods: both seek minimal changes to an input instance which alter a model's classification decision. It has been shown that traditional adversarial training, which seeks to minimize a classifier's susceptibility to malicious perturbations, increases the cost of generated recourse; with larger adversarial training radii correlating with higher recourse costs. From the perspective of algorithmic recourse, however, the appropriate adversarial training radius has always been unknown. Another recent line of work has motivated adversarial training with adaptive training radii to address the issue of instance-wise variable adversarial vulnerability, showing success in domains with unknown attack radii. This work studies the effects of adaptive adversarial training on algorithmic recourse costs. We establish that the improvements in model robustness induced by adaptive adversarial training show little effect on alg",
    "path": "papers/23/09/2309.02528.json",
    "total_tokens": 861,
    "translated_title": "自适应对抗训练不增加追溯成本",
    "translated_abstract": "最近的研究将对抗攻击和算法回溯方法联系在一起：两者都寻求对输入实例进行最小更改，以改变模型的分类决策。已经证明，传统的对抗训练会增加生成回溯的成本；对抗训练半径越大，回溯成本越高。然而，从算法回溯的角度来看，适当的对抗训练半径一直是未知的。最近的研究工作提出了利用自适应训练半径进行对抗训练的方法，以解决实例间可变对抗脆弱性的问题，在未知攻击半径的领域取得了成功。本文研究了自适应对抗训练对算法回溯成本的影响。我们证明，自适应对抗训练所引起的模型鲁棒性的改进对算法回溯成本几乎没有影响。",
    "tldr": "本文研究了自适应对抗训练对算法回溯成本的影响，证明了自适应对抗训练所引起的模型鲁棒性的改进对算法回溯成本几乎没有影响。"
}