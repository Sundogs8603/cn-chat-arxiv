{
    "title": "Non-Asymptotic Bounds for Adversarial Excess Risk under Misspecified Models. (arXiv:2309.00771v1 [stat.ML])",
    "abstract": "We propose a general approach to evaluating the performance of robust estimators based on adversarial losses under misspecified models. We first show that adversarial risk is equivalent to the risk induced by a distributional adversarial attack under certain smoothness conditions. This ensures that the adversarial training procedure is well-defined. To evaluate the generalization performance of the adversarial estimator, we study the adversarial excess risk. Our proposed analysis method includes investigations on both generalization error and approximation error. We then establish non-asymptotic upper bounds for the adversarial excess risk associated with Lipschitz loss functions. In addition, we apply our general results to adversarial training for classification and regression problems. For the quadratic loss in nonparametric regression, we show that the adversarial excess risk bound can be improved over those for a general loss.",
    "link": "http://arxiv.org/abs/2309.00771",
    "context": "Title: Non-Asymptotic Bounds for Adversarial Excess Risk under Misspecified Models. (arXiv:2309.00771v1 [stat.ML])\nAbstract: We propose a general approach to evaluating the performance of robust estimators based on adversarial losses under misspecified models. We first show that adversarial risk is equivalent to the risk induced by a distributional adversarial attack under certain smoothness conditions. This ensures that the adversarial training procedure is well-defined. To evaluate the generalization performance of the adversarial estimator, we study the adversarial excess risk. Our proposed analysis method includes investigations on both generalization error and approximation error. We then establish non-asymptotic upper bounds for the adversarial excess risk associated with Lipschitz loss functions. In addition, we apply our general results to adversarial training for classification and regression problems. For the quadratic loss in nonparametric regression, we show that the adversarial excess risk bound can be improved over those for a general loss.",
    "path": "papers/23/09/2309.00771.json",
    "total_tokens": 960,
    "translated_title": "攻击性过剩风险在错误指定模型下的非渐近界限",
    "translated_abstract": "我们提出了一种评估基于错误指定模型下的鲁棒估计器性能的通用方法，该方法基于攻击性损失。我们首先展示了在一定的平滑条件下，攻击性风险等同于由分布攻击导致的风险，这确保了攻击性训练过程的良好定义性。为了评估攻击性估计器的泛化性能，我们研究了攻击性过剩风险。我们提出的分析方法包括对泛化误差和逼近误差的调查。然后，我们建立了与利普西茨损失函数相关的攻击性过剩风险的非渐近上界。此外，我们将我们的通用结果应用于分类和回归问题的攻击性训练。对于非参数回归中的二次损失，我们展示了攻击性过剩风险界限可以优于一般损失的结果。",
    "tldr": "我们提出了一种通用方法来评估在错误指定模型下基于攻击性损失的鲁棒估计器的性能。我们研究了攻击性过剩风险，并建立了与利普西茨损失函数相关的非渐近上界。在二次损失的非参数回归中，我们展示了攻击性过剩风险界限优于一般损失的结果。",
    "en_tdlr": "We propose a general approach to evaluate the performance of robust estimators based on adversarial losses under misspecified models. We study the adversarial excess risk and establish non-asymptotic upper bounds for the adversarial excess risk associated with Lipschitz loss functions. In nonparametric regression with quadratic loss, we show that the adversarial excess risk bound can be improved over those for a general loss."
}