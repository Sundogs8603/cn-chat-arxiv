{
    "title": "A deep Natural Language Inference predictor without language-specific training data. (arXiv:2309.02887v1 [cs.CL])",
    "abstract": "In this paper we present a technique of NLP to tackle the problem of inference relation (NLI) between pairs of sentences in a target language of choice without a language-specific training dataset. We exploit a generic translation dataset, manually translated, along with two instances of the same pre-trained model - the first to generate sentence embeddings for the source language, and the second fine-tuned over the target language to mimic the first. This technique is known as Knowledge Distillation. The model has been evaluated over machine translated Stanford NLI test dataset, machine translated Multi-Genre NLI test dataset, and manually translated RTE3-ITA test dataset. We also test the proposed architecture over different tasks to empirically demonstrate the generality of the NLI task. The model has been evaluated over the native Italian ABSITA dataset, on the tasks of Sentiment Analysis, Aspect-Based Sentiment Analysis, and Topic Recognition. We emphasise the generality and explo",
    "link": "http://arxiv.org/abs/2309.02887",
    "context": "Title: A deep Natural Language Inference predictor without language-specific training data. (arXiv:2309.02887v1 [cs.CL])\nAbstract: In this paper we present a technique of NLP to tackle the problem of inference relation (NLI) between pairs of sentences in a target language of choice without a language-specific training dataset. We exploit a generic translation dataset, manually translated, along with two instances of the same pre-trained model - the first to generate sentence embeddings for the source language, and the second fine-tuned over the target language to mimic the first. This technique is known as Knowledge Distillation. The model has been evaluated over machine translated Stanford NLI test dataset, machine translated Multi-Genre NLI test dataset, and manually translated RTE3-ITA test dataset. We also test the proposed architecture over different tasks to empirically demonstrate the generality of the NLI task. The model has been evaluated over the native Italian ABSITA dataset, on the tasks of Sentiment Analysis, Aspect-Based Sentiment Analysis, and Topic Recognition. We emphasise the generality and explo",
    "path": "papers/23/09/2309.02887.json",
    "total_tokens": 909,
    "translated_title": "一种没有语言特定训练数据的深度自然语言推理预测器",
    "translated_abstract": "本文介绍了一种处理目标语言句子对之间推理关系（NLI）问题的自然语言处理技术，无需语言特定的训练数据集。我们利用一个通用的手动翻译数据集，并利用同一个预训练模型的两个实例——第一个用于生成源语言的句子嵌入，第二个在目标语言上进行微调以模仿第一个实例。这种技术称为知识蒸馏。我们将模型在机器翻译的斯坦福NLI测试数据集、机器翻译的多类型NLI测试数据集和手动翻译的RTE3-ITA测试数据集上进行了评估。我们还在不同任务上测试了所提出的体系结构，以实证地展示NLI任务的通用性。模型在意大利本地的ABSITA数据集上的情感分析、基于方面的情感分析和主题识别任务上进行了评估。",
    "tldr": "本文介绍了一种处理目标语言句子对之间推理关系问题的新方法，该方法不需要特定语言的训练数据集。通过利用一个通用的翻译数据集和两个预训练模型的实例，模型可以在不同任务上展现出通用性，且在多个数据集上得到了验证。",
    "en_tdlr": "This paper presents a novel approach for dealing with the problem of inference relation between pairs of sentences in a target language without language-specific training data. The technique utilizes a generic translation dataset and pre-trained models to achieve generality and has been validated on multiple datasets."
}