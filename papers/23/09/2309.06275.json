{
    "title": "Re-Reading Improves Reasoning in Language Models. (arXiv:2309.06275v1 [cs.CL])",
    "abstract": "Reasoning presents a significant and challenging issue for Large Language Models (LLMs). The predominant focus of research has revolved around developing diverse prompting strategies to guide and structure the reasoning processes of LLMs. However, these approaches based on decoder-only causal language models often operate the input question in a single forward pass, potentially missing the rich, back-and-forth interactions inherent in human reasoning. Scant attention has been paid to a critical dimension, i.e., the input question itself embedded within the prompts. In response, we introduce a deceptively simple yet highly effective prompting strategy, termed question \"re-reading\". Drawing inspiration from human learning and problem-solving, re-reading entails revisiting the question information embedded within input prompts. This approach aligns seamlessly with the cognitive principle of reinforcement, enabling LLMs to extract deeper insights, identify intricate patterns, establish mor",
    "link": "http://arxiv.org/abs/2309.06275",
    "context": "Title: Re-Reading Improves Reasoning in Language Models. (arXiv:2309.06275v1 [cs.CL])\nAbstract: Reasoning presents a significant and challenging issue for Large Language Models (LLMs). The predominant focus of research has revolved around developing diverse prompting strategies to guide and structure the reasoning processes of LLMs. However, these approaches based on decoder-only causal language models often operate the input question in a single forward pass, potentially missing the rich, back-and-forth interactions inherent in human reasoning. Scant attention has been paid to a critical dimension, i.e., the input question itself embedded within the prompts. In response, we introduce a deceptively simple yet highly effective prompting strategy, termed question \"re-reading\". Drawing inspiration from human learning and problem-solving, re-reading entails revisiting the question information embedded within input prompts. This approach aligns seamlessly with the cognitive principle of reinforcement, enabling LLMs to extract deeper insights, identify intricate patterns, establish mor",
    "path": "papers/23/09/2309.06275.json",
    "total_tokens": 915,
    "translated_title": "重新阅读改善语言模型的推理能力",
    "translated_abstract": "推理对于大型语言模型（LLM）是一个重要而具有挑战性的问题。目前的研究主要集中在开发多样化的提示策略，以引导和结构化LLM的推理过程。然而，这些基于仅解码的因果语言模型的方法通常在单个前向传递中操作输入问题，可能会忽略人类推理中丰富的前后交互。对于嵌入在提示中的输入问题这一关键维度，目前关注较少。为此，我们引入了一种简单但高效的提示策略，称为“重新阅读”。从人类学习和问题解决中汲取灵感，重新阅读意味着重访嵌在输入提示中的问题信息。这种方法与认知增强的原则完美契合，使LLM能够深入洞察、识别复杂的模式、建立 mor",
    "tldr": "许多研究关注于如何引导和结构化大型语言模型的推理过程，但很少有研究关注于输入问题本身。本研究引入了一种称为“重新阅读”的提示策略，通过深入阅读输入提示中的问题信息，提供了更深入的洞察、更准确的模式识别和更有效的推理能力。",
    "en_tdlr": "While much research has focused on guiding and structuring the reasoning processes of Large Language Models (LLMs), little attention has been paid to the input question itself. This study introduces a prompting strategy called \"re-reading\" that enables LLMs to gain deeper insights, identify intricate patterns, and improve reasoning abilities by revisiting the question information embedded within input prompts."
}