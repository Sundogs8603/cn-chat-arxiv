{
    "title": "Hide and Seek (HaS): A Lightweight Framework for Prompt Privacy Protection. (arXiv:2309.03057v1 [cs.CR])",
    "abstract": "Numerous companies have started offering services based on large language models (LLM), such as ChatGPT, which inevitably raises privacy concerns as users' prompts are exposed to the model provider. Previous research on secure reasoning using multi-party computation (MPC) has proven to be impractical for LLM applications due to its time-consuming and communication-intensive nature. While lightweight anonymization techniques can protect private information in prompts through substitution or masking, they fail to recover sensitive data replaced in the LLM-generated results. In this paper, we expand the application scenarios of anonymization techniques by training a small local model to de-anonymize the LLM's returned results with minimal computational overhead. We introduce the HaS framework, where \"H(ide)\" and \"S(eek)\" represent its two core processes: hiding private entities for anonymization and seeking private entities for de-anonymization, respectively. To quantitatively assess HaS'",
    "link": "http://arxiv.org/abs/2309.03057",
    "context": "Title: Hide and Seek (HaS): A Lightweight Framework for Prompt Privacy Protection. (arXiv:2309.03057v1 [cs.CR])\nAbstract: Numerous companies have started offering services based on large language models (LLM), such as ChatGPT, which inevitably raises privacy concerns as users' prompts are exposed to the model provider. Previous research on secure reasoning using multi-party computation (MPC) has proven to be impractical for LLM applications due to its time-consuming and communication-intensive nature. While lightweight anonymization techniques can protect private information in prompts through substitution or masking, they fail to recover sensitive data replaced in the LLM-generated results. In this paper, we expand the application scenarios of anonymization techniques by training a small local model to de-anonymize the LLM's returned results with minimal computational overhead. We introduce the HaS framework, where \"H(ide)\" and \"S(eek)\" represent its two core processes: hiding private entities for anonymization and seeking private entities for de-anonymization, respectively. To quantitatively assess HaS'",
    "path": "papers/23/09/2309.03057.json",
    "total_tokens": 918,
    "translated_title": "Hide and Seek (HaS): 一种用于保护隐私的轻量级提示隐私保护框架的研究",
    "translated_abstract": "许多公司已开始提供基于大型语言模型 (LLM) 的服务，如 ChatGPT，这不可避免地引起了隐私问题，因为用户的提示暴露给了模型提供者。之前关于使用多方计算 (MPC) 进行安全推理的研究已经证明对于 LLM 应用来说不可行，因为它耗时且通信密集。虽然轻量级的匿名化技术可以通过替换或掩盖来保护提示中的私人信息，但它们无法恢复 LLM 生成的结果中替换的敏感数据。本文通过训练一个小型本地模型来解匿名化 LLM 返回的结果，从而扩展了匿名化技术的应用场景，并且计算开销最小化。我们介绍了 Hide and Seek (HaS) 框架，其中 \"Hide\" 和 \"Seek\" 分别代表其两个核心过程：隐藏私有实体以进行匿名化，寻找私有实体以进行解匿名化。为了定量评估 HaS 的性能，",
    "tldr": "本论文提出了一种名为Hide and Seek (HaS)的轻量级框架，通过训练一个小型本地模型，可以在保护用户隐私的同时，对大型语言模型返回的结果进行解匿名化。",
    "en_tdlr": "This paper proposes a lightweight framework called Hide and Seek (HaS), which trains a small local model to de-anonymize the results generated by large language models, thus protecting user privacy while also providing the ability to recover sensitive data."
}