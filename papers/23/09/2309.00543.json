{
    "title": "Curating Naturally Adversarial Datasets for Trustworthy AI in Healthcare. (arXiv:2309.00543v1 [cs.LG])",
    "abstract": "Deep learning models have shown promising predictive accuracy for time-series healthcare applications. However, ensuring the robustness of these models is vital for building trustworthy AI systems. Existing research predominantly focuses on robustness to synthetic adversarial examples, crafted by adding imperceptible perturbations to clean input data. However, these synthetic adversarial examples do not accurately reflect the most challenging real-world scenarios, especially in the context of healthcare data. Consequently, robustness to synthetic adversarial examples may not necessarily translate to robustness against naturally occurring adversarial examples, which is highly desirable for trustworthy AI. We propose a method to curate datasets comprised of natural adversarial examples to evaluate model robustness. The method relies on probabilistic labels obtained from automated weakly-supervised labeling that combines noisy and cheap-to-obtain labeling heuristics. Based on these labels",
    "link": "http://arxiv.org/abs/2309.00543",
    "context": "Title: Curating Naturally Adversarial Datasets for Trustworthy AI in Healthcare. (arXiv:2309.00543v1 [cs.LG])\nAbstract: Deep learning models have shown promising predictive accuracy for time-series healthcare applications. However, ensuring the robustness of these models is vital for building trustworthy AI systems. Existing research predominantly focuses on robustness to synthetic adversarial examples, crafted by adding imperceptible perturbations to clean input data. However, these synthetic adversarial examples do not accurately reflect the most challenging real-world scenarios, especially in the context of healthcare data. Consequently, robustness to synthetic adversarial examples may not necessarily translate to robustness against naturally occurring adversarial examples, which is highly desirable for trustworthy AI. We propose a method to curate datasets comprised of natural adversarial examples to evaluate model robustness. The method relies on probabilistic labels obtained from automated weakly-supervised labeling that combines noisy and cheap-to-obtain labeling heuristics. Based on these labels",
    "path": "papers/23/09/2309.00543.json",
    "total_tokens": 877,
    "translated_title": "为了构建可信赖的医疗AI系统，筛选天然对立数据集",
    "translated_abstract": "深度学习模型在时间序列的医疗应用中展示出了有希望的预测准确性。然而，确保这些模型的鲁棒性对于构建可信赖的AI系统至关重要。现有研究主要关注于对合成对立示例的鲁棒性，这些示例是通过向清洁输入数据添加难以察觉的扰动而制作出来的。然而，这些合成对立示例并不能准确反映最具挑战性的现实场景，特别是在医疗数据的背景下。因此，对合成对立示例的鲁棒性未必能够转化为对自然产生的对立示例的鲁棒性，而这对于可信赖的AI而言是非常重要的。我们提出了一种筛选由自然对立示例组成的数据集来评估模型鲁棒性的方法。该方法依赖于通过自动弱监督标注获得的概率标签，这种标签结合了嘈杂且易获得的标注启发式方法。",
    "tldr": "提出了一种方法来筛选自然对立示例的数据集，以评估模型的鲁棒性，并通过自动弱监督标注获得的概率标签来实现这一方法。"
}