{
    "title": "Enhancing Student Performance Prediction on Learnersourced Questions with SGNN-LLM Synergy. (arXiv:2309.13500v2 [cs.LG] UPDATED)",
    "abstract": "Learnersourcing offers great potential for scalable education through student content creation. However, predicting student performance on learnersourced questions, which is essential for personalizing the learning experience, is challenging due to the inherent noise in student-generated data. Moreover, while conventional graph-based methods can capture the complex network of student and question interactions, they often fall short under cold start conditions where limited student engagement with questions yields sparse data. To address both challenges, we introduce an innovative strategy that synergizes the potential of integrating Signed Graph Neural Networks (SGNNs) and Large Language Model (LLM) embeddings. Our methodology employs a signed bipartite graph to comprehensively model student answers, complemented by a contrastive learning framework that enhances noise resilience. Furthermore, LLM's contribution lies in generating foundational question embeddings, proving especially adv",
    "link": "http://arxiv.org/abs/2309.13500",
    "context": "Title: Enhancing Student Performance Prediction on Learnersourced Questions with SGNN-LLM Synergy. (arXiv:2309.13500v2 [cs.LG] UPDATED)\nAbstract: Learnersourcing offers great potential for scalable education through student content creation. However, predicting student performance on learnersourced questions, which is essential for personalizing the learning experience, is challenging due to the inherent noise in student-generated data. Moreover, while conventional graph-based methods can capture the complex network of student and question interactions, they often fall short under cold start conditions where limited student engagement with questions yields sparse data. To address both challenges, we introduce an innovative strategy that synergizes the potential of integrating Signed Graph Neural Networks (SGNNs) and Large Language Model (LLM) embeddings. Our methodology employs a signed bipartite graph to comprehensively model student answers, complemented by a contrastive learning framework that enhances noise resilience. Furthermore, LLM's contribution lies in generating foundational question embeddings, proving especially adv",
    "path": "papers/23/09/2309.13500.json",
    "total_tokens": 948,
    "translated_title": "在学习者提供的问题上增强学生表现预测的SGNN-LLM协同",
    "translated_abstract": "通过学生内容创作，学习者合作具有可扩展教育的巨大潜力。然而，预测学生在学习者提供的问题上的表现，对于个性化学习体验至关重要，由于学生生成的数据中固有的噪声，这是具有挑战性的。此外，传统的基于图的方法可以捕获学生和问题交互的复杂网络，但在冷启动条件下，其中学生对问题的有限参与导致数据稀疏，这些方法往往表现不佳。为了解决这两个挑战，我们引入了一种创新策略，将整合有符号图神经网络（SGNNs）和大型语言模型（LLM）的潜力协同起来。我们的方法利用有符号二分图全面建模学生回答，并采用对比学习框架增强了噪声的鲁棒性。此外，LLM的贡献在于生成基础问题嵌入，特别是证明了其优势。",
    "tldr": "这项研究介绍了一种创新的策略，将有符号图神经网络（SGNNs）和大型语言模型（LLM）的潜力协同起来，用于预测学生在学习者提供的问题上的表现。该方法利用有符号二分图全面建模学生回答，并采用对比学习框架增强了噪声的鲁棒性。",
    "en_tdlr": "This study introduces an innovative strategy that synergizes the potential of integrating Signed Graph Neural Networks (SGNNs) and Large Language Model (LLM) embeddings for predicting student performance on learnersourced questions."
}