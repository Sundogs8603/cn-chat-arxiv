{
    "title": "Knowledge Distillation-Empowered Digital Twin for Anomaly Detection. (arXiv:2309.04616v1 [cs.LG])",
    "abstract": "Cyber-physical systems (CPSs), like train control and management systems (TCMS), are becoming ubiquitous in critical infrastructures. As safety-critical systems, ensuring their dependability during operation is crucial. Digital twins (DTs) have been increasingly studied for this purpose owing to their capability of runtime monitoring and warning, prediction and detection of anomalies, etc. However, constructing a DT for anomaly detection in TCMS necessitates sufficient training data and extracting both chronological and context features with high quality. Hence, in this paper, we propose a novel method named KDDT for TCMS anomaly detection. KDDT harnesses a language model (LM) and a long short-term memory (LSTM) network to extract contexts and chronological features, respectively. To enrich data volume, KDDT benefits from out-of-domain data with knowledge distillation (KD). We evaluated KDDT with two datasets from our industry partner Alstom and obtained the F1 scores of 0.931 and 0.91",
    "link": "http://arxiv.org/abs/2309.04616",
    "context": "Title: Knowledge Distillation-Empowered Digital Twin for Anomaly Detection. (arXiv:2309.04616v1 [cs.LG])\nAbstract: Cyber-physical systems (CPSs), like train control and management systems (TCMS), are becoming ubiquitous in critical infrastructures. As safety-critical systems, ensuring their dependability during operation is crucial. Digital twins (DTs) have been increasingly studied for this purpose owing to their capability of runtime monitoring and warning, prediction and detection of anomalies, etc. However, constructing a DT for anomaly detection in TCMS necessitates sufficient training data and extracting both chronological and context features with high quality. Hence, in this paper, we propose a novel method named KDDT for TCMS anomaly detection. KDDT harnesses a language model (LM) and a long short-term memory (LSTM) network to extract contexts and chronological features, respectively. To enrich data volume, KDDT benefits from out-of-domain data with knowledge distillation (KD). We evaluated KDDT with two datasets from our industry partner Alstom and obtained the F1 scores of 0.931 and 0.91",
    "path": "papers/23/09/2309.04616.json",
    "total_tokens": 1035,
    "translated_title": "基于知识蒸馏的数字孪生模型在异常检测中的应用",
    "translated_abstract": "物联网系统，在关键基础设施中越来越普及，如列车控制和管理系统（TCMS）。作为安全关键系统，确保其在操作过程中的可靠性至关重要。数字孪生（DTs）由于具有运行时监控和警告、异常预测和检测等能力而越来越受到研究关注。然而，在TCMS中构建用于异常检测的数字孪生模型需要充足的训练数据，并提取具有高质量的时间顺序和上下文特征。因此，在本文中，我们提出了一种名为KDDT的新方法，用于TCMS的异常检测。KDDT利用语言模型（LM）和长短期记忆（LSTM）网络分别提取上下文和时间顺序特征。为了增加数据量，KDDT利用知识蒸馏（KD）的方法来利用领域外数据。我们使用我们的工业合作伙伴阿尔斯通的两个数据集对KDDT进行了评估，并获得了0.931和0.91的F1分数。",
    "tldr": "本文提出了基于知识蒸馏的数字孪生模型KDDT，用于列车控制和管理系统（TCMS）的异常检测。KDDT利用语言模型和长短期记忆网络分别提取上下文和时间顺序特征，通过知识蒸馏丰富数据量。实验结果表明KDDT在两个数据集上取得了较高的F1分数0.931和0.91。",
    "en_tdlr": "This paper presents a knowledge distillation-empowered digital twin model (KDDT) for anomaly detection in train control and management systems (TCMS). KDDT uses a language model and a long short-term memory network to extract contextual and chronological features, and enriches data volume through knowledge distillation. Experimental results show high F1 scores of 0.931 and 0.91 on two datasets."
}