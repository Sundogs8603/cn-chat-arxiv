{
    "title": "Semi-supervised Domain Adaptation on Graphs with Contrastive Learning and Minimax Entropy. (arXiv:2309.07402v1 [cs.LG])",
    "abstract": "Label scarcity in a graph is frequently encountered in real-world applications due to the high cost of data labeling. To this end, semi-supervised domain adaptation (SSDA) on graphs aims to leverage the knowledge of a labeled source graph to aid in node classification on a target graph with limited labels. SSDA tasks need to overcome the domain gap between the source and target graphs. However, to date, this challenging research problem has yet to be formally considered by the existing approaches designed for cross-graph node classification. To tackle the SSDA problem on graphs, a novel method called SemiGCL is proposed, which benefits from graph contrastive learning and minimax entropy training. SemiGCL generates informative node representations by contrasting the representations learned from a graph's local and global views. Additionally, SemiGCL is adversarially optimized with the entropy loss of unlabeled target nodes to reduce domain divergence. Experimental results on benchmark d",
    "link": "http://arxiv.org/abs/2309.07402",
    "context": "Title: Semi-supervised Domain Adaptation on Graphs with Contrastive Learning and Minimax Entropy. (arXiv:2309.07402v1 [cs.LG])\nAbstract: Label scarcity in a graph is frequently encountered in real-world applications due to the high cost of data labeling. To this end, semi-supervised domain adaptation (SSDA) on graphs aims to leverage the knowledge of a labeled source graph to aid in node classification on a target graph with limited labels. SSDA tasks need to overcome the domain gap between the source and target graphs. However, to date, this challenging research problem has yet to be formally considered by the existing approaches designed for cross-graph node classification. To tackle the SSDA problem on graphs, a novel method called SemiGCL is proposed, which benefits from graph contrastive learning and minimax entropy training. SemiGCL generates informative node representations by contrasting the representations learned from a graph's local and global views. Additionally, SemiGCL is adversarially optimized with the entropy loss of unlabeled target nodes to reduce domain divergence. Experimental results on benchmark d",
    "path": "papers/23/09/2309.07402.json",
    "total_tokens": 953,
    "translated_title": "使用对比学习和最小最大熵的图上半监督领域适应",
    "translated_abstract": "由于数据标记成本高昂，图中的标签稀缺在现实世界中经常遇到。为此，图上的半监督领域适应(SSDA)旨在利用标记源图的知识来帮助有限标签的目标图中的节点分类。SSDA任务需要克服源图和目标图之间的域差异。然而，到目前为止，现有的用于跨图节点分类的方法尚未正式考虑这个具有挑战性的研究问题。为了解决图上的SSDA问题，提出了一种名为SemiGCL的新方法，它获益于图对比学习和最小最大熵训练。SemiGCL通过对比从图的局部和全局视图中学到的表示来生成信息丰富的节点表示。此外，SemiGCL通过目标图中未标记节点的熵损失进行对抗优化，以减小域差异。在基准数据集上的实验结果表明，SemiGCL在图上的SSDA任务中取得了良好的性能。",
    "tldr": "提出了一种名为SemiGCL的方法，使用图对比学习和最小最大熵训练来解决图上的半监督领域适应问题，该方法通过对比学得表示来生成信息丰富的节点表示，并使用对抗优化减小域差异。在实验中取得了良好的性能。",
    "en_tdlr": "A method called SemiGCL is proposed to address the problem of semi-supervised domain adaptation on graphs, utilizing graph contrastive learning and minimax entropy training to generate informative node representations and reduce domain divergence through adversarial optimization. Experimental results demonstrate its effectiveness in the task of SSDA on graphs."
}