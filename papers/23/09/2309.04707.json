{
    "title": "Advantage Actor-Critic with Reasoner: Explaining the Agent's Behavior from an Exploratory Perspective. (arXiv:2309.04707v1 [cs.AI])",
    "abstract": "Reinforcement learning (RL) is a powerful tool for solving complex decision-making problems, but its lack of transparency and interpretability has been a major challenge in domains where decisions have significant real-world consequences. In this paper, we propose a novel Advantage Actor-Critic with Reasoner (A2CR), which can be easily applied to Actor-Critic-based RL models and make them interpretable. A2CR consists of three interconnected networks: the Policy Network, the Value Network, and the Reasoner Network. By predefining and classifying the underlying purpose of the actor's actions, A2CR automatically generates a more comprehensive and interpretable paradigm for understanding the agent's decision-making process. It offers a range of functionalities such as purpose-based saliency, early failure detection, and model supervision, thereby promoting responsible and trustworthy RL. Evaluations conducted in action-rich Super Mario Bros environments yield intriguing findings: Reasoner-",
    "link": "http://arxiv.org/abs/2309.04707",
    "context": "Title: Advantage Actor-Critic with Reasoner: Explaining the Agent's Behavior from an Exploratory Perspective. (arXiv:2309.04707v1 [cs.AI])\nAbstract: Reinforcement learning (RL) is a powerful tool for solving complex decision-making problems, but its lack of transparency and interpretability has been a major challenge in domains where decisions have significant real-world consequences. In this paper, we propose a novel Advantage Actor-Critic with Reasoner (A2CR), which can be easily applied to Actor-Critic-based RL models and make them interpretable. A2CR consists of three interconnected networks: the Policy Network, the Value Network, and the Reasoner Network. By predefining and classifying the underlying purpose of the actor's actions, A2CR automatically generates a more comprehensive and interpretable paradigm for understanding the agent's decision-making process. It offers a range of functionalities such as purpose-based saliency, early failure detection, and model supervision, thereby promoting responsible and trustworthy RL. Evaluations conducted in action-rich Super Mario Bros environments yield intriguing findings: Reasoner-",
    "path": "papers/23/09/2309.04707.json",
    "total_tokens": 915,
    "translated_title": "从探索性视角解释代理行为的优势演员-评论员",
    "translated_abstract": "强化学习（RL）是解决复杂决策问题的强大工具，但它的缺乏透明度和解释性在决策具有实际后果的领域中一直是一个重要挑战。本文提出了一种新颖的基于Reasoner的优势演员-评论员（A2CR）方法，可以轻松应用于基于演员-评论员的RL模型，并使其具有可解释性。A2CR由三个相互连接的网络组成：策略网络，价值网络和Reasoner网络。通过预定义和分类演员行为的潜在目的，A2CR自动生成了一个更全面和可解释的理解代理决策过程的范例。它提供了诸如基于目的的显著性、早期失败检测和模型监管等一系列功能，从而促进负责任和可信赖的RL。在动作丰富的超级马里奥兄弟环境中进行的评估产生了有趣的发现：Reasoner-。",
    "tldr": "本文提出了一种新颖的基于Reasoner的优势演员-评论员（A2CR）方法，通过预定义和分类演员行为的潜在目的，自动生成一个更全面和可解释的理解代理决策过程的范例。"
}