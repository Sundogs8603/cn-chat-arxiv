{
    "title": "Hierarchical Multi-Agent Reinforcement Learning for Air Combat Maneuvering. (arXiv:2309.11247v1 [cs.LG])",
    "abstract": "The application of artificial intelligence to simulate air-to-air combat scenarios is attracting increasing attention. To date the high-dimensional state and action spaces, the high complexity of situation information (such as imperfect and filtered information, stochasticity, incomplete knowledge about mission targets) and the nonlinear flight dynamics pose significant challenges for accurate air combat decision-making. These challenges are exacerbated when multiple heterogeneous agents are involved. We propose a hierarchical multi-agent reinforcement learning framework for air-to-air combat with multiple heterogeneous agents. In our framework, the decision-making process is divided into two stages of abstraction, where heterogeneous low-level policies control the action of individual units, and a high-level commander policy issues macro commands given the overall mission targets. Low-level policies are trained for accurate unit combat control. Their training is organized in a learnin",
    "link": "http://arxiv.org/abs/2309.11247",
    "context": "Title: Hierarchical Multi-Agent Reinforcement Learning for Air Combat Maneuvering. (arXiv:2309.11247v1 [cs.LG])\nAbstract: The application of artificial intelligence to simulate air-to-air combat scenarios is attracting increasing attention. To date the high-dimensional state and action spaces, the high complexity of situation information (such as imperfect and filtered information, stochasticity, incomplete knowledge about mission targets) and the nonlinear flight dynamics pose significant challenges for accurate air combat decision-making. These challenges are exacerbated when multiple heterogeneous agents are involved. We propose a hierarchical multi-agent reinforcement learning framework for air-to-air combat with multiple heterogeneous agents. In our framework, the decision-making process is divided into two stages of abstraction, where heterogeneous low-level policies control the action of individual units, and a high-level commander policy issues macro commands given the overall mission targets. Low-level policies are trained for accurate unit combat control. Their training is organized in a learnin",
    "path": "papers/23/09/2309.11247.json",
    "total_tokens": 922,
    "translated_title": "针对空中战斗机动的分层多智能体强化学习",
    "translated_abstract": "将人工智能应用于模拟空中对空格斗场景正引起越来越多的关注。迄今为止，高维状态和行动空间、情况信息的高复杂性（如不完美和筛选信息、随机性、关于任务目标的不完全知识）以及非线性飞行动力学给准确的空战决策带来了重大挑战。当涉及多个异构智能体时，这些挑战变得更加严峻。我们提出了一个针对多个异构智能体的空对空格斗的分层多智能体强化学习框架。在我们的框架中，决策过程分为两个层次的抽象，异构的低层策略控制单个单位的行动，并且在整体任务目标下，高层指挥策略发出宏观命令。对于准确的单位战斗控制，我们训练了低层策略。他们的训练是以一种学习方式组织起来的。",
    "tldr": "提出了一个针对空中战斗机动的分层多智能体强化学习框架，通过将决策过程分为两个层次的抽象来处理高维状态和动作空间的挑战，通过训练低层策略实现准确的单位战斗控制。"
}