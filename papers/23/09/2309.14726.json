{
    "title": "PLMM: Personal Large Models on Mobile Devices. (arXiv:2309.14726v1 [cs.CV])",
    "abstract": "Inspired by Federated Learning, in this paper, we propose personal large models that are distilled from traditional large language models but more adaptive to local users' personal information such as education background and hobbies. We classify the large language models into three levels: the personal level, expert level and traditional level. The personal level models are adaptive to users' personal information. They encrypt the users' input and protect their privacy. The expert level models focus on merging specific knowledge such as finance, IT and art. The traditional models focus on the universal knowledge discovery and upgrading the expert models. In such classifications, the personal models directly interact with the user. For the whole system, the personal models have users' (encrypted) personal information. Moreover, such models must be small enough to be performed on personal computers or mobile devices. Finally, they also have to response in real-time for better user exper",
    "link": "http://arxiv.org/abs/2309.14726",
    "context": "Title: PLMM: Personal Large Models on Mobile Devices. (arXiv:2309.14726v1 [cs.CV])\nAbstract: Inspired by Federated Learning, in this paper, we propose personal large models that are distilled from traditional large language models but more adaptive to local users' personal information such as education background and hobbies. We classify the large language models into three levels: the personal level, expert level and traditional level. The personal level models are adaptive to users' personal information. They encrypt the users' input and protect their privacy. The expert level models focus on merging specific knowledge such as finance, IT and art. The traditional models focus on the universal knowledge discovery and upgrading the expert models. In such classifications, the personal models directly interact with the user. For the whole system, the personal models have users' (encrypted) personal information. Moreover, such models must be small enough to be performed on personal computers or mobile devices. Finally, they also have to response in real-time for better user exper",
    "path": "papers/23/09/2309.14726.json",
    "total_tokens": 929,
    "translated_title": "PLMM：移动设备上的个人大型模型",
    "translated_abstract": "在本文中，受到联邦学习的启发，我们提出了从传统大型语言模型中提取的个人大型模型，这些模型更适应本地用户的个人信息，如教育背景和爱好。我们将大型语言模型分为三个级别：个人级别，专家级别和传统级别。个人级别模型适应用户的个人信息，对用户的输入进行加密并保护其隐私。专家级别模型专注于合并特定领域的知识，如金融、IT和艺术。传统模型专注于普遍知识的发现和提升专家模型。在这样的分类中，个人模型直接与用户交互。对于整个系统来说，个人模型具有用户的（加密的）个人信息。此外，这些模型必须足够小以在个人计算机或移动设备上运行。最后，它们还必须实时响应，以提供更好的用户体验。",
    "tldr": "本文提出了一种从传统大型语言模型中提取的个人大型模型，该模型更适应于本地用户的个人信息，并且能够保护用户的隐私。该模型分为个人级别、专家级别和传统级别，同时还需要小型化以适应个人计算机或移动设备，并实现实时响应以提供更好的用户体验。",
    "en_tdlr": "This paper proposes personal large models extracted from traditional large language models, which are more adaptive to local users' personal information and can protect user privacy. The models are classified into personal level, expert level, and traditional level. They also need to be compact enough to run on personal computers or mobile devices, and provide real-time response for better user experience."
}