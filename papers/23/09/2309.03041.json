{
    "title": "A Refutation of Shapley Values for Explainability. (arXiv:2309.03041v1 [cs.AI])",
    "abstract": "Recent work demonstrated the existence of Boolean functions for which Shapley values provide misleading information about the relative importance of features in rule-based explanations. Such misleading information was broadly categorized into a number of possible issues. Each of those issues relates with features being relevant or irrelevant for a prediction, and all are significant regarding the inadequacy of Shapley values for rule-based explainability. This earlier work devised a brute-force approach to identify Boolean functions, defined on small numbers of features, and also associated instances, which displayed such inadequacy-revealing issues, and so served as evidence to the inadequacy of Shapley values for rule-based explainability. However, an outstanding question is how frequently such inadequacy-revealing issues can occur for Boolean functions with arbitrary large numbers of features. It is plain that a brute-force approach would be unlikely to provide insights on how to ta",
    "link": "http://arxiv.org/abs/2309.03041",
    "context": "Title: A Refutation of Shapley Values for Explainability. (arXiv:2309.03041v1 [cs.AI])\nAbstract: Recent work demonstrated the existence of Boolean functions for which Shapley values provide misleading information about the relative importance of features in rule-based explanations. Such misleading information was broadly categorized into a number of possible issues. Each of those issues relates with features being relevant or irrelevant for a prediction, and all are significant regarding the inadequacy of Shapley values for rule-based explainability. This earlier work devised a brute-force approach to identify Boolean functions, defined on small numbers of features, and also associated instances, which displayed such inadequacy-revealing issues, and so served as evidence to the inadequacy of Shapley values for rule-based explainability. However, an outstanding question is how frequently such inadequacy-revealing issues can occur for Boolean functions with arbitrary large numbers of features. It is plain that a brute-force approach would be unlikely to provide insights on how to ta",
    "path": "papers/23/09/2309.03041.json",
    "total_tokens": 887,
    "translated_title": "驳斥Shapley Values用于可解释性的论证",
    "translated_abstract": "最近的研究证明了在基于规则的解释中，Shapley值对特征的相对重要性提供了误导性信息的布尔函数的存在。这些误导性信息被广泛分类为几个可能的问题。每个问题都涉及与预测相关的特征的相关性或无关性，并且在基于规则的解释中，所有这些问题都与Shapley值的不足有关。其中的一个研究使用了一种蛮力方法来识别仅包含少数特征和相关实例的布尔函数，展示了Shapley值不足的问题，并作为证明在规则解释中Shapley值的不足的证据。然而，一个重要的问题是这种Shapley值不足的问题在具有任意大数量特征的布尔函数中有多频繁出现。很显然，蛮力方法不太可能提供洞察如何处理具有任意大数量特征的问题的见解。",
    "tldr": "这篇论文驳斥了Shapley Values在规则解释中的适用性，并证明了存在布尔函数，使得Shapley值给出的特征重要性信息具有误导性。该论文提供了一种蛮力方法来识别这种问题，但对于特征数量较大的布尔函数仍存在问题。",
    "en_tdlr": "This paper refutes the applicability of Shapley Values in rule-based explanations and demonstrates the existence of Boolean functions that provide misleading information about feature importance. It proposes a brute-force approach to identify such issues but acknowledges limitations for Boolean functions with a large number of features."
}