{
    "title": "Strategic Behavior of Large Language Models: Game Structure vs. Contextual Framing. (arXiv:2309.05898v1 [cs.GT])",
    "abstract": "This paper investigates the strategic decision-making capabilities of three Large Language Models (LLMs): GPT-3.5, GPT-4, and LLaMa-2, within the framework of game theory. Utilizing four canonical two-player games -- Prisoner's Dilemma, Stag Hunt, Snowdrift, and Prisoner's Delight -- we explore how these models navigate social dilemmas, situations where players can either cooperate for a collective benefit or defect for individual gain. Crucially, we extend our analysis to examine the role of contextual framing, such as diplomatic relations or casual friendships, in shaping the models' decisions. Our findings reveal a complex landscape: while GPT-3.5 is highly sensitive to contextual framing, it shows limited ability to engage in abstract strategic reasoning. Both GPT-4 and LLaMa-2 adjust their strategies based on game structure and context, but LLaMa-2 exhibits a more nuanced understanding of the games' underlying mechanics. These results highlight the current limitations and varied p",
    "link": "http://arxiv.org/abs/2309.05898",
    "context": "Title: Strategic Behavior of Large Language Models: Game Structure vs. Contextual Framing. (arXiv:2309.05898v1 [cs.GT])\nAbstract: This paper investigates the strategic decision-making capabilities of three Large Language Models (LLMs): GPT-3.5, GPT-4, and LLaMa-2, within the framework of game theory. Utilizing four canonical two-player games -- Prisoner's Dilemma, Stag Hunt, Snowdrift, and Prisoner's Delight -- we explore how these models navigate social dilemmas, situations where players can either cooperate for a collective benefit or defect for individual gain. Crucially, we extend our analysis to examine the role of contextual framing, such as diplomatic relations or casual friendships, in shaping the models' decisions. Our findings reveal a complex landscape: while GPT-3.5 is highly sensitive to contextual framing, it shows limited ability to engage in abstract strategic reasoning. Both GPT-4 and LLaMa-2 adjust their strategies based on game structure and context, but LLaMa-2 exhibits a more nuanced understanding of the games' underlying mechanics. These results highlight the current limitations and varied p",
    "path": "papers/23/09/2309.05898.json",
    "total_tokens": 1078,
    "translated_title": "大规模语言模型的战略行为：游戏结构与情境框架",
    "translated_abstract": "本文研究了三种大规模语言模型（LLM）：GPT-3.5、GPT-4和LLaMa-2在博弈论框架下的战略决策能力。通过使用四种典型的双人博弈游戏——囚徒困境、猎兔、雪崩和囚徒的喜悦——我们探讨了这些模型在社会困境中的导航方式，即玩家可以合作获得集体利益，也可以为了个人利益而背叛。关键是，我们扩展了分析，研究情境框架（如外交关系或非正式友谊）在塑造模型决策中的作用。我们的研究结果揭示了一个复杂的景观：虽然GPT-3.5对情境框架非常敏感，但它在抽象战略推理方面能力有限。而GPT-4和LLaMa-2根据游戏结构和情境调整策略，但LLaMa-2在对游戏潜在机制的理解上更加微妙。这些结果突显了当前的局限性和多样化。",
    "tldr": "本文研究了三种大规模语言模型在博弈论框架下的战略决策能力，并发现GPT-3.5对情境框架敏感但抽象战略推理能力有限，而GPT-4和LLaMa-2在游戏结构和情境下能调整策略，但LLaMa-2在游戏机制的理解上更加微妙。",
    "en_tdlr": "This paper investigates the strategic decision-making capabilities of three Large Language Models (LLMs) within the framework of game theory, and finds that GPT-3.5 is sensitive to contextual framing but has limited ability in abstract strategic reasoning, while GPT-4 and LLaMa-2 can adjust their strategies based on game structure and context, with LLaMa-2 exhibiting a more nuanced understanding of game mechanics."
}