{
    "title": "Emergent Linear Representations in World Models of Self-Supervised Sequence Models. (arXiv:2309.00941v2 [cs.LG] UPDATED)",
    "abstract": "How do sequence models represent their decision-making process? Prior work suggests that Othello-playing neural network learned nonlinear models of the board state (Li et al., 2023). In this work, we provide evidence of a closely related linear representation of the board. In particular, we show that probing for \"my colour\" vs. \"opponent's colour\" may be a simple yet powerful way to interpret the model's internal state. This precise understanding of the internal representations allows us to control the model's behaviour with simple vector arithmetic. Linear representations enable significant interpretability progress, which we demonstrate with further exploration of how the world model is computed.",
    "link": "http://arxiv.org/abs/2309.00941",
    "context": "Title: Emergent Linear Representations in World Models of Self-Supervised Sequence Models. (arXiv:2309.00941v2 [cs.LG] UPDATED)\nAbstract: How do sequence models represent their decision-making process? Prior work suggests that Othello-playing neural network learned nonlinear models of the board state (Li et al., 2023). In this work, we provide evidence of a closely related linear representation of the board. In particular, we show that probing for \"my colour\" vs. \"opponent's colour\" may be a simple yet powerful way to interpret the model's internal state. This precise understanding of the internal representations allows us to control the model's behaviour with simple vector arithmetic. Linear representations enable significant interpretability progress, which we demonstrate with further exploration of how the world model is computed.",
    "path": "papers/23/09/2309.00941.json",
    "total_tokens": 813,
    "translated_title": "自监督的序列模型中的新型线性表示",
    "translated_abstract": "序列模型如何表示其决策过程？之前的研究表明，黑白棋博弈神经网络学到了非线性的棋盘状态模型（Li等，2023）。在本研究中，我们提供了相关的证据，表明存在一个密切相关的线性棋盘表示。特别是，我们展示了通过探测\"我的颜色\"与\"对手的颜色\"这种简单而强大的方式来解释模型的内部状态。对内部表示的准确理解使我们能够通过简单的向量运算来控制模型的行为。线性表示使得重要的可解释性进展成为可能，我们通过进一步探索世界模型的计算来证明这一点。",
    "tldr": "本研究提供了自监督的序列模型中新型线性表示的证据，并表明通过探测棋盘的\"我的颜色\"与\"对手的颜色\"可以解释模型的内部状态。这种准确的内部表示理解使得我们能够通过简单的向量运算来控制模型的行为，并显著推进了可解释性的进展。",
    "en_tdlr": "This study provides evidence of emergent linear representations in self-supervised sequence models and shows that probing for \"my colour\" versus \"opponent's colour\" can explain the model's internal state. The precise understanding of these internal representations allows for controlling the model's behavior through simple vector arithmetic and enables significant progress in interpretability."
}