{
    "title": "A Practical Survey on Zero-shot Prompt Design for In-context Learning. (arXiv:2309.13205v1 [cs.CL])",
    "abstract": "The remarkable advancements in large language models (LLMs) have brought about significant improvements in Natural Language Processing(NLP) tasks. This paper presents a comprehensive review of in-context learning techniques, focusing on different types of prompts, including discrete, continuous, few-shot, and zero-shot, and their impact on LLM performance. We explore various approaches to prompt design, such as manual design, optimization algorithms, and evaluation methods, to optimize LLM performance across diverse tasks. Our review covers key research studies in prompt engineering, discussing their methodologies and contributions to the field. We also delve into the challenges faced in evaluating prompt performance, given the absence of a single \"best\" prompt and the importance of considering multiple metrics. In conclusion, the paper highlights the critical role of prompt design in harnessing the full potential of LLMs and provides insights into the combination of manual design, opt",
    "link": "http://arxiv.org/abs/2309.13205",
    "context": "Title: A Practical Survey on Zero-shot Prompt Design for In-context Learning. (arXiv:2309.13205v1 [cs.CL])\nAbstract: The remarkable advancements in large language models (LLMs) have brought about significant improvements in Natural Language Processing(NLP) tasks. This paper presents a comprehensive review of in-context learning techniques, focusing on different types of prompts, including discrete, continuous, few-shot, and zero-shot, and their impact on LLM performance. We explore various approaches to prompt design, such as manual design, optimization algorithms, and evaluation methods, to optimize LLM performance across diverse tasks. Our review covers key research studies in prompt engineering, discussing their methodologies and contributions to the field. We also delve into the challenges faced in evaluating prompt performance, given the absence of a single \"best\" prompt and the importance of considering multiple metrics. In conclusion, the paper highlights the critical role of prompt design in harnessing the full potential of LLMs and provides insights into the combination of manual design, opt",
    "path": "papers/23/09/2309.13205.json",
    "total_tokens": 1020,
    "translated_title": "针对上下文学习的零样本提示设计的实际调查",
    "translated_abstract": "大型语言模型（LLM）的显著进展在自然语言处理（NLP）任务中带来了显著的改进。本文对上下文学习技术进行了综合回顾，重点关注不同类型的提示，包括离散、连续、少样本和零样本，并探讨它们对LLM性能的影响。我们探索了各种提示设计方法，如人工设计、优化算法和评价方法，以优化LLM在各种任务中的性能。我们的回顾涵盖了提示工程领域的关键研究，讨论了其方法论和对该领域的贡献。我们还深入探讨了在评估提示性能方面面临的挑战，包括缺乏单一的\"最佳\"提示和考虑多个指标的重要性。总之，本文强调了提示设计在发挥LLM的全部潜力中的关键作用，并提供了关于人工设计、优化算法和评价方法结合的见解。",
    "tldr": "本文综述了针对上下文学习的零样本提示设计技术，并探讨了不同类型提示对大型语言模型性能的影响。研究重点讨论了人工设计、优化算法和评价方法等多种提示设计方法，以优化模型在不同任务上的性能。同时，本文强调了考虑多种指标和缺乏单一最佳提示等评估挑战。该研究揭示了提示设计在充分发挥大型语言模型潜力方面的关键作用。",
    "en_tdlr": "This paper provides a comprehensive survey on zero-shot prompt design for in-context learning, investigating the impact of different prompt types on large language model performance. It discusses various approaches to prompt design, including manual design, optimization algorithms, and evaluation methods, to optimize model performance across diverse tasks. The review highlights the challenges in evaluating prompt performance and emphasizes the critical role of prompt design in harnessing the full potential of large language models."
}