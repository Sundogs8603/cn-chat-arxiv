{
    "title": "Robot Parkour Learning. (arXiv:2309.05665v2 [cs.RO] UPDATED)",
    "abstract": "Parkour is a grand challenge for legged locomotion that requires robots to overcome various obstacles rapidly in complex environments. Existing methods can generate either diverse but blind locomotion skills or vision-based but specialized skills by using reference animal data or complex rewards. However, autonomous parkour requires robots to learn generalizable skills that are both vision-based and diverse to perceive and react to various scenarios. In this work, we propose a system for learning a single end-to-end vision-based parkour policy of diverse parkour skills using a simple reward without any reference motion data. We develop a reinforcement learning method inspired by direct collocation to generate parkour skills, including climbing over high obstacles, leaping over large gaps, crawling beneath low barriers, squeezing through thin slits, and running. We distill these skills into a single vision-based parkour policy and transfer it to a quadrupedal robot using its egocentric ",
    "link": "http://arxiv.org/abs/2309.05665",
    "context": "Title: Robot Parkour Learning. (arXiv:2309.05665v2 [cs.RO] UPDATED)\nAbstract: Parkour is a grand challenge for legged locomotion that requires robots to overcome various obstacles rapidly in complex environments. Existing methods can generate either diverse but blind locomotion skills or vision-based but specialized skills by using reference animal data or complex rewards. However, autonomous parkour requires robots to learn generalizable skills that are both vision-based and diverse to perceive and react to various scenarios. In this work, we propose a system for learning a single end-to-end vision-based parkour policy of diverse parkour skills using a simple reward without any reference motion data. We develop a reinforcement learning method inspired by direct collocation to generate parkour skills, including climbing over high obstacles, leaping over large gaps, crawling beneath low barriers, squeezing through thin slits, and running. We distill these skills into a single vision-based parkour policy and transfer it to a quadrupedal robot using its egocentric ",
    "path": "papers/23/09/2309.05665.json",
    "total_tokens": 920,
    "translated_title": "机器人公园our学习",
    "translated_abstract": "公园our是一个对于机器人来说需要在复杂环境中迅速克服各种障碍的长期挑战。现有的方法通过使用参考动物数据或复杂的奖励，可以生成多样但盲目的运动技能或基于视觉的特殊技能。然而，自主公园our需要机器人学习基于视觉的、多样化的可推广技能，以感知和应对各种情况。在这项工作中，我们提出了一个系统，通过使用简单的奖励而不使用任何参考动作数据，来学习多样化的、基于视觉的公园our技能的单一端到端策略。我们开发了一种受到直接协作的强化学习方法，用于生成公园our技能，包括攀爬高障碍物、跨越大距离间隙、爬行低壁垒、穿越狭窄缝隙和奔跑。我们将这些技能提炼成一个单一基于视觉的公园our策略，并将其转移到四足机器人上，利用其自我中心视角。",
    "tldr": "该论文提出了一个学习基于视觉的多样化公园our技能的系统，该系统使用简单的奖励而不使用参考动作数据，通过强化学习方法生成不同的公园our技能，并将其转移到四足机器人中。"
}