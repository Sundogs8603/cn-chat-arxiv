{
    "title": "Challenges in Annotating Datasets to Quantify Bias in Under-represented Society. (arXiv:2309.08624v1 [cs.CL])",
    "abstract": "Recent advances in artificial intelligence, including the development of highly sophisticated large language models (LLM), have proven beneficial in many real-world applications. However, evidence of inherent bias encoded in these LLMs has raised concerns about equity. In response, there has been an increase in research dealing with bias, including studies focusing on quantifying bias and developing debiasing techniques. Benchmark bias datasets have also been developed for binary gender classification and ethical/racial considerations, focusing predominantly on American demographics. However, there is minimal research in understanding and quantifying bias related to under-represented societies. Motivated by the lack of annotated datasets for quantifying bias in under-represented societies, we endeavoured to create benchmark datasets for the New Zealand (NZ) population. We faced many challenges in this process, despite the availability of three annotators. This research outlines the man",
    "link": "http://arxiv.org/abs/2309.08624",
    "context": "Title: Challenges in Annotating Datasets to Quantify Bias in Under-represented Society. (arXiv:2309.08624v1 [cs.CL])\nAbstract: Recent advances in artificial intelligence, including the development of highly sophisticated large language models (LLM), have proven beneficial in many real-world applications. However, evidence of inherent bias encoded in these LLMs has raised concerns about equity. In response, there has been an increase in research dealing with bias, including studies focusing on quantifying bias and developing debiasing techniques. Benchmark bias datasets have also been developed for binary gender classification and ethical/racial considerations, focusing predominantly on American demographics. However, there is minimal research in understanding and quantifying bias related to under-represented societies. Motivated by the lack of annotated datasets for quantifying bias in under-represented societies, we endeavoured to create benchmark datasets for the New Zealand (NZ) population. We faced many challenges in this process, despite the availability of three annotators. This research outlines the man",
    "path": "papers/23/09/2309.08624.json",
    "total_tokens": 954,
    "translated_title": "论注释用于衡量少数社群偏见的挑战",
    "translated_abstract": "最近人工智能的进展，包括高度复杂的大语言模型（LLM）的发展，在许多实际应用中证明是有益的。然而，这些LLM中固有的偏见编码的证据引发了对公平性的担忧。为此，出现了越来越多关于偏见的研究，包括关注衡量偏见和开发去偏见技术的研究。还开发了用于二元性别分类和道德/种族考虑的基准偏见数据集，主要关注美国的人口统计。然而，对于少数社群相关的偏见理解和衡量的研究很少。受到在衡量少数社群中偏见的注释数据集缺乏的启发，我们努力为新西兰（NZ）人口创建基准数据集。尽管有三名注释员的可用性，但我们在这个过程中面临了许多挑战。这项研究概述了这个过程中遇到的问题。",
    "tldr": "最近研究越来越关注衡量偏见和开发去偏见技术，但在少数社群相关的偏见衡量方面的研究仍然很少。本研究以新西兰人口为例，创建了用于衡量少数社群中偏见的基准数据集，并介绍了在这个过程中遇到的挑战。",
    "en_tdlr": "Recent research has focused on quantifying bias and developing debiasing techniques, but there is still limited study on measuring bias in under-represented societies. This research addresses this gap by creating benchmark datasets for quantifying bias in the New Zealand population and outlines the challenges encountered in the process."
}