{
    "title": "A Unifying Perspective on Non-Stationary Kernels for Deeper Gaussian Processes. (arXiv:2309.10068v1 [stat.ML])",
    "abstract": "The Gaussian process (GP) is a popular statistical technique for stochastic function approximation and uncertainty quantification from data. GPs have been adopted into the realm of machine learning in the last two decades because of their superior prediction abilities, especially in data-sparse scenarios, and their inherent ability to provide robust uncertainty estimates. Even so, their performance highly depends on intricate customizations of the core methodology, which often leads to dissatisfaction among practitioners when standard setups and off-the-shelf software tools are being deployed. Arguably the most important building block of a GP is the kernel function which assumes the role of a covariance operator. Stationary kernels of the Mat\\'ern class are used in the vast majority of applied studies; poor prediction performance and unrealistic uncertainty quantification are often the consequences. Non-stationary kernels show improved performance but are rarely used due to their more",
    "link": "http://arxiv.org/abs/2309.10068",
    "context": "Title: A Unifying Perspective on Non-Stationary Kernels for Deeper Gaussian Processes. (arXiv:2309.10068v1 [stat.ML])\nAbstract: The Gaussian process (GP) is a popular statistical technique for stochastic function approximation and uncertainty quantification from data. GPs have been adopted into the realm of machine learning in the last two decades because of their superior prediction abilities, especially in data-sparse scenarios, and their inherent ability to provide robust uncertainty estimates. Even so, their performance highly depends on intricate customizations of the core methodology, which often leads to dissatisfaction among practitioners when standard setups and off-the-shelf software tools are being deployed. Arguably the most important building block of a GP is the kernel function which assumes the role of a covariance operator. Stationary kernels of the Mat\\'ern class are used in the vast majority of applied studies; poor prediction performance and unrealistic uncertainty quantification are often the consequences. Non-stationary kernels show improved performance but are rarely used due to their more",
    "path": "papers/23/09/2309.10068.json",
    "total_tokens": 799,
    "translated_title": "非平稳核对深层高斯过程的统一视角",
    "translated_abstract": "高斯过程（GP）是一种流行的用于数据的随机函数近似和不确定性量化的统计技术。在过去的二十年中，由于其优越的预测能力，特别是在数据稀疏情况下，以及其固有的提供强健不确定性估计的能力，GP已被广泛应用于机器学习领域。然而，它们的性能高度依赖于核心方法的复杂定制，这往往在使用标准设置和现成软件工具时使从业者不满意。可以说，GP最重要的组成部分是核函数，它扮演协方差算子的角色。Mat\\'ern类的平稳核在大多数应用研究中被使用；低效的预测性能和不现实的不确定性估计往往是其结果。非平稳核表现出更好的性能，但由于其更加复杂的属性，很少被使用。",
    "tldr": "本论文提出了一个统一的视角来探讨非平稳核在深层高斯过程中的应用，以提高预测性能和不确定性估计。"
}