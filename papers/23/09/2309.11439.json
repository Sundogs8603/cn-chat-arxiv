{
    "title": "Controlled Generation with Prompt Insertion for Natural Language Explanations in Grammatical Error Correction. (arXiv:2309.11439v1 [cs.CL])",
    "abstract": "In Grammatical Error Correction (GEC), it is crucial to ensure the user's comprehension of a reason for correction. Existing studies present tokens, examples, and hints as to the basis for correction but do not directly explain the reasons for corrections. Although methods that use Large Language Models (LLMs) to provide direct explanations in natural language have been proposed for various tasks, no such method exists for GEC. Generating explanations for GEC corrections involves aligning input and output tokens, identifying correction points, and presenting corresponding explanations consistently. However, it is not straightforward to specify a complex format to generate explanations, because explicit control of generation is difficult with prompts. This study introduces a method called controlled generation with Prompt Insertion (PI) so that LLMs can explain the reasons for corrections in natural language. In PI, LLMs first correct the input text, and then we automatically extract th",
    "link": "http://arxiv.org/abs/2309.11439",
    "context": "Title: Controlled Generation with Prompt Insertion for Natural Language Explanations in Grammatical Error Correction. (arXiv:2309.11439v1 [cs.CL])\nAbstract: In Grammatical Error Correction (GEC), it is crucial to ensure the user's comprehension of a reason for correction. Existing studies present tokens, examples, and hints as to the basis for correction but do not directly explain the reasons for corrections. Although methods that use Large Language Models (LLMs) to provide direct explanations in natural language have been proposed for various tasks, no such method exists for GEC. Generating explanations for GEC corrections involves aligning input and output tokens, identifying correction points, and presenting corresponding explanations consistently. However, it is not straightforward to specify a complex format to generate explanations, because explicit control of generation is difficult with prompts. This study introduces a method called controlled generation with Prompt Insertion (PI) so that LLMs can explain the reasons for corrections in natural language. In PI, LLMs first correct the input text, and then we automatically extract th",
    "path": "papers/23/09/2309.11439.json",
    "total_tokens": 794,
    "translated_title": "在语法错误修正中通过提示插入实现自然语言解释的可控生成",
    "translated_abstract": "在语法错误修正（GEC）中，确保用户理解修正原因至关重要。现有研究提供了基于修正原因的标记、示例和提示，但未直接解释修正原因。虽然已提出使用大型语言模型（LLMs）为各种任务提供直接的自然语言解释的方法，但在GEC领域尚无此类方法。生成GEC修正的解释涉及对齐输入和输出标记，识别修正点，并始终呈现相应的解释。然而，由于提示难以显式地控制生成，因此很难指定复杂的格式来生成解释。本研究介绍了一种称为Prompt Insertion (PI)的控制生成方法，以使LLMs能够用自然语言解释修正原因。",
    "tldr": "本研究提出了一种称为Prompt Insertion (PI)的控制生成方法，以使大型语言模型能够用自然语言解释语法错误修正的原因。",
    "en_tdlr": "This paper introduces a method called Prompt Insertion (PI) for controlled generation, allowing large language models to explain the reasons for grammatical error corrections in natural language."
}