{
    "title": "GECTurk: Grammatical Error Correction and Detection Dataset for Turkish. (arXiv:2309.11346v1 [cs.CL])",
    "abstract": "Grammatical Error Detection and Correction (GEC) tools have proven useful for native speakers and second language learners. Developing such tools requires a large amount of parallel, annotated data, which is unavailable for most languages. Synthetic data generation is a common practice to overcome the scarcity of such data. However, it is not straightforward for morphologically rich languages like Turkish due to complex writing rules that require phonological, morphological, and syntactic information. In this work, we present a flexible and extensible synthetic data generation pipeline for Turkish covering more than 20 expert-curated grammar and spelling rules (a.k.a., writing rules) implemented through complex transformation functions. Using this pipeline, we derive 130,000 high-quality parallel sentences from professionally edited articles. Additionally, we create a more realistic test set by manually annotating a set of movie reviews. We implement three baselines formulating the tas",
    "link": "http://arxiv.org/abs/2309.11346",
    "context": "Title: GECTurk: Grammatical Error Correction and Detection Dataset for Turkish. (arXiv:2309.11346v1 [cs.CL])\nAbstract: Grammatical Error Detection and Correction (GEC) tools have proven useful for native speakers and second language learners. Developing such tools requires a large amount of parallel, annotated data, which is unavailable for most languages. Synthetic data generation is a common practice to overcome the scarcity of such data. However, it is not straightforward for morphologically rich languages like Turkish due to complex writing rules that require phonological, morphological, and syntactic information. In this work, we present a flexible and extensible synthetic data generation pipeline for Turkish covering more than 20 expert-curated grammar and spelling rules (a.k.a., writing rules) implemented through complex transformation functions. Using this pipeline, we derive 130,000 high-quality parallel sentences from professionally edited articles. Additionally, we create a more realistic test set by manually annotating a set of movie reviews. We implement three baselines formulating the tas",
    "path": "papers/23/09/2309.11346.json",
    "total_tokens": 928,
    "translated_title": "GECTurk：用于土耳其语的语法错误纠正和检测数据集",
    "translated_abstract": "语法错误检测和纠正（GEC）工具已经被证明对于母语使用者和第二语言学习者非常有用。开发这样的工具需要大量平行的、注释的数据，但是对于大多数语言来说，这种数据是不可得到的。合成数据生成是克服这种数据稀缺的常见做法。然而，对于土耳其语这样形态丰富的语言来说，并不直接，因为复杂的写作规则需要音韵、形态和句法信息。在这项工作中，我们提出了一个灵活且可扩展的土耳其语合成数据生成流水线，涵盖了20多个专家策划的语法和拼写规则（即写作规则），通过复杂的转换函数实现。使用这个流水线，我们从专业编辑的文章中派生出了13万条高质量的平行句子。此外，我们通过手动注释一组电影评论来创建一个更真实的测试集。我们实现了三个基准线，制定了任务的",
    "tldr": "GECTurk是一个用于土耳其语的语法错误纠正和检测数据集。它采用灵活且可扩展的合成数据生成流水线，覆盖了20多个专家策划的语法和拼写规则，并且通过手动注释电影评论创造了更真实的测试集。"
}