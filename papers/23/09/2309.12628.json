{
    "title": "Sequential Action-Induced Invariant Representation for Reinforcement Learning. (arXiv:2309.12628v1 [cs.LG])",
    "abstract": "How to accurately learn task-relevant state representations from high-dimensional observations with visual distractions is a realistic and challenging problem in visual reinforcement learning. Recently, unsupervised representation learning methods based on bisimulation metrics, contrast, prediction, and reconstruction have shown the ability for task-relevant information extraction. However, due to the lack of appropriate mechanisms for the extraction of task information in the prediction, contrast, and reconstruction-related approaches and the limitations of bisimulation-related methods in domains with sparse rewards, it is still difficult for these methods to be effectively extended to environments with distractions. To alleviate these problems, in the paper, the action sequences, which contain task-intensive signals, are incorporated into representation learning. Specifically, we propose a Sequential Action--induced invariant Representation (SAR) method, in which the encoder is optim",
    "link": "http://arxiv.org/abs/2309.12628",
    "context": "Title: Sequential Action-Induced Invariant Representation for Reinforcement Learning. (arXiv:2309.12628v1 [cs.LG])\nAbstract: How to accurately learn task-relevant state representations from high-dimensional observations with visual distractions is a realistic and challenging problem in visual reinforcement learning. Recently, unsupervised representation learning methods based on bisimulation metrics, contrast, prediction, and reconstruction have shown the ability for task-relevant information extraction. However, due to the lack of appropriate mechanisms for the extraction of task information in the prediction, contrast, and reconstruction-related approaches and the limitations of bisimulation-related methods in domains with sparse rewards, it is still difficult for these methods to be effectively extended to environments with distractions. To alleviate these problems, in the paper, the action sequences, which contain task-intensive signals, are incorporated into representation learning. Specifically, we propose a Sequential Action--induced invariant Representation (SAR) method, in which the encoder is optim",
    "path": "papers/23/09/2309.12628.json",
    "total_tokens": 828,
    "translated_title": "强化学习中的序贯动作引发不变表示",
    "translated_abstract": "如何从视觉干扰的高维观测中准确学习与任务相关的状态表示是视觉强化学习中一个现实而具有挑战性的问题。最近，基于对比、预测和重建的无监督表示学习方法已经显示出提取与任务相关信息的能力。然而，由于在预测、对比和重建方法中缺乏适当的任务信息提取机制以及在稀疏奖励领域中的双模拟相关方法的局限性，这些方法仍然难以有效地扩展到具有干扰的环境中。为了缓解这些问题，在本文中，将包含任务关键信号的动作序列纳入表示学习中。具体而言，我们提出了一种称为Sequential Action--Induced Invariant Representation (SAR)的方法，其中编码器被优化...",
    "tldr": "本文提出了一种称为Sequential Action--Induced Invariant Representation (SAR)的方法，通过将包含任务关键信号的动作序列纳入表示学习，解决了从视觉干扰的高维观测中准确学习与任务相关的状态表示的问题。"
}