{
    "title": "AI Risk Profiles: A Standards Proposal for Pre-Deployment AI Risk Disclosures. (arXiv:2309.13176v1 [cs.AI])",
    "abstract": "As AI systems' sophistication and proliferation have increased, awareness of the risks has grown proportionally (Sorkin et al. 2023). In response, calls have grown for stronger emphasis on disclosure and transparency in the AI industry (NTIA 2023; OpenAI 2023b), with proposals ranging from standardizing use of technical disclosures, like model cards (Mitchell et al. 2019), to yet-unspecified licensing regimes (Sindhu 2023). Since the AI value chain is complicated, with actors representing various expertise, perspectives, and values, it is crucial that consumers of a transparency disclosure be able to understand the risks of the AI system the disclosure concerns. In this paper we propose a risk profiling standard which can guide downstream decision-making, including triaging further risk assessment, informing procurement and deployment, and directing regulatory frameworks. The standard is built on our proposed taxonomy of AI risks, which reflects a high-level categorization of the wide ",
    "link": "http://arxiv.org/abs/2309.13176",
    "context": "Title: AI Risk Profiles: A Standards Proposal for Pre-Deployment AI Risk Disclosures. (arXiv:2309.13176v1 [cs.AI])\nAbstract: As AI systems' sophistication and proliferation have increased, awareness of the risks has grown proportionally (Sorkin et al. 2023). In response, calls have grown for stronger emphasis on disclosure and transparency in the AI industry (NTIA 2023; OpenAI 2023b), with proposals ranging from standardizing use of technical disclosures, like model cards (Mitchell et al. 2019), to yet-unspecified licensing regimes (Sindhu 2023). Since the AI value chain is complicated, with actors representing various expertise, perspectives, and values, it is crucial that consumers of a transparency disclosure be able to understand the risks of the AI system the disclosure concerns. In this paper we propose a risk profiling standard which can guide downstream decision-making, including triaging further risk assessment, informing procurement and deployment, and directing regulatory frameworks. The standard is built on our proposed taxonomy of AI risks, which reflects a high-level categorization of the wide ",
    "path": "papers/23/09/2309.13176.json",
    "total_tokens": 857,
    "translated_title": "AI风险概况：AI风险披露的标准提案",
    "translated_abstract": "随着AI系统的复杂性和普及程度的增加，对其风险的认识也相应增长。因此，对于AI行业更加强调披露和透明度的呼声越来越高，提议从标准化技术披露（如模型卡片）到尚未具体说明的许可制度。由于AI价值链具有复杂性，包括代表不同专业知识、观点和价值观的参与者，消费者能够理解与披露相关的AI系统的风险至关重要。在本文中，我们提出了一个风险概述标准，可以指导下游决策，包括风险评估的分流、采购和部署的信息和指导监管框架。这个标准是建立在我们提出的AI风险分类系统基础上的，反映了广泛的高级分类。",
    "tldr": "本文提出了一个AI风险概述的标准，旨在帮助消费者理解与披露相关的AI系统的风险，为下游决策和监管框架提供指导。",
    "en_tdlr": "This paper proposes a standard for AI risk profiling that aims to help consumers understand the risks of AI systems and provide guidance for downstream decision-making and regulatory frameworks."
}