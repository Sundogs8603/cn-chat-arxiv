{
    "title": "Cognitive Mirage: A Review of Hallucinations in Large Language Models. (arXiv:2309.06794v1 [cs.CL])",
    "abstract": "As large language models continue to develop in the field of AI, text generation systems are susceptible to a worrisome phenomenon known as hallucination. In this study, we summarize recent compelling insights into hallucinations in LLMs. We present a novel taxonomy of hallucinations from various text generation tasks, thus provide theoretical insights, detection methods and improvement approaches. Based on this, future research directions are proposed. Our contribution are threefold: (1) We provide a detailed and complete taxonomy for hallucinations appearing in text generation tasks; (2) We provide theoretical analyses of hallucinations in LLMs and provide existing detection and improvement methods; (3) We propose several research directions that can be developed in the future. As hallucinations garner significant attention from the community, we will maintain updates on relevant research progress.",
    "link": "http://arxiv.org/abs/2309.06794",
    "context": "Title: Cognitive Mirage: A Review of Hallucinations in Large Language Models. (arXiv:2309.06794v1 [cs.CL])\nAbstract: As large language models continue to develop in the field of AI, text generation systems are susceptible to a worrisome phenomenon known as hallucination. In this study, we summarize recent compelling insights into hallucinations in LLMs. We present a novel taxonomy of hallucinations from various text generation tasks, thus provide theoretical insights, detection methods and improvement approaches. Based on this, future research directions are proposed. Our contribution are threefold: (1) We provide a detailed and complete taxonomy for hallucinations appearing in text generation tasks; (2) We provide theoretical analyses of hallucinations in LLMs and provide existing detection and improvement methods; (3) We propose several research directions that can be developed in the future. As hallucinations garner significant attention from the community, we will maintain updates on relevant research progress.",
    "path": "papers/23/09/2309.06794.json",
    "total_tokens": 861,
    "translated_title": "认知幻觉：大规模语言模型中幻觉现象的综述",
    "translated_abstract": "随着人工智能领域中大规模语言模型的发展，文本生成系统容易受到一种令人担忧的现象，即幻觉。在本研究中，我们总结了最近关于大规模语言模型中幻觉的引人注目的见解。我们提出了一种针对各种文本生成任务的幻觉的新分类体系，从而提供了理论性的洞见、检测方法和改进方法。基于此，我们提出了未来的研究方向。我们的贡献有三个方面：（1）我们为出现在文本生成任务中的幻觉提供了详细和完整的分类体系；（2）我们对大规模语言模型中的幻觉进行了理论分析，并提供了现有的检测和改进方法；（3）我们提出了几个未来可以发展的研究方向。由于幻觉受到了学术界的广泛关注，我们将维护与相关研究进展的更新。",
    "tldr": "这篇论文综述了大规模语言模型中幻觉的现象，并提出了幻觉的分类、理论分析、检测方法和改进方法，同时还设想了未来的研究方向。",
    "en_tdlr": "This paper provides a review of hallucinations in large language models, including a taxonomy, theoretical analysis, detection, and improvement methods. It also suggests future research directions in this field."
}