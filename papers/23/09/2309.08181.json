{
    "title": "Large Language Models for Failure Mode Classification: An Investigation. (arXiv:2309.08181v1 [cs.CL])",
    "abstract": "In this paper we present the first investigation into the effectiveness of Large Language Models (LLMs) for Failure Mode Classification (FMC). FMC, the task of automatically labelling an observation with a corresponding failure mode code, is a critical task in the maintenance domain as it reduces the need for reliability engineers to spend their time manually analysing work orders. We detail our approach to prompt engineering to enable an LLM to predict the failure mode of a given observation using a restricted code list. We demonstrate that the performance of a GPT-3.5 model (F1=0.80) fine-tuned on annotated data is a significant improvement over a currently available text classification model (F1=0.60) trained on the same annotated data set. The fine-tuned model also outperforms the out-of-the box GPT-3.5 (F1=0.46). This investigation reinforces the need for high quality fine-tuning data sets for domain-specific tasks using LLMs.",
    "link": "http://arxiv.org/abs/2309.08181",
    "context": "Title: Large Language Models for Failure Mode Classification: An Investigation. (arXiv:2309.08181v1 [cs.CL])\nAbstract: In this paper we present the first investigation into the effectiveness of Large Language Models (LLMs) for Failure Mode Classification (FMC). FMC, the task of automatically labelling an observation with a corresponding failure mode code, is a critical task in the maintenance domain as it reduces the need for reliability engineers to spend their time manually analysing work orders. We detail our approach to prompt engineering to enable an LLM to predict the failure mode of a given observation using a restricted code list. We demonstrate that the performance of a GPT-3.5 model (F1=0.80) fine-tuned on annotated data is a significant improvement over a currently available text classification model (F1=0.60) trained on the same annotated data set. The fine-tuned model also outperforms the out-of-the box GPT-3.5 (F1=0.46). This investigation reinforces the need for high quality fine-tuning data sets for domain-specific tasks using LLMs.",
    "path": "papers/23/09/2309.08181.json",
    "total_tokens": 911,
    "translated_title": "大型语言模型用于故障模式分类的研究",
    "translated_abstract": "本文首次研究了大型语言模型 (LLMs) 在故障模式分类 (FMC) 中的有效性。FMC 是在维护领域中自动为观测结果标记相应故障模式代码的重要任务，它可以减少可靠性工程师手动分析工作指令的时间。我们详细介绍了我们的方法，即通过提示工程来使 LLM 能够使用受限制的代码列表来预测给定观测结果的故障模式。我们证明了在注释数据上细调的 GPT-3.5 模型 (F1=0.80) 的性能显著优于当前可用的在相同注释数据集上训练的文本分类模型 (F1=0.60)。细调模型还优于开箱即用的 GPT-3.5 (F1=0.46)。该研究强调了对使用LLMs进行领域特定任务的高质量微调数据集的需求。",
    "tldr": "本研究探讨了大型语言模型在故障模式分类中的应用，通过细调GPT-3.5模型在注释数据上取得了显著提升的性能，优于当前可用的文本分类模型和开箱即用的GPT-3.5模型。"
}