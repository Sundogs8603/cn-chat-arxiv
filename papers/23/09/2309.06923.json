{
    "title": "Native Language Identification with Big Bird Embeddings. (arXiv:2309.06923v1 [cs.CL])",
    "abstract": "Native Language Identification (NLI) intends to classify an author's native language based on their writing in another language. Historically, the task has heavily relied on time-consuming linguistic feature engineering, and transformer-based NLI models have thus far failed to offer effective, practical alternatives. The current work investigates if input size is a limiting factor, and shows that classifiers trained using Big Bird embeddings outperform linguistic feature engineering models by a large margin on the Reddit-L2 dataset. Additionally, we provide further insight into input length dependencies, show consistent out-of-sample performance, and qualitatively analyze the embedding space. Given the effectiveness and computational efficiency of this method, we believe it offers a promising avenue for future NLI work.",
    "link": "http://arxiv.org/abs/2309.06923",
    "context": "Title: Native Language Identification with Big Bird Embeddings. (arXiv:2309.06923v1 [cs.CL])\nAbstract: Native Language Identification (NLI) intends to classify an author's native language based on their writing in another language. Historically, the task has heavily relied on time-consuming linguistic feature engineering, and transformer-based NLI models have thus far failed to offer effective, practical alternatives. The current work investigates if input size is a limiting factor, and shows that classifiers trained using Big Bird embeddings outperform linguistic feature engineering models by a large margin on the Reddit-L2 dataset. Additionally, we provide further insight into input length dependencies, show consistent out-of-sample performance, and qualitatively analyze the embedding space. Given the effectiveness and computational efficiency of this method, we believe it offers a promising avenue for future NLI work.",
    "path": "papers/23/09/2309.06923.json",
    "total_tokens": 791,
    "translated_title": "基于Big Bird嵌入的母语识别",
    "translated_abstract": "母语识别旨在根据作者用另一种语言编写的内容来分类其母语。在历史上，该任务严重依赖耗时的语言特征工程，而基于Transformer的母语识别模型迄今为止未能提供有效、实用的替代方案。本研究研究了输入大小是否是一个限制因素，并展示了使用Big Bird嵌入训练的分类器在Reddit-L2数据集上相对于语言特征工程模型取得了显著的优势。此外，我们还提供了对输入长度依赖性的进一步洞察，展示了一致的样本外性能，并对嵌入空间进行了定性分析。考虑到这种方法的效果和计算效率，我们认为它为未来的母语识别工作提供了有前景的途径。",
    "tldr": "本研究通过使用Big Bird嵌入训练的分类器，在Reddit-L2数据集上超越了语言特征工程模型。此方法显示出了有效性和计算效率，为未来的母语识别工作提供了有前景的途径。",
    "en_tdlr": "This paper shows that classifiers trained using Big Bird embeddings outperform linguistic feature engineering models on the Reddit-L2 dataset, providing an effective and computationally efficient method for native language identification."
}