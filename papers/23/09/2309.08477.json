{
    "title": "Deep Multi-Agent Reinforcement Learning for Decentralized Active Hypothesis Testing. (arXiv:2309.08477v1 [stat.ML])",
    "abstract": "We consider a decentralized formulation of the active hypothesis testing (AHT) problem, where multiple agents gather noisy observations from the environment with the purpose of identifying the correct hypothesis. At each time step, agents have the option to select a sampling action. These different actions result in observations drawn from various distributions, each associated with a specific hypothesis. The agents collaborate to accomplish the task, where message exchanges between agents are allowed over a rate-limited communications channel. The objective is to devise a multi-agent policy that minimizes the Bayes risk. This risk comprises both the cost of sampling and the joint terminal cost incurred by the agents upon making a hypothesis declaration. Deriving optimal structured policies for AHT problems is generally mathematically intractable, even in the context of a single agent. As a result, recent efforts have turned to deep learning methodologies to address these problems, whi",
    "link": "http://arxiv.org/abs/2309.08477",
    "context": "Title: Deep Multi-Agent Reinforcement Learning for Decentralized Active Hypothesis Testing. (arXiv:2309.08477v1 [stat.ML])\nAbstract: We consider a decentralized formulation of the active hypothesis testing (AHT) problem, where multiple agents gather noisy observations from the environment with the purpose of identifying the correct hypothesis. At each time step, agents have the option to select a sampling action. These different actions result in observations drawn from various distributions, each associated with a specific hypothesis. The agents collaborate to accomplish the task, where message exchanges between agents are allowed over a rate-limited communications channel. The objective is to devise a multi-agent policy that minimizes the Bayes risk. This risk comprises both the cost of sampling and the joint terminal cost incurred by the agents upon making a hypothesis declaration. Deriving optimal structured policies for AHT problems is generally mathematically intractable, even in the context of a single agent. As a result, recent efforts have turned to deep learning methodologies to address these problems, whi",
    "path": "papers/23/09/2309.08477.json",
    "total_tokens": 855,
    "translated_title": "分布式主动假设测试的深度多智能体强化学习",
    "translated_abstract": "我们考虑了分布式主动假设测试（AHT）问题的一个分布式形式，在这个问题中，多个智能体从环境中收集到带噪声的观测数据，目的是识别出正确的假设。在每个时间步骤中，智能体可以选择一个采样动作，这些不同的动作会导致从不同分布中抽取观测数据，每个分布与一个特定的假设相关联。智能体通过在有限速率的通信通道上进行消息交换来合作完成任务。目标是设计一个多智能体策略，将贝叶斯风险最小化。这种风险包括采样成本和智能体在声明假设时产生的联合终端成本。在AHT问题中推导出最优的结构化策略通常在数学上是难以处理的，即使是在单个智能体的背景下也是如此。因此，最近的研究工作转向深度学习方法来解决这些问题，这些方法包括...",
    "tldr": "这个论文提出了一个分布式主动假设测试（AHT）问题的解决方法，通过多智能体强化学习，设计一个策略来在有限通信通道上合作完成任务，将贝叶斯风险最小化。"
}