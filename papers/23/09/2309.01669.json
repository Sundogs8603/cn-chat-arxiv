{
    "title": "Donkii: Can Annotation Error Detection Methods Find Errors in Instruction-Tuning Datasets?",
    "abstract": "arXiv:2309.01669v2 Announce Type: replace  Abstract: Instruction tuning has become an integral part of training pipelines for Large Language Models (LLMs) and has been shown to yield strong performance gains. In an orthogonal line of research, Annotation Error Detection (AED) has emerged as a tool for detecting quality problems in gold standard labels. So far, however, the application of AED methods has been limited to classification tasks. It is an open question how well AED methods generalize to language generation settings, which are becoming more widespread via LLMs. In this paper, we present a first and novel benchmark for AED on instruction tuning data: DONKII. It comprises three instruction-tuning datasets enriched with error annotations by experts and semi-automatic methods. We also provide a novel taxonomy of error types for instruction-tuning data. We find that all three datasets contain clear errors, which sometimes propagate directly into instruction-tuned LLMs. We propose ",
    "link": "https://arxiv.org/abs/2309.01669",
    "context": "Title: Donkii: Can Annotation Error Detection Methods Find Errors in Instruction-Tuning Datasets?\nAbstract: arXiv:2309.01669v2 Announce Type: replace  Abstract: Instruction tuning has become an integral part of training pipelines for Large Language Models (LLMs) and has been shown to yield strong performance gains. In an orthogonal line of research, Annotation Error Detection (AED) has emerged as a tool for detecting quality problems in gold standard labels. So far, however, the application of AED methods has been limited to classification tasks. It is an open question how well AED methods generalize to language generation settings, which are becoming more widespread via LLMs. In this paper, we present a first and novel benchmark for AED on instruction tuning data: DONKII. It comprises three instruction-tuning datasets enriched with error annotations by experts and semi-automatic methods. We also provide a novel taxonomy of error types for instruction-tuning data. We find that all three datasets contain clear errors, which sometimes propagate directly into instruction-tuned LLMs. We propose ",
    "path": "papers/23/09/2309.01669.json",
    "total_tokens": 881,
    "translated_title": "Donkii: 注释错误检测方法能否发现指令调整数据集中的错误？",
    "translated_abstract": "指导调整已成为大型语言模型（LLMs）训练流程中不可或缺的一部分，并已被证明能够产生强大的性能增益。 在研究的另一条线上，注释错误检测（AED）已经成为检测黄金标准标签中质量问题的工具。然而，到目前为止，AED方法的应用已经被限制在分类任务中。 如何评估AED方法在语言生成设置中的泛化能力仍然是一个未解之谜，这一设置通过LLMs正在变得越来越普遍。 本文提出了一个针对指令调整数据的AED的首个新颖基准：DONKII。 它包括三个由专家和半自动方法增强错误注释的指令调整数据集。 我们还为指令调整数据提供了新颖的错误类型分类法。 我们发现所有三个数据集都包含明显的错误，有时这些错误直接传播到指令调整的LLMs中。",
    "tldr": "本文提出了一个新颖的指令调整数据的AED基准DONKII，并发现所有三个数据集都包含明显的错误，有时这些错误直接传播到指令调整的LLMs中。",
    "en_tdlr": "This paper introduces a novel benchmark DONKII for AED on instruction tuning data and finds clear errors in all three datasets, which sometimes propagate directly into instruction-tuned LLMs."
}