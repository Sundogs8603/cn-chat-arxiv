{
    "title": "Feature Normalization Prevents Collapse of Non-contrastive Learning Dynamics. (arXiv:2309.16109v1 [cs.LG])",
    "abstract": "Contrastive learning is a self-supervised representation learning framework, where two positive views generated through data augmentation are made similar by an attraction force in a data representation space, while a repulsive force makes them far from negative examples. Non-contrastive learning, represented by BYOL and SimSiam, further gets rid of negative examples and improves computational efficiency. While learned representations may collapse into a single point due to the lack of the repulsive force at first sight, Tian et al. (2021) revealed through the learning dynamics analysis that the representations can avoid collapse if data augmentation is sufficiently stronger than regularization. However, their analysis does not take into account commonly-used feature normalization, a normalizer before measuring the similarity of representations, and hence excessively strong regularization may collapse the dynamics, which is an unnatural behavior under the presence of feature normalizat",
    "link": "http://arxiv.org/abs/2309.16109",
    "context": "Title: Feature Normalization Prevents Collapse of Non-contrastive Learning Dynamics. (arXiv:2309.16109v1 [cs.LG])\nAbstract: Contrastive learning is a self-supervised representation learning framework, where two positive views generated through data augmentation are made similar by an attraction force in a data representation space, while a repulsive force makes them far from negative examples. Non-contrastive learning, represented by BYOL and SimSiam, further gets rid of negative examples and improves computational efficiency. While learned representations may collapse into a single point due to the lack of the repulsive force at first sight, Tian et al. (2021) revealed through the learning dynamics analysis that the representations can avoid collapse if data augmentation is sufficiently stronger than regularization. However, their analysis does not take into account commonly-used feature normalization, a normalizer before measuring the similarity of representations, and hence excessively strong regularization may collapse the dynamics, which is an unnatural behavior under the presence of feature normalizat",
    "path": "papers/23/09/2309.16109.json",
    "total_tokens": 835,
    "translated_title": "特征归一化防止非对比学习动力的崩溃",
    "translated_abstract": "对比学习是一种自监督表示学习框架，通过数据增强生成的两个正视图在数据表示空间中通过吸引力使它们相似，而通过排斥力使它们远离负样本。非对比学习通过BYOL和SimSiam等手段去除了负样本，并提高了计算效率。虽然由于缺乏排斥力，学到的表示可能会崩溃成一个单点，但田等人（2021）通过学习动力分析揭示，如果数据增强足够强于正则化，则表示可以避免崩溃。然而，他们的分析没有考虑常用的特征归一化，即在衡量表示相似性之前进行的归一化操作，因此过强的正则化可能会导致动力崩溃，这在特征归一化存在的情况下是不自然的行为。",
    "tldr": "本论文研究了非对比学习中的动力崩溃问题，发现特征归一化可以防止此问题的出现，为解决自监督表示学习的计算效率提供了新的思路。",
    "en_tdlr": "This paper investigates the issue of collapse in non-contrastive learning and proposes that feature normalization can prevent this problem, providing new insights towards addressing computational efficiency in self-supervised representation learning."
}