{
    "title": "Practical Homomorphic Aggregation for Byzantine ML. (arXiv:2309.05395v2 [cs.LG] UPDATED)",
    "abstract": "Due to the large-scale availability of data, machine learning (ML) algorithms are being deployed in distributed topologies, where different nodes collaborate to train ML models over their individual data by exchanging model-related information (e.g., gradients) with a central server. However, distributed learning schemes are notably vulnerable to two threats. First, Byzantine nodes can single-handedly corrupt the learning by sending incorrect information to the server, e.g., erroneous gradients. The standard approach to mitigate such behavior is to use a non-linear robust aggregation method at the server. Second, the server can violate the privacy of the nodes. Recent attacks have shown that exchanging (unencrypted) gradients enables a curious server to recover the totality of the nodes' data. The use of homomorphic encryption (HE), a gold standard security primitive, has extensively been studied as a privacy-preserving solution to distributed learning in non-Byzantine scenarios. Howev",
    "link": "http://arxiv.org/abs/2309.05395",
    "context": "Title: Practical Homomorphic Aggregation for Byzantine ML. (arXiv:2309.05395v2 [cs.LG] UPDATED)\nAbstract: Due to the large-scale availability of data, machine learning (ML) algorithms are being deployed in distributed topologies, where different nodes collaborate to train ML models over their individual data by exchanging model-related information (e.g., gradients) with a central server. However, distributed learning schemes are notably vulnerable to two threats. First, Byzantine nodes can single-handedly corrupt the learning by sending incorrect information to the server, e.g., erroneous gradients. The standard approach to mitigate such behavior is to use a non-linear robust aggregation method at the server. Second, the server can violate the privacy of the nodes. Recent attacks have shown that exchanging (unencrypted) gradients enables a curious server to recover the totality of the nodes' data. The use of homomorphic encryption (HE), a gold standard security primitive, has extensively been studied as a privacy-preserving solution to distributed learning in non-Byzantine scenarios. Howev",
    "path": "papers/23/09/2309.05395.json",
    "total_tokens": 850,
    "translated_title": "适用于拜占庭式机器学习的实用同态聚合",
    "translated_abstract": "由于数据的大规模可用性，机器学习算法正在分布式拓扑中部署，不同的节点通过与中央服务器交换与模型相关的信息（例如梯度）来共同训练其个体数据上的机器学习模型。然而，分布式学习方案容易受到两种威胁。首先，拜占庭式节点可以通过向服务器发送不正确的信息（例如错误的梯度）单独破坏学习过程。缓解此类行为的标准方法是在服务器上使用非线性鲁棒聚合方法。其次，服务器可以侵犯节点的隐私。最近的攻击已经表明，交换（未加密的）梯度使得一个好奇的服务器能够恢复出所有节点的数据。同态加密（HE），一种金标准安全原语，已经广泛研究作为非拜占庭场景中分布式学习的隐私保护解决方案。",
    "tldr": "本文介绍了一种适用于拜占庭式机器学习的实用同态聚合方法，以应对拜占庭节点和服务器隐私侵犯的问题。",
    "en_tdlr": "This paper presents a practical homomorphic aggregation method for Byzantine machine learning, addressing the issues of Byzantine nodes and server privacy violation."
}