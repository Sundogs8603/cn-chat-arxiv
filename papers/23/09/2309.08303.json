{
    "title": "Self-Consistent Narrative Prompts on Abductive Natural Language Inference. (arXiv:2309.08303v1 [cs.CL])",
    "abstract": "Abduction has long been seen as crucial for narrative comprehension and reasoning about everyday situations. The abductive natural language inference ($\\alpha$NLI) task has been proposed, and this narrative text-based task aims to infer the most plausible hypothesis from the candidates given two observations. However, the inter-sentential coherence and the model consistency have not been well exploited in the previous works on this task. In this work, we propose a prompt tuning model $\\alpha$-PACE, which takes self-consistency and inter-sentential coherence into consideration. Besides, we propose a general self-consistent framework that considers various narrative sequences (e.g., linear narrative and reverse chronology) for guiding the pre-trained language model in understanding the narrative context of input. We conduct extensive experiments and thorough ablation studies to illustrate the necessity and effectiveness of $\\alpha$-PACE. The performance of our method shows significant im",
    "link": "http://arxiv.org/abs/2309.08303",
    "context": "Title: Self-Consistent Narrative Prompts on Abductive Natural Language Inference. (arXiv:2309.08303v1 [cs.CL])\nAbstract: Abduction has long been seen as crucial for narrative comprehension and reasoning about everyday situations. The abductive natural language inference ($\\alpha$NLI) task has been proposed, and this narrative text-based task aims to infer the most plausible hypothesis from the candidates given two observations. However, the inter-sentential coherence and the model consistency have not been well exploited in the previous works on this task. In this work, we propose a prompt tuning model $\\alpha$-PACE, which takes self-consistency and inter-sentential coherence into consideration. Besides, we propose a general self-consistent framework that considers various narrative sequences (e.g., linear narrative and reverse chronology) for guiding the pre-trained language model in understanding the narrative context of input. We conduct extensive experiments and thorough ablation studies to illustrate the necessity and effectiveness of $\\alpha$-PACE. The performance of our method shows significant im",
    "path": "papers/23/09/2309.08303.json",
    "total_tokens": 802,
    "translated_title": "自洽叙述式启示在演绎自然语言推理中的应用",
    "translated_abstract": "对于故事理解和日常情境推理，演绎一直被视为至关重要的。提出了一种基于自然语言的演绎任务 - 自然语言推理（$\\alpha$NLI）任务，旨在从两个观察中推断出最合理的假设。然而，在以往的研究中，句间连贯性和模型一致性的利用并不充分。本文提出了一个考虑自洽性和句间连贯性的提示调优模型 $\\alpha$-PACE。此外，还提出了一个通用的自洽框架，用于引导预训练语言模型理解输入的叙述背景，其中包括线性叙述和逆时间顺序等各种叙述序列。通过大量实验证明了 $\\alpha$-PACE 的必要性和有效性。我们的方法的性能表现出显著的改善。",
    "tldr": "该论文提出了一个考虑自洽性和句间连贯性的自然语言推理模型，并通过实验证明了其有效性。",
    "en_tdlr": "This paper proposes a natural language inference model that considers self-consistency and inter-sentential coherence, and demonstrates its effectiveness through experiments."
}