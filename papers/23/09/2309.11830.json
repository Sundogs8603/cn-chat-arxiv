{
    "title": "A Chinese Prompt Attack Dataset for LLMs with Evil Content. (arXiv:2309.11830v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs) present significant priority in text understanding and generation. However, LLMs suffer from the risk of generating harmful contents especially while being employed to applications. There are several black-box attack methods, such as Prompt Attack, which can change the behaviour of LLMs and induce LLMs to generate unexpected answers with harmful contents. Researchers are interested in Prompt Attack and Defense with LLMs, while there is no publicly available dataset to evaluate the abilities of defending prompt attack. In this paper, we introduce a Chinese Prompt Attack Dataset for LLMs, called CPAD. Our prompts aim to induce LLMs to generate unexpected outputs with several carefully designed prompt attack approaches and widely concerned attacking contents. Different from previous datasets involving safety estimation, We construct the prompts considering three dimensions: contents, attacking methods and goals, thus the responses can be easily evaluated and a",
    "link": "http://arxiv.org/abs/2309.11830",
    "context": "Title: A Chinese Prompt Attack Dataset for LLMs with Evil Content. (arXiv:2309.11830v1 [cs.CL])\nAbstract: Large Language Models (LLMs) present significant priority in text understanding and generation. However, LLMs suffer from the risk of generating harmful contents especially while being employed to applications. There are several black-box attack methods, such as Prompt Attack, which can change the behaviour of LLMs and induce LLMs to generate unexpected answers with harmful contents. Researchers are interested in Prompt Attack and Defense with LLMs, while there is no publicly available dataset to evaluate the abilities of defending prompt attack. In this paper, we introduce a Chinese Prompt Attack Dataset for LLMs, called CPAD. Our prompts aim to induce LLMs to generate unexpected outputs with several carefully designed prompt attack approaches and widely concerned attacking contents. Different from previous datasets involving safety estimation, We construct the prompts considering three dimensions: contents, attacking methods and goals, thus the responses can be easily evaluated and a",
    "path": "papers/23/09/2309.11830.json",
    "total_tokens": 767,
    "translated_title": "一个用于具有恶意内容的LLMs的中文提示攻击数据集",
    "translated_abstract": "大型语言模型（LLMs）在文本理解和生成方面具有重要优点。然而，LLMs在应用中存在生成有害内容的风险，尤其是在使用Prompt Attack等黑盒攻击方法时。研究人员对LLMs的Prompt Attack和Defense很感兴趣，但目前没有公开可用的数据集来评估防御Prompt Attack的能力。在本文中，我们介绍了一个用于LLMs的中文Prompt Attack数据集，称为CPAD。我们的提示旨在引导LLMs生成具有多个精心设计的提示攻击方法和广泛关注的攻击内容的意外输出。与以前涉及安全估计的数据集不同，我们构建的提示考虑了三个维度：内容、攻击方法和目标，因此可以轻松评估响应。",
    "tldr": "这个论文介绍了一个用于LLMs的中文Prompt Attack数据集，该数据集旨在评估防御提示攻击的能力。",
    "en_tdlr": "This paper introduces a Chinese Prompt Attack Dataset for LLMs, which aims to evaluate the ability to defend against prompt attacks."
}