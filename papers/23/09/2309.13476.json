{
    "title": "Hierarchical attention interpretation: an interpretable speech-level transformer for bi-modal depression detection. (arXiv:2309.13476v2 [cs.CL] UPDATED)",
    "abstract": "Depression is a common mental disorder. Automatic depression detection tools using speech, enabled by machine learning, help early screening of depression. This paper addresses two limitations that may hinder the clinical implementations of such tools: noise resulting from segment-level labelling and a lack of model interpretability. We propose a bi-modal speech-level transformer to avoid segment-level labelling and introduce a hierarchical interpretation approach to provide both speech-level and sentence-level interpretations, based on gradient-weighted attention maps derived from all attention layers to track interactions between input features. We show that the proposed model outperforms a model that learns at a segment level ($p$=0.854, $r$=0.947, $F1$=0.897 compared to $p$=0.732, $r$=0.808, $F1$=0.768). For model interpretation, using one true positive sample, we show which sentences within a given speech are most relevant to depression detection; and which text tokens and Mel-spe",
    "link": "http://arxiv.org/abs/2309.13476",
    "context": "Title: Hierarchical attention interpretation: an interpretable speech-level transformer for bi-modal depression detection. (arXiv:2309.13476v2 [cs.CL] UPDATED)\nAbstract: Depression is a common mental disorder. Automatic depression detection tools using speech, enabled by machine learning, help early screening of depression. This paper addresses two limitations that may hinder the clinical implementations of such tools: noise resulting from segment-level labelling and a lack of model interpretability. We propose a bi-modal speech-level transformer to avoid segment-level labelling and introduce a hierarchical interpretation approach to provide both speech-level and sentence-level interpretations, based on gradient-weighted attention maps derived from all attention layers to track interactions between input features. We show that the proposed model outperforms a model that learns at a segment level ($p$=0.854, $r$=0.947, $F1$=0.897 compared to $p$=0.732, $r$=0.808, $F1$=0.768). For model interpretation, using one true positive sample, we show which sentences within a given speech are most relevant to depression detection; and which text tokens and Mel-spe",
    "path": "papers/23/09/2309.13476.json",
    "total_tokens": 1049,
    "translated_title": "分层注意解释：一种用于双模式抑郁症检测的可解释性语音级变换器",
    "translated_abstract": "抑郁症是一种常见的心理障碍。使用机器学习实现的语音自动抑郁症检测工具有助于早期筛查抑郁症。本文针对这类工具可能存在的两个限制进行了探讨：由分段级标注导致的噪声和模型解释性的缺乏。我们提出了一种双模式语音级变换器来避免分段级标注，同时引入了一种层次化解释方法，根据从所有注意力层导出的梯度加权注意力图来追踪输入特征之间的交互作用，以提供语音级和句子级解释。我们展示了所提出的模型优于在分段级学习的模型（$p$=0.854, $r$=0.947, $F1$=0.897，与$p$=0.732, $r$=0.808, $F1$=0.768相比）。在模型解释方面，使用一个真实阳性样本，我们展示了哪些句子对于抑郁症检测相关性最高，以及哪些文本标记和Mel声谱图与之相关。",
    "tldr": "本文提出了一种双模式语音级变换器，通过引入分层解释方法解决了自动抑郁症检测工具中的标注噪声和模型解释性问题，同时展示了其在性能上的优势。该模型通过梯度加权注意力图追踪输入特征之间的交互作用，可以提供语音级和句子级的解释。"
}