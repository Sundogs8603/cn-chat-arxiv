{
    "title": "Supersonic: Learning to Generate Source Code Optimisations in C/C++. (arXiv:2309.14846v1 [cs.SE])",
    "abstract": "Software optimization refines programs for resource efficiency while preserving functionality. Traditionally, it is a process done by developers and compilers. This paper introduces a third option, automated optimization at the source code level. We present Supersonic, a neural approach targeting minor source code modifications for optimization. Using a seq2seq model, Supersonic is trained on C/C++ program pairs ($x_{t}$, $x_{t+1}$), where $x_{t+1}$ is an optimized version of $x_{t}$, and outputs a diff. Supersonic's performance is benchmarked against OpenAI's GPT-3.5-Turbo and GPT-4 on competitive programming tasks. The experiments show that Supersonic not only outperforms both models on the code optimization task, but also minimizes the extent of change with a more than 600x smaller than GPT-3.5-Turbo and 3700x smaller than GPT-4.",
    "link": "http://arxiv.org/abs/2309.14846",
    "context": "Title: Supersonic: Learning to Generate Source Code Optimisations in C/C++. (arXiv:2309.14846v1 [cs.SE])\nAbstract: Software optimization refines programs for resource efficiency while preserving functionality. Traditionally, it is a process done by developers and compilers. This paper introduces a third option, automated optimization at the source code level. We present Supersonic, a neural approach targeting minor source code modifications for optimization. Using a seq2seq model, Supersonic is trained on C/C++ program pairs ($x_{t}$, $x_{t+1}$), where $x_{t+1}$ is an optimized version of $x_{t}$, and outputs a diff. Supersonic's performance is benchmarked against OpenAI's GPT-3.5-Turbo and GPT-4 on competitive programming tasks. The experiments show that Supersonic not only outperforms both models on the code optimization task, but also minimizes the extent of change with a more than 600x smaller than GPT-3.5-Turbo and 3700x smaller than GPT-4.",
    "path": "papers/23/09/2309.14846.json",
    "total_tokens": 835,
    "translated_title": "Supersonic: 学习在C/C++中生成源代码优化",
    "translated_abstract": "软件优化在保持功能的同时改善资源效率。传统上，这是由开发人员和编译器完成的过程。本文介绍了第三种选择，即在源代码级别进行自动优化。我们提出了Supersonic，一个针对优化的轻微源代码修改的神经方法。使用seq2seq模型，Supersonic在C / C ++程序对（$x_{t}$，$x_{t+1}$）上进行训练，其中$x_{t+1}$是$x_{t}$的优化版本，并输出一个差异。Supersonic的性能在竞技编程任务上与OpenAI的GPT-3.5-Turbo和GPT-4进行了基准测试。实验表明，Supersonic不仅在代码优化任务上胜过了这两个模型，而且改变的程度比GPT-3.5-Turbo小了600多倍，比GPT-4小了3700多倍。",
    "tldr": "Supersonic 是一个神经方法，用于在C/C++中进行源代码优化。与GPT-3.5-Turbo和GPT-4相比，它在代码优化任务上表现更好，并且改变的程度更小。",
    "en_tdlr": "Supersonic is a neural approach for source code optimization in C/C++. It outperforms GPT-3.5-Turbo and GPT-4 on code optimization tasks and achieves a significantly smaller degree of change."
}