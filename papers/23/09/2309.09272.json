{
    "title": "Deep Neighbor Layer Aggregation for Lightweight Self-Supervised Monocular Depth Estimation. (arXiv:2309.09272v2 [cs.CV] UPDATED)",
    "abstract": "With the frequent use of self-supervised monocular depth estimation in robotics and autonomous driving, the model's efficiency is becoming increasingly important. Most current approaches apply much larger and more complex networks to improve the precision of depth estimation. Some researchers incorporated Transformer into self-supervised monocular depth estimation to achieve better performance. However, this method leads to high parameters and high computation. We present a fully convolutional depth estimation network using contextual feature fusion. Compared to UNet++ and HRNet, we use high-resolution and low-resolution features to reserve information on small targets and fast-moving objects instead of long-range fusion. We further promote depth estimation results employing lightweight channel attention based on convolution in the decoder stage. Our method reduces the parameters without sacrificing accuracy. Experiments on the KITTI benchmark show that our method can get better result",
    "link": "http://arxiv.org/abs/2309.09272",
    "context": "Title: Deep Neighbor Layer Aggregation for Lightweight Self-Supervised Monocular Depth Estimation. (arXiv:2309.09272v2 [cs.CV] UPDATED)\nAbstract: With the frequent use of self-supervised monocular depth estimation in robotics and autonomous driving, the model's efficiency is becoming increasingly important. Most current approaches apply much larger and more complex networks to improve the precision of depth estimation. Some researchers incorporated Transformer into self-supervised monocular depth estimation to achieve better performance. However, this method leads to high parameters and high computation. We present a fully convolutional depth estimation network using contextual feature fusion. Compared to UNet++ and HRNet, we use high-resolution and low-resolution features to reserve information on small targets and fast-moving objects instead of long-range fusion. We further promote depth estimation results employing lightweight channel attention based on convolution in the decoder stage. Our method reduces the parameters without sacrificing accuracy. Experiments on the KITTI benchmark show that our method can get better result",
    "path": "papers/23/09/2309.09272.json",
    "total_tokens": 921,
    "translated_title": "深度邻居层聚合用于轻量级自监督单眼深度估计",
    "translated_abstract": "随着自监督单眼深度估计在机器人和自动驾驶领域的频繁使用，模型的效率变得越来越重要。目前大多数方法采用更大、更复杂的网络来提高深度估计的准确性。一些研究者将Transformer引入到自监督单眼深度估计中以获得更好的性能，但这种方法导致参数和计算量较高。我们提出了一种使用上下文特征融合的完全卷积深度估计网络。与UNet++和HRNet不同，我们使用高分辨率和低分辨率特征来保留小目标和快速移动物体的信息，而不是进行远程融合。在解码器阶段，我们还采用基于卷积的轻量级通道注意力来提升深度估计结果。我们的方法减少了参数数量而不损失准确性。在KITTI基准测试中的实验证明了我们的方法可以获得更好的结果。",
    "tldr": "该论文提出了一种用于轻量级自监督单眼深度估计的深度邻居层聚合方法，通过使用上下文特征融合和轻量级通道注意力，在减少参数数量的同时保持准确性，在KITTI基准测试中取得了更好的结果。"
}