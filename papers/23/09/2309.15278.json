{
    "title": "Out of Sight, Still in Mind: Reasoning and Planning about Unobserved Objects with Video Tracking Enabled Memory Models. (arXiv:2309.15278v1 [cs.RO])",
    "abstract": "Robots need to have a memory of previously observed, but currently occluded objects to work reliably in realistic environments. We investigate the problem of encoding object-oriented memory into a multi-object manipulation reasoning and planning framework. We propose DOOM and LOOM, which leverage transformer relational dynamics to encode the history of trajectories given partial-view point clouds and an object discovery and tracking engine. Our approaches can perform multiple challenging tasks including reasoning with occluded objects, novel objects appearance, and object reappearance. Throughout our extensive simulation and real-world experiments, we find that our approaches perform well in terms of different numbers of objects and different numbers of distractor actions. Furthermore, we show our approaches outperform an implicit memory baseline.",
    "link": "http://arxiv.org/abs/2309.15278",
    "context": "Title: Out of Sight, Still in Mind: Reasoning and Planning about Unobserved Objects with Video Tracking Enabled Memory Models. (arXiv:2309.15278v1 [cs.RO])\nAbstract: Robots need to have a memory of previously observed, but currently occluded objects to work reliably in realistic environments. We investigate the problem of encoding object-oriented memory into a multi-object manipulation reasoning and planning framework. We propose DOOM and LOOM, which leverage transformer relational dynamics to encode the history of trajectories given partial-view point clouds and an object discovery and tracking engine. Our approaches can perform multiple challenging tasks including reasoning with occluded objects, novel objects appearance, and object reappearance. Throughout our extensive simulation and real-world experiments, we find that our approaches perform well in terms of different numbers of objects and different numbers of distractor actions. Furthermore, we show our approaches outperform an implicit memory baseline.",
    "path": "papers/23/09/2309.15278.json",
    "total_tokens": 822,
    "translated_title": "眼不见心不念：利用视频跟踪启用的记忆模型对未被观察到的对象进行推理和规划",
    "translated_abstract": "机器人需要具有对先前观察到但当前被遮挡的对象的记忆，以在现实环境中可靠地工作。我们研究了将面向对象的记忆编码到多对象操纵推理和规划框架中的问题。我们提出了DOOM和LOOM，它们利用转换器关系动力学来编码给定部分视点云和对象发现与跟踪引擎的轨迹历史。我们的方法可以执行多个具有挑战性的任务，包括处理被遮挡的对象，新出现的对象，以及物体重新出现。通过广泛的仿真和真实世界实验，我们发现我们的方法在不同数量的对象和不同数量的干扰动作方面表现良好。此外，我们展示了我们的方法优于隐式记忆基线。",
    "tldr": "本文研究了如何对先前观察到但当前被遮挡的对象进行推理和规划，提出了利用转换器关系动力学编码轨迹历史的方法，并在多个挑战性任务中表现出色。"
}