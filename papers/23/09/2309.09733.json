{
    "title": "Replication: Contrastive Learning and Data Augmentation in Traffic Classification Using a Flowpic Input Representation. (arXiv:2309.09733v2 [cs.LG] UPDATED)",
    "abstract": "Over the last years we witnessed a renewed interest toward Traffic Classification (TC) captivated by the rise of Deep Learning (DL). Yet, the vast majority of TC literature lacks code artifacts, performance assessments across datasets and reference comparisons against Machine Learning (ML) methods. Among those works, a recent study from IMC22 [16] is worth of attention since it adopts recent DL methodologies (namely, few-shot learning, self-supervision via contrastive learning and data augmentation) appealing for networking as they enable to learn from a few samples and transfer across datasets. The main result of [16] on the UCDAVIS19, ISCX-VPN and ISCX-Tor datasets is that, with such DL methodologies, 100 input samples are enough to achieve very high accuracy using an input representation called \"flowpic\" (i.e., a per-flow 2d histograms of the packets size evolution over time). In this paper (i) we reproduce [16] on the same datasets and (ii) we replicate its most salient aspect (the",
    "link": "http://arxiv.org/abs/2309.09733",
    "context": "Title: Replication: Contrastive Learning and Data Augmentation in Traffic Classification Using a Flowpic Input Representation. (arXiv:2309.09733v2 [cs.LG] UPDATED)\nAbstract: Over the last years we witnessed a renewed interest toward Traffic Classification (TC) captivated by the rise of Deep Learning (DL). Yet, the vast majority of TC literature lacks code artifacts, performance assessments across datasets and reference comparisons against Machine Learning (ML) methods. Among those works, a recent study from IMC22 [16] is worth of attention since it adopts recent DL methodologies (namely, few-shot learning, self-supervision via contrastive learning and data augmentation) appealing for networking as they enable to learn from a few samples and transfer across datasets. The main result of [16] on the UCDAVIS19, ISCX-VPN and ISCX-Tor datasets is that, with such DL methodologies, 100 input samples are enough to achieve very high accuracy using an input representation called \"flowpic\" (i.e., a per-flow 2d histograms of the packets size evolution over time). In this paper (i) we reproduce [16] on the same datasets and (ii) we replicate its most salient aspect (the",
    "path": "papers/23/09/2309.09733.json",
    "total_tokens": 983,
    "translated_title": "复制：在流量分类中使用Flowpic输入表示的对比学习和数据增强",
    "translated_abstract": "在过去的几年里，由于深度学习的兴起，我们见证了对流量分类（TC）的重新关注。然而，绝大部分 TC 文献缺乏代码工件、跨数据集的性能评估以及与机器学习（ML）方法的参考比较。其中，IMC22[16]的一项最近研究值得关注，因为它采用了最近的深度学习方法（即少样本学习、自监督对比学习和数据增强），这对于网络来说非常有吸引力，因为它们可以从少量样本中学习并在不同的数据集之间传输。[16]的主要结果是，在UCDAVIS19、ISCX-VPN和ISCX-Tor数据集上，使用这些深度学习方法，只需100个输入样本就可以实现非常高的准确性，使用的输入表示叫做“flowpic”（即在时间上演变的数据包大小的分指标的二维直方图）。本文的目标是(i)在相同的数据集上重现[16]的结果，以及(ii)复制其最显著的方面（即对比学习和数据增强）。",
    "tldr": "这项研究复制并重现了一项先前的流量分类研究，该研究使用了对比学习和数据增强的深度学习方法，证明了使用Flowpic输入表示能够在仅有100个样本的情况下实现高准确性。",
    "en_tdlr": "This study replicates and reproduces a previous research on traffic classification, which utilizes contrastive learning and data augmentation in deep learning methods. It demonstrates that high accuracy can be achieved using Flowpic input representation with only 100 samples."
}