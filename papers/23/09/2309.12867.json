{
    "title": "Accurate and Fast Compressed Video Captioning. (arXiv:2309.12867v1 [cs.CV])",
    "abstract": "Existing video captioning approaches typically require to first sample video frames from a decoded video and then conduct a subsequent process (e.g., feature extraction and/or captioning model learning). In this pipeline, manual frame sampling may ignore key information in videos and thus degrade performance. Additionally, redundant information in the sampled frames may result in low efficiency in the inference of video captioning. Addressing this, we study video captioning from a different perspective in compressed domain, which brings multi-fold advantages over the existing pipeline: 1) Compared to raw images from the decoded video, the compressed video, consisting of I-frames, motion vectors and residuals, is highly distinguishable, which allows us to leverage the entire video for learning without manual sampling through a specialized model design; 2) The captioning model is more efficient in inference as smaller and less redundant information is processed. We propose a simple yet e",
    "link": "http://arxiv.org/abs/2309.12867",
    "context": "Title: Accurate and Fast Compressed Video Captioning. (arXiv:2309.12867v1 [cs.CV])\nAbstract: Existing video captioning approaches typically require to first sample video frames from a decoded video and then conduct a subsequent process (e.g., feature extraction and/or captioning model learning). In this pipeline, manual frame sampling may ignore key information in videos and thus degrade performance. Additionally, redundant information in the sampled frames may result in low efficiency in the inference of video captioning. Addressing this, we study video captioning from a different perspective in compressed domain, which brings multi-fold advantages over the existing pipeline: 1) Compared to raw images from the decoded video, the compressed video, consisting of I-frames, motion vectors and residuals, is highly distinguishable, which allows us to leverage the entire video for learning without manual sampling through a specialized model design; 2) The captioning model is more efficient in inference as smaller and less redundant information is processed. We propose a simple yet e",
    "path": "papers/23/09/2309.12867.json",
    "total_tokens": 855,
    "translated_title": "准确快速的压缩视频字幕生成研究",
    "translated_abstract": "现有的视频字幕生成方法通常需要从解码视频中首先采样视频帧，然后进行后续处理（例如，特征提取和字幕模型学习）。在这个过程中，手动帧采样可能会忽略视频中的关键信息，从而降低性能。此外，采样帧中的冗余信息可能导致视频字幕生成推理的效率低下。针对这个问题，我们从压缩域的不同角度研究视频字幕生成，这种方法相比现有的流水线具有多重优势：1）与解码视频的原始图像相比，由I-帧、运动矢量和残差构成的压缩视频更具可识别性，这使得我们可以通过专用模型设计在学习过程中使用整个视频而不需要手动采样；2）字幕生成模型的推理效率更高，因为处理的信息更少且更少冗余。我们提出了一个简单但有效的方法。",
    "tldr": "这项研究提出了一种准确快速的压缩视频字幕生成方法，通过从压缩域进行学习，避免了手动帧采样和冗余处理，提高了性能和效率。",
    "en_tdlr": "This research proposes an accurate and fast approach for compressed video captioning, leveraging learning from the compressed domain to avoid manual frame sampling and redundant processing, improving performance and efficiency."
}