{
    "title": "Hyperbolic vs Euclidean Embeddings in Few-Shot Learning: Two Sides of the Same Coin. (arXiv:2309.10013v1 [cs.CV])",
    "abstract": "Recent research in representation learning has shown that hierarchical data lends itself to low-dimensional and highly informative representations in hyperbolic space. However, even if hyperbolic embeddings have gathered attention in image recognition, their optimization is prone to numerical hurdles. Further, it remains unclear which applications stand to benefit the most from the implicit bias imposed by hyperbolicity, when compared to traditional Euclidean features. In this paper, we focus on prototypical hyperbolic neural networks. In particular, the tendency of hyperbolic embeddings to converge to the boundary of the Poincar\\'e ball in high dimensions and the effect this has on few-shot classification. We show that the best few-shot results are attained for hyperbolic embeddings at a common hyperbolic radius. In contrast to prior benchmark results, we demonstrate that better performance can be achieved by a fixed-radius encoder equipped with the Euclidean metric, regardless of the",
    "link": "http://arxiv.org/abs/2309.10013",
    "context": "Title: Hyperbolic vs Euclidean Embeddings in Few-Shot Learning: Two Sides of the Same Coin. (arXiv:2309.10013v1 [cs.CV])\nAbstract: Recent research in representation learning has shown that hierarchical data lends itself to low-dimensional and highly informative representations in hyperbolic space. However, even if hyperbolic embeddings have gathered attention in image recognition, their optimization is prone to numerical hurdles. Further, it remains unclear which applications stand to benefit the most from the implicit bias imposed by hyperbolicity, when compared to traditional Euclidean features. In this paper, we focus on prototypical hyperbolic neural networks. In particular, the tendency of hyperbolic embeddings to converge to the boundary of the Poincar\\'e ball in high dimensions and the effect this has on few-shot classification. We show that the best few-shot results are attained for hyperbolic embeddings at a common hyperbolic radius. In contrast to prior benchmark results, we demonstrate that better performance can be achieved by a fixed-radius encoder equipped with the Euclidean metric, regardless of the",
    "path": "papers/23/09/2309.10013.json",
    "total_tokens": 995,
    "translated_title": "超几何与欧几里得嵌入在少样本学习中的比较：同一个硬币的两面。(arXiv:2309.10013v1 [cs.CV])",
    "translated_abstract": "最近的表示学习研究表明，层次化数据在超几何空间中具有低维且高度信息丰富的表示。然而，即使超几何嵌入在图像识别中引起了关注，它们的优化容易遇到数值问题。此外，与传统的欧几里得特征相比，超几何性对哪些应用程序最有益仍不清楚。在本文中，我们重点关注原型超几何神经网络。特别是超几何嵌入在高维度中收敛于Poincar\\'e球边界的趋势以及这对少样本分类的影响。我们证明了最好的少样本结果是在共同的超几何半径下获得的超几何嵌入。与之前的基准结果相反，我们证明了不论Euclidean度量，配备固定半径的编码器都可以实现更好的性能。",
    "tldr": "这项研究探讨了超几何和欧几里得嵌入在少样本学习中的比较。研究表明，超几何嵌入在高维度中呈现出边界收敛的趋势，并在少样本分类任务中取得了最佳结果。与以往研究不同，研究者还发现，配备固定半径的欧几里得编码器也可以实现更好的性能。",
    "en_tdlr": "This research examines the comparison between hyperbolic and Euclidean embeddings in few-shot learning. The study demonstrates that hyperbolic embeddings tend to converge to the boundary in high dimensions and achieve the best few-shot results. Contrary to previous findings, it is also discovered that a fixed-radius Euclidean encoder can achieve better performance."
}