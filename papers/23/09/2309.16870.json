{
    "title": "LEF: Late-to-Early Temporal Fusion for LiDAR 3D Object Detection. (arXiv:2309.16870v1 [cs.CV])",
    "abstract": "We propose a late-to-early recurrent feature fusion scheme for 3D object detection using temporal LiDAR point clouds. Our main motivation is fusing object-aware latent embeddings into the early stages of a 3D object detector. This feature fusion strategy enables the model to better capture the shapes and poses for challenging objects, compared with learning from raw points directly. Our method conducts late-to-early feature fusion in a recurrent manner. This is achieved by enforcing window-based attention blocks upon temporally calibrated and aligned sparse pillar tokens. Leveraging bird's eye view foreground pillar segmentation, we reduce the number of sparse history features that our model needs to fuse into its current frame by 10$\\times$. We also propose a stochastic-length FrameDrop training technique, which generalizes the model to variable frame lengths at inference for improved performance without retraining. We evaluate our method on the widely adopted Waymo Open Dataset and d",
    "link": "http://arxiv.org/abs/2309.16870",
    "context": "Title: LEF: Late-to-Early Temporal Fusion for LiDAR 3D Object Detection. (arXiv:2309.16870v1 [cs.CV])\nAbstract: We propose a late-to-early recurrent feature fusion scheme for 3D object detection using temporal LiDAR point clouds. Our main motivation is fusing object-aware latent embeddings into the early stages of a 3D object detector. This feature fusion strategy enables the model to better capture the shapes and poses for challenging objects, compared with learning from raw points directly. Our method conducts late-to-early feature fusion in a recurrent manner. This is achieved by enforcing window-based attention blocks upon temporally calibrated and aligned sparse pillar tokens. Leveraging bird's eye view foreground pillar segmentation, we reduce the number of sparse history features that our model needs to fuse into its current frame by 10$\\times$. We also propose a stochastic-length FrameDrop training technique, which generalizes the model to variable frame lengths at inference for improved performance without retraining. We evaluate our method on the widely adopted Waymo Open Dataset and d",
    "path": "papers/23/09/2309.16870.json",
    "total_tokens": 965,
    "translated_title": "LEF: LiDAR 3D物体检测的迟到早期时间融合",
    "translated_abstract": "我们提出了一种用于使用时间LiDAR点云进行3D物体检测的迟到早期循环特征融合方案。我们的主要动机是将目标感知的潜在嵌入融合到3D物体检测器的早期阶段。与直接从原始点学习相比，这种特征融合策略使模型能够更好地捕捉具有挑战性的对象的形状和姿态。我们的方法以一种循环的方式进行迟到早期特征融合。这通过在时间校准和对齐的稀疏柱状令牌上施加基于窗口的注意力块来实现。利用鸟瞰图前景柱状分割，我们将模型需要融合到当前帧中的稀疏历史特征数量减少了10倍。我们还提出了一种随机长度的FrameDrop训练技术，该技术可以在推断过程中根据需求调整帧长度，以提高性能而无需重新训练。我们在广泛采用的Waymo Open Dataset和d数据集上评估了我们的方法",
    "tldr": "LEF是一种用于LiDAR 3D物体检测的迟到早期时间融合方案，通过将目标感知的潜在嵌入融合到早期阶段，能够更好地捕捉具有挑战性的对象的形状和姿态。",
    "en_tdlr": "LEF is a late-to-early temporal fusion scheme for LiDAR 3D object detection, which captures the shapes and poses of challenging objects better by fusing object-aware latent embeddings into the early stages of the detector."
}