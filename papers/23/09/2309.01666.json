{
    "title": "Robust penalized least squares of depth trimmed residuals regression for high-dimensional data. (arXiv:2309.01666v1 [stat.ML])",
    "abstract": "Challenges with data in the big-data era include (i) the dimension $p$ is often larger than the sample size $n$ (ii) outliers or contaminated points are frequently hidden and more difficult to detect. Challenge (i) renders most conventional methods inapplicable. Thus, it attracts tremendous attention from statistics, computer science, and bio-medical communities. Numerous penalized regression methods have been introduced as modern methods for analyzing high-dimensional data. Disproportionate attention has been paid to the challenge (ii) though. Penalized regression methods can do their job very well and are expected to handle the challenge (ii) simultaneously. Most of them, however, can break down by a single outlier (or single adversary contaminated point) as revealed in this article.  The latter systematically examines leading penalized regression methods in the literature in terms of their robustness, provides quantitative assessment, and reveals that most of them can break down by ",
    "link": "http://arxiv.org/abs/2309.01666",
    "context": "Title: Robust penalized least squares of depth trimmed residuals regression for high-dimensional data. (arXiv:2309.01666v1 [stat.ML])\nAbstract: Challenges with data in the big-data era include (i) the dimension $p$ is often larger than the sample size $n$ (ii) outliers or contaminated points are frequently hidden and more difficult to detect. Challenge (i) renders most conventional methods inapplicable. Thus, it attracts tremendous attention from statistics, computer science, and bio-medical communities. Numerous penalized regression methods have been introduced as modern methods for analyzing high-dimensional data. Disproportionate attention has been paid to the challenge (ii) though. Penalized regression methods can do their job very well and are expected to handle the challenge (ii) simultaneously. Most of them, however, can break down by a single outlier (or single adversary contaminated point) as revealed in this article.  The latter systematically examines leading penalized regression methods in the literature in terms of their robustness, provides quantitative assessment, and reveals that most of them can break down by ",
    "path": "papers/23/09/2309.01666.json",
    "total_tokens": 795,
    "translated_title": "高维数据的鲁棒罚最小二乘深度修剪残差回归",
    "translated_abstract": "大数据时代的挑战包括：(i) 维数p往往大于样本量n (ii) 异常值或污染点经常被隐藏起来且更难检测。挑战(i)使得大多数传统方法不适用，因此它吸引了统计学、计算机科学和生物医学界的广泛关注。已经提出了大量惩罚回归方法作为分析高维数据的现代方法。然而，尽管关注了挑战(ii)，但大多数方法在面对单个异常值或污染点时都会崩溃。",
    "tldr": "这篇论文介绍了鲁棒罚最小二乘深度修剪残差回归方法，针对高维数据的挑战进行了深入研究，并指出大多数传统方法在处理异常值和污染点时不够稳健。",
    "en_tdlr": "This paper introduces a robust penalized least squares of depth trimmed residuals regression method, investigates the challenges with high-dimensional data, and reveals the lack of robustness in most conventional methods when dealing with outliers and contaminated points."
}