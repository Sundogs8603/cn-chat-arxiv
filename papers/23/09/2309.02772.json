{
    "title": "Improving Code Generation by Dynamic Temperature Sampling. (arXiv:2309.02772v1 [cs.SE])",
    "abstract": "Recently, Large Language Models (LLMs) have shown impressive results in code generation. However, existing decoding strategies are designed for Natural Language (NL) generation, overlooking the differences between NL and programming languages (PL). Due to this oversight, a better decoding strategy for code generation remains an open question. In this paper, we conduct the first systematic study to explore a decoding strategy specialized in code generation. With an analysis of loss distributions of code tokens, we find that code tokens can be divided into two categories: challenging tokens that are difficult to predict and confident tokens that can be easily inferred. Among them, the challenging tokens mainly appear at the beginning of a code block. Inspired by the above findings, we propose a simple yet effective method: Adaptive Temperature (AdapT) sampling, which dynamically adjusts the temperature coefficient when decoding different tokens. We apply a larger temperature when samplin",
    "link": "http://arxiv.org/abs/2309.02772",
    "context": "Title: Improving Code Generation by Dynamic Temperature Sampling. (arXiv:2309.02772v1 [cs.SE])\nAbstract: Recently, Large Language Models (LLMs) have shown impressive results in code generation. However, existing decoding strategies are designed for Natural Language (NL) generation, overlooking the differences between NL and programming languages (PL). Due to this oversight, a better decoding strategy for code generation remains an open question. In this paper, we conduct the first systematic study to explore a decoding strategy specialized in code generation. With an analysis of loss distributions of code tokens, we find that code tokens can be divided into two categories: challenging tokens that are difficult to predict and confident tokens that can be easily inferred. Among them, the challenging tokens mainly appear at the beginning of a code block. Inspired by the above findings, we propose a simple yet effective method: Adaptive Temperature (AdapT) sampling, which dynamically adjusts the temperature coefficient when decoding different tokens. We apply a larger temperature when samplin",
    "path": "papers/23/09/2309.02772.json",
    "total_tokens": 880,
    "translated_title": "通过动态温度采样改进代码生成",
    "translated_abstract": "最近，大型语言模型（LLM）在代码生成方面取得了令人印象深刻的结果。然而，现有的解码策略是针对自然语言生成设计的，忽视了自然语言和编程语言之间的差异。由于这个疏忽，如何设计更好的代码生成解码策略仍然是一个未解决的问题。在本文中，我们进行了第一次系统研究，探索了一种专门用于代码生成的解码策略。通过对代码标记丢失分布的分析，我们发现代码标记可以分为两类：难以预测的挑战性标记和易于推断的自信标记。其中，挑战性标记主要出现在代码块的开头。受到上述发现的启发，我们提出了一种简单而有效的方法：自适应温度（AdapT）采样，它在解码不同的标记时动态调整温度系数。我们在采样挑战性标记时应用较大的温度值。同时，在采样自信标记时应用较小的温度值。",
    "tldr": "通过动态温度采样的AdapT方法，我们提出了一种针对代码生成的新的解码策略，通过调整温度系数来解决难以预测的代码标记，并取得了显著效果。",
    "en_tdlr": "We propose a new decoding strategy, AdapT, for code generation by dynamically adjusting the temperature coefficient to handle challenging code tokens, resulting in significant improvements."
}