{
    "title": "TMac: Temporal Multi-Modal Graph Learning for Acoustic Event Classification. (arXiv:2309.11845v1 [cs.SD])",
    "abstract": "Audiovisual data is everywhere in this digital age, which raises higher requirements for the deep learning models developed on them. To well handle the information of the multi-modal data is the key to a better audiovisual modal. We observe that these audiovisual data naturally have temporal attributes, such as the time information for each frame in the video. More concretely, such data is inherently multi-modal according to both audio and visual cues, which proceed in a strict chronological order. It indicates that temporal information is important in multi-modal acoustic event modeling for both intra- and inter-modal. However, existing methods deal with each modal feature independently and simply fuse them together, which neglects the mining of temporal relation and thus leads to sub-optimal performance. With this motivation, we propose a Temporal Multi-modal graph learning method for Acoustic event Classification, called TMac, by modeling such temporal information via graph learning",
    "link": "http://arxiv.org/abs/2309.11845",
    "context": "Title: TMac: Temporal Multi-Modal Graph Learning for Acoustic Event Classification. (arXiv:2309.11845v1 [cs.SD])\nAbstract: Audiovisual data is everywhere in this digital age, which raises higher requirements for the deep learning models developed on them. To well handle the information of the multi-modal data is the key to a better audiovisual modal. We observe that these audiovisual data naturally have temporal attributes, such as the time information for each frame in the video. More concretely, such data is inherently multi-modal according to both audio and visual cues, which proceed in a strict chronological order. It indicates that temporal information is important in multi-modal acoustic event modeling for both intra- and inter-modal. However, existing methods deal with each modal feature independently and simply fuse them together, which neglects the mining of temporal relation and thus leads to sub-optimal performance. With this motivation, we propose a Temporal Multi-modal graph learning method for Acoustic event Classification, called TMac, by modeling such temporal information via graph learning",
    "path": "papers/23/09/2309.11845.json",
    "total_tokens": 845,
    "translated_title": "TMac：用于声音事件分类的时态多模态图学习",
    "translated_abstract": "在这个数字时代，音频视觉数据随处可见，这对于对它们开发的深度学习模型提出了更高的要求。有效处理多模态数据的信息是更好的音频视觉模型的关键。我们观察到这些音频视觉数据自然具有时间属性，例如视频中每一帧的时间信息。更具体地说，这些数据根据音频和视觉线索自然形成多模态，并且严格按照时间顺序进行。这表明，在多模态声音事件建模中，时态信息对于内部和跨模态都很重要。然而，现有的方法独立地处理每个模态特征，仅简单地将它们融合在一起，忽视了时态关系的挖掘，从而导致次优的性能。出于这个动机，我们提出了一种用于声音事件分类的时态多模态图学习方法，称为TMac，通过图学习对这种时态信息进行建模。",
    "tldr": "TMac是一个时态多模态图学习方法，用于声音事件分类。它通过图学习的方式对多模态数据中的时态信息进行建模，提高了声音事件分类的性能。",
    "en_tdlr": "TMac is a temporal multi-modal graph learning method for acoustic event classification. It models the temporal information in multi-modal data through graph learning, improving the performance of acoustic event classification."
}