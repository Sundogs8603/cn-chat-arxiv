{
    "title": "Connecting Speech Encoder and Large Language Model for ASR. (arXiv:2309.13963v2 [eess.AS] UPDATED)",
    "abstract": "The impressive capability and versatility of large language models (LLMs) have aroused increasing attention in automatic speech recognition (ASR), with several pioneering studies attempting to build integrated ASR models by connecting a speech encoder with an LLM. This paper presents a comparative study of three commonly used structures as connectors, including fully connected layers, multi-head cross-attention, and Q-Former. Speech encoders from the Whisper model series as well as LLMs from the Vicuna model series with different model sizes were studied. Experiments were performed on the commonly used LibriSpeech, Common Voice, and GigaSpeech datasets, where the LLMs with Q-Formers demonstrated consistent and considerable word error rate (WER) reductions over LLMs with other connector structures. Q-Former-based LLMs can generalise well to out-of-domain datasets, where 12% relative WER reductions over the Whisper baseline ASR model were achieved on the Eval2000 test set without using a",
    "link": "http://arxiv.org/abs/2309.13963",
    "context": "Title: Connecting Speech Encoder and Large Language Model for ASR. (arXiv:2309.13963v2 [eess.AS] UPDATED)\nAbstract: The impressive capability and versatility of large language models (LLMs) have aroused increasing attention in automatic speech recognition (ASR), with several pioneering studies attempting to build integrated ASR models by connecting a speech encoder with an LLM. This paper presents a comparative study of three commonly used structures as connectors, including fully connected layers, multi-head cross-attention, and Q-Former. Speech encoders from the Whisper model series as well as LLMs from the Vicuna model series with different model sizes were studied. Experiments were performed on the commonly used LibriSpeech, Common Voice, and GigaSpeech datasets, where the LLMs with Q-Formers demonstrated consistent and considerable word error rate (WER) reductions over LLMs with other connector structures. Q-Former-based LLMs can generalise well to out-of-domain datasets, where 12% relative WER reductions over the Whisper baseline ASR model were achieved on the Eval2000 test set without using a",
    "path": "papers/23/09/2309.13963.json",
    "total_tokens": 1035,
    "translated_title": "连接语音编码器和大型语言模型用于ASR",
    "translated_abstract": "大型语言模型(LLMs)的出色能力和多功能性引起了自动语音识别(ASR)领域的越来越多关注，几项开创性研究尝试通过连接语音编码器和LLMs构建一体化ASR模型。本文对三种常用的连接结构进行了比较研究，包括全连接层、多头交叉注意力和Q-Former。研究了Whisper模型系列的语音编码器以及Vicuna模型系列的LLMs，包括不同的模型大小。在常用的LibriSpeech、Common Voice和GigaSpeech数据集上进行了实验，在LLMs与其他连接结构相比，基于Q-Former的LLMs在词错误率(WER)上表现出一致且显著的降低。基于Q-Former的LLMs在领域外数据集上表现良好，在Eval2000测试集上相比Whisper基准ASR模型实现了12%的相对WER降低，而无需使用额外的领域适应数据。",
    "tldr": "本文通过比较研究了三种连接结构，即全连接层、多头交叉注意力和Q-Former，将语音编码器与大型语言模型相结合，实现了在自动语音识别中显著降低词错误率的效果。其中，基于Q-Former的大型语言模型在Out-of-Domain数据集上展现出了良好的泛化能力，并且相比基准模型实现了12%的相对词错误率降低。 (arXiv:2309.13963v2 [eess.AS] UPDATED)",
    "en_tdlr": "This paper presents a comparative study of connecting a speech encoder with large language models (LLMs) for automatic speech recognition (ASR). By comparing three connector structures, it is found that the use of Q-Formers in LLMs demonstrates consistent and considerable word error rate (WER) reductions, showing good generalization to out-of-domain datasets and achieving a 12% relative WER reduction compared to the baseline ASR model."
}