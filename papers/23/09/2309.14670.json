{
    "title": "DONNAv2 -- Lightweight Neural Architecture Search for Vision tasks. (arXiv:2309.14670v1 [cs.CV])",
    "abstract": "With the growing demand for vision applications and deployment across edge devices, the development of hardware-friendly architectures that maintain performance during device deployment becomes crucial. Neural architecture search (NAS) techniques explore various approaches to discover efficient architectures for diverse learning tasks in a computationally efficient manner. In this paper, we present the next-generation neural architecture design for computationally efficient neural architecture distillation - DONNAv2 . Conventional NAS algorithms rely on a computationally extensive stage where an accuracy predictor is learned to estimate model performance within search space. This building of accuracy predictors helps them predict the performance of models that are not being finetuned. Here, we have developed an elegant approach to eliminate building the accuracy predictor and extend DONNA to a computationally efficient setting. The loss metric of individual blocks forming the network s",
    "link": "http://arxiv.org/abs/2309.14670",
    "context": "Title: DONNAv2 -- Lightweight Neural Architecture Search for Vision tasks. (arXiv:2309.14670v1 [cs.CV])\nAbstract: With the growing demand for vision applications and deployment across edge devices, the development of hardware-friendly architectures that maintain performance during device deployment becomes crucial. Neural architecture search (NAS) techniques explore various approaches to discover efficient architectures for diverse learning tasks in a computationally efficient manner. In this paper, we present the next-generation neural architecture design for computationally efficient neural architecture distillation - DONNAv2 . Conventional NAS algorithms rely on a computationally extensive stage where an accuracy predictor is learned to estimate model performance within search space. This building of accuracy predictors helps them predict the performance of models that are not being finetuned. Here, we have developed an elegant approach to eliminate building the accuracy predictor and extend DONNA to a computationally efficient setting. The loss metric of individual blocks forming the network s",
    "path": "papers/23/09/2309.14670.json",
    "total_tokens": 851,
    "translated_title": "DONNAv2-轻量级神经体系结构搜索用于视觉任务",
    "translated_abstract": "随着对视觉应用和在边缘设备上部署的需求不断增长，开发对硬件友好的体系结构并在设备部署期间保持性能变得至关重要。神经体系结构搜索（NAS）技术以计算效率的方式探索各种方法，以发现用于不同学习任务的高效体系结构。在本文中，我们提出了用于计算效率的神经体系结构蒸馏的下一代神经体系结构设计-DONNAv2。传统的NAS算法依赖于一个计算密集的阶段，在该阶段中，学习精度预测器以预估搜索空间内模型的性能。建立精度预测器有助于预测不进行微调的模型的性能。在这里，我们提出了一种优雅的方法，消除了建立精度预测器并将DONNA扩展到计算效率的设置中。形成网络的个体块的损失指标",
    "tldr": "DONNAv2是一种轻量级神经体系结构搜索方法，用于视觉任务。它采用计算效率的方式探索不同学习任务的高效体系结构，并通过消除精度预测器来实现计算效率的设置。"
}