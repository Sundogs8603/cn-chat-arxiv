{
    "title": "Enhancing Keyphrase Generation by BART Finetuning with Splitting and Shuffling. (arXiv:2309.06726v1 [cs.CL])",
    "abstract": "Keyphrase generation is a task of identifying a set of phrases that best repre-sent the main topics or themes of a given text. Keyphrases are dividend int pre-sent and absent keyphrases. Recent approaches utilizing sequence-to-sequence models show effectiveness on absent keyphrase generation. However, the per-formance is still limited due to the hardness of finding absent keyphrases. In this paper, we propose Keyphrase-Focused BART, which exploits the differ-ences between present and absent keyphrase generations, and performs fine-tuning of two separate BART models for present and absent keyphrases. We further show effective approaches of shuffling keyphrases and candidate keyphrase ranking. For absent keyphrases, our Keyphrase-Focused BART achieved new state-of-the-art score on F1@5 in two out of five keyphrase gen-eration benchmark datasets.",
    "link": "http://arxiv.org/abs/2309.06726",
    "context": "Title: Enhancing Keyphrase Generation by BART Finetuning with Splitting and Shuffling. (arXiv:2309.06726v1 [cs.CL])\nAbstract: Keyphrase generation is a task of identifying a set of phrases that best repre-sent the main topics or themes of a given text. Keyphrases are dividend int pre-sent and absent keyphrases. Recent approaches utilizing sequence-to-sequence models show effectiveness on absent keyphrase generation. However, the per-formance is still limited due to the hardness of finding absent keyphrases. In this paper, we propose Keyphrase-Focused BART, which exploits the differ-ences between present and absent keyphrase generations, and performs fine-tuning of two separate BART models for present and absent keyphrases. We further show effective approaches of shuffling keyphrases and candidate keyphrase ranking. For absent keyphrases, our Keyphrase-Focused BART achieved new state-of-the-art score on F1@5 in two out of five keyphrase gen-eration benchmark datasets.",
    "path": "papers/23/09/2309.06726.json",
    "total_tokens": 897,
    "translated_title": "通过拆分和重排BART微调来增强关键短语生成",
    "translated_abstract": "关键短语生成是一项识别最佳代表给定文本主题或主题的短语集的任务。关键短语分为出现和不在出现的关键短语。最近利用序列到序列模型的方法在不出现的关键短语生成上显示出了效果。然而，由于找到不出现的关键短语的难度，性能仍然有限。在本文中，我们提出了关注关键短语的BART模型(Keyphrase-Focused BART)，利用了出现和不出现关键短语生成之间的差异，并对出现和不出现关键短语分别进行了两个独立BART模型的微调。我们进一步展示了关键短语的重排和候选关键短语排序的有效方法。对于不出现的关键短语，在五个关键短语生成基准数据集中，我们的关注关键短语的BART在F1@5上取得了新的最佳得分。",
    "tldr": "本文提出了关注关键短语的BART模型(Keyphrase-Focused BART)，通过拆分和重排的方式来增强关键短语生成的性能。在不出现的关键短语生成任务中，该模型在两个关键短语生成基准数据集上取得了新的最佳得分。",
    "en_tdlr": "This paper proposes a Keyphrase-Focused BART model that enhances keyphrase generation by splitting and shuffling, achieving new state-of-the-art scores in absent keyphrase generation on two benchmark datasets."
}