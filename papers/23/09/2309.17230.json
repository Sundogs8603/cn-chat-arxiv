{
    "title": "Spurious Feature Diversification Improves Out-of-distribution Generalization. (arXiv:2309.17230v1 [cs.LG])",
    "abstract": "Generalization to out-of-distribution (OOD) data is a critical challenge in machine learning. Ensemble-based methods, like weight space ensembles that interpolate model parameters, have been shown to achieve superior OOD performance. However, the underlying mechanism for their effectiveness remains unclear. In this study, we closely examine WiSE-FT, a popular weight space ensemble method that interpolates between a pre-trained and a fine-tuned model. We observe an unexpected phenomenon, in which WiSE-FT successfully corrects many cases where each individual model makes incorrect predictions, which contributes significantly to its OOD effectiveness. To gain further insights, we conduct theoretical analysis in a multi-class setting with a large number of spurious features. Our analysis predicts the above phenomenon and it further shows that ensemble-based models reduce prediction errors in the OOD settings by utilizing a more diverse set of spurious features. Contrary to the conventional",
    "link": "http://arxiv.org/abs/2309.17230",
    "context": "Title: Spurious Feature Diversification Improves Out-of-distribution Generalization. (arXiv:2309.17230v1 [cs.LG])\nAbstract: Generalization to out-of-distribution (OOD) data is a critical challenge in machine learning. Ensemble-based methods, like weight space ensembles that interpolate model parameters, have been shown to achieve superior OOD performance. However, the underlying mechanism for their effectiveness remains unclear. In this study, we closely examine WiSE-FT, a popular weight space ensemble method that interpolates between a pre-trained and a fine-tuned model. We observe an unexpected phenomenon, in which WiSE-FT successfully corrects many cases where each individual model makes incorrect predictions, which contributes significantly to its OOD effectiveness. To gain further insights, we conduct theoretical analysis in a multi-class setting with a large number of spurious features. Our analysis predicts the above phenomenon and it further shows that ensemble-based models reduce prediction errors in the OOD settings by utilizing a more diverse set of spurious features. Contrary to the conventional",
    "path": "papers/23/09/2309.17230.json",
    "total_tokens": 914,
    "translated_title": "伪特征多样性改善了对分布外泛化的效果",
    "translated_abstract": "在机器学习中，对分布外（OOD）数据的泛化是一个关键性挑战。基于集成的方法，如在模型参数上进行插值的权重空间集成，已被证明在OOD性能方面具有优势。然而，它们的有效性的基本机制仍不清楚。在本研究中，我们对一种常用的权重空间集成方法WiSE-FT进行了详细研究，该方法在预训练模型和微调模型之间进行插值。我们观察到一个意外的现象，即WiSE-FT成功地纠正了许多个体模型做出错误预测的情况，这对于其OOD的有效性贡献重大。为了进一步了解，我们在具有大量伪特征的多类别设置中进行了理论分析。我们的分析预测了上述现象，并进一步表明，基于集成的模型通过利用更多多样化的伪特征，减少了OOD设置中的预测错误。与传统观点相反。",
    "tldr": "本文研究了基于权重空间集成方法WiSE-FT在分布外泛化中的有效性，发现其成功纠正了许多个体模型的错误预测，并通过利用更多多样化的伪特征减少了分布外设置中的预测错误。",
    "en_tdlr": "This study investigates the effectiveness of the weight space ensemble method WiSE-FT in out-of-distribution generalization and finds that it successfully corrects errors made by individual models and reduces prediction errors in out-of-distribution settings by utilizing a more diverse set of spurious features."
}