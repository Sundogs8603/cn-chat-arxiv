{
    "title": "Dual Relation Alignment for Composed Image Retrieval. (arXiv:2309.02169v2 [cs.CV] UPDATED)",
    "abstract": "Composed image retrieval, a task involving the search for a target image using a reference image and a complementary text as the query, has witnessed significant advancements owing to the progress made in cross-modal modeling. Unlike the general image-text retrieval problem with only one alignment relation, i.e., image-text, we argue for the existence of two types of relations in composed image retrieval. The explicit relation pertains to the reference image & complementary text-target image, which is commonly exploited by existing methods. Besides this intuitive relation, the observations during our practice have uncovered another implicit yet crucial relation, i.e., reference image & target image-complementary text, since we found that the complementary text can be inferred by studying the relation between the target image and the reference image. Regrettably, existing methods largely focus on leveraging the explicit relation to learn their networks, while overlooking the implicit re",
    "link": "http://arxiv.org/abs/2309.02169",
    "context": "Title: Dual Relation Alignment for Composed Image Retrieval. (arXiv:2309.02169v2 [cs.CV] UPDATED)\nAbstract: Composed image retrieval, a task involving the search for a target image using a reference image and a complementary text as the query, has witnessed significant advancements owing to the progress made in cross-modal modeling. Unlike the general image-text retrieval problem with only one alignment relation, i.e., image-text, we argue for the existence of two types of relations in composed image retrieval. The explicit relation pertains to the reference image & complementary text-target image, which is commonly exploited by existing methods. Besides this intuitive relation, the observations during our practice have uncovered another implicit yet crucial relation, i.e., reference image & target image-complementary text, since we found that the complementary text can be inferred by studying the relation between the target image and the reference image. Regrettably, existing methods largely focus on leveraging the explicit relation to learn their networks, while overlooking the implicit re",
    "path": "papers/23/09/2309.02169.json",
    "total_tokens": 821,
    "translated_title": "双重关系对齐用于组合图像检索",
    "translated_abstract": "组合图像检索是一项通过使用参考图像和补充文本作为查询，来搜索目标图像的任务。随着跨模态建模的进展，这一任务取得了显著的进展。与仅存在一种对齐关系的一般图像-文本检索问题不同，我们认为在组合图像检索中存在着两种类型的关系。显性关系涉及参考图像 & 补充文本-目标图像，这是现有方法常用的关系。除了这种直观关系之外，我们在实践中观察到另一种隐含但关键的关系，即参考图像 & 目标图像-补充文本。因为我们发现，通过研究目标图像和参考图像之间的关系，可以推断出补充文本。可惜的是，现有方法主要关注利用显性关系来学习网络，而忽视了隐性关系。",
    "tldr": "本研究提出了双重关系对齐的方法，用于组合图像检索任务。通过利用显性和隐性关系，可以更好地学习网络并提升检索性能。",
    "en_tdlr": "This paper proposes a dual relation alignment method for composed image retrieval, which leverages both explicit and implicit relations to improve network learning and retrieval performance."
}