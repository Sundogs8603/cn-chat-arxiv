{
    "title": "Resisting Backdoor Attacks in Federated Learning via Bidirectional Elections and Individual Perspective. (arXiv:2309.16456v1 [cs.LG])",
    "abstract": "Existing approaches defend against backdoor attacks in federated learning (FL) mainly through a) mitigating the impact of infected models, or b) excluding infected models. The former negatively impacts model accuracy, while the latter usually relies on globally clear boundaries between benign and infected model updates. However, model updates are easy to be mixed and scattered throughout in reality due to the diverse distributions of local data. This work focuses on excluding infected models in FL. Unlike previous perspectives from a global view, we propose Snowball, a novel anti-backdoor FL framework through bidirectional elections from an individual perspective inspired by one principle deduced by us and two principles in FL and deep learning. It is characterized by a) bottom-up election, where each candidate model update votes to several peer ones such that a few model updates are elected as selectees for aggregation; and b) top-down election, where selectees progressively enlarge t",
    "link": "http://arxiv.org/abs/2309.16456",
    "context": "Title: Resisting Backdoor Attacks in Federated Learning via Bidirectional Elections and Individual Perspective. (arXiv:2309.16456v1 [cs.LG])\nAbstract: Existing approaches defend against backdoor attacks in federated learning (FL) mainly through a) mitigating the impact of infected models, or b) excluding infected models. The former negatively impacts model accuracy, while the latter usually relies on globally clear boundaries between benign and infected model updates. However, model updates are easy to be mixed and scattered throughout in reality due to the diverse distributions of local data. This work focuses on excluding infected models in FL. Unlike previous perspectives from a global view, we propose Snowball, a novel anti-backdoor FL framework through bidirectional elections from an individual perspective inspired by one principle deduced by us and two principles in FL and deep learning. It is characterized by a) bottom-up election, where each candidate model update votes to several peer ones such that a few model updates are elected as selectees for aggregation; and b) top-down election, where selectees progressively enlarge t",
    "path": "papers/23/09/2309.16456.json",
    "total_tokens": 977,
    "translated_title": "抵抗联邦学习中后门攻击的双向选举和个体视角方法",
    "translated_abstract": "现有的抵御联邦学习中后门攻击的方法主要通过减轻感染模型的影响或排除感染模型来实现。前者会对模型准确性产生负面影响，而后者通常依赖于对良性和感染模型更新之间的全局清晰边界的判定。然而，由于本地数据分布的多样性，模型更新在现实中容易混杂并分散。本文关注在联邦学习中排除感染模型的问题。与以往从全局视角出发的观点不同，我们提出了Snowball，一种新颖的反后门联邦学习框架，通过个体视角上的双向选举，受到我们推导出的一个原则和联邦学习和深度学习中的两个原则的启发。它具有以下特点：a）自下而上的选举，每个候选模型更新对多个对等候选模型更新进行投票，以选出一些模型更新作为聚合的被选项；b）自上而下的选举，被选项逐步增加。",
    "tldr": "本文提出了Snowball，一个通过个体视角上的双向选举方法来抵抗联邦学习中后门攻击的框架。它通过自下而上和自上而下的选举过程，逐步排除感染模型，以解决由于本地数据分布多样性导致模型更新混杂分散的问题。",
    "en_tdlr": "This paper proposes Snowball, a framework for resisting backdoor attacks in federated learning through bidirectional elections from an individual perspective. It eliminates infected models gradually by conducting bottom-up and top-down elections, addressing the issue of mixed and scattered model updates caused by diverse local data distributions."
}