{
    "title": "Exploring Self-Supervised Contrastive Learning of Spatial Sound Event Representation. (arXiv:2309.15938v1 [eess.AS])",
    "abstract": "In this study, we present a simple multi-channel framework for contrastive learning (MC-SimCLR) to encode 'what' and 'where' of spatial audios. MC-SimCLR learns joint spectral and spatial representations from unlabeled spatial audios, thereby enhancing both event classification and sound localization in downstream tasks. At its core, we propose a multi-level data augmentation pipeline that augments different levels of audio features, including waveforms, Mel spectrograms, and generalized cross-correlation (GCC) features. In addition, we introduce simple yet effective channel-wise augmentation methods to randomly swap the order of the microphones and mask Mel and GCC channels. By using these augmentations, we find that linear layers on top of the learned representation significantly outperform supervised models in terms of both event classification accuracy and localization error. We also perform a comprehensive analysis of the effect of each augmentation method and a comparison of the ",
    "link": "http://arxiv.org/abs/2309.15938",
    "context": "Title: Exploring Self-Supervised Contrastive Learning of Spatial Sound Event Representation. (arXiv:2309.15938v1 [eess.AS])\nAbstract: In this study, we present a simple multi-channel framework for contrastive learning (MC-SimCLR) to encode 'what' and 'where' of spatial audios. MC-SimCLR learns joint spectral and spatial representations from unlabeled spatial audios, thereby enhancing both event classification and sound localization in downstream tasks. At its core, we propose a multi-level data augmentation pipeline that augments different levels of audio features, including waveforms, Mel spectrograms, and generalized cross-correlation (GCC) features. In addition, we introduce simple yet effective channel-wise augmentation methods to randomly swap the order of the microphones and mask Mel and GCC channels. By using these augmentations, we find that linear layers on top of the learned representation significantly outperform supervised models in terms of both event classification accuracy and localization error. We also perform a comprehensive analysis of the effect of each augmentation method and a comparison of the ",
    "path": "papers/23/09/2309.15938.json",
    "total_tokens": 899,
    "translated_title": "探索自监督对比学习空间声音事件表示的研究",
    "translated_abstract": "在这项研究中，我们提出了一个简单的多通道框架，用于对比学习(MC-SimCLR)，以编码空间音频的“什么”和“哪里”。MC-SimCLR从未标记的空间音频中学习联合频谱和空间表示，从而提高下游任务中的事件分类和声音定位能力。核心思想是，我们提出了一个多级数据增强流水线，对不同级别的音频特征进行增强，包括波形、Mel频谱图和广义互相关(GCC)特征。此外，我们引入了简单但有效的通道增强方法，随机交换麦克风顺序和屏蔽Mel和GCC通道。通过使用这些增强方法，我们发现在学习表示之上的线性层在事件分类准确性和定位误差方面明显优于有监督模型。我们还对每种增强方法的效果进行了全面分析，并进行了比较。",
    "tldr": "该研究提出了一个简单的多通道对比学习框架，用于编码空间音频的“什么”和“哪里”。通过多级数据增强和通道增强方法，该框架在事件分类和声音定位方面优于有监督模型。"
}