{
    "title": "TradingGPT: Multi-Agent System with Layered Memory and Distinct Characters for Enhanced Financial Trading Performance. (arXiv:2309.03736v1 [q-fin.PM])",
    "abstract": "Large Language Models (LLMs), prominently highlighted by the recent evolution in the Generative Pre-trained Transformers (GPT) series, have displayed significant prowess across various domains, such as aiding in healthcare diagnostics and curating analytical business reports. The efficacy of GPTs lies in their ability to decode human instructions, achieved through comprehensively processing historical inputs as an entirety within their memory system. Yet, the memory processing of GPTs does not precisely emulate the hierarchical nature of human memory. This can result in LLMs struggling to prioritize immediate and critical tasks efficiently. To bridge this gap, we introduce an innovative LLM multi-agent framework endowed with layered memories. We assert that this framework is well-suited for stock and fund trading, where the extraction of highly relevant insights from hierarchical financial data is imperative to inform trading decisions. Within this framework, one agent organizes memory",
    "link": "http://arxiv.org/abs/2309.03736",
    "context": "Title: TradingGPT: Multi-Agent System with Layered Memory and Distinct Characters for Enhanced Financial Trading Performance. (arXiv:2309.03736v1 [q-fin.PM])\nAbstract: Large Language Models (LLMs), prominently highlighted by the recent evolution in the Generative Pre-trained Transformers (GPT) series, have displayed significant prowess across various domains, such as aiding in healthcare diagnostics and curating analytical business reports. The efficacy of GPTs lies in their ability to decode human instructions, achieved through comprehensively processing historical inputs as an entirety within their memory system. Yet, the memory processing of GPTs does not precisely emulate the hierarchical nature of human memory. This can result in LLMs struggling to prioritize immediate and critical tasks efficiently. To bridge this gap, we introduce an innovative LLM multi-agent framework endowed with layered memories. We assert that this framework is well-suited for stock and fund trading, where the extraction of highly relevant insights from hierarchical financial data is imperative to inform trading decisions. Within this framework, one agent organizes memory",
    "path": "papers/23/09/2309.03736.json",
    "total_tokens": 787,
    "translated_title": "TradingGPT: 多代理系统具有分层记忆和独特角色以提高金融交易性能",
    "translated_abstract": "大型语言模型（LLMs），特别是最近发展的生成预训练变换（GPT）系列，已在多个领域展现出显著的能力，例如在医疗诊断和分析业务报告方面提供帮助。GPT的效力在于其能够解读人类指令，通过全面处理历史输入作为其记忆系统的整体来实现。然而，GPT的记忆处理并没有精确地模拟人类记忆的分层特性。这可能导致LLMs难以高效地对待紧急和关键任务。为了弥补这个差距，我们引入了一个创新的LLM多代理框架，该框架具有分层记忆。我们断言，这个框架非常适合股票和基金交易，其中从分层金融数据中提取高度相关的见解对于确保交易决策至关重要。在这个框架内，一个代理组织记忆...",
    "tldr": "TradingGPT是一个创新的多代理数"
}