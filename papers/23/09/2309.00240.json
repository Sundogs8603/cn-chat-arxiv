{
    "title": "FactLLaMA: Optimizing Instruction-Following Language Models with External Knowledge for Automated Fact-Checking. (arXiv:2309.00240v1 [cs.CL])",
    "abstract": "Automatic fact-checking plays a crucial role in combating the spread of misinformation. Large Language Models (LLMs) and Instruction-Following variants, such as InstructGPT and Alpaca, have shown remarkable performance in various natural language processing tasks. However, their knowledge may not always be up-to-date or sufficient, potentially leading to inaccuracies in fact-checking. To address this limitation, we propose combining the power of instruction-following language models with external evidence retrieval to enhance fact-checking performance. Our approach involves leveraging search engines to retrieve relevant evidence for a given input claim. This external evidence serves as valuable supplementary information to augment the knowledge of the pretrained language model. Then, we instruct-tune an open-sourced language model, called LLaMA, using this evidence, enabling it to predict the veracity of the input claim more accurately. To evaluate our method, we conducted experiments ",
    "link": "http://arxiv.org/abs/2309.00240",
    "context": "Title: FactLLaMA: Optimizing Instruction-Following Language Models with External Knowledge for Automated Fact-Checking. (arXiv:2309.00240v1 [cs.CL])\nAbstract: Automatic fact-checking plays a crucial role in combating the spread of misinformation. Large Language Models (LLMs) and Instruction-Following variants, such as InstructGPT and Alpaca, have shown remarkable performance in various natural language processing tasks. However, their knowledge may not always be up-to-date or sufficient, potentially leading to inaccuracies in fact-checking. To address this limitation, we propose combining the power of instruction-following language models with external evidence retrieval to enhance fact-checking performance. Our approach involves leveraging search engines to retrieve relevant evidence for a given input claim. This external evidence serves as valuable supplementary information to augment the knowledge of the pretrained language model. Then, we instruct-tune an open-sourced language model, called LLaMA, using this evidence, enabling it to predict the veracity of the input claim more accurately. To evaluate our method, we conducted experiments ",
    "path": "papers/23/09/2309.00240.json",
    "total_tokens": 913,
    "translated_title": "FactLLaMA: 基于外部知识优化指令追踪语言模型以实现自动事实核查",
    "translated_abstract": "自动事实核查在打击虚假信息传播中发挥了重要作用。大型语言模型（LLM）和指令追踪变种，如InstructGPT和Alpaca，在各种自然语言处理任务中展现出了显著的性能。然而，它们的知识可能并不总是最新或充分的，可能导致事实核查的不准确性。为了解决这个问题，我们提出了将指令追踪语言模型与外部证据检索相结合，以增强事实核查性能。我们的方法涉及利用搜索引擎检索与给定输入声明相关的证据。这些外部证据作为有价值的补充信息，可以增强预训练语言模型的知识。然后，我们使用这些证据对一个名为LLaMA的开源语言模型进行指令调整，从而使其更准确地预测输入声明的真实性。为了评估我们的方法，我们进行了一系列实验。",
    "tldr": "本研究提出了一种结合外部知识检索来增强指令追踪语言模型的自动事实核查方法，通过利用搜索引擎检索相关证据，并指导调整语言模型，从而提高了事实核查的准确性。"
}