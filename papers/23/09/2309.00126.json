{
    "title": "QS-TTS: Towards Semi-Supervised Text-to-Speech Synthesis via Vector-Quantized Self-Supervised Speech Representation Learning. (arXiv:2309.00126v1 [cs.SD])",
    "abstract": "This paper proposes a novel semi-supervised TTS framework, QS-TTS, to improve TTS quality with lower supervised data requirements via Vector-Quantized Self-Supervised Speech Representation Learning (VQ-S3RL) utilizing more unlabeled speech audio. This framework comprises two VQ-S3R learners: first, the principal learner aims to provide a generative Multi-Stage Multi-Codebook (MSMC) VQ-S3R via the MSMC-VQ-GAN combined with the contrastive S3RL, while decoding it back to the high-quality audio; then, the associate learner further abstracts the MSMC representation into a highly-compact VQ representation through a VQ-VAE. These two generative VQ-S3R learners provide profitable speech representations and pre-trained models for TTS, significantly improving synthesis quality with the lower requirement for supervised data. QS-TTS is evaluated comprehensively under various scenarios via subjective and objective tests in experiments. The results powerfully demonstrate the superior performance of",
    "link": "http://arxiv.org/abs/2309.00126",
    "context": "Title: QS-TTS: Towards Semi-Supervised Text-to-Speech Synthesis via Vector-Quantized Self-Supervised Speech Representation Learning. (arXiv:2309.00126v1 [cs.SD])\nAbstract: This paper proposes a novel semi-supervised TTS framework, QS-TTS, to improve TTS quality with lower supervised data requirements via Vector-Quantized Self-Supervised Speech Representation Learning (VQ-S3RL) utilizing more unlabeled speech audio. This framework comprises two VQ-S3R learners: first, the principal learner aims to provide a generative Multi-Stage Multi-Codebook (MSMC) VQ-S3R via the MSMC-VQ-GAN combined with the contrastive S3RL, while decoding it back to the high-quality audio; then, the associate learner further abstracts the MSMC representation into a highly-compact VQ representation through a VQ-VAE. These two generative VQ-S3R learners provide profitable speech representations and pre-trained models for TTS, significantly improving synthesis quality with the lower requirement for supervised data. QS-TTS is evaluated comprehensively under various scenarios via subjective and objective tests in experiments. The results powerfully demonstrate the superior performance of",
    "path": "papers/23/09/2309.00126.json",
    "total_tokens": 939,
    "translated_title": "QS-TTS: 通过向量量化自监督语音表示学习实现半监督文本到语音合成",
    "translated_abstract": "本文提出了一种新颖的半监督TTS框架QS-TTS，通过利用更多无标签语音音频的向量量化自监督语音表示学习（VQ-S3RL）来提高TTS质量，并降低对有监督数据的要求。该框架包括两个VQ-S3R学习器：首先，主要学习器通过多阶段多码本（MSMC）VQ-S3R与对比式S3RL相结合的MSMC-VQ-GAN生成高质量音频，然后解码回原音频；同时，副学习器通过VQ-VAE将MSMC表示进一步抽象为高度紧凑的VQ表示。这两个生成式VQ-S3R学习器为TTS提供了有利的语音表示和预训练模型，显著提高了合成质量并降低了对有监督数据的要求。QS-TTS在各种场景下进行了全面的主观和客观测试实验评估。实验结果有力地证明了其卓越的性能。",
    "tldr": "通过向量量化自监督语音表示学习，QS-TTS是一种半监督的TTS框架，通过利用更多无标签语音音频提高合成质量并降低对有监督数据的要求。",
    "en_tdlr": "QS-TTS is a semi-supervised TTS framework that improves synthesis quality and reduces the need for supervised data by utilizing vector-quantized self-supervised speech representation learning with more unlabeled speech audio."
}