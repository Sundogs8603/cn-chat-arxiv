{
    "title": "On Penalty Methods for Nonconvex Bilevel Optimization and First-Order Stochastic Approximation",
    "abstract": "In this work, we study first-order algorithms for solving Bilevel Optimization (BO) where the objective functions are smooth but possibly nonconvex in both levels and the variables are restricted to closed convex sets. As a first step, we study the landscape of BO through the lens of penalty methods, in which the upper- and lower-level objectives are combined in a weighted sum with penalty parameter $\\sigma > 0$. In particular, we establish a strong connection between the penalty function and the hyper-objective by explicitly characterizing the conditions under which the values and derivatives of the two must be $O(\\sigma)$-close. A by-product of our analysis is the explicit formula for the gradient of hyper-objective when the lower-level problem has multiple solutions under minimal conditions, which could be of independent interest. Next, viewing the penalty formulation as $O(\\sigma)$-approximation of the original BO, we propose first-order algorithms that find an $\\epsilon$-stationar",
    "link": "https://arxiv.org/abs/2309.01753",
    "context": "Title: On Penalty Methods for Nonconvex Bilevel Optimization and First-Order Stochastic Approximation\nAbstract: In this work, we study first-order algorithms for solving Bilevel Optimization (BO) where the objective functions are smooth but possibly nonconvex in both levels and the variables are restricted to closed convex sets. As a first step, we study the landscape of BO through the lens of penalty methods, in which the upper- and lower-level objectives are combined in a weighted sum with penalty parameter $\\sigma > 0$. In particular, we establish a strong connection between the penalty function and the hyper-objective by explicitly characterizing the conditions under which the values and derivatives of the two must be $O(\\sigma)$-close. A by-product of our analysis is the explicit formula for the gradient of hyper-objective when the lower-level problem has multiple solutions under minimal conditions, which could be of independent interest. Next, viewing the penalty formulation as $O(\\sigma)$-approximation of the original BO, we propose first-order algorithms that find an $\\epsilon$-stationar",
    "path": "papers/23/09/2309.01753.json",
    "total_tokens": 867,
    "translated_title": "关于非凸双层优化和一阶随机逼近的罚函数方法研究",
    "translated_abstract": "在这项工作中，我们研究了求解双层优化问题（BO）的一阶算法，在这里，目标函数对于两个层级来说都是光滑的，但可能是非凸的，并且变量受限于闭合凸集。作为第一步，我们通过罚项方法研究了BO的概貌，其中上层和下层目标以加权和的罚项参数$\\sigma>0$的形式相结合。特别地，我们通过明确地刻画值和导数两者必须$O(\\sigma)$接近的条件，建立了罚函数与超级目标函数之间的强连接。我们分析的一个副产品是当下层问题在最小条件下具有多个解时，超级目标函数梯度的显式公式，这可能具有独立的研究价值。接下来，将罚函数形式视为原始BO的$O(\\sigma)$-近似，我们提出了一阶算法，找到一个$\\epsilon$-驻点。",
    "tldr": "本研究通过罚函数方法研究非凸双层优化问题，建立了罚函数与超级目标函数之间的强连接，并提出了一阶算法来找到驻点。"
}