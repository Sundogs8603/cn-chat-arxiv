{
    "title": "Copiloting the Copilots: Fusing Large Language Models with Completion Engines for Automated Program Repair. (arXiv:2309.00608v1 [cs.SE])",
    "abstract": "During Automated Program Repair (APR), it can be challenging to synthesize correct patches for real-world systems in general-purpose programming languages. Recent Large Language Models (LLMs) have been shown to be helpful \"copilots\" in assisting developers with various coding tasks, and have also been directly applied for patch synthesis. However, most LLMs treat programs as sequences of tokens, meaning that they are ignorant of the underlying semantics constraints of the target programming language. This results in plenty of statically invalid generated patches, impeding the practicality of the technique. Therefore, we propose Repilot, a framework to further copilot the AI \"copilots\" (i.e., LLMs) by synthesizing more valid patches during the repair process. Our key insight is that many LLMs produce outputs autoregressively (i.e., token by token), resembling human writing programs, which can be significantly boosted and guided through a Completion Engine. Repilot synergistically synthe",
    "link": "http://arxiv.org/abs/2309.00608",
    "context": "Title: Copiloting the Copilots: Fusing Large Language Models with Completion Engines for Automated Program Repair. (arXiv:2309.00608v1 [cs.SE])\nAbstract: During Automated Program Repair (APR), it can be challenging to synthesize correct patches for real-world systems in general-purpose programming languages. Recent Large Language Models (LLMs) have been shown to be helpful \"copilots\" in assisting developers with various coding tasks, and have also been directly applied for patch synthesis. However, most LLMs treat programs as sequences of tokens, meaning that they are ignorant of the underlying semantics constraints of the target programming language. This results in plenty of statically invalid generated patches, impeding the practicality of the technique. Therefore, we propose Repilot, a framework to further copilot the AI \"copilots\" (i.e., LLMs) by synthesizing more valid patches during the repair process. Our key insight is that many LLMs produce outputs autoregressively (i.e., token by token), resembling human writing programs, which can be significantly boosted and guided through a Completion Engine. Repilot synergistically synthe",
    "path": "papers/23/09/2309.00608.json",
    "total_tokens": 887,
    "translated_title": "Copiloting the Copilots: 将大型语言模型与完成引擎融合用于自动化程序修复",
    "translated_abstract": "在自动化程序修复中，对于通用编程语言中的实际系统合成正确的修补程序可能具有挑战性。最近的大型语言模型（LLMs）已被证明对开发人员在各种编码任务中具有帮助，并且已直接应用于修补程序的合成。然而，大多数LLMs将程序视为令牌序列，这意味着它们对目标编程语言的底层语义约束一无所知。这导致生成了大量静态无效的修补程序，阻碍了该技术的实用性。因此，我们提出了Repilot，一种在修复过程中通过合成更多有效修补程序从而进一步支持AI“副驾驶员”（即LLMs）的框架。我们的关键见解是，许多LLMs以自回归方式生成输出（即逐个令牌生成），类似于人类编写程序，这可以通过完成引擎显著提升和引导。Repilot协同合成了修补程序。",
    "tldr": "这篇论文提出了一种框架，利用完成引擎来进一步支持大型语言模型在自动化程序修复中合成更多有效的修补程序。",
    "en_tdlr": "This paper proposes a framework that utilizes completion engines to further support large language models in synthesizing more valid patches during automated program repair."
}