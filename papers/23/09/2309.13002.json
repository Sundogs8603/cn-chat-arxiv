{
    "title": "Expressive variational quantum circuits provide inherent privacy in federated learning. (arXiv:2309.13002v1 [quant-ph])",
    "abstract": "Federated learning has emerged as a viable distributed solution to train machine learning models without the actual need to share data with the central aggregator. However, standard neural network-based federated learning models have been shown to be susceptible to data leakage from the gradients shared with the server. In this work, we introduce federated learning with variational quantum circuit model built using expressive encoding maps coupled with overparameterized ans\\\"atze. We show that expressive maps lead to inherent privacy against gradient inversion attacks, while overparameterization ensures model trainability. Our privacy framework centers on the complexity of solving the system of high-degree multivariate Chebyshev polynomials generated by the gradients of quantum circuit. We present compelling arguments highlighting the inherent difficulty in solving these equations, both in exact and approximate scenarios. Additionally, we delve into machine learning-based attack strate",
    "link": "http://arxiv.org/abs/2309.13002",
    "context": "Title: Expressive variational quantum circuits provide inherent privacy in federated learning. (arXiv:2309.13002v1 [quant-ph])\nAbstract: Federated learning has emerged as a viable distributed solution to train machine learning models without the actual need to share data with the central aggregator. However, standard neural network-based federated learning models have been shown to be susceptible to data leakage from the gradients shared with the server. In this work, we introduce federated learning with variational quantum circuit model built using expressive encoding maps coupled with overparameterized ans\\\"atze. We show that expressive maps lead to inherent privacy against gradient inversion attacks, while overparameterization ensures model trainability. Our privacy framework centers on the complexity of solving the system of high-degree multivariate Chebyshev polynomials generated by the gradients of quantum circuit. We present compelling arguments highlighting the inherent difficulty in solving these equations, both in exact and approximate scenarios. Additionally, we delve into machine learning-based attack strate",
    "path": "papers/23/09/2309.13002.json",
    "total_tokens": 878,
    "translated_title": "表达性变分量子电路在联邦学习中提供固有隐私",
    "translated_abstract": "联邦学习已经成为一种可行的分布式解决方案，可以在不与中央聚合器共享数据的情况下训练机器学习模型。然而，已经显示出标准的基于神经网络的联邦学习模型容易受到与服务器共享的梯度的数据泄露攻击。在这项工作中，我们介绍了使用表达性编码映射和过度参数化ans\\\"tze构建的变分量子电路模型的联邦学习。我们证明了表达性映射导致对梯度反转攻击具有固有的隐私保护，而过度参数化确保了模型的可训练性。我们的隐私框架集中在通过量子电路梯度生成的高次多元切比雪夫多项式的解决复杂性上。我们提出了令人信服的论点，强调在精确和近似情况下解决这些方程的固有困难性。此外，我们深入探讨了基于机器学习的攻击策略。",
    "tldr": "表达性变分量子电路模型在联邦学习中提供固有隐私保护，同时通过使用过度参数化保证模型可训练性。通过解决高次多元切比雪夫多项式方程的复杂性，实现对梯度反转攻击的困难性。"
}