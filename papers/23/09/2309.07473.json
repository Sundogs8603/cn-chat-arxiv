{
    "title": "Where2Explore: Few-shot Affordance Learning for Unseen Novel Categories of Articulated Objects. (arXiv:2309.07473v1 [cs.RO])",
    "abstract": "Articulated object manipulation is a fundamental yet challenging task in robotics. Due to significant geometric and semantic variations across object categories, previous manipulation models struggle to generalize to novel categories. Few-shot learning is a promising solution for alleviating this issue by allowing robots to perform a few interactions with unseen objects. However, extant approaches often necessitate costly and inefficient test-time interactions with each unseen instance. Recognizing this limitation, we observe that despite their distinct shapes, different categories often share similar local geometries essential for manipulation, such as pullable handles and graspable edges - a factor typically underutilized in previous few-shot learning works. To harness this commonality, we introduce 'Where2Explore', an affordance learning framework that effectively explores novel categories with minimal interactions on a limited number of instances. Our framework explicitly estimates",
    "link": "http://arxiv.org/abs/2309.07473",
    "context": "Title: Where2Explore: Few-shot Affordance Learning for Unseen Novel Categories of Articulated Objects. (arXiv:2309.07473v1 [cs.RO])\nAbstract: Articulated object manipulation is a fundamental yet challenging task in robotics. Due to significant geometric and semantic variations across object categories, previous manipulation models struggle to generalize to novel categories. Few-shot learning is a promising solution for alleviating this issue by allowing robots to perform a few interactions with unseen objects. However, extant approaches often necessitate costly and inefficient test-time interactions with each unseen instance. Recognizing this limitation, we observe that despite their distinct shapes, different categories often share similar local geometries essential for manipulation, such as pullable handles and graspable edges - a factor typically underutilized in previous few-shot learning works. To harness this commonality, we introduce 'Where2Explore', an affordance learning framework that effectively explores novel categories with minimal interactions on a limited number of instances. Our framework explicitly estimates",
    "path": "papers/23/09/2309.07473.json",
    "total_tokens": 880,
    "translated_title": "Where2Explore: 为未见过的关节物体进行少样本能力学习的研究",
    "translated_abstract": "关节物体的操作是机器人中一项基本但具有挑战性的任务。由于物体类别之间存在重要的几何和语义差异，以往的操纵模型难以推广到新的类别。少样本学习是缓解这个问题的一种有希望的解决方案，它允许机器人对未见过的物体进行少量交互。然而，现有的方法通常需要与每个未见实例进行昂贵且低效的测试交互。鉴于这一限制，我们观察到，尽管它们具有不同的形状，不同的类别通常共享类似的局部几何结构，这些结构对于操作是必要的，比如可拉动的手柄和可抓取的边缘-这个因素在以前的少样本学习中通常没有充分利用。为了利用这种共性，我们引入了“Where2Explore”，一种探索未知类别的能力学习框架，该框架在有限数量的实例上进行最少交互的求解。",
    "tldr": "Where2Explore是一种针对未见物体的少样本能力学习框架，通过有效地探索和最少数量的交互，可以推广到具有类似局部几何结构的新类别。",
    "en_tdlr": "Where2Explore is a few-shot affordance learning framework for unseen objects, which can generalize to new categories with similar local geometries through effective exploration and minimal interactions."
}