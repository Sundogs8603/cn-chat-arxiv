{
    "title": "PRiSM: Enhancing Low-Resource Document-Level Relation Extraction with Relation-Aware Score Calibration. (arXiv:2309.13869v1 [cs.CL] CROSS LISTED)",
    "abstract": "Document-level relation extraction (DocRE) aims to extract relations of all entity pairs in a document. A key challenge in DocRE is the cost of annotating such data which requires intensive human effort. Thus, we investigate the case of DocRE in a low-resource setting, and we find that existing models trained on low data overestimate the NA (\"no relation\") label, causing limited performance. In this work, we approach the problem from a calibration perspective and propose PRiSM, which learns to adapt logits based on relation semantic information. We evaluate our method on three DocRE datasets and demonstrate that integrating existing models with PRiSM improves performance by as much as 26.38 F1 score, while the calibration error drops as much as 36 times when trained with about 3% of data. The code is publicly available at https://github.com/brightjade/PRiSM.",
    "link": "http://arxiv.org/abs/2309.13869",
    "context": "Title: PRiSM: Enhancing Low-Resource Document-Level Relation Extraction with Relation-Aware Score Calibration. (arXiv:2309.13869v1 [cs.CL] CROSS LISTED)\nAbstract: Document-level relation extraction (DocRE) aims to extract relations of all entity pairs in a document. A key challenge in DocRE is the cost of annotating such data which requires intensive human effort. Thus, we investigate the case of DocRE in a low-resource setting, and we find that existing models trained on low data overestimate the NA (\"no relation\") label, causing limited performance. In this work, we approach the problem from a calibration perspective and propose PRiSM, which learns to adapt logits based on relation semantic information. We evaluate our method on three DocRE datasets and demonstrate that integrating existing models with PRiSM improves performance by as much as 26.38 F1 score, while the calibration error drops as much as 36 times when trained with about 3% of data. The code is publicly available at https://github.com/brightjade/PRiSM.",
    "path": "papers/23/09/2309.13869.json",
    "total_tokens": 861,
    "translated_title": "PRiSM: 使用关系感知分数校准增强低资源文档级关系抽取",
    "translated_abstract": "文档级关系抽取（DocRE）旨在提取文档中所有实体对的关系。在DocRE中的一个关键挑战是注释这类数据的成本，需要大量的人力投入。因此，我们调查了低资源环境中的DocRE情况，并发现现有的在少量数据上训练的模型过高估计了NA（\"no relation\"）标签，导致性能受限。在这项工作中，我们从校准的角度来解决这个问题，提出了PRiSM，它可以根据关系语义信息来适应logits。我们在三个DocRE数据集上评估了我们的方法，并证明了将现有模型与PRiSM集成可以提高性能，F1分数提高了26.38%，而当用约3%的数据进行训练时，校准误差下降了36倍。代码可以在https://github.com/brightjade/PRiSM公开获取。",
    "tldr": "PRiSM是一种增强低资源文档级关系抽取的方法，通过关系感知分数校准来提高模型性能，成功地降低了在低资源环境下训练模型时的校准误差。"
}