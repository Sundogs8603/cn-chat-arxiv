{
    "title": "Towards Last-layer Retraining for Group Robustness with Fewer Annotations. (arXiv:2309.08534v1 [cs.LG])",
    "abstract": "Empirical risk minimization (ERM) of neural networks is prone to over-reliance on spurious correlations and poor generalization on minority groups. The recent deep feature reweighting (DFR) technique achieves state-of-the-art group robustness via simple last-layer retraining, but it requires held-out group and class annotations to construct a group-balanced reweighting dataset. In this work, we examine this impractical requirement and find that last-layer retraining can be surprisingly effective with no group annotations (other than for model selection) and only a handful of class annotations. We first show that last-layer retraining can greatly improve worst-group accuracy even when the reweighting dataset has only a small proportion of worst-group data. This implies a \"free lunch\" where holding out a subset of training data to retrain the last layer can substantially outperform ERM on the entire dataset with no additional data or annotations. To further improve group robustness, we i",
    "link": "http://arxiv.org/abs/2309.08534",
    "context": "Title: Towards Last-layer Retraining for Group Robustness with Fewer Annotations. (arXiv:2309.08534v1 [cs.LG])\nAbstract: Empirical risk minimization (ERM) of neural networks is prone to over-reliance on spurious correlations and poor generalization on minority groups. The recent deep feature reweighting (DFR) technique achieves state-of-the-art group robustness via simple last-layer retraining, but it requires held-out group and class annotations to construct a group-balanced reweighting dataset. In this work, we examine this impractical requirement and find that last-layer retraining can be surprisingly effective with no group annotations (other than for model selection) and only a handful of class annotations. We first show that last-layer retraining can greatly improve worst-group accuracy even when the reweighting dataset has only a small proportion of worst-group data. This implies a \"free lunch\" where holding out a subset of training data to retrain the last layer can substantially outperform ERM on the entire dataset with no additional data or annotations. To further improve group robustness, we i",
    "path": "papers/23/09/2309.08534.json",
    "total_tokens": 986,
    "translated_title": "朝着使用更少标注实现群体鲁棒性的最后一层再训练",
    "translated_abstract": "神经网络的经验风险最小化(ERM)容易过度依赖虚假相关性，并在少数群体上具有较差的泛化性能。最近的深度特征再赋权(DFR)技术通过简单的最后一层再训练实现了最先进的群体保护性能，但它需要保留群体和类别的标注，并构建一个群体平衡的再赋权数据集。在这项工作中，我们研究了这个不切实际的要求，并发现即使没有群体标注（除了模型选择），只有少量的类别标注，最后一层再训练仍然可以出人意料地有效。我们首先证明了即使再赋权数据集中仅有一小部分最差群体数据，最后一层再训练仍然可以显著提高最差群体准确性。这意味着通过保留一部分训练数据来重新训练最后一层，可以在没有额外数据或标注的情况下，显著优于对整个数据集进行ERM。为了进一步提高群体鲁棒性，我们...",
    "tldr": "本研究发现，在没有群体标注和只有少量类别标注的情况下，最后一层再训练仍然可以有效提高最差群体准确性，从而优于经验风险最小化在整个数据集上的表现，可以实现群体鲁棒性的提升。"
}