{
    "title": "Do You Trust ChatGPT? -- Perceived Credibility of Human and AI-Generated Content. (arXiv:2309.02524v1 [cs.HC])",
    "abstract": "This paper examines how individuals perceive the credibility of content originating from human authors versus content generated by large language models, like the GPT language model family that powers ChatGPT, in different user interface versions. Surprisingly, our results demonstrate that regardless of the user interface presentation, participants tend to attribute similar levels of credibility. While participants also do not report any different perceptions of competence and trustworthiness between human and AI-generated content, they rate AI-generated content as being clearer and more engaging. The findings from this study serve as a call for a more discerning approach to evaluating information sources, encouraging users to exercise caution and critical thinking when engaging with content generated by AI systems.",
    "link": "http://arxiv.org/abs/2309.02524",
    "context": "Title: Do You Trust ChatGPT? -- Perceived Credibility of Human and AI-Generated Content. (arXiv:2309.02524v1 [cs.HC])\nAbstract: This paper examines how individuals perceive the credibility of content originating from human authors versus content generated by large language models, like the GPT language model family that powers ChatGPT, in different user interface versions. Surprisingly, our results demonstrate that regardless of the user interface presentation, participants tend to attribute similar levels of credibility. While participants also do not report any different perceptions of competence and trustworthiness between human and AI-generated content, they rate AI-generated content as being clearer and more engaging. The findings from this study serve as a call for a more discerning approach to evaluating information sources, encouraging users to exercise caution and critical thinking when engaging with content generated by AI systems.",
    "path": "papers/23/09/2309.02524.json",
    "total_tokens": 940,
    "translated_title": "你相信ChatGPT吗？-- 关于人类与AI生成内容的可信度感知",
    "translated_abstract": "本文考察了个体对人类作者撰写内容和由大型语言模型生成的内容（如ChatGPT所采用的GPT语言模型系列）的可信度感知，同时比较了不同用户界面版本下的情况。令人惊讶的是，研究结果表明，不论用户界面的呈现形式如何，参与者倾向于赋予相似水平的可信度。尽管参与者对人类和AI生成内容的能力和值得信赖程度没有不同的感知，但他们认为AI生成的内容更加清晰且更具吸引力。这项研究的发现呼吁我们在评估信息来源时采取更加审慎的方式，鼓励用户在接触由AI系统生成的内容时保持警惕和批判性思维。",
    "tldr": "本文研究了人们对来自人类作者和由大型语言模型生成的内容的可信度感知，发现不论用户界面如何呈现，参与者倾向于赋予相似水平的可信度。尽管人们对人类和AI生成内容的能力和值得信赖程度没有不同的感知，但他们认为AI生成的内容更加清晰且更具吸引力。这项研究呼吁我们在评估信息来源时更加审慎，并鼓励用户保持警惕和批判性思维。",
    "en_tdlr": "This paper examines how individuals perceive the credibility of content generated by humans and large language models and finds that regardless of the user interface presentation, similar levels of credibility are attributed. Participants also do not differentiate between human and AI-generated content in terms of competence and trustworthiness, but rate AI-generated content as clearer and more engaging. The findings call for a more discerning approach to evaluating information sources and encourage users to exercise caution and critical thinking when engaging with AI-generated content."
}