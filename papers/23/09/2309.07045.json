{
    "title": "SafetyBench: Evaluating the Safety of Large Language Models with Multiple Choice Questions. (arXiv:2309.07045v1 [cs.CL])",
    "abstract": "With the rapid development of Large Language Models (LLMs), increasing attention has been paid to their safety concerns. Consequently, evaluating the safety of LLMs has become an essential task for facilitating the broad applications of LLMs. Nevertheless, the absence of comprehensive safety evaluation benchmarks poses a significant impediment to effectively assess and enhance the safety of LLMs. In this work, we present SafetyBench, a comprehensive benchmark for evaluating the safety of LLMs, which comprises 11,435 diverse multiple choice questions spanning across 7 distinct categories of safety concerns. Notably, SafetyBench also incorporates both Chinese and English data, facilitating the evaluation in both languages. Our extensive tests over 25 popular Chinese and English LLMs in both zero-shot and few-shot settings reveal a substantial performance advantage for GPT-4 over its counterparts, and there is still significant room for improving the safety of current LLMs. We believe Saf",
    "link": "http://arxiv.org/abs/2309.07045",
    "context": "Title: SafetyBench: Evaluating the Safety of Large Language Models with Multiple Choice Questions. (arXiv:2309.07045v1 [cs.CL])\nAbstract: With the rapid development of Large Language Models (LLMs), increasing attention has been paid to their safety concerns. Consequently, evaluating the safety of LLMs has become an essential task for facilitating the broad applications of LLMs. Nevertheless, the absence of comprehensive safety evaluation benchmarks poses a significant impediment to effectively assess and enhance the safety of LLMs. In this work, we present SafetyBench, a comprehensive benchmark for evaluating the safety of LLMs, which comprises 11,435 diverse multiple choice questions spanning across 7 distinct categories of safety concerns. Notably, SafetyBench also incorporates both Chinese and English data, facilitating the evaluation in both languages. Our extensive tests over 25 popular Chinese and English LLMs in both zero-shot and few-shot settings reveal a substantial performance advantage for GPT-4 over its counterparts, and there is still significant room for improving the safety of current LLMs. We believe Saf",
    "path": "papers/23/09/2309.07045.json",
    "total_tokens": 976,
    "translated_title": "SafetyBench: 用多项选择题评估大型语言模型的安全性",
    "translated_abstract": "随着大型语言模型（LLM）的快速发展，人们越来越关注它们的安全问题。因此，评估LLM的安全性已成为促进其广泛应用的重要任务。然而，缺乏全面的安全评估基准明显阻碍了对LLM安全性的有效评估和提升。在这项工作中，我们提出了SafetyBench，这是一个用于评估LLMs安全性的全面基准，包括11,435个不同的多项选择问题，涵盖了7个不同的安全问题类别。值得注意的是，SafetyBench还包括中英文数据，方便两种语言的评估。我们在25个热门中英文LLM上进行了广泛的测试，包括零-shot和少-shot设置。结果显示，GPT-4在性能上明显优于其他模型，并且当前LLM的安全性还有很大的提升空间。",
    "tldr": "SafetyBench是一个全面基准，用于评估大型语言模型的安全性。它包括了11,435个多项选择问题，涵盖了7个不同的安全问题类别，并且还提供中英文数据。通过对25个热门中英文LLM进行测试，我们发现GPT-4在性能上明显优于其他模型，但当前LLM的安全性仍有很大的提升空间。",
    "en_tdlr": "SafetyBench is a comprehensive benchmark for evaluating the safety of large language models (LLMs). It includes 11,435 diverse multiple choice questions spanning across 7 distinct categories of safety concerns and provides data in both Chinese and English. Through extensive tests on 25 popular Chinese and English LLMs, we found that GPT-4 outperforms its counterparts in terms of performance, but there is still significant room for improving the safety of current LLMs."
}