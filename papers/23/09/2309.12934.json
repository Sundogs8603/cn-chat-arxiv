{
    "title": "TopRoBERTa: Topology-Aware Authorship Attribution of Deepfake Texts. (arXiv:2309.12934v1 [cs.CL])",
    "abstract": "Recent advances in Large Language Models (LLMs) have enabled the generation of open-ended high-quality texts, that are non-trivial to distinguish from human-written texts. We refer to such LLM-generated texts as \\emph{deepfake texts}. There are currently over 11K text generation models in the huggingface model repo. As such, users with malicious intent can easily use these open-sourced LLMs to generate harmful texts and misinformation at scale. To mitigate this problem, a computational method to determine if a given text is a deepfake text or not is desired--i.e., Turing Test (TT). In particular, in this work, we investigate the more general version of the problem, known as \\emph{Authorship Attribution (AA)}, in a multi-class setting--i.e., not only determining if a given text is a deepfake text or not but also being able to pinpoint which LLM is the author. We propose \\textbf{TopRoBERTa} to improve existing AA solutions by capturing more linguistic patterns in deepfake texts by includ",
    "link": "http://arxiv.org/abs/2309.12934",
    "context": "Title: TopRoBERTa: Topology-Aware Authorship Attribution of Deepfake Texts. (arXiv:2309.12934v1 [cs.CL])\nAbstract: Recent advances in Large Language Models (LLMs) have enabled the generation of open-ended high-quality texts, that are non-trivial to distinguish from human-written texts. We refer to such LLM-generated texts as \\emph{deepfake texts}. There are currently over 11K text generation models in the huggingface model repo. As such, users with malicious intent can easily use these open-sourced LLMs to generate harmful texts and misinformation at scale. To mitigate this problem, a computational method to determine if a given text is a deepfake text or not is desired--i.e., Turing Test (TT). In particular, in this work, we investigate the more general version of the problem, known as \\emph{Authorship Attribution (AA)}, in a multi-class setting--i.e., not only determining if a given text is a deepfake text or not but also being able to pinpoint which LLM is the author. We propose \\textbf{TopRoBERTa} to improve existing AA solutions by capturing more linguistic patterns in deepfake texts by includ",
    "path": "papers/23/09/2309.12934.json",
    "total_tokens": 908,
    "translated_title": "TopRoBERTa：拓扑感知的深伪文本作者识别",
    "translated_abstract": "最近大规模语言模型（LLM）的进展使得生成开放性、高质量的文本成为可能，这些文本很难与人类写作的文本区分开来，我们将这种LLM生成的文本称为“深伪文本”。目前，huggingface模型存储库中有超过11K个文本生成模型。因此，恶意用户可以轻松使用这些开源的LLM生成大规模的有害文本和虚假信息。为了缓解这个问题，我们希望有一种计算方法能够确定给定的文本是否为深伪文本，即通过图灵测试（TT）来判断。具体而言，在这项工作中，我们调查了更一般版本的问题，即在多类别设置下的“作者识别（AA）”，即不仅确定给定的文本是否为深伪文本，而且还能够确定哪个LLM是作者。我们提出了TopRoBERTa，通过包含更多深伪文本中的语言模式来改进现有的AA解决方案。",
    "tldr": "本论文提出了一种拓扑感知的深伪文本作者识别方法TopRoBERTa，通过捕捉深伪文本中的更多语言模式，改进了现有的作者识别解决方案。"
}