{
    "title": "Unimodal Aggregation for CTC-based Speech Recognition. (arXiv:2309.08150v1 [cs.CL])",
    "abstract": "This paper works on non-autoregressive automatic speech recognition. A unimodal aggregation (UMA) is proposed to segment and integrate the feature frames that belong to the same text token, and thus to learn better feature representations for text tokens. The frame-wise features and weights are both derived from an encoder. Then, the feature frames with unimodal weights are integrated and further processed by a decoder. Connectionist temporal classification (CTC) loss is applied for training. Compared to the regular CTC, the proposed method learns better feature representations and shortens the sequence length, resulting in lower recognition error and computational complexity. Experiments on three Mandarin datasets show that UMA demonstrates superior or comparable performance to other advanced non-autoregressive methods, such as self-conditioned CTC. Moreover, by integrating self-conditioned CTC into the proposed framework, the performance can be further noticeably improved.",
    "link": "http://arxiv.org/abs/2309.08150",
    "context": "Title: Unimodal Aggregation for CTC-based Speech Recognition. (arXiv:2309.08150v1 [cs.CL])\nAbstract: This paper works on non-autoregressive automatic speech recognition. A unimodal aggregation (UMA) is proposed to segment and integrate the feature frames that belong to the same text token, and thus to learn better feature representations for text tokens. The frame-wise features and weights are both derived from an encoder. Then, the feature frames with unimodal weights are integrated and further processed by a decoder. Connectionist temporal classification (CTC) loss is applied for training. Compared to the regular CTC, the proposed method learns better feature representations and shortens the sequence length, resulting in lower recognition error and computational complexity. Experiments on three Mandarin datasets show that UMA demonstrates superior or comparable performance to other advanced non-autoregressive methods, such as self-conditioned CTC. Moreover, by integrating self-conditioned CTC into the proposed framework, the performance can be further noticeably improved.",
    "path": "papers/23/09/2309.08150.json",
    "total_tokens": 930,
    "translated_title": "CTC-based语音识别的单模聚合方法",
    "translated_abstract": "本文针对非自回归自动语音识别进行研究。提出了一种单模聚合（UMA）方法，用于对属于同一文本标记的特征帧进行分割和集成，从而学习更好的文本标记特征表示。特征帧和权重都来自于编码器。然后，使用单模权重集成特征帧，并经过解码器进一步处理。训练时采用了连接主义时间分类（CTC）损失。与常规CTC相比，所提出的方法学习到了更好的特征表示，并缩短了序列长度，从而降低了识别错误和计算复杂度。在三个普通话数据集上的实验结果表明，UMA相比其他先进的非自回归方法（如自条件CTC）表现出更好或相当的性能。此外，通过将自条件CTC集成到所提出的框架中，性能可以进一步显著提高。",
    "tldr": "本文提出了一种在CTC-based语音识别中用于学习更好的特征表示和缩短序列长度的单模聚合方法(UMA)，通过分割和集成同一文本标记的特征帧，实现了更低的识别错误和计算复杂度。实验证明，UMA在普通话数据集上表现出较好的性能，并且通过集成自条件CTC可以进一步提高性能。",
    "en_tdlr": "This paper proposes a unimodal aggregation (UMA) method for learning better feature representations and shortening sequence length in CTC-based speech recognition. Experimental results show that UMA achieves lower recognition error and computational complexity, and integrating self-conditioned CTC further improves the performance."
}