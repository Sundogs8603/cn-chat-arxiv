{
    "title": "Turbulence in Focus: Benchmarking Scaling Behavior of 3D Volumetric Super-Resolution with BLASTNet 2.0 Data. (arXiv:2309.13457v2 [cs.LG] UPDATED)",
    "abstract": "Analysis of compressible turbulent flows is essential for applications related to propulsion, energy generation, and the environment. Here, we present BLASTNet 2.0, a 2.2 TB network-of-datasets containing 744 full-domain samples from 34 high-fidelity direct numerical simulations, which addresses the current limited availability of 3D high-fidelity reacting and non-reacting compressible turbulent flow simulation data. With this data, we benchmark a total of 49 variations of five deep learning approaches for 3D super-resolution - which can be applied for improving scientific imaging, simulations, turbulence models, as well as in computer vision applications. We perform neural scaling analysis on these models to examine the performance of different machine learning (ML) approaches, including two scientific ML techniques. We demonstrate that (i) predictive performance can scale with model size and cost, (ii) architecture matters significantly, especially for smaller models, and (iii) the b",
    "link": "http://arxiv.org/abs/2309.13457",
    "context": "Title: Turbulence in Focus: Benchmarking Scaling Behavior of 3D Volumetric Super-Resolution with BLASTNet 2.0 Data. (arXiv:2309.13457v2 [cs.LG] UPDATED)\nAbstract: Analysis of compressible turbulent flows is essential for applications related to propulsion, energy generation, and the environment. Here, we present BLASTNet 2.0, a 2.2 TB network-of-datasets containing 744 full-domain samples from 34 high-fidelity direct numerical simulations, which addresses the current limited availability of 3D high-fidelity reacting and non-reacting compressible turbulent flow simulation data. With this data, we benchmark a total of 49 variations of five deep learning approaches for 3D super-resolution - which can be applied for improving scientific imaging, simulations, turbulence models, as well as in computer vision applications. We perform neural scaling analysis on these models to examine the performance of different machine learning (ML) approaches, including two scientific ML techniques. We demonstrate that (i) predictive performance can scale with model size and cost, (ii) architecture matters significantly, especially for smaller models, and (iii) the b",
    "path": "papers/23/09/2309.13457.json",
    "total_tokens": 945,
    "translated_title": "焦点中的湍流：用BLASTNet 2.0数据基准测量三维体积超分辨率的缩放行为",
    "translated_abstract": "压缩湍流流动的分析对推进、能源生成和环境相关应用至关重要。本文介绍了BLASTNet 2.0，它是一个包含744个完整域样本来自34个高保真直接数值模拟的2.2TB数据集网络，旨在解决目前三维高保真反应和非反应压缩湍流流动模拟数据有限的问题。利用这些数据，我们基准测试了49种不同的深度学习方法的五个变体，用于改进科学成像、模拟、湍流模型以及计算机视觉应用。我们对这些模型进行了神经缩放分析，以检查不同机器学习（ML）方法的性能，包括两种科学ML技术。我们证明了（i）预测性能可以随模型规模和成本而扩展，（ii）架构尤其对较小的模型有重要影响，以及（iii）b...",
    "tldr": "本研究提出了BLASTNet 2.0，包含三维高保真压缩湍流流动模拟数据，通过对五种深度学习方法的基准测试和神经缩放分析，揭示了模型规模、成本和架构对预测性能的影响。",
    "en_tdlr": "This study presents BLASTNet 2.0, a dataset containing 3D high-fidelity compressible turbulent flow simulation data, and reveals the impact of model size, cost, and architecture on predictive performance through benchmarking and neural scaling analysis of five deep learning approaches."
}