{
    "title": "The Confidence-Competence Gap in Large Language Models: A Cognitive Study. (arXiv:2309.16145v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs) have acquired ubiquitous attention for their performances across diverse domains. Our study here searches through LLMs' cognitive abilities and confidence dynamics. We dive deep into understanding the alignment between their self-assessed confidence and actual performance. We exploit these models with diverse sets of questionnaires and real-world scenarios and extract how LLMs exhibit confidence in their responses. Our findings reveal intriguing instances where models demonstrate high confidence even when they answer incorrectly. This is reminiscent of the Dunning-Kruger effect observed in human psychology. In contrast, there are cases where models exhibit low confidence with correct answers revealing potential underestimation biases. Our results underscore the need for a deeper understanding of their cognitive processes. By examining the nuances of LLMs' self-assessment mechanism, this investigation provides noteworthy revelations that serve to advance the",
    "link": "http://arxiv.org/abs/2309.16145",
    "context": "Title: The Confidence-Competence Gap in Large Language Models: A Cognitive Study. (arXiv:2309.16145v1 [cs.CL])\nAbstract: Large Language Models (LLMs) have acquired ubiquitous attention for their performances across diverse domains. Our study here searches through LLMs' cognitive abilities and confidence dynamics. We dive deep into understanding the alignment between their self-assessed confidence and actual performance. We exploit these models with diverse sets of questionnaires and real-world scenarios and extract how LLMs exhibit confidence in their responses. Our findings reveal intriguing instances where models demonstrate high confidence even when they answer incorrectly. This is reminiscent of the Dunning-Kruger effect observed in human psychology. In contrast, there are cases where models exhibit low confidence with correct answers revealing potential underestimation biases. Our results underscore the need for a deeper understanding of their cognitive processes. By examining the nuances of LLMs' self-assessment mechanism, this investigation provides noteworthy revelations that serve to advance the",
    "path": "papers/23/09/2309.16145.json",
    "total_tokens": 1115,
    "translated_title": "大型语言模型中的信心-能力差距：一项认知研究",
    "translated_abstract": "大型语言模型（LLMs）由于在各个领域的表现而引起了普遍关注。本研究探索了LLMs的认知能力和信心动态。我们深入了解了它们自我评估的信心与实际表现之间的一致性。我们利用各种问卷和真实场景对这些模型进行了实验，提取了LLMs在回答中展示的信心情况。我们的研究结果揭示了一些有趣的情况，即模型在回答错误时仍表现出高度的信心，这类似于人类心理学中观察到的邓宁-克鲁格效应。相反，也有一些情况下，模型在回答正确时展示出较低的信心，揭示了潜在的低估偏差。我们的研究结果强调了对LLMs认知过程的深入了解的必要性。通过对LLMs自我评估机制的细微研究，本研究提供了值得关注的新发现，有助于推动该领域的发展。",
    "tldr": "本研究探讨了大型语言模型（LLMs）在认知能力和信心动态方面的特点。我们发现，LLMs有时会在回答错误时表现出高度的信心，类似于人类心理学中的邓宁-克鲁格效应。与此同时，他们在回答正确时有时表现出较低的信心，暗示了潜在的低估偏差。这些发现强调了对LLMs认知过程的进一步研究的重要性。通过研究LLMs自我评估机制的细节，本研究提供了有意义的新发现，推动了该领域的发展。"
}