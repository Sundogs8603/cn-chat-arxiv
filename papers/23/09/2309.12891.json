{
    "title": "EarnHFT: Efficient Hierarchical Reinforcement Learning for High Frequency Trading. (arXiv:2309.12891v1 [q-fin.TR])",
    "abstract": "High-frequency trading (HFT) uses computer algorithms to make trading decisions in short time scales (e.g., second-level), which is widely used in the Cryptocurrency (Crypto) market (e.g., Bitcoin). Reinforcement learning (RL) in financial research has shown stellar performance on many quantitative trading tasks. However, most methods focus on low-frequency trading, e.g., day-level, which cannot be directly applied to HFT because of two challenges. First, RL for HFT involves dealing with extremely long trajectories (e.g., 2.4 million steps per month), which is hard to optimize and evaluate. Second, the dramatic price fluctuations and market trend changes of Crypto make existing algorithms fail to maintain satisfactory performance. To tackle these challenges, we propose an Efficient hieArchical Reinforcement learNing method for High Frequency Trading (EarnHFT), a novel three-stage hierarchical RL framework for HFT. In stage I, we compute a Q-teacher, i.e., the optimal action value based",
    "link": "http://arxiv.org/abs/2309.12891",
    "context": "Title: EarnHFT: Efficient Hierarchical Reinforcement Learning for High Frequency Trading. (arXiv:2309.12891v1 [q-fin.TR])\nAbstract: High-frequency trading (HFT) uses computer algorithms to make trading decisions in short time scales (e.g., second-level), which is widely used in the Cryptocurrency (Crypto) market (e.g., Bitcoin). Reinforcement learning (RL) in financial research has shown stellar performance on many quantitative trading tasks. However, most methods focus on low-frequency trading, e.g., day-level, which cannot be directly applied to HFT because of two challenges. First, RL for HFT involves dealing with extremely long trajectories (e.g., 2.4 million steps per month), which is hard to optimize and evaluate. Second, the dramatic price fluctuations and market trend changes of Crypto make existing algorithms fail to maintain satisfactory performance. To tackle these challenges, we propose an Efficient hieArchical Reinforcement learNing method for High Frequency Trading (EarnHFT), a novel three-stage hierarchical RL framework for HFT. In stage I, we compute a Q-teacher, i.e., the optimal action value based",
    "path": "papers/23/09/2309.12891.json",
    "total_tokens": 882,
    "translated_title": "EarnHFT: 高效的层次化强化学习应用于高频交易",
    "translated_abstract": "高频交易（HFT）使用计算机算法在短时间内（例如以秒为单位）进行交易决策，在加密货币市场（例如比特币）中被广泛应用。金融研究中的强化学习（RL）在许多量化交易任务上表现出色。然而，大多数方法集中在低频交易，例如日级别，不能直接应用于HFT，因为面临两个挑战。首先，HFT的RL涉及处理极长的轨迹（例如每月240万个步骤），难以优化和评估。其次，加密货币的剧烈价格波动和市场趋势变化使得现有算法无法保持令人满意的性能。为了解决这些挑战，我们提出了一种用于HFT的高效层次化强化学习方法EarnHFT，这是一个创新的三阶段层次化RL框架。",
    "tldr": "EarnHFT是一个高效的层次化强化学习方法，应用于高频交易。它解决了HFT中长轨迹优化和评估困难以及加密货币价格波动的挑战。",
    "en_tdlr": "EarnHFT is an efficient hierarchical reinforcement learning method applied to high-frequency trading. It tackles the challenges of optimizing and evaluating long trajectories in HFT and the price fluctuations in cryptocurrency."
}