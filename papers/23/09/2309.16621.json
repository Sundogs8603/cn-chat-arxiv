{
    "title": "Stress Testing Chain-of-Thought Prompting for Large Language Models. (arXiv:2309.16621v1 [cs.CL])",
    "abstract": "This report examines the effectiveness of Chain-of-Thought (CoT) prompting in improving the multi-step reasoning abilities of large language models (LLMs). Inspired by previous studies \\cite{Min2022RethinkingWork}, we analyze the impact of three types of CoT prompt perturbations, namely CoT order, CoT values, and CoT operators on the performance of GPT-3 on various tasks. Our findings show that incorrect CoT prompting leads to poor performance on accuracy metrics. Correct values in the CoT is crucial for predicting correct answers. Moreover, incorrect demonstrations, where the CoT operators or the CoT order are wrong, do not affect the performance as drastically when compared to the value based perturbations. This research deepens our understanding of CoT prompting and opens some new questions regarding the capability of LLMs to learn reasoning in context.",
    "link": "http://arxiv.org/abs/2309.16621",
    "context": "Title: Stress Testing Chain-of-Thought Prompting for Large Language Models. (arXiv:2309.16621v1 [cs.CL])\nAbstract: This report examines the effectiveness of Chain-of-Thought (CoT) prompting in improving the multi-step reasoning abilities of large language models (LLMs). Inspired by previous studies \\cite{Min2022RethinkingWork}, we analyze the impact of three types of CoT prompt perturbations, namely CoT order, CoT values, and CoT operators on the performance of GPT-3 on various tasks. Our findings show that incorrect CoT prompting leads to poor performance on accuracy metrics. Correct values in the CoT is crucial for predicting correct answers. Moreover, incorrect demonstrations, where the CoT operators or the CoT order are wrong, do not affect the performance as drastically when compared to the value based perturbations. This research deepens our understanding of CoT prompting and opens some new questions regarding the capability of LLMs to learn reasoning in context.",
    "path": "papers/23/09/2309.16621.json",
    "total_tokens": 930,
    "translated_title": "大型语言模型的链式思路提示的压力测试",
    "translated_abstract": "本报告研究了链式思路提示（CoT）在改进大型语言模型（LLM）的多步推理能力方面的有效性。受到之前的研究的启发，我们分析了CoT提示的三种类型的扰动（即CoT顺序，CoT值和CoT运算符）对GPT-3在各种任务上的性能的影响。我们的发现表明，错误的CoT提示会导致准确性指标下的性能较差。正确的CoT值对于预测正确答案至关重要。此外，当与基于值的扰动相比时，CoT运算符或CoT顺序错误的不正确演示并没有如此剧烈地影响性能。这项研究加深了我们对CoT提示的理解，并提出了一些关于LLM学习上下文推理能力的新问题。",
    "tldr": "本研究通过压力测试探究了大型语言模型中链式思路提示的有效性，并发现准确的CoT值对于预测正确答案非常重要，而错误的CoT提示会导致性能下降。此外，CoT运算符或CoT顺序错误的不正确演示对性能影响较小。这项研究加深了对CoT提示的理解，并对LLM学习上下文推理能力提出了一些新问题。",
    "en_tdlr": "This study examines the effectiveness of Chain-of-Thought (CoT) prompting in improving the reasoning abilities of large language models (LLMs), finding that accurate CoT values are crucial for predicting correct answers and incorrect CoT prompting leads to performance degradation. The research deepens our understanding of CoT prompting and raises new questions about LLMs' ability to learn reasoning in context."
}