{
    "title": "DNNShifter: An Efficient DNN Pruning System for Edge Computing. (arXiv:2309.06973v1 [cs.LG])",
    "abstract": "Deep neural networks (DNNs) underpin many machine learning applications. Production quality DNN models achieve high inference accuracy by training millions of DNN parameters which has a significant resource footprint. This presents a challenge for resources operating at the extreme edge of the network, such as mobile and embedded devices that have limited computational and memory resources. To address this, models are pruned to create lightweight, more suitable variants for these devices. Existing pruning methods are unable to provide similar quality models compared to their unpruned counterparts without significant time costs and overheads or are limited to offline use cases. Our work rapidly derives suitable model variants while maintaining the accuracy of the original model. The model variants can be swapped quickly when system and network conditions change to match workload demand. This paper presents DNNShifter, an end-to-end DNN training, spatial pruning, and model switching syst",
    "link": "http://arxiv.org/abs/2309.06973",
    "context": "Title: DNNShifter: An Efficient DNN Pruning System for Edge Computing. (arXiv:2309.06973v1 [cs.LG])\nAbstract: Deep neural networks (DNNs) underpin many machine learning applications. Production quality DNN models achieve high inference accuracy by training millions of DNN parameters which has a significant resource footprint. This presents a challenge for resources operating at the extreme edge of the network, such as mobile and embedded devices that have limited computational and memory resources. To address this, models are pruned to create lightweight, more suitable variants for these devices. Existing pruning methods are unable to provide similar quality models compared to their unpruned counterparts without significant time costs and overheads or are limited to offline use cases. Our work rapidly derives suitable model variants while maintaining the accuracy of the original model. The model variants can be swapped quickly when system and network conditions change to match workload demand. This paper presents DNNShifter, an end-to-end DNN training, spatial pruning, and model switching syst",
    "path": "papers/23/09/2309.06973.json",
    "total_tokens": 900,
    "translated_title": "DNNShifter: 一种高效的边缘计算DNN剪枝系统",
    "translated_abstract": "深度神经网络（DNN）是许多机器学习应用的基础。生产质量的DNN模型通过训练数百万个DNN参数来实现高推理准确性，但这占用了大量的计算资源。这对于在网络的极端边缘处工作的资源（如具有有限计算和内存资源的移动和嵌入式设备）构成挑战。为了解决这个问题，需要对模型进行剪枝，以创建轻量级、更适合这些设备的变体。现有的剪枝方法无法在不引入显著时间成本和负担的情况下提供与未剪枝模型相似的质量模型，或者只限于离线使用场景。我们的工作通过保持原始模型的准确性，快速推导出适合的模型变体。模型变体可以在系统和网络条件发生变化以匹配工作负载需求时快速切换。本文介绍了DNNShifter，一种端到端的DNN训练、空间剪枝和模型切换系统。",
    "tldr": "DNNShifter是一种高效的边缘计算DNN剪枝系统，通过快速推导出合适的模型变体来提供高推理准确性，适应系统和网络条件变化的工作负载需求。",
    "en_tdlr": "DNNShifter is an efficient DNN pruning system for edge computing that rapidly derives suitable model variants to provide high inference accuracy and adapts to changing workload demands under varying system and network conditions."
}