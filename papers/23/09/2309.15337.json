{
    "title": "Beyond the Chat: Executable and Verifiable Text-Editing with LLMs. (arXiv:2309.15337v1 [cs.CL])",
    "abstract": "Conversational interfaces powered by Large Language Models (LLMs) have recently become a popular way to obtain feedback during document editing. However, standard chat-based conversational interfaces do not support transparency and verifiability of the editing changes that they suggest. To give the author more agency when editing with an LLM, we present InkSync, an editing interface that suggests executable edits directly within the document being edited. Because LLMs are known to introduce factual errors, Inksync also supports a 3-stage approach to mitigate this risk: Warn authors when a suggested edit introduces new information, help authors Verify the new information's accuracy through external search, and allow an auditor to perform an a-posteriori verification by Auditing the document via a trace of all auto-generated content. Two usability studies confirm the effectiveness of InkSync's components when compared to standard LLM-based chat interfaces, leading to more accurate, more ",
    "link": "http://arxiv.org/abs/2309.15337",
    "context": "Title: Beyond the Chat: Executable and Verifiable Text-Editing with LLMs. (arXiv:2309.15337v1 [cs.CL])\nAbstract: Conversational interfaces powered by Large Language Models (LLMs) have recently become a popular way to obtain feedback during document editing. However, standard chat-based conversational interfaces do not support transparency and verifiability of the editing changes that they suggest. To give the author more agency when editing with an LLM, we present InkSync, an editing interface that suggests executable edits directly within the document being edited. Because LLMs are known to introduce factual errors, Inksync also supports a 3-stage approach to mitigate this risk: Warn authors when a suggested edit introduces new information, help authors Verify the new information's accuracy through external search, and allow an auditor to perform an a-posteriori verification by Auditing the document via a trace of all auto-generated content. Two usability studies confirm the effectiveness of InkSync's components when compared to standard LLM-based chat interfaces, leading to more accurate, more ",
    "path": "papers/23/09/2309.15337.json",
    "total_tokens": 835,
    "translated_title": "超越对话：具有LLMs的可执行和可验证的文本编辑",
    "translated_abstract": "最近，由大型语言模型（LLMs）提供支持的对话界面已经成为获取文档编辑反馈的流行方式。然而，标准基于聊天的对话界面不支持编辑建议的透明性和可验证性。为了在与LLM编辑时给予作者更多的自主权，我们提出了InkSync，一种编辑界面，在正在编辑的文档中直接建议可执行编辑。由于已知LLMs会引入事实错误，InkSync还支持一种3阶段的方法来减轻此风险：当建议的编辑引入新信息时，警告作者；通过外部搜索帮助作者验证新信息的准确性；允许审核人员通过跟踪所有自动生成内容的痕迹来对文档进行事后验证。两项可用性研究证实了InkSync的各个组件相比于标准的基于LLM的聊天界面的有效性，从而使得编辑更准确，",
    "tldr": "这项研究介绍了InkSync，一个具有LLMs的可执行和可验证的文本编辑界面，可提供对用户编辑建议的透明性和准确性的支持。"
}