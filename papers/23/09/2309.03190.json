{
    "title": "Blink: Link Local Differential Privacy in Graph Neural Networks via Bayesian Estimation. (arXiv:2309.03190v1 [cs.LG])",
    "abstract": "Graph neural networks (GNNs) have gained an increasing amount of popularity due to their superior capability in learning node embeddings for various graph inference tasks, but training them can raise privacy concerns. To address this, we propose using link local differential privacy over decentralized nodes, enabling collaboration with an untrusted server to train GNNs without revealing the existence of any link. Our approach spends the privacy budget separately on links and degrees of the graph for the server to better denoise the graph topology using Bayesian estimation, alleviating the negative impact of LDP on the accuracy of the trained GNNs. We bound the mean absolute error of the inferred link probabilities against the ground truth graph topology. We then propose two variants of our LDP mechanism complementing each other in different privacy settings, one of which estimates fewer links under lower privacy budgets to avoid false positive link estimates when the uncertainty is hig",
    "link": "http://arxiv.org/abs/2309.03190",
    "context": "Title: Blink: Link Local Differential Privacy in Graph Neural Networks via Bayesian Estimation. (arXiv:2309.03190v1 [cs.LG])\nAbstract: Graph neural networks (GNNs) have gained an increasing amount of popularity due to their superior capability in learning node embeddings for various graph inference tasks, but training them can raise privacy concerns. To address this, we propose using link local differential privacy over decentralized nodes, enabling collaboration with an untrusted server to train GNNs without revealing the existence of any link. Our approach spends the privacy budget separately on links and degrees of the graph for the server to better denoise the graph topology using Bayesian estimation, alleviating the negative impact of LDP on the accuracy of the trained GNNs. We bound the mean absolute error of the inferred link probabilities against the ground truth graph topology. We then propose two variants of our LDP mechanism complementing each other in different privacy settings, one of which estimates fewer links under lower privacy budgets to avoid false positive link estimates when the uncertainty is hig",
    "path": "papers/23/09/2309.03190.json",
    "total_tokens": 1040,
    "translated_title": "Blink: 使用贝叶斯估计在图神经网络中通过链接本地差分隐私",
    "translated_abstract": "图神经网络(GNNs)由于在各种图推理任务中学习节点嵌入的卓越能力而越来越受欢迎，但训练它们可能引起隐私问题。为了解决这个问题，我们提出使用链接本地差分隐私来进行分散节点的协作，使得GNNs可以与不受信任的服务器进行训练而不泄露任何链接的存在。我们的方法将隐私预算分别用于服务器上的链接和图的度，通过贝叶斯估计更好地去噪图拓扑结构，缓解差分隐私对训练GNNs准确性的负面影响。我们限制从推断出的链接概率与真实图拓扑之间的平均绝对误差。然后，我们提出了两种不同隐私设置下互补的LDP机制的变体之一，其中在较低的隐私预算下估计较少的链接，以避免当不确定性较高时出现误报链接估计。",
    "tldr": "本文提出了一种使用链接本地差分隐私的方法，在图神经网络中实现与不受信任的服务器的协作训练。通过贝叶斯估计，将隐私预算分别用于链接和图的度，缓解差分隐私对训练准确性的负面影响，并限制链接概率推断与真实图拓扑之间的误差。提出的LDP机制有两个变体，在不同隐私设置下互补使用，以避免误报链接估计问题。",
    "en_tdlr": "This paper proposes a method that uses link local differential privacy to enable collaboration with an untrusted server in training graph neural networks. By using Bayesian estimation and allocating the privacy budget separately on links and degrees of the graph, the negative impact of differential privacy on training accuracy is alleviated, and the error between inferred link probabilities and the ground truth graph topology is constrained. Two variants of the LDP mechanism are proposed to complement each other under different privacy settings to avoid false positive link estimates."
}