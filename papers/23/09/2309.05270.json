{
    "title": "CONFLATOR: Incorporating Switching Point based Rotatory Positional Encodings for Code-Mixed Language Modeling. (arXiv:2309.05270v2 [cs.CL] UPDATED)",
    "abstract": "The mixing of two or more languages is called Code-Mixing (CM). CM is a social norm in multilingual societies. Neural Language Models (NLMs) like transformers have been effective on many NLP tasks. However, NLM for CM is an under-explored area. Though transformers are capable and powerful, they cannot always encode positional information since they are non-recurrent. Therefore, to enrich word information and incorporate positional information, positional encoding is defined. We hypothesize that Switching Points (SPs), i.e., junctions in the text where the language switches (L1 -> L2 or L2 -> L1), pose a challenge for CM Language Models (LMs), and hence give special emphasis to SPs in the modeling process. We experiment with several positional encoding mechanisms and show that rotatory positional encodings along with switching point information yield the best results.  We introduce CONFLATOR: a neural language modeling approach for code-mixed languages. CONFLATOR tries to learn to empha",
    "link": "http://arxiv.org/abs/2309.05270",
    "context": "Title: CONFLATOR: Incorporating Switching Point based Rotatory Positional Encodings for Code-Mixed Language Modeling. (arXiv:2309.05270v2 [cs.CL] UPDATED)\nAbstract: The mixing of two or more languages is called Code-Mixing (CM). CM is a social norm in multilingual societies. Neural Language Models (NLMs) like transformers have been effective on many NLP tasks. However, NLM for CM is an under-explored area. Though transformers are capable and powerful, they cannot always encode positional information since they are non-recurrent. Therefore, to enrich word information and incorporate positional information, positional encoding is defined. We hypothesize that Switching Points (SPs), i.e., junctions in the text where the language switches (L1 -> L2 or L2 -> L1), pose a challenge for CM Language Models (LMs), and hence give special emphasis to SPs in the modeling process. We experiment with several positional encoding mechanisms and show that rotatory positional encodings along with switching point information yield the best results.  We introduce CONFLATOR: a neural language modeling approach for code-mixed languages. CONFLATOR tries to learn to empha",
    "path": "papers/23/09/2309.05270.json",
    "total_tokens": 910,
    "translated_title": "CONFLATOR:将基于切换点的旋转位置编码纳入混合语言建模中",
    "translated_abstract": "两种或多种语言的混合称为代码混合（CM）。 CM是多语言社会的社会规范。神经语言模型（NLMs）（如变压器）在许多自然语言处理任务上非常有效。然而，对于CM的NLM是一个未被充分探索的领域。尽管变压器具有能力，但由于它们是非递归的，它们不能始终编码位置信息。因此，为了丰富词的信息并纳入位置信息，定义了位置编码。我们假设转换点（SPs），即语言切换的文本中的交汇点（L1-> L2或L2-> L1），对CM语言模型（LMs）构成挑战，并对建模过程中SPs给予特别重视。我们尝试了几种位置编码机制，并表明旋转位置编码以及切换点信息可以获得最佳结果。我们引入CONFLATOR：一种针对混合语言的神经语言建模方法。",
    "tldr": "本论文提出了CONFLATOR：一种针对代码混合语言的神经语言建模方法，通过引入旋转位置编码和切换点信息，在混合语言建模中取得最佳结果。",
    "en_tdlr": "This paper introduces CONFLATOR, a neural language modeling approach for code-mixed languages. By incorporating rotatory positional encodings and switching point information, it achieves the best results in code-mixed language modeling."
}