{
    "title": "Revisiting Supertagging for HPSG. (arXiv:2309.07590v1 [cs.CL])",
    "abstract": "We present new supertaggers trained on HPSG-based treebanks. These treebanks feature high-quality annotation based on a well-developed linguistic theory and include diverse and challenging test datasets, beyond the usual WSJ section 23 and Wikipedia data. HPSG supertagging has previously relied on MaxEnt-based models. We use SVM and neural CRF- and BERT-based methods and show that both SVM and neural supertaggers achieve considerably higher accuracy compared to the baseline. Our fine-tuned BERT-based tagger achieves 97.26% accuracy on 1000 sentences from WSJ23 and 93.88% on the completely out-of-domain The Cathedral and the Bazaar (cb)). We conclude that it therefore makes sense to integrate these new supertaggers into modern HPSG parsers, and we also hope that the diverse and difficult datasets we used here will gain more popularity in the field. We contribute the complete dataset reformatted for token classification.",
    "link": "http://arxiv.org/abs/2309.07590",
    "context": "Title: Revisiting Supertagging for HPSG. (arXiv:2309.07590v1 [cs.CL])\nAbstract: We present new supertaggers trained on HPSG-based treebanks. These treebanks feature high-quality annotation based on a well-developed linguistic theory and include diverse and challenging test datasets, beyond the usual WSJ section 23 and Wikipedia data. HPSG supertagging has previously relied on MaxEnt-based models. We use SVM and neural CRF- and BERT-based methods and show that both SVM and neural supertaggers achieve considerably higher accuracy compared to the baseline. Our fine-tuned BERT-based tagger achieves 97.26% accuracy on 1000 sentences from WSJ23 and 93.88% on the completely out-of-domain The Cathedral and the Bazaar (cb)). We conclude that it therefore makes sense to integrate these new supertaggers into modern HPSG parsers, and we also hope that the diverse and difficult datasets we used here will gain more popularity in the field. We contribute the complete dataset reformatted for token classification.",
    "path": "papers/23/09/2309.07590.json",
    "total_tokens": 937,
    "translated_title": "重新审视基于HPSG的Supertagging",
    "translated_abstract": "我们提出了基于HPSG树库训练的新型supertagger。这些树库基于一个成熟的语言学理论，具有高质量的注释，并且包含了丰富多样和具有挑战性的测试数据集，超出了通常的WSJ第23节和维基百科数据。之前的HPSG supertagging主要依赖于基于MaxEnt的模型。我们使用SVM和基于神经CRF和BERT的方法，并展示出SVM和神经supertagger相对于基准模型取得了显著更高的准确率。我们微调的BERT-based tagger在来自WSJ23的1000个句子上达到了97.26%的准确率，并在完全不同领域的\"The Cathedral and the Bazaar\"上达到了93.88%的准确率。因此，我们得出结论，将这些新的supertagger集成到现代HPSG解析器中是有意义的，并且我们也希望我们在这里使用的多样且难的数据集在该领域中获得更多的关注。我们贡献了重新格式化为标记分类的完整数据集。",
    "tldr": "重新审视基于HPSG的Supertagging，在高质量注释的树库和多样化的测试数据集上，通过使用SVM和神经网络方法，取得了较高准确率。相关数据集已整理为标记分类形式，可为现代HPSG解析器提供帮助。",
    "en_tdlr": "Revisiting Supertagging for HPSG, achieving higher accuracy on diverse test datasets through the use of SVM and neural network models. The complete dataset reformatted for token classification is provided."
}