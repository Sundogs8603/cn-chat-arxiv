{
    "title": "Risk-Aware Reinforcement Learning through Optimal Transport Theory. (arXiv:2309.06239v1 [cs.LG])",
    "abstract": "In the dynamic and uncertain environments where reinforcement learning (RL) operates, risk management becomes a crucial factor in ensuring reliable decision-making. Traditional RL approaches, while effective in reward optimization, often overlook the landscape of potential risks. In response, this paper pioneers the integration of Optimal Transport (OT) theory with RL to create a risk-aware framework. Our approach modifies the objective function, ensuring that the resulting policy not only maximizes expected rewards but also respects risk constraints dictated by OT distances between state visitation distributions and the desired risk profiles. By leveraging the mathematical precision of OT, we offer a formulation that elevates risk considerations alongside conventional RL objectives. Our contributions are substantiated with a series of theorems, mapping the relationships between risk distributions, optimal value functions, and policy behaviors. Through the lens of OT, this work illumin",
    "link": "http://arxiv.org/abs/2309.06239",
    "context": "Title: Risk-Aware Reinforcement Learning through Optimal Transport Theory. (arXiv:2309.06239v1 [cs.LG])\nAbstract: In the dynamic and uncertain environments where reinforcement learning (RL) operates, risk management becomes a crucial factor in ensuring reliable decision-making. Traditional RL approaches, while effective in reward optimization, often overlook the landscape of potential risks. In response, this paper pioneers the integration of Optimal Transport (OT) theory with RL to create a risk-aware framework. Our approach modifies the objective function, ensuring that the resulting policy not only maximizes expected rewards but also respects risk constraints dictated by OT distances between state visitation distributions and the desired risk profiles. By leveraging the mathematical precision of OT, we offer a formulation that elevates risk considerations alongside conventional RL objectives. Our contributions are substantiated with a series of theorems, mapping the relationships between risk distributions, optimal value functions, and policy behaviors. Through the lens of OT, this work illumin",
    "path": "papers/23/09/2309.06239.json",
    "total_tokens": 901,
    "translated_title": "通过最优输运理论实现风险感知的强化学习",
    "translated_abstract": "在强化学习（RL）操作的动态和不确定环境中，风险管理成为确保可靠决策的关键因素。传统RL方法在奖励优化方面有效，但常常忽视潜在风险的情况。针对这一问题，本文首次将最优输运（OT）理论与RL相结合，创建了一个风险感知的框架。我们的方法修改了目标函数，确保得到的策略不仅最大化期望奖励，还遵守OT距离所指示的状态访问分布和期望风险配置之间的风险约束。通过利用OT的数学精确性，我们提供了一个公式，将风险考量与传统RL目标并列。通过一系列定理，我们证实了我们的贡献，揭示了风险分布、最优值函数和策略行为之间的关系。通过OT的视角，这项工作揭示了风险感知的强化学习的重要性。",
    "tldr": "本文将最优输运理论与强化学习相结合，创建了一个风险感知的框架，通过修改目标函数，在最大化期望奖励的同时捕捉潜在风险，提供了数学精确的方法来提升强化学习中风险考量的重要性。"
}