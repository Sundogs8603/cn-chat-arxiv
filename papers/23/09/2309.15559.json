{
    "title": "Towards Faithful Neural Network Intrinsic Interpretation with Shapley Additive Self-Attribution. (arXiv:2309.15559v1 [cs.LG])",
    "abstract": "Self-interpreting neural networks have garnered significant interest in research. Existing works in this domain often (1) lack a solid theoretical foundation ensuring genuine interpretability or (2) compromise model expressiveness. In response, we formulate a generic Additive Self-Attribution (ASA) framework. Observing the absence of Shapley value in Additive Self-Attribution, we propose Shapley Additive Self-Attributing Neural Network (SASANet), with theoretical guarantees for the self-attribution value equal to the output's Shapley values. Specifically, SASANet uses a marginal contribution-based sequential schema and internal distillation-based training strategies to model meaningful outputs for any number of features, resulting in un-approximated meaningful value function. Our experimental results indicate SASANet surpasses existing self-attributing models in performance and rivals black-box models. Moreover, SASANet is shown more precise and efficient than post-hoc methods in inter",
    "link": "http://arxiv.org/abs/2309.15559",
    "context": "Title: Towards Faithful Neural Network Intrinsic Interpretation with Shapley Additive Self-Attribution. (arXiv:2309.15559v1 [cs.LG])\nAbstract: Self-interpreting neural networks have garnered significant interest in research. Existing works in this domain often (1) lack a solid theoretical foundation ensuring genuine interpretability or (2) compromise model expressiveness. In response, we formulate a generic Additive Self-Attribution (ASA) framework. Observing the absence of Shapley value in Additive Self-Attribution, we propose Shapley Additive Self-Attributing Neural Network (SASANet), with theoretical guarantees for the self-attribution value equal to the output's Shapley values. Specifically, SASANet uses a marginal contribution-based sequential schema and internal distillation-based training strategies to model meaningful outputs for any number of features, resulting in un-approximated meaningful value function. Our experimental results indicate SASANet surpasses existing self-attributing models in performance and rivals black-box models. Moreover, SASANet is shown more precise and efficient than post-hoc methods in inter",
    "path": "papers/23/09/2309.15559.json",
    "total_tokens": 1092,
    "translated_title": "以Shapley增加的自我归因实现忠实的神经网络内部解释",
    "translated_abstract": "自我解释的神经网络在研究中引起了极大的关注。该领域现有的工作通常存在以下问题：(1)缺乏确保真正可解释性的坚实理论基础，或者(2)牺牲模型的表达能力。为此，我们提出了一个通用的增加自我归因(ASA)框架。观察到增加自我归因中缺乏Shapley值，我们提出了Shapley增加的自我归因神经网络(SASANet)，其具有保证自我归因值等于输出的Shapley值的理论保证。具体而言，SASANet使用基于边际贡献的顺序模式和内部蒸馏的训练策略，为任意数量的特征建模有意义的输出，从而得到非近似的有意义的价值函数。我们的实验结果表明，SASANet在性能上超过了现有的自我归因模型，并与黑盒模型相媲美。此外，SASANet在交互式解释和效率方面显示更精确和高效于事后方法。",
    "tldr": "本文提出了一种Shapley增加的自我归因神经网络(SASANet)来实现忠实的神经网络内部解释。通过引入Shapley值，SASANet能够确保自我归因值与输出的Shapley值相等，从而提供了一个具有理论保证的解释框架。实验证明，SASANet在性能上超过了现有的自我归因模型，并与黑盒模型相媲美。此外，SASANet在交互式解释和效率方面也表现出更高的精确度和高效性。"
}