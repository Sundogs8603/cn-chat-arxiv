{
    "title": "On the Definition of Appropriate Trust and the Tools that Come with it. (arXiv:2309.11937v1 [cs.AI])",
    "abstract": "Evaluating the efficiency of human-AI interactions is challenging, including subjective and objective quality aspects. With the focus on the human experience of the explanations, evaluations of explanation methods have become mostly subjective, making comparative evaluations almost impossible and highly linked to the individual user. However, it is commonly agreed that one aspect of explanation quality is how effectively the user can detect if the predictions are trustworthy and correct, i.e., if the explanations can increase the user's appropriate trust in the model. This paper starts with the definitions of appropriate trust from the literature. It compares the definitions with model performance evaluation, showing the strong similarities between appropriate trust and model performance evaluation. The paper's main contribution is a novel approach to evaluating appropriate trust by taking advantage of the likenesses between definitions. The paper offers several straightforward evaluat",
    "link": "http://arxiv.org/abs/2309.11937",
    "context": "Title: On the Definition of Appropriate Trust and the Tools that Come with it. (arXiv:2309.11937v1 [cs.AI])\nAbstract: Evaluating the efficiency of human-AI interactions is challenging, including subjective and objective quality aspects. With the focus on the human experience of the explanations, evaluations of explanation methods have become mostly subjective, making comparative evaluations almost impossible and highly linked to the individual user. However, it is commonly agreed that one aspect of explanation quality is how effectively the user can detect if the predictions are trustworthy and correct, i.e., if the explanations can increase the user's appropriate trust in the model. This paper starts with the definitions of appropriate trust from the literature. It compares the definitions with model performance evaluation, showing the strong similarities between appropriate trust and model performance evaluation. The paper's main contribution is a novel approach to evaluating appropriate trust by taking advantage of the likenesses between definitions. The paper offers several straightforward evaluat",
    "path": "papers/23/09/2309.11937.json",
    "total_tokens": 785,
    "translated_title": "对适当信任的定义及其相关工具",
    "translated_abstract": "评估人工智能与人类之间的交互效率是具有挑战性的，包括主观和客观的质量方面。专注于解释的人类体验，解释方法的评估主要是主观的，使得比较评估几乎不可能，并且与个体用户高度相关。然而，普遍认为解释质量的一个方面是用户能否有效地检测预测的可信度和正确性，即解释是否能增强用户对模型的适当信任。本文从文献中开始对适当信任的定义进行讨论。同时将定义与模型性能评估进行比较，展示了适当信任和模型性能评估之间的强大相似之处。本文的主要创新是通过利用这些定义之间的相似性来评估适当信任的一种新方法。本文提供了几种简单直观的评估方法。",
    "tldr": "本文讨论了对适当信任的定义，并提出了一种基于定义相似性的评估方法，以增强用户对模型的信任。",
    "en_tdlr": "This paper discusses the definition of appropriate trust and proposes a novel evaluation method based on definition similarities to enhance user trust in the model."
}