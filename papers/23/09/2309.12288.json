{
    "title": "The Reversal Curse: LLMs trained on \"A is B\" fail to learn \"B is A\". (arXiv:2309.12288v1 [cs.CL])",
    "abstract": "We expose a surprising failure of generalization in auto-regressive large language models (LLMs). If a model is trained on a sentence of the form \"A is B\", it will not automatically generalize to the reverse direction \"B is A\". This is the Reversal Curse. For instance, if a model is trained on \"Olaf Scholz was the ninth Chancellor of Germany\", it will not automatically be able to answer the question, \"Who was the ninth Chancellor of Germany?\". Moreover, the likelihood of the correct answer (\"Olaf Scholz\") will not be higher than for a random name. Thus, models exhibit a basic failure of logical deduction and do not generalize a prevalent pattern in their training set (i.e. if \"A is B'' occurs, \"B is A\" is more likely to occur). We provide evidence for the Reversal Curse by finetuning GPT-3 and Llama-1 on fictitious statements such as \"Uriah Hawthorne is the composer of 'Abyssal Melodies'\" and showing that they fail to correctly answer \"Who composed 'Abyssal Melodies?'\". The Reversal Cu",
    "link": "http://arxiv.org/abs/2309.12288",
    "context": "Title: The Reversal Curse: LLMs trained on \"A is B\" fail to learn \"B is A\". (arXiv:2309.12288v1 [cs.CL])\nAbstract: We expose a surprising failure of generalization in auto-regressive large language models (LLMs). If a model is trained on a sentence of the form \"A is B\", it will not automatically generalize to the reverse direction \"B is A\". This is the Reversal Curse. For instance, if a model is trained on \"Olaf Scholz was the ninth Chancellor of Germany\", it will not automatically be able to answer the question, \"Who was the ninth Chancellor of Germany?\". Moreover, the likelihood of the correct answer (\"Olaf Scholz\") will not be higher than for a random name. Thus, models exhibit a basic failure of logical deduction and do not generalize a prevalent pattern in their training set (i.e. if \"A is B'' occurs, \"B is A\" is more likely to occur). We provide evidence for the Reversal Curse by finetuning GPT-3 and Llama-1 on fictitious statements such as \"Uriah Hawthorne is the composer of 'Abyssal Melodies'\" and showing that they fail to correctly answer \"Who composed 'Abyssal Melodies?'\". The Reversal Cu",
    "path": "papers/23/09/2309.12288.json",
    "total_tokens": 979,
    "translated_title": "翻转诅咒: 在大型语言模型中训练的\"A是B\"无法学习\"B是A\"",
    "translated_abstract": "我们揭示了自回归大型语言模型（LLM）在泛化上的令人惊讶的失败。如果一个模型是基于\"A是B\"形式的句子进行训练，它不会自动推广到相反的方向\"B是A\"。这就是翻转诅咒。例如，如果一个模型是基于\"Olaf Scholz是德国第九任总理\"进行训练的，它不会自动能够回答问题\"谁是德国第九任总理？\"。此外，正确答案（\"Olaf Scholz\"）的可能性不会比随机名字更高。因此，模型在逻辑推断上存在基本失败，并且不会推广到它们训练集中的普遍模式（即如果出现\"A是B\"，则\"B是A\"更可能出现）。我们通过在虚构的陈述（如\"Uriah Hawthorne是'Abyssal Melodies'的作曲家\"）上对GPT-3和Llama-1进行微调，并展示它们无法正确回答\"谁创作了'Abyssal Melodies'?\"来提供翻转诅咒的证据。",
    "tldr": "LLMs模型在训练中只能学习到\"A是B\"的结构，无法自动推广到\"B是A\"。这表明模型在逻辑推断上存在基本失败和训练集中模式的推广问题。",
    "en_tdlr": "LLMs trained on \"A is B\" fail to learn \"B is A\", indicating a fundamental failure in logical deduction and lack of generalization of patterns within the training set."
}