{
    "title": "Oobleck: Resilient Distributed Training of Large Models Using Pipeline Templates. (arXiv:2309.08125v1 [cs.DC])",
    "abstract": "Oobleck enables resilient distributed training of large DNN models with guaranteed fault tolerance. It takes a planning-execution co-design approach, where it first generates a set of heterogeneous pipeline templates and instantiates at least $f+1$ logically equivalent pipeline replicas to tolerate any $f$ simultaneous failures. During execution, it relies on already-replicated model states across the replicas to provide fast recovery. Oobleck provably guarantees that some combination of the initially created pipeline templates can be used to cover all available resources after $f$ or fewer simultaneous failures, thereby avoiding resource idling at all times. Evaluation on large DNN models with billions of parameters shows that Oobleck provides consistently high throughput, and it outperforms state-of-the-art fault tolerance solutions like Bamboo and Varuna by up to $13.9x$.",
    "link": "http://arxiv.org/abs/2309.08125",
    "context": "Title: Oobleck: Resilient Distributed Training of Large Models Using Pipeline Templates. (arXiv:2309.08125v1 [cs.DC])\nAbstract: Oobleck enables resilient distributed training of large DNN models with guaranteed fault tolerance. It takes a planning-execution co-design approach, where it first generates a set of heterogeneous pipeline templates and instantiates at least $f+1$ logically equivalent pipeline replicas to tolerate any $f$ simultaneous failures. During execution, it relies on already-replicated model states across the replicas to provide fast recovery. Oobleck provably guarantees that some combination of the initially created pipeline templates can be used to cover all available resources after $f$ or fewer simultaneous failures, thereby avoiding resource idling at all times. Evaluation on large DNN models with billions of parameters shows that Oobleck provides consistently high throughput, and it outperforms state-of-the-art fault tolerance solutions like Bamboo and Varuna by up to $13.9x$.",
    "path": "papers/23/09/2309.08125.json",
    "total_tokens": 900,
    "translated_title": "Oobleck：使用流水线模板实现大型模型的弹性分布式训练",
    "translated_abstract": "Oobleck通过采用规定的容错率，可实现对大型深度神经网络模型的弹性分布式训练。它采用了规划-执行的协同设计方法，首先生成一组异构的流水线模板，并实例化至少$ f + 1 $个逻辑等效的流水线副本，以容纳任何$f$个同时故障。在执行过程中，它依赖于跨副本的已复制模型状态来提供快速恢复。Oobleck可以可靠地保证在$f$个或更少的同时故障后，初始创建的流水线模板的某种组合可以用于覆盖所有可用资源，从而始终避免资源闲置。在具有数十亿参数的大型深度神经网络模型上的评估表明，Oobleck提供了一致高吞吐量，并且在吞吐量上胜过了Bamboo和Varuna等最先进的容错解决方案。",
    "tldr": "Oobleck采用流水线模板和已复制模型状态来实现对大型模型的弹性分布式训练，并通过有效利用资源和快速恢复来提供高吞吐量。在评估中，Oobleck在吞吐量上胜过了Bamboo和Varuna等最先进的容错解决方案。"
}