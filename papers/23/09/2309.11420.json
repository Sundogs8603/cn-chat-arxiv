{
    "title": "Deep Networks as Denoising Algorithms: Sample-Efficient Learning of Diffusion Models in High-Dimensional Graphical Models. (arXiv:2309.11420v1 [cs.LG])",
    "abstract": "We investigate the approximation efficiency of score functions by deep neural networks in diffusion-based generative modeling. While existing approximation theories utilize the smoothness of score functions, they suffer from the curse of dimensionality for intrinsically high-dimensional data. This limitation is pronounced in graphical models such as Markov random fields, common for image distributions, where the approximation efficiency of score functions remains unestablished.  To address this, we observe score functions can often be well-approximated in graphical models through variational inference denoising algorithms. Furthermore, these algorithms are amenable to efficient neural network representation. We demonstrate this in examples of graphical models, including Ising models, conditional Ising models, restricted Boltzmann machines, and sparse encoding models. Combined with off-the-shelf discretization error bounds for diffusion-based sampling, we provide an efficient sample com",
    "link": "http://arxiv.org/abs/2309.11420",
    "context": "Title: Deep Networks as Denoising Algorithms: Sample-Efficient Learning of Diffusion Models in High-Dimensional Graphical Models. (arXiv:2309.11420v1 [cs.LG])\nAbstract: We investigate the approximation efficiency of score functions by deep neural networks in diffusion-based generative modeling. While existing approximation theories utilize the smoothness of score functions, they suffer from the curse of dimensionality for intrinsically high-dimensional data. This limitation is pronounced in graphical models such as Markov random fields, common for image distributions, where the approximation efficiency of score functions remains unestablished.  To address this, we observe score functions can often be well-approximated in graphical models through variational inference denoising algorithms. Furthermore, these algorithms are amenable to efficient neural network representation. We demonstrate this in examples of graphical models, including Ising models, conditional Ising models, restricted Boltzmann machines, and sparse encoding models. Combined with off-the-shelf discretization error bounds for diffusion-based sampling, we provide an efficient sample com",
    "path": "papers/23/09/2309.11420.json",
    "total_tokens": 875,
    "translated_title": "深度神经网络作为降噪算法：高维图形模型中扩散模型的高效学习",
    "translated_abstract": "我们研究了深度神经网络在基于扩散的生成建模中通过评分函数的逼近效率。尽管现有的近似理论利用了评分函数的平滑性，但它们在本质上高维数据中受到维度灾难的困扰。这种限制在图形模型（如马尔可夫随机场）中尤为明显，这是图像分布常见的类型，评分函数的近似效率尚未确立。为了解决这个问题，我们观察到评分函数在图形模型中通常可以通过变分推断降噪算法进行较好的逼近。此外，这些算法适用于高效的神经网络表示。我们在图形模型的例子中进行了演示，包括伊辛模型、条件伊辛模型、受限玻尔兹曼机和稀疏编码模型。结合基于扩散采样的现成离散化误差界限，我们提供了一种高效的样本方法。",
    "tldr": "深度神经网络可以作为降噪算法在高维图形模型中学习扩散模型，为生成建模提供了高效的逼近方法。",
    "en_tdlr": "Deep neural networks can be used as denoising algorithms to learn diffusion models in high-dimensional graphical models, providing an efficient approximation approach for generative modeling."
}