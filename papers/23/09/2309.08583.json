{
    "title": "ICLEF: In-Context Learning with Expert Feedback for Explainable Style Transfer. (arXiv:2309.08583v1 [cs.CL])",
    "abstract": "While state-of-the-art language models excel at the style transfer task, current work does not address explainability of style transfer systems. Explanations could be generated using large language models such as GPT-3.5 and GPT-4, but the use of such complex systems is inefficient when smaller, widely distributed, and transparent alternatives are available. We propose a framework to augment and improve a formality style transfer dataset with explanations via model distillation from ChatGPT. To further refine the generated explanations, we propose a novel way to incorporate scarce expert human feedback using in-context learning (ICLEF: In-Context Learning from Expert Feedback) by prompting ChatGPT to act as a critic to its own outputs. We use the resulting dataset of 9,960 explainable formality style transfer instances (e-GYAFC) to show that current openly distributed instruction-tuned models (and, in some settings, ChatGPT) perform poorly on the task, and that fine-tuning on our high-",
    "link": "http://arxiv.org/abs/2309.08583",
    "context": "Title: ICLEF: In-Context Learning with Expert Feedback for Explainable Style Transfer. (arXiv:2309.08583v1 [cs.CL])\nAbstract: While state-of-the-art language models excel at the style transfer task, current work does not address explainability of style transfer systems. Explanations could be generated using large language models such as GPT-3.5 and GPT-4, but the use of such complex systems is inefficient when smaller, widely distributed, and transparent alternatives are available. We propose a framework to augment and improve a formality style transfer dataset with explanations via model distillation from ChatGPT. To further refine the generated explanations, we propose a novel way to incorporate scarce expert human feedback using in-context learning (ICLEF: In-Context Learning from Expert Feedback) by prompting ChatGPT to act as a critic to its own outputs. We use the resulting dataset of 9,960 explainable formality style transfer instances (e-GYAFC) to show that current openly distributed instruction-tuned models (and, in some settings, ChatGPT) perform poorly on the task, and that fine-tuning on our high-",
    "path": "papers/23/09/2309.08583.json",
    "total_tokens": 914,
    "translated_title": "ICLEF: 基于专家反馈的上下文学习用于可解释风格转移",
    "translated_abstract": "虽然最先进的语言模型在风格转移任务上表现出色，但当前的工作没有解决风格转移系统的可解释性问题。通过使用GPT-3.5和GPT-4等大型语言模型，可以生成解释，但是当存在更小、广泛分布且透明的替代品时，使用这样复杂的系统是低效的。我们提出了一个框架，通过从ChatGPT中进行模型蒸馏来增强和改进一个正式风格转移数据集的解释。为了进一步改善生成的解释，我们提出了一种新颖的方式，即通过上下文学习（ICLEF:基于专家反馈的上下文学习），使ChatGPT充当其自身输出的评论者。我们使用包含9960个可解释的正式风格转移实例（e-GYAFC）的数据集来展示当前公开分发的经过指导的模型（在某些设置中包括ChatGPT）在该任务上表现不佳，并且在我们的高-",
    "tldr": "本研究提出了一个框架，使用模型蒸馏增强和改进正式风格转移数据集的解释，并提出了一种新颖的方法，通过上下文学习和专家反馈进一步优化生成的解释。"
}