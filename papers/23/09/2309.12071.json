{
    "title": "Benchmarking quantized LLaMa-based models on the Brazilian Secondary School Exam. (arXiv:2309.12071v1 [cs.AI])",
    "abstract": "Although Large Language Models (LLMs) represent a revolution in the way we interact with computers, allowing the construction of complex questions and the ability to reason over a sequence of statements, their use is restricted due to the need for dedicated hardware for execution. In this study, we evaluate the performance of LLMs based on the 7 and 13 billion LLaMA models, subjected to a quantization process and run on home hardware. The models considered were Alpaca, Koala, and Vicuna. To evaluate the effectiveness of these models, we developed a database containing 1,006 questions from the ENEM (Brazilian National Secondary School Exam). Our analysis revealed that the best performing models achieved an accuracy of approximately 46% for the original texts of the Portuguese questions and 49% on their English translations. In addition, we evaluated the computational efficiency of the models by measuring the time required for execution. On average, the 7 and 13 billion LLMs took approxi",
    "link": "http://arxiv.org/abs/2309.12071",
    "context": "Title: Benchmarking quantized LLaMa-based models on the Brazilian Secondary School Exam. (arXiv:2309.12071v1 [cs.AI])\nAbstract: Although Large Language Models (LLMs) represent a revolution in the way we interact with computers, allowing the construction of complex questions and the ability to reason over a sequence of statements, their use is restricted due to the need for dedicated hardware for execution. In this study, we evaluate the performance of LLMs based on the 7 and 13 billion LLaMA models, subjected to a quantization process and run on home hardware. The models considered were Alpaca, Koala, and Vicuna. To evaluate the effectiveness of these models, we developed a database containing 1,006 questions from the ENEM (Brazilian National Secondary School Exam). Our analysis revealed that the best performing models achieved an accuracy of approximately 46% for the original texts of the Portuguese questions and 49% on their English translations. In addition, we evaluated the computational efficiency of the models by measuring the time required for execution. On average, the 7 and 13 billion LLMs took approxi",
    "path": "papers/23/09/2309.12071.json",
    "total_tokens": 938,
    "translated_title": "在巴西中学考试上对基于量化LLaMa模型的基准测试",
    "translated_abstract": "尽管大型语言模型(LLM)在我们与计算机交互的方式上代表了一场革命，允许构建复杂问题并能够对一系列陈述进行推理，但由于需要专门的硬件执行，它们的使用受到限制。在这项研究中，我们评估了基于70亿和130亿LLaMA模型的LLMs在量化处理和运行在家庭硬件上的性能。考虑到的模型有Alpaca、Koala和Vicuna。为了评估这些模型的有效性，我们开发了一个包含1006个问题的数据库，这些问题来自巴西国家中学考试(ENEM)。我们的分析发现，表现最佳的模型在原版葡萄牙语问题和其英文翻译上的准确率约为46%，另外，我们通过测量执行所需的时间来评估模型的计算效率。在平均情况下，70亿和130亿LLMs需要约",
    "tldr": "本研究对基于量化LLaMa模型的大型语言模型在巴西中学考试上进行了性能评估。评估结果表明，最佳表现的模型在原版葡萄牙语问题和其英文翻译上的准确率约为46%。同时，作者还评估了这些模型的计算效率。",
    "en_tdlr": "This study benchmarks the performance of large language models based on quantized LLaMa models on the Brazilian Secondary School Exam. The best performing models achieved an accuracy of approximately 46% for the original Portuguese questions and their English translations. The computational efficiency of the models was also evaluated."
}