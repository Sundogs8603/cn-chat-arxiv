{
    "title": "Machine Learning Data Suitability and Performance Testing Using Fault Injection Testing Framework. (arXiv:2309.11274v1 [cs.AI])",
    "abstract": "Creating resilient machine learning (ML) systems has become necessary to ensure production-ready ML systems that acquire user confidence seamlessly. The quality of the input data and the model highly influence the successful end-to-end testing in data-sensitive systems. However, the testing approaches of input data are not as systematic and are few compared to model testing. To address this gap, this paper presents the Fault Injection for Undesirable Learning in input Data (FIUL-Data) testing framework that tests the resilience of ML models to multiple intentionally-triggered data faults. Data mutators explore vulnerabilities of ML systems against the effects of different fault injections. The proposed framework is designed based on three main ideas: The mutators are not random; one data mutator is applied at an instance of time, and the selected ML models are optimized beforehand. This paper evaluates the FIUL-Data framework using data from analytical chemistry, comprising retention t",
    "link": "http://arxiv.org/abs/2309.11274",
    "context": "Title: Machine Learning Data Suitability and Performance Testing Using Fault Injection Testing Framework. (arXiv:2309.11274v1 [cs.AI])\nAbstract: Creating resilient machine learning (ML) systems has become necessary to ensure production-ready ML systems that acquire user confidence seamlessly. The quality of the input data and the model highly influence the successful end-to-end testing in data-sensitive systems. However, the testing approaches of input data are not as systematic and are few compared to model testing. To address this gap, this paper presents the Fault Injection for Undesirable Learning in input Data (FIUL-Data) testing framework that tests the resilience of ML models to multiple intentionally-triggered data faults. Data mutators explore vulnerabilities of ML systems against the effects of different fault injections. The proposed framework is designed based on three main ideas: The mutators are not random; one data mutator is applied at an instance of time, and the selected ML models are optimized beforehand. This paper evaluates the FIUL-Data framework using data from analytical chemistry, comprising retention t",
    "path": "papers/23/09/2309.11274.json",
    "total_tokens": 904,
    "translated_title": "使用故障注入测试框架进行机器学习数据适应性和性能测试",
    "translated_abstract": "创建弹性机器学习(ML)系统已成为确保具有用户信心的生产就绪ML系统的必要条件。输入数据和模型的质量对数据敏感系统中成功的端到端测试有很大影响。然而，相对于模型测试来说，输入数据的测试方法并不像模型测试那样系统化，且数量较少。为了填补这一空白，本文提出了故障注入不满意学习输入数据(FIUL-Data)测试框架，用于测试ML模型对多个有意触发的数据故障的弹性。数据突变器可以探索ML系统对不同故障注入效果的脆弱性。该框架根据三个主要思想进行设计：突变器不是随机的；一个数据突变器在一个时间实例应用；在进行选择的ML模型之前进行了优化。本文使用分析化学的数据对FIUL-Data框架进行评估。",
    "tldr": "本文提出了基于故障注入的输入数据测试框架，用于测试机器学习模型对多个故意引发的数据故障的弹性。该框架使用数据突变器探索ML系统对不同故障注入效果的脆弱性，并在选定的ML模型之前进行优化。"
}