{
    "title": "A Unified View of Differentially Private Deep Generative Modeling. (arXiv:2309.15696v1 [cs.LG])",
    "abstract": "The availability of rich and vast data sources has greatly advanced machine learning applications in various domains. However, data with privacy concerns comes with stringent regulations that frequently prohibited data access and data sharing. Overcoming these obstacles in compliance with privacy considerations is key for technological progress in many real-world application scenarios that involve privacy sensitive data. Differentially private (DP) data publishing provides a compelling solution, where only a sanitized form of the data is publicly released, enabling privacy-preserving downstream analysis and reproducible research in sensitive domains. In recent years, various approaches have been proposed for achieving privacy-preserving high-dimensional data generation by private training on top of deep neural networks. In this paper, we present a novel unified view that systematizes these approaches. Our view provides a joint design space for systematically deriving methods that cater",
    "link": "http://arxiv.org/abs/2309.15696",
    "context": "Title: A Unified View of Differentially Private Deep Generative Modeling. (arXiv:2309.15696v1 [cs.LG])\nAbstract: The availability of rich and vast data sources has greatly advanced machine learning applications in various domains. However, data with privacy concerns comes with stringent regulations that frequently prohibited data access and data sharing. Overcoming these obstacles in compliance with privacy considerations is key for technological progress in many real-world application scenarios that involve privacy sensitive data. Differentially private (DP) data publishing provides a compelling solution, where only a sanitized form of the data is publicly released, enabling privacy-preserving downstream analysis and reproducible research in sensitive domains. In recent years, various approaches have been proposed for achieving privacy-preserving high-dimensional data generation by private training on top of deep neural networks. In this paper, we present a novel unified view that systematizes these approaches. Our view provides a joint design space for systematically deriving methods that cater",
    "path": "papers/23/09/2309.15696.json",
    "total_tokens": 835,
    "translated_title": "差分隐私深度生成建模的统一视角",
    "translated_abstract": "富饶且广泛的数据源的可用性极大地推动了各个领域中机器学习应用的发展。然而，涉及隐私问题的数据带来了严格的限制，经常禁止数据访问和数据共享。在遵守隐私考虑的前提下克服这些障碍对于涉及隐私敏感数据的实际应用场景中的技术进步至关重要。差分隐私（DP）数据发布提供了一个有力的解决方案，其中只公开发布数据的一种经过净化处理的形式，实现了保护隐私的下游分析和可重复研究。近年来，已提出了各种方法，通过在深度神经网络上进行私有培训，实现隐私保护的高维数据生成。在本文中，我们提出了一种新颖的统一视角，系统化这些方法。我们的视角为系统地衍生满足差分隐私需求的方法提供了一个联合设计空间。",
    "tldr": "本文提出了差分隐私深度生成建模的统一视角，系统化了方法，为满足差分隐私需求的方法提供了一个联合设计空间。"
}