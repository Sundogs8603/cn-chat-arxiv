{
    "title": "Cyber Security Requirements for Platforms Enhancing AI Reproducibility. (arXiv:2309.15525v1 [cs.CR])",
    "abstract": "Scientific research is increasingly reliant on computational methods, posing challenges for ensuring research reproducibility. This study focuses on the field of artificial intelligence (AI) and introduces a new framework for evaluating AI platforms for reproducibility from a cyber security standpoint to address the security challenges associated with AI research. Using this framework, five popular AI reproducibility platforms; Floydhub, BEAT, Codalab, Kaggle, and OpenML were assessed. The analysis revealed that none of these platforms fully incorporates the necessary cyber security measures essential for robust reproducibility. Kaggle and Codalab, however, performed better in terms of implementing cyber security measures covering aspects like security, privacy, usability, and trust. Consequently, the study provides tailored recommendations for different user scenarios, including individual researchers, small laboratories, and large corporations. It emphasizes the importance of integra",
    "link": "http://arxiv.org/abs/2309.15525",
    "context": "Title: Cyber Security Requirements for Platforms Enhancing AI Reproducibility. (arXiv:2309.15525v1 [cs.CR])\nAbstract: Scientific research is increasingly reliant on computational methods, posing challenges for ensuring research reproducibility. This study focuses on the field of artificial intelligence (AI) and introduces a new framework for evaluating AI platforms for reproducibility from a cyber security standpoint to address the security challenges associated with AI research. Using this framework, five popular AI reproducibility platforms; Floydhub, BEAT, Codalab, Kaggle, and OpenML were assessed. The analysis revealed that none of these platforms fully incorporates the necessary cyber security measures essential for robust reproducibility. Kaggle and Codalab, however, performed better in terms of implementing cyber security measures covering aspects like security, privacy, usability, and trust. Consequently, the study provides tailored recommendations for different user scenarios, including individual researchers, small laboratories, and large corporations. It emphasizes the importance of integra",
    "path": "papers/23/09/2309.15525.json",
    "total_tokens": 1039,
    "translated_title": "增强人工智能可复制性的平台的网络安全要求",
    "translated_abstract": "科学研究越来越依赖计算方法，这给确保研究可复制性带来了挑战。本研究聚焦于人工智能领域，并介绍了一个新的从网络安全角度评估人工智能平台可复制性的框架，以解决与人工智能研究相关的安全挑战。利用这个框架，评估了五个流行的人工智能可复制性平台：Floydhub、BEAT、Codalab、Kaggle和OpenML。分析发现，这些平台都没有完全整合必要的网络安全措施，这些措施对于稳健的可复制性至关重要。然而，Kaggle和Codalab在实施涵盖安全性、隐私、易用性和信任等方面的网络安全措施方面表现较好。因此，本研究针对不同的用户情况提供了量身定制的建议，包括个人研究者、小型实验室和大型企业。研究强调整合网络安全措施的重要性。",
    "tldr": "本研究针对人工智能研究领域，提出了一个新的框架来评估人工智能平台的可复制性和网络安全性。经过评估，发现目前流行的可复制性平台中没有一个完全整合了必要的网络安全措施，但Kaggle和Codalab在实施网络安全措施方面表现较好。本研究还根据用户的不同情况提供了相应的建议，强调整合网络安全措施的重要性。",
    "en_tdlr": "This study introduces a new framework for evaluating the reproducibility and cyber security of AI platforms in the field of artificial intelligence. The analysis reveals that existing popular reproducibility platforms lack necessary cyber security measures, but Kaggle and Codalab perform better in implementing these measures. The study provides tailored recommendations based on different user scenarios and emphasizes the importance of integrating cyber security measures."
}