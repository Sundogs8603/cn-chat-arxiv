{
    "title": "Compositional Learning of Visually-Grounded Concepts Using Reinforcement. (arXiv:2309.04504v1 [cs.LG])",
    "abstract": "Deep reinforcement learning agents need to be trained over millions of episodes to decently solve navigation tasks grounded to instructions. Furthermore, their ability to generalize to novel combinations of instructions is unclear. Interestingly however, children can decompose language-based instructions and navigate to the referred object, even if they have not seen the combination of queries prior. Hence, we created three 3D environments to investigate how deep RL agents learn and compose color-shape based combinatorial instructions to solve novel combinations in a spatial navigation task. First, we explore if agents can perform compositional learning, and whether they can leverage on frozen text encoders (e.g. CLIP, BERT) to learn word combinations in fewer episodes. Next, we demonstrate that when agents are pretrained on the shape or color concepts separately, they show a 20 times decrease in training episodes needed to solve unseen combinations of instructions. Lastly, we show tha",
    "link": "http://arxiv.org/abs/2309.04504",
    "context": "Title: Compositional Learning of Visually-Grounded Concepts Using Reinforcement. (arXiv:2309.04504v1 [cs.LG])\nAbstract: Deep reinforcement learning agents need to be trained over millions of episodes to decently solve navigation tasks grounded to instructions. Furthermore, their ability to generalize to novel combinations of instructions is unclear. Interestingly however, children can decompose language-based instructions and navigate to the referred object, even if they have not seen the combination of queries prior. Hence, we created three 3D environments to investigate how deep RL agents learn and compose color-shape based combinatorial instructions to solve novel combinations in a spatial navigation task. First, we explore if agents can perform compositional learning, and whether they can leverage on frozen text encoders (e.g. CLIP, BERT) to learn word combinations in fewer episodes. Next, we demonstrate that when agents are pretrained on the shape or color concepts separately, they show a 20 times decrease in training episodes needed to solve unseen combinations of instructions. Lastly, we show tha",
    "path": "papers/23/09/2309.04504.json",
    "total_tokens": 945,
    "translated_title": "使用强化学习进行基于视觉的概念组合学习",
    "translated_abstract": "深度强化学习代理需要通过数百万个回合的训练才能较好地解决与指令相关的导航任务，并且它们是否能够推广到新颖的指令组合的能力尚不清楚。有趣的是，儿童可以分解基于语言的指令并导航到指定的物体，即使他们之前没有见过这些查询的组合。因此，我们创建了三个3D环境，研究深度强化学习代理如何学习和组合基于颜色和形状的组合指令，以解决空间导航任务中的新颖组合。首先，我们探讨代理是否能够进行组合学习，并且它们是否可以利用冻结的文本编码器（例如CLIP、BERT）在更少的回合中学习单词组合。接下来，我们证明当代理在形状或颜色概念上进行预训练时，它们所需的训练回合数减少了20倍，可以解决未见过的指令组合。最后，我们展示了...",
    "tldr": "本研究探讨了深度强化学习代理如何学习和组合基于颜色和形状的组合指令，以解决空间导航任务中的新颖组合。通过利用冻结的文本编码器，代理所需的训练回合数减少了20倍。",
    "en_tdlr": "This study investigates how deep reinforcement learning agents learn and compose color-shape based combinatorial instructions to solve novel combinations in spatial navigation tasks. By leveraging frozen text encoders, the agents' training episodes are reduced by 20 times."
}