{
    "title": "Symmetry Leads to Structured Constraint of Learning. (arXiv:2309.16932v1 [cs.LG])",
    "abstract": "Due to common architecture designs, symmetries exist extensively in contemporary neural networks. In this work, we unveil the importance of the loss function symmetries in affecting, if not deciding, the learning behavior of machine learning models. We prove that every mirror symmetry of the loss function leads to a structured constraint, which becomes a favored solution when either the weight decay or gradient noise is large. As direct corollaries, we show that rescaling symmetry leads to sparsity, rotation symmetry leads to low rankness, and permutation symmetry leads to homogeneous ensembling. Then, we show that the theoretical framework can explain the loss of plasticity and various collapse phenomena in neural networks and suggest how symmetries can be used to design algorithms to enforce hard constraints in a differentiable way.",
    "link": "http://arxiv.org/abs/2309.16932",
    "context": "Title: Symmetry Leads to Structured Constraint of Learning. (arXiv:2309.16932v1 [cs.LG])\nAbstract: Due to common architecture designs, symmetries exist extensively in contemporary neural networks. In this work, we unveil the importance of the loss function symmetries in affecting, if not deciding, the learning behavior of machine learning models. We prove that every mirror symmetry of the loss function leads to a structured constraint, which becomes a favored solution when either the weight decay or gradient noise is large. As direct corollaries, we show that rescaling symmetry leads to sparsity, rotation symmetry leads to low rankness, and permutation symmetry leads to homogeneous ensembling. Then, we show that the theoretical framework can explain the loss of plasticity and various collapse phenomena in neural networks and suggest how symmetries can be used to design algorithms to enforce hard constraints in a differentiable way.",
    "path": "papers/23/09/2309.16932.json",
    "total_tokens": 859,
    "translated_title": "对称性导致学习的结构性约束",
    "translated_abstract": "由于常见的架构设计，对称性在当代神经网络中广泛存在。在这项工作中，我们揭示了损失函数对称性对影响机器学习模型的学习行为的重要性。我们证明了损失函数的每个镜像对称性都会导致一种结构性约束，当权重衰减或梯度噪声较大时，这种约束将成为首选解。作为直接推论，我们展示了重新缩放对称性导致稀疏性，旋转对称性导致低秩性，置换对称性导致同质集成。然后，我们展示了理论框架可以解释神经网络中的可塑性丧失和各种崩溃现象，并提出了如何利用对称性设计可微分实施硬性约束的算法。",
    "tldr": "本研究揭示了损失函数对称性对机器学习模型的学习行为至关重要，引入的每个镜像对称性都会导致一种结构性约束，可以用于实现稀疏性、低秩性和同质集成，并提供了解释网络塑性丧失和崩溃现象的理论框架。"
}