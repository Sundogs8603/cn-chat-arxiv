{
    "title": "Watch the Speakers: A Hybrid Continuous Attribution Network for Emotion Recognition in Conversation With Emotion Disentanglement. (arXiv:2309.09799v2 [cs.CL] UPDATED)",
    "abstract": "Emotion Recognition in Conversation (ERC) has attracted widespread attention in the natural language processing field due to its enormous potential for practical applications. Existing ERC methods face challenges in achieving generalization to diverse scenarios due to insufficient modeling of context, ambiguous capture of dialogue relationships and overfitting in speaker modeling. In this work, we present a Hybrid Continuous Attributive Network (HCAN) to address these issues in the perspective of emotional continuation and emotional attribution. Specifically, HCAN adopts a hybrid recurrent and attention-based module to model global emotion continuity. Then a novel Emotional Attribution Encoding (EAE) is proposed to model intra- and inter-emotional attribution for each utterance. Moreover, aiming to enhance the robustness of the model in speaker modeling and improve its performance in different scenarios, A comprehensive loss function emotional cognitive loss $\\mathcal{L}_{\\rm EC}$ is p",
    "link": "http://arxiv.org/abs/2309.09799",
    "context": "Title: Watch the Speakers: A Hybrid Continuous Attribution Network for Emotion Recognition in Conversation With Emotion Disentanglement. (arXiv:2309.09799v2 [cs.CL] UPDATED)\nAbstract: Emotion Recognition in Conversation (ERC) has attracted widespread attention in the natural language processing field due to its enormous potential for practical applications. Existing ERC methods face challenges in achieving generalization to diverse scenarios due to insufficient modeling of context, ambiguous capture of dialogue relationships and overfitting in speaker modeling. In this work, we present a Hybrid Continuous Attributive Network (HCAN) to address these issues in the perspective of emotional continuation and emotional attribution. Specifically, HCAN adopts a hybrid recurrent and attention-based module to model global emotion continuity. Then a novel Emotional Attribution Encoding (EAE) is proposed to model intra- and inter-emotional attribution for each utterance. Moreover, aiming to enhance the robustness of the model in speaker modeling and improve its performance in different scenarios, A comprehensive loss function emotional cognitive loss $\\mathcal{L}_{\\rm EC}$ is p",
    "path": "papers/23/09/2309.09799.json",
    "total_tokens": 871,
    "translated_title": "观察演讲者：一种用于情感识别的混合连续归属网络，对话中带有情感分离",
    "translated_abstract": "会话中的情感识别（ERC）在自然语言处理领域引起了广泛关注，因为它具有巨大的实际应用潜力。现有的ERC方法面临着在各种不同情景下泛化的挑战，原因是对上下文建模不足、对对话关系的模糊捕捉不精确以及在讲话者建模中过拟合。在这项工作中，我们提出了一种混合连续属性网络（HCAN），以情感延续和情感归属的视角解决这些问题。具体而言，HCAN采用混合循环和基于注意力的模块来建模全局情感连续性。然后，提出了一种新颖的情感归属编码（EAE）来对每个话语的内部和交叉情感归属进行建模。此外，为了增强模型在说话者建模方面的稳健性，并提高在不同情景下的性能，引入了一个综合的损失函数情感认知损失´EC。",
    "tldr": "本文提出了一种用于情感识别的混合连续归属网络，解决了在对话中情感的延续和归属的问题，并改善了模型在不同情景中的表现。"
}