{
    "title": "EFFL: Egalitarian Fairness in Federated Learning for Mitigating Matthew Effect. (arXiv:2309.16338v1 [cs.LG])",
    "abstract": "Recent advances in federated learning (FL) enable collaborative training of machine learning (ML) models from large-scale and widely dispersed clients while protecting their privacy. However, when different clients' datasets are heterogeneous, traditional FL mechanisms produce a global model that does not adequately represent the poorer clients with limited data resources, resulting in lower accuracy and higher bias on their local data. According to the Matthew effect, which describes how the advantaged gain more advantage and the disadvantaged lose more over time, deploying such a global model in client applications may worsen the resource disparity among the clients and harm the principles of social welfare and fairness. To mitigate the Matthew effect, we propose Egalitarian Fairness Federated Learning (EFFL), where egalitarian fairness refers to the global model learned from FL has: (1) equal accuracy among clients; (2) equal decision bias among clients. Besides achieving egalitaria",
    "link": "http://arxiv.org/abs/2309.16338",
    "context": "Title: EFFL: Egalitarian Fairness in Federated Learning for Mitigating Matthew Effect. (arXiv:2309.16338v1 [cs.LG])\nAbstract: Recent advances in federated learning (FL) enable collaborative training of machine learning (ML) models from large-scale and widely dispersed clients while protecting their privacy. However, when different clients' datasets are heterogeneous, traditional FL mechanisms produce a global model that does not adequately represent the poorer clients with limited data resources, resulting in lower accuracy and higher bias on their local data. According to the Matthew effect, which describes how the advantaged gain more advantage and the disadvantaged lose more over time, deploying such a global model in client applications may worsen the resource disparity among the clients and harm the principles of social welfare and fairness. To mitigate the Matthew effect, we propose Egalitarian Fairness Federated Learning (EFFL), where egalitarian fairness refers to the global model learned from FL has: (1) equal accuracy among clients; (2) equal decision bias among clients. Besides achieving egalitaria",
    "path": "papers/23/09/2309.16338.json",
    "total_tokens": 883,
    "translated_title": "EFFL: 在联邦学习中实现均等公平性以减轻马太效应",
    "translated_abstract": "最近在联邦学习（FL）方面取得的进展使得可以保护用户隐私的同时，从大规模和广泛分散的客户端进行机器学习（ML）模型的协作训练成为可能。然而，当不同客户端的数据集异构时，传统的FL机制产生的全局模型不能充分代表拥有有限数据资源的较贫困客户端，在其本地数据上导致较低的准确性和更高的偏见。根据马太效应的描述，即优势者获得更多优势，劣势者随着时间的推移失去更多，将这样的全局模型部署在客户端应用中可能加剧客户之间的资源差距，并损害社会福利和公平的原则。为了减轻马太效应，我们提出了均等公平联邦学习（EFFL），其中均等公平性指的是从FL学习到的全局模型具有以下特点：（1）客户端之间的准确性相等；（2）客户端之间的决策偏见相等。",
    "tldr": "EFFL是一种在联邦学习中实现均等公平性以减轻马太效应的方法，通过确保全局模型具有均等的准确性和决策偏见来减少客户端之间的资源差距。"
}