{
    "title": "Do PLMs Know and Understand Ontological Knowledge?. (arXiv:2309.05936v1 [cs.CL])",
    "abstract": "Ontological knowledge, which comprises classes and properties and their relationships, is integral to world knowledge. It is significant to explore whether Pretrained Language Models (PLMs) know and understand such knowledge. However, existing PLM-probing studies focus mainly on factual knowledge, lacking a systematic probing of ontological knowledge. In this paper, we focus on probing whether PLMs store ontological knowledge and have a semantic understanding of the knowledge rather than rote memorization of the surface form. To probe whether PLMs know ontological knowledge, we investigate how well PLMs memorize: (1) types of entities; (2) hierarchical relationships among classes and properties, e.g., Person is a subclass of Animal and Member of Sports Team is a subproperty of Member of ; (3) domain and range constraints of properties, e.g., the subject of Member of Sports Team should be a Person and the object should be a Sports Team. To further probe whether PLMs truly understand ont",
    "link": "http://arxiv.org/abs/2309.05936",
    "context": "Title: Do PLMs Know and Understand Ontological Knowledge?. (arXiv:2309.05936v1 [cs.CL])\nAbstract: Ontological knowledge, which comprises classes and properties and their relationships, is integral to world knowledge. It is significant to explore whether Pretrained Language Models (PLMs) know and understand such knowledge. However, existing PLM-probing studies focus mainly on factual knowledge, lacking a systematic probing of ontological knowledge. In this paper, we focus on probing whether PLMs store ontological knowledge and have a semantic understanding of the knowledge rather than rote memorization of the surface form. To probe whether PLMs know ontological knowledge, we investigate how well PLMs memorize: (1) types of entities; (2) hierarchical relationships among classes and properties, e.g., Person is a subclass of Animal and Member of Sports Team is a subproperty of Member of ; (3) domain and range constraints of properties, e.g., the subject of Member of Sports Team should be a Person and the object should be a Sports Team. To further probe whether PLMs truly understand ont",
    "path": "papers/23/09/2309.05936.json",
    "total_tokens": 884,
    "translated_title": "PLMs是否知道和理解本体知识？",
    "translated_abstract": "本体知识是世界知识的重要组成部分，包括类和属性以及它们之间的关系。探索预训练语言模型（PLMs）是否知道和理解这样的知识具有重要意义。然而，现有的PLM探测研究主要关注事实知识，缺乏对本体知识的系统探测。本文旨在探究PLMs是否存储本体知识，并对其具有语义理解而不是对表面形式的死记硬背。为了探测PLMs是否了解本体知识，我们研究了PLMs对以下方面的记忆情况：（1）实体类型；（2）类和属性之间的层次关系，例如，人是动物的子类，参与团队的成员是成员的子属性；（3）属性的域和范围约束，例如，参与团队的成员的主语应是人，宾语应是一个运动队。",
    "tldr": "本文研究了预训练语言模型（PLMs）对本体知识的存储和语义理解能力，以及其对实体类型、类和属性之间的层次关系，以及属性的域和范围约束的记忆情况。",
    "en_tdlr": "This paper investigates whether Pretrained Language Models (PLMs) store and have a semantic understanding of ontological knowledge. It explores their memory of entity types, hierarchical relationships among classes and properties, and domain and range constraints of properties."
}