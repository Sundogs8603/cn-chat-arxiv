{
    "title": "Examining the Values Reflected by Children during AI Problem Formulation. (arXiv:2309.15839v1 [cs.HC])",
    "abstract": "Understanding how children design and what they value in AI interfaces that allow them to explicitly train their models such as teachable machines, could help increase such activities' impact and guide the design of future technologies. In a co-design session using a modified storyboard, a team of 5 children (aged 7-13 years) and adult co-designers, engaged in AI problem formulation activities where they imagine their own teachable machines. Our findings, leveraging an established psychological value framework (the Rokeach Value Survey), illuminate how children conceptualize and embed their values in AI systems that they themselves devise to support their everyday activities. Specifically, we find that children's proposed ideas require advanced system intelligence, e.g. emotion detection and understanding the social relationships of a user. The underlying models could be trained under multiple modalities and any errors would be fixed by adding more data or by anticipating negative exam",
    "link": "http://arxiv.org/abs/2309.15839",
    "context": "Title: Examining the Values Reflected by Children during AI Problem Formulation. (arXiv:2309.15839v1 [cs.HC])\nAbstract: Understanding how children design and what they value in AI interfaces that allow them to explicitly train their models such as teachable machines, could help increase such activities' impact and guide the design of future technologies. In a co-design session using a modified storyboard, a team of 5 children (aged 7-13 years) and adult co-designers, engaged in AI problem formulation activities where they imagine their own teachable machines. Our findings, leveraging an established psychological value framework (the Rokeach Value Survey), illuminate how children conceptualize and embed their values in AI systems that they themselves devise to support their everyday activities. Specifically, we find that children's proposed ideas require advanced system intelligence, e.g. emotion detection and understanding the social relationships of a user. The underlying models could be trained under multiple modalities and any errors would be fixed by adding more data or by anticipating negative exam",
    "path": "papers/23/09/2309.15839.json",
    "total_tokens": 885,
    "translated_title": "检视儿童在AI问题构思中体现的价值观",
    "translated_abstract": "了解儿童在诸如可教授机器等AI界面设计中的设计过程和价值观，有助于增加这些活动的影响力，并指导未来技术的设计。通过一个改编的故事板设计会话，一个由5名年龄在7-13岁的儿童和成人共同设计者组成的团队，参与了AI问题构思活动，他们想象了自己的可教授机器。我们的研究结果利用了一个已经建立的心理价值框架（Rokeach价值调查）, 揭示了儿童如何在他们自己设计的AI系统中概念化和融入他们的价值观，以支持他们的日常活动。具体来说，我们发现儿童提出的想法需要先进的系统智能，例如情感检测和理解用户的社交关系。底层模型可以在多种模式下进行训练，通过添加更多数据或预测负面事件来修复任何错误。",
    "tldr": "研究通过观察儿童在AI问题构思中的活动，揭示了儿童如何向自己设计的AI系统中融入价值观，为日常活动提供支持，包括对高级系统智能的需求和对情感检测的需求。",
    "en_tdlr": "This study examines how children incorporate their values into AI systems that they design, to support their everyday activities, including the need for advanced system intelligence and emotion detection."
}