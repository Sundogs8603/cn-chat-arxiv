{
    "title": "Sensitivity Analysis for Linear Estimands. (arXiv:2309.06305v1 [econ.EM])",
    "abstract": "We propose a novel sensitivity analysis framework for linear estimands when identification failure can be viewed as seeing the wrong distribution of outcomes. Our family of assumptions bounds the density ratio between the observed and true conditional outcome distribution. This framework links naturally to selection models, generalizes existing assumptions for the Regression Discontinuity (RD) and Inverse Propensity Weighting (IPW) estimand, and provides a novel nonparametric perspective on violations of identification assumptions for ordinary least squares (OLS). Our sharp partial identification results extend existing results for IPW to cover other estimands and assumptions that allow even unbounded likelihood ratios, yielding a simple and unified characterization of bounds under assumptions like c-dependence of Masten and Poirier (2018). The sharp bounds can be written as a simple closed form moment of the data, the nuisance functions estimated in the primary analysis, and the condi",
    "link": "http://arxiv.org/abs/2309.06305",
    "context": "Title: Sensitivity Analysis for Linear Estimands. (arXiv:2309.06305v1 [econ.EM])\nAbstract: We propose a novel sensitivity analysis framework for linear estimands when identification failure can be viewed as seeing the wrong distribution of outcomes. Our family of assumptions bounds the density ratio between the observed and true conditional outcome distribution. This framework links naturally to selection models, generalizes existing assumptions for the Regression Discontinuity (RD) and Inverse Propensity Weighting (IPW) estimand, and provides a novel nonparametric perspective on violations of identification assumptions for ordinary least squares (OLS). Our sharp partial identification results extend existing results for IPW to cover other estimands and assumptions that allow even unbounded likelihood ratios, yielding a simple and unified characterization of bounds under assumptions like c-dependence of Masten and Poirier (2018). The sharp bounds can be written as a simple closed form moment of the data, the nuisance functions estimated in the primary analysis, and the condi",
    "path": "papers/23/09/2309.06305.json",
    "total_tokens": 832,
    "translated_title": "线性估计的敏感性分析",
    "translated_abstract": "我们提出了一个新的线性估计的敏感性分析框架，当鉴别失败可以被看作是看到了错误的结果分布时。我们的假设族限定了观察到的和真实条件结果分布之间的密度比。这个框架自然地与选择模型相关联，推广了回归不连续性（RD）和倒数概率加权度量（IPW）的现有假设，并针对普通最小二乘法（OLS）的鉴别假设违反提供了一种新的非参数视角。我们的尖锐部分鉴别结果将现有的IPW结果推广到其他估计和允许无界似然比的假设，从而在像Masten和Poirier（2018年）的c依赖性假设下提供了简单而统一的边界特征。尖锐边界可以写成数据的简单闭合形式矩、在主要分析中估计的无关函数和条件函数的乘积。",
    "tldr": "提出了一个新的线性估计的敏感性分析框架，可以处理鉴别失败和假设违反的问题，并给出了相应的尖锐边界特征。",
    "en_tdlr": "A novel sensitivity analysis framework is proposed for linear estimands to handle identification failure and assumption violations, providing sharp bounds and a nonparametric perspective."
}