{
    "title": "Kosmos-2.5: A Multimodal Literate Model. (arXiv:2309.11419v1 [cs.CL])",
    "abstract": "We present Kosmos-2.5, a multimodal literate model for machine reading of text-intensive images. Pre-trained on large-scale text-intensive images, Kosmos-2.5 excels in two distinct yet cooperative transcription tasks: (1) generating spatially-aware text blocks, where each block of text is assigned its spatial coordinates within the image, and (2) producing structured text output that captures styles and structures into the markdown format. This unified multimodal literate capability is achieved through a shared Transformer architecture, task-specific prompts, and flexible text representations. We evaluate Kosmos-2.5 on end-to-end document-level text recognition and image-to-markdown text generation. Furthermore, the model can be readily adapted for any text-intensive image understanding task with different prompts through supervised fine-tuning, making it a general-purpose tool for real-world applications involving text-rich images. This work also paves the way for the future scaling o",
    "link": "http://arxiv.org/abs/2309.11419",
    "context": "Title: Kosmos-2.5: A Multimodal Literate Model. (arXiv:2309.11419v1 [cs.CL])\nAbstract: We present Kosmos-2.5, a multimodal literate model for machine reading of text-intensive images. Pre-trained on large-scale text-intensive images, Kosmos-2.5 excels in two distinct yet cooperative transcription tasks: (1) generating spatially-aware text blocks, where each block of text is assigned its spatial coordinates within the image, and (2) producing structured text output that captures styles and structures into the markdown format. This unified multimodal literate capability is achieved through a shared Transformer architecture, task-specific prompts, and flexible text representations. We evaluate Kosmos-2.5 on end-to-end document-level text recognition and image-to-markdown text generation. Furthermore, the model can be readily adapted for any text-intensive image understanding task with different prompts through supervised fine-tuning, making it a general-purpose tool for real-world applications involving text-rich images. This work also paves the way for the future scaling o",
    "path": "papers/23/09/2309.11419.json",
    "total_tokens": 931,
    "translated_title": "Kosmos-2.5: 一个多模态文学模型",
    "translated_abstract": "我们介绍了Kosmos-2.5，一个用于对文本密集型图像进行机器阅读的多模态文学模型。Kosmos-2.5在两个不同但相互合作的转录任务中表现出色：(1) 生成具有空间感的文本块，其中每个文本块都被赋予其在图像中的空间坐标，以及(2) 生成以Markdown格式捕捉样式和结构的结构化文本输出。这种统一的多模态文学能力是通过共享的Transformer架构、任务特定的提示和灵活的文本表示实现的。我们在端到端的文档级文本识别和图像到Markdown文本生成上评估了Kosmos-2.5。此外，该模型可以通过监督微调轻松适应具有不同提示的任何文本密集型图像理解任务，使其成为涉及文本丰富图像的实际应用的通用工具。这项工作还为未来的扩展铺平了道路。",
    "tldr": "Kosmos-2.5是一个多模态文学模型，能够在机器阅读文本密集型图像方面表现出色，并能够生成具有空间感的文本块和结构化文本输出。该模型具有通用性，可以适应不同提示下任何文本密集型图像理解任务，并为未来的扩展提供了方向。",
    "en_tdlr": "Kosmos-2.5 is a multimodal literate model that excels in machine reading of text-intensive images and generates spatially-aware text blocks and structured text output. The model is versatile and can be adapted for any text-intensive image understanding task with different prompts, paving the way for future scaling."
}