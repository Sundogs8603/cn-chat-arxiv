{
    "title": "Containing Analog Data Deluge at Edge through Frequency-Domain Compression in Collaborative Compute-in-Memory Networks. (arXiv:2309.11048v1 [cs.LG])",
    "abstract": "Edge computing is a promising solution for handling high-dimensional, multispectral analog data from sensors and IoT devices for applications such as autonomous drones. However, edge devices' limited storage and computing resources make it challenging to perform complex predictive modeling at the edge. Compute-in-memory (CiM) has emerged as a principal paradigm to minimize energy for deep learning-based inference at the edge. Nevertheless, integrating storage and processing complicates memory cells and/or memory peripherals, essentially trading off area efficiency for energy efficiency. This paper proposes a novel solution to improve area efficiency in deep learning inference tasks. The proposed method employs two key strategies. Firstly, a Frequency domain learning approach uses binarized Walsh-Hadamard Transforms, reducing the necessary parameters for DNN (by 87% in MobileNetV2) and enabling compute-in-SRAM, which better utilizes parallelism during inference. Secondly, a memory-immer",
    "link": "http://arxiv.org/abs/2309.11048",
    "context": "Title: Containing Analog Data Deluge at Edge through Frequency-Domain Compression in Collaborative Compute-in-Memory Networks. (arXiv:2309.11048v1 [cs.LG])\nAbstract: Edge computing is a promising solution for handling high-dimensional, multispectral analog data from sensors and IoT devices for applications such as autonomous drones. However, edge devices' limited storage and computing resources make it challenging to perform complex predictive modeling at the edge. Compute-in-memory (CiM) has emerged as a principal paradigm to minimize energy for deep learning-based inference at the edge. Nevertheless, integrating storage and processing complicates memory cells and/or memory peripherals, essentially trading off area efficiency for energy efficiency. This paper proposes a novel solution to improve area efficiency in deep learning inference tasks. The proposed method employs two key strategies. Firstly, a Frequency domain learning approach uses binarized Walsh-Hadamard Transforms, reducing the necessary parameters for DNN (by 87% in MobileNetV2) and enabling compute-in-SRAM, which better utilizes parallelism during inference. Secondly, a memory-immer",
    "path": "papers/23/09/2309.11048.json",
    "total_tokens": 927,
    "translated_title": "在协作的内存计算网络中，通过频域压缩来控制边缘的模拟数据洪水",
    "translated_abstract": "边缘计算是处理来自传感器和物联网设备的高维、多光谱模拟数据的一种有希望的解决方案，用于自主无人机等应用。然而，边缘设备的有限存储和计算资源使得在边缘进行复杂的预测建模成为一项挑战。内存计算已经成为一种主要范式，用于在边缘的基于深度学习的推理中最小化能量消耗。然而，集成存储和处理在存储单元和/或存储外设上变得复杂，从根本上在面积效率和能量效率之间进行权衡。本文提出了一种改进深度学习推理任务中面积效率的新方法。所提出的方法采用两种关键策略。首先，频域学习方法使用二值化的Walsh-Hadamard变换，减少了DNN的必要参数（在MobileNetV2中减少了87%），并实现了在SRAM上进行计算，从而更好地利用推理过程中的并行性。其次，一种内存相互融合机制。",
    "tldr": "本文提出了一种在边缘进行高效深度学习推理的解决方案，通过频域压缩和内存相互融合机制，实现了更高的面积效率和能量效率。"
}