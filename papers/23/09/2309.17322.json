{
    "title": "Assessing Look-Ahead Bias in Stock Return Predictions Generated By GPT Sentiment Analysis. (arXiv:2309.17322v1 [q-fin.GN])",
    "abstract": "Large language models (LLMs), including ChatGPT, can extract profitable trading signals from the sentiment in news text. However, backtesting such strategies poses a challenge because LLMs are trained on many years of data, and backtesting produces biased results if the training and backtesting periods overlap. This bias can take two forms: a look-ahead bias, in which the LLM may have specific knowledge of the stock returns that followed a news article, and a distraction effect, in which general knowledge of the companies named interferes with the measurement of a text's sentiment. We investigate these sources of bias through trading strategies driven by the sentiment of financial news headlines. We compare trading performance based on the original headlines with de-biased strategies in which we remove the relevant company's identifiers from the text. In-sample (within the LLM training window), we find, surprisingly, that the anonymized headlines outperform, indicating that the distrac",
    "link": "http://arxiv.org/abs/2309.17322",
    "context": "Title: Assessing Look-Ahead Bias in Stock Return Predictions Generated By GPT Sentiment Analysis. (arXiv:2309.17322v1 [q-fin.GN])\nAbstract: Large language models (LLMs), including ChatGPT, can extract profitable trading signals from the sentiment in news text. However, backtesting such strategies poses a challenge because LLMs are trained on many years of data, and backtesting produces biased results if the training and backtesting periods overlap. This bias can take two forms: a look-ahead bias, in which the LLM may have specific knowledge of the stock returns that followed a news article, and a distraction effect, in which general knowledge of the companies named interferes with the measurement of a text's sentiment. We investigate these sources of bias through trading strategies driven by the sentiment of financial news headlines. We compare trading performance based on the original headlines with de-biased strategies in which we remove the relevant company's identifiers from the text. In-sample (within the LLM training window), we find, surprisingly, that the anonymized headlines outperform, indicating that the distrac",
    "path": "papers/23/09/2309.17322.json",
    "total_tokens": 963,
    "translated_title": "通过GPT情感分析评估股票回报预测中的前瞻性偏差",
    "translated_abstract": "大型语言模型（LLMs），包括ChatGPT，可以从新闻文本的情绪中提取有益的交易信号。然而，对这些策略进行回溯测试是一项挑战，因为LLMs是在多年的数据上进行训练的，如果训练和回溯测试期间重叠，回溯测试将产生偏倚的结果。这种偏差可以有两种形式：一种是前瞻性偏差，即LLM可能具有关于新闻文章之后的股票回报的具体知识；另一种是干扰效应，即所述公司的一般知识干扰了文本情感的测量。我们通过基于财经新闻标题情感的交易策略来调查这些偏差来源。我们将基于原始标题的交易绩效与去除相关公司标识符的去偏策略进行比较。令人惊讶的是，在样本内（LLM训练窗口内），我们发现匿名化标题的绩效优于原始标题，这表明干扰效应的存在。",
    "tldr": "本研究通过基于GPT情感分析的财经新闻标题的交易策略，评估了股票回报预测中的前瞻性偏差。研究发现，在去除相关公司标识符的去偏策略下，匿名化的标题表现出更好的交易绩效。",
    "en_tdlr": "This study assesses the look-ahead bias in stock return predictions generated by GPT sentiment analysis. By comparing trading performance based on original headlines with de-biased strategies, the study finds that anonymized headlines perform better, indicating the presence of a distraction effect."
}