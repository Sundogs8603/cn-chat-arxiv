{
    "title": "Towards LLM-based Autograding for Short Textual Answers. (arXiv:2309.11508v1 [cs.CL])",
    "abstract": "Grading of exams is an important, labor intensive, subjective, repetitive and frequently challenging task. The feasibility of autograding textual responses has greatly increased thanks to the availability of large language models (LLMs) such as ChatGPT and because of the substantial influx of data brought about by digitalization. However, entrusting AI models with decision-making roles raises ethical considerations, mainly stemming from potential biases and issues related to generating false information. Thus, in this manuscript we provide an evaluation of a large language model for the purpose of autograding, while also highlighting how LLMs can support educators in validating their grading procedures. Our evaluation is targeted towards automatic short textual answers grading (ASAG), spanning various languages and examinations from two distinct courses. Our findings suggest that while \"out-of-the-box\" LLMs provide a valuable tool to provide a complementary perspective, their readiness",
    "link": "http://arxiv.org/abs/2309.11508",
    "context": "Title: Towards LLM-based Autograding for Short Textual Answers. (arXiv:2309.11508v1 [cs.CL])\nAbstract: Grading of exams is an important, labor intensive, subjective, repetitive and frequently challenging task. The feasibility of autograding textual responses has greatly increased thanks to the availability of large language models (LLMs) such as ChatGPT and because of the substantial influx of data brought about by digitalization. However, entrusting AI models with decision-making roles raises ethical considerations, mainly stemming from potential biases and issues related to generating false information. Thus, in this manuscript we provide an evaluation of a large language model for the purpose of autograding, while also highlighting how LLMs can support educators in validating their grading procedures. Our evaluation is targeted towards automatic short textual answers grading (ASAG), spanning various languages and examinations from two distinct courses. Our findings suggest that while \"out-of-the-box\" LLMs provide a valuable tool to provide a complementary perspective, their readiness",
    "path": "papers/23/09/2309.11508.json",
    "total_tokens": 917,
    "translated_title": "基于LLM的短文本答案自动评分方法研究",
    "translated_abstract": "考试的评分是一项重要的、劳动密集的、主观的、重复的且常常具有挑战性的任务。大型语言模型（LLMs）如ChatGPT的可用性和数字化带来的大量数据的涌入， greatly increased autograding textual responses的可行性。然而，将决策角色交给AI模型引起了伦理考虑，主要源于潜在偏见和生成虚假信息的问题。因此，在本文中，我们评估了一个大型语言模型用于自动评分，同时强调了LLMs如何支持教育工作者验证其评分程序。我们的评估针对自动短文本答案评分（ASAG），涵盖了两个不同课程的各种语言和考试。我们的研究结果表明，“开箱即用”的LLMs提供了一个有价值的工具，可以提供补充的视角，但它们的可用性和性能在实际应用中还需进一步优化。",
    "tldr": "本文评估了大型语言模型（LLMs）在自动评分中的应用，并强调了它们如何支持教育工作者验证评分程序。研究结果表明，“开箱即用”的LLMs作为补充视角提供了有价值的工具，但仍需进一步优化其可用性和性能。",
    "en_tdlr": "This paper evaluates the application of large language models (LLMs) in autograding and highlights how they support educators in validating grading procedures. The findings suggest that \"out-of-the-box\" LLMs provide a valuable tool as a complementary perspective, but their usability and performance still need further optimization."
}