{
    "title": "Investigating Subtler Biases in LLMs: Ageism, Beauty, Institutional, and Nationality Bias in Generative Models. (arXiv:2309.08902v1 [cs.CL])",
    "abstract": "LLMs are increasingly powerful and widely used to assist users in a variety of tasks. This use risks the introduction of LLM biases to consequential decisions such as job hiring, human performance evaluation, and criminal sentencing. Bias in NLP systems along the lines of gender and ethnicity has been widely studied, especially for specific stereotypes (e.g., Asians are good at math). In this paper, we investigate bias along less studied, but still consequential, dimensions, such as age and beauty, measuring subtler correlated decisions that LLMs (specially autoregressive language models) make between social groups and unrelated positive and negative attributes. We ask whether LLMs hold wide-reaching biases of positive or negative sentiment for specific social groups similar to the ``what is beautiful is good'' bias found in people in experimental psychology. We introduce a template-generated dataset of sentence completion tasks that asks the model to select the most appropriate attrib",
    "link": "http://arxiv.org/abs/2309.08902",
    "context": "Title: Investigating Subtler Biases in LLMs: Ageism, Beauty, Institutional, and Nationality Bias in Generative Models. (arXiv:2309.08902v1 [cs.CL])\nAbstract: LLMs are increasingly powerful and widely used to assist users in a variety of tasks. This use risks the introduction of LLM biases to consequential decisions such as job hiring, human performance evaluation, and criminal sentencing. Bias in NLP systems along the lines of gender and ethnicity has been widely studied, especially for specific stereotypes (e.g., Asians are good at math). In this paper, we investigate bias along less studied, but still consequential, dimensions, such as age and beauty, measuring subtler correlated decisions that LLMs (specially autoregressive language models) make between social groups and unrelated positive and negative attributes. We ask whether LLMs hold wide-reaching biases of positive or negative sentiment for specific social groups similar to the ``what is beautiful is good'' bias found in people in experimental psychology. We introduce a template-generated dataset of sentence completion tasks that asks the model to select the most appropriate attrib",
    "path": "papers/23/09/2309.08902.json",
    "total_tokens": 1019,
    "translated_title": "调查LLMs中更微妙的偏见：生成模型中的年龄主义、美丽、机构和国籍偏见",
    "translated_abstract": "LLMs越来越强大并广泛用于辅助用户完成各种任务。这种使用可能会将LLM偏见引入到重要决策中，如招聘、人员绩效评估和刑事判决。在NLP系统中的性别和种族等方面的偏见已得到广泛研究，尤其是针对特定刻板印象的偏见（例如，亚洲人擅长数学）。在本文中，我们研究了一些较少研究但仍然重要的维度上的偏见，如年龄和美丽，在LLMs（特别是自回归语言模型）在社会群体和不相关的正负属性之间做出更微妙的相关决策。我们问LLMs是否对特定社会群体持有广泛的正面或负面态度的偏见，类似于实验心理学中人们发现的“美丽即善”的偏见。我们引入了一个模板生成的句子完成任务的数据集，要求模型选择最合适的属性。",
    "tldr": "本文调查了LLMs在年龄、美丽、机构和国籍等少研究但仍然重要的维度上的偏见，通过衡量在社会群体和不相关的正负属性之间做出的微妙相关决策。研究发现LLMs在特定社会群体上存在类似于“美丽即善”的广泛正面或负面态度的偏见。"
}