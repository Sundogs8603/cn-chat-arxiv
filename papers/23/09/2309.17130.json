{
    "title": "GRANDE: Gradient-Based Decision Tree Ensembles. (arXiv:2309.17130v1 [cs.LG])",
    "abstract": "Despite the success of deep learning for text and image data, tree-based ensemble models are still state-of-the-art for machine learning with heterogeneous tabular data. However, there is a significant need for tabular-specific gradient-based methods due to their high flexibility. In this paper, we propose $\\text{GRANDE}$, $\\text{GRA}$die$\\text{N}$t-Based $\\text{D}$ecision Tree $\\text{E}$nsembles, a novel approach for learning hard, axis-aligned decision tree ensembles using end-to-end gradient descent. GRANDE is based on a dense representation of tree ensembles, which affords to use backpropagation with a straight-through operator to jointly optimize all model parameters. Our method combines axis-aligned splits, which is a useful inductive bias for tabular data, with the flexibility of gradient-based optimization. Furthermore, we introduce an advanced instance-wise weighting that facilitates learning representations for both, simple and complex relations, within a single model. We con",
    "link": "http://arxiv.org/abs/2309.17130",
    "context": "Title: GRANDE: Gradient-Based Decision Tree Ensembles. (arXiv:2309.17130v1 [cs.LG])\nAbstract: Despite the success of deep learning for text and image data, tree-based ensemble models are still state-of-the-art for machine learning with heterogeneous tabular data. However, there is a significant need for tabular-specific gradient-based methods due to their high flexibility. In this paper, we propose $\\text{GRANDE}$, $\\text{GRA}$die$\\text{N}$t-Based $\\text{D}$ecision Tree $\\text{E}$nsembles, a novel approach for learning hard, axis-aligned decision tree ensembles using end-to-end gradient descent. GRANDE is based on a dense representation of tree ensembles, which affords to use backpropagation with a straight-through operator to jointly optimize all model parameters. Our method combines axis-aligned splits, which is a useful inductive bias for tabular data, with the flexibility of gradient-based optimization. Furthermore, we introduce an advanced instance-wise weighting that facilitates learning representations for both, simple and complex relations, within a single model. We con",
    "path": "papers/23/09/2309.17130.json",
    "total_tokens": 1016,
    "translated_title": "GRANDE: 基于梯度的决策树集成模型",
    "translated_abstract": "尽管深度学习在文本和图像数据方面取得了成功，但基于树的集成模型仍然是处理异构表格数据的机器学习的最先进方法。然而，由于其高灵活性，对于表格数据来说，存在对特定于表格的梯度方法的显著需求。在本文中，我们提出了一种名为GRANDE的新方法，即基于梯度的决策树集成模型，通过端到端梯度下降学习坚硬、轴对齐的决策树集成。GRANDE基于决策树集成的稠密表示，可以使用直通操作符和反向传播一起优化所有模型参数。我们的方法结合了轴对齐分割（这是表格数据的一个有用的归纳偏置）和梯度优化的灵活性。此外，我们引入了一种先进的逐个实例加权方法，可以在一个模型中便于学习简单和复杂关系的表示。我们在广泛的实验数据集上评估了GRANDE的性能，并与其他方法进行了比较。",
    "tldr": "这篇论文提出了一种名为GRANDE的基于梯度的决策树集成模型，通过端到端梯度下降学习坚硬、轴对齐的决策树集成，并结合了轴对齐分割和梯度优化的灵活性，引入了一种先进的逐个实例加权方法，可以在一个模型中便于学习简单和复杂关系的表示。",
    "en_tdlr": "This paper presents a gradient-based decision tree ensemble model called GRANDE, which learns hard, axis-aligned decision trees using end-to-end gradient descent. The model combines axis-aligned splits and gradient optimization, and introduces an advanced instance-wise weighting method to facilitate learning representations for both simple and complex relations within a single model."
}