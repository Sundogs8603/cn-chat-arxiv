{
    "title": "Refined Temporal Pyramidal Compression-and-Amplification Transformer for 3D Human Pose Estimation. (arXiv:2309.01365v2 [cs.CV] UPDATED)",
    "abstract": "Accurately estimating the 3D pose of humans in video sequences requires both accuracy and a well-structured architecture. With the success of transformers, we introduce the Refined Temporal Pyramidal Compression-and-Amplification (RTPCA) transformer. Exploiting the temporal dimension, RTPCA extends intra-block temporal modeling via its Temporal Pyramidal Compression-and-Amplification (TPCA) structure and refines inter-block feature interaction with a Cross-Layer Refinement (XLR) module. In particular, TPCA block exploits a temporal pyramid paradigm, reinforcing key and value representation capabilities and seamlessly extracting spatial semantics from motion sequences. We stitch these TPCA blocks with XLR that promotes rich semantic representation through continuous interaction of queries, keys, and values. This strategy embodies early-stage information with current flows, addressing typical deficits in detail and stability seen in other transformer-based methods. We demonstrate the eff",
    "link": "http://arxiv.org/abs/2309.01365",
    "context": "Title: Refined Temporal Pyramidal Compression-and-Amplification Transformer for 3D Human Pose Estimation. (arXiv:2309.01365v2 [cs.CV] UPDATED)\nAbstract: Accurately estimating the 3D pose of humans in video sequences requires both accuracy and a well-structured architecture. With the success of transformers, we introduce the Refined Temporal Pyramidal Compression-and-Amplification (RTPCA) transformer. Exploiting the temporal dimension, RTPCA extends intra-block temporal modeling via its Temporal Pyramidal Compression-and-Amplification (TPCA) structure and refines inter-block feature interaction with a Cross-Layer Refinement (XLR) module. In particular, TPCA block exploits a temporal pyramid paradigm, reinforcing key and value representation capabilities and seamlessly extracting spatial semantics from motion sequences. We stitch these TPCA blocks with XLR that promotes rich semantic representation through continuous interaction of queries, keys, and values. This strategy embodies early-stage information with current flows, addressing typical deficits in detail and stability seen in other transformer-based methods. We demonstrate the eff",
    "path": "papers/23/09/2309.01365.json",
    "total_tokens": 939,
    "translated_title": "优化的时间金字塔压缩和放大变换器用于3D人体姿势估计",
    "translated_abstract": "在视频序列中准确估计人体的3D姿势需要准确性和良好的结构化架构。基于transformer的成功，我们引入了优化的时间金字塔压缩和放大（RTPCA）变换器。RTPCA通过其时间金字塔压缩和放大（TPCA）结构扩展了块内时间建模，并通过交叉层细化（XLR）模块细化块间特征交互。特别地，TPCA块利用时间金字塔范例，增强关键和值表示能力，并从运动序列中无缝提取空间语义。我们将这些TPCA块与XLR连接起来，通过连续的查询、关键字和值的相互作用促进丰富的语义表示。这种策略通过当前流程体现了早期信息，解决了其他基于Transformer方法中常见的细节和稳定性不足。我们展示了改进后的模型在3D人体姿势估计上的效果。",
    "tldr": "通过优化的时间金字塔压缩和放大变换器，该论文提出了一种在视频序列中准确估计人体3D姿势的方法。该方法通过扩展时间建模和细化特征交互来解决其他方法中的细节和稳定性问题，展示了较好的效果。",
    "en_tdlr": "This paper introduces the Refined Temporal Pyramidal Compression-and-Amplification (RTPCA) transformer for accurately estimating 3D human pose in video sequences. By extending temporal modeling and refining feature interaction, the proposed method addresses issues related to detail and stability, demonstrating improved performance."
}