{
    "title": "Parallel Multi-Objective Hyperparameter Optimization with Uniform Normalization and Bounded Objectives. (arXiv:2309.14936v1 [cs.LG])",
    "abstract": "Machine learning (ML) methods offer a wide range of configurable hyperparameters that have a significant influence on their performance. While accuracy is a commonly used performance objective, in many settings, it is not sufficient. Optimizing the ML models with respect to multiple objectives such as accuracy, confidence, fairness, calibration, privacy, latency, and memory consumption is becoming crucial. To that end, hyperparameter optimization, the approach to systematically optimize the hyperparameters, which is already challenging for a single objective, is even more challenging for multiple objectives. In addition, the differences in objective scales, the failures, and the presence of outlier values in objectives make the problem even harder. We propose a multi-objective Bayesian optimization (MoBO) algorithm that addresses these problems through uniform objective normalization and randomized weights in scalarization. We increase the efficiency of our approach by imposing constra",
    "link": "http://arxiv.org/abs/2309.14936",
    "context": "Title: Parallel Multi-Objective Hyperparameter Optimization with Uniform Normalization and Bounded Objectives. (arXiv:2309.14936v1 [cs.LG])\nAbstract: Machine learning (ML) methods offer a wide range of configurable hyperparameters that have a significant influence on their performance. While accuracy is a commonly used performance objective, in many settings, it is not sufficient. Optimizing the ML models with respect to multiple objectives such as accuracy, confidence, fairness, calibration, privacy, latency, and memory consumption is becoming crucial. To that end, hyperparameter optimization, the approach to systematically optimize the hyperparameters, which is already challenging for a single objective, is even more challenging for multiple objectives. In addition, the differences in objective scales, the failures, and the presence of outlier values in objectives make the problem even harder. We propose a multi-objective Bayesian optimization (MoBO) algorithm that addresses these problems through uniform objective normalization and randomized weights in scalarization. We increase the efficiency of our approach by imposing constra",
    "path": "papers/23/09/2309.14936.json",
    "total_tokens": 847,
    "translated_title": "平行多目标超参数优化与统一归一化与有界目标",
    "translated_abstract": "机器学习方法提供了一系列可配置的超参数，这些超参数对于性能有着重要影响。尽管准确度是一个常用的性能目标，但在许多情况下，仅准确度是不足够的。在许多设置下，优化机器学习模型与准确度、置信度、公平性、校准、隐私、延迟和内存消耗等多个目标对其至关重要。为了解决这个问题，超参数优化，即系统地优化超参数的方法，对于单一目标已经很具挑战性了，对于多个目标则更加困难。此外，目标尺度的差异、失败和异常值的存在使问题更加困难。我们提出了一种多目标贝叶斯优化(MoBO)算法，通过统一目标归一化和随机化权重进行标量化，来解决这些问题。我们通过施加约束来提高我们方法的效率。",
    "tldr": "这项研究提出了一种多目标贝叶斯优化算法，通过统一目标归一化和随机化权重进行标量化，解决了多目标超参数优化中的挑战问题。"
}