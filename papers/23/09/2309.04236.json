{
    "title": "Adaptive Distributed Kernel Ridge Regression: A Feasible Distributed Learning Scheme for Data Silos. (arXiv:2309.04236v1 [cs.LG])",
    "abstract": "Data silos, mainly caused by privacy and interoperability, significantly constrain collaborations among different organizations with similar data for the same purpose. Distributed learning based on divide-and-conquer provides a promising way to settle the data silos, but it suffers from several challenges, including autonomy, privacy guarantees, and the necessity of collaborations. This paper focuses on developing an adaptive distributed kernel ridge regression (AdaDKRR) by taking autonomy in parameter selection, privacy in communicating non-sensitive information, and the necessity of collaborations in performance improvement into account. We provide both solid theoretical verification and comprehensive experiments for AdaDKRR to demonstrate its feasibility and effectiveness. Theoretically, we prove that under some mild conditions, AdaDKRR performs similarly to running the optimal learning algorithms on the whole data, verifying the necessity of collaborations and showing that no other",
    "link": "http://arxiv.org/abs/2309.04236",
    "context": "Title: Adaptive Distributed Kernel Ridge Regression: A Feasible Distributed Learning Scheme for Data Silos. (arXiv:2309.04236v1 [cs.LG])\nAbstract: Data silos, mainly caused by privacy and interoperability, significantly constrain collaborations among different organizations with similar data for the same purpose. Distributed learning based on divide-and-conquer provides a promising way to settle the data silos, but it suffers from several challenges, including autonomy, privacy guarantees, and the necessity of collaborations. This paper focuses on developing an adaptive distributed kernel ridge regression (AdaDKRR) by taking autonomy in parameter selection, privacy in communicating non-sensitive information, and the necessity of collaborations in performance improvement into account. We provide both solid theoretical verification and comprehensive experiments for AdaDKRR to demonstrate its feasibility and effectiveness. Theoretically, we prove that under some mild conditions, AdaDKRR performs similarly to running the optimal learning algorithms on the whole data, verifying the necessity of collaborations and showing that no other",
    "path": "papers/23/09/2309.04236.json",
    "total_tokens": 869,
    "translated_title": "自适应分布式核岭回归：一种可行的解决数据孤立的分布式学习方案",
    "translated_abstract": "数据孤立主要由隐私和互操作性引起，显著限制了不同组织在相同目的下具有相似数据的合作。基于分而治之的分布式学习为解决数据孤立提供了一种有前途的方法，但其面临着自治性、隐私保证和合作的必要性等诸多挑战。本文侧重于开发一种自适应分布式核岭回归（AdaDKRR）方法，考虑参数选择的自治性、传递非敏感信息的隐私性和性能改进的合作性。我们提供了对AdaDKRR的坚实理论验证和全面实验来证明其可行性和有效性。在理论上，我们证明在一些温和条件下，AdaDKRR在整个数据上运行最优学习算法的性能类似，验证了合作的必要性，并表明没有其他方法能够达到类似的性能。",
    "tldr": "本文提出了自适应分布式核岭回归（AdaDKRR）方法，该方法通过考虑自治性、隐私性和合作性解决了数据孤立的问题，理论上证明了其性能与整体数据运行最优学习算法类似。",
    "en_tdlr": "This paper proposes an adaptive distributed kernel ridge regression (AdaDKRR) method that addresses the problem of data silos by considering autonomy, privacy, and collaboration. The theoretical analysis demonstrates that AdaDKRR performs similarly to running the optimal learning algorithm on the entire data."
}