{
    "title": "Incorporating Singletons and Mention-based Features in Coreference Resolution via Multi-task Learning for Better Generalization. (arXiv:2309.11582v1 [cs.CL])",
    "abstract": "Previous attempts to incorporate a mention detection step into end-to-end neural coreference resolution for English have been hampered by the lack of singleton mention span data as well as other entity information. This paper presents a coreference model that learns singletons as well as features such as entity type and information status via a multi-task learning-based approach. This approach achieves new state-of-the-art scores on the OntoGUM benchmark (+2.7 points) and increases robustness on multiple out-of-domain datasets (+2.3 points on average), likely due to greater generalizability for mention detection and utilization of more data from singletons when compared to only coreferent mention pair matching.",
    "link": "http://arxiv.org/abs/2309.11582",
    "context": "Title: Incorporating Singletons and Mention-based Features in Coreference Resolution via Multi-task Learning for Better Generalization. (arXiv:2309.11582v1 [cs.CL])\nAbstract: Previous attempts to incorporate a mention detection step into end-to-end neural coreference resolution for English have been hampered by the lack of singleton mention span data as well as other entity information. This paper presents a coreference model that learns singletons as well as features such as entity type and information status via a multi-task learning-based approach. This approach achieves new state-of-the-art scores on the OntoGUM benchmark (+2.7 points) and increases robustness on multiple out-of-domain datasets (+2.3 points on average), likely due to greater generalizability for mention detection and utilization of more data from singletons when compared to only coreferent mention pair matching.",
    "path": "papers/23/09/2309.11582.json",
    "total_tokens": 787,
    "translated_title": "通过多任务学习将单例和基于提及的特征纳入共指消解，以实现更好的泛化能力",
    "translated_abstract": "先前在英语端到端神经共指消解中将提及检测步骤纳入其中的尝试由于缺乏单例提及段数据以及其他实体信息而受到阻碍。本文提出了一种共指模型，通过基于多任务学习的方法学习单例以及特征，例如实体类型和信息状态。与仅进行名词对匹配相比，此方法在OntoGUM基准测试中实现了新的最高分（+2.7分），并在多个领域外数据集上增强了鲁棒性（平均增加了2.3分），可能是由于提及检测的更好泛化能力以及更多单例数据的利用。",
    "tldr": "本文通过多任务学习的方法，将单例和基于提及的特征纳入共指消解中，从而提高了泛化能力。模型在OntoGUM基准测试中取得了新的最高分，并在多个领域外数据集上增强了鲁棒性。",
    "en_tdlr": "This paper incorporates singletons and mention-based features into coreference resolution via multi-task learning, resulting in improved generalization. The model achieves new state-of-the-art scores on the OntoGUM benchmark and increases robustness on multiple out-of-domain datasets."
}