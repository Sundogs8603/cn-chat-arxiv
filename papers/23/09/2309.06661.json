{
    "title": "Sound field decomposition based on two-stage neural networks. (arXiv:2309.06661v1 [eess.AS])",
    "abstract": "A method for sound field decomposition based on neural networks is proposed. The method comprises two stages: a sound field separation stage and a single-source localization stage. In the first stage, the sound pressure at microphones synthesized by multiple sources is separated into one excited by each sound source. In the second stage, the source location is obtained as a regression from the sound pressure at microphones consisting of a single sound source. The estimated location is not affected by discretization because the second stage is designed as a regression rather than a classification. Datasets are generated by simulation using Green's function, and the neural network is trained for each frequency. Numerical experiments reveal that, compared with conventional methods, the proposed method can achieve higher source-localization accuracy and higher sound-field-reconstruction accuracy.",
    "link": "http://arxiv.org/abs/2309.06661",
    "context": "Title: Sound field decomposition based on two-stage neural networks. (arXiv:2309.06661v1 [eess.AS])\nAbstract: A method for sound field decomposition based on neural networks is proposed. The method comprises two stages: a sound field separation stage and a single-source localization stage. In the first stage, the sound pressure at microphones synthesized by multiple sources is separated into one excited by each sound source. In the second stage, the source location is obtained as a regression from the sound pressure at microphones consisting of a single sound source. The estimated location is not affected by discretization because the second stage is designed as a regression rather than a classification. Datasets are generated by simulation using Green's function, and the neural network is trained for each frequency. Numerical experiments reveal that, compared with conventional methods, the proposed method can achieve higher source-localization accuracy and higher sound-field-reconstruction accuracy.",
    "path": "papers/23/09/2309.06661.json",
    "total_tokens": 860,
    "translated_title": "基于两阶段神经网络的声场分解",
    "translated_abstract": "提出了一种基于神经网络的声场分解方法。该方法包括两个阶段：声场分离阶段和单源定位阶段。在第一阶段，由多个声源合成的麦克风处的声压被分离成每个声源激发的声压。在第二阶段，通过由单一声源组成的麦克风处的声压进行回归，获得源位置。由于第二阶段设计为回归而不是分类，因此估计的位置不受离散化的影响。使用Green函数进行模拟生成数据集，并针对每个频率训练神经网络。数值实验表明，与传统方法相比，所提出的方法可以实现更高的源定位精度和声场重构精度。",
    "tldr": "该论文提出了一种基于两阶段神经网络的声场分解方法，通过第一阶段将合成的麦克风处的声压分离成每个声源激发的声压，然后通过第二阶段从单一声源处的声压回归得到源位置，实现了更高的源定位精度和声场重构精度。"
}