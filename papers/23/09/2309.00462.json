{
    "title": "New metrics for analyzing continual learners. (arXiv:2309.00462v1 [cs.LG])",
    "abstract": "Deep neural networks have shown remarkable performance when trained on independent and identically distributed data from a fixed set of classes. However, in real-world scenarios, it can be desirable to train models on a continuous stream of data where multiple classification tasks are presented sequentially. This scenario, known as Continual Learning (CL) poses challenges to standard learning algorithms which struggle to maintain knowledge of old tasks while learning new ones. This stability-plasticity dilemma remains central to CL and multiple metrics have been proposed to adequately measure stability and plasticity separately. However, none considers the increasing difficulty of the classification task, which inherently results in performance loss for any model. In that sense, we analyze some limitations of current metrics and identify the presence of setup-induced forgetting. Therefore, we propose new metrics that account for the task's increasing difficulty. Through experiments on ",
    "link": "http://arxiv.org/abs/2309.00462",
    "context": "Title: New metrics for analyzing continual learners. (arXiv:2309.00462v1 [cs.LG])\nAbstract: Deep neural networks have shown remarkable performance when trained on independent and identically distributed data from a fixed set of classes. However, in real-world scenarios, it can be desirable to train models on a continuous stream of data where multiple classification tasks are presented sequentially. This scenario, known as Continual Learning (CL) poses challenges to standard learning algorithms which struggle to maintain knowledge of old tasks while learning new ones. This stability-plasticity dilemma remains central to CL and multiple metrics have been proposed to adequately measure stability and plasticity separately. However, none considers the increasing difficulty of the classification task, which inherently results in performance loss for any model. In that sense, we analyze some limitations of current metrics and identify the presence of setup-induced forgetting. Therefore, we propose new metrics that account for the task's increasing difficulty. Through experiments on ",
    "path": "papers/23/09/2309.00462.json",
    "total_tokens": 830,
    "translated_title": "分析持续学习者的新指标",
    "translated_abstract": "深度神经网络在从固定的类别集合中进行独立和同分布的数据训练时表现出了显著的性能。然而，在现实世界的场景中，对于连续流的数据进行模型训练可能是有益的，其中多个分类任务按顺序呈现。这种情况被称为持续学习（CL），对于标准学习算法来说，它们在学习新任务的同时难以保持旧任务的知识。这种稳定性与可塑性的困境仍然是持续学习的核心问题，已经提出了多种指标来充分衡量稳定性和可塑性。然而，没有一个指标考虑到分类任务的逐渐增加的难度，这从本质上导致任何模型的性能下降。在这方面，我们分析了当前指标的一些限制，并确定了设置引起的遗忘的存在。因此，我们提出了考虑任务逐渐增加难度的新指标。",
    "tldr": "该论文提出了分析持续学习者的新指标，针对现有指标的局限性进行了分析，并提出解决了分类任务逐渐增加难度的问题。",
    "en_tdlr": "This paper proposes new metrics for analyzing continual learners, analyzes the limitations of current metrics, and addresses the issue of increasing difficulty in classification tasks."
}