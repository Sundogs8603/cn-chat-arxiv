{
    "title": "Benchmarking the Abilities of Large Language Models for RDF Knowledge Graph Creation and Comprehension: How Well Do LLMs Speak Turtle?. (arXiv:2309.17122v1 [cs.AI])",
    "abstract": "Large Language Models (LLMs) are advancing at a rapid pace, with significant improvements at natural language processing and coding tasks. Yet, their ability to work with formal languages representing data, specifically within the realm of knowledge graph engineering, remains under-investigated. To evaluate the proficiency of various LLMs, we created a set of five tasks that probe their ability to parse, understand, analyze, and create knowledge graphs serialized in Turtle syntax. These tasks, each embodying distinct degrees of complexity and being able to scale with the size of the problem, have been integrated into our automated evaluation system, the LLM-KG-Bench. The evaluation encompassed four commercially available LLMs - GPT-3.5, GPT-4, Claude 1.3, and Claude 2.0, as well as two freely accessible offline models, GPT4All Vicuna and GPT4All Falcon 13B. This analysis offers an in-depth understanding of the strengths and shortcomings of LLMs in relation to their application within R",
    "link": "http://arxiv.org/abs/2309.17122",
    "context": "Title: Benchmarking the Abilities of Large Language Models for RDF Knowledge Graph Creation and Comprehension: How Well Do LLMs Speak Turtle?. (arXiv:2309.17122v1 [cs.AI])\nAbstract: Large Language Models (LLMs) are advancing at a rapid pace, with significant improvements at natural language processing and coding tasks. Yet, their ability to work with formal languages representing data, specifically within the realm of knowledge graph engineering, remains under-investigated. To evaluate the proficiency of various LLMs, we created a set of five tasks that probe their ability to parse, understand, analyze, and create knowledge graphs serialized in Turtle syntax. These tasks, each embodying distinct degrees of complexity and being able to scale with the size of the problem, have been integrated into our automated evaluation system, the LLM-KG-Bench. The evaluation encompassed four commercially available LLMs - GPT-3.5, GPT-4, Claude 1.3, and Claude 2.0, as well as two freely accessible offline models, GPT4All Vicuna and GPT4All Falcon 13B. This analysis offers an in-depth understanding of the strengths and shortcomings of LLMs in relation to their application within R",
    "path": "papers/23/09/2309.17122.json",
    "total_tokens": 954,
    "translated_title": "基准测试大型语言模型在RDF知识图创建和理解中的能力：LLMs如何进行Turtle语言解析？",
    "translated_abstract": "大型语言模型（LLMs）在自然语言处理和编码任务方面取得了显著进展，然而它们在表示数据的形式语言中的工作能力，特别是在知识图工程领域中，仍未得到充分研究。为了评估各种LLMs的能力，我们创建了一组五个任务，以探究它们处理Turtle语法的知识图解析、理解、分析和创建的能力。这些任务具有不同的复杂性程度，并能随问题规模而扩展，已集成到我们的自动评估系统LLM-KG-Bench中。评估包括四个商业可用的LLMs - GPT-3.5、GPT-4、Claude 1.3 和 Claude 2.0，以及两个可免费使用的离线模型 GPT4All Vicuna 和 GPT4All Falcon 13B。这项分析深入了解了LLMs在其在R中应用的优势和不足之处。",
    "tldr": "本论文评估了各种大型语言模型在RDF知识图创建和理解中的能力，提出了一组任务来探究模型的解析、理解、分析和创建能力，并且对商业可用和免费的离线模型进行了评估和比较。",
    "en_tdlr": "This paper evaluates the abilities of different large language models in creating and comprehending RDF knowledge graphs. It presents a set of tasks to probe the models' parsing, understanding, analysis, and creation abilities, and conducts evaluations and comparisons on commercially available and freely accessible offline models."
}