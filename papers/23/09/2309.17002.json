{
    "title": "Understanding and Mitigating the Label Noise in Pre-training on Downstream Tasks. (arXiv:2309.17002v1 [cs.LG])",
    "abstract": "Pre-training on large-scale datasets and then fine-tuning on downstream tasks have become a standard practice in deep learning. However, pre-training data often contain label noise that may adversely affect the generalization of the model. This paper aims to understand the nature of noise in pre-training datasets and to mitigate its impact on downstream tasks. More specifically, through extensive experiments of supervised pre-training models on synthetic noisy ImageNet-1K and YFCC15M datasets, we demonstrate that while slight noise in pre-training can benefit in-domain (ID) transfer performance, where the training and testing data share the same distribution, it always deteriorates out-of-domain (OOD) performance, where training and testing data distribution are different. We empirically verify that the reason behind is noise in pre-training shapes the feature space differently. We then propose a lightweight black-box tuning method (NMTune) to affine the feature space to mitigate the m",
    "link": "http://arxiv.org/abs/2309.17002",
    "context": "Title: Understanding and Mitigating the Label Noise in Pre-training on Downstream Tasks. (arXiv:2309.17002v1 [cs.LG])\nAbstract: Pre-training on large-scale datasets and then fine-tuning on downstream tasks have become a standard practice in deep learning. However, pre-training data often contain label noise that may adversely affect the generalization of the model. This paper aims to understand the nature of noise in pre-training datasets and to mitigate its impact on downstream tasks. More specifically, through extensive experiments of supervised pre-training models on synthetic noisy ImageNet-1K and YFCC15M datasets, we demonstrate that while slight noise in pre-training can benefit in-domain (ID) transfer performance, where the training and testing data share the same distribution, it always deteriorates out-of-domain (OOD) performance, where training and testing data distribution are different. We empirically verify that the reason behind is noise in pre-training shapes the feature space differently. We then propose a lightweight black-box tuning method (NMTune) to affine the feature space to mitigate the m",
    "path": "papers/23/09/2309.17002.json",
    "total_tokens": 1004,
    "translated_title": "理解和减轻预训练中的标签噪声对下游任务的影响",
    "translated_abstract": "在深度学习中，先在大规模数据集上进行预训练，然后在下游任务上进行微调已经成为一种标准做法。然而，预训练数据通常包含标签噪声，这可能对模型的泛化能力产生不利影响。本文旨在了解预训练数据集中噪声的性质，并减轻其对下游任务的影响。具体而言，通过在合成噪声的ImageNet-1K和YFCC15M数据集上进行大量实验，我们证明在预训练中的轻微噪声可以促进领域内的转移性能，即训练和测试数据具有相同的分布；然而，它总是会损害领域外的性能，即训练和测试数据具有不同的分布。我们通过实验证实，预训练中的噪声会不同地塑造特征空间。然后我们提出了一种轻量级的黑盒调整方法（NMTune）来使特征空间达到映射并减轻噪声的影响。",
    "tldr": "本文研究了深度学习中预训练数据中的标签噪声对下游任务的影响，并通过在合成噪声数据集上的实验证明，在预训练中的轻微噪声可以提高领域内的性能，但会损害领域外的性能。为了减轻噪声的影响，提出了一种轻量级的黑盒调整方法（NMTune）。",
    "en_tdlr": "This paper investigates the impact of label noise in pre-training data on downstream tasks in deep learning. The experiments on synthetic noisy datasets demonstrate that slight noise in pre-training improves performance within the same domain but deteriorates performance across different domains. To mitigate the noise effect, a lightweight black-box tuning method (NMTune) is proposed."
}