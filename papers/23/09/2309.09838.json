{
    "title": "HypR: A comprehensive study for ASR hypothesis revising with a reference corpus. (arXiv:2309.09838v2 [cs.CL] UPDATED)",
    "abstract": "With the development of deep learning, automatic speech recognition (ASR) has made significant progress. To further enhance the performance, revising recognition results is one of the lightweight but efficient manners. Various methods can be roughly classified into N-best reranking methods and error correction models. The former aims to select the hypothesis with the lowest error rate from a set of candidates generated by ASR for a given input speech. The latter focuses on detecting recognition errors in a given hypothesis and correcting these errors to obtain an enhanced result. However, we observe that these studies are hardly comparable to each other as they are usually evaluated on different corpora, paired with different ASR models, and even use different datasets to train the models. Accordingly, we first concentrate on releasing an ASR hypothesis revising (HypR) dataset in this study. HypR contains several commonly used corpora (AISHELL-1, TED-LIUM 2, and LibriSpeech) and provid",
    "link": "http://arxiv.org/abs/2309.09838",
    "context": "Title: HypR: A comprehensive study for ASR hypothesis revising with a reference corpus. (arXiv:2309.09838v2 [cs.CL] UPDATED)\nAbstract: With the development of deep learning, automatic speech recognition (ASR) has made significant progress. To further enhance the performance, revising recognition results is one of the lightweight but efficient manners. Various methods can be roughly classified into N-best reranking methods and error correction models. The former aims to select the hypothesis with the lowest error rate from a set of candidates generated by ASR for a given input speech. The latter focuses on detecting recognition errors in a given hypothesis and correcting these errors to obtain an enhanced result. However, we observe that these studies are hardly comparable to each other as they are usually evaluated on different corpora, paired with different ASR models, and even use different datasets to train the models. Accordingly, we first concentrate on releasing an ASR hypothesis revising (HypR) dataset in this study. HypR contains several commonly used corpora (AISHELL-1, TED-LIUM 2, and LibriSpeech) and provid",
    "path": "papers/23/09/2309.09838.json",
    "total_tokens": 915,
    "translated_title": "HypR：一个使用参考语料库进行ASR假设修订的全面研究",
    "translated_abstract": "随着深度学习的发展，自动语音识别（ASR）取得了显著进展。为了进一步提高性能，修订识别结果是一种轻量级但高效的方法之一。各种方法可以大致分为N-best重排序方法和错误修正模型。前者旨在从由ASR生成的一组候选假设中选择错误率最低的假设，用于给定的输入语音。后者则专注于检测给定假设中的识别错误，并纠正这些错误以获得增强的结果。然而，我们观察到这些研究很难相互比较，因为它们通常在不同的语料库上进行评估，与不同的ASR模型配对，并且甚至使用不同的数据集来训练模型。因此，在本研究中，我们首先专注于发布一个ASR假设修订（HypR）数据集。HypR包含几个常用的语料库（AISHELL-1，TED-LIUM 2和LibriSpeech），并且提供了ASR模型的基线系统。",
    "tldr": "本研究集中在发布一个ASR假设修订（HypR）数据集，该数据集包含了几个常用的语料库，并且为ASR模型的修订提供了一个基础。",
    "en_tdlr": "This study focuses on releasing an ASR hypothesis revising (HypR) dataset, which contains several commonly used corpora and provides a foundation for revising ASR models."
}