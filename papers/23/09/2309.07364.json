{
    "title": "Hodge-Aware Contrastive Learning. (arXiv:2309.07364v1 [cs.LG])",
    "abstract": "Simplicial complexes prove effective in modeling data with multiway dependencies, such as data defined along the edges of networks or within other higher-order structures. Their spectrum can be decomposed into three interpretable subspaces via the Hodge decomposition, resulting foundational in numerous applications. We leverage this decomposition to develop a contrastive self-supervised learning approach for processing simplicial data and generating embeddings that encapsulate specific spectral information.Specifically, we encode the pertinent data invariances through simplicial neural networks and devise augmentations that yield positive contrastive examples with suitable spectral properties for downstream tasks. Additionally, we reweight the significance of negative examples in the contrastive loss, considering the similarity of their Hodge components to the anchor. By encouraging a stronger separation among less similar instances, we obtain an embedding space that reflects the spect",
    "link": "http://arxiv.org/abs/2309.07364",
    "context": "Title: Hodge-Aware Contrastive Learning. (arXiv:2309.07364v1 [cs.LG])\nAbstract: Simplicial complexes prove effective in modeling data with multiway dependencies, such as data defined along the edges of networks or within other higher-order structures. Their spectrum can be decomposed into three interpretable subspaces via the Hodge decomposition, resulting foundational in numerous applications. We leverage this decomposition to develop a contrastive self-supervised learning approach for processing simplicial data and generating embeddings that encapsulate specific spectral information.Specifically, we encode the pertinent data invariances through simplicial neural networks and devise augmentations that yield positive contrastive examples with suitable spectral properties for downstream tasks. Additionally, we reweight the significance of negative examples in the contrastive loss, considering the similarity of their Hodge components to the anchor. By encouraging a stronger separation among less similar instances, we obtain an embedding space that reflects the spect",
    "path": "papers/23/09/2309.07364.json",
    "total_tokens": 889,
    "translated_title": "Hodge-Aware Contrastive Learning（基于豪奇分解的对比学习）",
    "translated_abstract": "单纯复合体在对具有多向依赖关系的数据进行建模方面表现出很好的效果，例如在网络的边缘上定义的数据或其他高阶结构内的数据。通过豪奇分解，可以将其谱分解为三个可解释的子空间，这在许多应用中都具有基础性。我们利用这种分解来开发一种对比自我监督学习方法，用于处理单纯复合体数据并生成蕴含特定谱信息的嵌入。具体地，我们通过单纯神经网络来编码相关数据的不变性，并设计出具有适当谱特性的增强方法，以生成正对比示例。此外，我们通过考虑负样本的豪奇分量与锚点相似性，重新权衡对比损失中负样本的重要性。通过加强较少相似实例之间的分离，我们获得了一个反映谱信息的嵌入空间。",
    "tldr": "本文提出了一种基于豪奇分解的对比学习方法，用于处理单纯复合体数据，并生成具有特定谱信息的嵌入。通过编码数据不变性和设计合适的增强方法，以及重新权衡负样本的重要性，我们得到了一个反映谱信息的嵌入空间。",
    "en_tdlr": "This paper proposes a Hodge-Aware Contrastive Learning approach for processing simplicial data and generating embeddings with specific spectral information. By encoding data invariances, designing suitable augmentations, and reweighting the significance of negative examples, the resulting embedding space reflects spectral information."
}