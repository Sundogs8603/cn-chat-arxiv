{
    "title": "GInX-Eval: Towards In-Distribution Evaluation of Graph Neural Network Explanations. (arXiv:2309.16223v1 [cs.AI])",
    "abstract": "Diverse explainability methods of graph neural networks (GNN) have recently been developed to highlight the edges and nodes in the graph that contribute the most to the model predictions. However, it is not clear yet how to evaluate the correctness of those explanations, whether it is from a human or a model perspective. One unaddressed bottleneck in the current evaluation procedure is the problem of out-of-distribution explanations, whose distribution differs from those of the training data. This important issue affects existing evaluation metrics such as the popular faithfulness or fidelity score. In this paper, we show the limitations of faithfulness metrics. We propose GInX-Eval (Graph In-distribution eXplanation Evaluation), an evaluation procedure of graph explanations that overcomes the pitfalls of faithfulness and offers new insights on explainability methods. Using a retraining strategy, the GInX score measures how informative removed edges are for the model and the EdgeRank s",
    "link": "http://arxiv.org/abs/2309.16223",
    "context": "Title: GInX-Eval: Towards In-Distribution Evaluation of Graph Neural Network Explanations. (arXiv:2309.16223v1 [cs.AI])\nAbstract: Diverse explainability methods of graph neural networks (GNN) have recently been developed to highlight the edges and nodes in the graph that contribute the most to the model predictions. However, it is not clear yet how to evaluate the correctness of those explanations, whether it is from a human or a model perspective. One unaddressed bottleneck in the current evaluation procedure is the problem of out-of-distribution explanations, whose distribution differs from those of the training data. This important issue affects existing evaluation metrics such as the popular faithfulness or fidelity score. In this paper, we show the limitations of faithfulness metrics. We propose GInX-Eval (Graph In-distribution eXplanation Evaluation), an evaluation procedure of graph explanations that overcomes the pitfalls of faithfulness and offers new insights on explainability methods. Using a retraining strategy, the GInX score measures how informative removed edges are for the model and the EdgeRank s",
    "path": "papers/23/09/2309.16223.json",
    "total_tokens": 858,
    "translated_title": "GInX-Eval: 面向图神经网络解释的内分布评估",
    "translated_abstract": "最近，为了突出图中对模型预测最有贡献的边和节点，人们开发了各种解释图神经网络（GNN）的方法。然而，目前尚不清楚如何从人类或模型的角度评估这些解释的正确性。当前评估过程中一个未解决的瓶颈问题是解释的分布与训练数据的分布不同的情况。这个重要问题会影响到现有的评估指标，如流行的忠实度或保真度得分。在本文中，我们展示了忠实度指标的局限性。我们提出了GInX-Eval（图内分布解释评估），这是一种用于评估图解释的过程，克服了忠实度的缺陷，并提供了对解释方法的新见解。使用重新训练策略，GInX得分可衡量已移除边对模型的信息量以及边的重要性。",
    "tldr": "本文针对图神经网络解释的内分布评估问题，提出了GInX-Eval方法，克服了传统评估指标的局限性，为解释方法提供了新的见解。",
    "en_tdlr": "This paper proposes GInX-Eval, a method for in-distribution evaluation of graph neural network explanations, which overcomes the limitations of traditional evaluation metrics and provides new insights into explanation methods."
}