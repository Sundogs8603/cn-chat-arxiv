{
    "title": "Towards Human-Like RL: Taming Non-Naturalistic Behavior in Deep RL via Adaptive Behavioral Costs in 3D Games. (arXiv:2309.15484v1 [cs.AI])",
    "abstract": "In this paper, we propose a new approach called Adaptive Behavioral Costs in Reinforcement Learning (ABC-RL) for training a human-like agent with competitive strength. While deep reinforcement learning agents have recently achieved superhuman performance in various video games, some of these unconstrained agents may exhibit actions, such as shaking and spinning, that are not typically observed in human behavior, resulting in peculiar gameplay experiences. To behave like humans and retain similar performance, ABC-RL augments behavioral limitations as cost signals in reinforcement learning with dynamically adjusted weights. Unlike traditional constrained policy optimization, we propose a new formulation that minimizes the behavioral costs subject to a constraint of the value function. By leveraging the augmented Lagrangian, our approach is an approximation of the Lagrangian adjustment, which handles the trade-off between the performance and the human-like behavior. Through experiments co",
    "link": "http://arxiv.org/abs/2309.15484",
    "context": "Title: Towards Human-Like RL: Taming Non-Naturalistic Behavior in Deep RL via Adaptive Behavioral Costs in 3D Games. (arXiv:2309.15484v1 [cs.AI])\nAbstract: In this paper, we propose a new approach called Adaptive Behavioral Costs in Reinforcement Learning (ABC-RL) for training a human-like agent with competitive strength. While deep reinforcement learning agents have recently achieved superhuman performance in various video games, some of these unconstrained agents may exhibit actions, such as shaking and spinning, that are not typically observed in human behavior, resulting in peculiar gameplay experiences. To behave like humans and retain similar performance, ABC-RL augments behavioral limitations as cost signals in reinforcement learning with dynamically adjusted weights. Unlike traditional constrained policy optimization, we propose a new formulation that minimizes the behavioral costs subject to a constraint of the value function. By leveraging the augmented Lagrangian, our approach is an approximation of the Lagrangian adjustment, which handles the trade-off between the performance and the human-like behavior. Through experiments co",
    "path": "papers/23/09/2309.15484.json",
    "total_tokens": 975,
    "translated_title": "迈向人类化强化学习：通过3D游戏中的自适应行为成本控制深度强化学习中的非自然行为",
    "translated_abstract": "本文提出一种新的方法，称为自适应行为成本强化学习（ABC-RL），用于训练具有竞争力强人类化智能体。尽管深度强化学习智能体在各种视频游戏中最近实现了超人类的表现，但其中一些不受限制的智能体可能表现出不符合人类行为的动作，例如摇晃和旋转，导致奇特的游戏体验。为了像人类那样行为，并保持相似的表现，ABC-RL在强化学习中增加了行为限制作为成本信号，并动态调整权重。与传统的受限策略优化不同，我们提出了一种新的公式，最小化行为成本，同时约束价值函数。通过利用增广拉格朗日乘子法，我们的方法是拉格朗日调整的近似，处理性能与人类化行为之间的权衡。通过实验",
    "tldr": "本文提出了一种名为自适应行为成本强化学习（ABC-RL）的新方法，通过在强化学习中引入行为限制作为成本信号，并动态调整权重，训练出人类化的智能体。这种方法可以处理深度强化学习中出现的非自然行为问题，使智能体在游戏中更像人类，并保持相似的性能。"
}