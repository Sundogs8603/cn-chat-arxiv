{
    "title": "CATfOOD: Counterfactual Augmented Training for Improving Out-of-Domain Performance and Calibration. (arXiv:2309.07822v1 [cs.CL])",
    "abstract": "In recent years, large language models (LLMs) have shown remarkable capabilities at scale, particularly at generating text conditioned on a prompt. In our work, we investigate the use of LLMs to augment training data of small language models~(SLMs) with automatically generated counterfactual~(CF) instances -- i.e. minimally altered inputs -- in order to improve out-of-domain~(OOD) performance of SLMs in the extractive question answering~(QA) setup. We show that, across various LLM generators, such data augmentation consistently enhances OOD performance and improves model calibration for both confidence-based and rationale-augmented calibrator models. Furthermore, these performance improvements correlate with higher diversity of CF instances in terms of their surface form and semantic content. Finally, we show that CF augmented models which are easier to calibrate also exhibit much lower entropy when assigning importance, indicating that rationale-augmented calibrators prefer concise ex",
    "link": "http://arxiv.org/abs/2309.07822",
    "context": "Title: CATfOOD: Counterfactual Augmented Training for Improving Out-of-Domain Performance and Calibration. (arXiv:2309.07822v1 [cs.CL])\nAbstract: In recent years, large language models (LLMs) have shown remarkable capabilities at scale, particularly at generating text conditioned on a prompt. In our work, we investigate the use of LLMs to augment training data of small language models~(SLMs) with automatically generated counterfactual~(CF) instances -- i.e. minimally altered inputs -- in order to improve out-of-domain~(OOD) performance of SLMs in the extractive question answering~(QA) setup. We show that, across various LLM generators, such data augmentation consistently enhances OOD performance and improves model calibration for both confidence-based and rationale-augmented calibrator models. Furthermore, these performance improvements correlate with higher diversity of CF instances in terms of their surface form and semantic content. Finally, we show that CF augmented models which are easier to calibrate also exhibit much lower entropy when assigning importance, indicating that rationale-augmented calibrators prefer concise ex",
    "path": "papers/23/09/2309.07822.json",
    "total_tokens": 929,
    "translated_title": "CATfOOD：反事实增强训练以提高领域外性能和校准能力",
    "translated_abstract": "在最近的几年中，大型语言模型（LLM）在规模方面展示了显著的能力，特别是在给定提示的条件下生成文本。在我们的研究中，我们探讨了使用LLM来增强小型语言模型（SLM）的训练数据的方法，通过自动生成的反事实（CF）实例（即最小程度的改变输入），以提高SLM在摘要问答（QA）设置下的领域外（OOD）性能。我们证明，在各种LLM生成器中，这种数据增强始终能够提高OOD性能，并改进了基于置信度和基于理性增强的校准模型的模型校准能力。此外，这些性能提升与CF实例在外观形式和语义内容方面的多样性呈正相关。最后，我们证明了校准更容易的CF增强模型在分配重要性时的熵也较低，这表明理性增强的校准器更偏好简洁的解释。",
    "tldr": "本研究通过在小型语言模型训练数据中增加自动生成的反事实实例，提高了摘要问答模型在领域外的性能和模型校准能力，并发现性能改进与反事实实例的多样性相关。"
}