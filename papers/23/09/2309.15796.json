{
    "title": "Learning from Flawed Data: Weakly Supervised Automatic Speech Recognition. (arXiv:2309.15796v1 [eess.AS])",
    "abstract": "Training automatic speech recognition (ASR) systems requires large amounts of well-curated paired data. However, human annotators usually perform \"non-verbatim\" transcription, which can result in poorly trained models. In this paper, we propose Omni-temporal Classification (OTC), a novel training criterion that explicitly incorporates label uncertainties originating from such weak supervision. This allows the model to effectively learn speech-text alignments while accommodating errors present in the training transcripts. OTC extends the conventional CTC objective for imperfect transcripts by leveraging weighted finite state transducers. Through experiments conducted on the LibriSpeech and LibriVox datasets, we demonstrate that training ASR models with OTC avoids performance degradation even with transcripts containing up to 70% errors, a scenario where CTC models fail completely. Our implementation is available at https://github.com/k2-fsa/icefall.",
    "link": "http://arxiv.org/abs/2309.15796",
    "context": "Title: Learning from Flawed Data: Weakly Supervised Automatic Speech Recognition. (arXiv:2309.15796v1 [eess.AS])\nAbstract: Training automatic speech recognition (ASR) systems requires large amounts of well-curated paired data. However, human annotators usually perform \"non-verbatim\" transcription, which can result in poorly trained models. In this paper, we propose Omni-temporal Classification (OTC), a novel training criterion that explicitly incorporates label uncertainties originating from such weak supervision. This allows the model to effectively learn speech-text alignments while accommodating errors present in the training transcripts. OTC extends the conventional CTC objective for imperfect transcripts by leveraging weighted finite state transducers. Through experiments conducted on the LibriSpeech and LibriVox datasets, we demonstrate that training ASR models with OTC avoids performance degradation even with transcripts containing up to 70% errors, a scenario where CTC models fail completely. Our implementation is available at https://github.com/k2-fsa/icefall.",
    "path": "papers/23/09/2309.15796.json",
    "total_tokens": 861,
    "translated_title": "学习来自有缺陷的数据：弱监督式自动语音识别",
    "translated_abstract": "训练自动语音识别（ASR）系统需要大量经过精心筛选的配对数据。然而，人工标注者通常执行“非逐字”转录，这可能导致训练模型不佳。在本文中，我们提出了全时分类（OTC），一种新颖的训练准则，明确地融入了由此类弱监督引起的标签不确定性。这使得模型能够有效地学习语音-文本对齐，并适应训练转录中存在的错误。OTC通过利用加权有限状态转换器扩展了传统的CTC目标函数用于不完美转录。通过在LibriSpeech和LibriVox数据集上进行的实验，我们证明使用OTC训练ASR模型可以避免性能下降，即使转录中包含高达70％的错误，而CTC模型则完全失效。我们的实现可在https://github.com/k2-fsa/icefall获得。",
    "tldr": "本文提出了一种弱监督自动语音识别方法，使用全时分类准则训练模型，可以有效学习语音-文本对齐，并适应训练转录中的错误，避免性能下降。"
}