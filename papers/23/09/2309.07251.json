{
    "title": "In-Contextual Bias Suppression for Large Language Models. (arXiv:2309.07251v1 [cs.CL])",
    "abstract": "Despite their impressive performance in a wide range of NLP tasks, Large Language Models (LLMs) have been reported to encode worrying-levels of gender bias. Prior work has proposed debiasing methods that require human labelled examples, data augmentation and fine-tuning of the LLMs, which are computationally costly. Moreover, one might not even have access to the internal parameters for performing debiasing such as in the case of commercially available LLMs such as GPT-4. To address this challenge we propose bias suppression, a novel alternative to debiasing that does not require access to model parameters. We show that text-based preambles, generated from manually designed templates covering counterfactual statements, can accurately suppress gender biases in LLMs. Moreover, we find that descriptive sentences for occupations can further suppress gender biases. Interestingly, we find that bias suppression has a minimal adverse effect on downstream task performance, while effectively mit",
    "link": "http://arxiv.org/abs/2309.07251",
    "context": "Title: In-Contextual Bias Suppression for Large Language Models. (arXiv:2309.07251v1 [cs.CL])\nAbstract: Despite their impressive performance in a wide range of NLP tasks, Large Language Models (LLMs) have been reported to encode worrying-levels of gender bias. Prior work has proposed debiasing methods that require human labelled examples, data augmentation and fine-tuning of the LLMs, which are computationally costly. Moreover, one might not even have access to the internal parameters for performing debiasing such as in the case of commercially available LLMs such as GPT-4. To address this challenge we propose bias suppression, a novel alternative to debiasing that does not require access to model parameters. We show that text-based preambles, generated from manually designed templates covering counterfactual statements, can accurately suppress gender biases in LLMs. Moreover, we find that descriptive sentences for occupations can further suppress gender biases. Interestingly, we find that bias suppression has a minimal adverse effect on downstream task performance, while effectively mit",
    "path": "papers/23/09/2309.07251.json",
    "total_tokens": 894,
    "translated_title": "大型语言模型中的背景偏见抑制",
    "translated_abstract": "尽管大型语言模型在各种自然语言处理任务中表现出色，但已有研究报告称其存在令人担忧的性别偏见。先前的工作提出了需要人工标注示例、数据增强和LLM的微调的去偏方法，这些方法计算成本高昂。此外，某些情况下可能无法获得进行去偏所需的内部参数，如商用LLM（如GPT-4）的情况。为了解决这一挑战，我们提出了一种新的去偏替代方法，称为偏见抑制，它不需要访问模型参数。我们展示了基于手动设计的反事实命题模板生成的文本前导语可以准确地抑制LLM中的性别偏见。此外，我们发现职业的描述句可以进一步抑制性别偏见。有趣的是，我们发现偏见抑制对下游任务性能几乎没有不利影响，同时有效缓解了性别偏见。",
    "tldr": "基于文本前导语和职业描述句生成的反事实命题模板可以有效抑制大型语言模型中的性别偏见，而不需要访问模型参数，并且不会对下游任务性能产生明显的负面影响。",
    "en_tdlr": "The proposed bias suppression method uses text-based preambles, generated from manually designed templates, and descriptive sentences for occupations to effectively mitigate gender biases in large language models. This approach does not require accessing model parameters and has minimal adverse effects on downstream task performance."
}