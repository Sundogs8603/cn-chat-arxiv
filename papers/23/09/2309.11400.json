{
    "title": "Transformers versus LSTMs for electronic trading. (arXiv:2309.11400v1 [q-fin.TR])",
    "abstract": "With the rapid development of artificial intelligence, long short term memory (LSTM), one kind of recurrent neural network (RNN), has been widely applied in time series prediction.  Like RNN, Transformer is designed to handle the sequential data. As Transformer achieved great success in Natural Language Processing (NLP), researchers got interested in Transformer's performance on time series prediction, and plenty of Transformer-based solutions on long time series forecasting have come out recently. However, when it comes to financial time series prediction, LSTM is still a dominant architecture. Therefore, the question this study wants to answer is: whether the Transformer-based model can be applied in financial time series prediction and beat LSTM.  To answer this question, various LSTM-based and Transformer-based models are compared on multiple financial prediction tasks based on high-frequency limit order book data. A new LSTM-based model called DLSTM is built and new architecture f",
    "link": "http://arxiv.org/abs/2309.11400",
    "context": "Title: Transformers versus LSTMs for electronic trading. (arXiv:2309.11400v1 [q-fin.TR])\nAbstract: With the rapid development of artificial intelligence, long short term memory (LSTM), one kind of recurrent neural network (RNN), has been widely applied in time series prediction.  Like RNN, Transformer is designed to handle the sequential data. As Transformer achieved great success in Natural Language Processing (NLP), researchers got interested in Transformer's performance on time series prediction, and plenty of Transformer-based solutions on long time series forecasting have come out recently. However, when it comes to financial time series prediction, LSTM is still a dominant architecture. Therefore, the question this study wants to answer is: whether the Transformer-based model can be applied in financial time series prediction and beat LSTM.  To answer this question, various LSTM-based and Transformer-based models are compared on multiple financial prediction tasks based on high-frequency limit order book data. A new LSTM-based model called DLSTM is built and new architecture f",
    "path": "papers/23/09/2309.11400.json",
    "total_tokens": 840,
    "translated_title": "Transformers对电子交易的比较测试",
    "translated_abstract": "随着人工智能的快速发展，长短期记忆(LSTM)作为一种循环神经网络(RNN)被广泛应用于时间序列预测。与RNN相似，Transformer被设计用来处理序列数据。由于Transformer在自然语言处理(NLP)领域取得了巨大成功，研究者开始关注Transformer在时间序列预测中的表现，并最近提出了许多基于Transformer的长时间序列预测解决方案。然而，当涉及金融时间序列预测时，LSTM仍然是主流的架构。因此，本研究想要回答的问题是：Transformer基于模型是否可以应用在金融时间序列预测中，并击败LSTM。为了回答这个问题，本研究在基于高频限价委托簿数据的多个金融预测任务上比较了多种基于LSTM和Transformer的模型。创建了一个名为DLSTM的新型LSTM-based模型，并提出了新的架构。",
    "tldr": "本研究比较了基于LSTM和基于Transformer的模型在金融时间序列预测任务上的表现，并介绍了一种新的LSTM-based模型DLSTM。",
    "en_tdlr": "This study compares the performance of LSTM-based and Transformer-based models on financial time series prediction tasks, and introduces a new LSTM-based model called DLSTM."
}