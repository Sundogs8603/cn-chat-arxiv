{
    "title": "Measuring and Improving Chain-of-Thought Reasoning in Vision-Language Models. (arXiv:2309.04461v1 [cs.CL])",
    "abstract": "Vision-language models (VLMs) have recently demonstrated strong efficacy as visual assistants that can parse natural queries about the visual content and generate human-like outputs. In this work, we explore the ability of these models to demonstrate human-like reasoning based on the perceived information. To address a crucial concern regarding the extent to which their reasoning capabilities are fully consistent and grounded, we also measure the reasoning consistency of these models. We achieve this by proposing a chain-of-thought (CoT) based consistency measure. However, such an evaluation requires a benchmark that encompasses both high-level inference and detailed reasoning chains, which is costly. We tackle this challenge by proposing a LLM-Human-in-the-Loop pipeline, which notably reduces cost while simultaneously ensuring the generation of a high-quality dataset. Based on this pipeline and the existing coarse-grained annotated dataset, we build the CURE benchmark to measure both ",
    "link": "http://arxiv.org/abs/2309.04461",
    "context": "Title: Measuring and Improving Chain-of-Thought Reasoning in Vision-Language Models. (arXiv:2309.04461v1 [cs.CL])\nAbstract: Vision-language models (VLMs) have recently demonstrated strong efficacy as visual assistants that can parse natural queries about the visual content and generate human-like outputs. In this work, we explore the ability of these models to demonstrate human-like reasoning based on the perceived information. To address a crucial concern regarding the extent to which their reasoning capabilities are fully consistent and grounded, we also measure the reasoning consistency of these models. We achieve this by proposing a chain-of-thought (CoT) based consistency measure. However, such an evaluation requires a benchmark that encompasses both high-level inference and detailed reasoning chains, which is costly. We tackle this challenge by proposing a LLM-Human-in-the-Loop pipeline, which notably reduces cost while simultaneously ensuring the generation of a high-quality dataset. Based on this pipeline and the existing coarse-grained annotated dataset, we build the CURE benchmark to measure both ",
    "path": "papers/23/09/2309.04461.json",
    "total_tokens": 900,
    "translated_title": "测量和改进视觉-语言模型中的思维链推理",
    "translated_abstract": "最近，视觉-语言模型（VLMs）作为能解析关于视觉内容的自然查询并生成类人输出的视觉助手，展示出了强大的功效。在这项工作中，我们探索了这些模型展示基于所感知信息的类人推理的能力。为了解决关于它们的推理能力到底有多一致和有多基于实际的一个重要疑虑，我们还测量了这些模型的推理一致性。我们通过提出一种基于思维链（CoT）的一致性度量来实现这一目标。然而，这样的评估需要涵盖高层次推理和细节推理链的基准，这是一项昂贵的任务。我们通过提出LLM-Human-in-the-Loop流水线来应对这一挑战，该流水线显著降低了成本，同时确保生成高质量的数据集。基于这个流水线和现有的粗粒度注释数据集，我们构建了CURE基准来同时测量两者。",
    "tldr": "本研究探索了视觉-语言模型展示人类推理能力的能力，并提出了一种基于思维链的一致性度量。通过一个流水线和已有数据集，建立了一个基准来测量这种推理能力。",
    "en_tdlr": "This study explores the ability of vision-language models to demonstrate human-like reasoning and proposes a consistency measure based on chain-of-thought. The research also establishes a benchmark to measure this reasoning capability through a pipeline and existing dataset."
}