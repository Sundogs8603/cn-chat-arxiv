{
    "title": "LatticeGen: A Cooperative Framework which Hides Generated Text in a Lattice for Privacy-Aware Generation on Cloud. (arXiv:2309.17157v1 [cs.CL])",
    "abstract": "In the current user-server interaction paradigm of prompted generation with large language models (LLM) on cloud, the server fully controls the generation process, which leaves zero options for users who want to keep the generated text to themselves. We propose LatticeGen, a cooperative framework in which the server still handles most of the computation while the user controls the sampling operation. The key idea is that the true generated sequence is mixed with noise tokens by the user and hidden in a noised lattice. Considering potential attacks from a hypothetically malicious server and how the user can defend against it, we propose the repeated beam-search attack and the mixing noise scheme. In our experiments we apply LatticeGen to protect both prompt and generation. It is shown that while the noised lattice degrades generation quality, LatticeGen successfully protects the true generation to a remarkable degree under strong attacks (more than 50% of the semantic remains hidden as ",
    "link": "http://arxiv.org/abs/2309.17157",
    "context": "Title: LatticeGen: A Cooperative Framework which Hides Generated Text in a Lattice for Privacy-Aware Generation on Cloud. (arXiv:2309.17157v1 [cs.CL])\nAbstract: In the current user-server interaction paradigm of prompted generation with large language models (LLM) on cloud, the server fully controls the generation process, which leaves zero options for users who want to keep the generated text to themselves. We propose LatticeGen, a cooperative framework in which the server still handles most of the computation while the user controls the sampling operation. The key idea is that the true generated sequence is mixed with noise tokens by the user and hidden in a noised lattice. Considering potential attacks from a hypothetically malicious server and how the user can defend against it, we propose the repeated beam-search attack and the mixing noise scheme. In our experiments we apply LatticeGen to protect both prompt and generation. It is shown that while the noised lattice degrades generation quality, LatticeGen successfully protects the true generation to a remarkable degree under strong attacks (more than 50% of the semantic remains hidden as ",
    "path": "papers/23/09/2309.17157.json",
    "total_tokens": 926,
    "translated_title": "LatticeGen: 一种在云上进行隐私感知生成的协作框架，隐藏生成的文本在格子中",
    "translated_abstract": "在当前的用户-服务器交互模式中，使用大型语言模型（LLM）进行提示生成的过程中，服务器完全控制着生成过程，这使得想要将生成的文本保留给自己的用户没有任何选择。我们提出了LatticeGen，一个协作框架，在该框架中，服务器仍然处理大部分计算任务，而用户控制采样操作。其核心思想是用户将真实生成序列与噪声标记混合，并隐藏在一个带噪声的格子中。考虑到来自假设恶意服务器的潜在攻击以及用户如何进行防御，我们提出了重复波束搜索攻击和混合噪声方案。在实验中，我们将LatticeGen应用于保护提示和生成。结果显示，虽然带噪声的格子会降低生成质量，但LatticeGen成功地在强攻击下显著保护了真实生成（超过50%的语义仍然隐藏）。",
    "tldr": "LatticeGen是一个协作框架，通过将真实生成的文本与噪声混合并隐藏在格子中，以保护用户的隐私。实验证明，LatticeGen能够在面对强攻击时成功保护真实生成，超过50%的语义仍然隐藏。",
    "en_tdlr": "LatticeGen is a cooperative framework that protects user privacy by mixing the true generated text with noise and hiding it in a lattice. Experimental results demonstrate that LatticeGen successfully safeguards the true generation against strong attacks, with more than 50% of the semantics remaining hidden."
}