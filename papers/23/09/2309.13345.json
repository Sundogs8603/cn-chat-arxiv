{
    "title": "BAMBOO: A Comprehensive Benchmark for Evaluating Long Text Modeling Capacities of Large Language Models",
    "abstract": "arXiv:2309.13345v2 Announce Type: replace  Abstract: Large language models (LLMs) have achieved dramatic proficiency over NLP tasks with normal length. Recently, multiple studies have committed to extending the context length and enhancing the long text modeling capabilities of LLMs. To comprehensively evaluate the long context ability of LLMs, we propose BAMBOO, a multi-task long context benchmark. BAMBOO has been designed with four principles: comprehensive capacity evaluation, avoidance of data contamination, accurate automatic evaluation, and different length levels. It consists of 10 datasets from 5 different long text understanding tasks, i.e. question answering, hallucination detection, text sorting, language modeling, and code completion, to cover core capacities and various domains of LLMs. We conduct experiments with five long context models on BAMBOO and further discuss four key research questions of long text. We also qualitatively analyze current long context models and po",
    "link": "https://arxiv.org/abs/2309.13345",
    "context": "Title: BAMBOO: A Comprehensive Benchmark for Evaluating Long Text Modeling Capacities of Large Language Models\nAbstract: arXiv:2309.13345v2 Announce Type: replace  Abstract: Large language models (LLMs) have achieved dramatic proficiency over NLP tasks with normal length. Recently, multiple studies have committed to extending the context length and enhancing the long text modeling capabilities of LLMs. To comprehensively evaluate the long context ability of LLMs, we propose BAMBOO, a multi-task long context benchmark. BAMBOO has been designed with four principles: comprehensive capacity evaluation, avoidance of data contamination, accurate automatic evaluation, and different length levels. It consists of 10 datasets from 5 different long text understanding tasks, i.e. question answering, hallucination detection, text sorting, language modeling, and code completion, to cover core capacities and various domains of LLMs. We conduct experiments with five long context models on BAMBOO and further discuss four key research questions of long text. We also qualitatively analyze current long context models and po",
    "path": "papers/23/09/2309.13345.json",
    "total_tokens": 887,
    "translated_title": "BAMBOO：用于评估大语言模型长文本建模能力的全面基准",
    "translated_abstract": "大语言模型（LLMs）已经在处理普通长度的NLP任务中取得了惊人的熟练度。最近，多项研究致力于扩展上下文长度，并增强LLMs的长文本建模能力。为了全面评估LLMs的长上下文能力，我们提出了BAMBOO，一个多任务长上下文基准。BAMBOO设计之初考虑了四个原则：全面容量评估、避免数据污染、准确的自动评估以及不同长度级别。它由来自5个不同长文本理解任务的10个数据集组成，即问答、幻觉检测、文本排序、语言建模和代码补全，以涵盖LLMs的核心能力和各个领域。我们在BAMBOO上使用五个长上下文模型进行实验，并进一步讨论了长文本的四个关键研究问题。我们还对当前的长上下文模型进行了定性分析。",
    "tldr": "提出了BAMBOO基准来全面评估大语言模型对长文本的建模能力，包含10个数据集从5个不同长文本理解任务中提取，涵盖了LLMs的核心能力和各个领域。",
    "en_tdlr": "Introduced the BAMBOO benchmark to comprehensively evaluate the modeling capacities of large language models on long texts, consisting of 10 datasets from 5 different long text understanding tasks, covering core capacities and various domains of LLMs."
}