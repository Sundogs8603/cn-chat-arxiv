{
    "title": "XVO: Generalized Visual Odometry via Cross-Modal Self-Training. (arXiv:2309.16772v1 [cs.CV])",
    "abstract": "We propose XVO, a semi-supervised learning method for training generalized monocular Visual Odometry (VO) models with robust off-the-self operation across diverse datasets and settings. In contrast to standard monocular VO approaches which often study a known calibration within a single dataset, XVO efficiently learns to recover relative pose with real-world scale from visual scene semantics, i.e., without relying on any known camera parameters. We optimize the motion estimation model via self-training from large amounts of unconstrained and heterogeneous dash camera videos available on YouTube. Our key contribution is twofold. First, we empirically demonstrate the benefits of semi-supervised training for learning a general-purpose direct VO regression network. Second, we demonstrate multi-modal supervision, including segmentation, flow, depth, and audio auxiliary prediction tasks, to facilitate generalized representations for the VO task. Specifically, we find audio prediction task to",
    "link": "http://arxiv.org/abs/2309.16772",
    "context": "Title: XVO: Generalized Visual Odometry via Cross-Modal Self-Training. (arXiv:2309.16772v1 [cs.CV])\nAbstract: We propose XVO, a semi-supervised learning method for training generalized monocular Visual Odometry (VO) models with robust off-the-self operation across diverse datasets and settings. In contrast to standard monocular VO approaches which often study a known calibration within a single dataset, XVO efficiently learns to recover relative pose with real-world scale from visual scene semantics, i.e., without relying on any known camera parameters. We optimize the motion estimation model via self-training from large amounts of unconstrained and heterogeneous dash camera videos available on YouTube. Our key contribution is twofold. First, we empirically demonstrate the benefits of semi-supervised training for learning a general-purpose direct VO regression network. Second, we demonstrate multi-modal supervision, including segmentation, flow, depth, and audio auxiliary prediction tasks, to facilitate generalized representations for the VO task. Specifically, we find audio prediction task to",
    "path": "papers/23/09/2309.16772.json",
    "total_tokens": 962,
    "translated_title": "XVO: 通过跨模态自我训练的泛化视觉里程计方法",
    "translated_abstract": "我们提出了XVO，一种半监督学习方法，用于在不同数据集和环境设置下具有强大的自给自足操作的泛化单目视觉里程计（VO）模型的训练。与通常研究单个数据集内已知校准的标准单目VO方法不同，XVO可以高效地通过视觉场景语义（即不依赖于任何已知相机参数）学习恢复相对位姿，并从YouTube上的大量无约束和异构的车载摄像头视频进行自我训练来优化运动估计模型。我们的关键贡献有两个方面：第一，我们经验证明了半监督训练对于学习通用的直接VO回归网络的好处。第二，我们证明了多模式监督的有效性，包括分割、光流、深度和音频辅助预测任务，以促进VO任务的泛化表示。具体而言，我们发现音频预测任务对于总结摘要的关键创新和贡献有促进作用。",
    "tldr": "XVO是一种通过跨模态自我训练的泛化视觉里程计方法，可以在不同数据集和环境设置下具有强大的自给自足操作的训练模型。其关键创新和贡献包括通过半监督训练学习通用的直接VO回归网络以及使用多模式监督任务来促进泛化表示。",
    "en_tdlr": "XVO is a generalized visual odometry method trained through cross-modal self-training, which can operate robustly in diverse datasets and settings. Its key contributions are learning a general-purpose direct VO regression network through semi-supervised training and using multi-modal supervision tasks to facilitate generalized representations."
}