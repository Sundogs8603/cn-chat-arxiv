{
    "title": "The Lipschitz-Variance-Margin Tradeoff for Enhanced Randomized Smoothing. (arXiv:2309.16883v1 [cs.LG])",
    "abstract": "Real-life applications of deep neural networks are hindered by their unsteady predictions when faced with noisy inputs and adversarial attacks. The certified radius is in this context a crucial indicator of the robustness of models. However how to design an efficient classifier with a sufficient certified radius? Randomized smoothing provides a promising framework by relying on noise injection in inputs to obtain a smoothed and more robust classifier. In this paper, we first show that the variance introduced by randomized smoothing closely interacts with two other important properties of the classifier, i.e. its Lipschitz constant and margin. More precisely, our work emphasizes the dual impact of the Lipschitz constant of the base classifier, on both the smoothed classifier and the empirical variance. Moreover, to increase the certified robust radius, we introduce a different simplex projection technique for the base classifier to leverage the variance-margin trade-off thanks to Bernst",
    "link": "http://arxiv.org/abs/2309.16883",
    "context": "Title: The Lipschitz-Variance-Margin Tradeoff for Enhanced Randomized Smoothing. (arXiv:2309.16883v1 [cs.LG])\nAbstract: Real-life applications of deep neural networks are hindered by their unsteady predictions when faced with noisy inputs and adversarial attacks. The certified radius is in this context a crucial indicator of the robustness of models. However how to design an efficient classifier with a sufficient certified radius? Randomized smoothing provides a promising framework by relying on noise injection in inputs to obtain a smoothed and more robust classifier. In this paper, we first show that the variance introduced by randomized smoothing closely interacts with two other important properties of the classifier, i.e. its Lipschitz constant and margin. More precisely, our work emphasizes the dual impact of the Lipschitz constant of the base classifier, on both the smoothed classifier and the empirical variance. Moreover, to increase the certified robust radius, we introduce a different simplex projection technique for the base classifier to leverage the variance-margin trade-off thanks to Bernst",
    "path": "papers/23/09/2309.16883.json",
    "total_tokens": 913,
    "translated_title": "增强随机平滑的Lipschitz-方差-边界权衡",
    "translated_abstract": "面对噪声输入和对抗性攻击时，深度神经网络的实际应用受到其不稳定的预测的阻碍。在这种情况下，认证半径是模型鲁棒性的关键指标。然而，如何设计一个具有足够认证半径的高效分类器呢？随机平滑通过在输入中注入噪声来获得平滑且更鲁棒的分类器的框架提供了有希望的解决方案。本文首先展示了随机平滑引入的方差与分类器的另外两个重要属性，即其Lipschitz常数和边界之间的密切关系。更具体地说，我们的工作强调了基分类器的Lipschitz常数对平滑分类器和经验方差的双重影响。此外，为了增加认证鲁棒半径，我们引入了一种不同的单纯形投影技术，以便通过Bernst的方差-边界权衡来利用基分类器。",
    "tldr": "本文提出了一个增强随机平滑的方法，通过研究随机平滑引入的方差与分类器的Lipschitz常数和边界之间的关系，以及采用单纯形投影技术来增加认证鲁棒半径。",
    "en_tdlr": "This paper proposes an enhanced randomized smoothing method that investigates the relationship between the variance introduced by randomized smoothing and the Lipschitz constant and margin of the classifier, and introduces a simplex projection technique to increase the certified robust radius."
}