{
    "title": "Bypassing the Simulator: Near-Optimal Adversarial Linear Contextual Bandits. (arXiv:2309.00814v1 [cs.LG])",
    "abstract": "We consider the adversarial linear contextual bandit problem, where the loss vectors are selected fully adversarially and the per-round action set (i.e. the context) is drawn from a fixed distribution. Existing methods for this problem either require access to a simulator to generate free i.i.d. contexts, achieve a sub-optimal regret no better than $\\widetilde{O}(T^{\\frac{5}{6}})$, or are computationally inefficient. We greatly improve these results by achieving a regret of $\\widetilde{O}(\\sqrt{T})$ without a simulator, while maintaining computational efficiency when the action set in each round is small. In the special case of sleeping bandits with adversarial loss and stochastic arm availability, our result answers affirmatively the open question by Saha et al. [2020] on whether there exists a polynomial-time algorithm with $poly(d)\\sqrt{T}$ regret. Our approach naturally handles the case where the loss is linear up to an additive misspecification error, and our regret shows near-opt",
    "link": "http://arxiv.org/abs/2309.00814",
    "context": "Title: Bypassing the Simulator: Near-Optimal Adversarial Linear Contextual Bandits. (arXiv:2309.00814v1 [cs.LG])\nAbstract: We consider the adversarial linear contextual bandit problem, where the loss vectors are selected fully adversarially and the per-round action set (i.e. the context) is drawn from a fixed distribution. Existing methods for this problem either require access to a simulator to generate free i.i.d. contexts, achieve a sub-optimal regret no better than $\\widetilde{O}(T^{\\frac{5}{6}})$, or are computationally inefficient. We greatly improve these results by achieving a regret of $\\widetilde{O}(\\sqrt{T})$ without a simulator, while maintaining computational efficiency when the action set in each round is small. In the special case of sleeping bandits with adversarial loss and stochastic arm availability, our result answers affirmatively the open question by Saha et al. [2020] on whether there exists a polynomial-time algorithm with $poly(d)\\sqrt{T}$ regret. Our approach naturally handles the case where the loss is linear up to an additive misspecification error, and our regret shows near-opt",
    "path": "papers/23/09/2309.00814.json",
    "total_tokens": 1012,
    "translated_title": "绕过模拟器: 近似最优的对抗线性情境臂带",
    "translated_abstract": "本文考虑对抗性线性情境臂带问题，其中损失向量完全被对抗地选择，每轮行动集（即情境）从固定分布中抽样。现有针对该问题的方法要么需要访问模拟器生成自由的i.i.d.情境，要么在最优遗憾方面只能达到次优结果，不好于$\\widetilde{O}(T^{\\frac{5}{6}})$，或者计算效率低下。我们通过不使用模拟器，同时保持在每轮行动集较小的情况下计算效率，大大改善了这些结果，使得遗憾度达到$\\widetilde{O}(\\sqrt{T})$。对于具有对抗性损失和随机臂可用性的睡眠臂带特例，我们的结果肯定地回答了Saha等人所提出的关于是否存在具有$poly(d)\\sqrt{T}$遗憾度的多项式时间算法的开放问题。我们的方法自然地处理了损失近似为线性的情况，同时我们的遗憾度接近最优。",
    "tldr": "本文提出了一种绕过模拟器的对抗线性情境臂带算法，能够在每轮行动集较小的情况下实现$\\widetilde{O}(\\sqrt{T})$的遗憾度。这个算法还能够处理损失线性近似以及对抗性损失和随机臂可用性的特殊情况。"
}