{
    "title": "LeBenchmark 2.0: a Standardized, Replicable and Enhanced Framework for Self-supervised Representations of French Speech",
    "abstract": "arXiv:2309.05472v2 Announce Type: replace-cross  Abstract: Self-supervised learning (SSL) is at the origin of unprecedented improvements in many different domains including computer vision and natural language processing. Speech processing drastically benefitted from SSL as most of the current domain-related tasks are now being approached with pre-trained models. This work introduces LeBenchmark 2.0 an open-source framework for assessing and building SSL-equipped French speech technologies. It includes documented, large-scale and heterogeneous corpora with up to 14,000 hours of heterogeneous speech, ten pre-trained SSL wav2vec 2.0 models containing from 26 million to one billion learnable parameters shared with the community, and an evaluation protocol made of six downstream tasks to complement existing benchmarks. LeBenchmark 2.0 also presents unique perspectives on pre-trained SSL models for speech with the investigation of frozen versus fine-tuned downstream models, task-agnostic ve",
    "link": "https://arxiv.org/abs/2309.05472",
    "context": "Title: LeBenchmark 2.0: a Standardized, Replicable and Enhanced Framework for Self-supervised Representations of French Speech\nAbstract: arXiv:2309.05472v2 Announce Type: replace-cross  Abstract: Self-supervised learning (SSL) is at the origin of unprecedented improvements in many different domains including computer vision and natural language processing. Speech processing drastically benefitted from SSL as most of the current domain-related tasks are now being approached with pre-trained models. This work introduces LeBenchmark 2.0 an open-source framework for assessing and building SSL-equipped French speech technologies. It includes documented, large-scale and heterogeneous corpora with up to 14,000 hours of heterogeneous speech, ten pre-trained SSL wav2vec 2.0 models containing from 26 million to one billion learnable parameters shared with the community, and an evaluation protocol made of six downstream tasks to complement existing benchmarks. LeBenchmark 2.0 also presents unique perspectives on pre-trained SSL models for speech with the investigation of frozen versus fine-tuned downstream models, task-agnostic ve",
    "path": "papers/23/09/2309.05472.json",
    "total_tokens": 916,
    "translated_title": "LeBenchmark 2.0：用于自监督法表示法语语音的标准化、可复制和增强框架",
    "translated_abstract": "自监督学习（SSL）是许多不同领域，包括计算机视觉和自然语言处理等领域取得了前所未有的进展。语音处理极大受益于SSL，因为当前大部分领域相关任务现在都是用预训练模型处理的。本文介绍了LeBenchmark 2.0，这是一个用于评估和构建配备SSL的法语语音技术的开源框架。它包括有文档记录、大规模和异构语料库，涵盖长达14,000小时的异构语音，十个预训练的SSL wav2vec 2.0 模型，包含从2600万到10亿可学习参数与社区共享，并且包含由六个下游任务组成的评估协议，以补充现有基准。LeBenchmark 2.0 还对于语音的预训练SSL模型提出了独特的视角，探讨了冻结与微调下游模型以及任务不可知的相关性。",
    "tldr": "LeBenchmark 2.0是一个开源框架，用于评估和构建法语语音技术的自监督学习，提供大规模语料库、预训练模型和评估协议，并探讨了预训练SSL模型的独特视角。",
    "en_tdlr": "LeBenchmark 2.0 is an open-source framework for assessing and building self-supervised French speech technologies, providing large-scale corpora, pre-trained models, and an evaluation protocol, while exploring unique perspectives on pre-trained SSL models."
}