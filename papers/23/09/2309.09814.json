{
    "title": "Convolutional Deep Kernel Machines. (arXiv:2309.09814v1 [stat.ML])",
    "abstract": "Deep kernel machines (DKMs) are a recently introduced kernel method with the flexibility of other deep models including deep NNs and deep Gaussian processes. DKMs work purely with kernels, never with features, and are therefore different from other methods ranging from NNs to deep kernel learning and even deep Gaussian processes, which all use features as a fundamental component. Here, we introduce convolutional DKMs, along with an efficient inter-domain inducing point approximation scheme. Further, we develop and experimentally assess a number of model variants, including 9 different types of normalisation designed for the convolutional DKMs, two likelihoods, and two different types of top-layer. The resulting models achieve around 99% test accuracy on MNIST, 92% on CIFAR-10 and 71% on CIFAR-100, despite training in only around 28 GPU hours, 1-2 orders of magnitude faster than full NNGP / NTK / Myrtle kernels, whilst achieving comparable performance.",
    "link": "http://arxiv.org/abs/2309.09814",
    "context": "Title: Convolutional Deep Kernel Machines. (arXiv:2309.09814v1 [stat.ML])\nAbstract: Deep kernel machines (DKMs) are a recently introduced kernel method with the flexibility of other deep models including deep NNs and deep Gaussian processes. DKMs work purely with kernels, never with features, and are therefore different from other methods ranging from NNs to deep kernel learning and even deep Gaussian processes, which all use features as a fundamental component. Here, we introduce convolutional DKMs, along with an efficient inter-domain inducing point approximation scheme. Further, we develop and experimentally assess a number of model variants, including 9 different types of normalisation designed for the convolutional DKMs, two likelihoods, and two different types of top-layer. The resulting models achieve around 99% test accuracy on MNIST, 92% on CIFAR-10 and 71% on CIFAR-100, despite training in only around 28 GPU hours, 1-2 orders of magnitude faster than full NNGP / NTK / Myrtle kernels, whilst achieving comparable performance.",
    "path": "papers/23/09/2309.09814.json",
    "total_tokens": 963,
    "translated_title": "卷积深度核机器",
    "translated_abstract": "深度核机器(DKMs)是一种最近引入的具有其他深度模型灵活性的核方法，包括深度神经网络和深度高斯过程。DKMs纯粹使用核，而不使用特征，因此与其他方法（从神经网络到深度核学习甚至深度高斯过程）不同，后者都使用特征作为基本组成部分。在这里，我们引入了卷积DKMs，并配以一种高效的跨域诱导点近似方案。此外，我们还开发并实验评估了许多模型变体，包括9种不同类型的为卷积DKMs设计的归一化方法，两种似然函数和两种不同类型的顶层。尽管只在约28个GPU小时内训练（比完全的NNGP / NTK / Myrtle kernel快1-2个数量级），但得到的模型在MNIST上实现了约99％的测试准确性，在CIFAR-10上为92％，在CIFAR-100上为71％，同时达到可比较的性能。",
    "tldr": "这项研究介绍了一种称为卷积深度核机器的新型核方法，该方法纯粹使用核而不使用特征，通过高效的跨域诱导点近似方案和多种模型变体的设计，达到了在MNIST、CIFAR-10和CIFAR-100上接近甚至超过其他方法的测试准确率。",
    "en_tdlr": "This research introduces a new kernel method called Convolutional Deep Kernel Machines (DKMs), which purely uses kernels instead of features. Through an efficient inter-domain inducing point approximation scheme and the design of various model variants, it achieves test accuracies close to or surpassing other methods on MNIST, CIFAR-10, and CIFAR-100."
}