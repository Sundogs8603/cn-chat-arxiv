{
    "title": "A Theoretical and Practical Framework for Evaluating Uncertainty Calibration in Object Detection. (arXiv:2309.00464v1 [cs.CV])",
    "abstract": "The proliferation of Deep Neural Networks has resulted in machine learning systems becoming increasingly more present in various real-world applications. Consequently, there is a growing demand for highly reliable models in these domains, making the problem of uncertainty calibration pivotal, when considering the future of deep learning. This is especially true when considering object detection systems, that are commonly present in safety-critical application such as autonomous driving and robotics. For this reason, this work presents a novel theoretical and practical framework to evaluate object detection systems in the context of uncertainty calibration. The robustness of the proposed uncertainty calibration metrics is shown through a series of representative experiments. Code for the proposed uncertainty calibration metrics at: https://github.com/pedrormconde/Uncertainty_Calibration_Object_Detection.",
    "link": "http://arxiv.org/abs/2309.00464",
    "context": "Title: A Theoretical and Practical Framework for Evaluating Uncertainty Calibration in Object Detection. (arXiv:2309.00464v1 [cs.CV])\nAbstract: The proliferation of Deep Neural Networks has resulted in machine learning systems becoming increasingly more present in various real-world applications. Consequently, there is a growing demand for highly reliable models in these domains, making the problem of uncertainty calibration pivotal, when considering the future of deep learning. This is especially true when considering object detection systems, that are commonly present in safety-critical application such as autonomous driving and robotics. For this reason, this work presents a novel theoretical and practical framework to evaluate object detection systems in the context of uncertainty calibration. The robustness of the proposed uncertainty calibration metrics is shown through a series of representative experiments. Code for the proposed uncertainty calibration metrics at: https://github.com/pedrormconde/Uncertainty_Calibration_Object_Detection.",
    "path": "papers/23/09/2309.00464.json",
    "total_tokens": 751,
    "translated_title": "评估目标检测中的不确定性校准的理论和实践框架",
    "translated_abstract": "深度神经网络的普及导致机器学习系统在各种实际应用中越来越常见。因此，在考虑深度学习的未来时，不确定性校准问题成为至关重要的问题，尤其是在考虑到在自动驾驶和机器人等安全关键应用中常见的目标检测系统。基于此，本研究提出了一种新颖的理论和实践框架，以评估目标检测系统的不确定性校准。通过一系列代表性实验展示了所提出不确定性校准指标的鲁棒性。所提出不确定性校准指标的代码可在以下链接找到：https://github.com/pedrormconde/Uncertainty_Calibration_Object_Detection。",
    "tldr": "本文提出了一种评估目标检测中不确定性校准的理论和实践框架，并通过实验证明了所提出指标的有效性。",
    "en_tdlr": "This paper presents a theoretical and practical framework for evaluating uncertainty calibration in object detection and demonstrates the effectiveness of the proposed metrics through experiments."
}