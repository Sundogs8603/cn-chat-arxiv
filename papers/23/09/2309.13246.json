{
    "title": "Can I Trust the Explanations? Investigating Explainable Machine Learning Methods for Monotonic Models. (arXiv:2309.13246v1 [cs.LG])",
    "abstract": "In recent years, explainable machine learning methods have been very successful. Despite their success, most explainable machine learning methods are applied to black-box models without any domain knowledge. By incorporating domain knowledge, science-informed machine learning models have demonstrated better generalization and interpretation. But do we obtain consistent scientific explanations if we apply explainable machine learning methods to science-informed machine learning models? This question is addressed in the context of monotonic models that exhibit three different types of monotonicity. To demonstrate monotonicity, we propose three axioms. Accordingly, this study shows that when only individual monotonicity is involved, the baseline Shapley value provides good explanations; however, when strong pairwise monotonicity is involved, the Integrated gradients method provides reasonable explanations on average.",
    "link": "http://arxiv.org/abs/2309.13246",
    "context": "Title: Can I Trust the Explanations? Investigating Explainable Machine Learning Methods for Monotonic Models. (arXiv:2309.13246v1 [cs.LG])\nAbstract: In recent years, explainable machine learning methods have been very successful. Despite their success, most explainable machine learning methods are applied to black-box models without any domain knowledge. By incorporating domain knowledge, science-informed machine learning models have demonstrated better generalization and interpretation. But do we obtain consistent scientific explanations if we apply explainable machine learning methods to science-informed machine learning models? This question is addressed in the context of monotonic models that exhibit three different types of monotonicity. To demonstrate monotonicity, we propose three axioms. Accordingly, this study shows that when only individual monotonicity is involved, the baseline Shapley value provides good explanations; however, when strong pairwise monotonicity is involved, the Integrated gradients method provides reasonable explanations on average.",
    "path": "papers/23/09/2309.13246.json",
    "total_tokens": 828,
    "translated_title": "我可以相信解释吗？研究可解释机器学习方法在单调模型中的应用",
    "translated_abstract": "近年来，可解释机器学习方法取得了很大成功。尽管成功，但大多数可解释机器学习方法都是应用于黑盒模型而没有任何领域知识。通过结合领域知识，以科学为基础的机器学习模型展现出更好的泛化和解释性。但是，如果我们将可解释的机器学习方法应用于基于科学知识的机器学习模型，我们能获得一致的科学解释吗？这个问题在展示三种不同类型的单调模型的背景下得到了回答。为了展示单调性，我们提出了三个公理。相应地，这项研究表明，当仅涉及个体单调性时，基准Shapley值提供了良好的解释；然而，当涉及强大的成对单调性时，集成梯度方法在平均上提供了合理的解释。",
    "tldr": "本研究研究了可解释机器学习方法在单调模型中的应用，发现了解释的可靠性和模型的单调性之间的关系。",
    "en_tdlr": "This study investigates the application of explainable machine learning methods in monotonic models, revealing the relationship between the reliability of explanations and the monotonicity of the models."
}