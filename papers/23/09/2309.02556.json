{
    "title": "Domain Adaptation for Efficiently Fine-tuning Vision Transformer with Encrypted Images. (arXiv:2309.02556v1 [cs.CV])",
    "abstract": "In recent years, deep neural networks (DNNs) trained with transformed data have been applied to various applications such as privacy-preserving learning, access control, and adversarial defenses. However, the use of transformed data decreases the performance of models. Accordingly, in this paper, we propose a novel method for fine-tuning models with transformed images under the use of the vision transformer (ViT). The proposed domain adaptation method does not cause the accuracy degradation of models, and it is carried out on the basis of the embedding structure of ViT. In experiments, we confirmed that the proposed method prevents accuracy degradation even when using encrypted images with the CIFAR-10 and CIFAR-100 datasets.",
    "link": "http://arxiv.org/abs/2309.02556",
    "context": "Title: Domain Adaptation for Efficiently Fine-tuning Vision Transformer with Encrypted Images. (arXiv:2309.02556v1 [cs.CV])\nAbstract: In recent years, deep neural networks (DNNs) trained with transformed data have been applied to various applications such as privacy-preserving learning, access control, and adversarial defenses. However, the use of transformed data decreases the performance of models. Accordingly, in this paper, we propose a novel method for fine-tuning models with transformed images under the use of the vision transformer (ViT). The proposed domain adaptation method does not cause the accuracy degradation of models, and it is carried out on the basis of the embedding structure of ViT. In experiments, we confirmed that the proposed method prevents accuracy degradation even when using encrypted images with the CIFAR-10 and CIFAR-100 datasets.",
    "path": "papers/23/09/2309.02556.json",
    "total_tokens": 777,
    "translated_title": "使用加密图像有效微调视觉Transformer的领域自适应",
    "translated_abstract": "近年来，使用转换数据训练的深度神经网络(DNN)已被应用于隐私保护学习、访问控制和对抗防御等各种应用。然而，使用转换数据会降低模型的性能。因此，在本文中，我们提出了一种新颖的方法，利用视觉Transformer(ViT)对使用转换图像进行模型微调。所提出的领域自适应方法不会导致模型准确性的降低，并且是在ViT的嵌入结构基础上进行的。在实验中，我们验证了所提出的方法在使用具有CIFAR-10和CIFAR-100数据集的加密图像时防止准确性降低。",
    "tldr": "本文提出了一种使用视觉Transformer(ViT)进行模型微调的领域自适应方法，可解决使用转换图像训练模型导致准确性下降的问题，实验证明该方法在使用加密图像时也能保持模型的准确性。",
    "en_tdlr": "This paper presents a domain adaptation method for fine-tuning models using vision Transformer (ViT), which addresses the issue of decreased accuracy when training models with transformed images. The proposed method maintains the accuracy even when using encrypted images, as demonstrated in the experiments."
}