{
    "title": "Exploring Learned Representations of Neural Networks with Principal Component Analysis. (arXiv:2309.15328v1 [cs.LG])",
    "abstract": "Understanding feature representation for deep neural networks (DNNs) remains an open question within the general field of explainable AI. We use principal component analysis (PCA) to study the performance of a k-nearest neighbors classifier (k-NN), nearest class-centers classifier (NCC), and support vector machines on the learned layer-wise representations of a ResNet-18 trained on CIFAR-10. We show that in certain layers, as little as 20% of the intermediate feature-space variance is necessary for high-accuracy classification and that across all layers, the first ~100 PCs completely determine the performance of the k-NN and NCC classifiers. We relate our findings to neural collapse and provide partial evidence for the related phenomenon of intermediate neural collapse. Our preliminary work provides three distinct yet interpretable surrogate models for feature representation with an affine linear model the best performing. We also show that leveraging several surrogate models affords u",
    "link": "http://arxiv.org/abs/2309.15328",
    "context": "Title: Exploring Learned Representations of Neural Networks with Principal Component Analysis. (arXiv:2309.15328v1 [cs.LG])\nAbstract: Understanding feature representation for deep neural networks (DNNs) remains an open question within the general field of explainable AI. We use principal component analysis (PCA) to study the performance of a k-nearest neighbors classifier (k-NN), nearest class-centers classifier (NCC), and support vector machines on the learned layer-wise representations of a ResNet-18 trained on CIFAR-10. We show that in certain layers, as little as 20% of the intermediate feature-space variance is necessary for high-accuracy classification and that across all layers, the first ~100 PCs completely determine the performance of the k-NN and NCC classifiers. We relate our findings to neural collapse and provide partial evidence for the related phenomenon of intermediate neural collapse. Our preliminary work provides three distinct yet interpretable surrogate models for feature representation with an affine linear model the best performing. We also show that leveraging several surrogate models affords u",
    "path": "papers/23/09/2309.15328.json",
    "total_tokens": 924,
    "translated_title": "使用主成分分析探索神经网络的学习表示",
    "translated_abstract": "在可解释的AI领域中，理解深度神经网络(DNNs)的特征表示仍然是一个开放的问题。我们使用主成分分析(PCA)来研究在CIFAR-10上训练的ResNet-18学习的逐层表示在k最近邻分类器(k-NN)、最近类中心分类器(NCC)和支持向量机的性能。我们发现，在某些层中，只有20%的中间特征空间方差就足以实现高准确度的分类，并且在所有层中，前100个主成分完全决定了k-NN和NCC分类器的性能。我们将我们的发现与神经网络收缩联系起来，并提供了中间神经网络收缩相关现象的部分证据。我们的初步工作提供了三个不同但可解释的特征表示替代模型，其中最佳性能是一个仿射线性模型。我们还证明，利用几个替代模型可以提供更好的性能。",
    "tldr": "这项研究使用主成分分析探索了深度神经网络的特征表示，并发现在某些层中只需要20%的特征空间方差就能实现高准确度分类。该研究还提供了三个可解释的替代模型，并发现仿射线性模型表现最佳。"
}