{
    "title": "Fine-grained Late-interaction Multi-modal Retrieval for Retrieval Augmented Visual Question Answering. (arXiv:2309.17133v1 [cs.CL])",
    "abstract": "Knowledge-based Visual Question Answering (KB-VQA) requires VQA systems to utilize knowledge from existing knowledge bases to answer visually-grounded questions. Retrieval-Augmented Visual Question Answering (RA-VQA), a strong framework to tackle KB-VQA, first retrieves related documents with Dense Passage Retrieval (DPR) and then uses them to answer questions. This paper proposes Fine-grained Late-interaction Multi-modal Retrieval (FLMR) which significantly improves knowledge retrieval in RA-VQA. FLMR addresses two major limitations in RA-VQA's retriever: (1) the image representations obtained via image-to-text transforms can be incomplete and inaccurate and (2) relevance scores between queries and documents are computed with one-dimensional embeddings, which can be insensitive to finer-grained relevance. FLMR overcomes these limitations by obtaining image representations that complement those from the image-to-text transforms using a vision model aligned with an existing text-based r",
    "link": "http://arxiv.org/abs/2309.17133",
    "context": "Title: Fine-grained Late-interaction Multi-modal Retrieval for Retrieval Augmented Visual Question Answering. (arXiv:2309.17133v1 [cs.CL])\nAbstract: Knowledge-based Visual Question Answering (KB-VQA) requires VQA systems to utilize knowledge from existing knowledge bases to answer visually-grounded questions. Retrieval-Augmented Visual Question Answering (RA-VQA), a strong framework to tackle KB-VQA, first retrieves related documents with Dense Passage Retrieval (DPR) and then uses them to answer questions. This paper proposes Fine-grained Late-interaction Multi-modal Retrieval (FLMR) which significantly improves knowledge retrieval in RA-VQA. FLMR addresses two major limitations in RA-VQA's retriever: (1) the image representations obtained via image-to-text transforms can be incomplete and inaccurate and (2) relevance scores between queries and documents are computed with one-dimensional embeddings, which can be insensitive to finer-grained relevance. FLMR overcomes these limitations by obtaining image representations that complement those from the image-to-text transforms using a vision model aligned with an existing text-based r",
    "path": "papers/23/09/2309.17133.json",
    "total_tokens": 961,
    "translated_title": "精细化的后期交互多模检索用于检索增强视觉问答",
    "translated_abstract": "基于知识的视觉问答（KB-VQA）要求VQA系统利用现有知识库中的知识来回答与视觉相关的问题。检索增强的视觉问答（RA-VQA）是一种强大的框架，用于解决KB-VQA问题，首先使用密集段落检索（DPR）检索相关文档，然后利用这些文档回答问题。本文提出了精细化的后期交互多模检索（FLMR），显著改进了RA-VQA中的知识检索。FLMR解决了RA-VQA检索器中的两个主要限制：（1）通过图像到文本转换获得的图像表示可能不完整和不准确，（2）查询和文档之间的相关性分数是通过一维嵌入计算的，可能对更细粒度的相关性不敏感。FLMR通过使用与现有基于文本的模型相对齐的视觉模型获取补充图像表示来克服这些限制。",
    "tldr": "本文提出了一种精细化的后期交互多模检索方法（FLMR）来改进检索增强的视觉问答中的知识检索。FLMR通过获取补充的图像表示并使用与现有基于文本的模型相对齐的视觉模型，解决了RA-VQA中检索器的两个主要限制。",
    "en_tdlr": "This paper proposes Fine-grained Late-interaction Multi-modal Retrieval (FLMR) to improve knowledge retrieval in Retrieval-Augmented Visual Question Answering (RA-VQA). FLMR overcomes the limitations of the retriever in RA-VQA by obtaining complementary image representations and aligning a vision model with an existing text-based model."
}