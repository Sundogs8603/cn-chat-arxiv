{
    "title": "Framework-Based Qualitative Analysis of Free Responses of Large Language Models: Algorithmic Fidelity. (arXiv:2309.06364v1 [cs.CL])",
    "abstract": "Today, using Large-scale generative Language Models (LLMs) it is possible to simulate free responses to interview questions like those traditionally analyzed using qualitative research methods. Qualitative methodology encompasses a broad family of techniques involving manual analysis of open-ended interviews or conversations conducted freely in natural language. Here we consider whether artificial \"silicon participants\" generated by LLMs may be productively studied using qualitative methods aiming to produce insights that could generalize to real human populations. The key concept in our analysis is algorithmic fidelity, a term introduced by Argyle et al. (2023) capturing the degree to which LLM-generated outputs mirror human sub-populations' beliefs and attitudes. By definition, high algorithmic fidelity suggests latent beliefs elicited from LLMs may generalize to real humans, whereas low algorithmic fidelity renders such research invalid. Here we used an LLM to generate interviews wi",
    "link": "http://arxiv.org/abs/2309.06364",
    "context": "Title: Framework-Based Qualitative Analysis of Free Responses of Large Language Models: Algorithmic Fidelity. (arXiv:2309.06364v1 [cs.CL])\nAbstract: Today, using Large-scale generative Language Models (LLMs) it is possible to simulate free responses to interview questions like those traditionally analyzed using qualitative research methods. Qualitative methodology encompasses a broad family of techniques involving manual analysis of open-ended interviews or conversations conducted freely in natural language. Here we consider whether artificial \"silicon participants\" generated by LLMs may be productively studied using qualitative methods aiming to produce insights that could generalize to real human populations. The key concept in our analysis is algorithmic fidelity, a term introduced by Argyle et al. (2023) capturing the degree to which LLM-generated outputs mirror human sub-populations' beliefs and attitudes. By definition, high algorithmic fidelity suggests latent beliefs elicited from LLMs may generalize to real humans, whereas low algorithmic fidelity renders such research invalid. Here we used an LLM to generate interviews wi",
    "path": "papers/23/09/2309.06364.json",
    "total_tokens": 873,
    "translated_title": "基于框架的大型语言模型自由回答的定性分析：算法保真度",
    "translated_abstract": "如今，使用大规模生成式语言模型（LLMs），可以模拟自由回答面试问题，就像传统上使用定性研究方法分析的那样。定性方法涵盖了一系列技术，涉及对开放式访谈或自由进行的自然语言对话的手动分析。本文考虑通过定性方法对LLMs生成的\"硅参与者\"进行研究，从而产生可能可以推广到真实人群的洞察力。我们分析的关键概念是算法保真度，这是由Argyle等人（2023年）引入的一个术语，用于描述LLM生成的输出与人类亚群体的信念和态度的程度相吻合。根据定义，高算法保真度表明从LLMs中提取的潜在信念可能可以推广到真实人类，而低算法保真度则使得这样的研究无效。本文使用LLM生成面试问答，...",
    "tldr": "本文通过定性分析研究了大型语言模型生成的自由回答，重点考察了算法保真度，并提出高算法保真度可以推广到真实人类的观点。这对于使用语言模型研究人类行为具有重要意义。",
    "en_tdlr": "This paper presents a qualitative analysis of free responses generated by large language models, with a focus on algorithmic fidelity and the potential generalization to real human populations."
}