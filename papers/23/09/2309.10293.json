{
    "title": "QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems. (arXiv:2309.10293v1 [cs.AI])",
    "abstract": "Artificial Intelligence techniques can be used to classify a patient's physical activities and predict vital signs for remote patient monitoring. Regression analysis based on non-linear models like deep learning models has limited explainability due to its black-box nature. This can require decision-makers to make blind leaps of faith based on non-linear model results, especially in healthcare applications. In non-invasive monitoring, patient data from tracking sensors and their predisposing clinical attributes act as input features for predicting future vital signs. Explaining the contributions of various features to the overall output of the monitoring application is critical for a clinician's decision-making. In this study, an Explainable AI for Quantitative analysis (QXAI) framework is proposed with post-hoc model explainability and intrinsic explainability for regression and classification tasks in a supervised learning approach. This was achieved by utilizing the Shapley values c",
    "link": "http://arxiv.org/abs/2309.10293",
    "context": "Title: QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems. (arXiv:2309.10293v1 [cs.AI])\nAbstract: Artificial Intelligence techniques can be used to classify a patient's physical activities and predict vital signs for remote patient monitoring. Regression analysis based on non-linear models like deep learning models has limited explainability due to its black-box nature. This can require decision-makers to make blind leaps of faith based on non-linear model results, especially in healthcare applications. In non-invasive monitoring, patient data from tracking sensors and their predisposing clinical attributes act as input features for predicting future vital signs. Explaining the contributions of various features to the overall output of the monitoring application is critical for a clinician's decision-making. In this study, an Explainable AI for Quantitative analysis (QXAI) framework is proposed with post-hoc model explainability and intrinsic explainability for regression and classification tasks in a supervised learning approach. This was achieved by utilizing the Shapley values c",
    "path": "papers/23/09/2309.10293.json",
    "total_tokens": 896,
    "translated_title": "QXAI：可解释的人工智能框架用于患者监测系统中的定量分析",
    "translated_abstract": "人工智能技术可用于对患者的身体活动进行分类和预测远程患者监测的生命体征。基于非线性模型（如深度学习模型）的回归分析由于其黑盒性质而具有有限的可解释性。这可能需要决策者在医疗应用中基于非线性模型结果盲目决策。在非侵入式监测中，跟踪传感器获取的患者数据和其相关临床特征作为预测未来生命体征的输入特征。解释各种特征对监测应用整体输出的贡献对于临床医师的决策至关重要。本研究提出了一种QXAI框架，用于监督学习方法中回归和分类任务的事后模型可解释性和内在可解释性。这是通过利用Shapley值进行实现的。",
    "tldr": "该论文提出了一种QXAI框架，用于患者监测系统中的定量分析。该框架具有可解释性，对于决策者在医疗应用中基于非线性模型结果进行决策非常重要。"
}