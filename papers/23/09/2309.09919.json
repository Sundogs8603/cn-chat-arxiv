{
    "title": "Plug in the Safety Chip: Enforcing Constraints for LLM-driven Robot Agents. (arXiv:2309.09919v2 [cs.RO] UPDATED)",
    "abstract": "Recent advancements in large language models (LLMs) have enabled a new research domain, LLM agents, for solving robotics and planning tasks by leveraging the world knowledge and general reasoning abilities of LLMs obtained during pretraining. However, while considerable effort has been made to teach the robot the \"dos,\" the \"don'ts\" received relatively less attention. We argue that, for any practical usage, it is as crucial to teach the robot the \"don'ts\": conveying explicit instructions about prohibited actions, assessing the robot's comprehension of these restrictions, and, most importantly, ensuring compliance. Moreover, verifiable safe operation is essential for deployments that satisfy worldwide standards such as ISO 61508, which defines standards for safely deploying robots in industrial factory environments worldwide. Aiming at deploying the LLM agents in a collaborative environment, we propose a queryable safety constraint module based on linear temporal logic (LTL) that simult",
    "link": "http://arxiv.org/abs/2309.09919",
    "context": "Title: Plug in the Safety Chip: Enforcing Constraints for LLM-driven Robot Agents. (arXiv:2309.09919v2 [cs.RO] UPDATED)\nAbstract: Recent advancements in large language models (LLMs) have enabled a new research domain, LLM agents, for solving robotics and planning tasks by leveraging the world knowledge and general reasoning abilities of LLMs obtained during pretraining. However, while considerable effort has been made to teach the robot the \"dos,\" the \"don'ts\" received relatively less attention. We argue that, for any practical usage, it is as crucial to teach the robot the \"don'ts\": conveying explicit instructions about prohibited actions, assessing the robot's comprehension of these restrictions, and, most importantly, ensuring compliance. Moreover, verifiable safe operation is essential for deployments that satisfy worldwide standards such as ISO 61508, which defines standards for safely deploying robots in industrial factory environments worldwide. Aiming at deploying the LLM agents in a collaborative environment, we propose a queryable safety constraint module based on linear temporal logic (LTL) that simult",
    "path": "papers/23/09/2309.09919.json",
    "total_tokens": 953,
    "translated_title": "插入安全芯片：强制LLM驱动的机器人代理的约束条件翻译",
    "translated_abstract": "最近大型语言模型（LLMs）的进展使得一种新的研究领域成为可能，即通过利用预训练期间LLMs获得的世界知识和一般推理能力，解决机器人和规划任务的LLM代理。然而，虽然已经付出了相当大的努力来教会机器人\"做什么\"，但对\"不要做什么\"的关注相对较少。我们认为，对于任何实际应用而言，教机器人\"不要做什么\"同样重要：传达有关禁止行为的明确指示，评估机器人对这些限制的理解，并且最重要的是确保遵守这些限制。此外，可验证的安全操作对于满足ISO 61508等全球工业工厂环境中的机器人安全部署标准至关重要。针对将LLM代理部署在协同环境中，我们提出了基于线性时态逻辑（LTL）的可查询安全约束模块，同时确保实现实时约束检查和自适应运行。",
    "tldr": "这篇论文提出了一种基于线性时态逻辑（LTL）的可查询安全约束模块，用于强制LLM驱动的机器人代理遵守禁止行为的限制，并确保满足全球工业工厂环境中的安全部署标准。",
    "en_tdlr": "This paper proposes a queryable safety constraint module based on linear temporal logic (LTL) to enforce prohibitions on actions for LLM-driven robot agents, and ensures compliance with safety deployment standards in global industrial factory environments."
}