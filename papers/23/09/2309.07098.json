{
    "title": "Mitigating Hallucinations and Off-target Machine Translation with Source-Contrastive and Language-Contrastive Decoding. (arXiv:2309.07098v1 [cs.CL])",
    "abstract": "Hallucinations and off-target translation remain unsolved problems in machine translation, especially for low-resource languages and massively multilingual models. In this paper, we introduce methods to mitigate both failure cases with a modified decoding objective, without requiring retraining or external models. In source-contrastive decoding, we search for a translation that is probable given the correct input, but improbable given a random input segment, hypothesising that hallucinations will be similarly probable given either. In language-contrastive decoding, we search for a translation that is probable, but improbable given the wrong language indicator token. In experiments on M2M-100 (418M) and SMaLL-100, we find that these methods effectively suppress hallucinations and off-target translations, improving chrF2 by 1.7 and 1.4 points on average across 57 tested translation directions. In a proof of concept on English--German, we also show that we can suppress off-target translat",
    "link": "http://arxiv.org/abs/2309.07098",
    "context": "Title: Mitigating Hallucinations and Off-target Machine Translation with Source-Contrastive and Language-Contrastive Decoding. (arXiv:2309.07098v1 [cs.CL])\nAbstract: Hallucinations and off-target translation remain unsolved problems in machine translation, especially for low-resource languages and massively multilingual models. In this paper, we introduce methods to mitigate both failure cases with a modified decoding objective, without requiring retraining or external models. In source-contrastive decoding, we search for a translation that is probable given the correct input, but improbable given a random input segment, hypothesising that hallucinations will be similarly probable given either. In language-contrastive decoding, we search for a translation that is probable, but improbable given the wrong language indicator token. In experiments on M2M-100 (418M) and SMaLL-100, we find that these methods effectively suppress hallucinations and off-target translations, improving chrF2 by 1.7 and 1.4 points on average across 57 tested translation directions. In a proof of concept on English--German, we also show that we can suppress off-target translat",
    "path": "papers/23/09/2309.07098.json",
    "total_tokens": 981,
    "translated_title": "通过源对比和语言对比解码来缓解幻觉和偏离目标的机器翻译问题",
    "translated_abstract": "在机器翻译中，幻觉和偏离目标的翻译仍然是一个未解决的问题，特别是对于低资源语言和大规模多语言模型。本文介绍了一种修改的解码目标来缓解这两种失败情况的方法，而不需要重新训练或外部模型。在源对比解码中，我们寻找一个翻译，在给定正确输入时是可信的，但在随机输入片段给定时是不可信的，假设幻觉在任何情况下都是同样可信的。在语言对比解码中，我们寻找一个翻译，在给定正确语言指示符令牌时是可信的，但给定错误语言指示符令牌时是不可信的。在对M2M-100 (418M)和SMaLL-100进行实验后，我们发现这些方法有效地抑制了幻觉和偏离目标的翻译，平均在57个测试的翻译方向上提高了1.7和1.4个chrF2分数。在英德语言对的一个概念验证中，我们还展示了我们可以抑制偏离目标的翻译。",
    "tldr": "本文介绍了一种通过源对比和语言对比解码来解决机器翻译中幻觉和偏离目标的问题的方法，实验证明这些方法能有效地抑制幻觉和偏离目标的翻译。",
    "en_tdlr": "This paper introduces methods to mitigate the problems of hallucinations and off-target translations in machine translation by using source-contrastive and language-contrastive decoding. Experimental results show that these methods effectively suppress hallucinations and off-target translations."
}