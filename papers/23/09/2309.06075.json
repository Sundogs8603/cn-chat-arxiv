{
    "title": "A2V: A Semi-Supervised Domain Adaptation Framework for Brain Vessel Segmentation via Two-Phase Training Angiography-to-Venography Translation. (arXiv:2309.06075v1 [eess.IV])",
    "abstract": "We present a semi-supervised domain adaptation framework for brain vessel segmentation from different image modalities. Existing state-of-the-art methods focus on a single modality, despite the wide range of available cerebrovascular imaging techniques. This can lead to significant distribution shifts that negatively impact the generalization across modalities. By relying on annotated angiographies and a limited number of annotated venographies, our framework accomplishes image-to-image translation and semantic segmentation, leveraging a disentangled and semantically rich latent space to represent heterogeneous data and perform image-level adaptation from source to target domains. Moreover, we reduce the typical complexity of cycle-based architectures and minimize the use of adversarial training, which allows us to build an efficient and intuitive model with stable training. We evaluate our method on magnetic resonance angiographies and venographies. While achieving state-of-the-art pe",
    "link": "http://arxiv.org/abs/2309.06075",
    "context": "Title: A2V: A Semi-Supervised Domain Adaptation Framework for Brain Vessel Segmentation via Two-Phase Training Angiography-to-Venography Translation. (arXiv:2309.06075v1 [eess.IV])\nAbstract: We present a semi-supervised domain adaptation framework for brain vessel segmentation from different image modalities. Existing state-of-the-art methods focus on a single modality, despite the wide range of available cerebrovascular imaging techniques. This can lead to significant distribution shifts that negatively impact the generalization across modalities. By relying on annotated angiographies and a limited number of annotated venographies, our framework accomplishes image-to-image translation and semantic segmentation, leveraging a disentangled and semantically rich latent space to represent heterogeneous data and perform image-level adaptation from source to target domains. Moreover, we reduce the typical complexity of cycle-based architectures and minimize the use of adversarial training, which allows us to build an efficient and intuitive model with stable training. We evaluate our method on magnetic resonance angiographies and venographies. While achieving state-of-the-art pe",
    "path": "papers/23/09/2309.06075.json",
    "total_tokens": 1034,
    "translated_title": "A2V: 一种半监督领域自适应框架用于不同图像模态的脑血管分割，通过二阶段训练从血管造影到静脉造影的转换",
    "translated_abstract": "我们提出了一种半监督领域自适应框架，用于从不同图像模态中分割脑血管。现有的最先进方法集中于单一模态，忽视了广泛可用的脑血管成像技术。这可能导致显著的分布变化，对跨模态的泛化产生负面影响。通过依赖注释的血管造影和有限数量的注释的静脉造影，我们的框架实现图像到图像的转换和语义分割，利用离散化和语义丰富的潜在空间来表示异构数据，并进行源域到目标域的图像级自适应。此外，我们减少了基于循环的架构的典型复杂性，最小化了对抗性训练的使用，这使我们能够构建一个稳定训练的高效直观模型。我们在磁共振血管造影和静脉造影上评估了我们的方法。在实现最先进水平的同时，我们减少了所提出方法的计算复杂度和模型稳定性的改进。",
    "tldr": "A2V是一种半监督领域自适应框架，用于通过图像到图像转换实现脑血管的跨模态分割。它通过离散化和语义丰富的潜在空间实现源域到目标域的图像级自适应，并提高了计算效率和训练稳定性。",
    "en_tdlr": "A2V is a semi-supervised domain adaptation framework that achieves cross-modal segmentation of brain vessels through image-to-image translation. It leverages a disentangled and semantically rich latent space to enable image-level adaptation from source to target domains, while improving computational efficiency and training stability."
}