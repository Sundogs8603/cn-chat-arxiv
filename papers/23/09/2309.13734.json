{
    "title": "Prompting and Fine-Tuning Open-Sourced Large Language Models for Stance Classification",
    "abstract": "arXiv:2309.13734v2 Announce Type: replace-cross  Abstract: Stance classification, the task of predicting the viewpoint of an author on a subject of interest, has long been a focal point of research in domains ranging from social science to machine learning. Current stance detection methods rely predominantly on manual annotation of sentences, followed by training a supervised machine learning model. However, this manual annotation process requires laborious annotation effort, and thus hampers its potential to generalize across different contexts. In this work, we investigate the use of Large Language Models (LLMs) as a stance detection methodology that can reduce or even eliminate the need for manual annotations. We investigate 10 open-source models and 7 prompting schemes, finding that LLMs are competitive with in-domain supervised models but are not necessarily consistent in their performance. We also fine-tuned the LLMs, but discovered that fine-tuning process does not necessarily l",
    "link": "https://arxiv.org/abs/2309.13734",
    "context": "Title: Prompting and Fine-Tuning Open-Sourced Large Language Models for Stance Classification\nAbstract: arXiv:2309.13734v2 Announce Type: replace-cross  Abstract: Stance classification, the task of predicting the viewpoint of an author on a subject of interest, has long been a focal point of research in domains ranging from social science to machine learning. Current stance detection methods rely predominantly on manual annotation of sentences, followed by training a supervised machine learning model. However, this manual annotation process requires laborious annotation effort, and thus hampers its potential to generalize across different contexts. In this work, we investigate the use of Large Language Models (LLMs) as a stance detection methodology that can reduce or even eliminate the need for manual annotations. We investigate 10 open-source models and 7 prompting schemes, finding that LLMs are competitive with in-domain supervised models but are not necessarily consistent in their performance. We also fine-tuned the LLMs, but discovered that fine-tuning process does not necessarily l",
    "path": "papers/23/09/2309.13734.json",
    "total_tokens": 828,
    "translated_title": "使用大型开源语言模型进行立场分类的提示和微调",
    "translated_abstract": "立场分类是一个长期以来研究重点领域，从社会科学到机器学习领域，这项任务涉及预测作者对感兴趣主题的观点。当前的立场检测方法主要依赖于手动注释句子，然后训练监督式机器学习模型。然而，这种手动注释过程需要大量的注释工作，因此限制了它在不同环境中泛化的潜力。在这项工作中，我们调查了大型语言模型（LLMs）作为一种可以减少甚至消除手动注释需求的立场检测方法。我们研究了10个开源模型和7种提示方案，发现LLMs在与域内监督模型具竞争力，但性能并不一定一致。我们还进行了LLMs的微调，但发现微调过程不必然",
    "tldr": "本研究探讨了使用大型语言模型作为立场检测方法以减少手动注释的需求，发现它们与域内监督模型具有竞争力，但性能不一致。"
}