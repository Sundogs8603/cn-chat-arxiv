{
    "title": "Do the Frankenstein, or how to achieve better out-of-distribution performance with manifold mixing model soup. (arXiv:2309.08610v1 [cs.LG])",
    "abstract": "The standard recipe applied in transfer learning is to finetune a pretrained model on the task-specific dataset with different hyperparameter settings and pick the model with the highest accuracy on the validation dataset. Unfortunately, this leads to models which do not perform well under distribution shifts, e.g. when the model is given graphical sketches of the object as input instead of photos. In order to address this, we propose the manifold mixing model soup, an algorithm which mixes together the latent space manifolds of multiple finetuned models in an optimal way in order to generate a fused model. We show that the fused model gives significantly better out-of-distribution performance (+3.5 % compared to best individual model) when finetuning a CLIP model for image classification. In addition, it provides also better accuracy on the original dataset where the finetuning has been done.",
    "link": "http://arxiv.org/abs/2309.08610",
    "context": "Title: Do the Frankenstein, or how to achieve better out-of-distribution performance with manifold mixing model soup. (arXiv:2309.08610v1 [cs.LG])\nAbstract: The standard recipe applied in transfer learning is to finetune a pretrained model on the task-specific dataset with different hyperparameter settings and pick the model with the highest accuracy on the validation dataset. Unfortunately, this leads to models which do not perform well under distribution shifts, e.g. when the model is given graphical sketches of the object as input instead of photos. In order to address this, we propose the manifold mixing model soup, an algorithm which mixes together the latent space manifolds of multiple finetuned models in an optimal way in order to generate a fused model. We show that the fused model gives significantly better out-of-distribution performance (+3.5 % compared to best individual model) when finetuning a CLIP model for image classification. In addition, it provides also better accuracy on the original dataset where the finetuning has been done.",
    "path": "papers/23/09/2309.08610.json",
    "total_tokens": 806,
    "translated_title": "进行弗兰肯斯坦法或如何通过混合模型空间来提升对分布之外性能的改进",
    "translated_abstract": "在迁移学习中，使用的标准方法是在特定任务的数据集上微调预训练模型，使用不同的超参数设置，并选择在验证数据集上准确率最高的模型。然而，这会导致模型在分布转换时表现不佳，例如当模型接收输入的是图形化的物体草图而不是照片时。为了解决这个问题，我们提出了混合模型空间法，这是一种通过最佳方式混合多个微调模型的潜在空间流形来生成一个融合模型的算法。我们展示了，在对图像分类进行微调后，融合模型在分布之外性能方面显著优于最佳的单个模型（比最佳单个模型提高了3.5%）。此外，它还在进行微调的原始数据集上提供更好的准确性。",
    "tldr": "提出了一种混合模型空间法，在微调模型后生成融合模型，该模型在分布之外表现更好（比最佳单个模型提高了3.5%），同时在原始数据集上也提供更好的准确性。"
}