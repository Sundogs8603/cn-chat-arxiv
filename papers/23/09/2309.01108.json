{
    "title": "Acoustic-to-articulatory inversion for dysarthric speech: Are pre-trained self-supervised representations favorable?. (arXiv:2309.01108v2 [eess.AS] UPDATED)",
    "abstract": "$ $Acoustic-to-articulatory inversion (AAI) involves mapping from the acoustic space to the articulatory space. Signal-processing features like the MFCCs, have been widely used for the AAI task. For subjects with dysarthric speech, AAI is challenging because of an imprecise and indistinct pronunciation. In this work, we perform AAI for dysarthric speech using representations from pre-trained self-supervised learning (SSL) models. We demonstrate the impact of different pre-trained features on this challenging AAI task, at low-resource conditions. In addition, we also condition x-vectors to the extracted SSL features to train a BLSTM network. In the seen case, we experiment with three AAI training schemes (subject-specific, pooled, and fine-tuned). The results, consistent across training schemes, reveal that DeCoAR, in the fine-tuned scheme, achieves a relative improvement of the Pearson Correlation Coefficient (CC) by ${\\sim}$1.81\\% and ${\\sim}$4.56\\% for healthy controls and patients, ",
    "link": "http://arxiv.org/abs/2309.01108",
    "context": "Title: Acoustic-to-articulatory inversion for dysarthric speech: Are pre-trained self-supervised representations favorable?. (arXiv:2309.01108v2 [eess.AS] UPDATED)\nAbstract: $ $Acoustic-to-articulatory inversion (AAI) involves mapping from the acoustic space to the articulatory space. Signal-processing features like the MFCCs, have been widely used for the AAI task. For subjects with dysarthric speech, AAI is challenging because of an imprecise and indistinct pronunciation. In this work, we perform AAI for dysarthric speech using representations from pre-trained self-supervised learning (SSL) models. We demonstrate the impact of different pre-trained features on this challenging AAI task, at low-resource conditions. In addition, we also condition x-vectors to the extracted SSL features to train a BLSTM network. In the seen case, we experiment with three AAI training schemes (subject-specific, pooled, and fine-tuned). The results, consistent across training schemes, reveal that DeCoAR, in the fine-tuned scheme, achieves a relative improvement of the Pearson Correlation Coefficient (CC) by ${\\sim}$1.81\\% and ${\\sim}$4.56\\% for healthy controls and patients, ",
    "path": "papers/23/09/2309.01108.json",
    "total_tokens": 1055,
    "translated_title": "语音障碍者的声学到发音反演: 预先训练的自监督表示是否有利？",
    "translated_abstract": "声学到发音反演(ACI)涉及从声学空间映射到发音空间。信号处理特征如MFCCs已被广泛应用于ACI任务。对于有语音障碍的患者，由于不准确和不清晰的发音，ACI是具有挑战性的。本研究使用预先训练的自监督学习(SSL)模型中的表示对语音障碍的ACI进行了实验。我们评估了不同预训练特征对这个具有挑战性的低资源ACI任务的影响。此外，我们还将x-vectors与提取的SSL特征相结合，训练了一个BLSTM网络。在已知情况下，我们尝试了三种ACI训练方案（主题特定，聚合和微调）。结果一致表明，DeCoAR在微调方案中，相对于健康对照组和患者，皮尔逊相关系数(CC)的改进幅度分别为约1.81\\%和约4.56\\%。",
    "tldr": "本研究探讨了使用预先训练的自监督表示对语音障碍者的声学到发音反演任务的影响。实验结果表明，在低资源条件下，经过微调的DeCoAR模型在精细训练方案中相对于健康对照组和患者，分别取得了约1.81\\%和约4.56\\%的皮尔逊相关系数(CC)的改进。"
}