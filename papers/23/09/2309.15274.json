{
    "title": "Memory-Efficient Continual Learning Object Segmentation for Long Video. (arXiv:2309.15274v1 [cs.CV])",
    "abstract": "Recent state-of-the-art semi-supervised Video Object Segmentation (VOS) methods have shown significant improvements in target object segmentation accuracy when information from preceding frames is used in undertaking segmentation on the current frame. In particular, such memory-based approaches can help a model to more effectively handle appearance changes (representation drift) or occlusions. Ideally, for maximum performance, online VOS methods would need all or most of the preceding frames (or their extracted information) to be stored in memory and be used for online learning in consecutive frames. Such a solution is not feasible for long videos, as the required memory size would grow without bound. On the other hand, these methods can fail when memory is limited and a target object experiences repeated representation drifts throughout a video.  We propose two novel techniques to reduce the memory requirement of online VOS methods while improving modeling accuracy and generalization ",
    "link": "http://arxiv.org/abs/2309.15274",
    "context": "Title: Memory-Efficient Continual Learning Object Segmentation for Long Video. (arXiv:2309.15274v1 [cs.CV])\nAbstract: Recent state-of-the-art semi-supervised Video Object Segmentation (VOS) methods have shown significant improvements in target object segmentation accuracy when information from preceding frames is used in undertaking segmentation on the current frame. In particular, such memory-based approaches can help a model to more effectively handle appearance changes (representation drift) or occlusions. Ideally, for maximum performance, online VOS methods would need all or most of the preceding frames (or their extracted information) to be stored in memory and be used for online learning in consecutive frames. Such a solution is not feasible for long videos, as the required memory size would grow without bound. On the other hand, these methods can fail when memory is limited and a target object experiences repeated representation drifts throughout a video.  We propose two novel techniques to reduce the memory requirement of online VOS methods while improving modeling accuracy and generalization ",
    "path": "papers/23/09/2309.15274.json",
    "total_tokens": 817,
    "translated_title": "内存高效的连续学习长视频目标分割方法",
    "translated_abstract": "最近的半监督视频目标分割方法在利用前几帧的信息进行当前帧分割时显示出显著的目标对象分割准确性改进。特别地，这种基于记忆的方法可以帮助模型更有效地处理外观变化（表达漂移）或遮挡。理想情况下，为了达到最佳性能，在线视频目标分割（VOS）方法需要将所有或大部分前几帧（或其提取的信息）存储在内存中，并用于连续帧的在线学习。然而，对于长视频来说，这种解决方案是不可行的，因为所需的内存大小会无限增长。另一方面，在内存有限且目标对象在视频中重复发生表达漂移的情况下，这些方法可能会失败。我们提出了两种新技术来减少在线VOS方法的内存需求，同时提高建模准确性和泛化能力。",
    "tldr": "提出了两种新技术，以减少在线VOS方法的内存需求，并在提高建模准确性和泛化能力的同时进行目标分割。",
    "en_tdlr": "Two novel techniques are proposed to reduce the memory requirement of online VOS methods, while improving modeling accuracy and generalization for object segmentation."
}