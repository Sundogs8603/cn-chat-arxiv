{
    "title": "Large-scale Pretraining Improves Sample Efficiency of Active Learning based Molecule Virtual Screening. (arXiv:2309.11687v1 [cs.LG])",
    "abstract": "Virtual screening of large compound libraries to identify potential hit candidates is one of the earliest steps in drug discovery. As the size of commercially available compound collections grows exponentially to the scale of billions, brute-force virtual screening using traditional tools such as docking becomes infeasible in terms of time and computational resources. Active learning and Bayesian optimization has recently been proven as effective methods of narrowing down the search space. An essential component in those methods is a surrogate machine learning model that is trained with a small subset of the library to predict the desired properties of compounds. Accurate model can achieve high sample efficiency by finding the most promising compounds with only a fraction of the whole library being virtually screened. In this study, we examined the performance of pretrained transformer-based language model and graph neural network in Bayesian optimization active learning framework. The",
    "link": "http://arxiv.org/abs/2309.11687",
    "context": "Title: Large-scale Pretraining Improves Sample Efficiency of Active Learning based Molecule Virtual Screening. (arXiv:2309.11687v1 [cs.LG])\nAbstract: Virtual screening of large compound libraries to identify potential hit candidates is one of the earliest steps in drug discovery. As the size of commercially available compound collections grows exponentially to the scale of billions, brute-force virtual screening using traditional tools such as docking becomes infeasible in terms of time and computational resources. Active learning and Bayesian optimization has recently been proven as effective methods of narrowing down the search space. An essential component in those methods is a surrogate machine learning model that is trained with a small subset of the library to predict the desired properties of compounds. Accurate model can achieve high sample efficiency by finding the most promising compounds with only a fraction of the whole library being virtually screened. In this study, we examined the performance of pretrained transformer-based language model and graph neural network in Bayesian optimization active learning framework. The",
    "path": "papers/23/09/2309.11687.json",
    "total_tokens": 859,
    "translated_title": "大规模预训练改善了基于主动学习的分子虚拟筛选的样本效率",
    "translated_abstract": "针对大规模化合物库进行虚拟筛选以寻找潜在的命中候选物在药物发现中是最早的步骤之一。随着商业可得化合物库的规模以指数级增长，使用传统工具如对接进行暴力虚拟筛选在时间和计算资源方面变得不可行。最近，主动学习和贝叶斯优化已被证明是缩小搜索空间的有效方法。这些方法的一个重要组成部分是使用小型库子集进行训练的替代机器学习模型，用于预测化合物的所需特性。准确的模型可以通过仅虚拟筛选整个库的一小部分来实现高样本效率，发现最有前途的化合物。本研究中，我们在贝叶斯优化的主动学习框架中研究了预训练的基于Transformer的语言模型和图神经网络的性能。",
    "tldr": "本研究探究了在贝叶斯优化的主动学习框架中，预训练的Transformer语言模型和图神经网络在提高分子虚拟筛选样本效率方面的表现。"
}