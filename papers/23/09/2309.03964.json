{
    "title": "REALM: Robust Entropy Adaptive Loss Minimization for Improved Single-Sample Test-Time Adaptation. (arXiv:2309.03964v1 [cs.LG])",
    "abstract": "Fully-test-time adaptation (F-TTA) can mitigate performance loss due to distribution shifts between train and test data (1) without access to the training data, and (2) without knowledge of the model training procedure. In online F-TTA, a pre-trained model is adapted using a stream of test samples by minimizing a self-supervised objective, such as entropy minimization. However, models adapted with online using entropy minimization, are unstable especially in single sample settings, leading to degenerate solutions, and limiting the adoption of TTA inference strategies. Prior works identify noisy, or unreliable, samples as a cause of failure in online F-TTA. One solution is to ignore these samples, which can lead to bias in the update procedure, slow adaptation, and poor generalization. In this work, we present a general framework for improving robustness of F-TTA to these noisy samples, inspired by self-paced learning and robust loss functions. Our proposed approach, Robust Entropy Adap",
    "link": "http://arxiv.org/abs/2309.03964",
    "context": "Title: REALM: Robust Entropy Adaptive Loss Minimization for Improved Single-Sample Test-Time Adaptation. (arXiv:2309.03964v1 [cs.LG])\nAbstract: Fully-test-time adaptation (F-TTA) can mitigate performance loss due to distribution shifts between train and test data (1) without access to the training data, and (2) without knowledge of the model training procedure. In online F-TTA, a pre-trained model is adapted using a stream of test samples by minimizing a self-supervised objective, such as entropy minimization. However, models adapted with online using entropy minimization, are unstable especially in single sample settings, leading to degenerate solutions, and limiting the adoption of TTA inference strategies. Prior works identify noisy, or unreliable, samples as a cause of failure in online F-TTA. One solution is to ignore these samples, which can lead to bias in the update procedure, slow adaptation, and poor generalization. In this work, we present a general framework for improving robustness of F-TTA to these noisy samples, inspired by self-paced learning and robust loss functions. Our proposed approach, Robust Entropy Adap",
    "path": "papers/23/09/2309.03964.json",
    "total_tokens": 941,
    "translated_title": "REALM: 鲁棒的熵自适应损失最小化以提高单样本测试时适应性",
    "translated_abstract": "充分测试时适应（F-TTA）可以减轻由于训练和测试数据之间的分布偏移而导致的性能损失（1）无需访问训练数据，（2）无需了解模型训练过程。在在线F-TTA中，通过最小化自我监督目标（例如熵最小化）来适应使用测试样本流的预训练模型。然而，使用熵最小化在线进行适应的模型在单样本设置中不稳定，导致退化解，并限制了TTA推理策略的采用。之前的工作确定了嘈杂或不可靠的样本是在线F-TTA失败的原因之一。一种解决方案是忽略这些样本，这可能导致更新过程中的偏差，适应缓慢和泛化差。在这项工作中，我们提出了一个改善F-TTA对这些嘈杂样本鲁棒性的通用框架，受到自适应学习和鲁棒损失函数的启发。",
    "tldr": "本文提出了一种改善单样本测试时自适应鲁棒性的方法，通过自适应学习和鲁棒损失函数的框架，解决了在线F-TTA中嘈杂样本导致的不稳定性问题。"
}