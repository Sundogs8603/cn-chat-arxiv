{
    "title": "Test-Time Training for Speech. (arXiv:2309.10930v1 [cs.SD])",
    "abstract": "In this paper, we study the application of Test-Time Training (TTT) as a solution to handling distribution shifts in speech applications. In particular, we introduce distribution-shifts to the test datasets of standard speech-classification tasks -- for example, speaker-identification and emotion-detection -- and explore how Test-Time Training (TTT) can help adjust to the distribution-shift. In our experiments that include distribution shifts due to background noise and natural variations in speech such as gender and age, we identify some key-challenges with TTT including sensitivity to optimization hyperparameters (e.g., number of optimization steps and subset of parameters chosen for TTT) and scalability (e.g., as each example gets its own set of parameters, TTT is not scalable). Finally, we propose using BitFit -- a parameter-efficient fine-tuning algorithm proposed for text applications that only considers the bias parameters for fine-tuning -- as a solution to the aforementioned c",
    "link": "http://arxiv.org/abs/2309.10930",
    "context": "Title: Test-Time Training for Speech. (arXiv:2309.10930v1 [cs.SD])\nAbstract: In this paper, we study the application of Test-Time Training (TTT) as a solution to handling distribution shifts in speech applications. In particular, we introduce distribution-shifts to the test datasets of standard speech-classification tasks -- for example, speaker-identification and emotion-detection -- and explore how Test-Time Training (TTT) can help adjust to the distribution-shift. In our experiments that include distribution shifts due to background noise and natural variations in speech such as gender and age, we identify some key-challenges with TTT including sensitivity to optimization hyperparameters (e.g., number of optimization steps and subset of parameters chosen for TTT) and scalability (e.g., as each example gets its own set of parameters, TTT is not scalable). Finally, we propose using BitFit -- a parameter-efficient fine-tuning algorithm proposed for text applications that only considers the bias parameters for fine-tuning -- as a solution to the aforementioned c",
    "path": "papers/23/09/2309.10930.json",
    "total_tokens": 878,
    "translated_title": "测试时间训练用于语音的应用",
    "translated_abstract": "本文研究了测试时间训练（TTT）在处理语音应用中的分布偏移问题上的应用。特别是，我们将分布偏移引入到标准语音分类任务的测试数据集中，例如说话人识别和情绪检测，并探讨测试时间训练如何帮助调整到这些分布偏移。在我们的实验中，我们包括了由背景噪声和语音的自然变化（如性别和年龄）引起的分布偏移，我们发现了测试时间训练的一些关键挑战，包括对优化超参数（例如优化步骤的数量和选择用于测试时间训练的参数子集）的敏感性以及可扩展性（例如，由于每个样本都有自己的一组参数，测试时间训练不可扩展）。最后，我们提出使用BitFit——一种仅考虑偏置参数进行微调的参数高效的文本应用中提出的微调算法——作为解决上述问题的方案。",
    "tldr": "本文研究了测试时间训练在语音应用中处理分布偏移的应用，提出了一种解决方案BitFit，该方案通过只考虑偏置参数进行微调，解决了测试时间训练中的关键挑战。"
}