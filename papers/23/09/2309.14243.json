{
    "title": "Enhancing data efficiency in reinforcement learning: a novel imagination mechanism based on mesh information propagation. (arXiv:2309.14243v2 [cs.LG] UPDATED)",
    "abstract": "Reinforcement learning(RL) algorithms face the challenge of limited data efficiency, particularly when dealing with high-dimensional state spaces and large-scale problems. Most of RL methods often rely solely on state transition information within the same episode when updating the agent's Critic, which can lead to low data efficiency and sub-optimal training time consumption. Inspired by human-like analogical reasoning abilities, we introduce a novel mesh information propagation mechanism, termed the 'Imagination Mechanism (IM)', designed to significantly enhance the data efficiency of RL algorithms. Specifically, IM enables information generated by a single sample to be effectively broadcasted to different states across episodes, instead of simply transmitting in the same episode. This capability enhances the model's comprehension of state interdependencies and facilitates more efficient learning of limited sample information. To promote versatility, we extend the IM to function as a",
    "link": "http://arxiv.org/abs/2309.14243",
    "context": "Title: Enhancing data efficiency in reinforcement learning: a novel imagination mechanism based on mesh information propagation. (arXiv:2309.14243v2 [cs.LG] UPDATED)\nAbstract: Reinforcement learning(RL) algorithms face the challenge of limited data efficiency, particularly when dealing with high-dimensional state spaces and large-scale problems. Most of RL methods often rely solely on state transition information within the same episode when updating the agent's Critic, which can lead to low data efficiency and sub-optimal training time consumption. Inspired by human-like analogical reasoning abilities, we introduce a novel mesh information propagation mechanism, termed the 'Imagination Mechanism (IM)', designed to significantly enhance the data efficiency of RL algorithms. Specifically, IM enables information generated by a single sample to be effectively broadcasted to different states across episodes, instead of simply transmitting in the same episode. This capability enhances the model's comprehension of state interdependencies and facilitates more efficient learning of limited sample information. To promote versatility, we extend the IM to function as a",
    "path": "papers/23/09/2309.14243.json",
    "total_tokens": 971,
    "translated_title": "增强强化学习中的数据效率：基于网格信息传播的新型想象机制",
    "translated_abstract": "强化学习算法在处理高维状态空间和大规模问题时面临数据效率有限的挑战。大多数强化学习方法在更新智能体的评论家时往往仅依赖于同一集中的状态转换信息，这可能导致数据效率低和训练时间消耗亚优。受到人类类比推理能力的启发，我们引入了一种名为“想象机制（IM）”的新型网格信息传播机制，旨在显著提高强化学习算法的数据效率。具体而言，IM使得由单个样本生成的信息能够有效地广播到不同的集中状态，而不仅仅是在同一集中传输。这种能力增强了模型对状态间相互依赖性的理解，并促进了对有限样本信息更高效的学习。为了提高多功能性，我们将IM扩展为一种可以作为",
    "tldr": "这项研究提出了一种基于网格信息传播的想象机制，在强化学习算法中显著提高了数据效率。通过使信息在不同状态间广播，而不仅仅是在同一状态集中传输，这种机制促进了模型对状态间相互依赖性的理解，并提高了对有限样本信息的学习效率。"
}