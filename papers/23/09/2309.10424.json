{
    "title": "Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare. (arXiv:2309.10424v1 [cs.AI])",
    "abstract": "The Directorate General for Parliamentary Research Services of the European Parliament has prepared a report to the Members of the European Parliament where they enumerate seven main risks of Artificial Intelligence (AI) in medicine and healthcare: patient harm due to AI errors, misuse of medical AI tools, bias in AI and the perpetuation of existing inequities, lack of transparency, privacy and security issues, gaps in accountability, and obstacles in implementation.  In this study, we propose fourteen functional requirements that AI systems may implement to reduce the risks associated with their medical purpose: AI passport, User management, Regulation check, Academic use only disclaimer, data quality assessment, Clinicians double check, Continuous performance evaluation, Audit trail, Continuous usability test, Review of retrospective/simulated cases, Bias check, eXplainable AI, Encryption and use of field-tested libraries, and Semantic interoperability.  Our intention here is to prov",
    "link": "http://arxiv.org/abs/2309.10424",
    "context": "Title: Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare. (arXiv:2309.10424v1 [cs.AI])\nAbstract: The Directorate General for Parliamentary Research Services of the European Parliament has prepared a report to the Members of the European Parliament where they enumerate seven main risks of Artificial Intelligence (AI) in medicine and healthcare: patient harm due to AI errors, misuse of medical AI tools, bias in AI and the perpetuation of existing inequities, lack of transparency, privacy and security issues, gaps in accountability, and obstacles in implementation.  In this study, we propose fourteen functional requirements that AI systems may implement to reduce the risks associated with their medical purpose: AI passport, User management, Regulation check, Academic use only disclaimer, data quality assessment, Clinicians double check, Continuous performance evaluation, Audit trail, Continuous usability test, Review of retrospective/simulated cases, Bias check, eXplainable AI, Encryption and use of field-tested libraries, and Semantic interoperability.  Our intention here is to prov",
    "path": "papers/23/09/2309.10424.json",
    "total_tokens": 922,
    "translated_title": "减少医疗人工智能对患者造成伤害的功能要求",
    "translated_abstract": "欧洲议会议员研究服务总司为欧洲议会议员准备了一份报告，其中列举了医疗和医疗保健领域人工智能的七个主要风险：由于人工智能错误导致患者受伤、医用人工智能工具的滥用、人工智能的偏见以及现有不平等的延续、缺乏透明度、隐私和安全问题、责任缺失和实施障碍。本研究提出了14个功能要求，人工智能系统可以通过实施这些要求来降低与其医疗目的相关的风险：人工智能护照、用户管理、法规检查、仅供学术使用的免责声明、数据质量评估、临床医生的双重检查、持续性能评估、审计跟踪、持续可用性测试、回顾性/模拟案例的审查、偏见检查、可解释的人工智能、加密和使用经过实地测试的库以及语义互操作性。我们的目的是提供一种方法来减少医疗人工智能可能带来的风险。",
    "tldr": "提出了14个功能要求，人工智能系统可以通过实施这些要求来降低医疗领域人工智能可能带来的风险。",
    "en_tdlr": "The study proposes fourteen functional requirements that AI systems may implement to reduce the risks associated with their medical purpose in healthcare."
}