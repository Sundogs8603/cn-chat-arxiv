{
    "title": "Language Guided Adversarial Purification. (arXiv:2309.10348v1 [cs.LG])",
    "abstract": "Adversarial purification using generative models demonstrates strong adversarial defense performance. These methods are classifier and attack-agnostic, making them versatile but often computationally intensive. Recent strides in diffusion and score networks have improved image generation and, by extension, adversarial purification. Another highly efficient class of adversarial defense methods known as adversarial training requires specific knowledge of attack vectors, forcing them to be trained extensively on adversarial examples. To overcome these limitations, we introduce a new framework, namely Language Guided Adversarial Purification (LGAP), utilizing pre-trained diffusion models and caption generators to defend against adversarial attacks. Given an input image, our method first generates a caption, which is then used to guide the adversarial purification process through a diffusion network. Our approach has been evaluated against strong adversarial attacks, proving its effectivene",
    "link": "http://arxiv.org/abs/2309.10348",
    "context": "Title: Language Guided Adversarial Purification. (arXiv:2309.10348v1 [cs.LG])\nAbstract: Adversarial purification using generative models demonstrates strong adversarial defense performance. These methods are classifier and attack-agnostic, making them versatile but often computationally intensive. Recent strides in diffusion and score networks have improved image generation and, by extension, adversarial purification. Another highly efficient class of adversarial defense methods known as adversarial training requires specific knowledge of attack vectors, forcing them to be trained extensively on adversarial examples. To overcome these limitations, we introduce a new framework, namely Language Guided Adversarial Purification (LGAP), utilizing pre-trained diffusion models and caption generators to defend against adversarial attacks. Given an input image, our method first generates a caption, which is then used to guide the adversarial purification process through a diffusion network. Our approach has been evaluated against strong adversarial attacks, proving its effectivene",
    "path": "papers/23/09/2309.10348.json",
    "total_tokens": 893,
    "translated_title": "语言引导的对抗净化",
    "translated_abstract": "使用生成模型进行对抗净化展示出了强大的对抗防御性能。这些方法不依赖分类器和攻击手法，使其具有多功能性但通常计算密集。最近在扩散和评分网络方面取得的进展提高了图像生成和对抗净化的性能。另一类高效的对抗防御方法称为对抗训练，需要特定的攻击向量知识，迫使它们在对抗性样本上进行大量训练。为了克服这些局限性，我们提出了一种新的框架，即语言引导的对抗净化（LGAP），利用预训练的扩散模型和标题生成器来抵御对抗攻击。给定一个输入图像，我们的方法首先生成一个标题，然后通过扩散网络来指导对抗净化过程。我们的方法已经针对强大的对抗攻击进行了评估，证明了其有效性。",
    "tldr": "本文提出了一种语言引导的对抗净化（LGAP）框架，利用预训练的扩散模型和标题生成器来抵御对抗攻击。通过生成图像的标题并通过扩散网络进行引导，该方法可以有效地进行对抗净化，克服了现有方法的局限性。",
    "en_tdlr": "This paper introduces a new framework called Language Guided Adversarial Purification (LGAP), which utilizes pre-trained diffusion models and caption generators to defend against adversarial attacks. By generating captions for input images and guiding the purification process through a diffusion network, this method effectively overcomes the limitations of existing approaches."
}