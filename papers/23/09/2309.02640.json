{
    "title": "Epi-Curriculum: Episodic Curriculum Learning for Low-Resource Domain Adaptation in Neural Machine Translation. (arXiv:2309.02640v1 [cs.LG])",
    "abstract": "Neural Machine Translation (NMT) models have become successful, but their performance remains poor when translating on new domains with a limited number of data. In this paper, we present a novel approach Epi-Curriculum to address low-resource domain adaptation (DA), which contains a new episodic training framework along with denoised curriculum learning. Our episodic training framework enhances the model's robustness to domain shift by episodically exposing the encoder/decoder to an inexperienced decoder/encoder. The denoised curriculum learning filters the noised data and further improves the model's adaptability by gradually guiding the learning process from easy to more difficult tasks. Experiments on English-German and English-Romanian translation show that: (i) Epi-Curriculum improves both model's robustness and adaptability in seen and unseen domains; (ii) Our episodic training framework enhances the encoder and decoder's robustness to domain shift.",
    "link": "http://arxiv.org/abs/2309.02640",
    "context": "Title: Epi-Curriculum: Episodic Curriculum Learning for Low-Resource Domain Adaptation in Neural Machine Translation. (arXiv:2309.02640v1 [cs.LG])\nAbstract: Neural Machine Translation (NMT) models have become successful, but their performance remains poor when translating on new domains with a limited number of data. In this paper, we present a novel approach Epi-Curriculum to address low-resource domain adaptation (DA), which contains a new episodic training framework along with denoised curriculum learning. Our episodic training framework enhances the model's robustness to domain shift by episodically exposing the encoder/decoder to an inexperienced decoder/encoder. The denoised curriculum learning filters the noised data and further improves the model's adaptability by gradually guiding the learning process from easy to more difficult tasks. Experiments on English-German and English-Romanian translation show that: (i) Epi-Curriculum improves both model's robustness and adaptability in seen and unseen domains; (ii) Our episodic training framework enhances the encoder and decoder's robustness to domain shift.",
    "path": "papers/23/09/2309.02640.json",
    "total_tokens": 958,
    "translated_title": "Epi-Curriculum: 用于神经机器翻译中低资源领域自适应的分集课程学习",
    "translated_abstract": "神经机器翻译（NMT）模型非常成功，但在限定数量的数据上进行新领域的翻译时，其性能仍然较差。本文提出了一种新颖的方法Epi-Curriculum，用于解决低资源领域自适应（DA），它包含一个新的分集训练框架和去噪的课程学习。我们的分集训练框架通过周期性地将编码器/解码器暴露给经验不足的解码器/编码器，增强了模型对领域变化的鲁棒性。去噪的课程学习通过逐步引导学习过程从简单到更复杂的任务，进一步提高了模型的适应性。在英德和英罗马尼亚翻译方向上的实验证明：（i）Epi-Curriculum在已见和未见领域中提高了模型的鲁棒性和适应性；（ii）我们的分集训练框架增强了编码器和解码器对领域变化的鲁棒性。",
    "tldr": "Epi-Curriculum是一种用于神经机器翻译中低资源领域自适应的方法，通过分集训练和去噪的课程学习，提高了模型对领域变化的鲁棒性和适应性。"
}