{
    "title": "Symplectic Structure-Aware Hamiltonian (Graph) Embeddings. (arXiv:2309.04885v1 [cs.LG])",
    "abstract": "In traditional Graph Neural Networks (GNNs), the assumption of a fixed embedding manifold often limits their adaptability to diverse graph geometries. Recently, Hamiltonian system-inspired GNNs are proposed to address the dynamic nature of such embeddings by incorporating physical laws into node feature updates. In this work, we present SAH-GNN, a novel approach that generalizes Hamiltonian dynamics for more flexible node feature updates. Unlike existing Hamiltonian-inspired GNNs, SAH-GNN employs Riemannian optimization on the symplectic Stiefel manifold to adaptively learn the underlying symplectic structure during training, circumventing the limitations of existing Hamiltonian GNNs that rely on a pre-defined form of standard symplectic structure. This innovation allows SAH-GNN to automatically adapt to various graph datasets without extensive hyperparameter tuning. Moreover, it conserves energy during training such that the implicit Hamiltonian system is physically meaningful. To thi",
    "link": "http://arxiv.org/abs/2309.04885",
    "context": "Title: Symplectic Structure-Aware Hamiltonian (Graph) Embeddings. (arXiv:2309.04885v1 [cs.LG])\nAbstract: In traditional Graph Neural Networks (GNNs), the assumption of a fixed embedding manifold often limits their adaptability to diverse graph geometries. Recently, Hamiltonian system-inspired GNNs are proposed to address the dynamic nature of such embeddings by incorporating physical laws into node feature updates. In this work, we present SAH-GNN, a novel approach that generalizes Hamiltonian dynamics for more flexible node feature updates. Unlike existing Hamiltonian-inspired GNNs, SAH-GNN employs Riemannian optimization on the symplectic Stiefel manifold to adaptively learn the underlying symplectic structure during training, circumventing the limitations of existing Hamiltonian GNNs that rely on a pre-defined form of standard symplectic structure. This innovation allows SAH-GNN to automatically adapt to various graph datasets without extensive hyperparameter tuning. Moreover, it conserves energy during training such that the implicit Hamiltonian system is physically meaningful. To thi",
    "path": "papers/23/09/2309.04885.json",
    "total_tokens": 1003,
    "translated_title": "结构感知的辛系统哈密顿（图）嵌入",
    "translated_abstract": "在传统的图神经网络（GNNs）中，固定嵌入流形的假设常常限制了其对不同图几何结构的适应性。最近，提出了基于哈密顿系统的GNNs，通过将物理定律纳入节点特征更新中，来解决这类嵌入的动态特性。在这项工作中，我们提出了SAH-GNN，一种新颖的方法，将哈密顿动力学推广到更灵活的节点特征更新中。与现有的受哈密顿启发的GNNs不同，SAH-GNN在训练过程中采用辛斯蒂费尔流形上的黎曼优化，自适应地学习潜在的辛结构，从而规避了现有依赖预定义标准辛结构形式的哈密顿GNNs的局限性。这一创新使得SAH-GNN能够在没有大量超参数调整的情况下自动适应各种图数据集。此外，它在训练过程中保持能量守恒，使得隐式哈密顿系统具有物理意义。",
    "tldr": "本文提出了SAH-GNN，一种在图神经网络中应用结构感知的辛系统哈密顿嵌入方法。与传统方法不同，SAH-GNN通过在训练过程中自适应学习辛结构，避免了依赖预定义标准辛结构形式的限制，并能够适应不同的图数据集，同时保持物理意义上的能量守恒。",
    "en_tdlr": "This paper introduces SAH-GNN, a symplectic structure-aware Hamiltonian embedding method applied in graph neural networks. Unlike traditional approaches, SAH-GNN adaptsively learns the symplectic structure during training, avoiding the limitations of relying on a predefined standard structure, and is able to adapt to different graph datasets while maintaining energy conservation with physical significance."
}