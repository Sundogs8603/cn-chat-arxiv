{
    "title": "Text-Only Domain Adaptation for End-to-End Speech Recognition through Down-Sampling Acoustic Representation. (arXiv:2309.02459v1 [cs.SD])",
    "abstract": "Mapping two modalities, speech and text, into a shared representation space, is a research topic of using text-only data to improve end-to-end automatic speech recognition (ASR) performance in new domains. However, the length of speech representation and text representation is inconsistent. Although the previous method up-samples the text representation to align with acoustic modality, it may not match the expected actual duration. In this paper, we proposed novel representations match strategy through down-sampling acoustic representation to align with text modality. By introducing a continuous integrate-and-fire (CIF) module generating acoustic representations consistent with token length, our ASR model can learn unified representations from both modalities better, allowing for domain adaptation using text-only data of the target domain. Experiment results of new domain data demonstrate the effectiveness of the proposed method.",
    "link": "http://arxiv.org/abs/2309.02459",
    "context": "Title: Text-Only Domain Adaptation for End-to-End Speech Recognition through Down-Sampling Acoustic Representation. (arXiv:2309.02459v1 [cs.SD])\nAbstract: Mapping two modalities, speech and text, into a shared representation space, is a research topic of using text-only data to improve end-to-end automatic speech recognition (ASR) performance in new domains. However, the length of speech representation and text representation is inconsistent. Although the previous method up-samples the text representation to align with acoustic modality, it may not match the expected actual duration. In this paper, we proposed novel representations match strategy through down-sampling acoustic representation to align with text modality. By introducing a continuous integrate-and-fire (CIF) module generating acoustic representations consistent with token length, our ASR model can learn unified representations from both modalities better, allowing for domain adaptation using text-only data of the target domain. Experiment results of new domain data demonstrate the effectiveness of the proposed method.",
    "path": "papers/23/09/2309.02459.json",
    "total_tokens": 862,
    "translated_title": "通过下采样的声学表示进行纯文本领域自适应的端到端语音识别",
    "translated_abstract": "将两种形式的资料，声音和文本，映射到共享的表示空间中，是一种利用纯文本数据提高端到端自动语音识别(ASR)性能的研究课题。然而，声音和文本的表示长度不一致。虽然先前的方法通过上采样文本表示来与音频模态进行对齐，但可能不匹配预期的实际持续时间。在本文中，我们提出了通过下采样声学表示来与文本模态对齐的新型表示匹配策略。通过引入连续积分-火炮 (CIF) 模块生成与标记长度一致的声学表示，我们的ASR模型可以更好地从两种模态中学习统一的表示，从而能够使用目标领域的纯文本数据进行领域自适应。新领域数据的实验结果证明了所提方法的有效性。",
    "tldr": "本文提出了一种通过下采样声学表示来对齐文本模态的方法，以实现纯文本领域自适应的端到端语音识别。实验结果表明，该方法在新领域数据上取得了良好的效果。",
    "en_tdlr": "This paper proposes a method that aligns text modality through down-sampling acoustic representation, achieving text-only domain adaptation for end-to-end speech recognition. Experimental results demonstrate the effectiveness of the proposed method in new domain data."
}