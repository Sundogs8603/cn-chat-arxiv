{
    "title": "PRE: Vision-Language Prompt Learning with Reparameterization Encoder. (arXiv:2309.07760v1 [cs.CV])",
    "abstract": "Large pre-trained vision-language models such as CLIP have demonstrated great potential in zero-shot transferability to downstream tasks. However, to attain optimal performance, the manual selection of prompts is necessary to improve alignment between the downstream image distribution and the textual class descriptions. This manual prompt engineering is the major challenge for deploying such models in practice since it requires domain expertise and is extremely time-consuming. To avoid non-trivial prompt engineering, recent work Context Optimization (CoOp) introduced the concept of prompt learning to the vision domain using learnable textual tokens. While CoOp can achieve substantial improvements over manual prompts, its learned context is worse generalizable to wider unseen classes within the same dataset. In this work, we present Prompt Learning with Reparameterization Encoder (PRE) - a simple and efficient method that enhances the generalization ability of the learnable prompt to un",
    "link": "http://arxiv.org/abs/2309.07760",
    "context": "Title: PRE: Vision-Language Prompt Learning with Reparameterization Encoder. (arXiv:2309.07760v1 [cs.CV])\nAbstract: Large pre-trained vision-language models such as CLIP have demonstrated great potential in zero-shot transferability to downstream tasks. However, to attain optimal performance, the manual selection of prompts is necessary to improve alignment between the downstream image distribution and the textual class descriptions. This manual prompt engineering is the major challenge for deploying such models in practice since it requires domain expertise and is extremely time-consuming. To avoid non-trivial prompt engineering, recent work Context Optimization (CoOp) introduced the concept of prompt learning to the vision domain using learnable textual tokens. While CoOp can achieve substantial improvements over manual prompts, its learned context is worse generalizable to wider unseen classes within the same dataset. In this work, we present Prompt Learning with Reparameterization Encoder (PRE) - a simple and efficient method that enhances the generalization ability of the learnable prompt to un",
    "path": "papers/23/09/2309.07760.json",
    "total_tokens": 857,
    "translated_title": "PRE: 视觉-语言提示学习与重新参数化编码器",
    "translated_abstract": "大型预训练的视觉-语言模型（如CLIP）已经展示出在零样本迁移任务中具有巨大潜力。然而，为了达到最佳性能，需要手动选择提示以改进下游图像分布和文本类描述之间的对齐。这种手动提示工程是将这些模型部署到实践中的主要挑战，因为它需要领域专业知识并且非常耗时。为了避免复杂的提示工程，最近的CoOp工作引入了在视觉领域使用可控文本标记的提示学习概念。虽然CoOp可以在手动提示上取得显著改进，但其学到的上下文在同一数据集中更广泛的未见类别中的泛化能力较差。在这项工作中，我们提出了一种名为Prompt Learning with Reparameterization Encoder (PRE) 的简单高效的方法，改进了可学习提示的泛化能力。",
    "tldr": "这项工作提出了一种名为PRE的方法，通过重新参数化编码器来增强可学习提示的泛化能力，从而解决了大型预训练视觉-语言模型中手动提示工程的挑战。",
    "en_tdlr": "This work presents a method called PRE, which enhances the generalization ability of learnable prompts through reparameterization encoder, addressing the challenge of manual prompt engineering in large pre-trained vision-language models."
}