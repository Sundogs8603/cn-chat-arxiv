{
    "title": "Delays in Reinforcement Learning. (arXiv:2309.11096v1 [cs.LG])",
    "abstract": "Delays are inherent to most dynamical systems. Besides shifting the process in time, they can significantly affect their performance. For this reason, it is usually valuable to study the delay and account for it. Because they are dynamical systems, it is of no surprise that sequential decision-making problems such as Markov decision processes (MDP) can also be affected by delays. These processes are the foundational framework of reinforcement learning (RL), a paradigm whose goal is to create artificial agents capable of learning to maximise their utility by interacting with their environment.  RL has achieved strong, sometimes astonishing, empirical results, but delays are seldom explicitly accounted for. The understanding of the impact of delay on the MDP is limited. In this dissertation, we propose to study the delay in the agent's observation of the state of the environment or in the execution of the agent's actions. We will repeatedly change our point of view on the problem to reve",
    "link": "http://arxiv.org/abs/2309.11096",
    "context": "Title: Delays in Reinforcement Learning. (arXiv:2309.11096v1 [cs.LG])\nAbstract: Delays are inherent to most dynamical systems. Besides shifting the process in time, they can significantly affect their performance. For this reason, it is usually valuable to study the delay and account for it. Because they are dynamical systems, it is of no surprise that sequential decision-making problems such as Markov decision processes (MDP) can also be affected by delays. These processes are the foundational framework of reinforcement learning (RL), a paradigm whose goal is to create artificial agents capable of learning to maximise their utility by interacting with their environment.  RL has achieved strong, sometimes astonishing, empirical results, but delays are seldom explicitly accounted for. The understanding of the impact of delay on the MDP is limited. In this dissertation, we propose to study the delay in the agent's observation of the state of the environment or in the execution of the agent's actions. We will repeatedly change our point of view on the problem to reve",
    "path": "papers/23/09/2309.11096.json",
    "total_tokens": 881,
    "translated_title": "延迟在强化学习中的影响",
    "translated_abstract": "延迟是大多数动态系统固有的特性。除了将过程推后一段时间外，延迟还会显著影响系统的性能。因此，研究延迟并加以考虑通常是很有价值的。由于它们是动态系统，所以延迟也会影响到马尔可夫决策过程（MDP）等顺序决策问题。MDP是强化学习（RL）的基本框架，RL的目标是通过与环境互动学习以最大化效用的人工智能代理的创建。尽管RL取得了强大的实证结果，对于延迟的显式考虑却很少见。对于MDP的延迟影响的理解还很有限。在这篇论文中，我们提出研究代理对环境状态的观测或代理执行行动的延迟。我们将不断改变对问题的观点以揭示延迟的影响。",
    "tldr": "这篇论文研究了延迟对强化学习中马尔可夫决策过程的影响，通过对代理观测延迟和执行行动延迟的研究，揭示了延迟对系统性能的重要性。"
}