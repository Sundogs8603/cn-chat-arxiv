{
    "title": "Bayesian sparsity and class sparsity priors for dictionary learning and coding. (arXiv:2309.00999v1 [stat.ML])",
    "abstract": "Dictionary learning methods continue to gain popularity for the solution of challenging inverse problems. In the dictionary learning approach, the computational forward model is replaced by a large dictionary of possible outcomes, and the problem is to identify the dictionary entries that best match the data, akin to traditional query matching in search engines. Sparse coding techniques are used to guarantee that the dictionary matching identifies only few of the dictionary entries, and dictionary compression methods are used to reduce the complexity of the matching problem. In this article, we propose a work flow to facilitate the dictionary matching process. First, the full dictionary is divided into subdictionaries that are separately compressed. The error introduced by the dictionary compression is handled in the Bayesian framework as a modeling error. Furthermore, we propose a new Bayesian data-driven group sparsity coding method to help identify subdictionaries that are not relev",
    "link": "http://arxiv.org/abs/2309.00999",
    "context": "Title: Bayesian sparsity and class sparsity priors for dictionary learning and coding. (arXiv:2309.00999v1 [stat.ML])\nAbstract: Dictionary learning methods continue to gain popularity for the solution of challenging inverse problems. In the dictionary learning approach, the computational forward model is replaced by a large dictionary of possible outcomes, and the problem is to identify the dictionary entries that best match the data, akin to traditional query matching in search engines. Sparse coding techniques are used to guarantee that the dictionary matching identifies only few of the dictionary entries, and dictionary compression methods are used to reduce the complexity of the matching problem. In this article, we propose a work flow to facilitate the dictionary matching process. First, the full dictionary is divided into subdictionaries that are separately compressed. The error introduced by the dictionary compression is handled in the Bayesian framework as a modeling error. Furthermore, we propose a new Bayesian data-driven group sparsity coding method to help identify subdictionaries that are not relev",
    "path": "papers/23/09/2309.00999.json",
    "total_tokens": 889,
    "translated_title": "贝叶斯稀疏性和类别稀疏性先验于字典学习和编码",
    "translated_abstract": "字典学习方法在解决具有挑战性的逆问题中越来越受欢迎。在字典学习方法中，计算正向模型被一个包含可能结果的大型字典替代，问题是识别最能匹配数据的字典条目，类似于传统搜索引擎中的查询匹配。稀疏编码技术用于确保字典匹配只识别出少数字典条目，并且字典压缩方法用于减少匹配问题的复杂性。在本文中，我们提出了一种工作流程来促进字典匹配过程。首先，将完整字典分成单独压缩的子字典。字典压缩引入的误差在贝叶斯框架中被处理为建模误差。此外，我们提出了一种新的基于贝叶斯的数据驱动组稀疏编码方法，以帮助识别不相关的子字典。",
    "tldr": "本文提出了一种贝叶斯字典学习和编码方法，通过压缩子字典和引入建模误差来改进字典匹配过程，并采用数据驱动的稀疏编码技术识别不相关的子字典。",
    "en_tdlr": "This paper proposes a Bayesian dictionary learning and coding method that improves the dictionary matching process by compressing subdictionaries and introducing modeling error, and uses data-driven sparse coding techniques to identify irrelevant subdictionaries."
}