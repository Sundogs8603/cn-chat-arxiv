{
    "title": "Langevin Quasi-Monte Carlo. (arXiv:2309.12664v1 [stat.CO])",
    "abstract": "Langevin Monte Carlo (LMC) and its stochastic gradient versions are powerful algorithms for sampling from complex high-dimensional distributions. To sample from a distribution with density $\\pi(\\theta)\\propto \\exp(-U(\\theta)) $, LMC iteratively generates the next sample by taking a step in the gradient direction $\\nabla U$ with added Gaussian perturbations. Expectations w.r.t. the target distribution $\\pi$ are estimated by averaging over LMC samples. In ordinary Monte Carlo, it is well known that the estimation error can be substantially reduced by replacing independent random samples by quasi-random samples like low-discrepancy sequences. In this work, we show that the estimation error of LMC can also be reduced by using quasi-random samples. Specifically, we propose to use completely uniformly distributed (CUD) sequences with certain low-discrepancy property to generate the Gaussian perturbations. Under smoothness and convexity conditions, we prove that LMC with a low-discrepancy CUD",
    "link": "http://arxiv.org/abs/2309.12664",
    "context": "Title: Langevin Quasi-Monte Carlo. (arXiv:2309.12664v1 [stat.CO])\nAbstract: Langevin Monte Carlo (LMC) and its stochastic gradient versions are powerful algorithms for sampling from complex high-dimensional distributions. To sample from a distribution with density $\\pi(\\theta)\\propto \\exp(-U(\\theta)) $, LMC iteratively generates the next sample by taking a step in the gradient direction $\\nabla U$ with added Gaussian perturbations. Expectations w.r.t. the target distribution $\\pi$ are estimated by averaging over LMC samples. In ordinary Monte Carlo, it is well known that the estimation error can be substantially reduced by replacing independent random samples by quasi-random samples like low-discrepancy sequences. In this work, we show that the estimation error of LMC can also be reduced by using quasi-random samples. Specifically, we propose to use completely uniformly distributed (CUD) sequences with certain low-discrepancy property to generate the Gaussian perturbations. Under smoothness and convexity conditions, we prove that LMC with a low-discrepancy CUD",
    "path": "papers/23/09/2309.12664.json",
    "total_tokens": 880,
    "translated_title": "Langevin准蒙特卡洛算法",
    "translated_abstract": "Langevin蒙特卡洛（LMC）及其随机梯度版本是用于从复杂高维分布中抽样的强大算法。为了从密度为$\\pi(\\theta)\\propto \\exp(-U(\\theta)) $的分布中抽样，LMC通过在梯度方向$\\nabla U$上加入高斯扰动来迭代生成下一个样本。对于目标分布$\\pi$的期望值通过对LMC样本进行平均估计。在普通蒙特卡洛中，已知通过用低差异序列等准随机样本替代独立随机样本可以显著减少估计误差。在本文中，我们证明LMC的估计误差也可以通过使用准随机样本来减少。具体来说，我们建议使用具有特定低差异性质的完全均匀分布（CUD）序列来生成高斯扰动。在光滑性和凸性条件下，我们证明了带有低差异CUD的LMC算法的收敛性和渐进正态性质。",
    "tldr": "本文提出了Langevin准蒙特卡洛算法，通过使用低差异准随机样本可以减少其估计误差。",
    "en_tdlr": "The paper introduces the Langevin quasi-Monte Carlo algorithm and shows that the estimation error can be reduced by using low-discrepancy quasi-random samples."
}