{
    "title": "Self-Supervised Contrastive Learning for Robust Audio-Sheet Music Retrieval Systems. (arXiv:2309.12134v1 [cs.SD])",
    "abstract": "Linking sheet music images to audio recordings remains a key problem for the development of efficient cross-modal music retrieval systems. One of the fundamental approaches toward this task is to learn a cross-modal embedding space via deep neural networks that is able to connect short snippets of audio and sheet music. However, the scarcity of annotated data from real musical content affects the capability of such methods to generalize to real retrieval scenarios. In this work, we investigate whether we can mitigate this limitation with self-supervised contrastive learning, by exposing a network to a large amount of real music data as a pre-training step, by contrasting randomly augmented views of snippets of both modalities, namely audio and sheet images. Through a number of experiments on synthetic and real piano data, we show that pre-trained models are able to retrieve snippets with better precision in all scenarios and pre-training configurations. Encouraged by these results, we ",
    "link": "http://arxiv.org/abs/2309.12134",
    "context": "Title: Self-Supervised Contrastive Learning for Robust Audio-Sheet Music Retrieval Systems. (arXiv:2309.12134v1 [cs.SD])\nAbstract: Linking sheet music images to audio recordings remains a key problem for the development of efficient cross-modal music retrieval systems. One of the fundamental approaches toward this task is to learn a cross-modal embedding space via deep neural networks that is able to connect short snippets of audio and sheet music. However, the scarcity of annotated data from real musical content affects the capability of such methods to generalize to real retrieval scenarios. In this work, we investigate whether we can mitigate this limitation with self-supervised contrastive learning, by exposing a network to a large amount of real music data as a pre-training step, by contrasting randomly augmented views of snippets of both modalities, namely audio and sheet images. Through a number of experiments on synthetic and real piano data, we show that pre-trained models are able to retrieve snippets with better precision in all scenarios and pre-training configurations. Encouraged by these results, we ",
    "path": "papers/23/09/2309.12134.json",
    "total_tokens": 865,
    "translated_title": "自监督对比学习用于稳健的音频-乐谱检索系统",
    "translated_abstract": "将乐谱图像与音频录音进行链接仍然是开发高效的跨模态音乐检索系统的一个关键问题。一种基本的方法是通过深度神经网络学习一个能够连接短音频片段和乐谱的跨模态嵌入空间。然而，真实音乐内容的带注释数据的稀缺性影响了这些方法在真实检索场景中的泛化能力。在这项工作中，我们通过自监督对比学习来缓解这个限制，通过将网络暴露在大量真实音乐数据中作为预训练步骤，对比随机增强的音频和乐谱图像片段的视图。通过对合成和真实钢琴数据进行一系列实验，我们表明预训练模型能够在所有场景和预训练配置中更精确地检索片段。在这些结果的鼓舞下，我们...",
    "tldr": "本文研究了自监督对比学习在稳健音频-乐谱检索系统中的应用，通过对比两种模态的随机增强视图，预训练模型能够在所有场景中更精确地检索片段。",
    "en_tdlr": "This paper investigates the application of self-supervised contrastive learning in robust audio-sheet music retrieval systems, showing that pre-trained models can retrieve snippets with better precision in all scenarios."
}