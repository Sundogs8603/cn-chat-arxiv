{
    "title": "Adaptive approximation of monotone functions. (arXiv:2309.07530v1 [cs.LG])",
    "abstract": "We study the classical problem of approximating a non-decreasing function $f: \\mathcal{X} \\to \\mathcal{Y}$ in $L^p(\\mu)$ norm by sequentially querying its values, for known compact real intervals $\\mathcal{X}$, $\\mathcal{Y}$ and a known probability measure $\\mu$ on $\\cX$. For any function~$f$ we characterize the minimum number of evaluations of $f$ that algorithms need to guarantee an approximation $\\hat{f}$ with an $L^p(\\mu)$ error below $\\epsilon$ after stopping. Unlike worst-case results that hold uniformly over all $f$, our complexity measure is dependent on each specific function $f$. To address this problem, we introduce GreedyBox, a generalization of an algorithm originally proposed by Novak (1992) for numerical integration. We prove that GreedyBox achieves an optimal sample complexity for any function $f$, up to logarithmic factors. Additionally, we uncover results regarding piecewise-smooth functions. Perhaps as expected, the $L^p(\\mu)$ error of GreedyBox decreases much faster",
    "link": "http://arxiv.org/abs/2309.07530",
    "context": "Title: Adaptive approximation of monotone functions. (arXiv:2309.07530v1 [cs.LG])\nAbstract: We study the classical problem of approximating a non-decreasing function $f: \\mathcal{X} \\to \\mathcal{Y}$ in $L^p(\\mu)$ norm by sequentially querying its values, for known compact real intervals $\\mathcal{X}$, $\\mathcal{Y}$ and a known probability measure $\\mu$ on $\\cX$. For any function~$f$ we characterize the minimum number of evaluations of $f$ that algorithms need to guarantee an approximation $\\hat{f}$ with an $L^p(\\mu)$ error below $\\epsilon$ after stopping. Unlike worst-case results that hold uniformly over all $f$, our complexity measure is dependent on each specific function $f$. To address this problem, we introduce GreedyBox, a generalization of an algorithm originally proposed by Novak (1992) for numerical integration. We prove that GreedyBox achieves an optimal sample complexity for any function $f$, up to logarithmic factors. Additionally, we uncover results regarding piecewise-smooth functions. Perhaps as expected, the $L^p(\\mu)$ error of GreedyBox decreases much faster",
    "path": "papers/23/09/2309.07530.json",
    "total_tokens": 914,
    "translated_title": "自适应逼近单调函数",
    "translated_abstract": "我们研究了在已知紧实数区间X、Y和已知概率测度μ下，通过顺序查询函数值来逼近非递减函数$f:\\mathcal{X} \\to \\mathcal{Y}$在$L^p(\\mu)$范数下的经典问题。对于任意函数$f$，我们给出了算法需要保证在停止后误差小于ε的逼近$\\hat{f}$所需的最小评估次数的特征。与所有$f$上均一致适用的最坏情况结果不同，我们的复杂度度量是依赖于每个特定函数$f$的。为了解决这个问题，我们引入了GreedyBox，这是一个对数值积分的原始算法Novak(1992)的推广。我们证明了无论对于任何函数$f$，GreedyBox都能实现最优的样本复杂度，仅差对数因子。此外，我们还揭示了关于分段光滑函数的结果。也许预料之中的是，GreedyBox的$L^p(\\mu)$误差减小得更快。",
    "tldr": "这项研究解决了通过顺序查询函数值来逼近非递减函数的问题，并引入了一个通用算法GreedyBox，该算法对于任意函数都能实现最佳的样本复杂度。",
    "en_tdlr": "This study addresses the problem of approximating non-decreasing functions by sequentially querying their values, and introduces a general algorithm called GreedyBox that achieves optimal sample complexity for any function."
}