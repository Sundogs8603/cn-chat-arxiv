{
    "title": "A Quantum States Preparation Method Based on Difference-Driven Reinforcement Learning. (arXiv:2309.16972v1 [quant-ph])",
    "abstract": "Due to the large state space of the two-qubit system, and the adoption of ladder reward function in the existing quantum state preparation methods, the convergence speed is slow and it is difficult to prepare the desired target quantum state with high fidelity under limited conditions. To solve the above problems, a difference-driven reinforcement learning (RL) algorithm for quantum state preparation of two-qubit system is proposed by improving the reward function and action selection strategy. Firstly, a model is constructed for the problem of preparing quantum states of a two-qubit system, with restrictions on the type of quantum gates and the time for quantum state evolution. In the preparation process, a weighted differential dynamic reward function is designed to assist the algorithm quickly obtain the maximum expected cumulative reward. Then, an adaptive e-greedy action selection strategy is adopted to achieve a balance between exploration and utilization to a certain extent, the",
    "link": "http://arxiv.org/abs/2309.16972",
    "context": "Title: A Quantum States Preparation Method Based on Difference-Driven Reinforcement Learning. (arXiv:2309.16972v1 [quant-ph])\nAbstract: Due to the large state space of the two-qubit system, and the adoption of ladder reward function in the existing quantum state preparation methods, the convergence speed is slow and it is difficult to prepare the desired target quantum state with high fidelity under limited conditions. To solve the above problems, a difference-driven reinforcement learning (RL) algorithm for quantum state preparation of two-qubit system is proposed by improving the reward function and action selection strategy. Firstly, a model is constructed for the problem of preparing quantum states of a two-qubit system, with restrictions on the type of quantum gates and the time for quantum state evolution. In the preparation process, a weighted differential dynamic reward function is designed to assist the algorithm quickly obtain the maximum expected cumulative reward. Then, an adaptive e-greedy action selection strategy is adopted to achieve a balance between exploration and utilization to a certain extent, the",
    "path": "papers/23/09/2309.16972.json",
    "total_tokens": 819,
    "translated_title": "基于差分驱动增强学习的量子态制备方法",
    "translated_abstract": "由于两比特量子系统的状态空间较大，并且现有量子态制备方法采用阶梯型奖励函数，收敛速度慢，在有限条件下很难高保真度制备所需的目标量子态。为解决上述问题，本文提出了一种改进奖励函数和行为选择策略的差分驱动增强学习算法，用于两比特量子系统的量子态制备。首先，构建了一个模型，包括对量子门类型和量子态演化时间的限制。在制备过程中，设计了一种加权差分动态奖励函数，辅助算法快速获得最大期望累积奖励。然后，采取自适应ε-greedy行为选择策略，以在探索和利用之间取得一定平衡。",
    "tldr": "本文提出了一种基于差分驱动增强学习的量子态制备方法，改进了奖励函数和行为选择策略，以提高两比特量子系统的制备速度和保真度。",
    "en_tdlr": "This paper proposes a quantum state preparation method based on difference-driven reinforcement learning, which improves the reward function and action selection strategy to enhance the preparation speed and fidelity of a two-qubit system."
}