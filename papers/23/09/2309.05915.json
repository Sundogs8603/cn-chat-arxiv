{
    "title": "ACT: Empowering Decision Transformer with Dynamic Programming via Advantage Conditioning. (arXiv:2309.05915v1 [cs.LG])",
    "abstract": "Decision Transformer (DT), which employs expressive sequence modeling techniques to perform action generation, has emerged as a promising approach to offline policy optimization. However, DT generates actions conditioned on a desired future return, which is known to bear some weaknesses such as the susceptibility to environmental stochasticity. To overcome DT's weaknesses, we propose to empower DT with dynamic programming. Our method comprises three steps. First, we employ in-sample value iteration to obtain approximated value functions, which involves dynamic programming over the MDP structure. Second, we evaluate action quality in context with estimated advantages. We introduce two types of advantage estimators, IAE and GAE, which are suitable for different tasks. Third, we train an Advantage-Conditioned Transformer (ACT) to generate actions conditioned on the estimated advantages. Finally, during testing, ACT generates actions conditioned on a desired advantage. Our evaluation resul",
    "link": "http://arxiv.org/abs/2309.05915",
    "context": "Title: ACT: Empowering Decision Transformer with Dynamic Programming via Advantage Conditioning. (arXiv:2309.05915v1 [cs.LG])\nAbstract: Decision Transformer (DT), which employs expressive sequence modeling techniques to perform action generation, has emerged as a promising approach to offline policy optimization. However, DT generates actions conditioned on a desired future return, which is known to bear some weaknesses such as the susceptibility to environmental stochasticity. To overcome DT's weaknesses, we propose to empower DT with dynamic programming. Our method comprises three steps. First, we employ in-sample value iteration to obtain approximated value functions, which involves dynamic programming over the MDP structure. Second, we evaluate action quality in context with estimated advantages. We introduce two types of advantage estimators, IAE and GAE, which are suitable for different tasks. Third, we train an Advantage-Conditioned Transformer (ACT) to generate actions conditioned on the estimated advantages. Finally, during testing, ACT generates actions conditioned on a desired advantage. Our evaluation resul",
    "path": "papers/23/09/2309.05915.json",
    "total_tokens": 940,
    "translated_title": "通过优势调节使用动态规划增强决策Transformer",
    "translated_abstract": "决策Transformer (DT) 利用表达丰富的序列建模技术来执行动作生成，已成为离线策略优化的一种有前景的方法。然而，DT 生成的动作是基于期望未来回报的条件，已知具有某些弱点，比如易受环境随机性影响。为了克服DT的弱点，我们提出了在DT中增加动态规划能力的方法。我们的方法包括三个步骤。首先，我们使用样本内值迭代来获得近似值函数，这涉及到MDP结构上的动态规划。第二，我们结合估计的优势来评估动作的质量。我们引入了两种优势估计器，分别适用于不同的任务。第三，我们训练了一个以估计的优势为条件生成动作的优势条件Transformer (ACT)。最后，在测试阶段，ACT根据所需的优势生成动作。我们的评估结果表明...",
    "tldr": "这篇论文提出了一种通过将动态规划应用于决策Transformer来增强其能力的方法。作者提出了三个步骤来实现这一目标：使用样本内值迭代获得近似值函数，结合估计的优势评估动作质量，并训练ACT生成基于估计优势的动作。该方法在测试中表现出良好的性能。",
    "en_tdlr": "This paper proposes a method to enhance the capabilities of Decision Transformer (DT) by applying dynamic programming. The approach involves three steps: obtaining approximated value functions using in-sample value iteration, evaluating action quality with estimated advantages, and training ACT to generate actions conditioned on the estimated advantages. The method shows promising performance in testing."
}