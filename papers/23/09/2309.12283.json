{
    "title": "Performance Conditioning for Diffusion-Based Multi-Instrument Music Synthesis. (arXiv:2309.12283v1 [cs.SD])",
    "abstract": "Generating multi-instrument music from symbolic music representations is an important task in Music Information Retrieval (MIR). A central but still largely unsolved problem in this context is musically and acoustically informed control in the generation process. As the main contribution of this work, we propose enhancing control of multi-instrument synthesis by conditioning a generative model on a specific performance and recording environment, thus allowing for better guidance of timbre and style. Building on state-of-the-art diffusion-based music generative models, we introduce performance conditioning - a simple tool indicating the generative model to synthesize music with style and timbre of specific instruments taken from specific performances. Our prototype is evaluated using uncurated performances with diverse instrumentation and achieves state-of-the-art FAD realism scores while allowing novel timbre and style control. Our project page, including samples and demonstrations, is",
    "link": "http://arxiv.org/abs/2309.12283",
    "context": "Title: Performance Conditioning for Diffusion-Based Multi-Instrument Music Synthesis. (arXiv:2309.12283v1 [cs.SD])\nAbstract: Generating multi-instrument music from symbolic music representations is an important task in Music Information Retrieval (MIR). A central but still largely unsolved problem in this context is musically and acoustically informed control in the generation process. As the main contribution of this work, we propose enhancing control of multi-instrument synthesis by conditioning a generative model on a specific performance and recording environment, thus allowing for better guidance of timbre and style. Building on state-of-the-art diffusion-based music generative models, we introduce performance conditioning - a simple tool indicating the generative model to synthesize music with style and timbre of specific instruments taken from specific performances. Our prototype is evaluated using uncurated performances with diverse instrumentation and achieves state-of-the-art FAD realism scores while allowing novel timbre and style control. Our project page, including samples and demonstrations, is",
    "path": "papers/23/09/2309.12283.json",
    "total_tokens": 868,
    "translated_title": "基于扩散的多乐器音乐合成的性能调节",
    "translated_abstract": "从符号音乐表示生成多乐器音乐是音乐信息检索（MIR）中的一个重要任务。在这个背景下，一个集中但仍然很大程度上未解决的问题是在生成过程中以音乐和声学为基础的控制。作为本工作的主要贡献，我们提出通过对特定的演奏和录音环境进行条件处理，以增强多乐器合成的控制，从而更好地引导音色和风格。在现有先进的基于扩散的音乐生成模型基础上，我们引入了性能调节-一种简单的工具，指示生成模型用特定演奏中特定乐器的风格和音色合成音乐。我们的原型使用具有多样化仪器的非策划表演进行评估，并在保留了新颖音色和风格控制的同时实现了最先进的FAD逼真度得分。我们的项目页面包括样本和演示。",
    "tldr": "本研究提出了一种基于扩散的多乐器音乐合成性能调节方法，通过对特定的演奏和录音环境进行条件处理，实现了更好的音色和风格引导控制。",
    "en_tdlr": "This study proposes a performance conditioning method for diffusion-based multi-instrument music synthesis, which enhances control by conditioning the generative model on a specific performance and recording environment, allowing for better guidance of timbre and style."
}