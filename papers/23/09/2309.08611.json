{
    "title": "Maneuver Decision-Making Through Proximal Policy Optimization And Monte Carlo Tree Search. (arXiv:2309.08611v1 [cs.AI])",
    "abstract": "Maneuver decision-making can be regarded as a Markov decision process and can be address by reinforcement learning. However, original reinforcement learning algorithms can hardly solve the maneuvering decision-making problem. One reason is that agents use random actions in the early stages of training, which makes it difficult to get rewards and learn how to make effective decisions. To address this issue, a method based on proximal policy optimization and Monte Carlo tree search is proposed. The method uses proximal policy optimization to train the agent, and regards the results of air combat as targets to train the value network. Then, based on the value network and the visit count of each node, Monte Carlo tree search is used to find the actions with more expected returns than random actions, which can improve the training performance. The ablation studies and simulation experiments indicate that agents trained by the proposed method can make different decisions according to differe",
    "link": "http://arxiv.org/abs/2309.08611",
    "context": "Title: Maneuver Decision-Making Through Proximal Policy Optimization And Monte Carlo Tree Search. (arXiv:2309.08611v1 [cs.AI])\nAbstract: Maneuver decision-making can be regarded as a Markov decision process and can be address by reinforcement learning. However, original reinforcement learning algorithms can hardly solve the maneuvering decision-making problem. One reason is that agents use random actions in the early stages of training, which makes it difficult to get rewards and learn how to make effective decisions. To address this issue, a method based on proximal policy optimization and Monte Carlo tree search is proposed. The method uses proximal policy optimization to train the agent, and regards the results of air combat as targets to train the value network. Then, based on the value network and the visit count of each node, Monte Carlo tree search is used to find the actions with more expected returns than random actions, which can improve the training performance. The ablation studies and simulation experiments indicate that agents trained by the proposed method can make different decisions according to differe",
    "path": "papers/23/09/2309.08611.json",
    "total_tokens": 969,
    "translated_title": "通过近端策略优化和蒙特卡洛树搜索进行机动决策",
    "translated_abstract": "机动决策可以被视为马尔可夫决策过程，并可以通过强化学习进行处理。然而，传统的强化学习算法很难解决机动决策问题。一个原因是在训练的早期阶段，智能体使用随机动作，难以获得奖励和学习如何做出有效的决策。为了解决这个问题，提出了一种基于近端策略优化和蒙特卡洛树搜索的方法。该方法使用近端策略优化来训练智能体，并将空战结果作为目标来训练价值网络。然后，基于价值网络和每个节点的访问次数，使用蒙特卡洛树搜索来找到比随机动作更有预期回报的动作，从而提高训练性能。消融实验和仿真实验表明，通过该方法训练的智能体可以根据不同的情况做出不同的决策。",
    "tldr": "该论文提出了一种基于近端策略优化和蒙特卡洛树搜索的方法，用于解决机动决策问题。该方法通过训练价值网络和使用蒙特卡洛树搜索来选择行动，从而提高训练性能。实验证明，通过该方法训练的智能体可以根据不同情况做出不同决策。",
    "en_tdlr": "This paper proposes a method based on proximal policy optimization and Monte Carlo tree search for maneuver decision-making. The method trains the agent using proximal policy optimization and uses Monte Carlo tree search to select actions based on the value network, improving training performance. Experimental results demonstrate that agents trained with this method can make different decisions based on different situations."
}