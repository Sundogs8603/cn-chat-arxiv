{
    "title": "UER: A Heuristic Bias Addressing Approach for Online Continual Learning. (arXiv:2309.04081v1 [cs.LG])",
    "abstract": "Online continual learning aims to continuously train neural networks from a continuous data stream with a single pass-through data. As the most effective approach, the rehearsal-based methods replay part of previous data. Commonly used predictors in existing methods tend to generate biased dot-product logits that prefer to the classes of current data, which is known as a bias issue and a phenomenon of forgetting. Many approaches have been proposed to overcome the forgetting problem by correcting the bias; however, they still need to be improved in online fashion. In this paper, we try to address the bias issue by a more straightforward and more efficient method. By decomposing the dot-product logits into an angle factor and a norm factor, we empirically find that the bias problem mainly occurs in the angle factor, which can be used to learn novel knowledge as cosine logits. On the contrary, the norm factor abandoned by existing methods helps remember historical knowledge. Based on this",
    "link": "http://arxiv.org/abs/2309.04081",
    "context": "Title: UER: A Heuristic Bias Addressing Approach for Online Continual Learning. (arXiv:2309.04081v1 [cs.LG])\nAbstract: Online continual learning aims to continuously train neural networks from a continuous data stream with a single pass-through data. As the most effective approach, the rehearsal-based methods replay part of previous data. Commonly used predictors in existing methods tend to generate biased dot-product logits that prefer to the classes of current data, which is known as a bias issue and a phenomenon of forgetting. Many approaches have been proposed to overcome the forgetting problem by correcting the bias; however, they still need to be improved in online fashion. In this paper, we try to address the bias issue by a more straightforward and more efficient method. By decomposing the dot-product logits into an angle factor and a norm factor, we empirically find that the bias problem mainly occurs in the angle factor, which can be used to learn novel knowledge as cosine logits. On the contrary, the norm factor abandoned by existing methods helps remember historical knowledge. Based on this",
    "path": "papers/23/09/2309.04081.json",
    "total_tokens": 905,
    "translated_title": "UER: 一种针对在线连续学习的启发式偏差处理方法",
    "translated_abstract": "在线连续学习旨在通过单次遍历数据对神经网络进行连续训练。作为最有效的方法，基于回放的方法会重新播放部分先前的数据。然而，现有方法中使用的常见预测器倾向于生成偏向当前数据类别的有偏差的点积logits，这被称为偏差问题和遗忘现象。许多方法已经被提出来通过纠正偏差来克服遗忘问题，但是它们还需要在在线方式下改进。在本文中，我们尝试通过一种更直接和更高效的方法来解决偏差问题。通过将点积logits分解为角度因子和范数因子，我们经验性地发现偏差问题主要发生在角度因子中，可以用来学习新的知识作为余弦logits。相反，被现有方法抛弃的范数因子有助于记住历史知识。",
    "tldr": "本论文提出了一种针对在线连续学习的启发式偏差处理方法，通过将点积logits分解为角度因子和范数因子，解决了点积logits偏差问题。角度因子用于学习新的知识，而范数因子有助于记住历史知识。"
}