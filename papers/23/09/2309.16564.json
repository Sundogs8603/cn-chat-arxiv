{
    "title": "Augment to Interpret: Unsupervised and Inherently Interpretable Graph Embeddings. (arXiv:2309.16564v1 [cs.LG])",
    "abstract": "Unsupervised learning allows us to leverage unlabelled data, which has become abundantly available, and to create embeddings that are usable on a variety of downstream tasks. However, the typical lack of interpretability of unsupervised representation learning has become a limiting factor with regard to recent transparent-AI regulations. In this paper, we study graph representation learning and we show that data augmentation that preserves semantics can be learned and used to produce interpretations. Our framework, which we named INGENIOUS, creates inherently interpretable embeddings and eliminates the need for costly additional post-hoc analysis. We also introduce additional metrics addressing the lack of formalism and metrics in the understudied area of unsupervised-representation learning interpretability. Our results are supported by an experimental study applied to both graph-level and node-level tasks and show that interpretable embeddings provide state-of-the-art performance on ",
    "link": "http://arxiv.org/abs/2309.16564",
    "context": "Title: Augment to Interpret: Unsupervised and Inherently Interpretable Graph Embeddings. (arXiv:2309.16564v1 [cs.LG])\nAbstract: Unsupervised learning allows us to leverage unlabelled data, which has become abundantly available, and to create embeddings that are usable on a variety of downstream tasks. However, the typical lack of interpretability of unsupervised representation learning has become a limiting factor with regard to recent transparent-AI regulations. In this paper, we study graph representation learning and we show that data augmentation that preserves semantics can be learned and used to produce interpretations. Our framework, which we named INGENIOUS, creates inherently interpretable embeddings and eliminates the need for costly additional post-hoc analysis. We also introduce additional metrics addressing the lack of formalism and metrics in the understudied area of unsupervised-representation learning interpretability. Our results are supported by an experimental study applied to both graph-level and node-level tasks and show that interpretable embeddings provide state-of-the-art performance on ",
    "path": "papers/23/09/2309.16564.json",
    "total_tokens": 866,
    "translated_title": "增强解释性: 无监督的和本质上可解释的图嵌入",
    "translated_abstract": "无监督学习使我们能够利用大量可用的未标记数据，并创建可用于各种下游任务的嵌入。然而，无监督表示学习的典型缺乏解释性已成为最近透明人工智能法规的限制因素。在本文中，我们研究了图表示学习，并展示了学习保持语义的数据增强方法可以用于生成解释。我们的框架名为INGENIOUS，创建了本质上可解释的嵌入，并消除了昂贵的后续分析的需要。我们还引入了针对无监督表示学习可解释性研究领域缺乏形式化和度量的额外指标。我们的结果通过应用于图级和节点级任务的实验证明，可解释的嵌入在性能上达到了最先进水平。",
    "tldr": "本文研究了无监督图表示学习，通过学习并利用保持语义的数据增强方法，创建了解释性嵌入，并解决了无监督表示学习可解释性研究领域的不足。",
    "en_tdlr": "In this paper, the authors propose a framework called INGENIOUS that learns and utilizes data augmentation to create inherently interpretable graph embeddings in the field of unsupervised representation learning. Their approach addresses the lack of interpretability in unsupervised learning and provides state-of-the-art performance on graph-level and node-level tasks."
}