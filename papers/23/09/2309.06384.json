{
    "title": "Towards Reliable and Fluent Large Language Models: Incorporating Feedback Learning Loops in QA Systems. (arXiv:2309.06384v1 [cs.CL])",
    "abstract": "Large language models (LLMs) have emerged as versatile tools in various daily applications. However, they are fraught with issues that undermine their utility and trustworthiness. These include the incorporation of erroneous references (citation), the generation of hallucinated information (correctness), and the inclusion of superfluous or omission of crucial details (fluency). To ameliorate these concerns, this study makes several key contributions. First, we build a dataset to train a critic model capable of evaluating the citation, correctness, and fluency of responses generated by LLMs in QA systems. Second, we propose an automated feedback mechanism that leverages the critic model to offer real-time feedback on heterogeneous aspects of generated text. Third, we introduce a feedback learning loop that uses this critic model to iteratively improve the performance of the LLM responsible for response generation. Experimental results demonstrate the efficacy of our approach, showing su",
    "link": "http://arxiv.org/abs/2309.06384",
    "context": "Title: Towards Reliable and Fluent Large Language Models: Incorporating Feedback Learning Loops in QA Systems. (arXiv:2309.06384v1 [cs.CL])\nAbstract: Large language models (LLMs) have emerged as versatile tools in various daily applications. However, they are fraught with issues that undermine their utility and trustworthiness. These include the incorporation of erroneous references (citation), the generation of hallucinated information (correctness), and the inclusion of superfluous or omission of crucial details (fluency). To ameliorate these concerns, this study makes several key contributions. First, we build a dataset to train a critic model capable of evaluating the citation, correctness, and fluency of responses generated by LLMs in QA systems. Second, we propose an automated feedback mechanism that leverages the critic model to offer real-time feedback on heterogeneous aspects of generated text. Third, we introduce a feedback learning loop that uses this critic model to iteratively improve the performance of the LLM responsible for response generation. Experimental results demonstrate the efficacy of our approach, showing su",
    "path": "papers/23/09/2309.06384.json",
    "total_tokens": 862,
    "translated_title": "朝着可靠流利的大型语言模型迈进：在问答系统中引入反馈学习循环",
    "translated_abstract": "大型语言模型（LLMs）已成为各种日常应用中多功能的工具。然而，它们存在一些问题，影响了它们的实用性和可信度。这些问题包括引用错误（引文）、生成虚构信息（正确性）以及包含多余或遗漏关键细节（流畅性）。为了改善这些问题，本研究做出了几个重要贡献。首先，我们构建了一个数据集，用于训练评论模型，评估LLMs在问答系统中生成的回答的引文、正确性和流畅性。其次，我们提出了一种自动反馈机制，利用评论模型对生成文本的异构方面进行实时反馈。第三，我们引入了一个反馈学习循环，使用评论模型来迭代改进负责回答生成的LLM的性能。实验结果显示我们的方法的有效性。",
    "tldr": "本研究通过构建评论模型和引入反馈学习循环，解决了大型语言模型在问答系统中引用错误、生成虚构信息和缺少关键细节的问题。",
    "en_tdlr": "This study addresses the issues of erroneous references, hallucinated information, and missing crucial details in large language models used in QA systems by building a critic model, introducing an automated feedback mechanism, and implementing a feedback learning loop."
}