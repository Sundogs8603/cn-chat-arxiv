{
    "title": "SYNDICOM: Improving Conversational Commonsense with Error-Injection and Natural Language Feedback. (arXiv:2309.10015v1 [cs.CL])",
    "abstract": "Commonsense reasoning is a critical aspect of human communication. Despite recent advances in conversational AI driven by large language models, commonsense reasoning remains a challenging task. In this work, we introduce SYNDICOM - a method for improving commonsense in dialogue response generation. SYNDICOM consists of two components. The first component is a dataset composed of commonsense dialogues created from a knowledge graph and synthesized into natural language. This dataset includes both valid and invalid responses to dialogue contexts, along with natural language feedback (NLF) for the invalid responses. The second contribution is a two-step procedure: training a model to predict natural language feedback (NLF) for invalid responses, and then training a response generation model conditioned on the predicted NLF, the invalid response, and the dialogue. SYNDICOM is scalable and does not require reinforcement learning. Empirical results on three tasks are evaluated using a broad",
    "link": "http://arxiv.org/abs/2309.10015",
    "context": "Title: SYNDICOM: Improving Conversational Commonsense with Error-Injection and Natural Language Feedback. (arXiv:2309.10015v1 [cs.CL])\nAbstract: Commonsense reasoning is a critical aspect of human communication. Despite recent advances in conversational AI driven by large language models, commonsense reasoning remains a challenging task. In this work, we introduce SYNDICOM - a method for improving commonsense in dialogue response generation. SYNDICOM consists of two components. The first component is a dataset composed of commonsense dialogues created from a knowledge graph and synthesized into natural language. This dataset includes both valid and invalid responses to dialogue contexts, along with natural language feedback (NLF) for the invalid responses. The second contribution is a two-step procedure: training a model to predict natural language feedback (NLF) for invalid responses, and then training a response generation model conditioned on the predicted NLF, the invalid response, and the dialogue. SYNDICOM is scalable and does not require reinforcement learning. Empirical results on three tasks are evaluated using a broad",
    "path": "papers/23/09/2309.10015.json",
    "total_tokens": 879,
    "translated_title": "SYNDICOM: 错误注入和自然语言反馈改进对话常识研究",
    "translated_abstract": "常识推理是人类交流的关键方面。尽管近年来由大型语言模型驱动的对话人工智能取得了进展，但常识推理仍然是一个具有挑战性的任务。在这项工作中，我们介绍了SYNDICOM - 一种改进对话应答生成中常识的方法。SYNDICOM由两个部分组成。第一个组件是一个由知识图创建的常识对话数据集，并以自然语言形式合成。该数据集包括对话环境中的有效和无效回答，以及对无效回答的自然语言反馈（NLF）。第二个贡献是一个两步的过程：训练一个模型来预测无效回答的自然语言反馈（NLF），然后根据预测的NLF、无效回答和对话条件训练一个应答生成模型。SYNDICOM具有可伸缩性，不需要强化学习。通过对三个任务的经验结果进行评估。",
    "tldr": "SYNDICOM是一种改进对话常识的方法，包含了一个常识对话数据集和一个基于自然语言反馈的模型，可用于训练对话应答生成模型。",
    "en_tdlr": "SYNDICOM is a method for improving conversational commonsense, which includes a commonsense dialogue dataset and a model based on natural language feedback, used for training dialogue response generation models."
}