{
    "title": "Towards Robust Continual Learning with Bayesian Adaptive Moment Regularization. (arXiv:2309.08546v1 [cs.LG])",
    "abstract": "The pursuit of long-term autonomy mandates that robotic agents must continuously adapt to their changing environments and learn to solve new tasks. Continual learning seeks to overcome the challenge of catastrophic forgetting, where learning to solve new tasks causes a model to forget previously learnt information. Prior-based continual learning methods are appealing for robotic applications as they are space efficient and typically do not increase in computational complexity as the number of tasks grows. Despite these desirable properties, prior-based approaches typically fail on important benchmarks and consequently are limited in their potential applications compared to their memory-based counterparts. We introduce Bayesian adaptive moment regularization (BAdam), a novel prior-based method that better constrains parameter growth, leading to lower catastrophic forgetting. Our method boasts a range of desirable properties for robotic applications such as being lightweight and task lab",
    "link": "http://arxiv.org/abs/2309.08546",
    "context": "Title: Towards Robust Continual Learning with Bayesian Adaptive Moment Regularization. (arXiv:2309.08546v1 [cs.LG])\nAbstract: The pursuit of long-term autonomy mandates that robotic agents must continuously adapt to their changing environments and learn to solve new tasks. Continual learning seeks to overcome the challenge of catastrophic forgetting, where learning to solve new tasks causes a model to forget previously learnt information. Prior-based continual learning methods are appealing for robotic applications as they are space efficient and typically do not increase in computational complexity as the number of tasks grows. Despite these desirable properties, prior-based approaches typically fail on important benchmarks and consequently are limited in their potential applications compared to their memory-based counterparts. We introduce Bayesian adaptive moment regularization (BAdam), a novel prior-based method that better constrains parameter growth, leading to lower catastrophic forgetting. Our method boasts a range of desirable properties for robotic applications such as being lightweight and task lab",
    "path": "papers/23/09/2309.08546.json",
    "total_tokens": 871,
    "translated_title": "基于贝叶斯自适应时刻正则化的鲁棒性持续学习",
    "translated_abstract": "为了追求长期自主性，机器人代理必须不断适应不断变化的环境并学习解决新任务。持续学习试图克服灾难性遗忘的挑战，即学习解决新任务导致模型忘记先前学到的信息。基于先验的持续学习方法对于机器人应用具有吸引力，因为它们在空间效率上很高，并且通常不会随着任务数量的增加而增加计算复杂性。尽管具有这些理想的特性，但基于先验的方法通常在重要的基准测试中失败，因此与基于记忆的方法相比，在潜在应用方面有限。我们引入了贝叶斯自适应时刻正则化（BAdam），一种新的基于先验的方法，它更好地约束参数增长，降低灾难性遗忘。我们的方法在机器人应用中具有一系列理想的特性，例如轻量级和任务实验室。",
    "tldr": "基于贝叶斯自适应时刻正则化的鲁棒性持续学习方法能够在机器人应用中有效地解决灾难性遗忘问题，并具有轻量级和任务实验室等优势。"
}