{
    "title": "CLIP-based Synergistic Knowledge Transfer for Text-based Person Retrieval. (arXiv:2309.09496v2 [cs.CV] UPDATED)",
    "abstract": "Text-based Person Retrieval (TPR) aims to retrieve the target person images given a textual query. The primary challenge lies in bridging the substantial gap between vision and language modalities, especially when dealing with limited large-scale datasets. In this paper, we introduce a CLIP-based Synergistic Knowledge Transfer (CSKT) approach for TPR. Specifically, to explore the CLIP's knowledge on input side, we first propose a Bidirectional Prompts Transferring (BPT) module constructed by text-to-image and image-to-text bidirectional prompts and coupling projections. Secondly, Dual Adapters Transferring (DAT) is designed to transfer knowledge on output side of Multi-Head Attention (MHA) in vision and language. This synergistic two-way collaborative mechanism promotes the early-stage feature fusion and efficiently exploits the existing knowledge of CLIP. CSKT outperforms the state-of-the-art approaches across three benchmark datasets when the training parameters merely account for 7.",
    "link": "http://arxiv.org/abs/2309.09496",
    "context": "Title: CLIP-based Synergistic Knowledge Transfer for Text-based Person Retrieval. (arXiv:2309.09496v2 [cs.CV] UPDATED)\nAbstract: Text-based Person Retrieval (TPR) aims to retrieve the target person images given a textual query. The primary challenge lies in bridging the substantial gap between vision and language modalities, especially when dealing with limited large-scale datasets. In this paper, we introduce a CLIP-based Synergistic Knowledge Transfer (CSKT) approach for TPR. Specifically, to explore the CLIP's knowledge on input side, we first propose a Bidirectional Prompts Transferring (BPT) module constructed by text-to-image and image-to-text bidirectional prompts and coupling projections. Secondly, Dual Adapters Transferring (DAT) is designed to transfer knowledge on output side of Multi-Head Attention (MHA) in vision and language. This synergistic two-way collaborative mechanism promotes the early-stage feature fusion and efficiently exploits the existing knowledge of CLIP. CSKT outperforms the state-of-the-art approaches across three benchmark datasets when the training parameters merely account for 7.",
    "path": "papers/23/09/2309.09496.json",
    "total_tokens": 943,
    "translated_title": "基于CLIP的文字化人物检索的协同知识传递",
    "translated_abstract": "文字化人物检索（TPR）旨在根据文本查询检索目标人物图像。主要挑战在于弥合视觉和语言模态之间的巨大差距，特别是在处理有限的大规模数据集时。本文提出了一种基于CLIP的文字化人物检索的协同知识传递（CSKT）方法。具体而言，为了探索CLIP在输入端的知识，我们首先提出了一种由文本到图像和图像到文本的双向提示和耦合投影构建的双向提示传递（BPT）模块。其次，在视觉和语言的多头注意力（MHA）的输出端，设计了双适配器传递（DAT）以传递知识。这种协同的双向合作机制促进了早期特征融合，并有效地利用了CLIP的现有知识。当训练参数仅占7%时，CSKT在三个基准数据集上优于现有方法。",
    "tldr": "本文提出了一种基于CLIP的文字化人物检索的协同知识传递（CSKT）方法，通过双向提示传递（BPT）和双适配器传递（DAT）实现了输入端和输出端的知识传递，并在三个基准数据集上取得了优于现有方法的性能。",
    "en_tdlr": "This paper proposes a CLIP-based Synergistic Knowledge Transfer (CSKT) approach for text-based person retrieval, which utilizes Bidirectional Prompts Transferring (BPT) and Dual Adapters Transferring (DAT) to transfer knowledge between input and output sides, achieving superior performance on three benchmark datasets compared to existing approaches."
}