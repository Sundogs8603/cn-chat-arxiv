{
    "title": "Reconstruction of Patient-Specific Confounders in AI-based Radiologic Image Interpretation using Generative Pretraining. (arXiv:2309.17123v1 [cs.CV])",
    "abstract": "Detecting misleading patterns in automated diagnostic assistance systems, such as those powered by Artificial Intelligence, is critical to ensuring their reliability, particularly in healthcare. Current techniques for evaluating deep learning models cannot visualize confounding factors at a diagnostic level. Here, we propose a self-conditioned diffusion model termed DiffChest and train it on a dataset of 515,704 chest radiographs from 194,956 patients from multiple healthcare centers in the United States and Europe. DiffChest explains classifications on a patient-specific level and visualizes the confounding factors that may mislead the model. We found high inter-reader agreement when evaluating DiffChest's capability to identify treatment-related confounders, with Fleiss' Kappa values of 0.8 or higher across most imaging findings. Confounders were accurately captured with 11.1% to 100% prevalence rates. Furthermore, our pretraining process optimized the model to capture the most relev",
    "link": "http://arxiv.org/abs/2309.17123",
    "context": "Title: Reconstruction of Patient-Specific Confounders in AI-based Radiologic Image Interpretation using Generative Pretraining. (arXiv:2309.17123v1 [cs.CV])\nAbstract: Detecting misleading patterns in automated diagnostic assistance systems, such as those powered by Artificial Intelligence, is critical to ensuring their reliability, particularly in healthcare. Current techniques for evaluating deep learning models cannot visualize confounding factors at a diagnostic level. Here, we propose a self-conditioned diffusion model termed DiffChest and train it on a dataset of 515,704 chest radiographs from 194,956 patients from multiple healthcare centers in the United States and Europe. DiffChest explains classifications on a patient-specific level and visualizes the confounding factors that may mislead the model. We found high inter-reader agreement when evaluating DiffChest's capability to identify treatment-related confounders, with Fleiss' Kappa values of 0.8 or higher across most imaging findings. Confounders were accurately captured with 11.1% to 100% prevalence rates. Furthermore, our pretraining process optimized the model to capture the most relev",
    "path": "papers/23/09/2309.17123.json",
    "total_tokens": 991,
    "translated_title": "基于生成预训练的人工智能辅助放射图像解读中的患者特定混淆因素重建",
    "translated_abstract": "检测自动化诊断辅助系统中的误导性模式对于确保其可靠性至关重要，特别是在医疗保健领域。目前的深度学习模型评估技术无法在诊断水平上可视化混淆因素。在这里，我们提出了一种自我条件扩散模型DiffChest，并在美国和欧洲多个医疗中心的194,956名患者的515,704张胸部X射线图像的数据集上对其进行训练。DiffChest在患者特定级别上解释分类结果，并可视化可能误导模型的混淆因素。我们发现，在评估DiffChest识别与治疗相关的混淆因素的能力时，评估者之间存在较高的一致性，大多数影像结果的Fleiss' Kappa值为0.8或更高。混淆因素的捕捉准确率为11.1%到100%不等。此外，我们的预训练过程优化了模型以捕捉最相关的因素。",
    "tldr": "该论文提出了一种自我条件扩散模型DiffChest，通过在大规模胸部X射线图像数据集上训练，可解释和可视化可能误导模型的混淆因素。通过评估DiffChest在识别与治疗相关的混淆因素方面的能力，发现其具有较高的一致性和准确性。"
}