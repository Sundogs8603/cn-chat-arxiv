{
    "title": "Text Encoders Lack Knowledge: Leveraging Generative LLMs for Domain-Specific Semantic Textual Similarity. (arXiv:2309.06541v1 [cs.CL])",
    "abstract": "Amidst the sharp rise in the evaluation of large language models (LLMs) on various tasks, we find that semantic textual similarity (STS) has been under-explored. In this study, we show that STS can be cast as a text generation problem while maintaining strong performance on multiple STS benchmarks. Additionally, we show generative LLMs significantly outperform existing encoder-based STS models when characterizing the semantic similarity between two texts with complex semantic relationships dependent on world knowledge. We validate this claim by evaluating both generative LLMs and existing encoder-based STS models on three newly collected STS challenge sets which require world knowledge in the domains of Health, Politics, and Sports. All newly collected data is sourced from social media content posted after May 2023 to ensure the performance of closed-source models like ChatGPT cannot be credited to memorization. Our results show that, on average, generative LLMs outperform the best enc",
    "link": "http://arxiv.org/abs/2309.06541",
    "context": "Title: Text Encoders Lack Knowledge: Leveraging Generative LLMs for Domain-Specific Semantic Textual Similarity. (arXiv:2309.06541v1 [cs.CL])\nAbstract: Amidst the sharp rise in the evaluation of large language models (LLMs) on various tasks, we find that semantic textual similarity (STS) has been under-explored. In this study, we show that STS can be cast as a text generation problem while maintaining strong performance on multiple STS benchmarks. Additionally, we show generative LLMs significantly outperform existing encoder-based STS models when characterizing the semantic similarity between two texts with complex semantic relationships dependent on world knowledge. We validate this claim by evaluating both generative LLMs and existing encoder-based STS models on three newly collected STS challenge sets which require world knowledge in the domains of Health, Politics, and Sports. All newly collected data is sourced from social media content posted after May 2023 to ensure the performance of closed-source models like ChatGPT cannot be credited to memorization. Our results show that, on average, generative LLMs outperform the best enc",
    "path": "papers/23/09/2309.06541.json",
    "total_tokens": 926,
    "translated_title": "文本编码器缺乏知识：利用生成语言模型（LLM）增强领域特定的语义文本相似性",
    "translated_abstract": "在大型语言模型（LLM）在各种任务上得到广泛应用的背景下，我们发现语义文本相似性（STS）的研究相对较少。在本研究中，我们展示了STS可以被视为一个文本生成问题，并在多个STS基准测试中保持强大的性能。此外，当描述依赖于世界知识的两个文本之间的语义相似性时，我们发现生成式LLMs在性能上显著优于现有的基于编码器的STS模型。为了验证这一观点，我们在健康、政治和体育领域收集了三个新的STS挑战数据集，这些数据集需要在世界知识上进行判断。所有新收集的数据都来自于2023年5月之后发布的社交媒体内容，以确保ChatGPT等闭源模型的性能不能归功于记忆。我们的结果表明，平均而言，生成式LLM在性能上优于最好的编码器模型。",
    "tldr": "生成式LLMs在描述复杂语义关系依赖于世界知识的两个文本之间的语义相似性时，显著优于基于编码器的STS模型，并在多个STS基准测试中保持强大的性能。",
    "en_tdlr": "Generative LLMs significantly outperform existing encoder-based STS models when characterizing the semantic similarity between two texts with complex semantic relationships dependent on world knowledge, and achieve strong performance on multiple STS benchmarks."
}