{
    "title": "Enhancing Sharpness-Aware Optimization Through Variance Suppression. (arXiv:2309.15639v1 [cs.LG])",
    "abstract": "Sharpness-aware minimization (SAM) has well documented merits in enhancing generalization of deep neural networks, even without sizable data augmentation. Embracing the geometry of the loss function, where neighborhoods of 'flat minima' heighten generalization ability, SAM seeks 'flat valleys' by minimizing the maximum loss caused by an adversary perturbing parameters within the neighborhood. Although critical to account for sharpness of the loss function, such an 'over-friendly adversary' can curtail the outmost level of generalization. The novel approach of this contribution fosters stabilization of adversaries through variance suppression (VaSSO) to avoid such friendliness. VaSSO's provable stability safeguards its numerical improvement over SAM in model-agnostic tasks, including image classification and machine translation. In addition, experiments confirm that VaSSO endows SAM with robustness against high levels of label noise.",
    "link": "http://arxiv.org/abs/2309.15639",
    "context": "Title: Enhancing Sharpness-Aware Optimization Through Variance Suppression. (arXiv:2309.15639v1 [cs.LG])\nAbstract: Sharpness-aware minimization (SAM) has well documented merits in enhancing generalization of deep neural networks, even without sizable data augmentation. Embracing the geometry of the loss function, where neighborhoods of 'flat minima' heighten generalization ability, SAM seeks 'flat valleys' by minimizing the maximum loss caused by an adversary perturbing parameters within the neighborhood. Although critical to account for sharpness of the loss function, such an 'over-friendly adversary' can curtail the outmost level of generalization. The novel approach of this contribution fosters stabilization of adversaries through variance suppression (VaSSO) to avoid such friendliness. VaSSO's provable stability safeguards its numerical improvement over SAM in model-agnostic tasks, including image classification and machine translation. In addition, experiments confirm that VaSSO endows SAM with robustness against high levels of label noise.",
    "path": "papers/23/09/2309.15639.json",
    "total_tokens": 883,
    "translated_title": "通过方差抑制增强锐度感知优化",
    "translated_abstract": "锐度感知最小化（SAM）在增强深度神经网络的泛化能力方面有着良好的记录，即使没有大规模的数据增强。SAM借助损失函数的几何特性，通过最小化在邻域内参数对敌对扰动引起的最大损失，寻找“平坦最小值”所在的“平坦山谷”，提高泛化能力。尽管考虑了损失函数的锐度是至关重要的，但这种“过于友好的敌对者”可能会限制泛化的最高水平。本文的新方法通过方差抑制（VaSSO）来稳定敌对者，避免这种友好性。 VaSSO的稳定性可证明，并在模型无关任务中（包括图像分类和机器翻译）相对于SAM有着数值上的改进。此外，实验证实VaSSO赋予SAM对高水平标签噪声的鲁棒性。",
    "tldr": "本文通过方差抑制的方法（VaSSO）增强了锐度感知最小化（SAM）的优化算法，提高了深度神经网络的泛化能力，特别适用于模型无关任务和对高水平标签噪声具有鲁棒性的情况。",
    "en_tdlr": "This paper enhances the sharpness-aware minimization (SAM) optimization algorithm through variance suppression (VaSSO), improving the generalization ability of deep neural networks, especially in model-agnostic tasks and against high levels of label noise."
}