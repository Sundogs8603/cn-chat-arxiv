{
    "title": "Learning Active Subspaces for Effective and Scalable Uncertainty Quantification in Deep Neural Networks. (arXiv:2309.03061v1 [stat.ML])",
    "abstract": "Bayesian inference for neural networks, or Bayesian deep learning, has the potential to provide well-calibrated predictions with quantified uncertainty and robustness. However, the main hurdle for Bayesian deep learning is its computational complexity due to the high dimensionality of the parameter space. In this work, we propose a novel scheme that addresses this limitation by constructing a low-dimensional subspace of the neural network parameters-referred to as an active subspace-by identifying the parameter directions that have the most significant influence on the output of the neural network. We demonstrate that the significantly reduced active subspace enables effective and scalable Bayesian inference via either Monte Carlo (MC) sampling methods, otherwise computationally intractable, or variational inference. Empirically, our approach provides reliable predictions with robust uncertainty estimates for various regression tasks.",
    "link": "http://arxiv.org/abs/2309.03061",
    "context": "Title: Learning Active Subspaces for Effective and Scalable Uncertainty Quantification in Deep Neural Networks. (arXiv:2309.03061v1 [stat.ML])\nAbstract: Bayesian inference for neural networks, or Bayesian deep learning, has the potential to provide well-calibrated predictions with quantified uncertainty and robustness. However, the main hurdle for Bayesian deep learning is its computational complexity due to the high dimensionality of the parameter space. In this work, we propose a novel scheme that addresses this limitation by constructing a low-dimensional subspace of the neural network parameters-referred to as an active subspace-by identifying the parameter directions that have the most significant influence on the output of the neural network. We demonstrate that the significantly reduced active subspace enables effective and scalable Bayesian inference via either Monte Carlo (MC) sampling methods, otherwise computationally intractable, or variational inference. Empirically, our approach provides reliable predictions with robust uncertainty estimates for various regression tasks.",
    "path": "papers/23/09/2309.03061.json",
    "total_tokens": 999,
    "translated_title": "学习主动子空间在深度神经网络的有效和可扩展的不确定性量化中",
    "translated_abstract": "贝叶斯推理用于神经网络或贝叶斯深度学习具有提供具有量化的不确定性和鲁棒性的良好校准预测的潜力。然而，贝叶斯深度学习的主要障碍是由于参数空间的高维度而造成的计算复杂性。在这项工作中，我们提出了一种新颖的方案，通过识别对神经网络输出具有最显著影响的参数方向，构建神经网络参数的低维子空间，即主动子空间。我们证明了显著减少的主动子空间通过蒙特卡罗（MC）采样方法（否则难以计算）或变分推理实现了有效和可扩展的贝叶斯推理。从实证上看，我们的方法为各种回归任务提供了可靠的预测和鲁棒的不确定性估计。",
    "tldr": "该论文提出了一种通过识别对神经网络输出具有最显著影响的参数方向构建低维子空间的方法，从而解决了贝叶斯深度学习中由于参数空间高维度而带来的计算复杂性问题。通过在显著减少的主动子空间上进行蒙特卡罗采样或变分推理，该方法实现了有效和可扩展的贝叶斯推理，并通过多个回归任务的实证验证了可靠的预测和鲁棒的不确定性估计。",
    "en_tdlr": "This paper proposes a method of constructing a low-dimensional subspace by identifying the parameter directions that have the most significant influence on the output of the neural network, thereby addressing the computational complexity issue in Bayesian deep learning. By performing Monte Carlo sampling or variational inference on the significantly reduced active subspace, this method enables effective and scalable Bayesian inference, leading to reliable predictions and robust uncertainty estimates for various regression tasks."
}