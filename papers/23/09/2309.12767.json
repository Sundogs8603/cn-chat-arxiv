{
    "title": "Furthest Reasoning with Plan Assessment: Stable Reasoning Path with Retrieval-Augmented Large Language Models. (arXiv:2309.12767v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs), acting as a powerful reasoner and generator, exhibit extraordinary performance across various natural language tasks, such as question answering (QA). Among these tasks, Multi-Hop Question Answering (MHQA) stands as a widely discussed category, necessitating seamless integration between LLMs and the retrieval of external knowledge. Existing methods employ LLM to generate reasoning paths and plans, and utilize IR to iteratively retrieve related knowledge, but these approaches have inherent flaws. On one hand, Information Retriever (IR) is hindered by the low quality of generated queries by LLM. On the other hand, LLM is easily misguided by the irrelevant knowledge by IR. These inaccuracies, accumulated by the iterative interaction between IR and LLM, lead to a disaster in effectiveness at the end. To overcome above barriers, in this paper, we propose a novel pipeline for MHQA called Furthest-Reasoning-with-Plan-Assessment (FuRePA), including an improved fra",
    "link": "http://arxiv.org/abs/2309.12767",
    "context": "Title: Furthest Reasoning with Plan Assessment: Stable Reasoning Path with Retrieval-Augmented Large Language Models. (arXiv:2309.12767v1 [cs.CL])\nAbstract: Large Language Models (LLMs), acting as a powerful reasoner and generator, exhibit extraordinary performance across various natural language tasks, such as question answering (QA). Among these tasks, Multi-Hop Question Answering (MHQA) stands as a widely discussed category, necessitating seamless integration between LLMs and the retrieval of external knowledge. Existing methods employ LLM to generate reasoning paths and plans, and utilize IR to iteratively retrieve related knowledge, but these approaches have inherent flaws. On one hand, Information Retriever (IR) is hindered by the low quality of generated queries by LLM. On the other hand, LLM is easily misguided by the irrelevant knowledge by IR. These inaccuracies, accumulated by the iterative interaction between IR and LLM, lead to a disaster in effectiveness at the end. To overcome above barriers, in this paper, we propose a novel pipeline for MHQA called Furthest-Reasoning-with-Plan-Assessment (FuRePA), including an improved fra",
    "path": "papers/23/09/2309.12767.json",
    "total_tokens": 918,
    "translated_title": "与计划评估的最远推理：具有检索增强的大语言模型的稳定推理路径",
    "translated_abstract": "大语言模型（LLMs）作为强大的推理和生成器，在各种自然语言任务（如问答）中展现出非凡的性能。在这些任务中，多跳问答（MHQA）是一个广泛讨论的类别，需要LLMs与外部知识的无缝集成。现有的方法采用LLMs生成推理路径和计划，并利用IR迭代检索相关知识，但这些方法存在固有缺陷。一方面，信息检索器（IR）受到LLMs生成查询质量低的影响。另一方面，LLMs很容易被IR提供的无关知识误导。这些不准确性由IR与LLMs之间的迭代交互累积，最终导致效果的灾难性衰减。为了克服以上障碍，本文提出了一种新的MHQA流水线，称为最远推理与计划评估（FuRePA），包括一个改进的fra",
    "tldr": "本文提出了一种名为FuRePA的新的MHQA流水线，通过改进的fra算法解决了现有方法中信息检索器受到LLMs生成查询质量低和LLMs被IR提供的无关知识误导的问题。"
}