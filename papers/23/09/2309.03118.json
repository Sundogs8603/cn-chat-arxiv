{
    "title": "Knowledge Solver: Teaching LLMs to Search for Domain Knowledge from Knowledge Graphs. (arXiv:2309.03118v1 [cs.CL])",
    "abstract": "Large language models (LLMs), such as ChatGPT and GPT-4, are versatile and can solve different tasks due to their emergent ability and generalizability. However, LLMs sometimes lack domain-specific knowledge to perform tasks, which would also cause hallucination during inference. In some previous works, additional modules like graph neural networks (GNNs) are trained on retrieved knowledge from external knowledge bases, aiming to mitigate the problem of lacking domain-specific knowledge. However, incorporating additional modules: 1) would need retraining additional modules when encountering novel domains; 2) would become a bottleneck since LLMs' strong abilities are not fully utilized for retrieval. In this paper, we propose a paradigm, termed Knowledge Solver (KSL), to teach LLMs to search for essential knowledge from external knowledge bases by harnessing their own strong generalizability. Specifically, we design a simple yet effective prompt to transform retrieval into a multi-hop d",
    "link": "http://arxiv.org/abs/2309.03118",
    "context": "Title: Knowledge Solver: Teaching LLMs to Search for Domain Knowledge from Knowledge Graphs. (arXiv:2309.03118v1 [cs.CL])\nAbstract: Large language models (LLMs), such as ChatGPT and GPT-4, are versatile and can solve different tasks due to their emergent ability and generalizability. However, LLMs sometimes lack domain-specific knowledge to perform tasks, which would also cause hallucination during inference. In some previous works, additional modules like graph neural networks (GNNs) are trained on retrieved knowledge from external knowledge bases, aiming to mitigate the problem of lacking domain-specific knowledge. However, incorporating additional modules: 1) would need retraining additional modules when encountering novel domains; 2) would become a bottleneck since LLMs' strong abilities are not fully utilized for retrieval. In this paper, we propose a paradigm, termed Knowledge Solver (KSL), to teach LLMs to search for essential knowledge from external knowledge bases by harnessing their own strong generalizability. Specifically, we design a simple yet effective prompt to transform retrieval into a multi-hop d",
    "path": "papers/23/09/2309.03118.json",
    "total_tokens": 950,
    "translated_title": "知识求解器：教授LLMs从知识图谱中搜索领域知识",
    "translated_abstract": "大型语言模型（LLMs）如ChatGPT和GPT-4由于其新兴能力和泛化能力而具有多功能性，可以解决不同的任务。然而，LLMs有时缺乏领域特定的知识来执行任务，这也会导致推理过程中出现虚假信息。在一些先前的工作中，额外的模块如图神经网络（GNNs）被训练用于从外部知识库中检索知识，旨在缓解缺乏领域特定知识的问题。然而，将额外的模块纳入: 1）在遇到新领域时需要重新训练额外的模块; 2）会成为瓶颈，因为LLMs的强大能力没有充分利用于检索。在本文中，我们提出了一种名为Knowledge Solver（KSL）的范式，通过利用LLMs自身的强大泛化能力，教导LLMs从外部知识库中搜索关键知识。具体而言，我们设计了一个简单而有效的提示来将检索转化为多跳的形式。",
    "tldr": "本文提出了一种名为Knowledge Solver（KSL）的方法，通过利用大型语言模型（LLMs）的泛化能力，教导LLMs从外部知识库中搜索关键知识，从而解决了LLMs缺乏领域特定知识的问题。"
}