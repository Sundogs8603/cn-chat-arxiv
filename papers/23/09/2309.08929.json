{
    "title": "Leveraging Multi-lingual Positive Instances in Contrastive Learning to Improve Sentence Embedding",
    "abstract": "Learning multi-lingual sentence embeddings is a fundamental task in natural language processing. Recent trends in learning both mono-lingual and multi-lingual sentence embeddings are mainly based on contrastive learning (CL) among an anchor, one positive, and multiple negative instances. In this work, we argue that leveraging multiple positives should be considered for multi-lingual sentence embeddings because (1) positives in a diverse set of languages can benefit cross-lingual learning, and (2) transitive similarity across multiple positives can provide reliable structural information for learning. In order to investigate the impact of multiple positives in CL, we propose a novel approach, named MPCL, to effectively utilize multiple positive instances to improve the learning of multi-lingual sentence embeddings. Experimental results on various backbone models and downstream tasks demonstrate that MPCL leads to better retrieval, semantic similarity, and classification performances com",
    "link": "https://arxiv.org/abs/2309.08929",
    "context": "Title: Leveraging Multi-lingual Positive Instances in Contrastive Learning to Improve Sentence Embedding\nAbstract: Learning multi-lingual sentence embeddings is a fundamental task in natural language processing. Recent trends in learning both mono-lingual and multi-lingual sentence embeddings are mainly based on contrastive learning (CL) among an anchor, one positive, and multiple negative instances. In this work, we argue that leveraging multiple positives should be considered for multi-lingual sentence embeddings because (1) positives in a diverse set of languages can benefit cross-lingual learning, and (2) transitive similarity across multiple positives can provide reliable structural information for learning. In order to investigate the impact of multiple positives in CL, we propose a novel approach, named MPCL, to effectively utilize multiple positive instances to improve the learning of multi-lingual sentence embeddings. Experimental results on various backbone models and downstream tasks demonstrate that MPCL leads to better retrieval, semantic similarity, and classification performances com",
    "path": "papers/23/09/2309.08929.json",
    "total_tokens": 834,
    "translated_title": "利用多语言正例在对比学习中提升句子嵌入",
    "translated_abstract": "学习多语言句子嵌入是自然语言处理中的基础任务。最近学习单语和多语句子嵌入的趋势主要基于对比学习（CL），其中包括一个锚点、一个正例和多个负例。本文认为应该考虑利用多个正例来改进多语言句子嵌入，因为（1）不同语言的正例可以有益于跨语言学习，（2）多个正例之间的传递相似性可以提供可靠的结构信息用于学习。为了研究对比学习中多个正例的影响，我们提出了一种名为MPCL的新方法，以有效利用多个正例来提升多语言句子嵌入的学习效果。在各种主干模型和下游任务上的实验结果表明，MPCL可以提高检索、语义相似性和分类性能。",
    "tldr": "本研究提出了一种名为MPCL的方法，在对比学习中利用多语言正例来改进句子嵌入。实验结果表明，MPCL可以提高检索、语义相似性和分类性能。"
}