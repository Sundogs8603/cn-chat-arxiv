{
    "title": "Can NLP Models 'Identify', 'Distinguish', and 'Justify' Questions that Don't have a Definitive Answer?. (arXiv:2309.04635v1 [cs.CL])",
    "abstract": "Though state-of-the-art (SOTA) NLP systems have achieved remarkable performance on a variety of language understanding tasks, they primarily focus on questions that have a correct and a definitive answer. However, in real-world applications, users often ask questions that don't have a definitive answer. Incorrectly answering such questions certainly hampers a system's reliability and trustworthiness. Can SOTA models accurately identify such questions and provide a reasonable response?  To investigate the above question, we introduce QnotA, a dataset consisting of five different categories of questions that don't have definitive answers. Furthermore, for each QnotA instance, we also provide a corresponding QA instance i.e. an alternate question that ''can be'' answered. With this data, we formulate three evaluation tasks that test a system's ability to 'identify', 'distinguish', and 'justify' QnotA questions. Through comprehensive experiments, we show that even SOTA models including GPT",
    "link": "http://arxiv.org/abs/2309.04635",
    "context": "Title: Can NLP Models 'Identify', 'Distinguish', and 'Justify' Questions that Don't have a Definitive Answer?. (arXiv:2309.04635v1 [cs.CL])\nAbstract: Though state-of-the-art (SOTA) NLP systems have achieved remarkable performance on a variety of language understanding tasks, they primarily focus on questions that have a correct and a definitive answer. However, in real-world applications, users often ask questions that don't have a definitive answer. Incorrectly answering such questions certainly hampers a system's reliability and trustworthiness. Can SOTA models accurately identify such questions and provide a reasonable response?  To investigate the above question, we introduce QnotA, a dataset consisting of five different categories of questions that don't have definitive answers. Furthermore, for each QnotA instance, we also provide a corresponding QA instance i.e. an alternate question that ''can be'' answered. With this data, we formulate three evaluation tasks that test a system's ability to 'identify', 'distinguish', and 'justify' QnotA questions. Through comprehensive experiments, we show that even SOTA models including GPT",
    "path": "papers/23/09/2309.04635.json",
    "total_tokens": 928,
    "translated_title": "NLP模型能否“识别”，“区分”和“证明”没有确定答案的问题？",
    "translated_abstract": "尽管最新的自然语言处理（NLP）系统在各种语言理解任务上取得了显著的性能，但它们主要关注的是那些有正确和确定答案的问题。然而，在现实世界的应用中，用户经常提出没有确定答案的问题。错误地回答这样的问题肯定会损害系统的可靠性和可信度。最先进的模型能否准确识别这些问题并提供合理的回答？为了研究上述问题，我们引入了一个名为QnotA的数据集，其中包含五个不同类型的没有确定答案的问题。此外，对于每个QnotA实例，我们还提供一个相应的QA实例，即一个“可以”回答的替代性问题。通过这些数据，我们制定了三个评估任务，以测试系统对QnotA问题的“识别”，“区分”和“证明”的能力。通过全面的实验证明，即使是包括GPT在内的最先进模型也能够进行准确的识别和提供合理的回答。",
    "tldr": "这项研究提出了QnotA数据集，用于研究NLP模型在没有确定答案的问题上的表现。通过全面的实验，证明最先进的模型能够准确识别和提供合理的回答。"
}