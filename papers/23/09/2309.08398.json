{
    "title": "Exploring Meta Information for Audio-based Zero-shot Bird Classification. (arXiv:2309.08398v1 [cs.SD])",
    "abstract": "Advances in passive acoustic monitoring and machine learning have led to the procurement of vast datasets for computational bioacoustic research. Nevertheless, data scarcity is still an issue for rare and underrepresented species. This study investigates how meta-information can improve zero-shot audio classification, utilising bird species as an example case study due to the availability of rich and diverse metadata. We investigate three different sources of metadata: textual bird sound descriptions encoded via (S)BERT, functional traits (AVONET), and bird life-history (BLH) characteristics. As audio features, we extract audio spectrogram transformer (AST) embeddings and project them to the dimension of the auxiliary information by adopting a single linear layer. Then, we employ the dot product as compatibility function and a standard zero-shot learning ranking hinge loss to determine the correct class. The best results are achieved by concatenating the AVONET and BLH features attaini",
    "link": "http://arxiv.org/abs/2309.08398",
    "context": "Title: Exploring Meta Information for Audio-based Zero-shot Bird Classification. (arXiv:2309.08398v1 [cs.SD])\nAbstract: Advances in passive acoustic monitoring and machine learning have led to the procurement of vast datasets for computational bioacoustic research. Nevertheless, data scarcity is still an issue for rare and underrepresented species. This study investigates how meta-information can improve zero-shot audio classification, utilising bird species as an example case study due to the availability of rich and diverse metadata. We investigate three different sources of metadata: textual bird sound descriptions encoded via (S)BERT, functional traits (AVONET), and bird life-history (BLH) characteristics. As audio features, we extract audio spectrogram transformer (AST) embeddings and project them to the dimension of the auxiliary information by adopting a single linear layer. Then, we employ the dot product as compatibility function and a standard zero-shot learning ranking hinge loss to determine the correct class. The best results are achieved by concatenating the AVONET and BLH features attaini",
    "path": "papers/23/09/2309.08398.json",
    "total_tokens": 856,
    "translated_title": "探索基于元信息的基于音频的零样本鸟类分类",
    "translated_abstract": "被动声学监测和机器学习的进步已经为计算生物声学研究提供了大量数据集。然而，对于稀有和代表性不足的物种来说，数据稀缺仍然是一个问题。本研究通过使用丰富和多样的元数据，以鸟类物种为例进行了探索，研究了如何利用元信息来改善零样本音频分类。我们研究了三种不同的元数据来源：通过(S)BERT编码的文本鸟鸣描述，功能特性(AVONET)和鸟类生活史(BLH)特征。作为音频特征，我们提取音频频谱图变换器(AST)嵌入，并通过采用单个线性层将其投影到辅助信息的维度上。然后，我们采用点积作为兼容性函数，并使用标准的零样本学习排名铰链损失确定正确的类别。通过连接AVONET和BLH特征，我们获得了最佳结果。",
    "tldr": "该研究探索了如何利用元信息来改善基于音频的零样本鸟类分类，并通过连接不同的元数据和音频特征获得最佳结果。",
    "en_tdlr": "This study explores how meta-information can improve audio-based zero-shot bird classification and achieves the best results by combining different metadata and audio features."
}