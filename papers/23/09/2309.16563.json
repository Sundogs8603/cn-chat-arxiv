{
    "title": "CRIMED: Lower and Upper Bounds on Regret for Bandits with Unbounded Stochastic Corruption. (arXiv:2309.16563v1 [stat.ML])",
    "abstract": "We investigate the regret-minimisation problem in a multi-armed bandit setting with arbitrary corruptions. Similar to the classical setup, the agent receives rewards generated independently from the distribution of the arm chosen at each time. However, these rewards are not directly observed. Instead, with a fixed $\\varepsilon\\in (0,\\frac{1}{2})$, the agent observes a sample from the chosen arm's distribution with probability $1-\\varepsilon$, or from an arbitrary corruption distribution with probability $\\varepsilon$. Importantly, we impose no assumptions on these corruption distributions, which can be unbounded. In this setting, accommodating potentially unbounded corruptions, we establish a problem-dependent lower bound on regret for a given family of arm distributions. We introduce CRIMED, an asymptotically-optimal algorithm that achieves the exact lower bound on regret for bandits with Gaussian distributions with known variance. Additionally, we provide a finite-sample analysis of ",
    "link": "http://arxiv.org/abs/2309.16563",
    "context": "Title: CRIMED: Lower and Upper Bounds on Regret for Bandits with Unbounded Stochastic Corruption. (arXiv:2309.16563v1 [stat.ML])\nAbstract: We investigate the regret-minimisation problem in a multi-armed bandit setting with arbitrary corruptions. Similar to the classical setup, the agent receives rewards generated independently from the distribution of the arm chosen at each time. However, these rewards are not directly observed. Instead, with a fixed $\\varepsilon\\in (0,\\frac{1}{2})$, the agent observes a sample from the chosen arm's distribution with probability $1-\\varepsilon$, or from an arbitrary corruption distribution with probability $\\varepsilon$. Importantly, we impose no assumptions on these corruption distributions, which can be unbounded. In this setting, accommodating potentially unbounded corruptions, we establish a problem-dependent lower bound on regret for a given family of arm distributions. We introduce CRIMED, an asymptotically-optimal algorithm that achieves the exact lower bound on regret for bandits with Gaussian distributions with known variance. Additionally, we provide a finite-sample analysis of ",
    "path": "papers/23/09/2309.16563.json",
    "total_tokens": 947,
    "translated_title": "CRIMED：具有无界随机破坏的赌徒问题的遗憾下界和上界",
    "translated_abstract": "我们研究了在多臂赌徒问题中具有任意破坏的遗憾最小化问题。与经典设定类似，代理接收到的奖励是从每个时间点选择的臂的分布独立生成的。然而，这些奖励并不直接观察到。相反，对于固定的ε∈(0,12)，代理以概率1-ε从选择的臂的分布中观测一个样本，或以概率ε从任意破坏分布中观测。重要的是，我们对这些破坏分布不做任何假设，它们可以是无界的。在这种可能具有无界破坏的情况下，我们为给定的臂分布族建立了一个与问题相关的遗憾下界。我们引入了CRIMED，这是一个渐近最优的算法，它在具有已知方差的高斯分布赌徒问题上实现了遗憾下界。此外，我们还对有限样本进行了分析。",
    "tldr": "本文研究了具有任意破坏的多臂赌徒问题，并建立了一个与问题相关的遗憾下界。我们提出了CRIMED算法，该算法在具有已知方差的高斯分布赌徒问题上实现了遗憾下界。"
}