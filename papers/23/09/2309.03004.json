{
    "title": "Theoretical Explanation of Activation Sparsity through Flat Minima and Adversarial Robustness. (arXiv:2309.03004v1 [cs.LG])",
    "abstract": "A recent empirical observation of activation sparsity in MLP layers offers an opportunity to drastically reduce computation costs for free. Despite several works attributing it to training dynamics, the theoretical explanation of activation sparsity's emergence is restricted to shallow networks, small training steps well as modified training, even though the sparsity has been found in deep models trained by vanilla protocols for large steps. To fill the three gaps, we propose the notion of gradient sparsity as the source of activation sparsity and a theoretical explanation based on it that explains gradient sparsity and then activation sparsity as necessary steps to adversarial robustness w.r.t. hidden features and parameters, which is approximately the flatness of minima for well-learned models. The theory applies to standardly trained LayerNorm-ed pure MLPs, and further to Transformers or other architectures if noises are added to weights during training. To eliminate other sources o",
    "link": "http://arxiv.org/abs/2309.03004",
    "context": "Title: Theoretical Explanation of Activation Sparsity through Flat Minima and Adversarial Robustness. (arXiv:2309.03004v1 [cs.LG])\nAbstract: A recent empirical observation of activation sparsity in MLP layers offers an opportunity to drastically reduce computation costs for free. Despite several works attributing it to training dynamics, the theoretical explanation of activation sparsity's emergence is restricted to shallow networks, small training steps well as modified training, even though the sparsity has been found in deep models trained by vanilla protocols for large steps. To fill the three gaps, we propose the notion of gradient sparsity as the source of activation sparsity and a theoretical explanation based on it that explains gradient sparsity and then activation sparsity as necessary steps to adversarial robustness w.r.t. hidden features and parameters, which is approximately the flatness of minima for well-learned models. The theory applies to standardly trained LayerNorm-ed pure MLPs, and further to Transformers or other architectures if noises are added to weights during training. To eliminate other sources o",
    "path": "papers/23/09/2309.03004.json",
    "total_tokens": 1005,
    "translated_title": "通过平坦极小值和对抗鲁棒性解释激活稀疏性的理论解释",
    "translated_abstract": "最近对MLP层中的激活稀疏性的实证观察为大幅降低计算成本提供了机会。尽管有几项研究将其归因于训练动力学，但激活稀疏性的理论解释仅限于浅层网络、小训练步长以及修改的训练，尽管这种稀疏性已在通过vanilla协议进行大步骤训练的深层模型中被发现。为了填补这三个差距，我们提出了梯度稀疏性的概念作为激活稀疏性的源头，并基于此提出了一个理论解释，该解释将梯度稀疏性和激活稀疏性解释为对抗性鲁棒性的必要步骤，以隐藏特征和参数而言，这大致等于对学习良好模型的极小值平坦性。这个理论适用于经过LayerNorm标准训练的纯MLP，并且如果在训练过程中给权重添加噪声，还适用于Transformers或其他架构。为了消除其他来源的激活稀疏性，我们还进行了进一步的实证研究。",
    "tldr": "提出了一个理论解释，将梯度稀疏性和激活稀疏性解释为对抗性鲁棒性的必要步骤，以隐藏特征和参数而言，这大致等于对学习良好模型的极小值平坦性。"
}