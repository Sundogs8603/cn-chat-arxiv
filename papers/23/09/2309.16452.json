{
    "title": "On the Trade-offs between Adversarial Robustness and Actionable Explanations. (arXiv:2309.16452v1 [cs.LG])",
    "abstract": "As machine learning models are increasingly being employed in various high-stakes settings, it becomes important to ensure that predictions of these models are not only adversarially robust, but also readily explainable to relevant stakeholders. However, it is unclear if these two notions can be simultaneously achieved or if there exist trade-offs between them. In this work, we make one of the first attempts at studying the impact of adversarially robust models on actionable explanations which provide end users with a means for recourse. We theoretically and empirically analyze the cost (ease of implementation) and validity (probability of obtaining a positive model prediction) of recourses output by state-of-the-art algorithms when the underlying models are adversarially robust vs. non-robust. More specifically, we derive theoretical bounds on the differences between the cost and the validity of the recourses generated by state-of-the-art algorithms for adversarially robust vs. non-ro",
    "link": "http://arxiv.org/abs/2309.16452",
    "context": "Title: On the Trade-offs between Adversarial Robustness and Actionable Explanations. (arXiv:2309.16452v1 [cs.LG])\nAbstract: As machine learning models are increasingly being employed in various high-stakes settings, it becomes important to ensure that predictions of these models are not only adversarially robust, but also readily explainable to relevant stakeholders. However, it is unclear if these two notions can be simultaneously achieved or if there exist trade-offs between them. In this work, we make one of the first attempts at studying the impact of adversarially robust models on actionable explanations which provide end users with a means for recourse. We theoretically and empirically analyze the cost (ease of implementation) and validity (probability of obtaining a positive model prediction) of recourses output by state-of-the-art algorithms when the underlying models are adversarially robust vs. non-robust. More specifically, we derive theoretical bounds on the differences between the cost and the validity of the recourses generated by state-of-the-art algorithms for adversarially robust vs. non-ro",
    "path": "papers/23/09/2309.16452.json",
    "total_tokens": 919,
    "translated_title": "关于对抗鲁棒性和可操作解释之间的权衡",
    "translated_abstract": "随着机器学习模型在各种高风险环境中的应用越来越广泛，确保这些模型的预测不仅具有对抗性鲁棒性，而且还能向相关利益相关者提供可解释性变得越来越重要。然而，目前尚不清楚是否可以同时实现这两个概念，或者它们之间是否存在权衡。在这项工作中，我们首次尝试研究对抗性鲁棒模型对可操作解释的影响，这些解释为最终用户提供了追索权利。我们在理论和实证层面上分析了先进算法生成的追索结果的成本（实施的容易程度）和有效性（获得正向模型预测的概率），并比较了对抗性鲁棒和非鲁棒模型生成的追索结果之间的差异。具体而言，我们推导出对抗性鲁棒和非鲁棒模型生成的追索结果的成本和有效性之间的理论界限。",
    "tldr": "本论文研究了对抗鲁棒模型对可操作解释的影响，并通过理论和实证分析比较了对抗性鲁棒和非鲁棒模型生成的追索结果的成本和有效性之间的差异。",
    "en_tdlr": "This paper investigates the impact of adversarially robust models on actionable explanations, and compares the cost and validity differences of recourses generated by adversarially robust and non-robust models through theoretical and empirical analysis."
}