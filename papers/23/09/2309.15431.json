{
    "title": "Local Compressed Video Stream Learning for Generic Event Boundary Detection. (arXiv:2309.15431v1 [cs.CV])",
    "abstract": "Generic event boundary detection aims to localize the generic, taxonomy-free event boundaries that segment videos into chunks. Existing methods typically require video frames to be decoded before feeding into the network, which contains significant spatio-temporal redundancy and demands considerable computational power and storage space. To remedy these issues, we propose a novel compressed video representation learning method for event boundary detection that is fully end-to-end leveraging rich information in the compressed domain, i.e., RGB, motion vectors, residuals, and the internal group of pictures (GOP) structure, without fully decoding the video. Specifically, we use lightweight ConvNets to extract features of the P-frames in the GOPs and spatial-channel attention module (SCAM) is designed to refine the feature representations of the P-frames based on the compressed information with bidirectional information flow. To learn a suitable representation for boundary detection, we co",
    "link": "http://arxiv.org/abs/2309.15431",
    "context": "Title: Local Compressed Video Stream Learning for Generic Event Boundary Detection. (arXiv:2309.15431v1 [cs.CV])\nAbstract: Generic event boundary detection aims to localize the generic, taxonomy-free event boundaries that segment videos into chunks. Existing methods typically require video frames to be decoded before feeding into the network, which contains significant spatio-temporal redundancy and demands considerable computational power and storage space. To remedy these issues, we propose a novel compressed video representation learning method for event boundary detection that is fully end-to-end leveraging rich information in the compressed domain, i.e., RGB, motion vectors, residuals, and the internal group of pictures (GOP) structure, without fully decoding the video. Specifically, we use lightweight ConvNets to extract features of the P-frames in the GOPs and spatial-channel attention module (SCAM) is designed to refine the feature representations of the P-frames based on the compressed information with bidirectional information flow. To learn a suitable representation for boundary detection, we co",
    "path": "papers/23/09/2309.15431.json",
    "total_tokens": 966,
    "translated_title": "基于局部压缩视频流学习的通用事件边界检测",
    "translated_abstract": "通用事件边界检测旨在将视频分段为块，定位通用且无分类的事件边界。现有方法通常需要在将视频帧解码后才将其输入网络，这其中存在较大的时空冗余，并且需要较大的计算能力和存储空间。为了解决这些问题，我们提出了一种全新的压缩视频表示学习方法，用于事件边界检测，它完全基于压缩域中丰富的信息，包括RGB、运动向量、残差和图像组（GOP）结构，而无需完全解码视频。具体而言，我们使用轻量级的ConvNets提取GOP中的P帧的特征，并设计了一种空间-通道注意力模块（SCAM），根据双向信息流使用压缩信息来细化P帧的特征表示。为了学习适合边界检测的表示，我们通过联合最小切割（JLC）和中心切割（CFC）来执行事件边界优化。",
    "tldr": "提出了一种基于局部压缩视频流学习的方法用于通用事件边界的检测，该方法能够在不完全解码视频情况下，利用压缩域中的丰富信息进行端到端的学习。使用轻量级ConvNets提取GOP中的P帧特征，并通过设计的空间-通道注意力模块进行特征细化，最终实现了准确的事件边界检测。"
}