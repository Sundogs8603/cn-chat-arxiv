{
    "title": "Visual In-Context Learning for Few-Shot Eczema Segmentation. (arXiv:2309.16656v1 [cs.CV])",
    "abstract": "Automated diagnosis of eczema from digital camera images is crucial for developing applications that allow patients to self-monitor their recovery. An important component of this is the segmentation of eczema region from such images. Current methods for eczema segmentation rely on deep neural networks such as convolutional (CNN)-based U-Net or transformer-based Swin U-Net. While effective, these methods require high volume of annotated data, which can be difficult to obtain. Here, we investigate the capabilities of visual in-context learning that can perform few-shot eczema segmentation with just a handful of examples and without any need for retraining models. Specifically, we propose a strategy for applying in-context learning for eczema segmentation with a generalist vision model called SegGPT. When benchmarked on a dataset of annotated eczema images, we show that SegGPT with just 2 representative example images from the training dataset performs better (mIoU: 36.69) than a CNN U-Ne",
    "link": "http://arxiv.org/abs/2309.16656",
    "context": "Title: Visual In-Context Learning for Few-Shot Eczema Segmentation. (arXiv:2309.16656v1 [cs.CV])\nAbstract: Automated diagnosis of eczema from digital camera images is crucial for developing applications that allow patients to self-monitor their recovery. An important component of this is the segmentation of eczema region from such images. Current methods for eczema segmentation rely on deep neural networks such as convolutional (CNN)-based U-Net or transformer-based Swin U-Net. While effective, these methods require high volume of annotated data, which can be difficult to obtain. Here, we investigate the capabilities of visual in-context learning that can perform few-shot eczema segmentation with just a handful of examples and without any need for retraining models. Specifically, we propose a strategy for applying in-context learning for eczema segmentation with a generalist vision model called SegGPT. When benchmarked on a dataset of annotated eczema images, we show that SegGPT with just 2 representative example images from the training dataset performs better (mIoU: 36.69) than a CNN U-Ne",
    "path": "papers/23/09/2309.16656.json",
    "total_tokens": 974,
    "translated_title": "视觉背景下的少样本湿疹分割学习",
    "translated_abstract": "从数字相机图像中自动诊断湿疹对于开发允许患者自我监测恢复的应用程序至关重要。其中一个重要的组成部分是从这些图像中分割湿疹区域。当前的湿疹分割方法依赖于深度神经网络，如基于卷积（CNN）的U-Net或基于转换器的Swin U-Net。虽然有效，但这些方法需要大量的注释数据，而这很难获得。在这里，我们研究了视觉背景下的少样本湿疹分割学习的能力，可以仅用少量示例进行湿疹分割，而无需对模型进行重新训练。具体而言，我们提出了一种应用于湿疹分割的视觉背景下学习策略，使用了一个名为SegGPT的通用视觉模型。在拥有注释湿疹图像的数据集上进行基准测试时，我们展示了SegGPT仅使用训练数据集中的2个代表性示例图像的性能更好（mIoU：36.69）。",
    "tldr": "这篇论文研究了视觉背景下的少样本湿疹分割学习的能力，提出了一种基于通用视觉模型SegGPT的策略，通过仅使用少量示例图像进行湿疹分割，而无需重新训练模型。"
}