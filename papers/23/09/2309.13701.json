{
    "title": "ALLURE: Auditing and Improving LLM-based Evaluation of Text using Iterative In-Context-Learning. (arXiv:2309.13701v2 [cs.CL] UPDATED)",
    "abstract": "From grading papers to summarizing medical documents, large language models (LLMs) are evermore used for evaluation of text generated by humans and AI alike. However, despite their extensive utility, LLMs exhibit distinct failure modes, necessitating a thorough audit and improvement of their text evaluation capabilities. Here we introduce ALLURE, a systematic approach to Auditing Large Language Models Understanding and Reasoning Errors. ALLURE involves comparing LLM-generated evaluations with annotated data, and iteratively incorporating instances of significant deviation into the evaluator, which leverages in-context learning (ICL) to enhance and improve robust evaluation of text by LLMs. Through this iterative process, we refine the performance of the evaluator LLM, ultimately reducing reliance on human annotators in the evaluation process. We anticipate ALLURE to serve diverse applications of LLMs in various domains related to evaluation of textual data, such as medical summarizatio",
    "link": "http://arxiv.org/abs/2309.13701",
    "context": "Title: ALLURE: Auditing and Improving LLM-based Evaluation of Text using Iterative In-Context-Learning. (arXiv:2309.13701v2 [cs.CL] UPDATED)\nAbstract: From grading papers to summarizing medical documents, large language models (LLMs) are evermore used for evaluation of text generated by humans and AI alike. However, despite their extensive utility, LLMs exhibit distinct failure modes, necessitating a thorough audit and improvement of their text evaluation capabilities. Here we introduce ALLURE, a systematic approach to Auditing Large Language Models Understanding and Reasoning Errors. ALLURE involves comparing LLM-generated evaluations with annotated data, and iteratively incorporating instances of significant deviation into the evaluator, which leverages in-context learning (ICL) to enhance and improve robust evaluation of text by LLMs. Through this iterative process, we refine the performance of the evaluator LLM, ultimately reducing reliance on human annotators in the evaluation process. We anticipate ALLURE to serve diverse applications of LLMs in various domains related to evaluation of textual data, such as medical summarizatio",
    "path": "papers/23/09/2309.13701.json",
    "total_tokens": 922,
    "translated_title": "ALLURE: 基于迭代上下文学习的文本评估的审计和改进",
    "translated_abstract": "从评分论文到总结医疗文件，大型语言模型（LLM）越来越多地用于评估由人类和人工智能生成的文本。然而，尽管它们具有广泛的实用性，LLM存在着明显的失败模式，需要对其文本评估能力进行彻底审计和改进。在这里，我们介绍了ALLURE，一种系统的方法，用于审计大型语言模型的理解和推理错误。ALLURE涉及将LLM生成的评估与注释数据进行比较，并迭代地将重大偏差的实例纳入评估器中，利用上下文学习（ICL）提高和改进LLM对文本的鲁棒评估。通过这个迭代过程，我们改善了评估器LLM的性能，从而减少了在评估过程中对人工标注者的依赖。我们预计ALLURE将在与文本数据评估相关的各个领域，如医学概括等，为LLM的各种应用提供服务。",
    "tldr": "ALLURE是一种基于迭代上下文学习的文本评估的审计和改进方法，通过与注释数据进行比较并纳入重大偏差的实例，使用上下文学习提高LLM对文本的评估能力。",
    "en_tdlr": "ALLURE is a systematic approach that audits and improves the evaluation of text using large language models (LLMs) by iteratively incorporating instances of significant deviation into the evaluator, leveraging in-context learning (ICL) to enhance the LLM's evaluation abilities."
}