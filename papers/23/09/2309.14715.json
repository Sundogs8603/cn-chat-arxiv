{
    "title": "Explaining Deep Face Algorithms through Visualization: A Survey. (arXiv:2309.14715v1 [cs.CV])",
    "abstract": "Although current deep models for face tasks surpass human performance on some benchmarks, we do not understand how they work. Thus, we cannot predict how it will react to novel inputs, resulting in catastrophic failures and unwanted biases in the algorithms. Explainable AI helps bridge the gap, but currently, there are very few visualization algorithms designed for faces. This work undertakes a first-of-its-kind meta-analysis of explainability algorithms in the face domain. We explore the nuances and caveats of adapting general-purpose visualization algorithms to the face domain, illustrated by computing visualizations on popular face models. We review existing face explainability works and reveal valuable insights into the structure and hierarchy of face networks. We also determine the design considerations for practical face visualizations accessible to AI practitioners by conducting a user study on the utility of various explainability algorithms.",
    "link": "http://arxiv.org/abs/2309.14715",
    "context": "Title: Explaining Deep Face Algorithms through Visualization: A Survey. (arXiv:2309.14715v1 [cs.CV])\nAbstract: Although current deep models for face tasks surpass human performance on some benchmarks, we do not understand how they work. Thus, we cannot predict how it will react to novel inputs, resulting in catastrophic failures and unwanted biases in the algorithms. Explainable AI helps bridge the gap, but currently, there are very few visualization algorithms designed for faces. This work undertakes a first-of-its-kind meta-analysis of explainability algorithms in the face domain. We explore the nuances and caveats of adapting general-purpose visualization algorithms to the face domain, illustrated by computing visualizations on popular face models. We review existing face explainability works and reveal valuable insights into the structure and hierarchy of face networks. We also determine the design considerations for practical face visualizations accessible to AI practitioners by conducting a user study on the utility of various explainability algorithms.",
    "path": "papers/23/09/2309.14715.json",
    "total_tokens": 876,
    "translated_title": "通过可视化解释深度人脸算法：一项调查",
    "translated_abstract": "尽管当前的人脸任务深度模型在某些基准测试中超过了人类的表现，但我们并不了解它们是如何工作的。因此，我们无法预测它对新输入的反应，导致算法出现灾难性的失败和不希望的偏见。可解释的人工智能有助于填补这一差距，但目前针对人脸的可视化算法非常少。本研究首次进行了人脸领域可解释性算法的综述。我们探索了将通用可视化算法调整为适用于人脸领域的细微差别和注意事项，并通过对流行人脸模型进行计算可视化进行了说明。我们回顾了现有的人脸可解释性研究，并揭示了人脸网络结构和层次结构的有价值的见解。我们还通过对各种可解释性算法的实用性进行用户研究，确定了可为AI从业者提供的实用人脸可视化的设计考虑因素。",
    "tldr": "本文调查了解释深度人脸算法的可视化方法，并发现了人脸网络的结构和层次结构的有价值见解，为AI从业者提供了实用人脸可视化的设计考虑因素。",
    "en_tdlr": "This survey explores visualization methods for explaining deep face algorithms, revealing valuable insights into the structure and hierarchy of face networks and providing design considerations for practical face visualizations for AI practitioners."
}