{
    "title": "Finding Influencers in Complex Networks: An Effective Deep Reinforcement Learning Approach. (arXiv:2309.07153v1 [cs.SI])",
    "abstract": "Maximizing influences in complex networks is a practically important but computationally challenging task for social network analysis, due to its NPhard nature. Most current approximation or heuristic methods either require tremendous human design efforts or achieve unsatisfying balances between effectiveness and efficiency. Recent machine learning attempts only focus on speed but lack performance enhancement. In this paper, different from previous attempts, we propose an effective deep reinforcement learning model that achieves superior performances over traditional best influence maximization algorithms. Specifically, we design an end-to-end learning framework that combines graph neural network as the encoder and reinforcement learning as the decoder, named DREIM. Trough extensive training on small synthetic graphs, DREIM outperforms the state-of-the-art baseline methods on very large synthetic and real-world networks on solution quality, and we also empirically show its linear sca",
    "link": "http://arxiv.org/abs/2309.07153",
    "context": "Title: Finding Influencers in Complex Networks: An Effective Deep Reinforcement Learning Approach. (arXiv:2309.07153v1 [cs.SI])\nAbstract: Maximizing influences in complex networks is a practically important but computationally challenging task for social network analysis, due to its NPhard nature. Most current approximation or heuristic methods either require tremendous human design efforts or achieve unsatisfying balances between effectiveness and efficiency. Recent machine learning attempts only focus on speed but lack performance enhancement. In this paper, different from previous attempts, we propose an effective deep reinforcement learning model that achieves superior performances over traditional best influence maximization algorithms. Specifically, we design an end-to-end learning framework that combines graph neural network as the encoder and reinforcement learning as the decoder, named DREIM. Trough extensive training on small synthetic graphs, DREIM outperforms the state-of-the-art baseline methods on very large synthetic and real-world networks on solution quality, and we also empirically show its linear sca",
    "path": "papers/23/09/2309.07153.json",
    "total_tokens": 918,
    "translated_title": "在复杂网络中寻找影响者：一种有效的深度强化学习方法",
    "translated_abstract": "在社交网络分析中，最大化复杂网络中的影响力是一个实际重要但计算上具有挑战性的任务，因为它是一个NP难问题。目前大多数近似或启发式方法要么需要巨大的人工设计工作，要么在效果和效率之间无法达到令人满意的平衡。最近的机器学习尝试只注重速度，而缺乏性能提升。本文中，与以前的尝试不同，我们提出了一种有效的深度强化学习模型，它在传统的最佳影响力最大化算法上表现出优越的性能。具体而言，我们设计了一个端到端的学习框架，将图神经网络作为编码器，强化学习作为解码器，命名为DREIM。通过在小规模合成图上进行大量训练，DREIM在非常大的合成网络和真实世界网络上在解决质量方面超过了最先进的基准方法，我们还通过实验证明了其线性可扩展性。",
    "tldr": "本文提出了一种有效的深度强化学习模型，通过将图神经网络作为编码器、强化学习作为解码器，实现了在复杂网络中寻找影响者的任务上的优越性能，超过了传统的最佳影响力最大化算法。"
}