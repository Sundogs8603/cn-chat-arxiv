{
    "title": "Deepfake audio as a data augmentation technique for training automatic speech to text transcription models. (arXiv:2309.12802v1 [cs.SD])",
    "abstract": "To train transcriptor models that produce robust results, a large and diverse labeled dataset is required. Finding such data with the necessary characteristics is a challenging task, especially for languages less popular than English. Moreover, producing such data requires significant effort and often money. Therefore, a strategy to mitigate this problem is the use of data augmentation techniques. In this work, we propose a framework that approaches data augmentation based on deepfake audio. To validate the produced framework, experiments were conducted using existing deepfake and transcription models. A voice cloner and a dataset produced by Indians (in English) were selected, ensuring the presence of a single accent in the dataset. Subsequently, the augmented data was used to train speech to text models in various scenarios.",
    "link": "http://arxiv.org/abs/2309.12802",
    "context": "Title: Deepfake audio as a data augmentation technique for training automatic speech to text transcription models. (arXiv:2309.12802v1 [cs.SD])\nAbstract: To train transcriptor models that produce robust results, a large and diverse labeled dataset is required. Finding such data with the necessary characteristics is a challenging task, especially for languages less popular than English. Moreover, producing such data requires significant effort and often money. Therefore, a strategy to mitigate this problem is the use of data augmentation techniques. In this work, we propose a framework that approaches data augmentation based on deepfake audio. To validate the produced framework, experiments were conducted using existing deepfake and transcription models. A voice cloner and a dataset produced by Indians (in English) were selected, ensuring the presence of a single accent in the dataset. Subsequently, the augmented data was used to train speech to text models in various scenarios.",
    "path": "papers/23/09/2309.12802.json",
    "total_tokens": 810,
    "translated_title": "深度伪造音频作为训练自动语音转文字模型的数据增强技术",
    "translated_abstract": "为了训练产生鲁棒结果的转录器模型，需要一个大而多样的标记数据集。找到具备所需特征的这样的数据是一项具有挑战性的任务，特别是对于不如英语流行的语言。此外，生成这样的数据需要大量努力和经费。因此，缓解这个问题的策略是使用数据增强技术。在这项工作中，我们提出了一个基于深度伪造音频的数据增强框架。为了验证产生的框架，我们使用了现有的深度伪造和转录模型进行实验。选择了一个语音克隆器和由印度人（以英语为主）制作的数据集，以确保数据集中只有一个口音。随后，使用增强的数据在各种情景下训练语音到文本模型。",
    "tldr": "本论文提出了一种基于深度伪造音频的数据增强框架，用于训练自动语音转文字模型。通过使用已有的深度伪造和转录模型进行实验，验证了该框架的有效性。",
    "en_tdlr": "This paper proposes a data augmentation framework based on deepfake audio for training automatic speech to text transcription models. The effectiveness of the framework is validated through experiments using existing deepfake and transcription models."
}