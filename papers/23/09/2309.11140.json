{
    "title": "Investigating Personalization Methods in Text to Music Generation. (arXiv:2309.11140v1 [cs.SD])",
    "abstract": "In this work, we investigate the personalization of text-to-music diffusion models in a few-shot setting. Motivated by recent advances in the computer vision domain, we are the first to explore the combination of pre-trained text-to-audio diffusers with two established personalization methods. We experiment with the effect of audio-specific data augmentation on the overall system performance and assess different training strategies. For evaluation, we construct a novel dataset with prompts and music clips. We consider both embedding-based and music-specific metrics for quantitative evaluation, as well as a user study for qualitative evaluation. Our analysis shows that similarity metrics are in accordance with user preferences and that current personalization approaches tend to learn rhythmic music constructs more easily than melody. The code, dataset, and example material of this study are open to the research community.",
    "link": "http://arxiv.org/abs/2309.11140",
    "context": "Title: Investigating Personalization Methods in Text to Music Generation. (arXiv:2309.11140v1 [cs.SD])\nAbstract: In this work, we investigate the personalization of text-to-music diffusion models in a few-shot setting. Motivated by recent advances in the computer vision domain, we are the first to explore the combination of pre-trained text-to-audio diffusers with two established personalization methods. We experiment with the effect of audio-specific data augmentation on the overall system performance and assess different training strategies. For evaluation, we construct a novel dataset with prompts and music clips. We consider both embedding-based and music-specific metrics for quantitative evaluation, as well as a user study for qualitative evaluation. Our analysis shows that similarity metrics are in accordance with user preferences and that current personalization approaches tend to learn rhythmic music constructs more easily than melody. The code, dataset, and example material of this study are open to the research community.",
    "path": "papers/23/09/2309.11140.json",
    "total_tokens": 873,
    "translated_title": "探究个性化方法在文本到音乐生成中的应用",
    "translated_abstract": "在这项工作中，我们在少样本场景下研究了文本到音乐扩散模型的个性化问题。受计算机视觉领域的最新进展的启发，我们首次探索了预训练的文本到音频扩散器与两种已建立的个性化方法的结合。我们尝试了音频特定数据增强对整个系统性能的影响，并评估了不同的训练策略。为了进行评估，我们构建了一个新颖的数据集，包括提示和音乐片段。我们考虑了基于嵌入和音乐特定的指标进行定量评估，以及用户研究进行定性评估。我们的分析表明，相似度指标与用户偏好一致，并且当前的个性化方法更容易学习到节奏音乐结构而非旋律。本研究的代码、数据集和示例资料对研究社区开放。",
    "tldr": "本研究探索了在文本到音乐生成中的个性化方法，使用了预训练的文本到音频扩散器和两种已有的个性化方法。研究发现，当前的个性化方法更容易学习节奏音乐结构而非旋律。"
}