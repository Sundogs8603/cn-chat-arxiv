{
    "title": "Joint Sampling and Optimisation for Inverse Rendering. (arXiv:2309.15676v1 [cs.GR])",
    "abstract": "When dealing with difficult inverse problems such as inverse rendering, using Monte Carlo estimated gradients to optimise parameters can slow down convergence due to variance. Averaging many gradient samples in each iteration reduces this variance trivially. However, for problems that require thousands of optimisation iterations, the computational cost of this approach rises quickly.  We derive a theoretical framework for interleaving sampling and optimisation. We update and reuse past samples with low-variance finite-difference estimators that describe the change in the estimated gradients between each iteration. By combining proportional and finite-difference samples, we continuously reduce the variance of our novel gradient meta-estimators throughout the optimisation process. We investigate how our estimator interlinks with Adam and derive a stable combination.  We implement our method for inverse path tracing and demonstrate how our estimator speeds up convergence on difficult opti",
    "link": "http://arxiv.org/abs/2309.15676",
    "context": "Title: Joint Sampling and Optimisation for Inverse Rendering. (arXiv:2309.15676v1 [cs.GR])\nAbstract: When dealing with difficult inverse problems such as inverse rendering, using Monte Carlo estimated gradients to optimise parameters can slow down convergence due to variance. Averaging many gradient samples in each iteration reduces this variance trivially. However, for problems that require thousands of optimisation iterations, the computational cost of this approach rises quickly.  We derive a theoretical framework for interleaving sampling and optimisation. We update and reuse past samples with low-variance finite-difference estimators that describe the change in the estimated gradients between each iteration. By combining proportional and finite-difference samples, we continuously reduce the variance of our novel gradient meta-estimators throughout the optimisation process. We investigate how our estimator interlinks with Adam and derive a stable combination.  We implement our method for inverse path tracing and demonstrate how our estimator speeds up convergence on difficult opti",
    "path": "papers/23/09/2309.15676.json",
    "total_tokens": 914,
    "translated_title": "逆渲染的联合采样与优化",
    "translated_abstract": "在处理逆渲染等困难逆问题时，使用Monte Carlo估计梯度来优化参数可能会因方差而导致收敛速度变慢。每次迭代中平均多个梯度样本可以简单地减小这种方差。然而，对于需要进行数千次优化迭代的问题，这种方法的计算成本会迅速上升。我们推导了一个理论框架来交替进行采样和优化。我们使用低方差有限差分估计器来更新和重复使用过去的样本，描述了每次迭代之间估计梯度的变化。通过结合比例和有限差分样本，我们在整个优化过程中不断减小了我们的新颖梯度元估计器的方差。我们研究了我们的估计器如何与Adam相互关联，并推导出一个稳定的组合。我们实现了逆路径跟踪的方法，并展示了我们的估计器如何加速困难优化问题的收敛速度。",
    "tldr": "该论文提出了逆渲染的联合采样与优化方法，通过交替采样和优化以减小方差，使用有限差分估计器更新和重复使用过去的样本，在与Adam相结合的情况下实现了稳定的优化过程，加快了困难优化问题的收敛速度。",
    "en_tdlr": "This paper proposes a joint sampling and optimization method for inverse rendering, which reduces variance by interleaving sampling and optimization, updates and reuses past samples using finite-difference estimators, and achieves stable optimization in combination with Adam, resulting in faster convergence for difficult optimization problems."
}