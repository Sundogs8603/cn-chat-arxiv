{
    "title": "Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning. (arXiv:2309.02591v1 [cs.LG])",
    "abstract": "We present CM3Leon (pronounced \"Chameleon\"), a retrieval-augmented, token-based, decoder-only multi-modal language model capable of generating and infilling both text and images. CM3Leon uses the CM3 multi-modal architecture but additionally shows the extreme benefits of scaling up and tuning on more diverse instruction-style data. It is the first multi-modal model trained with a recipe adapted from text-only language models, including a large-scale retrieval-augmented pre-training stage and a second multi-task supervised fine-tuning (SFT) stage. It is also a general-purpose model that can do both text-to-image and image-to-text generation, allowing us to introduce self-contained contrastive decoding methods that produce high-quality outputs. Extensive experiments demonstrate that this recipe is highly effective for multi-modal models. CM3Leon achieves state-of-the-art performance in text-to-image generation with 5x less training compute than comparable methods (zero-shot MS-COCO FID o",
    "link": "http://arxiv.org/abs/2309.02591",
    "context": "Title: Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning. (arXiv:2309.02591v1 [cs.LG])\nAbstract: We present CM3Leon (pronounced \"Chameleon\"), a retrieval-augmented, token-based, decoder-only multi-modal language model capable of generating and infilling both text and images. CM3Leon uses the CM3 multi-modal architecture but additionally shows the extreme benefits of scaling up and tuning on more diverse instruction-style data. It is the first multi-modal model trained with a recipe adapted from text-only language models, including a large-scale retrieval-augmented pre-training stage and a second multi-task supervised fine-tuning (SFT) stage. It is also a general-purpose model that can do both text-to-image and image-to-text generation, allowing us to introduce self-contained contrastive decoding methods that produce high-quality outputs. Extensive experiments demonstrate that this recipe is highly effective for multi-modal models. CM3Leon achieves state-of-the-art performance in text-to-image generation with 5x less training compute than comparable methods (zero-shot MS-COCO FID o",
    "path": "papers/23/09/2309.02591.json",
    "total_tokens": 912,
    "translated_title": "缩放自回归多模态模型: 预训练和指令调整",
    "translated_abstract": "我们提出了CM3Leon（发音为\"Chameleon\"），一个检索增强的基于令牌的解码器多模态语言模型，能够生成和填充文本和图像。CM3Leon使用了CM3多模态架构，同时展示了在更多样化的指令风格数据上的扩展和调整的巨大优势。它是第一个使用从纯文本语言模型中改编的配方进行训练的多模态模型，包括大规模的检索增强预训练阶段和第二个多任务监督微调阶段。它也是一个通用模型，可以进行文本到图像和图像到文本的生成，使我们能够引入自包含的对比解码方法，产生高质量的输出。广泛的实验表明，这个配方对于多模态模型非常有效。CM3Leon在文本到图像的生成方面取得了最先进的性能，训练计算量比类似方法少5倍（零样本MS-COCO FID）",
    "tldr": "CM3Leon是一个缩放自回归多模态语言模型，通过预训练和指令调整实现了高质量的文本和图像的生成和填充，达到了文本到图像生成方面的最先进性能，而计算资源开销较小。",
    "en_tdlr": "CM3Leon, a scaled autoregressive multi-modal language model, achieves high-quality text and image generation and infilling through pretraining and instruction tuning, and it outperforms comparable methods in text-to-image generation with less computational resources."
}