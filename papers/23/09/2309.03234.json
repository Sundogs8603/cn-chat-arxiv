{
    "title": "Natural Example-Based Explainability: a Survey. (arXiv:2309.03234v1 [cs.AI])",
    "abstract": "Explainable Artificial Intelligence (XAI) has become increasingly significant for improving the interpretability and trustworthiness of machine learning models. While saliency maps have stolen the show for the last few years in the XAI field, their ability to reflect models' internal processes has been questioned. Although less in the spotlight, example-based XAI methods have continued to improve. It encompasses methods that use examples as explanations for a machine learning model's predictions. This aligns with the psychological mechanisms of human reasoning and makes example-based explanations natural and intuitive for users to understand. Indeed, humans learn and reason by forming mental representations of concepts based on examples.  This paper provides an overview of the state-of-the-art in natural example-based XAI, describing the pros and cons of each approach. A \"natural\" example simply means that it is directly drawn from the training data without involving any generative pro",
    "link": "http://arxiv.org/abs/2309.03234",
    "context": "Title: Natural Example-Based Explainability: a Survey. (arXiv:2309.03234v1 [cs.AI])\nAbstract: Explainable Artificial Intelligence (XAI) has become increasingly significant for improving the interpretability and trustworthiness of machine learning models. While saliency maps have stolen the show for the last few years in the XAI field, their ability to reflect models' internal processes has been questioned. Although less in the spotlight, example-based XAI methods have continued to improve. It encompasses methods that use examples as explanations for a machine learning model's predictions. This aligns with the psychological mechanisms of human reasoning and makes example-based explanations natural and intuitive for users to understand. Indeed, humans learn and reason by forming mental representations of concepts based on examples.  This paper provides an overview of the state-of-the-art in natural example-based XAI, describing the pros and cons of each approach. A \"natural\" example simply means that it is directly drawn from the training data without involving any generative pro",
    "path": "papers/23/09/2309.03234.json",
    "total_tokens": 872,
    "translated_title": "自然示例为基础的可解释性：一项调查",
    "translated_abstract": "可解释的人工智能（XAI）在提高机器学习模型的可解释性和可信度方面变得越来越重要。虽然在XAI领域，突出图已经成为主角多年，但其反映模型内部过程的能力受到了质疑。尽管不太受关注，但基于示例的XAI方法仍在不断改进。它包括使用示例作为机器学习模型预测的解释的方法。这符合人类推理的心理机制，使基于示例的解释对用户来说自然和直观易懂。事实上，人类通过基于示例形成概念的心理表示来学习和推理。本文概述了自然示例为基础的XAI的最新进展，并描述了每种方法的优缺点。所谓“自然”示例指的是直接从训练数据中绘制而来，而不涉及任何生成过程。",
    "tldr": "本文概述了自然示例为基础的可解释性人工智能的最新进展，这些方法通过使用示例作为解释来提高机器学习模型的可解释性，与人类的学习和推理过程相符，使解释更自然和易懂。",
    "en_tdlr": "This paper provides an overview of the latest progress in natural example-based explainable artificial intelligence, which improves the interpretability of machine learning models by using examples as explanations, aligning with human learning and reasoning processes, making explanations more natural and understandable."
}