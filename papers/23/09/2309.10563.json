{
    "title": "A Hierarchical Neural Framework for Classification and its Explanation in Large Unstructured Legal Documents. (arXiv:2309.10563v1 [cs.IR])",
    "abstract": "Automatic legal judgment prediction and its explanation suffer from the problem of long case documents exceeding tens of thousands of words, in general, and having a non-uniform structure. Predicting judgments from such documents and extracting their explanation becomes a challenging task, more so on documents with no structural annotation. We define this problem as \"scarce annotated legal documents\" and explore their lack of structural information and their long lengths with a deep learning-based classification framework which we call MESc; \"Multi-stage Encoder-based Supervised with-clustering\"; for judgment prediction. Specifically, we divide a document into parts to extract their embeddings from the last four layers of a custom fine-tuned Large Language Model, and try to approximate their structure through unsupervised clustering. Which we use in another set of transformer encoder layers to learn the inter-chunk representations. We explore the adaptability of LLMs with multi-billion",
    "link": "http://arxiv.org/abs/2309.10563",
    "context": "Title: A Hierarchical Neural Framework for Classification and its Explanation in Large Unstructured Legal Documents. (arXiv:2309.10563v1 [cs.IR])\nAbstract: Automatic legal judgment prediction and its explanation suffer from the problem of long case documents exceeding tens of thousands of words, in general, and having a non-uniform structure. Predicting judgments from such documents and extracting their explanation becomes a challenging task, more so on documents with no structural annotation. We define this problem as \"scarce annotated legal documents\" and explore their lack of structural information and their long lengths with a deep learning-based classification framework which we call MESc; \"Multi-stage Encoder-based Supervised with-clustering\"; for judgment prediction. Specifically, we divide a document into parts to extract their embeddings from the last four layers of a custom fine-tuned Large Language Model, and try to approximate their structure through unsupervised clustering. Which we use in another set of transformer encoder layers to learn the inter-chunk representations. We explore the adaptability of LLMs with multi-billion",
    "path": "papers/23/09/2309.10563.json",
    "total_tokens": 906,
    "translated_title": "一个用于分类和解释大型非结构化法律文件的分层神经框架",
    "translated_abstract": "自动法律判决预测及其解释常常面临长达数万字的案例文件和非统一结构的问题。在没有结构标注的文件上预测判决并提取解释变得更具挑战性。本论文将这一问题定义为“稀缺标注法律文件”，并通过一种称为MESc（基于多阶段编码器的带聚类的监督）的深度学习分类框架来探索缺乏结构信息和长文档的特点。具体来说，我们将文档分成多个部分，从自定义微调的大型语言模型的最后四个层中提取它们的嵌入，并试图通过无监督聚类来近似它们的结构。然后，我们利用另一组Transformer编码器层学习部分之间的表示。我们探索了多十亿参数的大型语言模型在这种情况下的适应性。",
    "tldr": "本论文提出了一个名为MESc的分层神经框架，用于分类和解释大型非结构化法律文件。通过将文件分成多个部分并使用大型语言模型的嵌入和无监督聚类，该框架能够实现从长文档中预测判决并提取解释。",
    "en_tdlr": "This paper introduces a hierarchical neural framework called MESc for the classification and explanation of large unstructured legal documents. By dividing the documents into parts and utilizing embeddings from a large language model and unsupervised clustering, the framework enables the prediction of judgments and extraction of explanations from lengthy documents."
}