{
    "title": "Prompt, Condition, and Generate: Classification of Unsupported Claims with In-Context Learning. (arXiv:2309.10359v1 [cs.CL])",
    "abstract": "Unsupported and unfalsifiable claims we encounter in our daily lives can influence our view of the world. Characterizing, summarizing, and -- more generally -- making sense of such claims, however, can be challenging. In this work, we focus on fine-grained debate topics and formulate a new task of distilling, from such claims, a countable set of narratives. We present a crowdsourced dataset of 12 controversial topics, comprising more than 120k arguments, claims, and comments from heterogeneous sources, each annotated with a narrative label. We further investigate how large language models (LLMs) can be used to synthesise claims using In-Context Learning. We find that generated claims with supported evidence can be used to improve the performance of narrative classification models and, additionally, that the same model can infer the stance and aspect using a few training examples. Such a model can be useful in applications which rely on narratives , e.g. fact-checking.",
    "link": "http://arxiv.org/abs/2309.10359",
    "context": "Title: Prompt, Condition, and Generate: Classification of Unsupported Claims with In-Context Learning. (arXiv:2309.10359v1 [cs.CL])\nAbstract: Unsupported and unfalsifiable claims we encounter in our daily lives can influence our view of the world. Characterizing, summarizing, and -- more generally -- making sense of such claims, however, can be challenging. In this work, we focus on fine-grained debate topics and formulate a new task of distilling, from such claims, a countable set of narratives. We present a crowdsourced dataset of 12 controversial topics, comprising more than 120k arguments, claims, and comments from heterogeneous sources, each annotated with a narrative label. We further investigate how large language models (LLMs) can be used to synthesise claims using In-Context Learning. We find that generated claims with supported evidence can be used to improve the performance of narrative classification models and, additionally, that the same model can infer the stance and aspect using a few training examples. Such a model can be useful in applications which rely on narratives , e.g. fact-checking.",
    "path": "papers/23/09/2309.10359.json",
    "total_tokens": 929,
    "translated_title": "提示、条件和生成：基于上下文学习的无支持论断的分类",
    "translated_abstract": "在我们日常生活中遇到的无支持和不可反驳的论断可以影响我们对世界的看法。然而，对这些论断进行表征、总结和更一般地理解却是具有挑战性的。在这项工作中，我们专注于细粒度的辩论主题，并提出了从这些论断中提炼可数集合的叙事的新任务。我们提供了一个众包数据集，包括12个有争议的主题，超过120k个来自异构来源的论证、论断和评论，每个都标注有一个叙事标签。我们进一步研究了如何使用大型语言模型（LLMs）使用上下文学习来合成论断。我们发现，使用支持的证据生成的论断可以提高叙事分类模型的性能，并且同样的模型可以使用少量的训练样例来推断立场和方面。这样的模型在依赖叙事的应用中，例如事实核查，是非常有用的。",
    "tldr": "本论文提出了一个新的任务，即通过对无支持论断进行分类，从中提取可数集合的叙事。作者使用大型语言模型合成支持论断，并发现这可以提高叙事分类模型的性能。这个模型在依赖叙事的应用中具有潜在的实用价值，例如事实核查。"
}