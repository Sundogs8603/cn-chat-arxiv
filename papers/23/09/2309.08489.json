{
    "title": "Towards Word-Level End-to-End Neural Speaker Diarization with Auxiliary Network. (arXiv:2309.08489v1 [eess.AS])",
    "abstract": "While standard speaker diarization attempts to answer the question \"who spoken when\", most of relevant applications in reality are more interested in determining \"who spoken what\". Whether it is the conventional modularized approach or the more recent end-to-end neural diarization (EEND), an additional automatic speech recognition (ASR) model and an orchestration algorithm are required to associate the speaker labels with recognized words. In this paper, we propose Word-level End-to-End Neural Diarization (WEEND) with auxiliary network, a multi-task learning algorithm that performs end-to-end ASR and speaker diarization in the same neural architecture. That is, while speech is being recognized, speaker labels are predicted simultaneously for each recognized word. Experimental results demonstrate that WEEND outperforms the turn-based diarization baseline system on all 2-speaker short-form scenarios and has the capability to generalize to audio lengths of 5 minutes. Although 3+speaker co",
    "link": "http://arxiv.org/abs/2309.08489",
    "context": "Title: Towards Word-Level End-to-End Neural Speaker Diarization with Auxiliary Network. (arXiv:2309.08489v1 [eess.AS])\nAbstract: While standard speaker diarization attempts to answer the question \"who spoken when\", most of relevant applications in reality are more interested in determining \"who spoken what\". Whether it is the conventional modularized approach or the more recent end-to-end neural diarization (EEND), an additional automatic speech recognition (ASR) model and an orchestration algorithm are required to associate the speaker labels with recognized words. In this paper, we propose Word-level End-to-End Neural Diarization (WEEND) with auxiliary network, a multi-task learning algorithm that performs end-to-end ASR and speaker diarization in the same neural architecture. That is, while speech is being recognized, speaker labels are predicted simultaneously for each recognized word. Experimental results demonstrate that WEEND outperforms the turn-based diarization baseline system on all 2-speaker short-form scenarios and has the capability to generalize to audio lengths of 5 minutes. Although 3+speaker co",
    "path": "papers/23/09/2309.08489.json",
    "total_tokens": 932,
    "translated_title": "朝向词级端到端神经发言人分离与辅助网络",
    "translated_abstract": "尽管标准的发言人分离试图回答“谁在什么时候说了什么”，但现实中大多数相关应用更关心确定“谁说了什么”。无论是传统的模块化方法还是最近的端到端神经分离（EEND），都需要一个额外的自动语音识别（ASR）模型和一个协调算法来将说话者标签与识别的单词关联起来。在本文中，我们提出了一种带有辅助网络的词级端到端神经分离（WEEND），这是一种多任务学习算法，它在相同的神经架构中执行端到端ASR和发言人分离。也就是说，当语音被识别时，同时为每个识别的单词预测说话者标签。实验结果表明，WEEND在所有两个发言人的短片场景上优于基线系统，并且能够推广到5分钟的音频长度。尽管在3个或更多发言人的情况下，相对于基线系统，不能达到最佳性能。",
    "tldr": "本文提出了一种名为WEEND的词级端到端神经网络方法，通过使用辅助网络，实现了同时进行自动语音识别和发言人分离，并在2个发言人的短片场景中取得了优于基线系统的性能。"
}