{
    "title": "Forgetting Private Textual Sequences in Language Models via Leave-One-Out Ensemble. (arXiv:2309.16082v1 [cs.CL])",
    "abstract": "Recent research has shown that language models have a tendency to memorize rare or unique token sequences in the training corpus. After deploying a model, practitioners might be asked to delete any personal information from the model by individuals' requests. Re-training the underlying model every time individuals would like to practice their rights to be forgotten is computationally expensive. We employ a teacher-student framework and propose a novel leave-one-out ensemble method to unlearn the targeted textual sequences that need to be forgotten from the model. In our approach, multiple teachers are trained on disjoint sets; for each targeted sequence to be removed, we exclude the teacher trained on the set containing this sequence and aggregate the predictions from remaining teachers to provide supervision during fine-tuning. Experiments on LibriSpeech and WikiText-103 datasets show that the proposed method achieves superior privacy-utility trade-offs than other counterparts.",
    "link": "http://arxiv.org/abs/2309.16082",
    "context": "Title: Forgetting Private Textual Sequences in Language Models via Leave-One-Out Ensemble. (arXiv:2309.16082v1 [cs.CL])\nAbstract: Recent research has shown that language models have a tendency to memorize rare or unique token sequences in the training corpus. After deploying a model, practitioners might be asked to delete any personal information from the model by individuals' requests. Re-training the underlying model every time individuals would like to practice their rights to be forgotten is computationally expensive. We employ a teacher-student framework and propose a novel leave-one-out ensemble method to unlearn the targeted textual sequences that need to be forgotten from the model. In our approach, multiple teachers are trained on disjoint sets; for each targeted sequence to be removed, we exclude the teacher trained on the set containing this sequence and aggregate the predictions from remaining teachers to provide supervision during fine-tuning. Experiments on LibriSpeech and WikiText-103 datasets show that the proposed method achieves superior privacy-utility trade-offs than other counterparts.",
    "path": "papers/23/09/2309.16082.json",
    "total_tokens": 862,
    "translated_title": "通过排除法集成模型来在语言模型中遗忘私人文本序列",
    "translated_abstract": "最近的研究表明，语言模型有倾向于在训练数据中记住罕见或独特的令牌序列。在部署模型后，根据个人要求，从模型中删除任何个人信息可能会被提出。每次个人想要行使被遗忘权利时重新训练底层模型的计算成本很高。我们使用教师-学生框架，并提出了一种新的排除法集成方法来从模型中遗忘需要遗忘的文本序列。在我们的方法中，多个教师模型在不同的数据集上进行训练；对于每个需要删除的目标序列，我们排除在包含该序列的训练集上训练的教师模型，并从剩余的教师模型中聚合预测结果，以提供在微调过程中的监督。在LibriSpeech和WikiText-103数据集上的实验证明，所提出的方法在隐私-效用权衡方面具有优势。",
    "tldr": "通过教师-学生框架和排除法集成方法，在语言模型中遗忘私人文本序列时能够取得比其他方法更好的隐私-效用权衡性能。",
    "en_tdlr": "A teacher-student framework and leave-one-out ensemble method are proposed to forget private textual sequences in language models, achieving superior privacy-utility trade-offs compared to other methods."
}