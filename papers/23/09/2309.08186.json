{
    "title": "A Precision-Scalable RISC-V DNN Processor with On-Device Learning Capability at the Extreme Edge. (arXiv:2309.08186v1 [cs.AR])",
    "abstract": "Extreme edge platforms, such as in-vehicle smart devices, require efficient deployment of quantized deep neural networks (DNNs) to enable intelligent applications with limited amounts of energy, memory, and computing resources. However, many edge devices struggle to boost inference throughput of various quantized DNNs due to the varying quantization levels, and these devices lack floating-point (FP) support for on-device learning, which prevents them from improving model accuracy while ensuring data privacy. To tackle the challenges above, we propose a precision-scalable RISC-V DNN processor with on-device learning capability. It facilitates diverse precision levels of fixed-point DNN inference, spanning from 2-bit to 16-bit, and enhances on-device learning through improved support with FP16 operations. Moreover, we employ multiple methods such as FP16 multiplier reuse and multi-precision integer multiplier reuse, along with balanced mapping of FPGA resources, to significantly improve ",
    "link": "http://arxiv.org/abs/2309.08186",
    "context": "Title: A Precision-Scalable RISC-V DNN Processor with On-Device Learning Capability at the Extreme Edge. (arXiv:2309.08186v1 [cs.AR])\nAbstract: Extreme edge platforms, such as in-vehicle smart devices, require efficient deployment of quantized deep neural networks (DNNs) to enable intelligent applications with limited amounts of energy, memory, and computing resources. However, many edge devices struggle to boost inference throughput of various quantized DNNs due to the varying quantization levels, and these devices lack floating-point (FP) support for on-device learning, which prevents them from improving model accuracy while ensuring data privacy. To tackle the challenges above, we propose a precision-scalable RISC-V DNN processor with on-device learning capability. It facilitates diverse precision levels of fixed-point DNN inference, spanning from 2-bit to 16-bit, and enhances on-device learning through improved support with FP16 operations. Moreover, we employ multiple methods such as FP16 multiplier reuse and multi-precision integer multiplier reuse, along with balanced mapping of FPGA resources, to significantly improve ",
    "path": "papers/23/09/2309.08186.json",
    "total_tokens": 917,
    "translated_title": "一种具有精度可扩展性的在极限边缘具有在设备学习能力的RISC-V DNN处理器",
    "translated_abstract": "极限边缘平台，例如车载智能设备，需要高效部署量化的深度神经网络（DNN），以便在能源、内存和计算资源有限的情况下实现智能应用。然而，由于量化水平的变化，许多边缘设备难以提高各种量化DNN的推断吞吐量，并且这些设备缺乏浮点（FP）支持的在设备学习能力，这阻碍了它们在确保数据隐私的同时提高模型准确性。为了解决以上挑战，我们提出了一种具有精度可扩展性的RISC-V DNN处理器，具有在设备学习能力。它可以方便地进行2位到16位的多种精度级别的定点DNN推断，并通过改进的FP16操作来增强在设备学习。此外，我们采用多种方法，如FP16乘法器重用和多精度整数乘法器重用，以及FPGA资源的平衡映射，大大提高了性能。",
    "tldr": "这篇论文提出了一种具有精度可扩展性的RISC-V DNN处理器，该处理器可以支持多种精度级别的定点DNN推断，并通过改进的FP16操作增强了在设备学习能力。",
    "en_tdlr": "This paper proposes a precision-scalable RISC-V DNN processor that supports various precision levels of fixed-point DNN inference and enhances the on-device learning capability through improved FP16 operations."
}