{
    "title": "ArtiGrasp: Physically Plausible Synthesis of Bi-Manual Dexterous Grasping and Articulation. (arXiv:2309.03891v1 [cs.RO])",
    "abstract": "We present ArtiGrasp, a novel method to synthesize bi-manual hand-object interactions that include grasping and articulation. This task is challenging due to the diversity of the global wrist motions and the precise finger control that are necessary to articulate objects. ArtiGrasp leverages reinforcement learning and physics simulations to train a policy that controls the global and local hand pose. Our framework unifies grasping and articulation within a single policy guided by a single hand pose reference. Moreover, to facilitate the training of the precise finger control required for articulation, we present a learning curriculum with increasing difficulty. It starts with single-hand manipulation of stationary objects and continues with multi-agent training including both hands and non-stationary objects. To evaluate our method, we introduce Dynamic Object Grasping and Articulation, a task that involves bringing an object into a target articulated pose. This task requires grasping,",
    "link": "http://arxiv.org/abs/2309.03891",
    "context": "Title: ArtiGrasp: Physically Plausible Synthesis of Bi-Manual Dexterous Grasping and Articulation. (arXiv:2309.03891v1 [cs.RO])\nAbstract: We present ArtiGrasp, a novel method to synthesize bi-manual hand-object interactions that include grasping and articulation. This task is challenging due to the diversity of the global wrist motions and the precise finger control that are necessary to articulate objects. ArtiGrasp leverages reinforcement learning and physics simulations to train a policy that controls the global and local hand pose. Our framework unifies grasping and articulation within a single policy guided by a single hand pose reference. Moreover, to facilitate the training of the precise finger control required for articulation, we present a learning curriculum with increasing difficulty. It starts with single-hand manipulation of stationary objects and continues with multi-agent training including both hands and non-stationary objects. To evaluate our method, we introduce Dynamic Object Grasping and Articulation, a task that involves bringing an object into a target articulated pose. This task requires grasping,",
    "path": "papers/23/09/2309.03891.json",
    "total_tokens": 896,
    "translated_title": "ArtiGrasp：双手灵巧抓握和关节表达的物理合理合成",
    "translated_abstract": "我们提出了ArtiGrasp，一种新的方法来合成包括抓握和关节表达在内的双手手-物体交互。由于全局手腕运动和精确的手指控制对于物体的关节表达是必要的，这个任务具有挑战性。ArtiGrasp利用强化学习和物理模拟训练一个控制全局和局部手姿态的策略。我们的框架在一个共同的手姿态参考下统一了抓握和关节表达。此外，为了训练关节表达所需的精确手指控制，我们提出了一个逐渐增加难度的学习课程。它从单手操作静止物体开始，然后进行包括两只手和非静止物体的多智能体训练。为了评估我们的方法，我们引入了动态物体抓握和关节表达，这是一个将物体移到目标关节姿态的任务。这个任务需要抓握，关节表达和物体姿态的控制。",
    "tldr": "ArtiGrasp是一种通过强化学习和物理模拟的方式，用一个统一的策略来合成双手灵巧抓握和关节表达的方法。",
    "en_tdlr": "ArtiGrasp is a method for synthesizing bi-manual dexterous grasping and articulation using reinforcement learning and physics simulations, unifying grasping and articulation within a single policy."
}