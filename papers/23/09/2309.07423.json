{
    "title": "ChatGPT MT: Competitive for High- (but not Low-) Resource Languages. (arXiv:2309.07423v1 [cs.CL])",
    "abstract": "Large language models (LLMs) implicitly learn to perform a range of language tasks, including machine translation (MT). Previous studies explore aspects of LLMs' MT capabilities. However, there exist a wide variety of languages for which recent LLM MT performance has never before been evaluated. Without published experimental evidence on the matter, it is difficult for speakers of the world's diverse languages to know how and whether they can use LLMs for their languages. We present the first experimental evidence for an expansive set of 204 languages, along with MT cost analysis, using the FLORES-200 benchmark. Trends reveal that GPT models approach or exceed traditional MT model performance for some high-resource languages (HRLs) but consistently lag for low-resource languages (LRLs), under-performing traditional MT for 84.1% of languages we covered. Our analysis reveals that a language's resource level is the most important feature in determining ChatGPT's relative ability to transl",
    "link": "http://arxiv.org/abs/2309.07423",
    "context": "Title: ChatGPT MT: Competitive for High- (but not Low-) Resource Languages. (arXiv:2309.07423v1 [cs.CL])\nAbstract: Large language models (LLMs) implicitly learn to perform a range of language tasks, including machine translation (MT). Previous studies explore aspects of LLMs' MT capabilities. However, there exist a wide variety of languages for which recent LLM MT performance has never before been evaluated. Without published experimental evidence on the matter, it is difficult for speakers of the world's diverse languages to know how and whether they can use LLMs for their languages. We present the first experimental evidence for an expansive set of 204 languages, along with MT cost analysis, using the FLORES-200 benchmark. Trends reveal that GPT models approach or exceed traditional MT model performance for some high-resource languages (HRLs) but consistently lag for low-resource languages (LRLs), under-performing traditional MT for 84.1% of languages we covered. Our analysis reveals that a language's resource level is the most important feature in determining ChatGPT's relative ability to transl",
    "path": "papers/23/09/2309.07423.json",
    "total_tokens": 895,
    "translated_title": "ChatGPT MT: 高资源语言中具有竞争力（但不是低资源语言）的机器翻译",
    "translated_abstract": "大型语言模型（LLMs）隐式地学习执行各种语言任务，包括机器翻译（MT）。先前的研究探索了LLMs在MT方面的能力。然而，存在许多语言，其最近的LLM MT性能尚未评估。在没有发表的实验证据的情况下，世界上多样化语言的使用者难以知道如何以及是否可以使用LLMs进行该语言的翻译。我们提供了首个实验证据，涵盖了204种语言，以及使用FLORES-200基准进行的MT成本分析。趋势表明GPT模型在某些高资源语言（HRLs）的性能接近或超过传统MT模型，但在低资源语言（LRLs）方面一直表现不佳，我们所研究的语言中有84.1%的语言在传统MT下效果更好。我们的分析表明，语言的资源水平是确定ChatGPT相对能力的最重要特征。",
    "tldr": "ChatGPT在高资源语言中具有竞争力的机器翻译能力，但在低资源语言方面表现不佳。资源水平是决定其翻译能力的最重要特征。",
    "en_tdlr": "ChatGPT demonstrates competitive machine translation capabilities in high-resource languages, but performs poorly in low-resource languages. The resource level of a language is the most important feature in determining its translation ability."
}