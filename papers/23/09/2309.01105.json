{
    "title": "A Study on the Implementation of Generative AI Services Using an Enterprise Data-Based LLM Application Architecture. (arXiv:2309.01105v2 [cs.AI] UPDATED)",
    "abstract": "This study presents a method for implementing generative AI services by utilizing the Large Language Models (LLM) application architecture. With recent advancements in generative AI technology, LLMs have gained prominence across various domains. In this context, the research addresses the challenge of information scarcity and proposes specific remedies by harnessing LLM capabilities. The investigation delves into strategies for mitigating the issue of inadequate data, offering tailored solutions. The study delves into the efficacy of employing fine-tuning techniques and direct document integration to alleviate data insufficiency. A significant contribution of this work is the development of a Retrieval-Augmented Generation (RAG) model, which tackles the aforementioned challenges. The RAG model is carefully designed to enhance information storage and retrieval processes, ensuring improved content generation. The research elucidates the key phases of the information storage and retrieval",
    "link": "http://arxiv.org/abs/2309.01105",
    "context": "Title: A Study on the Implementation of Generative AI Services Using an Enterprise Data-Based LLM Application Architecture. (arXiv:2309.01105v2 [cs.AI] UPDATED)\nAbstract: This study presents a method for implementing generative AI services by utilizing the Large Language Models (LLM) application architecture. With recent advancements in generative AI technology, LLMs have gained prominence across various domains. In this context, the research addresses the challenge of information scarcity and proposes specific remedies by harnessing LLM capabilities. The investigation delves into strategies for mitigating the issue of inadequate data, offering tailored solutions. The study delves into the efficacy of employing fine-tuning techniques and direct document integration to alleviate data insufficiency. A significant contribution of this work is the development of a Retrieval-Augmented Generation (RAG) model, which tackles the aforementioned challenges. The RAG model is carefully designed to enhance information storage and retrieval processes, ensuring improved content generation. The research elucidates the key phases of the information storage and retrieval",
    "path": "papers/23/09/2309.01105.json",
    "total_tokens": 883,
    "translated_title": "使用基于企业数据的LLM应用架构实现生成式AI服务的研究",
    "translated_abstract": "本研究提出了一种利用大型语言模型（LLM）应用架构实现生成式AI服务的方法。随着生成式AI技术的最新进展，LLM在各个领域都受到了重视。在这个背景下，本研究解决了信息稀缺的挑战，并通过利用LLM的能力提出了具体的解决方案。研究探讨了缓解数据不足问题的策略，并提供了量身定制的解决方案。研究探讨了利用微调技术和直接文档集成来缓解数据不足问题的有效性。本研究的一个重要贡献是开发了一种名为检索增强生成（RAG）模型，该模型解决了上述挑战。RAG模型经过精心设计，以提高信息存储和检索过程，确保改进内容生成。研究阐明了信息存储和检索的关键阶段。",
    "tldr": "本研究通过利用大型语言模型（LLM）应用架构实现了生成式AI服务，并开发了一种名为检索增强生成（RAG）模型，以解决信息稀缺和数据不足的挑战。"
}