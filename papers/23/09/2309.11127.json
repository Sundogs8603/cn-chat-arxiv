{
    "title": "Language-Oriented Communication with Semantic Coding and Knowledge Distillation for Text-to-Image Generation. (arXiv:2309.11127v1 [eess.SP])",
    "abstract": "By integrating recent advances in large language models (LLMs) and generative models into the emerging semantic communication (SC) paradigm, in this article we put forward to a novel framework of language-oriented semantic communication (LSC). In LSC, machines communicate using human language messages that can be interpreted and manipulated via natural language processing (NLP) techniques for SC efficiency. To demonstrate LSC's potential, we introduce three innovative algorithms: 1) semantic source coding (SSC) which compresses a text prompt into its key head words capturing the prompt's syntactic essence while maintaining their appearance order to keep the prompt's context; 2) semantic channel coding (SCC) that improves robustness against errors by substituting head words with their lenghthier synonyms; and 3) semantic knowledge distillation (SKD) that produces listener-customized prompts via in-context learning the listener's language style. In a communication task for progressive te",
    "link": "http://arxiv.org/abs/2309.11127",
    "context": "Title: Language-Oriented Communication with Semantic Coding and Knowledge Distillation for Text-to-Image Generation. (arXiv:2309.11127v1 [eess.SP])\nAbstract: By integrating recent advances in large language models (LLMs) and generative models into the emerging semantic communication (SC) paradigm, in this article we put forward to a novel framework of language-oriented semantic communication (LSC). In LSC, machines communicate using human language messages that can be interpreted and manipulated via natural language processing (NLP) techniques for SC efficiency. To demonstrate LSC's potential, we introduce three innovative algorithms: 1) semantic source coding (SSC) which compresses a text prompt into its key head words capturing the prompt's syntactic essence while maintaining their appearance order to keep the prompt's context; 2) semantic channel coding (SCC) that improves robustness against errors by substituting head words with their lenghthier synonyms; and 3) semantic knowledge distillation (SKD) that produces listener-customized prompts via in-context learning the listener's language style. In a communication task for progressive te",
    "path": "papers/23/09/2309.11127.json",
    "total_tokens": 971,
    "translated_title": "基于语义编码和知识蒸馏的面向语言的通信用于文本到图像生成",
    "translated_abstract": "通过将最近的大型语言模型（LLM）和生成模型集成到新兴的语义通信（SC）范式中，本文提出了一种新颖的面向语言的语义通信（LSC）框架。在LSC中，机器使用可以通过自然语言处理（NLP）技术解释和操作的人类语言消息进行通信，以提高SC效率。为了展示LSC的潜力，我们引入了三种创新算法：1）语义源编码（SSC），将文本提示压缩成捕捉提示的句法本质的关键头词，同时保持它们的出现顺序以保持提示的上下文；2）语义信道编码（SCC），通过用更长的同义词替换头词来提高对错误的容错性；3）语义知识蒸馏（SKD），通过在上下文中学习听众的语言风格来生成定制的提示。在逐步进行的通信任务中，我们验证了LSC的潜在能力。",
    "tldr": "本文提出了一种基于语义编码和知识蒸馏的面向语言的通信框架，通过将大型语言模型和生成模型集成到语义通信范式中，实现了使用人类语言消息进行通信的效率。同时引入了语义源编码、语义信道编码和语义知识蒸馏等创新算法来提高通信的效果。"
}