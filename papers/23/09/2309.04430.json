{
    "title": "Create Your World: Lifelong Text-to-Image Diffusion. (arXiv:2309.04430v1 [cs.CV])",
    "abstract": "Text-to-image generative models can produce diverse high-quality images of concepts with a text prompt, which have demonstrated excellent ability in image generation, image translation, etc. We in this work study the problem of synthesizing instantiations of a use's own concepts in a never-ending manner, i.e., create your world, where the new concepts from user are quickly learned with a few examples. To achieve this goal, we propose a Lifelong text-to-image Diffusion Model (L2DM), which intends to overcome knowledge \"catastrophic forgetting\" for the past encountered concepts, and semantic \"catastrophic neglecting\" for one or more concepts in the text prompt. In respect of knowledge \"catastrophic forgetting\", our L2DM framework devises a task-aware memory enhancement module and a elastic-concept distillation module, which could respectively safeguard the knowledge of both prior concepts and each past personalized concept. When generating images with a user text prompt, the solution to ",
    "link": "http://arxiv.org/abs/2309.04430",
    "context": "Title: Create Your World: Lifelong Text-to-Image Diffusion. (arXiv:2309.04430v1 [cs.CV])\nAbstract: Text-to-image generative models can produce diverse high-quality images of concepts with a text prompt, which have demonstrated excellent ability in image generation, image translation, etc. We in this work study the problem of synthesizing instantiations of a use's own concepts in a never-ending manner, i.e., create your world, where the new concepts from user are quickly learned with a few examples. To achieve this goal, we propose a Lifelong text-to-image Diffusion Model (L2DM), which intends to overcome knowledge \"catastrophic forgetting\" for the past encountered concepts, and semantic \"catastrophic neglecting\" for one or more concepts in the text prompt. In respect of knowledge \"catastrophic forgetting\", our L2DM framework devises a task-aware memory enhancement module and a elastic-concept distillation module, which could respectively safeguard the knowledge of both prior concepts and each past personalized concept. When generating images with a user text prompt, the solution to ",
    "path": "papers/23/09/2309.04430.json",
    "total_tokens": 964,
    "translated_title": "创造你的世界：终身文本到图像扩散",
    "translated_abstract": "文本到图像的生成模型可以通过文本提示产生多样且高质量的概念图像，在图像生成、图像翻译等领域展示出优秀的能力。本研究致力于解决以一种永无止境的方式合成用户自己概念的实例化问题，即创建你的世界，新的用户概念能够通过几个示例快速学习。为了实现这个目标，我们提出了一种终身文本到图像扩散模型（L2DM），旨在解决过去遇到的概念的知识“灾难性遗忘”和文本提示中一个或多个概念的语义“灾难性忽视”问题。在知识“灾难性遗忘”方面，我们的L2DM框架设计了一个任务感知的记忆增强模块和一个弹性概念蒸馏模块，分别保护了先前概念的知识和每个过去个性化概念的知识。在使用用户的文本提示生成图像时，解决方案是",
    "tldr": "本文介绍了一种终身文本到图像扩散模型（L2DM），该模型通过解决知识“灾难性遗忘”和文本提示中的语义“灾难性忽视”问题，能够在用户输入的文本提示下生成多样且高质量的图像。",
    "en_tdlr": "This paper introduces a lifelong text-to-image diffusion model (L2DM) that can generate diverse and high-quality images based on user inputs by addressing the issues of knowledge \"catastrophic forgetting\" and semantic \"catastrophic neglecting\" in the text prompt."
}