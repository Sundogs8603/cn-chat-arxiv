{
    "title": "Struc-Bench: Are Large Language Models Really Good at Generating Complex Structured Data?. (arXiv:2309.08963v2 [cs.CL] UPDATED)",
    "abstract": "Despite the power of Large Language Models (LLMs) like GPT-4, they still struggle with tasks that require generating complex, structured outputs. In this study, we assess the capability of Current LLMs in generating complex structured data and propose a structure-aware fine-tuning approach as a solution to improve this ability. To perform a comprehensive evaluation, we propose Struc-Bench, include five representative LLMs (i.e., GPT-NeoX 20B, GPT-3.5, GPT-4, and Vicuna) and evaluate them on our carefully constructed datasets spanning raw text, HTML, and LaTeX tables. Based on our analysis of current model performance, we identify specific common formatting errors and areas of potential improvement. To address complex formatting requirements, we utilize FormatCoT (Chain-of-Thought) to generate format instructions from target outputs. Our experiments show that our structure-aware fine-tuning method, when applied to LLaMA-7B, significantly improves adherence to natural language constraint",
    "link": "http://arxiv.org/abs/2309.08963",
    "context": "Title: Struc-Bench: Are Large Language Models Really Good at Generating Complex Structured Data?. (arXiv:2309.08963v2 [cs.CL] UPDATED)\nAbstract: Despite the power of Large Language Models (LLMs) like GPT-4, they still struggle with tasks that require generating complex, structured outputs. In this study, we assess the capability of Current LLMs in generating complex structured data and propose a structure-aware fine-tuning approach as a solution to improve this ability. To perform a comprehensive evaluation, we propose Struc-Bench, include five representative LLMs (i.e., GPT-NeoX 20B, GPT-3.5, GPT-4, and Vicuna) and evaluate them on our carefully constructed datasets spanning raw text, HTML, and LaTeX tables. Based on our analysis of current model performance, we identify specific common formatting errors and areas of potential improvement. To address complex formatting requirements, we utilize FormatCoT (Chain-of-Thought) to generate format instructions from target outputs. Our experiments show that our structure-aware fine-tuning method, when applied to LLaMA-7B, significantly improves adherence to natural language constraint",
    "path": "papers/23/09/2309.08963.json",
    "total_tokens": 1043,
    "translated_title": "Struc-Bench：大型语言模型在生成复杂结构化数据方面表现得真的好吗？",
    "translated_abstract": "尽管像GPT-4这样的大型语言模型（LLMs）非常强大，但它们在生成需要复杂结构化输出的任务上仍然有困难。在本研究中，我们评估了当前LLMs在生成复杂结构化数据方面的能力，并提出了一种结构感知的微调方法作为改进这种能力的解决方案。为了进行全面评估，我们提出了Struc-Bench，包括五个代表性的LLM（即GPT-NeoX 20B，GPT-3.5，GPT-4和Vicuna），并在我们精心构建的跨原始文本、HTML和LaTeX表的数据集上对它们进行评估。根据我们对当前模型性能的分析，我们确定了特定的常见格式错误和潜在改进的领域。为了解决复杂的格式要求，我们利用FormatCoT（思维链）从目标输出中生成格式指令。我们的实验证明，当将这种结构感知微调方法应用到LLaMA-7B上时，能够显著提高对自然语言约束的遵守程度。",
    "tldr": "本研究评估了当前大型语言模型（LLMs）在生成复杂结构化数据方面的能力，并提出了一种结构感知的微调方法来改善这种能力。通过使用Struc-Bench和多个代表性的LLMs进行评估，发现了常见的格式错误和潜在改进的领域。通过应用结构感知微调方法，能够显著提高对自然语言约束的遵守程度。",
    "en_tdlr": "This study assesses the capability of current Large Language Models (LLMs) in generating complex structured data and proposes a structure-aware fine-tuning method as a solution. By evaluating multiple representative LLMs using Struc-Bench, common formatting errors and areas of potential improvement were identified. Applying the structure-aware fine-tuning method significantly improves adherence to natural language constraint."
}