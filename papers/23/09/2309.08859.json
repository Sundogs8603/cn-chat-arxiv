{
    "title": "Rethinking Learning Rate Tuning in the Era of Large Language Models. (arXiv:2309.08859v1 [cs.LG])",
    "abstract": "Large Language Models (LLMs) represent the recent success of deep learning in achieving remarkable human-like predictive performance. It has become a mainstream strategy to leverage fine-tuning to adapt LLMs for various real-world applications due to the prohibitive expenses associated with LLM training. The learning rate is one of the most important hyperparameters in LLM fine-tuning with direct impacts on both fine-tuning efficiency and fine-tuned LLM quality. Existing learning rate policies are primarily designed for training traditional deep neural networks (DNNs), which may not work well for LLM fine-tuning. We reassess the research challenges and opportunities of learning rate tuning in the coming era of Large Language Models. This paper makes three original contributions. First, we revisit existing learning rate policies to analyze the critical challenges of learning rate tuning in the era of LLMs. Second, we present LRBench++ to benchmark learning rate policies and facilitate l",
    "link": "http://arxiv.org/abs/2309.08859",
    "context": "Title: Rethinking Learning Rate Tuning in the Era of Large Language Models. (arXiv:2309.08859v1 [cs.LG])\nAbstract: Large Language Models (LLMs) represent the recent success of deep learning in achieving remarkable human-like predictive performance. It has become a mainstream strategy to leverage fine-tuning to adapt LLMs for various real-world applications due to the prohibitive expenses associated with LLM training. The learning rate is one of the most important hyperparameters in LLM fine-tuning with direct impacts on both fine-tuning efficiency and fine-tuned LLM quality. Existing learning rate policies are primarily designed for training traditional deep neural networks (DNNs), which may not work well for LLM fine-tuning. We reassess the research challenges and opportunities of learning rate tuning in the coming era of Large Language Models. This paper makes three original contributions. First, we revisit existing learning rate policies to analyze the critical challenges of learning rate tuning in the era of LLMs. Second, we present LRBench++ to benchmark learning rate policies and facilitate l",
    "path": "papers/23/09/2309.08859.json",
    "total_tokens": 881,
    "translated_title": "在大语言模型时代重新思考学习率调整",
    "translated_abstract": "大语言模型（LLMs）代表了深度学习在实现了出色的人类预测性能方面的最新成功。鉴于LLM训练的昂贵费用，利用微调来适应各种实际应用已成为主流策略。学习率是LLM微调中最重要的超参数之一，直接影响微调效率和微调后的LLM质量。现有的学习率策略主要针对传统深度神经网络（DNNs）的训练而设计，可能在LLM微调方面效果不佳。我们重新评估了在大语言模型时代中学习率调整的研究挑战和机遇。本文做出了三个原创贡献。首先，我们重新审视现有的学习率策略，分析了在大语言模型时代中学习率调整的关键挑战。其次，我们提出了LRBench++来评估学习率策略并促进学习率调整的研究。",
    "tldr": "本文重新评估了在大语言模型时代中学习率调整的挑战和机遇，并提出了LRBench++来帮助研究者评估学习率策略。",
    "en_tdlr": "This paper reassesses the challenges and opportunities of learning rate tuning in the era of large language models and presents LRBench++ as a tool to benchmark learning rate policies for researchers."
}