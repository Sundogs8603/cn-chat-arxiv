{
    "title": "Dissipative Imitation Learning for Discrete Dynamic Output Feedback Control with Sparse Data Sets. (arXiv:2309.06658v1 [eess.SY])",
    "abstract": "Imitation learning enables the synthesis of controllers for complex objectives and highly uncertain plant models. However, methods to provide stability guarantees to imitation learned controllers often rely on large amounts of data and/or known plant models. In this paper, we explore an input-output (IO) stability approach to dissipative imitation learning, which achieves stability with sparse data sets and with little known about the plant model. A closed-loop stable dynamic output feedback controller is learned using expert data, a coarse IO plant model, and a new constraint to enforce dissipativity on the learned controller. While the learning objective is nonconvex, iterative convex overbounding (ICO) and projected gradient descent (PGD) are explored as methods to successfully learn the controller. This new imitation learning method is applied to two unknown plants and compared to traditionally learned dynamic output feedback controller and neural network controller. With little kn",
    "link": "http://arxiv.org/abs/2309.06658",
    "context": "Title: Dissipative Imitation Learning for Discrete Dynamic Output Feedback Control with Sparse Data Sets. (arXiv:2309.06658v1 [eess.SY])\nAbstract: Imitation learning enables the synthesis of controllers for complex objectives and highly uncertain plant models. However, methods to provide stability guarantees to imitation learned controllers often rely on large amounts of data and/or known plant models. In this paper, we explore an input-output (IO) stability approach to dissipative imitation learning, which achieves stability with sparse data sets and with little known about the plant model. A closed-loop stable dynamic output feedback controller is learned using expert data, a coarse IO plant model, and a new constraint to enforce dissipativity on the learned controller. While the learning objective is nonconvex, iterative convex overbounding (ICO) and projected gradient descent (PGD) are explored as methods to successfully learn the controller. This new imitation learning method is applied to two unknown plants and compared to traditionally learned dynamic output feedback controller and neural network controller. With little kn",
    "path": "papers/23/09/2309.06658.json",
    "total_tokens": 923,
    "translated_title": "带稀疏数据集的离散动态输出反馈控制的耗散型仿真学习",
    "translated_abstract": "仿真学习使得可以为复杂目标和高度不确定的植物模型合成控制器。然而，为了给仿真学习的控制器提供稳定性保证，通常需要大量的数据和/或已知的植物模型。本文中，我们探索了一种用于耗散型仿真学习的输入-输出（IO）稳定性方法，该方法在稀疏数据集和对植物模型了解有限的情况下实现稳定性。使用专家数据、粗糙的IO植物模型和新的约束来强制学习到的控制器具有耗散性，从而学习到了一个闭环稳定的动态输出反馈控制器。虽然学习目标是非凸的，但本文探索了迭代凸过估计（ICO）和投影梯度下降（PGD）作为成功学习控制器的方法。将这种新的仿真学习方法应用于两个未知的植物，并与传统学习的动态输出反馈控制器和神经网络控制器进行了比较。",
    "tldr": "这项研究探索了一种用于稀疏数据集和对植物模型了解有限的情况下实现稳定性的耗散型仿真学习方法，并成功应用于两个未知的植物。",
    "en_tdlr": "This paper explores a dissipative imitation learning method for achieving stability with sparse data sets and limited knowledge about the plant model, and successfully applies it to two unknown plants."
}