{
    "title": "Bridging the Gaps of Both Modality and Language: Synchronous Bilingual CTC for Speech Translation and Speech Recognition. (arXiv:2309.12234v1 [cs.CL])",
    "abstract": "In this study, we present synchronous bilingual Connectionist Temporal Classification (CTC), an innovative framework that leverages dual CTC to bridge the gaps of both modality and language in the speech translation (ST) task. Utilizing transcript and translation as concurrent objectives for CTC, our model bridges the gap between audio and text as well as between source and target languages. Building upon the recent advances in CTC application, we develop an enhanced variant, BiL-CTC+, that establishes new state-of-the-art performances on the MuST-C ST benchmarks under resource-constrained scenarios. Intriguingly, our method also yields significant improvements in speech recognition performance, revealing the effect of cross-lingual learning on transcription and demonstrating its broad applicability. The source code is available at https://github.com/xuchennlp/S2T.",
    "link": "http://arxiv.org/abs/2309.12234",
    "context": "Title: Bridging the Gaps of Both Modality and Language: Synchronous Bilingual CTC for Speech Translation and Speech Recognition. (arXiv:2309.12234v1 [cs.CL])\nAbstract: In this study, we present synchronous bilingual Connectionist Temporal Classification (CTC), an innovative framework that leverages dual CTC to bridge the gaps of both modality and language in the speech translation (ST) task. Utilizing transcript and translation as concurrent objectives for CTC, our model bridges the gap between audio and text as well as between source and target languages. Building upon the recent advances in CTC application, we develop an enhanced variant, BiL-CTC+, that establishes new state-of-the-art performances on the MuST-C ST benchmarks under resource-constrained scenarios. Intriguingly, our method also yields significant improvements in speech recognition performance, revealing the effect of cross-lingual learning on transcription and demonstrating its broad applicability. The source code is available at https://github.com/xuchennlp/S2T.",
    "path": "papers/23/09/2309.12234.json",
    "total_tokens": 875,
    "translated_title": "桥接模态和语言差距：同步双语CTC用于语音翻译和语音识别",
    "translated_abstract": "本研究提出了同步双语CTC，这是一种创新的框架，利用双重CTC来弥合语音翻译任务中模态和语言之间的差距。通过将转写和翻译作为CTC的并行目标，我们的模型桥接了音频和文本之间的差距，以及源语言和目标语言之间的差距。在CTC应用的最新进展基础上，我们开发了一种改进的变体BiL-CTC+，在资源受限的场景下在MuST-C语音翻译基准测试中取得了新的最佳表现。有趣的是，我们的方法在语音识别性能上也取得了显著的提升，揭示了跨语言学习对转录的影响并展示了其广泛的适用性。",
    "tldr": "本研究提出了一种同步双语CTC框架，用于桥接语音翻译任务中的模态和语言差距，并在资源有限情况下取得了state-of-the-art表现。同时，该方法还在语音识别性能上展示了显著的提升。"
}