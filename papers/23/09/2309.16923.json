{
    "title": "Mode Connectivity and Data Heterogeneity of Federated Learning. (arXiv:2309.16923v1 [cs.LG])",
    "abstract": "Federated learning (FL) enables multiple clients to train a model while keeping their data private collaboratively. Previous studies have shown that data heterogeneity between clients leads to drifts across client updates. However, there are few studies on the relationship between client and global modes, making it unclear where these updates end up drifting. We perform empirical and theoretical studies on this relationship by utilizing mode connectivity, which measures performance change (i.e., connectivity) along parametric paths between different modes. Empirically, reducing data heterogeneity makes the connectivity on different paths more similar, forming more low-error overlaps between client and global modes. We also find that a barrier to connectivity occurs when linearly connecting two global modes, while it disappears with considering non-linear mode connectivity. Theoretically, we establish a quantitative bound on the global-mode connectivity using mean-field theory or dropou",
    "link": "http://arxiv.org/abs/2309.16923",
    "context": "Title: Mode Connectivity and Data Heterogeneity of Federated Learning. (arXiv:2309.16923v1 [cs.LG])\nAbstract: Federated learning (FL) enables multiple clients to train a model while keeping their data private collaboratively. Previous studies have shown that data heterogeneity between clients leads to drifts across client updates. However, there are few studies on the relationship between client and global modes, making it unclear where these updates end up drifting. We perform empirical and theoretical studies on this relationship by utilizing mode connectivity, which measures performance change (i.e., connectivity) along parametric paths between different modes. Empirically, reducing data heterogeneity makes the connectivity on different paths more similar, forming more low-error overlaps between client and global modes. We also find that a barrier to connectivity occurs when linearly connecting two global modes, while it disappears with considering non-linear mode connectivity. Theoretically, we establish a quantitative bound on the global-mode connectivity using mean-field theory or dropou",
    "path": "papers/23/09/2309.16923.json",
    "total_tokens": 863,
    "translated_title": "联邦学习的模式连通性和数据异质性",
    "translated_abstract": "联邦学习（FL）可以让多个客户端在保持数据私密性的同时进行模型训练。以往的研究表明，客户端之间的数据异质性导致了更新之间的漂移。然而，对于客户端和全局模式之间的关系研究较少，不清楚这些更新漂移到了哪里。我们通过使用模式连通性进行经验和理论研究，模式连通性可以衡量在不同模式之间的参数路径上性能的变化（即连通性）。经验证明，减少数据异质性使得不同路径上的连通性更加相似，形成了客户端和全局模式之间更多的低误差重叠。我们还发现，在线性连接两个全局模式时存在连通性障碍，而考虑非线性模式连通性后连通性障碍消失。理论上，我们使用均场理论或dropout方法，建立了全局模式连通性的定量界限。",
    "tldr": "本研究通过模式连通性的经验和理论研究发现，减少数据异质性可以增加客户端和全局模式之间的连通性，建立了全局模式连通性的定量界限。",
    "en_tdlr": "This study investigates the relationship between client and global modes in federated learning (FL) and finds that reducing data heterogeneity increases connectivity between client and global modes. A quantitative bound on global-mode connectivity is established using mode connectivity."
}