{
    "title": "Target-aware Variational Auto-encoders for Ligand Generation with Multimodal Protein Representation Learning. (arXiv:2309.16685v1 [q-bio.BM])",
    "abstract": "Without knowledge of specific pockets, generating ligands based on the global structure of a protein target plays a crucial role in drug discovery as it helps reduce the search space for potential drug-like candidates in the pipeline. However, contemporary methods require optimizing tailored networks for each protein, which is arduous and costly. To address this issue, we introduce TargetVAE, a target-aware variational auto-encoder that generates ligands with high binding affinities to arbitrary protein targets, guided by a novel multimodal deep neural network built based on graph Transformers as the prior for the generative model. This is the first effort to unify different representations of proteins (e.g., sequence of amino-acids, 3D structure) into a single model that we name as Protein Multimodal Network (PMN). Our multimodal architecture learns from the entire protein structures and is able to capture their sequential, topological and geometrical information. We showcase the supe",
    "link": "http://arxiv.org/abs/2309.16685",
    "context": "Title: Target-aware Variational Auto-encoders for Ligand Generation with Multimodal Protein Representation Learning. (arXiv:2309.16685v1 [q-bio.BM])\nAbstract: Without knowledge of specific pockets, generating ligands based on the global structure of a protein target plays a crucial role in drug discovery as it helps reduce the search space for potential drug-like candidates in the pipeline. However, contemporary methods require optimizing tailored networks for each protein, which is arduous and costly. To address this issue, we introduce TargetVAE, a target-aware variational auto-encoder that generates ligands with high binding affinities to arbitrary protein targets, guided by a novel multimodal deep neural network built based on graph Transformers as the prior for the generative model. This is the first effort to unify different representations of proteins (e.g., sequence of amino-acids, 3D structure) into a single model that we name as Protein Multimodal Network (PMN). Our multimodal architecture learns from the entire protein structures and is able to capture their sequential, topological and geometrical information. We showcase the supe",
    "path": "papers/23/09/2309.16685.json",
    "total_tokens": 981,
    "translated_title": "针对多模态蛋白质表示学习的面向目标的变分自编码器用于配体生成",
    "translated_abstract": "在不了解特定口袋的情况下，基于蛋白质目标的整体结构生成配体在药物发现中起着关键作用，因为它有助于减少潜在药物候选在流水线中的搜索空间。然而，当代方法需要为每个蛋白质优化定制的网络，这是繁琐且昂贵的。为了解决这个问题，我们引入了TargetVAE，这是一个面向目标的变分自编码器，通过基于图形Transformer的新型多模态深度神经网络作为生成模型的先验，生成具有高结合亲和力的配体。这是第一个将蛋白质的不同表示（例如氨基酸序列、3D结构）统一到单一模型中的努力，我们将其命名为蛋白质多模态网络（PMN）。我们的多模态架构从整个蛋白质结构中学习，并能够捕捉它们的顺序、拓扑和几何信息。",
    "tldr": "本研究提出了一种面向目标的变分自编码器（TargetVAE），通过蛋白质多模态网络（PMN）将蛋白质的不同表示统一到一个模型中，实现配体的生成。该方法能够从整个蛋白质结构中学习，并捕捉其顺序、拓扑和几何信息。",
    "en_tdlr": "This study introduces a target-aware variational auto-encoder (TargetVAE) that generates ligands by unifying different representations of proteins into a single model called Protein Multimodal Network (PMN). The proposed method learns from the entire protein structures and captures their sequential, topological, and geometrical information."
}