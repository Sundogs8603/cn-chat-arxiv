{
    "title": "Toward Discretization-Consistent Closure Schemes for Large Eddy Simulation Using Reinforcement Learning. (arXiv:2309.06260v1 [physics.flu-dyn])",
    "abstract": "We propose a novel method for developing discretization-consistent closure schemes for implicitly filtered Large Eddy Simulation (LES). In implicitly filtered LES, the induced filter kernel, and thus the closure terms, are determined by the properties of the grid and the discretization operator, leading to additional computational subgrid terms that are generally unknown in a priori analysis. Therefore, the task of adapting the coefficients of LES closure models is formulated as a Markov decision process and solved in an a posteriori manner with Reinforcement Learning (RL). This allows to adjust the model to the actual discretization as it also incorporates the interaction between the discretization and the model itself. This optimization framework is applied to both explicit and implicit closure models. An element-local eddy viscosity model is optimized as the explicit model. For the implicit modeling, RL is applied to identify an optimal blending strategy for a hybrid discontinuous G",
    "link": "http://arxiv.org/abs/2309.06260",
    "context": "Title: Toward Discretization-Consistent Closure Schemes for Large Eddy Simulation Using Reinforcement Learning. (arXiv:2309.06260v1 [physics.flu-dyn])\nAbstract: We propose a novel method for developing discretization-consistent closure schemes for implicitly filtered Large Eddy Simulation (LES). In implicitly filtered LES, the induced filter kernel, and thus the closure terms, are determined by the properties of the grid and the discretization operator, leading to additional computational subgrid terms that are generally unknown in a priori analysis. Therefore, the task of adapting the coefficients of LES closure models is formulated as a Markov decision process and solved in an a posteriori manner with Reinforcement Learning (RL). This allows to adjust the model to the actual discretization as it also incorporates the interaction between the discretization and the model itself. This optimization framework is applied to both explicit and implicit closure models. An element-local eddy viscosity model is optimized as the explicit model. For the implicit modeling, RL is applied to identify an optimal blending strategy for a hybrid discontinuous G",
    "path": "papers/23/09/2309.06260.json",
    "total_tokens": 1050,
    "translated_title": "通过强化学习实现离散一致性闭塞方案用于大涡模拟",
    "translated_abstract": "我们提出了一种新的方法来开发用于隐式滤波的大涡模拟（LES）中的离散一致性闭塞方案。在隐式滤波的LES中，感应滤波核和闭塞项是由网格和离散化操作符的性质决定的，从而产生额外的未知计算细网项。因此，将LES闭塞模型的系数调整任务定义为马尔可夫决策过程，并通过强化学习在后期解决。这允许将模型调整到实际的离散化中，同时还包括离散化和模型本身之间的相互作用。这个优化框架应用于显式和隐式闭塞模型。通过优化局部涡粘度模型作为显式模型，通过强化学习来识别混合不连续G的最优混合策略。",
    "tldr": "本研究提出了一种使用强化学习方法开发离散一致性闭塞方案的新方法，其中将大涡模拟中的闭塞模型系数调整任务定义为马尔可夫决策过程，通过后期的强化学习解决。这一方法能够将模型调整到实际的离散化中并考虑离散化和模型本身之间的相互作用。通过优化显式和隐式闭塞模型中的局部涡粘度模型和混合策略，实现了闭塞模型的优化。",
    "en_tdlr": "This study proposes a novel method to develop discretization-consistent closure schemes for Large Eddy Simulation (LES) using reinforcement learning. The task of adapting LES closure models is formulated as a Markov decision process and solved through reinforcement learning, allowing for the adjustment of the model to the actual discretization and considering the interaction between discretization and the model itself. The optimization framework is applied to both explicit and implicit closure models, optimizing the element-local eddy viscosity model as the explicit model and identifying an optimal blending strategy for a hybrid discontinuous G model in the implicit modeling."
}