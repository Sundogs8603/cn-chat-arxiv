{
    "title": "Cross-Modal Translation and Alignment for Survival Analysis. (arXiv:2309.12855v1 [eess.IV])",
    "abstract": "With the rapid advances in high-throughput sequencing technologies, the focus of survival analysis has shifted from examining clinical indicators to incorporating genomic profiles with pathological images. However, existing methods either directly adopt a straightforward fusion of pathological features and genomic profiles for survival prediction, or take genomic profiles as guidance to integrate the features of pathological images. The former would overlook intrinsic cross-modal correlations. The latter would discard pathological information irrelevant to gene expression. To address these issues, we present a Cross-Modal Translation and Alignment (CMTA) framework to explore the intrinsic cross-modal correlations and transfer potential complementary information. Specifically, we construct two parallel encoder-decoder structures for multi-modal data to integrate intra-modal information and generate cross-modal representation. Taking the generated cross-modal representation to enhance an",
    "link": "http://arxiv.org/abs/2309.12855",
    "context": "Title: Cross-Modal Translation and Alignment for Survival Analysis. (arXiv:2309.12855v1 [eess.IV])\nAbstract: With the rapid advances in high-throughput sequencing technologies, the focus of survival analysis has shifted from examining clinical indicators to incorporating genomic profiles with pathological images. However, existing methods either directly adopt a straightforward fusion of pathological features and genomic profiles for survival prediction, or take genomic profiles as guidance to integrate the features of pathological images. The former would overlook intrinsic cross-modal correlations. The latter would discard pathological information irrelevant to gene expression. To address these issues, we present a Cross-Modal Translation and Alignment (CMTA) framework to explore the intrinsic cross-modal correlations and transfer potential complementary information. Specifically, we construct two parallel encoder-decoder structures for multi-modal data to integrate intra-modal information and generate cross-modal representation. Taking the generated cross-modal representation to enhance an",
    "path": "papers/23/09/2309.12855.json",
    "total_tokens": 891,
    "translated_title": "跨模态翻译与对齐技术在生存分析中的应用",
    "translated_abstract": "随着高通量测序技术的快速发展，生存分析的重点已经从研究临床指标转移到将基因组特征与病理图像结合起来。然而，现有方法要么直接将病理特征和基因组特征融合进行生存预测，要么将基因组特征作为指导用于整合病理图像的特征。前者会忽视内在的跨模态相关性，而后者会丢弃与基因表达无关的病理信息。为了解决这些问题，我们提出了一种跨模态翻译与对齐 (CMTA) 框架，用于探索内在的跨模态相关性并传递潜在的互补信息。具体而言，我们构建了两个并行的编码器-解码器结构，用于处理多模态数据，整合模态内信息并生成跨模态表示。利用生成的跨模态表示来增强生存分析预测任务。",
    "tldr": "本论文提出了一种跨模态翻译与对齐 (CMTA) 框架，用于将病理图像和基因组特征结合起来进行生存分析，通过探索内在的跨模态相关性和传递互补信息，提高了生存分析预测的准确性和效果。",
    "en_tdlr": "This paper proposes a Cross-Modal Translation and Alignment (CMTA) framework for integrating pathological images with genomic profiles in survival analysis. By exploring the intrinsic cross-modal correlations and transferring potential complementary information, it improves the accuracy and effectiveness of survival prediction."
}