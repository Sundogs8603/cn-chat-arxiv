{
    "title": "C$^2$VAE: Gaussian Copula-based VAE Differing Disentangled from Coupled Representations with Contrastive Posterior. (arXiv:2309.13303v1 [cs.LG])",
    "abstract": "We present a self-supervised variational autoencoder (VAE) to jointly learn disentangled and dependent hidden factors and then enhance disentangled representation learning by a self-supervised classifier to eliminate coupled representations in a contrastive manner. To this end, a Contrastive Copula VAE (C$^2$VAE) is introduced without relying on prior knowledge about data in the probabilistic principle and involving strong modeling assumptions on the posterior in the neural architecture. C$^2$VAE simultaneously factorizes the posterior (evidence lower bound, ELBO) with total correlation (TC)-driven decomposition for learning factorized disentangled representations and extracts the dependencies between hidden features by a neural Gaussian copula for copula coupled representations. Then, a self-supervised contrastive classifier differentiates the disentangled representations from the coupled representations, where a contrastive loss regularizes this contrastive classification together wi",
    "link": "http://arxiv.org/abs/2309.13303",
    "context": "Title: C$^2$VAE: Gaussian Copula-based VAE Differing Disentangled from Coupled Representations with Contrastive Posterior. (arXiv:2309.13303v1 [cs.LG])\nAbstract: We present a self-supervised variational autoencoder (VAE) to jointly learn disentangled and dependent hidden factors and then enhance disentangled representation learning by a self-supervised classifier to eliminate coupled representations in a contrastive manner. To this end, a Contrastive Copula VAE (C$^2$VAE) is introduced without relying on prior knowledge about data in the probabilistic principle and involving strong modeling assumptions on the posterior in the neural architecture. C$^2$VAE simultaneously factorizes the posterior (evidence lower bound, ELBO) with total correlation (TC)-driven decomposition for learning factorized disentangled representations and extracts the dependencies between hidden features by a neural Gaussian copula for copula coupled representations. Then, a self-supervised contrastive classifier differentiates the disentangled representations from the coupled representations, where a contrastive loss regularizes this contrastive classification together wi",
    "path": "papers/23/09/2309.13303.json",
    "total_tokens": 975,
    "translated_title": "C$^2$VAE：基于高斯Copula的VAE与对比后验的非耦合与非耦合表示有差异的联合学习",
    "translated_abstract": "我们提出了一个自监督变分自动编码器（VAE），以联合学习非耦合且相关的隐藏因素，然后通过自监督分类器增强非耦合表示学习，以对比方式消除耦合表示。为此，引入了一种无需依赖先验知识和在神经架构中涉及后验的强建模假设的对比Copula VAE（C$^2$VAE）。C$^2$VAE使用总相关（TC）驱动分解来因子化后验（ELBO），以学习因子化的非耦合表示，并通过神经高斯Copula提取隐藏特征之间的依赖关系以获得耦合表示。然后，自监督对比分类器区分非耦合表示和耦合表示，其中对比损失用于正则化该对比分类。",
    "tldr": "这篇论文提出了一种C$^2$VAE模型，通过联合学习非耦合且相关的隐藏因素，并通过自监督分类器消除耦合表示，以增强非耦合表示学习。该模型在不依赖先验知识和强建模假设的情况下，使用总相关驱动分解后验来学习因子化的非耦合表示，并利用神经高斯Copula模型提取隐藏特征之间的依赖关系来获得耦合表示。",
    "en_tdlr": "This paper proposes a C$^2$VAE model that jointly learns disentangled and dependent hidden factors and eliminates coupled representations by a self-supervised classifier. The model utilizes total correlation to factorize the posterior for learning factorized disentangled representations and extracts dependencies between hidden features using a neural Gaussian copula for coupled representations."
}