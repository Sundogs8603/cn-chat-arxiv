{
    "title": "Implicit Sensing in Traffic Optimization: Advanced Deep Reinforcement Learning Techniques. (arXiv:2309.14395v1 [cs.LG])",
    "abstract": "A sudden roadblock on highways due to many reasons such as road maintenance, accidents, and car repair is a common situation we encounter almost daily. Autonomous Vehicles (AVs) equipped with sensors that can acquire vehicle dynamics such as speed, acceleration, and location can make intelligent decisions to change lanes before reaching a roadblock. A number of literature studies have examined car-following models and lane-changing models. However, only a few studies proposed an integrated car-following and lane-changing model, which has the potential to model practical driving maneuvers. Hence, in this paper, we present an integrated car-following and lane-changing decision-control system based on Deep Reinforcement Learning (DRL) to address this issue. Specifically, we consider a scenario where sudden construction work will be carried out along a highway. We model the scenario as a Markov Decision Process (MDP) and employ the well-known DQN algorithm to train the RL agent to make the",
    "link": "http://arxiv.org/abs/2309.14395",
    "context": "Title: Implicit Sensing in Traffic Optimization: Advanced Deep Reinforcement Learning Techniques. (arXiv:2309.14395v1 [cs.LG])\nAbstract: A sudden roadblock on highways due to many reasons such as road maintenance, accidents, and car repair is a common situation we encounter almost daily. Autonomous Vehicles (AVs) equipped with sensors that can acquire vehicle dynamics such as speed, acceleration, and location can make intelligent decisions to change lanes before reaching a roadblock. A number of literature studies have examined car-following models and lane-changing models. However, only a few studies proposed an integrated car-following and lane-changing model, which has the potential to model practical driving maneuvers. Hence, in this paper, we present an integrated car-following and lane-changing decision-control system based on Deep Reinforcement Learning (DRL) to address this issue. Specifically, we consider a scenario where sudden construction work will be carried out along a highway. We model the scenario as a Markov Decision Process (MDP) and employ the well-known DQN algorithm to train the RL agent to make the",
    "path": "papers/23/09/2309.14395.json",
    "total_tokens": 930,
    "translated_title": "隐性感知在交通优化中的应用：先进的深度强化学习技术",
    "translated_abstract": "高速公路上的突然路障由于道路维护、事故和汽车维修等原因是我们几乎每天都会遇到的情况。配备可以获取车辆动态信息（如速度、加速度和位置）的自主驾驶车辆（AV）可以在到达路障之前做出智能决策来变换车道。许多文献研究已经考察了车辆跟随模型和变道模型。然而，只有很少的研究提出了集成的车辆跟随和变道模型，这个模型有潜力模拟实际的驾驶操纵。因此，在本文中，我们提出了一个基于深度强化学习（DRL）的集成车辆跟随和变道决策控制系统来解决这个问题。具体而言，我们考虑了在高速公路上将进行突发施工的情景。我们将情景建模为马尔可夫决策过程（MDP），并采用着名的DQN算法来训练RL代理以制定决策。",
    "tldr": "本论文提出了一个基于深度强化学习的集成车辆跟随和变道决策控制系统，旨在解决高速公路上突发路障情况下智能车辆的行车问题。",
    "en_tdlr": "This paper presents an integrated car-following and lane-changing decision-control system based on deep reinforcement learning, aiming to address the issue of intelligent vehicle driving in sudden roadblock situations on highways."
}