{
    "title": "3D Reconstruction with Generalizable Neural Fields using Scene Priors. (arXiv:2309.15164v1 [cs.CV])",
    "abstract": "High-fidelity 3D scene reconstruction has been substantially advanced by recent progress in neural fields. However, most existing methods train a separate network from scratch for each individual scene. This is not scalable, inefficient, and unable to yield good results given limited views. While learning-based multi-view stereo methods alleviate this issue to some extent, their multi-view setting makes it less flexible to scale up and to broad applications. Instead, we introduce training generalizable Neural Fields incorporating scene Priors (NFPs). The NFP network maps any single-view RGB-D image into signed distance and radiance values. A complete scene can be reconstructed by merging individual frames in the volumetric space WITHOUT a fusion module, which provides better flexibility. The scene priors can be trained on large-scale datasets, allowing for fast adaptation to the reconstruction of a new scene with fewer views. NFP not only demonstrates SOTA scene reconstruction performa",
    "link": "http://arxiv.org/abs/2309.15164",
    "context": "Title: 3D Reconstruction with Generalizable Neural Fields using Scene Priors. (arXiv:2309.15164v1 [cs.CV])\nAbstract: High-fidelity 3D scene reconstruction has been substantially advanced by recent progress in neural fields. However, most existing methods train a separate network from scratch for each individual scene. This is not scalable, inefficient, and unable to yield good results given limited views. While learning-based multi-view stereo methods alleviate this issue to some extent, their multi-view setting makes it less flexible to scale up and to broad applications. Instead, we introduce training generalizable Neural Fields incorporating scene Priors (NFPs). The NFP network maps any single-view RGB-D image into signed distance and radiance values. A complete scene can be reconstructed by merging individual frames in the volumetric space WITHOUT a fusion module, which provides better flexibility. The scene priors can be trained on large-scale datasets, allowing for fast adaptation to the reconstruction of a new scene with fewer views. NFP not only demonstrates SOTA scene reconstruction performa",
    "path": "papers/23/09/2309.15164.json",
    "total_tokens": 900,
    "translated_title": "使用场景先验的可推广神经场进行3D重建",
    "translated_abstract": "最近神经场的进展极大地推动了高保真度的3D场景重建。然而，大多数现有方法对每个场景都要从头开始训练一个独立的网络，这种方法不具有可扩展性，效率低下，且在有限视角下无法产生良好的结果。而基于学习的多视图立体方法在一定程度上解决了这个问题，但其多视图设置使得它在扩展和广泛应用方面不太灵活。相反，我们引入了训练可推广的融入场景先验的神经场（NFPs）方法。NFP网络将任何单视角的RGB-D图像映射成有符号距离和辐射值。通过在体积空间中合并单帧，可以重建完整的场景，无需融合模块，从而提供更好的灵活性。场景先验可以在大规模数据集上进行训练，使得能够快速适应使用较少视角重建新场景。NFP不仅展示了SOTA场景重建性能，",
    "tldr": "使用场景先验的可推广神经场方法，利用单个RGB-D图像映射场景，无需融合模块即可重建完整的场景，具有较好的灵活性和扩展性。"
}