{
    "title": "Machine Translation Models Stand Strong in the Face of Adversarial Attacks. (arXiv:2309.06527v1 [cs.CL])",
    "abstract": "Adversarial attacks expose vulnerabilities of deep learning models by introducing minor perturbations to the input, which lead to substantial alterations in the output. Our research focuses on the impact of such adversarial attacks on sequence-to-sequence (seq2seq) models, specifically machine translation models. We introduce algorithms that incorporate basic text perturbation heuristics and more advanced strategies, such as the gradient-based attack, which utilizes a differentiable approximation of the inherently non-differentiable translation metric. Through our investigation, we provide evidence that machine translation models display robustness displayed robustness against best performed known adversarial attacks, as the degree of perturbation in the output is directly proportional to the perturbation in the input. However, among underdogs, our attacks outperform alternatives, providing the best relative performance. Another strong candidate is an attack based on mixing of individu",
    "link": "http://arxiv.org/abs/2309.06527",
    "context": "Title: Machine Translation Models Stand Strong in the Face of Adversarial Attacks. (arXiv:2309.06527v1 [cs.CL])\nAbstract: Adversarial attacks expose vulnerabilities of deep learning models by introducing minor perturbations to the input, which lead to substantial alterations in the output. Our research focuses on the impact of such adversarial attacks on sequence-to-sequence (seq2seq) models, specifically machine translation models. We introduce algorithms that incorporate basic text perturbation heuristics and more advanced strategies, such as the gradient-based attack, which utilizes a differentiable approximation of the inherently non-differentiable translation metric. Through our investigation, we provide evidence that machine translation models display robustness displayed robustness against best performed known adversarial attacks, as the degree of perturbation in the output is directly proportional to the perturbation in the input. However, among underdogs, our attacks outperform alternatives, providing the best relative performance. Another strong candidate is an attack based on mixing of individu",
    "path": "papers/23/09/2309.06527.json",
    "total_tokens": 888,
    "translated_title": "机器翻译模型在面对对抗攻击时表现出强大的稳定性",
    "translated_abstract": "对抗攻击通过向输入引入微小扰动来暴露深度学习模型的漏洞，这导致输出结果发生重大变化。我们的研究关注这种对抗攻击对序列到序列（seq2seq）模型，特别是机器翻译模型的影响。我们引入了一些算法，包括基本文本扰动启发式和更高级的策略，如基于梯度的攻击，它利用可微分逼近非可微翻译度量。通过我们的调查，我们提供证据表明机器翻译模型对已知的最佳对抗攻击表现出了强大的稳定性，因为输出中的扰动程度与输入中的扰动成比例。然而，在不利情况下，我们的攻击胜过其他选择，提供了最佳的相对性能。另一个强大的候选是基于个体混合的攻击。",
    "tldr": "本研究探讨了对抗攻击对机器翻译模型的影响，证明了机器翻译模型在面对已知的最佳对抗攻击时表现出强大的稳定性。同时，我们提出的攻击算法在相对性能上超过其他替代选择。",
    "en_tdlr": "This research investigates the impact of adversarial attacks on machine translation models, demonstrating their robustness against known best-performed attacks. Additionally, our proposed attack algorithms outperform alternative choices in relative performance."
}