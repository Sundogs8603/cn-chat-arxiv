{
    "title": "InstaFlow: One Step is Enough for High-Quality Diffusion-Based Text-to-Image Generation. (arXiv:2309.06380v1 [cs.LG])",
    "abstract": "Diffusion models have revolutionized text-to-image generation with its exceptional quality and creativity. However, its multi-step sampling process is known to be slow, often requiring tens of inference steps to obtain satisfactory results. Previous attempts to improve its sampling speed and reduce computational costs through distillation have been unsuccessful in achieving a functional one-step model. In this paper, we explore a recent method called Rectified Flow, which, thus far, has only been applied to small datasets. The core of Rectified Flow lies in its \\emph{reflow} procedure, which straightens the trajectories of probability flows, refines the coupling between noises and images, and facilitates the distillation process with student models. We propose a novel text-conditioned pipeline to turn Stable Diffusion (SD) into an ultra-fast one-step model, in which we find reflow plays a critical role in improving the assignment between noise and images. Leveraging our new pipeline, w",
    "link": "http://arxiv.org/abs/2309.06380",
    "context": "Title: InstaFlow: One Step is Enough for High-Quality Diffusion-Based Text-to-Image Generation. (arXiv:2309.06380v1 [cs.LG])\nAbstract: Diffusion models have revolutionized text-to-image generation with its exceptional quality and creativity. However, its multi-step sampling process is known to be slow, often requiring tens of inference steps to obtain satisfactory results. Previous attempts to improve its sampling speed and reduce computational costs through distillation have been unsuccessful in achieving a functional one-step model. In this paper, we explore a recent method called Rectified Flow, which, thus far, has only been applied to small datasets. The core of Rectified Flow lies in its \\emph{reflow} procedure, which straightens the trajectories of probability flows, refines the coupling between noises and images, and facilitates the distillation process with student models. We propose a novel text-conditioned pipeline to turn Stable Diffusion (SD) into an ultra-fast one-step model, in which we find reflow plays a critical role in improving the assignment between noise and images. Leveraging our new pipeline, w",
    "path": "papers/23/09/2309.06380.json",
    "total_tokens": 978,
    "translated_title": "InstaFlow: 一步即可实现高质量基于扩散的文本到图像生成",
    "translated_abstract": "扩散模型以其出色的质量和创造力彻底改变了文本到图像生成领域。然而，其多步采样过程被认为很慢，通常需要十几步推断才能获得令人满意的结果。以往试图通过蒸馏来提高采样速度和减少计算成本的尝试都未能实现功能齐全的一步模型。本文中，我们探索了一种最近的方法，即修正的流动方法，这种方法到目前为止只应用于小数据集。修正的流动方法的核心在于其重新流动的过程，它将概率流的轨迹变得直线，改进了噪声与图像之间的耦合关系，并通过学生模型便于蒸馏过程。我们提出了一种新的文本条件的流程，将稳定扩散模型（SD）转化为超快速的一步模型，在其中我们发现重新流动在改善噪声与图像之间的对应关系方面起着关键作用。凭借我们的新流程，我们能够以较快的速度直接生成高质量的图像。",
    "tldr": "本研究提出了InstaFlow，一种基于扩散的文本到图像生成方法，将稳定扩散模型转化为一步模型，通过修正的流动方法提高了噪声与图像之间的对应关系，实现了高质量、高速度的图像生成。",
    "en_tdlr": "This paper presents InstaFlow, a diffusion-based text-to-image generation method that transforms Stable Diffusion into a one-step model. By leveraging the Rectified Flow method to improve the correspondence between noise and images, it achieves high-quality and high-speed image generation."
}