{
    "title": "Who to Trust, How and Why: Untangling AI Ethics Principles, Trustworthiness and Trust. (arXiv:2309.10318v1 [cs.AI])",
    "abstract": "We present an overview of the literature on trust in AI and AI trustworthiness and argue for the need to distinguish these concepts more clearly and to gather more empirically evidence on what contributes to people s trusting behaviours. We discuss that trust in AI involves not only reliance on the system itself, but also trust in the developers of the AI system. AI ethics principles such as explainability and transparency are often assumed to promote user trust, but empirical evidence of how such features actually affect how users perceive the system s trustworthiness is not as abundance or not that clear. AI systems should be recognised as socio-technical systems, where the people involved in designing, developing, deploying, and using the system are as important as the system for determining whether it is trustworthy. Without recognising these nuances, trust in AI and trustworthy AI risk becoming nebulous terms for any desirable feature for AI systems.",
    "link": "http://arxiv.org/abs/2309.10318",
    "context": "Title: Who to Trust, How and Why: Untangling AI Ethics Principles, Trustworthiness and Trust. (arXiv:2309.10318v1 [cs.AI])\nAbstract: We present an overview of the literature on trust in AI and AI trustworthiness and argue for the need to distinguish these concepts more clearly and to gather more empirically evidence on what contributes to people s trusting behaviours. We discuss that trust in AI involves not only reliance on the system itself, but also trust in the developers of the AI system. AI ethics principles such as explainability and transparency are often assumed to promote user trust, but empirical evidence of how such features actually affect how users perceive the system s trustworthiness is not as abundance or not that clear. AI systems should be recognised as socio-technical systems, where the people involved in designing, developing, deploying, and using the system are as important as the system for determining whether it is trustworthy. Without recognising these nuances, trust in AI and trustworthy AI risk becoming nebulous terms for any desirable feature for AI systems.",
    "path": "papers/23/09/2309.10318.json",
    "total_tokens": 952,
    "translated_title": "谁可以信任，如何以及为什么：梳理人工智能伦理原则、可信度和信任",
    "translated_abstract": "我们概述了关于人工智能信任和可信度的文献，并主张需要更清晰地区分这些概念，并收集更多关于人们信任行为的实证证据。我们讨论了信任人工智能不仅涉及对系统本身的依赖，还包括对人工智能系统的开发者的信任。人工智能伦理原则，如可解释性和透明度，经常被认为可以促进用户的信任，但这些特性实际上如何影响用户对系统可信度的感知的经验证据并不丰富或者不那么明确。人工智能系统应该被认识为社会技术系统，其中参与设计、开发、部署和使用系统的人与系统本身一样重要，以确定系统是否值得信赖。如果不认识到这些细微差别，对人工智能的信任和可信的人工智能就有可能成为任何对人工智能系统有益特性的模糊术语。",
    "tldr": "人工智能信任不仅取决于系统本身，还包括对开发者的信任。人工智能伦理原则如可解释性和透明度对用户的信任影响尚不清晰。人工智能系统应被认识为社会技术系统，人与系统同样重要来确定其可信度。",
    "en_tdlr": "Trust in AI depends not only on the system itself but also on trust in the developers. The impact of AI ethics principles such as explainability and transparency on user trust is still unclear. AI systems should be recognized as socio-technical systems where both people and the system itself play an important role in determining their trustworthiness."
}