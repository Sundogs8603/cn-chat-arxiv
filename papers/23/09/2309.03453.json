{
    "title": "SyncDreamer: Generating Multiview-consistent Images from a Single-view Image. (arXiv:2309.03453v1 [cs.CV])",
    "abstract": "In this paper, we present a novel diffusion model called that generates multiview-consistent images from a single-view image. Using pretrained large-scale 2D diffusion models, recent work Zero123 demonstrates the ability to generate plausible novel views from a single-view image of an object. However, maintaining consistency in geometry and colors for the generated images remains a challenge. To address this issue, we propose a synchronized multiview diffusion model that models the joint probability distribution of multiview images, enabling the generation of multiview-consistent images in a single reverse process. SyncDreamer synchronizes the intermediate states of all the generated images at every step of the reverse process through a 3D-aware feature attention mechanism that correlates the corresponding features across different views. Experiments show that SyncDreamer generates images with high consistency across different views, thus making it well-suited for various 3D generation",
    "link": "http://arxiv.org/abs/2309.03453",
    "context": "Title: SyncDreamer: Generating Multiview-consistent Images from a Single-view Image. (arXiv:2309.03453v1 [cs.CV])\nAbstract: In this paper, we present a novel diffusion model called that generates multiview-consistent images from a single-view image. Using pretrained large-scale 2D diffusion models, recent work Zero123 demonstrates the ability to generate plausible novel views from a single-view image of an object. However, maintaining consistency in geometry and colors for the generated images remains a challenge. To address this issue, we propose a synchronized multiview diffusion model that models the joint probability distribution of multiview images, enabling the generation of multiview-consistent images in a single reverse process. SyncDreamer synchronizes the intermediate states of all the generated images at every step of the reverse process through a 3D-aware feature attention mechanism that correlates the corresponding features across different views. Experiments show that SyncDreamer generates images with high consistency across different views, thus making it well-suited for various 3D generation",
    "path": "papers/23/09/2309.03453.json",
    "total_tokens": 926,
    "translated_title": "SyncDreamer: 从单视图图像生成多视角一致性图像",
    "translated_abstract": "本文提出了一种名为SyncDreamer的新型扩散模型，可以从单视图图像生成多视角一致性图像。通过使用预训练的大规模2D扩散模型，最近的Zero123工作展示了从单视图物体图像生成合理的新视角的能力。然而，生成的图像在几何和颜色上的一致性仍然是一个挑战。为了解决这个问题，我们提出了一种同步的多视角扩散模型，它模拟了多视角图像的联合概率分布，可以通过单个反向过程生成多视角一致性图像。SyncDreamer通过3D感知特征注意机制，在反向过程的每个步骤中同步所有生成图像的中间状态，从而相关联不同视角上的相应特征。实验表明，SyncDreamer能够在不同视角之间生成高度一致的图像，因此非常适用于各种3D生成任务。",
    "tldr": "本文提出了一种名为SyncDreamer的新型扩散模型，可以从单视图图像生成多视角一致性图像。通过同步所有生成图像的中间状态，并利用3D感知特征注意机制，SyncDreamer能够实现在不同视角上生成高度一致的图像，为各种3D生成任务提供了有力的支持。"
}