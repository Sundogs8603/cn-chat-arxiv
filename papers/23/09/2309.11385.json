{
    "title": "Safurai 001: New Qualitative Approach for Code LLM Evaluation. (arXiv:2309.11385v1 [cs.CL])",
    "abstract": "This paper presents Safurai-001, a new Large Language Model (LLM) with significant potential in the domain of coding assistance. Driven by recent advancements in coding LLMs, Safurai-001 competes in performance with the latest models like WizardCoder [Xu et al., 2023], PanguCoder [Shen et al., 2023] and Phi-1 [Gunasekar et al., 2023] but aims to deliver a more conversational interaction. By capitalizing on the progress in data engineering (including latest techniques of data transformation and prompt engineering) and instruction tuning, this new model promises to stand toe-to-toe with recent closed and open source developments. Recognizing the need for an efficacious evaluation metric for coding LLMs, this paper also introduces GPT4-based MultiParameters, an evaluation benchmark that harnesses varied parameters to present a comprehensive insight into the models functioning and performance. Our assessment shows that Safurai-001 can outperform GPT-3.5 by 1.58% and WizardCoder by 18.78% i",
    "link": "http://arxiv.org/abs/2309.11385",
    "context": "Title: Safurai 001: New Qualitative Approach for Code LLM Evaluation. (arXiv:2309.11385v1 [cs.CL])\nAbstract: This paper presents Safurai-001, a new Large Language Model (LLM) with significant potential in the domain of coding assistance. Driven by recent advancements in coding LLMs, Safurai-001 competes in performance with the latest models like WizardCoder [Xu et al., 2023], PanguCoder [Shen et al., 2023] and Phi-1 [Gunasekar et al., 2023] but aims to deliver a more conversational interaction. By capitalizing on the progress in data engineering (including latest techniques of data transformation and prompt engineering) and instruction tuning, this new model promises to stand toe-to-toe with recent closed and open source developments. Recognizing the need for an efficacious evaluation metric for coding LLMs, this paper also introduces GPT4-based MultiParameters, an evaluation benchmark that harnesses varied parameters to present a comprehensive insight into the models functioning and performance. Our assessment shows that Safurai-001 can outperform GPT-3.5 by 1.58% and WizardCoder by 18.78% i",
    "path": "papers/23/09/2309.11385.json",
    "total_tokens": 1026,
    "translated_title": "Safurai 001:代码LLM评估的新定性方法",
    "translated_abstract": "本文介绍了Safurai-001，这是一个具有显著潜力的新的大型语言模型（LLM），在编码辅助领域有着重要的应用。基于最新的编码LLM进展，Safurai-001在性能上与最新模型如WizardCoder、PanguCoder和Phi-1相媲美，但旨在提供更加对话式的交互体验。通过充分利用数据工程的进展（包括最新的数据转换和提示工程技术）和指令调优，这个新模型承诺能够与最近的闭源和开源发展并驾齐驱。鉴于对编码LLM的高效评估指标的需求，本文还介绍了基于GPT4的多参数评估基准，利用多样的参数来全面了解模型的功能和性能。我们的评估结果显示，Safurai-001在性能上能够超过GPT-3.5 1.58%和WizardCoder 18.78%。",
    "tldr": "Safurai-001是一种新的代码LLM评估方法，通过充分利用数据工程进展和指令调优，它能够提供与其他最新模型相媲美的性能，并在对话式交互体验方面有所提升。通过引入基于GPT4的多参数评估基准，它提供了全面洞察模型的功能和性能。在评估中，Safurai-001超过了GPT-3.5 1.58%和WizardCoder 18.78%。",
    "en_tdlr": "Safurai-001 is a new qualitative approach for code LLM evaluation that provides comparable performance to other state-of-the-art models while delivering enhanced conversational interaction. It introduces a GPT4-based MultiParameters evaluation benchmark to comprehensively assess the model's functioning and performance. In evaluations, Safurai-001 outperforms GPT-3.5 by 1.58% and WizardCoder by 18.78%."
}