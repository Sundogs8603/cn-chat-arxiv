{
    "title": "ViewMix: Augmentation for Robust Representation in Self-Supervised Learning. (arXiv:2309.03360v1 [cs.CV])",
    "abstract": "Joint Embedding Architecture-based self-supervised learning methods have attributed the composition of data augmentations as a crucial factor for their strong representation learning capabilities. While regional dropout strategies have proven to guide models to focus on lesser indicative parts of the objects in supervised methods, it hasn't been adopted by self-supervised methods for generating positive pairs. This is because the regional dropout methods are not suitable for the input sampling process of the self-supervised methodology. Whereas dropping informative pixels from the positive pairs can result in inefficient training, replacing patches of a specific object with a different one can steer the model from maximizing the agreement between different positive pairs. Moreover, joint embedding representation learning methods have not made robustness their primary training outcome. To this end, we propose the ViewMix augmentation policy, specially designed for self-supervised learni",
    "link": "http://arxiv.org/abs/2309.03360",
    "context": "Title: ViewMix: Augmentation for Robust Representation in Self-Supervised Learning. (arXiv:2309.03360v1 [cs.CV])\nAbstract: Joint Embedding Architecture-based self-supervised learning methods have attributed the composition of data augmentations as a crucial factor for their strong representation learning capabilities. While regional dropout strategies have proven to guide models to focus on lesser indicative parts of the objects in supervised methods, it hasn't been adopted by self-supervised methods for generating positive pairs. This is because the regional dropout methods are not suitable for the input sampling process of the self-supervised methodology. Whereas dropping informative pixels from the positive pairs can result in inefficient training, replacing patches of a specific object with a different one can steer the model from maximizing the agreement between different positive pairs. Moreover, joint embedding representation learning methods have not made robustness their primary training outcome. To this end, we propose the ViewMix augmentation policy, specially designed for self-supervised learni",
    "path": "papers/23/09/2309.03360.json",
    "total_tokens": 831,
    "translated_title": "ViewMix：自监督学习中的稳健表示增强方法",
    "translated_abstract": "基于联合嵌入架构的自监督学习方法认为数据增强的组合是其强大表示学习能力的关键因素。尽管在监督方法中，区域性丢失策略已被证明可以引导模型关注物体的较不明显部分，但在自监督方法中尚未采用这种方法生成正样本对。这是因为区域性丢失方法不适用于自监督方法的输入采样过程。然而，从正样本中丢弃信息性像素可能导致训练效率低下，用不同对象的补丁替换特定对象的补丁可以使模型无法最大化不同正样本之间的一致性。此外，联合嵌入表示学习方法尚未将稳健性作为其主要训练目标。为此，我们提出了ViewMix增强策略，特别针对自监督学习设计。",
    "tldr": "这项研究提出了一种名为ViewMix的增强策略，专门用于自监督学习，该策略可以改善模型的表示学习能力，并提高模型的稳健性。",
    "en_tdlr": "This study proposes an augmentation policy called ViewMix, specifically designed for self-supervised learning, which improves the model's representation learning capability and enhances its robustness."
}