{
    "title": "A Theory of Multimodal Learning. (arXiv:2309.12458v1 [cs.LG])",
    "abstract": "Human perception of the empirical world involves recognizing the diverse appearances, or 'modalities', of underlying objects. Despite the longstanding consideration of this perspective in philosophy and cognitive science, the study of multimodality remains relatively under-explored within the field of machine learning. Nevertheless, current studies of multimodal machine learning are limited to empirical practices, lacking theoretical foundations beyond heuristic arguments. An intriguing finding from the practice of multimodal learning is that a model trained on multiple modalities can outperform a finely-tuned unimodal model, even on unimodal tasks. This paper provides a theoretical framework that explains this phenomenon, by studying generalization properties of multimodal learning algorithms. We demonstrate that multimodal learning allows for a superior generalization bound compared to unimodal learning, up to a factor of $O(\\sqrt{n})$, where $n$ represents the sample size. Such adva",
    "link": "http://arxiv.org/abs/2309.12458",
    "context": "Title: A Theory of Multimodal Learning. (arXiv:2309.12458v1 [cs.LG])\nAbstract: Human perception of the empirical world involves recognizing the diverse appearances, or 'modalities', of underlying objects. Despite the longstanding consideration of this perspective in philosophy and cognitive science, the study of multimodality remains relatively under-explored within the field of machine learning. Nevertheless, current studies of multimodal machine learning are limited to empirical practices, lacking theoretical foundations beyond heuristic arguments. An intriguing finding from the practice of multimodal learning is that a model trained on multiple modalities can outperform a finely-tuned unimodal model, even on unimodal tasks. This paper provides a theoretical framework that explains this phenomenon, by studying generalization properties of multimodal learning algorithms. We demonstrate that multimodal learning allows for a superior generalization bound compared to unimodal learning, up to a factor of $O(\\sqrt{n})$, where $n$ represents the sample size. Such adva",
    "path": "papers/23/09/2309.12458.json",
    "total_tokens": 858,
    "translated_title": "多模态学习的理论",
    "translated_abstract": "人类对经验世界的感知涉及到识别基础物体的各种外观或“模态”。尽管哲学和认知科学领域长期以来一直考虑这一观点，但是在机器学习领域中，对多模态的研究相对较少。然而，目前关于多模态机器学习的研究仅限于经验实践，缺乏理论基础，只有启发式论证。多模态学习实践中的一个有趣发现是，在单模态任务上，训练在多个模态上的模型可以胜过经过精细调节的单模态模型。本文提供了一个理论框架来解释这一现象，通过研究多模态学习算法的泛化性质。我们证明了多模态学习相比于单模态学习具有更优的泛化界限，高达$O(\\sqrt{n})$的因子，其中$n$表示样本大小。",
    "tldr": "这篇论文提供了一个理论框架来解释多模态学习中的一个有趣发现，即在单模态任务上，训练在多个模态上的模型可以胜过经过精细调节的单模态模型。",
    "en_tdlr": "This paper provides a theoretical framework to explain an intriguing finding in multimodal learning, which is that a model trained on multiple modalities can outperform a finely-tuned unimodal model on unimodal tasks."
}