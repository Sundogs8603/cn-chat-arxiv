{
    "title": "CONVERSER: Few-Shot Conversational Dense Retrieval with Synthetic Data Generation. (arXiv:2309.06748v1 [cs.CL])",
    "abstract": "Conversational search provides a natural interface for information retrieval (IR). Recent approaches have demonstrated promising results in applying dense retrieval to conversational IR. However, training dense retrievers requires large amounts of in-domain paired data. This hinders the development of conversational dense retrievers, as abundant in-domain conversations are expensive to collect. In this paper, we propose CONVERSER, a framework for training conversational dense retrievers with at most 6 examples of in-domain dialogues. Specifically, we utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus. Experimental results on conversational retrieval benchmarks OR-QuAC and TREC CAsT 19 show that the proposed CONVERSER achieves comparable performance to fully-supervised models, demonstrating the effectiveness of our proposed framework in few-shot conversational dense retrieval. All source code and",
    "link": "http://arxiv.org/abs/2309.06748",
    "context": "Title: CONVERSER: Few-Shot Conversational Dense Retrieval with Synthetic Data Generation. (arXiv:2309.06748v1 [cs.CL])\nAbstract: Conversational search provides a natural interface for information retrieval (IR). Recent approaches have demonstrated promising results in applying dense retrieval to conversational IR. However, training dense retrievers requires large amounts of in-domain paired data. This hinders the development of conversational dense retrievers, as abundant in-domain conversations are expensive to collect. In this paper, we propose CONVERSER, a framework for training conversational dense retrievers with at most 6 examples of in-domain dialogues. Specifically, we utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus. Experimental results on conversational retrieval benchmarks OR-QuAC and TREC CAsT 19 show that the proposed CONVERSER achieves comparable performance to fully-supervised models, demonstrating the effectiveness of our proposed framework in few-shot conversational dense retrieval. All source code and",
    "path": "papers/23/09/2309.06748.json",
    "total_tokens": 893,
    "translated_title": "CONVERSER：使用合成数据生成的少样本对话密集检索",
    "translated_abstract": "对话式搜索为信息检索提供了自然界面。最近的方法在对话式信息检索中应用了密集检索取得了有希望的结果。然而，训练密集检索器需要大量的领域相关的配对数据。这限制了对话式密集检索器的发展，因为收集大量领域相关对话是昂贵的。在本文中，我们提出了CONVERSER，这是一个用最多6对领域相关对话进行训练的对话式密集检索框架。具体而言，我们利用大型语言模型的上下文学习能力，根据检索语料库中的段落生成对话查询。对OR-QuAC和TREC CAsT 19等对话检索基准进行的实验结果表明，所提出的CONVERSER达到了与完全监督模型相当的性能，证明了我们提出的少样本对话密集检索框架的有效性。",
    "tldr": "CONVERSER是一个使用少量对话样本进行训练的对话式密集检索框架，通过利用大型语言模型的上下文学习能力，能够生成与检索语料库中段落相关的对话查询，实验结果表明其在少样本对话密集检索中表现出与完全监督模型相当的性能。",
    "en_tdlr": "CONVERSER is a conversational dense retrieval framework trained with few examples, which utilizes the in-context learning capability of large language models to generate conversational queries related to passages in the retrieval corpus. Experimental results demonstrate comparable performance to fully-supervised models in few-shot conversational dense retrieval."
}