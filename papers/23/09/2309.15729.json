{
    "title": "MindGPT: Interpreting What You See with Non-invasive Brain Recordings. (arXiv:2309.15729v1 [cs.CV])",
    "abstract": "Decoding of seen visual contents with non-invasive brain recordings has important scientific and practical values. Efforts have been made to recover the seen images from brain signals. However, most existing approaches cannot faithfully reflect the visual contents due to insufficient image quality or semantic mismatches. Compared with reconstructing pixel-level visual images, speaking is a more efficient and effective way to explain visual information. Here we introduce a non-invasive neural decoder, termed as MindGPT, which interprets perceived visual stimuli into natural languages from fMRI signals. Specifically, our model builds upon a visually guided neural encoder with a cross-attention mechanism, which permits us to guide latent neural representations towards a desired language semantic direction in an end-to-end manner by the collaborative use of the large language model GPT. By doing so, we found that the neural representations of the MindGPT are explainable, which can be used ",
    "link": "http://arxiv.org/abs/2309.15729",
    "context": "Title: MindGPT: Interpreting What You See with Non-invasive Brain Recordings. (arXiv:2309.15729v1 [cs.CV])\nAbstract: Decoding of seen visual contents with non-invasive brain recordings has important scientific and practical values. Efforts have been made to recover the seen images from brain signals. However, most existing approaches cannot faithfully reflect the visual contents due to insufficient image quality or semantic mismatches. Compared with reconstructing pixel-level visual images, speaking is a more efficient and effective way to explain visual information. Here we introduce a non-invasive neural decoder, termed as MindGPT, which interprets perceived visual stimuli into natural languages from fMRI signals. Specifically, our model builds upon a visually guided neural encoder with a cross-attention mechanism, which permits us to guide latent neural representations towards a desired language semantic direction in an end-to-end manner by the collaborative use of the large language model GPT. By doing so, we found that the neural representations of the MindGPT are explainable, which can be used ",
    "path": "papers/23/09/2309.15729.json",
    "total_tokens": 857,
    "translated_title": "MindGPT：利用非侵入性脑记录解读所见图像",
    "translated_abstract": "利用非侵入性脑记录解读所见的视觉内容具有重要的科学和实践价值。已经做出了努力来从脑信号中恢复所见图像。然而，由于图像质量不足或语义不匹配，大多数现有方法无法真实反映视觉内容。与重建像素级视觉图像相比，讲话是一种更高效、更有效的解释视觉信息的方式。在这里，我们介绍了一种名为MindGPT的非侵入性神经解码器，它将感知到的视觉刺激解释为自然语言，通过fMRI信号。具体而言，我们的模型基于一个带有交叉注意机制的视觉引导神经编码器，通过协同使用大型语言模型GPT，可以以端到端的方式将潜在的神经表示引导到所需的语言语义方向。通过这样做，我们发现MindGPT的神经表示是可解释的，可以用于",
    "tldr": "这篇论文介绍了一种非侵入性神经解码器MindGPT，它能够从脑信号中解析所见的视觉刺激并转化为自然语言表达。"
}