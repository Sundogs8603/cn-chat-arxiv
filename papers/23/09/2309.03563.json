{
    "title": "All Labels Together: Low-shot Intent Detection with an Efficient Label Semantic Encoding Paradigm. (arXiv:2309.03563v1 [cs.CL])",
    "abstract": "In intent detection tasks, leveraging meaningful semantic information from intent labels can be particularly beneficial for few-shot scenarios. However, existing few-shot intent detection methods either ignore the intent labels, (e.g. treating intents as indices) or do not fully utilize this information (e.g. only using part of the intent labels). In this work, we present an end-to-end One-to-All system that enables the comparison of an input utterance with all label candidates. The system can then fully utilize label semantics in this way. Experiments on three few-shot intent detection tasks demonstrate that One-to-All is especially effective when the training resource is extremely scarce, achieving state-of-the-art performance in 1-, 3- and 5-shot settings. Moreover, we present a novel pretraining strategy for our model that utilizes indirect supervision from paraphrasing, enabling zero-shot cross-domain generalization on intent detection tasks. Our code is at https://github.com/jian",
    "link": "http://arxiv.org/abs/2309.03563",
    "context": "Title: All Labels Together: Low-shot Intent Detection with an Efficient Label Semantic Encoding Paradigm. (arXiv:2309.03563v1 [cs.CL])\nAbstract: In intent detection tasks, leveraging meaningful semantic information from intent labels can be particularly beneficial for few-shot scenarios. However, existing few-shot intent detection methods either ignore the intent labels, (e.g. treating intents as indices) or do not fully utilize this information (e.g. only using part of the intent labels). In this work, we present an end-to-end One-to-All system that enables the comparison of an input utterance with all label candidates. The system can then fully utilize label semantics in this way. Experiments on three few-shot intent detection tasks demonstrate that One-to-All is especially effective when the training resource is extremely scarce, achieving state-of-the-art performance in 1-, 3- and 5-shot settings. Moreover, we present a novel pretraining strategy for our model that utilizes indirect supervision from paraphrasing, enabling zero-shot cross-domain generalization on intent detection tasks. Our code is at https://github.com/jian",
    "path": "papers/23/09/2309.03563.json",
    "total_tokens": 946,
    "translated_title": "全部标签在一起：基于高效的标签语义编码范式的低资源意图检测",
    "translated_abstract": "在意图检测任务中，利用意图标签的有意义的语义信息对于少样本场景可能特别有益。然而，现有的少样本意图检测方法要么忽略了意图标签，（例如将意图视为索引），要么没有充分利用这些信息（例如仅使用部分意图标签）。在这项工作中，我们提出了一个端到端的One-to-All系统，可以将输入话语与所有标签候选项进行比较。系统可以通过这种方式充分利用标签语义。在三个少样本意图检测任务上的实验证明，当训练资源极为有限时，One-to-All特别有效，在1-shot、3-shot和5-shot设置中实现了最先进的性能。此外，我们还提出了一种新颖的预训练策略，利用了从释义得到的间接监督信号，实现了对意图检测任务的跨领域零样本泛化。我们的代码位于https://github.com/jian",
    "tldr": "这项工作中，我们提出了一个端到端的One-to-All系统，可以在少样本场景下通过比较输入话语与所有标签候选项来充分利用标签语义。实验证明该方法在低资源情况下表现出最先进的性能，并通过预训练策略实现了跨领域零样本泛化。"
}