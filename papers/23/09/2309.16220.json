{
    "title": "Unmasking the Chameleons: A Benchmark for Out-of-Distribution Detection in Medical Tabular Data. (arXiv:2309.16220v1 [cs.LG])",
    "abstract": "Despite their success, Machine Learning (ML) models do not generalize effectively to data not originating from the training distribution. To reliably employ ML models in real-world healthcare systems and avoid inaccurate predictions on out-of-distribution (OOD) data, it is crucial to detect OOD samples. Numerous OOD detection approaches have been suggested in other fields - especially in computer vision - but it remains unclear whether the challenge is resolved when dealing with medical tabular data. To answer this pressing need, we propose an extensive reproducible benchmark to compare different methods across a suite of tests including both near and far OODs. Our benchmark leverages the latest versions of eICU and MIMIC-IV, two public datasets encompassing tens of thousands of ICU patients in several hospitals. We consider a wide array of density-based methods and SOTA post-hoc detectors across diverse predictive architectures, including MLP, ResNet, and Transformer. Our findings sho",
    "link": "http://arxiv.org/abs/2309.16220",
    "context": "Title: Unmasking the Chameleons: A Benchmark for Out-of-Distribution Detection in Medical Tabular Data. (arXiv:2309.16220v1 [cs.LG])\nAbstract: Despite their success, Machine Learning (ML) models do not generalize effectively to data not originating from the training distribution. To reliably employ ML models in real-world healthcare systems and avoid inaccurate predictions on out-of-distribution (OOD) data, it is crucial to detect OOD samples. Numerous OOD detection approaches have been suggested in other fields - especially in computer vision - but it remains unclear whether the challenge is resolved when dealing with medical tabular data. To answer this pressing need, we propose an extensive reproducible benchmark to compare different methods across a suite of tests including both near and far OODs. Our benchmark leverages the latest versions of eICU and MIMIC-IV, two public datasets encompassing tens of thousands of ICU patients in several hospitals. We consider a wide array of density-based methods and SOTA post-hoc detectors across diverse predictive architectures, including MLP, ResNet, and Transformer. Our findings sho",
    "path": "papers/23/09/2309.16220.json",
    "total_tokens": 941,
    "translated_title": "揭示变色龙：医学表格数据中的ODD检测的基准。 (arXiv:2309.16220v1 [cs.LG])",
    "translated_abstract": "尽管机器学习（ML）模型取得了成功，但它们在来自训练分布之外的数据上没有有效的泛化能力。为了可靠地在现实世界的医疗系统中使用ML模型，并避免对ODD数据进行不准确的预测，检测ODD样本至关重要。虽然在其他领域，特别是在计算机视觉领域，提出了许多ODD检测方法，但当处理医学表格数据时，是否解决了这一挑战仍不清楚。为了回答这一迫切需求，我们提出了一个广泛可复制的基准，通过多个测试来比较不同方法，包括近和远ODDs。我们的基准利用了最新版本的eICU和MIMIC-IV，这是两个公共数据集，涵盖了数万名ICU患者在多家医院。我们考虑了各种基于密度的方法和SOTA后置检测器，涵盖了多种预测架构，包括MLP、ResNet和Transformer。我们的研究结果显示。",
    "tldr": "该论文提出了一个基准来比较不同的方法在医学表格数据中进行ODD检测，为了实现在实际医疗系统中可靠地使用机器学习模型并避免对ODD数据进行不准确的预测，该基准利用了大规模的ICU患者数据集，考虑了多种方法和预测架构。"
}