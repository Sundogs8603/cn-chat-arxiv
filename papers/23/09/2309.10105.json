{
    "title": "Understanding Catastrophic Forgetting in Language Models via Implicit Inference. (arXiv:2309.10105v1 [cs.CL])",
    "abstract": "Fine-tuning (via methods such as instruction-tuning or reinforcement learning from human feedback) is a crucial step in training language models to robustly carry out tasks of interest. However, we lack a systematic understanding of the effects of fine-tuning, particularly on tasks outside the narrow fine-tuning distribution. In a simplified scenario, we demonstrate that improving performance on tasks within the fine-tuning data distribution comes at the expense of suppressing model capabilities on other tasks. This degradation is especially pronounced for tasks \"closest\" to the fine-tuning distribution. We hypothesize that language models implicitly infer the task of the prompt corresponds, and the fine-tuning process predominantly skews this task inference towards tasks in the fine-tuning distribution. To test this hypothesis, we propose Conjugate Prompting to see if we can recover pretrained capabilities. Conjugate prompting artificially makes the task look farther from the fine-tun",
    "link": "http://arxiv.org/abs/2309.10105",
    "context": "Title: Understanding Catastrophic Forgetting in Language Models via Implicit Inference. (arXiv:2309.10105v1 [cs.CL])\nAbstract: Fine-tuning (via methods such as instruction-tuning or reinforcement learning from human feedback) is a crucial step in training language models to robustly carry out tasks of interest. However, we lack a systematic understanding of the effects of fine-tuning, particularly on tasks outside the narrow fine-tuning distribution. In a simplified scenario, we demonstrate that improving performance on tasks within the fine-tuning data distribution comes at the expense of suppressing model capabilities on other tasks. This degradation is especially pronounced for tasks \"closest\" to the fine-tuning distribution. We hypothesize that language models implicitly infer the task of the prompt corresponds, and the fine-tuning process predominantly skews this task inference towards tasks in the fine-tuning distribution. To test this hypothesis, we propose Conjugate Prompting to see if we can recover pretrained capabilities. Conjugate prompting artificially makes the task look farther from the fine-tun",
    "path": "papers/23/09/2309.10105.json",
    "total_tokens": 966,
    "translated_title": "通过隐式推理理解语言模型中的灾难性遗忘",
    "translated_abstract": "微调（通过指令微调或从人类反馈进行强化学习等方法）是训练语言模型以鲁棒地执行所需任务的关键步骤。然而，我们缺乏对微调的影响的系统理解，特别是在狭窄的微调分布之外的任务上。在一个简化的场景中，我们证明，在微调数据分布内提高任务表现的同时，会抑制模型在其他任务上的能力。这种退化在与微调分布“最接近”的任务中尤为显著。我们假设语言模型会隐式推理出与提示相对应的任务，并且微调过程主要偏向于微调分布中的任务，以测试这个假设，我们提出了共轭提示以查看是否可以恢复预训练的能力。共轭提示会人为地使任务看起来与微调分布较远。",
    "tldr": "本研究通过在语言模型上进行实验，发现微调对模型在微调数据分布任务上的表现有正面影响，但会抑制模型在其他任务上的能力，特别是与微调分布最接近的任务。作者假设语言模型会隐式推理任务，并且微调过程偏向于微调数据分布中的任务。作者进一步提出了共轭提示方法，以尝试恢复模型在预训练阶段的能力。",
    "en_tdlr": "This study reveals that fine-tuning has a positive impact on the performance of language models on tasks within the fine-tuning distribution, but suppresses the capabilities on other tasks, especially those closest to the fine-tuning distribution. The authors hypothesize that language models implicitly infer the task and that the fine-tuning process predominantly skews this task inference towards the tasks in the fine-tuning distribution. The authors propose Conjugate Prompting as a method to recover the pretrained capabilities."
}