{
    "title": "A Metaheuristic for Amortized Search in High-Dimensional Parameter Spaces. (arXiv:2309.16465v1 [q-bio.QM])",
    "abstract": "Parameter inference for dynamical models of (bio)physical systems remains a challenging problem. Intractable gradients, high-dimensional spaces, and non-linear model functions are typically problematic without large computational budgets. A recent body of work in that area has focused on Bayesian inference methods, which consider parameters under their statistical distributions and therefore, do not derive point estimates of optimal parameter values. Here we propose a new metaheuristic that drives dimensionality reductions from feature-informed transformations (DR-FFIT) to address these bottlenecks. DR-FFIT implements an efficient sampling strategy that facilitates a gradient-free parameter search in high-dimensional spaces. We use artificial neural networks to obtain differentiable proxies for the model's features of interest. The resulting gradients enable the estimation of a local active subspace of the model within a defined sampling region. This approach enables efficient dimensio",
    "link": "http://arxiv.org/abs/2309.16465",
    "context": "Title: A Metaheuristic for Amortized Search in High-Dimensional Parameter Spaces. (arXiv:2309.16465v1 [q-bio.QM])\nAbstract: Parameter inference for dynamical models of (bio)physical systems remains a challenging problem. Intractable gradients, high-dimensional spaces, and non-linear model functions are typically problematic without large computational budgets. A recent body of work in that area has focused on Bayesian inference methods, which consider parameters under their statistical distributions and therefore, do not derive point estimates of optimal parameter values. Here we propose a new metaheuristic that drives dimensionality reductions from feature-informed transformations (DR-FFIT) to address these bottlenecks. DR-FFIT implements an efficient sampling strategy that facilitates a gradient-free parameter search in high-dimensional spaces. We use artificial neural networks to obtain differentiable proxies for the model's features of interest. The resulting gradients enable the estimation of a local active subspace of the model within a defined sampling region. This approach enables efficient dimensio",
    "path": "papers/23/09/2309.16465.json",
    "total_tokens": 868,
    "translated_title": "一种在高维参数空间中进行摊销搜索的元启发式算法",
    "translated_abstract": "对（生物）物理系统的动力学模型进行参数推断仍然是一个具有挑战性的问题。难以处理的梯度、高维空间和非线性模型函数通常在没有大量计算预算的情况下成为问题。最近在这个领域的一系列工作集中在贝叶斯推断方法上，这些方法考虑参数在其统计分布下，并且因此不得出最优参数值的点估计。在这里，我们提出了一种新的元启发式算法，通过基于特征的变换（DR-FFIT）来降低维度，以解决这些瓶颈问题。DR-FFIT实现了一种有效的抽样策略，可以在高维空间中进行无梯度的参数搜索。我们使用人工神经网络来获取模型感兴趣特征的可微代理。由此产生的梯度使得在定义的抽样区域内估计模型的本地活跃子空间成为可能。这种方法实现了高效的维度约简。",
    "tldr": "我们提出了一种新的元启发式算法，通过基于特征的变换实现高维参数空间中的无梯度参数搜索，从而解决参数推断中的挑战性问题。",
    "en_tdlr": "We propose a new metaheuristic, DR-FFIT, which implements feature-informed transformations to enable gradient-free parameter search in high-dimensional spaces, addressing the challenges in parameter inference."
}