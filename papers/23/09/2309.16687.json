{
    "title": "Duality Principle and Biologically Plausible Learning: Connecting the Representer Theorem and Hebbian Learning. (arXiv:2309.16687v1 [cs.NE])",
    "abstract": "A normative approach called Similarity Matching was recently introduced for deriving and understanding the algorithmic basis of neural computation focused on unsupervised problems. It involves deriving algorithms from computational objectives and evaluating their compatibility with anatomical and physiological observations. In particular, it introduces neural architectures by considering dual alternatives instead of primal formulations of popular models such as PCA. However, its connection to the Representer theorem remains unexplored. In this work, we propose to use teachings from this approach to explore supervised learning algorithms and clarify the notion of Hebbian learning. We examine regularized supervised learning and elucidate the emergence of neural architecture and additive versus multiplicative update rules. In this work, we focus not on developing new algorithms but on showing that the Representer theorem offers the perfect lens to study biologically plausible learning alg",
    "link": "http://arxiv.org/abs/2309.16687",
    "context": "Title: Duality Principle and Biologically Plausible Learning: Connecting the Representer Theorem and Hebbian Learning. (arXiv:2309.16687v1 [cs.NE])\nAbstract: A normative approach called Similarity Matching was recently introduced for deriving and understanding the algorithmic basis of neural computation focused on unsupervised problems. It involves deriving algorithms from computational objectives and evaluating their compatibility with anatomical and physiological observations. In particular, it introduces neural architectures by considering dual alternatives instead of primal formulations of popular models such as PCA. However, its connection to the Representer theorem remains unexplored. In this work, we propose to use teachings from this approach to explore supervised learning algorithms and clarify the notion of Hebbian learning. We examine regularized supervised learning and elucidate the emergence of neural architecture and additive versus multiplicative update rules. In this work, we focus not on developing new algorithms but on showing that the Representer theorem offers the perfect lens to study biologically plausible learning alg",
    "path": "papers/23/09/2309.16687.json",
    "total_tokens": 873,
    "translated_title": "对偶原理和生物合理学习：连接表示定理和Hebbian学习",
    "translated_abstract": "最近引入了一种叫做相似性匹配的规范方法，用于推导和理解神经计算的算法基础，着重于无监督问题。它涉及从计算目标中推导算法，并评估其与解剖和生理观察的兼容性。特别地，它通过考虑双重替代而非主要形式的流行模型（如PCA）来引入神经结构。然而，它与表示定理的关联尚未被探索。在这项工作中，我们提出利用这种方法的教导来探索监督学习算法，并阐述了Hebbian学习的概念。我们研究了正则化的监督学习，并阐明了神经结构的出现以及加性更新和乘性更新规则之间的差异。在这项工作中，我们的重点不在于开发新算法，而在于展示表示定理提供了研究生物合理学习算法的完美视角。",
    "tldr": "本研究探索了一种规范方法，相似性匹配，用于推导和理解神经计算的算法基础，并且发现表示定理是研究生物合理学习算法的重要视角。",
    "en_tdlr": "This study explores a normative approach, Similarity Matching, for deriving and understanding the algorithmic basis of neural computation, and discovers that the Representer theorem offers an important perspective for studying biologically plausible learning algorithms."
}