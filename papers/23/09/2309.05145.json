{
    "title": "Outlier Robust Adversarial Training. (arXiv:2309.05145v1 [cs.LG])",
    "abstract": "Supervised learning models are challenged by the intrinsic complexities of training data such as outliers and minority subpopulations and intentional attacks at inference time with adversarial samples. While traditional robust learning methods and the recent adversarial training approaches are designed to handle each of the two challenges, to date, no work has been done to develop models that are robust with regard to the low-quality training data and the potential adversarial attack at inference time simultaneously. It is for this reason that we introduce Outlier Robust Adversarial Training (ORAT) in this work. ORAT is based on a bi-level optimization formulation of adversarial training with a robust rank-based loss function. Theoretically, we show that the learning objective of ORAT satisfies the $\\mathcal{H}$-consistency in binary classification, which establishes it as a proper surrogate to adversarial 0/1 loss. Furthermore, we analyze its generalization ability and provide uniform",
    "link": "http://arxiv.org/abs/2309.05145",
    "context": "Title: Outlier Robust Adversarial Training. (arXiv:2309.05145v1 [cs.LG])\nAbstract: Supervised learning models are challenged by the intrinsic complexities of training data such as outliers and minority subpopulations and intentional attacks at inference time with adversarial samples. While traditional robust learning methods and the recent adversarial training approaches are designed to handle each of the two challenges, to date, no work has been done to develop models that are robust with regard to the low-quality training data and the potential adversarial attack at inference time simultaneously. It is for this reason that we introduce Outlier Robust Adversarial Training (ORAT) in this work. ORAT is based on a bi-level optimization formulation of adversarial training with a robust rank-based loss function. Theoretically, we show that the learning objective of ORAT satisfies the $\\mathcal{H}$-consistency in binary classification, which establishes it as a proper surrogate to adversarial 0/1 loss. Furthermore, we analyze its generalization ability and provide uniform",
    "path": "papers/23/09/2309.05145.json",
    "total_tokens": 900,
    "translated_title": "异常值鲁棒对抗训练",
    "translated_abstract": "监督学习模型受到训练数据的固有复杂性的挑战，如异常值和少数子群，并且还受到推理时间的有意攻击，其中使用对抗样本。虽然传统的鲁棒学习方法和最近的对抗训练方法分别设计用于处理这两个挑战，但迄今为止，还没有研究开发出同时对训练数据质量低和推理时间潜在对抗攻击具有鲁棒性的模型。出于这个原因，我们在这项工作中介绍了异常值鲁棒对抗训练（ORAT）。ORAT基于一个双层优化公式的对抗训练，采用鲁棒的基于排名的损失函数。理论上，我们证明了ORAT的学习目标满足二分类的H-一致性，从而将其确立为对抗0/1损失的合适替代。此外，我们分析了它的泛化能力，并提供了统一的解释。",
    "tldr": "异常值鲁棒对抗训练（ORAT）是一种同时处理训练数据质量和推理时间对抗攻击的模型，采用了鲁棒的排名损失函数，具有较好的泛化性能。"
}