{
    "title": "Resolving Legalese: A Multilingual Exploration of Negation Scope Resolution in Legal Documents. (arXiv:2309.08695v1 [cs.CL])",
    "abstract": "Resolving the scope of a negation within a sentence is a challenging NLP task. The complexity of legal texts and the lack of annotated in-domain negation corpora pose challenges for state-of-the-art (SotA) models when performing negation scope resolution on multilingual legal data. Our experiments demonstrate that models pre-trained without legal data underperform in the task of negation scope resolution. Our experiments, using language models exclusively fine-tuned on domains like literary texts and medical data, yield inferior results compared to the outcomes documented in prior cross-domain experiments. We release a new set of annotated court decisions in German, French, and Italian and use it to improve negation scope resolution in both zero-shot and multilingual settings. We achieve token-level F1-scores of up to 86.7% in our zero-shot cross-lingual experiments, where the models are trained on two languages of our legal datasets and evaluated on the third. Our multilingual experim",
    "link": "http://arxiv.org/abs/2309.08695",
    "context": "Title: Resolving Legalese: A Multilingual Exploration of Negation Scope Resolution in Legal Documents. (arXiv:2309.08695v1 [cs.CL])\nAbstract: Resolving the scope of a negation within a sentence is a challenging NLP task. The complexity of legal texts and the lack of annotated in-domain negation corpora pose challenges for state-of-the-art (SotA) models when performing negation scope resolution on multilingual legal data. Our experiments demonstrate that models pre-trained without legal data underperform in the task of negation scope resolution. Our experiments, using language models exclusively fine-tuned on domains like literary texts and medical data, yield inferior results compared to the outcomes documented in prior cross-domain experiments. We release a new set of annotated court decisions in German, French, and Italian and use it to improve negation scope resolution in both zero-shot and multilingual settings. We achieve token-level F1-scores of up to 86.7% in our zero-shot cross-lingual experiments, where the models are trained on two languages of our legal datasets and evaluated on the third. Our multilingual experim",
    "path": "papers/23/09/2309.08695.json",
    "total_tokens": 994,
    "translated_title": "解决法律术语：法律文件中否定范围解析的多语言探索",
    "translated_abstract": "在句子中解析否定的范围是一项具有挑战性的自然语言处理任务。法律文本的复杂性以及缺乏经过注释的领域内否定语料库给最先进的模型在处理多语言法律数据上的否定范围解析时带来了挑战。我们的实验表明，预先未使用法律数据进行训练的模型在否定范围解析任务中表现不佳。我们的实验使用仅在文学文本和医学数据等领域进行了精细调整的语言模型，与之前的跨领域实验中记录的结果相比，效果较差。我们发布了一套德语、法语和意大利语的标注法院判决，并将其用于改进零摄取和多语言环境下的否定范围解析。在我们的零摄取跨语言实验中，我们的标记级F1分达到了86.7％，其中模型在我们的法律数据集的两种语言上进行训练，并在第三种语言上进行评估。",
    "tldr": "本研究通过多语言探索，解决了法律文件中否定范围解析的挑战。实验结果表明，以往模型在处理多语言法律数据时表现不佳，因此我们发布了一套新的法庭判决标注数据用于改进解析效果，并取得了高达86.7％的标记级F1分。",
    "en_tdlr": "This study addresses the challenge of negation scope resolution in legal documents by exploring multiple languages. Experimental results reveal that previous models underperform in handling multilingual legal data, prompting the release of a new set of annotated court decisions to improve resolution accuracy, achieving token-level F1-scores of up to 86.7%."
}