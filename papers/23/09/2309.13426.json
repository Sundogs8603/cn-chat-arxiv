{
    "title": "A Chat About Boring Problems: Studying GPT-based text normalization. (arXiv:2309.13426v2 [cs.CL] UPDATED)",
    "abstract": "Text normalization - the conversion of text from written to spoken form - is traditionally assumed to be an ill-formed task for language models. In this work, we argue otherwise. We empirically show the capacity of Large-Language Models (LLM) for text normalization in few-shot scenarios. Combining self-consistency reasoning with linguistic-informed prompt engineering, we find LLM based text normalization to achieve error rates around 40\\% lower than top normalization systems. Further, upon error analysis, we note key limitations in the conventional design of text normalization tasks. We create a new taxonomy of text normalization errors and apply it to results from GPT-3.5-Turbo and GPT-4.0. Through this new framework, we can identify strengths and weaknesses of GPT-based TN, opening opportunities for future work.",
    "link": "http://arxiv.org/abs/2309.13426",
    "context": "Title: A Chat About Boring Problems: Studying GPT-based text normalization. (arXiv:2309.13426v2 [cs.CL] UPDATED)\nAbstract: Text normalization - the conversion of text from written to spoken form - is traditionally assumed to be an ill-formed task for language models. In this work, we argue otherwise. We empirically show the capacity of Large-Language Models (LLM) for text normalization in few-shot scenarios. Combining self-consistency reasoning with linguistic-informed prompt engineering, we find LLM based text normalization to achieve error rates around 40\\% lower than top normalization systems. Further, upon error analysis, we note key limitations in the conventional design of text normalization tasks. We create a new taxonomy of text normalization errors and apply it to results from GPT-3.5-Turbo and GPT-4.0. Through this new framework, we can identify strengths and weaknesses of GPT-based TN, opening opportunities for future work.",
    "path": "papers/23/09/2309.13426.json",
    "total_tokens": 965,
    "translated_title": "闲谈令人无聊的问题：研究基于GPT的文本规范化",
    "translated_abstract": "文本规范化-将文本从书面形式转化为口语形式-通常被认为是语言模型面临的一个不完善的任务。在这项工作中，我们提出了与之相反的观点。我们通过实证研究了大型语言模型（LLM）在少样本情境下进行文本规范化的能力。通过结合自洽推理和基于语言知识的提示工程，我们发现基于LLM的文本规范化的错误率比顶级规范化系统低约40％。进一步的错误分析中，我们注意到传统的文本规范化任务设计的关键限制。我们创建了一个新的文本规范化错误分类，并将其应用于GPT-3.5-Turbo和GPT-4.0的结果中。通过这个新的框架，我们可以识别出基于GPT的文本规范化的优势和局限性，从而为未来的工作提供了机会。",
    "tldr": "本文研究了基于GPT的文本规范化任务。通过结合自洽推理和基于语言知识的提示工程，我们发现基于LLM的文本规范化的错误率比顶级规范化系统低约40％。同时，通过对错误分析，我们发现传统的文本规范化任务设计存在关键限制。我们创建了一个新的框架以识别基于GPT的文本规范化的优势和局限性。这为未来的工作提供了机会。",
    "en_tdlr": "This paper studies GPT-based text normalization and discovers that by combining self-consistency reasoning and linguistic-informed prompt engineering, it achieves error rates around 40% lower than top normalization systems. The paper also identifies key limitations in the conventional design of text normalization tasks and proposes a new framework to analyze the strengths and weaknesses of GPT-based text normalization, providing opportunities for future work."
}