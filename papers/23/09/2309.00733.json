{
    "title": "Learned Visual Features to Textual Explanations. (arXiv:2309.00733v2 [cs.CV] UPDATED)",
    "abstract": "Interpreting the learned features of vision models has posed a longstanding challenge in the field of machine learning. To address this issue, we propose a novel method that leverages the capabilities of large language models (LLMs) to interpret the learned features of pre-trained image classifiers. Our method, called TExplain, tackles this task by training a neural network to establish a connection between the feature space of image classifiers and LLMs. Then, during inference, our approach generates a vast number of sentences to explain the features learned by the classifier for a given image. These sentences are then used to extract the most frequent words, providing a comprehensive understanding of the learned features and patterns within the classifier. Our method, for the first time, utilizes these frequent words corresponding to a visual representation to provide insights into the decision-making process of the independently trained classifier, enabling the detection of spurious",
    "link": "http://arxiv.org/abs/2309.00733",
    "context": "Title: Learned Visual Features to Textual Explanations. (arXiv:2309.00733v2 [cs.CV] UPDATED)\nAbstract: Interpreting the learned features of vision models has posed a longstanding challenge in the field of machine learning. To address this issue, we propose a novel method that leverages the capabilities of large language models (LLMs) to interpret the learned features of pre-trained image classifiers. Our method, called TExplain, tackles this task by training a neural network to establish a connection between the feature space of image classifiers and LLMs. Then, during inference, our approach generates a vast number of sentences to explain the features learned by the classifier for a given image. These sentences are then used to extract the most frequent words, providing a comprehensive understanding of the learned features and patterns within the classifier. Our method, for the first time, utilizes these frequent words corresponding to a visual representation to provide insights into the decision-making process of the independently trained classifier, enabling the detection of spurious",
    "path": "papers/23/09/2309.00733.json",
    "total_tokens": 918,
    "translated_title": "学习的视觉特征到文本解释",
    "translated_abstract": "在机器学习领域，解释视觉模型学习到的特征一直是一个长期存在的挑战。为了解决这个问题，我们提出了一种新颖的方法，利用大型语言模型（LLMs）的能力来解释预训练图像分类器学习到的特征。我们的方法名为TExplain，通过训练一个神经网络在图像分类器的特征空间和LLMs之间建立连接来解决这个任务。然后，在推断过程中，我们的方法生成大量的句子来解释分类器对给定图像学习到的特征。这些句子然后用于提取最频繁的单词，从而全面理解分类器中学习到的特征和模式。我们的方法首次利用与视觉表示对应的这些频繁单词来揭示独立训练的分类器的决策过程，从而实现检测虚假特征的能力。",
    "tldr": "本研究提出了一种名为TExplain的方法，将大型语言模型与预训练图像分类器的特征空间连接起来，通过生成解释性句子来理解分类器学习到的特征。该方法首次利用这些频繁单词揭示出分类器的决策过程，实现了检测虚假特征的能力。",
    "en_tdlr": "A novel method called TExplain is proposed in this study, which connects large language models (LLMs) with the feature space of pre-trained image classifiers to generate explanatory sentences for understanding the learned features. This method utilizes frequent words to reveal the decision-making process of the classifier, enabling the detection of spurious features."
}