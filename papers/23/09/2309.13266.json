{
    "title": "Robust Navigation with Cross-Modal Fusion and Knowledge Transfer. (arXiv:2309.13266v1 [cs.RO])",
    "abstract": "Recently, learning-based approaches show promising results in navigation tasks. However, the poor generalization capability and the simulation-reality gap prevent a wide range of applications. We consider the problem of improving the generalization of mobile robots and achieving sim-to-real transfer for navigation skills. To that end, we propose a cross-modal fusion method and a knowledge transfer framework for better generalization. This is realized by a teacher-student distillation architecture. The teacher learns a discriminative representation and the near-perfect policy in an ideal environment. By imitating the behavior and representation of the teacher, the student is able to align the features from noisy multi-modal input and reduce the influence of variations on navigation policy. We evaluate our method in simulated and real-world environments. Experiments show that our method outperforms the baselines by a large margin and achieves robust navigation performance with varying wo",
    "link": "http://arxiv.org/abs/2309.13266",
    "context": "Title: Robust Navigation with Cross-Modal Fusion and Knowledge Transfer. (arXiv:2309.13266v1 [cs.RO])\nAbstract: Recently, learning-based approaches show promising results in navigation tasks. However, the poor generalization capability and the simulation-reality gap prevent a wide range of applications. We consider the problem of improving the generalization of mobile robots and achieving sim-to-real transfer for navigation skills. To that end, we propose a cross-modal fusion method and a knowledge transfer framework for better generalization. This is realized by a teacher-student distillation architecture. The teacher learns a discriminative representation and the near-perfect policy in an ideal environment. By imitating the behavior and representation of the teacher, the student is able to align the features from noisy multi-modal input and reduce the influence of variations on navigation policy. We evaluate our method in simulated and real-world environments. Experiments show that our method outperforms the baselines by a large margin and achieves robust navigation performance with varying wo",
    "path": "papers/23/09/2309.13266.json",
    "total_tokens": 882,
    "translated_title": "基于跨模态融合和知识迁移的鲁棒导航",
    "translated_abstract": "最近，基于学习的方法在导航任务中显示出了很好的结果。然而，差强人意的泛化能力和模拟-现实差距限制了广泛的应用。我们考虑提高移动机器人的泛化能力并实现导航技能的模拟到实际转移的问题。为此，我们提出了一种跨模态融合方法和一个知识迁移框架来提高泛化能力。这通过一个师生蒸馏架构实现。老师在一个理想的环境中学习一个有区分性的表示和近乎完美的策略。通过模仿老师的行为和表示，学生能够对来自嘈杂的多模态输入对齐特征，并减少变化对导航策略的影响。我们在模拟和现实环境中评估了我们的方法。实验表明，我们的方法相比基准线表现出了很大的优势，并实现了鲁棒的导航性能。",
    "tldr": "本文提出了一种跨模态融合方法和知识迁移框架，通过师生蒸馏架构实现。在实验中表现出了优于基准线的鲁棒导航性能。",
    "en_tdlr": "This paper proposes a method of cross-modal fusion and a knowledge transfer framework using a teacher-student distillation architecture. Experimental results show that the method achieves robust navigation performance that outperforms the baselines."
}