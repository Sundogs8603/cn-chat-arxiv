{
    "title": "Communication Efficient Private Federated Learning Using Dithering. (arXiv:2309.07809v1 [cs.LG])",
    "abstract": "The task of preserving privacy while ensuring efficient communication is a fundamental challenge in federated learning. In this work, we tackle this challenge in the trusted aggregator model, and propose a solution that achieves both objectives simultaneously. We show that employing a quantization scheme based on subtractive dithering at the clients can effectively replicate the normal noise addition process at the aggregator. This implies that we can guarantee the same level of differential privacy against other clients while substantially reducing the amount of communication required, as opposed to transmitting full precision gradients and using central noise addition. We also experimentally demonstrate that the accuracy of our proposed approach matches that of the full precision gradient method.",
    "link": "http://arxiv.org/abs/2309.07809",
    "context": "Title: Communication Efficient Private Federated Learning Using Dithering. (arXiv:2309.07809v1 [cs.LG])\nAbstract: The task of preserving privacy while ensuring efficient communication is a fundamental challenge in federated learning. In this work, we tackle this challenge in the trusted aggregator model, and propose a solution that achieves both objectives simultaneously. We show that employing a quantization scheme based on subtractive dithering at the clients can effectively replicate the normal noise addition process at the aggregator. This implies that we can guarantee the same level of differential privacy against other clients while substantially reducing the amount of communication required, as opposed to transmitting full precision gradients and using central noise addition. We also experimentally demonstrate that the accuracy of our proposed approach matches that of the full precision gradient method.",
    "path": "papers/23/09/2309.07809.json",
    "total_tokens": 810,
    "translated_title": "使用抖动实现高效通信的隐私联邦学习",
    "translated_abstract": "在联邦学习中，保护隐私和确保高效通信是一个基本挑战。本文在可信的聚合器模型中解决了这一挑战，并提出了一种实现同时达到两个目标的解决方案。我们展示了在客户端使用基于减法抖动的量化方案可以有效地复制聚合器中的正常噪声添加过程。这意味着我们可以在与其他客户端相比保证相同水平的差分隐私的同时，大大减少所需的通信量，而不是传输完整精度的梯度并使用中心噪声添加。我们还通过实验证明，我们提出的方法的准确性与完整精度梯度方法相匹配。",
    "tldr": "本文提出了一种使用抖动实现高效通信的隐私联邦学习方法，通过在客户端使用减法抖动的量化方案，可以复制正常噪声添加过程，实现与完整精度梯度方法相当的准确性，并大幅减少所需通信量。"
}