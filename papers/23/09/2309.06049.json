{
    "title": "A Perceptron-based Fine Approximation Technique for Linear Separation. (arXiv:2309.06049v1 [cs.LG])",
    "abstract": "This paper presents a novel online learning method that aims at finding a separator hyperplane between data points labelled as either positive or negative. Since weights and biases of artificial neurons can directly be related to hyperplanes in high-dimensional spaces, the technique is applicable to train perceptron-based binary classifiers in machine learning. In case of large or imbalanced data sets, use of analytical or gradient-based solutions can become prohibitive and impractical, where heuristics and approximation techniques are still applicable. The proposed method is based on the Perceptron algorithm, however, it tunes neuron weights in just the necessary extent during searching the separator hyperplane. Due to an appropriate transformation of the initial data set we need not to consider data labels, neither the bias term. respectively, reducing separability to a one-class classification problem. The presented method has proven converge; empirical results show that it can be m",
    "link": "http://arxiv.org/abs/2309.06049",
    "context": "Title: A Perceptron-based Fine Approximation Technique for Linear Separation. (arXiv:2309.06049v1 [cs.LG])\nAbstract: This paper presents a novel online learning method that aims at finding a separator hyperplane between data points labelled as either positive or negative. Since weights and biases of artificial neurons can directly be related to hyperplanes in high-dimensional spaces, the technique is applicable to train perceptron-based binary classifiers in machine learning. In case of large or imbalanced data sets, use of analytical or gradient-based solutions can become prohibitive and impractical, where heuristics and approximation techniques are still applicable. The proposed method is based on the Perceptron algorithm, however, it tunes neuron weights in just the necessary extent during searching the separator hyperplane. Due to an appropriate transformation of the initial data set we need not to consider data labels, neither the bias term. respectively, reducing separability to a one-class classification problem. The presented method has proven converge; empirical results show that it can be m",
    "path": "papers/23/09/2309.06049.json",
    "total_tokens": 889,
    "translated_title": "一种基于感知机的线性分离精细逼近技术",
    "translated_abstract": "本文提出了一种新颖的在线学习方法，旨在找到标记为正或负的数据点之间的分离超平面。由于人工神经元的权重和偏置可以直接与高维空间中的超平面相关联，所以该技术适用于机器学习中训练基于感知机的二分类器。在大型或不平衡的数据集情况下，使用解析或基于梯度的解决方案可能变得禁止和不实际，而启发式和近似技术仍然适用。所提出的方法基于感知机算法，但在搜索分离超平面期间只调整神经元权重的必要程度。通过适当转换初始数据集，我们不需要考虑数据标签，也不需要考虑偏置项，将可分性降低为一类分类问题。该方法已被证明收敛；实证结果表明，它可以m",
    "tldr": "本文提出了一种基于感知机的在线学习方法，通过精细调整神经元权重来找到数据点之间的分离超平面，从而降低了大型或不平衡数据集的计算复杂性。该方法通过适当转换初始数据集来将分离问题转化为一类分类问题。"
}