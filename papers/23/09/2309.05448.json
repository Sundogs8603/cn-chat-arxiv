{
    "title": "Panoptic Vision-Language Feature Fields. (arXiv:2309.05448v2 [cs.CV] UPDATED)",
    "abstract": "Recently, methods have been proposed for 3D open-vocabulary semantic segmentation. Such methods are able to segment scenes into arbitrary classes based on text descriptions provided during runtime. In this paper, we propose to the best of our knowledge the first algorithm for open-vocabulary panoptic segmentation in 3D scenes. Our algorithm, Panoptic Vision-Language Feature Fields (PVLFF), learns a semantic feature field of the scene by distilling vision-language features from a pretrained 2D model, and jointly fits an instance feature field through contrastive learning using 2D instance segments on input frames. Despite not being trained on the target classes, our method achieves panoptic segmentation performance similar to the state-of-the-art closed-set 3D systems on the HyperSim, ScanNet and Replica dataset and additionally outperforms current 3D open-vocabulary systems in terms of semantic segmentation. We ablate the components of our method to demonstrate the effectiveness of our",
    "link": "http://arxiv.org/abs/2309.05448",
    "context": "Title: Panoptic Vision-Language Feature Fields. (arXiv:2309.05448v2 [cs.CV] UPDATED)\nAbstract: Recently, methods have been proposed for 3D open-vocabulary semantic segmentation. Such methods are able to segment scenes into arbitrary classes based on text descriptions provided during runtime. In this paper, we propose to the best of our knowledge the first algorithm for open-vocabulary panoptic segmentation in 3D scenes. Our algorithm, Panoptic Vision-Language Feature Fields (PVLFF), learns a semantic feature field of the scene by distilling vision-language features from a pretrained 2D model, and jointly fits an instance feature field through contrastive learning using 2D instance segments on input frames. Despite not being trained on the target classes, our method achieves panoptic segmentation performance similar to the state-of-the-art closed-set 3D systems on the HyperSim, ScanNet and Replica dataset and additionally outperforms current 3D open-vocabulary systems in terms of semantic segmentation. We ablate the components of our method to demonstrate the effectiveness of our",
    "path": "papers/23/09/2309.05448.json",
    "total_tokens": 926,
    "translated_title": "全景视觉-语言特征场",
    "translated_abstract": "最近，出现了一些用于3D开放词汇语义分割的方法。这些方法能够根据运行时提供的文本描述将场景分割成任意类别。在本文中，我们提出了迄今为止首个用于3D场景中开放词汇全景分割的算法。我们的算法Panoptic Vision-Language Feature Fields (PVLFF)通过从预训练的2D模型中提取视觉-语言特征来学习场景的语义特征场，并通过在输入帧上使用2D实例分割实现对实例特征场的联合拟合。尽管没有针对目标类别进行训练，我们的方法在HyperSim、ScanNet和Replica数据集上实现了与最先进的闭集3D系统相似的全景分割性能，并且在语义分割方面优于当前的3D开放词汇系统。我们对我们方法的组成部分进行了实验来证明其有效性。",
    "tldr": "本文提出了一种用于3D场景中开放词汇全景分割的算法PVLFF，通过从预训练的2D模型中提取视觉-语言特征来学习语义特征场，通过对输入帧上的2D实例分割进行对比学习来联合拟合实例特征场。该方法在全景分割和语义分割方面具有良好的性能。",
    "en_tdlr": "This paper proposes an algorithm, PVLFF, for open-vocabulary panoptic segmentation in 3D scenes. It learns a semantic feature field by distilling vision-language features, and fits an instance feature field through contrastive learning. The method achieves good performance in both panoptic segmentation and semantic segmentation."
}