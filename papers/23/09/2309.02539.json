{
    "title": "A Generalized Bandsplit Neural Network for Cinematic Audio Source Separation. (arXiv:2309.02539v1 [eess.AS])",
    "abstract": "Cinematic audio source separation is a relatively new subtask of audio source separation, with the aim of extracting the dialogue stem, the music stem, and the effects stem from their mixture. In this work, we developed a model generalizing the Bandsplit RNN for any complete or overcomplete partitions of the frequency axis. Psycho-acoustically motivated frequency scales were used to inform the band definitions which are now defined with redundancy for more reliable feature extraction. A loss function motivated by the signal-to-noise ratio and the sparsity-promoting property of the 1-norm was proposed. We additionally exploit the information-sharing property of a common-encoder setup to reduce computational complexity during both training and inference, improve separation performance for hard-to-generalize classes of sounds, and allow flexibility during inference time with easily detachable decoders. Our best model sets the state of the art on the Divide and Remaster dataset with perfor",
    "link": "http://arxiv.org/abs/2309.02539",
    "context": "Title: A Generalized Bandsplit Neural Network for Cinematic Audio Source Separation. (arXiv:2309.02539v1 [eess.AS])\nAbstract: Cinematic audio source separation is a relatively new subtask of audio source separation, with the aim of extracting the dialogue stem, the music stem, and the effects stem from their mixture. In this work, we developed a model generalizing the Bandsplit RNN for any complete or overcomplete partitions of the frequency axis. Psycho-acoustically motivated frequency scales were used to inform the band definitions which are now defined with redundancy for more reliable feature extraction. A loss function motivated by the signal-to-noise ratio and the sparsity-promoting property of the 1-norm was proposed. We additionally exploit the information-sharing property of a common-encoder setup to reduce computational complexity during both training and inference, improve separation performance for hard-to-generalize classes of sounds, and allow flexibility during inference time with easily detachable decoders. Our best model sets the state of the art on the Divide and Remaster dataset with perfor",
    "path": "papers/23/09/2309.02539.json",
    "total_tokens": 872,
    "translated_title": "一种用于电影音频源分离的通用带通神经网络",
    "translated_abstract": "电影音频源分离是音频源分离的一个相对较新的子任务，其目标是从混音中提取对话音轨、音乐音轨和特效音轨。在这项工作中，我们开发了一个模型，可以对频率轴的任何完全或过完备的分区进行泛化。基于心理声学的频率尺度用于确定带通的定义，现在具备冗余性以进行更可靠的特征提取。我们提出了一个损失函数，该损失函数基于信噪比和1-范数的稀疏促进属性。我们还利用共同编码器结构的信息共享特性，在训练和推断过程中减少计算复杂性，改善难以泛化的声音类别的分离性能，并在推断时提供灵活性，可轻松分离解码器。我们的最佳模型在Divide and Remaster数据集上取得了最先进的性能。",
    "tldr": "本论文提出了一种通用带通神经网络用于电影音频源分离，通过使用心理声学的频率尺度来定义频带并且利用共同编码器结构的信息共享特性提高了分离性能。"
}