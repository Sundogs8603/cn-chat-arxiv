{
    "title": "Towards Better Multi-modal Keyphrase Generation via Visual Entity Enhancement and Multi-granularity Image Noise Filtering. (arXiv:2309.04734v1 [cs.CV])",
    "abstract": "Multi-modal keyphrase generation aims to produce a set of keyphrases that represent the core points of the input text-image pair. In this regard, dominant methods mainly focus on multi-modal fusion for keyphrase generation. Nevertheless, there are still two main drawbacks: 1) only a limited number of sources, such as image captions, can be utilized to provide auxiliary information. However, they may not be sufficient for the subsequent keyphrase generation. 2) the input text and image are often not perfectly matched, and thus the image may introduce noise into the model. To address these limitations, in this paper, we propose a novel multi-modal keyphrase generation model, which not only enriches the model input with external knowledge, but also effectively filters image noise. First, we introduce external visual entities of the image as the supplementary input to the model, which benefits the cross-modal semantic alignment for keyphrase generation. Second, we simultaneously calculate ",
    "link": "http://arxiv.org/abs/2309.04734",
    "context": "Title: Towards Better Multi-modal Keyphrase Generation via Visual Entity Enhancement and Multi-granularity Image Noise Filtering. (arXiv:2309.04734v1 [cs.CV])\nAbstract: Multi-modal keyphrase generation aims to produce a set of keyphrases that represent the core points of the input text-image pair. In this regard, dominant methods mainly focus on multi-modal fusion for keyphrase generation. Nevertheless, there are still two main drawbacks: 1) only a limited number of sources, such as image captions, can be utilized to provide auxiliary information. However, they may not be sufficient for the subsequent keyphrase generation. 2) the input text and image are often not perfectly matched, and thus the image may introduce noise into the model. To address these limitations, in this paper, we propose a novel multi-modal keyphrase generation model, which not only enriches the model input with external knowledge, but also effectively filters image noise. First, we introduce external visual entities of the image as the supplementary input to the model, which benefits the cross-modal semantic alignment for keyphrase generation. Second, we simultaneously calculate ",
    "path": "papers/23/09/2309.04734.json",
    "total_tokens": 837,
    "translated_title": "通过增强视觉实体和多尺度图像噪声滤波，实现更好的多模态关键词生成",
    "translated_abstract": "多模态关键词生成旨在生成一组能够代表输入文本-图像对核心要点的关键词。然而，目前的方法存在两个主要缺点：1）只能使用有限的信息源（如图像标题）提供辅助信息，但这些信息可能无法满足后续关键词生成的需要。2）输入的文本和图像通常不能完全匹配，图像可能会引入噪声。为解决这些问题，本文提出了一种新型的多模态关键词生成模型，它不仅通过外部知识丰富了模型输入，还能有效过滤图像噪声。首先，我们将图像的外部视觉实体作为模型的补充输入，有助于跨模态语义对齐进行关键词生成。其次，我们同时计算...",
    "tldr": "本文提出了一种新的多模态关键词生成模型，通过引入外部视觉实体作为模型输入并使用图像噪声滤波技术，实现了更好的关键词生成效果。",
    "en_tdlr": "This paper proposes a novel multi-modal keyphrase generation model that improves the generation process by introducing external visual entities as input and utilizing image noise filtering techniques."
}