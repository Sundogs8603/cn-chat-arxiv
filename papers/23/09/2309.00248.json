{
    "title": "DiffuGen: Adaptable Approach for Generating Labeled Image Datasets using Stable Diffusion Models. (arXiv:2309.00248v1 [cs.CV])",
    "abstract": "Generating high-quality labeled image datasets is crucial for training accurate and robust machine learning models in the field of computer vision. However, the process of manually labeling real images is often time-consuming and costly. To address these challenges associated with dataset generation, we introduce \"DiffuGen,\" a simple and adaptable approach that harnesses the power of stable diffusion models to create labeled image datasets efficiently. By leveraging stable diffusion models, our approach not only ensures the quality of generated datasets but also provides a versatile solution for label generation. In this paper, we present the methodology behind DiffuGen, which combines the capabilities of diffusion models with two distinct labeling techniques: unsupervised and supervised. Distinctively, DiffuGen employs prompt templating for adaptable image generation and textual inversion to enhance diffusion model capabilities.",
    "link": "http://arxiv.org/abs/2309.00248",
    "context": "Title: DiffuGen: Adaptable Approach for Generating Labeled Image Datasets using Stable Diffusion Models. (arXiv:2309.00248v1 [cs.CV])\nAbstract: Generating high-quality labeled image datasets is crucial for training accurate and robust machine learning models in the field of computer vision. However, the process of manually labeling real images is often time-consuming and costly. To address these challenges associated with dataset generation, we introduce \"DiffuGen,\" a simple and adaptable approach that harnesses the power of stable diffusion models to create labeled image datasets efficiently. By leveraging stable diffusion models, our approach not only ensures the quality of generated datasets but also provides a versatile solution for label generation. In this paper, we present the methodology behind DiffuGen, which combines the capabilities of diffusion models with two distinct labeling techniques: unsupervised and supervised. Distinctively, DiffuGen employs prompt templating for adaptable image generation and textual inversion to enhance diffusion model capabilities.",
    "path": "papers/23/09/2309.00248.json",
    "total_tokens": 854,
    "translated_title": "DiffuGen：使用稳定扩散模型生成标记图像数据集的可适应方法",
    "translated_abstract": "在计算机视觉领域，生成高质量的标记图像数据集对于训练准确且鲁棒的机器学习模型至关重要。然而，手动标注真实图像的过程往往耗时且昂贵。为了解决与数据集生成相关的挑战，我们提出了“DiffuGen”，这是一种简单且可适应的方法，利用稳定扩散模型高效地创建带标记的图像数据集。通过利用稳定扩散模型，我们的方法不仅确保了生成数据集的质量，还为标签生成提供了多功能解决方案。本文介绍了DiffuGen的方法论，将扩散模型的能力与两种不同的标注技术：无监督和监督相结合。独特之处在于，DiffuGen采用了适应性图像生成的提示模板和文本反演以增强扩散模型的能力。",
    "tldr": "DiffuGen是一种利用稳定扩散模型高效生成标记图像数据集的简单而可适应的方法，并结合无监督和监督标注技术，以确保生成数据集的质量和提供多功能解决方案。",
    "en_tdlr": "DiffuGen is a simple and adaptable approach that uses stable diffusion models to efficiently generate labeled image datasets. It combines unsupervised and supervised labeling techniques to ensure dataset quality and provide a versatile solution."
}