{
    "title": "Leveraging Negative Signals with Self-Attention for Sequential Music Recommendation. (arXiv:2309.11623v1 [cs.IR])",
    "abstract": "Music streaming services heavily rely on their recommendation engines to continuously provide content to their consumers. Sequential recommendation consequently has seen considerable attention in current literature, where state of the art approaches focus on self-attentive models leveraging contextual information such as long and short-term user history and item features; however, most of these studies focus on long-form content domains (retail, movie, etc.) rather than short-form, such as music. Additionally, many do not explore incorporating negative session-level feedback during training. In this study, we investigate the use of transformer-based self-attentive architectures to learn implicit session-level information for sequential music recommendation. We additionally propose a contrastive learning task to incorporate negative feedback (e.g skipped tracks) to promote positive hits and penalize negative hits. This task is formulated as a simple loss term that can be incorporated in",
    "link": "http://arxiv.org/abs/2309.11623",
    "context": "Title: Leveraging Negative Signals with Self-Attention for Sequential Music Recommendation. (arXiv:2309.11623v1 [cs.IR])\nAbstract: Music streaming services heavily rely on their recommendation engines to continuously provide content to their consumers. Sequential recommendation consequently has seen considerable attention in current literature, where state of the art approaches focus on self-attentive models leveraging contextual information such as long and short-term user history and item features; however, most of these studies focus on long-form content domains (retail, movie, etc.) rather than short-form, such as music. Additionally, many do not explore incorporating negative session-level feedback during training. In this study, we investigate the use of transformer-based self-attentive architectures to learn implicit session-level information for sequential music recommendation. We additionally propose a contrastive learning task to incorporate negative feedback (e.g skipped tracks) to promote positive hits and penalize negative hits. This task is formulated as a simple loss term that can be incorporated in",
    "path": "papers/23/09/2309.11623.json",
    "total_tokens": 876,
    "translated_title": "利用自注意力机制对连续音乐推荐进行负面信号的利用",
    "translated_abstract": "音乐流媒体服务仰赖其推荐引擎连续向用户提供内容。因此，顺序推荐已经引起了当前文献的相当关注，而当今最先进的方法主要集中在利用上下文信息（如长期和短期用户历史和项目特征）的自我关注模型上；然而，大多数研究集中在长格式内容领域（零售、电影等）而不是短格式，例如音乐。此外，许多研究未探索在训练过程中如何融入负面会话级反馈。在本研究中，我们研究了基于Transformer的自我关注体系结构，以学习用于顺序音乐推荐的隐式会话级信息。此外，我们还提出了一种对比学习任务，以融入负面反馈（例如跳过的曲目）以促进正面命中并惩罚负面命中。这个任务被形式化为一个简单的损失项，可以加入到训练中。",
    "tldr": "本研究利用自我注意力机制和负面反馈，提出了用于顺序音乐推荐的Transformer模型，并采用对比学习任务来提高推荐准确性。",
    "en_tdlr": "This study leverages self-attention and negative feedback to propose a Transformer model for sequential music recommendation and incorporates a contrastive learning task to improve recommendation accuracy."
}