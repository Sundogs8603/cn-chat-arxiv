{
    "title": "Order-preserving Consistency Regularization for Domain Adaptation and Generalization. (arXiv:2309.13258v1 [cs.CV])",
    "abstract": "Deep learning models fail on cross-domain challenges if the model is oversensitive to domain-specific attributes, e.g., lightning, background, camera angle, etc. To alleviate this problem, data augmentation coupled with consistency regularization are commonly adopted to make the model less sensitive to domain-specific attributes. Consistency regularization enforces the model to output the same representation or prediction for two views of one image. These constraints, however, are either too strict or not order-preserving for the classification probabilities. In this work, we propose the Order-preserving Consistency Regularization (OCR) for cross-domain tasks. The order-preserving property for the prediction makes the model robust to task-irrelevant transformations. As a result, the model becomes less sensitive to the domain-specific attributes. The comprehensive experiments show that our method achieves clear advantages on five different cross-domain tasks.",
    "link": "http://arxiv.org/abs/2309.13258",
    "context": "Title: Order-preserving Consistency Regularization for Domain Adaptation and Generalization. (arXiv:2309.13258v1 [cs.CV])\nAbstract: Deep learning models fail on cross-domain challenges if the model is oversensitive to domain-specific attributes, e.g., lightning, background, camera angle, etc. To alleviate this problem, data augmentation coupled with consistency regularization are commonly adopted to make the model less sensitive to domain-specific attributes. Consistency regularization enforces the model to output the same representation or prediction for two views of one image. These constraints, however, are either too strict or not order-preserving for the classification probabilities. In this work, we propose the Order-preserving Consistency Regularization (OCR) for cross-domain tasks. The order-preserving property for the prediction makes the model robust to task-irrelevant transformations. As a result, the model becomes less sensitive to the domain-specific attributes. The comprehensive experiments show that our method achieves clear advantages on five different cross-domain tasks.",
    "path": "papers/23/09/2309.13258.json",
    "total_tokens": 880,
    "translated_title": "跨领域适应和泛化的有序一致性正则化",
    "translated_abstract": "如果深度学习模型对特定领域的属性（如光线、背景、相机角度等）过于敏感，那么在跨领域挑战中，深度学习模型会失败。为了解决这个问题，通常采用数据增强和一致性正则化的方法，使模型对特定领域的属性不那么敏感。一致性正则化强制模型对同一图像的两个视角输出相同的表示或预测。然而，这些约束对于分类概率来说要么过于严格，要么不具有有序性。在这项工作中，我们提出了适用于跨领域任务的有序一致性正则化（OCR）。预测的有序性使模型对于任务无关的变换具有鲁棒性。结果，模型对特定领域的属性不那么敏感。综合实验表明，我们的方法在五个不同的跨领域任务上具有明显的优势。",
    "tldr": "提出了一种适用于跨领域任务的有序一致性正则化（OCR），通过保持预测的有序性，使模型对于特定领域的属性具有鲁棒性，并在多个跨领域任务上取得了明显的优势。"
}