{
    "title": "KD-FixMatch: Knowledge Distillation Siamese Neural Networks. (arXiv:2309.05826v1 [cs.LG])",
    "abstract": "Semi-supervised learning (SSL) has become a crucial approach in deep learning as a way to address the challenge of limited labeled data. The success of deep neural networks heavily relies on the availability of large-scale high-quality labeled data. However, the process of data labeling is time-consuming and unscalable, leading to shortages in labeled data. SSL aims to tackle this problem by leveraging additional unlabeled data in the training process. One of the popular SSL algorithms, FixMatch, trains identical weight-sharing teacher and student networks simultaneously using a siamese neural network (SNN). However, it is prone to performance degradation when the pseudo labels are heavily noisy in the early training stage. We present KD-FixMatch, a novel SSL algorithm that addresses the limitations of FixMatch by incorporating knowledge distillation. The algorithm utilizes a combination of sequential and simultaneous training of SNNs to enhance performance and reduce performance degra",
    "link": "http://arxiv.org/abs/2309.05826",
    "context": "Title: KD-FixMatch: Knowledge Distillation Siamese Neural Networks. (arXiv:2309.05826v1 [cs.LG])\nAbstract: Semi-supervised learning (SSL) has become a crucial approach in deep learning as a way to address the challenge of limited labeled data. The success of deep neural networks heavily relies on the availability of large-scale high-quality labeled data. However, the process of data labeling is time-consuming and unscalable, leading to shortages in labeled data. SSL aims to tackle this problem by leveraging additional unlabeled data in the training process. One of the popular SSL algorithms, FixMatch, trains identical weight-sharing teacher and student networks simultaneously using a siamese neural network (SNN). However, it is prone to performance degradation when the pseudo labels are heavily noisy in the early training stage. We present KD-FixMatch, a novel SSL algorithm that addresses the limitations of FixMatch by incorporating knowledge distillation. The algorithm utilizes a combination of sequential and simultaneous training of SNNs to enhance performance and reduce performance degra",
    "path": "papers/23/09/2309.05826.json",
    "total_tokens": 872,
    "translated_title": "KD-FixMatch: 知识蒸馏的孪生神经网络",
    "translated_abstract": "半监督学习（SSL）作为解决有限标注数据挑战的一种方法，在深度学习中变得至关重要。深度神经网络的成功严重依赖于大规模高质量标注数据的可用性。然而，数据标注的过程耗时且不可扩展，导致标注数据不足。SSL旨在通过利用额外的未标注数据来解决这个问题。FixMatch是一种流行的SSL算法，通过使用孪生神经网络（SNN）同时训练相同权重共享的教师和学生网络。然而，在早期训练阶段，如果伪标签存在较大噪声，该算法容易导致性能下降。我们提出了KD-FixMatch，一种新颖的SSL算法，通过引入知识蒸馏来解决FixMatch的局限性。该算法利用顺序和并行训练SNNs的组合来提高性能并降低性能下降。",
    "tldr": "KD-FixMatch是一种半监督学习算法，在FixMatch的基础上引入了知识蒸馏，通过顺序和并行训练SNNs的组合来提高性能并降低性能下降。",
    "en_tdlr": "KD-FixMatch is a semi-supervised learning algorithm that incorporates knowledge distillation on top of FixMatch, enhancing performance and reducing performance degradation through a combination of sequential and simultaneous training of SNNs."
}