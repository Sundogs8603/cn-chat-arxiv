{
    "title": "Safe POMDP Online Planning via Shielding. (arXiv:2309.10216v1 [cs.AI])",
    "abstract": "Partially observable Markov decision processes (POMDPs) have been widely used in many robotic applications for sequential decision-making under uncertainty. POMDP online planning algorithms such as Partially Observable Monte-Carlo Planning (POMCP) can solve very large POMDPs with the goal of maximizing the expected return. But the resulting policies cannot provide safety guarantees that are imperative for real-world safety-critical tasks (e.g., autonomous driving). In this work, we consider safety requirements represented as almost-sure reach-avoid specifications (i.e., the probability to reach a set of goal states is one and the probability to reach a set of unsafe states is zero). We compute shields that restrict unsafe actions violating almost-sure reach-avoid specifications. We then integrate these shields into the POMCP algorithm for safe POMDP online planning. We propose four distinct shielding methods, differing in how the shields are computed and integrated, including factored ",
    "link": "http://arxiv.org/abs/2309.10216",
    "context": "Title: Safe POMDP Online Planning via Shielding. (arXiv:2309.10216v1 [cs.AI])\nAbstract: Partially observable Markov decision processes (POMDPs) have been widely used in many robotic applications for sequential decision-making under uncertainty. POMDP online planning algorithms such as Partially Observable Monte-Carlo Planning (POMCP) can solve very large POMDPs with the goal of maximizing the expected return. But the resulting policies cannot provide safety guarantees that are imperative for real-world safety-critical tasks (e.g., autonomous driving). In this work, we consider safety requirements represented as almost-sure reach-avoid specifications (i.e., the probability to reach a set of goal states is one and the probability to reach a set of unsafe states is zero). We compute shields that restrict unsafe actions violating almost-sure reach-avoid specifications. We then integrate these shields into the POMCP algorithm for safe POMDP online planning. We propose four distinct shielding methods, differing in how the shields are computed and integrated, including factored ",
    "path": "papers/23/09/2309.10216.json",
    "total_tokens": 839,
    "translated_title": "通过屏蔽实现安全的POMDP在线规划",
    "translated_abstract": "部分可观察的马尔可夫决策过程（POMDP）广泛应用于许多机器人应用中，用于在不确定性下进行序列决策。POMDP在线规划算法，如部分可观察的蒙特卡洛规划（POMCP），可以解决目标为最大化预期回报的大型POMDP。但是，由此产生的策略无法提供对于现实世界中安全关键任务（如自动驾驶）至关重要的安全保证。在本文中，我们考虑安全要求，将其表示为几乎一定的到达-避免规范（即，达到一组目标状态的概率为1，达到一组不安全状态的概率为0）。我们计算限制违反几乎一定到达-避免规范的不安全动作的屏蔽。然后，将这些屏蔽集成到POMCP算法中以实现安全的POMDP在线规划。我们提出了四种不同的屏蔽方法，根据屏蔽的计算和集成方式的不同，包括分解方式。",
    "tldr": "通过计算屏蔽动作来实现安全的POMDP在线规划。四种屏蔽方法。"
}