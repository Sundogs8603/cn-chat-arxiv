{
    "title": "Explaining Agent Behavior with Large Language Models. (arXiv:2309.10346v1 [cs.LG])",
    "abstract": "Intelligent agents such as robots are increasingly deployed in real-world, safety-critical settings. It is vital that these agents are able to explain the reasoning behind their decisions to human counterparts, however, their behavior is often produced by uninterpretable models such as deep neural networks. We propose an approach to generate natural language explanations for an agent's behavior based only on observations of states and actions, agnostic to the underlying model representation. We show how a compact representation of the agent's behavior can be learned and used to produce plausible explanations with minimal hallucination while affording user interaction with a pre-trained large language model. Through user studies and empirical experiments, we show that our approach generates explanations as helpful as those generated by a human domain expert while enabling beneficial interactions such as clarification and counterfactual queries.",
    "link": "http://arxiv.org/abs/2309.10346",
    "context": "Title: Explaining Agent Behavior with Large Language Models. (arXiv:2309.10346v1 [cs.LG])\nAbstract: Intelligent agents such as robots are increasingly deployed in real-world, safety-critical settings. It is vital that these agents are able to explain the reasoning behind their decisions to human counterparts, however, their behavior is often produced by uninterpretable models such as deep neural networks. We propose an approach to generate natural language explanations for an agent's behavior based only on observations of states and actions, agnostic to the underlying model representation. We show how a compact representation of the agent's behavior can be learned and used to produce plausible explanations with minimal hallucination while affording user interaction with a pre-trained large language model. Through user studies and empirical experiments, we show that our approach generates explanations as helpful as those generated by a human domain expert while enabling beneficial interactions such as clarification and counterfactual queries.",
    "path": "papers/23/09/2309.10346.json",
    "total_tokens": 814,
    "translated_title": "使用大规模语言模型解释智能体行为",
    "translated_abstract": "智能体如机器人越来越多地被部署在真实世界中的安全关键环境中。重要的是，这些智能体能够向人类对等体解释他们决策背后的推理，然而，他们的行为通常是由不可解释的模型（如深度神经网络）产生的。我们提出了一种方法，基于状态和动作的观察，不考虑底层模型表示，生成智能体行为的自然语言解释。我们展示了如何学习智能体行为的简洁表示，并用其生成合理的解释，同时保证了与预训练的大规模语言模型的用户交互。通过用户研究和实证实验，我们证明了我们的方法生成的解释与人类领域专家生成的解释一样有用，同时具备有益的交互，如澄清和反事实查询。",
    "tldr": "使用大规模语言模型解释智能体行为的方法，通过学习智能体行为的紧凑表示，并与用户进行交互，能够生成合理的解释，具备与人类专家相似的帮助性。",
    "en_tdlr": "A method of explaining agent behavior using large language models, by learning a compact representation of the agent's behavior and enabling interactions with the user, can generate plausible explanations with similar helpfulness as human experts."
}