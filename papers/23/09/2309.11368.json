{
    "title": "Dynamic Hand Gesture-Featured Human Motor Adaptation in Tool Delivery using Voice Recognition. (arXiv:2309.11368v1 [cs.RO])",
    "abstract": "Human-robot collaboration has benefited users with higher efficiency towards interactive tasks. Nevertheless, most collaborative schemes rely on complicated human-machine interfaces, which might lack the requisite intuitiveness compared with natural limb control. We also expect to understand human intent with low training data requirements. In response to these challenges, this paper introduces an innovative human-robot collaborative framework that seamlessly integrates hand gesture and dynamic movement recognition, voice recognition, and a switchable control adaptation strategy. These modules provide a user-friendly approach that enables the robot to deliver the tools as per user need, especially when the user is working with both hands. Therefore, users can focus on their task execution without additional training in the use of human-machine interfaces, while the robot interprets their intuitive gestures. The proposed multimodal interaction framework is executed in the UR5e robot pla",
    "link": "http://arxiv.org/abs/2309.11368",
    "context": "Title: Dynamic Hand Gesture-Featured Human Motor Adaptation in Tool Delivery using Voice Recognition. (arXiv:2309.11368v1 [cs.RO])\nAbstract: Human-robot collaboration has benefited users with higher efficiency towards interactive tasks. Nevertheless, most collaborative schemes rely on complicated human-machine interfaces, which might lack the requisite intuitiveness compared with natural limb control. We also expect to understand human intent with low training data requirements. In response to these challenges, this paper introduces an innovative human-robot collaborative framework that seamlessly integrates hand gesture and dynamic movement recognition, voice recognition, and a switchable control adaptation strategy. These modules provide a user-friendly approach that enables the robot to deliver the tools as per user need, especially when the user is working with both hands. Therefore, users can focus on their task execution without additional training in the use of human-machine interfaces, while the robot interprets their intuitive gestures. The proposed multimodal interaction framework is executed in the UR5e robot pla",
    "path": "papers/23/09/2309.11368.json",
    "total_tokens": 836,
    "translated_title": "使用语音识别的动态手势特征的人体运动适应在工具传递中的应用",
    "translated_abstract": "人机协作有助于用户在交互任务中提高效率。然而，大多数协作方案依赖于复杂的人机接口，与自然肢体控制相比可能缺乏必要的直观性。我们希望通过低训练数据要求来理解人类意图。针对这些挑战，本文介绍了一种创新的人机协作框架，无缝集成了手势和动态运动识别、语音识别和可切换的控制适应策略。这些模块提供了一种用户友好的方法，使机器人能够根据用户需要传递工具，特别是当用户双手同时工作时。因此，用户可以专注于任务执行，而不需要额外培训人机界面的使用，同时机器人可以解读他们的直观手势。",
    "tldr": "本文介绍了一种使用语音识别的动态手势特征的人体运动适应方法，通过无缝集成多种模块来实现用户友好的工具传递，使用户无需额外培训以使用复杂的人机接口。",
    "en_tdlr": "This paper introduces an innovative approach that uses voice recognition and dynamic hand gesture features to adapt human motor movement, allowing for user-friendly tool delivery without the need for additional training in complex human-machine interfaces."
}