{
    "title": "Global-correlated 3D-decoupling Transformer for Clothed Avatar Reconstruction. (arXiv:2309.13524v2 [cs.CV] UPDATED)",
    "abstract": "Reconstructing 3D clothed human avatars from single images is a challenging task, especially when encountering complex poses and loose clothing. Current methods exhibit limitations in performance, largely attributable to their dependence on insufficient 2D image features and inconsistent query methods. Owing to this, we present the Global-correlated 3D-decoupling Transformer for clothed Avatar reconstruction (GTA), a novel transformer-based architecture that reconstructs clothed human avatars from monocular images. Our approach leverages transformer architectures by utilizing a Vision Transformer model as an encoder for capturing global-correlated image features. Subsequently, our innovative 3D-decoupling decoder employs cross-attention to decouple tri-plane features, using learnable embeddings as queries for cross-plane generation. To effectively enhance feature fusion with the tri-plane 3D feature and human body prior, we propose a hybrid prior fusion strategy combining spatial and p",
    "link": "http://arxiv.org/abs/2309.13524",
    "context": "Title: Global-correlated 3D-decoupling Transformer for Clothed Avatar Reconstruction. (arXiv:2309.13524v2 [cs.CV] UPDATED)\nAbstract: Reconstructing 3D clothed human avatars from single images is a challenging task, especially when encountering complex poses and loose clothing. Current methods exhibit limitations in performance, largely attributable to their dependence on insufficient 2D image features and inconsistent query methods. Owing to this, we present the Global-correlated 3D-decoupling Transformer for clothed Avatar reconstruction (GTA), a novel transformer-based architecture that reconstructs clothed human avatars from monocular images. Our approach leverages transformer architectures by utilizing a Vision Transformer model as an encoder for capturing global-correlated image features. Subsequently, our innovative 3D-decoupling decoder employs cross-attention to decouple tri-plane features, using learnable embeddings as queries for cross-plane generation. To effectively enhance feature fusion with the tri-plane 3D feature and human body prior, we propose a hybrid prior fusion strategy combining spatial and p",
    "path": "papers/23/09/2309.13524.json",
    "total_tokens": 943,
    "translated_title": "全球相关的三维解耦Transformer用于服装化身重建",
    "translated_abstract": "从单一图像中重建三维服装化身是一项具有挑战性的任务，特别是在遇到复杂姿势和宽松衣物时。现有方法在性能上存在局限性，这主要归因于它们对不足的二维图像特征和不一致的查询方法的依赖。基于此，我们提出了用于服装化身重建的全球相关的三维解耦Transformer（GTA），这是一种基于Transformer的创新体系结构，可以从单目图像中重建出具有衣服的人物化身。我们的方法利用Transformer体系结构，通过使用Vision Transformer模型作为编码器来捕捉全球相关的图像特征。随后，我们创新性地采用交叉注意力来解耦三位平面特征，并使用可学习的嵌入作为跨平面生成的查询。为了有效增强与三维特征和人体先验的特征融合，我们提出了一种融合空间和p的混合先验融合策略",
    "tldr": "这项研究提出了全球相关的三维解耦Transformer架构，用于从单目图像中重建具有衣服的人物化身。通过使用Transformer模型捕捉全局相关的图像特征，并采用创新的3D解耦解码器进行特征融合，实现了更好的重建效果。",
    "en_tdlr": "This paper introduces the Global-correlated 3D-decoupling Transformer architecture for reconstructing clothed human avatars from monocular images. By leveraging transformer models to capture global-correlated features and employing an innovative 3D-decoupling decoder for feature fusion, improved reconstruction results are achieved."
}