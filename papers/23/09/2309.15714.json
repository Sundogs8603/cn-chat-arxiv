{
    "title": "ChatGPT-BCI: Word-Level Neural State Classification Using GPT, EEG, and Eye-Tracking Biomarkers in Semantic Inference Reading Comprehension. (arXiv:2309.15714v1 [cs.CL])",
    "abstract": "With the recent explosion of large language models (LLMs), such as Generative Pretrained Transformers (GPT), the need to understand the ability of humans and machines to comprehend semantic language meaning has entered a new phase. This requires interdisciplinary research that bridges the fields of cognitive science and natural language processing (NLP). This pilot study aims to provide insights into individuals' neural states during a semantic relation reading-comprehension task. We propose jointly analyzing LLMs, eye-gaze, and electroencephalographic (EEG) data to study how the brain processes words with varying degrees of relevance to a keyword during reading. We also use a feature engineering approach to improve the fixation-related EEG data classification while participants read words with high versus low relevance to the keyword. The best validation accuracy in this word-level classification is over 60\\% across 12 subjects. Words of high relevance to the inference keyword had sig",
    "link": "http://arxiv.org/abs/2309.15714",
    "context": "Title: ChatGPT-BCI: Word-Level Neural State Classification Using GPT, EEG, and Eye-Tracking Biomarkers in Semantic Inference Reading Comprehension. (arXiv:2309.15714v1 [cs.CL])\nAbstract: With the recent explosion of large language models (LLMs), such as Generative Pretrained Transformers (GPT), the need to understand the ability of humans and machines to comprehend semantic language meaning has entered a new phase. This requires interdisciplinary research that bridges the fields of cognitive science and natural language processing (NLP). This pilot study aims to provide insights into individuals' neural states during a semantic relation reading-comprehension task. We propose jointly analyzing LLMs, eye-gaze, and electroencephalographic (EEG) data to study how the brain processes words with varying degrees of relevance to a keyword during reading. We also use a feature engineering approach to improve the fixation-related EEG data classification while participants read words with high versus low relevance to the keyword. The best validation accuracy in this word-level classification is over 60\\% across 12 subjects. Words of high relevance to the inference keyword had sig",
    "path": "papers/23/09/2309.15714.json",
    "total_tokens": 904,
    "translated_title": "ChatGPT-BCI：使用GPT、EEG和眼动生物标记器在语义推理阅读理解中进行单词级神经状态分类",
    "translated_abstract": "随着大型语言模型（LLM）（如GPT）的迅猛发展，人类和机器理解语义语言意义的能力已经进入了一个新阶段。这需要跨认知科学和自然语言处理（NLP）领域的跨学科研究。本文的目标是通过联合分析LLMs、眼动和脑电图（EEG）数据，研究大脑在阅读过程中如何处理与关键字相关程度不同的单词，从而提供关于个体神经状态在语义关系阅读理解任务中的洞察。我们还使用特征工程方法改进了与关键字高相关度和低相关度的单词阅读过程中与注视相关的EEG数据的分类。在12名受试者中，此单词级别分类的最佳验证准确率超过了60％。",
    "tldr": "本研究通过联合分析大型语言模型（LLMs）、眼动和脑电图（EEG）数据，研究了大脑在阅读过程中处理与关键字相关度不同的单词的神经状态，并提供了关于语义推理阅读理解中神经状态的洞察。",
    "en_tdlr": "This study provides insights into individuals' neural states during semantic relation reading comprehension by jointly analyzing large language models (LLMs), eye-gaze, and electroencephalographic (EEG) data."
}