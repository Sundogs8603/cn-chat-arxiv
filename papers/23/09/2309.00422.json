{
    "title": "Declarative Reasoning on Explanations Using Constraint Logic Programming. (arXiv:2309.00422v1 [cs.AI])",
    "abstract": "Explaining opaque Machine Learning (ML) models is an increasingly relevant problem. Current explanation in AI (XAI) methods suffer several shortcomings, among others an insufficient incorporation of background knowledge, and a lack of abstraction and interactivity with the user. We propose REASONX, an explanation method based on Constraint Logic Programming (CLP). REASONX can provide declarative, interactive explanations for decision trees, which can be the ML models under analysis or global/local surrogate models of any black-box model. Users can express background or common sense knowledge using linear constraints and MILP optimization over features of factual and contrastive instances, and interact with the answer constraints at different levels of abstraction through constraint projection. We present here the architecture of REASONX, which consists of a Python layer, closer to the user, and a CLP layer. REASONX's core execution engine is a Prolog meta-program with declarative seman",
    "link": "http://arxiv.org/abs/2309.00422",
    "context": "Title: Declarative Reasoning on Explanations Using Constraint Logic Programming. (arXiv:2309.00422v1 [cs.AI])\nAbstract: Explaining opaque Machine Learning (ML) models is an increasingly relevant problem. Current explanation in AI (XAI) methods suffer several shortcomings, among others an insufficient incorporation of background knowledge, and a lack of abstraction and interactivity with the user. We propose REASONX, an explanation method based on Constraint Logic Programming (CLP). REASONX can provide declarative, interactive explanations for decision trees, which can be the ML models under analysis or global/local surrogate models of any black-box model. Users can express background or common sense knowledge using linear constraints and MILP optimization over features of factual and contrastive instances, and interact with the answer constraints at different levels of abstraction through constraint projection. We present here the architecture of REASONX, which consists of a Python layer, closer to the user, and a CLP layer. REASONX's core execution engine is a Prolog meta-program with declarative seman",
    "path": "papers/23/09/2309.00422.json",
    "total_tokens": 891,
    "translated_title": "使用约束逻辑编程进行解释性推理",
    "translated_abstract": "解释不透明的机器学习模型是一个日益重要的问题。当前的解释方法在人工智能（XAI）中存在一些缺点，包括对背景知识的不充分结合，以及与用户的缺乏抽象和互动。我们提出了基于约束逻辑编程（CLP）的REASONX解释方法。REASONX可以为决策树提供声明性的交互式解释，这些决策树可以是分析的机器学习模型或任何黑盒模型的全局/局部替代模型。用户可以使用线性约束和基于事实和对比实例的特征的MILP优化来表达背景知识或常识，并通过约束投影在不同抽象级别上与答案约束进行交互。我们在这里介绍了REASONX的架构，它由接近用户的Python层和CLP层组成。REASONX的核心执行引擎是一个具有声明性语义的Prolog元编程。",
    "tldr": "这项研究提出了使用约束逻辑编程进行解释性推理的方法，可以为决策树提供声明性、交互式的解释，克服了当前解释方法中对背景知识的不充分结合和与用户的缺乏抽象和互动的问题。",
    "en_tdlr": "This study proposes a method using constraint logic programming for declarative reasoning, providing interactive explanations for decision trees and addressing the issues of insufficient incorporation of background knowledge and lack of abstraction and interactivity with users in current explanation methods."
}