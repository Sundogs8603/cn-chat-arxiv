{
    "title": "Distributional Shift-Aware Off-Policy Interval Estimation: A Unified Error Quantification Framework. (arXiv:2309.13278v1 [stat.ML])",
    "abstract": "We study high-confidence off-policy evaluation in the context of infinite-horizon Markov decision processes, where the objective is to establish a confidence interval (CI) for the target policy value using only offline data pre-collected from unknown behavior policies. This task faces two primary challenges: providing a comprehensive and rigorous error quantification in CI estimation, and addressing the distributional shift that results from discrepancies between the distribution induced by the target policy and the offline data-generating process. Motivated by an innovative unified error analysis, we jointly quantify the two sources of estimation errors: the misspecification error on modeling marginalized importance weights and the statistical uncertainty due to sampling, within a single interval. This unified framework reveals a previously hidden tradeoff between the errors, which undermines the tightness of the CI. Relying on a carefully designed discriminator function, the proposed",
    "link": "http://arxiv.org/abs/2309.13278",
    "context": "Title: Distributional Shift-Aware Off-Policy Interval Estimation: A Unified Error Quantification Framework. (arXiv:2309.13278v1 [stat.ML])\nAbstract: We study high-confidence off-policy evaluation in the context of infinite-horizon Markov decision processes, where the objective is to establish a confidence interval (CI) for the target policy value using only offline data pre-collected from unknown behavior policies. This task faces two primary challenges: providing a comprehensive and rigorous error quantification in CI estimation, and addressing the distributional shift that results from discrepancies between the distribution induced by the target policy and the offline data-generating process. Motivated by an innovative unified error analysis, we jointly quantify the two sources of estimation errors: the misspecification error on modeling marginalized importance weights and the statistical uncertainty due to sampling, within a single interval. This unified framework reveals a previously hidden tradeoff between the errors, which undermines the tightness of the CI. Relying on a carefully designed discriminator function, the proposed",
    "path": "papers/23/09/2309.13278.json",
    "total_tokens": 967,
    "translated_title": "分布偏移感知的强化学习非同策略区间估计方法：一个统一的误差量化框架",
    "translated_abstract": "本文研究了在无限时间马尔可夫决策过程中的高置信度非同策略评估问题，其目标是仅利用从未知行为策略预先收集的离线数据为目标策略的值建立一个置信区间（CI）。该任务面临两个主要挑战：在CI估计中提供全面且严格的误差量化，并解决由目标策略产生的分布偏移问题，该分布与离线数据生成过程之间存在差异。受到创新的统一误差分析的启发，我们在一个单一的区间内共同量化两个估计误差来源：在建模边际化重要性权重时的规范不准确误差和抽样导致的统计不确定性。这一统一的框架揭示了误差之间以前隐藏的权衡，从而削弱了CI的紧密性。通过依靠精心设计的判别函数，提出了一种新的解决方案来克服分布偏移问题。",
    "tldr": "本研究提出了一个对于强化学习非同策略评估问题的统一误差量化框架，并解决了分布偏移的挑战。通过在一个单一的区间内共同量化两个估计误差源，该框架揭示了之前隐藏的误差权衡，从而提高了置信区间的准确性。",
    "en_tdlr": "This study proposes a unified error quantification framework for off-policy evaluation in reinforcement learning, addressing the challenge of distributional shift. By jointly quantifying two sources of estimation errors within a single interval, the framework reveals previously hidden error tradeoffs, improving the accuracy of confidence intervals."
}