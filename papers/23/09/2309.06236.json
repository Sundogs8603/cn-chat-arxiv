{
    "title": "The first step is the hardest: Pitfalls of Representing and Tokenizing Temporal Data for Large Language Models. (arXiv:2309.06236v1 [cs.LG])",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable generalization across diverse tasks, leading individuals to increasingly use them as personal assistants and universal computing engines. Nevertheless, a notable obstacle emerges when feeding numerical/temporal data into these models, such as data sourced from wearables or electronic health records. LLMs employ tokenizers in their input that break down text into smaller units. However, tokenizers are not designed to represent numerical values and might struggle to understand repetitive patterns and context, treating consecutive values as separate tokens and disregarding their temporal relationships. Here, we discuss recent works that employ LLMs for human-centric tasks such as in mobile health sensing and present a case study showing that popular LLMs tokenize temporal data incorrectly. To address that, we highlight potential solutions such as prompt tuning with lightweight embedding layers as well as multimodal adapters, that c",
    "link": "http://arxiv.org/abs/2309.06236",
    "context": "Title: The first step is the hardest: Pitfalls of Representing and Tokenizing Temporal Data for Large Language Models. (arXiv:2309.06236v1 [cs.LG])\nAbstract: Large Language Models (LLMs) have demonstrated remarkable generalization across diverse tasks, leading individuals to increasingly use them as personal assistants and universal computing engines. Nevertheless, a notable obstacle emerges when feeding numerical/temporal data into these models, such as data sourced from wearables or electronic health records. LLMs employ tokenizers in their input that break down text into smaller units. However, tokenizers are not designed to represent numerical values and might struggle to understand repetitive patterns and context, treating consecutive values as separate tokens and disregarding their temporal relationships. Here, we discuss recent works that employ LLMs for human-centric tasks such as in mobile health sensing and present a case study showing that popular LLMs tokenize temporal data incorrectly. To address that, we highlight potential solutions such as prompt tuning with lightweight embedding layers as well as multimodal adapters, that c",
    "path": "papers/23/09/2309.06236.json",
    "total_tokens": 881,
    "translated_title": "踏出的第一步最困难：在大语言模型中表示和分词时间数据的陷阱",
    "translated_abstract": "大型语言模型(LLMs)在各种任务中展示了出色的泛化能力，导致人们越来越多地将它们用作个人助手和通用计算引擎。然而，将数值/时间数据输入到这些模型中时，会出现一个明显的障碍，比如从可穿戴设备或电子健康记录中获取的数据。LLMs在其输入中使用分词器将文本分解为较小的单位。然而，分词器并不设计用于表示数值，并可能难以理解重复模式和上下文，将连续的值视为单独的标记并忽略它们的时间关系。在这里，我们讨论了最近使用LLMs进行以人为中心任务的研究，并提出了一个案例研究，展示了流行的LLMs错误地对时间数据进行分词。为了解决这个问题，我们强调了一些潜在的解决方案，例如使用轻量级嵌入层进行提示调整和多模态适配器。",
    "tldr": "这项研究讨论了在大语言模型中表示和分词时间数据的困难，并提出了解决方案，如使用轻量级嵌入层进行提示调整和多模态适配器。",
    "en_tdlr": "This research discusses the challenges of representing and tokenizing temporal data in large language models and proposes solutions such as prompt tuning with lightweight embedding layers and multimodal adapters."
}