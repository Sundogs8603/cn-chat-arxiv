{
    "title": "Online Distributed Learning over Random Networks. (arXiv:2309.00520v1 [math.OC])",
    "abstract": "The recent deployment of multi-agent systems in a wide range of scenarios has enabled the solution of learning problems in a distributed fashion. In this context, agents are tasked with collecting local data and then cooperatively train a model, without directly sharing the data. While distributed learning offers the advantage of preserving agents' privacy, it also poses several challenges in terms of designing and analyzing suitable algorithms. This work focuses specifically on the following challenges motivated by practical implementation: (i) online learning, where the local data change over time; (ii) asynchronous agent computations; (iii) unreliable and limited communications; and (iv) inexact local computations. To tackle these challenges, we introduce the Distributed Operator Theoretical (DOT) version of the Alternating Direction Method of Multipliers (ADMM), which we call the DOT-ADMM Algorithm. We prove that it converges with a linear rate for a large class of convex learning ",
    "link": "http://arxiv.org/abs/2309.00520",
    "context": "Title: Online Distributed Learning over Random Networks. (arXiv:2309.00520v1 [math.OC])\nAbstract: The recent deployment of multi-agent systems in a wide range of scenarios has enabled the solution of learning problems in a distributed fashion. In this context, agents are tasked with collecting local data and then cooperatively train a model, without directly sharing the data. While distributed learning offers the advantage of preserving agents' privacy, it also poses several challenges in terms of designing and analyzing suitable algorithms. This work focuses specifically on the following challenges motivated by practical implementation: (i) online learning, where the local data change over time; (ii) asynchronous agent computations; (iii) unreliable and limited communications; and (iv) inexact local computations. To tackle these challenges, we introduce the Distributed Operator Theoretical (DOT) version of the Alternating Direction Method of Multipliers (ADMM), which we call the DOT-ADMM Algorithm. We prove that it converges with a linear rate for a large class of convex learning ",
    "path": "papers/23/09/2309.00520.json",
    "total_tokens": 874,
    "translated_title": "在随机网络上的在线分布式学习",
    "translated_abstract": "最近，在各种场景中部署的多智能体系统使得在分布式环境下解决学习问题成为可能。在这种情况下，智能体的任务是收集本地数据，然后合作训练模型，而不直接共享数据。虽然分布式学习在保护智能体隐私方面具有优势，但在设计和分析适当的算法方面也存在一些挑战。本文特别关注以下由实际实施所驱动的挑战：（i）在线学习，其中本地数据随时间变化；（ii）异步智能体计算；（iii）不可靠和有限的通信；（iv）不精确的本地计算。为了应对这些挑战，我们介绍了分布式操作理论（DOT）版本的交替方向乘子法（ADMM），称之为DOT-ADMM算法。我们证明了它在大类凸学习问题上具有线性收敛速度。",
    "tldr": "本文提出了在随机网络上进行在线分布式学习的DOT-ADMM算法，通过解决在线学习、异步计算、不可靠通信和不精确计算等挑战，在一大类凸学习问题上获得了线性收敛速度。",
    "en_tdlr": "This paper proposes the DOT-ADMM algorithm for online distributed learning over random networks, addressing challenges such as online learning, asynchronous computations, unreliable communications, and inexact computations, and achieving linear convergence rate for a large class of convex learning problems."
}