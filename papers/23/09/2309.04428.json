{
    "title": "Soft Quantization using Entropic Regularization. (arXiv:2309.04428v1 [math.PR])",
    "abstract": "The quantization problem aims to find the best possible approximation of probability measures on ${\\mathbb{R}}^d$ using finite, discrete measures. The Wasserstein distance is a typical choice to measure the quality of the approximation. This contribution investigates the properties and robustness of the entropy-regularized quantization problem, which relaxes the standard quantization problem. The proposed approximation technique naturally adopts the softmin function, which is well known for its robustness in terms of theoretical and practicability standpoints. Moreover, we use the entropy-regularized Wasserstein distance to evaluate the quality of the soft quantization problem's approximation, and we implement a stochastic gradient approach to achieve the optimal solutions. The control parameter in our proposed method allows for the adjustment of the optimization problem's difficulty level, providing significant advantages when dealing with exceptionally challenging problems of interes",
    "link": "http://arxiv.org/abs/2309.04428",
    "context": "Title: Soft Quantization using Entropic Regularization. (arXiv:2309.04428v1 [math.PR])\nAbstract: The quantization problem aims to find the best possible approximation of probability measures on ${\\mathbb{R}}^d$ using finite, discrete measures. The Wasserstein distance is a typical choice to measure the quality of the approximation. This contribution investigates the properties and robustness of the entropy-regularized quantization problem, which relaxes the standard quantization problem. The proposed approximation technique naturally adopts the softmin function, which is well known for its robustness in terms of theoretical and practicability standpoints. Moreover, we use the entropy-regularized Wasserstein distance to evaluate the quality of the soft quantization problem's approximation, and we implement a stochastic gradient approach to achieve the optimal solutions. The control parameter in our proposed method allows for the adjustment of the optimization problem's difficulty level, providing significant advantages when dealing with exceptionally challenging problems of interes",
    "path": "papers/23/09/2309.04428.json",
    "total_tokens": 849,
    "translated_title": "使用熵正则化的软量化问题",
    "translated_abstract": "量化问题旨在通过有限的离散测度找到在${\\mathbb{R}}^d$上概率测度的最佳近似。Wasserstein距离是衡量近似质量的典型选择。本研究调查了熵正则化量化问题的性质和鲁棒性，该方法放松了标准的量化问题。提出的近似技术自然地采用了软最小函数，该函数因其在理论和实践的可靠性方面而闻名。此外，我们使用熵正则化的Wasserstein距离来评估软量化问题近似的质量，并实现了一种随机梯度方法来获得最优解。我们提出的方法中的控制参数可以调整优化问题的难度级别，在处理异常挑战性问题时具有显著优势。",
    "tldr": "本研究通过使用熵正则化和软最小函数来解决量化问题，提出了一种新的近似技术，并使用随机梯度方法获得最优解。该方法具有调节优化问题难度的控制参数，可在处理具有挑战性问题时提供显著优势。",
    "en_tdlr": "This study proposes a new approximation technique for the quantization problem using entropy regularization and softmin function, and implements a stochastic gradient approach to find optimal solutions. The method includes a control parameter to adjust the difficulty level of the optimization problem, providing significant advantages in dealing with challenging problems."
}