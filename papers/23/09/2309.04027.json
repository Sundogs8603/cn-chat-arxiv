{
    "title": "TIDE: Textual Identity Detection for Evaluating and Augmenting Classification and Language Models. (arXiv:2309.04027v1 [cs.CL])",
    "abstract": "Machine learning models can perpetuate unintended biases from unfair and imbalanced datasets. Evaluating and debiasing these datasets and models is especially hard in text datasets where sensitive attributes such as race, gender, and sexual orientation may not be available. When these models are deployed into society, they can lead to unfair outcomes for historically underrepresented groups. In this paper, we present a dataset coupled with an approach to improve text fairness in classifiers and language models. We create a new, more comprehensive identity lexicon, TIDAL, which includes 15,123 identity terms and associated sense context across three demographic categories. We leverage TIDAL to develop an identity annotation and augmentation tool that can be used to improve the availability of identity context and the effectiveness of ML fairness techniques. We evaluate our approaches using human contributors, and additionally run experiments focused on dataset and model debiasing. Resul",
    "link": "http://arxiv.org/abs/2309.04027",
    "context": "Title: TIDE: Textual Identity Detection for Evaluating and Augmenting Classification and Language Models. (arXiv:2309.04027v1 [cs.CL])\nAbstract: Machine learning models can perpetuate unintended biases from unfair and imbalanced datasets. Evaluating and debiasing these datasets and models is especially hard in text datasets where sensitive attributes such as race, gender, and sexual orientation may not be available. When these models are deployed into society, they can lead to unfair outcomes for historically underrepresented groups. In this paper, we present a dataset coupled with an approach to improve text fairness in classifiers and language models. We create a new, more comprehensive identity lexicon, TIDAL, which includes 15,123 identity terms and associated sense context across three demographic categories. We leverage TIDAL to develop an identity annotation and augmentation tool that can be used to improve the availability of identity context and the effectiveness of ML fairness techniques. We evaluate our approaches using human contributors, and additionally run experiments focused on dataset and model debiasing. Resul",
    "path": "papers/23/09/2309.04027.json",
    "total_tokens": 903,
    "translated_title": "TIDE: 用于评估和增强分类和语言模型的文本身份检测",
    "translated_abstract": "机器学习模型可以继承不公正和不平衡数据集中的意外偏见。在文本数据集中，评估和去偏这些数据集和模型尤其困难，因为种族、性别和性取向等敏感属性可能不可用。当这些模型投放到社会中时，它们可能对历史上弱势群体产生不公平的结果。本文提出了一个与方法相结合的数据集，以改善分类器和语言模型中的文本公平性。我们创建了一个更全面的身份词汇表TIDAL，包括15,123个身份术语和相关的语境，涵盖了三个人口统计类别。我们利用TIDAL开发了一个身份注释和增强工具，可以用于改善身份语境的可用性和机器学习公平性技术的效果。我们使用人类贡献者对我们的方法进行了评估，并进行了重点关注数据集和模型去偏的实验。",
    "tldr": "本文介绍了TIDE（Textual Identity Detection）方法来改善分类器和语言模型中的文本公平性。通过创建一个包含身份词汇和语境的数据集，以及开发一个身份注释和增强工具，可以提高机器学习公平性技术的效果。",
    "en_tdlr": "This paper presents TIDE (Textual Identity Detection) approach to improve text fairness in classifiers and language models. By creating a dataset with identity terms and context and developing an identity annotation and augmentation tool, the effectiveness of ML fairness techniques can be enhanced."
}