{
    "title": "Stabilize to Act: Learning to Coordinate for Bimanual Manipulation. (arXiv:2309.01087v2 [cs.RO] UPDATED)",
    "abstract": "Key to rich, dexterous manipulation in the real world is the ability to coordinate control across two hands. However, while the promise afforded by bimanual robotic systems is immense, constructing control policies for dual arm autonomous systems brings inherent difficulties. One such difficulty is the high-dimensionality of the bimanual action space, which adds complexity to both model-based and data-driven methods. We counteract this challenge by drawing inspiration from humans to propose a novel role assignment framework: a stabilizing arm holds an object in place to simplify the environment while an acting arm executes the task. We instantiate this framework with BimanUal Dexterity from Stabilization (BUDS), which uses a learned restabilizing classifier to alternate between updating a learned stabilization position to keep the environment unchanged, and accomplishing the task with an acting policy learned from demonstrations. We evaluate BUDS on four bimanual tasks of varying compl",
    "link": "http://arxiv.org/abs/2309.01087",
    "context": "Title: Stabilize to Act: Learning to Coordinate for Bimanual Manipulation. (arXiv:2309.01087v2 [cs.RO] UPDATED)\nAbstract: Key to rich, dexterous manipulation in the real world is the ability to coordinate control across two hands. However, while the promise afforded by bimanual robotic systems is immense, constructing control policies for dual arm autonomous systems brings inherent difficulties. One such difficulty is the high-dimensionality of the bimanual action space, which adds complexity to both model-based and data-driven methods. We counteract this challenge by drawing inspiration from humans to propose a novel role assignment framework: a stabilizing arm holds an object in place to simplify the environment while an acting arm executes the task. We instantiate this framework with BimanUal Dexterity from Stabilization (BUDS), which uses a learned restabilizing classifier to alternate between updating a learned stabilization position to keep the environment unchanged, and accomplishing the task with an acting policy learned from demonstrations. We evaluate BUDS on four bimanual tasks of varying compl",
    "path": "papers/23/09/2309.01087.json",
    "total_tokens": 924,
    "translated_title": "稳定行动：学习协调双手操作的方法",
    "translated_abstract": "在真实世界中进行丰富和灵巧的操作的关键是能够协调控制两只手。然而，虽然双手机器人系统带来了巨大的前景，但构建双臂自主系统的控制策略却面临难题。其中一个困难是双手动作空间的高维度，这给基于模型和数据驱动的方法增加了复杂性。我们从人类身上得到启发，提出了一种新的角色分配框架来应对这一挑战：一个稳定的臂将物体固定在一个位置上，简化环境，而一个活动的臂则执行任务。我们利用学习到的稳定分类器来实施 BimanUal Dexterity from Stabilization (BUDS) 框架，该分类器交替更新学习到的稳定位置以保持环境稳定，并利用示范学习到的行动策略完成任务。我们对BUDS进行了四种不同的双手任务评估。",
    "tldr": "通过借鉴人类的角色分配方法，我们提出了一种稳定行动的框架，其中一个手臂用于固定物体，另一个手臂用于执行任务。通过学习到的稳定分类器和行动策略，我们实现了这一框架并对其进行了评估。",
    "en_tdlr": "We propose a framework for stabilizing bimanual manipulation by assigning one arm to hold an object while the other arm performs the task. We use a learned stabilizing classifier and an acting policy to accomplish this framework, and evaluate its performance on four different bimanual tasks."
}