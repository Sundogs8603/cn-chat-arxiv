{
    "title": "360$^\\circ$ from a Single Camera: A Few-Shot Approach for LiDAR Segmentation. (arXiv:2309.06197v1 [cs.CV])",
    "abstract": "Deep learning applications on LiDAR data suffer from a strong domain gap when applied to different sensors or tasks. In order for these methods to obtain similar accuracy on different data in comparison to values reported on public benchmarks, a large scale annotated dataset is necessary. However, in practical applications labeled data is costly and time consuming to obtain. Such factors have triggered various research in label-efficient methods, but a large gap remains to their fully-supervised counterparts. Thus, we propose ImageTo360, an effective and streamlined few-shot approach to label-efficient LiDAR segmentation. Our method utilizes an image teacher network to generate semantic predictions for LiDAR data within a single camera view. The teacher is used to pretrain the LiDAR segmentation student network, prior to optional fine-tuning on 360$^\\circ$ data. Our method is implemented in a modular manner on the point level and as such is generalizable to different architectures. We ",
    "link": "http://arxiv.org/abs/2309.06197",
    "context": "Title: 360$^\\circ$ from a Single Camera: A Few-Shot Approach for LiDAR Segmentation. (arXiv:2309.06197v1 [cs.CV])\nAbstract: Deep learning applications on LiDAR data suffer from a strong domain gap when applied to different sensors or tasks. In order for these methods to obtain similar accuracy on different data in comparison to values reported on public benchmarks, a large scale annotated dataset is necessary. However, in practical applications labeled data is costly and time consuming to obtain. Such factors have triggered various research in label-efficient methods, but a large gap remains to their fully-supervised counterparts. Thus, we propose ImageTo360, an effective and streamlined few-shot approach to label-efficient LiDAR segmentation. Our method utilizes an image teacher network to generate semantic predictions for LiDAR data within a single camera view. The teacher is used to pretrain the LiDAR segmentation student network, prior to optional fine-tuning on 360$^\\circ$ data. Our method is implemented in a modular manner on the point level and as such is generalizable to different architectures. We ",
    "path": "papers/23/09/2309.06197.json",
    "total_tokens": 899,
    "translated_title": "一台摄像机的360°视角：用于LiDAR分割的少样本方法",
    "translated_abstract": "LiDAR数据上的深度学习应用在应用于不同的传感器或任务时，会遭受到强烈的域间差距。为了使这些方法在不同数据上获得与公共基准报告值相似的准确性，需要一个大规模的带标注数据集。然而，在实际应用中，标注数据的获取成本和时间成本很高。这些因素引发了对标度效率方法的各种研究，但与完全监督的对照方法相比，仍存在很大差距。因此，我们提出了ImageTo360，一种有效且简洁的少样本方法，用于标度高效的LiDAR分割。我们的方法利用图像教师网络在单个摄像机视角下为LiDAR数据生成语义预测。在对360°数据进行可选微调之前，使用教师网络对LiDAR分割学生网络进行预训练。我们的方法以模块化的方式实现在点级别，并且适用于不同的体系结构。",
    "tldr": "本论文提出了一种用于LiDAR分割的少样本方法，通过使用图像教师网络在单个摄像机视角下生成语义预测，实现了标度高效的LiDAR分割。",
    "en_tdlr": "This paper proposes a few-shot approach for LiDAR segmentation, where an image teacher network is used to generate semantic predictions for LiDAR data within a single camera view, achieving label-efficient LiDAR segmentation."
}