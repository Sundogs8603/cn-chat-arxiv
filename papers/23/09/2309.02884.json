{
    "title": "Aligning Large Language Models for Clinical Tasks. (arXiv:2309.02884v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable adaptability, showcasing their capacity to excel in tasks for which they were not explicitly trained. However, despite their impressive natural language processing (NLP) capabilities, effective alignment of LLMs remains a crucial challenge when deploying them for specific clinical applications. The ability to generate responses with factually accurate content and to engage in non-trivial reasoning steps are crucial for the LLMs to be eligible for applications in clinical medicine. Employing a combination of techniques including instruction-tuning and in-prompt strategies like few-shot and chain of thought prompting has significantly enhanced the performance of LLMs. Our proposed alignment strategy for medical question-answering, known as 'expand-guess-refine', offers a parameter and data-efficient solution. A preliminary analysis of this method demonstrated outstanding performance, achieving a score of 70.63% on a subset of ques",
    "link": "http://arxiv.org/abs/2309.02884",
    "context": "Title: Aligning Large Language Models for Clinical Tasks. (arXiv:2309.02884v1 [cs.CL])\nAbstract: Large Language Models (LLMs) have demonstrated remarkable adaptability, showcasing their capacity to excel in tasks for which they were not explicitly trained. However, despite their impressive natural language processing (NLP) capabilities, effective alignment of LLMs remains a crucial challenge when deploying them for specific clinical applications. The ability to generate responses with factually accurate content and to engage in non-trivial reasoning steps are crucial for the LLMs to be eligible for applications in clinical medicine. Employing a combination of techniques including instruction-tuning and in-prompt strategies like few-shot and chain of thought prompting has significantly enhanced the performance of LLMs. Our proposed alignment strategy for medical question-answering, known as 'expand-guess-refine', offers a parameter and data-efficient solution. A preliminary analysis of this method demonstrated outstanding performance, achieving a score of 70.63% on a subset of ques",
    "path": "papers/23/09/2309.02884.json",
    "total_tokens": 915,
    "translated_title": "对于临床任务的大型语言模型的对齐",
    "translated_abstract": "大型语言模型(LLMs)展示出了令人瞩目的适应性，展示了它们在没有明确训练的任务中表现出色的能力。然而，尽管它们具有令人印象深刻的自然语言处理(NLP)能力，但有效地对齐LLM仍然是在特定临床应用中部署它们的关键挑战。生成具有事实准确内容的响应和从事非平凡推理步骤的能力对于LLMs能否适用于临床医学应用至关重要。采用一系列技术，包括指令调优和少量示例和思路链接等in-prompt策略，显著提高了LLMs的性能。我们提出的医学问答对齐策略被称为“ expand-guess-refine”，提供了一种参数和数据高效的解决方案。对这种方法的初步分析表明，它在问题子集上取得了出色的表现，得分为70.63％。",
    "tldr": "该论文讨论了对于临床任务的大型语言模型(LLMs)的对齐问题，提出了一种名为\"expand-guess-refine\"的医学问答对齐策略，并通过组合使用指令调优和in-prompt策略等技术来提高LLMs的性能。",
    "en_tdlr": "This paper discusses the alignment problem of large language models (LLMs) for clinical tasks, proposes a medical question-answering alignment strategy called \"expand-guess-refine\", and improves the performance of LLMs by employing techniques such as instruction-tuning and in-prompt strategies."
}