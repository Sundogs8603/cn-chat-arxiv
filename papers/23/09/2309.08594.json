{
    "title": "\"Merge Conflicts!\" Exploring the Impacts of External Distractors to Parametric Knowledge Graphs. (arXiv:2309.08594v1 [cs.CL])",
    "abstract": "Large language models (LLMs) acquire extensive knowledge during pre-training, known as their parametric knowledge. However, in order to remain up-to-date and align with human instructions, LLMs inevitably require external knowledge during their interactions with users. This raises a crucial question: How will LLMs respond when external knowledge interferes with their parametric knowledge? To investigate this question, we propose a framework that systematically elicits LLM parametric knowledge and introduces external knowledge. Specifically, we uncover the impacts by constructing a parametric knowledge graph to reveal the different knowledge structures of LLMs, and introduce external knowledge through distractors of varying degrees, methods, positions, and formats. Our experiments on both black-box and open-source models demonstrate that LLMs tend to produce responses that deviate from their parametric knowledge, particularly when they encounter direct conflicts or confounding changes o",
    "link": "http://arxiv.org/abs/2309.08594",
    "context": "Title: \"Merge Conflicts!\" Exploring the Impacts of External Distractors to Parametric Knowledge Graphs. (arXiv:2309.08594v1 [cs.CL])\nAbstract: Large language models (LLMs) acquire extensive knowledge during pre-training, known as their parametric knowledge. However, in order to remain up-to-date and align with human instructions, LLMs inevitably require external knowledge during their interactions with users. This raises a crucial question: How will LLMs respond when external knowledge interferes with their parametric knowledge? To investigate this question, we propose a framework that systematically elicits LLM parametric knowledge and introduces external knowledge. Specifically, we uncover the impacts by constructing a parametric knowledge graph to reveal the different knowledge structures of LLMs, and introduce external knowledge through distractors of varying degrees, methods, positions, and formats. Our experiments on both black-box and open-source models demonstrate that LLMs tend to produce responses that deviate from their parametric knowledge, particularly when they encounter direct conflicts or confounding changes o",
    "path": "papers/23/09/2309.08594.json",
    "total_tokens": 901,
    "translated_title": "\"合并冲突！探索外部干扰对参数化知识图谱的影响\"",
    "translated_abstract": "大型语言模型（LLMs）在预训练期间获取了广泛的知识，称为它们的参数化知识。然而，为了保持与人类指令的一致并与时俱进，LLMs在与用户交互过程中不可避免地需要外部知识的支持。这引发了一个关键问题：当外部知识干扰参数化知识时，LLMs将如何做出反应？为了研究这个问题，我们提出了一个框架，系统地挖掘LLMs的参数化知识并引入外部知识。具体而言，我们通过构建参数化知识图谱来揭示LLMs的不同知识结构，并通过不同程度、方法、位置和格式的干扰因素引入外部知识。我们在黑盒和开源模型上的实验表明，LLMs倾向于产生与其参数化知识不一致的回复，特别是在遇到直接冲突或混淆变化时。",
    "tldr": "本研究探索了外部干扰对参数化知识图谱的影响，通过引入不同程度、方法、位置和格式的干扰因素，发现大型语言模型倾向于产生与其参数化知识不一致的回复。",
    "en_tdlr": "This study explores the impacts of external distractors on parametric knowledge graphs. By introducing distractors of varying degrees, methods, positions, and formats, it is found that large language models tend to produce responses that deviate from their parametric knowledge."
}