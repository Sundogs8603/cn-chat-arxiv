{
    "title": "S-GBDT: Frugal Differentially Private Gradient Boosting Decision Trees. (arXiv:2309.12041v1 [cs.CR])",
    "abstract": "Privacy-preserving learning of gradient boosting decision trees (GBDT) has the potential for strong utility-privacy tradeoffs for tabular data, such as census data or medical meta data: classical GBDT learners can extract non-linear patterns from small sized datasets. The state-of-the-art notion for provable privacy-properties is differential privacy, which requires that the impact of single data points is limited and deniable. We introduce a novel differentially private GBDT learner and utilize four main techniques to improve the utility-privacy tradeoff. (1) We use an improved noise scaling approach with tighter accounting of privacy leakage of a decision tree leaf compared to prior work, resulting in noise that in expectation scales with $O(1/n)$, for $n$ data points. (2) We integrate individual R\\'enyi filters to our method to learn from data points that have been underutilized during an iterative training process, which -- potentially of independent interest -- results in a natura",
    "link": "http://arxiv.org/abs/2309.12041",
    "context": "Title: S-GBDT: Frugal Differentially Private Gradient Boosting Decision Trees. (arXiv:2309.12041v1 [cs.CR])\nAbstract: Privacy-preserving learning of gradient boosting decision trees (GBDT) has the potential for strong utility-privacy tradeoffs for tabular data, such as census data or medical meta data: classical GBDT learners can extract non-linear patterns from small sized datasets. The state-of-the-art notion for provable privacy-properties is differential privacy, which requires that the impact of single data points is limited and deniable. We introduce a novel differentially private GBDT learner and utilize four main techniques to improve the utility-privacy tradeoff. (1) We use an improved noise scaling approach with tighter accounting of privacy leakage of a decision tree leaf compared to prior work, resulting in noise that in expectation scales with $O(1/n)$, for $n$ data points. (2) We integrate individual R\\'enyi filters to our method to learn from data points that have been underutilized during an iterative training process, which -- potentially of independent interest -- results in a natura",
    "path": "papers/23/09/2309.12041.json",
    "total_tokens": 991,
    "translated_title": "S-GBDT: 节俭的差分隐私梯度提升决策树",
    "translated_abstract": "差分隐私学习梯度提升决策树(GBDT)在表格数据(如人口普查数据或医疗元数据)中具有很强的效用和隐私权之间的平衡潜力：经典的GBDT学习器可以从小规模数据集中提取非线性模式。可证明具有隐私性质的当前方法是差分隐私，该方法要求单个数据点的影响有限且可否认。我们引入了一种新的差分隐私GBDT学习器，并利用四种主要技术来改善效用和隐私权之间的平衡。(1)我们使用了一种改进的噪声缩放方法，更紧密地计算了与先前工作相比决策树叶子的隐私泄露，从而导致噪声的期望与数据点数量n的比例为$O(1/n)$，其中n为数据点数量。(2)我们将个体Rényi滤波器整合到我们的方法中，以从在迭代训练过程中未充分利用的数据点中学习，这可能是独立于兴趣的结果。",
    "tldr": "S-GBDT是一种节俭的差分隐私梯度提升决策树学习器，利用了四种技术来改善效用和隐私权之间的平衡，包括对隐私泄露的更紧密计算和整合个体Rényi滤波器以学习未充分利用的数据点。",
    "en_tdlr": "S-GBDT is a frugal differentially private gradient boosting decision tree learner that improves the trade-off between utility and privacy through techniques such as tighter calculations of privacy leakage and integration of individual Rényi filters to learn from underutilized data points."
}