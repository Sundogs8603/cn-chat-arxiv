{
    "title": "TrTr: A Versatile Pre-Trained Large Traffic Model based on Transformer for Capturing Trajectory Diversity in Vehicle Population. (arXiv:2309.12677v1 [cs.AI])",
    "abstract": "Understanding trajectory diversity is a fundamental aspect of addressing practical traffic tasks. However, capturing the diversity of trajectories presents challenges, particularly with traditional machine learning and recurrent neural networks due to the requirement of large-scale parameters. The emerging Transformer technology, renowned for its parallel computation capabilities enabling the utilization of models with hundreds of millions of parameters, offers a promising solution. In this study, we apply the Transformer architecture to traffic tasks, aiming to learn the diversity of trajectories within vehicle populations. We analyze the Transformer's attention mechanism and its adaptability to the goals of traffic tasks, and subsequently, design specific pre-training tasks. To achieve this, we create a data structure tailored to the attention mechanism and introduce a set of noises that correspond to spatio-temporal demands, which are incorporated into the structured data during the",
    "link": "http://arxiv.org/abs/2309.12677",
    "context": "Title: TrTr: A Versatile Pre-Trained Large Traffic Model based on Transformer for Capturing Trajectory Diversity in Vehicle Population. (arXiv:2309.12677v1 [cs.AI])\nAbstract: Understanding trajectory diversity is a fundamental aspect of addressing practical traffic tasks. However, capturing the diversity of trajectories presents challenges, particularly with traditional machine learning and recurrent neural networks due to the requirement of large-scale parameters. The emerging Transformer technology, renowned for its parallel computation capabilities enabling the utilization of models with hundreds of millions of parameters, offers a promising solution. In this study, we apply the Transformer architecture to traffic tasks, aiming to learn the diversity of trajectories within vehicle populations. We analyze the Transformer's attention mechanism and its adaptability to the goals of traffic tasks, and subsequently, design specific pre-training tasks. To achieve this, we create a data structure tailored to the attention mechanism and introduce a set of noises that correspond to spatio-temporal demands, which are incorporated into the structured data during the",
    "path": "papers/23/09/2309.12677.json",
    "total_tokens": 893,
    "translated_title": "TrTr：一种基于Transformer的通用预训练大型流量模型，用于捕捉车辆群体中的轨迹多样性",
    "translated_abstract": "理解轨迹多样性是解决实际交通任务的基本方面。然而，由于需要大规模参数，传统的机器学习和递归神经网络在捕捉轨迹多样性方面存在挑战。新兴的Transformer技术以其并行计算能力而闻名，可以利用具有数亿个参数的模型，为此提供了有希望的解决方案。在本研究中，我们将Transformer架构应用于交通任务，旨在学习车辆群体内的轨迹多样性。我们分析了Transformer的注意力机制以及其适应交通任务目标的能力，随后设计了特定的预训练任务。为了实现这一目标，我们创建了一个适合注意力机制的数据结构，并引入了一组与时空需求对应的噪声，这些噪声在结构化数据中被纳入。",
    "tldr": "本研究使用Transformer模型来捕捉车辆群体中轨迹的多样性，在交通任务中具有重要意义。通过分析注意力机制和设计预训练任务，实现了对车辆轨迹的学习，并提出了适用于交通任务的数据结构和噪声。",
    "en_tdlr": "This study applies the Transformer model to capture trajectory diversity in vehicle population, which is significant in traffic tasks. Analyzing the attention mechanism and designing pre-training tasks enable the learning of vehicle trajectories, along with the introduction of specific data structure and noise for traffic tasks."
}