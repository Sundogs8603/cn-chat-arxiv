{
    "title": "Retrieving Supporting Evidence for Generative Question Answering. (arXiv:2309.11392v1 [cs.IR])",
    "abstract": "Current large language models (LLMs) can exhibit near-human levels of performance on many natural language-based tasks, including open-domain question answering. Unfortunately, at this time, they also convincingly hallucinate incorrect answers, so that responses to questions must be verified against external sources before they can be accepted at face value. In this paper, we report two simple experiments to automatically validate generated answers against a corpus. We base our experiments on questions and passages from the MS MARCO (V1) test collection, and a retrieval pipeline consisting of sparse retrieval, dense retrieval and neural rerankers. In the first experiment, we validate the generated answer in its entirety. After presenting a question to an LLM and receiving a generated answer, we query the corpus with the combination of the question + generated answer. We then present the LLM with the combination of the question + generated answer + retrieved answer, prompting it to indi",
    "link": "http://arxiv.org/abs/2309.11392",
    "context": "Title: Retrieving Supporting Evidence for Generative Question Answering. (arXiv:2309.11392v1 [cs.IR])\nAbstract: Current large language models (LLMs) can exhibit near-human levels of performance on many natural language-based tasks, including open-domain question answering. Unfortunately, at this time, they also convincingly hallucinate incorrect answers, so that responses to questions must be verified against external sources before they can be accepted at face value. In this paper, we report two simple experiments to automatically validate generated answers against a corpus. We base our experiments on questions and passages from the MS MARCO (V1) test collection, and a retrieval pipeline consisting of sparse retrieval, dense retrieval and neural rerankers. In the first experiment, we validate the generated answer in its entirety. After presenting a question to an LLM and receiving a generated answer, we query the corpus with the combination of the question + generated answer. We then present the LLM with the combination of the question + generated answer + retrieved answer, prompting it to indi",
    "path": "papers/23/09/2309.11392.json",
    "total_tokens": 839,
    "translated_title": "生成式问答中的支持证据获取",
    "translated_abstract": "当前的大型语言模型（LLM）在许多自然语言任务（包括开放域问答）上表现出接近人类水平的性能。然而，它们也会生动地产生错误答案，因此在接受问题答案之前必须对其进行验证。本文报道了两个简单的实验来自动验证生成的答案与语料库的一致性。我们的实验基于MS MARCO（V1）测试集中的问题和段落，以及由稀疏检索、密集检索和神经重排器组成的检索流程。在第一个实验中，我们对整个生成的答案进行验证。将问题提供给LLM，并接收生成的答案后，我们使用问题+生成答案的组合在语料库中进行查询。然后，我们将问题+生成答案+检索答案的组合再次提供给LLM，促使其指明答案是否正确。",
    "tldr": "本文报道了两个实验，用于自动验证开放域问答生成的答案在语料库中的正确性。使用稀疏检索、密集检索和神经重排器的检索流程，通过对问题+生成答案+检索答案的组合进行验证。",
    "en_tdlr": "This paper presents two experiments that automatically validate the correctness of generated answers in open-domain question answering using a retrieval pipeline consisting of sparse retrieval, dense retrieval, and neural rerankers."
}