{
    "title": "Prompt Learning With Knowledge Memorizing Prototypes For Generalized Few-Shot Intent Detection. (arXiv:2309.04971v1 [cs.CL])",
    "abstract": "Generalized Few-Shot Intent Detection (GFSID) is challenging and realistic because it needs to categorize both seen and novel intents simultaneously. Previous GFSID methods rely on the episodic learning paradigm, which makes it hard to extend to a generalized setup as they do not explicitly learn the classification of seen categories and the knowledge of seen intents. To address the dilemma, we propose to convert the GFSID task into the class incremental learning paradigm. Specifically, we propose a two-stage learning framework, which sequentially learns the knowledge of different intents in various periods via prompt learning. And then we exploit prototypes for categorizing both seen and novel intents. Furthermore, to achieve the transfer knowledge of intents in different stages, for different scenarios we design two knowledge preservation methods which close to realistic applications. Extensive experiments and detailed analyses on two widely used datasets show that our framework base",
    "link": "http://arxiv.org/abs/2309.04971",
    "context": "Title: Prompt Learning With Knowledge Memorizing Prototypes For Generalized Few-Shot Intent Detection. (arXiv:2309.04971v1 [cs.CL])\nAbstract: Generalized Few-Shot Intent Detection (GFSID) is challenging and realistic because it needs to categorize both seen and novel intents simultaneously. Previous GFSID methods rely on the episodic learning paradigm, which makes it hard to extend to a generalized setup as they do not explicitly learn the classification of seen categories and the knowledge of seen intents. To address the dilemma, we propose to convert the GFSID task into the class incremental learning paradigm. Specifically, we propose a two-stage learning framework, which sequentially learns the knowledge of different intents in various periods via prompt learning. And then we exploit prototypes for categorizing both seen and novel intents. Furthermore, to achieve the transfer knowledge of intents in different stages, for different scenarios we design two knowledge preservation methods which close to realistic applications. Extensive experiments and detailed analyses on two widely used datasets show that our framework base",
    "path": "papers/23/09/2309.04971.json",
    "total_tokens": 952,
    "translated_title": "使用知识记忆原型进行广义少样本意图检测的提示学习",
    "translated_abstract": "广义少样本意图检测是具有挑战性和现实性的，因为它需要同时对已知和新意图进行分类。以往的广义少样本意图检测方法依赖于情节学习范式，难以扩展到广义设置，因为它们没有明确学习已知类别的分类和已知意图的知识。为了解决这个困境，我们提出将广义少样本意图检测任务转化为类增量学习范式。具体而言，我们提出了一个两阶段的学习框架，通过提示学习在不同阶段顺序学习不同意图的知识。然后，我们利用原型对已知和新意图进行分类。此外，为了在不同阶段实现意图的转移知识，在不同场景下我们设计了两种接近实际应用的知识保留方法。在两个广泛使用的数据集上的大量实验和详细分析表明我们的框架基于提示学习和知识记忆原型可以在广义少样本意图检测中取得优秀的性能。",
    "tldr": "本研究提出了一种使用知识记忆原型进行广义少样本意图检测的提示学习方法，通过将任务转化为类增量学习范式来同时分类已知和新意图。进行了大量的实验和分析，结果表明这种方法在广义少样本意图检测中具有优秀的性能。",
    "en_tdlr": "This paper proposes a prompt learning method with knowledge memorizing prototypes for generalized few-shot intent detection. It converts the task into a class incremental learning paradigm to classify both seen and novel intents. Extensive experiments and analysis show that this method achieves excellent performance in generalized few-shot intent detection."
}