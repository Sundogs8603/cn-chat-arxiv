{
    "title": "Exploration of TPUs for AI Applications. (arXiv:2309.08918v1 [cs.AR])",
    "abstract": "Tensor Processing Units (TPUs) are specialized hardware accelerators for deep learning developed by Google. This paper explores the performance of TPU with a focus on AI and its implementation in edge computing. It first provides an overview of TPUs, specifically their design in relation to neural networks, their general architecture, compilation techniques and supporting frameworks. Furthermore, we provide a comparative analysis of Cloud and Edge TPU performance against other counterpart chip architectures. It is then discussed how TPUs can be used to speed up AI workloads. The results show that TPUs can provide significant performance improvements both in cloud and edge computing. Additionally, we address the need for further research for the deployment of more architectures in the Edge TPU, as well as the need for the development of more robust comparisons in edge computing.",
    "link": "http://arxiv.org/abs/2309.08918",
    "context": "Title: Exploration of TPUs for AI Applications. (arXiv:2309.08918v1 [cs.AR])\nAbstract: Tensor Processing Units (TPUs) are specialized hardware accelerators for deep learning developed by Google. This paper explores the performance of TPU with a focus on AI and its implementation in edge computing. It first provides an overview of TPUs, specifically their design in relation to neural networks, their general architecture, compilation techniques and supporting frameworks. Furthermore, we provide a comparative analysis of Cloud and Edge TPU performance against other counterpart chip architectures. It is then discussed how TPUs can be used to speed up AI workloads. The results show that TPUs can provide significant performance improvements both in cloud and edge computing. Additionally, we address the need for further research for the deployment of more architectures in the Edge TPU, as well as the need for the development of more robust comparisons in edge computing.",
    "path": "papers/23/09/2309.08918.json",
    "total_tokens": 828,
    "translated_title": "探索TPUs在人工智能应用中的应用",
    "translated_abstract": "Tensor Processing Units（TPUs）是由Google开发的专门用于深度学习的硬件加速器。本文主要探讨了TPU在人工智能领域的性能和在边缘计算中的实现。首先概述了TPU的设计与神经网络的关系，以及其总体架构、编译技术和支持框架。此外，我们还对云TPU和边缘TPU的性能与其他芯片架构进行了比较分析。接下来讨论了如何利用TPU加速AI工作负载。结果表明，TPU在云计算和边缘计算中均能提供显著的性能改进。此外，我们还强调了需要进一步研究在边缘TPU中部署更多架构的需求，以及在边缘计算中进行更可靠比较的需求。",
    "tldr": "本文探索了TPUs在人工智能应用中的性能和在边缘计算中的实现，并提供了与其他芯片架构的性能比较。结果表明，TPUs可以在云计算和边缘计算中提供显著的性能改进。",
    "en_tdlr": "This paper explores the performance of TPUs for AI applications and their implementation in edge computing, and provides a comparative analysis of their performance against other chip architectures. The results show that TPUs can significantly improve performance in both cloud and edge computing."
}