{
    "title": "Towards Practical and Efficient Image-to-Speech Captioning with Vision-Language Pre-training and Multi-modal Tokens. (arXiv:2309.08531v1 [cs.CV])",
    "abstract": "In this paper, we propose methods to build a powerful and efficient Image-to-Speech captioning (Im2Sp) model. To this end, we start with importing the rich knowledge related to image comprehension and language modeling from a large-scale pre-trained vision-language model into Im2Sp. We set the output of the proposed Im2Sp as discretized speech units, i.e., the quantized speech features of a self-supervised speech model. The speech units mainly contain linguistic information while suppressing other characteristics of speech. This allows us to incorporate the language modeling capability of the pre-trained vision-language model into the spoken language modeling of Im2Sp. With the vision-language pre-training strategy, we set new state-of-the-art Im2Sp performances on two widely used benchmark databases, COCO and Flickr8k. Then, we further improve the efficiency of the Im2Sp model. Similar to the speech unit case, we convert the original image into image units, which are derived through v",
    "link": "http://arxiv.org/abs/2309.08531",
    "context": "Title: Towards Practical and Efficient Image-to-Speech Captioning with Vision-Language Pre-training and Multi-modal Tokens. (arXiv:2309.08531v1 [cs.CV])\nAbstract: In this paper, we propose methods to build a powerful and efficient Image-to-Speech captioning (Im2Sp) model. To this end, we start with importing the rich knowledge related to image comprehension and language modeling from a large-scale pre-trained vision-language model into Im2Sp. We set the output of the proposed Im2Sp as discretized speech units, i.e., the quantized speech features of a self-supervised speech model. The speech units mainly contain linguistic information while suppressing other characteristics of speech. This allows us to incorporate the language modeling capability of the pre-trained vision-language model into the spoken language modeling of Im2Sp. With the vision-language pre-training strategy, we set new state-of-the-art Im2Sp performances on two widely used benchmark databases, COCO and Flickr8k. Then, we further improve the efficiency of the Im2Sp model. Similar to the speech unit case, we convert the original image into image units, which are derived through v",
    "path": "papers/23/09/2309.08531.json",
    "total_tokens": 1030,
    "translated_title": "实现实用高效的图像到语音字幕生成的方法：基于视觉语言预训练和多模态令牌化",
    "translated_abstract": "在本文中，我们提出了构建强大高效的图像到语音字幕生成（Im2Sp）模型的方法。首先，我们从一个大规模预训练的视觉语言模型中引入与图像理解和语言建模有关的丰富知识并融入到Im2Sp中。我们将提出的Im2Sp的输出设置为离散化的语音单位，即自监督语音模型的量化语音特征。这些语音单位主要包含语言信息，而抑制了语音的其他特征。这使得我们能够将预训练的视觉语言模型的语言建模能力融入到Im2Sp的口语建模中。通过视觉语言预训练策略，我们在两个广泛使用的基准数据库COCO和Flickr8k上取得了新的最优Im2Sp性能。然后，我们进一步提高了Im2Sp模型的效率。类似于语音单位案例，我们将原始图像转换为图像单位，这些图像单位是通过视觉特征编码得到的。",
    "tldr": "本文提出了一种实现实用高效的图像到语音字幕生成的方法。通过引入来自大规模预训练的视觉语言模型的知识，并将其融入到Im2Sp模型中，以实现更好的性能。通过视觉语言预训练策略，在COOC和Flickr8k两个基准数据库上刷新了Im2Sp的最佳性能。同时，还改进了Im2Sp模型的效率。"
}