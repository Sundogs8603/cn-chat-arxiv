{
    "title": "Adversarial Attacks on Tables with Entity Swap. (arXiv:2309.08650v1 [cs.CL])",
    "abstract": "The capabilities of large language models (LLMs) have been successfully applied in the context of table representation learning. The recently proposed tabular language models have reported state-of-the-art results across various tasks for table interpretation. However, a closer look into the datasets commonly used for evaluation reveals an entity leakage from the train set into the test set. Motivated by this observation, we explore adversarial attacks that represent a more realistic inference setup. Adversarial attacks on text have been shown to greatly affect the performance of LLMs, but currently, there are no attacks targeting tabular language models. In this paper, we propose an evasive entity-swap attack for the column type annotation (CTA) task. Our CTA attack is the first black-box attack on tables, where we employ a similarity-based sampling strategy to generate adversarial examples. The experimental results show that the proposed attack generates up to a 70% drop in performan",
    "link": "http://arxiv.org/abs/2309.08650",
    "context": "Title: Adversarial Attacks on Tables with Entity Swap. (arXiv:2309.08650v1 [cs.CL])\nAbstract: The capabilities of large language models (LLMs) have been successfully applied in the context of table representation learning. The recently proposed tabular language models have reported state-of-the-art results across various tasks for table interpretation. However, a closer look into the datasets commonly used for evaluation reveals an entity leakage from the train set into the test set. Motivated by this observation, we explore adversarial attacks that represent a more realistic inference setup. Adversarial attacks on text have been shown to greatly affect the performance of LLMs, but currently, there are no attacks targeting tabular language models. In this paper, we propose an evasive entity-swap attack for the column type annotation (CTA) task. Our CTA attack is the first black-box attack on tables, where we employ a similarity-based sampling strategy to generate adversarial examples. The experimental results show that the proposed attack generates up to a 70% drop in performan",
    "path": "papers/23/09/2309.08650.json",
    "total_tokens": 912,
    "translated_title": "对包含实体交换的表格进行的对抗攻击",
    "translated_abstract": "大型语言模型(LLMs)的能力已成功应用于表格表示学习的环境中。最近提出的表格语言模型在表格解释的各种任务上报告了最先进的结果。然而，对常用于评估的数据集进行仔细观察发现，训练集中的实体泄漏至测试集中。基于这一观察，我们探索了一种更真实的推理设置的对抗攻击。已经证明，对文本的对抗攻击极大地影响了LLMs的性能，但目前尚无攻击针对表格语言模型。在本文中，我们提出了一种针对列类型注释(CTA)任务的逃避性实体交换攻击。我们的CTA攻击是对表格的第一次黑盒攻击，我们采用基于相似度的采样策略生成对抗性示例。实验结果显示，所提出的攻击导致性能下降了高达70%。",
    "tldr": "本论文研究了对包含实体交换的表格进行的对抗攻击。作者提出了一种针对列类型注释任务的逃避性实体交换攻击，通过采用基于相似度的采样策略生成对抗性示例，成功导致性能下降了高达70%。",
    "en_tdlr": "This paper investigates adversarial attacks on tables with entity swap. The authors propose an evasive entity-swap attack for the column type annotation task, which successfully causes a drop in performance of up to 70% by employing a similarity-based sampling strategy to generate adversarial examples."
}