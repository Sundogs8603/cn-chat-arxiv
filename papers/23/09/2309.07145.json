{
    "title": "ETP: Learning Transferable ECG Representations via ECG-Text Pre-training. (arXiv:2309.07145v1 [eess.SP])",
    "abstract": "In the domain of cardiovascular healthcare, the Electrocardiogram (ECG) serves as a critical, non-invasive diagnostic tool. Although recent strides in self-supervised learning (SSL) have been promising for ECG representation learning, these techniques often require annotated samples and struggle with classes not present in the fine-tuning stages. To address these limitations, we introduce ECG-Text Pre-training (ETP), an innovative framework designed to learn cross-modal representations that link ECG signals with textual reports. For the first time, this framework leverages the zero-shot classification task in the ECG domain. ETP employs an ECG encoder along with a pre-trained language model to align ECG signals with their corresponding textual reports. The proposed framework excels in both linear evaluation and zero-shot classification tasks, as demonstrated on the PTB-XL and CPSC2018 datasets, showcasing its ability for robust and generalizable cross-modal ECG feature learning.",
    "link": "http://arxiv.org/abs/2309.07145",
    "context": "Title: ETP: Learning Transferable ECG Representations via ECG-Text Pre-training. (arXiv:2309.07145v1 [eess.SP])\nAbstract: In the domain of cardiovascular healthcare, the Electrocardiogram (ECG) serves as a critical, non-invasive diagnostic tool. Although recent strides in self-supervised learning (SSL) have been promising for ECG representation learning, these techniques often require annotated samples and struggle with classes not present in the fine-tuning stages. To address these limitations, we introduce ECG-Text Pre-training (ETP), an innovative framework designed to learn cross-modal representations that link ECG signals with textual reports. For the first time, this framework leverages the zero-shot classification task in the ECG domain. ETP employs an ECG encoder along with a pre-trained language model to align ECG signals with their corresponding textual reports. The proposed framework excels in both linear evaluation and zero-shot classification tasks, as demonstrated on the PTB-XL and CPSC2018 datasets, showcasing its ability for robust and generalizable cross-modal ECG feature learning.",
    "path": "papers/23/09/2309.07145.json",
    "total_tokens": 965,
    "translated_title": "ETP: 通过ECG-Text预训练学习可迁移的ECG表示",
    "translated_abstract": "在心血管保健领域中，心电图（ECG）作为一种重要的非侵入性诊断工具。尽管近年来自我监督学习（SSL）在ECG表示学习方面取得了进展，但这些技术通常需要注释样本，并且在微调阶段难以处理不存在的类别。为了解决这些限制，我们引入了ECG-Text预训练（ETP），这是一种创新的框架，旨在学习将ECG信号与文本报告联系起来的跨模态表示。该框架首次在ECG领域中利用了零样本分类任务。ETP使用ECG编码器和预训练语言模型来将ECG信号与其相应的文本报告对齐。所提出的框架在线性评估和零样本分类任务中表现出色，在PTB-XL和CPSC2018数据集上的实验结果表明其具有鲁棒且可迁移的跨模态ECG特征学习能力。",
    "tldr": "本论文介绍了ECG-Text预训练（ETP）框架，它通过将ECG信号与文本报告对齐，实现了跨模态ECG特征学习。ETP在线性评估和零样本分类任务中表现出色，并展示了其在跨模态ECG特征学习方面的鲁棒性和可迁移性。",
    "en_tdlr": "This paper introduces ECG-Text pre-training (ETP), a framework that achieves cross-modal ECG feature learning by aligning ECG signals and textual reports. ETP performs well in both linear evaluation and zero-shot classification tasks, demonstrating its robustness and transferability in cross-modal ECG feature learning."
}