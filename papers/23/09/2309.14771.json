{
    "title": "Boosting In-Context Learning with Factual Knowledge. (arXiv:2309.14771v1 [cs.CL])",
    "abstract": "In-Context Learning (ICL) over Large language models (LLMs) aims at solving previously unseen tasks by conditioning on a few training examples, eliminating the need for parameter updates and achieving competitive performance. In this paper, we demonstrate that factual knowledge is imperative for the performance of ICL in three core facets, i.e., the inherent knowledge learned in LLMs, the factual knowledge derived from the selected in-context examples, and the knowledge biases in LLMs for output generation. To unleash the power of LLMs in few-shot learning scenarios, we introduce a novel Knowledgeable In-Context Tuning (KICT) framework to further improve the performance of ICL: 1) injecting factual knowledge to LLMs during continual self-supervised pre-training, 2) judiciously selecting the examples with high knowledge relevance, and 3) calibrating the prediction results based on prior knowledge. We evaluate the proposed approaches on auto-regressive LLMs (e.g., GPT-style models) over ",
    "link": "http://arxiv.org/abs/2309.14771",
    "context": "Title: Boosting In-Context Learning with Factual Knowledge. (arXiv:2309.14771v1 [cs.CL])\nAbstract: In-Context Learning (ICL) over Large language models (LLMs) aims at solving previously unseen tasks by conditioning on a few training examples, eliminating the need for parameter updates and achieving competitive performance. In this paper, we demonstrate that factual knowledge is imperative for the performance of ICL in three core facets, i.e., the inherent knowledge learned in LLMs, the factual knowledge derived from the selected in-context examples, and the knowledge biases in LLMs for output generation. To unleash the power of LLMs in few-shot learning scenarios, we introduce a novel Knowledgeable In-Context Tuning (KICT) framework to further improve the performance of ICL: 1) injecting factual knowledge to LLMs during continual self-supervised pre-training, 2) judiciously selecting the examples with high knowledge relevance, and 3) calibrating the prediction results based on prior knowledge. We evaluate the proposed approaches on auto-regressive LLMs (e.g., GPT-style models) over ",
    "path": "papers/23/09/2309.14771.json",
    "total_tokens": 867,
    "translated_title": "使用事实知识提升上下文学习的效果",
    "translated_abstract": "在大型语言模型上下文学习（ICL）旨在通过依赖于少量的训练示例解决以前未见过的任务，从而消除参数更新的需求，并实现有竞争力的性能。本文展示了事实知识在ICL的性能中的重要性，包括在LLM中学到的固有知识，从所选的上下文示例中得出的事实知识，以及LLM在输出生成中的知识偏差。为了发挥LLM在少样本学习场景中的能力，我们引入了一种新的知识上下文调优（KICT）框架来进一步提高ICL的性能：1）在持续自监督预训练期间向LLM注入事实知识，2）谨慎选择具有高知识相关性的示例，3）根据先前的知识对预测结果进行校准。我们在自回归LLM（如GPT风格模型）上评估了所提出的方法。",
    "tldr": "本文研究了使用事实知识提升上下文学习的效果，并提出了一个新的知识上下文调优框架来改善学习性能。"
}