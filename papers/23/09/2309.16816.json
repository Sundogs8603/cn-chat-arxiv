{
    "title": "PROSE: Predicting Operators and Symbolic Expressions using Multimodal Transformers. (arXiv:2309.16816v1 [cs.LG])",
    "abstract": "Approximating nonlinear differential equations using a neural network provides a robust and efficient tool for various scientific computing tasks, including real-time predictions, inverse problems, optimal controls, and surrogate modeling. Previous works have focused on embedding dynamical systems into networks through two approaches: learning a single solution operator (i.e., the mapping from input parametrized functions to solutions) or learning the governing system of equations (i.e., the constitutive model relative to the state variables). Both of these approaches yield different representations for the same underlying data or function. Additionally, observing that families of differential equations often share key characteristics, we seek one network representation across a wide range of equations. Our method, called Predicting Operators and Symbolic Expressions (PROSE), learns maps from multimodal inputs to multimodal outputs, capable of generating both numerical predictions and ",
    "link": "http://arxiv.org/abs/2309.16816",
    "context": "Title: PROSE: Predicting Operators and Symbolic Expressions using Multimodal Transformers. (arXiv:2309.16816v1 [cs.LG])\nAbstract: Approximating nonlinear differential equations using a neural network provides a robust and efficient tool for various scientific computing tasks, including real-time predictions, inverse problems, optimal controls, and surrogate modeling. Previous works have focused on embedding dynamical systems into networks through two approaches: learning a single solution operator (i.e., the mapping from input parametrized functions to solutions) or learning the governing system of equations (i.e., the constitutive model relative to the state variables). Both of these approaches yield different representations for the same underlying data or function. Additionally, observing that families of differential equations often share key characteristics, we seek one network representation across a wide range of equations. Our method, called Predicting Operators and Symbolic Expressions (PROSE), learns maps from multimodal inputs to multimodal outputs, capable of generating both numerical predictions and ",
    "path": "papers/23/09/2309.16816.json",
    "total_tokens": 787,
    "translated_title": "PROSE: 使用多模态Transformer预测运算符和符号表达式",
    "translated_abstract": "使用神经网络近似非线性微分方程为各种科学计算任务提供了稳健高效的工具，包括实时预测、反问题、最优控制和代理模拟。以前的研究集中于通过两种方法将动力学系统嵌入到网络中：学习单个解算符（即从输入参数化函数映射到解的映射）或学习控制系统（即相对于状态变量的构成模型）。这两种方法都会得到相同基础数据或函数的不同表示。此外，鉴于一组微分方程经常具有共同的特征，我们寻求在广泛的方程中获得一个网络表示。我们的方法称为预测运算符和符号表达式（PROSE），它学习从多模态输入到多模态输出的映射，能够生成数值预测和...",
    "tldr": "PROSE是一种能够从多模态输入到多模态输出的网络表示方法，可以用于预测非线性微分方程的数值解和符号表达式。",
    "en_tdlr": "PROSE is a network representation method that can generate both numerical predictions and symbolic expressions for nonlinear differential equations by learning maps from multimodal inputs to multimodal outputs."
}