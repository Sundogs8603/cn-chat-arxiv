{
    "title": "Learning to Predict Concept Ordering for Common Sense Generation. (arXiv:2309.06363v1 [cs.CL])",
    "abstract": "Prior work has shown that the ordering in which concepts are shown to a commonsense generator plays an important role, affecting the quality of the generated sentence. However, it remains a challenge to determine the optimal ordering of a given set of concepts such that a natural sentence covering all the concepts could be generated from a pretrained generator. To understand the relationship between the ordering of the input concepts and the quality of the generated sentences, we conduct a systematic study considering multiple language models (LMs) and concept ordering strategies. We find that BART-large model consistently outperforms all other LMs considered in this study when fine-tuned using the ordering of concepts as they appear in CommonGen training data as measured using multiple evaluation metrics. Moreover, the larger GPT3-based large language models (LLMs) variants do not necessarily outperform much smaller LMs on this task, even when fine-tuned on task-specific training data",
    "link": "http://arxiv.org/abs/2309.06363",
    "context": "Title: Learning to Predict Concept Ordering for Common Sense Generation. (arXiv:2309.06363v1 [cs.CL])\nAbstract: Prior work has shown that the ordering in which concepts are shown to a commonsense generator plays an important role, affecting the quality of the generated sentence. However, it remains a challenge to determine the optimal ordering of a given set of concepts such that a natural sentence covering all the concepts could be generated from a pretrained generator. To understand the relationship between the ordering of the input concepts and the quality of the generated sentences, we conduct a systematic study considering multiple language models (LMs) and concept ordering strategies. We find that BART-large model consistently outperforms all other LMs considered in this study when fine-tuned using the ordering of concepts as they appear in CommonGen training data as measured using multiple evaluation metrics. Moreover, the larger GPT3-based large language models (LLMs) variants do not necessarily outperform much smaller LMs on this task, even when fine-tuned on task-specific training data",
    "path": "papers/23/09/2309.06363.json",
    "total_tokens": 893,
    "translated_title": "学习预测常识生成的概念排序",
    "translated_abstract": "先前的研究表明，向常识生成器展示概念的顺序对生成的句子质量起着重要作用。然而，确定给定一组概念的最佳顺序以便从预训练生成器生成包含所有概念的自然句子仍然是一个挑战。为了了解输入概念的排序与生成句子质量之间的关系，我们进行了一项系统研究，考虑了多种语言模型和概念排序策略。我们发现，在使用CommonGen训练数据中概念的出现顺序作为度量标准进行微调时，BART-large模型始终优于本研究中考虑的所有其他语言模型。此外，即使在针对特定任务的训练数据上进行微调，较大的基于GPT3的大型语言模型（LLM）变体在这个任务上并不一定能胜过更小的语言模型。",
    "tldr": "之前的研究发现，向常识生成器展示概念的顺序对生成句子的质量起重要作用。本研究通过考虑多种语言模型和概念排序策略，发现BART-large模型在使用CommonGen训练数据进行微调时表现最佳。",
    "en_tdlr": "Prior research has shown that the ordering in which concepts are presented to a commonsense generator is crucial for sentence quality. This study found that the BART-large model outperforms other language models when fine-tuned using the concept ordering in the CommonGen training data."
}