{
    "title": "ORL-AUDITOR: Dataset Auditing in Offline Deep Reinforcement Learning. (arXiv:2309.03081v1 [cs.CR])",
    "abstract": "Data is a critical asset in AI, as high-quality datasets can significantly improve the performance of machine learning models. In safety-critical domains such as autonomous vehicles, offline deep reinforcement learning (offline DRL) is frequently used to train models on pre-collected datasets, as opposed to training these models by interacting with the real-world environment as the online DRL. To support the development of these models, many institutions make datasets publicly available with opensource licenses, but these datasets are at risk of potential misuse or infringement. Injecting watermarks to the dataset may protect the intellectual property of the data, but it cannot handle datasets that have already been published and is infeasible to be altered afterward. Other existing solutions, such as dataset inference and membership inference, do not work well in the offline DRL scenario due to the diverse model behavior characteristics and offline setting constraints. In this paper, ",
    "link": "http://arxiv.org/abs/2309.03081",
    "context": "Title: ORL-AUDITOR: Dataset Auditing in Offline Deep Reinforcement Learning. (arXiv:2309.03081v1 [cs.CR])\nAbstract: Data is a critical asset in AI, as high-quality datasets can significantly improve the performance of machine learning models. In safety-critical domains such as autonomous vehicles, offline deep reinforcement learning (offline DRL) is frequently used to train models on pre-collected datasets, as opposed to training these models by interacting with the real-world environment as the online DRL. To support the development of these models, many institutions make datasets publicly available with opensource licenses, but these datasets are at risk of potential misuse or infringement. Injecting watermarks to the dataset may protect the intellectual property of the data, but it cannot handle datasets that have already been published and is infeasible to be altered afterward. Other existing solutions, such as dataset inference and membership inference, do not work well in the offline DRL scenario due to the diverse model behavior characteristics and offline setting constraints. In this paper, ",
    "path": "papers/23/09/2309.03081.json",
    "total_tokens": 829,
    "translated_title": "ORL-AUDITOR：深度强化学习离线数据集审核",
    "translated_abstract": "在AI领域，数据是一项重要的资产，高质量的数据集可以显著提升机器学习模型的性能。在自动驾驶等安全关键领域中，离线深度强化学习（离线DRL）经常用于在预先收集的数据集上训练模型，而不是通过与真实环境进行交互来训练这些模型的在线DRL。为了支持这些模型的开发，许多机构以开源许可的形式公开了数据集，但这些数据集存在潜在的滥用或侵权风险。向数据集中添加水印可以保护数据的知识产权，但无法处理已经发布的数据集，且后续修改是不可行的。其他现有的解决方案，如数据集推断和成员推断，在离线DRL场景下由于模型行为特征多样和离线环境限制而不起作用。本文中，",
    "tldr": "ORL-AUDITOR是一种用于审核离线深度强化学习数据集的方法，以保护知识产权和防止滥用或侵权风险。"
}