{
    "title": "Comparing Llama-2 and GPT-3 LLMs for HPC kernels generation. (arXiv:2309.07103v1 [cs.SE])",
    "abstract": "We evaluate the use of the open-source Llama-2 model for generating well-known, high-performance computing kernels (e.g., AXPY, GEMV, GEMM) on different parallel programming models and languages (e.g., C++: OpenMP, OpenMP Offload, OpenACC, CUDA, HIP; Fortran: OpenMP, OpenMP Offload, OpenACC; Python: numpy, Numba, pyCUDA, cuPy; and Julia: Threads, CUDA.jl, AMDGPU.jl). We built upon our previous work that is based on the OpenAI Codex, which is a descendant of GPT-3, to generate similar kernels with simple prompts via GitHub Copilot. Our goal is to compare the accuracy of Llama-2 and our original GPT-3 baseline by using a similar metric. Llama-2 has a simplified model that shows competitive or even superior accuracy. We also report on the differences between these foundational large language models as generative AI continues to redefine human-computer interactions. Overall, Copilot generates codes that are more reliable but less optimized, whereas codes generated by Llama-2 are less relia",
    "link": "http://arxiv.org/abs/2309.07103",
    "context": "Title: Comparing Llama-2 and GPT-3 LLMs for HPC kernels generation. (arXiv:2309.07103v1 [cs.SE])\nAbstract: We evaluate the use of the open-source Llama-2 model for generating well-known, high-performance computing kernels (e.g., AXPY, GEMV, GEMM) on different parallel programming models and languages (e.g., C++: OpenMP, OpenMP Offload, OpenACC, CUDA, HIP; Fortran: OpenMP, OpenMP Offload, OpenACC; Python: numpy, Numba, pyCUDA, cuPy; and Julia: Threads, CUDA.jl, AMDGPU.jl). We built upon our previous work that is based on the OpenAI Codex, which is a descendant of GPT-3, to generate similar kernels with simple prompts via GitHub Copilot. Our goal is to compare the accuracy of Llama-2 and our original GPT-3 baseline by using a similar metric. Llama-2 has a simplified model that shows competitive or even superior accuracy. We also report on the differences between these foundational large language models as generative AI continues to redefine human-computer interactions. Overall, Copilot generates codes that are more reliable but less optimized, whereas codes generated by Llama-2 are less relia",
    "path": "papers/23/09/2309.07103.json",
    "total_tokens": 910,
    "translated_title": "比较Llama-2和GPT-3在HPC核心生成方面的效果",
    "translated_abstract": "我们评估了开源Llama-2模型在不同并行编程模型和语言上生成著名高性能计算核心（如AXPY，GEMV，GEMM）的使用。我们基于我们之前的工作，使用基于OpenAI Codex的简单提示通过GitHub Copilot生成类似的核心。我们的目标是通过使用类似的指标比较Llama-2和我们原始的GPT-3基准的准确性。Llama-2具有简化的模型，显示出有竞争力甚至更高的准确性。我们还报告了这些基础大型语言模型之间的差异，因为生成式人工智能继续重新定义人机交互。总体而言，Copilot生成的代码更可靠但优化程度较低，而Llama-2生成的代码则更可靠。",
    "tldr": "本研究评估了Llama-2和GPT-3在生成HPC核心方面的性能，并发现Llama-2在准确性方面具有竞争力。同时，通过使用GitHub Copilot生成的代码更可靠，而Llama-2生成的代码更可靠。"
}