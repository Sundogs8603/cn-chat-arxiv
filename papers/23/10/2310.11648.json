{
    "title": "Zero-shot Faithfulness Evaluation for Text Summarization with Foundation Language Model. (arXiv:2310.11648v1 [cs.CL])",
    "abstract": "Despite tremendous improvements in natural language generation, summarization models still suffer from the unfaithfulness issue. Previous work evaluates faithfulness either using models trained on the other tasks or in-domain synthetic data, or prompting a large model such as ChatGPT. This paper proposes to do zero-shot faithfulness evaluation simply with a moderately-sized foundation language model. We introduce a new metric FFLM, which is a combination of probability changes based on the intuition that prefixing a piece of text that is consistent with the output will increase the probability of predicting the output. Experiments show that FFLM performs competitively with or even outperforms ChatGPT on both inconsistency detection and faithfulness rating with 24x fewer parameters. FFLM also achieves improvements over other strong baselines.",
    "link": "http://arxiv.org/abs/2310.11648",
    "context": "Title: Zero-shot Faithfulness Evaluation for Text Summarization with Foundation Language Model. (arXiv:2310.11648v1 [cs.CL])\nAbstract: Despite tremendous improvements in natural language generation, summarization models still suffer from the unfaithfulness issue. Previous work evaluates faithfulness either using models trained on the other tasks or in-domain synthetic data, or prompting a large model such as ChatGPT. This paper proposes to do zero-shot faithfulness evaluation simply with a moderately-sized foundation language model. We introduce a new metric FFLM, which is a combination of probability changes based on the intuition that prefixing a piece of text that is consistent with the output will increase the probability of predicting the output. Experiments show that FFLM performs competitively with or even outperforms ChatGPT on both inconsistency detection and faithfulness rating with 24x fewer parameters. FFLM also achieves improvements over other strong baselines.",
    "path": "papers/23/10/2310.11648.json",
    "total_tokens": 846,
    "translated_title": "用基础语言模型进行零样本忠实性评估的文本摘要研究",
    "translated_abstract": "尽管自然语言生成取得了巨大的进步，但摘要模型仍然存在忠实性问题。先前的研究要么使用在其他任务上训练的模型或领域内的合成数据来评估忠实性，要么使用类似ChatGPT这样的大型模型进行评估。本文提出使用一个中等大小的基础语言模型进行零样本忠实性评估。我们引入了一种新的度量标准FFLM，它是基于概率变化的组合，这种组合是基于一个观点：在输出的文本前加上与输出一致的一段文本将增加预测输出的概率。实验证明，FFLM在不一致性检测和忠实性评级上与ChatGPT相比表现出色，且参数数量减少24倍。FFLM还在其他强基准上取得了改进。",
    "tldr": "本文提出了使用基础语言模型进行零样本忠实性评估的方法，并引入了一种新的度量标准FFLM。实验证明，FFLM在不一致性检测和忠实性评级方面表现优异，并且参数数量减少了24倍。"
}