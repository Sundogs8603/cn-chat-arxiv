{
    "title": "Spline-based neural network interatomic potentials: blending classical and machine learning models. (arXiv:2310.02904v1 [cond-mat.mtrl-sci])",
    "abstract": "While machine learning (ML) interatomic potentials (IPs) are able to achieve accuracies nearing the level of noise inherent in the first-principles data to which they are trained, it remains to be shown if their increased complexities are strictly necessary for constructing high-quality IPs. In this work, we introduce a new MLIP framework which blends the simplicity of spline-based MEAM (s-MEAM) potentials with the flexibility of a neural network (NN) architecture. The proposed framework, which we call the spline-based neural network potential (s-NNP), is a simplified version of the traditional NNP that can be used to describe complex datasets in a computationally efficient manner. We demonstrate how this framework can be used to probe the boundary between classical and ML IPs, highlighting the benefits of key architectural changes. Furthermore, we show that using spline filters for encoding atomic environments results in a readily interpreted embedding layer which can be coupled with ",
    "link": "http://arxiv.org/abs/2310.02904",
    "context": "Title: Spline-based neural network interatomic potentials: blending classical and machine learning models. (arXiv:2310.02904v1 [cond-mat.mtrl-sci])\nAbstract: While machine learning (ML) interatomic potentials (IPs) are able to achieve accuracies nearing the level of noise inherent in the first-principles data to which they are trained, it remains to be shown if their increased complexities are strictly necessary for constructing high-quality IPs. In this work, we introduce a new MLIP framework which blends the simplicity of spline-based MEAM (s-MEAM) potentials with the flexibility of a neural network (NN) architecture. The proposed framework, which we call the spline-based neural network potential (s-NNP), is a simplified version of the traditional NNP that can be used to describe complex datasets in a computationally efficient manner. We demonstrate how this framework can be used to probe the boundary between classical and ML IPs, highlighting the benefits of key architectural changes. Furthermore, we show that using spline filters for encoding atomic environments results in a readily interpreted embedding layer which can be coupled with ",
    "path": "papers/23/10/2310.02904.json",
    "total_tokens": 1036,
    "translated_title": "基于样条函数的神经网络原子间势: 融合经典与机器学习模型",
    "translated_abstract": "虽然机器学习(Machine Learning, ML)原子间势(Interatomic Potentials, IPs)在训练时能够达到接近第一原理数据固有噪音水平的精确度，但还需要展示它们的增加复杂性是否严格必要来构建高质量的IPs。在这项工作中，我们引入了一种新的MLIP框架，它将基于样条函数的MEAM (s-MEAM)原子间势的简单性与神经网络(NN)架构的灵活性相结合。提出的框架被称为基于样条函数的神经网络势(s-NNP)，是传统NNP的简化版本，可以用于以高效的方式描述复杂数据集。我们演示了如何使用这个框架来探索经典和ML IPs之间的边界，并突出了关键架构变化的好处。此外，我们还展示了使用样条滤波器来编码原子环境会产生一个容易解释的嵌入层，可以与其他模型进行耦合。",
    "tldr": "本研究引入了一种新的基于样条函数的神经网络势(s-NNP)框架，将简单性的s-MEAM原子间势与神经网络的灵活性相结合，用于构建高质量的IPs。该框架能够突破经典和ML IPs之间的界限，并通过关键架构变化提供更好的性能。同时，使用样条滤波器来编码原子环境，可以产生容易解释的嵌入层。",
    "en_tdlr": "This study introduces a new framework called spline-based neural network potential (s-NNP), which combines the simplicity of spline-based MEAM potentials with the flexibility of a neural network architecture, to construct high-quality interatomic potentials (IPs). The framework breaks the boundaries between classical and ML IPs, offering improved performance through key architectural changes. Additionally, using spline filters to encode atomic environments results in an interpretable embedding layer."
}