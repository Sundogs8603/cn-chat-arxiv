{
    "title": "GPCR-BERT: Interpreting Sequential Design of G Protein Coupled Receptors Using Protein Language Models. (arXiv:2310.19915v1 [cs.LG])",
    "abstract": "With the rise of Transformers and Large Language Models (LLMs) in Chemistry and Biology, new avenues for the design and understanding of therapeutics have opened up to the scientific community. Protein sequences can be modeled as language and can take advantage of recent advances in LLMs, specifically with the abundance of our access to the protein sequence datasets. In this paper, we developed the GPCR-BERT model for understanding the sequential design of G Protein-Coupled Receptors (GPCRs). GPCRs are the target of over one-third of FDA-approved pharmaceuticals. However, there is a lack of comprehensive understanding regarding the relationship between amino acid sequence, ligand selectivity, and conformational motifs (such as NPxxY, CWxP, E/DRY). By utilizing the pre-trained protein model (Prot-Bert) and fine-tuning with prediction tasks of variations in the motifs, we were able to shed light on several relationships between residues in the binding pocket and some of the conserved mot",
    "link": "http://arxiv.org/abs/2310.19915",
    "context": "Title: GPCR-BERT: Interpreting Sequential Design of G Protein Coupled Receptors Using Protein Language Models. (arXiv:2310.19915v1 [cs.LG])\nAbstract: With the rise of Transformers and Large Language Models (LLMs) in Chemistry and Biology, new avenues for the design and understanding of therapeutics have opened up to the scientific community. Protein sequences can be modeled as language and can take advantage of recent advances in LLMs, specifically with the abundance of our access to the protein sequence datasets. In this paper, we developed the GPCR-BERT model for understanding the sequential design of G Protein-Coupled Receptors (GPCRs). GPCRs are the target of over one-third of FDA-approved pharmaceuticals. However, there is a lack of comprehensive understanding regarding the relationship between amino acid sequence, ligand selectivity, and conformational motifs (such as NPxxY, CWxP, E/DRY). By utilizing the pre-trained protein model (Prot-Bert) and fine-tuning with prediction tasks of variations in the motifs, we were able to shed light on several relationships between residues in the binding pocket and some of the conserved mot",
    "path": "papers/23/10/2310.19915.json",
    "total_tokens": 994,
    "translated_title": "GPCR-BERT:使用蛋白质语言模型解释G蛋白偶联受体(GPCR)的顺序设计",
    "translated_abstract": "随着化学和生物学中Transformer和大型语言模型(LLMs)的兴起，对治疗方法的设计和理解的科学界开辟了新的途径。蛋白质序列可以被建模为语言，并可以利用最近在LLMs中取得的进展，特别是在我们对蛋白质序列数据集的广泛访问方面。在本文中，我们开发了GPCR-BERT模型，用于理解G蛋白偶联受体(GPCRs)的顺序设计。GPCRs是FDA批准的药物中超过三分之一的靶点。然而，关于氨基酸序列、配体选择性和构象基序(如NPxxY、CWxP、E/DRY)之间的关系缺乏全面的理解。通过利用预训练的蛋白质模型(Prot-Bert)并通过变异预测任务对基序的微调，我们能够揭示结合口袋中残基之间的几种关系和一些保守的基序。",
    "tldr": "本文提出了一种名为GPCR-BERT的模型，使用蛋白质语言模型解释了G蛋白偶联受体(GPCR)的顺序设计。通过利用预训练的蛋白质模型和微调预测任务，我们揭示了结合口袋中残基之间的关系和一些保守的基序。"
}