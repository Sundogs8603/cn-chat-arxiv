{
    "title": "Auto-Instruct: Automatic Instruction Generation and Ranking for Black-Box Language Models. (arXiv:2310.13127v1 [cs.CL])",
    "abstract": "Large language models (LLMs) can perform a wide range of tasks by following natural language instructions, without the necessity of task-specific fine-tuning. Unfortunately, the performance of LLMs is greatly influenced by the quality of these instructions, and manually writing effective instructions for each task is a laborious and subjective process. In this paper, we introduce Auto-Instruct, a novel method to automatically improve the quality of instructions provided to LLMs. Our method leverages the inherent generative ability of LLMs to produce diverse candidate instructions for a given task, and then ranks them using a scoring model trained on a variety of 575 existing NLP tasks. In experiments on 118 out-of-domain tasks, Auto-Instruct surpasses both human-written instructions and existing baselines of LLM-generated instructions. Furthermore, our method exhibits notable generalizability even with other LLMs that are not incorporated into its training process.",
    "link": "http://arxiv.org/abs/2310.13127",
    "context": "Title: Auto-Instruct: Automatic Instruction Generation and Ranking for Black-Box Language Models. (arXiv:2310.13127v1 [cs.CL])\nAbstract: Large language models (LLMs) can perform a wide range of tasks by following natural language instructions, without the necessity of task-specific fine-tuning. Unfortunately, the performance of LLMs is greatly influenced by the quality of these instructions, and manually writing effective instructions for each task is a laborious and subjective process. In this paper, we introduce Auto-Instruct, a novel method to automatically improve the quality of instructions provided to LLMs. Our method leverages the inherent generative ability of LLMs to produce diverse candidate instructions for a given task, and then ranks them using a scoring model trained on a variety of 575 existing NLP tasks. In experiments on 118 out-of-domain tasks, Auto-Instruct surpasses both human-written instructions and existing baselines of LLM-generated instructions. Furthermore, our method exhibits notable generalizability even with other LLMs that are not incorporated into its training process.",
    "path": "papers/23/10/2310.13127.json",
    "total_tokens": 930,
    "translated_title": "Auto-Instruct: 黑盒语言模型的自动指令生成与排序",
    "translated_abstract": "大型语言模型（LLMs）可以通过遵循自然语言指令执行各种任务，无需进行特定任务的微调。然而，LLMs的性能很大程度上受到指令质量的影响，而为每个任务手动编写有效的指令是一项繁琐而主观的过程。在本文中，我们介绍了Auto-Instruct，一种新颖的方法，可自动提高提供给LLMs的指令的质量。我们的方法利用LLMs的内在生成能力为给定任务生成多样的候选指令，然后使用在多种575个现有NLP任务上训练的评分模型对它们进行排序。在118个领域外任务的实验中，Auto-Instruct超越了人工编写的指令和现有的LLM生成的指令基线。此外，我们的方法表现出显著的泛化能力，即使使用其他未包括在其训练过程中的LLMs也如此。",
    "tldr": "Auto-Instruct是一种自动提高大型语言模型（LLMs）指令质量的方法，通过利用LLMs的生成能力产生多样的候选指令，并使用评分模型对其进行排序。在多个实验中表现出优于人工编写的指令和现有LLM生成指令基线的性能，且具有良好的泛化能力。"
}