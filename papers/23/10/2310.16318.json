{
    "title": "Modality-Agnostic Self-Supervised Learning with Meta-Learned Masked Auto-Encoder. (arXiv:2310.16318v1 [cs.LG])",
    "abstract": "Despite its practical importance across a wide range of modalities, recent advances in self-supervised learning (SSL) have been primarily focused on a few well-curated domains, e.g., vision and language, often relying on their domain-specific knowledge. For example, Masked Auto-Encoder (MAE) has become one of the popular architectures in these domains, but less has explored its potential in other modalities. In this paper, we develop MAE as a unified, modality-agnostic SSL framework. In turn, we argue meta-learning as a key to interpreting MAE as a modality-agnostic learner, and propose enhancements to MAE from the motivation to jointly improve its SSL across diverse modalities, coined MetaMAE as a result. Our key idea is to view the mask reconstruction of MAE as a meta-learning task: masked tokens are predicted by adapting the Transformer meta-learner through the amortization of unmasked tokens. Based on this novel interpretation, we propose to integrate two advanced meta-learning tec",
    "link": "http://arxiv.org/abs/2310.16318",
    "context": "Title: Modality-Agnostic Self-Supervised Learning with Meta-Learned Masked Auto-Encoder. (arXiv:2310.16318v1 [cs.LG])\nAbstract: Despite its practical importance across a wide range of modalities, recent advances in self-supervised learning (SSL) have been primarily focused on a few well-curated domains, e.g., vision and language, often relying on their domain-specific knowledge. For example, Masked Auto-Encoder (MAE) has become one of the popular architectures in these domains, but less has explored its potential in other modalities. In this paper, we develop MAE as a unified, modality-agnostic SSL framework. In turn, we argue meta-learning as a key to interpreting MAE as a modality-agnostic learner, and propose enhancements to MAE from the motivation to jointly improve its SSL across diverse modalities, coined MetaMAE as a result. Our key idea is to view the mask reconstruction of MAE as a meta-learning task: masked tokens are predicted by adapting the Transformer meta-learner through the amortization of unmasked tokens. Based on this novel interpretation, we propose to integrate two advanced meta-learning tec",
    "path": "papers/23/10/2310.16318.json",
    "total_tokens": 974,
    "translated_title": "一种与语言形式无关的元学习蒙版自监督学习方法",
    "translated_abstract": "尽管自监督学习在各种语言形式中具有实际重要性，但近期的研究主要集中在少数经过精选的领域，如视觉和语言，并且常常依赖于特定领域的知识。本文中，我们将蒙版自编码器（MAE）作为一个统一的、与语言形式无关的自监督学习框架进行了拓展。我们认为元学习是解释MAE作为与语言形式无关学习器的关键，并从共同提高其在多种语言形式上的自监督学习能力的动机出发，提出了MetaMAE框架。我们的核心思想是将MAE的蒙版重构视为一个元学习任务：通过对未蒙版标记进行自适应来预测蒙版标记，从而通过转换器元学习实现对其进行总误差减小。基于这一新的解释，我们提出了将两种高级元学习技术结合的方法。",
    "tldr": "本文提出了一种与语言形式无关的元学习蒙版自监督学习框架MetaMAE，通过将蒙版自编码器（MAE）的蒙版重构视为元学习任务，并采用转换器元学习技术来改进MAE的自监督学习在不同语言形式上的表现。",
    "en_tdlr": "This paper introduces MetaMAE, a modality-agnostic self-supervised learning framework, which enhances the Masked Auto-Encoder (MAE) by treating the mask reconstruction as a meta-learning task and using Transformer meta-learning technique to improve its self-supervised learning performance across different modalities."
}