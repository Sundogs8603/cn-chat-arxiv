{
    "title": "Geometrically Aligned Transfer Encoder for Inductive Transfer in Regression Tasks. (arXiv:2310.06369v1 [cs.AI])",
    "abstract": "Transfer learning is a crucial technique for handling a small amount of data that is potentially related to other abundant data. However, most of the existing methods are focused on classification tasks using images and language datasets. Therefore, in order to expand the transfer learning scheme to regression tasks, we propose a novel transfer technique based on differential geometry, namely the Geometrically Aligned Transfer Encoder (GATE). In this method, we interpret the latent vectors from the model to exist on a Riemannian curved manifold. We find a proper diffeomorphism between pairs of tasks to ensure that every arbitrary point maps to a locally flat coordinate in the overlapping region, allowing the transfer of knowledge from the source to the target data. This also serves as an effective regularizer for the model to behave in extrapolation regions. In this article, we demonstrate that GATE outperforms conventional methods and exhibits stable behavior in both the latent space ",
    "link": "http://arxiv.org/abs/2310.06369",
    "context": "Title: Geometrically Aligned Transfer Encoder for Inductive Transfer in Regression Tasks. (arXiv:2310.06369v1 [cs.AI])\nAbstract: Transfer learning is a crucial technique for handling a small amount of data that is potentially related to other abundant data. However, most of the existing methods are focused on classification tasks using images and language datasets. Therefore, in order to expand the transfer learning scheme to regression tasks, we propose a novel transfer technique based on differential geometry, namely the Geometrically Aligned Transfer Encoder (GATE). In this method, we interpret the latent vectors from the model to exist on a Riemannian curved manifold. We find a proper diffeomorphism between pairs of tasks to ensure that every arbitrary point maps to a locally flat coordinate in the overlapping region, allowing the transfer of knowledge from the source to the target data. This also serves as an effective regularizer for the model to behave in extrapolation regions. In this article, we demonstrate that GATE outperforms conventional methods and exhibits stable behavior in both the latent space ",
    "path": "papers/23/10/2310.06369.json",
    "total_tokens": 889,
    "translated_title": "几何对齐转移编码器用于归纳转移回归任务",
    "translated_abstract": "转移学习是处理可能与其他丰富数据相关的少量数据的关键技术。然而，现有大部分方法都集中在使用图像和语言数据集的分类任务上。因此，为了扩展转移学习方案到回归任务，我们提出了一种基于微分几何的新型转移技术，即几何对齐转移编码器（GATE）。在这种方法中，我们将模型的潜在向量解释为存在于黎曼曲面上的。我们找到了一种适当的微分同胚，确保每个任意点映射到重叠区域中的局部平坦坐标，从而实现从源数据到目标数据的知识转移。这也作为模型在外推区域行为良好的有效正则化器。在本文中，我们证明了GATE优于传统方法，并在潜在空间中表现出稳定的行为。",
    "tldr": "本文提出了一种基于微分几何的转移学习技术，通过将模型的潜在向量映射到黎曼曲面上的局部平坦坐标，实现在回归任务中的知识转移，并展示了该方法的优越性能和稳定行为。",
    "en_tdlr": "This paper introduces a transfer learning technique based on differential geometry, which maps the latent vectors of the model to locally flat coordinates on a Riemannian manifold, enabling knowledge transfer in regression tasks. The proposed method outperforms conventional methods and exhibits stable behavior in the latent space."
}