{
    "title": "AllTogether: Investigating the Efficacy of Spliced Prompt for Web Navigation using Large Language Models. (arXiv:2310.18331v2 [cs.CL] UPDATED)",
    "abstract": "Large Language Models (LLMs) have emerged as promising agents for web navigation tasks, interpreting objectives and interacting with web pages. However, the efficiency of spliced prompts for such tasks remains underexplored. We introduces AllTogether, a standardized prompt template that enhances task context representation, thereby improving LLMs' performance in HTML-based web navigation. We evaluate the efficacy of this approach through prompt learning and instruction finetuning based on open-source Llama-2 and API-accessible GPT models. Our results reveal that models like GPT-4 outperform smaller models in web navigation tasks. Additionally, we find that the length of HTML snippet and history trajectory significantly influence performance, and prior step-by-step instructions prove less effective than real-time environmental feedback. Overall, we believe our work provides valuable insights for future research in LLM-driven web agents.",
    "link": "http://arxiv.org/abs/2310.18331",
    "context": "Title: AllTogether: Investigating the Efficacy of Spliced Prompt for Web Navigation using Large Language Models. (arXiv:2310.18331v2 [cs.CL] UPDATED)\nAbstract: Large Language Models (LLMs) have emerged as promising agents for web navigation tasks, interpreting objectives and interacting with web pages. However, the efficiency of spliced prompts for such tasks remains underexplored. We introduces AllTogether, a standardized prompt template that enhances task context representation, thereby improving LLMs' performance in HTML-based web navigation. We evaluate the efficacy of this approach through prompt learning and instruction finetuning based on open-source Llama-2 and API-accessible GPT models. Our results reveal that models like GPT-4 outperform smaller models in web navigation tasks. Additionally, we find that the length of HTML snippet and history trajectory significantly influence performance, and prior step-by-step instructions prove less effective than real-time environmental feedback. Overall, we believe our work provides valuable insights for future research in LLM-driven web agents.",
    "path": "papers/23/10/2310.18331.json",
    "total_tokens": 1017,
    "translated_title": "AllTogether：使用大型语言模型对使用拼接提示进行Web导航的效果进行研究",
    "translated_abstract": "大型语言模型（LLMs）已经成为用于Web导航任务的有前景的代理，它们解释目标并与Web页面进行交互。然而，这种任务中使用拼接提示的效果仍未得到充分探索。我们引入了AllTogether，一个标准化的提示模板，增强任务背景表示，从而提高LLMs在基于HTML的Web导航中的性能。我们通过来自开源Llama-2和可访问的GPT模型的提示学习和指令微调来评估这种方法的效果。我们的结果表明，像GPT-4这样的模型在Web导航任务中优于较小的模型。此外，我们发现HTML代码片段的长度和历史轨迹显著影响性能，并且之前的逐步指导比实时环境反馈更有效。总体而言，我们相信我们的工作为未来LLM驱动的Web代理研究提供了宝贵的见解。",
    "tldr": "AllTogether是一个标准化的提示模板，通过增强任务背景表示，提高了大型语言模型（LLMs）在基于HTML的Web导航中的性能。研究结果显示，像GPT-4这样的模型在这类任务中优于较小的模型，并且HTML代码片段的长度和历史轨迹对性能有显著影响。同时，在实时环境反馈方面，优于之前的逐步指导。这项工作为未来LLM驱动的Web代理研究提供了宝贵的见解。",
    "en_tdlr": "AllTogether is a standardized prompt template that enhances task context representation, improving the performance of large language models (LLMs) in HTML-based web navigation. The research findings show that models like GPT-4 outperform smaller models in this task, and the length of HTML snippets and history trajectory significantly affect performance. Moreover, real-time environmental feedback is more effective than previous step-by-step instructions. This work provides valuable insights for future research in LLM-driven web agents."
}