{
    "title": "A Bias-Variance-Covariance Decomposition of Kernel Scores for Generative Models. (arXiv:2310.05833v1 [cs.LG])",
    "abstract": "Generative models, like large language models, are becoming increasingly relevant in our daily lives, yet a theoretical framework to assess their generalization behavior and uncertainty does not exist. Particularly, the problem of uncertainty estimation is commonly solved in an ad-hoc manner and task dependent. For example, natural language approaches cannot be transferred to image generation. In this paper we introduce the first bias-variance-covariance decomposition for kernel scores and their associated entropy. We propose unbiased and consistent estimators for each quantity which only require generated samples but not the underlying model itself. As an application, we offer a generalization evaluation of diffusion models and discover how mode collapse of minority groups is a contrary phenomenon to overfitting. Further, we demonstrate that variance and predictive kernel entropy are viable measures of uncertainty for image, audio, and language generation. Specifically, our approach f",
    "link": "http://arxiv.org/abs/2310.05833",
    "context": "Title: A Bias-Variance-Covariance Decomposition of Kernel Scores for Generative Models. (arXiv:2310.05833v1 [cs.LG])\nAbstract: Generative models, like large language models, are becoming increasingly relevant in our daily lives, yet a theoretical framework to assess their generalization behavior and uncertainty does not exist. Particularly, the problem of uncertainty estimation is commonly solved in an ad-hoc manner and task dependent. For example, natural language approaches cannot be transferred to image generation. In this paper we introduce the first bias-variance-covariance decomposition for kernel scores and their associated entropy. We propose unbiased and consistent estimators for each quantity which only require generated samples but not the underlying model itself. As an application, we offer a generalization evaluation of diffusion models and discover how mode collapse of minority groups is a contrary phenomenon to overfitting. Further, we demonstrate that variance and predictive kernel entropy are viable measures of uncertainty for image, audio, and language generation. Specifically, our approach f",
    "path": "papers/23/10/2310.05833.json",
    "total_tokens": 961,
    "translated_title": "生成模型的核评分的偏差-方差-协方差分解",
    "translated_abstract": "生成模型在我们日常生活中变得越来越重要，然而，尚不存在一个理论框架来评估它们的泛化行为和不确定性。特别是，不确定性估计问题通常以一种特定任务的临时解决方案来解决。例如，自然语言方法不能应用于图像生成。在本文中，我们首次引入了用于核评分及其相关熵的偏差-方差-协方差分解。我们提出了每个量的无偏和一致估计器，只需要生成样本而不需要底层模型本身。作为应用，我们提供了扩散模型的泛化评估，并发现少数群体的模式坍缩是一种与过拟合相反的现象。此外，我们证明了方差和预测核熵是图像、音频和语言生成不确定性的可行度量。具体来说，我们的方法使得可以通过样本生成评估生成模型的泛化性能，并且发现了不同模型类型下的不确定性现象。",
    "tldr": "该论文首次引入了生成模型的核评分的偏差-方差-协方差分解，并提出了相应的量的无偏和一致估计器。通过应用在扩散模型上发现少数群体的模式坍缩是一种与过拟合相反的现象，并证明了方差和预测核熵是图像、音频和语言生成不确定性的可行度量。"
}