{
    "title": "Few-Shot In-Context Imitation Learning via Implicit Graph Alignment. (arXiv:2310.12238v1 [cs.RO])",
    "abstract": "Consider the following problem: given a few demonstrations of a task across a few different objects, how can a robot learn to perform that same task on new, previously unseen objects? This is challenging because the large variety of objects within a class makes it difficult to infer the task-relevant relationship between the new objects and the objects in the demonstrations. We address this by formulating imitation learning as a conditional alignment problem between graph representations of objects. Consequently, we show that this conditioning allows for in-context learning, where a robot can perform a task on a set of new objects immediately after the demonstrations, without any prior knowledge about the object class or any further training. In our experiments, we explore and validate our design choices, and we show that our method is highly effective for few-shot learning of several real-world, everyday tasks, whilst outperforming baselines. Videos are available on our project webpag",
    "link": "http://arxiv.org/abs/2310.12238",
    "context": "Title: Few-Shot In-Context Imitation Learning via Implicit Graph Alignment. (arXiv:2310.12238v1 [cs.RO])\nAbstract: Consider the following problem: given a few demonstrations of a task across a few different objects, how can a robot learn to perform that same task on new, previously unseen objects? This is challenging because the large variety of objects within a class makes it difficult to infer the task-relevant relationship between the new objects and the objects in the demonstrations. We address this by formulating imitation learning as a conditional alignment problem between graph representations of objects. Consequently, we show that this conditioning allows for in-context learning, where a robot can perform a task on a set of new objects immediately after the demonstrations, without any prior knowledge about the object class or any further training. In our experiments, we explore and validate our design choices, and we show that our method is highly effective for few-shot learning of several real-world, everyday tasks, whilst outperforming baselines. Videos are available on our project webpag",
    "path": "papers/23/10/2310.12238.json",
    "total_tokens": 876,
    "translated_title": "通过隐式图对齐进行少样本背景下的模仿学习",
    "translated_abstract": "考虑以下问题：给定在几个不同物体上进行的任务的少量演示，机器人如何学会在新的、之前未见过的物体上执行相同的任务？这是具有挑战性的，因为类别内多样的物体使得推断新物体与演示中的物体之间的任务相关关系变得困难。我们通过将模仿学习视为物体的图表示之间的条件对齐问题来解决这个问题。因此，我们展示了这种条件允许背景下的学习，在演示之后，机器人可以立即在一组新物体上执行任务，而无需关于物体类别的任何先验知识或任何进一步的训练。在实验中，我们探索和验证了我们的设计选择，并证明了我们的方法在几个真实世界的日常任务的少样本学习中非常有效，同时优于基线方法。可以在我们的项目网页上观看视频。",
    "tldr": "本文提出了一种少样本背景下的模仿学习方法，通过将模仿学习视为物体的图表示之间的条件对齐问题，实现了在没有先验知识或进一步训练的情况下，机器人可以在新的物体集上执行任务。",
    "en_tdlr": "This paper presents a few-shot imitation learning method that formulates imitation learning as a conditional alignment problem between graph representations of objects, enabling a robot to perform tasks on new objects without prior knowledge or further training."
}