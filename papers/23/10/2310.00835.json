{
    "title": "TRAM: Benchmarking Temporal Reasoning for Large Language Models. (arXiv:2310.00835v2 [cs.CL] UPDATED)",
    "abstract": "Reasoning about time is essential for understanding the nuances of events described in natural language. Previous research on this topic has been limited in scope, characterized by a lack of standardized benchmarks that would allow for consistent evaluations across different studies. In this paper, we introduce TRAM, a temporal reasoning benchmark composed of ten datasets, encompassing various temporal aspects of events such as order, arithmetic, frequency, and duration, designed to facilitate a comprehensive evaluation of the temporal reasoning capabilities of large language models (LLMs). We conduct an extensive evaluation using popular LLMs, such as GPT-4 and Llama2, in both zero-shot and few-shot learning scenarios. Additionally, we employ BERT-based models to establish the baseline evaluations. Our findings indicate that these models still trail human performance in temporal reasoning tasks. It is our aspiration that TRAM will spur further progress in enhancing the temporal reason",
    "link": "http://arxiv.org/abs/2310.00835",
    "context": "Title: TRAM: Benchmarking Temporal Reasoning for Large Language Models. (arXiv:2310.00835v2 [cs.CL] UPDATED)\nAbstract: Reasoning about time is essential for understanding the nuances of events described in natural language. Previous research on this topic has been limited in scope, characterized by a lack of standardized benchmarks that would allow for consistent evaluations across different studies. In this paper, we introduce TRAM, a temporal reasoning benchmark composed of ten datasets, encompassing various temporal aspects of events such as order, arithmetic, frequency, and duration, designed to facilitate a comprehensive evaluation of the temporal reasoning capabilities of large language models (LLMs). We conduct an extensive evaluation using popular LLMs, such as GPT-4 and Llama2, in both zero-shot and few-shot learning scenarios. Additionally, we employ BERT-based models to establish the baseline evaluations. Our findings indicate that these models still trail human performance in temporal reasoning tasks. It is our aspiration that TRAM will spur further progress in enhancing the temporal reason",
    "path": "papers/23/10/2310.00835.json",
    "total_tokens": 934,
    "translated_title": "TRAM：用于大型语言模型的时间推理基准评估",
    "translated_abstract": "时间推理对于理解自然语言中描述的事件的细微差别至关重要。以往对于这个主题的研究范围有限，缺乏标准化的基准评估，这导致不同研究间的评估结果不一致。本文介绍了一个称为TRAM的时间推理基准评估，由十个数据集组成，涵盖了事件的各种时间方面，如顺序、算术、频率和持续时间，旨在促进对大型语言模型（LLM）的时间推理能力的全面评估。我们在零样本学习和少样本学习场景中使用了流行的LLM，如GPT-4和Llama2进行了广泛评估。此外，我们还使用基于BERT的模型进行了基准评估。我们的研究结果表明，这些模型在时间推理任务上仍然落后于人类的表现。我们希望TRAM能够推动进一步提升时间推理的研究进展。",
    "tldr": "TRAM是一个用于评估大型语言模型的时间推理能力的基准评估。我们介绍了由十个数据集组成的TRAM基准评估，涵盖了事件的各种时间方面。尽管使用流行的语言模型进行广泛评估，结果表明这些模型在时间推理任务上仍然落后于人类。"
}