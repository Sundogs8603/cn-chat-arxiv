{
    "title": "AutomaTikZ: Text-Guided Synthesis of Scientific Vector Graphics with TikZ. (arXiv:2310.00367v2 [cs.CL] UPDATED)",
    "abstract": "Generating bitmap graphics from text has gained considerable attention, yet for scientific figures, vector graphics are often preferred. Given that vector graphics are typically encoded using low-level graphics primitives, generating them directly is difficult. To address this, we propose the use of TikZ, a well-known abstract graphics language that can be compiled to vector graphics, as an intermediate representation of scientific figures. TikZ offers human-oriented, high-level commands, thereby facilitating conditional language modeling with any large language model. To this end, we introduce DaTikZ, the first large-scale TikZ dataset consisting of 120k TikZ drawings aligned with captions. We fine-tune LLaMA on DaTikZ, as well as our new model CLiMA, which augments LLaMA with multimodal CLIP embeddings. In both human and automatic evaluation, CLiMA and LLaMA outperform commercial GPT-4 and Claude 2 in terms of similarity to human-created figures, with CLiMA additionally improving tex",
    "link": "http://arxiv.org/abs/2310.00367",
    "context": "Title: AutomaTikZ: Text-Guided Synthesis of Scientific Vector Graphics with TikZ. (arXiv:2310.00367v2 [cs.CL] UPDATED)\nAbstract: Generating bitmap graphics from text has gained considerable attention, yet for scientific figures, vector graphics are often preferred. Given that vector graphics are typically encoded using low-level graphics primitives, generating them directly is difficult. To address this, we propose the use of TikZ, a well-known abstract graphics language that can be compiled to vector graphics, as an intermediate representation of scientific figures. TikZ offers human-oriented, high-level commands, thereby facilitating conditional language modeling with any large language model. To this end, we introduce DaTikZ, the first large-scale TikZ dataset consisting of 120k TikZ drawings aligned with captions. We fine-tune LLaMA on DaTikZ, as well as our new model CLiMA, which augments LLaMA with multimodal CLIP embeddings. In both human and automatic evaluation, CLiMA and LLaMA outperform commercial GPT-4 and Claude 2 in terms of similarity to human-created figures, with CLiMA additionally improving tex",
    "path": "papers/23/10/2310.00367.json",
    "total_tokens": 942,
    "translated_title": "AutomaTikZ: 使用TikZ进行科学矢量图的文本引导合成",
    "translated_abstract": "从文本生成位图图形已经引起了相当大的关注，但是对于科学图形，常常更喜欢使用矢量图形。鉴于矢量图形通常使用低级别的图形原语进行编码，直接生成它们是困难的。为了解决这个问题，我们提出了使用TikZ作为科学图形的中间表示，TikZ是一种众所周知的抽象图形语言，可以编译成矢量图形。TikZ提供了面向人的高级命令，从而使得在任何大型语言模型中进行条件语言建模变得容易。为此，我们介绍了DaTikZ，这是第一个包含120k个与标题对齐的TikZ绘图的大规模数据集。我们在DaTikZ上对LLaMA进行了微调，同时引入了我们的新模型CLiMA，该模型使用了多模态的CLIP嵌入。在人工和自动评估中，CLiMA和LLaMA在与人类创建的图形的相似度方面都优于商业的GPT-4和Claude 2，其中CLiMA还改进了tex。",
    "tldr": "本论文引入了AutomaTikZ，它通过使用TikZ作为中间表示来实现科学图形的文本引导合成。通过微调LLaMA和引入CLiMA模型，并使用DaTikZ数据集进行训练，在人工评估和自动评估中，CLiMA和LLaMA在与人类创建的图形的相似度方面表现出色，并且CLiMA还改进了tex。"
}