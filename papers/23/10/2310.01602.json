{
    "title": "CAT-LM: Training Language Models on Aligned Code And Tests. (arXiv:2310.01602v1 [cs.SE])",
    "abstract": "Testing is an integral part of the software development process. Yet, writing tests is time-consuming and therefore often neglected. Classical test generation tools such as EvoSuite generate behavioral test suites by optimizing for coverage, but tend to produce tests that are hard to understand. Language models trained on code can generate code that is highly similar to that written by humans, but current models are trained to generate each file separately, as is standard practice in natural language processing, and thus fail to consider the code-under-test context when producing a test file. In this work, we propose the Aligned Code And Tests Language Model (CAT-LM), a GPT-style language model with 2.7 Billion parameters, trained on a corpus of Python and Java projects. We utilize a novel pretraining signal that explicitly considers the mapping between code and test files when available. We also drastically increase the maximum sequence length of inputs to 8,192 tokens, 4x more than t",
    "link": "http://arxiv.org/abs/2310.01602",
    "context": "Title: CAT-LM: Training Language Models on Aligned Code And Tests. (arXiv:2310.01602v1 [cs.SE])\nAbstract: Testing is an integral part of the software development process. Yet, writing tests is time-consuming and therefore often neglected. Classical test generation tools such as EvoSuite generate behavioral test suites by optimizing for coverage, but tend to produce tests that are hard to understand. Language models trained on code can generate code that is highly similar to that written by humans, but current models are trained to generate each file separately, as is standard practice in natural language processing, and thus fail to consider the code-under-test context when producing a test file. In this work, we propose the Aligned Code And Tests Language Model (CAT-LM), a GPT-style language model with 2.7 Billion parameters, trained on a corpus of Python and Java projects. We utilize a novel pretraining signal that explicitly considers the mapping between code and test files when available. We also drastically increase the maximum sequence length of inputs to 8,192 tokens, 4x more than t",
    "path": "papers/23/10/2310.01602.json",
    "total_tokens": 898,
    "translated_title": "CAT-LM: 在对齐的代码和测试上训练语言模型",
    "translated_abstract": "测试是软件开发过程的重要组成部分。然而，编写测试是耗时且经常被忽视的。经典的测试生成工具如EvoSuite通过优化覆盖率生成行为测试套件，但往往产生难以理解的测试。在现有的代码训练语言模型中，大多数是将每个文件单独训练生成，这在自然语言处理中是标准做法，因此在生成测试文件时没有考虑到代码的上下文。在这项工作中，我们提出了Aligned Code And Tests Language Model (CAT-LM)，一个2.7亿参数的GPT风格语言模型，训练用于Python和Java项目的语料库。我们利用了一种新颖的预训练信号，在有可用时显式考虑代码与测试文件之间的映射。同时，我们还大幅提高了输入的最大序列长度，达到8192个标记，是之前的4倍。",
    "tldr": "该论文提出了一种在对齐的代码和测试上训练的语言模型CAT-LM，该模型能够生成与人类编写代码非常相似的代码。它利用了映射信号来考虑代码和测试文件之间的关系，并大幅增加了输入的最大序列长度。",
    "en_tdlr": "This paper presents CAT-LM, a language model trained on aligned code and tests, which is able to generate code that is highly similar to human-written code. It utilizes mapping signals to consider the relationship between code and test files, and significantly increases the maximum sequence length of inputs."
}