{
    "title": "STANLEY: Stochastic Gradient Anisotropic Langevin Dynamics for Learning Energy-Based Models. (arXiv:2310.12667v1 [stat.ML])",
    "abstract": "We propose in this paper, STANLEY, a STochastic gradient ANisotropic LangEvin dYnamics, for sampling high dimensional data. With the growing efficacy and potential of Energy-Based modeling, also known as non-normalized probabilistic modeling, for modeling a generative process of different natures of high dimensional data observations, we present an end-to-end learning algorithm for Energy-Based models (EBM) with the purpose of improving the quality of the resulting sampled data points. While the unknown normalizing constant of EBMs makes the training procedure intractable, resorting to Markov Chain Monte Carlo (MCMC) is in general a viable option. Realizing what MCMC entails for the EBM training, we propose in this paper, a novel high dimensional sampling method, based on an anisotropic stepsize and a gradient-informed covariance matrix, embedded into a discretized Langevin diffusion. We motivate the necessity for an anisotropic update of the negative samples in the Markov Chain by the",
    "link": "http://arxiv.org/abs/2310.12667",
    "context": "Title: STANLEY: Stochastic Gradient Anisotropic Langevin Dynamics for Learning Energy-Based Models. (arXiv:2310.12667v1 [stat.ML])\nAbstract: We propose in this paper, STANLEY, a STochastic gradient ANisotropic LangEvin dYnamics, for sampling high dimensional data. With the growing efficacy and potential of Energy-Based modeling, also known as non-normalized probabilistic modeling, for modeling a generative process of different natures of high dimensional data observations, we present an end-to-end learning algorithm for Energy-Based models (EBM) with the purpose of improving the quality of the resulting sampled data points. While the unknown normalizing constant of EBMs makes the training procedure intractable, resorting to Markov Chain Monte Carlo (MCMC) is in general a viable option. Realizing what MCMC entails for the EBM training, we propose in this paper, a novel high dimensional sampling method, based on an anisotropic stepsize and a gradient-informed covariance matrix, embedded into a discretized Langevin diffusion. We motivate the necessity for an anisotropic update of the negative samples in the Markov Chain by the",
    "path": "papers/23/10/2310.12667.json",
    "total_tokens": 847,
    "translated_title": "STANLEY：用于学习能量模型的随机梯度异向拉格朗日动力学",
    "translated_abstract": "本文提出了一种名为STANLEY的随机梯度异向拉格朗日动力学算法，用于采样高维数据。通过增强能量模型（EBM）的学习算法来改善采样数据点的质量，我们展示了EBM的端到端学习算法，该算法也被称为非归一化概率建模。由于EBMs的未知归一化常数导致训练过程难以处理，采用马尔科夫链蒙特卡罗（MCMC）通常是可行的选择。在本文中，我们提出了一种新颖的高维采样方法，该方法基于细分随机过程的异向步长和梯度信息的协方差矩阵。我们通过论证马尔科夫链中负样本的异向更新的必要性来解释了MCMC在EBM训练中的作用。",
    "tldr": "本文提出了一种名为STANLEY的算法用于采样高维数据，改善了能量模型学习算法的质量。",
    "en_tdlr": "This paper proposes an algorithm called STANLEY for sampling high dimensional data and improving the quality of the energy model learning algorithm."
}