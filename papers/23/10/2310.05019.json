{
    "title": "Compressed online Sinkhorn. (arXiv:2310.05019v1 [cs.LG])",
    "abstract": "The use of optimal transport (OT) distances, and in particular entropic-regularised OT distances, is an increasingly popular evaluation metric in many areas of machine learning and data science. Their use has largely been driven by the availability of efficient algorithms such as the Sinkhorn algorithm. One of the drawbacks of the Sinkhorn algorithm for large-scale data processing is that it is a two-phase method, where one first draws a large stream of data from the probability distributions, before applying the Sinkhorn algorithm to the discrete probability measures. More recently, there have been several works developing stochastic versions of Sinkhorn that directly handle continuous streams of data. In this work, we revisit the recently introduced online Sinkhorn algorithm of [Mensch and Peyr\\'e, 2020]. Our contributions are twofold: We improve the convergence analysis for the online Sinkhorn algorithm, the new rate that we obtain is faster than the previous rate under certain para",
    "link": "http://arxiv.org/abs/2310.05019",
    "context": "Title: Compressed online Sinkhorn. (arXiv:2310.05019v1 [cs.LG])\nAbstract: The use of optimal transport (OT) distances, and in particular entropic-regularised OT distances, is an increasingly popular evaluation metric in many areas of machine learning and data science. Their use has largely been driven by the availability of efficient algorithms such as the Sinkhorn algorithm. One of the drawbacks of the Sinkhorn algorithm for large-scale data processing is that it is a two-phase method, where one first draws a large stream of data from the probability distributions, before applying the Sinkhorn algorithm to the discrete probability measures. More recently, there have been several works developing stochastic versions of Sinkhorn that directly handle continuous streams of data. In this work, we revisit the recently introduced online Sinkhorn algorithm of [Mensch and Peyr\\'e, 2020]. Our contributions are twofold: We improve the convergence analysis for the online Sinkhorn algorithm, the new rate that we obtain is faster than the previous rate under certain para",
    "path": "papers/23/10/2310.05019.json",
    "total_tokens": 829,
    "translated_title": "压缩在线Sinkhorn算法",
    "translated_abstract": "在机器学习和数据科学的许多领域中，最优传输（OT）距离的使用，特别是熵正则化OT距离，成为越来越受欢迎的评估指标。它们的使用主要是由于Sinkhorn算法等高效算法的可用性。Sinkhorn算法在大规模数据处理中的一个缺点是它是一个两阶段的方法，首先从概率分布中抽取大量数据，然后将Sinkhorn算法应用于离散概率测度。最近，已经有一些研究开发了直接处理连续数据流的Sinkhorn的随机版本。在这项工作中，我们重新审视了[Mensch和Peyr\\'e, 2020]最近引入的在线Sinkhorn算法。我们的贡献有两个方面：我们改进了在线Sinkhorn算法的收敛分析，新得到的收敛速度在某些参数下比先前的速度更快。",
    "tldr": "这篇论文介绍了压缩在线Sinkhorn算法，在机器学习和数据科学领域中，它提出了处理连续数据流的随机版本，收敛速度更快。",
    "en_tdlr": "This paper presents a compressed online Sinkhorn algorithm, which introduces a stochastic version for handling continuous data streams in the fields of machine learning and data science, achieving faster convergence speed."
}