{
    "title": "Mind the instructions: a holistic evaluation of consistency and interactions in prompt-based learning. (arXiv:2310.13486v1 [cs.CL])",
    "abstract": "Finding the best way of adapting pre-trained language models to a task is a big challenge in current NLP. Just like the previous generation of task-tuned models (TT), models that are adapted to tasks via in-context-learning (ICL) are robust in some setups but not in others. Here, we present a detailed analysis of which design choices cause instabilities and inconsistencies in LLM predictions. First, we show how spurious correlations between input distributions and labels -- a known issue in TT models -- form only a minor problem for prompted models. Then, we engage in a systematic, holistic evaluation of different factors that have been found to influence predictions in a prompting setup. We test all possible combinations of a range of factors on both vanilla and instruction-tuned (IT) LLMs of different scale and statistically analyse the results to show which factors are the most influential, interactive or stable. Our results show which factors can be used without precautions and whi",
    "link": "http://arxiv.org/abs/2310.13486",
    "context": "Title: Mind the instructions: a holistic evaluation of consistency and interactions in prompt-based learning. (arXiv:2310.13486v1 [cs.CL])\nAbstract: Finding the best way of adapting pre-trained language models to a task is a big challenge in current NLP. Just like the previous generation of task-tuned models (TT), models that are adapted to tasks via in-context-learning (ICL) are robust in some setups but not in others. Here, we present a detailed analysis of which design choices cause instabilities and inconsistencies in LLM predictions. First, we show how spurious correlations between input distributions and labels -- a known issue in TT models -- form only a minor problem for prompted models. Then, we engage in a systematic, holistic evaluation of different factors that have been found to influence predictions in a prompting setup. We test all possible combinations of a range of factors on both vanilla and instruction-tuned (IT) LLMs of different scale and statistically analyse the results to show which factors are the most influential, interactive or stable. Our results show which factors can be used without precautions and whi",
    "path": "papers/23/10/2310.13486.json",
    "total_tokens": 931,
    "translated_title": "留意指令：对基于提示的学习中一致性和交互性的全面评估",
    "translated_abstract": "在当前自然语言处理中，寻找将预训练语言模型适应到任务的最佳方式是一个重大挑战。与先前一代的任务调整模型（TT）类似，通过上下文学习（ICL）适应任务的模型在某些设置下是健壮的，但在其他设置下不是。在这里，我们对导致线性语言模型（LLM）预测不稳定和不一致的设计选择进行了详细分析。首先，我们展示了输入分布与标签之间的伪相关性在提示模型中只是一个次要问题，而对于TT模型来说是已知的问题。然后，我们进行了对提示设置中影响预测的不同因素的系统的全面评估。我们在不同规模的原始和指令调整（IT）LLMs上测试了所有可能的因素组合，并对结果进行统计分析，以展示哪些因素最具影响力、交互性或稳定性。我们的结果显示了哪些因素可以在不加预防的情况下使用，哪些因素需要预防措施。",
    "tldr": "这项研究对基于提示的学习中导致预测不稳定和不一致的设计选择进行了详细分析，并通过全面评估不同因素的影响，确定了对预测影响最大、具有交互性或稳定性的因素。"
}