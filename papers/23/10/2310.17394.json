{
    "title": "Enhancing Graph Neural Networks with Structure-Based Prompt. (arXiv:2310.17394v1 [cs.LG])",
    "abstract": "Graph Neural Networks (GNNs) are powerful in learning semantics of graph data. Recently, a new paradigm \"pre-train, prompt\" has shown promising results in adapting GNNs to various tasks with less supervised data. The success of such paradigm can be attributed to the more consistent objectives of pre-training and task-oriented prompt tuning, where the pre-trained knowledge can be effectively transferred to downstream tasks. However, an overlooked issue of existing studies is that the structure information of graph is usually exploited during pre-training for learning node representations, while neglected in the prompt tuning stage for learning task-specific parameters. To bridge this gap, we propose a novel structure-based prompting method for GNNs, namely SAP, which consistently exploits structure information in both pre-training and prompt tuning stages. In particular, SAP 1) employs a dual-view contrastive learning to align the latent semantic spaces of node attributes and graph stru",
    "link": "http://arxiv.org/abs/2310.17394",
    "context": "Title: Enhancing Graph Neural Networks with Structure-Based Prompt. (arXiv:2310.17394v1 [cs.LG])\nAbstract: Graph Neural Networks (GNNs) are powerful in learning semantics of graph data. Recently, a new paradigm \"pre-train, prompt\" has shown promising results in adapting GNNs to various tasks with less supervised data. The success of such paradigm can be attributed to the more consistent objectives of pre-training and task-oriented prompt tuning, where the pre-trained knowledge can be effectively transferred to downstream tasks. However, an overlooked issue of existing studies is that the structure information of graph is usually exploited during pre-training for learning node representations, while neglected in the prompt tuning stage for learning task-specific parameters. To bridge this gap, we propose a novel structure-based prompting method for GNNs, namely SAP, which consistently exploits structure information in both pre-training and prompt tuning stages. In particular, SAP 1) employs a dual-view contrastive learning to align the latent semantic spaces of node attributes and graph stru",
    "path": "papers/23/10/2310.17394.json",
    "total_tokens": 907,
    "translated_title": "以结构为基础增强图神经网络",
    "translated_abstract": "图神经网络（GNNs）在学习图数据的语义方面具有很强的能力。最近，一种新的范式“pre-train, prompt”在使用较少有监督数据的情况下适应各种任务的GNNs方面取得了有希望的结果。这种范式的成功可以归因于预训练和面向任务的提示调整的更一致的目标，其中预训练的知识可以有效地转移到下游任务中。然而，现有研究中一个被忽视的问题是，在学习节点表示的预训练阶段通常利用图的结构信息，而在提示调整阶段忽视了结构信息的利用以学习任务特定参数。为了弥补这一差距，我们提出了一种新的以结构为基础的GNNs提示方法，即SAP，它在预训练和提示调整阶段都一致地利用了结构信息。具体而言，SAP 1）采用了双视图对比学习，以对齐节点属性和图结构的潜在语义空间。",
    "tldr": "这篇论文提出了一种以结构为基础的图神经网络的提示方法（SAP），该方法在预训练和提示调整阶段都一致地利用结构信息，从而增强了图神经网络在学习任务特定参数方面的能力。",
    "en_tdlr": "This paper proposes a structure-based prompting method (SAP) for graph neural networks, which consistently exploits structure information in both pre-training and prompt tuning stages, enhancing the capability of graph neural networks in learning task-specific parameters."
}