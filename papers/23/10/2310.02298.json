{
    "title": "Prompting Audios Using Acoustic Properties For Emotion Representation. (arXiv:2310.02298v1 [cs.SD])",
    "abstract": "Emotions lie on a continuum, but current models treat emotions as a finite valued discrete variable. This representation does not capture the diversity in the expression of emotion. To better represent emotions we propose the use of natural language descriptions (or prompts). In this work, we address the challenge of automatically generating these prompts and training a model to better learn emotion representations from audio and prompt pairs. We use acoustic properties that are correlated to emotion like pitch, intensity, speech rate, and articulation rate to automatically generate prompts i.e. 'acoustic prompts'. We use a contrastive learning objective to map speech to their respective acoustic prompts. We evaluate our model on Emotion Audio Retrieval and Speech Emotion Recognition. Our results show that the acoustic prompts significantly improve the model's performance in EAR, in various Precision@K metrics. In SER, we observe a 3.8% relative accuracy improvement on the Ravdess data",
    "link": "http://arxiv.org/abs/2310.02298",
    "context": "Title: Prompting Audios Using Acoustic Properties For Emotion Representation. (arXiv:2310.02298v1 [cs.SD])\nAbstract: Emotions lie on a continuum, but current models treat emotions as a finite valued discrete variable. This representation does not capture the diversity in the expression of emotion. To better represent emotions we propose the use of natural language descriptions (or prompts). In this work, we address the challenge of automatically generating these prompts and training a model to better learn emotion representations from audio and prompt pairs. We use acoustic properties that are correlated to emotion like pitch, intensity, speech rate, and articulation rate to automatically generate prompts i.e. 'acoustic prompts'. We use a contrastive learning objective to map speech to their respective acoustic prompts. We evaluate our model on Emotion Audio Retrieval and Speech Emotion Recognition. Our results show that the acoustic prompts significantly improve the model's performance in EAR, in various Precision@K metrics. In SER, we observe a 3.8% relative accuracy improvement on the Ravdess data",
    "path": "papers/23/10/2310.02298.json",
    "total_tokens": 855,
    "translated_title": "使用声学特性为情感表达生成音频提示",
    "translated_abstract": "情感存在于一个连续的范围内，但现有模型将情感视为有限离散值变量。这种表示方式无法捕捉情感表达的多样性。为了更好地表示情感，我们提出使用自然语言描述（或提示）。在这项工作中，我们解决了自动生成这些提示并训练模型从音频和提示对中更好地学习情感表达的挑战。我们使用与情感相关的声学特性（如音调、强度、语速和发音速度）来自动生成提示，即“声学提示”。我们使用对比学习目标将语音映射到相应的声学提示。我们在情感音频检索和语音情感识别上评估了我们的模型。我们的结果显示，声学提示在EAR中显著提高了模型在各种Precision@K指标上的性能。在SER中，我们观察到Ravdess数据上的相对准确率提高了3.8%。",
    "tldr": "本研究提出使用声学特性生成音频提示，并通过训练模型来更好地学习情感表达。实验结果表明，声学提示显著提高了模型在情感音频检索和语音情感识别中的性能。"
}