{
    "title": "Too Good To Be True: performance overestimation in (re)current practices for Human Activity Recognition. (arXiv:2310.11950v1 [cs.LG])",
    "abstract": "Today, there are standard and well established procedures within the Human Activity Recognition (HAR) pipeline. However, some of these conventional approaches lead to accuracy overestimation. In particular, sliding windows for data segmentation followed by standard random k-fold cross validation, produce biased results. An analysis of previous literature and present-day studies, surprisingly, shows that these are common approaches in state-of-the-art studies on HAR. It is important to raise awareness in the scientific community about this problem, whose negative effects are being overlooked. Otherwise, publications of biased results lead to papers that report lower accuracies, with correct unbiased methods, harder to publish. Several experiments with different types of datasets and different types of classification models allow us to exhibit the problem and show it persists independently of the method or dataset.",
    "link": "http://arxiv.org/abs/2310.11950",
    "context": "Title: Too Good To Be True: performance overestimation in (re)current practices for Human Activity Recognition. (arXiv:2310.11950v1 [cs.LG])\nAbstract: Today, there are standard and well established procedures within the Human Activity Recognition (HAR) pipeline. However, some of these conventional approaches lead to accuracy overestimation. In particular, sliding windows for data segmentation followed by standard random k-fold cross validation, produce biased results. An analysis of previous literature and present-day studies, surprisingly, shows that these are common approaches in state-of-the-art studies on HAR. It is important to raise awareness in the scientific community about this problem, whose negative effects are being overlooked. Otherwise, publications of biased results lead to papers that report lower accuracies, with correct unbiased methods, harder to publish. Several experiments with different types of datasets and different types of classification models allow us to exhibit the problem and show it persists independently of the method or dataset.",
    "path": "papers/23/10/2310.11950.json",
    "total_tokens": 875,
    "translated_title": "太好不像是真的：人类活动识别中的性能评估过高的问题",
    "translated_abstract": "当今，在人类活动识别（HAR）领域有一些标准和既定程序。然而，一些传统方法会导致精度被高估，特别是使用滑动窗口进行数据分割的方法以及标准的随机k折交叉验证方法会产生偏见结果。对过去的文献和现代研究的分析显示，这些方法在HAR领域的最新研究中很常见。我们有必要引起科学界对这个问题的关注，因为它的负面影响被忽视了。否则，发表偏见结果的论文将会报告较低的准确度，正确的无偏方法更难以发表。通过对不同类型的数据集和不同类型的分类模型进行多次实验，我们可以证明这个问题的存在，并且无论方法和数据集如何，这个问题都存在。",
    "tldr": "本文发现在人类活动识别中存在性能评估过高的问题，传统方法中的数据分割和交叉验证导致了结果的偏见。这个问题在最新的研究中很常见，但往往被忽视。不正确的结果会导致报告较低准确度的论文更难发表。",
    "en_tdlr": "This paper discovers the issue of performance overestimation in Human Activity Recognition, where conventional methods of data segmentation and cross validation lead to biased results. This problem is common in recent studies but often overlooked, and reporting inaccurate results makes it harder to publish papers with lower accuracies."
}