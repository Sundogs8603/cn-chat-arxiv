{
    "title": "LLMs and Finetuning: Benchmarking cross-domain performance for hate speech detection",
    "abstract": "arXiv:2310.18964v2 Announce Type: replace  Abstract: In the evolving landscape of online communication, hate speech detection remains a formidable challenge, further compounded by the diversity of digital platforms. This study investigates the effectiveness and adaptability of pre-trained and fine-tuned Large Language Models (LLMs) in identifying hate speech, to address two central questions: (1) To what extent does the model performance depend on the fine-tuning and training parameters?, (2) To what extent do models generalize to cross-domain hate speech detection? and (3) What are the specific features of the datasets or models that influence the generalization potential? The experiment shows that LLMs offer a huge advantage over the state-of-the-art even without pretraining. To answer (1) we analyze 36 in-domain classifiers comprising LLaMA, Vicuna, and their variations in pre-trained and fine-tuned states across nine publicly available datasets that span a wide range of platforms a",
    "link": "https://arxiv.org/abs/2310.18964",
    "context": "Title: LLMs and Finetuning: Benchmarking cross-domain performance for hate speech detection\nAbstract: arXiv:2310.18964v2 Announce Type: replace  Abstract: In the evolving landscape of online communication, hate speech detection remains a formidable challenge, further compounded by the diversity of digital platforms. This study investigates the effectiveness and adaptability of pre-trained and fine-tuned Large Language Models (LLMs) in identifying hate speech, to address two central questions: (1) To what extent does the model performance depend on the fine-tuning and training parameters?, (2) To what extent do models generalize to cross-domain hate speech detection? and (3) What are the specific features of the datasets or models that influence the generalization potential? The experiment shows that LLMs offer a huge advantage over the state-of-the-art even without pretraining. To answer (1) we analyze 36 in-domain classifiers comprising LLaMA, Vicuna, and their variations in pre-trained and fine-tuned states across nine publicly available datasets that span a wide range of platforms a",
    "path": "papers/23/10/2310.18964.json",
    "total_tokens": 917,
    "translated_title": "LLMs与Fine-tuning: 对仇恨言论检测跨领域性能的基准测试",
    "translated_abstract": "在在线交流不断发展的环境中，仇恨言论检测仍然是一个严峻的挑战，数字平台的多样性进一步加剧了这一挑战。本研究调查了预训练和微调的大型语言模型（LLMs）在识别仇恨言论中的有效性和适应性，以解决两个核心问题：（1）模型性能在多大程度上依赖于微调和训练参数？（2）模型在跨领域仇恨言论检测中的泛化程度如何？以及（3）影响泛化潜力的数据集或模型的具体特征是什么？实验证明，即使没有预训练，LLMs也比最先进的模型具有巨大优势。为了回答问题（1），我们分析了36个领域内分类器，涵盖了LLaMA、Vicuna及其不同的预训练和微调状态，跨越了九个公开可用数据集，涵盖了各种平台。",
    "tldr": "本研究调查了预训练和微调的Large Language Models在识别仇恨言论方面的有效性和适应性，揭示了即使没有预训练，LLMs在性能上仍然具有极大优势。",
    "en_tdlr": "This study investigates the effectiveness and adaptability of pre-trained and fine-tuned Large Language Models (LLMs) in identifying hate speech, revealing that LLMs offer a huge advantage over the state-of-the-art even without pretraining."
}