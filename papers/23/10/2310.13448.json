{
    "title": "Steering Large Language Models for Machine Translation with Finetuning and In-Context Learning. (arXiv:2310.13448v1 [cs.CL])",
    "abstract": "Large language models (LLMs) are a promising avenue for machine translation (MT). However, current LLM-based MT systems are brittle: their effectiveness highly depends on the choice of few-shot examples and they often require extra post-processing due to overgeneration. Alternatives such as finetuning on translation instructions are computationally expensive and may weaken in-context learning capabilities, due to overspecialization. In this paper, we provide a closer look at this problem. We start by showing that adapter-based finetuning with LoRA matches the performance of traditional finetuning while reducing the number of training parameters by a factor of 50. This method also outperforms few-shot prompting and eliminates the need for post-processing or in-context examples. However, we show that finetuning generally degrades few-shot performance, hindering adaptation capabilities. Finally, to obtain the best of both worlds, we propose a simple approach that incorporates few-shot exa",
    "link": "http://arxiv.org/abs/2310.13448",
    "context": "Title: Steering Large Language Models for Machine Translation with Finetuning and In-Context Learning. (arXiv:2310.13448v1 [cs.CL])\nAbstract: Large language models (LLMs) are a promising avenue for machine translation (MT). However, current LLM-based MT systems are brittle: their effectiveness highly depends on the choice of few-shot examples and they often require extra post-processing due to overgeneration. Alternatives such as finetuning on translation instructions are computationally expensive and may weaken in-context learning capabilities, due to overspecialization. In this paper, we provide a closer look at this problem. We start by showing that adapter-based finetuning with LoRA matches the performance of traditional finetuning while reducing the number of training parameters by a factor of 50. This method also outperforms few-shot prompting and eliminates the need for post-processing or in-context examples. However, we show that finetuning generally degrades few-shot performance, hindering adaptation capabilities. Finally, to obtain the best of both worlds, we propose a simple approach that incorporates few-shot exa",
    "path": "papers/23/10/2310.13448.json",
    "total_tokens": 903,
    "translated_title": "通过微调和上下文学习引导大型语言模型进行机器翻译",
    "translated_abstract": "大型语言模型(LLMs)在机器翻译领域有着很大的潜力。然而，当前基于LLM的机器翻译系统存在问题：它们的有效性高度依赖于少样本示例的选择，并且由于过度生成而经常需要额外的后处理。其他替代方案，如在翻译指令上进行微调，计算负荷很大，并可能削弱上下文学习能力，导致过度专门化。本文提供对此问题的更详细介绍。我们首先展示了使用LoRA适配器进行微调与传统微调的性能匹配，同时将训练参数数量减少了50倍。这种方法还优于少样本提示方式，并消除了后处理或上下文示例的需求。然而，我们发现微调通常会降低少样本性能，阻碍了模型的适应能力。最后，为了获得两者的最佳效果，我们提出了一种简单的方法，结合了少样本示例和适配器微调。",
    "tldr": "本文提出了一种通过适配器微调的方法，能够在减少训练参数的同时匹配传统微调的性能，优于少样本提示方式，并消除了后处理或上下文示例的需求。",
    "en_tdlr": "This paper presents an approach using adapter-based finetuning that matches the performance of traditional finetuning while reducing training parameters. It outperforms few-shot prompting and eliminates the need for post-processing or in-context examples."
}