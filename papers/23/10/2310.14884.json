{
    "title": "Budgeted Embedding Table For Recommender Systems",
    "abstract": "arXiv:2310.14884v4 Announce Type: replace  Abstract: At the heart of contemporary recommender systems (RSs) are latent factor models that provide quality recommendation experience to users. These models use embedding vectors, which are typically of a uniform and fixed size, to represent users and items. As the number of users and items continues to grow, this design becomes inefficient and hard to scale. Recent lightweight embedding methods have enabled different users and items to have diverse embedding sizes, but are commonly subject to two major drawbacks. Firstly, they limit the embedding size search to optimizing a heuristic balancing the recommendation quality and the memory complexity, where the trade-off coefficient needs to be manually tuned for every memory budget requested. The implicitly enforced memory complexity term can even fail to cap the parameter usage, making the resultant embedding table fail to meet the memory budget strictly. Secondly, most solutions, especially ",
    "link": "https://arxiv.org/abs/2310.14884",
    "context": "Title: Budgeted Embedding Table For Recommender Systems\nAbstract: arXiv:2310.14884v4 Announce Type: replace  Abstract: At the heart of contemporary recommender systems (RSs) are latent factor models that provide quality recommendation experience to users. These models use embedding vectors, which are typically of a uniform and fixed size, to represent users and items. As the number of users and items continues to grow, this design becomes inefficient and hard to scale. Recent lightweight embedding methods have enabled different users and items to have diverse embedding sizes, but are commonly subject to two major drawbacks. Firstly, they limit the embedding size search to optimizing a heuristic balancing the recommendation quality and the memory complexity, where the trade-off coefficient needs to be manually tuned for every memory budget requested. The implicitly enforced memory complexity term can even fail to cap the parameter usage, making the resultant embedding table fail to meet the memory budget strictly. Secondly, most solutions, especially ",
    "path": "papers/23/10/2310.14884.json",
    "total_tokens": 762,
    "translated_title": "面向推荐系统的预算嵌入表",
    "translated_abstract": "当今推荐系统的核心是提供给用户优质推荐体验的潜在因素模型。这些模型使用嵌入向量来表示用户和项目。最近的轻量级嵌入方法使不同用户和项目能够具有不同的嵌入大小，但通常存在两个主要缺点。首先，它们将嵌入大小搜索限制在优化启发式平衡推荐质量和内存复杂性的范围内，其中折衷系数需要为每个内存预算手动调整。隐式强制的内存复杂性项甚至可能无法限制参数使用量，使得得到的嵌入表无法严格满足内存预算。其次，大多数解决方案，特别是……",
    "tldr": "提出了一种预算嵌入表的方法，解决了传统推荐系统中固定嵌入大小难以扩展的问题，能够有效应对不同用户和项目的多样性嵌入大小。",
    "en_tdlr": "A budgeted embedding table method is proposed to address the inefficiency of fixed embedding sizes in traditional recommender systems, enabling effective scaling for diverse embedding sizes of users and items."
}