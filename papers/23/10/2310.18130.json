{
    "title": "DELPHI: Data for Evaluating LLMs' Performance in Handling Controversial Issues. (arXiv:2310.18130v1 [cs.CL])",
    "abstract": "Controversy is a reflection of our zeitgeist, and an important aspect to any discourse. The rise of large language models (LLMs) as conversational systems has increased public reliance on these systems for answers to their various questions. Consequently, it is crucial to systematically examine how these models respond to questions that pertaining to ongoing debates. However, few such datasets exist in providing human-annotated labels reflecting the contemporary discussions. To foster research in this area, we propose a novel construction of a controversial questions dataset, expanding upon the publicly released Quora Question Pairs Dataset. This dataset presents challenges concerning knowledge recency, safety, fairness, and bias. We evaluate different LLMs using a subset of this dataset, illuminating how they handle controversial issues and the stances they adopt. This research ultimately contributes to our understanding of LLMs' interaction with controversial issues, paving the way f",
    "link": "http://arxiv.org/abs/2310.18130",
    "context": "Title: DELPHI: Data for Evaluating LLMs' Performance in Handling Controversial Issues. (arXiv:2310.18130v1 [cs.CL])\nAbstract: Controversy is a reflection of our zeitgeist, and an important aspect to any discourse. The rise of large language models (LLMs) as conversational systems has increased public reliance on these systems for answers to their various questions. Consequently, it is crucial to systematically examine how these models respond to questions that pertaining to ongoing debates. However, few such datasets exist in providing human-annotated labels reflecting the contemporary discussions. To foster research in this area, we propose a novel construction of a controversial questions dataset, expanding upon the publicly released Quora Question Pairs Dataset. This dataset presents challenges concerning knowledge recency, safety, fairness, and bias. We evaluate different LLMs using a subset of this dataset, illuminating how they handle controversial issues and the stances they adopt. This research ultimately contributes to our understanding of LLMs' interaction with controversial issues, paving the way f",
    "path": "papers/23/10/2310.18130.json",
    "total_tokens": 884,
    "translated_title": "DELPHI: 评估LLMs在处理争议问题中的表现的数据",
    "translated_abstract": "争议是我们时代的一种反映，并且是任何言论的重要方面。大型语言模型(LLMs)作为对话系统的兴起，增加了公众对这些系统回答各种问题的依赖。因此，系统地考察这些模型如何回答涉及正在进行的辩论的问题是至关重要的。然而，目前很少有这样的数据集提供人类注释的标签，反映当前的讨论。为了促进这个领域的研究，我们提出了一个新的有争议性问题数据集构建方法，基于已经公开发布的Quora问题对数据集的扩展。该数据集提出了涉及知识时效性、安全性、公平性和偏见的挑战。我们使用该数据集的一个子集来评估不同的LLMs，阐明它们如何处理争议问题以及采取的立场。这项研究最终有助于我们理解LLMs与争议问题的互动，并为未来研究铺平了道路。",
    "tldr": "提出了一个评估LLMs在处理争议问题中表现的数据集，并使用其中的子集对不同的LLMs进行评估，阐明它们如何处理争议问题以及采取的立场。"
}