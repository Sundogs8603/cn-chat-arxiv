{
    "title": "Initialization Bias of Fourier Neural Operator: Revisiting the Edge of Chaos. (arXiv:2310.06379v1 [cs.LG])",
    "abstract": "This paper investigates the initialization bias of the Fourier neural operator (FNO). A mean-field theory for FNO is established, analyzing the behavior of the random FNO from an ``edge of chaos'' perspective. We uncover that the forward and backward propagation behaviors exhibit characteristics unique to FNO, induced by mode truncation, while also showcasing similarities to those of densely connected networks. Building upon this observation, we also propose a FNO version of the He initialization scheme to mitigate the negative initialization bias leading to training instability. Experimental results demonstrate the effectiveness of our initialization scheme, enabling stable training of a 32-layer FNO without the need for additional techniques or significant performance degradation.",
    "link": "http://arxiv.org/abs/2310.06379",
    "context": "Title: Initialization Bias of Fourier Neural Operator: Revisiting the Edge of Chaos. (arXiv:2310.06379v1 [cs.LG])\nAbstract: This paper investigates the initialization bias of the Fourier neural operator (FNO). A mean-field theory for FNO is established, analyzing the behavior of the random FNO from an ``edge of chaos'' perspective. We uncover that the forward and backward propagation behaviors exhibit characteristics unique to FNO, induced by mode truncation, while also showcasing similarities to those of densely connected networks. Building upon this observation, we also propose a FNO version of the He initialization scheme to mitigate the negative initialization bias leading to training instability. Experimental results demonstrate the effectiveness of our initialization scheme, enabling stable training of a 32-layer FNO without the need for additional techniques or significant performance degradation.",
    "path": "papers/23/10/2310.06379.json",
    "total_tokens": 763,
    "translated_title": "Fourier神经操作符的初始化偏差：重新审视混沌边缘",
    "translated_abstract": "本文研究了Fourier神经操作符(FNO)的初始化偏差。建立了一个针对FNO的平均场理论，从“混沌边缘”的视角分析了随机FNO的行为。我们揭示了前向和反向传播行为表现出与FNO独特的特征，这是由模式截断引起的，同时也展示了与密集连接网络相似的特点。基于这一观察，我们还提出了一种FNO版本的He初始化方案，以减轻导致训练不稳定的负初始化偏差。实验结果显示了我们初始化方案的有效性，使得32层FNO的训练稳定，无需额外技术或显著性能下降。",
    "tldr": "本文研究了Fourier神经操作符(FNO)的初始化偏差，提出了一种FNO版本的He初始化方案，通过模式截断和密集连接网络相似的特点，解决了训练不稳定的负初始化偏差问题。",
    "en_tdlr": "This paper investigates the initialization bias of the Fourier neural operator (FNO) and proposes a FNO version of the He initialization scheme to mitigate the negative initialization bias leading to training instability."
}