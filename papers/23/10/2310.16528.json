{
    "title": "CUNI Submission to MRL 2023 Shared Task on Multi-lingual Multi-task Information Retrieval. (arXiv:2310.16528v1 [cs.CL])",
    "abstract": "We present the Charles University system for the MRL~2023 Shared Task on Multi-lingual Multi-task Information Retrieval. The goal of the shared task was to develop systems for named entity recognition and question answering in several under-represented languages. Our solutions to both subtasks rely on the translate-test approach. We first translate the unlabeled examples into English using a multilingual machine translation model. Then, we run inference on the translated data using a strong task-specific model. Finally, we project the labeled data back into the original language. To keep the inferred tags on the correct positions in the original language, we propose a method based on scoring the candidate positions using a label-sensitive translation model. In both settings, we experiment with finetuning the classification models on the translated data. However, due to a domain mismatch between the development data and the shared task validation and test sets, the finetuned models coul",
    "link": "http://arxiv.org/abs/2310.16528",
    "context": "Title: CUNI Submission to MRL 2023 Shared Task on Multi-lingual Multi-task Information Retrieval. (arXiv:2310.16528v1 [cs.CL])\nAbstract: We present the Charles University system for the MRL~2023 Shared Task on Multi-lingual Multi-task Information Retrieval. The goal of the shared task was to develop systems for named entity recognition and question answering in several under-represented languages. Our solutions to both subtasks rely on the translate-test approach. We first translate the unlabeled examples into English using a multilingual machine translation model. Then, we run inference on the translated data using a strong task-specific model. Finally, we project the labeled data back into the original language. To keep the inferred tags on the correct positions in the original language, we propose a method based on scoring the candidate positions using a label-sensitive translation model. In both settings, we experiment with finetuning the classification models on the translated data. However, due to a domain mismatch between the development data and the shared task validation and test sets, the finetuned models coul",
    "path": "papers/23/10/2310.16528.json",
    "total_tokens": 952,
    "translated_title": "《CUNI投稿MRL 2023多语言多任务信息检索共享任务》的翻译",
    "translated_abstract": "我们介绍了查理大学在MRL 2023多语言多任务信息检索共享任务中的系统。该共享任务的目标是开发针对多个语言中的命名实体识别和问题回答的系统。我们对两个子任务的解决方案都依赖于“翻译测试”方法。首先，我们使用多语言机器翻译模型将未标记的示例翻译成英语。然后，我们使用强大的任务特定模型对翻译后的数据进行推断。最后，我们将标记的数据投影回原始语言。为了保持原始语言中的推断标签正确的位置，我们提出了一种基于使用标签敏感翻译模型评分候选位置的方法。在两种设置中，我们在翻译后的数据上尝试了分类模型的微调。然而，由于开发数据和共享任务验证和测试集之间存在领域不匹配，微调的模型可能无法得到准确的结果。",
    "tldr": "这个论文介绍了查理大学在MRL 2023多语言多任务信息检索共享任务中采用的解决方案，并通过翻译测试方法实现了命名实体识别和问题回答的多语言应用，通过使用标签敏感的翻译模型评分候选位置，保持了推断标签在原始语言中的正确位置。"
}