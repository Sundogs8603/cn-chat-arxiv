{
    "title": "Improving Entropy-Based Test-Time Adaptation from a Clustering View. (arXiv:2310.20327v1 [cs.AI])",
    "abstract": "Domain shift is a common problem in the realistic world, where training data and test data follow different data distributions. To deal with this problem, fully test-time adaptation (TTA) leverages the unlabeled data encountered during test time to adapt the model. In particular, Entropy-Based TTA (EBTTA) methods, which minimize the prediction's entropy on test samples, have shown great success. In this paper, we introduce a new perspective on the EBTTA, which interprets these methods from a view of clustering. It is an iterative algorithm: 1) in the assignment step, the forward process of the EBTTA models is the assignment of labels for these test samples, and 2) in the updating step, the backward process is the update of the model via the assigned samples. Based on the interpretation, we can gain a deeper understanding of EBTTA, where we show that the entropy loss would further increase the largest probability. Accordingly, we offer an alternative explanation that why existing EBTTA ",
    "link": "http://arxiv.org/abs/2310.20327",
    "context": "Title: Improving Entropy-Based Test-Time Adaptation from a Clustering View. (arXiv:2310.20327v1 [cs.AI])\nAbstract: Domain shift is a common problem in the realistic world, where training data and test data follow different data distributions. To deal with this problem, fully test-time adaptation (TTA) leverages the unlabeled data encountered during test time to adapt the model. In particular, Entropy-Based TTA (EBTTA) methods, which minimize the prediction's entropy on test samples, have shown great success. In this paper, we introduce a new perspective on the EBTTA, which interprets these methods from a view of clustering. It is an iterative algorithm: 1) in the assignment step, the forward process of the EBTTA models is the assignment of labels for these test samples, and 2) in the updating step, the backward process is the update of the model via the assigned samples. Based on the interpretation, we can gain a deeper understanding of EBTTA, where we show that the entropy loss would further increase the largest probability. Accordingly, we offer an alternative explanation that why existing EBTTA ",
    "path": "papers/23/10/2310.20327.json",
    "total_tokens": 946,
    "translated_title": "从聚类视角改进基于熵的测试时间自适应",
    "translated_abstract": "在现实世界中，领域偏移是一个常见的问题，训练数据和测试数据遵循不同的数据分布。为了解决这个问题，完全的测试时间自适应（TTA）利用测试时间遇到的无标签数据来适应模型。特别是基于熵的测试时间自适应（EBTTA）方法，在测试样本上最小化预测的熵，取得了很大的成功。在本文中，我们从聚类的角度介绍了EBTTA的新视角和解释。这是一个迭代算法：1）在分配步骤中，EBTTA模型的前向过程是为这些测试样本分配标签；2）在更新步骤中，反向过程是通过已分配的样本来更新模型。根据这种解释，我们可以更深入地理解EBTTA，其中我们展示了熵损失会进一步增加最大的概率。因此，我们提供了一个替代性解释，解释了为什么现有的EBTTA方法在聚类任务上比在分类任务上表现更好。",
    "tldr": "本文从聚类的角度解释了基于熵的测试时间自适应（EBTTA）方法，提出了一个迭代算法，并展示了对于EBTTA方法来说，熵损失会进一步增加最大的概率，从而为其在聚类任务上的较好性能提供了一个替代性解释。",
    "en_tdlr": "This paper introduces a new perspective on entropy-based test-time adaptation (EBTTA) methods from a clustering view, presenting an iterative algorithm and demonstrating that the entropy loss would further increase the largest probability for better performance in clustering tasks."
}