{
    "title": "Robust Learning via Conditional Prevalence Adjustment. (arXiv:2310.15766v1 [cs.LG])",
    "abstract": "Healthcare data often come from multiple sites in which the correlations between confounding variables can vary widely. If deep learning models exploit these unstable correlations, they might fail catastrophically in unseen sites. Although many methods have been proposed to tackle unstable correlations, each has its limitations. For example, adversarial training forces models to completely ignore unstable correlations, but doing so may lead to poor predictive performance. Other methods (e.g. Invariant risk minimization [4]) try to learn domain-invariant representations that rely only on stable associations by assuming a causal data-generating process (input X causes class label Y ). Thus, they may be ineffective for anti-causal tasks (Y causes X), which are common in computer vision. We propose a method called CoPA (Conditional Prevalence-Adjustment) for anti-causal tasks. CoPA assumes that (1) generation mechanism is stable, i.e. label Y and confounding variable(s) Z generate X, and (",
    "link": "http://arxiv.org/abs/2310.15766",
    "context": "Title: Robust Learning via Conditional Prevalence Adjustment. (arXiv:2310.15766v1 [cs.LG])\nAbstract: Healthcare data often come from multiple sites in which the correlations between confounding variables can vary widely. If deep learning models exploit these unstable correlations, they might fail catastrophically in unseen sites. Although many methods have been proposed to tackle unstable correlations, each has its limitations. For example, adversarial training forces models to completely ignore unstable correlations, but doing so may lead to poor predictive performance. Other methods (e.g. Invariant risk minimization [4]) try to learn domain-invariant representations that rely only on stable associations by assuming a causal data-generating process (input X causes class label Y ). Thus, they may be ineffective for anti-causal tasks (Y causes X), which are common in computer vision. We propose a method called CoPA (Conditional Prevalence-Adjustment) for anti-causal tasks. CoPA assumes that (1) generation mechanism is stable, i.e. label Y and confounding variable(s) Z generate X, and (",
    "path": "papers/23/10/2310.15766.json",
    "total_tokens": 924,
    "translated_title": "通过条件性患病率调整实现鲁棒学习",
    "translated_abstract": "医疗数据通常来自多个来源，其中混淆变量之间的相关性可能变化很大。如果深度学习模型利用这些不稳定的相关性，它们可能在未知的来源中发生灾难性失败。尽管提出了许多方法来解决不稳定的相关性，但每种方法都有其局限性。例如，对抗训练强制模型完全忽略不稳定的相关性，但这样做可能导致预测性能不佳。其他方法（例如，不变风险最小化）试图学习仅依赖于稳定关联的域不变表示，通过假设存在一个因果数据生成过程（输入X导致类别标签Y）。因此，它们对反因果任务（Y导致X）可能不起作用，这在计算机视觉中很常见。我们提出了一种名为CoPA（条件患病率调整）的反因果任务方法。CoPA假设（1）生成机制稳定，即标签Y和混淆变量Z生成X。",
    "tldr": "该论文提出了一种名为CoPA的方法，用于处理医疗数据中不稳定相关性的问题，特别适用于反因果任务。这种方法通过调整患病率来处理混淆变量和标签的关系，从而实现鲁棒学习。",
    "en_tdlr": "This paper proposes a method called CoPA for handling unstable correlations in medical data, especially for anti-causal tasks. This approach adjusts the prevalence of confounding variables to address the relationship between confounding variables and labels, thereby achieving robust learning."
}