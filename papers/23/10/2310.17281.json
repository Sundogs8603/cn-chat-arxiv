{
    "title": "BEVContrast: Self-Supervision in BEV Space for Automotive Lidar Point Clouds. (arXiv:2310.17281v1 [cs.CV])",
    "abstract": "We present a surprisingly simple and efficient method for self-supervision of 3D backbone on automotive Lidar point clouds. We design a contrastive loss between features of Lidar scans captured in the same scene. Several such approaches have been proposed in the literature from PointConstrast, which uses a contrast at the level of points, to the state-of-the-art TARL, which uses a contrast at the level of segments, roughly corresponding to objects. While the former enjoys a great simplicity of implementation, it is surpassed by the latter, which however requires a costly pre-processing. In BEVContrast, we define our contrast at the level of 2D cells in the Bird's Eye View plane. Resulting cell-level representations offer a good trade-off between the point-level representations exploited in PointContrast and segment-level representations exploited in TARL: we retain the simplicity of PointContrast (cell representations are cheap to compute) while surpassing the performance of TARL in do",
    "link": "http://arxiv.org/abs/2310.17281",
    "context": "Title: BEVContrast: Self-Supervision in BEV Space for Automotive Lidar Point Clouds. (arXiv:2310.17281v1 [cs.CV])\nAbstract: We present a surprisingly simple and efficient method for self-supervision of 3D backbone on automotive Lidar point clouds. We design a contrastive loss between features of Lidar scans captured in the same scene. Several such approaches have been proposed in the literature from PointConstrast, which uses a contrast at the level of points, to the state-of-the-art TARL, which uses a contrast at the level of segments, roughly corresponding to objects. While the former enjoys a great simplicity of implementation, it is surpassed by the latter, which however requires a costly pre-processing. In BEVContrast, we define our contrast at the level of 2D cells in the Bird's Eye View plane. Resulting cell-level representations offer a good trade-off between the point-level representations exploited in PointContrast and segment-level representations exploited in TARL: we retain the simplicity of PointContrast (cell representations are cheap to compute) while surpassing the performance of TARL in do",
    "path": "papers/23/10/2310.17281.json",
    "total_tokens": 787,
    "translated_title": "BEVContrast: 汽车激光雷达点云BEV空间的自我监督方法",
    "translated_abstract": "我们提出了一种自我监督汽车激光雷达点云3D主干的简单高效的方法。我们设计了一种对相同场景中捕获的激光雷达扫描特征进行对比的损失函数。我们将对比方法从点级别（PointContrast）到分段级别（TARL）进行了比较，并在Bird's Eye View平面的2D单元级别定义了我们的对比。所得到的单元级表示在计算成本上既保持了PointContrast的简单性（单元表示计算成本低），同时也超越了TARL的性能。",
    "tldr": "BEVContrast是一种在汽车激光雷达点云中使用BEV空间自我监督的方法，通过对比不同场景下的特征，提供了一种在计算成本和性能之间取得平衡的解决方案。"
}