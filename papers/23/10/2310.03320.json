{
    "title": "BioBridge: Bridging Biomedical Foundation Models via Knowledge Graph. (arXiv:2310.03320v1 [cs.LG])",
    "abstract": "Foundation models (FMs) are able to leverage large volumes of unlabeled data to demonstrate superior performance across a wide range of tasks. However, FMs developed for biomedical domains have largely remained unimodal, i.e., independently trained and used for tasks on protein sequences alone, small molecule structures alone, or clinical data alone. To overcome this limitation of biomedical FMs, we present BioBridge, a novel parameter-efficient learning framework, to bridge independently trained unimodal FMs to establish multimodal behavior. BioBridge achieves it by utilizing Knowledge Graphs (KG) to learn transformations between one unimodal FM and another without fine-tuning any underlying unimodal FMs. Our empirical results demonstrate that BioBridge can beat the best baseline KG embedding methods (on average by around 76.3%) in cross-modal retrieval tasks. We also identify BioBridge demonstrates out-of-domain generalization ability by extrapolating to unseen modalities or relation",
    "link": "http://arxiv.org/abs/2310.03320",
    "context": "Title: BioBridge: Bridging Biomedical Foundation Models via Knowledge Graph. (arXiv:2310.03320v1 [cs.LG])\nAbstract: Foundation models (FMs) are able to leverage large volumes of unlabeled data to demonstrate superior performance across a wide range of tasks. However, FMs developed for biomedical domains have largely remained unimodal, i.e., independently trained and used for tasks on protein sequences alone, small molecule structures alone, or clinical data alone. To overcome this limitation of biomedical FMs, we present BioBridge, a novel parameter-efficient learning framework, to bridge independently trained unimodal FMs to establish multimodal behavior. BioBridge achieves it by utilizing Knowledge Graphs (KG) to learn transformations between one unimodal FM and another without fine-tuning any underlying unimodal FMs. Our empirical results demonstrate that BioBridge can beat the best baseline KG embedding methods (on average by around 76.3%) in cross-modal retrieval tasks. We also identify BioBridge demonstrates out-of-domain generalization ability by extrapolating to unseen modalities or relation",
    "path": "papers/23/10/2310.03320.json",
    "total_tokens": 893,
    "translated_title": "BioBridge: 通过知识图谱桥接生物医学基础模型",
    "translated_abstract": "基础模型(FMs)能够利用大量的无标签数据，在各种任务上展现出优秀的性能。然而，用于生物医学领域的FMs主要仍处于单模态状态，即独立训练并用于处理蛋白质序列、小分子结构或临床数据等单一任务。为了克服生物医学FMs的这种局限性，我们提出了一种新颖的参数高效学习框架BioBridge，通过利用知识图谱(KG)来学习不需要微调任何底层单模态FMs的转换，从而桥接独立训练的单模态FMs以建立多模态行为。我们的实证结果表明，BioBridge在跨模态检索任务中可以击败最佳基线KG嵌入方法（平均提高约76.3%）。我们还发现，BioBridge表现出领域外的泛化能力，可以推广到未见的模态或关系中。",
    "tldr": "BioBridge是一种通过知识图谱桥接单模态生物医学基础模型的参数高效学习框架。实验证明，BioBridge在跨模态检索任务中胜过最佳基线KG嵌入方法，具有泛化能力。",
    "en_tdlr": "BioBridge is a parameter-efficient learning framework that bridges unimodal biomedical foundation models via knowledge graphs. It demonstrates superior performance in cross-modal retrieval tasks, outperforming the best baseline KG embedding methods, and showcases out-of-domain generalization ability."
}