{
    "title": "GASS: Generalizing Audio Source Separation with Large-scale Data. (arXiv:2310.00140v1 [cs.SD])",
    "abstract": "Universal source separation targets at separating the audio sources of an arbitrary mix, removing the constraint to operate on a specific domain like speech or music. Yet, the potential of universal source separation is limited because most existing works focus on mixes with predominantly sound events, and small training datasets also limit its potential for supervised learning. Here, we study a single general audio source separation (GASS) model trained to separate speech, music, and sound events in a supervised fashion with a large-scale dataset. We assess GASS models on a diverse set of tasks. Our strong in-distribution results show the feasibility of GASS models, and the competitive out-of-distribution performance in sound event and speech separation shows its generalization abilities. Yet, it is challenging for GASS models to generalize for separating out-of-distribution cinematic and music content. We also fine-tune GASS models on each dataset and consistently outperform the ones",
    "link": "http://arxiv.org/abs/2310.00140",
    "context": "Title: GASS: Generalizing Audio Source Separation with Large-scale Data. (arXiv:2310.00140v1 [cs.SD])\nAbstract: Universal source separation targets at separating the audio sources of an arbitrary mix, removing the constraint to operate on a specific domain like speech or music. Yet, the potential of universal source separation is limited because most existing works focus on mixes with predominantly sound events, and small training datasets also limit its potential for supervised learning. Here, we study a single general audio source separation (GASS) model trained to separate speech, music, and sound events in a supervised fashion with a large-scale dataset. We assess GASS models on a diverse set of tasks. Our strong in-distribution results show the feasibility of GASS models, and the competitive out-of-distribution performance in sound event and speech separation shows its generalization abilities. Yet, it is challenging for GASS models to generalize for separating out-of-distribution cinematic and music content. We also fine-tune GASS models on each dataset and consistently outperform the ones",
    "path": "papers/23/10/2310.00140.json",
    "total_tokens": 876,
    "translated_title": "GASS：使用大规模数据进行音频源分离的泛化方法",
    "translated_abstract": "通用源分离的目标是分离任意混合音频中的音频源，消除仅操作于特定领域（如语音或音乐）的约束。然而，通用源分离的潜力受限于大多数现有作品主要关注具有主要声音事件的混合以及小型训练数据集对于监督学习的潜力限制。本文研究了使用大规模数据集以有监督的方式训练的单一通用音频源分离（GASS）模型，该模型能够分离语音、音乐和声音事件。我们对GASS模型进行了多样化任务的评估。我们的强有力分布结果显示了GASS模型的可行性，而在声音事件和语音分离方面的竞争性超出分布性能则显示了其泛化能力。然而，GASS模型在分离超出分布的电影和音乐内容方面具有挑战性。我们还对每个数据集对GASS模型进行了微调，并始终表现优于其他模型。",
    "tldr": "本文研究了一种使用大规模数据进行音频源分离的通用方法（GASS），在有限分布范围内表现出良好的效果，并展示了其在声音事件和语音分离方面的泛化能力。然而，在分离超出分布的电影和音乐内容方面仍存在挑战。"
}