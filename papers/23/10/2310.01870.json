{
    "title": "DeepDecipher: Accessing and Investigating Neuron Activation in Large Language Models. (arXiv:2310.01870v1 [cs.LG])",
    "abstract": "As large language models (LLMs) become more capable, there is an urgent need for interpretable and transparent tools. Current methods are difficult to implement, and accessible tools to analyze model internals are lacking. To bridge this gap, we present DeepDecipher - an API and interface for probing neurons in transformer models' MLP layers. DeepDecipher makes the outputs of advanced interpretability techniques for LLMs readily available. The easy-to-use interface also makes inspecting these complex models more intuitive. This paper outlines DeepDecipher's design and capabilities. We demonstrate how to analyze neurons, compare models, and gain insights into model behavior. For example, we contrast DeepDecipher's functionality with similar tools like Neuroscope and OpenAI's Neuron Explainer. DeepDecipher enables efficient, scalable analysis of LLMs. By granting access to state-of-the-art interpretability methods, DeepDecipher makes LLMs more transparent, trustworthy, and safe. Research",
    "link": "http://arxiv.org/abs/2310.01870",
    "context": "Title: DeepDecipher: Accessing and Investigating Neuron Activation in Large Language Models. (arXiv:2310.01870v1 [cs.LG])\nAbstract: As large language models (LLMs) become more capable, there is an urgent need for interpretable and transparent tools. Current methods are difficult to implement, and accessible tools to analyze model internals are lacking. To bridge this gap, we present DeepDecipher - an API and interface for probing neurons in transformer models' MLP layers. DeepDecipher makes the outputs of advanced interpretability techniques for LLMs readily available. The easy-to-use interface also makes inspecting these complex models more intuitive. This paper outlines DeepDecipher's design and capabilities. We demonstrate how to analyze neurons, compare models, and gain insights into model behavior. For example, we contrast DeepDecipher's functionality with similar tools like Neuroscope and OpenAI's Neuron Explainer. DeepDecipher enables efficient, scalable analysis of LLMs. By granting access to state-of-the-art interpretability methods, DeepDecipher makes LLMs more transparent, trustworthy, and safe. Research",
    "path": "papers/23/10/2310.01870.json",
    "total_tokens": 878,
    "translated_title": "DeepDecipher: 访问和研究大规模语言模型中的神经元激活",
    "translated_abstract": "随着大规模语言模型（LLMs）的能力越来越强，对可解释和透明工具的紧迫需求逐渐增加。目前的方法难以实现，并且缺乏分析模型内部的可访问工具。为了弥补这一差距，我们提出了DeepDecipher - 一种用于探测转换器模型MLP层中神经元的API和接口。DeepDecipher将LLMs的先进可解释性技术的输出变得容易获取。易于使用的界面还使得对这些复杂模型的检查更加直观。本文概述了DeepDecipher的设计和能力。我们演示了如何分析神经元，比较模型，并获得有关模型行为的见解。例如，我们将DeepDecipher的功能与类似的工具如Neuroscope和OpenAI的Neuron Explainer进行对比。DeepDecipher实现了对LLMs的高效可扩展分析。通过提供最先进的可解释性方法，DeepDecipher使LLMs变得更加透明、可信和安全。",
    "tldr": "DeepDecipher是一种用于探测大规模语言模型中神经元激活的API和接口，它通过提供先进的可解释性技术和易于使用的界面，使得对这些复杂模型的分析更加直观和可访问。"
}