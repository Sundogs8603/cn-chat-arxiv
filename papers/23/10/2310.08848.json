{
    "title": "Semi-Supervised End-To-End Contrastive Learning For Time Series Classification. (arXiv:2310.08848v1 [cs.LG])",
    "abstract": "Time series classification is a critical task in various domains, such as finance, healthcare, and sensor data analysis. Unsupervised contrastive learning has garnered significant interest in learning effective representations from time series data with limited labels. The prevalent approach in existing contrastive learning methods consists of two separate stages: pre-training the encoder on unlabeled datasets and fine-tuning the well-trained model on a small-scale labeled dataset. However, such two-stage approaches suffer from several shortcomings, such as the inability of unsupervised pre-training contrastive loss to directly affect downstream fine-tuning classifiers, and the lack of exploiting the classification loss which is guided by valuable ground truth. In this paper, we propose an end-to-end model called SLOTS (Semi-supervised Learning fOr Time clasSification). SLOTS receives semi-labeled datasets, comprising a large number of unlabeled samples and a small proportion of labele",
    "link": "http://arxiv.org/abs/2310.08848",
    "context": "Title: Semi-Supervised End-To-End Contrastive Learning For Time Series Classification. (arXiv:2310.08848v1 [cs.LG])\nAbstract: Time series classification is a critical task in various domains, such as finance, healthcare, and sensor data analysis. Unsupervised contrastive learning has garnered significant interest in learning effective representations from time series data with limited labels. The prevalent approach in existing contrastive learning methods consists of two separate stages: pre-training the encoder on unlabeled datasets and fine-tuning the well-trained model on a small-scale labeled dataset. However, such two-stage approaches suffer from several shortcomings, such as the inability of unsupervised pre-training contrastive loss to directly affect downstream fine-tuning classifiers, and the lack of exploiting the classification loss which is guided by valuable ground truth. In this paper, we propose an end-to-end model called SLOTS (Semi-supervised Learning fOr Time clasSification). SLOTS receives semi-labeled datasets, comprising a large number of unlabeled samples and a small proportion of labele",
    "path": "papers/23/10/2310.08848.json",
    "total_tokens": 889,
    "translated_title": "半监督端到端对比学习用于时间序列分类",
    "translated_abstract": "时间序列分类是金融、医疗和传感器数据分析等各种领域中的关键任务。无监督对比学习在使用有限标签的时间序列数据中学习有效表示方面引起了极大的兴趣。现有对比学习方法中普遍的方法包括两个独立的阶段：在无标签数据集上进行预训练编码器，然后在小规模标记数据集上对经过良好训练的模型进行微调。然而，这种两阶段方法存在一些缺点，例如无监督预训练对比损失不能直接影响下游微调分类器，以及缺乏利用由有价值的真实标签引导的分类损失。在本文中，我们提出了一个名为SLOTS（Semi-supervised Learning fOr Time clasSification）的端到端模型。SLOTS接收半标记数据集，其中包括大量无标签样本和少量标记样本。",
    "tldr": "本文提出了一个名为SLOTS的半监督端到端模型，用于时间序列分类。它通过接收半标记数据集，在无监督预训练和下游微调中综合利用对比损失和分类损失，解决了现有方法中的缺点。",
    "en_tdlr": "This paper proposes an end-to-end model called SLOTS for semi-supervised time series classification. It addresses the shortcomings of existing methods by integrating contrastive loss and classification loss in both unsupervised pre-training and downstream fine-tuning stages using semi-labeled datasets."
}