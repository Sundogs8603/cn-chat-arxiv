{
    "title": "DP-SGD for non-decomposable objective functions. (arXiv:2310.03104v1 [cs.LG])",
    "abstract": "Unsupervised pre-training is a common step in developing computer vision models and large language models. In this setting, the absence of labels requires the use of similarity-based loss functions, such as contrastive loss, that favor minimizing the distance between similar inputs and maximizing the distance between distinct inputs. As privacy concerns mount, training these models using differential privacy has become more important. However, due to how inputs are generated for these losses, one of their undesirable properties is that their $L_2$ sensitivity can grow with increasing batch size. This property is particularly disadvantageous for differentially private training methods, such as DP-SGD. To overcome this issue, we develop a new DP-SGD variant for similarity based loss functions -- in particular the commonly used contrastive loss -- that manipulates gradients of the objective function in a novel way to obtain a senstivity of the summed gradient that is $O(1)$ for batch size",
    "link": "http://arxiv.org/abs/2310.03104",
    "context": "Title: DP-SGD for non-decomposable objective functions. (arXiv:2310.03104v1 [cs.LG])\nAbstract: Unsupervised pre-training is a common step in developing computer vision models and large language models. In this setting, the absence of labels requires the use of similarity-based loss functions, such as contrastive loss, that favor minimizing the distance between similar inputs and maximizing the distance between distinct inputs. As privacy concerns mount, training these models using differential privacy has become more important. However, due to how inputs are generated for these losses, one of their undesirable properties is that their $L_2$ sensitivity can grow with increasing batch size. This property is particularly disadvantageous for differentially private training methods, such as DP-SGD. To overcome this issue, we develop a new DP-SGD variant for similarity based loss functions -- in particular the commonly used contrastive loss -- that manipulates gradients of the objective function in a novel way to obtain a senstivity of the summed gradient that is $O(1)$ for batch size",
    "path": "papers/23/10/2310.03104.json",
    "total_tokens": 875,
    "translated_title": "非可分的目标函数的DP-SGD方法",
    "translated_abstract": "无监督预训练是开发计算机视觉模型和大型语言模型的常见步骤。在这种情况下，由于缺少标签，需要使用基于相似性的损失函数，如对比损失，来优化相似输入之间的距离并最大化不同输入之间的距离。随着隐私问题的增多，使用差分隐私来训练这些模型变得更加重要。然而，由于这些损失函数生成输入的方式，它们的$L_2$敏感度会随着批量大小的增加而增加，这对于差分隐私训练方法（如DP-SGD）特别不利。为了解决这个问题，我们开发了一种新的DP-SGD变体，用于基于相似性的损失函数，特别是常用的对比损失，通过一种新颖的方式处理目标函数的梯度，使得梯度的敏感度对于批量大小是$O(1)$。",
    "tldr": "本论文提出了一种针对非可分的目标函数的DP-SGD方法，解决了使用差分隐私进行训练时，相似性损失函数的$L_2$敏感度增长随着批量大小增加的问题。",
    "en_tdlr": "This paper introduces a new variant of DP-SGD for non-decomposable objective functions, addressing the issue of increasing $L_2$ sensitivity of similarity-based loss functions with batch size in differentially private training."
}