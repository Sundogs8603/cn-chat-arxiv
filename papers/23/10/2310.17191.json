{
    "title": "How do Language Models Bind Entities in Context?. (arXiv:2310.17191v1 [cs.LG])",
    "abstract": "To correctly use in-context information, language models (LMs) must bind entities to their attributes. For example, given a context describing a \"green square\" and a \"blue circle\", LMs must bind the shapes to their respective colors. We analyze LM representations and identify the binding ID mechanism: a general mechanism for solving the binding problem, which we observe in every sufficiently large model from the Pythia and LLaMA families. Using causal interventions, we show that LMs' internal activations represent binding information by attaching binding ID vectors to corresponding entities and attributes. We further show that binding ID vectors form a continuous subspace, in which distances between binding ID vectors reflect their discernability. Overall, our results uncover interpretable strategies in LMs for representing symbolic knowledge in-context, providing a step towards understanding general in-context reasoning in large-scale LMs.",
    "link": "http://arxiv.org/abs/2310.17191",
    "context": "Title: How do Language Models Bind Entities in Context?. (arXiv:2310.17191v1 [cs.LG])\nAbstract: To correctly use in-context information, language models (LMs) must bind entities to their attributes. For example, given a context describing a \"green square\" and a \"blue circle\", LMs must bind the shapes to their respective colors. We analyze LM representations and identify the binding ID mechanism: a general mechanism for solving the binding problem, which we observe in every sufficiently large model from the Pythia and LLaMA families. Using causal interventions, we show that LMs' internal activations represent binding information by attaching binding ID vectors to corresponding entities and attributes. We further show that binding ID vectors form a continuous subspace, in which distances between binding ID vectors reflect their discernability. Overall, our results uncover interpretable strategies in LMs for representing symbolic knowledge in-context, providing a step towards understanding general in-context reasoning in large-scale LMs.",
    "path": "papers/23/10/2310.17191.json",
    "total_tokens": 941,
    "translated_title": "语言模型如何将实体绑定到上下文中?",
    "translated_abstract": "为了正确使用上下文信息，语言模型（LMs）必须将实体与其属性进行绑定。例如，给定描述“绿色方块”和“蓝色圆形”的上下文，LMs必须将形状与它们对应的颜色进行绑定。我们分析LM表示并确定绑定ID机制：这是一种解决绑定问题的通用机制，我们在Pythia和LLaMA家族的每个足够大的模型中观察到。通过因果干预，我们展示了LMs内部激活通过将绑定ID向量附加到相应的实体和属性上来表示绑定信息。我们进一步展示了绑定ID向量形成连续的子空间，在这个子空间中，绑定ID向量之间的距离反映了它们的区别。总体而言，我们的结果揭示了LMs在上下文中表示符号知识的可解释策略，为理解大规模LMs中的一般上下文推理迈出了一步。",
    "tldr": "通过分析语言模型的表示，我们发现了绑定ID机制，它可以将实体与属性进行有效地绑定。我们通过因果干预实验进一步证明了语言模型内部激活表示绑定信息的方式。研究结果揭示了语言模型在上下文中如何表示符号知识，从而为理解大规模语言模型的一般上下文推理提供了指导。",
    "en_tdlr": "By analyzing the representations of language models (LMs), we have discovered a binding ID mechanism that effectively binds entities to their attributes. Through causal interventions, we have demonstrated how LMs internally represent binding information. These findings reveal how LMs represent symbolic knowledge in context and provide insights into general in-context reasoning in large-scale language models."
}