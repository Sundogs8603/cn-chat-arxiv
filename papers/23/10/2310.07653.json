{
    "title": "Mini-DALLE3: Interactive Text to Image by Prompting Large Language Models. (arXiv:2310.07653v2 [cs.AI] UPDATED)",
    "abstract": "The revolution of artificial intelligence content generation has been rapidly accelerated with the booming text-to-image (T2I) diffusion models. Within just two years of development, it was unprecedentedly of high-quality, diversity, and creativity that the state-of-the-art models could generate. However, a prevalent limitation persists in the effective communication with these popular T2I models, such as Stable Diffusion, using natural language descriptions. This typically makes an engaging image hard to obtain without expertise in prompt engineering with complex word compositions, magic tags, and annotations. Inspired by the recently released DALLE3 - a T2I model directly built-in ChatGPT that talks human language, we revisit the existing T2I systems endeavoring to align human intent and introduce a new task - interactive text to image (iT2I), where people can interact with LLM for interleaved high-quality image generation/edit/refinement and question answering with stronger images a",
    "link": "http://arxiv.org/abs/2310.07653",
    "context": "Title: Mini-DALLE3: Interactive Text to Image by Prompting Large Language Models. (arXiv:2310.07653v2 [cs.AI] UPDATED)\nAbstract: The revolution of artificial intelligence content generation has been rapidly accelerated with the booming text-to-image (T2I) diffusion models. Within just two years of development, it was unprecedentedly of high-quality, diversity, and creativity that the state-of-the-art models could generate. However, a prevalent limitation persists in the effective communication with these popular T2I models, such as Stable Diffusion, using natural language descriptions. This typically makes an engaging image hard to obtain without expertise in prompt engineering with complex word compositions, magic tags, and annotations. Inspired by the recently released DALLE3 - a T2I model directly built-in ChatGPT that talks human language, we revisit the existing T2I systems endeavoring to align human intent and introduce a new task - interactive text to image (iT2I), where people can interact with LLM for interleaved high-quality image generation/edit/refinement and question answering with stronger images a",
    "path": "papers/23/10/2310.07653.json",
    "total_tokens": 1007,
    "translated_title": "这里是翻译过的论文标题：Mini-DALLE3：通过提示大型语言模型进行交互式文本生成图像",
    "translated_abstract": "人工智能内容生成的革命在繁盛的文本生成图像（T2I）扩散模型中得到了快速推进。在仅仅两年的发展中，最先进的模型能够以前所未有的高质量、多样性和创造力生成图像。然而，目前普遍存在的一个限制是使用自然语言描述与这些流行的T2I模型，如稳定扩散（Stable Diffusion）进行有效的交流。这通常使得获取一个有吸引力的图像变得困难，除非在复杂的提示工程中具有专业知识，包括复杂的单词组合、魔法标签和注释。受最近发布的DALLE3的启发，DALLE3是一个直接内置于ChatGPT中以人类语言进行对话的T2I模型，我们重新审视现有的T2I系统，努力实现人类意图的对齐，并引入了一项新任务 - 交互式文本生成图像（iT2I），在这个任务中，人们可以与语言模型进行交互，交替生成/编辑/优化高质量的图像并进行问答，以获得更强大的图像。",
    "tldr": "这里是中文总结出的一句话要点：在本论文中，通过引入交互式文本生成图像（iT2I）的新任务，提出了Mini-DALLE3模型，通过与大型语言模型的交互，用户可以实现更好质量的图像生成、编辑和优化。",
    "en_tdlr": "这里是英文总结出的一句话要点：This paper introduces the Mini-DALLE3 model, which addresses the limitation of effective communication with popular text-to-image (T2I) models by proposing a new task called interactive text to image (iT2I). Through interacting with large language models, users can achieve better quality image generation, editing, and refinement."
}