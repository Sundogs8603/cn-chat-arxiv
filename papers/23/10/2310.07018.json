{
    "title": "NEWTON: Are Large Language Models Capable of Physical Reasoning?. (arXiv:2310.07018v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs), through their contextualized representations, have been empirically proven to encapsulate syntactic, semantic, word sense, and common-sense knowledge. However, there has been limited exploration of their physical reasoning abilities, specifically concerning the crucial attributes for comprehending everyday objects. To address this gap, we introduce NEWTON, a repository and benchmark for evaluating the physics reasoning skills of LLMs. Further, to enable domain-specific adaptation of this benchmark, we present a pipeline to enable researchers to generate a variant of this benchmark that has been customized to the objects and attributes relevant for their application. The NEWTON repository comprises a collection of 2800 object-attribute pairs, providing the foundation for generating infinite-scale assessment templates. The NEWTON benchmark consists of 160K QA questions, curated using the NEWTON repository to investigate the physical reasoning capabilities of",
    "link": "http://arxiv.org/abs/2310.07018",
    "context": "Title: NEWTON: Are Large Language Models Capable of Physical Reasoning?. (arXiv:2310.07018v1 [cs.CL])\nAbstract: Large Language Models (LLMs), through their contextualized representations, have been empirically proven to encapsulate syntactic, semantic, word sense, and common-sense knowledge. However, there has been limited exploration of their physical reasoning abilities, specifically concerning the crucial attributes for comprehending everyday objects. To address this gap, we introduce NEWTON, a repository and benchmark for evaluating the physics reasoning skills of LLMs. Further, to enable domain-specific adaptation of this benchmark, we present a pipeline to enable researchers to generate a variant of this benchmark that has been customized to the objects and attributes relevant for their application. The NEWTON repository comprises a collection of 2800 object-attribute pairs, providing the foundation for generating infinite-scale assessment templates. The NEWTON benchmark consists of 160K QA questions, curated using the NEWTON repository to investigate the physical reasoning capabilities of",
    "path": "papers/23/10/2310.07018.json",
    "total_tokens": 772,
    "translated_title": "NEWTON: 大型语言模型能够进行物理推理吗？",
    "translated_abstract": "通过其语境化表示，大型语言模型（LLM）被实证地证明包含句法、语义、词义和常识知识。然而，对于它们在物理推理能力方面的探索还有一定限制，特别是涉及理解日常物体的关键属性。为了解决这一问题，我们引入了NEWTON，一个用于评估LLM的物理推理能力的仓库和基准。此外，为了实现此基准的领域特定适应，我们提供了一种流程，使研究人员能够生成一个根据他们应用程序相关物体和属性定制的基准变体。NEWTON仓库包括2800个物体-属性对的集合，为生成无限规模的评估模板奠定基础。NEWTON基准包含160K个问答问题，使用NEWTON仓库策划，以调查物理推理能力。",
    "tldr": "NEWTON是一个用于评估大型语言模型物理推理能力的仓库和基准，包含2800个物体-属性对和160K个问答问题。"
}