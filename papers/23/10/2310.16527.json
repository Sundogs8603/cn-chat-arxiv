{
    "title": "Enhancing Document Information Analysis with Multi-Task Pre-training: A Robust Approach for Information Extraction in Visually-Rich Documents. (arXiv:2310.16527v1 [cs.CV])",
    "abstract": "This paper introduces a deep learning model tailored for document information analysis, emphasizing document classification, entity relation extraction, and document visual question answering. The proposed model leverages transformer-based models to encode all the information present in a document image, including textual, visual, and layout information. The model is pre-trained and subsequently fine-tuned for various document image analysis tasks. The proposed model incorporates three additional tasks during the pre-training phase, including reading order identification of different layout segments in a document image, layout segments categorization as per PubLayNet, and generation of the text sequence within a given layout segment (text block). The model also incorporates a collective pre-training scheme where losses of all the tasks under consideration, including pre-training and fine-tuning tasks with all datasets, are considered. Additional encoder and decoder blocks are added to ",
    "link": "http://arxiv.org/abs/2310.16527",
    "context": "Title: Enhancing Document Information Analysis with Multi-Task Pre-training: A Robust Approach for Information Extraction in Visually-Rich Documents. (arXiv:2310.16527v1 [cs.CV])\nAbstract: This paper introduces a deep learning model tailored for document information analysis, emphasizing document classification, entity relation extraction, and document visual question answering. The proposed model leverages transformer-based models to encode all the information present in a document image, including textual, visual, and layout information. The model is pre-trained and subsequently fine-tuned for various document image analysis tasks. The proposed model incorporates three additional tasks during the pre-training phase, including reading order identification of different layout segments in a document image, layout segments categorization as per PubLayNet, and generation of the text sequence within a given layout segment (text block). The model also incorporates a collective pre-training scheme where losses of all the tasks under consideration, including pre-training and fine-tuning tasks with all datasets, are considered. Additional encoder and decoder blocks are added to ",
    "path": "papers/23/10/2310.16527.json",
    "total_tokens": 979,
    "translated_title": "利用多任务预训练增强文档信息分析：一种面向视觉丰富文档中信息提取的鲁棒方法",
    "translated_abstract": "本文介绍了一种专门用于文档信息分析的深度学习模型，重点关注文档分类、实体关系提取和文档视觉问题回答。所提出的模型利用基于transformer的模型来编码文档图像中的所有信息，包括文本、视觉和布局信息。该模型经过预训练后，继续对各种文档图像分析任务进行微调。在预训练阶段，所提出的模型还包括三个额外的任务，包括识别文档图像中不同布局段落的阅读顺序、根据PubLayNet对布局段落进行分类以及生成给定布局段落（文本块）内的文本序列。该模型还采用了一种集体预训练方案，其中考虑了所有考虑的任务的损失，包括使用所有数据集进行的预训练和微调任务。此外，还添加了额外的编码器和解码器块。",
    "tldr": "本文提出了一种深度学习模型，通过多任务预训练来增强文档信息分析的能力，实现了对视觉丰富文档中信息的提取。模型利用transformer-based模型编码文档图像的各种信息，并通过预训练和微调来优化各种文档图像分析任务。另外，模型还包括了额外的任务和集体预训练方案。",
    "en_tdlr": "This paper proposes a deep learning model that enhances document information analysis with multi-task pre-training, achieving robust information extraction in visually-rich documents. The model utilizes transformer-based models to encode various types of information in document images and is fine-tuned for different document image analysis tasks. Additionally, it incorporates additional tasks and a collective pre-training scheme."
}