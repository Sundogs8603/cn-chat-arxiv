{
    "title": "Fast Scalable and Accurate Discovery of DAGs Using the Best Order Score Search and Grow-Shrink Trees. (arXiv:2310.17679v1 [cs.LG])",
    "abstract": "Learning graphical conditional independence structures is an important machine learning problem and a cornerstone of causal discovery. However, the accuracy and execution time of learning algorithms generally struggle to scale to problems with hundreds of highly connected variables -- for instance, recovering brain networks from fMRI data. We introduce the best order score search (BOSS) and grow-shrink trees (GSTs) for learning directed acyclic graphs (DAGs) in this paradigm. BOSS greedily searches over permutations of variables, using GSTs to construct and score DAGs from permutations. GSTs efficiently cache scores to eliminate redundant calculations. BOSS achieves state-of-the-art performance in accuracy and execution time, comparing favorably to a variety of combinatorial and gradient-based learning algorithms under a broad range of conditions. To demonstrate its practicality, we apply BOSS to two sets of resting-state fMRI data: simulated data with pseudo-empirical noise distributi",
    "link": "http://arxiv.org/abs/2310.17679",
    "context": "Title: Fast Scalable and Accurate Discovery of DAGs Using the Best Order Score Search and Grow-Shrink Trees. (arXiv:2310.17679v1 [cs.LG])\nAbstract: Learning graphical conditional independence structures is an important machine learning problem and a cornerstone of causal discovery. However, the accuracy and execution time of learning algorithms generally struggle to scale to problems with hundreds of highly connected variables -- for instance, recovering brain networks from fMRI data. We introduce the best order score search (BOSS) and grow-shrink trees (GSTs) for learning directed acyclic graphs (DAGs) in this paradigm. BOSS greedily searches over permutations of variables, using GSTs to construct and score DAGs from permutations. GSTs efficiently cache scores to eliminate redundant calculations. BOSS achieves state-of-the-art performance in accuracy and execution time, comparing favorably to a variety of combinatorial and gradient-based learning algorithms under a broad range of conditions. To demonstrate its practicality, we apply BOSS to two sets of resting-state fMRI data: simulated data with pseudo-empirical noise distributi",
    "path": "papers/23/10/2310.17679.json",
    "total_tokens": 953,
    "translated_title": "使用最佳顺序分数搜索和生长-收缩树快速扩展的DAG发现方法",
    "translated_abstract": "学习图形条件独立结构是一个重要的机器学习问题，也是因果发现的基石。然而，学习算法的准确性和执行时间通常难以适应具有数百个高度连接的变量的问题，例如从fMRI数据中恢复脑网络。我们介绍了最佳顺序分数搜索（BOSS）和生长-收缩树（GSTs）用于在这个范例中学习有向无环图（DAGs）。BOSS贪婪地搜索变量的排列，使用GSTs从排列构建和评分DAGs。GSTs有效地缓存分数以消除冗余计算。BOSS在准确性和执行时间方面达到了最先进的性能，在广泛的条件下与各种组合和基于梯度的学习算法进行了有利的比较。为了证明它的实用性，我们将BOSS应用于两组静息态fMRI数据：带有伪经验噪声分布的模拟数据",
    "tldr": "本论文介绍了一种用于学习有向无环图的最佳顺序分数搜索（BOSS）和生长-收缩树（GSTs）方法，该方法在准确性和执行时间方面达到了最先进的性能，适用于具有数百个高度连接的变量的问题，例如从fMRI数据中恢复脑网络。"
}