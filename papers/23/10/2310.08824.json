{
    "title": "Confounding-Robust Policy Improvement with Human-AI Teams. (arXiv:2310.08824v1 [cs.HC])",
    "abstract": "Human-AI collaboration has the potential to transform various domains by leveraging the complementary strengths of human experts and Artificial Intelligence (AI) systems. However, unobserved confounding can undermine the effectiveness of this collaboration, leading to biased and unreliable outcomes. In this paper, we propose a novel solution to address unobserved confounding in human-AI collaboration by employing the marginal sensitivity model (MSM). Our approach combines domain expertise with AI-driven statistical modeling to account for potential confounders that may otherwise remain hidden. We present a deferral collaboration framework for incorporating the MSM into policy learning from observational data, enabling the system to control for the influence of unobserved confounding factors. In addition, we propose a personalized deferral collaboration system to leverage the diverse expertise of different human decision-makers. By adjusting for potential biases, our proposed solution e",
    "link": "http://arxiv.org/abs/2310.08824",
    "context": "Title: Confounding-Robust Policy Improvement with Human-AI Teams. (arXiv:2310.08824v1 [cs.HC])\nAbstract: Human-AI collaboration has the potential to transform various domains by leveraging the complementary strengths of human experts and Artificial Intelligence (AI) systems. However, unobserved confounding can undermine the effectiveness of this collaboration, leading to biased and unreliable outcomes. In this paper, we propose a novel solution to address unobserved confounding in human-AI collaboration by employing the marginal sensitivity model (MSM). Our approach combines domain expertise with AI-driven statistical modeling to account for potential confounders that may otherwise remain hidden. We present a deferral collaboration framework for incorporating the MSM into policy learning from observational data, enabling the system to control for the influence of unobserved confounding factors. In addition, we propose a personalized deferral collaboration system to leverage the diverse expertise of different human decision-makers. By adjusting for potential biases, our proposed solution e",
    "path": "papers/23/10/2310.08824.json",
    "total_tokens": 1003,
    "translated_title": "带有人工智能团队的混淆鲁棒的策略改进",
    "translated_abstract": "人工智能与人类的合作有可能通过充分发挥人类专家和人工智能系统的相互补充优势来改变各个领域。然而，未被观察到的混淆可能会破坏这种合作的有效性，导致偏见和不可靠的结果。本文提出了一种解决人工智能与人类合作中未被观察到的混淆问题的新方法，即采用边际灵敏度模型（MSM）。我们的方法将领域专业知识与基于人工智能的统计建模相结合，以考虑潜在的可能会隐藏的混淆因素。我们提出了一个推迟合作框架，将边际灵敏度模型纳入观测数据中的策略学习，使系统能够控制未被观察到的混淆因素的影响。此外，我们提出了一个个性化的推迟合作系统，以利用不同人类决策者的多样化专业知识。通过调整潜在的偏见，我们的解决方案能够提高合作结果的可靠性。",
    "tldr": "本文提出了一种通过采用边际灵敏度模型来解决人工智能与人类合作中未被观察到的混淆问题的新方法。该方法结合了领域专业知识和基于人工智能的统计建模，以控制潜在的混淆因素的影响，并通过推迟合作系统来利用不同决策者的专业知识。",
    "en_tdlr": "This paper proposes a novel solution to address unobserved confounding in human-AI collaboration by employing the marginal sensitivity model (MSM). The approach combines domain expertise with AI-driven statistical modeling to control for potential confounders and leverages a deferral collaboration system to utilize diverse decision-makers' expertise."
}