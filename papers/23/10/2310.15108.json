{
    "title": "Evaluating machine learning models in non-standard settings: An overview and new findings. (arXiv:2310.15108v1 [stat.ML])",
    "abstract": "Estimating the generalization error (GE) of machine learning models is fundamental, with resampling methods being the most common approach. However, in non-standard settings, particularly those where observations are not independently and identically distributed, resampling using simple random data divisions may lead to biased GE estimates. This paper strives to present well-grounded guidelines for GE estimation in various such non-standard settings: clustered data, spatial data, unequal sampling probabilities, concept drift, and hierarchically structured outcomes. Our overview combines well-established methodologies with other existing methods that, to our knowledge, have not been frequently considered in these particular settings. A unifying principle among these techniques is that the test data used in each iteration of the resampling procedure should reflect the new observations to which the model will be applied, while the training data should be representative of the entire data ",
    "link": "http://arxiv.org/abs/2310.15108",
    "context": "Title: Evaluating machine learning models in non-standard settings: An overview and new findings. (arXiv:2310.15108v1 [stat.ML])\nAbstract: Estimating the generalization error (GE) of machine learning models is fundamental, with resampling methods being the most common approach. However, in non-standard settings, particularly those where observations are not independently and identically distributed, resampling using simple random data divisions may lead to biased GE estimates. This paper strives to present well-grounded guidelines for GE estimation in various such non-standard settings: clustered data, spatial data, unequal sampling probabilities, concept drift, and hierarchically structured outcomes. Our overview combines well-established methodologies with other existing methods that, to our knowledge, have not been frequently considered in these particular settings. A unifying principle among these techniques is that the test data used in each iteration of the resampling procedure should reflect the new observations to which the model will be applied, while the training data should be representative of the entire data ",
    "path": "papers/23/10/2310.15108.json",
    "total_tokens": 950,
    "translated_title": "在非标准环境中评估机器学习模型：综述与新发现",
    "translated_abstract": "估计机器学习模型的泛化误差是基本的，采用重采样方法是最常见的方法。然而，在非标准环境中，特别是观测值不是独立同分布的情况下，使用简单的随机数据划分进行重采样可能导致偏倚的泛化误差估计。本文旨在提供在各种非标准环境中进行泛化误差估计的可靠准则：聚类数据、空间数据、不均匀采样概率、概念漂移和层次结构化结果。我们的综述将已建立的方法与我们所知的其他在这些特定情景中较少被考虑的方法相结合。这些技术之间的一个统一原则是，在重采样过程的每次迭代中使用的测试数据应反映出模型将要应用的新观测数据，而训练数据应代表整个数据集。",
    "tldr": "本文综述了在非标准环境中评估机器学习模型的准则和方法，包括聚类数据、空间数据、不均匀采样概率、概念漂移和层次结构化结果。其中的统一原则是在重采样过程中使用的测试数据应反映出模型将要应用的新观测数据，而训练数据应代表整个数据集。",
    "en_tdlr": "This paper provides guidelines and methods for evaluating machine learning models in non-standard settings, including clustered data, spatial data, unequal sampling probabilities, concept drift, and hierarchically structured outcomes. The unifying principle is that the test data used in the resampling process should reflect the new observations to which the model will be applied, while the training data should be representative of the entire dataset."
}