{
    "title": "Ada-Instruct: Adapting Instruction Generators for Complex Reasoning. (arXiv:2310.04484v2 [cs.CL] UPDATED)",
    "abstract": "Generating diverse and sophisticated instructions for downstream tasks by Large Language Models (LLMs) is pivotal for advancing the effect. Current approaches leverage closed-source LLMs, employing in-context prompting for instruction generation. However, in this paper, we found that in-context prompting cannot generate complex instructions with length $\\ge 100$ for tasks like code completion.  To solve this problem, we introduce Ada-Instruct, an adaptive instruction generator developed by fine-tuning open-source LLMs. Our pivotal finding illustrates that fine-tuning open-source LLMs with a mere ten samples generates long instructions that maintain distributional consistency for complex reasoning tasks. We empirically validated Ada-Instruct's efficacy across different applications, including code completion, mathematical reasoning, and commonsense reasoning. The results underscore Ada-Instruct's superiority, evidencing its improvements over its base models, current self-instruct method",
    "link": "http://arxiv.org/abs/2310.04484",
    "context": "Title: Ada-Instruct: Adapting Instruction Generators for Complex Reasoning. (arXiv:2310.04484v2 [cs.CL] UPDATED)\nAbstract: Generating diverse and sophisticated instructions for downstream tasks by Large Language Models (LLMs) is pivotal for advancing the effect. Current approaches leverage closed-source LLMs, employing in-context prompting for instruction generation. However, in this paper, we found that in-context prompting cannot generate complex instructions with length $\\ge 100$ for tasks like code completion.  To solve this problem, we introduce Ada-Instruct, an adaptive instruction generator developed by fine-tuning open-source LLMs. Our pivotal finding illustrates that fine-tuning open-source LLMs with a mere ten samples generates long instructions that maintain distributional consistency for complex reasoning tasks. We empirically validated Ada-Instruct's efficacy across different applications, including code completion, mathematical reasoning, and commonsense reasoning. The results underscore Ada-Instruct's superiority, evidencing its improvements over its base models, current self-instruct method",
    "path": "papers/23/10/2310.04484.json",
    "total_tokens": 852,
    "translated_title": "Ada-Instruct: 为复杂推理调整指令生成器",
    "translated_abstract": "通过大型语言模型（LLM）生成多样且复杂的指令对于推进效果至关重要。当前的方法利用闭源的LLMs，通过上下文提示进行指令生成。然而，本文发现对于诸如代码补全等任务，上下文提示无法生成长度大于等于100的复杂指令。为解决这个问题，我们引入Ada-Instruct，一种通过对开源LLMs进行微调的自适应指令生成器。我们的关键发现表明，仅使用十个样本对开源LLMs进行微调即可生成保持分布一致性的长指令，适用于复杂推理任务。我们在代码补全、数学推理和常识推理等不同应用中对Ada-Instruct的有效性进行了实证验证。结果显示Ada-Instruct优于其基本模型和当前的自我指导方法。",
    "tldr": "Ada-Instruct是一种自适应指令生成器，通过对开源LLMs进行微调，能够生成复杂推理任务中长度大于等于100的指令。在代码补全、数学推理和常识推理等任务中，Ada-Instruct显示出优于基本模型和当前自我指导方法的改进效果。"
}