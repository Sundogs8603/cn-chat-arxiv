{
    "title": "Multi-level Adaptive Contrastive Learning for Knowledge Internalization in Dialogue Generation. (arXiv:2310.08943v1 [cs.CL])",
    "abstract": "Knowledge-grounded dialogue generation aims to mitigate the issue of text degeneration by incorporating external knowledge to supplement the context. However, the model often fails to internalize this information into responses in a human-like manner. Instead, it simply inserts segments of the provided knowledge into generic responses. As a result, the generated responses tend to be tedious, incoherent, and in lack of interactivity which means the degeneration problem is still unsolved. In this work, we first find that such copying-style degeneration is primarily due to the weak likelihood objective, which allows the model to \"cheat\" the objective by merely duplicating knowledge segments in a superficial pattern matching based on overlap. To overcome this challenge, we then propose a Multi-level Adaptive Contrastive Learning (MACL) framework that dynamically samples negative examples and subsequently penalizes degeneration behaviors at both the token-level and sequence-level. Extensive",
    "link": "http://arxiv.org/abs/2310.08943",
    "context": "Title: Multi-level Adaptive Contrastive Learning for Knowledge Internalization in Dialogue Generation. (arXiv:2310.08943v1 [cs.CL])\nAbstract: Knowledge-grounded dialogue generation aims to mitigate the issue of text degeneration by incorporating external knowledge to supplement the context. However, the model often fails to internalize this information into responses in a human-like manner. Instead, it simply inserts segments of the provided knowledge into generic responses. As a result, the generated responses tend to be tedious, incoherent, and in lack of interactivity which means the degeneration problem is still unsolved. In this work, we first find that such copying-style degeneration is primarily due to the weak likelihood objective, which allows the model to \"cheat\" the objective by merely duplicating knowledge segments in a superficial pattern matching based on overlap. To overcome this challenge, we then propose a Multi-level Adaptive Contrastive Learning (MACL) framework that dynamically samples negative examples and subsequently penalizes degeneration behaviors at both the token-level and sequence-level. Extensive",
    "path": "papers/23/10/2310.08943.json",
    "total_tokens": 918,
    "translated_title": "多层自适应对比学习在对话生成中的知识内化",
    "translated_abstract": "知识引导的对话生成旨在通过整合外部知识来补充上下文，从而缓解文本退化问题。然而，模型往往无法以类似人类的方式将此信息内化到回答中。相反，它只是简单地将提供的知识片段插入到普通的回答中。因此，生成的回答往往乏味、不连贯，并且缺乏互动性，这意味着退化问题仍未解决。在这项工作中，我们首先发现，这种复制式退化主要是由于弱概率目标造成的，它允许模型通过仅基于重叠的表面模式匹配来“欺骗”目标。为了克服这个挑战，我们提出了一个多层自适应对比学习（MACL）框架，该框架在令牌级和序列级上动态采样负例，并随后惩罚退化行为。",
    "tldr": "这是一篇关于知识引导对话生成的论文，通过引入多层自适应对比学习（MACL）框架，并在令牌级和序列级上动态采样负例来解决模型简单插入知识片段导致的退化问题。",
    "en_tdlr": "This paper proposes a Multi-level Adaptive Contrastive Learning (MACL) framework to address the issue of text degeneration in knowledge-grounded dialogue generation. By dynamically sampling negative examples and penalizing degeneration behaviors at both the token-level and sequence-level, the framework improves the internalization of external knowledge and generates more coherent and interactive responses."
}