{
    "title": "Extreme sparsification of physics-augmented neural networks for interpretable model discovery in mechanics. (arXiv:2310.03652v1 [cs.CE])",
    "abstract": "Data-driven constitutive modeling with neural networks has received increased interest in recent years due to its ability to easily incorporate physical and mechanistic constraints and to overcome the challenging and time-consuming task of formulating phenomenological constitutive laws that can accurately capture the observed material response. However, even though neural network-based constitutive laws have been shown to generalize proficiently, the generated representations are not easily interpretable due to their high number of trainable parameters. Sparse regression approaches exist that allow to obtaining interpretable expressions, but the user is tasked with creating a library of model forms which by construction limits their expressiveness to the functional forms provided in the libraries. In this work, we propose to train regularized physics-augmented neural network-based constitutive models utilizing a smoothed version of $L^{0}$-regularization. This aims to maintain the trus",
    "link": "http://arxiv.org/abs/2310.03652",
    "context": "Title: Extreme sparsification of physics-augmented neural networks for interpretable model discovery in mechanics. (arXiv:2310.03652v1 [cs.CE])\nAbstract: Data-driven constitutive modeling with neural networks has received increased interest in recent years due to its ability to easily incorporate physical and mechanistic constraints and to overcome the challenging and time-consuming task of formulating phenomenological constitutive laws that can accurately capture the observed material response. However, even though neural network-based constitutive laws have been shown to generalize proficiently, the generated representations are not easily interpretable due to their high number of trainable parameters. Sparse regression approaches exist that allow to obtaining interpretable expressions, but the user is tasked with creating a library of model forms which by construction limits their expressiveness to the functional forms provided in the libraries. In this work, we propose to train regularized physics-augmented neural network-based constitutive models utilizing a smoothed version of $L^{0}$-regularization. This aims to maintain the trus",
    "path": "papers/23/10/2310.03652.json",
    "total_tokens": 881,
    "translated_title": "物理增强神经网络的极度稀疏化：用于可解释的模型发现在力学中",
    "translated_abstract": "近年来，基于神经网络的数据驱动本构建模在物理学中受到越来越多的关注，因为它能够轻松地融入物理和机制约束，并且能够克服描述物质响应的表象本构定律的费时且具有挑战性的任务。然而，尽管基于神经网络的本构定律显示出良好的泛化能力，但由于其可训练参数数量过多，所生成的表示形式不容易解释。存在着稀疏回归方法可以获得可解释的表达式，但用户需要创建模型形式的库，这限制了库所提供的函数形式的表达能力。在这项工作中，我们提出了使用平滑的$L^{0}$正则化训练物理增强神经网络的本构模型。这旨在维持对真实情况的建模能力的同时产生可解释性的结果。",
    "tldr": "该论文提出了一种训练物理增强神经网络的极度稀疏化方法，以实现在力学中可解释的模型发现。这种方法能够生成具有较少可训练参数的本构模型，使其更易于解释和理解。"
}