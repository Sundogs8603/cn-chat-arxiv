{
    "title": "Class-Incremental Learning Using Generative Experience Replay Based on Time-aware Regularization. (arXiv:2310.03898v1 [cs.LG])",
    "abstract": "Learning new tasks accumulatively without forgetting remains a critical challenge in continual learning. Generative experience replay addresses this challenge by synthesizing pseudo-data points for past learned tasks and later replaying them for concurrent training along with the new tasks' data. Generative replay is the best strategy for continual learning under a strict class-incremental setting when certain constraints need to be met: (i) constant model size, (ii) no pre-training dataset, and (iii) no memory buffer for storing past tasks' data. Inspired by the biological nervous system mechanisms, we introduce a time-aware regularization method to dynamically fine-tune the three training objective terms used for generative replay: supervised learning, latent regularization, and data reconstruction. Experimental results on major benchmarks indicate that our method pushes the limit of brain-inspired continual learners under such strict settings, improves memory retention, and increase",
    "link": "http://arxiv.org/abs/2310.03898",
    "context": "Title: Class-Incremental Learning Using Generative Experience Replay Based on Time-aware Regularization. (arXiv:2310.03898v1 [cs.LG])\nAbstract: Learning new tasks accumulatively without forgetting remains a critical challenge in continual learning. Generative experience replay addresses this challenge by synthesizing pseudo-data points for past learned tasks and later replaying them for concurrent training along with the new tasks' data. Generative replay is the best strategy for continual learning under a strict class-incremental setting when certain constraints need to be met: (i) constant model size, (ii) no pre-training dataset, and (iii) no memory buffer for storing past tasks' data. Inspired by the biological nervous system mechanisms, we introduce a time-aware regularization method to dynamically fine-tune the three training objective terms used for generative replay: supervised learning, latent regularization, and data reconstruction. Experimental results on major benchmarks indicate that our method pushes the limit of brain-inspired continual learners under such strict settings, improves memory retention, and increase",
    "path": "papers/23/10/2310.03898.json",
    "total_tokens": 907,
    "translated_title": "基于时间感知正则化的生成经验重放的增量学习",
    "translated_abstract": "在连续学习中，学习新任务而不遗忘旧任务仍然是一个重要挑战。生成经验重放通过合成过去学习任务的伪数据点，并在与新任务的数据一起并行训练时进行重放，从而解决了这个挑战。在严格的增量类别设置下，生成重放是连续学习的最佳策略，同时要满足一些约束条件：（i）模型大小固定，（ii）没有预训练数据集，（iii）没有用于存储过去任务数据的内存缓冲区。受生物神经系统机制的启发，我们引入了一种时间感知正则化方法，动态调整生成重放的三个训练目标项：监督学习、潜在正则化和数据重构。主要基准测试结果表明，我们的方法在这种严格设置下推动了受大脑启发的连续学习模型的极限，提高了记忆保留和模型性能。",
    "tldr": "提出了一种基于时间感知正则化的生成经验重放的增量学习方法，解决了连续学习中新任务累积且不遗忘旧任务的挑战。实验证明该方法在严格的增量类别设置下具有较好的记忆保留和模型性能。"
}