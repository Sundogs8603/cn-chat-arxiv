{
    "title": "Robustness to Multi-Modal Environment Uncertainty in MARL using Curriculum Learning. (arXiv:2310.08746v1 [cs.LG])",
    "abstract": "Multi-agent reinforcement learning (MARL) plays a pivotal role in tackling real-world challenges. However, the seamless transition of trained policies from simulations to real-world requires it to be robust to various environmental uncertainties. Existing works focus on finding Nash Equilibrium or the optimal policy under uncertainty in one environment variable (i.e. action, state or reward). This is because a multi-agent system itself is highly complex and unstationary. However, in real-world situation uncertainty can occur in multiple environment variables simultaneously. This work is the first to formulate the generalised problem of robustness to multi-modal environment uncertainty in MARL. To this end, we propose a general robust training approach for multi-modal uncertainty based on curriculum learning techniques. We handle two distinct environmental uncertainty simultaneously and present extensive results across both cooperative and competitive MARL environments, demonstrating th",
    "link": "http://arxiv.org/abs/2310.08746",
    "context": "Title: Robustness to Multi-Modal Environment Uncertainty in MARL using Curriculum Learning. (arXiv:2310.08746v1 [cs.LG])\nAbstract: Multi-agent reinforcement learning (MARL) plays a pivotal role in tackling real-world challenges. However, the seamless transition of trained policies from simulations to real-world requires it to be robust to various environmental uncertainties. Existing works focus on finding Nash Equilibrium or the optimal policy under uncertainty in one environment variable (i.e. action, state or reward). This is because a multi-agent system itself is highly complex and unstationary. However, in real-world situation uncertainty can occur in multiple environment variables simultaneously. This work is the first to formulate the generalised problem of robustness to multi-modal environment uncertainty in MARL. To this end, we propose a general robust training approach for multi-modal uncertainty based on curriculum learning techniques. We handle two distinct environmental uncertainty simultaneously and present extensive results across both cooperative and competitive MARL environments, demonstrating th",
    "path": "papers/23/10/2310.08746.json",
    "total_tokens": 867,
    "translated_title": "在多模态环境不确定性中，使用课程学习提高MARL的稳健性",
    "translated_abstract": "多智能体强化学习（MARL）在解决现实世界的挑战中起着重要作用。然而，将训练好的策略从仿真环境无缝过渡到现实世界需要它对各种环境不确定性具有稳健性。现有的工作集中在在单个环境变量（即行动、状态或奖励）的不确定性下找到纳什均衡或最优策略。这是因为多智能体系统本身非常复杂和非平稳。然而，在现实世界中，不确定性可能同时发生在多个环境变量中。本研究首次提出了在MARL中针对多模态环境不确定性的广义问题。为此，我们提出了一种基于课程学习技术的多模态不确定性的通用稳健训练方法。我们同时处理两种不同的环境不确定性，并在合作和竞争的MARL环境中呈现了广泛的结果，证明了我们的方法的有效性。",
    "tldr": "本文首次提出了在多模态环境不确定性中提高MARL稳健性的广义问题，并通过课程学习技术提出了通用的稳健训练方法。"
}