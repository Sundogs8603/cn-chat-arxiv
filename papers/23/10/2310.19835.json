{
    "title": "CrossEAI: Using Explainable AI to generate better bounding boxes for Chest X-ray images. (arXiv:2310.19835v1 [eess.IV])",
    "abstract": "Explainability is critical for deep learning applications in healthcare which are mandated to provide interpretations to both patients and doctors according to legal regulations and responsibilities. Explainable AI methods, such as feature importance using integrated gradients, model approximation using LIME, or neuron activation and layer conductance to provide interpretations for certain health risk predictions. In medical imaging diagnosis, disease classification usually achieves high accuracy, but generated bounding boxes have much lower Intersection over Union (IoU). Different methods with self-supervised or semi-supervised learning strategies have been proposed, but few improvements have been identified for bounding box generation. Previous work shows that bounding boxes generated by these methods are usually larger than ground truth and contain major non-disease area. This paper utilizes the advantages of post-hoc AI explainable methods to generate bounding boxes for chest x-ray",
    "link": "http://arxiv.org/abs/2310.19835",
    "context": "Title: CrossEAI: Using Explainable AI to generate better bounding boxes for Chest X-ray images. (arXiv:2310.19835v1 [eess.IV])\nAbstract: Explainability is critical for deep learning applications in healthcare which are mandated to provide interpretations to both patients and doctors according to legal regulations and responsibilities. Explainable AI methods, such as feature importance using integrated gradients, model approximation using LIME, or neuron activation and layer conductance to provide interpretations for certain health risk predictions. In medical imaging diagnosis, disease classification usually achieves high accuracy, but generated bounding boxes have much lower Intersection over Union (IoU). Different methods with self-supervised or semi-supervised learning strategies have been proposed, but few improvements have been identified for bounding box generation. Previous work shows that bounding boxes generated by these methods are usually larger than ground truth and contain major non-disease area. This paper utilizes the advantages of post-hoc AI explainable methods to generate bounding boxes for chest x-ray",
    "path": "papers/23/10/2310.19835.json",
    "total_tokens": 882,
    "translated_title": "CrossEAI: 使用可解释的人工智能生成更好的胸部X射线图像边界框",
    "translated_abstract": "可解释性对于医疗保健中的深度学习应用非常重要，这些应用根据法律法规和责任要求向患者和医生提供解释。可解释的人工智能方法，如使用集成梯度的特征重要性、使用LIME的模型逼近，或者使用神经元激活和层导电来提供对某些健康风险预测的解释。在医学成像诊断中，疾病分类通常能够达到很高的准确性，但生成的边界框的交并比（IoU）要低得多。已经提出了不同的自监督或半监督学习策略的方法，但在边界框生成方面很少有改进。以前的工作表明，通过这些方法生成的边界框通常比真实值更大，并包含主要的非疾病区域。本文利用事后可解释的人工智能方法，为胸部X射线图像生成边界框。",
    "tldr": "这篇论文利用可解释的人工智能方法生成胸部X射线图像的边界框，提供了对医学成像诊断的解释，并试图改进现有方法中边界框生成的问题。"
}