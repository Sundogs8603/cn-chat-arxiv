{
    "title": "Beyond Memorization: Violating Privacy Via Inference with Large Language Models. (arXiv:2310.07298v1 [cs.AI])",
    "abstract": "Current privacy research on large language models (LLMs) primarily focuses on the issue of extracting memorized training data. At the same time, models' inference capabilities have increased drastically. This raises the key question of whether current LLMs could violate individuals' privacy by inferring personal attributes from text given at inference time. In this work, we present the first comprehensive study on the capabilities of pretrained LLMs to infer personal attributes from text. We construct a dataset consisting of real Reddit profiles, and show that current LLMs can infer a wide range of personal attributes (e.g., location, income, sex), achieving up to $85\\%$ top-1 and $95.8\\%$ top-3 accuracy at a fraction of the cost ($100\\times$) and time ($240\\times$) required by humans. As people increasingly interact with LLM-powered chatbots across all aspects of life, we also explore the emerging threat of privacy-invasive chatbots trying to extract personal information through seemi",
    "link": "http://arxiv.org/abs/2310.07298",
    "context": "Title: Beyond Memorization: Violating Privacy Via Inference with Large Language Models. (arXiv:2310.07298v1 [cs.AI])\nAbstract: Current privacy research on large language models (LLMs) primarily focuses on the issue of extracting memorized training data. At the same time, models' inference capabilities have increased drastically. This raises the key question of whether current LLMs could violate individuals' privacy by inferring personal attributes from text given at inference time. In this work, we present the first comprehensive study on the capabilities of pretrained LLMs to infer personal attributes from text. We construct a dataset consisting of real Reddit profiles, and show that current LLMs can infer a wide range of personal attributes (e.g., location, income, sex), achieving up to $85\\%$ top-1 and $95.8\\%$ top-3 accuracy at a fraction of the cost ($100\\times$) and time ($240\\times$) required by humans. As people increasingly interact with LLM-powered chatbots across all aspects of life, we also explore the emerging threat of privacy-invasive chatbots trying to extract personal information through seemi",
    "path": "papers/23/10/2310.07298.json",
    "total_tokens": 988,
    "translated_title": "超越记忆：通过大型语言模型进行推理来侵犯隐私",
    "translated_abstract": "目前关于大型语言模型（LLMs）的隐私研究主要集中在提取记忆训练数据的问题上。同时，模型的推理能力已大幅增强。这引发了一个关键问题，即当前的LLMs是否能够通过从推理时给出的文本中推断个人属性来侵犯个人隐私。在这项工作中，我们首次对预训练LLMs从文本中推断个人属性的能力进行了全面研究。我们构建了一个包含真实Reddit个人资料的数据集，并且显示当前的LLMs可以推断出各种各样的个人属性（例如，位置、收入、性别），在成本（100倍）和时间（240倍）上仅需人类的一小部分，达到了最高1的准确率达到85％，最高3的准确率达到95.8％。随着人们越来越多地与由LLM驱动的聊天机器人在生活的各个方面进行互动，我们还探讨了侵犯隐私的聊天机器人通过似乎无关的对话试图提取个人信息的新威胁。",
    "tldr": "该论文首次全面研究了预训练大型语言模型从文本中推断个人属性的能力，发现当前的模型可以以较低的成本和时间比例，准确地推断出多种个人属性，这引发了隐私泄露的新威胁。"
}