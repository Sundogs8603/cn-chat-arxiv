{
    "title": "1-PAGER: One Pass Answer Generation and Evidence Retrieval. (arXiv:2310.16568v1 [cs.CL])",
    "abstract": "We present 1-Pager the first system that answers a question and retrieves evidence using a single Transformer-based model and decoding process. 1-Pager incrementally partitions the retrieval corpus using constrained decoding to select a document and answer string, and we show that this is competitive with comparable retrieve-and-read alternatives according to both retrieval and answer accuracy metrics. 1-Pager also outperforms the equivalent closed-book question answering model, by grounding predictions in an evidence corpus. While 1-Pager is not yet on-par with more expensive systems that read many more documents before generating an answer, we argue that it provides an important step toward attributed generation by folding retrieval into the sequence-to-sequence paradigm that is currently dominant in NLP. We also show that the search paths used to partition the corpus are easy to read and understand, paving a way forward for interpretable neural retrieval.",
    "link": "http://arxiv.org/abs/2310.16568",
    "context": "Title: 1-PAGER: One Pass Answer Generation and Evidence Retrieval. (arXiv:2310.16568v1 [cs.CL])\nAbstract: We present 1-Pager the first system that answers a question and retrieves evidence using a single Transformer-based model and decoding process. 1-Pager incrementally partitions the retrieval corpus using constrained decoding to select a document and answer string, and we show that this is competitive with comparable retrieve-and-read alternatives according to both retrieval and answer accuracy metrics. 1-Pager also outperforms the equivalent closed-book question answering model, by grounding predictions in an evidence corpus. While 1-Pager is not yet on-par with more expensive systems that read many more documents before generating an answer, we argue that it provides an important step toward attributed generation by folding retrieval into the sequence-to-sequence paradigm that is currently dominant in NLP. We also show that the search paths used to partition the corpus are easy to read and understand, paving a way forward for interpretable neural retrieval.",
    "path": "papers/23/10/2310.16568.json",
    "total_tokens": 915,
    "translated_title": "1-PAGER: 一次通行的回答生成和证据检索",
    "translated_abstract": "我们提出了1-Pager，这是第一个使用单个基于Transformer的模型和解码过程同时回答问题和检索证据的系统。1-Pager使用约束解码逐步分割检索语料库，选择文档和答案字符串，并且我们展示出在检索和回答准确度度量方面，这与可比较的检索和阅读替代方法相比是有竞争力的。1-Pager还通过将预测结果基于证据语料库，胜过了等效的闭书问答模型。虽然1-Pager的表现还不及阅读多个文档后生成答案的更昂贵系统，但我们认为它是向归因生成迈出的重要一步，将检索融入到当前在自然语言处理中占主导地位的序列到序列范式中。我们还展示了用于分割语料库的搜索路径易于阅读和理解，为可解释的神经检索铺平了道路。",
    "tldr": "1-PAGER是第一个使用单一模型和解码过程同时回答问题和检索证据的系统，通过约束解码和证据语料库的利用，达到了与传统的检索和阅读替代方法相比有竞争力的检索和回答准确度。此外，该系统也为可解释的神经检索提供了一种简单易读的搜索路径。"
}