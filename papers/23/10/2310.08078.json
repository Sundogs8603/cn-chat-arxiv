{
    "title": "To token or not to token: A Comparative Study of Text Representations for Cross-Lingual Transfer. (arXiv:2310.08078v1 [cs.CL])",
    "abstract": "Choosing an appropriate tokenization scheme is often a bottleneck in low-resource cross-lingual transfer. To understand the downstream implications of text representation choices, we perform a comparative analysis on language models having diverse text representation modalities including 2 segmentation-based models (\\texttt{BERT}, \\texttt{mBERT}), 1 image-based model (\\texttt{PIXEL}), and 1 character-level model (\\texttt{CANINE}). First, we propose a scoring Language Quotient (LQ) metric capable of providing a weighted representation of both zero-shot and few-shot evaluation combined. Utilizing this metric, we perform experiments comprising 19 source languages and 133 target languages on three tasks (POS tagging, Dependency parsing, and NER). Our analysis reveals that image-based models excel in cross-lingual transfer when languages are closely related and share visually similar scripts. However, for tasks biased toward word meaning (POS, NER), segmentation-based models prove to be sup",
    "link": "http://arxiv.org/abs/2310.08078",
    "context": "Title: To token or not to token: A Comparative Study of Text Representations for Cross-Lingual Transfer. (arXiv:2310.08078v1 [cs.CL])\nAbstract: Choosing an appropriate tokenization scheme is often a bottleneck in low-resource cross-lingual transfer. To understand the downstream implications of text representation choices, we perform a comparative analysis on language models having diverse text representation modalities including 2 segmentation-based models (\\texttt{BERT}, \\texttt{mBERT}), 1 image-based model (\\texttt{PIXEL}), and 1 character-level model (\\texttt{CANINE}). First, we propose a scoring Language Quotient (LQ) metric capable of providing a weighted representation of both zero-shot and few-shot evaluation combined. Utilizing this metric, we perform experiments comprising 19 source languages and 133 target languages on three tasks (POS tagging, Dependency parsing, and NER). Our analysis reveals that image-based models excel in cross-lingual transfer when languages are closely related and share visually similar scripts. However, for tasks biased toward word meaning (POS, NER), segmentation-based models prove to be sup",
    "path": "papers/23/10/2310.08078.json",
    "total_tokens": 951,
    "translated_title": "是否进行词元化：用于跨语言转换的文本表示的比较研究",
    "translated_abstract": "在资源匮乏的跨语言转换中，选择适当的词元化方案往往是一个瓶颈。为了理解文本表示选择的下游影响，我们对具有不同文本表示模态的语言模型进行了比较分析，包括2个基于分割的模型（BERT，mBERT），1个基于图像的模型（PIXEL），和1个字符级模型（CANINE）。首先，我们提出了一个评分语言商数（LQ）指标，能够提供零射击和少射击评估的加权表示。利用这个指标，我们在三个任务（词性标注，依存句法分析和命名实体识别）上进行了包含19个源语言和133个目标语言的实验。我们的分析表明，当语言之间关系密切且具有相似的视觉脚本时，基于图像的模型在跨语言转换中表现出色。然而，对于偏向于单词含义的任务（词性标注，命名实体识别），基于分割的模型证明是更好的选择。",
    "tldr": "本文进行了针对跨语言转换的文本表示方案的比较研究，发现图像模型在相关且脚本相似的语言之间的转换中表现优秀，而基于分割的模型在偏向单词含义的任务中表现更好。",
    "en_tdlr": "This paper presents a comparative study on text representation schemes for cross-lingual transfer, and finds that image-based models excel in transfer between closely related languages with visually similar scripts, while segmentation-based models perform better in tasks biased towards word meaning."
}