{
    "title": "Fighting Fire with Fire: The Dual Role of LLMs in Crafting and Detecting Elusive Disinformation. (arXiv:2310.15515v1 [cs.CL])",
    "abstract": "Recent ubiquity and disruptive impacts of large language models (LLMs) have raised concerns about their potential to be misused (.i.e, generating large-scale harmful and misleading content). To combat this emerging risk of LLMs, we propose a novel \"Fighting Fire with Fire\" (F3) strategy that harnesses modern LLMs' generative and emergent reasoning capabilities to counter human-written and LLM-generated disinformation. First, we leverage GPT-3.5-turbo to synthesize authentic and deceptive LLM-generated content through paraphrase-based and perturbation-based prefix-style prompts, respectively. Second, we apply zero-shot in-context semantic reasoning techniques with cloze-style prompts to discern genuine from deceptive posts and news articles. In our extensive experiments, we observe GPT-3.5-turbo's zero-shot superiority for both in-distribution and out-of-distribution datasets, where GPT-3.5-turbo consistently achieved accuracy at 68-72%, unlike the decline observed in previous customize",
    "link": "http://arxiv.org/abs/2310.15515",
    "context": "Title: Fighting Fire with Fire: The Dual Role of LLMs in Crafting and Detecting Elusive Disinformation. (arXiv:2310.15515v1 [cs.CL])\nAbstract: Recent ubiquity and disruptive impacts of large language models (LLMs) have raised concerns about their potential to be misused (.i.e, generating large-scale harmful and misleading content). To combat this emerging risk of LLMs, we propose a novel \"Fighting Fire with Fire\" (F3) strategy that harnesses modern LLMs' generative and emergent reasoning capabilities to counter human-written and LLM-generated disinformation. First, we leverage GPT-3.5-turbo to synthesize authentic and deceptive LLM-generated content through paraphrase-based and perturbation-based prefix-style prompts, respectively. Second, we apply zero-shot in-context semantic reasoning techniques with cloze-style prompts to discern genuine from deceptive posts and news articles. In our extensive experiments, we observe GPT-3.5-turbo's zero-shot superiority for both in-distribution and out-of-distribution datasets, where GPT-3.5-turbo consistently achieved accuracy at 68-72%, unlike the decline observed in previous customize",
    "path": "papers/23/10/2310.15515.json",
    "total_tokens": 987,
    "translated_title": "用火攻火：LLM在制作和检测隐蔽虚假信息中的双重角色",
    "translated_abstract": "近期大型语言模型（LLM）的普及和破坏性影响引发了人们对其潜在被滥用的担忧（即生成大规模有害和误导性内容）。为了应对LLM的这一新兴风险，我们提出了一种新颖的“以火攻火”（F3）策略，利用现代LLM的生成和逻辑推理能力来对抗人类撰写和LLM生成的虚假信息。首先，我们利用GPT-3.5-turbo通过基于释义和扰动的前缀式提示合成真实和欺骗性的LLM生成内容。其次，我们应用零-shot语境语义推理技术，通过填空式提示区分真实和虚假的帖子和新闻文章。在广泛的实验证明中，我们观察到GPT-3.5-turbo在分布和非分布数据集方面具有零-shot上的优势，其中GPT-3.5-turbo始终保持在68-72%的准确率，不像之前的个性化下降现象。",
    "tldr": "这项研究提出了一种新的策略，即利用现代语言模型的生成和推理能力来对抗虚假信息。通过合成真实和欺骗性的内容以及利用语境语义推理技术，该策略在检测和对抗虚假信息方面取得了良好的效果。"
}