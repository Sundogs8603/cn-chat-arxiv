{
    "title": "Do large language models solve verbal analogies like children do?. (arXiv:2310.20384v1 [cs.CL])",
    "abstract": "Analogy-making lies at the heart of human cognition. Adults solve analogies such as \\textit{Horse belongs to stable like chicken belongs to ...?} by mapping relations (\\textit{kept in}) and answering \\textit{chicken coop}. In contrast, children often use association, e.g., answering \\textit{egg}. This paper investigates whether large language models (LLMs) solve verbal analogies in A:B::C:? form using associations, similar to what children do. We use verbal analogies extracted from an online adaptive learning environment, where 14,002 7-12 year-olds from the Netherlands solved 622 analogies in Dutch. The six tested Dutch monolingual and multilingual LLMs performed around the same level as children, with MGPT performing worst, around the 7-year-old level, and XLM-V and GPT-3 the best, slightly above the 11-year-old level. However, when we control for associative processes this picture changes and each model's performance level drops 1-2 years. Further experiments demonstrate that associ",
    "link": "http://arxiv.org/abs/2310.20384",
    "context": "Title: Do large language models solve verbal analogies like children do?. (arXiv:2310.20384v1 [cs.CL])\nAbstract: Analogy-making lies at the heart of human cognition. Adults solve analogies such as \\textit{Horse belongs to stable like chicken belongs to ...?} by mapping relations (\\textit{kept in}) and answering \\textit{chicken coop}. In contrast, children often use association, e.g., answering \\textit{egg}. This paper investigates whether large language models (LLMs) solve verbal analogies in A:B::C:? form using associations, similar to what children do. We use verbal analogies extracted from an online adaptive learning environment, where 14,002 7-12 year-olds from the Netherlands solved 622 analogies in Dutch. The six tested Dutch monolingual and multilingual LLMs performed around the same level as children, with MGPT performing worst, around the 7-year-old level, and XLM-V and GPT-3 the best, slightly above the 11-year-old level. However, when we control for associative processes this picture changes and each model's performance level drops 1-2 years. Further experiments demonstrate that associ",
    "path": "papers/23/10/2310.20384.json",
    "total_tokens": 991,
    "translated_title": "大型语言模型是否像孩子一样解决语言类比问题？",
    "translated_abstract": "类比思维是人类认知的核心。成年人通过映射关系并回答问题，如“马属于马厩，鸡属于...？”而解决语言类比问题。相反，孩子们经常使用联想作答，例如回答“蛋”。本文研究了大型语言模型（LLMs）是否像孩子一样通过联想来解决A:B::C:?形式的语言类比问题。我们使用从在线自适应学习环境中提取的语言类比问题，其中来自荷兰的14,002名7-12岁儿童解决了622个荷兰语的语言类比问题。六个测试的荷兰语母语和多语言LLMs的表现与儿童大致相当，MGPT表现最差，接近7岁水平，XLM-V和GPT-3表现最佳，略高于11岁水平。然而，当我们控制联想过程时，情况发生变化，每个模型的表现水平下降1-2年。进一步实验表明，联想过程的控制对模型的性能有显著影响。",
    "tldr": "本文研究了大型语言模型是否像孩子一样通过联想来解决语言类比问题，实验证明荷兰语母语和多语言LLMs的表现与儿童相当，但当控制联想过程时，模型的性能下降1-2年。"
}