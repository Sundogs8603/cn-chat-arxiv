{
    "title": "InfoEntropy Loss to Mitigate Bias of Learning Difficulties for Generative Language Models. (arXiv:2310.19531v2 [cs.CL] UPDATED)",
    "abstract": "Generative language models are usually pretrained on large text corpus via predicting the next token (i.e., sub-word/word/phrase) given the previous ones. Recent works have demonstrated the impressive performance of large generative language models on downstream tasks. However, existing generative language models generally neglect an inherent challenge in text corpus during training, i.e., the imbalance between frequent tokens and infrequent ones. It can lead a language model to be dominated by common and easy-to-learn tokens, thereby overlooking the infrequent and difficult-to-learn ones. To alleviate that, we propose an Information Entropy Loss (InfoEntropy Loss) function. During training, it can dynamically assess the learning difficulty of a to-be-learned token, according to the information entropy of the corresponding predicted probability distribution over the vocabulary. Then it scales the training loss adaptively, trying to lead the model to focus more on the difficult-to-learn",
    "link": "http://arxiv.org/abs/2310.19531",
    "context": "Title: InfoEntropy Loss to Mitigate Bias of Learning Difficulties for Generative Language Models. (arXiv:2310.19531v2 [cs.CL] UPDATED)\nAbstract: Generative language models are usually pretrained on large text corpus via predicting the next token (i.e., sub-word/word/phrase) given the previous ones. Recent works have demonstrated the impressive performance of large generative language models on downstream tasks. However, existing generative language models generally neglect an inherent challenge in text corpus during training, i.e., the imbalance between frequent tokens and infrequent ones. It can lead a language model to be dominated by common and easy-to-learn tokens, thereby overlooking the infrequent and difficult-to-learn ones. To alleviate that, we propose an Information Entropy Loss (InfoEntropy Loss) function. During training, it can dynamically assess the learning difficulty of a to-be-learned token, according to the information entropy of the corresponding predicted probability distribution over the vocabulary. Then it scales the training loss adaptively, trying to lead the model to focus more on the difficult-to-learn",
    "path": "papers/23/10/2310.19531.json",
    "total_tokens": 869,
    "translated_title": "减少生成式语言模型学习困难的信息熵损失",
    "translated_abstract": "生成式语言模型通常通过预测上一个标记（子词/词/短语）给出的下一个标记来进行预训练。最近的研究展示了大规模生成式语言模型在下游任务上的出色性能。然而，现有的生成式语言模型在训练过程中通常忽视文本语料库中的固有挑战，即频繁标记和不经常出现的标记之间的不平衡。这可能导致语言模型被常见且易学的标记所主导，从而忽视不经常出现且难以学习的标记。为了缓解这个问题，我们提出了一种信息熵损失（InfoEntropy Loss）函数。在训练过程中，它可以根据相应的预测概率分布的信息熵动态评估待学习标记的学习难度。然后，它适应地调整训练损失，试图使模型更加关注难以学习的标记。",
    "tldr": "提出了一种信息熵损失函数，用于减少生成式语言模型对常见和易学标记的偏好，使其更关注不常见和难学的标记。",
    "en_tdlr": "Proposed an InfoEntropy Loss function to mitigate the bias of generative language models towards frequent and easy-to-learn tokens, enabling them to focus more on infrequent and difficult-to-learn ones."
}