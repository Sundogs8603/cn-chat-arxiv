{
    "title": "PrIeD-KIE: Towards Privacy Preserved Document Key Information Extraction. (arXiv:2310.03777v1 [cs.CL])",
    "abstract": "In this paper, we introduce strategies for developing private Key Information Extraction (KIE) systems by leveraging large pretrained document foundation models in conjunction with differential privacy (DP), federated learning (FL), and Differentially Private Federated Learning (DP-FL). Through extensive experimentation on six benchmark datasets (FUNSD, CORD, SROIE, WildReceipts, XFUND, and DOCILE), we demonstrate that large document foundation models can be effectively fine-tuned for the KIE task under private settings to achieve adequate performance while maintaining strong privacy guarantees. Moreover, by thoroughly analyzing the impact of various training and model parameters on model performance, we propose simple yet effective guidelines for achieving an optimal privacy-utility trade-off for the KIE task under global DP. Finally, we introduce FeAm-DP, a novel DP-FL algorithm that enables efficiently upscaling global DP from a standalone context to a multi-client federated environ",
    "link": "http://arxiv.org/abs/2310.03777",
    "context": "Title: PrIeD-KIE: Towards Privacy Preserved Document Key Information Extraction. (arXiv:2310.03777v1 [cs.CL])\nAbstract: In this paper, we introduce strategies for developing private Key Information Extraction (KIE) systems by leveraging large pretrained document foundation models in conjunction with differential privacy (DP), federated learning (FL), and Differentially Private Federated Learning (DP-FL). Through extensive experimentation on six benchmark datasets (FUNSD, CORD, SROIE, WildReceipts, XFUND, and DOCILE), we demonstrate that large document foundation models can be effectively fine-tuned for the KIE task under private settings to achieve adequate performance while maintaining strong privacy guarantees. Moreover, by thoroughly analyzing the impact of various training and model parameters on model performance, we propose simple yet effective guidelines for achieving an optimal privacy-utility trade-off for the KIE task under global DP. Finally, we introduce FeAm-DP, a novel DP-FL algorithm that enables efficiently upscaling global DP from a standalone context to a multi-client federated environ",
    "path": "papers/23/10/2310.03777.json",
    "total_tokens": 1056,
    "translated_title": "PrIeD-KIE: 实现隐私保护的文档关键信息提取",
    "translated_abstract": "本文介绍了通过利用大型预训练文档基础模型与差分隐私（DP）、联邦学习（FL）和差分隐私联邦学习（DP-FL）相结合的策略，开发隐私保护的关键信息提取（KIE）系统的方法。通过在六个基准数据集（FUNSD、CORD、SROIE、WildReceipts、XFUND和DOCILE）上进行广泛实验证明，在私密环境下，可以有效地微调大型文档基础模型以实现足够的性能并保持强大的隐私保证。此外，通过深入分析各种训练和模型参数对模型性能的影响，我们提出了实现KIE任务在全局DP下最佳隐私-效用权衡的简单而有效的准则。最后，我们引入了FeAm-DP，一种新颖的DP-FL算法，可以将全局DP从独立环境有效地扩展到多客户联合环境。",
    "tldr": "本文提出了一种通过使用差分隐私、联邦学习和差分隐私联邦学习的策略，开发隐私保护的关键信息提取系统的方法。实验证明，在私密环境下，可以通过微调大型文档基础模型来获得足够的性能和强大的隐私保证。通过分析各种训练和模型参数的影响，提出了实现最佳隐私-效用权衡的准则。引入了一种新颖的DP-FL算法，可以将全局差分隐私从独立环境扩展到多客户联合环境。",
    "en_tdlr": "This paper proposes a method for developing privacy-preserving document key information extraction systems using strategies such as differential privacy, federated learning, and differentially private federated learning. The experiments demonstrate that fine-tuning large document foundation models in private settings can achieve adequate performance while maintaining strong privacy guarantees. The paper also provides guidelines for achieving an optimal privacy-utility trade-off and introduces a novel DP-FL algorithm for scaling global differential privacy in a multi-client federated environment."
}