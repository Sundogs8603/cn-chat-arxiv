{
    "title": "Predictor-Rejector Multi-Class Abstention: Theoretical Analysis and Algorithms. (arXiv:2310.14772v1 [cs.LG])",
    "abstract": "We study the key framework of learning with abstention in the multi-class classification setting. In this setting, the learner can choose to abstain from making a prediction with some pre-defined cost. We present a series of new theoretical and algorithmic results for this learning problem in the predictor-rejector framework. We introduce several new families of surrogate losses for which we prove strong non-asymptotic and hypothesis set-specific consistency guarantees, thereby resolving positively two existing open questions. These guarantees provide upper bounds on the estimation error of the abstention loss function in terms of that of the surrogate loss. We analyze both a single-stage setting where the predictor and rejector are learned simultaneously and a two-stage setting crucial in applications, where the predictor is learned in a first stage using a standard surrogate loss such as cross-entropy. These guarantees suggest new multi-class abstention algorithms based on minimizing",
    "link": "http://arxiv.org/abs/2310.14772",
    "context": "Title: Predictor-Rejector Multi-Class Abstention: Theoretical Analysis and Algorithms. (arXiv:2310.14772v1 [cs.LG])\nAbstract: We study the key framework of learning with abstention in the multi-class classification setting. In this setting, the learner can choose to abstain from making a prediction with some pre-defined cost. We present a series of new theoretical and algorithmic results for this learning problem in the predictor-rejector framework. We introduce several new families of surrogate losses for which we prove strong non-asymptotic and hypothesis set-specific consistency guarantees, thereby resolving positively two existing open questions. These guarantees provide upper bounds on the estimation error of the abstention loss function in terms of that of the surrogate loss. We analyze both a single-stage setting where the predictor and rejector are learned simultaneously and a two-stage setting crucial in applications, where the predictor is learned in a first stage using a standard surrogate loss such as cross-entropy. These guarantees suggest new multi-class abstention algorithms based on minimizing",
    "path": "papers/23/10/2310.14772.json",
    "total_tokens": 905,
    "translated_title": "预测-拒绝多类放弃：理论分析和算法",
    "translated_abstract": "我们研究了多类别分类设置中的学习与放弃框架。在这种设置中，学习者可以选择以一定的预定义成本放弃进行预测。我们提出了一系列新的理论和算法结果，解决了预测-拒绝框架下的学习问题。我们引入了几个新的替代损失函数家族，证明了强非渐进和假设集特定的一致性保证，从而积极地解决了两个现存的开放问题。这些保证提供了放弃损失函数的估计误差的上界，与替代损失的误差相关。我们分析了同时学习预测器和拒绝器的单阶段设置，以及在应用中至关重要的两阶段设置，在第一阶段使用标准替代损失函数如交叉熵来学习预测器。这些保证为基于最小化放弃损失的新的多类别放弃算法提供了启示。",
    "tldr": "我们研究了多类别分类设置中的学习与放弃框架，并提出了一系列新的理论和算法结果，解决了两个现存的开放问题。这些保证为基于最小化放弃损失的新的多类别放弃算法提供了启示。"
}