{
    "title": "Mean Estimation Under Heterogeneous Privacy Demands. (arXiv:2310.13137v1 [cs.CR])",
    "abstract": "Differential Privacy (DP) is a well-established framework to quantify privacy loss incurred by any algorithm. Traditional formulations impose a uniform privacy requirement for all users, which is often inconsistent with real-world scenarios in which users dictate their privacy preferences individually. This work considers the problem of mean estimation, where each user can impose their own distinct privacy level. The algorithm we propose is shown to be minimax optimal and has a near-linear run-time. Our results elicit an interesting saturation phenomenon that occurs. Namely, the privacy requirements of the most stringent users dictate the overall error rates. As a consequence, users with less but differing privacy requirements are all given more privacy than they require, in equal amounts. In other words, these privacy-indifferent users are given a nontrivial degree of privacy for free, without any sacrifice in the performance of the estimator.",
    "link": "http://arxiv.org/abs/2310.13137",
    "context": "Title: Mean Estimation Under Heterogeneous Privacy Demands. (arXiv:2310.13137v1 [cs.CR])\nAbstract: Differential Privacy (DP) is a well-established framework to quantify privacy loss incurred by any algorithm. Traditional formulations impose a uniform privacy requirement for all users, which is often inconsistent with real-world scenarios in which users dictate their privacy preferences individually. This work considers the problem of mean estimation, where each user can impose their own distinct privacy level. The algorithm we propose is shown to be minimax optimal and has a near-linear run-time. Our results elicit an interesting saturation phenomenon that occurs. Namely, the privacy requirements of the most stringent users dictate the overall error rates. As a consequence, users with less but differing privacy requirements are all given more privacy than they require, in equal amounts. In other words, these privacy-indifferent users are given a nontrivial degree of privacy for free, without any sacrifice in the performance of the estimator.",
    "path": "papers/23/10/2310.13137.json",
    "total_tokens": 925,
    "translated_title": "异构隐私需求下的均值估计",
    "translated_abstract": "差分隐私是一种量化算法造成的隐私损失的成熟框架。传统的方法对所有用户都施加统一的隐私要求，这与现实情景不一致，因为用户可以个别决定自己的隐私偏好。本文考虑了均值估计的问题，每个用户都可以施加自己不同的隐私水平。我们提出的算法被证明是极小化最优的，且具有接近线性的运行时间。我们的结果揭示了一种有趣的饱和现象。即最严格用户的隐私要求决定了整体的误差率。因此，拥有较少但不同隐私要求的用户都会获得超过自身需求的隐私保护，且保护程度相同。换句话说，这些对隐私不敏感的用户可以免费获得非平凡程度的隐私保护，而无需在估计器性能上做出任何牺牲。",
    "tldr": "本文研究了异构隐私需求下的均值估计问题，提出的算法在接近线性的时间复杂度下，能够满足每个用户的个别隐私要求，并且获得极小化最优结果。最严格的用户的隐私要求决定了整体的误差率，且拥有较少但不同隐私要求的用户都会获得超过自身需求的隐私保护，且保护程度相同。这意味着对隐私不敏感的用户可以免费获得非平凡程度的隐私保护。"
}