{
    "title": "Free-text Keystroke Authentication using Transformers: A Comparative Study of Architectures and Loss Functions. (arXiv:2310.11640v1 [cs.CR])",
    "abstract": "Keystroke biometrics is a promising approach for user identification and verification, leveraging the unique patterns in individuals' typing behavior. In this paper, we propose a Transformer-based network that employs self-attention to extract informative features from keystroke sequences, surpassing the performance of traditional Recurrent Neural Networks. We explore two distinct architectures, namely bi-encoder and cross-encoder, and compare their effectiveness in keystroke authentication. Furthermore, we investigate different loss functions, including triplet, batch-all triplet, and WDCL loss, along with various distance metrics such as Euclidean, Manhattan, and cosine distances. These experiments allow us to optimize the training process and enhance the performance of our model. To evaluate our proposed model, we employ the Aalto desktop keystroke dataset. The results demonstrate that the bi-encoder architecture with batch-all triplet loss and cosine distance achieves the best perf",
    "link": "http://arxiv.org/abs/2310.11640",
    "context": "Title: Free-text Keystroke Authentication using Transformers: A Comparative Study of Architectures and Loss Functions. (arXiv:2310.11640v1 [cs.CR])\nAbstract: Keystroke biometrics is a promising approach for user identification and verification, leveraging the unique patterns in individuals' typing behavior. In this paper, we propose a Transformer-based network that employs self-attention to extract informative features from keystroke sequences, surpassing the performance of traditional Recurrent Neural Networks. We explore two distinct architectures, namely bi-encoder and cross-encoder, and compare their effectiveness in keystroke authentication. Furthermore, we investigate different loss functions, including triplet, batch-all triplet, and WDCL loss, along with various distance metrics such as Euclidean, Manhattan, and cosine distances. These experiments allow us to optimize the training process and enhance the performance of our model. To evaluate our proposed model, we employ the Aalto desktop keystroke dataset. The results demonstrate that the bi-encoder architecture with batch-all triplet loss and cosine distance achieves the best perf",
    "path": "papers/23/10/2310.11640.json",
    "total_tokens": 967,
    "translated_title": "使用Transformer的自由文本按键身份验证：架构和损失函数的比较研究",
    "translated_abstract": "按键生物特征是一种有前景的用户识别和验证方法，利用个体的输入行为中的独特模式。在本文中，我们提出了一种基于Transformer的网络，利用自注意机制从按键序列中提取信息特征，超过传统的循环神经网络的性能。我们探索了两种不同的架构，即双重编码器和交叉编码器，并比较了它们在按键身份验证中的有效性。此外，我们还研究了不同的损失函数，包括三重，批量-全部三重和WDCL损失，以及不同的距离度量标准，如欧氏距离，曼哈顿距离和余弦距离。这些实验使我们能够优化训练过程并提高模型的性能。为了评估我们提出的模型，我们使用了Aalto桌面按键数据集。结果表明，使用批量-全部三重损失和余弦距离的双重编码器架构实现了最佳性能。",
    "tldr": "本研究提出了一种基于Transformer的网络，通过自注意机制从按键序列中提取信息特征，改进了传统的循环神经网络在按键身份验证中的性能。实验结果表明，在Aalto桌面按键数据集上，采用批量-全部三重损失和余弦距离的双重编码器架构达到了最佳性能。",
    "en_tdlr": "This study proposes a Transformer-based network that extracts informative features from keystroke sequences using self-attention, improving the performance of traditional Recurrent Neural Networks in keystroke authentication. The results show that the bi-encoder architecture with batch-all triplet loss and cosine distance achieves the best performance on the Aalto desktop keystroke dataset."
}