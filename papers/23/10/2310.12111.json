{
    "title": "DASA: Difficulty-Aware Semantic Augmentation for Speaker Verification. (arXiv:2310.12111v1 [eess.AS])",
    "abstract": "Data augmentation is vital to the generalization ability and robustness of deep neural networks (DNNs) models. Existing augmentation methods for speaker verification manipulate the raw signal, which are time-consuming and the augmented samples lack diversity. In this paper, we present a novel difficulty-aware semantic augmentation (DASA) approach for speaker verification, which can generate diversified training samples in speaker embedding space with negligible extra computing cost. Firstly, we augment training samples by perturbing speaker embeddings along semantic directions, which are obtained from speaker-wise covariance matrices. Secondly, accurate covariance matrices are estimated from robust speaker embeddings during training, so we introduce difficultyaware additive margin softmax (DAAM-Softmax) to obtain optimal speaker embeddings. Finally, we assume the number of augmented samples goes to infinity and derive a closed-form upper bound of the expected loss with DASA, which achi",
    "link": "http://arxiv.org/abs/2310.12111",
    "context": "Title: DASA: Difficulty-Aware Semantic Augmentation for Speaker Verification. (arXiv:2310.12111v1 [eess.AS])\nAbstract: Data augmentation is vital to the generalization ability and robustness of deep neural networks (DNNs) models. Existing augmentation methods for speaker verification manipulate the raw signal, which are time-consuming and the augmented samples lack diversity. In this paper, we present a novel difficulty-aware semantic augmentation (DASA) approach for speaker verification, which can generate diversified training samples in speaker embedding space with negligible extra computing cost. Firstly, we augment training samples by perturbing speaker embeddings along semantic directions, which are obtained from speaker-wise covariance matrices. Secondly, accurate covariance matrices are estimated from robust speaker embeddings during training, so we introduce difficultyaware additive margin softmax (DAAM-Softmax) to obtain optimal speaker embeddings. Finally, we assume the number of augmented samples goes to infinity and derive a closed-form upper bound of the expected loss with DASA, which achi",
    "path": "papers/23/10/2310.12111.json",
    "total_tokens": 962,
    "translated_title": "DASA: Difficulty-Aware Semantic Augmentation for Speaker Verification. (arXiv:2310.12111v1 [eess.AS])",
    "translated_abstract": "数据增强对于深度神经网络(DNN)模型的泛化能力和鲁棒性至关重要。现有的说话人验证增强方法操纵原始信号，这些方法耗时且增强样本缺乏多样性。本文提出了一种新的面向说话人验证的难度感知语义增强(DASA)方法，可以在说话人嵌入空间中生成多样化的训练样本，成本几乎可以忽略。首先，我们通过扰动来自说话人矩阵的语义方向来增强训练样本。其次，在训练过程中，我们从鲁棒的说话人嵌入中估计准确的协方差矩阵，所以我们引入了难度感知的加性边界软最大值(DAAM-Softmax)来获得最优的说话人嵌入。最后，我们假设增强样本数量趋近无穷大，并推导出带有DASA的期望损失的闭式上界，该方法实现了最优的性能提升。",
    "tldr": "本文提出了一种面向说话人验证的难度感知语义增强(DASA)方法，通过扰动语义方向来增强训练样本，并引入了难度感知的加性边界软最大值(DAAM-Softmax)来实现最优的说话人嵌入，从而改善模型的泛化能力和鲁棒性。",
    "en_tdlr": "This paper proposes a Difficulty-Aware Semantic Augmentation (DASA) approach for speaker verification, augmenting training samples by perturbing semantic directions and employing a Difficulty-Aware Additive Margin Softmax (DAAM-Softmax) to achieve optimal speaker embeddings, ultimately improving the generalization ability and robustness of the model."
}