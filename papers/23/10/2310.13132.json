{
    "title": "Ask Me in English Instead: Cross-Lingual Evaluation of Large Language Models for Healthcare Queries. (arXiv:2310.13132v1 [cs.CL])",
    "abstract": "Large language models (LLMs) are transforming the ways the general public accesses and consumes information. Their influence is particularly pronounced in pivotal sectors like healthcare, where lay individuals are increasingly appropriating LLMs as conversational agents for everyday queries. While LLMs demonstrate impressive language understanding and generation proficiencies, concerns regarding their safety remain paramount in these high-stake domains. Moreover, the development of LLMs is disproportionately focused on English. It remains unclear how these LLMs perform in the context of non-English languages, a gap that is critical for ensuring equity in the real-world use of these systems.This paper provides a framework to investigate the effectiveness of LLMs as multi-lingual dialogue systems for healthcare queries. Our empirically-derived framework XlingEval focuses on three fundamental criteria for evaluating LLM responses to naturalistic human-authored health-related questions: co",
    "link": "http://arxiv.org/abs/2310.13132",
    "context": "Title: Ask Me in English Instead: Cross-Lingual Evaluation of Large Language Models for Healthcare Queries. (arXiv:2310.13132v1 [cs.CL])\nAbstract: Large language models (LLMs) are transforming the ways the general public accesses and consumes information. Their influence is particularly pronounced in pivotal sectors like healthcare, where lay individuals are increasingly appropriating LLMs as conversational agents for everyday queries. While LLMs demonstrate impressive language understanding and generation proficiencies, concerns regarding their safety remain paramount in these high-stake domains. Moreover, the development of LLMs is disproportionately focused on English. It remains unclear how these LLMs perform in the context of non-English languages, a gap that is critical for ensuring equity in the real-world use of these systems.This paper provides a framework to investigate the effectiveness of LLMs as multi-lingual dialogue systems for healthcare queries. Our empirically-derived framework XlingEval focuses on three fundamental criteria for evaluating LLM responses to naturalistic human-authored health-related questions: co",
    "path": "papers/23/10/2310.13132.json",
    "total_tokens": 804,
    "translated_title": "不妨用英文问我：基于大语言模型的医疗问题跨语言评估",
    "translated_abstract": "大语言模型（LLMs）正在改变一般公众获取和消费信息的方式。它们在关键领域如医疗保健中的影响尤为显著，普通人日常查询越来越多地使用LLMs作为对话代理。虽然LLMs展示出令人印象深刻的语言理解和生成能力，但对其安全性的关注在这些高风险领域仍然很重要。此外，LLMs的开发过于集中在英文上。这些LLMs在非英文语言环境中的表现如何仍不明确，这是确保这些系统在真实环境中使用公平性的关键。本文提供了一个框架，研究LLMs作为多语言对话系统在医疗问题中的效果。我们通过实证得出的框架XlingEval，重点关注对LLMs回答自然人撰写的与健康相关问题的评估的三个基本标准：协议",
    "tldr": "本文提供了一个框架，研究LLMs作为医疗问题的多语言对话系统的有效性。"
}