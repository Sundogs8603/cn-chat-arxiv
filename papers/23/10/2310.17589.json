{
    "title": "An Open Source Data Contamination Report for Large Language Models. (arXiv:2310.17589v3 [cs.CL] UPDATED)",
    "abstract": "Data contamination in model evaluation has become increasingly prevalent with the growing popularity of large language models. It allows models to \"cheat\" via memorisation instead of displaying true capabilities. Therefore, contamination analysis has become an crucial part of reliable model evaluation to validate results. However, existing contamination analysis is usually conducted internally by large language model developers and often lacks transparency and completeness. This paper presents an extensive data contamination report for over 15 popular large language models across six popular multiple-choice QA benchmarks. We also introduce an open-source pipeline that enables the community to perform contamination analysis on customised data and models. Our experiments reveal varying contamination levels ranging from 1\\% to 45\\% across benchmarks, with the contamination degree increasing rapidly over time. Performance analysis of large language models indicates that data contamination ",
    "link": "http://arxiv.org/abs/2310.17589",
    "context": "Title: An Open Source Data Contamination Report for Large Language Models. (arXiv:2310.17589v3 [cs.CL] UPDATED)\nAbstract: Data contamination in model evaluation has become increasingly prevalent with the growing popularity of large language models. It allows models to \"cheat\" via memorisation instead of displaying true capabilities. Therefore, contamination analysis has become an crucial part of reliable model evaluation to validate results. However, existing contamination analysis is usually conducted internally by large language model developers and often lacks transparency and completeness. This paper presents an extensive data contamination report for over 15 popular large language models across six popular multiple-choice QA benchmarks. We also introduce an open-source pipeline that enables the community to perform contamination analysis on customised data and models. Our experiments reveal varying contamination levels ranging from 1\\% to 45\\% across benchmarks, with the contamination degree increasing rapidly over time. Performance analysis of large language models indicates that data contamination ",
    "path": "papers/23/10/2310.17589.json",
    "total_tokens": 916,
    "translated_title": "一份针对大型语言模型的开源数据污染报告",
    "translated_abstract": "随着大型语言模型的日益普及，模型评估中的数据污染问题越来越普遍。它允许模型通过记忆而不是展示真正的能力来\"作弊\"。因此，污染分析已成为可靠的模型评估的重要部分，用于验证结果。然而，现有的污染分析通常由大型语言模型开发者内部进行，往往缺乏透明度和完整性。本文为六个常见的多项选择问答基准测试提供了超过15个热门大型语言模型的详细数据污染报告。我们还介绍了一个开源的流程，使社区能够对自定义数据和模型进行污染分析。我们的实验揭示了基准测试中不同的污染水平，范围从1%到45%，污染程度随时间迅速增加。大型语言模型的性能分析表明，数据污染会显著降低模型的性能。",
    "tldr": "本文介绍了一个针对大型语言模型的开源数据污染报告，其中包括超过15个热门模型对六个常见多项选择问答基准测试的污染分析。实验证明，数据污染会显著降低模型性能，并且随着时间的推移污染程度不断增加。"
}