{
    "title": "Data-Free Distillation Improves Efficiency and Privacy in Federated Thorax Disease Analysis. (arXiv:2310.18346v2 [eess.IV] UPDATED)",
    "abstract": "Thorax disease analysis in large-scale, multi-centre, and multi-scanner settings is often limited by strict privacy policies. Federated learning (FL) offers a potential solution, while traditional parameter-based FL can be limited by issues such as high communication costs, data leakage, and heterogeneity. Distillation-based FL can improve efficiency, but it relies on a proxy dataset, which is often impractical in clinical practice. To address these challenges, we introduce a data-free distillation-based FL approach FedKDF. In FedKDF, the server employs a lightweight generator to aggregate knowledge from different clients without requiring access to their private data or a proxy dataset. FedKDF combines the predictors from clients into a single, unified predictor, which is further optimized using the learned knowledge in the lightweight generator. Our empirical experiments demonstrate that FedKDF offers a robust solution for efficient, privacy-preserving federated thorax disease analys",
    "link": "http://arxiv.org/abs/2310.18346",
    "context": "Title: Data-Free Distillation Improves Efficiency and Privacy in Federated Thorax Disease Analysis. (arXiv:2310.18346v2 [eess.IV] UPDATED)\nAbstract: Thorax disease analysis in large-scale, multi-centre, and multi-scanner settings is often limited by strict privacy policies. Federated learning (FL) offers a potential solution, while traditional parameter-based FL can be limited by issues such as high communication costs, data leakage, and heterogeneity. Distillation-based FL can improve efficiency, but it relies on a proxy dataset, which is often impractical in clinical practice. To address these challenges, we introduce a data-free distillation-based FL approach FedKDF. In FedKDF, the server employs a lightweight generator to aggregate knowledge from different clients without requiring access to their private data or a proxy dataset. FedKDF combines the predictors from clients into a single, unified predictor, which is further optimized using the learned knowledge in the lightweight generator. Our empirical experiments demonstrate that FedKDF offers a robust solution for efficient, privacy-preserving federated thorax disease analys",
    "path": "papers/23/10/2310.18346.json",
    "total_tokens": 980,
    "translated_title": "无数据蒸馏提高了联邦胸部疾病分析的效率和隐私",
    "translated_abstract": "在大规模、多中心和多扫描仪环境中，胸部疾病分析受到严格的隐私政策的限制。联邦学习（FL）提供了一种潜在的解决方案，而传统的基于参数的FL可能受到高通信成本、数据泄漏和异质性等问题的限制。基于蒸馏的FL可以提高效率，但依赖于一个代理数据集，在临床实践中通常不实用。为了解决这些挑战，我们引入了一种无数据蒸馏的FL方法FedKDF。在FedKDF中，服务器使用轻量级生成器从不同客户端聚合知识，而无需访问其私有数据或代理数据集。FedKDF将客户端的预测器组合成一个统一的预测器，并使用轻量级生成器中学到的知识进行进一步优化。我们的实证实验表明，FedKDF提供了一个稳健的解决方案，用于高效、隐私保护的联邦胸部疾病分析。",
    "tldr": "我们提出了一种名为FedKDF的无数据蒸馏联邦学习方法，可以在保护隐私的前提下提高胸部疾病分析的效率和准确性。通过使用轻量级生成器聚合来自不同客户端的知识，FedKDF能够生成一个统一的预测器，并在其基础上进行进一步优化。"
}