{
    "title": "Beyond Random Noise: Insights on Anonymization Strategies from a Latent Bandit Study. (arXiv:2310.00221v1 [cs.LG])",
    "abstract": "This paper investigates the issue of privacy in a learning scenario where users share knowledge for a recommendation task. Our study contributes to the growing body of research on privacy-preserving machine learning and underscores the need for tailored privacy techniques that address specific attack patterns rather than relying on one-size-fits-all solutions. We use the latent bandit setting to evaluate the trade-off between privacy and recommender performance by employing various aggregation strategies, such as averaging, nearest neighbor, and clustering combined with noise injection. More specifically, we simulate a linkage attack scenario leveraging publicly available auxiliary information acquired by the adversary. Our results on three open real-world datasets reveal that adding noise using the Laplace mechanism to an individual user's data record is a poor choice. It provides the highest regret for any noise level, relative to de-anonymization probability and the ADS metric. Inst",
    "link": "http://arxiv.org/abs/2310.00221",
    "context": "Title: Beyond Random Noise: Insights on Anonymization Strategies from a Latent Bandit Study. (arXiv:2310.00221v1 [cs.LG])\nAbstract: This paper investigates the issue of privacy in a learning scenario where users share knowledge for a recommendation task. Our study contributes to the growing body of research on privacy-preserving machine learning and underscores the need for tailored privacy techniques that address specific attack patterns rather than relying on one-size-fits-all solutions. We use the latent bandit setting to evaluate the trade-off between privacy and recommender performance by employing various aggregation strategies, such as averaging, nearest neighbor, and clustering combined with noise injection. More specifically, we simulate a linkage attack scenario leveraging publicly available auxiliary information acquired by the adversary. Our results on three open real-world datasets reveal that adding noise using the Laplace mechanism to an individual user's data record is a poor choice. It provides the highest regret for any noise level, relative to de-anonymization probability and the ADS metric. Inst",
    "path": "papers/23/10/2310.00221.json",
    "total_tokens": 984,
    "translated_title": "超越随机噪声：通过隐性强盗研究洞察匿名化策略",
    "translated_abstract": "本文研究了在用户共享知识进行推荐任务的学习场景中，隐私问题。我们的研究为隐私保护机器学习领域的研究增加了贡献，并强调了需要针对特定攻击模式而非依赖一刀切解决方案的定制隐私技术。我们使用了隐性强盗设置来评估隐私和推荐器性能之间的权衡，通过采用各种聚合策略，如平均、最近邻和聚类结合噪声注入。更具体地说，我们模拟了一个利用对手收集的公开可获得的辅助信息进行链接攻击的情景。我们在三个开放的真实数据集上的结果表明，对个体用户的数据记录添加拉普拉斯机制的噪声是一个糟糕的选择。它相对于去匿名化概率和ADS度量来说，在任何噪声水平下都提供了最大的遗憾。",
    "tldr": "本文通过使用隐性强盗设置和不同的聚合策略，评估了隐私和推荐器性能之间的权衡，为定制隐私技术的需求提供了洞察。研究结果表明，对个体用户的数据记录添加拉普拉斯机制的噪声是不合适的选择，它在任何噪声水平下都会产生最大的遗憾。",
    "en_tdlr": "This paper provides insights into the trade-off between privacy and recommender performance by using the latent bandit setting and different aggregation strategies, highlighting the need for tailored privacy techniques. The results show that adding noise using the Laplace mechanism to individual user's data record is not a suitable choice, as it leads to the highest regret across all noise levels."
}