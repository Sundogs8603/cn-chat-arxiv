{
    "title": "An International Consortium for Evaluations of Societal-Scale Risks from Advanced AI. (arXiv:2310.14455v2 [cs.CY] UPDATED)",
    "abstract": "Given rapid progress toward advanced AI and risks from frontier AI systems (advanced AI systems pushing the boundaries of the AI capabilities frontier), the creation and implementation of AI governance and regulatory schemes deserves prioritization and substantial investment. However, the status quo is untenable and, frankly, dangerous. A regulatory gap has permitted AI labs to conduct research, development, and deployment activities with minimal oversight. In response, frontier AI system evaluations have been proposed as a way of assessing risks from the development and deployment of frontier AI systems. Yet, the budding AI risk evaluation ecosystem faces significant coordination challenges, such as a limited diversity of evaluators, suboptimal allocation of effort, and perverse incentives. This paper proposes a solution in the form of an international consortium for AI risk evaluations, comprising both AI developers and third-party AI risk evaluators. Such a consortium could play a c",
    "link": "http://arxiv.org/abs/2310.14455",
    "context": "Title: An International Consortium for Evaluations of Societal-Scale Risks from Advanced AI. (arXiv:2310.14455v2 [cs.CY] UPDATED)\nAbstract: Given rapid progress toward advanced AI and risks from frontier AI systems (advanced AI systems pushing the boundaries of the AI capabilities frontier), the creation and implementation of AI governance and regulatory schemes deserves prioritization and substantial investment. However, the status quo is untenable and, frankly, dangerous. A regulatory gap has permitted AI labs to conduct research, development, and deployment activities with minimal oversight. In response, frontier AI system evaluations have been proposed as a way of assessing risks from the development and deployment of frontier AI systems. Yet, the budding AI risk evaluation ecosystem faces significant coordination challenges, such as a limited diversity of evaluators, suboptimal allocation of effort, and perverse incentives. This paper proposes a solution in the form of an international consortium for AI risk evaluations, comprising both AI developers and third-party AI risk evaluators. Such a consortium could play a c",
    "path": "papers/23/10/2310.14455.json",
    "total_tokens": 958,
    "translated_title": "一个国际合作机构评估面向先进人工智能的社会规模风险。",
    "translated_abstract": "鉴于先进人工智能的快速发展和前沿人工智能系统的风险，人工智能治理和监管方案的创建和实施应该优先考虑并进行大量投资。然而，现状是难以维持的，而且危险。监管缺口使得人工智能实验室可以在很少监督下进行研究、开发和部署活动。作为回应，提出了前沿人工智能系统评估作为评估前沿人工智能系统的风险的方法。然而，新兴的人工智能风险评估生态系统面临着重大的协调挑战，例如评估人员的多样性有限、努力分配不理想和激励机制颠倒。本文提出了一种解决方案，即通过一个由人工智能开发者和第三方风险评估人员组成的国际联合体来进行人工智能风险评估。这样的联合体可以发挥决定性作用。",
    "tldr": "本文提出了面向先进人工智能的社会规模风险评估的国际合作机构解决方案，提议在人工智能开发者和第三方评估人员之间建立联合体，以解决评估人员多样性有限、努力分配不理想和激励机制颠倒等协调挑战。",
    "en_tdlr": "This paper proposes an international consortium for evaluating societal-scale risks from advanced AI, suggesting the establishment of a collaboration between AI developers and third-party evaluators to address coordination challenges such as limited diversity of evaluators, suboptimal allocation of effort, and perverse incentives."
}