{
    "title": "Memory-Consistent Neural Networks for Imitation Learning. (arXiv:2310.06171v1 [cs.LG])",
    "abstract": "Imitation learning considerably simplifies policy synthesis compared to alternative approaches by exploiting access to expert demonstrations. For such imitation policies, errors away from the training samples are particularly critical. Even rare slip-ups in the policy action outputs can compound quickly over time, since they lead to unfamiliar future states where the policy is still more likely to err, eventually causing task failures. We revisit simple supervised ``behavior cloning'' for conveniently training the policy from nothing more than pre-recorded demonstrations, but carefully design the model class to counter the compounding error phenomenon. Our ``memory-consistent neural network'' (MCNN) outputs are hard-constrained to stay within clearly specified permissible regions anchored to prototypical ``memory'' training samples. We provide a guaranteed upper bound for the sub-optimality gap induced by MCNN policies. Using MCNNs on 9 imitation learning tasks, with MLP, Transformer, ",
    "link": "http://arxiv.org/abs/2310.06171",
    "context": "Title: Memory-Consistent Neural Networks for Imitation Learning. (arXiv:2310.06171v1 [cs.LG])\nAbstract: Imitation learning considerably simplifies policy synthesis compared to alternative approaches by exploiting access to expert demonstrations. For such imitation policies, errors away from the training samples are particularly critical. Even rare slip-ups in the policy action outputs can compound quickly over time, since they lead to unfamiliar future states where the policy is still more likely to err, eventually causing task failures. We revisit simple supervised ``behavior cloning'' for conveniently training the policy from nothing more than pre-recorded demonstrations, but carefully design the model class to counter the compounding error phenomenon. Our ``memory-consistent neural network'' (MCNN) outputs are hard-constrained to stay within clearly specified permissible regions anchored to prototypical ``memory'' training samples. We provide a guaranteed upper bound for the sub-optimality gap induced by MCNN policies. Using MCNNs on 9 imitation learning tasks, with MLP, Transformer, ",
    "path": "papers/23/10/2310.06171.json",
    "total_tokens": 895,
    "translated_title": "内存一致的神经网络在模仿学习中的应用",
    "translated_abstract": "模仿学习利用专家演示大大简化了策略合成的过程。然而，对于这种模仿策略来说，远离训练样本的错误尤为关键。即使在策略的行动输出中出现罕见的错误，由于这些错误会导致不熟悉的未来状态，策略在这些状态下仍更容易出错，最终导致任务失败。本文重新审视了简单的监督式“行为克隆”方法，能够方便地仅通过预先记录的演示来训练策略，并设计了一种能够抵消错误累积现象的模型类。我们的“内存一致神经网络”(MCNN)输出被强制约束在与典型的“内存”训练样本相关的明确指定的允许区域内。我们提供了MCNN策略导致的次优性差距的保证上界。通过在9个模仿学习任务上使用MCNNs，采用MLP、Transformer等方法。",
    "tldr": "本文介绍了一种内存一致的神经网络模型，在模仿学习中使用专家演示训练策略。该模型通过对输出结果进行硬约束，避免了错误的累积现象，保证了策略效果的上界。",
    "en_tdlr": "This paper presents a memory-consistent neural network model for training imitation learning policies with expert demonstrations, which avoids the compounding error phenomenon by constraining the output within specified permissible regions."
}