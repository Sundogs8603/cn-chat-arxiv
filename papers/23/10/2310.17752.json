{
    "title": "PockEngine: Sparse and Efficient Fine-tuning in a Pocket. (arXiv:2310.17752v1 [cs.LG])",
    "abstract": "On-device learning and efficient fine-tuning enable continuous and privacy-preserving customization (e.g., locally fine-tuning large language models on personalized data). However, existing training frameworks are designed for cloud servers with powerful accelerators (e.g., GPUs, TPUs) and lack the optimizations for learning on the edge, which faces challenges of resource limitations and edge hardware diversity. We introduce PockEngine: a tiny, sparse and efficient engine to enable fine-tuning on various edge devices. PockEngine supports sparse backpropagation: it prunes the backward graph and sparsely updates the model with measured memory saving and latency reduction while maintaining the model quality. Secondly, PockEngine is compilation first: the entire training graph (including forward, backward and optimization steps) is derived at compile-time, which reduces the runtime overhead and brings opportunities for graph transformations. PockEngine also integrates a rich set of trainin",
    "link": "http://arxiv.org/abs/2310.17752",
    "context": "Title: PockEngine: Sparse and Efficient Fine-tuning in a Pocket. (arXiv:2310.17752v1 [cs.LG])\nAbstract: On-device learning and efficient fine-tuning enable continuous and privacy-preserving customization (e.g., locally fine-tuning large language models on personalized data). However, existing training frameworks are designed for cloud servers with powerful accelerators (e.g., GPUs, TPUs) and lack the optimizations for learning on the edge, which faces challenges of resource limitations and edge hardware diversity. We introduce PockEngine: a tiny, sparse and efficient engine to enable fine-tuning on various edge devices. PockEngine supports sparse backpropagation: it prunes the backward graph and sparsely updates the model with measured memory saving and latency reduction while maintaining the model quality. Secondly, PockEngine is compilation first: the entire training graph (including forward, backward and optimization steps) is derived at compile-time, which reduces the runtime overhead and brings opportunities for graph transformations. PockEngine also integrates a rich set of trainin",
    "path": "papers/23/10/2310.17752.json",
    "total_tokens": 907,
    "translated_title": "PockEngine: 稀疏且高效的边缘微调引擎",
    "translated_abstract": "设备上的学习和高效微调能够实现持续且隐私保护的个性化定制（例如，在个性化数据上本地微调大型语言模型）。然而，现有的训练框架是为强大的云服务器设计的（例如，GPU、TPU等），缺乏针对边缘学习的优化，面临着资源有限和边缘硬件多样性的挑战。我们介绍了PockEngine：一种小型、稀疏且高效的引擎，可以在各种边缘设备上进行微调。PockEngine支持稀疏反向传播：它修剪反向图，并使用经过测量的内存节省和延迟降低来稀疏更新模型，同时保持模型质量。其次，PockEngine以编译为先：整个训练图（包括前向、反向和优化步骤）在编译时推导出来，从而降低了运行时开销，并带来了图变换的机会。PockEngine还整合了丰富的训练工具集。",
    "tldr": "PockEngine是一种稀疏且高效的边缘微调引擎，支持稀疏反向传播和编译为先策略，以应对边缘设备的资源限制和硬件多样性。",
    "en_tdlr": "PockEngine is a sparse and efficient fine-tuning engine for edge devices, supporting sparse backpropagation and a compilation-first strategy to address resource limitations and hardware diversity at the edge."
}