{
    "title": "On Context Utilization in Summarization with Large Language Models",
    "abstract": "arXiv:2310.10570v3 Announce Type: replace  Abstract: Large language models (LLMs) excel in abstractive summarization tasks, delivering fluent and pertinent summaries. Recent advancements have extended their capabilities to handle long-input contexts, exceeding 100k tokens. However, in question answering, language models exhibit uneven utilization of their input context. They tend to favor the initial and final segments, resulting in a U-shaped performance pattern concerning where the answer is located within the input. This bias raises concerns, particularly in summarization where crucial content may be dispersed throughout the source document(s). Besides, in summarization, mapping facts from the source to the summary is not trivial as salient content is usually re-phrased. In this paper, we conduct the first comprehensive study on context utilization and position bias in summarization. Our analysis encompasses 5 LLMs, 10 datasets, and 5 evaluation metrics. We introduce a new evaluatio",
    "link": "https://arxiv.org/abs/2310.10570",
    "context": "Title: On Context Utilization in Summarization with Large Language Models\nAbstract: arXiv:2310.10570v3 Announce Type: replace  Abstract: Large language models (LLMs) excel in abstractive summarization tasks, delivering fluent and pertinent summaries. Recent advancements have extended their capabilities to handle long-input contexts, exceeding 100k tokens. However, in question answering, language models exhibit uneven utilization of their input context. They tend to favor the initial and final segments, resulting in a U-shaped performance pattern concerning where the answer is located within the input. This bias raises concerns, particularly in summarization where crucial content may be dispersed throughout the source document(s). Besides, in summarization, mapping facts from the source to the summary is not trivial as salient content is usually re-phrased. In this paper, we conduct the first comprehensive study on context utilization and position bias in summarization. Our analysis encompasses 5 LLMs, 10 datasets, and 5 evaluation metrics. We introduce a new evaluatio",
    "path": "papers/23/10/2310.10570.json",
    "total_tokens": 853,
    "translated_title": "关于大型语言模型在摘要中上下文利用的研究",
    "translated_abstract": "大型语言模型（LLMs）在抽象摘要任务中表现出色，提供流畅且相关的摘要。最近的进展扩展了它们处理长输入上下文的能力，超过了100k个标记。然而，在问答中，语言模型对其输入上下文的利用不均匀。它们倾向于偏爱初始和最终段落，导致了关于答案在输入中位置的U形性能模式。这种偏见引发了担忧，特别是在摘要中，关键内容可能分散在源文件中。此外，在摘要中，从源文件到摘要的事实映射并不是微不足道的，因为显著内容通常会被重新表述。在本文中，我们对摘要中上下文利用和位置偏见进行了第一次全面研究。我们的分析涵盖了5个LLMs，10个数据集和5个评估指标。我们引入了一个新的评估",
    "tldr": "本文研究了大型语言模型在摘要中上下文利用的问题，发现了摘要任务中关于输入位置的性能模式以及源文件到摘要的内容映射挑战。",
    "en_tdlr": "This paper investigates the context utilization in summarization with large language models, revealing a performance pattern and challenges in content mapping from the source to the summary."
}