{
    "title": "Pitfalls in Language Models for Code Intelligence: A Taxonomy and Survey. (arXiv:2310.17903v1 [cs.SE])",
    "abstract": "Modern language models (LMs) have been successfully employed in source code generation and understanding, leading to a significant increase in research focused on learning-based code intelligence, such as automated bug repair, and test case generation. Despite their great potential, language models for code intelligence (LM4Code) are susceptible to potential pitfalls, which hinder realistic performance and further impact their reliability and applicability in real-world deployment. Such challenges drive the need for a comprehensive understanding - not just identifying these issues but delving into their possible implications and existing solutions to build more reliable language models tailored to code intelligence. Based on a well-defined systematic research approach, we conducted an extensive literature review to uncover the pitfalls inherent in LM4Code. Finally, 67 primary studies from top-tier venues have been identified. After carefully examining these studies, we designed a taxon",
    "link": "http://arxiv.org/abs/2310.17903",
    "context": "Title: Pitfalls in Language Models for Code Intelligence: A Taxonomy and Survey. (arXiv:2310.17903v1 [cs.SE])\nAbstract: Modern language models (LMs) have been successfully employed in source code generation and understanding, leading to a significant increase in research focused on learning-based code intelligence, such as automated bug repair, and test case generation. Despite their great potential, language models for code intelligence (LM4Code) are susceptible to potential pitfalls, which hinder realistic performance and further impact their reliability and applicability in real-world deployment. Such challenges drive the need for a comprehensive understanding - not just identifying these issues but delving into their possible implications and existing solutions to build more reliable language models tailored to code intelligence. Based on a well-defined systematic research approach, we conducted an extensive literature review to uncover the pitfalls inherent in LM4Code. Finally, 67 primary studies from top-tier venues have been identified. After carefully examining these studies, we designed a taxon",
    "path": "papers/23/10/2310.17903.json",
    "total_tokens": 882,
    "translated_title": "代码智能中的语言模型陷阱: 一份分类法与调查",
    "translated_abstract": "现代语言模型（LM）已成功应用于源代码生成和理解，从而大幅增加了对基于学习的代码智能（如自动错误修复和测试用例生成）的研究。尽管具有巨大潜力，但面向代码智能的语言模型（LM4Code）容易受到潜在陷阱的影响，这限制了实际性能，并进一步影响它们在现实世界中的可靠性和适用性。这些挑战驱动着对这些问题的全面理解——不仅要识别这些问题，还要深入研究其可能的影响以及现有解决方案，以构建更可靠的面向代码智能的语言模型。基于明确定义的系统化研究方法，我们进行了广泛的文献综述，揭示了LM4Code中固有的陷阱。最后，我们确定了来自顶级会议的67个主要研究。经过仔细研究这些研究，我们设计了一个分类法。",
    "tldr": "该论文介绍了面向代码智能的语言模型（LM4Code）可能遇到的陷阱，并提出了一个分类法，总结了67个主要研究，以促进构建更可靠的LM4Code。"
}