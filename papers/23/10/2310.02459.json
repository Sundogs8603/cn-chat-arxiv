{
    "title": "Distributionally Safe Reinforcement Learning under Model Uncertainty: A Single-Level Approach by Differentiable Convex Programming. (arXiv:2310.02459v1 [cs.LG])",
    "abstract": "Safety assurance is uncompromisable for safety-critical environments with the presence of drastic model uncertainties (e.g., distributional shift), especially with humans in the loop. However, incorporating uncertainty in safe learning will naturally lead to a bi-level problem, where at the lower level the (worst-case) safety constraint is evaluated within the uncertainty ambiguity set. In this paper, we present a tractable distributionally safe reinforcement learning framework to enforce safety under a distributional shift measured by a Wasserstein metric. To improve the tractability, we first use duality theory to transform the lower-level optimization from infinite-dimensional probability space where distributional shift is measured, to a finite-dimensional parametric space. Moreover, by differentiable convex programming, the bi-level safe learning problem is further reduced to a single-level one with two sequential computationally efficient modules: a convex quadratic program to gu",
    "link": "http://arxiv.org/abs/2310.02459",
    "context": "Title: Distributionally Safe Reinforcement Learning under Model Uncertainty: A Single-Level Approach by Differentiable Convex Programming. (arXiv:2310.02459v1 [cs.LG])\nAbstract: Safety assurance is uncompromisable for safety-critical environments with the presence of drastic model uncertainties (e.g., distributional shift), especially with humans in the loop. However, incorporating uncertainty in safe learning will naturally lead to a bi-level problem, where at the lower level the (worst-case) safety constraint is evaluated within the uncertainty ambiguity set. In this paper, we present a tractable distributionally safe reinforcement learning framework to enforce safety under a distributional shift measured by a Wasserstein metric. To improve the tractability, we first use duality theory to transform the lower-level optimization from infinite-dimensional probability space where distributional shift is measured, to a finite-dimensional parametric space. Moreover, by differentiable convex programming, the bi-level safe learning problem is further reduced to a single-level one with two sequential computationally efficient modules: a convex quadratic program to gu",
    "path": "papers/23/10/2310.02459.json",
    "total_tokens": 879,
    "translated_title": "在模型不确定性下的分布安全强化学习: 基于可微分凸规划的单层方法",
    "translated_abstract": "在存在剧烈模型不确定性（如分布偏移）的安全关键环境中，安全保证是不可妥协的，特别是在人员参与的情况下。然而，将不确定性纳入安全学习中自然会导致一个双层问题，在这个问题中，较低层次上在不确定性模糊集合内评估（最坏情况下的）安全约束。本文提出了一个可行的分布安全强化学习框架，通过Wasserstein度量来确保在分布偏移下的安全性。为了提高可操作性，我们首先使用对偶理论将较低层次的优化问题从无限维概率空间（用于测量分布偏移）转化为有限维参数空间。此外，通过可微分凸规划，将双层安全学习问题进一步简化为一个单层问题，需要两个顺序计算高效模块：一个凸二次规划来保证安全性约束，一个可微分优化来学习策略。",
    "tldr": "本文提出了一个分布安全的强化学习框架，通过Wasserstein度量来确保在模型不确定性下的安全性。通过使用对偶理论和可微分凸规划，将双层问题简化为单层问题，提高了可行性和效率。"
}