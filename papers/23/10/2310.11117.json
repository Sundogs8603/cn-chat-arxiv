{
    "title": "USDC: Unified Static and Dynamic Compression for Visual Transformer. (arXiv:2310.11117v1 [cs.CV])",
    "abstract": "Visual Transformers have achieved great success in almost all vision tasks, such as classification, detection, and so on. However, the model complexity and the inference speed of the visual transformers hinder their deployments in industrial products. Various model compression techniques focus on directly compressing the visual transformers into a smaller one while maintaining the model performance, however, the performance drops dramatically when the compression ratio is large. Furthermore, several dynamic network techniques have also been applied to dynamically compress the visual transformers to obtain input-adaptive efficient sub-structures during the inference stage, which can achieve a better trade-off between the compression ratio and the model performance. The upper bound of memory of dynamic models is not reduced in the practical deployment since the whole original visual transformer model and the additional control gating modules should be loaded onto devices together for inf",
    "link": "http://arxiv.org/abs/2310.11117",
    "context": "Title: USDC: Unified Static and Dynamic Compression for Visual Transformer. (arXiv:2310.11117v1 [cs.CV])\nAbstract: Visual Transformers have achieved great success in almost all vision tasks, such as classification, detection, and so on. However, the model complexity and the inference speed of the visual transformers hinder their deployments in industrial products. Various model compression techniques focus on directly compressing the visual transformers into a smaller one while maintaining the model performance, however, the performance drops dramatically when the compression ratio is large. Furthermore, several dynamic network techniques have also been applied to dynamically compress the visual transformers to obtain input-adaptive efficient sub-structures during the inference stage, which can achieve a better trade-off between the compression ratio and the model performance. The upper bound of memory of dynamic models is not reduced in the practical deployment since the whole original visual transformer model and the additional control gating modules should be loaded onto devices together for inf",
    "path": "papers/23/10/2310.11117.json",
    "total_tokens": 805,
    "translated_title": "USDC:面向视觉Transformer的统一静态和动态压缩",
    "translated_abstract": "视觉Transformer在几乎所有的视觉任务中取得了巨大的成功，如分类、检测等。然而，视觉Transformer的模型复杂度和推理速度阻碍了它们在工业产品中的部署。各种模型压缩技术侧重于直接将视觉Transformer压缩为更小的模型，同时保持模型性能，然而，当压缩比例较大时，性能急剧下降。此外，在推理阶段还应用了几种动态网络技术，动态压缩视觉Transformer以在推理阶段获取输入自适应的高效子结构，这可以在压缩比例和模型性能之间实现更好的折衷。动态模型的内存上限在实际部署中没有减小，因为整个原始视觉Transformer模型和额外的控制门控模块都必须一起加载到设备上进行推理。",
    "tldr": "USDC是一种统一静态和动态压缩的方法，用于缩减视觉Transformer模型的复杂度和推理速度，并取得更好的性能折衷。",
    "en_tdlr": "USDC is a method that combines static and dynamic compression to reduce the complexity and inference speed of visual Transformer models, achieving a better trade-off in performance."
}