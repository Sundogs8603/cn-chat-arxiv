{
    "title": "Adapt Anything: Tailor Any Image Classifiers across Domains And Categories Using Text-to-Image Diffusion Models. (arXiv:2310.16573v1 [cs.CV])",
    "abstract": "We do not pursue a novel method in this paper, but aim to study if a modern text-to-image diffusion model can tailor any task-adaptive image classifier across domains and categories. Existing domain adaptive image classification works exploit both source and target data for domain alignment so as to transfer the knowledge learned from the labeled source data to the unlabeled target data. However, as the development of the text-to-image diffusion model, we wonder if the high-fidelity synthetic data from the text-to-image generator can serve as a surrogate of the source data in real world. In this way, we do not need to collect and annotate the source data for each domain adaptation task in a one-for-one manner. Instead, we utilize only one off-the-shelf text-to-image model to synthesize images with category labels derived from the corresponding text prompts, and then leverage the surrogate data as a bridge to transfer the knowledge embedded in the task-agnostic text-to-image generator t",
    "link": "http://arxiv.org/abs/2310.16573",
    "context": "Title: Adapt Anything: Tailor Any Image Classifiers across Domains And Categories Using Text-to-Image Diffusion Models. (arXiv:2310.16573v1 [cs.CV])\nAbstract: We do not pursue a novel method in this paper, but aim to study if a modern text-to-image diffusion model can tailor any task-adaptive image classifier across domains and categories. Existing domain adaptive image classification works exploit both source and target data for domain alignment so as to transfer the knowledge learned from the labeled source data to the unlabeled target data. However, as the development of the text-to-image diffusion model, we wonder if the high-fidelity synthetic data from the text-to-image generator can serve as a surrogate of the source data in real world. In this way, we do not need to collect and annotate the source data for each domain adaptation task in a one-for-one manner. Instead, we utilize only one off-the-shelf text-to-image model to synthesize images with category labels derived from the corresponding text prompts, and then leverage the surrogate data as a bridge to transfer the knowledge embedded in the task-agnostic text-to-image generator t",
    "path": "papers/23/10/2310.16573.json",
    "total_tokens": 968,
    "translated_title": "通过文本生成图片扩散模型，适应性地调整任何图像分类器跨域和类别",
    "translated_abstract": "本文研究的不是一种新的方法，而是研究了现代文本生成图片扩散模型能否适应性地调整任何跨域和跨类别的图像分类器。现有的领域适应性图像分类方法通过利用源域和目标域数据进行域对齐，从而将从有标签源域数据中学到的知识转移到无标签目标域数据中。然而，随着文本生成图片扩散模型的发展，我们想知道从文本生成的高保真度合成数据是否可以作为实际场景中源域数据的代理。这样，我们就不需要以一对一的方式收集和注释每个领域适应的任务中的源域数据。而是只使用一个现成的文本生成图片模型，生成带有相应文本提示派生的类别标签的图片，然后利用这些合成数据作为桥梁，将嵌入在任务无关的文本生成图片模型中的知识转移到目标域。",
    "tldr": "本文研究了利用文本生成图片扩散模型适应性地调整任何跨域和跨类别的图像分类器。作者通过使用合成的高保真度图片作为源域数据的代理，并将嵌入在文本生成图片模型中的知识转移到目标域，从而省去了手动收集和注释源域数据的过程。",
    "en_tdlr": "This paper investigates the adaptability of image classifiers across domains and categories using a text-to-image diffusion model. By using high-fidelity synthetic images as proxies for source domain data and transferring the knowledge embedded in the text-to-image model to the target domain, the need for manual collection and annotation of source domain data is eliminated."
}