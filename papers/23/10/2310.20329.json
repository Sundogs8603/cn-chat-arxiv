{
    "title": "InstructCoder: Empowering Language Models for Code Editing. (arXiv:2310.20329v1 [cs.CL])",
    "abstract": "Code editing encompasses a variety of pragmatic tasks that developers deal with daily. Despite its relevance and practical usefulness, automatic code editing remains an underexplored area in the evolution of deep learning models, partly due to data scarcity. In this work, we explore the use of large language models (LLMs) to edit code based on user instructions, covering a broad range of implicit tasks such as comment insertion, code optimization, and code refactoring. To facilitate this, we introduce InstructCoder, the first dataset designed to adapt LLMs for general-purpose code editing, containing highdiversity code-editing tasks. It consists of over 114,000 instruction-input-output triplets and covers multiple distinct code editing scenarios. The dataset is systematically expanded through an iterative process that commences with code editing data sourced from GitHub commits as seed tasks. Seed and generated tasks are used subsequently to prompt ChatGPT for more task data. Our exper",
    "link": "http://arxiv.org/abs/2310.20329",
    "context": "Title: InstructCoder: Empowering Language Models for Code Editing. (arXiv:2310.20329v1 [cs.CL])\nAbstract: Code editing encompasses a variety of pragmatic tasks that developers deal with daily. Despite its relevance and practical usefulness, automatic code editing remains an underexplored area in the evolution of deep learning models, partly due to data scarcity. In this work, we explore the use of large language models (LLMs) to edit code based on user instructions, covering a broad range of implicit tasks such as comment insertion, code optimization, and code refactoring. To facilitate this, we introduce InstructCoder, the first dataset designed to adapt LLMs for general-purpose code editing, containing highdiversity code-editing tasks. It consists of over 114,000 instruction-input-output triplets and covers multiple distinct code editing scenarios. The dataset is systematically expanded through an iterative process that commences with code editing data sourced from GitHub commits as seed tasks. Seed and generated tasks are used subsequently to prompt ChatGPT for more task data. Our exper",
    "path": "papers/23/10/2310.20329.json",
    "total_tokens": 843,
    "translated_title": "InstructCoder: 为代码编辑赋能的语言模型。",
    "translated_abstract": "代码编辑涵盖了开发者日常处理的各种实用任务。尽管其相关性和实用性，但自动代码编辑仍然是深度学习模型演化中尚未充分探索的领域，部分原因是数据稀缺。在本研究中，我们探索了使用大型语言模型（LLMs）根据用户指令编辑代码的方法，涵盖了诸如注释插入，代码优化和代码重构等一系列隐含任务。为了实现这一目标，我们引入了InstructCoder，这是第一个专为通用代码编辑而设计的数据集，包含高多样性的代码编辑任务。该数据集包含超过114,000个指令-输入-输出三元组，并涵盖了多个不同的代码编辑场景。数据集通过一个迭代过程进行系统扩展，该过程从GitHub的提交中获取代码编辑数据作为种子任务。种子任务和生成的任务随后用于提示ChatGPT获取更多任务数据。",
    "tldr": "本研究旨在探索使用大型语言模型（LLMs）进行代码编辑，并引入了InstructCoder数据集，该数据集包含多样性的代码编辑任务，为通用代码编辑提供支持。",
    "en_tdlr": "This study investigates the use of large language models (LLMs) for code editing and introduces the InstructCoder dataset, which contains diverse code editing tasks to support general-purpose code editing."
}