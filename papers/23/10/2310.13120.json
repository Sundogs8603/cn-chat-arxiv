{
    "title": "RSAdapter: Adapting Multimodal Models for Remote Sensing Visual Question Answering. (arXiv:2310.13120v1 [cs.CV])",
    "abstract": "In recent years, with the rapid advancement of transformer models, transformer-based multimodal architectures have found wide application in various downstream tasks, including but not limited to Image Captioning, Visual Question Answering (VQA), and Image-Text Generation. However, contemporary approaches to Remote Sensing (RS) VQA often involve resource-intensive techniques, such as full fine-tuning of large models or the extraction of image-text features from pre-trained multimodal models, followed by modality fusion using decoders. These approaches demand significant computational resources and time, and a considerable number of trainable parameters are introduced. To address these challenges, we introduce a novel method known as RSAdapter, which prioritizes runtime and parameter efficiency. RSAdapter comprises two key components: the Parallel Adapter and an additional linear transformation layer inserted after each fully connected (FC) layer within the Adapter. This approach not on",
    "link": "http://arxiv.org/abs/2310.13120",
    "context": "Title: RSAdapter: Adapting Multimodal Models for Remote Sensing Visual Question Answering. (arXiv:2310.13120v1 [cs.CV])\nAbstract: In recent years, with the rapid advancement of transformer models, transformer-based multimodal architectures have found wide application in various downstream tasks, including but not limited to Image Captioning, Visual Question Answering (VQA), and Image-Text Generation. However, contemporary approaches to Remote Sensing (RS) VQA often involve resource-intensive techniques, such as full fine-tuning of large models or the extraction of image-text features from pre-trained multimodal models, followed by modality fusion using decoders. These approaches demand significant computational resources and time, and a considerable number of trainable parameters are introduced. To address these challenges, we introduce a novel method known as RSAdapter, which prioritizes runtime and parameter efficiency. RSAdapter comprises two key components: the Parallel Adapter and an additional linear transformation layer inserted after each fully connected (FC) layer within the Adapter. This approach not on",
    "path": "papers/23/10/2310.13120.json",
    "total_tokens": 810,
    "translated_title": "RSAdapter: 适应遥感视觉问答的多模态模型",
    "translated_abstract": "近年来，随着Transformer模型的快速发展，基于Transformer的多模态架构在各种下游任务中都得到了广泛应用，包括但不限于图像描述、视觉问答（VQA）和图像文本生成。然而，当前的遥感VQA方法通常涉及资源密集型技术，如对大型模型进行全面微调或从预训练的多模态模型中提取图像-文本特征，然后使用解码器进行模态融合。这些方法需要大量的计算资源和时间，并引入了相当数量的可训练参数。为了解决这些挑战，我们提出了一种名为RSAdapter的新方法，该方法优先考虑运行时和参数效率。RSAdapter包括两个关键组件：并行适配器和插入在适配器的每个全连接（FC）层后的额外线性转换层。",
    "tldr": "RSAdapter是一种针对遥感视觉问答的多模态模型，通过并行适配器和线性转换层的设计，提高了运行时和参数效率。"
}