{
    "title": "From Chatbots to PhishBots? -- Preventing Phishing scams created using ChatGPT, Google Bard and Claude",
    "abstract": "arXiv:2310.19181v2 Announce Type: replace-cross  Abstract: The advanced capabilities of Large Language Models (LLMs) have made them invaluable across various applications, from conversational agents and content creation to data analysis, research, and innovation. However, their effectiveness and accessibility also render them susceptible to abuse for generating malicious content, including phishing attacks. This study explores the potential of using four popular commercially available LLMs, i.e., ChatGPT (GPT 3.5 Turbo), GPT 4, Claude, and Bard, to generate functional phishing attacks using a series of malicious prompts. We discover that these LLMs can generate both phishing websites and emails that can convincingly imitate well-known brands and also deploy a range of evasive tactics that are used to elude detection mechanisms employed by anti-phishing systems. These attacks can be generated using unmodified or \"vanilla\" versions of these LLMs without requiring any prior adversarial ex",
    "link": "https://arxiv.org/abs/2310.19181",
    "context": "Title: From Chatbots to PhishBots? -- Preventing Phishing scams created using ChatGPT, Google Bard and Claude\nAbstract: arXiv:2310.19181v2 Announce Type: replace-cross  Abstract: The advanced capabilities of Large Language Models (LLMs) have made them invaluable across various applications, from conversational agents and content creation to data analysis, research, and innovation. However, their effectiveness and accessibility also render them susceptible to abuse for generating malicious content, including phishing attacks. This study explores the potential of using four popular commercially available LLMs, i.e., ChatGPT (GPT 3.5 Turbo), GPT 4, Claude, and Bard, to generate functional phishing attacks using a series of malicious prompts. We discover that these LLMs can generate both phishing websites and emails that can convincingly imitate well-known brands and also deploy a range of evasive tactics that are used to elude detection mechanisms employed by anti-phishing systems. These attacks can be generated using unmodified or \"vanilla\" versions of these LLMs without requiring any prior adversarial ex",
    "path": "papers/23/10/2310.19181.json",
    "total_tokens": 909,
    "translated_title": "从聊天机器人到网络钓鱼机器人？-- 预防使用 ChatGPT、Google Bard 和 Claude 创建的网络钓鱼诈骗",
    "translated_abstract": "大型语言模型（LLMs）的高级功能使它们在各种应用中变得不可或缺，包括对话代理、内容创作、数据分析、研究和创新。然而，它们的有效性和可访问性也使它们容易被滥用来生成恶意内容，包括网络钓鱼攻击。本研究探讨了使用四种流行的商业可用的LLMs（ChatGPT（GPT 3.5 Turbo）、GPT 4、Claude 和 Bard）来生成功能性网络钓鱼攻击的潜力，使用一系列恶意提示。我们发现这些LLMs可以生成既能够逼真模仿知名品牌又能够部署一系列逃避探测机制的网络钓鱼网站和电子邮件。这些攻击可以使用这些LLMs的未修改或“原始”版本生成，而无需任何先前的敌对训练。",
    "tldr": "研究探讨了使用 ChatGPT、Google Bard 和 Claude 创建网络钓鱼攻击的潜力，发现这些大型语言模型可以生成逼真的网络钓鱼网站和电子邮件，并采用逃避检测机制的策略。",
    "en_tdlr": "The study explores the potential of using ChatGPT, Google Bard, and Claude to create phishing attacks, finding that these large language models can generate convincing phishing websites and emails with evasion tactics."
}