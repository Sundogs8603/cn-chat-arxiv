{
    "title": "Statistical guarantees for stochastic Metropolis-Hastings. (arXiv:2310.09335v1 [stat.ML])",
    "abstract": "A Metropolis-Hastings step is widely used for gradient-based Markov chain Monte Carlo methods in uncertainty quantification. By calculating acceptance probabilities on batches, a stochastic Metropolis-Hastings step saves computational costs, but reduces the effective sample size. We show that this obstacle can be avoided by a simple correction term. We study statistical properties of the resulting stationary distribution of the chain if the corrected stochastic Metropolis-Hastings approach is applied to sample from a Gibbs posterior distribution in a nonparametric regression setting. Focusing on deep neural network regression, we prove a PAC-Bayes oracle inequality which yields optimal contraction rates and we analyze the diameter and show high coverage probability of the resulting credible sets. With a numerical example in a high-dimensional parameter space, we illustrate that credible sets and contraction rates of the stochastic Metropolis-Hastings algorithm indeed behave similar to ",
    "link": "http://arxiv.org/abs/2310.09335",
    "context": "Title: Statistical guarantees for stochastic Metropolis-Hastings. (arXiv:2310.09335v1 [stat.ML])\nAbstract: A Metropolis-Hastings step is widely used for gradient-based Markov chain Monte Carlo methods in uncertainty quantification. By calculating acceptance probabilities on batches, a stochastic Metropolis-Hastings step saves computational costs, but reduces the effective sample size. We show that this obstacle can be avoided by a simple correction term. We study statistical properties of the resulting stationary distribution of the chain if the corrected stochastic Metropolis-Hastings approach is applied to sample from a Gibbs posterior distribution in a nonparametric regression setting. Focusing on deep neural network regression, we prove a PAC-Bayes oracle inequality which yields optimal contraction rates and we analyze the diameter and show high coverage probability of the resulting credible sets. With a numerical example in a high-dimensional parameter space, we illustrate that credible sets and contraction rates of the stochastic Metropolis-Hastings algorithm indeed behave similar to ",
    "path": "papers/23/10/2310.09335.json",
    "total_tokens": 894,
    "translated_title": "针对随机Metropolis-Hastings算法的统计保证",
    "translated_abstract": "Metropolis-Hastings步骤被广泛应用于基于梯度的马尔可夫链蒙特卡洛方法中的不确定性量化中。通过对批次计算接受概率，随机Metropolis-Hastings步骤节省了计算成本，但降低了有效样本量。我们展示了通过简单的修正项可以避免这个障碍。我们研究了如果在非参数回归设置中应用改进的随机Metropolis-Hastings方法从Gibbs后验分布中采样，则链的结果稳态分布的统计属性。针对深度神经网络回归，我们证明了PAC-Bayes预言不等式，它提供了最优的收缩速率，并分析了结果可信区间的直径和高置信概率。通过在高维参数空间中的数值实例，我们说明了随机Metropolis-Hastings算法的可信区间和收缩速率确实表现出类似的行为。",
    "tldr": "该论文研究了针对随机Metropolis-Hastings算法的统计保证。通过引入简单的修正项，该方法可以避免计算成本上的损失，并通过分析非参数回归情景和深度神经网络回归的数值实例来证明了其在采样和可信区间方面的优势。",
    "en_tdlr": "This paper investigates the statistical guarantees for stochastic Metropolis-Hastings algorithm. By introducing a simple correction term, the approach avoids the loss in computational cost and demonstrates advantages in sampling and credible interval through analyzing numerical examples in nonparametric regression and deep neural network regression."
}