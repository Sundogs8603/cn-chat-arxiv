{
    "title": "Revisiting Implicit Differentiation for Learning Problems in Optimal Control. (arXiv:2310.14468v2 [cs.LG] UPDATED)",
    "abstract": "This paper proposes a new method for differentiating through optimal trajectories arising from non-convex, constrained discrete-time optimal control (COC) problems using the implicit function theorem (IFT). Previous works solve a differential Karush-Kuhn-Tucker (KKT) system for the trajectory derivative, and achieve this efficiently by solving an auxiliary Linear Quadratic Regulator (LQR) problem. In contrast, we directly evaluate the matrix equations which arise from applying variable elimination on the Lagrange multiplier terms in the (differential) KKT system. By appropriately accounting for the structure of the terms within the resulting equations, we show that the trajectory derivatives scale linearly with the number of timesteps. Furthermore, our approach allows for easy parallelization, significantly improved scalability with model size, direct computation of vector-Jacobian products and improved numerical stability compared to prior works. As an additional contribution, we unif",
    "link": "http://arxiv.org/abs/2310.14468",
    "context": "Title: Revisiting Implicit Differentiation for Learning Problems in Optimal Control. (arXiv:2310.14468v2 [cs.LG] UPDATED)\nAbstract: This paper proposes a new method for differentiating through optimal trajectories arising from non-convex, constrained discrete-time optimal control (COC) problems using the implicit function theorem (IFT). Previous works solve a differential Karush-Kuhn-Tucker (KKT) system for the trajectory derivative, and achieve this efficiently by solving an auxiliary Linear Quadratic Regulator (LQR) problem. In contrast, we directly evaluate the matrix equations which arise from applying variable elimination on the Lagrange multiplier terms in the (differential) KKT system. By appropriately accounting for the structure of the terms within the resulting equations, we show that the trajectory derivatives scale linearly with the number of timesteps. Furthermore, our approach allows for easy parallelization, significantly improved scalability with model size, direct computation of vector-Jacobian products and improved numerical stability compared to prior works. As an additional contribution, we unif",
    "path": "papers/23/10/2310.14468.json",
    "total_tokens": 937,
    "translated_title": "重新审视隐式微分以解决最优控制中的学习问题",
    "translated_abstract": "本文提出了一种新方法，通过隐函数定理，对非凸、受约束的离散时间最优控制（COC）问题中产生的最优轨迹进行微分。先前的工作通过解决一种微分卡鲁什-库恩-塔克（KKT）系统来求解轨迹导数，并通过解决一个辅助线性二次调节器（LQR）问题来实现高效计算。相比之下，我们直接评估由在（微分）KKT系统中消除拉格朗日乘子项产生的矩阵方程。通过适当考虑结果方程中的项的结构，我们表明轨迹导数与时间步数呈线性缩放关系。此外，我们的方法允许轻松并行化，与模型大小显著改善可扩展性，直接计算向量 - 雅可比乘积，并且与以前的工作相比具有改进的数值稳定性。作为额外的贡献，我们统一了...",
    "tldr": "本文提出了一种新方法，通过隐函数定理对非凸、受约束的最优控制问题中的最优轨迹进行微分。与先前的方法相比，该方法可以线性缩放地计算轨迹导数，可以容易地进行并行化，并且在模型规模、数值稳定性和计算效率方面表现出色。",
    "en_tdlr": "This paper proposes a new method for differentiating through optimal trajectories in non-convex, constrained optimal control problems. Compared to previous methods, this approach allows for linear scaling in computing trajectory derivatives, easy parallelization, and better performance in terms of model size, numerical stability, and computational efficiency."
}