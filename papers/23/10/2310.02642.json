{
    "title": "GET: Group Event Transformer for Event-Based Vision. (arXiv:2310.02642v1 [cs.CV])",
    "abstract": "Event cameras are a type of novel neuromorphic sen-sor that has been gaining increasing attention. Existing event-based backbones mainly rely on image-based designs to extract spatial information within the image transformed from events, overlooking important event properties like time and polarity. To address this issue, we propose a novel Group-based vision Transformer backbone for Event-based vision, called Group Event Transformer (GET), which de-couples temporal-polarity information from spatial infor-mation throughout the feature extraction process. Specifi-cally, we first propose a new event representation for GET, named Group Token, which groups asynchronous events based on their timestamps and polarities. Then, GET ap-plies the Event Dual Self-Attention block, and Group Token Aggregation module to facilitate effective feature commu-nication and integration in both the spatial and temporal-polarity domains. After that, GET can be integrated with different downstream tasks by con",
    "link": "http://arxiv.org/abs/2310.02642",
    "context": "Title: GET: Group Event Transformer for Event-Based Vision. (arXiv:2310.02642v1 [cs.CV])\nAbstract: Event cameras are a type of novel neuromorphic sen-sor that has been gaining increasing attention. Existing event-based backbones mainly rely on image-based designs to extract spatial information within the image transformed from events, overlooking important event properties like time and polarity. To address this issue, we propose a novel Group-based vision Transformer backbone for Event-based vision, called Group Event Transformer (GET), which de-couples temporal-polarity information from spatial infor-mation throughout the feature extraction process. Specifi-cally, we first propose a new event representation for GET, named Group Token, which groups asynchronous events based on their timestamps and polarities. Then, GET ap-plies the Event Dual Self-Attention block, and Group Token Aggregation module to facilitate effective feature commu-nication and integration in both the spatial and temporal-polarity domains. After that, GET can be integrated with different downstream tasks by con",
    "path": "papers/23/10/2310.02642.json",
    "total_tokens": 883,
    "translated_title": "GET: 用于事件视觉的团体事件变换器",
    "translated_abstract": "事件相机是一种新型的神经形态传感器，备受关注。现有的基于事件的骨干主要依赖于基于图像的设计来提取从事件转换而来的空间信息，忽视了时间和极性等重要的事件属性。为了解决这个问题，我们提出了一种用于事件视觉的新型团体视觉变换器骨干，名为团体事件变换器(GET)，它能够在特征提取过程中将时间和极性从空间信息中解耦出来。具体而言，我们首先提出了GET的新事件表示方式，名为团体标记(Group Token)，它根据时间戳和极性对异步事件进行分组。然后，GET应用事件双自注意块和团体标记聚合模块，在空间和时间-极性领域中促进有效的特征通信和整合。在此之后，GET可以通过不同的下游任务进行集成。",
    "tldr": "GET提出了一种用于事件视觉的新型团体事件变换器，它能够将事件的时间和极性与空间信息解耦，通过事件双自注意块和团体标记聚合模块实现了在空间和时间-极性领域的特征通信和整合。",
    "en_tdlr": "GET proposes a novel Group Event Transformer for event-based vision, which decouples the temporal and polarity information of events from the spatial information. It achieves effective feature communication and integration in both the spatial and temporal-polarity domains through Event Dual Self-Attention blocks and Group Token Aggregation modules."
}