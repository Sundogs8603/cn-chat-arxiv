{
    "title": "How Graph Neural Networks Learn: Lessons from Training Dynamics",
    "abstract": "arXiv:2310.05105v2 Announce Type: replace  Abstract: A long-standing goal in deep learning has been to characterize the learning behavior of black-box models in a more interpretable manner. For graph neural networks (GNNs), considerable advances have been made in formalizing what functions they can represent, but whether GNNs will learn desired functions during the optimization process remains less clear. To fill this gap, we study their training dynamics in function space. In particular, we find that the optimization of GNNs through gradient descent implicitly leverages the graph structure to update the learned function. This phenomenon is dubbed as kernel-graph alignment, which has been empirically and theoretically corroborated. This new analytical framework from the optimization perspective enables interpretable explanations of when and why the learned GNN functions generalize, which are relevant to their limitations on heterophilic graphs. From a practical standpoint, it also prov",
    "link": "https://arxiv.org/abs/2310.05105",
    "context": "Title: How Graph Neural Networks Learn: Lessons from Training Dynamics\nAbstract: arXiv:2310.05105v2 Announce Type: replace  Abstract: A long-standing goal in deep learning has been to characterize the learning behavior of black-box models in a more interpretable manner. For graph neural networks (GNNs), considerable advances have been made in formalizing what functions they can represent, but whether GNNs will learn desired functions during the optimization process remains less clear. To fill this gap, we study their training dynamics in function space. In particular, we find that the optimization of GNNs through gradient descent implicitly leverages the graph structure to update the learned function. This phenomenon is dubbed as kernel-graph alignment, which has been empirically and theoretically corroborated. This new analytical framework from the optimization perspective enables interpretable explanations of when and why the learned GNN functions generalize, which are relevant to their limitations on heterophilic graphs. From a practical standpoint, it also prov",
    "path": "papers/23/10/2310.05105.json",
    "total_tokens": 845,
    "translated_title": "图神经网络是如何学习的：来自训练动态的启示",
    "translated_abstract": "在深度学习中，一个长期以来的目标是以更易解释的方式表征黑盒模型的学习行为。对于图神经网络（GNNs），在正式化它们可以表示的函数方面已经取得了相当大的进展，但在优化过程中GNNs是否会学习到期望的函数仍不太清楚。为了填补这一空白，我们研究了它们在函数空间中的训练动态。特别是，我们发现通过梯度下降优化GNNs隐式利用图结构来更新学到的函数。这种现象被称为核-图对齐，已经经验性和理论上得到了验证。这种来自优化角度的新分析框架能够解释了何时以及为什么学习到的GNN函数泛化，这对于它们在异源图上的限制具有相关性。从实用的角度看，它也提供了对于GNNs如何学习函数的洞察。",
    "tldr": "图神经网络的优化过程中涉及核-图对齐现象，从优化角度解释了学到的函数何时和为何泛化，有助于理解其在异源图上的限制。"
}