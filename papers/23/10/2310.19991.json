{
    "title": "PolyThrottle: Energy-efficient Neural Network Inference on Edge Devices. (arXiv:2310.19991v1 [cs.LG])",
    "abstract": "As neural networks (NN) are deployed across diverse sectors, their energy demand correspondingly grows. While several prior works have focused on reducing energy consumption during training, the continuous operation of ML-powered systems leads to significant energy use during inference. This paper investigates how the configuration of on-device hardware-elements such as GPU, memory, and CPU frequency, often neglected in prior studies, affects energy consumption for NN inference with regular fine-tuning. We propose PolyThrottle, a solution that optimizes configurations across individual hardware components using Constrained Bayesian Optimization in an energy-conserving manner. Our empirical evaluation uncovers novel facets of the energy-performance equilibrium showing that we can save up to 36 percent of energy for popular models. We also validate that PolyThrottle can quickly converge towards near-optimal settings while satisfying application constraints.",
    "link": "http://arxiv.org/abs/2310.19991",
    "context": "Title: PolyThrottle: Energy-efficient Neural Network Inference on Edge Devices. (arXiv:2310.19991v1 [cs.LG])\nAbstract: As neural networks (NN) are deployed across diverse sectors, their energy demand correspondingly grows. While several prior works have focused on reducing energy consumption during training, the continuous operation of ML-powered systems leads to significant energy use during inference. This paper investigates how the configuration of on-device hardware-elements such as GPU, memory, and CPU frequency, often neglected in prior studies, affects energy consumption for NN inference with regular fine-tuning. We propose PolyThrottle, a solution that optimizes configurations across individual hardware components using Constrained Bayesian Optimization in an energy-conserving manner. Our empirical evaluation uncovers novel facets of the energy-performance equilibrium showing that we can save up to 36 percent of energy for popular models. We also validate that PolyThrottle can quickly converge towards near-optimal settings while satisfying application constraints.",
    "path": "papers/23/10/2310.19991.json",
    "total_tokens": 865,
    "translated_title": "PolyThrottle: 边缘设备上的节能神经网络推理",
    "translated_abstract": "随着神经网络在各个领域的部署，其能量需求也相应增长。尽管一些先前的工作专注于在训练过程中减少能量消耗，但是ML驱动系统的连续运行在推理过程中会导致显著的能量消耗。本文调查了设备上的硬件元素配置（如GPU、内存和CPU频率）在常规微调的神经网络推理中如何影响能量消耗，这在先前的研究中经常被忽视。我们提出了一种名为PolyThrottle的解决方案，通过受约束的贝叶斯优化以节能的方式对各个硬件组件的配置进行优化。我们的实证评估揭示了能量性能平衡的新颖方面，表明我们可以为流行模型节省高达36%的能量。我们还验证了PolyThrottle可以在满足应用约束条件的同时快速收敛到接近最优的设置。",
    "tldr": "PolyThrottle是一种在边缘设备上进行节能神经网络推理的解决方案，通过优化设备上的硬件元素配置，可以达到高达36%的能量节省，并且能够快速收敛到近乎最优的设置。",
    "en_tdlr": "PolyThrottle is a solution for energy-efficient neural network inference on edge devices. By optimizing the configuration of hardware elements, it achieves up to 36% energy savings for popular models and quickly converges to near-optimal settings."
}