{
    "title": "MuSe-GNN: Learning Unified Gene Representation From Multimodal Biological Graph Data. (arXiv:2310.02275v1 [cs.LG])",
    "abstract": "Discovering genes with similar functions across diverse biomedical contexts poses a significant challenge in gene representation learning due to data heterogeneity. In this study, we resolve this problem by introducing a novel model called Multimodal Similarity Learning Graph Neural Network, which combines Multimodal Machine Learning and Deep Graph Neural Networks to learn gene representations from single-cell sequencing and spatial transcriptomic data. Leveraging 82 training datasets from 10 tissues, three sequencing techniques, and three species, we create informative graph structures for model training and gene representations generation, while incorporating regularization with weighted similarity learning and contrastive learning to learn cross-data gene-gene relationships. This novel design ensures that we can offer gene representations containing functional similarity across different contexts in a joint space. Comprehensive benchmarking analysis shows our model's capacity to eff",
    "link": "http://arxiv.org/abs/2310.02275",
    "context": "Title: MuSe-GNN: Learning Unified Gene Representation From Multimodal Biological Graph Data. (arXiv:2310.02275v1 [cs.LG])\nAbstract: Discovering genes with similar functions across diverse biomedical contexts poses a significant challenge in gene representation learning due to data heterogeneity. In this study, we resolve this problem by introducing a novel model called Multimodal Similarity Learning Graph Neural Network, which combines Multimodal Machine Learning and Deep Graph Neural Networks to learn gene representations from single-cell sequencing and spatial transcriptomic data. Leveraging 82 training datasets from 10 tissues, three sequencing techniques, and three species, we create informative graph structures for model training and gene representations generation, while incorporating regularization with weighted similarity learning and contrastive learning to learn cross-data gene-gene relationships. This novel design ensures that we can offer gene representations containing functional similarity across different contexts in a joint space. Comprehensive benchmarking analysis shows our model's capacity to eff",
    "path": "papers/23/10/2310.02275.json",
    "total_tokens": 872,
    "translated_title": "MuSe-GNN：从多模态生物图数据中学习统一的基因表示",
    "translated_abstract": "在基因表示学习中，由于数据异质性，发现具有相似功能的基因在不同生物医学背景下的问题仍然具有挑战性。本研究引入了一种名为多模态相似性学习图神经网络（MuSe-GNN）的新模型来解决这个问题，该模型结合了多模态机器学习和深度图神经网络，从单细胞测序和空间转录组数据中学习基因表示。利用10个组织的82个训练数据集、三种测序技术和三个物种，我们创建了信息丰富的图结构用于模型训练和基因表示生成，并通过加权相似性学习和对比学习的正则化方法学习跨数据基因关系。这种新颖的设计确保我们可以在一个共同的空间中提供包含不同背景下功能相似性的基因表示。全面的基准分析表明我们的模型具有有效的性能。",
    "tldr": "本研究引入了一种名为MuSe-GNN的模型，通过结合多模态机器学习和深度图神经网络，从单细胞测序和空间转录组数据中学习基因表示，并利用加权相似性学习和对比学习的正则化方法学习跨数据基因关系。该模型能够在一个共同的空间中提供包含不同背景下功能相似性的基因表示。"
}