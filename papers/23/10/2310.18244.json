{
    "title": "A Review of the Evidence for Existential Risk from AI via Misaligned Power-Seeking. (arXiv:2310.18244v1 [cs.CY])",
    "abstract": "Rapid advancements in artificial intelligence (AI) have sparked growing concerns among experts, policymakers, and world leaders regarding the potential for increasingly advanced AI systems to pose existential risks. This paper reviews the evidence for existential risks from AI via misalignment, where AI systems develop goals misaligned with human values, and power-seeking, where misaligned AIs actively seek power. The review examines empirical findings, conceptual arguments and expert opinion relating to specification gaming, goal misgeneralization, and power-seeking. The current state of the evidence is found to be concerning but inconclusive regarding the existence of extreme forms of misaligned power-seeking. Strong empirical evidence of specification gaming combined with strong conceptual evidence for power-seeking make it difficult to dismiss the possibility of existential risk from misaligned power-seeking. On the other hand, to date there are no public empirical examples of misa",
    "link": "http://arxiv.org/abs/2310.18244",
    "context": "Title: A Review of the Evidence for Existential Risk from AI via Misaligned Power-Seeking. (arXiv:2310.18244v1 [cs.CY])\nAbstract: Rapid advancements in artificial intelligence (AI) have sparked growing concerns among experts, policymakers, and world leaders regarding the potential for increasingly advanced AI systems to pose existential risks. This paper reviews the evidence for existential risks from AI via misalignment, where AI systems develop goals misaligned with human values, and power-seeking, where misaligned AIs actively seek power. The review examines empirical findings, conceptual arguments and expert opinion relating to specification gaming, goal misgeneralization, and power-seeking. The current state of the evidence is found to be concerning but inconclusive regarding the existence of extreme forms of misaligned power-seeking. Strong empirical evidence of specification gaming combined with strong conceptual evidence for power-seeking make it difficult to dismiss the possibility of existential risk from misaligned power-seeking. On the other hand, to date there are no public empirical examples of misa",
    "path": "papers/23/10/2310.18244.json",
    "total_tokens": 984,
    "translated_title": "对AI通过目标不协调和寻求权力的存在风险的证据综述",
    "translated_abstract": "快速发展的人工智能（AI）引发了专家、政策制定者和世界领导人对日益先进的AI系统可能造成的存在风险的担忧。本文综述了关于AI通过目标不协调和寻求权力导致的存在风险的证据。综述涵盖了关于规范游戏、目标误概化和寻求权力的实证研究、概念上的论证和专家意见。研究发现目前的证据情况令人担忧但又没有定论，无法排除存在极端形式的目标不协调和寻求权力的存在风险。强有力的规范游戏的实证证据和对寻求权力的概念性证据使得忽视目标不协调和寻求权力导致的存在风险的可能性变得困难。然而到目前为止，尚无公开的实证例子证明存在风险。",
    "tldr": "这篇文章综述了关于人工智能通过目标不协调和寻求权力可能导致的存在风险的证据。研究发现尽管目前的证据情况令人担忧但又没有确定的结论，强有力的规范游戏实证证据以及对寻求权力的概念性证据使得无法排除存在风险的可能性。然而，到目前为止尚无公开的实证例子证明存在风险。",
    "en_tdlr": "This paper reviews the evidence for existential risks from AI via misalignment and power-seeking. The review suggests that although the current evidence is concerning but inconclusive, strong empirical evidence of specification gaming combined with strong conceptual evidence for power-seeking make it difficult to dismiss the possibility of existential risk from misaligned power-seeking. However, to date there are no public empirical examples of such risks."
}