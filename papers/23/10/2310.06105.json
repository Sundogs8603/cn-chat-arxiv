{
    "title": "Quantifying Uncertainty in Deep Learning Classification with Noise in Discrete Inputs for Risk-Based Decision Making. (arXiv:2310.06105v1 [stat.ML])",
    "abstract": "The use of Deep Neural Network (DNN) models in risk-based decision-making has attracted extensive attention with broad applications in medical, finance, manufacturing, and quality control. To mitigate prediction-related risks in decision making, prediction confidence or uncertainty should be assessed alongside the overall performance of algorithms. Recent studies on Bayesian deep learning helps quantify prediction uncertainty arises from input noises and model parameters. However, the normality assumption of input noise in these models limits their applicability to problems involving categorical and discrete feature variables in tabular datasets. In this paper, we propose a mathematical framework to quantify prediction uncertainty for DNN models. The prediction uncertainty arises from errors in predictors that follow some known finite discrete distribution. We then conducted a case study using the framework to predict treatment outcome for tuberculosis patients during their course of t",
    "link": "http://arxiv.org/abs/2310.06105",
    "context": "Title: Quantifying Uncertainty in Deep Learning Classification with Noise in Discrete Inputs for Risk-Based Decision Making. (arXiv:2310.06105v1 [stat.ML])\nAbstract: The use of Deep Neural Network (DNN) models in risk-based decision-making has attracted extensive attention with broad applications in medical, finance, manufacturing, and quality control. To mitigate prediction-related risks in decision making, prediction confidence or uncertainty should be assessed alongside the overall performance of algorithms. Recent studies on Bayesian deep learning helps quantify prediction uncertainty arises from input noises and model parameters. However, the normality assumption of input noise in these models limits their applicability to problems involving categorical and discrete feature variables in tabular datasets. In this paper, we propose a mathematical framework to quantify prediction uncertainty for DNN models. The prediction uncertainty arises from errors in predictors that follow some known finite discrete distribution. We then conducted a case study using the framework to predict treatment outcome for tuberculosis patients during their course of t",
    "path": "papers/23/10/2310.06105.json",
    "total_tokens": 935,
    "translated_title": "用于基于风险决策的深度学习分类中离散输入的不确定性量化",
    "translated_abstract": "深度神经网络（DNN）模型在基于风险决策中的应用引起了广泛关注，在医疗、金融、制造和质量控制等领域具有广泛的应用。为了在决策过程中减轻相关风险，预测的置信度或不确定性应该与算法的整体性能一起进行评估。最近关于贝叶斯深度学习的研究有助于量化源于输入噪声和模型参数的预测不确定性。然而，这些模型中对输入噪声的正态性假设限制了其适用于涉及分类和离散特征变量的问题。在本文中，我们提出了一个数学框架来量化DNN模型的预测不确定性。这种预测不确定性源于遵循已知有限离散分布的预测器误差。然后，我们使用该框架进行了一个案例研究，预测结核病患者治疗结果的过程中的不确定性。",
    "tldr": "本文提出了一种数学框架来量化基于风险决策的深度学习分类中离散输入的预测不确定性。我们的研究有助于在决策过程中减轻相关风险，并且可以适用于处理涉及分类和离散特征变量的问题。",
    "en_tdlr": "This paper proposes a mathematical framework to quantify prediction uncertainty for risk-based decision-making in deep learning classification with discrete inputs. The research contributes to mitigating related risks in decision-making and can be applied to problems involving categorical and discrete feature variables."
}