{
    "title": "Learning Fair Representations with High-Confidence Guarantees. (arXiv:2310.15358v1 [cs.LG])",
    "abstract": "Representation learning is increasingly employed to generate representations that are predictive across multiple downstream tasks. The development of representation learning algorithms that provide strong fairness guarantees is thus important because it can prevent unfairness towards disadvantaged groups for all downstream prediction tasks. To prevent unfairness towards disadvantaged groups in all downstream tasks, it is crucial to provide representation learning algorithms that provide fairness guarantees. In this paper, we formally define the problem of learning representations that are fair with high confidence. We then introduce the Fair Representation learning with high-confidence Guarantees (FRG) framework, which provides high-confidence guarantees for limiting unfairness across all downstream models and tasks, with user-defined upper bounds. After proving that FRG ensures fairness for all downstream models and tasks with high probability, we present empirical evaluations that de",
    "link": "http://arxiv.org/abs/2310.15358",
    "context": "Title: Learning Fair Representations with High-Confidence Guarantees. (arXiv:2310.15358v1 [cs.LG])\nAbstract: Representation learning is increasingly employed to generate representations that are predictive across multiple downstream tasks. The development of representation learning algorithms that provide strong fairness guarantees is thus important because it can prevent unfairness towards disadvantaged groups for all downstream prediction tasks. To prevent unfairness towards disadvantaged groups in all downstream tasks, it is crucial to provide representation learning algorithms that provide fairness guarantees. In this paper, we formally define the problem of learning representations that are fair with high confidence. We then introduce the Fair Representation learning with high-confidence Guarantees (FRG) framework, which provides high-confidence guarantees for limiting unfairness across all downstream models and tasks, with user-defined upper bounds. After proving that FRG ensures fairness for all downstream models and tasks with high probability, we present empirical evaluations that de",
    "path": "papers/23/10/2310.15358.json",
    "total_tokens": 821,
    "translated_title": "学习具有高置信度保证的公平表示",
    "translated_abstract": "越来越多地使用表示学习生成跨多个下游任务具有预测性的表示。因此，开发能提供强有力公平保证的表示学习算法非常重要，因为它可以防止对弱势群体在所有下游预测任务中的不公平待遇。为了防止在所有下游任务中对弱势群体的不公平待遇，提供提供公平保证的表示学习算法至关重要。本文形式化定义了学习具有高置信度的公平表示的问题。然后，我们介绍了具有高置信度保证的公平表示学习（FRG）框架，该框架以用户定义的上界为限制，在所有下游模型和任务中降低不公平性，并证明FRG能以高概率保证所有下游模型和任务的公平性。最后，我们进行了实证评估，证明了FRG框架的有效性。",
    "tldr": "本文提出了一个具有高概率公平性保证的公平表示学习框架（FRG），通过用户定义的上界限制，在所有下游模型和任务中减少不公平性。实证评估结果证明了FRG的有效性。"
}