{
    "title": "On the Inherent Privacy Properties of Discrete Denoising Diffusion Models. (arXiv:2310.15524v1 [cs.LG])",
    "abstract": "Privacy concerns have led to a surge in the creation of synthetic datasets, with diffusion models emerging as a promising avenue. Although prior studies have performed empirical evaluations on these models, there has been a gap in providing a mathematical characterization of their privacy-preserving capabilities. To address this, we present the pioneering theoretical exploration of the privacy preservation inherent in discrete diffusion models (DDMs) for discrete dataset generation. Focusing on per-instance differential privacy (pDP), our framework elucidates the potential privacy leakage for each data point in a given training dataset, offering insights into data preprocessing to reduce privacy risks of the synthetic dataset generation via DDMs. Our bounds also show that training with $s$-sized data points leads to a surge in privacy leakage from $(\\epsilon, \\mathcal{O}(\\frac{1}{s^2\\epsilon}))$-pDP to $(\\epsilon, \\mathcal{O}(\\frac{1}{s\\epsilon}))$-pDP during the transition from the pu",
    "link": "http://arxiv.org/abs/2310.15524",
    "context": "Title: On the Inherent Privacy Properties of Discrete Denoising Diffusion Models. (arXiv:2310.15524v1 [cs.LG])\nAbstract: Privacy concerns have led to a surge in the creation of synthetic datasets, with diffusion models emerging as a promising avenue. Although prior studies have performed empirical evaluations on these models, there has been a gap in providing a mathematical characterization of their privacy-preserving capabilities. To address this, we present the pioneering theoretical exploration of the privacy preservation inherent in discrete diffusion models (DDMs) for discrete dataset generation. Focusing on per-instance differential privacy (pDP), our framework elucidates the potential privacy leakage for each data point in a given training dataset, offering insights into data preprocessing to reduce privacy risks of the synthetic dataset generation via DDMs. Our bounds also show that training with $s$-sized data points leads to a surge in privacy leakage from $(\\epsilon, \\mathcal{O}(\\frac{1}{s^2\\epsilon}))$-pDP to $(\\epsilon, \\mathcal{O}(\\frac{1}{s\\epsilon}))$-pDP during the transition from the pu",
    "path": "papers/23/10/2310.15524.json",
    "total_tokens": 952,
    "translated_title": "关于离散去噪扩散模型内在隐私属性的研究",
    "translated_abstract": "隐私问题导致合成数据集的创建激增，扩散模型成为一种有前景的方法。虽然以前的研究已经对这些模型进行了经验评估，但在提供数学特征化其隐私保护能力方面存在差距。为了解决这个问题，我们提出了离散扩散模型（DDMs）内在隐私保护的开创性理论研究，用于离散数据集生成。对于每个数据点的每个实例差异隐私（pDP），我们的框架阐明了给定训练数据集中每个数据点的潜在隐私泄露，从而为通过DDMs降低合成数据集生成的隐私风险提供了洞察。我们的界限还表明，使用$s$个大小的数据点进行训练会导致隐私泄露从$(\\epsilon, \\mathcal{O}(\\frac{1}{s^2\\epsilon}))$-pDP到$(\\epsilon, \\mathcal{O}(\\frac{1}{s\\epsilon}))$-pDP的激增。",
    "tldr": "本研究探索了离散扩散模型在隐私保护方面的潜力，提供了关于训练数据集中每个数据点的隐私泄露的洞察，以及通过数据预处理减少合成数据集生成中隐私风险的方法。",
    "en_tdlr": "This study explores the potential of discrete diffusion models in privacy preservation, offering insights into the privacy leakage of each data point in the training dataset and methods to reduce privacy risks in synthetic dataset generation through data preprocessing."
}