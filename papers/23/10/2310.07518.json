{
    "title": "Exploiting Causal Graph Priors with Posterior Sampling for Reinforcement Learning. (arXiv:2310.07518v1 [cs.LG])",
    "abstract": "Posterior sampling allows the exploitation of prior knowledge of the environment's transition dynamics to improve the sample efficiency of reinforcement learning. The prior is typically specified as a class of parametric distributions, a task that can be cumbersome in practice, often resulting in the choice of uninformative priors. In this work, we propose a novel posterior sampling approach in which the prior is given as a (partial) causal graph over the environment's variables. The latter is often more natural to design, such as listing known causal dependencies between biometric features in a medical treatment study. Specifically, we propose a hierarchical Bayesian procedure, called C-PSRL, simultaneously learning the full causal graph at the higher level and the parameters of the resulting factored dynamics at the lower level. For this procedure, we provide an analysis of its Bayesian regret, which explicitly connects the regret rate with the degree of prior knowledge. Our numerica",
    "link": "http://arxiv.org/abs/2310.07518",
    "context": "Title: Exploiting Causal Graph Priors with Posterior Sampling for Reinforcement Learning. (arXiv:2310.07518v1 [cs.LG])\nAbstract: Posterior sampling allows the exploitation of prior knowledge of the environment's transition dynamics to improve the sample efficiency of reinforcement learning. The prior is typically specified as a class of parametric distributions, a task that can be cumbersome in practice, often resulting in the choice of uninformative priors. In this work, we propose a novel posterior sampling approach in which the prior is given as a (partial) causal graph over the environment's variables. The latter is often more natural to design, such as listing known causal dependencies between biometric features in a medical treatment study. Specifically, we propose a hierarchical Bayesian procedure, called C-PSRL, simultaneously learning the full causal graph at the higher level and the parameters of the resulting factored dynamics at the lower level. For this procedure, we provide an analysis of its Bayesian regret, which explicitly connects the regret rate with the degree of prior knowledge. Our numerica",
    "path": "papers/23/10/2310.07518.json",
    "total_tokens": 860,
    "translated_title": "利用后验采样和因果图先验来提高强化学习的样本效率",
    "translated_abstract": "后验采样允许利用环境转移动态的先验知识，提高强化学习的样本效率。先验通常被指定为环境变量的（部分）因果图，相比实践中麻烦的参数分布类别指定更加自然，例如在医疗治疗研究中列出生物特征之间的已知因果依赖关系。我们提出了一种新颖的后验采样方法，名为C-PSRL，该方法同时学习更高层的完整因果图和更低层导致的分解动态的参数。对于该方法，我们提供了其贝叶斯遗憾的分析，明确地将遗憾率与先验知识程度相关联。",
    "tldr": "本文提出了一种利用因果图先验和后验采样的方法来提高强化学习样本效率。通过同时学习完整的因果图和分解动态参数，该方法能够更自然地设计先验，并且根据先验知识程度连接了遗憾率与贝叶斯遗憾之间的关系。",
    "en_tdlr": "This paper proposes a method that improves sample efficiency in reinforcement learning by exploiting causal graph priors and posterior sampling. The method simultaneously learns the full causal graph and the parameters of the resulting factored dynamics, connecting regret rates with the degree of prior knowledge."
}