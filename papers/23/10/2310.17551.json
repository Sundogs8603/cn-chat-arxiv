{
    "title": "Unpacking the Ethical Value Alignment in Big Models. (arXiv:2310.17551v1 [cs.CY])",
    "abstract": "Big models have greatly advanced AI's ability to understand, generate, and manipulate information and content, enabling numerous applications. However, as these models become increasingly integrated into everyday life, their inherent ethical values and potential biases pose unforeseen risks to society. This paper provides an overview of the risks and challenges associated with big models, surveys existing AI ethics guidelines, and examines the ethical implications arising from the limitations of these models. Taking a normative ethics perspective, we propose a reassessment of recent normative guidelines, highlighting the importance of collaborative efforts in academia to establish a unified and universal AI ethics framework. Furthermore, we investigate the moral inclinations of current mainstream LLMs using the Moral Foundation theory, analyze existing alignment algorithms, and outline the unique challenges encountered in aligning ethical values within them. To address these challenges",
    "link": "http://arxiv.org/abs/2310.17551",
    "context": "Title: Unpacking the Ethical Value Alignment in Big Models. (arXiv:2310.17551v1 [cs.CY])\nAbstract: Big models have greatly advanced AI's ability to understand, generate, and manipulate information and content, enabling numerous applications. However, as these models become increasingly integrated into everyday life, their inherent ethical values and potential biases pose unforeseen risks to society. This paper provides an overview of the risks and challenges associated with big models, surveys existing AI ethics guidelines, and examines the ethical implications arising from the limitations of these models. Taking a normative ethics perspective, we propose a reassessment of recent normative guidelines, highlighting the importance of collaborative efforts in academia to establish a unified and universal AI ethics framework. Furthermore, we investigate the moral inclinations of current mainstream LLMs using the Moral Foundation theory, analyze existing alignment algorithms, and outline the unique challenges encountered in aligning ethical values within them. To address these challenges",
    "path": "papers/23/10/2310.17551.json",
    "total_tokens": 953,
    "translated_title": "解读大模型中的伦理价值对齐问题",
    "translated_abstract": "大型模型极大地提升了人工智能理解、生成和操作信息与内容的能力，并被广泛应用于各个领域。然而，随着这些模型越来越多地融入日常生活，其固有的伦理价值观和潜在偏见给社会带来了未预料的风险。本文概述了与大型模型有关的风险和挑战，调查了现有的人工智能伦理准则，并分析了这些模型的局限性所引发的伦理影响。从规范伦理的角度出发，我们提出了对最近的规范准则进行重新评估的建议，强调了学术界在建立统一和普遍的人工智能伦理框架方面的合作努力的重要性。此外，我们使用道德基础理论调查了当前主流大型语言模型的道德倾向，分析了现有的价值观对齐算法，并概述了在实现伦理价值对齐时遇到的独特挑战。",
    "tldr": "本文探讨了大型模型中的伦理价值对齐问题，调查了现有的人工智能伦理准则，并提出了建立统一和普遍的人工智能伦理框架的重要性。此外，对当前主流大型语言模型的伦理倾向进行了研究，并分析了在实现伦理价值对齐时的挑战。"
}