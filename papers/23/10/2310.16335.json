{
    "title": "Defense Against Model Extraction Attacks on Recommender Systems. (arXiv:2310.16335v1 [cs.LG])",
    "abstract": "The robustness of recommender systems has become a prominent topic within the research community. Numerous adversarial attacks have been proposed, but most of them rely on extensive prior knowledge, such as all the white-box attacks or most of the black-box attacks which assume that certain external knowledge is available. Among these attacks, the model extraction attack stands out as a promising and practical method, involving training a surrogate model by repeatedly querying the target model. However, there is a significant gap in the existing literature when it comes to defending against model extraction attacks on recommender systems. In this paper, we introduce Gradient-based Ranking Optimization (GRO), which is the first defense strategy designed to counter such attacks. We formalize the defense as an optimization problem, aiming to minimize the loss of the protected target model while maximizing the loss of the attacker's surrogate model. Since top-k ranking lists are non-differ",
    "link": "http://arxiv.org/abs/2310.16335",
    "context": "Title: Defense Against Model Extraction Attacks on Recommender Systems. (arXiv:2310.16335v1 [cs.LG])\nAbstract: The robustness of recommender systems has become a prominent topic within the research community. Numerous adversarial attacks have been proposed, but most of them rely on extensive prior knowledge, such as all the white-box attacks or most of the black-box attacks which assume that certain external knowledge is available. Among these attacks, the model extraction attack stands out as a promising and practical method, involving training a surrogate model by repeatedly querying the target model. However, there is a significant gap in the existing literature when it comes to defending against model extraction attacks on recommender systems. In this paper, we introduce Gradient-based Ranking Optimization (GRO), which is the first defense strategy designed to counter such attacks. We formalize the defense as an optimization problem, aiming to minimize the loss of the protected target model while maximizing the loss of the attacker's surrogate model. Since top-k ranking lists are non-differ",
    "path": "papers/23/10/2310.16335.json",
    "total_tokens": 893,
    "translated_title": "防御推荐系统模型抽取攻击",
    "translated_abstract": "推荐系统的鲁棒性已成为研究界的突出问题。已经提出了许多敌对攻击方法，但大多数依赖于广泛的先验知识，如所有的白盒攻击或大部分黑盒攻击都假设某些外部知识可用。在这些攻击中，模型抽取攻击是一种有前景且实用的方法，涉及通过反复查询目标模型来训练代理模型。然而，现有文献在防御推荐系统模型抽取攻击方面存在显著差距。在本文中，我们引入了基于梯度的排序优化（GRO）作为第一个针对此类攻击的防御策略。我们将防御形式化为一个优化问题，旨在最小化受保护的目标模型的损失，同时最大化攻击者的代理模型的损失。由于前k个排序列表是不可微分的，并且问题的复杂度很高。",
    "tldr": "本文引入了基于梯度的排序优化（GRO）作为第一个防御推荐系统模型抽取攻击的策略，最小化受保护的目标模型的损失，同时最大化攻击者的代理模型的损失。",
    "en_tdlr": "This paper introduces Gradient-based Ranking Optimization (GRO) as the first defense strategy against model extraction attacks on recommender systems, aiming to minimize the loss of the protected target model while maximizing the loss of the attacker's surrogate model."
}