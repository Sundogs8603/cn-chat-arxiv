{
    "title": "From Continuous Dynamics to Graph Neural Networks: Neural Diffusion and Beyond. (arXiv:2310.10121v1 [cs.LG])",
    "abstract": "Graph neural networks (GNNs) have demonstrated significant promise in modelling relational data and have been widely applied in various fields of interest. The key mechanism behind GNNs is the so-called message passing where information is being iteratively aggregated to central nodes from their neighbourhood. Such a scheme has been found to be intrinsically linked to a physical process known as heat diffusion, where the propagation of GNNs naturally corresponds to the evolution of heat density. Analogizing the process of message passing to the heat dynamics allows to fundamentally understand the power and pitfalls of GNNs and consequently informs better model design. Recently, there emerges a plethora of works that proposes GNNs inspired from the continuous dynamics formulation, in an attempt to mitigate the known limitations of GNNs, such as oversmoothing and oversquashing. In this survey, we provide the first systematic and comprehensive review of studies that leverage the continuou",
    "link": "http://arxiv.org/abs/2310.10121",
    "context": "Title: From Continuous Dynamics to Graph Neural Networks: Neural Diffusion and Beyond. (arXiv:2310.10121v1 [cs.LG])\nAbstract: Graph neural networks (GNNs) have demonstrated significant promise in modelling relational data and have been widely applied in various fields of interest. The key mechanism behind GNNs is the so-called message passing where information is being iteratively aggregated to central nodes from their neighbourhood. Such a scheme has been found to be intrinsically linked to a physical process known as heat diffusion, where the propagation of GNNs naturally corresponds to the evolution of heat density. Analogizing the process of message passing to the heat dynamics allows to fundamentally understand the power and pitfalls of GNNs and consequently informs better model design. Recently, there emerges a plethora of works that proposes GNNs inspired from the continuous dynamics formulation, in an attempt to mitigate the known limitations of GNNs, such as oversmoothing and oversquashing. In this survey, we provide the first systematic and comprehensive review of studies that leverage the continuou",
    "path": "papers/23/10/2310.10121.json",
    "total_tokens": 837,
    "translated_title": "从连续动力学到图神经网络：神经扩散与更多",
    "translated_abstract": "图神经网络（GNN）在建模关系数据方面表现出显著的潜力，并在各个领域得到广泛应用。GNN背后的关键机制是所谓的消息传递，它通过从邻居节点中集中地聚合信息来进行迭代。这种方案与称为热传导的物理过程密切相关，其中GNN的传播自然对应于热密度的演化。将消息传递过程类比为热动力学可以从根本上理解GNN的能力和缺陷，从而有助于更好地设计模型。最近出现了大量旨在减轻GNN已知限制（如过度平滑和过度压缩）的GNN提出作品，这些作品受到连续动力学的启发。在本综述中，我们首次系统全面地回顾了利用连续动力学框架的研究。",
    "tldr": "本综述系统全面地回顾了利用连续动力学框架的图神经网络，以帮助从根本上理解和改进GNN的能力和缺陷。",
    "en_tdlr": "This survey provides a systematic and comprehensive review of graph neural networks that leverage the continuous dynamics framework, aiming to fundamentally understand and improve their capabilities and limitations."
}