{
    "title": "What Makes it Ok to Set a Fire? Iterative Self-distillation of Contexts and Rationales for Disambiguating Defeasible Social and Moral Situations. (arXiv:2310.15431v1 [cs.CL])",
    "abstract": "Moral or ethical judgments rely heavily on the specific contexts in which they occur. Understanding varying shades of defeasible contextualizations (i.e., additional information that strengthens or attenuates the moral acceptability of an action) is critical to accurately represent the subtlety and intricacy of grounded human moral judgment in real-life scenarios.  We introduce defeasible moral reasoning: a task to provide grounded contexts that make an action more or less morally acceptable, along with commonsense rationales that justify the reasoning. To elicit high-quality task data, we take an iterative self-distillation approach that starts from a small amount of unstructured seed knowledge from GPT-3 and then alternates between (1) self-distillation from student models; (2) targeted filtering with a critic model trained by human judgment (to boost validity) and NLI (to boost diversity); (3) self-imitation learning (to amplify the desired data quality). This process yields a stude",
    "link": "http://arxiv.org/abs/2310.15431",
    "context": "Title: What Makes it Ok to Set a Fire? Iterative Self-distillation of Contexts and Rationales for Disambiguating Defeasible Social and Moral Situations. (arXiv:2310.15431v1 [cs.CL])\nAbstract: Moral or ethical judgments rely heavily on the specific contexts in which they occur. Understanding varying shades of defeasible contextualizations (i.e., additional information that strengthens or attenuates the moral acceptability of an action) is critical to accurately represent the subtlety and intricacy of grounded human moral judgment in real-life scenarios.  We introduce defeasible moral reasoning: a task to provide grounded contexts that make an action more or less morally acceptable, along with commonsense rationales that justify the reasoning. To elicit high-quality task data, we take an iterative self-distillation approach that starts from a small amount of unstructured seed knowledge from GPT-3 and then alternates between (1) self-distillation from student models; (2) targeted filtering with a critic model trained by human judgment (to boost validity) and NLI (to boost diversity); (3) self-imitation learning (to amplify the desired data quality). This process yields a stude",
    "path": "papers/23/10/2310.15431.json",
    "total_tokens": 984,
    "translated_title": "什么情况下纵火是可以接受的？通过迭代自蒸馏情境和原因来消除模糊的社会和道德情境。",
    "translated_abstract": "道德或伦理判断在很大程度上依赖于其发生的具体背景。理解易推翻的情境化变化（即增强或减弱一个行为的道德可接受性的额外信息）对于准确呈现现实场景中凝固的人类道德判断的微妙和复杂性非常重要。我们引入了易推翻的道德推理：一项任务，提供使行为在道德上更可接受或不可接受的情境，以及证明推理的常识理由。为了获取高质量的任务数据，我们采用了迭代自蒸馏的方法，从GPT-3的一小部分非结构化种子知识开始，然后在学生模型和批判者模型之间交替进行（1）自蒸馏；（2）通过人类判断进行有针对性的过滤（以提高有效性）和NLI（以提高多样性）；（3）自模仿学习（以放大所需数据质量）。这个过程产生了一个学生模型。",
    "tldr": "本研究提出了易推翻的道德推理任务，以了解不同背景下行为的道德可接受性，并提供常识理由来支持推理。通过迭代的自蒸馏方法，我们获得了高质量的任务数据。",
    "en_tdlr": "This paper introduces the task of defeasible moral reasoning to understand the moral acceptability of actions in different contexts, providing commonsense justifications for the reasoning. Through iterative self-distillation, high-quality task data is obtained."
}