{
    "title": "Configuration Validation with Large Language Models",
    "abstract": "arXiv:2310.09690v2 Announce Type: replace-cross  Abstract: Misconfigurations are major causes of software failures. Existing practices rely on developer-written rules or test cases to validate configurations, which are expensive. Machine learning (ML) for configuration validation is considered a promising direction, but has been facing challenges such as the need of large-scale field data and system-specific models. Recent advances in Large Language Models (LLMs) show promise in addressing some of the long-lasting limitations of ML-based configuration validation. We present a first analysis on the feasibility and effectiveness of using LLMs for configuration validation. We empirically evaluate LLMs as configuration validators by developing a generic LLM-based configuration validation framework, named Ciri. Ciri employs effective prompt engineering with few-shot learning based on both valid configuration and misconfiguration data. Ciri checks outputs from LLMs when producing results, ad",
    "link": "https://arxiv.org/abs/2310.09690",
    "context": "Title: Configuration Validation with Large Language Models\nAbstract: arXiv:2310.09690v2 Announce Type: replace-cross  Abstract: Misconfigurations are major causes of software failures. Existing practices rely on developer-written rules or test cases to validate configurations, which are expensive. Machine learning (ML) for configuration validation is considered a promising direction, but has been facing challenges such as the need of large-scale field data and system-specific models. Recent advances in Large Language Models (LLMs) show promise in addressing some of the long-lasting limitations of ML-based configuration validation. We present a first analysis on the feasibility and effectiveness of using LLMs for configuration validation. We empirically evaluate LLMs as configuration validators by developing a generic LLM-based configuration validation framework, named Ciri. Ciri employs effective prompt engineering with few-shot learning based on both valid configuration and misconfiguration data. Ciri checks outputs from LLMs when producing results, ad",
    "path": "papers/23/10/2310.09690.json",
    "total_tokens": 766,
    "translated_title": "使用大型语言模型进行配置验证",
    "translated_abstract": "配置不当是软件故障的主要原因之一。现有实践依赖于开发人员编写的规则或测试用例来验证配置，这是昂贵的。配置验证的机器学习(ML)被认为是一个有前途的方向，但面临诸如需要大规模的现场数据和特定于系统的模型等挑战。大型语言模型(LLMs)的最新进展显示了在解决基于ML的配置验证长期限制方面的一些希望。我们首次分析了使用LLMs进行配置验证的可行性和有效性。我们通过开发一个名为Ciri的通用基于LLM的配置验证框架，以经验性评估LLMs作为配置验证器。Ciri利用有效的提示工程，基于有效配置和误配置数据进行少次学习。当生成结果时，Ciri检查LLM的输出。",
    "tldr": "大型语言模型在配置验证中的应用具有可行性和有效性，通过开发一个名为Ciri的通用基于LLM的配置验证框架进行了实证评估。",
    "en_tdlr": "The application of Large Language Models in configuration validation shows feasibility and effectiveness, empirically evaluated through the development of a generic LLM-based configuration validation framework named Ciri."
}