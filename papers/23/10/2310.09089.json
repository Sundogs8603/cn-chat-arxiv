{
    "title": "Qilin-Med: Multi-stage Knowledge Injection Advanced Medical Large Language Model. (arXiv:2310.09089v1 [cs.CL])",
    "abstract": "Integrating large language models (LLMs) into healthcare presents potential but faces challenges. Directly pre-training LLMs for domains like medicine is resource-heavy and sometimes unfeasible. Sole reliance on Supervised Fine-tuning (SFT) can result in overconfident predictions and may not tap into domain specific insights. Addressing these challenges, we present a multi-stage training method combining Domain-specific Continued Pre-training (DCPT), SFT, and Direct Preference Optimization (DPO). A notable contribution of our study is the introduction of a 3Gb Chinese Medicine (ChiMed) dataset, encompassing medical question answering, plain texts, knowledge graphs, and dialogues, segmented into three training stages. The medical LLM trained with our pipeline, Qilin-Med, exhibits significant performance boosts. In the CPT and SFT phases, it achieves 38.4% and 40.0% accuracy on the CMExam, surpassing Baichuan-7B's 33.5%. In the DPO phase, on the Huatuo-26M test set, it scores 16.66 in BL",
    "link": "http://arxiv.org/abs/2310.09089",
    "context": "Title: Qilin-Med: Multi-stage Knowledge Injection Advanced Medical Large Language Model. (arXiv:2310.09089v1 [cs.CL])\nAbstract: Integrating large language models (LLMs) into healthcare presents potential but faces challenges. Directly pre-training LLMs for domains like medicine is resource-heavy and sometimes unfeasible. Sole reliance on Supervised Fine-tuning (SFT) can result in overconfident predictions and may not tap into domain specific insights. Addressing these challenges, we present a multi-stage training method combining Domain-specific Continued Pre-training (DCPT), SFT, and Direct Preference Optimization (DPO). A notable contribution of our study is the introduction of a 3Gb Chinese Medicine (ChiMed) dataset, encompassing medical question answering, plain texts, knowledge graphs, and dialogues, segmented into three training stages. The medical LLM trained with our pipeline, Qilin-Med, exhibits significant performance boosts. In the CPT and SFT phases, it achieves 38.4% and 40.0% accuracy on the CMExam, surpassing Baichuan-7B's 33.5%. In the DPO phase, on the Huatuo-26M test set, it scores 16.66 in BL",
    "path": "papers/23/10/2310.09089.json",
    "total_tokens": 984,
    "translated_title": "Qilin-Med: 多阶段知识注入先进的医疗大型语言模型",
    "translated_abstract": "将大型语言模型 (LLMs) 应用于医疗领域有着潜力但也面临挑战。直接为像医学这样的领域进行预训练需要大量资源，有时不可行。仅依赖于监督微调 (SFT) 可能导致过于自信的预测结果，无法利用领域特定的见解。为了解决这些问题，我们提出了一种多阶段训练方法，结合了领域特定继续预训练 (DCPT)、SFT 和直接偏好优化 (DPO)。我们研究的一个显著贡献是引入了一个 3Gb 的中医数据集 (ChiMed)，包括医学问答、纯文本、知识图谱和对话，分为三个训练阶段。我们使用我们的训练流程训练的医学LLM，Qilin-Med，在CPT和SFT阶段在CMExam上分别达到了38.4%和40.0%的准确率，超过了Baichuan-7B的33.5%。在DPO阶段，在Huatuo-26M测试集上得分为16.66。",
    "tldr": "Qilin-Med是一个多阶段训练的医疗大型语言模型，通过结合领域特定继续预训练、监督微调和直接偏好优化的方法，实现了显著的性能提升，并引入了一个包含医学问答、纯文本、知识图谱和对话的3Gb中医数据集。"
}