{
    "title": "Enhancing Large Language Models for Secure Code Generation: A Dataset-driven Study on Vulnerability Mitigation. (arXiv:2310.16263v1 [cs.SE])",
    "abstract": "Large language models (LLMs) have brought significant advancements to code generation, benefiting both novice and experienced developers. However, their training using unsanitized data from open-source repositories, like GitHub, introduces the risk of inadvertently propagating security vulnerabilities. To effectively mitigate this concern, this paper presents a comprehensive study focused on evaluating and enhancing code LLMs from a software security perspective. We introduce SecuCoGen\\footnote{SecuCoGen has been uploaded as supplemental material and will be made publicly available after publication.}, a meticulously curated dataset targeting 21 critical vulnerability types. SecuCoGen comprises 180 samples and serves as the foundation for conducting experiments on three crucial code-related tasks: code generation, code repair and vulnerability classification, with a strong emphasis on security. Our experimental results reveal that existing models often overlook security concerns during",
    "link": "http://arxiv.org/abs/2310.16263",
    "context": "Title: Enhancing Large Language Models for Secure Code Generation: A Dataset-driven Study on Vulnerability Mitigation. (arXiv:2310.16263v1 [cs.SE])\nAbstract: Large language models (LLMs) have brought significant advancements to code generation, benefiting both novice and experienced developers. However, their training using unsanitized data from open-source repositories, like GitHub, introduces the risk of inadvertently propagating security vulnerabilities. To effectively mitigate this concern, this paper presents a comprehensive study focused on evaluating and enhancing code LLMs from a software security perspective. We introduce SecuCoGen\\footnote{SecuCoGen has been uploaded as supplemental material and will be made publicly available after publication.}, a meticulously curated dataset targeting 21 critical vulnerability types. SecuCoGen comprises 180 samples and serves as the foundation for conducting experiments on three crucial code-related tasks: code generation, code repair and vulnerability classification, with a strong emphasis on security. Our experimental results reveal that existing models often overlook security concerns during",
    "path": "papers/23/10/2310.16263.json",
    "total_tokens": 915,
    "translated_title": "提升大规模语言模型用于安全代码生成：基于数据集驱动的漏洞缓解研究",
    "translated_abstract": "大规模语言模型（LLMs）对代码生成带来了显著的进展，既有利于新手开发人员，也有利于经验丰富的开发人员。然而，它们使用来自开源仓库（如GitHub）的未经消毒的数据进行训练，会引入意外传播安全漏洞的风险。为了有效缓解这个问题，本文从软件安全的角度进行了一项综合研究，旨在评估和增强代码LLMs。我们引入了SecuCoGen，一个精心策划的数据集，针对21种关键漏洞类型。SecuCoGen包含180个样本，并作为进行三个关键的与代码相关任务的实验的基础：代码生成、代码修复和漏洞分类，其中安全性得到了极大的强调。我们的实验结果表明，现有模型在处理安全问题时经常被忽视了。",
    "tldr": "本文介绍了一项针对安全代码生成的综合研究，通过使用经过策划的数据集评估和增强代码大规模语言模型（LLMs），有效解决了使用未经消毒的开源数据训练模型引入安全漏洞的风险。实验结果显示现有模型在安全方面常常被忽视。"
}