{
    "title": "Improving Question Generation with Multi-level Content Planning. (arXiv:2310.13512v1 [cs.CL])",
    "abstract": "This paper addresses the problem of generating questions from a given context and an answer, specifically focusing on questions that require multi-hop reasoning across an extended context. Previous studies have suggested that key phrase selection is essential for question generation (QG), yet it is still challenging to connect such disjointed phrases into meaningful questions, particularly for long context. To mitigate this issue, we propose MultiFactor, a novel QG framework based on multi-level content planning. Specifically, MultiFactor includes two components: FA-model, which simultaneously selects key phrases and generates full answers, and Q-model which takes the generated full answer as an additional input to generate questions. Here, full answer generation is introduced to connect the short answer with the selected key phrases, thus forming an answer-aware summary to facilitate QG. Both FA-model and Q-model are formalized as simple-yet-effective Phrase-Enhanced Transformers, our",
    "link": "http://arxiv.org/abs/2310.13512",
    "context": "Title: Improving Question Generation with Multi-level Content Planning. (arXiv:2310.13512v1 [cs.CL])\nAbstract: This paper addresses the problem of generating questions from a given context and an answer, specifically focusing on questions that require multi-hop reasoning across an extended context. Previous studies have suggested that key phrase selection is essential for question generation (QG), yet it is still challenging to connect such disjointed phrases into meaningful questions, particularly for long context. To mitigate this issue, we propose MultiFactor, a novel QG framework based on multi-level content planning. Specifically, MultiFactor includes two components: FA-model, which simultaneously selects key phrases and generates full answers, and Q-model which takes the generated full answer as an additional input to generate questions. Here, full answer generation is introduced to connect the short answer with the selected key phrases, thus forming an answer-aware summary to facilitate QG. Both FA-model and Q-model are formalized as simple-yet-effective Phrase-Enhanced Transformers, our",
    "path": "papers/23/10/2310.13512.json",
    "total_tokens": 848,
    "translated_abstract": "本文针对从给定的背景和答案生成问题的问题进行探讨，特别关注需要在扩展背景中进行多跳推理的问题。先前的研究表明关键词选择对于问题生成(QG)至关重要，然而将这些不连贯的关键词连接成有意义的问题仍然具有挑战性，尤其是对于长背景来说。为了缓解这个问题，我们提出了一种基于多级内容规划的新型QG框架——MultiFactor。具体而言，MultiFactor包括两个部分：FA模型，同时选择关键词和生成完整答案；Q模型，以生成的完整答案作为额外输入来生成问题。这里，引入完整答案生成来连接简短答案和选择的关键词，从而形成一个问题意识摘要，促进QG。FA模型和Q模型都被形式化为简单而有效的Phrase-Enhanced Transformers，我们的模型。",
    "tldr": "本文提出了一种基于多级内容规划的新型问题生成框架MultiFactor，该框架通过引入完整答案生成来连接关键词，并形成问题意识摘要，促进问题生成。模型使用简单而有效的Phrase-Enhanced Transformers。"
}