{
    "title": "How does prompt engineering affect ChatGPT performance on unsupervised entity resolution?. (arXiv:2310.06174v1 [cs.AI])",
    "abstract": "Entity Resolution (ER) is the problem of semi-automatically determining when two entities refer to the same underlying entity, with applications ranging from healthcare to e-commerce. Traditional ER solutions required considerable manual expertise, including feature engineering, as well as identification and curation of training data. In many instances, such techniques are highly dependent on the domain. With recent advent in large language models (LLMs), there is an opportunity to make ER much more seamless and domain-independent. However, it is also well known that LLMs can pose risks, and that the quality of their outputs can depend on so-called prompt engineering. Unfortunately, a systematic experimental study on the effects of different prompting methods for addressing ER, using LLMs like ChatGPT, has been lacking thus far. This paper aims to address this gap by conducting such a study. Although preliminary in nature, our results show that prompting can significantly affect the qu",
    "link": "http://arxiv.org/abs/2310.06174",
    "context": "Title: How does prompt engineering affect ChatGPT performance on unsupervised entity resolution?. (arXiv:2310.06174v1 [cs.AI])\nAbstract: Entity Resolution (ER) is the problem of semi-automatically determining when two entities refer to the same underlying entity, with applications ranging from healthcare to e-commerce. Traditional ER solutions required considerable manual expertise, including feature engineering, as well as identification and curation of training data. In many instances, such techniques are highly dependent on the domain. With recent advent in large language models (LLMs), there is an opportunity to make ER much more seamless and domain-independent. However, it is also well known that LLMs can pose risks, and that the quality of their outputs can depend on so-called prompt engineering. Unfortunately, a systematic experimental study on the effects of different prompting methods for addressing ER, using LLMs like ChatGPT, has been lacking thus far. This paper aims to address this gap by conducting such a study. Although preliminary in nature, our results show that prompting can significantly affect the qu",
    "path": "papers/23/10/2310.06174.json",
    "total_tokens": 897,
    "translated_title": "提示工程对ChatGPT在无监督实体解析中的性能影响是如何的？",
    "translated_abstract": "实体解析（ER）是一种半自动确定两个实体是否指向相同基础实体的问题，应用范围从医疗保健到电子商务。传统的ER解决方案需要相当多的手动专业知识，包括特征工程以及训练数据的识别和策划。在许多情况下，这些技术高度依赖于领域。随着大型语言模型（LLMs）的最新发展，有机会使ER更加无缝和领域无关。然而，众所周知，LLMs可能存在风险，其输出质量可能取决于所谓的提示工程。不幸的是，迄今为止，关于使用像ChatGPT这样的LLMs解决ER的不同提示方法的影响的系统实验研究还缺乏。本文旨在填补这一空白，通过进行这样一项研究。尽管这只是初步性质的研究，我们的结果表明，提示可以显著影响实体解析的质量。",
    "tldr": "本研究对提示工程对ChatGPT在无监督实体解析中的影响进行了初步实验研究，结果显示提示可以显著影响实体解析的质量。"
}