{
    "title": "Randomized Dimension Reduction with Statistical Guarantees. (arXiv:2310.01739v1 [cs.LG])",
    "abstract": "Large models and enormous data are essential driving forces of the unprecedented successes achieved by modern algorithms, especially in scientific computing and machine learning. Nevertheless, the growing dimensionality and model complexity, as well as the non-negligible workload of data pre-processing, also bring formidable costs to such successes in both computation and data aggregation. As the deceleration of Moore's Law slackens the cost reduction of computation from the hardware level, fast heuristics for expensive classical routines and efficient algorithms for exploiting limited data are increasingly indispensable for pushing the limit of algorithm potency. This thesis explores some of such algorithms for fast execution and efficient data utilization.  From the computational efficiency perspective, we design and analyze fast randomized low-rank decomposition algorithms for large matrices based on \"matrix sketching\", which can be regarded as a dimension reduction strategy in the ",
    "link": "http://arxiv.org/abs/2310.01739",
    "context": "Title: Randomized Dimension Reduction with Statistical Guarantees. (arXiv:2310.01739v1 [cs.LG])\nAbstract: Large models and enormous data are essential driving forces of the unprecedented successes achieved by modern algorithms, especially in scientific computing and machine learning. Nevertheless, the growing dimensionality and model complexity, as well as the non-negligible workload of data pre-processing, also bring formidable costs to such successes in both computation and data aggregation. As the deceleration of Moore's Law slackens the cost reduction of computation from the hardware level, fast heuristics for expensive classical routines and efficient algorithms for exploiting limited data are increasingly indispensable for pushing the limit of algorithm potency. This thesis explores some of such algorithms for fast execution and efficient data utilization.  From the computational efficiency perspective, we design and analyze fast randomized low-rank decomposition algorithms for large matrices based on \"matrix sketching\", which can be regarded as a dimension reduction strategy in the ",
    "path": "papers/23/10/2310.01739.json",
    "total_tokens": 828,
    "translated_title": "具有统计保证的随机维度降低",
    "translated_abstract": "大型模型和庞大数据是现代算法取得前所未有成功的关键驱动力，尤其是在科学计算和机器学习领域。然而，不断增长的维度和模型复杂性以及数据预处理的工作量也给计算和数据聚合带来了巨大的成本。随着摩尔定律放缓导致计算成本从硬件层面降低的减速，快速大型经典例程的启发式算法和利用有限数据的高效算法对于推动算法潜力的极限变得越来越不可或缺。本论文探索了一些快速执行和高效利用数据的算法。从计算效率的角度出发，我们设计和分析了基于“矩阵抽样”的大型矩阵的快速随机低秩分解算法，该算法可以被视为一种维度降低策略。",
    "tldr": "本论文提出了一种基于“矩阵抽样”的快速随机低秩分解算法，用于大型矩阵的维度降低，从而提高计算效率和数据利用率。"
}