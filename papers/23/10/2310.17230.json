{
    "title": "Codebook Features: Sparse and Discrete Interpretability for Neural Networks. (arXiv:2310.17230v1 [cs.LG])",
    "abstract": "Understanding neural networks is challenging in part because of the dense, continuous nature of their hidden states. We explore whether we can train neural networks to have hidden states that are sparse, discrete, and more interpretable by quantizing their continuous features into what we call codebook features. Codebook features are produced by finetuning neural networks with vector quantization bottlenecks at each layer, producing a network whose hidden features are the sum of a small number of discrete vector codes chosen from a larger codebook. Surprisingly, we find that neural networks can operate under this extreme bottleneck with only modest degradation in performance. This sparse, discrete bottleneck also provides an intuitive way of controlling neural network behavior: first, find codes that activate when the desired behavior is present, then activate those same codes during generation to elicit that behavior. We validate our approach by training codebook Transformers on sever",
    "link": "http://arxiv.org/abs/2310.17230",
    "context": "Title: Codebook Features: Sparse and Discrete Interpretability for Neural Networks. (arXiv:2310.17230v1 [cs.LG])\nAbstract: Understanding neural networks is challenging in part because of the dense, continuous nature of their hidden states. We explore whether we can train neural networks to have hidden states that are sparse, discrete, and more interpretable by quantizing their continuous features into what we call codebook features. Codebook features are produced by finetuning neural networks with vector quantization bottlenecks at each layer, producing a network whose hidden features are the sum of a small number of discrete vector codes chosen from a larger codebook. Surprisingly, we find that neural networks can operate under this extreme bottleneck with only modest degradation in performance. This sparse, discrete bottleneck also provides an intuitive way of controlling neural network behavior: first, find codes that activate when the desired behavior is present, then activate those same codes during generation to elicit that behavior. We validate our approach by training codebook Transformers on sever",
    "path": "papers/23/10/2310.17230.json",
    "total_tokens": 951,
    "translated_title": "Codebook特征：神经网络的稀疏和离散可解释性",
    "translated_abstract": "理解神经网络是具有挑战性的，部分原因是由于它们的隐藏状态是密集和连续的。我们探讨了是否可以通过将连续特征量化为我们称之为codebook特征来训练神经网络，使其具有稀疏、离散且更易解释的隐藏状态。通过在每层引入向量量化瓶颈来微调神经网络，产生的codebook特征由从更大的codebook中选择的少量离散向量码的总和组成。令人惊讶的是，我们发现神经网络可以在这种极端瓶颈下运行，性能只有适度的下降。这种稀疏、离散的瓶颈还提供了一种直观的控制神经网络行为的方法：首先，找到在所需行为出现时激活的码，然后在生成过程中激活相同的码以引发该行为。我们通过训练codebook Transformers验证了我们的方法。",
    "tldr": "本研究提出了一种称为codebook特征的方法，通过将神经网络的连续特征量化为离散向量码的总和来实现稀疏和离散的隐藏状态。实验证明，神经网络在这种极端瓶颈条件下运行时性能下降适度，同时这种方法还提供了一种直观的神经网络行为控制方式。",
    "en_tdlr": "This study proposes a method called codebook features, which achieves sparse and discrete hidden states in neural networks by quantizing their continuous features into the sum of discrete vector codes. Experimental results show that neural networks perform with only modest degradation under this extreme bottleneck, and this method also provides an intuitive way of controlling neural network behavior."
}