{
    "title": "Fair Streaming Principal Component Analysis: Statistical and Algorithmic Viewpoint. (arXiv:2310.18593v1 [stat.ML])",
    "abstract": "Fair Principal Component Analysis (PCA) is a problem setting where we aim to perform PCA while making the resulting representation fair in that the projected distributions, conditional on the sensitive attributes, match one another. However, existing approaches to fair PCA have two main problems: theoretically, there has been no statistical foundation of fair PCA in terms of learnability; practically, limited memory prevents us from using existing approaches, as they explicitly rely on full access to the entire data. On the theoretical side, we rigorously formulate fair PCA using a new notion called \\emph{probably approximately fair and optimal} (PAFO) learnability. On the practical side, motivated by recent advances in streaming algorithms for addressing memory limitation, we propose a new setting called \\emph{fair streaming PCA} along with a memory-efficient algorithm, fair noisy power method (FNPM). We then provide its {\\it statistical} guarantee in terms of PAFO-learnability, which",
    "link": "http://arxiv.org/abs/2310.18593",
    "context": "Title: Fair Streaming Principal Component Analysis: Statistical and Algorithmic Viewpoint. (arXiv:2310.18593v1 [stat.ML])\nAbstract: Fair Principal Component Analysis (PCA) is a problem setting where we aim to perform PCA while making the resulting representation fair in that the projected distributions, conditional on the sensitive attributes, match one another. However, existing approaches to fair PCA have two main problems: theoretically, there has been no statistical foundation of fair PCA in terms of learnability; practically, limited memory prevents us from using existing approaches, as they explicitly rely on full access to the entire data. On the theoretical side, we rigorously formulate fair PCA using a new notion called \\emph{probably approximately fair and optimal} (PAFO) learnability. On the practical side, motivated by recent advances in streaming algorithms for addressing memory limitation, we propose a new setting called \\emph{fair streaming PCA} along with a memory-efficient algorithm, fair noisy power method (FNPM). We then provide its {\\it statistical} guarantee in terms of PAFO-learnability, which",
    "path": "papers/23/10/2310.18593.json",
    "total_tokens": 831,
    "translated_title": "公平的流式主成分分析：统计学和算法视角",
    "translated_abstract": "公平主成分分析（PCA）是一个问题设置，我们的目标是在执行PCA的同时使得得到的表示公平，即在敏感属性条件下，投影分布相匹配。然而，现有的公平PCA方法存在两个主要问题：从理论上讲，没有以可学习性为基础的公平PCA统计学依据；从实践上讲，有限的内存使得我们无法使用现有方法，因为它们明确依赖于对整个数据的完全访问。在理论方面，我们使用一种称为“可能近似公平和最优”（PAFO）可学习性的新概念，严格地制定了公平PCA。在实践方面，受到解决内存限制的流式算法的最新进展的启发，我们提出了一个新的设置，称为“公平流式PCA”，以及一个内存高效的算法，公平噪声功率方法（FNPM）。然后，我们提供了其在PAFO可学习性方面的统计保证。",
    "tldr": "该论文提出了公平流式主成分分析（PCA）算法，并且在理论和实践上解决了公平PCA的两个主要问题。"
}