{
    "title": "An evaluation of pre-trained models for feature extraction in image classification. (arXiv:2310.02037v1 [cs.CV])",
    "abstract": "In recent years, we have witnessed a considerable increase in performance in image classification tasks. This performance improvement is mainly due to the adoption of deep learning techniques. Generally, deep learning techniques demand a large set of annotated data, making it a challenge when applying it to small datasets. In this scenario, transfer learning strategies have become a promising alternative to overcome these issues. This work aims to compare the performance of different pre-trained neural networks for feature extraction in image classification tasks. We evaluated 16 different pre-trained models in four image datasets. Our results demonstrate that the best general performance along the datasets was achieved by CLIP-ViT-B and ViT-H-14, where the CLIP-ResNet50 model had similar performance but with less variability. Therefore, our study provides evidence supporting the choice of models for feature extraction in image classification tasks.",
    "link": "http://arxiv.org/abs/2310.02037",
    "context": "Title: An evaluation of pre-trained models for feature extraction in image classification. (arXiv:2310.02037v1 [cs.CV])\nAbstract: In recent years, we have witnessed a considerable increase in performance in image classification tasks. This performance improvement is mainly due to the adoption of deep learning techniques. Generally, deep learning techniques demand a large set of annotated data, making it a challenge when applying it to small datasets. In this scenario, transfer learning strategies have become a promising alternative to overcome these issues. This work aims to compare the performance of different pre-trained neural networks for feature extraction in image classification tasks. We evaluated 16 different pre-trained models in four image datasets. Our results demonstrate that the best general performance along the datasets was achieved by CLIP-ViT-B and ViT-H-14, where the CLIP-ResNet50 model had similar performance but with less variability. Therefore, our study provides evidence supporting the choice of models for feature extraction in image classification tasks.",
    "path": "papers/23/10/2310.02037.json",
    "total_tokens": 910,
    "translated_title": "对预训练模型在图像分类中特征提取的评估",
    "translated_abstract": "近年来，图像分类任务的性能有了显著提高，这主要归功于深度学习技术的采用。然而，深度学习技术通常需要大量标注数据，这对于小数据集来说是一个挑战。在这种情况下，迁移学习策略成为了克服这些问题的一种有希望的选择。本研究旨在比较不同预训练神经网络在图像分类任务中特征提取方面的性能。我们在四个图像数据集上评估了16种不同的预训练模型。研究结果表明，在数据集中取得了最佳的整体性能的是CLIP-ViT-B和ViT-H-14，而CLIP-ResNet50模型的性能与之类似但变动较小。因此，我们的研究为在图像分类任务中选择模型进行特征提取提供了证据支持。",
    "tldr": "本研究评估了不同预训练神经网络在图像分类任务中特征提取的性能，并发现CLIP-ViT-B和ViT-H-14等模型具有最佳的整体性能，CLIP-ResNet50模型具有类似性能但变动较小。这为在图像分类任务中选择模型进行特征提取提供了支持。"
}