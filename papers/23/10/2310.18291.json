{
    "title": "Addressing GAN Training Instabilities via Tunable Classification Losses. (arXiv:2310.18291v1 [cs.LG])",
    "abstract": "Generative adversarial networks (GANs), modeled as a zero-sum game between a generator (G) and a discriminator (D), allow generating synthetic data with formal guarantees. Noting that D is a classifier, we begin by reformulating the GAN value function using class probability estimation (CPE) losses. We prove a two-way correspondence between CPE loss GANs and $f$-GANs which minimize $f$-divergences. We also show that all symmetric $f$-divergences are equivalent in convergence. In the finite sample and model capacity setting, we define and obtain bounds on estimation and generalization errors. We specialize these results to $\\alpha$-GANs, defined using $\\alpha$-loss, a tunable CPE loss family parametrized by $\\alpha\\in(0,\\infty]$. We next introduce a class of dual-objective GANs to address training instabilities of GANs by modeling each player's objective using $\\alpha$-loss to obtain $(\\alpha_D,\\alpha_G)$-GANs. We show that the resulting non-zero sum game simplifies to minimizing an $f$",
    "link": "http://arxiv.org/abs/2310.18291",
    "context": "Title: Addressing GAN Training Instabilities via Tunable Classification Losses. (arXiv:2310.18291v1 [cs.LG])\nAbstract: Generative adversarial networks (GANs), modeled as a zero-sum game between a generator (G) and a discriminator (D), allow generating synthetic data with formal guarantees. Noting that D is a classifier, we begin by reformulating the GAN value function using class probability estimation (CPE) losses. We prove a two-way correspondence between CPE loss GANs and $f$-GANs which minimize $f$-divergences. We also show that all symmetric $f$-divergences are equivalent in convergence. In the finite sample and model capacity setting, we define and obtain bounds on estimation and generalization errors. We specialize these results to $\\alpha$-GANs, defined using $\\alpha$-loss, a tunable CPE loss family parametrized by $\\alpha\\in(0,\\infty]$. We next introduce a class of dual-objective GANs to address training instabilities of GANs by modeling each player's objective using $\\alpha$-loss to obtain $(\\alpha_D,\\alpha_G)$-GANs. We show that the resulting non-zero sum game simplifies to minimizing an $f$",
    "path": "papers/23/10/2310.18291.json",
    "total_tokens": 932,
    "translated_title": "通过可调的分类损失解决 GAN 训练不稳定性问题",
    "translated_abstract": "生成对抗网络（GAN）作为生成器（G）和鉴别器（D）之间的零和博弈模型，允许以形式保证生成合成数据。我们通过使用类概率估计（CPE）损失来重新定义GAN的价值函数。我们证明了CPE损失GAN和最小化f-散度的f-GAN之间存在双向对应关系。我们还证明了所有对称f-散度在收敛性上等价。在有限样本和模型容量设定下，我们定义并获得了关于估计和泛化误差的界限。我们将这些结果特化到使用α-loss定义的α-GAN，它是一个由α（0，∞]参数化的可调CPE损失的家族。然后，我们引入了一类双目标GAN来解决GAN的训练不稳定性问题，通过使用α-loss来对每个玩家的目标建模，以获得(α_D，α_G)-GAN。我们证明了产生的非零和游戏简化为最小化f-散度的形式。",
    "tldr": "该论文通过使用可调的分类损失解决了GAN训练不稳定性问题，并证明了CPE损失GAN和最小化f-散度的f-GAN之间的双向对应关系。",
    "en_tdlr": "This paper addresses GAN training instabilities by using tunable classification losses, and it proves a two-way correspondence between CPE loss GANs and f-GANs which minimize f-divergences."
}