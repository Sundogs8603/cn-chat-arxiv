{
    "title": "Multi-modal Medical Neurological Image Fusion using Wavelet Pooled Edge Preserving Autoencoder. (arXiv:2310.11910v1 [eess.IV])",
    "abstract": "Medical image fusion integrates the complementary diagnostic information of the source image modalities for improved visualization and analysis of underlying anomalies. Recently, deep learning-based models have excelled the conventional fusion methods by executing feature extraction, feature selection, and feature fusion tasks, simultaneously. However, most of the existing convolutional neural network (CNN) architectures use conventional pooling or strided convolutional strategies to downsample the feature maps. It causes the blurring or loss of important diagnostic information and edge details available in the source images and dilutes the efficacy of the feature extraction process. Therefore, this paper presents an end-to-end unsupervised fusion model for multimodal medical images based on an edge-preserving dense autoencoder network. In the proposed model, feature extraction is improved by using wavelet decomposition-based attention pooling of feature maps. This helps in preserving ",
    "link": "http://arxiv.org/abs/2310.11910",
    "context": "Title: Multi-modal Medical Neurological Image Fusion using Wavelet Pooled Edge Preserving Autoencoder. (arXiv:2310.11910v1 [eess.IV])\nAbstract: Medical image fusion integrates the complementary diagnostic information of the source image modalities for improved visualization and analysis of underlying anomalies. Recently, deep learning-based models have excelled the conventional fusion methods by executing feature extraction, feature selection, and feature fusion tasks, simultaneously. However, most of the existing convolutional neural network (CNN) architectures use conventional pooling or strided convolutional strategies to downsample the feature maps. It causes the blurring or loss of important diagnostic information and edge details available in the source images and dilutes the efficacy of the feature extraction process. Therefore, this paper presents an end-to-end unsupervised fusion model for multimodal medical images based on an edge-preserving dense autoencoder network. In the proposed model, feature extraction is improved by using wavelet decomposition-based attention pooling of feature maps. This helps in preserving ",
    "path": "papers/23/10/2310.11910.json",
    "total_tokens": 847,
    "translated_title": "使用小波池化边缘保留自编码器进行多模式医学神经图像融合",
    "translated_abstract": "医学图像融合整合了源图像模态的互补诊断信息，以改善对潜在异常的可视化和分析。最近，基于深度学习的模型通过同时执行特征提取、特征选择和特征融合任务，胜过传统的融合方法。然而，大多数现有的卷积神经网络（CNN）架构使用传统的池化或跨步卷积策略对特征图进行下采样。这会导致源图像中的重要诊断信息和边缘细节的模糊或丢失，并稀释了特征提取过程的效力。因此，本文提出了一种基于保边稠密自编码器网络的端到端无监督融合模型，用于多模式医学图像。在提出的模型中，通过使用小波分解基于注意机制池化特征图来改善特征提取。",
    "tldr": "本文提出了一种使用小波池化边缘保留自编码器的无监督多模式医学图像融合模型，用于提高特征提取和信息保留的效果。",
    "en_tdlr": "This paper presents an unsupervised multi-modal medical image fusion model using a wavelet pooled edge-preserving autoencoder, which improves feature extraction and information retention."
}