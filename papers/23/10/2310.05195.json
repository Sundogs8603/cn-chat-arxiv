{
    "title": "GMMFormer: Gaussian-Mixture-Model Based Transformer for Efficient Partially Relevant Video Retrieval. (arXiv:2310.05195v2 [cs.CV] UPDATED)",
    "abstract": "Given a text query, partially relevant video retrieval (PRVR) seeks to find untrimmed videos containing pertinent moments in a database. For PRVR, clip modeling is essential to capture the partial relationship between texts and videos. Current PRVR methods adopt scanning-based clip construction to achieve explicit clip modeling, which is information-redundant and requires a large storage overhead. To solve the efficiency problem of PRVR methods, this paper proposes GMMFormer, a Gaussian-Mixture-Model based Transformer which models clip representations implicitly. During frame interactions, we incorporate Gaussian-Mixture-Model constraints to focus each frame on its adjacent frames instead of the whole video. Then generated representations will contain multi-scale clip information, achieving implicit clip modeling. In addition, PRVR methods ignore semantic differences between text queries relevant to the same video, leading to a sparse embedding space. We propose a query diverse loss to",
    "link": "http://arxiv.org/abs/2310.05195",
    "context": "Title: GMMFormer: Gaussian-Mixture-Model Based Transformer for Efficient Partially Relevant Video Retrieval. (arXiv:2310.05195v2 [cs.CV] UPDATED)\nAbstract: Given a text query, partially relevant video retrieval (PRVR) seeks to find untrimmed videos containing pertinent moments in a database. For PRVR, clip modeling is essential to capture the partial relationship between texts and videos. Current PRVR methods adopt scanning-based clip construction to achieve explicit clip modeling, which is information-redundant and requires a large storage overhead. To solve the efficiency problem of PRVR methods, this paper proposes GMMFormer, a Gaussian-Mixture-Model based Transformer which models clip representations implicitly. During frame interactions, we incorporate Gaussian-Mixture-Model constraints to focus each frame on its adjacent frames instead of the whole video. Then generated representations will contain multi-scale clip information, achieving implicit clip modeling. In addition, PRVR methods ignore semantic differences between text queries relevant to the same video, leading to a sparse embedding space. We propose a query diverse loss to",
    "path": "papers/23/10/2310.05195.json",
    "total_tokens": 935,
    "translated_title": "GMMFormer: 基于高斯混合模型的Transformer用于高效的部分相关视频检索",
    "translated_abstract": "在给定一个文本查询的情况下，部分相关视频检索（PRVR）旨在在数据库中找到包含相关片段的未剪辑视频。对于PRVR，剪辑建模对于捕捉文本和视频之间的部分关系至关重要。当前的PRVR方法采用基于扫描的剪辑构建来实现显式剪辑建模，这种方法的信息冗余且需要大量的存储开销。为了解决PRVR方法的效率问题，本文提出了GMMFormer，一种基于高斯混合模型的Transformer，它隐式地建模了剪辑表示。在帧交互过程中，我们采用高斯混合模型约束，使每个帧专注于其相邻帧而不是整个视频。然后生成的表示将包含多尺度的剪辑信息，实现隐式剪辑建模。此外，PRVR方法忽视了与同一视频相关的文本查询之间的语义差异，导致稀疏的嵌入空间。我们提出了一个多样性损失函数来解决这个问题。",
    "tldr": "GMMFormer是一种基于高斯混合模型的Transformer，用于高效的部分相关视频检索。它通过隐式建模剪辑表示，采用多尺度剪辑信息，并引入了一个多样性损失函数来解决语义差异导致的稀疏嵌入空间问题。"
}