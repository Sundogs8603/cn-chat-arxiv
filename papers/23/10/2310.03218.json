{
    "title": "Learning Energy-Based Prior Model with Diffusion-Amortized MCMC. (arXiv:2310.03218v1 [cs.LG])",
    "abstract": "Latent space Energy-Based Models (EBMs), also known as energy-based priors, have drawn growing interests in the field of generative modeling due to its flexibility in the formulation and strong modeling power of the latent space. However, the common practice of learning latent space EBMs with non-convergent short-run MCMC for prior and posterior sampling is hindering the model from further progress; the degenerate MCMC sampling quality in practice often leads to degraded generation quality and instability in training, especially with highly multi-modal and/or high-dimensional target distributions. To remedy this sampling issue, in this paper we introduce a simple but effective diffusion-based amortization method for long-run MCMC sampling and develop a novel learning algorithm for the latent space EBM based on it. We provide theoretical evidence that the learned amortization of MCMC is a valid long-run MCMC sampler. Experiments on several image modeling benchmark datasets demonstrate t",
    "link": "http://arxiv.org/abs/2310.03218",
    "context": "Title: Learning Energy-Based Prior Model with Diffusion-Amortized MCMC. (arXiv:2310.03218v1 [cs.LG])\nAbstract: Latent space Energy-Based Models (EBMs), also known as energy-based priors, have drawn growing interests in the field of generative modeling due to its flexibility in the formulation and strong modeling power of the latent space. However, the common practice of learning latent space EBMs with non-convergent short-run MCMC for prior and posterior sampling is hindering the model from further progress; the degenerate MCMC sampling quality in practice often leads to degraded generation quality and instability in training, especially with highly multi-modal and/or high-dimensional target distributions. To remedy this sampling issue, in this paper we introduce a simple but effective diffusion-based amortization method for long-run MCMC sampling and develop a novel learning algorithm for the latent space EBM based on it. We provide theoretical evidence that the learned amortization of MCMC is a valid long-run MCMC sampler. Experiments on several image modeling benchmark datasets demonstrate t",
    "path": "papers/23/10/2310.03218.json",
    "total_tokens": 895,
    "translated_title": "用扩散改进的 MCMC 学习能量先验模型",
    "translated_abstract": "隐变量空间的能量基模型（EBMs），也称为能量先验模型，由于其在公式化和潜在空间的强建模能力上的灵活性，引起了生成建模领域的日益关注。然而，使用非收敛的短期 MCMC 进行先验和后验采样来学习隐变量空间的能量先验模型的常见做法，阻碍了模型的进一步发展；实践中退化的 MCMC 采样质量通常导致生成质量下降和训练不稳定，特别是在高多模态和/或高维目标分布中。为了解决这个采样问题，在本文中，我们引入了一种简单但有效的基于扩散的摊销方法，用于长期 MCMC 采样，并基于此开发了一种新的学习算法来学习隐变量空间的EBM。我们提供了理论证据，表明学习到的MCMC摊销是一个有效的长期MCMC采样器。在几个图像建模基准数据集上的实验证明了",
    "tldr": "本文介绍了一种基于扩散改进的长期 MCMC采样的学习算法，用于学习能量先验模型。实验证明了该算法的有效性。",
    "en_tdlr": "This paper introduces a learning algorithm based on diffusion-amortized MCMC sampling for latent space Energy-Based Models. The experiments demonstrate the effectiveness of this algorithm."
}