{
    "title": "An Approach for Efficient Neural Architecture Search Space Definition. (arXiv:2310.17669v1 [cs.LG])",
    "abstract": "As we advance in the fast-growing era of Machine Learning, various new and more complex neural architectures are arising to tackle problem more efficiently. On the one hand their efficient usage requires advanced knowledge and expertise, which is most of the time difficult to find on the labor market. On the other hand, searching for an optimized neural architecture is a time-consuming task when it is performed manually using a trial and error approach. Hence, a method and a tool support is needed to assist users of neural architectures, leading to an eagerness in the field of Automatic Machine Learning (AutoML). When it comes to Deep Learning, an important part of AutoML is the Neural Architecture Search (NAS). In this paper, we propose a novel cell-based hierarchical search space, easy to comprehend and manipulate. The objectives of the proposed approach are to optimize the search-time and to be general enough to handle most of state of the art Convolutional Neural Networks (CNN) arc",
    "link": "http://arxiv.org/abs/2310.17669",
    "context": "Title: An Approach for Efficient Neural Architecture Search Space Definition. (arXiv:2310.17669v1 [cs.LG])\nAbstract: As we advance in the fast-growing era of Machine Learning, various new and more complex neural architectures are arising to tackle problem more efficiently. On the one hand their efficient usage requires advanced knowledge and expertise, which is most of the time difficult to find on the labor market. On the other hand, searching for an optimized neural architecture is a time-consuming task when it is performed manually using a trial and error approach. Hence, a method and a tool support is needed to assist users of neural architectures, leading to an eagerness in the field of Automatic Machine Learning (AutoML). When it comes to Deep Learning, an important part of AutoML is the Neural Architecture Search (NAS). In this paper, we propose a novel cell-based hierarchical search space, easy to comprehend and manipulate. The objectives of the proposed approach are to optimize the search-time and to be general enough to handle most of state of the art Convolutional Neural Networks (CNN) arc",
    "path": "papers/23/10/2310.17669.json",
    "total_tokens": 858,
    "translated_title": "一种高效神经架构搜索空间定义方法",
    "translated_abstract": "随着机器学习快速发展的时代的到来，各种新的、更复杂的神经架构正在出现，以更高效地解决问题。一方面，它们的高效使用需要先进的知识和专业技能，这在劳动力市场上往往难以找到。另一方面，使用试错方法手动搜索优化的神经架构是一项耗时的任务。因此，需要一种方法和工具来辅助神经架构的用户，这导致了自动机器学习（AutoML）领域的热切关注。在深度学习领域，自动机器学习的一个重要部分是神经架构搜索（NAS）。在本文中，我们提出了一种新颖的基于单元的分层搜索空间，易于理解和操作。该方法的目标是优化搜索时间，并且足够通用，能够处理大多数最先进的卷积神经网络（CNN）架构。",
    "tldr": "这篇论文介绍了一种高效的神经架构搜索空间定义方法，旨在优化搜索时间，并且能够处理大多数最先进的卷积神经网络（CNN）架构。",
    "en_tdlr": "This paper presents an efficient approach for defining neural architecture search space, aiming to optimize search time and handle state-of-the-art Convolutional Neural Network (CNN) architectures."
}