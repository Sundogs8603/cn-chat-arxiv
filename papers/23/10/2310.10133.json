{
    "title": "Empowering SMPC: Bridging the Gap Between Scalability, Memory Efficiency and Privacy in Neural Network Inference. (arXiv:2310.10133v1 [cs.CR])",
    "abstract": "This paper aims to develop an efficient open-source Secure Multi-Party Computation (SMPC) repository, that addresses the issue of practical and scalable implementation of SMPC protocol on machines with moderate computational resources, while aiming to reduce the execution time. We implement the ABY2.0 protocol for SMPC, providing developers with effective tools for building applications on the ABY 2.0 protocol. This article addresses the limitations of the C++ based MOTION2NX framework for secure neural network inference, including memory constraints and operation compatibility issues. Our enhancements include optimizing the memory usage, reducing execution time using a third-party Helper node, and enhancing efficiency while still preserving data privacy. These optimizations enable MNIST dataset inference in just 32 seconds with only 0.2 GB of RAM for a 5-layer neural network. In contrast, the previous baseline implementation required 8.03 GB of RAM and 200 seconds of execution time.",
    "link": "http://arxiv.org/abs/2310.10133",
    "context": "Title: Empowering SMPC: Bridging the Gap Between Scalability, Memory Efficiency and Privacy in Neural Network Inference. (arXiv:2310.10133v1 [cs.CR])\nAbstract: This paper aims to develop an efficient open-source Secure Multi-Party Computation (SMPC) repository, that addresses the issue of practical and scalable implementation of SMPC protocol on machines with moderate computational resources, while aiming to reduce the execution time. We implement the ABY2.0 protocol for SMPC, providing developers with effective tools for building applications on the ABY 2.0 protocol. This article addresses the limitations of the C++ based MOTION2NX framework for secure neural network inference, including memory constraints and operation compatibility issues. Our enhancements include optimizing the memory usage, reducing execution time using a third-party Helper node, and enhancing efficiency while still preserving data privacy. These optimizations enable MNIST dataset inference in just 32 seconds with only 0.2 GB of RAM for a 5-layer neural network. In contrast, the previous baseline implementation required 8.03 GB of RAM and 200 seconds of execution time.",
    "path": "papers/23/10/2310.10133.json",
    "total_tokens": 885,
    "translated_title": "提升SMPC: 在神经网络推断中跨越可扩展性、内存效率和隐私之间的差距",
    "translated_abstract": "本文旨在开发一个高效的开源Secure Multi-Party Computation（SMPC）仓库，解决了在中等计算资源的机器上实现SMPC协议的实际和可扩展性问题，并旨在减少执行时间。我们实现了ABY2.0协议，为开发人员提供了在ABY 2.0协议上构建应用程序的有效工具。文章解决了基于C++的MOTION2NX框架的限制，包括内存限制和操作兼容性问题。我们的改进包括优化内存使用、利用第三方Helper节点减少执行时间，并在保护数据隐私的同时提高效率。这些优化使得MNIST数据集的推断只需32秒，仅需0.2GB的RAM用于5层神经网络。相比之下，之前的基准实现需要8.03GB的RAM和200秒的执行时间。",
    "tldr": "本文提出了一个高效的开源SMPC仓库，解决了在资源有限的机器上实现SMPC协议的实际和可扩展性问题，并通过优化内存使用、减少执行时间和提高效率的方法，在保护数据隐私的同时完成了MNIST数据集推断任务。",
    "en_tdlr": "This paper presents an efficient open-source SMPC repository that addresses the practical and scalable implementation of SMPC protocol on machines with limited resources, and achieves faster execution time and improved efficiency while preserving data privacy for MNIST dataset inference."
}