{
    "title": "Interacting Diffusion Processes for Event Sequence Forecasting. (arXiv:2310.17800v1 [cs.LG])",
    "abstract": "Neural Temporal Point Processes (TPPs) have emerged as the primary framework for predicting sequences of events that occur at irregular time intervals, but their sequential nature can hamper performance for long-horizon forecasts. To address this, we introduce a novel approach that incorporates a diffusion generative model. The model facilitates sequence-to-sequence prediction, allowing multi-step predictions based on historical event sequences. In contrast to previous approaches, our model directly learns the joint probability distribution of types and inter-arrival times for multiple events. This allows us to fully leverage the high dimensional modeling capability of modern generative models. Our model is composed of two diffusion processes, one for the time intervals and one for the event types. These processes interact through their respective denoising functions, which can take as input intermediate representations from both processes, allowing the model to learn complex interacti",
    "link": "http://arxiv.org/abs/2310.17800",
    "context": "Title: Interacting Diffusion Processes for Event Sequence Forecasting. (arXiv:2310.17800v1 [cs.LG])\nAbstract: Neural Temporal Point Processes (TPPs) have emerged as the primary framework for predicting sequences of events that occur at irregular time intervals, but their sequential nature can hamper performance for long-horizon forecasts. To address this, we introduce a novel approach that incorporates a diffusion generative model. The model facilitates sequence-to-sequence prediction, allowing multi-step predictions based on historical event sequences. In contrast to previous approaches, our model directly learns the joint probability distribution of types and inter-arrival times for multiple events. This allows us to fully leverage the high dimensional modeling capability of modern generative models. Our model is composed of two diffusion processes, one for the time intervals and one for the event types. These processes interact through their respective denoising functions, which can take as input intermediate representations from both processes, allowing the model to learn complex interacti",
    "path": "papers/23/10/2310.17800.json",
    "total_tokens": 884,
    "translated_title": "事件序列预测的交互扩散过程",
    "translated_abstract": "神经时间点过程（TPPs）已成为预测不规则时间间隔中发生的事件序列的主要框架，但其顺序性可能会影响长期预测的性能。为了解决这个问题，我们引入了一种新颖的方法，将扩散生成模型纳入其中。该模型实现了序列到序列的预测，根据历史事件序列进行多步预测。与之前的方法不同，我们的模型直接学习多个事件类型和两个事件之间的到达时间的联合概率分布。这使我们能够充分利用现代生成模型的高维建模能力。我们的模型由两个扩散过程组成，一个用于时间间隔，一个用于事件类型。这些过程通过各自的去噪函数进行交互，可以接受来自两个过程的中间表示作为输入，使模型能够学习复杂的交互关系。",
    "tldr": "本研究提出了一种基于扩散生成模型的交互扩散过程，用于事件序列预测。与之前的方法不同，该模型直接学习多个事件类型和两个事件之间的到达时间的联合概率分布，能够充分利用现代生成模型的高维建模能力。",
    "en_tdlr": "This research proposes an interacting diffusion process based on a diffusion generative model for event sequence forecasting. Unlike previous approaches, the model directly learns the joint probability distribution of multiple event types and inter-arrival times, allowing for the leverage of the high dimensional modeling capability of modern generative models."
}