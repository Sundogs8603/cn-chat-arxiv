{
    "title": "Artemis: HE-Aware Training for Efficient Privacy-Preserving Machine Learning. (arXiv:2310.01664v1 [cs.LG])",
    "abstract": "Privacy-Preserving ML (PPML) based on Homomorphic Encryption (HE) is a promising foundational privacy technology. Making it more practical requires lowering its computational cost, especially, in handling modern large deep neural networks. Model compression via pruning is highly effective in conventional plaintext ML but cannot be effectively applied to HE-PPML as is.  We propose Artemis, a highly effective DNN pruning technique for HE-based inference. We judiciously investigate two HE-aware pruning strategies (positional and diagonal) to reduce the number of Rotation operations, which dominate compute time in HE convolution. We find that Pareto-optimal solutions are based fully on diagonal pruning. Artemis' benefits come from coupling DNN training, driven by a novel group Lasso regularization objective, with pruning to maximize HE-specific cost reduction (dominated by the Rotation operations). We show that Artemis improves on prior HE-oriented pruning and can achieve a 1.2-6x improvem",
    "link": "http://arxiv.org/abs/2310.01664",
    "context": "Title: Artemis: HE-Aware Training for Efficient Privacy-Preserving Machine Learning. (arXiv:2310.01664v1 [cs.LG])\nAbstract: Privacy-Preserving ML (PPML) based on Homomorphic Encryption (HE) is a promising foundational privacy technology. Making it more practical requires lowering its computational cost, especially, in handling modern large deep neural networks. Model compression via pruning is highly effective in conventional plaintext ML but cannot be effectively applied to HE-PPML as is.  We propose Artemis, a highly effective DNN pruning technique for HE-based inference. We judiciously investigate two HE-aware pruning strategies (positional and diagonal) to reduce the number of Rotation operations, which dominate compute time in HE convolution. We find that Pareto-optimal solutions are based fully on diagonal pruning. Artemis' benefits come from coupling DNN training, driven by a novel group Lasso regularization objective, with pruning to maximize HE-specific cost reduction (dominated by the Rotation operations). We show that Artemis improves on prior HE-oriented pruning and can achieve a 1.2-6x improvem",
    "path": "papers/23/10/2310.01664.json",
    "total_tokens": 927,
    "translated_title": "Artemis: 针对高效隐私保护机器学习的HE感知训练",
    "translated_abstract": "基于同态加密的隐私保护机器学习（PPML）是一项有前景的基础隐私技术。要使其更加实用，需要降低其计算成本，特别是在处理现代大型深度神经网络时。模型压缩通过修剪在传统明文机器学习中非常有效，但无法有效应用于HE-PPML。我们提出了Artemis，一种针对HE推理的高效DNN修剪技术。我们审慎研究了两种HE感知修剪策略（位置和对角线），以减少旋转操作的数量，在HE卷积中占主导地位的计算时间。我们发现，基于对角线修剪的 Pareto 最优解是完全可行的。Artemis的优势在于将DNN训练与修剪相结合，通过一种新的团体Lasso正则化目标驱动，以最大化HE特定的成本降低（由旋转操作主导）。我们展示了Artemis在先前的HE导向修剪的基础上取得改进，并能够实现1.2-6倍的改进。",
    "tldr": "Artemis是一种针对基于同态加密的隐私保护机器学习的高效DNN修剪技术，通过HE感知修剪策略最大化降低计算成本，并取得了显著的改进。"
}