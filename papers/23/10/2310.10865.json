{
    "title": "Will the Prince Get True Love's Kiss? On the Model Sensitivity to Gender Perturbation over Fairytale Texts. (arXiv:2310.10865v1 [cs.CL])",
    "abstract": "Recent studies show that traditional fairytales are rife with harmful gender biases. To help mitigate these gender biases in fairytales, this work aims to assess learned biases of language models by evaluating their robustness against gender perturbations. Specifically, we focus on Question Answering (QA) tasks in fairytales. Using counterfactual data augmentation to the FairytaleQA dataset, we evaluate model robustness against swapped gender character information, and then mitigate learned biases by introducing counterfactual gender stereotypes during training time. We additionally introduce a novel approach that utilizes the massive vocabulary of language models to support text genres beyond fairytales. Our experimental results suggest that models are sensitive to gender perturbations, with significant performance drops compared to the original testing set. However, when first fine-tuned on a counterfactual training dataset, models are less sensitive to the later introduced anti-gend",
    "link": "http://arxiv.org/abs/2310.10865",
    "context": "Title: Will the Prince Get True Love's Kiss? On the Model Sensitivity to Gender Perturbation over Fairytale Texts. (arXiv:2310.10865v1 [cs.CL])\nAbstract: Recent studies show that traditional fairytales are rife with harmful gender biases. To help mitigate these gender biases in fairytales, this work aims to assess learned biases of language models by evaluating their robustness against gender perturbations. Specifically, we focus on Question Answering (QA) tasks in fairytales. Using counterfactual data augmentation to the FairytaleQA dataset, we evaluate model robustness against swapped gender character information, and then mitigate learned biases by introducing counterfactual gender stereotypes during training time. We additionally introduce a novel approach that utilizes the massive vocabulary of language models to support text genres beyond fairytales. Our experimental results suggest that models are sensitive to gender perturbations, with significant performance drops compared to the original testing set. However, when first fine-tuned on a counterfactual training dataset, models are less sensitive to the later introduced anti-gend",
    "path": "papers/23/10/2310.10865.json",
    "total_tokens": 1003,
    "translated_title": "王子会得到真爱之吻吗？关于童话文本中性别扰动对模型敏感性的研究",
    "translated_abstract": "最近的研究显示，传统的童话故事中存在大量有害的性别偏见。为了减轻童话中的性别偏见，本研究旨在评估语言模型学习到的偏见对性别扰动的鲁棒性。具体而言，我们关注童话故事中的问答任务。通过使用反事实数据增强FairytaleQA数据集，我们评估模型对交换性别角色信息的鲁棒性，并在训练时引入反事实性别刻板印象来减轻学习到的偏见。此外，我们还引入了一种新的方法，利用语言模型的庞大词汇量来支持超越童话故事的文本类型。我们的实验结果表明，模型对性别扰动敏感，性能与原始测试集相比显著下降。然而，当首先在反事实的训练数据集上进行微调后，模型对后续引入的反性别偏见更不敏感。",
    "tldr": "该研究旨在通过评估语言模型对性别扰动的鲁棒性，帮助减轻传统童话中的性别偏见，并通过引入反事实性别刻板印象来减轻学习到的偏见。实验结果显示，模型对性别扰动敏感，但在反事实训练后对后续引入的反性别偏见更不敏感。",
    "en_tdlr": "This research aims to mitigate gender biases in traditional fairytales by evaluating the robustness of language models against gender perturbations and introducing counterfactual gender stereotypes to alleviate learned biases. Experimental results suggest that models are sensitive to gender perturbations, but become less sensitive to later introduced anti-gender biases after being fine-tuned on counterfactual training data."
}