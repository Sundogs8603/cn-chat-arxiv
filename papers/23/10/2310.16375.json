{
    "title": "DyExplainer: Explainable Dynamic Graph Neural Networks. (arXiv:2310.16375v1 [cs.LG])",
    "abstract": "Graph Neural Networks (GNNs) resurge as a trending research subject owing to their impressive ability to capture representations from graph-structured data. However, the black-box nature of GNNs presents a significant challenge in terms of comprehending and trusting these models, thereby limiting their practical applications in mission-critical scenarios. Although there has been substantial progress in the field of explaining GNNs in recent years, the majority of these studies are centered on static graphs, leaving the explanation of dynamic GNNs largely unexplored. Dynamic GNNs, with their ever-evolving graph structures, pose a unique challenge and require additional efforts to effectively capture temporal dependencies and structural relationships. To address this challenge, we present DyExplainer, a novel approach to explaining dynamic GNNs on the fly. DyExplainer trains a dynamic GNN backbone to extract representations of the graph at each snapshot, while simultaneously exploring st",
    "link": "http://arxiv.org/abs/2310.16375",
    "context": "Title: DyExplainer: Explainable Dynamic Graph Neural Networks. (arXiv:2310.16375v1 [cs.LG])\nAbstract: Graph Neural Networks (GNNs) resurge as a trending research subject owing to their impressive ability to capture representations from graph-structured data. However, the black-box nature of GNNs presents a significant challenge in terms of comprehending and trusting these models, thereby limiting their practical applications in mission-critical scenarios. Although there has been substantial progress in the field of explaining GNNs in recent years, the majority of these studies are centered on static graphs, leaving the explanation of dynamic GNNs largely unexplored. Dynamic GNNs, with their ever-evolving graph structures, pose a unique challenge and require additional efforts to effectively capture temporal dependencies and structural relationships. To address this challenge, we present DyExplainer, a novel approach to explaining dynamic GNNs on the fly. DyExplainer trains a dynamic GNN backbone to extract representations of the graph at each snapshot, while simultaneously exploring st",
    "path": "papers/23/10/2310.16375.json",
    "total_tokens": 835,
    "translated_title": "DyExplainer: 可解释的动态图神经网络",
    "translated_abstract": "图神经网络(GNNs)因其能从图结构数据中捕捉表示的能力而重新兴起为一个研究热点。然而，GNNs的黑盒特性在理解和信任这些模型方面存在着显著挑战，从而限制了它们在关键任务场景中的实际应用。虽然近年来在解释GNNs领域取得了显著进展，但其中大部分研究都集中在静态图上，对动态GNNs的解释研究相对较少。动态GNNs以其不断演化的图结构提出了独特的挑战，并需要额外的努力来有效捕捉时间依赖性和结构关系。为了解决这一挑战，我们提出了DyExplainer，一种新颖的动态GNNs解释方法。DyExplainer训练一个动态GNNs骨架，在每个快照中提取图的表示，并同时进行探索。",
    "tldr": "DyExplainer是一个新颖的方法，用于解释动态图神经网络。它训练一个动态GNNs骨架，能够提取每个快照中图的表示，并且同时进行探索，以有效捕捉时间依赖性和结构关系。"
}