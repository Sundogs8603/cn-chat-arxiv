{
    "title": "Effects of Human Adversarial and Affable Samples on BERT Generalizability. (arXiv:2310.08008v1 [cs.AI])",
    "abstract": "BERT-based models have had strong performance on leaderboards, yet have been demonstrably worse in real-world settings requiring generalization. Limited quantities of training data is considered a key impediment to achieving generalizability in machine learning. In this paper, we examine the impact of training \\textit{data quality}, not quantity, on a model's generalizability. We consider two characteristics of training data: the portion of human-adversarial (h-adversarial), i.e., sample pairs with seemingly minor differences but different ground-truth labels, and human-affable (h-affable) training samples, i.e., sample pairs with minor differences but the same ground-truth label. We find that for a fixed size of training samples, as a rule of thumb, having 10-30\\% h-adversarial instances improves the precision, and therefore F1, by up to 20 points in the tasks of text classification and relation extraction. Increasing h-adversarials beyond this range can result in performance plateaus",
    "link": "http://arxiv.org/abs/2310.08008",
    "context": "Title: Effects of Human Adversarial and Affable Samples on BERT Generalizability. (arXiv:2310.08008v1 [cs.AI])\nAbstract: BERT-based models have had strong performance on leaderboards, yet have been demonstrably worse in real-world settings requiring generalization. Limited quantities of training data is considered a key impediment to achieving generalizability in machine learning. In this paper, we examine the impact of training \\textit{data quality}, not quantity, on a model's generalizability. We consider two characteristics of training data: the portion of human-adversarial (h-adversarial), i.e., sample pairs with seemingly minor differences but different ground-truth labels, and human-affable (h-affable) training samples, i.e., sample pairs with minor differences but the same ground-truth label. We find that for a fixed size of training samples, as a rule of thumb, having 10-30\\% h-adversarial instances improves the precision, and therefore F1, by up to 20 points in the tasks of text classification and relation extraction. Increasing h-adversarials beyond this range can result in performance plateaus",
    "path": "papers/23/10/2310.08008.json",
    "total_tokens": 904,
    "translated_title": "BERT广义性的影响：人为对抗样本和友好样本的效果",
    "translated_abstract": "基于BERT的模型在领先榜上表现强劲，但在需要泛化的实际场景中表现较差。有限的训练数据被认为是机器学习泛化能力的主要障碍。本文研究训练数据质量对模型泛化能力的影响，而不是数量。我们考虑了训练数据的两个特征：人为对抗样本（具有看似微小差异但具有不同标签的样本对）和人为友好样本（具有微小差异但具有相同标签的样本对）。我们发现，在固定大小的训练样本上，以10-30\\%的人为对抗实例为经验，可以提高文本分类和关系抽取任务的精度和F1值最多20个百分点。超过此范围的增加对模型性能无显著影响。",
    "tldr": "本研究研究了对BERT模型的广义性影响，发现在固定大小的训练样本上，有10-30\\%的人为对抗实例可以显著提高文本分类和关系抽取任务的精度和F1值。",
    "en_tdlr": "This study examines the effects of adversarial and affable samples on BERT models' generalizability, and finds that having 10-30% adversarial instances in the training data significantly improves the precision and F1 scores in text classification and relation extraction tasks."
}