{
    "title": "Can Language Models Employ the Socratic Method? Experiments with Code Debugging. (arXiv:2310.03210v1 [cs.CL])",
    "abstract": "When employing the Socratic method of teaching, instructors guide students toward solving a problem on their own rather than providing the solution directly. While this strategy can substantially improve learning outcomes, it is usually time-consuming and cognitively demanding. Automated Socratic conversational agents can augment human instruction and provide the necessary scale, however their development is hampered by the lack of suitable data for training and evaluation. In this paper, we introduce a manually created dataset of multi-turn Socratic advice that is aimed at helping a novice programmer fix buggy solutions to simple computational problems. The dataset is then used for benchmarking the Socratic debugging abilities of a number of language models, ranging from fine-tuning the instruction-based text-to-text transformer Flan-T5 to zero-shot and chain of thought prompting of the much larger GPT-4. The code and datasets are made freely available for research at the link below. ",
    "link": "http://arxiv.org/abs/2310.03210",
    "context": "Title: Can Language Models Employ the Socratic Method? Experiments with Code Debugging. (arXiv:2310.03210v1 [cs.CL])\nAbstract: When employing the Socratic method of teaching, instructors guide students toward solving a problem on their own rather than providing the solution directly. While this strategy can substantially improve learning outcomes, it is usually time-consuming and cognitively demanding. Automated Socratic conversational agents can augment human instruction and provide the necessary scale, however their development is hampered by the lack of suitable data for training and evaluation. In this paper, we introduce a manually created dataset of multi-turn Socratic advice that is aimed at helping a novice programmer fix buggy solutions to simple computational problems. The dataset is then used for benchmarking the Socratic debugging abilities of a number of language models, ranging from fine-tuning the instruction-based text-to-text transformer Flan-T5 to zero-shot and chain of thought prompting of the much larger GPT-4. The code and datasets are made freely available for research at the link below. ",
    "path": "papers/23/10/2310.03210.json",
    "total_tokens": 894,
    "translated_title": "语言模型能否使用苏格拉底方法？关于代码调试的实验。",
    "translated_abstract": "当采用苏格拉底教学法时，指导员会引导学生自己解决问题，而不是直接提供解决方案。虽然这种策略可以极大地改善学习结果，但通常需要大量时间和认知能力。自动化的苏格拉底对话代理可以增强人类教学，并提供所需的规模，然而它们的发展受到缺乏适合的训练和评估数据的限制。在本文中，我们引入了一个手工创建的多轮苏格拉底建议数据集，旨在帮助初学者程序员修复简单计算问题的错误解决方案。然后使用该数据集对一些语言模型的苏格拉底调试能力进行了基准测试，从微调以指令为基础的文本到文本转换器Flan-T5，到零-shot和更大的GPT-4的思维链提示。代码和数据集已在下方链接中免费提供给研究者使用。",
    "tldr": "本文介绍了一个手工创建的多轮苏格拉底建议数据集，旨在帮助初学者程序员修复简单计算问题的错误解决方案。通过对一系列语言模型的基准测试，研究了它们的苏格拉底调试能力。",
    "en_tdlr": "This paper presents a manually created dataset aimed at helping novice programmers fix buggy solutions to simple computational problems using the Socratic method. The paper also benchmarks the Socratic debugging abilities of various language models."
}