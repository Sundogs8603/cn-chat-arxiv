{
    "title": "Evaluating Large Language Models: A Comprehensive Survey. (arXiv:2310.19736v2 [cs.CL] UPDATED)",
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across a broad spectrum of tasks. They have attracted significant attention and been deployed in numerous downstream applications. Nevertheless, akin to a double-edged sword, LLMs also present potential risks. They could suffer from private data leaks or yield inappropriate, harmful, or misleading content. Additionally, the rapid progress of LLMs raises concerns about the potential emergence of superintelligent systems without adequate safeguards. To effectively capitalize on LLM capacities as well as ensure their safe and beneficial development, it is critical to conduct a rigorous and comprehensive evaluation of LLMs.  This survey endeavors to offer a panoramic perspective on the evaluation of LLMs. We categorize the evaluation of LLMs into three major groups: knowledge and capability evaluation, alignment evaluation and safety evaluation. In addition to the comprehensive review on the evaluation methodologies and",
    "link": "http://arxiv.org/abs/2310.19736",
    "context": "Title: Evaluating Large Language Models: A Comprehensive Survey. (arXiv:2310.19736v2 [cs.CL] UPDATED)\nAbstract: Large language models (LLMs) have demonstrated remarkable capabilities across a broad spectrum of tasks. They have attracted significant attention and been deployed in numerous downstream applications. Nevertheless, akin to a double-edged sword, LLMs also present potential risks. They could suffer from private data leaks or yield inappropriate, harmful, or misleading content. Additionally, the rapid progress of LLMs raises concerns about the potential emergence of superintelligent systems without adequate safeguards. To effectively capitalize on LLM capacities as well as ensure their safe and beneficial development, it is critical to conduct a rigorous and comprehensive evaluation of LLMs.  This survey endeavors to offer a panoramic perspective on the evaluation of LLMs. We categorize the evaluation of LLMs into three major groups: knowledge and capability evaluation, alignment evaluation and safety evaluation. In addition to the comprehensive review on the evaluation methodologies and",
    "path": "papers/23/10/2310.19736.json",
    "total_tokens": 859,
    "translated_title": "评估大型语言模型：一项全面调查",
    "translated_abstract": "大型语言模型（LLMs）在各种任务中展示了卓越的能力。它们吸引了广泛的关注，并在许多下游应用中得到了应用。然而，与双刃剑一样，LLMs也存在潜在风险。它们可能受到私人数据泄露，产生不适当、有害或误导性的内容。此外，LLMs的快速进展引发了对可能出现没有足够保障的超智能系统的担忧。为了有效利用LLMs的能力，并确保其安全和有益的发展，对LLMs进行严格和全面的评估至关重要。本调查旨在提供对LLMs评估的全面概述。我们将LLMs的评估分为三大类别：知识和能力评估，对齐评估和安全评估。除了全面回顾评估方法和技术之外，",
    "tldr": "本调查综述了对大型语言模型（LLMs）的评估，包括知识和能力评估、对齐评估和安全评估。对于充分利用LLMs的能力以及确保其安全和有益的发展至关重要。",
    "en_tdlr": "This survey provides a comprehensive overview of the evaluation of large language models (LLMs), including knowledge and capability evaluation, alignment evaluation, and safety evaluation. It is crucial to effectively capitalize on the capabilities of LLMs and ensure their safe and beneficial development."
}