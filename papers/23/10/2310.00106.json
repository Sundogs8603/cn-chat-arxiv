{
    "title": "FashionFlow: Leveraging Diffusion Models for Dynamic Fashion Video Synthesis from Static Imagery. (arXiv:2310.00106v1 [cs.CV])",
    "abstract": "Our study introduces a new image-to-video generator called FashionFlow. By utilising a diffusion model, we are able to create short videos from still images. Our approach involves developing and connecting relevant components with the diffusion model, which sets our work apart. The components include the use of pseudo-3D convolutional layers to generate videos efficiently. VAE and CLIP encoders capture vital characteristics from still images to influence the diffusion model. Our research demonstrates a successful synthesis of fashion videos featuring models posing from various angles, showcasing the fit and appearance of the garment. Our findings hold great promise for improving and enhancing the shopping experience for the online fashion industry.",
    "link": "http://arxiv.org/abs/2310.00106",
    "context": "Title: FashionFlow: Leveraging Diffusion Models for Dynamic Fashion Video Synthesis from Static Imagery. (arXiv:2310.00106v1 [cs.CV])\nAbstract: Our study introduces a new image-to-video generator called FashionFlow. By utilising a diffusion model, we are able to create short videos from still images. Our approach involves developing and connecting relevant components with the diffusion model, which sets our work apart. The components include the use of pseudo-3D convolutional layers to generate videos efficiently. VAE and CLIP encoders capture vital characteristics from still images to influence the diffusion model. Our research demonstrates a successful synthesis of fashion videos featuring models posing from various angles, showcasing the fit and appearance of the garment. Our findings hold great promise for improving and enhancing the shopping experience for the online fashion industry.",
    "path": "papers/23/10/2310.00106.json",
    "total_tokens": 896,
    "translated_title": "FashionFlow: 利用扩散模型从静态图像生成动态时尚视频",
    "translated_abstract": "我们的研究介绍了一种新的图像到视频生成器，称为FashionFlow。通过利用扩散模型，我们能够从静态图像创建短视频。我们的方法涉及开发并连接与扩散模型相关的组件，这使得我们的工作与众不同。这些组件包括使用伪3D卷积层高效生成视频。VAE和CLIP编码器从静态图像中捕捉到重要特征，以影响扩散模型。我们的研究展示了成功合成具有不同角度的模特一边摆姿势，展示服装的合身度和外观的时尚视频。我们的发现对于改进和提升在线时尚行业的购物体验有很大的潜力。",
    "tldr": "本研究提出了一种名为FashionFlow的图像到视频生成器，利用扩散模型从静态图像生成短视频。我们通过开发并连接与扩散模型相关的组件来实现这一目标，其中包括使用伪3D卷积层高效生成视频，并利用VAE和CLIP编码器捕捉关键特征。研究结果展示了成功合成时尚视频的能力，能够展示服装的合身度和外观，为在线时尚行业的购物体验提供改进和增强的潜力。",
    "en_tdlr": "This study introduces FashionFlow, an image-to-video generator that utilizes diffusion models to create short fashion videos from still images. By developing and connecting relevant components such as pseudo-3D convolutional layers and VAE/CLIP encoders, the research successfully synthesizes fashion videos showcasing garment fit and appearance, promising to enhance the online fashion shopping experience."
}