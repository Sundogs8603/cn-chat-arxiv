{
    "title": "Attention-Based Ensemble Pooling for Time Series Forecasting. (arXiv:2310.16231v1 [cs.LG])",
    "abstract": "A common technique to reduce model bias in time-series forecasting is to use an ensemble of predictive models and pool their output into an ensemble forecast. In cases where each predictive model has different biases, however, it is not always clear exactly how each model forecast should be weighed during this pooling. We propose a method for pooling that performs a weighted average over candidate model forecasts, where the weights are learned by an attention-based ensemble pooling model. We test this method on two time-series forecasting problems: multi-step forecasting of the dynamics of the non-stationary Lorenz `63 equation, and one-step forecasting of the weekly incident deaths due to COVID-19. We find that while our model achieves excellent valid times when forecasting the non-stationary Lorenz `63 equation, it does not consistently perform better than the existing ensemble pooling when forecasting COVID-19 weekly incident deaths.",
    "link": "http://arxiv.org/abs/2310.16231",
    "context": "Title: Attention-Based Ensemble Pooling for Time Series Forecasting. (arXiv:2310.16231v1 [cs.LG])\nAbstract: A common technique to reduce model bias in time-series forecasting is to use an ensemble of predictive models and pool their output into an ensemble forecast. In cases where each predictive model has different biases, however, it is not always clear exactly how each model forecast should be weighed during this pooling. We propose a method for pooling that performs a weighted average over candidate model forecasts, where the weights are learned by an attention-based ensemble pooling model. We test this method on two time-series forecasting problems: multi-step forecasting of the dynamics of the non-stationary Lorenz `63 equation, and one-step forecasting of the weekly incident deaths due to COVID-19. We find that while our model achieves excellent valid times when forecasting the non-stationary Lorenz `63 equation, it does not consistently perform better than the existing ensemble pooling when forecasting COVID-19 weekly incident deaths.",
    "path": "papers/23/10/2310.16231.json",
    "total_tokens": 870,
    "translated_title": "基于注意力机制的集成池化方法用于时间序列预测",
    "translated_abstract": "在时间序列预测中，减少模型偏差的常见技术是使用多个预测模型的集成，并将其输出汇总为一个集成预测。然而，在每个预测模型具有不同偏差的情况下，如何在汇总中权衡每个模型的预测并不总是清晰的。我们提出了一种集成池化方法，利用基于注意力的集成池化模型学习预测候选模型的加权平均值。我们将这种方法应用于两个时间序列预测问题：非平稳的Lorenz `63方程的多步预测和COVID-19每周发生的死亡事件的单步预测。我们发现，虽然我们的模型在预测非平稳的Lorenz `63方程时表现出色，但在预测COVID-19每周发生的死亡事件时，并不一直比现有的集成池化方法表现更好。",
    "tldr": "提出了一种基于注意力机制的集成池化方法，用于时间序列预测。该方法通过学习加权平均值来权衡不同预测模型的输出，并在两个时间序列预测问题上进行了测试。在某些情况下，该方法优于现有的集成池化方法。"
}