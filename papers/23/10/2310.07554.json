{
    "title": "Retrieve Anything To Augment Large Language Models. (arXiv:2310.07554v2 [cs.IR] UPDATED)",
    "abstract": "Large language models (LLMs) face significant challenges stemming from their inherent limitations in knowledge, memory, alignment, and action. These challenges cannot be addressed by LLMs alone, but should rely on assistance from the external world, such as knowledge base, memory store, demonstration examples, and tools. Retrieval augmentation stands as a vital mechanism for bridging the gap between LLMs and the external assistance. However, conventional methods encounter two pressing issues. On the one hand, the general-purpose retrievers are not properly optimized for the retrieval augmentation of LLMs. On the other hand, the task-specific retrievers lack the required versatility, hindering their performance across the diverse retrieval augmentation scenarios.  In this work, we present a novel approach, the LLM-Embedder, which comprehensively supports the diverse retrieval augmentation needs of LLMs with one unified embedding model. Training such a unified model is non-trivial, as va",
    "link": "http://arxiv.org/abs/2310.07554",
    "context": "Title: Retrieve Anything To Augment Large Language Models. (arXiv:2310.07554v2 [cs.IR] UPDATED)\nAbstract: Large language models (LLMs) face significant challenges stemming from their inherent limitations in knowledge, memory, alignment, and action. These challenges cannot be addressed by LLMs alone, but should rely on assistance from the external world, such as knowledge base, memory store, demonstration examples, and tools. Retrieval augmentation stands as a vital mechanism for bridging the gap between LLMs and the external assistance. However, conventional methods encounter two pressing issues. On the one hand, the general-purpose retrievers are not properly optimized for the retrieval augmentation of LLMs. On the other hand, the task-specific retrievers lack the required versatility, hindering their performance across the diverse retrieval augmentation scenarios.  In this work, we present a novel approach, the LLM-Embedder, which comprehensively supports the diverse retrieval augmentation needs of LLMs with one unified embedding model. Training such a unified model is non-trivial, as va",
    "path": "papers/23/10/2310.07554.json",
    "total_tokens": 866,
    "translated_title": "检索任何内容来增强大型语言模型",
    "translated_abstract": "大型语言模型(LLMs)面临着由于其在知识、记忆、对齐和行动方面的固有限制而产生的重要挑战。这些挑战不能单靠LLMs自行解决，而应依赖于来自外部世界（如知识库、记忆存储、演示示例和工具）的辅助。检索增强作为LLMs与外部辅助之间的重要机制。然而，传统方法遇到两个紧迫问题。一方面，通用检索器未能适当优化LLMs的检索增强。另一方面，任务特定的检索器缺乏所需的多样性，阻碍其在各种检索增强场景中的性能表现。在这项工作中，我们提出了一种新的方法，即LLM-Embedder，它通过一个统一的嵌入模型全面支持LLMs的多样化检索增强需求。训练这样的统一模型并不容易，由于不同检索增强场景的多样性。",
    "tldr": "这项工作提出了一种新的方法，即LLM-Embedder，通过一个统一的嵌入模型全面支持LLMs的多样化检索增强需求。",
    "en_tdlr": "This work presents a novel approach called LLM-Embedder, which comprehensively supports the diverse retrieval augmentation needs of large language models (LLMs) with one unified embedding model."
}