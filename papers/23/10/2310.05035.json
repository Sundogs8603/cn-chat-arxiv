{
    "title": "Self-Convinced Prompting: Few-Shot Question Answering with Repeated Introspection. (arXiv:2310.05035v2 [cs.CL] UPDATED)",
    "abstract": "While large language models (LLMs) such as ChatGPT and PaLM have demonstrated remarkable performance in various language understanding and generation tasks, their capabilities in complex reasoning and intricate knowledge utilization still fall short of human-level proficiency. Recent studies have established the effectiveness of prompts in steering LLMs towards generating desired outputs. Building on these insights, we introduce a novel framework that harnesses the potential of large-scale pre-trained language models, to iteratively enhance performance of the LLMs. Our framework incorporates three components: \\textit{Normal CoT}, a \\textit{Convincer}, and an \\textit{Answerer}. It processes the output of a typical few-shot chain-of-thought prompt, assesses the correctness of the response, scrutinizes the answer, refines the reasoning, and ultimately produces a new solution. Experimental results on the 7 datasets of miscellaneous problems validate the efficacy of the Self-Convince framew",
    "link": "http://arxiv.org/abs/2310.05035",
    "context": "Title: Self-Convinced Prompting: Few-Shot Question Answering with Repeated Introspection. (arXiv:2310.05035v2 [cs.CL] UPDATED)\nAbstract: While large language models (LLMs) such as ChatGPT and PaLM have demonstrated remarkable performance in various language understanding and generation tasks, their capabilities in complex reasoning and intricate knowledge utilization still fall short of human-level proficiency. Recent studies have established the effectiveness of prompts in steering LLMs towards generating desired outputs. Building on these insights, we introduce a novel framework that harnesses the potential of large-scale pre-trained language models, to iteratively enhance performance of the LLMs. Our framework incorporates three components: \\textit{Normal CoT}, a \\textit{Convincer}, and an \\textit{Answerer}. It processes the output of a typical few-shot chain-of-thought prompt, assesses the correctness of the response, scrutinizes the answer, refines the reasoning, and ultimately produces a new solution. Experimental results on the 7 datasets of miscellaneous problems validate the efficacy of the Self-Convince framew",
    "path": "papers/23/10/2310.05035.json",
    "total_tokens": 859,
    "translated_title": "自我验证提示：利用重复内省进行少样本问题回答",
    "translated_abstract": "虽然像ChatGPT和PaLM这样的大型语言模型在各种语言理解和生成任务中表现出色，但它们在复杂推理和繁琐知识利用方面仍然不及人类的熟练程度。最近的研究已经证明了提示在引导语言模型生成期望的输出方面的有效性。在这些见解的基础上，我们引入了一种新的框架，利用大规模预训练语言模型的潜力，以迭代的方式增强语言模型的性能。我们的框架包含三个组件：\\textit{Normal CoT}、\\textit{Convincer}和\\textit{Answerer}。它处理typical few-shot chain-of-thought prompt的输出，评估回答的正确性，审查答案，改进推理，最终产生一个新的解决方案。在七个各种问题的数据集上的实验结果验证了自我验证框架的有效性。",
    "tldr": "该论文提出了一种利用大规模预训练语言模型的框架，通过迭代反思和改进推理过程，以提升模型在少样本问题回答上的性能。",
    "en_tdlr": "This paper proposes a framework that utilizes large-scale pre-trained language models to enhance performance in few-shot question answering by iteratively reflecting and improving the reasoning process."
}