{
    "title": "EMMA-X: An EM-like Multilingual Pre-training Algorithm for Cross-lingual Representation Learning. (arXiv:2310.17233v1 [cs.CL])",
    "abstract": "Expressing universal semantics common to all languages is helpful in understanding the meanings of complex and culture-specific sentences. The research theme underlying this scenario focuses on learning universal representations across languages with the usage of massive parallel corpora. However, due to the sparsity and scarcity of parallel data, there is still a big challenge in learning authentic ``universals'' for any two languages. In this paper, we propose EMMA-X: an EM-like Multilingual pre-training Algorithm, to learn (X)Cross-lingual universals with the aid of excessive multilingual non-parallel data. EMMA-X unifies the cross-lingual representation learning task and an extra semantic relation prediction task within an EM framework. Both the extra semantic classifier and the cross-lingual sentence encoder approximate the semantic relation of two sentences, and supervise each other until convergence. To evaluate EMMA-X, we conduct experiments on XRETE, a newly introduced benchma",
    "link": "http://arxiv.org/abs/2310.17233",
    "context": "Title: EMMA-X: An EM-like Multilingual Pre-training Algorithm for Cross-lingual Representation Learning. (arXiv:2310.17233v1 [cs.CL])\nAbstract: Expressing universal semantics common to all languages is helpful in understanding the meanings of complex and culture-specific sentences. The research theme underlying this scenario focuses on learning universal representations across languages with the usage of massive parallel corpora. However, due to the sparsity and scarcity of parallel data, there is still a big challenge in learning authentic ``universals'' for any two languages. In this paper, we propose EMMA-X: an EM-like Multilingual pre-training Algorithm, to learn (X)Cross-lingual universals with the aid of excessive multilingual non-parallel data. EMMA-X unifies the cross-lingual representation learning task and an extra semantic relation prediction task within an EM framework. Both the extra semantic classifier and the cross-lingual sentence encoder approximate the semantic relation of two sentences, and supervise each other until convergence. To evaluate EMMA-X, we conduct experiments on XRETE, a newly introduced benchma",
    "path": "papers/23/10/2310.17233.json",
    "total_tokens": 961,
    "translated_title": "EMMA-X:一种用于跨语言表示学习的类EM多语言预训练算法",
    "translated_abstract": "在理解复杂和特定于文化的句子的含义时，表达所有语言共同的通用语义是有帮助的。本文的研究主题是使用海量并行语料库学习跨语言的通用表示。然而，由于并行数据的稀疏性和匮乏性，对于任何两种语言来说，学习真正的“普遍性”仍然是一个巨大的挑战。在本文中，我们提出了一种名为EMMA-X的类EM多语言预训练算法，利用多语言非并行数据来学习跨语言的“普遍性”。EMMA-X在EM框架内将跨语言表示学习任务和额外的语义关系预测任务统一起来。额外的语义分类器和跨语言句子编码器都近似了两个句子的语义关系，并相互监督直到收敛。为了评估EMMA-X，我们在新引入的XRETE基准上进行了实验。",
    "tldr": "本文提出了一种名为EMMA-X的类EM多语言预训练算法，通过利用多语言非并行数据进行学习，实现了跨语言的通用表示。该算法在一个EM框架内统一了跨语言表示学习任务和额外的语义关系预测任务，通过互相监督直到收敛的方式进行训练。",
    "en_tdlr": "This paper proposes a EM-like multilingual pre-training algorithm called EMMA-X, which learns cross-lingual universal representations by utilizing multilingual non-parallel data. The algorithm unifies the cross-lingual representation learning task and an extra semantic relation prediction task within an EM framework, training them in a mutually supervising manner until convergence."
}