{
    "title": "Graph Neural Networks with a Distribution of Parametrized Graphs. (arXiv:2310.16401v1 [cs.LG])",
    "abstract": "Traditionally, graph neural networks have been trained using a single observed graph. However, the observed graph represents only one possible realization. In many applications, the graph may encounter uncertainties, such as having erroneous or missing edges, as well as edge weights that provide little informative value. To address these challenges and capture additional information previously absent in the observed graph, we introduce latent variables to parameterize and generate multiple graphs. We obtain the maximum likelihood estimate of the network parameters in an Expectation-Maximization (EM) framework based on the multiple graphs. Specifically, we iteratively determine the distribution of the graphs using a Markov Chain Monte Carlo (MCMC) method, incorporating the principles of PAC-Bayesian theory. Numerical experiments demonstrate improvements in performance against baseline models on node classification for heterogeneous graphs and graph regression on chemistry datasets.",
    "link": "http://arxiv.org/abs/2310.16401",
    "context": "Title: Graph Neural Networks with a Distribution of Parametrized Graphs. (arXiv:2310.16401v1 [cs.LG])\nAbstract: Traditionally, graph neural networks have been trained using a single observed graph. However, the observed graph represents only one possible realization. In many applications, the graph may encounter uncertainties, such as having erroneous or missing edges, as well as edge weights that provide little informative value. To address these challenges and capture additional information previously absent in the observed graph, we introduce latent variables to parameterize and generate multiple graphs. We obtain the maximum likelihood estimate of the network parameters in an Expectation-Maximization (EM) framework based on the multiple graphs. Specifically, we iteratively determine the distribution of the graphs using a Markov Chain Monte Carlo (MCMC) method, incorporating the principles of PAC-Bayesian theory. Numerical experiments demonstrate improvements in performance against baseline models on node classification for heterogeneous graphs and graph regression on chemistry datasets.",
    "path": "papers/23/10/2310.16401.json",
    "total_tokens": 882,
    "translated_title": "具有参数化图的图神经网络",
    "translated_abstract": "传统上，图神经网络是使用单个观察到的图进行训练的。然而，观察到的图仅代表了一种可能的实现。在许多应用中，图可能会遇到不确定性，例如存在错误或缺失的边，以及提供很少信息价值的边权重。为了解决这些挑战并捕捉先前在观察到的图中缺失的附加信息，我们引入潜在变量来参数化和生成多个图。我们基于多个图的期望最大化（EM）框架，使用最大似然估计网络参数。具体而言，我们使用马尔可夫链蒙特卡洛（MCMC）方法迭代地确定图的分布，结合PAC-Bayesian理论的原则。数值实验在异质图的节点分类和化学数据集的图回归上改进了性能。",
    "tldr": "这篇论文提出了一种使用参数化和生成多个图来解决图神经网络仅使用单个观察图的挑战的方法。在节点分类和图回归任务上，通过最大似然估计网络参数，在多个图上使用马尔可夫链蒙特卡洛方法，结合PAC-Bayesian理论的原则，取得了性能改进。"
}