{
    "title": "Adversarial Robustness in Graph Neural Networks: A Hamiltonian Approach. (arXiv:2310.06396v1 [cs.LG])",
    "abstract": "Graph neural networks (GNNs) are vulnerable to adversarial perturbations, including those that affect both node features and graph topology. This paper investigates GNNs derived from diverse neural flows, concentrating on their connection to various stability notions such as BIBO stability, Lyapunov stability, structural stability, and conservative stability. We argue that Lyapunov stability, despite its common use, does not necessarily ensure adversarial robustness. Inspired by physics principles, we advocate for the use of conservative Hamiltonian neural flows to construct GNNs that are robust to adversarial attacks. The adversarial robustness of different neural flow GNNs is empirically compared on several benchmark datasets under a variety of adversarial attacks. Extensive numerical experiments demonstrate that GNNs leveraging conservative Hamiltonian flows with Lyapunov stability substantially improve robustness against adversarial perturbations. The implementation code of experim",
    "link": "http://arxiv.org/abs/2310.06396",
    "context": "Title: Adversarial Robustness in Graph Neural Networks: A Hamiltonian Approach. (arXiv:2310.06396v1 [cs.LG])\nAbstract: Graph neural networks (GNNs) are vulnerable to adversarial perturbations, including those that affect both node features and graph topology. This paper investigates GNNs derived from diverse neural flows, concentrating on their connection to various stability notions such as BIBO stability, Lyapunov stability, structural stability, and conservative stability. We argue that Lyapunov stability, despite its common use, does not necessarily ensure adversarial robustness. Inspired by physics principles, we advocate for the use of conservative Hamiltonian neural flows to construct GNNs that are robust to adversarial attacks. The adversarial robustness of different neural flow GNNs is empirically compared on several benchmark datasets under a variety of adversarial attacks. Extensive numerical experiments demonstrate that GNNs leveraging conservative Hamiltonian flows with Lyapunov stability substantially improve robustness against adversarial perturbations. The implementation code of experim",
    "path": "papers/23/10/2310.06396.json",
    "total_tokens": 893,
    "translated_title": "图神经网络中的对抗鲁棒性：一种哈密顿方法",
    "translated_abstract": "图神经网络(GNNs)容易受到对抗性扰动的影响，包括影响节点特征和图拓扑的扰动。本文研究了从不同的神经流导出的GNNs，重点关注它们与多种稳定性概念（如BIBO稳定性、李亚普诺夫稳定性、结构稳定性和保守稳定性）的联系。我们认为，尽管李亚普诺夫稳定性被广泛使用，但并不能保证对抗鲁棒性。受物理学原理的启发，我们提倡使用具有保守哈密顿神经流的GNNs来构建对抗攻击鲁棒的网络。在各种对抗攻击下，通过对几个基准数据集进行大量数值实验比较了不同神经流GNNs的对抗鲁棒性。实验证明，利用具有李亚普诺夫稳定性的保守哈密顿流的GNNs在对抗扰动方面大幅提高了鲁棒性。",
    "tldr": "本文通过引入保守哈密顿神经流构建了对抗攻击鲁棒的图神经网络，从而提高了对抗扰动下的鲁棒性。"
}