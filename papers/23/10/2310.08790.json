{
    "title": "Price of Stability in Quality-Aware Federated Learning. (arXiv:2310.08790v1 [cs.LG])",
    "abstract": "Federated Learning (FL) is a distributed machine learning scheme that enables clients to train a shared global model without exchanging local data. The presence of label noise can severely degrade the FL performance, and some existing studies have focused on algorithm design for label denoising. However, they ignored the important issue that clients may not apply costly label denoising strategies due to them being self-interested and having heterogeneous valuations on the FL performance. To fill this gap, we model the clients' interactions as a novel label denoising game and characterize its equilibrium. We also analyze the price of stability, which quantifies the difference in the system performance (e.g., global model accuracy, social welfare) between the equilibrium outcome and the socially optimal solution. We prove that the equilibrium outcome always leads to a lower global model accuracy than the socially optimal solution does. We further design an efficient algorithm to compute ",
    "link": "http://arxiv.org/abs/2310.08790",
    "context": "Title: Price of Stability in Quality-Aware Federated Learning. (arXiv:2310.08790v1 [cs.LG])\nAbstract: Federated Learning (FL) is a distributed machine learning scheme that enables clients to train a shared global model without exchanging local data. The presence of label noise can severely degrade the FL performance, and some existing studies have focused on algorithm design for label denoising. However, they ignored the important issue that clients may not apply costly label denoising strategies due to them being self-interested and having heterogeneous valuations on the FL performance. To fill this gap, we model the clients' interactions as a novel label denoising game and characterize its equilibrium. We also analyze the price of stability, which quantifies the difference in the system performance (e.g., global model accuracy, social welfare) between the equilibrium outcome and the socially optimal solution. We prove that the equilibrium outcome always leads to a lower global model accuracy than the socially optimal solution does. We further design an efficient algorithm to compute ",
    "path": "papers/23/10/2310.08790.json",
    "total_tokens": 949,
    "translated_title": "质量感知联邦学习中的稳定成本",
    "translated_abstract": "联邦学习是一种分布式机器学习方案，可以使客户端在不交换本地数据的情况下训练一个共享的全局模型。标签噪声的存在会严重影响联邦学习的性能，一些现有研究已经关注了用于标签去噪的算法设计。然而，它们忽视了一个重要问题，即由于自利性和对联邦学习性能的异质估值，客户端可能不会应用昂贵的标签去噪策略。为了填补这一空白，我们将客户端之间的互动建模为一种新颖的标签去噪博弈，并确定其均衡状态。我们还分析了稳定成本，该成本用来衡量均衡结果与社会最优解之间的系统性能差异（例如，全局模型准确度、社会福利）。我们证明了均衡结果的全局模型准确度始终低于社会最优解。我们进一步设计了一种高效算法来计算。",
    "tldr": "本论文提出了一种质量感知的联邦学习方案，研究了标签噪声对系统性能的影响，并设计了一种游戏模型来理解客户端的行为。研究结果表明均衡结果的全局模型准确度低于社会最优解，并提出了一种高效算法来计算。"
}