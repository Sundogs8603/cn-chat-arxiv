{
    "title": "TRAM: Bridging Trust Regions and Sharpness Aware Minimization. (arXiv:2310.03646v1 [cs.LG])",
    "abstract": "By reducing the curvature of the loss surface in the parameter space, Sharpness-aware minimization (SAM) yields widespread robustness improvement under domain transfer. Instead of focusing on parameters, however, this work considers the transferability of representations as the optimization target for out-of-domain generalization in a fine-tuning setup. To encourage the retention of transferable representations, we consider trust region-based fine-tuning methods, which exploit task-specific skills without forgetting task-agnostic representations from pre-training. We unify parameter- and representation-space smoothing approaches by using trust region bounds to inform SAM-style regularizers on both of these optimization surfaces. We propose Trust Region Aware Minimization (TRAM), a fine-tuning algorithm that optimizes for flat minima and smooth, informative representations without forgetting pre-trained structure. We find that TRAM outperforms both sharpness-aware and trust region-based",
    "link": "http://arxiv.org/abs/2310.03646",
    "context": "Title: TRAM: Bridging Trust Regions and Sharpness Aware Minimization. (arXiv:2310.03646v1 [cs.LG])\nAbstract: By reducing the curvature of the loss surface in the parameter space, Sharpness-aware minimization (SAM) yields widespread robustness improvement under domain transfer. Instead of focusing on parameters, however, this work considers the transferability of representations as the optimization target for out-of-domain generalization in a fine-tuning setup. To encourage the retention of transferable representations, we consider trust region-based fine-tuning methods, which exploit task-specific skills without forgetting task-agnostic representations from pre-training. We unify parameter- and representation-space smoothing approaches by using trust region bounds to inform SAM-style regularizers on both of these optimization surfaces. We propose Trust Region Aware Minimization (TRAM), a fine-tuning algorithm that optimizes for flat minima and smooth, informative representations without forgetting pre-trained structure. We find that TRAM outperforms both sharpness-aware and trust region-based",
    "path": "papers/23/10/2310.03646.json",
    "total_tokens": 979,
    "translated_title": "TRAM: 桥接信任区域和锐度感知最小化",
    "translated_abstract": "通过减少参数空间中损失曲面的曲率，锐度感知最小化（SAM）在领域转移下提供了广泛的鲁棒性改进。然而，本文不是关注参数，而是考虑到表示的可转移性作为优化目标，在微调设置中实现领域外泛化。为了鼓励保留可转移的表示，我们考虑到基于信任区域的微调方法，这些方法利用任务特定的技能，而不会忘记预训练的任务无关表示。我们通过使用信任区域边界在这两种优化表面上通知SAM风格的正则化器，统一了参数和表示空间平滑方法。我们提出了Trust Region Aware Minimization (TRAM)，一种优化平坦的极小值和平滑、有信息量的表示的微调算法，而不会忘记预先训练的结构。我们发现，TRAM优于锐度感知和基于信任区域的方法。",
    "tldr": "TRAM是一种桥接信任区域和锐度感知最小化的算法，通过减少损失曲面的曲率来提供鲁棒性改进。它通过在微调过程中优化可转移的表示来实现领域外泛化，并且通过结合信任区域方法和SAM风格的正则化器来统一参数和表示空间平滑方法。TRAM在保持预训练结构的同时实现了平坦的极小值和平滑、有信息量的表示。"
}