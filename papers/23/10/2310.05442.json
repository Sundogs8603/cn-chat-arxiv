{
    "title": "Establishing Trustworthiness: Rethinking Tasks and Model Evaluation. (arXiv:2310.05442v2 [cs.CL] UPDATED)",
    "abstract": "Language understanding is a multi-faceted cognitive capability, which the Natural Language Processing (NLP) community has striven to model computationally for decades. Traditionally, facets of linguistic intelligence have been compartmentalized into tasks with specialized model architectures and corresponding evaluation protocols. With the advent of large language models (LLMs) the community has witnessed a dramatic shift towards general purpose, task-agnostic approaches powered by generative models. As a consequence, the traditional compartmentalized notion of language tasks is breaking down, followed by an increasing challenge for evaluation and analysis. At the same time, LLMs are being deployed in more real-world scenarios, including previously unforeseen zero-shot setups, increasing the need for trustworthy and reliable systems. Therefore, we argue that it is time to rethink what constitutes tasks and model evaluation in NLP, and pursue a more holistic view on language, placing tr",
    "link": "http://arxiv.org/abs/2310.05442",
    "context": "Title: Establishing Trustworthiness: Rethinking Tasks and Model Evaluation. (arXiv:2310.05442v2 [cs.CL] UPDATED)\nAbstract: Language understanding is a multi-faceted cognitive capability, which the Natural Language Processing (NLP) community has striven to model computationally for decades. Traditionally, facets of linguistic intelligence have been compartmentalized into tasks with specialized model architectures and corresponding evaluation protocols. With the advent of large language models (LLMs) the community has witnessed a dramatic shift towards general purpose, task-agnostic approaches powered by generative models. As a consequence, the traditional compartmentalized notion of language tasks is breaking down, followed by an increasing challenge for evaluation and analysis. At the same time, LLMs are being deployed in more real-world scenarios, including previously unforeseen zero-shot setups, increasing the need for trustworthy and reliable systems. Therefore, we argue that it is time to rethink what constitutes tasks and model evaluation in NLP, and pursue a more holistic view on language, placing tr",
    "path": "papers/23/10/2310.05442.json",
    "total_tokens": 847,
    "translated_title": "建立可信度：重新思考任务和模型评估",
    "translated_abstract": "语言理解是一种多方面的认知能力，自然语言处理（NLP）社区一直在努力将其计算建模几十年。传统上，语言智能的多个方面被分隔成具有专门模型架构和相应评估协议的任务。随着大型语言模型（LLMs）的出现，社区目睹了一种通过生成模型驱动的通用目标无关方法的戏剧性转变。因此，传统的分隔式语言任务概念正在被打破，随之而来的是对评估和分析的越来越大的挑战。与此同时，LLMs正在更多现实世界的场景中进行部署，包括以前未预料到的零-shot设定，增加了对可信和可靠系统的需求。因此，我们认为是时候重新思考NLP中任务和模型评估的定义，并追求对语言的更全面的视角，将可信度放在首位。",
    "tldr": "重新思考自然语言处理中的任务和模型评估，以应对通用目标无关方法引发的挑战，并且关注在不断增加的实际应用中建立可信度的需求。"
}