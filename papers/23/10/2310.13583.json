{
    "title": "Improving Cross-Lingual Transfer through Subtree-Aware Word Reordering. (arXiv:2310.13583v1 [cs.CL])",
    "abstract": "Despite the impressive growth of the abilities of multilingual language models, such as XLM-R and mT5, it has been shown that they still face difficulties when tackling typologically-distant languages, particularly in the low-resource setting. One obstacle for effective cross-lingual transfer is variability in word-order patterns. It can be potentially mitigated via sourceor target-side word reordering, and numerous approaches to reordering have been proposed. However, they rely on language-specific rules, work on the level of POS tags, or only target the main clause, leaving subordinate clauses intact. To address these limitations, we present a new powerful reordering method, defined in terms of Universal Dependencies, that is able to learn fine-grained word-order patterns conditioned on the syntactic context from a small amount of annotated data and can be applied at all levels of the syntactic tree. We conduct experiments on a diverse set of tasks and show that our method consiste",
    "link": "http://arxiv.org/abs/2310.13583",
    "context": "Title: Improving Cross-Lingual Transfer through Subtree-Aware Word Reordering. (arXiv:2310.13583v1 [cs.CL])\nAbstract: Despite the impressive growth of the abilities of multilingual language models, such as XLM-R and mT5, it has been shown that they still face difficulties when tackling typologically-distant languages, particularly in the low-resource setting. One obstacle for effective cross-lingual transfer is variability in word-order patterns. It can be potentially mitigated via sourceor target-side word reordering, and numerous approaches to reordering have been proposed. However, they rely on language-specific rules, work on the level of POS tags, or only target the main clause, leaving subordinate clauses intact. To address these limitations, we present a new powerful reordering method, defined in terms of Universal Dependencies, that is able to learn fine-grained word-order patterns conditioned on the syntactic context from a small amount of annotated data and can be applied at all levels of the syntactic tree. We conduct experiments on a diverse set of tasks and show that our method consiste",
    "path": "papers/23/10/2310.13583.json",
    "total_tokens": 903,
    "translated_title": "通过子树感知的单词重排序提升跨语言转移能力",
    "translated_abstract": "尽管多语言语言模型（如XLM-R和mT5）的能力有了令人印象深刻的增长，但已经发现它们在处理语言差异较大的语言特别是在资源匮乏的情况下仍然存在困难。有效的跨语言转移的一个障碍是单词顺序模式的可变性。这可以通过源端或目标端的单词重排序来减轻，并且已经提出了许多重排序方法。然而，它们依赖于特定语言的规则，工作在POS标签的级别上，或者只针对主句，而保持从属从句不变。为了解决这些限制，我们提出了一种新的强大的重排序方法，它基于通用依赖关系来定义，能够利用少量标注数据学习以句法上下文为条件的细粒度单词顺序模式，并且可以应用于句法树的所有层级。我们在各种任务上进行实验，并展示了我们的方法的一致性。",
    "tldr": "通过子树感知的单词重排序方法能够提高跨语言转移的能力，并克服了现有方法中语言特定规则、POS标签级别或只针对主句的限制。",
    "en_tdlr": "The paper proposes a powerful method for word reordering based on Universal Dependencies, which improves cross-lingual transfer and overcomes limitations of existing methods such as language-specific rules, POS tag-level processing, and focusing only on main clauses."
}