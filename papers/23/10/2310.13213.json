{
    "title": "MultiCoNER v2: a Large Multilingual dataset for Fine-grained and Noisy Named Entity Recognition. (arXiv:2310.13213v1 [cs.CL])",
    "abstract": "We present MULTICONER V2, a dataset for fine-grained Named Entity Recognition covering 33 entity classes across 12 languages, in both monolingual and multilingual settings. This dataset aims to tackle the following practical challenges in NER: (i) effective handling of fine-grained classes that include complex entities like movie titles, and (ii) performance degradation due to noise generated from typing mistakes or OCR errors. The dataset is compiled from open resources like Wikipedia and Wikidata, and is publicly available. Evaluation based on the XLM-RoBERTa baseline highlights the unique challenges posed by MULTICONER V2: (i) the fine-grained taxonomy is challenging, where the scores are low with macro-F1=0.63 (across all languages), and (ii) the corruption strategy significantly impairs performance, with entity corruption resulting in 9% lower performance relative to non-entity corruptions across all languages. This highlights the greater impact of entity noise in contrast to cont",
    "link": "http://arxiv.org/abs/2310.13213",
    "context": "Title: MultiCoNER v2: a Large Multilingual dataset for Fine-grained and Noisy Named Entity Recognition. (arXiv:2310.13213v1 [cs.CL])\nAbstract: We present MULTICONER V2, a dataset for fine-grained Named Entity Recognition covering 33 entity classes across 12 languages, in both monolingual and multilingual settings. This dataset aims to tackle the following practical challenges in NER: (i) effective handling of fine-grained classes that include complex entities like movie titles, and (ii) performance degradation due to noise generated from typing mistakes or OCR errors. The dataset is compiled from open resources like Wikipedia and Wikidata, and is publicly available. Evaluation based on the XLM-RoBERTa baseline highlights the unique challenges posed by MULTICONER V2: (i) the fine-grained taxonomy is challenging, where the scores are low with macro-F1=0.63 (across all languages), and (ii) the corruption strategy significantly impairs performance, with entity corruption resulting in 9% lower performance relative to non-entity corruptions across all languages. This highlights the greater impact of entity noise in contrast to cont",
    "path": "papers/23/10/2310.13213.json",
    "total_tokens": 1010,
    "translated_title": "MultiCoNER v2: 一个用于细粒度和含噪音命名实体识别的大型多语言数据集",
    "translated_abstract": "我们提出了MULTICONER V2，这是一个细粒度命名实体识别的数据集，涵盖了12种语言中的33个实体类别，包括单语和多语境的设置。该数据集旨在解决NER中的以下实际挑战：(i) 有效处理包括电影标题等复杂实体的细粒度类别，以及(ii) 由于打字错误或OCR错误而产生的噪音导致性能下降。该数据集是从维基百科和维基数据等公开资源中编译而成，并可公开获取。基于XLM-RoBERTa基准的评估突出了MULTICONER V2所面临的独特挑战：(i)细粒度分类是具有挑战性的，在所有语言中的宏F1得分较低，为0.63；以及(ii)损坏策略显著影响性能，实体损坏导致的性能比非实体损坏低9%。这突显了与上下文相关的实体噪音相比于其他噪音对性能的更大影响。",
    "tldr": "MultiCoNER v2是一个大型多语言数据集，用于细粒度和含噪音的命名实体识别。它解决了细粒度类别处理和噪音导致的性能下降的实际挑战。评估结果表明，细粒度分类具有挑战性，而实体损坏对性能影响更大。",
    "en_tdlr": "MultiCoNER v2 is a large multilingual dataset for fine-grained and noisy named entity recognition. It tackles the practical challenges of handling fine-grained classes and performance degradation caused by noise. The evaluation highlights the difficulty of fine-grained classification and the significant impact of entity corruption on performance."
}