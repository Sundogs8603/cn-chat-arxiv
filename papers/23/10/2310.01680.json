{
    "title": "Keypoint-Augmented Self-Supervised Learning for Medical Image Segmentation with Limited Annotation. (arXiv:2310.01680v1 [cs.CV])",
    "abstract": "Pretraining CNN models (i.e., UNet) through self-supervision has become a powerful approach to facilitate medical image segmentation under low annotation regimes. Recent contrastive learning methods encourage similar global representations when the same image undergoes different transformations, or enforce invariance across different image/patch features that are intrinsically correlated. However, CNN-extracted global and local features are limited in capturing long-range spatial dependencies that are essential in biological anatomy. To this end, we present a keypoint-augmented fusion layer that extracts representations preserving both short- and long-range self-attention. In particular, we augment the CNN feature map at multiple scales by incorporating an additional input that learns long-range spatial self-attention among localized keypoint features. Further, we introduce both global and local self-supervised pretraining for the framework. At the global scale, we obtain global repres",
    "link": "http://arxiv.org/abs/2310.01680",
    "context": "Title: Keypoint-Augmented Self-Supervised Learning for Medical Image Segmentation with Limited Annotation. (arXiv:2310.01680v1 [cs.CV])\nAbstract: Pretraining CNN models (i.e., UNet) through self-supervision has become a powerful approach to facilitate medical image segmentation under low annotation regimes. Recent contrastive learning methods encourage similar global representations when the same image undergoes different transformations, or enforce invariance across different image/patch features that are intrinsically correlated. However, CNN-extracted global and local features are limited in capturing long-range spatial dependencies that are essential in biological anatomy. To this end, we present a keypoint-augmented fusion layer that extracts representations preserving both short- and long-range self-attention. In particular, we augment the CNN feature map at multiple scales by incorporating an additional input that learns long-range spatial self-attention among localized keypoint features. Further, we introduce both global and local self-supervised pretraining for the framework. At the global scale, we obtain global repres",
    "path": "papers/23/10/2310.01680.json",
    "total_tokens": 914,
    "translated_title": "通过关键点增强的自监督学习在有限注释情况下的医学图像分割",
    "translated_abstract": "通过自监督训练CNN模型（如UNet）已成为在低注释环境下促进医学图像分割的强大方法。最近的对比学习方法鼓励相同图像经历不同变换时的类似全局表示，或在本质上相关的不同图像/补丁特征之间实施不变性。然而，通过CNN提取的全局和局部特征在捕捉生物解剖学中至关重要的长程空间依赖性方面存在局限性。为此，我们提出了一个关键点增强的融合层，可以提取既保留短程又保留长程自注意力的表示。特别地，我们通过增加一个额外的输入，在多个尺度上增强CNN特征图，该输入学习了局部关键点特征之间的长程空间自注意力。此外，我们还引入了全局和局部自监督预训练框架。在全局尺度上，我们获得了全局的表示。",
    "tldr": "本论文提出了一种关键点增强的自监督学习方法，通过在医学图像分割中引入长程空间自注意力，同时运用全局和局部自监督预训练，以提高CNN模型在低注释情况下的性能。"
}