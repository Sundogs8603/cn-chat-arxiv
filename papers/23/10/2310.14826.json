{
    "title": "Sharp error bounds for imbalanced classification: how many examples in the minority class?. (arXiv:2310.14826v1 [stat.ML])",
    "abstract": "When dealing with imbalanced classification data, reweighting the loss function is a standard procedure allowing to equilibrate between the true positive and true negative rates within the risk measure. Despite significant theoretical work in this area, existing results do not adequately address a main challenge within the imbalanced classification framework, which is the negligible size of one class in relation to the full sample size and the need to rescale the risk function by a probability tending to zero. To address this gap, we present two novel contributions in the setting where the rare class probability approaches zero: (1) a non asymptotic fast rate probability bound for constrained balanced empirical risk minimization, and (2) a consistent upper bound for balanced nearest neighbors estimates. Our findings provide a clearer understanding of the benefits of class-weighting in realistic settings, opening new avenues for further research in this field.",
    "link": "http://arxiv.org/abs/2310.14826",
    "context": "Title: Sharp error bounds for imbalanced classification: how many examples in the minority class?. (arXiv:2310.14826v1 [stat.ML])\nAbstract: When dealing with imbalanced classification data, reweighting the loss function is a standard procedure allowing to equilibrate between the true positive and true negative rates within the risk measure. Despite significant theoretical work in this area, existing results do not adequately address a main challenge within the imbalanced classification framework, which is the negligible size of one class in relation to the full sample size and the need to rescale the risk function by a probability tending to zero. To address this gap, we present two novel contributions in the setting where the rare class probability approaches zero: (1) a non asymptotic fast rate probability bound for constrained balanced empirical risk minimization, and (2) a consistent upper bound for balanced nearest neighbors estimates. Our findings provide a clearer understanding of the benefits of class-weighting in realistic settings, opening new avenues for further research in this field.",
    "path": "papers/23/10/2310.14826.json",
    "total_tokens": 954,
    "translated_title": "针对不平衡分类的尖锐误差界：少数类中有多少样本？",
    "translated_abstract": "在处理不平衡分类数据时，重新加权损失函数是一种标准的方法，可以在风险度量中平衡真正的正例率和真正的负例率。尽管在这个领域有重要的理论工作，但现有的结果并没有充分解决不平衡分类框架中的主要挑战，即相对于整个样本大小来说一个类的可忽略的大小以及需要通过趋近于零的概率来重新调整风险函数的问题。为了解决这个问题，我们在稀有类概率趋近于零的情况下提出了两个新的贡献：（1）用于约束平衡经验风险最小化的非渐近快速率概率界限，以及（2）用于平衡最近邻估计的一致上界。我们的发现更清楚地说明了类别加权在实际情况下的益处，为这个领域的进一步研究开辟了新的途径。",
    "tldr": "该论文提出了两个在稀有类概率趋近于零的情况下的新贡献，分别是一种非渐近快速率概率界限和一种一致上界估计方法，这些发现为在实际情况下的类别加权提供了更清晰的理解，为进一步的研究提供了新的方向。"
}