{
    "title": "Multi-modal Gaussian Process Variational Autoencoders for Neural and Behavioral Data. (arXiv:2310.03111v1 [cs.LG])",
    "abstract": "Characterizing the relationship between neural population activity and behavioral data is a central goal of neuroscience. While latent variable models (LVMs) are successful in describing high-dimensional time-series data, they are typically only designed for a single type of data, making it difficult to identify structure shared across different experimental data modalities. Here, we address this shortcoming by proposing an unsupervised LVM which extracts temporally evolving shared and independent latents for distinct, simultaneously recorded experimental modalities. We do this by combining Gaussian Process Factor Analysis (GPFA), an interpretable LVM for neural spiking data with temporally smooth latent space, with Gaussian Process Variational Autoencoders (GP-VAEs), which similarly use a GP prior to characterize correlations in a latent space, but admit rich expressivity due to a deep neural network mapping to observations. We achieve interpretability in our model by partitioning lat",
    "link": "http://arxiv.org/abs/2310.03111",
    "context": "Title: Multi-modal Gaussian Process Variational Autoencoders for Neural and Behavioral Data. (arXiv:2310.03111v1 [cs.LG])\nAbstract: Characterizing the relationship between neural population activity and behavioral data is a central goal of neuroscience. While latent variable models (LVMs) are successful in describing high-dimensional time-series data, they are typically only designed for a single type of data, making it difficult to identify structure shared across different experimental data modalities. Here, we address this shortcoming by proposing an unsupervised LVM which extracts temporally evolving shared and independent latents for distinct, simultaneously recorded experimental modalities. We do this by combining Gaussian Process Factor Analysis (GPFA), an interpretable LVM for neural spiking data with temporally smooth latent space, with Gaussian Process Variational Autoencoders (GP-VAEs), which similarly use a GP prior to characterize correlations in a latent space, but admit rich expressivity due to a deep neural network mapping to observations. We achieve interpretability in our model by partitioning lat",
    "path": "papers/23/10/2310.03111.json",
    "total_tokens": 961,
    "translated_title": "多模态高斯过程变分自编码器用于神经和行为数据",
    "translated_abstract": "描述神经群体活动和行为数据之间的关系是神经科学的核心目标。虽然潜在变量模型（LVMs）在描述高维时间序列数据方面取得了成功，但它们通常只用于单一类型的数据，这使得难以识别不同实验数据模态之间的共享结构。在这里，我们通过提出一种无监督的LVM来解决这个缺点，该模型提取了不同、同时记录的实验模态的时间演化共享和独立潜变量。我们通过将高斯过程因子分析（GPFA），一种解释性的用于神经尖峰数据的LVM，并具有时间平滑潜空间，与高斯过程变分自编码器（GP-VAEs）相结合来实现这一点，GP-VAEs同样使用高斯先验来描述潜空间中的相关性，但由于深度神经网络映射到观测值具有丰富的表达能力。我们通过将潜变量分区来实现模型的可解释性。",
    "tldr": "该论文介绍了一种多模态高斯过程变分自编码器（GP-VAEs）的方法，用于描述神经和行为数据之间的关系。该方法通过将高斯过程因子分析（GPFA）和深度神经网络相结合，能够提取不同实验模态的共享和独立潜变量，并且具有解释能力。",
    "en_tdlr": "This paper introduces a multi-modal Gaussian Process Variational Autoencoder (GP-VAEs) approach for characterizing the relationship between neural and behavioral data. By combining Gaussian Process Factor Analysis (GPFA) with deep neural networks, this method extracts shared and independent latent variables for different experimental modalities and achieves interpretability."
}