{
    "title": "Towards Self-Interpretable Graph-Level Anomaly Detection. (arXiv:2310.16520v1 [cs.LG])",
    "abstract": "Graph-level anomaly detection (GLAD) aims to identify graphs that exhibit notable dissimilarity compared to the majority in a collection. However, current works primarily focus on evaluating graph-level abnormality while failing to provide meaningful explanations for the predictions, which largely limits their reliability and application scope. In this paper, we investigate a new challenging problem, explainable GLAD, where the learning objective is to predict the abnormality of each graph sample with corresponding explanations, i.e., the vital subgraph that leads to the predictions. To address this challenging problem, we propose a Self-Interpretable Graph aNomaly dETection model (SIGNET for short) that detects anomalous graphs as well as generates informative explanations simultaneously. Specifically, we first introduce the multi-view subgraph information bottleneck (MSIB) framework, serving as the design basis of our self-interpretable GLAD approach. This way SIGNET is able to not o",
    "link": "http://arxiv.org/abs/2310.16520",
    "context": "Title: Towards Self-Interpretable Graph-Level Anomaly Detection. (arXiv:2310.16520v1 [cs.LG])\nAbstract: Graph-level anomaly detection (GLAD) aims to identify graphs that exhibit notable dissimilarity compared to the majority in a collection. However, current works primarily focus on evaluating graph-level abnormality while failing to provide meaningful explanations for the predictions, which largely limits their reliability and application scope. In this paper, we investigate a new challenging problem, explainable GLAD, where the learning objective is to predict the abnormality of each graph sample with corresponding explanations, i.e., the vital subgraph that leads to the predictions. To address this challenging problem, we propose a Self-Interpretable Graph aNomaly dETection model (SIGNET for short) that detects anomalous graphs as well as generates informative explanations simultaneously. Specifically, we first introduce the multi-view subgraph information bottleneck (MSIB) framework, serving as the design basis of our self-interpretable GLAD approach. This way SIGNET is able to not o",
    "path": "papers/23/10/2310.16520.json",
    "total_tokens": 855,
    "translated_title": "面向自解释图级异常检测的研究",
    "translated_abstract": "图级异常检测旨在识别与集合中的大多数图相比具有显著差异的图形。然而，当前的研究主要关注评估图级异常性，而未能提供有意义的预测解释，这在很大程度上限制了它们的可靠性和应用范围。在本文中，我们研究了一个新的有挑战性的问题，即可解释图级异常检测，其中学习目标是预测每个图样本的异常性，并提供相应的解释，即导致预测的关键子图。为了解决这个具有挑战性的问题，我们提出了一种自解释图级异常检测模型（SIGNET），它可以同时检测异常图并生成信息丰富的解释。具体而言，我们首先引入了多视图子图信息瓶颈（MSIB）框架，作为我们自解释图级异常检测方法的设计基础。",
    "tldr": "本文提出了一个自解释图级异常检测模型（SIGNET），能够识别异常图并生成有意义的解释，解决了当前图级异常检测方法无法提供有效解释的问题。",
    "en_tdlr": "This paper proposes a self-interpretable graph-level anomaly detection model (SIGNET) that can identify anomalous graphs and generate meaningful explanations, addressing the issue of current graph-level anomaly detection methods not providing effective explanations."
}