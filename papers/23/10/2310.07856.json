{
    "title": "Assessing Evaluation Metrics for Neural Test Oracle Generation. (arXiv:2310.07856v1 [cs.CL])",
    "abstract": "In this work, we revisit existing oracle generation studies plus ChatGPT to empirically investigate the current standing of their performance in both NLG-based and test adequacy metrics. Specifically, we train and run four state-of-the-art test oracle generation models on five NLG-based and two test adequacy metrics for our analysis. We apply two different correlation analyses between these two different sets of metrics. Surprisingly, we found no significant correlation between the NLG-based metrics and test adequacy metrics. For instance, oracles generated from ChatGPT on the project activemq-artemis had the highest performance on all the NLG-based metrics among the studied NOGs, however, it had the most number of projects with a decrease in test adequacy metrics compared to all the studied NOGs. We further conduct a qualitative analysis to explore the reasons behind our observations, we found that oracles with high NLG-based metrics but low test adequacy metrics tend to have complex ",
    "link": "http://arxiv.org/abs/2310.07856",
    "context": "Title: Assessing Evaluation Metrics for Neural Test Oracle Generation. (arXiv:2310.07856v1 [cs.CL])\nAbstract: In this work, we revisit existing oracle generation studies plus ChatGPT to empirically investigate the current standing of their performance in both NLG-based and test adequacy metrics. Specifically, we train and run four state-of-the-art test oracle generation models on five NLG-based and two test adequacy metrics for our analysis. We apply two different correlation analyses between these two different sets of metrics. Surprisingly, we found no significant correlation between the NLG-based metrics and test adequacy metrics. For instance, oracles generated from ChatGPT on the project activemq-artemis had the highest performance on all the NLG-based metrics among the studied NOGs, however, it had the most number of projects with a decrease in test adequacy metrics compared to all the studied NOGs. We further conduct a qualitative analysis to explore the reasons behind our observations, we found that oracles with high NLG-based metrics but low test adequacy metrics tend to have complex ",
    "path": "papers/23/10/2310.07856.json",
    "total_tokens": 908,
    "translated_title": "评估神经测试Oracle生成的评估指标",
    "translated_abstract": "在这项工作中，我们重新审视了现有的Oracle生成研究和ChatGPT，并从经验上调查了它们在基于自然语言生成的度量和测试充分性度量方面的性能。具体而言，我们对五种基于自然语言生成的度量和两种测试充分性度量进行了四种最先进的测试Oracle生成模型的训练和运行，以进行分析。令人惊讶的是，我们发现基于自然语言的度量和测试充分性度量之间没有显著的相关性。例如，在研究中的所有NOG中，ChatGPT在project activemq-artemis上生成的oracle在所有基于自然语言的度量中具有最高的性能，然而，在测试充分性度量上，它有最多的项目表现出下降。我们进一步进行了定性分析，探索了我们观察结果背后的原因，我们发现基于自然语言的度量较高但测试充分性度量较低的oracle往往具有复杂的特征。",
    "tldr": "评估了神经测试Oracle生成的评估指标，在基于自然语言生成的度量和测试充分性度量之间发现了没有显著相关性。基于自然语言生成的度量高但测试充分性度量低的oracle往往具有复杂的特征。",
    "en_tdlr": "We assessed evaluation metrics for neural test oracle generation and found no significant correlation between NLG-based metrics and test adequacy metrics. Oracles with high NLG-based metrics but low test adequacy metrics tend to have complex features."
}