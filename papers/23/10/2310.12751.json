{
    "title": "Character-level Chinese Backpack Language Models. (arXiv:2310.12751v1 [cs.CL])",
    "abstract": "The Backpack is a Transformer alternative shown to improve interpretability in English language modeling by decomposing predictions into a weighted sum of token sense components. However, Backpacks' reliance on token-defined meaning raises questions as to their potential for languages other than English, a language for which subword tokenization provides a reasonable approximation for lexical items. In this work, we train, evaluate, interpret, and control Backpack language models in character-tokenized Chinese, in which words are often composed of many characters. We find that our (134M parameter) Chinese Backpack language model performs comparably to a (104M parameter) Transformer, and learns rich character-level meanings that log-additively compose to form word meanings. In SimLex-style lexical semantic evaluations, simple averages of Backpack character senses outperform input embeddings from a Transformer. We find that complex multi-character meanings are often formed by using the s",
    "link": "http://arxiv.org/abs/2310.12751",
    "context": "Title: Character-level Chinese Backpack Language Models. (arXiv:2310.12751v1 [cs.CL])\nAbstract: The Backpack is a Transformer alternative shown to improve interpretability in English language modeling by decomposing predictions into a weighted sum of token sense components. However, Backpacks' reliance on token-defined meaning raises questions as to their potential for languages other than English, a language for which subword tokenization provides a reasonable approximation for lexical items. In this work, we train, evaluate, interpret, and control Backpack language models in character-tokenized Chinese, in which words are often composed of many characters. We find that our (134M parameter) Chinese Backpack language model performs comparably to a (104M parameter) Transformer, and learns rich character-level meanings that log-additively compose to form word meanings. In SimLex-style lexical semantic evaluations, simple averages of Backpack character senses outperform input embeddings from a Transformer. We find that complex multi-character meanings are often formed by using the s",
    "path": "papers/23/10/2310.12751.json",
    "total_tokens": 859,
    "translated_title": "字符级中文背包语言模型",
    "translated_abstract": "背包是一种Transformer的替代方法，通过将预测分解为令牌意义组件的加权和来提高英语语言模型的可解释性。然而，背包对于除英语以外的其他语言，特别是对于词项的子词标记化提供合理近似的语言而言，它们对令牌定义的含义的依赖性引发了一些问题。在这项工作中，我们训练、评估、解释和控制字符标记化的中文背包语言模型，其中词通常由多个字符组成。我们发现，我们的（134M参数）中文背包语言模型与（104M参数）Transformer相比表现相当，并学习到了丰富的字符级别含义，这些含义以对数加法组合成词义。在类似SimLex的词汇语义评估中，背包字符意义的简单平均值胜过Transformer的输入嵌入。我们发现，复杂的多字符含义通常是通过使用...",
    "tldr": "通过对中文进行字符标记化，我们训练了一个比Transformer更具解释性的中文背包语言模型，该模型学习到了丰富的字符级别含义，其组合形成词义，并且在词汇语义评估中胜过Transformer的输入嵌入。"
}