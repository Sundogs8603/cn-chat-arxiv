{
    "title": "Saliency-Guided Hidden Associative Replay for Continual Learning. (arXiv:2310.04334v1 [cs.LG])",
    "abstract": "Continual Learning is a burgeoning domain in next-generation AI, focusing on training neural networks over a sequence of tasks akin to human learning. While CL provides an edge over traditional supervised learning, its central challenge remains to counteract catastrophic forgetting and ensure the retention of prior tasks during subsequent learning. Amongst various strategies to tackle this, replay based methods have emerged as preeminent, echoing biological memory mechanisms. However, these methods are memory intensive, often preserving entire data samples, an approach inconsistent with humans selective memory retention of salient experiences. While some recent works have explored the storage of only significant portions of data in episodic memory, the inherent nature of partial data necessitates innovative retrieval mechanisms. Current solutions, like inpainting, approximate full data reconstruction from partial cues, a method that diverges from genuine human memory processes. Address",
    "link": "http://arxiv.org/abs/2310.04334",
    "context": "Title: Saliency-Guided Hidden Associative Replay for Continual Learning. (arXiv:2310.04334v1 [cs.LG])\nAbstract: Continual Learning is a burgeoning domain in next-generation AI, focusing on training neural networks over a sequence of tasks akin to human learning. While CL provides an edge over traditional supervised learning, its central challenge remains to counteract catastrophic forgetting and ensure the retention of prior tasks during subsequent learning. Amongst various strategies to tackle this, replay based methods have emerged as preeminent, echoing biological memory mechanisms. However, these methods are memory intensive, often preserving entire data samples, an approach inconsistent with humans selective memory retention of salient experiences. While some recent works have explored the storage of only significant portions of data in episodic memory, the inherent nature of partial data necessitates innovative retrieval mechanisms. Current solutions, like inpainting, approximate full data reconstruction from partial cues, a method that diverges from genuine human memory processes. Address",
    "path": "papers/23/10/2310.04334.json",
    "total_tokens": 935,
    "translated_title": "基于显著性引导的隐含关联回放用于持续学习",
    "translated_abstract": "持续学习是下一代人工智能中一个新兴的领域，专注于训练神经网络以类似于人类学习的任务序列。虽然持续学习相比传统的监督学习具有优势，但其主要挑战仍然是抵抗灾难性遗忘并确保在后续学习过程中保留先前任务的相关知识。在各种解决方法中，基于回放的方法已经成为卓越的方法，模仿了生物记忆机制。然而，这些方法在内存使用方面往往是密集的，通常保留整个数据样本，这种方法与人类选择性记忆保留显著经验的方式不一致。虽然最近的一些研究探索了只在情景记忆中存储重要数据部分的方法，但部分数据的固有性质需要创新的检索机制。当前的解决方案，如图像修复，试图通过部分线索来近似完整数据重建，这种方法与真实的人类记忆过程不一致。",
    "tldr": "该论文提出了一种基于显著性引导的隐含关联回放方法，用于解决持续学习中的灾难性遗忘问题。这种方法通过存储和检索重要的数据部分，模仿了人类记忆过程，与传统的完整数据存储方法不同。"
}