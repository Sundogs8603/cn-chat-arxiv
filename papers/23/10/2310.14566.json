{
    "title": "HallusionBench: An Advanced Diagnostic Suite for Entangled Language Hallucination and Visual Illusion in Large Vision-Language Models",
    "abstract": "arXiv:2310.14566v3 Announce Type: replace-cross  Abstract: We introduce HallusionBench, a comprehensive benchmark designed for the evaluation of image-context reasoning. This benchmark presents significant challenges to advanced large visual-language models (LVLMs), such as GPT-4V(Vision), Gemini Pro Vision, and LLaVA-1.5, by emphasizing nuanced understanding and interpretation of visual data. The benchmark comprises 346 images paired with 1129 questions, all meticulously crafted by human experts. We introduce a novel structure for these visual questions designed to establish control groups. This structure enables us to conduct a quantitative analysis of the models' response tendencies, logical consistency, and various failure modes. In our evaluation on HallusionBench, we benchmarked 14 different models, highlighting a 31.42% question-pair accuracy achieved by the state-of-the-art GPT-4V. Notably, all other evaluated models achieve accuracy below 16%. Moreover, our analysis not only h",
    "link": "https://arxiv.org/abs/2310.14566",
    "context": "Title: HallusionBench: An Advanced Diagnostic Suite for Entangled Language Hallucination and Visual Illusion in Large Vision-Language Models\nAbstract: arXiv:2310.14566v3 Announce Type: replace-cross  Abstract: We introduce HallusionBench, a comprehensive benchmark designed for the evaluation of image-context reasoning. This benchmark presents significant challenges to advanced large visual-language models (LVLMs), such as GPT-4V(Vision), Gemini Pro Vision, and LLaVA-1.5, by emphasizing nuanced understanding and interpretation of visual data. The benchmark comprises 346 images paired with 1129 questions, all meticulously crafted by human experts. We introduce a novel structure for these visual questions designed to establish control groups. This structure enables us to conduct a quantitative analysis of the models' response tendencies, logical consistency, and various failure modes. In our evaluation on HallusionBench, we benchmarked 14 different models, highlighting a 31.42% question-pair accuracy achieved by the state-of-the-art GPT-4V. Notably, all other evaluated models achieve accuracy below 16%. Moreover, our analysis not only h",
    "path": "papers/23/10/2310.14566.json",
    "total_tokens": 945,
    "translated_title": "HallusionBench：一种用于评估大型视觉语言模型中纠缠的语言幻觉和视幻觉的高级诊断套件",
    "translated_abstract": "我们介绍了HallusionBench，这是一个专为评估图像背景推理而设计的全面基准。这个基准对于高级大型视觉语言模型（LVLMs）（如GPT-4V（Vision）、Gemini Pro Vision和LLaVA-1.5）提出了重大挑战，强调对视觉数据的微妙理解和解释。该基准包含346张图像和1129个问题，全部由人类专家精心设计。我们为这些视觉问题引入了一种新颖的结构，旨在建立对照组。这种结构使我们能够对模型的响应倾向、逻辑一致性和各种故障模式进行定量分析。在我们对HallusionBench的评估中，我们对14种不同模型进行了基准测试，突出了目前最先进的GPT-4V取得的31.42％的问题对准确率。值得注意的是，所有其他评估模型的准确率均低于16％。",
    "tldr": "HallusionBench是一个专为评估大型视觉语言模型在图像背景推理中面临挑战的基准，通过引入新颖结构和量化分析，显示出GPT-4V取得了31.42%的准确率，远高于其他模型。",
    "en_tdlr": "HallusionBench is a benchmark designed for evaluating the challenges faced by large vision-language models in image-context reasoning, showcasing that GPT-4V achieved a 31.42% accuracy through novel structures and quantitative analysis, surpassing other models significantly."
}