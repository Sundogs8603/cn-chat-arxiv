{
    "title": "StoryAnalogy: Deriving Story-level Analogies from Large Language Models to Unlock Analogical Understanding. (arXiv:2310.12874v1 [cs.CL])",
    "abstract": "Analogy-making between narratives is one of the most critical abilities in natural language understanding. In this paper, we evaluate the ability to identify and generate analogy by building a first-of-its-kind large-scale story-level analogy corpus, StoryAnalogy, which contains 24K story pairs from diverse domains with human annotations on two similarities from the extended Structure-Mapping Theory. We design a set of tests on StoryAnalogy, presenting the first evaluation of story-level analogy identification and generation. Interestingly, we find that the analogy identification tasks are extremely challenging not only for the sentence embedding models but also for the recent large language models (LLMs) such as ChatGPT and LLaMa, where ChatGPT only achieved around 30% accuracy in multiple-choice questions (> 85% accuracy for humans). Finally, we find that data in StoryAnalogy can improve LLMs analogy generation quality, where a fine-tuned FlanT5-xxl model yields comparable performanc",
    "link": "http://arxiv.org/abs/2310.12874",
    "context": "Title: StoryAnalogy: Deriving Story-level Analogies from Large Language Models to Unlock Analogical Understanding. (arXiv:2310.12874v1 [cs.CL])\nAbstract: Analogy-making between narratives is one of the most critical abilities in natural language understanding. In this paper, we evaluate the ability to identify and generate analogy by building a first-of-its-kind large-scale story-level analogy corpus, StoryAnalogy, which contains 24K story pairs from diverse domains with human annotations on two similarities from the extended Structure-Mapping Theory. We design a set of tests on StoryAnalogy, presenting the first evaluation of story-level analogy identification and generation. Interestingly, we find that the analogy identification tasks are extremely challenging not only for the sentence embedding models but also for the recent large language models (LLMs) such as ChatGPT and LLaMa, where ChatGPT only achieved around 30% accuracy in multiple-choice questions (> 85% accuracy for humans). Finally, we find that data in StoryAnalogy can improve LLMs analogy generation quality, where a fine-tuned FlanT5-xxl model yields comparable performanc",
    "path": "papers/23/10/2310.12874.json",
    "total_tokens": 905,
    "translated_title": "StoryAnalogy: 从大型语言模型中衍生出故事级类比以解开类比理解",
    "translated_abstract": "故事之间的类比是自然语言理解中最关键的能力之一。本文通过构建一个规模巨大的故事级类比语料库StoryAnalogy来评估识别和生成类比的能力，该语料库包含来自不同领域的24K个故事对，并对来自扩展结构映射理论的两个相似性进行人工注释。我们设计了一系列在StoryAnalogy上的测试，首次评估了故事级类比的识别和生成。有趣的是，我们发现类比识别任务对于句子嵌入模型以及最近的大型语言模型（如ChatGPT和LLaMa）来说都非常具有挑战性，其中ChatGPT在多选题中只能达到约30%的准确率（对于人类而言，准确率超过85%）。最后，我们发现StoryAnalogy中的数据可以提高大型语言模型的类比生成质量，其中经过微调的FlanT5-xxl模型获得了可比较的性能。",
    "tldr": "本文通过构建故事级类比语料库StoryAnalogy评估了大型语言模型在识别和生成类比任务上的能力，发现这些任务对于句子嵌入模型和最近的大型语言模型来说都非常具有挑战性。同时，研究发现通过使用StoryAnalogy中的数据可以提高大型语言模型的类比生成质量。"
}