{
    "title": "Minimax Forward and Backward Learning of Evolving Tasks with Performance Guarantees. (arXiv:2310.15974v1 [stat.ML])",
    "abstract": "For a sequence of classification tasks that arrive over time, it is common that tasks are evolving in the sense that consecutive tasks often have a higher similarity. The incremental learning of a growing sequence of tasks holds promise to enable accurate classification even with few samples per task by leveraging information from all the tasks in the sequence (forward and backward learning). However, existing techniques developed for continual learning and concept drift adaptation are either designed for tasks with time-independent similarities or only aim to learn the last task in the sequence. This paper presents incremental minimax risk classifiers (IMRCs) that effectively exploit forward and backward learning and account for evolving tasks. In addition, we analytically characterize the performance improvement provided by forward and backward learning in terms of the tasks' expected quadratic change and the number of tasks. The experimental evaluation shows that IMRCs can result in",
    "link": "http://arxiv.org/abs/2310.15974",
    "context": "Title: Minimax Forward and Backward Learning of Evolving Tasks with Performance Guarantees. (arXiv:2310.15974v1 [stat.ML])\nAbstract: For a sequence of classification tasks that arrive over time, it is common that tasks are evolving in the sense that consecutive tasks often have a higher similarity. The incremental learning of a growing sequence of tasks holds promise to enable accurate classification even with few samples per task by leveraging information from all the tasks in the sequence (forward and backward learning). However, existing techniques developed for continual learning and concept drift adaptation are either designed for tasks with time-independent similarities or only aim to learn the last task in the sequence. This paper presents incremental minimax risk classifiers (IMRCs) that effectively exploit forward and backward learning and account for evolving tasks. In addition, we analytically characterize the performance improvement provided by forward and backward learning in terms of the tasks' expected quadratic change and the number of tasks. The experimental evaluation shows that IMRCs can result in",
    "path": "papers/23/10/2310.15974.json",
    "total_tokens": 829,
    "translated_title": "最小化正反向学习的任务与性能保证",
    "translated_abstract": "对于随时间推移的分类任务序列，往往存在任务的演变，在这个意义上，连续的任务经常具有更高的相似性。通过利用序列中所有任务的信息（前向和后向学习），增量学习日益增长的任务序列有望实现即使每个任务只有很少样本也能进行准确分类。然而，现有的持续学习和概念漂移适应技术要么是针对具有时间无关相似性的任务设计的，要么只针对学习序列中的最后一个任务。本文介绍了一种有效利用前向和后向学习并考虑任务演变的增量最小化风险分类器（IMRCs）。此外，我们从任务的预期二次变化和任务数量的角度分析了前向和后向学习所提供的性能改进。实验评估表明，IMRCs可以导致性能提高。",
    "tldr": "本文提出了一种增量最小化风险分类器（IMRCs），能够有效利用前向和后向学习，并考虑任务的演变。实验评估表明，IMRCs可以提高分类性能。",
    "en_tdlr": "This paper presents incremental minimax risk classifiers (IMRCs) that effectively exploit forward and backward learning and account for evolving tasks. The experimental evaluation shows that IMRCs can improve classification performance."
}