{
    "title": "LXMERT Model Compression for Visual Question Answering. (arXiv:2310.15325v1 [cs.CV])",
    "abstract": "Large-scale pretrained models such as LXMERT are becoming popular for learning cross-modal representations on text-image pairs for vision-language tasks. According to the lottery ticket hypothesis, NLP and computer vision models contain smaller subnetworks capable of being trained in isolation to full performance. In this paper, we combine these observations to evaluate whether such trainable subnetworks exist in LXMERT when fine-tuned on the VQA task. In addition, we perform a model size cost-benefit analysis by investigating how much pruning can be done without significant loss in accuracy. Our experiment results demonstrate that LXMERT can be effectively pruned by 40%-60% in size with 3% loss in accuracy.",
    "link": "http://arxiv.org/abs/2310.15325",
    "context": "Title: LXMERT Model Compression for Visual Question Answering. (arXiv:2310.15325v1 [cs.CV])\nAbstract: Large-scale pretrained models such as LXMERT are becoming popular for learning cross-modal representations on text-image pairs for vision-language tasks. According to the lottery ticket hypothesis, NLP and computer vision models contain smaller subnetworks capable of being trained in isolation to full performance. In this paper, we combine these observations to evaluate whether such trainable subnetworks exist in LXMERT when fine-tuned on the VQA task. In addition, we perform a model size cost-benefit analysis by investigating how much pruning can be done without significant loss in accuracy. Our experiment results demonstrate that LXMERT can be effectively pruned by 40%-60% in size with 3% loss in accuracy.",
    "path": "papers/23/10/2310.15325.json",
    "total_tokens": 812,
    "translated_title": "视觉问答任务中的LXMERT模型压缩",
    "translated_abstract": "大规模预训练模型如LXMERT在文本-图像对上学习跨模态表示变得流行。根据中彩票假说，自然语言处理和计算机视觉模型中包含可单独训练以达到完全性能的较小子网络。本文结合这些观察结果，评估在VQA任务上对LXMERT进行微调时是否存在这样的可训练子网络。此外，我们通过研究可以进行多少剪枝而不会造成显著的精度损失来进行模型大小成本收益分析。我们的实验结果表明，对LXMERT进行40%-60%的有效剪枝，仅会损失3%的精度。",
    "tldr": "本文通过组合大规模预训练模型的观察结果，并评估在视觉问答任务中对LXMERT进行微调时的可训练子网络，研究了LXMERT模型的压缩。实验结果表明，在仅损失3%的精度下，可以有效地通过剪枝方法将LXMERT模型大小减小40%-60%。",
    "en_tdlr": "This paper investigates the compression of the LXMERT model by combining observations from large-scale pretrained models and evaluating trainable subnetworks when fine-tuned on the visual question answering task. The experiment results demonstrate that the LXMERT model can be effectively pruned by 40%-60% in size with only a 3% loss in accuracy."
}