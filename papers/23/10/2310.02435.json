{
    "title": "Multi-Agent Reinforcement Learning Based on Representational Communication for Large-Scale Traffic Signal Control. (arXiv:2310.02435v1 [cs.MA])",
    "abstract": "Traffic signal control (TSC) is a challenging problem within intelligent transportation systems and has been tackled using multi-agent reinforcement learning (MARL). While centralized approaches are often infeasible for large-scale TSC problems, decentralized approaches provide scalability but introduce new challenges, such as partial observability. Communication plays a critical role in decentralized MARL, as agents must learn to exchange information using messages to better understand the system and achieve effective coordination. Deep MARL has been used to enable inter-agent communication by learning communication protocols in a differentiable manner. However, many deep MARL communication frameworks proposed for TSC allow agents to communicate with all other agents at all times, which can add to the existing noise in the system and degrade overall performance. In this study, we propose a communication-based MARL framework for large-scale TSC. Our framework allows each agent to learn",
    "link": "http://arxiv.org/abs/2310.02435",
    "context": "Title: Multi-Agent Reinforcement Learning Based on Representational Communication for Large-Scale Traffic Signal Control. (arXiv:2310.02435v1 [cs.MA])\nAbstract: Traffic signal control (TSC) is a challenging problem within intelligent transportation systems and has been tackled using multi-agent reinforcement learning (MARL). While centralized approaches are often infeasible for large-scale TSC problems, decentralized approaches provide scalability but introduce new challenges, such as partial observability. Communication plays a critical role in decentralized MARL, as agents must learn to exchange information using messages to better understand the system and achieve effective coordination. Deep MARL has been used to enable inter-agent communication by learning communication protocols in a differentiable manner. However, many deep MARL communication frameworks proposed for TSC allow agents to communicate with all other agents at all times, which can add to the existing noise in the system and degrade overall performance. In this study, we propose a communication-based MARL framework for large-scale TSC. Our framework allows each agent to learn",
    "path": "papers/23/10/2310.02435.json",
    "total_tokens": 943,
    "translated_title": "基于表征交流的多智能体强化学习用于大规模交通信号控制",
    "translated_abstract": "交通信号控制（TSC）是智能交通系统中一个具有挑战性的问题，已经使用多智能体强化学习（MARL）进行解决。尽管对于大规模TSC问题来说，集中式方法通常是不可行的，但分散式方法提供了可扩展性，但也引入了新的挑战，比如部分可观察性。在分散式MARL中，通信起着关键的作用，因为智能体必须通过消息交换信息以更好地理解系统并实现有效协调。深度MARL已经被用来通过可微分的方式学习通信协议从而实现智能体间的交流。然而，许多为TSC提出的深度MARL通信框架允许智能体在任何时候与其他所有智能体进行通信，这可能会增加系统中的噪声并降低整体性能。在本研究中，我们提出了一种基于通信的大规模TSC的MARL框架。我们的框架允许每个智能体学习在何时和如何进行通信，以实现良好的协调和性能。",
    "tldr": "本研究提出了一种基于通信的多智能体强化学习框架，用于大规模交通信号控制。该框架允许智能体学习何时和如何进行通信，从而实现良好的协调和性能。",
    "en_tdlr": "This study proposes a communication-based framework for multi-agent reinforcement learning in large-scale traffic signal control, allowing agents to learn when and how to communicate for effective coordination and performance."
}