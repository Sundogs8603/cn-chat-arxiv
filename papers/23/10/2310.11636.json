{
    "title": "A Symbolic Language for Interpreting Decision Trees. (arXiv:2310.11636v1 [cs.LO])",
    "abstract": "The recent development of formal explainable AI has disputed the folklore claim that \"decision trees are readily interpretable models\", showing different interpretability queries that are computationally hard on decision trees, as well as proposing different methods to deal with them in practice. Nonetheless, no single explainability query or score works as a \"silver bullet\" that is appropriate for every context and end-user. This naturally suggests the possibility of \"interpretability languages\" in which a wide variety of queries can be expressed, giving control to the end-user to tailor queries to their particular needs. In this context, our work presents ExplainDT, a symbolic language for interpreting decision trees. ExplainDT is rooted in a carefully constructed fragment of first-ordered logic that we call StratiFOILed. StratiFOILed balances expressiveness and complexity of evaluation, allowing for the computation of many post-hoc explanations--both local (e.g., abductive and contr",
    "link": "http://arxiv.org/abs/2310.11636",
    "context": "Title: A Symbolic Language for Interpreting Decision Trees. (arXiv:2310.11636v1 [cs.LO])\nAbstract: The recent development of formal explainable AI has disputed the folklore claim that \"decision trees are readily interpretable models\", showing different interpretability queries that are computationally hard on decision trees, as well as proposing different methods to deal with them in practice. Nonetheless, no single explainability query or score works as a \"silver bullet\" that is appropriate for every context and end-user. This naturally suggests the possibility of \"interpretability languages\" in which a wide variety of queries can be expressed, giving control to the end-user to tailor queries to their particular needs. In this context, our work presents ExplainDT, a symbolic language for interpreting decision trees. ExplainDT is rooted in a carefully constructed fragment of first-ordered logic that we call StratiFOILed. StratiFOILed balances expressiveness and complexity of evaluation, allowing for the computation of many post-hoc explanations--both local (e.g., abductive and contr",
    "path": "papers/23/10/2310.11636.json",
    "total_tokens": 882,
    "translated_title": "解释决策树的符号语言",
    "translated_abstract": "近期发展的正式可解释的AI挑战了“决策树是易解释的模型”的流行说法，展示了在决策树上进行解释性查询的计算难题，并提出了不同的方法在实践中处理这些问题。然而，没有一个单一的解释性查询或评分适用于每个情境和最终用户。这自然地提出了“可解释性语言”的可能性，其中可以表达各种查询，为最终用户提供根据其特定需求定制查询的控制。在这个背景下，我们的工作介绍了解释决策树的符号语言ExplainDT。ExplainDT根植于我们称之为StratiFOILed的精心构建的一阶逻辑的片段。StratiFOILed平衡了表达能力和评估复杂度，允许计算出许多事后解释，包括局部解释（例如，认为和反向推理）和全局解释（例如，推广和对抗）。",
    "tldr": "这篇论文介绍了一种解释决策树的符号语言ExplainDT，使用了一阶逻辑的片段StratiFOILed，可以计算出各种事后解释，包括局部解释和全局解释。",
    "en_tdlr": "This paper presents ExplainDT, a symbolic language for interpreting decision trees. It is rooted in a carefully constructed fragment of first-ordered logic called StratiFOILed. ExplainDT allows for the computation of various post-hoc explanations, including both local and global explanations."
}