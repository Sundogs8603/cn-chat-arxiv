{
    "title": "LoHoRavens: A Long-Horizon Language-Conditioned Benchmark for Robotic Tabletop Manipulation. (arXiv:2310.12020v1 [cs.RO])",
    "abstract": "The convergence of embodied agents and large language models (LLMs) has brought significant advancements to embodied instruction following. Particularly, the strong reasoning capabilities of LLMs make it possible for robots to perform long-horizon tasks without expensive annotated demonstrations. However, public benchmarks for testing the long-horizon reasoning capabilities of language-conditioned robots in various scenarios are still missing. To fill this gap, this work focuses on the tabletop manipulation task and releases a simulation benchmark, \\textit{LoHoRavens}, which covers various long-horizon reasoning aspects spanning color, size, space, arithmetics and reference. Furthermore, there is a key modality bridging problem for long-horizon manipulation tasks with LLMs: how to incorporate the observation feedback during robot execution for the LLM's closed-loop planning, which is however less studied by prior work. We investigate two methods of bridging the modality gap: caption ge",
    "link": "http://arxiv.org/abs/2310.12020",
    "context": "Title: LoHoRavens: A Long-Horizon Language-Conditioned Benchmark for Robotic Tabletop Manipulation. (arXiv:2310.12020v1 [cs.RO])\nAbstract: The convergence of embodied agents and large language models (LLMs) has brought significant advancements to embodied instruction following. Particularly, the strong reasoning capabilities of LLMs make it possible for robots to perform long-horizon tasks without expensive annotated demonstrations. However, public benchmarks for testing the long-horizon reasoning capabilities of language-conditioned robots in various scenarios are still missing. To fill this gap, this work focuses on the tabletop manipulation task and releases a simulation benchmark, \\textit{LoHoRavens}, which covers various long-horizon reasoning aspects spanning color, size, space, arithmetics and reference. Furthermore, there is a key modality bridging problem for long-horizon manipulation tasks with LLMs: how to incorporate the observation feedback during robot execution for the LLM's closed-loop planning, which is however less studied by prior work. We investigate two methods of bridging the modality gap: caption ge",
    "path": "papers/23/10/2310.12020.json",
    "total_tokens": 982,
    "translated_title": "LoHoRavens: 一项针对机器人桌面操作的长时程语言条件基准测试",
    "translated_abstract": "体验式代理与大型语言模型的融合为体验式指导带来了显著的进展。特别是，大型语言模型的强大推理能力使得机器人能够在没有昂贵的注释演示的情况下进行长时程任务。然而，目前还缺乏用于测试语言条件机器人在各种场景中推理长时程能力的公共基准。为了填补这一空白，本研究聚焦于桌面操作任务，并发布了一个称为“LoHoRavens”的仿真基准测试，涵盖颜色、大小、空间、算术和引用等各种长时程推理方面。此外，对于使用大型语言模型进行长时程操作的任务，存在一个关键的模态过渡问题：如何在机器人执行过程中将观测反馈纳入到大型语言模型的闭环规划中，然而之前的研究对此进行的探索较少。我们研究了两种解决模态过渡问题的方法：标题生成和快照。",
    "tldr": "LoHoRavens是一个针对机器人桌面操作的长时程语言条件基准测试，涵盖颜色、大小、空间、算术和引用等各种推理方面。本研究还探索了在机器人执行过程中如何将观测反馈纳入到大型语言模型的闭环规划中的两种方法。"
}