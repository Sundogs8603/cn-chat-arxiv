{
    "title": "Examining the Potential and Pitfalls of ChatGPT in Science and Engineering Problem-Solving. (arXiv:2310.08773v1 [cs.AI])",
    "abstract": "The study explores the capabilities of OpenAI's ChatGPT in solving different types of physics problems. ChatGPT (with GPT-4) was queried to solve a total of 40 problems from a college-level engineering physics course. These problems ranged from well-specified problems, where all data required for solving the problem was provided, to under-specified, real-world problems where not all necessary data were given. Our findings show that ChatGPT could successfully solve 62.5\\% of the well-specified problems, but its accuracy drops to 8.3\\% for under-specified problems. Analysis of the model's incorrect solutions revealed three distinct failure modes: 1) failure to construct accurate models of the physical world, 2) failure to make reasonable assumptions about missing data, and 3) calculation errors. The study offers implications for how to leverage LLM-augmented instructional materials to enhance STEM education. The insights also contribute to the broader discourse on AI's strengths and limi",
    "link": "http://arxiv.org/abs/2310.08773",
    "context": "Title: Examining the Potential and Pitfalls of ChatGPT in Science and Engineering Problem-Solving. (arXiv:2310.08773v1 [cs.AI])\nAbstract: The study explores the capabilities of OpenAI's ChatGPT in solving different types of physics problems. ChatGPT (with GPT-4) was queried to solve a total of 40 problems from a college-level engineering physics course. These problems ranged from well-specified problems, where all data required for solving the problem was provided, to under-specified, real-world problems where not all necessary data were given. Our findings show that ChatGPT could successfully solve 62.5\\% of the well-specified problems, but its accuracy drops to 8.3\\% for under-specified problems. Analysis of the model's incorrect solutions revealed three distinct failure modes: 1) failure to construct accurate models of the physical world, 2) failure to make reasonable assumptions about missing data, and 3) calculation errors. The study offers implications for how to leverage LLM-augmented instructional materials to enhance STEM education. The insights also contribute to the broader discourse on AI's strengths and limi",
    "path": "papers/23/10/2310.08773.json",
    "total_tokens": 1010,
    "translated_title": "探究ChatGPT在科学与工程问题解决中的潜力与困境",
    "translated_abstract": "该研究探索了OpenAI的ChatGPT在解决不同类型的物理问题上的能力。使用ChatGPT（具有GPT-4）来解决了来自大学级工程物理课程的40个问题。这些问题范围从有明确规定的问题（提供了解决问题所需的所有数据）到未明确规定的现实世界问题（未提供所有必要数据）不等。我们的研究结果表明，ChatGPT可以成功解决62.5％的有明确规定的问题，但对于未明确规定的问题，其准确率下降到8.3％。对模型的错误解的分析揭示了三种不同的失败模式：1）无法构建准确的物理世界模型，2）无法对缺失数据做出合理的假设，以及3）计算错误。该研究为如何利用LLM增强的教学材料来提升STEM教育提供了启示。这些观察结果还对AI的优势和局限性的广泛讨论作出了贡献。",
    "tldr": "ChatGPT被用于解决物理问题，发现在解决明确规定的问题时准确率较高，但在解决未明确规定的问题时准确率较低。错误解的分析揭示了三种失败模式，并探讨了如何利用LLM增强的教材提升STEM教育。这些观察结果对于AI的优势和局限性也有贡献。"
}