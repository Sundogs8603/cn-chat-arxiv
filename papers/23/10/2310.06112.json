{
    "title": "Theoretical Analysis of Robust Overfitting for Wide DNNs: An NTK Approach. (arXiv:2310.06112v1 [cs.LG])",
    "abstract": "Adversarial training (AT) is a canonical method for enhancing the robustness of deep neural networks (DNNs). However, recent studies empirically demonstrated that it suffers from robust overfitting, i.e., a long time AT can be detrimental to the robustness of DNNs. This paper presents a theoretical explanation of robust overfitting for DNNs. Specifically, we non-trivially extend the neural tangent kernel (NTK) theory to AT and prove that an adversarially trained wide DNN can be well approximated by a linearized DNN. Moreover, for squared loss, closed-form AT dynamics for the linearized DNN can be derived, which reveals a new AT degeneration phenomenon: a long-term AT will result in a wide DNN degenerates to that obtained without AT and thus cause robust overfitting. Based on our theoretical results, we further design a method namely Adv-NTK, the first AT algorithm for infinite-width DNNs. Experiments on real-world datasets show that Adv-NTK can help infinite-width DNNs enhance comparab",
    "link": "http://arxiv.org/abs/2310.06112",
    "context": "Title: Theoretical Analysis of Robust Overfitting for Wide DNNs: An NTK Approach. (arXiv:2310.06112v1 [cs.LG])\nAbstract: Adversarial training (AT) is a canonical method for enhancing the robustness of deep neural networks (DNNs). However, recent studies empirically demonstrated that it suffers from robust overfitting, i.e., a long time AT can be detrimental to the robustness of DNNs. This paper presents a theoretical explanation of robust overfitting for DNNs. Specifically, we non-trivially extend the neural tangent kernel (NTK) theory to AT and prove that an adversarially trained wide DNN can be well approximated by a linearized DNN. Moreover, for squared loss, closed-form AT dynamics for the linearized DNN can be derived, which reveals a new AT degeneration phenomenon: a long-term AT will result in a wide DNN degenerates to that obtained without AT and thus cause robust overfitting. Based on our theoretical results, we further design a method namely Adv-NTK, the first AT algorithm for infinite-width DNNs. Experiments on real-world datasets show that Adv-NTK can help infinite-width DNNs enhance comparab",
    "path": "papers/23/10/2310.06112.json",
    "total_tokens": 960,
    "translated_title": "宽深度神经网络的鲁棒过拟合的理论分析：一种NTK方法",
    "translated_abstract": "对抗训练(AT)是增强深度神经网络(DNNs)鲁棒性的经典方法。然而，最近的研究实验证明它存在鲁棒过拟合现象，即长时间的AT可能对DNNs的鲁棒性产生不利影响。本文对DNNs的鲁棒过拟合提出了一个理论解释。具体而言，我们将神经切向核(NTK)理论非平凡地扩展到AT，并证明了通过AT训练的宽DNN可以很好地近似为一个线性化的DNN。此外，对于平方损失，可以推导出线性化DNN的闭式AT动力学，揭示了一种新的AT退化现象：长期的AT将导致宽DNN退化为没有AT的DNN，从而引起鲁棒过拟合。根据我们的理论结果，我们进一步设计了一种名为Adv-NTK的方法，这是第一种针对无限宽的DNNs的AT算法。在实际数据集上的实验结果表明，Adv-NTK可以帮助无限宽的DNNs提升鲁棒性。",
    "tldr": "本文理论分析了宽深度神经网络的鲁棒过拟合现象，并提出了一种名为Adv-NTK的AT算法来增强神经网络的鲁棒性。"
}