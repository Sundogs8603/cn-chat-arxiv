{
    "title": "DialogueLLM: Context and Emotion Knowledge-Tuned Large Language Models for Emotion Recognition in Conversations. (arXiv:2310.11374v4 [cs.CL] UPDATED)",
    "abstract": "Large language models (LLMs) and their variants have shown extraordinary efficacy across numerous downstream natural language processing (NLP) tasks, which has presented a new vision for the development of NLP. Despite their remarkable performance in natural language generating (NLG), LLMs lack a distinct focus on the emotion understanding domain. As a result, using LLMs for emotion recognition may lead to suboptimal and inadequate precision. Another limitation of LLMs is that they are typical trained without leveraging multi-modal information. To overcome these limitations, we propose DialogueLLM, a context and emotion knowledge tuned LLM that is obtained by fine-tuning LLaMA models with 13,638 multi-modal (i.e., texts and videos) emotional dialogues. The visual information is considered as the supplementary knowledge to construct high-quality instructions. We offer a comprehensive evaluation of our proposed model on three benchmarking emotion recognition in conversations (ERC) datase",
    "link": "http://arxiv.org/abs/2310.11374",
    "context": "Title: DialogueLLM: Context and Emotion Knowledge-Tuned Large Language Models for Emotion Recognition in Conversations. (arXiv:2310.11374v4 [cs.CL] UPDATED)\nAbstract: Large language models (LLMs) and their variants have shown extraordinary efficacy across numerous downstream natural language processing (NLP) tasks, which has presented a new vision for the development of NLP. Despite their remarkable performance in natural language generating (NLG), LLMs lack a distinct focus on the emotion understanding domain. As a result, using LLMs for emotion recognition may lead to suboptimal and inadequate precision. Another limitation of LLMs is that they are typical trained without leveraging multi-modal information. To overcome these limitations, we propose DialogueLLM, a context and emotion knowledge tuned LLM that is obtained by fine-tuning LLaMA models with 13,638 multi-modal (i.e., texts and videos) emotional dialogues. The visual information is considered as the supplementary knowledge to construct high-quality instructions. We offer a comprehensive evaluation of our proposed model on three benchmarking emotion recognition in conversations (ERC) datase",
    "path": "papers/23/10/2310.11374.json",
    "total_tokens": 870,
    "translated_title": "DialogueLLM: 对情感识别中对话进行情境和情感知识调校的大型语言模型",
    "translated_abstract": "大型语言模型（LLMs）及其变种在众多自然语言处理（NLP）任务中显示出非凡的效果，这为NLP的发展带来了新的视野。尽管LLMs在自然语言生成（NLG）方面的表现出色，但缺乏对情感理解领域的明确关注。因此，使用LLMs进行情感识别可能导致精度不佳和不充分。另一个LLMs的限制是它们通常在没有利用多模态信息的情况下进行训练。为了克服这些限制，我们提出了DialogueLLM，一种经过细调的上下文和情感知识调校的LLM，通过使用13,638个多模态（文本和视频）情感对话的LLaMA模型进行微调获得。视觉信息被视为构建高质量指令的补充知识。我们对我们提出的模型在三个情感识别对话（ERC）基准数据集上进行了全面评估。",
    "tldr": "DialogueLLM是一种通过使用多模态情感对话微调的上下文和情感知识调校的大型语言模型，用于情感识别任务。"
}