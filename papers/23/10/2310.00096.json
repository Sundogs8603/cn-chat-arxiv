{
    "title": "Towards Few-Call Model Stealing via Active Self-Paced Knowledge Distillation and Diffusion-Based Image Generation. (arXiv:2310.00096v1 [cs.CV])",
    "abstract": "Diffusion models showcased strong capabilities in image synthesis, being used in many computer vision tasks with great success. To this end, we propose to explore a new use case, namely to copy black-box classification models without having access to the original training data, the architecture, and the weights of the model, \\ie~the model is only exposed through an inference API. More specifically, we can only observe the (soft or hard) labels for some image samples passed as input to the model. Furthermore, we consider an additional constraint limiting the number of model calls, mostly focusing our research on few-call model stealing. In order to solve the model extraction task given the applied restrictions, we propose the following framework. As training data, we create a synthetic data set (called proxy data set) by leveraging the ability of diffusion models to generate realistic and diverse images. Given a maximum number of allowed API calls, we pass the respective number of sampl",
    "link": "http://arxiv.org/abs/2310.00096",
    "context": "Title: Towards Few-Call Model Stealing via Active Self-Paced Knowledge Distillation and Diffusion-Based Image Generation. (arXiv:2310.00096v1 [cs.CV])\nAbstract: Diffusion models showcased strong capabilities in image synthesis, being used in many computer vision tasks with great success. To this end, we propose to explore a new use case, namely to copy black-box classification models without having access to the original training data, the architecture, and the weights of the model, \\ie~the model is only exposed through an inference API. More specifically, we can only observe the (soft or hard) labels for some image samples passed as input to the model. Furthermore, we consider an additional constraint limiting the number of model calls, mostly focusing our research on few-call model stealing. In order to solve the model extraction task given the applied restrictions, we propose the following framework. As training data, we create a synthetic data set (called proxy data set) by leveraging the ability of diffusion models to generate realistic and diverse images. Given a maximum number of allowed API calls, we pass the respective number of sampl",
    "path": "papers/23/10/2310.00096.json",
    "total_tokens": 847,
    "translated_title": "近似黑盒模型窃取的少次调用方法：活跃自适应知识蒸馏和基于扩散的图像生成",
    "translated_abstract": "扩散模型在图像合成方面展示了强大的能力，并在许多计算机视觉任务中取得了巨大成功。为此，我们提出了一个新的用例，即在没有访问原始训练数据、架构和模型权重的情况下复制黑盒分类模型，即只能通过推理API使用模型。具体来说，我们只能观察到一些图像样本作为输入传递给模型时的（软性或硬性）标签。此外，我们考虑到限制模型调用次数的额外约束，主要关注于少次调用的模型窃取。为了在应用限制条件的情况下解决模型提取任务，我们提出了以下框架。作为训练数据，我们利用扩散模型生成逼真且多样化的图像创建了一个合成数据集（称为代理数据集）。给定允许的最大API调用次数，我们传递相应数量的样本进行训练。",
    "tldr": "本研究提出了一种利用扩散模型生成合成数据集，并通过少次调用的方法窃取黑盒模型的框架，突破了访问限制条件。"
}