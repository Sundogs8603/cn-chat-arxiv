{
    "title": "ArTST: Arabic Text and Speech Transformer. (arXiv:2310.16621v1 [cs.CL])",
    "abstract": "We present ArTST, a pre-trained Arabic text and speech transformer for supporting open-source speech technologies for the Arabic language. The model architecture follows the unified-modal framework, SpeechT5, that was recently released for English, and is focused on Modern Standard Arabic (MSA), with plans to extend the model for dialectal and code-switched Arabic in future editions. We pre-trained the model from scratch on MSA speech and text data, and fine-tuned it for the following tasks: Automatic Speech Recognition (ASR), Text-To-Speech synthesis (TTS), and spoken dialect identification. In our experiments comparing ArTST with SpeechT5, as well as with previously reported results in these tasks, ArTST performs on a par with or exceeding the current state-of-the-art in all three tasks. Moreover, we find that our pre-training is conducive for generalization, which is particularly evident in the low-resource TTS task. The pre-trained model as well as the fine-tuned ASR and TTS models",
    "link": "http://arxiv.org/abs/2310.16621",
    "context": "Title: ArTST: Arabic Text and Speech Transformer. (arXiv:2310.16621v1 [cs.CL])\nAbstract: We present ArTST, a pre-trained Arabic text and speech transformer for supporting open-source speech technologies for the Arabic language. The model architecture follows the unified-modal framework, SpeechT5, that was recently released for English, and is focused on Modern Standard Arabic (MSA), with plans to extend the model for dialectal and code-switched Arabic in future editions. We pre-trained the model from scratch on MSA speech and text data, and fine-tuned it for the following tasks: Automatic Speech Recognition (ASR), Text-To-Speech synthesis (TTS), and spoken dialect identification. In our experiments comparing ArTST with SpeechT5, as well as with previously reported results in these tasks, ArTST performs on a par with or exceeding the current state-of-the-art in all three tasks. Moreover, we find that our pre-training is conducive for generalization, which is particularly evident in the low-resource TTS task. The pre-trained model as well as the fine-tuned ASR and TTS models",
    "path": "papers/23/10/2310.16621.json",
    "total_tokens": 931,
    "translated_title": "ArTST: 阿拉伯文本和语音变换器",
    "translated_abstract": "我们提出了一种用于支持阿拉伯语开源语音技术的预训练阿拉伯文本和语音变换器ArTST。该模型架构遵循最近发布的英文统一模态框架SpeechT5，并且专注于现代标准阿拉伯语（MSA），计划将模型扩展到未来版本的方言和混合阿拉伯语。我们从头开始在MSA语音和文本数据上进行了模型的预训练，并对以下任务进行了微调：自动语音识别（ASR）、文本到语音合成（TTS）和口语方言识别。通过与SpeechT5以及先前报道的这些任务的结果进行比较，ArTST在所有三个任务中的表现与当前最先进的技术持平或超过。此外，我们发现我们的预训练有助于泛化，这在低资源TTS任务中特别明显。预训练模型以及微调的ASR和TTS模型",
    "tldr": "ArTST是一种用于支持阿拉伯语开源语音技术的预训练模型，通过从头开始的预训练和微调，它在自动语音识别、文本到语音合成和口语方言识别任务中达到了与当前最先进技术相当甚至超过的性能。",
    "en_tdlr": "ArTST is a pre-trained model for supporting open-source speech technologies for the Arabic language. Through pre-training from scratch and fine-tuning, it achieves comparable or even superior performance in Automatic Speech Recognition, Text-To-Speech synthesis, and spoken dialect identification tasks compared to the current state-of-the-art."
}