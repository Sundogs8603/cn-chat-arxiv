{
    "title": "Dialect Adaptation and Data Augmentation for Low-Resource ASR: TalTech Systems for the MADASR 2023 Challenge. (arXiv:2310.17448v1 [cs.CL])",
    "abstract": "This paper describes Tallinn University of Technology (TalTech) systems developed for the ASRU MADASR 2023 Challenge. The challenge focuses on automatic speech recognition of dialect-rich Indian languages with limited training audio and text data. TalTech participated in two tracks of the challenge: Track 1 that allowed using only the provided training data and Track 3 which allowed using additional audio data. In both tracks, we relied on wav2vec2.0 models. Our methodology diverges from the traditional procedure of finetuning pretrained wav2vec2.0 models in two key points: firstly, through the implementation of the aligned data augmentation technique to enhance the linguistic diversity of the training data, and secondly, via the application of deep prefix tuning for dialect adaptation of wav2vec2.0 models. In both tracks, our approach yielded significant improvements over the provided baselines, achieving the lowest word error rates across all participating teams.",
    "link": "http://arxiv.org/abs/2310.17448",
    "context": "Title: Dialect Adaptation and Data Augmentation for Low-Resource ASR: TalTech Systems for the MADASR 2023 Challenge. (arXiv:2310.17448v1 [cs.CL])\nAbstract: This paper describes Tallinn University of Technology (TalTech) systems developed for the ASRU MADASR 2023 Challenge. The challenge focuses on automatic speech recognition of dialect-rich Indian languages with limited training audio and text data. TalTech participated in two tracks of the challenge: Track 1 that allowed using only the provided training data and Track 3 which allowed using additional audio data. In both tracks, we relied on wav2vec2.0 models. Our methodology diverges from the traditional procedure of finetuning pretrained wav2vec2.0 models in two key points: firstly, through the implementation of the aligned data augmentation technique to enhance the linguistic diversity of the training data, and secondly, via the application of deep prefix tuning for dialect adaptation of wav2vec2.0 models. In both tracks, our approach yielded significant improvements over the provided baselines, achieving the lowest word error rates across all participating teams.",
    "path": "papers/23/10/2310.17448.json",
    "total_tokens": 912,
    "translated_title": "《方言适应与数据增强对于资源匮乏 ASR 的影响：TalTech 系统在 MADASR 2023 挑战中的表现》",
    "translated_abstract": "本文介绍了TalTech开发的ASRU MADASR 2023挑战中，针对方言丰富的印度语言的自动语音识别系统。挑战主要关注有限的训练音频和文本数据。TalTech参与了挑战的两个任务：第一个任务只能使用提供的训练数据，第三个任务可以使用额外的音频数据。在这两个任务中，我们使用了wav2vec2.0模型。我们的方法与传统的finetuning预训练的wav2vec2.0模型的过程有两个关键点的差异：首先，通过实施对齐数据增强技术来增加训练数据的语言多样性；其次，通过深层前缀调整将wav2vec2.0模型进行方言适应。在这两个任务中，我们的方法显著改进了提供的基准线，达到了参与团队中最低的词错误率。",
    "tldr": "TalTech使用了方言适应和数据增强的方法，并分别在提供的训练数据和额外音频数据上取得了显著的改进。实验结果表明，该方法在低资源ASR场景中取得了最低的词错误率。",
    "en_tdlr": "TalTech utilized dialect adaptation and data augmentation techniques, achieving significant improvements in both provided training data and additional audio data. The results demonstrate that their approach achieved the lowest word error rates in low-resource ASR scenarios."
}