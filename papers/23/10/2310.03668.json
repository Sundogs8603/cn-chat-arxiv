{
    "title": "GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction. (arXiv:2310.03668v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs) combined with instruction tuning have made significant progress when generalizing to unseen tasks. However, they have been less successful in Information Extraction (IE), lagging behind task-specific models. Typically, IE tasks are characterized by complex annotation guidelines which describe the task and give examples to humans. Previous attempts to leverage such information have failed, even with the largest models, as they are not able to follow the guidelines out-of-the-box. In this paper we propose GoLLIE (Guideline-following Large Language Model for IE), a model able to improve zero-shot results on unseen IE tasks by virtue of being fine-tuned to comply with annotation guidelines. Comprehensive evaluation empirically demonstrates that GoLLIE is able to generalize to and follow unseen guidelines, outperforming previous attempts at zero-shot information extraction. The ablation study shows that detailed guidelines is key for good results.",
    "link": "http://arxiv.org/abs/2310.03668",
    "context": "Title: GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction. (arXiv:2310.03668v1 [cs.CL])\nAbstract: Large Language Models (LLMs) combined with instruction tuning have made significant progress when generalizing to unseen tasks. However, they have been less successful in Information Extraction (IE), lagging behind task-specific models. Typically, IE tasks are characterized by complex annotation guidelines which describe the task and give examples to humans. Previous attempts to leverage such information have failed, even with the largest models, as they are not able to follow the guidelines out-of-the-box. In this paper we propose GoLLIE (Guideline-following Large Language Model for IE), a model able to improve zero-shot results on unseen IE tasks by virtue of being fine-tuned to comply with annotation guidelines. Comprehensive evaluation empirically demonstrates that GoLLIE is able to generalize to and follow unseen guidelines, outperforming previous attempts at zero-shot information extraction. The ablation study shows that detailed guidelines is key for good results.",
    "path": "papers/23/10/2310.03668.json",
    "total_tokens": 829,
    "translated_title": "GoLLIE:注释指南提高了零样本信息抽取",
    "translated_abstract": "大型语言模型 (LLMs) 结合指导调优已经在泛化到未见任务方面取得了显著进展。然而，在信息抽取 (IE) 方面，它们的表现较差，落后于任务特定模型。通常，IE 任务的特点是复杂的注释指南，描述任务并给出示例给人类。先前利用这样的信息的尝试都失败了，即使使用最大的模型，它们也不能直接遵循指南。在本文中，我们提出了针对信息抽取的指南遵循大型语言模型 GoLLIE (Guideline-following Large Language Model for IE)，该模型通过微调以遵守注释指南，从而能够改进未见 IE 任务的零样本结果。全面的评估实证表明，GoLLIE 能够泛化并遵循未见指南，在零样本信息抽取方面优于先前的尝试。消融研究表明，详细的指南是取得良好结果的关键。",
    "tldr": "GoLLIE 是一个遵循注释指南的大型语言模型，通过微调以改进未见信息抽取任务的零样本结果。",
    "en_tdlr": "GoLLIE is a large language model that follows annotation guidelines and improves zero-shot results in unseen information extraction tasks through fine-tuning."
}