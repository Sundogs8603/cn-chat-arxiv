{
    "title": "Rethinking Word-Level Auto-Completion in Computer-Aided Translation. (arXiv:2310.14523v2 [cs.CL] UPDATED)",
    "abstract": "Word-Level Auto-Completion (WLAC) plays a crucial role in Computer-Assisted Translation. It aims at providing word-level auto-completion suggestions for human translators. While previous studies have primarily focused on designing complex model architectures, this paper takes a different perspective by rethinking the fundamental question: what kind of words are good auto-completions? We introduce a measurable criterion to answer this question and discover that existing WLAC models often fail to meet this criterion. Building upon this observation, we propose an effective approach to enhance WLAC performance by promoting adherence to the criterion. Notably, the proposed approach is general and can be applied to various encoder-based architectures. Through extensive experiments, we demonstrate that our approach outperforms the top-performing system submitted to the WLAC shared tasks in WMT2022, while utilizing significantly smaller model sizes.",
    "link": "http://arxiv.org/abs/2310.14523",
    "context": "Title: Rethinking Word-Level Auto-Completion in Computer-Aided Translation. (arXiv:2310.14523v2 [cs.CL] UPDATED)\nAbstract: Word-Level Auto-Completion (WLAC) plays a crucial role in Computer-Assisted Translation. It aims at providing word-level auto-completion suggestions for human translators. While previous studies have primarily focused on designing complex model architectures, this paper takes a different perspective by rethinking the fundamental question: what kind of words are good auto-completions? We introduce a measurable criterion to answer this question and discover that existing WLAC models often fail to meet this criterion. Building upon this observation, we propose an effective approach to enhance WLAC performance by promoting adherence to the criterion. Notably, the proposed approach is general and can be applied to various encoder-based architectures. Through extensive experiments, we demonstrate that our approach outperforms the top-performing system submitted to the WLAC shared tasks in WMT2022, while utilizing significantly smaller model sizes.",
    "path": "papers/23/10/2310.14523.json",
    "total_tokens": 907,
    "translated_title": "重新思考计算辅助翻译中的单词级自动补全",
    "translated_abstract": "单词级自动补全在计算辅助翻译中发挥着关键作用，旨在为人类翻译人员提供单词级自动补全建议。然而，以往的研究主要关注设计复杂的模型架构，而本文从不同的角度重新思考了一个基本问题：什么样的单词是好的自动补全？我们引入了一种可衡量的标准来回答这个问题，并发现现有的单词级自动补全模型往往无法满足这一标准。基于这一观察，我们提出了一种有效的方法来提高单词级自动补全性能，促进对标准的遵循。值得注意的是，所提出的方法是通用的，可以应用于各种基于编码器的架构。通过大量实验，我们证明了我们的方法优于提交给WMT2022单词级自动补全共享任务的最佳系统，同时使用了明显更小的模型尺寸。",
    "tldr": "本论文重新思考了计算辅助翻译中单词级自动补全的问题，引入了一个可衡量的标准来确定好的自动补全，提出了一种有效方法来提高性能，并在实验中证明了其优于目前最佳系统的表现。",
    "en_tdlr": "This paper rethinks word-level auto-completion in computer-aided translation, introduces a measurable criterion to determine good auto-completions, proposes an effective approach to enhance performance, and demonstrates its superiority over the current top-performing system through experiments."
}