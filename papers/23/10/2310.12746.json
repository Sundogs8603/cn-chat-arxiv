{
    "title": "TabuLa: Harnessing Language Models for Tabular Data Synthesis. (arXiv:2310.12746v1 [cs.LG])",
    "abstract": "Given the ubiquitous use of tabular data in industries and the growing concerns in data privacy and security, tabular data synthesis emerges as a critical research area. The recent state-of-the-art methods show that large language models (LLMs) can be adopted to generate realistic tabular data. As LLMs pre-process tabular data as full text, they have the advantage of avoiding the curse of dimensionality associated with one-hot encoding high-dimensional data. However, their long training time and limited re-usability on new tasks prevent them from replacing exiting tabular generative models. In this paper, we propose Tabula, a tabular data synthesizer based on the language model structure. Through Tabula, we demonstrate the inherent limitation of employing pre-trained language models designed for natural language processing (NLP) in the context of tabular data synthesis. Our investigation delves into the development of a dedicated foundational model tailored specifically for tabular dat",
    "link": "http://arxiv.org/abs/2310.12746",
    "context": "Title: TabuLa: Harnessing Language Models for Tabular Data Synthesis. (arXiv:2310.12746v1 [cs.LG])\nAbstract: Given the ubiquitous use of tabular data in industries and the growing concerns in data privacy and security, tabular data synthesis emerges as a critical research area. The recent state-of-the-art methods show that large language models (LLMs) can be adopted to generate realistic tabular data. As LLMs pre-process tabular data as full text, they have the advantage of avoiding the curse of dimensionality associated with one-hot encoding high-dimensional data. However, their long training time and limited re-usability on new tasks prevent them from replacing exiting tabular generative models. In this paper, we propose Tabula, a tabular data synthesizer based on the language model structure. Through Tabula, we demonstrate the inherent limitation of employing pre-trained language models designed for natural language processing (NLP) in the context of tabular data synthesis. Our investigation delves into the development of a dedicated foundational model tailored specifically for tabular dat",
    "path": "papers/23/10/2310.12746.json",
    "total_tokens": 892,
    "translated_title": "TabuLa: 利用语言模型进行表格数据合成",
    "translated_abstract": "鉴于表格数据在各行业中的广泛应用以及对数据隐私和安全性的日益关注，表格数据合成成为一个重要的研究领域。最近的最先进方法表明，可以采用大型语言模型（LLMs）来生成逼真的表格数据。由于LLMs将表格数据预处理为全文，它们具有避免高维度数据的独热编码所带来的维度灾难的优势。然而，它们训练时间长、在新任务上的可重用性有限，使得它们无法取代现有的表格生成模型。在本文中，我们提出了基于语言模型结构的Tabula，一种表格数据合成器。通过Tabula，我们展示了在表格数据合成的背景下，采用为自然语言处理（NLP）设计的预训练语言模型的固有限制。我们的研究深入探讨了专门针对表格数据定制的基础模型的开发。",
    "tldr": "本文提出了一种基于语言模型结构的Tabula表格数据合成工具，通过研究我们发现，为自然语言处理设计的预训练语言模型在表格数据合成方面存在固有限制。",
    "en_tdlr": "This paper proposes TabuLa, a tabular data synthesizer based on the language model structure. Through our investigation, we discover the inherent limitations of using pre-trained language models designed for natural language processing in the context of tabular data synthesis."
}