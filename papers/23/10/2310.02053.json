{
    "title": "Controlling Topic-Focus Articulation in Meaning-to-Text Generation using Graph Neural Networks. (arXiv:2310.02053v1 [cs.CL])",
    "abstract": "A bare meaning representation can be expressed in various ways using natural language, depending on how the information is structured on the surface level. We are interested in finding ways to control topic-focus articulation when generating text from meaning. We focus on distinguishing active and passive voice for sentences with transitive verbs. The idea is to add pragmatic information such as topic to the meaning representation, thereby forcing either active or passive voice when given to a natural language generation system. We use graph neural models because there is no explicit information about word order in a meaning represented by a graph. We try three different methods for topic-focus articulation (TFA) employing graph neural models for a meaning-to-text generation task. We propose a novel encoding strategy about node aggregation in graph neural models, which instead of traditional encoding by aggregating adjacent node information, learns node representations by using depth-f",
    "link": "http://arxiv.org/abs/2310.02053",
    "context": "Title: Controlling Topic-Focus Articulation in Meaning-to-Text Generation using Graph Neural Networks. (arXiv:2310.02053v1 [cs.CL])\nAbstract: A bare meaning representation can be expressed in various ways using natural language, depending on how the information is structured on the surface level. We are interested in finding ways to control topic-focus articulation when generating text from meaning. We focus on distinguishing active and passive voice for sentences with transitive verbs. The idea is to add pragmatic information such as topic to the meaning representation, thereby forcing either active or passive voice when given to a natural language generation system. We use graph neural models because there is no explicit information about word order in a meaning represented by a graph. We try three different methods for topic-focus articulation (TFA) employing graph neural models for a meaning-to-text generation task. We propose a novel encoding strategy about node aggregation in graph neural models, which instead of traditional encoding by aggregating adjacent node information, learns node representations by using depth-f",
    "path": "papers/23/10/2310.02053.json",
    "total_tokens": 927,
    "translated_title": "使用图神经网络控制意义到文本生成中的话题-焦点表达",
    "translated_abstract": "裸露的意义表示可以通过自然语言以各种方式表达，这取决于信息在表面层面上的结构。我们有兴趣找到一种在从意义生成文本时控制话题-焦点表达的方法。我们将重点放在区分带有及物动词的句子的主动语态和被动语态上。我们的思路是在意义表示中添加话题等语用信息，从而在提供给自然语言生成系统时强制使用主动语态或被动语态。我们使用图神经模型，因为在用图表示的意义中没有关于词序的明确信息。我们尝试了三种不同的话题-焦点表达（TFA）方法，使用图神经模型进行意义到文本生成任务。我们提出了一种关于图神经模型中的节点聚合的新编码策略，通过使用深度学习节点表示来代替传统的聚合相邻节点信息的编码方法。",
    "tldr": "本研究提出了一种使用图神经网络控制意义到文本生成中的话题-焦点表达的方法，通过在意义表示中添加语用信息来强制使用主动或被动语态。研究采用了一种新的节点聚合编码策略，通过使用深度学习表示节点，来解决了意义中词序信息缺失的问题。",
    "en_tdlr": "This research proposes a method of controlling topic-focus articulation in meaning-to-text generation using graph neural networks. The method adds pragmatic information to the meaning representation to force the use of either active or passive voice. A novel encoding strategy for node aggregation in graph neural networks is also introduced to address the lack of word order information in the meaning."
}