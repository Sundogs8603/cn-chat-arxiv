{
    "title": "Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning",
    "abstract": "arXiv:2310.01061v2 Announce Type: replace-cross  Abstract: Large language models (LLMs) have demonstrated impressive reasoning abilities in complex tasks. However, they lack up-to-date knowledge and experience hallucinations during reasoning, which can lead to incorrect reasoning processes and diminish their performance and trustworthiness. Knowledge graphs (KGs), which capture vast amounts of facts in a structured format, offer a reliable source of knowledge for reasoning. Nevertheless, existing KG-based LLM reasoning methods only treat KGs as factual knowledge bases and overlook the importance of their structural information for reasoning. In this paper, we propose a novel method called reasoning on graphs (RoG) that synergizes LLMs with KGs to enable faithful and interpretable reasoning. Specifically, we present a planning-retrieval-reasoning framework, where RoG first generates relation paths grounded by KGs as faithful plans. These plans are then used to retrieve valid reasoning p",
    "link": "https://arxiv.org/abs/2310.01061",
    "context": "Title: Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning\nAbstract: arXiv:2310.01061v2 Announce Type: replace-cross  Abstract: Large language models (LLMs) have demonstrated impressive reasoning abilities in complex tasks. However, they lack up-to-date knowledge and experience hallucinations during reasoning, which can lead to incorrect reasoning processes and diminish their performance and trustworthiness. Knowledge graphs (KGs), which capture vast amounts of facts in a structured format, offer a reliable source of knowledge for reasoning. Nevertheless, existing KG-based LLM reasoning methods only treat KGs as factual knowledge bases and overlook the importance of their structural information for reasoning. In this paper, we propose a novel method called reasoning on graphs (RoG) that synergizes LLMs with KGs to enable faithful and interpretable reasoning. Specifically, we present a planning-retrieval-reasoning framework, where RoG first generates relation paths grounded by KGs as faithful plans. These plans are then used to retrieve valid reasoning p",
    "path": "papers/23/10/2310.01061.json",
    "total_tokens": 828,
    "translated_title": "在图上推理：忠实且可解释的大型语言模型推理",
    "translated_abstract": "大型语言模型（LLMs）在复杂任务中展示了令人印象深刻的推理能力。然而，在推理过程中它们缺乏最新知识，经历幻觉，这可能导致不正确的推理过程，并降低其性能和可信度。知识图（KGs）以结构化格式捕获了大量事实，为推理提供了可靠的知识来源。然而，现有基于KG的LLM推理方法只将KGs视为事实知识库，忽视其结构信息对推理的重要性。本文提出了一种称为图推理（RoG）的新方法，通过使LLMs与KGs协同工作，实现忠实且可解释的推理。具体而言，我们提出了一个规划-检索-推理的框架，其中RoG首先生成由KGs作为忠实计划的关系路径。这些计划然后用于检索有效的推理过程。",
    "tldr": "提出了一种名为图推理（RoG）的新方法，通过将LLMs与KGs协同工作，实现忠实且可解释的大型语言模型推理。",
    "en_tdlr": "Introduced a new method called reasoning on graphs (RoG) that synergizes LLMs with KGs to enable faithful and interpretable reasoning."
}