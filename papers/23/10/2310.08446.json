{
    "title": "Towards Robust Multi-Modal Reasoning via Model Selection",
    "abstract": "arXiv:2310.08446v2 Announce Type: replace-cross  Abstract: The reasoning capabilities of LLM (Large Language Model) are widely acknowledged in recent research, inspiring studies on tool learning and autonomous agents. LLM serves as the \"brain\" of the agent, orchestrating multiple tools for collaborative multi-step task solving. Unlike methods invoking tools like calculators or weather APIs for straightforward tasks, multi-modal agents excel by integrating diverse AI models for complex challenges. However, current multi-modal agents neglect the significance of model selection: they primarily focus on the planning and execution phases, and will only invoke predefined task-specific models for each subtask, making the execution fragile. Meanwhile, other traditional model selection methods are either incompatible with or suboptimal for the multi-modal agent scenarios, due to ignorance of dependencies among subtasks arising by multi-step reasoning. To this end, we identify the key challenges",
    "link": "https://arxiv.org/abs/2310.08446",
    "context": "Title: Towards Robust Multi-Modal Reasoning via Model Selection\nAbstract: arXiv:2310.08446v2 Announce Type: replace-cross  Abstract: The reasoning capabilities of LLM (Large Language Model) are widely acknowledged in recent research, inspiring studies on tool learning and autonomous agents. LLM serves as the \"brain\" of the agent, orchestrating multiple tools for collaborative multi-step task solving. Unlike methods invoking tools like calculators or weather APIs for straightforward tasks, multi-modal agents excel by integrating diverse AI models for complex challenges. However, current multi-modal agents neglect the significance of model selection: they primarily focus on the planning and execution phases, and will only invoke predefined task-specific models for each subtask, making the execution fragile. Meanwhile, other traditional model selection methods are either incompatible with or suboptimal for the multi-modal agent scenarios, due to ignorance of dependencies among subtasks arising by multi-step reasoning. To this end, we identify the key challenges",
    "path": "papers/23/10/2310.08446.json",
    "total_tokens": 787,
    "translated_title": "通过模型选择实现健壮的多模态推理",
    "translated_abstract": "最近的研究普遍承认了大型语言模型（LLM）的推理能力，在工具学习和自主代理研究中鼓舞了研究。LLM充当代理的“大脑”，为协作多步任务求解集成多个工具。多模态代理通过整合各种人工智能模型处理复杂挑战，在处理直观任务时不像调用计算器或天气API那样。然而，当前的多模态代理忽视了模型选择的重要性：它们主要专注于计划和执行阶段，只会为每个子任务调用预定义的任务特定模型，使执行变得脆弱。与此同时，其他传统的模型选择方法要么与多模态代理场景不兼容或不理想，因为它们忽视了多步推理产生的子任务之间的依赖关系。因此，我们确定了主要挑战。",
    "tldr": "多模态代理在处理复杂挑战时需要考虑模型选择的重要性，以避免执行的脆弱性。",
    "en_tdlr": "Multi-modal agents need to consider the importance of model selection in handling complex challenges to avoid fragility in execution."
}