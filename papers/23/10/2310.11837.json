{
    "title": "Optimising Distributions with Natural Gradient Surrogates. (arXiv:2310.11837v1 [stat.ML])",
    "abstract": "Natural gradient methods have been used to optimise the parameters of probability distributions in a variety of settings, often resulting in fast-converging procedures. Unfortunately, for many distributions of interest, computing the natural gradient has a number of challenges. In this work we propose a novel technique for tackling such issues, which involves reframing the optimisation as one with respect to the parameters of a surrogate distribution, for which computing the natural gradient is easy. We give several examples of existing methods that can be interpreted as applying this technique, and propose a new method for applying it to a wide variety of problems. Our method expands the set of distributions that can be efficiently targeted with natural gradients. Furthermore, it is fast, easy to understand, simple to implement using standard autodiff software, and does not require lengthy model-specific derivations. We demonstrate our method on maximum likelihood estimation and varia",
    "link": "http://arxiv.org/abs/2310.11837",
    "context": "Title: Optimising Distributions with Natural Gradient Surrogates. (arXiv:2310.11837v1 [stat.ML])\nAbstract: Natural gradient methods have been used to optimise the parameters of probability distributions in a variety of settings, often resulting in fast-converging procedures. Unfortunately, for many distributions of interest, computing the natural gradient has a number of challenges. In this work we propose a novel technique for tackling such issues, which involves reframing the optimisation as one with respect to the parameters of a surrogate distribution, for which computing the natural gradient is easy. We give several examples of existing methods that can be interpreted as applying this technique, and propose a new method for applying it to a wide variety of problems. Our method expands the set of distributions that can be efficiently targeted with natural gradients. Furthermore, it is fast, easy to understand, simple to implement using standard autodiff software, and does not require lengthy model-specific derivations. We demonstrate our method on maximum likelihood estimation and varia",
    "path": "papers/23/10/2310.11837.json",
    "total_tokens": 897,
    "translated_title": "使用自然梯度替代品优化分布",
    "translated_abstract": "自然梯度方法已经被用于优化各种情况下的概率分布参数，通常能得到快速收敛的过程。然而，对于许多感兴趣的分布，计算自然梯度存在一些挑战。在这项工作中，我们提出了一种新的技术来解决这些问题，这涉及将优化重新定义为关于替代分布参数的优化，计算自然梯度很容易。我们给出了几个可以解释为应用这种技术的现有方法的例子，并提出了一种新的方法，可以将其应用于各种问题。我们的方法扩展了可以有效使用自然梯度的分布集合。此外，它快速、易于理解，可以使用标准的自动微分软件进行简单实现，并且不需要冗长的模型特定导数计算。我们在最大似然估计和变分推断上演示了我们的方法。",
    "tldr": "本研究提出了一种新的技术，通过重新定义优化过程为针对易于计算自然梯度的替代分布的参数优化来解决计算自然梯度的挑战。该方法能够扩展可应用自然梯度的分布范围，速度快且易于实现。",
    "en_tdlr": "This research proposes a novel technique to address the challenges of computing natural gradients by reframing the optimization process as one with respect to the parameters of a surrogate distribution for which computing the natural gradient is easy. The method expands the range of distributions that can be efficiently targeted with natural gradients and is fast and easy to implement."
}