{
    "title": "LocSelect: Target Speaker Localization with an Auditory Selective Hearing Mechanism. (arXiv:2310.10497v2 [cs.SD] UPDATED)",
    "abstract": "The prevailing noise-resistant and reverberation-resistant localization algorithms primarily emphasize separating and providing directional output for each speaker in multi-speaker scenarios, without association with the identity of speakers. In this paper, we present a target speaker localization algorithm with a selective hearing mechanism. Given a reference speech of the target speaker, we first produce a speaker-dependent spectrogram mask to eliminate interfering speakers' speech. Subsequently, a Long short-term memory (LSTM) network is employed to extract the target speaker's location from the filtered spectrogram. Experiments validate the superiority of our proposed method over the existing algorithms for different scale invariant signal-to-noise ratios (SNR) conditions. Specifically, at SNR = -10 dB, our proposed network LocSelect achieves a mean absolute error (MAE) of 3.55 and an accuracy (ACC) of 87.40%.",
    "link": "http://arxiv.org/abs/2310.10497",
    "context": "Title: LocSelect: Target Speaker Localization with an Auditory Selective Hearing Mechanism. (arXiv:2310.10497v2 [cs.SD] UPDATED)\nAbstract: The prevailing noise-resistant and reverberation-resistant localization algorithms primarily emphasize separating and providing directional output for each speaker in multi-speaker scenarios, without association with the identity of speakers. In this paper, we present a target speaker localization algorithm with a selective hearing mechanism. Given a reference speech of the target speaker, we first produce a speaker-dependent spectrogram mask to eliminate interfering speakers' speech. Subsequently, a Long short-term memory (LSTM) network is employed to extract the target speaker's location from the filtered spectrogram. Experiments validate the superiority of our proposed method over the existing algorithms for different scale invariant signal-to-noise ratios (SNR) conditions. Specifically, at SNR = -10 dB, our proposed network LocSelect achieves a mean absolute error (MAE) of 3.55 and an accuracy (ACC) of 87.40%.",
    "path": "papers/23/10/2310.10497.json",
    "total_tokens": 831,
    "translated_title": "LocSelect: 具有听觉选择性听觉机制的目标说话人定位",
    "translated_abstract": "发表该论文提出了一种具有选择性听觉机制的目标说话人定位算法。通过给定目标说话人的参考语音，首先生成一个说话人相关的频谱掩蔽，以消除干扰说话人的语音。然后，使用长短时记忆（LSTM）网络从过滤后的频谱中提取目标说话人的位置。实验证实，我们提出的方法在不同的尺度不变信噪比（SNR）条件下优于现有算法。具体而言，当SNR为-10 dB时，我们的网络LocSelect实现了平均绝对误差（MAE）为3.55和准确性（ACC）为87.40%。",
    "tldr": "该论文提出了一种具有选择性听觉机制的目标说话人定位算法，通过生成说话人相关的频谱掩蔽来消除干扰说话人的语音，并使用LSTM网络从过滤后的频谱中提取目标说话人的位置。实验证实该方法在不同的信噪比条件下表现优异。"
}