{
    "title": "Error Norm Truncation: Robust Training in the Presence of Data Noise for Text Generation Models",
    "abstract": "arXiv:2310.00840v2 Announce Type: replace  Abstract: Text generation models are notoriously vulnerable to errors in the training data. With the wide-spread availability of massive amounts of web-crawled data becoming more commonplace, how can we enhance the robustness of models trained on a massive amount of noisy web-crawled text? In our work, we propose Error Norm Truncation (ENT), a robust enhancement method to the standard training objective that truncates noisy data. Compared to methods that only uses the negative log-likelihood loss to estimate data quality, our method provides a more accurate estimation by considering the distribution of non-target tokens, which is often overlooked by previous work. Through comprehensive experiments across language modeling, machine translation, and text summarization, we show that equipping text generation models with ENT improves generation quality over standard training and previous soft and hard truncation methods. Furthermore, we show that ",
    "link": "https://arxiv.org/abs/2310.00840",
    "context": "Title: Error Norm Truncation: Robust Training in the Presence of Data Noise for Text Generation Models\nAbstract: arXiv:2310.00840v2 Announce Type: replace  Abstract: Text generation models are notoriously vulnerable to errors in the training data. With the wide-spread availability of massive amounts of web-crawled data becoming more commonplace, how can we enhance the robustness of models trained on a massive amount of noisy web-crawled text? In our work, we propose Error Norm Truncation (ENT), a robust enhancement method to the standard training objective that truncates noisy data. Compared to methods that only uses the negative log-likelihood loss to estimate data quality, our method provides a more accurate estimation by considering the distribution of non-target tokens, which is often overlooked by previous work. Through comprehensive experiments across language modeling, machine translation, and text summarization, we show that equipping text generation models with ENT improves generation quality over standard training and previous soft and hard truncation methods. Furthermore, we show that ",
    "path": "papers/23/10/2310.00840.json",
    "total_tokens": 870,
    "translated_title": "错误范数截断：针对数据噪音的文本生成模型的鲁棒训练",
    "translated_abstract": "文本生成模型在训练数据存在错误时往往容易受到影响。随着海量网络抓取数据的普遍可用，我们如何增强在大量嘈杂的网络抓取文本上训练的模型的鲁棒性呢？在我们的研究中，我们提出了一种名为错误范数截断（ENT）的鲁棒增强方法，可以截断嘈杂的数据。与仅使用负对数似然损失来估计数据质量的方法相比，我们的方法通过考虑非目标标记的分布，提供了更准确的估计，这在以往的研究中经常被忽略。通过对语言建模、机器翻译和文本摘要的全面实验，我们展示了将文本生成模型配备错误范数截断能够改善生成质量，优于标准训练和先前软截断和硬截断方法。",
    "tldr": "提出了错误范数截断（ENT）方法，通过考虑非目标标记的分布从而提供更准确的数据截断，证实在文本生成模型中应用ENT可以改善生成质量。",
    "en_tdlr": "Proposed Error Norm Truncation (ENT) method provides a more accurate data truncation by considering the distribution of non-target tokens, demonstrating the effectiveness of applying ENT in improving generation quality for text generation models."
}