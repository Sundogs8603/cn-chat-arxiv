{
    "title": "Spectral Neural Networks: Approximation Theory and Optimization Landscape. (arXiv:2310.00729v1 [cs.LG])",
    "abstract": "There is a large variety of machine learning methodologies that are based on the extraction of spectral geometric information from data. However, the implementations of many of these methods often depend on traditional eigensolvers, which present limitations when applied in practical online big data scenarios. To address some of these challenges, researchers have proposed different strategies for training neural networks as alternatives to traditional eigensolvers, with one such approach known as Spectral Neural Network (SNN). In this paper, we investigate key theoretical aspects of SNN. First, we present quantitative insights into the tradeoff between the number of neurons and the amount of spectral geometric information a neural network learns. Second, we initiate a theoretical exploration of the optimization landscape of SNN's objective to shed light on the training dynamics of SNN. Unlike typical studies of convergence to global solutions of NN training dynamics, SNN presents an ad",
    "link": "http://arxiv.org/abs/2310.00729",
    "context": "Title: Spectral Neural Networks: Approximation Theory and Optimization Landscape. (arXiv:2310.00729v1 [cs.LG])\nAbstract: There is a large variety of machine learning methodologies that are based on the extraction of spectral geometric information from data. However, the implementations of many of these methods often depend on traditional eigensolvers, which present limitations when applied in practical online big data scenarios. To address some of these challenges, researchers have proposed different strategies for training neural networks as alternatives to traditional eigensolvers, with one such approach known as Spectral Neural Network (SNN). In this paper, we investigate key theoretical aspects of SNN. First, we present quantitative insights into the tradeoff between the number of neurons and the amount of spectral geometric information a neural network learns. Second, we initiate a theoretical exploration of the optimization landscape of SNN's objective to shed light on the training dynamics of SNN. Unlike typical studies of convergence to global solutions of NN training dynamics, SNN presents an ad",
    "path": "papers/23/10/2310.00729.json",
    "total_tokens": 877,
    "translated_title": "光谱神经网络：逼近理论和优化路径的研究",
    "translated_abstract": "有许多基于从数据中提取光谱几何信息的机器学习方法。然而，许多这些方法的实现往往依赖于传统的特征求解器，在实际的在线大数据场景中存在一些限制。为了解决这些挑战，研究人员提出了不同的策略来训练神经网络作为传统特征求解器的替代方案，其中一种方法被称为光谱神经网络（SNN）。在本文中，我们研究了SNN的关键理论方面。首先，我们对神经网络学习光谱几何信息的神经元数量和量之间的权衡提出了定量洞察。其次，我们对SNN目标的优化路径进行了理论探索，以揭示SNN的训练动态。与典型的神经网络训练动态收敛到全局解的研究不同，SNN呈现了某种程度上的保守。",
    "tldr": "这项研究探索了光谱神经网络（SNN）的关键理论方面，包括神经网络学习光谱几何信息的权衡和SNN优化路径的理论探索。"
}