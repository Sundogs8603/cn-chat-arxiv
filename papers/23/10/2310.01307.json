{
    "title": "On the Generalization of Training-based ChatGPT Detection Methods. (arXiv:2310.01307v2 [cs.CL] UPDATED)",
    "abstract": "ChatGPT is one of the most popular language models which achieve amazing performance on various natural language tasks. Consequently, there is also an urgent need to detect the texts generated ChatGPT from human written. One of the extensively studied methods trains classification models to distinguish both. However, existing studies also demonstrate that the trained models may suffer from distribution shifts (during test), i.e., they are ineffective to predict the generated texts from unseen language tasks or topics. In this work, we aim to have a comprehensive investigation on these methods' generalization behaviors under distribution shift caused by a wide range of factors, including prompts, text lengths, topics, and language tasks. To achieve this goal, we first collect a new dataset with human and ChatGPT texts, and then we conduct extensive studies on the collected dataset. Our studies unveil insightful findings which provide guidance for developing future methodologies or data ",
    "link": "http://arxiv.org/abs/2310.01307",
    "context": "Title: On the Generalization of Training-based ChatGPT Detection Methods. (arXiv:2310.01307v2 [cs.CL] UPDATED)\nAbstract: ChatGPT is one of the most popular language models which achieve amazing performance on various natural language tasks. Consequently, there is also an urgent need to detect the texts generated ChatGPT from human written. One of the extensively studied methods trains classification models to distinguish both. However, existing studies also demonstrate that the trained models may suffer from distribution shifts (during test), i.e., they are ineffective to predict the generated texts from unseen language tasks or topics. In this work, we aim to have a comprehensive investigation on these methods' generalization behaviors under distribution shift caused by a wide range of factors, including prompts, text lengths, topics, and language tasks. To achieve this goal, we first collect a new dataset with human and ChatGPT texts, and then we conduct extensive studies on the collected dataset. Our studies unveil insightful findings which provide guidance for developing future methodologies or data ",
    "path": "papers/23/10/2310.01307.json",
    "total_tokens": 912,
    "translated_title": "关于基于训练的ChatGPT检测方法的泛化性研究",
    "translated_abstract": "ChatGPT是最受欢迎的语言模型之一，在各种自然语言任务上表现出色。因此，有迫切的需求从人类编写的文本中检测出由ChatGPT生成的文本。一种广泛研究的方法是训练分类模型来区分二者。然而，现有研究也表明，在测试过程中，训练的模型可能会遭受分布漂移的影响，即它们对于预测未见过的语言任务或主题生成的文本是无效的。在这项工作中，我们旨在全面研究这些方法在由多种因素引起的分布漂移下的泛化行为，包括提示、文本长度、主题和语言任务。为实现这一目标，我们首先收集了一个包含人类和ChatGPT文本的新数据集，然后对收集的数据集进行了广泛的研究。我们的研究揭示了有启示性的发现，为未来方法或数据的开发提供了指导。",
    "tldr": "本研究综合调查了基于训练的ChatGPT检测方法在分布漂移下的泛化行为，包括提示、文本长度、主题和语言任务，在新数据集上揭示了有启示性的发现，为未来方法或数据的开发提供了指导。",
    "en_tdlr": "This study investigates the generalization behaviors of training-based ChatGPT detection methods under distribution shifts caused by factors such as prompts, text lengths, topics, and language tasks. Insightful findings are revealed on a new dataset, providing guidance for future methodologies or data development."
}