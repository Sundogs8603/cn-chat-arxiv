{
    "title": "Symbolic Planning and Code Generation for Grounded Dialogue. (arXiv:2310.17140v1 [cs.CL])",
    "abstract": "Large language models (LLMs) excel at processing and generating both text and code. However, LLMs have had limited applicability in grounded task-oriented dialogue as they are difficult to steer toward task objectives and fail to handle novel grounding. We present a modular and interpretable grounded dialogue system that addresses these shortcomings by composing LLMs with a symbolic planner and grounded code execution. Our system consists of a reader and planner: the reader leverages an LLM to convert partner utterances into executable code, calling functions that perform grounding. The translated code's output is stored to track dialogue state, while a symbolic planner determines the next appropriate response. We evaluate our system's performance on the demanding OneCommon dialogue task, involving collaborative reference resolution on abstract images of scattered dots. Our system substantially outperforms the previous state-of-the-art, including improving task success in human evaluat",
    "link": "http://arxiv.org/abs/2310.17140",
    "context": "Title: Symbolic Planning and Code Generation for Grounded Dialogue. (arXiv:2310.17140v1 [cs.CL])\nAbstract: Large language models (LLMs) excel at processing and generating both text and code. However, LLMs have had limited applicability in grounded task-oriented dialogue as they are difficult to steer toward task objectives and fail to handle novel grounding. We present a modular and interpretable grounded dialogue system that addresses these shortcomings by composing LLMs with a symbolic planner and grounded code execution. Our system consists of a reader and planner: the reader leverages an LLM to convert partner utterances into executable code, calling functions that perform grounding. The translated code's output is stored to track dialogue state, while a symbolic planner determines the next appropriate response. We evaluate our system's performance on the demanding OneCommon dialogue task, involving collaborative reference resolution on abstract images of scattered dots. Our system substantially outperforms the previous state-of-the-art, including improving task success in human evaluat",
    "path": "papers/23/10/2310.17140.json",
    "total_tokens": 950,
    "translated_title": "符号化规划和代码生成在基于实际对话中的应用",
    "translated_abstract": "大型语言模型(LLMs)在处理和生成文本和代码方面表现出色。然而，在基于任务的对话中，LLMs的适用性有限，因为很难引导其朝着任务目标前进，并且无法处理新颖的基于实际对话。我们提出了一个模块化和可解释的基于实际对话系统，通过组合LLMs和符号化规划器以及基于实际的代码执行，解决了这些缺点。我们的系统由阅读器和规划器组成：阅读器利用LLMs将合作伙伴的话语转换为可执行的代码，调用执行基于实际的函数。转换后的代码的输出被存储以跟踪对话状态，而符号化规划器确定下一个适当的响应。我们在要求高的OneCommon对话任务上评估了我们系统的性能，该任务涉及解决散点图像的协同参考问题。我们的系统在先前的最先进技术的基础上实现了显著的性能提升，包括在人工评估中改善了任务成功率。",
    "tldr": "该论文介绍了一个模块化和可解释的基于实际对话系统，通过组合大型语言模型(LLMs)、符号化规划器和基于实际的代码执行来解决基于任务的对话中的挑战。实验证明该系统在协同参考解析任务上的性能显著优于先前的最先进技术。",
    "en_tdlr": "This paper presents a modular and interpretable grounded dialogue system that combines large language models (LLMs), symbolic planners, and grounded code execution to address the challenges in task-oriented dialogue. Experimental results show that the system outperforms the previous state-of-the-art in the task of collaborative reference resolution."
}