{
    "title": "Data Optimization in Deep Learning: A Survey. (arXiv:2310.16499v1 [cs.LG])",
    "abstract": "Large-scale, high-quality data are considered an essential factor for the successful application of many deep learning techniques. Meanwhile, numerous real-world deep learning tasks still have to contend with the lack of sufficient amounts of high-quality data. Additionally, issues such as model robustness, fairness, and trustworthiness are also closely related to training data. Consequently, a huge number of studies in the existing literature have focused on the data aspect in deep learning tasks. Some typical data optimization techniques include data augmentation, logit perturbation, sample weighting, and data condensation. These techniques usually come from different deep learning divisions and their theoretical inspirations or heuristic motivations may seem unrelated to each other. This study aims to organize a wide range of existing data optimization methodologies for deep learning from the previous literature, and makes the effort to construct a comprehensive taxonomy for them. T",
    "link": "http://arxiv.org/abs/2310.16499",
    "context": "Title: Data Optimization in Deep Learning: A Survey. (arXiv:2310.16499v1 [cs.LG])\nAbstract: Large-scale, high-quality data are considered an essential factor for the successful application of many deep learning techniques. Meanwhile, numerous real-world deep learning tasks still have to contend with the lack of sufficient amounts of high-quality data. Additionally, issues such as model robustness, fairness, and trustworthiness are also closely related to training data. Consequently, a huge number of studies in the existing literature have focused on the data aspect in deep learning tasks. Some typical data optimization techniques include data augmentation, logit perturbation, sample weighting, and data condensation. These techniques usually come from different deep learning divisions and their theoretical inspirations or heuristic motivations may seem unrelated to each other. This study aims to organize a wide range of existing data optimization methodologies for deep learning from the previous literature, and makes the effort to construct a comprehensive taxonomy for them. T",
    "path": "papers/23/10/2310.16499.json",
    "total_tokens": 769,
    "translated_title": "深度学习中的数据优化：一项综述研究",
    "translated_abstract": "大规模、高质量的数据被认为是许多深度学习技术成功应用的关键因素。然而，许多实际深度学习任务仍然面临着缺乏足够数量高质量数据的问题。此外，模型的稳健性、公平性和可信度等问题也与训练数据密切相关。因此，大量现有文献中的研究都集中在深度学习任务中的数据方面。一些典型的数据优化技术包括数据增强、逻辑扰动、样本加权和数据压缩。这些技术通常来自于不同的深度学习领域，它们的理论灵感或启发动机可能看似无关。本研究旨在组织广泛的现有数据优化方法论并构建一个全面的分类体系。",
    "tldr": "该论文综合了现有的深度学习数据优化方法，并提出了全面的分类体系。",
    "en_tdlr": "This paper presents a comprehensive taxonomy of existing data optimization techniques in deep learning, covering various methodologies and providing a comprehensive framework."
}