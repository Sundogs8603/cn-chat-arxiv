{
    "title": "BayesDiff: Estimating Pixel-wise Uncertainty in Diffusion via Bayesian Inference. (arXiv:2310.11142v1 [cs.CV])",
    "abstract": "Diffusion models have impressive image generation capability, but low-quality generations still exist, and their identification remains challenging due to the lack of a proper sample-wise metric. To address this, we propose BayesDiff, a pixel-wise uncertainty estimator for generations from diffusion models based on Bayesian inference. In particular, we derive a novel uncertainty iteration principle to characterize the uncertainty dynamics in diffusion, and leverage the last-layer Laplace approximation for efficient Bayesian inference. The estimated pixel-wise uncertainty can not only be aggregated into a sample-wise metric to filter out low-fidelity images but also aids in augmenting successful generations and rectifying artifacts in failed generations in text-to-image tasks. Extensive experiments demonstrate the efficacy of BayesDiff and its promise for practical applications.",
    "link": "http://arxiv.org/abs/2310.11142",
    "context": "Title: BayesDiff: Estimating Pixel-wise Uncertainty in Diffusion via Bayesian Inference. (arXiv:2310.11142v1 [cs.CV])\nAbstract: Diffusion models have impressive image generation capability, but low-quality generations still exist, and their identification remains challenging due to the lack of a proper sample-wise metric. To address this, we propose BayesDiff, a pixel-wise uncertainty estimator for generations from diffusion models based on Bayesian inference. In particular, we derive a novel uncertainty iteration principle to characterize the uncertainty dynamics in diffusion, and leverage the last-layer Laplace approximation for efficient Bayesian inference. The estimated pixel-wise uncertainty can not only be aggregated into a sample-wise metric to filter out low-fidelity images but also aids in augmenting successful generations and rectifying artifacts in failed generations in text-to-image tasks. Extensive experiments demonstrate the efficacy of BayesDiff and its promise for practical applications.",
    "path": "papers/23/10/2310.11142.json",
    "total_tokens": 886,
    "translated_title": "BayesDiff: 通过贝叶斯推断估计扩散中的像素级不确定性",
    "translated_abstract": "扩散模型在图像生成方面表现出色，但仍存在质量较低的生成结果，并且由于缺乏适当的样本度量，对其进行鉴别仍然具有挑战性。为了解决这个问题，我们提出了BayesDiff，一种基于贝叶斯推断的用于扩散模型生成结果的像素级不确定性估计器。具体而言，我们提出了一种新的不确定性迭代原则来描述扩散中的不确定性动态，并利用最后一层的拉普拉斯近似来实现高效的贝叶斯推断。估计的像素级不确定性不仅可以聚合成样本级度量，以过滤出质量较低的图像，而且还可以在文本转图像任务中增强成功的生成结果并纠正失败的生成结果中的伪影。大量实验证明了BayesDiff的有效性及其在实际应用中的潜力。",
    "tldr": "BayesDiff提出了一种像素级不确定性估计方法，用于扩散模型生成结果。该方法通过贝叶斯推断和不确定性迭代原则来实现高效的估计，并可在图像生成任务中过滤低质量图像，增强成功生成结果，并纠正失败生成结果中的伪影。",
    "en_tdlr": "BayesDiff proposes a pixel-wise uncertainty estimation method for generation results from diffusion models. This method achieves efficient estimation through Bayesian inference and the iteration principle of uncertainty, and can filter out low-quality images, enhance successful generation results, and rectify artifacts in failed generation results in image generation tasks."
}