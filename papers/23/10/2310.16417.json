{
    "title": "Enhanced Simultaneous Machine Translation with Word-level Policies. (arXiv:2310.16417v1 [cs.CL])",
    "abstract": "Recent years have seen remarkable advances in the field of Simultaneous Machine Translation (SiMT) due to the introduction of innovative policies that dictate whether to READ or WRITE at each step of the translation process. However, a common assumption in many existing studies is that operations are carried out at the subword level, even though the standard unit for input and output in most practical scenarios is typically at the word level. This paper demonstrates that policies devised and validated at the subword level are surpassed by those operating at the word level, which process multiple subwords to form a complete word in a single step. Additionally, we suggest a method to boost SiMT models using language models (LMs), wherein the proposed word-level policy plays a vital role in addressing the subword disparity between LMs and SiMT models. Code is available at https://github.com/xl8-ai/WordSiMT.",
    "link": "http://arxiv.org/abs/2310.16417",
    "context": "Title: Enhanced Simultaneous Machine Translation with Word-level Policies. (arXiv:2310.16417v1 [cs.CL])\nAbstract: Recent years have seen remarkable advances in the field of Simultaneous Machine Translation (SiMT) due to the introduction of innovative policies that dictate whether to READ or WRITE at each step of the translation process. However, a common assumption in many existing studies is that operations are carried out at the subword level, even though the standard unit for input and output in most practical scenarios is typically at the word level. This paper demonstrates that policies devised and validated at the subword level are surpassed by those operating at the word level, which process multiple subwords to form a complete word in a single step. Additionally, we suggest a method to boost SiMT models using language models (LMs), wherein the proposed word-level policy plays a vital role in addressing the subword disparity between LMs and SiMT models. Code is available at https://github.com/xl8-ai/WordSiMT.",
    "path": "papers/23/10/2310.16417.json",
    "total_tokens": 872,
    "translated_title": "通过词级策略提升同时机器翻译",
    "translated_abstract": "最近几年，在同时机器翻译（SiMT）领域取得了显著进展，这要归功于引入了创新的策略，决定了在翻译过程的每一步中是读取还是写入。然而，许多现有研究中的一个常见假设是，操作是在子词级别进行的，尽管在大多数实际场景中，输入和输出的标准单位通常是以词为单位。本文证明了在子词级别制定和验证的策略被在以词为单位进行操作的策略超越，并且这些策略一次处理多个子词以形成一个完整的词。此外，我们提出了一种使用语言模型（LMs）提升SiMT模型的方法，其中所提出的词级策略在解决LMs和SiMT模型之间的子词差异中起着重要作用。代码可在https://github.com/xl8-ai/WordSiMT找到。",
    "tldr": "本论文提出了一种使用词级策略提升同时机器翻译的方法，并证明了词级策略优于子词级策略，并且提出了一种使用语言模型的方法来改进同时机器翻译模型。",
    "en_tdlr": "This paper presents a method to enhance simultaneous machine translation using word-level policies, demonstrating that word-level policies surpass subword-level policies and suggesting the use of language models to improve simultaneous machine translation models."
}