{
    "title": "A Comparative Study of Transformer-based Neural Text Representation Techniques on Bug Triaging. (arXiv:2310.06913v1 [cs.SE])",
    "abstract": "Often, the first step in managing bug reports is related to triaging a bug to the appropriate developer who is best suited to understand, localize, and fix the target bug. Additionally, assigning a given bug to a particular part of a software project can help to expedite the fixing process. However, despite the importance of these activities, they are quite challenging, where days can be spent on the manual triaging process. Past studies have attempted to leverage the limited textual data of bug reports to train text classification models that automate this process -- to varying degrees of success. However, the textual representations and machine learning models used in prior work are limited by their expressiveness, often failing to capture nuanced textual patterns that might otherwise aid in the triaging process. Recently, large, transformer-based, pre-trained neural text representation techniques such as BERT have achieved greater performance in several natural language processing t",
    "link": "http://arxiv.org/abs/2310.06913",
    "context": "Title: A Comparative Study of Transformer-based Neural Text Representation Techniques on Bug Triaging. (arXiv:2310.06913v1 [cs.SE])\nAbstract: Often, the first step in managing bug reports is related to triaging a bug to the appropriate developer who is best suited to understand, localize, and fix the target bug. Additionally, assigning a given bug to a particular part of a software project can help to expedite the fixing process. However, despite the importance of these activities, they are quite challenging, where days can be spent on the manual triaging process. Past studies have attempted to leverage the limited textual data of bug reports to train text classification models that automate this process -- to varying degrees of success. However, the textual representations and machine learning models used in prior work are limited by their expressiveness, often failing to capture nuanced textual patterns that might otherwise aid in the triaging process. Recently, large, transformer-based, pre-trained neural text representation techniques such as BERT have achieved greater performance in several natural language processing t",
    "path": "papers/23/10/2310.06913.json",
    "total_tokens": 875,
    "translated_title": "基于Transformer的神经文本表示技术在缺陷分配中的比较研究",
    "translated_abstract": "在管理缺陷报告时，通常第一步是将缺陷分配给最适合理解、定位和修复目标缺陷的开发人员。此外，将给定的缺陷分配给软件项目的特定部分可以加快修复过程。然而，尽管这些活动的重要性，但在手动分配的过程中可能需要花费几天的时间。过去的研究尝试利用有限的文本数据训练文本分类模型来自动化这个过程，但得到的成功程度参差不齐。然而，先前工作中使用的文本表示和机器学习模型受到其表达能力的限制，往往无法捕捉到可以帮助缺陷分配过程的微妙文本模式。最近，基于Transformer的大型预训练神经文本表示技术（如BERT）在几个自然语言处理任务中取得了更好的性能。",
    "tldr": "本文研究了基于Transformer的神经文本表示技术在缺陷分配中的应用，相比之前的方法，这些新技术能更好地捕捉微妙的文本模式，提高自动化缺陷分配的性能。",
    "en_tdlr": "This paper investigates the application of Transformer-based neural text representation techniques in bug triaging. Compared to previous methods, these new techniques are able to better capture nuanced textual patterns and improve the performance of automated bug assignment."
}