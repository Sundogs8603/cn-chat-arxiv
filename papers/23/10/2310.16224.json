{
    "title": "Poison is Not Traceless: Fully-Agnostic Detection of Poisoning Attacks. (arXiv:2310.16224v1 [cs.CR])",
    "abstract": "The performance of machine learning models depends on the quality of the underlying data. Malicious actors can attack the model by poisoning the training data. Current detectors are tied to either specific data types, models, or attacks, and therefore have limited applicability in real-world scenarios. This paper presents a novel fully-agnostic framework, DIVA (Detecting InVisible Attacks), that detects attacks solely relying on analyzing the potentially poisoned data set. DIVA is based on the idea that poisoning attacks can be detected by comparing the classifier's accuracy on poisoned and clean data and pre-trains a meta-learner using Complexity Measures to estimate the otherwise unknown accuracy on a hypothetical clean dataset. The framework applies to generic poisoning attacks. For evaluation purposes, in this paper, we test DIVA on label-flipping attacks.",
    "link": "http://arxiv.org/abs/2310.16224",
    "context": "Title: Poison is Not Traceless: Fully-Agnostic Detection of Poisoning Attacks. (arXiv:2310.16224v1 [cs.CR])\nAbstract: The performance of machine learning models depends on the quality of the underlying data. Malicious actors can attack the model by poisoning the training data. Current detectors are tied to either specific data types, models, or attacks, and therefore have limited applicability in real-world scenarios. This paper presents a novel fully-agnostic framework, DIVA (Detecting InVisible Attacks), that detects attacks solely relying on analyzing the potentially poisoned data set. DIVA is based on the idea that poisoning attacks can be detected by comparing the classifier's accuracy on poisoned and clean data and pre-trains a meta-learner using Complexity Measures to estimate the otherwise unknown accuracy on a hypothetical clean dataset. The framework applies to generic poisoning attacks. For evaluation purposes, in this paper, we test DIVA on label-flipping attacks.",
    "path": "papers/23/10/2310.16224.json",
    "total_tokens": 925,
    "translated_title": "毒药不是无痕的：全面不可知的检测毒害攻击",
    "translated_abstract": "机器学习模型的性能取决于底层数据的质量。恶意攻击者可以通过毒化训练数据来攻击模型。当前的检测器针对特定数据类型、模型或攻击类型，因此在现实场景中具有有限的适用性。本文提出了一种新颖的全面不可知框架DIVA（检测不可见攻击），仅通过分析潜在毒害数据集来检测攻击。DIVA基于这样一个思想，即通过比较分类器在受到毒害和干净数据上的准确性来检测毒害攻击，并使用复杂性度量预训练元学习器来估计在假设的干净数据集上的未知准确性。该框架适用于一般的毒害攻击。为了评估目的，在本文中，我们在标签翻转攻击上测试了DIVA。",
    "tldr": "这项研究提出了一种全面不可知的框架DIVA，通过分析潜在的毒害数据集来检测机器学习模型遭受的攻击。通过比较模型在受到毒害和干净数据上的准确性，DIVA能够预测未知的干净数据集上的准确性，从而实现对一般毒害攻击的检测。"
}