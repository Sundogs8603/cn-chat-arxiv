{
    "title": "Chameleon: Increasing Label-Only Membership Leakage with Adaptive Poisoning. (arXiv:2310.03838v1 [cs.LG])",
    "abstract": "The integration of machine learning (ML) in numerous critical applications introduces a range of privacy concerns for individuals who provide their datasets for model training. One such privacy risk is Membership Inference (MI), in which an attacker seeks to determine whether a particular data sample was included in the training dataset of a model. Current state-of-the-art MI attacks capitalize on access to the model's predicted confidence scores to successfully perform membership inference, and employ data poisoning to further enhance their effectiveness. In this work, we focus on the less explored and more realistic label-only setting, where the model provides only the predicted label on a queried sample. We show that existing label-only MI attacks are ineffective at inferring membership in the low False Positive Rate (FPR) regime. To address this challenge, we propose a new attack Chameleon that leverages a novel adaptive data poisoning strategy and an efficient query selection meth",
    "link": "http://arxiv.org/abs/2310.03838",
    "context": "Title: Chameleon: Increasing Label-Only Membership Leakage with Adaptive Poisoning. (arXiv:2310.03838v1 [cs.LG])\nAbstract: The integration of machine learning (ML) in numerous critical applications introduces a range of privacy concerns for individuals who provide their datasets for model training. One such privacy risk is Membership Inference (MI), in which an attacker seeks to determine whether a particular data sample was included in the training dataset of a model. Current state-of-the-art MI attacks capitalize on access to the model's predicted confidence scores to successfully perform membership inference, and employ data poisoning to further enhance their effectiveness. In this work, we focus on the less explored and more realistic label-only setting, where the model provides only the predicted label on a queried sample. We show that existing label-only MI attacks are ineffective at inferring membership in the low False Positive Rate (FPR) regime. To address this challenge, we propose a new attack Chameleon that leverages a novel adaptive data poisoning strategy and an efficient query selection meth",
    "path": "papers/23/10/2310.03838.json",
    "total_tokens": 816,
    "translated_title": "Chameleon: 使用自适应污染增强标签唯一成员泄露",
    "translated_abstract": "在众多关键应用中引入机器学习(ML)后，个人数据提供者面临多种隐私问题。其中之一是成员推理(MI)，攻击者试图确定特定数据样本是否包含在模型的训练数据集中。目前的MI攻击利用模型的预测置信度分数来成功进行成员推理，并通过数据污染进一步提高效果。在这项工作中，我们关注较少探索且更现实的仅标签设置中，模型仅在查询样本上提供预测的标签。我们表明现有的仅标签MI攻击在低误报率(FPR)情况下无法有效推断成员身份。为了应对这一挑战，我们提出了一种新的攻击方法Chameleon，它利用一种新颖的自适应数据污染策略和高效的查询选择方法。",
    "tldr": "Chameleon是一种新的成员推理攻击方法，利用自适应数据污染策略和高效的查询选择方法，可在标签唯一设置中提高成员泄露的准确率。"
}