{
    "title": "PathRL: An End-to-End Path Generation Method for Collision Avoidance via Deep Reinforcement Learning. (arXiv:2310.13295v1 [cs.RO])",
    "abstract": "Robot navigation using deep reinforcement learning (DRL) has shown great potential in improving the performance of mobile robots. Nevertheless, most existing DRL-based navigation methods primarily focus on training a policy that directly commands the robot with low-level controls, like linear and angular velocities, which leads to unstable speeds and unsmooth trajectories of the robot during the long-term execution. An alternative method is to train a DRL policy that outputs the navigation path directly. However, two roadblocks arise for training a DRL policy that outputs paths: (1) The action space for potential paths often involves higher dimensions comparing to low-level commands, which increases the difficulties of training; (2) It takes multiple time steps to track a path instead of a single time step, which requires the path to predicate the interactions of the robot w.r.t. the dynamic environment in multiple time steps. This, in turn, amplifies the challenges associated with tra",
    "link": "http://arxiv.org/abs/2310.13295",
    "context": "Title: PathRL: An End-to-End Path Generation Method for Collision Avoidance via Deep Reinforcement Learning. (arXiv:2310.13295v1 [cs.RO])\nAbstract: Robot navigation using deep reinforcement learning (DRL) has shown great potential in improving the performance of mobile robots. Nevertheless, most existing DRL-based navigation methods primarily focus on training a policy that directly commands the robot with low-level controls, like linear and angular velocities, which leads to unstable speeds and unsmooth trajectories of the robot during the long-term execution. An alternative method is to train a DRL policy that outputs the navigation path directly. However, two roadblocks arise for training a DRL policy that outputs paths: (1) The action space for potential paths often involves higher dimensions comparing to low-level commands, which increases the difficulties of training; (2) It takes multiple time steps to track a path instead of a single time step, which requires the path to predicate the interactions of the robot w.r.t. the dynamic environment in multiple time steps. This, in turn, amplifies the challenges associated with tra",
    "path": "papers/23/10/2310.13295.json",
    "total_tokens": 1069,
    "translated_title": "PathRL：一种基于深度强化学习的端到端路径生成方法，用于碰撞避免",
    "translated_abstract": "深度强化学习（DRL）在改善移动机器人性能方面显示出巨大潜力。然而，大多数现有的基于DRL的导航方法主要集中在训练一个直接指导机器人的策略，如线性和角速度，这导致机器人在长期执行过程中的速度不稳定和轨迹不平滑。另一种方法是训练一个直接输出导航路径的DRL策略。然而，训练输出路径的DRL策略面临两个难题：（1）潜在路径的动作空间通常涉及比低级指令更高的维度，增加了训练的难度；（2）跟踪路径需要多个时间步骤，而不是单个时间步骤，这要求路径在多个时间步骤内预测机器人与动态环境的相互作用。这反过来增加了与路径跟踪相关的挑战。",
    "tldr": "这项研究提出了PathRL，一种使用深度强化学习生成导航路径的端到端方法。传统的DRL方法通过训练低级控制指令来直接指导机器人行动，但这导致速度不稳定和轨迹不平滑。相比之下，PathRL通过训练直接输出路径的DRL策略，克服了高维动作空间和多时间步骤跟踪路径的难题。通过这种方法，PathRL能够生成稳定且平滑的导航路径，用于避免碰撞和提高移动机器人性能。"
}