{
    "title": "Leveraging Diffusion Disentangled Representations to Mitigate Shortcuts in Underspecified Visual Tasks. (arXiv:2310.02230v3 [cs.CV] UPDATED)",
    "abstract": "Spurious correlations in the data, where multiple cues are predictive of the target labels, often lead to shortcut learning phenomena, where a model may rely on erroneous, easy-to-learn, cues while ignoring reliable ones. In this work, we propose an ensemble diversification framework exploiting the generation of synthetic counterfactuals using Diffusion Probabilistic Models (DPMs). We discover that DPMs have the inherent capability to represent multiple visual cues independently, even when they are largely correlated in the training data. We leverage this characteristic to encourage model diversity and empirically show the efficacy of the approach with respect to several diversification objectives. We show that diffusion-guided diversification can lead models to avert attention from shortcut cues, achieving ensemble diversity performance comparable to previous methods requiring additional data collection.",
    "link": "http://arxiv.org/abs/2310.02230",
    "context": "Title: Leveraging Diffusion Disentangled Representations to Mitigate Shortcuts in Underspecified Visual Tasks. (arXiv:2310.02230v3 [cs.CV] UPDATED)\nAbstract: Spurious correlations in the data, where multiple cues are predictive of the target labels, often lead to shortcut learning phenomena, where a model may rely on erroneous, easy-to-learn, cues while ignoring reliable ones. In this work, we propose an ensemble diversification framework exploiting the generation of synthetic counterfactuals using Diffusion Probabilistic Models (DPMs). We discover that DPMs have the inherent capability to represent multiple visual cues independently, even when they are largely correlated in the training data. We leverage this characteristic to encourage model diversity and empirically show the efficacy of the approach with respect to several diversification objectives. We show that diffusion-guided diversification can lead models to avert attention from shortcut cues, achieving ensemble diversity performance comparable to previous methods requiring additional data collection.",
    "path": "papers/23/10/2310.02230.json",
    "total_tokens": 850,
    "translated_title": "利用扩散分离表示来缓解不完全规定的视觉任务中的捷径问题",
    "translated_abstract": "数据中的伪相关性，其中多个线索预测目标标签，通常会导致捷径学习现象，即模型可能依赖于错误的、易于学习的线索而忽略可靠线索。在这项工作中，我们提出了一个利用扩散概率模型（DPMs）生成合成反事实的集成多样化框架。我们发现，即使训练数据中这些线索高度相关，DPMs具有独立表示多个视觉线索的固有能力。我们利用这个特性来促进模型的多样性，并在几个多样化目标上实证证明了该方法的有效性。我们展示了扩散引导的多样化可以使模型避开捷径线索的注意，实现了与需要额外数据收集的先前方法可比较的集成多样性性能。",
    "tldr": "本文提出了一种利用扩散分离表示来处理不完全规定的视觉任务中捷径学习问题的方法，通过生成合成反事实来促进模型的多样性，从而使模型能够忽略捷径线索并达到与其他方法相当的性能。",
    "en_tdlr": "This paper proposes a method to address shortcut learning in underspecified visual tasks by leveraging diffusion disentangled representations and generating synthetic counterfactuals, which encourages model diversity and enables the model to ignore shortcut cues, achieving comparable performance to other methods."
}