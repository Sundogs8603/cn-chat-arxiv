{
    "title": "Gotta be SAFE: A New Framework for Molecular Design. (arXiv:2310.10773v1 [cs.LG])",
    "abstract": "Traditional molecular string representations, such as SMILES, often pose challenges for AI-driven molecular design due to their non-sequential depiction of molecular substructures. To address this issue, we introduce Sequential Attachment-based Fragment Embedding (SAFE), a novel line notation for chemical structures. SAFE reimagines SMILES strings as an unordered sequence of interconnected fragment blocks while maintaining full compatibility with existing SMILES parsers. It streamlines complex generative tasks, including scaffold decoration, fragment linking, polymer generation, and scaffold hopping, while facilitating autoregressive generation for fragment-constrained design, thereby eliminating the need for intricate decoding or graph-based models. We demonstrate the effectiveness of SAFE by training an 87-million-parameter GPT2-like model on a dataset containing 1.1 billion SAFE representations. Through extensive experimentation, we show that our SAFE-GPT model exhibits versatile an",
    "link": "http://arxiv.org/abs/2310.10773",
    "context": "Title: Gotta be SAFE: A New Framework for Molecular Design. (arXiv:2310.10773v1 [cs.LG])\nAbstract: Traditional molecular string representations, such as SMILES, often pose challenges for AI-driven molecular design due to their non-sequential depiction of molecular substructures. To address this issue, we introduce Sequential Attachment-based Fragment Embedding (SAFE), a novel line notation for chemical structures. SAFE reimagines SMILES strings as an unordered sequence of interconnected fragment blocks while maintaining full compatibility with existing SMILES parsers. It streamlines complex generative tasks, including scaffold decoration, fragment linking, polymer generation, and scaffold hopping, while facilitating autoregressive generation for fragment-constrained design, thereby eliminating the need for intricate decoding or graph-based models. We demonstrate the effectiveness of SAFE by training an 87-million-parameter GPT2-like model on a dataset containing 1.1 billion SAFE representations. Through extensive experimentation, we show that our SAFE-GPT model exhibits versatile an",
    "path": "papers/23/10/2310.10773.json",
    "total_tokens": 843,
    "translated_title": "《必须安全：一种新的分子设计框架》",
    "translated_abstract": "传统的分子字符串表示，如SMILES，在基于人工智能的分子设计中经常面临问题，因为它们以非连续的方式描述了分子的亚结构。为了解决这个问题，我们引入了基于顺序连接的片段嵌入（SAFE）——一种新颖的化学结构线性符号表示法。SAFE将SMILES字符串重新构想为一个无序的互连片段块序列，同时与现有的SMILES解析器完全兼容。它简化了复杂的生成任务，包括骨架装饰、片段连接、聚合物生成和骨架跳跃，同时促进了受片段约束的设计的自回归生成，从而消除了繁琐的解码或基于图的模型的需求。我们通过在包含11亿个SAFE表示的数据集上训练了一个8700万参数的类GPT2模型，展示了SAFE的有效性。通过广泛的实验，我们展示了我们的SAFE-GPT模型展示了多功能的...",
    "tldr": "SAFE is a novel line notation for chemical structures that reimagines SMILES strings as an unordered sequence of interconnected fragment blocks, streamlining complex generative tasks and facilitating fragment-constrained design without the need for intricate decoding or graph-based models. It has been demonstrated to be effective through extensive experimentation."
}