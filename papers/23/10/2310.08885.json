{
    "title": "InstructTODS: Large Language Models for End-to-End Task-Oriented Dialogue Systems. (arXiv:2310.08885v1 [cs.CL])",
    "abstract": "Large language models (LLMs) have been used for diverse tasks in natural language processing (NLP), yet remain under-explored for task-oriented dialogue systems (TODS), especially for end-to-end TODS. We present InstructTODS, a novel off-the-shelf framework for zero-shot end-to-end task-oriented dialogue systems that can adapt to diverse domains without fine-tuning. By leveraging LLMs, InstructTODS generates a proxy belief state that seamlessly translates user intentions into dynamic queries for efficient interaction with any KB. Our extensive experiments demonstrate that InstructTODS achieves comparable performance to fully fine-tuned TODS in guiding dialogues to successful completion without prior knowledge or task-specific data. Furthermore, a rigorous human evaluation of end-to-end TODS shows that InstructTODS produces dialogue responses that notably outperform both the gold responses and the state-of-the-art TODS in terms of helpfulness, informativeness, and humanness. Moreover, t",
    "link": "http://arxiv.org/abs/2310.08885",
    "context": "Title: InstructTODS: Large Language Models for End-to-End Task-Oriented Dialogue Systems. (arXiv:2310.08885v1 [cs.CL])\nAbstract: Large language models (LLMs) have been used for diverse tasks in natural language processing (NLP), yet remain under-explored for task-oriented dialogue systems (TODS), especially for end-to-end TODS. We present InstructTODS, a novel off-the-shelf framework for zero-shot end-to-end task-oriented dialogue systems that can adapt to diverse domains without fine-tuning. By leveraging LLMs, InstructTODS generates a proxy belief state that seamlessly translates user intentions into dynamic queries for efficient interaction with any KB. Our extensive experiments demonstrate that InstructTODS achieves comparable performance to fully fine-tuned TODS in guiding dialogues to successful completion without prior knowledge or task-specific data. Furthermore, a rigorous human evaluation of end-to-end TODS shows that InstructTODS produces dialogue responses that notably outperform both the gold responses and the state-of-the-art TODS in terms of helpfulness, informativeness, and humanness. Moreover, t",
    "path": "papers/23/10/2310.08885.json",
    "total_tokens": 1045,
    "translated_title": "InstructTODS: 用于端到端任务导向对话系统的大规模语言模型",
    "translated_abstract": "大规模语言模型(LLMs)被广泛应用于自然语言处理(NLP)的各种任务，但在任务导向对话系统(TODS)方面仍存在很大的探索空间，特别是在端到端的TODS中。我们提出了InstructTODS，一个新颖的即插即用框架，用于零-shot端到端任务导向对话系统，在不进行微调的情况下能够适应多个领域。通过利用LLMs，InstructTODS生成一个代理信念状态，将用户意图无缝地转化为动态查询，以与任何知识库进行高效交互。我们的大量实验表明，InstructTODS能够在没有先验知识或任务特定数据的情况下，引导对话成功完成，并取得与完全微调的TODS相当的性能。此外，对端到端TODS的严格人工评估表明，InstructTODS所生成的对话回应在帮助性、信息量和人性化等方面显著优于黄金回应和最先进的TODS。",
    "tldr": "InstructTODS是一个端到端任务导向对话系统的大规模语言模型，通过利用LLMs生成代理信念状态，并在零-shot的情况下适应多个领域。在实验中展示了与完全微调的TODS相媲美的性能，并且经过严格的人工评估，InstructTODS所生成的对话回应在帮助性、信息量和人性化方面明显优于黄金回应和最先进的TODS。"
}