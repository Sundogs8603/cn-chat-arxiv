{
    "title": "Salted Inference: Enhancing Privacy while Maintaining Efficiency of Split Inference in Mobile Computing. (arXiv:2310.13384v1 [cs.LG])",
    "abstract": "Split inference partitions a deep neural network (DNN) to run the early part at the edge and the later part in the cloud. This meets two key requirements for on-device machine learning: input privacy and compute efficiency. Still, an open question in split inference is output privacy, given that the output of a DNN is visible to the cloud. While encrypted computing can protect output privacy, it mandates extensive computation and communication resources. In this paper, we introduce \"Salted DNNs\": a novel method that lets clients control the semantic interpretation of DNN output at inference time while maintaining accuracy and efficiency very close to that of a standard DNN. Experimental evaluations conducted on both image and sensor data show that Salted DNNs achieve classification accuracy very close to standard DNNs, particularly when the salted layer is positioned within the early part to meet the requirements of split inference. Our method is general and can be applied to various D",
    "link": "http://arxiv.org/abs/2310.13384",
    "context": "Title: Salted Inference: Enhancing Privacy while Maintaining Efficiency of Split Inference in Mobile Computing. (arXiv:2310.13384v1 [cs.LG])\nAbstract: Split inference partitions a deep neural network (DNN) to run the early part at the edge and the later part in the cloud. This meets two key requirements for on-device machine learning: input privacy and compute efficiency. Still, an open question in split inference is output privacy, given that the output of a DNN is visible to the cloud. While encrypted computing can protect output privacy, it mandates extensive computation and communication resources. In this paper, we introduce \"Salted DNNs\": a novel method that lets clients control the semantic interpretation of DNN output at inference time while maintaining accuracy and efficiency very close to that of a standard DNN. Experimental evaluations conducted on both image and sensor data show that Salted DNNs achieve classification accuracy very close to standard DNNs, particularly when the salted layer is positioned within the early part to meet the requirements of split inference. Our method is general and can be applied to various D",
    "path": "papers/23/10/2310.13384.json",
    "total_tokens": 934,
    "translated_title": "Salted Inference: 在移动计算中提升隐私并保持分割推理的效率的方法",
    "translated_abstract": "分割推理将深度神经网络（DNN）划分为两部分，边缘部分在设备上运行，后续部分在云端运行。这满足了设备上机器学习的两个关键需求：输入隐私和计算效率。然而，在分割推理中，一个未解决的问题是输出隐私，因为DNN的输出可见于云端。尽管加密计算可以保护输出隐私，但需要大量的计算和通信资源。本文引入了“盐化DNN”：一种新颖的方法，可以让客户在推理时控制DNN输出的语义解释，同时保持准确性和效率与标准DNN几乎一致。在图像和传感器数据上进行的实验评估表明，盐化DNN在分类准确性上与标准DNN非常接近，尤其是当盐化层位于较早阶段以满足分割推理的要求时。我们的方法是通用的，可以应用于各种领域。",
    "tldr": "本文介绍了一种名为“盐化DNN”的方法，通过在推理时让客户控制DNN输出的语义解释，同时保持准确性和效率与标准DNN几乎一致，提升了移动计算中隐私和计算效率的问题。",
    "en_tdlr": "This paper introduces a method called \"Salted DNNs\" that allows clients to control the semantic interpretation of DNN output at inference time while maintaining accuracy and efficiency very close to that of a standard DNN, thereby enhancing privacy and compute efficiency in mobile computing."
}