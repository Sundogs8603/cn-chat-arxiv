{
    "title": "DOMINO: A Dual-System for Multi-step Visual Language Reasoning. (arXiv:2310.02804v1 [cs.CL])",
    "abstract": "Visual language reasoning requires a system to extract text or numbers from information-dense images like charts or plots and perform logical or arithmetic reasoning to arrive at an answer. To tackle this task, existing work relies on either (1) an end-to-end vision-language model trained on a large amount of data, or (2) a two-stage pipeline where a captioning model converts the image into text that is further read by another large language model to deduce the answer. However, the former approach forces the model to answer a complex question with one single step, and the latter approach is prone to inaccurate or distracting information in the converted text that can confuse the language model. In this work, we propose a dual-system for multi-step multimodal reasoning, which consists of a \"System-1\" step for visual information extraction and a \"System-2\" step for deliberate reasoning. Given an input, System-2 breaks down the question into atomic sub-steps, each guiding System-1 to extr",
    "link": "http://arxiv.org/abs/2310.02804",
    "context": "Title: DOMINO: A Dual-System for Multi-step Visual Language Reasoning. (arXiv:2310.02804v1 [cs.CL])\nAbstract: Visual language reasoning requires a system to extract text or numbers from information-dense images like charts or plots and perform logical or arithmetic reasoning to arrive at an answer. To tackle this task, existing work relies on either (1) an end-to-end vision-language model trained on a large amount of data, or (2) a two-stage pipeline where a captioning model converts the image into text that is further read by another large language model to deduce the answer. However, the former approach forces the model to answer a complex question with one single step, and the latter approach is prone to inaccurate or distracting information in the converted text that can confuse the language model. In this work, we propose a dual-system for multi-step multimodal reasoning, which consists of a \"System-1\" step for visual information extraction and a \"System-2\" step for deliberate reasoning. Given an input, System-2 breaks down the question into atomic sub-steps, each guiding System-1 to extr",
    "path": "papers/23/10/2310.02804.json",
    "total_tokens": 957,
    "translated_title": "DOMINO: 多步骤视觉语言推理的双系统",
    "translated_abstract": "视觉语言推理需要一个系统从信息密集的图像（如图表或绘图）中提取文本或数字，并执行逻辑或算术推理以得出答案。为了解决这个任务，现有的工作依靠以下两种方法：（1）训练在大量数据上的端到端视觉语言模型，或者（2）使用两阶段的流程，其中一个字幕模型将图像转换成文本，然后由另一个大型语言模型读取文本以推断出答案。然而，前一种方法强迫模型用单个步骤回答复杂问题，后一种方法容易产生转换文本中的不准确或分散注意力的信息，从而让语言模型混淆。在这项工作中，我们提出了一种用于多步骤多模型推理的双系统，它包含用于视觉信息提取的“System-1”步骤和用于有意推理的“System-2”步骤。给定一个输入，System-2将问题分解为原子子步骤，每个子步骤指导System-1进行信息提取。",
    "tldr": "本文提出了一种用于多步骤多模态推理的双系统，其中一个系统用于提取视觉信息，另一个系统用于有意推理。这种方法可以避免模型在一个步骤回答复杂问题或被转换文本中的误导信息困扰。",
    "en_tdlr": "This paper proposes a dual-system for multi-step multimodal reasoning, where one system is used for visual information extraction and the other system is used for deliberate reasoning. This approach avoids the model being burdened with answering complex questions in one step or being confused by misleading information in the converted text."
}