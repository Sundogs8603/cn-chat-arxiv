{
    "title": "Real-Fake: Effective Training Data Synthesis Through Distribution Matching",
    "abstract": "arXiv:2310.10402v2 Announce Type: replace  Abstract: Synthetic training data has gained prominence in numerous learning tasks and scenarios, offering advantages such as dataset augmentation, generalization evaluation, and privacy preservation. Despite these benefits, the efficiency of synthetic data generated by current methodologies remains inferior when training advanced deep models exclusively, limiting its practical utility. To address this challenge, we analyze the principles underlying training data synthesis for supervised learning and elucidate a principled theoretical framework from the distribution-matching perspective that explicates the mechanisms governing synthesis efficacy. Through extensive experiments, we demonstrate the effectiveness of our synthetic data across diverse image classification tasks, both as a replacement for and augmentation to real datasets, while also benefits such as out-of-distribution generalization, privacy preservation, and scalability. Specifica",
    "link": "https://arxiv.org/abs/2310.10402",
    "context": "Title: Real-Fake: Effective Training Data Synthesis Through Distribution Matching\nAbstract: arXiv:2310.10402v2 Announce Type: replace  Abstract: Synthetic training data has gained prominence in numerous learning tasks and scenarios, offering advantages such as dataset augmentation, generalization evaluation, and privacy preservation. Despite these benefits, the efficiency of synthetic data generated by current methodologies remains inferior when training advanced deep models exclusively, limiting its practical utility. To address this challenge, we analyze the principles underlying training data synthesis for supervised learning and elucidate a principled theoretical framework from the distribution-matching perspective that explicates the mechanisms governing synthesis efficacy. Through extensive experiments, we demonstrate the effectiveness of our synthetic data across diverse image classification tasks, both as a replacement for and augmentation to real datasets, while also benefits such as out-of-distribution generalization, privacy preservation, and scalability. Specifica",
    "path": "papers/23/10/2310.10402.json",
    "total_tokens": 751,
    "translated_title": "Real-Fake：通过分布匹配进行有效的训练数据合成",
    "translated_abstract": "合成训练数据在许多学习任务和场景中占据重要地位，它具有数据集增强、泛化评估和隐私保护等优势。然而，目前方法生成的合成数据在专门训练高级深度模型时效率仍不足，限制了其实际效用。为了解决这一挑战，我们分析了监督学习训练数据合成的原则，并从分布匹配的角度阐明了一个原理性的理论框架，阐明了支配合成有效性的机制。通过大量实验证明了我们的合成数据在各种图像分类任务中的有效性，既可以替代真实数据集，也可以作为其增强，同时具有诸如超出分布泛化、隐私保护和可伸缩性等优点。",
    "tldr": "通过分布匹配的理论框架，实现了有效的训练数据合成，提升了合成数据在图像分类任务中的效果和实用性",
    "en_tdlr": "Effective training data synthesis was achieved through a theoretical framework of distribution matching, enhancing the performance and utility of synthetic data in image classification tasks."
}