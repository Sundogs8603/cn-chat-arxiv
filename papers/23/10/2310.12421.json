{
    "title": "Detecting and Mitigating Algorithmic Bias in Binary Classification using Causal Modeling. (arXiv:2310.12421v1 [cs.LG])",
    "abstract": "This paper proposes the use of causal modeling to detect and mitigate algorithmic bias. We provide a brief description of causal modeling and a general overview of our approach. We then use the Adult dataset, which is available for download from the UC Irvine Machine Learning Repository, to develop (1) a prediction model, which is treated as a black box, and (2) a causal model for bias mitigation. In this paper, we focus on gender bias and the problem of binary classification. We show that gender bias in the prediction model is statistically significant at the 0.05 level. We demonstrate the effectiveness of the causal model in mitigating gender bias by cross-validation. Furthermore, we show that the overall classification accuracy is improved slightly. Our novel approach is intuitive, easy-to-use, and can be implemented using existing statistical software tools such as \"lavaan\" in R. Hence, it enhances explainability and promotes trust.",
    "link": "http://arxiv.org/abs/2310.12421",
    "context": "Title: Detecting and Mitigating Algorithmic Bias in Binary Classification using Causal Modeling. (arXiv:2310.12421v1 [cs.LG])\nAbstract: This paper proposes the use of causal modeling to detect and mitigate algorithmic bias. We provide a brief description of causal modeling and a general overview of our approach. We then use the Adult dataset, which is available for download from the UC Irvine Machine Learning Repository, to develop (1) a prediction model, which is treated as a black box, and (2) a causal model for bias mitigation. In this paper, we focus on gender bias and the problem of binary classification. We show that gender bias in the prediction model is statistically significant at the 0.05 level. We demonstrate the effectiveness of the causal model in mitigating gender bias by cross-validation. Furthermore, we show that the overall classification accuracy is improved slightly. Our novel approach is intuitive, easy-to-use, and can be implemented using existing statistical software tools such as \"lavaan\" in R. Hence, it enhances explainability and promotes trust.",
    "path": "papers/23/10/2310.12421.json",
    "total_tokens": 893,
    "translated_title": "使用因果建模检测和减轻二元分类中的算法偏见",
    "translated_abstract": "本文提出使用因果建模来检测和减轻算法偏见。我们简要介绍了因果建模的概念并概述了我们的方法。我们使用了UC Irvine机器学习库中可下载的成年人数据集，分别开发了（1）一个被视为黑箱的预测模型和（2）一个用于减轻偏见的因果模型。本文重点关注性别偏见和二元分类问题。我们展示了预测模型中性别偏见的统计显著性（p<0.05），并通过交叉验证展示了因果模型在减轻性别偏见方面的有效性。此外，我们还展示了整体分类准确率的轻微提升。我们的创新方法直观易懂，并且可以使用现有统计软件工具（如R中的“lavaan”）实现。因此，它提高了可解释性并促进了信任。",
    "tldr": "本文提出了使用因果建模来检测和减轻算法偏见的新方法，并在性别偏见和二元分类问题上进行了实证研究。通过交叉验证实验证明了因果模型在减轻性别偏见方面的有效性，并轻微提高了整体分类准确率。"
}