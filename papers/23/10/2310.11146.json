{
    "title": "The Quo Vadis of the Relationship between Language and Large Language Models. (arXiv:2310.11146v1 [cs.CL])",
    "abstract": "In the field of Artificial (General) Intelligence (AI), the several recent advancements in Natural language processing (NLP) activities relying on Large Language Models (LLMs) have come to encourage the adoption of LLMs as scientific models of language. While the terminology employed for the characterization of LLMs favors their embracing as such, it is not clear that they are in a place to offer insights into the target system they seek to represent. After identifying the most important theoretical and empirical risks brought about by the adoption of scientific models that lack transparency, we discuss LLMs relating them to every scientific model's fundamental components: the object, the medium, the meaning and the user. We conclude that, at their current stage of development, LLMs hardly offer any explanations for language, and then we provide an outlook for more informative future research directions on this topic.",
    "link": "http://arxiv.org/abs/2310.11146",
    "context": "Title: The Quo Vadis of the Relationship between Language and Large Language Models. (arXiv:2310.11146v1 [cs.CL])\nAbstract: In the field of Artificial (General) Intelligence (AI), the several recent advancements in Natural language processing (NLP) activities relying on Large Language Models (LLMs) have come to encourage the adoption of LLMs as scientific models of language. While the terminology employed for the characterization of LLMs favors their embracing as such, it is not clear that they are in a place to offer insights into the target system they seek to represent. After identifying the most important theoretical and empirical risks brought about by the adoption of scientific models that lack transparency, we discuss LLMs relating them to every scientific model's fundamental components: the object, the medium, the meaning and the user. We conclude that, at their current stage of development, LLMs hardly offer any explanations for language, and then we provide an outlook for more informative future research directions on this topic.",
    "path": "papers/23/10/2310.11146.json",
    "total_tokens": 855,
    "translated_title": "语言与大型语言模型之间的去往何方",
    "translated_abstract": "在人工（通用）智能（AI）领域中，依赖于大型语言模型（LLMs）的自然语言处理（NLP）活动的几个最近的进展鼓励将LLMs作为语言科学模型。虽然用于描述LLMs的术语倾向于将其作为科学模型，但它们是否能够为他们试图表示的目标系统提供洞见尚不清楚。我们在确定缺乏透明度的科学模型带来的最重要的理论和实证风险之后，论述了LLMs，并将其与每个科学模型的基本组成部分（对象、媒介、含义和用户）相关联。我们得出结论，目前发展阶段的LLMs几乎对语言没有提供任何解释，然后对这个主题的未来研究方向提供了一个更具信息价值的展望。",
    "tldr": "大型语言模型（LLMs）在语言科学模型中的地位引发了关于其透明度和信息提供能力的讨论，当前阶段的LLMs几乎对语言没有提供任何解释，未来研究需要探索更具信息价值的方向。"
}