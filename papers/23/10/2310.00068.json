{
    "title": "Emotional Listener Portrait: Realistic Listener Motion Simulation in Conversation. (arXiv:2310.00068v1 [cs.GR])",
    "abstract": "Listener head generation centers on generating non-verbal behaviors (e.g., smile) of a listener in reference to the information delivered by a speaker. A significant challenge when generating such responses is the non-deterministic nature of fine-grained facial expressions during a conversation, which varies depending on the emotions and attitudes of both the speaker and the listener. To tackle this problem, we propose the Emotional Listener Portrait (ELP), which treats each fine-grained facial motion as a composition of several discrete motion-codewords and explicitly models the probability distribution of the motions under different emotion in conversation. Benefiting from the ``explicit'' and ``discrete'' design, our ELP model can not only automatically generate natural and diverse responses toward a given speaker via sampling from the learned distribution but also generate controllable responses with a predetermined attitude. Under several quantitative metrics, our ELP exhibits sig",
    "link": "http://arxiv.org/abs/2310.00068",
    "context": "Title: Emotional Listener Portrait: Realistic Listener Motion Simulation in Conversation. (arXiv:2310.00068v1 [cs.GR])\nAbstract: Listener head generation centers on generating non-verbal behaviors (e.g., smile) of a listener in reference to the information delivered by a speaker. A significant challenge when generating such responses is the non-deterministic nature of fine-grained facial expressions during a conversation, which varies depending on the emotions and attitudes of both the speaker and the listener. To tackle this problem, we propose the Emotional Listener Portrait (ELP), which treats each fine-grained facial motion as a composition of several discrete motion-codewords and explicitly models the probability distribution of the motions under different emotion in conversation. Benefiting from the ``explicit'' and ``discrete'' design, our ELP model can not only automatically generate natural and diverse responses toward a given speaker via sampling from the learned distribution but also generate controllable responses with a predetermined attitude. Under several quantitative metrics, our ELP exhibits sig",
    "path": "papers/23/10/2310.00068.json",
    "total_tokens": 863,
    "translated_title": "情感听众肖像：真实的听众动作模拟对话",
    "translated_abstract": "听者头部生成主要关注在根据讲话者传递的信息生成听者的非语言行为（例如微笑）。生成这样的响应时一个重要的挑战是对话中精细面部表情的非确定性特性，这取决于讲话者和听者的情绪和态度。为了解决这个问题，我们提出了情感听众肖像（ELP），它将每个细粒度面部动作视为若干离散动作编码词的组合，并显式地建模了不同情感下动作的概率分布。由于“显式”和“离散”的设计，我们的ELP模型不仅可以通过从学习的分布中采样自动生成对给定讲话者的自然多样的响应，还可以生成具有预先确定态度的可控响应。在几个定量度量指标下，我们的ELP表现出显著的结果。",
    "tldr": "本论文提出了一种情感听众肖像（ELP）模型，采用了显式离散设计，能根据对话中不同情绪生成自然多样又可控的响应，解决了面部表情生成中的非确定性问题。",
    "en_tdlr": "This paper proposes an Emotional Listener Portrait (ELP) model that uses an explicit and discrete design to generate natural and diverse responses based on different emotions in a conversation, solving the challenge of non-deterministic fine-grained facial expression generation."
}