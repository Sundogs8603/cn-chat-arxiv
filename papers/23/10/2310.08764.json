{
    "title": "Calibrating Likelihoods towards Consistency in Summarization Models. (arXiv:2310.08764v1 [cs.CL])",
    "abstract": "Despite the recent advances in abstractive text summarization, current summarization models still suffer from generating factually inconsistent summaries, reducing their utility for real-world application. We argue that the main reason for such behavior is that the summarization models trained with maximum likelihood objective assign high probability to plausible sequences given the context, but they often do not accurately rank sequences by their consistency. In this work, we solve this problem by calibrating the likelihood of model generated sequences to better align with a consistency metric measured by natural language inference (NLI) models. The human evaluation study and automatic metrics show that the calibrated models generate more consistent and higher-quality summaries. We also show that the models trained using our method return probabilities that are better aligned with the NLI scores, which significantly increase reliability of summarization models.",
    "link": "http://arxiv.org/abs/2310.08764",
    "context": "Title: Calibrating Likelihoods towards Consistency in Summarization Models. (arXiv:2310.08764v1 [cs.CL])\nAbstract: Despite the recent advances in abstractive text summarization, current summarization models still suffer from generating factually inconsistent summaries, reducing their utility for real-world application. We argue that the main reason for such behavior is that the summarization models trained with maximum likelihood objective assign high probability to plausible sequences given the context, but they often do not accurately rank sequences by their consistency. In this work, we solve this problem by calibrating the likelihood of model generated sequences to better align with a consistency metric measured by natural language inference (NLI) models. The human evaluation study and automatic metrics show that the calibrated models generate more consistent and higher-quality summaries. We also show that the models trained using our method return probabilities that are better aligned with the NLI scores, which significantly increase reliability of summarization models.",
    "path": "papers/23/10/2310.08764.json",
    "total_tokens": 887,
    "translated_title": "校准使得摘要模型在一致性方面更为准确",
    "translated_abstract": "尽管抽象化文本摘要取得了一些新的进展，但目前的摘要模型仍然存在生成事实不一致的摘要的问题，这减弱了它们在实际应用中的效用。我们认为造成这种行为的主要原因是由于基于最大似然目标训练的摘要模型在给定上下文时赋予可能序列高概率，但它们往往不能准确地根据其一致性排名序列。在这项工作中，我们通过校准模型生成的序列的似然性，使其更好地与通过自然语言推理（NLI）模型测量的一致性度量相一致来解决这个问题。人类评估研究和自动指标表明，经过校准的模型生成更一致且更高质量的摘要。我们还展示了使用我们方法训练的模型返回的概率与NLI得分更为对齐，这显著提高了摘要模型的可靠性。",
    "tldr": "通过校准模型生成的序列的似然性，使其更好地与通过自然语言推理（NLI）模型测量的一致性度量相一致，从而提高摘要模型的一致性和质量。",
    "en_tdlr": "This study addresses the issue of generating inconsistent summaries in abstractive text summarization models. The authors propose calibrating the likelihood of model generated sequences to align with a consistency metric measured by natural language inference (NLI) models, resulting in more consistent and higher-quality summaries."
}