{
    "title": "A Neuro-Mimetic Realization of the Common Model of Cognition via Hebbian Learning and Free Energy Minimization. (arXiv:2310.15177v1 [q-bio.NC])",
    "abstract": "Over the last few years, large neural generative models, capable of synthesizing intricate sequences of words or producing complex image patterns, have recently emerged as a popular representation of what has come to be known as \"generative artificial intelligence\" (generative AI). Beyond opening the door to new opportunities as well as challenges for the domain of statistical machine learning, the rising popularity of generative AI brings with it interesting questions for Cognitive Science, which seeks to discover the nature of the processes that underpin minds and brains as well as to understand how such functionality might be acquired and instantiated in biological (or artificial) substrate. With this goal in mind, we argue that a promising long-term pathway lies in the crafting of cognitive architectures, a long-standing tradition of the field, cast fundamentally in terms of neuro-mimetic generative building blocks. Concretely, we discuss the COGnitive Neural GENerative system, whi",
    "link": "http://arxiv.org/abs/2310.15177",
    "context": "Title: A Neuro-Mimetic Realization of the Common Model of Cognition via Hebbian Learning and Free Energy Minimization. (arXiv:2310.15177v1 [q-bio.NC])\nAbstract: Over the last few years, large neural generative models, capable of synthesizing intricate sequences of words or producing complex image patterns, have recently emerged as a popular representation of what has come to be known as \"generative artificial intelligence\" (generative AI). Beyond opening the door to new opportunities as well as challenges for the domain of statistical machine learning, the rising popularity of generative AI brings with it interesting questions for Cognitive Science, which seeks to discover the nature of the processes that underpin minds and brains as well as to understand how such functionality might be acquired and instantiated in biological (or artificial) substrate. With this goal in mind, we argue that a promising long-term pathway lies in the crafting of cognitive architectures, a long-standing tradition of the field, cast fundamentally in terms of neuro-mimetic generative building blocks. Concretely, we discuss the COGnitive Neural GENerative system, whi",
    "path": "papers/23/10/2310.15177.json",
    "total_tokens": 912,
    "translated_title": "通过赫比安学习和自由能最小化实现了神经模仿的认知共同模型",
    "translated_abstract": "在过去几年中，大型的神经生成模型日益流行，能够合成复杂的字词序列或产生复杂的图像模式，成为了所谓\"生成人工智能\"的热门代表。除了给统计机器学习领域带来新的机遇和挑战之外，生成人工智能的兴起还给认知科学提出了有趣的问题，该领域旨在揭示构成思维和大脑过程的本质，以及理解这种功能如何在生物（或人工）基质中获取和实现。为了实现这一目标，我们认为有一个有前景的长期途径在于设计认知架构，这是该领域长期以来的传统，基本上是根据神经模仿的生成性构建模块构建的。具体地，我们讨论了COGitive NEural GENerative系统，它以赫比安学习和自由能最小化为基础，实现了神经模仿的认知共同模型。",
    "tldr": "这项研究通过赫比安学习和自由能最小化实现了神经模仿的认知共同模型，该模型能够合成复杂的字词序列或产生复杂的图像模式。",
    "en_tdlr": "This study presents a neuro-mimetic realization of the common model of cognition through Hebbian learning and free energy minimization, allowing the synthesis of intricate sequences of words or complex image patterns."
}