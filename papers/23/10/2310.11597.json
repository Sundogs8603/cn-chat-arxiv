{
    "title": "The Efficacy of Transformer-based Adversarial Attacks in Security Domains. (arXiv:2310.11597v1 [cs.CR])",
    "abstract": "Today, the security of many domains rely on the use of Machine Learning to detect threats, identify vulnerabilities, and safeguard systems from attacks. Recently, transformer architectures have improved the state-of-the-art performance on a wide range of tasks such as malware detection and network intrusion detection. But, before abandoning current approaches to transformers, it is crucial to understand their properties and implications on cybersecurity applications. In this paper, we evaluate the robustness of transformers to adversarial samples for system defenders (i.e., resiliency to adversarial perturbations generated on different types of architectures) and their adversarial strength for system attackers (i.e., transferability of adversarial samples generated by transformers to other target models). To that effect, we first fine-tune a set of pre-trained transformer, Convolutional Neural Network (CNN), and hybrid (an ensemble of transformer and CNN) models to solve different down",
    "link": "http://arxiv.org/abs/2310.11597",
    "context": "Title: The Efficacy of Transformer-based Adversarial Attacks in Security Domains. (arXiv:2310.11597v1 [cs.CR])\nAbstract: Today, the security of many domains rely on the use of Machine Learning to detect threats, identify vulnerabilities, and safeguard systems from attacks. Recently, transformer architectures have improved the state-of-the-art performance on a wide range of tasks such as malware detection and network intrusion detection. But, before abandoning current approaches to transformers, it is crucial to understand their properties and implications on cybersecurity applications. In this paper, we evaluate the robustness of transformers to adversarial samples for system defenders (i.e., resiliency to adversarial perturbations generated on different types of architectures) and their adversarial strength for system attackers (i.e., transferability of adversarial samples generated by transformers to other target models). To that effect, we first fine-tune a set of pre-trained transformer, Convolutional Neural Network (CNN), and hybrid (an ensemble of transformer and CNN) models to solve different down",
    "path": "papers/23/10/2310.11597.json",
    "total_tokens": 835,
    "translated_title": "基于Transformer的对抗攻击在安全领域中的有效性",
    "translated_abstract": "如今，许多领域的安全依赖于使用机器学习来检测威胁、识别漏洞并保护系统免受攻击。最近，Transformer架构在恶意软件检测和网络入侵检测等各种任务中改善了最先进的性能。然而，在放弃当前的Transformer方法之前，了解它们对网络安全应用的属性和影响是至关重要的。在本文中，我们评估了Transformer对于系统防御者（即对于在不同类型的架构上生成的对抗性扰动的韧性）和系统攻击者（即将由Transformer生成的对抗样本的可转移性）的对抗样本的鲁棒性。为此，我们首先微调一套预训练的Transformer、卷积神经网络（CNN）和混合（Transformer和CNN的集成）模型来解决不同的问题。",
    "tldr": "本文评估了Transformer对于系统防御者和系统攻击者的对抗性样本的鲁棒性和可转移性，为了更好地理解Transformer在网络安全应用中的属性和影响。",
    "en_tdlr": "This paper evaluates the robustness and transferability of adversarial samples generated by Transformers for system defenders and attackers, providing insights into the properties and implications of Transformers in cybersecurity applications."
}