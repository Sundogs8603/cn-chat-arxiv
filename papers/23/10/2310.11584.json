{
    "title": "BasahaCorpus: An Expanded Linguistic Resource for Readability Assessment in Central Philippine Languages. (arXiv:2310.11584v1 [cs.CL])",
    "abstract": "Current research on automatic readability assessment (ARA) has focused on improving the performance of models in high-resource languages such as English. In this work, we introduce and release BasahaCorpus as part of an initiative aimed at expanding available corpora and baseline models for readability assessment in lower resource languages in the Philippines. We compiled a corpus of short fictional narratives written in Hiligaynon, Minasbate, Karay-a, and Rinconada -- languages belonging to the Central Philippine family tree subgroup -- to train ARA models using surface-level, syllable-pattern, and n-gram overlap features. We also propose a new hierarchical cross-lingual modeling approach that takes advantage of a language's placement in the family tree to increase the amount of available training data. Our study yields encouraging results that support previous work showcasing the efficacy of cross-lingual models in low-resource settings, as well as similarities in highly informative ",
    "link": "http://arxiv.org/abs/2310.11584",
    "context": "Title: BasahaCorpus: An Expanded Linguistic Resource for Readability Assessment in Central Philippine Languages. (arXiv:2310.11584v1 [cs.CL])\nAbstract: Current research on automatic readability assessment (ARA) has focused on improving the performance of models in high-resource languages such as English. In this work, we introduce and release BasahaCorpus as part of an initiative aimed at expanding available corpora and baseline models for readability assessment in lower resource languages in the Philippines. We compiled a corpus of short fictional narratives written in Hiligaynon, Minasbate, Karay-a, and Rinconada -- languages belonging to the Central Philippine family tree subgroup -- to train ARA models using surface-level, syllable-pattern, and n-gram overlap features. We also propose a new hierarchical cross-lingual modeling approach that takes advantage of a language's placement in the family tree to increase the amount of available training data. Our study yields encouraging results that support previous work showcasing the efficacy of cross-lingual models in low-resource settings, as well as similarities in highly informative ",
    "path": "papers/23/10/2310.11584.json",
    "total_tokens": 983,
    "translated_title": "BasahaCorpus: 菲律宾中央语系语言可读性评估的扩展语言资源",
    "translated_abstract": "目前自动可读性评估（ARA）的研究主要集中在提高英语等资源较丰富的语言模型的性能上。在这项工作中，我们引入并发布了BasahaCorpus作为一个旨在拓展菲律宾低资源语言可读性评估的可用语料库和基准模型的倡议的一部分。我们编译了一个由Hiligaynon，Minasbate，Karay-a和Rinconada四种语言编写的短篇小说故事的语料库，这些语言属于菲律宾中央语系家族树的子分支，我们使用表层特征、音节模式和n-gram重叠特征训练ARA模型。我们还提出了一种新的层次化跨语言建模方法，利用语言在家族树中的位置以增加可用的训练数据量。我们的研究取得了令人鼓舞的结果，支持先前工作展示了跨语言模型在低资源环境中的有效性，以及高度信息化的相似性。",
    "tldr": "BasahaCorpus 是一个扩展菲律宾中央语系语言可读性评估的语料库，利用表层特征、音节模式和n-gram重叠特征训练了ARA模型，并提出了一种新的层次化跨语言建模方法；研究发现跨语言模型在低资源环境中是有效的。",
    "en_tdlr": "BasahaCorpus is an expanded corpus for readability assessment in Central Philippine languages, which includes the use of surface-level features, syllable-pattern features, and n-gram overlap features to train ARA models. The study also proposes a new hierarchical cross-lingual modeling approach and finds that cross-lingual models are effective in low-resource settings."
}