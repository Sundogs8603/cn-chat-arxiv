{
    "title": "fairret: a Framework for Differentiable Fairness Regularization Terms. (arXiv:2310.17256v1 [cs.LG])",
    "abstract": "Current tools for machine learning fairness only admit a limited range of fairness definitions and have seen little integration with automatic differentiation libraries, despite the central role these libraries play in modern machine learning pipelines.  We introduce a framework of fairness regularization terms (fairrets) which quantify bias as modular objectives that are easily integrated in automatic differentiation pipelines. By employing a general definition of fairness in terms of linear-fractional statistics, a wide class of fairrets can be computed efficiently. Experiments show the behavior of their gradients and their utility in enforcing fairness with minimal loss of predictive power compared to baselines. Our contribution includes a PyTorch implementation of the fairret framework.",
    "link": "http://arxiv.org/abs/2310.17256",
    "context": "Title: fairret: a Framework for Differentiable Fairness Regularization Terms. (arXiv:2310.17256v1 [cs.LG])\nAbstract: Current tools for machine learning fairness only admit a limited range of fairness definitions and have seen little integration with automatic differentiation libraries, despite the central role these libraries play in modern machine learning pipelines.  We introduce a framework of fairness regularization terms (fairrets) which quantify bias as modular objectives that are easily integrated in automatic differentiation pipelines. By employing a general definition of fairness in terms of linear-fractional statistics, a wide class of fairrets can be computed efficiently. Experiments show the behavior of their gradients and their utility in enforcing fairness with minimal loss of predictive power compared to baselines. Our contribution includes a PyTorch implementation of the fairret framework.",
    "path": "papers/23/10/2310.17256.json",
    "total_tokens": 850,
    "translated_title": "fairret：一种可微公平性正则化项的框架",
    "translated_abstract": "目前的机器学习公平性工具仅接受有限范围的公平性定义，并且与自动微分库的整合较少，尽管这些库在现代机器学习流程中起着核心作用。我们引入了一种公平性正则化项（fairret）的框架，以模块化目标的形式量化偏见，并且可以轻松地集成到自动微分流程中。通过采用线性分式统计的广义公平性定义，可以高效地计算出一类广泛的fairret。实验显示了它们的梯度行为以及与基准相比将公平性强制执行的实用性而最小化预测能力损失。我们的贡献包括fairret框架的PyTorch实现。",
    "tldr": "本论文介绍了一种称为fairret的可微公平性正则化项框架，通过模块化的目标量化偏见，并可以轻松集成到自动微分流程中。通过从线性分式统计角度定义公平性，可以高效计算多种类型的公平性正则化项。实验证明，fairret框架与基准相比在强制执行公平性时几乎不损失预测能力。"
}