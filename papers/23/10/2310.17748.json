{
    "title": "Making the End-User a Priority in Benchmarking: OrionBench for Unsupervised Time Series Anomaly Detection. (arXiv:2310.17748v1 [cs.LG])",
    "abstract": "Time series anomaly detection is a prevalent problem in many application domains such as patient monitoring in healthcare, forecasting in finance, or predictive maintenance in energy. This has led to the emergence of a plethora of anomaly detection methods, including more recently, deep learning based methods. Although several benchmarks have been proposed to compare newly developed models, they usually rely on one-time execution over a limited set of datasets and the comparison is restricted to a few models. We propose OrionBench -- a user centric continuously maintained benchmark for unsupervised time series anomaly detection. The framework provides universal abstractions to represent models, extensibility to add new pipelines and datasets, hyperparameter standardization, pipeline verification, and frequent releases with published benchmarks. We demonstrate the usage of OrionBench, and the progression of pipelines across 15 releases published over the course of three years. Moreover,",
    "link": "http://arxiv.org/abs/2310.17748",
    "context": "Title: Making the End-User a Priority in Benchmarking: OrionBench for Unsupervised Time Series Anomaly Detection. (arXiv:2310.17748v1 [cs.LG])\nAbstract: Time series anomaly detection is a prevalent problem in many application domains such as patient monitoring in healthcare, forecasting in finance, or predictive maintenance in energy. This has led to the emergence of a plethora of anomaly detection methods, including more recently, deep learning based methods. Although several benchmarks have been proposed to compare newly developed models, they usually rely on one-time execution over a limited set of datasets and the comparison is restricted to a few models. We propose OrionBench -- a user centric continuously maintained benchmark for unsupervised time series anomaly detection. The framework provides universal abstractions to represent models, extensibility to add new pipelines and datasets, hyperparameter standardization, pipeline verification, and frequent releases with published benchmarks. We demonstrate the usage of OrionBench, and the progression of pipelines across 15 releases published over the course of three years. Moreover,",
    "path": "papers/23/10/2310.17748.json",
    "total_tokens": 863,
    "translated_title": "让最终用户成为基准测试的重点：OrionBench用于无监督时间序列异常检测",
    "translated_abstract": "时间序列异常检测是许多应用领域中的常见问题，例如医疗保健中的患者监测、金融中的预测或能源中的预测性维护。这导致了许多异常检测方法的出现，包括最近的基于深度学习的方法。虽然已经提出了几种用于比较新开发模型的基准测试，但它们通常依赖于对有限数据集的一次性执行，并且比较仅限于少数模型。我们提出了OrionBench——一个以用户为中心、持续维护的无监督时间序列异常检测基准测试。该框架提供了用于表示模型的通用抽象、添加新的流水线和数据集的可扩展性、超参数标准化、流水线验证以及发布基准测试的频繁版本。我们展示了OrionBench的用法，并展示了在三年时间内发布的15个版本中流水线的演化过程。",
    "tldr": "OrionBench是一个以用户为中心的无监督时间序列异常检测基准测试，提供了通用抽象、可扩展性和发布频繁的基准测试。",
    "en_tdlr": "OrionBench is a user-centric benchmark for unsupervised time series anomaly detection, providing universal abstractions, extensibility, and frequent releases of benchmarks."
}