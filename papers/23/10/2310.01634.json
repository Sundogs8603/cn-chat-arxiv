{
    "title": "Deep Insights into Noisy Pseudo Labeling on Graph Data. (arXiv:2310.01634v1 [cs.LG])",
    "abstract": "Pseudo labeling (PL) is a wide-applied strategy to enlarge the labeled dataset by self-annotating the potential samples during the training process. Several works have shown that it can improve the graph learning model performance in general. However, we notice that the incorrect labels can be fatal to the graph training process. Inappropriate PL may result in the performance degrading, especially on graph data where the noise can propagate. Surprisingly, the corresponding error is seldom theoretically analyzed in the literature. In this paper, we aim to give deep insights of PL on graph learning models. We first present the error analysis of PL strategy by showing that the error is bounded by the confidence of PL threshold and consistency of multi-view prediction. Then, we theoretically illustrate the effect of PL on convergence property. Based on the analysis, we propose a cautious pseudo labeling methodology in which we pseudo label the samples with highest confidence and multi-view",
    "link": "http://arxiv.org/abs/2310.01634",
    "context": "Title: Deep Insights into Noisy Pseudo Labeling on Graph Data. (arXiv:2310.01634v1 [cs.LG])\nAbstract: Pseudo labeling (PL) is a wide-applied strategy to enlarge the labeled dataset by self-annotating the potential samples during the training process. Several works have shown that it can improve the graph learning model performance in general. However, we notice that the incorrect labels can be fatal to the graph training process. Inappropriate PL may result in the performance degrading, especially on graph data where the noise can propagate. Surprisingly, the corresponding error is seldom theoretically analyzed in the literature. In this paper, we aim to give deep insights of PL on graph learning models. We first present the error analysis of PL strategy by showing that the error is bounded by the confidence of PL threshold and consistency of multi-view prediction. Then, we theoretically illustrate the effect of PL on convergence property. Based on the analysis, we propose a cautious pseudo labeling methodology in which we pseudo label the samples with highest confidence and multi-view",
    "path": "papers/23/10/2310.01634.json",
    "total_tokens": 894,
    "translated_title": "图数据上嘈杂伪标签的深入洞察",
    "translated_abstract": "伪标签（PL）是一种广泛应用的策略，通过在训练过程中对潜在样本进行自注释，扩大已标记数据集。一些研究表明，它可以改善图学习模型的性能。然而，我们注意到错误标签对图训练过程可能具有致命影响。不适当的PL可能导致性能下降，特别是在图数据上，噪音可以传播。令人惊讶的是，相关错误在文献中很少被理论分析。在本文中，我们旨在深入洞察PL对图学习模型的影响。我们首先通过展示错误被PL阈值的置信度和多视图预测的一致性所限制来分析PL策略的错误。然后，我们从理论上说明了PL对收敛性质的影响。基于这些分析，我们提出了一种谨慎的伪标签方法，在这种方法中，我们使用最高置信度和多视图进行伪标签。",
    "tldr": "该论文深入研究了图数据上嘈杂伪标签的影响，通过理论分析展示了伪标签对图学习模型性能的边界和收敛性的影响，并提出了一种谨慎的伪标签方法。",
    "en_tdlr": "This paper provides deep insights into the effects of noisy pseudo labeling on graph data, analyzing the boundaries of its impact on the performance and convergence property of graph learning models, and proposing a cautious pseudo labeling methodology."
}