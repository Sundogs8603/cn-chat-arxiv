{
    "title": "Revolutionizing Mobile Interaction: Enabling a 3 Billion Parameter GPT LLM on Mobile. (arXiv:2310.01434v1 [cs.CL])",
    "abstract": "The field of Artificial Intelligence has witnessed remarkable progress in recent years, especially with the emergence of powerful large language models (LLMs) based on the transformer architecture. Cloud-based LLMs, such as OpenAI's ChatGPT, offer impressive capabilities but come with concerns regarding latency and privacy due to network dependencies. This article presents an innovative approach to LLM inference, envisioning a future where LLMs with billions of parameters can be executed directly on mobile devices without network connectivity. The article showcases a fine-tuned GPT LLM with 3 billion parameters that can operate smoothly on devices with as low as 4GB of memory. Through the integration of native code and model quantization techniques, the application not only serves as a general-purpose assistant but also facilitates seamless mobile interactions with text-to-actions features. The article provides insights into the training pipeline, implementation details, test results, ",
    "link": "http://arxiv.org/abs/2310.01434",
    "context": "Title: Revolutionizing Mobile Interaction: Enabling a 3 Billion Parameter GPT LLM on Mobile. (arXiv:2310.01434v1 [cs.CL])\nAbstract: The field of Artificial Intelligence has witnessed remarkable progress in recent years, especially with the emergence of powerful large language models (LLMs) based on the transformer architecture. Cloud-based LLMs, such as OpenAI's ChatGPT, offer impressive capabilities but come with concerns regarding latency and privacy due to network dependencies. This article presents an innovative approach to LLM inference, envisioning a future where LLMs with billions of parameters can be executed directly on mobile devices without network connectivity. The article showcases a fine-tuned GPT LLM with 3 billion parameters that can operate smoothly on devices with as low as 4GB of memory. Through the integration of native code and model quantization techniques, the application not only serves as a general-purpose assistant but also facilitates seamless mobile interactions with text-to-actions features. The article provides insights into the training pipeline, implementation details, test results, ",
    "path": "papers/23/10/2310.01434.json",
    "total_tokens": 925,
    "translated_title": "革新移动互动：在移动设备上实现30亿参数的GPT LLM",
    "translated_abstract": "近年来，人工智能领域取得了显著进展，特别是基于变压器架构的强大大型语言模型（LLM）的出现。云端的LLM，例如OpenAI的ChatGPT，具有令人印象深刻的功能，但由于网络依赖性，延迟和隐私问题令人担忧。本文提出了一种创新的LLM推断方法，展望了未来在没有网络连接的情况下，拥有数十亿参数的LLM可以直接在移动设备上执行。本文展示了一种具有30亿参数的精调GPT LLM，可以在内存只有4GB的设备上平稳运行。通过整合本地代码和模型量化技术，该应用不仅可以作为通用助手，还可以通过文本到操作的功能实现无缝的移动互动。本文提供了有关训练流程、实现细节和测试结果的见解。",
    "tldr": "本文介绍了一种在移动设备上执行30亿参数的GPT LLM的创新方法，通过集成本地代码和模型量化技术实现了在低内存设备上的平稳运行，并解决了网络依赖性的问题。这种应用不仅具有通用助手功能，还可以实现文本到操作的无缝移动互动。"
}