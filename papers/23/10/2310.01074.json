{
    "title": "Back to the Future: Towards Explainable Temporal Reasoning with Large Language Models. (arXiv:2310.01074v2 [cs.CL] UPDATED)",
    "abstract": "Temporal reasoning is a crucial NLP task, providing a nuanced understanding of time-sensitive contexts within textual data. Although recent advancements in LLMs have demonstrated their potential in temporal reasoning, the predominant focus has been on tasks such as temporal expression and temporal relation extraction. These tasks are primarily designed for the extraction of direct and past temporal cues and to engage in simple reasoning processes. A significant gap remains when considering complex reasoning tasks such as event forecasting, which requires multi-step temporal reasoning on events and prediction on the future timestamp. Another notable limitation of existing methods is their incapability to provide an illustration of their reasoning process, hindering explainability. In this paper, we introduce the first task of explainable temporal reasoning, to predict an event's occurrence at a future timestamp based on context which requires multiple reasoning over multiple events, and",
    "link": "http://arxiv.org/abs/2310.01074",
    "context": "Title: Back to the Future: Towards Explainable Temporal Reasoning with Large Language Models. (arXiv:2310.01074v2 [cs.CL] UPDATED)\nAbstract: Temporal reasoning is a crucial NLP task, providing a nuanced understanding of time-sensitive contexts within textual data. Although recent advancements in LLMs have demonstrated their potential in temporal reasoning, the predominant focus has been on tasks such as temporal expression and temporal relation extraction. These tasks are primarily designed for the extraction of direct and past temporal cues and to engage in simple reasoning processes. A significant gap remains when considering complex reasoning tasks such as event forecasting, which requires multi-step temporal reasoning on events and prediction on the future timestamp. Another notable limitation of existing methods is their incapability to provide an illustration of their reasoning process, hindering explainability. In this paper, we introduce the first task of explainable temporal reasoning, to predict an event's occurrence at a future timestamp based on context which requires multiple reasoning over multiple events, and",
    "path": "papers/23/10/2310.01074.json",
    "total_tokens": 811,
    "translated_title": "重返未来：面向大型语言模型的可解释的时间推理",
    "translated_abstract": "时间推理是一项关键的自然语言处理任务，可以在文本数据中提供对时间敏感环境的细致理解。虽然最近的LLM进展展示了它们在时间推理方面的潜力，但主要关注的是诸如时间表达和时间关系抽取等任务。这些任务主要设计用于提取直接和过去的时间线索，并进行简单的推理过程。然而，在考虑复杂推理任务（如事件预测）时仍存在重大差距，这需要对事件进行多步的时间推理，并对未来时间戳进行预测。现有方法的另一个显著局限是它们无法提供推理过程的说明，从而阻碍了可解释性。在本文中，我们引入了可解释的时间推理的第一个任务，用于基于上下文预测未来时间戳上事件的发生，这需要对多个事件进行多步推理。",
    "tldr": "本文提出了一个新的任务——可解释的时间推理，旨在预测未来时间戳上事件的发生，需要进行多步推理和多个事件的综合。"
}