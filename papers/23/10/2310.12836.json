{
    "title": "Knowledge-Augmented Language Model Verification. (arXiv:2310.12836v1 [cs.CL])",
    "abstract": "Recent Language Models (LMs) have shown impressive capabilities in generating texts with the knowledge internalized in parameters. Yet, LMs often generate the factually incorrect responses to the given queries, since their knowledge may be inaccurate, incomplete, and outdated. To address this problem, previous works propose to augment LMs with the knowledge retrieved from an external knowledge source. However, such approaches often show suboptimal text generation performance due to two reasons: 1) the model may fail to retrieve the knowledge relevant to the given query, or 2) the model may not faithfully reflect the retrieved knowledge in the generated text. To overcome these, we propose to verify the output and the knowledge of the knowledge-augmented LMs with a separate verifier, which is a small LM that is trained to detect those two types of errors through instruction-finetuning. Then, when the verifier recognizes an error, we can rectify it by either retrieving new knowledge or ge",
    "link": "http://arxiv.org/abs/2310.12836",
    "context": "Title: Knowledge-Augmented Language Model Verification. (arXiv:2310.12836v1 [cs.CL])\nAbstract: Recent Language Models (LMs) have shown impressive capabilities in generating texts with the knowledge internalized in parameters. Yet, LMs often generate the factually incorrect responses to the given queries, since their knowledge may be inaccurate, incomplete, and outdated. To address this problem, previous works propose to augment LMs with the knowledge retrieved from an external knowledge source. However, such approaches often show suboptimal text generation performance due to two reasons: 1) the model may fail to retrieve the knowledge relevant to the given query, or 2) the model may not faithfully reflect the retrieved knowledge in the generated text. To overcome these, we propose to verify the output and the knowledge of the knowledge-augmented LMs with a separate verifier, which is a small LM that is trained to detect those two types of errors through instruction-finetuning. Then, when the verifier recognizes an error, we can rectify it by either retrieving new knowledge or ge",
    "path": "papers/23/10/2310.12836.json",
    "total_tokens": 893,
    "translated_title": "知识增强的语言模型验证",
    "translated_abstract": "最近的语言模型在生成文本方面展现出了令人瞩目的能力，因为它们具备了参数中内部化的知识。然而，由于它们的知识可能是不准确、不完整和过时的，因此语言模型往往会对给定查询生成出事实上不正确的回应。为了解决这个问题，之前的研究提出了利用从外部知识源检索到的知识来增强语言模型的方法。然而，这样的方法经常因为两个原因而显示出次优的文本生成性能：1）模型可能无法检索到与给定查询相关的知识；2）模型可能无法在生成文本中忠实地反映检索到的知识。为了克服这些问题，我们提出了利用一个单独的验证器来验证知识增强的语言模型的输出和知识，这个验证器是一个小型语言模型，通过指导微调的方式训练来检测这两种类型的错误。然后，当验证器检测到错误时，我们可以通过检索新的知识或获取更改摘要来进行修复。",
    "tldr": "提出了一种知识增强的语言模型验证方法，通过一个独立的验证器来检测模型输出和知识的错误，并通过检索新知识或修正摘要来纠正错误。"
}