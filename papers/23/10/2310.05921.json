{
    "title": "Conformal Decision Theory: Safe Autonomous Decisions from Imperfect Predictions. (arXiv:2310.05921v1 [stat.ML])",
    "abstract": "We introduce Conformal Decision Theory, a framework for producing safe autonomous decisions despite imperfect machine learning predictions. Examples of such decisions are ubiquitous, from robot planning algorithms that rely on pedestrian predictions, to calibrating autonomous manufacturing to exhibit high throughput and low error, to the choice of trusting a nominal policy versus switching to a safe backup policy at run-time. The decisions produced by our algorithms are safe in the sense that they come with provable statistical guarantees of having low risk without any assumptions on the world model whatsoever; the observations need not be I.I.D. and can even be adversarial. The theory extends results from conformal prediction to calibrate decisions directly, without requiring the construction of prediction sets. Experiments demonstrate the utility of our approach in robot motion planning around humans, automated stock trading, and robot manufacturin",
    "link": "http://arxiv.org/abs/2310.05921",
    "context": "Title: Conformal Decision Theory: Safe Autonomous Decisions from Imperfect Predictions. (arXiv:2310.05921v1 [stat.ML])\nAbstract: We introduce Conformal Decision Theory, a framework for producing safe autonomous decisions despite imperfect machine learning predictions. Examples of such decisions are ubiquitous, from robot planning algorithms that rely on pedestrian predictions, to calibrating autonomous manufacturing to exhibit high throughput and low error, to the choice of trusting a nominal policy versus switching to a safe backup policy at run-time. The decisions produced by our algorithms are safe in the sense that they come with provable statistical guarantees of having low risk without any assumptions on the world model whatsoever; the observations need not be I.I.D. and can even be adversarial. The theory extends results from conformal prediction to calibrate decisions directly, without requiring the construction of prediction sets. Experiments demonstrate the utility of our approach in robot motion planning around humans, automated stock trading, and robot manufacturin",
    "path": "papers/23/10/2310.05921.json",
    "total_tokens": 902,
    "translated_title": "符合决策理论: 通过不完美的预测产生安全的自主决策",
    "translated_abstract": "我们介绍了一种符合决策理论的框架，可以在机器学习预测不完美的情况下产生安全的自主决策。这种决策的例子是普遍存在的，从依赖于行人预测的机器人规划算法，到校准自动化制造以实现高吞吐量和低错误率，再到在运行时选择信任名义策略还是切换到安全备份策略。我们算法产生的决策在统计保证的情况下是安全的，无需对世界模型作出任何假设；观测数据可以不满足独立同分布(I.I.D.)的条件，甚至可能是对抗性的。该理论将符合预测的结果扩展到直接校准决策，而不需要构建预测集合。实验证明了我们方法在围绕人类进行机器人运动规划、自动股票交易和机器人制造方面的实用性。",
    "tldr": "符合决策理论是一种框架，可以通过不完美的机器学习预测产生安全的自主决策。该理论的创新之处在于可以在没有对世界模型做出任何假设的情况下提供具有低风险的统计保证的决策。",
    "en_tdlr": "Conformal Decision Theory is a framework for generating safe autonomous decisions from imperfect machine learning predictions. The innovation of this theory lies in providing statistically guaranteed decisions with low risk without making any assumptions on the world model."
}