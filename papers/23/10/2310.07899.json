{
    "title": "RoboCLIP: One Demonstration is Enough to Learn Robot Policies. (arXiv:2310.07899v1 [cs.AI])",
    "abstract": "Reward specification is a notoriously difficult problem in reinforcement learning, requiring extensive expert supervision to design robust reward functions. Imitation learning (IL) methods attempt to circumvent these problems by utilizing expert demonstrations but typically require a large number of in-domain expert demonstrations. Inspired by advances in the field of Video-and-Language Models (VLMs), we present RoboCLIP, an online imitation learning method that uses a single demonstration (overcoming the large data requirement) in the form of a video demonstration or a textual description of the task to generate rewards without manual reward function design. Additionally, RoboCLIP can also utilize out-of-domain demonstrations, like videos of humans solving the task for reward generation, circumventing the need to have the same demonstration and deployment domains. RoboCLIP utilizes pretrained VLMs without any finetuning for reward generation. Reinforcement learning agents trained with",
    "link": "http://arxiv.org/abs/2310.07899",
    "context": "Title: RoboCLIP: One Demonstration is Enough to Learn Robot Policies. (arXiv:2310.07899v1 [cs.AI])\nAbstract: Reward specification is a notoriously difficult problem in reinforcement learning, requiring extensive expert supervision to design robust reward functions. Imitation learning (IL) methods attempt to circumvent these problems by utilizing expert demonstrations but typically require a large number of in-domain expert demonstrations. Inspired by advances in the field of Video-and-Language Models (VLMs), we present RoboCLIP, an online imitation learning method that uses a single demonstration (overcoming the large data requirement) in the form of a video demonstration or a textual description of the task to generate rewards without manual reward function design. Additionally, RoboCLIP can also utilize out-of-domain demonstrations, like videos of humans solving the task for reward generation, circumventing the need to have the same demonstration and deployment domains. RoboCLIP utilizes pretrained VLMs without any finetuning for reward generation. Reinforcement learning agents trained with",
    "path": "papers/23/10/2310.07899.json",
    "total_tokens": 883,
    "translated_title": "RoboCLIP：只需要一次演示即可学习机器人策略",
    "translated_abstract": "奖励规范是强化学习中一个非常困难的问题，需要大量的专家监督来设计稳健的奖励函数。模仿学习（IL）方法试图通过利用专家演示来规避这些问题，但通常需要大量领域内的专家演示。受到视频语言模型（VLMs）领域的进展的启发，我们提出了RoboCLIP，一种在线模仿学习方法，使用单个演示（克服了大数据要求）来生成奖励，演示可以是视频演示或任务的文本描述，而无需手动设计奖励函数。此外，RoboCLIP还可以利用领域外的演示，例如人类解决任务的视频，以生成奖励，从而避免了需要相同演示和部署领域的要求。RoboCLIP利用预训练的VLMs进行奖励生成，无需任何微调。通过RoboCLIP训练的强化学习代理",
    "tldr": "RoboCLIP是一种在线模仿学习方法，通过单个视频演示或文本描述生成奖励函数，不需要专家监督或设计奖励函数。同时，它还可以利用领域外的演示进行训练。",
    "en_tdlr": "RoboCLIP is an online imitation learning method that uses a single video demonstration or textual description to generate reward functions without the need for expert supervision or manual reward function design. It can also utilize out-of-domain demonstrations for training purposes."
}