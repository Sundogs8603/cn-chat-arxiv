{
    "title": "Fast Adversarial Label-Flipping Attack on Tabular Data. (arXiv:2310.10744v1 [cs.LG])",
    "abstract": "Machine learning models are increasingly used in fields that require high reliability such as cybersecurity. However, these models remain vulnerable to various attacks, among which the adversarial label-flipping attack poses significant threats. In label-flipping attacks, the adversary maliciously flips a portion of training labels to compromise the machine learning model. This paper raises significant concerns as these attacks can camouflage a highly skewed dataset as an easily solvable classification problem, often misleading machine learning practitioners into lower defenses and miscalculations of potential risks. This concern amplifies in tabular data settings, where identifying true labels requires expertise, allowing malicious label-flipping attacks to easily slip under the radar. To demonstrate this risk is inherited in the adversary's objective, we propose FALFA (Fast Adversarial Label-Flipping Attack), a novel efficient attack for crafting adversarial labels. FALFA is based on",
    "link": "http://arxiv.org/abs/2310.10744",
    "context": "Title: Fast Adversarial Label-Flipping Attack on Tabular Data. (arXiv:2310.10744v1 [cs.LG])\nAbstract: Machine learning models are increasingly used in fields that require high reliability such as cybersecurity. However, these models remain vulnerable to various attacks, among which the adversarial label-flipping attack poses significant threats. In label-flipping attacks, the adversary maliciously flips a portion of training labels to compromise the machine learning model. This paper raises significant concerns as these attacks can camouflage a highly skewed dataset as an easily solvable classification problem, often misleading machine learning practitioners into lower defenses and miscalculations of potential risks. This concern amplifies in tabular data settings, where identifying true labels requires expertise, allowing malicious label-flipping attacks to easily slip under the radar. To demonstrate this risk is inherited in the adversary's objective, we propose FALFA (Fast Adversarial Label-Flipping Attack), a novel efficient attack for crafting adversarial labels. FALFA is based on",
    "path": "papers/23/10/2310.10744.json",
    "total_tokens": 950,
    "translated_title": "对表格数据的快速对抗性标签翻转攻击",
    "translated_abstract": "机器学习模型越来越多地应用于需要高可靠性的领域，如网络安全。然而，这些模型仍然容易受到各种攻击，其中对抗性标签翻转攻击构成了重大威胁。在标签翻转攻击中，攻击者恶意地翻转一部分训练标签以破坏机器学习模型。本文提出了对这些攻击的重大担忧，因为这些攻击可以将高度偏斜的数据集伪装成易于解决的分类问题，往往会误导机器学习从业者降低防御措施并错误估计潜在风险。在表格数据设置中，这种担忧更加严重，因为识别真实标签需要专业知识，使得恶意标签翻转攻击很容易逃脱检测。为了证明这种风险体现在对手的目标中，我们提出了FALFA（快速对抗性标签翻转攻击），一种新颖高效的对抗性标签生成攻击方法。FALFA基于...",
    "tldr": "本文提出了基于表格数据的快速对抗性标签翻转攻击，并强调了这种攻击对机器学习模型的潜在风险和误导。为了证明这种风险，提出了一种新颖高效的攻击方法FALFA。"
}