{
    "title": "Transparency challenges in policy evaluation with causal machine learning -- improving usability and accountability. (arXiv:2310.13240v1 [cs.LG])",
    "abstract": "Causal machine learning tools are beginning to see use in real-world policy evaluation tasks to flexibly estimate treatment effects. One issue with these methods is that the machine learning models used are generally black boxes, i.e., there is no globally interpretable way to understand how a model makes estimates. This is a clear problem in policy evaluation applications, particularly in government, because it is difficult to understand whether such models are functioning in ways that are fair, based on the correct interpretation of evidence and transparent enough to allow for accountability if things go wrong. However, there has been little discussion of transparency problems in the causal machine learning literature and how these might be overcome. This paper explores why transparency issues are a problem for causal machine learning in public policy evaluation applications and considers ways these problems might be addressed through explainable AI tools and by simplifying models in",
    "link": "http://arxiv.org/abs/2310.13240",
    "context": "Title: Transparency challenges in policy evaluation with causal machine learning -- improving usability and accountability. (arXiv:2310.13240v1 [cs.LG])\nAbstract: Causal machine learning tools are beginning to see use in real-world policy evaluation tasks to flexibly estimate treatment effects. One issue with these methods is that the machine learning models used are generally black boxes, i.e., there is no globally interpretable way to understand how a model makes estimates. This is a clear problem in policy evaluation applications, particularly in government, because it is difficult to understand whether such models are functioning in ways that are fair, based on the correct interpretation of evidence and transparent enough to allow for accountability if things go wrong. However, there has been little discussion of transparency problems in the causal machine learning literature and how these might be overcome. This paper explores why transparency issues are a problem for causal machine learning in public policy evaluation applications and considers ways these problems might be addressed through explainable AI tools and by simplifying models in",
    "path": "papers/23/10/2310.13240.json",
    "total_tokens": 851,
    "translated_title": "透明度挑战与因果机器学习中的政策评估 - 提高可用性和问责性",
    "translated_abstract": "因果机器学习工具开始在实际政策评估任务中使用，灵活估计治疗效果。这些方法的一个问题是所使用的机器学习模型通常是黑盒子，即没有全局可解释的方式来理解模型如何进行估计。这在政策评估应用中是一个明显的问题，特别是在政府领域，因为很难理解这些模型是否按照公正的方式运行，基于正确的证据解释，并且透明到足以允许在出现问题时进行问责。然而，在因果机器学习文献中很少讨论透明度问题以及如何解决这些问题。本文探讨了为什么透明度问题是因果机器学习在公共政策评估应用中的问题，并考虑通过可解释的AI工具和简化模型来解决这些问题的方法。",
    "tldr": "透明度问题是因果机器学习在政策评估中的挑战，因为黑盒子模型难以理解和问责。本文提出了通过可解释的AI工具和简化模型来解决这些问题的方法。",
    "en_tdlr": "Transparency issues pose challenges in causal machine learning for policy evaluation, as black box models are difficult to understand and hold accountable. This paper suggests addressing these issues through explainable AI tools and simplifying models."
}