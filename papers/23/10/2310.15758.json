{
    "title": "Learning From Free-Text Human Feedback -- Collect New Datasets Or Extend Existing Ones?. (arXiv:2310.15758v1 [cs.CL])",
    "abstract": "Learning from free-text human feedback is essential for dialog systems, but annotated data is scarce and usually covers only a small fraction of error types known in conversational AI. Instead of collecting and annotating new datasets from scratch, recent advances in synthetic dialog generation could be used to augment existing dialog datasets with the necessary annotations. However, to assess the feasibility of such an effort, it is important to know the types and frequency of free-text human feedback included in these datasets. In this work, we investigate this question for a variety of commonly used dialog datasets, including MultiWoZ, SGD, BABI, PersonaChat, Wizards-of-Wikipedia, and the human-bot split of the Self-Feeding Chatbot. Using our observations, we derive new taxonomies for the annotation of free-text human feedback in dialogs and investigate the impact of including such data in response generation for three SOTA language generation models, including GPT-2, LLAMA, and Fla",
    "link": "http://arxiv.org/abs/2310.15758",
    "context": "Title: Learning From Free-Text Human Feedback -- Collect New Datasets Or Extend Existing Ones?. (arXiv:2310.15758v1 [cs.CL])\nAbstract: Learning from free-text human feedback is essential for dialog systems, but annotated data is scarce and usually covers only a small fraction of error types known in conversational AI. Instead of collecting and annotating new datasets from scratch, recent advances in synthetic dialog generation could be used to augment existing dialog datasets with the necessary annotations. However, to assess the feasibility of such an effort, it is important to know the types and frequency of free-text human feedback included in these datasets. In this work, we investigate this question for a variety of commonly used dialog datasets, including MultiWoZ, SGD, BABI, PersonaChat, Wizards-of-Wikipedia, and the human-bot split of the Self-Feeding Chatbot. Using our observations, we derive new taxonomies for the annotation of free-text human feedback in dialogs and investigate the impact of including such data in response generation for three SOTA language generation models, including GPT-2, LLAMA, and Fla",
    "path": "papers/23/10/2310.15758.json",
    "total_tokens": 958,
    "translated_title": "从自由文本的人类反馈中学习 - 收集新数据集还是扩展现有数据集？",
    "translated_abstract": "从自由文本的人类反馈中学习对于对话系统是必要的，但是标注的数据稀缺，并且通常只涵盖了对话人工智能中已知错误类型的一小部分。与其从头开始收集和注释新的数据集，最近在合成对话生成方面的先进技术可以用于扩充现有的对话数据集以获得必要的注释。然而，为了评估这种努力的可行性，了解这些数据集中包含的各种类型和频率的自由文本人类反馈是很重要的。在这项工作中，我们对各种常用的对话数据集进行了调查，包括 MultiWoZ、SGD、BABI、PersonaChat、Wizards-of-Wikipedia 和 Self-Feeding Chatbot 的人类与机器对话分开的部分。根据我们的观察，我们为对话中的自由文本人类反馈的注释提出了新的分类法，并研究了将这些数据包含在三种先进的语言生成模型（包括GPT-2、LLAMA和Fla）的回答生成中的影响。",
    "tldr": "本研究调查了常用对话数据集中自由文本人类反馈的类型和频率，并提出了用于注释这些反馈的新分类法。通过将这些数据用于回答生成，我们研究了对GPT-2、LLAMA和Fla等语言生成模型的影响。",
    "en_tdlr": "This work investigates the types and frequency of free-text human feedback in commonly used dialog datasets and proposes new taxonomies for annotating this feedback. By incorporating this data into response generation, the impact on language generation models such as GPT-2, LLAMA, and Fla is studied."
}