{
    "title": "Searching for High-Value Molecules Using Reinforcement Learning and Transformers. (arXiv:2310.02902v1 [cs.LG])",
    "abstract": "Reinforcement learning (RL) over text representations can be effective for finding high-value policies that can search over graphs. However, RL requires careful structuring of the search space and algorithm design to be effective in this challenge. Through extensive experiments, we explore how different design choices for text grammar and algorithmic choices for training can affect an RL policy's ability to generate molecules with desired properties. We arrive at a new RL-based molecular design algorithm (ChemRLformer) and perform a thorough analysis using 25 molecule design tasks, including computationally complex protein docking simulations. From this analysis, we discover unique insights in this problem space and show that ChemRLformer achieves state-of-the-art performance while being more straightforward than prior work by demystifying which design choices are actually helpful for text-based molecule design.",
    "link": "http://arxiv.org/abs/2310.02902",
    "context": "Title: Searching for High-Value Molecules Using Reinforcement Learning and Transformers. (arXiv:2310.02902v1 [cs.LG])\nAbstract: Reinforcement learning (RL) over text representations can be effective for finding high-value policies that can search over graphs. However, RL requires careful structuring of the search space and algorithm design to be effective in this challenge. Through extensive experiments, we explore how different design choices for text grammar and algorithmic choices for training can affect an RL policy's ability to generate molecules with desired properties. We arrive at a new RL-based molecular design algorithm (ChemRLformer) and perform a thorough analysis using 25 molecule design tasks, including computationally complex protein docking simulations. From this analysis, we discover unique insights in this problem space and show that ChemRLformer achieves state-of-the-art performance while being more straightforward than prior work by demystifying which design choices are actually helpful for text-based molecule design.",
    "path": "papers/23/10/2310.02902.json",
    "total_tokens": 904,
    "translated_title": "使用强化学习和Transformer搜索高价值分子",
    "translated_abstract": "在搜索图中的高价值策略方面，使用文本表示的强化学习（RL）可以很有效。然而，RL需要对搜索空间进行精心结构化和算法设计才能在这个挑战中发挥作用。通过大量实验，我们探索了不同文本语法设计和训练算法选择如何影响RL策略生成具有所需属性的分子的能力。我们提出了一种新的基于RL的分子设计算法（ChemRLformer），并对其进行了深入分析，包括对计算复杂的蛋白质对接模拟进行的25个分子设计任务。通过这个分析，我们发现了该问题空间中的独特见解，并展示了ChemRLformer相较于之前的工作，通过阐明哪些设计选择实际上对基于文本的分子设计有帮助，实现了最先进的性能。",
    "tldr": "通过使用强化学习和Transformer，我们提出了一种新的基于RL的分子设计算法（ChemRLformer），并在25个分子设计任务中进行了综合分析，包括计算复杂的蛋白质对接模拟。我们发现了分子设计领域的独特见解，并展示了ChemRLformer相对于之前的工作更为简单且实现了最先进的性能。",
    "en_tdlr": "By utilizing reinforcement learning and Transformers, we propose a new RL-based molecular design algorithm (ChemRLformer) and conduct a comprehensive analysis on 25 molecule design tasks, including computationally complex protein docking simulations. We discover unique insights in the field of molecule design and demonstrate that ChemRLformer achieves state-of-the-art performance while being simpler than prior work by elucidating which design choices are truly helpful for text-based molecule design."
}