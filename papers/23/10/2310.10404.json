{
    "title": "LLM4SGG: Large Language Model for Weakly Supervised Scene Graph Generation",
    "abstract": "arXiv:2310.10404v5 Announce Type: cross  Abstract: Weakly-Supervised Scene Graph Generation (WSSGG) research has recently emerged as an alternative to the fully-supervised approach that heavily relies on costly annotations. In this regard, studies on WSSGG have utilized image captions to obtain unlocalized triplets while primarily focusing on grounding the unlocalized triplets over image regions. However, they have overlooked the two issues involved in the triplet formation process from the captions: 1) Semantic over-simplification issue arises when extracting triplets from captions, where fine-grained predicates in captions are undesirably converted into coarse-grained predicates, resulting in a long-tailed predicate distribution, and 2) Low-density scene graph issue arises when aligning the triplets in the caption with entity/predicate classes of interest, where many triplets are discarded and not used in training, leading to insufficient supervision. To tackle the two issues, we pro",
    "link": "https://arxiv.org/abs/2310.10404",
    "context": "Title: LLM4SGG: Large Language Model for Weakly Supervised Scene Graph Generation\nAbstract: arXiv:2310.10404v5 Announce Type: cross  Abstract: Weakly-Supervised Scene Graph Generation (WSSGG) research has recently emerged as an alternative to the fully-supervised approach that heavily relies on costly annotations. In this regard, studies on WSSGG have utilized image captions to obtain unlocalized triplets while primarily focusing on grounding the unlocalized triplets over image regions. However, they have overlooked the two issues involved in the triplet formation process from the captions: 1) Semantic over-simplification issue arises when extracting triplets from captions, where fine-grained predicates in captions are undesirably converted into coarse-grained predicates, resulting in a long-tailed predicate distribution, and 2) Low-density scene graph issue arises when aligning the triplets in the caption with entity/predicate classes of interest, where many triplets are discarded and not used in training, leading to insufficient supervision. To tackle the two issues, we pro",
    "path": "papers/23/10/2310.10404.json",
    "total_tokens": 816,
    "translated_title": "LLM4SGG: 用于弱监督场景图生成的大型语言模型",
    "translated_abstract": "弱监督场景图生成（WSSGG）研究最近出现作为对严重依赖昂贵标注的全监督方法的另一种选择。在这方面，WSSGG研究利用图像标题获取未定位三元组，主要集中在对图像区域中的未定位三元组进行定位。然而，它们忽略了从标题中形成三元组的两个问题：1）从标题提取三元组时出现的语义过度简化问题，其中标题中的细粒度谓词不希望地转换为粗粒度谓词，导致长尾谓词分布，以及2）将标题中的三元组与感兴趣的实体/谓词类对齐时出现低密度场景图问题，其中许多三元组被丢弃且不用于训练，导致监督不足。为了解决这两个问题，我们提出了一种方法",
    "tldr": "这种方法解决了弱监督场景图生成中的语义过度简化和低密度场景图问题。",
    "en_tdlr": "This method addresses the issues of semantic oversimplification and low-density scene graphs in weakly supervised scene graph generation."
}