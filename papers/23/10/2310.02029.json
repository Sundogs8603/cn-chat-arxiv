{
    "title": "Between accurate prediction and poor decision making: the AI/ML gap. (arXiv:2310.02029v1 [cs.LG])",
    "abstract": "Intelligent agents rely on AI/ML functionalities to predict the consequence of possible actions and optimise the policy. However, the effort of the research community in addressing prediction accuracy has been so intense (and successful) that it created the illusion that the more accurate the learner prediction (or classification) the better would have been the final decision. Now, such an assumption is valid only if the (human or artificial) decision maker has complete knowledge of the utility of the possible actions. This paper argues that AI/ML community has taken so far a too unbalanced approach by devoting excessive attention to the estimation of the state (or target) probability to the detriment of accurate and reliable estimations of the utility. In particular, few evidence exists about the impact of a wrong utility assessment on the resulting expected utility of the decision strategy. This situation is creating a substantial gap between the expectations and the effective impact",
    "link": "http://arxiv.org/abs/2310.02029",
    "context": "Title: Between accurate prediction and poor decision making: the AI/ML gap. (arXiv:2310.02029v1 [cs.LG])\nAbstract: Intelligent agents rely on AI/ML functionalities to predict the consequence of possible actions and optimise the policy. However, the effort of the research community in addressing prediction accuracy has been so intense (and successful) that it created the illusion that the more accurate the learner prediction (or classification) the better would have been the final decision. Now, such an assumption is valid only if the (human or artificial) decision maker has complete knowledge of the utility of the possible actions. This paper argues that AI/ML community has taken so far a too unbalanced approach by devoting excessive attention to the estimation of the state (or target) probability to the detriment of accurate and reliable estimations of the utility. In particular, few evidence exists about the impact of a wrong utility assessment on the resulting expected utility of the decision strategy. This situation is creating a substantial gap between the expectations and the effective impact",
    "path": "papers/23/10/2310.02029.json",
    "total_tokens": 873,
    "translated_title": "在准确预测与糟糕决策之间：AI/ML的差距",
    "translated_abstract": "智能代理依赖于AI/ML功能来预测可能行动的后果并优化策略。然而，研究界在解决预测准确性方面的努力非常强烈（且成功），以至于产生了这样的幻觉：学习者预测（或分类）越准确，最终决策就会越好。但这种假设只有在（人类或人工）决策者对可能行动的效用有完全了解的情况下才成立。本文认为，AI/ML界迄今为止采取了过于不平衡的方法，过分关注状态（或目标）概率的估计，而忽视了对效用的准确可靠估计。特别是，很少有证据证明错误的效用评估对决策策略的预期效用产生的影响。这种情况导致了期望和实际影响之间的实质性差距。",
    "tldr": "本文指出，AI/ML界在预测准确性方面过于关注状态概率的估计，忽视了对效用的准确可靠估计，导致了期望和实际影响之间的差距。",
    "en_tdlr": "This paper argues that the AI/ML community has focused too much on estimating state probabilities and neglected accurate and reliable estimations of utility, resulting in a gap between expectations and actual impact."
}