{
    "title": "DP-SGD with weight clipping. (arXiv:2310.18001v1 [cs.LG])",
    "abstract": "Recently, due to the popularity of deep neural networks and other methods whose training typically relies on the optimization of an objective function, and due to concerns for data privacy, there is a lot of interest in differentially private gradient descent methods. To achieve differential privacy guarantees with a minimum amount of noise, it is important to be able to bound precisely the sensitivity of the information which the participants will observe. In this study, we present a novel approach that mitigates the bias arising from traditional gradient clipping. By leveraging public information concerning the current global model and its location within the search domain, we can achieve improved gradient bounds, leading to enhanced sensitivity determinations and refined noise level adjustments. We extend the state of the art algorithms, present improved differential privacy guarantees requiring less noise and present an empirical evaluation.",
    "link": "http://arxiv.org/abs/2310.18001",
    "context": "Title: DP-SGD with weight clipping. (arXiv:2310.18001v1 [cs.LG])\nAbstract: Recently, due to the popularity of deep neural networks and other methods whose training typically relies on the optimization of an objective function, and due to concerns for data privacy, there is a lot of interest in differentially private gradient descent methods. To achieve differential privacy guarantees with a minimum amount of noise, it is important to be able to bound precisely the sensitivity of the information which the participants will observe. In this study, we present a novel approach that mitigates the bias arising from traditional gradient clipping. By leveraging public information concerning the current global model and its location within the search domain, we can achieve improved gradient bounds, leading to enhanced sensitivity determinations and refined noise level adjustments. We extend the state of the art algorithms, present improved differential privacy guarantees requiring less noise and present an empirical evaluation.",
    "path": "papers/23/10/2310.18001.json",
    "total_tokens": 850,
    "translated_title": "带权重剪裁的差分隐私梯度下降方法",
    "translated_abstract": "最近，由于深度神经网络和其他依赖于目标函数优化的方法的高度流行，以及对数据隐私的关注，差分隐私梯度下降方法引起了极大的兴趣。为了在提供最小噪声的情况下实现差分隐私保证，能够准确地限制参与者将观察到的信息的灵敏度非常重要。在本研究中，我们提出了一种新颖的方法，弥补了传统梯度剪裁产生的偏差。通过利用关于当前全局模型及其在搜索领域中位置的公共信息，我们可以获得改进的梯度界限，从而实现更精确的灵敏度确定和噪声水平调整。我们扩展了最先进的算法，提供了更好的差分隐私保证，需要更少的噪声，并进行了实证评估。",
    "tldr": "本研究提出了一种带权重剪裁的差分隐私梯度下降方法，通过利用公共信息对全局模型进行改进，获得更精确的灵敏度界限和噪声水平调整，提供了更好的差分隐私保证。",
    "en_tdlr": "This study presents a novel approach of differentially private gradient descent with weight clipping, which improves gradient bounds and noise level adjustments by leveraging public information about the current global model, leading to enhanced differential privacy guarantees."
}