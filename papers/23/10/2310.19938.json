{
    "title": "Lyapunov-Based Dropout Deep Neural Network (Lb-DDNN) Controller. (arXiv:2310.19938v1 [eess.SY])",
    "abstract": "Deep neural network (DNN)-based adaptive controllers can be used to compensate for unstructured uncertainties in nonlinear dynamic systems. However, DNNs are also very susceptible to overfitting and co-adaptation. Dropout regularization is an approach where nodes are randomly dropped during training to alleviate issues such as overfitting and co-adaptation. In this paper, a dropout DNN-based adaptive controller is developed. The developed dropout technique allows the deactivation of weights that are stochastically selected for each individual layer within the DNN. Simultaneously, a Lyapunov-based real-time weight adaptation law is introduced to update the weights of all layers of the DNN for online unsupervised learning. A non-smooth Lyapunov-based stability analysis is performed to ensure asymptotic convergence of the tracking error. Simulation results of the developed dropout DNN-based adaptive controller indicate a 38.32% improvement in the tracking error, a 53.67% improvement in th",
    "link": "http://arxiv.org/abs/2310.19938",
    "context": "Title: Lyapunov-Based Dropout Deep Neural Network (Lb-DDNN) Controller. (arXiv:2310.19938v1 [eess.SY])\nAbstract: Deep neural network (DNN)-based adaptive controllers can be used to compensate for unstructured uncertainties in nonlinear dynamic systems. However, DNNs are also very susceptible to overfitting and co-adaptation. Dropout regularization is an approach where nodes are randomly dropped during training to alleviate issues such as overfitting and co-adaptation. In this paper, a dropout DNN-based adaptive controller is developed. The developed dropout technique allows the deactivation of weights that are stochastically selected for each individual layer within the DNN. Simultaneously, a Lyapunov-based real-time weight adaptation law is introduced to update the weights of all layers of the DNN for online unsupervised learning. A non-smooth Lyapunov-based stability analysis is performed to ensure asymptotic convergence of the tracking error. Simulation results of the developed dropout DNN-based adaptive controller indicate a 38.32% improvement in the tracking error, a 53.67% improvement in th",
    "path": "papers/23/10/2310.19938.json",
    "total_tokens": 932,
    "translated_title": "基于Lyapunov的Dropout深度神经网络（Lb-DDNN）控制器",
    "translated_abstract": "深度神经网络（DNN）基于自适应控制器可以用来补偿非线性动态系统中的非结构化不确定性。然而，DNN也很容易过拟合和共适应。Dropout正则化是一种在训练过程中随机丢弃节点的方法，以减轻过拟合和共适应等问题。本文提出了一种基于Dropout的DNN自适应控制器。该Dropout技术允许对DNN每个层中的权重进行随机选择的去激活。同时，引入了一种基于Lyapunov的实时权重调整定律，用于更新DNN所有层级的权重以实现在线无监督学习。进行了非光滑的基于Lyapunov的稳定性分析，以确保跟踪误差的渐近收敛。实验结果表明，该基于Dropout的DNN自适应控制器的跟踪误差改进了38.32%，精度改进了53.67%。",
    "tldr": "本文提出了一种基于Dropout的DNN自适应控制器，通过引入基于Lyapunov的实时权重调整定律和Dropout技术，实现了在线无监督学习，并取得了显著的跟踪误差改进和精度提升。",
    "en_tdlr": "This paper proposes a Dropout DNN-based adaptive controller that achieves significant improvement in tracking error and accuracy through the introduction of a real-time weight adaptation law based on Lyapunov and the Dropout technique for online unsupervised learning."
}