{
    "title": "Architectural Implications of GNN Aggregation Programming Abstractions. (arXiv:2310.12184v1 [cs.LG])",
    "abstract": "Graph neural networks (GNNs) have gained significant popularity due to the powerful capability to extract useful representations from graph data. As the need for efficient GNN computation intensifies, a variety of programming abstractions designed for optimizing GNN Aggregation have emerged to facilitate acceleration. However, there is no comprehensive evaluation and analysis upon existing abstractions, thus no clear consensus on which approach is better. In this letter, we classify existing programming abstractions for GNN Aggregation by the dimension of data organization and propagation method. By constructing these abstractions on a state-of-the-art GNN library, we perform a thorough and detailed characterization study to compare their performance and efficiency, and provide several insights on future GNN acceleration based on our analysis.",
    "link": "http://arxiv.org/abs/2310.12184",
    "context": "Title: Architectural Implications of GNN Aggregation Programming Abstractions. (arXiv:2310.12184v1 [cs.LG])\nAbstract: Graph neural networks (GNNs) have gained significant popularity due to the powerful capability to extract useful representations from graph data. As the need for efficient GNN computation intensifies, a variety of programming abstractions designed for optimizing GNN Aggregation have emerged to facilitate acceleration. However, there is no comprehensive evaluation and analysis upon existing abstractions, thus no clear consensus on which approach is better. In this letter, we classify existing programming abstractions for GNN Aggregation by the dimension of data organization and propagation method. By constructing these abstractions on a state-of-the-art GNN library, we perform a thorough and detailed characterization study to compare their performance and efficiency, and provide several insights on future GNN acceleration based on our analysis.",
    "path": "papers/23/10/2310.12184.json",
    "total_tokens": 761,
    "translated_title": "GNN聚合编程抽象的架构影响",
    "translated_abstract": "图神经网络（GNN）由于从图数据中提取有用表示的强大能力而受到广泛关注。随着对高效GNN计算的需求增加，为优化GNN聚合而设计的各种编程抽象应运而生，以促进加速。然而，对现有抽象没有全面的评估和分析，因此对哪种方法更好没有明确的共识。在这封信中，我们通过数据组织和传播方法的维度对现有的GNN聚合编程抽象进行分类。通过在最先进的GNN库上构建这些抽象，我们进行了彻底和详细的特征研究，以比较它们的性能和效率，并根据我们的分析提供了一些关于未来GNN加速的见解。",
    "tldr": "本文通过对现有GNN聚合编程抽象进行分类，并在最先进的GNN库上进行特征研究和性能比较，提供了未来GNN加速的见解。",
    "en_tdlr": "This paper classifies existing GNN aggregation programming abstractions and conducts a comprehensive study to compare their performance and efficiency using a state-of-the-art GNN library, providing insights for future GNN acceleration."
}