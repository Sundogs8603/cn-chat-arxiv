{
    "title": "Causal Context Connects Counterfactual Fairness to Robust Prediction and Group Fairness. (arXiv:2310.19691v1 [cs.LG])",
    "abstract": "Counterfactual fairness requires that a person would have been classified in the same way by an AI or other algorithmic system if they had a different protected class, such as a different race or gender. This is an intuitive standard, as reflected in the U.S. legal system, but its use is limited because counterfactuals cannot be directly observed in real-world data. On the other hand, group fairness metrics (e.g., demographic parity or equalized odds) are less intuitive but more readily observed. In this paper, we use $\\textit{causal context}$ to bridge the gaps between counterfactual fairness, robust prediction, and group fairness. First, we motivate counterfactual fairness by showing that there is not necessarily a fundamental trade-off between fairness and accuracy because, under plausible conditions, the counterfactually fair predictor is in fact accuracy-optimal in an unbiased target distribution. Second, we develop a correspondence between the causal graph of the data-generating ",
    "link": "http://arxiv.org/abs/2310.19691",
    "context": "Title: Causal Context Connects Counterfactual Fairness to Robust Prediction and Group Fairness. (arXiv:2310.19691v1 [cs.LG])\nAbstract: Counterfactual fairness requires that a person would have been classified in the same way by an AI or other algorithmic system if they had a different protected class, such as a different race or gender. This is an intuitive standard, as reflected in the U.S. legal system, but its use is limited because counterfactuals cannot be directly observed in real-world data. On the other hand, group fairness metrics (e.g., demographic parity or equalized odds) are less intuitive but more readily observed. In this paper, we use $\\textit{causal context}$ to bridge the gaps between counterfactual fairness, robust prediction, and group fairness. First, we motivate counterfactual fairness by showing that there is not necessarily a fundamental trade-off between fairness and accuracy because, under plausible conditions, the counterfactually fair predictor is in fact accuracy-optimal in an unbiased target distribution. Second, we develop a correspondence between the causal graph of the data-generating ",
    "path": "papers/23/10/2310.19691.json",
    "total_tokens": 983,
    "translated_title": "因果背景将反事实公平性与强健预测和群体公平性相连接",
    "translated_abstract": "反事实公平性要求如果一个人属于不同的受保护类别，如不同的种族或性别，那么该人在人工智能或其他算法系统中将被分类为相同类别。这是一种直观的标准，反映在美国的法律体系中，但由于反事实在真实世界的数据中无法直接观察到，其使用受限。另一方面，群体公平性度量（如人口平衡或平等赔率）较少直观，但更容易观察到。在本文中，我们使用“因果背景”来弥合反事实公平性、强健预测和群体公平性之间的差距。首先，我们通过展示在合理的条件下，反事实公平预测器实际上在无偏目标分布中是最优准确性的，从而激发了反事实公平性的动机。其次，我们发展了数据生成的因果图与强健预测和群体公平性之间的对应关系。",
    "tldr": "本文通过使用因果背景来将反事实公平性、强健预测和群体公平性相连接。首先，通过合理条件下的研究，证明了反事实公平预测器在无偏目标分布中是准确性最优的。其次，发展了数据生成的因果图与强健预测和群体公平性之间的对应关系。"
}