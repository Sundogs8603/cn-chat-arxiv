{
    "title": "FOCAL: Contrastive Learning for Multimodal Time-Series Sensing Signals in Factorized Orthogonal Latent Space. (arXiv:2310.20071v1 [cs.AI])",
    "abstract": "This paper proposes a novel contrastive learning framework, called FOCAL, for extracting comprehensive features from multimodal time-series sensing signals through self-supervised training. Existing multimodal contrastive frameworks mostly rely on the shared information between sensory modalities, but do not explicitly consider the exclusive modality information that could be critical to understanding the underlying sensing physics. Besides, contrastive frameworks for time series have not handled the temporal information locality appropriately. FOCAL solves these challenges by making the following contributions: First, given multimodal time series, it encodes each modality into a factorized latent space consisting of shared features and private features that are orthogonal to each other. The shared space emphasizes feature patterns consistent across sensory modalities through a modal-matching objective. In contrast, the private space extracts modality-exclusive information through a tr",
    "link": "http://arxiv.org/abs/2310.20071",
    "context": "Title: FOCAL: Contrastive Learning for Multimodal Time-Series Sensing Signals in Factorized Orthogonal Latent Space. (arXiv:2310.20071v1 [cs.AI])\nAbstract: This paper proposes a novel contrastive learning framework, called FOCAL, for extracting comprehensive features from multimodal time-series sensing signals through self-supervised training. Existing multimodal contrastive frameworks mostly rely on the shared information between sensory modalities, but do not explicitly consider the exclusive modality information that could be critical to understanding the underlying sensing physics. Besides, contrastive frameworks for time series have not handled the temporal information locality appropriately. FOCAL solves these challenges by making the following contributions: First, given multimodal time series, it encodes each modality into a factorized latent space consisting of shared features and private features that are orthogonal to each other. The shared space emphasizes feature patterns consistent across sensory modalities through a modal-matching objective. In contrast, the private space extracts modality-exclusive information through a tr",
    "path": "papers/23/10/2310.20071.json",
    "total_tokens": 905,
    "translated_title": "FOCAL: 在因子化正交潜空间中的多模时间序列感知信号中的对比学习",
    "translated_abstract": "本文提出了一个名为FOCAL的新型对比学习框架，通过自监督训练从多模时间序列感知信号中提取全面的特征。现有的多模对比框架主要依赖于感知模态之间的共享信息，但没有明确考虑对理解底层感知物理学至关重要的专属模态信息。此外，针对时间序列的对比框架没有适当处理时间信息局部性。FOCAL解决了这些挑战，具体贡献如下：首先，对于给定的多模时间序列，将每个模态编码到一个因子化的潜空间中，该潜空间由共享特征和彼此正交的专属特征组成。共享空间通过模态匹配目标强调跨感知模态的特征模式一致性。相反，专属空间通过一个目标提取模态独占信息。",
    "tldr": "本文提出了FOCAL框架，可以通过自监督训练从多模时间序列感知信号中提取全面的特征。它通过使每个模态都编码到一个因子化的潜空间中，同时突出共享特征和专属特征，从而有效处理感知模态之间的共享信息和专属信息。",
    "en_tdlr": "This paper proposes the FOCAL framework for extracting comprehensive features from multimodal time-series sensing signals through self-supervised training. It encodes each modality into a factorized latent space and effectively handles both shared and exclusive information between sensory modalities."
}