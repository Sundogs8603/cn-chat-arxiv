{
    "title": "Lightweight Boosting Models for User Response Prediction Using Adversarial Validation. (arXiv:2310.03778v1 [cs.LG])",
    "abstract": "The ACM RecSys Challenge 2023, organized by ShareChat, aims to predict the probability of the app being installed. This paper describes the lightweight solution to this challenge. We formulate the task as a user response prediction task. For rapid prototyping for the task, we propose a lightweight solution including the following steps: 1) using adversarial validation, we effectively eliminate uninformative features from a dataset; 2) to address noisy continuous features and categorical features with a large number of unique values, we employ feature engineering techniques.; 3) we leverage Gradient Boosted Decision Trees (GBDT) for their exceptional performance and scalability. The experiments show that a single LightGBM model, without additional ensembling, performs quite well. Our team achieved ninth place in the challenge with the final leaderboard score of 6.059065. Code for our approach can be found here: https://github.com/choco9966/recsys-challenge-2023.",
    "link": "http://arxiv.org/abs/2310.03778",
    "context": "Title: Lightweight Boosting Models for User Response Prediction Using Adversarial Validation. (arXiv:2310.03778v1 [cs.LG])\nAbstract: The ACM RecSys Challenge 2023, organized by ShareChat, aims to predict the probability of the app being installed. This paper describes the lightweight solution to this challenge. We formulate the task as a user response prediction task. For rapid prototyping for the task, we propose a lightweight solution including the following steps: 1) using adversarial validation, we effectively eliminate uninformative features from a dataset; 2) to address noisy continuous features and categorical features with a large number of unique values, we employ feature engineering techniques.; 3) we leverage Gradient Boosted Decision Trees (GBDT) for their exceptional performance and scalability. The experiments show that a single LightGBM model, without additional ensembling, performs quite well. Our team achieved ninth place in the challenge with the final leaderboard score of 6.059065. Code for our approach can be found here: https://github.com/choco9966/recsys-challenge-2023.",
    "path": "papers/23/10/2310.03778.json",
    "total_tokens": 946,
    "translated_title": "使用对抗验证的轻量级增强模型进行用户响应预测",
    "translated_abstract": "ShareChat组织的ACM RecSys Challenge 2023旨在预测应用被安装的概率。本文描述了对这个挑战的轻量级解决方案。我们将该任务定义为用户响应预测任务。为了快速原型设计，我们提出了一个包括以下步骤的轻量级解决方案：1）使用对抗验证，有效地从数据集中消除非信息性特征；2）为了处理有噪声的连续特征和具有大量唯一值的分类特征，我们采用了特征工程技术；3）我们利用梯度提升决策树（GBDT）的卓越性能和可伸缩性。实验证明，一个单独的LightGBM模型，在没有额外的集成的情况下，表现得很好。我们的团队在比赛中取得了第九名，最终排行榜得分为6.059065。我们的方法的代码可以在这里找到：https://github.com/choco9966/recsys-challenge-2023。",
    "tldr": "这篇论文提出了一个轻量级的增强模型解决方案，通过使用对抗验证来消除非信息性特征，并通过特征工程技术处理有噪声的连续特征和具有大量唯一值的分类特征。实验证明，该方法在ACM RecSys Challenge 2023中取得了良好的性能。",
    "en_tdlr": "This paper presents a lightweight boosting model solution that effectively eliminates uninformative features using adversarial validation and handles noisy continuous features and categorical features with a large number of unique values using feature engineering techniques. The experiments show that the method performs well in the ACM RecSys Challenge 2023."
}