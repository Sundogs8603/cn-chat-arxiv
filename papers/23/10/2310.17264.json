{
    "title": "Variance of ML-based software fault predictors: are we really improving fault prediction?. (arXiv:2310.17264v1 [cs.SE])",
    "abstract": "Software quality assurance activities become increasingly difficult as software systems become more and more complex and continuously grow in size. Moreover, testing becomes even more expensive when dealing with large-scale systems. Thus, to effectively allocate quality assurance resources, researchers have proposed fault prediction (FP) which utilizes machine learning (ML) to predict fault-prone code areas. However, ML algorithms typically make use of stochastic elements to increase the prediction models' generalizability and efficiency of the training process. These stochastic elements, also known as nondeterminism-introducing (NI) factors, lead to variance in the training process and as a result, lead to variance in prediction accuracy and training time. This variance poses a challenge for reproducibility in research. More importantly, while fault prediction models may have shown good performance in the lab (e.g., often-times involving multiple runs and averaging outcomes), high var",
    "link": "http://arxiv.org/abs/2310.17264",
    "context": "Title: Variance of ML-based software fault predictors: are we really improving fault prediction?. (arXiv:2310.17264v1 [cs.SE])\nAbstract: Software quality assurance activities become increasingly difficult as software systems become more and more complex and continuously grow in size. Moreover, testing becomes even more expensive when dealing with large-scale systems. Thus, to effectively allocate quality assurance resources, researchers have proposed fault prediction (FP) which utilizes machine learning (ML) to predict fault-prone code areas. However, ML algorithms typically make use of stochastic elements to increase the prediction models' generalizability and efficiency of the training process. These stochastic elements, also known as nondeterminism-introducing (NI) factors, lead to variance in the training process and as a result, lead to variance in prediction accuracy and training time. This variance poses a challenge for reproducibility in research. More importantly, while fault prediction models may have shown good performance in the lab (e.g., often-times involving multiple runs and averaging outcomes), high var",
    "path": "papers/23/10/2310.17264.json",
    "total_tokens": 898,
    "translated_title": "基于机器学习的软件缺陷预测模型的方差：我们真的在改进缺陷预测吗？",
    "translated_abstract": "随着软件系统越来越复杂并持续增长，软件质量保证活动变得越来越困难。此外，对大规模系统进行测试的成本也更高。为了有效分配质量保证资源，研究人员提出了利用机器学习来预测有缺陷代码区域的缺陷预测（FP）。然而，机器学习算法通常利用随机元素来增加预测模型的泛化能力和训练过程的效率。这些随机元素，也称为引入非确定性因素（NI）的因素，导致训练过程中的方差，从而导致预测准确性和训练时间的方差。这种方差对于研究的可重复性构成了挑战。更重要的是，在实验室中，虽然缺陷预测模型可能表现良好（例如，通常涉及多次运行和平均结果），但高方差会限制其应用范围。",
    "tldr": "本论文研究了基于机器学习的软件缺陷预测模型中的方差问题，并指出这种方差对于研究的可重复性和模型在实际应用中的性能有重要影响。",
    "en_tdlr": "This paper investigates the issue of variance in ML-based software fault prediction models and highlights its significant impact on research reproducibility and the performance of these models in practical applications."
}