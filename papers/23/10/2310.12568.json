{
    "title": "Julearn: an easy-to-use library for leakage-free evaluation and inspection of ML models. (arXiv:2310.12568v1 [cs.LG])",
    "abstract": "The fast-paced development of machine learning (ML) methods coupled with its increasing adoption in research poses challenges for researchers without extensive training in ML. In neuroscience, for example, ML can help understand brain-behavior relationships, diagnose diseases, and develop biomarkers using various data sources like magnetic resonance imaging and electroencephalography. The primary objective of ML is to build models that can make accurate predictions on unseen data. Researchers aim to prove the existence of such generalizable models by evaluating performance using techniques such as cross-validation (CV), which uses systematic subsampling to estimate the generalization performance. Choosing a CV scheme and evaluating an ML pipeline can be challenging and, if used improperly, can lead to overestimated results and incorrect interpretations.  We created julearn, an open-source Python library, that allow researchers to design and evaluate complex ML pipelines without encount",
    "link": "http://arxiv.org/abs/2310.12568",
    "context": "Title: Julearn: an easy-to-use library for leakage-free evaluation and inspection of ML models. (arXiv:2310.12568v1 [cs.LG])\nAbstract: The fast-paced development of machine learning (ML) methods coupled with its increasing adoption in research poses challenges for researchers without extensive training in ML. In neuroscience, for example, ML can help understand brain-behavior relationships, diagnose diseases, and develop biomarkers using various data sources like magnetic resonance imaging and electroencephalography. The primary objective of ML is to build models that can make accurate predictions on unseen data. Researchers aim to prove the existence of such generalizable models by evaluating performance using techniques such as cross-validation (CV), which uses systematic subsampling to estimate the generalization performance. Choosing a CV scheme and evaluating an ML pipeline can be challenging and, if used improperly, can lead to overestimated results and incorrect interpretations.  We created julearn, an open-source Python library, that allow researchers to design and evaluate complex ML pipelines without encount",
    "path": "papers/23/10/2310.12568.json",
    "total_tokens": 875,
    "translated_title": "Julearn: 一个易于使用的库，用于无泄漏评估和检查机器学习模型",
    "translated_abstract": "快速发展的机器学习方法以及它在研究中越来越广泛的应用为没有深入培训的研究人员带来了挑战。例如，在神经科学中，机器学习可以帮助理解脑与行为之间的关系，诊断疾病，并利用磁共振成像和脑电图等各种数据源开发生物标志物。机器学习的主要目标是构建能够在未见数据上进行准确预测的模型。研究人员通过使用交叉验证等技术来评估性能，从而证明这样的可推广模型的存在，交叉验证使用系统子抽样来估计泛化性能。选择交叉验证方案并评估机器学习流水线可能是具有挑战性的，并且如果使用不当可能导致过高的结果和错误的解释。我们创建了一个名为julearn的开源Python库，允许研究人员设计和评估复杂的机器学习流水线而没有遇到漏洞。",
    "tldr": "Julearn是一个易于使用的Python库，可以帮助研究人员设计和评估复杂的机器学习流水线，避免泄漏问题。",
    "en_tdlr": "Julearn is an easy-to-use Python library that helps researchers design and evaluate complex ML pipelines, avoiding leakage issues."
}