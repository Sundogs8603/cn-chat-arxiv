{
    "title": "Relearning Forgotten Knowledge: on Forgetting, Overfit and Training-Free Ensembles of DNNs. (arXiv:2310.11094v1 [cs.LG])",
    "abstract": "The infrequent occurrence of overfit in deep neural networks is perplexing. On the one hand, theory predicts that as models get larger they should eventually become too specialized for a specific training set, with ensuing decrease in generalization. In contrast, empirical results in image classification indicate that increasing the training time of deep models or using bigger models almost never hurts generalization. Is it because the way we measure overfit is too limited? Here, we introduce a novel score for quantifying overfit, which monitors the forgetting rate of deep models on validation data. Presumably, this score indicates that even while generalization improves overall, there are certain regions of the data space where it deteriorates. When thus measured, we show that overfit can occur with and without a decrease in validation accuracy, and may be more common than previously appreciated. This observation may help to clarify the aforementioned confusing picture. We use our obs",
    "link": "http://arxiv.org/abs/2310.11094",
    "context": "Title: Relearning Forgotten Knowledge: on Forgetting, Overfit and Training-Free Ensembles of DNNs. (arXiv:2310.11094v1 [cs.LG])\nAbstract: The infrequent occurrence of overfit in deep neural networks is perplexing. On the one hand, theory predicts that as models get larger they should eventually become too specialized for a specific training set, with ensuing decrease in generalization. In contrast, empirical results in image classification indicate that increasing the training time of deep models or using bigger models almost never hurts generalization. Is it because the way we measure overfit is too limited? Here, we introduce a novel score for quantifying overfit, which monitors the forgetting rate of deep models on validation data. Presumably, this score indicates that even while generalization improves overall, there are certain regions of the data space where it deteriorates. When thus measured, we show that overfit can occur with and without a decrease in validation accuracy, and may be more common than previously appreciated. This observation may help to clarify the aforementioned confusing picture. We use our obs",
    "path": "papers/23/10/2310.11094.json",
    "total_tokens": 1018,
    "translated_title": "重学已遗忘知识：关于遗忘，过拟合和无需训练的深度神经网络集成",
    "translated_abstract": "深度神经网络中过拟合的不经常发生令人困惑。理论预测，随着模型变得更大，它们最终应该变得过度适应某个特定的训练集，从而导致泛化下降。然而，在图像分类的实证结果中，增加深度模型的训练时间或使用更大的模型几乎从不损害泛化。这是因为我们衡量过拟合的方式太过有限吗？在这里，我们引入了一种新的评估过拟合程度的得分，该得分监测深度模型在验证数据上的遗忘速率。这个分数表明，尽管整体上泛化性能得到改善，但在数据空间的某些区域中，泛化性能可能会下降。当用这种方式测量时，我们展示了过拟合可以在验证精度降低和不降低的情况下发生，并且可能比以前认为的更常见。这一观察结果可能有助于澄清前述的困惑局面。",
    "tldr": "本论文介绍一种新的评估过拟合的得分，该得分通过监测深度模型在验证数据上的遗忘速率来衡量。实证结果发现，尽管整体上泛化性能得到改善，但在数据空间的某些区域中，泛化性能可能会下降。这一观察结果有助于澄清关于深度神经网络中过拟合的困惑情况。",
    "en_tdlr": "This paper introduces a novel score for quantifying overfit, which monitors the forgetting rate of deep models on validation data. Empirical results show that while generalization improves overall, there are certain regions of the data space where it deteriorates, contributing to a better understanding of overfit in deep neural networks."
}