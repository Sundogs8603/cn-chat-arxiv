{
    "title": "Making Large Language Models Better Data Creators. (arXiv:2310.20111v1 [cs.CL])",
    "abstract": "Although large language models (LLMs) have advanced the state-of-the-art in NLP significantly, deploying them for downstream applications is still challenging due to cost, responsiveness, control, or concerns around privacy and security. As such, trainable models are still the preferred option in some cases. However, these models still require human-labeled data for optimal performance, which is expensive and time-consuming to obtain. In order to address this issue, several techniques to reduce human effort involve labeling or generating data using LLMs. Although these methods are effective for certain applications, in practice they encounter difficulties in real-world scenarios. Labeling data requires careful data selection, while generating data necessitates task-specific prompt engineering. In this paper, we propose a unified data creation pipeline that requires only a single formatting example, and which is applicable to a broad range of tasks, including traditionally problematic o",
    "link": "http://arxiv.org/abs/2310.20111",
    "context": "Title: Making Large Language Models Better Data Creators. (arXiv:2310.20111v1 [cs.CL])\nAbstract: Although large language models (LLMs) have advanced the state-of-the-art in NLP significantly, deploying them for downstream applications is still challenging due to cost, responsiveness, control, or concerns around privacy and security. As such, trainable models are still the preferred option in some cases. However, these models still require human-labeled data for optimal performance, which is expensive and time-consuming to obtain. In order to address this issue, several techniques to reduce human effort involve labeling or generating data using LLMs. Although these methods are effective for certain applications, in practice they encounter difficulties in real-world scenarios. Labeling data requires careful data selection, while generating data necessitates task-specific prompt engineering. In this paper, we propose a unified data creation pipeline that requires only a single formatting example, and which is applicable to a broad range of tasks, including traditionally problematic o",
    "path": "papers/23/10/2310.20111.json",
    "total_tokens": 895,
    "translated_title": "提升大型语言模型的数据生成能力",
    "translated_abstract": "尽管大型语言模型（LLM）在自然语言处理领域显著提升了技术水平，但在实际应用中，由于成本、响应速度、控制能力以及隐私和安全等方面的考虑，将它们用于下游任务仍然具有挑战性。因此，在某些情况下，可训练模型仍然是首选解决方案。然而，这些模型仍然需要人工标注的数据才能实现最佳性能，而这种数据获取工作成本高且耗时。为了解决这个问题，一些减少人力工作量的技术被提出，其中包括使用LLM进行数据标注或生成数据。虽然这些方法在某些应用中是有效的，但在实际场景中遇到了困难。数据标注需要仔细选择数据，而生成数据则需要特定任务的启示工程。在本文中，我们提出了一个统一的数据生成流程，只需要一个格式化示例，适用于包括传统问题场景在内的广泛任务范围。",
    "tldr": "本文提出了一种统一的数据生成流程，只需要一个格式化示例，可以应用于各种任务，包括传统问题场景。该方法旨在解决大型语言模型在下游应用中依赖于人工标注数据的问题。",
    "en_tdlr": "This paper proposes a unified data creation pipeline that requires only a single formatting example, applicable to a broad range of tasks, including traditionally problematic scenarios. The method aims to address the issue of large language models relying on human-labeled data in downstream applications."
}