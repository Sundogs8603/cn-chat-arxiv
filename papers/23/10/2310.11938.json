{
    "title": "Grounded and Well-rounded: A Methodological Approach to the Study of Cross-modal and Cross-lingual Grounding. (arXiv:2310.11938v1 [cs.CL])",
    "abstract": "Grounding has been argued to be a crucial component towards the development of more complete and truly semantically competent artificial intelligence systems. Literature has divided into two camps: While some argue that grounding allows for qualitatively different generalizations, others believe it can be compensated by mono-modal data quantity. Limited empirical evidence has emerged for or against either position, which we argue is due to the methodological challenges that come with studying grounding and its effects on NLP systems.  In this paper, we establish a methodological framework for studying what the effects are - if any - of providing models with richer input sources than text-only. The crux of it lies in the construction of comparable samples of populations of models trained on different input modalities, so that we can tease apart the qualitative effects of different input sources from quantifiable model performances. Experiments using this framework reveal qualitative dif",
    "link": "http://arxiv.org/abs/2310.11938",
    "context": "Title: Grounded and Well-rounded: A Methodological Approach to the Study of Cross-modal and Cross-lingual Grounding. (arXiv:2310.11938v1 [cs.CL])\nAbstract: Grounding has been argued to be a crucial component towards the development of more complete and truly semantically competent artificial intelligence systems. Literature has divided into two camps: While some argue that grounding allows for qualitatively different generalizations, others believe it can be compensated by mono-modal data quantity. Limited empirical evidence has emerged for or against either position, which we argue is due to the methodological challenges that come with studying grounding and its effects on NLP systems.  In this paper, we establish a methodological framework for studying what the effects are - if any - of providing models with richer input sources than text-only. The crux of it lies in the construction of comparable samples of populations of models trained on different input modalities, so that we can tease apart the qualitative effects of different input sources from quantifiable model performances. Experiments using this framework reveal qualitative dif",
    "path": "papers/23/10/2310.11938.json",
    "total_tokens": 874,
    "translated_title": "紧密与全面：研究跨模态和跨语言基础的方法论途径",
    "translated_abstract": "现有文献对于基础（grounding）被认为是发展更完整和真正语义能力的人工智能系统的关键组成部分存在分歧。有些人认为基础允许进行质量不同的泛化，而其他人则认为通过单模态数据量可以弥补这一差距。然而，目前缺乏有关基础对NLP系统的影响的实证证据，我们认为这是由于研究基础及其对NLP系统的影响所面临的方法论挑战。在本文中，我们建立了一个方法论框架，研究各种输入源（而不仅仅是纯文本）对模型的影响。关键在于构建在不同输入模态上进行训练的模型群体的可比较样本，以便我们可以将不同输入源的质量效应与可量化的模型性能区分开来。使用这一框架的实验揭示了质量的差异。",
    "tldr": "本文提出了一种研究跨模态和跨语言基础问题的方法论框架，通过比较不同输入源的质量效应和模型性能，揭示了基础的影响。",
    "en_tdlr": "This paper presents a methodological framework for studying cross-modal and cross-lingual grounding, revealing the effects of different input sources on model performance and the impact of grounding."
}