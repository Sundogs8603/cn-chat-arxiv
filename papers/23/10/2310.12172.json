{
    "title": "Overview of ImageArg-2023: The First Shared Task in Multimodal Argument Mining. (arXiv:2310.12172v1 [cs.CL])",
    "abstract": "This paper presents an overview of the ImageArg shared task, the first multimodal Argument Mining shared task co-located with the 10th Workshop on Argument Mining at EMNLP 2023. The shared task comprises two classification subtasks - (1) Subtask-A: Argument Stance Classification; (2) Subtask-B: Image Persuasiveness Classification. The former determines the stance of a tweet containing an image and a piece of text toward a controversial topic (e.g., gun control and abortion). The latter determines whether the image makes the tweet text more persuasive. The shared task received 31 submissions for Subtask-A and 21 submissions for Subtask-B from 9 different teams across 6 countries. The top submission in Subtask-A achieved an F1-score of 0.8647 while the best submission in Subtask-B achieved an F1-score of 0.5561.",
    "link": "http://arxiv.org/abs/2310.12172",
    "context": "Title: Overview of ImageArg-2023: The First Shared Task in Multimodal Argument Mining. (arXiv:2310.12172v1 [cs.CL])\nAbstract: This paper presents an overview of the ImageArg shared task, the first multimodal Argument Mining shared task co-located with the 10th Workshop on Argument Mining at EMNLP 2023. The shared task comprises two classification subtasks - (1) Subtask-A: Argument Stance Classification; (2) Subtask-B: Image Persuasiveness Classification. The former determines the stance of a tweet containing an image and a piece of text toward a controversial topic (e.g., gun control and abortion). The latter determines whether the image makes the tweet text more persuasive. The shared task received 31 submissions for Subtask-A and 21 submissions for Subtask-B from 9 different teams across 6 countries. The top submission in Subtask-A achieved an F1-score of 0.8647 while the best submission in Subtask-B achieved an F1-score of 0.5561.",
    "path": "papers/23/10/2310.12172.json",
    "total_tokens": 896,
    "translated_title": "ImageArg-2023概述：多模态论证挖掘中的首个共享任务",
    "translated_abstract": "本文介绍了ImageArg共享任务的概述，这是第一个与EMNLP 2023 Argument Mining Workshop同时举办的多模态论证挖掘共享任务。该共享任务包括两个分类子任务：（1）子任务A：论证立场分类；（2）子任务B：图像说服力分类。前者确定了包含图像和一段文字的推文对于一个有争议的主题（如枪支控制和堕胎）的立场。后者确定图像是否使推文的文字更具说服力。共享任务共收到来自6个国家的9个不同团队提交的31个子任务A的提交和21个子任务B的提交。子任务A中最好的提交的F1得分为0.8647，而子任务B中最好的提交的F1得分为0.5561。",
    "tldr": "ImageArg-2023是第一个多模态论证挖掘的共享任务，涵盖了论证立场分类和图像说服力分类两个子任务。共收到了来自6个国家的9个团队提交的31个子任务A的提交和21个子任务B的提交，最好的提交在子任务A中达到了0.8647的F1得分，在子任务B中达到了0.5561的F1得分。",
    "en_tdlr": "ImageArg-2023 is the first shared task in multimodal argument mining, covering argument stance classification and image persuasiveness classification. It received 31 submissions for Subtask-A and 21 submissions for Subtask-B from 9 teams across 6 countries, with the top submissions achieving F1 scores of 0.8647 and 0.5561, respectively."
}