{
    "title": "Learn from the Past: A Proxy based Adversarial Defense Framework to Boost Robustness. (arXiv:2310.12713v1 [cs.LG])",
    "abstract": "In light of the vulnerability of deep learning models to adversarial samples and the ensuing security issues, a range of methods, including Adversarial Training (AT) as a prominent representative, aimed at enhancing model robustness against various adversarial attacks, have seen rapid development. However, existing methods essentially assist the current state of target model to defend against parameter-oriented adversarial attacks with explicit or implicit computation burdens, which also suffers from unstable convergence behavior due to inconsistency of optimization trajectories. Diverging from previous work, this paper reconsiders the update rule of target model and corresponding deficiency to defend based on its current state. By introducing the historical state of the target model as a proxy, which is endowed with much prior information for defense, we formulate a two-stage update rule, resulting in a general adversarial defense framework, which we refer to as `LAST' ({\\bf L}earn fr",
    "link": "http://arxiv.org/abs/2310.12713",
    "context": "Title: Learn from the Past: A Proxy based Adversarial Defense Framework to Boost Robustness. (arXiv:2310.12713v1 [cs.LG])\nAbstract: In light of the vulnerability of deep learning models to adversarial samples and the ensuing security issues, a range of methods, including Adversarial Training (AT) as a prominent representative, aimed at enhancing model robustness against various adversarial attacks, have seen rapid development. However, existing methods essentially assist the current state of target model to defend against parameter-oriented adversarial attacks with explicit or implicit computation burdens, which also suffers from unstable convergence behavior due to inconsistency of optimization trajectories. Diverging from previous work, this paper reconsiders the update rule of target model and corresponding deficiency to defend based on its current state. By introducing the historical state of the target model as a proxy, which is endowed with much prior information for defense, we formulate a two-stage update rule, resulting in a general adversarial defense framework, which we refer to as `LAST' ({\\bf L}earn fr",
    "path": "papers/23/10/2310.12713.json",
    "total_tokens": 871,
    "translated_title": "从过去学习：基于代理的对抗性防御框架来增强鲁棒性",
    "translated_abstract": "鉴于深度学习模型对对抗样本的脆弱性及其带来的安全问题，一系列方法，包括突出代表性的对抗训练（AT），旨在增强模型对各种对抗攻击的鲁棒性，得到了快速发展。然而，现有方法主要是通过明确或隐性的计算负担帮助目标模型的当前状态来防御面向参数的对抗攻击，同时由于优化轨迹不一致而导致不稳定的收敛行为。与以往的工作不同，本文重新考虑了目标模型的更新规则及其当前状态下的防御不足。通过引入目标模型的历史状态作为代理，并赋予其用于防御的先验信息，我们制定了一个两阶段的更新规则，从而得到一个通用的对抗性防御框架，我们称之为\"LAST\"。",
    "tldr": "本文提出了一个基于代理的对抗性防御框架，通过引入目标模型的历史状态作为代理来增强模型对各种对抗攻击的鲁棒性。"
}