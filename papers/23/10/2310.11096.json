{
    "title": "Sparse-DySta: Sparsity-Aware Dynamic and Static Scheduling for Sparse Multi-DNN Workloads. (arXiv:2310.11096v1 [cs.DC])",
    "abstract": "Running multiple deep neural networks (DNNs) in parallel has become an emerging workload in both edge devices, such as mobile phones where multiple tasks serve a single user for daily activities, and data centers, where various requests are raised from millions of users, as seen with large language models. To reduce the costly computational and memory requirements of these workloads, various efficient sparsification approaches have been introduced, resulting in widespread sparsity across different types of DNN models. In this context, there is an emerging need for scheduling sparse multi-DNN workloads, a problem that is largely unexplored in previous literature. This paper systematically analyses the use-cases of multiple sparse DNNs and investigates the opportunities for optimizations. Based on these findings, we propose Dysta, a novel bi-level dynamic and static scheduler that utilizes both static sparsity patterns and dynamic sparsity information for the sparse multi-DNN scheduling.",
    "link": "http://arxiv.org/abs/2310.11096",
    "context": "Title: Sparse-DySta: Sparsity-Aware Dynamic and Static Scheduling for Sparse Multi-DNN Workloads. (arXiv:2310.11096v1 [cs.DC])\nAbstract: Running multiple deep neural networks (DNNs) in parallel has become an emerging workload in both edge devices, such as mobile phones where multiple tasks serve a single user for daily activities, and data centers, where various requests are raised from millions of users, as seen with large language models. To reduce the costly computational and memory requirements of these workloads, various efficient sparsification approaches have been introduced, resulting in widespread sparsity across different types of DNN models. In this context, there is an emerging need for scheduling sparse multi-DNN workloads, a problem that is largely unexplored in previous literature. This paper systematically analyses the use-cases of multiple sparse DNNs and investigates the opportunities for optimizations. Based on these findings, we propose Dysta, a novel bi-level dynamic and static scheduler that utilizes both static sparsity patterns and dynamic sparsity information for the sparse multi-DNN scheduling.",
    "path": "papers/23/10/2310.11096.json",
    "total_tokens": 960,
    "translated_title": "稀疏-DySta：用于稀疏多DNN工作负载的稀疏感知动态和静态调度",
    "translated_abstract": "在边缘设备（如手机）和数据中心中，同时运行多个深度神经网络（DNN）已成为新兴工作负载，其中多个任务为单个用户的日常活动提供服务，并且从数百万用户中提出各种请求，如大型语言模型。为了减少这些工作负载的高昂计算和内存需求，引入了各种高效的稀疏化方法，导致不同类型的DNN模型普遍稀疏。在这个背景下，以往文献中很少探讨稀疏多DNN工作负载的调度问题。本文系统地分析了多个稀疏DNN的使用情况，并探讨了优化的机会。基于这些发现，我们提出了Dysta，一种新颖的双层动态和静态调度器，利用静态稀疏模式和动态稀疏信息进行稀疏多DNN调度。",
    "tldr": "本文提出了Dysta，一种稀疏感知的动态和静态调度器，用于稀疏多DNN工作负载。通过分析多个稀疏DNN的使用情况，发现了优化的机会，并提出了Dysta调度器，利用静态稀疏模式和动态稀疏信息进行调度。",
    "en_tdlr": "This paper proposes Dysta, a sparsity-aware dynamic and static scheduler for sparse multi-DNN workloads. By analyzing the use-cases of multiple sparse DNNs, opportunities for optimization are identified and the Dysta scheduler is introduced, utilizing both static sparsity patterns and dynamic sparsity information for scheduling."
}