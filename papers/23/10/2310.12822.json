{
    "title": "Generating collective counterfactual explanations in score-based classification via mathematical optimization. (arXiv:2310.12822v1 [stat.ML])",
    "abstract": "Due to the increasing use of Machine Learning models in high stakes decision making settings, it has become increasingly important to have tools to understand how models arrive at decisions. Assuming a trained Supervised Classification model, explanations can be obtained via counterfactual analysis: a counterfactual explanation of an instance indicates how this instance should be minimally modified so that the perturbed instance is classified in the desired class by the Machine Learning classification model. Most of the Counterfactual Analysis literature focuses on the single-instance single-counterfactual setting, in which the analysis is done for one single instance to provide one single explanation. Taking a stakeholder's perspective, in this paper we introduce the so-called collective counterfactual explanations. By means of novel Mathematical Optimization models, we provide a counterfactual explanation for each instance in a group of interest, so that the total cost of the perturb",
    "link": "http://arxiv.org/abs/2310.12822",
    "context": "Title: Generating collective counterfactual explanations in score-based classification via mathematical optimization. (arXiv:2310.12822v1 [stat.ML])\nAbstract: Due to the increasing use of Machine Learning models in high stakes decision making settings, it has become increasingly important to have tools to understand how models arrive at decisions. Assuming a trained Supervised Classification model, explanations can be obtained via counterfactual analysis: a counterfactual explanation of an instance indicates how this instance should be minimally modified so that the perturbed instance is classified in the desired class by the Machine Learning classification model. Most of the Counterfactual Analysis literature focuses on the single-instance single-counterfactual setting, in which the analysis is done for one single instance to provide one single explanation. Taking a stakeholder's perspective, in this paper we introduce the so-called collective counterfactual explanations. By means of novel Mathematical Optimization models, we provide a counterfactual explanation for each instance in a group of interest, so that the total cost of the perturb",
    "path": "papers/23/10/2310.12822.json",
    "total_tokens": 870,
    "translated_title": "通过数学优化在基于评分的分类中生成集体反事实解释",
    "translated_abstract": "随着机器学习模型在高风险决策场景中的增加使用，了解模型如何做出决策变得越来越重要。在经过训练的监督分类模型中，可以通过反事实分析获得解释：一个实例的反事实解释指示应该如何最小程度地修改这个实例，使得被扰动的实例在机器学习模型中被分类到所期望的类别中。大部分反事实分析文献集中在单实例单反事实的情况下，即针对一个单一实例来提供一个单一解释。从利益相关者的角度出发，在本文中我们介绍了所谓的集体反事实解释。通过新颖的数学优化模型，我们为感兴趣的一组实例提供反事实解释，以使扰动的总成本最小。",
    "tldr": "通过数学优化，本文引入了集体反事实解释，为高风险决策场景中的机器学习模型提供了解释工具。与传统的单实例解释不同，该方法针对一组实例提供解释，并通过最小化扰动的总成本来提供最优解释。",
    "en_tdlr": "This paper introduces collective counterfactual explanations using mathematical optimization, providing tools to understand machine learning models used in high-stakes decision making. Unlike traditional single-instance explanations, this method offers explanations for a group of instances and aims to minimize the total cost of perturbations."
}