{
    "title": "Bird's Eye View Based Pretrained World model for Visual Navigation",
    "abstract": "arXiv:2310.18847v2 Announce Type: replace-cross  Abstract: Sim2Real transfer has gained popularity because it helps transfer from inexpensive simulators to real world. This paper presents a novel system that fuses components in a traditional World Model into a robust system, trained entirely within a simulator, that Zero-Shot transfers to the real world. To facilitate transfer, we use an intermediary representation that is based on \\textit{Bird's Eye View (BEV)} images. Thus, our robot learns to navigate in a simulator by first learning to translate from complex \\textit{First-Person View (FPV)} based RGB images to BEV representations, then learning to navigate using those representations. Later, when tested in the real world, the robot uses the perception model that translates FPV-based RGB images to embeddings that were learned by the FPV to BEV translator and that can be used by the downstream policy. The incorporation of state-checking modules using \\textit{Anchor images} and Mixtur",
    "link": "https://arxiv.org/abs/2310.18847",
    "context": "Title: Bird's Eye View Based Pretrained World model for Visual Navigation\nAbstract: arXiv:2310.18847v2 Announce Type: replace-cross  Abstract: Sim2Real transfer has gained popularity because it helps transfer from inexpensive simulators to real world. This paper presents a novel system that fuses components in a traditional World Model into a robust system, trained entirely within a simulator, that Zero-Shot transfers to the real world. To facilitate transfer, we use an intermediary representation that is based on \\textit{Bird's Eye View (BEV)} images. Thus, our robot learns to navigate in a simulator by first learning to translate from complex \\textit{First-Person View (FPV)} based RGB images to BEV representations, then learning to navigate using those representations. Later, when tested in the real world, the robot uses the perception model that translates FPV-based RGB images to embeddings that were learned by the FPV to BEV translator and that can be used by the downstream policy. The incorporation of state-checking modules using \\textit{Anchor images} and Mixtur",
    "path": "papers/23/10/2310.18847.json",
    "total_tokens": 812,
    "translated_title": "基于鸟瞰视角预训练世界模型用于视觉导航",
    "translated_abstract": "Sim2Real转移已经变得流行，因为它有助于从廉价的模拟器转移到现实世界。本文提出了一个新颖的系统，在传统世界模型中融合组件，完全在模拟器中训练，可以零迁移到真实世界。为了促进转移，我们使用基于鸟瞰视角图像的中间表示。因此，我们的机器人通过先学习将复杂的基于第一人称视角的RGB图像转换为BEV表示，然后学习使用这些表示来在模拟中导航。当在真实世界中进行测试时，机器人使用将FPV基础RGB图像转换为FPV到BEV转换器学习的嵌入的感知模型，并且可以被下游策略使用。利用状态检查模块，使用锚定图像和混合",
    "tldr": "通过基于鸟瞰视角图像的预训练世界模型，实现了从模拟器到真实世界的零迁移",
    "en_tdlr": "Achieved Zero-Shot transfer from simulator to real world using a pretrained world model based on Bird's Eye View images."
}