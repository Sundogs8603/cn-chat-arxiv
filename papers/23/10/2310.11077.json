{
    "title": "United We Stand: Using Epoch-wise Agreement of Ensembles to Combat Overfit. (arXiv:2310.11077v1 [cs.LG])",
    "abstract": "Deep neural networks have become the method of choice for solving many image classification tasks, largely because they can fit very complex functions defined over raw images. The downside of such powerful learners is the danger of overfitting the training set, leading to poor generalization, which is usually avoided by regularization and \"early stopping\" of the training. In this paper, we propose a new deep network ensemble classifier that is very effective against overfit. We begin with the theoretical analysis of a regression model, whose predictions - that the variance among classifiers increases when overfit occurs - is demonstrated empirically in deep networks in common use. Guided by these results, we construct a new ensemble-based prediction method designed to combat overfit, where the prediction is determined by the most consensual prediction throughout the training. On multiple image and text classification datasets, we show that when regular ensembles suffer from overfit, ou",
    "link": "http://arxiv.org/abs/2310.11077",
    "context": "Title: United We Stand: Using Epoch-wise Agreement of Ensembles to Combat Overfit. (arXiv:2310.11077v1 [cs.LG])\nAbstract: Deep neural networks have become the method of choice for solving many image classification tasks, largely because they can fit very complex functions defined over raw images. The downside of such powerful learners is the danger of overfitting the training set, leading to poor generalization, which is usually avoided by regularization and \"early stopping\" of the training. In this paper, we propose a new deep network ensemble classifier that is very effective against overfit. We begin with the theoretical analysis of a regression model, whose predictions - that the variance among classifiers increases when overfit occurs - is demonstrated empirically in deep networks in common use. Guided by these results, we construct a new ensemble-based prediction method designed to combat overfit, where the prediction is determined by the most consensual prediction throughout the training. On multiple image and text classification datasets, we show that when regular ensembles suffer from overfit, ou",
    "path": "papers/23/10/2310.11077.json",
    "total_tokens": 982,
    "translated_title": "团结一致：利用分时一致性集合来对抗过拟合",
    "translated_abstract": "深度神经网络已经成为解决许多图像分类任务的首选方法，主要是因为它们可以拟合原始图像上定义的非常复杂的函数。这种强大学习器的缺点是过拟合训练集的危险，导致泛化能力差，通常通过正则化和训练的“提前停止”来避免。在本文中，我们提出了一种新的深度网络集成分类器，它对抗过拟合非常有效。我们首先对回归模型进行理论分析，证明了当发生过拟合时，分类器之间的方差增加，这一点已在常用的深度网络中得到了实证。在这些结果的指导下，我们构建了一种新的基于集成的预测方法，旨在对抗过拟合，其中预测结果是通过整个训练过程中最具一致性的预测结果确定的。在多个图像和文本分类数据集上，我们展示了当常规集成遭受过拟合时，我们的方法能够更好地应对。",
    "tldr": "本论文提出了一种新的深度网络集成分类器，通过分析和实证发现过拟合时分类器之间的方差增加，基于此构建了一种通过整个训练过程中最具一致性的预测结果来对抗过拟合的方法。在实验中表明，这种方法在多个图像和文本分类任务上的表现优于传统的集成方法。",
    "en_tdlr": "This paper proposes a new deep network ensemble classifier that effectively combats overfitting. By analyzing and empirically demonstrating the increase in variance among classifiers when overfitting occurs, the paper constructs a prediction method that relies on the most consensual prediction throughout the training process. Experimental results show that this method outperforms traditional ensemble methods for multiple image and text classification tasks."
}