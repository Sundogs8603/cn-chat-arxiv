{
    "title": "No Privacy Left Outside: On the (In-)Security of TEE-Shielded DNN Partition for On-Device ML. (arXiv:2310.07152v1 [cs.CR])",
    "abstract": "On-device ML introduces new security challenges: DNN models become white-box accessible to device users. Based on white-box information, adversaries can conduct effective model stealing (MS) and membership inference attack (MIA). Using Trusted Execution Environments (TEEs) to shield on-device DNN models aims to downgrade (easy) white-box attacks to (harder) black-box attacks. However, one major shortcoming is the sharply increased latency (up to 50X). To accelerate TEE-shield DNN computation with GPUs, researchers proposed several model partition techniques. These solutions, referred to as TEE-Shielded DNN Partition (TSDP), partition a DNN model into two parts, offloading the privacy-insensitive part to the GPU while shielding the privacy-sensitive part within the TEE. This paper benchmarks existing TSDP solutions using both MS and MIA across a variety of DNN models, datasets, and metrics. We show important findings that existing TSDP solutions are vulnerable to privacy-stealing attack",
    "link": "http://arxiv.org/abs/2310.07152",
    "context": "Title: No Privacy Left Outside: On the (In-)Security of TEE-Shielded DNN Partition for On-Device ML. (arXiv:2310.07152v1 [cs.CR])\nAbstract: On-device ML introduces new security challenges: DNN models become white-box accessible to device users. Based on white-box information, adversaries can conduct effective model stealing (MS) and membership inference attack (MIA). Using Trusted Execution Environments (TEEs) to shield on-device DNN models aims to downgrade (easy) white-box attacks to (harder) black-box attacks. However, one major shortcoming is the sharply increased latency (up to 50X). To accelerate TEE-shield DNN computation with GPUs, researchers proposed several model partition techniques. These solutions, referred to as TEE-Shielded DNN Partition (TSDP), partition a DNN model into two parts, offloading the privacy-insensitive part to the GPU while shielding the privacy-sensitive part within the TEE. This paper benchmarks existing TSDP solutions using both MS and MIA across a variety of DNN models, datasets, and metrics. We show important findings that existing TSDP solutions are vulnerable to privacy-stealing attack",
    "path": "papers/23/10/2310.07152.json",
    "total_tokens": 966,
    "translated_title": "设备外没有隐私：关于TEE保护下的设备端机器学习的（不）安全性",
    "translated_abstract": "设备端机器学习引入了新的安全挑战：DNN模型可以被设备用户白盒访问。基于白盒信息，攻击者可以进行有效的模型窃取和成员推断攻击。使用可信执行环境（TEE）来保护设备端的DNN模型旨在将（易于进行的）白盒攻击降级为（更难进行的）黑盒攻击。然而，一个主要的缺点是大大增加了延迟（高达50倍）。为了加速使用GPU进行TEE保护的DNN计算，研究人员提出了几种模型分区技术。这些解决方案被称为TEE保护的DNN分区（TSDP），将DNN模型分为两个部分，将隐私不敏感的部分卸载到GPU上，同时将隐私敏感的部分保护在TEE内。本文评估了现有的TSDP解决方案在各种DNN模型、数据集和指标上进行了模型窃取和成员推断攻击的实验。我们发现现有的TSDP解决方案容易受到隐私窃取攻击的影响。",
    "tldr": "本文研究了TEE保护下设备端机器学习的安全性问题。通过对现有的TSDP解决方案进行评估，发现这些解决方案容易受到隐私窃取攻击的影响。"
}