{
    "title": "Transformers and Large Language Models for Chemistry and Drug Discovery. (arXiv:2310.06083v1 [cs.LG])",
    "abstract": "Language modeling has seen impressive progress over the last years, mainly prompted by the invention of the Transformer architecture, sparking a revolution in many fields of machine learning, with breakthroughs in chemistry and biology. In this chapter, we explore how analogies between chemical and natural language have inspired the use of Transformers to tackle important bottlenecks in the drug discovery process, such as retrosynthetic planning and chemical space exploration. The revolution started with models able to perform particular tasks with a single type of data, like linearised molecular graphs, which then evolved to include other types of data, like spectra from analytical instruments, synthesis actions, and human language. A new trend leverages recent developments in large language models, giving rise to a wave of models capable of solving generic tasks in chemistry, all facilitated by the flexibility of natural language. As we continue to explore and harness these capabilit",
    "link": "http://arxiv.org/abs/2310.06083",
    "context": "Title: Transformers and Large Language Models for Chemistry and Drug Discovery. (arXiv:2310.06083v1 [cs.LG])\nAbstract: Language modeling has seen impressive progress over the last years, mainly prompted by the invention of the Transformer architecture, sparking a revolution in many fields of machine learning, with breakthroughs in chemistry and biology. In this chapter, we explore how analogies between chemical and natural language have inspired the use of Transformers to tackle important bottlenecks in the drug discovery process, such as retrosynthetic planning and chemical space exploration. The revolution started with models able to perform particular tasks with a single type of data, like linearised molecular graphs, which then evolved to include other types of data, like spectra from analytical instruments, synthesis actions, and human language. A new trend leverages recent developments in large language models, giving rise to a wave of models capable of solving generic tasks in chemistry, all facilitated by the flexibility of natural language. As we continue to explore and harness these capabilit",
    "path": "papers/23/10/2310.06083.json",
    "total_tokens": 924,
    "translated_title": "Transformers和大型语言模型在化学和药物发现中的应用",
    "translated_abstract": "这篇论文探讨了语言建模在过去几年取得的显著进展，主要是由于Transformer架构的发明，引发了机器学习领域的许多领域的革命，以及在化学和生物学领域的突破。本章中，我们探讨了化学和自然语言之间的类比是如何启发使用Transformer来解决药物发现过程中的重要瓶颈，如逆合成规划和化学空间探索。这一革命始于能够使用一种类型的数据执行特定任务的模型，比如线性化的分子图，然后发展到包括其他类型的数据，如来自分析仪器的光谱、合成行动和人类语言。一种新的趋势利用了大型语言模型的最新发展，产生了一系列能够解决化学中通用任务的模型，这些模型的灵活性是由自然语言提供的。随着我们继续探索和应用这些能力，我们可以期待进一步的突破和进步。",
    "tldr": "transformers和大型语言模型在化学和药物发现中的应用取得了显著进展，通过类比自然语言和化学的关系，这些模型能够解决药物发现过程中的重要问题，进一步的发展将带来更多突破和进步。"
}