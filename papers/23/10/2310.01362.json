{
    "title": "Fleet Learning via Policy Merging",
    "abstract": "arXiv:2310.01362v2 Announce Type: replace-cross  Abstract: Fleets of robots ingest massive amounts of heterogeneous streaming data silos generated by interacting with their environments, far more than what can be stored or transmitted with ease. At the same time, teams of robots should co-acquire diverse skills through their heterogeneous experiences in varied settings. How can we enable such fleet-level learning without having to transmit or centralize fleet-scale data? In this paper, we investigate policy merging (PoMe) from such distributed heterogeneous datasets as a potential solution. To efficiently merge policies in the fleet setting, we propose FLEET-MERGE, an instantiation of distributed learning that accounts for the permutation invariance that arises when parameterizing the control policies with recurrent neural networks. We show that FLEET-MERGE consolidates the behavior of policies trained on 50 tasks in the Meta-World environment, with good performance on nearly all train",
    "link": "https://arxiv.org/abs/2310.01362",
    "context": "Title: Fleet Learning via Policy Merging\nAbstract: arXiv:2310.01362v2 Announce Type: replace-cross  Abstract: Fleets of robots ingest massive amounts of heterogeneous streaming data silos generated by interacting with their environments, far more than what can be stored or transmitted with ease. At the same time, teams of robots should co-acquire diverse skills through their heterogeneous experiences in varied settings. How can we enable such fleet-level learning without having to transmit or centralize fleet-scale data? In this paper, we investigate policy merging (PoMe) from such distributed heterogeneous datasets as a potential solution. To efficiently merge policies in the fleet setting, we propose FLEET-MERGE, an instantiation of distributed learning that accounts for the permutation invariance that arises when parameterizing the control policies with recurrent neural networks. We show that FLEET-MERGE consolidates the behavior of policies trained on 50 tasks in the Meta-World environment, with good performance on nearly all train",
    "path": "papers/23/10/2310.01362.json",
    "total_tokens": 867,
    "translated_title": "通过策略合并实现舰队学习",
    "translated_abstract": "机器人群体通过与环境互动产生的大量异构流数据存储或传输上的困难，机器人团队需要通过在不同环境中的异构经验来共同获得多样化的技能。本文研究了从这种分布式异构数据集中进行策略合并作为潜在解决方案的问题。为了在舰队环境中高效合并策略，我们提出了FLEET-MERGE，一种基于循环神经网络参数化控制策略的分布式学习实例，考虑了参数化控制策略中的排列不变性。我们表明，FLEET-MERGE在Meta-World环境中对50个任务进行训练的策略行为进行了整合，并且几乎在所有训练任务上表现良好。",
    "tldr": "本文研究了通过策略合并解决机器人群体学习中的数据存储和传输问题，并提出了一种基于循环神经网络的分布式学习方法。该方法能够在Meta-World环境中将50个任务的策略行为整合，并在大多数训练任务上表现良好。",
    "en_tdlr": "This paper investigates the problem of data storage and transmission in fleet-level learning for robots and proposes a distributed learning approach based on recurrent neural networks to solve it. The approach, called FLEET-MERGE, consolidates the behavior of policies trained on 50 tasks in the Meta-World environment and performs well on the majority of training tasks."
}