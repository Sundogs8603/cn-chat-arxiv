{
    "title": "UniPredict: Large Language Models are Universal Tabular Predictors. (arXiv:2310.03266v1 [cs.LG])",
    "abstract": "Tabular data prediction is a fundamental machine learning task for many applications. Existing methods predominantly employ discriminative modeling and operate under the assumption of a fixed target column, necessitating re-training for every new predictive task. Inspired by the generative power of large language models (LLMs), this paper exploits the idea of building universal tabular data predictors based on generative modeling, namely UniPredict. Here, we show that scaling up an LLM to extensive tabular datasets with the capability of comprehending diverse tabular inputs and predicting for target variables following the input instructions. Specifically, we train a single LLM on an aggregation of 169 tabular datasets with diverse targets and compare its performance against baselines that are trained on each dataset separately. We observe this versatile UniPredict model demonstrates an advantage over other models, ranging from 5.4% to 13.4%, when compared with the best tree-boosting b",
    "link": "http://arxiv.org/abs/2310.03266",
    "context": "Title: UniPredict: Large Language Models are Universal Tabular Predictors. (arXiv:2310.03266v1 [cs.LG])\nAbstract: Tabular data prediction is a fundamental machine learning task for many applications. Existing methods predominantly employ discriminative modeling and operate under the assumption of a fixed target column, necessitating re-training for every new predictive task. Inspired by the generative power of large language models (LLMs), this paper exploits the idea of building universal tabular data predictors based on generative modeling, namely UniPredict. Here, we show that scaling up an LLM to extensive tabular datasets with the capability of comprehending diverse tabular inputs and predicting for target variables following the input instructions. Specifically, we train a single LLM on an aggregation of 169 tabular datasets with diverse targets and compare its performance against baselines that are trained on each dataset separately. We observe this versatile UniPredict model demonstrates an advantage over other models, ranging from 5.4% to 13.4%, when compared with the best tree-boosting b",
    "path": "papers/23/10/2310.03266.json",
    "total_tokens": 902,
    "translated_title": "UniPredict：大型语言模型是通用的表格预测器",
    "translated_abstract": "表格数据预测是许多应用中的基础机器学习任务。现有方法主要采用判别建模，并在假设固定目标列的情况下进行运算，需要为每个新的预测任务重新训练。本文受到大型语言模型(LLMs)生成能力的启发，提出了基于生成建模的通用表格数据预测器UniPredict。我们展示了将LLM扩展到庞大的表格数据集的方法，能够理解不同的表格输入并根据输入指令预测目标变量。具体地，我们在169个具有不同目标的表格数据集上训练了一个单一的LLM，并将其性能与分别在每个数据集上训练的基准模型进行了比较。我们观察到这个多功能的UniPredict模型在与最佳的树提升模型相比时表现出5.4%到13.4%的优势。",
    "tldr": "本文提出了UniPredict，一个基于大型语言模型的通用表格数据预测器，能够扩展到庞大的表格数据集，并具备理解多样化表格输入和根据输入指令预测目标变量的能力。实验结果表明，UniPredict模型在与其他模型相比时具有显著优势。",
    "en_tdlr": "This paper introduces UniPredict, a universal tabular data predictor based on large language models. It demonstrates the ability to scale up to extensive tabular datasets, comprehend diverse tabular inputs, and predict target variables based on input instructions. Experimental results show that UniPredict outperforms other models significantly."
}