{
    "title": "Flood and Echo: Algorithmic Alignment of GNNs with Distributed Computing. (arXiv:2310.06970v1 [cs.LG])",
    "abstract": "Graph Neural Networks are a natural fit for learning algorithms. They can directly represent tasks through an abstract but versatile graph structure and handle inputs of different sizes. This opens up the possibility for scaling and extrapolation to larger graphs, one of the most important advantages of an algorithm. However, this raises two core questions i) How can we enable nodes to gather the required information in a given graph ($\\textit{information exchange}$), even if is far away and ii) How can we design an execution framework which enables this information exchange for extrapolation to larger graph sizes ($\\textit{algorithmic alignment for extrapolation}$). We propose a new execution framework that is inspired by the design principles of distributed algorithms: Flood and Echo Net. It propagates messages through the entire graph in a wave like activation pattern, which naturally generalizes to larger instances. Through its sparse but parallel activations it is provably more ef",
    "link": "http://arxiv.org/abs/2310.06970",
    "context": "Title: Flood and Echo: Algorithmic Alignment of GNNs with Distributed Computing. (arXiv:2310.06970v1 [cs.LG])\nAbstract: Graph Neural Networks are a natural fit for learning algorithms. They can directly represent tasks through an abstract but versatile graph structure and handle inputs of different sizes. This opens up the possibility for scaling and extrapolation to larger graphs, one of the most important advantages of an algorithm. However, this raises two core questions i) How can we enable nodes to gather the required information in a given graph ($\\textit{information exchange}$), even if is far away and ii) How can we design an execution framework which enables this information exchange for extrapolation to larger graph sizes ($\\textit{algorithmic alignment for extrapolation}$). We propose a new execution framework that is inspired by the design principles of distributed algorithms: Flood and Echo Net. It propagates messages through the entire graph in a wave like activation pattern, which naturally generalizes to larger instances. Through its sparse but parallel activations it is provably more ef",
    "path": "papers/23/10/2310.06970.json",
    "total_tokens": 868,
    "translated_title": "洪水和回声：图神经网络与分布式计算的算法对齐",
    "translated_abstract": "图神经网络是学习算法的自然选择。它们可以通过抽象而多功能的图结构直接表示任务，并处理不同规模的输入。这为算法的扩展和外推到更大的图形提供了可能性，这是一种最重要的优势。然而，这提出了两个核心问题：i）如何使节点能够在给定的图中收集所需的信息（即“信息交换”），即使节点距离很远；ii）我们如何设计一个执行框架，以实现该信息交换以便外推到更大的图大小（即“外推时的算法对齐”）。我们提出了一个新的执行框架，受分布式算法的设计原则启发：洪水和回声网络。它以波状激活模式将消息传播到整个图中，自然地推广到更大的实例。通过它的稀疏但并行激活，可以证明它更加高效。",
    "tldr": "本论文提出了一个基于分布式算法设计原则的新的执行框架：洪水和回声网络。通过波状激活模式，它可以在整个图中传递消息，并且可以有效地处理更大的图形。",
    "en_tdlr": "This paper proposes a new execution framework called Flood and Echo Net, which is inspired by the design principles of distributed algorithms. It enables the propagation of messages through the entire graph in a wave-like activation pattern and can effectively handle larger graphs."
}