{
    "title": "Accelerate Presolve in Large-Scale Linear Programming via Reinforcement Learning. (arXiv:2310.11845v1 [cs.LG])",
    "abstract": "Large-scale LP problems from industry usually contain much redundancy that severely hurts the efficiency and reliability of solving LPs, making presolve (i.e., the problem simplification module) one of the most critical components in modern LP solvers. However, how to design high-quality presolve routines -that is, the program determining (P1) which presolvers to select, (P2) in what order to execute, and (P3) when to stop -- remains a highly challenging task due to the extensive requirements on expert knowledge and the large search space. Due to the sequential decision property of the task and the lack of expert demonstrations, we propose a simple and efficient reinforcement learning (RL) framework -- namely, reinforcement learning for presolve (RL4Presolve) -to tackle (P1)-(P3) simultaneously. Specifically, we formulate the routine design task as a Markov decision process and propose an RL framework with adaptive action sequences to generate high-quality presolve routines efficie",
    "link": "http://arxiv.org/abs/2310.11845",
    "context": "Title: Accelerate Presolve in Large-Scale Linear Programming via Reinforcement Learning. (arXiv:2310.11845v1 [cs.LG])\nAbstract: Large-scale LP problems from industry usually contain much redundancy that severely hurts the efficiency and reliability of solving LPs, making presolve (i.e., the problem simplification module) one of the most critical components in modern LP solvers. However, how to design high-quality presolve routines -that is, the program determining (P1) which presolvers to select, (P2) in what order to execute, and (P3) when to stop -- remains a highly challenging task due to the extensive requirements on expert knowledge and the large search space. Due to the sequential decision property of the task and the lack of expert demonstrations, we propose a simple and efficient reinforcement learning (RL) framework -- namely, reinforcement learning for presolve (RL4Presolve) -to tackle (P1)-(P3) simultaneously. Specifically, we formulate the routine design task as a Markov decision process and propose an RL framework with adaptive action sequences to generate high-quality presolve routines efficie",
    "path": "papers/23/10/2310.11845.json",
    "total_tokens": 928,
    "translated_title": "通过强化学习加速大规模线性规划中的前处理",
    "translated_abstract": "来自工业界的大规模线性规划问题通常包含大量冗余，严重影响了解决线性规划问题的效率和可靠性，使得前处理（即问题简化模块）成为现代线性规划求解器中最关键的组件之一。然而，如何设计高质量的前处理程序（即确定（P1）选择哪些前处理器，（P2）以何种顺序执行，（P3）何时停止）仍然是一个极具挑战性的任务，因为它涉及专家知识的广泛要求和庞大的搜索空间。由于任务具有顺序决策属性和缺乏专家示范，我们提出了一种简单高效的强化学习（RL）框架——即前处理的强化学习（RL4Presolve），以同时解决（P1）-（P3）。具体而言，我们将算法设计任务转化为马尔可夫决策过程，并提出了具有自适应动作序列的RL框架，以生成高质量的前处理程序。",
    "tldr": "本论文提出了一种简单高效的强化学习框架（RL4Presolve），通过将算法设计任务转化为马尔可夫决策过程，同时解决了在大规模线性规划中前处理程序的选择、顺序和停止等问题。"
}