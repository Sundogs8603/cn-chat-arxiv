{
    "title": "STEER: Semantic Turn Extension-Expansion Recognition for Voice Assistants. (arXiv:2310.16990v1 [cs.CL])",
    "abstract": "In the context of a voice assistant system, steering refers to the phenomenon in which a user issues a follow-up command attempting to direct or clarify a previous turn. We propose STEER, a steering detection model that predicts whether a follow-up turn is a user's attempt to steer the previous command. Constructing a training dataset for steering use cases poses challenges due to the cold-start problem. To overcome this, we developed heuristic rules to sample opt-in usage data, approximating positive and negative samples without any annotation. Our experimental results show promising performance in identifying steering intent, with over 95% accuracy on our sampled data. Moreover, STEER, in conjunction with our sampling strategy, aligns effectively with real-world steering scenarios, as evidenced by its strong zero-shot performance on a human-graded evaluation set. In addition to relying solely on user transcripts as input, we introduce STEER+, an enhanced version of the model. STEER+ ",
    "link": "http://arxiv.org/abs/2310.16990",
    "context": "Title: STEER: Semantic Turn Extension-Expansion Recognition for Voice Assistants. (arXiv:2310.16990v1 [cs.CL])\nAbstract: In the context of a voice assistant system, steering refers to the phenomenon in which a user issues a follow-up command attempting to direct or clarify a previous turn. We propose STEER, a steering detection model that predicts whether a follow-up turn is a user's attempt to steer the previous command. Constructing a training dataset for steering use cases poses challenges due to the cold-start problem. To overcome this, we developed heuristic rules to sample opt-in usage data, approximating positive and negative samples without any annotation. Our experimental results show promising performance in identifying steering intent, with over 95% accuracy on our sampled data. Moreover, STEER, in conjunction with our sampling strategy, aligns effectively with real-world steering scenarios, as evidenced by its strong zero-shot performance on a human-graded evaluation set. In addition to relying solely on user transcripts as input, we introduce STEER+, an enhanced version of the model. STEER+ ",
    "path": "papers/23/10/2310.16990.json",
    "total_tokens": 858,
    "translated_title": "STEER: 语义转向扩展识别用于语音助手",
    "translated_abstract": "在语音助手系统的背景下，转向是指用户发出后续命令，试图引导或澄清之前的指令的现象。我们提出了STEER，一个转向检测模型，用于预测后续命令是否是用户企图转向之前指令的尝试。由于冷启动问题，构建用于转向案例的训练数据集带来了挑战。为了克服这个问题，我们开发了启发式规则来采样选择加入使用数据，近似正负样本而无需任何标注。我们的实验结果显示了识别转向意图的良好性能，在我们采样的数据上超过95%的准确率。此外，STEER结合我们的采样策略，在人工评估集上表现出了强大的零样本性能，有效地与真实的转向场景相匹配。除了仅依赖用户的转录作为输入，我们还引入了STEER+，这是模型的增强版本。",
    "tldr": "STEER是一个用于语音助手的语义转向扩展识别模型，通过训练数据集和启发式规则进行转向意图预测，并在实验中展现出了良好的性能。"
}