{
    "title": "Towards Fair and Calibrated Models. (arXiv:2310.10399v1 [cs.LG])",
    "abstract": "Recent literature has seen a significant focus on building machine learning models with specific properties such as fairness, i.e., being non-biased with respect to a given set of attributes, calibration i.e., model confidence being aligned with its predictive accuracy, and explainability, i.e., ability to be understandable to humans. While there has been work focusing on each of these aspects individually, researchers have shied away from simultaneously addressing more than one of these dimensions. In this work, we address the problem of building models which are both fair and calibrated. We work with a specific definition of fairness, which closely matches [Biswas et. al. 2019], and has the nice property that Bayes optimal classifier has the maximum possible fairness under our definition. We show that an existing negative result towards achieving a fair and calibrated model [Kleinberg et. al. 2017] does not hold for our definition of fairness. Further, we show that ensuring group-wis",
    "link": "http://arxiv.org/abs/2310.10399",
    "context": "Title: Towards Fair and Calibrated Models. (arXiv:2310.10399v1 [cs.LG])\nAbstract: Recent literature has seen a significant focus on building machine learning models with specific properties such as fairness, i.e., being non-biased with respect to a given set of attributes, calibration i.e., model confidence being aligned with its predictive accuracy, and explainability, i.e., ability to be understandable to humans. While there has been work focusing on each of these aspects individually, researchers have shied away from simultaneously addressing more than one of these dimensions. In this work, we address the problem of building models which are both fair and calibrated. We work with a specific definition of fairness, which closely matches [Biswas et. al. 2019], and has the nice property that Bayes optimal classifier has the maximum possible fairness under our definition. We show that an existing negative result towards achieving a fair and calibrated model [Kleinberg et. al. 2017] does not hold for our definition of fairness. Further, we show that ensuring group-wis",
    "path": "papers/23/10/2310.10399.json",
    "total_tokens": 879,
    "translated_title": "朝着公平和校准模型的方向",
    "translated_abstract": "最近的文献注重于构建具有特定属性的机器学习模型，如公平性（即对于给定的一组属性，不偏袒任何一方）、校准性（即模型信心与预测准确性一致）、可解释性（即能够被人理解的能力）。虽然已经有关于每个方面的研究工作，但研究人员迄今为止还没有同时解决这些维度中超过一个的问题。在这项工作中，我们解决了构建既公平又校准的模型的问题。我们采用了与[Biswas et. al. 2019]非常接近的公平性定义，并且在我们的定义下，贝叶斯最优分类器具有最大可能的公平性。我们证明了一个现有的关于实现公平和校准模型的负面结果[Kleinberg et. al. 2017]在我们的公平性定义下不成立。此外，我们证明了确保群体智能的方法。",
    "tldr": "该论文研究了构建同时具备公平性和校准性的机器学习模型的问题，并提出了一种与经典定义不同的公平性概念，展示了先前的负面结果在这一新定义下不再成立。"
}