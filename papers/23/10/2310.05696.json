{
    "title": "Protecting Sensitive Data through Federated Co-Training",
    "abstract": "arXiv:2310.05696v2 Announce Type: replace  Abstract: In many applications, sensitive data is inherently distributed and may not be pooled due to privacy concerns. Federated learning allows us to collaboratively train a model without pooling the data by iteratively aggregating the parameters of local models. It is possible, though, to infer upon the sensitive data from the shared model parameters. We propose to use a federated co-training approach where clients share hard labels on a public unlabeled dataset instead of model parameters. A consensus on the shared labels forms a pseudo labeling for the unlabeled dataset that clients use in combination with their private data to train local models. We show that sharing hard labels substantially improves privacy over sharing model parameters. At the same time, federated co-training achieves a model quality comparable to federated learning. Moreover, it allows us to use local models such as (gradient boosted) decision trees, rule ensembles, ",
    "link": "https://arxiv.org/abs/2310.05696",
    "context": "Title: Protecting Sensitive Data through Federated Co-Training\nAbstract: arXiv:2310.05696v2 Announce Type: replace  Abstract: In many applications, sensitive data is inherently distributed and may not be pooled due to privacy concerns. Federated learning allows us to collaboratively train a model without pooling the data by iteratively aggregating the parameters of local models. It is possible, though, to infer upon the sensitive data from the shared model parameters. We propose to use a federated co-training approach where clients share hard labels on a public unlabeled dataset instead of model parameters. A consensus on the shared labels forms a pseudo labeling for the unlabeled dataset that clients use in combination with their private data to train local models. We show that sharing hard labels substantially improves privacy over sharing model parameters. At the same time, federated co-training achieves a model quality comparable to federated learning. Moreover, it allows us to use local models such as (gradient boosted) decision trees, rule ensembles, ",
    "path": "papers/23/10/2310.05696.json",
    "total_tokens": 887,
    "translated_title": "通过联合协同训练保护敏感数据",
    "translated_abstract": "在许多应用中，敏感数据本质上是分布的，由于隐私问题可能无法汇总。联邦学习允许我们通过迭代地聚合本地模型的参数来协作训练模型，而无需合并数据。然而，可以通过共享模型参数推断出敏感数据。我们提出使用联合协同训练方法，在其中客户端分享公共未标记数据集上的硬标签，而不是模型参数。对共享标签的一致性形成了未标记数据集的伪标签，客户端将其与私有数据结合使用来训练本地模型。我们表明，共享硬标签大大提高了与共享模型参数相比的隐私保护。同时，联合协同训练实现了与联邦学习相媲美的模型质量。此外，它使我们能够使用像(梯度提升)决策树、规则集合等本地模型",
    "tldr": "提出了使用联合协同训练方法来保护敏感数据，通过在公共未标记数据集上共享硬标签代替模型参数，形成伪标签以结合私有数据训练本地模型，提高隐私保护效果并获得与联邦学习相媲美的模型质量。",
    "en_tdlr": "Introducing federated co-training approach to protect sensitive data, sharing hard labels on public unlabeled dataset instead of model parameters, forming pseudo labeling for training local models with private data, improving privacy and achieving model quality comparable to federated learning."
}