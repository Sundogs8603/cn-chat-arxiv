{
    "title": "Modality Dropout for Multimodal Device Directed Speech Detection using Verbal and Non-Verbal Features. (arXiv:2310.15261v1 [cs.SD])",
    "abstract": "Device-directed speech detection (DDSD) is the binary classification task of distinguishing between queries directed at a voice assistant versus side conversation or background speech. State-of-the-art DDSD systems use verbal cues, e.g acoustic, text and/or automatic speech recognition system (ASR) features, to classify speech as device-directed or otherwise, and often have to contend with one or more of these modalities being unavailable when deployed in real-world settings. In this paper, we investigate fusion schemes for DDSD systems that can be made more robust to missing modalities. Concurrently, we study the use of non-verbal cues, specifically prosody features, in addition to verbal cues for DDSD. We present different approaches to combine scores and embeddings from prosody with the corresponding verbal cues, finding that prosody improves DDSD performance by upto 8.5% in terms of false acceptance rate (FA) at a given fixed operating point via non-linear intermediate fusion, whil",
    "link": "http://arxiv.org/abs/2310.15261",
    "context": "Title: Modality Dropout for Multimodal Device Directed Speech Detection using Verbal and Non-Verbal Features. (arXiv:2310.15261v1 [cs.SD])\nAbstract: Device-directed speech detection (DDSD) is the binary classification task of distinguishing between queries directed at a voice assistant versus side conversation or background speech. State-of-the-art DDSD systems use verbal cues, e.g acoustic, text and/or automatic speech recognition system (ASR) features, to classify speech as device-directed or otherwise, and often have to contend with one or more of these modalities being unavailable when deployed in real-world settings. In this paper, we investigate fusion schemes for DDSD systems that can be made more robust to missing modalities. Concurrently, we study the use of non-verbal cues, specifically prosody features, in addition to verbal cues for DDSD. We present different approaches to combine scores and embeddings from prosody with the corresponding verbal cues, finding that prosody improves DDSD performance by upto 8.5% in terms of false acceptance rate (FA) at a given fixed operating point via non-linear intermediate fusion, whil",
    "path": "papers/23/10/2310.15261.json",
    "total_tokens": 871,
    "translated_title": "基于多模态特征的语音识别中的模态丢失问题研究",
    "translated_abstract": "设备导向的语音识别（DDSD）是一种将问题区分为针对语音助手的查询和旁白或背景语音的二元分类任务。目前的DDSD系统使用语言线索（如声学特征、文本和/或自动语音识别系统（ASR）特征）来将语音分类为设备导向或其他类型，并在实际情况中往往要处理其中一种或多种模态不可用的情况。本文研究了能够对缺失模态更加稳健的DDSD系统的融合方案。同时，我们研究了在DDSD中将非语言线索（具体是韵律特征）与语言线索结合使用的方法。我们通过非线性中间融合的方式，将韵律特征的分数和嵌入与对应的语言线索结合起来，发现韵律特征可以使DDSD性能在给定固定操作点上的误接受率（FA）提高多达8.5%。",
    "tldr": "本论文研究了在语音识别中处理模态丢失问题的方法，并通过将韵律特征与语言线索结合使用，提高了DDSD性能。",
    "en_tdlr": "This paper investigates methods for handling modality dropout in speech recognition and improves DDSD performance by combining prosody features with verbal cues."
}