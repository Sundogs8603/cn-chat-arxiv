{
    "title": "How well can machine-generated texts be identified and can language models be trained to avoid identification?. (arXiv:2310.16992v1 [cs.CL])",
    "abstract": "With the rise of generative pre-trained transformer models such as GPT-3, GPT-NeoX, or OPT, distinguishing human-generated texts from machine-generated ones has become important. We refined five separate language models to generate synthetic tweets, uncovering that shallow learning classification algorithms, like Naive Bayes, achieve detection accuracy between 0.6 and 0.8.  Shallow learning classifiers differ from human-based detection, especially when using higher temperature values during text generation, resulting in a lower detection rate. Humans prioritize linguistic acceptability, which tends to be higher at lower temperature values. In contrast, transformer-based classifiers have an accuracy of 0.9 and above. We found that using a reinforcement learning approach to refine our generative models can successfully evade BERT-based classifiers with a detection accuracy of 0.15 or less.",
    "link": "http://arxiv.org/abs/2310.16992",
    "context": "Title: How well can machine-generated texts be identified and can language models be trained to avoid identification?. (arXiv:2310.16992v1 [cs.CL])\nAbstract: With the rise of generative pre-trained transformer models such as GPT-3, GPT-NeoX, or OPT, distinguishing human-generated texts from machine-generated ones has become important. We refined five separate language models to generate synthetic tweets, uncovering that shallow learning classification algorithms, like Naive Bayes, achieve detection accuracy between 0.6 and 0.8.  Shallow learning classifiers differ from human-based detection, especially when using higher temperature values during text generation, resulting in a lower detection rate. Humans prioritize linguistic acceptability, which tends to be higher at lower temperature values. In contrast, transformer-based classifiers have an accuracy of 0.9 and above. We found that using a reinforcement learning approach to refine our generative models can successfully evade BERT-based classifiers with a detection accuracy of 0.15 or less.",
    "path": "papers/23/10/2310.16992.json",
    "total_tokens": 928,
    "translated_title": "机器生成的文本能够被多好地识别出来，能够训练语言模型来避免识别吗？",
    "translated_abstract": "随着GPT-3、GPT-NeoX和OPT等生成预训练转换模型的崛起，区分人类生成的文本和机器生成的文本变得很重要。我们对五个不同的语言模型进行了精细调整，生成了合成推文，发现浅层学习分类算法（如朴素贝叶斯）的检测准确率在0.6到0.8之间。当在文本生成过程中使用较高的温度值时，浅层学习分类器与基于人类的检测有所不同，导致较低的检测率。人类更注重语言的可接受性，在较低的温度值下，语言的可接受性往往较高。相反，基于转换器的分类器的准确率在0.9及以上。我们发现使用强化学习方法来改进我们的生成模型可以成功躲避基于BERT的分类器，其检测准确率为0.15或更低。",
    "tldr": "本研究针对机器生成的文本进行了识别，发现在较高温度值下，浅层学习算法的检测准确率较低，而基于转换器的分类器的准确率高。通过强化学习方法改进生成模型，可以成功躲避基于BERT的文本识别。",
    "en_tdlr": "This study focuses on identifying machine-generated texts and found that shallow learning algorithms have lower detection accuracy at higher temperature values, while transformer-based classifiers have higher accuracy. By refining generative models using reinforcement learning, successful evasion of BERT-based text identification is achieved."
}