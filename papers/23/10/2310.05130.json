{
    "title": "Fast-DetectGPT: Efficient Zero-Shot Detection of Machine-Generated Text via Conditional Probability Curvature",
    "abstract": "arXiv:2310.05130v2 Announce Type: replace  Abstract: Large language models (LLMs) have shown the ability to produce fluent and cogent content, presenting both productivity opportunities and societal risks. To build trustworthy AI systems, it is imperative to distinguish between machine-generated and human-authored content. The leading zero-shot detector, DetectGPT, showcases commendable performance but is marred by its intensive computational costs. In this paper, we introduce the concept of conditional probability curvature to elucidate discrepancies in word choices between LLMs and humans within a given context. Utilizing this curvature as a foundational metric, we present **Fast-DetectGPT**, an optimized zero-shot detector, which substitutes DetectGPT's perturbation step with a more efficient sampling step. Our evaluations on various datasets, source models, and test conditions indicate that Fast-DetectGPT not only surpasses DetectGPT by a relative around 75% in both the white-box a",
    "link": "https://arxiv.org/abs/2310.05130",
    "context": "Title: Fast-DetectGPT: Efficient Zero-Shot Detection of Machine-Generated Text via Conditional Probability Curvature\nAbstract: arXiv:2310.05130v2 Announce Type: replace  Abstract: Large language models (LLMs) have shown the ability to produce fluent and cogent content, presenting both productivity opportunities and societal risks. To build trustworthy AI systems, it is imperative to distinguish between machine-generated and human-authored content. The leading zero-shot detector, DetectGPT, showcases commendable performance but is marred by its intensive computational costs. In this paper, we introduce the concept of conditional probability curvature to elucidate discrepancies in word choices between LLMs and humans within a given context. Utilizing this curvature as a foundational metric, we present **Fast-DetectGPT**, an optimized zero-shot detector, which substitutes DetectGPT's perturbation step with a more efficient sampling step. Our evaluations on various datasets, source models, and test conditions indicate that Fast-DetectGPT not only surpasses DetectGPT by a relative around 75% in both the white-box a",
    "path": "papers/23/10/2310.05130.json",
    "total_tokens": 821,
    "translated_title": "Fast-DetectGPT: 通过条件概率曲率实现高效的零样本检测机器生成文本",
    "translated_abstract": "大型语言模型(LLMs)已经展现出产生流畅、连贯内容的能力，提供了生产力机会同时也带来了社会风险。为构建值得信赖的人工智能系统，有必要区分机器生成和人类创作的内容。本文引入条件概率曲率概念，以阐明LLMs和人类在特定上下文中的词汇选择差异。利用该曲率作为基础度量，我们提出**Fast-DetectGPT**，一个优化的零样本检测器，将DetectGPT的扰动步骤替换为更高效的采样步骤。我们在各种数据集、源模型和测试条件上的评估表明，Fast-DetectGPT在白盒和...",
    "tldr": "通过引入条件概率曲率概念，本文提出了Fast-DetectGPT，一个优化的零样本检测器，相对于DetectGPT在白盒和其他测试条件下的性能提升达到约75%。"
}