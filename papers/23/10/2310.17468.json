{
    "title": "Cross-modal Active Complementary Learning with Self-refining Correspondence. (arXiv:2310.17468v1 [cs.CV])",
    "abstract": "Recently, image-text matching has attracted more and more attention from academia and industry, which is fundamental to understanding the latent correspondence across visual and textual modalities. However, most existing methods implicitly assume the training pairs are well-aligned while ignoring the ubiquitous annotation noise, a.k.a noisy correspondence (NC), thereby inevitably leading to a performance drop. Although some methods attempt to address such noise, they still face two challenging problems: excessive memorizing/overfitting and unreliable correction for NC, especially under high noise. To address the two problems, we propose a generalized Cross-modal Robust Complementary Learning framework (CRCL), which benefits from a novel Active Complementary Loss (ACL) and an efficient Self-refining Correspondence Correction (SCC) to improve the robustness of existing methods. Specifically, ACL exploits active and complementary learning losses to reduce the risk of providing erroneous s",
    "link": "http://arxiv.org/abs/2310.17468",
    "context": "Title: Cross-modal Active Complementary Learning with Self-refining Correspondence. (arXiv:2310.17468v1 [cs.CV])\nAbstract: Recently, image-text matching has attracted more and more attention from academia and industry, which is fundamental to understanding the latent correspondence across visual and textual modalities. However, most existing methods implicitly assume the training pairs are well-aligned while ignoring the ubiquitous annotation noise, a.k.a noisy correspondence (NC), thereby inevitably leading to a performance drop. Although some methods attempt to address such noise, they still face two challenging problems: excessive memorizing/overfitting and unreliable correction for NC, especially under high noise. To address the two problems, we propose a generalized Cross-modal Robust Complementary Learning framework (CRCL), which benefits from a novel Active Complementary Loss (ACL) and an efficient Self-refining Correspondence Correction (SCC) to improve the robustness of existing methods. Specifically, ACL exploits active and complementary learning losses to reduce the risk of providing erroneous s",
    "path": "papers/23/10/2310.17468.json",
    "total_tokens": 923,
    "translated_title": "跨模态主动互补学习与自我完善对应关系",
    "translated_abstract": "最近，图像和文本的匹配引起了学术界和工业界越来越多的关注，这是理解视觉和文本模态之间潜在对应关系的基础。然而，大多数现有方法隐式假设训练对是对齐良好的，而忽略了普遍存在的注释噪音，即噪声对应（NC），从而不可避免地导致性能下降。虽然一些方法尝试解决这种噪声，但仍面临两个挑战性问题：过度记忆/过拟合和对于NC的不可靠修正，特别是在高噪声下。为了解决这两个问题，我们提出了一个通用的跨模态鲁棒互补学习框架（CRCL），它通过利用一种新颖的主动互补损失（ACL）和高效的自我完善对应关系修正（SCC）来改进现有方法的鲁棒性。具体而言，ACL利用主动和互补的学习损失来减少提供错误信息的风险。",
    "tldr": "本文提出了一种跨模态主动互补学习框架（CRCL），通过使用新颖的主动互补损失（ACL）和高效的自我完善对应关系修正（SCC），改善了现有方法的鲁棒性。"
}