{
    "title": "Target Variable Engineering. (arXiv:2310.09440v1 [cs.LG])",
    "abstract": "How does the formulation of a target variable affect performance within the ML pipeline? The experiments in this study examine numeric targets that have been binarized by comparing against a threshold. We compare the predictive performance of regression models trained to predict the numeric targets vs. classifiers trained to predict their binarized counterparts. Specifically, we make this comparison at every point of a randomized hyperparameter optimization search to understand the effect of computational resource budget on the tradeoff between the two. We find that regression requires significantly more computational effort to converge upon the optimal performance, and is more sensitive to both randomness and heuristic choices in the training process. Although classification can and does benefit from systematic hyperparameter tuning and model selection, the improvements are much less than for regression. This work comprises the first systematic comparison of regression and classificat",
    "link": "http://arxiv.org/abs/2310.09440",
    "context": "Title: Target Variable Engineering. (arXiv:2310.09440v1 [cs.LG])\nAbstract: How does the formulation of a target variable affect performance within the ML pipeline? The experiments in this study examine numeric targets that have been binarized by comparing against a threshold. We compare the predictive performance of regression models trained to predict the numeric targets vs. classifiers trained to predict their binarized counterparts. Specifically, we make this comparison at every point of a randomized hyperparameter optimization search to understand the effect of computational resource budget on the tradeoff between the two. We find that regression requires significantly more computational effort to converge upon the optimal performance, and is more sensitive to both randomness and heuristic choices in the training process. Although classification can and does benefit from systematic hyperparameter tuning and model selection, the improvements are much less than for regression. This work comprises the first systematic comparison of regression and classificat",
    "path": "papers/23/10/2310.09440.json",
    "total_tokens": 796,
    "translated_title": "目标变量工程",
    "translated_abstract": "目标变量的设计如何影响机器学习流程中的性能？本研究的实验通过将数值目标与阈值进行比较来进行二元化处理。我们比较了针对数值目标进行训练的回归模型与针对其二元化版本进行训练的分类器的预测性能。具体而言，我们在随机超参数优化搜索的每个点上进行比较，以了解计算资源预算对两者之间权衡的影响。我们发现，回归模型需要更多的计算工作才能收敛到最佳性能，并且对训练过程中的随机性和启发式选择更为敏感。虽然分类也可以通过系统化的超参数调整和模型选择进行改进，但改进程度远不及回归。本研究是对回归和分类进行系统比较的第一项工作。",
    "tldr": "本研究通过比较回归和分类的预测性能，发现回归模型需要更多计算工作才能达到最佳性能，并且对训练过程中的随机性和启发式选择更为敏感。",
    "en_tdlr": "This study compares the predictive performance of regression and classification models, finding that regression models require more computational efforts to achieve optimal performance and are more sensitive to randomness and heuristic choices in the training process."
}