{
    "title": "Technical Report for ICCV 2023 Visual Continual Learning Challenge: Continuous Test-time Adaptation for Semantic Segmentation. (arXiv:2310.13533v1 [cs.CV])",
    "abstract": "The goal of the challenge is to develop a test-time adaptation (TTA) method, which could adapt the model to gradually changing domains in video sequences for semantic segmentation task. It is based on a synthetic driving video dataset - SHIFT. The source model is trained on images taken during daytime in clear weather. Domain changes at test-time are mainly caused by varying weather conditions and times of day. The TTA methods are evaluated in each image sequence (video) separately, meaning the model is reset to the source model state before the next sequence. Images come one by one and a prediction has to be made at the arrival of each frame. Each sequence is composed of 401 images and starts with the source domain, then gradually drifts to a different one (changing weather or time of day) until the middle of the sequence. In the second half of the sequence, the domain gradually shifts back to the source one. Ground truth data is available only for the validation split of the SHIFT da",
    "link": "http://arxiv.org/abs/2310.13533",
    "context": "Title: Technical Report for ICCV 2023 Visual Continual Learning Challenge: Continuous Test-time Adaptation for Semantic Segmentation. (arXiv:2310.13533v1 [cs.CV])\nAbstract: The goal of the challenge is to develop a test-time adaptation (TTA) method, which could adapt the model to gradually changing domains in video sequences for semantic segmentation task. It is based on a synthetic driving video dataset - SHIFT. The source model is trained on images taken during daytime in clear weather. Domain changes at test-time are mainly caused by varying weather conditions and times of day. The TTA methods are evaluated in each image sequence (video) separately, meaning the model is reset to the source model state before the next sequence. Images come one by one and a prediction has to be made at the arrival of each frame. Each sequence is composed of 401 images and starts with the source domain, then gradually drifts to a different one (changing weather or time of day) until the middle of the sequence. In the second half of the sequence, the domain gradually shifts back to the source one. Ground truth data is available only for the validation split of the SHIFT da",
    "path": "papers/23/10/2310.13533.json",
    "total_tokens": 939,
    "translated_title": "ICCV 2023视觉连续学习挑战的技术报告：语义分割的连续测试时间适应",
    "translated_abstract": "该挑战的目标是开发一种测试时间适应方法（TTA），该方法能够适应视频序列中逐渐变化的领域，用于语义分割任务。它基于一个合成驾驶视频数据集- SHIFT。源模型是在天气晴朗的白天拍摄的图像上训练的。测试时间的领域变化主要是由于不同的天气条件和不同时段。TTA方法在每个图像序列（视频）中单独评估，意味着在下一个序列之前，模型会被重新置为源模型状态。图像一个接一个地到达，每个帧到达时都需要进行预测。每个序列由401个图像组成，从源领域开始，然后逐渐转变为不同的领域（改变天气或时段），直到序列的中间部分。在序列的后半部分，领域逐渐回归到源领域。只有SHIFT数据集的验证集提供了真实数据。",
    "tldr": "该论文提出了一种连续测试时间适应方法，用于解决语义分割任务中视频序列中逐渐变化的领域问题。该方法在每个图像序列中单独评估，并通过逐渐改变天气条件和时段来测试模型的性能。",
    "en_tdlr": "This paper proposes a method for continuous test-time adaptation in semantic segmentation tasks, addressing the problem of domain changes in video sequences. The method is evaluated in each image sequence separately using varying weather conditions and times of day."
}