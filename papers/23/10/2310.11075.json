{
    "title": "Sim-to-Real Transfer of Adaptive Control Parameters for AUV Stabilization under Current Disturbance. (arXiv:2310.11075v1 [cs.RO])",
    "abstract": "Learning-based adaptive control methods hold the premise of enabling autonomous agents to reduce the effect of process variations with minimal human intervention. However, its application to autonomous underwater vehicles (AUVs) has so far been restricted due to 1) unknown dynamics under the form of sea current disturbance that we can not model properly nor measure due to limited sensor capability and 2) the nonlinearity of AUVs tasks where the controller response at some operating points must be overly conservative in order to satisfy the specification at other operating points. Deep Reinforcement Learning (DRL) can alleviates these limitations by training general-purpose neural network policies, but applications of DRL algorithms to AUVs have been restricted to simulated environments, due to their inherent high sample complexity and distribution shift problem. This paper presents a novel approach, merging the Maximum Entropy Deep Reinforcement Learning framework with a classic model-",
    "link": "http://arxiv.org/abs/2310.11075",
    "context": "Title: Sim-to-Real Transfer of Adaptive Control Parameters for AUV Stabilization under Current Disturbance. (arXiv:2310.11075v1 [cs.RO])\nAbstract: Learning-based adaptive control methods hold the premise of enabling autonomous agents to reduce the effect of process variations with minimal human intervention. However, its application to autonomous underwater vehicles (AUVs) has so far been restricted due to 1) unknown dynamics under the form of sea current disturbance that we can not model properly nor measure due to limited sensor capability and 2) the nonlinearity of AUVs tasks where the controller response at some operating points must be overly conservative in order to satisfy the specification at other operating points. Deep Reinforcement Learning (DRL) can alleviates these limitations by training general-purpose neural network policies, but applications of DRL algorithms to AUVs have been restricted to simulated environments, due to their inherent high sample complexity and distribution shift problem. This paper presents a novel approach, merging the Maximum Entropy Deep Reinforcement Learning framework with a classic model-",
    "path": "papers/23/10/2310.11075.json",
    "total_tokens": 863,
    "translated_title": "自适应控制参数在海流扰动下实现AUV稳定性的模拟到真实场景迁移",
    "translated_abstract": "基于学习的自适应控制方法可以在最小人为干预的情况下减少过程变化对自主代理的影响。然而，由于海流扰动的未知动力学无法准确建模或测量，并且AUV的非线性任务要求在某些工作点上的控制器响应必须过分保守，以满足其他工作点上的规范，因此其在AUV中的应用受到限制。深度强化学习(DRL)可以通过训练通用的神经网络策略来缓解这些限制，但由于其高样本复杂度和分布转移问题，DRL算法在AUV中的应用目前仅限于仿真环境。本文提出了一种新的方法，将最大熵深度强化学习框架与经典的模型进行融合。",
    "tldr": "本文介绍了一种新的方法，将最大熵深度强化学习框架与经典模型融合，实现了自适应控制参数在海流扰动下AUV稳定性的模拟到真实场景迁移。"
}