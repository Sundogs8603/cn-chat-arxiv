{
    "title": "Exploring the Potential of Large Language Models in Generating Code-Tracing Questions for Introductory Programming Courses. (arXiv:2310.15317v1 [cs.CL])",
    "abstract": "In this paper, we explore the application of large language models (LLMs) for generating code-tracing questions in introductory programming courses. We designed targeted prompts for GPT4, guiding it to generate code-tracing questions based on code snippets and descriptions. We established a set of human evaluation metrics to assess the quality of questions produced by the model compared to those created by human experts. Our analysis provides insights into the capabilities and potential of LLMs in generating diverse code-tracing questions. Additionally, we present a unique dataset of human and LLM-generated tracing questions, serving as a valuable resource for both the education and NLP research communities. This work contributes to the ongoing dialogue on the potential uses of LLMs in educational settings.",
    "link": "http://arxiv.org/abs/2310.15317",
    "context": "Title: Exploring the Potential of Large Language Models in Generating Code-Tracing Questions for Introductory Programming Courses. (arXiv:2310.15317v1 [cs.CL])\nAbstract: In this paper, we explore the application of large language models (LLMs) for generating code-tracing questions in introductory programming courses. We designed targeted prompts for GPT4, guiding it to generate code-tracing questions based on code snippets and descriptions. We established a set of human evaluation metrics to assess the quality of questions produced by the model compared to those created by human experts. Our analysis provides insights into the capabilities and potential of LLMs in generating diverse code-tracing questions. Additionally, we present a unique dataset of human and LLM-generated tracing questions, serving as a valuable resource for both the education and NLP research communities. This work contributes to the ongoing dialogue on the potential uses of LLMs in educational settings.",
    "path": "papers/23/10/2310.15317.json",
    "total_tokens": 843,
    "translated_title": "探索大型语言模型在生成入门编程课程中的代码追踪问题中的潜力",
    "translated_abstract": "本文研究了在入门编程课程中应用大型语言模型（LLMs）生成代码追踪问题的应用。我们针对GPT4设计了目标提示，引导其基于代码片段和描述生成代码追踪问题。我们建立了一组人工评估指标，以评估模型生成的问题与人类专家创建的问题的质量。我们的分析提供了关于LLMs在生成多样化代码追踪问题方面的能力和潜力的见解。此外，我们还提供了一个独特的人工和LLM生成的追踪问题数据集，为教育和自然语言处理研究界提供了宝贵的资源。这项工作对于对LLMs在教育环境中潜在用途的持续对话作出了贡献。",
    "tldr": "本文探索了在入门编程课程中应用大型语言模型生成多样化的代码追踪问题，并提供了评估模型质量的人工评估指标和宝贵的数据集，为教育和自然语言处理研究提供了重要资源。"
}