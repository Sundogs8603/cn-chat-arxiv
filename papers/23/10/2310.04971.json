{
    "title": "Understanding the Robustness of Multi-modal Contrastive Learning to Distribution Shift",
    "abstract": "arXiv:2310.04971v2 Announce Type: replace  Abstract: Recently, multimodal contrastive learning (MMCL) approaches, such as CLIP, have achieved a remarkable success in learning representations that are robust against distribution shift and generalize to new domains. Despite the empirical success, the mechanism behind learning such generalizable representations is not understood. In this work, we rigorously analyze this problem and uncover two mechanisms behind MMCL's robustness: \\emph{intra-class contrasting}, which allows the model to learn features with a high variance, and \\emph{inter-class feature sharing}, where annotated details in one class help learning other classes better. Both mechanisms prevent spurious features that are over-represented in the training data to overshadow the generalizable core features. This yields superior zero-shot classification accuracy under distribution shift. Furthermore, we theoretically demonstrate the benefits of using rich captions on robustness a",
    "link": "https://arxiv.org/abs/2310.04971",
    "context": "Title: Understanding the Robustness of Multi-modal Contrastive Learning to Distribution Shift\nAbstract: arXiv:2310.04971v2 Announce Type: replace  Abstract: Recently, multimodal contrastive learning (MMCL) approaches, such as CLIP, have achieved a remarkable success in learning representations that are robust against distribution shift and generalize to new domains. Despite the empirical success, the mechanism behind learning such generalizable representations is not understood. In this work, we rigorously analyze this problem and uncover two mechanisms behind MMCL's robustness: \\emph{intra-class contrasting}, which allows the model to learn features with a high variance, and \\emph{inter-class feature sharing}, where annotated details in one class help learning other classes better. Both mechanisms prevent spurious features that are over-represented in the training data to overshadow the generalizable core features. This yields superior zero-shot classification accuracy under distribution shift. Furthermore, we theoretically demonstrate the benefits of using rich captions on robustness a",
    "path": "papers/23/10/2310.04971.json",
    "total_tokens": 920,
    "translated_title": "理解多模态对比学习对分布转移的鲁棒性",
    "translated_abstract": "最近，诸如CLIP之类的多模态对比学习（MMCL）方法在学习对抗分布转移且推广到新领域的表示方面取得了显著成功。尽管在实证方面取得了成功，但学习这种具有泛化性的表示背后的机理尚不清楚。在这项工作中，我们对这一问题进行了严格分析，并发现MMCL鲁棒性背后的两种机制：\\emph{类内对比}，使模型能够学习具有高方差的特征；\\emph{类间特征共享}，其中一个类别中的注释细节有助于更好地学习其他类别。这两种机制防止了训练数据中过度表示的虚假特征掩盖泛化性核心特征。在分布转移下，这产生了更优秀的零样本分类准确度。此外，我们从理论上证明了在鲁棒性方面使用丰富字幕的好处。",
    "tldr": "本研究发现多模态对比学习对抗分布转移具有鲁棒性的两种机制，即类内对比和类间特征共享，这有助于防止训练数据中的虚假特征干扰核心特征，从而在零样本分类准确度方面表现优越。",
    "en_tdlr": "This study identifies two mechanisms, intra-class contrasting and inter-class feature sharing, behind the robustness of multi-modal contrastive learning against distribution shift, which help prevent spurious features from overshadowing core features in the training data and lead to superior zero-shot classification accuracy."
}