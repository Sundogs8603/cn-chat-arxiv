{
    "title": "CycleNet: Rethinking Cycle Consistency in Text-Guided Diffusion for Image Manipulation. (arXiv:2310.13165v1 [cs.CV])",
    "abstract": "Diffusion models (DMs) have enabled breakthroughs in image synthesis tasks but lack an intuitive interface for consistent image-to-image (I2I) translation. Various methods have been explored to address this issue, including mask-based methods, attention-based methods, and image-conditioning. However, it remains a critical challenge to enable unpaired I2I translation with pre-trained DMs while maintaining satisfying consistency. This paper introduces Cyclenet, a novel but simple method that incorporates cycle consistency into DMs to regularize image manipulation. We validate Cyclenet on unpaired I2I tasks of different granularities. Besides the scene and object level translation, we additionally contribute a multi-domain I2I translation dataset to study the physical state changes of objects. Our empirical studies show that Cyclenet is superior in translation consistency and quality, and can generate high-quality images for out-of-domain distributions with a simple change of the textual ",
    "link": "http://arxiv.org/abs/2310.13165",
    "context": "Title: CycleNet: Rethinking Cycle Consistency in Text-Guided Diffusion for Image Manipulation. (arXiv:2310.13165v1 [cs.CV])\nAbstract: Diffusion models (DMs) have enabled breakthroughs in image synthesis tasks but lack an intuitive interface for consistent image-to-image (I2I) translation. Various methods have been explored to address this issue, including mask-based methods, attention-based methods, and image-conditioning. However, it remains a critical challenge to enable unpaired I2I translation with pre-trained DMs while maintaining satisfying consistency. This paper introduces Cyclenet, a novel but simple method that incorporates cycle consistency into DMs to regularize image manipulation. We validate Cyclenet on unpaired I2I tasks of different granularities. Besides the scene and object level translation, we additionally contribute a multi-domain I2I translation dataset to study the physical state changes of objects. Our empirical studies show that Cyclenet is superior in translation consistency and quality, and can generate high-quality images for out-of-domain distributions with a simple change of the textual ",
    "path": "papers/23/10/2310.13165.json",
    "total_tokens": 936,
    "translated_title": "CycleNet：重新思考文本引导扩散中的循环一致性，以进行图像操作",
    "translated_abstract": "扩散模型（DM）在图像合成任务中取得了突破，但缺乏一种直观的一致图像到图像（I2I）翻译接口。为解决这个问题，已经探索了各种方法，包括基于掩码的方法，基于注意力的方法和基于图像的方法。然而，如何使用预训练的DMs进行无配对的I2I翻译并保持一致性仍然是一个关键挑战。本文介绍了Cyclenet，一种新颖但简单的方法，它将循环一致性纳入DMs中，以规范图像操作。我们验证了Cyclenet在不同粒度的无配对I2I任务上的优势。除了场景和对象级别的翻译，我们还贡献了一个多领域I2I翻译数据集，用于研究物体的物理状态变化。我们的实证研究表明，Cyclenet在翻译的一致性和质量方面具有优势，并且在改变文本描述时可以生成高质量的跨领域分布图像。",
    "tldr": "CycleNet是一种将循环一致性引入扩散模型的新方法，用于规范图像操作，具有优越的翻译一致性和质量，并且可以生成高质量的跨领域分布图像。",
    "en_tdlr": "CycleNet is a novel method that incorporates cycle consistency into diffusion models to regulate image manipulation. It demonstrates superior translation consistency and quality, and is capable of generating high-quality images for out-of-domain distributions."
}