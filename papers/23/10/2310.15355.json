{
    "title": "Why LLMs Hallucinate, and How to Get (Evidential) Closure: Perceptual, Intensional, and Extensional Learning for Faithful Natural Language Generation. (arXiv:2310.15355v1 [cs.CL])",
    "abstract": "We show that LLMs hallucinate because their output is not constrained to be synonymous with claims for which they have evidence: a condition that we call evidential closure. Information about the truth or falsity of sentences is not statistically identified in the standard neural probabilistic language model setup, and so cannot be conditioned on to generate new strings. We then show how to constrain LLMs to produce output that does satisfy evidential closure. A multimodal LLM must learn about the external world (perceptual learning); it must learn a mapping from strings to states of the world (extensional learning); and, to achieve fluency when generalizing beyond a body of evidence, it must learn mappings from strings to their synonyms (intensional learning). The output of a unimodal LLM must be synonymous with strings in a validated evidence set. Finally, we present a heuristic procedure, Learn-Babble-Prune, that yields faithful output from an LLM by rejecting output that is not syn",
    "link": "http://arxiv.org/abs/2310.15355",
    "context": "Title: Why LLMs Hallucinate, and How to Get (Evidential) Closure: Perceptual, Intensional, and Extensional Learning for Faithful Natural Language Generation. (arXiv:2310.15355v1 [cs.CL])\nAbstract: We show that LLMs hallucinate because their output is not constrained to be synonymous with claims for which they have evidence: a condition that we call evidential closure. Information about the truth or falsity of sentences is not statistically identified in the standard neural probabilistic language model setup, and so cannot be conditioned on to generate new strings. We then show how to constrain LLMs to produce output that does satisfy evidential closure. A multimodal LLM must learn about the external world (perceptual learning); it must learn a mapping from strings to states of the world (extensional learning); and, to achieve fluency when generalizing beyond a body of evidence, it must learn mappings from strings to their synonyms (intensional learning). The output of a unimodal LLM must be synonymous with strings in a validated evidence set. Finally, we present a heuristic procedure, Learn-Babble-Prune, that yields faithful output from an LLM by rejecting output that is not syn",
    "path": "papers/23/10/2310.15355.json",
    "total_tokens": 1004,
    "translated_title": "为什么LLM会产生幻觉，以及如何获得（证据性的）闭合性：用于忠实自然语言生成的感知、内涵和外延学习",
    "translated_abstract": "我们展示了LLMs为什么会产生幻觉，因为它们的输出没有受到具备证据支持的主张的约束，这种条件被称为证据闭合。在标准的神经概率语言模型设置中，并不能从统计上辨别出关于句子真伪的信息，因此不能以此为条件生成新的字符串。然后我们展示了如何约束LLMs以产生满足证据闭合性的输出。多模态LLM必须学习外部世界（感知学习）；它必须学习从字符串到世界状态的映射（外延学习）；并且，为了在超越一组证据时实现流畅性，它必须学习从字符串到它们的同义词的映射（内涵学习）。一种单模态LLM的输出必须与验证的证据集中的字符串意义相同。最后，我们提供了一个启发式过程——学习-胡言乱语-修剪（Learn-Babble-Prune），通过拒绝不同义的输出，从LLM中产生忠实的输出。",
    "tldr": "本研究展示了LLMs产生幻觉的原因是因为它们的输出没有受到证据支持的主张的约束，并介绍了如何通过感知、内涵和外延学习来约束LLMs以生成满足证据闭合性的输出。"
}