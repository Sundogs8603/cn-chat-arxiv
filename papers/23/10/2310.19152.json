{
    "title": "BERT Lost Patience Won't Be Robust to Adversarial Slowdown. (arXiv:2310.19152v2 [cs.LG] UPDATED)",
    "abstract": "In this paper, we systematically evaluate the robustness of multi-exit language models against adversarial slowdown. To audit their robustness, we design a slowdown attack that generates natural adversarial text bypassing early-exit points. We use the resulting WAFFLE attack as a vehicle to conduct a comprehensive evaluation of three multi-exit mechanisms with the GLUE benchmark against adversarial slowdown. We then show our attack significantly reduces the computational savings provided by the three methods in both white-box and black-box settings. The more complex a mechanism is, the more vulnerable it is to adversarial slowdown. We also perform a linguistic analysis of the perturbed text inputs, identifying common perturbation patterns that our attack generates, and comparing them with standard adversarial text attacks. Moreover, we show that adversarial training is ineffective in defeating our slowdown attack, but input sanitization with a conversational model, e.g., ChatGPT, can r",
    "link": "http://arxiv.org/abs/2310.19152",
    "context": "Title: BERT Lost Patience Won't Be Robust to Adversarial Slowdown. (arXiv:2310.19152v2 [cs.LG] UPDATED)\nAbstract: In this paper, we systematically evaluate the robustness of multi-exit language models against adversarial slowdown. To audit their robustness, we design a slowdown attack that generates natural adversarial text bypassing early-exit points. We use the resulting WAFFLE attack as a vehicle to conduct a comprehensive evaluation of three multi-exit mechanisms with the GLUE benchmark against adversarial slowdown. We then show our attack significantly reduces the computational savings provided by the three methods in both white-box and black-box settings. The more complex a mechanism is, the more vulnerable it is to adversarial slowdown. We also perform a linguistic analysis of the perturbed text inputs, identifying common perturbation patterns that our attack generates, and comparing them with standard adversarial text attacks. Moreover, we show that adversarial training is ineffective in defeating our slowdown attack, but input sanitization with a conversational model, e.g., ChatGPT, can r",
    "path": "papers/23/10/2310.19152.json",
    "total_tokens": 905,
    "translated_title": "BERT失去耐心对抗恶意减速不能保持稳健性",
    "translated_abstract": "本文系统评估多出口语言模型对抗恶意减速的稳健性。为了审核其稳健性，我们设计了一种减速攻击，生成绕过早期退出点的自然恶意文本。我们使用所得到的WAFFLE攻击作为工具，对三种多出口机制在GLUE基准测试中对抗恶意减速进行全面评估。然后，我们展示了我们的攻击显著降低了这三种方法在白盒和黑盒设置下提供的计算节省效果。机制越复杂，越容易受到恶意减速的攻击。我们还对扰动的文本输入进行了语言分析，识别出我们的攻击生成的常见扰动模式，并将其与标准的恶意文本攻击进行了比较。此外，我们证明对抗训练在打败我们的减速攻击方面是无效的，但使用对话模型（如ChatGPT）进行输入清洗是有效的。",
    "tldr": "本文评估了多出口语言模型对抗恶意减速的稳健性, 发现复杂的机制更易受到恶意减速的攻击。此外，对抗训练无效，但对话模型的输入清洗是有效的。"
}