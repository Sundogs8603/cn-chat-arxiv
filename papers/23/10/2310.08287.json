{
    "title": "A Symmetry-Aware Exploration of Bayesian Neural Network Posteriors. (arXiv:2310.08287v1 [stat.ML])",
    "abstract": "The distribution of the weights of modern deep neural networks (DNNs) crucial for uncertainty quantification and robustness - is an eminently complex object due to its extremely high dimensionality. This paper proposes one of the first large-scale explorations of the posterior distribution of deep Bayesian Neural Networks (BNNs), expanding its study to real-world vision tasks and architectures. Specifically, we investigate the optimal approach for approximating the posterior, analyze the connection between posterior quality and uncertainty quantification, delve into the impact of modes on the posterior, and explore methods for visualizing the posterior. Moreover, we uncover weight-space symmetries as a critical aspect for understanding the posterior. To this extent, we develop an in-depth assessment of the impact of both permutation and scaling symmetries that tend to obfuscate the Bayesian posterior. While the first type of transformation is known for duplicating modes, we explore t",
    "link": "http://arxiv.org/abs/2310.08287",
    "context": "Title: A Symmetry-Aware Exploration of Bayesian Neural Network Posteriors. (arXiv:2310.08287v1 [stat.ML])\nAbstract: The distribution of the weights of modern deep neural networks (DNNs) crucial for uncertainty quantification and robustness - is an eminently complex object due to its extremely high dimensionality. This paper proposes one of the first large-scale explorations of the posterior distribution of deep Bayesian Neural Networks (BNNs), expanding its study to real-world vision tasks and architectures. Specifically, we investigate the optimal approach for approximating the posterior, analyze the connection between posterior quality and uncertainty quantification, delve into the impact of modes on the posterior, and explore methods for visualizing the posterior. Moreover, we uncover weight-space symmetries as a critical aspect for understanding the posterior. To this extent, we develop an in-depth assessment of the impact of both permutation and scaling symmetries that tend to obfuscate the Bayesian posterior. While the first type of transformation is known for duplicating modes, we explore t",
    "path": "papers/23/10/2310.08287.json",
    "total_tokens": 901,
    "translated_title": "对贝叶斯神经网络后验的对称感知探索",
    "translated_abstract": "现代深度神经网络(DNNs)的权重分布对不确定性量化和鲁棒性非常重要，由于其极高的维度，其本质非常复杂。本文提出了对深度贝叶斯神经网络(BNNs)后验分布的首次大规模探索，将其研究扩展到现实世界的视觉任务和架构。具体而言，我们研究了逼近后验的最佳方法，分析了后验质量和不确定性量化之间的关系，深入研究了后验中模式的影响，并探索了可视化后验的方法。此外，我们发现权重空间的对称性是理解后验的关键方面。为此，我们对置换和缩放对称性的影响进行了深入评估，这些对称性往往会使贝叶斯后验变得模糊。尽管第一种变换已知会复制模式，但我们还是对其进行了探索。",
    "tldr": "本文对贝叶斯神经网络后验进行了大规模探索，研究了逼近后验的最佳方法和后验质量与不确定性量化的关系，同时发现了权重空间对称性对后验的影响。",
    "en_tdlr": "This paper conducts a large-scale exploration of the posterior distribution of Bayesian Neural Networks (BNNs), investigating the optimal approach for approximating the posterior and the connection between posterior quality and uncertainty quantification. The study also highlights the importance of weight-space symmetries in understanding the posterior."
}