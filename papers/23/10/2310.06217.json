{
    "title": "Federated Multi-Level Optimization over Decentralized Networks. (arXiv:2310.06217v1 [cs.LG])",
    "abstract": "Multi-level optimization has gained increasing attention in recent years, as it provides a powerful framework for solving complex optimization problems that arise in many fields, such as meta-learning, multi-player games, reinforcement learning, and nested composition optimization. In this paper, we study the problem of distributed multi-level optimization over a network, where agents can only communicate with their immediate neighbors. This setting is motivated by the need for distributed optimization in large-scale systems, where centralized optimization may not be practical or feasible. To address this problem, we propose a novel gossip-based distributed multi-level optimization algorithm that enables networked agents to solve optimization problems at different levels in a single timescale and share information through network propagation. Our algorithm achieves optimal sample complexity, scaling linearly with the network size, and demonstrates state-of-the-art performance on variou",
    "link": "http://arxiv.org/abs/2310.06217",
    "context": "Title: Federated Multi-Level Optimization over Decentralized Networks. (arXiv:2310.06217v1 [cs.LG])\nAbstract: Multi-level optimization has gained increasing attention in recent years, as it provides a powerful framework for solving complex optimization problems that arise in many fields, such as meta-learning, multi-player games, reinforcement learning, and nested composition optimization. In this paper, we study the problem of distributed multi-level optimization over a network, where agents can only communicate with their immediate neighbors. This setting is motivated by the need for distributed optimization in large-scale systems, where centralized optimization may not be practical or feasible. To address this problem, we propose a novel gossip-based distributed multi-level optimization algorithm that enables networked agents to solve optimization problems at different levels in a single timescale and share information through network propagation. Our algorithm achieves optimal sample complexity, scaling linearly with the network size, and demonstrates state-of-the-art performance on variou",
    "path": "papers/23/10/2310.06217.json",
    "total_tokens": 824,
    "translated_title": "分布式网络上的联合多级优化",
    "translated_abstract": "近年来，多级优化受到越来越多的关注，因为它为解决许多领域中出现的复杂优化问题（如元学习、多人游戏、强化学习和嵌套组合优化）提供了强大的框架。本文研究了在网络上的分布式多级优化问题，其中代理只能与它们的直接邻居进行通信。这个设置是由大规模系统中分布式优化的需求所驱动的，其中集中优化可能不切实际或不可行。为了解决这个问题，我们提出了一种基于流言的分布式多级优化算法，使网络代理可以在单个时间尺度内解决不同层次的优化问题，并通过网络传播共享信息。我们的算法实现了最优的样本复杂度，与网络规模线性增长，并在各种应用场景上展现了最先进的性能。",
    "tldr": "本文研究了在网络上的分布式多级优化问题，提出了一种基于流言的分布式多级优化算法，实现了最优的样本复杂度，并在各种应用场景上展现了最先进的性能。",
    "en_tdlr": "This paper investigates the problem of distributed multi-level optimization over a network and proposes a novel gossip-based algorithm that achieves optimal sample complexity and demonstrates state-of-the-art performance on various applications."
}