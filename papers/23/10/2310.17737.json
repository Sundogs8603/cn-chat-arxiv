{
    "title": "ArchBERT: Bi-Modal Understanding of Neural Architectures and Natural Languages. (arXiv:2310.17737v1 [cs.CL])",
    "abstract": "Building multi-modal language models has been a trend in the recent years, where additional modalities such as image, video, speech, etc. are jointly learned along with natural languages (i.e., textual information). Despite the success of these multi-modal language models with different modalities, there is no existing solution for neural network architectures and natural languages. Providing neural architectural information as a new modality allows us to provide fast architecture-2-text and text-2-architecture retrieval/generation services on the cloud with a single inference. Such solution is valuable in terms of helping beginner and intermediate ML users to come up with better neural architectures or AutoML approaches with a simple text query. In this paper, we propose ArchBERT, a bi-modal model for joint learning and understanding of neural architectures and natural languages, which opens up new avenues for research in this area. We also introduce a pre-training strategy named Mask",
    "link": "http://arxiv.org/abs/2310.17737",
    "context": "Title: ArchBERT: Bi-Modal Understanding of Neural Architectures and Natural Languages. (arXiv:2310.17737v1 [cs.CL])\nAbstract: Building multi-modal language models has been a trend in the recent years, where additional modalities such as image, video, speech, etc. are jointly learned along with natural languages (i.e., textual information). Despite the success of these multi-modal language models with different modalities, there is no existing solution for neural network architectures and natural languages. Providing neural architectural information as a new modality allows us to provide fast architecture-2-text and text-2-architecture retrieval/generation services on the cloud with a single inference. Such solution is valuable in terms of helping beginner and intermediate ML users to come up with better neural architectures or AutoML approaches with a simple text query. In this paper, we propose ArchBERT, a bi-modal model for joint learning and understanding of neural architectures and natural languages, which opens up new avenues for research in this area. We also introduce a pre-training strategy named Mask",
    "path": "papers/23/10/2310.17737.json",
    "total_tokens": 894,
    "translated_title": "ArchBERT: 神经结构和自然语言的双模态理解",
    "translated_abstract": "近年来，建立多模态语言模型已经成为一个趋势，额外的模态，如图像、视频、语音等与自然语言（即文本信息）一起进行联合学习。虽然这些多模态语言模型在不同的模态上取得了成功，但是关于神经网络结构和自然语言的解决方案还不存在。将神经结构信息作为一种新的模态可以在云端提供快速的结构-文本和文本-结构检索/生成服务，且仅需单次推理。这样的解决方案在帮助初学者和中级机器学习用户提出更好的神经架构或自动机器学习方法方面具有价值，只需使用简单的文本查询。在本文中，我们提出了一种名为ArchBERT的双模态模型，用于联合学习和理解神经结构和自然语言，为这个领域的研究开辟了新的研究方向。此外，我们还介绍了一种名为Mask的预训练策略。",
    "tldr": "ArchBERT是一种双模态模型，可以联合学习和理解神经结构和自然语言，为神经架构和自动机器学习方法提供快速的结构-文本和文本-结构检索/生成服务。"
}