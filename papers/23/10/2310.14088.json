{
    "title": "MedEval: A Multi-Level, Multi-Task, and Multi-Domain Medical Benchmark for Language Model Evaluation. (arXiv:2310.14088v2 [cs.CL] UPDATED)",
    "abstract": "Curated datasets for healthcare are often limited due to the need of human annotations from experts. In this paper, we present MedEval, a multi-level, multi-task, and multi-domain medical benchmark to facilitate the development of language models for healthcare. MedEval is comprehensive and consists of data from several healthcare systems and spans 35 human body regions from 8 examination modalities. With 22,779 collected sentences and 21,228 reports, we provide expert annotations at multiple levels, offering a granular potential usage of the data and supporting a wide range of tasks. Moreover, we systematically evaluated 10 generic and domain-specific language models under zero-shot and finetuning settings, from domain-adapted baselines in healthcare to general-purposed state-of-the-art large language models (e.g., ChatGPT). Our evaluations reveal varying effectiveness of the two categories of language models across different tasks, from which we notice the importance of instruction t",
    "link": "http://arxiv.org/abs/2310.14088",
    "context": "Title: MedEval: A Multi-Level, Multi-Task, and Multi-Domain Medical Benchmark for Language Model Evaluation. (arXiv:2310.14088v2 [cs.CL] UPDATED)\nAbstract: Curated datasets for healthcare are often limited due to the need of human annotations from experts. In this paper, we present MedEval, a multi-level, multi-task, and multi-domain medical benchmark to facilitate the development of language models for healthcare. MedEval is comprehensive and consists of data from several healthcare systems and spans 35 human body regions from 8 examination modalities. With 22,779 collected sentences and 21,228 reports, we provide expert annotations at multiple levels, offering a granular potential usage of the data and supporting a wide range of tasks. Moreover, we systematically evaluated 10 generic and domain-specific language models under zero-shot and finetuning settings, from domain-adapted baselines in healthcare to general-purposed state-of-the-art large language models (e.g., ChatGPT). Our evaluations reveal varying effectiveness of the two categories of language models across different tasks, from which we notice the importance of instruction t",
    "path": "papers/23/10/2310.14088.json",
    "total_tokens": 997,
    "translated_title": "MedEval: 一个多层次、多任务和多领域的医学语言模型评估基准",
    "translated_abstract": "由于需要专家的人工注释，医疗保健的筛选数据集往往有限。本文提出了MedEval，一个多层次、多任务和多领域的医学基准，以促进医疗保健语言模型的开发。MedEval是全面的，包含来自几个医疗系统的数据，涵盖了8种检查模式下的35个人体区域。我们收集了22,779个句子和21,228份报告，并在多个层次上提供了专家注释，为数据提供了细致的潜在用法，并支持广泛的任务范围。此外，我们在零-shot和微调设置下对10个通用和领域特定的语言模型进行了系统评估，从医疗保健中的领域适应基线到通用的最先进的大型语言模型（如ChatGPT）。我们的评估揭示了两种类别的语言模型在不同任务中的不同有效性，从中我们注意到了指导的重要性。",
    "tldr": "MedEval是一个多层次、多任务和多领域的医学基准，用于促进医疗保健语言模型的开发。它包含了来自多个医疗系统的数据，涵盖了多个人体区域和检查模式。我们针对10个语言模型进行了评估，发现不同模型在不同任务上的有效性各有差异，从中我们注意到了指导的重要性。",
    "en_tdlr": "MedEval is a multi-level, multi-task, and multi-domain medical benchmark that facilitates the development of language models for healthcare. It includes data from multiple healthcare systems, covering various human body regions and examination modalities. Evaluations of 10 language models show varying effectiveness across different tasks, highlighting the importance of guidance."
}