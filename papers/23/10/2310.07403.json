{
    "title": "DASpeech: Directed Acyclic Transformer for Fast and High-quality Speech-to-Speech Translation. (arXiv:2310.07403v1 [cs.CL])",
    "abstract": "Direct speech-to-speech translation (S2ST) translates speech from one language into another using a single model. However, due to the presence of linguistic and acoustic diversity, the target speech follows a complex multimodal distribution, posing challenges to achieving both high-quality translations and fast decoding speeds for S2ST models. In this paper, we propose DASpeech, a non-autoregressive direct S2ST model which realizes both fast and high-quality S2ST. To better capture the complex distribution of the target speech, DASpeech adopts the two-pass architecture to decompose the generation process into two steps, where a linguistic decoder first generates the target text, and an acoustic decoder then generates the target speech based on the hidden states of the linguistic decoder. Specifically, we use the decoder of DA-Transformer as the linguistic decoder, and use FastSpeech 2 as the acoustic decoder. DA-Transformer models translations with a directed acyclic graph (DAG). To co",
    "link": "http://arxiv.org/abs/2310.07403",
    "context": "Title: DASpeech: Directed Acyclic Transformer for Fast and High-quality Speech-to-Speech Translation. (arXiv:2310.07403v1 [cs.CL])\nAbstract: Direct speech-to-speech translation (S2ST) translates speech from one language into another using a single model. However, due to the presence of linguistic and acoustic diversity, the target speech follows a complex multimodal distribution, posing challenges to achieving both high-quality translations and fast decoding speeds for S2ST models. In this paper, we propose DASpeech, a non-autoregressive direct S2ST model which realizes both fast and high-quality S2ST. To better capture the complex distribution of the target speech, DASpeech adopts the two-pass architecture to decompose the generation process into two steps, where a linguistic decoder first generates the target text, and an acoustic decoder then generates the target speech based on the hidden states of the linguistic decoder. Specifically, we use the decoder of DA-Transformer as the linguistic decoder, and use FastSpeech 2 as the acoustic decoder. DA-Transformer models translations with a directed acyclic graph (DAG). To co",
    "path": "papers/23/10/2310.07403.json",
    "total_tokens": 865,
    "translated_title": "DASpeech：用于快速高质量语音翻译的有向无环变换器",
    "translated_abstract": "直接语音翻译（S2ST）使用单个模型将一种语言的语音翻译成另一种语言。然而，由于存在语言和声学多样性，目标语音遵循一个复杂的多模态分布，给S2ST模型实现高质量翻译和快速解码速度带来挑战。在本文中，我们提出了DASpeech，这是一个非自回归的直接S2ST模型，实现了快速和高质量的S2ST。为了更好地捕捉目标语音的复杂分布，DASpeech采用了两步解码的架构，先由语言解码器生成目标文本，然后由声学解码器根据语言解码器的隐藏状态生成目标语音。具体而言，我们将DA-Transformer的解码器作为语言解码器，将FastSpeech 2作为声学解码器。DA-Transformer使用有向无环图（DAG）模拟翻译过程。",
    "tldr": "DASpeech是一个非自回归的直接语音翻译模型，使用有向无环图（DAG）来实现快速和高质量的语音翻译。",
    "en_tdlr": "DASpeech is a non-autoregressive direct speech-to-speech translation model that uses directed acyclic graph (DAG) to achieve fast and high-quality speech translation."
}