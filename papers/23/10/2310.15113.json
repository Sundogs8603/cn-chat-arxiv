{
    "title": "Counting the Bugs in ChatGPT's Wugs: A Multilingual Investigation into the Morphological Capabilities of a Large Language Model. (arXiv:2310.15113v2 [cs.CL] UPDATED)",
    "abstract": "Large language models (LLMs) have recently reached an impressive level of linguistic capability, prompting comparisons with human language skills. However, there have been relatively few systematic inquiries into the linguistic capabilities of the latest generation of LLMs, and those studies that do exist (i) ignore the remarkable ability of humans to generalize, (ii) focus only on English, and (iii) investigate syntax or semantics and overlook other capabilities that lie at the heart of human language, like morphology. Here, we close these gaps by conducting the first rigorous analysis of the morphological capabilities of ChatGPT in four typologically varied languages (specifically, English, German, Tamil, and Turkish). We apply a version of Berko's (1958) wug test to ChatGPT, using novel, uncontaminated datasets for the four examined languages. We find that ChatGPT massively underperforms purpose-built systems, particularly in English. Overall, our results -- through the lens of morp",
    "link": "http://arxiv.org/abs/2310.15113",
    "context": "Title: Counting the Bugs in ChatGPT's Wugs: A Multilingual Investigation into the Morphological Capabilities of a Large Language Model. (arXiv:2310.15113v2 [cs.CL] UPDATED)\nAbstract: Large language models (LLMs) have recently reached an impressive level of linguistic capability, prompting comparisons with human language skills. However, there have been relatively few systematic inquiries into the linguistic capabilities of the latest generation of LLMs, and those studies that do exist (i) ignore the remarkable ability of humans to generalize, (ii) focus only on English, and (iii) investigate syntax or semantics and overlook other capabilities that lie at the heart of human language, like morphology. Here, we close these gaps by conducting the first rigorous analysis of the morphological capabilities of ChatGPT in four typologically varied languages (specifically, English, German, Tamil, and Turkish). We apply a version of Berko's (1958) wug test to ChatGPT, using novel, uncontaminated datasets for the four examined languages. We find that ChatGPT massively underperforms purpose-built systems, particularly in English. Overall, our results -- through the lens of morp",
    "path": "papers/23/10/2310.15113.json",
    "total_tokens": 868,
    "translated_title": "ChatGPT乌格的缺陷统计：对大型语言模型的形态学能力进行的跨语言研究",
    "translated_abstract": "大型语言模型（LLMs）近期在语言能力方面取得了令人印象深刻的进展，与人类语言能力相提并论。然而，对最新一代LLMs的语言能力进行系统调查的研究相对较少，而且这些研究忽视了人类泛化的显著能力，只关注英语，并且忽视了语言的其他核心能力，如形态学。在这里，我们通过在四种语言（具体来说是英语，德语，泰米尔语和土耳其语）上进行第一次严格的ChatGPT形态学能力分析来填补这些空白。我们使用Berko（1958）的乌格测试版本对ChatGPT进行实验，使用了针对四种语言的新颖、无污染的数据集。我们发现ChatGPT的表现远远不及专门构建的系统，尤其是在英语方面。总体而言，我们的结果按形态学能力衡量",
    "tldr": "本研究通过对ChatGPT在四种语言上的形态学能力进行严格分析，发现它在英语上的表现特别不理想，远远达不到专门构建系统的水平。"
}