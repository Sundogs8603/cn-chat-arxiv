{
    "title": "Hierarchical Forecasting at Scale. (arXiv:2310.12809v1 [cs.LG])",
    "abstract": "Existing hierarchical forecasting techniques scale poorly when the number of time series increases. We propose to learn a coherent forecast for millions of time series with a single bottom-level forecast model by using a sparse loss function that directly optimizes the hierarchical product and/or temporal structure. The benefit of our sparse hierarchical loss function is that it provides practitioners a method of producing bottom-level forecasts that are coherent to any chosen cross-sectional or temporal hierarchy. In addition, removing the need for a post-processing step as required in traditional hierarchical forecasting techniques reduces the computational cost of the prediction phase in the forecasting pipeline. On the public M5 dataset, our sparse hierarchical loss function performs up to 10% (RMSE) better compared to the baseline loss function. We implement our sparse hierarchical loss function within an existing forecasting model at bol, a large European e-commerce platform, res",
    "link": "http://arxiv.org/abs/2310.12809",
    "context": "Title: Hierarchical Forecasting at Scale. (arXiv:2310.12809v1 [cs.LG])\nAbstract: Existing hierarchical forecasting techniques scale poorly when the number of time series increases. We propose to learn a coherent forecast for millions of time series with a single bottom-level forecast model by using a sparse loss function that directly optimizes the hierarchical product and/or temporal structure. The benefit of our sparse hierarchical loss function is that it provides practitioners a method of producing bottom-level forecasts that are coherent to any chosen cross-sectional or temporal hierarchy. In addition, removing the need for a post-processing step as required in traditional hierarchical forecasting techniques reduces the computational cost of the prediction phase in the forecasting pipeline. On the public M5 dataset, our sparse hierarchical loss function performs up to 10% (RMSE) better compared to the baseline loss function. We implement our sparse hierarchical loss function within an existing forecasting model at bol, a large European e-commerce platform, res",
    "path": "papers/23/10/2310.12809.json",
    "total_tokens": 843,
    "translated_title": "大规模层次预测",
    "translated_abstract": "当时间序列的数量增加时，现有的层次预测技术的扩展性较差。我们提出使用稀疏损失函数来学习千万个时间序列的一致预测，该损失函数直接优化层次产品和/或时间结构。我们稀疏层次损失函数的优点是提供了一种方法，使实践者能够产生与任何选择的横向或时间层次一致的底层预测。此外，消除传统层次预测技术中需要的后处理步骤，减少了预测流程中的计算成本。在公开的M5数据集上，与基准损失函数相比，我们的稀疏层次损失函数性能提高了10%（RMSE）。我们将稀疏层次损失函数实现在bol这个大型欧洲电子商务平台上现存的预测模型中。",
    "tldr": "提出了一种大规模层次预测的方法，使用稀疏损失函数直接优化层次产品和/或时间结构，从而为数百万个时间序列提供一致的预测。在实验中，该方法在M5数据集上表现出10%的性能提升。",
    "en_tdlr": "A method for hierarchical forecasting at scale is proposed, which uses a sparse loss function to directly optimize hierarchical structure and provides coherent forecasts for millions of time series. The method achieves a performance improvement of 10% on the M5 dataset."
}