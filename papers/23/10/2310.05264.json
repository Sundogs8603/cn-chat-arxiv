{
    "title": "The Emergence of Reproducibility and Consistency in Diffusion Models",
    "abstract": "arXiv:2310.05264v2 Announce Type: replace  Abstract: In this work, we investigate an intriguing and prevalent phenomenon of diffusion models which we term as \"consistent model reproducibility\": given the same starting noise input and a deterministic sampler, different diffusion models often yield remarkably similar outputs. We confirm this phenomenon through comprehensive experiments, implying that different diffusion models consistently reach the same data distribution and scoring function regardless of diffusion model frameworks, model architectures, or training procedures. More strikingly, our further investigation implies that diffusion models are learning distinct distributions affected by the training data size. This is supported by the fact that the model reproducibility manifests in two distinct training regimes: (i) \"memorization regime\", where the diffusion model overfits to the training data distribution, and (ii) \"generalization regime\", where the model learns the underlyin",
    "link": "https://arxiv.org/abs/2310.05264",
    "context": "Title: The Emergence of Reproducibility and Consistency in Diffusion Models\nAbstract: arXiv:2310.05264v2 Announce Type: replace  Abstract: In this work, we investigate an intriguing and prevalent phenomenon of diffusion models which we term as \"consistent model reproducibility\": given the same starting noise input and a deterministic sampler, different diffusion models often yield remarkably similar outputs. We confirm this phenomenon through comprehensive experiments, implying that different diffusion models consistently reach the same data distribution and scoring function regardless of diffusion model frameworks, model architectures, or training procedures. More strikingly, our further investigation implies that diffusion models are learning distinct distributions affected by the training data size. This is supported by the fact that the model reproducibility manifests in two distinct training regimes: (i) \"memorization regime\", where the diffusion model overfits to the training data distribution, and (ii) \"generalization regime\", where the model learns the underlyin",
    "path": "papers/23/10/2310.05264.json",
    "total_tokens": 975,
    "translated_title": "扩散模型中的可重复性和一致性的出现",
    "translated_abstract": "在这项工作中，我们研究了扩散模型中的一个有趣且普遍存在的现象，我们称之为“一致的模型可重复性”：在给定相同的起始噪声输入和确定性采样器的情况下，不同的扩散模型通常产生非常相似的输出。我们通过全面的实验证实了这一现象，表明不同的扩散模型无论扩散模型框架、模型架构或训练过程如何，在数据分布和评分函数上都能够一致地达到相同的结果。更令人惊讶的是，我们进一步的调查表明，扩散模型在学习受训数据规模影响下的不同分布。这一点得到了两种不同训练模式下模型可重复性的体现：（i）“记忆化模式”，其中扩散模型过度拟合于训练数据分布，和（ii）“泛化模式”，其中模型学习到了基础数据分布。",
    "tldr": "该论文研究了扩散模型中的一致模型可重复性现象，实验证实了无论模型框架、模型架构或训练过程如何，不同的扩散模型都能够一致地达到相同的数据分布和评分函数。此外，研究发现扩散模型在学习过程中受训练数据规模的影响，表现出两种不同的训练模式：记忆化模式和泛化模式。",
    "en_tdlr": "This paper investigates the phenomenon of consistent model reproducibility in diffusion models, confirming that different diffusion models can consistently reach the same data distribution and scoring function regardless of model frameworks or training procedures. Additionally, the study reveals that diffusion models exhibit two distinct training regimes influenced by data size: a memorization regime and a generalization regime."
}