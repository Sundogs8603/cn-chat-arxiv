{
    "title": "Generating Continuations in Multilingual Idiomatic Contexts. (arXiv:2310.20195v1 [cs.CL])",
    "abstract": "The ability to process idiomatic or literal multiword expressions is a crucial aspect of understanding and generating any language. The task of generating contextually relevant continuations for narratives containing idiomatic (or literal) expressions can allow us to test the ability of generative language models (LMs) in understanding nuanced language containing non-compositional figurative text. We conduct a series of experiments using datasets in two distinct languages (English and Portuguese) under three different training settings (zero-shot, few-shot, and fine-tuned). Our results suggest that the models are only slightly better at generating continuations for literal contexts than idiomatic contexts, with exceedingly small margins. Furthermore, the models studied in this work perform equally well across both languages, indicating the robustness of generative models in performing this task.",
    "link": "http://arxiv.org/abs/2310.20195",
    "context": "Title: Generating Continuations in Multilingual Idiomatic Contexts. (arXiv:2310.20195v1 [cs.CL])\nAbstract: The ability to process idiomatic or literal multiword expressions is a crucial aspect of understanding and generating any language. The task of generating contextually relevant continuations for narratives containing idiomatic (or literal) expressions can allow us to test the ability of generative language models (LMs) in understanding nuanced language containing non-compositional figurative text. We conduct a series of experiments using datasets in two distinct languages (English and Portuguese) under three different training settings (zero-shot, few-shot, and fine-tuned). Our results suggest that the models are only slightly better at generating continuations for literal contexts than idiomatic contexts, with exceedingly small margins. Furthermore, the models studied in this work perform equally well across both languages, indicating the robustness of generative models in performing this task.",
    "path": "papers/23/10/2310.20195.json",
    "total_tokens": 796,
    "translated_title": "在多语种惯用语境下生成延续",
    "translated_abstract": "处理惯用或字面多词表达是理解和生成任何语言的关键方面。为包含惯用（或字面）表达的叙述生成具有上下文相关的延续的任务可以让我们测试生成性语言模型（LMs）理解非组合性比喻文本的纤细语言能力。我们使用两种不同语言（英语和葡萄牙语）的数据集在三种不同的训练设置下（零样本、少样本和微调）进行了一系列实验。我们的结果表明，模型在生成字面上下文的延续时略优于惯用上下文，但差距很小。此外，本研究中研究的模型在两种语言中表现出同样出色的性能，表明生成模型在执行此任务时具有鲁棒性。",
    "tldr": "本论文测试了生成性语言模型在多语种惯用语境中生成延续的能力，并发现模型在字面和惯用上下文中的表现相似，并且在两种语言中均具有鲁棒性。",
    "en_tdlr": "This paper tests the ability of generative language models to generate continuations in multilingual idiomatic contexts and finds that the models perform similarly in literal and idiomatic contexts, and are robust across languages."
}