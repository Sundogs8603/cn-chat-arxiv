{
    "title": "Understanding and Improving Ensemble Adversarial Defense. (arXiv:2310.18477v2 [cs.LG] UPDATED)",
    "abstract": "The strategy of ensemble has become popular in adversarial defense, which trains multiple base classifiers to defend against adversarial attacks in a cooperative manner. Despite the empirical success, theoretical explanations on why an ensemble of adversarially trained classifiers is more robust than single ones remain unclear. To fill in this gap, we develop a new error theory dedicated to understanding ensemble adversarial defense, demonstrating a provable 0-1 loss reduction on challenging sample sets in an adversarial defense scenario. Guided by this theory, we propose an effective approach to improve ensemble adversarial defense, named interactive global adversarial training (iGAT). The proposal includes (1) a probabilistic distributing rule that selectively allocates to different base classifiers adversarial examples that are globally challenging to the ensemble, and (2) a regularization term to rescue the severest weaknesses of the base classifiers. Being tested over various exis",
    "link": "http://arxiv.org/abs/2310.18477",
    "context": "Title: Understanding and Improving Ensemble Adversarial Defense. (arXiv:2310.18477v2 [cs.LG] UPDATED)\nAbstract: The strategy of ensemble has become popular in adversarial defense, which trains multiple base classifiers to defend against adversarial attacks in a cooperative manner. Despite the empirical success, theoretical explanations on why an ensemble of adversarially trained classifiers is more robust than single ones remain unclear. To fill in this gap, we develop a new error theory dedicated to understanding ensemble adversarial defense, demonstrating a provable 0-1 loss reduction on challenging sample sets in an adversarial defense scenario. Guided by this theory, we propose an effective approach to improve ensemble adversarial defense, named interactive global adversarial training (iGAT). The proposal includes (1) a probabilistic distributing rule that selectively allocates to different base classifiers adversarial examples that are globally challenging to the ensemble, and (2) a regularization term to rescue the severest weaknesses of the base classifiers. Being tested over various exis",
    "path": "papers/23/10/2310.18477.json",
    "total_tokens": 910,
    "translated_title": "理解和改进集成对抗防御",
    "translated_abstract": "集成策略已经在对抗防御中变得流行，它训练多个基本分类器以协同方式防御对抗攻击。尽管在经验上取得了成功，但对于为什么对抗训练的分类器集成比单个分类器更强大的理论解释仍然不清楚。为了填补这个空白，我们开发了一个新的错误理论，专门用于理解集成对抗防御，在对抗防御场景中展示了可以证明的在具有挑战性的样本集上的0-1损失降低。在这个理论的指导下，我们提出了一种改进集成对抗防御的有效方法，命名为交互全局对抗训练（iGAT）。该提案包括（1）一种概率分配规则，将全局上对集成具有挑战性的对抗样本选择性地分配给不同的基本分类器，以及（2）一个正则化项，以弥补基本分类器的严重弱点。在各种情况下进行了测试。",
    "tldr": "通过新的错误理论，作者提出了一个名为iGAT的方法用于改进集成对抗防御，该方法通过选择性地分配对抗样本和正则化来提高防御效果。该方法在各种情况下进行了测试并取得成功。",
    "en_tdlr": "Through a new error theory, the authors propose a method called iGAT to improve ensemble adversarial defense, which enhances defense effectiveness by selectively allocating adversarial examples and applying regularization. The method has been tested and successful in various scenarios."
}