{
    "title": "Learning Interpretable Rules for Scalable Data Representation and Classification. (arXiv:2310.14336v2 [cs.LG] UPDATED)",
    "abstract": "Rule-based models, e.g., decision trees, are widely used in scenarios demanding high model interpretability for their transparent inner structures and good model expressivity. However, rule-based models are hard to optimize, especially on large data sets, due to their discrete parameters and structures. Ensemble methods and fuzzy/soft rules are commonly used to improve performance, but they sacrifice the model interpretability. To obtain both good scalability and interpretability, we propose a new classifier, named Rule-based Representation Learner (RRL), that automatically learns interpretable non-fuzzy rules for data representation and classification. To train the non-differentiable RRL effectively, we project it to a continuous space and propose a novel training method, called Gradient Grafting, that can directly optimize the discrete model using gradient descent. A novel design of logical activation functions is also devised to increase the scalability of RRL and enable it to discr",
    "link": "http://arxiv.org/abs/2310.14336",
    "context": "Title: Learning Interpretable Rules for Scalable Data Representation and Classification. (arXiv:2310.14336v2 [cs.LG] UPDATED)\nAbstract: Rule-based models, e.g., decision trees, are widely used in scenarios demanding high model interpretability for their transparent inner structures and good model expressivity. However, rule-based models are hard to optimize, especially on large data sets, due to their discrete parameters and structures. Ensemble methods and fuzzy/soft rules are commonly used to improve performance, but they sacrifice the model interpretability. To obtain both good scalability and interpretability, we propose a new classifier, named Rule-based Representation Learner (RRL), that automatically learns interpretable non-fuzzy rules for data representation and classification. To train the non-differentiable RRL effectively, we project it to a continuous space and propose a novel training method, called Gradient Grafting, that can directly optimize the discrete model using gradient descent. A novel design of logical activation functions is also devised to increase the scalability of RRL and enable it to discr",
    "path": "papers/23/10/2310.14336.json",
    "total_tokens": 890,
    "translated_title": "学习可解释的规则以实现可扩展的数据表示和分类",
    "translated_abstract": "基于规则的模型（如决策树）在需要高模型解释性的场景中被广泛使用，因为它们具有透明的内部结构和良好的模型表达能力。然而，由于离散的参数和结构，基于规则的模型在优化方面很难应对大规模的数据集。集成方法和模糊/软规则通常用于提高性能，但会牺牲模型的解释性。为了获得良好的可扩展性和可解释性，我们提出了一种新的分类器，称为基于规则的表示学习器（RRL），它可以自动学习用于数据表示和分类的可解释的非模糊规则。为了有效训练不可微分的RRL，我们将其映射到连续空间，并提出一种称为梯度嵌入的新的训练方法，可以使用梯度下降直接优化离散模型。此外，还设计了一种新颖的逻辑激活函数，以增加RRL的可扩展性，并使其能够进行判别。",
    "tldr": "这项研究提出了一种名为RRL的新型分类器，通过自动学习可解释的非模糊规则，实现了数据表示和分类的良好可扩展性和解释性。",
    "en_tdlr": "This research proposes a new classifier called RRL, which achieves both good scalability and interpretability in data representation and classification by automatically learning interpretable non-fuzzy rules."
}