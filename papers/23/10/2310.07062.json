{
    "title": "Acoustic Model Fusion for End-to-end Speech Recognition. (arXiv:2310.07062v1 [cs.SD])",
    "abstract": "Recent advances in deep learning and automatic speech recognition (ASR) have enabled the end-to-end (E2E) ASR system and boosted the accuracy to a new level. The E2E systems implicitly model all conventional ASR components, such as the acoustic model (AM) and the language model (LM), in a single network trained on audio-text pairs. Despite this simpler system architecture, fusing a separate LM, trained exclusively on text corpora, into the E2E system has proven to be beneficial. However, the application of LM fusion presents certain drawbacks, such as its inability to address the domain mismatch issue inherent to the internal AM. Drawing inspiration from the concept of LM fusion, we propose the integration of an external AM into the E2E system to better address the domain mismatch. By implementing this novel approach, we have achieved a significant reduction in the word error rate, with an impressive drop of up to 14.3% across varied test sets. We also discovered that this AM fusion ap",
    "link": "http://arxiv.org/abs/2310.07062",
    "context": "Title: Acoustic Model Fusion for End-to-end Speech Recognition. (arXiv:2310.07062v1 [cs.SD])\nAbstract: Recent advances in deep learning and automatic speech recognition (ASR) have enabled the end-to-end (E2E) ASR system and boosted the accuracy to a new level. The E2E systems implicitly model all conventional ASR components, such as the acoustic model (AM) and the language model (LM), in a single network trained on audio-text pairs. Despite this simpler system architecture, fusing a separate LM, trained exclusively on text corpora, into the E2E system has proven to be beneficial. However, the application of LM fusion presents certain drawbacks, such as its inability to address the domain mismatch issue inherent to the internal AM. Drawing inspiration from the concept of LM fusion, we propose the integration of an external AM into the E2E system to better address the domain mismatch. By implementing this novel approach, we have achieved a significant reduction in the word error rate, with an impressive drop of up to 14.3% across varied test sets. We also discovered that this AM fusion ap",
    "path": "papers/23/10/2310.07062.json",
    "total_tokens": 898,
    "translated_title": "声学模型融合用于端到端语音识别",
    "translated_abstract": "深度学习和自动语音识别（ASR）的最新进展使得端到端（E2E）ASR系统成为可能，并将准确度提升到一个新的水平。E2E系统在训练语音-文本对的同时隐式地建模了所有传统的ASR组件，如声学模型（AM）和语言模型（LM）。尽管这种简化的系统架构，将一个专门在文本语料库上训练的独立LM融合到E2E系统中被证明是有益的。然而，LM融合的应用存在一定的缺点，例如无法解决内部AM固有的领域不匹配问题。受到LM融合概念的启发，我们提出将外部AM融合到E2E系统中，以更好地解决领域不匹配问题。通过实施这种新颖的方法，我们在不同测试集中实现了显著的词错误率下降，最高达14.3％。我们还发现，这种AM融合方法可以提供额外的性能优势。",
    "tldr": "该论文提出了一种声学模型融合的方法，可以改进端到端语音识别系统中存在的领域不匹配问题，并显著降低词错误率。"
}