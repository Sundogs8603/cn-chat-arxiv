{
    "title": "Fast and Accurate Factual Inconsistency Detection Over Long Documents. (arXiv:2310.13189v1 [cs.CL])",
    "abstract": "Generative AI models exhibit remarkable potential; however, hallucinations across various tasks present a significant challenge, particularly for longer inputs that current approaches struggle to address effectively. We introduce SCALE (Source Chunking Approach for Large-scale inconsistency Evaluation), a task-agnostic model for detecting factual inconsistencies using a novel chunking strategy. Specifically, SCALE is a Natural Language Inference (NLI) based model that uses large text chunks to condition over long texts. This approach achieves state-of-the-art performance in factual inconsistency detection for diverse tasks and long inputs. Additionally, we leverage the chunking mechanism and employ a novel algorithm to explain SCALE's decisions through relevant source sentence retrieval. Our evaluations reveal that SCALE outperforms existing methods on both standard benchmarks and a new long-form dialogue dataset ScreenEval we constructed. Moreover, SCALE surpasses competitive systems ",
    "link": "http://arxiv.org/abs/2310.13189",
    "context": "Title: Fast and Accurate Factual Inconsistency Detection Over Long Documents. (arXiv:2310.13189v1 [cs.CL])\nAbstract: Generative AI models exhibit remarkable potential; however, hallucinations across various tasks present a significant challenge, particularly for longer inputs that current approaches struggle to address effectively. We introduce SCALE (Source Chunking Approach for Large-scale inconsistency Evaluation), a task-agnostic model for detecting factual inconsistencies using a novel chunking strategy. Specifically, SCALE is a Natural Language Inference (NLI) based model that uses large text chunks to condition over long texts. This approach achieves state-of-the-art performance in factual inconsistency detection for diverse tasks and long inputs. Additionally, we leverage the chunking mechanism and employ a novel algorithm to explain SCALE's decisions through relevant source sentence retrieval. Our evaluations reveal that SCALE outperforms existing methods on both standard benchmarks and a new long-form dialogue dataset ScreenEval we constructed. Moreover, SCALE surpasses competitive systems ",
    "path": "papers/23/10/2310.13189.json",
    "total_tokens": 869,
    "translated_title": "长文档中快速准确的事实不一致检测",
    "translated_abstract": "生成式AI模型具有巨大的潜力；然而，对于当前方法难以有效解决的较长输入中的各种任务中的幻觉是一个重大挑战。我们引入了SCALE（用于大规模不一致性评估的源块化方法），这是一个用于检测事实不一致性的通用模型，使用了一种新颖的块化策略。具体而言，SCALE是一个基于自然语言推理（NLI）的模型，它使用大的文本块对长文本进行条件化。这种方法在各种任务和长文本的事实不一致性检测方面实现了最先进的性能。此外，我们利用块化机制并采用一种新颖的算法通过相关的源语句检索来解释SCALE的决策。我们的评估结果显示，SCALE在标准基准测试和我们构建的新的长形式对话数据集ScreenEval上均优于现有方法。此外，SCALE超过了竞争系统。",
    "tldr": "SCALE是一个用于检测长文本中事实不一致性的通用模型，通过使用新颖的块化策略和自然语言推理（NLI）实现了最先进的性能，同时还能解释决策并超过竞争系统。",
    "en_tdlr": "SCALE is a task-agnostic model for detecting factual inconsistencies in long texts, achieving state-of-the-art performance through a novel chunking strategy and Natural Language Inference (NLI), while also providing explanations for its decisions and surpassing competitive systems."
}