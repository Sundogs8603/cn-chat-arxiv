{
    "title": "Towards Explainability in Monocular Depth Estimation. (arXiv:2310.16457v1 [cs.CV])",
    "abstract": "The estimation of depth in two-dimensional images has long been a challenging and extensively studied subject in computer vision. Recently, significant progress has been made with the emergence of Deep Learning-based approaches, which have proven highly successful. This paper focuses on the explainability in monocular depth estimation methods, in terms of how humans perceive depth. This preliminary study emphasizes on one of the most significant visual cues, the relative size, which is prominent in almost all viewed images. We designed a specific experiment to mimic the experiments in humans and have tested state-of-the-art methods to indirectly assess the explainability in the context defined. In addition, we observed that measuring the accuracy required further attention and a particular approach is proposed to this end. The results show that a mean accuracy of around 77% across methods is achieved, with some of the methods performing markedly better, thus, indirectly revealing their",
    "link": "http://arxiv.org/abs/2310.16457",
    "context": "Title: Towards Explainability in Monocular Depth Estimation. (arXiv:2310.16457v1 [cs.CV])\nAbstract: The estimation of depth in two-dimensional images has long been a challenging and extensively studied subject in computer vision. Recently, significant progress has been made with the emergence of Deep Learning-based approaches, which have proven highly successful. This paper focuses on the explainability in monocular depth estimation methods, in terms of how humans perceive depth. This preliminary study emphasizes on one of the most significant visual cues, the relative size, which is prominent in almost all viewed images. We designed a specific experiment to mimic the experiments in humans and have tested state-of-the-art methods to indirectly assess the explainability in the context defined. In addition, we observed that measuring the accuracy required further attention and a particular approach is proposed to this end. The results show that a mean accuracy of around 77% across methods is achieved, with some of the methods performing markedly better, thus, indirectly revealing their",
    "path": "papers/23/10/2310.16457.json",
    "total_tokens": 931,
    "translated_title": "《单眼深度估计中的可解释性》",
    "translated_abstract": "二维图像深度估计一直是计算机视觉中具有挑战性且广泛研究的课题。近年来，随着基于深度学习的方法的出现，取得了显著的进展，并且取得了极高的成功率。本文关注单眼深度估计方法中的可解释性，即人类如何感知深度。这项初步研究强调了最显著的视觉线索之一，即相对尺寸，在几乎所有观察的图像中都非常突出。我们设计了一个特定的实验来模拟人类实验，并测试了最先进的方法以间接评估在所定义的上下文中的可解释性。此外，我们观察到测量准确性需要进一步关注，并提出了一种特殊的方法来解决这个问题。结果表明，在各种方法中，平均准确率达到了约77%，其中一些方法表现出色，从而间接揭示了它们的可解释性。",
    "tldr": "本文研究了单眼深度估计方法中的可解释性，重点关注了人类感知深度的一个最重要的视觉线索——相对尺寸。通过模拟人类实验和测试最先进的方法，本研究实现了平均准确率约为77%的结果，间接揭示了这些方法的可解释性。",
    "en_tdlr": "This paper focuses on the explainability in monocular depth estimation methods, emphasizing on the prominent visual cue of relative size. By simulating human experiments and testing state-of-the-art methods, an average accuracy of around 77% is achieved, indirectly revealing the explainability of these methods."
}