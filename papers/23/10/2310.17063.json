{
    "title": "Coreset Markov Chain Monte Carlo. (arXiv:2310.17063v1 [stat.CO])",
    "abstract": "A Bayesian coreset is a small, weighted subset of data that replaces the full dataset during inference in order to reduce computational cost. However, state of the art methods for tuning coreset weights are expensive, require nontrivial user input, and impose constraints on the model. In this work, we propose a new method -- Coreset MCMC -- that simulates a Markov chain targeting the coreset posterior, while simultaneously updating the coreset weights using those same draws. Coreset MCMC is simple to implement and tune, and can be used with any existing MCMC kernel. We analyze Coreset MCMC in a representative setting to obtain key insights about the convergence behaviour of the method. Empirical results demonstrate that Coreset MCMC provides higher quality posterior approximations and reduced computational cost compared with other coreset construction methods. Further, compared with other general subsampling MCMC methods, we find that Coreset MCMC has a higher sampling efficiency with ",
    "link": "http://arxiv.org/abs/2310.17063",
    "context": "Title: Coreset Markov Chain Monte Carlo. (arXiv:2310.17063v1 [stat.CO])\nAbstract: A Bayesian coreset is a small, weighted subset of data that replaces the full dataset during inference in order to reduce computational cost. However, state of the art methods for tuning coreset weights are expensive, require nontrivial user input, and impose constraints on the model. In this work, we propose a new method -- Coreset MCMC -- that simulates a Markov chain targeting the coreset posterior, while simultaneously updating the coreset weights using those same draws. Coreset MCMC is simple to implement and tune, and can be used with any existing MCMC kernel. We analyze Coreset MCMC in a representative setting to obtain key insights about the convergence behaviour of the method. Empirical results demonstrate that Coreset MCMC provides higher quality posterior approximations and reduced computational cost compared with other coreset construction methods. Further, compared with other general subsampling MCMC methods, we find that Coreset MCMC has a higher sampling efficiency with ",
    "path": "papers/23/10/2310.17063.json",
    "total_tokens": 915,
    "translated_title": "Coreset马尔可夫链蒙特卡罗",
    "translated_abstract": "贝叶斯coreset是一个小而加权的数据子集，用于在推断过程中替代完整数据集以降低计算成本。然而，目前调整coreset权重的最先进方法耗时昂贵，需要复杂的用户输入，并对模型施加约束。在本文中，我们提出了一种新的方法——Coreset MCMC，该方法模拟了一个马尔可夫链，目标是coreset后验分布，同时使用相同的抽样更新coreset权重。Coreset MCMC易于实施和调整，并可与任何现有的MCMC内核一起使用。我们在一个代表性场景中分析了Coreset MCMC，以获得有关该方法收敛行为的关键见解。实证结果表明，与其他coreset构造方法相比，Coreset MCMC能够提供更高质量的后验近似和更低的计算成本。此外，与其他常规子采样MCMC方法相比，我们发现Coreset MCMC具有较高的采样效率。",
    "tldr": "Coreset MCMC提出了一种新的方法，通过模拟马尔可夫链以更新coreset权重，从而实现在推断过程中降低计算成本的目的。与其他方法相比，Coreset MCMC提供了更高质量的后验近似和更高的采样效率。"
}