{
    "title": "Failures Pave the Way: Enhancing Large Language Models through Tuning-free Rule Accumulation. (arXiv:2310.15746v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs) have showcased impressive performance. However, due to their inability to capture relationships among samples, these frozen LLMs inevitably keep repeating similar mistakes. In this work, we propose our Tuning-free Rule Accumulation (TRAN) framework, which guides LLMs in improving their performance by learning from previous mistakes. Considering data arrives sequentially, LLMs gradually accumulate rules from incorrect cases, forming a rule collection. These rules are then utilized by the LLMs to avoid making similar mistakes when processing subsequent inputs. Moreover, the rules remain independent of the primary prompts, seamlessly complementing prompt design strategies. Experimentally, we show that TRAN improves over recent baselines by a large margin.",
    "link": "http://arxiv.org/abs/2310.15746",
    "context": "Title: Failures Pave the Way: Enhancing Large Language Models through Tuning-free Rule Accumulation. (arXiv:2310.15746v1 [cs.CL])\nAbstract: Large Language Models (LLMs) have showcased impressive performance. However, due to their inability to capture relationships among samples, these frozen LLMs inevitably keep repeating similar mistakes. In this work, we propose our Tuning-free Rule Accumulation (TRAN) framework, which guides LLMs in improving their performance by learning from previous mistakes. Considering data arrives sequentially, LLMs gradually accumulate rules from incorrect cases, forming a rule collection. These rules are then utilized by the LLMs to avoid making similar mistakes when processing subsequent inputs. Moreover, the rules remain independent of the primary prompts, seamlessly complementing prompt design strategies. Experimentally, we show that TRAN improves over recent baselines by a large margin.",
    "path": "papers/23/10/2310.15746.json",
    "total_tokens": 806,
    "translated_title": "失败指引之路：通过无调优规则累积增强大型语言模型",
    "translated_abstract": "大型语言模型(LLM)展现出了令人印象深刻的性能。然而，由于无法捕捉样本之间的关系，这些静态的LLM不可避免地不断重复相似的错误。在这项工作中，我们提出了无调优规则累积（TRAN）框架，通过从以前的错误中学习来指导LLM改善其性能。考虑到数据是顺序到达的，LLM逐渐积累了从错误案例中得到的规则，形成了一个规则集合。然后，LLM在处理后续输入时利用这些规则避免犯类似的错误。此外，规则与主要提示无关，无缝补充了提示设计策略。实验证明，TRAN相较于最近的基准线有很大的改进。",
    "tldr": "本论文提出了一种无调优规则累积（TRAN）框架，通过从以前的错误中学习来指导大型语言模型（LLMs）改善性能。实验证明，TRAN相较于最近的基准线有很大的改进。",
    "en_tdlr": "This paper proposes a tuning-free rule accumulation (TRAN) framework to guide large language models (LLMs) in improving their performance by learning from previous mistakes. Experimental results show significant improvement over recent baselines."
}