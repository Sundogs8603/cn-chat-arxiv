{
    "title": "AutoFHE: Automated Adaption of CNNs for Efficient Evaluation over FHE. (arXiv:2310.08012v1 [cs.LG])",
    "abstract": "Secure inference of deep convolutional neural networks (CNNs) under RNS-CKKS involves polynomial approximation of unsupported non-linear activation functions. However, existing approaches have three main limitations: 1) Inflexibility: The polynomial approximation and associated homomorphic evaluation architecture are customized manually for each CNN architecture and do not generalize to other networks. 2) Suboptimal Approximation: Each activation function is approximated instead of the function represented by the CNN. 3) Restricted Design: Either high-degree or low-degree polynomial approximations are used. The former retains high accuracy but slows down inference due to bootstrapping operations, while the latter accelerates ciphertext inference but compromises accuracy. To address these limitations, we present AutoFHE, which automatically adapts standard CNNs for secure inference under RNS-CKKS. The key idea is to adopt layerwise mixed-degree polynomial activation functions, which are",
    "link": "http://arxiv.org/abs/2310.08012",
    "context": "Title: AutoFHE: Automated Adaption of CNNs for Efficient Evaluation over FHE. (arXiv:2310.08012v1 [cs.LG])\nAbstract: Secure inference of deep convolutional neural networks (CNNs) under RNS-CKKS involves polynomial approximation of unsupported non-linear activation functions. However, existing approaches have three main limitations: 1) Inflexibility: The polynomial approximation and associated homomorphic evaluation architecture are customized manually for each CNN architecture and do not generalize to other networks. 2) Suboptimal Approximation: Each activation function is approximated instead of the function represented by the CNN. 3) Restricted Design: Either high-degree or low-degree polynomial approximations are used. The former retains high accuracy but slows down inference due to bootstrapping operations, while the latter accelerates ciphertext inference but compromises accuracy. To address these limitations, we present AutoFHE, which automatically adapts standard CNNs for secure inference under RNS-CKKS. The key idea is to adopt layerwise mixed-degree polynomial activation functions, which are",
    "path": "papers/23/10/2310.08012.json",
    "total_tokens": 888,
    "translated_title": "AutoFHE: 用于FHE高效评估的CNN自动适应方法",
    "translated_abstract": "在RNS-CKKS下，对于深度卷积神经网络（CNN）的安全推理，需要对不支持的非线性激活函数进行多项式逼近。然而，现有方法存在三个主要限制：1）不灵活：多项式逼近和相关的同态评估架构是针对每个CNN架构手动定制的，并且无法推广到其他网络。2）次优逼近：对于CNN表示的每个激活函数进行近似，而不是近似整个函数。3）限制性设计：使用高次或低次多项式逼近。前者保留了较高的准确性，但由于引导操作而减慢了推理速度，而后者加快了密文推理，但损害了准确性。为了解决这些限制，我们提出了AutoFHE，它可以自动适应RNS-CKKS下标准CNN进行安全推理。关键思想是采用逐层混合次数多项式激活函数。",
    "tldr": "AutoFHE针对深度卷积神经网络的安全推理提出了一种自动方法，通过采用逐层混合次数多项式激活函数来解决现有方法的灵活性、次优逼近和限制性设计限制。",
    "en_tdlr": "AutoFHE presents an automated approach for secure inference of deep CNNs, addressing the limitations of existing methods in terms of flexibility, suboptimal approximation, and restricted design by adopting layerwise mixed-degree polynomial activation functions."
}