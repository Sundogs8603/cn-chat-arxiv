{
    "title": "Theory of Mind in Large Language Models: Examining Performance of 11 State-of-the-Art models vs. Children Aged 7-10 on Advanced Tests. (arXiv:2310.20320v1 [cs.CL])",
    "abstract": "To what degree should we ascribe cognitive capacities to Large Language Models (LLMs), such as the ability to reason about intentions and beliefs known as Theory of Mind (ToM)? Here we add to this emerging debate by (i) testing 11 base- and instruction-tuned LLMs on capabilities relevant to ToM beyond the dominant false-belief paradigm, including non-literal language usage and recursive intentionality; (ii) using newly rewritten versions of standardized tests to gauge LLMs' robustness; (iii) prompting and scoring for open besides closed questions; and (iv) benchmarking LLM performance against that of children aged 7-10 on the same tasks. We find that instruction-tuned LLMs from the GPT family outperform other models, and often also children. Base-LLMs are mostly unable to solve ToM tasks, even with specialized prompting. We suggest that the interlinked evolution and development of language and ToM may help explain what instruction-tuning adds: rewarding cooperative communication that t",
    "link": "http://arxiv.org/abs/2310.20320",
    "context": "Title: Theory of Mind in Large Language Models: Examining Performance of 11 State-of-the-Art models vs. Children Aged 7-10 on Advanced Tests. (arXiv:2310.20320v1 [cs.CL])\nAbstract: To what degree should we ascribe cognitive capacities to Large Language Models (LLMs), such as the ability to reason about intentions and beliefs known as Theory of Mind (ToM)? Here we add to this emerging debate by (i) testing 11 base- and instruction-tuned LLMs on capabilities relevant to ToM beyond the dominant false-belief paradigm, including non-literal language usage and recursive intentionality; (ii) using newly rewritten versions of standardized tests to gauge LLMs' robustness; (iii) prompting and scoring for open besides closed questions; and (iv) benchmarking LLM performance against that of children aged 7-10 on the same tasks. We find that instruction-tuned LLMs from the GPT family outperform other models, and often also children. Base-LLMs are mostly unable to solve ToM tasks, even with specialized prompting. We suggest that the interlinked evolution and development of language and ToM may help explain what instruction-tuning adds: rewarding cooperative communication that t",
    "path": "papers/23/10/2310.20320.json",
    "total_tokens": 1097,
    "translated_title": "大型语言模型中的心灵理论：11种最新模型与7-10岁儿童在高级测试中的表现比较",
    "translated_abstract": "我们应该给予大型语言模型（LLM）多大的认知能力，例如理解意图和信念的理论心灵（ToM）能力？在这里，我们通过以下方式，为这场新兴辩论增加一些证据：（i）测试11个基础模型和调整指令的LLMs的ToM相关能力，超越主导的虚假信念范式，包括非文字的语言使用和递归的意图；（ii）使用新编写的标准化测试版本来评估LLMs的稳健性；（iii）提示并计分开放问题和封闭问题；（iv）将LLM的表现与7-10岁儿童在相同任务上的表现进行基准测试。我们发现，GPT系列的调整指令LLMs在其他模型中表现最佳，并且通常也超过了儿童的表现。基础LLMs大多无法解决ToM任务，即使使用了专门的提示。我们认为，语言和ToM的相互关联性可能有助于解释为什么调整指令会增加LLM的性能：奖励合作性沟通。",
    "tldr": "本研究通过将11种基础模型和调整指令的大型语言模型（LLMs）与7-10岁儿童在高级测试中进行比较，发现GPT系列的调整指令LLMs表现最佳，并且在某些任务上超过了儿童的表现。此外，基础LLMs大多无法解决ToM任务，而调整指令则通过奖励合作性沟通有助于提升LLM的性能。",
    "en_tdlr": "This study compares the performance of 11 base and instruction-tuned Large Language Models (LLMs) with children aged 7-10 on advanced tests. The results show that instruction-tuned LLMs from the GPT family outperform other models and often exceed the performance of children. Additionally, base-LLMs are mostly unable to solve Theory of Mind (ToM) tasks, while instruction-tuning improves LLM performance through rewarding cooperative communication."
}