{
    "title": "Neuro-Inspired Fragmentation and Recall to Overcome Catastrophic Forgetting in Curiosity. (arXiv:2310.17537v1 [cs.AI])",
    "abstract": "Deep reinforcement learning methods exhibit impressive performance on a range of tasks but still struggle on hard exploration tasks in large environments with sparse rewards. To address this, intrinsic rewards can be generated using forward model prediction errors that decrease as the environment becomes known, and incentivize an agent to explore novel states. While prediction-based intrinsic rewards can help agents solve hard exploration tasks, they can suffer from catastrophic forgetting and actually increase at visited states. We first examine the conditions and causes of catastrophic forgetting in grid world environments. We then propose a new method FARCuriosity, inspired by how humans and animals learn. The method depends on fragmentation and recall: an agent fragments an environment based on surprisal, and uses different local curiosity modules (prediction-based intrinsic reward functions) for each fragment so that modules are not trained on the entire environment. At each fragm",
    "link": "http://arxiv.org/abs/2310.17537",
    "context": "Title: Neuro-Inspired Fragmentation and Recall to Overcome Catastrophic Forgetting in Curiosity. (arXiv:2310.17537v1 [cs.AI])\nAbstract: Deep reinforcement learning methods exhibit impressive performance on a range of tasks but still struggle on hard exploration tasks in large environments with sparse rewards. To address this, intrinsic rewards can be generated using forward model prediction errors that decrease as the environment becomes known, and incentivize an agent to explore novel states. While prediction-based intrinsic rewards can help agents solve hard exploration tasks, they can suffer from catastrophic forgetting and actually increase at visited states. We first examine the conditions and causes of catastrophic forgetting in grid world environments. We then propose a new method FARCuriosity, inspired by how humans and animals learn. The method depends on fragmentation and recall: an agent fragments an environment based on surprisal, and uses different local curiosity modules (prediction-based intrinsic reward functions) for each fragment so that modules are not trained on the entire environment. At each fragm",
    "path": "papers/23/10/2310.17537.json",
    "total_tokens": 959,
    "translated_title": "神经启发的分段和回溯法克服好奇心中的灾难性遗忘",
    "translated_abstract": "深度强化学习方法在一系列任务上表现出色，但在大型环境中稀疏奖励的困难探索任务中仍然存在困难。为了解决这个问题，可以使用通过前向模型预测误差生成的内在奖励，这些误差随着环境的熟悉程度而减少，并激励代理探索新的状态。虽然基于预测的内在奖励可以帮助代理解决困难的探索任务，但它们可能会遭受灾难性遗忘，并且实际上会在访问的状态上增加。我们首先研究了格状世界环境中灾难性遗忘的条件和原因。然后，我们提出了一种受人类和动物学习启发的新方法FARCuriosity。该方法依赖于分段和回溯：代理根据惊讶性对环境进行分段，并为每个分段使用不同的本地好奇模块（基于预测的内在奖励函数），以使模块不是在整个环境上进行训练。在每个分段中，代理可以同时存储并回溯先前的奖励值以应对灾难性遗忘。",
    "tldr": "提出了一种受神经启发的方法，通过分段和回溯来克服深度强化学习中的灾难性遗忘问题，并通过内在奖励激励代理探索新的状态。",
    "en_tdlr": "A neuro-inspired method called FARCuriosity is proposed to overcome catastrophic forgetting in deep reinforcement learning by utilizing fragmentation and recall, and incentivizing agents to explore novel states through intrinsic rewards."
}