{
    "title": "Samples on Thin Ice: Re-Evaluating Adversarial Pruning of Neural Networks. (arXiv:2310.08073v1 [cs.LG])",
    "abstract": "Neural network pruning has shown to be an effective technique for reducing the network size, trading desirable properties like generalization and robustness to adversarial attacks for higher sparsity. Recent work has claimed that adversarial pruning methods can produce sparse networks while also preserving robustness to adversarial examples. In this work, we first re-evaluate three state-of-the-art adversarial pruning methods, showing that their robustness was indeed overestimated. We then compare pruned and dense versions of the same models, discovering that samples on thin ice, i.e., closer to the unpruned model's decision boundary, are typically misclassified after pruning. We conclude by discussing how this intuition may lead to designing more effective adversarial pruning methods in future work.",
    "link": "http://arxiv.org/abs/2310.08073",
    "context": "Title: Samples on Thin Ice: Re-Evaluating Adversarial Pruning of Neural Networks. (arXiv:2310.08073v1 [cs.LG])\nAbstract: Neural network pruning has shown to be an effective technique for reducing the network size, trading desirable properties like generalization and robustness to adversarial attacks for higher sparsity. Recent work has claimed that adversarial pruning methods can produce sparse networks while also preserving robustness to adversarial examples. In this work, we first re-evaluate three state-of-the-art adversarial pruning methods, showing that their robustness was indeed overestimated. We then compare pruned and dense versions of the same models, discovering that samples on thin ice, i.e., closer to the unpruned model's decision boundary, are typically misclassified after pruning. We conclude by discussing how this intuition may lead to designing more effective adversarial pruning methods in future work.",
    "path": "papers/23/10/2310.08073.json",
    "total_tokens": 848,
    "translated_title": "薄冰样本：重新评估神经网络的对抗剪枝",
    "translated_abstract": "神经网络剪枝已被证明是一种有效的减小网络大小的技术，它通过增加稀疏度来换取良好的泛化能力和对抗攻击的鲁棒性。最近的研究声称，对抗性剪枝方法可以在产生稀疏网络的同时保持对抗性示例的鲁棒性。在本文中，我们首先重新评估了三种最先进的对抗性剪枝方法，发现它们的鲁棒性的确被高估了。然后，我们比较了剪枝和密集模型的版本，发现在剪枝之后，接近未剪枝模型决策边界的样本通常被错误分类。最后，我们讨论了这种直觉可能如何在未来的工作中导致设计更有效的对抗性剪枝方法。",
    "tldr": "本研究重新评估了对抗性剪枝方法，发现其鲁棒性被高估。剪枝后，接近未剪枝模型决策边界的样本通常被错误分类。这些结果对未来设计更有效的对抗性剪枝方法具有指导意义。"
}