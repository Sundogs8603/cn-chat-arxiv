{
    "title": "Not All Demonstration Examples are Equally Beneficial: Reweighting Demonstration Examples for In-Context Learning. (arXiv:2310.08309v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs) have recently gained the In-Context Learning (ICL) ability with the models scaling up, allowing them to quickly adapt to downstream tasks with only a few demonstration examples prepended in the input sequence. Nonetheless, the current practice of ICL treats all demonstration examples equally, which still warrants improvement, as the quality of examples is usually uneven. In this paper, we investigate how to determine approximately optimal weights for demonstration examples and how to apply them during ICL. To assess the quality of weights in the absence of additional validation data, we design a masked self-prediction (MSP) score that exhibits a strong correlation with the final ICL performance. To expedite the weight-searching process, we discretize the continuous weight space and adopt beam search. With approximately optimal weights obtained, we further propose two strategies to apply them to demonstrations at different model positions. Experimental resul",
    "link": "http://arxiv.org/abs/2310.08309",
    "context": "Title: Not All Demonstration Examples are Equally Beneficial: Reweighting Demonstration Examples for In-Context Learning. (arXiv:2310.08309v1 [cs.CL])\nAbstract: Large Language Models (LLMs) have recently gained the In-Context Learning (ICL) ability with the models scaling up, allowing them to quickly adapt to downstream tasks with only a few demonstration examples prepended in the input sequence. Nonetheless, the current practice of ICL treats all demonstration examples equally, which still warrants improvement, as the quality of examples is usually uneven. In this paper, we investigate how to determine approximately optimal weights for demonstration examples and how to apply them during ICL. To assess the quality of weights in the absence of additional validation data, we design a masked self-prediction (MSP) score that exhibits a strong correlation with the final ICL performance. To expedite the weight-searching process, we discretize the continuous weight space and adopt beam search. With approximately optimal weights obtained, we further propose two strategies to apply them to demonstrations at different model positions. Experimental resul",
    "path": "papers/23/10/2310.08309.json",
    "total_tokens": 960,
    "translated_title": "并非所有的演示示例都有同样的益处：为上下文学习重新加权演示示例",
    "translated_abstract": "最近，随着模型规模的扩大，大型语言模型（LLMs）已经获得了上下文学习（ICL）的能力，仅通过在输入序列中添加几个演示示例就可以快速适应下游任务。然而，目前的ICL实践将所有演示示例视为相等，仍需要改进，因为示例的质量通常是不均匀的。在本文中，我们研究了如何确定近似最优的演示示例权重以及如何在ICL过程中应用它们。为了在没有额外验证数据的情况下评估权重的质量，我们设计了一个掩码自我预测（MSP）分数，该分数与最终的ICL性能呈强相关。为了加速权重搜索过程，我们对连续权重空间进行离散化，并采用波束搜索。通过获得近似最优权重，我们进一步提出了两种策略来将它们应用到不同模型位置的演示示例上。实验结果表明...",
    "tldr": "本文研究了如何给演示示例重新加权以优化上下文学习的效果。通过设计一个和最终学习性能具有强相关性的掩码自我预测分数，我们确定了近似最优的权重，并采用离散化和波束搜索等方法加快了权重搜索过程。",
    "en_tdlr": "This paper investigates how to reweight demonstration examples to improve the performance of in-context learning. By designing a masked self-prediction score that has a strong correlation with the final learning performance, we determine approximate optimal weights and accelerate the weight-searching process with techniques such as discretization and beam search."
}