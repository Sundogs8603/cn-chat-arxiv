{
    "title": "Diversity of Thought Improves Reasoning Abilities of Large Language Models. (arXiv:2310.07088v1 [cs.CL])",
    "abstract": "Large language models (LLMs) are documented to struggle in settings that require complex reasoning. Nevertheless, instructing the model to break down the problem into smaller reasoning steps (Wei et al., 2022), or ensembling various generations through modifying decoding steps (Wang et al., 2023) boosts performance. Current methods assume that the input prompt is fixed and expect the decoding strategies to introduce the diversity needed for ensembling. In this work, we relax this assumption and discuss how one can create and leverage variations of the input prompt as a means to diversity of thought to improve model performance. We propose a method that automatically improves prompt diversity by soliciting feedback from the LLM to ideate approaches that fit for the problem. We then ensemble the diverse prompts in our method DIV-SE (DIVerse reasoning path Self-Ensemble) across multiple inference calls. We also propose a cost-effective alternative where diverse prompts are used within a s",
    "link": "http://arxiv.org/abs/2310.07088",
    "context": "Title: Diversity of Thought Improves Reasoning Abilities of Large Language Models. (arXiv:2310.07088v1 [cs.CL])\nAbstract: Large language models (LLMs) are documented to struggle in settings that require complex reasoning. Nevertheless, instructing the model to break down the problem into smaller reasoning steps (Wei et al., 2022), or ensembling various generations through modifying decoding steps (Wang et al., 2023) boosts performance. Current methods assume that the input prompt is fixed and expect the decoding strategies to introduce the diversity needed for ensembling. In this work, we relax this assumption and discuss how one can create and leverage variations of the input prompt as a means to diversity of thought to improve model performance. We propose a method that automatically improves prompt diversity by soliciting feedback from the LLM to ideate approaches that fit for the problem. We then ensemble the diverse prompts in our method DIV-SE (DIVerse reasoning path Self-Ensemble) across multiple inference calls. We also propose a cost-effective alternative where diverse prompts are used within a s",
    "path": "papers/23/10/2310.07088.json",
    "total_tokens": 886,
    "translated_title": "思维多样性提升大规模语言模型的推理能力",
    "translated_abstract": "大规模语言模型在需要复杂推理的环境中表现不佳。然而，将模型指导分解问题为更小的推理步骤或通过修改解码步骤使各种生成结果合并可以提升性能。目前的方法都假设输入提示是固定的，并期望解码策略引入所需的多样性。本文放松了这个假设，并讨论了如何通过创建和利用输入提示的变化来提升思维多样性以改善模型性能。我们提出了一种方法，通过向语言模型征求反馈来构思适合问题的方法，从而自动提高提示的多样性。我们在我们的方法DIV-SE (DIVerse reasoning path Self-Ensemble)中对多样的提示进行合成，通过多次推理调用实现。我们还提出了一种经济高效的替代方案，即在一个推理中使用多样的提示。",
    "tldr": "本文提出了一种方法，通过改变输入提示来提高大规模语言模型的推理能力，从而改善模型在复杂推理场景中的表现。这种方法自动采集模型反馈，生成适合问题的多样化提示，并通过多次推理调用来集成这些多样化的提示。"
}