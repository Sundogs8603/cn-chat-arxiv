{
    "title": "3D-Aware Visual Question Answering about Parts, Poses and Occlusions. (arXiv:2310.17914v1 [cs.CV])",
    "abstract": "Despite rapid progress in Visual question answering (VQA), existing datasets and models mainly focus on testing reasoning in 2D. However, it is important that VQA models also understand the 3D structure of visual scenes, for example to support tasks like navigation or manipulation. This includes an understanding of the 3D object pose, their parts and occlusions. In this work, we introduce the task of 3D-aware VQA, which focuses on challenging questions that require a compositional reasoning over the 3D structure of visual scenes. We address 3D-aware VQA from both the dataset and the model perspective. First, we introduce Super-CLEVR-3D, a compositional reasoning dataset that contains questions about object parts, their 3D poses, and occlusions. Second, we propose PO3D-VQA, a 3D-aware VQA model that marries two powerful ideas: probabilistic neural symbolic program execution for reasoning and deep neural networks with 3D generative representations of objects for robust visual recognition",
    "link": "http://arxiv.org/abs/2310.17914",
    "context": "Title: 3D-Aware Visual Question Answering about Parts, Poses and Occlusions. (arXiv:2310.17914v1 [cs.CV])\nAbstract: Despite rapid progress in Visual question answering (VQA), existing datasets and models mainly focus on testing reasoning in 2D. However, it is important that VQA models also understand the 3D structure of visual scenes, for example to support tasks like navigation or manipulation. This includes an understanding of the 3D object pose, their parts and occlusions. In this work, we introduce the task of 3D-aware VQA, which focuses on challenging questions that require a compositional reasoning over the 3D structure of visual scenes. We address 3D-aware VQA from both the dataset and the model perspective. First, we introduce Super-CLEVR-3D, a compositional reasoning dataset that contains questions about object parts, their 3D poses, and occlusions. Second, we propose PO3D-VQA, a 3D-aware VQA model that marries two powerful ideas: probabilistic neural symbolic program execution for reasoning and deep neural networks with 3D generative representations of objects for robust visual recognition",
    "path": "papers/23/10/2310.17914.json",
    "total_tokens": 1010,
    "translated_title": "关于部件、姿态和遮挡的3D感知视觉问答",
    "translated_abstract": "尽管在视觉问答（VQA）领域取得了长足进展，现有的数据集和模型主要集中于2D推理。然而，VQA模型也需要理解视觉场景的3D结构，例如支持导航或操作等任务。这包括对三维物体姿态、部件和遮挡的理解。在本研究中，我们引入了一项名为3D感知VQA的任务，重点关注需要在视觉场景的三维结构上进行组合推理的挑战性问题。我们从数据集和模型两个方面来解决3D感知VQA问题。首先，我们引入了Super-CLEVR-3D，一个包含关于物体部件、它们的三维姿态和遮挡的组合推理数据集。其次，我们提出了PO3D-VQA，一个将两个强大的思想相结合的3D感知VQA模型：用于推理的概率神经符号程序执行和基于物体的三维生成表示的深度神经网络用于强大的视觉识别。",
    "tldr": "这个论文提出了一种名为3D感知VQA的任务，旨在推动VQA模型对于视觉场景的3D结构进行组合推理。作者从数据集和模型角度出发，分别引入了Super-CLEVR-3D数据集和PO3D-VQA模型，并将概率神经符号程序执行和3D生成表示相结合，用于强大的视觉识别。",
    "en_tdlr": "This paper introduces a task called 3D-aware VQA, which aims to promote compositional reasoning over the 3D structure of visual scenes in VQA models. The authors address this task by introducing the Super-CLEVR-3D dataset and the PO3D-VQA model, combining probabilistic neural symbolic program execution with 3D generative representations for robust visual recognition."
}