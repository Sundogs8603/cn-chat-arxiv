{
    "title": "Uncovering hidden geometry in Transformers via disentangling position and context. (arXiv:2310.04861v1 [cs.LG])",
    "abstract": "Transformers are widely used to extract complex semantic meanings from input tokens, yet they usually operate as black-box models. In this paper, we present a simple yet informative decomposition of hidden states (or embeddings) of trained transformers into interpretable components. For any layer, embedding vectors of input sequence samples are represented by a tensor $\\boldsymbol{h} \\in \\mathbb{R}^{C \\times T \\times d}$. Given embedding vector $\\boldsymbol{h}_{c,t} \\in \\mathbb{R}^d$ at sequence position $t \\le T$ in a sequence (or context) $c \\le C$, extracting the mean effects yields the decomposition \\[ \\boldsymbol{h}_{c,t} = \\boldsymbol{\\mu} + \\mathbf{pos}_t + \\mathbf{ctx}_c + \\mathbf{resid}_{c,t} \\] where $\\boldsymbol{\\mu}$ is the global mean vector, $\\mathbf{pos}_t$ and $\\mathbf{ctx}_c$ are the mean vectors across contexts and across positions respectively, and $\\mathbf{resid}_{c,t}$ is the residual vector. For popular transformer architectures and diverse text datasets, empirica",
    "link": "http://arxiv.org/abs/2310.04861",
    "context": "Title: Uncovering hidden geometry in Transformers via disentangling position and context. (arXiv:2310.04861v1 [cs.LG])\nAbstract: Transformers are widely used to extract complex semantic meanings from input tokens, yet they usually operate as black-box models. In this paper, we present a simple yet informative decomposition of hidden states (or embeddings) of trained transformers into interpretable components. For any layer, embedding vectors of input sequence samples are represented by a tensor $\\boldsymbol{h} \\in \\mathbb{R}^{C \\times T \\times d}$. Given embedding vector $\\boldsymbol{h}_{c,t} \\in \\mathbb{R}^d$ at sequence position $t \\le T$ in a sequence (or context) $c \\le C$, extracting the mean effects yields the decomposition \\[ \\boldsymbol{h}_{c,t} = \\boldsymbol{\\mu} + \\mathbf{pos}_t + \\mathbf{ctx}_c + \\mathbf{resid}_{c,t} \\] where $\\boldsymbol{\\mu}$ is the global mean vector, $\\mathbf{pos}_t$ and $\\mathbf{ctx}_c$ are the mean vectors across contexts and across positions respectively, and $\\mathbf{resid}_{c,t}$ is the residual vector. For popular transformer architectures and diverse text datasets, empirica",
    "path": "papers/23/10/2310.04861.json",
    "total_tokens": 939,
    "translated_title": "通过区分位置和上下文来揭示Transformers中的隐藏几何",
    "translated_abstract": "Transformers广泛用于从输入令牌中提取复杂的语义意义，然而它们通常作为黑盒模型运行。本文提出了一种简单而信息丰富的方法，将训练好的transformer的隐藏状态（或嵌入）分解为可解释的组件。对于任何层，输入序列样本的嵌入向量由一个张量表示 $\\boldsymbol{h} \\in \\mathbb{R}^{C \\times T \\times d}$。给定在序列（或上下文） $c \\le C$ 的位置 $t \\le T$ 处的嵌入向量 $\\boldsymbol{h}_{c,t} \\in \\mathbb{R}^d$，提取均值效果得到分解形式 \\[ \\boldsymbol{h}_{c,t} = \\boldsymbol{\\mu} + \\mathbf{pos}_t + \\mathbf{ctx}_c + \\mathbf{resid}_{c,t} \\] 其中 $\\boldsymbol{\\mu}$ 是全局均值向量，$\\mathbf{pos}_t$ 和 $\\mathbf{ctx}_c$ 分别是跨上下文和跨位置的均值向量，$\\mathbf{resid}_{c,t}$ 是残余向量。针对流行的transformer架构和多样的文本数据集，经验结果表明...",
    "tldr": "本文通过分解transformer的隐藏状态，揭示了其在语义理解中的隐含几何结构。",
    "en_tdlr": "This paper uncovers the hidden geometric structure of Transformers in semantic understanding through decomposing their hidden states."
}