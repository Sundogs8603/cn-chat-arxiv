{
    "title": "From Zero to Hero: Detecting Leaked Data through Synthetic Data Injection and Model Querying. (arXiv:2310.04145v1 [cs.LG])",
    "abstract": "Safeguarding the Intellectual Property (IP) of data has become critically important as machine learning applications continue to proliferate, and their success heavily relies on the quality of training data. While various mechanisms exist to secure data during storage, transmission, and consumption, fewer studies have been developed to detect whether they are already leaked for model training without authorization. This issue is particularly challenging due to the absence of information and control over the training process conducted by potential attackers.  In this paper, we concentrate on the domain of tabular data and introduce a novel methodology, Local Distribution Shifting Synthesis (\\textsc{LDSS}), to detect leaked data that are used to train classification models. The core concept behind \\textsc{LDSS} involves injecting a small volume of synthetic data--characterized by local shifts in class distribution--into the owner's dataset. This enables the effective identification of mo",
    "link": "http://arxiv.org/abs/2310.04145",
    "context": "Title: From Zero to Hero: Detecting Leaked Data through Synthetic Data Injection and Model Querying. (arXiv:2310.04145v1 [cs.LG])\nAbstract: Safeguarding the Intellectual Property (IP) of data has become critically important as machine learning applications continue to proliferate, and their success heavily relies on the quality of training data. While various mechanisms exist to secure data during storage, transmission, and consumption, fewer studies have been developed to detect whether they are already leaked for model training without authorization. This issue is particularly challenging due to the absence of information and control over the training process conducted by potential attackers.  In this paper, we concentrate on the domain of tabular data and introduce a novel methodology, Local Distribution Shifting Synthesis (\\textsc{LDSS}), to detect leaked data that are used to train classification models. The core concept behind \\textsc{LDSS} involves injecting a small volume of synthetic data--characterized by local shifts in class distribution--into the owner's dataset. This enables the effective identification of mo",
    "path": "papers/23/10/2310.04145.json",
    "total_tokens": 901,
    "translated_title": "从零到英雄: 通过合成数据注入和模型查询来检测泄露数据",
    "translated_abstract": "随着机器学习应用的不断增多，保护数据的知识产权已变得至关重要，而其成功在很大程度上取决于训练数据的质量。虽然存在各种机制来在存储、传输和使用过程中保护数据，但较少有研究是针对是否已经未经授权地泄露用于模型训练的数据进行检测。由于对潜在攻击者进行的训练过程缺乏信息和控制，这个问题尤为具有挑战性。本文针对表格数据领域，引入了一种新的方法论，局部分布偏移合成（LDSS），用于检测用于训练分类模型的泄露数据。LDSS 的核心概念是向所有者的数据集中注入少量合成数据，其特点是类别分布的局部偏移。这样可以有效识别出模型查询中的泄露数据。",
    "tldr": "本文介绍了一种名为 LDSS 的新方法，用于检测用于训练分类模型的泄露数据。该方法通过注入特征为类别分布的局部偏移的合成数据来实现。这种方法能够有效地识别出模型查询中的泄露数据。"
}