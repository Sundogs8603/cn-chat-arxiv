{
    "title": "Dialogue-based generation of self-driving simulation scenarios using Large Language Models. (arXiv:2310.17372v1 [cs.AI])",
    "abstract": "Simulation is an invaluable tool for developing and evaluating controllers for self-driving cars. Current simulation frameworks are driven by highly-specialist domain specific languages, and so a natural language interface would greatly enhance usability. But there is often a gap, consisting of tacit assumptions the user is making, between a concise English utterance and the executable code that captures the user's intent. In this paper we describe a system that addresses this issue by supporting an extended multimodal interaction: the user can follow up prior instructions with refinements or revisions, in reaction to the simulations that have been generated from their utterances so far. We use Large Language Models (LLMs) to map the user's English utterances in this interaction into domain-specific code, and so we explore the extent to which LLMs capture the context sensitivity that's necessary for computing the speaker's intended message in discourse.",
    "link": "http://arxiv.org/abs/2310.17372",
    "context": "Title: Dialogue-based generation of self-driving simulation scenarios using Large Language Models. (arXiv:2310.17372v1 [cs.AI])\nAbstract: Simulation is an invaluable tool for developing and evaluating controllers for self-driving cars. Current simulation frameworks are driven by highly-specialist domain specific languages, and so a natural language interface would greatly enhance usability. But there is often a gap, consisting of tacit assumptions the user is making, between a concise English utterance and the executable code that captures the user's intent. In this paper we describe a system that addresses this issue by supporting an extended multimodal interaction: the user can follow up prior instructions with refinements or revisions, in reaction to the simulations that have been generated from their utterances so far. We use Large Language Models (LLMs) to map the user's English utterances in this interaction into domain-specific code, and so we explore the extent to which LLMs capture the context sensitivity that's necessary for computing the speaker's intended message in discourse.",
    "path": "papers/23/10/2310.17372.json",
    "total_tokens": 857,
    "translated_title": "基于大型语言模型的对话式生成自动驾驶仿真场景",
    "translated_abstract": "仿真是开发和评估自动驾驶汽车控制器的无价工具。当前的仿真框架基于高度专业的领域特定语言，因此自然语言界面将极大地增加可用性。但是，英文简洁用语和捕捉用户意图的可执行代码之间经常存在一定的隐含假设差距。本文描述了一个系统来解决这个问题，通过支持扩展的多模态交互，用户可以用修正或修改来跟进之前的指令，以对迄今为止从他们的话语生成的仿真作出反应。我们使用大型语言模型（LLMs）将用户的英文话语在这种互动中映射到特定领域的代码，因此我们探索了LLMs能否捕捉到计算发言者在话语中的预期信息所需的上下文敏感性。",
    "tldr": "本文介绍了一个系统，使用大型语言模型将用户的英文话语映射为领域特定代码，以支持对话式生成自动驾驶仿真场景，并探索了语言模型所能捕捉到的上下文敏感性。"
}