{
    "title": "Energy-Based Models For Speech Synthesis. (arXiv:2310.12765v1 [cs.SD])",
    "abstract": "Recently there has been a lot of interest in non-autoregressive (non-AR) models for speech synthesis, such as FastSpeech 2 and diffusion models. Unlike AR models, these models do not have autoregressive dependencies among outputs which makes inference efficient. This paper expands the range of available non-AR models with another member called energy-based models (EBMs). The paper describes how noise contrastive estimation, which relies on the comparison between positive and negative samples, can be used to train EBMs. It proposes a number of strategies for generating effective negative samples, including using high-performing AR models. It also describes how sampling from EBMs can be performed using Langevin Markov Chain Monte-Carlo (MCMC). The use of Langevin MCMC enables to draw connections between EBMs and currently popular diffusion models. Experiments on LJSpeech dataset show that the proposed approach offers improvements over Tacotron 2.",
    "link": "http://arxiv.org/abs/2310.12765",
    "context": "Title: Energy-Based Models For Speech Synthesis. (arXiv:2310.12765v1 [cs.SD])\nAbstract: Recently there has been a lot of interest in non-autoregressive (non-AR) models for speech synthesis, such as FastSpeech 2 and diffusion models. Unlike AR models, these models do not have autoregressive dependencies among outputs which makes inference efficient. This paper expands the range of available non-AR models with another member called energy-based models (EBMs). The paper describes how noise contrastive estimation, which relies on the comparison between positive and negative samples, can be used to train EBMs. It proposes a number of strategies for generating effective negative samples, including using high-performing AR models. It also describes how sampling from EBMs can be performed using Langevin Markov Chain Monte-Carlo (MCMC). The use of Langevin MCMC enables to draw connections between EBMs and currently popular diffusion models. Experiments on LJSpeech dataset show that the proposed approach offers improvements over Tacotron 2.",
    "path": "papers/23/10/2310.12765.json",
    "total_tokens": 903,
    "translated_title": "基于能量的模型用于语音合成",
    "translated_abstract": "最近对于非自回归 (non-AR) 模型在语音合成领域引起了很多关注，比如 FastSpeech 2 和扩散模型。与自回归模型不同的是，这些模型的输出之间没有自回归的依赖关系，这使得推断过程更加高效。本文通过引入基于能量的模型 (EBMs) 来拓展非自回归模型的范围。论文描述了如何使用噪声对比估计来训练基于能量的模型，噪声对比估计依赖于正样本和负样本之间的比较。论文提出了一些生成有效负样本的策略，包括使用表现优秀的自回归模型。论文还描述了如何使用 Langevin Markov Chain Monte-Carlo (MCMC) 从基于能量的模型中进行采样。使用 Langevin MCMC 可以建立基于能量的模型与当前流行的扩散模型之间的联系。在 LJSpeech 数据集上的实验证明，所提出的方法相对于 Tacotron 2 有改进。",
    "tldr": "本文引入了一种新的非自回归模型，即基于能量的模型 (EBMs)，通过噪声对比估计进行训练。该模型可以使用 Langevin MCMC 进行采样，并在语音合成任务中取得了改进。"
}