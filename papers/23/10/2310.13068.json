{
    "title": "GARI: Graph Attention for Relative Isomorphism of Arabic Word Embeddings. (arXiv:2310.13068v1 [cs.CL])",
    "abstract": "Bilingual Lexical Induction (BLI) is a core challenge in NLP, it relies on the relative isomorphism of individual embedding spaces. Existing attempts aimed at controlling the relative isomorphism of different embedding spaces fail to incorporate the impact of semantically related words in the model training objective. To address this, we propose GARI that combines the distributional training objectives with multiple isomorphism losses guided by the graph attention network. GARI considers the impact of semantical variations of words in order to define the relative isomorphism of the embedding spaces. Experimental evaluation using the Arabic language data set shows that GARI outperforms the existing research by improving the average P@1 by a relative score of up to 40.95% and 76.80% for in-domain and domain mismatch settings respectively. We release the codes for GARI at https://github.com/asif6827/GARI.",
    "link": "http://arxiv.org/abs/2310.13068",
    "context": "Title: GARI: Graph Attention for Relative Isomorphism of Arabic Word Embeddings. (arXiv:2310.13068v1 [cs.CL])\nAbstract: Bilingual Lexical Induction (BLI) is a core challenge in NLP, it relies on the relative isomorphism of individual embedding spaces. Existing attempts aimed at controlling the relative isomorphism of different embedding spaces fail to incorporate the impact of semantically related words in the model training objective. To address this, we propose GARI that combines the distributional training objectives with multiple isomorphism losses guided by the graph attention network. GARI considers the impact of semantical variations of words in order to define the relative isomorphism of the embedding spaces. Experimental evaluation using the Arabic language data set shows that GARI outperforms the existing research by improving the average P@1 by a relative score of up to 40.95% and 76.80% for in-domain and domain mismatch settings respectively. We release the codes for GARI at https://github.com/asif6827/GARI.",
    "path": "papers/23/10/2310.13068.json",
    "total_tokens": 901,
    "translated_title": "GARI: 基于图注意力的阿拉伯词嵌入相对同构性研究",
    "translated_abstract": "双语词汇归纳是自然语言处理中的一个核心挑战，它依赖于各个嵌入空间之间的相对同构性。现有的尝试控制不同嵌入空间之间的相对同构性未能在模型训练目标中考虑语义相关单词的影响。为了解决这个问题，我们提出了GARI，它将分布式训练目标与由图注意力网络引导的多个同构性损失相结合。GARI考虑了词汇的语义变化对嵌入空间的相对同构性的定义。在阿拉伯语数据集上进行的实验评估表明，GARI相对于现有研究提高了平均P@1的相对分数，分别为领域内设置下的40.95%和领域不匹配设置下的76.80%。我们在https://github.com/asif6827/GARI上发布了GARI的代码。",
    "tldr": "GARI提出了一种基于图注意力的方法，在相对同构性任务中结合了分布式训练目标和多个同构性损失，考虑了语义相关单词对嵌入空间的影响，并在阿拉伯语数据集上取得了显著性能提升。",
    "en_tdlr": "GARI proposes a graph attention-based approach that combines distributional training objectives with multiple isomorphism losses, taking into account the impact of semantically related words on the embedding spaces, and achieves significant performance improvement on an Arabic language dataset."
}