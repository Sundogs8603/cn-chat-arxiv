{
    "title": "Compositional preference models for aligning LMs. (arXiv:2310.13011v1 [cs.CL])",
    "abstract": "As language models (LMs) become more capable, it is increasingly important to align them with human preferences. However, the dominant paradigm for training Preference Models (PMs) for that purpose suffers from fundamental limitations, such as lack of transparency and scalability, along with susceptibility to overfitting the preference dataset. We propose Compositional Preference Models (CPMs), a novel PM framework that decomposes one global preference assessment into several interpretable features, obtains scalar scores for these features from a prompted LM, and aggregates these scores using a logistic regression classifier. CPMs allow to control which properties of the preference data are used to train the preference model and to build it based on features that are believed to underlie the human preference judgment. Our experiments show that CPMs not only improve generalization and are more robust to overoptimization than standard PMs, but also that best-of-n samples obtained using C",
    "link": "http://arxiv.org/abs/2310.13011",
    "context": "Title: Compositional preference models for aligning LMs. (arXiv:2310.13011v1 [cs.CL])\nAbstract: As language models (LMs) become more capable, it is increasingly important to align them with human preferences. However, the dominant paradigm for training Preference Models (PMs) for that purpose suffers from fundamental limitations, such as lack of transparency and scalability, along with susceptibility to overfitting the preference dataset. We propose Compositional Preference Models (CPMs), a novel PM framework that decomposes one global preference assessment into several interpretable features, obtains scalar scores for these features from a prompted LM, and aggregates these scores using a logistic regression classifier. CPMs allow to control which properties of the preference data are used to train the preference model and to build it based on features that are believed to underlie the human preference judgment. Our experiments show that CPMs not only improve generalization and are more robust to overoptimization than standard PMs, but also that best-of-n samples obtained using C",
    "path": "papers/23/10/2310.13011.json",
    "total_tokens": 918,
    "translated_title": "用于对齐语言模型的组合偏好模型",
    "translated_abstract": "随着语言模型的能力越来越强，将其与人类偏好进行对齐变得越来越重要。然而，用于训练偏好模型的主流范式存在根本性的限制，例如缺乏透明度和可扩展性，以及对偏好数据集过拟合的敏感性。我们提出了组合偏好模型（CPMs），这是一个新颖的偏好模型框架，将一个全局偏好评估分解为多个可解释的特征，从一个提示的语言模型中获取这些特征的标量评分，并使用逻辑回归分类器聚合这些评分。CPMs允许控制从偏好数据中使用哪些属性来训练偏好模型，并基于被认为是人类偏好判断基础的特征构建模型。我们的实验表明，CPMs不仅改善了泛化能力，比标准偏好模型更具鲁棒性，并且使用CPMs获得的最佳n个样本比使用标准PMs的表现更好。",
    "tldr": "用于对齐语言模型的组合偏好模型（CPMs）是一种新颖的偏好模型框架，可以分解全局偏好评估并根据可解释的特征进行标量评分，得到更好的泛化能力和鲁棒性。"
}