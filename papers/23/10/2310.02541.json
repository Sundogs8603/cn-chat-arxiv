{
    "title": "Benign Overfitting and Grokking in ReLU Networks for XOR Cluster Data. (arXiv:2310.02541v1 [cs.LG])",
    "abstract": "Neural networks trained by gradient descent (GD) have exhibited a number of surprising generalization behaviors. First, they can achieve a perfect fit to noisy training data and still generalize near-optimally, showing that overfitting can sometimes be benign. Second, they can undergo a period of classical, harmful overfitting -- achieving a perfect fit to training data with near-random performance on test data -- before transitioning (\"grokking\") to near-optimal generalization later in training. In this work, we show that both of these phenomena provably occur in two-layer ReLU networks trained by GD on XOR cluster data where a constant fraction of the training labels are flipped. In this setting, we show that after the first step of GD, the network achieves 100% training accuracy, perfectly fitting the noisy labels in the training data, but achieves near-random test accuracy. At a later training step, the network achieves near-optimal test accuracy while still fitting the random labe",
    "link": "http://arxiv.org/abs/2310.02541",
    "context": "Title: Benign Overfitting and Grokking in ReLU Networks for XOR Cluster Data. (arXiv:2310.02541v1 [cs.LG])\nAbstract: Neural networks trained by gradient descent (GD) have exhibited a number of surprising generalization behaviors. First, they can achieve a perfect fit to noisy training data and still generalize near-optimally, showing that overfitting can sometimes be benign. Second, they can undergo a period of classical, harmful overfitting -- achieving a perfect fit to training data with near-random performance on test data -- before transitioning (\"grokking\") to near-optimal generalization later in training. In this work, we show that both of these phenomena provably occur in two-layer ReLU networks trained by GD on XOR cluster data where a constant fraction of the training labels are flipped. In this setting, we show that after the first step of GD, the network achieves 100% training accuracy, perfectly fitting the noisy labels in the training data, but achieves near-random test accuracy. At a later training step, the network achieves near-optimal test accuracy while still fitting the random labe",
    "path": "papers/23/10/2310.02541.json",
    "total_tokens": 992,
    "translated_title": "针对XOR集群数据中的ReLU网络的良性过拟合和理解",
    "translated_abstract": "通过梯度下降(GD)训练的神经网络展现了许多令人惊讶的泛化行为。首先，它们可以对噪声训练数据实现完美拟合，并且仍然能够近乎最优地进行泛化，表明过拟合有时可能是良性的。其次，在训练的早期阶段，它们可能会经历一段经典且有害的过拟合期，即在训练数据上实现完美拟合但在测试数据上表现随机，随后过渡到近乎最优的泛化行为（即“理解”）。在这项工作中，我们证明了这两个现象在通过GD对XOR集群数据上的两层ReLU网络进行训练时确实会出现，其中训练标签的一部分会被翻转。我们发现在GD的第一步之后，神经网络能够实现100%的训练准确度，在训练数据中完美拟合噪声标签，但在测试上表现接近随机。在随后的训练步骤中，网络能够实现近乎最优的测试准确度，同时仍然拟合随机标签。",
    "tldr": "通过梯度下降训练的ReLU网络在XOR集群数据上会产生良性过拟合和理解现象，即在训练阶段实现噪声标签的完美拟合但在测试阶段表现随机，在后续阶段可以实现近乎最优的泛化能力。"
}