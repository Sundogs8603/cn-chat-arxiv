{
    "title": "Teaching Language Models to Hallucinate Less with Synthetic Tasks. (arXiv:2310.06827v2 [cs.CL] UPDATED)",
    "abstract": "Large language models (LLMs) frequently hallucinate on abstractive summarization tasks such as document-based question-answering, meeting summarization, and clinical report generation, even though all necessary information is included in context. However, optimizing LLMs to hallucinate less on these tasks is challenging, as hallucination is hard to efficiently evaluate at each optimization step. In this work, we show that reducing hallucination on a synthetic task can also reduce hallucination on real-world downstream tasks. Our method, SynTra, first designs a synthetic task where hallucinations are easy to elicit and measure. It next optimizes the LLM's system message via prefix-tuning on the synthetic task, and finally transfers the system message to realistic, hard-to-optimize tasks. Across three realistic abstractive summarization tasks, SynTra reduces hallucination for two 13B-parameter LLMs using only a synthetic retrieval task for supervision. We also find that optimizing the sy",
    "link": "http://arxiv.org/abs/2310.06827",
    "context": "Title: Teaching Language Models to Hallucinate Less with Synthetic Tasks. (arXiv:2310.06827v2 [cs.CL] UPDATED)\nAbstract: Large language models (LLMs) frequently hallucinate on abstractive summarization tasks such as document-based question-answering, meeting summarization, and clinical report generation, even though all necessary information is included in context. However, optimizing LLMs to hallucinate less on these tasks is challenging, as hallucination is hard to efficiently evaluate at each optimization step. In this work, we show that reducing hallucination on a synthetic task can also reduce hallucination on real-world downstream tasks. Our method, SynTra, first designs a synthetic task where hallucinations are easy to elicit and measure. It next optimizes the LLM's system message via prefix-tuning on the synthetic task, and finally transfers the system message to realistic, hard-to-optimize tasks. Across three realistic abstractive summarization tasks, SynTra reduces hallucination for two 13B-parameter LLMs using only a synthetic retrieval task for supervision. We also find that optimizing the sy",
    "path": "papers/23/10/2310.06827.json",
    "total_tokens": 886,
    "translated_title": "使用合成任务教授语言模型更少幻觉",
    "translated_abstract": "大型语言模型（LLMs）在抽象概括任务（如基于文档的问答、会议概述和临床报告生成）中经常产生幻觉，即使所有必要信息都在上下文中。然而，在这些任务上优化LLMs以减少幻觉是具有挑战性的，因为在每个优化步骤中有效评估幻觉是困难的。在这项工作中，我们展示了通过减少合成任务上的幻觉也可以减少现实世界下游任务上的幻觉。我们的方法，SynTra，首先设计了一个合成任务，其中易于诱发和衡量幻觉。然后，通过对合成任务进行前缀调优来优化LLM的系统消息，并最终将系统消息转移到现实中难以优化的任务中。通过对三个现实的抽象概括任务，使用仅合成检索任务进行监督，SynTra减少了两个具有13B参数的LLMs的幻觉。我们还发现通过优化合成任务上的系统消息，可以最大限度地减少现实任务上的幻觉。",
    "tldr": "通过设计合成任务，我们的研究表明减少合成任务上的幻觉可以帮助减少现实世界的抽象概括任务上的幻觉。",
    "en_tdlr": "Our research shows that reducing hallucinations on synthetic tasks can help reduce hallucinations on real-world abstractive summarization tasks."
}