{
    "title": "Learning to Explain: A Model-Agnostic Framework for Explaining Black Box Models. (arXiv:2310.16584v1 [cs.CV])",
    "abstract": "We present Learning to Explain (LTX), a model-agnostic framework designed for providing post-hoc explanations for vision models. The LTX framework introduces an \"explainer\" model that generates explanation maps, highlighting the crucial regions that justify the predictions made by the model being explained. To train the explainer, we employ a two-stage process consisting of initial pretraining followed by per-instance finetuning. During both stages of training, we utilize a unique configuration where we compare the explained model's prediction for a masked input with its original prediction for the unmasked input. This approach enables the use of a novel counterfactual objective, which aims to anticipate the model's output using masked versions of the input image. Importantly, the LTX framework is not restricted to a specific model architecture and can provide explanations for both Transformer-based and convolutional models. Through our evaluations, we demonstrate that LTX significantl",
    "link": "http://arxiv.org/abs/2310.16584",
    "context": "Title: Learning to Explain: A Model-Agnostic Framework for Explaining Black Box Models. (arXiv:2310.16584v1 [cs.CV])\nAbstract: We present Learning to Explain (LTX), a model-agnostic framework designed for providing post-hoc explanations for vision models. The LTX framework introduces an \"explainer\" model that generates explanation maps, highlighting the crucial regions that justify the predictions made by the model being explained. To train the explainer, we employ a two-stage process consisting of initial pretraining followed by per-instance finetuning. During both stages of training, we utilize a unique configuration where we compare the explained model's prediction for a masked input with its original prediction for the unmasked input. This approach enables the use of a novel counterfactual objective, which aims to anticipate the model's output using masked versions of the input image. Importantly, the LTX framework is not restricted to a specific model architecture and can provide explanations for both Transformer-based and convolutional models. Through our evaluations, we demonstrate that LTX significantl",
    "path": "papers/23/10/2310.16584.json",
    "total_tokens": 849,
    "translated_title": "学会解释：一个无关模型的用于解释黑盒模型的框架",
    "translated_abstract": "我们提出了学会解释（LTX），这是一个为视觉模型提供事后解释的无关模型的框架。LTX框架引入了一个“解释器”模型，生成解释地图，突出显示解释模型所做预测的关键区域。为了训练解释器，我们采用了一个两阶段过程，包括初始预训练和每个实例微调。在训练的两个阶段中，我们利用了一种独特的配置，将解释模型对被屏蔽输入的预测与对未屏蔽输入的原始预测进行比较。这种方法使得可以使用一种新颖的反事实目标，通过使用输入图像的屏蔽版本来预测模型的输出。值得注意的是，LTX框架不限定于特定的模型架构，并且可以为基于Transformer和卷积模型的模型提供解释。通过评估，我们证明LTX signi",
    "tldr": "Learning to Explain is a model-agnostic framework that provides post-hoc explanations for vision models. It introduces an \"explainer\" model to generate explanation maps, highlighting crucial regions. The framework can be used with different model architectures and provides explanations for both Transformer-based and convolutional models.",
    "en_tdlr": "Learning to Explain is a model-agnostic framework that generates explanation maps for vision models, highlighting crucial regions, and works with various model architectures."
}