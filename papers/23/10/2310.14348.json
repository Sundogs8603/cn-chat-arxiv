{
    "title": "DePAint: A Decentralized Safe Multi-Agent Reinforcement Learning Algorithm considering Peak and Average Constraints. (arXiv:2310.14348v1 [cs.MA])",
    "abstract": "The field of safe multi-agent reinforcement learning, despite its potential applications in various domains such as drone delivery and vehicle automation, remains relatively unexplored. Training agents to learn optimal policies that maximize rewards while considering specific constraints can be challenging, particularly in scenarios where having a central controller to coordinate the agents during the training process is not feasible. In this paper, we address the problem of multi-agent policy optimization in a decentralized setting, where agents communicate with their neighbors to maximize the sum of their cumulative rewards while also satisfying each agent's safety constraints. We consider both peak and average constraints. In this scenario, there is no central controller coordinating the agents and both the rewards and constraints are only known to each agent locally/privately. We formulate the problem as a decentralized constrained multi-agent Markov Decision Problem and propose a ",
    "link": "http://arxiv.org/abs/2310.14348",
    "context": "Title: DePAint: A Decentralized Safe Multi-Agent Reinforcement Learning Algorithm considering Peak and Average Constraints. (arXiv:2310.14348v1 [cs.MA])\nAbstract: The field of safe multi-agent reinforcement learning, despite its potential applications in various domains such as drone delivery and vehicle automation, remains relatively unexplored. Training agents to learn optimal policies that maximize rewards while considering specific constraints can be challenging, particularly in scenarios where having a central controller to coordinate the agents during the training process is not feasible. In this paper, we address the problem of multi-agent policy optimization in a decentralized setting, where agents communicate with their neighbors to maximize the sum of their cumulative rewards while also satisfying each agent's safety constraints. We consider both peak and average constraints. In this scenario, there is no central controller coordinating the agents and both the rewards and constraints are only known to each agent locally/privately. We formulate the problem as a decentralized constrained multi-agent Markov Decision Problem and propose a ",
    "path": "papers/23/10/2310.14348.json",
    "total_tokens": 927,
    "translated_title": "DePAint：考虑峰值和平均限制的分散安全多智能体强化学习算法",
    "translated_abstract": "安全的多智能体强化学习领域，尽管在无人机投递和车辆自动化等各个领域具有潜在应用，但仍然相对未被探索。在训练智能体学习最优策略以最大化奖励的同时考虑特定限制，特别是在训练过程中无法有中央控制器协调智能体的场景中，可能具有挑战性。本文针对分散环境下的多智能体策略优化问题进行了研究，其中智能体通过与邻居通信以最大化其累积奖励总和的同时满足每个智能体的安全约束。我们同时考虑了峰值和平均限制。在这种情况下，没有中央控制器协调智能体，奖励和约束只在每个智能体本地/私有可知。我们将问题形式化为分散约束的多智能体马尔可夫决策问题，并提出了一个算法。",
    "tldr": "本文提出了一种分散的安全多智能体强化学习算法，能够在没有中央控制器的情况下，通过智能体之间的邻居通信来最大化累积奖励总和，并同时满足每个智能体的安全约束限制。"
}