{
    "title": "StyleBART: Decorate Pretrained Model with Style Adapters for Unsupervised Stylistic Headline Generation. (arXiv:2310.17743v1 [cs.CL])",
    "abstract": "Stylistic headline generation is the task to generate a headline that not only summarizes the content of an article, but also reflects a desired style that attracts users. As style-specific article-headline pairs are scarce, previous researches focus on unsupervised approaches with a standard headline generation dataset and mono-style corpora. In this work, we follow this line and propose StyleBART, an unsupervised approach for stylistic headline generation. Our method decorates the pretrained BART model with adapters that are responsible for different styles and allows the generation of headlines with diverse styles by simply switching the adapters. Different from previous works, StyleBART separates the task of style learning and headline generation, making it possible to freely combine the base model and the style adapters during inference. We further propose an inverse paraphrasing task to enhance the style adapters. Extensive automatic and human evaluations show that StyleBART achi",
    "link": "http://arxiv.org/abs/2310.17743",
    "context": "Title: StyleBART: Decorate Pretrained Model with Style Adapters for Unsupervised Stylistic Headline Generation. (arXiv:2310.17743v1 [cs.CL])\nAbstract: Stylistic headline generation is the task to generate a headline that not only summarizes the content of an article, but also reflects a desired style that attracts users. As style-specific article-headline pairs are scarce, previous researches focus on unsupervised approaches with a standard headline generation dataset and mono-style corpora. In this work, we follow this line and propose StyleBART, an unsupervised approach for stylistic headline generation. Our method decorates the pretrained BART model with adapters that are responsible for different styles and allows the generation of headlines with diverse styles by simply switching the adapters. Different from previous works, StyleBART separates the task of style learning and headline generation, making it possible to freely combine the base model and the style adapters during inference. We further propose an inverse paraphrasing task to enhance the style adapters. Extensive automatic and human evaluations show that StyleBART achi",
    "path": "papers/23/10/2310.17743.json",
    "total_tokens": 990,
    "translated_title": "StyleBART: 使用风格适配器装饰预训练模型进行无监督风格化标题生成",
    "translated_abstract": "风格化标题生成任务是生成一个既总结文章内容又反映所需风格来吸引用户的标题。由于风格特定的文章-标题对非常稀缺，先前的研究主要关注于使用标准标题生成数据集和单一风格语料库进行无监督方法。在本研究中，我们遵循这一路线，并提出了StyleBART，一种无监督的风格化标题生成方法。我们的方法使用适配器将预训练的BART模型装饰起来，适配器负责不同的风格，通过简单地切换适配器，可以生成具有多样风格的标题。与之前的工作不同，StyleBART将风格学习和标题生成的任务分离开来，在推理过程中可以自由组合基础模型和风格适配器。我们进一步提出了一个逆向改写任务以增强风格适配器的效果。广泛的自动和人工评估结果表明，StyleBART取得了很好的性能。",
    "tldr": "StyleBART是一种无监督的风格化标题生成方法，通过使用适配器来装饰预训练模型，可以生成具有多样风格的标题。与其他方法不同，StyleBART将风格学习和标题生成任务分离开来，在推理过程中可以自由组合基础模型和风格适配器。经过广泛的评估，StyleBART表现出了优秀的性能。"
}