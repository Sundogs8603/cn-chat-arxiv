{
    "title": "Toward Joint Language Modeling for Speech Units and Text. (arXiv:2310.08715v1 [cs.CL])",
    "abstract": "Speech and text are two major forms of human language. The research community has been focusing on mapping speech to text or vice versa for many years. However, in the field of language modeling, very little effort has been made to model them jointly. In light of this, we explore joint language modeling for speech units and text. Specifically, we compare different speech tokenizers to transform continuous speech signals into discrete units and use different methods to construct mixed speech-text data. We introduce automatic metrics to evaluate how well the joint LM mixes speech and text. We also fine-tune the LM on downstream spoken language understanding (SLU) tasks with different modalities (speech or text) and test its performance to assess the model's learning of shared representations. Our results show that by mixing speech units and text with our proposed mixing techniques, the joint LM improves over a speech-only baseline on SLU tasks and shows zero-shot cross-modal transferabil",
    "link": "http://arxiv.org/abs/2310.08715",
    "context": "Title: Toward Joint Language Modeling for Speech Units and Text. (arXiv:2310.08715v1 [cs.CL])\nAbstract: Speech and text are two major forms of human language. The research community has been focusing on mapping speech to text or vice versa for many years. However, in the field of language modeling, very little effort has been made to model them jointly. In light of this, we explore joint language modeling for speech units and text. Specifically, we compare different speech tokenizers to transform continuous speech signals into discrete units and use different methods to construct mixed speech-text data. We introduce automatic metrics to evaluate how well the joint LM mixes speech and text. We also fine-tune the LM on downstream spoken language understanding (SLU) tasks with different modalities (speech or text) and test its performance to assess the model's learning of shared representations. Our results show that by mixing speech units and text with our proposed mixing techniques, the joint LM improves over a speech-only baseline on SLU tasks and shows zero-shot cross-modal transferabil",
    "path": "papers/23/10/2310.08715.json",
    "total_tokens": 904,
    "translated_title": "迈向语音单元和文本的联合语言建模",
    "translated_abstract": "语音和文本是人类语言的两种主要形式。研究界多年来一直在关注将语音映射到文本或者反之亦然。然而，在语言建模领域，很少有人尝试联合建模这两者。基于此，我们探索了语音单元和文本的联合语言建模。具体而言，我们比较了不同的语音分词工具，将连续的语音信号转化为离散的单元，并使用不同的方法构建混合的语音-文本数据。我们引入了自动指标来评估联合语言建模的语音和文本融合效果。我们还使用不同的模态（语音或文本）在下游的口语理解任务上对联合语言模型进行了微调，并测试其性能以评估模型对共享表示的学习能力。我们的结果表明，在使用我们提出的混合技术将语音单元和文本混合的情况下，联合语言模型在口语理解任务上优于仅使用语音的基线模型，并展示了零-shot的跨模态迁移能力。",
    "tldr": "本文研究了联合语言建模中语音单元和文本的混合方法，并通过口语理解任务评估了模型的性能，结果表明混合语言模型优于仅使用语音的基线模型。",
    "en_tdlr": "This paper explores joint language modeling for speech units and text, proposing mixing techniques to combine them and evaluating the model's performance on spoken language understanding tasks. The results show that the joint language model outperforms the speech-only baseline model."
}