{
    "title": "Generative retrieval-augmented ontologic graph and multi-agent strategies for interpretive large language model-based materials design. (arXiv:2310.19998v1 [cs.CL])",
    "abstract": "Transformer neural networks show promising capabilities, in particular for uses in materials analysis, design and manufacturing, including their capacity to work effectively with both human language, symbols, code, and numerical data. Here we explore the use of large language models (LLMs) as a tool that can support engineering analysis of materials, applied to retrieving key information about subject areas, developing research hypotheses, discovery of mechanistic relationships across disparate areas of knowledge, and writing and executing simulation codes for active knowledge generation based on physical ground truths. When used as sets of AI agents with specific features, capabilities, and instructions, LLMs can provide powerful problem solution strategies for applications in analysis and design problems. Our experiments focus on using a fine-tuned model, MechGPT, developed based on training data in the mechanics of materials domain. We first affirm how finetuning endows LLMs with re",
    "link": "http://arxiv.org/abs/2310.19998",
    "context": "Title: Generative retrieval-augmented ontologic graph and multi-agent strategies for interpretive large language model-based materials design. (arXiv:2310.19998v1 [cs.CL])\nAbstract: Transformer neural networks show promising capabilities, in particular for uses in materials analysis, design and manufacturing, including their capacity to work effectively with both human language, symbols, code, and numerical data. Here we explore the use of large language models (LLMs) as a tool that can support engineering analysis of materials, applied to retrieving key information about subject areas, developing research hypotheses, discovery of mechanistic relationships across disparate areas of knowledge, and writing and executing simulation codes for active knowledge generation based on physical ground truths. When used as sets of AI agents with specific features, capabilities, and instructions, LLMs can provide powerful problem solution strategies for applications in analysis and design problems. Our experiments focus on using a fine-tuned model, MechGPT, developed based on training data in the mechanics of materials domain. We first affirm how finetuning endows LLMs with re",
    "path": "papers/23/10/2310.19998.json",
    "total_tokens": 1004,
    "translated_title": "通过生成检索增强本体图和多智能体策略，解释性基于大型语言模型的材料设计",
    "translated_abstract": "Transformer神经网络显示出非常有希望的能力，特别是在材料分析、设计和制造方面的应用，包括它们有效地处理人类语言、符号、代码和数值数据的能力。在本文中，我们探讨了使用大型语言模型（LLM）作为支持材料工程分析的工具，用于检索有关主题领域的关键信息、开发研究假设、发现知识不同领域之间的机制关系，并根据物理基本事实编写和执行仿真代码进行主动知识生成。当LLMs被用作具有特定特征、能力和指令的AI代理集合时，它们可以为分析和设计问题提供强大的问题解决策略。我们的实验重点是使用在材料力学领域的训练数据基础上开发的Fine-tuned模型MechGPT。我们首先证实了Fine-tuning如何赋予LLMs重新调整参数的能力。",
    "tldr": "本文探索了使用大型语言模型（LLMs）作为工具在材料工程分析中的应用。LLMs可以用作一组具有特定特征、能力和指令的人工智能代理，为分析和设计问题提供强大的问题解决策略。实验重点是使用经过微调的模型MechGPT，在材料力学领域进行训练。通过Fine-tuning重新调整参数，增强了LLMs的能力。",
    "en_tdlr": "This paper explores the use of large language models (LLMs) as a tool for materials engineering analysis. LLMs can serve as a set of AI agents with specific features, capabilities, and instructions, providing powerful problem-solving strategies for analysis and design problems. The experiments focus on using a fine-tuned model, MechGPT, trained in the field of materials mechanics. The capability of LLMs is enhanced through fine-tuning of parameters."
}