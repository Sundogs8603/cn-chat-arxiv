{
    "title": "Training Generative Question-Answering on Synthetic Data Obtained from an Instruct-tuned Mo. (arXiv:2310.08072v1 [cs.CL])",
    "abstract": "This paper presents a simple and cost-effective method for synthesizing data to train question-answering systems. For training, fine-tuning GPT models is a common practice in resource-rich languages like English, however, it becomes challenging for non-English languages due to the scarcity of sufficient question-answer (QA) pairs. Existing approaches use question and answer generators trained on human-authored QA pairs, which involves substantial human expenses. In contrast, we use an instruct-tuned model to generate QA pairs in a zero-shot or few-shot manner. We conduct experiments to compare various strategies for obtaining QA pairs from the instruct-tuned model. The results demonstrate that a model trained on our proposed synthetic data achieves comparable performance to a model trained on manually curated datasets, without incurring human costs.",
    "link": "http://arxiv.org/abs/2310.08072",
    "context": "Title: Training Generative Question-Answering on Synthetic Data Obtained from an Instruct-tuned Mo. (arXiv:2310.08072v1 [cs.CL])\nAbstract: This paper presents a simple and cost-effective method for synthesizing data to train question-answering systems. For training, fine-tuning GPT models is a common practice in resource-rich languages like English, however, it becomes challenging for non-English languages due to the scarcity of sufficient question-answer (QA) pairs. Existing approaches use question and answer generators trained on human-authored QA pairs, which involves substantial human expenses. In contrast, we use an instruct-tuned model to generate QA pairs in a zero-shot or few-shot manner. We conduct experiments to compare various strategies for obtaining QA pairs from the instruct-tuned model. The results demonstrate that a model trained on our proposed synthetic data achieves comparable performance to a model trained on manually curated datasets, without incurring human costs.",
    "path": "papers/23/10/2310.08072.json",
    "total_tokens": 857,
    "translated_title": "从训练模型生成的合成数据中训练生成式问答系统的方法",
    "translated_abstract": "本文提出了一种简单且经济的方法来合成数据以训练问答系统。在资源充足的英语等语言中，调整GPT模型是一种常见的训练方法，但是在非英语语言中由于缺乏足够的问答对，这变得具有挑战性。现有的方法使用在人类作者的问答对上训练的问答生成模型，这涉及相当大的人力成本。相反，我们使用一个调整指导模型以零样本或少量样本的方式生成问答对。我们进行了实验，比较了从指导模型获取问答对的各种策略。结果表明，使用我们提出的合成数据训练的模型在性能上与在手动整理的数据集上训练的模型相当，而无需承担人力成本。",
    "tldr": "本文提出了一种在非英语语言中训练问答系统的简单且经济的方法，使用调整指导模型生成合成数据，避免了人力成本，并展示了合成数据训练的模型与手动整理的数据集训练的模型在性能上的可比较性。",
    "en_tdlr": "This paper proposes a simple and cost-effective method to train question-answering systems in non-English languages by using an instruct-tuned model to generate synthetic data, avoiding human costs, and demonstrates the comparable performance of the model trained on synthetic data to the one trained on manually curated datasets."
}