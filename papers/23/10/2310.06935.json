{
    "title": "Quantum Shadow Gradient Descent for Quantum Learning. (arXiv:2310.06935v1 [quant-ph])",
    "abstract": "This paper proposes a new procedure called quantum shadow gradient descent (QSGD) that addresses these key challenges. Our method has the benefits of a one-shot approach, in not requiring any sample duplication while having a convergence rate comparable to the ideal update rule using exact gradient computation. We propose a new technique for generating quantum shadow samples (QSS), which generates quantum shadows as opposed to classical shadows used in existing works. With classical shadows, the computations are typically performed on classical computers and, hence, are prohibitive since the dimension grows exponentially. Our approach resolves this issue by measurements of quantum shadows. As the second main contribution, we study more general non-product ansatz of the form $\\exp\\{i\\sum_j \\theta_j A_j\\}$ that model variational Hamiltonians. We prove that the gradient can be written in terms of the gradient of single-parameter ansatzes that can be easily measured. Our proof is based on ",
    "link": "http://arxiv.org/abs/2310.06935",
    "context": "Title: Quantum Shadow Gradient Descent for Quantum Learning. (arXiv:2310.06935v1 [quant-ph])\nAbstract: This paper proposes a new procedure called quantum shadow gradient descent (QSGD) that addresses these key challenges. Our method has the benefits of a one-shot approach, in not requiring any sample duplication while having a convergence rate comparable to the ideal update rule using exact gradient computation. We propose a new technique for generating quantum shadow samples (QSS), which generates quantum shadows as opposed to classical shadows used in existing works. With classical shadows, the computations are typically performed on classical computers and, hence, are prohibitive since the dimension grows exponentially. Our approach resolves this issue by measurements of quantum shadows. As the second main contribution, we study more general non-product ansatz of the form $\\exp\\{i\\sum_j \\theta_j A_j\\}$ that model variational Hamiltonians. We prove that the gradient can be written in terms of the gradient of single-parameter ansatzes that can be easily measured. Our proof is based on ",
    "path": "papers/23/10/2310.06935.json",
    "total_tokens": 862,
    "translated_title": "量子阴影梯度下降算法用于量子学习",
    "translated_abstract": "本文提出了一种称为量子阴影梯度下降（QSGD）的新方法，解决了关键挑战。我们的方法具有一次性操作的优点，不需要任何样本复制，同时具有与使用精确梯度计算的理想更新规则相当的收敛速度。我们提出了一种生成量子阴影样本（QSS）的新技术，生成量子阴影而不是现有工作中使用的经典阴影。通过测量量子阴影，我们解决了在经典计算机上执行计算时因维度呈指数增长而导致的限制问题。作为第二个主要贡献，我们研究了更一般的非乘积形式的模拟变分哈密顿量，形式为$\\exp\\{i\\sum_j \\theta_j A_j\\}$。我们证明了梯度可以用易于测量的单参数模拟态的梯度来表示。",
    "tldr": "本文提出了一种称为量子阴影梯度下降的新方法，解决了量子学习中的关键挑战，并通过测量量子阴影样本和模拟态的梯度来提高计算效率。",
    "en_tdlr": "This paper proposes a new method called quantum shadow gradient descent (QSGD) to address the key challenges in quantum learning, and improves computational efficiency by measuring quantum shadow samples and gradient of the ansatz."
}