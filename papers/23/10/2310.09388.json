{
    "title": "CORN: Co-Trained Full-Reference And No-Reference Audio Metrics. (arXiv:2310.09388v1 [eess.AS])",
    "abstract": "Perceptual evaluation constitutes a crucial aspect of various audio-processing tasks. Full reference (FR) or similarity-based metrics rely on high-quality reference recordings, to which lower-quality or corrupted versions of the recording may be compared for evaluation. In contrast, no-reference (NR) metrics evaluate a recording without relying on a reference. Both the FR and NR approaches exhibit advantages and drawbacks relative to each other. In this paper, we present a novel framework called CORN that amalgamates these dual approaches, concurrently training both FR and NR models together. After training, the models can be applied independently. We evaluate CORN by predicting several common objective metrics and across two different architectures. The NR model trained using CORN has access to a reference recording during training, and thus, as one would expect, it consistently outperforms baseline NR models trained independently. Perhaps even more remarkable is that the CORN FR mode",
    "link": "http://arxiv.org/abs/2310.09388",
    "context": "Title: CORN: Co-Trained Full-Reference And No-Reference Audio Metrics. (arXiv:2310.09388v1 [eess.AS])\nAbstract: Perceptual evaluation constitutes a crucial aspect of various audio-processing tasks. Full reference (FR) or similarity-based metrics rely on high-quality reference recordings, to which lower-quality or corrupted versions of the recording may be compared for evaluation. In contrast, no-reference (NR) metrics evaluate a recording without relying on a reference. Both the FR and NR approaches exhibit advantages and drawbacks relative to each other. In this paper, we present a novel framework called CORN that amalgamates these dual approaches, concurrently training both FR and NR models together. After training, the models can be applied independently. We evaluate CORN by predicting several common objective metrics and across two different architectures. The NR model trained using CORN has access to a reference recording during training, and thus, as one would expect, it consistently outperforms baseline NR models trained independently. Perhaps even more remarkable is that the CORN FR mode",
    "path": "papers/23/10/2310.09388.json",
    "total_tokens": 897,
    "translated_title": "CORN: 全参考和非参考音频度量的共训练模型",
    "translated_abstract": "感知评估是各种音频处理任务中至关重要的方面。全参考（FR）或基于相似性的度量依赖于高质量的参考录音，将其与录音的低质量或损坏版本进行比较以进行评估。相反，非参考（NR）度量评估录音而不依赖参考。FR和NR两种方法相对于彼此都具有优势和缺点。本文中，我们提出了一种新颖的框架称为CORN，将这两种方法结合起来，同时训练FR和NR模型。训练完成后，可以独立应用这些模型。我们通过预测几个常见的客观度量指标以及在两种不同架构上进行评估CORN。使用CORN训练的NR模型在训练期间可以访问参考录音，因此可以预期，它始终优于独立训练的基线NR模型。更令人印象深刻的是CORN FR模式可以同时提供全参考和非参考度量的性能。",
    "tldr": "CORN是一个新颖的框架，将全参考和非参考音频度量结合起来，并尝试在训练时同时训练这两种模型。CORN FR模式同时具备全参考和非参考度量的性能。",
    "en_tdlr": "CORN is a novel framework that combines full-reference and no-reference audio metrics, training both models simultaneously. The FR mode of CORN achieves performance in both full-reference and no-reference metrics."
}