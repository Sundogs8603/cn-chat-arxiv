{
    "title": "A Comparative Study of Pre-trained CNNs and GRU-Based Attention for Image Caption Generation. (arXiv:2310.07252v1 [cs.CV])",
    "abstract": "Image captioning is a challenging task involving generating a textual description for an image using computer vision and natural language processing techniques. This paper proposes a deep neural framework for image caption generation using a GRU-based attention mechanism. Our approach employs multiple pre-trained convolutional neural networks as the encoder to extract features from the image and a GRU-based language model as the decoder to generate descriptive sentences. To improve performance, we integrate the Bahdanau attention model with the GRU decoder to enable learning to focus on specific image parts. We evaluate our approach using the MSCOCO and Flickr30k datasets and show that it achieves competitive scores compared to state-of-the-art methods. Our proposed framework can bridge the gap between computer vision and natural language and can be extended to specific domains.",
    "link": "http://arxiv.org/abs/2310.07252",
    "context": "Title: A Comparative Study of Pre-trained CNNs and GRU-Based Attention for Image Caption Generation. (arXiv:2310.07252v1 [cs.CV])\nAbstract: Image captioning is a challenging task involving generating a textual description for an image using computer vision and natural language processing techniques. This paper proposes a deep neural framework for image caption generation using a GRU-based attention mechanism. Our approach employs multiple pre-trained convolutional neural networks as the encoder to extract features from the image and a GRU-based language model as the decoder to generate descriptive sentences. To improve performance, we integrate the Bahdanau attention model with the GRU decoder to enable learning to focus on specific image parts. We evaluate our approach using the MSCOCO and Flickr30k datasets and show that it achieves competitive scores compared to state-of-the-art methods. Our proposed framework can bridge the gap between computer vision and natural language and can be extended to specific domains.",
    "path": "papers/23/10/2310.07252.json",
    "total_tokens": 910,
    "translated_title": "一种基于预训练CNN和GRU注意力机制的图像描述生成的比较研究",
    "translated_abstract": "图像描述生成是一项具有挑战性的任务，涉及使用计算机视觉和自然语言处理技术为图像生成文本描述。本文提出了一种使用基于GRU的注意力机制的深度神经网络框架，用于图像描述生成。我们的方法使用多个预训练的卷积神经网络作为编码器从图像中提取特征，并使用基于GRU的语言模型作为解码器生成描述性句子。为了提高性能，我们将Bahdanau注意力模型与GRU解码器集成在一起，使其能够学习专注于特定的图像部分。我们使用MSCOCO和Flickr30k数据集对我们的方法进行评估，并展示其与最先进方法相比具有竞争力的分数。我们提出的框架可以弥合计算机视觉和自然语言之间的差距，并可以扩展到特定领域。",
    "tldr": "本文提出了一种基于预训练CNN和GRU注意力机制的深度神经网络框架，用于图像描述生成。该方法通过多个预训练的卷积神经网络从图像中提取特征，并使用基于GRU的解码器生成描述性句子。实验证明，该方法在MSCOCO和Flickr30k数据集上取得了竞争性的成绩。",
    "en_tdlr": "This paper proposes a deep neural network framework for image caption generation using pre-trained CNNs and a GRU-based attention mechanism. The approach extracts features from the image using multiple pre-trained CNNs as encoders, and generates descriptive sentences using a GRU-based decoder. Experimental results demonstrate competitive performance on the MSCOCO and Flickr30k datasets."
}