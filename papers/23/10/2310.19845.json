{
    "title": "Modified Genetic Algorithm for Feature Selection and Hyper Parameter Optimization: Case of XGBoost in Spam Prediction. (arXiv:2310.19845v1 [cs.LG])",
    "abstract": "Recently, spam on online social networks has attracted attention in the research and business world. Twitter has become the preferred medium to spread spam content. Many research efforts attempted to encounter social networks spam. Twitter brought extra challenges represented by the feature space size, and imbalanced data distributions. Usually, the related research works focus on part of these main challenges or produce black-box models. In this paper, we propose a modified genetic algorithm for simultaneous dimensionality reduction and hyper parameter optimization over imbalanced datasets. The algorithm initialized an eXtreme Gradient Boosting classifier and reduced the features space of tweets dataset; to generate a spam prediction model. The model is validated using a 50 times repeated 10-fold stratified cross-validation, and analyzed using nonparametric statistical tests. The resulted prediction model attains on average 82.32\\% and 92.67\\% in terms of geometric mean and accuracy r",
    "link": "http://arxiv.org/abs/2310.19845",
    "context": "Title: Modified Genetic Algorithm for Feature Selection and Hyper Parameter Optimization: Case of XGBoost in Spam Prediction. (arXiv:2310.19845v1 [cs.LG])\nAbstract: Recently, spam on online social networks has attracted attention in the research and business world. Twitter has become the preferred medium to spread spam content. Many research efforts attempted to encounter social networks spam. Twitter brought extra challenges represented by the feature space size, and imbalanced data distributions. Usually, the related research works focus on part of these main challenges or produce black-box models. In this paper, we propose a modified genetic algorithm for simultaneous dimensionality reduction and hyper parameter optimization over imbalanced datasets. The algorithm initialized an eXtreme Gradient Boosting classifier and reduced the features space of tweets dataset; to generate a spam prediction model. The model is validated using a 50 times repeated 10-fold stratified cross-validation, and analyzed using nonparametric statistical tests. The resulted prediction model attains on average 82.32\\% and 92.67\\% in terms of geometric mean and accuracy r",
    "path": "papers/23/10/2310.19845.json",
    "total_tokens": 916,
    "translated_title": "修改的遗传算法用于特征选择和超参数优化：以XGBoost在垃圾邮件预测中为例",
    "translated_abstract": "近期，在在线社交网络上的垃圾邮件问题引起了研究界和商业界的关注。Twitter已成为传播垃圾邮件内容的首选媒介。许多研究努力试图应对社交网络垃圾邮件。Twitter带来了额外的挑战，包括特征空间的大小和不平衡的数据分布。通常，相关研究工作关注其中的一部分主要挑战，或者产生黑盒模型。在本文中，我们提出了一种修改的遗传算法，用于同时降低维度和优化超参数在不平衡数据集上。该算法初始化了一个eXtreme Gradient Boosting分类器，并减少了推文数据集的特征空间，以生成一个垃圾邮件预测模型。该模型使用50次重复的10倍分层交叉验证进行验证，并使用非参数统计检验进行分析。结果预测模型在几何平均和准确率上平均达到82.32％和92.67％。",
    "tldr": "本文提出了一种修改的遗传算法，用于同时降低维度和优化超参数，在不平衡数据集上进行垃圾邮件预测。实验结果表明，该模型在几何平均和准确率上表现良好。",
    "en_tdlr": "This paper proposes a modified genetic algorithm for simultaneous dimensionality reduction and hyper parameter optimization in spam prediction on imbalanced datasets. Experimental results show that the model performs well in terms of geometric mean and accuracy."
}