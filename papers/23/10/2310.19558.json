{
    "title": "Privacy-preserving Federated Primal-dual Learning for Non-convex and Non-smooth Problems with Model Sparsification",
    "abstract": "arXiv:2310.19558v2 Announce Type: replace  Abstract: Federated learning (FL) has been recognized as a rapidly growing research area, where the model is trained over massively distributed clients under the orchestration of a parameter server (PS) without sharing clients' data. This paper delves into a class of federated problems characterized by non-convex and non-smooth loss functions, that are prevalent in FL applications but challenging to handle due to their intricate non-convexity and non-smoothness nature and the conflicting requirements on communication efficiency and privacy protection. In this paper, we propose a novel federated primal-dual algorithm with bidirectional model sparsification tailored for non-convex and non-smooth FL problems, and differential privacy is applied for privacy guarantee. Its unique insightful properties and some privacy and convergence analyses are also presented as the FL algorithm design guidelines. Extensive experiments on real-world data are cond",
    "link": "https://arxiv.org/abs/2310.19558",
    "context": "Title: Privacy-preserving Federated Primal-dual Learning for Non-convex and Non-smooth Problems with Model Sparsification\nAbstract: arXiv:2310.19558v2 Announce Type: replace  Abstract: Federated learning (FL) has been recognized as a rapidly growing research area, where the model is trained over massively distributed clients under the orchestration of a parameter server (PS) without sharing clients' data. This paper delves into a class of federated problems characterized by non-convex and non-smooth loss functions, that are prevalent in FL applications but challenging to handle due to their intricate non-convexity and non-smoothness nature and the conflicting requirements on communication efficiency and privacy protection. In this paper, we propose a novel federated primal-dual algorithm with bidirectional model sparsification tailored for non-convex and non-smooth FL problems, and differential privacy is applied for privacy guarantee. Its unique insightful properties and some privacy and convergence analyses are also presented as the FL algorithm design guidelines. Extensive experiments on real-world data are cond",
    "path": "papers/23/10/2310.19558.json",
    "total_tokens": 884,
    "translated_title": "面向非凸非光滑问题的隐私保护联邦原始-对偶学习与模型稀疏化",
    "translated_abstract": "隐私保护联邦原始-对偶学习针对于分布式客户端训练模型的类型进行研究，参数服务器进行协调，而不共享客户端数据。本文深入探讨了一类在FL应用中普遍存在但难以处理的非凸非光滑损失函数的联邦问题，这些问题因其复杂的非凸性和非光滑性质以及对通信效率和隐私保护的矛盾要求而具有挑战性。提出了一种针对非凸非光滑FL问题的新颖联邦原始-对偶算法，在隐私保证方面应用了差分隐私。文中还介绍了其独特的见解性属性以及一些隐私和收敛性分析，作为FL算法设计指导原则。在真实数据上进行了大量实验。",
    "tldr": "本文提出了一种针对非凸非光滑FL问题的新颖联邦原始-对偶算法，采用双向模型稀疏化，应用差分隐私进行隐私保障，并提出了FL算法设计指导原则。",
    "en_tdlr": "This paper introduces a novel federated primal-dual algorithm tailored for non-convex and non-smooth FL problems, with bidirectional model sparsification and differential privacy for privacy protection, and provides insights for FL algorithm design principles."
}