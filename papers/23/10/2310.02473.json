{
    "title": "Prompting-based Efficient Temporal Domain Generalization. (arXiv:2310.02473v1 [cs.LG])",
    "abstract": "Machine learning traditionally assumes that training and testing data are distributed independently and identically. However, in many real-world settings, the data distribution can shift over time, leading to poor generalization of trained models in future time periods. Our paper presents a novel prompting-based approach to temporal domain generalization that is parameter-efficient, time-efficient, and does not require access to the target domain data (i.e., unseen future time periods) during training. Our method adapts a target pre-trained model to temporal drift by learning global prompts, domain-specific prompts, and drift-aware prompts that capture underlying temporal dynamics. It is compatible across diverse tasks, such as classification, regression, and time series forecasting, and sets a new state-of-the-art benchmark in temporal domain generalization. The code repository will be publicly shared.",
    "link": "http://arxiv.org/abs/2310.02473",
    "context": "Title: Prompting-based Efficient Temporal Domain Generalization. (arXiv:2310.02473v1 [cs.LG])\nAbstract: Machine learning traditionally assumes that training and testing data are distributed independently and identically. However, in many real-world settings, the data distribution can shift over time, leading to poor generalization of trained models in future time periods. Our paper presents a novel prompting-based approach to temporal domain generalization that is parameter-efficient, time-efficient, and does not require access to the target domain data (i.e., unseen future time periods) during training. Our method adapts a target pre-trained model to temporal drift by learning global prompts, domain-specific prompts, and drift-aware prompts that capture underlying temporal dynamics. It is compatible across diverse tasks, such as classification, regression, and time series forecasting, and sets a new state-of-the-art benchmark in temporal domain generalization. The code repository will be publicly shared.",
    "path": "papers/23/10/2310.02473.json",
    "total_tokens": 806,
    "translated_title": "基于提示的高效时域泛化",
    "translated_abstract": "传统的机器学习假设训练和测试数据是独立且相同分布的。然而，在许多实际应用中，数据分布会随时间变化，导致训练好的模型在未来时间段的泛化能力变差。我们的论文提出了一种新颖的基于提示的时域泛化方法，它具有参数高效、时间高效，并且在训练过程中不需要访问目标域数据（即未知的未来时间段）。我们的方法通过学习全局提示、领域特定提示和感知到时序漂移的提示的方式，将目标预训练模型适应于时序漂移。它适用于各种任务，例如分类、回归和时间序列预测，并在时域泛化方面取得了新的最优性能。代码仓库将公开分享。",
    "tldr": "我们提出了一种基于提示的高效时域泛化方法，通过学习全局提示、领域特定提示和感知时序漂移的提示，不需要目标域数据的情况下适应时序漂移，并在各种任务中取得了state-of-the-art的性能。",
    "en_tdlr": "We propose a prompting-based efficient temporal domain generalization method that adapts to temporal drift without requiring target domain data, achieving state-of-the-art performance across diverse tasks."
}