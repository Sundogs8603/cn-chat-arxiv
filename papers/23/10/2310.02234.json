{
    "title": "MIS-AVoiDD: Modality Invariant and Specific Representation for Audio-Visual Deepfake Detection. (arXiv:2310.02234v2 [cs.CV] UPDATED)",
    "abstract": "Deepfakes are synthetic media generated using deep generative algorithms and have posed a severe societal and political threat. Apart from facial manipulation and synthetic voice, recently, a novel kind of deepfakes has emerged with either audio or visual modalities manipulated. In this regard, a new generation of multimodal audio-visual deepfake detectors is being investigated to collectively focus on audio and visual data for multimodal manipulation detection. Existing multimodal (audio-visual) deepfake detectors are often based on the fusion of the audio and visual streams from the video. Existing studies suggest that these multimodal detectors often obtain equivalent performances with unimodal audio and visual deepfake detectors. We conjecture that the heterogeneous nature of the audio and visual signals creates distributional modality gaps and poses a significant challenge to effective fusion and efficient performance. In this paper, we tackle the problem at the representation lev",
    "link": "http://arxiv.org/abs/2310.02234",
    "context": "Title: MIS-AVoiDD: Modality Invariant and Specific Representation for Audio-Visual Deepfake Detection. (arXiv:2310.02234v2 [cs.CV] UPDATED)\nAbstract: Deepfakes are synthetic media generated using deep generative algorithms and have posed a severe societal and political threat. Apart from facial manipulation and synthetic voice, recently, a novel kind of deepfakes has emerged with either audio or visual modalities manipulated. In this regard, a new generation of multimodal audio-visual deepfake detectors is being investigated to collectively focus on audio and visual data for multimodal manipulation detection. Existing multimodal (audio-visual) deepfake detectors are often based on the fusion of the audio and visual streams from the video. Existing studies suggest that these multimodal detectors often obtain equivalent performances with unimodal audio and visual deepfake detectors. We conjecture that the heterogeneous nature of the audio and visual signals creates distributional modality gaps and poses a significant challenge to effective fusion and efficient performance. In this paper, we tackle the problem at the representation lev",
    "path": "papers/23/10/2310.02234.json",
    "total_tokens": 914,
    "translated_title": "MIS-AVoiDD:音视深度伪造检测的模态不变和特定表示",
    "translated_abstract": "深度伪造是使用深度生成算法生成的合成媒体，对社会和政治构成了严重威胁。除了面部操作和合成语音，最近还出现了一种新型的深度伪造，其中音频或视觉模态被操作。为此，正在研究一种新一代的多模态音视深度伪造检测器，共同关注音频和视觉数据进行多模态操作检测。现有的多模态（音视）深度伪造检测器通常基于从视频中融合音频和视觉流。现有研究表明，这些多模态检测器通常具有与单模态音频和视觉深度伪造检测器相当的性能。我们推测，音频和视觉信号的异质性本质造成了模态分布差距，并对有效融合和高效性能提出了重大挑战。本文从表示层面解决了这个问题。",
    "tldr": "本论文提出了一种名为MIS-AVoiDD的模态不变和特定表示方法，用于音视深度伪造检测。通过充分关注音频和视觉数据，并解决音频和视觉信号的异质性问题，该方法在多模态操作检测中表现出良好的性能。",
    "en_tdlr": "This paper proposes a modality invariant and specific representation method called MIS-AVoiDD for audio-visual deepfake detection. By focusing on audio and visual data and addressing the heterogeneity of audio and visual signals, the method shows good performance in multimodal manipulation detection."
}