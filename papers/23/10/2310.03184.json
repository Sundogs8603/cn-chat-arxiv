{
    "title": "Retrieval-augmented Generation to Improve Math Question-Answering: Trade-offs Between Groundedness and Human Preference. (arXiv:2310.03184v1 [cs.CL])",
    "abstract": "For middle-school math students, interactive question-answering (QA) with tutors is an effective way to learn. The flexibility and emergent capabilities of generative large language models (LLMs) has led to a surge of interest in automating portions of the tutoring process - including interactive QA to support conceptual discussion of mathematical concepts. However, LLM responses to math questions can be incorrect or mismatched to the educational context such as being misaligned with a school's curriculum. One potential solution is retrieval-augmented generation (RAG), which involves incorporating a vetted external knowledge source in the LLM prompt to increase response quality. In this paper, we designed prompts that retrieve and use content from a high-quality open-source math textbook to generate responses to real student questions. We evaluate the efficacy of this RAG system for middle-school algebra and geometry QA by administering a multi-condition survey, finding that humans p",
    "link": "http://arxiv.org/abs/2310.03184",
    "context": "Title: Retrieval-augmented Generation to Improve Math Question-Answering: Trade-offs Between Groundedness and Human Preference. (arXiv:2310.03184v1 [cs.CL])\nAbstract: For middle-school math students, interactive question-answering (QA) with tutors is an effective way to learn. The flexibility and emergent capabilities of generative large language models (LLMs) has led to a surge of interest in automating portions of the tutoring process - including interactive QA to support conceptual discussion of mathematical concepts. However, LLM responses to math questions can be incorrect or mismatched to the educational context such as being misaligned with a school's curriculum. One potential solution is retrieval-augmented generation (RAG), which involves incorporating a vetted external knowledge source in the LLM prompt to increase response quality. In this paper, we designed prompts that retrieve and use content from a high-quality open-source math textbook to generate responses to real student questions. We evaluate the efficacy of this RAG system for middle-school algebra and geometry QA by administering a multi-condition survey, finding that humans p",
    "path": "papers/23/10/2310.03184.json",
    "total_tokens": 884,
    "translated_title": "使用检索增强的生成模型改进数学问答：在可靠性和人类偏好之间的权衡",
    "translated_abstract": "对于中学数学学生来说，与导师进行互动问答是一种有效的学习方式。生成式大型语言模型的灵活性和新兴能力导致人们对自动化部分辅导过程的兴趣增加，包括支持数学概念的概念讨论的互动问答。然而，生成模型对数学问题的回答可能是错误的，或者与教育背景不匹配，例如与学校的课程不一致。检索增强的生成模型是其中一个潜在的解决方案，它通过在生成模型提示中加入经验证的外部知识资源来提高回答质量。在本文中，我们设计了提示来检索并使用高质量的开源数学教科书中的内容，以回答真实学生提出的问题。我们通过进行一项多条件调查来评估这种检索增强的生成模型在中学代数和几何问答中的效果，并发现人类偏好。",
    "tldr": "通过检索增强的生成模型来改进数学问答，在可靠性和人类偏好之间进行权衡",
    "en_tdlr": "Trade-offs between groundedness and human preference are explored in this paper, which proposes a retrieval-augmented generation (RAG) system to improve math question-answering. The system incorporates a vetted external knowledge source to increase response quality and has been evaluated for middle-school algebra and geometry QA."
}