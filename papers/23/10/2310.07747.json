{
    "title": "Accountability in Offline Reinforcement Learning: Explaining Decisions with a Corpus of Examples. (arXiv:2310.07747v1 [cs.LG])",
    "abstract": "Learning transparent, interpretable controllers with offline data in decision-making systems is an essential area of research due to its potential to reduce the risk of applications in real-world systems. However, in responsibility-sensitive settings such as healthcare, decision accountability is of paramount importance, yet has not been adequately addressed by the literature. This paper introduces the Accountable Offline Controller (AOC) that employs the offline dataset as the Decision Corpus and performs accountable control based on a tailored selection of examples, referred to as the Corpus Subset. ABC operates effectively in low-data scenarios, can be extended to the strictly offline imitation setting, and displays qualities of both conservation and adaptability. We assess ABC's performance in both simulated and real-world healthcare scenarios, emphasizing its capability to manage offline control tasks with high levels of performance while maintaining accountability.  Keywords: Int",
    "link": "http://arxiv.org/abs/2310.07747",
    "context": "Title: Accountability in Offline Reinforcement Learning: Explaining Decisions with a Corpus of Examples. (arXiv:2310.07747v1 [cs.LG])\nAbstract: Learning transparent, interpretable controllers with offline data in decision-making systems is an essential area of research due to its potential to reduce the risk of applications in real-world systems. However, in responsibility-sensitive settings such as healthcare, decision accountability is of paramount importance, yet has not been adequately addressed by the literature. This paper introduces the Accountable Offline Controller (AOC) that employs the offline dataset as the Decision Corpus and performs accountable control based on a tailored selection of examples, referred to as the Corpus Subset. ABC operates effectively in low-data scenarios, can be extended to the strictly offline imitation setting, and displays qualities of both conservation and adaptability. We assess ABC's performance in both simulated and real-world healthcare scenarios, emphasizing its capability to manage offline control tasks with high levels of performance while maintaining accountability.  Keywords: Int",
    "path": "papers/23/10/2310.07747.json",
    "total_tokens": 875,
    "translated_title": "离线强化学习中的问责制：用语料库的例子解释决策",
    "translated_abstract": "在决策系统中使用离线数据学习透明、可解释的控制器是一个重要的研究领域，因为它有潜力降低在现实世界系统中应用的风险。然而，在责任敏感的设置（如医疗保健）中，决策问责制非常重要，但目前的文献尚未充分解决这个问题。本文介绍了一种名为Accountable Offline Controller（AOC）的方法，它将离线数据集作为决策语料库，并根据一组定制的例子（称为语料库子集）进行问责制的控制。AOC在低数据场景中有效地运行，可以扩展到严格的离线模仿设置，并表现出保护和适应性的特点。我们在模拟和真实的医疗保健场景中评估了AOC的性能，强调了它在保持问责制的同时能够管理高水平的离线控制任务。",
    "tldr": "本论文介绍了一种可解释的离线控制器方法，通过使用离线数据集作为决策语料库，在低数据场景中实现了问责制的控制，并在医疗保健领域展示了良好的性能。",
    "en_tdlr": "This paper presents an interpretable offline controller method that achieves accountability in low-data scenarios by using an offline dataset as the decision corpus, and demonstrates good performance in the healthcare domain."
}