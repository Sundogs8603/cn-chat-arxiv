{
    "title": "Constrained Hierarchical Monte Carlo Belief-State Planning. (arXiv:2310.20054v1 [cs.AI])",
    "abstract": "Optimal plans in Constrained Partially Observable Markov Decision Processes (CPOMDPs) maximize reward objectives while satisfying hard cost constraints, generalizing safe planning under state and transition uncertainty. Unfortunately, online CPOMDP planning is extremely difficult in large or continuous problem domains. In many large robotic domains, hierarchical decomposition can simplify planning by using tools for low-level control given high-level action primitives (options). We introduce Constrained Options Belief Tree Search (COBeTS) to leverage this hierarchy and scale online search-based CPOMDP planning to large robotic problems. We show that if primitive option controllers are defined to satisfy assigned constraint budgets, then COBeTS will satisfy constraints anytime. Otherwise, COBeTS will guide the search towards a safe sequence of option primitives, and hierarchical monitoring can be used to achieve runtime safety. We demonstrate COBeTS in several safety-critical, constrain",
    "link": "http://arxiv.org/abs/2310.20054",
    "context": "Title: Constrained Hierarchical Monte Carlo Belief-State Planning. (arXiv:2310.20054v1 [cs.AI])\nAbstract: Optimal plans in Constrained Partially Observable Markov Decision Processes (CPOMDPs) maximize reward objectives while satisfying hard cost constraints, generalizing safe planning under state and transition uncertainty. Unfortunately, online CPOMDP planning is extremely difficult in large or continuous problem domains. In many large robotic domains, hierarchical decomposition can simplify planning by using tools for low-level control given high-level action primitives (options). We introduce Constrained Options Belief Tree Search (COBeTS) to leverage this hierarchy and scale online search-based CPOMDP planning to large robotic problems. We show that if primitive option controllers are defined to satisfy assigned constraint budgets, then COBeTS will satisfy constraints anytime. Otherwise, COBeTS will guide the search towards a safe sequence of option primitives, and hierarchical monitoring can be used to achieve runtime safety. We demonstrate COBeTS in several safety-critical, constrain",
    "path": "papers/23/10/2310.20054.json",
    "total_tokens": 911,
    "translated_title": "有约束的层次蒙特卡洛信念状态规划",
    "translated_abstract": "有约束的部分可观察马尔可夫决策过程（CPOMDPs）中的最优规划在满足硬性成本约束的同时最大化奖励目标，推广了状态和过渡不确定性下的安全规划。然而，在大型或连续的问题域中进行在线CPOMDP规划非常困难。在许多大型机器人领域，通过使用高层动作原语（选项）为低层控制提供工具，分层分解可以简化规划。我们引入了有约束的选项信念树搜索（COBeTS）来利用这个层次结构，将在线基于搜索的CPOMDP规划扩展到大型机器人问题。我们证明如果原始选项控制器被定义为满足指定的约束预算，那么COBeTS将随时满足约束。否则，COBeTS将引导搜索朝着安全的选项原语序列，并且可以使用分层监控来实现运行时安全。我们在几个安全关键的约束问题中展示了COBeTS。",
    "tldr": "有约束的层次蒙特卡洛信念状态规划（COBeTS）通过使用分层分解和约束选项控制器，将在线基于搜索的CPOMDP规划扩展到大型机器人问题，并能同时满足约束和奖励目标。",
    "en_tdlr": "Constrained Hierarchical Monte Carlo Belief-State Planning (COBeTS) extends online search-based CPOMDP planning to large robotic problems by using hierarchical decomposition and constrained option controllers, satisfying both constraints and reward objectives."
}