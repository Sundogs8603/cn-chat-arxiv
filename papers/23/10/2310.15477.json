{
    "title": "CRaSh: Clustering, Removing, and Sharing Enhance Fine-tuning without Full Large Language Model. (arXiv:2310.15477v1 [cs.CL])",
    "abstract": "Instruction tuning has recently been recognized as an effective way of aligning Large Language Models (LLMs) to enhance their generalization ability across various tasks. However, when tuning publicly accessible, centralized LLMs with private instruction data, privacy concerns are inevitable. While direct transfer of parameterized modules between models is a plausible approach to address this, its implications and effectiveness need further exploration. This paper focuses on Offsite-Tuning (OFT), a representative technique that transfers transformer blocks between centralized LLMs and downstream emulators. Given the limited understanding of the underlying mechanism of OFT, we perform an empirical analysis on LLMs from the perspectives of representation and functional similarity. Interestingly, our findings reveal a unique modular structure within the layers of LLMs that appears to emerge as the model size expands. Simultaneously, we note subtle but potentially significant changes in re",
    "link": "http://arxiv.org/abs/2310.15477",
    "context": "Title: CRaSh: Clustering, Removing, and Sharing Enhance Fine-tuning without Full Large Language Model. (arXiv:2310.15477v1 [cs.CL])\nAbstract: Instruction tuning has recently been recognized as an effective way of aligning Large Language Models (LLMs) to enhance their generalization ability across various tasks. However, when tuning publicly accessible, centralized LLMs with private instruction data, privacy concerns are inevitable. While direct transfer of parameterized modules between models is a plausible approach to address this, its implications and effectiveness need further exploration. This paper focuses on Offsite-Tuning (OFT), a representative technique that transfers transformer blocks between centralized LLMs and downstream emulators. Given the limited understanding of the underlying mechanism of OFT, we perform an empirical analysis on LLMs from the perspectives of representation and functional similarity. Interestingly, our findings reveal a unique modular structure within the layers of LLMs that appears to emerge as the model size expands. Simultaneously, we note subtle but potentially significant changes in re",
    "path": "papers/23/10/2310.15477.json",
    "total_tokens": 936,
    "translated_title": "CRaSh: 聚类、去除和共享无需完整大型语言模型增强微调",
    "translated_abstract": "最近，指令微调被认为是对大型语言模型（LLM）进行对齐以增强其在不同任务中的泛化能力的有效方法。然而，当使用私有指令数据对公开可访问的集中式LLM进行微调时，隐私问题不可避免。直接在模型之间传输参数化模块是解决这个问题的一种可行方法，但其实际效果和影响需要进一步探索。本文重点研究了Offsite-Tuning（OFT），这是一种将转换器块在集中式LLM和下游模拟器之间传输的代表性技术。鉴于对OFT的底层机制的理解有限，我们从表示和功能相似性的角度对LLM进行了实证分析。有趣的是，我们的研究结果揭示了LLM层内独特的模块结构，随着模型规模扩大而出现。同时，我们注意到微小但潜在重要的改变。",
    "tldr": "本文研究了CRaSh模型，这是一种 Cluster, Remove, and Share 的技术，通过在不完整的大型语言模型上进行微调来增强其性能。从实证分析中发现，LLM层内存在独特的模块结构，并且在模型规模扩大时会出现微小但可能重要的改变。"
}