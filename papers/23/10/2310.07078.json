{
    "title": "Auditing and Robustifying COVID-19 Misinformation Datasets via Anticontent Sampling. (arXiv:2310.07078v1 [cs.LG])",
    "abstract": "This paper makes two key contributions. First, it argues that highly specialized rare content classifiers trained on small data typically have limited exposure to the richness and topical diversity of the negative class (dubbed anticontent) as observed in the wild. As a result, these classifiers' strong performance observed on the test set may not translate into real-world settings. In the context of COVID-19 misinformation detection, we conduct an in-the-wild audit of multiple datasets and demonstrate that models trained with several prominently cited recent datasets are vulnerable to anticontent when evaluated in the wild. Second, we present a novel active learning pipeline that requires zero manual annotation and iteratively augments the training data with challenging anticontent, robustifying these classifiers.",
    "link": "http://arxiv.org/abs/2310.07078",
    "context": "Title: Auditing and Robustifying COVID-19 Misinformation Datasets via Anticontent Sampling. (arXiv:2310.07078v1 [cs.LG])\nAbstract: This paper makes two key contributions. First, it argues that highly specialized rare content classifiers trained on small data typically have limited exposure to the richness and topical diversity of the negative class (dubbed anticontent) as observed in the wild. As a result, these classifiers' strong performance observed on the test set may not translate into real-world settings. In the context of COVID-19 misinformation detection, we conduct an in-the-wild audit of multiple datasets and demonstrate that models trained with several prominently cited recent datasets are vulnerable to anticontent when evaluated in the wild. Second, we present a novel active learning pipeline that requires zero manual annotation and iteratively augments the training data with challenging anticontent, robustifying these classifiers.",
    "path": "papers/23/10/2310.07078.json",
    "total_tokens": 870,
    "translated_title": "通过抗内容采样对COVID-19虚假信息数据集进行审计和强化",
    "translated_abstract": "本文有两个关键贡献。首先，它认为在小数据上训练的高度专业的罕见内容分类器通常对野外观察到的负面类别的丰富性和话题多样性（称为抗内容）有限暴露。因此，这些分类器在测试集上观察到的强大性能可能无法在现实世界的环境中有效转化。在COVID-19虚假信息检测的背景下，我们对多个数据集进行了野外审计，并证明了使用几个重要引用的最近数据集进行训练的模型在野外评估时容易受到抗内容的攻击。其次，我们提出了一种新颖的主动学习流程，它不需要任何人工注释，并通过挑战性的抗内容不断增强训练数据，从而强化这些分类器。",
    "tldr": "本文拓展了对COVID-19虚假信息数据集进行审计和强化的研究。首先，发现在小数据上训练的专业分类器在野外环境中的性能表现有限。其次，提出了一种无需人工注释的主动学习方法，通过增加具有挑战性的抗内容来增强分类器。"
}