{
    "title": "Fine-tuned vs. Prompt-tuned Supervised Representations: Which Better Account for Brain Language Representations?. (arXiv:2310.01854v1 [cs.AI])",
    "abstract": "To decipher the algorithm underlying the human brain's language representation, previous work probed brain responses to language input with pre-trained artificial neural network (ANN) models fine-tuned on NLU tasks. However, full fine-tuning generally updates the entire parametric space and distorts pre-trained features, cognitively inconsistent with the brain's robust multi-task learning ability. Prompt-tuning, in contrast, protects pre-trained weights and learns task-specific embeddings to fit a task. Could prompt-tuning generate representations that better account for the brain's language representations than fine-tuning? If so, what kind of NLU task leads a pre-trained model to better decode the information represented in the human brain? We investigate these questions by comparing prompt-tuned and fine-tuned representations in neural decoding, that is predicting the linguistic stimulus from the brain activities evoked by the stimulus. We find that on none of the 10 NLU tasks, full",
    "link": "http://arxiv.org/abs/2310.01854",
    "context": "Title: Fine-tuned vs. Prompt-tuned Supervised Representations: Which Better Account for Brain Language Representations?. (arXiv:2310.01854v1 [cs.AI])\nAbstract: To decipher the algorithm underlying the human brain's language representation, previous work probed brain responses to language input with pre-trained artificial neural network (ANN) models fine-tuned on NLU tasks. However, full fine-tuning generally updates the entire parametric space and distorts pre-trained features, cognitively inconsistent with the brain's robust multi-task learning ability. Prompt-tuning, in contrast, protects pre-trained weights and learns task-specific embeddings to fit a task. Could prompt-tuning generate representations that better account for the brain's language representations than fine-tuning? If so, what kind of NLU task leads a pre-trained model to better decode the information represented in the human brain? We investigate these questions by comparing prompt-tuned and fine-tuned representations in neural decoding, that is predicting the linguistic stimulus from the brain activities evoked by the stimulus. We find that on none of the 10 NLU tasks, full",
    "path": "papers/23/10/2310.01854.json",
    "total_tokens": 891,
    "translated_title": "精调与提示调整的监督表示：哪种更能解释大脑中的语言表示？",
    "translated_abstract": "为了解读人脑语言表示背后的算法，先前的研究使用在NLU任务上进行过精调的预训练人工神经网络（ANN）模型来探测大脑对语言输入的反应。然而，完全的精调会更新整个参数空间并扭曲预训练的特征，与大脑的强健多任务学习能力不一致。相比之下，提示调整保护预训练的权重并学习任务特定的嵌入以适应任务。提示调整是否能生成更能解释大脑语言表示的表示？如果是，哪种NLU任务能让预训练模型更好地解码人脑中的信息表示？我们通过比较提示调整和精调的表示在神经解码中进行了这些问题的研究，即从刺激引发的大脑活动中预测语言刺激。我们发现，在10个NLU任务中，全球精调表示都不能更好地解码人脑中的信息。",
    "tldr": "本研究比较了精调和提示调整的表示在神经解码中的效果，发现在10个NLU任务中，精调表示不能更好地解码人脑中的信息。",
    "en_tdlr": "This study compares fine-tuned and prompt-tuned representations in neural decoding and finds that fine-tuned representations do not better decode information in the human brain on 10 NLU tasks."
}