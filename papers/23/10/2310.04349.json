{
    "title": "Learning to Grasp: from Somewhere to Anywhere. (arXiv:2310.04349v1 [cs.RO])",
    "abstract": "Robotic grasping is still a partially solved, multidisciplinary problem where data-driven techniques play an increasing role. The sparse nature of rewards make the automatic generation of grasping datasets challenging, especially for unconventional morphologies or highly actuated end-effectors. Most approaches for obtaining large-scale datasets rely on numerous human-provided demonstrations or heavily engineered solutions that do not scale well. Recent advances in Quality-Diversity (QD) methods have investigated how to learn object grasping at a specific pose with different robot morphologies. The present work introduces a pipeline for adapting QD-generated trajectories to new object poses. Using an RGB-D data stream, the vision pipeline first detects the targeted object, predicts its 6-DOF pose, and finally tracks it. An automatically generated reach-and-grasp trajectory can then be adapted by projecting it relatively to the object frame. Hundreds of trajectories have been deployed in",
    "link": "http://arxiv.org/abs/2310.04349",
    "context": "Title: Learning to Grasp: from Somewhere to Anywhere. (arXiv:2310.04349v1 [cs.RO])\nAbstract: Robotic grasping is still a partially solved, multidisciplinary problem where data-driven techniques play an increasing role. The sparse nature of rewards make the automatic generation of grasping datasets challenging, especially for unconventional morphologies or highly actuated end-effectors. Most approaches for obtaining large-scale datasets rely on numerous human-provided demonstrations or heavily engineered solutions that do not scale well. Recent advances in Quality-Diversity (QD) methods have investigated how to learn object grasping at a specific pose with different robot morphologies. The present work introduces a pipeline for adapting QD-generated trajectories to new object poses. Using an RGB-D data stream, the vision pipeline first detects the targeted object, predicts its 6-DOF pose, and finally tracks it. An automatically generated reach-and-grasp trajectory can then be adapted by projecting it relatively to the object frame. Hundreds of trajectories have been deployed in",
    "path": "papers/23/10/2310.04349.json",
    "total_tokens": 951,
    "translated_title": "从某处到任何地方的学习：抓取技术",
    "translated_abstract": "机器人抓取仍然是一个部分解决的、多学科的问题，在其中数据驱动的技术发挥着越来越重要的作用。奖励的稀疏性使得自动生成抓取数据集变得具有挑战性，尤其是对于非传统形态或高度驱动的末端执行器。获得大规模数据集的大多数方法依赖于众多人工提供的演示或严重工程化的解决方案，这些方法很难扩展。最新的质量-多样性（QD）方法的进展研究了如何使用不同机器人形态学习特定姿势下的物体抓取。本研究介绍了一个将QD生成的轨迹适应到新物体姿态的流水线。使用RGB-D数据流，视觉流水线首先检测目标物体，预测其6自由度姿态，最后跟踪它。然后通过将轨迹相对于物体框架进行投影来自动生成可达到的抓取轨迹。数百个轨迹已经在实验中部署。",
    "tldr": "本研究介绍了一个采用质量-多样性方法的流水线，用于将生成的抓取轨迹适应到新物体姿态。使用RGB-D数据流，该方法能够自动检测目标物体、预测其姿态，并生成可达到的抓取轨迹。",
    "en_tdlr": "This study presents a pipeline using Quality-Diversity (QD) methods to adapt generated grasping trajectories to new object poses. With the use of an RGB-D data stream, the pipeline can automatically detect the target object, predict its pose, and generate reachable grasping trajectories."
}