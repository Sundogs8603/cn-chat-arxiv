{
    "title": "PoseAction: Action Recognition for Patients in the Ward using Deep Learning Approaches. (arXiv:2310.03288v1 [cs.CV])",
    "abstract": "Real-time intelligent detection and prediction of subjects' behavior particularly their movements or actions is critical in the ward. This approach offers the advantage of reducing in-hospital care costs and improving the efficiency of healthcare workers, which is especially true for scenarios at night or during peak admission periods. Therefore, in this work, we propose using computer vision (CV) and deep learning (DL) methods for detecting subjects and recognizing their actions. We utilize OpenPose as an accurate subject detector for recognizing the positions of human subjects in the video stream. Additionally, we employ AlphAction's Asynchronous Interaction Aggregation (AIA) network to predict the actions of detected subjects. This integrated model, referred to as PoseAction, is proposed. At the same time, the proposed model is further trained to predict 12 common actions in ward areas, such as staggering, chest pain, and falling down, using medical-related video clips from the NTU ",
    "link": "http://arxiv.org/abs/2310.03288",
    "context": "Title: PoseAction: Action Recognition for Patients in the Ward using Deep Learning Approaches. (arXiv:2310.03288v1 [cs.CV])\nAbstract: Real-time intelligent detection and prediction of subjects' behavior particularly their movements or actions is critical in the ward. This approach offers the advantage of reducing in-hospital care costs and improving the efficiency of healthcare workers, which is especially true for scenarios at night or during peak admission periods. Therefore, in this work, we propose using computer vision (CV) and deep learning (DL) methods for detecting subjects and recognizing their actions. We utilize OpenPose as an accurate subject detector for recognizing the positions of human subjects in the video stream. Additionally, we employ AlphAction's Asynchronous Interaction Aggregation (AIA) network to predict the actions of detected subjects. This integrated model, referred to as PoseAction, is proposed. At the same time, the proposed model is further trained to predict 12 common actions in ward areas, such as staggering, chest pain, and falling down, using medical-related video clips from the NTU ",
    "path": "papers/23/10/2310.03288.json",
    "total_tokens": 932,
    "translated_title": "使用深度学习方法的病房患者动作识别",
    "translated_abstract": "在病房中实时智能地检测和预测患者的行为，尤其是他们的运动或动作，对于降低住院护理成本和提高医护人员效率至关重要，特别是在夜间或高峰期。因此，在这项工作中，我们提出使用计算机视觉（CV）和深度学习（DL）方法来检测患者并识别其动作。我们利用OpenPose作为准确的患者检测器，来识别视频流中人体的位置。此外，我们采用AlphAction的异步交互聚合（AIA）网络来预测已检测到的患者的动作。我们提出了这个集成模型，称为PoseAction。同时，我们进一步训练所提出的模型，使用来自NTU医学视频片段来预测病房区域的12种常见动作，例如蹒跚、胸痛和摔倒。",
    "tldr": "这项工作使用深度学习方法开发了一个集成模型PoseAction，该模型利用计算机视觉和异步交互聚合网络来实现病房患者的动作识别和预测。通过准确的患者检测和常见动作的预测，可以提高病房的护理效率和降低护理成本。"
}