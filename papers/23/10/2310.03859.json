{
    "title": "Living Lab Evaluation for Life and Social Sciences Search Platforms -- LiLAS at CLEF 2021. (arXiv:2310.03859v1 [cs.IR])",
    "abstract": "Meta-evaluation studies of system performances in controlled offline evaluation campaigns, like TREC and CLEF, show a need for innovation in evaluating IR-systems. The field of academic search is no exception to this. This might be related to the fact that relevance in academic search is multilayered and therefore the aspect of user-centric evaluation is becoming more and more important. The Living Labs for Academic Search (LiLAS) lab aims to strengthen the concept of user-centric living labs for the domain of academic search by allowing participants to evaluate their retrieval approaches in two real-world academic search systems from the life sciences and the social sciences. To this end, we provide participants with metadata on the systems' content as well as candidate lists with the task to rank the most relevant candidate to the top. Using the STELLA-infrastructure, we allow participants to easily integrate their approaches into the real-world systems and provide the possibility to",
    "link": "http://arxiv.org/abs/2310.03859",
    "context": "Title: Living Lab Evaluation for Life and Social Sciences Search Platforms -- LiLAS at CLEF 2021. (arXiv:2310.03859v1 [cs.IR])\nAbstract: Meta-evaluation studies of system performances in controlled offline evaluation campaigns, like TREC and CLEF, show a need for innovation in evaluating IR-systems. The field of academic search is no exception to this. This might be related to the fact that relevance in academic search is multilayered and therefore the aspect of user-centric evaluation is becoming more and more important. The Living Labs for Academic Search (LiLAS) lab aims to strengthen the concept of user-centric living labs for the domain of academic search by allowing participants to evaluate their retrieval approaches in two real-world academic search systems from the life sciences and the social sciences. To this end, we provide participants with metadata on the systems' content as well as candidate lists with the task to rank the most relevant candidate to the top. Using the STELLA-infrastructure, we allow participants to easily integrate their approaches into the real-world systems and provide the possibility to",
    "path": "papers/23/10/2310.03859.json",
    "total_tokens": 899,
    "translated_title": "生活与社会科学搜索平台的Living Lab评估- LiLAS在CLEF 2021中",
    "translated_abstract": "在控制的离线评估活动（如TREC和CLEF）的元评估研究中，系统性能评估方面存在创新的需求，学术搜索领域也不例外。这可能与学术搜索中的相关性是多层次的事实有关，因此用户中心评估的方面变得越来越重要。学术搜索的Living Labs（LiLAS）实验室旨在通过允许参与者在生命科学和社会科学领域的两个真实学术搜索系统中评估其检索方法，加强用户中心生活实验室的概念。为此，我们为参与者提供了系统内容的元数据以及候选列表，要求将最相关的候选排在前面。利用STELLA基础设施，我们允许参与者将自己的方法轻松集成到真实系统中，并提供将方案部署到在线实验系统中的可能性。",
    "tldr": "本研究介绍了通过LiLAS实验室对生命科学和社会科学领域的真实学术搜索系统进行用户中心评估的方法，为参与者提供了系统内容的元数据和候选列表，并允许他们轻松集成自己的方法到实际系统中。",
    "en_tdlr": "This study presents a method for user-centric evaluation of real academic search systems in the fields of life sciences and social sciences through LiLAS lab, providing participants with metadata of system content and candidate lists, and allowing them to easily integrate their approaches into the actual systems."
}