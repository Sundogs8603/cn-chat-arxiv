{
    "title": "Logical Languages Accepted by Transformer Encoders with Hard Attention. (arXiv:2310.03817v1 [cs.FL])",
    "abstract": "We contribute to the study of formal languages that can be recognized by transformer encoders. We focus on two self-attention mechanisms: (1) UHAT (Unique Hard Attention Transformers) and (2) AHAT (Average Hard Attention Transformers). UHAT encoders are known to recognize only languages inside the circuit complexity class ${\\sf AC}^0$, i.e., accepted by a family of poly-sized and depth-bounded boolean circuits with unbounded fan-ins. On the other hand, AHAT encoders can recognize languages outside ${\\sf AC}^0$), but their expressive power still lies within the bigger circuit complexity class ${\\sf TC}^0$, i.e., ${\\sf AC}^0$-circuits extended by majority gates. We first show a negative result that there is an ${\\sf AC}^0$-language that cannot be recognized by an UHAT encoder. On the positive side, we show that UHAT encoders can recognize a rich fragment of ${\\sf AC}^0$-languages, namely, all languages definable in first-order logic with arbitrary unary numerical predicates. This logic, ",
    "link": "http://arxiv.org/abs/2310.03817",
    "context": "Title: Logical Languages Accepted by Transformer Encoders with Hard Attention. (arXiv:2310.03817v1 [cs.FL])\nAbstract: We contribute to the study of formal languages that can be recognized by transformer encoders. We focus on two self-attention mechanisms: (1) UHAT (Unique Hard Attention Transformers) and (2) AHAT (Average Hard Attention Transformers). UHAT encoders are known to recognize only languages inside the circuit complexity class ${\\sf AC}^0$, i.e., accepted by a family of poly-sized and depth-bounded boolean circuits with unbounded fan-ins. On the other hand, AHAT encoders can recognize languages outside ${\\sf AC}^0$), but their expressive power still lies within the bigger circuit complexity class ${\\sf TC}^0$, i.e., ${\\sf AC}^0$-circuits extended by majority gates. We first show a negative result that there is an ${\\sf AC}^0$-language that cannot be recognized by an UHAT encoder. On the positive side, we show that UHAT encoders can recognize a rich fragment of ${\\sf AC}^0$-languages, namely, all languages definable in first-order logic with arbitrary unary numerical predicates. This logic, ",
    "path": "papers/23/10/2310.03817.json",
    "total_tokens": 980,
    "translated_title": "使用硬注意力的Transformer编码器可以接受的逻辑语言",
    "translated_abstract": "我们对可以被Transformer编码器识别的形式语言进行了研究。我们重点研究了两种自注意机制：(1)UHAT（唯一硬注意力Transformer）和(2)AHAT（平均硬注意力Transformer）。已知UHAT编码器只能识别电路复杂度类${\\sf AC}^0$中的语言，即由多项式大小和深度有界的布尔电路以及无限扇入的布尔门接受的语言。另一方面，AHAT编码器可以识别${\\sf AC}^0$之外的语言，但它们的表达能力仍然在更大的电路复杂度类${\\sf TC}^0$内，即由多数门扩展的${\\sf AC}^0$电路。我们首先给出了一个负面结果，即存在一个${\\sf AC}^0$语言，无法被UHAT编码器识别。在积极的一面，我们展示了UHAT编码器可以识别${\\sf AC}^0$-语言的一个丰富片段，即在一阶逻辑中使用任意一元数量谓词定义的所有语言。",
    "tldr": "本文研究了使用硬注意力的Transformer编码器可以接受的逻辑语言的问题，发现UHAT编码器只能识别${\\sf AC}^0$中的一部分语言，而AHAT编码器可以识别更丰富的语言。",
    "en_tdlr": "This paper investigates the logical languages recognized by Transformer encoders with hard attention and finds that UHAT encoders can only recognize a subset of ${\\sf AC}^0$ languages, while AHAT encoders have a higher expressive power."
}