{
    "title": "Gauge-optimal approximate learning for small data classification problems. (arXiv:2310.19066v1 [cs.LG])",
    "abstract": "Small data learning problems are characterized by a significant discrepancy between the limited amount of response variable observations and the large feature space dimension. In this setting, the common learning tools struggle to identify the features important for the classification task from those that bear no relevant information, and cannot derive an appropriate learning rule which allows to discriminate between different classes. As a potential solution to this problem, here we exploit the idea of reducing and rotating the feature space in a lower-dimensional gauge and propose the Gauge-Optimal Approximate Learning (GOAL) algorithm, which provides an analytically tractable joint solution to the dimension reduction, feature segmentation and classification problems for small data learning problems. We prove that the optimal solution of the GOAL algorithm consists in piecewise-linear functions in the Euclidean space, and that it can be approximated through a monotonically convergent",
    "link": "http://arxiv.org/abs/2310.19066",
    "context": "Title: Gauge-optimal approximate learning for small data classification problems. (arXiv:2310.19066v1 [cs.LG])\nAbstract: Small data learning problems are characterized by a significant discrepancy between the limited amount of response variable observations and the large feature space dimension. In this setting, the common learning tools struggle to identify the features important for the classification task from those that bear no relevant information, and cannot derive an appropriate learning rule which allows to discriminate between different classes. As a potential solution to this problem, here we exploit the idea of reducing and rotating the feature space in a lower-dimensional gauge and propose the Gauge-Optimal Approximate Learning (GOAL) algorithm, which provides an analytically tractable joint solution to the dimension reduction, feature segmentation and classification problems for small data learning problems. We prove that the optimal solution of the GOAL algorithm consists in piecewise-linear functions in the Euclidean space, and that it can be approximated through a monotonically convergent",
    "path": "papers/23/10/2310.19066.json",
    "total_tokens": 858,
    "translated_title": "小样本分类问题的规范最优近似学习",
    "translated_abstract": "小样本学习问题的特点是有限的响应变量观测和庞大的特征空间维度之间存在显著的差异。在这种情况下，常见的学习工具难以确定对分类任务重要的特征和不相关信息的特征，并且无法推导出适当的学习规则来区分不同的类别。作为解决这个问题的潜在方法，我们利用减少和旋转特征空间的思想，在一个低维度规范中提出了规范最优近似学习（GOAL）算法，为小样本学习问题的维度缩减、特征分割和分类问题提供了一个可分析的联合解决方案。我们证明，GOAL算法的最优解是欧几里得空间中的分段线性函数，并且可以通过单调收敛逼近。",
    "tldr": "我们提出了一种规范最优近似学习（GOAL）算法，用于解决小样本学习问题。该算法通过减少和旋转特征空间，提供了一个可分析的联合解决方案，其中最优解是欧几里得空间中的分段线性函数。"
}