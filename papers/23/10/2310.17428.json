{
    "title": "''Fifty Shades of Bias'': Normative Ratings of Gender Bias in GPT Generated English Text. (arXiv:2310.17428v1 [cs.CL])",
    "abstract": "Language serves as a powerful tool for the manifestation of societal belief systems. In doing so, it also perpetuates the prevalent biases in our society. Gender bias is one of the most pervasive biases in our society and is seen in online and offline discourses. With LLMs increasingly gaining human-like fluency in text generation, gaining a nuanced understanding of the biases these systems can generate is imperative. Prior work often treats gender bias as a binary classification task. However, acknowledging that bias must be perceived at a relative scale; we investigate the generation and consequent receptivity of manual annotators to bias of varying degrees. Specifically, we create the first dataset of GPT-generated English text with normative ratings of gender bias. Ratings were obtained using Best--Worst Scaling -- an efficient comparative annotation framework. Next, we systematically analyze the variation of themes of gender biases in the observed ranking and show that identity-at",
    "link": "http://arxiv.org/abs/2310.17428",
    "context": "Title: ''Fifty Shades of Bias'': Normative Ratings of Gender Bias in GPT Generated English Text. (arXiv:2310.17428v1 [cs.CL])\nAbstract: Language serves as a powerful tool for the manifestation of societal belief systems. In doing so, it also perpetuates the prevalent biases in our society. Gender bias is one of the most pervasive biases in our society and is seen in online and offline discourses. With LLMs increasingly gaining human-like fluency in text generation, gaining a nuanced understanding of the biases these systems can generate is imperative. Prior work often treats gender bias as a binary classification task. However, acknowledging that bias must be perceived at a relative scale; we investigate the generation and consequent receptivity of manual annotators to bias of varying degrees. Specifically, we create the first dataset of GPT-generated English text with normative ratings of gender bias. Ratings were obtained using Best--Worst Scaling -- an efficient comparative annotation framework. Next, we systematically analyze the variation of themes of gender biases in the observed ranking and show that identity-at",
    "path": "papers/23/10/2310.17428.json",
    "total_tokens": 976,
    "translated_title": "\"五十种偏见\": GPT生成的英文文本中的性别偏见的规范评级",
    "translated_abstract": "语言是社会信仰体系表现的强大工具。在这样做的过程中，它也使我们社会中普遍存在的偏见得以延续。性别偏见是我们社会中最普遍的偏见之一，在在线和离线讨论中都能看到。随着LLMs在文本生成中越来越像人类一样流利，了解这些系统可能产生的偏见的细微差别变得至关重要。以前的研究通常将性别偏见视为一个二元分类任务。然而，我们认识到偏见必须以相对的尺度来感知；我们调查了偏见的生成和随后的手动标注者对不同程度偏见的接受能力。具体而言，我们创建了第一个具有规范评级的GPT生成的英文文本数据集。使用Best--Worst Scaling进行评级获取--这是一个高效的比较标注框架。接下来，我们系统地分析了观察排名中性别偏见主题的变化，并展示了身份在其中的作用。",
    "tldr": "本研究通过创建包含规范评级的GPT生成的英文文本数据集，系统地分析了观察到的性别偏见主题的变化及其对偏见的感知。通过认识到偏见必须以相对的尺度来感知，本研究对不同程度偏见的接受能力进行了调查，对性别偏见的研究提供了新的视角。",
    "en_tdlr": "This study analyzes the variation of gender bias in GPT-generated English text by creating a dataset with normative ratings. By investigating the receptivity to bias of varying degrees and acknowledging the relative scale of bias perception, this study provides a new perspective on understanding gender bias."
}