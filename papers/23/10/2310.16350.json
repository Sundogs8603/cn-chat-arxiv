{
    "title": "Unraveling Feature Extraction Mechanisms in Neural Networks. (arXiv:2310.16350v1 [cs.CL])",
    "abstract": "The underlying mechanism of neural networks in capturing precise knowledge has been the subject of consistent research efforts. In this work, we propose a theoretical approach based on Neural Tangent Kernels (NTKs) to investigate such mechanisms. Specifically, considering the infinite network width, we hypothesize the learning dynamics of target models may intuitively unravel the features they acquire from training data, deepening our insights into their internal mechanisms. We apply our approach to several fundamental models and reveal how these models leverage statistical features during gradient descent and how they are integrated into final decisions. We also discovered that the choice of activation function can affect feature extraction. For instance, the use of the \\textit{ReLU} activation function could potentially introduce a bias in features, providing a plausible explanation for its replacement with alternative functions in recent pre-trained language models. Additionally, we",
    "link": "http://arxiv.org/abs/2310.16350",
    "context": "Title: Unraveling Feature Extraction Mechanisms in Neural Networks. (arXiv:2310.16350v1 [cs.CL])\nAbstract: The underlying mechanism of neural networks in capturing precise knowledge has been the subject of consistent research efforts. In this work, we propose a theoretical approach based on Neural Tangent Kernels (NTKs) to investigate such mechanisms. Specifically, considering the infinite network width, we hypothesize the learning dynamics of target models may intuitively unravel the features they acquire from training data, deepening our insights into their internal mechanisms. We apply our approach to several fundamental models and reveal how these models leverage statistical features during gradient descent and how they are integrated into final decisions. We also discovered that the choice of activation function can affect feature extraction. For instance, the use of the \\textit{ReLU} activation function could potentially introduce a bias in features, providing a plausible explanation for its replacement with alternative functions in recent pre-trained language models. Additionally, we",
    "path": "papers/23/10/2310.16350.json",
    "total_tokens": 878,
    "translated_title": "揭示神经网络中的特征提取机制",
    "translated_abstract": "神经网络在捕捉精确知识方面的基本机制一直是持续研究的对象。本研究提出了一种基于神经切线核（NTK）的理论方法，用于研究这些机制。具体而言，考虑无限网络宽度，我们猜测目标模型的学习动态可能直观地揭示其从训练数据中获取的特征，进一步加深我们对其内部机制的理解。我们将该方法应用于几个基本模型，并揭示了这些模型在梯度下降过程中如何利用统计特征、以及它们如何融入最终的决策中。我们还发现激活函数的选择会影响特征提取。例如，使用ReLU激活函数可能会引入特征偏差，这可以解释为什么最近的预训练语言模型中选择了替代函数来代替它。",
    "tldr": "本研究提出了一种基于神经切线核的理论方法，研究神经网络中的特征提取机制。研究发现在梯度下降过程中模型如何利用统计特征，并揭示了激活函数选择对特征提取的影响。"
}