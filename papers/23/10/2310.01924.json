{
    "title": "RoFormer for Position Aware Multiple Instance Learning in Whole Slide Image Classification. (arXiv:2310.01924v1 [cs.CV])",
    "abstract": "Whole slide image (WSI) classification is a critical task in computational pathology. However, the gigapixel-size of such images remains a major challenge for the current state of deep-learning. Current methods rely on multiple-instance learning (MIL) models with frozen feature extractors. Given the the high number of instances in each image, MIL methods have long assumed independence and permutation-invariance of patches, disregarding the tissue structure and correlation between patches. Recent works started studying this correlation between instances but the computational workload of such a high number of tokens remained a limiting factor. In particular, relative position of patches remains unaddressed. We propose to apply a straightforward encoding module, namely a RoFormer layer , relying on memory-efficient exact self-attention and relative positional encoding. This module can perform full self-attention with relative position encoding on patches of large and arbitrary shaped WSIs",
    "link": "http://arxiv.org/abs/2310.01924",
    "context": "Title: RoFormer for Position Aware Multiple Instance Learning in Whole Slide Image Classification. (arXiv:2310.01924v1 [cs.CV])\nAbstract: Whole slide image (WSI) classification is a critical task in computational pathology. However, the gigapixel-size of such images remains a major challenge for the current state of deep-learning. Current methods rely on multiple-instance learning (MIL) models with frozen feature extractors. Given the the high number of instances in each image, MIL methods have long assumed independence and permutation-invariance of patches, disregarding the tissue structure and correlation between patches. Recent works started studying this correlation between instances but the computational workload of such a high number of tokens remained a limiting factor. In particular, relative position of patches remains unaddressed. We propose to apply a straightforward encoding module, namely a RoFormer layer , relying on memory-efficient exact self-attention and relative positional encoding. This module can perform full self-attention with relative position encoding on patches of large and arbitrary shaped WSIs",
    "path": "papers/23/10/2310.01924.json",
    "total_tokens": 910,
    "translated_title": "RoFormer对于全幻灯片图像分类中的位置感知多实例学习的应用",
    "translated_abstract": "全幻灯片图像分类是计算病理学中的关键任务。然而，这种图像的几个十亿像素规模对于现有的深度学习方法仍然是一个重要挑战。当前的方法依赖于具有冻结特征提取器的多实例学习模型。鉴于每个图像中实例的数量较高，多实例学习方法通常假设补丁的独立性和排序不变性，忽略了组织结构和补丁之间的相关性。最近的研究开始研究实例之间的相关性，但是这种大量令牌的计算工作量仍然是一个限制因素。尤其是补丁的相对位置问题仍未得到解决。我们提出使用一种直接的编码模块，即RoFormer层，依靠内存高效的准确自注意力和相对位置编码。该模块可以在大型和任意形状的幻灯片补丁上进行完全自注意力计算和相对位置编码。",
    "tldr": "RoFormer模块可以为全幻灯片图像分类任务中的位置感知多实例学习提供准确自注意力和相对位置编码，克服了当前方法中对补丁独立性和排序不变性的假设，并解决了计算工作量过大的问题。",
    "en_tdlr": "The RoFormer module provides accurate self-attention and relative positional encoding for position aware multiple instance learning in whole slide image classification, overcoming the assumptions of patch independence and permutation invariance in current methods, and addressing the issue of high computational workload."
}