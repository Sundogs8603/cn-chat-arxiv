{
    "title": "MIST: Medical Image Segmentation Transformer with Convolutional Attention Mixing (CAM) Decoder. (arXiv:2310.19898v1 [cs.CV])",
    "abstract": "One of the common and promising deep learning approaches used for medical image segmentation is transformers, as they can capture long-range dependencies among the pixels by utilizing self-attention. Despite being successful in medical image segmentation, transformers face limitations in capturing local contexts of pixels in multimodal dimensions. We propose a Medical Image Segmentation Transformer (MIST) incorporating a novel Convolutional Attention Mixing (CAM) decoder to address this issue. MIST has two parts: a pre-trained multi-axis vision transformer (MaxViT) is used as an encoder, and the encoded feature representation is passed through the CAM decoder for segmenting the images. In the CAM decoder, an attention-mixer combining multi-head self-attention, spatial attention, and squeeze and excitation attention modules is introduced to capture long-range dependencies in all spatial dimensions. Moreover, to enhance spatial information gain, deep and shallow convolutions are used for",
    "link": "http://arxiv.org/abs/2310.19898",
    "context": "Title: MIST: Medical Image Segmentation Transformer with Convolutional Attention Mixing (CAM) Decoder. (arXiv:2310.19898v1 [cs.CV])\nAbstract: One of the common and promising deep learning approaches used for medical image segmentation is transformers, as they can capture long-range dependencies among the pixels by utilizing self-attention. Despite being successful in medical image segmentation, transformers face limitations in capturing local contexts of pixels in multimodal dimensions. We propose a Medical Image Segmentation Transformer (MIST) incorporating a novel Convolutional Attention Mixing (CAM) decoder to address this issue. MIST has two parts: a pre-trained multi-axis vision transformer (MaxViT) is used as an encoder, and the encoded feature representation is passed through the CAM decoder for segmenting the images. In the CAM decoder, an attention-mixer combining multi-head self-attention, spatial attention, and squeeze and excitation attention modules is introduced to capture long-range dependencies in all spatial dimensions. Moreover, to enhance spatial information gain, deep and shallow convolutions are used for",
    "path": "papers/23/10/2310.19898.json",
    "total_tokens": 890,
    "translated_title": "MIST: 具有卷积注意力混合（CAM）解码器的医学图像分割Transformer",
    "translated_abstract": "医学图像分割常用的深度学习方法之一是Transformer，通过利用自注意力机制，可以捕捉像素之间的长程依赖关系。尽管Transformer在医学图像分割方面取得了成功，但在多模态尺寸中捕捉像素的局部上下文方面存在局限性。我们提出了一种医学图像分割Transformer（MIST），其中包含了一种新颖的卷积注意力混合（CAM）解码器，以解决此问题。MIST由两部分组成：首先使用预训练的多轴视觉Transformer（MaxViT）作为编码器，然后通过CAM解码器对编码的特征表示进行图像分割。在CAM解码器中，引入了一个注意力混合器，结合了多头自注意力、空间注意力和压缩激励注意力模块，以捕捉所有空间维度中的长程依赖关系。此外，为了增强空间信息的获取，还使用了深层和浅层卷积。",
    "tldr": "提出了一种医学图像分割Transformer（MIST），利用Convolutional Attention Mixing（CAM）解码器解决了Transformer在多模态尺寸中捕捉像素局部上下文的局限性。"
}