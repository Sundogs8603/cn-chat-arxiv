{
    "title": "Recent Advances in Multi-modal 3D Scene Understanding: A Comprehensive Survey and Evaluation. (arXiv:2310.15676v1 [cs.CV])",
    "abstract": "Multi-modal 3D scene understanding has gained considerable attention due to its wide applications in many areas, such as autonomous driving and human-computer interaction. Compared to conventional single-modal 3D understanding, introducing an additional modality not only elevates the richness and precision of scene interpretation but also ensures a more robust and resilient understanding. This becomes especially crucial in varied and challenging environments where solely relying on 3D data might be inadequate. While there has been a surge in the development of multi-modal 3D methods over past three years, especially those integrating multi-camera images (3D+2D) and textual descriptions (3D+language), a comprehensive and in-depth review is notably absent. In this article, we present a systematic survey of recent progress to bridge this gap. We begin by briefly introducing a background that formally defines various 3D multi-modal tasks and summarizes their inherent challenges. After that",
    "link": "http://arxiv.org/abs/2310.15676",
    "context": "Title: Recent Advances in Multi-modal 3D Scene Understanding: A Comprehensive Survey and Evaluation. (arXiv:2310.15676v1 [cs.CV])\nAbstract: Multi-modal 3D scene understanding has gained considerable attention due to its wide applications in many areas, such as autonomous driving and human-computer interaction. Compared to conventional single-modal 3D understanding, introducing an additional modality not only elevates the richness and precision of scene interpretation but also ensures a more robust and resilient understanding. This becomes especially crucial in varied and challenging environments where solely relying on 3D data might be inadequate. While there has been a surge in the development of multi-modal 3D methods over past three years, especially those integrating multi-camera images (3D+2D) and textual descriptions (3D+language), a comprehensive and in-depth review is notably absent. In this article, we present a systematic survey of recent progress to bridge this gap. We begin by briefly introducing a background that formally defines various 3D multi-modal tasks and summarizes their inherent challenges. After that",
    "path": "papers/23/10/2310.15676.json",
    "total_tokens": 883,
    "translated_title": "多模态3D场景理解的最新进展：一项全面调查和评估",
    "translated_abstract": "多模态3D场景理解因其在自动驾驶和人机交互等许多领域中的广泛应用而受到了广泛关注。与传统的单模态3D理解相比，引入额外的模态不仅提升了场景解释的丰富性和准确性，还确保了更稳健和弹性的理解。这在多样化和具有挑战性的环境中尤为关键，仅依靠3D数据可能是不足够的。尽管在过去三年中出现了许多多模态3D方法的发展，特别是那些整合多摄像头图像（3D+2D）和文本描述（3D+语言）的方法，但缺乏全面深入的评估。在本文中，我们对最近的进展进行了系统的调查，以填补这一空白。我们首先简要介绍了一个背景，正式定义了各种3D多模态任务，并总结了它们固有的挑战。",
    "tldr": "多模态3D场景理解在自动驾驶和人机交互等领域中应用广泛。本文从理论的角度对多模态3D方法的进展进行了全面调查和评估。",
    "en_tdlr": "Multi-modal 3D scene understanding has wide applications in areas like autonomous driving and human-computer interaction. This article presents a comprehensive survey and evaluation of recent progress in multi-modal 3D methods from a theoretical perspective."
}