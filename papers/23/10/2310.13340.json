{
    "title": "Large-Scale and Multi-Perspective Opinion Summarization with Diverse Review Subsets. (arXiv:2310.13340v1 [cs.CL])",
    "abstract": "Opinion summarization is expected to digest larger review sets and provide summaries from different perspectives. However, most existing solutions are deficient in epitomizing extensive reviews and offering opinion summaries from various angles due to the lack of designs for information selection. To this end, we propose SUBSUMM, a supervised summarization framework for large-scale multi-perspective opinion summarization. SUBSUMM consists of a review sampling strategy set and a two-stage training scheme. The sampling strategies take sentiment orientation and contrastive information value into consideration, with which the review subsets from different perspectives and quality levels can be selected. Subsequently, the summarizer is encouraged to learn from the sub-optimal and optimal subsets successively in order to capitalize on the massive input. Experimental results on AmaSum and Rotten Tomatoes datasets demonstrate that SUBSUMM is adept at generating pros, cons, and verdict summarie",
    "link": "http://arxiv.org/abs/2310.13340",
    "context": "Title: Large-Scale and Multi-Perspective Opinion Summarization with Diverse Review Subsets. (arXiv:2310.13340v1 [cs.CL])\nAbstract: Opinion summarization is expected to digest larger review sets and provide summaries from different perspectives. However, most existing solutions are deficient in epitomizing extensive reviews and offering opinion summaries from various angles due to the lack of designs for information selection. To this end, we propose SUBSUMM, a supervised summarization framework for large-scale multi-perspective opinion summarization. SUBSUMM consists of a review sampling strategy set and a two-stage training scheme. The sampling strategies take sentiment orientation and contrastive information value into consideration, with which the review subsets from different perspectives and quality levels can be selected. Subsequently, the summarizer is encouraged to learn from the sub-optimal and optimal subsets successively in order to capitalize on the massive input. Experimental results on AmaSum and Rotten Tomatoes datasets demonstrate that SUBSUMM is adept at generating pros, cons, and verdict summarie",
    "path": "papers/23/10/2310.13340.json",
    "total_tokens": 867,
    "translated_title": "大规模多透视观点摘要化与多样化评论子集",
    "translated_abstract": "观点摘要化希望能够消化更大量的评论集，并提供来自不同角度的摘要。然而，现有的解决方案大多因为缺乏信息选择设计而无法精炼广泛的评论和提供多角度观点的摘要。为此，我们提出了SUBSUMM，一种用于大规模多透视观点摘要化的有监督摘要框架。SUBSUMM包括一个评论采样策略集和一个两阶段训练方案。这些采样策略考虑了情感倾向和对比信息价值，可以选择不同角度和质量水平的评论子集。随后，摘要器依次从次优和最优子集中进行学习，以充分利用大量的输入。在AmaSum和Rotten Tomatoes数据集上的实验结果表明，SUBSUMM能够熟练生成优点、缺点和结论摘要。",
    "tldr": "SUBSUMM是一种用于大规模多透视观点摘要化的有监督摘要框架，能够从不同角度选择评论子集，并通过两阶段训练方案进行学习，以提供精炼的多角度的摘要。",
    "en_tdlr": "SUBSUMM is a supervised summarization framework for large-scale multi-perspective opinion summarization, which selects review subsets from different perspectives and learns from them through a two-stage training scheme, providing concise summaries from diverse angles."
}