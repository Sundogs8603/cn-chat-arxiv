{
    "title": "Uncertainty Quantification using Generative Approach. (arXiv:2310.09338v1 [cs.LG])",
    "abstract": "We present the Incremental Generative Monte Carlo (IGMC) method, designed to measure uncertainty in deep neural networks using deep generative approaches. IGMC iteratively trains generative models, adding their output to the dataset, to compute the posterior distribution of the expectation of a random variable. We provide a theoretical guarantee of the convergence rate of IGMC relative to the sample size and sampling depth. Due to its compatibility with deep generative approaches, IGMC is adaptable to both neural network classification and regression tasks. We empirically study the behavior of IGMC on the MNIST digit classification task.",
    "link": "http://arxiv.org/abs/2310.09338",
    "context": "Title: Uncertainty Quantification using Generative Approach. (arXiv:2310.09338v1 [cs.LG])\nAbstract: We present the Incremental Generative Monte Carlo (IGMC) method, designed to measure uncertainty in deep neural networks using deep generative approaches. IGMC iteratively trains generative models, adding their output to the dataset, to compute the posterior distribution of the expectation of a random variable. We provide a theoretical guarantee of the convergence rate of IGMC relative to the sample size and sampling depth. Due to its compatibility with deep generative approaches, IGMC is adaptable to both neural network classification and regression tasks. We empirically study the behavior of IGMC on the MNIST digit classification task.",
    "path": "papers/23/10/2310.09338.json",
    "total_tokens": 801,
    "translated_title": "使用生成方法的不确定性量化",
    "translated_abstract": "我们提出了增量生成Monte Carlo (IGMC) 方法，该方法使用深度生成方法来测量深度神经网络中的不确定性。IGMC通过迭代训练生成模型，并将其输出添加到数据集中，以计算随机变量期望的后验分布。我们提供了IGMC相对于样本大小和抽样深度的收敛速度的理论保证。由于其与深度生成方法的兼容性，IGMC适用于神经网络分类和回归任务。我们在MNIST数字分类任务上对IGMC的行为进行了实证研究。",
    "tldr": "这篇论文介绍了一种使用深度生成方法的增量生成蒙特卡洛(IGMC)方法，用于测量深度神经网络中的不确定性。通过迭代训练生成模型并将其输出添加到数据集中，IGMC能计算随机变量期望的后验分布，并且具有理论保证的收敛速度。该方法适用于神经网络分类和回归任务，并在MNIST数字分类任务上进行了实证研究。",
    "en_tdlr": "This paper presents the Incremental Generative Monte Carlo (IGMC) method, which uses deep generative approaches to measure uncertainty in deep neural networks. IGMC iteratively trains generative models and computes the posterior distribution of the expectation of a random variable by adding their output to the dataset. It provides a theoretical guarantee of convergence rate relative to sample size and sampling depth. IGMC is adaptable to both neural network classification and regression tasks, and its behavior is empirically studied on the MNIST digit classification task."
}