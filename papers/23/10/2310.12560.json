{
    "title": "Fast Model Debias with Machine Unlearning. (arXiv:2310.12560v1 [cs.LG])",
    "abstract": "Recent discoveries have revealed that deep neural networks might behave in a biased manner in many real-world scenarios. For instance, deep networks trained on a large-scale face recognition dataset CelebA tend to predict blonde hair for females and black hair for males. Such biases not only jeopardize the robustness of models but also perpetuate and amplify social biases, which is especially concerning for automated decision-making processes in healthcare, recruitment, etc., as they could exacerbate unfair economic and social inequalities among different groups. Existing debiasing methods suffer from high costs in bias labeling or model re-training, while also exhibiting a deficiency in terms of elucidating the origins of biases within the model. To this respect, we propose a fast model debiasing framework (FMD) which offers an efficient approach to identify, evaluate and remove biases inherent in trained models. The FMD identifies biased attributes through an explicit counterfactual ",
    "link": "http://arxiv.org/abs/2310.12560",
    "context": "Title: Fast Model Debias with Machine Unlearning. (arXiv:2310.12560v1 [cs.LG])\nAbstract: Recent discoveries have revealed that deep neural networks might behave in a biased manner in many real-world scenarios. For instance, deep networks trained on a large-scale face recognition dataset CelebA tend to predict blonde hair for females and black hair for males. Such biases not only jeopardize the robustness of models but also perpetuate and amplify social biases, which is especially concerning for automated decision-making processes in healthcare, recruitment, etc., as they could exacerbate unfair economic and social inequalities among different groups. Existing debiasing methods suffer from high costs in bias labeling or model re-training, while also exhibiting a deficiency in terms of elucidating the origins of biases within the model. To this respect, we propose a fast model debiasing framework (FMD) which offers an efficient approach to identify, evaluate and remove biases inherent in trained models. The FMD identifies biased attributes through an explicit counterfactual ",
    "path": "papers/23/10/2310.12560.json",
    "total_tokens": 901,
    "translated_title": "快速模型去偏置与机器取消学习",
    "translated_abstract": "最近的研究发现，深度神经网络在许多现实场景中可能表现出偏差的行为。例如，在一个大规模的人脸识别数据集CelebA上训练的深度网络倾向于预测女性的金色头发和男性的黑色头发。这些偏差不仅危害了模型的稳健性，而且会持续和放大社会偏见，这对于医疗、招聘等自动决策过程尤其令人担忧，因为它们可能加剧不同群体之间的不公平经济和社会不平等。现有的去偏置方法在偏见标记或模型重新训练方面成本高昂，同时也在阐明模型内部偏见的起源方面存在不足。为此，我们提出了一个快速模型去偏置框架(FMD)，它提供了一种有效的方法来识别、评估和消除训练模型中固有的偏见。FMD通过显式的反事实机制来识别偏置属性。",
    "tldr": "这篇论文提出了一种快速模型去偏置的框架（FMD），可以有效识别、评估和消除深度神经网络中的偏见，解决了现有方法在成本和解释性方面的不足。",
    "en_tdlr": "This paper proposes a fast model debiasing framework (FMD) that can effectively identify, evaluate, and remove biases in deep neural networks, addressing the shortcomings of existing methods in terms of cost and interpretability."
}