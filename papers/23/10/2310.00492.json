{
    "title": "From Language Modeling to Instruction Following: Understanding the Behavior Shift in LLMs after Instruction Tuning",
    "abstract": "arXiv:2310.00492v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) have achieved remarkable success, where instruction tuning is the critical step in aligning LLMs with user intentions. In this work, we investigate how the instruction tuning adjusts pre-trained models with a focus on intrinsic changes. Specifically, we first develop several local and global explanation methods, including a gradient-based method for input-output attribution and techniques for interpreting patterns and concepts in self-attention and feed-forward layers. The impact of instruction tuning is then studied by comparing the explanations derived from the pre-trained and instruction-tuned models. This approach provides an internal perspective of the model shifts on a human-comprehensible level. Our findings reveal three significant impacts of instruction tuning: 1) It empowers LLMs to recognize the instruction parts from user prompts, and promotes the response generation constantly condition",
    "link": "https://arxiv.org/abs/2310.00492",
    "context": "Title: From Language Modeling to Instruction Following: Understanding the Behavior Shift in LLMs after Instruction Tuning\nAbstract: arXiv:2310.00492v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) have achieved remarkable success, where instruction tuning is the critical step in aligning LLMs with user intentions. In this work, we investigate how the instruction tuning adjusts pre-trained models with a focus on intrinsic changes. Specifically, we first develop several local and global explanation methods, including a gradient-based method for input-output attribution and techniques for interpreting patterns and concepts in self-attention and feed-forward layers. The impact of instruction tuning is then studied by comparing the explanations derived from the pre-trained and instruction-tuned models. This approach provides an internal perspective of the model shifts on a human-comprehensible level. Our findings reveal three significant impacts of instruction tuning: 1) It empowers LLMs to recognize the instruction parts from user prompts, and promotes the response generation constantly condition",
    "path": "papers/23/10/2310.00492.json",
    "total_tokens": 844,
    "translated_title": "从语言建模到指令跟随：理解指令调整后LLMs中行为的转变",
    "translated_abstract": "大型语言模型（LLMs）已经取得了显著的成功，其中指令调整是将LLMs与用户意图对齐的关键步骤。在这项工作中，我们研究了指令调整如何调整经过预训练的模型，重点关注内在变化。具体来说，我们首先开发了几种本地和全局解释方法，包括一种基于梯度的输入输出归因方法，以及用于解释自注意力和前馈层中的模式和概念的技术。然后通过比较从预训练和指令调整模型中得出的解释来研究指令调整的影响。这种方法在人可理解的水平上提供了模型转变的内部视角。我们的研究发现了指令调整的三个重要影响：1）它使LLMs能够识别用户提示中的指令部分，并不断促进响应生成",
    "tldr": "指令调整对LLMs产生了三个重要影响：1）使其能够识别用户提示中的指令部分；2）促进响应生成的不断调整",
    "en_tdlr": "Instruction tuning has three significant impacts on LLMs: 1) enabling them to recognize instruction parts from user prompts; 2) promoting continuous adjustments in response generation."
}