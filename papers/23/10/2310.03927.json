{
    "title": "Improving classifier decision boundaries using nearest neighbors. (arXiv:2310.03927v1 [cs.LG])",
    "abstract": "Neural networks are not learning optimal decision boundaries. We show that decision boundaries are situated in areas of low training data density. They are impacted by few training samples which can easily lead to overfitting. We provide a simple algorithm performing a weighted average of the prediction of a sample and its nearest neighbors' (computed in latent space) leading to a minor favorable outcomes for a variety of important measures for neural networks. In our evaluation, we employ various self-trained and pre-trained convolutional neural networks to show that our approach improves (i) resistance to label noise, (ii) robustness against adversarial attacks, (iii) classification accuracy, and to some degree even (iv) interpretability. While improvements are not necessarily large in all four areas, our approach is conceptually simple, i.e., improvements come without any modification to network architecture, training procedure or dataset. Furthermore, they are in stark contrast to ",
    "link": "http://arxiv.org/abs/2310.03927",
    "context": "Title: Improving classifier decision boundaries using nearest neighbors. (arXiv:2310.03927v1 [cs.LG])\nAbstract: Neural networks are not learning optimal decision boundaries. We show that decision boundaries are situated in areas of low training data density. They are impacted by few training samples which can easily lead to overfitting. We provide a simple algorithm performing a weighted average of the prediction of a sample and its nearest neighbors' (computed in latent space) leading to a minor favorable outcomes for a variety of important measures for neural networks. In our evaluation, we employ various self-trained and pre-trained convolutional neural networks to show that our approach improves (i) resistance to label noise, (ii) robustness against adversarial attacks, (iii) classification accuracy, and to some degree even (iv) interpretability. While improvements are not necessarily large in all four areas, our approach is conceptually simple, i.e., improvements come without any modification to network architecture, training procedure or dataset. Furthermore, they are in stark contrast to ",
    "path": "papers/23/10/2310.03927.json",
    "total_tokens": 935,
    "translated_title": "使用最近邻改善分类器决策边界",
    "translated_abstract": "神经网络无法学习最优决策边界。我们表明决策边界位于训练数据密度低的区域，并受到少量训练样本的影响，容易导致过拟合。我们提供一个简单的算法，在潜在空间中计算样本及其最近邻的预测的加权平均，对于神经网络的各种重要指标导致了一些有利的结果。在我们的评估中，我们使用各种自训练和预训练的卷积神经网络来展示我们的方法改善了：(i)对标签噪声的抵抗力，(ii)对抗性攻击的鲁棒性，(iii)分类准确性，甚至在一定程度上还有(iv)可解释性。虽然在这四个方面改进不一定是很大的，但我们的方法在概念上很简单，即改进不需要对网络架构、训练过程或数据集进行任何修改。而且，这些改进与",
    "tldr": "该论文提出了一个简单的算法，通过计算样本及其最近邻在潜在空间中的预测的加权平均，改善了神经网络在对抗性攻击、标签噪声、分类准确性和可解释性方面的性能，而无需改变网络架构、训练过程或数据集。",
    "en_tdlr": "This paper proposes a simple algorithm that improves the performance of neural networks in terms of resistance to adversarial attacks, label noise, classification accuracy, and interpretability by calculating the weighted average of the prediction of a sample and its nearest neighbors in latent space, without modifying the network architecture, training procedure, or dataset."
}