{
    "title": "Balanced Group Convolution: An Improved Group Convolution Based on Approximability Estimates. (arXiv:2310.12461v1 [cs.LG])",
    "abstract": "The performance of neural networks has been significantly improved by increasing the number of channels in convolutional layers. However, this increase in performance comes with a higher computational cost, resulting in numerous studies focused on reducing it. One promising approach to address this issue is group convolution, which effectively reduces the computational cost by grouping channels. However, to the best of our knowledge, there has been no theoretical analysis on how well the group convolution approximates the standard convolution. In this paper, we mathematically analyze the approximation of the group convolution to the standard convolution with respect to the number of groups. Furthermore, we propose a novel variant of the group convolution called balanced group convolution, which shows a higher approximation with a small additional computational cost. We provide experimental results that validate our theoretical findings and demonstrate the superior performance of the ba",
    "link": "http://arxiv.org/abs/2310.12461",
    "context": "Title: Balanced Group Convolution: An Improved Group Convolution Based on Approximability Estimates. (arXiv:2310.12461v1 [cs.LG])\nAbstract: The performance of neural networks has been significantly improved by increasing the number of channels in convolutional layers. However, this increase in performance comes with a higher computational cost, resulting in numerous studies focused on reducing it. One promising approach to address this issue is group convolution, which effectively reduces the computational cost by grouping channels. However, to the best of our knowledge, there has been no theoretical analysis on how well the group convolution approximates the standard convolution. In this paper, we mathematically analyze the approximation of the group convolution to the standard convolution with respect to the number of groups. Furthermore, we propose a novel variant of the group convolution called balanced group convolution, which shows a higher approximation with a small additional computational cost. We provide experimental results that validate our theoretical findings and demonstrate the superior performance of the ba",
    "path": "papers/23/10/2310.12461.json",
    "total_tokens": 875,
    "translated_title": "平衡组卷积：一种基于近似性评估的改进组卷积方法",
    "translated_abstract": "通过增加卷积层中的通道数量，神经网络的性能得到了显著提升。然而，这种性能提升伴随着更高的计算成本，导致许多研究致力于减少它。解决这个问题的一种有希望的方法是组卷积，通过分组通道有效地减少计算成本。然而，据我们所知，关于组卷积如何近似标准卷积还没有进行理论分析。本文在理论上分析了组卷积相对于组数的标准卷积的近似程度。此外，我们提出了一种名为平衡组卷积的新变体，它在仅增加小的计算成本的情况下展现出更高的近似性。我们提供的实验结果验证了我们的理论发现，并展示了平衡组卷积的卓越性能。",
    "tldr": "本文通过理论分析，发现组卷积相对于标准卷积的近似程度，提出了一种名为平衡组卷积的新变体，它在增加较小计算成本的情况下，展现出更高的近似性。实验结果验证了该方法的卓越性能。",
    "en_tdlr": "This paper mathematically analyzes the approximation of group convolution to standard convolution and proposes a novel variant called balanced group convolution, which shows higher approximation with a small additional computational cost. Experimental results validate the superior performance of this method."
}