{
    "title": "Pose-to-Motion: Cross-Domain Motion Retargeting with Pose Prior. (arXiv:2310.20249v1 [cs.CV])",
    "abstract": "Creating believable motions for various characters has long been a goal in computer graphics. Current learning-based motion synthesis methods depend on extensive motion datasets, which are often challenging, if not impossible, to obtain. On the other hand, pose data is more accessible, since static posed characters are easier to create and can even be extracted from images using recent advancements in computer vision. In this paper, we utilize this alternative data source and introduce a neural motion synthesis approach through retargeting. Our method generates plausible motions for characters that have only pose data by transferring motion from an existing motion capture dataset of another character, which can have drastically different skeletons. Our experiments show that our method effectively combines the motion features of the source character with the pose features of the target character, and performs robustly with small or noisy pose data sets, ranging from a few artist-created",
    "link": "http://arxiv.org/abs/2310.20249",
    "context": "Title: Pose-to-Motion: Cross-Domain Motion Retargeting with Pose Prior. (arXiv:2310.20249v1 [cs.CV])\nAbstract: Creating believable motions for various characters has long been a goal in computer graphics. Current learning-based motion synthesis methods depend on extensive motion datasets, which are often challenging, if not impossible, to obtain. On the other hand, pose data is more accessible, since static posed characters are easier to create and can even be extracted from images using recent advancements in computer vision. In this paper, we utilize this alternative data source and introduce a neural motion synthesis approach through retargeting. Our method generates plausible motions for characters that have only pose data by transferring motion from an existing motion capture dataset of another character, which can have drastically different skeletons. Our experiments show that our method effectively combines the motion features of the source character with the pose features of the target character, and performs robustly with small or noisy pose data sets, ranging from a few artist-created",
    "path": "papers/23/10/2310.20249.json",
    "total_tokens": 957,
    "translated_title": "Pose-to-Motion: 基于姿势先验的跨领域动作重定向",
    "translated_abstract": "在计算机图形学领域，创造逼真的角色动作一直是一个目标。目前的基于学习的动作合成方法依赖于大量的动作数据集，这些数据集往往很难甚至不可能获得。另一方面，姿势数据更易获取，因为静态的角色姿势更容易创建，并且可以通过最新的计算机视觉技术从图像中提取出来。在本文中，我们利用这个替代数据源，引入了一种神经动作合成方法通过重定向。我们的方法通过从另一个具有极其不同骨架的角色的现有运动捕捉数据集中转移动作，为仅具有姿势数据的角色生成合理的动作。实验证明我们的方法有效地将源角色的动作特征与目标角色的姿势特征相结合，并且在姿势数据集很小或带有噪声的情况下表现出鲁棒性，从几个艺术家创建的数据集到大规模真实数据集等各种情况的实验都取得了良好的结果。",
    "tldr": "本文提出了一种基于姿势先验的跨领域动作重定向方法，通过从另一个具有不同骨架的角色的现有动作数据集中转移动作，为仅具有姿势数据的角色生成合理的动作。实验证明该方法在小样本或噪声数据集情况下表现鲁棒性。"
}