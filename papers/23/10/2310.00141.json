{
    "title": "The Gift of Feedback: Improving ASR Model Quality by Learning from User Corrections through Federated Learning. (arXiv:2310.00141v1 [cs.CL])",
    "abstract": "Automatic speech recognition (ASR) models are typically trained on large datasets of transcribed speech. As language evolves and new terms come into use, these models can become outdated and stale. In the context of models trained on the server but deployed on edge devices, errors may result from the mismatch between server training data and actual on-device usage. In this work, we seek to continually learn from on-device user corrections through Federated Learning (FL) to address this issue. We explore techniques to target fresh terms that the model has not previously encountered, learn long-tail words, and mitigate catastrophic forgetting. In experimental evaluations, we find that the proposed techniques improve model recognition of fresh terms, while preserving quality on the overall language distribution.",
    "link": "http://arxiv.org/abs/2310.00141",
    "context": "Title: The Gift of Feedback: Improving ASR Model Quality by Learning from User Corrections through Federated Learning. (arXiv:2310.00141v1 [cs.CL])\nAbstract: Automatic speech recognition (ASR) models are typically trained on large datasets of transcribed speech. As language evolves and new terms come into use, these models can become outdated and stale. In the context of models trained on the server but deployed on edge devices, errors may result from the mismatch between server training data and actual on-device usage. In this work, we seek to continually learn from on-device user corrections through Federated Learning (FL) to address this issue. We explore techniques to target fresh terms that the model has not previously encountered, learn long-tail words, and mitigate catastrophic forgetting. In experimental evaluations, we find that the proposed techniques improve model recognition of fresh terms, while preserving quality on the overall language distribution.",
    "path": "papers/23/10/2310.00141.json",
    "total_tokens": 862,
    "translated_title": "用户反馈的馈赠：通过联合学习从用户纠正中提高ASR模型质量",
    "translated_abstract": "自动语音识别（ASR）模型通常在大量的转录语音数据集上进行训练。随着语言的发展和新词汇的出现，这些模型可能变得过时和陈旧。在基于服务器训练但部署在边缘设备上的模型中，错误可能是由于服务器训练数据与实际设备使用之间的不匹配导致的。在这项工作中，我们通过联合学习来不断从设备上的用户纠正中学习，从而解决这个问题。我们探索了一些技术，以针对模型以前未遇到过的新词汇，学习长尾词汇，并减轻灾难性遗忘现象。在实验评估中，我们发现所提出的技术改进了模型对新词汇的识别，同时保持了整体语言分布的质量。",
    "tldr": "本论文通过联合学习来持续从用户纠正中学习，以解决自动语音识别模型因为语言的发展和新词汇的出现而变得过时的问题，并通过针对新词汇、长尾词汇和灾难性遗忘等技术提高模型的识别效果。",
    "en_tdlr": "This paper addresses the issue of outdated automatic speech recognition (ASR) models by continuously learning from on-device user corrections through Federated Learning (FL), improving recognition of fresh and long-tail terms while preserving overall language quality."
}