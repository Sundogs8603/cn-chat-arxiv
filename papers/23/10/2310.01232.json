{
    "title": "Modality-aware Transformer for Financial Time series Forecasting",
    "abstract": "arXiv:2310.01232v2 Announce Type: replace  Abstract: Time series forecasting presents a significant challenge, particularly when its accuracy relies on external data sources rather than solely on historical values. This issue is prevalent in the financial sector, where the future behavior of time series is often intricately linked to information derived from various textual reports and a multitude of economic indicators. In practice, the key challenge lies in constructing a reliable time series forecasting model capable of harnessing data from diverse sources and extracting valuable insights to predict the target time series accurately. In this work, we tackle this challenging problem and introduce a novel multimodal transformer-based model named the \\textit{Modality-aware Transformer}. Our model excels in exploring the power of both categorical text and numerical timeseries to forecast the target time series effectively while providing insights through its neural attention mechanism. ",
    "link": "https://arxiv.org/abs/2310.01232",
    "context": "Title: Modality-aware Transformer for Financial Time series Forecasting\nAbstract: arXiv:2310.01232v2 Announce Type: replace  Abstract: Time series forecasting presents a significant challenge, particularly when its accuracy relies on external data sources rather than solely on historical values. This issue is prevalent in the financial sector, where the future behavior of time series is often intricately linked to information derived from various textual reports and a multitude of economic indicators. In practice, the key challenge lies in constructing a reliable time series forecasting model capable of harnessing data from diverse sources and extracting valuable insights to predict the target time series accurately. In this work, we tackle this challenging problem and introduce a novel multimodal transformer-based model named the \\textit{Modality-aware Transformer}. Our model excels in exploring the power of both categorical text and numerical timeseries to forecast the target time series effectively while providing insights through its neural attention mechanism. ",
    "path": "papers/23/10/2310.01232.json",
    "total_tokens": 804,
    "translated_title": "面向金融时间序列预测的模态感知Transformer",
    "translated_abstract": "时间序列预测是一个重大挑战，特别是当其准确性依赖于外部数据源而不仅仅基于历史数值时。金融领域普遍存在这一问题，时间序列的未来行为常常与从各种文本报告和大量经济指标中得出的信息密切相关。在实践中，关键挑战在于构建一个可靠的时间序列预测模型，能够利用不同来源的数据并提取有价值的见解，从而准确预测目标时间序列。在这项工作中，我们解决了这一挑战性问题，引入了一种新颖的多模态基于Transformer的模型，命名为\\textit{模态感知Transformer}。我们的模型擅长于探索分类文本和数值时间序列的力量，有效预测目标时间序列，并通过其神经注意力机制提供见解。",
    "tldr": "提出了一种新颖的模态感知Transformer模型，能够有效地利用分类文本和数值时间序列的信息来预测金融时间序列，并通过神经注意力机制提供有价值的见解。"
}