{
    "title": "Online Clustering of Bandits with Misspecified User Models. (arXiv:2310.02717v1 [cs.LG])",
    "abstract": "The contextual linear bandit is an important online learning problem where given arm features, a learning agent selects an arm at each round to maximize the cumulative rewards in the long run. A line of works, called the clustering of bandits (CB), utilize the collaborative effect over user preferences and have shown significant improvements over classic linear bandit algorithms. However, existing CB algorithms require well-specified linear user models and can fail when this critical assumption does not hold. Whether robust CB algorithms can be designed for more practical scenarios with misspecified user models remains an open problem. In this paper, we are the first to present the important problem of clustering of bandits with misspecified user models (CBMUM), where the expected rewards in user models can be perturbed away from perfect linear models. We devise two robust CB algorithms, RCLUMB and RSCLUMB (representing the learned clustering structure with dynamic graph and sets, resp",
    "link": "http://arxiv.org/abs/2310.02717",
    "context": "Title: Online Clustering of Bandits with Misspecified User Models. (arXiv:2310.02717v1 [cs.LG])\nAbstract: The contextual linear bandit is an important online learning problem where given arm features, a learning agent selects an arm at each round to maximize the cumulative rewards in the long run. A line of works, called the clustering of bandits (CB), utilize the collaborative effect over user preferences and have shown significant improvements over classic linear bandit algorithms. However, existing CB algorithms require well-specified linear user models and can fail when this critical assumption does not hold. Whether robust CB algorithms can be designed for more practical scenarios with misspecified user models remains an open problem. In this paper, we are the first to present the important problem of clustering of bandits with misspecified user models (CBMUM), where the expected rewards in user models can be perturbed away from perfect linear models. We devise two robust CB algorithms, RCLUMB and RSCLUMB (representing the learned clustering structure with dynamic graph and sets, resp",
    "path": "papers/23/10/2310.02717.json",
    "total_tokens": 887,
    "translated_title": "在用户模型错误的情况下的在线聚类强化学习",
    "translated_abstract": "上下文线性强化学习是一个重要的在线学习问题，在每轮中，给定臂的特征，学习代理选择一个臂来最大化长期的累积奖励。聚类强化学习是一系列工作，利用用户偏好的协同效应，并在经典的线性强化学习算法上取得了显著的改进。然而，现有的聚类强化学习算法需要正确规定线性用户模型，当这个关键假设不成立时，可能会失败。如何为在用户模型错误的实际情况下设计鲁棒的聚类强化学习算法仍然是一个开放的问题。在本文中，我们首次提出了在用户模型错误的情况下的聚类强化学习问题，其中用户模型中的期望奖励可能有偏差，不是完美的线性模型。我们设计了两个鲁棒的聚类强化学习算法RCLUMB和RSCLUMB（分别用动态图和集合表示学习到的聚类结构）。",
    "tldr": "本文介绍了在用户模型错误的情况下的聚类强化学习问题，并提出了两个鲁棒的聚类强化学习算法，以解决用户模型偏差的挑战。",
    "en_tdlr": "This paper introduces the problem of clustering of bandits with misspecified user models and proposes two robust clustering algorithms to address the challenge of user model bias."
}