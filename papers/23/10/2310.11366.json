{
    "title": "Lie Group Decompositions for Equivariant Neural Networks. (arXiv:2310.11366v1 [cs.LG])",
    "abstract": "Invariance and equivariance to geometrical transformations have proven to be very useful inductive biases when training (convolutional) neural network models, especially in the low-data regime. Much work has focused on the case where the symmetry group employed is compact or abelian, or both. Recent work has explored enlarging the class of transformations used to the case of Lie groups, principally through the use of their Lie algebra, as well as the group exponential and logarithm maps. The applicability of such methods to larger transformation groups is limited by the fact that depending on the group of interest $G$, the exponential map may not be surjective. Further limitations are encountered when $G$ is neither compact nor abelian. Using the structure and geometry of Lie groups and their homogeneous spaces, we present a framework by which it is possible to work with such groups primarily focusing on the Lie groups $G = \\text{GL}^{+}(n, \\mathbb{R})$ and $G = \\text{SL}(n, \\mathbb{R}",
    "link": "http://arxiv.org/abs/2310.11366",
    "context": "Title: Lie Group Decompositions for Equivariant Neural Networks. (arXiv:2310.11366v1 [cs.LG])\nAbstract: Invariance and equivariance to geometrical transformations have proven to be very useful inductive biases when training (convolutional) neural network models, especially in the low-data regime. Much work has focused on the case where the symmetry group employed is compact or abelian, or both. Recent work has explored enlarging the class of transformations used to the case of Lie groups, principally through the use of their Lie algebra, as well as the group exponential and logarithm maps. The applicability of such methods to larger transformation groups is limited by the fact that depending on the group of interest $G$, the exponential map may not be surjective. Further limitations are encountered when $G$ is neither compact nor abelian. Using the structure and geometry of Lie groups and their homogeneous spaces, we present a framework by which it is possible to work with such groups primarily focusing on the Lie groups $G = \\text{GL}^{+}(n, \\mathbb{R})$ and $G = \\text{SL}(n, \\mathbb{R}",
    "path": "papers/23/10/2310.11366.json",
    "total_tokens": 1005,
    "translated_title": "Lie Group Decompositions for Equivariant Neural Networks. (arXiv:2310.11366v1 [cs.LG]) \b(等变神经网络的Lie群分解)",
    "translated_abstract": "在训练（卷积）神经网络模型时，对几何变换的不变性和等变性被证明是非常有用的归纳偏差，特别是在低数据环境下。大部分研究集中在使用的对称群为紧致或阿贝尔群，或者两者都是。最近的研究拓展了使用的变换类别到Lie群的情况，主要通过使用其Lie代数以及群的指数和对数映射。然而，这样的方法在适用于更大的变换群时受到限制，因为根据所关心的群$G$的不同，指数映射可能不满射。当$G$既不是紧致群也不是阿贝尔群时，还会遇到进一步的限制。我们利用Lie群及其齐次空间的结构和几何特性，提出了一个可以处理这类群的框架，主要关注Lie群$G = \\text{GL}^{+}(n, \\mathbb{R})$和$G = \\text{SL}(n, \\mathbb{R}$。",
    "tldr": "本论文提出了一种基于Lie群结构和几何特性的框架，可以处理非紧致非阿贝尔的Lie群，特别关注于$\\text{GL}^{+}(n, \\mathbb{R})$和$\\text{SL}(n, \\mathbb{R})$这两个Lie群。",
    "en_tdlr": "This paper presents a framework based on the structure and geometry of Lie groups, which can handle non-compact non-abelian Lie groups, with a particular focus on $\\text{GL}^{+}(n, \\mathbb{R})$ and $\\text{SL}(n, \\mathbb{R})$."
}