{
    "title": "Practical Membership Inference Attacks Against Large-Scale Multi-Modal Models: A Pilot Study. (arXiv:2310.00108v1 [cs.LG])",
    "abstract": "Membership inference attacks (MIAs) aim to infer whether a data point has been used to train a machine learning model. These attacks can be employed to identify potential privacy vulnerabilities and detect unauthorized use of personal data. While MIAs have been traditionally studied for simple classification models, recent advancements in multi-modal pre-training, such as CLIP, have demonstrated remarkable zero-shot performance across a range of computer vision tasks. However, the sheer scale of data and models presents significant computational challenges for performing the attacks.  This paper takes a first step towards developing practical MIAs against large-scale multi-modal models. We introduce a simple baseline strategy by thresholding the cosine similarity between text and image features of a target point and propose further enhancing the baseline by aggregating cosine similarity across transformations of the target. We also present a new weakly supervised attack method that lev",
    "link": "http://arxiv.org/abs/2310.00108",
    "context": "Title: Practical Membership Inference Attacks Against Large-Scale Multi-Modal Models: A Pilot Study. (arXiv:2310.00108v1 [cs.LG])\nAbstract: Membership inference attacks (MIAs) aim to infer whether a data point has been used to train a machine learning model. These attacks can be employed to identify potential privacy vulnerabilities and detect unauthorized use of personal data. While MIAs have been traditionally studied for simple classification models, recent advancements in multi-modal pre-training, such as CLIP, have demonstrated remarkable zero-shot performance across a range of computer vision tasks. However, the sheer scale of data and models presents significant computational challenges for performing the attacks.  This paper takes a first step towards developing practical MIAs against large-scale multi-modal models. We introduce a simple baseline strategy by thresholding the cosine similarity between text and image features of a target point and propose further enhancing the baseline by aggregating cosine similarity across transformations of the target. We also present a new weakly supervised attack method that lev",
    "path": "papers/23/10/2310.00108.json",
    "total_tokens": 915,
    "translated_title": "大规模多模态模型的实际会员推断攻击：一项初步研究",
    "translated_abstract": "会员推断攻击（MIAs）旨在推断数据点是否用于训练机器学习模型。这些攻击可用于识别潜在的隐私漏洞和检测个人数据的未经授权使用。虽然传统上研究的是针对简单分类模型的MIAs，但多模态预训练（如CLIP）的最新发展已经展示了在各种计算机视觉任务上的非常好的零样本性能。然而，大规模数据和模型的规模给执行这些攻击带来了重大的计算挑战。本文首次尝试开发针对大规模多模态模型的实际MIAs。我们通过对目标点的文本和图像特征之间的余弦相似度进行阈值处理，引入了一个简单的基准策略，并提出通过对目标的变换进行余弦相似度聚合来进一步增强基准策略。我们还提出了一种新的弱监督攻击方法，对模型进行泛化攻击。",
    "tldr": "本文提出了一种针对大规模多模态模型的实际会员推断攻击方法，通过对目标点的文本和图像特征之间的余弦相似度进行阈值处理，并通过聚合相似度来进一步增强攻击效果。"
}