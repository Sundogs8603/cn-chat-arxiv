{
    "title": "MTS-LOF: Medical Time-Series Representation Learning via Occlusion-Invariant Features. (arXiv:2310.12451v1 [cs.LG])",
    "abstract": "Medical time series data are indispensable in healthcare, providing critical insights for disease diagnosis, treatment planning, and patient management. The exponential growth in data complexity, driven by advanced sensor technologies, has presented challenges related to data labeling. Self-supervised learning (SSL) has emerged as a transformative approach to address these challenges, eliminating the need for extensive human annotation. In this study, we introduce a novel framework for Medical Time Series Representation Learning, known as MTS-LOF. MTS-LOF leverages the strengths of contrastive learning and Masked Autoencoder (MAE) methods, offering a unique approach to representation learning for medical time series data. By combining these techniques, MTS-LOF enhances the potential of healthcare applications by providing more sophisticated, context-rich representations. Additionally, MTS-LOF employs a multi-masking strategy to facilitate occlusion-invariant feature learning. This appr",
    "link": "http://arxiv.org/abs/2310.12451",
    "context": "Title: MTS-LOF: Medical Time-Series Representation Learning via Occlusion-Invariant Features. (arXiv:2310.12451v1 [cs.LG])\nAbstract: Medical time series data are indispensable in healthcare, providing critical insights for disease diagnosis, treatment planning, and patient management. The exponential growth in data complexity, driven by advanced sensor technologies, has presented challenges related to data labeling. Self-supervised learning (SSL) has emerged as a transformative approach to address these challenges, eliminating the need for extensive human annotation. In this study, we introduce a novel framework for Medical Time Series Representation Learning, known as MTS-LOF. MTS-LOF leverages the strengths of contrastive learning and Masked Autoencoder (MAE) methods, offering a unique approach to representation learning for medical time series data. By combining these techniques, MTS-LOF enhances the potential of healthcare applications by providing more sophisticated, context-rich representations. Additionally, MTS-LOF employs a multi-masking strategy to facilitate occlusion-invariant feature learning. This appr",
    "path": "papers/23/10/2310.12451.json",
    "total_tokens": 956,
    "translated_title": "MTS-LOF: 利用遮挡不变特征进行医学时间序列的表示学习",
    "translated_abstract": "医学时间序列数据在医疗保健中不可或缺，为疾病诊断、治疗计划和患者管理提供了重要的洞察力。先进的传感器技术带来的数据复杂性的指数增长，使数据标注面临挑战。自监督学习（SSL）已经成为解决这些挑战的一种变革性方法，消除了对广泛人工标注的需求。在本研究中，我们介绍了一种新的医学时间序列表示学习框架，称为MTS-LOF。MTS-LOF利用对比学习和遮挡自编码器（MAE）方法的优势，提供了一种针对医学时间序列数据的独特的表示学习方法。通过结合这些技术，MTS-LOF通过提供更复杂、更丰富的上下文表示，增强了医疗应用的潜力。此外，MTS-LOF采用多遮挡策略，促进了遮挡不变特征的学习。",
    "tldr": "MTS-LOF是一种利用对比学习和遮挡自编码器方法的医学时间序列表示学习框架，能够为医疗应用提供更复杂、更丰富的上下文表示，并通过多遮挡策略实现了遮挡不变特征的学习。",
    "en_tdlr": "MTS-LOF is a medical time series representation learning framework that utilizes contrastive learning and masked autoencoder methods to provide more sophisticated and context-rich representations for healthcare applications, while also enabling occlusion-invariant feature learning through a multi-masking strategy."
}