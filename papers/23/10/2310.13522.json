{
    "title": "Teaching Language Models to Self-Improve through Interactive Demonstrations. (arXiv:2310.13522v1 [cs.CL])",
    "abstract": "The self-improving ability of large language models (LLMs), enabled by prompting them to analyze and revise their own outputs, has garnered significant interest in recent research. However, this ability has been shown to be absent and difficult to learn for smaller models, thus widening the performance gap between state-of-the-art LLMs and more cost-effective and faster ones. To reduce this gap, we introduce TriPosT, a training algorithm that endows smaller models with such self-improvement ability, and show that our approach can improve a LLaMA-7b's performance on math and reasoning tasks by up to 7.13%. In contrast to prior work, we achieve this by using the smaller model to interact with LLMs to collect feedback and improvements on its own generations. We then replay this experience to train the small model. Our experiments on four math and reasoning datasets show that the interactive experience of learning from and correcting its own mistakes is crucial for small models to improve ",
    "link": "http://arxiv.org/abs/2310.13522",
    "context": "Title: Teaching Language Models to Self-Improve through Interactive Demonstrations. (arXiv:2310.13522v1 [cs.CL])\nAbstract: The self-improving ability of large language models (LLMs), enabled by prompting them to analyze and revise their own outputs, has garnered significant interest in recent research. However, this ability has been shown to be absent and difficult to learn for smaller models, thus widening the performance gap between state-of-the-art LLMs and more cost-effective and faster ones. To reduce this gap, we introduce TriPosT, a training algorithm that endows smaller models with such self-improvement ability, and show that our approach can improve a LLaMA-7b's performance on math and reasoning tasks by up to 7.13%. In contrast to prior work, we achieve this by using the smaller model to interact with LLMs to collect feedback and improvements on its own generations. We then replay this experience to train the small model. Our experiments on four math and reasoning datasets show that the interactive experience of learning from and correcting its own mistakes is crucial for small models to improve ",
    "path": "papers/23/10/2310.13522.json",
    "total_tokens": 916,
    "translated_title": "教导语言模型通过互动演示自我提升",
    "translated_abstract": "大型语言模型（LLM）通过提示其分析和修订自己的输出来实现自我提升的能力，近年来在研究中引起了显著关注。然而，这种能力在较小的模型中被证明是缺失且难以学习的，从而扩大了最先进的LLM与成本效益更高且速度更快的模型之间的性能差距。为了减小这一差距，我们引入了TriPosT，一种训练算法，赋予较小的模型这种自我提升的能力，并且展示了我们的方法可以将LLaMA-7b在数学和推理任务上的性能提升高达7.13%。与以往的工作相比，我们通过使用较小的模型与LLM进行互动以收集反馈和改进自身生成的结果来实现这一点。然后，我们重播这一经验来训练小型模型。我们在四个数学和推理数据集上的实验表明，从并纠正自己的错误中进行互动学习的经验对于小型模型的提升至关重要。",
    "tldr": "这项研究通过互动演示的方式，教导较小的语言模型具备自我提升能力，减小了最先进模型与成本效益更高模型之间的性能差距。",
    "en_tdlr": "This study teaches smaller language models to self-improve through interactive demonstrations, reducing the performance gap between state-of-the-art models and more cost-effective ones."
}