{
    "title": "Verification of Neural Networks Local Differential Classification Privacy. (arXiv:2310.20299v1 [cs.LG])",
    "abstract": "Neural networks are susceptible to privacy attacks. To date, no verifier can reason about the privacy of individuals participating in the training set. We propose a new privacy property, called local differential classification privacy (LDCP), extending local robustness to a differential privacy setting suitable for black-box classifiers. Given a neighborhood of inputs, a classifier is LDCP if it classifies all inputs the same regardless of whether it is trained with the full dataset or whether any single entry is omitted. A naive algorithm is highly impractical because it involves training a very large number of networks and verifying local robustness of the given neighborhood separately for every network. We propose Sphynx, an algorithm that computes an abstraction of all networks, with a high probability, from a small set of networks, and verifies LDCP directly on the abstract network. The challenge is twofold: network parameters do not adhere to a known distribution probability, ma",
    "link": "http://arxiv.org/abs/2310.20299",
    "context": "Title: Verification of Neural Networks Local Differential Classification Privacy. (arXiv:2310.20299v1 [cs.LG])\nAbstract: Neural networks are susceptible to privacy attacks. To date, no verifier can reason about the privacy of individuals participating in the training set. We propose a new privacy property, called local differential classification privacy (LDCP), extending local robustness to a differential privacy setting suitable for black-box classifiers. Given a neighborhood of inputs, a classifier is LDCP if it classifies all inputs the same regardless of whether it is trained with the full dataset or whether any single entry is omitted. A naive algorithm is highly impractical because it involves training a very large number of networks and verifying local robustness of the given neighborhood separately for every network. We propose Sphynx, an algorithm that computes an abstraction of all networks, with a high probability, from a small set of networks, and verifies LDCP directly on the abstract network. The challenge is twofold: network parameters do not adhere to a known distribution probability, ma",
    "path": "papers/23/10/2310.20299.json",
    "total_tokens": 943,
    "translated_title": "神经网络局部差分分类隐私的验证",
    "translated_abstract": "神经网络容易受到隐私攻击。至今没有验证器能够推断参与训练集的个体的隐私。我们提出了一种新的隐私属性，称为局部差分分类隐私（LDCP），将局部鲁棒性扩展到适用于黑盒分类器的差分隐私设置中。给定一个输入邻域，如果一个分类器是LDCP的，无论它是使用完整数据集训练还是省略任何一个条目训练，它都能对所有输入进行相同的分类。一个天真的算法是非常不切实际的，因为它涉及到训练大量的网络，并且对给定邻域的局部鲁棒性进行单独验证。我们提出了Sphynx算法，它可以从一小组网络中以高概率计算出所有网络的抽象，并直接在抽象网络上验证LDCP。挑战是双重的：网络参数不遵循已知的分布概率。",
    "tldr": "该论文提出了局部差分分类隐私（LDCP）的概念，扩展了局部鲁棒性的差分隐私设置，旨在验证神经网络对隐私的保护能力。作者提出了Sphynx算法，通过计算网络的抽象来验证LDCP，解决了传统算法中需要训练大量网络和逐个验证的问题。",
    "en_tdlr": "This paper introduces the concept of local differential classification privacy (LDCP), which extends local robustness to a differential privacy setting for neural networks. The authors propose the Sphynx algorithm to compute an abstraction of all networks and verify LDCP directly, addressing the issue of training a large number of networks and verifying local robustness separately."
}