{
    "title": "Benchmarking and Improving Generator-Validator Consistency of Language Models. (arXiv:2310.01846v1 [cs.CL])",
    "abstract": "As of September 2023, ChatGPT correctly answers \"what is 7+8\" with 15, but when asked \"7+8=15, True or False\" it responds with \"False\". This inconsistency between generating and validating an answer is prevalent in language models (LMs) and erodes trust. In this paper, we propose a framework for measuring the consistency between generation and validation (which we call generator-validator consistency, or GV-consistency), finding that even GPT-4, a state-of-the-art LM, is GV-consistent only 76% of the time. To improve the consistency of LMs, we propose to finetune on the filtered generator and validator responses that are GV-consistent, and call this approach consistency fine-tuning. We find that this approach improves GV-consistency of Alpaca-30B from 60% to 93%, and the improvement extrapolates to unseen tasks and domains (e.g., GV-consistency for positive style transfers extrapolates to unseen styles like humor). In addition to improving consistency, consistency fine-tuning improves ",
    "link": "http://arxiv.org/abs/2310.01846",
    "context": "Title: Benchmarking and Improving Generator-Validator Consistency of Language Models. (arXiv:2310.01846v1 [cs.CL])\nAbstract: As of September 2023, ChatGPT correctly answers \"what is 7+8\" with 15, but when asked \"7+8=15, True or False\" it responds with \"False\". This inconsistency between generating and validating an answer is prevalent in language models (LMs) and erodes trust. In this paper, we propose a framework for measuring the consistency between generation and validation (which we call generator-validator consistency, or GV-consistency), finding that even GPT-4, a state-of-the-art LM, is GV-consistent only 76% of the time. To improve the consistency of LMs, we propose to finetune on the filtered generator and validator responses that are GV-consistent, and call this approach consistency fine-tuning. We find that this approach improves GV-consistency of Alpaca-30B from 60% to 93%, and the improvement extrapolates to unseen tasks and domains (e.g., GV-consistency for positive style transfers extrapolates to unseen styles like humor). In addition to improving consistency, consistency fine-tuning improves ",
    "path": "papers/23/10/2310.01846.json",
    "total_tokens": 1140,
    "translated_title": "基准测试和改进语言模型生成器验证器一致性",
    "translated_abstract": "截至2023年9月，ChatGPT在被问到\"7+8=15，对还是错\"时，回答\"错\"，但在被问到\"7+8\"等于多少时，回答\"15\"。这种生成和验证答案之间的不一致在语言模型中很常见，破坏了人们的信任。在本文中，我们提出了一种衡量生成和验证之间一致性的框架（称为生成器验证器一致性），发现即使是最先进的GPT-4语言模型，仅在76%的情况下是一致的。为了改进语言模型的一致性，我们提出了在经过生成器和验证器答案筛选的基础上进行微调的方法，并称之为一致性微调。我们发现，这种方法将Alpaca-30B的一致性从60%提高到了93%，并且这种改进可以推广到未见过的任务和领域（例如，对于积极的风格转换，一致性的改进可以推广到未见过的风格，如幽默）。除了改进一致性外，一致性微调还改善了其他性能指标。",
    "tldr": "本文提出了一种衡量生成和验证之间一致性的框架，发现目前最先进的语言模型GPT-4仅在76%的情况下是一致的。为了改进一致性，提出了一种通过经过筛选的生成器和验证器答案进行微调的方法，并将其称为一致性微调。该方法将Alpaca-30B的一致性从60%提高到93%，并且对未见过的任务和领域也具有泛化能力。除了改进一致性外，一致性微调还带来了其他性能的提升。",
    "en_tdlr": "This paper proposes a framework for measuring the consistency between generation and validation in language models, and finds that even the state-of-the-art GPT-4 is consistent only 76% of the time. To improve consistency, the paper introduces a method called consistency fine-tuning, which involves finetuning on filtered generator and validator responses. This approach improves the consistency of Alpaca-30B from 60% to 93% and shows generalization to unseen tasks and domains. In addition to improving consistency, consistency fine-tuning also brings performance improvements."
}