{
    "title": "Revising with a Backward Glance: Regressions and Skips during Reading as Cognitive Signals for Revision Policies in Incremental Processing. (arXiv:2310.18229v1 [cs.CL])",
    "abstract": "In NLP, incremental processors produce output in instalments, based on incoming prefixes of the linguistic input. Some tokens trigger revisions, causing edits to the output hypothesis, but little is known about why models revise when they revise. A policy that detects the time steps where revisions should happen can improve efficiency. Still, retrieving a suitable signal to train a revision policy is an open problem, since it is not naturally available in datasets. In this work, we investigate the appropriateness of regressions and skips in human reading eye-tracking data as signals to inform revision policies in incremental sequence labelling. Using generalised mixed-effects models, we find that the probability of regressions and skips by humans can potentially serve as useful predictors for revisions in BiLSTMs and Transformer models, with consistent results for various languages.",
    "link": "http://arxiv.org/abs/2310.18229",
    "context": "Title: Revising with a Backward Glance: Regressions and Skips during Reading as Cognitive Signals for Revision Policies in Incremental Processing. (arXiv:2310.18229v1 [cs.CL])\nAbstract: In NLP, incremental processors produce output in instalments, based on incoming prefixes of the linguistic input. Some tokens trigger revisions, causing edits to the output hypothesis, but little is known about why models revise when they revise. A policy that detects the time steps where revisions should happen can improve efficiency. Still, retrieving a suitable signal to train a revision policy is an open problem, since it is not naturally available in datasets. In this work, we investigate the appropriateness of regressions and skips in human reading eye-tracking data as signals to inform revision policies in incremental sequence labelling. Using generalised mixed-effects models, we find that the probability of regressions and skips by humans can potentially serve as useful predictors for revisions in BiLSTMs and Transformer models, with consistent results for various languages.",
    "path": "papers/23/10/2310.18229.json",
    "total_tokens": 864,
    "translated_title": "回顾性修订：阅读中的回退和跳过作为增量处理中修订策略的认知信号",
    "translated_abstract": "在自然语言处理中，增量处理器根据语言输入的前缀产生输出。一些标记触发修订，导致对输出假设进行编辑。然而，目前对于为何模型进行修订的知识还很有限。检测修订应该发生的时间步骤的策略可以提高效率。然而，训练修订策略的合适信号的获取是一个开放性问题，因为在数据集中自然不可用。在这项工作中，我们研究了人类阅读的眼动跟踪数据中的回退和跳过在增量序列标记中作为修订策略的信息信号的适用性。通过使用广义混合效应模型，我们发现人类的回退和跳过的概率可能作为BiLSTMs和Transformer模型中修订的有用预测因素，而对于不同语言的结果保持一致。",
    "tldr": "本研究调查了人类阅读眼动追踪数据中的回退和跳过作为增量序列标记中修订策略的信息信号的适用性，并发现其可能作为修订的有用预测因素。"
}