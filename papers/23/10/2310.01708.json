{
    "title": "Deciphering Diagnoses: How Large Language Models Explanations Influence Clinical Decision Making. (arXiv:2310.01708v1 [cs.CL])",
    "abstract": "Clinical Decision Support Systems (CDSS) utilize evidence-based knowledge and patient data to offer real-time recommendations, with Large Language Models (LLMs) emerging as a promising tool to generate plain-text explanations for medical decisions. This study explores the effectiveness and reliability of LLMs in generating explanations for diagnoses based on patient complaints. Three experienced doctors evaluated LLM-generated explanations of the connection between patient complaints and doctor and model-assigned diagnoses across several stages. Experimental results demonstrated that LLM explanations significantly increased doctors' agreement rates with given diagnoses and highlighted potential errors in LLM outputs, ranging from 5% to 30%. The study underscores the potential and challenges of LLMs in healthcare and emphasizes the need for careful integration and evaluation to ensure patient safety and optimal clinical utility.",
    "link": "http://arxiv.org/abs/2310.01708",
    "context": "Title: Deciphering Diagnoses: How Large Language Models Explanations Influence Clinical Decision Making. (arXiv:2310.01708v1 [cs.CL])\nAbstract: Clinical Decision Support Systems (CDSS) utilize evidence-based knowledge and patient data to offer real-time recommendations, with Large Language Models (LLMs) emerging as a promising tool to generate plain-text explanations for medical decisions. This study explores the effectiveness and reliability of LLMs in generating explanations for diagnoses based on patient complaints. Three experienced doctors evaluated LLM-generated explanations of the connection between patient complaints and doctor and model-assigned diagnoses across several stages. Experimental results demonstrated that LLM explanations significantly increased doctors' agreement rates with given diagnoses and highlighted potential errors in LLM outputs, ranging from 5% to 30%. The study underscores the potential and challenges of LLMs in healthcare and emphasizes the need for careful integration and evaluation to ensure patient safety and optimal clinical utility.",
    "path": "papers/23/10/2310.01708.json",
    "total_tokens": 903,
    "translated_title": "解读诊断：大型语言模型解释如何影响临床决策",
    "translated_abstract": "临床决策支持系统（CDSS）利用基于证据的知识和患者数据提供实时建议，大型语言模型（LLMs）作为生成医学决策的纯文本解释的有希望的工具。本研究探讨了LLMs在基于患者症状的诊断解释生成中的有效性和可靠性。三名有经验的医生评估了LLM生成的关于患者症状与医生及模型分配的诊断之间的联系的解释。实验结果表明，LLM解释显著提高了医生对给定诊断的一致率，并凸显了LLM输出中的潜在错误，范围从5%到30%不等。本研究凸显了LLMs在医疗保健中的潜力和挑战，并强调了需要仔细整合和评估以确保患者安全和最佳临床效用。",
    "tldr": "大型语言模型在医学决策中生成的解释能显著提高医生对诊断的一致率，并指出潜在的LLM输出错误。这项研究强调了LLMs在医疗保健中的潜力和挑战，以及确保患者安全和最佳临床效用的需求。",
    "en_tdlr": "LLM-generated explanations significantly improve doctors' agreement rates with diagnoses and identify potential errors in LLM outputs. This study highlights the potential and challenges of LLMs in healthcare and emphasizes the need for patient safety and optimal clinical utility."
}