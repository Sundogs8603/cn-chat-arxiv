{
    "title": "Improving Few-shot Generalization of Safety Classifiers via Data Augmented Parameter-Efficient Fine-Tuning. (arXiv:2310.16959v1 [cs.LG])",
    "abstract": "As large language models (LLMs) are widely adopted, new safety issues and policies emerge, to which existing safety classifiers do not generalize well. If we have only observed a few examples of violations of a new safety rule, how can we build a classifier to detect violations? In this paper, we study the novel setting of domain-generalized few-shot learning for LLM-based text safety classifiers. Unlike prior few-shot work, these new safety issues can be hard to uncover and we do not get to choose the few examples. We demonstrate that existing few-shot techniques do not perform well in this setting, and rather we propose to do parameter-efficient fine-tuning (PEFT) combined with augmenting training data based on similar examples in prior existing rules. We empirically show that our approach of similarity-based data-augmentation + prompt-tuning (DAPT) consistently outperforms baselines that either do not rely on data augmentation or on PEFT by 7-17% F1 score in the Social Chemistry mor",
    "link": "http://arxiv.org/abs/2310.16959",
    "context": "Title: Improving Few-shot Generalization of Safety Classifiers via Data Augmented Parameter-Efficient Fine-Tuning. (arXiv:2310.16959v1 [cs.LG])\nAbstract: As large language models (LLMs) are widely adopted, new safety issues and policies emerge, to which existing safety classifiers do not generalize well. If we have only observed a few examples of violations of a new safety rule, how can we build a classifier to detect violations? In this paper, we study the novel setting of domain-generalized few-shot learning for LLM-based text safety classifiers. Unlike prior few-shot work, these new safety issues can be hard to uncover and we do not get to choose the few examples. We demonstrate that existing few-shot techniques do not perform well in this setting, and rather we propose to do parameter-efficient fine-tuning (PEFT) combined with augmenting training data based on similar examples in prior existing rules. We empirically show that our approach of similarity-based data-augmentation + prompt-tuning (DAPT) consistently outperforms baselines that either do not rely on data augmentation or on PEFT by 7-17% F1 score in the Social Chemistry mor",
    "path": "papers/23/10/2310.16959.json",
    "total_tokens": 957,
    "translated_title": "通过数据增强的参数高效微调改善少样本通用性安全分类器",
    "translated_abstract": "随着大型语言模型的广泛采用，出现了新的安全问题和政策，现有的安全分类器无法很好地进行泛化。如果我们只观察到少量违反新安全规则的示例，如何构建一个分类器来检测违规行为？本文研究了基于语言模型的文本安全分类器的领域通用少样本学习的新设置。与之前的少样本学习工作不同，这些新的安全问题很难发现，而且我们不能选择少量示例。我们证明了现有的少样本学习技术在这种情况下表现不佳，相反，我们提出了基于参数高效微调（PEFT）的数据增强训练方法，以及基于先前现有规则中的相似示例进行数据增强。我们通过实验证明，我们的相似性数据增强+提示微调（DAPT）方法在社交化学领域的F1分数上始终比不依赖于数据增强或PEFT的基准模型提高了7-17%。",
    "tldr": "通过数据增强的参数高效微调方法在大型语言模型的文本安全分类器中改善了少样本通用性问题，相比于基准模型，在社交化学领域的F1得分提高了7-17%。",
    "en_tdlr": "Augmenting training data with parameter-efficient fine-tuning improved few-shot generalization of safety classifiers based on large language models. Our approach, called similarity-based data-augmentation + prompt-tuning (DAPT), consistently outperformed baselines by 7-17% in terms of F1 score in the domain of Social Chemistry."
}