{
    "title": "FinGPT: Instruction Tuning Benchmark for Open-Source Large Language Models in Financial Datasets. (arXiv:2310.04793v1 [cs.CL])",
    "abstract": "In the swiftly expanding domain of Natural Language Processing (NLP), the potential of GPT-based models for the financial sector is increasingly evident. However, the integration of these models with financial datasets presents challenges, notably in determining their adeptness and relevance. This paper introduces a distinctive approach anchored in the Instruction Tuning paradigm for open-source large language models, specifically adapted for financial contexts. Through this methodology, we capitalize on the interoperability of open-source models, ensuring a seamless and transparent integration. We begin by explaining the Instruction Tuning paradigm, highlighting its effectiveness for immediate integration. The paper presents a benchmarking scheme designed for end-to-end training and testing, employing a cost-effective progression. Firstly, we assess basic competencies and fundamental tasks, such as Named Entity Recognition (NER) and sentiment analysis to enhance specialization. Next, ",
    "link": "http://arxiv.org/abs/2310.04793",
    "context": "Title: FinGPT: Instruction Tuning Benchmark for Open-Source Large Language Models in Financial Datasets. (arXiv:2310.04793v1 [cs.CL])\nAbstract: In the swiftly expanding domain of Natural Language Processing (NLP), the potential of GPT-based models for the financial sector is increasingly evident. However, the integration of these models with financial datasets presents challenges, notably in determining their adeptness and relevance. This paper introduces a distinctive approach anchored in the Instruction Tuning paradigm for open-source large language models, specifically adapted for financial contexts. Through this methodology, we capitalize on the interoperability of open-source models, ensuring a seamless and transparent integration. We begin by explaining the Instruction Tuning paradigm, highlighting its effectiveness for immediate integration. The paper presents a benchmarking scheme designed for end-to-end training and testing, employing a cost-effective progression. Firstly, we assess basic competencies and fundamental tasks, such as Named Entity Recognition (NER) and sentiment analysis to enhance specialization. Next, ",
    "path": "papers/23/10/2310.04793.json",
    "total_tokens": 860,
    "translated_title": "FinGPT: 在金融数据集中自然语言处理的指令调优基准测试",
    "translated_abstract": "在自然语言处理领域迅速扩展的背景下，GPT模型在金融领域的潜力日益明显。然而，将这些模型与金融数据集集成在一起存在挑战，特别是在确定其熟练程度和相关性方面。本文介绍了一种基于指令调优范式的独特方法，专门用于金融环境下的开源大型语言模型。通过这种方法，我们利用开源模型的互操作性，确保了无缝透明的集成。我们首先解释了指令调优范式，并强调其对于立即集成的有效性。本文提出了一个用于端到端训练和测试的基准测试方案，采用成本效益的逐步推进。首先，我们评估了基本的能力和基础任务，比如命名实体识别（NER）和情感分析，以增强专业化。",
    "tldr": "本文介绍了一种针对金融环境下开源语言模型的指令调优方法，并提出了端到端训练和测试的基准测试方案，以加强模型在金融数据集上的专业能力。",
    "en_tdlr": "This paper introduces an instruction tuning approach for open-source language models in the financial sector and proposes a benchmarking scheme for end-to-end training and testing, aiming to enhance the models' specialization in financial datasets."
}