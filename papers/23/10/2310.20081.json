{
    "title": "Integrating Summarization and Retrieval for Enhanced Personalization via Large Language Models. (arXiv:2310.20081v1 [cs.CL])",
    "abstract": "Personalization, the ability to tailor a system to individual users, is an essential factor in user experience with natural language processing (NLP) systems. With the emergence of Large Language Models (LLMs), a key question is how to leverage these models to better personalize user experiences. To personalize a language model's output, a straightforward approach is to incorporate past user data into the language model prompt, but this approach can result in lengthy inputs exceeding limitations on input length and incurring latency and cost issues. Existing approaches tackle such challenges by selectively extracting relevant user data (i.e. selective retrieval) to construct a prompt for downstream tasks. However, retrieval-based methods are limited by potential information loss, lack of more profound user understanding, and cold-start challenges. To overcome these limitations, we propose a novel summary-augmented approach by extending retrieval-augmented personalization with task-awar",
    "link": "http://arxiv.org/abs/2310.20081",
    "context": "Title: Integrating Summarization and Retrieval for Enhanced Personalization via Large Language Models. (arXiv:2310.20081v1 [cs.CL])\nAbstract: Personalization, the ability to tailor a system to individual users, is an essential factor in user experience with natural language processing (NLP) systems. With the emergence of Large Language Models (LLMs), a key question is how to leverage these models to better personalize user experiences. To personalize a language model's output, a straightforward approach is to incorporate past user data into the language model prompt, but this approach can result in lengthy inputs exceeding limitations on input length and incurring latency and cost issues. Existing approaches tackle such challenges by selectively extracting relevant user data (i.e. selective retrieval) to construct a prompt for downstream tasks. However, retrieval-based methods are limited by potential information loss, lack of more profound user understanding, and cold-start challenges. To overcome these limitations, we propose a novel summary-augmented approach by extending retrieval-augmented personalization with task-awar",
    "path": "papers/23/10/2310.20081.json",
    "total_tokens": 812,
    "translated_title": "通过大型语言模型将总结和检索整合，增强个性化能力",
    "translated_abstract": "个性化是自然语言处理(NLP)系统中用户体验的一个关键因素。我们提出了一种利用大型语言模型(LLM)来更好地个性化用户体验的方法。为了个性化语言模型的输出，一个直接的方法是将过去的用户数据并入语言模型的提示中，但这种方法会导致输入过长，超出输入长度限制，并且引起延迟和成本问题。现有方法通过选择性地提取相关的用户数据（即选择性检索）来解决这些挑战，以构建下游任务的提示。然而，基于检索的方法受限于潜在的信息丢失、缺乏更深入的用户理解和冷启动挑战。为了克服这些限制，我们提出了一种新颖的总结增强方法，通过扩展检索增强个性化与任务感知相结合。",
    "tldr": "个性化是NLP系统中用户体验的关键，本文通过大型语言模型将总结和检索整合，提出了一种利用任务感知的总结增强个性化方法。"
}