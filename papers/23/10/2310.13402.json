{
    "title": "Calibrating Neural Simulation-Based Inference with Differentiable Coverage Probability. (arXiv:2310.13402v1 [stat.ML])",
    "abstract": "Bayesian inference allows expressing the uncertainty of posterior belief under a probabilistic model given prior information and the likelihood of the evidence. Predominantly, the likelihood function is only implicitly established by a simulator posing the need for simulation-based inference (SBI). However, the existing algorithms can yield overconfident posteriors (Hermans *et al.*, 2022) defeating the whole purpose of credibility if the uncertainty quantification is inaccurate. We propose to include a calibration term directly into the training objective of the neural model in selected amortized SBI techniques. By introducing a relaxation of the classical formulation of calibration error we enable end-to-end backpropagation. The proposed method is not tied to any particular neural model and brings moderate computational overhead compared to the profits it introduces. It is directly applicable to existing computational pipelines allowing reliable black-box posterior inference. We empi",
    "link": "http://arxiv.org/abs/2310.13402",
    "context": "Title: Calibrating Neural Simulation-Based Inference with Differentiable Coverage Probability. (arXiv:2310.13402v1 [stat.ML])\nAbstract: Bayesian inference allows expressing the uncertainty of posterior belief under a probabilistic model given prior information and the likelihood of the evidence. Predominantly, the likelihood function is only implicitly established by a simulator posing the need for simulation-based inference (SBI). However, the existing algorithms can yield overconfident posteriors (Hermans *et al.*, 2022) defeating the whole purpose of credibility if the uncertainty quantification is inaccurate. We propose to include a calibration term directly into the training objective of the neural model in selected amortized SBI techniques. By introducing a relaxation of the classical formulation of calibration error we enable end-to-end backpropagation. The proposed method is not tied to any particular neural model and brings moderate computational overhead compared to the profits it introduces. It is directly applicable to existing computational pipelines allowing reliable black-box posterior inference. We empi",
    "path": "papers/23/10/2310.13402.json",
    "total_tokens": 874,
    "translated_title": "使用可微覆盖概率校准神经仿真推理",
    "translated_abstract": "贝叶斯推理允许在给定先验信息和证据的似然的概率模型下表达后验信念的不确定性。主要是通过模拟器隐式建立的似然函数需要进行基于仿真的推理(SBI)。然而，现有的算法可能产生过于自信的后验概率(Hermans等，2022)，如果不确定性量化不准确，将击败整个可信性的目的。我们提出在选定的摊销SBI技术的神经模型的训练目标中直接包含一个校准项。通过引入对经典校准错误公式的松弛，我们实现了端到端的反向传播。所提出的方法不局限于任何特定的神经模型，并带来适度的计算开销。它直接适用于现有的计算流程，实现可靠的黑盒后验推断。",
    "tldr": "本研究提出了一种在选定的摊销SBI技术的神经模型的训练目标中添加校准项的方法，以解决现有算法产生过于自信的后验概率的问题。该方法适用于现有的计算流程，实现可靠的黑盒后验推断。",
    "en_tdlr": "This study proposes a method to add a calibration term to the training objective of the neural model in selected amortized SBI techniques, addressing the issue of overconfident posterior probabilities from existing algorithms. The method is applicable to existing computational pipelines and enables reliable black-box posterior inference."
}