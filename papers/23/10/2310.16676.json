{
    "title": "SSLCL: An Efficient Model-Agnostic Supervised Contrastive Learning Framework for Emotion Recognition in Conversations. (arXiv:2310.16676v1 [cs.CL])",
    "abstract": "Emotion recognition in conversations (ERC) is a rapidly evolving task within the natural language processing community, which aims to detect the emotions expressed by speakers during a conversation. Recently, a growing number of ERC methods have focused on leveraging supervised contrastive learning (SCL) to enhance the robustness and generalizability of learned features. However, current SCL-based approaches in ERC are impeded by the constraint of large batch sizes and the lack of compatibility with most existing ERC models. To address these challenges, we propose an efficient and model-agnostic SCL framework named Supervised Sample-Label Contrastive Learning with Soft-HGR Maximal Correlation (SSLCL), which eliminates the need for a large batch size and can be seamlessly integrated with existing ERC models without introducing any model-specific assumptions. Specifically, we introduce a novel perspective on utilizing label representations by projecting discrete labels into dense embeddi",
    "link": "http://arxiv.org/abs/2310.16676",
    "context": "Title: SSLCL: An Efficient Model-Agnostic Supervised Contrastive Learning Framework for Emotion Recognition in Conversations. (arXiv:2310.16676v1 [cs.CL])\nAbstract: Emotion recognition in conversations (ERC) is a rapidly evolving task within the natural language processing community, which aims to detect the emotions expressed by speakers during a conversation. Recently, a growing number of ERC methods have focused on leveraging supervised contrastive learning (SCL) to enhance the robustness and generalizability of learned features. However, current SCL-based approaches in ERC are impeded by the constraint of large batch sizes and the lack of compatibility with most existing ERC models. To address these challenges, we propose an efficient and model-agnostic SCL framework named Supervised Sample-Label Contrastive Learning with Soft-HGR Maximal Correlation (SSLCL), which eliminates the need for a large batch size and can be seamlessly integrated with existing ERC models without introducing any model-specific assumptions. Specifically, we introduce a novel perspective on utilizing label representations by projecting discrete labels into dense embeddi",
    "path": "papers/23/10/2310.16676.json",
    "total_tokens": 883,
    "translated_title": "SSLCL: 一种高效的无模型偏向的监督对比学习框架用于对话中的情感识别",
    "translated_abstract": "对话中的情感识别 (ERC) 是自然语言处理领域中一个快速发展的任务，旨在检测对话中发言者表达的情感。最近，越来越多的ERC方法专注于利用监督对比学习 (SCL) 来增强学到的特征的鲁棒性和泛化能力。然而，当前ERC中基于SCL的方法受到大批量大小的限制，并且与大多数现有的ERC模型不兼容。为了解决这些挑战，我们提出了一种高效且无模型偏向的SCL框架，名为Supervised Sample-Label Contrastive Learning with Soft-HGR Maximal Correlation (SSLCL)，它消除了对大批量大小的需求，并且可以与现有的ERC模型无缝集成而不引入任何特定于模型的假设。具体来说，我们介绍了一种利用标签表示的新视角，通过将离散标签投影到密集表示中来实现。",
    "tldr": "SSLCL是一种高效的无模型偏向的监督对比学习框架，用于对话中的情感识别。它解决了基于SCL的方法中大批量大小的限制和与现有ERC模型不兼容的问题，并通过投影离散标签到密集表示中来改善特征的鲁棒性和泛化能力。"
}