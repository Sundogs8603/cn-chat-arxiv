{
    "title": "A randomized algorithm for nonconvex minimization with inexact evaluations and complexity guarantees",
    "abstract": "arXiv:2310.18841v2 Announce Type: replace-cross  Abstract: We consider minimization of a smooth nonconvex function with inexact oracle access to gradient and Hessian (without assuming access to the function value) to achieve approximate second-order optimality. A novel feature of our method is that if an approximate direction of negative curvature is chosen as the step, we choose its sense to be positive or negative with equal probability. We allow gradients to be inexact in a relative sense and relax the coupling between inexactness thresholds for the first- and second-order optimality conditions. Our convergence analysis includes both an expectation bound based on martingale analysis and a high-probability bound based on concentration inequalities. We apply our algorithm to empirical risk minimization problems and obtain improved gradient sample complexity over existing works.",
    "link": "https://arxiv.org/abs/2310.18841",
    "context": "Title: A randomized algorithm for nonconvex minimization with inexact evaluations and complexity guarantees\nAbstract: arXiv:2310.18841v2 Announce Type: replace-cross  Abstract: We consider minimization of a smooth nonconvex function with inexact oracle access to gradient and Hessian (without assuming access to the function value) to achieve approximate second-order optimality. A novel feature of our method is that if an approximate direction of negative curvature is chosen as the step, we choose its sense to be positive or negative with equal probability. We allow gradients to be inexact in a relative sense and relax the coupling between inexactness thresholds for the first- and second-order optimality conditions. Our convergence analysis includes both an expectation bound based on martingale analysis and a high-probability bound based on concentration inequalities. We apply our algorithm to empirical risk minimization problems and obtain improved gradient sample complexity over existing works.",
    "path": "papers/23/10/2310.18841.json",
    "total_tokens": 819,
    "translated_title": "一种具有不精确评估和复杂性保证的非凸最小化随机算法",
    "translated_abstract": "我们考虑使用对梯度和Hessian（不假设对函数值有访问权限）的不精确Oracle访问来最小化平滑非凸函数，以实现近似二阶最优性。我们方法的一个新特点是，如果选择一个近似的负曲率方向作为步骤，我们以相等概率选择其方向为正或负。我们允许梯度在相对意义上不精确，并放松不精确度阈值在一阶和二阶最优性条件之间的耦合。我们的收敛性分析包括基于鞍点分析的期望上界和基于浓度不等式的高概率上界。我们将我们的算法应用于经验风险最小化问题，并获得比现有作品更好的梯度样本复杂度。",
    "tldr": "该算法针对非凸函数的最小化问题使用了不精确的梯度和Hessian信息，通过随机选择近似的负曲率方向步进，实现近似二阶最优性，并在梯度样本复杂度上取得了改进。",
    "en_tdlr": "This algorithm addresses the minimization of nonconvex functions with inexact gradient and Hessian information, achieving approximate second-order optimality by stochastically choosing approximate negative curvature directions for stepping, resulting in improved gradient sample complexity."
}