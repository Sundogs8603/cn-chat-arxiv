{
    "title": "VAL: Interactive Task Learning with GPT Dialog Parsing. (arXiv:2310.01627v1 [cs.HC])",
    "abstract": "Reinforcement learning often requires millions of examples to produce static, black-box models. In contrast, interactive task learning (ITL) emphasizes incremental knowledge acquisition from limited instruction provided by humans in modalities such as natural language. However, in practice, ITL systems often suffers from brittle, error-prone language parsing. Large language models (LLMs) are resistant to brittleness but are not interpretable and cannot learn incrementally. We present VAL, an ITL system with a new philosophy for LLM/symbolic integration. By using LLMs only for specific tasks -- such as predicate and argument selection -- within an algorithmic framework, VAL reaps the benefits of LLMs to support interactive learning of hierarchical task knowledge from natural language. Acquired knowledge is human interpretable and generalizes to support execution of novel tasks without additional training. We studied users' interactions with VAL in a video game setting, finding that most",
    "link": "http://arxiv.org/abs/2310.01627",
    "context": "Title: VAL: Interactive Task Learning with GPT Dialog Parsing. (arXiv:2310.01627v1 [cs.HC])\nAbstract: Reinforcement learning often requires millions of examples to produce static, black-box models. In contrast, interactive task learning (ITL) emphasizes incremental knowledge acquisition from limited instruction provided by humans in modalities such as natural language. However, in practice, ITL systems often suffers from brittle, error-prone language parsing. Large language models (LLMs) are resistant to brittleness but are not interpretable and cannot learn incrementally. We present VAL, an ITL system with a new philosophy for LLM/symbolic integration. By using LLMs only for specific tasks -- such as predicate and argument selection -- within an algorithmic framework, VAL reaps the benefits of LLMs to support interactive learning of hierarchical task knowledge from natural language. Acquired knowledge is human interpretable and generalizes to support execution of novel tasks without additional training. We studied users' interactions with VAL in a video game setting, finding that most",
    "path": "papers/23/10/2310.01627.json",
    "total_tokens": 1012,
    "translated_title": "VAL：带有GPT对话解析的交互式任务学习",
    "translated_abstract": "强化学习通常需要数百万个样本来生成静态的黑箱模型。相比之下，交互式任务学习（ITL）强调从人类提供的有限指令中逐步获得知识，这些指令以自然语言等形式出现。然而，在实践中，ITL系统往往受到脆弱、容易出错的语言解析的困扰。大型语言模型（LLMs）对脆弱性有一定的抵抗能力，但不具备可解释性，也无法进行增量学习。我们提出了VAL，一种具有新的LLM/符号集成理念的ITL系统。通过仅在特定任务中使用LLMs（例如谓词和参数选择），在算法框架内，VAL利用LLMs的优势，支持从自然语言中交互式学习分层任务知识。所获得的知识是人类可解释的，并能够推广到支持执行新任务而不需要额外的训练。我们在一个视频游戏环境中研究了用户与VAL的交互，发现大部分用户能够从有限的指令中成功学到有效的任务知识。",
    "tldr": "VAL是一种交互式任务学习系统，通过结合大型语言模型（LLM）和符号集成的理念，实现了从自然语言中进行交互式学习的分层任务知识的获取。所获得的知识可解释并能够推广到执行新任务。在视频游戏环境中的用户交互实验表明，VAL能够从有限的指令中成功学到有效的任务知识。"
}