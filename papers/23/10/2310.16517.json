{
    "title": "OccuQuest: Mitigating Occupational Bias for Inclusive Large Language Models. (arXiv:2310.16517v1 [cs.CL])",
    "abstract": "The emergence of large language models (LLMs) has revolutionized natural language processing tasks. However, existing instruction-tuning datasets suffer from occupational bias: the majority of data relates to only a few occupations, which hampers the instruction-tuned LLMs to generate helpful responses to professional queries from practitioners in specific fields. To mitigate this issue and promote occupation-inclusive LLMs, we create an instruction-tuning dataset named \\emph{OccuQuest}, which contains 110,000+ prompt-completion pairs and 30,000+ dialogues covering over 1,000 occupations in 26 occupational categories. We systematically request ChatGPT, organizing queries hierarchically based on Occupation, Responsibility, Topic, and Question, to ensure a comprehensive coverage of occupational specialty inquiries. By comparing with three commonly used datasets (Dolly, ShareGPT, and WizardLM), we observe that OccuQuest exhibits a more balanced distribution across occupations. Furthermore",
    "link": "http://arxiv.org/abs/2310.16517",
    "context": "Title: OccuQuest: Mitigating Occupational Bias for Inclusive Large Language Models. (arXiv:2310.16517v1 [cs.CL])\nAbstract: The emergence of large language models (LLMs) has revolutionized natural language processing tasks. However, existing instruction-tuning datasets suffer from occupational bias: the majority of data relates to only a few occupations, which hampers the instruction-tuned LLMs to generate helpful responses to professional queries from practitioners in specific fields. To mitigate this issue and promote occupation-inclusive LLMs, we create an instruction-tuning dataset named \\emph{OccuQuest}, which contains 110,000+ prompt-completion pairs and 30,000+ dialogues covering over 1,000 occupations in 26 occupational categories. We systematically request ChatGPT, organizing queries hierarchically based on Occupation, Responsibility, Topic, and Question, to ensure a comprehensive coverage of occupational specialty inquiries. By comparing with three commonly used datasets (Dolly, ShareGPT, and WizardLM), we observe that OccuQuest exhibits a more balanced distribution across occupations. Furthermore",
    "path": "papers/23/10/2310.16517.json",
    "total_tokens": 865,
    "translated_title": "OccuQuest：缓解针对具有包容性的大型语言模型的职业偏见",
    "translated_abstract": "大型语言模型（LLMs）的出现彻底改变了自然语言处理任务。然而，现有的指导调优数据集存在职业偏见：大多数数据只涉及少数几个职业，这使得指导调优的LLMs难以对特定领域的从业人员的专业问题生成有用的响应。为了减轻这个问题并推广包容性的LLMs，我们创建了一个名为“OccuQuest”的指导调优数据集，其中包含110,000多个提示完成对和30,000多个对话，涵盖了26个职业类别中的1,000多个职业。我们通过与三个常用数据集（Dolly、ShareGPT和WizardLM）进行比较，发现OccuQuest在职业分布上更加平衡。",
    "tldr": "OccuQuest是一个用于减轻大型语言模型中的职业偏见的指导调优数据集，它包含了1,000多个职业的110,000+个提示完成对和30,000+个对话，并表现出更加平衡的职业分布。",
    "en_tdlr": "OccuQuest is an instruction-tuning dataset designed to mitigate occupational bias in large language models (LLMs). It contains over 110,000 prompt-completion pairs and 30,000 dialogues covering more than 1,000 occupations, and exhibits a more balanced distribution across occupations compared to other commonly used datasets (Dolly, ShareGPT, and WizardLM)."
}