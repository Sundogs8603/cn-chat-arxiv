{
    "title": "An Investigation of LLMs' Inefficacy in Understanding Converse Relations. (arXiv:2310.05163v2 [cs.CL] UPDATED)",
    "abstract": "Large Language Models (LLMs) have achieved remarkable success in many formal language oriented tasks, such as structural data-to-text and semantic parsing. However current benchmarks mostly follow the data distribution of the pre-training data of LLMs. Therefore, a natural question rises that do LLMs really understand the structured semantics of formal languages. In this paper, we investigate this problem on a special case, converse binary relation. We introduce a new benchmark ConvRe focusing on converse relations, which contains 17 relations and 1240 triples extracted from popular knowledge graph completion datasets. Our ConvRE features two tasks, Re2Text and Text2Re, which are formulated as multi-choice question answering to evaluate LLMs' ability to determine the matching between relations and associated text. For the evaluation protocol, apart from different prompting methods, we further introduce variants to the test text and few-shot example text. We conduct experiments on three",
    "link": "http://arxiv.org/abs/2310.05163",
    "context": "Title: An Investigation of LLMs' Inefficacy in Understanding Converse Relations. (arXiv:2310.05163v2 [cs.CL] UPDATED)\nAbstract: Large Language Models (LLMs) have achieved remarkable success in many formal language oriented tasks, such as structural data-to-text and semantic parsing. However current benchmarks mostly follow the data distribution of the pre-training data of LLMs. Therefore, a natural question rises that do LLMs really understand the structured semantics of formal languages. In this paper, we investigate this problem on a special case, converse binary relation. We introduce a new benchmark ConvRe focusing on converse relations, which contains 17 relations and 1240 triples extracted from popular knowledge graph completion datasets. Our ConvRE features two tasks, Re2Text and Text2Re, which are formulated as multi-choice question answering to evaluate LLMs' ability to determine the matching between relations and associated text. For the evaluation protocol, apart from different prompting methods, we further introduce variants to the test text and few-shot example text. We conduct experiments on three",
    "path": "papers/23/10/2310.05163.json",
    "total_tokens": 925,
    "translated_title": "LLMs在理解反向关系中的无效性的调查",
    "translated_abstract": "大型语言模型（LLMs）在许多形式语言导向的任务中取得了显着的成功，如结构化数据到文本和语义解析。然而，当前的基准大多遵循LLMs的预训练数据的数据分布。因此，一个自然的问题是，LLMs真正理解形式语言的结构化语义吗？本文在特殊情况下，即逆向二进制关系上进行了调查。我们引入了一个名为ConvRe的新基准，专注于逆向关系，其中包含来自知识图谱完成数据集的17个关系和1240个三元组。我们的ConvRE包括两个任务，Re2Text和Text2Re，这些任务被制定为多项选择题，用于评估LLMs确定关系和相关文本之间匹配能力。在评估协议方面，除了不同的提示方法，我们还引入了测试文本和少样本示例文本的变体。我们在三个实验上进行实验。",
    "tldr": "本论文调查了LLMs在理解反向关系方面的无效性。作者引入了一个名为ConvRe的新基准，专注于逆向关系。通过两个任务Re2Text和Text2Re，作者评估了LLMs确定关系和相关文本之间匹配能力。实验结果揭示了LLMs在此方面的限制。",
    "en_tdlr": "This paper investigates the inefficacy of LLMs in understanding converse relations. The authors introduce a new benchmark called ConvRe, focusing on converse relations. Through two tasks, Re2Text and Text2Re, the authors evaluate LLMs' ability to determine the matching between relations and associated text. The experiments reveal the limitations of LLMs in this regard."
}