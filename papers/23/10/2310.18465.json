{
    "title": "Minimax Optimal Submodular Optimization with Bandit Feedback. (arXiv:2310.18465v1 [cs.LG])",
    "abstract": "We consider maximizing a monotonic, submodular set function $f: 2^{[n]} \\rightarrow [0,1]$ under stochastic bandit feedback. Specifically, $f$ is unknown to the learner but at each time $t=1,\\dots,T$ the learner chooses a set $S_t \\subset [n]$ with $|S_t| \\leq k$ and receives reward $f(S_t) + \\eta_t$ where $\\eta_t$ is mean-zero sub-Gaussian noise. The objective is to minimize the learner's regret over $T$ times with respect to ($1-e^{-1}$)-approximation of maximum $f(S_*)$ with $|S_*| = k$, obtained through greedy maximization of $f$. To date, the best regret bound in the literature scales as $k n^{1/3} T^{2/3}$. And by trivially treating every set as a unique arm one deduces that $\\sqrt{ {n \\choose k} T }$ is also achievable. In this work, we establish the first minimax lower bound for this setting that scales like $\\mathcal{O}(\\min_{i \\le k}(in^{1/3}T^{2/3} + \\sqrt{n^{k-i}T}))$. Moreover, we propose an algorithm that is capable of matching the lower bound regret.",
    "link": "http://arxiv.org/abs/2310.18465",
    "context": "Title: Minimax Optimal Submodular Optimization with Bandit Feedback. (arXiv:2310.18465v1 [cs.LG])\nAbstract: We consider maximizing a monotonic, submodular set function $f: 2^{[n]} \\rightarrow [0,1]$ under stochastic bandit feedback. Specifically, $f$ is unknown to the learner but at each time $t=1,\\dots,T$ the learner chooses a set $S_t \\subset [n]$ with $|S_t| \\leq k$ and receives reward $f(S_t) + \\eta_t$ where $\\eta_t$ is mean-zero sub-Gaussian noise. The objective is to minimize the learner's regret over $T$ times with respect to ($1-e^{-1}$)-approximation of maximum $f(S_*)$ with $|S_*| = k$, obtained through greedy maximization of $f$. To date, the best regret bound in the literature scales as $k n^{1/3} T^{2/3}$. And by trivially treating every set as a unique arm one deduces that $\\sqrt{ {n \\choose k} T }$ is also achievable. In this work, we establish the first minimax lower bound for this setting that scales like $\\mathcal{O}(\\min_{i \\le k}(in^{1/3}T^{2/3} + \\sqrt{n^{k-i}T}))$. Moreover, we propose an algorithm that is capable of matching the lower bound regret.",
    "path": "papers/23/10/2310.18465.json",
    "total_tokens": 1082,
    "translated_title": "带有Bandit反馈的极小极大次模优化问题",
    "translated_abstract": "我们考虑在随机Bandit反馈下，最大化一个单调次模集函数$f：2 ^ {[n]} \\rightarrow [0,1]$。具体来说，$f$对于学习者是未知的，但是在每个时间$t=1,\\dots,T$，学习者选择一个集合$S_t \\subset [n]$，其中$|S_t|\\leq k$，并接收奖励$f(S_t)+\\eta_t$，其中$\\eta_t$是均值为零的次高斯噪声。目标是在$T$次中使得学习者对于带有$|S_*|=k$的最大$f(S_*)$的($1-e^{-1}$)近似的最小遗憾，通过对$f$的贪婪最大化来达到。到目前为止，文献中最好的遗憾边界按照$k n^{1/3} T^{2/3}$的比例缩放。通过将每个集合简单地视为一个唯一的arm，可以推断出$\\sqrt{{n \\choose k} T}$也是可实现的。在这项工作中，我们建立了这种情况下的第一个极小极大下限，其按照$\\mathcal{O}(\\min_{i \\le k}(in^{1/3}T^{2/3} + \\sqrt{n^{k-i}T}))$的比例缩放。此外，我们提出了一个能够与下限遗憾相匹配的算法。",
    "tldr": "这项工作研究了带有Bandit反馈的极小极大次模优化问题，在这个问题中，我们建立了第一个最小最大下限，并提出了一个能够与下限遗憾相匹配的算法。"
}