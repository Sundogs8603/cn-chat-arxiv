{
    "title": "Unified Uncertainty Calibration. (arXiv:2310.01202v1 [stat.ML])",
    "abstract": "To build robust, fair, and safe AI systems, we would like our classifiers to say ``I don't know'' when facing test examples that are difficult or fall outside of the training classes.The ubiquitous strategy to predict under uncertainty is the simplistic \\emph{reject-or-classify} rule: abstain from prediction if epistemic uncertainty is high, classify otherwise.Unfortunately, this recipe does not allow different sources of uncertainty to communicate with each other, produces miscalibrated predictions, and it does not allow to correct for misspecifications in our uncertainty estimates. To address these three issues, we introduce \\emph{unified uncertainty calibration (U2C)}, a holistic framework to combine aleatoric and epistemic uncertainties. U2C enables a clean learning-theoretical analysis of uncertainty estimation, and outperforms reject-or-classify across a variety of ImageNet benchmarks.",
    "link": "http://arxiv.org/abs/2310.01202",
    "context": "Title: Unified Uncertainty Calibration. (arXiv:2310.01202v1 [stat.ML])\nAbstract: To build robust, fair, and safe AI systems, we would like our classifiers to say ``I don't know'' when facing test examples that are difficult or fall outside of the training classes.The ubiquitous strategy to predict under uncertainty is the simplistic \\emph{reject-or-classify} rule: abstain from prediction if epistemic uncertainty is high, classify otherwise.Unfortunately, this recipe does not allow different sources of uncertainty to communicate with each other, produces miscalibrated predictions, and it does not allow to correct for misspecifications in our uncertainty estimates. To address these three issues, we introduce \\emph{unified uncertainty calibration (U2C)}, a holistic framework to combine aleatoric and epistemic uncertainties. U2C enables a clean learning-theoretical analysis of uncertainty estimation, and outperforms reject-or-classify across a variety of ImageNet benchmarks.",
    "path": "papers/23/10/2310.01202.json",
    "total_tokens": 768,
    "translated_title": "统一的不确定性校准",
    "translated_abstract": "为了构建健壮，公平和安全的人工智能系统，我们希望在面对困难或超出训练类别的测试样例时，分类器能够说“我不知道”。普遍的预测不确定性策略是简单的“拒绝或分类”规则：如果认知不确定性高，则放弃预测，否则进行分类。然而，这种方法不允许不同的不确定性来源相互通信，会产生未校准的预测，并且不能纠正不确定性估计中的错误。为了解决这三个问题，我们引入了统一的不确定性校准（U2C）的整体框架，用于合并可知和认知不确定性。U2C能够进行清晰的学习理论分析不确定性估计，并且在各种ImageNet基准测试中优于拒绝或分类方法。",
    "tldr": "该论文提出了一种统一的不确定性校准（U2C）框架，用于合并可知和认知不确定性，实现了面对困难样例时的准确预测和校准。"
}