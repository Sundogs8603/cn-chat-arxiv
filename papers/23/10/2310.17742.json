{
    "title": "BERT-PIN: A BERT-based Framework for Recovering Missing Data Segments in Time-series Load Profiles. (arXiv:2310.17742v1 [eess.AS])",
    "abstract": "Inspired by the success of the Transformer model in natural language processing and computer vision, this paper introduces BERT-PIN, a Bidirectional Encoder Representations from Transformers (BERT) powered Profile Inpainting Network. BERT-PIN recovers multiple missing data segments (MDSs) using load and temperature time-series profiles as inputs. To adopt a standard Transformer model structure for profile inpainting, we segment the load and temperature profiles into line segments, treating each segment as a word and the entire profile as a sentence. We incorporate a top candidates selection process in BERT-PIN, enabling it to produce a sequence of probability distributions, based on which users can generate multiple plausible imputed data sets, each reflecting different confidence levels. We develop and evaluate BERT-PIN using real-world dataset for two applications: multiple MDSs recovery and demand response baseline estimation. Simulation results show that BERT-PIN outperforms the ex",
    "link": "http://arxiv.org/abs/2310.17742",
    "context": "Title: BERT-PIN: A BERT-based Framework for Recovering Missing Data Segments in Time-series Load Profiles. (arXiv:2310.17742v1 [eess.AS])\nAbstract: Inspired by the success of the Transformer model in natural language processing and computer vision, this paper introduces BERT-PIN, a Bidirectional Encoder Representations from Transformers (BERT) powered Profile Inpainting Network. BERT-PIN recovers multiple missing data segments (MDSs) using load and temperature time-series profiles as inputs. To adopt a standard Transformer model structure for profile inpainting, we segment the load and temperature profiles into line segments, treating each segment as a word and the entire profile as a sentence. We incorporate a top candidates selection process in BERT-PIN, enabling it to produce a sequence of probability distributions, based on which users can generate multiple plausible imputed data sets, each reflecting different confidence levels. We develop and evaluate BERT-PIN using real-world dataset for two applications: multiple MDSs recovery and demand response baseline estimation. Simulation results show that BERT-PIN outperforms the ex",
    "path": "papers/23/10/2310.17742.json",
    "total_tokens": 997,
    "translated_title": "BERT-PIN: 一种基于BERT的框架来恢复时间序列负载曲线中的缺失数据段",
    "translated_abstract": "受到Transformer模型在自然语言处理和计算机视觉中的成功启发，本文引入了BERT-PIN，一种基于双向编码器转换器（BERT）的Profile Inpainting Network。BERT-PIN使用负载和温度时间序列曲线作为输入来恢复多个缺失数据段（MDSs）。为了采用标准的Transformer模型结构进行曲线修复，我们将负载和温度曲线分割为直线段，将每个段作为一个词，整个曲线作为一个句子。我们在BERT-PIN中引入了一个候选者选择过程，使其能够产生一系列概率分布，用户可以根据这些概率分布生成多个可信度不同的可能的修复数据集。我们使用真实数据集开发和评估了BERT-PIN，应用于两个场景：多个MDS的恢复和需求响应基线估计。仿真结果表明，BERT-PIN优于以前的方法。",
    "tldr": "BERT-PIN是一种基于BERT的框架，用于恢复时间序列负载曲线中的缺失数据段。它使用负载和温度时间序列曲线作为输入，采用Transformer模型结构进行曲线修复，并通过候选者选择过程生成多个可信度不同的可能的修复数据集。在多个MDS恢复和需求响应基线估计等应用中，BERT-PIN表现出优越性能。",
    "en_tdlr": "BERT-PIN is a BERT-based framework for recovering missing data segments in time-series load profiles. It uses load and temperature time-series profiles as inputs and adopts a Transformer model structure for profile inpainting. By incorporating a top candidates selection process, BERT-PIN can generate multiple plausible imputed data sets with different confidence levels. It outperforms previous methods in applications such as recovering multiple missing data segments and estimating demand response baseline."
}