{
    "title": "Graph Condensation via Eigenbasis Matching. (arXiv:2310.09202v1 [cs.LG])",
    "abstract": "The increasing amount of graph data places requirements on the efficiency and scalability of graph neural networks (GNNs), despite their effectiveness in various graph-related applications. Recently, the emerging graph condensation (GC) sheds light on reducing the computational cost of GNNs from a data perspective. It aims to replace the real large graph with a significantly smaller synthetic graph so that GNNs trained on both graphs exhibit comparable performance. However, our empirical investigation reveals that existing GC methods suffer from poor generalization, i.e., different GNNs trained on the same synthetic graph have obvious performance gaps. What factors hinder the generalization of GC and how can we mitigate it? To answer this question, we commence with a detailed analysis and observe that GNNs will inject spectrum bias into the synthetic graph, resulting in a distribution shift. To tackle this issue, we propose eigenbasis matching for spectrum-free graph condensation, name",
    "link": "http://arxiv.org/abs/2310.09202",
    "context": "Title: Graph Condensation via Eigenbasis Matching. (arXiv:2310.09202v1 [cs.LG])\nAbstract: The increasing amount of graph data places requirements on the efficiency and scalability of graph neural networks (GNNs), despite their effectiveness in various graph-related applications. Recently, the emerging graph condensation (GC) sheds light on reducing the computational cost of GNNs from a data perspective. It aims to replace the real large graph with a significantly smaller synthetic graph so that GNNs trained on both graphs exhibit comparable performance. However, our empirical investigation reveals that existing GC methods suffer from poor generalization, i.e., different GNNs trained on the same synthetic graph have obvious performance gaps. What factors hinder the generalization of GC and how can we mitigate it? To answer this question, we commence with a detailed analysis and observe that GNNs will inject spectrum bias into the synthetic graph, resulting in a distribution shift. To tackle this issue, we propose eigenbasis matching for spectrum-free graph condensation, name",
    "path": "papers/23/10/2310.09202.json",
    "total_tokens": 900,
    "translated_title": "图嵌入与特征匹配的图压缩",
    "translated_abstract": "随着图数据量的增加，要求图神经网络（GNN）在各种图相关应用中提高效率和可伸缩性。最近，新兴的图压缩（GC）从数据角度降低了GNN的计算成本。它旨在用一个明显较小的合成图替代真实的大型图，使得在这两个图上训练的GNN表现出可比较的性能。然而，我们的实证研究发现，现有的GC方法在泛化能力上存在问题，即在同一个合成图上训练的不同GNN性能存在明显差异。是什么因素阻碍了GC的泛化能力，我们如何缓解这个问题？为了回答这个问题，我们进行了详细分析，发现GNN会将谱偏差注入合成图中，导致分布偏移。为解决这个问题，我们提出了基于特征匹配的无谱图压缩，称之为...",
    "tldr": "本论文提出了基于特征匹配的无谱图压缩方法，以解决现有方法在泛化能力上存在的问题。通过详细分析发现，GNN注入合成图中的谱偏差导致了性能差异，我们的方法可以缓解这个问题。",
    "en_tdlr": "This paper proposes a spectrum-free graph condensation method based on eigenbasis matching to address the poor generalization issue in existing methods. Through detailed analysis, it is found that the spectrum bias injected by GNN into the synthetic graph leads to performance gaps, and our method can mitigate this problem."
}