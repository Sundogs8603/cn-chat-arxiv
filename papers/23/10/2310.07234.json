{
    "title": "Hierarchical Decomposition of Prompt-Based Continual Learning: Rethinking Obscured Sub-optimality. (arXiv:2310.07234v1 [cs.LG])",
    "abstract": "Prompt-based continual learning is an emerging direction in leveraging pre-trained knowledge for downstream continual learning, and has almost reached the performance pinnacle under supervised pre-training. However, our empirical research reveals that the current strategies fall short of their full potential under the more realistic self-supervised pre-training, which is essential for handling vast quantities of unlabeled data in practice. This is largely due to the difficulty of task-specific knowledge being incorporated into instructed representations via prompt parameters and predicted by uninstructed representations at test time. To overcome the exposed sub-optimality, we conduct a theoretical analysis of the continual learning objective in the context of pre-training, and decompose it into hierarchical components: within-task prediction, task-identity inference, and task-adaptive prediction. Following these empirical and theoretical insights, we propose Hierarchical Decomposition ",
    "link": "http://arxiv.org/abs/2310.07234",
    "context": "Title: Hierarchical Decomposition of Prompt-Based Continual Learning: Rethinking Obscured Sub-optimality. (arXiv:2310.07234v1 [cs.LG])\nAbstract: Prompt-based continual learning is an emerging direction in leveraging pre-trained knowledge for downstream continual learning, and has almost reached the performance pinnacle under supervised pre-training. However, our empirical research reveals that the current strategies fall short of their full potential under the more realistic self-supervised pre-training, which is essential for handling vast quantities of unlabeled data in practice. This is largely due to the difficulty of task-specific knowledge being incorporated into instructed representations via prompt parameters and predicted by uninstructed representations at test time. To overcome the exposed sub-optimality, we conduct a theoretical analysis of the continual learning objective in the context of pre-training, and decompose it into hierarchical components: within-task prediction, task-identity inference, and task-adaptive prediction. Following these empirical and theoretical insights, we propose Hierarchical Decomposition ",
    "path": "papers/23/10/2310.07234.json",
    "total_tokens": 845,
    "translated_title": "基于提示的持续学习的分层分解：重新思考模糊的次优性",
    "translated_abstract": "基于提示的持续学习是利用预训练知识进行下游持续学习的新兴方向，在受监督的预训练下几乎达到了性能峰值。然而，我们的实证研究发现，在更加现实的自监督预训练中，当前的策略未能发挥出其全部潜力，而这在实践中处理大量未标记数据是必要的。这主要是由于任务特定知识通过提示参数被纳入到指示表示中，并在测试时由未指示的表示进行预测的困难。为了解决这个问题，我们在预训练的上下文中对持续学习目标进行了理论分析，并将其分解为分层组成部分：任务内预测、任务身份推断和任务自适应预测。根据这些实证和理论的见解，我们提出了Hierarchical Decomposition方法。",
    "tldr": "本论文通过对基于提示的持续学习目标进行分层分解，在自监督预训练的背景下，解决了任务特定知识整合和预测困难的问题。",
    "en_tdlr": "This paper proposes a Hierarchical Decomposition method by analyzing and decomposing the prompt-based continual learning objective into hierarchical components, addressing the challenges of incorporating and predicting task-specific knowledge in the context of self-supervised pre-training."
}