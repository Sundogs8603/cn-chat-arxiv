{
    "title": "Towards Fixing Clever-Hans Predictors with Counterfactual Knowledge Distillation. (arXiv:2310.01011v2 [cs.AI] UPDATED)",
    "abstract": "This paper introduces a novel technique called counterfactual knowledge distillation (CFKD) to detect and remove reliance on confounders in deep learning models with the help of human expert feedback. Confounders are spurious features that models tend to rely on, which can result in unexpected errors in regulated or safety-critical domains. The paper highlights the benefit of CFKD in such domains and shows some advantages of counterfactual explanations over other types of explanations. We propose an experiment scheme to quantitatively evaluate the success of CFKD and different teachers that can give feedback to the model. We also introduce a new metric that is better correlated with true test performance than validation accuracy. The paper demonstrates the effectiveness of CFKD on synthetically augmented datasets and on real-world histopathological datasets.",
    "link": "http://arxiv.org/abs/2310.01011",
    "context": "Title: Towards Fixing Clever-Hans Predictors with Counterfactual Knowledge Distillation. (arXiv:2310.01011v2 [cs.AI] UPDATED)\nAbstract: This paper introduces a novel technique called counterfactual knowledge distillation (CFKD) to detect and remove reliance on confounders in deep learning models with the help of human expert feedback. Confounders are spurious features that models tend to rely on, which can result in unexpected errors in regulated or safety-critical domains. The paper highlights the benefit of CFKD in such domains and shows some advantages of counterfactual explanations over other types of explanations. We propose an experiment scheme to quantitatively evaluate the success of CFKD and different teachers that can give feedback to the model. We also introduce a new metric that is better correlated with true test performance than validation accuracy. The paper demonstrates the effectiveness of CFKD on synthetically augmented datasets and on real-world histopathological datasets.",
    "path": "papers/23/10/2310.01011.json",
    "total_tokens": 814,
    "translated_title": "解决利用反事实知识蒸馏的聪明汉斯预测模型问题",
    "translated_abstract": "本论文引入一种名为反事实知识蒸馏（CFKD）的新技术，借助人类专家反馈来检测和消除深度学习模型对混淆因素的依赖。混淆因素是模型倾向于依赖的虚假特征，可能导致在受监管或安全关键领域出现意外错误。论文强调了CFKD在此类领域中的优势，并展示了反事实解释相对于其他类型解释的一些优点。我们提出了一个实验方案来定量评估CFKD的成功性和可以为模型提供反馈的不同教师。我们还引入了一个与真实测试性能更相关的新度量标准，而不是仅仅依靠验证精度。论文展示了CFKD在合成增强数据集和现实世界组织病理学数据集上的有效性。",
    "tldr": "这项研究提出了一种称为反事实知识蒸馏的新技术，通过人类专家的反馈来检测和消除深度学习模型对虚假特征的依赖，特别适用于受监管或安全关键领域。"
}