{
    "title": "Context Does Matter: End-to-end Panoptic Narrative Grounding with Deformable Attention Refined Matching Network. (arXiv:2310.16616v1 [cs.CV])",
    "abstract": "Panoramic Narrative Grounding (PNG) is an emerging visual grounding task that aims to segment visual objects in images based on dense narrative captions. The current state-of-the-art methods first refine the representation of phrase by aggregating the most similar $k$ image pixels, and then match the refined text representations with the pixels of the image feature map to generate segmentation results. However, simply aggregating sampled image features ignores the contextual information, which can lead to phrase-to-pixel mis-match. In this paper, we propose a novel learning framework called Deformable Attention Refined Matching Network (DRMN), whose main idea is to bring deformable attention in the iterative process of feature learning to incorporate essential context information of different scales of pixels. DRMN iteratively re-encodes pixels with the deformable attention network after updating the feature representation of the top-$k$ most similar pixels. As such, DRMN can lead to a",
    "link": "http://arxiv.org/abs/2310.16616",
    "context": "Title: Context Does Matter: End-to-end Panoptic Narrative Grounding with Deformable Attention Refined Matching Network. (arXiv:2310.16616v1 [cs.CV])\nAbstract: Panoramic Narrative Grounding (PNG) is an emerging visual grounding task that aims to segment visual objects in images based on dense narrative captions. The current state-of-the-art methods first refine the representation of phrase by aggregating the most similar $k$ image pixels, and then match the refined text representations with the pixels of the image feature map to generate segmentation results. However, simply aggregating sampled image features ignores the contextual information, which can lead to phrase-to-pixel mis-match. In this paper, we propose a novel learning framework called Deformable Attention Refined Matching Network (DRMN), whose main idea is to bring deformable attention in the iterative process of feature learning to incorporate essential context information of different scales of pixels. DRMN iteratively re-encodes pixels with the deformable attention network after updating the feature representation of the top-$k$ most similar pixels. As such, DRMN can lead to a",
    "path": "papers/23/10/2310.16616.json",
    "total_tokens": 916,
    "translated_title": "上下文确实很重要：具有可变形注意力精细匹配网络的端到端全景叙事对齐",
    "translated_abstract": "全景叙事对齐（PNG）是一种新兴的视觉对齐任务，旨在基于密集叙事标题在图像中分割视觉对象。当前最先进的方法首先通过聚合最相似的$k$个图像像素来改进短语的表示，然后将经过改进的文本表示与图像特征图的像素进行匹配，以生成分割结果。然而，简单地聚合采样的图像特征忽略了上下文信息，这可能导致短语与像素的不匹配。在本文中，我们提出了一种新颖的学习框架，称为可变形注意力精细匹配网络（DRMN），其主要思想是在特征学习的迭代过程中引入可变形注意力，以融入不同尺度像素的重要上下文信息。DRMN在更新了最相似的$k$个像素的特征表示后，使用可变形注意力网络对像素进行迭代重新编码。因此，DRMN可以实现一个...",
    "tldr": "本文主要提出了一种名为DRMN的学习框架，通过引入可变形注意力以融入不同尺度像素的上下文信息，解决了全景叙事对齐中短语与像素不匹配的问题。"
}