{
    "title": "Training A Semantic Communication System with Federated Learning. (arXiv:2310.13236v1 [cs.LG])",
    "abstract": "Semantic communication has emerged as a pillar for the next generation of communication systems due to its capabilities in alleviating data redundancy. Most semantic communication systems are built using advanced deep learning models whose performance heavily depends on data availability. These studies assume that an abundance of training data is available, which is unrealistic. In practice, data is mainly created on the user side. Due to privacy and security concerns, the transmission of data is restricted, which is necessary for conventional centralized training schemes. To address this challenge, we explore semantic communication in federated learning (FL) setting that utilizes user data without leaking privacy. Additionally, we design our system to tackle the communication overhead by reducing the quantity of information delivered in each global round. In this way, we can save significant bandwidth for resource-limited devices and reduce overall network traffic. Finally, we propose",
    "link": "http://arxiv.org/abs/2310.13236",
    "context": "Title: Training A Semantic Communication System with Federated Learning. (arXiv:2310.13236v1 [cs.LG])\nAbstract: Semantic communication has emerged as a pillar for the next generation of communication systems due to its capabilities in alleviating data redundancy. Most semantic communication systems are built using advanced deep learning models whose performance heavily depends on data availability. These studies assume that an abundance of training data is available, which is unrealistic. In practice, data is mainly created on the user side. Due to privacy and security concerns, the transmission of data is restricted, which is necessary for conventional centralized training schemes. To address this challenge, we explore semantic communication in federated learning (FL) setting that utilizes user data without leaking privacy. Additionally, we design our system to tackle the communication overhead by reducing the quantity of information delivered in each global round. In this way, we can save significant bandwidth for resource-limited devices and reduce overall network traffic. Finally, we propose",
    "path": "papers/23/10/2310.13236.json",
    "total_tokens": 815,
    "translated_title": "用联邦学习训练语义通信系统",
    "translated_abstract": "语义通信因其减少数据冗余的功能成为下一代通信系统的重要支柱。大多数语义通信系统使用先进的深度学习模型构建，其性能严重依赖于数据的可用性。这些研究假设有丰富的训练数据可用，这是不现实的。实际上，数据主要是由用户生成的。由于隐私和安全问题，数据传输受到限制，这对于传统的集中式训练方案是必要的。为了解决这个挑战，我们在联邦学习（FL）环境中探索语义通信，利用用户数据而不泄露隐私。此外，我们设计了一个系统来解决通信开销问题，通过减少每个全局轮次传送的信息量。这样，我们可以为资源受限的设备节省大量带宽，减少整体网络流量。最后，我们提出了...",
    "tldr": "该论文介绍了用联邦学习训练语义通信系统的方法，通过利用用户数据而不泄露隐私的方式，减少了通信开销，并提高了网络资源利用率。",
    "en_tdlr": "This paper presents a method for training a semantic communication system with federated learning, which reduces communication overhead and improves network resource utilization by utilizing user data without compromising privacy."
}