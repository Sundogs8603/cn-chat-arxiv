{
    "title": "On the Evaluation of Generative Models in Distributed Learning Tasks. (arXiv:2310.11714v1 [cs.LG])",
    "abstract": "The evaluation of deep generative models including generative adversarial networks (GANs) and diffusion models has been extensively studied in the literature. While the existing evaluation methods mainly target a centralized learning problem with training data stored by a single client, many applications of generative models concern distributed learning settings, e.g. the federated learning scenario, where training data are collected by and distributed among several clients. In this paper, we study the evaluation of generative models in distributed learning tasks with heterogeneous data distributions. First, we focus on the Fr\\'echet inception distance (FID) and consider the following FID-based aggregate scores over the clients: 1) FID-avg as the mean of clients' individual FID scores, 2) FID-all as the FID distance of the trained model to the collective dataset containing all clients' data. We prove that the model rankings according to the FID-all and FID-avg scores could be inconsist",
    "link": "http://arxiv.org/abs/2310.11714",
    "context": "Title: On the Evaluation of Generative Models in Distributed Learning Tasks. (arXiv:2310.11714v1 [cs.LG])\nAbstract: The evaluation of deep generative models including generative adversarial networks (GANs) and diffusion models has been extensively studied in the literature. While the existing evaluation methods mainly target a centralized learning problem with training data stored by a single client, many applications of generative models concern distributed learning settings, e.g. the federated learning scenario, where training data are collected by and distributed among several clients. In this paper, we study the evaluation of generative models in distributed learning tasks with heterogeneous data distributions. First, we focus on the Fr\\'echet inception distance (FID) and consider the following FID-based aggregate scores over the clients: 1) FID-avg as the mean of clients' individual FID scores, 2) FID-all as the FID distance of the trained model to the collective dataset containing all clients' data. We prove that the model rankings according to the FID-all and FID-avg scores could be inconsist",
    "path": "papers/23/10/2310.11714.json",
    "total_tokens": 910,
    "translated_title": "在分布式学习任务中评估生成模型",
    "translated_abstract": "在文献中已经广泛研究了对包括生成对抗网络（GAN）和扩散模型在内的深度生成模型的评估。然而，现有的评估方法主要针对单个客户端存储的训练数据的集中式学习问题，而生成模型的许多应用涉及到分布式学习环境，例如联邦学习场景，其中训练数据由多个客户端收集并分发。本文研究了在具有异构数据分布的分布式学习任务中评估生成模型。首先，我们关注Fr\\'echet inception距离（FID），并考虑以下基于FID的聚合分数：1）FID-avg作为客户端个体FID分数的平均值，2）FID-all作为训练模型与包含所有客户端数据的集体数据集之间的FID距离。我们证明了根据FID-all和FID-avg分数的模型排名可能不一致。",
    "tldr": "本文研究了在具有异构数据分布的分布式学习任务中评估生成模型。通过研究Fr\\'echet inception距离（FID），并考虑不同聚合分数，发现FID-all和FID-avg分数的模型排名可能不一致。",
    "en_tdlr": "This paper investigates the evaluation of generative models in distributed learning tasks with heterogeneous data distributions. By studying the Fr\\'echet inception distance (FID) and considering different aggregate scores, it is found that the model rankings based on FID-all and FID-avg scores may be inconsistent."
}