{
    "title": "FedSym: Unleashing the Power of Entropy for Benchmarking the Algorithms for Federated Learning. (arXiv:2310.07807v1 [cs.LG])",
    "abstract": "Federated learning (FL) is a decentralized machine learning approach where independent learners process data privately. Its goal is to create a robust and accurate model by aggregating and retraining local models over multiple rounds. However, FL faces challenges regarding data heterogeneity and model aggregation effectiveness. In order to simulate real-world data, researchers use methods for data partitioning that transform a dataset designated for centralized learning into a group of sub-datasets suitable for distributed machine learning with different data heterogeneity. In this paper, we study the currently popular data partitioning techniques and visualize their main disadvantages: the lack of precision in the data diversity, which leads to unreliable heterogeneity indexes, and the inability to incrementally challenge the FL algorithms. To resolve this problem, we propose a method that leverages entropy and symmetry to construct 'the most challenging' and controllable data distrib",
    "link": "http://arxiv.org/abs/2310.07807",
    "context": "Title: FedSym: Unleashing the Power of Entropy for Benchmarking the Algorithms for Federated Learning. (arXiv:2310.07807v1 [cs.LG])\nAbstract: Federated learning (FL) is a decentralized machine learning approach where independent learners process data privately. Its goal is to create a robust and accurate model by aggregating and retraining local models over multiple rounds. However, FL faces challenges regarding data heterogeneity and model aggregation effectiveness. In order to simulate real-world data, researchers use methods for data partitioning that transform a dataset designated for centralized learning into a group of sub-datasets suitable for distributed machine learning with different data heterogeneity. In this paper, we study the currently popular data partitioning techniques and visualize their main disadvantages: the lack of precision in the data diversity, which leads to unreliable heterogeneity indexes, and the inability to incrementally challenge the FL algorithms. To resolve this problem, we propose a method that leverages entropy and symmetry to construct 'the most challenging' and controllable data distrib",
    "path": "papers/23/10/2310.07807.json",
    "total_tokens": 873,
    "translated_title": "FedSym: 发挥熵的力量对联邦学习算法进行基准测试",
    "translated_abstract": "联邦学习是一种去中心化的机器学习方法，独立学习者会私下处理数据，通过聚合和重新训练本地模型来创建稳健准确的模型。然而，联邦学习面临着数据异质性和模型聚合效果的挑战。为了模拟真实世界的数据，研究人员使用数据分区方法，将为集中式学习设计的数据集转化为适用于具有不同数据异质性的分布式机器学习的一组子数据集。本文研究了目前流行的数据分区技术，并可视化其主要缺点：数据多样性的精度不足，导致不可靠的异质性指标，以及无法增量挑战联邦学习算法。为了解决这个问题，我们提出了一种利用熵和对称性构建“最具挑战性”和可控数据分布的方法。",
    "tldr": "本文提出了一种利用熵和对称性构建数据分布的方法，用于基于联邦学习的算法基准测试。该方法解决了数据分区技术中存在的精度不足和无法增量挑战算法的问题。"
}