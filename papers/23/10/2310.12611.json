{
    "title": "Identifying and Adapting Transformer-Components Responsible for Gender Bias in an English Language Model. (arXiv:2310.12611v1 [cs.CL])",
    "abstract": "Language models (LMs) exhibit and amplify many types of undesirable biases learned from the training data, including gender bias. However, we lack tools for effectively and efficiently changing this behavior without hurting general language modeling performance. In this paper, we study three methods for identifying causal relations between LM components and particular output: causal mediation analysis, automated circuit discovery and our novel, efficient method called DiffMask+ based on differential masking. We apply the methods to GPT-2 small and the problem of gender bias, and use the discovered sets of components to perform parameter-efficient fine-tuning for bias mitigation. Our results show significant overlap in the identified components (despite huge differences in the computational requirements of the methods) as well as success in mitigating gender bias, with less damage to general language modeling compared to full model fine-tuning. However, our work also underscores the dif",
    "link": "http://arxiv.org/abs/2310.12611",
    "context": "Title: Identifying and Adapting Transformer-Components Responsible for Gender Bias in an English Language Model. (arXiv:2310.12611v1 [cs.CL])\nAbstract: Language models (LMs) exhibit and amplify many types of undesirable biases learned from the training data, including gender bias. However, we lack tools for effectively and efficiently changing this behavior without hurting general language modeling performance. In this paper, we study three methods for identifying causal relations between LM components and particular output: causal mediation analysis, automated circuit discovery and our novel, efficient method called DiffMask+ based on differential masking. We apply the methods to GPT-2 small and the problem of gender bias, and use the discovered sets of components to perform parameter-efficient fine-tuning for bias mitigation. Our results show significant overlap in the identified components (despite huge differences in the computational requirements of the methods) as well as success in mitigating gender bias, with less damage to general language modeling compared to full model fine-tuning. However, our work also underscores the dif",
    "path": "papers/23/10/2310.12611.json",
    "total_tokens": 894,
    "translated_title": "识别和调整英文语言模型中负责性别偏见的Transformer组件",
    "translated_abstract": "语言模型（LMs）展现和放大了许多种不希望从训练数据中学到的偏见，包括性别偏见。然而，我们缺乏有效和高效地改变这种行为而不损害一般语言建模性能的工具。在本文中，我们研究了三种方法来识别LM组件与特定输出之间的因果关系：因果中介分析、自动电路发现和我们的新颖高效的方法DiffMask+，基于差异掩模。我们将这些方法应用于GPT-2 small和性别偏见问题，并使用发现的组件集进行参数高效的偏见缓解微调。我们的结果表明，尽管这些方法的计算要求存在巨大差异，但识别出的组件在很大程度上重叠，并且成功减轻了性别偏见，相比于完整模型微调对一般语言建模的损害较小。然而，我们的工作也强调了一些困难。",
    "tldr": "本研究通过三种方法识别英文语言模型中负责性别偏见的Transformer组件，然后使用这些组件进行参数高效的偏见缓解微调，取得了成功的性别偏见缓解效果并减少了对一般语言建模的损害。"
}