{
    "title": "Latent Consistency Models: Synthesizing High-Resolution Images with Few-Step Inference. (arXiv:2310.04378v1 [cs.CV])",
    "abstract": "Latent Diffusion models (LDMs) have achieved remarkable results in synthesizing high-resolution images. However, the iterative sampling process is computationally intensive and leads to slow generation. Inspired by Consistency Models (song et al.), we propose Latent Consistency Models (LCMs), enabling swift inference with minimal steps on any pre-trained LDMs, including Stable Diffusion (rombach et al). Viewing the guided reverse diffusion process as solving an augmented probability flow ODE (PF-ODE), LCMs are designed to directly predict the solution of such ODE in latent space, mitigating the need for numerous iterations and allowing rapid, high-fidelity sampling. Efficiently distilled from pre-trained classifier-free guided diffusion models, a high-quality 768 x 768 2~4-step LCM takes only 32 A100 GPU hours for training. Furthermore, we introduce Latent Consistency Fine-tuning (LCF), a novel method that is tailored for fine-tuning LCMs on customized image datasets. Evaluation on the",
    "link": "http://arxiv.org/abs/2310.04378",
    "context": "Title: Latent Consistency Models: Synthesizing High-Resolution Images with Few-Step Inference. (arXiv:2310.04378v1 [cs.CV])\nAbstract: Latent Diffusion models (LDMs) have achieved remarkable results in synthesizing high-resolution images. However, the iterative sampling process is computationally intensive and leads to slow generation. Inspired by Consistency Models (song et al.), we propose Latent Consistency Models (LCMs), enabling swift inference with minimal steps on any pre-trained LDMs, including Stable Diffusion (rombach et al). Viewing the guided reverse diffusion process as solving an augmented probability flow ODE (PF-ODE), LCMs are designed to directly predict the solution of such ODE in latent space, mitigating the need for numerous iterations and allowing rapid, high-fidelity sampling. Efficiently distilled from pre-trained classifier-free guided diffusion models, a high-quality 768 x 768 2~4-step LCM takes only 32 A100 GPU hours for training. Furthermore, we introduce Latent Consistency Fine-tuning (LCF), a novel method that is tailored for fine-tuning LCMs on customized image datasets. Evaluation on the",
    "path": "papers/23/10/2310.04378.json",
    "total_tokens": 933,
    "translated_title": "潜在一致性模型：使用少量步骤的推理合成高分辨率图像",
    "translated_abstract": "潜在扩散模型（LDM）在合成高分辨率图像方面取得了显著的成果。然而，迭代采样过程计算密集、生成速度慢。受到一致性模型的启发，我们提出了潜在一致性模型（LCM），在任何预训练的LDM上实现了快速推理，仅需最少的步骤，包括稳定扩散模型。将引导逆扩散过程视为解决增广概率流ODE（PF-ODE），LCM被设计为直接预测潜在空间中该ODE的解，减少了多次迭代的需求，实现了快速、高保真的采样。有效地从预训练的无分类器引导扩散模型中提取，一个高质量的768 x 768的2~4步LCM仅需32个A100 GPU小时进行训练。此外，我们引入了潜在一致性微调（LCF），一种针对自定义图像数据集精心设计的LCM微调方法。",
    "tldr": "该论文提出了潜在一致性模型（LCMs），通过直接预测潜在空间中扩散过程的解，实现了高分辨率图像的快速合成，减少了计算量和时间成本。",
    "en_tdlr": "The paper proposes Latent Consistency Models (LCMs) that enable swift synthesis of high-resolution images by directly predicting the solution of the diffusion process in latent space, reducing computational complexity and time."
}