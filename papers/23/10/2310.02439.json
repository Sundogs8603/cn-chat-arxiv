{
    "title": "Novice Learner and Expert Tutor: Evaluating Math Reasoning Abilities of Large Language Models with Misconceptions. (arXiv:2310.02439v1 [cs.CL])",
    "abstract": "We propose novel evaluations for mathematical reasoning capabilities of Large Language Models (LLMs) based on mathematical misconceptions. Our primary approach is to simulate LLMs as a novice learner and an expert tutor, aiming to identify the incorrect answer to math question resulted from a specific misconception and to recognize the misconception(s) behind an incorrect answer, respectively. Contrary to traditional LLMs-based mathematical evaluations that focus on answering math questions correctly, our approach takes inspirations from principles in educational learning sciences. We explicitly ask LLMs to mimic a novice learner by answering questions in a specific incorrect manner based on incomplete knowledge; and to mimic an expert tutor by identifying misconception(s) corresponding to an incorrect answer to a question. Using simple grade-school math problems, our experiments reveal that, while LLMs can easily answer these questions correctly, they struggle to identify 1) the incor",
    "link": "http://arxiv.org/abs/2310.02439",
    "context": "Title: Novice Learner and Expert Tutor: Evaluating Math Reasoning Abilities of Large Language Models with Misconceptions. (arXiv:2310.02439v1 [cs.CL])\nAbstract: We propose novel evaluations for mathematical reasoning capabilities of Large Language Models (LLMs) based on mathematical misconceptions. Our primary approach is to simulate LLMs as a novice learner and an expert tutor, aiming to identify the incorrect answer to math question resulted from a specific misconception and to recognize the misconception(s) behind an incorrect answer, respectively. Contrary to traditional LLMs-based mathematical evaluations that focus on answering math questions correctly, our approach takes inspirations from principles in educational learning sciences. We explicitly ask LLMs to mimic a novice learner by answering questions in a specific incorrect manner based on incomplete knowledge; and to mimic an expert tutor by identifying misconception(s) corresponding to an incorrect answer to a question. Using simple grade-school math problems, our experiments reveal that, while LLMs can easily answer these questions correctly, they struggle to identify 1) the incor",
    "path": "papers/23/10/2310.02439.json",
    "total_tokens": 933,
    "translated_title": "初学者学习者和专家导师：评估大型语言模型在数学推理能力上的误解",
    "translated_abstract": "我们提出了一种基于数学误解的大型语言模型（LLM）数学推理能力的新评估方法。我们的主要方法是将LLM模拟成初学者学习者和专家导师，旨在识别由特定误解引起的数学问题的错误答案，并识别与错误答案相关的误解。与传统基于LLM的数学评估不同，我们的方法受到教育学习科学原则的启发。我们明确要求LLM模拟初学者学习者的行为，通过基于不完全知识以特定错误的方式回答问题；以及模拟专家导师的行为，识别与问题的错误答案相对应的误解。通过使用简单的小学数学问题，我们的实验揭示了LLM虽然可以轻松正确回答这些问题，但在识别误解方面却存在困难。",
    "tldr": "本研究提出了一种基于数学误解的评估方法，测试大型语言模型在数学推理能力上的表现。与传统评估方法不同，我们通过模拟初学者和专家导师的角色来识别错误答案和相应的误解。实验结果表明，虽然大型语言模型可以正确回答问题，但在识别误解方面存在困难。"
}