{
    "title": "CodeFusion: A Pre-trained Diffusion Model for Code Generation. (arXiv:2310.17680v1 [cs.SE])",
    "abstract": "Imagine a developer who can only change their last line of code, how often would they have to start writing a function from scratch before it is correct? Auto-regressive models for code generation from natural language have a similar limitation: they do not easily allow reconsidering earlier tokens generated. We introduce CodeFusion, a pre-trained diffusion code generation model that addresses this limitation by iteratively denoising a complete program conditioned on the encoded natural language. We evaluate CodeFusion on the task of natural language to code generation for Bash, Python, and Microsoft Excel conditional formatting (CF) rules. Experiments show that CodeFusion (75M parameters) performs on par with state-of-the-art auto-regressive systems (350M-175B parameters) in top-1 accuracy and outperforms them in top-3 and top-5 accuracy due to its better balance in diversity versus quality.",
    "link": "http://arxiv.org/abs/2310.17680",
    "context": "Title: CodeFusion: A Pre-trained Diffusion Model for Code Generation. (arXiv:2310.17680v1 [cs.SE])\nAbstract: Imagine a developer who can only change their last line of code, how often would they have to start writing a function from scratch before it is correct? Auto-regressive models for code generation from natural language have a similar limitation: they do not easily allow reconsidering earlier tokens generated. We introduce CodeFusion, a pre-trained diffusion code generation model that addresses this limitation by iteratively denoising a complete program conditioned on the encoded natural language. We evaluate CodeFusion on the task of natural language to code generation for Bash, Python, and Microsoft Excel conditional formatting (CF) rules. Experiments show that CodeFusion (75M parameters) performs on par with state-of-the-art auto-regressive systems (350M-175B parameters) in top-1 accuracy and outperforms them in top-3 and top-5 accuracy due to its better balance in diversity versus quality.",
    "path": "papers/23/10/2310.17680.json",
    "total_tokens": 844,
    "translated_title": "CodeFusion: 一种用于代码生成的预训练扩散模型",
    "translated_abstract": "假设一个开发者只能修改其最后一行代码，在正确之前，他们需要多少次从头开始编写函数呢？自然语言代码生成的自回归模型也有类似的限制：它们不容易重新考虑之前生成的标记。我们介绍了一种名为CodeFusion的预训练扩散代码生成模型，通过迭代地对以编码的自然语言为条件的完整程序进行去噪，以解决这个限制。我们针对Bash、Python和Microsoft Excel条件格式(CF)规则的自然语言到代码生成任务对CodeFusion进行评估。实验结果显示，CodeFusion（75M参数）在top-1准确率上表现与最先进的自回归系统（350M-175B参数）相当，并且在top-3和top-5准确率上表现优于它们，这是由于它在多样性与质量之间的平衡更好。",
    "tldr": "CodeFusion是一种预训练的代码生成模型，通过扩散的方式解决了自然语言代码生成中遇到的限制，实验表明其在准确率和多样性上优于最先进的自回归系统。",
    "en_tdlr": "CodeFusion is a pre-trained code generation model that addresses the limitations of natural language code generation by diffusion, and experimental results show that it outperforms state-of-the-art auto-regressive systems in terms of accuracy and diversity."
}