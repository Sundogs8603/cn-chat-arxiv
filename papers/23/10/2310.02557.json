{
    "title": "Generalization in diffusion models arises from geometry-adaptive harmonic representation. (arXiv:2310.02557v1 [cs.CV])",
    "abstract": "High-quality samples generated with score-based reverse diffusion algorithms provide evidence that deep neural networks (DNN) trained for denoising can learn high-dimensional densities, despite the curse of dimensionality. However, recent reports of memorization of the training set raise the question of whether these networks are learning the \"true\" continuous density of the data. Here, we show that two denoising DNNs trained on non-overlapping subsets of a dataset learn nearly the same score function, and thus the same density, with a surprisingly small number of training images. This strong generalization demonstrates an alignment of powerful inductive biases in the DNN architecture and/or training algorithm with properties of the data distribution. We analyze these, demonstrating that the denoiser performs a shrinkage operation in a basis adapted to the underlying image. Examination of these bases reveals oscillating harmonic structures along contours and in homogeneous image region",
    "link": "http://arxiv.org/abs/2310.02557",
    "context": "Title: Generalization in diffusion models arises from geometry-adaptive harmonic representation. (arXiv:2310.02557v1 [cs.CV])\nAbstract: High-quality samples generated with score-based reverse diffusion algorithms provide evidence that deep neural networks (DNN) trained for denoising can learn high-dimensional densities, despite the curse of dimensionality. However, recent reports of memorization of the training set raise the question of whether these networks are learning the \"true\" continuous density of the data. Here, we show that two denoising DNNs trained on non-overlapping subsets of a dataset learn nearly the same score function, and thus the same density, with a surprisingly small number of training images. This strong generalization demonstrates an alignment of powerful inductive biases in the DNN architecture and/or training algorithm with properties of the data distribution. We analyze these, demonstrating that the denoiser performs a shrinkage operation in a basis adapted to the underlying image. Examination of these bases reveals oscillating harmonic structures along contours and in homogeneous image region",
    "path": "papers/23/10/2310.02557.json",
    "total_tokens": 1034,
    "translated_title": "扩散模型中的泛化性质源于几何自适应的谐波表示",
    "translated_abstract": "使用基于分数的反向扩散算法生成的高质量样本提供了证据，表明尽管存在维度灾难，为了降噪而训练的深度神经网络（DNN）可以学习高维密度。然而，关于训练集记忆化的最新报告引发了一个问题，即这些网络是否学习了数据的“真实”连续密度。我们在这里展示，训练在数据集的非重叠子集上的两个降噪DNN学习的几乎是相同的分数函数，从而学习了相同的密度，且仅需很少的训练图像。这种强大的泛化性证明了DNN架构和/或训练算法中的有力归纳偏差与数据分布的特性之间的一致性。我们分析了这些结果，展示了降噪器在适应于底层图像的基础上执行收缩操作。对这些基矢的检查揭示了沿轮廓和均匀图像区域的振荡谐波结构。",
    "tldr": "通过分析基于分数的反向扩散算法生成的高质量样本的研究结果，我们发现尽管存在维度灾难，但为了降噪而训练的深度神经网络可以学习到高维密度。此外，我们展示了在训练集的非重叠子集上训练的网络可以学习到相同的密度，从而证明了DNN架构和训练算法中的归纳偏差与数据分布的一致性。",
    "en_tdlr": "Our analysis of high-quality samples generated by score-based reverse diffusion algorithms reveals that deep neural networks trained for denoising can learn high-dimensional densities despite the curse of dimensionality. Furthermore, we demonstrate that networks trained on non-overlapping subsets of a dataset can learn the same density, highlighting the consistency between the inductive biases in the DNN architecture and the characteristics of the data distribution."
}