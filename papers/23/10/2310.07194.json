{
    "title": "Boosting Learning for LDPC Codes to Improve the Error-Floor Performance. (arXiv:2310.07194v1 [cs.IT])",
    "abstract": "Low-density parity-check (LDPC) codes have been successfully commercialized in communication systems due to their strong error correction ability and simple decoding process. However, the error-floor phenomenon of LDPC codes, in which the error rate stops decreasing rapidly at a certain level, poses challenges in achieving extremely low error rates and the application of LDPC codes in scenarios demanding ultra high reliability. In this work, we propose training methods to optimize neural min-sum (NMS) decoders that are robust to the error-floor. Firstly, by leveraging the boosting learning technique of ensemble networks, we divide the decoding network into two networks and train the post network to be specialized for uncorrected codewords that failed in the first network. Secondly, to address the vanishing gradient issue in training, we introduce a block-wise training schedule that locally trains a block of weights while retraining the preceding block. Lastly, we show that assigning di",
    "link": "http://arxiv.org/abs/2310.07194",
    "context": "Title: Boosting Learning for LDPC Codes to Improve the Error-Floor Performance. (arXiv:2310.07194v1 [cs.IT])\nAbstract: Low-density parity-check (LDPC) codes have been successfully commercialized in communication systems due to their strong error correction ability and simple decoding process. However, the error-floor phenomenon of LDPC codes, in which the error rate stops decreasing rapidly at a certain level, poses challenges in achieving extremely low error rates and the application of LDPC codes in scenarios demanding ultra high reliability. In this work, we propose training methods to optimize neural min-sum (NMS) decoders that are robust to the error-floor. Firstly, by leveraging the boosting learning technique of ensemble networks, we divide the decoding network into two networks and train the post network to be specialized for uncorrected codewords that failed in the first network. Secondly, to address the vanishing gradient issue in training, we introduce a block-wise training schedule that locally trains a block of weights while retraining the preceding block. Lastly, we show that assigning di",
    "path": "papers/23/10/2310.07194.json",
    "total_tokens": 889,
    "translated_title": "提升LDPC码学习以改善误码底的性能",
    "translated_abstract": "由于其强大的纠错能力和简单的解码过程，低密度奇偶校验（LDPC）码已成功商用化于通信系统中。然而，LDPC码的误码底现象使得在实现极低误码率和在对超高可靠性有要求的场景中应用LDPC码时面临挑战。在本文中，我们提出了训练方法来优化对误码底具有鲁棒性的神经min-sum（NMS）解码器。首先，通过利用集成网络的提升学习技术，我们将解码网络分为两个网络，并训练后续网络专门用于对第一个网络中解码失败的未纠正码字进行识别。其次，为解决训练中的梯度消失问题，我们引入分块训练方案，局部训练一块权重，并重新训练前一块权重。最后，我们展示了将NMS解码器分配给每个未解码的码字的相关性信息，从而进一步提高了误码底性能。",
    "tldr": "通过利用集成网络提升学习技术和引入分块训练方案，本文提出了一种优化LDPC码解码器的方法，以解决误码底问题，并改善了LDPC码的性能。"
}