{
    "title": "AutoVP: An Automated Visual Prompting Framework and Benchmark",
    "abstract": "arXiv:2310.08381v2 Announce Type: replace-cross  Abstract: Visual prompting (VP) is an emerging parameter-efficient fine-tuning approach to adapting pre-trained vision models to solve various downstream image-classification tasks. However, there has hitherto been little systematic study of the design space of VP and no clear benchmark for evaluating its performance. To bridge this gap, we propose AutoVP, an end-to-end expandable framework for automating VP design choices, along with 12 downstream image-classification tasks that can serve as a holistic VP-performance benchmark. Our design space covers 1) the joint optimization of the prompts; 2) the selection of pre-trained models, including image classifiers and text-image encoders; and 3) model output mapping strategies, including nonparametric and trainable label mapping. Our extensive experimental results show that AutoVP outperforms the best-known current VP methods by a substantial margin, having up to 6.7% improvement in accuracy",
    "link": "https://arxiv.org/abs/2310.08381",
    "context": "Title: AutoVP: An Automated Visual Prompting Framework and Benchmark\nAbstract: arXiv:2310.08381v2 Announce Type: replace-cross  Abstract: Visual prompting (VP) is an emerging parameter-efficient fine-tuning approach to adapting pre-trained vision models to solve various downstream image-classification tasks. However, there has hitherto been little systematic study of the design space of VP and no clear benchmark for evaluating its performance. To bridge this gap, we propose AutoVP, an end-to-end expandable framework for automating VP design choices, along with 12 downstream image-classification tasks that can serve as a holistic VP-performance benchmark. Our design space covers 1) the joint optimization of the prompts; 2) the selection of pre-trained models, including image classifiers and text-image encoders; and 3) model output mapping strategies, including nonparametric and trainable label mapping. Our extensive experimental results show that AutoVP outperforms the best-known current VP methods by a substantial margin, having up to 6.7% improvement in accuracy",
    "path": "papers/23/10/2310.08381.json",
    "total_tokens": 861,
    "translated_title": "AutoVP: 一种自动化的视觉提示框架和基准",
    "translated_abstract": "视觉提示（VP）是一种新兴的参数高效微调方法，用于调整预训练视觉模型以解决各种下游图像分类任务。然而，迄今为止，对VP的设计空间缺乏系统性研究，并没有明确的用于评估其性能的基准。为了弥合这一差距，我们提出了AutoVP，一个端到端可扩展的框架，用于自动化VP设计选择，以及12个下游图像分类任务，可以作为一个全面的VP性能基准。我们的设计空间覆盖了1）提示的联合优化；2）预训练模型的选择，包括图像分类器和文本-图像编码器；以及3）模型输出映射策略，包括非参数化和可训练的标签映射。我们的广泛实验结果表明，AutoVP在准确性方面优于目前已知的最佳VP方法，精度提高高达6.7%。",
    "tldr": "AutoVP提出了一个自动化的视觉提示框架，同时提供12个下游图像分类任务作为基准，实验结果显示AutoVP在准确性方面明显优于当前已知的最佳VP方法。",
    "en_tdlr": "AutoVP introduces an automated visual prompting framework along with 12 downstream image-classification tasks as a benchmark, and experimental results demonstrate its significant outperformance in accuracy over the current best-known VP methods."
}