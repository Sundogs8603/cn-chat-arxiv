{
    "title": "Prompt-augmented Temporal Point Process for Streaming Event Sequence. (arXiv:2310.04993v2 [cs.LG] UPDATED)",
    "abstract": "Neural Temporal Point Processes (TPPs) are the prevalent paradigm for modeling continuous-time event sequences, such as user activities on the web and financial transactions. In real-world applications, event data is typically received in a \\emph{streaming} manner, where the distribution of patterns may shift over time. Additionally, \\emph{privacy and memory constraints} are commonly observed in practical scenarios, further compounding the challenges. Therefore, the continuous monitoring of a TPP to learn the streaming event sequence is an important yet under-explored problem. Our work paper addresses this challenge by adopting Continual Learning (CL), which makes the model capable of continuously learning a sequence of tasks without catastrophic forgetting under realistic constraints. Correspondingly, we propose a simple yet effective framework, PromptTPP\\footnote{Our code is available at {\\small \\url{ https://github.com/yanyanSann/PromptTPP}}}, by integrating the base TPP with a cont",
    "link": "http://arxiv.org/abs/2310.04993",
    "context": "Title: Prompt-augmented Temporal Point Process for Streaming Event Sequence. (arXiv:2310.04993v2 [cs.LG] UPDATED)\nAbstract: Neural Temporal Point Processes (TPPs) are the prevalent paradigm for modeling continuous-time event sequences, such as user activities on the web and financial transactions. In real-world applications, event data is typically received in a \\emph{streaming} manner, where the distribution of patterns may shift over time. Additionally, \\emph{privacy and memory constraints} are commonly observed in practical scenarios, further compounding the challenges. Therefore, the continuous monitoring of a TPP to learn the streaming event sequence is an important yet under-explored problem. Our work paper addresses this challenge by adopting Continual Learning (CL), which makes the model capable of continuously learning a sequence of tasks without catastrophic forgetting under realistic constraints. Correspondingly, we propose a simple yet effective framework, PromptTPP\\footnote{Our code is available at {\\small \\url{ https://github.com/yanyanSann/PromptTPP}}}, by integrating the base TPP with a cont",
    "path": "papers/23/10/2310.04993.json",
    "total_tokens": 809,
    "translated_title": "基于提示增强的时态点过程用于流式事件序列",
    "translated_abstract": "神经时态点过程（TPP）是建模连续时间事件序列（如网络用户活动和金融交易）的主要范例。在现实世界的应用中，事件数据通常以流式方式接收，模式的分布可能随时间变化。此外，隐私和内存限制在实际场景中也很常见，进一步增加了挑战。因此，连续监测TPP以学习流式事件序列是一个重要但未充分研究的问题。我们的工作通过采用持续学习（CL）来解决这个挑战，使模型能够在现实约束下连续学习一系列任务而不会发生灾难性遗忘。相应地，我们提出了一个简单而有效的框架PromptTPP，通过将基本TPP与一个提示机制进行整合，来解决这个问题。",
    "tldr": "提出了一种基于提示增强的时态点过程（PromptTPP）方法，用于解决流式事件序列学习的挑战。",
    "en_tdlr": "A Prompt-augmented Temporal Point Process (PromptTPP) method is proposed to tackle the challenge of learning streaming event sequences."
}