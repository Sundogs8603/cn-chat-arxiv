{
    "title": "Improving Language Models Meaning Understanding and Consistency by Learning Conceptual Roles from Dictionary. (arXiv:2310.15541v1 [cs.CL])",
    "abstract": "The non-humanlike behaviour of contemporary pre-trained language models (PLMs) is a leading cause undermining their trustworthiness. A striking phenomenon of such faulty behaviours is the generation of inconsistent predictions, which produces logically contradictory results, such as generating different predictions for texts delivering the same meaning or violating logical properties. Previous studies exploited data augmentation or implemented specialised loss functions to alleviate the issue. However, their usage is limited, because they consume expensive training resources for large-sized PLMs and can only handle a certain consistency type. To this end, we propose a practical approach that alleviates the inconsistent behaviour issue by fundamentally improving PLMs' meaning awareness. Based on the conceptual role theory, our method allows PLMs to capture accurate meaning by learning precise interrelationships between concepts from word-definition pairs in a dictionary. Next, we propos",
    "link": "http://arxiv.org/abs/2310.15541",
    "context": "Title: Improving Language Models Meaning Understanding and Consistency by Learning Conceptual Roles from Dictionary. (arXiv:2310.15541v1 [cs.CL])\nAbstract: The non-humanlike behaviour of contemporary pre-trained language models (PLMs) is a leading cause undermining their trustworthiness. A striking phenomenon of such faulty behaviours is the generation of inconsistent predictions, which produces logically contradictory results, such as generating different predictions for texts delivering the same meaning or violating logical properties. Previous studies exploited data augmentation or implemented specialised loss functions to alleviate the issue. However, their usage is limited, because they consume expensive training resources for large-sized PLMs and can only handle a certain consistency type. To this end, we propose a practical approach that alleviates the inconsistent behaviour issue by fundamentally improving PLMs' meaning awareness. Based on the conceptual role theory, our method allows PLMs to capture accurate meaning by learning precise interrelationships between concepts from word-definition pairs in a dictionary. Next, we propos",
    "path": "papers/23/10/2310.15541.json",
    "total_tokens": 821,
    "translated_title": "通过从字典学习概念角色，改进语言模型的语义理解和一致性",
    "translated_abstract": "当代预训练语言模型（PLMs）的非人类行为是影响其可信度的主要原因。这种错误行为的一个显著现象是生成不一致的预测，导致逻辑上矛盾的结果，例如为传达相同意义的文本生成不同的预测或违反逻辑性质。先前的研究利用数据增强或实施专门的损失函数来缓解这个问题。然而，它们的使用受限，因为它们消耗了大规模PLMs的昂贵训练资源，并且只能处理一定类型的一致性。为此，我们提出了一种实用的方法，通过从字典中的词-定义对中学习概念角色的准确相互关系，从根本上改善PLMs的意义认知，从而缓解了不一致行为问题。",
    "tldr": "该论文提出了一种实用的方法，通过从字典中学习概念角色，从根本上改善语言模型的意义认知，以缓解其生成不一致预测的问题。",
    "en_tdlr": "This paper proposes a practical approach to fundamentally improve the meaning awareness of language models by learning conceptual roles from a dictionary, thus alleviating the issue of generating inconsistent predictions."
}