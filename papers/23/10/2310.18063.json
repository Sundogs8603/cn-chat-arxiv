{
    "title": "\"Honey, Tell Me What's Wrong\", Global Explanation of Textual Discriminative Models through Cooperative Generation. (arXiv:2310.18063v1 [cs.CL])",
    "abstract": "The ubiquity of complex machine learning has raised the importance of model-agnostic explanation algorithms. These methods create artificial instances by slightly perturbing real instances, capturing shifts in model decisions. However, such methods rely on initial data and only provide explanations of the decision for these. To tackle these problems, we propose Therapy, the first global and model-agnostic explanation method adapted to text which requires no input dataset. Therapy generates texts following the distribution learned by a classifier through cooperative generation. Because it does not rely on initial samples, it allows to generate explanations even when data is absent (e.g., for confidentiality reasons). Moreover, conversely to existing methods that combine multiple local explanations into a global one, Therapy offers a global overview of the model behavior on the input space. Our experiments show that although using no input data to generate samples, Therapy provides insig",
    "link": "http://arxiv.org/abs/2310.18063",
    "context": "Title: \"Honey, Tell Me What's Wrong\", Global Explanation of Textual Discriminative Models through Cooperative Generation. (arXiv:2310.18063v1 [cs.CL])\nAbstract: The ubiquity of complex machine learning has raised the importance of model-agnostic explanation algorithms. These methods create artificial instances by slightly perturbing real instances, capturing shifts in model decisions. However, such methods rely on initial data and only provide explanations of the decision for these. To tackle these problems, we propose Therapy, the first global and model-agnostic explanation method adapted to text which requires no input dataset. Therapy generates texts following the distribution learned by a classifier through cooperative generation. Because it does not rely on initial samples, it allows to generate explanations even when data is absent (e.g., for confidentiality reasons). Moreover, conversely to existing methods that combine multiple local explanations into a global one, Therapy offers a global overview of the model behavior on the input space. Our experiments show that although using no input data to generate samples, Therapy provides insig",
    "path": "papers/23/10/2310.18063.json",
    "total_tokens": 858,
    "translated_title": "“亲爱的，告诉我出了什么问题”，通过合作生成全局文本辨别模型的解释",
    "translated_abstract": "复杂机器学习的普及提高了无模型解释算法的重要性。这些方法通过轻微扰动真实实例来创建人工实例，捕捉模型决策的变化。然而，这些方法依赖于初始数据，并且只提供关于这些初始数据决策的解释。为了解决这些问题，我们提出了 Therapy，这是第一个适用于文本的全局和无模型解释方法，不需要输入数据集。Therapy通过合作生成，根据分类器学习到的分布生成文本。因为它不依赖于初始样本，所以即使数据缺失（例如因保密原因），也能生成解释。此外，与将多个局部解释组合成一个全局解释的现有方法不同，Therapy提供了对输入空间中模型行为的全局概览。我们的实验表明，虽然不使用输入数据来生成样本，但 Therapy 提供了有价值的洞察。",
    "tldr": "Therapy是第一个适用于文本的全局和无模型解释方法，通过合作生成文本，不依赖于初始样本，并提供了对输入空间中模型行为的全局概览。"
}