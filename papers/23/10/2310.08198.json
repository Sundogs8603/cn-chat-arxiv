{
    "title": "Beyond Traditional DoE: Deep Reinforcement Learning for Optimizing Experiments in Model Identification of Battery Dynamics. (arXiv:2310.08198v1 [cs.LG])",
    "abstract": "Model identification of battery dynamics is a central problem in energy research; many energy management systems and design processes rely on accurate battery models for efficiency optimization. The standard methodology for battery modelling is traditional design of experiments (DoE), where the battery dynamics are excited with many different current profiles and the measured outputs are used to estimate the system dynamics. However, although it is possible to obtain useful models with the traditional approach, the process is time consuming and expensive because of the need to sweep many different current-profile configurations. In the present work, a novel DoE approach is developed based on deep reinforcement learning, which alters the configuration of the experiments on the fly based on the statistics of past experiments. Instead of sticking to a library of predefined current profiles, the proposed approach modifies the current profiles dynamically by updating the output space covere",
    "link": "http://arxiv.org/abs/2310.08198",
    "context": "Title: Beyond Traditional DoE: Deep Reinforcement Learning for Optimizing Experiments in Model Identification of Battery Dynamics. (arXiv:2310.08198v1 [cs.LG])\nAbstract: Model identification of battery dynamics is a central problem in energy research; many energy management systems and design processes rely on accurate battery models for efficiency optimization. The standard methodology for battery modelling is traditional design of experiments (DoE), where the battery dynamics are excited with many different current profiles and the measured outputs are used to estimate the system dynamics. However, although it is possible to obtain useful models with the traditional approach, the process is time consuming and expensive because of the need to sweep many different current-profile configurations. In the present work, a novel DoE approach is developed based on deep reinforcement learning, which alters the configuration of the experiments on the fly based on the statistics of past experiments. Instead of sticking to a library of predefined current profiles, the proposed approach modifies the current profiles dynamically by updating the output space covere",
    "path": "papers/23/10/2310.08198.json",
    "total_tokens": 858,
    "translated_title": "超越传统DoE：深度强化学习用于优化电池动力学模型识别中的实验设计",
    "translated_abstract": "电池动力学模型识别是能源研究中的一个核心问题；许多能源管理系统和设计过程依赖于准确的电池模型进行效率优化。传统的电池建模方法是利用传统的实验设计（DoE），其中通过许多不同的电流配置来激发电池动力学，并利用测量输出来估计系统动力学。然而，虽然传统方法可以获得有用的模型，但由于需要扫描许多不同的电流配置，这一过程时间长且昂贵。在本研究中，基于深度强化学习开发了一种新的DoE方法，该方法根据过去实验的统计信息动态地改变实验配置。与坚持预定义电流配置的库不同，提出的方法通过更新输出空间来动态修改电流配置。",
    "tldr": "本论文提出了一种基于深度强化学习的新颖DoE方法，用于优化电池动力学模型识别中的实验设计。该方法根据过去实验的统计信息动态地改变实验配置，从而提高了实验效率和准确性。",
    "en_tdlr": "This paper proposes a novel DoE approach based on deep reinforcement learning for optimizing experiment design in battery dynamics model identification. The approach dynamically modifies the experiment configuration based on the statistics of past experiments, thereby improving the efficiency and accuracy of the experiments."
}