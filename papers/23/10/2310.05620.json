{
    "title": "LAiW: A Chinese Legal Large Language Models Benchmark",
    "abstract": "arXiv:2310.05620v2 Announce Type: replace  Abstract: General and legal domain LLMs have demonstrated strong performance in various tasks of LegalAI. However, the current evaluations of these LLMs in LegalAI are defined by the experts of computer science, lacking consistency with the logic of legal practice, making it difficult to judge their practical capabilities. To address this challenge, we are the first to build the Chinese legal LLMs benchmark LAiW, based on the logic of legal practice. To align with the thinking process of legal experts and legal practice (syllogism), we divide the legal capabilities of LLMs from easy to difficult into three levels: basic information retrieval, legal foundation inference, and complex legal application. Each level contains multiple tasks to ensure a comprehensive evaluation. Through automated evaluation of current general and legal domain LLMs on our benchmark, we indicate that these LLMs may not align with the logic of legal practice. LLMs seem ",
    "link": "https://arxiv.org/abs/2310.05620",
    "context": "Title: LAiW: A Chinese Legal Large Language Models Benchmark\nAbstract: arXiv:2310.05620v2 Announce Type: replace  Abstract: General and legal domain LLMs have demonstrated strong performance in various tasks of LegalAI. However, the current evaluations of these LLMs in LegalAI are defined by the experts of computer science, lacking consistency with the logic of legal practice, making it difficult to judge their practical capabilities. To address this challenge, we are the first to build the Chinese legal LLMs benchmark LAiW, based on the logic of legal practice. To align with the thinking process of legal experts and legal practice (syllogism), we divide the legal capabilities of LLMs from easy to difficult into three levels: basic information retrieval, legal foundation inference, and complex legal application. Each level contains multiple tasks to ensure a comprehensive evaluation. Through automated evaluation of current general and legal domain LLMs on our benchmark, we indicate that these LLMs may not align with the logic of legal practice. LLMs seem ",
    "path": "papers/23/10/2310.05620.json",
    "total_tokens": 901,
    "translated_title": "LAiW：一个中文法律大型语言模型基准",
    "translated_abstract": "arXiv:2310.05620v2 公告类型：替换 摘要：一般和法律领域的LLM在LegalAI的各种任务中表现出色。然而，当前对这些LLM在LegalAI中的评估是由计算机科学专家定义的，缺乏与法律实践逻辑一致性，使得很难判断它们的实际能力。为了解决这一挑战，我们首次基于法律实践逻辑构建了中文法律LLM基准LAiW。为了与法律专家和法律实践的思维过程（三段论）保持一致，我们将LLM的法律能力从易到难分为三个级别：基本信息检索、法律基础推理和复杂法律应用。每个级别包含多个任务以确保全面评估。通过对当前通用和法律领域LLM在我们的基准上的自动化评估，我们表明这些LLM可能不符合法律实践逻辑。LLM似乎",
    "tldr": "该论文提出了一个中文法律大型语言模型基准LAiW，通过构建基于法律实践逻辑的评估任务，揭示了当前通用和法律领域LLM可能不符合法律实践逻辑。"
}