{
    "title": "LitCab: Lightweight Language Model Calibration over Short- and Long-form Responses",
    "abstract": "arXiv:2310.19208v2 Announce Type: replace  Abstract: A model is considered well-calibrated when its probability estimate aligns with the actual likelihood of the output being correct. Calibrating language models (LMs) is crucial, as it plays a vital role in detecting and mitigating hallucinations of LMs as well as building more trustworthy models. However, standard calibration techniques may not be suited for LM calibration. For instance, post-processing methods such as temperature scaling do not reorder the candidate generations. On the other hand, training-based methods require fine-tuning the entire model, which is impractical for LMs of large scale. We present LitCab, a lightweight calibration mechanism consisting of a single linear layer that takes the input text representation and predicts a bias term, which is then added to the LM output logits. LitCab improves model calibration by only adding < 2% of the original model parameters. For evaluation, we construct CaT, a benchmark c",
    "link": "https://arxiv.org/abs/2310.19208",
    "context": "Title: LitCab: Lightweight Language Model Calibration over Short- and Long-form Responses\nAbstract: arXiv:2310.19208v2 Announce Type: replace  Abstract: A model is considered well-calibrated when its probability estimate aligns with the actual likelihood of the output being correct. Calibrating language models (LMs) is crucial, as it plays a vital role in detecting and mitigating hallucinations of LMs as well as building more trustworthy models. However, standard calibration techniques may not be suited for LM calibration. For instance, post-processing methods such as temperature scaling do not reorder the candidate generations. On the other hand, training-based methods require fine-tuning the entire model, which is impractical for LMs of large scale. We present LitCab, a lightweight calibration mechanism consisting of a single linear layer that takes the input text representation and predicts a bias term, which is then added to the LM output logits. LitCab improves model calibration by only adding < 2% of the original model parameters. For evaluation, we construct CaT, a benchmark c",
    "path": "papers/23/10/2310.19208.json",
    "total_tokens": 728,
    "translated_title": "LitCab: 在短语和长语言模型应答中的轻量级校准",
    "translated_abstract": "当模型的概率估计与实际输出正确的可能性一致时，该模型被认为是校准良好的。校准语言模型（LMs）至关重要，因为它在检测和减轻LMs的幻觉以及构建更可信赖的模型中发挥着重要作用。我们提出了LitCab，这是一种轻量级校准机制，由一个单一线性层组成，它接受输入文本表示并预测一个偏差项，然后将其添加到LM输出logits中。",
    "tldr": "LitCab 是一种轻量级校准机制，通过仅添加原始模型参数的 < 2%，以一个单一线性层的形式改善语言模型的校准。",
    "en_tdlr": "LitCab is a lightweight calibration mechanism that improves model calibration by adding less than 2% of the original model parameters, in the form of a single linear layer."
}