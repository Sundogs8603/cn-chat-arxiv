{
    "title": "PAC Learning Linear Thresholds from Label Proportions. (arXiv:2310.10098v1 [cs.LG])",
    "abstract": "Learning from label proportions (LLP) is a generalization of supervised learning in which the training data is available as sets or bags of feature-vectors (instances) along with the average instance-label of each bag. The goal is to train a good instance classifier. While most previous works on LLP have focused on training models on such training data, computational learnability of LLP was only recently explored by [Saket'21, Saket'22] who showed worst case intractability of properly learning linear threshold functions (LTFs) from label proportions. However, their work did not rule out efficient algorithms for this problem on natural distributions.  In this work we show that it is indeed possible to efficiently learn LTFs using LTFs when given access to random bags of some label proportion in which feature-vectors are, conditioned on their labels, independently sampled from a Gaussian distribution $N(\\mathbf{\\mu}, \\mathbf{\\Sigma})$. Our work shows that a certain matrix -- formed using",
    "link": "http://arxiv.org/abs/2310.10098",
    "context": "Title: PAC Learning Linear Thresholds from Label Proportions. (arXiv:2310.10098v1 [cs.LG])\nAbstract: Learning from label proportions (LLP) is a generalization of supervised learning in which the training data is available as sets or bags of feature-vectors (instances) along with the average instance-label of each bag. The goal is to train a good instance classifier. While most previous works on LLP have focused on training models on such training data, computational learnability of LLP was only recently explored by [Saket'21, Saket'22] who showed worst case intractability of properly learning linear threshold functions (LTFs) from label proportions. However, their work did not rule out efficient algorithms for this problem on natural distributions.  In this work we show that it is indeed possible to efficiently learn LTFs using LTFs when given access to random bags of some label proportion in which feature-vectors are, conditioned on their labels, independently sampled from a Gaussian distribution $N(\\mathbf{\\mu}, \\mathbf{\\Sigma})$. Our work shows that a certain matrix -- formed using",
    "path": "papers/23/10/2310.10098.json",
    "total_tokens": 883,
    "translated_title": "从标签比例中学习线性阈值（标题翻译）",
    "translated_abstract": "标签比例学习（LLP）是一种监督学习的泛化形式，其中训练数据以特征向量（实例）的集合或包的形式给出，同时还提供了每个包的平均实例标签。其目标是训练一个良好的实例分类器。尽管之前的LLP研究主要集中在该训练数据上训练模型，但最近的工作[Saket'21, Saket'22]探索了LLP的计算可学习性，展示了从标签比例中准确学习线性阈值函数（LTFs）的最坏情况复杂性。然而，他们的工作没有排除在自然分布下该问题的高效算法。在本文中，我们展示了通过使用LTFs从某个标签比例的随机包获取的条件下标签独立地从高斯分布$N(\\mathbf{\\mu}, \\mathbf{\\Sigma})$中采样的特征向量，可以有效地学习LTFs。我们的工作表明，通过某种矩阵的形式-",
    "tldr": "本文探讨了从标签比例中学习线性阈值函数的计算可学习性，提出了一种使用LTFs有效学习LTFs的方法。",
    "en_tdlr": "This paper explores the computational learnability of learning linear threshold functions from label proportions and proposes an efficient method of using LTFs to learn LTFs."
}