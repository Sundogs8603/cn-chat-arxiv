{
    "title": "Beyond Myopia: Learning from Positive and Unlabeled Data through Holistic Predictive Trends. (arXiv:2310.04078v1 [cs.LG])",
    "abstract": "Learning binary classifiers from positive and unlabeled data (PUL) is vital in many real-world applications, especially when verifying negative examples is difficult. Despite the impressive empirical performance of recent PUL methods, challenges like accumulated errors and increased estimation bias persist due to the absence of negative labels. In this paper, we unveil an intriguing yet long-overlooked observation in PUL: \\textit{resampling the positive data in each training iteration to ensure a balanced distribution between positive and unlabeled examples results in strong early-stage performance. Furthermore, predictive trends for positive and negative classes display distinctly different patterns.} Specifically, the scores (output probability) of unlabeled negative examples consistently decrease, while those of unlabeled positive examples show largely chaotic trends. Instead of focusing on classification within individual time frames, we innovatively adopt a holistic approach, inte",
    "link": "http://arxiv.org/abs/2310.04078",
    "context": "Title: Beyond Myopia: Learning from Positive and Unlabeled Data through Holistic Predictive Trends. (arXiv:2310.04078v1 [cs.LG])\nAbstract: Learning binary classifiers from positive and unlabeled data (PUL) is vital in many real-world applications, especially when verifying negative examples is difficult. Despite the impressive empirical performance of recent PUL methods, challenges like accumulated errors and increased estimation bias persist due to the absence of negative labels. In this paper, we unveil an intriguing yet long-overlooked observation in PUL: \\textit{resampling the positive data in each training iteration to ensure a balanced distribution between positive and unlabeled examples results in strong early-stage performance. Furthermore, predictive trends for positive and negative classes display distinctly different patterns.} Specifically, the scores (output probability) of unlabeled negative examples consistently decrease, while those of unlabeled positive examples show largely chaotic trends. Instead of focusing on classification within individual time frames, we innovatively adopt a holistic approach, inte",
    "path": "papers/23/10/2310.04078.json",
    "total_tokens": 913,
    "translated_title": "超越近视：通过整体预测趋势从正样本和无标签数据中学习",
    "translated_abstract": "在许多现实世界的应用中，从正样本和无标签数据(PUL)中学习二元分类器是至关重要的，特别是在验证负样本困难的情况下。尽管最近的PUL方法在实验性能方面表现出色，但由于缺乏负标签，仍然存在积累误差和增加估计偏差等挑战。在本文中，我们揭示了PUL中一个引人注目但长期被忽视的观察结果：\\textit{在每个训练迭代中重新采样正样本以确保正样本和无标签样本之间的平衡分布会导致强的早期性能。此外，正类和负类的预测趋势显示出不同的模式。}具体而言，无标签负样本的得分(输出概率)持续下降，而无标签正样本的得分显示出大致混乱的趋势。我们创新地采用了一种整体方法，而不是在个别时间段内进行分类。",
    "tldr": "本文发现了从正样本和无标签数据中学习的一个重要观察：通过在每个训练迭代中重新采样正样本，可以获得强大的早期性能，并且正类和负类的预测趋势显示出不同的模式。",
    "en_tdlr": "This paper reveals an important observation in learning from positive and unlabeled data (PUL): resampling positive data in each training iteration leads to strong early-stage performance, and the predictive trends for positive and negative classes exhibit different patterns."
}