{
    "title": "PGA: Personalizing Grasping Agents with Single Human-Robot Interaction. (arXiv:2310.12547v1 [cs.RO])",
    "abstract": "Language-Conditioned Robotic Grasping (LCRG) aims to develop robots that ground and grasp objects based on natural language instructions. While robots capable of recognizing personal objects like \"my wallet\" can interact more naturally with non-expert users, current LCRG systems primarily limit robots to understanding only generic expressions. To this end, we introduce a task scenario GraspMine with a novel dataset that aims to locate and grasp personal objects given personal indicators via learning from a single human-robot interaction. To address GraspMine, we propose Personalized Grasping Agent (PGA), that learns personal objects by propagating user-given information through a Reminiscence-a collection of raw images from the user's environment. Specifically, PGA acquires personal object information by a user presenting a personal object with its associated indicator, followed by PGA inspecting the object by rotating it. Based on the acquired information, PGA pseudo-labels objects in",
    "link": "http://arxiv.org/abs/2310.12547",
    "context": "Title: PGA: Personalizing Grasping Agents with Single Human-Robot Interaction. (arXiv:2310.12547v1 [cs.RO])\nAbstract: Language-Conditioned Robotic Grasping (LCRG) aims to develop robots that ground and grasp objects based on natural language instructions. While robots capable of recognizing personal objects like \"my wallet\" can interact more naturally with non-expert users, current LCRG systems primarily limit robots to understanding only generic expressions. To this end, we introduce a task scenario GraspMine with a novel dataset that aims to locate and grasp personal objects given personal indicators via learning from a single human-robot interaction. To address GraspMine, we propose Personalized Grasping Agent (PGA), that learns personal objects by propagating user-given information through a Reminiscence-a collection of raw images from the user's environment. Specifically, PGA acquires personal object information by a user presenting a personal object with its associated indicator, followed by PGA inspecting the object by rotating it. Based on the acquired information, PGA pseudo-labels objects in",
    "path": "papers/23/10/2310.12547.json",
    "total_tokens": 891,
    "translated_title": "PGA: 个性化抓取代理与单一人机交互",
    "translated_abstract": "语言条件化机器人抓取（LCRG）旨在开发基于自然语言指令的机器人来进行物体的接地和抓取。虽然能够识别个人物品如“我的钱包”的机器人可以更自然地与非专家用户交互，但当前的LCRG系统主要限制机器人只能理解一般表达。为此，我们引入了一个名为GraspMine的任务场景，并提供了一个新颖的数据集，旨在通过从单一人机交互中学习定位和抓取个人物体。为了解决GraspMine，我们提出了个性化抓取代理（PGA），通过将用户提供的信息传播到个人物体上，通过Reminiscence-用户环境中的一系列原始图像，获取个人物体信息。具体而言，PGA通过用户展示带有相关指示器的个人物体，并以旋转的方式检查物体来获取个人物体信息。根据所获得的信息，PGA为物体进行伪标签化。",
    "tldr": "这项研究介绍了个性化抓取代理（PGA），它通过单一人机交互学习并定位和抓取个人物体。PGA通过用户提供的信息和用户环境中的原始图像，实现个性化物体抓取。",
    "en_tdlr": "This study presents Personalized Grasping Agent (PGA) which learns to locate and grasp personal objects through single human-robot interaction. PGA achieves personalized object grasping by utilizing user-provided information and a collection of raw images from the user's environment."
}