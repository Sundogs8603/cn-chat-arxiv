{
    "title": "SecurityNet: Assessing Machine Learning Vulnerabilities on Public Models. (arXiv:2310.12665v1 [cs.CR] CROSS LISTED)",
    "abstract": "While advanced machine learning (ML) models are deployed in numerous real-world applications, previous works demonstrate these models have security and privacy vulnerabilities. Various empirical research has been done in this field. However, most of the experiments are performed on target ML models trained by the security researchers themselves. Due to the high computational resource requirement for training advanced models with complex architectures, researchers generally choose to train a few target models using relatively simple architectures on typical experiment datasets. We argue that to understand ML models' vulnerabilities comprehensively, experiments should be performed on a large set of models trained with various purposes (not just the purpose of evaluating ML attacks and defenses). To this end, we propose using publicly available models with weights from the Internet (public models) for evaluating attacks and defenses on ML models. We establish a database, namely SecurityNe",
    "link": "http://arxiv.org/abs/2310.12665",
    "context": "Title: SecurityNet: Assessing Machine Learning Vulnerabilities on Public Models. (arXiv:2310.12665v1 [cs.CR] CROSS LISTED)\nAbstract: While advanced machine learning (ML) models are deployed in numerous real-world applications, previous works demonstrate these models have security and privacy vulnerabilities. Various empirical research has been done in this field. However, most of the experiments are performed on target ML models trained by the security researchers themselves. Due to the high computational resource requirement for training advanced models with complex architectures, researchers generally choose to train a few target models using relatively simple architectures on typical experiment datasets. We argue that to understand ML models' vulnerabilities comprehensively, experiments should be performed on a large set of models trained with various purposes (not just the purpose of evaluating ML attacks and defenses). To this end, we propose using publicly available models with weights from the Internet (public models) for evaluating attacks and defenses on ML models. We establish a database, namely SecurityNe",
    "path": "papers/23/10/2310.12665.json",
    "total_tokens": 836,
    "translated_title": "SecurityNet：评估公共模型上的机器学习漏洞",
    "translated_abstract": "尽管先进的机器学习（ML）模型被部署在许多实际应用中，之前的研究表明这些模型存在安全和隐私漏洞。在这一领域有各种经验性研究。然而，大多数实验是在由安全研究人员自己训练的目标ML模型上进行的。由于使用复杂架构训练高级模型需要高计算资源，研究人员通常选择使用相对简单的架构在典型的实验数据集上训练少数目标模型。我们认为，为了全面了解ML模型的漏洞，应该在训练有不同目的（而不仅仅是评估ML攻击和防御的目的）的大量模型上进行实验。为此，我们提出使用来自互联网的公开模型权重（公共模型）来评估对ML模型的攻击和防御。我们建立了一个数据库，名为SecurityNet",
    "tldr": "本研究通过在公共模型上评估攻击和防御来全面理解机器学习模型的漏洞，以解决对高计算资源要求较高的问题。"
}