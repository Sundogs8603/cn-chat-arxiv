{
    "title": "Meta-CoT: Generalizable Chain-of-Thought Prompting in Mixed-task Scenarios with Large Language Models. (arXiv:2310.06692v2 [cs.CL] UPDATED)",
    "abstract": "Large language models (LLMs) have unveiled remarkable reasoning capabilities by exploiting chain-of-thought (CoT) prompting, which generates intermediate reasoning chains to serve as the rationale for deriving the answer. However, current CoT methods either simply employ general prompts such as Let's think step by step, or heavily rely on handcrafted task-specific demonstrations to attain preferable performances, thereby engendering an inescapable gap between performance and generalization. To bridge this gap, we propose Meta-CoT, a generalizable CoT prompting method in mixed-task scenarios where the type of input questions is unknown. Meta-CoT firstly categorizes the scenario based on the input question and subsequently constructs diverse demonstrations from the corresponding data pool in an automatic pattern. Meta-CoT simultaneously enjoys remarkable performances on ten public benchmark reasoning tasks and superior generalization capabilities. Notably, Meta-CoT achieves the state-of-",
    "link": "http://arxiv.org/abs/2310.06692",
    "context": "Title: Meta-CoT: Generalizable Chain-of-Thought Prompting in Mixed-task Scenarios with Large Language Models. (arXiv:2310.06692v2 [cs.CL] UPDATED)\nAbstract: Large language models (LLMs) have unveiled remarkable reasoning capabilities by exploiting chain-of-thought (CoT) prompting, which generates intermediate reasoning chains to serve as the rationale for deriving the answer. However, current CoT methods either simply employ general prompts such as Let's think step by step, or heavily rely on handcrafted task-specific demonstrations to attain preferable performances, thereby engendering an inescapable gap between performance and generalization. To bridge this gap, we propose Meta-CoT, a generalizable CoT prompting method in mixed-task scenarios where the type of input questions is unknown. Meta-CoT firstly categorizes the scenario based on the input question and subsequently constructs diverse demonstrations from the corresponding data pool in an automatic pattern. Meta-CoT simultaneously enjoys remarkable performances on ten public benchmark reasoning tasks and superior generalization capabilities. Notably, Meta-CoT achieves the state-of-",
    "path": "papers/23/10/2310.06692.json",
    "total_tokens": 862,
    "translated_title": "Meta-CoT:大规模语言模型在混合任务场景中的通用思维链提示",
    "translated_abstract": "大规模语言模型（LLM）通过利用链式思维提示展示出了卓越的推理能力，这种提示生成中间推理链以作为得出答案的基本理由。然而，目前的CoT方法要么仅仅使用类似“让我们逐步思考”的通用提示，要么过于依赖手工设计的任务特定演示来达到理想的性能，从而导致性能和泛化之间的不可避免的鸿沟。为了弥合这一鸿沟，我们提出了Meta-CoT，一种在未知输入问题类型的混合任务场景中具有通用性的CoT提示方法。Meta-CoT首先根据输入问题对场景进行分类，然后以自动模式从相应的数据池中构建多样的演示。Meta-CoT在十个公共基准推理任务上表现出卓越的性能和优越的泛化能力。值得注意的是，Meta-CoT实现了最新技术水平。",
    "tldr": "Meta-CoT是一种在混合任务场景中能够通用思维链提示的方法，在十个公共基准推理任务中表现出卓越的性能和优越的泛化能力。",
    "en_tdlr": "Meta-CoT is a method that provides generalizable chain-of-thought prompting in mixed-task scenarios, and achieves remarkable performance and superior generalization capabilities on ten public benchmark reasoning tasks."
}