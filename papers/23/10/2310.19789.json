{
    "title": "DiffEnc: Variational Diffusion with a Learned Encoder. (arXiv:2310.19789v1 [cs.LG])",
    "abstract": "Diffusion models may be viewed as hierarchical variational autoencoders (VAEs) with two improvements: parameter sharing for the conditional distributions in the generative process and efficient computation of the loss as independent terms over the hierarchy. We consider two changes to the diffusion model that retain these advantages while adding flexibility to the model. Firstly, we introduce a data- and depth-dependent mean function in the diffusion process, which leads to a modified diffusion loss. Our proposed framework, DiffEnc, achieves state-of-the-art likelihood on CIFAR-10. Secondly, we let the ratio of the noise variance of the reverse encoder process and the generative process be a free weight parameter rather than being fixed to 1. This leads to theoretical insights: For a finite depth hierarchy, the evidence lower bound (ELBO) can be used as an objective for a weighted diffusion loss approach and for optimizing the noise schedule specifically for inference. For the infinite",
    "link": "http://arxiv.org/abs/2310.19789",
    "context": "Title: DiffEnc: Variational Diffusion with a Learned Encoder. (arXiv:2310.19789v1 [cs.LG])\nAbstract: Diffusion models may be viewed as hierarchical variational autoencoders (VAEs) with two improvements: parameter sharing for the conditional distributions in the generative process and efficient computation of the loss as independent terms over the hierarchy. We consider two changes to the diffusion model that retain these advantages while adding flexibility to the model. Firstly, we introduce a data- and depth-dependent mean function in the diffusion process, which leads to a modified diffusion loss. Our proposed framework, DiffEnc, achieves state-of-the-art likelihood on CIFAR-10. Secondly, we let the ratio of the noise variance of the reverse encoder process and the generative process be a free weight parameter rather than being fixed to 1. This leads to theoretical insights: For a finite depth hierarchy, the evidence lower bound (ELBO) can be used as an objective for a weighted diffusion loss approach and for optimizing the noise schedule specifically for inference. For the infinite",
    "path": "papers/23/10/2310.19789.json",
    "total_tokens": 849,
    "translated_title": "DiffEnc: 使用学习的编码器的变分扩散模型",
    "translated_abstract": "扩散模型可以看作是具有两种改进的分层变分自编码器（VAEs）：在生成过程中参数共享的条件分布和在层次结构上独立计算损失。我们对扩散模型进行了两个变化，保留了这些优势的同时增加了模型的灵活性。首先，我们在扩散过程中引入了一个与数据和深度相关的均值函数，从而导致了修改后的扩散损失。我们提出的框架DiffEnc在CIFAR-10上实现了最先进的可能性。其次，我们让反向编码过程的噪声方差与生成过程的比率成为一个自由的权重参数，而不是固定为1。这带来了理论上的洞察力：对于有限深度层次，证据下界（ELBO）可以用作加权扩散损失方法的目标，并用于专门为推理而优化噪声调度。",
    "tldr": "DiffEnc是一种使用学习的编码器的变分扩散模型，通过引入数据和深度相关的均值函数和可调节的噪声方差比率，实现了最先进的可能性。",
    "en_tdlr": "DiffEnc is a variational diffusion model with a learned encoder, achieving state-of-the-art likelihood by introducing a data and depth-dependent mean function and a configurable noise variance ratio."
}