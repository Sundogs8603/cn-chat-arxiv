{
    "title": "Identifying and examining machine learning biases on Adult dataset. (arXiv:2310.09373v1 [cs.CY])",
    "abstract": "This research delves into the reduction of machine learning model bias through Ensemble Learning. Our rigorous methodology comprehensively assesses bias across various categorical variables, ultimately revealing a pronounced gender attribute bias. The empirical evidence unveils a substantial gender-based wage prediction disparity: wages predicted for males, initially at \\$902.91, significantly decrease to \\$774.31 when the gender attribute is alternated to females. Notably, Kullback-Leibler divergence scores point to gender bias, with values exceeding 0.13, predominantly within tree-based models. Employing Ensemble Learning elucidates the quest for fairness and transparency. Intriguingly, our findings reveal that the stacked model aligns with individual models, confirming the resilience of model bias. This study underscores ethical considerations and advocates the implementation of hybrid models for a data-driven society marked by impartiality and inclusivity.",
    "link": "http://arxiv.org/abs/2310.09373",
    "context": "Title: Identifying and examining machine learning biases on Adult dataset. (arXiv:2310.09373v1 [cs.CY])\nAbstract: This research delves into the reduction of machine learning model bias through Ensemble Learning. Our rigorous methodology comprehensively assesses bias across various categorical variables, ultimately revealing a pronounced gender attribute bias. The empirical evidence unveils a substantial gender-based wage prediction disparity: wages predicted for males, initially at \\$902.91, significantly decrease to \\$774.31 when the gender attribute is alternated to females. Notably, Kullback-Leibler divergence scores point to gender bias, with values exceeding 0.13, predominantly within tree-based models. Employing Ensemble Learning elucidates the quest for fairness and transparency. Intriguingly, our findings reveal that the stacked model aligns with individual models, confirming the resilience of model bias. This study underscores ethical considerations and advocates the implementation of hybrid models for a data-driven society marked by impartiality and inclusivity.",
    "path": "papers/23/10/2310.09373.json",
    "total_tokens": 919,
    "translated_title": "识别并研究成人数据集上的机器学习偏见",
    "translated_abstract": "本研究通过集成学习深入探讨了减少机器学习模型偏见的方法。我们采用严格的方法全面评估了各个分类变量上的偏见，最终揭示了明显的性别属性偏见。实证证据揭示了显著的基于性别的工资预测差距：在将性别属性改为女性时，男性的预测工资从初始的902.91美元大幅降至774.31美元。值得注意的是，Kullback-Leibler散度得分指出了性别偏见，值超过0.13，主要集中在基于树的模型中。采用集成学习有助于追求公平和透明。有趣的是，我们的研究结果表明堆叠模型与各个单独模型一致，确认了模型偏见的弹性。本研究强调了道德考虑，并主张在以数据驱动的社会中实施混合模型，以追求公正和包容性。",
    "tldr": "该研究通过集成学习探讨了减少机器学习模型偏见的方法，揭示了性别属性偏见对工资预测的重要影响。研究结果强调了在数据驱动的社会中实施混合模型的必要性，以实现公正和包容性。",
    "en_tdlr": "This research investigates the reduction of machine learning model bias through Ensemble Learning and reveals the significant impact of gender attribute bias on wage prediction. The study underscores the importance of implementing hybrid models in a data-driven society to achieve fairness and inclusivity."
}