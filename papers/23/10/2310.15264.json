{
    "title": "Towards Possibilities & Impossibilities of AI-generated Text Detection: A Survey. (arXiv:2310.15264v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs) have revolutionized the domain of natural language processing (NLP) with remarkable capabilities of generating human-like text responses. However, despite these advancements, several works in the existing literature have raised serious concerns about the potential misuse of LLMs such as spreading misinformation, generating fake news, plagiarism in academia, and contaminating the web. To address these concerns, a consensus among the research community is to develop algorithmic solutions to detect AI-generated text. The basic idea is that whenever we can tell if the given text is either written by a human or an AI, we can utilize this information to address the above-mentioned concerns. To that end, a plethora of detection frameworks have been proposed, highlighting the possibilities of AI-generated text detection. But in parallel to the development of detection frameworks, researchers have also concentrated on designing strategies to elude detection, i.e., f",
    "link": "http://arxiv.org/abs/2310.15264",
    "context": "Title: Towards Possibilities & Impossibilities of AI-generated Text Detection: A Survey. (arXiv:2310.15264v1 [cs.CL])\nAbstract: Large Language Models (LLMs) have revolutionized the domain of natural language processing (NLP) with remarkable capabilities of generating human-like text responses. However, despite these advancements, several works in the existing literature have raised serious concerns about the potential misuse of LLMs such as spreading misinformation, generating fake news, plagiarism in academia, and contaminating the web. To address these concerns, a consensus among the research community is to develop algorithmic solutions to detect AI-generated text. The basic idea is that whenever we can tell if the given text is either written by a human or an AI, we can utilize this information to address the above-mentioned concerns. To that end, a plethora of detection frameworks have been proposed, highlighting the possibilities of AI-generated text detection. But in parallel to the development of detection frameworks, researchers have also concentrated on designing strategies to elude detection, i.e., f",
    "path": "papers/23/10/2310.15264.json",
    "total_tokens": 885,
    "translated_title": "对AI生成文本检测的可能性和不可能性进行综述",
    "translated_abstract": "大型语言模型（LLMs）以其生成人类化文本响应的显著能力，彻底改变了自然语言处理（NLP）领域。然而，尽管取得了这些进展，现有文献中的一些工作对LLMs的潜在滥用问题提出了严重关注，如传播错误信息、生成假新闻、学术抄袭和污染网络。为了解决这些问题，研究界达成共识，即开发用于检测AI生成文本的算法解决方案。基本思想是，只要我们能判断给定文本是由人类还是AI编写的，我们就可以利用这些信息来应对上述问题。为此，提出了大量的检测框架，突出了AI生成文本检测的可能性。然而，与检测框架的发展同时，研究人员还致力于设计规避检测的策略。",
    "tldr": "本文综述了AI生成文本检测的可能性和不可能性。具体而言，讨论了使用大型语言模型产生的文本可能导致的问题以及表明AI生成文本检测的意义。另外，还提到了对抗检测的策略的设计。",
    "en_tdlr": "This paper surveys the possibilities and impossibilities of AI-generated text detection. It discusses the issues that may arise from using large language models to generate text and highlights the significance of AI-generated text detection. Additionally, the paper mentions the design of strategies to evade detection."
}