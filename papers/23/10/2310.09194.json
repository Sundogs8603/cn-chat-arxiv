{
    "title": "Variational autoencoder with weighted samples for high-dimensional non-parametric adaptive importance sampling. (arXiv:2310.09194v1 [cs.LG])",
    "abstract": "Probability density function estimation with weighted samples is the main foundation of all adaptive importance sampling algorithms. Classically, a target distribution is approximated either by a non-parametric model or within a parametric family. However, these models suffer from the curse of dimensionality or from their lack of flexibility. In this contribution, we suggest to use as the approximating model a distribution parameterised by a variational autoencoder. We extend the existing framework to the case of weighted samples by introducing a new objective function. The flexibility of the obtained family of distributions makes it as expressive as a non-parametric model, and despite the very high number of parameters to estimate, this family is much more efficient in high dimension than the classical Gaussian or Gaussian mixture families. Moreover, in order to add flexibility to the model and to be able to learn multimodal distributions, we consider a learnable prior distribution fo",
    "link": "http://arxiv.org/abs/2310.09194",
    "context": "Title: Variational autoencoder with weighted samples for high-dimensional non-parametric adaptive importance sampling. (arXiv:2310.09194v1 [cs.LG])\nAbstract: Probability density function estimation with weighted samples is the main foundation of all adaptive importance sampling algorithms. Classically, a target distribution is approximated either by a non-parametric model or within a parametric family. However, these models suffer from the curse of dimensionality or from their lack of flexibility. In this contribution, we suggest to use as the approximating model a distribution parameterised by a variational autoencoder. We extend the existing framework to the case of weighted samples by introducing a new objective function. The flexibility of the obtained family of distributions makes it as expressive as a non-parametric model, and despite the very high number of parameters to estimate, this family is much more efficient in high dimension than the classical Gaussian or Gaussian mixture families. Moreover, in order to add flexibility to the model and to be able to learn multimodal distributions, we consider a learnable prior distribution fo",
    "path": "papers/23/10/2310.09194.json",
    "total_tokens": 972,
    "translated_title": "变分自动编码器与加权样本在高维非参数自适应重要性采样中的应用",
    "translated_abstract": "采用加权样本的概率密度函数估计是所有自适应重要性采样算法的基础。传统上，目标分布要么通过非参数模型进行近似，要么在参数化族中进行近似。然而，这些模型要么面临维度灾难，要么缺乏灵活性。在本文中，我们建议使用由变分自动编码器参数化的分布作为近似模型。我们通过引入新的目标函数将现有框架扩展到加权样本的情况。所得到的分布族的灵活性使其与非参数模型一样表达能力强，尽管参数估计的数量非常高，但在高维情况下，这个分布族比传统的高斯或高斯混合族要更高效。此外，为了增加模型的灵活性和学习多模态分布的能力，我们考虑了可学习的先验分布。",
    "tldr": "本文提出了一种使用变分自动编码器和加权样本的方法来近似高维非参数自适应重要性采样中的目标分布。所得到的分布族具有与非参数模型相当的表达能力，并且在高维情况下比传统的高斯或高斯混合族更高效。同时，我们还引入了可学习的先验分布以增加模型的灵活性和学习多模态分布的能力。"
}