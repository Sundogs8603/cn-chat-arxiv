{
    "title": "MAF: Multi-Aspect Feedback for Improving Reasoning in Large Language Models. (arXiv:2310.12426v1 [cs.CL])",
    "abstract": "Language Models (LMs) have shown impressive performance in various natural language tasks. However, when it comes to natural language reasoning, LMs still face challenges such as hallucination, generating incorrect intermediate reasoning steps, and making mathematical errors. Recent research has focused on enhancing LMs through self-improvement using feedback. Nevertheless, existing approaches relying on a single generic feedback source fail to address the diverse error types found in LM-generated reasoning chains. In this work, we propose Multi-Aspect Feedback, an iterative refinement framework that integrates multiple feedback modules, including frozen LMs and external tools, each focusing on a specific error category. Our experimental results demonstrate the efficacy of our approach to addressing several errors in the LM-generated reasoning chain and thus improving the overall performance of an LM in several reasoning tasks. We see a relative improvement of up to 20% in Mathematical",
    "link": "http://arxiv.org/abs/2310.12426",
    "context": "Title: MAF: Multi-Aspect Feedback for Improving Reasoning in Large Language Models. (arXiv:2310.12426v1 [cs.CL])\nAbstract: Language Models (LMs) have shown impressive performance in various natural language tasks. However, when it comes to natural language reasoning, LMs still face challenges such as hallucination, generating incorrect intermediate reasoning steps, and making mathematical errors. Recent research has focused on enhancing LMs through self-improvement using feedback. Nevertheless, existing approaches relying on a single generic feedback source fail to address the diverse error types found in LM-generated reasoning chains. In this work, we propose Multi-Aspect Feedback, an iterative refinement framework that integrates multiple feedback modules, including frozen LMs and external tools, each focusing on a specific error category. Our experimental results demonstrate the efficacy of our approach to addressing several errors in the LM-generated reasoning chain and thus improving the overall performance of an LM in several reasoning tasks. We see a relative improvement of up to 20% in Mathematical",
    "path": "papers/23/10/2310.12426.json",
    "total_tokens": 949,
    "translated_title": "MAF: 多方面反馈以改善大型语言模型的推理能力",
    "translated_abstract": "语言模型在各种自然语言任务中展现出了令人印象深刻的性能。然而，在涉及自然语言推理的情况下，语言模型仍然面临诸如幻觉，生成错误的中间推理步骤和数学错误等挑战。最近的研究集中在通过反馈自我改进来增强语言模型。然而，现有的方法仅依赖于单一的通用反馈来源，无法解决语言模型生成的推理链中的多样错误类型。在这项工作中，我们提出了多方面反馈，这是一个集成了多个反馈模块的迭代优化框架，其中包括冻结的语言模型和外部工具，每个模块都专注于特定的错误类别。我们的实验证明了我们的方法在解决语言模型生成的推理链中的几个错误方面的有效性，从而改善了语言模型在几个推理任务中的整体性能。我们看到了在数学推理任务中相对提升了多达20%。",
    "tldr": "本研究提出了一种多方面反馈的迭代优化框架，该框架包括冻结的语言模型和外部工具模块，每个模块都专注于特定的错误类型。实验证明该方法改善了大型语言模型在推理任务中的性能，相对提升了多达20%。",
    "en_tdlr": "This study proposes an iterative refinement framework called Multi-Aspect Feedback, which integrates multiple feedback modules including frozen language models and external tools, each focusing on a specific error category. Experimental results demonstrate the efficacy of this approach in improving the performance of large language models in reasoning tasks, with a relative improvement of up to 20%."
}