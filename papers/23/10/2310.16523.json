{
    "title": "Improving Diversity of Demographic Representation in Large Language Models via Collective-Critiques and Self-Voting. (arXiv:2310.16523v1 [cs.CL])",
    "abstract": "A crucial challenge for generative large language models (LLMs) is diversity: when a user's prompt is under-specified, models may follow implicit assumptions while generating a response, which may result in homogenization of the responses, as well as certain demographic groups being under-represented or even erased from the generated responses. In this paper, we formalize diversity of representation in generative LLMs. We present evaluation datasets and propose metrics to measure diversity in generated responses along people and culture axes. We find that LLMs understand the notion of diversity, and that they can reason and critique their own responses for that goal. This finding motivated a new prompting technique called collective-critique and self-voting (CCSV) to self-improve people diversity of LLMs by tapping into its diversity reasoning capabilities, without relying on handcrafted examples or prompt tuning. Extensive empirical experiments with both human and automated evaluation",
    "link": "http://arxiv.org/abs/2310.16523",
    "context": "Title: Improving Diversity of Demographic Representation in Large Language Models via Collective-Critiques and Self-Voting. (arXiv:2310.16523v1 [cs.CL])\nAbstract: A crucial challenge for generative large language models (LLMs) is diversity: when a user's prompt is under-specified, models may follow implicit assumptions while generating a response, which may result in homogenization of the responses, as well as certain demographic groups being under-represented or even erased from the generated responses. In this paper, we formalize diversity of representation in generative LLMs. We present evaluation datasets and propose metrics to measure diversity in generated responses along people and culture axes. We find that LLMs understand the notion of diversity, and that they can reason and critique their own responses for that goal. This finding motivated a new prompting technique called collective-critique and self-voting (CCSV) to self-improve people diversity of LLMs by tapping into its diversity reasoning capabilities, without relying on handcrafted examples or prompt tuning. Extensive empirical experiments with both human and automated evaluation",
    "path": "papers/23/10/2310.16523.json",
    "total_tokens": 917,
    "translated_title": "通过集体批评和自我投票改善大型语言模型中的人口多样性",
    "translated_abstract": "对于生成式大型语言模型（LLMs）来说，多样性是一个重要挑战：当用户的提示不明确时，模型可能会在生成响应时遵循隐含假设，这可能导致响应的同质化，以及某些人口群体的代表性不足甚至消失在生成的响应中。本文规范了生成式LLMs中的多样性表示。我们提出了评估数据集，并提出了衡量在人和文化方向上生成响应多样性的度量指标。我们发现LLMs理解多样性的概念，并且它们可以对自己的响应进行推理和批评以实现这个目标。这一发现激发了一种名为集体批评和自我投票(CCSC)的新提示技术，通过利用它的多样性推理能力来提高LLMs的人口多样性，而不依赖于手工制作的示例或提示调整。通过人类和自动化评估进行了广泛的实证实验。",
    "tldr": "本文研究了生成式大型语言模型中的人口多样性挑战，并提出了一种新的提示技术CCSV，通过利用模型的多样性推理能力来改善人口多样性，而无需依赖手工制作的示例或提示调整。",
    "en_tdlr": "This paper addresses the challenge of demographic diversity in generative large language models (LLMs) and proposes a new prompting technique called CCSV to improve diversity by leveraging the model's diversity reasoning capabilities, without relying on handcrafted examples or prompt tuning."
}