{
    "title": "MCAD: Multi-teacher Cross-modal Alignment Distillation for efficient image-text retrieval",
    "abstract": "arXiv:2310.19654v2 Announce Type: replace-cross  Abstract: Due to the success of large-scale visual-language pretraining (VLP) models and the widespread use of image-text retrieval in industry areas, it is now critically necessary to reduce the model size and streamline their mobile-device deployment. Single- and dual-stream model structures are commonly used in image-text retrieval with the goal of closing the semantic gap between textual and visual modalities. While single-stream models use deep feature fusion to achieve more accurate cross-model alignment, dual-stream models are better at offline indexing and fast inference.We propose a Multi-teacher Cross-modality Alignment Distillation (MCAD) technique to integrate the advantages of single- and dual-stream models. By incorporating the fused single-stream features into the image and text features of the dual-stream model, we formulate new modified teacher similarity distributions and features. Then, we conduct both distribution and",
    "link": "https://arxiv.org/abs/2310.19654",
    "context": "Title: MCAD: Multi-teacher Cross-modal Alignment Distillation for efficient image-text retrieval\nAbstract: arXiv:2310.19654v2 Announce Type: replace-cross  Abstract: Due to the success of large-scale visual-language pretraining (VLP) models and the widespread use of image-text retrieval in industry areas, it is now critically necessary to reduce the model size and streamline their mobile-device deployment. Single- and dual-stream model structures are commonly used in image-text retrieval with the goal of closing the semantic gap between textual and visual modalities. While single-stream models use deep feature fusion to achieve more accurate cross-model alignment, dual-stream models are better at offline indexing and fast inference.We propose a Multi-teacher Cross-modality Alignment Distillation (MCAD) technique to integrate the advantages of single- and dual-stream models. By incorporating the fused single-stream features into the image and text features of the dual-stream model, we formulate new modified teacher similarity distributions and features. Then, we conduct both distribution and",
    "path": "papers/23/10/2310.19654.json",
    "total_tokens": 878,
    "translated_title": "MCAD: 多教师跨模态对齐蒸馏用于高效图像-文本检索",
    "translated_abstract": "由于大规模视觉-语言预训练（VLP）模型的成功以及图像-文本检索在工业领域的广泛应用，现在迫切需要减小模型大小并简化它们在移动设备上的部署。 图像-文本检索中通常使用单流和双流模型结构，目的是缩小文本和视觉模态之间的语义差距。 虽然单流模型使用深度特征融合实现更准确的跨模态对齐，但双流模型更适用于离线索引和快速推理。我们提出了一种多教师跨模态对齐蒸馏（MCAD）技术，以整合单流和双流模型的优点。 通过将融合的单流特征合并到双流模型的图像和文本特征中，我们构建了新的修改后的教师相似性分布和特征。 然后，我们进行了分布",
    "tldr": "提出了一种Multi-teacher Cross-modality Alignment Distillation（MCAD）技术，通过将融合的单流特征合并到双流模型的图像和文本特征中，以整合单流和双流模型的优点。",
    "en_tdlr": "Introduced a Multi-teacher Cross-modality Alignment Distillation (MCAD) technique that integrates the advantages of single- and dual-stream models by incorporating the fused single-stream features into the image and text features of the dual-stream model."
}