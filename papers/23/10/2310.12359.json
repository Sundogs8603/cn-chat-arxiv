{
    "title": "MARVEL: Multi-Agent Reinforcement-Learning for Large-Scale Variable Speed Limits. (arXiv:2310.12359v1 [cs.MA])",
    "abstract": "Variable speed limit (VSL) control is a promising traffic management strategy for enhancing safety and mobility. This work introduces MARVEL, a multi-agent reinforcement learning (MARL) framework for implementing large-scale VSL control on freeway corridors using only commonly available data. The agents learn through a reward structure that incorporates adaptability to traffic conditions, safety, and mobility; enabling coordination among the agents. The proposed framework scales to cover corridors with many gantries thanks to a parameter sharing among all VSL agents. The agents are trained in a microsimulation environment based on a short freeway stretch with 8 gantries spanning 7 miles and tested with 34 gantries spanning 17 miles of I-24 near Nashville, TN. MARVEL improves traffic safety by 63.4% compared to the no control scenario and enhances traffic mobility by 14.6% compared to a state-of-the-practice algorithm that has been deployed on I-24. An explainability analysis is underta",
    "link": "http://arxiv.org/abs/2310.12359",
    "context": "Title: MARVEL: Multi-Agent Reinforcement-Learning for Large-Scale Variable Speed Limits. (arXiv:2310.12359v1 [cs.MA])\nAbstract: Variable speed limit (VSL) control is a promising traffic management strategy for enhancing safety and mobility. This work introduces MARVEL, a multi-agent reinforcement learning (MARL) framework for implementing large-scale VSL control on freeway corridors using only commonly available data. The agents learn through a reward structure that incorporates adaptability to traffic conditions, safety, and mobility; enabling coordination among the agents. The proposed framework scales to cover corridors with many gantries thanks to a parameter sharing among all VSL agents. The agents are trained in a microsimulation environment based on a short freeway stretch with 8 gantries spanning 7 miles and tested with 34 gantries spanning 17 miles of I-24 near Nashville, TN. MARVEL improves traffic safety by 63.4% compared to the no control scenario and enhances traffic mobility by 14.6% compared to a state-of-the-practice algorithm that has been deployed on I-24. An explainability analysis is underta",
    "path": "papers/23/10/2310.12359.json",
    "total_tokens": 1026,
    "translated_title": "MARVEL: 用于大规模可变速限的多智能体强化学习",
    "translated_abstract": "可变速限（VSL）控制是一种提高安全性和流动性的有前途的交通管理策略。本工作介绍了MARVEL，这是一个使用仅有常见可用数据实现高速公路走廊大规模VSL控制的多智能体强化学习（MARL）框架。智能体通过包括对交通状况的适应性、安全性和流动性在内的奖励结构进行学习，实现了智能体之间的协调。该框架通过在所有VSL智能体之间共享参数，可以扩展到包括许多立柱的走廊。智能体在一个基于一个短的高速公路路段的微仿真环境中进行训练，该路段有8个立柱，跨越7英里，并在纳什维尔附近的I-24上有34个立柱，跨越17英里进行测试。与无控制情况相比，MARVEL将交通安全性提高了63.4%，并将交通流动性提高了14.6%，与已在I-24上部署的最新算法相比。进行了一项可解释性分析。",
    "tldr": "MARVEL是一个多智能体强化学习框架，可以实现利用常见数据在高速公路走廊上进行大规模可变速限控制。它通过奖励结构和智能体之间的协调，提高交通安全性和流动性。与无控制情况相比，MARVEL可以提高交通安全性63.4%，提高交通流动性14.6%。",
    "en_tdlr": "MARVEL is a multi-agent reinforcement learning framework that implements large-scale variable speed limit (VSL) control on freeway corridors using commonly available data. It improves traffic safety and mobility through a reward structure and coordination among agents. Compared to no control, MARVEL increases traffic safety by 63.4% and enhances traffic mobility by 14.6%."
}