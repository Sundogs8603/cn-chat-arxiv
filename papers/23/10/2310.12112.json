{
    "title": "A Cautionary Tale: On the Role of Reference Data in Empirical Privacy Defenses. (arXiv:2310.12112v1 [cs.CR])",
    "abstract": "Within the realm of privacy-preserving machine learning, empirical privacy defenses have been proposed as a solution to achieve satisfactory levels of training data privacy without a significant drop in model utility. Most existing defenses against membership inference attacks assume access to reference data, defined as an additional dataset coming from the same (or a similar) underlying distribution as training data. Despite the common use of reference data, previous works are notably reticent about defining and evaluating reference data privacy. As gains in model utility and/or training data privacy may come at the expense of reference data privacy, it is essential that all three aspects are duly considered. In this paper, we first examine the availability of reference data and its privacy treatment in previous works and demonstrate its necessity for fairly comparing defenses. Second, we propose a baseline defense that enables the utility-privacy tradeoff with respect to both trainin",
    "link": "http://arxiv.org/abs/2310.12112",
    "context": "Title: A Cautionary Tale: On the Role of Reference Data in Empirical Privacy Defenses. (arXiv:2310.12112v1 [cs.CR])\nAbstract: Within the realm of privacy-preserving machine learning, empirical privacy defenses have been proposed as a solution to achieve satisfactory levels of training data privacy without a significant drop in model utility. Most existing defenses against membership inference attacks assume access to reference data, defined as an additional dataset coming from the same (or a similar) underlying distribution as training data. Despite the common use of reference data, previous works are notably reticent about defining and evaluating reference data privacy. As gains in model utility and/or training data privacy may come at the expense of reference data privacy, it is essential that all three aspects are duly considered. In this paper, we first examine the availability of reference data and its privacy treatment in previous works and demonstrate its necessity for fairly comparing defenses. Second, we propose a baseline defense that enables the utility-privacy tradeoff with respect to both trainin",
    "path": "papers/23/10/2310.12112.json",
    "total_tokens": 915,
    "translated_title": "一则警示故事：关于参考数据在实证隐私防御中的作用",
    "translated_abstract": "在隐私保护机器学习领域，已经提出了实证隐私防御作为一种解决方案，以实现在不显著降低模型效用的情况下，达到令人满意的训练数据隐私水平。大多数现有的防御成员推理攻击的方法假设可以访问参考数据，参考数据指的是来自训练数据相同（或类似）基础分布的附加数据集。尽管参考数据的使用很普遍，但之前的研究对于定义和评估参考数据隐私相当保守。由于模型效用和/或训练数据隐私的提升可能以牺牲参考数据隐私为代价，因此需要充分考虑这三个方面。在本文中，我们首先研究了之前的作品中参考数据的可用性及其隐私处理情况，并证明了对于公平比较防御方法来说参考数据的必要性。其次，我们提出了一种基准防御方法，它可以在模型效用和训练数据隐私之间进行权衡。",
    "tldr": "本文研究了实证隐私防御中参考数据的作用和隐私问题，提出了一种基准防御方法，实现了模型效用和训练数据隐私的权衡。",
    "en_tdlr": "This paper examines the role and privacy concerns of reference data in empirical privacy defenses, and proposes a baseline defense method that achieves a tradeoff between model utility and training data privacy."
}