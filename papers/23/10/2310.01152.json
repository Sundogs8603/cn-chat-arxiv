{
    "title": "Large Language Model-Powered Smart Contract Vulnerability Detection: New Perspectives. (arXiv:2310.01152v2 [cs.CR] UPDATED)",
    "abstract": "This paper provides a systematic analysis of the opportunities, challenges, and potential solutions of harnessing Large Language Models (LLMs) such as GPT-4 to dig out vulnerabilities within smart contracts based on our ongoing research. For the task of smart contract vulnerability detection, achieving practical usability hinges on identifying as many true vulnerabilities as possible while minimizing the number of false positives. Nonetheless, our empirical study reveals contradictory yet interesting findings: generating more answers with higher randomness largely boosts the likelihood of producing a correct answer but inevitably leads to a higher number of false positives. To mitigate this tension, we propose an adversarial framework dubbed GPTLens that breaks the conventional one-stage detection into two synergistic stages $-$ generation and discrimination, for progressive detection and refinement, wherein the LLM plays dual roles, i.e., auditor and critic, respectively. The goal of ",
    "link": "http://arxiv.org/abs/2310.01152",
    "context": "Title: Large Language Model-Powered Smart Contract Vulnerability Detection: New Perspectives. (arXiv:2310.01152v2 [cs.CR] UPDATED)\nAbstract: This paper provides a systematic analysis of the opportunities, challenges, and potential solutions of harnessing Large Language Models (LLMs) such as GPT-4 to dig out vulnerabilities within smart contracts based on our ongoing research. For the task of smart contract vulnerability detection, achieving practical usability hinges on identifying as many true vulnerabilities as possible while minimizing the number of false positives. Nonetheless, our empirical study reveals contradictory yet interesting findings: generating more answers with higher randomness largely boosts the likelihood of producing a correct answer but inevitably leads to a higher number of false positives. To mitigate this tension, we propose an adversarial framework dubbed GPTLens that breaks the conventional one-stage detection into two synergistic stages $-$ generation and discrimination, for progressive detection and refinement, wherein the LLM plays dual roles, i.e., auditor and critic, respectively. The goal of ",
    "path": "papers/23/10/2310.01152.json",
    "total_tokens": 899,
    "translated_title": "大型语言模型驱动的智能合约漏洞检测：新的视角",
    "translated_abstract": "本文对利用大型语言模型（LLMs）如GPT-4挖掘智能合约中的漏洞的机会、挑战和潜在解决方案进行了系统分析，基于我们现有的研究。对于智能合约漏洞检测任务，实现实用性取决于尽可能识别出更多的真实漏洞同时最小化误报数目。然而，我们的实证研究揭示了矛盾但有趣的发现：生成更多的答案且更具随机性很大程度上提高了产生正确答案的可能性，但同时也导致了更多的误报。为了缓解这种紧张关系，我们提出了一种对抗性框架 GPTLens，将传统的单阶段检测分为两个协同的阶段——生成和区分，用于逐步的检测和改进，其中LLM分别扮演着评审员和评论家的双重角色。",
    "tldr": "本研究通过利用大型语言模型（如GPT-4）来发现智能合约中的漏洞，并提出了一种名为GPTLens的对抗性框架，通过分两个阶段来逐步检测和改进漏洞检测，同时最大限度地减少误报。"
}