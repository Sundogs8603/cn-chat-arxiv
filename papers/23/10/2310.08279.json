{
    "title": "CP-KGC: Constrained-Prompt Knowledge Graph Completion with Large Language Models. (arXiv:2310.08279v1 [cs.CL])",
    "abstract": "Knowledge graph completion (KGC) aims to utilize existing knowledge to deduce and infer missing connections within knowledge graphs. Text-based approaches, like SimKGC, have outperformed graph embedding methods, showcasing the promise of inductive KGC. However, the efficacy of text-based methods hinges on the quality of entity textual descriptions. In this paper, we identify the key issue of whether large language models (LLMs) can generate effective text. To mitigate hallucination in LLM-generated text in this paper, we introduce a constraint-based prompt that utilizes the entity and its textual description as contextual constraints to enhance data quality. Our Constrained-Prompt Knowledge Graph Completion (CP-KGC) method demonstrates effective inference under low resource computing conditions and surpasses prior results on the WN18RR and FB15K237 datasets. This showcases the integration of LLMs in KGC tasks and provides new directions for future research.",
    "link": "http://arxiv.org/abs/2310.08279",
    "context": "Title: CP-KGC: Constrained-Prompt Knowledge Graph Completion with Large Language Models. (arXiv:2310.08279v1 [cs.CL])\nAbstract: Knowledge graph completion (KGC) aims to utilize existing knowledge to deduce and infer missing connections within knowledge graphs. Text-based approaches, like SimKGC, have outperformed graph embedding methods, showcasing the promise of inductive KGC. However, the efficacy of text-based methods hinges on the quality of entity textual descriptions. In this paper, we identify the key issue of whether large language models (LLMs) can generate effective text. To mitigate hallucination in LLM-generated text in this paper, we introduce a constraint-based prompt that utilizes the entity and its textual description as contextual constraints to enhance data quality. Our Constrained-Prompt Knowledge Graph Completion (CP-KGC) method demonstrates effective inference under low resource computing conditions and surpasses prior results on the WN18RR and FB15K237 datasets. This showcases the integration of LLMs in KGC tasks and provides new directions for future research.",
    "path": "papers/23/10/2310.08279.json",
    "total_tokens": 850,
    "translated_title": "CP-KGC: 利用大型语言模型的约束式提示对知识图谱进行补全",
    "translated_abstract": "知识图谱补全旨在利用现有知识推断和推测知识图谱中缺失的连接。SimKGC等基于文本的方法已经超过了图嵌入方法，展示了归纳式知识图谱补全的潜力。然而，基于文本的方法的效果取决于实体文本描述的质量。为了减轻LLM生成的文本中的幻觉，在本文中，我们引入了一种基于约束的提示方法，利用实体及其文本描述作为上下文约束来提高数据质量。我们的约束式提示知识图谱补全方法（CP-KGC）在低资源计算条件下表现出有效的推断能力，并超过了WN18RR和FB15K237数据集上的之前结果。这展示了LLMs在知识图谱补全任务中的整合，并为未来的研究提供了新的方向。",
    "tldr": "CP-KGC方法利用大型语言模型，通过约束式提示来补全知识图谱，提高推断效果，展示了在低资源计算条件下的有效性，并在数据集上取得了优于之前方法的结果。",
    "en_tdlr": "The CP-KGC method utilizes large language models and constraint-based prompts to complete knowledge graphs, enhancing inference efficiency. It demonstrates effectiveness under low resource computing conditions and outperforms previous methods on benchmark datasets."
}