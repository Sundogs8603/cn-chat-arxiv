{
    "title": "An Ensemble Method Based on the Combination of Transformers with Convolutional Neural Networks to Detect Artificially Generated Text. (arXiv:2310.17312v1 [cs.CL])",
    "abstract": "Thanks to the state-of-the-art Large Language Models (LLMs), language generation has reached outstanding levels. These models are capable of generating high quality content, thus making it a challenging task to detect generated text from human-written content. Despite the advantages provided by Natural Language Generation, the inability to distinguish automatically generated text can raise ethical concerns in terms of authenticity. Consequently, it is important to design and develop methodologies to detect artificial content. In our work, we present some classification models constructed by ensembling transformer models such as Sci-BERT, DeBERTa and XLNet, with Convolutional Neural Networks (CNNs). Our experiments demonstrate that the considered ensemble architectures surpass the performance of the individual transformer models for classification. Furthermore, the proposed SciBERT-CNN ensemble model produced an F1-score of 98.36% on the ALTA shared task 2023 data.",
    "link": "http://arxiv.org/abs/2310.17312",
    "context": "Title: An Ensemble Method Based on the Combination of Transformers with Convolutional Neural Networks to Detect Artificially Generated Text. (arXiv:2310.17312v1 [cs.CL])\nAbstract: Thanks to the state-of-the-art Large Language Models (LLMs), language generation has reached outstanding levels. These models are capable of generating high quality content, thus making it a challenging task to detect generated text from human-written content. Despite the advantages provided by Natural Language Generation, the inability to distinguish automatically generated text can raise ethical concerns in terms of authenticity. Consequently, it is important to design and develop methodologies to detect artificial content. In our work, we present some classification models constructed by ensembling transformer models such as Sci-BERT, DeBERTa and XLNet, with Convolutional Neural Networks (CNNs). Our experiments demonstrate that the considered ensemble architectures surpass the performance of the individual transformer models for classification. Furthermore, the proposed SciBERT-CNN ensemble model produced an F1-score of 98.36% on the ALTA shared task 2023 data.",
    "path": "papers/23/10/2310.17312.json",
    "total_tokens": 915,
    "translated_title": "基于Transformer和卷积神经网络的集成方法用于检测人工生成的文本",
    "translated_abstract": "随着最先进的大型语言模型（LLM），语言生成已经达到了卓越的水平。这些模型能够生成高质量的内容，因此从人工撰写的内容中检测生成文本变成了一个具有挑战性的任务。尽管自然语言生成提供了诸多优势，但无法区分自动生成的文本可能会引发关于真实性的道德顾虑。因此，设计和开发检测人工内容的方法非常重要。在我们的工作中，我们提出了一些通过集成Transformer模型（如Sci-BERT、DeBERTa和XLNet）与卷积神经网络（CNN）构建的分类模型。我们的实验表明，考虑的集成架构在分类任务上超越了单个Transformer模型的表现。此外，提出的SciBERT-CNN集成模型在ALTA共享任务2023数据上得到了98.36%的F1得分。",
    "tldr": "这项研究提出了一种基于Transformer和卷积神经网络的集成方法，用于检测人工生成的文本。实验结果表明，这种集成架构在分类任务上的性能超过了单个Transformer模型，而提出的SciBERT-CNN集成模型在ALTA共享任务2023数据上取得了98.36%的F1得分。"
}