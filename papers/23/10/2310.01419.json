{
    "title": "Design Principles of Robust Multi-Armed Bandit Framework in Video Recommendations. (arXiv:2310.01419v1 [cs.IR])",
    "abstract": "Current multi-armed bandit approaches in recommender systems (RS) have focused more on devising effective exploration techniques, while not adequately addressing common exploitation challenges related to distributional changes and item cannibalization. Little work exists to guide the design of robust bandit frameworks that can address these frequent challenges in RS. In this paper, we propose a new design principles to (i) make bandit models robust to time-variant metadata signals, (ii) less prone to item cannibalization, and (iii) prevent their weights fluctuating due to data sparsity. Through a series of experiments, we systematically examine the influence of several important bandit design choices. We demonstrate the advantage of our proposed design principles at making bandit models robust to dynamic behavioral changes through in-depth analyses. Noticeably, we show improved relative gain compared to a baseline bandit model not incorporating our design choices of up to $11.88\\%$ and",
    "link": "http://arxiv.org/abs/2310.01419",
    "context": "Title: Design Principles of Robust Multi-Armed Bandit Framework in Video Recommendations. (arXiv:2310.01419v1 [cs.IR])\nAbstract: Current multi-armed bandit approaches in recommender systems (RS) have focused more on devising effective exploration techniques, while not adequately addressing common exploitation challenges related to distributional changes and item cannibalization. Little work exists to guide the design of robust bandit frameworks that can address these frequent challenges in RS. In this paper, we propose a new design principles to (i) make bandit models robust to time-variant metadata signals, (ii) less prone to item cannibalization, and (iii) prevent their weights fluctuating due to data sparsity. Through a series of experiments, we systematically examine the influence of several important bandit design choices. We demonstrate the advantage of our proposed design principles at making bandit models robust to dynamic behavioral changes through in-depth analyses. Noticeably, we show improved relative gain compared to a baseline bandit model not incorporating our design choices of up to $11.88\\%$ and",
    "path": "papers/23/10/2310.01419.json",
    "total_tokens": 884,
    "translated_title": "视频推荐中鲁棒多臂赌博框架的设计原则",
    "translated_abstract": "目前推荐系统中的多臂赌博方法更多关注有效的探索技术，而没有充分解决与分布变化和项目竞争相关的常见利用挑战。很少有工作指导设计能够解决推荐系统中这些频繁挑战的鲁棒赌博框架。在本文中，我们提出了一种新的设计原则，以使赌博模型对时变元数据信号鲁棒，对项目竞争少有影响，并防止由于数据稀疏性而导致权重波动。通过一系列实验，我们系统地研究了几个重要的赌博设计选择的影响。我们通过深入分析展示了我们提出的设计原则在使赌博模型对动态行为变化鲁棒方面的优势。值得注意的是，相对于不采用我们设计选择的基线赌博模型，我们展示了高达11.88％的改进相对收益。",
    "tldr": "本文提出了一种鲁棒多臂赌博框架的设计原则，以解决推荐系统中的利用挑战和分布变化问题，并通过实验证明了其相对收益提升。",
    "en_tdlr": "This paper proposes design principles for a robust multi-armed bandit framework to address exploitation challenges and distributional changes in recommender systems, and demonstrates improved relative gain through experiments."
}