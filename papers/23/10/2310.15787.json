{
    "title": "SequenceMatch: Revisiting the design of weak-strong augmentations for Semi-supervised learning. (arXiv:2310.15787v1 [cs.CV])",
    "abstract": "Semi-supervised learning (SSL) has become popular in recent years because it allows the training of a model using a large amount of unlabeled data. However, one issue that many SSL methods face is the confirmation bias, which occurs when the model is overfitted to the small labeled training dataset and produces overconfident, incorrect predictions. To address this issue, we propose SequenceMatch, an efficient SSL method that utilizes multiple data augmentations. The key element of SequenceMatch is the inclusion of a medium augmentation for unlabeled data. By taking advantage of different augmentations and the consistency constraints between each pair of augmented examples, SequenceMatch helps reduce the divergence between the prediction distribution of the model for weakly and strongly augmented examples. In addition, SequenceMatch defines two different consistency constraints for high and low-confidence predictions. As a result, SequenceMatch is more data-efficient than ReMixMatch, an",
    "link": "http://arxiv.org/abs/2310.15787",
    "context": "Title: SequenceMatch: Revisiting the design of weak-strong augmentations for Semi-supervised learning. (arXiv:2310.15787v1 [cs.CV])\nAbstract: Semi-supervised learning (SSL) has become popular in recent years because it allows the training of a model using a large amount of unlabeled data. However, one issue that many SSL methods face is the confirmation bias, which occurs when the model is overfitted to the small labeled training dataset and produces overconfident, incorrect predictions. To address this issue, we propose SequenceMatch, an efficient SSL method that utilizes multiple data augmentations. The key element of SequenceMatch is the inclusion of a medium augmentation for unlabeled data. By taking advantage of different augmentations and the consistency constraints between each pair of augmented examples, SequenceMatch helps reduce the divergence between the prediction distribution of the model for weakly and strongly augmented examples. In addition, SequenceMatch defines two different consistency constraints for high and low-confidence predictions. As a result, SequenceMatch is more data-efficient than ReMixMatch, an",
    "path": "papers/23/10/2310.15787.json",
    "total_tokens": 859,
    "translated_title": "SequenceMatch: 重新考虑强弱增强设计的半监督学习方法",
    "translated_abstract": "近年来，半监督学习（SSL）因其可以利用大量未标记数据进行模型训练而变得流行。然而，许多SSL方法面临的一个问题是确认偏差，即当模型过度拟合小型标记训练数据集并产生自信但错误的预测时。为了解决这个问题，我们提出了SequenceMatch，一种高效的SSL方法，它利用多种数据增强方法。SequenceMatch的关键是为未标记的数据引入了中等增强方法。通过利用不同的增强方法和每对增强示例之间的一致性约束，SequenceMatch帮助缩小了模型对弱增强和强增强示例的预测分布之间的差异。此外，SequenceMatch为高置信度和低置信度的预测定义了两种不同的一致性约束。因此，SequenceMatch比ReMixMatch更具数据效率。",
    "tldr": "SequenceMatch是一种半监督学习方法，通过引入中等增强方法和不同的一致性约束，帮助减小了模型对弱增强和强增强示例的预测分布之间的差异，提高了数据效率。",
    "en_tdlr": "SequenceMatch is a semi-supervised learning method that improves data efficiency by introducing medium augmentations and different consistency constraints to reduce the divergence between the prediction distribution of the model for weakly and strongly augmented examples."
}