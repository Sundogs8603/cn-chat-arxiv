{
    "title": "Nugget: Neural Agglomerative Embeddings of Text. (arXiv:2310.01732v1 [cs.CL])",
    "abstract": "Embedding text sequences is a widespread requirement in modern language understanding. Existing approaches focus largely on constant-size representations. This is problematic, as the amount of information contained in text often varies with the length of the input. We propose a solution called Nugget, which encodes language into a representation based on a dynamically selected subset of input tokens. These nuggets are learned through tasks like autoencoding and machine translation, and intuitively segment language into meaningful units. We demonstrate Nugget outperforms related approaches in tasks involving semantic comparison. Finally, we illustrate these compact units allow for expanding the contextual window of a language model (LM), suggesting new future LMs that can condition on significantly larger amounts of content.",
    "link": "http://arxiv.org/abs/2310.01732",
    "context": "Title: Nugget: Neural Agglomerative Embeddings of Text. (arXiv:2310.01732v1 [cs.CL])\nAbstract: Embedding text sequences is a widespread requirement in modern language understanding. Existing approaches focus largely on constant-size representations. This is problematic, as the amount of information contained in text often varies with the length of the input. We propose a solution called Nugget, which encodes language into a representation based on a dynamically selected subset of input tokens. These nuggets are learned through tasks like autoencoding and machine translation, and intuitively segment language into meaningful units. We demonstrate Nugget outperforms related approaches in tasks involving semantic comparison. Finally, we illustrate these compact units allow for expanding the contextual window of a language model (LM), suggesting new future LMs that can condition on significantly larger amounts of content.",
    "path": "papers/23/10/2310.01732.json",
    "total_tokens": 801,
    "translated_title": "Nugget: 文本的神经聚合嵌入",
    "translated_abstract": "在现代语言理解中，嵌入文本序列是一个广泛需求。现有方法主要侧重于恒定大小的表示。这是有问题的，因为文本中包含的信息量通常随输入的长度而变化。我们提出了一种称为Nugget的解决方案，它将语言编码为基于动态选择的输入令牌子集的表示。通过自编码和机器翻译等任务，学习这些nuggets，并直观地将语言分割成有意义的单元。我们展示了Nugget在涉及语义比较的任务中优于相关方法。最后，我们证明了这些紧凑单元允许扩展语言模型(LM)的上下文窗口，从而提出了新的LM可能会对更大量的内容进行条件处理。",
    "tldr": "Nugget是一种基于动态选择的输入令牌子集的文本嵌入方法，通过自编码和机器翻译等任务，将语言分割为有意义的单元，优于相关方法，在语义比较任务中表现出色，并且允许扩展语言模型的上下文窗口。"
}