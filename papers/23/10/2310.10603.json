{
    "title": "Exploring the Power of Graph Neural Networks in Solving Linear Optimization Problems. (arXiv:2310.10603v1 [cs.LG])",
    "abstract": "Recently, machine learning, particularly message-passing graph neural networks (MPNNs), has gained traction in enhancing exact optimization algorithms. For example, MPNNs speed up solving mixed-integer optimization problems by imitating computational intensive heuristics like strong branching, which entails solving multiple linear optimization problems (LPs). Despite the empirical success, the reasons behind MPNNs' effectiveness in emulating linear optimization remain largely unclear. Here, we show that MPNNs can simulate standard interior-point methods for LPs, explaining their practical success. Furthermore, we highlight how MPNNs can serve as a lightweight proxy for solving LPs, adapting to a given problem instance distribution. Empirically, we show that MPNNs solve LP relaxations of standard combinatorial optimization problems close to optimality, often surpassing conventional solvers and competing approaches in solving time.",
    "link": "http://arxiv.org/abs/2310.10603",
    "context": "Title: Exploring the Power of Graph Neural Networks in Solving Linear Optimization Problems. (arXiv:2310.10603v1 [cs.LG])\nAbstract: Recently, machine learning, particularly message-passing graph neural networks (MPNNs), has gained traction in enhancing exact optimization algorithms. For example, MPNNs speed up solving mixed-integer optimization problems by imitating computational intensive heuristics like strong branching, which entails solving multiple linear optimization problems (LPs). Despite the empirical success, the reasons behind MPNNs' effectiveness in emulating linear optimization remain largely unclear. Here, we show that MPNNs can simulate standard interior-point methods for LPs, explaining their practical success. Furthermore, we highlight how MPNNs can serve as a lightweight proxy for solving LPs, adapting to a given problem instance distribution. Empirically, we show that MPNNs solve LP relaxations of standard combinatorial optimization problems close to optimality, often surpassing conventional solvers and competing approaches in solving time.",
    "path": "papers/23/10/2310.10603.json",
    "total_tokens": 844,
    "translated_title": "探索图神经网络在解决线性优化问题中的威力",
    "translated_abstract": "最近，机器学习特别是消息传递图神经网络（MPNNs）在增强精确优化算法方面已经引起了关注。例如，MPNNs通过模拟计算密集型启发式方法如强支分支加速解决混合整数优化问题，这需要解决多个线性优化问题（LPs）。尽管有实证成功，但MPNNs在模拟线性优化方面的有效性的原因仍然不清楚。在这里，我们展示了MPNNs可以模拟LPs的标准内点法，解释了它们在实践中的成功。此外，我们强调了MPNNs如何作为解决LPs的轻量级代理，适应给定的问题实例分布。实证结果表明，MPNNs在接近最优性上解决了标准组合优化问题的LP松弛，通常在解决时间上超过了传统求解器和竞争方法。",
    "tldr": "本研究发现图神经网络（MPNNs）可以模拟标准内点法来解决线性优化问题，并且在解决时间上表现出色，超过了传统求解器和竞争方法。",
    "en_tdlr": "This study finds that graph neural networks (MPNNs) can simulate standard interior-point methods for solving linear optimization problems, and they perform well in terms of solving time, surpassing conventional solvers and competing approaches."
}