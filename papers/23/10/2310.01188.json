{
    "title": "Quantifying the Plausibility of Context Reliance in Neural Machine Translation",
    "abstract": "arXiv:2310.01188v2 Announce Type: replace-cross  Abstract: Establishing whether language models can use contextual information in a human-plausible way is important to ensure their trustworthiness in real-world settings. However, the questions of when and which parts of the context affect model generations are typically tackled separately, with current plausibility evaluations being practically limited to a handful of artificial benchmarks. To address this, we introduce Plausibility Evaluation of Context Reliance (PECoRe), an end-to-end interpretability framework designed to quantify context usage in language models' generations. Our approach leverages model internals to (i) contrastively identify context-sensitive target tokens in generated texts and (ii) link them to contextual cues justifying their prediction. We use \\pecore to quantify the plausibility of context-aware machine translation models, comparing model rationales with human annotations across several discourse-level pheno",
    "link": "https://arxiv.org/abs/2310.01188",
    "context": "Title: Quantifying the Plausibility of Context Reliance in Neural Machine Translation\nAbstract: arXiv:2310.01188v2 Announce Type: replace-cross  Abstract: Establishing whether language models can use contextual information in a human-plausible way is important to ensure their trustworthiness in real-world settings. However, the questions of when and which parts of the context affect model generations are typically tackled separately, with current plausibility evaluations being practically limited to a handful of artificial benchmarks. To address this, we introduce Plausibility Evaluation of Context Reliance (PECoRe), an end-to-end interpretability framework designed to quantify context usage in language models' generations. Our approach leverages model internals to (i) contrastively identify context-sensitive target tokens in generated texts and (ii) link them to contextual cues justifying their prediction. We use \\pecore to quantify the plausibility of context-aware machine translation models, comparing model rationales with human annotations across several discourse-level pheno",
    "path": "papers/23/10/2310.01188.json",
    "total_tokens": 704,
    "translated_title": "量化神经机器翻译中背景依赖性的可信度",
    "translated_abstract": "本文介绍了一种名为PECoRe的端到端可解释性框架，旨在量化语言模型生成中上下文使用的情况。我们的方法利用模型内部来对比识别生成文本中上下文敏感的目标令牌，并将它们与证明其预测的上下文线索联系起来。我们使用PECORE来量化具有上下文感知的机器翻译模型的可信度，将模型的理由与人类注释在几个层次的话语水平上进行比较。",
    "tldr": "引入了PECoRe框架，用于量化语言模型生成中的上下文使用情况，从而评估上下文感知机器翻译模型的可信度。",
    "en_tdlr": "Introduced the PECoRe framework to quantify the usage of context in language model generations, aiming to assess the plausibility of context-aware machine translation models."
}