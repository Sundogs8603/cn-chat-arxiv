{
    "title": "VeriDIP: Verifying Ownership of Deep Neural Networks through Privacy Leakage Fingerprints. (arXiv:2310.10656v1 [cs.CR])",
    "abstract": "Deploying Machine Learning as a Service gives rise to model plagiarism, leading to copyright infringement. Ownership testing techniques are designed to identify model fingerprints for verifying plagiarism. However, previous works often rely on overfitting or robustness features as fingerprints, lacking theoretical guarantees and exhibiting under-performance on generalized models. In this paper, we propose a novel ownership testing method called VeriDIP, which verifies a DNN model's intellectual property. VeriDIP makes two major contributions. (1) It utilizes membership inference attacks to estimate the lower bound of privacy leakage, which reflects the fingerprint of a given model. The privacy leakage fingerprints highlight the unique patterns through which the models memorize sensitive training datasets. (2) We introduce a novel approach using less private samples to enhance the performance of ownership testing.  Extensive experimental results confirm that VeriDIP is effective and eff",
    "link": "http://arxiv.org/abs/2310.10656",
    "context": "Title: VeriDIP: Verifying Ownership of Deep Neural Networks through Privacy Leakage Fingerprints. (arXiv:2310.10656v1 [cs.CR])\nAbstract: Deploying Machine Learning as a Service gives rise to model plagiarism, leading to copyright infringement. Ownership testing techniques are designed to identify model fingerprints for verifying plagiarism. However, previous works often rely on overfitting or robustness features as fingerprints, lacking theoretical guarantees and exhibiting under-performance on generalized models. In this paper, we propose a novel ownership testing method called VeriDIP, which verifies a DNN model's intellectual property. VeriDIP makes two major contributions. (1) It utilizes membership inference attacks to estimate the lower bound of privacy leakage, which reflects the fingerprint of a given model. The privacy leakage fingerprints highlight the unique patterns through which the models memorize sensitive training datasets. (2) We introduce a novel approach using less private samples to enhance the performance of ownership testing.  Extensive experimental results confirm that VeriDIP is effective and eff",
    "path": "papers/23/10/2310.10656.json",
    "total_tokens": 866,
    "translated_title": "VeriDIP: 通过隐私泄露指纹验证深度神经网络的所有权",
    "translated_abstract": "部署机器学习作为一项服务会导致模型抄袭，从而导致版权侵权。所有权测试技术旨在识别模型指纹以验证抄袭行为。然而，先前的工作往往依赖于过度拟合或鲁棒性特征作为指纹，缺乏理论保证，并在广义模型上表现出不足的性能。在本文中，我们提出了一种名为VeriDIP的新型所有权测试方法，用于验证DNN模型的知识产权。VeriDIP做出了两个主要贡献。(1)它利用隐私推断攻击来估计隐私泄露的下界，从而反映了给定模型的指纹。隐私泄露指纹突出了模型记忆敏感训练数据集的独特模式。(2)我们引入了一种使用较少私有样本增强所有权测试性能的新方法。大量实验证实了VeriDIP的有效性和效率。",
    "tldr": "VeriDIP是一种新颖的所有权测试方法，通过利用隐私泄露指纹和使用较少私有样本的方法来验证深度神经网络模型的知识产权。",
    "en_tdlr": "VeriDIP is a novel ownership testing method that verifies the intellectual property of deep neural network models through privacy leakage fingerprints and the use of fewer private samples."
}