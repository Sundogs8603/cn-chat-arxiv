{
    "title": "Estimating Shape Distances on Neural Representations with Limited Samples. (arXiv:2310.05742v1 [stat.ML])",
    "abstract": "Measuring geometric similarity between high-dimensional network representations is a topic of longstanding interest to neuroscience and deep learning. Although many methods have been proposed, only a few works have rigorously analyzed their statistical efficiency or quantified estimator uncertainty in data-limited regimes. Here, we derive upper and lower bounds on the worst-case convergence of standard estimators of shape distance$\\unicode{x2014}$a measure of representational dissimilarity proposed by Williams et al. (2021). These bounds reveal the challenging nature of the problem in high-dimensional feature spaces. To overcome these challenges, we introduce a new method-of-moments estimator with a tunable bias-variance tradeoff. We show that this estimator achieves superior performance to standard estimators in simulation and on neural data, particularly in high-dimensional settings. Thus, we lay the foundation for a rigorous statistical theory for high-dimensional shape analysis, an",
    "link": "http://arxiv.org/abs/2310.05742",
    "context": "Title: Estimating Shape Distances on Neural Representations with Limited Samples. (arXiv:2310.05742v1 [stat.ML])\nAbstract: Measuring geometric similarity between high-dimensional network representations is a topic of longstanding interest to neuroscience and deep learning. Although many methods have been proposed, only a few works have rigorously analyzed their statistical efficiency or quantified estimator uncertainty in data-limited regimes. Here, we derive upper and lower bounds on the worst-case convergence of standard estimators of shape distance$\\unicode{x2014}$a measure of representational dissimilarity proposed by Williams et al. (2021). These bounds reveal the challenging nature of the problem in high-dimensional feature spaces. To overcome these challenges, we introduce a new method-of-moments estimator with a tunable bias-variance tradeoff. We show that this estimator achieves superior performance to standard estimators in simulation and on neural data, particularly in high-dimensional settings. Thus, we lay the foundation for a rigorous statistical theory for high-dimensional shape analysis, an",
    "path": "papers/23/10/2310.05742.json",
    "total_tokens": 996,
    "translated_title": "有限采样下神经表示的形状距离估计",
    "translated_abstract": "在神经科学和深度学习领域，衡量高维网络表示之间的几何相似性一直是一个长期的研究兴趣。尽管已经提出了许多方法，但只有少数工作对它们的统计效率进行了严格分析，或者对数据有限情况下的估计器不确定性进行了量化。在这里，我们推导出了标准形状距离估计器（由Williams et al. (2021)提出）的最坏情况收敛上下界。这些界限揭示了在高维特征空间中这个问题的挑战性质。为了克服这些挑战，我们引入了一种新的矩法估计器，具有可调的偏差-方差权衡。我们展示了这个估计器在模拟和神经数据上相对于标准估计器在高维设置下实现了更好的性能。因此，我们为高维形状分析奠定了严格的统计理论基础。",
    "tldr": "本论文研究了在数据有限情况下，对高维神经表示进行形状距离估计的问题。通过推导出对形状距离标准估计器最坏情况下的收敛上下界，我们揭示了这个问题的挑战性质。为了克服挑战，我们引入了一种新的矩法估计器，并展示了其在高维设置下相对于标准估计器的优越性能。",
    "en_tdlr": "This paper investigates the problem of shape distance estimation in the high-dimensional neural representations with limited data. By deriving upper and lower bounds on the worst-case convergence of standard estimators, the challenging nature of the problem is revealed. To overcome these challenges, a new method-of-moments estimator is introduced, and its superior performance compared to standard estimators is demonstrated in high-dimensional settings."
}