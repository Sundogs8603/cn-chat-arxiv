{
    "title": "Fine-Tuning Language Models Using Formal Methods Feedback. (arXiv:2310.18239v1 [cs.AI])",
    "abstract": "Although pre-trained language models encode generic knowledge beneficial for planning and control, they may fail to generate appropriate control policies for domain-specific tasks. Existing fine-tuning methods use human feedback to address this limitation, however, sourcing human feedback is labor intensive and costly. We present a fully automated approach to fine-tune pre-trained language models for applications in autonomous systems, bridging the gap between generic knowledge and domain-specific requirements while reducing cost. The method synthesizes automaton-based controllers from pre-trained models guided by natural language task descriptions. These controllers are verifiable against independently provided specifications within a world model, which can be abstract or obtained from a high-fidelity simulator. Controllers with high compliance with the desired specifications receive higher ranks, guiding the iterative fine-tuning process. We provide quantitative evidences, primarily ",
    "link": "http://arxiv.org/abs/2310.18239",
    "context": "Title: Fine-Tuning Language Models Using Formal Methods Feedback. (arXiv:2310.18239v1 [cs.AI])\nAbstract: Although pre-trained language models encode generic knowledge beneficial for planning and control, they may fail to generate appropriate control policies for domain-specific tasks. Existing fine-tuning methods use human feedback to address this limitation, however, sourcing human feedback is labor intensive and costly. We present a fully automated approach to fine-tune pre-trained language models for applications in autonomous systems, bridging the gap between generic knowledge and domain-specific requirements while reducing cost. The method synthesizes automaton-based controllers from pre-trained models guided by natural language task descriptions. These controllers are verifiable against independently provided specifications within a world model, which can be abstract or obtained from a high-fidelity simulator. Controllers with high compliance with the desired specifications receive higher ranks, guiding the iterative fine-tuning process. We provide quantitative evidences, primarily ",
    "path": "papers/23/10/2310.18239.json",
    "total_tokens": 890,
    "translated_title": "使用形式方法反馈调整语言模型",
    "translated_abstract": "虽然预先训练的语言模型可以编码对规划和控制有益的通用知识，但它们可能无法为特定领域任务生成适当的控制策略。现有的微调方法使用人工反馈来解决这个限制，然而，获取人工反馈是劳动密集型和昂贵的。我们提出了一种全自动的方法，用于微调预先训练的语言模型，应用于自主系统，弥合通用知识与特定领域要求之间的差距，同时降低成本。该方法通过自然语言任务描述来引导从预先训练模型中合成基于自动机的控制器。这些控制器在一个世界模型中与独立提供的规范进行验证，该世界模型可以是抽象的或来自高保真度的模拟器。与期望规范高度一致的控制器获得更高的排名，引导迭代的微调过程。我们提供了定量证据，主要是",
    "tldr": "该论文介绍了一种使用形式方法反馈调整语言模型的自动化方法，用于在自主系统中微调预先训练的模型。通过合成基于自动机的控制器并与给定规范进行验证，该方法可以减少人工反馈的成本并实现领域特定任务的控制策略生成。",
    "en_tdlr": "This paper presents an automated method for fine-tuning language models using formal methods feedback, allowing for the generation of control policies in domain-specific tasks while reducing the need for costly and labor-intensive human feedback."
}