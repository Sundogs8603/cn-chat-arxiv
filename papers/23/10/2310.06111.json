{
    "title": "BYOC: Personalized Few-Shot Classification with Co-Authored Class Descriptions. (arXiv:2310.06111v1 [cs.CL])",
    "abstract": "Text classification is a well-studied and versatile building block for many NLP applications. Yet, existing approaches require either large annotated corpora to train a model with or, when using large language models as a base, require carefully crafting the prompt as well as using a long context that can fit many examples. As a result, it is not possible for end-users to build classifiers for themselves. To address this issue, we propose a novel approach to few-shot text classification using an LLM. Rather than few-shot examples, the LLM is prompted with descriptions of the salient features of each class. These descriptions are coauthored by the user and the LLM interactively: while the user annotates each few-shot example, the LLM asks relevant questions that the user answers. Examples, questions, and answers are summarized to form the classification prompt. Our experiments show that our approach yields high accuracy classifiers, within 82% of the performance of models trained with s",
    "link": "http://arxiv.org/abs/2310.06111",
    "context": "Title: BYOC: Personalized Few-Shot Classification with Co-Authored Class Descriptions. (arXiv:2310.06111v1 [cs.CL])\nAbstract: Text classification is a well-studied and versatile building block for many NLP applications. Yet, existing approaches require either large annotated corpora to train a model with or, when using large language models as a base, require carefully crafting the prompt as well as using a long context that can fit many examples. As a result, it is not possible for end-users to build classifiers for themselves. To address this issue, we propose a novel approach to few-shot text classification using an LLM. Rather than few-shot examples, the LLM is prompted with descriptions of the salient features of each class. These descriptions are coauthored by the user and the LLM interactively: while the user annotates each few-shot example, the LLM asks relevant questions that the user answers. Examples, questions, and answers are summarized to form the classification prompt. Our experiments show that our approach yields high accuracy classifiers, within 82% of the performance of models trained with s",
    "path": "papers/23/10/2310.06111.json",
    "total_tokens": 895,
    "translated_title": "BYOC: 使用合著的类别描述个性化进行少样本分类",
    "translated_abstract": "文本分类是许多自然语言处理应用的重要组成部分，但现有方法要么需要大规模带标注的语料库进行模型训练，要么在使用大型语言模型作为基础时，需要精心设计提示并使用能容纳许多示例的长上下文。结果，普通用户不能为自己构建分类器。为了解决这个问题，我们提出了一种新颖的个性化少样本文本分类方法，使用LLM（大型语言模型）。LLM不是使用少样本示例，而是由用户和LLM合著的每个类别的显著特征的描述进行提示。在用户标注每个少样本示例时，LLM会提出相关的问题，用户给出答案。示例、问题和答案被总结成分类提示。实验证明，我们的方法可以获得高准确率的分类器，其性能达到使用大规模数据集进行训练的模型的82%。",
    "tldr": "提出了一种个性化的少样本文本分类方法，使用合著的类别描述作为提示，用户与LLM交互合作进行标注，形成分类提示，实验结果显示其准确率达到了使用大规模数据集进行训练的模型的82%。",
    "en_tdlr": "A personalized few-shot text classification approach is proposed, using co-authored class descriptions as prompts. Users interactively annotate examples with relevant questions asked by the LLM, and the summarized information forms the classification prompt. Experimental results show that the approach achieves an accuracy of 82% of models trained with large annotated datasets."
}