{
    "title": "ToxicChat: Unveiling Hidden Challenges of Toxicity Detection in Real-World User-AI Conversation. (arXiv:2310.17389v1 [cs.CL])",
    "abstract": "Despite remarkable advances that large language models have achieved in chatbots, maintaining a non-toxic user-AI interactive environment has become increasingly critical nowadays. However, previous efforts in toxicity detection have been mostly based on benchmarks derived from social media content, leaving the unique challenges inherent to real-world user-AI interactions insufficiently explored. In this work, we introduce ToxicChat, a novel benchmark based on real user queries from an open-source chatbot. This benchmark contains the rich, nuanced phenomena that can be tricky for current toxicity detection models to identify, revealing a significant domain difference compared to social media content. Our systematic evaluation of models trained on existing toxicity datasets has shown their shortcomings when applied to this unique domain of ToxicChat. Our work illuminates the potentially overlooked challenges of toxicity detection in real-world user-AI conversations. In the future, Toxic",
    "link": "http://arxiv.org/abs/2310.17389",
    "context": "Title: ToxicChat: Unveiling Hidden Challenges of Toxicity Detection in Real-World User-AI Conversation. (arXiv:2310.17389v1 [cs.CL])\nAbstract: Despite remarkable advances that large language models have achieved in chatbots, maintaining a non-toxic user-AI interactive environment has become increasingly critical nowadays. However, previous efforts in toxicity detection have been mostly based on benchmarks derived from social media content, leaving the unique challenges inherent to real-world user-AI interactions insufficiently explored. In this work, we introduce ToxicChat, a novel benchmark based on real user queries from an open-source chatbot. This benchmark contains the rich, nuanced phenomena that can be tricky for current toxicity detection models to identify, revealing a significant domain difference compared to social media content. Our systematic evaluation of models trained on existing toxicity datasets has shown their shortcomings when applied to this unique domain of ToxicChat. Our work illuminates the potentially overlooked challenges of toxicity detection in real-world user-AI conversations. In the future, Toxic",
    "path": "papers/23/10/2310.17389.json",
    "total_tokens": 954,
    "translated_title": "ToxicChat: 揭示实际用户-AI对话中的毒性检测隐藏挑战",
    "translated_abstract": "尽管大型语言模型在聊天机器人方面取得了显著的进展，但如今维持一个非毒性的用户-AI互动环境变得越来越重要。然而，先前的毒性检测工作大多基于社交媒体内容导出的基准，未充分探索实际用户-AI互动中固有的独特挑战。本研究引入了ToxicChat，这是一个基于开源聊天机器人的实际用户查询构建的新型基准。该基准包含了对当前毒性检测模型难以识别的丰富而微妙的现象，相对于社交媒体内容来说存在显著的领域差异。我们对在现有毒性数据集上训练的模型进行了系统评估，发现它们在应用于ToxicChat的这个独特领域时存在缺点。我们的研究揭示了实际用户-AI对话中毒性检测可能被忽视的挑战。将来，ToxicChat的研究可以推动更好的毒性检测方法和工具的发展。",
    "tldr": "本研究引入了ToxicChat，一个基于实际用户查询构建的新型毒性检测基准。该基准揭示了当前毒性检测模型在实际用户-AI对话中面临的困难，强调了实际对话中存在的独特挑战。",
    "en_tdlr": "This study introduces ToxicChat, a novel toxicity detection benchmark based on real user queries. The benchmark highlights the challenges faced by current toxicity detection models in real-world user-AI conversations, emphasizing the unique difficulties present in such interactions."
}