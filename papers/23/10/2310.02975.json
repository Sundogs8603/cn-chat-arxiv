{
    "title": "Towards Fully Adaptive Regret Minimization in Heavy-Tailed Bandits. (arXiv:2310.02975v1 [cs.LG])",
    "abstract": "Heavy-tailed distributions naturally arise in many settings, from finance to telecommunications. While regret minimization under sub-Gaussian or bounded support rewards has been widely studied, learning on heavy-tailed distributions only gained popularity over the last decade. In the stochastic heavy-tailed bandit problem, an agent learns under the assumption that the distributions have finite moments of maximum order $1+\\epsilon$ which are uniformly bounded by a constant $u$, for some $\\epsilon \\in (0,1]$. To the best of our knowledge, literature only provides algorithms requiring these two quantities as an input. In this paper, we study the stochastic adaptive heavy-tailed bandit, a variation of the standard setting where both $\\epsilon$ and $u$ are unknown to the agent. We show that adaptivity comes at a cost, introducing two lower bounds on the regret of any adaptive algorithm, implying a higher regret w.r.t. the standard setting. Finally, we introduce a specific distributional ass",
    "link": "http://arxiv.org/abs/2310.02975",
    "context": "Title: Towards Fully Adaptive Regret Minimization in Heavy-Tailed Bandits. (arXiv:2310.02975v1 [cs.LG])\nAbstract: Heavy-tailed distributions naturally arise in many settings, from finance to telecommunications. While regret minimization under sub-Gaussian or bounded support rewards has been widely studied, learning on heavy-tailed distributions only gained popularity over the last decade. In the stochastic heavy-tailed bandit problem, an agent learns under the assumption that the distributions have finite moments of maximum order $1+\\epsilon$ which are uniformly bounded by a constant $u$, for some $\\epsilon \\in (0,1]$. To the best of our knowledge, literature only provides algorithms requiring these two quantities as an input. In this paper, we study the stochastic adaptive heavy-tailed bandit, a variation of the standard setting where both $\\epsilon$ and $u$ are unknown to the agent. We show that adaptivity comes at a cost, introducing two lower bounds on the regret of any adaptive algorithm, implying a higher regret w.r.t. the standard setting. Finally, we introduce a specific distributional ass",
    "path": "papers/23/10/2310.02975.json",
    "total_tokens": 887,
    "translated_title": "在重尾波段的完全自适应遗憾最小化领域中的研究",
    "translated_abstract": "重尾分布在金融到电信等多种环境中自然而然地出现。虽然在次高斯或有界支撑奖励下的遗憾最小化已被广泛研究，但在重尾分布上的学习只在过去十年中受到关注。在随机重尾波段问题中，一个代理在假设分布有有界最大阶的有限矩的情况下学习，这些矩被常数u一致有界，对于某个ε∈(0,1]。据我们所知，文献中只提供需要这两个量作为输入的算法。在本文中，我们研究了随机自适应重尾波段问题，这是标准设置的一个变种，其中代理对ε和u均不知晓。我们表明，适应性是存在代价的，并引入对于任何自适应算法遗憾的两个下界，意味着相对于标准设置有更高的遗憾。最后，我们引入一种特定的分布假设。",
    "tldr": "本文研究了在重尾波段问题中完全自适应的遗憾最小化，提出了随机自适应重尾波段问题，并证明了适应性算法相对于标准设置会有更高的遗憾。"
}