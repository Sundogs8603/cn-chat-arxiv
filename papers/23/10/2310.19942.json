{
    "title": "Split-NER: Named Entity Recognition via Two Question-Answering-based Classifications. (arXiv:2310.19942v1 [cs.CL])",
    "abstract": "In this work, we address the NER problem by splitting it into two logical sub-tasks: (1) Span Detection which simply extracts entity mention spans irrespective of entity type; (2) Span Classification which classifies the spans into their entity types. Further, we formulate both sub-tasks as question-answering (QA) problems and produce two leaner models which can be optimized separately for each sub-task. Experiments with four cross-domain datasets demonstrate that this two-step approach is both effective and time efficient. Our system, SplitNER outperforms baselines on OntoNotes5.0, WNUT17 and a cybersecurity dataset and gives on-par performance on BioNLP13CG. In all cases, it achieves a significant reduction in training time compared to its QA baseline counterpart. The effectiveness of our system stems from fine-tuning the BERT model twice, separately for span detection and classification. The source code can be found at https://github.com/c3sr/split-ner.",
    "link": "http://arxiv.org/abs/2310.19942",
    "context": "Title: Split-NER: Named Entity Recognition via Two Question-Answering-based Classifications. (arXiv:2310.19942v1 [cs.CL])\nAbstract: In this work, we address the NER problem by splitting it into two logical sub-tasks: (1) Span Detection which simply extracts entity mention spans irrespective of entity type; (2) Span Classification which classifies the spans into their entity types. Further, we formulate both sub-tasks as question-answering (QA) problems and produce two leaner models which can be optimized separately for each sub-task. Experiments with four cross-domain datasets demonstrate that this two-step approach is both effective and time efficient. Our system, SplitNER outperforms baselines on OntoNotes5.0, WNUT17 and a cybersecurity dataset and gives on-par performance on BioNLP13CG. In all cases, it achieves a significant reduction in training time compared to its QA baseline counterpart. The effectiveness of our system stems from fine-tuning the BERT model twice, separately for span detection and classification. The source code can be found at https://github.com/c3sr/split-ner.",
    "path": "papers/23/10/2310.19942.json",
    "total_tokens": 905,
    "translated_title": "Split-NER: 通过两个基于问答的分类解决命名实体识别问题",
    "translated_abstract": "本研究将命名实体识别问题分成两个逻辑子任务：（1）提取实体提及跨度，无论实体类型如何；（2）将跨度分类为实体类型。进一步，我们将这两个子任务都形式化为问答问题，并产生两个可以分别为每个子任务进行优化的更轻的模型。在四个跨领域数据集上的实验表明，这个两步法既有效又节省时间。我们的系统SplitNER在OntoNotes5.0、WNUT17和一个网络安全数据集上的性能超过了基线，并在BioNLP13CG上表现相当。在所有情况下，与QA基线对照相比，它在训练时减少了显著的时间。我们系统的有效性源于分别对跨度检测和分类进行BERT模型的微调。源代码可在https://github.com/c3sr/split-ner找到。",
    "tldr": "本研究提出了一种名为Split-NER的系统，通过将命名实体识别问题分成提取实体提及跨度和跨度分类两个子任务，然后利用问答模型解决这两个子任务，实现了高效和准确的命名实体识别。",
    "en_tdlr": "This paper proposes a system called Split-NER, which tackles the named entity recognition problem by dividing it into two sub-tasks: extracting entity mention spans and classifying the spans. The two sub-tasks are solved using question-answering models, resulting in an efficient and accurate named entity recognition system."
}