{
    "title": "Causal Inference with Conditional Front-Door Adjustment and Identifiable Variational Autoencoder. (arXiv:2310.01937v1 [cs.LG])",
    "abstract": "An essential and challenging problem in causal inference is causal effect estimation from observational data. The problem becomes more difficult with the presence of unobserved confounding variables. The front-door adjustment is a practical approach for dealing with unobserved confounding variables. However, the restriction for the standard front-door adjustment is difficult to satisfy in practice. In this paper, we relax some of the restrictions by proposing the concept of conditional front-door (CFD) adjustment and develop the theorem that guarantees the causal effect identifiability of CFD adjustment. Furthermore, as it is often impossible for a CFD variable to be given in practice, it is desirable to learn it from data. By leveraging the ability of deep generative models, we propose CFDiVAE to learn the representation of the CFD adjustment variable directly from data with the identifiable Variational AutoEncoder and formally prove the model identifiability. Extensive experiments on",
    "link": "http://arxiv.org/abs/2310.01937",
    "context": "Title: Causal Inference with Conditional Front-Door Adjustment and Identifiable Variational Autoencoder. (arXiv:2310.01937v1 [cs.LG])\nAbstract: An essential and challenging problem in causal inference is causal effect estimation from observational data. The problem becomes more difficult with the presence of unobserved confounding variables. The front-door adjustment is a practical approach for dealing with unobserved confounding variables. However, the restriction for the standard front-door adjustment is difficult to satisfy in practice. In this paper, we relax some of the restrictions by proposing the concept of conditional front-door (CFD) adjustment and develop the theorem that guarantees the causal effect identifiability of CFD adjustment. Furthermore, as it is often impossible for a CFD variable to be given in practice, it is desirable to learn it from data. By leveraging the ability of deep generative models, we propose CFDiVAE to learn the representation of the CFD adjustment variable directly from data with the identifiable Variational AutoEncoder and formally prove the model identifiability. Extensive experiments on",
    "path": "papers/23/10/2310.01937.json",
    "total_tokens": 889,
    "translated_title": "Causal Inference with Conditional Front-Door Adjustment and Identifiable Variational Autoencoder",
    "translated_abstract": "因果推断中的一个重要且具有挑战性的问题是如何从观测数据中估计因果效应。当存在未观测到的混淆变量时，这个问题变得更加困难。前门调整是处理未观测到的混淆变量的一种实用方法。然而，标准前门调整的限制在实践中很难满足。本文通过提出条件前门调整的概念并发展保证条件前门调整的因果效应可辨识性的定理，放松了一些限制。此外，由于在实践中往往无法给定一个条件前门变量，因此希望能够从数据中学习该变量。通过利用深度生成模型的能力，我们提出了CFDiVAE来直接从数据中学习条件前门调整变量的表示，并正式证明了模型的可辨识性。在大量实验中进行了验证。",
    "tldr": "本文提出了条件前门调整和可辨识性变分自编码器来解决因果推断中的问题，通过放松限制和利用深度生成模型，从观测数据中学习未观测到的混淆变量的表示，从而保证因果效应的可辨识性。"
}