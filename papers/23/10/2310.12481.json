{
    "title": "Not All Countries Celebrate Thanksgiving: On the Cultural Dominance in Large Language Models. (arXiv:2310.12481v1 [cs.CL])",
    "abstract": "In this paper, we identify a cultural dominance issue within large language models (LLMs) due to the predominant use of English data in model training (e.g. ChatGPT). LLMs often provide inappropriate English-culture-related answers that are not relevant to the expected culture when users ask in non-English languages. To systematically evaluate the cultural dominance issue, we build a benchmark that consists of both concrete (e.g. holidays and songs) and abstract (e.g. values and opinions) cultural objects. Empirical results show that the representative GPT models suffer from the culture dominance problem, where GPT-4 is the most affected while text-davinci-003 suffers the least from this problem. Our study emphasizes the need for critical examination of cultural dominance and ethical consideration in their development and deployment. We show two straightforward methods in model development (i.e. pretraining on more diverse data) and deployment (e.g. culture-aware prompting) can signifi",
    "link": "http://arxiv.org/abs/2310.12481",
    "context": "Title: Not All Countries Celebrate Thanksgiving: On the Cultural Dominance in Large Language Models. (arXiv:2310.12481v1 [cs.CL])\nAbstract: In this paper, we identify a cultural dominance issue within large language models (LLMs) due to the predominant use of English data in model training (e.g. ChatGPT). LLMs often provide inappropriate English-culture-related answers that are not relevant to the expected culture when users ask in non-English languages. To systematically evaluate the cultural dominance issue, we build a benchmark that consists of both concrete (e.g. holidays and songs) and abstract (e.g. values and opinions) cultural objects. Empirical results show that the representative GPT models suffer from the culture dominance problem, where GPT-4 is the most affected while text-davinci-003 suffers the least from this problem. Our study emphasizes the need for critical examination of cultural dominance and ethical consideration in their development and deployment. We show two straightforward methods in model development (i.e. pretraining on more diverse data) and deployment (e.g. culture-aware prompting) can signifi",
    "path": "papers/23/10/2310.12481.json",
    "total_tokens": 1013,
    "translated_title": "并非所有国家都庆祝感恩节：关于大型语言模型中的文化主导问题",
    "translated_abstract": "本文针对大型语言模型（LLM）中存在的文化主导问题进行了研究，该问题源于在模型训练中主要使用英语数据（例如ChatGPT）。当用户使用非英语语言提问时，LLMs往往会提供与预期文化不相关的不恰当的英语文化相关答案。为了系统评估文化主导问题，我们构建了一个包含具体文化对象（如假日和歌曲）和抽象文化对象（如价值观和观点）的基准测试集。实证结果表明，代表性的GPT模型存在文化主导问题，其中GPT-4受到最严重影响，而text-davinci-003在这个问题上受影响最小。我们的研究强调了在开发和部署过程中对文化主导问题进行批判性审视和伦理考虑的需要。我们展示了两种直接的方法：模型开发中的多样化数据预训练和部署中的文化感知提示，可以显著缓解文化主导问题。",
    "tldr": "本文研究了大型语言模型中的文化主导问题，发现由于在模型训练中主要使用英语数据，当用户使用非英语语言提问时，模型往往提供与预期文化不相关的不恰当答案。我们提出了通过多样化数据预训练和文化感知提示两种方法来解决这个问题。",
    "en_tdlr": "This paper addresses the issue of cultural dominance in large language models (LLMs), which arises from the heavy reliance on English data during model training. It is found that LLMs often provide inappropriate English-culture-related answers when users ask in non-English languages. The study highlights the need for critical examination and ethical consideration of cultural dominance in the development and deployment of LLMs. Two straightforward methods, namely pretraining on diverse data and culture-aware prompting, are proposed to mitigate this problem."
}