{
    "title": "Quantile-based Maximum Likelihood Training for Outlier Detection. (arXiv:2310.06085v1 [cs.CV])",
    "abstract": "Discriminative learning effectively predicts true object class for image classification. However, it often results in false positives for outliers, posing critical concerns in applications like autonomous driving and video surveillance systems. Previous attempts to address this challenge involved training image classifiers through contrastive learning using actual outlier data or synthesizing outliers for self-supervised learning. Furthermore, unsupervised generative modeling of inliers in pixel space has shown limited success for outlier detection. In this work, we introduce a quantile-based maximum likelihood objective for learning the inlier distribution to improve the outlier separation during inference. Our approach fits a normalizing flow to pre-trained discriminative features and detects the outliers according to the evaluated log-likelihood. The experimental evaluation demonstrates the effectiveness of our method as it surpasses the performance of the state-of-the-art unsupervi",
    "link": "http://arxiv.org/abs/2310.06085",
    "context": "Title: Quantile-based Maximum Likelihood Training for Outlier Detection. (arXiv:2310.06085v1 [cs.CV])\nAbstract: Discriminative learning effectively predicts true object class for image classification. However, it often results in false positives for outliers, posing critical concerns in applications like autonomous driving and video surveillance systems. Previous attempts to address this challenge involved training image classifiers through contrastive learning using actual outlier data or synthesizing outliers for self-supervised learning. Furthermore, unsupervised generative modeling of inliers in pixel space has shown limited success for outlier detection. In this work, we introduce a quantile-based maximum likelihood objective for learning the inlier distribution to improve the outlier separation during inference. Our approach fits a normalizing flow to pre-trained discriminative features and detects the outliers according to the evaluated log-likelihood. The experimental evaluation demonstrates the effectiveness of our method as it surpasses the performance of the state-of-the-art unsupervi",
    "path": "papers/23/10/2310.06085.json",
    "total_tokens": 911,
    "translated_title": "基于分位数的极大似然训练用于异常检测",
    "translated_abstract": "判别性学习有效地对图像分类预测真实的对象类别。然而，在异常值方面，它经常导致误报阳性，这在自主驾驶和视频监视系统等应用中引起了严重关注。以往解决这个挑战的尝试包括使用实际异常值数据通过对比学习训练图像分类器，或者通过合成异常值进行自我监督学习。此外，像素空间中对内点进行无监督生成建模对于异常检测显示出有限的成功。在这项工作中，我们引入了一种基于分位数的极大似然目标，用于学习内点分布，以在推断过程中提高异常值的分离程度。我们的方法通过将正则化流拟合到预训练的判别性特征，并根据评估的对数似然度来检测异常值。实验评估证明了我们方法的有效性，因为它超过了最先进的无监督方法的性能。",
    "tldr": "本文提出了一种基于分位数的极大似然目标，用于改进异常检测中异常值的分离程度。通过将正则化流拟合到预训练的判别性特征，并根据对数似然度评估来检测异常值。实验结果表明，这种方法优于最先进的无监督模型。"
}