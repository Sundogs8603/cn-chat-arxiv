{
    "title": "Impact of multi-armed bandit strategies on deep recurrent reinforcement learning. (arXiv:2310.08331v1 [stat.ML])",
    "abstract": "Incomplete knowledge of the environment leads an agent to make decisions under uncertainty. One of the major dilemmas in Reinforcement Learning (RL) where an autonomous agent has to balance two contrasting needs in making its decisions is: exploiting the current knowledge of the environment to maximize the cumulative reward as well as exploring actions that allow improving the knowledge of the environment, hopefully leading to higher reward values (exploration-exploitation trade-off). Concurrently, another relevant issue regards the full observability of the states, which may not be assumed in all applications. Such as when only 2D images are considered as input in a RL approach used for finding the optimal action within a 3D simulation environment. In this work, we address these issues by deploying and testing several techniques to balance exploration and exploitation trade-off on partially observable systems for predicting steering wheels in autonomous driving scenario. More precisel",
    "link": "http://arxiv.org/abs/2310.08331",
    "context": "Title: Impact of multi-armed bandit strategies on deep recurrent reinforcement learning. (arXiv:2310.08331v1 [stat.ML])\nAbstract: Incomplete knowledge of the environment leads an agent to make decisions under uncertainty. One of the major dilemmas in Reinforcement Learning (RL) where an autonomous agent has to balance two contrasting needs in making its decisions is: exploiting the current knowledge of the environment to maximize the cumulative reward as well as exploring actions that allow improving the knowledge of the environment, hopefully leading to higher reward values (exploration-exploitation trade-off). Concurrently, another relevant issue regards the full observability of the states, which may not be assumed in all applications. Such as when only 2D images are considered as input in a RL approach used for finding the optimal action within a 3D simulation environment. In this work, we address these issues by deploying and testing several techniques to balance exploration and exploitation trade-off on partially observable systems for predicting steering wheels in autonomous driving scenario. More precisel",
    "path": "papers/23/10/2310.08331.json",
    "total_tokens": 814,
    "translated_title": "多臂赌博策略对深度循环强化学习的影响",
    "translated_abstract": "对环境的不完全了解导致智能体在不确定性下做出决策。强化学习中一个重要的困境是，在做出决策时，智能体需要在利用当前环境知识最大化累积奖励和探索行动以提高环境知识的之间进行权衡（探索-利用的平衡）。同时，另一个相关问题是状态的完全可观测性，不是所有应用都能假定。例如，当只将2D图像作为输入用于在3D模拟环境中找到最佳行动时，就存在这个问题。在本研究中，我们通过部署和测试多种技术来解决部分可观测系统中探索和利用的平衡问题，以预测自动驾驶场景中的方向盘操作。",
    "tldr": "本研究在自动驾驶场景中使用部分可观测系统，通过部署和测试多种技术来平衡探索和利用的权衡，以预测方向盘操作。",
    "en_tdlr": "This study explores the balance between exploration and exploitation in partially observable systems in the context of autonomous driving, by deploying and testing various techniques to predict steering wheel operations."
}