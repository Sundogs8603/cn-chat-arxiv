{
    "title": "A Stability Principle for Learning under Non-Stationarity. (arXiv:2310.18304v1 [cs.LG])",
    "abstract": "We develop a versatile framework for statistical learning in non-stationary environments. In each time period, our approach applies a stability principle to select a look-back window that maximizes the utilization of historical data while keeping the cumulative bias within an acceptable range relative to the stochastic error. Our theory showcases the adaptability of this approach to unknown non-stationarity. The regret bound is minimax optimal up to logarithmic factors when the population losses are strongly convex, or Lipschitz only. At the heart of our analysis lie two novel components: a measure of similarity between functions and a segmentation technique for dividing the non-stationary data sequence into quasi-stationary pieces.",
    "link": "http://arxiv.org/abs/2310.18304",
    "context": "Title: A Stability Principle for Learning under Non-Stationarity. (arXiv:2310.18304v1 [cs.LG])\nAbstract: We develop a versatile framework for statistical learning in non-stationary environments. In each time period, our approach applies a stability principle to select a look-back window that maximizes the utilization of historical data while keeping the cumulative bias within an acceptable range relative to the stochastic error. Our theory showcases the adaptability of this approach to unknown non-stationarity. The regret bound is minimax optimal up to logarithmic factors when the population losses are strongly convex, or Lipschitz only. At the heart of our analysis lie two novel components: a measure of similarity between functions and a segmentation technique for dividing the non-stationary data sequence into quasi-stationary pieces.",
    "path": "papers/23/10/2310.18304.json",
    "total_tokens": 904,
    "translated_title": "学习非稳态条件下的稳定性原则",
    "translated_abstract": "我们在非稳定环境中开发了一个灵活的统计学习框架。在每个时间段，我们的方法应用稳定性原则来选择一个回溯窗口，最大限度地利用历史数据，同时将累积偏差保持在与随机误差相对可接受的范围内。我们的理论展示了该方法对未知非稳定性的适应性。当人口损失函数强凸或仅满足Lipschitz条件时，遗憾界是极小化的最优解，仅受对数因子的影响。我们的分析核心是两个新颖的组成部分：函数之间的相似度度量和将非稳态数据序列划分为准稳态片段的分割技术。",
    "tldr": "本研究提出了一个适用于非稳态环境的统计学习框架，通过应用稳定性原则选择回溯窗口来最大化历史数据利用，并保持累积偏差在可接受范围内。该方法展示了对未知非稳态的适应性，遗憾界在强凸或满足Lipschitz条件下是极小化的最优解。该研究的创新点是函数相似度度量和非稳态数据序列划分技术。",
    "en_tdlr": "This study proposes a statistical learning framework for non-stationary environments, which selects a look-back window based on a stability principle to maximize the utilization of historical data while keeping the cumulative bias within an acceptable range. The approach demonstrates adaptability to unknown non-stationarity and achieves minimax optimal regret bounds under strong convexity or Lipschitz conditions. The novel contributions lie in the measures of similarity between functions and the segmentation technique for non-stationary data sequences."
}