{
    "title": "Reproducibility in Multiple Instance Learning: A Case For Algorithmic Unit Tests. (arXiv:2310.17867v1 [stat.ML])",
    "abstract": "Multiple Instance Learning (MIL) is a sub-domain of classification problems with positive and negative labels and a \"bag\" of inputs, where the label is positive if and only if a positive element is contained within the bag, and otherwise is negative. Training in this context requires associating the bag-wide label to instance-level information, and implicitly contains a causal assumption and asymmetry to the task (i.e., you can't swap the labels without changing the semantics). MIL problems occur in healthcare (one malignant cell indicates cancer), cyber security (one malicious executable makes an infected computer), and many other tasks. In this work, we examine five of the most prominent deep-MIL models and find that none of them respects the standard MIL assumption. They are able to learn anti-correlated instances, i.e., defaulting to \"positive\" labels until seeing a negative counter-example, which should not be possible for a correct MIL model. We suspect that enhancements and othe",
    "link": "http://arxiv.org/abs/2310.17867",
    "context": "Title: Reproducibility in Multiple Instance Learning: A Case For Algorithmic Unit Tests. (arXiv:2310.17867v1 [stat.ML])\nAbstract: Multiple Instance Learning (MIL) is a sub-domain of classification problems with positive and negative labels and a \"bag\" of inputs, where the label is positive if and only if a positive element is contained within the bag, and otherwise is negative. Training in this context requires associating the bag-wide label to instance-level information, and implicitly contains a causal assumption and asymmetry to the task (i.e., you can't swap the labels without changing the semantics). MIL problems occur in healthcare (one malignant cell indicates cancer), cyber security (one malicious executable makes an infected computer), and many other tasks. In this work, we examine five of the most prominent deep-MIL models and find that none of them respects the standard MIL assumption. They are able to learn anti-correlated instances, i.e., defaulting to \"positive\" labels until seeing a negative counter-example, which should not be possible for a correct MIL model. We suspect that enhancements and othe",
    "path": "papers/23/10/2310.17867.json",
    "total_tokens": 884,
    "translated_title": "多实例学习中的可重现性: 算法单元测试的案例",
    "translated_abstract": "多实例学习(MIL)是分类问题的一个子领域，其中有正负标签和一个输入的“包”，当且仅当包中包含一个正元素时，标签为正，否则为负。在这种情况下，训练需要将包级标签与实例级信息关联起来，并隐含着一个因果假设和任务的不对称性（即，无法交换标签而不改变语义）。MIL问题出现在医疗保健（一个恶性细胞表示癌症），网络安全（一个恶意可执行文件会感染计算机）等许多任务中。在这项工作中，我们检查了最著名的五个深度MIL模型，并发现它们都不符合标准的MIL假设。它们能够学习反相关的实例，即在看到负的反例之前默认为“正”标签，这对于一个正确的MIL模型来说是不可能的。我们怀疑改进和其他策略可能会改善这一问题。",
    "tldr": "多实例学习中的五个深度模型在学习过程中违反了标准的MIL假设，导致能够学习反相关的实例。这一问题需要通过改进和其他策略来解决。",
    "en_tdlr": "Five deep MIL models violate the standard MIL assumption, allowing them to learn anti-correlated instances. Enhancements and other strategies are needed to address this issue."
}