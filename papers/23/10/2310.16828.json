{
    "title": "TD-MPC2: Scalable, Robust World Models for Continuous Control",
    "abstract": "arXiv:2310.16828v2 Announce Type: replace-cross  Abstract: TD-MPC is a model-based reinforcement learning (RL) algorithm that performs local trajectory optimization in the latent space of a learned implicit (decoder-free) world model. In this work, we present TD-MPC2: a series of improvements upon the TD-MPC algorithm. We demonstrate that TD-MPC2 improves significantly over baselines across 104 online RL tasks spanning 4 diverse task domains, achieving consistently strong results with a single set of hyperparameters. We further show that agent capabilities increase with model and data size, and successfully train a single 317M parameter agent to perform 80 tasks across multiple task domains, embodiments, and action spaces. We conclude with an account of lessons, opportunities, and risks associated with large TD-MPC2 agents. Explore videos, models, data, code, and more at https://tdmpc2.com",
    "link": "https://arxiv.org/abs/2310.16828",
    "context": "Title: TD-MPC2: Scalable, Robust World Models for Continuous Control\nAbstract: arXiv:2310.16828v2 Announce Type: replace-cross  Abstract: TD-MPC is a model-based reinforcement learning (RL) algorithm that performs local trajectory optimization in the latent space of a learned implicit (decoder-free) world model. In this work, we present TD-MPC2: a series of improvements upon the TD-MPC algorithm. We demonstrate that TD-MPC2 improves significantly over baselines across 104 online RL tasks spanning 4 diverse task domains, achieving consistently strong results with a single set of hyperparameters. We further show that agent capabilities increase with model and data size, and successfully train a single 317M parameter agent to perform 80 tasks across multiple task domains, embodiments, and action spaces. We conclude with an account of lessons, opportunities, and risks associated with large TD-MPC2 agents. Explore videos, models, data, code, and more at https://tdmpc2.com",
    "path": "papers/23/10/2310.16828.json",
    "total_tokens": 845,
    "translated_title": "TD-MPC2：可扩展、稳健的连续控制世界模型",
    "translated_abstract": "TD-MPC是一种基于模型的强化学习（RL）算法，它在学习的隐式（无解码器）世界模型的潜在空间中执行局部轨迹优化。在这项工作中，我们展示了TD-MPC2：对TD-MPC算法的一系列改进。我们证明TD-MPC2在跨越4个不同任务领域的104个在线RL任务中显著改善了基线，通过一组超参数实现了持续强大的结果。我们进一步展示了随着模型和数据规模的增加，代理的能力也在增强，并成功训练了一个单一的317M参数代理，在多个任务领域、具象和动作空间中执行了80个任务。最后，我们总结了大型TD-MPC2代理所涉及的教训、机会和风险。在https://tdmpc2.com上探索视频、模型、数据、代码等。",
    "tldr": "TD-MPC2是对TD-MPC算法的一系列改进，通过一组超参数在104个在线RL任务中取得了显著进展，成功训练单一的317M参数代理执行80个任务。",
    "en_tdlr": "TD-MPC2 is a series of improvements upon the TD-MPC algorithm that achieves significant progress across 104 online RL tasks with a single set of hyperparameters, successfully training a single 317M parameter agent to perform 80 tasks."
}