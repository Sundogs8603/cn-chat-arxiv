{
    "title": "Instructive Dialogue Summarization with Query Aggregations. (arXiv:2310.10981v1 [cs.CL])",
    "abstract": "Conventional dialogue summarization methods directly generate summaries and do not consider user's specific interests. This poses challenges in cases where the users are more focused on particular topics or aspects. With the advancement of instruction-finetuned language models, we introduce instruction-tuning to dialogues to expand the capability set of dialogue summarization models. To overcome the scarcity of instructive dialogue summarization data, we propose a three-step approach to synthesize high-quality query-based summarization triples. This process involves summary-anchored query generation, query filtering, and query-based summary generation. By training a unified model called InstructDS (Instructive Dialogue Summarization) on three summarization datasets with multi-purpose instructive triples, we expand the capability of dialogue summarization models. We evaluate our method on four datasets, including dialogue summarization and dialogue reading comprehension. Experimental re",
    "link": "http://arxiv.org/abs/2310.10981",
    "context": "Title: Instructive Dialogue Summarization with Query Aggregations. (arXiv:2310.10981v1 [cs.CL])\nAbstract: Conventional dialogue summarization methods directly generate summaries and do not consider user's specific interests. This poses challenges in cases where the users are more focused on particular topics or aspects. With the advancement of instruction-finetuned language models, we introduce instruction-tuning to dialogues to expand the capability set of dialogue summarization models. To overcome the scarcity of instructive dialogue summarization data, we propose a three-step approach to synthesize high-quality query-based summarization triples. This process involves summary-anchored query generation, query filtering, and query-based summary generation. By training a unified model called InstructDS (Instructive Dialogue Summarization) on three summarization datasets with multi-purpose instructive triples, we expand the capability of dialogue summarization models. We evaluate our method on four datasets, including dialogue summarization and dialogue reading comprehension. Experimental re",
    "path": "papers/23/10/2310.10981.json",
    "total_tokens": 884,
    "translated_title": "使用查询聚合的指导性对话摘要",
    "translated_abstract": "传统的对话摘要方法直接生成摘要，不考虑用户的特定兴趣。这在用户更加关注特定主题或方面的情况下会带来挑战。随着指导调优语言模型的进步，我们引入了指导对话来扩展对话摘要模型的能力集。为了克服指导性对话摘要数据的稀缺性，我们提出了一种三步方法来合成高质量的基于查询的摘要三元组。这个过程包括以摘要为锚点的查询生成、查询过滤和基于查询的摘要生成。通过在三个摘要数据集上训练一个统一的模型InstructDS（指导性对话摘要），我们扩展了对话摘要模型的能力。我们在包括对话摘要和对话阅读理解的四个数据集上对我们的方法进行评估。",
    "tldr": "传统的对话摘要方法无法考虑用户的特定兴趣，而指导对话摘要的引入可以帮助扩展对话摘要模型的能力。我们提出了一个三步方法来合成高质量的查询摘要三元组，并通过在多个数据集上训练一个统一模型来扩展对话摘要模型的能力。",
    "en_tdlr": "Conventional dialogue summarization methods fail to consider user-specific interests, while the introduction of instructive dialogue can help expand the capabilities of dialogue summarization models. We propose a three-step approach to synthesize high-quality query-based summarization triples, and expand the capabilities of dialogue summarization models by training a unified model on multiple datasets."
}