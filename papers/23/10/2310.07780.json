{
    "title": "Promoting Robustness of Randomized Smoothing: Two Cost-Effective Approaches. (arXiv:2310.07780v1 [cs.LG])",
    "abstract": "Randomized smoothing has recently attracted attentions in the field of adversarial robustness to provide provable robustness guarantees on smoothed neural network classifiers. However, existing works show that vanilla randomized smoothing usually does not provide good robustness performance and often requires (re)training techniques on the base classifier in order to boost the robustness of the resulting smoothed classifier. In this work, we propose two cost-effective approaches to boost the robustness of randomized smoothing while preserving its clean performance. The first approach introduces a new robust training method AdvMacerwhich combines adversarial training and robustness certification maximization for randomized smoothing. We show that AdvMacer can improve the robustness performance of randomized smoothing classifiers compared to SOTA baselines, while being 3x faster to train than MACER baseline. The second approach introduces a post-processing method EsbRS which greatly impr",
    "link": "http://arxiv.org/abs/2310.07780",
    "context": "Title: Promoting Robustness of Randomized Smoothing: Two Cost-Effective Approaches. (arXiv:2310.07780v1 [cs.LG])\nAbstract: Randomized smoothing has recently attracted attentions in the field of adversarial robustness to provide provable robustness guarantees on smoothed neural network classifiers. However, existing works show that vanilla randomized smoothing usually does not provide good robustness performance and often requires (re)training techniques on the base classifier in order to boost the robustness of the resulting smoothed classifier. In this work, we propose two cost-effective approaches to boost the robustness of randomized smoothing while preserving its clean performance. The first approach introduces a new robust training method AdvMacerwhich combines adversarial training and robustness certification maximization for randomized smoothing. We show that AdvMacer can improve the robustness performance of randomized smoothing classifiers compared to SOTA baselines, while being 3x faster to train than MACER baseline. The second approach introduces a post-processing method EsbRS which greatly impr",
    "path": "papers/23/10/2310.07780.json",
    "total_tokens": 967,
    "translated_title": "提升随机平滑的鲁棒性：两种成本效益的方法",
    "translated_abstract": "随机平滑最近在对抗鲁棒性领域吸引了注意，它可以为平滑的神经网络分类器提供可证明的鲁棒性保证。然而，现有的研究表明，普通的随机平滑通常不能提供良好的鲁棒性性能，并且经常需要在基本分类器上进行（重新）训练技术来提高平滑分类器的鲁棒性。在这项工作中，我们提出了两种成本效益的方法来提高随机平滑的鲁棒性，同时保持其良好的性能。第一种方法引入了一种新的鲁棒训练方法AdvMacer，结合对抗训练和最大化随机平滑的鲁棒性认证，我们展示了AdvMacer相对于SOTA基准可以提高随机平滑分类器的鲁棒性性能，同时训练速度比MACER基准快3倍。第二个方法引入了一种后处理方法EsbRS，它可以显著改善随机平滑的鲁棒性性能。",
    "tldr": "本文提出了两种成本效益的方法来提高随机平滑的鲁棒性，一种是结合对抗训练和鲁棒性认证的新的鲁棒训练方法，另一种是后处理方法，这些方法在保持良好性能的同时能够提高随机平滑的鲁棒性。",
    "en_tdlr": "This paper proposes two cost-effective approaches to enhance the robustness of randomized smoothing, one is a new robust training method that combines adversarial training and robustness certification, and the other is a post-processing method. These methods can improve the robustness of randomized smoothing while maintaining good performance."
}