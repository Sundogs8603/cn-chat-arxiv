{
    "title": "Fair Classifiers that Abstain without Harm. (arXiv:2310.06205v1 [cs.LG])",
    "abstract": "In critical applications, it is vital for classifiers to defer decision-making to humans. We propose a post-hoc method that makes existing classifiers selectively abstain from predicting certain samples. Our abstaining classifier is incentivized to maintain the original accuracy for each sub-population (i.e. no harm) while achieving a set of group fairness definitions to a user specified degree. To this end, we design an Integer Programming (IP) procedure that assigns abstention decisions for each training sample to satisfy a set of constraints. To generalize the abstaining decisions to test samples, we then train a surrogate model to learn the abstaining decisions based on the IP solutions in an end-to-end manner. We analyze the feasibility of the IP procedure to determine the possible abstention rate for different levels of unfairness tolerance and accuracy constraint for achieving no harm. To the best of our knowledge, this work is the first to identify the theoretical relationships",
    "link": "http://arxiv.org/abs/2310.06205",
    "context": "Title: Fair Classifiers that Abstain without Harm. (arXiv:2310.06205v1 [cs.LG])\nAbstract: In critical applications, it is vital for classifiers to defer decision-making to humans. We propose a post-hoc method that makes existing classifiers selectively abstain from predicting certain samples. Our abstaining classifier is incentivized to maintain the original accuracy for each sub-population (i.e. no harm) while achieving a set of group fairness definitions to a user specified degree. To this end, we design an Integer Programming (IP) procedure that assigns abstention decisions for each training sample to satisfy a set of constraints. To generalize the abstaining decisions to test samples, we then train a surrogate model to learn the abstaining decisions based on the IP solutions in an end-to-end manner. We analyze the feasibility of the IP procedure to determine the possible abstention rate for different levels of unfairness tolerance and accuracy constraint for achieving no harm. To the best of our knowledge, this work is the first to identify the theoretical relationships",
    "path": "papers/23/10/2310.06205.json",
    "total_tokens": 934,
    "translated_title": "公正的分类器，能够不造成伤害地弃权",
    "translated_abstract": "在关键应用中，分类器向人类推迟决策至关重要。我们提出了一种事后方法，使现有的分类器有选择地弃权预测某些样本。我们的弃权分类器被激励以在保持每个子群体的原始准确性的同时，实现一组指定程度的群体公平定义（即无伤害）。为此，我们设计了一个整数规划过程，为每个训练样本分配弃权决策以满足一组约束条件。为了将弃权决策推广到测试样本，我们接着以端到端的方式使用整数规划解决方案训练一个代理模型来学习弃权决策。我们分析了整数规划过程的可行性，以确定在不同的不公平容忍度和准确性约束水平下实现无伤害所可能的弃权率。据我们所知，这项工作是第一个确定了这些理论关系的工作。",
    "tldr": "提出了一种公正的分类器弃权方法，不造成伤害的同时达到一定程度的群体公平性定义。通过整数规划和代理模型训练的方式实现对训练和测试样本的弃权决策，分析了弃权率与不公平容忍度和准确性约束的关系。",
    "en_tdlr": "We propose a method for fair abstention in classifiers, ensuring no harm while achieving a specified level of group fairness. This is achieved through an Integer Programming procedure and training a surrogate model to make abstention decisions for both training and test samples. The relationships between abstention rate, unfairness tolerance, and accuracy constraint are analyzed. This is the first work to identify these theoretical relationships."
}