{
    "title": "MUSCLE: Multi-task Self-supervised Continual Learning to Pre-train Deep Models for X-ray Images of Multiple Body Parts. (arXiv:2310.02000v1 [cs.CV])",
    "abstract": "While self-supervised learning (SSL) algorithms have been widely used to pre-train deep models, few efforts [11] have been done to improve representation learning of X-ray image analysis with SSL pre-trained models. In this work, we study a novel self-supervised pre-training pipeline, namely Multi-task Self-super-vised Continual Learning (MUSCLE), for multiple medical imaging tasks, such as classification and segmentation, using X-ray images collected from multiple body parts, including heads, lungs, and bones. Specifically, MUSCLE aggregates X-rays collected from multiple body parts for MoCo-based representation learning, and adopts a well-designed continual learning (CL) procedure to further pre-train the backbone subject various X-ray analysis tasks jointly. Certain strategies for image pre-processing, learning schedules, and regularization have been used to solve data heterogeneity, overfitting, and catastrophic forgetting problems for multi-task/dataset learning in MUSCLE.We evalu",
    "link": "http://arxiv.org/abs/2310.02000",
    "context": "Title: MUSCLE: Multi-task Self-supervised Continual Learning to Pre-train Deep Models for X-ray Images of Multiple Body Parts. (arXiv:2310.02000v1 [cs.CV])\nAbstract: While self-supervised learning (SSL) algorithms have been widely used to pre-train deep models, few efforts [11] have been done to improve representation learning of X-ray image analysis with SSL pre-trained models. In this work, we study a novel self-supervised pre-training pipeline, namely Multi-task Self-super-vised Continual Learning (MUSCLE), for multiple medical imaging tasks, such as classification and segmentation, using X-ray images collected from multiple body parts, including heads, lungs, and bones. Specifically, MUSCLE aggregates X-rays collected from multiple body parts for MoCo-based representation learning, and adopts a well-designed continual learning (CL) procedure to further pre-train the backbone subject various X-ray analysis tasks jointly. Certain strategies for image pre-processing, learning schedules, and regularization have been used to solve data heterogeneity, overfitting, and catastrophic forgetting problems for multi-task/dataset learning in MUSCLE.We evalu",
    "path": "papers/23/10/2310.02000.json",
    "total_tokens": 1075,
    "translated_title": "MUSCLE: 多任务自监督连续学习用于多个身体部位的X-ray图像的深度模型预训练",
    "translated_abstract": "尽管自监督学习（SSL）算法已广泛用于深度模型的预训练，但很少有研究着眼于通过自监督预训练模型提高X-ray图像分析的表示学习。在本研究中，我们研究了一种新颖的自监督预训练流程，名为多任务自监督连续学习（MUSCLE），用于多种医学影像任务，如分类和分割，使用来自多个身体部位（包括头部、肺部和骨骼）的X-ray图像。具体而言，MUSCLE通过汇集来自多个身体部位的X-ray图像进行基于MoCo的表示学习，并采用精心设计的连续学习过程，以共同预训练用于各种X-ray分析任务的骨干网络。MUSCLE中使用了图像预处理、学习计划和正则化策略来解决多任务/数据集学习中的数据异质性、过拟合和灾难性遗忘问题。我们评估了MUSCLE在不同身体部位的X-ray图像上的性能，并与其他方法进行了比较。",
    "tldr": "MUSCLE提出了一种多任务自监督连续学习（MUSCLE）的预训练流程，用于多个身体部位的X-ray图像的深度模型。它通过汇集来自多个身体部位的X-ray图像进行表示学习，并采用连续学习过程来预训练骨干网络，以应对多个X-ray分析任务中的数据异质性、过拟合和灾难性遗忘问题。"
}