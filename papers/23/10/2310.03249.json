{
    "title": "Can Large Language Models be Good Path Planners? A Benchmark and Investigation on Spatial-temporal Reasoning. (arXiv:2310.03249v1 [cs.CL])",
    "abstract": "Large language models (LLMs) have achieved remarkable success across a wide spectrum of tasks; however, they still face limitations in scenarios that demand long-term planning and spatial reasoning. To facilitate this line of research, in this work, we propose a new benchmark, termed $\\textbf{P}$ath $\\textbf{P}$lanning from $\\textbf{N}$atural $\\textbf{L}$anguage ($\\textbf{PPNL}$). Our benchmark evaluates LLMs' spatial-temporal reasoning by formulating ''path planning'' tasks that require an LLM to navigate to target locations while avoiding obstacles and adhering to constraints. Leveraging this benchmark, we systematically investigate LLMs including GPT-4 via different few-shot prompting methodologies and BART and T5 of various sizes via fine-tuning. Our experimental results show the promise of few-shot GPT-4 in spatial reasoning, when it is prompted to reason and act interleavedly, although it still fails to make long-term temporal reasoning. In contrast, while fine-tuned LLMs achieve",
    "link": "http://arxiv.org/abs/2310.03249",
    "context": "Title: Can Large Language Models be Good Path Planners? A Benchmark and Investigation on Spatial-temporal Reasoning. (arXiv:2310.03249v1 [cs.CL])\nAbstract: Large language models (LLMs) have achieved remarkable success across a wide spectrum of tasks; however, they still face limitations in scenarios that demand long-term planning and spatial reasoning. To facilitate this line of research, in this work, we propose a new benchmark, termed $\\textbf{P}$ath $\\textbf{P}$lanning from $\\textbf{N}$atural $\\textbf{L}$anguage ($\\textbf{PPNL}$). Our benchmark evaluates LLMs' spatial-temporal reasoning by formulating ''path planning'' tasks that require an LLM to navigate to target locations while avoiding obstacles and adhering to constraints. Leveraging this benchmark, we systematically investigate LLMs including GPT-4 via different few-shot prompting methodologies and BART and T5 of various sizes via fine-tuning. Our experimental results show the promise of few-shot GPT-4 in spatial reasoning, when it is prompted to reason and act interleavedly, although it still fails to make long-term temporal reasoning. In contrast, while fine-tuned LLMs achieve",
    "path": "papers/23/10/2310.03249.json",
    "total_tokens": 928,
    "translated_title": "大型语言模型能成为好的路径规划器吗？对空间-时间推理进行的基准测试和调查",
    "translated_abstract": "大型语言模型（LLM）在各种任务中取得了显著的成功，但在需要长期规划和空间推理的场景中仍然面临限制。为了促进这一研究方向，本文提出了一种新的基准测试，称为自然语言路径规划（PPNL）。我们的基准测试通过制定需要LLM导航到目标位置并避开障碍物和遵守约束条件的“路径规划”任务，评估LLM的空间-时间推理能力。利用这个基准测试，我们系统地调查了包括GPT-4在内的LLM，使用不同的少样本提示方法和各种规模的BART和T5进行微调。实验结果表明，在提示LLM进行推理和交互行动时，少样本的GPT-4在空间推理方面有希望，但仍无法进行长期时间推理。相比之下，经过微调的LLM取得了较好的结果。",
    "tldr": "本研究提出了一种新的基准测试PPNL，评估大型语言模型的空间-时间推理能力。实验结果显示，少样本的GPT-4在空间推理方面表现良好，但仍有待改进。"
}