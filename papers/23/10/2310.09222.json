{
    "title": "Fast & Efficient Learning of Bayesian Networks from Data: Knowledge Discovery and Causality. (arXiv:2310.09222v1 [cs.LG])",
    "abstract": "Structure learning is essential for Bayesian networks (BNs) as it uncovers causal relationships, and enables knowledge discovery, predictions, inferences, and decision-making under uncertainty. Two novel algorithms, FSBN and SSBN, based on the PC algorithm, employ local search strategy and conditional independence tests to learn the causal network structure from data. They incorporate d-separation to infer additional topology information, prioritize conditioning sets, and terminate the search immediately and efficiently. FSBN achieves up to 52% computation cost reduction, while SSBN surpasses it with a remarkable 72% reduction for a 200-node network. SSBN demonstrates further efficiency gains due to its intelligent strategy. Experimental studies show that both algorithms match the induction quality of the PC algorithm while significantly reducing computation costs. This enables them to offer interpretability and adaptability while reducing the computational burden, making them valuable",
    "link": "http://arxiv.org/abs/2310.09222",
    "context": "Title: Fast & Efficient Learning of Bayesian Networks from Data: Knowledge Discovery and Causality. (arXiv:2310.09222v1 [cs.LG])\nAbstract: Structure learning is essential for Bayesian networks (BNs) as it uncovers causal relationships, and enables knowledge discovery, predictions, inferences, and decision-making under uncertainty. Two novel algorithms, FSBN and SSBN, based on the PC algorithm, employ local search strategy and conditional independence tests to learn the causal network structure from data. They incorporate d-separation to infer additional topology information, prioritize conditioning sets, and terminate the search immediately and efficiently. FSBN achieves up to 52% computation cost reduction, while SSBN surpasses it with a remarkable 72% reduction for a 200-node network. SSBN demonstrates further efficiency gains due to its intelligent strategy. Experimental studies show that both algorithms match the induction quality of the PC algorithm while significantly reducing computation costs. This enables them to offer interpretability and adaptability while reducing the computational burden, making them valuable",
    "path": "papers/23/10/2310.09222.json",
    "total_tokens": 934,
    "translated_title": "从数据中快速和高效地学习贝叶斯网络：知识发现与因果关系",
    "translated_abstract": "结构学习对贝叶斯网络（BNs）至关重要，它可以揭示因果关系，并能在不确定性下进行知识发现、预测、推理和决策。基于PC算法的两个新算法FSBN和SSBN，采用局部搜索策略和条件独立性测试，从数据中学习因果网络结构。它们利用d-分离来推断额外的拓扑信息，优先考虑条件集，并高效地终止搜索。FSBN实现了高达52%的计算成本减少，而SSBN在200个节点的网络中超过了它，减少了72%的计算成本。由于智能策略，SSBN展示了进一步的效率提升。实验研究表明，这两个算法在显著降低计算成本的同时，与PC算法的归纳质量相匹配。这使得它们在减轻计算负担的同时提供了可解释性和适应性，使它们具有很高的价值。",
    "tldr": "本论文提出了两个新算法FSBN和SSBN，它们利用局部搜索和条件独立性测试从数据中学习贝叶斯网络的因果结构。实验结果表明，这两个算法在降低计算成本的同时保持了高质量的归纳，提供了可解释性和适应性。"
}