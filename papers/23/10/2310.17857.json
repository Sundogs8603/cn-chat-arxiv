{
    "title": "From Values to Opinions: Predicting Human Behaviors and Stances Using Value-Injected Large Language Models. (arXiv:2310.17857v1 [cs.CL])",
    "abstract": "Being able to predict people's opinions on issues and behaviors in realistic scenarios can be helpful in various domains, such as politics and marketing. However, conducting large-scale surveys like the European Social Survey to solicit people's opinions on individual issues can incur prohibitive costs. Leveraging prior research showing influence of core human values on individual decisions and actions, we propose to use value-injected large language models (LLM) to predict opinions and behaviors. To this end, we present Value Injection Method (VIM), a collection of two methods -- argument generation and question answering -- designed to inject targeted value distributions into LLMs via fine-tuning. We then conduct a series of experiments on four tasks to test the effectiveness of VIM and the possibility of using value-injected LLMs to predict opinions and behaviors of people. We find that LLMs value-injected with variations of VIM substantially outperform the baselines. Also, the resu",
    "link": "http://arxiv.org/abs/2310.17857",
    "context": "Title: From Values to Opinions: Predicting Human Behaviors and Stances Using Value-Injected Large Language Models. (arXiv:2310.17857v1 [cs.CL])\nAbstract: Being able to predict people's opinions on issues and behaviors in realistic scenarios can be helpful in various domains, such as politics and marketing. However, conducting large-scale surveys like the European Social Survey to solicit people's opinions on individual issues can incur prohibitive costs. Leveraging prior research showing influence of core human values on individual decisions and actions, we propose to use value-injected large language models (LLM) to predict opinions and behaviors. To this end, we present Value Injection Method (VIM), a collection of two methods -- argument generation and question answering -- designed to inject targeted value distributions into LLMs via fine-tuning. We then conduct a series of experiments on four tasks to test the effectiveness of VIM and the possibility of using value-injected LLMs to predict opinions and behaviors of people. We find that LLMs value-injected with variations of VIM substantially outperform the baselines. Also, the resu",
    "path": "papers/23/10/2310.17857.json",
    "total_tokens": 873,
    "translated_title": "从价值观到观点：利用注入价值的大型语言模型预测人类行为和立场",
    "translated_abstract": "在现实场景中能够预测人们对问题和行为的观点可以在政治和市场营销等领域中非常有帮助。然而，进行大规模调查（如欧洲社会调查）以获取人们对个别问题的意见可能会产生高昂的成本。基于先前的研究表明核心人类价值观对个人决策和行动的影响，我们提出使用注入价值的大型语言模型（LLM）来预测观点和行为。为此，我们提出了价值注入方法（VIM），这是一种由两种方法组成的集合——论据生成和问答，旨在通过微调将定向价值分布注入LLMs中。然后，我们对四个任务进行了一系列实验，以测试VIM的有效性和使用注入价值的LLM预测人们观点和行为的可能性。我们发现，注入了VIM变种的LLMs在性能上明显优于基线模型。",
    "tldr": "本研究提出了一种利用注入价值的大型语言模型（LLM）来预测人类行为和观点的方法。通过价值注入方法（VIM）对LLMs进行微调，实验结果表明注入了VIM的LLMs在预测人们观点和行为方面表现出较好的性能。"
}