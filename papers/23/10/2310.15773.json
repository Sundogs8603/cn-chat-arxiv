{
    "title": "BLESS: Benchmarking Large Language Models on Sentence Simplification. (arXiv:2310.15773v1 [cs.CL])",
    "abstract": "We present BLESS, a comprehensive performance benchmark of the most recent state-of-the-art large language models (LLMs) on the task of text simplification (TS). We examine how well off-the-shelf LLMs can solve this challenging task, assessing a total of 44 models, differing in size, architecture, pre-training methods, and accessibility, on three test sets from different domains (Wikipedia, news, and medical) under a few-shot setting. Our analysis considers a suite of automatic metrics as well as a large-scale quantitative investigation into the types of common edit operations performed by the different models. Furthermore, we perform a manual qualitative analysis on a subset of model outputs to better gauge the quality of the generated simplifications. Our evaluation indicates that the best LLMs, despite not being trained on TS, perform comparably with state-of-the-art TS baselines. Additionally, we find that certain LLMs demonstrate a greater range and diversity of edit operations. O",
    "link": "http://arxiv.org/abs/2310.15773",
    "context": "Title: BLESS: Benchmarking Large Language Models on Sentence Simplification. (arXiv:2310.15773v1 [cs.CL])\nAbstract: We present BLESS, a comprehensive performance benchmark of the most recent state-of-the-art large language models (LLMs) on the task of text simplification (TS). We examine how well off-the-shelf LLMs can solve this challenging task, assessing a total of 44 models, differing in size, architecture, pre-training methods, and accessibility, on three test sets from different domains (Wikipedia, news, and medical) under a few-shot setting. Our analysis considers a suite of automatic metrics as well as a large-scale quantitative investigation into the types of common edit operations performed by the different models. Furthermore, we perform a manual qualitative analysis on a subset of model outputs to better gauge the quality of the generated simplifications. Our evaluation indicates that the best LLMs, despite not being trained on TS, perform comparably with state-of-the-art TS baselines. Additionally, we find that certain LLMs demonstrate a greater range and diversity of edit operations. O",
    "path": "papers/23/10/2310.15773.json",
    "total_tokens": 943,
    "translated_title": "BLESS:对大型语言模型在句子简化任务上的性能进行基准测试",
    "translated_abstract": "我们提出了BLESS，这是一个全面的性能基准测试，针对最新的大型语言模型（LLMs）在文本简化任务上的表现。我们评估了共计44个模型在不同领域（维基百科、新闻和医学）的三个测试集上，涉及模型的大小、架构、预训练方法和可访问性等方面。我们的分析考虑了一系列自动评估指标，同时还进行了大规模的定量研究，探究了不同模型执行的常见编辑操作的类型。此外，我们对部分模型输出进行了手动质量分析，以更好地评估生成的简化质量。我们的评估结果表明，即使未经过句子简化的训练，最好的LLMs在性能上与最新的简化任务基线相当。此外，我们发现某些LLMs展示出更广泛和多样化的编辑操作。",
    "tldr": "BLESS是一个对大型语言模型在句子简化任务上进行基准测试的项目，评测了44个模型在不同领域的三个测试集上的性能，并发现即使未经过句子简化的训练，最好的模型性能与最新的简化任务基线相当，并且某些模型展示了更广泛和多样化的编辑操作。"
}