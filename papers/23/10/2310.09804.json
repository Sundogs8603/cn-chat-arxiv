{
    "title": "Communication Compression for Byzantine Robust Learning: New Efficient Algorithms and Improved Rates",
    "abstract": "arXiv:2310.09804v2 Announce Type: replace-cross  Abstract: Byzantine robustness is an essential feature of algorithms for certain distributed optimization problems, typically encountered in collaborative/federated learning. These problems are usually huge-scale, implying that communication compression is also imperative for their resolution. These factors have spurred recent algorithmic and theoretical developments in the literature of Byzantine-robust learning with compression. In this paper, we contribute to this research area in two main directions. First, we propose a new Byzantine-robust method with compression - Byz-DASHA-PAGE - and prove that the new method has better convergence rate (for non-convex and Polyak-Lojasiewicz smooth optimization problems), smaller neighborhood size in the heterogeneous case, and tolerates more Byzantine workers under over-parametrization than the previous method with SOTA theoretical convergence guarantees (Byz-VR-MARINA). Secondly, we develop the ",
    "link": "https://arxiv.org/abs/2310.09804",
    "context": "Title: Communication Compression for Byzantine Robust Learning: New Efficient Algorithms and Improved Rates\nAbstract: arXiv:2310.09804v2 Announce Type: replace-cross  Abstract: Byzantine robustness is an essential feature of algorithms for certain distributed optimization problems, typically encountered in collaborative/federated learning. These problems are usually huge-scale, implying that communication compression is also imperative for their resolution. These factors have spurred recent algorithmic and theoretical developments in the literature of Byzantine-robust learning with compression. In this paper, we contribute to this research area in two main directions. First, we propose a new Byzantine-robust method with compression - Byz-DASHA-PAGE - and prove that the new method has better convergence rate (for non-convex and Polyak-Lojasiewicz smooth optimization problems), smaller neighborhood size in the heterogeneous case, and tolerates more Byzantine workers under over-parametrization than the previous method with SOTA theoretical convergence guarantees (Byz-VR-MARINA). Secondly, we develop the ",
    "path": "papers/23/10/2310.09804.json",
    "total_tokens": 978,
    "translated_title": "拜占庭鲁棒学习的通信压缩：新高效算法和改进收敛速率",
    "translated_abstract": "拜占庭鲁棒性是某些分布式优化问题算法的基本特征，通常出现在协作/联邦学习中。这些问题通常规模巨大，因此通信压缩对于解决这些问题至关重要。这些因素推动了最近在拜占庭鲁棒学习与压缩领域的算法和理论发展。本文在两个主要方向上为这一研究领域做出贡献。首先，我们提出了一种新的带压缩的拜占庭鲁棒方法 - Byz-DASHA-PAGE，并证明该新方法在非凸和Polyak-Lojasiewicz平滑优化问题上具有更好的收敛速率，在异构情况下具有更小的邻域大小，并且在过参数化情况下容忍更多的拜占庭工作者，胜过具有SOTA理论收敛保证的先前方法（Byz-VR-MARINA）。其次，我们开发了…",
    "tldr": "本文提出了一种新的带压缩的拜占庭鲁棒方法 Byz-DASHA-PAGE，证明了其在非凸和Polyak-Lojasiewicz平滑优化问题上具有更好的收敛速率，同时在异构情况下具有更小的邻域大小，以及在过参数化情况下能容忍更多的拜占庭工作者。",
    "en_tdlr": "This paper introduces a new Byzantine-robust method with compression, Byz-DASHA-PAGE, showing better convergence rates for non-convex and Polyak-Lojasiewicz smooth optimization problems, smaller neighborhood sizes in heterogeneous cases, and increased tolerance for Byzantine workers under over-parametrization compared to the previous state-of-the-art method (Byz-VR-MARINA)."
}