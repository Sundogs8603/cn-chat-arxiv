{
    "title": "POE: Process of Elimination for Multiple Choice Reasoning. (arXiv:2310.15575v1 [cs.CL])",
    "abstract": "Language models (LMs) are capable of conducting in-context learning for multiple choice reasoning tasks, but the options in these tasks are treated equally. As humans often first eliminate wrong options before picking the final correct answer, we argue a similar two-step strategy can make LMs better at these tasks. To this end, we present the Process of Elimination (POE), a two-step scoring method. In the first step, POE scores each option, and eliminates seemingly wrong options. In the second step, POE masks these wrong options, and makes the final prediction from the remaining options. Zero-shot experiments on 8 reasoning tasks illustrate the effectiveness of POE, and a following analysis finds our method to be especially performant on logical reasoning tasks. We further analyze the effect of masks, and show that POE applies to few-shot settings and large language models (LLMs) like ChatGPT.",
    "link": "http://arxiv.org/abs/2310.15575",
    "context": "Title: POE: Process of Elimination for Multiple Choice Reasoning. (arXiv:2310.15575v1 [cs.CL])\nAbstract: Language models (LMs) are capable of conducting in-context learning for multiple choice reasoning tasks, but the options in these tasks are treated equally. As humans often first eliminate wrong options before picking the final correct answer, we argue a similar two-step strategy can make LMs better at these tasks. To this end, we present the Process of Elimination (POE), a two-step scoring method. In the first step, POE scores each option, and eliminates seemingly wrong options. In the second step, POE masks these wrong options, and makes the final prediction from the remaining options. Zero-shot experiments on 8 reasoning tasks illustrate the effectiveness of POE, and a following analysis finds our method to be especially performant on logical reasoning tasks. We further analyze the effect of masks, and show that POE applies to few-shot settings and large language models (LLMs) like ChatGPT.",
    "path": "papers/23/10/2310.15575.json",
    "total_tokens": 854,
    "translated_title": "POE: 多项选择推理的排除过程",
    "translated_abstract": "语言模型（LMs）能够进行多项选择推理任务的上下文学习，但是这些任务中的选项被平等对待。由于人类往往会在选择最终正确答案之前先排除错误的选项，我们认为类似的两步策略能够使LMs在这些任务中表现更好。为此，我们提出了排除过程（POE），一种两步评分方法。在第一步中，POE评分每个选项，并排除看似错误的选项。在第二步中，POE屏蔽这些错误的选项，并从剩余的选项中进行最终预测。对8个推理任务的零样本实验证明了POE的有效性，并随后的分析发现我们的方法在逻辑推理任务上表现特别好。我们进一步分析了屏蔽效果，并展示了POE适用于少样本设置和大语言模型（LLMs）如ChatGPT。",
    "tldr": "POE是一种两步策略的评分方法，通过排除看似错误的选项，提高了语言模型在多项选择推理任务上的表现。该方法在逻辑推理任务上表现特别好，并适用于少样本设置和大语言模型。"
}