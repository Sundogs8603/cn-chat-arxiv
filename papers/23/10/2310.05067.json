{
    "title": "Robust-GBDT: GBDT with Nonconvex Loss for Tabular Classification in the Presence of Label Noise and Class Imbalance",
    "abstract": "arXiv:2310.05067v2 Announce Type: replace  Abstract: Dealing with label noise in tabular classification tasks poses a persistent challenge in machine learning. While robust boosting methods have shown promise in binary classification, their effectiveness in complex, multi-class scenarios is often limited. Additionally, issues like imbalanced datasets, missing values, and computational inefficiencies further complicate their practical utility. This study introduces Robust-GBDT, a groundbreaking approach that combines the power of Gradient Boosted Decision Trees (GBDT) with the resilience of nonconvex loss functions against label noise. By leveraging local convexity within specific regions, Robust-GBDT demonstrates unprecedented robustness, challenging conventional wisdom. Through seamless integration of advanced GBDT with a novel Robust Focal Loss tailored for class imbalance, Robust-GBDT significantly enhances generalization capabilities, particularly in noisy and imbalanced datasets. ",
    "link": "https://arxiv.org/abs/2310.05067",
    "context": "Title: Robust-GBDT: GBDT with Nonconvex Loss for Tabular Classification in the Presence of Label Noise and Class Imbalance\nAbstract: arXiv:2310.05067v2 Announce Type: replace  Abstract: Dealing with label noise in tabular classification tasks poses a persistent challenge in machine learning. While robust boosting methods have shown promise in binary classification, their effectiveness in complex, multi-class scenarios is often limited. Additionally, issues like imbalanced datasets, missing values, and computational inefficiencies further complicate their practical utility. This study introduces Robust-GBDT, a groundbreaking approach that combines the power of Gradient Boosted Decision Trees (GBDT) with the resilience of nonconvex loss functions against label noise. By leveraging local convexity within specific regions, Robust-GBDT demonstrates unprecedented robustness, challenging conventional wisdom. Through seamless integration of advanced GBDT with a novel Robust Focal Loss tailored for class imbalance, Robust-GBDT significantly enhances generalization capabilities, particularly in noisy and imbalanced datasets. ",
    "path": "papers/23/10/2310.05067.json",
    "total_tokens": 910,
    "translated_title": "Robust-GBDT: 在标签噪声和类别不平衡情况下用非凸损失进行表格分类的GBDT",
    "translated_abstract": "处理表格分类任务中的标签噪声是机器学习中持久的挑战。虽然强化提升方法在二元分类中已经显示出潜力，但在复杂的多类情况下，它们的有效性通常有限。此外，不平衡数据集、缺失值和计算效率等问题进一步复杂化了它们的实际效用。本研究引入了Robust-GBDT，这是一种开创性方法，它将梯度提升决策树（GBDT）的强大能力与非凸损失函数对抗标签噪声的韧性相结合。通过利用特定区域内的局部凸性，Robust-GBDT展示了前所未有的稳健性，挑战了传统智慧。通过将先进的GBDT与针对类别不平衡量身定制的新型Robust Focal Loss进行无缝集成，Robust-GBDT显著增强了泛化能力，特别是在嘈杂和不平衡的数据集中。",
    "tldr": "Robust-GBDT结合了梯度提升决策树（GBDT）和非凸损失函数，在处理标签噪声和类别不平衡方面展现出了前所未有的稳健性和泛化能力。"
}