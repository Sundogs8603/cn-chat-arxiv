{
    "title": "Chain-of-Choice Hierarchical Policy Learning for Conversational Recommendation. (arXiv:2310.17922v1 [cs.IR])",
    "abstract": "Conversational Recommender Systems (CRS) illuminate user preferences via multi-round interactive dialogues, ultimately navigating towards precise and satisfactory recommendations. However, contemporary CRS are limited to inquiring binary or multi-choice questions based on a single attribute type (e.g., color) per round, which causes excessive rounds of interaction and diminishes the user's experience. To address this, we propose a more realistic and efficient conversational recommendation problem setting, called Multi-Type-Attribute Multi-round Conversational Recommendation (MTAMCR), which enables CRS to inquire about multi-choice questions covering multiple types of attributes in each round, thereby improving interactive efficiency. Moreover, by formulating MTAMCR as a hierarchical reinforcement learning task, we propose a Chain-of-Choice Hierarchical Policy Learning (CoCHPL) framework to enhance both the questioning efficiency and recommendation effectiveness in MTAMCR. Specifically,",
    "link": "http://arxiv.org/abs/2310.17922",
    "context": "Title: Chain-of-Choice Hierarchical Policy Learning for Conversational Recommendation. (arXiv:2310.17922v1 [cs.IR])\nAbstract: Conversational Recommender Systems (CRS) illuminate user preferences via multi-round interactive dialogues, ultimately navigating towards precise and satisfactory recommendations. However, contemporary CRS are limited to inquiring binary or multi-choice questions based on a single attribute type (e.g., color) per round, which causes excessive rounds of interaction and diminishes the user's experience. To address this, we propose a more realistic and efficient conversational recommendation problem setting, called Multi-Type-Attribute Multi-round Conversational Recommendation (MTAMCR), which enables CRS to inquire about multi-choice questions covering multiple types of attributes in each round, thereby improving interactive efficiency. Moreover, by formulating MTAMCR as a hierarchical reinforcement learning task, we propose a Chain-of-Choice Hierarchical Policy Learning (CoCHPL) framework to enhance both the questioning efficiency and recommendation effectiveness in MTAMCR. Specifically,",
    "path": "papers/23/10/2310.17922.json",
    "total_tokens": 874,
    "translated_title": "Chain-of-Choice层次化策略学习用于对话推荐",
    "translated_abstract": "对话推荐系统通过多轮互动对话来揭示用户偏好，最终导向精确和满意的推荐。然而，现有的对话推荐系统仅限于根据每轮单个属性类型（如颜色）询问二进制或多选题，导致互动轮数过多，降低了用户体验。为解决这个问题，我们提出了一种更现实和高效的对话推荐问题设定，称为多类型属性多轮对话推荐（MTAMCR），该问题设定使得对话推荐系统能够在每轮中询问涵盖多个属性类型的多选题，从而提高互动效率。此外，通过将MTAMCR定义为一项层次化强化学习任务，我们提出了一种Chain-of-Choice层次化策略学习（CoCHPL）框架来提高MTAMCR中的询问效率和推荐效果。",
    "tldr": "提出了一种称为MTAMCR的对话推荐问题设定，通过每轮询问涵盖多个属性类型的多选题，提高了互动效率。同时，通过Chain-of-Choice层次化策略学习框架，提高了对话推荐系统的询问效率和推荐效果。"
}