{
    "title": "Causal Unsupervised Semantic Segmentation. (arXiv:2310.07379v1 [cs.CV])",
    "abstract": "Unsupervised semantic segmentation aims to achieve high-quality semantic grouping without human-labeled annotations. With the advent of self-supervised pre-training, various frameworks utilize the pre-trained features to train prediction heads for unsupervised dense prediction. However, a significant challenge in this unsupervised setup is determining the appropriate level of clustering required for segmenting concepts. To address it, we propose a novel framework, CAusal Unsupervised Semantic sEgmentation (CAUSE), which leverages insights from causal inference. Specifically, we bridge intervention-oriented approach (i.e., frontdoor adjustment) to define suitable two-step tasks for unsupervised prediction. The first step involves constructing a concept clusterbook as a mediator, which represents possible concept prototypes at different levels of granularity in a discretized form. Then, the mediator establishes an explicit link to the subsequent concept-wise self-supervised learning for ",
    "link": "http://arxiv.org/abs/2310.07379",
    "context": "Title: Causal Unsupervised Semantic Segmentation. (arXiv:2310.07379v1 [cs.CV])\nAbstract: Unsupervised semantic segmentation aims to achieve high-quality semantic grouping without human-labeled annotations. With the advent of self-supervised pre-training, various frameworks utilize the pre-trained features to train prediction heads for unsupervised dense prediction. However, a significant challenge in this unsupervised setup is determining the appropriate level of clustering required for segmenting concepts. To address it, we propose a novel framework, CAusal Unsupervised Semantic sEgmentation (CAUSE), which leverages insights from causal inference. Specifically, we bridge intervention-oriented approach (i.e., frontdoor adjustment) to define suitable two-step tasks for unsupervised prediction. The first step involves constructing a concept clusterbook as a mediator, which represents possible concept prototypes at different levels of granularity in a discretized form. Then, the mediator establishes an explicit link to the subsequent concept-wise self-supervised learning for ",
    "path": "papers/23/10/2310.07379.json",
    "total_tokens": 922,
    "translated_title": "因果无监督语义分割",
    "translated_abstract": "无监督语义分割旨在在没有人工标注注释的情况下实现高质量的语义分组。随着自监督预训练的出现，各种框架利用预训练特征训练无监督密集预测的预测头。然而，在这种无监督设置中的一个重要挑战是确定用于分割概念所需的适当聚类水平。为了解决这个问题，我们提出了一个新的框架，称为因果无监督语义分割（CAUSE），它利用了因果推断的见解。具体而言，我们桥接了面向干预的方法（即前门调整），以定义适合无监督预测的两步任务。第一步涉及构建一个概念聚类表作为中介，以离散形式表示不同粒度层次上的可能概念原型。然后，中介与随后的概念自监督学习建立了明确的联系...",
    "tldr": "因果无监督语义分割（CAUSE）是一个利用因果推断的新框架，旨在实现无监督语义分割。该方法通过构建概念聚类表作为中介，并与概念自监督学习建立联系，解决了无监督分割中适当聚类水平的挑战。"
}