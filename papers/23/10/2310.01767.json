{
    "title": "Differentially Encoded Observation Spaces for Perceptive Reinforcement Learning. (arXiv:2310.01767v1 [cs.RO])",
    "abstract": "Perceptive deep reinforcement learning (DRL) has lead to many recent breakthroughs for complex AI systems leveraging image-based input data. Applications of these results range from super-human level video game agents to dexterous, physically intelligent robots. However, training these perceptive DRL-enabled systems remains incredibly compute and memory intensive, often requiring huge training datasets and large experience replay buffers. This poses a challenge for the next generation of field robots that will need to be able to learn on the edge in order to adapt to their environments. In this paper, we begin to address this issue through differentially encoded observation spaces. By reinterpreting stored image-based observations as a video, we leverage lossless differential video encoding schemes to compress the replay buffer without impacting training performance. We evaluate our approach with three state-of-the-art DRL algorithms and find that differential image encoding reduces th",
    "link": "http://arxiv.org/abs/2310.01767",
    "context": "Title: Differentially Encoded Observation Spaces for Perceptive Reinforcement Learning. (arXiv:2310.01767v1 [cs.RO])\nAbstract: Perceptive deep reinforcement learning (DRL) has lead to many recent breakthroughs for complex AI systems leveraging image-based input data. Applications of these results range from super-human level video game agents to dexterous, physically intelligent robots. However, training these perceptive DRL-enabled systems remains incredibly compute and memory intensive, often requiring huge training datasets and large experience replay buffers. This poses a challenge for the next generation of field robots that will need to be able to learn on the edge in order to adapt to their environments. In this paper, we begin to address this issue through differentially encoded observation spaces. By reinterpreting stored image-based observations as a video, we leverage lossless differential video encoding schemes to compress the replay buffer without impacting training performance. We evaluate our approach with three state-of-the-art DRL algorithms and find that differential image encoding reduces th",
    "path": "papers/23/10/2310.01767.json",
    "total_tokens": 855,
    "translated_title": "差分编码观测空间在感知增强学习中的应用",
    "translated_abstract": "感知增强学习（Perceptive deep reinforcement learning，DRL）在利用基于图像的输入数据的复杂AI系统中取得了许多突破。这些结果的应用范围从超人级别的视频游戏代理到灵巧、具有物理智能的机器人。然而，训练这些感知DRL系统仍然需要大量的计算和内存资源，通常需要庞大的训练数据集和大容量的经验回放缓冲区。这对未来一代的现场机器人来说是一个挑战，他们需要能够在边缘学习，以适应环境变化。在本文中，我们通过差分编码观测空间来解决这个问题。通过将存储的基于图像的观测重解释为视频，我们利用无损差分视频编码方案来压缩经验回放缓冲区，而不影响训练性能。我们使用三种最先进的DRL算法评估了我们的方法，并发现差分图像编码可以降低训练的计算和内存需求。",
    "tldr": "使用差分编码观测空间来降低感知增强学习（DRL）系统训练的计算和内存需求。",
    "en_tdlr": "Reducing computational and memory requirements for training perceptive deep reinforcement learning (DRL) systems by utilizing differentially encoded observation spaces."
}