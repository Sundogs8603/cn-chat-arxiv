{
    "title": "Efficient Subgraph GNNs by Learning Effective Selection Policies. (arXiv:2310.20082v1 [cs.LG])",
    "abstract": "Subgraph GNNs are provably expressive neural architectures that learn graph representations from sets of subgraphs. Unfortunately, their applicability is hampered by the computational complexity associated with performing message passing on many subgraphs. In this paper, we consider the problem of learning to select a small subset of the large set of possible subgraphs in a data-driven fashion. We first motivate the problem by proving that there are families of WL-indistinguishable graphs for which there exist efficient subgraph selection policies: small subsets of subgraphs that can already identify all the graphs within the family. We then propose a new approach, called Policy-Learn, that learns how to select subgraphs in an iterative manner. We prove that, unlike popular random policies and prior work addressing the same problem, our architecture is able to learn the efficient policies mentioned above. Our experimental results demonstrate that Policy-Learn outperforms existing basel",
    "link": "http://arxiv.org/abs/2310.20082",
    "context": "Title: Efficient Subgraph GNNs by Learning Effective Selection Policies. (arXiv:2310.20082v1 [cs.LG])\nAbstract: Subgraph GNNs are provably expressive neural architectures that learn graph representations from sets of subgraphs. Unfortunately, their applicability is hampered by the computational complexity associated with performing message passing on many subgraphs. In this paper, we consider the problem of learning to select a small subset of the large set of possible subgraphs in a data-driven fashion. We first motivate the problem by proving that there are families of WL-indistinguishable graphs for which there exist efficient subgraph selection policies: small subsets of subgraphs that can already identify all the graphs within the family. We then propose a new approach, called Policy-Learn, that learns how to select subgraphs in an iterative manner. We prove that, unlike popular random policies and prior work addressing the same problem, our architecture is able to learn the efficient policies mentioned above. Our experimental results demonstrate that Policy-Learn outperforms existing basel",
    "path": "papers/23/10/2310.20082.json",
    "total_tokens": 802,
    "translated_title": "通过学习有效的选择策略提高子图图神经网络的效率",
    "translated_abstract": "子图图神经网络是一种可证明表达力的神经架构，可以从一组子图中学习图表示。然而，由于在许多子图上执行信息传递所带来的计算复杂性，它们的适用性受到了限制。本文考虑以数据驱动方式学习如何选择一个小的子图子集的问题。我们首先通过证明存在一些WL-难区分的图族，这些图族存在可以识别该族中所有图的有效子图选择策略，来解释这个问题。然后，我们提出了一种名为Policy-Learn的新方法，以迭代方式学习如何选择子图。我们证明，与常用的随机策略和解决相同问题的先前工作不同，我们的架构能够学习到上述高效策略。我们的实验结果表明，Policy-Learn的性能优于现有的基准方法。",
    "tldr": "本文通过学习有效的选择策略提高了子图图神经网络的效率，并且实验证明该方法优于现有的基准方法。",
    "en_tdlr": "This paper improves the efficiency of subgraph graph neural networks by learning effective selection policies, which outperforms existing baseline methods."
}