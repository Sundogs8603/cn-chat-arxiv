{
    "title": "Backdoor Attack through Machine Unlearning. (arXiv:2310.10659v1 [cs.CR])",
    "abstract": "In recent years, the security issues of artificial intelligence have become increasingly prominent due to the rapid development of deep learning research and applications. Backdoor attack is an attack targeting the vulnerability of deep learning models, where hidden backdoors are activated by triggers embedded by the attacker, thereby outputting malicious predictions that may not align with the intended output for a given input. In this work, we propose a novel black-box backdoor attack based on machine unlearning. The attacker first augments the training set with carefully designed samples, including poison and mitigation data, to train a 'benign' model. Then, the attacker posts unlearning requests for the mitigation samples to remove the impact of relevant data on the model, gradually activating the hidden backdoor. Since backdoors are implanted during the iterative unlearning process, it significantly increases the computational overhead of existing defense methods for backdoor dete",
    "link": "http://arxiv.org/abs/2310.10659",
    "context": "Title: Backdoor Attack through Machine Unlearning. (arXiv:2310.10659v1 [cs.CR])\nAbstract: In recent years, the security issues of artificial intelligence have become increasingly prominent due to the rapid development of deep learning research and applications. Backdoor attack is an attack targeting the vulnerability of deep learning models, where hidden backdoors are activated by triggers embedded by the attacker, thereby outputting malicious predictions that may not align with the intended output for a given input. In this work, we propose a novel black-box backdoor attack based on machine unlearning. The attacker first augments the training set with carefully designed samples, including poison and mitigation data, to train a 'benign' model. Then, the attacker posts unlearning requests for the mitigation samples to remove the impact of relevant data on the model, gradually activating the hidden backdoor. Since backdoors are implanted during the iterative unlearning process, it significantly increases the computational overhead of existing defense methods for backdoor dete",
    "path": "papers/23/10/2310.10659.json",
    "total_tokens": 842,
    "translated_title": "通过机器遗忘实施后门攻击",
    "translated_abstract": "最近几年，由于深度学习研究和应用的快速发展，人工智能的安全问题变得越来越突出。后门攻击是一种针对深度学习模型的攻击，攻击者通过嵌入的触发器激活隐藏的后门，从而输出可能与给定输入的预期输出不符的恶意预测。在本文中，我们提出了一种基于机器遗忘的新型黑盒后门攻击。攻击者首先通过精心设计的样本（包括毒数据和缓解数据）扩充训练集，训练一个“善意”模型。然后，攻击者提交遗忘请求，以移除缓解样本对模型的影响，逐步激活隐藏的后门。由于后门是在迭代的遗忘过程中植入的，这显著增加了现有的后门检测方法的计算开销。",
    "tldr": "本文提出了一种基于机器遗忘的新型黑盒后门攻击方法，通过激活隐藏后门来输出恶意预测，从而针对深度学习模型的脆弱性进行攻击。",
    "en_tdlr": "This paper proposes a new black-box backdoor attack method based on machine unlearning, which activates hidden backdoors to output malicious predictions, thereby attacking the vulnerability of deep learning models."
}