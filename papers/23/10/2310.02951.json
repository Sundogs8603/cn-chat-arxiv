{
    "title": "A Fisher-Rao gradient flow for entropy-regularised Markov decision processes in Polish spaces. (arXiv:2310.02951v1 [math.OC])",
    "abstract": "We study the global convergence of a Fisher-Rao policy gradient flow for infinite-horizon entropy-regularised Markov decision processes with Polish state and action space. The flow is a continuous-time analogue of a policy mirror descent method. We establish the global well-posedness of the gradient flow and demonstrate its exponential convergence to the optimal policy. Moreover, we prove the flow is stable with respect to gradient evaluation, offering insights into the performance of a natural policy gradient flow with log-linear policy parameterisation. To overcome challenges stemming from the lack of the convexity of the objective function and the discontinuity arising from the entropy regulariser, we leverage the performance difference lemma and the duality relationship between the gradient and mirror descent flows.",
    "link": "http://arxiv.org/abs/2310.02951",
    "context": "Title: A Fisher-Rao gradient flow for entropy-regularised Markov decision processes in Polish spaces. (arXiv:2310.02951v1 [math.OC])\nAbstract: We study the global convergence of a Fisher-Rao policy gradient flow for infinite-horizon entropy-regularised Markov decision processes with Polish state and action space. The flow is a continuous-time analogue of a policy mirror descent method. We establish the global well-posedness of the gradient flow and demonstrate its exponential convergence to the optimal policy. Moreover, we prove the flow is stable with respect to gradient evaluation, offering insights into the performance of a natural policy gradient flow with log-linear policy parameterisation. To overcome challenges stemming from the lack of the convexity of the objective function and the discontinuity arising from the entropy regulariser, we leverage the performance difference lemma and the duality relationship between the gradient and mirror descent flows.",
    "path": "papers/23/10/2310.02951.json",
    "total_tokens": 860,
    "translated_title": "Fisher-Rao梯度流在Polish空间中对熵正则化Markov决策过程的研究",
    "translated_abstract": "我们研究了在Polish状态和动作空间中无限时域的熵正则化的Markov决策过程的Fisher-Rao策略梯度流的全局收敛性。这个流是策略镜像下降方法的连续时间类比。我们证明了梯度流的全局良定义性，并展示了它对最优策略的指数收敛性。此外，我们证明了梯度流在梯度评估方面的稳定性，为对数线性策略参数化的自然策略梯度流的性能提供了洞见。为了克服目标函数非凸性和熵正则化引起的不连续性所带来的挑战，我们利用性能差别引理和梯度与镜像下降流之间的对偶关系。",
    "tldr": "该论文研究了在Polish空间中的熵正则化Markov决策过程上的Fisher-Rao策略梯度流的全局收敛性和指数收敛性，并证明了梯度流在梯度评估方面的稳定性，为自然策略梯度流的性能提供了洞见。"
}