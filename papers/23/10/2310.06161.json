{
    "title": "Mitigating Simplicity Bias in Deep Learning for Improved OOD Generalization and Robustness. (arXiv:2310.06161v1 [cs.LG])",
    "abstract": "Neural networks (NNs) are known to exhibit simplicity bias where they tend to prefer learning 'simple' features over more 'complex' ones, even when the latter may be more informative. Simplicity bias can lead to the model making biased predictions which have poor out-of-distribution (OOD) generalization. To address this, we propose a framework that encourages the model to use a more diverse set of features to make predictions. We first train a simple model, and then regularize the conditional mutual information with respect to it to obtain the final model. We demonstrate the effectiveness of this framework in various problem settings and real-world applications, showing that it effectively addresses simplicity bias and leads to more features being used, enhances OOD generalization, and improves subgroup robustness and fairness. We complement these results with theoretical analyses of the effect of the regularization and its OOD generalization properties.",
    "link": "http://arxiv.org/abs/2310.06161",
    "context": "Title: Mitigating Simplicity Bias in Deep Learning for Improved OOD Generalization and Robustness. (arXiv:2310.06161v1 [cs.LG])\nAbstract: Neural networks (NNs) are known to exhibit simplicity bias where they tend to prefer learning 'simple' features over more 'complex' ones, even when the latter may be more informative. Simplicity bias can lead to the model making biased predictions which have poor out-of-distribution (OOD) generalization. To address this, we propose a framework that encourages the model to use a more diverse set of features to make predictions. We first train a simple model, and then regularize the conditional mutual information with respect to it to obtain the final model. We demonstrate the effectiveness of this framework in various problem settings and real-world applications, showing that it effectively addresses simplicity bias and leads to more features being used, enhances OOD generalization, and improves subgroup robustness and fairness. We complement these results with theoretical analyses of the effect of the regularization and its OOD generalization properties.",
    "path": "papers/23/10/2310.06161.json",
    "total_tokens": 877,
    "translated_title": "减轻深度学习中的简单性偏差以改善OOD推广和鲁棒性",
    "translated_abstract": "神经网络已知存在简单性偏差，即它们倾向于学习“简单”特征而不是更“复杂”的特征，即使后者可能更具信息量。简单性偏差可能导致模型做出具有较差的OOD推广的偏见性预测。为了解决这个问题，我们提出了一个框架，鼓励模型使用更多样的特征进行预测。我们首先训练一个简单模型，然后使用条件互信息对其进行正则化，得到最终模型。我们在各种问题设置和真实世界应用中展示了这个框架的有效性，证明它有效地解决了简单性偏差，促使更多特征被使用，增强了OOD推广，并提高了子组鲁棒性和公平性。我们补充这些结果与对正则化效果及其OOD推广特性的理论分析。",
    "tldr": "本论文提出了一个框架，鼓励深度模型利用更多样的特征进行预测，以减轻简单性偏差带来的OOD推广问题，并在各种问题和应用中展示了其有效性。",
    "en_tdlr": "This paper proposes a framework that encourages deep models to use more diverse features for predictions, mitigating the simplicity bias and improving OOD generalization. The effectiveness of this framework is demonstrated in various problem settings and real-world applications."
}