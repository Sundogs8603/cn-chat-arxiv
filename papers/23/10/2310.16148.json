{
    "title": "Yin Yang Convolutional Nets: Image Manifold Extraction by the Analysis of Opposites. (arXiv:2310.16148v1 [cs.CV])",
    "abstract": "Computer vision in general presented several advances such as training optimizations, new architectures (pure attention, efficient block, vision language models, generative models, among others). This have improved performance in several tasks such as classification, and others. However, the majority of these models focus on modifications that are taking distance from realistic neuroscientific approaches related to the brain. In this work, we adopt a more bio-inspired approach and present the Yin Yang Convolutional Network, an architecture that extracts visual manifold, its blocks are intended to separate analysis of colors and forms at its initial layers, simulating occipital lobe's operations. Our results shows that our architecture provides State-of-the-Art efficiency among low parameter architectures in the dataset CIFAR-10. Our first model reached 93.32\\% test accuracy, 0.8\\% more than the older SOTA in this category, while having 150k less parameters (726k in total). Our second m",
    "link": "http://arxiv.org/abs/2310.16148",
    "context": "Title: Yin Yang Convolutional Nets: Image Manifold Extraction by the Analysis of Opposites. (arXiv:2310.16148v1 [cs.CV])\nAbstract: Computer vision in general presented several advances such as training optimizations, new architectures (pure attention, efficient block, vision language models, generative models, among others). This have improved performance in several tasks such as classification, and others. However, the majority of these models focus on modifications that are taking distance from realistic neuroscientific approaches related to the brain. In this work, we adopt a more bio-inspired approach and present the Yin Yang Convolutional Network, an architecture that extracts visual manifold, its blocks are intended to separate analysis of colors and forms at its initial layers, simulating occipital lobe's operations. Our results shows that our architecture provides State-of-the-Art efficiency among low parameter architectures in the dataset CIFAR-10. Our first model reached 93.32\\% test accuracy, 0.8\\% more than the older SOTA in this category, while having 150k less parameters (726k in total). Our second m",
    "path": "papers/23/10/2310.16148.json",
    "total_tokens": 882,
    "translated_title": "Yin Yang卷积网络：通过对立分析提取图像流形",
    "translated_abstract": "计算机视觉在训练优化、新的架构（纯注意力、高效块、视觉语言模型、生成模型等）等方面取得了一些进步。这些进步改善了分类等多个任务的性能。然而，大多数这些模型都集中于与大脑相关的现实神经科学方法的修改。在这项工作中，我们采用更具生物启发的方法，并提出了Yin Yang卷积网络，这是一种提取视觉流形的架构，它的块旨在在初始层分离颜色和形状的分析，模拟枕叶的操作。我们的结果表明，在CIFAR-10数据集上，我们的架构在参数较低的架构中提供了最先进的效能。我们的第一个模型达到了93.32％的测试准确率，比该类别中更早的最佳结果高出0.8％，同时参数减少了15万个（总共726k）。",
    "tldr": "提出了Yin Yang卷积网络，通过对立分析提取图像流形，在CIFAR-10数据集上达到了State-of-the-Art的效能，并且相对于之前的SOTA模型，参数减少了150k。",
    "en_tdlr": "Yin Yang Convolutional Network is proposed to extract image manifold through the analysis of opposites. It achieves State-of-the-Art efficiency on the CIFAR-10 dataset with 150k fewer parameters compared to the previous SOTA model."
}