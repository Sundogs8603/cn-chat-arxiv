{
    "title": "Recovery of Training Data from Overparameterized Autoencoders: An Inverse Problem Perspective. (arXiv:2310.02897v1 [cs.LG])",
    "abstract": "We study the recovery of training data from overparameterized autoencoder models. Given a degraded training sample, we define the recovery of the original sample as an inverse problem and formulate it as an optimization task. In our inverse problem, we use the trained autoencoder to implicitly define a regularizer for the particular training dataset that we aim to retrieve from. We develop the intricate optimization task into a practical method that iteratively applies the trained autoencoder and relatively simple computations that estimate and address the unknown degradation operator. We evaluate our method for blind inpainting where the goal is to recover training images from degradation of many missing pixels in an unknown pattern. We examine various deep autoencoder architectures, such as fully connected and U-Net (with various nonlinearities and at diverse train loss values), and show that our method significantly outperforms previous methods for training data recovery from autoen",
    "link": "http://arxiv.org/abs/2310.02897",
    "context": "Title: Recovery of Training Data from Overparameterized Autoencoders: An Inverse Problem Perspective. (arXiv:2310.02897v1 [cs.LG])\nAbstract: We study the recovery of training data from overparameterized autoencoder models. Given a degraded training sample, we define the recovery of the original sample as an inverse problem and formulate it as an optimization task. In our inverse problem, we use the trained autoencoder to implicitly define a regularizer for the particular training dataset that we aim to retrieve from. We develop the intricate optimization task into a practical method that iteratively applies the trained autoencoder and relatively simple computations that estimate and address the unknown degradation operator. We evaluate our method for blind inpainting where the goal is to recover training images from degradation of many missing pixels in an unknown pattern. We examine various deep autoencoder architectures, such as fully connected and U-Net (with various nonlinearities and at diverse train loss values), and show that our method significantly outperforms previous methods for training data recovery from autoen",
    "path": "papers/23/10/2310.02897.json",
    "total_tokens": 967,
    "translated_title": "从过参数自编码器中恢复训练数据：逆问题的观点",
    "translated_abstract": "我们研究了从过参数自编码器模型中恢复训练数据的问题。给定一个退化的训练样本，我们将原始样本的恢复定义为一个逆问题，并将其构建为一个优化任务。在我们的逆问题中，我们使用训练好的自编码器来隐式地定义一个正则化器，用于从特定的训练数据集中检索。我们将复杂的优化任务开发成一个实际方法，该方法迭代地应用训练好的自编码器和相对简单的计算来估计和处理未知的退化操作符。我们将该方法应用于盲目修补，目标是从许多缺失的像素中恢复训练图像，而这些缺失的像素是按照未知的模式进行的。我们检验了各种深度自编码器架构，如全连接和U-Net（具有不同的非线性和多样的训练损失值），并且证明了我们的方法明显优于以前的自编码器恢复训练数据的方法。",
    "tldr": "本研究从逆问题的角度研究了从过参数自编码器模型恢复训练数据的问题，并提出了一种实际方法，该方法利用训练好的自编码器来定义正则化器并通过迭代计算处理未知的退化操作符。实验结果表明，该方法在自编码器恢复训练数据方面具有显著的优势。",
    "en_tdlr": "This paper investigates the recovery of training data from overparameterized autoencoder models by formulating it as an inverse problem and developing a practical method that utilizes the trained autoencoder to define a regularizer and address unknown degradation operators. Experimental results show that the proposed method outperforms previous approaches in recovering training data from autoencoders."
}