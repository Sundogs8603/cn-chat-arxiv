{
    "title": "MM-BigBench: Evaluating Multimodal Models on Multimodal Content Comprehension Tasks. (arXiv:2310.09036v1 [cs.CL])",
    "abstract": "The popularity of multimodal large language models (MLLMs) has triggered a recent surge in research efforts dedicated to evaluating these models. Nevertheless, existing evaluation studies of MLLMs primarily focus on the comprehension and reasoning of unimodal (vision) content, neglecting performance evaluations in the domain of multimodal (vision-language) content understanding. Beyond multimodal reasoning, tasks related to multimodal content comprehension necessitate a profound understanding of multimodal contexts, achieved through the multimodal interaction to obtain a final answer. In this paper, we introduce a comprehensive assessment framework called MM-BigBench, which incorporates a diverse range of metrics to offer an extensive evaluation of the performance of various models and instructions across a wide spectrum of diverse multimodal content comprehension tasks. Consequently, our work complements research on the performance of MLLMs in multimodal comprehension tasks, achieving",
    "link": "http://arxiv.org/abs/2310.09036",
    "context": "Title: MM-BigBench: Evaluating Multimodal Models on Multimodal Content Comprehension Tasks. (arXiv:2310.09036v1 [cs.CL])\nAbstract: The popularity of multimodal large language models (MLLMs) has triggered a recent surge in research efforts dedicated to evaluating these models. Nevertheless, existing evaluation studies of MLLMs primarily focus on the comprehension and reasoning of unimodal (vision) content, neglecting performance evaluations in the domain of multimodal (vision-language) content understanding. Beyond multimodal reasoning, tasks related to multimodal content comprehension necessitate a profound understanding of multimodal contexts, achieved through the multimodal interaction to obtain a final answer. In this paper, we introduce a comprehensive assessment framework called MM-BigBench, which incorporates a diverse range of metrics to offer an extensive evaluation of the performance of various models and instructions across a wide spectrum of diverse multimodal content comprehension tasks. Consequently, our work complements research on the performance of MLLMs in multimodal comprehension tasks, achieving",
    "path": "papers/23/10/2310.09036.json",
    "total_tokens": 809,
    "translated_title": "MM-BigBench: 在多模态内容理解任务上评估多模态模型",
    "translated_abstract": "多模态大型语言模型（MLLMs）的流行引发了近期对这些模型的评估的研究努力的激增。然而，现有的MLLMs评估研究主要关注对单模态（视觉）内容的理解和推理，忽视了在多模态（视觉-语言）内容理解领域的性能评估。除了多模态推理外，与多模态内容理解相关的任务需要对多模态上下文的深入理解，通过多模态交互来获得最终答案。在本文中，我们引入了一个全面的评估框架，称为MM-BigBench，它包含了各种指标，以广泛评估不同模型和指示在多样化的多模态内容理解任务中的性能。因此，我们的工作补充了关于MLLMs在多模态理解任务中性能的研究。",
    "tldr": "MM-BigBench是一个评估多模态模型在多模态内容理解任务上表现的综合评估框架，通过多模态交互来实现对多模态上下文的深入理解，并提供广泛的性能评估指标。"
}