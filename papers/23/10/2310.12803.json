{
    "title": "Causal-structure Driven Augmentations for Text OOD Generalization. (arXiv:2310.12803v1 [cs.LG])",
    "abstract": "The reliance of text classifiers on spurious correlations can lead to poor generalization at deployment, raising concerns about their use in safety-critical domains such as healthcare. In this work, we propose to use counterfactual data augmentation, guided by knowledge of the causal structure of the data, to simulate interventions on spurious features and to learn more robust text classifiers. We show that this strategy is appropriate in prediction problems where the label is spuriously correlated with an attribute. Under the assumptions of such problems, we discuss the favorable sample complexity of counterfactual data augmentation, compared to importance re-weighting. Pragmatically, we match examples using auxiliary data, based on diff-in-diff methodology, and use a large language model (LLM) to represent a conditional probability of text. Through extensive experimentation on learning caregiver-invariant predictors of clinical diagnoses from medical narratives and on semi-synthetic ",
    "link": "http://arxiv.org/abs/2310.12803",
    "context": "Title: Causal-structure Driven Augmentations for Text OOD Generalization. (arXiv:2310.12803v1 [cs.LG])\nAbstract: The reliance of text classifiers on spurious correlations can lead to poor generalization at deployment, raising concerns about their use in safety-critical domains such as healthcare. In this work, we propose to use counterfactual data augmentation, guided by knowledge of the causal structure of the data, to simulate interventions on spurious features and to learn more robust text classifiers. We show that this strategy is appropriate in prediction problems where the label is spuriously correlated with an attribute. Under the assumptions of such problems, we discuss the favorable sample complexity of counterfactual data augmentation, compared to importance re-weighting. Pragmatically, we match examples using auxiliary data, based on diff-in-diff methodology, and use a large language model (LLM) to represent a conditional probability of text. Through extensive experimentation on learning caregiver-invariant predictors of clinical diagnoses from medical narratives and on semi-synthetic ",
    "path": "papers/23/10/2310.12803.json",
    "total_tokens": 885,
    "translated_title": "基于因果结构的文本离群值泛化增强方法",
    "translated_abstract": "文本分类器对虚假相关性的依赖可能导致在实际应用中的泛化效果不佳，这引发了对其在如医疗领域等安全关键行业中使用的担忧。在本研究中，我们提出使用因果结构知识指导的反事实数据增强方法，模拟对虚假特征进行干预，以学习更加鲁棒的文本分类器。我们证明了在标签与属性之间存在虚假相关性的预测问题中，这种策略是合适的。在这种问题的假设下，我们讨论了反事实数据增强相对于重要性重加权的有利样本复杂性。实际上，我们使用辅助数据通过差分在差分的方法来匹配样本，并使用大型语言模型（LLM）来表示文本的条件概率。通过对从医学叙述中学习与看护者无关的临床诊断预测器以及半合成数据上进行了广泛的实验。",
    "tldr": "本文提出了一种基于因果结构的反事实数据增强方法，用于改善文本分类器在应用中的泛化效果，特别适用于存在虚假相关性的标签与属性预测问题。",
    "en_tdlr": "This paper proposes a causal-structure guided counterfactual data augmentation method to improve the generalization performance of text classifiers, particularly for prediction problems where there are spurious correlations between labels and attributes."
}