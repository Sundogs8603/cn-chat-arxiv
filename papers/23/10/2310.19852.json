{
    "title": "AI Alignment: A Comprehensive Survey. (arXiv:2310.19852v1 [cs.AI])",
    "abstract": "AI alignment aims to build AI systems that are in accordance with human intentions and values. With the emergence of AI systems possessing superhuman capabilities, the potential large-scale risks associated with misaligned systems become apparent. Hundreds of AI experts and public figures have expressed their concerns about AI risks, arguing that mitigating the risk of extinction from AI should be a global priority, alongside other societal-scale risks such as pandemics and nuclear war. Motivated by the lack of an up-to-date systematic survey on AI alignment, in this paper, we delve into the core concepts, methodology, and practice of alignment research. To begin with, we identify four principles as the key objectives of AI alignment: Robustness, Interpretability, Controllability, and Ethicality (RICE). We outline the landscape of current alignment research and decompose them into two key components: forward alignment and backward alignment. The former aims to make AI systems aligned v",
    "link": "http://arxiv.org/abs/2310.19852",
    "context": "Title: AI Alignment: A Comprehensive Survey. (arXiv:2310.19852v1 [cs.AI])\nAbstract: AI alignment aims to build AI systems that are in accordance with human intentions and values. With the emergence of AI systems possessing superhuman capabilities, the potential large-scale risks associated with misaligned systems become apparent. Hundreds of AI experts and public figures have expressed their concerns about AI risks, arguing that mitigating the risk of extinction from AI should be a global priority, alongside other societal-scale risks such as pandemics and nuclear war. Motivated by the lack of an up-to-date systematic survey on AI alignment, in this paper, we delve into the core concepts, methodology, and practice of alignment research. To begin with, we identify four principles as the key objectives of AI alignment: Robustness, Interpretability, Controllability, and Ethicality (RICE). We outline the landscape of current alignment research and decompose them into two key components: forward alignment and backward alignment. The former aims to make AI systems aligned v",
    "path": "papers/23/10/2310.19852.json",
    "total_tokens": 917,
    "translated_title": "AI对齐: 一项全面调查",
    "translated_abstract": "AI对齐旨在构建符合人类意图和价值观的AI系统。随着拥有超人类能力的AI系统的出现，错误对齐系统所带来的潜在大规模风险变得明显。数百名AI专家和公众人物都对AI风险表达了关注，认为减轻AI带来的灭绝风险应该成为全球的优先事项，与大规模社会风险如大流行病和核战争并列。鉴于AI对齐领域缺乏最新的系统调查，本文深入探讨对齐研究的核心概念、方法论和实践。首先，我们确定了四个目标原则作为AI对齐的关键目标：健壮性、可解释性、可控性和道德性（RICE）。我们概述了当前对齐研究的现状，并将其分解为两个关键组成部分：前向对齐和后向对齐。前者旨在使AI系统与人类意图对齐。",
    "tldr": "本篇论文主要介绍了AI对齐的概念、方法和实践。研究围绕四个关键目标：健壮性、可解释性、可控性和道德性展开，并将其分为前向对齐和后向对齐两个部分。 AI对齐是为了构建符合人类意图和价值观的AI系统，并减轻由于系统不对齐带来的潜在风险。"
}