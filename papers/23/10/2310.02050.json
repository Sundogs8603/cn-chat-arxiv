{
    "title": "Tuning Large language model for End-to-end Speech Translation. (arXiv:2310.02050v1 [cs.CL])",
    "abstract": "With the emergence of large language models (LLMs), multimodal models based on LLMs have demonstrated significant potential. Models such as LLaSM, X-LLM, and SpeechGPT exhibit an impressive ability to comprehend and generate human instructions. However, their performance often falters when faced with complex tasks like end-to-end speech translation (E2E-ST), a cross-language and cross-modal translation task. In comparison to single-modal models, multimodal models lag behind in these scenarios. This paper introduces LST, a Large multimodal model designed to excel at the E2E-ST task. LST consists of a speech frontend, an adapter, and a LLM backend. The training of LST consists of two stages: (1) Modality adjustment, where the adapter is tuned to align speech representation with text embedding space, and (2) Downstream task fine-tuning, where both the adapter and LLM model are trained to optimize performance on the E2EST task. Experimental results on the MuST-C speech translation benchmar",
    "link": "http://arxiv.org/abs/2310.02050",
    "context": "Title: Tuning Large language model for End-to-end Speech Translation. (arXiv:2310.02050v1 [cs.CL])\nAbstract: With the emergence of large language models (LLMs), multimodal models based on LLMs have demonstrated significant potential. Models such as LLaSM, X-LLM, and SpeechGPT exhibit an impressive ability to comprehend and generate human instructions. However, their performance often falters when faced with complex tasks like end-to-end speech translation (E2E-ST), a cross-language and cross-modal translation task. In comparison to single-modal models, multimodal models lag behind in these scenarios. This paper introduces LST, a Large multimodal model designed to excel at the E2E-ST task. LST consists of a speech frontend, an adapter, and a LLM backend. The training of LST consists of two stages: (1) Modality adjustment, where the adapter is tuned to align speech representation with text embedding space, and (2) Downstream task fine-tuning, where both the adapter and LLM model are trained to optimize performance on the E2EST task. Experimental results on the MuST-C speech translation benchmar",
    "path": "papers/23/10/2310.02050.json",
    "total_tokens": 942,
    "translated_title": "针对端到端语音翻译的大型语言模型调优",
    "translated_abstract": "随着大型语言模型（LLM）的出现，基于LLM的多模态模型展示了显著的潜力。像LLaSM、X-LLM和SpeechGPT这样的模型展示出了理解和生成人类指令的卓越能力。然而，在面对端到端语音翻译（E2E-ST）这样的复杂任务时，它们的性能常常不稳定，这是一个跨语言和跨模态的翻译任务。与单模态模型相比，多模态模型在这些场景中落后。本文介绍了LST，这是一个专门设计用于在E2E-ST任务上表现出色的大型多模态模型。LST由语音前端、适配器和LLM后端组成。LST的训练分为两个阶段：（1）模态调整，其中适配器被调整以使语音表示与文本嵌入空间对齐，（2）下游任务微调，其中适配器和LLM模型同时进行训练，以在E2E-ST任务上优化性能。在MuST-C语音翻译基准测试上的实验结果表明...",
    "tldr": "本文介绍了一个名为LST的大型多模态模型用于端到端语音翻译任务。该模型通过两个训练阶段进行模态调整和下游任务微调，优化了翻译性能。"
}