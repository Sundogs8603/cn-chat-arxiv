{
    "title": "PAC-Bayesian Spectrally-Normalized Bounds for Adversarially Robust Generalization. (arXiv:2310.06182v1 [cs.LG])",
    "abstract": "Deep neural networks (DNNs) are vulnerable to adversarial attacks. It is found empirically that adversarially robust generalization is crucial in establishing defense algorithms against adversarial attacks. Therefore, it is interesting to study the theoretical guarantee of robust generalization. This paper focuses on norm-based complexity, based on a PAC-Bayes approach (Neyshabur et al., 2017). The main challenge lies in extending the key ingredient, which is a weight perturbation bound in standard settings, to the robust settings. Existing attempts heavily rely on additional strong assumptions, leading to loose bounds. In this paper, we address this issue and provide a spectrally-normalized robust generalization bound for DNNs. Compared to existing bounds, our bound offers two significant advantages: Firstly, it does not depend on additional assumptions. Secondly, it is considerably tighter, aligning with the bounds of standard generalization. Therefore, our result provides a differen",
    "link": "http://arxiv.org/abs/2310.06182",
    "context": "Title: PAC-Bayesian Spectrally-Normalized Bounds for Adversarially Robust Generalization. (arXiv:2310.06182v1 [cs.LG])\nAbstract: Deep neural networks (DNNs) are vulnerable to adversarial attacks. It is found empirically that adversarially robust generalization is crucial in establishing defense algorithms against adversarial attacks. Therefore, it is interesting to study the theoretical guarantee of robust generalization. This paper focuses on norm-based complexity, based on a PAC-Bayes approach (Neyshabur et al., 2017). The main challenge lies in extending the key ingredient, which is a weight perturbation bound in standard settings, to the robust settings. Existing attempts heavily rely on additional strong assumptions, leading to loose bounds. In this paper, we address this issue and provide a spectrally-normalized robust generalization bound for DNNs. Compared to existing bounds, our bound offers two significant advantages: Firstly, it does not depend on additional assumptions. Secondly, it is considerably tighter, aligning with the bounds of standard generalization. Therefore, our result provides a differen",
    "path": "papers/23/10/2310.06182.json",
    "total_tokens": 991,
    "translated_title": "PAC-Bayesian光谱归一化界对抗鲁棒泛化性的研究",
    "translated_abstract": "深度神经网络(DNNs)容易受到对抗攻击。实验证明，对抗性鲁棒泛化在建立防御对抗攻击的算法中至关重要。因此，研究对鲁棒泛化的理论保证非常有意义。本文基于PAC-Bayes方法(Neyshabur等人，2017年)的基于范数的复杂性展开研究。主要挑战在于将在标准情况下的主要构成要素，即权重扰动界，扩展到鲁棒情况下。现有的尝试严重依赖于额外的强假设，导致界限不严。本文解决了这个问题，并为DNNs提供了一种光谱归一化的鲁棒泛化界限。与现有的界限相比，我们的界限具有两个显著优势：首先，它不依赖于额外的假设。其次，它的界限相当紧密，与标准泛化的界限一致。因此，我们的结果提供了一种不同的方法，可以更好地保证对抗鲁棒性。",
    "tldr": "本文提出了一种PAC-Bayesian光谱归一化界限，用于对抗鲁棒深度神经网络的泛化性。与现有界限相比，我们的方法不依赖额外的假设，且更紧密地与标准泛化的界限一致。"
}