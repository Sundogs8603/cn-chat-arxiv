{
    "title": "Visual Question Generation in Bengali. (arXiv:2310.08187v1 [cs.CL])",
    "abstract": "The task of Visual Question Generation (VQG) is to generate human-like questions relevant to the given image. As VQG is an emerging research field, existing works tend to focus only on resource-rich language such as English due to the availability of datasets. In this paper, we propose the first Bengali Visual Question Generation task and develop a novel transformer-based encoder-decoder architecture that generates questions in Bengali when given an image. We propose multiple variants of models - (i) image-only: baseline model of generating questions from images without additional information, (ii) image-category and image-answer-category: guided VQG where we condition the model to generate questions based on the answer and the category of expected question. These models are trained and evaluated on the translated VQAv2.0 dataset. Our quantitative and qualitative results establish the first state of the art models for VQG task in Bengali and demonstrate that our models are capable of g",
    "link": "http://arxiv.org/abs/2310.08187",
    "context": "Title: Visual Question Generation in Bengali. (arXiv:2310.08187v1 [cs.CL])\nAbstract: The task of Visual Question Generation (VQG) is to generate human-like questions relevant to the given image. As VQG is an emerging research field, existing works tend to focus only on resource-rich language such as English due to the availability of datasets. In this paper, we propose the first Bengali Visual Question Generation task and develop a novel transformer-based encoder-decoder architecture that generates questions in Bengali when given an image. We propose multiple variants of models - (i) image-only: baseline model of generating questions from images without additional information, (ii) image-category and image-answer-category: guided VQG where we condition the model to generate questions based on the answer and the category of expected question. These models are trained and evaluated on the translated VQAv2.0 dataset. Our quantitative and qualitative results establish the first state of the art models for VQG task in Bengali and demonstrate that our models are capable of g",
    "path": "papers/23/10/2310.08187.json",
    "total_tokens": 921,
    "translated_title": "孟加拉语中的视觉问题生成",
    "translated_abstract": "视觉问题生成（VQG）的任务是生成与给定图像相关的类似于人类问题的文本。由于数据集的可用性，现有的工作往往只关注资源丰富的语言，如英语。本文提出了首个孟加拉语视觉问题生成任务，并开发了一种基于transformer的编码器-解码器架构，在给定图像时可以生成孟加拉语问题。我们提出了多个模型变体-（i）仅图像：从图像中生成问题的基线模型，没有额外的信息，（ii）图像-类别和图像-答案-类别：引导型VQG，在此模型中，我们通过答案和期望问题的类别对模型进行约束以生成问题。这些模型在翻译后的VQAv2.0数据集上进行了训练和评估。我们的定量和定性结果建立了孟加拉语VQG任务的首个最先进模型，并证明我们的模型能够生成高质量的问题。",
    "tldr": "本文提出了孟加拉语视觉问题生成任务，并开发了基于transformer的编码器-解码器架构，能够生成孟加拉语问题。通过引导型VQG模型，我们能够根据答案和问题类别生成问题。实验证明我们的模型在孟加拉语VQG任务上取得了最先进的性能。",
    "en_tdlr": "This paper presents the task of Visual Question Generation in Bengali and develops a transformer-based encoder-decoder architecture that generates questions in Bengali. By using guided VQG models, questions can be generated based on the answer and question category. Experimental results demonstrate that our models achieve state-of-the-art performance on the Bengali VQG task."
}