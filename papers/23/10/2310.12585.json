{
    "title": "Time-Aware Representation Learning for Time-Sensitive Question Answering. (arXiv:2310.12585v1 [cs.CL])",
    "abstract": "Time is one of the crucial factors in real-world question answering (QA) problems. However, language models have difficulty understanding the relationships between time specifiers, such as 'after' and 'before', and numbers, since existing QA datasets do not include sufficient time expressions. To address this issue, we propose a Time-Context aware Question Answering (TCQA) framework. We suggest a Time-Context dependent Span Extraction (TCSE) task, and build a time-context dependent data generation framework for model training. Moreover, we present a metric to evaluate the time awareness of the QA model using TCSE. The TCSE task consists of a question and four sentence candidates classified as correct or incorrect based on time and context. The model is trained to extract the answer span from the sentence that is both correct in time and context. The model trained with TCQA outperforms baseline models up to 8.5 of the F1-score in the TimeQA dataset. Our dataset and code are available at",
    "link": "http://arxiv.org/abs/2310.12585",
    "context": "Title: Time-Aware Representation Learning for Time-Sensitive Question Answering. (arXiv:2310.12585v1 [cs.CL])\nAbstract: Time is one of the crucial factors in real-world question answering (QA) problems. However, language models have difficulty understanding the relationships between time specifiers, such as 'after' and 'before', and numbers, since existing QA datasets do not include sufficient time expressions. To address this issue, we propose a Time-Context aware Question Answering (TCQA) framework. We suggest a Time-Context dependent Span Extraction (TCSE) task, and build a time-context dependent data generation framework for model training. Moreover, we present a metric to evaluate the time awareness of the QA model using TCSE. The TCSE task consists of a question and four sentence candidates classified as correct or incorrect based on time and context. The model is trained to extract the answer span from the sentence that is both correct in time and context. The model trained with TCQA outperforms baseline models up to 8.5 of the F1-score in the TimeQA dataset. Our dataset and code are available at",
    "path": "papers/23/10/2310.12585.json",
    "total_tokens": 935,
    "translated_title": "时态敏感问题回答的时态感知表示学习",
    "translated_abstract": "时间是现实世界中问题回答的关键因素之一，然而语言模型很难理解时间限定词如“之后”和“之前”与数字之间的关系，因为现有的问题回答数据集中没有足够的时间表达。为了解决这个问题，我们提出了一种时间上下文感知的问题回答框架。我们提出了一种基于时间上下文的区间抽取任务，并构建了一个依赖于时间上下文的数据生成框架用于模型训练。此外，我们提出了一个评估QA模型的时间感知度的度量方法。区间抽取任务包括一个问题和四个句子候选项，根据时间和上下文分类为正确或错误。模型被训练为从在时间和上下文上都正确的句子中提取答案区间。通过使用TCQA训练的模型在TimeQA数据集上的F1分数上优于基准模型达8.5。我们的数据集和代码可在以下链接中获得。",
    "tldr": "该论文提出了一种时态感知的问题回答框架，通过引入时间上下文的区间抽取任务和相应的数据生成框架来训练模型，提高了QA模型的时间感知能力，在TimeQA数据集中的F1分数上超过了基准模型达8.5。",
    "en_tdlr": "This paper proposes a time-aware framework for question answering, which improves the time awareness of QA models by introducing a time-context dependent span extraction task and a corresponding data generation framework. The model trained with this framework outperforms baseline models by up to 8.5 in F1-score on the TimeQA dataset."
}