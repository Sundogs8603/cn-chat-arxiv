{
    "title": "The Lattice Overparametrization Paradigm for the Machine Learning of Lattice Operators. (arXiv:2310.06639v2 [cs.LG] UPDATED)",
    "abstract": "The machine learning of lattice operators has three possible bottlenecks. From a statistical standpoint, it is necessary to design a constrained class of operators based on prior information with low bias, and low complexity relative to the sample size. From a computational perspective, there should be an efficient algorithm to minimize an empirical error over the class. From an understanding point of view, the properties of the learned operator need to be derived, so its behavior can be theoretically understood. The statistical bottleneck can be overcome due to the rich literature about the representation of lattice operators, but there is no general learning algorithm for them. In this paper, we discuss a learning paradigm in which, by overparametrizing a class via elements in a lattice, an algorithm for minimizing functions in a lattice is applied to learn. We present the stochastic lattice descent algorithm as a general algorithm to learn on constrained classes of operators as long",
    "link": "http://arxiv.org/abs/2310.06639",
    "context": "Title: The Lattice Overparametrization Paradigm for the Machine Learning of Lattice Operators. (arXiv:2310.06639v2 [cs.LG] UPDATED)\nAbstract: The machine learning of lattice operators has three possible bottlenecks. From a statistical standpoint, it is necessary to design a constrained class of operators based on prior information with low bias, and low complexity relative to the sample size. From a computational perspective, there should be an efficient algorithm to minimize an empirical error over the class. From an understanding point of view, the properties of the learned operator need to be derived, so its behavior can be theoretically understood. The statistical bottleneck can be overcome due to the rich literature about the representation of lattice operators, but there is no general learning algorithm for them. In this paper, we discuss a learning paradigm in which, by overparametrizing a class via elements in a lattice, an algorithm for minimizing functions in a lattice is applied to learn. We present the stochastic lattice descent algorithm as a general algorithm to learn on constrained classes of operators as long",
    "path": "papers/23/10/2310.06639.json",
    "total_tokens": 789,
    "translated_title": "通过格子过参数化范式进行格子操作器的机器学习",
    "translated_abstract": "格子操作器的机器学习存在三个潜在瓶颈。从统计角度来看，需要设计一个基于先验信息的受限操作器类，具有低偏差和与样本大小相对较低的复杂性。从计算角度来看，应该有一种高效的算法来在该类上最小化经验误差。从理解的角度来看，需要推导出学习到的操作器的属性，以便从理论上理解其行为。统计瓶颈可以通过有关格子操作器表示的丰富文献克服，但没有通用的学习算法。在本文中，我们讨论了一种学习范式，在其中通过格子中的元素进行过参数化，将格子函数最小化算法应用于学习。我们将随机格子下降算法作为一种通用算法，用于对操作器的受限类进行学习。",
    "tldr": "本文介绍了一种通过过参数化格子，利用格子函数最小化算法进行学习的范式，以克服格子操作器机器学习中的三个潜在瓶颈。"
}