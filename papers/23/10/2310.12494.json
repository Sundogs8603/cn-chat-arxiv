{
    "title": "SDGym: Low-Code Reinforcement Learning Environments using System Dynamics Models. (arXiv:2310.12494v1 [cs.LG])",
    "abstract": "Understanding the long-term impact of algorithmic interventions on society is vital to achieving responsible AI. Traditional evaluation strategies often fall short due to the complex, adaptive and dynamic nature of society. While reinforcement learning (RL) can be a powerful approach for optimizing decisions in dynamic settings, the difficulty of realistic environment design remains a barrier to building robust agents that perform well in practical settings. To address this issue we tap into the field of system dynamics (SD) as a complementary method that incorporates collaborative simulation model specification practices. We introduce SDGym, a low-code library built on the OpenAI Gym framework which enables the generation of custom RL environments based on SD simulation models. Through a feasibility study we validate that well specified, rich RL environments can be generated from preexisting SD models and a few lines of configuration code. We demonstrate the capabilities of the SDGym ",
    "link": "http://arxiv.org/abs/2310.12494",
    "context": "Title: SDGym: Low-Code Reinforcement Learning Environments using System Dynamics Models. (arXiv:2310.12494v1 [cs.LG])\nAbstract: Understanding the long-term impact of algorithmic interventions on society is vital to achieving responsible AI. Traditional evaluation strategies often fall short due to the complex, adaptive and dynamic nature of society. While reinforcement learning (RL) can be a powerful approach for optimizing decisions in dynamic settings, the difficulty of realistic environment design remains a barrier to building robust agents that perform well in practical settings. To address this issue we tap into the field of system dynamics (SD) as a complementary method that incorporates collaborative simulation model specification practices. We introduce SDGym, a low-code library built on the OpenAI Gym framework which enables the generation of custom RL environments based on SD simulation models. Through a feasibility study we validate that well specified, rich RL environments can be generated from preexisting SD models and a few lines of configuration code. We demonstrate the capabilities of the SDGym ",
    "path": "papers/23/10/2310.12494.json",
    "total_tokens": 901,
    "translated_title": "SDGym: 使用系统动力学模型的低代码强化学习环境",
    "translated_abstract": "理解算法干预对社会的长期影响对于实现负责任的人工智能至关重要。传统的评估策略通常难以应对社会的复杂、适应性和动态性。虽然强化学习（RL）可以是优化动态环境下决策的强大方法，但现实环境设计的困难仍然是构建在实际环境中表现良好的强大智能体的障碍。为了解决这个问题，我们利用系统动力学（SD）领域作为一种补充方法，纳入协作仿真模型规范实践。我们介绍了SDGym，这是一个基于OpenAI Gym框架构建的低代码库，它可以根据SD模拟模型生成定制的RL环境。通过一项可行性研究，我们验证了可以从现有SD模型和少量配置代码中生成具有规范良好、丰富的RL环境。我们展示了SDGym的功能。",
    "tldr": "这项研究提出了SDGym，一个基于系统动力学模型的低代码强化学习环境库，通过生成定制的RL环境来解决现实环境设计的困难，从而构建在实际设置中表现良好的强大智能体。"
}