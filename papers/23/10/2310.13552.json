{
    "title": "Self-prompted Chain-of-Thought on Large Language Models for Open-domain Multi-hop Reasoning. (arXiv:2310.13552v1 [cs.CL])",
    "abstract": "In open-domain question-answering (ODQA), most existing questions require single-hop reasoning on commonsense. To further extend this task, we officially introduce open-domain multi-hop reasoning (ODMR) by answering multi-hop questions with explicit reasoning steps in open-domain setting. Recently, large language models (LLMs) have found significant utility in facilitating ODQA without external corpus. Furthermore, chain-of-thought (CoT) prompting boosts the reasoning capability of LLMs to a greater extent with manual or automated paradigms. However, existing automated methods lack of quality assurance, while manual approaches suffer from limited scalability and poor diversity, hindering the capabilities of LLMs. In this paper, we propose Self-prompted Chain-of-Thought (SP-CoT), an automated framework to mass-produce high quality CoTs of LLMs, by LLMs and for LLMs. SP-CoT introduces an automated generation pipeline of high quality ODMR datasets, an adaptive sampler for in-context CoT s",
    "link": "http://arxiv.org/abs/2310.13552",
    "context": "Title: Self-prompted Chain-of-Thought on Large Language Models for Open-domain Multi-hop Reasoning. (arXiv:2310.13552v1 [cs.CL])\nAbstract: In open-domain question-answering (ODQA), most existing questions require single-hop reasoning on commonsense. To further extend this task, we officially introduce open-domain multi-hop reasoning (ODMR) by answering multi-hop questions with explicit reasoning steps in open-domain setting. Recently, large language models (LLMs) have found significant utility in facilitating ODQA without external corpus. Furthermore, chain-of-thought (CoT) prompting boosts the reasoning capability of LLMs to a greater extent with manual or automated paradigms. However, existing automated methods lack of quality assurance, while manual approaches suffer from limited scalability and poor diversity, hindering the capabilities of LLMs. In this paper, we propose Self-prompted Chain-of-Thought (SP-CoT), an automated framework to mass-produce high quality CoTs of LLMs, by LLMs and for LLMs. SP-CoT introduces an automated generation pipeline of high quality ODMR datasets, an adaptive sampler for in-context CoT s",
    "path": "papers/23/10/2310.13552.json",
    "total_tokens": 921,
    "translated_title": "自我启示的大型语言模型在开放领域多跳推理中的应用",
    "translated_abstract": "在开放领域问答（ODQA）中，大多数问题需要对常识进行单跳推理。为了进一步扩展这个任务，我们正式引入了开放领域多跳推理（ODMR），通过在开放领域设置中回答多跳问题并提供明确的推理步骤。最近，大型语言模型（LLMs）在无需外部语料库的情况下在促进ODQA方面发挥了重要作用。此外，思维链（CoT）提示通过手动或自动化范例，显著提升了LLMs的推理能力。然而，现有的自动化方法缺乏质量保证，而手动方法受到可扩展性和多样性的限制，阻碍了LLMs的能力。在本文中，我们提出了自我启示的思维链（SP-CoT），这是一个自动化框架，可以通过LLMs并为LLMs大规模生成高质量的CoTs。",
    "tldr": "本文提出了自我启示的思维链（SP-CoT）框架，在开放领域多跳推理中利用大型语言模型（LLMs），通过自动化生成高质量的CoTs，扩展了开放领域问答的能力。"
}