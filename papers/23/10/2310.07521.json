{
    "title": "Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity. (arXiv:2310.07521v1 [cs.CL])",
    "abstract": "This survey addresses the crucial issue of factuality in Large Language Models (LLMs). As LLMs find applications across diverse domains, the reliability and accuracy of their outputs become vital. We define the Factuality Issue as the probability of LLMs to produce content inconsistent with established facts. We first delve into the implications of these inaccuracies, highlighting the potential consequences and challenges posed by factual errors in LLM outputs. Subsequently, we analyze the mechanisms through which LLMs store and process facts, seeking the primary causes of factual errors. Our discussion then transitions to methodologies for evaluating LLM factuality, emphasizing key metrics, benchmarks, and studies. We further explore strategies for enhancing LLM factuality, including approaches tailored for specific domains. We focus two primary LLM configurations standalone LLMs and Retrieval-Augmented LLMs that utilizes external data, we detail their unique challenges and potential ",
    "link": "http://arxiv.org/abs/2310.07521",
    "context": "Title: Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity. (arXiv:2310.07521v1 [cs.CL])\nAbstract: This survey addresses the crucial issue of factuality in Large Language Models (LLMs). As LLMs find applications across diverse domains, the reliability and accuracy of their outputs become vital. We define the Factuality Issue as the probability of LLMs to produce content inconsistent with established facts. We first delve into the implications of these inaccuracies, highlighting the potential consequences and challenges posed by factual errors in LLM outputs. Subsequently, we analyze the mechanisms through which LLMs store and process facts, seeking the primary causes of factual errors. Our discussion then transitions to methodologies for evaluating LLM factuality, emphasizing key metrics, benchmarks, and studies. We further explore strategies for enhancing LLM factuality, including approaches tailored for specific domains. We focus two primary LLM configurations standalone LLMs and Retrieval-Augmented LLMs that utilizes external data, we detail their unique challenges and potential ",
    "path": "papers/23/10/2310.07521.json",
    "total_tokens": 952,
    "translated_title": "大型语言模型中的事实性调查：知识、检索和领域专属性",
    "translated_abstract": "本调查研究了大型语言模型（LLMs）中的关键问题，即事实性。由于LLMs在不同领域中都有应用，它们的输出的可靠性和准确性变得至关重要。我们将事实性问题定义为LLMs产生与已确立事实不一致的内容的概率。我们首先深入探讨了这些不准确性的含义，突出了事实错误在LLMs输出中可能带来的潜在后果和挑战。随后，我们分析了LLMs存储和处理事实的机制，寻找事实错误的主要原因。我们的讨论随后转向评估LLM事实性的方法论，强调关键指标、基准和研究。我们进一步探讨了增强LLM事实性的策略，包括针对特定领域的方法。我们重点关注两种主要的LLM配置，独立LLMs和利用外部数据的检索增强LLMs，详细介绍它们的独特挑战和潜在解决方法。",
    "tldr": "这项调查研究了大型语言模型（LLMs）中的事实性问题，包括其可能带来的后果和挑战，以及存储、处理和评估事实的方法。同时，提出了一些增强LLM事实性的策略，涵盖了不同领域的需求。"
}