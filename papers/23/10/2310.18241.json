{
    "title": "$\\alpha$-Mutual Information: A Tunable Privacy Measure for Privacy Protection in Data Sharing. (arXiv:2310.18241v1 [cs.LG])",
    "abstract": "This paper adopts Arimoto's $\\alpha$-Mutual Information as a tunable privacy measure, in a privacy-preserving data release setting that aims to prevent disclosing private data to adversaries. By fine-tuning the privacy metric, we demonstrate that our approach yields superior models that effectively thwart attackers across various performance dimensions. We formulate a general distortion-based mechanism that manipulates the original data to offer privacy protection. The distortion metrics are determined according to the data structure of a specific experiment. We confront the problem expressed in the formulation by employing a general adversarial deep learning framework that consists of a releaser and an adversary, trained with opposite goals. This study conducts empirical experiments on images and time-series data to verify the functionality of $\\alpha$-Mutual Information. We evaluate the privacy-utility trade-off of customized models and compare them to mutual information as the basel",
    "link": "http://arxiv.org/abs/2310.18241",
    "context": "Title: $\\alpha$-Mutual Information: A Tunable Privacy Measure for Privacy Protection in Data Sharing. (arXiv:2310.18241v1 [cs.LG])\nAbstract: This paper adopts Arimoto's $\\alpha$-Mutual Information as a tunable privacy measure, in a privacy-preserving data release setting that aims to prevent disclosing private data to adversaries. By fine-tuning the privacy metric, we demonstrate that our approach yields superior models that effectively thwart attackers across various performance dimensions. We formulate a general distortion-based mechanism that manipulates the original data to offer privacy protection. The distortion metrics are determined according to the data structure of a specific experiment. We confront the problem expressed in the formulation by employing a general adversarial deep learning framework that consists of a releaser and an adversary, trained with opposite goals. This study conducts empirical experiments on images and time-series data to verify the functionality of $\\alpha$-Mutual Information. We evaluate the privacy-utility trade-off of customized models and compare them to mutual information as the basel",
    "path": "papers/23/10/2310.18241.json",
    "total_tokens": 992,
    "translated_title": "$\\alpha$-互信息：一个可调节的隐私度量用于数据共享中的隐私保护",
    "translated_abstract": "本文采用Arimoto的$\\alpha$-互信息作为可调节的隐私度量，在隐私保护的数据发布环境中旨在防止向攻击者披露私密数据。通过对隐私度量进行精细调整，我们证明了我们的方法能够产生在各种性能维度上有效阻挠攻击者的优越模型。我们提出了一种基于扭曲的通用机制，通过操纵原始数据来提供隐私保护。扭曲度量是根据特定实验的数据结构来确定的。我们通过采用一个包含发布者和对手的通用对抗性深度学习框架来解决表达式中的问题，这两者都是以相反目标进行训练的。本研究对图像和时间序列数据进行了实证实验，以验证$\\alpha$-互信息的功能。我们评估了定制模型的隐私-效用权衡，并将其与互信息作为基准进行比较。",
    "tldr": "本文提出了一种可调节的隐私度量$\\alpha$-互信息，在隐私保护的数据共享中能够生成优越的模型以有效阻挠攻击者，通过操纵原始数据提供隐私保护，并使用一个通用对抗性深度学习框架来解决隐私度量问题。通过实证实验验证了$\\alpha$-互信息的功能，并评估了隐私-效用权衡。",
    "en_tdlr": "This paper proposes a tunable privacy measure, $\\alpha$-Mutual Information, for privacy protection in data sharing. It demonstrates that the approach can generate superior models to effectively thwart attackers, manipulate original data for privacy protection, and addresses the privacy measure problem using a general adversarial deep learning framework. The functionality of $\\alpha$-Mutual Information is validated through empirical experiments, and the privacy-utility trade-off is evaluated."
}