{
    "title": "Fine-tune Language Models to Approximate Unbiased In-context Learning. (arXiv:2310.03331v1 [cs.LG])",
    "abstract": "In-context learning (ICL) is an astonishing emergent ability of large language models (LLMs). By presenting a prompt that includes multiple input-output pairs as examples and introducing a new query input, models can generate the corresponding output. However, the performance of models heavily relies on the quality of the input prompt when implementing in-context learning. Biased or imbalanced input prompts can significantly degrade the performance of language models. To address this issue, we introduce a reweighted algorithm called RICL (Reweighted In-context Learning). This algorithm fine-tunes language models using an unbiased validation set to determine the optimal weight for each input-output example to approximate unbiased in-context learning. Furthermore, we also introduce a low-cost reweighted algorithm, a linear optimal weight approximation algorithm called LARICL (Linear Approximation of Reweighted In-context Learning). This algorithm requires minimal training cost while prov",
    "link": "http://arxiv.org/abs/2310.03331",
    "context": "Title: Fine-tune Language Models to Approximate Unbiased In-context Learning. (arXiv:2310.03331v1 [cs.LG])\nAbstract: In-context learning (ICL) is an astonishing emergent ability of large language models (LLMs). By presenting a prompt that includes multiple input-output pairs as examples and introducing a new query input, models can generate the corresponding output. However, the performance of models heavily relies on the quality of the input prompt when implementing in-context learning. Biased or imbalanced input prompts can significantly degrade the performance of language models. To address this issue, we introduce a reweighted algorithm called RICL (Reweighted In-context Learning). This algorithm fine-tunes language models using an unbiased validation set to determine the optimal weight for each input-output example to approximate unbiased in-context learning. Furthermore, we also introduce a low-cost reweighted algorithm, a linear optimal weight approximation algorithm called LARICL (Linear Approximation of Reweighted In-context Learning). This algorithm requires minimal training cost while prov",
    "path": "papers/23/10/2310.03331.json",
    "total_tokens": 920,
    "translated_title": "精调语言模型以实现无偏的上下文学习",
    "translated_abstract": "上下文学习（ICL）是大语言模型（LLM）惊人的新兴能力。通过提供包含多个输入-输出对作为示例的提示，并引入新的查询输入，模型可以生成相应的输出。然而，在实施上下文学习时，模型的性能严重依赖于输入提示的质量。偏差或不平衡的输入提示会显著降低语言模型的性能。为了解决这个问题，我们引入了一种名为RICL（重加权上下文学习）的重加权算法。该算法通过使用无偏验证集来精调语言模型，确定每个输入-输出示例的最佳权重，以实现无偏的上下文学习。此外，我们还引入了一种低成本的重加权算法，一种称为LARICL（重加权上下文学习的线性近似）的线性最优权重近似算法。该算法在训练成本上要求最小，同时提供高效准确的重加权上下文学习。",
    "tldr": "这篇论文介绍了一种精调语言模型的算法，名为RICL，并提出了一种低成本的线性最优权重近似算法LARICL。这些算法可以通过使用无偏验证集和确定每个输入-输出示例的最佳权重，实现无偏的上下文学习。",
    "en_tdlr": "This paper introduces an algorithm called RICL for fine-tuning language models and proposes a low-cost linear optimal weight approximation algorithm called LARICL. These algorithms achieve unbiased in-context learning by using an unbiased validation set and determining the optimal weight for each input-output example."
}