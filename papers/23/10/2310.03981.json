{
    "title": "CUPre: Cross-domain Unsupervised Pre-training for Few-Shot Cell Segmentation. (arXiv:2310.03981v1 [cs.CV])",
    "abstract": "While pre-training on object detection tasks, such as Common Objects in Contexts (COCO) [1], could significantly boost the performance of cell segmentation, it still consumes on massive fine-annotated cell images [2] with bounding boxes, masks, and cell types for every cell in every image, to fine-tune the pre-trained model. To lower the cost of annotation, this work considers the problem of pre-training DNN models for few-shot cell segmentation, where massive unlabeled cell images are available but only a small proportion is annotated. Hereby, we propose Cross-domain Unsupervised Pre-training, namely CUPre, transferring the capability of object detection and instance segmentation for common visual objects (learned from COCO) to the visual domain of cells using unlabeled images. Given a standard COCO pre-trained network with backbone, neck, and head modules, CUPre adopts an alternate multi-task pre-training (AMT2) procedure with two sub-tasks -- in every iteration of pre-training, AMT2",
    "link": "http://arxiv.org/abs/2310.03981",
    "context": "Title: CUPre: Cross-domain Unsupervised Pre-training for Few-Shot Cell Segmentation. (arXiv:2310.03981v1 [cs.CV])\nAbstract: While pre-training on object detection tasks, such as Common Objects in Contexts (COCO) [1], could significantly boost the performance of cell segmentation, it still consumes on massive fine-annotated cell images [2] with bounding boxes, masks, and cell types for every cell in every image, to fine-tune the pre-trained model. To lower the cost of annotation, this work considers the problem of pre-training DNN models for few-shot cell segmentation, where massive unlabeled cell images are available but only a small proportion is annotated. Hereby, we propose Cross-domain Unsupervised Pre-training, namely CUPre, transferring the capability of object detection and instance segmentation for common visual objects (learned from COCO) to the visual domain of cells using unlabeled images. Given a standard COCO pre-trained network with backbone, neck, and head modules, CUPre adopts an alternate multi-task pre-training (AMT2) procedure with two sub-tasks -- in every iteration of pre-training, AMT2",
    "path": "papers/23/10/2310.03981.json",
    "total_tokens": 979,
    "translated_title": "CUPre: 跨领域无监督预训练用于少样本细胞分割",
    "translated_abstract": "在目标检测任务的预训练中，例如在常见物体上下文（COCO）[1]上，可以显著提高细胞分割的性能，但仍然需要大量精细注释的细胞图像[2]，其中包括每个图像中每个细胞的边界框、掩膜和细胞类型，以对预训练模型进行微调。为了降低注释成本，本研究考虑了少样本细胞分割的预训练DNN模型问题，其中有大量未标注的细胞图像可用，但只有一小部分被注释。因此，我们提出了跨域无监督预训练（CUPre）方法，通过使用未标注图像将对象检测和实例分割的能力（从COCO学习）转移到细胞的视觉领域。给定一个带有主干、脖子和头部模块的标准COCO预训练网络，CUPre采用交替多任务预训练（AMT2）流程并进行两个子任务的训练。",
    "tldr": "本论文提出了CUPre方法，实现了跨领域无监督预训练，将常见物体检测和实例分割的能力应用于细胞图像领域，为少样本细胞分割提供了一种低成本的注释方法。",
    "en_tdlr": "This paper proposes the CUPre method, which achieves cross-domain unsupervised pre-training and applies the capabilities of common object detection and instance segmentation to the field of cell imagery, providing a low-cost annotation approach for few-shot cell segmentation."
}