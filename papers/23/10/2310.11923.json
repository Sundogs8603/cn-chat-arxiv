{
    "title": "Investigating semantic subspaces of Transformer sentence embeddings through linear structural probing. (arXiv:2310.11923v1 [cs.CL])",
    "abstract": "The question of what kinds of linguistic information are encoded in different layers of Transformer-based language models is of considerable interest for the NLP community. Existing work, however, has overwhelmingly focused on word-level representations and encoder-only language models with the masked-token training objective. In this paper, we present experiments with semantic structural probing, a method for studying sentence-level representations via finding a subspace of the embedding space that provides suitable task-specific pairwise distances between data-points. We apply our method to language models from different families (encoder-only, decoder-only, encoder-decoder) and of different sizes in the context of two tasks, semantic textual similarity and natural-language inference. We find that model families differ substantially in their performance and layer dynamics, but that the results are largely model-size invariant.",
    "link": "http://arxiv.org/abs/2310.11923",
    "context": "Title: Investigating semantic subspaces of Transformer sentence embeddings through linear structural probing. (arXiv:2310.11923v1 [cs.CL])\nAbstract: The question of what kinds of linguistic information are encoded in different layers of Transformer-based language models is of considerable interest for the NLP community. Existing work, however, has overwhelmingly focused on word-level representations and encoder-only language models with the masked-token training objective. In this paper, we present experiments with semantic structural probing, a method for studying sentence-level representations via finding a subspace of the embedding space that provides suitable task-specific pairwise distances between data-points. We apply our method to language models from different families (encoder-only, decoder-only, encoder-decoder) and of different sizes in the context of two tasks, semantic textual similarity and natural-language inference. We find that model families differ substantially in their performance and layer dynamics, but that the results are largely model-size invariant.",
    "path": "papers/23/10/2310.11923.json",
    "total_tokens": 848,
    "translated_title": "通过线性结构探索研究Transformer句子嵌入的语义子空间",
    "translated_abstract": "对于NLP社区来说，研究基于Transformer的语言模型的不同层级中编码的语言信息的类型是非常重要的问题。然而，现有研究主要集中在单词级表示和仅使用编码器的语言模型以及遮蔽标记训练目标。本文通过语义结构探测实验介绍了一种研究句子级表示的方法，即通过找到嵌入空间的一个子空间，提供适合每一对数据点的特定任务的距离。我们在两个任务（语义文本相似性和自然语言推理）的背景下，将我们的方法应用于不同种类（仅编码器、仅解码器、编码器-解码器）和不同大小的语言模型。我们发现不同家族的模型在性能和层动力学上存在显著差异，但结果在很大程度上与模型大小无关。",
    "tldr": "通过语义结构探测实验，本论文研究了Transformer句子嵌入的语义子空间。研究结果表明，不同类型和大小的语言模型在性能和层动力学上存在差异，但模型大小与结果关联较小。"
}