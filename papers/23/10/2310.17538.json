{
    "title": "Little Exploration is All You Need. (arXiv:2310.17538v1 [cs.LG])",
    "abstract": "The prevailing principle of \"Optimism in the Face of Uncertainty\" advocates for the incorporation of an exploration bonus, generally assumed to be proportional to the inverse square root of the visit count ($1/\\sqrt{n}$), where $n$ is the number of visits to a particular state-action pair. This approach, however, exclusively focuses on \"uncertainty,\" neglecting the inherent \"difficulty\" of different options. To address this gap, we introduce a novel modification of standard UCB algorithm in the multi-armed bandit problem, proposing an adjusted bonus term of $1/n^\\tau$, where $\\tau > 1/2$, that accounts for task difficulty. Our proposed algorithm, denoted as UCB$^\\tau$, is substantiated through comprehensive regret and risk analyses, confirming its theoretical robustness. Comparative evaluations with standard UCB and Thompson Sampling algorithms on synthetic datasets demonstrate that UCB$^\\tau$ not only outperforms in efficacy but also exhibits lower risk across various environmental co",
    "link": "http://arxiv.org/abs/2310.17538",
    "context": "Title: Little Exploration is All You Need. (arXiv:2310.17538v1 [cs.LG])\nAbstract: The prevailing principle of \"Optimism in the Face of Uncertainty\" advocates for the incorporation of an exploration bonus, generally assumed to be proportional to the inverse square root of the visit count ($1/\\sqrt{n}$), where $n$ is the number of visits to a particular state-action pair. This approach, however, exclusively focuses on \"uncertainty,\" neglecting the inherent \"difficulty\" of different options. To address this gap, we introduce a novel modification of standard UCB algorithm in the multi-armed bandit problem, proposing an adjusted bonus term of $1/n^\\tau$, where $\\tau > 1/2$, that accounts for task difficulty. Our proposed algorithm, denoted as UCB$^\\tau$, is substantiated through comprehensive regret and risk analyses, confirming its theoretical robustness. Comparative evaluations with standard UCB and Thompson Sampling algorithms on synthetic datasets demonstrate that UCB$^\\tau$ not only outperforms in efficacy but also exhibits lower risk across various environmental co",
    "path": "papers/23/10/2310.17538.json",
    "total_tokens": 885,
    "translated_title": "只需稍微探索：面对不确定性的乐观主义",
    "translated_abstract": "“面对不确定性的乐观主义”是一种主张将探索奖励因子纳入考虑的原则，通常被假定成与状态-动作对访问次数的倒数平方根成比例($1/\\sqrt{n}$)，其中$n$是访问某个特定状态-动作对的次数。然而，这种方法专注于\"不确定性\"，忽略了不同选项的固有\"困难性\"。为了解决这一空白，我们在多臂赌博问题中引入了标准UCB算法的一种新颖修改，提出了一个根据任务的难度进行调整的奖励项$1/n^\\tau$，其中$\\tau > 1/2$。我们的提议算法被标记为UCB$^\\tau$，通过全面的遗憾和风险分析来证明其理论上的鲁棒性。在合成数据集上与标准UCB算法和Thompson采样算法进行比较评估表明，UCB$^\\tau$不仅在效能上表现出色，还在各种环境中显示出较低的风险。",
    "tldr": "本研究提出了UCB$^\\tau$算法，通过对任务困难度的调整，实现了更好的效能和较低的风险。",
    "en_tdlr": "This paper introduces the UCB$^\\tau$ algorithm, which achieves better performance and lower risk through the adjustment of task difficulty."
}