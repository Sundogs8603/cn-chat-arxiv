{
    "title": "Auditing Gender Analyzers on Text Data. (arXiv:2310.06061v1 [cs.CY])",
    "abstract": "AI models have become extremely popular and accessible to the general public. However, they are continuously under the scanner due to their demonstrable biases toward various sections of the society like people of color and non-binary people. In this study, we audit three existing gender analyzers -uClassify, Readable and HackerFactor, for biases against non-binary individuals. These tools are designed to predict only the cisgender binary labels, which leads to discrimination against non-binary members of the society. We curate two datasets -- Reddit comments (660k) and, Tumblr posts (2.05M) and our experimental evaluation shows that the tools are highly inaccurate with the overall accuracy being ~50% on all platforms. Predictions for non-binary comments on all platforms are mostly female, thus propagating the societal bias that non-binary individuals are effeminate. To address this, we fine-tune a BERT multi-label classifier on the two datasets in multiple combinations, observe an o",
    "link": "http://arxiv.org/abs/2310.06061",
    "context": "Title: Auditing Gender Analyzers on Text Data. (arXiv:2310.06061v1 [cs.CY])\nAbstract: AI models have become extremely popular and accessible to the general public. However, they are continuously under the scanner due to their demonstrable biases toward various sections of the society like people of color and non-binary people. In this study, we audit three existing gender analyzers -uClassify, Readable and HackerFactor, for biases against non-binary individuals. These tools are designed to predict only the cisgender binary labels, which leads to discrimination against non-binary members of the society. We curate two datasets -- Reddit comments (660k) and, Tumblr posts (2.05M) and our experimental evaluation shows that the tools are highly inaccurate with the overall accuracy being ~50% on all platforms. Predictions for non-binary comments on all platforms are mostly female, thus propagating the societal bias that non-binary individuals are effeminate. To address this, we fine-tune a BERT multi-label classifier on the two datasets in multiple combinations, observe an o",
    "path": "papers/23/10/2310.06061.json",
    "total_tokens": 903,
    "translated_title": "对文本数据中的性别分析器进行审计",
    "translated_abstract": "AI模型已经变得非常流行和可访问，然而，它们不断受到批评，因为它们对各个社会群体，如有色人种和非二元性别人群，存在可证明的偏见。在这项研究中，我们对三种已有的性别分析器 - uClassify，Readable和HackerFactor进行审计，以评估它们针对非二元个体存在的偏见。这些工具仅设计用于预测二元性别标签，因此对非二元性别社会成员存在歧视。我们整理了两个数据集-Reddit评论（660k）和Tumblr帖子（2.05M），我们的实验评估显示这些工具在所有平台上的总体准确率约为50%。所有平台上针对非二元评论的预测主要是女性，从而传播了社会对非二元人群的偏见，认为他们是女性化的。为了解决这个问题，我们在这两个数据集上以多种组合对BERT多标签分类器进行了微调实验，并观察到一个 o",
    "tldr": "对三种现有的性别分析器进行了不对二元个体做预测的偏见的审计，发现这些工具在准确性上存在严重问题，并且对非二元评论的预测主要是女性，从而传播了对非二元人群的偏见。",
    "en_tdlr": "An audit was conducted on three existing gender analyzers to assess biases against non-binary individuals, revealing significant accuracy issues and a tendency to label non-binary comments as female, perpetuating bias against this group."
}