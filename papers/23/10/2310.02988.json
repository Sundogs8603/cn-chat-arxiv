{
    "title": "Probing Intersectional Biases in Vision-Language Models with Counterfactual Examples. (arXiv:2310.02988v1 [cs.CV])",
    "abstract": "While vision-language models (VLMs) have achieved remarkable performance improvements recently, there is growing evidence that these models also posses harmful biases with respect to social attributes such as gender and race. Prior studies have primarily focused on probing such bias attributes individually while ignoring biases associated with intersections between social attributes. This could be due to the difficulty of collecting an exhaustive set of image-text pairs for various combinations of social attributes from existing datasets. To address this challenge, we employ text-to-image diffusion models to produce counterfactual examples for probing intserctional social biases at scale. Our approach utilizes Stable Diffusion with cross attention control to produce sets of counterfactual image-text pairs that are highly similar in their depiction of a subject (e.g., a given occupation) while differing only in their depiction of intersectional social attributes (e.g., race & gender). W",
    "link": "http://arxiv.org/abs/2310.02988",
    "context": "Title: Probing Intersectional Biases in Vision-Language Models with Counterfactual Examples. (arXiv:2310.02988v1 [cs.CV])\nAbstract: While vision-language models (VLMs) have achieved remarkable performance improvements recently, there is growing evidence that these models also posses harmful biases with respect to social attributes such as gender and race. Prior studies have primarily focused on probing such bias attributes individually while ignoring biases associated with intersections between social attributes. This could be due to the difficulty of collecting an exhaustive set of image-text pairs for various combinations of social attributes from existing datasets. To address this challenge, we employ text-to-image diffusion models to produce counterfactual examples for probing intserctional social biases at scale. Our approach utilizes Stable Diffusion with cross attention control to produce sets of counterfactual image-text pairs that are highly similar in their depiction of a subject (e.g., a given occupation) while differing only in their depiction of intersectional social attributes (e.g., race & gender). W",
    "path": "papers/23/10/2310.02988.json",
    "total_tokens": 867,
    "translated_title": "使用反事实例子探究视觉-语言模型中的交叉偏见",
    "translated_abstract": "虽然近年来视觉-语言模型（VLMs）取得了显著的性能提升，但越来越多的证据表明这些模型在性别和种族等社会属性方面也存在有害的偏见。先前的研究主要集中于个别探测这种偏见属性，而忽视了与社会属性交叉相关的偏见。这可能是因为从现有数据集中收集包含各种社会属性组合的图像-文本对的完整集合非常困难。为了解决这一挑战，我们采用文本到图像扩散模型，在规模上生成反事实的例子来探测交叉社会偏见。我们的方法利用稳定扩散和交叉注意力控制，生成了一组反事实的图像-文本对，它们在描述主题（例如某个职业）方面非常相似，只在描述交叉社会属性（例如种族和性别）方面有所不同。",
    "tldr": "本研究利用反事实例子探究了视觉-语言模型中的交叉偏见，并通过文本到图像扩散模型生成了一组高度相似但存在交叉社会属性差异的图像-文本对。",
    "en_tdlr": "This study probes intersectional biases in vision-language models and generates a set of highly similar image-text pairs with counterfactual examples using text-to-image diffusion models."
}