{
    "title": "Exact Verification of ReLU Neural Control Barrier Functions. (arXiv:2310.09360v1 [cs.LG])",
    "abstract": "Control Barrier Functions (CBFs) are a popular approach for safe control of nonlinear systems. In CBF-based control, the desired safety properties of the system are mapped to nonnegativity of a CBF, and the control input is chosen to ensure that the CBF remains nonnegative for all time. Recently, machine learning methods that represent CBFs as neural networks (neural control barrier functions, or NCBFs) have shown great promise due to the universal representability of neural networks. However, verifying that a learned CBF guarantees safety remains a challenging research problem. This paper presents novel exact conditions and algorithms for verifying safety of feedforward NCBFs with ReLU activation functions. The key challenge in doing so is that, due to the piecewise linearity of the ReLU function, the NCBF will be nondifferentiable at certain points, thus invalidating traditional safety verification methods that assume a smooth barrier function. We resolve this issue by leveraging a g",
    "link": "http://arxiv.org/abs/2310.09360",
    "context": "Title: Exact Verification of ReLU Neural Control Barrier Functions. (arXiv:2310.09360v1 [cs.LG])\nAbstract: Control Barrier Functions (CBFs) are a popular approach for safe control of nonlinear systems. In CBF-based control, the desired safety properties of the system are mapped to nonnegativity of a CBF, and the control input is chosen to ensure that the CBF remains nonnegative for all time. Recently, machine learning methods that represent CBFs as neural networks (neural control barrier functions, or NCBFs) have shown great promise due to the universal representability of neural networks. However, verifying that a learned CBF guarantees safety remains a challenging research problem. This paper presents novel exact conditions and algorithms for verifying safety of feedforward NCBFs with ReLU activation functions. The key challenge in doing so is that, due to the piecewise linearity of the ReLU function, the NCBF will be nondifferentiable at certain points, thus invalidating traditional safety verification methods that assume a smooth barrier function. We resolve this issue by leveraging a g",
    "path": "papers/23/10/2310.09360.json",
    "total_tokens": 911,
    "translated_title": "ReLU神经控制屏障函数的精确验证",
    "translated_abstract": "控制屏障函数(CBFs)是一种用于非线性系统安全控制的常用方法。在基于CBF的控制中，系统的期望安全性质被映射到CBF的非负性，控制输入被选择以确保CBF始终保持非负。最近，将CBFs表示为神经网络(神经控制屏障函数，或NCBFs)的机器学习方法由于神经网络的普适表示能力而显示出巨大的潜力。然而，验证学习到的CBF是否能保证安全性仍然是一个具有挑战性的研究问题。本文提出了一种针对具有ReLU激活函数的前馈NCBFs的精确条件和算法来验证安全性。其中的关键挑战在于，由于ReLU函数的分段线性性质，在某些点处NCBF将是不可微的，因此无效地使传统的安全验证方法无法适用，这些方法假设一个光滑的屏障函数。我们通过利用g函数解决了这个问题。",
    "tldr": "本文提出了一种用于验证具有ReLU激活函数的前馈神经控制屏障函数的安全性的新精确条件和算法，克服了传统安全验证方法中ReLU函数的不可微性质的挑战。",
    "en_tdlr": "This paper presents novel exact conditions and algorithms for verifying safety of feedforward neural control barrier functions (NCBFs) with ReLU activation functions, overcoming the challenge of the non-differentiability of ReLU functions in traditional safety verification methods."
}