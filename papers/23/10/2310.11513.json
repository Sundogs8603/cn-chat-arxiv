{
    "title": "GenEval: An Object-Focused Framework for Evaluating Text-to-Image Alignment. (arXiv:2310.11513v1 [cs.CV])",
    "abstract": "Recent breakthroughs in diffusion models, multimodal pretraining, and efficient finetuning have led to an explosion of text-to-image generative models. Given human evaluation is expensive and difficult to scale, automated methods are critical for evaluating the increasingly large number of new models. However, most current automated evaluation metrics like FID or CLIPScore only offer a holistic measure of image quality or image-text alignment, and are unsuited for fine-grained or instance-level analysis. In this paper, we introduce GenEval, an object-focused framework to evaluate compositional image properties such as object co-occurrence, position, count, and color. We show that current object detection models can be leveraged to evaluate text-to-image models on a variety of generation tasks with strong human agreement, and that other discriminative vision models can be linked to this pipeline to further verify properties like object color. We then evaluate several open-source text-to",
    "link": "http://arxiv.org/abs/2310.11513",
    "context": "Title: GenEval: An Object-Focused Framework for Evaluating Text-to-Image Alignment. (arXiv:2310.11513v1 [cs.CV])\nAbstract: Recent breakthroughs in diffusion models, multimodal pretraining, and efficient finetuning have led to an explosion of text-to-image generative models. Given human evaluation is expensive and difficult to scale, automated methods are critical for evaluating the increasingly large number of new models. However, most current automated evaluation metrics like FID or CLIPScore only offer a holistic measure of image quality or image-text alignment, and are unsuited for fine-grained or instance-level analysis. In this paper, we introduce GenEval, an object-focused framework to evaluate compositional image properties such as object co-occurrence, position, count, and color. We show that current object detection models can be leveraged to evaluate text-to-image models on a variety of generation tasks with strong human agreement, and that other discriminative vision models can be linked to this pipeline to further verify properties like object color. We then evaluate several open-source text-to",
    "path": "papers/23/10/2310.11513.json",
    "total_tokens": 938,
    "translated_title": "GenEval：用于评估文本到图像对齐的面向对象框架",
    "translated_abstract": "最近，在扩散模型、多模态预训练和高效微调方面取得了突破，导致了文本到图像生成模型的爆炸性增长。由于人工评估昂贵且难以扩展，自动化方法对于评估越来越多的新模型至关重要。然而，目前大多数自动化评估指标（如FID或CLIPScore）仅提供图像质量或图像-文本对齐的整体度量，并不适用于细粒度或实例级别的分析。在本文中，我们引入了一个名为GenEval的面向对象的框架，用于评估图像的组成属性，如对象共现、位置、计数和颜色。我们展示了当前的对象检测模型可以用于在多种生成任务上评估文本到图像模型，并且得到了与人类的强一致性，其余的视觉判别模型可以链接到这个流程中，进一步验证像对象颜色这样的属性。然后，我们对几个开源的文本到图像模型进行评估。",
    "tldr": "本论文介绍了GenEval，一种面向对象的框架，用于评估文本到图像生成模型的组成属性。通过利用当前的对象检测模型，我们可以在各种生成任务上评估文本到图像模型，并通过其他视觉判别模型进一步验证属性。",
    "en_tdlr": "This paper introduces GenEval, an object-focused framework for evaluating the composition properties of text-to-image generative models. By leveraging current object detection models, it evaluates text-to-image models on various generation tasks and further verifies properties using discriminative vision models."
}