{
    "title": "SD-HuBERT: Self-Distillation Induces Syllabic Organization in HuBERT. (arXiv:2310.10803v1 [cs.CL])",
    "abstract": "Data-driven unit discovery in self-supervised learning (SSL) of speech has embarked on a new era of spoken language processing. Yet, the discovered units often remain in phonetic space, limiting the utility of SSL representations. Here, we demonstrate that a syllabic organization emerges in learning sentence-level representation of speech. In particular, we adopt \"self-distillation\" objective to fine-tune the pretrained HuBERT with an aggregator token that summarizes the entire sentence. Without any supervision, the resulting model draws definite boundaries in speech, and the representations across frames show salient syllabic structures. We demonstrate that this emergent structure largely corresponds to the ground truth syllables. Furthermore, we propose a new benchmark task, Spoken Speech ABX, for evaluating sentence-level representation of speech. When compared to previous models, our model outperforms in both unsupervised syllable discovery and learning sentence-level representatio",
    "link": "http://arxiv.org/abs/2310.10803",
    "context": "Title: SD-HuBERT: Self-Distillation Induces Syllabic Organization in HuBERT. (arXiv:2310.10803v1 [cs.CL])\nAbstract: Data-driven unit discovery in self-supervised learning (SSL) of speech has embarked on a new era of spoken language processing. Yet, the discovered units often remain in phonetic space, limiting the utility of SSL representations. Here, we demonstrate that a syllabic organization emerges in learning sentence-level representation of speech. In particular, we adopt \"self-distillation\" objective to fine-tune the pretrained HuBERT with an aggregator token that summarizes the entire sentence. Without any supervision, the resulting model draws definite boundaries in speech, and the representations across frames show salient syllabic structures. We demonstrate that this emergent structure largely corresponds to the ground truth syllables. Furthermore, we propose a new benchmark task, Spoken Speech ABX, for evaluating sentence-level representation of speech. When compared to previous models, our model outperforms in both unsupervised syllable discovery and learning sentence-level representatio",
    "path": "papers/23/10/2310.10803.json",
    "total_tokens": 1014,
    "translated_title": "SD-HuBERT: 自我蒸馏诱导HuBERT中的音节组织",
    "translated_abstract": "自我监督学习（SSL）中的数据驱动单元发现开启了口语语言处理的新时代。然而，发现的单元往往仍处于音素空间，限制了SSL表示的实用性。在这里，我们展示了在学习语音的句子级表示时，音节组织的出现。特别地，我们采用“自我蒸馏”目标来微调预训练的HuBERT，并加入一个汇聚标记来总结整个句子。在没有任何监督的情况下，得到的模型在语音中划定了明确的边界，并且帧间的表示显示出显著的音节结构。我们证明这种出现的结构很大程度上与真实音节对应。此外，我们提出了一个新的基准任务，Spoken Speech ABX，用于评估语音的句子级表示。与之前的模型相比，我们的模型在无监督音节发现和学习句子级表示方面表现优异。",
    "tldr": "本研究提出了SD-HuBERT模型，通过采用自我蒸馏目标进行微调，实现了在学习语音句子级表示时音节组织的出现，模型能够在语音中划定明确的边界，并展现出显著的音节结构。该研究还提出了一个新的基准任务用于评估语音的句子级表示，与之前的模型相比，在无监督音节发现和学习句子级表示方面表现优异。",
    "en_tdlr": "This study proposes the SD-HuBERT model, which utilizes self-distillation objective for fine-tuning, resulting in the emergence of syllabic organization in learning sentence-level representation of speech. The model is able to define clear boundaries in speech, showing salient syllabic structures. Additionally, a new benchmark task is introduced for evaluating sentence-level representation of speech, in which the model outperforms previous models in unsupervised syllable discovery and learning sentence-level representation."
}