{
    "title": "An Information Bottleneck Characterization of the Understanding-Workload Tradeoff. (arXiv:2310.07802v1 [cs.AI])",
    "abstract": "Recent advances in artificial intelligence (AI) have underscored the need for explainable AI (XAI) to support human understanding of AI systems. Consideration of human factors that impact explanation efficacy, such as mental workload and human understanding, is central to effective XAI design. Existing work in XAI has demonstrated a tradeoff between understanding and workload induced by different types of explanations. Explaining complex concepts through abstractions (hand-crafted groupings of related problem features) has been shown to effectively address and balance this workload-understanding tradeoff. In this work, we characterize the workload-understanding balance via the Information Bottleneck method: an information-theoretic approach which automatically generates abstractions that maximize informativeness and minimize complexity. In particular, we establish empirical connections between workload and complexity and between understanding and informativeness through human-subject e",
    "link": "http://arxiv.org/abs/2310.07802",
    "context": "Title: An Information Bottleneck Characterization of the Understanding-Workload Tradeoff. (arXiv:2310.07802v1 [cs.AI])\nAbstract: Recent advances in artificial intelligence (AI) have underscored the need for explainable AI (XAI) to support human understanding of AI systems. Consideration of human factors that impact explanation efficacy, such as mental workload and human understanding, is central to effective XAI design. Existing work in XAI has demonstrated a tradeoff between understanding and workload induced by different types of explanations. Explaining complex concepts through abstractions (hand-crafted groupings of related problem features) has been shown to effectively address and balance this workload-understanding tradeoff. In this work, we characterize the workload-understanding balance via the Information Bottleneck method: an information-theoretic approach which automatically generates abstractions that maximize informativeness and minimize complexity. In particular, we establish empirical connections between workload and complexity and between understanding and informativeness through human-subject e",
    "path": "papers/23/10/2310.07802.json",
    "total_tokens": 855,
    "translated_title": "对理解-工作负荷权衡的信息瓶颈特征化",
    "translated_abstract": "最近人工智能的进展突显了对可解释人工智能（XAI）的需求，以支持人类对人工智能系统的理解。考虑到影响解释效力的人类因素，如心理负荷和人类理解，是有效的XAI设计的核心。现有的XAI研究已经证明了不同类型的解释引起的理解和工作负荷之间的权衡。通过抽象（手工制作的相关问题特征的组合）解释复杂概念已被证明能够有效地解决和平衡这种工作负荷-理解的权衡。在这项工作中，我们通过信息瓶颈方法对工作负荷-理解平衡进行特征化：这是一种自动生成最大化信息量和最小化复杂性的抽象的信息论方法。特别地，我们通过人体实验建立了工作负荷与复杂性之间以及理解与信息量之间的实证联系。",
    "tldr": "本论文利用信息瓶颈方法对工作负荷和理解之间的平衡进行了特征化，通过抽象化来解释复杂概念，以实现工作负荷和理解之间的权衡。"
}