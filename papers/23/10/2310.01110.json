{
    "title": "Prompt-tuning latent diffusion models for inverse problems. (arXiv:2310.01110v1 [cs.LG])",
    "abstract": "We propose a new method for solving imaging inverse problems using text-to-image latent diffusion models as general priors. Existing methods using latent diffusion models for inverse problems typically rely on simple null text prompts, which can lead to suboptimal performance. To address this limitation, we introduce a method for prompt tuning, which jointly optimizes the text embedding on-the-fly while running the reverse diffusion process. This allows us to generate images that are more faithful to the diffusion prior. In addition, we propose a method to keep the evolution of latent variables within the range space of the encoder, by projection. This helps to reduce image artifacts, a major problem when using latent diffusion models instead of pixel-based diffusion models. Our combined method, called P2L, outperforms both image- and latent-diffusion model-based inverse problem solvers on a variety of tasks, such as super-resolution, deblurring, and inpainting.",
    "link": "http://arxiv.org/abs/2310.01110",
    "context": "Title: Prompt-tuning latent diffusion models for inverse problems. (arXiv:2310.01110v1 [cs.LG])\nAbstract: We propose a new method for solving imaging inverse problems using text-to-image latent diffusion models as general priors. Existing methods using latent diffusion models for inverse problems typically rely on simple null text prompts, which can lead to suboptimal performance. To address this limitation, we introduce a method for prompt tuning, which jointly optimizes the text embedding on-the-fly while running the reverse diffusion process. This allows us to generate images that are more faithful to the diffusion prior. In addition, we propose a method to keep the evolution of latent variables within the range space of the encoder, by projection. This helps to reduce image artifacts, a major problem when using latent diffusion models instead of pixel-based diffusion models. Our combined method, called P2L, outperforms both image- and latent-diffusion model-based inverse problem solvers on a variety of tasks, such as super-resolution, deblurring, and inpainting.",
    "path": "papers/23/10/2310.01110.json",
    "total_tokens": 986,
    "translated_title": "用于逆问题的Prompt-tuning潜在扩散模型",
    "translated_abstract": "我们提出了一种使用文本到图像潜在扩散模型作为通用先验解决成像逆问题的新方法。现有的使用潜在扩散模型解决逆问题的方法通常依赖简单的空文本提示，这可能导致性能不佳。为了解决这个限制，我们引入了一种Prompt-tuning方法，在运行反向扩散过程时实时优化文本嵌入。这使我们能够生成更符合扩散先验的图像。此外，我们提出了一种通过投影将潜在变量的演化保持在编码器的范围空间内的方法。这有助于减少使用潜在扩散模型而不是基于像素的扩散模型时产生的图像伪影问题。我们提出的综合方法称为P2L，在各种任务（如超分辨率、去模糊和修复）中优于基于图像和基于潜在扩散模型的逆问题求解器。",
    "tldr": "本论文提出了一种使用文本到图像潜在扩散模型作为通用先验解决成像逆问题的方法。通过Prompt-tuning将文本嵌入进行实时优化，同时通过投影保持潜在变量的演化在编码器的范围空间内，使生成图像更符合扩散先验。这种综合方法，在超分辨率、去模糊和修复等各种任务中，优于基于图像和基于潜在扩散模型的逆问题求解器。",
    "en_tdlr": "This paper proposes a method for solving imaging inverse problems using text-to-image latent diffusion models as general priors. By tuning the text prompts and keeping the evolution of latent variables within the range space of the encoder, the proposed method generates images that are more faithful to the diffusion prior, outperforming existing solvers on various tasks."
}