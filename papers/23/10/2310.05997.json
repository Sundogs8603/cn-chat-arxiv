{
    "title": "Cost-sensitive probabilistic predictions for support vector machines. (arXiv:2310.05997v1 [stat.ML])",
    "abstract": "Support vector machines (SVMs) are widely used and constitute one of the best examined and used machine learning models for two-class classification. Classification in SVM is based on a score procedure, yielding a deterministic classification rule, which can be transformed into a probabilistic rule (as implemented in off-the-shelf SVM libraries), but is not probabilistic in nature. On the other hand, the tuning of the regularization parameters in SVM is known to imply a high computational effort and generates pieces of information that are not fully exploited, not being used to build a probabilistic classification rule. In this paper we propose a novel approach to generate probabilistic outputs for the SVM. The new method has the following three properties. First, it is designed to be cost-sensitive, and thus the different importance of sensitivity (or true positive rate, TPR) and specificity (true negative rate, TNR) is readily accommodated in the model. As a result, the model can dea",
    "link": "http://arxiv.org/abs/2310.05997",
    "context": "Title: Cost-sensitive probabilistic predictions for support vector machines. (arXiv:2310.05997v1 [stat.ML])\nAbstract: Support vector machines (SVMs) are widely used and constitute one of the best examined and used machine learning models for two-class classification. Classification in SVM is based on a score procedure, yielding a deterministic classification rule, which can be transformed into a probabilistic rule (as implemented in off-the-shelf SVM libraries), but is not probabilistic in nature. On the other hand, the tuning of the regularization parameters in SVM is known to imply a high computational effort and generates pieces of information that are not fully exploited, not being used to build a probabilistic classification rule. In this paper we propose a novel approach to generate probabilistic outputs for the SVM. The new method has the following three properties. First, it is designed to be cost-sensitive, and thus the different importance of sensitivity (or true positive rate, TPR) and specificity (true negative rate, TNR) is readily accommodated in the model. As a result, the model can dea",
    "path": "papers/23/10/2310.05997.json",
    "total_tokens": 799,
    "translated_title": "成本敏感的支持向量机的概率预测",
    "translated_abstract": "支持向量机（SVM）被广泛使用，是最受关注和使用的二元分类机器学习模型之一。SVM的分类是基于得分过程的，得到的是确定性的分类规则，可以转化为概率规则（在现成的SVM库中实现），但本质上并不是概率性的。另一方面，SVM中正则化参数的调优被认为需要很高的计算量，并且生成的信息没有充分利用，没有用于构建概率分类规则。在本文中，我们提出了一种新方法来生成SVM的概率输出。新方法具有以下三个特点。首先，它是设计为成本敏感的，因此可以很容易地适应敏感性（或真正例率，TPR）和特异性（真负例率，TNR）的不同重要性。结果，模型能够处理成本敏感的问题。",
    "tldr": "提出了一种新方法，将支持向量机转化为成本敏感的概率分类器，并充分利用了正则化参数的信息。",
    "en_tdlr": "A novel approach is proposed to transform support vector machines into cost-sensitive probabilistic classifiers, fully utilizing the information of regularization parameters."
}