{
    "title": "Large language models for aspect-based sentiment analysis. (arXiv:2310.18025v1 [cs.CL])",
    "abstract": "Large language models (LLMs) offer unprecedented text completion capabilities. As general models, they can fulfill a wide range of roles, including those of more specialized models. We assess the performance of GPT-4 and GPT-3.5 in zero shot, few shot and fine-tuned settings on the aspect-based sentiment analysis (ABSA) task. Fine-tuned GPT-3.5 achieves a state-of-the-art F1 score of 83.8 on the joint aspect term extraction and polarity classification task of the SemEval-2014 Task 4, improving upon InstructABSA [@scaria_instructabsa_2023] by 5.7%. However, this comes at the price of 1000 times more model parameters and thus increased inference cost. We discuss the the cost-performance trade-offs of different models, and analyze the typical errors that they make. Our results also indicate that detailed prompts improve performance in zero-shot and few-shot settings but are not necessary for fine-tuned models. This evidence is relevant for practioners that are faced with the choice of pro",
    "link": "http://arxiv.org/abs/2310.18025",
    "context": "Title: Large language models for aspect-based sentiment analysis. (arXiv:2310.18025v1 [cs.CL])\nAbstract: Large language models (LLMs) offer unprecedented text completion capabilities. As general models, they can fulfill a wide range of roles, including those of more specialized models. We assess the performance of GPT-4 and GPT-3.5 in zero shot, few shot and fine-tuned settings on the aspect-based sentiment analysis (ABSA) task. Fine-tuned GPT-3.5 achieves a state-of-the-art F1 score of 83.8 on the joint aspect term extraction and polarity classification task of the SemEval-2014 Task 4, improving upon InstructABSA [@scaria_instructabsa_2023] by 5.7%. However, this comes at the price of 1000 times more model parameters and thus increased inference cost. We discuss the the cost-performance trade-offs of different models, and analyze the typical errors that they make. Our results also indicate that detailed prompts improve performance in zero-shot and few-shot settings but are not necessary for fine-tuned models. This evidence is relevant for practioners that are faced with the choice of pro",
    "path": "papers/23/10/2310.18025.json",
    "total_tokens": 994,
    "translated_title": "大型语言模型用于基于方面的情感分析",
    "translated_abstract": "大型语言模型（LLMs）提供了前所未有的文本完成能力。作为通用模型，它们可以担任各种角色，包括更专门的模型。我们评估了GPT-4和GPT-3.5在基于方面的情感分析（ABSA）任务中的零-shot、少-shot和微调设置下的性能。微调后的GPT-3.5在SemEval-2014任务4的联合方面术语提取和极性分类任务上取得了83.8的最先进F1分数，相比于InstructABSA [Scaria等人，2023]提高了5.7％。然而，这是以1000倍更多的模型参数和因此增加的推理成本为代价的。我们讨论了不同模型的成本性能权衡，并分析了它们的典型错误。我们的结果还表明，在零-shot和少-shot设置中，详细提示可以提高性能，但对于微调模型来说并不是必要的。这些证据对于面临选择问题的实践者是相关的。",
    "tldr": "该论文评估了GPT-4和GPT-3.5在基于方面的情感分析任务中的性能，并发现微调后的GPT-3.5在SemEval-2014任务4中取得了83.8的最先进F1分数，相比于InstructABSA提高了5.7%。但是，这需要1000倍的模型参数增加了推理成本。"
}