{
    "title": "Leveraging Low-Rank and Sparse Recurrent Connectivity for Robust Closed-Loop Control. (arXiv:2310.03915v1 [cs.LG])",
    "abstract": "Developing autonomous agents that can interact with changing environments is an open challenge in machine learning. Robustness is particularly important in these settings as agents are often fit offline on expert demonstrations but deployed online where they must generalize to the closed feedback loop within the environment. In this work, we explore the application of recurrent neural networks to tasks of this nature and understand how a parameterization of their recurrent connectivity influences robustness in closed-loop settings. Specifically, we represent the recurrent connectivity as a function of rank and sparsity and show both theoretically and empirically that modulating these two variables has desirable effects on network dynamics. The proposed low-rank, sparse connectivity induces an interpretable prior on the network that proves to be most amenable for a class of models known as closed-form continuous-time neural networks (CfCs). We find that CfCs with fewer parameters can ou",
    "link": "http://arxiv.org/abs/2310.03915",
    "context": "Title: Leveraging Low-Rank and Sparse Recurrent Connectivity for Robust Closed-Loop Control. (arXiv:2310.03915v1 [cs.LG])\nAbstract: Developing autonomous agents that can interact with changing environments is an open challenge in machine learning. Robustness is particularly important in these settings as agents are often fit offline on expert demonstrations but deployed online where they must generalize to the closed feedback loop within the environment. In this work, we explore the application of recurrent neural networks to tasks of this nature and understand how a parameterization of their recurrent connectivity influences robustness in closed-loop settings. Specifically, we represent the recurrent connectivity as a function of rank and sparsity and show both theoretically and empirically that modulating these two variables has desirable effects on network dynamics. The proposed low-rank, sparse connectivity induces an interpretable prior on the network that proves to be most amenable for a class of models known as closed-form continuous-time neural networks (CfCs). We find that CfCs with fewer parameters can ou",
    "path": "papers/23/10/2310.03915.json",
    "total_tokens": 913,
    "translated_title": "利用低秩和稀疏的循环连接进行鲁棒闭环控制",
    "translated_abstract": "在机器学习中，开发能够与变化环境进行交互的自主代理是一个开放性挑战。在这些环境中，稳健性尤为重要，因为代理通常是在专家示范中进行离线拟合，但在在线部署时必须能够推广到环境内的闭环反馈中。在这项工作中，我们探讨了将递归神经网络应用于这类任务，并了解其循环连接参数化如何影响闭环设置的鲁棒性。具体而言，我们将循环连接表示为秩和稀疏性的函数，并从理论和实证的角度展示调节这两个变量对网络动态的有益影响。所提出的低秩稀疏连接为网络引入了可解释性先验，对于一类称为闭式连续时间神经网络（CfCs）的模型最为适用。我们发现，具有较少参数的CfCs可以超过其他模型的表现。",
    "tldr": "本文探讨了将循环神经网络应用于鲁棒闭环控制任务，研究循环连接的秩和稀疏性如何影响网络的稳定性。实验证明，采用低秩稀疏连接可以在闭环设置中取得良好效果。"
}