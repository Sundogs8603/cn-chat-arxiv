{
    "title": "On the Interpretability of Part-Prototype Based Classifiers: A Human Centric Analysis. (arXiv:2310.06966v1 [cs.CV])",
    "abstract": "Part-prototype networks have recently become methods of interest as an interpretable alternative to many of the current black-box image classifiers. However, the interpretability of these methods from the perspective of human users has not been sufficiently explored. In this work, we have devised a framework for evaluating the interpretability of part-prototype-based models from a human perspective. The proposed framework consists of three actionable metrics and experiments. To demonstrate the usefulness of our framework, we performed an extensive set of experiments using Amazon Mechanical Turk. They not only show the capability of our framework in assessing the interpretability of various part-prototype-based models, but they also are, to the best of our knowledge, the most comprehensive work on evaluating such methods in a unified framework.",
    "link": "http://arxiv.org/abs/2310.06966",
    "context": "Title: On the Interpretability of Part-Prototype Based Classifiers: A Human Centric Analysis. (arXiv:2310.06966v1 [cs.CV])\nAbstract: Part-prototype networks have recently become methods of interest as an interpretable alternative to many of the current black-box image classifiers. However, the interpretability of these methods from the perspective of human users has not been sufficiently explored. In this work, we have devised a framework for evaluating the interpretability of part-prototype-based models from a human perspective. The proposed framework consists of three actionable metrics and experiments. To demonstrate the usefulness of our framework, we performed an extensive set of experiments using Amazon Mechanical Turk. They not only show the capability of our framework in assessing the interpretability of various part-prototype-based models, but they also are, to the best of our knowledge, the most comprehensive work on evaluating such methods in a unified framework.",
    "path": "papers/23/10/2310.06966.json",
    "total_tokens": 845,
    "translated_title": "关于基于部分原型的分类器的可解释性：人类中心分析",
    "translated_abstract": "最近，基于部分原型的网络已成为许多黑盒图像分类器的可解释性替代方法。然而，从人类用户的角度来看，这些方法的可解释性还未得到充分探索。在这项工作中，我们设计了一个从人类角度评估基于部分原型模型可解释性的框架。该框架由三个可操作的度量和实验组成。为了展示我们的框架的实用性，我们使用了亚马逊机械土耳其进行了一系列广泛的实验。它们不仅展示了我们的框架在评估各种基于部分原型模型的可解释性方面的能力，而且是我们所知的在一个统一的框架中评估这些方法最全面的工作。",
    "tldr": "本论文提出了一个用于从人类角度评估基于部分原型模型可解释性的框架，并使用亚马逊机械土耳其进行了广泛实验。这些实验不仅展示了框架在评估各种基于部分原型模型的可解释性方面的能力，还是最全面的工作。",
    "en_tdlr": "This paper proposes a framework for evaluating the interpretability of part-prototype-based models from a human perspective. Extensive experiments using Amazon Mechanical Turk demonstrate the framework's ability to assess the interpretability of various part-prototype-based models and establish this work as the most comprehensive in evaluating such methods in a unified framework."
}