{
    "title": "MULTITuDE: Large-Scale Multilingual Machine-Generated Text Detection Benchmark. (arXiv:2310.13606v1 [cs.CL])",
    "abstract": "There is a lack of research into capabilities of recent LLMs to generate convincing text in languages other than English and into performance of detectors of machine-generated text in multilingual settings. This is also reflected in the available benchmarks which lack authentic texts in languages other than English and predominantly cover older generators. To fill this gap, we introduce MULTITuDE, a novel benchmarking dataset for multilingual machine-generated text detection comprising of 74,081 authentic and machine-generated texts in 11 languages (ar, ca, cs, de, en, es, nl, pt, ru, uk, and zh) generated by 8 multilingual LLMs. Using this benchmark, we compare the performance of zero-shot (statistical and black-box) and fine-tuned detectors. Considering the multilinguality, we evaluate 1) how these detectors generalize to unseen languages (linguistically similar as well as dissimilar) and unseen LLMs and 2) whether the detectors improve their performance when trained on multiple lang",
    "link": "http://arxiv.org/abs/2310.13606",
    "context": "Title: MULTITuDE: Large-Scale Multilingual Machine-Generated Text Detection Benchmark. (arXiv:2310.13606v1 [cs.CL])\nAbstract: There is a lack of research into capabilities of recent LLMs to generate convincing text in languages other than English and into performance of detectors of machine-generated text in multilingual settings. This is also reflected in the available benchmarks which lack authentic texts in languages other than English and predominantly cover older generators. To fill this gap, we introduce MULTITuDE, a novel benchmarking dataset for multilingual machine-generated text detection comprising of 74,081 authentic and machine-generated texts in 11 languages (ar, ca, cs, de, en, es, nl, pt, ru, uk, and zh) generated by 8 multilingual LLMs. Using this benchmark, we compare the performance of zero-shot (statistical and black-box) and fine-tuned detectors. Considering the multilinguality, we evaluate 1) how these detectors generalize to unseen languages (linguistically similar as well as dissimilar) and unseen LLMs and 2) whether the detectors improve their performance when trained on multiple lang",
    "path": "papers/23/10/2310.13606.json",
    "total_tokens": 1038,
    "translated_title": "MULTITuDE: 大规模多语言机器生成文本检测基准",
    "translated_abstract": "目前对于最近的LLMs生成其他语言的令人信服的文本能力以及多语言环境下机器生成文本检测器的性能研究不足。这也反映在现有的基准数据集中，缺乏其他语言真实文本，主要涵盖较旧的生成器。为了填补这一空白，我们引入了MULTITuDE，一个新颖的多语言机器生成文本检测基准数据集，包含11种语言（阿拉伯语，加泰罗尼亚语，捷克语，德语，英语，西班牙语，荷兰语，葡萄牙语，俄语，乌克兰语和中文）生成的74,081个真实和机器生成的文本，由8个多语言LLMs生成。使用这个基准，我们比较了零样本（统计和黑盒）和微调检测器的性能。考虑到多语性，我们评估了1）这些检测器对于未见过的语言（语言上相似和不相似的语言）和未见过的LLMs的泛化能力，以及2）当在多个语言上进行训练时，检测器是否能提高其性能。",
    "tldr": "这篇论文介绍了MULTITuDE，一个针对多语言机器生成文本检测的基准数据集。通过比较不同的检测器在零样本和微调情况下的性能，研究了这些检测器对于未见过的语言和生成器的泛化能力，并探讨了在多语言训练下检测器的性能提升。",
    "en_tdlr": "This paper introduces MULTITuDE, a benchmark dataset for multilingual machine-generated text detection. By comparing the performance of different detectors under zero-shot and fine-tuning scenarios, it investigates the generalization ability of these detectors to unseen languages and generators, and explores the performance improvement of detectors trained on multiple languages."
}