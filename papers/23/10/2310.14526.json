{
    "title": "Towards Zero Shot Learning in Restless Multi-armed Bandits. (arXiv:2310.14526v2 [cs.LG] UPDATED)",
    "abstract": "Restless multi-arm bandits (RMABs), a class of resource allocation problems with broad application in areas such as healthcare, online advertising, and anti-poaching, have recently been studied from a multi-agent reinforcement learning perspective. Prior RMAB research suffers from several limitations, e.g., it fails to adequately address continuous states, and requires retraining from scratch when arms opt-in and opt-out over time, a common challenge in many real world applications. We address these limitations by developing a neural network-based pre-trained model (PreFeRMAB) that has general zero-shot ability on a wide range of previously unseen RMABs, and which can be fine-tuned on specific instances in a more sample-efficient way than retraining from scratch. Our model also accommodates general multi-action settings and discrete or continuous state spaces. To enable fast generalization, we learn a novel single policy network model that utilizes feature information and employs a tra",
    "link": "http://arxiv.org/abs/2310.14526",
    "context": "Title: Towards Zero Shot Learning in Restless Multi-armed Bandits. (arXiv:2310.14526v2 [cs.LG] UPDATED)\nAbstract: Restless multi-arm bandits (RMABs), a class of resource allocation problems with broad application in areas such as healthcare, online advertising, and anti-poaching, have recently been studied from a multi-agent reinforcement learning perspective. Prior RMAB research suffers from several limitations, e.g., it fails to adequately address continuous states, and requires retraining from scratch when arms opt-in and opt-out over time, a common challenge in many real world applications. We address these limitations by developing a neural network-based pre-trained model (PreFeRMAB) that has general zero-shot ability on a wide range of previously unseen RMABs, and which can be fine-tuned on specific instances in a more sample-efficient way than retraining from scratch. Our model also accommodates general multi-action settings and discrete or continuous state spaces. To enable fast generalization, we learn a novel single policy network model that utilizes feature information and employs a tra",
    "path": "papers/23/10/2310.14526.json",
    "total_tokens": 965,
    "translated_title": "在不断变化的多臂赌博机中实现零样本学习",
    "translated_abstract": "近来，通过多智能体强化学习的视角研究了一类资源分配问题——不断变化的多臂赌博机（RMABs），该问题在医疗保健、在线广告和反盗猎等领域具有广泛应用。先前的RMAB研究存在一些限制，例如没有充分解决连续状态问题，并且在多个真实世界应用中，当赌博机的入选和退出不断发生时，需要从头开始重新训练，这是一个常见的挑战。为了解决这些限制，我们开发了一个基于神经网络的预训练模型（PreFeRMAB），该模型具有对之前未见过的广泛RMAB问题的零样本能力，并且可以比从头训练更加高效地对特定实例进行微调。此外，我们的模型还适用于一般的多行为设置和离散或连续状态空间。为了实现快速泛化，我们学习了一种新颖的单一策略网络模型，该模型利用特征信息并采用了一种新的训练方式。",
    "tldr": "通过开发一个基于神经网络的预训练模型，我们实现了在不断变化的多臂赌博机中的零样本学习，该模型具有泛化能力，并且能够在特定实例上进行高效微调，同时适用于多行为设置和离散或连续状态空间。",
    "en_tdlr": "We achieve zero-shot learning in restless multi-armed bandits by developing a neural network-based pre-trained model that has generalization ability, can be fine-tuned efficiently on specific instances, and is applicable to multi-action settings and discrete or continuous state spaces."
}