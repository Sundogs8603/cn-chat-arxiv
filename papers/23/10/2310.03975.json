{
    "title": "HuBERTopic: Enhancing Semantic Representation of HuBERT through Self-supervision Utilizing Topic Model. (arXiv:2310.03975v1 [cs.SD])",
    "abstract": "Recently, the usefulness of self-supervised representation learning (SSRL) methods has been confirmed in various downstream tasks. Many of these models, as exemplified by HuBERT and WavLM, use pseudo-labels generated from spectral features or the model's own representation features. From previous studies, it is known that the pseudo-labels contain semantic information. However, the masked prediction task, the learning criterion of HuBERT, focuses on local contextual information and may not make effective use of global semantic information such as speaker, theme of speech, and so on. In this paper, we propose a new approach to enrich the semantic representation of HuBERT. We apply topic model to pseudo-labels to generate a topic label for each utterance. An auxiliary topic classification task is added to HuBERT by using topic labels as teachers. This allows additional global semantic information to be incorporated in an unsupervised manner. Experimental results demonstrate that our meth",
    "link": "http://arxiv.org/abs/2310.03975",
    "context": "Title: HuBERTopic: Enhancing Semantic Representation of HuBERT through Self-supervision Utilizing Topic Model. (arXiv:2310.03975v1 [cs.SD])\nAbstract: Recently, the usefulness of self-supervised representation learning (SSRL) methods has been confirmed in various downstream tasks. Many of these models, as exemplified by HuBERT and WavLM, use pseudo-labels generated from spectral features or the model's own representation features. From previous studies, it is known that the pseudo-labels contain semantic information. However, the masked prediction task, the learning criterion of HuBERT, focuses on local contextual information and may not make effective use of global semantic information such as speaker, theme of speech, and so on. In this paper, we propose a new approach to enrich the semantic representation of HuBERT. We apply topic model to pseudo-labels to generate a topic label for each utterance. An auxiliary topic classification task is added to HuBERT by using topic labels as teachers. This allows additional global semantic information to be incorporated in an unsupervised manner. Experimental results demonstrate that our meth",
    "path": "papers/23/10/2310.03975.json",
    "total_tokens": 922,
    "translated_title": "通过利用主题模型的自监督方法提升HuBERT的语义表示能力",
    "translated_abstract": "最近，自监督学习方法在各种下游任务中的有用性得到了证实。其中许多模型，如HuBERT和WavLM，使用从谱特征或模型自身的表示特征生成的伪标签。根据以前的研究，伪标签包含语义信息。然而，HuBERT的学习准则遮蔽预测任务专注于局部上下文信息，可能未能有效利用全局语义信息，如说话人、演讲主题等。本文提出了一种新方法来丰富HuBERT的语义表示。我们将主题模型应用于伪标签，为每个话语生成一个主题标签。通过使用主题标签作为教师，向HuBERT添加了一个辅助主题分类任务。这样可以以无监督的方式融入更多的全局语义信息。实验证明，我们的方法可以提升模型的语义表示能力。",
    "tldr": "本文提出了一种通过利用主题模型的自监督方法来提升HuBERT的语义表示能力的方法。这种方法通过添加一个辅助主题分类任务，将主题标签作为教师，以无监督的方式将全局语义信息融入模型中。实验证明，这种方法能够提升模型的语义表示能力。",
    "en_tdlr": "This paper presents a method to enhance the semantic representation of HuBERT by utilizing a topic model for self-supervision. By adding an auxiliary topic classification task and using topic labels as teachers, global semantic information can be incorporated into the model in an unsupervised manner. Experimental results demonstrate the effectiveness of this method in enhancing the model's semantic representation."
}