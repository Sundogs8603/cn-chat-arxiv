{
    "title": "Leveraging Temporal Graph Networks Using Module Decoupling. (arXiv:2310.02721v1 [cs.LG])",
    "abstract": "Modern approaches for learning on dynamic graphs have adopted the use of batches instead of applying updates one by one. The use of batches allows these techniques to become helpful in streaming scenarios where updates to graphs are received at extreme speeds. Using batches, however, forces the models to update infrequently, which results in the degradation of their performance. In this work, we suggest a decoupling strategy that enables the models to update frequently while using batches. By decoupling the core modules of temporal graph networks and implementing them using a minimal number of learnable parameters, we have developed the Lightweight Decoupled Temporal Graph Network (LDTGN), an exceptionally efficient model for learning on dynamic graphs. LDTG was validated on various dynamic graph benchmarks, providing comparable or state-of-the-art results with significantly higher throughput than previous art. Notably, our method outperforms previous approaches by more than 20\\% on be",
    "link": "http://arxiv.org/abs/2310.02721",
    "context": "Title: Leveraging Temporal Graph Networks Using Module Decoupling. (arXiv:2310.02721v1 [cs.LG])\nAbstract: Modern approaches for learning on dynamic graphs have adopted the use of batches instead of applying updates one by one. The use of batches allows these techniques to become helpful in streaming scenarios where updates to graphs are received at extreme speeds. Using batches, however, forces the models to update infrequently, which results in the degradation of their performance. In this work, we suggest a decoupling strategy that enables the models to update frequently while using batches. By decoupling the core modules of temporal graph networks and implementing them using a minimal number of learnable parameters, we have developed the Lightweight Decoupled Temporal Graph Network (LDTGN), an exceptionally efficient model for learning on dynamic graphs. LDTG was validated on various dynamic graph benchmarks, providing comparable or state-of-the-art results with significantly higher throughput than previous art. Notably, our method outperforms previous approaches by more than 20\\% on be",
    "path": "papers/23/10/2310.02721.json",
    "total_tokens": 903,
    "translated_title": "利用模块解耦提升时间图网络",
    "translated_abstract": "现代学习动态图的方法采用了批处理来替代逐个更新。采用批处理使得这些技术在流式场景中能够处理极快速度的图更新。然而，使用批处理会导致模型的更新频率降低，从而降低了性能。本研究提出了一种解耦策略，使得模型能够在使用批处理的同时频繁地更新。通过将时间图网络的核心模块进行解耦并使用最少的可学习参数进行实现，我们开发了轻量级解耦时间图网络 (LDTGN)，这是一个非常高效的学习动态图的模型。LDTGN在各种动态图基准测试上得到了验证，在吞吐量显著高于之前的方法的同时，提供了可比或具有最新成果的结果。值得注意的是，我们的方法在be数据集上的性能超过之前的方法20%以上。",
    "tldr": "本研究通过解耦时间图网络的核心模块并使用最少的可学习参数，提出了一种轻量级解耦时间图网络 (LDTGN)。在学习动态图的过程中，LDTGN表现出与之前方法可比甚至领先的结果，并且具有显著更高的吞吐量。"
}