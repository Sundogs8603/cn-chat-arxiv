{
    "title": "Hieros: Hierarchical Imagination on Structured State Space Sequence World Models. (arXiv:2310.05167v2 [cs.AI] UPDATED)",
    "abstract": "One of the biggest challenges to modern deep reinforcement learning (DRL) algorithms is sample efficiency. Many approaches learn a world model in order to train an agent entirely in imagination, eliminating the need for direct environment interaction during training. However, these methods often suffer from either a lack of imagination accuracy, exploration capabilities, or runtime efficiency. We propose Hieros, a hierarchical policy that learns time abstracted world representations and imagines trajectories at multiple time scales in latent space. Hieros uses an S5 layer-based world model, which predicts next world states in parallel during training and iteratively during environment interaction. Due to the special properties of S5 layers, our method can train in parallel and predict next world states iteratively during imagination. This allows for more efficient training than RNN-based world models and more efficient imagination than Transformer-based world models.  We show that our ",
    "link": "http://arxiv.org/abs/2310.05167",
    "context": "Title: Hieros: Hierarchical Imagination on Structured State Space Sequence World Models. (arXiv:2310.05167v2 [cs.AI] UPDATED)\nAbstract: One of the biggest challenges to modern deep reinforcement learning (DRL) algorithms is sample efficiency. Many approaches learn a world model in order to train an agent entirely in imagination, eliminating the need for direct environment interaction during training. However, these methods often suffer from either a lack of imagination accuracy, exploration capabilities, or runtime efficiency. We propose Hieros, a hierarchical policy that learns time abstracted world representations and imagines trajectories at multiple time scales in latent space. Hieros uses an S5 layer-based world model, which predicts next world states in parallel during training and iteratively during environment interaction. Due to the special properties of S5 layers, our method can train in parallel and predict next world states iteratively during imagination. This allows for more efficient training than RNN-based world models and more efficient imagination than Transformer-based world models.  We show that our ",
    "path": "papers/23/10/2310.05167.json",
    "total_tokens": 902,
    "translated_title": "Hieros: 基于结构化状态空间序列的分层想像模型",
    "translated_abstract": "现代深度强化学习（DRL）算法面临的最大挑战之一是样本效率。许多方法通过学习世界模型，在想象中完全训练代理，消除了在训练期间直接与环境进行交互的需求。然而，这些方法通常面临想像准确性、探索能力或运行效率的问题。我们提出了Hieros，一种分层策略，它学习时间抽象的世界表示，并在潜在空间中多个时间尺度上想象轨迹。Hieros使用基于S5层的世界模型，它在训练期间并行预测下一个世界状态，并在环境交互期间进行迭代预测。由于S5层的特殊性质，我们的方法可以在想象过程中并行训练和迭代预测下一个世界状态。这比基于RNN的世界模型具有更高的训练效率，也比基于Transformer的世界模型具有更高的想象效率。",
    "tldr": "Hieros是一种基于结构化状态空间序列的分层想像模型，通过学习时间抽象的世界表示并在潜在空间中多个时间尺度上想象轨迹，实现了更高效的训练和想象。",
    "en_tdlr": "Hieros is a hierarchical imagination model based on structured state space sequences. It learns time abstracted world representations and imagines trajectories at multiple time scales in latent space, achieving more efficient training and imagination."
}