{
    "title": "GPT-4 Doesn't Know It's Wrong: An Analysis of Iterative Prompting for Reasoning Problems. (arXiv:2310.12397v1 [cs.AI])",
    "abstract": "There has been considerable divergence of opinion on the reasoning abilities of Large Language Models (LLMs). While the initial optimism that reasoning might emerge automatically with scale has been tempered thanks to a slew of counterexamples, a wide spread belief in their iterative self-critique capabilities persists. In this paper, we set out to systematically investigate the effectiveness of iterative prompting of LLMs in the context of Graph Coloring, a canonical NP-complete reasoning problem that is related to propositional satisfiability as well as practical problems like scheduling and allocation. We present a principled empirical study of the performance of GPT4 in solving graph coloring instances or verifying the correctness of candidate colorings. In iterative modes, we experiment with the model critiquing its own answers and an external correct reasoner verifying proposed solutions. In both cases, we analyze whether the content of the criticisms actually affects bottom line",
    "link": "http://arxiv.org/abs/2310.12397",
    "context": "Title: GPT-4 Doesn't Know It's Wrong: An Analysis of Iterative Prompting for Reasoning Problems. (arXiv:2310.12397v1 [cs.AI])\nAbstract: There has been considerable divergence of opinion on the reasoning abilities of Large Language Models (LLMs). While the initial optimism that reasoning might emerge automatically with scale has been tempered thanks to a slew of counterexamples, a wide spread belief in their iterative self-critique capabilities persists. In this paper, we set out to systematically investigate the effectiveness of iterative prompting of LLMs in the context of Graph Coloring, a canonical NP-complete reasoning problem that is related to propositional satisfiability as well as practical problems like scheduling and allocation. We present a principled empirical study of the performance of GPT4 in solving graph coloring instances or verifying the correctness of candidate colorings. In iterative modes, we experiment with the model critiquing its own answers and an external correct reasoner verifying proposed solutions. In both cases, we analyze whether the content of the criticisms actually affects bottom line",
    "path": "papers/23/10/2310.12397.json",
    "total_tokens": 875,
    "translated_title": "GPT-4并不知道它错了：对迭代提示在推理问题中的分析",
    "translated_abstract": "关于大型语言模型（LLM）的推理能力存在许多意见分歧。尽管最初对于推理能够随着规模自动产生的乐观主义被一系列反例所抑制，但人们普遍相信它们具有迭代自我批评能力。本文系统地调查了在图着色的上下文中对LLM的迭代提示的有效性，这是一个与命题可满足性以及实践问题（如调度和分配）相关的经典NP完全推理问题。我们通过对GPT4在解决图着色实例或验证候选着色的正确性中的表现进行了有原则的实证研究。在迭代模式下，我们尝试了模型批评自己的答案以及外部的正确推理器验证提出的解决方案。在两种情况下，我们分析了批评的内容是否实际影响了最终结果。",
    "tldr": "本文研究了在推理问题中使用迭代提示的有效性，以解决图着色问题。通过实证研究发现，GPT-4的迭代自我批评和外部正确推理器验证对最终结果有实际影响。",
    "en_tdlr": "This paper examines the effectiveness of iterative prompting for reasoning problems, specifically to address graph coloring. Empirical study reveals that GPT-4's iterative self-critique and external correct reasoner verification have actual implications on the final results."
}