{
    "title": "Gradient Descent Fails to Learn High-frequency Functions and Modular Arithmetic. (arXiv:2310.12660v1 [cs.LG])",
    "abstract": "Classes of target functions containing a large number of approximately orthogonal elements are known to be hard to learn by the Statistical Query algorithms. Recently this classical fact re-emerged in a theory of gradient-based optimization of neural networks. In the novel framework, the hardness of a class is usually quantified by the variance of the gradient with respect to a random choice of a target function.  A set of functions of the form $x\\to ax \\bmod p$, where $a$ is taken from ${\\mathbb Z}_p$, has attracted some attention from deep learning theorists and cryptographers recently. This class can be understood as a subset of $p$-periodic functions on ${\\mathbb Z}$ and is tightly connected with a class of high-frequency periodic functions on the real line.  We present a mathematical analysis of limitations and challenges associated with using gradient-based learning techniques to train a high-frequency periodic function or modular multiplication from examples. We highlight that t",
    "link": "http://arxiv.org/abs/2310.12660",
    "context": "Title: Gradient Descent Fails to Learn High-frequency Functions and Modular Arithmetic. (arXiv:2310.12660v1 [cs.LG])\nAbstract: Classes of target functions containing a large number of approximately orthogonal elements are known to be hard to learn by the Statistical Query algorithms. Recently this classical fact re-emerged in a theory of gradient-based optimization of neural networks. In the novel framework, the hardness of a class is usually quantified by the variance of the gradient with respect to a random choice of a target function.  A set of functions of the form $x\\to ax \\bmod p$, where $a$ is taken from ${\\mathbb Z}_p$, has attracted some attention from deep learning theorists and cryptographers recently. This class can be understood as a subset of $p$-periodic functions on ${\\mathbb Z}$ and is tightly connected with a class of high-frequency periodic functions on the real line.  We present a mathematical analysis of limitations and challenges associated with using gradient-based learning techniques to train a high-frequency periodic function or modular multiplication from examples. We highlight that t",
    "path": "papers/23/10/2310.12660.json",
    "total_tokens": 833,
    "translated_title": "梯度下降无法学习高频函数和模运算",
    "translated_abstract": "已知一些包含大量近似正交元素的目标函数类别难以被统计查询算法学习到。最近，这一经典事实再次出现在神经网络梯度优化的理论中。在这个新的框架中，一个类的难度通常由梯度对随机选择的目标函数的方差来衡量。最近，一个形式为$x \\to ax \\bmod p$的函数集合，其中$a$取自${\\mathbb Z}_p$，引起了深度学习理论家和密码学家的关注。这个类可以被理解为${\\mathbb Z}$上的$p$-周期函数的子集，并且与实数线上的高频周期函数类紧密相关。我们对使用基于梯度的学习技术从示例中训练高频周期函数或模乘法进行了数学分析，并强调了相关的限制和挑战。",
    "tldr": "梯度下降无法学习高频函数和模运算，该研究为使用基于梯度的学习技术训练高频周期函数和模乘法提供了数学分析。",
    "en_tdlr": "Gradient descent fails to learn high-frequency functions and modular arithmetic. This research provides a mathematical analysis for training high-frequency periodic functions and modular multiplication using gradient-based learning techniques."
}