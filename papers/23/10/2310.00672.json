{
    "title": "GeRA: Label-Efficient Geometrically Regularized Alignment. (arXiv:2310.00672v2 [cs.LG] UPDATED)",
    "abstract": "Pretrained unimodal encoders incorporate rich semantic information into embedding space structures. To be similarly informative, multi-modal encoders typically require massive amounts of paired data for alignment and training. We introduce a semi-supervised Geometrically Regularized Alignment (GeRA) method to align the embedding spaces of pretrained unimodal encoders in a label-efficient way. Our method leverages the manifold geometry of unpaired (unlabeled) data to improve alignment performance. To prevent distortions to local geometry during the alignment process, potentially disrupting semantic neighborhood structures and causing misalignment of unobserved pairs, we introduce a geometric loss term. This term is built upon a diffusion operator that captures the local manifold geometry of the unimodal pretrained encoders. GeRA is modality-agnostic and thus can be used to align pretrained encoders from any data modalities. We provide empirical evidence to the effectiveness of our metho",
    "link": "http://arxiv.org/abs/2310.00672",
    "context": "Title: GeRA: Label-Efficient Geometrically Regularized Alignment. (arXiv:2310.00672v2 [cs.LG] UPDATED)\nAbstract: Pretrained unimodal encoders incorporate rich semantic information into embedding space structures. To be similarly informative, multi-modal encoders typically require massive amounts of paired data for alignment and training. We introduce a semi-supervised Geometrically Regularized Alignment (GeRA) method to align the embedding spaces of pretrained unimodal encoders in a label-efficient way. Our method leverages the manifold geometry of unpaired (unlabeled) data to improve alignment performance. To prevent distortions to local geometry during the alignment process, potentially disrupting semantic neighborhood structures and causing misalignment of unobserved pairs, we introduce a geometric loss term. This term is built upon a diffusion operator that captures the local manifold geometry of the unimodal pretrained encoders. GeRA is modality-agnostic and thus can be used to align pretrained encoders from any data modalities. We provide empirical evidence to the effectiveness of our metho",
    "path": "papers/23/10/2310.00672.json",
    "total_tokens": 874,
    "translated_title": "GeRA: 标签效率的几何正则化对齐",
    "translated_abstract": "预训练的单模态编码器将丰富的语义信息融入嵌入空间结构中。为了具有类似的信息量，多模态编码器通常需要大量成对数据进行对齐和训练。我们引入了一种半监督的几何正则化对齐方法（GeRA），以标签高效的方式对预训练的单模态编码器的嵌入空间进行对齐。我们的方法利用未配对（未标记）数据的流形几何来提高对齐性能。为了防止在对齐过程中对局部几何造成失真，可能破坏语义邻域结构并导致未观察到的对产生错位，我们引入了几何损失项。该项基于一个捕获单模态预训练编码器局部流形几何的扩散算子构建。GeRA是模态无关的，因此可以用于对齐任何数据模态的预训练编码器。我们提供了实证证据来支持我们方法的有效性。",
    "tldr": "GeRA是一种标签效率的几何正则化对齐方法，利用未配对数据的流形几何提高了预训练单模态编码器的对齐性能。"
}