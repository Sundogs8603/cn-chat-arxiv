{
    "title": "A Formalism and Approach for Improving Robustness of Large Language Models Using Risk-Adjusted Confidence Scores. (arXiv:2310.03283v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs), such as ChatGPT, have achieved impressive milestones in natural language processing (NLP). Despite their impressive performance, the models are known to pose important risks. As these models are deployed in real-world applications, a systematic understanding of different risks posed by these models on tasks such as natural language inference (NLI), is much needed. In this paper, we define and formalize two distinct types of risk: decision risk and composite risk. We also propose a risk-centric evaluation framework, and four novel metrics, for assessing LLMs on these risks in both in-domain and out-of-domain settings. Finally, we propose a risk-adjusted calibration method called DwD for helping LLMs minimize these risks in an overall NLI architecture. Detailed experiments, using four NLI benchmarks, three baselines and two LLMs, including ChatGPT, show both the practical utility of the evaluation framework, and the efficacy of DwD in reducing decision and c",
    "link": "http://arxiv.org/abs/2310.03283",
    "context": "Title: A Formalism and Approach for Improving Robustness of Large Language Models Using Risk-Adjusted Confidence Scores. (arXiv:2310.03283v1 [cs.CL])\nAbstract: Large Language Models (LLMs), such as ChatGPT, have achieved impressive milestones in natural language processing (NLP). Despite their impressive performance, the models are known to pose important risks. As these models are deployed in real-world applications, a systematic understanding of different risks posed by these models on tasks such as natural language inference (NLI), is much needed. In this paper, we define and formalize two distinct types of risk: decision risk and composite risk. We also propose a risk-centric evaluation framework, and four novel metrics, for assessing LLMs on these risks in both in-domain and out-of-domain settings. Finally, we propose a risk-adjusted calibration method called DwD for helping LLMs minimize these risks in an overall NLI architecture. Detailed experiments, using four NLI benchmarks, three baselines and two LLMs, including ChatGPT, show both the practical utility of the evaluation framework, and the efficacy of DwD in reducing decision and c",
    "path": "papers/23/10/2310.03283.json",
    "total_tokens": 1141,
    "translated_title": "一种改善大型语言模型鲁棒性的形式化和方法：使用风险调整的置信度评分",
    "translated_abstract": "大型语言模型（LLMs），如ChatGPT，在自然语言处理（NLP）中取得了令人印象深刻的里程碑。尽管它们表现出色，但这些模型也存在重要的风险。随着这些模型在实际应用中的部署，对这些模型在自然语言推理（NLI）等任务中所带来的不同风险的系统理解非常必要。在本文中，我们定义和形式化了两种不同类型的风险：决策风险和综合风险。我们还提出了一个以风险为中心的评估框架，并提出了四个新颖的度量标准，用于评估LLMs在域内和域外环境中的这些风险。最后，我们提出了一种名为DwD的风险调整校准方法，帮助LLMs在整体NLI架构中最小化这些风险。通过使用四个NLI基准测试、三个基准线和两个LLMs（包括ChatGPT）进行详细实验，我们展示了评估框架的实际效用以及DwD在减少决策风险和综合风险方面的有效性。",
    "tldr": "这项研究定义了两种不同类型的风险（决策风险和综合风险），提出了一个以风险为中心的评估框架和四个新颖的度量标准，以帮助评估大型语言模型在自然语言推理任务中的鲁棒性。同时，还提出了一种名为DwD的风险调整校准方法，在整体NLI架构中减少决策风险和综合风险。实验表明，评估框架和DwD方法具有实际效用。",
    "en_tdlr": "This research defines two types of risks (decision risk and composite risk), proposes a risk-centric evaluation framework and four novel metrics to assess the robustness of large language models in natural language inference tasks. It also introduces a risk-adjusted calibration method called DwD to reduce decision and composite risks in the overall NLI architecture. Experiments demonstrate the practical utility of the evaluation framework and the efficacy of DwD."
}