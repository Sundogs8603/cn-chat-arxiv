{
    "title": "Prevalence and prevention of large language model use in crowd work. (arXiv:2310.15683v1 [cs.CL])",
    "abstract": "We show that the use of large language models (LLMs) is prevalent among crowd workers, and that targeted mitigation strategies can significantly reduce, but not eliminate, LLM use. On a text summarization task where workers were not directed in any way regarding their LLM use, the estimated prevalence of LLM use was around 30%, but was reduced by about half by asking workers to not use LLMs and by raising the cost of using them, e.g., by disabling copy-pasting. Secondary analyses give further insight into LLM use and its prevention: LLM use yields high-quality but homogeneous responses, which may harm research concerned with human (rather than model) behavior and degrade future models trained with crowdsourced data. At the same time, preventing LLM use may be at odds with obtaining high-quality responses; e.g., when requesting workers not to use LLMs, summaries contained fewer keywords carrying essential information. Our estimates will likely change as LLMs increase in popularity or ca",
    "link": "http://arxiv.org/abs/2310.15683",
    "context": "Title: Prevalence and prevention of large language model use in crowd work. (arXiv:2310.15683v1 [cs.CL])\nAbstract: We show that the use of large language models (LLMs) is prevalent among crowd workers, and that targeted mitigation strategies can significantly reduce, but not eliminate, LLM use. On a text summarization task where workers were not directed in any way regarding their LLM use, the estimated prevalence of LLM use was around 30%, but was reduced by about half by asking workers to not use LLMs and by raising the cost of using them, e.g., by disabling copy-pasting. Secondary analyses give further insight into LLM use and its prevention: LLM use yields high-quality but homogeneous responses, which may harm research concerned with human (rather than model) behavior and degrade future models trained with crowdsourced data. At the same time, preventing LLM use may be at odds with obtaining high-quality responses; e.g., when requesting workers not to use LLMs, summaries contained fewer keywords carrying essential information. Our estimates will likely change as LLMs increase in popularity or ca",
    "path": "papers/23/10/2310.15683.json",
    "total_tokens": 1050,
    "translated_title": "大型语言模型在众包工作中的使用率和预防措施",
    "translated_abstract": "我们展示了大型语言模型（LLMs）在众包工作中的普遍使用，并且证明有针对性的缓解策略可以显著降低LLM的使用率，但无法完全消除。在一个文本摘要任务中，工作者没有任何关于LLM使用的指示，估计LLM使用率约为30%，但通过要求工作者不使用LLM并增加使用成本（例如禁止复制粘贴），LLM使用率减少了约一半。进一步的分析揭示了关于LLM使用及其预防的更多见解：LLM使用产生高质量但同质化的回答，这可能损害那些关注人类（而不是模型）行为的研究，并且降低对众包数据训练的未来模型的质量。同时，防止LLM的使用可能与获得高质量的回答存在矛盾；例如，在请求工作者不使用LLM时，摘要中包含的关键信息较少。我们的估计可能会随着LLM的普及或取消而改变。",
    "tldr": "该论文研究了众包工作者使用大型语言模型（LLM）的使用率，并探讨了预防措施。研究发现，通过要求工作者不使用LLM并增加使用成本可显著降低LLM的使用率，但无法完全消除。然而，防止LLM的使用可能影响到获得高质量回答。这些发现对于关注人类行为和众包数据训练的未来模型具有重要意义。",
    "en_tdlr": "This paper investigates the prevalence and prevention of large language model (LLM) use in crowd work. The study shows that targeted mitigation strategies, such as asking workers to not use LLMs and increasing the cost of using them, can significantly reduce LLM use but not eliminate it completely. However, preventing LLM use may impact obtaining high-quality responses. These findings have implications for understanding human behavior and the training of future models with crowdsourced data."
}