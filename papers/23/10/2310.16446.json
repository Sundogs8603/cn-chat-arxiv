{
    "title": "Diversity Enhanced Narrative Question Generation for Storybooks. (arXiv:2310.16446v1 [cs.CL])",
    "abstract": "Question generation (QG) from a given context can enhance comprehension, engagement, assessment, and overall efficacy in learning or conversational environments. Despite recent advancements in QG, the challenge of enhancing or measuring the diversity of generated questions often remains unaddressed. In this paper, we introduce a multi-question generation model (mQG), which is capable of generating multiple, diverse, and answerable questions by focusing on context and questions. To validate the answerability of the generated questions, we employ a SQuAD2.0 fine-tuned question answering model, classifying the questions as answerable or not. We train and evaluate mQG on the FairytaleQA dataset, a well-structured QA dataset based on storybooks, with narrative questions. We further apply a zero-shot adaptation on the TellMeWhy and SQuAD1.1 datasets. mQG shows promising results across various evaluation metrics, among strong baselines.",
    "link": "http://arxiv.org/abs/2310.16446",
    "context": "Title: Diversity Enhanced Narrative Question Generation for Storybooks. (arXiv:2310.16446v1 [cs.CL])\nAbstract: Question generation (QG) from a given context can enhance comprehension, engagement, assessment, and overall efficacy in learning or conversational environments. Despite recent advancements in QG, the challenge of enhancing or measuring the diversity of generated questions often remains unaddressed. In this paper, we introduce a multi-question generation model (mQG), which is capable of generating multiple, diverse, and answerable questions by focusing on context and questions. To validate the answerability of the generated questions, we employ a SQuAD2.0 fine-tuned question answering model, classifying the questions as answerable or not. We train and evaluate mQG on the FairytaleQA dataset, a well-structured QA dataset based on storybooks, with narrative questions. We further apply a zero-shot adaptation on the TellMeWhy and SQuAD1.1 datasets. mQG shows promising results across various evaluation metrics, among strong baselines.",
    "path": "papers/23/10/2310.16446.json",
    "total_tokens": 992,
    "translated_title": "故事书的多样性增强叙事问题生成",
    "translated_abstract": "从给定的上下文生成问题可以增强理解、参与度、评估和学习或对话环境的整体效力。尽管问题生成领域近年来取得了一些进展，但提高或衡量生成问题的多样性仍然是一个未解决的挑战。在本文中，我们引入了一个多问题生成模型（mQG），该模型可以通过关注上下文和问题来生成多样化且可回答的问题。为了验证生成问题的可回答性，我们使用了一个经过SQuAD2.0微调的问答模型，将问题分类为可回答或不可回答。我们在FairytaleQA数据集上对mQG进行训练和评估，该数据集是基于故事书的结构化问答数据集，包含叙事性问题。我们还对TellMeWhy和SQuAD1.1数据集进行了零-shot适应。mQG在各种评估指标上表现出色，超过了强基线模型。",
    "tldr": "本文介绍了一种多问题生成模型（mQG），该模型可以通过关注上下文和问题来生成多样化且可回答的问题。通过对FairytaleQA数据集进行训练和评估，以及在TellMeWhy和SQuAD1.1数据集上进行零-shot适应，mQG在各种评估指标上显示出有希望的结果。这项研究将问题生成的多样性引入故事书领域，为提高理解和参与度提供了新的方法。",
    "en_tdlr": "This paper introduces a multi-question generation model (mQG) that can generate diverse and answerable questions by focusing on context and questions. Through training and evaluation on the FairytaleQA dataset, as well as zero-shot adaptation on the TellMeWhy and SQuAD1.1 datasets, mQG shows promising results in various evaluation metrics. This study introduces diversity in question generation for storybooks, providing a new approach to enhance comprehension and engagement."
}