{
    "title": "Visual Storytelling with Question-Answer Plans. (arXiv:2310.05295v2 [cs.CL] UPDATED)",
    "abstract": "Visual storytelling aims to generate compelling narratives from image sequences. Existing models often focus on enhancing the representation of the image sequence, e.g., with external knowledge sources or advanced graph structures. Despite recent progress, the stories are often repetitive, illogical, and lacking in detail. To mitigate these issues, we present a novel framework which integrates visual representations with pretrained language models and planning. Our model translates the image sequence into a visual prefix, a sequence of continuous embeddings which language models can interpret. It also leverages a sequence of question-answer pairs as a blueprint plan for selecting salient visual concepts and determining how they should be assembled into a narrative. Automatic and human evaluation on the VIST benchmark (Huang et al., 2016) demonstrates that blueprint-based models generate stories that are more coherent, interesting, and natural compared to competitive baselines and state",
    "link": "http://arxiv.org/abs/2310.05295",
    "context": "Title: Visual Storytelling with Question-Answer Plans. (arXiv:2310.05295v2 [cs.CL] UPDATED)\nAbstract: Visual storytelling aims to generate compelling narratives from image sequences. Existing models often focus on enhancing the representation of the image sequence, e.g., with external knowledge sources or advanced graph structures. Despite recent progress, the stories are often repetitive, illogical, and lacking in detail. To mitigate these issues, we present a novel framework which integrates visual representations with pretrained language models and planning. Our model translates the image sequence into a visual prefix, a sequence of continuous embeddings which language models can interpret. It also leverages a sequence of question-answer pairs as a blueprint plan for selecting salient visual concepts and determining how they should be assembled into a narrative. Automatic and human evaluation on the VIST benchmark (Huang et al., 2016) demonstrates that blueprint-based models generate stories that are more coherent, interesting, and natural compared to competitive baselines and state",
    "path": "papers/23/10/2310.05295.json",
    "total_tokens": 853,
    "translated_title": "使用问题-答案计划的视觉叙事",
    "translated_abstract": "视觉叙事旨在从图像序列中生成引人入胜的叙事。现有模型通常着重于改进图像序列的表征，例如通过外部知识源或先进的图结构。尽管最近取得了一些进展，但故事往往重复、不合逻辑且缺乏细节。为了缓解这些问题，我们提出了一个新颖的框架，将视觉表达与预训练语言模型和计划相结合。我们的模型将图像序列转化为视觉前缀，即连续嵌入的序列，可以由语言模型解释。它还利用一系列问题-答案对作为蓝图计划，选择显著的视觉概念并确定它们如何组合成叙事。在VIST基准测试上进行的自动和人工评估表明，基于蓝图的模型生成的故事与竞争基准和现有模型相比更连贯，更有趣，更自然。",
    "tldr": "本论文引入了一种新颖的框架，将视觉表示与预训练语言模型和计划相结合，从图像序列中生成更具连贯性、趣味性和自然性的叙事。",
    "en_tdlr": "This paper introduces a novel framework that integrates visual representations with pretrained language models and planning to generate narratives from image sequences that are more coherent, interesting, and natural."
}