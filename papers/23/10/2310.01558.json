{
    "title": "Making Retrieval-Augmented Language Models Robust to Irrelevant Context. (arXiv:2310.01558v1 [cs.CL])",
    "abstract": "Retrieval-augmented language models (RALMs) hold promise to produce language understanding systems that are are factual, efficient, and up-to-date. An important desideratum of RALMs, is that retrieved information helps model performance when it is relevant, and does not harm performance when it is not. This is particularly important in multi-hop reasoning scenarios, where misuse of irrelevant evidence can lead to cascading errors. However, recent work has shown that retrieval augmentation can sometimes have a negative effect on performance. In this work, we present a thorough analysis on five open-domain question answering benchmarks, characterizing cases when retrieval reduces accuracy. We then propose two methods to mitigate this issue. First, a simple baseline that filters out retrieved passages that do not entail question-answer pairs according to a natural language inference (NLI) model. This is effective in preventing performance reduction, but at a cost of also discarding releva",
    "link": "http://arxiv.org/abs/2310.01558",
    "context": "Title: Making Retrieval-Augmented Language Models Robust to Irrelevant Context. (arXiv:2310.01558v1 [cs.CL])\nAbstract: Retrieval-augmented language models (RALMs) hold promise to produce language understanding systems that are are factual, efficient, and up-to-date. An important desideratum of RALMs, is that retrieved information helps model performance when it is relevant, and does not harm performance when it is not. This is particularly important in multi-hop reasoning scenarios, where misuse of irrelevant evidence can lead to cascading errors. However, recent work has shown that retrieval augmentation can sometimes have a negative effect on performance. In this work, we present a thorough analysis on five open-domain question answering benchmarks, characterizing cases when retrieval reduces accuracy. We then propose two methods to mitigate this issue. First, a simple baseline that filters out retrieved passages that do not entail question-answer pairs according to a natural language inference (NLI) model. This is effective in preventing performance reduction, but at a cost of also discarding releva",
    "path": "papers/23/10/2310.01558.json",
    "total_tokens": 831,
    "translated_title": "使检索增强的语言模型对无关上下文具有鲁棒性",
    "translated_abstract": "检索增强的语言模型（RALMs）有望产生准确、高效和最新的语言理解系统。RALMs的一个重要目标是在相关时提高模型性能，在不相关时不影响性能。这在多跳推理场景中尤为重要，因为不相关证据的误用会导致连锁错误。然而，最近的研究表明，检索增强有时会对性能产生负面影响。在这项工作中，我们对五个开放领域的问答基准进行了彻底分析，描述了检索降低准确性的情况。然后，我们提出了两种缓解这个问题的方法。首先，一个简单的基准线，根据自然语言推理（NLI）模型筛选出不涉及问题-答案对的检索段落。这可以有效防止性能下降，但代价是舍弃了相关信息。",
    "tldr": "本文分析了检索增强的语言模型在开放领域问答中的性能问题，并提出了基于自然语言推理的方法来缓解这个问题。",
    "en_tdlr": "This paper analyzes the performance issues of retrieval-augmented language models in open-domain question answering and proposes a method based on natural language inference to mitigate this problem."
}