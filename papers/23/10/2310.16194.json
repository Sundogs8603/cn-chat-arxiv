{
    "title": "Learning Low-Rank Latent Spaces with Simple Deterministic Autoencoder: Theoretical and Empirical Insights. (arXiv:2310.16194v1 [cs.LG])",
    "abstract": "The autoencoder is an unsupervised learning paradigm that aims to create a compact latent representation of data by minimizing the reconstruction loss. However, it tends to overlook the fact that most data (images) are embedded in a lower-dimensional space, which is crucial for effective data representation. To address this limitation, we propose a novel approach called Low-Rank Autoencoder (LoRAE). In LoRAE, we incorporated a low-rank regularizer to adaptively reconstruct a low-dimensional latent space while preserving the basic objective of an autoencoder. This helps embed the data in a lower-dimensional space while preserving important information. It is a simple autoencoder extension that learns low-rank latent space. Theoretically, we establish a tighter error bound for our model. Empirically, our model's superiority shines through various tasks such as image generation and downstream classification. Both theoretical and practical outcomes highlight the importance of acquiring low",
    "link": "http://arxiv.org/abs/2310.16194",
    "context": "Title: Learning Low-Rank Latent Spaces with Simple Deterministic Autoencoder: Theoretical and Empirical Insights. (arXiv:2310.16194v1 [cs.LG])\nAbstract: The autoencoder is an unsupervised learning paradigm that aims to create a compact latent representation of data by minimizing the reconstruction loss. However, it tends to overlook the fact that most data (images) are embedded in a lower-dimensional space, which is crucial for effective data representation. To address this limitation, we propose a novel approach called Low-Rank Autoencoder (LoRAE). In LoRAE, we incorporated a low-rank regularizer to adaptively reconstruct a low-dimensional latent space while preserving the basic objective of an autoencoder. This helps embed the data in a lower-dimensional space while preserving important information. It is a simple autoencoder extension that learns low-rank latent space. Theoretically, we establish a tighter error bound for our model. Empirically, our model's superiority shines through various tasks such as image generation and downstream classification. Both theoretical and practical outcomes highlight the importance of acquiring low",
    "path": "papers/23/10/2310.16194.json",
    "total_tokens": 957,
    "translated_title": "学习低秩潜空间的简单确定性自编码器：理论和经验洞见",
    "translated_abstract": "自编码器是一种无监督学习范式，通过最小化重构损失来创建数据的紧凑潜在表示。然而，它往往忽视了大多数数据（图像）被嵌入在一个低维空间中的事实，这对于有效的数据表示至关重要。为了解决这个限制，我们提出了一种称为低秩自编码器（LoRAE）的新方法。在LoRAE中，我们加入了一个低秩正则化项，以自适应地重构一个低维潜在空间，同时保持自编码器的基本目标。这有助于将数据嵌入到一个低维空间中，同时保留重要信息。它是一个学习低秩潜空间的简单自编码器扩展。从理论上讲，我们为我们的模型建立了一个更紧密的误差界。在实证上，我们的模型在图像生成和下游分类等各种任务中展现出了优越性。理论和实践结果都强调了获取低秩潜空间的重要性。",
    "tldr": "本文提出了一种新的方法，称为低秩自编码器（LoRAE），通过加入低秩正则化项，自适应地重构低维潜在空间，同时保持自编码器的基本目标。该方法在图像生成和下游分类等任务中展现出了优越性。",
    "en_tdlr": "This paper proposes a novel method called Low-Rank Autoencoder (LoRAE) that reconstructs a low-dimensional latent space using a low-rank regularizer while preserving the basic objective of an autoencoder. The approach shows superior performance in tasks such as image generation and downstream classification."
}