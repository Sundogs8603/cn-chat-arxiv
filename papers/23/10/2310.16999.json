{
    "title": "Trust, but Verify: Robust Image Segmentation using Deep Learning. (arXiv:2310.16999v1 [cs.CV])",
    "abstract": "We describe a method for verifying the output of a deep neural network for medical image segmentation that is robust to several classes of random as well as worst-case perturbations i.e. adversarial attacks. This method is based on a general approach recently developed by the authors called ``Trust, but Verify\" wherein an auxiliary verification network produces predictions about certain masked features in the input image using the segmentation as an input. A well-designed auxiliary network will produce high-quality predictions when the input segmentations are accurate, but will produce low-quality predictions when the segmentations are incorrect. Checking the predictions of such a network with the original image allows us to detect bad segmentations. However, to ensure the verification method is truly robust, we need a method for checking the quality of the predictions that does not itself rely on a black-box neural network. Indeed, we show that previous methods for segmentation evalua",
    "link": "http://arxiv.org/abs/2310.16999",
    "context": "Title: Trust, but Verify: Robust Image Segmentation using Deep Learning. (arXiv:2310.16999v1 [cs.CV])\nAbstract: We describe a method for verifying the output of a deep neural network for medical image segmentation that is robust to several classes of random as well as worst-case perturbations i.e. adversarial attacks. This method is based on a general approach recently developed by the authors called ``Trust, but Verify\" wherein an auxiliary verification network produces predictions about certain masked features in the input image using the segmentation as an input. A well-designed auxiliary network will produce high-quality predictions when the input segmentations are accurate, but will produce low-quality predictions when the segmentations are incorrect. Checking the predictions of such a network with the original image allows us to detect bad segmentations. However, to ensure the verification method is truly robust, we need a method for checking the quality of the predictions that does not itself rely on a black-box neural network. Indeed, we show that previous methods for segmentation evalua",
    "path": "papers/23/10/2310.16999.json",
    "total_tokens": 947,
    "translated_title": "信任，但要验证：使用深度学习进行鲁棒图像分割",
    "translated_abstract": "我们描述了一种用于验证深度神经网络在医学图像分割中的输出的方法，该方法对于多种类型的随机和最坏情况的扰动具有鲁棒性，即对抗性攻击。该方法基于作者最近提出的一种称为“信任，但要验证”的通用方法，其中辅助验证网络使用分割作为输入来对输入图像中的某些被遮蔽特征进行预测。设计良好的辅助网络将在输入分割准确时生成高质量的预测，但在分割不正确时生成低质量的预测。通过将这个网络的预测与原始图像进行检查，我们可以检测出错误的分割。然而，为了确保验证方法真正鲁棒，我们需要一种不依赖于黑盒神经网络的方法来检查预测的质量。事实上，我们展示了先前用于分割评估的方法无法应对鲁棒的情况。",
    "tldr": "本文描述了一种使用“信任，但要验证”方法进行深度学习图像分割的方法，通过辅助验证网络对分割进行预测，以此来验证深度神经网络的输出。这种方法对多种扰动具有鲁棒性，可以应对对抗性攻击，并且不依赖于黑盒神经网络来检测错误的分割。",
    "en_tdlr": "This paper proposes a method for robust image segmentation using the \"Trust, but Verify\" approach, which uses an auxiliary verification network to predict certain features in the input image based on the segmentation. This method is robust to various perturbations, including adversarial attacks, and does not rely on a black-box neural network to detect incorrect segmentations."
}