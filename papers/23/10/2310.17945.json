{
    "title": "A Comprehensive and Reliable Feature Attribution Method: Double-sided Remove and Reconstruct (DoRaR). (arXiv:2310.17945v1 [cs.LG])",
    "abstract": "The limited transparency of the inner decision-making mechanism in deep neural networks (DNN) and other machine learning (ML) models has hindered their application in several domains. In order to tackle this issue, feature attribution methods have been developed to identify the crucial features that heavily influence decisions made by these black box models. However, many feature attribution methods have inherent downsides. For example, one category of feature attribution methods suffers from the artifacts problem, which feeds out-of-distribution masked inputs directly through the classifier that was originally trained on natural data points. Another category of feature attribution method finds explanations by using jointly trained feature selectors and predictors. While avoiding the artifacts problem, this new category suffers from the Encoding Prediction in the Explanation (EPITE) problem, in which the predictor's decisions rely not on the features, but on the masks that selects thos",
    "link": "http://arxiv.org/abs/2310.17945",
    "context": "Title: A Comprehensive and Reliable Feature Attribution Method: Double-sided Remove and Reconstruct (DoRaR). (arXiv:2310.17945v1 [cs.LG])\nAbstract: The limited transparency of the inner decision-making mechanism in deep neural networks (DNN) and other machine learning (ML) models has hindered their application in several domains. In order to tackle this issue, feature attribution methods have been developed to identify the crucial features that heavily influence decisions made by these black box models. However, many feature attribution methods have inherent downsides. For example, one category of feature attribution methods suffers from the artifacts problem, which feeds out-of-distribution masked inputs directly through the classifier that was originally trained on natural data points. Another category of feature attribution method finds explanations by using jointly trained feature selectors and predictors. While avoiding the artifacts problem, this new category suffers from the Encoding Prediction in the Explanation (EPITE) problem, in which the predictor's decisions rely not on the features, but on the masks that selects thos",
    "path": "papers/23/10/2310.17945.json",
    "total_tokens": 866,
    "translated_title": "一种全面可靠的特征归因方法：双边删除和重构（DoRaR）",
    "translated_abstract": "深度神经网络（DNN）和其他机器学习（ML）模型内部决策机制的透明度有限，阻碍了它们在多个领域的应用。为了解决这个问题，已经开发出了特征归因方法，用于识别对这些黑盒模型的决策产生重要影响的关键特征。然而，许多特征归因方法存在固有的缺点。例如，一类特征归因方法存在伪影问题，这些方法直接通过原始训练在自然数据点上的分类器，对超出分布范围的屏蔽输入进行反馈。另一类特征归因方法通过使用联合训练的特征选择器和预测器来找到解释。虽然避免了伪影问题，但这个新类别的方法存在解释中的编码预测问题（EPITE），其中预测器的决策不依赖于特征，而是依赖于选择这些特征的遮罩。",
    "tldr": "双边删除和重构（DoRaR）是一种全面可靠的特征归因方法，用于解决深度神经网络和其他相关模型内部决策机制不透明的问题。"
}