{
    "title": "Large Multi-modal Encoders for Recommendation. (arXiv:2310.20343v1 [cs.IR])",
    "abstract": "In recent years, the rapid growth of online multimedia services, such as e-commerce platforms, has necessitated the development of personalised recommendation approaches that can encode diverse content about each item. Indeed, modern multi-modal recommender systems exploit diverse features obtained from raw images and item descriptions to enhance the recommendation performance. However, the existing multi-modal recommenders primarily depend on the features extracted individually from different media through pre-trained modality-specific encoders, and exhibit only shallow alignments between different modalities - limiting these systems' ability to capture the underlying relationships between the modalities. In this paper, we investigate the usage of large multi-modal encoders within the specific context of recommender systems, as these have previously demonstrated state-of-the-art effectiveness when ranking items across various domains. Specifically, we tailor two state-of-the-art multi",
    "link": "http://arxiv.org/abs/2310.20343",
    "context": "Title: Large Multi-modal Encoders for Recommendation. (arXiv:2310.20343v1 [cs.IR])\nAbstract: In recent years, the rapid growth of online multimedia services, such as e-commerce platforms, has necessitated the development of personalised recommendation approaches that can encode diverse content about each item. Indeed, modern multi-modal recommender systems exploit diverse features obtained from raw images and item descriptions to enhance the recommendation performance. However, the existing multi-modal recommenders primarily depend on the features extracted individually from different media through pre-trained modality-specific encoders, and exhibit only shallow alignments between different modalities - limiting these systems' ability to capture the underlying relationships between the modalities. In this paper, we investigate the usage of large multi-modal encoders within the specific context of recommender systems, as these have previously demonstrated state-of-the-art effectiveness when ranking items across various domains. Specifically, we tailor two state-of-the-art multi",
    "path": "papers/23/10/2310.20343.json",
    "total_tokens": 864,
    "translated_title": "大规模多模态编码器用于推荐",
    "translated_abstract": "近年来，快速增长的在线多媒体服务（如电子商务平台）使得需要开发个性化推荐方法来对每个项目的多样内容进行编码。现代的多模态推荐系统利用从原始图像和物品描述中获取的多种特征来提高推荐性能。然而，现有的多模态推荐系统主要依赖于通过预训练的媒体特定编码器单独提取的特征，并且不同模态之间只有浅层次的对齐，限制了这些系统捕捉模态之间潜在关系的能力。本文中，我们研究在推荐系统特定背景下使用大规模多模态编码器的用法，因为在各个领域中评估物品排名时，这些编码器以前已经展示出最先进的效果。",
    "tldr": "本文研究了在推荐系统中使用大规模多模态编码器的方法，以提高推荐性能。现有的多模态推荐系统主要依赖于单独提取的特征，并且不同模态之间只有浅层次的对齐，而大规模多模态编码器能够更好地捕捉模态之间的潜在关系。",
    "en_tdlr": "This paper investigates the usage of large multi-modal encoders in recommender systems to enhance recommendation performance. The existing multi-modal recommenders primarily depend on individually extracted features with shallow alignments between different modalities, while large multi-modal encoders can better capture the underlying relationships between modalities."
}