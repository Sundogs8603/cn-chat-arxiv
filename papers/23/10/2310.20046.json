{
    "title": "Which Examples to Annotate for In-Context Learning? Towards Effective and Efficient Selection. (arXiv:2310.20046v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs) can adapt to new tasks via in-context learning (ICL). ICL is efficient as it does not require any parameter updates to the trained LLM, but only few annotated examples as input for the LLM. In this work, we investigate an active learning approach for ICL, where there is a limited budget for annotating examples. We propose a model-adaptive optimization-free algorithm, termed AdaICL, which identifies examples that the model is uncertain about, and performs semantic diversity-based example selection. Diversity-based sampling improves overall effectiveness, while uncertainty sampling improves budget efficiency and helps the LLM learn new information. Moreover, AdaICL poses its sampling strategy as a Maximum Coverage problem, that dynamically adapts based on the model's feedback and can be approximately solved via greedy algorithms. Extensive experiments on nine datasets and seven LLMs show that AdaICL improves performance by 4.4% accuracy points over SOTA (7.7%",
    "link": "http://arxiv.org/abs/2310.20046",
    "context": "Title: Which Examples to Annotate for In-Context Learning? Towards Effective and Efficient Selection. (arXiv:2310.20046v1 [cs.CL])\nAbstract: Large Language Models (LLMs) can adapt to new tasks via in-context learning (ICL). ICL is efficient as it does not require any parameter updates to the trained LLM, but only few annotated examples as input for the LLM. In this work, we investigate an active learning approach for ICL, where there is a limited budget for annotating examples. We propose a model-adaptive optimization-free algorithm, termed AdaICL, which identifies examples that the model is uncertain about, and performs semantic diversity-based example selection. Diversity-based sampling improves overall effectiveness, while uncertainty sampling improves budget efficiency and helps the LLM learn new information. Moreover, AdaICL poses its sampling strategy as a Maximum Coverage problem, that dynamically adapts based on the model's feedback and can be approximately solved via greedy algorithms. Extensive experiments on nine datasets and seven LLMs show that AdaICL improves performance by 4.4% accuracy points over SOTA (7.7%",
    "path": "papers/23/10/2310.20046.json",
    "total_tokens": 926,
    "translated_title": "哪些示例适合用于上下文学习？朝着有效和高效的选择方向。(arXiv:2310.20046v1 [cs.CL])",
    "translated_abstract": "大规模语言模型（LLM）可以通过上下文学习（ICL）适应新任务。ICL是高效的，因为它不需要对训练过的LLM进行任何参数更新，只需要少量的标注示例作为LLM的输入。本文研究了一种用于ICL的主动学习方法，在标注示例的预算有限的情况下。我们提出了一种模型自适应的无优化算法，称为AdaICL，它可以识别模型不确定的示例，并进行基于语义多样性的示例选择。基于多样性的采样可以提高整体效果，而不确定性采样可以提高预算效率并帮助LLM学习新信息。此外，AdaICL将其采样策略建模为一个最大覆盖问题，根据模型的反馈动态调整，并可以通过贪婪算法进行近似求解。在九个数据集和七个LLM上进行的大量实验证明，AdaICL的性能提高了4.4%的准确度，比现有技术达到了7.7%。",
    "tldr": "本文提出了一种模型自适应的无优化算法AdaICL，通过识别不确定的示例并进行基于语义多样性的选择，提高了上下文学习的效果和预算效率。",
    "en_tdlr": "This paper proposes a model-adaptive optimization-free algorithm, AdaICL, which improves the effectiveness and budget efficiency of in-context learning by identifying uncertain examples and performing diversity-based selection."
}