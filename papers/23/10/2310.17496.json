{
    "title": "Tackling Interference Induced by Data Training Loops in A/B Tests: A Weighted Training Approach. (arXiv:2310.17496v1 [stat.ME])",
    "abstract": "In modern recommendation systems, the standard pipeline involves training machine learning models on historical data to predict user behaviors and improve recommendations continuously. However, these data training loops can introduce interference in A/B tests, where data generated by control and treatment algorithms, potentially with different distributions, are combined. To address these challenges, we introduce a novel approach called weighted training. This approach entails training a model to predict the probability of each data point appearing in either the treatment or control data and subsequently applying weighted losses during model training. We demonstrate that this approach achieves the least variance among all estimators without causing shifts in the training distributions. Through simulation studies, we demonstrate the lower bias and variance of our approach compared to other methods.",
    "link": "http://arxiv.org/abs/2310.17496",
    "context": "Title: Tackling Interference Induced by Data Training Loops in A/B Tests: A Weighted Training Approach. (arXiv:2310.17496v1 [stat.ME])\nAbstract: In modern recommendation systems, the standard pipeline involves training machine learning models on historical data to predict user behaviors and improve recommendations continuously. However, these data training loops can introduce interference in A/B tests, where data generated by control and treatment algorithms, potentially with different distributions, are combined. To address these challenges, we introduce a novel approach called weighted training. This approach entails training a model to predict the probability of each data point appearing in either the treatment or control data and subsequently applying weighted losses during model training. We demonstrate that this approach achieves the least variance among all estimators without causing shifts in the training distributions. Through simulation studies, we demonstrate the lower bias and variance of our approach compared to other methods.",
    "path": "papers/23/10/2310.17496.json",
    "total_tokens": 925,
    "translated_title": "解决A/B测试中数据训练循环引起的干扰：一种加权训练方法",
    "translated_abstract": "在现代推荐系统中，标准流程涉及使用历史数据训练机器学习模型来预测用户行为并持续改进推荐。然而，这些数据训练循环可能在A/B测试中引入干扰，其中控制组和实验组算法生成的数据，可能具有不同的分布，被合并在一起。为了解决这些挑战，我们提出了一种新颖的方法，称为加权训练。该方法包括训练一个模型来预测每个数据点出现在实验组或控制组数据中的概率，并在模型训练过程中应用加权损失。我们通过模拟研究证明了这种方法在所有估计量中具有最小的方差，且不会导致训练分布发生变化。我们通过模拟研究证明了与其他方法相比，我们的方法具有较低的偏差和方差。",
    "tldr": "该论文提出了一种名为加权训练的方法，用于解决A/B测试中由数据训练循环引起的干扰。该方法通过训练模型预测每个数据点在实验组或控制组中出现的概率，并在模型训练过程中应用加权损失，从而实现了最小方差的估计结果，并且不会引起训练分布的变化。",
    "en_tdlr": "This paper proposes a weighted training approach to tackle interference induced by data training loops in A/B tests. By training a model to predict the probability of each data point appearing in either the treatment or control data and applying weighted losses during model training, this approach achieves the least variance among all estimators without causing shifts in the training distributions."
}