{
    "title": "ViTs are Everywhere: A Comprehensive Study Showcasing Vision Transformers in Different Domain. (arXiv:2310.05664v2 [cs.CV] UPDATED)",
    "abstract": "Transformer design is the de facto standard for natural language processing tasks. The success of the transformer design in natural language processing has lately piqued the interest of researchers in the domain of computer vision. When compared to Convolutional Neural Networks (CNNs), Vision Transformers (ViTs) are becoming more popular and dominant solutions for many vision problems. Transformer-based models outperform other types of networks, such as convolutional and recurrent neural networks, in a range of visual benchmarks. We evaluate various vision transformer models in this work by dividing them into distinct jobs and examining their benefits and drawbacks. ViTs can overcome several possible difficulties with convolutional neural networks (CNNs). The goal of this survey is to show the first use of ViTs in CV. In the first phase, we categorize various CV applications where ViTs are appropriate. Image classification, object identification, image segmentation, video transformer, ",
    "link": "http://arxiv.org/abs/2310.05664",
    "context": "Title: ViTs are Everywhere: A Comprehensive Study Showcasing Vision Transformers in Different Domain. (arXiv:2310.05664v2 [cs.CV] UPDATED)\nAbstract: Transformer design is the de facto standard for natural language processing tasks. The success of the transformer design in natural language processing has lately piqued the interest of researchers in the domain of computer vision. When compared to Convolutional Neural Networks (CNNs), Vision Transformers (ViTs) are becoming more popular and dominant solutions for many vision problems. Transformer-based models outperform other types of networks, such as convolutional and recurrent neural networks, in a range of visual benchmarks. We evaluate various vision transformer models in this work by dividing them into distinct jobs and examining their benefits and drawbacks. ViTs can overcome several possible difficulties with convolutional neural networks (CNNs). The goal of this survey is to show the first use of ViTs in CV. In the first phase, we categorize various CV applications where ViTs are appropriate. Image classification, object identification, image segmentation, video transformer, ",
    "path": "papers/23/10/2310.05664.json",
    "total_tokens": 870,
    "translated_title": "ViTs无处不在：展示不同领域中的视觉Transformer的综合研究",
    "translated_abstract": "Transformer设计是自然语言处理任务的事实标准。Transformer设计在自然语言处理中的成功最近引起了计算机视觉领域研究人员的兴趣。与卷积神经网络（CNN）相比，视觉Transformer（ViTs）正在成为许多视觉问题的流行和主导解决方案。基于Transformer的模型在多种视觉基准中表现优异，超过了卷积神经网络（CNN）和循环神经网络等其他类型网络。本工作通过将各种视觉Transformer模型划分为不同任务并研究其优势和缺点，对其进行评估。ViTs能够克服卷积神经网络（CNN）可能遇到的一些困难。本调查的目标是展示ViTs在计算机视觉中的首次应用。在第一阶段，我们对适用ViTs的各种计算机视觉应用进行分类，包括图像分类、目标识别、图像分割、视频Transformer等。",
    "tldr": "这项综合研究展示了视觉Transformer在不同领域中的应用，通过与卷积神经网络的比较，证明了其在视觉问题上的优越性和潜力。"
}