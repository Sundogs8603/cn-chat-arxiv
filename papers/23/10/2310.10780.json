{
    "title": "Demystifying Poisoning Backdoor Attacks from a Statistical Perspective. (arXiv:2310.10780v1 [cs.CR])",
    "abstract": "The growing dependence on machine learning in real-world applications emphasizes the importance of understanding and ensuring its safety. Backdoor attacks pose a significant security risk due to their stealthy nature and potentially serious consequences. Such attacks involve embedding triggers within a learning model with the intention of causing malicious behavior when an active trigger is present while maintaining regular functionality without it. This paper evaluates the effectiveness of any backdoor attack incorporating a constant trigger, by establishing tight lower and upper boundaries for the performance of the compromised model on both clean and backdoor test data. The developed theory answers a series of fundamental but previously underexplored problems, including (1) what are the determining factors for a backdoor attack's success, (2) what is the direction of the most effective backdoor attack, and (3) when will a human-imperceptible trigger succeed. Our derived understandin",
    "link": "http://arxiv.org/abs/2310.10780",
    "context": "Title: Demystifying Poisoning Backdoor Attacks from a Statistical Perspective. (arXiv:2310.10780v1 [cs.CR])\nAbstract: The growing dependence on machine learning in real-world applications emphasizes the importance of understanding and ensuring its safety. Backdoor attacks pose a significant security risk due to their stealthy nature and potentially serious consequences. Such attacks involve embedding triggers within a learning model with the intention of causing malicious behavior when an active trigger is present while maintaining regular functionality without it. This paper evaluates the effectiveness of any backdoor attack incorporating a constant trigger, by establishing tight lower and upper boundaries for the performance of the compromised model on both clean and backdoor test data. The developed theory answers a series of fundamental but previously underexplored problems, including (1) what are the determining factors for a backdoor attack's success, (2) what is the direction of the most effective backdoor attack, and (3) when will a human-imperceptible trigger succeed. Our derived understandin",
    "path": "papers/23/10/2310.10780.json",
    "total_tokens": 928,
    "translated_title": "从统计学角度揭开中毒后门攻击的神秘面纱",
    "translated_abstract": "在现实世界中，对机器学习的依赖日益增长，强调了理解和确保其安全性的重要性。中毒后门攻击由于其隐蔽性和潜在的严重后果而构成了重大的安全风险。这类攻击涉及将触发器嵌入学习模型中，以在存在活动触发器时引起恶意行为，同时在没有触发器的情况下维持正常功能。本文通过为受损模型在清洁和后门测试数据上的性能建立严格的下限和上限，评估了任何包含恒定触发器的后门攻击的有效性。所开发的理论回答了一系列基本但以前未被充分探索的问题，包括（1）后门攻击成功的决定因素是什么，（2）最有效的后门攻击方向是什么，以及（3）几乎不可察觉的人类触发器何时会成功。我们得到的理解...",
    "tldr": "从统计学角度揭开中毒后门攻击的神秘面纱，通过评估任何包含恒定触发器的后门攻击的有效性，确定了后门攻击成功的决定因素、最有效的攻击方向以及几乎不可察觉的人类触发器何时会成功。",
    "en_tdlr": "This paper demystifies poisoning backdoor attacks from a statistical perspective by evaluating the effectiveness of any backdoor attack incorporating a constant trigger. It determines the factors for a backdoor attack's success, the direction of the most effective attack, and when a human-imperceptible trigger will succeed."
}