{
    "title": "Multi-Grid Tensorized Fourier Neural Operator for High-Resolution PDEs. (arXiv:2310.00120v1 [cs.LG])",
    "abstract": "Memory complexity and data scarcity have so far prohibited learning solution operators of partial differential equations (PDEs) at high resolutions. We address these limitations by introducing a new data efficient and highly parallelizable operator learning approach with reduced memory requirement and better generalization, called multi-grid tensorized neural operator (MG-TFNO). MG-TFNO scales to large resolutions by leveraging local and global structures of full-scale, real-world phenomena, through a decomposition of both the input domain and the operator's parameter space. Our contributions are threefold: i) we enable parallelization over input samples with a novel multi-grid-based domain decomposition, ii) we represent the parameters of the model in a high-order latent subspace of the Fourier domain, through a global tensor factorization, resulting in an extreme reduction in the number of parameters and improved generalization, and iii) we propose architectural improvements to the b",
    "link": "http://arxiv.org/abs/2310.00120",
    "context": "Title: Multi-Grid Tensorized Fourier Neural Operator for High-Resolution PDEs. (arXiv:2310.00120v1 [cs.LG])\nAbstract: Memory complexity and data scarcity have so far prohibited learning solution operators of partial differential equations (PDEs) at high resolutions. We address these limitations by introducing a new data efficient and highly parallelizable operator learning approach with reduced memory requirement and better generalization, called multi-grid tensorized neural operator (MG-TFNO). MG-TFNO scales to large resolutions by leveraging local and global structures of full-scale, real-world phenomena, through a decomposition of both the input domain and the operator's parameter space. Our contributions are threefold: i) we enable parallelization over input samples with a novel multi-grid-based domain decomposition, ii) we represent the parameters of the model in a high-order latent subspace of the Fourier domain, through a global tensor factorization, resulting in an extreme reduction in the number of parameters and improved generalization, and iii) we propose architectural improvements to the b",
    "path": "papers/23/10/2310.00120.json",
    "total_tokens": 954,
    "translated_title": "高分辨率偏微分方程的多重网格张量傅里叶神经算子",
    "translated_abstract": "到目前为止，内存复杂性和数据稀缺性阻碍了学习高分辨率偏微分方程（PDE）的解算子。我们通过引入一种新的数据有效且高度并行化的算子学习方法，降低了内存需求并改进了泛化性能，称为多重网格张量化神经算子（MG-TFNO）。MG-TFNO通过利用完整世界现象的局部和全局结构，通过输入域和算子参数空间的分解来扩展到大尺度的分辨率。我们的贡献有三个方面：i）我们通过一种新颖的基于多重网格的域分解实现了对输入样本的并行化，ii）我们通过傅里叶域中的高阶潜在子空间将模型参数表示，通过全局张量分解，大大减少参数数量并提高泛化性能，iii）我们提出了对b的架构改进。",
    "tldr": "本论文介绍了一种称为多重网格张量傅里叶神经算子（MG-TFNO）的新型数据有效且高度并行化的算子学习方法，它通过局部和全局结构的分解来扩展至大尺度的分辨率。其创新包括多重网格的域分解、在傅里叶域中的高阶潜在子空间表示参数以及对架构的改进。",
    "en_tdlr": "This paper introduces a novel data-efficient and highly parallelizable operator learning approach called Multi-Grid Tensorized Fourier Neural Operator (MG-TFNO), which extends to high resolutions by leveraging local and global structures through decomposition. The innovations include a multi-grid domain decomposition, representing parameters in a high-order latent subspace of the Fourier domain, and architectural improvements."
}