{
    "title": "Generative Pre-trained Transformer for Vietnamese Community-based COVID-19 Question Answering. (arXiv:2310.14602v2 [cs.CL] UPDATED)",
    "abstract": "Recent studies have provided empirical evidence of the wide-ranging potential of Generative Pre-trained Transformer (GPT), a pretrained language model, in the field of natural language processing. GPT has been effectively employed as a decoder within state-of-the-art (SOTA) question answering systems, yielding exceptional performance across various tasks. However, the current research landscape concerning GPT's application in Vietnamese remains limited. This paper aims to address this gap by presenting an implementation of GPT-2 for community-based question answering specifically focused on COVID-19 related queries in Vietnamese. We introduce a novel approach by conducting a comparative analysis of different Transformers vs SOTA models in the community-based COVID-19 question answering dataset. The experimental findings demonstrate that the GPT-2 models exhibit highly promising outcomes, outperforming other SOTA models as well as previous community-based COVID-19 question answering mod",
    "link": "http://arxiv.org/abs/2310.14602",
    "context": "Title: Generative Pre-trained Transformer for Vietnamese Community-based COVID-19 Question Answering. (arXiv:2310.14602v2 [cs.CL] UPDATED)\nAbstract: Recent studies have provided empirical evidence of the wide-ranging potential of Generative Pre-trained Transformer (GPT), a pretrained language model, in the field of natural language processing. GPT has been effectively employed as a decoder within state-of-the-art (SOTA) question answering systems, yielding exceptional performance across various tasks. However, the current research landscape concerning GPT's application in Vietnamese remains limited. This paper aims to address this gap by presenting an implementation of GPT-2 for community-based question answering specifically focused on COVID-19 related queries in Vietnamese. We introduce a novel approach by conducting a comparative analysis of different Transformers vs SOTA models in the community-based COVID-19 question answering dataset. The experimental findings demonstrate that the GPT-2 models exhibit highly promising outcomes, outperforming other SOTA models as well as previous community-based COVID-19 question answering mod",
    "path": "papers/23/10/2310.14602.json",
    "total_tokens": 863,
    "translated_title": "用于越南社区基于COVID-19问答的生成前训练转换器",
    "translated_abstract": "最近的研究提供了生成前训练转换器（GPT），一种预训练的语言模型，在自然语言处理领域的广泛潜力的经验证据。 GPT已被有效地应用于最先进的问答系统中作为解码器，在各种任务中表现出色。然而，有关GPT在越南语中应用的当前研究现状仍然有限。 本文旨在通过在越南语中特别关注COVID-19相关查询的社区问答中实现GPT-2来填补这一差距。我们通过对社区COVID-19问答数据集中不同的转换器与SOTA模型进行比较分析，引入了一种新颖的方法。实验结果表明，GPT-2模型显示出非常有希望的结果，优于其他SOTA模型以及先前的社区COVID-19问答模型。",
    "tldr": "本研究实现了用于越南社区的生成前训练转换器(GPT-2)，专注于COVID-19相关问答。实验结果表明，GPT-2模型在社区COVID-19问答数据集中表现出色，优于其他模型。"
}