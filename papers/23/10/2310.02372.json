{
    "title": "ProtoNER: Few shot Incremental Learning for Named Entity Recognition using Prototypical Networks. (arXiv:2310.02372v1 [cs.CL])",
    "abstract": "Key value pair (KVP) extraction or Named Entity Recognition(NER) from visually rich documents has been an active area of research in document understanding and data extraction domain. Several transformer based models such as LayoutLMv2, LayoutLMv3, and LiLT have emerged achieving state of the art results. However, addition of even a single new class to the existing model requires (a) re-annotation of entire training dataset to include this new class and (b) retraining the model again. Both of these issues really slow down the deployment of updated model. \\\\ We present \\textbf{ProtoNER}: Prototypical Network based end-to-end KVP extraction model that allows addition of new classes to an existing model while requiring minimal number of newly annotated training samples. The key contributions of our model are: (1) No dependency on dataset used for initial training of the model, which alleviates the need to retain original training dataset for longer duration as well as data re-annotation w",
    "link": "http://arxiv.org/abs/2310.02372",
    "context": "Title: ProtoNER: Few shot Incremental Learning for Named Entity Recognition using Prototypical Networks. (arXiv:2310.02372v1 [cs.CL])\nAbstract: Key value pair (KVP) extraction or Named Entity Recognition(NER) from visually rich documents has been an active area of research in document understanding and data extraction domain. Several transformer based models such as LayoutLMv2, LayoutLMv3, and LiLT have emerged achieving state of the art results. However, addition of even a single new class to the existing model requires (a) re-annotation of entire training dataset to include this new class and (b) retraining the model again. Both of these issues really slow down the deployment of updated model. \\\\ We present \\textbf{ProtoNER}: Prototypical Network based end-to-end KVP extraction model that allows addition of new classes to an existing model while requiring minimal number of newly annotated training samples. The key contributions of our model are: (1) No dependency on dataset used for initial training of the model, which alleviates the need to retain original training dataset for longer duration as well as data re-annotation w",
    "path": "papers/23/10/2310.02372.json",
    "total_tokens": 712,
    "translated_title": "ProtoNER: 使用原型网络进行命名实体识别的少样本增量学习",
    "translated_abstract": "键值对（KVP）提取或命名实体识别（NER）是文档理解和数据提取领域的研究热点。一些基于transformer的模型如LayoutLMv2、LayoutLMv3和LiLT已经取得了最先进的结果。然而，即使向现有模型添加一个新类别，也需要重新注释整个训练数据集并重新训练模型。这些问题都严重影响了更新模型的部署速度。",
    "tldr": "ProtoNER是一种基于原型网络的端到端KVP提取模型，可以在现有模型中添加新类别，而只需最少数量的新注释训练样本。"
}