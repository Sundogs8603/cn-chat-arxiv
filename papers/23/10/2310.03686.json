{
    "title": "DecoderLens: Layerwise Interpretation of Encoder-Decoder Transformers. (arXiv:2310.03686v1 [cs.CL])",
    "abstract": "In recent years, many interpretability methods have been proposed to help interpret the internal states of Transformer-models, at different levels of precision and complexity. Here, to analyze encoder-decoder Transformers, we propose a simple, new method: DecoderLens. Inspired by the LogitLens (for decoder-only Transformers), this method involves allowing the decoder to cross-attend representations of intermediate encoder layers instead of using the final encoder output, as is normally done in encoder-decoder models. The method thus maps previously uninterpretable vector representations to human-interpretable sequences of words or symbols. We report results from the DecoderLens applied to models trained on question answering, logical reasoning, speech recognition and machine translation. The DecoderLens reveals several specific subtasks that are solved at low or intermediate layers, shedding new light on the information flow inside the encoder component of this important class of model",
    "link": "http://arxiv.org/abs/2310.03686",
    "context": "Title: DecoderLens: Layerwise Interpretation of Encoder-Decoder Transformers. (arXiv:2310.03686v1 [cs.CL])\nAbstract: In recent years, many interpretability methods have been proposed to help interpret the internal states of Transformer-models, at different levels of precision and complexity. Here, to analyze encoder-decoder Transformers, we propose a simple, new method: DecoderLens. Inspired by the LogitLens (for decoder-only Transformers), this method involves allowing the decoder to cross-attend representations of intermediate encoder layers instead of using the final encoder output, as is normally done in encoder-decoder models. The method thus maps previously uninterpretable vector representations to human-interpretable sequences of words or symbols. We report results from the DecoderLens applied to models trained on question answering, logical reasoning, speech recognition and machine translation. The DecoderLens reveals several specific subtasks that are solved at low or intermediate layers, shedding new light on the information flow inside the encoder component of this important class of model",
    "path": "papers/23/10/2310.03686.json",
    "total_tokens": 951,
    "translated_title": "DecoderLens: 编码器-解码器Transformer的逐层解释",
    "translated_abstract": "近年来，已经提出了许多可解释性方法来帮助解释Transformer模型的内部状态，这些方法在不同的精度和复杂性级别上工作。在这里，为了分析编码器-解码器Transformer，我们提出了一种简单而新颖的方法：DecoderLens。受到了LogitLens（用于仅解码器的Transformer）的启发，这种方法允许解码器跨越中间编码器层的表示进行交叉注意，而不是像常规的编码器-解码器模型中那样使用最终的编码器输出。因此，这种方法将先前无法解释的向量表示映射到人类可解释的单词或符号序列。我们报告了应用于问题回答、逻辑推理、语音识别和机器翻译训练模型的DecoderLens的结果。DecoderLens在低层或中间层揭示了解决的几个特定子任务，为这个重要模型类别中的编码器组件内的信息流提供了新的光明。",
    "tldr": "DecoderLens是一种用于解释编码器-解码器Transformer模型中内部状态的新方法。通过让解码器跨越中间编码器层的表示进行交叉注意，DecoderLens将先前无法解释的向量表示映射到可解释的单词或符号序列，揭示了模型在低层或中间层解决的特定子任务，为信息流提供了新的洞察。",
    "en_tdlr": "DecoderLens is a new method for interpreting the internal states of encoder-decoder Transformer models. By allowing the decoder to cross-attend representations of intermediate encoder layers, DecoderLens maps previously uninterpretable vector representations to interpretable sequences of words or symbols, revealing specific subtasks solved at low or intermediate layers and providing new insights into the information flow."
}