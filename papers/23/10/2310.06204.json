{
    "title": "Estimating Numbers without Regression. (arXiv:2310.06204v1 [cs.CL])",
    "abstract": "Despite recent successes in language models, their ability to represent numbers is insufficient. Humans conceptualize numbers based on their magnitudes, effectively projecting them on a number line; whereas subword tokenization fails to explicitly capture magnitude by splitting numbers into arbitrary chunks. To alleviate this shortcoming, alternative approaches have been proposed that modify numbers at various stages of the language modeling pipeline. These methods change either the (1) notation in which numbers are written (\\eg scientific vs decimal), the (2) vocabulary used to represent numbers or the entire (3) architecture of the underlying language model, to directly regress to a desired number.  Previous work suggests that architectural change helps achieve state-of-the-art on number estimation but we find an insightful ablation: changing the model's vocabulary instead (\\eg introduce a new token for numbers in range 10-100) is a far better trade-off. In the context of masked numb",
    "link": "http://arxiv.org/abs/2310.06204",
    "context": "Title: Estimating Numbers without Regression. (arXiv:2310.06204v1 [cs.CL])\nAbstract: Despite recent successes in language models, their ability to represent numbers is insufficient. Humans conceptualize numbers based on their magnitudes, effectively projecting them on a number line; whereas subword tokenization fails to explicitly capture magnitude by splitting numbers into arbitrary chunks. To alleviate this shortcoming, alternative approaches have been proposed that modify numbers at various stages of the language modeling pipeline. These methods change either the (1) notation in which numbers are written (\\eg scientific vs decimal), the (2) vocabulary used to represent numbers or the entire (3) architecture of the underlying language model, to directly regress to a desired number.  Previous work suggests that architectural change helps achieve state-of-the-art on number estimation but we find an insightful ablation: changing the model's vocabulary instead (\\eg introduce a new token for numbers in range 10-100) is a far better trade-off. In the context of masked numb",
    "path": "papers/23/10/2310.06204.json",
    "total_tokens": 809,
    "translated_title": "无回归估计数字",
    "translated_abstract": "尽管语言模型在最近取得了成功，但它们表示数字的能力仍然不足。人类根据数字的大小进行概念化，有效地将它们投射到数字线上；而子词标记化无法明确捕捉数字的大小，将数字分割成任意的块。为了克服这个缺点，已经提出了替代方法，在语言建模管线的各个阶段修改数字。这些方法要么改变数字的表示方式（例如科学计数法与十进制），要么改变用于表示数字的词汇表，要么直接改变基础语言模型的架构，以直接回归到所需的数字。以前的工作表明，架构的更改有助于在数字估计上达到最先进的水平，但我们发现一个有洞察力的缺憾：改变模型的词汇表（例如在10-100范围内引入一个新的数字标记）是一个更好的权衡。",
    "tldr": "提出了一种不使用回归的方法来估计数字，通过改变模型的词汇表来更好地表示数字的大小，并取得了令人满意的结果。",
    "en_tdlr": "A method for estimating numbers without regression is proposed, which achieves satisfactory results by changing the model's vocabulary to better represent the magnitude of the numbers."
}