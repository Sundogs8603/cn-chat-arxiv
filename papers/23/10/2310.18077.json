{
    "title": "Detrimental Contexts in Open-Domain Question Answering. (arXiv:2310.18077v1 [cs.CL])",
    "abstract": "For knowledge intensive NLP tasks, it has been widely accepted that accessing more information is a contributing factor to improvements in the model's end-to-end performance. However, counter-intuitively, too much context can have a negative impact on the model when evaluated on common question answering (QA) datasets. In this paper, we analyze how passages can have a detrimental effect on retrieve-then-read architectures used in question answering. Our empirical evidence indicates that the current read architecture does not fully leverage the retrieved passages and significantly degrades its performance when using the whole passages compared to utilizing subsets of them. Our findings demonstrate that model accuracy can be improved by 10% on two popular QA datasets by filtering out detrimental passages. Additionally, these outcomes are attained by utilizing existing retrieval methods without further training or data. We further highlight the challenges associated with identifying the d",
    "link": "http://arxiv.org/abs/2310.18077",
    "context": "Title: Detrimental Contexts in Open-Domain Question Answering. (arXiv:2310.18077v1 [cs.CL])\nAbstract: For knowledge intensive NLP tasks, it has been widely accepted that accessing more information is a contributing factor to improvements in the model's end-to-end performance. However, counter-intuitively, too much context can have a negative impact on the model when evaluated on common question answering (QA) datasets. In this paper, we analyze how passages can have a detrimental effect on retrieve-then-read architectures used in question answering. Our empirical evidence indicates that the current read architecture does not fully leverage the retrieved passages and significantly degrades its performance when using the whole passages compared to utilizing subsets of them. Our findings demonstrate that model accuracy can be improved by 10% on two popular QA datasets by filtering out detrimental passages. Additionally, these outcomes are attained by utilizing existing retrieval methods without further training or data. We further highlight the challenges associated with identifying the d",
    "path": "papers/23/10/2310.18077.json",
    "total_tokens": 857,
    "translated_title": "开放领域问答中有害背景的影响",
    "translated_abstract": "对于知识密集型的自然语言处理任务，广泛认可的观点是访问更多信息有助于模型的端到端性能改善。然而，令人感到困惑的是，当在常见的问答数据集上进行评估时，过多的背景信息会对模型产生负面影响。本文分析了在问答中使用的检索-阅读结构中，段落如何对模型产生不利影响。我们的实证证据表明，当前的阅读结构没有充分利用检索到的段落，在使用整个段落时与利用它们的子集相比，其性能显著下降。我们的研究结果表明，通过过滤掉有害的段落，可以在两个受欢迎的问答数据集上将模型的准确性提高10%。此外，这些结果是通过利用现有的检索方法而无需进一步训练或数据来实现的。我们还进一步强调了识别有害背景的挑战。",
    "tldr": "本文分析了在开放领域问答中过多的背景信息对模型性能的负面影响，并发现通过过滤掉有害的段落可以提高模型的准确性。",
    "en_tdlr": "This paper analyzes the negative impact of excessive background information on model performance in open-domain question answering and finds that model accuracy can be improved by filtering out detrimental passages."
}