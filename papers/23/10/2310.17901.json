{
    "title": "Improving the Knowledge Gradient Algorithm. (arXiv:2310.17901v1 [cs.LG])",
    "abstract": "The knowledge gradient (KG) algorithm is a popular policy for the best arm identification (BAI) problem. It is built on the simple idea of always choosing the measurement that yields the greatest expected one-step improvement in the estimate of the best mean of the arms. In this research, we show that this policy has limitations, causing the algorithm not asymptotically optimal. We next provide a remedy for it, by following the manner of one-step look ahead of KG, but instead choosing the measurement that yields the greatest one-step improvement in the probability of selecting the best arm. The new policy is called improved knowledge gradient (iKG). iKG can be shown to be asymptotically optimal. In addition, we show that compared to KG, it is easier to extend iKG to variant problems of BAI, with the $\\epsilon$-good arm identification and feasible arm identification as two examples. The superior performances of iKG on these problems are further demonstrated using numerical examples.",
    "link": "http://arxiv.org/abs/2310.17901",
    "context": "Title: Improving the Knowledge Gradient Algorithm. (arXiv:2310.17901v1 [cs.LG])\nAbstract: The knowledge gradient (KG) algorithm is a popular policy for the best arm identification (BAI) problem. It is built on the simple idea of always choosing the measurement that yields the greatest expected one-step improvement in the estimate of the best mean of the arms. In this research, we show that this policy has limitations, causing the algorithm not asymptotically optimal. We next provide a remedy for it, by following the manner of one-step look ahead of KG, but instead choosing the measurement that yields the greatest one-step improvement in the probability of selecting the best arm. The new policy is called improved knowledge gradient (iKG). iKG can be shown to be asymptotically optimal. In addition, we show that compared to KG, it is easier to extend iKG to variant problems of BAI, with the $\\epsilon$-good arm identification and feasible arm identification as two examples. The superior performances of iKG on these problems are further demonstrated using numerical examples.",
    "path": "papers/23/10/2310.17901.json",
    "total_tokens": 969,
    "translated_title": "改进知识梯度算法",
    "translated_abstract": "知识梯度（KG）算法是一种用于最佳臂识别（BAI）问题的流行策略。它建立在一种简单的思想上，即始终选择产生对臂的最佳均值估计预期一步改进最大的测量。在这项研究中，我们发现这种策略存在局限性，导致算法在渐近上不是最优的。我们接下来提供了一种改进方法，通过遵循KG的一步前瞻方式，但选择产生对选择最佳臂的概率最大的一步改进的测量。新的策略称为改进的知识梯度（iKG）。可以证明iKG在渐近上是最优的。此外，我们还展示了与KG相比，更容易将iKG扩展到BAI的不同问题，其中包括ε-好臂识别和可行臂识别两个例子。我们还通过数值实例进一步展示了iKG在这些问题上的优越性能。",
    "tldr": "本研究改进了知识梯度算法，提出了一种改进的知识梯度（iKG）策略，该策略解决了知识梯度算法的局限性，并且在最佳臂识别问题中具有渐近最优性。此外，相比知识梯度（KG），iKG更容易扩展到其他BAI问题，且在这些问题上表现出更好的性能。",
    "en_tdlr": "This study improves the knowledge gradient algorithm by introducing an improved knowledge gradient (iKG) strategy, which addresses the limitations of the knowledge gradient algorithm and achieves asymptotic optimality in the best arm identification problem. Additionally, compared to the knowledge gradient (KG), iKG is easier to extend to other BAI problems and demonstrates superior performance in these problems."
}