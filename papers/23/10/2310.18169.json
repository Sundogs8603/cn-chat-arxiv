{
    "title": "Style Description based Text-to-Speech with Conditional Prosodic Layer Normalization based Diffusion GAN. (arXiv:2310.18169v1 [cs.SD])",
    "abstract": "In this paper, we present a Diffusion GAN based approach (Prosodic Diff-TTS) to generate the corresponding high-fidelity speech based on the style description and content text as an input to generate speech samples within only 4 denoising steps. It leverages the novel conditional prosodic layer normalization to incorporate the style embeddings into the multi head attention based phoneme encoder and mel spectrogram decoder based generator architecture to generate the speech. The style embedding is generated by fine tuning the pretrained BERT model on auxiliary tasks such as pitch, speaking speed, emotion,gender classifications. We demonstrate the efficacy of our proposed architecture on multi-speaker LibriTTS and PromptSpeech datasets, using multiple quantitative metrics that measure generated accuracy and MOS.",
    "link": "http://arxiv.org/abs/2310.18169",
    "context": "Title: Style Description based Text-to-Speech with Conditional Prosodic Layer Normalization based Diffusion GAN. (arXiv:2310.18169v1 [cs.SD])\nAbstract: In this paper, we present a Diffusion GAN based approach (Prosodic Diff-TTS) to generate the corresponding high-fidelity speech based on the style description and content text as an input to generate speech samples within only 4 denoising steps. It leverages the novel conditional prosodic layer normalization to incorporate the style embeddings into the multi head attention based phoneme encoder and mel spectrogram decoder based generator architecture to generate the speech. The style embedding is generated by fine tuning the pretrained BERT model on auxiliary tasks such as pitch, speaking speed, emotion,gender classifications. We demonstrate the efficacy of our proposed architecture on multi-speaker LibriTTS and PromptSpeech datasets, using multiple quantitative metrics that measure generated accuracy and MOS.",
    "path": "papers/23/10/2310.18169.json",
    "total_tokens": 774,
    "translated_title": "基于条件韵律层标准化扩散GAN的风格描述文本转语音",
    "translated_abstract": "本文提出了一种基于扩散GAN的方法（Prosodic Diff-TTS），根据风格描述和内容文本生成相应的高保真语音。它利用了新颖的条件韵律层标准化，将风格嵌入到基于多头注意力的音素编码器和基于梅尔频谱图的解码器的生成器架构中，从而生成语音。风格嵌入是通过在辅助任务（如音高、语速、情感、性别分类）上微调预训练的BERT模型来生成的。我们使用多个定量指标来衡量生成准确性和MOS，并在多说话人的LibriTTS和PromptSpeech数据集上展示了我们提出的架构的有效性。",
    "tldr": "本文介绍了一种基于Diffusion GAN的方法，利用条件韵律层标准化将风格嵌入到生成架构中，从而实现根据风格描述和内容文本生成高质量语音。",
    "en_tdlr": "This paper presents an approach based on Diffusion GAN, which incorporates style into the generation architecture using conditional prosodic layer normalization, enabling the generation of high-quality speech based on style description and content text."
}