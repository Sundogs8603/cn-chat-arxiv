{
    "title": "Non-Autoregressive Sentence Ordering. (arXiv:2310.12640v1 [cs.CL])",
    "abstract": "Existing sentence ordering approaches generally employ encoder-decoder frameworks with the pointer net to recover the coherence by recurrently predicting each sentence step-by-step. Such an autoregressive manner only leverages unilateral dependencies during decoding and cannot fully explore the semantic dependency between sentences for ordering. To overcome these limitations, in this paper, we propose a novel Non-Autoregressive Ordering Network, dubbed \\textit{NAON}, which explores bilateral dependencies between sentences and predicts the sentence for each position in parallel. We claim that the non-autoregressive manner is not just applicable but also particularly suitable to the sentence ordering task because of two peculiar characteristics of the task: 1) each generation target is in deterministic length, and 2) the sentences and positions should match exclusively. Furthermore, to address the repetition issue of the naive non-autoregressive Transformer, we introduce an exclusive los",
    "link": "http://arxiv.org/abs/2310.12640",
    "context": "Title: Non-Autoregressive Sentence Ordering. (arXiv:2310.12640v1 [cs.CL])\nAbstract: Existing sentence ordering approaches generally employ encoder-decoder frameworks with the pointer net to recover the coherence by recurrently predicting each sentence step-by-step. Such an autoregressive manner only leverages unilateral dependencies during decoding and cannot fully explore the semantic dependency between sentences for ordering. To overcome these limitations, in this paper, we propose a novel Non-Autoregressive Ordering Network, dubbed \\textit{NAON}, which explores bilateral dependencies between sentences and predicts the sentence for each position in parallel. We claim that the non-autoregressive manner is not just applicable but also particularly suitable to the sentence ordering task because of two peculiar characteristics of the task: 1) each generation target is in deterministic length, and 2) the sentences and positions should match exclusively. Furthermore, to address the repetition issue of the naive non-autoregressive Transformer, we introduce an exclusive los",
    "path": "papers/23/10/2310.12640.json",
    "total_tokens": 846,
    "translated_title": "非自回归句子排序",
    "translated_abstract": "现有的句子排序方法通常采用编码器-解码器框架与指针网络，通过逐步预测每个句子来恢复连贯性。这种自回归方式只能在解码过程中利用单向依赖关系，无法充分探索句子之间的语义依赖关系进行排序。为了克服这些限制，本文提出了一种新颖的非自回归排序网络，名为NAON，它探索了句子之间的双向依赖关系，并并行预测每个位置的句子。我们认为非自回归方式不仅适用于句子排序任务，而且特别适用，原因有两个：1）每个生成目标具有确定化的长度，2）句子和位置应该完全匹配。此外，为了解决朴素的非自回归Transformer的重复问题，我们引入了一种排他性的损失函数。",
    "tldr": "这篇论文提出了一种非自回归的句子排序方法，通过探索句子之间的双向依赖关系，并并行预测每个位置的句子，以解决现有方法在排序任务中只能利用单向依赖关系的限制。",
    "en_tdlr": "This paper proposes a non-autoregressive approach for sentence ordering, which explores bilateral dependencies between sentences and predicts the sentence for each position in parallel, overcoming the limitations of existing approaches that can only leverage unilateral dependencies in the ordering task."
}