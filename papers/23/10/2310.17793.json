{
    "title": "\"You Are An Expert Linguistic Annotator\": Limits of LLMs as Analyzers of Abstract Meaning Representation. (arXiv:2310.17793v1 [cs.CL])",
    "abstract": "Large language models (LLMs) show amazing proficiency and fluency in the use of language. Does this mean that they have also acquired insightful linguistic knowledge about the language, to an extent that they can serve as an \"expert linguistic annotator\"? In this paper, we examine the successes and limitations of the GPT-3, ChatGPT, and GPT-4 models in analysis of sentence meaning structure, focusing on the Abstract Meaning Representation (AMR; Banarescu et al. 2013) parsing formalism, which provides rich graphical representations of sentence meaning structure while abstracting away from surface forms. We compare models' analysis of this semantic structure across two settings: 1) direct production of AMR parses based on zero- and few-shot prompts, and 2) indirect partial reconstruction of AMR via metalinguistic natural language queries (e.g., \"Identify the primary event of this sentence, and the predicate corresponding to that event.\"). Across these settings, we find that models can re",
    "link": "http://arxiv.org/abs/2310.17793",
    "context": "Title: \"You Are An Expert Linguistic Annotator\": Limits of LLMs as Analyzers of Abstract Meaning Representation. (arXiv:2310.17793v1 [cs.CL])\nAbstract: Large language models (LLMs) show amazing proficiency and fluency in the use of language. Does this mean that they have also acquired insightful linguistic knowledge about the language, to an extent that they can serve as an \"expert linguistic annotator\"? In this paper, we examine the successes and limitations of the GPT-3, ChatGPT, and GPT-4 models in analysis of sentence meaning structure, focusing on the Abstract Meaning Representation (AMR; Banarescu et al. 2013) parsing formalism, which provides rich graphical representations of sentence meaning structure while abstracting away from surface forms. We compare models' analysis of this semantic structure across two settings: 1) direct production of AMR parses based on zero- and few-shot prompts, and 2) indirect partial reconstruction of AMR via metalinguistic natural language queries (e.g., \"Identify the primary event of this sentence, and the predicate corresponding to that event.\"). Across these settings, we find that models can re",
    "path": "papers/23/10/2310.17793.json",
    "total_tokens": 1015,
    "translated_title": "\"您是一位专家语言注释者\"：作为抽象意义表示分析器的LLMs的限制",
    "translated_abstract": "大型语言模型（LLMs）在语言使用方面显示出了令人惊讶的熟练度和流畅性。这是否意味着它们也已经获得了关于语言的深刻语言知识，以至于它们可以充当\"专家语言注释者\"？在本文中，我们考察了GPT-3、ChatGPT和GPT-4模型在句子意义结构分析中的成功和限制，重点关注了抽象意义表示（AMR；Banarescu等人，2013）分析形式主义，该形式主义提供了丰富的图形化句子意义结构表示，同时从表面形式中抽象出来。我们将模型在这种语义结构分析上的结果在两种情况下进行比较：1）基于零射和少学样本的AMR解析的直接生成，以及2）通过元语言自然语言查询（例如\"确定该句子的主要事件，以及与该事件对应的谓词\"）间接的部分重构AMR。在这些情况下，我们发现模型能够重新生成正确的AMR解析，但在复杂的句子结构或语义推理任务中仍存在局限性。",
    "tldr": "本文研究了大型语言模型在分析句子的意义结构方面的成功和限制，发现模型在生成和重构抽象意义表示（AMR）方面表现出一定的能力，但在复杂的句子结构或语义推理任务中存在局限性。",
    "en_tdlr": "This paper examines the successes and limitations of large language models (LLMs) in analyzing sentence meaning structure, focusing on Abstract Meaning Representation (AMR) parsing. The study finds that while the models show some capability in generating and reconstructing AMR, they still have limitations in handling complex sentence structures and semantic reasoning tasks."
}