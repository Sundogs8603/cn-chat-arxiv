{
    "title": "On the Language Encoder of Contrastive Cross-modal Models. (arXiv:2310.13267v1 [cs.CL])",
    "abstract": "Contrastive cross-modal models such as CLIP and CLAP aid various vision-language (VL) and audio-language (AL) tasks. However, there has been limited investigation of and improvement in their language encoder, which is the central component of encoding natural language descriptions of image/audio into vector representations. We extensively evaluate how unsupervised and supervised sentence embedding training affect language encoder quality and cross-modal task performance. In VL pretraining, we found that sentence embedding training language encoder quality and aids in cross-modal tasks, improving contrastive VL models such as CyCLIP. In contrast, AL pretraining benefits less from sentence embedding training, which may result from the limited amount of pretraining data. We analyze the representation spaces to understand the strengths of sentence embedding training, and find that it improves text-space uniformity, at the cost of decreased cross-modal alignment.",
    "link": "http://arxiv.org/abs/2310.13267",
    "context": "Title: On the Language Encoder of Contrastive Cross-modal Models. (arXiv:2310.13267v1 [cs.CL])\nAbstract: Contrastive cross-modal models such as CLIP and CLAP aid various vision-language (VL) and audio-language (AL) tasks. However, there has been limited investigation of and improvement in their language encoder, which is the central component of encoding natural language descriptions of image/audio into vector representations. We extensively evaluate how unsupervised and supervised sentence embedding training affect language encoder quality and cross-modal task performance. In VL pretraining, we found that sentence embedding training language encoder quality and aids in cross-modal tasks, improving contrastive VL models such as CyCLIP. In contrast, AL pretraining benefits less from sentence embedding training, which may result from the limited amount of pretraining data. We analyze the representation spaces to understand the strengths of sentence embedding training, and find that it improves text-space uniformity, at the cost of decreased cross-modal alignment.",
    "path": "papers/23/10/2310.13267.json",
    "total_tokens": 998,
    "translated_title": "关于对比跨模态模型的语言编码器的研究",
    "translated_abstract": "对比跨模态模型如CLIP和CLAP在各种视觉语言和音频语言任务中发挥作用。然而，对它们的语言编码器的研究和改进还很有限，而语言编码器是将图像/音频的自然语言描述编码成向量表示的核心组件。我们广泛评估了无监督和监督的句子嵌入训练对语言编码器质量和跨模态任务性能的影响。在视觉语言预训练中，我们发现句子嵌入训练提高了语言编码器质量，并有助于跨模态任务，改进了诸如CyCLIP等对比视觉语言模型。相比之下，音频语言预训练对句子嵌入训练的效益较小，可能是由于预训练数据量有限的原因。我们分析了表示空间，以了解句子嵌入训练的优势，并发现它改善了文本空间的均匀性，但代价是降低了跨模态对齐度。",
    "tldr": "本研究探究了对比跨模态模型中的语言编码器，并发现在视觉语言任务中，句子嵌入训练提高了语言编码器的质量并改善了跨模态任务的性能。而在音频语言任务中，句子嵌入训练效果较小。另外，句子嵌入训练改善了文本空间的均匀性，但降低了跨模态对齐度。",
    "en_tdlr": "This study investigates the language encoder of contrastive cross-modal models and finds that sentence embedding training improves the quality of the language encoder and enhances the performance of cross-modal tasks in vision-language tasks. However, the benefits in audio-language tasks are limited. Additionally, sentence embedding training improves the uniformity of the text space but decreases cross-modal alignment."
}