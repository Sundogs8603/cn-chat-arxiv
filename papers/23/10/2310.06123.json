{
    "title": "Text-driven Prompt Generation for Vision-Language Models in Federated Learning. (arXiv:2310.06123v1 [cs.CV])",
    "abstract": "Prompt learning for vision-language models, e.g., CoOp, has shown great success in adapting CLIP to different downstream tasks, making it a promising solution for federated learning due to computational reasons. Existing prompt learning techniques replace hand-crafted text prompts with learned vectors that offer improvements on seen classes, but struggle to generalize to unseen classes. Our work addresses this challenge by proposing Federated Text-driven Prompt Generation (FedTPG), which learns a unified prompt generation network across multiple remote clients in a scalable manner. The prompt generation network is conditioned on task-related text input, thus is context-aware, making it suitable to generalize for both seen and unseen classes. Our comprehensive empirical evaluations on nine diverse image classification datasets show that our method is superior to existing federated prompt learning methods, that achieve overall better generalization on both seen and unseen classes and is ",
    "link": "http://arxiv.org/abs/2310.06123",
    "context": "Title: Text-driven Prompt Generation for Vision-Language Models in Federated Learning. (arXiv:2310.06123v1 [cs.CV])\nAbstract: Prompt learning for vision-language models, e.g., CoOp, has shown great success in adapting CLIP to different downstream tasks, making it a promising solution for federated learning due to computational reasons. Existing prompt learning techniques replace hand-crafted text prompts with learned vectors that offer improvements on seen classes, but struggle to generalize to unseen classes. Our work addresses this challenge by proposing Federated Text-driven Prompt Generation (FedTPG), which learns a unified prompt generation network across multiple remote clients in a scalable manner. The prompt generation network is conditioned on task-related text input, thus is context-aware, making it suitable to generalize for both seen and unseen classes. Our comprehensive empirical evaluations on nine diverse image classification datasets show that our method is superior to existing federated prompt learning methods, that achieve overall better generalization on both seen and unseen classes and is ",
    "path": "papers/23/10/2310.06123.json",
    "total_tokens": 926,
    "translated_title": "文本驱动的视觉-语言模型在联邦学习中的提示生成",
    "translated_abstract": "视觉-语言模型的提示学习，例如CoOp，在适应不同的下游任务中取得了巨大的成功，这使得它成为联邦学习的一种有前景的解决方案，因为考虑到计算方面的原因。现有的提示学习技术用学习的向量替换手工制作的文本提示，在已知类别上取得了改进，但在未知类别上难以泛化。我们的工作通过提出联邦文本驱动的提示生成（FedTPG）来解决这一挑战，该方法能够以可扩展的方式在多个远程客户端上学习统一的提示生成网络。提示生成网络以任务相关的文本输入为条件，因此具有上下文感知性，适合泛化到已知和未知类别。我们对九个不同的图像分类数据集进行了全面的实证评估，结果表明，我们的方法优于现有的联邦提示学习方法，对已知和未知类别的总体泛化能力更好。",
    "tldr": "本论文提出了一种联邦文本驱动的提示生成方法（FedTPG），通过在多个远程客户端上学习统一的提示生成网络，实现了视觉-语言模型的泛化。实证评估表明，该方法在已知和未知类别上的泛化能力优于现有的联邦提示学习方法。",
    "en_tdlr": "This paper proposes a Federated Text-driven Prompt Generation (FedTPG) method, which learns a unified prompt generation network across multiple remote clients, to achieve the generalization of vision-language models. Empirical evaluations show that this method outperforms existing federated prompt learning methods in terms of generalization on both seen and unseen classes."
}