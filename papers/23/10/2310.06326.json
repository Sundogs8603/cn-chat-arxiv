{
    "title": "I2SRM: Intra- and Inter-Sample Relationship Modeling for Multimodal Information Extraction. (arXiv:2310.06326v1 [cs.AI])",
    "abstract": "Multimodal information extraction is attracting research attention nowadays, which requires aggregating representations from different modalities. In this paper, we present the Intra- and Inter-Sample Relationship Modeling (I2SRM) method for this task, which contains two modules. Firstly, the intra-sample relationship modeling module operates on a single sample and aims to learn effective representations. Embeddings from textual and visual modalities are shifted to bridge the modality gap caused by distinct pre-trained language and image models. Secondly, the inter-sample relationship modeling module considers relationships among multiple samples and focuses on capturing the interactions. An AttnMixup strategy is proposed, which not only enables collaboration among samples but also augments data to improve generalization. We conduct extensive experiments on the multimodal named entity recognition datasets Twitter-2015 and Twitter-2017, and the multimodal relation extraction dataset MNR",
    "link": "http://arxiv.org/abs/2310.06326",
    "context": "Title: I2SRM: Intra- and Inter-Sample Relationship Modeling for Multimodal Information Extraction. (arXiv:2310.06326v1 [cs.AI])\nAbstract: Multimodal information extraction is attracting research attention nowadays, which requires aggregating representations from different modalities. In this paper, we present the Intra- and Inter-Sample Relationship Modeling (I2SRM) method for this task, which contains two modules. Firstly, the intra-sample relationship modeling module operates on a single sample and aims to learn effective representations. Embeddings from textual and visual modalities are shifted to bridge the modality gap caused by distinct pre-trained language and image models. Secondly, the inter-sample relationship modeling module considers relationships among multiple samples and focuses on capturing the interactions. An AttnMixup strategy is proposed, which not only enables collaboration among samples but also augments data to improve generalization. We conduct extensive experiments on the multimodal named entity recognition datasets Twitter-2015 and Twitter-2017, and the multimodal relation extraction dataset MNR",
    "path": "papers/23/10/2310.06326.json",
    "total_tokens": 882,
    "translated_title": "I2SRM：用于多模态信息提取的样本内外关系建模",
    "translated_abstract": "多模态信息提取如今受到研究重视，它需要聚合来自不同模态的表示。本文提出了用于该任务的样本内外关系建模（I2SRM）方法，其中包含两个模块。首先，样本内关系建模模块作用于单个样本，旨在学习有效的表示。文本和视觉模态的嵌入被转换，以弥合不同预训练语言和图像模型引起的模态差异。其次，样本间关系建模模块考虑了多个样本之间的关系，专注于捕捉交互作用。提出了一种AttnMixup策略，不仅能够使样本之间协作，还能增加数据以提高泛化性能。我们对多模态命名实体识别数据集Twitter-2015、Twitter-2017和多模态关系抽取数据集MNR进行了大量实验。",
    "tldr": "本文提出了I2SRM方法，它通过样本内关系建模和样本间关系建模来解决多模态信息提取问题。通过转换嵌入表示、捕捉交互作用和引入AttnMixup策略，该方法在多个数据集上取得了良好的性能。",
    "en_tdlr": "This paper presents the I2SRM method to address the problem of multimodal information extraction through intra-sample and inter-sample relationship modeling. By transforming embedding representations, capturing interactions, and introducing the AttnMixup strategy, the method achieves good performance on multiple datasets."
}