{
    "title": "XIMAGENET-12: An Explainable AI Benchmark Dataset for Model Robustness Evaluation. (arXiv:2310.08182v1 [cs.CV])",
    "abstract": "The lack of standardized robustness metrics and the widespread reliance on numerous unrelated benchmark datasets for testing have created a gap between academically validated robust models and their often problematic practical adoption. To address this, we introduce XIMAGENET-12, an explainable benchmark dataset with over 200K images and 15,600 manual semantic annotations. Covering 12 categories from ImageNet to represent objects commonly encountered in practical life and simulating six diverse scenarios, including overexposure, blurring, color changing, etc., we further propose a novel robustness criterion that extends beyond model generation ability assessment. This benchmark dataset, along with related code, is available at https://sites.google.com/view/ximagenet-12/home. Researchers and practitioners can leverage this resource to evaluate the robustness of their visual models under challenging conditions and ultimately benefit from the demands of practical computer vision systems.",
    "link": "http://arxiv.org/abs/2310.08182",
    "context": "Title: XIMAGENET-12: An Explainable AI Benchmark Dataset for Model Robustness Evaluation. (arXiv:2310.08182v1 [cs.CV])\nAbstract: The lack of standardized robustness metrics and the widespread reliance on numerous unrelated benchmark datasets for testing have created a gap between academically validated robust models and their often problematic practical adoption. To address this, we introduce XIMAGENET-12, an explainable benchmark dataset with over 200K images and 15,600 manual semantic annotations. Covering 12 categories from ImageNet to represent objects commonly encountered in practical life and simulating six diverse scenarios, including overexposure, blurring, color changing, etc., we further propose a novel robustness criterion that extends beyond model generation ability assessment. This benchmark dataset, along with related code, is available at https://sites.google.com/view/ximagenet-12/home. Researchers and practitioners can leverage this resource to evaluate the robustness of their visual models under challenging conditions and ultimately benefit from the demands of practical computer vision systems.",
    "path": "papers/23/10/2310.08182.json",
    "total_tokens": 951,
    "translated_title": "XIMAGENET-12：一种可解释的AI基准数据集，用于模型的稳健性评估",
    "translated_abstract": "缺乏标准化的稳健性评估指标以及广泛依赖各种无关的基准数据集的测试方法，导致学术验证的稳健模型与实际应用中存在的问题之间存在差距。为了解决这个问题，我们引入了XIMAGENET-12，一个可解释的基准数据集，包含超过200,000张图像和15,600个手动语义注释。该数据集涵盖了ImageNet的12个类别，以代表在实际生活中常见的物体，并模拟了六个不同的场景，包括过曝、模糊、颜色变化等。我们进一步提出了一种超越模型生成能力评估的新的稳健性准则。该基准数据集以及相关代码可在https://sites.google.com/view/ximagenet-12/home获取。研究人员和实践者可以利用这一资源，在具有挑战性条件下评估他们的视觉模型的稳健性，从而从实际计算机视觉系统的需求中获益。",
    "tldr": "XIMAGENET-12是一个可解释的AI基准数据集，包含12个常见物体类别的超过200,000张图像和15,600个手动语义注释。它通过模拟六个不同的场景，提出了一种超越模型生成能力评估的新的稳健性准则。",
    "en_tdlr": "XIMAGENET-12 is an explainable AI benchmark dataset with over 200,000 images and 15,600 manual semantic annotations covering 12 common object categories. It introduces a novel robustness criterion that extends beyond model generation ability assessment by simulating six different scenarios."
}