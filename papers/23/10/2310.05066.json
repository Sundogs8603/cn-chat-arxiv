{
    "title": "Guideline Learning for In-context Information Extraction. (arXiv:2310.05066v2 [cs.CL] UPDATED)",
    "abstract": "Large language models (LLMs) can perform a new task by merely conditioning on task instructions and a few input-output examples, without optimizing any parameters. This is called In-Context Learning (ICL). In-context Information Extraction (IE) has recently garnered attention in the research community. However, the performance of In-context IE generally lags behind the state-of-the-art supervised expert models. We highlight a key reason for this shortfall: underspecified task description. The limited-length context struggles to thoroughly express the intricate IE task instructions and various edge cases, leading to misalignment in task comprehension with humans. In this paper, we propose a Guideline Learning (GL) framework for In-context IE which reflectively learns and follows guidelines. During the learning phrase, GL automatically synthesizes a set of guidelines based on a few error cases, and during inference, GL retrieves helpful guidelines for better ICL. Moreover, we propose a s",
    "link": "http://arxiv.org/abs/2310.05066",
    "context": "Title: Guideline Learning for In-context Information Extraction. (arXiv:2310.05066v2 [cs.CL] UPDATED)\nAbstract: Large language models (LLMs) can perform a new task by merely conditioning on task instructions and a few input-output examples, without optimizing any parameters. This is called In-Context Learning (ICL). In-context Information Extraction (IE) has recently garnered attention in the research community. However, the performance of In-context IE generally lags behind the state-of-the-art supervised expert models. We highlight a key reason for this shortfall: underspecified task description. The limited-length context struggles to thoroughly express the intricate IE task instructions and various edge cases, leading to misalignment in task comprehension with humans. In this paper, we propose a Guideline Learning (GL) framework for In-context IE which reflectively learns and follows guidelines. During the learning phrase, GL automatically synthesizes a set of guidelines based on a few error cases, and during inference, GL retrieves helpful guidelines for better ICL. Moreover, we propose a s",
    "path": "papers/23/10/2310.05066.json",
    "total_tokens": 826,
    "translated_title": "指南学习用于上下文信息抽取",
    "translated_abstract": "大型语言模型(LLMs)可以通过仅依赖任务指令和少量输入输出示例来执行新任务，而无需优化任何参数。这被称为上下文学习(ICL)。最近，上下文信息抽取(IE)在研究界引起了关注。然而，上下文IE的性能通常落后于最先进的有监督专家模型。我们强调了一个主要原因: 任务描述不明确。有限长度的上下文难以充分表达复杂的IE任务指令和各种边界情况，导致任务理解与人类出现不匹配。本文提出了一种用于上下文IE的指南学习(GL)框架，其反思性地学习并遵循指南。在学习阶段，GL基于少量错误案例自动合成一组指南，在推理阶段，GL检索有用的指南以实现更好的ICL。此外，我们提出了一种s",
    "tldr": "本文提出了一种用于上下文信息抽取的指南学习框架，通过反思性地学习和遵循指南，以更好地理解任务并提高性能。"
}