{
    "title": "Explaining by Imitating: Understanding Decisions by Interpretable Policy Learning. (arXiv:2310.19831v1 [stat.ML])",
    "abstract": "Understanding human behavior from observed data is critical for transparency and accountability in decision-making. Consider real-world settings such as healthcare, in which modeling a decision-maker's policy is challenging -- with no access to underlying states, no knowledge of environment dynamics, and no allowance for live experimentation. We desire learning a data-driven representation of decision-making behavior that (1) inheres transparency by design, (2) accommodates partial observability, and (3) operates completely offline. To satisfy these key criteria, we propose a novel model-based Bayesian method for interpretable policy learning (\"Interpole\") that jointly estimates an agent's (possibly biased) belief-update process together with their (possibly suboptimal) belief-action mapping. Through experiments on both simulated and real-world data for the problem of Alzheimer's disease diagnosis, we illustrate the potential of our approach as an investigative device for auditing, qua",
    "link": "http://arxiv.org/abs/2310.19831",
    "context": "Title: Explaining by Imitating: Understanding Decisions by Interpretable Policy Learning. (arXiv:2310.19831v1 [stat.ML])\nAbstract: Understanding human behavior from observed data is critical for transparency and accountability in decision-making. Consider real-world settings such as healthcare, in which modeling a decision-maker's policy is challenging -- with no access to underlying states, no knowledge of environment dynamics, and no allowance for live experimentation. We desire learning a data-driven representation of decision-making behavior that (1) inheres transparency by design, (2) accommodates partial observability, and (3) operates completely offline. To satisfy these key criteria, we propose a novel model-based Bayesian method for interpretable policy learning (\"Interpole\") that jointly estimates an agent's (possibly biased) belief-update process together with their (possibly suboptimal) belief-action mapping. Through experiments on both simulated and real-world data for the problem of Alzheimer's disease diagnosis, we illustrate the potential of our approach as an investigative device for auditing, qua",
    "path": "papers/23/10/2310.19831.json",
    "total_tokens": 964,
    "translated_title": "模仿解释：通过可解释的策略学习理解决策",
    "translated_abstract": "从观察数据中理解人类行为对于透明度和决策的问责是至关重要的。在现实世界中，如医疗保健领域，建模决策者的策略具有挑战性——没有访问底层状态的权限，没有了解环境动态的知识，也没有进行实时实验的容错能力。我们希望学习一个数据驱动的决策行为表示，它具有（1）设计上的透明度，（2）适应部分可观测性，（3）完全离线运行。为了满足这些关键条件，我们提出了一种新颖的基于模型的贝叶斯方法来进行可解释的策略学习（\"Interpole\"），它同时估计一个代理人的（可能有偏差的）置信更新过程以及他们（可能次优的）信念动作映射。通过对模拟和真实世界的阿尔茨海默病诊断问题的实验，我们展示了我们的方法作为审计和分析工具的潜力。",
    "tldr": "本文提出了一种新的模型基于的贝叶斯方法，通过可解释的策略学习来理解决策，该方法具有透明度、适应部分可观测性和完全离线运行的特点。通过对阿尔茨海默病诊断问题的实验验证，展示了该方法作为审计和分析工具的潜力。"
}