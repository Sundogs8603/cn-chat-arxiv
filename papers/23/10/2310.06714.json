{
    "title": "Exploring Memorization in Fine-tuned Language Models",
    "abstract": "arXiv:2310.06714v2 Announce Type: replace  Abstract: Large language models (LLMs) have shown great capabilities in various tasks but also exhibited memorization of training data, raising tremendous privacy and copyright concerns. While prior works have studied memorization during pre-training, the exploration of memorization during fine-tuning is rather limited. Compared to pre-training, fine-tuning typically involves more sensitive data and diverse objectives, thus may bring distinct privacy risks and unique memorization behaviors. In this work, we conduct the first comprehensive analysis to explore language models' (LMs) memorization during fine-tuning across tasks. Our studies with open-sourced and our own fine-tuned LMs across various tasks indicate that memorization presents a strong disparity among different fine-tuning tasks. We provide an intuitive explanation of this task disparity via sparse coding theory and unveil a strong correlation between memorization and attention scor",
    "link": "https://arxiv.org/abs/2310.06714",
    "context": "Title: Exploring Memorization in Fine-tuned Language Models\nAbstract: arXiv:2310.06714v2 Announce Type: replace  Abstract: Large language models (LLMs) have shown great capabilities in various tasks but also exhibited memorization of training data, raising tremendous privacy and copyright concerns. While prior works have studied memorization during pre-training, the exploration of memorization during fine-tuning is rather limited. Compared to pre-training, fine-tuning typically involves more sensitive data and diverse objectives, thus may bring distinct privacy risks and unique memorization behaviors. In this work, we conduct the first comprehensive analysis to explore language models' (LMs) memorization during fine-tuning across tasks. Our studies with open-sourced and our own fine-tuned LMs across various tasks indicate that memorization presents a strong disparity among different fine-tuning tasks. We provide an intuitive explanation of this task disparity via sparse coding theory and unveil a strong correlation between memorization and attention scor",
    "path": "papers/23/10/2310.06714.json",
    "total_tokens": 780,
    "translated_title": "探索微调语言模型中的记忆能力",
    "translated_abstract": "大型语言模型（LLMs）展现出在各种任务中的巨大能力，但同时也表现出对训练数据的记忆，引起了巨大的隐私和版权担忧。 在此工作中，我们进行了首次全面分析，探讨了在各种任务中微调语言模型（LMs）时的记忆现象。 我们使用开源和我们自己的微调LMs进行了研究，结果表明在不同微调任务中，记忆呈现出较强的差异性。 我们通过稀疏编码理论提供了对这种任务差异性的直观解释，并揭示了记忆和注意力分数之间的强相关性。",
    "tldr": "在微调语言模型过程中，该研究首次全面分析了不同任务中模型的记忆现象，发现了记忆在各种微调任务中表现出显著的差异，并通过稀疏编码理论解释了这种任务差异性。",
    "en_tdlr": "This study comprehensively analyzes the memorization phenomenon in models across different tasks during fine-tuning, revealing significant disparities in memorization among various fine-tuning tasks and providing an explanation through sparse coding theory."
}