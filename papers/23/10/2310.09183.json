{
    "title": "PRIOR: Personalized Prior for Reactivating the Information Overlooked in Federated Learning. (arXiv:2310.09183v1 [cs.LG])",
    "abstract": "Classical federated learning (FL) enables training machine learning models without sharing data for privacy preservation, but heterogeneous data characteristic degrades the performance of the localized model. Personalized FL (PFL) addresses this by synthesizing personalized models from a global model via training on local data. Such a global model may overlook the specific information that the clients have been sampled. In this paper, we propose a novel scheme to inject personalized prior knowledge into the global model in each client, which attempts to mitigate the introduced incomplete information problem in PFL. At the heart of our proposed approach is a framework, the PFL with Bregman Divergence (pFedBreD), decoupling the personalized prior from the local objective function regularized by Bregman divergence for greater adaptability in personalized scenarios. We also relax the mirror descent (RMD) to extract the prior explicitly to provide optional strategies. Additionally, our pFed",
    "link": "http://arxiv.org/abs/2310.09183",
    "context": "Title: PRIOR: Personalized Prior for Reactivating the Information Overlooked in Federated Learning. (arXiv:2310.09183v1 [cs.LG])\nAbstract: Classical federated learning (FL) enables training machine learning models without sharing data for privacy preservation, but heterogeneous data characteristic degrades the performance of the localized model. Personalized FL (PFL) addresses this by synthesizing personalized models from a global model via training on local data. Such a global model may overlook the specific information that the clients have been sampled. In this paper, we propose a novel scheme to inject personalized prior knowledge into the global model in each client, which attempts to mitigate the introduced incomplete information problem in PFL. At the heart of our proposed approach is a framework, the PFL with Bregman Divergence (pFedBreD), decoupling the personalized prior from the local objective function regularized by Bregman divergence for greater adaptability in personalized scenarios. We also relax the mirror descent (RMD) to extract the prior explicitly to provide optional strategies. Additionally, our pFed",
    "path": "papers/23/10/2310.09183.json",
    "total_tokens": 963,
    "translated_title": "PRIOR: 个性化先验用于重新激活联邦学习中被忽视的信息",
    "translated_abstract": "传统的联邦学习（FL）通过在保护隐私的前提下训练机器学习模型，而异质数据特性降低了局部模型的性能。个性化联邦学习（PFL）通过从全局模型中合成个性化模型来解决这个问题，在本地数据上进行训练。然而，这样的全局模型可能忽视了客户端被采样的特定信息。本文提出了一种新的方案，通过将个性化先验知识注入到每个客户端的全局模型中，试图减轻PFL中引入的不完整信息问题。我们提出的方法的核心是一种框架，即带Bregman散度（pFedBreD）的PFL，通过在个性化场景中使用Bregman散度正则化的本地目标函数，使个性化先验与之解耦，具有更强的适应性。我们还放松了镜像下降（RMD），以显式地提取先验知识，提供可选择的策略。",
    "tldr": "本研究提出了一种名为PRIOR的个性化先验方案，用于解决个性化联邦学习中由于全局模型忽视特定信息而导致的不完整信息问题。该方案使用带Bregman散度的PFL框架将个性化先验与本地目标函数解耦，以提高适应性和性能。"
}