{
    "title": "Taming Gradient Variance in Federated Learning with Networked Control Variates. (arXiv:2310.17200v1 [cs.LG])",
    "abstract": "Federated learning, a decentralized approach to machine learning, faces significant challenges such as extensive communication overheads, slow convergence, and unstable improvements. These challenges primarily stem from the gradient variance due to heterogeneous client data distributions. To address this, we introduce a novel Networked Control Variates (FedNCV) framework for Federated Learning. We adopt the REINFORCE Leave-One-Out (RLOO) as a fundamental control variate unit in the FedNCV framework, implemented at both client and server levels. At the client level, the RLOO control variate is employed to optimize local gradient updates, mitigating the variance introduced by data samples. Once relayed to the server, the RLOO-based estimator further provides an unbiased and low-variance aggregated gradient, leading to robust global updates. This dual-side application is formalized as a linear combination of composite control variates. We provide a mathematical expression capturing this i",
    "link": "http://arxiv.org/abs/2310.17200",
    "context": "Title: Taming Gradient Variance in Federated Learning with Networked Control Variates. (arXiv:2310.17200v1 [cs.LG])\nAbstract: Federated learning, a decentralized approach to machine learning, faces significant challenges such as extensive communication overheads, slow convergence, and unstable improvements. These challenges primarily stem from the gradient variance due to heterogeneous client data distributions. To address this, we introduce a novel Networked Control Variates (FedNCV) framework for Federated Learning. We adopt the REINFORCE Leave-One-Out (RLOO) as a fundamental control variate unit in the FedNCV framework, implemented at both client and server levels. At the client level, the RLOO control variate is employed to optimize local gradient updates, mitigating the variance introduced by data samples. Once relayed to the server, the RLOO-based estimator further provides an unbiased and low-variance aggregated gradient, leading to robust global updates. This dual-side application is formalized as a linear combination of composite control variates. We provide a mathematical expression capturing this i",
    "path": "papers/23/10/2310.17200.json",
    "total_tokens": 988,
    "translated_title": "用网络控制变量驯服联邦学习中的梯度方差",
    "translated_abstract": "联邦学习是一种分散式的机器学习方法，面临着诸如沟通开销大、收敛速度慢和改进不稳定等重要挑战。这些挑战主要源于由异构客户端数据分布引起的梯度方差。为了解决这个问题，我们引入了一种新颖的网络控制变量（FedNCV）框架来进行联邦学习。我们在FedNCV框架的客户端和服务器级别都采用REINFORCE Leave-One-Out（RLOO）作为基本控制变量单元。在客户端级别，RLOO控制变量用于优化本地梯度更新，减轻数据样本引入的方差。一旦传输到服务器，基于RLOO的估计量进一步提供了无偏和低方差的聚合梯度，实现了稳健的全局更新。这种双侧应用被形式化为组合控制变量的线性组合。我们提供了一个数学公式来捕捉这个过程。",
    "tldr": "本论文提出了一种名为FedNCV的新型框架，用于解决联邦学习中梯度方差的问题。通过在客户端和服务器级别实现REINFORCE Leave-One-Out (RLOO)作为控制变量单元，优化了本地梯度更新并提供了无偏和低方差的聚合梯度，实现了稳健的全局更新。"
}