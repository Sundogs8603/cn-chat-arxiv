{
    "title": "SALSA: Semantically-Aware Latent Space Autoencoder. (arXiv:2310.02744v1 [cs.LG])",
    "abstract": "In deep learning for drug discovery, chemical data are often represented as simplified molecular-input line-entry system (SMILES) sequences which allow for straightforward implementation of natural language processing methodologies, one being the sequence-to-sequence autoencoder. However, we observe that training an autoencoder solely on SMILES is insufficient to learn molecular representations that are semantically meaningful, where semantics are defined by the structural (graph-to-graph) similarities between molecules. We demonstrate by example that autoencoders may map structurally similar molecules to distant codes, resulting in an incoherent latent space that does not respect the structural similarities between molecules. To address this shortcoming we propose Semantically-Aware Latent Space Autoencoder (SALSA), a transformer-autoencoder modified with a contrastive task, tailored specifically to learn graph-to-graph similarity between molecules. Formally, the contrastive objective",
    "link": "http://arxiv.org/abs/2310.02744",
    "context": "Title: SALSA: Semantically-Aware Latent Space Autoencoder. (arXiv:2310.02744v1 [cs.LG])\nAbstract: In deep learning for drug discovery, chemical data are often represented as simplified molecular-input line-entry system (SMILES) sequences which allow for straightforward implementation of natural language processing methodologies, one being the sequence-to-sequence autoencoder. However, we observe that training an autoencoder solely on SMILES is insufficient to learn molecular representations that are semantically meaningful, where semantics are defined by the structural (graph-to-graph) similarities between molecules. We demonstrate by example that autoencoders may map structurally similar molecules to distant codes, resulting in an incoherent latent space that does not respect the structural similarities between molecules. To address this shortcoming we propose Semantically-Aware Latent Space Autoencoder (SALSA), a transformer-autoencoder modified with a contrastive task, tailored specifically to learn graph-to-graph similarity between molecules. Formally, the contrastive objective",
    "path": "papers/23/10/2310.02744.json",
    "total_tokens": 839,
    "translated_title": "SALSA: 语义感知的潜空间自编码器",
    "translated_abstract": "在深度学习中应用于药物发现的研究中，化学数据通常以简化的分子输入线条输入系统 (SMILES) 序列表示，这可以方便地实施自然语言处理方法之一，即序列到序列自编码器。然而，我们观察到仅仅在SMILES上训练自编码器是不足以学习到语义上有意义的分子表示的。在这里，语义通过分子之间的结构（图对图）相似性来定义。我们通过示例证明，自编码器可能会将结构相似的分子映射到相距较远的编码，导致一个不一致的潜空间，不尊重分子之间的结构相似性。为了解决这个问题，我们提出了Semantically-Aware Latent Space Autoencoder (SALSA)，这是一个经过修改的变换器自编码器，用于学习分子之间的图对图相似性。形式上，对比目标是",
    "tldr": "SALSA提出了一种语义感知的潜空间自编码器（SALSA），通过在自编码器中引入对比任务，专门设计用于学习分子之间的图对图相似性。",
    "en_tdlr": "SALSA proposes a semantically-aware latent space autoencoder (SALSA), which introduces a contrastive task into the autoencoder, specifically designed to learn graph-to-graph similarity between molecules."
}