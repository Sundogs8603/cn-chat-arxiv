{
    "title": "Provably Fast Convergence of Independent Natural Policy Gradient for Markov Potential Games. (arXiv:2310.09727v2 [cs.LG] UPDATED)",
    "abstract": "This work studies an independent natural policy gradient (NPG) algorithm for the multi-agent reinforcement learning problem in Markov potential games. It is shown that, under mild technical assumptions and the introduction of the \\textit{suboptimality gap}, the independent NPG method with an oracle providing exact policy evaluation asymptotically reaches an $\\epsilon$-Nash Equilibrium (NE) within $\\mathcal{O}(1/\\epsilon)$ iterations. This improves upon the previous best result of $\\mathcal{O}(1/\\epsilon^2)$ iterations and is of the same order, $\\mathcal{O}(1/\\epsilon)$, that is achievable for the single-agent case. Empirical results for a synthetic potential game and a congestion game are presented to verify the theoretical bounds.",
    "link": "http://arxiv.org/abs/2310.09727",
    "context": "Title: Provably Fast Convergence of Independent Natural Policy Gradient for Markov Potential Games. (arXiv:2310.09727v2 [cs.LG] UPDATED)\nAbstract: This work studies an independent natural policy gradient (NPG) algorithm for the multi-agent reinforcement learning problem in Markov potential games. It is shown that, under mild technical assumptions and the introduction of the \\textit{suboptimality gap}, the independent NPG method with an oracle providing exact policy evaluation asymptotically reaches an $\\epsilon$-Nash Equilibrium (NE) within $\\mathcal{O}(1/\\epsilon)$ iterations. This improves upon the previous best result of $\\mathcal{O}(1/\\epsilon^2)$ iterations and is of the same order, $\\mathcal{O}(1/\\epsilon)$, that is achievable for the single-agent case. Empirical results for a synthetic potential game and a congestion game are presented to verify the theoretical bounds.",
    "path": "papers/23/10/2310.09727.json",
    "total_tokens": 812,
    "translated_title": "Provably Fast Convergence of Independent Natural Policy Gradient for Markov Potential Games.（arXiv：2310.09727v2[cs.LG]已更新）",
    "translated_abstract": "本文研究了马尔可夫潜在博弈中独立自然策略梯度（NPG）算法的多智能体强化学习问题。研究结果表明，在一些技术假设和引入“次优间隙”的条件下，具有提供精确策略评估的预言机的独立NPG方法渐近地在$\\mathcal{O}(1/ \\epsilon)$次迭代内达到$\\epsilon$-Nash均衡（NE）。这改进了之前最好结果$\\mathcal{O}(1/ \\epsilon^2)$次迭代，并且与单智能体情况下可达到的$\\mathcal{O}(1/ \\epsilon)$次迭代具有相同的数量级。通过合成潜在博弈和拥塞博弈的实证结果验证了理论界限。",
    "tldr": "本文研究了马尔可夫潜在博弈中独立自然策略梯度算法的多智能体强化学习问题，通过引入“次优间隙”的条件和精确策略评估的预言机，在$\\mathcal{O}(1/ \\epsilon)$次迭代内达到$\\epsilon$-Nash均衡。"
}