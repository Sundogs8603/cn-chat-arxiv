{
    "title": "Measuring Feature Sparsity in Language Models. (arXiv:2310.07837v1 [cs.LG])",
    "abstract": "Recent works have proposed that activations in language models can be modelled as sparse linear combinations of vectors corresponding to features of input text. Under this assumption, these works aimed to reconstruct feature directions using sparse coding. We develop metrics to assess the success of these sparse coding techniques and test the validity of the linearity and sparsity assumptions. We show our metrics can predict the level of sparsity on synthetic sparse linear activations, and can distinguish between sparse linear data and several other distributions. We use our metrics to measure levels of sparsity in several language models. We find evidence that language model activations can be accurately modelled by sparse linear combinations of features, significantly more so than control datasets. We also show that model activations appear to be sparsest in the first and final layers.",
    "link": "http://arxiv.org/abs/2310.07837",
    "context": "Title: Measuring Feature Sparsity in Language Models. (arXiv:2310.07837v1 [cs.LG])\nAbstract: Recent works have proposed that activations in language models can be modelled as sparse linear combinations of vectors corresponding to features of input text. Under this assumption, these works aimed to reconstruct feature directions using sparse coding. We develop metrics to assess the success of these sparse coding techniques and test the validity of the linearity and sparsity assumptions. We show our metrics can predict the level of sparsity on synthetic sparse linear activations, and can distinguish between sparse linear data and several other distributions. We use our metrics to measure levels of sparsity in several language models. We find evidence that language model activations can be accurately modelled by sparse linear combinations of features, significantly more so than control datasets. We also show that model activations appear to be sparsest in the first and final layers.",
    "path": "papers/23/10/2310.07837.json",
    "total_tokens": 886,
    "translated_title": "在语言模型中衡量特征稀疏性",
    "translated_abstract": "最近的研究提出，语言模型中的激活可以被建模为与输入文本特征对应的向量的稀疏线性组合。在这个假设下，这些研究旨在使用稀疏编码重构特征方向。我们开发了度量方法来评估这些稀疏编码技术的成功，并测试线性性和稀疏性假设的有效性。我们展示了我们的度量方法可以预测合成稀疏线性激活的稀疏程度，并能够区分稀疏线性数据和其他几种分布。我们使用我们的度量方法来衡量几个语言模型的稀疏程度。我们发现，与对照数据集相比，语言模型的激活可以准确地建模为特征的稀疏线性组合，并且在第一层和最后一层中呈最稀疏状态。",
    "tldr": "这项研究开发了度量方法来评估语言模型中特征稀疏性的成功，并测试了线性性和稀疏性假设的有效性。研究结果表明，语言模型的激活可以准确地建模为特征的稀疏线性组合，并且在第一层和最后一层中呈最稀疏状态。"
}