{
    "title": "Improving Factual Consistency for Knowledge-Grounded Dialogue Systems via Knowledge Enhancement and Alignment. (arXiv:2310.08372v2 [cs.CL] UPDATED)",
    "abstract": "Pretrained language models (PLMs) based knowledge-grounded dialogue systems are prone to generate responses that are factually inconsistent with the provided knowledge source. In such inconsistent responses, the dialogue models fail to accurately express the external knowledge they rely upon. Inspired by previous work which identified that feed-forward networks (FFNs) within Transformers are responsible for factual knowledge expressions, we investigate two methods to efficiently improve the factual expression capability {of FFNs} by knowledge enhancement and alignment respectively. We first propose \\textsc{K-Dial}, which {explicitly} introduces {extended FFNs in Transformers to enhance factual knowledge expressions} given the specific patterns of knowledge-grounded dialogue inputs. Additionally, we apply the reinforcement learning for factual consistency (RLFC) method to implicitly adjust FFNs' expressions in responses by aligning with gold knowledge for the factual consistency prefere",
    "link": "http://arxiv.org/abs/2310.08372",
    "context": "Title: Improving Factual Consistency for Knowledge-Grounded Dialogue Systems via Knowledge Enhancement and Alignment. (arXiv:2310.08372v2 [cs.CL] UPDATED)\nAbstract: Pretrained language models (PLMs) based knowledge-grounded dialogue systems are prone to generate responses that are factually inconsistent with the provided knowledge source. In such inconsistent responses, the dialogue models fail to accurately express the external knowledge they rely upon. Inspired by previous work which identified that feed-forward networks (FFNs) within Transformers are responsible for factual knowledge expressions, we investigate two methods to efficiently improve the factual expression capability {of FFNs} by knowledge enhancement and alignment respectively. We first propose \\textsc{K-Dial}, which {explicitly} introduces {extended FFNs in Transformers to enhance factual knowledge expressions} given the specific patterns of knowledge-grounded dialogue inputs. Additionally, we apply the reinforcement learning for factual consistency (RLFC) method to implicitly adjust FFNs' expressions in responses by aligning with gold knowledge for the factual consistency prefere",
    "path": "papers/23/10/2310.08372.json",
    "total_tokens": 834,
    "translated_title": "通过知识增强和对齐来提升基于知识的对话系统的事实一致性",
    "translated_abstract": "预训练语言模型（PLMs）基于知识的对话系统容易生成与提供的知识源事实不一致的回复。在这种不一致的回复中，对话模型无法准确表达其依赖的外部知识。受先前工作的启发，该工作发现变压器中的前馈网络（FFNs）负责事实知识的表达，因此我们通过知识增强和对齐两种方法，对FFNs的事实表达能力进行了高效改进。我们首先提出了K-Dial方法，通过引入变压器中的扩展FFNs以增强特定模式的知识对话输入的事实知识表达。此外，我们还通过强化学习方法对FFNs在回复中的表达进行了调整，以使其与事实一致的最优知识对齐。",
    "tldr": "该论文研究了通过知识增强和对齐两种方法来提高基于知识的对话系统的事实一致性，以解决生成与提供的知识源事实不一致的回复的问题。",
    "en_tdlr": "This paper investigates two methods, knowledge enhancement and alignment, to improve the factual consistency in knowledge-grounded dialogue systems, addressing the issue of generating responses that are inconsistent with the provided knowledge source."
}