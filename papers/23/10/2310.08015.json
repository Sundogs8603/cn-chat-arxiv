{
    "title": "Why Train More? Effective and Efficient Membership Inference via Memorization. (arXiv:2310.08015v1 [cs.LG])",
    "abstract": "Membership Inference Attacks (MIAs) aim to identify specific data samples within the private training dataset of machine learning models, leading to serious privacy violations and other sophisticated threats. Many practical black-box MIAs require query access to the data distribution (the same distribution where the private data is drawn) to train shadow models. By doing so, the adversary obtains models trained \"with\" or \"without\" samples drawn from the distribution, and analyzes the characteristics of the samples under consideration. The adversary is often required to train more than hundreds of shadow models to extract the signals needed for MIAs; this becomes the computational overhead of MIAs. In this paper, we propose that by strategically choosing the samples, MI adversaries can maximize their attack success while minimizing the number of shadow models. First, our motivational experiments suggest memorization as the key property explaining disparate sample vulnerability to MIAs. ",
    "link": "http://arxiv.org/abs/2310.08015",
    "context": "Title: Why Train More? Effective and Efficient Membership Inference via Memorization. (arXiv:2310.08015v1 [cs.LG])\nAbstract: Membership Inference Attacks (MIAs) aim to identify specific data samples within the private training dataset of machine learning models, leading to serious privacy violations and other sophisticated threats. Many practical black-box MIAs require query access to the data distribution (the same distribution where the private data is drawn) to train shadow models. By doing so, the adversary obtains models trained \"with\" or \"without\" samples drawn from the distribution, and analyzes the characteristics of the samples under consideration. The adversary is often required to train more than hundreds of shadow models to extract the signals needed for MIAs; this becomes the computational overhead of MIAs. In this paper, we propose that by strategically choosing the samples, MI adversaries can maximize their attack success while minimizing the number of shadow models. First, our motivational experiments suggest memorization as the key property explaining disparate sample vulnerability to MIAs. ",
    "path": "papers/23/10/2310.08015.json",
    "total_tokens": 765,
    "translated_title": "为什么要训练更多？通过记忆进行有效和高效的成员推断攻击。",
    "translated_abstract": "成员推断攻击（MIAs）旨在识别机器学习模型私有训练数据集中的特定数据样本，从而造成严重的隐私侵犯和其他复杂的威胁。许多实际的黑盒MIAs需要对数据分布进行查询访问（与私有数据绘制的相同分布），以训练影子模型。通过这样做，攻击者获得在数据分布中使用或不使用样本训练的模型，并分析所考虑样本的特征。攻击者通常需要训练超过数百个影子模型来提取MIAs所需的信号，这成为MIAs的计算开销。",
    "tldr": "本文通过策略性选择样本，最大化攻击成功并最小化影子模型的数量，从而提出了一种通过记忆进行有效和高效的成员推断攻击的方法。",
    "en_tdlr": "This paper proposes an effective and efficient membership inference attack method by strategically selecting samples and utilizing the property of memorization, which maximizes attack success while minimizing the number of shadow models needed."
}