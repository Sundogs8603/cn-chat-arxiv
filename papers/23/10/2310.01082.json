{
    "title": "Linear attention is (maybe) all you need (to understand transformer optimization)",
    "abstract": "arXiv:2310.01082v2 Announce Type: replace-cross  Abstract: Transformer training is notoriously difficult, requiring a careful design of optimizers and use of various heuristics. We make progress towards understanding the subtleties of training Transformers by carefully studying a simple yet canonical linearized shallow Transformer model. Specifically, we train linear Transformers to solve regression tasks, inspired by J.~von Oswald et al.~(ICML 2023), and K.~Ahn et al.~(NeurIPS 2023). Most importantly, we observe that our proposed linearized models can reproduce several prominent aspects of Transformer training dynamics. Consequently, the results obtained in this paper suggest that a simple linearized Transformer model could actually be a valuable, realistic abstraction for understanding Transformer optimization.",
    "link": "https://arxiv.org/abs/2310.01082",
    "context": "Title: Linear attention is (maybe) all you need (to understand transformer optimization)\nAbstract: arXiv:2310.01082v2 Announce Type: replace-cross  Abstract: Transformer training is notoriously difficult, requiring a careful design of optimizers and use of various heuristics. We make progress towards understanding the subtleties of training Transformers by carefully studying a simple yet canonical linearized shallow Transformer model. Specifically, we train linear Transformers to solve regression tasks, inspired by J.~von Oswald et al.~(ICML 2023), and K.~Ahn et al.~(NeurIPS 2023). Most importantly, we observe that our proposed linearized models can reproduce several prominent aspects of Transformer training dynamics. Consequently, the results obtained in this paper suggest that a simple linearized Transformer model could actually be a valuable, realistic abstraction for understanding Transformer optimization.",
    "path": "papers/23/10/2310.01082.json",
    "total_tokens": 757,
    "translated_title": "线性注意力可能就是理解Transformer优化的关键",
    "translated_abstract": "Transformer的训练因需要仔细设计优化器并使用各种启发式而变得困难。本文通过仔细研究一个简单但经典的线性化浅层Transformer模型，取得了解析Transformer训练细微之处的进展。具体来说，我们训练线性Transformer来解决回归任务，灵感来源于J. von Oswald等人（ICML 2023）和K. Ahn等人（NeurIPS 2023）。最重要的是，我们观察到我们提出的线性化模型能够重现Transformer训练动态的几个重要方面。因此，本文得到的结果表明，一个简单的线性化Transformer模型实际上可能是理解Transformer优化的有价值、现实的抽象。",
    "tldr": "研究者通过训练线性Transformer模型解决回归任务，发现这种简单的线性化模型能够重现Transformer训练动态的多个关键方面，表明线性注意力可能是理解Transformer优化的关键。",
    "en_tdlr": "Researchers found that training linear Transformer models to solve regression tasks can reproduce key aspects of Transformer training dynamics, suggesting that linear attention may be the key to understanding Transformer optimization."
}