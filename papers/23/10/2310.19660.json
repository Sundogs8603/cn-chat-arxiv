{
    "title": "Interpretable-by-Design Text Understanding with Iteratively Generated Concept Bottleneck",
    "abstract": "arXiv:2310.19660v2 Announce Type: replace  Abstract: Black-box deep neural networks excel in text classification, yet their application in high-stakes domains is hindered by their lack of interpretability. To address this, we propose Text Bottleneck Models (TBM), an intrinsically interpretable text classification framework that offers both global and local explanations. Rather than directly predicting the output label, TBM predicts categorical values for a sparse set of salient concepts and uses a linear layer over those concept values to produce the final prediction. These concepts can be automatically discovered and measured by a Large Language Model (LLM) without the need for human curation. Experiments on 12 diverse text understanding datasets demonstrate that TBM can rival the performance of black-box baselines such as few-shot GPT-4 and finetuned DeBERTa while falling short against finetuned GPT-3.5. Comprehensive human evaluation validates that TBM can generate high-quality conc",
    "link": "https://arxiv.org/abs/2310.19660",
    "context": "Title: Interpretable-by-Design Text Understanding with Iteratively Generated Concept Bottleneck\nAbstract: arXiv:2310.19660v2 Announce Type: replace  Abstract: Black-box deep neural networks excel in text classification, yet their application in high-stakes domains is hindered by their lack of interpretability. To address this, we propose Text Bottleneck Models (TBM), an intrinsically interpretable text classification framework that offers both global and local explanations. Rather than directly predicting the output label, TBM predicts categorical values for a sparse set of salient concepts and uses a linear layer over those concept values to produce the final prediction. These concepts can be automatically discovered and measured by a Large Language Model (LLM) without the need for human curation. Experiments on 12 diverse text understanding datasets demonstrate that TBM can rival the performance of black-box baselines such as few-shot GPT-4 and finetuned DeBERTa while falling short against finetuned GPT-3.5. Comprehensive human evaluation validates that TBM can generate high-quality conc",
    "path": "papers/23/10/2310.19660.json",
    "total_tokens": 898,
    "translated_title": "通过迭代生成的概念瓶颈实现设计可解释的文本理解",
    "translated_abstract": "arXiv:2310.19660v2 公告类型: 替换 摘要: 黑盒深度神经网络在文本分类方面表现出色，但它们在高风险领域的应用受到其缺乏可解释性的限制。为了解决这一问题，我们提出了文本瓶颈模型（TBM），这是一个固有可解释的文本分类框架，可以提供全局和局部解释。TBM不是直接预测输出标签，而是预测一组突出概念的分类值，并使用这些概念值上的线性层来生成最终预测。这些概念可以由大型语言模型（LLM）自动发现和衡量，无需人工筛选。对12个不同的文本理解数据集的实验表明，TBM可以与黑盒基准（例如少样本GPT-4和微调DeBERTa）的性能相媲美，但在与微调GPT-3.5的比较中表现不佳。全面的人类评估验证了TBM可以生成高质量的解释。",
    "tldr": "提出了一种文本瓶颈模型（TBM），通过预测一组突出概念的分类值来实现文本分类，从而在高风险领域提供全局和局部解释",
    "en_tdlr": "Introduced Text Bottleneck Models (TBM) that predict categorical values for a sparse set of salient concepts to achieve text classification, providing both global and local explanations in high-stakes domains."
}