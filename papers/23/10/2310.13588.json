{
    "title": "Simultaneous Machine Translation with Tailored Reference. (arXiv:2310.13588v1 [cs.CL])",
    "abstract": "Simultaneous machine translation (SiMT) generates translation while reading the whole source sentence. However, existing SiMT models are typically trained using the same reference disregarding the varying amounts of available source information at different latency. Training the model with ground-truth at low latency may introduce forced anticipations, whereas utilizing reference consistent with the source word order at high latency results in performance degradation. Consequently, it is crucial to train the SiMT model with appropriate reference that avoids forced anticipations during training while maintaining high quality. In this paper, we propose a novel method that provides tailored reference for the SiMT models trained at different latency by rephrasing the ground-truth. Specifically, we introduce the tailor, induced by reinforcement learning, to modify ground-truth to the tailored reference. The SiMT model is trained with the tailored reference and jointly optimized with the tai",
    "link": "http://arxiv.org/abs/2310.13588",
    "context": "Title: Simultaneous Machine Translation with Tailored Reference. (arXiv:2310.13588v1 [cs.CL])\nAbstract: Simultaneous machine translation (SiMT) generates translation while reading the whole source sentence. However, existing SiMT models are typically trained using the same reference disregarding the varying amounts of available source information at different latency. Training the model with ground-truth at low latency may introduce forced anticipations, whereas utilizing reference consistent with the source word order at high latency results in performance degradation. Consequently, it is crucial to train the SiMT model with appropriate reference that avoids forced anticipations during training while maintaining high quality. In this paper, we propose a novel method that provides tailored reference for the SiMT models trained at different latency by rephrasing the ground-truth. Specifically, we introduce the tailor, induced by reinforcement learning, to modify ground-truth to the tailored reference. The SiMT model is trained with the tailored reference and jointly optimized with the tai",
    "path": "papers/23/10/2310.13588.json",
    "total_tokens": 941,
    "translated_title": "使用定制的参考文献的同时机器翻译",
    "translated_abstract": "同时机器翻译（SiMT）在读取整个源句子的同时生成翻译。然而，现有的SiMT模型通常使用相同的参考文献进行训练，而忽略了在不同延迟下可用的源信息的数量不同。使用低延迟下的真实参考文献可能引入强制预测，而使用与源词顺序一致的参考文献在高延迟下会导致性能下降。因此，关键是使用适当的参考文献来训练SiMT模型，既避免在训练过程中强制预测，又保持高质量。在本文中，我们提出了一种新颖的方法，通过重述真实参考文献，为不同延迟进行训练的SiMT模型提供定制的参考文献。具体而言，我们引入了由强化学习引发的改编器来修改真实参考文献，以得到定制的参考文献。SiMT模型是使用定制的参考文献进行训练，并与定制器共同优化。",
    "tldr": "本文提出了一种使用定制参考文献的方法，以解决在同时机器翻译模型训练过程中存在的问题。通过重述真实参考文献，定制参考文献可以在不同延迟下训练SiMT模型，避免了强制预测并保持高质量。",
    "en_tdlr": "This paper proposes a method of using tailored reference to address the issues in training simultaneous machine translation models. By rephrasing the ground-truth, tailored reference can be used to train SiMT models at different latency, avoiding forced predictions and maintaining high quality."
}