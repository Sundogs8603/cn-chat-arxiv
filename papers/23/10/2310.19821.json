{
    "title": "A Risk-Averse Framework for Non-Stationary Stochastic Multi-Armed Bandits. (arXiv:2310.19821v1 [cs.LG])",
    "abstract": "In a typical stochastic multi-armed bandit problem, the objective is often to maximize the expected sum of rewards over some time horizon $T$. While the choice of a strategy that accomplishes that is optimal with no additional information, it is no longer the case when provided additional environment-specific knowledge. In particular, in areas of high volatility like healthcare or finance, a naive reward maximization approach often does not accurately capture the complexity of the learning problem and results in unreliable solutions. To tackle problems of this nature, we propose a framework of adaptive risk-aware strategies that operate in non-stationary environments. Our framework incorporates various risk measures prevalent in the literature to map multiple families of multi-armed bandit algorithms into a risk-sensitive setting. In addition, we equip the resulting algorithms with the Restarted Bayesian Online Change-Point Detection (R-BOCPD) algorithm and impose a (tunable) forced ex",
    "link": "http://arxiv.org/abs/2310.19821",
    "context": "Title: A Risk-Averse Framework for Non-Stationary Stochastic Multi-Armed Bandits. (arXiv:2310.19821v1 [cs.LG])\nAbstract: In a typical stochastic multi-armed bandit problem, the objective is often to maximize the expected sum of rewards over some time horizon $T$. While the choice of a strategy that accomplishes that is optimal with no additional information, it is no longer the case when provided additional environment-specific knowledge. In particular, in areas of high volatility like healthcare or finance, a naive reward maximization approach often does not accurately capture the complexity of the learning problem and results in unreliable solutions. To tackle problems of this nature, we propose a framework of adaptive risk-aware strategies that operate in non-stationary environments. Our framework incorporates various risk measures prevalent in the literature to map multiple families of multi-armed bandit algorithms into a risk-sensitive setting. In addition, we equip the resulting algorithms with the Restarted Bayesian Online Change-Point Detection (R-BOCPD) algorithm and impose a (tunable) forced ex",
    "path": "papers/23/10/2310.19821.json",
    "total_tokens": 941,
    "translated_title": "一种面向非平稳随机多臂老虎机的风险规避框架",
    "translated_abstract": "在典型的随机多臂老虎机问题中，目标通常是在一定的时间范围内最大化预期奖励总和。然而，当提供额外的环境特定知识时，选择一个能够达到最优的策略不再适用。尤其是在医疗或金融等高波动性领域，简单的奖励最大化方法往往不能准确捕捉学习问题的复杂性，导致不可靠的解决方案。为解决这类问题，我们提出了一种自适应风险感知策略的框架，用于在非平稳环境中操作。我们的框架结合了文献中普遍存在的各种风险度量，将多个多臂老虎机算法族映射到风险敏感设置中。此外，我们将结果算法配备了重启贝叶斯在线变点检测（R-BOCPD）算法，并施加了（可调节的）强制终止机制。",
    "tldr": "我们提出了一种适用于非平稳环境的自适应风险感知策略框架，通过结合各种风险度量和重启贝叶斯在线变点检测算法，解决了高波动性领域中简单奖励最大化方法的不可靠性问题。",
    "en_tdlr": "We propose an adaptive risk-aware strategy framework for non-stationary environments, which addresses the issue of unreliable solutions in high volatility domains by incorporating various risk measures and the Restarted Bayesian Online Change-Point Detection algorithm."
}