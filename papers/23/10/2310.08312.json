{
    "title": "GePSAn: Generative Procedure Step Anticipation in Cooking Videos. (arXiv:2310.08312v1 [cs.CV])",
    "abstract": "We study the problem of future step anticipation in procedural videos. Given a video of an ongoing procedural activity, we predict a plausible next procedure step described in rich natural language. While most previous work focus on the problem of data scarcity in procedural video datasets, another core challenge of future anticipation is how to account for multiple plausible future realizations in natural settings. This problem has been largely overlooked in previous work. To address this challenge, we frame future step prediction as modelling the distribution of all possible candidates for the next step. Specifically, we design a generative model that takes a series of video clips as input, and generates multiple plausible and diverse candidates (in natural language) for the next step. Following previous work, we side-step the video annotation scarcity by pretraining our model on a large text-based corpus of procedural activities, and then transfer the model to the video domain. Our ",
    "link": "http://arxiv.org/abs/2310.08312",
    "context": "Title: GePSAn: Generative Procedure Step Anticipation in Cooking Videos. (arXiv:2310.08312v1 [cs.CV])\nAbstract: We study the problem of future step anticipation in procedural videos. Given a video of an ongoing procedural activity, we predict a plausible next procedure step described in rich natural language. While most previous work focus on the problem of data scarcity in procedural video datasets, another core challenge of future anticipation is how to account for multiple plausible future realizations in natural settings. This problem has been largely overlooked in previous work. To address this challenge, we frame future step prediction as modelling the distribution of all possible candidates for the next step. Specifically, we design a generative model that takes a series of video clips as input, and generates multiple plausible and diverse candidates (in natural language) for the next step. Following previous work, we side-step the video annotation scarcity by pretraining our model on a large text-based corpus of procedural activities, and then transfer the model to the video domain. Our ",
    "path": "papers/23/10/2310.08312.json",
    "total_tokens": 905,
    "translated_title": "GePSAn: 烹饪视频中的生成式步骤预测",
    "translated_abstract": "我们研究了在过程视频中未来步骤预测的问题。给定一个正在进行的过程活动的视频，我们预测一个合理的下一个步骤，用丰富的自然语言描述。虽然大多数先前的工作关注的是过程视频数据集中的数据稀缺问题，但未来预测的另一个核心挑战是如何考虑到自然环境中多个可能的未来实现。这个问题在以前的工作中被大部分忽视了。为了解决这个挑战，我们将未来步骤预测制定为建模下一个步骤的所有可能候选的分布。具体地，我们设计了一个生成模型，它以一系列视频片段作为输入，并生成多个下一个步骤的合理和多样化的候选（用自然语言表示）。遵循先前的工作，我们通过在大型基于文本的过程活动语料库上预训练模型，然后将模型转移到视频领域来避开视频注释的稀缺性。",
    "tldr": "这篇论文研究了在烹饪视频中未来步骤预测的问题，通过设计一个生成模型，能够生成多个合理且多样的候选步骤，解决了之前工作中忽视的考虑多个可能实现的挑战。",
    "en_tdlr": "This paper investigates the problem of future step anticipation in cooking videos and proposes a generative model that can generate multiple plausible and diverse candidate steps, addressing the challenge of considering multiple possible realizations that has been overlooked in previous work."
}