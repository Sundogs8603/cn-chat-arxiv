{
    "title": "(Dynamic) Prompting might be all you need to repair Compressed LLMs. (arXiv:2310.00867v2 [cs.CL] UPDATED)",
    "abstract": "Large language models (LLMs), while transformative for NLP, come with significant computational demands, underlining the need for efficient, training-free compression. Notably, despite the marked improvement in training-free compression for the largest of LLMs, our tests using LLaMA-7B and OPT-6.7b highlight a significant performance drop in several realistic downstream tasks. Investigation into the trade-off between resource-intensive post-compression re-training highlights the prospect of prompt-driven recovery as a lightweight adaption tool. However, existing studies, confined mainly to perplexity evaluations and simple tasks, fail to offer unequivocal confidence in the scalability and generalizability of prompting. We tackle this uncertainty in two key ways. First, we uncover the vulnerability of naive prompts in LLM compression as an over-reliance on a singular prompt per input. In response, we propose inference-time dynamic prompting (IDP), a mechanism that autonomously chooses f",
    "link": "http://arxiv.org/abs/2310.00867",
    "context": "Title: (Dynamic) Prompting might be all you need to repair Compressed LLMs. (arXiv:2310.00867v2 [cs.CL] UPDATED)\nAbstract: Large language models (LLMs), while transformative for NLP, come with significant computational demands, underlining the need for efficient, training-free compression. Notably, despite the marked improvement in training-free compression for the largest of LLMs, our tests using LLaMA-7B and OPT-6.7b highlight a significant performance drop in several realistic downstream tasks. Investigation into the trade-off between resource-intensive post-compression re-training highlights the prospect of prompt-driven recovery as a lightweight adaption tool. However, existing studies, confined mainly to perplexity evaluations and simple tasks, fail to offer unequivocal confidence in the scalability and generalizability of prompting. We tackle this uncertainty in two key ways. First, we uncover the vulnerability of naive prompts in LLM compression as an over-reliance on a singular prompt per input. In response, we propose inference-time dynamic prompting (IDP), a mechanism that autonomously chooses f",
    "path": "papers/23/10/2310.00867.json",
    "total_tokens": 942,
    "translated_title": "(动态)提示可能是修复压缩LLMs所需的全部。(arXiv:2310.00867v2 [cs.CL] UPDATED)",
    "translated_abstract": "大型语言模型(LLMs)在自然语言处理方面有着重大的变革，但同时也带来了显著的计算需求，强调了高效、无需训练的压缩的需求。尽管针对最大的LLMs在无需训练的压缩方面取得了显著的改进，但我们使用LLaMA-7B和OPT-6.7b进行的测试显示，在一些实际的下游任务中存在显著的性能下降。对资源密集型的压缩后重新训练的权衡的调查表明，提示驱动的恢复作为一种轻量级的适应工具具有潜在的前景。然而，现有研究主要局限在困惑度评估和简单任务上，对提示的可扩展性和通用性没有给出明确的信心。我们通过两种关键方法解决了这种不确定性。首先，我们揭示了LLM压缩中天真提示的脆弱性，即过度依赖单一输入的提示。作为回应，我们提出了推理时动态提示(IDP)的机制，它可以自主选择最佳的提示。",
    "tldr": "提出了一种动态提示(IDP)的机制，它可以作为一种轻量级的适应工具，修复压缩的大型语言模型(LLMs)在一些实际的下游任务中的性能下降。",
    "en_tdlr": "Dynamic Prompting (IDP) mechanism is proposed as a lightweight adaptation tool to repair the performance drop in compressed Large Language Models (LLMs) in several realistic downstream tasks."
}