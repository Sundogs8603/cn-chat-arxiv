{
    "title": "On the Foundations of Shortcut Learning. (arXiv:2310.16228v1 [cs.LG])",
    "abstract": "Deep-learning models can extract a rich assortment of features from data. Which features a model uses depends not only on predictivity-how reliably a feature indicates train-set labels-but also on availability-how easily the feature can be extracted, or leveraged, from inputs. The literature on shortcut learning has noted examples in which models privilege one feature over another, for example texture over shape and image backgrounds over foreground objects. Here, we test hypotheses about which input properties are more available to a model, and systematically study how predictivity and availability interact to shape models' feature use. We construct a minimal, explicit generative framework for synthesizing classification datasets with two latent features that vary in predictivity and in factors we hypothesize to relate to availability, and quantify a model's shortcut bias-its over-reliance on the shortcut (more available, less predictive) feature at the expense of the core (less avail",
    "link": "http://arxiv.org/abs/2310.16228",
    "context": "Title: On the Foundations of Shortcut Learning. (arXiv:2310.16228v1 [cs.LG])\nAbstract: Deep-learning models can extract a rich assortment of features from data. Which features a model uses depends not only on predictivity-how reliably a feature indicates train-set labels-but also on availability-how easily the feature can be extracted, or leveraged, from inputs. The literature on shortcut learning has noted examples in which models privilege one feature over another, for example texture over shape and image backgrounds over foreground objects. Here, we test hypotheses about which input properties are more available to a model, and systematically study how predictivity and availability interact to shape models' feature use. We construct a minimal, explicit generative framework for synthesizing classification datasets with two latent features that vary in predictivity and in factors we hypothesize to relate to availability, and quantify a model's shortcut bias-its over-reliance on the shortcut (more available, less predictive) feature at the expense of the core (less avail",
    "path": "papers/23/10/2310.16228.json",
    "total_tokens": 903,
    "translated_title": "关于快速学习的基础研究",
    "translated_abstract": "深度学习模型可以从数据中提取丰富的特征。模型使用哪些特征不仅取决于预测能力 - 一个特征可靠地指示训练集标签的程度，还取决于可用性 - 一个特征可以从输入中被轻松提取或利用的程度。有关快速学习的文献已经指出了模型偏好一个特征而不是另一个特征的例子，例如在纹理和形状之间以及在图像背景和前景对象之间。在这里，我们测试关于哪些输入属性对于模型更容易获取的假设，并系统地研究预测能力和可用性如何相互作用来塑造模型的特征使用。我们构建了一个最小的、明确的生成框架来合成具有两个潜在特征的分类数据集，这两个特征在预测能力和我们假设与可用性有关的因素上有所不同，并量化了模型的快捷偏差 - 它过度依赖快捷（更可用、不太预测）特征而忽视了核心（不太可用)特征。",
    "tldr": "该论文研究了快速学习的基础，揭示了模型对哪些特征更偏好，即可预测性和可用性如何相互影响模型的特征使用。",
    "en_tdlr": "This paper investigates the foundations of shortcut learning and reveals which features models prefer, exploring how predictivity and availability interact in shaping the use of these features."
}