{
    "title": "Network Contention-Aware Cluster Scheduling with Reinforcement Learning. (arXiv:2310.20209v1 [cs.LG])",
    "abstract": "With continuous advances in deep learning, distributed training is becoming common in GPU clusters. Specifically, for emerging workloads with diverse amounts, ratios, and patterns of communication, we observe that network contention can significantly degrade training throughput. However, widely used scheduling policies often face limitations as they are agnostic to network contention between jobs. In this paper, we present a new approach to mitigate network contention in GPU clusters using reinforcement learning. We formulate GPU cluster scheduling as a reinforcement learning problem and opt to learn a network contention-aware scheduling policy that efficiently captures contention sensitivities and dynamically adapts scheduling decisions through continuous evaluation and improvement. We show that compared to widely used scheduling policies, our approach reduces average job completion time by up to 18.2\\% and effectively cuts the tail job completion time by up to 20.7\\% while allowing a",
    "link": "http://arxiv.org/abs/2310.20209",
    "context": "Title: Network Contention-Aware Cluster Scheduling with Reinforcement Learning. (arXiv:2310.20209v1 [cs.LG])\nAbstract: With continuous advances in deep learning, distributed training is becoming common in GPU clusters. Specifically, for emerging workloads with diverse amounts, ratios, and patterns of communication, we observe that network contention can significantly degrade training throughput. However, widely used scheduling policies often face limitations as they are agnostic to network contention between jobs. In this paper, we present a new approach to mitigate network contention in GPU clusters using reinforcement learning. We formulate GPU cluster scheduling as a reinforcement learning problem and opt to learn a network contention-aware scheduling policy that efficiently captures contention sensitivities and dynamically adapts scheduling decisions through continuous evaluation and improvement. We show that compared to widely used scheduling policies, our approach reduces average job completion time by up to 18.2\\% and effectively cuts the tail job completion time by up to 20.7\\% while allowing a",
    "path": "papers/23/10/2310.20209.json",
    "total_tokens": 849,
    "translated_title": "基于强化学习的网络争用感知集群调度",
    "translated_abstract": "随着深度学习不断的发展，分布式训练在GPU集群中变得越来越普遍。特别是对于具有不同通信量、比例和模式的新兴工作负载，我们观察到网络争用可以显著降低训练吞吐量。然而，广泛使用的调度策略通常面临着局限性，因为它们对于作业之间的网络争用是无视的。在本文中，我们提出了一种新的方法来通过强化学习来减少GPU集群中的网络争用。我们将GPU集群调度问题形式化为一个强化学习问题，并选择学习网络争用感知调度策略，通过持续的评估和改进来动态调整调度决策。我们展示了与广泛使用的调度策略相比，我们的方法可以将作业的平均完成时间降低高达18.2％，并且可以将作业完成时间的尾部减少高达20.7%。",
    "tldr": "基于强化学习的网络争用感知集群调度方法有效减少GPU集群中的网络争用，通过学习动态调整调度决策，提高作业完成时间。",
    "en_tdlr": "Network contention-aware cluster scheduling using reinforcement learning reduces network contention in GPU clusters and improves job completion time by dynamically adjusting scheduling decisions."
}