{
    "title": "ASPIRO: Any-shot Structured Parsing-error-Induced ReprOmpting for Consistent Data-to-Text Generation. (arXiv:2310.17877v1 [cs.CL])",
    "abstract": "We present ASPIRO, an approach for structured data verbalisation into short template sentences in zero to few-shot settings. Unlike previous methods, our approach prompts large language models (LLMs) to directly produce entity-agnostic templates, rather than relying on LLMs to faithfully copy the given example entities, or validating/crafting the templates manually. We incorporate LLM re-prompting, triggered by algorithmic parsing checks, as well as the PARENT metric induced consistency validation to identify and rectify template generation problems in real-time. ASPIRO, compared to direct LLM output, averages 66\\% parsing error rate reduction in generated verbalisations of RDF triples on the DART dataset. Our best 5-shot text-davinci-003 setup, scoring BLEU of 50.62, METEOR of 45.16, BLEURT of 0.82, NUBIA of 0.87, and PARENT of 0.8962 on the Rel2Text dataset, competes effectively with recent fine-tuned pre-trained language models.",
    "link": "http://arxiv.org/abs/2310.17877",
    "context": "Title: ASPIRO: Any-shot Structured Parsing-error-Induced ReprOmpting for Consistent Data-to-Text Generation. (arXiv:2310.17877v1 [cs.CL])\nAbstract: We present ASPIRO, an approach for structured data verbalisation into short template sentences in zero to few-shot settings. Unlike previous methods, our approach prompts large language models (LLMs) to directly produce entity-agnostic templates, rather than relying on LLMs to faithfully copy the given example entities, or validating/crafting the templates manually. We incorporate LLM re-prompting, triggered by algorithmic parsing checks, as well as the PARENT metric induced consistency validation to identify and rectify template generation problems in real-time. ASPIRO, compared to direct LLM output, averages 66\\% parsing error rate reduction in generated verbalisations of RDF triples on the DART dataset. Our best 5-shot text-davinci-003 setup, scoring BLEU of 50.62, METEOR of 45.16, BLEURT of 0.82, NUBIA of 0.87, and PARENT of 0.8962 on the Rel2Text dataset, competes effectively with recent fine-tuned pre-trained language models.",
    "path": "papers/23/10/2310.17877.json",
    "total_tokens": 1006,
    "translated_title": "ASPIRO: 一种适用于零到少样本情况下结构化数据到文本生成的错误感知重提示方法",
    "translated_abstract": "我们提出了ASPIRO，一种在零到少样本情况下将结构化数据转化为简短模板句子的方法。与之前的方法不同，我们的方法直接提示大型语言模型（LLM）产生与实体无关的模板，而不是依赖LLM忠实地复制给定的实体，或者手动验证/制作模板。我们通过算法解析检查和PARENT指标诱导的一致性验证，结合LLM的重新提示，实时识别和纠正模板生成问题。在DART数据集上，与直接LLM输出相比，ASPIRO对RDF三元组的生成文本的解析错误率平均降低了66％。我们在Rel2Text数据集上的最佳5样本text-davinci-003设置评分为BLEU 50.62，METEOR 45.16，BLEURT 0.82，NUBIA 0.87和PARENT 0.8962，与最近的精调预训练语言模型有了有效的竞争力。",
    "tldr": "ASPIRO是一种能在零到少样本情况下将结构化数据转化为简短模板句子的方法。通过算法解析检查、LLM的重新提示以及一致性验证指标PARENT，ASPIRO成功降低了66%的解析错误率，并且在与最近的预训练语言模型的竞争中表现出色。",
    "en_tdlr": "ASPIRO is an approach for converting structured data into short template sentences in zero to few-shot settings. It achieves a 66% reduction in parsing error rate compared to direct large language model (LLM) output, and competes effectively with recent fine-tuned pre-trained language models by incorporating algorithmic parsing checks, LLM re-prompting, and the PARENT metric for consistency validation."
}