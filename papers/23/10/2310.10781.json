{
    "title": "BanglaNLP at BLP-2023 Task 1: Benchmarking different Transformer Models for Violence Inciting Text Detection in Bengali. (arXiv:2310.10781v1 [cs.CL])",
    "abstract": "This paper presents the system that we have developed while solving this shared task on violence inciting text detection in Bangla. We explain both the traditional and the recent approaches that we have used to make our models learn. Our proposed system helps to classify if the given text contains any threat. We studied the impact of data augmentation when there is a limited dataset available. Our quantitative results show that finetuning a multilingual-e5-base model performed the best in our task compared to other transformer-based architectures. We obtained a macro F1 of 68.11\\% in the test set and our performance in this shared task is ranked at 23 in the leaderboard.",
    "link": "http://arxiv.org/abs/2310.10781",
    "context": "Title: BanglaNLP at BLP-2023 Task 1: Benchmarking different Transformer Models for Violence Inciting Text Detection in Bengali. (arXiv:2310.10781v1 [cs.CL])\nAbstract: This paper presents the system that we have developed while solving this shared task on violence inciting text detection in Bangla. We explain both the traditional and the recent approaches that we have used to make our models learn. Our proposed system helps to classify if the given text contains any threat. We studied the impact of data augmentation when there is a limited dataset available. Our quantitative results show that finetuning a multilingual-e5-base model performed the best in our task compared to other transformer-based architectures. We obtained a macro F1 of 68.11\\% in the test set and our performance in this shared task is ranked at 23 in the leaderboard.",
    "path": "papers/23/10/2310.10781.json",
    "total_tokens": 812,
    "translated_title": "BanglaNLP在BLP-2023任务1中的表现：在孟加拉文中暴力煽动文字检测中对不同Transformer模型进行基准测试",
    "translated_abstract": "本文介绍了我们在孟加拉文中暴力煽动文字检测的共享任务中开发的系统。我们解释了我们使用的传统方法和最近的方法来让我们的模型学习。我们提出的系统有助于分类判断给定的文本是否包含威胁。我们研究了在数据集有限的情况下进行数据增强的影响。我们的定量结果显示，在我们的任务中，对多语言-e5-base模型进行微调在性能上胜过其他基于Transformer的架构。我们在测试集中获得了68.11%的宏F1值，并在这个共享任务中排名第23位。",
    "tldr": "本文介绍了BanglaNLP开发的系统在解决孟加拉文中暴力煽动文字检测共享任务中的表现。通过研究数据增强和使用多语言-e5-base模型进行微调，我们在测试集上取得了68.11%的宏F1值，在排行榜上排名第23位。",
    "en_tdlr": "This paper presents the system developed by BanglaNLP for violence inciting text detection in Bengali. By studying data augmentation and fine-tuning the multilingual-e5-base model, the system achieved a macro F1 of 68.11% in the test set, ranking 23rd in the leaderboard for this shared task."
}