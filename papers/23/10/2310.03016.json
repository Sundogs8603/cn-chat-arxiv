{
    "title": "Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions. (arXiv:2310.03016v1 [cs.LG])",
    "abstract": "In order to understand the in-context learning phenomenon, recent works have adopted a stylized experimental framework and demonstrated that Transformers can learn gradient-based learning algorithms for various classes of real-valued functions. However, the limitations of Transformers in implementing learning algorithms, and their ability to learn other forms of algorithms are not well understood. Additionally, the degree to which these capabilities are confined to attention-based models is unclear. Furthermore, it remains to be seen whether the insights derived from these stylized settings can be extrapolated to pretrained Large Language Models (LLMs). In this work, we take a step towards answering these questions by demonstrating the following: (a) On a test-bed with a variety of Boolean function classes, we find that Transformers can nearly match the optimal learning algorithm for 'simpler' tasks, while their performance deteriorates on more 'complex' tasks. Additionally, we find th",
    "link": "http://arxiv.org/abs/2310.03016",
    "context": "Title: Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions. (arXiv:2310.03016v1 [cs.LG])\nAbstract: In order to understand the in-context learning phenomenon, recent works have adopted a stylized experimental framework and demonstrated that Transformers can learn gradient-based learning algorithms for various classes of real-valued functions. However, the limitations of Transformers in implementing learning algorithms, and their ability to learn other forms of algorithms are not well understood. Additionally, the degree to which these capabilities are confined to attention-based models is unclear. Furthermore, it remains to be seen whether the insights derived from these stylized settings can be extrapolated to pretrained Large Language Models (LLMs). In this work, we take a step towards answering these questions by demonstrating the following: (a) On a test-bed with a variety of Boolean function classes, we find that Transformers can nearly match the optimal learning algorithm for 'simpler' tasks, while their performance deteriorates on more 'complex' tasks. Additionally, we find th",
    "path": "papers/23/10/2310.03016.json",
    "total_tokens": 920,
    "translated_title": "通过学习离散函数来理解变压器和LLM中的上下文学习现象",
    "translated_abstract": "为了理解上下文学习现象，最近的工作采用了规范化的实验框架，并证明了变压器可以学习各种实值函数的基于梯度的学习算法。然而，变压器在实现学习算法方面的限制以及它们学习其他形式算法的能力还不清楚。此外，这些能力在基于注意力模型中的限制程度也不明确。此外，尚不清楚从这些规范化设置中得出的见解是否能推广到预训练的大型语言模型（LLM）。在这项工作中，我们通过以下方式向这些问题迈进：（a）在一个包含各种布尔函数类的测试平台上，我们发现变压器几乎可以与“较简单”任务的最优学习算法相匹配，但在“较复杂”任务上其性能下降。此外，我们还发现",
    "tldr": "这项工作通过实验发现，变压器可以学习各种实值函数的基于梯度的学习算法，但对于更复杂的任务性能下降。另外，该研究还探讨了这些能力在基于注意力模型中的限制程度以及推广到预训练的大型语言模型（LLM）的可行性。"
}