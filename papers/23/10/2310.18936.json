{
    "title": "Adversarial Examples Are Not Real Features",
    "abstract": "The existence of adversarial examples has been a mystery for years and attracted much interest. A well-known theory by \\citet{ilyas2019adversarial} explains adversarial vulnerability from a data perspective by showing that one can extract non-robust features from adversarial examples and these features alone are useful for classification. However, the explanation remains quite counter-intuitive since non-robust features are mostly noise features to humans. In this paper, we re-examine the theory from a larger context by incorporating multiple learning paradigms. Notably, we find that contrary to their good usefulness under supervised learning, non-robust features attain poor usefulness when transferred to other self-supervised learning paradigms, such as contrastive learning, masked image modeling, and diffusion models. It reveals that non-robust features are not really as useful as robust or natural features that enjoy good transferability between these paradigms. Meanwhile, for robus",
    "link": "https://arxiv.org/abs/2310.18936",
    "context": "Title: Adversarial Examples Are Not Real Features\nAbstract: The existence of adversarial examples has been a mystery for years and attracted much interest. A well-known theory by \\citet{ilyas2019adversarial} explains adversarial vulnerability from a data perspective by showing that one can extract non-robust features from adversarial examples and these features alone are useful for classification. However, the explanation remains quite counter-intuitive since non-robust features are mostly noise features to humans. In this paper, we re-examine the theory from a larger context by incorporating multiple learning paradigms. Notably, we find that contrary to their good usefulness under supervised learning, non-robust features attain poor usefulness when transferred to other self-supervised learning paradigms, such as contrastive learning, masked image modeling, and diffusion models. It reveals that non-robust features are not really as useful as robust or natural features that enjoy good transferability between these paradigms. Meanwhile, for robus",
    "path": "papers/23/10/2310.18936.json",
    "total_tokens": 969,
    "translated_title": "对抗样本不是真正的特征",
    "translated_abstract": "对抗样本的存在多年来一直是一个谜团，并引起了广泛的关注。一种由Ilyas等人提出的著名理论从数据的角度解释了对抗性脆弱性，即通过展示可以从对抗样本中提取非鲁棒特征，并且这些特征单独用于分类是有用的。然而，这种解释仍然相当反直觉，因为非鲁棒特征对于人类来说大部分是噪声特征。在本文中，我们从更大的背景下重新审视了这个理论，结合了多个学习范式。值得注意的是，我们发现与在监督学习中的良好效用相反，当将非鲁棒特征转移到其他无监督学习范式时（如对比学习、遮挡图像建模和扩散模型），它们的效用变差。这揭示了非鲁棒特征并不像在这些范式之间享有良好可迁移性的鲁棒特征或自然特征那样真正有用。同时，对于鲁棒特征而言，在自监督学习中的效用与监督学习中的效用相当。",
    "tldr": "该论文从多个学习范式的角度重新审视对抗样本的理论，发现非鲁棒特征在多种无监督学习范式中的效用较差，揭示了这些特征并不像鲁棒特征或自然特征那样真正有用。"
}