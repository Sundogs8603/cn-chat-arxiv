{
    "title": "Predictive auxiliary objectives in deep RL mimic learning in the brain. (arXiv:2310.06089v1 [cs.AI])",
    "abstract": "The ability to predict upcoming events has been hypothesized to comprise a key aspect of natural and machine cognition. This is supported by trends in deep reinforcement learning (RL), where self-supervised auxiliary objectives such as prediction are widely used to support representation learning and improve task performance. Here, we study the effects predictive auxiliary objectives have on representation learning across different modules of an RL system and how these mimic representational changes observed in the brain. We find that predictive objectives improve and stabilize learning particularly in resource-limited architectures, and we identify settings where longer predictive horizons better support representational transfer. Furthermore, we find that representational changes in this RL system bear a striking resemblance to changes in neural activity observed in the brain across various experiments. Specifically, we draw a connection between the auxiliary predictive model of the ",
    "link": "http://arxiv.org/abs/2310.06089",
    "context": "Title: Predictive auxiliary objectives in deep RL mimic learning in the brain. (arXiv:2310.06089v1 [cs.AI])\nAbstract: The ability to predict upcoming events has been hypothesized to comprise a key aspect of natural and machine cognition. This is supported by trends in deep reinforcement learning (RL), where self-supervised auxiliary objectives such as prediction are widely used to support representation learning and improve task performance. Here, we study the effects predictive auxiliary objectives have on representation learning across different modules of an RL system and how these mimic representational changes observed in the brain. We find that predictive objectives improve and stabilize learning particularly in resource-limited architectures, and we identify settings where longer predictive horizons better support representational transfer. Furthermore, we find that representational changes in this RL system bear a striking resemblance to changes in neural activity observed in the brain across various experiments. Specifically, we draw a connection between the auxiliary predictive model of the ",
    "path": "papers/23/10/2310.06089.json",
    "total_tokens": 930,
    "translated_title": "深度强化学习中的预测辅助目标模仿大脑学习",
    "translated_abstract": "预测即将发生的事件的能力被假设为自然和机器认知的关键方面。这在深度强化学习中得到了支持，其中自监督辅助目标（如预测）被广泛用于支持表示学习和提高任务性能。本文研究了预测辅助目标对RL系统中不同模块的表示学习的影响，以及这些模拟大脑观察到的表征变化。我们发现，在资源受限的架构中，预测目标特别提高和稳定学习，并且我们确定了更长的预测时段在支持表征迁移方面更好。此外，我们发现这个RL系统中的表征变化与大脑中观察到的神经活动变化有惊人的相似之处。具体而言，我们在辅助预测模型和大脑中的表征变化之间建立了联系。",
    "tldr": "本文研究了深度强化学习中预测辅助目标对表示学习和性能的影响，发现在资源受限的情况下，预测目标能显著提高和稳定学习，并且能支持表征迁移。此外，与神经活动变化相似，这些辅助目标也模拟了大脑中的表征变化。",
    "en_tdlr": "This paper investigates the impact of predictive auxiliary objectives in deep reinforcement learning on representation learning and task performance. The study finds that in resource-limited architectures, predictive objectives significantly improve and stabilize learning and support representational transfer. Furthermore, these auxiliary objectives also mimic representational changes observed in the brain, similar to neural activity changes."
}