{
    "title": "Interactive Robot Learning from Verbal Correction. (arXiv:2310.17555v1 [cs.RO])",
    "abstract": "The ability to learn and refine behavior after deployment has become ever more important for robots as we design them to operate in unstructured environments like households. In this work, we design a new learning system based on large language model (LLM), OLAF, that allows everyday users to teach a robot using verbal corrections when the robot makes mistakes, e.g., by saying \"Stop what you're doing. You should move closer to the cup.\" A key feature of OLAF is its ability to update the robot's visuomotor neural policy based on the verbal feedback to avoid repeating mistakes in the future. This is in contrast to existing LLM-based robotic systems, which only follow verbal commands or corrections but not learn from them. We demonstrate the efficacy of our design in experiments where a user teaches a robot to perform long-horizon manipulation tasks both in simulation and on physical hardware, achieving on average 20.0% improvement in policy success rate. Videos and more results are at ht",
    "link": "http://arxiv.org/abs/2310.17555",
    "context": "Title: Interactive Robot Learning from Verbal Correction. (arXiv:2310.17555v1 [cs.RO])\nAbstract: The ability to learn and refine behavior after deployment has become ever more important for robots as we design them to operate in unstructured environments like households. In this work, we design a new learning system based on large language model (LLM), OLAF, that allows everyday users to teach a robot using verbal corrections when the robot makes mistakes, e.g., by saying \"Stop what you're doing. You should move closer to the cup.\" A key feature of OLAF is its ability to update the robot's visuomotor neural policy based on the verbal feedback to avoid repeating mistakes in the future. This is in contrast to existing LLM-based robotic systems, which only follow verbal commands or corrections but not learn from them. We demonstrate the efficacy of our design in experiments where a user teaches a robot to perform long-horizon manipulation tasks both in simulation and on physical hardware, achieving on average 20.0% improvement in policy success rate. Videos and more results are at ht",
    "path": "papers/23/10/2310.17555.json",
    "total_tokens": 1009,
    "translated_title": "从口头纠正中进行交互式机器人学习",
    "translated_abstract": "随着我们将机器人设计成能在家庭等非结构化环境中运行，学习和改进行为的能力越来越重要。在这项工作中，我们设计了一个基于大型语言模型（LLM）OLAF的新学习系统，它允许日常用户通过口头纠正教授机器人，当机器人犯错误时，例如说“停下你正在做的事情。你应该靠近杯子。” OLAF的一个关键特点是它能够根据口头反馈更新机器人的视觉运动神经策略，以避免将来重复错误。这与现有的基于LLM的机器人系统形成对比，后者仅仅遵循口头命令或纠正，而不会从中学习。在模拟和物理硬件上的实验中，我们证明了我们设计的有效性，用户教机器人执行长时间线的操纵任务，在策略成功率方面平均改善了20.0%。视频和更多结果可在ht找到。",
    "tldr": "本研究设计了一个新的基于大型语言模型（LLM）OLAF的交互式机器人学习系统，它允许日常用户通过口头纠正教授机器人，并能根据口头反馈更新机器人的视觉运动神经策略，从而避免重复错误。实验结果表明，在模拟和物理硬件上，该系统在长时间线的操纵任务中平均改善了20.0%的策略成功率。",
    "en_tdlr": "This study presents a new interactive robot learning system based on a large language model (LLM) OLAF, which allows everyday users to teach robots through verbal corrections and updates the robot's visuomotor neural policy based on the feedback. The system achieved an average 20.0% improvement in policy success rate for long-horizon manipulation tasks in both simulation and physical hardware experiments."
}