{
    "title": "Leveraging Model-based Trees as Interpretable Surrogate Models for Model Distillation. (arXiv:2310.03112v1 [stat.ML])",
    "abstract": "Surrogate models play a crucial role in retrospectively interpreting complex and powerful black box machine learning models via model distillation. This paper focuses on using model-based trees as surrogate models which partition the feature space into interpretable regions via decision rules. Within each region, interpretable models based on additive main effects are used to approximate the behavior of the black box model, striking for an optimal balance between interpretability and performance. Four model-based tree algorithms, namely SLIM, GUIDE, MOB, and CTree, are compared regarding their ability to generate such surrogate models. We investigate fidelity, interpretability, stability, and the algorithms' capability to capture interaction effects through appropriate splits. Based on our comprehensive analyses, we finally provide an overview of user-specific recommendations.",
    "link": "http://arxiv.org/abs/2310.03112",
    "context": "Title: Leveraging Model-based Trees as Interpretable Surrogate Models for Model Distillation. (arXiv:2310.03112v1 [stat.ML])\nAbstract: Surrogate models play a crucial role in retrospectively interpreting complex and powerful black box machine learning models via model distillation. This paper focuses on using model-based trees as surrogate models which partition the feature space into interpretable regions via decision rules. Within each region, interpretable models based on additive main effects are used to approximate the behavior of the black box model, striking for an optimal balance between interpretability and performance. Four model-based tree algorithms, namely SLIM, GUIDE, MOB, and CTree, are compared regarding their ability to generate such surrogate models. We investigate fidelity, interpretability, stability, and the algorithms' capability to capture interaction effects through appropriate splits. Based on our comprehensive analyses, we finally provide an overview of user-specific recommendations.",
    "path": "papers/23/10/2310.03112.json",
    "total_tokens": 871,
    "translated_title": "利用基于模型的树作为可解释的替代模型进行模型蒸馏",
    "translated_abstract": "替代模型在通过模型蒸馏回顾性地解释复杂而强大的黑盒子机器学习模型中起着至关重要的作用。本文着重于使用基于模型的树作为替代模型，通过决策规则将特征空间划分为可解释的区域。在每个区域内，使用基于可加性主效应的可解释模型来近似黑盒子模型的行为，以在可解释性和性能之间达到最佳平衡。我们比较了四种基于模型的树算法（SLIM，GUIDE，MOB和CTree）在生成这样的替代模型方面的能力。我们通过对保真度、可解释性、稳定性以及算法捕捉交互效应的能力进行了全面分析。最后，基于我们的综合分析，我们提供了用户特定的推荐概述。",
    "tldr": "这项研究利用基于模型的树作为可解释的替代模型，通过决策规则将特征空间划分为可解释的区域，并使用基于可加性主效应的可解释模型来近似黑盒子模型的行为，以在可解释性和性能之间达到最佳平衡。",
    "en_tdlr": "This research leverages model-based trees as interpretable surrogate models by partitioning the feature space into interpretable regions through decision rules and approximating the behavior of black box models with interpretable models based on additive main effects, striking an optimal balance between interpretability and performance."
}