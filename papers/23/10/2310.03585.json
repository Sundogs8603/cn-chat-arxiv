{
    "title": "Smoothing Methods for Automatic Differentiation Across Conditional Branches. (arXiv:2310.03585v1 [cs.LG])",
    "abstract": "Programs involving discontinuities introduced by control flow constructs such as conditional branches pose challenges to mathematical optimization methods that assume a degree of smoothness in the objective function's response surface. Smooth interpretation (SI) is a form of abstract interpretation that approximates the convolution of a program's output with a Gaussian kernel, thus smoothing its output in a principled manner. Here, we combine SI with automatic differentiation (AD) to efficiently compute gradients of smoothed programs. In contrast to AD across a regular program execution, these gradients also capture the effects of alternative control flow paths. The combination of SI with AD enables the direct gradient-based parameter synthesis for branching programs, allowing for instance the calibration of simulation models or their combination with neural network models in machine learning pipelines. We detail the effects of the approximations made for tractability in SI and propose",
    "link": "http://arxiv.org/abs/2310.03585",
    "context": "Title: Smoothing Methods for Automatic Differentiation Across Conditional Branches. (arXiv:2310.03585v1 [cs.LG])\nAbstract: Programs involving discontinuities introduced by control flow constructs such as conditional branches pose challenges to mathematical optimization methods that assume a degree of smoothness in the objective function's response surface. Smooth interpretation (SI) is a form of abstract interpretation that approximates the convolution of a program's output with a Gaussian kernel, thus smoothing its output in a principled manner. Here, we combine SI with automatic differentiation (AD) to efficiently compute gradients of smoothed programs. In contrast to AD across a regular program execution, these gradients also capture the effects of alternative control flow paths. The combination of SI with AD enables the direct gradient-based parameter synthesis for branching programs, allowing for instance the calibration of simulation models or their combination with neural network models in machine learning pipelines. We detail the effects of the approximations made for tractability in SI and propose",
    "path": "papers/23/10/2310.03585.json",
    "total_tokens": 828,
    "translated_title": "跨条件分支的自动微分平滑方法",
    "translated_abstract": "具有条件分支引入的不连续性的程序对假定目标函数响应曲面具有一定平滑性的数学优化方法提出了挑战。平滑解释（SI）是一种抽象解释形式，它以高斯核近似程序输出的卷积，从而以原则性的方式平滑其输出。在这里，我们将SI与自动微分（AD）相结合，以高效地计算平滑程序的梯度。与在常规程序执行中进行的自动微分不同，这些梯度还捕捉了替代控制流路径的影响。SI与AD的组合使得支持基于梯度的分支程序参数合成成为可能，例如在机器学习流程中，对仿真模型进行校准或将其与神经网络模型结合。我们详细说明了SI中为可行性而进行的近似的影响，并提出了改进方法。",
    "tldr": "本研究提出了一种通过结合平滑解释和自动微分的方法来处理具有条件分支的程序，并成功计算出平滑程序的梯度，从而支持分支程序参数合成和机器学习流程中的模型校准。",
    "en_tdlr": "This research proposes a method for handling programs with conditional branches by combining smooth interpretation and automatic differentiation, successfully computing gradients of smoothed programs, enabling parameter synthesis for branching programs and model calibration in machine learning pipelines."
}