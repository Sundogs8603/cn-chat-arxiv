{
    "title": "DiffNAS: Bootstrapping Diffusion Models by Prompting for Better Architectures. (arXiv:2310.04750v2 [cs.AI] UPDATED)",
    "abstract": "Diffusion models have recently exhibited remarkable performance on synthetic data. After a diffusion path is selected, a base model, such as UNet, operates as a denoising autoencoder, primarily predicting noises that need to be eliminated step by step. Consequently, it is crucial to employ a model that aligns with the expected budgets to facilitate superior synthetic performance. In this paper, we meticulously analyze the diffusion model and engineer a base model search approach, denoted \"DiffNAS\". Specifically, we leverage GPT-4 as a supernet to expedite the search, supplemented with a search memory to enhance the results. Moreover, we employ RFID as a proxy to promptly rank the experimental outcomes produced by GPT-4. We also adopt a rapid-convergence training strategy to boost search efficiency. Rigorous experimentation corroborates that our algorithm can augment the search efficiency by 2 times under GPT-based scenarios, while also attaining a performance of 2.82 with 0.37 improvem",
    "link": "http://arxiv.org/abs/2310.04750",
    "context": "Title: DiffNAS: Bootstrapping Diffusion Models by Prompting for Better Architectures. (arXiv:2310.04750v2 [cs.AI] UPDATED)\nAbstract: Diffusion models have recently exhibited remarkable performance on synthetic data. After a diffusion path is selected, a base model, such as UNet, operates as a denoising autoencoder, primarily predicting noises that need to be eliminated step by step. Consequently, it is crucial to employ a model that aligns with the expected budgets to facilitate superior synthetic performance. In this paper, we meticulously analyze the diffusion model and engineer a base model search approach, denoted \"DiffNAS\". Specifically, we leverage GPT-4 as a supernet to expedite the search, supplemented with a search memory to enhance the results. Moreover, we employ RFID as a proxy to promptly rank the experimental outcomes produced by GPT-4. We also adopt a rapid-convergence training strategy to boost search efficiency. Rigorous experimentation corroborates that our algorithm can augment the search efficiency by 2 times under GPT-based scenarios, while also attaining a performance of 2.82 with 0.37 improvem",
    "path": "papers/23/10/2310.04750.json",
    "total_tokens": 970,
    "translated_title": "DiffNAS: 通过引导更好的结构来启动扩散模型",
    "translated_abstract": "最近，扩散模型在合成数据上表现出了显著的性能。在选择扩散路径之后，像UNet这样的基础模型作为去噪自编码器，主要预测需要逐步消除的噪声。因此，采用与预期预算相一致的模型以促进优良的合成性能至关重要。在本文中，我们精心分析了扩散模型，并设计了一种名为\"DiffNAS\"的基础模型搜索方法。具体而言，我们利用GPT-4作为超网来加速搜索，辅以搜索内存以增强结果。此外，我们采用RFID作为代理，快速对GPT-4产生的实验结果进行排序。我们还采用了快速收敛训练策略来提高搜索效率。严格的实验验证了我们的算法在基于GPT的情境下可以将搜索效率提高2倍，同时取得了2.82的性能，改善了0.37。",
    "tldr": "本文提出了一种名为DiffNAS的基础模型搜索方法，通过引导更好的结构来启动扩散模型，以提高合成性能。通过利用GPT-4作为超网，辅以搜索内存和RFID代理，以及快速收敛训练策略，搜索效率提高了2倍，达到了2.82的性能提升0.37。",
    "en_tdlr": "This paper proposes a base model search approach called DiffNAS to bootstrap diffusion models and improve synthetic performance by prompting for better architectures. By leveraging GPT-4 as a supernet, along with search memory and RFID proxy, and adopting a rapid-convergence training strategy, the algorithm achieves a 2 times improvement in search efficiency and a performance of 2.82 with 0.37 improvement."
}