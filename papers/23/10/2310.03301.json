{
    "title": "Learning Energy Decompositions for Partial Inference of GFlowNets. (arXiv:2310.03301v1 [cs.LG])",
    "abstract": "This paper studies generative flow networks (GFlowNets) to sample objects from the Boltzmann energy distribution via a sequence of actions. In particular, we focus on improving GFlowNet with partial inference: training flow functions with the evaluation of the intermediate states or transitions. To this end, the recently developed forward-looking GFlowNet reparameterizes the flow functions based on evaluating the energy of intermediate states. However, such an evaluation of intermediate energies may (i) be too expensive or impossible to evaluate and (ii) even provide misleading training signals under large energy fluctuations along the sequence of actions. To resolve this issue, we propose learning energy decompositions for GFlowNets (LED-GFN). Our main idea is to (i) decompose the energy of an object into learnable potential functions defined on state transitions and (ii) reparameterize the flow functions using the potential functions. In particular, to produce informative local credi",
    "link": "http://arxiv.org/abs/2310.03301",
    "context": "Title: Learning Energy Decompositions for Partial Inference of GFlowNets. (arXiv:2310.03301v1 [cs.LG])\nAbstract: This paper studies generative flow networks (GFlowNets) to sample objects from the Boltzmann energy distribution via a sequence of actions. In particular, we focus on improving GFlowNet with partial inference: training flow functions with the evaluation of the intermediate states or transitions. To this end, the recently developed forward-looking GFlowNet reparameterizes the flow functions based on evaluating the energy of intermediate states. However, such an evaluation of intermediate energies may (i) be too expensive or impossible to evaluate and (ii) even provide misleading training signals under large energy fluctuations along the sequence of actions. To resolve this issue, we propose learning energy decompositions for GFlowNets (LED-GFN). Our main idea is to (i) decompose the energy of an object into learnable potential functions defined on state transitions and (ii) reparameterize the flow functions using the potential functions. In particular, to produce informative local credi",
    "path": "papers/23/10/2310.03301.json",
    "total_tokens": 902,
    "translated_title": "学习能量分解用于GFlowNets部分推断的研究",
    "translated_abstract": "本文研究了生成性流网络（GFlowNets），通过一系列操作从Boltzmann能量分布中采样对象。特别地，我们关注改进GFlowNet的部分推断方法：使用中间状态或转换的评估来训练流函数。为此，最近发展的前瞻性GFlowNet基于评估中间状态的能量对流函数进行了重新参数化。然而，对中间能量的评估可能（i）太昂贵或无法进行评估，（ii）甚至在操作序列中能量波动较大时提供误导性的训练信号。为解决这个问题，我们提出了用于GFlowNets的能量分解学习（LED-GFN）。我们的主要思想是（i）将对象的能量分解为在状态转换上定义的可学习潜在函数，（ii）使用这些潜在函数对流函数进行重新参数化。",
    "tldr": "本文提出了一种学习能量分解方法（LED-GFN），用于改进生成性流网络（GFlowNets）在采样对象时的部分推断。方法利用可学习的潜在函数对流函数进行重新参数化，解决了在操作序列中能量波动较大时的训练信号误导问题。",
    "en_tdlr": "This paper introduces a method for learning energy decompositions (LED-GFN) to improve partial inference of generative flow networks (GFlowNets) when sampling objects. The method reparameterizes flow functions using learnable potential functions, addressing the issue of misleading training signals when there are large energy fluctuations along the sequence of actions."
}