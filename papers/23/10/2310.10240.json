{
    "title": "The Mixtures and the Neural Critics: On the Pointwise Mutual Information Profiles of Fine Distributions. (arXiv:2310.10240v1 [stat.ML])",
    "abstract": "Mutual information quantifies the dependence between two random variables and remains invariant under diffeomorphisms. In this paper, we explore the pointwise mutual information profile, an extension of mutual information that maintains this invariance. We analytically describe the profiles of multivariate normal distributions and introduce the family of fine distributions, for which the profile can be accurately approximated using Monte Carlo methods. We then show how fine distributions can be used to study the limitations of existing mutual information estimators, investigate the behavior of neural critics used in variational estimators, and understand the effect of experimental outliers on mutual information estimation. Finally, we show how fine distributions can be used to obtain model-based Bayesian estimates of mutual information, suitable for problems with available domain expertise in which uncertainty quantification is necessary.",
    "link": "http://arxiv.org/abs/2310.10240",
    "context": "Title: The Mixtures and the Neural Critics: On the Pointwise Mutual Information Profiles of Fine Distributions. (arXiv:2310.10240v1 [stat.ML])\nAbstract: Mutual information quantifies the dependence between two random variables and remains invariant under diffeomorphisms. In this paper, we explore the pointwise mutual information profile, an extension of mutual information that maintains this invariance. We analytically describe the profiles of multivariate normal distributions and introduce the family of fine distributions, for which the profile can be accurately approximated using Monte Carlo methods. We then show how fine distributions can be used to study the limitations of existing mutual information estimators, investigate the behavior of neural critics used in variational estimators, and understand the effect of experimental outliers on mutual information estimation. Finally, we show how fine distributions can be used to obtain model-based Bayesian estimates of mutual information, suitable for problems with available domain expertise in which uncertainty quantification is necessary.",
    "path": "papers/23/10/2310.10240.json",
    "total_tokens": 951,
    "translated_title": "混合物与神经批评家：关于精细分布的点间互信息的研究",
    "translated_abstract": "互信息量化了两个随机变量之间的依赖关系，并且在微分同胚下保持不变。在本文中，我们探讨了点间互信息的特征，这是互信息的推广形式，保持了这种不变性。我们在解析上描述了多元正态分布的特征，并引入了细分布家族，通过蒙特卡洛方法可以准确地逼近这种特征。然后，我们展示了如何利用细分布来研究现有互信息估计器的局限性，调查在变分估计器中使用的神经批评家的行为，并了解实验异常值对互信息估计的影响。最后，我们展示了如何利用细分布来获得基于模型的贝叶斯估计的互信息，适用于具有可用领域专业知识且需要不确定性量化的问题。",
    "tldr": "本文研究了点间互信息的特征，引入了细分布家族来解决现有互信息估计器的局限性，并探究了神经批评家在变分估计器中的行为，以及实验异常值对互信息估计的影响。此外，还介绍了基于模型的贝叶斯估计的方法，适用于具有领域专业知识且需要不确定性量化的问题。",
    "en_tdlr": "This paper investigates the characteristics of pointwise mutual information profiles, introduces the family of fine distributions to address the limitations of existing mutual information estimators, and explores the behavior of neural critics in variational estimators and the impact of experimental outliers on mutual information estimation. Additionally, it presents a model-based Bayesian estimation method suitable for problems with available domain expertise and the need for uncertainty quantification."
}