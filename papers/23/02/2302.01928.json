{
    "title": "Aligning Robot and Human Representations. (arXiv:2302.01928v2 [cs.RO] UPDATED)",
    "abstract": "To act in the world, robots rely on a representation of salient task aspects: for example, to carry a coffee mug, a robot may consider movement efficiency or mug orientation in its behavior. However, if we want robots to act for and with people, their representations must not be just functional but also reflective of what humans care about, i.e. they must be aligned. We observe that current learning approaches suffer from representation misalignment, where the robot's learned representation does not capture the human's representation. We suggest that because humans are the ultimate evaluator of robot performance, we must explicitly focus our efforts on aligning learned representations with humans, in addition to learning the downstream task. We advocate that current representation learning approaches in robotics should be studied from the perspective of how well they accomplish the objective of representation alignment. We mathematically define the problem, identify its key desiderata,",
    "link": "http://arxiv.org/abs/2302.01928",
    "context": "Title: Aligning Robot and Human Representations. (arXiv:2302.01928v2 [cs.RO] UPDATED)\nAbstract: To act in the world, robots rely on a representation of salient task aspects: for example, to carry a coffee mug, a robot may consider movement efficiency or mug orientation in its behavior. However, if we want robots to act for and with people, their representations must not be just functional but also reflective of what humans care about, i.e. they must be aligned. We observe that current learning approaches suffer from representation misalignment, where the robot's learned representation does not capture the human's representation. We suggest that because humans are the ultimate evaluator of robot performance, we must explicitly focus our efforts on aligning learned representations with humans, in addition to learning the downstream task. We advocate that current representation learning approaches in robotics should be studied from the perspective of how well they accomplish the objective of representation alignment. We mathematically define the problem, identify its key desiderata,",
    "path": "papers/23/02/2302.01928.json",
    "total_tokens": 876,
    "translated_title": "机器人与人类表征的对齐",
    "translated_abstract": "为了在世界中行动，机器人依赖于一个凸显任务关键方面的表示：例如，为了搬运咖啡杯，机器人可能会考虑动作效率或杯子的方向。然而，如果我们希望机器人为人类而行动，它们的表示不能只是功能性的，还必须反映人类关心的事物，即它们必须对齐。我们观察到当前的学习方法存在表示不对齐的问题，即机器人学习的表示不能捕捉到人类的表示。我们认为，因为人类是机器人表现的最终评估者，所以我们必须明确地将我们的努力集中在与人类的表征对齐上，而不仅仅是学习下游任务。我们提倡从对表征对齐目标的完成程度的角度研究当前机器人表征学习方法。我们在数学上定义了这个问题，并确定了它的关键要求。",
    "tldr": "本文研究了机器人与人类表征之间的对齐问题，指出了当前学习方法存在的表示不对齐的困境，并建议应将机器人表征学习方法从实现任务目标的角度转向与人类表征对齐的问题。",
    "en_tdlr": "This paper focuses on the alignment of robot and human representations, highlighting the challenges of representation misalignment in current learning approaches. It suggests shifting the focus of representation learning in robotics towards achieving alignment with human representations."
}