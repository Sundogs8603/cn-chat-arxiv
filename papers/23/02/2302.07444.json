{
    "title": "A Case Study on Designing Evaluations of ML Explanations with Simulated User Studies. (arXiv:2302.07444v2 [cs.LG] UPDATED)",
    "abstract": "When conducting user studies to ascertain the usefulness of model explanations in aiding human decision-making, it is important to use real-world use cases, data, and users. However, this process can be resource-intensive, allowing only a limited number of explanation methods to be evaluated. Simulated user evaluations (SimEvals), which use machine learning models as a proxy for human users, have been proposed as an intermediate step to select promising explanation methods. In this work, we conduct the first SimEvals on a real-world use case to evaluate whether explanations can better support ML-assisted decision-making in e-commerce fraud detection. We study whether SimEvals can corroborate findings from a user study conducted in this fraud detection context. In particular, we find that SimEvals suggest that all considered explainers are equally performant, and none beat a baseline without explanations -- this matches the conclusions of the original user study. Such correspondences be",
    "link": "http://arxiv.org/abs/2302.07444",
    "context": "Title: A Case Study on Designing Evaluations of ML Explanations with Simulated User Studies. (arXiv:2302.07444v2 [cs.LG] UPDATED)\nAbstract: When conducting user studies to ascertain the usefulness of model explanations in aiding human decision-making, it is important to use real-world use cases, data, and users. However, this process can be resource-intensive, allowing only a limited number of explanation methods to be evaluated. Simulated user evaluations (SimEvals), which use machine learning models as a proxy for human users, have been proposed as an intermediate step to select promising explanation methods. In this work, we conduct the first SimEvals on a real-world use case to evaluate whether explanations can better support ML-assisted decision-making in e-commerce fraud detection. We study whether SimEvals can corroborate findings from a user study conducted in this fraud detection context. In particular, we find that SimEvals suggest that all considered explainers are equally performant, and none beat a baseline without explanations -- this matches the conclusions of the original user study. Such correspondences be",
    "path": "papers/23/02/2302.07444.json",
    "total_tokens": 927,
    "translated_title": "基于模拟用户研究设计机器学习解释性评估的案例研究",
    "translated_abstract": "当进行用户研究以确定模型解释在帮助人类决策方面的有效性时，使用真实世界的用例、数据和用户非常重要。然而，这个过程可能需要耗费大量资源，使得只能评估少量的解释方法。已经提出了使用机器学习模型作为人类用户代理的模拟用户评估（SimEvals）作为选择有前景的解释方法的中间步骤。在这项工作中，我们对一个真实世界的用例进行了第一次 SimEvals，以评估解释是否可以更好地支持在电子商务欺诈检测中进行机器学习辅助决策。我们研究了 SimEvals 是否能够证实在这个欺诈检测背景下进行的用户研究的结果。特别地，我们发现 SimEvals 表明，所有考虑的解释器性能相当，并且没有一个能够超过没有解释的基准 -- 这与原始用户研究的结论相符。这些对应关系",
    "tldr": "本研究进行了一项真实用例的“SimEvals”评估，以评估在电子商务欺诈检测中解释是否可以更好地支持机器学习辅助决策，并证实了其与用户研究的结论一致。"
}