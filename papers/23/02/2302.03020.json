{
    "title": "RLSbench: Domain Adaptation Under Relaxed Label Shift. (arXiv:2302.03020v2 [cs.LG] UPDATED)",
    "abstract": "Despite the emergence of principled methods for domain adaptation under label shift, their sensitivity to shifts in class conditional distributions is precariously under explored. Meanwhile, popular deep domain adaptation heuristics tend to falter when faced with label proportions shifts. While several papers modify these heuristics in attempts to handle label proportions shifts, inconsistencies in evaluation standards, datasets, and baselines make it difficult to gauge the current best practices. In this paper, we introduce RLSbench, a large-scale benchmark for relaxed label shift, consisting of $>$500 distribution shift pairs spanning vision, tabular, and language modalities, with varying label proportions. Unlike existing benchmarks, which primarily focus on shifts in class-conditional $p(x|y)$, our benchmark also focuses on label marginal shifts. First, we assess 13 popular domain adaptation methods, demonstrating more widespread failures under label proportion shifts than were pre",
    "link": "http://arxiv.org/abs/2302.03020",
    "context": "Title: RLSbench: Domain Adaptation Under Relaxed Label Shift. (arXiv:2302.03020v2 [cs.LG] UPDATED)\nAbstract: Despite the emergence of principled methods for domain adaptation under label shift, their sensitivity to shifts in class conditional distributions is precariously under explored. Meanwhile, popular deep domain adaptation heuristics tend to falter when faced with label proportions shifts. While several papers modify these heuristics in attempts to handle label proportions shifts, inconsistencies in evaluation standards, datasets, and baselines make it difficult to gauge the current best practices. In this paper, we introduce RLSbench, a large-scale benchmark for relaxed label shift, consisting of $>$500 distribution shift pairs spanning vision, tabular, and language modalities, with varying label proportions. Unlike existing benchmarks, which primarily focus on shifts in class-conditional $p(x|y)$, our benchmark also focuses on label marginal shifts. First, we assess 13 popular domain adaptation methods, demonstrating more widespread failures under label proportion shifts than were pre",
    "path": "papers/23/02/2302.03020.json",
    "total_tokens": 913,
    "translated_title": "RLSbench: 宽松标签偏移下的领域自适应",
    "translated_abstract": "尽管出现了解决标签偏移下领域自适应的原则性方法，但对于类条件分布的偏移敏感性却未得到充分探索。同时，流行的深度领域自适应启发式方法在面对标签比例偏移时往往疲软。虽然有几篇论文改进了这些启发方法以尝试处理标签比例偏移，但评估标准、数据集和基线的不一致使得评估当前最佳实践变得困难。在这篇论文中，我们引入 RLSbench，一个大规模的宽松标签偏移基准，涵盖500多个分布偏移对，跨视觉、表格和语言模式，具有不同的标签比例。与现有基准主要关注类条件$p(x|y)$偏移不同，我们的基准还关注标签边际偏移。首先，我们评估了13种流行的领域自适应方法，证明在标签比例偏移下更普遍地失败。",
    "tldr": "本文介绍了 RLSbench，它是一个大规模基准，用于宽松标签偏移。与现有基准不同，它旨在评估领域自适应方法在标签边际偏移下的表现。"
}