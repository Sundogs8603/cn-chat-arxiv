{
    "title": "Similarity, Compression and Local Steps: Three Pillars of Efficient Communications for Distributed Variational Inequalities",
    "abstract": "arXiv:2302.07615v2 Announce Type: replace-cross  Abstract: Variational inequalities are a broad and flexible class of problems that includes minimization, saddle point, and fixed point problems as special cases. Therefore, variational inequalities are used in various applications ranging from equilibrium search to adversarial learning. With the increasing size of data and models, today's instances demand parallel and distributed computing for real-world machine learning problems, most of which can be represented as variational inequalities. Meanwhile, most distributed approaches have a significant bottleneck - the cost of communications. The three main techniques to reduce the total number of communication rounds and the cost of one such round are the similarity of local functions, compression of transmitted information, and local updates. In this paper, we combine all these approaches. Such a triple synergy did not exist before for variational inequalities and saddle problems, nor eve",
    "link": "https://arxiv.org/abs/2302.07615",
    "context": "Title: Similarity, Compression and Local Steps: Three Pillars of Efficient Communications for Distributed Variational Inequalities\nAbstract: arXiv:2302.07615v2 Announce Type: replace-cross  Abstract: Variational inequalities are a broad and flexible class of problems that includes minimization, saddle point, and fixed point problems as special cases. Therefore, variational inequalities are used in various applications ranging from equilibrium search to adversarial learning. With the increasing size of data and models, today's instances demand parallel and distributed computing for real-world machine learning problems, most of which can be represented as variational inequalities. Meanwhile, most distributed approaches have a significant bottleneck - the cost of communications. The three main techniques to reduce the total number of communication rounds and the cost of one such round are the similarity of local functions, compression of transmitted information, and local updates. In this paper, we combine all these approaches. Such a triple synergy did not exist before for variational inequalities and saddle problems, nor eve",
    "path": "papers/23/02/2302.07615.json",
    "total_tokens": 824,
    "translated_title": "相似性、压缩和局部步骤：分布式变分不等式高效通信的三大支柱",
    "translated_abstract": "变分不等式是一个广泛而灵活的问题类，包括最小化、鞍点和不动点问题作为特例。因此，变分不等式在各种应用中被使用，从均衡搜索到对抗学习都有涉及。随着数据和模型规模的增加，当今的实例需要并行和分布式计算来解决现实世界中的机器学习问题，其中大部分可以表示为变分不等式。同时，大多数分布式方法存在一个重大瓶颈 - 通信成本。减少通信轮次的总数和每轮成本的三种主要技术是本地函数的相似性、传输信息的压缩和局部更新。本文结合了所有这些方法。对于变分不等式和鞍点问题来说，这样的三重协同作用以前并不存在。",
    "tldr": "相似性、压缩和局部更新是本文提出的三大技术，用于减少分布式变分不等式问题中通信轮次和成本，实现了前所未有的三重协同作用。",
    "en_tdlr": "Similarity, compression, and local updates are the three main techniques proposed in this paper to reduce the number of communication rounds and costs in distributed variational inequalities problems, achieving unprecedented triple synergy."
}