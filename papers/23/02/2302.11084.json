{
    "title": "Test-Time Distribution Normalization for Contrastively Learned Vision-language Models. (arXiv:2302.11084v2 [cs.LG] UPDATED)",
    "abstract": "Advances in the field of vision-language contrastive learning have made it possible for many downstream applications to be carried out efficiently and accurately by simply taking the dot product between image and text representations. One of the most representative approaches proposed recently known as CLIP has garnered widespread adoption due to its effectiveness. CLIP is trained with an InfoNCE loss that takes into account both positive and negative samples to help learn a much more robust representation space. This paper reveals that the common downstream practice of taking a dot product is only a zeroth-order approximation of the optimization goal, resulting in a loss of information during test-time. Intuitively, since the model has been optimized based on the InfoNCE loss, test-time procedures should also be in alignment. The question lies in how one can retrieve any semblance of negative samples information during inference in a computationally efficient way. To this end, we prop",
    "link": "http://arxiv.org/abs/2302.11084",
    "context": "Title: Test-Time Distribution Normalization for Contrastively Learned Vision-language Models. (arXiv:2302.11084v2 [cs.LG] UPDATED)\nAbstract: Advances in the field of vision-language contrastive learning have made it possible for many downstream applications to be carried out efficiently and accurately by simply taking the dot product between image and text representations. One of the most representative approaches proposed recently known as CLIP has garnered widespread adoption due to its effectiveness. CLIP is trained with an InfoNCE loss that takes into account both positive and negative samples to help learn a much more robust representation space. This paper reveals that the common downstream practice of taking a dot product is only a zeroth-order approximation of the optimization goal, resulting in a loss of information during test-time. Intuitively, since the model has been optimized based on the InfoNCE loss, test-time procedures should also be in alignment. The question lies in how one can retrieve any semblance of negative samples information during inference in a computationally efficient way. To this end, we prop",
    "path": "papers/23/02/2302.11084.json",
    "total_tokens": 862,
    "translated_title": "对比学习的视觉-语言模型的测试时分布归一化",
    "translated_abstract": "视觉-语言对比学习的进展使得许多下游应用可以通过简单地对图像和文本表示进行点乘来高效准确地进行。最近提出的代表性方法之一是CLIP，由于其有效性已经得到了广泛的采用。CLIP使用InfoNCE损失进行训练，该损失同时考虑了正样本和负样本，以帮助学习更加稳健的表示空间。本文揭示了常见的下游实践——进行点乘仅仅是对优化目标的零阶近似，导致了测试时信息的丢失。直观上，由于模型是基于InfoNCE损失进行优化的，测试时的过程也应该保持一致。问题在于如何以一种计算高效的方式检索到任何负样本信息。为此，我们提出了一种测试时分布归一化的方法",
    "tldr": "这篇论文介绍了一个针对对比学习的视觉-语言模型的测试时分布归一化的方法，解决了常见的点乘操作导致测试时信息丢失的问题，提高了模型在测试阶段的准确性和效率。",
    "en_tdlr": "This paper presents a method for test-time distribution normalization for contrastive learned vision-language models, addressing the issue of information loss during testing caused by the common dot product operation. It improves the accuracy and efficiency of the model during the testing phase."
}