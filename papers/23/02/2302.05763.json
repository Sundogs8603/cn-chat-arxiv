{
    "title": "Towards Multi-User Activity Recognition through Facilitated Training Data and Deep Learning for Human-Robot Collaboration Applications. (arXiv:2302.05763v2 [cs.LG] UPDATED)",
    "abstract": "Human-robot interaction (HRI) research is progressively addressing multi-party scenarios, where a robot interacts with more than one human user at the same time. Conversely, research is still at an early stage for human-robot collaboration. The use of machine learning techniques to handle such type of collaboration requires data that are less feasible to produce than in a typical HRC setup. This work outlines scenarios of concurrent tasks for non-dyadic HRC applications. Based upon these concepts, this study also proposes an alternative way of gathering data regarding multi-user activity, by collecting data related to single users and merging them in post-processing, to reduce the effort involved in producing recordings of pair settings. To validate this statement, 3D skeleton poses of activity of single users were collected and merged in pairs. After this, such datapoints were used to separately train a long short-term memory (LSTM) network and a variational autoencoder (VAE) composed",
    "link": "http://arxiv.org/abs/2302.05763",
    "context": "Title: Towards Multi-User Activity Recognition through Facilitated Training Data and Deep Learning for Human-Robot Collaboration Applications. (arXiv:2302.05763v2 [cs.LG] UPDATED)\nAbstract: Human-robot interaction (HRI) research is progressively addressing multi-party scenarios, where a robot interacts with more than one human user at the same time. Conversely, research is still at an early stage for human-robot collaboration. The use of machine learning techniques to handle such type of collaboration requires data that are less feasible to produce than in a typical HRC setup. This work outlines scenarios of concurrent tasks for non-dyadic HRC applications. Based upon these concepts, this study also proposes an alternative way of gathering data regarding multi-user activity, by collecting data related to single users and merging them in post-processing, to reduce the effort involved in producing recordings of pair settings. To validate this statement, 3D skeleton poses of activity of single users were collected and merged in pairs. After this, such datapoints were used to separately train a long short-term memory (LSTM) network and a variational autoencoder (VAE) composed",
    "path": "papers/23/02/2302.05763.json",
    "total_tokens": 859,
    "translated_title": "基于深度学习和辅助训练数据的多用户活动识别实现人机协作",
    "translated_abstract": "人机交互研究逐渐关注多方面场景，即机器人与多个人用户同时交互的场景。 然而，在人机协作方面，研究仍处于早期阶段。处理此类合作的机器学习技术需要的数据比典型的人机交互设置中更不可行。本研究提出了非二元人机协作应用的并行任务场景，并提议一种替代方法来收集与多用户活动相关的数据，即收集与单个用户相关的数据并在后处理中合并它们，以减少产生成双设置录制的努力。收集了单个用户的活动三维骨架姿势并将它们合并成一对来验证该语句，随后，这些数据点被用于分别训练由LSTM网络和VAE 混合而成的模型。",
    "tldr": "本研究通过收集单个用户数据并在后处理中合并数据的方法，实现了多用户活动的识别，有望用于人机协作领域。",
    "en_tdlr": "This study proposes a method to recognize multi-user activities through collecting and merging data related to single users, which can reduce the effort involved in producing recordings of pair settings and has the potential to apply in the field of human-robot collaboration."
}