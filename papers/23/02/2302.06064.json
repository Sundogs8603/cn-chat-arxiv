{
    "title": "Provably Safe Reinforcement Learning with Step-wise Violation Constraints. (arXiv:2302.06064v3 [cs.LG] UPDATED)",
    "abstract": "In this paper, we investigate a novel safe reinforcement learning problem with step-wise violation constraints. Our problem differs from existing works in that we consider stricter step-wise violation constraints and do not assume the existence of safe actions, making our formulation more suitable for safety-critical applications which need to ensure safety in all decision steps and may not always possess safe actions, e.g., robot control and autonomous driving. We propose a novel algorithm SUCBVI, which guarantees $\\widetilde{O}(\\sqrt{ST})$ step-wise violation and $\\widetilde{O}(\\sqrt{H^3SAT})$ regret. Lower bounds are provided to validate the optimality in both violation and regret performance with respect to $S$ and $T$. Moreover, we further study a novel safe reward-free exploration problem with step-wise violation constraints. For this problem, we design an $(\\varepsilon,\\delta)$-PAC algorithm SRF-UCRL, which achieves nearly state-of-the-art sample complexity $\\widetilde{O}((\\frac",
    "link": "http://arxiv.org/abs/2302.06064",
    "context": "Title: Provably Safe Reinforcement Learning with Step-wise Violation Constraints. (arXiv:2302.06064v3 [cs.LG] UPDATED)\nAbstract: In this paper, we investigate a novel safe reinforcement learning problem with step-wise violation constraints. Our problem differs from existing works in that we consider stricter step-wise violation constraints and do not assume the existence of safe actions, making our formulation more suitable for safety-critical applications which need to ensure safety in all decision steps and may not always possess safe actions, e.g., robot control and autonomous driving. We propose a novel algorithm SUCBVI, which guarantees $\\widetilde{O}(\\sqrt{ST})$ step-wise violation and $\\widetilde{O}(\\sqrt{H^3SAT})$ regret. Lower bounds are provided to validate the optimality in both violation and regret performance with respect to $S$ and $T$. Moreover, we further study a novel safe reward-free exploration problem with step-wise violation constraints. For this problem, we design an $(\\varepsilon,\\delta)$-PAC algorithm SRF-UCRL, which achieves nearly state-of-the-art sample complexity $\\widetilde{O}((\\frac",
    "path": "papers/23/02/2302.06064.json",
    "total_tokens": 1017,
    "translated_title": "具有逐步违规约束的可证明安全的强化学习",
    "translated_abstract": "本文研究了一种具有逐步违规约束的新型安全强化学习问题。我们的问题不同于现有的研究，我们考虑更严格的逐步违规约束，并且不假定存在安全动作，使得我们的表述更适合需要在所有决策步骤中确保安全且可能不总是具有安全动作的安全关键应用，例如机器人控制和自动驾驶。我们提出了一种新的算法SUCBVI，该算法保证$\\tilde{O}(\\sqrt{ST})$的逐步违规和$\\tilde{O}(\\sqrt{H^3SAT})$的后悔。我们提供了下界，以验证对于$S$和$T$的违规和后悔性能的最优性。此外，我们进一步研究了一种具有逐步违规约束的新型安全无奖探索问题。对于这个问题，我们设计了一个$(\\varepsilon,\\delta)$-PAC算法SRF-UCRL，其实现了几乎最先进的样本复杂度$\\tilde{O}((\\frac{nHS^2A}{\\epsilon})^{\\frac{1}{3}}(SAT)^{\\frac{2}{3}})$。",
    "tldr": "本文提出了一种具有逐步违规约束的新型安全强化学习问题和解决方案SUCBVI，并证明了其最优性能，同时研究了具有逐步违规约束的安全无奖探索问题并设计了算法SRF-UCRL。",
    "en_tdlr": "This paper proposes a novel safe reinforcement learning problem and solution with step-wise violation constraints (SUCBVI) for safety-critical applications that do not always possess safe actions. It also studies a safe reward-free exploration problem with the same constraints and designs an algorithm (SRF-UCRL) with nearly state-of-the-art sample complexity."
}