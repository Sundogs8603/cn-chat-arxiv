{
    "title": "GAN-based Vertical Federated Learning for Label Protection in Binary Classification. (arXiv:2302.02245v2 [cs.LG] UPDATED)",
    "abstract": "Split learning (splitNN) has emerged as a popular strategy for addressing the high computational costs and low modeling efficiency in Vertical Federated Learning (VFL). However, despite its popularity, vanilla splitNN lacks encryption protection, leaving it vulnerable to privacy leakage issues, especially Label Leakage from Gradients (LLG). Motivated by the LLG issue resulting from the use of labels during training, we propose the Generative Adversarial Federated Model (GAFM), a novel method designed specifically to enhance label privacy protection by integrating splitNN with Generative Adversarial Networks (GANs). GAFM leverages GANs to indirectly utilize label information by learning the label distribution rather than relying on explicit labels, thereby mitigating LLG. GAFM also employs an additional cross-entropy loss based on the noisy labels to further improve the prediction accuracy. Our ablation experiment demonstrates that the combination of GAN and the cross-entropy loss compo",
    "link": "http://arxiv.org/abs/2302.02245",
    "context": "Title: GAN-based Vertical Federated Learning for Label Protection in Binary Classification. (arXiv:2302.02245v2 [cs.LG] UPDATED)\nAbstract: Split learning (splitNN) has emerged as a popular strategy for addressing the high computational costs and low modeling efficiency in Vertical Federated Learning (VFL). However, despite its popularity, vanilla splitNN lacks encryption protection, leaving it vulnerable to privacy leakage issues, especially Label Leakage from Gradients (LLG). Motivated by the LLG issue resulting from the use of labels during training, we propose the Generative Adversarial Federated Model (GAFM), a novel method designed specifically to enhance label privacy protection by integrating splitNN with Generative Adversarial Networks (GANs). GAFM leverages GANs to indirectly utilize label information by learning the label distribution rather than relying on explicit labels, thereby mitigating LLG. GAFM also employs an additional cross-entropy loss based on the noisy labels to further improve the prediction accuracy. Our ablation experiment demonstrates that the combination of GAN and the cross-entropy loss compo",
    "path": "papers/23/02/2302.02245.json",
    "total_tokens": 941,
    "translated_title": "面向二元分类中标签保护的基于GAN的竖直联邦学习方法",
    "translated_abstract": "分裂学习（SplitNN）已成为解决竖直联邦学习（VFL）中高计算成本和低建模效率问题的常用策略。然而，尽管SplitNN很受欢迎，但其缺乏加密保护，因此容易出现隐私泄露问题，特别是梯度标签泄漏（LLG）。出于对使用标签训练引起的LLG问题的关注，我们提出了生成对抗竖直联邦模型（GAFM），这是一种新方法，专门设计用于通过将SplitNN与生成对抗网络（GAN）集成来增强标签隐私保护。GAFM利用GAN间接利用标签信息，学习标签分布而不是依赖于显式标签，从而减轻LLG问题。 GAFM还采用基于噪声标签的交叉熵损失，进一步提高预测准确性。我们的消融实验表明，GAN和交叉熵损失的组合可以显著提高模型的性能。",
    "tldr": "GAFM是一种用于竖直联邦学习中标签保护的新方法，它利用生成对抗网络间接利用标签信息来减轻梯度标签泄漏问题，并采用交叉熵损失来提高预测准确性。",
    "en_tdlr": "GAFM is a novel method for label protection in vertical federated learning, which leverages Generative Adversarial Networks to indirectly utilize label information and mitigate Label Leakage from Gradients (LLG). It also employs a cross-entropy loss based on noisy labels to improve prediction accuracy."
}