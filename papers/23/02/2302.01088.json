{
    "title": "Sketched Ridgeless Linear Regression: The Role of Downsampling. (arXiv:2302.01088v2 [math.ST] UPDATED)",
    "abstract": "Overparametrization often helps improve the generalization performance. This paper presents a dual view of overparametrization suggesting that downsampling may also help generalize. Focusing on the proportional regime $m\\asymp n \\asymp p$, where $m$ represents the sketching size, $n$ is the sample size, and $p$ is the feature dimensionality, we investigate two out-of-sample prediction risks of the sketched ridgeless least square estimator. Our findings challenge conventional beliefs by showing that downsampling does not always harm generalization but can actually improve it in certain cases. We identify the optimal sketching size that minimizes out-of-sample prediction risks and demonstrate that the optimally sketched estimator exhibits stabler risk curves, eliminating the peaks of those for the full-sample estimator. To facilitate practical implementation, we propose an empirical procedure to determine the optimal sketching size. Finally, we extend our analysis to cover central limit ",
    "link": "http://arxiv.org/abs/2302.01088",
    "context": "Title: Sketched Ridgeless Linear Regression: The Role of Downsampling. (arXiv:2302.01088v2 [math.ST] UPDATED)\nAbstract: Overparametrization often helps improve the generalization performance. This paper presents a dual view of overparametrization suggesting that downsampling may also help generalize. Focusing on the proportional regime $m\\asymp n \\asymp p$, where $m$ represents the sketching size, $n$ is the sample size, and $p$ is the feature dimensionality, we investigate two out-of-sample prediction risks of the sketched ridgeless least square estimator. Our findings challenge conventional beliefs by showing that downsampling does not always harm generalization but can actually improve it in certain cases. We identify the optimal sketching size that minimizes out-of-sample prediction risks and demonstrate that the optimally sketched estimator exhibits stabler risk curves, eliminating the peaks of those for the full-sample estimator. To facilitate practical implementation, we propose an empirical procedure to determine the optimal sketching size. Finally, we extend our analysis to cover central limit ",
    "path": "papers/23/02/2302.01088.json",
    "total_tokens": 970,
    "translated_title": "通过下采样，描绘无岗位线性回归：下采样的作用",
    "translated_abstract": "过度参数化通常有助于提高泛化性能。本文提出了过度参数化的双重视角，并认为下采样也可以帮助泛化。我们针对比例区域$m\\asymp n \\asymp p$进行了研究，其中$m$表示缩略图大小，$n$是样本大小，$p$是特征维度，研究了描绘无岗位最小二乘估计器的两个样本外预测风险。我们的发现挑战了传统观念，表明下采样不总是对泛化有害，而在某些情况下实际上可以改善泛化。我们确定了最小化样本外预测风险的最佳缩略图大小，并证明了最优缩略图估计器显示出更稳定的风险曲线，消除了完全样本估计器的峰值。为了便于实际实施，我们提出了一种确定最佳缩略图大小的经验方法。最后，我们扩展了我们的分析，涵盖了中心极限定理。",
    "tldr": "本文研究了描绘无岗位最小二乘估计器在比例区域下的样本外预测风险，挑战了传统观念，并发现下采样在某些情况下可以改善泛化，我们确定了最佳缩略图大小并提出了实际实施方法。",
    "en_tdlr": "This paper investigates the out-of-sample prediction risks of sketched ridgeless least square estimator in the proportional regime and challenges conventional beliefs by showing that downsampling can improve generalization in certain cases. The optimal sketching size is identified and an empirical procedure is proposed for practical implementation."
}