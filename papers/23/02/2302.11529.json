{
    "title": "Modular Deep Learning. (arXiv:2302.11529v2 [cs.LG] UPDATED)",
    "abstract": "Transfer learning has recently become the dominant paradigm of machine learning. Pre-trained models fine-tuned for downstream tasks achieve better performance with fewer labelled examples. Nonetheless, it remains unclear how to develop models that specialise towards multiple tasks without incurring negative interference and that generalise systematically to non-identically distributed tasks. Modular deep learning has emerged as a promising solution to these challenges. In this framework, units of computation are often implemented as autonomous parameter-efficient modules. Information is conditionally routed to a subset of modules and subsequently aggregated. These properties enable positive transfer and systematic generalisation by separating computation from routing and updating modules locally. We offer a survey of modular architectures, providing a unified view over several threads of research that evolved independently in the scientific literature. Moreover, we explore various addi",
    "link": "http://arxiv.org/abs/2302.11529",
    "context": "Title: Modular Deep Learning. (arXiv:2302.11529v2 [cs.LG] UPDATED)\nAbstract: Transfer learning has recently become the dominant paradigm of machine learning. Pre-trained models fine-tuned for downstream tasks achieve better performance with fewer labelled examples. Nonetheless, it remains unclear how to develop models that specialise towards multiple tasks without incurring negative interference and that generalise systematically to non-identically distributed tasks. Modular deep learning has emerged as a promising solution to these challenges. In this framework, units of computation are often implemented as autonomous parameter-efficient modules. Information is conditionally routed to a subset of modules and subsequently aggregated. These properties enable positive transfer and systematic generalisation by separating computation from routing and updating modules locally. We offer a survey of modular architectures, providing a unified view over several threads of research that evolved independently in the scientific literature. Moreover, we explore various addi",
    "path": "papers/23/02/2302.11529.json",
    "total_tokens": 814,
    "translated_title": "模块化深度学习",
    "translated_abstract": "迁移学习近年来已成为机器学习的主要范式，预训练模型在下游任务中经过微调能够以更少的标记示例获得更好的性能。然而，如何开发能够专注于多个任务而不会产生负面干扰，并且能够系统地推广到非相同分布任务仍然不清楚。模块化深度学习已经成为应对这些挑战的一种有希望的解决方案。在这个框架中，计算单元通常被实现为自主参数高效的模块。信息被有条件地路由到一部分模块，然后进行汇总。这些特性通过将计算与路由和局部更新模块分离，实现了积极迁移和系统化的推广。我们提供了对模块化架构的调查，提供了在科学文献中独立演化的几个研究方向的统一视角。此外，我们还探索了各种附加...",
    "tldr": "模块化深度学习是一种有前景的解决方案，通过将计算与路由和局部更新模块分离，实现了积极迁移和系统化的推广。",
    "en_tdlr": "Modular deep learning is a promising solution that separates computation from routing and updating modules, enabling positive transfer and systematic generalization."
}