{
    "title": "On the Privacy-Robustness-Utility Trilemma in Distributed Learning. (arXiv:2302.04787v2 [cs.LG] UPDATED)",
    "abstract": "The ubiquity of distributed machine learning (ML) in sensitive public domain applications calls for algorithms that protect data privacy, while being robust to faults and adversarial behaviors. Although privacy and robustness have been extensively studied independently in distributed ML, their synthesis remains poorly understood. We present the first tight analysis of the error incurred by any algorithm ensuring robustness against a fraction of adversarial machines, as well as differential privacy (DP) for honest machines' data against any other curious entity. Our analysis exhibits a fundamental trade-off between privacy, robustness, and utility. To prove our lower bound, we consider the case of mean estimation, subject to distributed DP and robustness constraints, and devise reductions to centralized estimation of one-way marginals. We prove our matching upper bound by presenting a new distributed ML algorithm using a high-dimensional robust aggregation rule. The latter amortizes the",
    "link": "http://arxiv.org/abs/2302.04787",
    "context": "Title: On the Privacy-Robustness-Utility Trilemma in Distributed Learning. (arXiv:2302.04787v2 [cs.LG] UPDATED)\nAbstract: The ubiquity of distributed machine learning (ML) in sensitive public domain applications calls for algorithms that protect data privacy, while being robust to faults and adversarial behaviors. Although privacy and robustness have been extensively studied independently in distributed ML, their synthesis remains poorly understood. We present the first tight analysis of the error incurred by any algorithm ensuring robustness against a fraction of adversarial machines, as well as differential privacy (DP) for honest machines' data against any other curious entity. Our analysis exhibits a fundamental trade-off between privacy, robustness, and utility. To prove our lower bound, we consider the case of mean estimation, subject to distributed DP and robustness constraints, and devise reductions to centralized estimation of one-way marginals. We prove our matching upper bound by presenting a new distributed ML algorithm using a high-dimensional robust aggregation rule. The latter amortizes the",
    "path": "papers/23/02/2302.04787.json",
    "total_tokens": 1097,
    "translated_title": "关于分布式学习中隐私、鲁棒性和实用性三难题的探讨",
    "translated_abstract": "分布式机器学习在敏感公共领域应用中的普及需要保护数据隐私的算法，同时对故障和敌对行为具有鲁棒性。虽然隐私和鲁棒性在分布式机器学习中都有广泛的研究，但它们的综合仍然不为人所理解。本文提出了第一个紧密分析了任何算法在确保对抗性机器的鲁棒性和诚实机器的差分隐私方面会产生误差的模型，展示了隐私、鲁棒性和实用性之间的基本权衡。我们通过平均估计的案例来证明我们的下限，并将其受到分布式差分隐私和鲁棒性约束的影响，使用了一些减少单向边际中心化估计的降低方法。我们通过提出一种新的分布式机器学习算法，使用高维度的鲁棒聚合规则证明了我们的上限匹配。后面所述的方法将计算成本分摊化，并获得了改进的效用-隐私权衡。我们的结果阐明了在隐私-鲁棒性-效用三难问题的背景下出现的交叉学科挑战，并可以指导大规模分布式机器学习系统的实际设计。",
    "tldr": "本文研究了分布式学习中隐私、鲁棒性和实用性之间的权衡关系，并证明了它们之间存在一种根本的平衡，同时提出了一种新的高维度鲁棒聚合规则的分布式机器学习算法，可以优化效用-隐私权衡。",
    "en_tdlr": "This paper investigates the trade-off between privacy, robustness, and utility in distributed learning, and proves the existence of a fundamental balance between them. It also presents a new distributed machine learning algorithm using a high-dimensional robust aggregation rule to optimize the utility-privacy trade-off."
}