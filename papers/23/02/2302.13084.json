{
    "title": "RemoteNet: Remote Sensing Image Segmentation Network based on Global-Local Information. (arXiv:2302.13084v2 [cs.CV] UPDATED)",
    "abstract": "Remotely captured images possess an immense scale and object appearance variability due to the complex scene. It becomes challenging to capture the underlying attributes in the global and local context for their segmentation. Existing networks struggle to capture the inherent features due to the cluttered background. To address these issues, we propose a remote sensing image segmentation network, RemoteNet, for semantic segmentation of remote sensing images. We capture the global and local features by leveraging the benefits of the transformer and convolution mechanisms. RemoteNet is an encoder-decoder design that uses multi-scale features. We construct an attention map module to generate channel-wise attention scores for fusing these features. We construct a global-local transformer block (GLTB) in the decoder network to support learning robust representations during a decoding phase. Further, we designed a feature refinement module to refine the fused output of the shallow stage enco",
    "link": "http://arxiv.org/abs/2302.13084",
    "context": "Title: RemoteNet: Remote Sensing Image Segmentation Network based on Global-Local Information. (arXiv:2302.13084v2 [cs.CV] UPDATED)\nAbstract: Remotely captured images possess an immense scale and object appearance variability due to the complex scene. It becomes challenging to capture the underlying attributes in the global and local context for their segmentation. Existing networks struggle to capture the inherent features due to the cluttered background. To address these issues, we propose a remote sensing image segmentation network, RemoteNet, for semantic segmentation of remote sensing images. We capture the global and local features by leveraging the benefits of the transformer and convolution mechanisms. RemoteNet is an encoder-decoder design that uses multi-scale features. We construct an attention map module to generate channel-wise attention scores for fusing these features. We construct a global-local transformer block (GLTB) in the decoder network to support learning robust representations during a decoding phase. Further, we designed a feature refinement module to refine the fused output of the shallow stage enco",
    "path": "papers/23/02/2302.13084.json",
    "total_tokens": 892,
    "translated_title": "RemoteNet: 基于全局-局部信息的遥感图像分割网络",
    "translated_abstract": "由于复杂的场景，远程捕获的图像具有巨大的尺度和物体外观的变化。对于其分割，捕捉全局和局部上下文中的潜在属性变得具有挑战性。现有的网络难以捕捉因杂乱的背景而产生的内在特征。为了解决这些问题，我们提出了一种用于遥感图像语义分割的遥感图像分割网络RemoteNet。我们通过利用Transformer和卷积机制的优势来捕捉全局和局部特征。RemoteNet采用编码解码器的设计，使用多尺度特征。我们构建了一个注意力映射模块来生成通道注意力分数，用于融合这些特征。我们在解码器网络中构建了一个全局-局部Transformer块（GLTB）来支持在解码阶段学习鲁棒表示。此外，我们设计了一个特征细化模块来优化浅层阶段编码器的融合输出。",
    "tldr": "本文提出了一种名为RemoteNet的遥感图像分割网络，通过使用全局-局部信息和多尺度特征，以及注意力机制和Transformer进行特征融合和学习，改进了遥感图像的语义分割性能。"
}