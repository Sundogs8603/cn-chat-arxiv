{
    "title": "Learning Hidden Markov Models Using Conditional Samples",
    "abstract": "arXiv:2302.14753v2 Announce Type: replace-cross  Abstract: This paper is concerned with the computational complexity of learning the Hidden Markov Model (HMM). Although HMMs are some of the most widely used tools in sequential and time series modeling, they are cryptographically hard to learn in the standard setting where one has access to i.i.d. samples of observation sequences. In this paper, we depart from this setup and consider an interactive access model, in which the algorithm can query for samples from the conditional distributions of the HMMs. We show that interactive access to the HMM enables computationally efficient learning algorithms, thereby bypassing cryptographic hardness. Specifically, we obtain efficient algorithms for learning HMMs in two settings:   (a) An easier setting where we have query access to the exact conditional probabilities. Here our algorithm runs in polynomial time and makes polynomially many queries to approximate any HMM in total variation distance.",
    "link": "https://arxiv.org/abs/2302.14753",
    "context": "Title: Learning Hidden Markov Models Using Conditional Samples\nAbstract: arXiv:2302.14753v2 Announce Type: replace-cross  Abstract: This paper is concerned with the computational complexity of learning the Hidden Markov Model (HMM). Although HMMs are some of the most widely used tools in sequential and time series modeling, they are cryptographically hard to learn in the standard setting where one has access to i.i.d. samples of observation sequences. In this paper, we depart from this setup and consider an interactive access model, in which the algorithm can query for samples from the conditional distributions of the HMMs. We show that interactive access to the HMM enables computationally efficient learning algorithms, thereby bypassing cryptographic hardness. Specifically, we obtain efficient algorithms for learning HMMs in two settings:   (a) An easier setting where we have query access to the exact conditional probabilities. Here our algorithm runs in polynomial time and makes polynomially many queries to approximate any HMM in total variation distance.",
    "path": "papers/23/02/2302.14753.json",
    "total_tokens": 858,
    "translated_title": "使用条件样本学习隐马尔可夫模型",
    "translated_abstract": "本文关注学习隐马尔可夫模型（HMM）的计算复杂性。虽然HMM是顺序和时间序列建模中最广泛使用的工具之一，但在标准设置下，即对观测序列的独立同分布（i.i.d.）样本具有访问权限的情况下，学习起来是具有密码学困难性的。本文偏离了这一设定，考虑了一种交互访问模型，在这种模型中，算法可以查询HMM的条件分布的样本。我们展示了对HMM的交互访问可以实现计算高效的学习算法，从而绕过密码学困难性。具体来说，我们设计了在两种情况下学习HMM的高效算法：（a）一种更容易的设置，我们可以查询准确条件概率。在这里，我们的算法在多项式时间内运行，并进行了多项式次查询，以在总变差距离中近似任何HMM。",
    "tldr": "本文提出了一种使用交互方式访问隐马尔可夫模型的条件分布样本的学习方法，实现了对HMM的高效学习算法，从而绕过了其密码学困难性。",
    "en_tdlr": "This paper introduces a learning method that uses interactive access to samples from the conditional distributions of Hidden Markov Models, enabling computationally efficient learning algorithms for HMMs and bypassing their cryptographic hardness."
}