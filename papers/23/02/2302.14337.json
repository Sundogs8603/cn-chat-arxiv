{
    "title": "UniFLG: Unified Facial Landmark Generator from Text or Speech. (arXiv:2302.14337v2 [cs.CV] UPDATED)",
    "abstract": "Talking face generation has been extensively investigated owing to its wide applicability. The two primary frameworks used for talking face generation comprise a text-driven framework, which generates synchronized speech and talking faces from text, and a speech-driven framework, which generates talking faces from speech. To integrate these frameworks, this paper proposes a unified facial landmark generator (UniFLG). The proposed system exploits end-to-end text-to-speech not only for synthesizing speech but also for extracting a series of latent representations that are common to text and speech, and feeds it to a landmark decoder to generate facial landmarks. We demonstrate that our system achieves higher naturalness in both speech synthesis and facial landmark generation compared to the state-of-the-art text-driven method. We further demonstrate that our system can generate facial landmarks from speech of speakers without facial video data or even speech data.",
    "link": "http://arxiv.org/abs/2302.14337",
    "context": "Title: UniFLG: Unified Facial Landmark Generator from Text or Speech. (arXiv:2302.14337v2 [cs.CV] UPDATED)\nAbstract: Talking face generation has been extensively investigated owing to its wide applicability. The two primary frameworks used for talking face generation comprise a text-driven framework, which generates synchronized speech and talking faces from text, and a speech-driven framework, which generates talking faces from speech. To integrate these frameworks, this paper proposes a unified facial landmark generator (UniFLG). The proposed system exploits end-to-end text-to-speech not only for synthesizing speech but also for extracting a series of latent representations that are common to text and speech, and feeds it to a landmark decoder to generate facial landmarks. We demonstrate that our system achieves higher naturalness in both speech synthesis and facial landmark generation compared to the state-of-the-art text-driven method. We further demonstrate that our system can generate facial landmarks from speech of speakers without facial video data or even speech data.",
    "path": "papers/23/02/2302.14337.json",
    "total_tokens": 898,
    "translated_title": "UniFLG: 文本或语音驱动的统一面部特征点生成器",
    "translated_abstract": "说话的面部生成已经被广泛研究了。用于说话的两种主要框架包括驱动于文本的框架，从文本生成同步的语音和说话的面孔，以及驱动于语音的框架，从语音生成说话的面孔。为了整合这些框架，本文提出了一个统一的面部特征点生成器（UniFLG）。该系统不仅利用端到端的文本到语音来合成语音，还利用其中的一系列潜在表示来从文本和语音中提取共同的信息，并将其输入到特征点解码器中生成面部特征点。我们证明了我们的系统在语音合成和面部特征点生成方面都比最先进的基于文本驱动的方法具有更高的自然度。我们进一步证明了我们的系统可以从没有面部视频数据或甚至语音数据的讲话者的语音中生成面部特征点。",
    "tldr": "该论文提出了一个基于文本或语音驱动的UniFLG系统，将文本与语音结合起来生成面部特征点。该系统表现出比现有基于文本驱动方法更高的语音和面部表现自然度，可以从没有面部视频数据或语音数据的讲话者中生成面部特征点。",
    "en_tdlr": "This paper proposes a UniFLG system driven by text or speech to generate facial landmarks by combining text and speech to extract common information. The system outperforms existing text-driven methods in both naturalness of speech synthesis and facial landmark generation. Moreover, it can generate facial landmarks from speakers without facial video or speech data."
}