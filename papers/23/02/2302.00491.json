{
    "title": "Learning Prototype Classifiers for Long-Tailed Recognition. (arXiv:2302.00491v2 [cs.CV] UPDATED)",
    "abstract": "The problem of long-tailed recognition (LTR) has received attention in recent years due to the fundamental power-law distribution of objects in the real-world. Most recent works in LTR use softmax classifiers that have a tendency to correlate classifier norm with the amount of training data for a given class. On the other hand, Prototype classifiers do not suffer from this shortcoming and can deliver promising results simply using Nearest-Class-Mean (NCM), a special case where prototypes are empirical centroids. However, the potential of Prototype classifiers as an alternative to softmax in LTR is relatively underexplored. In this work, we propose Prototype classifiers, which jointly learn prototypes that minimize average cross-entropy loss based on probability scores from distances to prototypes. We theoretically analyze the properties of Euclidean distance based prototype classifiers that leads to stable gradient-based optimization which is robust to outliers. We further enhance Prot",
    "link": "http://arxiv.org/abs/2302.00491",
    "context": "Title: Learning Prototype Classifiers for Long-Tailed Recognition. (arXiv:2302.00491v2 [cs.CV] UPDATED)\nAbstract: The problem of long-tailed recognition (LTR) has received attention in recent years due to the fundamental power-law distribution of objects in the real-world. Most recent works in LTR use softmax classifiers that have a tendency to correlate classifier norm with the amount of training data for a given class. On the other hand, Prototype classifiers do not suffer from this shortcoming and can deliver promising results simply using Nearest-Class-Mean (NCM), a special case where prototypes are empirical centroids. However, the potential of Prototype classifiers as an alternative to softmax in LTR is relatively underexplored. In this work, we propose Prototype classifiers, which jointly learn prototypes that minimize average cross-entropy loss based on probability scores from distances to prototypes. We theoretically analyze the properties of Euclidean distance based prototype classifiers that leads to stable gradient-based optimization which is robust to outliers. We further enhance Prot",
    "path": "papers/23/02/2302.00491.json",
    "total_tokens": 1092,
    "translated_title": "针对长尾识别的原型分类器学习",
    "translated_abstract": "近年来，由于现实世界中物体的幂律分布，长尾识别(LTR)问题受到了关注。LTR中大多数最新的工作使用softmax分类器，其具有将分类器范数与给定类别的训练数据量相关联的倾向。另一方面，原型分类器不受这种缺点的困扰，并且只使用最近类平均值（NCM）即可交付有前途的结果，其中原型是经验质心。然而，在LTR中，原型分类器作为softmax的替代方法的潜力相对较少被探索。在这项工作中，我们提出了原型分类器，该分类器联合学习原型，以最小化基于概率分数与原型之间距离的平均交叉熵损失。我们从理论上分析了基于欧几里德距离的原型分类器的性质，这导致了稳定的基于梯度的优化，对异常值具有鲁棒性。我们通过引入一种新的方法，自适应平衡来自不同类别的损失的重要性，进一步增强了原型分类器。对几个基准数据集的实验证明，我们提出的原型分类器在LTR上实现了有竞争力的性能，在几种最新方法中表现出色。",
    "tldr": "本文介绍了针对长尾识别的原型分类器学习，通过联合学习原型以最小化基于概率分数与原型之间距离的平均交叉熵损失，并通过引入一种新的方法，自适应平衡来自不同类别的损失的重要性，进一步增强了原型分类器，从而实现在几个基准数据集上的竞争性性能。",
    "en_tdlr": "This paper presents the learning of prototype classifiers for long-tailed recognition (LTR) through joint learning of prototypes to minimize average cross-entropy loss based on probability scores from distances to prototypes. The proposed method introduces adaptive balancing of the importance of loss from different classes, resulting in competitive performance on several benchmark datasets."
}