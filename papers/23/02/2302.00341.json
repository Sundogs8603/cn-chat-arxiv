{
    "title": "Reverse Ordering Techniques for Attention-Based Channel Prediction. (arXiv:2302.00341v2 [stat.ML] UPDATED)",
    "abstract": "This work aims to predict channels in wireless communication systems based on noisy observations, utilizing sequence-to-sequence models with attention (Seq2Seq-attn) and transformer models. Both models are adapted from natural language processing to tackle the complex challenge of channel prediction. Additionally, a new technique called reverse positional encoding is introduced in the transformer model to improve the robustness of the model against varying sequence lengths. Similarly, the encoder outputs of the Seq2Seq-attn model are reversed before applying attention. Simulation results demonstrate that the proposed ordering techniques allow the models to better capture the relationships between the channel snapshots within the sequence, irrespective of the sequence length, as opposed to existing methods.",
    "link": "http://arxiv.org/abs/2302.00341",
    "context": "Title: Reverse Ordering Techniques for Attention-Based Channel Prediction. (arXiv:2302.00341v2 [stat.ML] UPDATED)\nAbstract: This work aims to predict channels in wireless communication systems based on noisy observations, utilizing sequence-to-sequence models with attention (Seq2Seq-attn) and transformer models. Both models are adapted from natural language processing to tackle the complex challenge of channel prediction. Additionally, a new technique called reverse positional encoding is introduced in the transformer model to improve the robustness of the model against varying sequence lengths. Similarly, the encoder outputs of the Seq2Seq-attn model are reversed before applying attention. Simulation results demonstrate that the proposed ordering techniques allow the models to better capture the relationships between the channel snapshots within the sequence, irrespective of the sequence length, as opposed to existing methods.",
    "path": "papers/23/02/2302.00341.json",
    "total_tokens": 734,
    "translated_title": "基于注意力及反向技术的信道预测方法",
    "translated_abstract": "本文旨在利用序列到序列模型（Seq2Seq-attn）和Transformer模型，基于噪声观测来预测无线通信系统中的信道。两种模型都是从自然语言处理中改编而来，以应对信道预测的复杂挑战。此外，还引入了一种称为“反向位置编码”的新技术以提高Transformer模型在不同序列长度下的鲁棒性。类似地，在应用注意力之前，Seq2Seq-attn模型的编码器输出也会被翻转。仿真结果表明，所提出的反向技术使模型能够更好地捕捉序列中信道瞬间之间的关系，无论序列长度如何，与现有方法相比有更好的效果。",
    "tldr": "本文提出了基于Seq2Seq-attn和Transformer的信道预测模型，并引入了反向技术以提高模型鲁棒性，仿真结果表明比现有方法更好。",
    "en_tdlr": "This paper proposes channel prediction models based on Seq2Seq-attn and Transformer, and introduces reverse techniques to improve model robustness. Simulation results show better performance than existing methods."
}