{
    "title": "Effective Robustness against Natural Distribution Shifts for Models with Different Training Data. (arXiv:2302.01381v2 [cs.LG] UPDATED)",
    "abstract": "\"Effective robustness\" measures the extra out-of-distribution (OOD) robustness beyond what can be predicted from the in-distribution (ID) performance. Existing effective robustness evaluations typically use a single test set such as ImageNet to evaluate the ID accuracy. This becomes problematic when evaluating models trained on different data distributions, e.g., comparing models trained on ImageNet vs. zero-shot language-image pre-trained models trained on LAION. In this paper, we propose a new evaluation metric to evaluate and compare the effective robustness of models trained on different data. To do this, we control for the accuracy on multiple ID test sets that cover the training distributions for all the evaluated models. Our new evaluation metric provides a better estimate of effective robustness when there are models with different training data. It may also explain the surprising effective robustness gains of zero-shot CLIP-like models exhibited in prior works that used ImageN",
    "link": "http://arxiv.org/abs/2302.01381",
    "context": "Title: Effective Robustness against Natural Distribution Shifts for Models with Different Training Data. (arXiv:2302.01381v2 [cs.LG] UPDATED)\nAbstract: \"Effective robustness\" measures the extra out-of-distribution (OOD) robustness beyond what can be predicted from the in-distribution (ID) performance. Existing effective robustness evaluations typically use a single test set such as ImageNet to evaluate the ID accuracy. This becomes problematic when evaluating models trained on different data distributions, e.g., comparing models trained on ImageNet vs. zero-shot language-image pre-trained models trained on LAION. In this paper, we propose a new evaluation metric to evaluate and compare the effective robustness of models trained on different data. To do this, we control for the accuracy on multiple ID test sets that cover the training distributions for all the evaluated models. Our new evaluation metric provides a better estimate of effective robustness when there are models with different training data. It may also explain the surprising effective robustness gains of zero-shot CLIP-like models exhibited in prior works that used ImageN",
    "path": "papers/23/02/2302.01381.json",
    "total_tokens": 1005,
    "translated_title": "与不同训练数据的模型的自然分布偏移的有效鲁棒性",
    "translated_abstract": "\"有效鲁棒性\"衡量了超出由于在分布（ID）性能预测的额外的离域（OOD）鲁棒性。现有的有效鲁棒性评估通常使用单个测试集（如ImageNet）来评估ID准确性。当评估在不同数据分布上训练的模型（例如，在ImageNet上训练的模型与在LAION上进行零样本语言-图像预训练的模型进行比较）时，这会产生问题。在本文中，我们提出了一种新的评估指标来评估和比较在不同数据上训练的模型的有效鲁棒性。为此，我们控制了所有评估模型的训练分布所涵盖的多个ID测试集上的准确性。我们的新评估指标在存在具有不同训练数据的模型时能够更好地估计有效鲁棒性。它还可以解释先前工作中使用ImageNet的CLIP样式零样本模型展现出的令人惊讶的有效鲁棒性增益。",
    "tldr": "本论文提出了一种用于评估和比较在不同训练数据上训练的模型有效鲁棒性的新指标，通过控制所有模型的训练分布的多个ID测试集准确性，提供更准确估计的有效鲁棒性。这有助于解释先前工作中使用ImageNet的CLIP样式零样本模型所展示出的令人惊讶的有效鲁棒性提升。",
    "en_tdlr": "This paper proposes a new metric to evaluate and compare the effective robustness of models trained on different data distributions, providing a better estimate of effective robustness by controlling the accuracy on multiple ID test sets. It helps explain the surprising effective robustness gains exhibited by zero-shot CLIP-like models in prior works that used ImageNet."
}