{
    "title": "Policy Evaluation in Decentralized POMDPs with Belief Sharing. (arXiv:2302.04151v2 [cs.LG] UPDATED)",
    "abstract": "Most works on multi-agent reinforcement learning focus on scenarios where the state of the environment is fully observable. In this work, we consider a cooperative policy evaluation task in which agents are not assumed to observe the environment state directly. Instead, agents can only have access to noisy observations and to belief vectors. It is well-known that finding global posterior distributions under multi-agent settings is generally NP-hard. As a remedy, we propose a fully decentralized belief forming strategy that relies on individual updates and on localized interactions over a communication network. In addition to the exchange of the beliefs, agents exploit the communication network by exchanging value function parameter estimates as well. We analytically show that the proposed strategy allows information to diffuse over the network, which in turn allows the agents' parameters to have a bounded difference with a centralized baseline. A multi-sensor target tracking applicatio",
    "link": "http://arxiv.org/abs/2302.04151",
    "context": "Title: Policy Evaluation in Decentralized POMDPs with Belief Sharing. (arXiv:2302.04151v2 [cs.LG] UPDATED)\nAbstract: Most works on multi-agent reinforcement learning focus on scenarios where the state of the environment is fully observable. In this work, we consider a cooperative policy evaluation task in which agents are not assumed to observe the environment state directly. Instead, agents can only have access to noisy observations and to belief vectors. It is well-known that finding global posterior distributions under multi-agent settings is generally NP-hard. As a remedy, we propose a fully decentralized belief forming strategy that relies on individual updates and on localized interactions over a communication network. In addition to the exchange of the beliefs, agents exploit the communication network by exchanging value function parameter estimates as well. We analytically show that the proposed strategy allows information to diffuse over the network, which in turn allows the agents' parameters to have a bounded difference with a centralized baseline. A multi-sensor target tracking applicatio",
    "path": "papers/23/02/2302.04151.json",
    "total_tokens": 824,
    "translated_title": "具有信念共享的去中心化POMDP策略评估",
    "translated_abstract": "多智能体强化学习的大多数工作都集中在环境状态完全可观察的场景中。本文考虑一种协作策略评估任务，其中代理不能直接观察环境状态。相反，代理只能访问含噪声观测和置信向量。我们提出了一种完全去中心化的信念形成策略，该策略依赖于个体更新和通信网络上的本地化交互。除了交换信念外，代理还利用通信网络交换价值函数参数估计。我们分析地表明，该策略允许信息在网络中扩散，从而使代理的参数与集中式基线具有有界差异。一个多传感器目标跟踪应用是我们的案例研究。",
    "tldr": "本文提出了一种去中心化的信念形成策略，使得代理的参数可以与集中式基线有界的差异，并在多传感器目标跟踪应用中得到应用。",
    "en_tdlr": "This paper proposes a decentralized belief forming strategy for cooperative policy evaluation in which agents rely on individual updates and localized interactions over a communication network, allowing information to diffuse over the network and reducing the bounded difference of agents' parameters from a centralized baseline, with a multi-sensor target tracking application."
}