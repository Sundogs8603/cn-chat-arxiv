{
    "title": "DualStreamFoveaNet: A Dual Stream Fusion Architecture with Anatomical Awareness for Robust Fovea Localization. (arXiv:2302.06961v3 [cs.CV] UPDATED)",
    "abstract": "Accurate fovea localization is essential for analyzing retinal diseases to prevent irreversible vision loss. While current deep learning-based methods outperform traditional ones, they still face challenges such as the lack of local anatomical landmarks around the fovea, the inability to robustly handle diseased retinal images, and the variations in image conditions. In this paper, we propose a novel transformer-based architecture called DualStreamFoveaNet (DSFN) for multi-cue fusion. This architecture explicitly incorporates long-range connections and global features using retina and vessel distributions for robust fovea localization. We introduce a spatial attention mechanism in the dual-stream encoder to extract and fuse self-learned anatomical information, focusing more on features distributed along blood vessels and significantly reducing computational costs by decreasing token numbers. Our extensive experiments show that the proposed architecture achieves state-of-the-art perform",
    "link": "http://arxiv.org/abs/2302.06961",
    "context": "Title: DualStreamFoveaNet: A Dual Stream Fusion Architecture with Anatomical Awareness for Robust Fovea Localization. (arXiv:2302.06961v3 [cs.CV] UPDATED)\nAbstract: Accurate fovea localization is essential for analyzing retinal diseases to prevent irreversible vision loss. While current deep learning-based methods outperform traditional ones, they still face challenges such as the lack of local anatomical landmarks around the fovea, the inability to robustly handle diseased retinal images, and the variations in image conditions. In this paper, we propose a novel transformer-based architecture called DualStreamFoveaNet (DSFN) for multi-cue fusion. This architecture explicitly incorporates long-range connections and global features using retina and vessel distributions for robust fovea localization. We introduce a spatial attention mechanism in the dual-stream encoder to extract and fuse self-learned anatomical information, focusing more on features distributed along blood vessels and significantly reducing computational costs by decreasing token numbers. Our extensive experiments show that the proposed architecture achieves state-of-the-art perform",
    "path": "papers/23/02/2302.06961.json",
    "total_tokens": 971,
    "translated_title": "DualStreamFoveaNet: 一种具有解剖意识的双流融合架构用于鲁棒的中央凹点定位",
    "translated_abstract": "准确的中央凹点定位对于分析视网膜疾病以预防不可逆视力损失至关重要。当前基于深度学习的方法虽然优于传统方法，但仍面临一些挑战，如中央凹点周围局部解剖标记的缺失、不能鲁棒地处理病变视网膜图像和图像条件的变化。本文提出了一种新颖的基于Transformer的架构称为DualStreamFoveaNet (DSFN)用于多线索融合。该架构明确地利用视网膜和血管分布来实现长程连接和全局特征的融合，实现鲁棒的中央凹点定位。我们在双流编码器中引入了一种空间注意机制，用于提取和融合自学习的解剖信息，更注重分布在血管沿线的特征，并通过减少令牌数量显著降低计算成本。我们的广泛实验结果表明，所提出的架构达到了最先进的性能。",
    "tldr": "DualStreamFoveaNet是一种具有解剖意识的双流融合架构，通过利用视网膜和血管分布进行多线索融合，实现对鲁棒的中央凹点定位。实验证明该架构在中央凹点定位方面达到了最先进的性能。"
}