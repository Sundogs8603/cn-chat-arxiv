{
    "title": "CHiLS: Zero-Shot Image Classification with Hierarchical Label Sets. (arXiv:2302.02551v3 [cs.CV] UPDATED)",
    "abstract": "Open vocabulary models (e.g. CLIP) have shown strong performance on zero-shot classification through their ability generate embeddings for each class based on their (natural language) names. Prior work has focused on improving the accuracy of these models through prompt engineering or by incorporating a small amount of labeled downstream data (via finetuning). However, there has been little focus on improving the richness of the class names themselves, which can pose issues when class labels are coarsely-defined and are uninformative. We propose Classification with Hierarchical Label Sets (or CHiLS), an alternative strategy for zero-shot classification specifically designed for datasets with implicit semantic hierarchies. CHiLS proceeds in three steps: (i) for each class, produce a set of subclasses, using either existing label hierarchies or by querying GPT-3; (ii) perform the standard zero-shot CLIP procedure as though these subclasses were the labels of interest; (iii) map the predi",
    "link": "http://arxiv.org/abs/2302.02551",
    "context": "Title: CHiLS: Zero-Shot Image Classification with Hierarchical Label Sets. (arXiv:2302.02551v3 [cs.CV] UPDATED)\nAbstract: Open vocabulary models (e.g. CLIP) have shown strong performance on zero-shot classification through their ability generate embeddings for each class based on their (natural language) names. Prior work has focused on improving the accuracy of these models through prompt engineering or by incorporating a small amount of labeled downstream data (via finetuning). However, there has been little focus on improving the richness of the class names themselves, which can pose issues when class labels are coarsely-defined and are uninformative. We propose Classification with Hierarchical Label Sets (or CHiLS), an alternative strategy for zero-shot classification specifically designed for datasets with implicit semantic hierarchies. CHiLS proceeds in three steps: (i) for each class, produce a set of subclasses, using either existing label hierarchies or by querying GPT-3; (ii) perform the standard zero-shot CLIP procedure as though these subclasses were the labels of interest; (iii) map the predi",
    "path": "papers/23/02/2302.02551.json",
    "total_tokens": 1042,
    "translated_title": "CHiLS：具有分层标签集的零样本图像分类",
    "translated_abstract": "开放词汇模型（例如CLIP）通过能够基于它们（自然语言）的名称为每个类别生成嵌入向量，在零样本分类方面表现出强大的性能。先前的工作着重于通过提示工程或通过包含少量标记的下游数据（通过微调）来提高这些模型的准确性。但是，在改进类别名称的丰富性方面却鲜有研究，这在类别标签被粗略定义并且不具信息性的情况下可能会有问题。我们提出了具有分层标签集（CHiLS）的分类，这是一种专门为具有隐含语义层次结构的数据集设计的零样本分类替代策略。CHiLS分三步进行：（i）为每个类别生成一组子类，使用现有的标签层次结构或通过查询GPT-3实现；（ii）执行标准的零样本CLIP过程，就像这些子类别是感兴趣的标签那样进行；（iii）将预测的类别嵌入映射回原始类别层次结构，以在期望的粒度水平上进行预测。我们用四个具有不同语义层次的基准测试数据集评估了CHiLS，并表明它在需要更少的下游标签的同时优于最先进的零样本分类器。",
    "tldr": "本文提出了 CHiLS，它利用分层标签集进行零样本图像分类，通过产生更具信息性的类别名称，在获得更精细的分类效果的同时，还能使用更少的有标签数据。",
    "en_tdlr": "This paper proposes CHiLS, an alternative zero-shot image classification strategy that utilizes hierarchical label sets to generate more informative class names, resulting in more accurate classification with fewer labeled images."
}