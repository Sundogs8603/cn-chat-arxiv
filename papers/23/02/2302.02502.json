{
    "title": "Rethinking Robust Contrastive Learning from the Adversarial Perspective. (arXiv:2302.02502v2 [cs.LG] UPDATED)",
    "abstract": "To advance the understanding of robust deep learning, we delve into the effects of adversarial training on self-supervised and supervised contrastive learning alongside supervised learning. Our analysis uncovers significant disparities between adversarial and clean representations in standard-trained networks across various learning algorithms. Remarkably, adversarial training mitigates these disparities and fosters the convergence of representations toward a universal set, regardless of the learning scheme used. Additionally, increasing the similarity between adversarial and clean representations, particularly near the end of the network, enhances network robustness. These findings offer valuable insights for designing and training effective and robust deep learning networks. Our code is released at \\textcolor{magenta}{\\url{https://github.com/softsys4ai/CL-Robustness}}.",
    "link": "http://arxiv.org/abs/2302.02502",
    "context": "Title: Rethinking Robust Contrastive Learning from the Adversarial Perspective. (arXiv:2302.02502v2 [cs.LG] UPDATED)\nAbstract: To advance the understanding of robust deep learning, we delve into the effects of adversarial training on self-supervised and supervised contrastive learning alongside supervised learning. Our analysis uncovers significant disparities between adversarial and clean representations in standard-trained networks across various learning algorithms. Remarkably, adversarial training mitigates these disparities and fosters the convergence of representations toward a universal set, regardless of the learning scheme used. Additionally, increasing the similarity between adversarial and clean representations, particularly near the end of the network, enhances network robustness. These findings offer valuable insights for designing and training effective and robust deep learning networks. Our code is released at \\textcolor{magenta}{\\url{https://github.com/softsys4ai/CL-Robustness}}.",
    "path": "papers/23/02/2302.02502.json",
    "total_tokens": 877,
    "translated_title": "从对抗角度重新思考鲁棒对比学习",
    "translated_abstract": "为了推进对鲁棒深度学习的理解，我们探讨了对抗训练对自监督和监督对比学习以及监督学习的影响。我们的分析揭示了标准训练网络中对抗性和干净性表示之间存在重大差异，这种差异得到了显著缓解并促进了表示收敛到一个通用集合中，无论使用哪种学习方案。此外，增加对抗和干净表示之间的相似度，特别是在网络末端附近，可以增强网络的鲁棒性。这些发现为设计和训练高效而鲁棒的深度学习网络提供了有价值的见解。我们的代码已在\\url{https://github.com/softsys4ai/CL-Robustness}上发布。",
    "tldr": "研究揭示了在标准训练网络中对抗性和干净性表示之间存在重大差异，对抗训练能够缓解这种差异并促进表示收敛到一个通用集合中，无论使用哪种学习方案。增加对抗和干净表示之间的相似度可以增强网络的鲁棒性。",
    "en_tdlr": "This study revealed significant disparities between adversarial and clean representations in standard-trained networks and that adversarial training can mitigate these disparities and foster the convergence of representations towards a universal set, regardless of the learning scheme used. Increasing the similarity between adversarial and clean representations, particularly near the end of the network, enhances network robustness."
}