{
    "title": "Distributional Learning of Variational AutoEncoder: Application to Synthetic Data Generation. (arXiv:2302.11294v2 [stat.ML] UPDATED)",
    "abstract": "The Gaussianity assumption has been consistently criticized as a main limitation of the Variational Autoencoder (VAE), despite its efficiency in computational modeling. In this paper, we propose a new approach that expands the model capacity (i.e., expressive power of distributional family) without sacrificing the computational advantages of the VAE framework. Our VAE model's decoder is composed of an infinite mixture of asymmetric Laplacian distribution, which possesses general distribution fitting capabilities for continuous variables. Our model is represented by a special form of a nonparametric M-estimator for estimating general quantile functions, and we theoretically establish the relevance between the proposed model and quantile estimation. We apply the proposed model to synthetic data generation, and particularly, our model demonstrates superiority in easily adjusting the level of data privacy.",
    "link": "http://arxiv.org/abs/2302.11294",
    "context": "Title: Distributional Learning of Variational AutoEncoder: Application to Synthetic Data Generation. (arXiv:2302.11294v2 [stat.ML] UPDATED)\nAbstract: The Gaussianity assumption has been consistently criticized as a main limitation of the Variational Autoencoder (VAE), despite its efficiency in computational modeling. In this paper, we propose a new approach that expands the model capacity (i.e., expressive power of distributional family) without sacrificing the computational advantages of the VAE framework. Our VAE model's decoder is composed of an infinite mixture of asymmetric Laplacian distribution, which possesses general distribution fitting capabilities for continuous variables. Our model is represented by a special form of a nonparametric M-estimator for estimating general quantile functions, and we theoretically establish the relevance between the proposed model and quantile estimation. We apply the proposed model to synthetic data generation, and particularly, our model demonstrates superiority in easily adjusting the level of data privacy.",
    "path": "papers/23/02/2302.11294.json",
    "total_tokens": 814,
    "translated_title": "变分自编码器的分布式学习：在合成数据生成中的应用",
    "translated_abstract": "尽管变分自编码器（VAE）在计算建模方面很高效，但高斯假设一直被认为是它的主要局限性。在本文中，我们提出了一种新方法，扩展了模型容量（即分布族的表达能力），而不会牺牲VAE框架的计算优势。我们的VAE模型的解码器由无限组合的非对称拉普拉斯分布构成，具有连续变量的分布拟合能力。我们的模型由估计一般分位函数的非参数M-estimator的特殊形式表示，并在理论上建立了所提出模型与分位数估计之间的关系。我们将所提出的模型应用于合成数据生成，特别是在轻松调整数据隐私级别方面，我们的模型展现了其优越性。",
    "tldr": "提出了一种新的方法扩展了VAE模型容量，采用无限混合的非对称拉普拉斯分布作为解码器，具有分布拟合能力和调整数据隐私级别的优越性。",
    "en_tdlr": "A new method is proposed to expand the capacity of the VAE model with an infinite mixture of asymmetric Laplacian distribution as the decoder, which has the capability of distribution fitting and adjusting data privacy level in synthetic data generation."
}