{
    "title": "Asymmetric Certified Robustness via Feature-Convex Neural Networks. (arXiv:2302.01961v2 [cs.LG] UPDATED)",
    "abstract": "Recent works have introduced input-convex neural networks (ICNNs) as learning models with advantageous training, inference, and generalization properties linked to their convex structure. In this paper, we propose a novel feature-convex neural network architecture as the composition of an ICNN with a Lipschitz feature map in order to achieve adversarial robustness. We consider the asymmetric binary classification setting with one \"sensitive\" class, and for this class we prove deterministic, closed-form, and easily-computable certified robust radii for arbitrary $\\ell_p$-norms. We theoretically justify the use of these models by characterizing their decision region geometry, extending the universal approximation theorem for ICNN regression to the classification setting, and proving a lower bound on the probability that such models perfectly fit even unstructured uniformly distributed data in sufficiently high dimensions. Experiments on Malimg malware classification and subsets of MNIST,",
    "link": "http://arxiv.org/abs/2302.01961",
    "context": "Title: Asymmetric Certified Robustness via Feature-Convex Neural Networks. (arXiv:2302.01961v2 [cs.LG] UPDATED)\nAbstract: Recent works have introduced input-convex neural networks (ICNNs) as learning models with advantageous training, inference, and generalization properties linked to their convex structure. In this paper, we propose a novel feature-convex neural network architecture as the composition of an ICNN with a Lipschitz feature map in order to achieve adversarial robustness. We consider the asymmetric binary classification setting with one \"sensitive\" class, and for this class we prove deterministic, closed-form, and easily-computable certified robust radii for arbitrary $\\ell_p$-norms. We theoretically justify the use of these models by characterizing their decision region geometry, extending the universal approximation theorem for ICNN regression to the classification setting, and proving a lower bound on the probability that such models perfectly fit even unstructured uniformly distributed data in sufficiently high dimensions. Experiments on Malimg malware classification and subsets of MNIST,",
    "path": "papers/23/02/2302.01961.json",
    "total_tokens": 942,
    "translated_title": "通过特征凸卷积神经网络实现非对称的可信鲁棒性",
    "translated_abstract": "最近的研究引入了输入凸卷积神经网络(ICNNs)作为具有有利的训练、推理和泛化特性的学习模型，与其凸结构相关。在本文中，我们提出了一种新颖的特征凸卷积神经网络架构，将ICNN与Lipschitz特征映射组合起来，以实现对抗鲁棒性。我们考虑具有一个“敏感”类的不对称二元分类设置，并为这个类证明了确定性的、封闭形式的和易于计算的任意$\\ell_p$范数的认证鲁棒半径。我们通过表征它们的决策区域几何、将ICNN回归的通用逼近定理扩展到分类设定，并证明了在足够高维度下，这些模型完美地拟合甚至无结构均匀分布数据的概率下界，从理论上证明了使用这些模型的合理性。在Malimg恶意软件分类和MNIST子集上的实验中，",
    "tldr": "本文提出了一种新颖的特征凸卷积神经网络架构，将ICNN与Lipschitz特征映射结合，实现了对抗鲁棒性，并证明了对于具有一个“敏感”类的不对称二元分类设置，可以计算出确定性的认证鲁棒半径。"
}