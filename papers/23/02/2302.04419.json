{
    "title": "An Investigation into Pre-Training Object-Centric Representations for Reinforcement Learning. (arXiv:2302.04419v2 [cs.LG] UPDATED)",
    "abstract": "Unsupervised object-centric representation (OCR) learning has recently drawn attention as a new paradigm of visual representation. This is because of its potential of being an effective pre-training technique for various downstream tasks in terms of sample efficiency, systematic generalization, and reasoning. Although image-based reinforcement learning (RL) is one of the most important and thus frequently mentioned such downstream tasks, the benefit in RL has surprisingly not been investigated systematically thus far. Instead, most of the evaluations have focused on rather indirect metrics such as segmentation quality and object property prediction accuracy. In this paper, we investigate the effectiveness of OCR pre-training for image-based reinforcement learning via empirical experiments. For systematic evaluation, we introduce a simple object-centric visual RL benchmark and conduct experiments to answer questions such as ``Does OCR pre-training improve performance on object-centric t",
    "link": "http://arxiv.org/abs/2302.04419",
    "context": "Title: An Investigation into Pre-Training Object-Centric Representations for Reinforcement Learning. (arXiv:2302.04419v2 [cs.LG] UPDATED)\nAbstract: Unsupervised object-centric representation (OCR) learning has recently drawn attention as a new paradigm of visual representation. This is because of its potential of being an effective pre-training technique for various downstream tasks in terms of sample efficiency, systematic generalization, and reasoning. Although image-based reinforcement learning (RL) is one of the most important and thus frequently mentioned such downstream tasks, the benefit in RL has surprisingly not been investigated systematically thus far. Instead, most of the evaluations have focused on rather indirect metrics such as segmentation quality and object property prediction accuracy. In this paper, we investigate the effectiveness of OCR pre-training for image-based reinforcement learning via empirical experiments. For systematic evaluation, we introduce a simple object-centric visual RL benchmark and conduct experiments to answer questions such as ``Does OCR pre-training improve performance on object-centric t",
    "path": "papers/23/02/2302.04419.json",
    "total_tokens": 869,
    "translated_abstract": "最近，非监督的面向对象表达(OCR)学习作为一种新的视觉表达范式引起了人们的关注。这是因为它有潜力成为各种下游任务的有效预训练技术，具有样本效率、系统化泛化和推理能力。虽然基于图像的强化学习（RL）是最重要的下游任务之一，因此经常被提及，但其在RL中的效益迄今令人惊讶地没有得到系统地研究。相反，大多数评估都集中在一些间接的指标上，如分割质量和对象属性的预测精度。本文通过实证实验研究了OCR预训练对基于图像的强化学习的有效性。为了进行系统评估，我们引入了一个简单的面向对象的视觉RL基准，并进行的实验来回答一些问题，例如“OCR预训练是否提高了面向对象任务的性能”。",
    "tldr": "本文探讨了非监督的面向对象表达(OCR)学习作为一种新的视觉表达范式，在强化学习中的应用。通过实证实验，证明了OCR预训练可以提高面向对象任务的性能。"
}