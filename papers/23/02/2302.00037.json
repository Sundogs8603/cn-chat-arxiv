{
    "title": "Differentially-Private Hierarchical Clustering with Provable Approximation Guarantees. (arXiv:2302.00037v2 [cs.LG] UPDATED)",
    "abstract": "Hierarchical Clustering is a popular unsupervised machine learning method with decades of history and numerous applications. We initiate the study of differentially private approximation algorithms for hierarchical clustering under the rigorous framework introduced by (Dasgupta, 2016). We show strong lower bounds for the problem: that any $\\epsilon$-DP algorithm must exhibit $O(|V|^2/ \\epsilon)$-additive error for an input dataset $V$. Then, we exhibit a polynomial-time approximation algorithm with $O(|V|^{2.5}/ \\epsilon)$-additive error, and an exponential-time algorithm that meets the lower bound. To overcome the lower bound, we focus on the stochastic block model, a popular model of graphs, and, with a separation assumption on the blocks, propose a private $1+o(1)$ approximation algorithm which also recovers the blocks exactly. Finally, we perform an empirical study of our algorithms and validate their performance.",
    "link": "http://arxiv.org/abs/2302.00037",
    "context": "Title: Differentially-Private Hierarchical Clustering with Provable Approximation Guarantees. (arXiv:2302.00037v2 [cs.LG] UPDATED)\nAbstract: Hierarchical Clustering is a popular unsupervised machine learning method with decades of history and numerous applications. We initiate the study of differentially private approximation algorithms for hierarchical clustering under the rigorous framework introduced by (Dasgupta, 2016). We show strong lower bounds for the problem: that any $\\epsilon$-DP algorithm must exhibit $O(|V|^2/ \\epsilon)$-additive error for an input dataset $V$. Then, we exhibit a polynomial-time approximation algorithm with $O(|V|^{2.5}/ \\epsilon)$-additive error, and an exponential-time algorithm that meets the lower bound. To overcome the lower bound, we focus on the stochastic block model, a popular model of graphs, and, with a separation assumption on the blocks, propose a private $1+o(1)$ approximation algorithm which also recovers the blocks exactly. Finally, we perform an empirical study of our algorithms and validate their performance.",
    "path": "papers/23/02/2302.00037.json",
    "total_tokens": 963,
    "translated_title": "具有可证明近似保证的差分隐私分层聚类",
    "translated_abstract": "分层聚类是一种流行的无监督机器学习方法，具有悠久的历史和众多的应用。本文在Dasgupta(2016)引入的严格框架下，首次研究了具有差分隐私近似算法的分层聚类。我们对该问题进行了强有力的下界分析：任何$\\epsilon$-差分隐私算法对于输入集合$V$都必须显示$O(|V|^2/\\epsilon)$的加性误差。然后，我们提出了一个多项式时间复杂度的近似算法，其加性误差为$O(|V|^{2.5}/\\epsilon)$，还提出了一种满足下界的指数时间复杂度算法。为了克服这个下界，我们将重点放在随机块模型上，这是一种流行的图形模型，通过对块的分离假设，提出了一种私有的$1+o(1)$逼近算法，同时还恢复了块的确切值。最后，我们对我们的算法进行了实证研究，并验证了它们的性能。",
    "tldr": "本文研究了具有差分隐私近似算法的分层聚类，并提出了一种满足下界的指数时间复杂度算法和一个私有的$1+o(1)$逼近算法。同时，我们对算法进行了实证研究，并验证了它们的性能。",
    "en_tdlr": "This paper studies differentially private approximation algorithms for hierarchical clustering and proposes an exponential-time algorithm that meets the lower bound and a private $1+o(1)$ approximation algorithm. Empirical studies were also conducted to validate the algorithms' performance."
}