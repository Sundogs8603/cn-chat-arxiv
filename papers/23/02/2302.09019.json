{
    "title": "Tensor Networks Meet Neural Networks: A Survey and Future Perspectives. (arXiv:2302.09019v2 [cs.LG] UPDATED)",
    "abstract": "Tensor networks (TNs) and neural networks (NNs) are two fundamental data modeling approaches. TNs were introduced to solve the curse of dimensionality in large-scale tensors by converting an exponential number of dimensions to polynomial complexity. As a result, they have attracted significant attention in the fields of quantum physics and machine learning. Meanwhile, NNs have displayed exceptional performance in various applications, e.g., computer vision, natural language processing, and robotics research. Interestingly, although these two types of networks originate from different observations, they are inherently linked through the common multilinearity structure underlying both TNs and NNs, thereby motivating a significant number of intellectual developments regarding combinations of TNs and NNs. In this paper, we refer to these combinations as tensorial neural networks (TNNs), and present an introduction to TNNs in three primary aspects: network compression, information fusion, a",
    "link": "http://arxiv.org/abs/2302.09019",
    "context": "Title: Tensor Networks Meet Neural Networks: A Survey and Future Perspectives. (arXiv:2302.09019v2 [cs.LG] UPDATED)\nAbstract: Tensor networks (TNs) and neural networks (NNs) are two fundamental data modeling approaches. TNs were introduced to solve the curse of dimensionality in large-scale tensors by converting an exponential number of dimensions to polynomial complexity. As a result, they have attracted significant attention in the fields of quantum physics and machine learning. Meanwhile, NNs have displayed exceptional performance in various applications, e.g., computer vision, natural language processing, and robotics research. Interestingly, although these two types of networks originate from different observations, they are inherently linked through the common multilinearity structure underlying both TNs and NNs, thereby motivating a significant number of intellectual developments regarding combinations of TNs and NNs. In this paper, we refer to these combinations as tensorial neural networks (TNNs), and present an introduction to TNNs in three primary aspects: network compression, information fusion, a",
    "path": "papers/23/02/2302.09019.json",
    "total_tokens": 971,
    "translated_title": "评述与未来展望",
    "translated_abstract": "张量网络(TN)和神经网络(NN)是两种基本的数据建模方法。TN旨在通过将指数维度转化为多项式复杂度来解决处理大规模张量的维度灾难，并吸引了物理和机器学习的关注。与此同时，NN在计算机视觉、自然语言处理和机器人研究等各种应用中表现出了优异的性能。值得注意的是，尽管这两种网络源于不同的观察，但它们通过TNN (张量神经网络)概念的结合有着内在的联系，共同支撑着多线性结构。本文介绍了TNN的三个方面：网络压缩、信息融合和量子启发式神经网络构建，并阐述了TNN与其他神经网络架构的差异以及TNN的优点、局限性及其对于不同应用的潜在影响。最后，我们讨论了TNN的未来研究方向。",
    "tldr": "这篇论文评述了张量网络和神经网络并介绍了它们的结合：张量神经网络(TNN)，探讨了TNN在网络压缩、信息融合和量子启发式神经网络构建方面的优缺点和未来研究方向。",
    "en_tdlr": "This paper provides a survey of tensor networks and neural networks and introduces their combination, tensorial neural networks (TNNs), which are explored in terms of network compression, information fusion, and quantum-inspired neural network construction. The strengths, limitations, and potential impact of TNNs on various applications are discussed, and future research directions of TNNs are proposed."
}