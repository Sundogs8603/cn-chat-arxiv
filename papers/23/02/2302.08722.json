{
    "title": "GPT4MIA: Utilizing Generative Pre-trained Transformer (GPT-3) as A Plug-and-Play Transductive Model for Medical Image Analysis. (arXiv:2302.08722v3 [cs.CV] UPDATED)",
    "abstract": "In this paper, we propose a novel approach (called GPT4MIA) that utilizes Generative Pre-trained Transformer (GPT) as a plug-and-play transductive inference tool for medical image analysis (MIA). We provide theoretical analysis on why a large pre-trained language model such as GPT-3 can be used as a plug-and-play transductive inference model for MIA. At the methodological level, we develop several technical treatments to improve the efficiency and effectiveness of GPT4MIA, including better prompt structure design, sample selection, and prompt ordering of representative samples/features. We present two concrete use cases (with workflow) of GPT4MIA: (1) detecting prediction errors and (2) improving prediction accuracy, working in conjecture with well-established vision-based models for image classification (e.g., ResNet). Experiments validate that our proposed method is effective for these two tasks. We further discuss the opportunities and challenges in utilizing Transformer-based large",
    "link": "http://arxiv.org/abs/2302.08722",
    "context": "Title: GPT4MIA: Utilizing Generative Pre-trained Transformer (GPT-3) as A Plug-and-Play Transductive Model for Medical Image Analysis. (arXiv:2302.08722v3 [cs.CV] UPDATED)\nAbstract: In this paper, we propose a novel approach (called GPT4MIA) that utilizes Generative Pre-trained Transformer (GPT) as a plug-and-play transductive inference tool for medical image analysis (MIA). We provide theoretical analysis on why a large pre-trained language model such as GPT-3 can be used as a plug-and-play transductive inference model for MIA. At the methodological level, we develop several technical treatments to improve the efficiency and effectiveness of GPT4MIA, including better prompt structure design, sample selection, and prompt ordering of representative samples/features. We present two concrete use cases (with workflow) of GPT4MIA: (1) detecting prediction errors and (2) improving prediction accuracy, working in conjecture with well-established vision-based models for image classification (e.g., ResNet). Experiments validate that our proposed method is effective for these two tasks. We further discuss the opportunities and challenges in utilizing Transformer-based large",
    "path": "papers/23/02/2302.08722.json",
    "total_tokens": 981,
    "translated_title": "GPT4MIA: 利用生成预训练变压器 (GPT-3) 作为插入式检验模型进行医学图像分析",
    "translated_abstract": "本文提出了一种称为 GPT4MIA 的新方法，利用生成预训练变压器 (GPT) 作为插入式检验工具，用于医学图像分析 (MIA)。我们提供了理论分析，解释了为什么像 GPT-3 这样的大型预训练语言模型可以作为插入式检验模型用于 MIA。在方法学层面上，我们开发了几种技术处理方法，包括更好的提示结构设计、样本选择以及代表性样本/特征的提示排序，以提高 GPT4MIA 的效率和有效性。我们呈现了两种具体的 GPT4MIA 使用案例 (带有工作流程)：(1) 检测预测错误和 (2) 改进预测准确性，与已经建立的基于视觉的图像分类模型 (例如 ResNet) 协同工作。实验验证了我们提出的方法对于这两个任务的有效性。我们进一步讨论了利用基于变压器的大型语言模型进行 MIA 任务的机会和挑战。",
    "tldr": "本文提出 GPT4MIA 方法，利用 GPT-3 作为插入式检验工具进行医学图像分析；该方法在提示结构设计、样本选择及提示排序等方面优化，能有效提高预测准确性。",
    "en_tdlr": "This paper proposes a method called GPT4MIA, which utilizes GPT-3 as a plug-and-play transductive inference tool for medical image analysis. The proposed method is optimized in terms of prompt structure design, sample selection, and prompt ordering of representative samples/features, resulting in improved prediction accuracy."
}