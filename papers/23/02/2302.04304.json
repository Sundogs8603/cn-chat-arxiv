{
    "title": "Q-Diffusion: Quantizing Diffusion Models. (arXiv:2302.04304v3 [cs.CV] UPDATED)",
    "abstract": "Diffusion models have achieved great success in image synthesis through iterative noise estimation using deep neural networks. However, the slow inference, high memory consumption, and computation intensity of the noise estimation model hinder the efficient adoption of diffusion models. Although post-training quantization (PTQ) is considered a go-to compression method for other tasks, it does not work out-of-the-box on diffusion models. We propose a novel PTQ method specifically tailored towards the unique multi-timestep pipeline and model architecture of the diffusion models, which compresses the noise estimation network to accelerate the generation process. We identify the key difficulty of diffusion model quantization as the changing output distributions of noise estimation networks over multiple time steps and the bimodal activation distribution of the shortcut layers within the noise estimation network. We tackle these challenges with timestep-aware calibration and split shortcut ",
    "link": "http://arxiv.org/abs/2302.04304",
    "context": "Title: Q-Diffusion: Quantizing Diffusion Models. (arXiv:2302.04304v3 [cs.CV] UPDATED)\nAbstract: Diffusion models have achieved great success in image synthesis through iterative noise estimation using deep neural networks. However, the slow inference, high memory consumption, and computation intensity of the noise estimation model hinder the efficient adoption of diffusion models. Although post-training quantization (PTQ) is considered a go-to compression method for other tasks, it does not work out-of-the-box on diffusion models. We propose a novel PTQ method specifically tailored towards the unique multi-timestep pipeline and model architecture of the diffusion models, which compresses the noise estimation network to accelerate the generation process. We identify the key difficulty of diffusion model quantization as the changing output distributions of noise estimation networks over multiple time steps and the bimodal activation distribution of the shortcut layers within the noise estimation network. We tackle these challenges with timestep-aware calibration and split shortcut ",
    "path": "papers/23/02/2302.04304.json",
    "total_tokens": 853,
    "translated_title": "Q-Diffusion: 量化扩散模型",
    "translated_abstract": "扩散模型通过使用深度神经网络进行迭代噪声估计，在图像合成方面取得了巨大成功。然而，噪声估计模型的慢推断、高内存消耗和计算强度妨碍了扩散模型的有效采用。虽然后训练量化（PTQ）被认为是其他任务的首选压缩方法，但它不能直接用于扩散模型。我们提出了一种新颖的PTQ方法，专门针对扩散模型的独特多时间步骤管道和模型架构，压缩噪声估计网络以加速生成过程。我们认为扩散模型量化的关键难点是噪声估计网络在多个时间步骤上的变化输出分布和噪声估计网络中快捷层的双峰激活分布。我们通过时间步长感知校准和拆分快捷路来应对这些挑战。",
    "tldr": "本文提出了一种特定于扩散模型的量化方法，通过时间步骤感知校准和拆分快捷路来加速图像生成，解决了扩散模型中后训练量化所面临的难题。",
    "en_tdlr": "This paper proposes a quantization method specific to diffusion models which tackles the challenges of post-training quantization through timestep-aware calibration and split shortcut layers, accelerating image generation process."
}