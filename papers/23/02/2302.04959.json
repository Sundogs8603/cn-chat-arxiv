{
    "title": "Hypernetworks build Implicit Neural Representations of Sounds. (arXiv:2302.04959v3 [cs.LG] UPDATED)",
    "abstract": "Implicit Neural Representations (INRs) are nowadays used to represent multimedia signals across various real-life applications, including image super-resolution, image compression, or 3D rendering. Existing methods that leverage INRs are predominantly focused on visual data, as their application to other modalities, such as audio, is nontrivial due to the inductive biases present in architectural attributes of image-based INR models. To address this limitation, we introduce HyperSound, the first meta-learning approach to produce INRs for audio samples that leverages hypernetworks to generalize beyond samples observed in training. Our approach reconstructs audio samples with quality comparable to other state-of-the-art models and provides a viable alternative to contemporary sound representations used in deep neural networks for audio processing, such as spectrograms.",
    "link": "http://arxiv.org/abs/2302.04959",
    "context": "Title: Hypernetworks build Implicit Neural Representations of Sounds. (arXiv:2302.04959v3 [cs.LG] UPDATED)\nAbstract: Implicit Neural Representations (INRs) are nowadays used to represent multimedia signals across various real-life applications, including image super-resolution, image compression, or 3D rendering. Existing methods that leverage INRs are predominantly focused on visual data, as their application to other modalities, such as audio, is nontrivial due to the inductive biases present in architectural attributes of image-based INR models. To address this limitation, we introduce HyperSound, the first meta-learning approach to produce INRs for audio samples that leverages hypernetworks to generalize beyond samples observed in training. Our approach reconstructs audio samples with quality comparable to other state-of-the-art models and provides a viable alternative to contemporary sound representations used in deep neural networks for audio processing, such as spectrograms.",
    "path": "papers/23/02/2302.04959.json",
    "total_tokens": 872,
    "translated_title": "超网络构建音频的隐式神经表示",
    "translated_abstract": "隐式神经表示（INR）现在被广泛地应用于各种实际应用程序中来代表多媒体信号，包括图像超分辨率、图像压缩或3D渲染。现有的利用INR的方法主要集中在视觉数据上，因为在基于图像的INR模型的架构属性中存在归纳偏差，所以将其应用于其他模态，如音频，是非常困难的。为了解决这个问题，我们介绍了超声（HyperSound），这是一种利用超网络进行元学习的方法，用于为音频样本生成INR，以便能够在训练中观察到的样本上进行推广。我们的方法以可比较其他最先进模型的质量重构音频样本，并为用于音频处理的深度神经网络中的当代声音表示提供了可行的替代方案，如谱图。",
    "tldr": "该论文介绍了一种新的方法，名为“HyperSound”，可将超网络结构应用于元学习，从而生成音频隐式神经表示（INR），该方法可用于音频信号的处理，并且重构质量可与其他最先进的模型相媲美，是当代音频处理中的一个有潜力的替代方案。",
    "en_tdlr": "This paper presents a novel approach, called \"HyperSound,\" which applies hypernetworks to meta-learning to generate Implicit Neural Representations (INRs) for audio signals, providing a promising alternative to contemporary sound representations used in deep neural networks for audio processing with comparable quality reconstruction."
}