{
    "title": "Decoupled Iterative Refinement Framework for Interacting Hands Reconstruction from a Single RGB Image. (arXiv:2302.02410v2 [cs.CV] UPDATED)",
    "abstract": "Reconstructing interacting hands from a single RGB image is a very challenging task. On the one hand, severe mutual occlusion and similar local appearance between two hands confuse the extraction of visual features, resulting in the misalignment of estimated hand meshes and the image. On the other hand, there are complex spatial relationship between interacting hands, which significantly increases the solution space of hand poses and increases the difficulty of network learning. In this paper, we propose a decoupled iterative refinement framework to achieve pixel-alignment hand reconstruction while efficiently modeling the spatial relationship between hands. Specifically, we define two feature spaces with different characteristics, namely 2D visual feature space and 3D joint feature space. First, we obtain joint-wise features from the visual feature map and utilize a graph convolution network and a transformer to perform intra- and inter-hand information interaction in the 3D joint fea",
    "link": "http://arxiv.org/abs/2302.02410",
    "context": "Title: Decoupled Iterative Refinement Framework for Interacting Hands Reconstruction from a Single RGB Image. (arXiv:2302.02410v2 [cs.CV] UPDATED)\nAbstract: Reconstructing interacting hands from a single RGB image is a very challenging task. On the one hand, severe mutual occlusion and similar local appearance between two hands confuse the extraction of visual features, resulting in the misalignment of estimated hand meshes and the image. On the other hand, there are complex spatial relationship between interacting hands, which significantly increases the solution space of hand poses and increases the difficulty of network learning. In this paper, we propose a decoupled iterative refinement framework to achieve pixel-alignment hand reconstruction while efficiently modeling the spatial relationship between hands. Specifically, we define two feature spaces with different characteristics, namely 2D visual feature space and 3D joint feature space. First, we obtain joint-wise features from the visual feature map and utilize a graph convolution network and a transformer to perform intra- and inter-hand information interaction in the 3D joint fea",
    "path": "papers/23/02/2302.02410.json",
    "total_tokens": 936,
    "translated_title": "单个RGB图像中相互作用的双手重建的分离迭代细化框架",
    "translated_abstract": "从单个RGB图像中重建相互作用的双手是一项非常具有挑战性的任务。一方面，两只手之间严重的互相遮挡和类似的局部外观使得视觉特征的提取变得困难，导致估计的手模型和图像的错位。另一方面，相互作用的双手之间存在复杂的空间关系，这显著增加了手姿态的解空间，增加了网络学习的难度。在本文中，我们提出了一个分离迭代细化框架，以实现像素对齐的手部重建，并高效地建模手之间的空间关系。具体而言，我们定义了两个具有不同特征的特征空间，即2D视觉特征空间和3D关节特征空间。首先，我们从视觉特征图中获取关节特征，并利用图卷积网络和变形器在3D关节特征空间进行手内部和手之间的信息交互。",
    "tldr": "本文提出了一种分离迭代细化框架，用于从单个RGB图像中重建相互作用的双手。通过定义2D视觉特征空间和3D关节特征空间，实现了手部重建的像素对齐，并高效地建模手之间的空间关系。",
    "en_tdlr": "This paper proposes a decoupled iterative refinement framework for reconstructing interacting hands from a single RGB image. By defining 2D visual feature space and 3D joint feature space, it achieves pixel-alignment hand reconstruction and efficiently models the spatial relationship between hands."
}