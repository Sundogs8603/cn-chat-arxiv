{
    "title": "Gradient Remedy for Multi-Task Learning in End-to-End Noise-Robust Speech Recognition. (arXiv:2302.11362v2 [eess.AS] UPDATED)",
    "abstract": "Speech enhancement (SE) is proved effective in reducing noise from noisy speech signals for downstream automatic speech recognition (ASR), where multi-task learning strategy is employed to jointly optimize these two tasks. However, the enhanced speech learned by SE objective may not always yield good ASR results. From the optimization view, there sometimes exists interference between the gradients of SE and ASR tasks, which could hinder the multi-task learning and finally lead to sub-optimal ASR performance. In this paper, we propose a simple yet effective approach called gradient remedy (GR) to solve interference between task gradients in noise-robust speech recognition, from perspectives of both angle and magnitude. Specifically, we first project the SE task's gradient onto a dynamic surface that is at acute angle to ASR gradient, in order to remove the conflict between them and assist in ASR optimization. Furthermore, we adaptively rescale the magnitude of two gradients to prevent t",
    "link": "http://arxiv.org/abs/2302.11362",
    "context": "Title: Gradient Remedy for Multi-Task Learning in End-to-End Noise-Robust Speech Recognition. (arXiv:2302.11362v2 [eess.AS] UPDATED)\nAbstract: Speech enhancement (SE) is proved effective in reducing noise from noisy speech signals for downstream automatic speech recognition (ASR), where multi-task learning strategy is employed to jointly optimize these two tasks. However, the enhanced speech learned by SE objective may not always yield good ASR results. From the optimization view, there sometimes exists interference between the gradients of SE and ASR tasks, which could hinder the multi-task learning and finally lead to sub-optimal ASR performance. In this paper, we propose a simple yet effective approach called gradient remedy (GR) to solve interference between task gradients in noise-robust speech recognition, from perspectives of both angle and magnitude. Specifically, we first project the SE task's gradient onto a dynamic surface that is at acute angle to ASR gradient, in order to remove the conflict between them and assist in ASR optimization. Furthermore, we adaptively rescale the magnitude of two gradients to prevent t",
    "path": "papers/23/02/2302.11362.json",
    "total_tokens": 702,
    "translated_abstract": "本文提出了一种称为渐变矫正（GR）的简单而有效的方法，用于消除噪音鲁棒语音识别中任务梯度之间的干扰。具体来说，我们将SE任务的梯度投影到ASR梯度的锐角动态平面上，以消除它们之间的冲突，并协助ASR优化。",
    "tldr": "本研究提出了一种渐变矫正的方法，用于消除多任务学习中梯度干扰，提高噪音鲁棒语音识别的性能。",
    "en_tdlr": "The proposed gradient remedy (GR) method aims to eliminate the interference between task gradients in noise-robust speech recognition, and thus achieves optimal performance in multi-task learning."
}