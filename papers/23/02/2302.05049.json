{
    "title": "Federated Auto-weighted Domain Adaptation. (arXiv:2302.05049v3 [cs.LG] UPDATED)",
    "abstract": "Federated Domain Adaptation (FDA) describes the federated learning setting where a set of source clients work collaboratively to improve the performance of a target client where limited data is available. The domain shift between the source and target domains, coupled with sparse data in the target domain, makes FDA a challenging problem, e.g., common techniques such as FedAvg and fine-tuning, often fail with the presence of significant domain shift and data scarcity. To comprehensively understand the problem, we introduce metrics that characterize the FDA setting and put forth a theoretical framework for analyzing the performance of aggregation rules. We also propose a novel aggregation rule for FDA, Federated Gradient Projection ($\\texttt{FedGP}$), used to aggregate the source gradients and target gradient during training. Importantly, our framework enables the development of an $\\textit{auto-weighting scheme}$ that optimally combines the source and target gradients. This scheme impr",
    "link": "http://arxiv.org/abs/2302.05049",
    "context": "Title: Federated Auto-weighted Domain Adaptation. (arXiv:2302.05049v3 [cs.LG] UPDATED)\nAbstract: Federated Domain Adaptation (FDA) describes the federated learning setting where a set of source clients work collaboratively to improve the performance of a target client where limited data is available. The domain shift between the source and target domains, coupled with sparse data in the target domain, makes FDA a challenging problem, e.g., common techniques such as FedAvg and fine-tuning, often fail with the presence of significant domain shift and data scarcity. To comprehensively understand the problem, we introduce metrics that characterize the FDA setting and put forth a theoretical framework for analyzing the performance of aggregation rules. We also propose a novel aggregation rule for FDA, Federated Gradient Projection ($\\texttt{FedGP}$), used to aggregate the source gradients and target gradient during training. Importantly, our framework enables the development of an $\\textit{auto-weighting scheme}$ that optimally combines the source and target gradients. This scheme impr",
    "path": "papers/23/02/2302.05049.json",
    "total_tokens": 943,
    "translated_title": "联邦自加权领域自适应",
    "translated_abstract": "联邦领域自适应（FDA）是描述多个源客户端协作改善目标客户端性能的联邦学习设置，其中目标领域数据有限。源领域和目标领域之间的领域转移，加上目标领域的稀疏数据，使得FDA成为一个具有挑战性的问题，例如，常见的技术（如FedAvg和微调）在存在显著领域转移和数据稀缺性时通常会失败。为了全面了解这个问题，我们介绍了表征FDA设置的度量标准，并提出了用于分析聚合规则性能的理论框架。我们还提出了用于FDA的一种新的聚合规则，称为联邦梯度投影（$\\texttt{FedGP}$），用于在训练期间聚合源梯度和目标梯度。重要的是，我们的框架使得开发一个自动加权方案成为可能，这个方案能够最优地结合源和目标梯度。",
    "tldr": "这篇论文提出了一种用于联邦领域自适应的新聚合规则-联邦梯度投影。在此基础上，开发了一个自动加权方案，用于最优地结合源和目标梯度，以解决在数据稀缺和领域转移时常见的技术失败的问题。",
    "en_tdlr": "This paper proposes a novel aggregation rule, Federated Gradient Projection, for Federated Domain Adaptation problem in the context of limited data and significant domain shift. The paper also develops an auto-weighting scheme to optimally combine the source and target gradient during training to overcome the challenges posed by data scarcity and domain shift."
}