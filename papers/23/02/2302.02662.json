{
    "title": "Grounding Large Language Models in Interactive Environments with Online Reinforcement Learning. (arXiv:2302.02662v2 [cs.LG] UPDATED)",
    "abstract": "Recent works successfully leveraged Large Language Models' (LLM) abilities to capture abstract knowledge about world's physics to solve decision-making problems. Yet, the alignment between LLMs' knowledge and the environment can be wrong and limit functional competence due to lack of grounding. In this paper, we study an approach (named GLAM) to achieve this alignment through functional grounding: we consider an agent using an LLM as a policy that is progressively updated as the agent interacts with the environment, leveraging online Reinforcement Learning to improve its performance to solve goals. Using an interactive textual environment designed to study higher-level forms of functional grounding, and a set of spatial and navigation tasks, we study several scientific questions: 1) Can LLMs boost sample efficiency for online learning of various RL tasks? 2) How can it boost different forms of generalization? 3) What is the impact of online learning? We study these questions by functio",
    "link": "http://arxiv.org/abs/2302.02662",
    "context": "Title: Grounding Large Language Models in Interactive Environments with Online Reinforcement Learning. (arXiv:2302.02662v2 [cs.LG] UPDATED)\nAbstract: Recent works successfully leveraged Large Language Models' (LLM) abilities to capture abstract knowledge about world's physics to solve decision-making problems. Yet, the alignment between LLMs' knowledge and the environment can be wrong and limit functional competence due to lack of grounding. In this paper, we study an approach (named GLAM) to achieve this alignment through functional grounding: we consider an agent using an LLM as a policy that is progressively updated as the agent interacts with the environment, leveraging online Reinforcement Learning to improve its performance to solve goals. Using an interactive textual environment designed to study higher-level forms of functional grounding, and a set of spatial and navigation tasks, we study several scientific questions: 1) Can LLMs boost sample efficiency for online learning of various RL tasks? 2) How can it boost different forms of generalization? 3) What is the impact of online learning? We study these questions by functio",
    "path": "papers/23/02/2302.02662.json",
    "total_tokens": 957,
    "translated_title": "在交互环境中使用在线强化学习对大型语言模型进行基础设施建设",
    "translated_abstract": "最近的研究成功地利用了大型语言模型（LLM）捕捉世界物理的抽象知识，以解决决策问题。然而，LLMs的知识与环境之间的对齐可能是错误的，并且由于缺乏基础设施建设而限制了其功能能力。在本文中，我们研究了一种通过功能基础设施建设实现这种对齐的方法（称为GLAM）：我们考虑一个使用LLM作为策略的代理程序，随着代理程序与环境进行交互而逐步更新，并利用在线强化学习来提高其解决目标的性能。使用一个交互式的文本环境设计来研究更高级形式的基础设施建设，以及一组空间和导航任务，我们研究了几个科学问题：1）LLMs能否提高各种RL任务的在线学习的样本效率？2）它如何提高不同形式的泛化？3）在线学习的影响是什么？我们通过功能方式研究这些问题。",
    "tldr": "本文研究了一种名为GLAM的方法，通过功能基础设施建设，利用在线强化学习提高LLM代理程序的性能来实现LLMs与环境之间的对齐，解决决策问题。"
}