{
    "title": "Off-the-Grid MARL: Datasets with Baselines for Offline Multi-Agent Reinforcement Learning. (arXiv:2302.00521v2 [cs.LG] UPDATED)",
    "abstract": "Being able to harness the power of large datasets for developing cooperative multi-agent controllers promises to unlock enormous value for real-world applications. Many important industrial systems are multi-agent in nature and are difficult to model using bespoke simulators. However, in industry, distributed processes can often be recorded during operation, and large quantities of demonstrative data stored. Offline multi-agent reinforcement learning (MARL) provides a promising paradigm for building effective decentralised controllers from such datasets. However, offline MARL is still in its infancy and therefore lacks standardised benchmark datasets and baselines typically found in more mature subfields of reinforcement learning (RL). These deficiencies make it difficult for the community to sensibly measure progress. In this work, we aim to fill this gap by releasing off-the-grid MARL (OG-MARL): a growing repository of high-quality datasets with baselines for cooperative offline MARL",
    "link": "http://arxiv.org/abs/2302.00521",
    "context": "Title: Off-the-Grid MARL: Datasets with Baselines for Offline Multi-Agent Reinforcement Learning. (arXiv:2302.00521v2 [cs.LG] UPDATED)\nAbstract: Being able to harness the power of large datasets for developing cooperative multi-agent controllers promises to unlock enormous value for real-world applications. Many important industrial systems are multi-agent in nature and are difficult to model using bespoke simulators. However, in industry, distributed processes can often be recorded during operation, and large quantities of demonstrative data stored. Offline multi-agent reinforcement learning (MARL) provides a promising paradigm for building effective decentralised controllers from such datasets. However, offline MARL is still in its infancy and therefore lacks standardised benchmark datasets and baselines typically found in more mature subfields of reinforcement learning (RL). These deficiencies make it difficult for the community to sensibly measure progress. In this work, we aim to fill this gap by releasing off-the-grid MARL (OG-MARL): a growing repository of high-quality datasets with baselines for cooperative offline MARL",
    "path": "papers/23/02/2302.00521.json",
    "total_tokens": 900,
    "translated_title": "Off-the-Grid MARL: 带有基准的离线多智能体增强学习数据集",
    "translated_abstract": "能够利用大型数据集开发合作多智能体控制器，为实际应用开启了巨大的价值。许多重要的工业系统是多智能体的，并且很难使用定制的模拟器进行建模。然而，在工业中，分布式进程经常可以在运行期间记录，并存储大量的演示数据。离线多智能体增强学习（MARL）为利用这些数据建立有效的分散式控制器提供了有希望的范例。然而，离线MARL仍处于起步阶段，因此缺乏在强化学习更成熟的子领域中通常会找到的标准化基准数据集和基线。这些不足使得社区无法合理地衡量进展。在这项工作中，我们旨在通过发布Off-the-Grid MARL（OG-MARL）来填补这个空白：一个不断增长的高质量数据集存储库，其中包含协作离线MARL的基准。",
    "tldr": "这项工作填补了离线多智能体增强学习（MARL）领域的一个空白，提供了Off-the-Grid MARL（OG-MARL）数据集和基准，帮助社区衡量进展。",
    "en_tdlr": "This work fills a gap in the field of offline multi-agent reinforcement learning (MARL) by providing the Off-the-Grid MARL (OG-MARL) dataset with baselines, enabling the community to measure progress."
}