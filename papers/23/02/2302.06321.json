{
    "title": "Parameter-efficient Modularised Bias Mitigation via AdapterFusion. (arXiv:2302.06321v2 [cs.CL] UPDATED)",
    "abstract": "Large pre-trained language models contain societal biases and carry along these biases to downstream tasks. Current in-processing bias mitigation approaches (like adversarial training) impose debiasing by updating a model's parameters, effectively transferring the model to a new, irreversible debiased state. In this work, we propose a novel approach to develop stand-alone debiasing functionalities separate from the model, which can be integrated into the model on-demand, while keeping the core model untouched. Drawing from the concept of AdapterFusion in multi-task learning, we introduce DAM (Debiasing with Adapter Modules) - a debiasing approach to first encapsulate arbitrary bias mitigation functionalities into separate adapters, and then add them to the model on-demand in order to deliver fairness qualities. We conduct a large set of experiments on three classification tasks with gender, race, and age as protected attributes. Our results show that DAM improves or maintains the effec",
    "link": "http://arxiv.org/abs/2302.06321",
    "context": "Title: Parameter-efficient Modularised Bias Mitigation via AdapterFusion. (arXiv:2302.06321v2 [cs.CL] UPDATED)\nAbstract: Large pre-trained language models contain societal biases and carry along these biases to downstream tasks. Current in-processing bias mitigation approaches (like adversarial training) impose debiasing by updating a model's parameters, effectively transferring the model to a new, irreversible debiased state. In this work, we propose a novel approach to develop stand-alone debiasing functionalities separate from the model, which can be integrated into the model on-demand, while keeping the core model untouched. Drawing from the concept of AdapterFusion in multi-task learning, we introduce DAM (Debiasing with Adapter Modules) - a debiasing approach to first encapsulate arbitrary bias mitigation functionalities into separate adapters, and then add them to the model on-demand in order to deliver fairness qualities. We conduct a large set of experiments on three classification tasks with gender, race, and age as protected attributes. Our results show that DAM improves or maintains the effec",
    "path": "papers/23/02/2302.06321.json",
    "total_tokens": 927,
    "translated_title": "通过AdapterFusion实现参数高效的模块化偏差修正",
    "translated_abstract": "大型预训练语言模型存在社会偏见，并将这些偏见带给下游任务。当前的内部处理偏差修正方法（如对抗训练）通过更新模型参数来施加去偏差，从而将模型转移到新的、不可逆的去偏差状态。在本文中，我们提出了一种新颖的方法，开发出了独立的去偏差功能，与模型分离，可以按需集成到模型中，同时保持核心模型不变。借鉴多任务学习中的AdapterFusion概念，我们引入了DAM（使用适配器模块进行去偏差）——一种去偏差方法，首先将任意偏差修正功能封装到独立的适配器中，然后按需将它们添加到模型中，以实现公平性。我们在三种分类任务上进行了大量实验，保护属性为性别、种族和年龄。我们的结果表明，DAM改进或保持了模型的效果。",
    "tldr": "本文提出了一个新的去偏差方法——DAM，它采用AdapterFusion概念，将偏差修正功能封装到独立的适配器中，在不影响核心模型的情况下，实现了按需的去偏差，可以有效降低模型的偏见问题。",
    "en_tdlr": "This paper proposes a novel debiasing approach called DAM, using the concept of AdapterFusion to encapsulate bias mitigation functionalities into separate adapters and integrate them into the model on-demand while keeping the core model untouched. The results of experiments on three classification tasks show that DAM improves or maintains the effectiveness of the model."
}