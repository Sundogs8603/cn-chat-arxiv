{
    "title": "Protecting Language Generation Models via Invisible Watermarking. (arXiv:2302.03162v2 [cs.CR] UPDATED)",
    "abstract": "Language generation models have been an increasingly powerful enabler for many applications. Many such models offer free or affordable API access, which makes them potentially vulnerable to model extraction attacks through distillation. To protect intellectual property (IP) and ensure fair use of these models, various techniques such as lexical watermarking and synonym replacement have been proposed. However, these methods can be nullified by obvious countermeasures such as \"synonym randomization\". To address this issue, we propose GINSEW, a novel method to protect text generation models from being stolen through distillation. The key idea of our method is to inject secret signals into the probability vector of the decoding steps for each target token. We can then detect the secret message by probing a suspect model to tell if it is distilled from the protected one. Experimental results show that GINSEW can effectively identify instances of IP infringement with minimal impact on the ge",
    "link": "http://arxiv.org/abs/2302.03162",
    "context": "Title: Protecting Language Generation Models via Invisible Watermarking. (arXiv:2302.03162v2 [cs.CR] UPDATED)\nAbstract: Language generation models have been an increasingly powerful enabler for many applications. Many such models offer free or affordable API access, which makes them potentially vulnerable to model extraction attacks through distillation. To protect intellectual property (IP) and ensure fair use of these models, various techniques such as lexical watermarking and synonym replacement have been proposed. However, these methods can be nullified by obvious countermeasures such as \"synonym randomization\". To address this issue, we propose GINSEW, a novel method to protect text generation models from being stolen through distillation. The key idea of our method is to inject secret signals into the probability vector of the decoding steps for each target token. We can then detect the secret message by probing a suspect model to tell if it is distilled from the protected one. Experimental results show that GINSEW can effectively identify instances of IP infringement with minimal impact on the ge",
    "path": "papers/23/02/2302.03162.json",
    "total_tokens": 905,
    "translated_title": "通过隐形水印保护语言生成模型",
    "translated_abstract": "语言生成模型是许多应用的有力支持者。许多这样的模型提供免费或经济实惠的 API 访问，这使它们可能受到模型抽取攻击的威胁。为了保护知识产权并确保这些模型的公正使用，已经提出了各种技术，例如词汇水印和同义词替换。然而，这些方法可能会被明显的对策如“同义词随机化”等所抵消。为了解决这个问题，我们提出了 GINSEW，一种新的方法，用于通过蒸馏保护文本生成模型。我们的方法的关键思想是将秘密信号注入到每个目标标记的解码步骤的概率向量中。然后，我们可以通过探测嫌疑的模型来检测秘密消息是否由受保护的模型蒸馏而来。实验结果表明，GINSEW 可以有效地识别出侵权行为，对生成模型的影响极小。",
    "tldr": "本文提出了一种名为 GINSEW 的新方法，通过将秘密信号注入到每个目标标记的解码步骤的概率向量中，保护文本生成模型，有效识别出侵权行为，对模型的影响很小。"
}