{
    "title": "Towards Universal Fake Image Detectors that Generalize Across Generative Models",
    "abstract": "arXiv:2302.10174v2 Announce Type: replace-cross  Abstract: With generative models proliferating at a rapid rate, there is a growing need for general purpose fake image detectors. In this work, we first show that the existing paradigm, which consists of training a deep network for real-vs-fake classification, fails to detect fake images from newer breeds of generative models when trained to detect GAN fake images. Upon analysis, we find that the resulting classifier is asymmetrically tuned to detect patterns that make an image fake. The real class becomes a sink class holding anything that is not fake, including generated images from models not accessible during training. Building upon this discovery, we propose to perform real-vs-fake classification without learning; i.e., using a feature space not explicitly trained to distinguish real from fake images. We use nearest neighbor and linear probing as instantiations of this idea. When given access to the feature space of a large pretrain",
    "link": "https://arxiv.org/abs/2302.10174",
    "context": "Title: Towards Universal Fake Image Detectors that Generalize Across Generative Models\nAbstract: arXiv:2302.10174v2 Announce Type: replace-cross  Abstract: With generative models proliferating at a rapid rate, there is a growing need for general purpose fake image detectors. In this work, we first show that the existing paradigm, which consists of training a deep network for real-vs-fake classification, fails to detect fake images from newer breeds of generative models when trained to detect GAN fake images. Upon analysis, we find that the resulting classifier is asymmetrically tuned to detect patterns that make an image fake. The real class becomes a sink class holding anything that is not fake, including generated images from models not accessible during training. Building upon this discovery, we propose to perform real-vs-fake classification without learning; i.e., using a feature space not explicitly trained to distinguish real from fake images. We use nearest neighbor and linear probing as instantiations of this idea. When given access to the feature space of a large pretrain",
    "path": "papers/23/02/2302.10174.json",
    "total_tokens": 855,
    "translated_title": "通向跨生成模型泛化的通用假图像检测器",
    "translated_abstract": "随着生成模型的快速增多，对于通用目的的假图像检测器的需求正在增长。本文首先展示了现有范式的失败，该范式包括训练深度网络进行真假分类，当训练以检测GAN伪图像时，无法检测到来自新型生成模型的假图像。通过分析，我们发现得到的分类器对检测使图像伪造的模式进行了不对称调整。真实类成为一个盛放任何非假的东西的汇类，包括在训练期间无法访问的模型生成的图像。基于这一发现，我们提出执行真伪分类而不进行学习；即使用非明确训练以区分真假图像的特征空间。我们使用最近邻和线性探查作为这一想法的实例化。当提供对一个大型预训练特征空间的访问时，我们能够比现有的[image-based]学习方法更好地区分不同的生成模型来源的图像。",
    "tldr": "通过在不进行训练的情况下执行真伪图像分类，使用非明确区分特征空间，可以更好地识别不同生成模型来源的图像。",
    "en_tdlr": "By performing real-vs-fake image classification without training, using an implicitly distinguishing feature space, images from different generative model sources can be better distinguished."
}