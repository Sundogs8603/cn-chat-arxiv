{
    "title": "Stitchable Neural Networks. (arXiv:2302.06586v3 [cs.LG] UPDATED)",
    "abstract": "The public model zoo containing enormous powerful pretrained model families (e.g., ResNet/DeiT) has reached an unprecedented scope than ever, which significantly contributes to the success of deep learning. As each model family consists of pretrained models with diverse scales (e.g., DeiT-Ti/S/B), it naturally arises a fundamental question of how to efficiently assemble these readily available models in a family for dynamic accuracy-efficiency trade-offs at runtime. To this end, we present Stitchable Neural Networks (SN-Net), a novel scalable and efficient framework for model deployment. It cheaply produces numerous networks with different complexity and performance trade-offs given a family of pretrained neural networks, which we call anchors. Specifically, SN-Net splits the anchors across the blocks/layers and then stitches them together with simple stitching layers to map the activations from one anchor to another. With only a few epochs of training, SN-Net effectively interpolates ",
    "link": "http://arxiv.org/abs/2302.06586",
    "context": "Title: Stitchable Neural Networks. (arXiv:2302.06586v3 [cs.LG] UPDATED)\nAbstract: The public model zoo containing enormous powerful pretrained model families (e.g., ResNet/DeiT) has reached an unprecedented scope than ever, which significantly contributes to the success of deep learning. As each model family consists of pretrained models with diverse scales (e.g., DeiT-Ti/S/B), it naturally arises a fundamental question of how to efficiently assemble these readily available models in a family for dynamic accuracy-efficiency trade-offs at runtime. To this end, we present Stitchable Neural Networks (SN-Net), a novel scalable and efficient framework for model deployment. It cheaply produces numerous networks with different complexity and performance trade-offs given a family of pretrained neural networks, which we call anchors. Specifically, SN-Net splits the anchors across the blocks/layers and then stitches them together with simple stitching layers to map the activations from one anchor to another. With only a few epochs of training, SN-Net effectively interpolates ",
    "path": "papers/23/02/2302.06586.json",
    "total_tokens": 955,
    "translated_title": "可缝合神经网络",
    "translated_abstract": "具有巨大威力的预训练模型集群(如ResNet/DeiT)所构成的公共模型库已经达到了前所未有的范围，这在很大程度上促进了深度学习的成功。然而，每个模型系列都包含着不同规模的预训练模型(比如DeiT-Ti/S/B)，这自然地引出了一个基本问题：如何在运行时有效地组合这些可用的模型系列以实现动态的精度-效率权衡。针对这个问题，我们提出了Stitchable Neural Networks (SN-Net)，这是一个新颖的可扩展、高效的模型部署框架。在一个预先训练的神经网络家族中，它可以便宜地产生许多不同复杂度和性能权衡的网络，我们称之为锚点。具体来说，SN-Net将锚点分散在块/层之间，然后使用简单的缝合层将它们拼接在一起，以映射一个锚点的激活到另一个锚点。仅仅通过几个轮次的训练，SN-Net可以有效地插值网络。",
    "tldr": "本文提出了一个名为SN-Net的框架，它可以便宜地产生许多不同复杂度和性能权衡的网络，利用预先训练的神经网络家族作为锚点，并使用简单的缝合层将它们拼接在一起以实现动态的精度-效率权衡。",
    "en_tdlr": "This paper proposes a framework called SN-Net that can cheaply produce networks with different complexity and performance trade-offs using a family of pretrained neural networks as anchors, and stitches them together with simple stitching layers for dynamic accuracy-efficiency trade-offs."
}