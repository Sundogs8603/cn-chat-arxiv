{
    "title": "Meta-Learning Siamese Network for Few-Shot Text Classification. (arXiv:2302.03507v2 [cs.CL] UPDATED)",
    "abstract": "Few-shot learning has been used to tackle the problem of label scarcity in text classification, of which meta-learning based methods have shown to be effective, such as the prototypical networks (PROTO). Despite the success of PROTO, there still exist three main problems: (1) ignore the randomness of the sampled support sets when computing prototype vectors; (2) disregard the importance of labeled samples; (3) construct meta-tasks in a purely random manner. In this paper, we propose a Meta-Learning Siamese Network, namely, Meta-SN, to address these issues. Specifically, instead of computing prototype vectors from the sampled support sets, Meta-SN utilizes external knowledge (e.g. class names and descriptive texts) for class labels, which is encoded as the low-dimensional embeddings of prototype vectors. In addition, Meta-SN presents a novel sampling strategy for constructing meta-tasks, which gives higher sampling probabilities to hard-to-classify samples. Extensive experiments are con",
    "link": "http://arxiv.org/abs/2302.03507",
    "context": "Title: Meta-Learning Siamese Network for Few-Shot Text Classification. (arXiv:2302.03507v2 [cs.CL] UPDATED)\nAbstract: Few-shot learning has been used to tackle the problem of label scarcity in text classification, of which meta-learning based methods have shown to be effective, such as the prototypical networks (PROTO). Despite the success of PROTO, there still exist three main problems: (1) ignore the randomness of the sampled support sets when computing prototype vectors; (2) disregard the importance of labeled samples; (3) construct meta-tasks in a purely random manner. In this paper, we propose a Meta-Learning Siamese Network, namely, Meta-SN, to address these issues. Specifically, instead of computing prototype vectors from the sampled support sets, Meta-SN utilizes external knowledge (e.g. class names and descriptive texts) for class labels, which is encoded as the low-dimensional embeddings of prototype vectors. In addition, Meta-SN presents a novel sampling strategy for constructing meta-tasks, which gives higher sampling probabilities to hard-to-classify samples. Extensive experiments are con",
    "path": "papers/23/02/2302.03507.json",
    "total_tokens": 973,
    "translated_title": "几乎没有标签的文本分类的元学习连对网络",
    "translated_abstract": "几乎没有标签的文本分类问题可以通过少量样本训练数据来解决，其中元学习方法（例如PROTO）已经被证明是有效的。本文提出了一种元学习连对网络，Meta-SN，来解决PROTO方法中存在的三个问题：（1）忽略了计算原型向量时采样支持集的随机性；（2）忽略了标记样本的重要性；（3）以纯随机方式构建元任务。Meta-SN利用外部知识（例如类别名称和描述文本）来编码类别标签的低维嵌入向量，而不是从采样支持集中计算原型向量。此外，Meta-SN提出了一种新的采样策略，即增加了对难以分类样本的采样概率。在基准数据集上进行了大量的实验，结果表明Meta-SN优于包括PROTO在内的多种最先进的少样本学习方法。",
    "tldr": "本文提出了Meta-SN，一种基于元学习的连对网络，用于解决几乎没有标签的文本分类问题。Meta-SN通过使用外部知识来编码类别标签的低维嵌入向量，并提出新的采样策略，克服了信念网络算法中的一些问题，提高了少样本学习的准确性。"
}