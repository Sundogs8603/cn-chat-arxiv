{
    "title": "Adding Conditional Control to Text-to-Image Diffusion Models. (arXiv:2302.05543v2 [cs.CV] UPDATED)",
    "abstract": "We present ControlNet, a neural network architecture to add spatial conditioning controls to large, pretrained text-to-image diffusion models. ControlNet locks the production-ready large diffusion models, and reuses their deep and robust encoding layers pretrained with billions of images as a strong backbone to learn a diverse set of conditional controls. The neural architecture is connected with \"zero convolutions\" (zero-initialized convolution layers) that progressively grow the parameters from zero and ensure that no harmful noise could affect the finetuning. We test various conditioning controls, eg, edges, depth, segmentation, human pose, etc, with Stable Diffusion, using single or multiple conditions, with or without prompts. We show that the training of ControlNets is robust with small (<50k) and large (>1m) datasets. Extensive results show that ControlNet may facilitate wider applications to control image diffusion models.",
    "link": "http://arxiv.org/abs/2302.05543",
    "context": "Title: Adding Conditional Control to Text-to-Image Diffusion Models. (arXiv:2302.05543v2 [cs.CV] UPDATED)\nAbstract: We present ControlNet, a neural network architecture to add spatial conditioning controls to large, pretrained text-to-image diffusion models. ControlNet locks the production-ready large diffusion models, and reuses their deep and robust encoding layers pretrained with billions of images as a strong backbone to learn a diverse set of conditional controls. The neural architecture is connected with \"zero convolutions\" (zero-initialized convolution layers) that progressively grow the parameters from zero and ensure that no harmful noise could affect the finetuning. We test various conditioning controls, eg, edges, depth, segmentation, human pose, etc, with Stable Diffusion, using single or multiple conditions, with or without prompts. We show that the training of ControlNets is robust with small (<50k) and large (>1m) datasets. Extensive results show that ControlNet may facilitate wider applications to control image diffusion models.",
    "path": "papers/23/02/2302.05543.json",
    "total_tokens": 931,
    "translated_title": "在文本到图像扩散模型中添加条件控制",
    "translated_abstract": "我们提出了ControlNet，一种神经网络架构，可以为大规模预训练的文本到图像扩散模型添加空间条件控制。ControlNet锁定了生产就绪的大型扩散模型，并重复使用它们以数十亿张图像进行预训练的深度和稳健的编码层作为强大的骨干，从而学习多样化的条件控制。该神经架构与“零卷积”（零初始化的卷积层）连接，从零开始逐渐增加参数，并确保没有有害的噪声影响微调。我们使用单个或多个条件进行稳定扩散测试了各种条件控制，例如边缘、深度、分割、人体姿势等，并且可以有或没有提示。我们展示了ControlNets的训练对于小（<50k）和大（>1m）数据集是鲁棒的。广泛的结果表明，ControlNet可以促进更广泛的应用以控制图像扩散模型。",
    "tldr": "ControlNet是一种神经网络架构，用于为大规模预训练的文本到图像扩散模型添加条件控制。它可以通过重复使用预先训练的编码层学习多样的条件控制，并通过逐渐增加参数进行微调，从而在控制图像扩散模型方面具有鲁棒性。",
    "en_tdlr": "ControlNet is a neural network architecture that adds conditional controls to large pretrained text-to-image diffusion models. It uses pretrained encoding layers as a backbone to learn diverse conditional controls and fine-tunes the model by gradually increasing parameters, resulting in robust control of image diffusion models."
}