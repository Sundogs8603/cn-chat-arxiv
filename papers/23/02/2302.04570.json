{
    "title": "NeuKron: Constant-Size Lossy Compression of Sparse Reorderable Matrices and Tensors. (arXiv:2302.04570v2 [cs.LG] UPDATED)",
    "abstract": "Many real-world data are naturally represented as a sparse reorderable matrix, whose rows and columns can be arbitrarily ordered (e.g., the adjacency matrix of a bipartite graph). Storing a sparse matrix in conventional ways requires an amount of space linear in the number of non-zeros, and lossy compression of sparse matrices (e.g., Truncated SVD) typically requires an amount of space linear in the number of rows and columns. In this work, we propose NeuKron for compressing a sparse reorderable matrix into a constant-size space. NeuKron generalizes Kronecker products using a recurrent neural network with a constant number of parameters. NeuKron updates the parameters so that a given matrix is approximated by the product and reorders the rows and columns of the matrix to facilitate the approximation. The updates take time linear in the number of non-zeros in the input matrix, and the approximation of each entry can be retrieved in logarithmic time. We also extend NeuKron to compress sp",
    "link": "http://arxiv.org/abs/2302.04570",
    "context": "Title: NeuKron: Constant-Size Lossy Compression of Sparse Reorderable Matrices and Tensors. (arXiv:2302.04570v2 [cs.LG] UPDATED)\nAbstract: Many real-world data are naturally represented as a sparse reorderable matrix, whose rows and columns can be arbitrarily ordered (e.g., the adjacency matrix of a bipartite graph). Storing a sparse matrix in conventional ways requires an amount of space linear in the number of non-zeros, and lossy compression of sparse matrices (e.g., Truncated SVD) typically requires an amount of space linear in the number of rows and columns. In this work, we propose NeuKron for compressing a sparse reorderable matrix into a constant-size space. NeuKron generalizes Kronecker products using a recurrent neural network with a constant number of parameters. NeuKron updates the parameters so that a given matrix is approximated by the product and reorders the rows and columns of the matrix to facilitate the approximation. The updates take time linear in the number of non-zeros in the input matrix, and the approximation of each entry can be retrieved in logarithmic time. We also extend NeuKron to compress sp",
    "path": "papers/23/02/2302.04570.json",
    "total_tokens": 969,
    "translated_title": "NeuKron: 稀疏可重排矩阵和张量的常数大小有损压缩",
    "translated_abstract": "许多真实世界的数据自然地被表示为稀疏可重排矩阵，其行和列可以任意排序(例如双分图的邻接矩阵)。将稀疏矩阵存储在传统的方式需要线性数量的空间来存储非零元素，而稀疏矩阵的有损压缩(例如截断SVD)通常需要与行和列的数量成线性关系的空间。本文提出了一种称为NeuKron的方法，用于将稀疏可重排矩阵压缩至常数大小的空间。NeuKron使用具有常数参数数量的循环神经网络泛化Kronecker乘积。NeuKron通过更新参数来近似给定矩阵的乘积，并重新排列矩阵的行和列以便于近似。更新所需的时间为输入矩阵中非零元素的线性时间，并且每个条目的近似可以在对数时间内检索。我们还将NeuKron扩展到可以压缩具有常数参数数量的稀疏可重排张量。",
    "tldr": "NeuKron提出了一种可以将稀疏可重排矩阵和张量压缩至常数大小的方法，其使用了循环神经网络并能在线性时间内更新参数，同时可以在对数时间内检索每个条目的近似。",
    "en_tdlr": "NeuKron proposes a method to compress sparse reorderable matrices and tensors into a constant-size space using a recurrent neural network with linear time updates and logarithmic time retrieval of each entry's approximation."
}