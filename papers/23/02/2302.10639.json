{
    "title": "Handling Long and Richly Constrained Tasks through Constrained Hierarchical Reinforcement Learning. (arXiv:2302.10639v2 [cs.AI] UPDATED)",
    "abstract": "Safety in goal directed Reinforcement Learning (RL) settings has typically been handled through constraints over trajectories and have demonstrated good performance in primarily short horizon tasks. In this paper, we are specifically interested in the problem of solving temporally extended decision making problems such as robots cleaning different areas in a house while avoiding slippery and unsafe areas (e.g., stairs) and retaining enough charge to move to a charging dock; in the presence of complex safety constraints. Our key contribution is a (safety) Constrained Search with Hierarchical Reinforcement Learning (CoSHRL) mechanism that combines an upper level constrained search agent (which computes a reward maximizing policy from a given start to a far away goal state while satisfying cost constraints) with a low-level goal conditioned RL agent (which estimates cost and reward values to move between nearby states). A major advantage of CoSHRL is that it can handle constraints on the ",
    "link": "http://arxiv.org/abs/2302.10639",
    "context": "Title: Handling Long and Richly Constrained Tasks through Constrained Hierarchical Reinforcement Learning. (arXiv:2302.10639v2 [cs.AI] UPDATED)\nAbstract: Safety in goal directed Reinforcement Learning (RL) settings has typically been handled through constraints over trajectories and have demonstrated good performance in primarily short horizon tasks. In this paper, we are specifically interested in the problem of solving temporally extended decision making problems such as robots cleaning different areas in a house while avoiding slippery and unsafe areas (e.g., stairs) and retaining enough charge to move to a charging dock; in the presence of complex safety constraints. Our key contribution is a (safety) Constrained Search with Hierarchical Reinforcement Learning (CoSHRL) mechanism that combines an upper level constrained search agent (which computes a reward maximizing policy from a given start to a far away goal state while satisfying cost constraints) with a low-level goal conditioned RL agent (which estimates cost and reward values to move between nearby states). A major advantage of CoSHRL is that it can handle constraints on the ",
    "path": "papers/23/02/2302.10639.json",
    "total_tokens": 868,
    "translated_title": "通过约束层次强化学习处理长期和丰富约束的任务",
    "translated_abstract": "过去在目标导向的强化学习（RL）设置中，通常通过对轨迹施加约束来处理安全问题，对于短期任务表现良好。本文特别关注解决时间上延续的决策问题，例如机器人在清洁房屋的不同区域时，需要避开湿滑和不安全的区域（例如楼梯），同时保持足够的电量移动到充电站；而且面临复杂的安全约束。我们的主要创新是将上层的约束搜索代理（从给定的起始状态到远处目标状态计算最大化回报策略，同时满足成本约束）与底层的目标条件强化学习代理（估计在附近状态之间移动的成本和回报值）结合使用的安全约束搜索与层次强化学习（CoSHRL）机制。CoSHRL的一个主要优势在于它可以处理对轨迹上的约束。",
    "tldr": "本文通过约束层次强化学习的机制解决了长期和丰富约束的任务，在机器人清洁房屋的场景中展示了良好的性能。",
    "en_tdlr": "This paper addresses long and richly constrained tasks by introducing a Constrained Search with Hierarchical Reinforcement Learning (CoSHRL) mechanism and demonstrates its effectiveness in a scenario of robots cleaning a house."
}