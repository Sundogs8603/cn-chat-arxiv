{
    "title": "Deep reinforced learning heuristic tested on spin-glass ground states: The larger picture. (arXiv:2302.10848v2 [cond-mat.dis-nn] UPDATED)",
    "abstract": "In Changjun Fan et al. [Nature Communications https://doi.org/10.1038/s41467-023-36363-w (2023)], the authors present a deep reinforced learning approach to augment combinatorial optimization heuristics. In particular, they present results for several spin glass ground state problems, for which instances on non-planar networks are generally NP-hard, in comparison with several Monte Carlo based methods, such as simulated annealing (SA) or parallel tempering (PT). Indeed, those results demonstrate that the reinforced learning improves the results over those obtained with SA or PT, or at least allows for reduced runtimes for the heuristics before results of comparable quality have been obtained relative to those other methods. To facilitate the conclusion that their method is ''superior'', the authors pursue two basic strategies: (1) A commercial GUROBI solver is called on to procure a sample of exact ground states as a testbed to compare with, and (2) a head-to-head comparison between th",
    "link": "http://arxiv.org/abs/2302.10848",
    "context": "Title: Deep reinforced learning heuristic tested on spin-glass ground states: The larger picture. (arXiv:2302.10848v2 [cond-mat.dis-nn] UPDATED)\nAbstract: In Changjun Fan et al. [Nature Communications https://doi.org/10.1038/s41467-023-36363-w (2023)], the authors present a deep reinforced learning approach to augment combinatorial optimization heuristics. In particular, they present results for several spin glass ground state problems, for which instances on non-planar networks are generally NP-hard, in comparison with several Monte Carlo based methods, such as simulated annealing (SA) or parallel tempering (PT). Indeed, those results demonstrate that the reinforced learning improves the results over those obtained with SA or PT, or at least allows for reduced runtimes for the heuristics before results of comparable quality have been obtained relative to those other methods. To facilitate the conclusion that their method is ''superior'', the authors pursue two basic strategies: (1) A commercial GUROBI solver is called on to procure a sample of exact ground states as a testbed to compare with, and (2) a head-to-head comparison between th",
    "path": "papers/23/02/2302.10848.json",
    "total_tokens": 966,
    "translated_title": "基于深度强化学习的启发式方法在自旋玻璃基态问题上的测试：更广泛的视角",
    "translated_abstract": "在Changjun Fan等人的研究中，作者们提出了一种基于深度强化学习的方法来增强组合优化启发式方法。具体而言，他们针对几个自旋玻璃基态问题展示了结果，其中非平面网络上的实例通常是NP困难的，与几种基于蒙特卡洛的方法进行比较，如模拟退火（SA）或并行退火（PT）。事实上，这些结果表明，强化学习相对于SA或PT改进了结果，或者至少在获得与其他方法相当质量的结果之前，减少了启发式方法的运行时间。为了证明他们的方法“优越”，作者采取了两种基本策略：（1）调用商业GUROBI求解器获取一些精确基态样本作为测试基准进行比较，以及（2）将他们的方法与其他策略进行了直接对比。",
    "tldr": "该研究提出了一种基于深度强化学习的启发式方法，用于增强组合优化过程，并在自旋玻璃基态问题上取得了改进结果。研究结果表明，相对于传统方法如模拟退火或并行退火，强化学习方法在提供相当质量的结果之前减少了运行时间。"
}