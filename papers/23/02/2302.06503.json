{
    "title": "Ground(less) Truth: A Causal Framework for Proxy Labels in Human-Algorithm Decision-Making. (arXiv:2302.06503v4 [cs.CY] UPDATED)",
    "abstract": "A growing literature on human-AI decision-making investigates strategies for combining human judgment with statistical models to improve decision-making. Research in this area often evaluates proposed improvements to models, interfaces, or workflows by demonstrating improved predictive performance on \"ground truth\" labels. However, this practice overlooks a key difference between human judgments and model predictions. Whereas humans reason about broader phenomena of interest in a decision -- including latent constructs that are not directly observable, such as disease status, the \"toxicity\" of online comments, or future \"job performance\" -- predictive models target proxy labels that are readily available in existing datasets. Predictive models' reliance on simplistic proxies makes them vulnerable to various sources of statistical bias. In this paper, we identify five sources of target variable bias that can impact the validity of proxy labels in human-AI decision-making tasks. We devel",
    "link": "http://arxiv.org/abs/2302.06503",
    "context": "Title: Ground(less) Truth: A Causal Framework for Proxy Labels in Human-Algorithm Decision-Making. (arXiv:2302.06503v4 [cs.CY] UPDATED)\nAbstract: A growing literature on human-AI decision-making investigates strategies for combining human judgment with statistical models to improve decision-making. Research in this area often evaluates proposed improvements to models, interfaces, or workflows by demonstrating improved predictive performance on \"ground truth\" labels. However, this practice overlooks a key difference between human judgments and model predictions. Whereas humans reason about broader phenomena of interest in a decision -- including latent constructs that are not directly observable, such as disease status, the \"toxicity\" of online comments, or future \"job performance\" -- predictive models target proxy labels that are readily available in existing datasets. Predictive models' reliance on simplistic proxies makes them vulnerable to various sources of statistical bias. In this paper, we identify five sources of target variable bias that can impact the validity of proxy labels in human-AI decision-making tasks. We devel",
    "path": "papers/23/02/2302.06503.json",
    "total_tokens": 994,
    "translated_title": "没有地基的真相：人工智能决策中代理标签的因果框架",
    "translated_abstract": "越来越多关于人工智能决策的文献调查将人类判断与统计模型相结合以改善决策质量。该领域的研究通常通过展示对“地基”标签的预测性能来评估所提出的改进模型、接口或工作流程的有效性。然而，这种做法忽略了人类判断与模型预测之间的一个关键差异。而预测模型则仅针对可在现有数据集中轻松获取的代理标签。预测模型依赖于简单代理标签，因此容易受到各种统计偏差的影响。本文识别了人工智能决策中可能影响代理标签有效性的五种目标变量偏差来源。我们提出一个因果框架来理解这些偏差来源及其对决策质量带来的风险。我们认为仅根据地基标签来评估决策支持系统可能会产生误导性，同时建议未来的工作强调针对较广泛的问题感兴趣的因果评估候选方法。",
    "tldr": "本文提出了一个因果框架，解释了在人工智能决策中使用的代理标签可能存在的目标变量偏差，并提出未来研究应强调针对较广泛问题的因果评估。",
    "en_tdlr": "This paper proposes a causal framework to explain the potential target variable bias of proxy labels used in AI decision-making, and suggests that future research emphasize causal evaluation of broader phenomena of interest."
}