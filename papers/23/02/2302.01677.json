{
    "title": "Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks. (arXiv:2302.01677v2 [cs.LG] UPDATED)",
    "abstract": "In this work, besides improving prediction accuracy, we study whether personalization could bring robustness benefits to backdoor attacks. We conduct the first study of backdoor attacks in the pFL framework, testing 4 widely used backdoor attacks against 6 pFL methods on benchmark datasets FEMNIST and CIFAR-10, a total of 600 experiments. The study shows that pFL methods with partial model-sharing can significantly boost robustness against backdoor attacks. In contrast, pFL methods with full model-sharing do not show robustness. To analyze the reasons for varying robustness performances, we provide comprehensive ablation studies on different pFL methods. Based on our findings, we further propose a lightweight defense method, Simple-Tuning, which empirically improves defense performance against backdoor attacks. We believe that our work could provide both guidance for pFL application in terms of its robustness and offer valuable insights to design more robust FL methods in the future. W",
    "link": "http://arxiv.org/abs/2302.01677",
    "context": "Title: Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks. (arXiv:2302.01677v2 [cs.LG] UPDATED)\nAbstract: In this work, besides improving prediction accuracy, we study whether personalization could bring robustness benefits to backdoor attacks. We conduct the first study of backdoor attacks in the pFL framework, testing 4 widely used backdoor attacks against 6 pFL methods on benchmark datasets FEMNIST and CIFAR-10, a total of 600 experiments. The study shows that pFL methods with partial model-sharing can significantly boost robustness against backdoor attacks. In contrast, pFL methods with full model-sharing do not show robustness. To analyze the reasons for varying robustness performances, we provide comprehensive ablation studies on different pFL methods. Based on our findings, we further propose a lightweight defense method, Simple-Tuning, which empirically improves defense performance against backdoor attacks. We believe that our work could provide both guidance for pFL application in terms of its robustness and offer valuable insights to design more robust FL methods in the future. W",
    "path": "papers/23/02/2302.01677.json",
    "total_tokens": 924,
    "translated_title": "重新考虑个性化联邦学习：对抗后门攻击的鲁棒性",
    "translated_abstract": "本文研究个性化能否提高对抗后门攻击的鲁棒性，并在FEMNIST和CIFAR-10这两个基准数据集上对6种pFL方法进行了4种后门攻击的测试，进行了600次实验。结果表明，具有部分模型共享的pFL方法可以显著提高抵御后门攻击的鲁棒性。与此相反，具有完全模型共享的pFL方法并不表现出鲁棒性。我们还提供了不同pFL方法的全面剖析研究，以分析鲁棒性表现差异的原因。基于研究结果，我们进一步提出了一种轻量级的防御方法Simple-Tuning，这种方法可以在经验上提高对抗后门攻击的防御性能。我们认为，本研究提供了有关pFL在鲁棒性方面的应用指导，并为设计更可靠的FL方法提供了有价值的见解。",
    "tldr": "研究展示了部分模型共享的个性化联邦学习方法可以显著提高对抗后门攻击的鲁棒性，提出了一个轻量级的防御方法Simple-Tuning，可用于提高对抗后门攻击的防御性能。",
    "en_tdlr": "The study shows that personalized federated learning (pFL) methods with partial model-sharing can significantly boost robustness against backdoor attacks. A lightweight defense method called Simple-Tuning is proposed to improve the defense performance against backdoor attacks."
}