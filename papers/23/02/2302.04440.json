{
    "title": "Feature Likelihood Score: Evaluating Generalization of Generative Models Using Samples. (arXiv:2302.04440v2 [cs.LG] UPDATED)",
    "abstract": "The past few years have seen impressive progress in the development of deep generative models capable of producing high-dimensional, complex, and photo-realistic data. However, current methods for evaluating such models remain incomplete: standard likelihood-based metrics do not always apply and rarely correlate with perceptual fidelity, while sample-based metrics, such as FID, are insensitive to overfitting, i.e., inability to generalize beyond the training set. To address these limitations, we propose a new metric called the Feature Likelihood Score (FLS), a parametric sample-based score that uses density estimation to provide a comprehensive trichotomic evaluation accounting for novelty (i.e., different from the training samples), fidelity, and diversity of generated samples. We empirically demonstrate the ability of FLS to identify specific overfitting problem cases, where previously proposed metrics fail. We also extensively evaluate FLS on various image datasets and model classes",
    "link": "http://arxiv.org/abs/2302.04440",
    "context": "Title: Feature Likelihood Score: Evaluating Generalization of Generative Models Using Samples. (arXiv:2302.04440v2 [cs.LG] UPDATED)\nAbstract: The past few years have seen impressive progress in the development of deep generative models capable of producing high-dimensional, complex, and photo-realistic data. However, current methods for evaluating such models remain incomplete: standard likelihood-based metrics do not always apply and rarely correlate with perceptual fidelity, while sample-based metrics, such as FID, are insensitive to overfitting, i.e., inability to generalize beyond the training set. To address these limitations, we propose a new metric called the Feature Likelihood Score (FLS), a parametric sample-based score that uses density estimation to provide a comprehensive trichotomic evaluation accounting for novelty (i.e., different from the training samples), fidelity, and diversity of generated samples. We empirically demonstrate the ability of FLS to identify specific overfitting problem cases, where previously proposed metrics fail. We also extensively evaluate FLS on various image datasets and model classes",
    "path": "papers/23/02/2302.04440.json",
    "total_tokens": 942,
    "translated_title": "使用样本评估生成模型的泛化能力",
    "translated_abstract": "过去几年，深度生成模型的发展取得了令人印象深刻的进展，能够生成高维、复杂和照片般逼真的数据。然而，目前评估这些模型的方法仍然不完全：标准的基于似然的指标并不总是适用于这些模型，也很少与感知保真度相关，而基于样本的指标（如FID）对过拟合不敏感。为了解决这些局限性，我们提出了一种新的度量指标，称为特征似然分数（FLS），它是一个参数化的基于样本的分数，使用密度估计来提供全面的三相评估，考虑生成样本的新颖性（即与训练样本不同）、保真度和多样性。我们通过实验证明了FLS在检测过拟合问题上的能力，先前提出的度量指标无法解决这些问题。我们还对各种图像数据集和模型类别进行了广泛的FLS评估。",
    "tldr": "本文提出了一种新的特征似然分数（FLS）评估深度生成模型泛化能力的度量指标，用于评估生成样本的新颖性、保真度和多样性，通过实验证明其优于现有的指标，并能够检测出过拟合问题。",
    "en_tdlr": "This paper proposes a new metric, the Feature Likelihood Score (FLS), to evaluate the generalization of deep generative models, which considers novelty, fidelity, and diversity of generated samples. The FLS outperforms existing metrics and can identify overfitting problems. Extensive evaluations on various image datasets and model classes are presented in the paper."
}