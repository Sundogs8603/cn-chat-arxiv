{
    "title": "Sneaky Spikes: Uncovering Stealthy Backdoor Attacks in Spiking Neural Networks with Neuromorphic Data. (arXiv:2302.06279v2 [cs.CR] UPDATED)",
    "abstract": "Deep neural networks (DNNs) have demonstrated remarkable performance across various tasks, including image and speech recognition. However, maximizing the effectiveness of DNNs requires meticulous optimization of numerous hyperparameters and network parameters through training. Moreover, high-performance DNNs entail many parameters, which consume significant energy during training. In order to overcome these challenges, researchers have turned to spiking neural networks (SNNs), which offer enhanced energy efficiency and biologically plausible data processing capabilities, rendering them highly suitable for sensory data tasks, particularly in neuromorphic data. Despite their advantages, SNNs, like DNNs, are susceptible to various threats, including adversarial examples and backdoor attacks. Yet, the field of SNNs still needs to be explored in terms of understanding and countering these attacks.  This paper delves into backdoor attacks in SNNs using neuromorphic datasets and diverse trig",
    "link": "http://arxiv.org/abs/2302.06279",
    "context": "Title: Sneaky Spikes: Uncovering Stealthy Backdoor Attacks in Spiking Neural Networks with Neuromorphic Data. (arXiv:2302.06279v2 [cs.CR] UPDATED)\nAbstract: Deep neural networks (DNNs) have demonstrated remarkable performance across various tasks, including image and speech recognition. However, maximizing the effectiveness of DNNs requires meticulous optimization of numerous hyperparameters and network parameters through training. Moreover, high-performance DNNs entail many parameters, which consume significant energy during training. In order to overcome these challenges, researchers have turned to spiking neural networks (SNNs), which offer enhanced energy efficiency and biologically plausible data processing capabilities, rendering them highly suitable for sensory data tasks, particularly in neuromorphic data. Despite their advantages, SNNs, like DNNs, are susceptible to various threats, including adversarial examples and backdoor attacks. Yet, the field of SNNs still needs to be explored in terms of understanding and countering these attacks.  This paper delves into backdoor attacks in SNNs using neuromorphic datasets and diverse trig",
    "path": "papers/23/02/2302.06279.json",
    "total_tokens": 873,
    "translated_title": "Sneaky Spikes: 用神经形态数据在脉冲神经网络中揭示隐蔽的后门攻击",
    "translated_abstract": "深度神经网络（DNN）在各种任务中显示出了卓越的性能，包括图像和语音识别。然而，最大化DNN的效果需要通过训练对众多超参数和网络参数进行精细优化。此外，高性能的DNN涉及许多参数，在训练过程中消耗大量能源。为了克服这些挑战，研究人员转向了脉冲神经网络（SNN），其提供了增强的能源效率和生物学可行的数据处理能力，使其非常适合感知数据任务，特别是在神经形态数据方面。尽管存在优势，SNN与DNN一样，容易受到各种威胁的影响，包括对抗性示例和后门攻击。然而，关于SNN在理解和对抗这些攻击方面，仍需要进一步探索。本文深入研究了使用神经形态数据和多样化的刺激的SNN中的后门攻击。",
    "tldr": "本文研究使用神经形态数据和多样化的刺激在脉冲神经网络中的后门攻击问题。",
    "en_tdlr": "This paper investigates the issue of backdoor attacks in spiking neural networks using neuromorphic data and diverse stimuli."
}