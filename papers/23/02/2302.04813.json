{
    "title": "Explanation Selection Using Unlabeled Data for Chain-of-Thought Prompting. (arXiv:2302.04813v2 [cs.CL] UPDATED)",
    "abstract": "Recent work has addressed textual reasoning tasks by prompting large language models with explanations via the chain-of-thought paradigm. However, subtly different explanations can yield widely varying downstream task accuracy, so explanations that have not been \"tuned\" for a task, such as off-the-shelf explanations written by non-experts, may lead to mediocre performance. This paper tackles the problem of how to optimize explanation-infused prompts in a black-box fashion. We first generate sets of candidate explanations for each example in the prompt using a leave-one-out scheme. We then use a two-stage framework where we first evaluate explanations for each in-context example in isolation according to two proxy metrics, log likelihood and accuracy on new examples. Finally, we search over sets of explanations to find a set that yields high performance against a silver-labeled development set. Across four textual reasoning tasks spanning question answering, mathematical reasoning, and ",
    "link": "http://arxiv.org/abs/2302.04813",
    "context": "Title: Explanation Selection Using Unlabeled Data for Chain-of-Thought Prompting. (arXiv:2302.04813v2 [cs.CL] UPDATED)\nAbstract: Recent work has addressed textual reasoning tasks by prompting large language models with explanations via the chain-of-thought paradigm. However, subtly different explanations can yield widely varying downstream task accuracy, so explanations that have not been \"tuned\" for a task, such as off-the-shelf explanations written by non-experts, may lead to mediocre performance. This paper tackles the problem of how to optimize explanation-infused prompts in a black-box fashion. We first generate sets of candidate explanations for each example in the prompt using a leave-one-out scheme. We then use a two-stage framework where we first evaluate explanations for each in-context example in isolation according to two proxy metrics, log likelihood and accuracy on new examples. Finally, we search over sets of explanations to find a set that yields high performance against a silver-labeled development set. Across four textual reasoning tasks spanning question answering, mathematical reasoning, and ",
    "path": "papers/23/02/2302.04813.json",
    "total_tokens": 938,
    "tldr": "本文解决了如何以黑盒方式优化融入解释的提示的问题，通过生成解释的候选集合，并评估每个同上下文的例子的解释。在跨越问答、数学推理和逻辑推理等四个文本推理任务中表现出着优异的性能。",
    "en_tdlr": "This paper proposes a two-stage framework to optimize explanation-infused prompts in a black-box manner. It generates sets of candidate explanations for each example in the prompt using a leave-one-out scheme, evaluates explanations for each in-context example in isolation according to two proxy metrics, and searches over sets of explanations to find a set that yields high performance. The proposed method achieves excellent performance across a range of textual reasoning tasks."
}