{
    "title": "Pathologies of Predictive Diversity in Deep Ensembles. (arXiv:2302.00704v3 [cs.LG] UPDATED)",
    "abstract": "Classic results establish that encouraging predictive diversity improves performance in ensembles of low-capacity models, e.g. through bagging or boosting. Here we demonstrate that these intuitions do not apply to high-capacity neural network ensembles (deep ensembles), and in fact the opposite is often true. In a large scale study of nearly 600 neural network classification ensembles, we examine a variety of interventions that trade off component model performance for predictive diversity. While such interventions can improve the performance of small neural network ensembles (in line with standard intuitions), they harm the performance of the large neural network ensembles most often used in practice. Surprisingly, we also find that discouraging predictive diversity is often benign in large-network ensembles, fully inverting standard intuitions. Even when diversity-promoting interventions do not sacrifice component model performance (e.g. using heterogeneous architectures and training",
    "link": "http://arxiv.org/abs/2302.00704",
    "context": "Title: Pathologies of Predictive Diversity in Deep Ensembles. (arXiv:2302.00704v3 [cs.LG] UPDATED)\nAbstract: Classic results establish that encouraging predictive diversity improves performance in ensembles of low-capacity models, e.g. through bagging or boosting. Here we demonstrate that these intuitions do not apply to high-capacity neural network ensembles (deep ensembles), and in fact the opposite is often true. In a large scale study of nearly 600 neural network classification ensembles, we examine a variety of interventions that trade off component model performance for predictive diversity. While such interventions can improve the performance of small neural network ensembles (in line with standard intuitions), they harm the performance of the large neural network ensembles most often used in practice. Surprisingly, we also find that discouraging predictive diversity is often benign in large-network ensembles, fully inverting standard intuitions. Even when diversity-promoting interventions do not sacrifice component model performance (e.g. using heterogeneous architectures and training",
    "path": "papers/23/02/2302.00704.json",
    "total_tokens": 908,
    "translated_title": "深度集成中的预测多样性病态",
    "translated_abstract": "传统的结果表明，鼓励预测多样性可以提高低容量模型的集成性能，例如通过Bagging或Boosting。然而，在本文中，我们证明这些直觉在高容量的神经网络集成（深度集成）中并不适用，事实上，往往相反。通过对近600个神经网络分类集成的大规模研究，我们考察了一系列平衡组件模型性能与预测多样性之间关系的干预措施。虽然这样的干预措施可以改善小规模神经网络集成的性能（符合标准直觉），但它们却会损害在实践中最常用的大规模神经网络集成的性能。令人惊讶的是，在大型网络集成中，阻止预测多样性往往是无害的，完全颠覆了标准的直觉。即使多样性促进的干预措施不牺牲组件模型的性能（例如使用异构架构和训练策略）...",
    "tldr": "本文发现在高容量的神经网络集成中，鼓励预测多样性并不总是有效的，甚至反而会损害性能。相反地，阻止预测多样性往往是无害的，这与先前的直觉相反。",
    "en_tdlr": "This paper demonstrates that encouraging predictive diversity is not always effective and can even harm the performance in high-capacity neural network ensembles. Surprisingly, discouraging predictive diversity is often benign, contrary to previous intuitions."
}