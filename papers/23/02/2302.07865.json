{
    "title": "Dataset Interfaces: Diagnosing Model Failures Using Controllable Counterfactual Generation. (arXiv:2302.07865v2 [cs.LG] UPDATED)",
    "abstract": "Distribution shift is a major source of failure for machine learning models. However, evaluating model reliability under distribution shift can be challenging, especially since it may be difficult to acquire counterfactual examples that exhibit a specified shift. In this work, we introduce the notion of a dataset interface: a framework that, given an input dataset and a user-specified shift, returns instances from that input distribution that exhibit the desired shift. We study a number of natural implementations for such an interface, and find that they often introduce confounding shifts that complicate model evaluation. Motivated by this, we propose a dataset interface implementation that leverages Textual Inversion to tailor generation to the input distribution. We then demonstrate how applying this dataset interface to the ImageNet dataset enables studying model behavior across a diverse array of distribution shifts, including variations in background, lighting, and attributes of t",
    "link": "http://arxiv.org/abs/2302.07865",
    "context": "Title: Dataset Interfaces: Diagnosing Model Failures Using Controllable Counterfactual Generation. (arXiv:2302.07865v2 [cs.LG] UPDATED)\nAbstract: Distribution shift is a major source of failure for machine learning models. However, evaluating model reliability under distribution shift can be challenging, especially since it may be difficult to acquire counterfactual examples that exhibit a specified shift. In this work, we introduce the notion of a dataset interface: a framework that, given an input dataset and a user-specified shift, returns instances from that input distribution that exhibit the desired shift. We study a number of natural implementations for such an interface, and find that they often introduce confounding shifts that complicate model evaluation. Motivated by this, we propose a dataset interface implementation that leverages Textual Inversion to tailor generation to the input distribution. We then demonstrate how applying this dataset interface to the ImageNet dataset enables studying model behavior across a diverse array of distribution shifts, including variations in background, lighting, and attributes of t",
    "path": "papers/23/02/2302.07865.json",
    "total_tokens": 922,
    "translated_title": "数据集接口：使用可控对抗生成来诊断模型失败",
    "translated_abstract": "数据分布偏移是机器学习模型失败的主要原因。然而，评估模型在分布偏移下的可靠性可能很具有挑战性，特别是因为可能很难获取表现出指定偏移的反事实示例。在本文中，我们引入了数据集接口的概念：一个框架，给定输入数据集和用户指定的偏移，返回来自该输入分布的具有所需偏移的实例。我们研究了许多自然的实现方式，发现它们经常引入混淆偏移来使模型评估复杂化。受此启发，我们提出了一个数据集接口实现，利用文本反转来自定义生成器以适应输入分布。然后，我们演示了如何将这个数据集接口应用于ImageNet数据集，以研究模型在多样的分布偏移下的行为，包括背景、光照和属性的变化。",
    "tldr": "本文提出了一种数据集接口的概念，旨在通过给定一个输入数据集和一个用户指定的分布偏移来返回针对该分布的实例。我们提出了一种利用文本反转的数据集接口实现，使得生成更加适应输入分布，进而帮助研究模型在各种分布偏移下的行为。"
}