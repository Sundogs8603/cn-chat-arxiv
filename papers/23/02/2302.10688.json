{
    "title": "On Calibrating Diffusion Probabilistic Models. (arXiv:2302.10688v2 [cs.LG] UPDATED)",
    "abstract": "Recently, diffusion probabilistic models (DPMs) have achieved promising results in diverse generative tasks. A typical DPM framework includes a forward process that gradually diffuses the data distribution and a reverse process that recovers the data distribution from time-dependent data scores. In this work, we observe that the stochastic reverse process of data scores is a martingale, from which concentration bounds and the optional stopping theorem for data scores can be derived. Then, we discover a simple way for calibrating an arbitrary pretrained DPM, with which the score matching loss can be reduced and the lower bounds of model likelihood can consequently be increased. We provide general calibration guidelines under various model parametrizations. Our calibration method is performed only once and the resulting models can be used repeatedly for sampling. We conduct experiments on multiple datasets to empirically validate our proposal. Our code is at https://github.com/thudzj/Cal",
    "link": "http://arxiv.org/abs/2302.10688",
    "context": "Title: On Calibrating Diffusion Probabilistic Models. (arXiv:2302.10688v2 [cs.LG] UPDATED)\nAbstract: Recently, diffusion probabilistic models (DPMs) have achieved promising results in diverse generative tasks. A typical DPM framework includes a forward process that gradually diffuses the data distribution and a reverse process that recovers the data distribution from time-dependent data scores. In this work, we observe that the stochastic reverse process of data scores is a martingale, from which concentration bounds and the optional stopping theorem for data scores can be derived. Then, we discover a simple way for calibrating an arbitrary pretrained DPM, with which the score matching loss can be reduced and the lower bounds of model likelihood can consequently be increased. We provide general calibration guidelines under various model parametrizations. Our calibration method is performed only once and the resulting models can be used repeatedly for sampling. We conduct experiments on multiple datasets to empirically validate our proposal. Our code is at https://github.com/thudzj/Cal",
    "path": "papers/23/02/2302.10688.json",
    "total_tokens": 917,
    "translated_title": "关于校准扩散概率模型",
    "translated_abstract": "最近，扩散概率模型（DPM）在各种生成性任务中取得了有希望的结果。一个典型的DPM框架包括一个逐渐扩散数据分布的正向过程和一个从时间相关数据分数中恢复数据分布的随机反向过程。本文观察到数据分数的随机反向过程是一个鞅，从中可以导出数据分数的集中界和随机停止定理。然后，我们发现一种简单的方法，用于校准任意预先训练的DPM，以减小得分匹配损失，并因此增加模型似然的下限。我们提供了各种模型参数化下的一般校准指南。我们的校准方法仅执行一次，并且可以重复使用所得到的模型进行采样。我们在多个数据集上进行实验，以经验性地验证我们的提议。我们的代码位于https://github.com/thudzj/Cal。",
    "tldr": "本文发现了数据分数随机反向过程是一个鞅，提出了一种简单的方法，用于校准任意预先训练的DPM，有效减小模型的得分匹配损失，增加模型似然的下限，并提供了一般校准指南。",
    "en_tdlr": "This paper observes that the stochastic reverse process of data scores is a martingale, proposes a simple method for calibrating an arbitrary pretrained diffusion probabilistic model (DPM) to reduce the score matching loss and increase the lower bounds of model likelihood, and provides general calibration guidelines under various model parametrizations. The resulting models can be repeatedly used for sampling and experiments on multiple datasets validate the proposal."
}