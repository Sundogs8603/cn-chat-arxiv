{
    "title": "Data Forensics in Diffusion Models: A Systematic Analysis of Membership Privacy. (arXiv:2302.07801v2 [cs.LG] UPDATED)",
    "abstract": "In recent years, diffusion models have achieved tremendous success in the field of image generation, becoming the stateof-the-art technology for AI-based image processing applications. Despite the numerous benefits brought by recent advances in diffusion models, there are also concerns about their potential misuse, specifically in terms of privacy breaches and intellectual property infringement. In particular, some of their unique characteristics open up new attack surfaces when considering the real-world deployment of such models. With a thorough investigation of the attack vectors, we develop a systematic analysis of membership inference attacks on diffusion models and propose novel attack methods tailored to each attack scenario specifically relevant to diffusion models. Our approach exploits easily obtainable quantities and is highly effective, achieving near-perfect attack performance (>0.9 AUCROC) in realistic scenarios. Our extensive experiments demonstrate the effectiveness of ",
    "link": "http://arxiv.org/abs/2302.07801",
    "context": "Title: Data Forensics in Diffusion Models: A Systematic Analysis of Membership Privacy. (arXiv:2302.07801v2 [cs.LG] UPDATED)\nAbstract: In recent years, diffusion models have achieved tremendous success in the field of image generation, becoming the stateof-the-art technology for AI-based image processing applications. Despite the numerous benefits brought by recent advances in diffusion models, there are also concerns about their potential misuse, specifically in terms of privacy breaches and intellectual property infringement. In particular, some of their unique characteristics open up new attack surfaces when considering the real-world deployment of such models. With a thorough investigation of the attack vectors, we develop a systematic analysis of membership inference attacks on diffusion models and propose novel attack methods tailored to each attack scenario specifically relevant to diffusion models. Our approach exploits easily obtainable quantities and is highly effective, achieving near-perfect attack performance (>0.9 AUCROC) in realistic scenarios. Our extensive experiments demonstrate the effectiveness of ",
    "path": "papers/23/02/2302.07801.json",
    "total_tokens": 852,
    "translated_title": "扩散模型中的数据取证: 对会员隐私的系统分析",
    "translated_abstract": "近年来，扩散模型在图像生成领域取得了巨大的成功，成为基于人工智能的图像处理应用的最先进技术。尽管最近在扩散模型方面取得了诸多好处，但人们也担忧其潜在的滥用，尤其是在隐私侵犯和知识产权侵权方面。特别是，考虑到这些模型的真实世界应用，它们的某些独特特性为攻击提供了新的攻击面。通过对攻击向量进行深入研究，我们对扩散模型上的会员推断攻击进行了系统分析，并提出了针对每种与扩散模型相关的攻击场景的新攻击方法。我们的方法利用易得的数量并具有极高的效果，在实际场景中实现了接近完美的攻击性能（>0.9 AUCROC）。我们的广泛实验证明了我们方法的有效性。",
    "tldr": "本研究对扩散模型中的会员推断攻击进行了系统分析，并提出了适用于不同攻击场景的新攻击方法，取得了接近完美的攻击性能。"
}