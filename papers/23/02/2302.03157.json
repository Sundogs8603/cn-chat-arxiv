{
    "title": "A distribution-free mixed-integer optimization approach to hierarchical modelling of clustered and longitudinal data",
    "abstract": "arXiv:2302.03157v2 Announce Type: replace-cross  Abstract: Recent advancements in Mixed Integer Optimization (MIO) algorithms, paired with hardware enhancements, have led to significant speedups in resolving MIO problems. These strategies have been utilized for optimal subset selection, specifically for choosing $k$ features out of $p$ in linear regression given $n$ observations. In this paper, we broaden this method to facilitate cluster-aware regression, where selection aims to choose $\\lambda$ out of $K$ clusters in a linear mixed effects (LMM) model with $n_k$ observations for each cluster. Through comprehensive testing on a multitude of synthetic and real datasets, we exhibit that our method efficiently solves problems within minutes. Through numerical experiments, we also show that the MIO approach outperforms both Gaussian- and Laplace-distributed LMMs in terms of generating sparse solutions with high predictive power. Traditional LMMs typically assume that clustering effects ar",
    "link": "https://arxiv.org/abs/2302.03157",
    "context": "Title: A distribution-free mixed-integer optimization approach to hierarchical modelling of clustered and longitudinal data\nAbstract: arXiv:2302.03157v2 Announce Type: replace-cross  Abstract: Recent advancements in Mixed Integer Optimization (MIO) algorithms, paired with hardware enhancements, have led to significant speedups in resolving MIO problems. These strategies have been utilized for optimal subset selection, specifically for choosing $k$ features out of $p$ in linear regression given $n$ observations. In this paper, we broaden this method to facilitate cluster-aware regression, where selection aims to choose $\\lambda$ out of $K$ clusters in a linear mixed effects (LMM) model with $n_k$ observations for each cluster. Through comprehensive testing on a multitude of synthetic and real datasets, we exhibit that our method efficiently solves problems within minutes. Through numerical experiments, we also show that the MIO approach outperforms both Gaussian- and Laplace-distributed LMMs in terms of generating sparse solutions with high predictive power. Traditional LMMs typically assume that clustering effects ar",
    "path": "papers/23/02/2302.03157.json",
    "total_tokens": 872,
    "translated_title": "一个面向层次化建模的分布无关混合整数优化方法",
    "translated_abstract": "最近混合整数优化（MIO）算法的进展，结合硬件增强，大大加快了解决MIO问题的速度。这些策略已被用于最优子集选择，特别是在线性回归中在给定$n$观测的情况下选择$k$个特征中的$p$个。在本文中，我们将这种方法扩展到促进群集感知回归，选择$LMM$模型的$K$个群集中的$\\lambda$个，每个群集有$n_k$个观测。通过对多种合成和真实数据集的全面测试，我们展示了我们的方法可以在几分钟内高效地解决问题。通过数值实验，我们还展示了MIO方法在生成具有高预测能力的稀疏解方面优于高斯分布和拉普拉斯分布LMM。传统的LMM通常假设聚类效果为",
    "tldr": "该论文提出了一个面向层次化数据建模的分布无关混合整数优化方法，通过在线性混合效应模型中选取群体特性来提高解决问题的效率，并在生成稀疏解方面表现出更高的预测能力。",
    "en_tdlr": "This paper introduces a distribution-free mixed-integer optimization approach for hierarchical data modeling, enhancing efficiency in problem-solving by selecting cluster features in linear mixed effects models and outperforming Gaussian- and Laplace-distributed LMMs in generating sparse solutions with high predictive power."
}