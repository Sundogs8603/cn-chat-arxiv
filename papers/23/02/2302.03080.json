{
    "title": "Five policy uses of algorithmic transparency and explainability. (arXiv:2302.03080v2 [cs.LG] UPDATED)",
    "abstract": "The notion that algorithmic systems should be \"transparent\" and \"explainable\" is common in the many statements of consensus principles developed by governments, companies, and advocacy organizations. But what exactly do policy and legal actors want from these technical concepts, and how do their desiderata compare with the explainability techniques developed in the machine learning literature? In hopes of better connecting the policy and technical communities, we provide case studies illustrating five ways in which algorithmic transparency and explainability have been used in policy settings: specific requirements for explanations; in nonbinding guidelines for internal governance of algorithms; in regulations applicable to highly regulated settings; in guidelines meant to increase the utility of legal liability for algorithms; and broad requirements for model and data transparency. The case studies span a spectrum from precise requirements for specific types of explanations to nonspeci",
    "link": "http://arxiv.org/abs/2302.03080",
    "context": "Title: Five policy uses of algorithmic transparency and explainability. (arXiv:2302.03080v2 [cs.LG] UPDATED)\nAbstract: The notion that algorithmic systems should be \"transparent\" and \"explainable\" is common in the many statements of consensus principles developed by governments, companies, and advocacy organizations. But what exactly do policy and legal actors want from these technical concepts, and how do their desiderata compare with the explainability techniques developed in the machine learning literature? In hopes of better connecting the policy and technical communities, we provide case studies illustrating five ways in which algorithmic transparency and explainability have been used in policy settings: specific requirements for explanations; in nonbinding guidelines for internal governance of algorithms; in regulations applicable to highly regulated settings; in guidelines meant to increase the utility of legal liability for algorithms; and broad requirements for model and data transparency. The case studies span a spectrum from precise requirements for specific types of explanations to nonspeci",
    "path": "papers/23/02/2302.03080.json",
    "total_tokens": 924,
    "translated_title": "五种算法透明性和可解释性的政策应用",
    "translated_abstract": "\"算法系统应该具有“透明性”和“可解释性”的观念在政府、公司和倡导组织制定的许多共识原则中很常见。但政策和法律行为者究竟要求这些技术概念的哪些方面，以及他们的要求与机器学习文献中开发的可解释性技术相比如何？为了更好地连接政策和技术社区，我们提供了案例研究，说明算法透明性和可解释性在政策环境中的五种应用方式：对解释的具体要求；在算法内部治理的非约束性指南中；适用于高度管制环境的法规；旨在提高算法法律责任的实用性的指南；以及对模型和数据透明性的广泛要求。案例研究涵盖了从对特定类型解释的精确要求到非具体要求的范围。",
    "tldr": "本论文通过案例研究展示了算法透明性和可解释性在政策环境中的五种应用方式：对解释的具体要求；在算法内部治理的非约束性指南中；适用于高度管制环境的法规；旨在提高算法法律责任的实用性的指南；以及对模型和数据透明性的广泛要求。"
}