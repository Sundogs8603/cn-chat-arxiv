{
    "title": "Adaptive Selective Sampling for Online Prediction with Experts. (arXiv:2302.08397v2 [stat.ML] UPDATED)",
    "abstract": "We consider online prediction of a binary sequence with expert advice. For this setting, we devise label-efficient forecasting algorithms, which use a selective sampling scheme that enables collecting much fewer labels than standard procedures, while still retaining optimal worst-case regret guarantees. These algorithms are based on exponentially weighted forecasters, suitable for settings with and without a perfect expert. For a scenario where one expert is strictly better than the others in expectation, we show that the label complexity of the label-efficient forecaster scales roughly as the square root of the number of rounds. Finally, we present numerical experiments empirically showing that the normalized regret of the label-efficient forecaster can asymptotically match known minimax rates for pool-based active learning, suggesting it can optimally adapt to benign settings.",
    "link": "http://arxiv.org/abs/2302.08397",
    "context": "Title: Adaptive Selective Sampling for Online Prediction with Experts. (arXiv:2302.08397v2 [stat.ML] UPDATED)\nAbstract: We consider online prediction of a binary sequence with expert advice. For this setting, we devise label-efficient forecasting algorithms, which use a selective sampling scheme that enables collecting much fewer labels than standard procedures, while still retaining optimal worst-case regret guarantees. These algorithms are based on exponentially weighted forecasters, suitable for settings with and without a perfect expert. For a scenario where one expert is strictly better than the others in expectation, we show that the label complexity of the label-efficient forecaster scales roughly as the square root of the number of rounds. Finally, we present numerical experiments empirically showing that the normalized regret of the label-efficient forecaster can asymptotically match known minimax rates for pool-based active learning, suggesting it can optimally adapt to benign settings.",
    "path": "papers/23/02/2302.08397.json",
    "total_tokens": 919,
    "translated_title": "对于带有专家建议的在线预测，自适应选择采样方法",
    "translated_abstract": "我们考虑对于二进制序列的在线预测，所提出的标签高效预测算法使用了选择性采样方案，在保持最优最坏情况后悔保证的同时，能够使用比标准程序少得多的标签。这些算法基于指数加权预测器，适用于有或无完美专家的情况。对于一个在期望上明显更好的专家而言，我们展示了标签高效预测器的标签复杂度大致与回合数的平方根成比例。最后，我们通过数值实验证明了标签高效预测器的归一化后悔可以渐近匹配已知的基于池式主动学习的极小极大速率，表明它能够在良性环境中进行最优适应。",
    "tldr": "针对带有专家建议的在线预测，我们提出了使用选择性采样方案的标签高效预测算法，能够使用比标准程序少得多的标签，并保持最优最坏情况后悔保证。对于在期望上明显更好的专家，算法的标签复杂度与回合数的平方根成比例，并且在实验中表现出与池式主动学习的极小极大速率相匹配的归一化后悔。",
    "en_tdlr": "For online prediction with expert advice, we propose label-efficient forecasting algorithms using a selective sampling scheme, reducing the number of required labels while maintaining optimal worst-case regret guarantees. The label complexity scales with the square root of the number of rounds for scenarios where one expert is significantly better. Empirical results show that the normalized regret of the algorithm asymptotically matches the minimax rates for pool-based active learning, suggesting optimal adaptability in benign settings."
}