{
    "title": "Improving and generalizing flow-based generative models with minibatch optimal transport. (arXiv:2302.00482v2 [cs.LG] UPDATED)",
    "abstract": "Continuous normalizing flows (CNFs) are an attractive generative modeling technique, but they have been held back by limitations in their simulation-based maximum likelihood training. We introduce the generalized conditional flow matching (CFM) technique, a family of simulation-free training objectives for CNFs. CFM features a stable regression objective like that used to train the stochastic flow in diffusion models but enjoys the efficient inference of deterministic flow models. In contrast to both diffusion models and prior CNF training algorithms, CFM does not require the source distribution to be Gaussian or require evaluation of its density. A variant of our objective is optimal transport CFM (OT-CFM), which creates simpler flows that are more stable to train and lead to faster inference, as evaluated in our experiments. Furthermore, OT-CFM is the first method to compute dynamic OT in a simulation-free way. Training CNFs with CFM improves results on a variety of conditional and u",
    "link": "http://arxiv.org/abs/2302.00482",
    "context": "Title: Improving and generalizing flow-based generative models with minibatch optimal transport. (arXiv:2302.00482v2 [cs.LG] UPDATED)\nAbstract: Continuous normalizing flows (CNFs) are an attractive generative modeling technique, but they have been held back by limitations in their simulation-based maximum likelihood training. We introduce the generalized conditional flow matching (CFM) technique, a family of simulation-free training objectives for CNFs. CFM features a stable regression objective like that used to train the stochastic flow in diffusion models but enjoys the efficient inference of deterministic flow models. In contrast to both diffusion models and prior CNF training algorithms, CFM does not require the source distribution to be Gaussian or require evaluation of its density. A variant of our objective is optimal transport CFM (OT-CFM), which creates simpler flows that are more stable to train and lead to faster inference, as evaluated in our experiments. Furthermore, OT-CFM is the first method to compute dynamic OT in a simulation-free way. Training CNFs with CFM improves results on a variety of conditional and u",
    "path": "papers/23/02/2302.00482.json",
    "total_tokens": 959,
    "translated_title": "通过最小批量优化传输改进和泛化基于流的生成模型",
    "translated_abstract": "连续正则化流（CNFs）是一种吸引人的生成建模技术，但由于其基于模拟的最大似然训练存在局限性而受到约束。我们介绍了广义条件流匹配（CFM）技术，这是一种针对CNFs的无模拟训练目标的集合。CFM具有类似于扩散模型中用于训练随机流的稳定回归目标，但同时享有确定性流模型的高效推断。与扩散模型和之前的CNF训练算法相比，CFM不需要源分布为高斯分布，也不需要对其密度进行评估。我们的目标的一种变体是最优传输CFM（OT-CFM），它创建了更简单的流，更容易训练，并且导致更快的推断，如我们的实验证明所示。此外，OT-CFM是第一种以无模拟方式计算动态OT的方法。使用CFM训练CNFs可以改进各种条件和...",
    "tldr": "这篇论文提出了一种称为广义条件流匹配（CFM）的技术，在连续正则化流（CNFs）的生成模型中无需模拟训练，极大提高了效率和稳定性。此外，论文还引入了最优传输CFM（OT-CFM）的变体，可以以无模拟方式计算动态OT，加速了推断过程。"
}