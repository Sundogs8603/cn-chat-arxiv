{
    "title": "Statistical Complexity and Optimal Algorithms for Non-linear Ridge Bandits. (arXiv:2302.06025v2 [stat.ML] UPDATED)",
    "abstract": "We consider the sequential decision-making problem where the mean outcome is a non-linear function of the chosen action. Compared with the linear model, two curious phenomena arise in non-linear models: first, in addition to the \"learning phase\" with a standard parametric rate for estimation or regret, there is an \"burn-in period\" with a fixed cost determined by the non-linear function; second, achieving the smallest burn-in cost requires new exploration algorithms. For a special family of non-linear functions named ridge functions in the literature, we derive upper and lower bounds on the optimal burn-in cost, and in addition, on the entire learning trajectory during the burn-in period via differential equations. In particular, a two-stage algorithm that first finds a good initial action and then treats the problem as locally linear is statistically optimal. In contrast, several classical algorithms, such as UCB and algorithms relying on regression oracles, are provably suboptimal.",
    "link": "http://arxiv.org/abs/2302.06025",
    "context": "Title: Statistical Complexity and Optimal Algorithms for Non-linear Ridge Bandits. (arXiv:2302.06025v2 [stat.ML] UPDATED)\nAbstract: We consider the sequential decision-making problem where the mean outcome is a non-linear function of the chosen action. Compared with the linear model, two curious phenomena arise in non-linear models: first, in addition to the \"learning phase\" with a standard parametric rate for estimation or regret, there is an \"burn-in period\" with a fixed cost determined by the non-linear function; second, achieving the smallest burn-in cost requires new exploration algorithms. For a special family of non-linear functions named ridge functions in the literature, we derive upper and lower bounds on the optimal burn-in cost, and in addition, on the entire learning trajectory during the burn-in period via differential equations. In particular, a two-stage algorithm that first finds a good initial action and then treats the problem as locally linear is statistically optimal. In contrast, several classical algorithms, such as UCB and algorithms relying on regression oracles, are provably suboptimal.",
    "path": "papers/23/02/2302.06025.json",
    "total_tokens": 909,
    "translated_title": "非线性Ridge Bandits的统计复杂度和最优算法",
    "translated_abstract": "本文考虑了一种顺序决策问题，其中平均结果是所选择动作的非线性函数。与线性模型相比，非线性模型有两种奇特现象：首先，除了具有标准参数率的“学习阶段”以进行估计或后悔外，还有一个由非线性函数确定的固定成本的“烧录期”; 其次，实现最小烧录成本需要新的探索算法。针对一类名为ridge函数的特殊非线性函数，我们通过微分方程推导了最优烧录成本的上下限，此外还推导了整个烧录期间的学习轨迹的上下限。特别地，一种两阶段算法先找到一个好的初始行动，然后将问题视为局部线性，这是统计上最优的。相反，几种经典算法，例如UCB和依赖于回归神经元的算法，其可证明是次优的。",
    "tldr": "本文探讨了非线性Ridge Bandits中独特的学习现象，推导出了最优烧录成本的上下限和整个烧录期间的学习轨迹的统计算法，并证明了UCB和基于回归神经元的算法都是次优解。",
    "en_tdlr": "This paper discusses the unique learning phenomena in non-linear Ridge Bandits, derives the upper and lower bounds for optimal burn-in cost and the trajectory during the entire burn-in period via differential equations, and proves that classical algorithms such as UCB and those relying on regression oracles are suboptimal."
}