{
    "title": "3D Generative Model Latent Disentanglement via Local Eigenprojection. (arXiv:2302.12798v2 [cs.CV] UPDATED)",
    "abstract": "Designing realistic digital humans is extremely complex. Most data-driven generative models used to simplify the creation of their underlying geometric shape do not offer control over the generation of local shape attributes. In this paper, we overcome this limitation by introducing a novel loss function grounded in spectral geometry and applicable to different neural-network-based generative models of 3D head and body meshes. Encouraging the latent variables of mesh variational autoencoders (VAEs) or generative adversarial networks (GANs) to follow the local eigenprojections of identity attributes, we improve latent disentanglement and properly decouple the attribute creation. Experimental results show that our local eigenprojection disentangled (LED) models not only offer improved disentanglement with respect to the state-of-the-art, but also maintain good generation capabilities with training times comparable to the vanilla implementations of the models.",
    "link": "http://arxiv.org/abs/2302.12798",
    "context": "Title: 3D Generative Model Latent Disentanglement via Local Eigenprojection. (arXiv:2302.12798v2 [cs.CV] UPDATED)\nAbstract: Designing realistic digital humans is extremely complex. Most data-driven generative models used to simplify the creation of their underlying geometric shape do not offer control over the generation of local shape attributes. In this paper, we overcome this limitation by introducing a novel loss function grounded in spectral geometry and applicable to different neural-network-based generative models of 3D head and body meshes. Encouraging the latent variables of mesh variational autoencoders (VAEs) or generative adversarial networks (GANs) to follow the local eigenprojections of identity attributes, we improve latent disentanglement and properly decouple the attribute creation. Experimental results show that our local eigenprojection disentangled (LED) models not only offer improved disentanglement with respect to the state-of-the-art, but also maintain good generation capabilities with training times comparable to the vanilla implementations of the models.",
    "path": "papers/23/02/2302.12798.json",
    "total_tokens": 886,
    "translated_title": "基于本地特征向量投影的3D生成模型潜在空间解耦",
    "translated_abstract": "设计逼真的数字人物是非常复杂的。大多数数据驱动的生成模型用于简化底层几何形状的创建并不提供对本地形状属性生成的控制。在本文中，我们通过引入一种基于谱几何的全新损失函数，应用于不同的基于神经网络的3D头部和身体网格生成模型，克服了这一限制。通过鼓舞网格变分自编码器或生成对抗网络的潜在变量遵循特征向量投影，我们改善了潜在空间解耦并正确地分离了属性的生成。实验结果表明，我们的本地特征向量投影解耦模型不仅相对于现有最先进技术有改进，而且在保持良好的生成能力的同时，其训练时间也与模型的基本实现相当。",
    "tldr": "本文提出了一种基于谱几何的全新损失函数，应用于不同的3D头部和身体网格生成模型，通过激励潜在变量遵循特征向量投影并改善潜在空间解耦，实现对生成本地形状属性的控制。",
    "en_tdlr": "This paper proposes a novel loss function based on spectral geometry and applicable to different 3D head and body mesh generative models. By encouraging latent variables to follow the local eigenprojections and improving latent disentanglement, the proposed method offers control over the generation of local shape attributes."
}