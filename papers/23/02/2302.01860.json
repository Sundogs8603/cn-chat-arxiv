{
    "title": "GLADIS: A General and Large Acronym Disambiguation Benchmark. (arXiv:2302.01860v2 [cs.CL] UPDATED)",
    "abstract": "Acronym Disambiguation (AD) is crucial for natural language understanding on various sources, including biomedical reports, scientific papers, and search engine queries. However, existing acronym disambiguation benchmarks and tools are limited to specific domains, and the size of prior benchmarks is rather small. To accelerate the research on acronym disambiguation, we construct a new benchmark named GLADIS with three components: (1) a much larger acronym dictionary with 1.5M acronyms and 6.4M long forms; (2) a pre-training corpus with 160 million sentences; (3) three datasets that cover the general, scientific, and biomedical domains. We then pre-train a language model, \\emph{AcroBERT}, on our constructed corpus for general acronym disambiguation, and show the challenges and values of our new benchmark.",
    "link": "http://arxiv.org/abs/2302.01860",
    "context": "Title: GLADIS: A General and Large Acronym Disambiguation Benchmark. (arXiv:2302.01860v2 [cs.CL] UPDATED)\nAbstract: Acronym Disambiguation (AD) is crucial for natural language understanding on various sources, including biomedical reports, scientific papers, and search engine queries. However, existing acronym disambiguation benchmarks and tools are limited to specific domains, and the size of prior benchmarks is rather small. To accelerate the research on acronym disambiguation, we construct a new benchmark named GLADIS with three components: (1) a much larger acronym dictionary with 1.5M acronyms and 6.4M long forms; (2) a pre-training corpus with 160 million sentences; (3) three datasets that cover the general, scientific, and biomedical domains. We then pre-train a language model, \\emph{AcroBERT}, on our constructed corpus for general acronym disambiguation, and show the challenges and values of our new benchmark.",
    "path": "papers/23/02/2302.01860.json",
    "total_tokens": 934,
    "translated_title": "GLADIS: 一个通用的大型缩写消歧基准",
    "translated_abstract": "缩写消歧对于理解各种来源的自然语言都至关重要，包括生物医学报告、科学论文和搜索引擎查询。然而，现有的缩写消歧基准和工具仅适用于特定领域，先前的基准的规模也相对较小。为了加速缩写消歧的研究，我们构建了一个名为GLADIS的新基准，包括三个部分：(1)一个含有1.5M缩写和6.4M长格式的更大的缩写词典; (2)一个包含1.6亿个句子的预训练语料库; (3)覆盖通用、科学和生物医学领域的三个数据集。我们在我们构建的语料库上预先训练了一种语言模型AcroBERT以进行通用缩写消歧，并展示了我们新基准的挑战和价值。",
    "tldr": "该论文构建了一个名为GLADIS的通用大型缩写消歧基准，包括一个更大的缩写词典、一个包含1.6亿个句子的预训练语料库和覆盖通用、科学和生物医学领域的三个数据集。在此基础上预训练了一种语言模型AcroBERT，以用于通用缩写消歧。",
    "en_tdlr": "This paper constructs a general and large acronym disambiguation benchmark named GLADIS, which includes a larger acronym dictionary, a pre-training corpus with 160 million sentences, and three datasets covering the general, scientific, and biomedical domains. The authors pre-train a language model, AcroBERT, on this benchmark for general acronym disambiguation."
}