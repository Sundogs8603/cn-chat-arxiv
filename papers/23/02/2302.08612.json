{
    "title": "Robust expected improvement for Bayesian optimization. (arXiv:2302.08612v2 [cs.LG] UPDATED)",
    "abstract": "Bayesian Optimization (BO) links Gaussian Process (GP) surrogates with sequential design toward optimizing expensive-to-evaluate black-box functions. Example design heuristics, or so-called acquisition functions, like expected improvement (EI), balance exploration and exploitation to furnish global solutions under stringent evaluation budgets. However, they fall short when solving for robust optima, meaning a preference for solutions in a wider domain of attraction. Robust solutions are useful when inputs are imprecisely specified, or where a series of solutions is desired. A common mathematical programming technique in such settings involves an adversarial objective, biasing a local solver away from ``sharp'' troughs. Here we propose a surrogate modeling and active learning technique called robust expected improvement (REI) that ports adversarial methodology into the BO/GP framework. After describing the methods, we illustrate and draw comparisons to several competitors on benchmark s",
    "link": "http://arxiv.org/abs/2302.08612",
    "context": "Title: Robust expected improvement for Bayesian optimization. (arXiv:2302.08612v2 [cs.LG] UPDATED)\nAbstract: Bayesian Optimization (BO) links Gaussian Process (GP) surrogates with sequential design toward optimizing expensive-to-evaluate black-box functions. Example design heuristics, or so-called acquisition functions, like expected improvement (EI), balance exploration and exploitation to furnish global solutions under stringent evaluation budgets. However, they fall short when solving for robust optima, meaning a preference for solutions in a wider domain of attraction. Robust solutions are useful when inputs are imprecisely specified, or where a series of solutions is desired. A common mathematical programming technique in such settings involves an adversarial objective, biasing a local solver away from ``sharp'' troughs. Here we propose a surrogate modeling and active learning technique called robust expected improvement (REI) that ports adversarial methodology into the BO/GP framework. After describing the methods, we illustrate and draw comparisons to several competitors on benchmark s",
    "path": "papers/23/02/2302.08612.json",
    "total_tokens": 887,
    "translated_title": "鲁棒的期望改进用于贝叶斯优化",
    "translated_abstract": "贝叶斯优化（BO）将高斯过程（GP）拟合与顺序设计相结合，以优化昂贵的黑盒函数。例如设计启发式方法，如期望改进（EI），在严格的评估预算下平衡勘探和开发，以提供全局解决方案。然而，当解决鲁棒最优解时，它们表现不佳，意味着更广阔的吸引域中优先考虑解决方案。当输入不精确指定或需要一系列解决方案时，鲁棒解决方案很有用。在这种情况下，常见的数学规划技术涉及对抗性目标，将局部求解器从“尖锐”的低谷偏离。在描述方法之后，我们提出了一种称为鲁棒期望改进（REI）的拟合模型和主动学习技术，将对抗方法引入了BO / GP框架。我们展示并对比了几个竞争对手在基准上的效果。",
    "tldr": "本论文提出了一种鲁棒的期望改进（REI）方法，将对抗性方法引入贝叶斯优化框架，以解决在广阔的吸引域中寻找解决方案的问题。",
    "en_tdlr": "This paper introduces a robust expected improvement (REI) method that incorporates adversarial techniques into the Bayesian optimization framework to solve the problem of finding solutions in a wider domain of attraction."
}