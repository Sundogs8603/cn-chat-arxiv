{
    "title": "ASSET: Robust Backdoor Data Detection Across a Multiplicity of Deep Learning Paradigms. (arXiv:2302.11408v2 [cs.LG] UPDATED)",
    "abstract": "Backdoor data detection is traditionally studied in an end-to-end supervised learning (SL) setting. However, recent years have seen the proliferating adoption of self-supervised learning (SSL) and transfer learning (TL), due to their lesser need for labeled data. Successful backdoor attacks have also been demonstrated in these new settings. However, we lack a thorough understanding of the applicability of existing detection methods across a variety of learning settings. By evaluating 56 attack settings, we show that the performance of most existing detection methods varies significantly across different attacks and poison ratios, and all fail on the state-of-the-art clean-label attack. In addition, they either become inapplicable or suffer large performance losses when applied to SSL and TL. We propose a new detection method called Active Separation via Offset (ASSET), which actively induces different model behaviors between the backdoor and clean samples to promote their separation. W",
    "link": "http://arxiv.org/abs/2302.11408",
    "context": "Title: ASSET: Robust Backdoor Data Detection Across a Multiplicity of Deep Learning Paradigms. (arXiv:2302.11408v2 [cs.LG] UPDATED)\nAbstract: Backdoor data detection is traditionally studied in an end-to-end supervised learning (SL) setting. However, recent years have seen the proliferating adoption of self-supervised learning (SSL) and transfer learning (TL), due to their lesser need for labeled data. Successful backdoor attacks have also been demonstrated in these new settings. However, we lack a thorough understanding of the applicability of existing detection methods across a variety of learning settings. By evaluating 56 attack settings, we show that the performance of most existing detection methods varies significantly across different attacks and poison ratios, and all fail on the state-of-the-art clean-label attack. In addition, they either become inapplicable or suffer large performance losses when applied to SSL and TL. We propose a new detection method called Active Separation via Offset (ASSET), which actively induces different model behaviors between the backdoor and clean samples to promote their separation. W",
    "path": "papers/23/02/2302.11408.json",
    "total_tokens": 1056,
    "translated_title": "ASSET：在多种深度学习范式中实现鲁棒的后门数据检测",
    "translated_abstract": "传统上，后门数据检测是在端到端监督学习（SL）的设置中进行研究的。然而，近年来，自监督学习（SSL）和迁移学习（TL）的普及应用增加，因为它们对标注数据的需求较少。成功的后门攻击也在这些新的设置中得到了证明。然而，我们对现有检测方法在不同学习设置下的适用性缺乏深入的理解。通过评估56种攻击设置，我们发现大多数现有检测方法的性能在不同攻击和毒害比例下存在显著差异，并且在最新的干净标签攻击下全部失败。此外，当应用于SSL和TL时，它们要么变得不适用，要么遭受较大的性能损失。我们提出了一种名为Active Separation via Offset (ASSET)的新的检测方法，通过在后门和干净样本之间主动引导不同的模型行为来促进它们的分离。",
    "tldr": "该论文研究了在多种深度学习范式中实现鲁棒的后门数据检测，并发现现有的检测方法在不同攻击和毒害比例下的性能变化很大，且不能应用于最新的干净标签攻击，以及自监督学习和迁移学习中性能损失较大。为此，论文提出了一种名为ASSET的新的检测方法，通过主动引导不同的模型行为来促进后门和干净样本的分离。",
    "en_tdlr": "This paper investigates the robust backdoor data detection across multiple deep learning paradigms, and finds that existing detection methods show significant variations in performance across different attacks and poison ratios, fail on the state-of-the-art clean-label attack, and suffer large performance losses in self-supervised learning and transfer learning. As a solution, the paper proposes a new detection method called ASSET, which actively induces different model behaviors to promote the separation between backdoor and clean samples."
}