{
    "title": "Unified Convergence Theory of Stochastic and Variance-Reduced Cubic Newton Methods. (arXiv:2302.11962v2 [math.OC] UPDATED)",
    "abstract": "We study stochastic Cubic Newton methods for solving general possibly non-convex minimization problems. We propose a new framework, which we call the helper framework, that provides a unified view of the stochastic and variance-reduced second-order algorithms equipped with global complexity guarantees. It can also be applied to learning with auxiliary information. Our helper framework offers the algorithm designer high flexibility for constructing and analyzing the stochastic Cubic Newton methods, allowing arbitrary size batches, and the use of noisy and possibly biased estimates of the gradients and Hessians, incorporating both the variance reduction and the lazy Hessian updates. We recover the best-known complexities for the stochastic and variance-reduced Cubic Newton, under weak assumptions on the noise. A direct consequence of our theory is the new lazy stochastic second-order method, which significantly improves the arithmetic complexity for large dimension problems. We also esta",
    "link": "http://arxiv.org/abs/2302.11962",
    "context": "Title: Unified Convergence Theory of Stochastic and Variance-Reduced Cubic Newton Methods. (arXiv:2302.11962v2 [math.OC] UPDATED)\nAbstract: We study stochastic Cubic Newton methods for solving general possibly non-convex minimization problems. We propose a new framework, which we call the helper framework, that provides a unified view of the stochastic and variance-reduced second-order algorithms equipped with global complexity guarantees. It can also be applied to learning with auxiliary information. Our helper framework offers the algorithm designer high flexibility for constructing and analyzing the stochastic Cubic Newton methods, allowing arbitrary size batches, and the use of noisy and possibly biased estimates of the gradients and Hessians, incorporating both the variance reduction and the lazy Hessian updates. We recover the best-known complexities for the stochastic and variance-reduced Cubic Newton, under weak assumptions on the noise. A direct consequence of our theory is the new lazy stochastic second-order method, which significantly improves the arithmetic complexity for large dimension problems. We also esta",
    "path": "papers/23/02/2302.11962.json",
    "total_tokens": 1055,
    "translated_title": "随机和方差减少的三次牛顿方法的统一收敛理论",
    "translated_abstract": "我们研究用于解决一般可能非凸最小化问题的随机三次牛顿方法。我们提出了一个新的框架，称之为辅助框架，它提供了具有全局复杂性保证的随机和方差减少的二阶算法的统一视角。它还可以应用于带有辅助信息的学习。我们的辅助框架为算法设计者提供了构建和分析随机三次牛顿方法的高度灵活性，允许任意大小的批量，并且使用有噪声和可能有偏差的梯度和Hessian的估计，将方差减少和惰性Hessian更新结合起来。在噪声的弱假设下，我们恢复了已知的随机和方差减少的三次牛顿的最佳复杂性。我们理论的一个直接结果是新的惰性随机二阶方法，它显著改进了大维问题的算术复杂性。",
    "tldr": "该论文提出了一个名为辅助框架的新框架，通过统一的视角，提供了具有全局复杂性保证的随机和方差减少的二阶算法。该框架在构建和分析随机三次牛顿方法时具有高度灵活性，使用了任意大小的批量，以及有噪声和可能有偏差的梯度和Hessian的估计，结合了方差减少和惰性Hessian更新。在噪声的弱假设下，恢复了已知的随机和方差减少的三次牛顿的最佳复杂性。",
    "en_tdlr": "This paper proposes a new framework called the helper framework, which provides a unified view of stochastic and variance-reduced second-order algorithms with global complexity guarantees. The framework allows for flexibility in constructing and analyzing stochastic cubic Newton methods, incorporating various batching sizes, noisy and biased estimates, and combining variance reduction with lazy Hessian updates. The paper also presents a new lazy stochastic second-order method that significantly improves arithmetic complexity for high-dimensional problems."
}