{
    "title": "RETVec: Resilient and Efficient Text Vectorizer. (arXiv:2302.09207v2 [cs.CL] UPDATED)",
    "abstract": "This paper describes RETVec, an efficient, resilient, and multilingual text vectorizer designed for neural-based text processing. RETVec combines a novel character encoding with an optional small embedding model to embed words into a 256-dimensional vector space. The RETVec embedding model is pre-trained using pair-wise metric learning to be robust against typos and character-level adversarial attacks. In this paper, we evaluate and compare RETVec to state-of-the-art vectorizers and word embeddings on popular model architectures and datasets. These comparisons demonstrate that RETVec leads to competitive, multilingual models that are significantly more resilient to typos and adversarial text attacks. RETVec is available under the Apache 2 license at https://github.com/google-research/retvec.",
    "link": "http://arxiv.org/abs/2302.09207",
    "context": "Title: RETVec: Resilient and Efficient Text Vectorizer. (arXiv:2302.09207v2 [cs.CL] UPDATED)\nAbstract: This paper describes RETVec, an efficient, resilient, and multilingual text vectorizer designed for neural-based text processing. RETVec combines a novel character encoding with an optional small embedding model to embed words into a 256-dimensional vector space. The RETVec embedding model is pre-trained using pair-wise metric learning to be robust against typos and character-level adversarial attacks. In this paper, we evaluate and compare RETVec to state-of-the-art vectorizers and word embeddings on popular model architectures and datasets. These comparisons demonstrate that RETVec leads to competitive, multilingual models that are significantly more resilient to typos and adversarial text attacks. RETVec is available under the Apache 2 license at https://github.com/google-research/retvec.",
    "path": "papers/23/02/2302.09207.json",
    "total_tokens": 876,
    "translated_title": "RETVec：弹性和高效的文本向量化",
    "translated_abstract": "本文介绍了RETVec，一种专为基于神经网络的文本处理而设计的高效、弹性和多语言的文本向量化器。RETVec采用了一种新颖的字符编码和可选的小型嵌入模型，将词语嵌入到256维向量空间中。RETVec的嵌入模型使用对比度学习进行预训练，以针对拼写错误和字符级对抗攻击具有鲁棒性。在本文中，我们对RETVec在流行的模型架构和数据集上进行了评估和比较。这些比较表明，RETVec能够产生具有竞争力的多语言模型，对拼写错误和对抗性文本攻击具有显著的弹性。RETVec在Apache 2许可下可在https://github.com/google-research/retvec获取。",
    "tldr": "RETVec是一种高效、弹性和多语言的文本向量化器，通过采用新颖的字符编码和对抗攻击鲁棒的嵌入模型，实现了对拼写错误和对抗性攻击的更好适应性。与其他向量化器和词嵌入模型相比，RETVec在各种模型架构和数据集上表现出竞争力和显著的弹性。",
    "en_tdlr": "RETVec is an efficient, resilient, and multilingual text vectorizer that utilizes novel character encoding and adversarially robust embedding model to adapt better to typos and adversarial attacks. Comparative evaluations show that RETVec outperforms other vectorizers and word embeddings in various model architectures and datasets, demonstrating its competitive performance and significant resilience."
}