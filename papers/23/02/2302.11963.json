{
    "title": "Investigating Catastrophic Overfitting in Fast Adversarial Training: A Self-fitting Perspective. (arXiv:2302.11963v2 [cs.LG] UPDATED)",
    "abstract": "Although fast adversarial training provides an efficient approach for building robust networks, it may suffer from a serious problem known as catastrophic overfitting (CO), where multi-step robust accuracy suddenly collapses to zero. In this paper, we for the first time decouple single-step adversarial examples into data-information and self-information, which reveals an interesting phenomenon called \"self-fitting\". Self-fitting, i.e., the network learns the self-information embedded in single-step perturbations, naturally leads to the occurrence of CO. When self-fitting occurs, the network experiences an obvious \"channel differentiation\" phenomenon that some convolution channels accounting for recognizing self-information become dominant, while others for data-information are suppressed. In this way, the network can only recognize images with sufficient self-information and loses generalization ability to other types of data. Based on self-fitting, we provide new insights into the exi",
    "link": "http://arxiv.org/abs/2302.11963",
    "context": "Title: Investigating Catastrophic Overfitting in Fast Adversarial Training: A Self-fitting Perspective. (arXiv:2302.11963v2 [cs.LG] UPDATED)\nAbstract: Although fast adversarial training provides an efficient approach for building robust networks, it may suffer from a serious problem known as catastrophic overfitting (CO), where multi-step robust accuracy suddenly collapses to zero. In this paper, we for the first time decouple single-step adversarial examples into data-information and self-information, which reveals an interesting phenomenon called \"self-fitting\". Self-fitting, i.e., the network learns the self-information embedded in single-step perturbations, naturally leads to the occurrence of CO. When self-fitting occurs, the network experiences an obvious \"channel differentiation\" phenomenon that some convolution channels accounting for recognizing self-information become dominant, while others for data-information are suppressed. In this way, the network can only recognize images with sufficient self-information and loses generalization ability to other types of data. Based on self-fitting, we provide new insights into the exi",
    "path": "papers/23/02/2302.11963.json",
    "total_tokens": 736,
    "translated_title": "快速对抗训练中的灾难性过拟合的自我拟合视角研究",
    "translated_abstract": "虽然快速对抗训练提供了一种构建强健网络的高效方法，但它可能会面临一个严重问题，即灾难性过拟合（CO），其中多步强健准确率突然降至零。本文首次将单步对抗示例分解为数据信息和自信息，揭示了一种有趣的现象，称为“自我拟合”。",
    "tldr": "本文首次将单步对抗示例分解为数据信息和自信息，揭示了一种有趣的现象，称为“自我拟合”，即网络学习单步扰动中嵌入的自信息，导致灾难性过拟合。",
    "en_tdlr": "This paper for the first time decouples single-step adversarial examples into data-information and self-information, revealing an interesting phenomenon called \"self-fitting\", where the network learns the self-information embedded in single-step perturbations, leading to catastrophic overfitting."
}