{
    "title": "Improved Best-of-Both-Worlds Guarantees for Multi-Armed Bandits: FTRL with General Regularizers and Multiple Optimal Arms. (arXiv:2302.13534v2 [cs.LG] UPDATED)",
    "abstract": "We study the problem of designing adaptive multi-armed bandit algorithms that perform optimally in both the stochastic setting and the adversarial setting simultaneously (often known as a best-of-both-world guarantee). A line of recent works shows that when configured and analyzed properly, the Follow-the-Regularized-Leader (FTRL) algorithm, originally designed for the adversarial setting, can in fact optimally adapt to the stochastic setting as well. Such results, however, critically rely on an assumption that there exists one unique optimal arm. Recently, Ito (2021) took the first step to remove such an undesirable uniqueness assumption for one particular FTRL algorithm with the $\\frac{1}{2}$-Tsallis entropy regularizer. In this work, we significantly improve and generalize this result, showing that uniqueness is unnecessary for FTRL with a broad family of regularizers and a new learning rate schedule. For some regularizers, our regret bounds also improve upon prior results even when",
    "link": "http://arxiv.org/abs/2302.13534",
    "context": "Title: Improved Best-of-Both-Worlds Guarantees for Multi-Armed Bandits: FTRL with General Regularizers and Multiple Optimal Arms. (arXiv:2302.13534v2 [cs.LG] UPDATED)\nAbstract: We study the problem of designing adaptive multi-armed bandit algorithms that perform optimally in both the stochastic setting and the adversarial setting simultaneously (often known as a best-of-both-world guarantee). A line of recent works shows that when configured and analyzed properly, the Follow-the-Regularized-Leader (FTRL) algorithm, originally designed for the adversarial setting, can in fact optimally adapt to the stochastic setting as well. Such results, however, critically rely on an assumption that there exists one unique optimal arm. Recently, Ito (2021) took the first step to remove such an undesirable uniqueness assumption for one particular FTRL algorithm with the $\\frac{1}{2}$-Tsallis entropy regularizer. In this work, we significantly improve and generalize this result, showing that uniqueness is unnecessary for FTRL with a broad family of regularizers and a new learning rate schedule. For some regularizers, our regret bounds also improve upon prior results even when",
    "path": "papers/23/02/2302.13534.json",
    "total_tokens": 933,
    "translated_title": "对于多臂赌博机问题，FTRL算法与一般正则化和多个最优臂的最佳保证有所提升",
    "translated_abstract": "本文研究设计自适应多臂赌博机算法，同时在随机设置和对抗设置中表现最优（通常称为最佳保证）。最近的一系列研究表明，当正确配置和分析时，原本设计用于对抗设置的Follow-the-Regularized-Leader（FTRL）算法实际上可以最优地适应随机设置。然而，这些结果关键依赖于存在唯一最优臂的假设。最近，Ito（2021）首次采取措施删除了一个特定FTRL算法对于$\\frac{1}{2}$-Tsallis熵正则化的不可取唯一性假设。本文对这一结果进行了显著改进和推广，表明FTRL算法在广泛的正则化器和新的学习率计划下不需要唯一性。对于某些正则化器，我们的遗憾界限与前人的结果相比也有所提高。",
    "tldr": "本文提出了对于多臂赌博机问题的改进的FTRL算法，通过使用一系列正则化器和新的学习率计划，不再需要假设存在唯一最优臂，并对某些正则化器的遗憾界限进行了改进。"
}