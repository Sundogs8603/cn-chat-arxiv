{
    "title": "A Theoretical Understanding of Shallow Vision Transformers: Learning, Generalization, and Sample Complexity. (arXiv:2302.06015v2 [cs.LG] UPDATED)",
    "abstract": "Vision Transformers (ViTs) with self-attention modules have recently achieved great empirical success in many vision tasks. Due to non-convex interactions across layers, however, theoretical learning and generalization analysis is mostly elusive. Based on a data model characterizing both label-relevant and label-irrelevant tokens, this paper provides the first theoretical analysis of training a shallow ViT, i.e., one self-attention layer followed by a two-layer perceptron, for a classification task. We characterize the sample complexity to achieve a zero generalization error. Our sample complexity bound is positively correlated with the inverse of the fraction of label-relevant tokens, the token noise level, and the initial model error. We also prove that a training process using stochastic gradient descent (SGD) leads to a sparse attention map, which is a formal verification of the general intuition about the success of attention. Moreover, this paper indicates that a proper token spa",
    "link": "http://arxiv.org/abs/2302.06015",
    "context": "Title: A Theoretical Understanding of Shallow Vision Transformers: Learning, Generalization, and Sample Complexity. (arXiv:2302.06015v2 [cs.LG] UPDATED)\nAbstract: Vision Transformers (ViTs) with self-attention modules have recently achieved great empirical success in many vision tasks. Due to non-convex interactions across layers, however, theoretical learning and generalization analysis is mostly elusive. Based on a data model characterizing both label-relevant and label-irrelevant tokens, this paper provides the first theoretical analysis of training a shallow ViT, i.e., one self-attention layer followed by a two-layer perceptron, for a classification task. We characterize the sample complexity to achieve a zero generalization error. Our sample complexity bound is positively correlated with the inverse of the fraction of label-relevant tokens, the token noise level, and the initial model error. We also prove that a training process using stochastic gradient descent (SGD) leads to a sparse attention map, which is a formal verification of the general intuition about the success of attention. Moreover, this paper indicates that a proper token spa",
    "path": "papers/23/02/2302.06015.json",
    "total_tokens": 972,
    "translated_title": "浅层视觉Transformer的理论理解：学习、泛化和样本复杂性的分析",
    "translated_abstract": "近年来，具有自我注意机制的视觉Transformer（ViTs）在许多视觉任务中取得了巨大的实证成功。然而，由于层间的非凸交互，理论上的学习和泛化分析大多是难以理解的。本文提供了对于一项分类任务，使用一个自我注意层和两层感知机的浅层ViT进行训练的第一篇理论分析，建立了对于数据模型的描述，该模型可以同时表征标记相关和标记不相关的令牌。我们界定了达到零泛化误差的样本复杂性。我们的样本复杂性限制与标记相关令牌的部分倒数、标记级别的令牌噪声水平和初始模型误差呈正相关。我们还证明了使用随机梯度下降SGD（stochastic gradient descent）进行训练过程会导致稀疏的注意力图，这是对于注意力成功的一种形式证明。此外，本文指出，适当的令牌确定是确保实现最优性能的关键。",
    "tldr": "本文提供了第一份对于浅层ViT进行训练的理论分析，证明了使用SGD训练会产生稀疏的注意力图，目前的样本复杂度与标记相关令牌的分数倒数、标记级别的令牌噪声水平和初始模型错误呈正相关关系。"
}