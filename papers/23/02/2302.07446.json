{
    "title": "On-Demand Communication for Asynchronous Multi-Agent Bandits. (arXiv:2302.07446v2 [cs.LG] UPDATED)",
    "abstract": "This paper studies a cooperative multi-agent multi-armed stochastic bandit problem where agents operate asynchronously -- agent pull times and rates are unknown, irregular, and heterogeneous -- and face the same instance of a K-armed bandit problem. Agents can share reward information to speed up the learning process at additional communication costs. We propose ODC, an on-demand communication protocol that tailors the communication of each pair of agents based on their empirical pull times. ODC is efficient when the pull times of agents are highly heterogeneous, and its communication complexity depends on the empirical pull times of agents. ODC is a generic protocol that can be integrated into most cooperative bandit algorithms without degrading their performance. We then incorporate ODC into the natural extensions of UCB and AAE algorithms and propose two communication-efficient cooperative algorithms. Our analysis shows that both algorithms are near-optimal in regret.",
    "link": "http://arxiv.org/abs/2302.07446",
    "context": "Title: On-Demand Communication for Asynchronous Multi-Agent Bandits. (arXiv:2302.07446v2 [cs.LG] UPDATED)\nAbstract: This paper studies a cooperative multi-agent multi-armed stochastic bandit problem where agents operate asynchronously -- agent pull times and rates are unknown, irregular, and heterogeneous -- and face the same instance of a K-armed bandit problem. Agents can share reward information to speed up the learning process at additional communication costs. We propose ODC, an on-demand communication protocol that tailors the communication of each pair of agents based on their empirical pull times. ODC is efficient when the pull times of agents are highly heterogeneous, and its communication complexity depends on the empirical pull times of agents. ODC is a generic protocol that can be integrated into most cooperative bandit algorithms without degrading their performance. We then incorporate ODC into the natural extensions of UCB and AAE algorithms and propose two communication-efficient cooperative algorithms. Our analysis shows that both algorithms are near-optimal in regret.",
    "path": "papers/23/02/2302.07446.json",
    "total_tokens": 980,
    "translated_title": "异步多智能体赌博机的按需通信",
    "translated_abstract": "本文研究了一种协作多智能体多臂赌博问题，其中智能体的操作是异步的 - 智能体的拉动时间和速率是未知的、不规则的和异构的 - 并且面对相同的K臂赌博问题的实例。智能体可以共享奖励信息以加快学习过程，但需要额外的通信成本。我们提出了一种按需通信协议ODC，根据智能体的经验拉动时间调整每对智能体间的通信。当智能体的拉动时间高度不均匀时，ODC具有高效性，并且其通信复杂性取决于智能体的经验拉动时间。ODC是一个通用的协议，可以集成到大多数协作赌博算法中而不降低其性能。然后，我们将ODC集成到UCB和AAE算法的自然扩展中，并提出了两种通信效率高的协作算法。我们的分析表明，这两个算法在遗憾方面都接近最优。",
    "tldr": "本文研究了一种协作多智能体多臂赌博问题，提出了一种按需通信协议ODC，可以根据智能体的经验拉动时间调整每对智能体间的通信，同时将ODC集成到UCB和AAE算法的自然扩展中，提出了两种通信效率高的协作算法，分析表明这两个算法在遗憾方面都接近最优。",
    "en_tdlr": "This paper studies a cooperative multi-agent multi-armed bandit problem and proposes an on-demand communication protocol ODC, which adjusts the communication between each pair of agents based on their empirical pull times. ODC is integrated into the natural extensions of UCB and AAE algorithms to propose two communication-efficient cooperative algorithms, and analysis shows that both algorithms are near-optimal in regret."
}