{
    "title": "Two-Stage Constrained Actor-Critic for Short Video Recommendation. (arXiv:2302.01680v3 [cs.LG] UPDATED)",
    "abstract": "The wide popularity of short videos on social media poses new opportunities and challenges to optimize recommender systems on the video-sharing platforms. Users sequentially interact with the system and provide complex and multi-faceted responses, including watch time and various types of interactions with multiple videos. One the one hand, the platforms aims at optimizing the users' cumulative watch time (main goal) in long term, which can be effectively optimized by Reinforcement Learning. On the other hand, the platforms also needs to satisfy the constraint of accommodating the responses of multiple user interactions (auxiliary goals) such like, follow, share etc. In this paper, we formulate the problem of short video recommendation as a Constrained Markov Decision Process (CMDP). We find that traditional constrained reinforcement learning algorithms can not work well in this setting. We propose a novel two-stage constrained actor-critic method: At stage one, we learn individual pol",
    "link": "http://arxiv.org/abs/2302.01680",
    "context": "Title: Two-Stage Constrained Actor-Critic for Short Video Recommendation. (arXiv:2302.01680v3 [cs.LG] UPDATED)\nAbstract: The wide popularity of short videos on social media poses new opportunities and challenges to optimize recommender systems on the video-sharing platforms. Users sequentially interact with the system and provide complex and multi-faceted responses, including watch time and various types of interactions with multiple videos. One the one hand, the platforms aims at optimizing the users' cumulative watch time (main goal) in long term, which can be effectively optimized by Reinforcement Learning. On the other hand, the platforms also needs to satisfy the constraint of accommodating the responses of multiple user interactions (auxiliary goals) such like, follow, share etc. In this paper, we formulate the problem of short video recommendation as a Constrained Markov Decision Process (CMDP). We find that traditional constrained reinforcement learning algorithms can not work well in this setting. We propose a novel two-stage constrained actor-critic method: At stage one, we learn individual pol",
    "path": "papers/23/02/2302.01680.json",
    "total_tokens": 1006,
    "translated_title": "两阶段有约束的演员-评论家算法用于短视频推荐",
    "translated_abstract": "社交媒体上短视频的广泛流行为视频分享平台上的推荐系统优化提供了新的机遇和挑战。用户与系统依次交互，并提供包括观看时间和对多个视频的各种类型交互在内的复杂多面 responses。一方面，平台旨在长期优化用户的累计观看时间（主要目标），这可以通过强化学习有效优化。另一方面，平台还需要满足适应多个用户交互 responses（辅助目标）的约束，如 follow、share 等。在本文中，我们将短视频推荐问题作为约束马尔可夫决策过程（CMDP）进行了建模。我们发现传统的约束强化学习算法在这种情况下效果不好。我们提出了一种新颖的两阶段有约束的演员-评论家方法：第一阶段，我们学习个体的策略，以优化主要目标。第二阶段，我们进一步学习共享的策略，以满足辅助目标的约束。",
    "tldr": "本论文提出了一种两阶段有约束的演员-评论家算法，用于解决短视频推荐问题。通过将短视频推荐问题建模为约束马尔可夫决策过程，我们解决了在用户交互和多样的响应中优化累计观看时间的问题。进行了两阶段的策略学习，并且能够同时满足主要目标和辅助目标的约束。",
    "en_tdlr": "This paper proposes a two-stage constrained actor-critic algorithm for short video recommendation. By formulating the problem as a Constrained Markov Decision Process, it addresses the challenge of optimizing cumulative watch time in the context of user interactions and diverse responses. The paper introduces a two-stage policy learning approach that can simultaneously satisfy the main objective and auxiliary constraints."
}