{
    "title": "The geometry of hidden representations of large transformer models. (arXiv:2302.00294v2 [cs.LG] UPDATED)",
    "abstract": "Large transformers are powerful architectures used for self-supervised data analysis across various data types, including protein sequences, images, and text. In these models, the semantic structure of the dataset emerges from a sequence of transformations between one representation and the next. We characterize the geometric and statistical properties of these representations and how they change as we move through the layers. By analyzing the intrinsic dimension (ID) and neighbor composition, we find that the representations evolve similarly in transformers trained on protein language tasks and image reconstruction tasks. In the first layers, the data manifold expands, becoming high-dimensional, and then contracts significantly in the intermediate layers. In the last part of the model, the ID remains approximately constant or forms a second shallow peak. We show that the semantic information of the dataset is better expressed at the end of the first peak, and this phenomenon can be ob",
    "link": "http://arxiv.org/abs/2302.00294",
    "context": "Title: The geometry of hidden representations of large transformer models. (arXiv:2302.00294v2 [cs.LG] UPDATED)\nAbstract: Large transformers are powerful architectures used for self-supervised data analysis across various data types, including protein sequences, images, and text. In these models, the semantic structure of the dataset emerges from a sequence of transformations between one representation and the next. We characterize the geometric and statistical properties of these representations and how they change as we move through the layers. By analyzing the intrinsic dimension (ID) and neighbor composition, we find that the representations evolve similarly in transformers trained on protein language tasks and image reconstruction tasks. In the first layers, the data manifold expands, becoming high-dimensional, and then contracts significantly in the intermediate layers. In the last part of the model, the ID remains approximately constant or forms a second shallow peak. We show that the semantic information of the dataset is better expressed at the end of the first peak, and this phenomenon can be ob",
    "path": "papers/23/02/2302.00294.json",
    "total_tokens": 919,
    "translated_title": "大型Transformer模型的隐藏表示的几何学",
    "translated_abstract": "大型Transformer模型是用于自监督数据分析的强大架构，可以处理包括蛋白质序列、图像和文本在内的各种数据类型。在这些模型中，数据集的语义结构通过一个表示与下一个表示之间的一系列变换而出现。我们表征了这些表示的几何和统计特性，以及它们在层级移动时的变化。通过分析内在维度（ID）和邻居组成，我们发现在训练在蛋白质语言任务和图像重建任务上的Transformer模型中，表示以相似的方式演化。在最初的几层中，数据流形扩展，变得高维，然后在中间层中显著收缩。在模型的最后部分，ID保持大致恒定或形成第二个浅峰。我们展示了数据集的语义信息在第一个峰值结束时更好地表达，这一现象可以被观察到。",
    "tldr": "大型Transformer模型中的隐藏表示具有类似的几何和统计特性，随着层级的移动，它们在最初的几层中变得高维，然后在中间层中显著收缩，在模型的最后部分，保持恒定或形成第二个浅峰。在第一个峰值结束时，数据集的语义信息被更好地表达。"
}