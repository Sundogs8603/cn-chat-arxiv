{
    "title": "Gradient Descent with Linearly Correlated Noise: Theory and Applications to Differential Privacy. (arXiv:2302.01463v2 [cs.LG] UPDATED)",
    "abstract": "We study gradient descent under linearly correlated noise. Our work is motivated by recent practical methods for optimization with differential privacy (DP), such as DP-FTRL, which achieve strong performance in settings where privacy amplification techniques are infeasible (such as in federated learning). These methods inject privacy noise through a matrix factorization mechanism, making the noise linearly correlated over iterations. We propose a simplified setting that distills key facets of these methods and isolates the impact of linearly correlated noise. We analyze the behavior of gradient descent in this setting, for both convex and non-convex functions. Our analysis is demonstrably tighter than prior work and recovers multiple important special cases exactly (including anticorrelated perturbed gradient descent). We use our results to develop new, effective matrix factorizations for differentially private optimization, and highlight the benefits of these factorizations theoretica",
    "link": "http://arxiv.org/abs/2302.01463",
    "context": "Title: Gradient Descent with Linearly Correlated Noise: Theory and Applications to Differential Privacy. (arXiv:2302.01463v2 [cs.LG] UPDATED)\nAbstract: We study gradient descent under linearly correlated noise. Our work is motivated by recent practical methods for optimization with differential privacy (DP), such as DP-FTRL, which achieve strong performance in settings where privacy amplification techniques are infeasible (such as in federated learning). These methods inject privacy noise through a matrix factorization mechanism, making the noise linearly correlated over iterations. We propose a simplified setting that distills key facets of these methods and isolates the impact of linearly correlated noise. We analyze the behavior of gradient descent in this setting, for both convex and non-convex functions. Our analysis is demonstrably tighter than prior work and recovers multiple important special cases exactly (including anticorrelated perturbed gradient descent). We use our results to develop new, effective matrix factorizations for differentially private optimization, and highlight the benefits of these factorizations theoretica",
    "path": "papers/23/02/2302.01463.json",
    "total_tokens": 864,
    "translated_title": "线性相关噪声下的梯度下降：理论及应用于差分隐私中",
    "translated_abstract": "我们研究了在线性相关噪声下的梯度下降。我们的工作是由最近针对具有差分隐私（DP）的优化的实践方法所启发的，例如DP-FTRL，在无法使用隐私放大技术的情况下（例如在联邦学习中），这些方法通过矩阵分解机制注入隐私噪声，使噪声在迭代过程中呈线性相关关系。我们提出了一种简化的环境，精简了这些方法的关键面貌，并分离了线性相关噪声的影响。我们分析了梯度下降在这种情况下的行为，无论是凸函数还是非凸函数。我们的分析明显比之前的工作更紧，并精确地恢复了多个重要的特殊情况（包括反相关扰动梯度下降）。我们使用我们的结果开发了新的，有效的矩阵分解方法，用于不同ially private optimization，并突出了这些因子分解方法的好处",
    "tldr": "本文研究梯度下降在线性相关噪声下的表现，提出了新的矩阵分解方法用于不同ially private optimization。",
    "en_tdlr": "This paper investigates the behavior of gradient descent under linearly correlated noise and proposes new matrix factorizations for differentially private optimization."
}