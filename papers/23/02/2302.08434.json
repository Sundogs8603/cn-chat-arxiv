{
    "title": "On marginal feature attributions of tree-based models. (arXiv:2302.08434v2 [cs.LG] UPDATED)",
    "abstract": "Due to their power and ease of use, tree-based machine learning models, such as random forests and gradient-boosted tree ensembles, have become very popular. To interpret them, local feature attributions based on marginal expectations, e.g. marginal (interventional) Shapley, Owen or Banzhaf values, may be employed. Such methods are true to the model and implementation invariant, i.e. dependent only on the input-output function of the model. We contrast this with the popular TreeSHAP algorithm by presenting two (statistically similar) decision trees that compute the exact same function for which the \"path-dependent\" TreeSHAP yields different rankings of features, whereas the marginal Shapley values coincide. Furthermore, we discuss how the internal structure of tree-based models may be leveraged to help with computing their marginal feature attributions according to a linear game value. One important observation is that these are simple (piecewise-constant) functions with respect to a c",
    "link": "http://arxiv.org/abs/2302.08434",
    "context": "Title: On marginal feature attributions of tree-based models. (arXiv:2302.08434v2 [cs.LG] UPDATED)\nAbstract: Due to their power and ease of use, tree-based machine learning models, such as random forests and gradient-boosted tree ensembles, have become very popular. To interpret them, local feature attributions based on marginal expectations, e.g. marginal (interventional) Shapley, Owen or Banzhaf values, may be employed. Such methods are true to the model and implementation invariant, i.e. dependent only on the input-output function of the model. We contrast this with the popular TreeSHAP algorithm by presenting two (statistically similar) decision trees that compute the exact same function for which the \"path-dependent\" TreeSHAP yields different rankings of features, whereas the marginal Shapley values coincide. Furthermore, we discuss how the internal structure of tree-based models may be leveraged to help with computing their marginal feature attributions according to a linear game value. One important observation is that these are simple (piecewise-constant) functions with respect to a c",
    "path": "papers/23/02/2302.08434.json",
    "total_tokens": 953,
    "translated_title": "基于树模型的边际特征归因研究",
    "translated_abstract": "由于其强大和易于使用的特点，随机森林和梯度提升树集成等基于树的机器学习模型变得非常流行。为了解释这些模型，可以使用基于边际期望的局部特征归因方法，例如边际（干预）Shapley、Owen或Banzhaf值。这些方法对模型真实且实现不变，即仅依赖于模型的输入输出函数。通过提供两个（具有相似统计性质的）决策树来对比这一点，这两个决策树计算完全相同的函数，但“路径相关”的TreeSHAP方法给出了不同的特征排序，而边际Shapley值重合。此外，我们讨论了如何利用基于树模型的内部结构来帮助计算它们的边际特征归因，以得到线性博弈值。一个重要的观察是，这些函数在某个常数区间内是简单的（分段常数）函数。",
    "tldr": "该论文讨论了基于树模型的边际特征归因方法，与流行的TreeSHAP算法相比，边际Shapley值在相同函数的情况下保持一致，并且介绍了如何利用树模型的内部结构计算边际特征归因。",
    "en_tdlr": "This paper discusses marginal feature attributions based on tree-based models and compares them with the popular TreeSHAP algorithm. It shows that the marginal Shapley values remain consistent for the same function, while TreeSHAP yields different rankings. The paper also explores leveraging the internal structure of tree-based models for computing marginal feature attributions."
}