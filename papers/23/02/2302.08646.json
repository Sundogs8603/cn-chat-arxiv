{
    "title": "AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving. (arXiv:2302.08646v3 [cs.LG] UPDATED)",
    "abstract": "Object detection with on-board sensors (e.g., lidar, radar, and camera) play a crucial role in autonomous driving (AD), and these sensors complement each other in modalities. While crowdsensing may potentially exploit these sensors (of huge quantity) to derive more comprehensive knowledge, \\textit{federated learning} (FL) appears to be the necessary tool to reach this potential: it enables autonomous vehicles (AVs) to train machine learning models without explicitly sharing raw sensory data. However, the multimodal sensors introduce various data heterogeneity across distributed AVs (e.g., label quantity skews and varied modalities), posing critical challenges to effective FL. To this end, we present AutoFed as a heterogeneity-aware FL framework to fully exploit multimodal sensory data on AVs and thus enable robust AD. Specifically, we first propose a novel model leveraging pseudo-labeling to avoid mistakenly treating unlabeled objects as the background. We also propose an autoencoder-b",
    "link": "http://arxiv.org/abs/2302.08646",
    "context": "Title: AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving. (arXiv:2302.08646v3 [cs.LG] UPDATED)\nAbstract: Object detection with on-board sensors (e.g., lidar, radar, and camera) play a crucial role in autonomous driving (AD), and these sensors complement each other in modalities. While crowdsensing may potentially exploit these sensors (of huge quantity) to derive more comprehensive knowledge, \\textit{federated learning} (FL) appears to be the necessary tool to reach this potential: it enables autonomous vehicles (AVs) to train machine learning models without explicitly sharing raw sensory data. However, the multimodal sensors introduce various data heterogeneity across distributed AVs (e.g., label quantity skews and varied modalities), posing critical challenges to effective FL. To this end, we present AutoFed as a heterogeneity-aware FL framework to fully exploit multimodal sensory data on AVs and thus enable robust AD. Specifically, we first propose a novel model leveraging pseudo-labeling to avoid mistakenly treating unlabeled objects as the background. We also propose an autoencoder-b",
    "path": "papers/23/02/2302.08646.json",
    "total_tokens": 1167,
    "translated_title": "AutoFed：用于稳健自动驾驶的异构感知联邦多模态学习",
    "translated_abstract": "自动驾驶中，基于车载传感器（如激光雷达、雷达和摄像头）的目标检测起着至关重要的作用，而这些传感器在模态上互为补充。尽管众感知技术可能潜在地利用这些传感器（数量巨大）来得出更全面的知识，但是，\\textit{联邦学习}（FL）似乎是达到这个潜力的必要工具：它使得自动驾驶车辆（AVs）能够在不显式共享原始传感数据的情况下训练机器学习模型。然而，多模态传感器引入了分布式AVs（如标签数量偏差和不同形式）的各种数据异质性，给有效FL带来了重大挑战。为此，我们提出了AutoFed作为一种异构感知FL框架，充分利用AVs上的多模态传感数据，从而实现稳健的自动驾驶。具体而言，我们首先提出了一种新颖的模型，利用伪标签来避免错误地将未标记的对象视为背景。我们还提出了一种基于自编码器的预训练方法，用于学习多模态数据的通用特征表示。借助这些技术，AutoFed可以成功地聚合来自具有各种数据异质性的分布式AVs的多模态数据，并比传统FL和非FL方法实现更好的物体检测结果。",
    "tldr": "AutoFed 是一种支持异构感知联邦学习的框架，旨在充分利用自动驾驶车辆上的多模态传感数据，并以此实现稳健的自动驾驶。它通过伪标签和自编码器预训练的方法，在解决分布式AVs上具有异构数据的挑战方面表现良好。",
    "en_tdlr": "AutoFed is a heterogeneity-aware federated learning framework that aims to fully exploit multimodal sensory data on autonomous vehicles and enable robust autonomous driving. It performs well in addressing the challenges of heterogeneous data on distributed AVs through the use of pseudo-labels and autoencoder pretraining."
}