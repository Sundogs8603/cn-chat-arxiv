{
    "title": "Black-Box Batch Active Learning for Regression. (arXiv:2302.08981v2 [cs.LG] UPDATED)",
    "abstract": "Batch active learning is a popular approach for efficiently training machine learning models on large, initially unlabelled datasets by repeatedly acquiring labels for batches of data points. However, many recent batch active learning methods are white-box approaches and are often limited to differentiable parametric models: they score unlabeled points using acquisition functions based on model embeddings or first- and second-order derivatives. In this paper, we propose black-box batch active learning for regression tasks as an extension of white-box approaches. Crucially, our method only relies on model predictions. This approach is compatible with a wide range of machine learning models, including regular and Bayesian deep learning models and non-differentiable models such as random forests. It is rooted in Bayesian principles and utilizes recent kernel-based approaches. This allows us to extend a wide range of existing state-of-the-art white-box batch active learning methods (BADGE,",
    "link": "http://arxiv.org/abs/2302.08981",
    "context": "Title: Black-Box Batch Active Learning for Regression. (arXiv:2302.08981v2 [cs.LG] UPDATED)\nAbstract: Batch active learning is a popular approach for efficiently training machine learning models on large, initially unlabelled datasets by repeatedly acquiring labels for batches of data points. However, many recent batch active learning methods are white-box approaches and are often limited to differentiable parametric models: they score unlabeled points using acquisition functions based on model embeddings or first- and second-order derivatives. In this paper, we propose black-box batch active learning for regression tasks as an extension of white-box approaches. Crucially, our method only relies on model predictions. This approach is compatible with a wide range of machine learning models, including regular and Bayesian deep learning models and non-differentiable models such as random forests. It is rooted in Bayesian principles and utilizes recent kernel-based approaches. This allows us to extend a wide range of existing state-of-the-art white-box batch active learning methods (BADGE,",
    "path": "papers/23/02/2302.08981.json",
    "total_tokens": 838,
    "translated_title": "黑盒批量主动学习回归",
    "translated_abstract": "批量主动学习是一种常用的方法，可以通过重复获取数据点的标签来高效地训练机器学习模型，尤其是对于大规模的初始未标记数据集。然而，许多最近的批量主动学习方法都是白盒方法，并且通常仅限于可微分的参数模型：它们使用基于模型嵌入或一阶和二阶导数的获取函数对未标记的数据点进行评分。在本文中，我们提出了一种黑盒批量主动学习回归任务的方法，作为白盒方法的扩展。关键的是，我们的方法仅依赖于模型的预测。这种方法适用于各种机器学习模型，包括常规的和贝叶斯深度学习模型以及非可微分模型，如随机森林。它基于贝叶斯原则，并利用最近的基于核的方法。这使得我们能够扩展一系列现有的最先进的白盒批量主动学习方法（BADGE）。",
    "tldr": "本文提出了一种黑盒批量主动学习方法，该方法仅利用模型预测进行评估，适用于各种机器学习模型，并扩展了一系列白盒批量主动学习方法。"
}