{
    "title": "IC3: Image Captioning by Committee Consensus. (arXiv:2302.01328v3 [cs.CV] UPDATED)",
    "abstract": "If you ask a human to describe an image, they might do so in a thousand different ways. Traditionally, image captioning models are trained to generate a single \"best\" (most like a reference) image caption. Unfortunately, doing so encourages captions that are \"informationally impoverished,\" and focus on only a subset of the possible details, while ignoring other potentially useful information in the scene. In this work, we introduce a simple, yet novel, method: \"Image Captioning by Committee Consensus\" (IC3), designed to generate a single caption that captures high-level details from several annotator viewpoints. Humans rate captions produced by IC3 at least as helpful as baseline SOTA models more than two thirds of the time, and IC3 can improve the performance of SOTA automated recall systems by up to 84%, outperforming single human-generated reference captions, and indicating significant improvements over SOTA approaches for visual description. Code is available at https://davidmchan.",
    "link": "http://arxiv.org/abs/2302.01328",
    "context": "Title: IC3: Image Captioning by Committee Consensus. (arXiv:2302.01328v3 [cs.CV] UPDATED)\nAbstract: If you ask a human to describe an image, they might do so in a thousand different ways. Traditionally, image captioning models are trained to generate a single \"best\" (most like a reference) image caption. Unfortunately, doing so encourages captions that are \"informationally impoverished,\" and focus on only a subset of the possible details, while ignoring other potentially useful information in the scene. In this work, we introduce a simple, yet novel, method: \"Image Captioning by Committee Consensus\" (IC3), designed to generate a single caption that captures high-level details from several annotator viewpoints. Humans rate captions produced by IC3 at least as helpful as baseline SOTA models more than two thirds of the time, and IC3 can improve the performance of SOTA automated recall systems by up to 84%, outperforming single human-generated reference captions, and indicating significant improvements over SOTA approaches for visual description. Code is available at https://davidmchan.",
    "path": "papers/23/02/2302.01328.json",
    "total_tokens": 930,
    "translated_title": "IC3：通过委员会共识进行图像字幕生成",
    "translated_abstract": "如果你请一个人描述一幅图像，他们可能会用一千种不同的方式来描述。传统上，图像字幕生成模型被训练成生成一个“最佳”（与参考最相似）的图像字幕。然而，这样做会鼓励生成“信息贫乏”的字幕，并且只关注可能细节的一个子集，而忽略了场景中其他可能有用的信息。在这项工作中，我们引入了一种简单而新颖的方法：\"通过委员会共识进行图像字幕生成\"（IC3），旨在生成一个能够从多个注释者的视角捕捉到高层细节的单个字幕。人类评价IC3生成的字幕至少与基准SOTA模型一样有帮助的情况占了三分之二以上，并且IC3可以将SOTA自动召回系统的性能提升高达84%，胜过单个人生成的参考字幕，并显示出在视觉描述方面相比于SOTA方法的显著改进。代码可通过https://davidmchan获取。",
    "tldr": "\"IC3: Image Captioning by Committee Consensus\"引入了一种通过委员会共识生成图像字幕的方法，能够从多个注释者的视角捕捉高层细节，优于单个人生成的参考字幕，并在视觉描述方面取得了显著改进。",
    "en_tdlr": "\"IC3: Image Captioning by Committee Consensus\" introduces a method of generating image captions through committee consensus, capturing high-level details from multiple annotators and outperforming single human-generated reference captions, resulting in significant improvements in visual description."
}