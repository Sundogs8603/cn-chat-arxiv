{
    "title": "Mean Field Optimization Problem Regularized by Fisher Information. (arXiv:2302.05938v2 [math.PR] UPDATED)",
    "abstract": "Recently there is a rising interest in the research of mean field optimization, in particular because of its role in analyzing the training of neural networks. In this paper by adding the Fisher Information as the regularizer, we relate the regularized mean field optimization problem to a so-called mean field Schrodinger dynamics. We develop an energy-dissipation method to show that the marginal distributions of the mean field Schrodinger dynamics converge exponentially quickly towards the unique minimizer of the regularized optimization problem. Remarkably, the mean field Schrodinger dynamics is proved to be a gradient flow on the probability measure space with respect to the relative entropy. Finally we propose a Monte Carlo method to sample the marginal distributions of the mean field Schrodinger dynamics.",
    "link": "http://arxiv.org/abs/2302.05938",
    "context": "Title: Mean Field Optimization Problem Regularized by Fisher Information. (arXiv:2302.05938v2 [math.PR] UPDATED)\nAbstract: Recently there is a rising interest in the research of mean field optimization, in particular because of its role in analyzing the training of neural networks. In this paper by adding the Fisher Information as the regularizer, we relate the regularized mean field optimization problem to a so-called mean field Schrodinger dynamics. We develop an energy-dissipation method to show that the marginal distributions of the mean field Schrodinger dynamics converge exponentially quickly towards the unique minimizer of the regularized optimization problem. Remarkably, the mean field Schrodinger dynamics is proved to be a gradient flow on the probability measure space with respect to the relative entropy. Finally we propose a Monte Carlo method to sample the marginal distributions of the mean field Schrodinger dynamics.",
    "path": "papers/23/02/2302.05938.json",
    "total_tokens": 811,
    "translated_title": "通过Fisher信息对均值场优化问题进行正则化",
    "translated_abstract": "最近，对均值场优化的研究越发受到关注，特别是在分析神经网络训练时。本文通过将Fisher信息作为正则化项，将正则化的均值场优化问题与所谓的均值场薛定谔动力学联系起来。我们开发了一种能量耗散方法，证明了均值场薛定谔动力学的边缘分布以指数速度收敛于正则化优化问题的唯一最小值点。值得注意的是，我们证明了均值场薛定谔动力学是概率测度空间上相对熵的梯度流。最后，我们提出了一种蒙特卡洛方法来采样均值场薛定谔动力学的边缘分布。",
    "tldr": "本文通过Fisher信息对均值场优化问题进行了正则化，证明了均值场薛定谔动力学是概率测度空间上的梯度流，并提出了一种蒙特卡洛方法来采样均值场薛定谔动力学的边缘分布。"
}