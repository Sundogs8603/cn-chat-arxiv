{
    "title": "Learning Complex Teamwork Tasks Using a Given Sub-task Decomposition",
    "abstract": "arXiv:2302.04944v2 Announce Type: replace-cross  Abstract: Training a team to complete a complex task via multi-agent reinforcement learning can be difficult due to challenges such as policy search in a large joint policy space, and non-stationarity caused by mutually adapting agents. To facilitate efficient learning of complex multi-agent tasks, we propose an approach which uses an expert-provided decomposition of a task into simpler multi-agent sub-tasks. In each sub-task, a subset of the entire team is trained to acquire sub-task-specific policies. The sub-teams are then merged and transferred to the target task, where their policies are collectively fine-tuned to solve the more complex target task. We show empirically that such approaches can greatly reduce the number of timesteps required to solve a complex target task relative to training from-scratch. However, we also identify and investigate two problems with naive implementations of approaches based on sub-task decomposition, ",
    "link": "https://arxiv.org/abs/2302.04944",
    "context": "Title: Learning Complex Teamwork Tasks Using a Given Sub-task Decomposition\nAbstract: arXiv:2302.04944v2 Announce Type: replace-cross  Abstract: Training a team to complete a complex task via multi-agent reinforcement learning can be difficult due to challenges such as policy search in a large joint policy space, and non-stationarity caused by mutually adapting agents. To facilitate efficient learning of complex multi-agent tasks, we propose an approach which uses an expert-provided decomposition of a task into simpler multi-agent sub-tasks. In each sub-task, a subset of the entire team is trained to acquire sub-task-specific policies. The sub-teams are then merged and transferred to the target task, where their policies are collectively fine-tuned to solve the more complex target task. We show empirically that such approaches can greatly reduce the number of timesteps required to solve a complex target task relative to training from-scratch. However, we also identify and investigate two problems with naive implementations of approaches based on sub-task decomposition, ",
    "path": "papers/23/02/2302.04944.json",
    "total_tokens": 883,
    "translated_title": "使用给定的子任务分解学习复杂的团队合作任务",
    "translated_abstract": "通过多智能体强化学习训练团队完成复杂任务可能面临诸如在大型联合策略空间中搜索策略和因互相适应而导致的非稳定性等挑战。为了促进对复杂多智能体任务的高效学习，我们提出了一种方法，该方法使用专家提供的任务分解为更简单的多智能体子任务。在每个子任务中，对整个团队的子集进行训练以获取特定于子任务的策略。然后将子团队合并并迁移到目标任务中，在那里他们的策略被集体调整以解决更复杂的目标任务。我们通过实验证明，这种方法可以显著减少解决复杂目标任务所需的时间步数，相对于从头开始训练。然而，我们还发现并研究了基于子任务分解的天真实现方法的两个问题。",
    "tldr": "通过使用专家提供的任务分解为更简单的多智能体子任务，并将其转移到目标任务中进行集体调整，我们的方法可以有效地学习复杂的多智能体任务，并在解决复杂目标任务所需的时间步数上实现了显著的减少。",
    "en_tdlr": "By using expert-provided task decomposition into simpler multi-agent sub-tasks and transferring them to the target task for collective fine-tuning, our approach enables efficient learning of complex multi-agent tasks and significantly reduces the number of timesteps required to solve complex target tasks."
}