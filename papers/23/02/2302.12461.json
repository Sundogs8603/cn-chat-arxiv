{
    "title": "Analyzing And Editing Inner Mechanisms Of Backdoored Language Models. (arXiv:2302.12461v2 [cs.LG] UPDATED)",
    "abstract": "Poisoning of data sets is a potential security threat to large language models that can lead to backdoored models. A description of the internal mechanisms of backdoored language models and how they process trigger inputs, e.g., when switching to toxic language, has yet to be found. In this work, we study the internal representations of transformer-based backdoored language models and determine early-layer MLP modules as most important for the backdoor mechanism in combination with the initial embedding projection. We use this knowledge to remove, insert, and modify backdoor mechanisms with engineered replacements that reduce the MLP module outputs to essentials for the backdoor mechanism. To this end, we introduce PCP ablation, where we replace transformer modules with low-rank matrices based on the principal components of their activations. We demonstrate our results on backdoored toy, backdoored large, and non-backdoored open-source models. We show that we can improve the backdoor r",
    "link": "http://arxiv.org/abs/2302.12461",
    "context": "Title: Analyzing And Editing Inner Mechanisms Of Backdoored Language Models. (arXiv:2302.12461v2 [cs.LG] UPDATED)\nAbstract: Poisoning of data sets is a potential security threat to large language models that can lead to backdoored models. A description of the internal mechanisms of backdoored language models and how they process trigger inputs, e.g., when switching to toxic language, has yet to be found. In this work, we study the internal representations of transformer-based backdoored language models and determine early-layer MLP modules as most important for the backdoor mechanism in combination with the initial embedding projection. We use this knowledge to remove, insert, and modify backdoor mechanisms with engineered replacements that reduce the MLP module outputs to essentials for the backdoor mechanism. To this end, we introduce PCP ablation, where we replace transformer modules with low-rank matrices based on the principal components of their activations. We demonstrate our results on backdoored toy, backdoored large, and non-backdoored open-source models. We show that we can improve the backdoor r",
    "path": "papers/23/02/2302.12461.json",
    "total_tokens": 954,
    "translated_title": "分析和编辑暗藏后门的语言模型的内部机制",
    "translated_abstract": "数据集中的毒化是对大型语言模型的潜在安全威胁，可能导致暗藏后门的模型。关于暗藏后门语言模型的内部机制以及它们如何处理触发输入（例如，切换至有毒语言）的描述尚未找到。本文研究基于Transformer的暗藏后门语言模型的内部表示，并确定早期层的MLP模块与初始嵌入投影结合是后门机制中最重要的部分。我们利用这些知识来删除、插入和修改后门机制，并用工程化替代物降低MLP模块输出的重要性。为此，我们引入了基于主要成分的低秩矩阵的PCP消融技术，用其替换变压器模块。我们在暗藏后门的玩具模型、暗藏后门的大型模型和非暗藏后门的开源模型上展示了我们的结果。我们表明我们可以改善后门的输出效果。",
    "tldr": "本研究分析并编辑暗藏后门的语言模型的内部机制，发现早期层的MLP模块和初始嵌入投影是后门机制中最重要的部分。通过使用PCP消融技术替换变压器模块，我们成功删除、插入和修改后门机制，并显著改善了后门的输出效果。",
    "en_tdlr": "This study analyzes and edits the internal mechanisms of backdoored language models, identifying early-layer MLP modules and initial embedding projection as crucial components of the backdoor mechanism. By employing PCP ablation technique to replace transformer modules, we successfully remove, insert, and modify the backdoor mechanism, greatly improving the output performance."
}