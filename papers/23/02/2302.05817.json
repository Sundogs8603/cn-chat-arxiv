{
    "title": "Level Generation Through Large Language Models. (arXiv:2302.05817v2 [cs.AI] UPDATED)",
    "abstract": "Large Language Models (LLMs) are powerful tools, capable of leveraging their training on natural language to write stories, generate code, and answer questions. But can they generate functional video game levels? Game levels, with their complex functional constraints and spatial relationships in more than one dimension, are very different from the kinds of data an LLM typically sees during training. Datasets of game levels are also hard to come by, potentially taxing the abilities of these data-hungry models. We investigate the use of LLMs to generate levels for the game Sokoban, finding that LLMs are indeed capable of doing so, and that their performance scales dramatically with dataset size. We also perform preliminary experiments on controlling LLM level generators and discuss promising areas for future work.",
    "link": "http://arxiv.org/abs/2302.05817",
    "context": "Title: Level Generation Through Large Language Models. (arXiv:2302.05817v2 [cs.AI] UPDATED)\nAbstract: Large Language Models (LLMs) are powerful tools, capable of leveraging their training on natural language to write stories, generate code, and answer questions. But can they generate functional video game levels? Game levels, with their complex functional constraints and spatial relationships in more than one dimension, are very different from the kinds of data an LLM typically sees during training. Datasets of game levels are also hard to come by, potentially taxing the abilities of these data-hungry models. We investigate the use of LLMs to generate levels for the game Sokoban, finding that LLMs are indeed capable of doing so, and that their performance scales dramatically with dataset size. We also perform preliminary experiments on controlling LLM level generators and discuss promising areas for future work.",
    "path": "papers/23/02/2302.05817.json",
    "total_tokens": 812,
    "translated_title": "通过大型语言模型进行关卡生成",
    "translated_abstract": "大型语言模型(LLM)是强大的工具，能够利用自然语言的训练写故事、生成代码和回答问题。但它们能否生成功能性的视频游戏关卡呢？游戏关卡由于功能约束和多维空间关系的复杂性，与LLM在训练期间通常看到的数据种类非常不同。游戏关卡的数据集也很难获得，可能会耗尽这些对数据有强烈需求的模型的能力。我们研究了使用LLMs生成Sokoban游戏关卡，并发现LLMs确实能够实现这一点，并且它的性能随着数据集大小的增加而大幅提高。我们还进行了初步的实验来控制LLM关卡生成器，并讨论了未来工作的有前途的领域。",
    "tldr": "该研究探讨了使用大型语言模型(LLMs)生成Sokoban游戏关卡，并发现随着数据集大小的增加，LLMs的性能得到了很大的提高。未来工作的前景也被讨论了。"
}