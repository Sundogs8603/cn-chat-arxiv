{
    "title": "Training neural networks with structured noise improves classification and generalization. (arXiv:2302.13417v3 [cond-mat.dis-nn] UPDATED)",
    "abstract": "The beneficial role of noise in learning is nowadays a consolidated concept in the field of artificial neural networks, suggesting that even biological systems might take advantage of similar mechanisms to maximize their performance. The training-with-noise algorithm proposed by Gardner and collaborators is an emblematic example of a noise injection procedure in recurrent networks, which are usually employed to model real neural systems. We show how adding structure into noisy training data can substantially improve the algorithm performance, allowing to approach perfect classification and maximal basins of attraction. We also prove that the so-called Hebbian unlearning rule coincides with the training-with-noise algorithm when noise is maximal and data are fixed points of the network dynamics. A sampling scheme for optimal noisy data is eventually proposed and implemented to outperform both the training-with-noise and the Hebbian unlearning procedures.",
    "link": "http://arxiv.org/abs/2302.13417",
    "context": "Title: Training neural networks with structured noise improves classification and generalization. (arXiv:2302.13417v3 [cond-mat.dis-nn] UPDATED)\nAbstract: The beneficial role of noise in learning is nowadays a consolidated concept in the field of artificial neural networks, suggesting that even biological systems might take advantage of similar mechanisms to maximize their performance. The training-with-noise algorithm proposed by Gardner and collaborators is an emblematic example of a noise injection procedure in recurrent networks, which are usually employed to model real neural systems. We show how adding structure into noisy training data can substantially improve the algorithm performance, allowing to approach perfect classification and maximal basins of attraction. We also prove that the so-called Hebbian unlearning rule coincides with the training-with-noise algorithm when noise is maximal and data are fixed points of the network dynamics. A sampling scheme for optimal noisy data is eventually proposed and implemented to outperform both the training-with-noise and the Hebbian unlearning procedures.",
    "path": "papers/23/02/2302.13417.json",
    "total_tokens": 841,
    "translated_title": "通过结构化噪声训练神经网络提高分类和泛化能力。",
    "translated_abstract": "噪声在学习中的积极作用是人工神经网络领域中一个已经被确认的概念，这表明甚至生物系统可能利用类似的机制来最大化性能。Gardner和合作者提出的噪声训练算法是在循环网络中注入噪声的典型示例，循环网络通常用于建模真实神经系统。我们展示了在噪声训练数据中添加结构可以显着提高算法性能，使得可以接近完美分类和最大吸引域。我们还证明了所谓的赫布生规则在噪声达到最大且数据是网络动力学的固定点时与噪声训练算法一致。最后，我们提出并实施了一种用于最佳噪声数据的采样策略，来超越噪声训练和赫布生规则的性能。",
    "tldr": "通过在训练数据中添加结构化噪声，可以显著提高神经网络的分类和泛化能力，并提出了一种采样策略来优于传统的训练和赫布生规则方法。",
    "en_tdlr": "Adding structured noise to training data significantly improves the classification and generalization ability of neural networks. A sampling strategy is also proposed to outperform traditional training methods and Hebbian unlearning rule."
}