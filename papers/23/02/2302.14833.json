{
    "title": "Learning to Control Autonomous Fleets from Observation via Offline Reinforcement Learning. (arXiv:2302.14833v2 [eess.SY] UPDATED)",
    "abstract": "Autonomous Mobility-on-Demand (AMoD) systems are an evolving mode of transportation in which a centrally coordinated fleet of self-driving vehicles dynamically serves travel requests. The control of these systems is typically formulated as a large network optimization problem, and reinforcement learning (RL) has recently emerged as a promising approach to solve the open challenges in this space. Recent centralized RL approaches focus on learning from online data, ignoring the per-sample-cost of interactions within real-world transportation systems. To address these limitations, we propose to formalize the control of AMoD systems through the lens of offline reinforcement learning and learn effective control strategies using solely offline data, which is readily available to current mobility operators. We further investigate design decisions and provide empirical evidence based on data from real-world mobility systems showing how offline learning allows to recover AMoD control policies t",
    "link": "http://arxiv.org/abs/2302.14833",
    "context": "Title: Learning to Control Autonomous Fleets from Observation via Offline Reinforcement Learning. (arXiv:2302.14833v2 [eess.SY] UPDATED)\nAbstract: Autonomous Mobility-on-Demand (AMoD) systems are an evolving mode of transportation in which a centrally coordinated fleet of self-driving vehicles dynamically serves travel requests. The control of these systems is typically formulated as a large network optimization problem, and reinforcement learning (RL) has recently emerged as a promising approach to solve the open challenges in this space. Recent centralized RL approaches focus on learning from online data, ignoring the per-sample-cost of interactions within real-world transportation systems. To address these limitations, we propose to formalize the control of AMoD systems through the lens of offline reinforcement learning and learn effective control strategies using solely offline data, which is readily available to current mobility operators. We further investigate design decisions and provide empirical evidence based on data from real-world mobility systems showing how offline learning allows to recover AMoD control policies t",
    "path": "papers/23/02/2302.14833.json",
    "total_tokens": 892,
    "translated_title": "通过离线强化学习从观察中学习控制自主机群",
    "translated_abstract": "自主移动出行（AMoD）系统是一种不断发展的交通方式，其中由中央协调的自动驾驶车辆组成的车队动态地提供出行服务。这些系统的控制通常被形式化为一个大规模网络优化问题，而强化学习（RL）最近被提出作为解决该领域的挑战的有希望的方法。最近的集中式RL方法关注在线学习数据，忽视了实际交通系统中每个样本交互的成本。为了解决这些限制，我们提出通过离线强化学习的视角来形式化AMoD系统的控制，并仅使用可用于当前出行运营商的离线数据学习有效的控制策略。我们进一步研究设计决策，并基于真实出行系统的数据提供了实证证据，展示了离线学习如何恢复AMoD控制策略。",
    "tldr": "本文提出了通过离线强化学习从观察中学习控制自主机群，并利用离线数据学习有效控制策略的方法。通过在真实出行系统数据上的实证研究，展示了离线学习恢复AMoD控制策略的能力。",
    "en_tdlr": "This paper proposes a method of learning to control autonomous fleets from observation via offline reinforcement learning, and learning effective control strategies using offline data. The empirical evidence from real-world mobility systems demonstrates the capability of offline learning to recover AMoD control policies."
}