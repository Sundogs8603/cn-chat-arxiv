{
    "title": "The Meta-Evaluation Problem in Explainable AI: Identifying Reliable Estimators with MetaQuantus. (arXiv:2302.07265v2 [cs.LG] UPDATED)",
    "abstract": "One of the unsolved challenges in the field of Explainable AI (XAI) is determining how to most reliably estimate the quality of an explanation method in the absence of ground truth explanation labels. Resolving this issue is of utmost importance as the evaluation outcomes generated by competing evaluation methods (or ''quality estimators''), which aim at measuring the same property of an explanation method, frequently present conflicting rankings. Such disagreements can be challenging for practitioners to interpret, thereby complicating their ability to select the best-performing explanation method. We address this problem through a meta-evaluation of different quality estimators in XAI, which we define as ''the process of evaluating the evaluation method''. Our novel framework, MetaQuantus, analyses two complementary performance characteristics of a quality estimator: its resilience to noise and reactivity to randomness, thus circumventing the need for ground truth labels. We demonstr",
    "link": "http://arxiv.org/abs/2302.07265",
    "context": "Title: The Meta-Evaluation Problem in Explainable AI: Identifying Reliable Estimators with MetaQuantus. (arXiv:2302.07265v2 [cs.LG] UPDATED)\nAbstract: One of the unsolved challenges in the field of Explainable AI (XAI) is determining how to most reliably estimate the quality of an explanation method in the absence of ground truth explanation labels. Resolving this issue is of utmost importance as the evaluation outcomes generated by competing evaluation methods (or ''quality estimators''), which aim at measuring the same property of an explanation method, frequently present conflicting rankings. Such disagreements can be challenging for practitioners to interpret, thereby complicating their ability to select the best-performing explanation method. We address this problem through a meta-evaluation of different quality estimators in XAI, which we define as ''the process of evaluating the evaluation method''. Our novel framework, MetaQuantus, analyses two complementary performance characteristics of a quality estimator: its resilience to noise and reactivity to randomness, thus circumventing the need for ground truth labels. We demonstr",
    "path": "papers/23/02/2302.07265.json",
    "total_tokens": 955,
    "translated_title": "在可解释人工智能中的元评估问题：使用MetaQuantus识别可靠的估计器",
    "translated_abstract": "在可解释人工智能（XAI）领域中，确定在没有真实解释标签的情况下最可靠地估算解释方法的质量是一个尚未解决的挑战。解决这个问题至关重要，因为竞争评估方法（或“质量估计器”）生成的评估结果，旨在衡量解释方法的相同性质，经常呈现出不一致的排名。这样的分歧对于实践者来说很难解释，从而使他们难以选择表现最好的解释方法。我们通过对XAI中的不同质量估计器进行元评估（\"评估评估方法的过程\"）来解决这个问题。我们的新框架MetaQuantus分析了质量估计器的两个互补性性能特征：对噪声的韧性和对随机性的反应，从而避免了对真实标签的需求。",
    "tldr": "这项研究解决了可解释人工智能领域中关于在缺乏真实解释标签的情况下如何可靠估算解释方法质量的问题。通过对不同质量估计器进行元评估，利用MetaQuantus框架分析了估计器的韧性和反应特征，从而帮助实践者选择最佳的解释方法。"
}