{
    "title": "A Modern Look at the Relationship between Sharpness and Generalization. (arXiv:2302.07011v2 [cs.LG] UPDATED)",
    "abstract": "Sharpness of minima is a promising quantity that can correlate with generalization in deep networks and, when optimized during training, can improve generalization. However, standard sharpness is not invariant under reparametrizations of neural networks, and, to fix this, reparametrization-invariant sharpness definitions have been proposed, most prominently adaptive sharpness (Kwon et al., 2021). But does it really capture generalization in modern practical settings? We comprehensively explore this question in a detailed study of various definitions of adaptive sharpness in settings ranging from training from scratch on ImageNet and CIFAR-10 to fine-tuning CLIP on ImageNet and BERT on MNLI. We focus mostly on transformers for which little is known in terms of sharpness despite their widespread usage. Overall, we observe that sharpness does not correlate well with generalization but rather with some training parameters like the learning rate that can be positively or negatively correlat",
    "link": "http://arxiv.org/abs/2302.07011",
    "context": "Title: A Modern Look at the Relationship between Sharpness and Generalization. (arXiv:2302.07011v2 [cs.LG] UPDATED)\nAbstract: Sharpness of minima is a promising quantity that can correlate with generalization in deep networks and, when optimized during training, can improve generalization. However, standard sharpness is not invariant under reparametrizations of neural networks, and, to fix this, reparametrization-invariant sharpness definitions have been proposed, most prominently adaptive sharpness (Kwon et al., 2021). But does it really capture generalization in modern practical settings? We comprehensively explore this question in a detailed study of various definitions of adaptive sharpness in settings ranging from training from scratch on ImageNet and CIFAR-10 to fine-tuning CLIP on ImageNet and BERT on MNLI. We focus mostly on transformers for which little is known in terms of sharpness despite their widespread usage. Overall, we observe that sharpness does not correlate well with generalization but rather with some training parameters like the learning rate that can be positively or negatively correlat",
    "path": "papers/23/02/2302.07011.json",
    "total_tokens": 798,
    "translated_title": "尖度与泛化关系的现代研究",
    "translated_abstract": "尖度是一种有希望与深度网络泛化相关的量，当在训练过程中优化时，可以改善泛化能力。然而，标准尖度并不是神经网络重参数化不变的，并因此提出了重参数化不变尖度定义，最著名的是自适应尖度。本文全面探索各种自适应尖度定义在从头开始训练Imagenet和CIFAR-10到微调Imagenet和MNLI的CLIP和BERT的各种设置中的泛化性能。我们主要关注变形器，尽管它们被广泛使用，但对其尖度的了解仍很有限。总体而言，我们观察到尖度与泛化关系不大，而与一些训练参数（如学习率）呈正相关或负相关。",
    "tldr": "研究表明，尖度与泛化关系并不密切相关，而与某些训练参数呈正相关或负相关。",
    "en_tdlr": "The study shows that sharpness is not strongly correlated with generalization, but rather with some training parameters, such as learning rate, that can be positively or negatively correlated."
}