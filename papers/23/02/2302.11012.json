{
    "title": "Likelihood Annealing: Fast Calibrated Uncertainty for Regression. (arXiv:2302.11012v2 [cs.LG] UPDATED)",
    "abstract": "Recent advances in deep learning have shown that uncertainty estimation is becoming increasingly important in applications such as medical imaging, natural language processing, and autonomous systems. However, accurately quantifying uncertainty remains a challenging problem, especially in regression tasks where the output space is continuous. Deep learning approaches that allow uncertainty estimation for regression problems often converge slowly and yield poorly calibrated uncertainty estimates that can not be effectively used for quantification. Recently proposed post hoc calibration techniques are seldom applicable to regression problems and often add overhead to an already slow model training phase. This work presents a fast calibrated uncertainty estimation method for regression tasks called Likelihood Annealing, that consistently improves the convergence of deep regression models and yields calibrated uncertainty without any post hoc calibration phase. Unlike previous methods for ",
    "link": "http://arxiv.org/abs/2302.11012",
    "context": "Title: Likelihood Annealing: Fast Calibrated Uncertainty for Regression. (arXiv:2302.11012v2 [cs.LG] UPDATED)\nAbstract: Recent advances in deep learning have shown that uncertainty estimation is becoming increasingly important in applications such as medical imaging, natural language processing, and autonomous systems. However, accurately quantifying uncertainty remains a challenging problem, especially in regression tasks where the output space is continuous. Deep learning approaches that allow uncertainty estimation for regression problems often converge slowly and yield poorly calibrated uncertainty estimates that can not be effectively used for quantification. Recently proposed post hoc calibration techniques are seldom applicable to regression problems and often add overhead to an already slow model training phase. This work presents a fast calibrated uncertainty estimation method for regression tasks called Likelihood Annealing, that consistently improves the convergence of deep regression models and yields calibrated uncertainty without any post hoc calibration phase. Unlike previous methods for ",
    "path": "papers/23/02/2302.11012.json",
    "total_tokens": 850,
    "translated_title": "可用于回归的快速校准不确定性的似然退火方法",
    "translated_abstract": "近年来，深度学习的发展表明，不确定性估计在医学影像、自然语言处理和自主系统等应用中变得越来越重要。然而，准确量化不确定性仍然是一个具有挑战性的问题，特别是在输出空间连续的回归任务中。允许回归问题进行不确定性估计的深度学习方法通常收敛速度较慢，并产生不良校准的不确定性估计，不能有效用于量化。最近提出的事后校准技术很少适用于回归问题，并且常常给已经较慢的模型训练阶段增加了额外开销。本文提出了一种用于回归任务的快速校准不确定性估计方法，称为似然退火，它能够持续改进深度回归模型的收敛性，并在没有任何事后校准阶段的情况下产生校准的不确定性。",
    "tldr": "该论文提出了一种名为似然退火的快速校准回归任务不确定性估计方法，能够改进深度回归模型的收敛性并产生校准的不确定性估计。",
    "en_tdlr": "This paper presents a method called Likelihood Annealing, which is a fast calibrated uncertainty estimation approach for regression tasks. It improves the convergence of deep regression models and yields calibrated uncertainty estimates without any post hoc calibration phase."
}