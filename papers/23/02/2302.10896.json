{
    "title": "IB-RAR: Information Bottleneck as Regularizer for Adversarial Robustness. (arXiv:2302.10896v2 [cs.LG] UPDATED)",
    "abstract": "In this paper, we propose a novel method, IB-RAR, which uses Information Bottleneck (IB) to strengthen adversarial robustness for both adversarial training and non-adversarial-trained methods. We first use the IB theory to build regularizers as learning objectives in the loss function. Then, we filter out unnecessary features of intermediate representation according to their mutual information (MI) with labels, as the network trained with IB provides easily distinguishable MI for its features. Experimental results show that our method can be naturally combined with adversarial training and provides consistently better accuracy on new adversarial examples. Our method improves the accuracy by an average of 3.07% against five adversarial attacks for the VGG16 network, trained with three adversarial training benchmarks and the CIFAR-10 dataset. In addition, our method also provides good robustness for undefended methods, such as training with cross-entropy loss only. Finally, in the absenc",
    "link": "http://arxiv.org/abs/2302.10896",
    "context": "Title: IB-RAR: Information Bottleneck as Regularizer for Adversarial Robustness. (arXiv:2302.10896v2 [cs.LG] UPDATED)\nAbstract: In this paper, we propose a novel method, IB-RAR, which uses Information Bottleneck (IB) to strengthen adversarial robustness for both adversarial training and non-adversarial-trained methods. We first use the IB theory to build regularizers as learning objectives in the loss function. Then, we filter out unnecessary features of intermediate representation according to their mutual information (MI) with labels, as the network trained with IB provides easily distinguishable MI for its features. Experimental results show that our method can be naturally combined with adversarial training and provides consistently better accuracy on new adversarial examples. Our method improves the accuracy by an average of 3.07% against five adversarial attacks for the VGG16 network, trained with three adversarial training benchmarks and the CIFAR-10 dataset. In addition, our method also provides good robustness for undefended methods, such as training with cross-entropy loss only. Finally, in the absenc",
    "path": "papers/23/02/2302.10896.json",
    "total_tokens": 984,
    "translated_title": "IB-RAR：信息瓶颈作为对抗性鲁棒性的正则化方法",
    "translated_abstract": "本文提出了一种新颖的方法IB-RAR，利用信息瓶颈（IB）来增强对抗性训练和非对抗性训练方法的对抗性鲁棒性。首先，本文使用IB理论在损失函数中构建正则化器作为学习目标。然后，根据中间表示与标签之间的互信息（MI）过滤掉不必要的特征，因为使用IB训练的网络提供易于区分的MI特征。实验结果表明，我们的方法可以自然地与对抗性训练相结合，并在新的对抗性例子上提供始终更好的准确性。我们的方法在针对VGG16网络进行三次对抗性训练基准和CIFAR-10数据集的五种对抗性攻击方案中，平均提高了3.07％的准确率。此外，我们的方法也为无防御方法提供了良好的鲁棒性，例如仅使用交叉熵损失进行训练。最后，在无人干预的情况下，我们的方法可以在处理缺失标签的情况下提供更好的学习效果。",
    "tldr": "本文提出了一种名为IB-RAR的正则化方法，利用信息瓶颈来增强对抗性训练和非对抗性训练方法的鲁棒性，并通过过滤不必要的特征来提高准确性。",
    "en_tdlr": "The paper proposes a novel regularizer method called IB-RAR, which uses Information Bottleneck (IB) to enhance adversarial robustness for both adversarial and non-adversarial training methods. The method filters out unnecessary features and improves accuracy by an average of 3.07% against five adversarial attacks for the VGG16 network."
}