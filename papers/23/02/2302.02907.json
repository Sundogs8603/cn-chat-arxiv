{
    "title": "GAT: Guided Adversarial Training with Pareto-optimal Auxiliary Tasks. (arXiv:2302.02907v2 [cs.CV] UPDATED)",
    "abstract": "While leveraging additional training data is well established to improve adversarial robustness, it incurs the unavoidable cost of data collection and the heavy computation to train models. To mitigate the costs, we propose Guided Adversarial Training (GAT), a novel adversarial training technique that exploits auxiliary tasks under a limited set of training data. Our approach extends single-task models into multi-task models during the min-max optimization of adversarial training, and drives the loss optimization with a regularization of the gradient curvature across multiple tasks. GAT leverages two types of auxiliary tasks: self-supervised tasks, where the labels are generated automatically, and domain-knowledge tasks, where human experts provide additional labels. Experimentally, GAT increases the robust AUC of CheXpert medical imaging dataset from 50% to 83% and On CIFAR-10, GAT outperforms eight state-of-the-art adversarial training and achieves 56.21% robust accuracy with Resnet-",
    "link": "http://arxiv.org/abs/2302.02907",
    "context": "Title: GAT: Guided Adversarial Training with Pareto-optimal Auxiliary Tasks. (arXiv:2302.02907v2 [cs.CV] UPDATED)\nAbstract: While leveraging additional training data is well established to improve adversarial robustness, it incurs the unavoidable cost of data collection and the heavy computation to train models. To mitigate the costs, we propose Guided Adversarial Training (GAT), a novel adversarial training technique that exploits auxiliary tasks under a limited set of training data. Our approach extends single-task models into multi-task models during the min-max optimization of adversarial training, and drives the loss optimization with a regularization of the gradient curvature across multiple tasks. GAT leverages two types of auxiliary tasks: self-supervised tasks, where the labels are generated automatically, and domain-knowledge tasks, where human experts provide additional labels. Experimentally, GAT increases the robust AUC of CheXpert medical imaging dataset from 50% to 83% and On CIFAR-10, GAT outperforms eight state-of-the-art adversarial training and achieves 56.21% robust accuracy with Resnet-",
    "path": "papers/23/02/2302.02907.json",
    "total_tokens": 930,
    "translated_title": "GAT：带 Pareto 最优辅助任务的引导式对抗训练",
    "translated_abstract": "在提高对抗鲁棒性方面，利用额外的训练数据是确立的好方法，但是它要付出数据收集的不可避免的代价和训练模型的重计算成本。为了减少这些成本，我们提出了 Guided Adversarial Training (GAT)，这是一种利用有限的训练数据进行的新型对抗训练技术，它利用辅助任务。在对抗训练的极小化最大化优化中，我们的方法将单任务模型扩展为多任务模型，并通过跨多个任务的梯度曲率的正则化来驱动损失优化。GAT利用了两种类型的辅助任务：自监督任务，其中标签是自动生成的，和领域知识任务，其中人类专家提供额外的标签。在实验中，GAT将 CheXpert 医学成像数据集的鲁棒性 AUC 从50% 提高到83%，在 CIFAR-10 上，GAT 超过了八种最先进的对抗性训练方法，使用Resnet可以达到56.21% 的鲁棒准确性。",
    "tldr": "本文介绍了一种新的对抗训练技术——Guided Adversarial Training (GAT)，它可以在有限的训练数据下利用辅助任务提高模型对抗鲁棒性。",
    "en_tdlr": "This paper introduces a novel adversarial training technique, Guided Adversarial Training (GAT), which exploits auxiliary tasks under a limited set of training data to improve model's adversarial robustness."
}