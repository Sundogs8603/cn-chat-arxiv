{
    "title": "VLSP2022-EVJVQA Challenge: Multilingual Visual Question Answering. (arXiv:2302.11752v4 [cs.CL] UPDATED)",
    "abstract": "Visual Question Answering (VQA) is a challenging task of natural language processing (NLP) and computer vision (CV), attracting significant attention from researchers. English is a resource-rich language that has witnessed various developments in datasets and models for visual question answering. Visual question answering in other languages also would be developed for resources and models. In addition, there is no multilingual dataset targeting the visual content of a particular country with its own objects and cultural characteristics. To address the weakness, we provide the research community with a benchmark dataset named EVJVQA, including 33,000+ pairs of question-answer over three languages: Vietnamese, English, and Japanese, on approximately 5,000 images taken from Vietnam for evaluating multilingual VQA systems or models. EVJVQA is used as a benchmark dataset for the challenge of multilingual visual question answering at the 9th Workshop on Vietnamese Language and Speech Process",
    "link": "http://arxiv.org/abs/2302.11752",
    "context": "Title: VLSP2022-EVJVQA Challenge: Multilingual Visual Question Answering. (arXiv:2302.11752v4 [cs.CL] UPDATED)\nAbstract: Visual Question Answering (VQA) is a challenging task of natural language processing (NLP) and computer vision (CV), attracting significant attention from researchers. English is a resource-rich language that has witnessed various developments in datasets and models for visual question answering. Visual question answering in other languages also would be developed for resources and models. In addition, there is no multilingual dataset targeting the visual content of a particular country with its own objects and cultural characteristics. To address the weakness, we provide the research community with a benchmark dataset named EVJVQA, including 33,000+ pairs of question-answer over three languages: Vietnamese, English, and Japanese, on approximately 5,000 images taken from Vietnam for evaluating multilingual VQA systems or models. EVJVQA is used as a benchmark dataset for the challenge of multilingual visual question answering at the 9th Workshop on Vietnamese Language and Speech Process",
    "path": "papers/23/02/2302.11752.json",
    "total_tokens": 888,
    "translated_title": "VLSP2022-EVJVQA挑战：多语种视觉问答",
    "translated_abstract": "视觉问答（VQA）是自然语言处理（NLP）和计算机视觉（CV）的一个具有挑战性的任务，吸引了研究人员的重视。 英语是一个资源丰富的语言，在视觉问答的数据集和模型方面有着各种发展。 其他语言的视觉问答也将会有资源和模型的发展。 此外，还没有针对特定国家的视觉内容和文化特点提供多语言数据集。为了解决这些问题，我们提供了一个名为EVJVQA的基准数据集，包括在越南拍摄的约5,000张图片上的三种语言（越南语，英语和日语）的33,000多对问答对，以评估多语言VQA系统或模型。 EVJVQA作为挑战多语种视觉问答的基准数据集，在第9届越南语言和语音处理研讨会（VLSP2022）上使用。",
    "tldr": "该论文介绍了一个新的多语种视觉问答数据集EVJVQA，包括越南语，英语和日语的33,000+问答对，可用于评估多语言VQA系统或模型的性能。"
}