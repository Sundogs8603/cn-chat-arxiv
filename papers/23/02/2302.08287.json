{
    "title": "Unsupervised Evaluation of Out-of-distribution Detection: A Data-centric Perspective. (arXiv:2302.08287v2 [cs.CV] UPDATED)",
    "abstract": "Out-of-distribution (OOD) detection methods assume that they have test ground truths, i.e., whether individual test samples are in-distribution (IND) or OOD. However, in the real world, we do not always have such ground truths, and thus do not know which sample is correctly detected and cannot compute the metric like AUROC to evaluate the performance of different OOD detection methods. In this paper, we are the first to introduce the unsupervised evaluation problem in OOD detection, which aims to evaluate OOD detection methods in real-world changing environments without OOD labels. We propose three methods to compute Gscore as an unsupervised indicator of OOD detection performance. We further introduce a new benchmark Gbench, which has 200 real-world OOD datasets of various label spaces to train and evaluate our method. Through experiments, we find a strong quantitative correlation betwwen Gscore and the OOD detection performance. Extensive experiments demonstrate that our Gscore achie",
    "link": "http://arxiv.org/abs/2302.08287",
    "context": "Title: Unsupervised Evaluation of Out-of-distribution Detection: A Data-centric Perspective. (arXiv:2302.08287v2 [cs.CV] UPDATED)\nAbstract: Out-of-distribution (OOD) detection methods assume that they have test ground truths, i.e., whether individual test samples are in-distribution (IND) or OOD. However, in the real world, we do not always have such ground truths, and thus do not know which sample is correctly detected and cannot compute the metric like AUROC to evaluate the performance of different OOD detection methods. In this paper, we are the first to introduce the unsupervised evaluation problem in OOD detection, which aims to evaluate OOD detection methods in real-world changing environments without OOD labels. We propose three methods to compute Gscore as an unsupervised indicator of OOD detection performance. We further introduce a new benchmark Gbench, which has 200 real-world OOD datasets of various label spaces to train and evaluate our method. Through experiments, we find a strong quantitative correlation betwwen Gscore and the OOD detection performance. Extensive experiments demonstrate that our Gscore achie",
    "path": "papers/23/02/2302.08287.json",
    "total_tokens": 909,
    "translated_title": "无监督评估外部分布检测：基于数据的视角",
    "translated_abstract": "外部分布检测需要确定测试样本属于内部分布还是外部分布，但现实中我们并不总是拥有这些测试数据的真实标签。本文首次提出了一种无监督评估外部分布检测方法的问题，并提出了三种计算Gscore的方法，作为衡量无监督测试的性能指标。我们还引入了一个名为Gbench的新基准测试数据集，该数据集包含200个真实世界的外部分布数据集，用于训练和评估我们的方法。通过实验，我们发现Gscore与外部分布检测性能之间存在较强的定量相关性。大量实验证明，与AUROC等监督评估方法相比，我们的Gscore的结果一致且具有竞争力，并且可以作为一个实用的有效评估方法用于无监督环境下的外部分布检测。",
    "tldr": "本文提出了一种无监督评估外部分布检测方法的问题，并提出了一种基于Gscore的有效性指标，这对于没有真实标签的测试时可作为实用的评估方法。",
    "en_tdlr": "This paper introduces the unsupervised evaluation problem in OOD detection and proposes a Gscore-based evaluation method that can serve as a practical and effective approach for evaluation in testing without true labels. The paper also presents a new benchmark dataset and demonstrates the effectiveness of Gscore compared to supervised metrics such as AUROC."
}