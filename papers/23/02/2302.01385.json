{
    "title": "Hyper-parameter Tuning for Fair Classification without Sensitive Attribute Access",
    "abstract": "arXiv:2302.01385v2 Announce Type: replace-cross  Abstract: Fair machine learning methods seek to train models that balance model performance across demographic subgroups defined over sensitive attributes like race and gender. Although sensitive attributes are typically assumed to be known during training, they may not be available in practice due to privacy and other logistical concerns. Recent work has sought to train fair models without sensitive attributes on training data. However, these methods need extensive hyper-parameter tuning to achieve good results, and hence assume that sensitive attributes are known on validation data. However, this assumption too might not be practical. Here, we propose Antigone, a framework to train fair classifiers without access to sensitive attributes on either training or validation data. Instead, we generate pseudo sensitive attributes on the validation data by training a biased classifier and using the classifier's incorrectly (correctly) labeled ",
    "link": "https://arxiv.org/abs/2302.01385",
    "context": "Title: Hyper-parameter Tuning for Fair Classification without Sensitive Attribute Access\nAbstract: arXiv:2302.01385v2 Announce Type: replace-cross  Abstract: Fair machine learning methods seek to train models that balance model performance across demographic subgroups defined over sensitive attributes like race and gender. Although sensitive attributes are typically assumed to be known during training, they may not be available in practice due to privacy and other logistical concerns. Recent work has sought to train fair models without sensitive attributes on training data. However, these methods need extensive hyper-parameter tuning to achieve good results, and hence assume that sensitive attributes are known on validation data. However, this assumption too might not be practical. Here, we propose Antigone, a framework to train fair classifiers without access to sensitive attributes on either training or validation data. Instead, we generate pseudo sensitive attributes on the validation data by training a biased classifier and using the classifier's incorrectly (correctly) labeled ",
    "path": "papers/23/02/2302.01385.json",
    "total_tokens": 826,
    "translated_title": "无需访问敏感属性的公平分类超参数调整",
    "translated_abstract": "公平的机器学习方法旨在训练能够在基于种族和性别等敏感属性定义的人口统计亚组之间平衡模型性能的模型。然而，在训练期间通常假定敏感属性已知，但由于隐私和其他后勤方面的考虑，实践中可能无法获取这些属性。最近的研究致力于在训练数据上没有敏感属性的情况下训练公平模型。然而，这些方法需要进行大量的超参数调整才能获得良好结果，因此假设在验证数据上已知敏感属性。然而，这种假设在实践中也可能不切实际。因此，在这里，我们提出了Antigone，这是一个框架，可以在训练数据或验证数据中都无需访问敏感属性即可训练公平的分类器。相反，我们通过训练有偏见的分类器并使用分类器错误（正确）标记的方式在验证数据上生成伪敏感属性。",
    "tldr": "提出了Antigone框架，可以在训练数据或验证数据中都无需访问敏感属性即可训练公平的分类器，通过生成伪敏感属性来实现。",
    "en_tdlr": "Proposed the Antigone framework for training fair classifiers without access to sensitive attributes in either training or validation data by generating pseudo sensitive attributes."
}