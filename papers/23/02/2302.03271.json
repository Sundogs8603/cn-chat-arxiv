{
    "title": "IB-UQ: Information bottleneck based uncertainty quantification for neural function regression and neural operator learning. (arXiv:2302.03271v2 [math.NA] UPDATED)",
    "abstract": "We propose a novel framework for uncertainty quantification via information bottleneck (IB-UQ) for scientific machine learning tasks, including deep neural network (DNN) regression and neural operator learning (DeepONet). Specifically, we incorporate the bottleneck by a confidence-aware encoder, which encodes inputs into latent representations according to the confidence of the input data belonging to the region where training data is located, and utilize a Gaussian decoder to predict means and variances of outputs conditional on representation variables. Furthermore, we propose a data augmentation based information bottleneck objective which can enhance the quantification quality of the extrapolation uncertainty, and the encoder and decoder can be both trained by minimizing a tractable variational bound of the objective. In comparison to uncertainty quantification (UQ) methods for scientific learning tasks that rely on Bayesian neural networks with Hamiltonian Monte Carlo posterior es",
    "link": "http://arxiv.org/abs/2302.03271",
    "context": "Title: IB-UQ: Information bottleneck based uncertainty quantification for neural function regression and neural operator learning. (arXiv:2302.03271v2 [math.NA] UPDATED)\nAbstract: We propose a novel framework for uncertainty quantification via information bottleneck (IB-UQ) for scientific machine learning tasks, including deep neural network (DNN) regression and neural operator learning (DeepONet). Specifically, we incorporate the bottleneck by a confidence-aware encoder, which encodes inputs into latent representations according to the confidence of the input data belonging to the region where training data is located, and utilize a Gaussian decoder to predict means and variances of outputs conditional on representation variables. Furthermore, we propose a data augmentation based information bottleneck objective which can enhance the quantification quality of the extrapolation uncertainty, and the encoder and decoder can be both trained by minimizing a tractable variational bound of the objective. In comparison to uncertainty quantification (UQ) methods for scientific learning tasks that rely on Bayesian neural networks with Hamiltonian Monte Carlo posterior es",
    "path": "papers/23/02/2302.03271.json",
    "total_tokens": 942,
    "translated_title": "基于信息瓶颈的神经函数回归和神经操作器学习的不确定性量化",
    "translated_abstract": "我们提出了一种新的不确定性量化框架IB-UQ，用于科学机器学习任务，包括深度神经网络（DNN）回归和神经操作器学习（DeepONet）。特别地，我们通过自信感知的编码器加入了瓶颈，该编码器根据输入数据属于训练数据所在区域的可信度将输入编码为潜在表示，并利用高斯解码器条件地预测输出的均值和方差。此外，我们提出了一种基于数据增强的信息瓶颈目标，可以增强外推不确定性的量化质量，并且编码器和解码器都可以通过最小化该目标的可计算变分下界来进行训练。与依赖于哈密尔顿蒙特卡罗后验估计的贝叶斯神经网络的不确定性量化（UQ）方法相比，我们提出的IB-UQ框架提供了一种更有效和可扩展的方法，用于量化具有可比较准确度的预测不确定性。",
    "tldr": "我们提出了基于信息瓶颈的不确定性量化框架IB-UQ，用于深度学习任务，在回归和操作器学习中提供了一种更有效和可扩展的量化预测不确定性的方法。",
    "en_tdlr": "We propose a novel IB-UQ framework for uncertainty quantification in scientific machine learning tasks, including DNN regression and DeepONet, which offers a more efficient and scalable method for quantifying predictive uncertainties in comparison to Bayesian neural networks with HMC posterior estimates."
}