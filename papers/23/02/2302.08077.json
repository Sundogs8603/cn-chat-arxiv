{
    "title": "Group Fairness with Uncertainty in Sensitive Attributes. (arXiv:2302.08077v2 [cs.LG] UPDATED)",
    "abstract": "Learning a fair predictive model is crucial to mitigate biased decisions against minority groups in high-stakes applications. A common approach to learn such a model involves solving an optimization problem that maximizes the predictive power of the model under an appropriate group fairness constraint. However, in practice, sensitive attributes are often missing or noisy resulting in uncertainty. We demonstrate that solely enforcing fairness constraints on uncertain sensitive attributes can fall significantly short in achieving the level of fairness of models trained without uncertainty. To overcome this limitation, we propose a bootstrap-based algorithm that achieves the target level of fairness despite the uncertainty in sensitive attributes. The algorithm is guided by a Gaussian analysis for the independence notion of fairness where we propose a robust quadratically constrained quadratic problem to ensure a strict fairness guarantee with uncertain sensitive attributes. Our algorithm",
    "link": "http://arxiv.org/abs/2302.08077",
    "context": "Title: Group Fairness with Uncertainty in Sensitive Attributes. (arXiv:2302.08077v2 [cs.LG] UPDATED)\nAbstract: Learning a fair predictive model is crucial to mitigate biased decisions against minority groups in high-stakes applications. A common approach to learn such a model involves solving an optimization problem that maximizes the predictive power of the model under an appropriate group fairness constraint. However, in practice, sensitive attributes are often missing or noisy resulting in uncertainty. We demonstrate that solely enforcing fairness constraints on uncertain sensitive attributes can fall significantly short in achieving the level of fairness of models trained without uncertainty. To overcome this limitation, we propose a bootstrap-based algorithm that achieves the target level of fairness despite the uncertainty in sensitive attributes. The algorithm is guided by a Gaussian analysis for the independence notion of fairness where we propose a robust quadratically constrained quadratic problem to ensure a strict fairness guarantee with uncertain sensitive attributes. Our algorithm",
    "path": "papers/23/02/2302.08077.json",
    "total_tokens": 923,
    "translated_title": "带有敏感属性不确定性的群体公平性",
    "translated_abstract": "在高风险应用中，学习一个公平的预测模型对于减少针对少数群体的有偏决策至关重要。学习这样一个模型的常见方法是解决一个优化问题，该问题在适当的群体公平性约束下最大化模型的预测能力。然而，在实际应用中，敏感属性通常会缺失或存在噪声，从而导致不确定性。我们证明，仅在不确定的敏感属性上实施公平约束可能无法实现训练时没有不确定性的模型所达到的公平水平。为了克服这个限制，我们提出了一种基于自助法的算法，该算法在存在敏感属性不确定性的情况下实现了目标的公平水平。该算法通过高斯分析进行引导，实现“独立概念”的公平性，我们提出了一个鲁棒的二次约束二次问题，以确保具有不确定敏感属性的严格公平性保证。我们在一个真实的信用贷款数据集上评估了我们的算法，结果显示出当敏感属性存在不确定性时，它优于现有的公平学习算法。",
    "tldr": "该论文提出了一种基于自助法的算法来解决存在敏感属性不确定性的群体公平性问题，该算法在真实的信用贷款数据集上表现出优异的性能。"
}