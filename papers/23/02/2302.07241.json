{
    "title": "ConceptFusion: Open-set Multimodal 3D Mapping. (arXiv:2302.07241v3 [cs.CV] UPDATED)",
    "abstract": "Building 3D maps of the environment is central to robot navigation, planning, and interaction with objects in a scene. Most existing approaches that integrate semantic concepts with 3D maps largely remain confined to the closed-set setting: they can only reason about a finite set of concepts, pre-defined at training time. Further, these maps can only be queried using class labels, or in recent work, using text prompts.  We address both these issues with ConceptFusion, a scene representation that is (1) fundamentally open-set, enabling reasoning beyond a closed set of concepts and (ii) inherently multimodal, enabling a diverse range of possible queries to the 3D map, from language, to images, to audio, to 3D geometry, all working in concert. ConceptFusion leverages the open-set capabilities of today's foundation models pre-trained on internet-scale data to reason about concepts across modalities such as natural language, images, and audio. We demonstrate that pixel-aligned open-set feat",
    "link": "http://arxiv.org/abs/2302.07241",
    "context": "Title: ConceptFusion: Open-set Multimodal 3D Mapping. (arXiv:2302.07241v3 [cs.CV] UPDATED)\nAbstract: Building 3D maps of the environment is central to robot navigation, planning, and interaction with objects in a scene. Most existing approaches that integrate semantic concepts with 3D maps largely remain confined to the closed-set setting: they can only reason about a finite set of concepts, pre-defined at training time. Further, these maps can only be queried using class labels, or in recent work, using text prompts.  We address both these issues with ConceptFusion, a scene representation that is (1) fundamentally open-set, enabling reasoning beyond a closed set of concepts and (ii) inherently multimodal, enabling a diverse range of possible queries to the 3D map, from language, to images, to audio, to 3D geometry, all working in concert. ConceptFusion leverages the open-set capabilities of today's foundation models pre-trained on internet-scale data to reason about concepts across modalities such as natural language, images, and audio. We demonstrate that pixel-aligned open-set feat",
    "path": "papers/23/02/2302.07241.json",
    "total_tokens": 931,
    "translated_title": "ConceptFusion：开放集合多模态三维建图",
    "translated_abstract": "构建环境的三维地图对机器人导航、规划和与场景中的物体交互至关重要。大多数现有的将语义概念与三维地图集成的方法主要局限于封闭集合的设定：它们只能推理出一个在训练时预定义的有限概念集。此外，这些地图只能使用类别标签或最近的工作中，使用文本提示来查询。我们通过ConceptFusion解决了这两个问题，这是一种场景表示，它既是基本的开放集合，可以在封闭的概念集之外进行推理，又是固有的多模态，可以在语言、图像、音频和三维几何等多种查询方式下使用三维地图。ConceptFusion利用了当今在互联网规模数据上预训练的基础模型的开放集合能力，可以推理各种跨模态的概念，如自然语言、图像和音频。我们证明了像素对齐的开放集合特征的能力，并在几个实际任务中展示了ConceptFusion的鲁棒性。",
    "tldr": "ConceptFusion是一种开放集合的多模态三维建图方法，能够超越封闭集合的概念，同时支持从语言、图像、音频和三维几何等多种方式查询三维地图。"
}