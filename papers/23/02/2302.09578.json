{
    "title": "On Feasibility of Server-side Backdoor Attacks on Split Learning. (arXiv:2302.09578v2 [cs.CR] UPDATED)",
    "abstract": "Split learning is a collaborative learning design that allows several participants (clients) to train a shared model while keeping their datasets private. Recent studies demonstrate that collaborative learning models, specifically federated learning, are vulnerable to security and privacy attacks such as model inference and backdoor attacks. Backdoor attacks are a group of poisoning attacks in which the attacker tries to control the model output by manipulating the model's training process. While there have been studies regarding inference attacks on split learning, it has not yet been tested for backdoor attacks. This paper performs a novel backdoor attack on split learning and studies its effectiveness. Despite traditional backdoor attacks done on the client side, we inject the backdoor trigger from the server side. For this purpose, we provide two attack methods: one using a surrogate client and another using an autoencoder to poison the model via incoming smashed data and its outgo",
    "link": "http://arxiv.org/abs/2302.09578",
    "context": "Title: On Feasibility of Server-side Backdoor Attacks on Split Learning. (arXiv:2302.09578v2 [cs.CR] UPDATED)\nAbstract: Split learning is a collaborative learning design that allows several participants (clients) to train a shared model while keeping their datasets private. Recent studies demonstrate that collaborative learning models, specifically federated learning, are vulnerable to security and privacy attacks such as model inference and backdoor attacks. Backdoor attacks are a group of poisoning attacks in which the attacker tries to control the model output by manipulating the model's training process. While there have been studies regarding inference attacks on split learning, it has not yet been tested for backdoor attacks. This paper performs a novel backdoor attack on split learning and studies its effectiveness. Despite traditional backdoor attacks done on the client side, we inject the backdoor trigger from the server side. For this purpose, we provide two attack methods: one using a surrogate client and another using an autoencoder to poison the model via incoming smashed data and its outgo",
    "path": "papers/23/02/2302.09578.json",
    "total_tokens": 1022,
    "translated_title": "关于在服务器端进行分割学习后门攻击的可行性研究",
    "translated_abstract": "分割学习是一种协作学习设计，允许多个参与者（客户端）训练共享模型同时保持其数据集私有。最近的研究表明，协作学习模型，特别是联邦学习，容易受到安全和隐私攻击，例如模型推断和后门攻击。后门攻击是一种毒化攻击，攻击者试图通过操纵模型的训练过程来控制模型输出。虽然已经有了关于分割学习推断攻击的研究，但还没有进行过后门攻击的测试。本文对分割学习进行了一种新颖的后门攻击，并研究了其有效性。尽管传统的后门攻击是在客户端上完成的，但我们从服务器端注入后门触发器。为此，我们提供了两种攻击方法：一种是使用代理客户端，另一种是使用自编码器通过传入的破碎数据及其传出的梯度毒化模型。我们的实验结果表明，即使有多个客户端参与学习且具有不同的数据分布，这两种方法都非常有效。这项工作强调了进一步研究在服务器端进行分割学习后门攻击的必要性。",
    "tldr": "本文研究了在服务器端进行分割学习后门攻击的可行性，提供了两种攻击方法，并证明其即使在多个客户端参与学习且具有不同的数据分布时也是有效的。",
    "en_tdlr": "This paper investigates the feasibility of server-side backdoor attacks on split learning, provides two attack methods through injecting a backdoor trigger from the server-side, and demonstrates their effectiveness even in the presence of multiple clients with different data distributions."
}