{
    "title": "Multimodality Representation Learning: A Survey on Evolution, Pretraining and Its Applications",
    "abstract": "arXiv:2302.00389v2 Announce Type: replace  Abstract: Multimodality Representation Learning, as a technique of learning to embed information from different modalities and their correlations, has achieved remarkable success on a variety of applications, such as Visual Question Answering (VQA), Natural Language for Visual Reasoning (NLVR), and Vision Language Retrieval (VLR). Among these applications, cross-modal interaction and complementary information from different modalities are crucial for advanced models to perform any multimodal task, e.g., understand, recognize, retrieve, or generate optimally. Researchers have proposed diverse methods to address these tasks. The different variants of transformer-based architectures performed extraordinarily on multiple modalities. This survey presents the comprehensive literature on the evolution and enhancement of deep learning multimodal architectures to deal with textual, visual and audio features for diverse cross-modal and modern multimodal",
    "link": "https://arxiv.org/abs/2302.00389",
    "context": "Title: Multimodality Representation Learning: A Survey on Evolution, Pretraining and Its Applications\nAbstract: arXiv:2302.00389v2 Announce Type: replace  Abstract: Multimodality Representation Learning, as a technique of learning to embed information from different modalities and their correlations, has achieved remarkable success on a variety of applications, such as Visual Question Answering (VQA), Natural Language for Visual Reasoning (NLVR), and Vision Language Retrieval (VLR). Among these applications, cross-modal interaction and complementary information from different modalities are crucial for advanced models to perform any multimodal task, e.g., understand, recognize, retrieve, or generate optimally. Researchers have proposed diverse methods to address these tasks. The different variants of transformer-based architectures performed extraordinarily on multiple modalities. This survey presents the comprehensive literature on the evolution and enhancement of deep learning multimodal architectures to deal with textual, visual and audio features for diverse cross-modal and modern multimodal",
    "path": "papers/23/02/2302.00389.json",
    "total_tokens": 823,
    "translated_title": "多模态表示学习：演进、预训练及其应用的调查",
    "translated_abstract": "多模态表示学习作为一种学习将来自不同模态及其相关性的信息嵌入的技术，在诸如视觉问答（VQA）、视觉推理的自然语言（NLVR）和视觉语言检索（VLR）等各种应用上取得了显著成功。在这些应用中，来自不同模态的跨模态交互和补充信息对于先进模型执行任何多模态任务（如理解、识别、检索或生成）至关重要。研究人员提出了各种方法来解决这些任务。基于变压器的不同变体架构在多个模态上表现出色。本调查对深度学习多模态架构的演变和增强进行了全面综述，以处理文本、视觉和音频特征，以应对多样的跨模态和现代多模态挑战。",
    "tldr": "多模态表示学习涉及学习将不同模态信息嵌入并处理跨模态任务，在不同应用上取得显著成功，研究人员提出多种方法来实现这一目标。",
    "en_tdlr": "Multimodality Representation Learning involves embedding information from different modalities and handling cross-modal tasks, achieving notable success in various applications, with researchers proposing diverse methods to achieve this goal."
}