{
    "title": "Language Model Analysis for Ontology Subsumption Inference. (arXiv:2302.06761v2 [cs.CL] UPDATED)",
    "abstract": "Investigating whether pre-trained language models (LMs) can function as knowledge bases (KBs) has raised wide research interests recently. However, existing works focus on simple, triple-based, relational KBs, but omit more sophisticated, logic-based, conceptualised KBs such as OWL ontologies. To investigate an LM's knowledge of ontologies, we propose OntoLAMA, a set of inference-based probing tasks and datasets from ontology subsumption axioms involving both atomic and complex concepts. We conduct extensive experiments on ontologies of different domains and scales, and our results demonstrate that LMs encode relatively less background knowledge of Subsumption Inference (SI) than traditional Natural Language Inference (NLI) but can improve on SI significantly when a small number of samples are given. We will open-source our code and datasets.",
    "link": "http://arxiv.org/abs/2302.06761",
    "context": "Title: Language Model Analysis for Ontology Subsumption Inference. (arXiv:2302.06761v2 [cs.CL] UPDATED)\nAbstract: Investigating whether pre-trained language models (LMs) can function as knowledge bases (KBs) has raised wide research interests recently. However, existing works focus on simple, triple-based, relational KBs, but omit more sophisticated, logic-based, conceptualised KBs such as OWL ontologies. To investigate an LM's knowledge of ontologies, we propose OntoLAMA, a set of inference-based probing tasks and datasets from ontology subsumption axioms involving both atomic and complex concepts. We conduct extensive experiments on ontologies of different domains and scales, and our results demonstrate that LMs encode relatively less background knowledge of Subsumption Inference (SI) than traditional Natural Language Inference (NLI) but can improve on SI significantly when a small number of samples are given. We will open-source our code and datasets.",
    "path": "papers/23/02/2302.06761.json",
    "total_tokens": 893,
    "translated_title": "语言模型分析本体子类推断",
    "translated_abstract": "最近，研究人员开始探究预训练的语言模型是否能够作为知识库的替代。然而，现有的研究都关注于简单的三元组关系型知识库，忽略了更为复杂、逻辑为基础、概念化的 OWL 本体等知识库。为了研究语言模型对于本体的了解，我们提出 OntoLAMA，它包含基于推理的一系列测试任务和数据集，从涉及原子概念和复合概念的子类推断公理出发。我们对不同领域和规模的本体进行了大量实验，结果表明，相比传统的自然语言推理，语言模型对子类推断的背景知识记忆相对较少，但是在给定少量样本的情况下，可以显著提高子类推断的准确率。我们将公开源码和数据集。",
    "tldr": "本文研究了语言模型对本体子类推断的理解能力，提出了一套涉及原子概念和复合概念的推理任务，并证明语言模型对子类推断背景知识的记忆相对较少，但在给定少量样本的情况下可显著提高准确率。",
    "en_tdlr": "This paper investigates pre-trained language models' ability to understand ontology subsumption, proposes a set of probing tasks and datasets, and shows that while language models encode relatively less background knowledge of subsumption inference than natural language inference, they can significantly improve accuracy with only a small number of samples."
}