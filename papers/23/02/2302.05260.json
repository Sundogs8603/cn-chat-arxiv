{
    "title": "Policy Learning with Rare Outcomes. (arXiv:2302.05260v2 [econ.EM] UPDATED)",
    "abstract": "Machine learning (ML) estimates of conditional average treatment effects (CATE) can guide policy decisions, either by allowing targeting of individuals with beneficial CATE estimates, or as inputs to decision trees that optimise overall outcomes. There is limited information available regarding how well these algorithms perform in real-world policy evaluation scenarios. Using synthetic data, we compare the finite sample performance of different policy learning algorithms, machine learning techniques employed during their learning phases, and methods for presenting estimated policy values. For each algorithm, we assess the resulting treatment allocation by measuring deviation from the ideal (\"oracle\") policy. Our main finding is that policy trees based on estimated CATEs outperform trees learned from doubly-robust scores. Across settings, Causal Forests and the Normalised Double-Robust Learner perform consistently well, while Bayesian Additive Regression Trees perform poorly. These meth",
    "link": "http://arxiv.org/abs/2302.05260",
    "context": "Title: Policy Learning with Rare Outcomes. (arXiv:2302.05260v2 [econ.EM] UPDATED)\nAbstract: Machine learning (ML) estimates of conditional average treatment effects (CATE) can guide policy decisions, either by allowing targeting of individuals with beneficial CATE estimates, or as inputs to decision trees that optimise overall outcomes. There is limited information available regarding how well these algorithms perform in real-world policy evaluation scenarios. Using synthetic data, we compare the finite sample performance of different policy learning algorithms, machine learning techniques employed during their learning phases, and methods for presenting estimated policy values. For each algorithm, we assess the resulting treatment allocation by measuring deviation from the ideal (\"oracle\") policy. Our main finding is that policy trees based on estimated CATEs outperform trees learned from doubly-robust scores. Across settings, Causal Forests and the Normalised Double-Robust Learner perform consistently well, while Bayesian Additive Regression Trees perform poorly. These meth",
    "path": "papers/23/02/2302.05260.json",
    "total_tokens": 889,
    "translated_title": "稀有结果的政策学习",
    "translated_abstract": "机器学习（ML）对条件平均处理效应（CATE）的估计可以指导政策决策，可以通过允许将有益的CATE估计应用于个体，或者作为决策树的输入，优化总体结果。关于这些算法在实际政策评估场景中的表现如何的信息有限。使用合成数据，我们比较了不同政策学习算法的有限样本性能，以及在学习阶段中使用的机器学习技术和展示估计政策价值的方法。对于每个算法，我们通过衡量与理想（“神谕”）政策的偏差来评估得到的处理分配。我们的主要发现是基于估计CATE的政策树优于从双重鲁棒得分学习的树。在各种设置中，因果森林和标准化双重鲁棒学习器的表现一直很好，而贝叶斯加性回归树的表现较差。",
    "tldr": "在政策学习中，使用估计的条件平均处理效应（CATE）的政策树优于使用双重鲁棒得分学习的树，因果森林和标准化双重鲁棒学习器在各种设置下的表现较好。",
    "en_tdlr": "Policy trees based on estimated conditional average treatment effects (CATE) outperform trees learned from doubly-robust scores in policy learning. Causal Forests and the Normalised Double-Robust Learner consistently perform well across settings."
}