{
    "title": "Private GANs, Revisited. (arXiv:2302.02936v2 [cs.LG] UPDATED)",
    "abstract": "We show that the canonical approach for training differentially private GANs -- updating the discriminator with differentially private stochastic gradient descent (DPSGD) -- can yield significantly improved results after modifications to training. Specifically, we propose that existing instantiations of this approach neglect to consider how adding noise only to discriminator updates inhibits discriminator training, disrupting the balance between the generator and discriminator necessary for successful GAN training. We show that a simple fix -- taking more discriminator steps between generator steps -- restores parity between the generator and discriminator and improves results.  Additionally, with the goal of restoring parity, we experiment with other modifications -- namely, large batch sizes and adaptive discriminator update frequency -- to improve discriminator training and see further improvements in generation quality. Our results demonstrate that on standard image synthesis bench",
    "link": "http://arxiv.org/abs/2302.02936",
    "context": "Title: Private GANs, Revisited. (arXiv:2302.02936v2 [cs.LG] UPDATED)\nAbstract: We show that the canonical approach for training differentially private GANs -- updating the discriminator with differentially private stochastic gradient descent (DPSGD) -- can yield significantly improved results after modifications to training. Specifically, we propose that existing instantiations of this approach neglect to consider how adding noise only to discriminator updates inhibits discriminator training, disrupting the balance between the generator and discriminator necessary for successful GAN training. We show that a simple fix -- taking more discriminator steps between generator steps -- restores parity between the generator and discriminator and improves results.  Additionally, with the goal of restoring parity, we experiment with other modifications -- namely, large batch sizes and adaptive discriminator update frequency -- to improve discriminator training and see further improvements in generation quality. Our results demonstrate that on standard image synthesis bench",
    "path": "papers/23/02/2302.02936.json",
    "total_tokens": 871,
    "translated_title": "重新审视私有GANs",
    "translated_abstract": "我们表明，在训练差分隐私GANs的经典方法中，通过对鉴别器使用差分隐私随机梯度下降（DPSGD）进行更新，在改进训练后可以获得显著改善的结果。具体地，我们提出现有实施该方法的论述忽视了对鉴别器更新添加噪声如何阻碍鉴别器训练，破坏了生成器和鉴别器之间成功训练GAN所必需的平衡。我们展示了一个简单的修复方法——在生成器步骤之间进行更多的鉴别器步骤——可以恢复生成器和鉴别器之间的平等，并改善结果。此外，为了恢复平等，我们尝试了其他修改——即较大的批处理大小和自适应的鉴别器更新频率——以改善鉴别器训练，并在生成质量上进一步改善。我们的结果表明，在标准图像合成基准测试上，我们的方法在生成图像的质量和多样性方面优于现有方法。",
    "tldr": "在训练差分隐私GANs时，通过对鉴别器进行一些修改和优化，如增加鉴别器的训练步骤和使用较大的批处理大小等，可以显著提高GAN的训练结果和生成质量。"
}