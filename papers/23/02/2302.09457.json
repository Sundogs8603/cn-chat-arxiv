{
    "title": "Attacks in Adversarial Machine Learning: A Systematic Survey from the Life-cycle Perspective. (arXiv:2302.09457v2 [cs.LG] UPDATED)",
    "abstract": "Adversarial machine learning (AML) studies the adversarial phenomenon of machine learning, which may make inconsistent or unexpected predictions with humans. Some paradigms have been recently developed to explore this adversarial phenomenon occurring at different stages of a machine learning system, such as backdoor attack occurring at the pre-training, in-training and inference stage; weight attack occurring at the post-training, deployment and inference stage; adversarial attack occurring at the inference stage. However, although these adversarial paradigms share a common goal, their developments are almost independent, and there is still no big picture of AML. In this work, we aim to provide a unified perspective to the AML community to systematically review the overall progress of this field. We firstly provide a general definition about AML, and then propose a unified mathematical framework to covering existing attack paradigms. According to the proposed unified framework, we buil",
    "link": "http://arxiv.org/abs/2302.09457",
    "context": "Title: Attacks in Adversarial Machine Learning: A Systematic Survey from the Life-cycle Perspective. (arXiv:2302.09457v2 [cs.LG] UPDATED)\nAbstract: Adversarial machine learning (AML) studies the adversarial phenomenon of machine learning, which may make inconsistent or unexpected predictions with humans. Some paradigms have been recently developed to explore this adversarial phenomenon occurring at different stages of a machine learning system, such as backdoor attack occurring at the pre-training, in-training and inference stage; weight attack occurring at the post-training, deployment and inference stage; adversarial attack occurring at the inference stage. However, although these adversarial paradigms share a common goal, their developments are almost independent, and there is still no big picture of AML. In this work, we aim to provide a unified perspective to the AML community to systematically review the overall progress of this field. We firstly provide a general definition about AML, and then propose a unified mathematical framework to covering existing attack paradigms. According to the proposed unified framework, we buil",
    "path": "papers/23/02/2302.09457.json",
    "total_tokens": 867,
    "translated_title": "对抗机器学习中的攻击：从生命周期角度的系统性调查",
    "translated_abstract": "对抗性机器学习（AML）研究机器学习中的对抗现象，这些现象可能与人类的预测不一致或出乎意料。最近已经开发了一些范式来探索发生在机器学习系统不同阶段的对抗现象，例如在预训练、训练和推断阶段发生的后门攻击；在后训练、部署和推断阶段发生的权重攻击；在推断阶段发生的对抗攻击。然而，尽管这些对抗范式有着共同的目标，但它们的发展几乎是独立的，对于AML领域仍然没有完整的整体认知。本文旨在为AML社区提供一个统一的视角，系统地回顾该领域的整体进展。我们首先提供了关于AML的通用定义，然后提出了一个统一的数学框架，以涵盖现有的攻击范式。",
    "tldr": "本研究通过对抗机器学习中攻击现象的生命周期角度进行系统调查，提供一种统一的视角和数学框架，总结整体进展。"
}