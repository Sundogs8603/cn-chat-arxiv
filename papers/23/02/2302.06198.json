{
    "title": "Distinguishability Calibration to In-Context Learning. (arXiv:2302.06198v2 [cs.CL] UPDATED)",
    "abstract": "Recent years have witnessed increasing interests in prompt-based learning in which models can be trained on only a few annotated instances, making them suitable in low-resource settings. When using prompt-based learning for text classification, the goal is to use a pre-trained language model (PLM) to predict a missing token in a pre-defined template given an input text, which can be mapped to a class label. However, PLMs built on the transformer architecture tend to generate similar output embeddings, making it difficult to discriminate between different class labels. The problem is further exacerbated when dealing with classification tasks involving many fine-grained class labels. In this work, we alleviate this information diffusion issue, i.e., different tokens share a large proportion of similar information after going through stacked multiple self-attention layers in a transformer, by proposing a calibration method built on feature transformations through rotation and scaling to m",
    "link": "http://arxiv.org/abs/2302.06198",
    "context": "Title: Distinguishability Calibration to In-Context Learning. (arXiv:2302.06198v2 [cs.CL] UPDATED)\nAbstract: Recent years have witnessed increasing interests in prompt-based learning in which models can be trained on only a few annotated instances, making them suitable in low-resource settings. When using prompt-based learning for text classification, the goal is to use a pre-trained language model (PLM) to predict a missing token in a pre-defined template given an input text, which can be mapped to a class label. However, PLMs built on the transformer architecture tend to generate similar output embeddings, making it difficult to discriminate between different class labels. The problem is further exacerbated when dealing with classification tasks involving many fine-grained class labels. In this work, we alleviate this information diffusion issue, i.e., different tokens share a large proportion of similar information after going through stacked multiple self-attention layers in a transformer, by proposing a calibration method built on feature transformations through rotation and scaling to m",
    "path": "papers/23/02/2302.06198.json",
    "total_tokens": 841,
    "translated_title": "区分度校准到上下文学习中的应用",
    "translated_abstract": "近年来，随着对基于提示的学习方法的兴趣增加，模型能够在少量标注实例上进行训练，使它们适用于低资源环境。使用基于提示的学习进行文本分类时，目标是使用预训练语言模型 (PLM) 来预测预定义模板中的缺失标记，并将其映射到类别标签。然而，基于转换器架构构建的 PLM 倾向于生成相似的输出嵌入，很难区分不同的类别标签。当处理涉及许多细粒度类别标签的分类任务时，这个问题会进一步加剧。本文通过提出基于特征旋转和缩放的校准方法来缓解这个信息扩散问题，即当不同的令牌经过转换器中堆叠的多个自注意层时，它们共享大量相似的信息。",
    "tldr": "本文提出了一种旋转和缩放的特征变换校准方法，可用于基于提示的学习进行文本分类，从而解决了在转换器中进行上下文学习时遇到的信息扩散问题。",
    "en_tdlr": "This paper proposes a feature transformation calibration method using rotation and scaling, which can be used for prompt-based learning in text classification, to alleviate the information diffusion issue when conducting in-context learning in transformers."
}