{
    "title": "Can we avoid Double Descent in Deep Neural Networks?. (arXiv:2302.13259v4 [cs.LG] UPDATED)",
    "abstract": "Finding the optimal size of deep learning models is very actual and of broad impact, especially in energy-saving schemes. Very recently, an unexpected phenomenon, the ``double descent'', has caught the attention of the deep learning community. As the model's size grows, the performance gets first worse, and then goes back to improving. It raises serious questions about the optimal model's size to maintain high generalization: the model needs to be sufficiently over-parametrized, but adding too many parameters wastes training resources. Is it possible to find, in an efficient way, the best trade-off? Our work shows that the double descent phenomenon is potentially avoidable with proper conditioning of the learning problem, but a final answer is yet to be found. We empirically observe that there is hope to dodge the double descent in complex scenarios with proper regularization, as a simple $\\ell_2$ regularization is already positively contributing to such a perspective.",
    "link": "http://arxiv.org/abs/2302.13259",
    "context": "Title: Can we avoid Double Descent in Deep Neural Networks?. (arXiv:2302.13259v4 [cs.LG] UPDATED)\nAbstract: Finding the optimal size of deep learning models is very actual and of broad impact, especially in energy-saving schemes. Very recently, an unexpected phenomenon, the ``double descent'', has caught the attention of the deep learning community. As the model's size grows, the performance gets first worse, and then goes back to improving. It raises serious questions about the optimal model's size to maintain high generalization: the model needs to be sufficiently over-parametrized, but adding too many parameters wastes training resources. Is it possible to find, in an efficient way, the best trade-off? Our work shows that the double descent phenomenon is potentially avoidable with proper conditioning of the learning problem, but a final answer is yet to be found. We empirically observe that there is hope to dodge the double descent in complex scenarios with proper regularization, as a simple $\\ell_2$ regularization is already positively contributing to such a perspective.",
    "path": "papers/23/02/2302.13259.json",
    "total_tokens": 869,
    "translated_title": "是否可以在深度神经网络中避免双下降？",
    "translated_abstract": "寻找深度学习模型的最优大小非常重要且具有广泛影响，尤其在节能方案中。最近，一个意外的现象，“双下降”，引起了深度学习界的关注。随着模型大小的增加，性能首先变差，然后恢复提升。这对于维持高泛化的最优模型大小提出了严重的问题：模型需要足够的超参数化，但添加过多的参数会浪费训练资源。是否可能以高效的方式找到最佳折衷方案？我们的工作表明，通过适当调整学习问题的条件，可能可以避免双下降现象，但最终答案仍待确定。我们经验地观察到，在复杂情况下，通过适当的正则化有望避开双下降，简单的$\\ell_2$正则化已经对此有积极的贡献。",
    "tldr": "这项研究表明，通过适当调整学习问题的条件，可以避免双下降现象，特别是在复杂情况下使用适当的正则化。这对于寻找深度学习模型的最优大小具有重要意义。"
}