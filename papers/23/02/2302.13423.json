{
    "title": "Sim-and-Real Reinforcement Learning for Manipulation: A Consensus-based Approach. (arXiv:2302.13423v2 [cs.RO] UPDATED)",
    "abstract": "Sim-and-real training is a promising alternative to sim-to-real training for robot manipulations. However, the current sim-and-real training is neither efficient, i.e., slow convergence to the optimal policy, nor effective, i.e., sizeable real-world robot data. Given limited time and hardware budgets, the performance of sim-and-real training is not satisfactory. In this paper, we propose a Consensus-based Sim-And-Real deep reinforcement learning algorithm (CSAR) for manipulator pick-and-place tasks, which shows comparable performance in both sim-and-real worlds. In this algorithm, we train the agents in simulators and the real world to get the optimal policies for both sim-and-real worlds. We found two interesting phenomenons: (1) Best policy in simulation is not the best for sim-and-real training. (2) The more simulation agents, the better sim-and-real training. The experimental video is available at: https://youtu.be/mcHJtNIsTEQ.",
    "link": "http://arxiv.org/abs/2302.13423",
    "context": "Title: Sim-and-Real Reinforcement Learning for Manipulation: A Consensus-based Approach. (arXiv:2302.13423v2 [cs.RO] UPDATED)\nAbstract: Sim-and-real training is a promising alternative to sim-to-real training for robot manipulations. However, the current sim-and-real training is neither efficient, i.e., slow convergence to the optimal policy, nor effective, i.e., sizeable real-world robot data. Given limited time and hardware budgets, the performance of sim-and-real training is not satisfactory. In this paper, we propose a Consensus-based Sim-And-Real deep reinforcement learning algorithm (CSAR) for manipulator pick-and-place tasks, which shows comparable performance in both sim-and-real worlds. In this algorithm, we train the agents in simulators and the real world to get the optimal policies for both sim-and-real worlds. We found two interesting phenomenons: (1) Best policy in simulation is not the best for sim-and-real training. (2) The more simulation agents, the better sim-and-real training. The experimental video is available at: https://youtu.be/mcHJtNIsTEQ.",
    "path": "papers/23/02/2302.13423.json",
    "total_tokens": 1015,
    "translated_title": "模拟与实际强化学习在操纵中的应用：一种基于共识的方法",
    "translated_abstract": "模拟与实际训练是机器人操纵的一种有希望的替代方案。然而，当前的模拟与实际训练既不高效（即收敛到最优策略较慢），也不有效（即真实世界机器人数据较少）。考虑到有限的时间和硬件预算，模拟与实际训练的性能不尽如人意。本文提出一种基于共识的模拟与实际深度强化学习算法 (CSAR)，用于操纵器人的挑选和放置任务，该算法在模拟和实际世界中都表现出可比较的性能。在这个算法中，我们通过在模拟器和真实世界中训练智能体来获得模拟和实际世界的最优策略。我们发现了两个有趣的现象：（1）在模拟中的最佳策略并不是模拟与实际训练的最佳策略。（2）模拟智能体越多，模拟与实际训练效果越好。",
    "tldr": "本文提出了一种基于共识的模拟与实际深度强化学习算法，该算法在机器人操纵中表现出可比较的性能，并发现了在模拟中的最佳策略不一定适用于模拟与实际训练，以及模拟智能体数量越多，模拟与实际训练效果越好。"
}