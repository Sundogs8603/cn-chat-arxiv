{
    "title": "BiasTestGPT: Using ChatGPT for Social Bias Testing of Language Models. (arXiv:2302.07371v2 [cs.CL] UPDATED)",
    "abstract": "Pretrained Language Models (PLMs) harbor inherent social biases that can result in harmful real-world implications. Such social biases are measured through the probability values that PLMs output for different social groups and attributes appearing in a set of test sentences. However, bias testing is currently cumbersome since the test sentences are generated either from a limited set of manual templates or need expensive crowd-sourcing. We instead propose using ChatGPT for controllable generation of test sentences, given any arbitrary user-specified combination of social groups and attributes appearing in the test sentences. When compared to template-based methods, our approach using ChatGPT for test sentence generation is superior in detecting social bias, especially in challenging settings such as intersectional biases. We present an open-source comprehensive bias testing framework (BiasTestGPT), hosted on HuggingFace, that can be plugged into any open-source PLM for bias testing. W",
    "link": "http://arxiv.org/abs/2302.07371",
    "context": "Title: BiasTestGPT: Using ChatGPT for Social Bias Testing of Language Models. (arXiv:2302.07371v2 [cs.CL] UPDATED)\nAbstract: Pretrained Language Models (PLMs) harbor inherent social biases that can result in harmful real-world implications. Such social biases are measured through the probability values that PLMs output for different social groups and attributes appearing in a set of test sentences. However, bias testing is currently cumbersome since the test sentences are generated either from a limited set of manual templates or need expensive crowd-sourcing. We instead propose using ChatGPT for controllable generation of test sentences, given any arbitrary user-specified combination of social groups and attributes appearing in the test sentences. When compared to template-based methods, our approach using ChatGPT for test sentence generation is superior in detecting social bias, especially in challenging settings such as intersectional biases. We present an open-source comprehensive bias testing framework (BiasTestGPT), hosted on HuggingFace, that can be plugged into any open-source PLM for bias testing. W",
    "path": "papers/23/02/2302.07371.json",
    "total_tokens": 867,
    "translated_title": "BiasTestGPT: 使用ChatGPT对语言模型进行社会偏见测试",
    "translated_abstract": "预训练语言模型（PLMs）存在固有的社会偏见，可能导致有害的现实影响。这种社会偏见是通过PLMs对一组测试句子中不同社会群体和属性的概率值进行测量得出的。然而，目前的偏见测试方法非常繁琐，因为测试句子要么是从有限的一组手动模板中生成，要么需要昂贵的众包。我们提出使用ChatGPT进行可控生成测试句子，以满足用户指定的任意社会群体和属性组合。与基于模板的方法相比，我们使用ChatGPT进行测试句子生成的方法在检测社会偏见方面更为优越，特别是在交叉偏见等具有挑战性的情境中。我们提供了一个开源的全面偏见测试框架（BiasTestGPT），托管在HuggingFace上，可以插入到任何开源PLM中进行偏见测试。",
    "tldr": "BiasTestGPT是一个开源的偏见测试框架，利用ChatGPT进行测试句子的生成，可以更好地检测语言模型中的社会偏见，尤其是在交叉偏见等挑战性情境中。",
    "en_tdlr": "BiasTestGPT is an open-source bias testing framework that utilizes ChatGPT for generating test sentences, providing better detection of social biases in language models, especially in challenging settings such as intersectional biases."
}