{
    "title": "XploreNAS: Explore Adversarially Robust & Hardware-efficient Neural Architectures for Non-ideal Xbars. (arXiv:2302.07769v2 [cs.LG] UPDATED)",
    "abstract": "Compute In-Memory platforms such as memristive crossbars are gaining focus as they facilitate acceleration of Deep Neural Networks (DNNs) with high area and compute-efficiencies. However, the intrinsic non-idealities associated with the analog nature of computing in crossbars limits the performance of the deployed DNNs. Furthermore, DNNs are shown to be vulnerable to adversarial attacks leading to severe security threats in their large-scale deployment. Thus, finding adversarially robust DNN architectures for non-ideal crossbars is critical to the safe and secure deployment of DNNs on the edge. This work proposes a two-phase algorithm-hardware co-optimization approach called XploreNAS that searches for hardware-efficient & adversarially robust neural architectures for non-ideal crossbar platforms. We use the one-shot Neural Architecture Search (NAS) approach to train a large Supernet with crossbar-awareness and sample adversarially robust Subnets therefrom, maintaining competitive hard",
    "link": "http://arxiv.org/abs/2302.07769",
    "context": "Title: XploreNAS: Explore Adversarially Robust & Hardware-efficient Neural Architectures for Non-ideal Xbars. (arXiv:2302.07769v2 [cs.LG] UPDATED)\nAbstract: Compute In-Memory platforms such as memristive crossbars are gaining focus as they facilitate acceleration of Deep Neural Networks (DNNs) with high area and compute-efficiencies. However, the intrinsic non-idealities associated with the analog nature of computing in crossbars limits the performance of the deployed DNNs. Furthermore, DNNs are shown to be vulnerable to adversarial attacks leading to severe security threats in their large-scale deployment. Thus, finding adversarially robust DNN architectures for non-ideal crossbars is critical to the safe and secure deployment of DNNs on the edge. This work proposes a two-phase algorithm-hardware co-optimization approach called XploreNAS that searches for hardware-efficient & adversarially robust neural architectures for non-ideal crossbar platforms. We use the one-shot Neural Architecture Search (NAS) approach to train a large Supernet with crossbar-awareness and sample adversarially robust Subnets therefrom, maintaining competitive hard",
    "path": "papers/23/02/2302.07769.json",
    "total_tokens": 1134,
    "translated_title": "XploreNAS：针对非理想交叉栏架构探索对抗性强和硬件高效的神经网络结构",
    "translated_abstract": "运用计算内存平台，如存储器性交叉栏架，可以加速深度神经网络（DNN）的计算量和效率，但由于计算中精度的不理想性，其性能受到一定限制。此外，DNN容易受到对抗攻击，这会导致在大规模部署DNN时存在严重的安全威胁。因此，为非理想交叉栏架构寻找对抗性强的DNN结构对于在边缘上安全地部署DNN至关重要。本文提出了一种名为XploreNAS的两阶段算法-硬件协同优化方法，该方法寻找适用于非理想交叉栏架构的硬件高效和对抗性强的神经网络结构。我们采用一次性神经网络结构搜索（NAS）方法训练一个具有交叉栏架构感知的大型超网络，并采样出具有对抗性强度的子网络，同时维持具有竞争性的硬件约束。实验结果表明，该方法在为非理想交叉栏架构的DNN实现硬件和对抗性的均衡发展方面具有良好的效果。",
    "tldr": "本文提出了一种名为XploreNAS的方法，该方法通过两阶段算法-硬件协同优化，针对非理想交叉栏架构探索对抗性强和硬件高效的神经网络结构，通过采样出具有对抗性强度的子网络，实现了在非理想性交叉栏架构下的硬件和对抗性的均衡发展。",
    "en_tdlr": "XploreNAS proposes a two-phase algorithm-hardware co-optimization approach, which explores adversarially robust and hardware-efficient neural architectures for non-ideal crossbar platforms. By using a one-shot NAS approach to train a large Supernet with crossbar-awareness and sampling adversarially robust subnets, it achieves a balance between hardware and adversarial robustness in DNNs for non-ideal crossbar platforms."
}