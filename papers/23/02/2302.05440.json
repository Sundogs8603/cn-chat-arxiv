{
    "title": "Forward Learning with Top-Down Feedback: Empirical and Analytical Characterization",
    "abstract": "arXiv:2302.05440v2 Announce Type: replace  Abstract: \"Forward-only\" algorithms, which train neural networks while avoiding a backward pass, have recently gained attention as a way of solving the biologically unrealistic aspects of backpropagation. Here, we first address compelling challenges related to the \"forward-only\" rules, which include reducing the performance gap with backpropagation and providing an analytical understanding of their dynamics. To this end, we show that the forward-only algorithm with top-down feedback is well-approximated by an \"adaptive-feedback-alignment\" algorithm, and we analytically track its performance during learning in a prototype high-dimensional setting. Then, we compare different versions of forward-only algorithms, focusing on the Forward-Forward and PEPITA frameworks, and we show that they share the same learning principles. Overall, our work unveils the connections between three key neuro-inspired learning rules, providing a link between \"forward-",
    "link": "https://arxiv.org/abs/2302.05440",
    "context": "Title: Forward Learning with Top-Down Feedback: Empirical and Analytical Characterization\nAbstract: arXiv:2302.05440v2 Announce Type: replace  Abstract: \"Forward-only\" algorithms, which train neural networks while avoiding a backward pass, have recently gained attention as a way of solving the biologically unrealistic aspects of backpropagation. Here, we first address compelling challenges related to the \"forward-only\" rules, which include reducing the performance gap with backpropagation and providing an analytical understanding of their dynamics. To this end, we show that the forward-only algorithm with top-down feedback is well-approximated by an \"adaptive-feedback-alignment\" algorithm, and we analytically track its performance during learning in a prototype high-dimensional setting. Then, we compare different versions of forward-only algorithms, focusing on the Forward-Forward and PEPITA frameworks, and we show that they share the same learning principles. Overall, our work unveils the connections between three key neuro-inspired learning rules, providing a link between \"forward-",
    "path": "papers/23/02/2302.05440.json",
    "total_tokens": 894,
    "translated_title": "具有自上而下反馈的前馈学习：实证和分析特性",
    "translated_abstract": "\"仅向前\"算法近来受到关注，这些算法在训练神经网络时避免了向后传递，被认为是解决反向传播中生物不现实因素的一种方法。本文首先针对与“仅向前”规则相关的引人注目的挑战，包括缩小与反向传播的性能差距和对其动态特性进行分析。我们展示了具有自上而下反馈的仅向前算法可被很好地近似为“自适应反馈对齐”算法，并在原型高维设置中对其学习过程进行了分析跟踪。然后，我们比较了不同版本的仅向前算法，重点关注前-前和PEPITA框架，并且表明它们共享相同的学习原理。总体而言，我们的工作揭示了三种重要的受神经启发的学习规则之间的联系，为“向前-",
    "tldr": "本研究揭示了具有自上而下反馈的前馈学习算法与自适应反馈对齐算法之间的联系，分析了它们在学习过程中的性能，并比较了不同版本的仅向前算法，揭示它们共享相同的学习原理。"
}