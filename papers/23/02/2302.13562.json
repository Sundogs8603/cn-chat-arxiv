{
    "title": "Communication-efficient Federated Learning with Single-Step Synthetic Features Compressor for Faster Convergence. (arXiv:2302.13562v2 [cs.LG] UPDATED)",
    "abstract": "Reducing communication overhead in federated learning (FL) is challenging but crucial for large-scale distributed privacy-preserving machine learning. While methods utilizing sparsification or others can largely lower the communication overhead, the convergence rate is also greatly compromised. In this paper, we propose a novel method, named single-step synthetic features compressor (3SFC), to achieve communication-efficient FL by directly constructing a tiny synthetic dataset based on raw gradients. Thus, 3SFC can achieve an extremely low compression rate when the constructed dataset contains only one data sample. Moreover, 3SFC's compressing phase utilizes a similarity-based objective function so that it can be optimized with just one step, thereby considerably improving its performance and robustness. In addition, to minimize the compressing error, error feedback (EF) is also incorporated into 3SFC. Experiments on multiple datasets and models suggest that 3SFC owns significantly bet",
    "link": "http://arxiv.org/abs/2302.13562",
    "context": "Title: Communication-efficient Federated Learning with Single-Step Synthetic Features Compressor for Faster Convergence. (arXiv:2302.13562v2 [cs.LG] UPDATED)\nAbstract: Reducing communication overhead in federated learning (FL) is challenging but crucial for large-scale distributed privacy-preserving machine learning. While methods utilizing sparsification or others can largely lower the communication overhead, the convergence rate is also greatly compromised. In this paper, we propose a novel method, named single-step synthetic features compressor (3SFC), to achieve communication-efficient FL by directly constructing a tiny synthetic dataset based on raw gradients. Thus, 3SFC can achieve an extremely low compression rate when the constructed dataset contains only one data sample. Moreover, 3SFC's compressing phase utilizes a similarity-based objective function so that it can be optimized with just one step, thereby considerably improving its performance and robustness. In addition, to minimize the compressing error, error feedback (EF) is also incorporated into 3SFC. Experiments on multiple datasets and models suggest that 3SFC owns significantly bet",
    "path": "papers/23/02/2302.13562.json",
    "total_tokens": 993,
    "tldr": "本文提出了一种单步合成特征压缩器(3SFC)的新方法来进行通信高效的联邦学习，通过直接构建微小的合成数据集并利用基于相似度的目标函数进行优化，在保证鲁棒性的同时极大地提高了性能，并在多个数据集和模型上的实验中取得了显著优势。"
}