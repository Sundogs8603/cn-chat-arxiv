{
    "title": "Side Adapter Network for Open-Vocabulary Semantic Segmentation. (arXiv:2302.12242v2 [cs.CV] UPDATED)",
    "abstract": "This paper presents a new framework for open-vocabulary semantic segmentation with the pre-trained vision-language model, named Side Adapter Network (SAN). Our approach models the semantic segmentation task as a region recognition problem. A side network is attached to a frozen CLIP model with two branches: one for predicting mask proposals, and the other for predicting attention bias which is applied in the CLIP model to recognize the class of masks. This decoupled design has the benefit CLIP in recognizing the class of mask proposals. Since the attached side network can reuse CLIP features, it can be very light. In addition, the entire network can be trained end-to-end, allowing the side network to be adapted to the frozen CLIP model, which makes the predicted mask proposals CLIP-aware. Our approach is fast, accurate, and only adds a few additional trainable parameters. We evaluate our approach on multiple semantic segmentation benchmarks. Our method significantly outperforms other c",
    "link": "http://arxiv.org/abs/2302.12242",
    "context": "Title: Side Adapter Network for Open-Vocabulary Semantic Segmentation. (arXiv:2302.12242v2 [cs.CV] UPDATED)\nAbstract: This paper presents a new framework for open-vocabulary semantic segmentation with the pre-trained vision-language model, named Side Adapter Network (SAN). Our approach models the semantic segmentation task as a region recognition problem. A side network is attached to a frozen CLIP model with two branches: one for predicting mask proposals, and the other for predicting attention bias which is applied in the CLIP model to recognize the class of masks. This decoupled design has the benefit CLIP in recognizing the class of mask proposals. Since the attached side network can reuse CLIP features, it can be very light. In addition, the entire network can be trained end-to-end, allowing the side network to be adapted to the frozen CLIP model, which makes the predicted mask proposals CLIP-aware. Our approach is fast, accurate, and only adds a few additional trainable parameters. We evaluate our approach on multiple semantic segmentation benchmarks. Our method significantly outperforms other c",
    "path": "papers/23/02/2302.12242.json",
    "total_tokens": 958,
    "translated_title": "Side Adapter Network用于开放词汇语义分割",
    "translated_abstract": "本文提出了一种新的开放词汇语义分割框架，利用预训练的视觉-语言模型命名为Side Adapter Network (SAN)。我们的方法将语义分割任务建模为区域识别问题，通过在冻结的CLIP模型上附加一个辅助网络来实现。该网络有两个分支：一个用于预测掩模提案，另一个用于预测注意偏差，该偏差应用于CLIP模型中来识别掩模的类别。这种分离的设计使得CLIP能够识别掩模提案的类别。由于辅助网络可以重用CLIP特征，因此它非常轻巧。此外，整个网络可以端到端地训练，使得辅助网络能够适应冻结的CLIP模型，从而使预测的掩模提案建立在CLIP的基础上。我们的方法快速、准确，仅增加了一些可训练参数。我们在多个语义分割基准测试上评估了我们的方法，结果表明我们的方法显着优于其他方法。",
    "tldr": "本文提出的Side Adapter Network框架采用冻结的CLIP模型和辅助网络来实现开放词汇语义分割任务，具有快速、准确和轻量级优势。该网络可以重用CLIP特征，仅增加少量可训练参数，显著优于其他方法。",
    "en_tdlr": "The Side Adapter Network framework proposed in this paper uses a frozen CLIP model and an auxiliary network to achieve open-vocabulary semantic segmentation task, which has the advantages of speed, accuracy and lightweight. The network can reuse CLIP features, adding only a few trainable parameters and significantly outperforms other methods."
}