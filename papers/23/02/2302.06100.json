{
    "title": "Can GPT-3 Perform Statutory Reasoning?. (arXiv:2302.06100v2 [cs.CL] UPDATED)",
    "abstract": "Statutory reasoning is the task of reasoning with facts and statutes, which are rules written in natural language by a legislature. It is a basic legal skill. In this paper we explore the capabilities of the most capable GPT-3 model, text-davinci-003, on an established statutory-reasoning dataset called SARA. We consider a variety of approaches, including dynamic few-shot prompting, chain-of-thought prompting, and zero-shot prompting. While we achieve results with GPT-3 that are better than the previous best published results, we also identify several types of clear errors it makes. We investigate why these errors happen. We discover that GPT-3 has imperfect prior knowledge of the actual U.S. statutes on which SARA is based. More importantly, we create simple synthetic statutes, which GPT-3 is guaranteed not to have seen during training. We find GPT-3 performs poorly at answering straightforward questions about these simple synthetic statutes.",
    "link": "http://arxiv.org/abs/2302.06100",
    "context": "Title: Can GPT-3 Perform Statutory Reasoning?. (arXiv:2302.06100v2 [cs.CL] UPDATED)\nAbstract: Statutory reasoning is the task of reasoning with facts and statutes, which are rules written in natural language by a legislature. It is a basic legal skill. In this paper we explore the capabilities of the most capable GPT-3 model, text-davinci-003, on an established statutory-reasoning dataset called SARA. We consider a variety of approaches, including dynamic few-shot prompting, chain-of-thought prompting, and zero-shot prompting. While we achieve results with GPT-3 that are better than the previous best published results, we also identify several types of clear errors it makes. We investigate why these errors happen. We discover that GPT-3 has imperfect prior knowledge of the actual U.S. statutes on which SARA is based. More importantly, we create simple synthetic statutes, which GPT-3 is guaranteed not to have seen during training. We find GPT-3 performs poorly at answering straightforward questions about these simple synthetic statutes.",
    "path": "papers/23/02/2302.06100.json",
    "total_tokens": 886,
    "translated_title": "GPT-3能进行法定推理吗？",
    "translated_abstract": "法定推理是一种利用事实和由立法机构用自然语言书写的规则（即法规）进行推理的基本法律技能。本文研究了最强大的GPT-3模型text-davinci-003在一个名为SARA的已建立的法定推理数据集上的能力。我们考虑了各种方法，包括动态少量示例提示、思维链提示和零样本提示。虽然我们取得了比先前最佳发表结果更好的GPT-3结果，但我们也确认了其出现了几种明显的错误。我们调查了这些错误的原因，并发现GPT-3对SARA基于实际美国法规的先验知识存在缺陷。更重要的是，我们创建了简单的合成法规，确保GPT-3在训练期间从未见过。我们发现GPT-3在回答关于这些简单合成法规的直截了当的问题时表现不佳。",
    "tldr": "本文研究了GPT-3在法定推理任务上的表现，并发现其表现优于之前最佳结果，但仍存在错误。研究还发现GPT-3对实际法规存在缺陷，且在对于合成法规的问题回答表现不佳。",
    "en_tdlr": "This paper examines the performance of GPT-3 on statutory reasoning, finding that while it performs better than previous models, it still makes errors and has imperfect knowledge of actual statutes. Additionally, it performs poorly on questions related to synthetic statutes."
}