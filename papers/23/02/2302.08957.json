{
    "title": "Like a Good Nearest Neighbor: Practical Content Moderation and Text Classification. (arXiv:2302.08957v3 [cs.CL] UPDATED)",
    "abstract": "Few-shot text classification systems have impressive capabilities but are infeasible to deploy and use reliably due to their dependence on prompting and billion-parameter language models. SetFit (Tunstall et al., 2022) is a recent, practical approach that fine-tunes a Sentence Transformer under a contrastive learning paradigm and achieves similar results to more unwieldy systems. Inexpensive text classification is important for addressing the problem of domain drift in all classification tasks, and especially in detecting harmful content, which plagues social media platforms. Here, we propose Like a Good Nearest Neighbor (LaGoNN), a modification to SetFit that introduces no learnable parameters but alters input text with information from its nearest neighbor, for example, the label and text, in the training data, making novel data appear similar to an instance on which the model was optimized. LaGoNN is effective at flagging undesirable content and text classification, and improves the",
    "link": "http://arxiv.org/abs/2302.08957",
    "context": "Title: Like a Good Nearest Neighbor: Practical Content Moderation and Text Classification. (arXiv:2302.08957v3 [cs.CL] UPDATED)\nAbstract: Few-shot text classification systems have impressive capabilities but are infeasible to deploy and use reliably due to their dependence on prompting and billion-parameter language models. SetFit (Tunstall et al., 2022) is a recent, practical approach that fine-tunes a Sentence Transformer under a contrastive learning paradigm and achieves similar results to more unwieldy systems. Inexpensive text classification is important for addressing the problem of domain drift in all classification tasks, and especially in detecting harmful content, which plagues social media platforms. Here, we propose Like a Good Nearest Neighbor (LaGoNN), a modification to SetFit that introduces no learnable parameters but alters input text with information from its nearest neighbor, for example, the label and text, in the training data, making novel data appear similar to an instance on which the model was optimized. LaGoNN is effective at flagging undesirable content and text classification, and improves the",
    "path": "papers/23/02/2302.08957.json",
    "total_tokens": 924,
    "translated_title": "如同一个好邻居：实用的内容审核和文本分类",
    "translated_abstract": "少样本文本分类系统具有令人印象深刻的能力，但由于依赖于提示和十亿参数的语言模型，因此无法可靠地部署和使用。SetFit（Tunstall等，2022年）是一种最近的实用方法，它在对比学习范式下微调了一个句子转换器，并取得了与更难管理的系统类似的结果。廉价的文本分类对于解决所有分类任务中的领域漂移问题非常重要，尤其是在检测社交媒体平台上的有害内容方面。在这里，我们提出了像一个好邻居（LaGoNN）这样的修改SetFit的方法，它不引入可学习参数，但是通过使用训练数据中最近邻的信息改变输入文本，例如标签和文本，使新颖的数据看起来类似于模型优化的实例。LaGoNN在标记不需要的内容和文本分类方面非常有效，并且改善了效果。",
    "tldr": "我们提出了一种名为LaGoNN的修改方法，该方法在不引入可学习参数的情况下，通过使用训练数据中最近邻的信息改变输入文本，从而使新颖的数据看起来类似于模型优化的实例。该方法对于标记不需要的内容和文本分类非常有效，并且改善了效果。",
    "en_tdlr": "We propose a modification called LaGoNN that improves text classification by altering input text with information from its nearest neighbor in the training data, making novel data appear similar to an instance on which the model was optimized. This method is effective at flagging undesirable content and improves performance."
}