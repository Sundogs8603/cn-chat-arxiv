{
    "title": "When Can We Track Significant Preference Shifts in Dueling Bandits?. (arXiv:2302.06595v2 [cs.LG] UPDATED)",
    "abstract": "The $K$-armed dueling bandits problem, where the feedback is in the form of noisy pairwise preferences, has been widely studied due its applications in information retrieval, recommendation systems, etc. Motivated by concerns that user preferences/tastes can evolve over time, we consider the problem of dueling bandits with distribution shifts. Specifically, we study the recent notion of significant shifts (Suk and Kpotufe, 2022), and ask whether one can design an adaptive algorithm for the dueling problem with $O(\\sqrt{K\\tilde{L}T})$ dynamic regret, where $\\tilde{L}$ is the (unknown) number of significant shifts in preferences. We show that the answer to this question depends on the properties of underlying preference distributions.  Firstly, we give an impossibility result that rules out any algorithm with $O(\\sqrt{K\\tilde{L}T})$ dynamic regret under the well-studied Condorcet and SST classes of preference distributions. Secondly, we show that $\\text{SST} \\cap \\text{STI}$ is the large",
    "link": "http://arxiv.org/abs/2302.06595",
    "context": "Title: When Can We Track Significant Preference Shifts in Dueling Bandits?. (arXiv:2302.06595v2 [cs.LG] UPDATED)\nAbstract: The $K$-armed dueling bandits problem, where the feedback is in the form of noisy pairwise preferences, has been widely studied due its applications in information retrieval, recommendation systems, etc. Motivated by concerns that user preferences/tastes can evolve over time, we consider the problem of dueling bandits with distribution shifts. Specifically, we study the recent notion of significant shifts (Suk and Kpotufe, 2022), and ask whether one can design an adaptive algorithm for the dueling problem with $O(\\sqrt{K\\tilde{L}T})$ dynamic regret, where $\\tilde{L}$ is the (unknown) number of significant shifts in preferences. We show that the answer to this question depends on the properties of underlying preference distributions.  Firstly, we give an impossibility result that rules out any algorithm with $O(\\sqrt{K\\tilde{L}T})$ dynamic regret under the well-studied Condorcet and SST classes of preference distributions. Secondly, we show that $\\text{SST} \\cap \\text{STI}$ is the large",
    "path": "papers/23/02/2302.06595.json",
    "total_tokens": 1136,
    "translated_title": "何时可以追踪到决斗对抗中的显著偏好转变？",
    "translated_abstract": "在信息检索、推荐系统等领域应用广泛的$K$臂决斗对抗问题中，反馈以有噪声的成对偏好形式给出，因此得到了广泛研究。考虑到用户的偏好/口味可能随时间演变，我们研究了具有分布转变的决斗对抗问题。具体来说，我们研究了最近提出的显著转变概念（Suk和Kpotufe，2022），并提出是否可以设计一种自适应算法来解决具有$O(\\sqrt{K\\tilde{L}T})$动态遗憾（regret）的决斗问题，其中$\\tilde{L}$是偏好中显著转变的（未知）数量。我们表明，这个问题的答案取决于底层偏好分布的属性。首先，我们给出了一个不可能的结果，排除了在广受研究的Condorcet和SST偏好分布类下具有$O(\\sqrt{K\\tilde{L}T})$动态遗憾的任何算法。其次，我们表明$\\text{SST} \\cap \\text{STI}$是大规模的情况。",
    "tldr": "这个论文研究了具有分布转变的决斗对抗问题，并探讨了设计自适应算法以解决动态遗憾的问题，结果发现取决于底层偏好分布的属性。达到$O(\\sqrt{K\\tilde{L}T})$的动态遗憾是不可能的；对于$\\text{SST} \\cap \\text{STI}$情况，存在一种算法实现动态遗憾为$O(\\sqrt{K\\tilde{L}T})$。",
    "en_tdlr": "This paper investigates the dueling bandits problem with distribution shifts and explores the design of adaptive algorithms for dynamic regret. The results suggest that achieving $O(\\sqrt{K\\tilde{L}T})$ dynamic regret is impossible under well-studied preference distribution classes such as Condorcet and SST, while for the case of $\\text{SST} \\cap \\text{STI}$, an algorithm can achieve dynamic regret of $O(\\sqrt{K\\tilde{L}T})$."
}