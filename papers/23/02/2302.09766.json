{
    "title": "A One-Sample Decentralized Proximal Algorithm for Non-Convex Stochastic Composite Optimization. (arXiv:2302.09766v2 [math.OC] UPDATED)",
    "abstract": "We focus on decentralized stochastic non-convex optimization, where $n$ agents work together to optimize a composite objective function which is a sum of a smooth term and a non-smooth convex term. To solve this problem, we propose two single-time scale algorithms: Prox-DASA and Prox-DASA-GT. These algorithms can find $\\epsilon$-stationary points in $\\mathcal{O}(n^{-1}\\epsilon^{-2})$ iterations using constant batch sizes (i.e., $\\mathcal{O}(1)$). Unlike prior work, our algorithms achieve comparable complexity without requiring large batch sizes, more complex per-iteration operations (such as double loops), or stronger assumptions. Our theoretical findings are supported by extensive numerical experiments, which demonstrate the superiority of our algorithms over previous approaches. Our code is available at https://github.com/xuxingc/ProxDASA.",
    "link": "http://arxiv.org/abs/2302.09766",
    "context": "Title: A One-Sample Decentralized Proximal Algorithm for Non-Convex Stochastic Composite Optimization. (arXiv:2302.09766v2 [math.OC] UPDATED)\nAbstract: We focus on decentralized stochastic non-convex optimization, where $n$ agents work together to optimize a composite objective function which is a sum of a smooth term and a non-smooth convex term. To solve this problem, we propose two single-time scale algorithms: Prox-DASA and Prox-DASA-GT. These algorithms can find $\\epsilon$-stationary points in $\\mathcal{O}(n^{-1}\\epsilon^{-2})$ iterations using constant batch sizes (i.e., $\\mathcal{O}(1)$). Unlike prior work, our algorithms achieve comparable complexity without requiring large batch sizes, more complex per-iteration operations (such as double loops), or stronger assumptions. Our theoretical findings are supported by extensive numerical experiments, which demonstrate the superiority of our algorithms over previous approaches. Our code is available at https://github.com/xuxingc/ProxDASA.",
    "path": "papers/23/02/2302.09766.json",
    "total_tokens": 902,
    "translated_title": "一种单样本去中心化近端算法用于非凸随机复合优化",
    "translated_abstract": "本文研究了去中心化随机非凸优化问题，其中$n$个代理共同优化由光滑项和非光滑凸项相加的复合目标函数。为了解决这个问题，我们提出了两个单时间规模算法：Prox-DASA和Prox-DASA-GT。这些算法可以使用常量批量大小（即$\\mathcal{O}(1)$）在$\\mathcal{O}(n^{-1}\\epsilon^{-2})$次迭代中找到$\\epsilon$-静止点。与以前的工作不同，我们的算法在不需要大批量大小、更复杂的每次迭代操作（如双重循环）或更强的假设的情况下实现了可比拟的复杂度。我们的理论发现得到了广泛的数值实验支持，这些实验证明了我们的算法优于以前的方法。我们的代码可在https://github.com/xuxingc/ProxDASA找到。",
    "tldr": "本文提出了两种单时间规模的算法：Prox-DASA和Prox-DASA-GT，它们可以用常量批量大小找到复合目标函数的$\\epsilon$-静止点，并且不需要大批量大小、更复杂的操作或更强的假设。",
    "en_tdlr": "This paper presents two single-time scale algorithms, Prox-DASA and Prox-DASA-GT, for decentralized stochastic non-convex optimization problems, which can find $\\epsilon$-stationary points using constant batch sizes without requiring large batch sizes, more complex per-iteration operations or stronger assumptions, and are supported by extensive numerical experiments."
}