{
    "title": "On the Generalization of PINNs outside the training domain and the Hyperparameters influencing it. (arXiv:2302.07557v2 [cs.LG] UPDATED)",
    "abstract": "Physics-Informed Neural Networks (PINNs) are Neural Network architectures trained to emulate solutions of differential equations without the necessity of solution data. They are currently ubiquitous in the scientific literature due to their flexible and promising settings. However, very little of the available research provides practical studies that aim for a better quantitative understanding of such architecture and its functioning. In this paper, we perform an empirical analysis of the behavior of PINN predictions outside their training domain. The primary goal is to investigate the scenarios in which a PINN can provide consistent predictions outside the training area. Thereinafter, we assess whether the algorithmic setup of PINNs can influence their potential for generalization and showcase the respective effect on the prediction. The results obtained in this study returns insightful and at times counterintuitive perspectives which can be highly relevant for architectures which com",
    "link": "http://arxiv.org/abs/2302.07557",
    "context": "Title: On the Generalization of PINNs outside the training domain and the Hyperparameters influencing it. (arXiv:2302.07557v2 [cs.LG] UPDATED)\nAbstract: Physics-Informed Neural Networks (PINNs) are Neural Network architectures trained to emulate solutions of differential equations without the necessity of solution data. They are currently ubiquitous in the scientific literature due to their flexible and promising settings. However, very little of the available research provides practical studies that aim for a better quantitative understanding of such architecture and its functioning. In this paper, we perform an empirical analysis of the behavior of PINN predictions outside their training domain. The primary goal is to investigate the scenarios in which a PINN can provide consistent predictions outside the training area. Thereinafter, we assess whether the algorithmic setup of PINNs can influence their potential for generalization and showcase the respective effect on the prediction. The results obtained in this study returns insightful and at times counterintuitive perspectives which can be highly relevant for architectures which com",
    "path": "papers/23/02/2302.07557.json",
    "total_tokens": 847,
    "translated_title": "关于PINNs在训练域之外的泛化及其影响的超参数",
    "translated_abstract": "物理知识驱动神经网络（PINNs）是一种神经网络架构，通过训练来模拟微分方程的解，而无需解决数据。由于其灵活和有前景的设置，PINNs目前在科学文献中得到广泛应用。然而，目前可用的研究很少提供实际的研究，旨在更好地定量理解这种架构及其功能。在本文中，我们对PINN在其训练域之外的预测行为进行了实证分析。主要目标是研究PINN在提供一致预测的情况下的场景。随后，我们评估了PINNs的算法设置是否会影响其泛化能力，并展示了对预测的相应影响。本研究的结果提供了有见地且有时直观的观点，对于这种架构的相关性可能是非常重要的。",
    "tldr": "本研究对PINN在训练域之外的预测行为进行了实证分析，并评估了算法设置对其泛化能力的影响。结果提供了有见地且有时直观的观点。",
    "en_tdlr": "This study empirically analyzes the behavior of PINN predictions outside the training domain and evaluates the influence of algorithm settings on their generalization capability. The results provide insightful and sometimes counterintuitive perspectives."
}