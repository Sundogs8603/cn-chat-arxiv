{
    "title": "Diversity is Definitely Needed: Improving Model-Agnostic Zero-shot Classification via Stable Diffusion. (arXiv:2302.03298v3 [cs.CV] UPDATED)",
    "abstract": "In this work, we investigate the problem of Model-Agnostic Zero-Shot Classification (MA-ZSC), which refers to training non-specific classification architectures (downstream models) to classify real images without using any real images during training. Recent research has demonstrated that generating synthetic training images using diffusion models provides a potential solution to address MA-ZSC. However, the performance of this approach currently falls short of that achieved by large-scale vision-language models. One possible explanation is a potential significant domain gap between synthetic and real images. Our work offers a fresh perspective on the problem by providing initial insights that MA-ZSC performance can be improved by improving the diversity of images in the generated dataset. We propose a set of modifications to the text-to-image generation process using a pre-trained diffusion model to enhance diversity, which we refer to as our $\\textbf{bag of tricks}$. Our approach sho",
    "link": "http://arxiv.org/abs/2302.03298",
    "context": "Title: Diversity is Definitely Needed: Improving Model-Agnostic Zero-shot Classification via Stable Diffusion. (arXiv:2302.03298v3 [cs.CV] UPDATED)\nAbstract: In this work, we investigate the problem of Model-Agnostic Zero-Shot Classification (MA-ZSC), which refers to training non-specific classification architectures (downstream models) to classify real images without using any real images during training. Recent research has demonstrated that generating synthetic training images using diffusion models provides a potential solution to address MA-ZSC. However, the performance of this approach currently falls short of that achieved by large-scale vision-language models. One possible explanation is a potential significant domain gap between synthetic and real images. Our work offers a fresh perspective on the problem by providing initial insights that MA-ZSC performance can be improved by improving the diversity of images in the generated dataset. We propose a set of modifications to the text-to-image generation process using a pre-trained diffusion model to enhance diversity, which we refer to as our $\\textbf{bag of tricks}$. Our approach sho",
    "path": "papers/23/02/2302.03298.json",
    "total_tokens": 1018,
    "translated_title": "需要多样性：通过稳定的扩散改善模型无关的零样本分类",
    "translated_abstract": "本文研究了模型无关的零样本分类（MA-ZSC）问题，这意味着训练分类架构来对真实图像进行分类，而在训练过程中不使用任何真实图像。最近的研究表明，使用扩散模型生成合成训练图像可以提供潜在的解决MA-ZSC问题的方法。然而，该方法的性能目前仍然不如大规模视觉-语言模型所取得的性能。我们提出了一种通过改善生成数据集中图像的多样性来提高MA-ZSC性能的新思路。我们提出了一组修改文本到图像生成过程的方法，使用预训练的扩散模型来增强多样性，我们称之为“绝招”。我们的方法适用于任何下游的分类架构，尽管我们重点关注视觉-语言模型。实验证明，在CUB数据集上，我们的方法比最先进的方法提高了1.4mAP，在ImageNet数据集上提高了8.4mAP，同时需要更少的生成图像进行训练。",
    "tldr": "本文提出了一种通过增强生成数据集中图像的多样性来提高模型无关的零样本分类性能的方法，比最先进的方法提高了1.4mAP（CUB数据集）和8.4mAP（ImageNet数据集），并且适用于任何下游的分类架构。",
    "en_tdlr": "This paper proposes a method to improve the performance of model-agnostic zero-shot classification by enhancing the diversity of generated images, which achieved better results than the state-of-the-art method by 1.4 mAP (CUB dataset) and 8.4 mAP (ImageNet dataset) and is compatible with any downstream classification architecture."
}