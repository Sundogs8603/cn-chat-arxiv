{
    "title": "SoK: A Systematic Evaluation of Backdoor Trigger Characteristics in Image Classification. (arXiv:2302.01740v2 [cs.CV] UPDATED)",
    "abstract": "Deep learning achieves outstanding results in many machine learning tasks. Nevertheless, it is vulnerable to backdoor attacks that modify the training set to embed a secret functionality in the trained model. The modified training samples have a secret property, i. e., a trigger. At inference time, the secret functionality is activated when the input contains the trigger, while the model functions correctly in other cases. While there are many known backdoor attacks (and defenses), deploying a stealthy attack is still far from trivial. Successfully creating backdoor triggers depends on numerous parameters. Unfortunately, research has not yet determined which parameters contribute most to the attack performance.  This paper systematically analyzes the most relevant parameters for the backdoor attacks, i.e., trigger size, position, color, and poisoning rate. Using transfer learning, which is very common in computer vision, we evaluate the attack on state-of-the-art models (ResNet, VGG, A",
    "link": "http://arxiv.org/abs/2302.01740",
    "context": "Title: SoK: A Systematic Evaluation of Backdoor Trigger Characteristics in Image Classification. (arXiv:2302.01740v2 [cs.CV] UPDATED)\nAbstract: Deep learning achieves outstanding results in many machine learning tasks. Nevertheless, it is vulnerable to backdoor attacks that modify the training set to embed a secret functionality in the trained model. The modified training samples have a secret property, i. e., a trigger. At inference time, the secret functionality is activated when the input contains the trigger, while the model functions correctly in other cases. While there are many known backdoor attacks (and defenses), deploying a stealthy attack is still far from trivial. Successfully creating backdoor triggers depends on numerous parameters. Unfortunately, research has not yet determined which parameters contribute most to the attack performance.  This paper systematically analyzes the most relevant parameters for the backdoor attacks, i.e., trigger size, position, color, and poisoning rate. Using transfer learning, which is very common in computer vision, we evaluate the attack on state-of-the-art models (ResNet, VGG, A",
    "path": "papers/23/02/2302.01740.json",
    "total_tokens": 990,
    "translated_title": "SoK：图像分类中后门触发特征的系统性评估",
    "translated_abstract": "深度学习在许多机器学习任务中都取得了出色的成果。然而，它容易受到后门攻击的影响，这种攻击通过修改训练集来嵌入受控功能于训练好的模型中。所修改训练样本具有秘密属性，即一个触发器。在推理时，当输入包含触发器时，秘密功能被激活，而在其他情况下模型则能正常运作。虽然已知有许多后门攻击和防御方法，但成功创建隐蔽的后门攻击仍然很困难。成功地创建后门触发器取决于众多参数，不幸的是，尚未确定哪些参数对攻击性能贡献最大。因此本文通过系统分析最相关的后门攻击参数，即触发器尺寸，位置，颜色和污染率。使用迁移学习来评估现有最先进的模型（ResNet，VGG，AlexNet）和数据集（MNIST，CIFAR-10，ImageNet）中的攻击。我们的结果表明，污染率是创建有效后门的最关键参数；2x2像素大小的触发器已足够大多数情况。",
    "tldr": "本论文对图像分类中的后门触发特征进行了系统性评估，结果显示污染率和2x2像素大小的触发器是创建有效后门的最关键参数。",
    "en_tdlr": "This paper systematically evaluates backdoor trigger characteristics in image classification, finding that the poisoning rate and trigger size of 2x2 pixels are the most critical parameters for creating effective backdoors."
}