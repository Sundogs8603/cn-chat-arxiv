{
    "title": "Exploring Self-supervised Pre-trained ASR Models For Dysarthric and Elderly Speech Recognition. (arXiv:2302.14564v2 [cs.SD] UPDATED)",
    "abstract": "Automatic recognition of disordered and elderly speech remains a highly challenging task to date due to the difficulty in collecting such data in large quantities. This paper explores a series of approaches to integrate domain adapted SSL pre-trained models into TDNN and Conformer ASR systems for dysarthric and elderly speech recognition: a) input feature fusion between standard acoustic frontends and domain adapted wav2vec2.0 speech representations; b) frame-level joint decoding of TDNN systems separately trained using standard acoustic features alone and with additional wav2vec2.0 features; and c) multi-pass decoding involving the TDNN/Conformer system outputs to be rescored using domain adapted wav2vec2.0 models. In addition, domain adapted wav2vec2.0 representations are utilized in acoustic-to-articulatory (A2A) inversion to construct multi-modal dysarthric and elderly speech recognition systems. Experiments conducted on the UASpeech dysarthric and DementiaBank Pitt elderly speech ",
    "link": "http://arxiv.org/abs/2302.14564",
    "context": "Title: Exploring Self-supervised Pre-trained ASR Models For Dysarthric and Elderly Speech Recognition. (arXiv:2302.14564v2 [cs.SD] UPDATED)\nAbstract: Automatic recognition of disordered and elderly speech remains a highly challenging task to date due to the difficulty in collecting such data in large quantities. This paper explores a series of approaches to integrate domain adapted SSL pre-trained models into TDNN and Conformer ASR systems for dysarthric and elderly speech recognition: a) input feature fusion between standard acoustic frontends and domain adapted wav2vec2.0 speech representations; b) frame-level joint decoding of TDNN systems separately trained using standard acoustic features alone and with additional wav2vec2.0 features; and c) multi-pass decoding involving the TDNN/Conformer system outputs to be rescored using domain adapted wav2vec2.0 models. In addition, domain adapted wav2vec2.0 representations are utilized in acoustic-to-articulatory (A2A) inversion to construct multi-modal dysarthric and elderly speech recognition systems. Experiments conducted on the UASpeech dysarthric and DementiaBank Pitt elderly speech ",
    "path": "papers/23/02/2302.14564.json",
    "total_tokens": 824,
    "translated_title": "探索自监督预训练ASR模型用于口吃和老年人语音识别",
    "translated_abstract": "自动识别语音障碍和老年人的语音仍然是一项极具挑战性的任务，因为很难收集大量这样的数据。本文探讨了一系列方法，将领域自适应的SSL预训练模型与TDNN和Conformer ASR系统相结合，用于口吃和老年人的语音识别。",
    "tldr": "本文探索了将自监督预训练模型与ASR系统相结合以提高口吃和老年人的语音识别性能的方法，包括输入特征融合，TDNN系统的帧级联合解码，以及多通道解码等。同时，在构建多模式的口吃和老年人语音识别系统时，采用了领域自适应的wav2vec2.0表示法。",
    "en_tdlr": "This paper explores approaches to combine self-supervised pre-trained models with ASR systems to improve speech recognition for dysarthric and elderly speech, including input feature fusion, frame-level joint decoding, and multi-pass decoding. Domain adapted wav2vec2.0 representations are also utilized in acoustic-to-articulatory inversion for constructing multimodal recognition systems."
}