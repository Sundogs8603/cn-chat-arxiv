{
    "title": "Causally Disentangled Generative Variational AutoEncoder. (arXiv:2302.11737v2 [stat.ML] UPDATED)",
    "abstract": "We present a new supervised learning technique for the Variational AutoEncoder (VAE) that allows it to learn a causally disentangled representation and generate causally disentangled outcomes simultaneously. We call this approach Causally Disentangled Generation (CDG). CDG is a generative model that accurately decodes an output based on a causally disentangled representation. Our research demonstrates that adding supervised regularization to the encoder alone is insufficient for achieving a generative model with CDG, even for a simple task. Therefore, we explore the necessary and sufficient conditions for achieving CDG within a specific model. Additionally, we introduce a universal metric for evaluating the causal disentanglement of a generative model. Empirical results from both image and tabular datasets support our findings.",
    "link": "http://arxiv.org/abs/2302.11737",
    "context": "Title: Causally Disentangled Generative Variational AutoEncoder. (arXiv:2302.11737v2 [stat.ML] UPDATED)\nAbstract: We present a new supervised learning technique for the Variational AutoEncoder (VAE) that allows it to learn a causally disentangled representation and generate causally disentangled outcomes simultaneously. We call this approach Causally Disentangled Generation (CDG). CDG is a generative model that accurately decodes an output based on a causally disentangled representation. Our research demonstrates that adding supervised regularization to the encoder alone is insufficient for achieving a generative model with CDG, even for a simple task. Therefore, we explore the necessary and sufficient conditions for achieving CDG within a specific model. Additionally, we introduce a universal metric for evaluating the causal disentanglement of a generative model. Empirical results from both image and tabular datasets support our findings.",
    "path": "papers/23/02/2302.11737.json",
    "total_tokens": 915,
    "translated_title": "因果解缠的生成变分自动编码器",
    "translated_abstract": "我们提出了一种新的监督学习技术，用于变分自动编码器（VAE），使其能够同时学习因果解缠表示和生成因果解缠结果。我们将这种方法称为因果解缠生成（CDG）。CDG是一个生成模型，它可以根据因果解缠表示准确地解码输出。我们的研究表明，仅仅在编码器中加入监督正则化是无法实现具有CDG的生成模型的，即使对于一个简单的任务也是如此。因此，我们探讨了在特定模型中实现CDG所需的必要条件和充分条件。此外，我们引入了一个用于评估生成模型因果解缠程度的通用度量。来自图像和表格数据集的实证结果支持了我们的发现。",
    "tldr": "本研究提出了一种名为CDG的方法，通过对变分自动编码器进行监督学习，实现了同时学习因果解缠表示和生成因果解缠结果。通过探索特定模型下实现CDG的必要和充分条件，我们发现仅在编码器中加入监督正则化是不够的。此外，我们引入了一个通用度量来评估生成模型的因果解缠程度，并通过实证结果验证了我们的发现。",
    "en_tdlr": "This research introduces a method called CDG, which enables supervised learning in the Variational AutoEncoder (VAE) to simultaneously learn causally disentangled representations and generate causally disentangled outcomes. By exploring the necessary and sufficient conditions in a specific model, it is found that adding supervised regularization only to the encoder is insufficient. Additionally, a universal metric for evaluating the causal disentanglement of a generative model is introduced, and empirical results support the findings."
}