{
    "title": "A Lower Bound and a Near-Optimal Algorithm for Bilevel Empirical Risk Minimization. (arXiv:2302.08766v2 [stat.ML] UPDATED)",
    "abstract": "Bilevel optimization problems, which are problems where two optimization problems are nested, have more and more applications in machine learning. In many practical cases, the upper and the lower objectives correspond to empirical risk minimization problems and therefore have a sum structure. In this context, we propose a bilevel extension of the celebrated SARAH algorithm. We demonstrate that the algorithm requires $\\mathcal{O}((n+m)^{\\frac12}\\varepsilon^{-1})$ gradient computations to achieve $\\varepsilon$-stationarity with $n+m$ the total number of samples, which improves over all previous bilevel algorithms. Moreover, we provide a lower bound on the number of oracle calls required to get an approximate stationary point of the objective function of the bilevel problem. This lower bound is attained by our algorithm, which is therefore optimal in terms of sample complexity.",
    "link": "http://arxiv.org/abs/2302.08766",
    "context": "Title: A Lower Bound and a Near-Optimal Algorithm for Bilevel Empirical Risk Minimization. (arXiv:2302.08766v2 [stat.ML] UPDATED)\nAbstract: Bilevel optimization problems, which are problems where two optimization problems are nested, have more and more applications in machine learning. In many practical cases, the upper and the lower objectives correspond to empirical risk minimization problems and therefore have a sum structure. In this context, we propose a bilevel extension of the celebrated SARAH algorithm. We demonstrate that the algorithm requires $\\mathcal{O}((n+m)^{\\frac12}\\varepsilon^{-1})$ gradient computations to achieve $\\varepsilon$-stationarity with $n+m$ the total number of samples, which improves over all previous bilevel algorithms. Moreover, we provide a lower bound on the number of oracle calls required to get an approximate stationary point of the objective function of the bilevel problem. This lower bound is attained by our algorithm, which is therefore optimal in terms of sample complexity.",
    "path": "papers/23/02/2302.08766.json",
    "total_tokens": 873,
    "translated_title": "一种双层经验风险最小化算法的下界和近似最优算法",
    "translated_abstract": "双层最优化问题越来越多地应用于机器学习中。在许多实际情况下，上层和下层目标对应于经验风险最小化问题，并因此具有总和结构。在这个背景下，我们提出了一个著名的SARAH算法的双层扩展。我们证明了该算法需要$\\mathcal {O}((n+m)^{\\frac{1}{2}}\\varepsilon ^{-1})$次梯度计算才能实现$\\varepsilon$稳定性，其中$n+m$是样本总数，这比先前所有的双层算法都要好。此外，我们提供了一个下界，用于得到双层问题的目标函数的近似稳定点所需的oracle调用次数。这个下界正是我们的算法所达到的，因此在样本复杂度方面是最优的。",
    "tldr": "该论文提出了一种双层经验风险最小化算法，使用的梯度计算次数 $O((n+m)^{\\frac{1}{2}}\\varepsilon^{-1})$，在样本复杂度方面是最优的。",
    "en_tdlr": "This paper proposes a bilevel empirical risk minimization algorithm that achieves an optimal sample complexity of $\\mathcal{O}((n+m)^{\\frac12}\\varepsilon^{-1})$ for $\\varepsilon$-stationarity and provides a lower bound on the number of oracle calls required for an approximate stationary point of the objective function."
}