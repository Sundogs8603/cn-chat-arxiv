{
    "title": "Invariant Slot Attention: Object Discovery with Slot-Centric Reference Frames. (arXiv:2302.04973v2 [cs.CV] UPDATED)",
    "abstract": "Automatically discovering composable abstractions from raw perceptual data is a long-standing challenge in machine learning. Recent slot-based neural networks that learn about objects in a self-supervised manner have made exciting progress in this direction. However, they typically fall short at adequately capturing spatial symmetries present in the visual world, which leads to sample inefficiency, such as when entangling object appearance and pose. In this paper, we present a simple yet highly effective method for incorporating spatial symmetries via slot-centric reference frames. We incorporate equivariance to per-object pose transformations into the attention and generation mechanism of Slot Attention by translating, scaling, and rotating position encodings. These changes result in little computational overhead, are easy to implement, and can result in large gains in terms of data efficiency and overall improvements to object discovery. We evaluate our method on a wide range of synt",
    "link": "http://arxiv.org/abs/2302.04973",
    "context": "Title: Invariant Slot Attention: Object Discovery with Slot-Centric Reference Frames. (arXiv:2302.04973v2 [cs.CV] UPDATED)\nAbstract: Automatically discovering composable abstractions from raw perceptual data is a long-standing challenge in machine learning. Recent slot-based neural networks that learn about objects in a self-supervised manner have made exciting progress in this direction. However, they typically fall short at adequately capturing spatial symmetries present in the visual world, which leads to sample inefficiency, such as when entangling object appearance and pose. In this paper, we present a simple yet highly effective method for incorporating spatial symmetries via slot-centric reference frames. We incorporate equivariance to per-object pose transformations into the attention and generation mechanism of Slot Attention by translating, scaling, and rotating position encodings. These changes result in little computational overhead, are easy to implement, and can result in large gains in terms of data efficiency and overall improvements to object discovery. We evaluate our method on a wide range of synt",
    "path": "papers/23/02/2302.04973.json",
    "total_tokens": 882,
    "translated_title": "不变的槽注意力: 通过以槽为中心的参考框架进行对象发现",
    "translated_abstract": "从原始感知数据中自动发现可组合的抽象是机器学习中长期存在的挑战。最近，基于槽的神经网络以自我监督的方式学习对象在这个方向上取得了令人兴奋的进展。然而，它们通常在充分捕捉视觉世界中的空间对称性方面表现不佳，导致样本效率低下，比如在纠结对象外观和姿态时。在本文中，我们提出了一种简单但极其有效的方法，通过以槽为中心的参考框架来融入空间对称性。我们将等变性引入到Slot Attention的注意力和生成机制中，通过平移、缩放和旋转位置编码来实现对每个对象姿态变换的等变性。这些改变几乎没有额外的计算开销，易于实现，并可以在数据效率和整体对象发现方面取得巨大的改进。我们在广泛的语法范围内对我们的方法进行了评估。",
    "tldr": "本文介绍了一种通过以槽为中心的参考框架来改进对象发现的方法，通过在Slot Attention中融入空间对称性，可以大幅提高数据效率和整体对象发现效果。",
    "en_tdlr": "This paper presents a method for improving object discovery by incorporating spatial symmetries using slot-centric reference frames. By introducing equivariance into Slot Attention, significant improvements in data efficiency and overall object discovery can be achieved."
}