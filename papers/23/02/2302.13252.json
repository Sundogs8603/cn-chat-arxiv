{
    "title": "No-Regret Linear Bandits beyond Realizability. (arXiv:2302.13252v2 [cs.LG] UPDATED)",
    "abstract": "We study linear bandits when the underlying reward function is not linear. Existing work relies on a uniform misspecification parameter $\\epsilon$ that measures the sup-norm error of the best linear approximation. This results in an unavoidable linear regret whenever $\\epsilon > 0$. We describe a more natural model of misspecification which only requires the approximation error at each input $x$ to be proportional to the suboptimality gap at $x$. It captures the intuition that, for optimization problems, near-optimal regions should matter more and we can tolerate larger approximation errors in suboptimal regions. Quite surprisingly, we show that the classical LinUCB algorithm -- designed for the realizable case -- is automatically robust against such gap-adjusted misspecification. It achieves a near-optimal $\\sqrt{T}$ regret for problems that the best-known regret is almost linear in time horizon $T$. Technically, our proof relies on a novel self-bounding argument that bounds the part ",
    "link": "http://arxiv.org/abs/2302.13252",
    "context": "Title: No-Regret Linear Bandits beyond Realizability. (arXiv:2302.13252v2 [cs.LG] UPDATED)\nAbstract: We study linear bandits when the underlying reward function is not linear. Existing work relies on a uniform misspecification parameter $\\epsilon$ that measures the sup-norm error of the best linear approximation. This results in an unavoidable linear regret whenever $\\epsilon > 0$. We describe a more natural model of misspecification which only requires the approximation error at each input $x$ to be proportional to the suboptimality gap at $x$. It captures the intuition that, for optimization problems, near-optimal regions should matter more and we can tolerate larger approximation errors in suboptimal regions. Quite surprisingly, we show that the classical LinUCB algorithm -- designed for the realizable case -- is automatically robust against such gap-adjusted misspecification. It achieves a near-optimal $\\sqrt{T}$ regret for problems that the best-known regret is almost linear in time horizon $T$. Technically, our proof relies on a novel self-bounding argument that bounds the part ",
    "path": "papers/23/02/2302.13252.json",
    "total_tokens": 1014,
    "translated_title": "非可实现情况下的无懊悔线性Bandit",
    "translated_abstract": "我们研究了线性Bandit的情况，当底层的奖励函数不是线性的时候。现有的工作依赖于一个统一的错误参数 $\\epsilon$，该参数衡量了最佳线性逼近的超范数误差。这导致当 $\\epsilon > 0$ 时无法避免线性的懊悔。我们描述了一种更自然的错误模型，该模型仅要求每个输入 $x$ 的逼近误差与 $x$ 处的次优间隙成比例。这捕捉到了优化问题中近似最优区域的重要性，我们可以容忍次优区域中更大的逼近误差。令人惊讶的是，我们证明了经典的LinUCB算法——针对可实现情况设计的算法——自动适应了这样的间隙调整的错误。它在问题的最佳懊悔几乎是线性的情况下实现了近似最优的 $\\sqrt{T}$ 懊悔，其中 $T$ 是时间长度。技术上，我们的证明依赖于一种新颖的自限制论证方法，该方法对部分进行了上界绑定。",
    "tldr": "本文研究了线性Bandit中当奖励函数非线性时的情况。我们提出了一个更自然的错误模型，该模型只要求每个输入的逼近误差与其次优解之间的间距成比例。我们证明了经典的LinUCB算法可以自动适应这种错误模型，并在时间长度较大时达到近似最优的懊悔。"
}