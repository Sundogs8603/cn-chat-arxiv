{
    "title": "Auditing large language models: a three-layered approach. (arXiv:2302.08500v2 [cs.CL] UPDATED)",
    "abstract": "Large language models (LLMs) represent a major advance in artificial intelligence (AI) research. However, the widespread use of LLMs is also coupled with significant ethical and social challenges. Previous research has pointed towards auditing as a promising governance mechanism to help ensure that AI systems are designed and deployed in ways that are ethical, legal, and technically robust. However, existing auditing procedures fail to address the governance challenges posed by LLMs, which display emergent capabilities and are adaptable to a wide range of downstream tasks. In this article, we address that gap by outlining a novel blueprint for how to audit LLMs. Specifically, we propose a three-layered approach, whereby governance audits (of technology providers that design and disseminate LLMs), model audits (of LLMs after pre-training but prior to their release), and application audits (of applications based on LLMs) complement and inform each other. We show how audits, when conducte",
    "link": "http://arxiv.org/abs/2302.08500",
    "context": "Title: Auditing large language models: a three-layered approach. (arXiv:2302.08500v2 [cs.CL] UPDATED)\nAbstract: Large language models (LLMs) represent a major advance in artificial intelligence (AI) research. However, the widespread use of LLMs is also coupled with significant ethical and social challenges. Previous research has pointed towards auditing as a promising governance mechanism to help ensure that AI systems are designed and deployed in ways that are ethical, legal, and technically robust. However, existing auditing procedures fail to address the governance challenges posed by LLMs, which display emergent capabilities and are adaptable to a wide range of downstream tasks. In this article, we address that gap by outlining a novel blueprint for how to audit LLMs. Specifically, we propose a three-layered approach, whereby governance audits (of technology providers that design and disseminate LLMs), model audits (of LLMs after pre-training but prior to their release), and application audits (of applications based on LLMs) complement and inform each other. We show how audits, when conducte",
    "path": "papers/23/02/2302.08500.json",
    "total_tokens": 913,
    "translated_title": "审计大型语言模型：一个三层次的方法",
    "translated_abstract": "大型语言模型（LLMs）是人工智能（AI）研究的一个重大突破。然而，LLMs的广泛使用也伴随着重大的伦理和社会挑战。先前的研究指出，审计作为一种有前途的治理机制，有助于确保AI系统设计和部署的道德、法律和技术的健壮性。然而，现有的审计程序无法解决LLMs带来的治理挑战，因为LLMs显示出新兴能力，并可适应各种下游任务。在本文中，我们通过概述一种新颖的审计LLMs的蓝图来填补这一空白。具体而言，我们提出了一个三层次的方法，即治理审计（针对设计和传播LLMs的技术提供商）、模型审计（针对LLMs进行预训练但尚未发布的审计）和应用审计（基于LLMs的应用程序的审计），相互补充和相互通知。我们展示了审计在LLMs上的实施可以有效解决伦理和社会挑战。",
    "tldr": "本文提出了一个三层次的方法来审计大型语言模型（LLMs），包括治理审计、模型审计和应用审计，解决LLMs带来的伦理和社会挑战。",
    "en_tdlr": "This article proposes a three-layered approach to auditing large language models (LLMs), including governance audits, model audits, and application audits, addressing the ethical and social challenges posed by LLMs."
}