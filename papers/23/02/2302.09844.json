{
    "title": "FederatedTrust: A Solution for Trustworthy Federated Learning. (arXiv:2302.09844v2 [cs.CR] UPDATED)",
    "abstract": "The rapid expansion of the Internet of Things (IoT) and Edge Computing has presented challenges for centralized Machine and Deep Learning (ML/DL) methods due to the presence of distributed data silos that hold sensitive information. To address concerns regarding data privacy, collaborative and privacy-preserving ML/DL techniques like Federated Learning (FL) have emerged. However, ensuring data privacy and performance alone is insufficient since there is a growing need to establish trust in model predictions. Existing literature has proposed various approaches on trustworthy ML/DL (excluding data privacy), identifying robustness, fairness, explainability, and accountability as important pillars. Nevertheless, further research is required to identify trustworthiness pillars and evaluation metrics specifically relevant to FL models, as well as to develop solutions that can compute the trustworthiness level of FL models. This work examines the existing requirements for evaluating trustwort",
    "link": "http://arxiv.org/abs/2302.09844",
    "context": "Title: FederatedTrust: A Solution for Trustworthy Federated Learning. (arXiv:2302.09844v2 [cs.CR] UPDATED)\nAbstract: The rapid expansion of the Internet of Things (IoT) and Edge Computing has presented challenges for centralized Machine and Deep Learning (ML/DL) methods due to the presence of distributed data silos that hold sensitive information. To address concerns regarding data privacy, collaborative and privacy-preserving ML/DL techniques like Federated Learning (FL) have emerged. However, ensuring data privacy and performance alone is insufficient since there is a growing need to establish trust in model predictions. Existing literature has proposed various approaches on trustworthy ML/DL (excluding data privacy), identifying robustness, fairness, explainability, and accountability as important pillars. Nevertheless, further research is required to identify trustworthiness pillars and evaluation metrics specifically relevant to FL models, as well as to develop solutions that can compute the trustworthiness level of FL models. This work examines the existing requirements for evaluating trustwort",
    "path": "papers/23/02/2302.09844.json",
    "total_tokens": 896,
    "translated_title": "FederatedTrust: 解决可信任的联邦学习问题",
    "translated_abstract": "随着物联网（IoT）和边缘计算的快速发展，集中式机器学习和深度学习方法面临着分布式数据孤立所带来的挑战，这些数据孤立中保存着敏感信息。为了解决数据隐私问题，出现了协作和隐私保护的机器学习和深度学习技术，如联邦学习（FL）。然而，仅仅确保数据隐私和性能是不够的，因为越来越需要建立对模型预测的信任。现有文献提出了各种关于可信任机器学习和深度学习方面的方法（不包括数据隐私），将健壮性、公平性、可解释性和问责制视为重要支柱。然而，进一步的研究需要确定与FL模型特别相关的可信任支柱和评估指标，并开发能够计算FL模型可信任水平的解决方案。本研究检查了评估可信任性的现有要求",
    "tldr": "本研究关注解决分布式数据隐私问题，提出了一个名为FederatedTrust的解决方案，旨在处理联邦学习模型的可信任性问题，包括健壮性、公平性、可解释性和问责制。",
    "en_tdlr": "This study focuses on addressing the issue of distributed data privacy and proposes a solution called FederatedTrust to handle trustworthiness of federated learning models, including robustness, fairness, explainability, and accountability."
}