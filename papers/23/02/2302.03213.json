{
    "title": "LUT-NN: Empower Efficient Neural Network Inference with Centroid Learning and Table Lookup. (arXiv:2302.03213v2 [cs.LG] UPDATED)",
    "abstract": "On-device Deep Neural Network (DNN) inference consumes significant computing resources and development efforts. To alleviate that, we propose LUT-NN, the first system to empower inference by table lookup, to reduce inference cost. LUT-NN learns the typical features for each operator, named centroid, and precompute the results for these centroids to save in lookup tables. During inference, the results of the closest centroids with the inputs can be read directly from the table, as the approximated outputs without computations. LUT-NN integrates two major novel techniques: (1) differentiable centroid learning through backpropagation, which adapts three levels of approximation to minimize the accuracy impact by centroids; (2) table lookup inference execution, which comprehensively considers different levels of parallelism, memory access reduction, and dedicated hardware units for optimal performance. LUT-NN is evaluated on multiple real tasks, covering image and speech recognition, and na",
    "link": "http://arxiv.org/abs/2302.03213",
    "context": "Title: LUT-NN: Empower Efficient Neural Network Inference with Centroid Learning and Table Lookup. (arXiv:2302.03213v2 [cs.LG] UPDATED)\nAbstract: On-device Deep Neural Network (DNN) inference consumes significant computing resources and development efforts. To alleviate that, we propose LUT-NN, the first system to empower inference by table lookup, to reduce inference cost. LUT-NN learns the typical features for each operator, named centroid, and precompute the results for these centroids to save in lookup tables. During inference, the results of the closest centroids with the inputs can be read directly from the table, as the approximated outputs without computations. LUT-NN integrates two major novel techniques: (1) differentiable centroid learning through backpropagation, which adapts three levels of approximation to minimize the accuracy impact by centroids; (2) table lookup inference execution, which comprehensively considers different levels of parallelism, memory access reduction, and dedicated hardware units for optimal performance. LUT-NN is evaluated on multiple real tasks, covering image and speech recognition, and na",
    "path": "papers/23/02/2302.03213.json",
    "total_tokens": 960,
    "translated_title": "LUT-NN：通过质心学习和表格查找提高高效神经网络推理能力",
    "translated_abstract": "在设备上进行深度神经网络（DNN）推理消耗了大量的计算资源和开发工作。为了缓解这个问题，我们提出了LUT-NN，这是第一个通过表格查找提高推理效果以减少推理成本的系统。LUT-NN学习了每个运算符的典型特征，被称为质心，并预先计算了这些质心的结果，保存在查找表中。在推理过程中，可以直接从表格中读取与输入最接近的质心的结果作为近似输出，无需进行计算。LUT-NN整合了两个主要的创新技术：（1）可微分的通过反向传播进行质心学习，通过质心适应三个级别的近似来最小化质心对准确性的影响；（2）表格查找推理执行，全面考虑了不同级别的并行性、内存访问的降低和专用硬件单元，以达到最佳性能。LUT-NN在多个实际任务上进行了评估，涵盖了图像和语音识别等领域。",
    "tldr": "LUT-NN通过质心学习和表格查找提高神经网络推理效果以减少推理成本。具体而言，LUT-NN使用可微分的质心学习来最小化质心对准确性的影响，并通过表格查找直接读取近似输出结果，以实现高效的推理执行。"
}