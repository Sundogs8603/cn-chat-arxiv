{
    "title": "Towards Agile Text Classifiers for Everyone. (arXiv:2302.06541v2 [cs.CL] UPDATED)",
    "abstract": "Text-based safety classifiers are widely used for content moderation and increasingly to tune generative language model behavior - a topic of growing concern for the safety of digital assistants and chatbots. However, different policies require different classifiers, and safety policies themselves improve from iteration and adaptation. This paper introduces and evaluates methods for agile text classification, whereby classifiers are trained using small, targeted datasets that can be quickly developed for a particular policy. Experimenting with 7 datasets from three safety-related domains, comprising 15 annotation schemes, led to our key finding: prompt-tuning large language models, like PaLM 62B, with a labeled dataset of as few as 80 examples can achieve state-of-the-art performance. We argue that this enables a paradigm shift for text classification, especially for models supporting safer online discourse. Instead of collecting millions of examples to attempt to create universal safe",
    "link": "http://arxiv.org/abs/2302.06541",
    "context": "Title: Towards Agile Text Classifiers for Everyone. (arXiv:2302.06541v2 [cs.CL] UPDATED)\nAbstract: Text-based safety classifiers are widely used for content moderation and increasingly to tune generative language model behavior - a topic of growing concern for the safety of digital assistants and chatbots. However, different policies require different classifiers, and safety policies themselves improve from iteration and adaptation. This paper introduces and evaluates methods for agile text classification, whereby classifiers are trained using small, targeted datasets that can be quickly developed for a particular policy. Experimenting with 7 datasets from three safety-related domains, comprising 15 annotation schemes, led to our key finding: prompt-tuning large language models, like PaLM 62B, with a labeled dataset of as few as 80 examples can achieve state-of-the-art performance. We argue that this enables a paradigm shift for text classification, especially for models supporting safer online discourse. Instead of collecting millions of examples to attempt to create universal safe",
    "path": "papers/23/02/2302.06541.json",
    "total_tokens": 912,
    "translated_title": "面向所有人的敏捷文本分类器",
    "translated_abstract": "基于文本的安全分类器广泛用于内容审核，并且越来越多地用于调整生成语言模型的行为，这是对数字助理和聊天机器人安全性的日益关注的话题。然而，不同的策略需要不同的分类器，并且安全策略本身也可以通过迭代和调整来改进。本文引入并评估了敏捷文本分类的方法，通过使用小型、定向的数据集进行训练，可以为特定策略快速开发分类器。在三个与安全相关的领域使用7个数据集，包括15个注释方案的实验中，我们的主要发现是：使用尽少80个示例的标记数据集，对大型语言模型（如PaLM 62B）进行提示调整，可以实现最先进的性能。我们认为，这为文本分类带来了范式转变，特别是为支持更安全的在线交流的模型。与试图收集数百万个示例以创建通用安全的模型相比，这种方法更加高效和灵活。",
    "tldr": "本文介绍和评估了敏捷文本分类的方法，通过使用小型、定向的数据集进行训练，可以为特定策略快速开发分类器，并通过提示调整大型语言模型来实现最先进的性能。这为支持更安全的在线交流的模型带来了范式转变。"
}