{
    "title": "Improving Domain Generalization with Domain Relations",
    "abstract": "arXiv:2302.02609v2 Announce Type: replace  Abstract: Distribution shift presents a significant challenge in machine learning, where models often underperform during the test stage when faced with a different distribution than the one they were trained on. This paper focuses on domain shifts, which occur when the model is applied to new domains that are different from the ones it was trained on, and propose a new approach called D$^3$G. Unlike previous methods that aim to learn a single model that is domain invariant, D$^3$G leverages domain similarities based on domain metadata to learn domain-specific models. Concretely, D$^3$G learns a set of training-domain-specific functions during the training stage and reweights them based on domain relations during the test stage. These domain relations can be directly obtained and learned from domain metadata. Under mild assumptions, we theoretically prove that using domain relations to reweight training-domain-specific functions achieves stron",
    "link": "https://arxiv.org/abs/2302.02609",
    "context": "Title: Improving Domain Generalization with Domain Relations\nAbstract: arXiv:2302.02609v2 Announce Type: replace  Abstract: Distribution shift presents a significant challenge in machine learning, where models often underperform during the test stage when faced with a different distribution than the one they were trained on. This paper focuses on domain shifts, which occur when the model is applied to new domains that are different from the ones it was trained on, and propose a new approach called D$^3$G. Unlike previous methods that aim to learn a single model that is domain invariant, D$^3$G leverages domain similarities based on domain metadata to learn domain-specific models. Concretely, D$^3$G learns a set of training-domain-specific functions during the training stage and reweights them based on domain relations during the test stage. These domain relations can be directly obtained and learned from domain metadata. Under mild assumptions, we theoretically prove that using domain relations to reweight training-domain-specific functions achieves stron",
    "path": "papers/23/02/2302.02609.json",
    "total_tokens": 841,
    "translated_title": "通过领域关系改进领域泛化",
    "translated_abstract": "分布转移在机器学习中构成了一个重要挑战，当模型在测试阶段面对不同于训练时的分布时往往表现不佳。本文关注领域转移，即当模型被应用于与其训练时不同的新领域时发生的情况，并提出了一种新方法称为D$^3$G。与先前旨在学习一个领域不变模型的方法不同，D$^3$G利用基于领域元数据的领域相似性来学习特定领域的模型。具体来说，D$^3$G在训练阶段学习一组特定于训练领域的函数，并在测试阶段基于领域关系对其进行重新加权。这些领域关系可以直接从领域元数据中获得和学习。在温和的假设条件下，我们在理论上证明了利用领域关系对训练领域特定函数进行重新加权可以取得强。。。（待续）",
    "tldr": "通过利用领域关系对训练领域特定函数重新加权，D$^3$G方法能够改进领域泛化能力。",
    "en_tdlr": "By reweighting training-domain-specific functions with domain relations, the D$^3$G method improves domain generalization."
}