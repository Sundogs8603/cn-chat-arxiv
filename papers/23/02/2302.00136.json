{
    "title": "Learning Topology-Preserving Data Representations. (arXiv:2302.00136v2 [cs.LG] CROSS LISTED)",
    "abstract": "We propose a method for learning topology-preserving data representations (dimensionality reduction). The method aims to provide topological similarity between the data manifold and its latent representation via enforcing the similarity in topological features (clusters, loops, 2D voids, etc.) and their localization. The core of the method is the minimization of the Representation Topology Divergence (RTD) between original high-dimensional data and low-dimensional representation in latent space. RTD minimization provides closeness in topological features with strong theoretical guarantees. We develop a scheme for RTD differentiation and apply it as a loss term for the autoencoder. The proposed method \"RTD-AE\" better preserves the global structure and topology of the data manifold than state-of-the-art competitors as measured by linear correlation, triplet distance ranking accuracy, and Wasserstein distance between persistence barcodes.",
    "link": "http://arxiv.org/abs/2302.00136",
    "context": "Title: Learning Topology-Preserving Data Representations. (arXiv:2302.00136v2 [cs.LG] CROSS LISTED)\nAbstract: We propose a method for learning topology-preserving data representations (dimensionality reduction). The method aims to provide topological similarity between the data manifold and its latent representation via enforcing the similarity in topological features (clusters, loops, 2D voids, etc.) and their localization. The core of the method is the minimization of the Representation Topology Divergence (RTD) between original high-dimensional data and low-dimensional representation in latent space. RTD minimization provides closeness in topological features with strong theoretical guarantees. We develop a scheme for RTD differentiation and apply it as a loss term for the autoencoder. The proposed method \"RTD-AE\" better preserves the global structure and topology of the data manifold than state-of-the-art competitors as measured by linear correlation, triplet distance ranking accuracy, and Wasserstein distance between persistence barcodes.",
    "path": "papers/23/02/2302.00136.json",
    "total_tokens": 859,
    "translated_title": "学习保持拓扑结构的数据表示",
    "translated_abstract": "本文提出了一种用于学习拓扑保持数据表示（降维）的方法。该方法旨在通过强制拓扑特征（聚类、环、2D空洞等）及其本地化的相似性提供数据流形和其潜在表示之间的拓扑相似性。该方法的核心是在潜在空间中在原始高维数据和低维表示之间最小化表示拓扑散度（RTD）。RTD最小化提供了强有力的理论保证，拓扑特征的相似性。我们开发了一种RTD分化方案，并将其应用为自编码器损失项。 RTD-AE方法与现有最先进竞争对手相比，通过线性相关、三重距离排名准确性以及持久条形码之间的Wasserstein距离等测量，更好地保留了数据流形的全局结构和拓扑性。",
    "tldr": "本文提出了一种名为RTD-AE的方法用于学习保持数据拓扑结构的降维表示,在保留全局结构和拓扑性方面，其表现优于现有最先进竞争对手。",
    "en_tdlr": "This paper proposes a method called RTD-AE for learning topology-preserving data representations, which better preserves the global structure and topology of the data manifold than state-of-the-art competitors, as measured by linear correlation, triplet distance ranking accuracy, and Wasserstein distance between persistence barcodes."
}