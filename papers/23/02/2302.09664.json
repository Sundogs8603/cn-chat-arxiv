{
    "title": "Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation. (arXiv:2302.09664v3 [cs.CL] UPDATED)",
    "abstract": "We introduce a method to measure uncertainty in large language models. For tasks like question answering, it is essential to know when we can trust the natural language outputs of foundation models. We show that measuring uncertainty in natural language is challenging because of \"semantic equivalence\" -- different sentences can mean the same thing. To overcome these challenges we introduce semantic entropy -- an entropy which incorporates linguistic invariances created by shared meanings. Our method is unsupervised, uses only a single model, and requires no modifications to off-the-shelf language models. In comprehensive ablation studies we show that the semantic entropy is more predictive of model accuracy on question answering data sets than comparable baselines.",
    "link": "http://arxiv.org/abs/2302.09664",
    "context": "Title: Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation. (arXiv:2302.09664v3 [cs.CL] UPDATED)\nAbstract: We introduce a method to measure uncertainty in large language models. For tasks like question answering, it is essential to know when we can trust the natural language outputs of foundation models. We show that measuring uncertainty in natural language is challenging because of \"semantic equivalence\" -- different sentences can mean the same thing. To overcome these challenges we introduce semantic entropy -- an entropy which incorporates linguistic invariances created by shared meanings. Our method is unsupervised, uses only a single model, and requires no modifications to off-the-shelf language models. In comprehensive ablation studies we show that the semantic entropy is more predictive of model accuracy on question answering data sets than comparable baselines.",
    "path": "papers/23/02/2302.09664.json",
    "total_tokens": 828,
    "translated_title": "语义不确定性：自然语言生成不确定性估计中的语言不变量",
    "translated_abstract": "我们介绍了一种测量大型语言模型中不确定性的方法。对于像问答任务这样的任务，了解何时可以信任基础模型的自然语言输出至关重要。我们发现，由于“语义等价性”，测量自然语言的不确定性是有挑战性的——不同的句子可以表示相同的意思。为了克服这些挑战，我们引入了语义熵——一种包含共享含义所创建的语言不变量的熵。我们的方法是无监督的，仅使用单个模型，并且不需要修改现成的语言模型。在全面的消融研究中，我们展示了语义熵对于问题回答数据集上的模型准确性比可比基线更具有预测性。",
    "tldr": "本文提出了一种测量大型语言模型中不确定性的方法，引入了语义熵以克服自然语言中的“语义等价性”，该方法是无监督的，并且对于问题回答数据集上的模型准确性具有更好的预测性能。",
    "en_tdlr": "This paper proposes a method to measure uncertainty in large language models by introducing semantic entropy that incorporates linguistic invariances created by shared meanings to overcome the challenge of \"semantic equivalence.\" The method is unsupervised, uses only a single model, and requires no modifications to off-the-shelf language models. The semantic entropy is shown to be more predictive of model accuracy on question answering datasets than comparable baselines."
}