{
    "title": "Regularization and Optimization in Model-Based Clustering",
    "abstract": "Due to their conceptual simplicity, k-means algorithm variants have been extensively used for unsupervised cluster analysis. However, one main shortcoming of these algorithms is that they essentially fit a mixture of identical spherical Gaussians to data that vastly deviates from such a distribution. In comparison, general Gaussian Mixture Models (GMMs) can fit richer structures but require estimating a quadratic number of parameters per cluster to represent the covariance matrices. This poses two main issues: (i) the underlying optimization problems are challenging due to their larger number of local minima, and (ii) their solutions can overfit the data. In this work, we design search strategies that circumvent both issues. We develop more effective optimization algorithms for general GMMs, and we combine these algorithms with regularization strategies that avoid overfitting. Through extensive computational analyses, we observe that optimization or regularization in isolation does not",
    "link": "https://arxiv.org/abs/2302.02450",
    "context": "Title: Regularization and Optimization in Model-Based Clustering\nAbstract: Due to their conceptual simplicity, k-means algorithm variants have been extensively used for unsupervised cluster analysis. However, one main shortcoming of these algorithms is that they essentially fit a mixture of identical spherical Gaussians to data that vastly deviates from such a distribution. In comparison, general Gaussian Mixture Models (GMMs) can fit richer structures but require estimating a quadratic number of parameters per cluster to represent the covariance matrices. This poses two main issues: (i) the underlying optimization problems are challenging due to their larger number of local minima, and (ii) their solutions can overfit the data. In this work, we design search strategies that circumvent both issues. We develop more effective optimization algorithms for general GMMs, and we combine these algorithms with regularization strategies that avoid overfitting. Through extensive computational analyses, we observe that optimization or regularization in isolation does not",
    "path": "papers/23/02/2302.02450.json",
    "total_tokens": 897,
    "translated_title": "基于模型的聚类中的正则化和优化",
    "translated_abstract": "由于它们的概念简单性，k-means算法的变体被广泛应用于无监督聚类分析。然而，这些算法的主要缺点是它们基本上将相同的球状高斯混合适用于与这种分布大相径庭的数据。相比之下，通用的高斯混合模型（GMM）可以适应更丰富的结构，但需要估计每个簇表示协方差矩阵的二次数量的参数。这带来了两个主要问题：（i）由于局部最小值数量较多，底层的优化问题具有挑战性，（ii）它们的解决方案可能过度拟合数据。在这项工作中，我们设计了既能解决这两个问题的搜索策略。我们开发了更有效的通用GMM优化算法，并将这些算法与避免过拟合的正则化策略相结合。通过广泛的计算分析，我们观察到单独进行优化或正则化不会解决这些问题。",
    "tldr": "本论文针对基于模型的聚类中的正则化和优化提出了解决的方法，通过设计更有效的通用GMM优化算法以及结合正则化策略，解决了局部最小值数量较多以及解决方案过度拟合数据的问题。",
    "en_tdlr": "This paper proposes solutions to regularization and optimization in model-based clustering, by designing more effective optimization algorithms for general Gaussian Mixture Models (GMMs) and combining them with regularization strategies to address challenges such as a larger number of local minima and overfitting."
}