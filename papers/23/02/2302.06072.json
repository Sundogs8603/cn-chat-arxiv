{
    "title": "Actional Atomic-Concept Learning for Demystifying Vision-Language Navigation",
    "abstract": "arXiv:2302.06072v2 Announce Type: replace-cross  Abstract: Vision-Language Navigation (VLN) is a challenging task which requires an agent to align complex visual observations to language instructions to reach the goal position. Most existing VLN agents directly learn to align the raw directional features and visual features trained using one-hot labels to linguistic instruction features. However, the big semantic gap among these multi-modal inputs makes the alignment difficult and therefore limits the navigation performance. In this paper, we propose Actional Atomic-Concept Learning (AACL), which maps visual observations to actional atomic concepts for facilitating the alignment. Specifically, an actional atomic concept is a natural language phrase containing an atomic action and an object, e.g., ``go up stairs''. These actional atomic concepts, which serve as the bridge between observations and instructions, can effectively mitigate the semantic gap and simplify the alignment. AACL co",
    "link": "https://arxiv.org/abs/2302.06072",
    "context": "Title: Actional Atomic-Concept Learning for Demystifying Vision-Language Navigation\nAbstract: arXiv:2302.06072v2 Announce Type: replace-cross  Abstract: Vision-Language Navigation (VLN) is a challenging task which requires an agent to align complex visual observations to language instructions to reach the goal position. Most existing VLN agents directly learn to align the raw directional features and visual features trained using one-hot labels to linguistic instruction features. However, the big semantic gap among these multi-modal inputs makes the alignment difficult and therefore limits the navigation performance. In this paper, we propose Actional Atomic-Concept Learning (AACL), which maps visual observations to actional atomic concepts for facilitating the alignment. Specifically, an actional atomic concept is a natural language phrase containing an atomic action and an object, e.g., ``go up stairs''. These actional atomic concepts, which serve as the bridge between observations and instructions, can effectively mitigate the semantic gap and simplify the alignment. AACL co",
    "path": "papers/23/02/2302.06072.json",
    "total_tokens": 912,
    "translated_title": "行动性原子概念学习用于解密视觉语言导航",
    "translated_abstract": "arXiv:2302.06072v2 公告类型：替换-跨摘要：视觉语言导航（VLN）是一项具有挑战性的任务，需要一个代理人将复杂的视觉观察结果与语言指令对齐，以达到目标位置。大多数现有的VLN代理直接学习将原始方向特征和使用一位标签训练的视觉特征与语言指令特征对齐。然而，这些多模态输入之间存在较大的语义差距使得对齐变得困难，从而限制了导航性能。在本文中，我们提出了行动性原子概念学习（AACL），它将视觉观察结果映射到行动性原子概念以促进对齐。具体而言，行动性原子概念是包含原子动作和对象的自然语言短语，例如“上楼梯”。这些行动性原子概念作为观察和指令之间的桥梁，可以有效减少语义差距并简化对齐。AACL",
    "tldr": "提出了行动性原子概念学习（AACL）方法，将视觉观察映射到行动性原子概念，作为观察和指令之间的桥梁，减少语义差距并简化对齐。"
}