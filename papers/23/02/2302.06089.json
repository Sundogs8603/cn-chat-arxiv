{
    "title": "Federated contrastive learning models for prostate cancer diagnosis and Gleason grading. (arXiv:2302.06089v3 [cs.CV] UPDATED)",
    "abstract": "The application effect of artificial intelligence (AI) in the field of medical imaging is remarkable. Robust AI model training requires large datasets, but data collection faces communication, ethics, and privacy protection constraints. Fortunately, federated learning can solve the above problems by coordinating multiple clients to train the model without sharing the original data. In this study, we design a federated contrastive learning framework (FCL) for large-scale pathology images and the heterogeneity challenges. It enhances the model's generalization ability by maximizing the attention consistency between the local client and server models. To alleviate the privacy leakage problem when transferring parameters and verify the robustness of FCL, we use differential privacy to further protect the model by adding noise. We evaluate the effectiveness of FCL on the cancer diagnosis task and Gleason grading task on 19,635 prostate cancer WSIs from multiple clients. In the diagnosis tas",
    "link": "http://arxiv.org/abs/2302.06089",
    "context": "Title: Federated contrastive learning models for prostate cancer diagnosis and Gleason grading. (arXiv:2302.06089v3 [cs.CV] UPDATED)\nAbstract: The application effect of artificial intelligence (AI) in the field of medical imaging is remarkable. Robust AI model training requires large datasets, but data collection faces communication, ethics, and privacy protection constraints. Fortunately, federated learning can solve the above problems by coordinating multiple clients to train the model without sharing the original data. In this study, we design a federated contrastive learning framework (FCL) for large-scale pathology images and the heterogeneity challenges. It enhances the model's generalization ability by maximizing the attention consistency between the local client and server models. To alleviate the privacy leakage problem when transferring parameters and verify the robustness of FCL, we use differential privacy to further protect the model by adding noise. We evaluate the effectiveness of FCL on the cancer diagnosis task and Gleason grading task on 19,635 prostate cancer WSIs from multiple clients. In the diagnosis tas",
    "path": "papers/23/02/2302.06089.json",
    "total_tokens": 1125,
    "translated_title": "面向前列腺癌诊断和格里森分级的联邦对比学习模型",
    "translated_abstract": "人工智能在医学影像领域的应用效果显著。然而，稳健的人工智能模型训练需要大规模的数据集，但数据收集面临沟通、伦理和隐私保护等限制。联邦学习可以通过协调多个客户端训练模型而不共享原始数据来解决上述问题。本研究设计了一个面向大规模病理图像和异质性挑战的联邦对比学习框架（FCL），通过最大化本地客户端和服务器模型间的注意力一致性来增强模型的泛化能力。为了缓解参数传输中的隐私泄露问题并验证FCL的稳健性，我们使用差分隐私通过添加噪音进一步保护模型。我们在19,635个来自多个客户端的前列腺癌WSI上评估了FCL在癌症诊断任务和格里森分级任务中的有效性。在诊断任务中，我们实现了区分癌性和非癌性WSI的0.99的曲线下面积（AUC）。在格里森分级任务中，我们的FCL模型实现了一个均方误差（MSE）为0.143，相比最先进的方法降低了21.7％。",
    "tldr": "该研究提出了一个面向大规模病理图像和异质性挑战的联邦对比学习模型（FCL），通过最大化本地客户端和服务器模型间的注意力一致性来增强模型的泛化能力。 在前列腺癌诊断和格里森分级任务中，FCL表现出优异的性能。"
}