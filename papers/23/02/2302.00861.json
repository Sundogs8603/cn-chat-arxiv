{
    "title": "SimMTM: A Simple Pre-Training Framework for Masked Time-Series Modeling. (arXiv:2302.00861v3 [cs.LG] UPDATED)",
    "abstract": "Time series analysis is widely used in extensive areas. Recently, to reduce labeling expenses and benefit various tasks, self-supervised pre-training has attracted immense interest. One mainstream paradigm is masked modeling, which successfully pre-trains deep models by learning to reconstruct the masked content based on the unmasked part. However, since the semantic information of time series is mainly contained in temporal variations, the standard way of randomly masking a portion of time points will seriously ruin vital temporal variations of time series, making the reconstruction task too difficult to guide representation learning. We thus present SimMTM, a Simple pre-training framework for Masked Time-series Modeling. By relating masked modeling to manifold learning, SimMTM proposes to recover masked time points by the weighted aggregation of multiple neighbors outside the manifold, which eases the reconstruction task by assembling ruined but complementary temporal variations from",
    "link": "http://arxiv.org/abs/2302.00861",
    "context": "Title: SimMTM: A Simple Pre-Training Framework for Masked Time-Series Modeling. (arXiv:2302.00861v3 [cs.LG] UPDATED)\nAbstract: Time series analysis is widely used in extensive areas. Recently, to reduce labeling expenses and benefit various tasks, self-supervised pre-training has attracted immense interest. One mainstream paradigm is masked modeling, which successfully pre-trains deep models by learning to reconstruct the masked content based on the unmasked part. However, since the semantic information of time series is mainly contained in temporal variations, the standard way of randomly masking a portion of time points will seriously ruin vital temporal variations of time series, making the reconstruction task too difficult to guide representation learning. We thus present SimMTM, a Simple pre-training framework for Masked Time-series Modeling. By relating masked modeling to manifold learning, SimMTM proposes to recover masked time points by the weighted aggregation of multiple neighbors outside the manifold, which eases the reconstruction task by assembling ruined but complementary temporal variations from",
    "path": "papers/23/02/2302.00861.json",
    "total_tokens": 867,
    "translated_title": "SimMTM: 一种用于序列模型的简单预训练框架",
    "translated_abstract": "时间序列分析广泛应用于许多领域。为了降低标注成本并受益于各种任务，最近，自监督预训练引起了极大的兴趣。其中一种主流范例是掩码建模，它通过学习基于未掩码部分的掩码内容的重构，成功地预训练深度模型。但是，由于时间序列的语义信息主要包含在时间变化中，标准的随机屏蔽一部分时间点的方式会严重破坏时间序列的重要时间变化，使重构任务过于困难，无法引导表示学习。因此，我们提出了一个用于序列模型的简单预训练框架SimMTM。通过将掩码建模与流形学习相关联，SimMTM提出通过多个流形之外的邻居的加权聚合来恢复掩码时间点，从而通过组装被破坏但互补的时间变化来简化重构任务。",
    "tldr": "SimMTM是一个简单的序列模型预训练框架，通过加权聚合多个流形之外的邻居来恢复掩码时间点，从而简化重构任务。",
    "en_tdlr": "SimMTM is a simple pre-training framework for sequence models, which recovers masked time points by weighted aggregating multiple neighbors outside the manifold, thereby simplifying the reconstruction task."
}