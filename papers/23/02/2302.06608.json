{
    "title": "3D-aware Blending with Generative NeRFs. (arXiv:2302.06608v2 [cs.CV] UPDATED)",
    "abstract": "Image blending aims to combine multiple images seamlessly. It remains challenging for existing 2D-based methods, especially when input images are misaligned due to differences in 3D camera poses and object shapes. To tackle these issues, we propose a 3D-aware blending method using generative Neural Radiance Fields (NeRF), including two key components: 3D-aware alignment and 3D-aware blending. For 3D-aware alignment, we first estimate the camera pose of the reference image with respect to generative NeRFs and then perform 3D local alignment for each part. To further leverage 3D information of the generative NeRF, we propose 3D-aware blending that directly blends images on the NeRF's latent representation space, rather than raw pixel space. Collectively, our method outperforms existing 2D baselines, as validated by extensive quantitative and qualitative evaluations with FFHQ and AFHQ-Cat.",
    "link": "http://arxiv.org/abs/2302.06608",
    "context": "Title: 3D-aware Blending with Generative NeRFs. (arXiv:2302.06608v2 [cs.CV] UPDATED)\nAbstract: Image blending aims to combine multiple images seamlessly. It remains challenging for existing 2D-based methods, especially when input images are misaligned due to differences in 3D camera poses and object shapes. To tackle these issues, we propose a 3D-aware blending method using generative Neural Radiance Fields (NeRF), including two key components: 3D-aware alignment and 3D-aware blending. For 3D-aware alignment, we first estimate the camera pose of the reference image with respect to generative NeRFs and then perform 3D local alignment for each part. To further leverage 3D information of the generative NeRF, we propose 3D-aware blending that directly blends images on the NeRF's latent representation space, rather than raw pixel space. Collectively, our method outperforms existing 2D baselines, as validated by extensive quantitative and qualitative evaluations with FFHQ and AFHQ-Cat.",
    "path": "papers/23/02/2302.06608.json",
    "total_tokens": 915,
    "translated_title": "具有生成式NeRF的3D感知融合",
    "translated_abstract": "图像融合旨在无缝地合并多个图像。对于现有的基于2D的方法来说，如果输入图像由于3D相机姿态和物体形状的差异而不对齐，仍然具有挑战性。为了解决这些问题，我们提出了一种使用生成式神经辐射场（NeRF）的3D感知融合方法，包括两个关键组件：3D感知对齐和3D感知融合。对于3D感知对齐，我们首先估计与生成式NeRF相关的参考图像的相机姿态，然后对每个部分进行3D局部对齐。为了进一步利用生成式NeRF的3D信息，我们提出了基于3D感知的融合，它直接在NeRF的潜在表示空间上进行图像融合，而不是在原始像素空间上进行。通过对FFHQ和AFHQ-Cat进行广泛的定量和定性评估，我们的方法优于现有的2D基线。",
    "tldr": "这篇论文提出了一种使用生成式NeRF的3D感知融合方法，通过3D感知对齐和融合来解决输入图像不对齐的问题，该方法在FFHQ和AFHQ-Cat上验证了优于现有2D方法的性能。"
}