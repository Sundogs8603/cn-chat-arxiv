{
    "title": "Multimodal LLMs for health grounded in individual-specific data. (arXiv:2307.09018v1 [q-bio.QM])",
    "abstract": "Foundation large language models (LLMs) have shown an impressive ability to solve tasks across a wide range of fields including health. To effectively solve personalized health tasks, LLMs need the ability to ingest a diversity of data modalities that are relevant to an individual's health status. In this paper, we take a step towards creating multimodal LLMs for health that are grounded in individual-specific data by developing a framework (HeLM: Health Large Language Model for Multimodal Understanding) that enables LLMs to use high-dimensional clinical modalities to estimate underlying disease risk. HeLM encodes complex data modalities by learning an encoder that maps them into the LLM's token embedding space and for simple modalities like tabular data by serializing the data into text. Using data from the UK Biobank, we show that HeLM can effectively use demographic and clinical features in addition to high-dimensional time-series data to estimate disease risk. For example, HeLM ach",
    "link": "http://arxiv.org/abs/2307.09018",
    "context": "Title: Multimodal LLMs for health grounded in individual-specific data. (arXiv:2307.09018v1 [q-bio.QM])\nAbstract: Foundation large language models (LLMs) have shown an impressive ability to solve tasks across a wide range of fields including health. To effectively solve personalized health tasks, LLMs need the ability to ingest a diversity of data modalities that are relevant to an individual's health status. In this paper, we take a step towards creating multimodal LLMs for health that are grounded in individual-specific data by developing a framework (HeLM: Health Large Language Model for Multimodal Understanding) that enables LLMs to use high-dimensional clinical modalities to estimate underlying disease risk. HeLM encodes complex data modalities by learning an encoder that maps them into the LLM's token embedding space and for simple modalities like tabular data by serializing the data into text. Using data from the UK Biobank, we show that HeLM can effectively use demographic and clinical features in addition to high-dimensional time-series data to estimate disease risk. For example, HeLM ach",
    "path": "papers/23/07/2307.09018.json",
    "total_tokens": 855,
    "translated_title": "基于个体专属数据的多模态健康大型语言模型",
    "translated_abstract": "基于个体专属数据的健康大型语言模型（LLMs）可以有效地解决个性化健康问题，但为了实现这一目标，LLMs需要具备摄入与个体健康状况相关的多样化数据模态能力。本文提出了一个框架（HeLM：健康大型语言模型多模态理解），该框架通过开发一个编码器，将复杂的数据模态映射到LLMs的令牌嵌入空间，并将简单的模态如表格数据序列化为文本，实现了基于个体专属数据的多模态LLMs。通过使用来自英国生物库的数据，我们证明了HeLM能够有效地利用人口统计学和临床特征，以及高维时间序列数据来估计疾病风险。",
    "tldr": "本文提出了一个多模态健康大型语言模型（HeLM），通过学习复杂数据模态的编码器，同时支持简单模态数据的文本序列化，HeLM可以有效地使用个体专属数据估计疾病风险。",
    "en_tdlr": "This paper introduces a multimodal health large language model (HeLM) that effectively utilizes individual-specific data to estimate disease risk by learning an encoder for complex data modalities and serializing simple modalities into text."
}