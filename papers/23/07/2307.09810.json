{
    "title": "GenKL: An Iterative Framework for Resolving Label Ambiguity and Label Non-conformity in Web Images Via a New Generalized KL Divergence. (arXiv:2307.09810v1 [cs.CV])",
    "abstract": "Web image datasets curated online inherently contain ambiguous in-distribution (ID) instances and out-of-distribution (OOD) instances, which we collectively call non-conforming (NC) instances. In many recent approaches for mitigating the negative effects of NC instances, the core implicit assumption is that the NC instances can be found via entropy maximization. For \"entropy\" to be well-defined, we are interpreting the output prediction vector of an instance as the parameter vector of a multinomial random variable, with respect to some trained model with a softmax output layer. Hence, entropy maximization is based on the idealized assumption that NC instances have predictions that are \"almost\" uniformly distributed. However, in real-world web image datasets, there are numerous NC instances whose predictions are far from being uniformly distributed. To tackle the limitation of entropy maximization, we propose $(\\alpha, \\beta)$-generalized KL divergence, $\\mathcal{D}_{\\text{KL}}^{\\alpha,",
    "link": "http://arxiv.org/abs/2307.09810",
    "context": "Title: GenKL: An Iterative Framework for Resolving Label Ambiguity and Label Non-conformity in Web Images Via a New Generalized KL Divergence. (arXiv:2307.09810v1 [cs.CV])\nAbstract: Web image datasets curated online inherently contain ambiguous in-distribution (ID) instances and out-of-distribution (OOD) instances, which we collectively call non-conforming (NC) instances. In many recent approaches for mitigating the negative effects of NC instances, the core implicit assumption is that the NC instances can be found via entropy maximization. For \"entropy\" to be well-defined, we are interpreting the output prediction vector of an instance as the parameter vector of a multinomial random variable, with respect to some trained model with a softmax output layer. Hence, entropy maximization is based on the idealized assumption that NC instances have predictions that are \"almost\" uniformly distributed. However, in real-world web image datasets, there are numerous NC instances whose predictions are far from being uniformly distributed. To tackle the limitation of entropy maximization, we propose $(\\alpha, \\beta)$-generalized KL divergence, $\\mathcal{D}_{\\text{KL}}^{\\alpha,",
    "path": "papers/23/07/2307.09810.json",
    "total_tokens": 917,
    "translated_title": "GenKL：通过新的广义KL散度，解决Web图像中的标签模糊和标签不符的迭代框架",
    "translated_abstract": "在在线整理的Web图像数据集中，存在着模糊（ID）实例和非符合（OOD）实例，我们统称为非符合（NC）实例。在许多最近的解决NC实例产生的负面影响的方法中，核心的隐含假设是可以通过最大熵来找到NC实例。为了定义\"熵\"，我们将一个实例的输出预测向量解释为一个多项式随机变量的参数向量，相对于一些具有softmax输出层的训练模型。因此，熵最大化是基于理想化假设，即NC实例的预测是\"几乎\"均匀分布的。然而，在现实世界的Web图像数据集中，有许多NC实例的预测远非均匀分布。为了解决熵最大化的限制，我们提出了$(\\alpha, \\beta)$-广义KL散度，$\\mathcal{D}_{\\text{KL}}^{\\alpha, beta}$，从而允许更好地处理非均匀分布和标签模糊性。",
    "tldr": "提出了一个新的迭代框架GenKL，通过$(\\alpha, \\beta)$-广义KL散度来解决Web图像中的标签模糊和非符合实例的问题。",
    "en_tdlr": "A new iterative framework called GenKL is proposed to address label ambiguity and label non-conformity in web images using $(\\alpha, \\beta)$-generalized KL divergence."
}