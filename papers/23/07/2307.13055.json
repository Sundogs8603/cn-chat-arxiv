{
    "title": "MARIO: Model Agnostic Recipe for Improving OOD Generalization of Graph Contrastive Learning. (arXiv:2307.13055v1 [cs.LG])",
    "abstract": "In this work, we investigate the problem of out-of-distribution (OOD) generalization for unsupervised learning methods on graph data. This scenario is particularly challenging because graph neural networks (GNNs) have been shown to be sensitive to distributional shifts, even when labels are available. To address this challenge, we propose a \\underline{M}odel-\\underline{A}gnostic \\underline{R}ecipe for \\underline{I}mproving \\underline{O}OD generalizability of unsupervised graph contrastive learning methods, which we refer to as MARIO. MARIO introduces two principles aimed at developing distributional-shift-robust graph contrastive methods to overcome the limitations of existing frameworks: (i) Information Bottleneck (IB) principle for achieving generalizable representations and (ii) Invariant principle that incorporates adversarial data augmentation to obtain invariant representations. To the best of our knowledge, this is the first work that investigates the OOD generalization problem ",
    "link": "http://arxiv.org/abs/2307.13055",
    "context": "Title: MARIO: Model Agnostic Recipe for Improving OOD Generalization of Graph Contrastive Learning. (arXiv:2307.13055v1 [cs.LG])\nAbstract: In this work, we investigate the problem of out-of-distribution (OOD) generalization for unsupervised learning methods on graph data. This scenario is particularly challenging because graph neural networks (GNNs) have been shown to be sensitive to distributional shifts, even when labels are available. To address this challenge, we propose a \\underline{M}odel-\\underline{A}gnostic \\underline{R}ecipe for \\underline{I}mproving \\underline{O}OD generalizability of unsupervised graph contrastive learning methods, which we refer to as MARIO. MARIO introduces two principles aimed at developing distributional-shift-robust graph contrastive methods to overcome the limitations of existing frameworks: (i) Information Bottleneck (IB) principle for achieving generalizable representations and (ii) Invariant principle that incorporates adversarial data augmentation to obtain invariant representations. To the best of our knowledge, this is the first work that investigates the OOD generalization problem ",
    "path": "papers/23/07/2307.13055.json",
    "total_tokens": 854,
    "translated_title": "MARIO: 用于改善图对比学习的模型无关配方，提高OOD泛化性能",
    "translated_abstract": "在这项工作中，我们研究了图数据上无监督学习方法的域外泛化问题。这种情况特别具有挑战性，因为即使有标签，图神经网络(GNNs)也显示出对分布偏移的敏感性。为了解决这个挑战，我们提出了一种名为MARIO的模型无关配方，旨在开发具有分布偏移鲁棒性的图对比方法，克服现有框架的局限性：(i)信息瓶颈(IB)原则用于实现可泛化的表示，(ii)不变性原则采用对抗性数据增强来获得不变表示。据我们所知，这是第一项研究OOD泛化问题的工作",
    "tldr": "提出了一个模型无关配方MARIO，用于改善图对比学习的OOD泛化性能。MARIO引入了信息瓶颈原则和不变性原则，旨在获得具有分布偏移鲁棒性和不变性的图表示。",
    "en_tdlr": "A model-agnostic recipe named MARIO is proposed to improve OOD generalization of graph contrastive learning. MARIO introduces the principles of information bottleneck and invariance to obtain distributional-shift-robust and invariant graph representations."
}