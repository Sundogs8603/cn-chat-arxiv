{
    "title": "Fair Machine Unlearning: Data Removal while Mitigating Disparities. (arXiv:2307.14754v1 [cs.LG])",
    "abstract": "As public consciousness regarding the collection and use of personal information by corporations grows, it is of increasing importance that consumers be active participants in the curation of corporate datasets. In light of this, data governance frameworks such as the General Data Protection Regulation (GDPR) have outlined the right to be forgotten as a key principle allowing individuals to request that their personal data be deleted from the databases and models used by organizations. To achieve forgetting in practice, several machine unlearning methods have been proposed to address the computational inefficiencies of retraining a model from scratch with each unlearning request. While efficient online alternatives to retraining, it is unclear how these methods impact other properties critical to real-world applications, such as fairness. In this work, we propose the first fair machine unlearning method that can provably and efficiently unlearn data instances while preserving group fai",
    "link": "http://arxiv.org/abs/2307.14754",
    "context": "Title: Fair Machine Unlearning: Data Removal while Mitigating Disparities. (arXiv:2307.14754v1 [cs.LG])\nAbstract: As public consciousness regarding the collection and use of personal information by corporations grows, it is of increasing importance that consumers be active participants in the curation of corporate datasets. In light of this, data governance frameworks such as the General Data Protection Regulation (GDPR) have outlined the right to be forgotten as a key principle allowing individuals to request that their personal data be deleted from the databases and models used by organizations. To achieve forgetting in practice, several machine unlearning methods have been proposed to address the computational inefficiencies of retraining a model from scratch with each unlearning request. While efficient online alternatives to retraining, it is unclear how these methods impact other properties critical to real-world applications, such as fairness. In this work, we propose the first fair machine unlearning method that can provably and efficiently unlearn data instances while preserving group fai",
    "path": "papers/23/07/2307.14754.json",
    "total_tokens": 780,
    "translated_title": "公平机器遗忘：在减少差异的同时删除数据",
    "translated_abstract": "随着公众对企业收集和使用个人信息的意识增强，消费者积极参与企业数据集的管理变得越来越重要。为此，数据管理框架（如欧洲通用数据保护条例）已经提出了被遗忘的权利，允许个人请求将其个人数据从组织使用的数据库和模型中删除。为了实现遗忘，已经提出了几种机器学习遗忘方法，以解决每个遗忘请求重新训练模型的计算效率问题。虽然这些在线替代方案可以高效地进行遗忘，但它们对于其他关键的实际应用属性（如公平性）的影响尚不清楚。在这项工作中，我们提出了第一个能够可靠而高效地遗忘数据实例并保持公平性的方法。",
    "tldr": "本研究提出了第一个能够可靠而高效地遗忘数据实例并保持公平性的机器学习方法。",
    "en_tdlr": "This paper introduces the first machine learning method that can reliably and efficiently unlearn data instances while preserving fairness."
}