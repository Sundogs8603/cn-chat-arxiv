{
    "title": "Adaptively Optimised Adaptive Importance Samplers. (arXiv:2307.09341v1 [stat.CO])",
    "abstract": "We introduce a new class of adaptive importance samplers leveraging adaptive optimisation tools, which we term AdaOAIS. We build on Optimised Adaptive Importance Samplers (OAIS), a class of techniques that adapt proposals to improve the mean-squared error of the importance sampling estimators by parameterising the proposal and optimising the $\\chi^2$-divergence between the target and the proposal. We show that a naive implementation of OAIS using stochastic gradient descent may lead to unstable estimators despite its convergence guarantees. To remedy this shortcoming, we instead propose to use adaptive optimisers (such as AdaGrad and Adam) to improve the stability of the OAIS. We provide convergence results for AdaOAIS in a similar manner to OAIS. We also provide empirical demonstration on a variety of examples and show that AdaOAIS lead to stable importance sampling estimators in practice.",
    "link": "http://arxiv.org/abs/2307.09341",
    "context": "Title: Adaptively Optimised Adaptive Importance Samplers. (arXiv:2307.09341v1 [stat.CO])\nAbstract: We introduce a new class of adaptive importance samplers leveraging adaptive optimisation tools, which we term AdaOAIS. We build on Optimised Adaptive Importance Samplers (OAIS), a class of techniques that adapt proposals to improve the mean-squared error of the importance sampling estimators by parameterising the proposal and optimising the $\\chi^2$-divergence between the target and the proposal. We show that a naive implementation of OAIS using stochastic gradient descent may lead to unstable estimators despite its convergence guarantees. To remedy this shortcoming, we instead propose to use adaptive optimisers (such as AdaGrad and Adam) to improve the stability of the OAIS. We provide convergence results for AdaOAIS in a similar manner to OAIS. We also provide empirical demonstration on a variety of examples and show that AdaOAIS lead to stable importance sampling estimators in practice.",
    "path": "papers/23/07/2307.09341.json",
    "total_tokens": 885,
    "translated_title": "自适应优化的自适应重要性采样器",
    "translated_abstract": "我们引入了一种新的自适应重要性采样器类别，借助自适应优化工具，称之为AdaOAIS。我们借鉴了优化自适应重要性采样器（OAIS）的技术，该技术通过参数化提议并优化目标与提议之间的$\\chi^2$-散度，来改善重要性采样估计量的均方误差。我们发现，尽管随机梯度下降法保证收敛，但OAIS的朴素实现可能导致不稳定的估计器。为了解决这个缺点，我们提出改用自适应优化器（如AdaGrad和Adam）来提高OAIS的稳定性。我们以类似于OAIS的方式提供了AdaOAIS的收敛结果。我们还在各种示例上进行了实证演示，并表明AdaOAIS在实践中可以产生稳定的重要性采样估计器。",
    "tldr": "论文介绍了一种利用自适应优化工具的自适应重要性采样器，称为AdaOAIS。通过使用自适应优化器改善了优化自适应重要性采样器的稳定性，并在实例中展示了其稳定的重要性采样估计器。",
    "en_tdlr": "The paper introduces a new class of adaptive importance samplers, AdaOAIS, that leverages adaptive optimization tools. By using adaptive optimizers, the stability of the Optimized Adaptive Importance Samplers (OAIS) is improved, and empirical demonstration shows the stability of the importance sampling estimators."
}