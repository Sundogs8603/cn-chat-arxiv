{
    "title": "Towards Trustworthy Dataset Distillation. (arXiv:2307.09165v1 [cs.LG])",
    "abstract": "Efficiency and trustworthiness are two eternal pursuits when applying deep learning in real-world applications. With regard to efficiency, dataset distillation (DD) endeavors to reduce training costs by distilling the large dataset into a tiny synthetic dataset. However, existing methods merely concentrate on in-distribution (InD) classification in a closed-world setting, disregarding out-of-distribution (OOD) samples. On the other hand, OOD detection aims to enhance models' trustworthiness, which is always inefficiently achieved in full-data settings. For the first time, we simultaneously consider both issues and propose a novel paradigm called Trustworthy Dataset Distillation (TrustDD). By distilling both InD samples and outliers, the condensed datasets are capable to train models competent in both InD classification and OOD detection. To alleviate the requirement of real outlier data and make OOD detection more practical, we further propose to corrupt InD samples to generate pseudo-",
    "link": "http://arxiv.org/abs/2307.09165",
    "context": "Title: Towards Trustworthy Dataset Distillation. (arXiv:2307.09165v1 [cs.LG])\nAbstract: Efficiency and trustworthiness are two eternal pursuits when applying deep learning in real-world applications. With regard to efficiency, dataset distillation (DD) endeavors to reduce training costs by distilling the large dataset into a tiny synthetic dataset. However, existing methods merely concentrate on in-distribution (InD) classification in a closed-world setting, disregarding out-of-distribution (OOD) samples. On the other hand, OOD detection aims to enhance models' trustworthiness, which is always inefficiently achieved in full-data settings. For the first time, we simultaneously consider both issues and propose a novel paradigm called Trustworthy Dataset Distillation (TrustDD). By distilling both InD samples and outliers, the condensed datasets are capable to train models competent in both InD classification and OOD detection. To alleviate the requirement of real outlier data and make OOD detection more practical, we further propose to corrupt InD samples to generate pseudo-",
    "path": "papers/23/07/2307.09165.json",
    "total_tokens": 930,
    "translated_title": "迈向可信赖的数据集精炼",
    "translated_abstract": "在将深度学习应用于实际应用时，效率和可信赖性是两个永恒的追求。就效率而言，数据集精炼（DD）致力于通过将大型数据集精炼为小型合成数据集来降低训练成本。然而，现有方法仅集中于在封闭世界环境下的内部分布（InD）分类，忽略了外部分布（OOD）样本。另一方面，OOD检测旨在提高模型的可信赖性，在完整数据设置下通常效率低下。我们首次同时考虑了这两个问题，并提出了一种新的范式，称为可信赖的数据集精炼（TrustDD）。通过精炼InD样本和异常值，这些被筛选的数据集能够训练出既擅长InD分类又能进行OOD检测的模型。为了缓解对真实异常值数据的需求，并使OOD检测更加实用，我们进一步提出了对InD样本损坏以生成伪样本的方法。",
    "tldr": "本论文提出了一种名为可信赖的数据集精炼（TrustDD）的新范式，通过同时考虑内部分布（InD）分类和外部分布（OOD）检测的问题，将大型数据集精炼为小型合成数据集，从而提高模型的效率和可信赖性。"
}