{
    "title": "Federated Split Learning with Only Positive Labels for resource-constrained IoT environment. (arXiv:2307.13266v1 [cs.LG])",
    "abstract": "Distributed collaborative machine learning (DCML) is a promising method in the Internet of Things (IoT) domain for training deep learning models, as data is distributed across multiple devices. A key advantage of this approach is that it improves data privacy by removing the necessity for the centralized aggregation of raw data but also empowers IoT devices with low computational power. Among various techniques in a DCML framework, federated split learning, known as splitfed learning (SFL), is the most suitable for efficient training and testing when devices have limited computational capabilities. Nevertheless, when resource-constrained IoT devices have only positive labeled data, multiclass classification deep learning models in SFL fail to converge or provide suboptimal results. To overcome these challenges, we propose splitfed learning with positive labels (SFPL). SFPL applies a random shuffling function to the smashed data received from clients before supplying it to the server fo",
    "link": "http://arxiv.org/abs/2307.13266",
    "context": "Title: Federated Split Learning with Only Positive Labels for resource-constrained IoT environment. (arXiv:2307.13266v1 [cs.LG])\nAbstract: Distributed collaborative machine learning (DCML) is a promising method in the Internet of Things (IoT) domain for training deep learning models, as data is distributed across multiple devices. A key advantage of this approach is that it improves data privacy by removing the necessity for the centralized aggregation of raw data but also empowers IoT devices with low computational power. Among various techniques in a DCML framework, federated split learning, known as splitfed learning (SFL), is the most suitable for efficient training and testing when devices have limited computational capabilities. Nevertheless, when resource-constrained IoT devices have only positive labeled data, multiclass classification deep learning models in SFL fail to converge or provide suboptimal results. To overcome these challenges, we propose splitfed learning with positive labels (SFPL). SFPL applies a random shuffling function to the smashed data received from clients before supplying it to the server fo",
    "path": "papers/23/07/2307.13266.json",
    "total_tokens": 894,
    "translated_title": "仅使用正标签的资源受限物联网环境中的联邦分割学习",
    "translated_abstract": "分布式协作机器学习（DCML）是物联网领域中训练深度学习模型的一种有前景的方法，因为数据分布在多个设备上。这种方法的一个主要优点是通过消除原始数据的集中聚合来改善数据隐私，同时也为具有低计算能力的物联网设备提供动力。在DCML框架中的各种技术中，称为splitfed学习（SFL）的联邦分割学习是在设备具有有限计算能力时进行高效训练和测试的最合适的方法。然而，当资源受限的物联网设备只有正标记数据时，SFL中的多类别分类深度学习模型无法收敛或提供次优结果。为了克服这些挑战，我们提出了带有正标签的splitfed学习（SFPL）。SFPL在将客户端接收到的破碎数据提供给服务器之前，对其应用随机洗牌功能。",
    "tldr": "在资源受限的物联网环境中，我们提出了带有正标签的分割学习（SFPL）方法，通过对数据进行随机洗牌来改善多类别分类深度学习模型在联邦分割学习中的效果。",
    "en_tdlr": "In resource-constrained IoT environments, we propose splitfed learning with positive labels (SFPL) to improve the performance of multiclass classification deep learning models in federated split learning by applying random shuffling to the data."
}