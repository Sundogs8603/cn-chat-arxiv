{
    "title": "VerifAI: Verified Generative AI. (arXiv:2307.02796v1 [cs.DB])",
    "abstract": "Generative AI has made significant strides, yet concerns about the accuracy and reliability of its outputs continue to grow. Such inaccuracies can have serious consequences such as inaccurate decision-making, the spread of false information, privacy violations, legal liabilities, and more. Although efforts to address these risks are underway, including explainable AI and responsible AI practices such as transparency, privacy protection, bias mitigation, and social and environmental responsibility, misinformation caused by generative AI will remain a significant challenge. We propose that verifying the outputs of generative AI from a data management perspective is an emerging issue for generative AI. This involves analyzing the underlying data from multi-modal data lakes, including text files, tables, and knowledge graphs, and assessing its quality and consistency. By doing so, we can establish a stronger foundation for evaluating the outputs of generative AI models. Such an approach ca",
    "link": "http://arxiv.org/abs/2307.02796",
    "context": "Title: VerifAI: Verified Generative AI. (arXiv:2307.02796v1 [cs.DB])\nAbstract: Generative AI has made significant strides, yet concerns about the accuracy and reliability of its outputs continue to grow. Such inaccuracies can have serious consequences such as inaccurate decision-making, the spread of false information, privacy violations, legal liabilities, and more. Although efforts to address these risks are underway, including explainable AI and responsible AI practices such as transparency, privacy protection, bias mitigation, and social and environmental responsibility, misinformation caused by generative AI will remain a significant challenge. We propose that verifying the outputs of generative AI from a data management perspective is an emerging issue for generative AI. This involves analyzing the underlying data from multi-modal data lakes, including text files, tables, and knowledge graphs, and assessing its quality and consistency. By doing so, we can establish a stronger foundation for evaluating the outputs of generative AI models. Such an approach ca",
    "path": "papers/23/07/2307.02796.json",
    "total_tokens": 920,
    "translated_title": "VerifAI：验证生成式人工智能",
    "translated_abstract": "生成式人工智能已经取得了重要的进展，但是对于其输出的准确性和可靠性的担忧仍在增长。这种不准确性可能产生严重后果，如错误决策，传播虚假信息，侵犯隐私，法律责任等。虽然已经在进行应对这些风险的努力，包括可解释的人工智能和负责任的人工智能实践，如透明度，隐私保护，偏见缓解以及社会和环境责任等，但由生成式人工智能引起的错误信息仍然是一个重大挑战。我们提出，从数据管理的角度验证生成式人工智能的输出是生成式人工智能的一个新兴问题。这包括分析来自多模态数据湖的底层数据，包括文本文件，表格和知识图谱，并评估其质量和一致性。通过这样做，我们可以为评估生成式人工智能模型的输出奠定更坚实的基础。这种方法能够帮助解决生成式人工智能的输出验证问题。",
    "tldr": "验证生成式人工智能的输出是一个新兴问题，我们提出了通过分析多模态数据湖的底层数据，评估其质量和一致性，来建立评估生成式人工智能模型输出的更坚实基础，并解决错误信息传播的挑战。",
    "en_tdlr": "Verifying the outputs of generative AI is an emerging issue, and we propose analyzing underlying data from multi-modal data lakes to establish a stronger foundation for evaluating the outputs of generative AI models and address the challenge of misinformation spread."
}