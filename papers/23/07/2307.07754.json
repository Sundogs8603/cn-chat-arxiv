{
    "title": "Bidirectionally Deformable Motion Modulation For Video-based Human Pose Transfer. (arXiv:2307.07754v1 [cs.CV])",
    "abstract": "Video-based human pose transfer is a video-to-video generation task that animates a plain source human image based on a series of target human poses. Considering the difficulties in transferring highly structural patterns on the garments and discontinuous poses, existing methods often generate unsatisfactory results such as distorted textures and flickering artifacts. To address these issues, we propose a novel Deformable Motion Modulation (DMM) that utilizes geometric kernel offset with adaptive weight modulation to simultaneously perform feature alignment and style transfer. Different from normal style modulation used in style transfer, the proposed modulation mechanism adaptively reconstructs smoothed frames from style codes according to the object shape through an irregular receptive field of view. To enhance the spatio-temporal consistency, we leverage bidirectional propagation to extract the hidden motion information from a warped image sequence generated by noisy poses. The prop",
    "link": "http://arxiv.org/abs/2307.07754",
    "context": "Title: Bidirectionally Deformable Motion Modulation For Video-based Human Pose Transfer. (arXiv:2307.07754v1 [cs.CV])\nAbstract: Video-based human pose transfer is a video-to-video generation task that animates a plain source human image based on a series of target human poses. Considering the difficulties in transferring highly structural patterns on the garments and discontinuous poses, existing methods often generate unsatisfactory results such as distorted textures and flickering artifacts. To address these issues, we propose a novel Deformable Motion Modulation (DMM) that utilizes geometric kernel offset with adaptive weight modulation to simultaneously perform feature alignment and style transfer. Different from normal style modulation used in style transfer, the proposed modulation mechanism adaptively reconstructs smoothed frames from style codes according to the object shape through an irregular receptive field of view. To enhance the spatio-temporal consistency, we leverage bidirectional propagation to extract the hidden motion information from a warped image sequence generated by noisy poses. The prop",
    "path": "papers/23/07/2307.07754.json",
    "total_tokens": 928,
    "translated_title": "双向可变形运动调制用于基于视频的人体姿态转移",
    "translated_abstract": "基于视频的人体姿态转移是一个将普通源人体图像根据一系列目标人物姿态进行动画化的视频生成任务。鉴于在服装的高度结构性图案和不连续的姿势转移上存在的困难，现有方法通常会产生不理想的结果，如扭曲的纹理和闪烁的伪影。为解决这些问题，我们提出了一种新颖的可变形运动调制（DMM），该方法利用几何核偏移和自适应权重调制来同时进行特征对齐和风格转移。与在风格转移中使用的普通风格调制不同，所提出的调制机制通过一种非规则感受野根据对象形状自适应重构平滑帧，以实现风格转移。为增强时空一致性，我们利用双向传播从由噪声姿势生成的畸变图像序列中提取隐藏的运动信息。",
    "tldr": "该论文提出了一种双向可变形运动调制方法，用于基于视频的人体姿态转移。通过几何核偏移和自适应权重调制，同时实现特征对齐和风格转移。与传统方法相比，该方法能够更好地处理服装上的结构图案和不连续的姿势转移，并提供更加满意的结果。",
    "en_tdlr": "This paper proposes a bidirectionally deformable motion modulation approach for video-based human pose transfer. It simultaneously performs feature alignment and style transfer through geometric kernel offset and adaptive weight modulation. Compared to existing methods, it can better handle structural patterns on garments and discontinuous pose transfer, resulting in more satisfactory results."
}