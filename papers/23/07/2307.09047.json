{
    "title": "Multimodal Machine Learning for Extraction of Theorems and Proofs in the Scientific Literature. (arXiv:2307.09047v1 [cs.AI])",
    "abstract": "Scholarly articles in mathematical fields feature mathematical statements such as theorems, propositions, etc., as well as their proofs. Extracting them from the PDF representation of the articles requires understanding of scientific text along with visual and font-based indicators. We pose this problem as a multimodal classification problem using text, font features, and bitmap image rendering of the PDF as different modalities. In this paper we propose a multimodal machine learning approach for extraction of theorem-like environments and proofs, based on late fusion of features extracted by individual unimodal classifiers, taking into account the sequential succession of blocks in the document. For the text modality, we pretrain a new language model on a 11 GB scientific corpus; experiments shows similar performance for our task than a model (RoBERTa) pretrained on 160 GB, with faster convergence while requiring much less fine-tuning data. Font-based information relies on training a ",
    "link": "http://arxiv.org/abs/2307.09047",
    "context": "Title: Multimodal Machine Learning for Extraction of Theorems and Proofs in the Scientific Literature. (arXiv:2307.09047v1 [cs.AI])\nAbstract: Scholarly articles in mathematical fields feature mathematical statements such as theorems, propositions, etc., as well as their proofs. Extracting them from the PDF representation of the articles requires understanding of scientific text along with visual and font-based indicators. We pose this problem as a multimodal classification problem using text, font features, and bitmap image rendering of the PDF as different modalities. In this paper we propose a multimodal machine learning approach for extraction of theorem-like environments and proofs, based on late fusion of features extracted by individual unimodal classifiers, taking into account the sequential succession of blocks in the document. For the text modality, we pretrain a new language model on a 11 GB scientific corpus; experiments shows similar performance for our task than a model (RoBERTa) pretrained on 160 GB, with faster convergence while requiring much less fine-tuning data. Font-based information relies on training a ",
    "path": "papers/23/07/2307.09047.json",
    "total_tokens": 966,
    "translated_title": "用于从科学文献中提取定理和证明的多模态机器学习",
    "translated_abstract": "数学领域的学术文章中包含定理、命题等数学陈述及其证明。从文章的PDF表示中提取它们需要理解科学文本以及视觉和基于字体的指示符。我们将这个问题作为一种多模态分类问题，使用文本、字体特征和PDF的位图图像渲染作为不同的模态。在本文中，我们提出了一种基于多模态机器学习的方法，用于提取类定理环境和证明，该方法基于通过单一单模态分类器提取的特征的后期融合，考虑文档中块的顺序。对于文本模态，我们在一个11 GB的科学语料库上预训练了一个新的语言模型；实验证明，我们的任务与一个在160 GB上预训练的（RoBERTa）模型相比拥有类似的性能，在要求更少的微调数据的同时收敛更快。",
    "tldr": "这篇论文提出了一种使用多模态机器学习的方法，通过对文本、字体特征和PDF的位图图像渲染进行融合分类，成功实现了从科学文献中提取定理和证明的目标。在文本模态方面，通过在11 GB的科学语料库上预训练一个新的语言模型，得到了与在160 GB预训练的模型相似的性能，同时具有更快的收敛速度和更少的微调数据要求。",
    "en_tdlr": "This paper introduces a multimodal machine learning approach that combines text, font features, and bitmap image rendering to successfully extract theorems and proofs from scientific literature. Pretraining a new language model on a smaller scientific corpus yields comparable performance to a model pretrained on a larger corpus, with faster convergence and less fine-tuning data required."
}