{
    "title": "A Survey on Multi-Objective Neural Architecture Search. (arXiv:2307.09099v1 [cs.CV])",
    "abstract": "Recently, the expert-crafted neural architectures is increasing overtaken by the utilization of neural architecture search (NAS) and automatic generation (and tuning) of network structures which has a close relation to the Hyperparameter Optimization and Auto Machine Learning (AutoML). After the earlier NAS attempts to optimize only the prediction accuracy, Multi-Objective Neural architecture Search (MONAS) has been attracting attentions which considers more goals such as computational complexity, power consumption, and size of the network for optimization, reaching a trade-off between the accuracy and other features like the computational cost. In this paper, we present an overview of principal and state-of-the-art works in the field of MONAS. Starting from a well-categorized taxonomy and formulation for the NAS, we address and correct some miscategorizations in previous surveys of the NAS field. We also provide a list of all known objectives used and add a number of new ones and elab",
    "link": "http://arxiv.org/abs/2307.09099",
    "context": "Title: A Survey on Multi-Objective Neural Architecture Search. (arXiv:2307.09099v1 [cs.CV])\nAbstract: Recently, the expert-crafted neural architectures is increasing overtaken by the utilization of neural architecture search (NAS) and automatic generation (and tuning) of network structures which has a close relation to the Hyperparameter Optimization and Auto Machine Learning (AutoML). After the earlier NAS attempts to optimize only the prediction accuracy, Multi-Objective Neural architecture Search (MONAS) has been attracting attentions which considers more goals such as computational complexity, power consumption, and size of the network for optimization, reaching a trade-off between the accuracy and other features like the computational cost. In this paper, we present an overview of principal and state-of-the-art works in the field of MONAS. Starting from a well-categorized taxonomy and formulation for the NAS, we address and correct some miscategorizations in previous surveys of the NAS field. We also provide a list of all known objectives used and add a number of new ones and elab",
    "path": "papers/23/07/2307.09099.json",
    "total_tokens": 823,
    "translated_title": "多目标神经架构搜索综述",
    "translated_abstract": "最近，通过神经架构搜索（NAS）和自动化生成（和调整）网络结构，领域内使用专家设计的神经架构的趋势正在逐渐被取代。这与超参数优化和自动机器学习（AutoML）密切相关。在过去，NAS仅优化预测准确性，而多目标神经架构搜索（MONAS）已经引起了人们的关注，它考虑了更多的目标，如计算复杂性、功耗和网络大小，实现了准确性与计算成本等其他特征之间的平衡。本文概述了MONAS领域的主要和最新研究工作。从对NAS的分类和表述开始，我们纠正了之前一些关于NAS领域的分类错误，并提供了已知目标的列表，并补充了一些新目标，并进行了详细阐述。",
    "tldr": "这篇论文综述了多目标神经架构搜索（MONAS）的主要研究工作，介绍了领域内的分类和表述问题，并提供了一个目标列表和一些新的目标。"
}