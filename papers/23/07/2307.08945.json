{
    "title": "Mitigating Label Bias via Decoupled Confident Learning. (arXiv:2307.08945v1 [cs.LG])",
    "abstract": "Growing concerns regarding algorithmic fairness have led to a surge in methodologies to mitigate algorithmic bias. However, such methodologies largely assume that observed labels in training data are correct. This is problematic because bias in labels is pervasive across important domains, including healthcare, hiring, and content moderation. In particular, human-generated labels are prone to encoding societal biases. While the presence of labeling bias has been discussed conceptually, there is a lack of methodologies to address this problem. We propose a pruning method -- Decoupled Confident Learning (DeCoLe) -- specifically designed to mitigate label bias. After illustrating its performance on a synthetic dataset, we apply DeCoLe in the context of hate speech detection, where label bias has been recognized as an important challenge, and show that it successfully identifies biased labels and outperforms competing approaches.",
    "link": "http://arxiv.org/abs/2307.08945",
    "context": "Title: Mitigating Label Bias via Decoupled Confident Learning. (arXiv:2307.08945v1 [cs.LG])\nAbstract: Growing concerns regarding algorithmic fairness have led to a surge in methodologies to mitigate algorithmic bias. However, such methodologies largely assume that observed labels in training data are correct. This is problematic because bias in labels is pervasive across important domains, including healthcare, hiring, and content moderation. In particular, human-generated labels are prone to encoding societal biases. While the presence of labeling bias has been discussed conceptually, there is a lack of methodologies to address this problem. We propose a pruning method -- Decoupled Confident Learning (DeCoLe) -- specifically designed to mitigate label bias. After illustrating its performance on a synthetic dataset, we apply DeCoLe in the context of hate speech detection, where label bias has been recognized as an important challenge, and show that it successfully identifies biased labels and outperforms competing approaches.",
    "path": "papers/23/07/2307.08945.json",
    "total_tokens": 839,
    "translated_title": "通过解耦置信学习来减缓标签偏见",
    "translated_abstract": "随着对算法公平性的担忧增加，出现了许多方法来减轻算法偏见。然而，这些方法主要假设训练数据中观察到的标签是正确的。这是有问题的，因为标签偏见在包括医疗、招聘和内容审核在内的重要领域中普遍存在。特别是，人类生成的标签容易带有社会偏见。虽然标签偏见的存在已经在概念上进行了讨论，但缺乏应对此问题的方法。我们提出了一种修剪方法——解耦置信学习（DeCoLe），专门设计来减轻标签偏见。在演示了其在合成数据集上的性能后，我们将DeCoLe应用于仇恨言论检测的环境中，这是一个被认为是重要挑战的领域，并展示其成功识别出偏见标签并超越竞争方法的表现。",
    "tldr": "这项研究提出了一种名为DeCoLe的修剪方法，用于减轻标签偏见问题。研究在合成数据集和仇恨言论检测领域取得了成功的结果。"
}