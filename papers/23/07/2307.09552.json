{
    "title": "Self-Compatibility: Evaluating Causal Discovery without Ground Truth. (arXiv:2307.09552v1 [cs.LG])",
    "abstract": "As causal ground truth is incredibly rare, causal discovery algorithms are commonly only evaluated on simulated data. This is concerning, given that simulations reflect common preconceptions about generating processes regarding noise distributions, model classes, and more. In this work, we propose a novel method for falsifying the output of a causal discovery algorithm in the absence of ground truth. Our key insight is that while statistical learning seeks stability across subsets of data points, causal learning should seek stability across subsets of variables. Motivated by this insight, our method relies on a notion of compatibility between causal graphs learned on different subsets of variables. We prove that detecting incompatibilities can falsify wrongly inferred causal relations due to violation of assumptions or errors from finite sample effects. Although passing such compatibility tests is only a necessary criterion for good performance, we argue that it provides strong evidenc",
    "link": "http://arxiv.org/abs/2307.09552",
    "context": "Title: Self-Compatibility: Evaluating Causal Discovery without Ground Truth. (arXiv:2307.09552v1 [cs.LG])\nAbstract: As causal ground truth is incredibly rare, causal discovery algorithms are commonly only evaluated on simulated data. This is concerning, given that simulations reflect common preconceptions about generating processes regarding noise distributions, model classes, and more. In this work, we propose a novel method for falsifying the output of a causal discovery algorithm in the absence of ground truth. Our key insight is that while statistical learning seeks stability across subsets of data points, causal learning should seek stability across subsets of variables. Motivated by this insight, our method relies on a notion of compatibility between causal graphs learned on different subsets of variables. We prove that detecting incompatibilities can falsify wrongly inferred causal relations due to violation of assumptions or errors from finite sample effects. Although passing such compatibility tests is only a necessary criterion for good performance, we argue that it provides strong evidenc",
    "path": "papers/23/07/2307.09552.json",
    "total_tokens": 879,
    "translated_title": "自我兼容性：在没有基准数据的情况下评估因果发现的方法。",
    "translated_abstract": "鉴于因果基本事实非常罕见，因果发现算法通常只在模拟数据上进行评估。这令人担忧，因为模拟反映了关于噪声分布、模型类别等生成过程的常见假设。在这项工作中，我们提出了一种新的方法，用于在没有基准数据的情况下对因果发现算法的输出进行伪证。我们的关键见解是，尽管统计学习寻求数据点子集之间的稳定性，但因果学习应该寻求变量子集之间的稳定性。基于这个见解，我们的方法依赖于在不同变量子集上学习的因果图之间的兼容性概念。我们证明了检测不兼容性可以伪证因果关系被错误推断的原因，这是因为假设违反或有限样本效应带来的错误。虽然通过这种兼容性测试只是对良好性能的必要条件，但我们认为它提供了强有力的证据。",
    "tldr": "本论文提出了一种在没有基准数据的情况下评估因果发现方法的新方法，通过在不同变量子集上学习的因果图之间的兼容性检测，来伪证因果关系的推断正确性。",
    "en_tdlr": "This paper proposes a novel method for evaluating causal discovery without ground truth by detecting compatibility between causal graphs learned on different subsets of variables, thereby providing strong evidence for the correctness of inferred causal relations."
}