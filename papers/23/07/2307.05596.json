{
    "title": "Compositional Generalization from First Principles. (arXiv:2307.05596v1 [cs.LG])",
    "abstract": "Leveraging the compositional nature of our world to expedite learning and facilitate generalization is a hallmark of human perception. In machine learning, on the other hand, achieving compositional generalization has proven to be an elusive goal, even for models with explicit compositional priors. To get a better handle on compositional generalization, we here approach it from the bottom up: Inspired by identifiable representation learning, we investigate compositionality as a property of the data-generating process rather than the data itself. This reformulation enables us to derive mild conditions on only the support of the training distribution and the model architecture, which are sufficient for compositional generalization. We further demonstrate how our theoretical framework applies to real-world scenarios and validate our findings empirically. Our results set the stage for a principled theoretical study of compositional generalization.",
    "link": "http://arxiv.org/abs/2307.05596",
    "context": "Title: Compositional Generalization from First Principles. (arXiv:2307.05596v1 [cs.LG])\nAbstract: Leveraging the compositional nature of our world to expedite learning and facilitate generalization is a hallmark of human perception. In machine learning, on the other hand, achieving compositional generalization has proven to be an elusive goal, even for models with explicit compositional priors. To get a better handle on compositional generalization, we here approach it from the bottom up: Inspired by identifiable representation learning, we investigate compositionality as a property of the data-generating process rather than the data itself. This reformulation enables us to derive mild conditions on only the support of the training distribution and the model architecture, which are sufficient for compositional generalization. We further demonstrate how our theoretical framework applies to real-world scenarios and validate our findings empirically. Our results set the stage for a principled theoretical study of compositional generalization.",
    "path": "papers/23/07/2307.05596.json",
    "total_tokens": 844,
    "translated_title": "从第一原理中实现组合性泛化",
    "translated_abstract": "利用我们世界的组合性质加快学习和促进泛化是人类感知的一个特点。然而，在机器学习中，即使对于具有明确组合性先验的模型，实现组合性泛化也是一个难以实现的目标。为了更好地理解组合性泛化，我们从底层开始进行探索：受可识别表示学习的启发，我们研究组合性作为数据生成过程的属性，而不是数据本身。这种改进使我们能够导出仅对训练分布的支持和模型架构有轻微条件的要求，这些条件足以实现组合性泛化。我们进一步展示了我们的理论框架如何应用于现实场景，并通过实验证实了我们的发现。我们的结果为组合性泛化的原则性理论研究奠定了基础。",
    "tldr": "本论文将组合性泛化视为数据生成过程的属性，通过导出对训练分布支持和模型架构的条件要求，实现了组合性泛化。对于机器学习中的组合性泛化问题提供了理论性的研究基础。"
}