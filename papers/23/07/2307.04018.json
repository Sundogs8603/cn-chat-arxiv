{
    "title": "Revisiting Cross-Lingual Summarization: A Corpus-based Study and A New Benchmark with Improved Annotation. (arXiv:2307.04018v1 [cs.CL])",
    "abstract": "Most existing cross-lingual summarization (CLS) work constructs CLS corpora by simply and directly translating pre-annotated summaries from one language to another, which can contain errors from both summarization and translation processes. To address this issue, we propose ConvSumX, a cross-lingual conversation summarization benchmark, through a new annotation schema that explicitly considers source input context. ConvSumX consists of 2 sub-tasks under different real-world scenarios, with each covering 3 language directions. We conduct thorough analysis on ConvSumX and 3 widely-used manually annotated CLS corpora and empirically find that ConvSumX is more faithful towards input text. Additionally, based on the same intuition, we propose a 2-Step method, which takes both conversation and summary as input to simulate human annotation process. Experimental results show that 2-Step method surpasses strong baselines on ConvSumX under both automatic and human evaluation. Analysis shows that",
    "link": "http://arxiv.org/abs/2307.04018",
    "context": "Title: Revisiting Cross-Lingual Summarization: A Corpus-based Study and A New Benchmark with Improved Annotation. (arXiv:2307.04018v1 [cs.CL])\nAbstract: Most existing cross-lingual summarization (CLS) work constructs CLS corpora by simply and directly translating pre-annotated summaries from one language to another, which can contain errors from both summarization and translation processes. To address this issue, we propose ConvSumX, a cross-lingual conversation summarization benchmark, through a new annotation schema that explicitly considers source input context. ConvSumX consists of 2 sub-tasks under different real-world scenarios, with each covering 3 language directions. We conduct thorough analysis on ConvSumX and 3 widely-used manually annotated CLS corpora and empirically find that ConvSumX is more faithful towards input text. Additionally, based on the same intuition, we propose a 2-Step method, which takes both conversation and summary as input to simulate human annotation process. Experimental results show that 2-Step method surpasses strong baselines on ConvSumX under both automatic and human evaluation. Analysis shows that",
    "path": "papers/23/07/2307.04018.json",
    "total_tokens": 944,
    "translated_title": "重新审视跨语言摘要：一个基于语料库的研究和一个新的具有改进注释的基准",
    "translated_abstract": "大多数现有的跨语言摘要（CLS）工作通过简单直接地将预先注释的摘要从一种语言翻译为另一种语言来构建CLS语料库，这可能包含摘要和翻译过程中的错误。为了解决这个问题，我们提出了ConvSumX，一个跨语言对话摘要基准，通过一个新的注释架构，明确考虑了源输入上下文。ConvSumX包括两个子任务，涵盖了不同的现实场景，每个子任务涵盖了三个语言方向。我们对ConvSumX和3个广泛使用的手工注释的CLS语料库进行了深入分析，实证发现ConvSumX对输入文本更可靠。此外，基于相同的直觉，我们提出了一种两步方法，将对话和摘要作为输入来模拟人类注释过程。实验结果表明，两步方法在ConvSumX上在自动评估和人工评估下均超越了强基线。分析表明，",
    "tldr": "本研究重新审视了跨语言摘要，并提出了一个新的具有改进注释的基准。通过考虑源输入上下文，该基准更可靠。此外，作者还提出了一种两步方法，在ConvSumX上表现出较强的性能。",
    "en_tdlr": "This study revisits cross-lingual summarization and proposes a new benchmark with improved annotations. The benchmark, ConvSumX, considers source input context and shows higher reliability. Additionally, the authors propose a two-step method which achieves strong performance on ConvSumX."
}