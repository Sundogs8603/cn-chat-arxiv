{
    "title": "False Sense of Security: Leveraging XAI to Analyze the Reasoning and True Performance of Context-less DGA Classifiers. (arXiv:2307.04358v2 [cs.CR] UPDATED)",
    "abstract": "The problem of revealing botnet activity through Domain Generation Algorithm (DGA) detection seems to be solved, considering that available deep learning classifiers achieve accuracies of over 99.9%. However, these classifiers provide a false sense of security as they are heavily biased and allow for trivial detection bypass. In this work, we leverage explainable artificial intelligence (XAI) methods to analyze the reasoning of deep learning classifiers and to systematically reveal such biases. We show that eliminating these biases from DGA classifiers considerably deteriorates their performance. Nevertheless we are able to design a context-aware detection system that is free of the identified biases and maintains the detection rate of state-of-the art deep learning classifiers. In this context, we propose a visual analysis system that helps to better understand a classifier's reasoning, thereby increasing trust in and transparency of detection methods and facilitating decision-making.",
    "link": "http://arxiv.org/abs/2307.04358",
    "context": "Title: False Sense of Security: Leveraging XAI to Analyze the Reasoning and True Performance of Context-less DGA Classifiers. (arXiv:2307.04358v2 [cs.CR] UPDATED)\nAbstract: The problem of revealing botnet activity through Domain Generation Algorithm (DGA) detection seems to be solved, considering that available deep learning classifiers achieve accuracies of over 99.9%. However, these classifiers provide a false sense of security as they are heavily biased and allow for trivial detection bypass. In this work, we leverage explainable artificial intelligence (XAI) methods to analyze the reasoning of deep learning classifiers and to systematically reveal such biases. We show that eliminating these biases from DGA classifiers considerably deteriorates their performance. Nevertheless we are able to design a context-aware detection system that is free of the identified biases and maintains the detection rate of state-of-the art deep learning classifiers. In this context, we propose a visual analysis system that helps to better understand a classifier's reasoning, thereby increasing trust in and transparency of detection methods and facilitating decision-making.",
    "path": "papers/23/07/2307.04358.json",
    "total_tokens": 975,
    "translated_title": "虚假的安全感：利用可解释的人工智能分析无上下文DGA分类器的推理和真实性能",
    "translated_abstract": "通过域生成算法（DGA）检测揭示僵尸网络活动的问题似乎已经解决，因为现有的深度学习分类器的准确率超过99.9%。然而，这些分类器提供了一种虚假的安全感，因为它们存在严重的偏见，容易被绕过。本研究利用可解释的人工智能方法分析深度学习分类器的推理过程，并系统地揭示这些偏见。我们发现，消除DGA分类器的这些偏见会显著降低其性能。然而，我们能够设计一个无偏见的上下文感知检测系统，同时保持最先进的深度学习分类器的检测率。在这个背景下，我们提出了一个视觉分析系统，帮助更好地理解分类器的推理过程，从而增加对检测方法的信任和透明度，并促进决策制定。",
    "tldr": "本研究利用可解释的人工智能方法分析了基于深度学习的DGA分类器的推理过程，并揭示了其中的偏见。通过消除这些偏见，我们设计了一个无偏见且上下文感知的检测系统，保持了最先进分类器的检测率，同时提出了一个视觉分析系统，以增加对检测方法的信任和透明度。"
}