{
    "title": "Enhancing Continuous Time Series Modelling with a Latent ODE-LSTM Approach. (arXiv:2307.05126v1 [cs.LG])",
    "abstract": "Due to their dynamic properties such as irregular sampling rate and high-frequency sampling, Continuous Time Series (CTS) are found in many applications. Since CTS with irregular sampling rate are difficult to model with standard Recurrent Neural Networks (RNNs), RNNs have been generalised to have continuous-time hidden dynamics defined by a Neural Ordinary Differential Equation (Neural ODE), leading to the ODE-RNN model. Another approach that provides a better modelling is that of the Latent ODE model, which constructs a continuous-time model where a latent state is defined at all times. The Latent ODE model uses a standard RNN as the encoder and a Neural ODE as the decoder. However, since the RNN encoder leads to difficulties with missing data and ill-defined latent variables, a Latent ODE-RNN model has recently been proposed that uses a ODE-RNN model as the encoder instead. Both the Latent ODE and Latent ODE-RNN models are difficult to train due to the vanishing and exploding gradie",
    "link": "http://arxiv.org/abs/2307.05126",
    "context": "Title: Enhancing Continuous Time Series Modelling with a Latent ODE-LSTM Approach. (arXiv:2307.05126v1 [cs.LG])\nAbstract: Due to their dynamic properties such as irregular sampling rate and high-frequency sampling, Continuous Time Series (CTS) are found in many applications. Since CTS with irregular sampling rate are difficult to model with standard Recurrent Neural Networks (RNNs), RNNs have been generalised to have continuous-time hidden dynamics defined by a Neural Ordinary Differential Equation (Neural ODE), leading to the ODE-RNN model. Another approach that provides a better modelling is that of the Latent ODE model, which constructs a continuous-time model where a latent state is defined at all times. The Latent ODE model uses a standard RNN as the encoder and a Neural ODE as the decoder. However, since the RNN encoder leads to difficulties with missing data and ill-defined latent variables, a Latent ODE-RNN model has recently been proposed that uses a ODE-RNN model as the encoder instead. Both the Latent ODE and Latent ODE-RNN models are difficult to train due to the vanishing and exploding gradie",
    "path": "papers/23/07/2307.05126.json",
    "total_tokens": 965,
    "translated_title": "用潜在ODE-LSTM方法增强连续时间序列建模",
    "translated_abstract": "由于其不规则的采样率和高频采样等动态特性，连续时间序列（CTS）广泛应用于许多领域。由于具有不规则采样率的CTS难以使用标准循环神经网络（RNN）进行建模，因此RNN被推广为具有由神经常微分方程（Neural ODE）定义的连续时间隐藏动力学的ODE-RNN模型。另一种提供更好建模效果的方法是潜在ODE模型，该模型构建了一个连续时间模型，在所有时间点上定义了一个潜在状态。潜在ODE模型使用标准RNN作为编码器和神经ODE作为解码器。然而，由于RNN编码器存在缺失数据和不完全定义的潜在变量问题，最近提出了一种使用ODE-RNN模型作为编码器的潜在ODE-RNN模型。由于梯度消失和爆炸问题，潜在ODE模型和潜在ODE-RNN模型都难以训练。",
    "tldr": "该论文提出了使用潜在ODE-LSTM方法增强连续时间序列建模的方法，解决了使用标准RNN进行建模时遇到的问题，包括不规则采样和缺失数据等。该方法使用ODE-RNN模型作为编码器，并使用神经ODE作为解码器，提供了更好的建模效果。",
    "en_tdlr": "This paper proposes a latent ODE-LSTM approach to enhance continuous time series modelling, addressing issues encountered when using standard RNNs, including irregular sampling and missing data. The approach utilizes an ODE-RNN model as the encoder and a neural ODE as the decoder, resulting in improved modelling performance."
}