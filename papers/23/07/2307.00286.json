{
    "title": "CMA-ES for Post Hoc Ensembling in AutoML: A Great Success and Salvageable Failure. (arXiv:2307.00286v1 [cs.LG])",
    "abstract": "Many state-of-the-art automated machine learning (AutoML) systems use greedy ensemble selection (GES) by Caruana et al. (2004) to ensemble models found during model selection post hoc. Thereby, boosting predictive performance and likely following Auto-Sklearn 1's insight that alternatives, like stacking or gradient-free numerical optimization, overfit. Overfitting in Auto-Sklearn 1 is much more likely than in other AutoML systems because it uses only low-quality validation data for post hoc ensembling. Therefore, we were motivated to analyze whether Auto-Sklearn 1's insight holds true for systems with higher-quality validation data. Consequently, we compared the performance of covariance matrix adaptation evolution strategy (CMA-ES), state-of-the-art gradient-free numerical optimization, to GES on the 71 classification datasets from the AutoML benchmark for AutoGluon. We found that Auto-Sklearn's insight depends on the chosen metric. For the metric ROC AUC, CMA-ES overfits drastically ",
    "link": "http://arxiv.org/abs/2307.00286",
    "context": "Title: CMA-ES for Post Hoc Ensembling in AutoML: A Great Success and Salvageable Failure. (arXiv:2307.00286v1 [cs.LG])\nAbstract: Many state-of-the-art automated machine learning (AutoML) systems use greedy ensemble selection (GES) by Caruana et al. (2004) to ensemble models found during model selection post hoc. Thereby, boosting predictive performance and likely following Auto-Sklearn 1's insight that alternatives, like stacking or gradient-free numerical optimization, overfit. Overfitting in Auto-Sklearn 1 is much more likely than in other AutoML systems because it uses only low-quality validation data for post hoc ensembling. Therefore, we were motivated to analyze whether Auto-Sklearn 1's insight holds true for systems with higher-quality validation data. Consequently, we compared the performance of covariance matrix adaptation evolution strategy (CMA-ES), state-of-the-art gradient-free numerical optimization, to GES on the 71 classification datasets from the AutoML benchmark for AutoGluon. We found that Auto-Sklearn's insight depends on the chosen metric. For the metric ROC AUC, CMA-ES overfits drastically ",
    "path": "papers/23/07/2307.00286.json",
    "total_tokens": 936,
    "translated_title": "CMA-ES用于后续集成在AutoML中：一个巨大的成功和可挽救的失败。",
    "translated_abstract": "许多最先进的自动机器学习（AutoML）系统在模型选择后使用Caruana等人（2004年）的贪婪集成选择（GES）来集成找到的模型。从而提高预测性能并且像 Auto-Sklearn 1 般提示，其他方法，如堆叠或无梯度数值优化，容易过拟合。Auto-Sklearn 1 中的过拟合比其他AutoML系统更有可能，因为它仅使用质量较低的验证数据进行后续集成。因此，我们有动力分析Auto-Sklearn 1 的观点是否适用于具有质量更高的验证数据的系统。因此，我们将协方差矩阵适应进化策略（CMA-ES），一个最先进的无梯度数值优化方法，与AutoGluon的AutoML基准测试中的GES在71个分类数据集上的性能进行了比较。我们发现，Auto-Sklearn的观点取决于选择的度量指标。对于ROC AUC指标，CMA-ES出现了严重的过拟合。",
    "tldr": "本论文研究使用CMA-ES来替代贪婪集成选择方法，在AutoML中的表现。比较结果表明对于ROC AUC指标，CMA-ES出现了严重过拟合问题。",
    "en_tdlr": "This paper investigates the performance of using CMA-ES as an alternative to greedy ensemble selection (GES) in AutoML. The comparison results show that CMA-ES suffers from severe overfitting issues for the ROC AUC metric."
}