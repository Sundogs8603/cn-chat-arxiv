{
    "title": "Gradient-Based Word Substitution for Obstinate Adversarial Examples Generation in Language Models. (arXiv:2307.12507v2 [cs.CL] UPDATED)",
    "abstract": "In this paper, we study the problem of generating obstinate (over-stability) adversarial examples by word substitution in NLP, where input text is meaningfully changed but the model's prediction does not, even though it should. Previous word substitution approaches have predominantly focused on manually designed antonym-based strategies for generating obstinate adversarial examples, which hinders its application as these strategies can only find a subset of obstinate adversarial examples and require human efforts. To address this issue, in this paper, we introduce a novel word substitution method named GradObstinate, a gradient-based approach that automatically generates obstinate adversarial examples without any constraints on the search space or the need for manual design principles. To empirically evaluate the efficacy of GradObstinate, we conduct comprehensive experiments on five representative models (Electra, ALBERT, Roberta, DistillBERT, and CLIP) finetuned on four NLP benchmark",
    "link": "http://arxiv.org/abs/2307.12507",
    "context": "Title: Gradient-Based Word Substitution for Obstinate Adversarial Examples Generation in Language Models. (arXiv:2307.12507v2 [cs.CL] UPDATED)\nAbstract: In this paper, we study the problem of generating obstinate (over-stability) adversarial examples by word substitution in NLP, where input text is meaningfully changed but the model's prediction does not, even though it should. Previous word substitution approaches have predominantly focused on manually designed antonym-based strategies for generating obstinate adversarial examples, which hinders its application as these strategies can only find a subset of obstinate adversarial examples and require human efforts. To address this issue, in this paper, we introduce a novel word substitution method named GradObstinate, a gradient-based approach that automatically generates obstinate adversarial examples without any constraints on the search space or the need for manual design principles. To empirically evaluate the efficacy of GradObstinate, we conduct comprehensive experiments on five representative models (Electra, ALBERT, Roberta, DistillBERT, and CLIP) finetuned on four NLP benchmark",
    "path": "papers/23/07/2307.12507.json",
    "total_tokens": 917,
    "translated_title": "基于梯度的词替换用于生成语言模型中顽固对抗样本",
    "translated_abstract": "本文研究了在自然语言处理中通过词替换生成顽固（超稳定性）对抗样本的问题，在这种情况下，输入文本的意义发生了改变，但模型的预测却没有变化，尽管应该发生变化。以往的词替换方法主要集中在手动设计的反义词策略上，用于生成顽固对抗样本，这制约了它的应用，因为这些策略只能找到部分顽固对抗样本，并且需要人工努力。为了解决这个问题，本文介绍了一种新的词替换方法，名为GradObstinate，它是一种基于梯度的方法，可以自动生成顽固对抗样本，不受搜索空间限制或需求人工设计原则的约束。为了经验性地评估GradObstinate的效果，我们在与自然语言处理基准模型（Electra、ALBERT、Roberta、DistillBERT和CLIP）上进行了全面的实验。",
    "tldr": "本文介绍了一种名为GradObstinate的基于梯度的方法，用于生成顽固对抗样本。该方法可以自动生成意义改变但模型预测结果保持不变的对抗样本，无需人工设计约束。"
}