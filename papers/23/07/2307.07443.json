{
    "title": "Can Large Language Models Empower Molecular Property Prediction?. (arXiv:2307.07443v1 [cs.LG])",
    "abstract": "Molecular property prediction has gained significant attention due to its transformative potential in multiple scientific disciplines. Conventionally, a molecule graph can be represented either as a graph-structured data or a SMILES text. Recently, the rapid development of Large Language Models (LLMs) has revolutionized the field of NLP. Although it is natural to utilize LLMs to assist in understanding molecules represented by SMILES, the exploration of how LLMs will impact molecular property prediction is still in its early stage. In this work, we advance towards this objective through two perspectives: zero/few-shot molecular classification, and using the new explanations generated by LLMs as representations of molecules. To be specific, we first prompt LLMs to do in-context molecular classification and evaluate their performance. After that, we employ LLMs to generate semantically enriched explanations for the original SMILES and then leverage that to fine-tune a small-scale LM mode",
    "link": "http://arxiv.org/abs/2307.07443",
    "context": "Title: Can Large Language Models Empower Molecular Property Prediction?. (arXiv:2307.07443v1 [cs.LG])\nAbstract: Molecular property prediction has gained significant attention due to its transformative potential in multiple scientific disciplines. Conventionally, a molecule graph can be represented either as a graph-structured data or a SMILES text. Recently, the rapid development of Large Language Models (LLMs) has revolutionized the field of NLP. Although it is natural to utilize LLMs to assist in understanding molecules represented by SMILES, the exploration of how LLMs will impact molecular property prediction is still in its early stage. In this work, we advance towards this objective through two perspectives: zero/few-shot molecular classification, and using the new explanations generated by LLMs as representations of molecules. To be specific, we first prompt LLMs to do in-context molecular classification and evaluate their performance. After that, we employ LLMs to generate semantically enriched explanations for the original SMILES and then leverage that to fine-tune a small-scale LM mode",
    "path": "papers/23/07/2307.07443.json",
    "total_tokens": 807,
    "translated_title": "大型语言模型能增强分子属性预测吗？",
    "translated_abstract": "分子属性预测因其在多个科学领域中的改变潜力而受到重视。传统上，分子图可以表示为图结构化数据或SMILES文本。最近，大型语言模型（LLMs）的快速发展彻底改变了自然语言处理领域。尽管利用LLMs来理解用SMILES表示的分子是自然的，但LLMs如何影响分子属性预测的探索仍处于早期阶段。在这项工作中，我们从零/少样本分子分类和使用LLMs生成的新解释作为分子表示两个角度推进了这一目标。具体而言，我们首先提示LLMs进行上下文分子分类并评估其性能。然后，我们利用LLMs为原始SMILES生成语义丰富的解释，并利用此来微调小规模的LM模型。",
    "tldr": "本研究提出了利用大型语言模型（LLMs）对分子属性预测进行增强的方法，通过零/少样本分子分类和生成新的解释来推进这一目标。",
    "en_tdlr": "This study proposes a method to enhance molecular property prediction using large language models (LLMs), advancing towards this objective through zero/few-shot molecular classification and generating new explanations."
}