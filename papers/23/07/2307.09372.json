{
    "title": "Enhancing Pattern Classification in Support Vector Machines through Matrix Formulation. (arXiv:2307.09372v1 [cs.LG])",
    "abstract": "Support Vector Machines (SVM) have gathered significant acclaim as classifiers due to their successful implementation of Statistical Learning Theory. However, in the context of multiclass and multilabel settings, the reliance on vector-based formulations in existing SVM-based models poses limitations regarding flexibility and ease of incorporating additional terms to handle specific challenges. To overcome these limitations, our research paper focuses on introducing a matrix formulation for SVM that effectively addresses these constraints. By employing the Accelerated Gradient Descent method in the dual, we notably enhance the efficiency of solving the Matrix-SVM problem. Experimental evaluations on multilabel and multiclass datasets demonstrate that Matrix SVM achieves superior time efficacy while delivering similar results to Binary Relevance SVM.  Moreover, our matrix formulation unveils crucial insights and advantages that may not be readily apparent in traditional vector-based not",
    "link": "http://arxiv.org/abs/2307.09372",
    "context": "Title: Enhancing Pattern Classification in Support Vector Machines through Matrix Formulation. (arXiv:2307.09372v1 [cs.LG])\nAbstract: Support Vector Machines (SVM) have gathered significant acclaim as classifiers due to their successful implementation of Statistical Learning Theory. However, in the context of multiclass and multilabel settings, the reliance on vector-based formulations in existing SVM-based models poses limitations regarding flexibility and ease of incorporating additional terms to handle specific challenges. To overcome these limitations, our research paper focuses on introducing a matrix formulation for SVM that effectively addresses these constraints. By employing the Accelerated Gradient Descent method in the dual, we notably enhance the efficiency of solving the Matrix-SVM problem. Experimental evaluations on multilabel and multiclass datasets demonstrate that Matrix SVM achieves superior time efficacy while delivering similar results to Binary Relevance SVM.  Moreover, our matrix formulation unveils crucial insights and advantages that may not be readily apparent in traditional vector-based not",
    "path": "papers/23/07/2307.09372.json",
    "total_tokens": 988,
    "translated_title": "通过矩阵表述增强支持向量机中的模式分类",
    "translated_abstract": "支持向量机（SVM）由于其成功实现统计学习理论而成为分类器领域内备受赞誉。然而，在多类别和多标签设置下，现有SVM模型中基于向量的表述存在灵活性和整合额外项来应对特定挑战的限制。为了克服这些限制，我们的研究论文专注于引入一种能够有效解决这些约束的矩阵表述来作为SVM的解决方案。通过在对偶问题中采用加速梯度下降方法，我们显著提高了解决Matrix-SVM问题的效率。对多标签和多类别数据集的实验评估表明，矩阵SVM在时间效率上达到了优越性能，同时提供了与二进制相关性SVM相似的结果。此外，我们的矩阵表述揭示了传统基于向量的方法中难以察觉的关键洞见和优势。",
    "tldr": "本文介绍了一种改进的支持向量机（SVM）方法，通过引入矩阵表述来解决多类别和多标签设置下的灵活性和整合额外项的限制。通过在对偶问题中采用加速梯度下降方法，我们提高了矩阵SVM的解决效率，并证明其在时间效率和性能上与传统的二进制相关性SVM方法相当。这种矩阵表述揭示出了传统方法中难以察觉的关键洞见和优势。",
    "en_tdlr": "This paper presents an improved approach for Support Vector Machines (SVM) that overcomes limitations in flexibility and incorporating additional terms by introducing a matrix formulation in the context of multiclass and multilabel settings. By employing the Accelerated Gradient Descent method in the dual, the efficiency of solving the Matrix-SVM problem is notably enhanced, achieving comparable results to Binary Relevance SVM while offering insights and advantages not readily apparent in traditional vector-based methods."
}