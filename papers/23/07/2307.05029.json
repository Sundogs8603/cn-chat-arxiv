{
    "title": "FairLay-ML: Intuitive Remedies for Unfairness in Data-Driven Social-Critical Algorithms. (arXiv:2307.05029v1 [cs.LG])",
    "abstract": "This thesis explores open-sourced machine learning (ML) model explanation tools to understand whether these tools can allow a layman to visualize, understand, and suggest intuitive remedies to unfairness in ML-based decision-support systems. Machine learning models trained on datasets biased against minority groups are increasingly used to guide life-altering social decisions, prompting the urgent need to study their logic for unfairness. Due to this problem's impact on vast populations of the general public, it is critical for the layperson -- not just subject matter experts in social justice or machine learning experts -- to understand the nature of unfairness within these algorithms and the potential trade-offs. Existing research on fairness in machine learning focuses mostly on the mathematical definitions and tools to understand and remedy unfair models, with some directly citing user-interactive tools as necessary for future work. This thesis presents FairLay-ML, a proof-of-conce",
    "link": "http://arxiv.org/abs/2307.05029",
    "context": "Title: FairLay-ML: Intuitive Remedies for Unfairness in Data-Driven Social-Critical Algorithms. (arXiv:2307.05029v1 [cs.LG])\nAbstract: This thesis explores open-sourced machine learning (ML) model explanation tools to understand whether these tools can allow a layman to visualize, understand, and suggest intuitive remedies to unfairness in ML-based decision-support systems. Machine learning models trained on datasets biased against minority groups are increasingly used to guide life-altering social decisions, prompting the urgent need to study their logic for unfairness. Due to this problem's impact on vast populations of the general public, it is critical for the layperson -- not just subject matter experts in social justice or machine learning experts -- to understand the nature of unfairness within these algorithms and the potential trade-offs. Existing research on fairness in machine learning focuses mostly on the mathematical definitions and tools to understand and remedy unfair models, with some directly citing user-interactive tools as necessary for future work. This thesis presents FairLay-ML, a proof-of-conce",
    "path": "papers/23/07/2307.05029.json",
    "total_tokens": 874,
    "translated_title": "FairLay-ML：数据驱动社会关键算法中不公平的直观改善方法",
    "translated_abstract": "本论文探讨了开源的机器学习（ML）模型解释工具，以了解这些工具是否能够让普通人可视化、理解和建议直观的方法来改善ML决策支持系统中的不公平问题。针对少数群体受偏见数据训练的机器学习模型越来越被用于指导重大的社会决策，迫切需要研究它们在不公平方面的逻辑。由于这个问题对广大公众产生重大影响，理解这些算法中不公平性质和潜在的权衡是非常关键的，不仅仅是社会正义领域的专家或机器学习专家需要理解。现有研究主要集中在数学定义和工具上，以理解和解决不公平模型，其中一些直接提到用户交互工具是未来工作所必需的。本论文介绍了FairLay-ML，一个概念证明工具。",
    "tldr": "本论文研究了如何利用开源的机器学习模型解释工具，使普通人可以直观地理解和改善决策支持系统中的不公平问题。",
    "en_tdlr": "This thesis explores the use of open-source machine learning model explanation tools to enable laypeople to intuitively understand and address unfairness in decision-support systems based on machine learning."
}