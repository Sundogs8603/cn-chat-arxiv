{
    "title": "L3DMC: Lifelong Learning using Distillation via Mixed-Curvature Space. (arXiv:2307.16459v2 [cs.LG] UPDATED)",
    "abstract": "The performance of a lifelong learning (L3) model degrades when it is trained on a series of tasks, as the geometrical formation of the embedding space changes while learning novel concepts sequentially. The majority of existing L3 approaches operate on a fixed-curvature (e.g., zero-curvature Euclidean) space that is not necessarily suitable for modeling the complex geometric structure of data. Furthermore, the distillation strategies apply constraints directly on low-dimensional embeddings, discouraging the L3 model from learning new concepts by making the model highly stable. To address the problem, we propose a distillation strategy named L3DMC that operates on mixed-curvature spaces to preserve the already-learned knowledge by modeling and maintaining complex geometrical structures. We propose to embed the projected low dimensional embedding of fixed-curvature spaces (Euclidean and hyperbolic) to higher-dimensional Reproducing Kernel Hilbert Space (RKHS) using a positive-definite k",
    "link": "http://arxiv.org/abs/2307.16459",
    "context": "Title: L3DMC: Lifelong Learning using Distillation via Mixed-Curvature Space. (arXiv:2307.16459v2 [cs.LG] UPDATED)\nAbstract: The performance of a lifelong learning (L3) model degrades when it is trained on a series of tasks, as the geometrical formation of the embedding space changes while learning novel concepts sequentially. The majority of existing L3 approaches operate on a fixed-curvature (e.g., zero-curvature Euclidean) space that is not necessarily suitable for modeling the complex geometric structure of data. Furthermore, the distillation strategies apply constraints directly on low-dimensional embeddings, discouraging the L3 model from learning new concepts by making the model highly stable. To address the problem, we propose a distillation strategy named L3DMC that operates on mixed-curvature spaces to preserve the already-learned knowledge by modeling and maintaining complex geometrical structures. We propose to embed the projected low dimensional embedding of fixed-curvature spaces (Euclidean and hyperbolic) to higher-dimensional Reproducing Kernel Hilbert Space (RKHS) using a positive-definite k",
    "path": "papers/23/07/2307.16459.json",
    "total_tokens": 906,
    "translated_title": "L3DMC: 使用混合曲率空间的蒸馏进行终身学习",
    "translated_abstract": "当终身学习模型在一系列任务上进行训练时，其性能会下降，因为在顺序学习新概念时嵌入空间的几何结构会发生变化。现有的终身学习方法大多在固定曲率（例如零曲率的欧几里德空间）上运行，这并不适合建模复杂的数据几何结构。此外，蒸馏策略直接应用于低维嵌入，通过使模型高度稳定来阻碍终身学习模型学习新概念。为了解决这个问题，我们提出了一种名为L3DMC的蒸馏策略，它在混合曲率空间上操作，通过建模和维护复杂的几何结构来保留已经学到的知识。我们建议使用正定的重构核希尔伯特空间（RKHS）将固定曲率空间（欧几里德和双曲）的投影低维嵌入到更高维度的空间中。",
    "tldr": "L3DMC是一种使用混合曲率空间进行终身学习的蒸馏策略，通过建模和维护复杂几何结构来保留已经学到的知识。",
    "en_tdlr": "L3DMC is a distillation strategy for lifelong learning that operates on mixed-curvature spaces to preserve already-learned knowledge by modeling and maintaining complex geometrical structures."
}