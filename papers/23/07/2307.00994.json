{
    "title": "Environmental effects on emergent strategy in micro-scale multi-agent reinforcement learning. (arXiv:2307.00994v2 [physics.bio-ph] UPDATED)",
    "abstract": "Multi-Agent Reinforcement Learning (MARL) is a promising candidate for realizing efficient control of microscopic particles, of which micro-robots are a subset. However, the microscopic particles' environment presents unique challenges, such as Brownian motion at sufficiently small length-scales. In this work, we explore the role of temperature in the emergence and efficacy of strategies in MARL systems using particle-based Langevin molecular dynamics simulations as a realistic representation of micro-scale environments. To this end, we perform experiments on two different multi-agent tasks in microscopic environments at different temperatures, detecting the source of a concentration gradient and rotation of a rod. We find that at higher temperatures, the RL agents identify new strategies for achieving these tasks, highlighting the importance of understanding this regime and providing insight into optimal training strategies for bridging the generalization gap between simulation and re",
    "link": "http://arxiv.org/abs/2307.00994",
    "context": "Title: Environmental effects on emergent strategy in micro-scale multi-agent reinforcement learning. (arXiv:2307.00994v2 [physics.bio-ph] UPDATED)\nAbstract: Multi-Agent Reinforcement Learning (MARL) is a promising candidate for realizing efficient control of microscopic particles, of which micro-robots are a subset. However, the microscopic particles' environment presents unique challenges, such as Brownian motion at sufficiently small length-scales. In this work, we explore the role of temperature in the emergence and efficacy of strategies in MARL systems using particle-based Langevin molecular dynamics simulations as a realistic representation of micro-scale environments. To this end, we perform experiments on two different multi-agent tasks in microscopic environments at different temperatures, detecting the source of a concentration gradient and rotation of a rod. We find that at higher temperatures, the RL agents identify new strategies for achieving these tasks, highlighting the importance of understanding this regime and providing insight into optimal training strategies for bridging the generalization gap between simulation and re",
    "path": "papers/23/07/2307.00994.json",
    "total_tokens": 961,
    "translated_title": "微观尺度多智能体强化学习中的环境对新兴策略的影响",
    "translated_abstract": "多智能体强化学习（MARL）是实现微观粒子（如微型机器人）高效控制的有前景的候选方案。然而，微观粒子的环境存在着独特的挑战，例如在足够小的尺度上的布朗运动。本研究利用基于粒子的Langevin分子动力学模拟作为微观环境的逼真表示，探讨了温度在MARL系统中策略形成和有效性方面的作用。为此，我们在不同温度下对微观环境中的两个不同的多智能体任务进行了实验，这包括检测浓度梯度的来源和杆的旋转。我们发现，在较高温度下，RL智能体能够识别出实现这些任务的新策略，突显了理解该温度范围的重要性，并为弥合模拟与实际环境之间的泛化差距提供了训练策略的洞见。",
    "tldr": "本研究使用基于粒子的动力学模拟研究了微观环境中温度对多智能体强化学习系统中策略形成和有效性的影响。实验结果显示，在较高温度下，强化学习智能体能够发展出新的策略，为解决微观尺度控制问题提供了洞见。"
}