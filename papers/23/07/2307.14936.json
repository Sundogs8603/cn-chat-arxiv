{
    "title": "PanGu-Coder2: Boosting Large Language Models for Code with Ranking Feedback. (arXiv:2307.14936v1 [cs.CL])",
    "abstract": "Large Language Models for Code (Code LLM) are flourishing. New and powerful models are released on a weekly basis, demonstrating remarkable performance on the code generation task. Various approaches have been proposed to boost the code generation performance of pre-trained Code LLMs, such as supervised fine-tuning, instruction tuning, reinforcement learning, etc. In this paper, we propose a novel RRTF (Rank Responses to align Test&Teacher Feedback) framework, which can effectively and efficiently boost pre-trained large language models for code generation. Under this framework, we present PanGu-Coder2, which achieves 62.20% pass@1 on the OpenAI HumanEval benchmark. Furthermore, through an extensive evaluation on CoderEval and LeetCode benchmarks, we show that PanGu-Coder2 consistently outperforms all previous Code LLMs.",
    "link": "http://arxiv.org/abs/2307.14936",
    "context": "Title: PanGu-Coder2: Boosting Large Language Models for Code with Ranking Feedback. (arXiv:2307.14936v1 [cs.CL])\nAbstract: Large Language Models for Code (Code LLM) are flourishing. New and powerful models are released on a weekly basis, demonstrating remarkable performance on the code generation task. Various approaches have been proposed to boost the code generation performance of pre-trained Code LLMs, such as supervised fine-tuning, instruction tuning, reinforcement learning, etc. In this paper, we propose a novel RRTF (Rank Responses to align Test&Teacher Feedback) framework, which can effectively and efficiently boost pre-trained large language models for code generation. Under this framework, we present PanGu-Coder2, which achieves 62.20% pass@1 on the OpenAI HumanEval benchmark. Furthermore, through an extensive evaluation on CoderEval and LeetCode benchmarks, we show that PanGu-Coder2 consistently outperforms all previous Code LLMs.",
    "path": "papers/23/07/2307.14936.json",
    "total_tokens": 830,
    "translated_title": "PanGu-Coder2：利用排名反馈增强大型语言模型在代码生成方面的能力",
    "translated_abstract": "大型语言模型（Code LLM）在代码生成任务上展现出了卓越的性能，每周都有新的强大模型发布。为了提高预训练的Code LLM的代码生成性能，提出了各种方法，如有监督的微调、指令微调、强化学习等。本文提出了一种新颖的RRTF（Rank Responses to align Test&Teacher Feedback）框架，可以有效、高效地提升预训练的大型语言模型在代码生成方面的能力。在该框架下，我们提出了PanGu-Coder2，在OpenAI HumanEval基准上取得了62.20%的一级通过率。此外，通过对CoderEval和LeetCode基准的广泛评估，我们展示了PanGu-Coder2始终优于所有先前的Code LLMs。",
    "tldr": "本文提出了一种新的框架RRTF，以增强预训练的大型语言模型在代码生成方面的能力。PanGu-Coder2是该框架的实现，在多个基准测试中均表现出色，优于其他先前的Code LLMs。",
    "en_tdlr": "This paper proposes a novel framework called RRTF to enhance the code generation capability of pre-trained large language models. PanGu-Coder2, the implementation of this framework, consistently outperforms previous Code LLMs in various benchmarks."
}