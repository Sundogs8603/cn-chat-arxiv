{
    "title": "MoP-CLIP: A Mixture of Prompt-Tuned CLIP Models for Domain Incremental Learning. (arXiv:2307.05707v1 [cs.CV])",
    "abstract": "Despite the recent progress in incremental learning, addressing catastrophic forgetting under distributional drift is still an open and important problem. Indeed, while state-of-the-art domain incremental learning (DIL) methods perform satisfactorily within known domains, their performance largely degrades in the presence of novel domains. This limitation hampers their generalizability, and restricts their scalability to more realistic settings where train and test data are drawn from different distributions. To address these limitations, we present a novel DIL approach based on a mixture of prompt-tuned CLIP models (MoP-CLIP), which generalizes the paradigm of S-Prompting to handle both in-distribution and out-of-distribution data at inference. In particular, at the training stage we model the features distribution of every class in each domain, learning individual text and visual prompts to adapt to a given domain. At inference, the learned distributions allow us to identify whether ",
    "link": "http://arxiv.org/abs/2307.05707",
    "context": "Title: MoP-CLIP: A Mixture of Prompt-Tuned CLIP Models for Domain Incremental Learning. (arXiv:2307.05707v1 [cs.CV])\nAbstract: Despite the recent progress in incremental learning, addressing catastrophic forgetting under distributional drift is still an open and important problem. Indeed, while state-of-the-art domain incremental learning (DIL) methods perform satisfactorily within known domains, their performance largely degrades in the presence of novel domains. This limitation hampers their generalizability, and restricts their scalability to more realistic settings where train and test data are drawn from different distributions. To address these limitations, we present a novel DIL approach based on a mixture of prompt-tuned CLIP models (MoP-CLIP), which generalizes the paradigm of S-Prompting to handle both in-distribution and out-of-distribution data at inference. In particular, at the training stage we model the features distribution of every class in each domain, learning individual text and visual prompts to adapt to a given domain. At inference, the learned distributions allow us to identify whether ",
    "path": "papers/23/07/2307.05707.json",
    "total_tokens": 926,
    "translated_title": "MoP-CLIP：一种用于领域增量学习的混合Prompt-Tuned CLIP模型",
    "translated_abstract": "尽管增量学习取得了近期的进展，但解决在分布漂移下的灾难性遗忘问题仍然是一个开放且重要的问题。尽管当前领域增量学习（DIL）方法在已知领域内表现令人满意，但在新领域中性能大幅下降。这种限制使其难以泛化，并限制了在训练和测试数据来源于不同分布的更现实的情景下的可扩展性。为了解决这些限制，我们提出了一种基于混合Prompt-Tuned CLIP模型（MoP-CLIP）的新型DIL方法，该方法将S-Prompting的范式推广到处理推断时的分布内和分布外数据。具体而言，在训练阶段，我们对每个领域中每个类的特征分布进行建模，并学习个体化的文本和视觉提示来适应给定的领域。在推断阶段，学到的分布可以帮助我们识别是否",
    "tldr": "MoP-CLIP是一种用于领域增量学习的混合Prompt-Tuned CLIP模型，该模型通过模拟每个领域中每个类的特征分布并学习个体化的提示，实现了对分布内外数据的处理和推断。"
}