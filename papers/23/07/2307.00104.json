{
    "title": "Obscured Wildfire Flame Detection By Temporal Analysis of Smoke Patterns Captured by Unmanned Aerial Systems. (arXiv:2307.00104v1 [cs.CV])",
    "abstract": "This research paper addresses the challenge of detecting obscured wildfires (when the fire flames are covered by trees, smoke, clouds, and other natural barriers) in real-time using drones equipped only with RGB cameras. We propose a novel methodology that employs semantic segmentation based on the temporal analysis of smoke patterns in video sequences. Our approach utilizes an encoder-decoder architecture based on deep convolutional neural network architecture with a pre-trained CNN encoder and 3D convolutions for decoding while using sequential stacking of features to exploit temporal variations. The predicted fire locations can assist drones in effectively combating forest fires and pinpoint fire retardant chemical drop on exact flame locations. We applied our method to a curated dataset derived from the FLAME2 dataset that includes RGB video along with IR video to determine the ground truth. Our proposed method has a unique property of detecting obscured fire and achieves a Dice sc",
    "link": "http://arxiv.org/abs/2307.00104",
    "context": "Title: Obscured Wildfire Flame Detection By Temporal Analysis of Smoke Patterns Captured by Unmanned Aerial Systems. (arXiv:2307.00104v1 [cs.CV])\nAbstract: This research paper addresses the challenge of detecting obscured wildfires (when the fire flames are covered by trees, smoke, clouds, and other natural barriers) in real-time using drones equipped only with RGB cameras. We propose a novel methodology that employs semantic segmentation based on the temporal analysis of smoke patterns in video sequences. Our approach utilizes an encoder-decoder architecture based on deep convolutional neural network architecture with a pre-trained CNN encoder and 3D convolutions for decoding while using sequential stacking of features to exploit temporal variations. The predicted fire locations can assist drones in effectively combating forest fires and pinpoint fire retardant chemical drop on exact flame locations. We applied our method to a curated dataset derived from the FLAME2 dataset that includes RGB video along with IR video to determine the ground truth. Our proposed method has a unique property of detecting obscured fire and achieves a Dice sc",
    "path": "papers/23/07/2307.00104.json",
    "total_tokens": 954,
    "translated_title": "通过对无人机捕捉的烟雾模式的时间分析来检测被遮挡的野火火焰",
    "translated_abstract": "本研究论文解决了使用仅配备RGB相机的无人机实时检测被树木、烟雾、云雾和其他自然屏障遮挡的野火（当火焰被遮挡时）的挑战。我们提出了一种新的方法，利用视频序列中烟雾模式的语义分割进行时间分析。我们的方法利用了基于深度卷积神经网络的编码器-解码器架构，采用预训练的CNN编码器和3D卷积进行解码，并使用特征的顺序叠加来利用时间变化。预测的火灾位置可以帮助无人机有效地对抗森林火灾，并准确定位火焰位置进行阻燃化学物质投放。我们将我们的方法应用于从FLAME2数据集衍生的精选数据集，该数据集包括RGB视频和IR视频以确定地面真实情况。我们提出的方法具有检测被遮挡的火灾的独特属性，并实现了一种Dice系数。",
    "tldr": "本论文通过对视频序列中烟雾模式的时间分析，提出了一种用于实时检测被遮挡的野火火焰的方法，通过预测火灾位置来帮助无人机对抗森林火灾。这种方法具有独特的检测被遮挡的火灾的能力。"
}