{
    "title": "ATWM: Defense against adversarial malware based on adversarial training. (arXiv:2307.05095v1 [cs.CR])",
    "abstract": "Deep learning technology has made great achievements in the field of image. In order to defend against malware attacks, researchers have proposed many Windows malware detection models based on deep learning. However, deep learning models are vulnerable to adversarial example attacks. Malware can generate adversarial malware with the same malicious function to attack the malware detection model and evade detection of the model. Currently, many adversarial defense studies have been proposed, but existing adversarial defense studies are based on image sample and cannot be directly applied to malware sample. Therefore, this paper proposes an adversarial malware defense method based on adversarial training. This method uses preprocessing to defend simple adversarial examples to reduce the difficulty of adversarial training. Moreover, this method improves the adversarial defense capability of the model through adversarial training. We experimented with three attack methods in two sets of dat",
    "link": "http://arxiv.org/abs/2307.05095",
    "context": "Title: ATWM: Defense against adversarial malware based on adversarial training. (arXiv:2307.05095v1 [cs.CR])\nAbstract: Deep learning technology has made great achievements in the field of image. In order to defend against malware attacks, researchers have proposed many Windows malware detection models based on deep learning. However, deep learning models are vulnerable to adversarial example attacks. Malware can generate adversarial malware with the same malicious function to attack the malware detection model and evade detection of the model. Currently, many adversarial defense studies have been proposed, but existing adversarial defense studies are based on image sample and cannot be directly applied to malware sample. Therefore, this paper proposes an adversarial malware defense method based on adversarial training. This method uses preprocessing to defend simple adversarial examples to reduce the difficulty of adversarial training. Moreover, this method improves the adversarial defense capability of the model through adversarial training. We experimented with three attack methods in two sets of dat",
    "path": "papers/23/07/2307.05095.json",
    "total_tokens": 866,
    "translated_title": "ATWM：基于对抗训练的对抗恶意软件防御方法",
    "translated_abstract": "深度学习技术在图像领域取得了巨大的成就。为了抵御恶意软件攻击，研究人员提出了许多基于深度学习的Windows恶意软件检测模型。然而，深度学习模型容易受到对抗样本攻击。恶意软件可以生成具有相同恶意功能的对抗性恶意软件，以攻击恶意软件检测模型并逃避其检测。目前，已经提出了许多对抗性防御研究，但现有的对抗性防御研究都是基于图像样本，不能直接应用于恶意软件样本。因此，本文提出了一种基于对抗训练的对抗恶意软件防御方法。该方法通过预处理来防御简单的对抗样本，以降低对抗训练的难度。此外，该方法通过对抗训练提高了模型的对抗防御能力。我们在两组数据集中使用了三种攻击方法进行了实验证明。",
    "tldr": "本文提出了一种基于对抗训练的对抗恶意软件防御方法，通过预处理降低简单的对抗样本的防御难度，并通过对抗训练提高模型的对抗防御能力。"
}