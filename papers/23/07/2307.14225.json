{
    "title": "Large Language Models are Competitive Near Cold-start Recommenders for Language- and Item-based Preferences. (arXiv:2307.14225v1 [cs.IR])",
    "abstract": "Traditional recommender systems leverage users' item preference history to recommend novel content that users may like. However, modern dialog interfaces that allow users to express language-based preferences offer a fundamentally different modality for preference input. Inspired by recent successes of prompting paradigms for large language models (LLMs), we study their use for making recommendations from both item-based and language-based preferences in comparison to state-of-the-art item-based collaborative filtering (CF) methods. To support this investigation, we collect a new dataset consisting of both item-based and language-based preferences elicited from users along with their ratings on a variety of (biased) recommended items and (unbiased) random items. Among numerous experimental results, we find that LLMs provide competitive recommendation performance for pure language-based preferences (no item preferences) in the near cold-start case in comparison to item-based CF methods,",
    "link": "http://arxiv.org/abs/2307.14225",
    "context": "Title: Large Language Models are Competitive Near Cold-start Recommenders for Language- and Item-based Preferences. (arXiv:2307.14225v1 [cs.IR])\nAbstract: Traditional recommender systems leverage users' item preference history to recommend novel content that users may like. However, modern dialog interfaces that allow users to express language-based preferences offer a fundamentally different modality for preference input. Inspired by recent successes of prompting paradigms for large language models (LLMs), we study their use for making recommendations from both item-based and language-based preferences in comparison to state-of-the-art item-based collaborative filtering (CF) methods. To support this investigation, we collect a new dataset consisting of both item-based and language-based preferences elicited from users along with their ratings on a variety of (biased) recommended items and (unbiased) random items. Among numerous experimental results, we find that LLMs provide competitive recommendation performance for pure language-based preferences (no item preferences) in the near cold-start case in comparison to item-based CF methods,",
    "path": "papers/23/07/2307.14225.json",
    "total_tokens": 878,
    "translated_title": "大规模语言模型在冷启动推荐系统中与基于语言和基于项目偏好竞争力相当",
    "translated_abstract": "传统的推荐系统利用用户的项目偏好历史来推荐用户可能喜欢的新内容。然而，现代对话界面允许用户表达基于语言的偏好，提供了一种根本不同的偏好输入方式。受最近大规模语言模型（LLMs）提示范式的成功启发，我们研究了它们在基于项目和基于语言偏好方面与最先进的基于项目协同过滤（CF）方法相比的推荐应用。为了支持这项研究，我们收集了一个新的数据集，其中包含从用户那里引发出来的基于项目和基于语言偏好，以及他们对各种（有偏见的）推荐项目和（无偏见的）随机项目的评分。在众多实验结果中，我们发现在纯基于语言偏好（没有项目偏好）的情况下，LLMs在接近冷启动情况下与基于项目的CF方法相比具有竞争力的推荐性能。",
    "tldr": "大规模语言模型（LLMs）在冷启动情况下提供了与基于项目协同过滤（CF）方法相当的推荐性能，特别是在纯基于语言偏好的情况下。"
}