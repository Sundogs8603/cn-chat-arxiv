{
    "title": "Selective Perception: Optimizing State Descriptions with Reinforcement Learning for Language Model Actors. (arXiv:2307.11922v1 [cs.LG])",
    "abstract": "Large language models (LLMs) are being applied as actors for sequential decision making tasks in domains such as robotics and games, utilizing their general world knowledge and planning abilities. However, previous work does little to explore what environment state information is provided to LLM actors via language. Exhaustively describing high-dimensional states can impair performance and raise inference costs for LLM actors. Previous LLM actors avoid the issue by relying on hand-engineered, task-specific protocols to determine which features to communicate about a state and which to leave out. In this work, we propose Brief Language INputs for DEcision-making Responses (BLINDER), a method for automatically selecting concise state descriptions by learning a value function for task-conditioned state descriptions. We evaluate BLINDER on the challenging video game NetHack and a robotic manipulation task. Our method improves task success rate, reduces input size and compute costs, and gen",
    "link": "http://arxiv.org/abs/2307.11922",
    "context": "Title: Selective Perception: Optimizing State Descriptions with Reinforcement Learning for Language Model Actors. (arXiv:2307.11922v1 [cs.LG])\nAbstract: Large language models (LLMs) are being applied as actors for sequential decision making tasks in domains such as robotics and games, utilizing their general world knowledge and planning abilities. However, previous work does little to explore what environment state information is provided to LLM actors via language. Exhaustively describing high-dimensional states can impair performance and raise inference costs for LLM actors. Previous LLM actors avoid the issue by relying on hand-engineered, task-specific protocols to determine which features to communicate about a state and which to leave out. In this work, we propose Brief Language INputs for DEcision-making Responses (BLINDER), a method for automatically selecting concise state descriptions by learning a value function for task-conditioned state descriptions. We evaluate BLINDER on the challenging video game NetHack and a robotic manipulation task. Our method improves task success rate, reduces input size and compute costs, and gen",
    "path": "papers/23/07/2307.11922.json",
    "total_tokens": 865,
    "translated_title": "选择性感知：利用强化学习为语言模型演员优化状态描述",
    "translated_abstract": "大型语言模型(LLM)被应用于机器人和游戏等顺序决策任务的演员中，利用其丰富的世界知识和规划能力。然而，以往的研究很少探索通过语言向LLM演员提供什么环境状态信息。详尽描述高维状态可能会影响性能并增加LLM演员的推理成本。以前的LLM演员通过依赖手工设计的任务特定协议来确定该状态的哪些特征需要进行传递，哪些不需要。在本工作中，我们提出了一种名为BLINDER的方法，通过学习任务条件下状态描述的值函数，自动选择简明的状态描述。我们在具有挑战性的视频游戏NetHack和机器人操作任务中评估了BLINDER。我们的方法提高了任务成功率，减少了输入大小和计算成本，并且提高了生成的结果。",
    "tldr": "本研究提出了一种名为BLINDER的方法，通过学习任务条件下状态描述的值函数，自动选择简明的状态描述，以优化大型语言模型(LLM)演员在顺序决策任务中的性能和效率。",
    "en_tdlr": "This study proposes a method called BLINDER, which automatically selects concise state descriptions for large language model (LLM) actors in sequential decision-making tasks by learning a value function for task-conditioned state descriptions, aiming to optimize their performance and efficiency."
}