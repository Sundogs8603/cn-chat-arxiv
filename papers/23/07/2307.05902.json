{
    "title": "Stability Guarantees for Feature Attributions with Multiplicative Smoothing. (arXiv:2307.05902v1 [cs.LG])",
    "abstract": "Explanation methods for machine learning models tend to not provide any formal guarantees and may not reflect the underlying decision-making process. In this work, we analyze stability as a property for reliable feature attribution methods. We prove that relaxed variants of stability are guaranteed if the model is sufficiently Lipschitz with respect to the masking of features. To achieve such a model, we develop a smoothing method called Multiplicative Smoothing (MuS). We show that MuS overcomes theoretical limitations of standard smoothing techniques and can be integrated with any classifier and feature attribution method. We evaluate MuS on vision and language models with a variety of feature attribution methods, such as LIME and SHAP, and demonstrate that MuS endows feature attributions with non-trivial stability guarantees.",
    "link": "http://arxiv.org/abs/2307.05902",
    "context": "Title: Stability Guarantees for Feature Attributions with Multiplicative Smoothing. (arXiv:2307.05902v1 [cs.LG])\nAbstract: Explanation methods for machine learning models tend to not provide any formal guarantees and may not reflect the underlying decision-making process. In this work, we analyze stability as a property for reliable feature attribution methods. We prove that relaxed variants of stability are guaranteed if the model is sufficiently Lipschitz with respect to the masking of features. To achieve such a model, we develop a smoothing method called Multiplicative Smoothing (MuS). We show that MuS overcomes theoretical limitations of standard smoothing techniques and can be integrated with any classifier and feature attribution method. We evaluate MuS on vision and language models with a variety of feature attribution methods, such as LIME and SHAP, and demonstrate that MuS endows feature attributions with non-trivial stability guarantees.",
    "path": "papers/23/07/2307.05902.json",
    "total_tokens": 850,
    "translated_title": "带有乘法平滑的特征归因稳定性保证",
    "translated_abstract": "机器学习模型的解释方法往往不能提供任何形式的保证，也可能不反映底层的决策过程。在这项工作中，我们将稳定性作为可靠的特征归因方法的一个属性进行分析。我们证明了如果模型在特征屏蔽方面具有足够的Lipschitz性质，则可以保证放松变体的稳定性。为了实现这样的模型，我们开发了一种称为乘法平滑（MuS）的平滑方法。我们展示了MuS克服了标准平滑技术的理论限制，并且可以与任何分类器和特征归因方法结合使用。我们使用各种特征归因方法（如LIME和SHAP）对视觉和语言模型进行了MuS的评估，并展示了MuS赋予了特征归因以非平凡的稳定性保证。",
    "tldr": "本文提出了一种基于乘法平滑的特征归因方法，通过证明模型的Lipschitz性质，保证了其稳定性，并在视觉和语言模型上进行了评估，显示了非平凡的稳定性保证。",
    "en_tdlr": "This paper presents a feature attribution method based on multiplicative smoothing, which guarantees stability by proving the Lipschitz property of the model. The method, called Multiplicative Smoothing (MuS), overcomes theoretical limitations of standard smoothing techniques and is evaluated on vision and language models, demonstrating non-trivial stability guarantees."
}