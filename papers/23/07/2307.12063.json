{
    "title": "Balancing Exploration and Exploitation in Hierarchical Reinforcement Learning via Latent Landmark Graphs. (arXiv:2307.12063v1 [cs.LG])",
    "abstract": "Goal-Conditioned Hierarchical Reinforcement Learning (GCHRL) is a promising paradigm to address the exploration-exploitation dilemma in reinforcement learning. It decomposes the source task into subgoal conditional subtasks and conducts exploration and exploitation in the subgoal space. The effectiveness of GCHRL heavily relies on subgoal representation functions and subgoal selection strategy. However, existing works often overlook the temporal coherence in GCHRL when learning latent subgoal representations and lack an efficient subgoal selection strategy that balances exploration and exploitation. This paper proposes HIerarchical reinforcement learning via dynamically building Latent Landmark graphs (HILL) to overcome these limitations. HILL learns latent subgoal representations that satisfy temporal coherence using a contrastive representation learning objective. Based on these representations, HILL dynamically builds latent landmark graphs and employs a novelty measure on nodes and",
    "link": "http://arxiv.org/abs/2307.12063",
    "context": "Title: Balancing Exploration and Exploitation in Hierarchical Reinforcement Learning via Latent Landmark Graphs. (arXiv:2307.12063v1 [cs.LG])\nAbstract: Goal-Conditioned Hierarchical Reinforcement Learning (GCHRL) is a promising paradigm to address the exploration-exploitation dilemma in reinforcement learning. It decomposes the source task into subgoal conditional subtasks and conducts exploration and exploitation in the subgoal space. The effectiveness of GCHRL heavily relies on subgoal representation functions and subgoal selection strategy. However, existing works often overlook the temporal coherence in GCHRL when learning latent subgoal representations and lack an efficient subgoal selection strategy that balances exploration and exploitation. This paper proposes HIerarchical reinforcement learning via dynamically building Latent Landmark graphs (HILL) to overcome these limitations. HILL learns latent subgoal representations that satisfy temporal coherence using a contrastive representation learning objective. Based on these representations, HILL dynamically builds latent landmark graphs and employs a novelty measure on nodes and",
    "path": "papers/23/07/2307.12063.json",
    "total_tokens": 856,
    "translated_title": "通过动态构建潜在地标图在分层强化学习中平衡探索和利用",
    "translated_abstract": "目标条件分层强化学习(GCHRL)是解决强化学习中探索-利用困境的一种有前途的范例。它将源任务分解为子目标条件子任务，并在子目标空间中进行探索和利用。GCHRL的有效性在很大程度上依赖于子目标表示函数和子目标选择策略。然而，现有的工作常常忽视了GCHRL中学习潜在子目标表示的时间一致性，并且缺乏一种平衡探索和利用的高效子目标选择策略。本文提出了通过动态构建Latent Landmark图的分层强化学习（HILL）来克服这些局限性。HILL使用对比表示学习目标学习满足时间一致性的潜在子目标表示。基于这些表示，HILL动态构建潜在地标图，并在节点和边上使用新颖性度量。",
    "tldr": "本文提出了一种通过动态构建潜在地标图来平衡探索和利用，解决了目标条件分层强化学习中的时间一致性和子目标选择策略的问题。"
}