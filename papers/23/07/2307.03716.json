{
    "title": "SAR: Generalization of Physiological Agility and Dexterity via Synergistic Action Representation. (arXiv:2307.03716v1 [cs.RO])",
    "abstract": "Learning effective continuous control policies in high-dimensional systems, including musculoskeletal agents, remains a significant challenge. Over the course of biological evolution, organisms have developed robust mechanisms for overcoming this complexity to learn highly sophisticated strategies for motor control. What accounts for this robust behavioral flexibility? Modular control via muscle synergies, i.e. coordinated muscle co-contractions, is considered to be one putative mechanism that enables organisms to learn muscle control in a simplified and generalizable action space. Drawing inspiration from this evolved motor control strategy, we use physiologically accurate human hand and leg models as a testbed for determining the extent to which a Synergistic Action Representation (SAR) acquired from simpler tasks facilitates learning more complex tasks. We find in both cases that SAR-exploiting policies significantly outperform end-to-end reinforcement learning. Policies trained wit",
    "link": "http://arxiv.org/abs/2307.03716",
    "context": "Title: SAR: Generalization of Physiological Agility and Dexterity via Synergistic Action Representation. (arXiv:2307.03716v1 [cs.RO])\nAbstract: Learning effective continuous control policies in high-dimensional systems, including musculoskeletal agents, remains a significant challenge. Over the course of biological evolution, organisms have developed robust mechanisms for overcoming this complexity to learn highly sophisticated strategies for motor control. What accounts for this robust behavioral flexibility? Modular control via muscle synergies, i.e. coordinated muscle co-contractions, is considered to be one putative mechanism that enables organisms to learn muscle control in a simplified and generalizable action space. Drawing inspiration from this evolved motor control strategy, we use physiologically accurate human hand and leg models as a testbed for determining the extent to which a Synergistic Action Representation (SAR) acquired from simpler tasks facilitates learning more complex tasks. We find in both cases that SAR-exploiting policies significantly outperform end-to-end reinforcement learning. Policies trained wit",
    "path": "papers/23/07/2307.03716.json",
    "total_tokens": 934,
    "translated_title": "SAR: 通过协同行动表示实现生理敏捷性和灵巧性的普适性",
    "translated_abstract": "在高维系统中学习高效连续控制策略，包括肌肉骨骼代理，仍然是一个重大挑战。通过生物进化的过程中，生物体发展出了克服这种复杂性的鲁棒机制，学习了高度复杂的运动控制策略。是什么导致了这种鲁棒的行为灵活性呢？通过肌肉协同的模块化控制被认为是一种潜在的机制，使生物能够在简化和可推广的行动空间中学习肌肉控制。受到这种进化的运动控制策略的启发，我们使用生理准确的人手和腿模型作为测试平台，确定从简单任务中获得的协同行动表示（SAR）在学习更复杂任务中的作用程度。我们发现，在这两种情况下，利用SAR的策略明显优于端到端强化学习。通过SAR进行训练的策略优于端到端强化学习.",
    "tldr": "本研究将生物进化中发展出的肌肉协同控制策略应用于人手和腿模型，发现通过协同行动表示（SAR）训练的策略在学习复杂任务时明显优于端到端强化学习。",
    "en_tdlr": "This study applies the evolved modular control strategy of muscle synergies to human hand and leg models, and finds that policies trained with Synergistic Action Representation (SAR) significantly outperform end-to-end reinforcement learning in learning complex tasks."
}