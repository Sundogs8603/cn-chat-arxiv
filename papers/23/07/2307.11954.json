{
    "title": "On-Robot Bayesian Reinforcement Learning for POMDPs. (arXiv:2307.11954v1 [cs.RO])",
    "abstract": "Robot learning is often difficult due to the expense of gathering data. The need for large amounts of data can, and should, be tackled with effective algorithms and leveraging expert information on robot dynamics. Bayesian reinforcement learning (BRL), thanks to its sample efficiency and ability to exploit prior knowledge, is uniquely positioned as such a solution method. Unfortunately, the application of BRL has been limited due to the difficulties of representing expert knowledge as well as solving the subsequent inference problem. This paper advances BRL for robotics by proposing a specialized framework for physical systems. In particular, we capture this knowledge in a factored representation, then demonstrate the posterior factorizes in a similar shape, and ultimately formalize the model in a Bayesian framework. We then introduce a sample-based online solution method, based on Monte-Carlo tree search and particle filtering, specialized to solve the resulting model. This approach c",
    "link": "http://arxiv.org/abs/2307.11954",
    "context": "Title: On-Robot Bayesian Reinforcement Learning for POMDPs. (arXiv:2307.11954v1 [cs.RO])\nAbstract: Robot learning is often difficult due to the expense of gathering data. The need for large amounts of data can, and should, be tackled with effective algorithms and leveraging expert information on robot dynamics. Bayesian reinforcement learning (BRL), thanks to its sample efficiency and ability to exploit prior knowledge, is uniquely positioned as such a solution method. Unfortunately, the application of BRL has been limited due to the difficulties of representing expert knowledge as well as solving the subsequent inference problem. This paper advances BRL for robotics by proposing a specialized framework for physical systems. In particular, we capture this knowledge in a factored representation, then demonstrate the posterior factorizes in a similar shape, and ultimately formalize the model in a Bayesian framework. We then introduce a sample-based online solution method, based on Monte-Carlo tree search and particle filtering, specialized to solve the resulting model. This approach c",
    "path": "papers/23/07/2307.11954.json",
    "total_tokens": 926,
    "translated_title": "关于基于贝叶斯强化学习解决部分可观测马尔可夫决策过程的机器人的研究",
    "translated_abstract": "由于获取数据的成本较高，机器人学习往往困难重重。然而，通过有效的算法和充分利用专家对机器人动态的信息，我们可以解决大量数据的需求。基于贝叶斯强化学习（BRL）由于其样本效率和对先验知识的利用能力，在这一问题上独具优势。不幸的是，由于表达专家知识和解决后续推理问题的困难，BRL的应用受到了限制。本文通过提出一个专门针对物理系统的框架，推动了机器人中的BRL。具体而言，我们以分解表示的形式捕捉这些知识，然后展示了后验概率的分解形式，并最终在贝叶斯框架下将模型形式化。然后，我们引入了一种基于蒙特卡洛树搜索和粒子滤波的基于样本的在线解决方法，专门用于解决所得到的模型。",
    "tldr": "本研究提供了解决机器人学习中大量数据需求的方法，通过将专家知识捕捉并形式化为贝叶斯框架，使用基于样本的在线解决方法来推动基于贝叶斯强化学习在机器人中的应用。"
}