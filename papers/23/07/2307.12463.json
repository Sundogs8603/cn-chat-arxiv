{
    "title": "Rethinking Data Distillation: Do Not Overlook Calibration. (arXiv:2307.12463v2 [cs.CV] UPDATED)",
    "abstract": "Neural networks trained on distilled data often produce over-confident output and require correction by calibration methods. Existing calibration methods such as temperature scaling and mixup work well for networks trained on original large-scale data. However, we find that these methods fail to calibrate networks trained on data distilled from large source datasets. In this paper, we show that distilled data lead to networks that are not calibratable due to (i) a more concentrated distribution of the maximum logits and (ii) the loss of information that is semantically meaningful but unrelated to classification tasks. To address this problem, we propose Masked Temperature Scaling (MTS) and Masked Distillation Training (MDT) which mitigate the limitations of distilled data and achieve better calibration results while maintaining the efficiency of dataset distillation.",
    "link": "http://arxiv.org/abs/2307.12463",
    "context": "Title: Rethinking Data Distillation: Do Not Overlook Calibration. (arXiv:2307.12463v2 [cs.CV] UPDATED)\nAbstract: Neural networks trained on distilled data often produce over-confident output and require correction by calibration methods. Existing calibration methods such as temperature scaling and mixup work well for networks trained on original large-scale data. However, we find that these methods fail to calibrate networks trained on data distilled from large source datasets. In this paper, we show that distilled data lead to networks that are not calibratable due to (i) a more concentrated distribution of the maximum logits and (ii) the loss of information that is semantically meaningful but unrelated to classification tasks. To address this problem, we propose Masked Temperature Scaling (MTS) and Masked Distillation Training (MDT) which mitigate the limitations of distilled data and achieve better calibration results while maintaining the efficiency of dataset distillation.",
    "path": "papers/23/07/2307.12463.json",
    "total_tokens": 838,
    "translated_title": "重新思考数据蒸馏：不要忽视校准",
    "translated_abstract": "在经过蒸馏的数据上训练的神经网络经常产生过于自信的输出，并需要通过校准方法进行修正。现有的校准方法，如温度缩放和混合训练，在原始的大规模数据上训练的神经网络上效果良好。然而，我们发现这些方法无法对从大源数据集蒸馏出的数据进行校准。本文中，我们展示了蒸馏数据会导致网络无法校准，原因是（i）最大logit分布更为集中，以及（ii）在分类任务无关但语义意义明确的信息损失。为了解决这个问题，我们提出了遮蔽温度缩放（MTS）和遮蔽蒸馏训练（MDT）方法，以减轻蒸馏数据的限制，并在保持数据蒸馏效率的同时实现更好的校准结果。",
    "tldr": "本文指出经过蒸馏的数据无法很好地进行校准，因为在这种情况下，网络的 logits 分布更加集中，并且语义明确但与分类任务无关的信息会丢失。为了解决这个问题，我们提出了遮蔽温度缩放 (MTS) 和遮蔽蒸馏训练 (MDT) 方法，以获得更好的校准结果。"
}