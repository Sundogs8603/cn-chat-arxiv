{
    "title": "Estimating label quality and errors in semantic segmentation data via any model. (arXiv:2307.05080v1 [cs.LG])",
    "abstract": "The labor-intensive annotation process of semantic segmentation datasets is often prone to errors, since humans struggle to label every pixel correctly. We study algorithms to automatically detect such annotation errors, in particular methods to score label quality, such that the images with the lowest scores are least likely to be correctly labeled. This helps prioritize what data to review in order to ensure a high-quality training/evaluation dataset, which is critical in sensitive applications such as medical imaging and autonomous vehicles. Widely applicable, our label quality scores rely on probabilistic predictions from a trained segmentation model -- any model architecture and training procedure can be utilized. Here we study 7 different label quality scoring methods used in conjunction with a DeepLabV3+ or a FPN segmentation model to detect annotation errors in a version of the SYNTHIA dataset. Precision-recall evaluations reveal a score -- the soft-minimum of the model-estimat",
    "link": "http://arxiv.org/abs/2307.05080",
    "context": "Title: Estimating label quality and errors in semantic segmentation data via any model. (arXiv:2307.05080v1 [cs.LG])\nAbstract: The labor-intensive annotation process of semantic segmentation datasets is often prone to errors, since humans struggle to label every pixel correctly. We study algorithms to automatically detect such annotation errors, in particular methods to score label quality, such that the images with the lowest scores are least likely to be correctly labeled. This helps prioritize what data to review in order to ensure a high-quality training/evaluation dataset, which is critical in sensitive applications such as medical imaging and autonomous vehicles. Widely applicable, our label quality scores rely on probabilistic predictions from a trained segmentation model -- any model architecture and training procedure can be utilized. Here we study 7 different label quality scoring methods used in conjunction with a DeepLabV3+ or a FPN segmentation model to detect annotation errors in a version of the SYNTHIA dataset. Precision-recall evaluations reveal a score -- the soft-minimum of the model-estimat",
    "path": "papers/23/07/2307.05080.json",
    "total_tokens": 906,
    "translated_title": "通过任何模型估计语义分割数据中的标签质量和错误",
    "translated_abstract": "语义分割数据集的劳动密集型注释过程往往容易出现错误，因为人们很难正确标记每个像素。我们研究了自动检测此类注释错误的算法，尤其是评分标签质量的方法，从而使得得分最低的图像最不可能被正确标记。这有助于优先考虑要审查的数据，以确保高质量的训练/评估数据集，在敏感应用（如医学成像和自动驾驶）中至关重要。广泛适用，我们的标签质量评分依靠训练的分割模型的概率预测-任何模型架构和训练过程都可以利用。本文研究了与DeepLabV3+或FPN分割模型结合使用的7种不同的标签质量评分方法，以在SYNTHIA数据集的一个版本中检测注释错误。通过精确度-召回率评估揭示了一个得分-",
    "tldr": "通过任何模型，我们可以估计语义分割数据中标签的质量和错误。这导致了一种用于自动检测错误的标签质量评分方法，并且可以帮助确定需要重点检查的数据，以确保高质量的训练/评估数据集。",
    "en_tdlr": "We propose using any model to estimate the quality and errors of labels in semantic segmentation data. This leads to a label quality scoring method for automatically detecting errors, and helps identify the data that needs to be prioritized for review to ensure a high-quality training/evaluation dataset."
}