{
    "title": "Improving Fairness of Graph Neural Networks: A Graph Counterfactual Perspective. (arXiv:2307.04937v1 [cs.LG])",
    "abstract": "Graph neural networks have shown great ability in representation (GNNs) learning on graphs, facilitating various tasks. Despite their great performance in modeling graphs, recent works show that GNNs tend to inherit and amplify the bias from training data, causing concerns of the adoption of GNNs in high-stake scenarios. Hence, many efforts have been taken for fairness-aware GNNs. However, most existing fair GNNs learn fair node representations by adopting statistical fairness notions, which may fail to alleviate bias in the presence of statistical anomalies. Motivated by causal theory, there are several attempts utilizing graph counterfactual fairness to mitigate root causes of unfairness. However, these methods suffer from non-realistic counterfactuals obtained by perturbation or generation. In this paper, we take a causal view on fair graph learning problem. Guided by the casual analysis, we propose a novel framework CAF, which can select counterfactuals from training data to avoid ",
    "link": "http://arxiv.org/abs/2307.04937",
    "context": "Title: Improving Fairness of Graph Neural Networks: A Graph Counterfactual Perspective. (arXiv:2307.04937v1 [cs.LG])\nAbstract: Graph neural networks have shown great ability in representation (GNNs) learning on graphs, facilitating various tasks. Despite their great performance in modeling graphs, recent works show that GNNs tend to inherit and amplify the bias from training data, causing concerns of the adoption of GNNs in high-stake scenarios. Hence, many efforts have been taken for fairness-aware GNNs. However, most existing fair GNNs learn fair node representations by adopting statistical fairness notions, which may fail to alleviate bias in the presence of statistical anomalies. Motivated by causal theory, there are several attempts utilizing graph counterfactual fairness to mitigate root causes of unfairness. However, these methods suffer from non-realistic counterfactuals obtained by perturbation or generation. In this paper, we take a causal view on fair graph learning problem. Guided by the casual analysis, we propose a novel framework CAF, which can select counterfactuals from training data to avoid ",
    "path": "papers/23/07/2307.04937.json",
    "total_tokens": 906,
    "translated_title": "提高图神经网络公平性：一种图反事实角度",
    "translated_abstract": "图神经网络在图的表示学习中展现了出色的能力，促进了各种任务的进行。尽管它们在建模图中表现出色，但最近的研究表明，GNN倾向于从训练数据中继承和放大偏见，引起了在高风险场景中使用GNN的担忧。因此，已经做出了许多努力来实现公平感知的GNN。然而，大多数现有的公平GNN通过采用统计公平概念来学习公平节点表示，但在统计异常存在的情况下，这种方法可能无法减轻偏见。受因果理论的启发，有几种方法利用图反事实公平性来减轻不公平的根本原因。然而，这些方法会受到通过扰动或生成获得的非现实反事实的影响。在本文中，我们以因果视角看待公平图学习问题。在因果分析的指导下，我们提出了一种新的框架CAF，它可以从训练数据中选择反事实以避免偏见。",
    "tldr": "这项研究提出了以因果视角看待公平图学习问题的框架CAF，通过选择训练数据中的反事实来避免图神经网络中的偏见。"
}