{
    "title": "Magnetic Field-Based Reward Shaping for Goal-Conditioned Reinforcement Learning. (arXiv:2307.08033v1 [cs.LG])",
    "abstract": "Goal-conditioned reinforcement learning (RL) is an interesting extension of the traditional RL framework, where the dynamic environment and reward sparsity can cause conventional learning algorithms to fail. Reward shaping is a practical approach to improving sample efficiency by embedding human domain knowledge into the learning process. Existing reward shaping methods for goal-conditioned RL are typically built on distance metrics with a linear and isotropic distribution, which may fail to provide sufficient information about the ever-changing environment with high complexity. This paper proposes a novel magnetic field-based reward shaping (MFRS) method for goal-conditioned RL tasks with dynamic target and obstacles. Inspired by the physical properties of magnets, we consider the target and obstacles as permanent magnets and establish the reward function according to the intensity values of the magnetic field generated by these magnets. The nonlinear and anisotropic distribution of t",
    "link": "http://arxiv.org/abs/2307.08033",
    "context": "Title: Magnetic Field-Based Reward Shaping for Goal-Conditioned Reinforcement Learning. (arXiv:2307.08033v1 [cs.LG])\nAbstract: Goal-conditioned reinforcement learning (RL) is an interesting extension of the traditional RL framework, where the dynamic environment and reward sparsity can cause conventional learning algorithms to fail. Reward shaping is a practical approach to improving sample efficiency by embedding human domain knowledge into the learning process. Existing reward shaping methods for goal-conditioned RL are typically built on distance metrics with a linear and isotropic distribution, which may fail to provide sufficient information about the ever-changing environment with high complexity. This paper proposes a novel magnetic field-based reward shaping (MFRS) method for goal-conditioned RL tasks with dynamic target and obstacles. Inspired by the physical properties of magnets, we consider the target and obstacles as permanent magnets and establish the reward function according to the intensity values of the magnetic field generated by these magnets. The nonlinear and anisotropic distribution of t",
    "path": "papers/23/07/2307.08033.json",
    "total_tokens": 941,
    "translated_title": "基于磁场的奖励塑形用于目标条件强化学习",
    "translated_abstract": "目标条件强化学习是传统强化学习框架的有趣扩展，动态环境和奖励稀疏性可能导致传统学习算法失败。奖励塑形是通过将人类领域知识嵌入学习过程来提高采样效率的实际方法。现有基于距离度量的目标条件强化学习奖励塑形方法通常建立在线性和各向同性分布的距离度量上，可能无法提供关于高复杂度环境的充分信息。本文提出了一种新颖的基于磁场的目标条件强化学习奖励塑形方法（MFRS），用于具有动态目标和障碍物的任务。受到磁铁的物理特性的启发，我们将目标和障碍物视为永久磁铁，并根据这些磁铁产生的磁场强度值来建立奖励函数。奖励函数具有非线性和各向异性分布。",
    "tldr": "本论文提出了一种基于磁场的奖励塑形方法，用于目标条件强化学习任务。通过将目标和障碍物视为永久磁铁，并根据磁场强度值建立奖励函数，解决了传统奖励塑形方法在动态环境中应用效果不好的问题。"
}