{
    "title": "Optimal Compression of Unit Norm Vectors in the High Distortion Regime. (arXiv:2307.07941v1 [cs.IT])",
    "abstract": "Motivated by the need for communication-efficient distributed learning, we investigate the method for compressing a unit norm vector into the minimum number of bits, while still allowing for some acceptable level of distortion in recovery. This problem has been explored in the rate-distortion/covering code literature, but our focus is exclusively on the \"high-distortion\" regime. We approach this problem in a worst-case scenario, without any prior information on the vector, but allowing for the use of randomized compression maps. Our study considers both biased and unbiased compression methods and determines the optimal compression rates. It turns out that simple compression schemes are nearly optimal in this scenario. While the results are a mix of new and known, they are compiled in this paper for completeness.",
    "link": "http://arxiv.org/abs/2307.07941",
    "context": "Title: Optimal Compression of Unit Norm Vectors in the High Distortion Regime. (arXiv:2307.07941v1 [cs.IT])\nAbstract: Motivated by the need for communication-efficient distributed learning, we investigate the method for compressing a unit norm vector into the minimum number of bits, while still allowing for some acceptable level of distortion in recovery. This problem has been explored in the rate-distortion/covering code literature, but our focus is exclusively on the \"high-distortion\" regime. We approach this problem in a worst-case scenario, without any prior information on the vector, but allowing for the use of randomized compression maps. Our study considers both biased and unbiased compression methods and determines the optimal compression rates. It turns out that simple compression schemes are nearly optimal in this scenario. While the results are a mix of new and known, they are compiled in this paper for completeness.",
    "path": "papers/23/07/2307.07941.json",
    "total_tokens": 801,
    "translated_title": "高失真条件下单位范数向量的最优压缩",
    "translated_abstract": "受到通信高效分布式学习的需求的驱动，我们研究了将单位范数向量压缩到最少比特数的方法，同时允许一定程度的失真恢复。这个问题在速率-失真/覆盖编码文献中已经被研究过，但我们的重点仅限于“高失真”情况。我们在最坏情况下考虑了这个问题，没有任何关于向量的先验信息，但允许使用随机压缩映射。我们研究了有偏和无偏压缩方法，并确定了最优压缩比率。结果表明，简单的压缩方案在这种情况下几乎是最优的。虽然结果是新旧问题的混合，但为了完整起见，它们在本文中予以整理。",
    "tldr": "本研究探讨了在高失真情况下，将单位范数向量压缩到最少比特数的最优方法。研究发现，简单的压缩方案在这种情况下几乎是最优的。"
}