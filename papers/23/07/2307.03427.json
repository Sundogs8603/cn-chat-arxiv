{
    "title": "Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer. (arXiv:2307.03427v1 [eess.IV])",
    "abstract": "Survival prediction is crucial for cancer patients as it provides early prognostic information for treatment planning. Recently, deep survival models based on deep learning and medical images have shown promising performance for survival prediction. However, existing deep survival models are not well developed in utilizing multi-modality images (e.g., PET-CT) and in extracting region-specific information (e.g., the prognostic information in Primary Tumor (PT) and Metastatic Lymph Node (MLN) regions). In view of this, we propose a merging-diverging learning framework for survival prediction from multi-modality images. This framework has a merging encoder to fuse multi-modality information and a diverging decoder to extract region-specific information. In the merging encoder, we propose a Hybrid Parallel Cross-Attention (HPCA) block to effectively fuse multi-modality features via parallel convolutional layers and cross-attention transformers. In the diverging decoder, we propose a Region",
    "link": "http://arxiv.org/abs/2307.03427",
    "context": "Title: Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer. (arXiv:2307.03427v1 [eess.IV])\nAbstract: Survival prediction is crucial for cancer patients as it provides early prognostic information for treatment planning. Recently, deep survival models based on deep learning and medical images have shown promising performance for survival prediction. However, existing deep survival models are not well developed in utilizing multi-modality images (e.g., PET-CT) and in extracting region-specific information (e.g., the prognostic information in Primary Tumor (PT) and Metastatic Lymph Node (MLN) regions). In view of this, we propose a merging-diverging learning framework for survival prediction from multi-modality images. This framework has a merging encoder to fuse multi-modality information and a diverging decoder to extract region-specific information. In the merging encoder, we propose a Hybrid Parallel Cross-Attention (HPCA) block to effectively fuse multi-modality features via parallel convolutional layers and cross-attention transformers. In the diverging decoder, we propose a Region",
    "path": "papers/23/07/2307.03427.json",
    "total_tokens": 934,
    "translated_title": "合并-分流混合Transformer网络用于头颈癌的生存预测",
    "translated_abstract": "生存预测对于癌症患者至关重要，因为它为治疗计划提供了早期预后信息。最近，基于深度学习和医学影像的深度生存模型在生存预测方面表现出了很大的潜力。然而，现有的深度生存模型在利用多模态影像（如PET-CT）和提取特定区域信息（如原发肿瘤（PT）和转移淋巴结（MLN）区域的预后信息）方面尚未得到很好的发展。鉴于此，我们提出了一个用于从多模态影像进行生存预测的合并-分流学习框架。该框架具有一个合并编码器用于融合多模态信息，以及一个分流解码器用于提取特定区域的信息。在合并编码器中，我们提出了一种混合并行交叉注意力（HPCA）块，通过并行卷积层和交叉注意力Transformer有效地融合多模态特征。在分流解码器中，我们提出了一种区域",
    "tldr": "这篇论文提出了一种合并-分流混合Transformer网络用于头颈癌的生存预测。该网络利用多模态影像和提取特定区域信息，通过合并编码器和分流解码器实现生存预测，取得了很好的效果。",
    "en_tdlr": "This paper proposes a merging-diverging hybrid Transformer network for survival prediction in head and neck cancer. The network effectively utilizes multi-modality images and extracts region-specific information to achieve accurate survival prediction."
}