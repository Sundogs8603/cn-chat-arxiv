{
    "title": "Implicit regularisation in stochastic gradient descent: from single-objective to two-player games. (arXiv:2307.05789v1 [stat.ML])",
    "abstract": "Recent years have seen many insights on deep learning optimisation being brought forward by finding implicit regularisation effects of commonly used gradient-based optimisers. Understanding implicit regularisation can not only shed light on optimisation dynamics, but it can also be used to improve performance and stability across problem domains, from supervised learning to two-player games such as Generative Adversarial Networks. An avenue for finding such implicit regularisation effects has been quantifying the discretisation errors of discrete optimisers via continuous-time flows constructed by backward error analysis (BEA). The current usage of BEA is not without limitations, since not all the vector fields of continuous-time flows obtained using BEA can be written as a gradient, hindering the construction of modified losses revealing implicit regularisers. In this work, we provide a novel approach to use BEA, and show how our approach can be used to construct continuous-time flows",
    "link": "http://arxiv.org/abs/2307.05789",
    "context": "Title: Implicit regularisation in stochastic gradient descent: from single-objective to two-player games. (arXiv:2307.05789v1 [stat.ML])\nAbstract: Recent years have seen many insights on deep learning optimisation being brought forward by finding implicit regularisation effects of commonly used gradient-based optimisers. Understanding implicit regularisation can not only shed light on optimisation dynamics, but it can also be used to improve performance and stability across problem domains, from supervised learning to two-player games such as Generative Adversarial Networks. An avenue for finding such implicit regularisation effects has been quantifying the discretisation errors of discrete optimisers via continuous-time flows constructed by backward error analysis (BEA). The current usage of BEA is not without limitations, since not all the vector fields of continuous-time flows obtained using BEA can be written as a gradient, hindering the construction of modified losses revealing implicit regularisers. In this work, we provide a novel approach to use BEA, and show how our approach can be used to construct continuous-time flows",
    "path": "papers/23/07/2307.05789.json",
    "total_tokens": 895,
    "translated_title": "隐式正则化在随机梯度下降中的应用：从单目标到双人游戏",
    "translated_abstract": "近年来，通过发现常用的基于梯度的优化器的隐式正则化效应，为深度学习优化带来了许多新的见解。理解隐式正则化不仅可以揭示优化动态，还可以用于改善性能和稳定性，涉及到从有监督学习到生成对抗网络等问题领域的两人游戏。通过向后误差分析（BEA）构建的连续时间流量来量化离散优化器的离散化误差是找到隐式正则化效应的一种方法。然而，目前BEA的使用存在限制，因为并不是通过BEA获得的所有连续时间流的向量场都可以写成梯度，这阻碍了构建揭示隐式正则化器的修正损失。在这项工作中，我们提供了一种新的使用BEA的方法，并展示了我们的方法如何用于构建连续时间流量。",
    "tldr": "本文研究了隐式正则化在随机梯度下降中的应用，通过向后误差分析构建连续时间流量来量化离散优化器的离散化误差，并提供了一种新的使用BEA的方法。",
    "en_tdlr": "This paper investigates the application of implicit regularization in stochastic gradient descent, quantifying the discretization errors of discrete optimizers by constructing continuous-time flows through backward error analysis (BEA). A novel approach to using BEA is provided, shedding light on the implicit regularization effects."
}