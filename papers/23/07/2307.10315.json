{
    "title": "Absolutist AI. (arXiv:2307.10315v1 [cs.AI])",
    "abstract": "This paper argues that training AI systems with absolute constraints -- which forbid certain acts irrespective of the amount of value they might produce -may make considerable progress on many AI safety problems in principle. First, it provides a guardrail for avoiding the very worst outcomes of misalignment. Second, it could prevent AIs from causing catastrophes for the sake of very valuable consequences, such as replacing humans with a much larger number of beings living at a higher welfare level. Third, it makes systems more corrigible, allowing creators to make corrective interventions in them, such as altering their objective functions or shutting them down. And fourth, it helps systems explore their environment more safely by prohibiting them from exploring especially dangerous acts. I offer a decision-theoretic formalization of an absolute constraints, improving on existing models in the literature, and use this model to prove some results about the training and behavior of ab",
    "link": "http://arxiv.org/abs/2307.10315",
    "context": "Title: Absolutist AI. (arXiv:2307.10315v1 [cs.AI])\nAbstract: This paper argues that training AI systems with absolute constraints -- which forbid certain acts irrespective of the amount of value they might produce -may make considerable progress on many AI safety problems in principle. First, it provides a guardrail for avoiding the very worst outcomes of misalignment. Second, it could prevent AIs from causing catastrophes for the sake of very valuable consequences, such as replacing humans with a much larger number of beings living at a higher welfare level. Third, it makes systems more corrigible, allowing creators to make corrective interventions in them, such as altering their objective functions or shutting them down. And fourth, it helps systems explore their environment more safely by prohibiting them from exploring especially dangerous acts. I offer a decision-theoretic formalization of an absolute constraints, improving on existing models in the literature, and use this model to prove some results about the training and behavior of ab",
    "path": "papers/23/07/2307.10315.json",
    "total_tokens": 867,
    "translated_title": "绝对主义AI",
    "translated_abstract": "本文认为，训练AI系统时采用绝对约束条件 - 即禁止某些行为，无论它们可能产生多少价值 - 在原则上可以在许多AI安全问题上取得重大进展。首先，它为避免最糟糕的误对齐结果提供了护栏。其次，它可以防止AI为了非常有价值的结果而引发灾难，例如用更多数量和更高福利水平的生物替代人类。第三，它使系统更加可矫正，允许创建者进行纠正性干预，比如改变它们的目标函数或关闭它们。第四，它通过禁止特别危险的行为，帮助系统更安全地探索环境。我提供了对绝对约束条件进行决策论形式化的改进模型，并利用该模型证明了有关培训和行为的一些结果。",
    "tldr": "本文提出了绝对主义AI的概念，认为通过训练AI系统时使用绝对约束条件可以解决许多AI安全问题，这样做可以避免最糟糕的结果、防止灾难、增加系统的可矫正性并帮助系统更安全地探索环境。"
}