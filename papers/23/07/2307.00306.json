{
    "title": "SyMFM6D: Symmetry-aware Multi-directional Fusion for Multi-View 6D Object Pose Estimation. (arXiv:2307.00306v1 [cs.CV])",
    "abstract": "Detecting objects and estimating their 6D poses is essential for automated systems to interact safely with the environment. Most 6D pose estimators, however, rely on a single camera frame and suffer from occlusions and ambiguities due to object symmetries. We overcome this issue by presenting a novel symmetry-aware multi-view 6D pose estimator called SyMFM6D. Our approach efficiently fuses the RGB-D frames from multiple perspectives in a deep multi-directional fusion network and predicts predefined keypoints for all objects in the scene simultaneously. Based on the keypoints and an instance semantic segmentation, we efficiently compute the 6D poses by least-squares fitting. To address the ambiguity issues for symmetric objects, we propose a novel training procedure for symmetry-aware keypoint detection including a new objective function. Our SyMFM6D network significantly outperforms the state-of-the-art in both single-view and multi-view 6D pose estimation. We furthermore show the effe",
    "link": "http://arxiv.org/abs/2307.00306",
    "context": "Title: SyMFM6D: Symmetry-aware Multi-directional Fusion for Multi-View 6D Object Pose Estimation. (arXiv:2307.00306v1 [cs.CV])\nAbstract: Detecting objects and estimating their 6D poses is essential for automated systems to interact safely with the environment. Most 6D pose estimators, however, rely on a single camera frame and suffer from occlusions and ambiguities due to object symmetries. We overcome this issue by presenting a novel symmetry-aware multi-view 6D pose estimator called SyMFM6D. Our approach efficiently fuses the RGB-D frames from multiple perspectives in a deep multi-directional fusion network and predicts predefined keypoints for all objects in the scene simultaneously. Based on the keypoints and an instance semantic segmentation, we efficiently compute the 6D poses by least-squares fitting. To address the ambiguity issues for symmetric objects, we propose a novel training procedure for symmetry-aware keypoint detection including a new objective function. Our SyMFM6D network significantly outperforms the state-of-the-art in both single-view and multi-view 6D pose estimation. We furthermore show the effe",
    "path": "papers/23/07/2307.00306.json",
    "total_tokens": 1060,
    "translated_title": "SyMFM6D：面向对称多方位融合的多视角6D物体姿态估计",
    "translated_abstract": "检测物体并估计其6D姿态对于自动化系统与环境安全互动至关重要。然而，大多数6D姿态估计器仅依赖于单个摄像头帧，并且受到由于物体对称性而引起的遮挡和模糊的影响。我们通过提出一种新颖的面向对称多视角6D姿态估计器SyMFM6D来解决这个问题。我们的方法通过深度多方向融合网络有效地融合多个角度的RGB-D帧，并同时预测场景中所有物体的预定义关键点。基于关键点和实例语义分割，我们通过最小二乘拟合高效计算6D姿态。为了解决对称物体的歧义问题，我们提出了一种新的训练过程用于对称感知的关键点检测，包括一种新的目标函数。我们的SyMFM6D网络在单视角和多视角6D姿态估计方面显著优于现有技术。此外，我们还展示了该方法对姿态估计的影响。",
    "tldr": "该论文介绍了一种叫做SyMFM6D的面向对称多视角融合的6D物体姿态估计方法。该方法通过多方向融合网络有效地融合多个视角的RGB-D帧，并通过预测关键点和实例语义分割来计算6D姿态。通过新的训练过程和目标函数，该方法能够解决对称物体的歧义问题，并在单视角和多视角姿态估计方面取得了显著的性能提升。",
    "en_tdlr": "This paper presents a symmetry-aware multi-directional fusion method called SyMFM6D for multi-view 6D object pose estimation. By efficiently fusing RGB-D frames from multiple perspectives and predicting keypoints with instance semantic segmentation, the method addresses the ambiguity issues for symmetric objects and achieves significant performance improvement in both single-view and multi-view pose estimation."
}