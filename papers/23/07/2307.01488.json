{
    "title": "SCAT: Robust Self-supervised Contrastive Learning via Adversarial Training for Text Classification. (arXiv:2307.01488v1 [cs.CL])",
    "abstract": "Despite their promising performance across various natural language processing (NLP) tasks, current NLP systems are vulnerable to textual adversarial attacks. To defend against these attacks, most existing methods apply adversarial training by incorporating adversarial examples. However, these methods have to rely on ground-truth labels to generate adversarial examples, rendering it impractical for large-scale model pre-training which is commonly used nowadays for NLP and many other tasks. In this paper, we propose a novel learning framework called SCAT (Self-supervised Contrastive Learning via Adversarial Training), which can learn robust representations without requiring labeled data. Specifically, SCAT modifies random augmentations of the data in a fully labelfree manner to generate adversarial examples. Adversarial training is achieved by minimizing the contrastive loss between the augmentations and their adversarial counterparts. We evaluate SCAT on two text classification dataset",
    "link": "http://arxiv.org/abs/2307.01488",
    "context": "Title: SCAT: Robust Self-supervised Contrastive Learning via Adversarial Training for Text Classification. (arXiv:2307.01488v1 [cs.CL])\nAbstract: Despite their promising performance across various natural language processing (NLP) tasks, current NLP systems are vulnerable to textual adversarial attacks. To defend against these attacks, most existing methods apply adversarial training by incorporating adversarial examples. However, these methods have to rely on ground-truth labels to generate adversarial examples, rendering it impractical for large-scale model pre-training which is commonly used nowadays for NLP and many other tasks. In this paper, we propose a novel learning framework called SCAT (Self-supervised Contrastive Learning via Adversarial Training), which can learn robust representations without requiring labeled data. Specifically, SCAT modifies random augmentations of the data in a fully labelfree manner to generate adversarial examples. Adversarial training is achieved by minimizing the contrastive loss between the augmentations and their adversarial counterparts. We evaluate SCAT on two text classification dataset",
    "path": "papers/23/07/2307.01488.json",
    "total_tokens": 931,
    "translated_title": "SCAT：通过对抗训练的自监督对比学习技术实现文本分类的鲁棒性",
    "translated_abstract": "尽管在各种自然语言处理（NLP）任务中表现出很好的性能，但当前的NLP系统容易受到文本对抗攻击的影响。为了防御这些攻击，现有方法大多数采用对抗训练的方式来引入对抗样本。然而，这些方法通常需要依赖于标准标签来生成对抗样本，这在如今常用于NLP和其他任务的大规模模型预训练中是不可行的。本文提出了一种新的学习框架，名为SCAT（通过对抗训练的自监督对比学习），它可以在不需要标记数据的情况下学习鲁棒的表示。具体而言，SCAT通过对数据进行完全无标记的随机增强来生成对抗样本，并通过最小化增强和其对应的对抗样本之间的对比损失来实现对抗训练。我们在两个文本分类数据集上评估了SCAT的性能。",
    "tldr": "本文提出了一种名为SCAT的自监督对比学习框架，通过对抗训练来生成对抗样本，从而实现在不依赖标签数据的情况下学习鲁棒的表示。评估结果显示，SCAT在两个文本分类数据集上取得了良好性能。",
    "en_tdlr": "This paper proposes a self-supervised contrastive learning framework called SCAT, which generates adversarial examples through adversarial training, enabling robust representation learning without relying on labeled data. Evaluation results show that SCAT achieves good performance on two text classification datasets."
}