{
    "title": "Analyzing Chain-of-Thought Prompting in Large Language Models via Gradient-based Feature Attributions. (arXiv:2307.13339v1 [cs.CL])",
    "abstract": "Chain-of-thought (CoT) prompting has been shown to empirically improve the accuracy of large language models (LLMs) on various question answering tasks. While understanding why CoT prompting is effective is crucial to ensuring that this phenomenon is a consequence of desired model behavior, little work has addressed this; nonetheless, such an understanding is a critical prerequisite for responsible model deployment. We address this question by leveraging gradient-based feature attribution methods which produce saliency scores that capture the influence of input tokens on model output. Specifically, we probe several open-source LLMs to investigate whether CoT prompting affects the relative importances they assign to particular input tokens. Our results indicate that while CoT prompting does not increase the magnitude of saliency scores attributed to semantically relevant tokens in the prompt compared to standard few-shot prompting, it increases the robustness of saliency scores to quest",
    "link": "http://arxiv.org/abs/2307.13339",
    "context": "Title: Analyzing Chain-of-Thought Prompting in Large Language Models via Gradient-based Feature Attributions. (arXiv:2307.13339v1 [cs.CL])\nAbstract: Chain-of-thought (CoT) prompting has been shown to empirically improve the accuracy of large language models (LLMs) on various question answering tasks. While understanding why CoT prompting is effective is crucial to ensuring that this phenomenon is a consequence of desired model behavior, little work has addressed this; nonetheless, such an understanding is a critical prerequisite for responsible model deployment. We address this question by leveraging gradient-based feature attribution methods which produce saliency scores that capture the influence of input tokens on model output. Specifically, we probe several open-source LLMs to investigate whether CoT prompting affects the relative importances they assign to particular input tokens. Our results indicate that while CoT prompting does not increase the magnitude of saliency scores attributed to semantically relevant tokens in the prompt compared to standard few-shot prompting, it increases the robustness of saliency scores to quest",
    "path": "papers/23/07/2307.13339.json",
    "total_tokens": 832,
    "translated_title": "通过基于梯度的特征归因分析大型语言模型中的思维链启发",
    "translated_abstract": "在各种问答任务中，已经证明思维链启发在大型语言模型的准确性方面有实际的改善。然而，为了确保这种现象是期望的模型行为的结果，理解为何思维链启发有效非常重要，但是目前很少有研究探讨这个问题。我们通过利用基于梯度的特征归因方法来回答这个问题，该方法产生了衡量输入标记对模型输出影响的重要性分数。具体而言，我们探索了几个开源的大型语言模型，以研究思维链启发是否会影响它们分配给特定输入标记的相对重要性。我们的结果表明，与标准的少样本启发相比，思维链启发并未增加分配给语义相关标记的重要性分数的大小，但它提高了分配给问题相关标记的重要性分数的鲁棒性。",
    "tldr": "通过基于梯度的特征归因方法，研究发现思维链启发在大型语言模型中并没有增加与语义相关标记的重要性，但提高了与问题相关标记的重要性分数的鲁棒性。"
}