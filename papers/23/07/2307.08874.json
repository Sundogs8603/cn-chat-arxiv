{
    "title": "Latent Space Representations of Neural Algorithmic Reasoners. (arXiv:2307.08874v1 [cs.LG])",
    "abstract": "Neural Algorithmic Reasoning (NAR) is a research area focused on designing neural architectures that can reliably capture classical computation, usually by learning to execute algorithms. A typical approach is to rely on Graph Neural Network (GNN) architectures, which encode inputs in high-dimensional latent spaces that are repeatedly transformed during the execution of the algorithm. In this work we perform a detailed analysis of the structure of the latent space induced by the GNN when executing algorithms. We identify two possible failure modes: (i) loss of resolution, making it hard to distinguish similar values; (ii) inability to deal with values outside the range observed during training. We propose to solve the first issue by relying on a softmax aggregator, and propose to decay the latent space in order to deal with out-of-range values. We show that these changes lead to improvements on the majority of algorithms in the standard CLRS-30 benchmark when using the state-of-the-art",
    "link": "http://arxiv.org/abs/2307.08874",
    "context": "Title: Latent Space Representations of Neural Algorithmic Reasoners. (arXiv:2307.08874v1 [cs.LG])\nAbstract: Neural Algorithmic Reasoning (NAR) is a research area focused on designing neural architectures that can reliably capture classical computation, usually by learning to execute algorithms. A typical approach is to rely on Graph Neural Network (GNN) architectures, which encode inputs in high-dimensional latent spaces that are repeatedly transformed during the execution of the algorithm. In this work we perform a detailed analysis of the structure of the latent space induced by the GNN when executing algorithms. We identify two possible failure modes: (i) loss of resolution, making it hard to distinguish similar values; (ii) inability to deal with values outside the range observed during training. We propose to solve the first issue by relying on a softmax aggregator, and propose to decay the latent space in order to deal with out-of-range values. We show that these changes lead to improvements on the majority of algorithms in the standard CLRS-30 benchmark when using the state-of-the-art",
    "path": "papers/23/07/2307.08874.json",
    "total_tokens": 966,
    "translated_title": "神经算法推理器的潜在空间表示",
    "translated_abstract": "神经算法推理（NAR）是一个研究领域，专注于设计能够可靠地捕捉经典计算的神经架构，通常通过学习执行算法来实现。典型的方法是依赖于图神经网络（GNN）架构，它们将输入编码为高维潜在空间，在算法执行期间反复转换。在这项工作中，我们对GNN在执行算法时导致的潜在空间结构进行了详细分析。我们发现了两种可能的故障模式：（i）分辨率丧失，使得难以区分相似的值；（ii）无法处理训练期间未观察到的值范围之外的值。我们提出通过依赖softmax聚合器来解决第一个问题，并建议衰减潜在空间以处理超出范围的值。我们展示了这些变化在使用最先进的方法时，在标准CLRS-30基准测试中大多数算法上的改进。",
    "tldr": "这项工作对神经算法推理器中执行算法时产生的潜在空间结构进行了详细分析，并提出了解决两种故障模式的方法。通过使用softmax聚合器解决分辨率丧失问题，以及衰减潜在空间来处理超出范围的值，这些改变在标准CLRS-30基准测试中大多数算法上实现了改进。"
}