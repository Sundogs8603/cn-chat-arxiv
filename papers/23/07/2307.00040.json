{
    "title": "DisCo: Disentangled Control for Referring Human Dance Generation in Real World. (arXiv:2307.00040v1 [cs.CV])",
    "abstract": "Generative AI has made significant strides in computer vision, particularly in image/video synthesis conditioned on text descriptions. Despite the advancements, it remains challenging especially in the generation of human-centric content such as dance synthesis. Existing dance synthesis methods struggle with the gap between synthesized content and real-world dance scenarios. In this paper, we define a new problem setting: Referring Human Dance Generation, which focuses on real-world dance scenarios with three important properties: (i) Faithfulness: the synthesis should retain the appearance of both human subject foreground and background from the reference image, and precisely follow the target pose; (ii) Generalizability: the model should generalize to unseen human subjects, backgrounds, and poses; (iii) Compositionality: it should allow for composition of seen/unseen subjects, backgrounds, and poses from different sources. To address these challenges, we introduce a novel approach, D",
    "link": "http://arxiv.org/abs/2307.00040",
    "context": "Title: DisCo: Disentangled Control for Referring Human Dance Generation in Real World. (arXiv:2307.00040v1 [cs.CV])\nAbstract: Generative AI has made significant strides in computer vision, particularly in image/video synthesis conditioned on text descriptions. Despite the advancements, it remains challenging especially in the generation of human-centric content such as dance synthesis. Existing dance synthesis methods struggle with the gap between synthesized content and real-world dance scenarios. In this paper, we define a new problem setting: Referring Human Dance Generation, which focuses on real-world dance scenarios with three important properties: (i) Faithfulness: the synthesis should retain the appearance of both human subject foreground and background from the reference image, and precisely follow the target pose; (ii) Generalizability: the model should generalize to unseen human subjects, backgrounds, and poses; (iii) Compositionality: it should allow for composition of seen/unseen subjects, backgrounds, and poses from different sources. To address these challenges, we introduce a novel approach, D",
    "path": "papers/23/07/2307.00040.json",
    "total_tokens": 913,
    "translated_title": "DisCo: 用于现实世界中基于人类舞蹈的引用生成的解耦控制",
    "translated_abstract": "生成AI在计算机视觉领域取得了显著的进展，特别是在基于文本描述的图像/视频合成方面。尽管有了这些进步，但在生成人类中心内容（如舞蹈合成）方面仍然存在挑战。现有的舞蹈合成方法在合成内容与现实世界舞蹈场景之间存在差距。在本文中，我们定义了一个新的问题设置：引用人类舞蹈生成，重点关注具有三个重要属性的现实世界舞蹈场景：（i）忠实性：合成应该保留引用图像中人类主体前景和背景的外观，并精确地遵循目标姿势；（ii）泛化能力：模型应该适用于未见过的人类主体、背景和姿势；（iii）组合性：它应该允许来自不同来源的已见/未见主体、背景和姿势的组合。为了应对这些挑战，我们引入了一种新颖的方法，D",
    "tldr": "这篇论文提出了一个新的问题设置：引用人类舞蹈生成。在现实世界的舞蹈场景中，通过解耦控制来解决舞蹈合成中的挑战，包括忠实性、泛化能力和组合性。",
    "en_tdlr": "This paper proposes a new problem setting: Referring Human Dance Generation, which focuses on generating human-centric dance content in real-world scenarios. It introduces a novel approach, D"
}