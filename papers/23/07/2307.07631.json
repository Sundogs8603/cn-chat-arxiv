{
    "title": "Towards Model-Size Agnostic, Compute-Free, Memorization-based Inference of Deep Learning. (arXiv:2307.07631v1 [cs.LG])",
    "abstract": "The rapid advancement of deep neural networks has significantly improved various tasks, such as image and speech recognition. However, as the complexity of these models increases, so does the computational cost and the number of parameters, making it difficult to deploy them on resource-constrained devices. This paper proposes a novel memorization-based inference (MBI) that is compute free and only requires lookups. Specifically, our work capitalizes on the inference mechanism of the recurrent attention model (RAM), where only a small window of input domain (glimpse) is processed in a one time step, and the outputs from multiple glimpses are combined through a hidden vector to determine the overall classification output of the problem. By leveraging the low-dimensionality of glimpse, our inference procedure stores key value pairs comprising of glimpse location, patch vector, etc. in a table. The computations are obviated during inference by utilizing the table to read out key-value pai",
    "link": "http://arxiv.org/abs/2307.07631",
    "context": "Title: Towards Model-Size Agnostic, Compute-Free, Memorization-based Inference of Deep Learning. (arXiv:2307.07631v1 [cs.LG])\nAbstract: The rapid advancement of deep neural networks has significantly improved various tasks, such as image and speech recognition. However, as the complexity of these models increases, so does the computational cost and the number of parameters, making it difficult to deploy them on resource-constrained devices. This paper proposes a novel memorization-based inference (MBI) that is compute free and only requires lookups. Specifically, our work capitalizes on the inference mechanism of the recurrent attention model (RAM), where only a small window of input domain (glimpse) is processed in a one time step, and the outputs from multiple glimpses are combined through a hidden vector to determine the overall classification output of the problem. By leveraging the low-dimensionality of glimpse, our inference procedure stores key value pairs comprising of glimpse location, patch vector, etc. in a table. The computations are obviated during inference by utilizing the table to read out key-value pai",
    "path": "papers/23/07/2307.07631.json",
    "total_tokens": 893,
    "translated_title": "面向模型大小不可知、无需计算、基于记忆的深度学习推理",
    "translated_abstract": "深度神经网络的快速发展显著提高了各种任务的性能，如图像和语音识别。然而，随着这些模型的复杂性增加，计算成本和参数数量也增加，使得难以在资源受限设备上部署。本文提出了一种新颖的基于记忆的推理方法（MBI），它不需要计算，只需要查找。具体来说，我们的工作利用了循环注意模型（RAM）的推理机制，其中只有一个小窗口的输入域（glance）在一个时间步骤中进行处理，并且来自多个glance的输出通过隐藏向量组合来确定问题的整体分类输出。通过利用glance的低维性，我们的推理过程将由包含glance位置、补丁向量等的键值对存储在一张表中。在推理过程中，通过利用该表来读取键值对，可以避免计算。",
    "tldr": "本研究提出了一种基于记忆的推理方法（MBI），可以实现无需计算的深度学习推理。该方法利用了循环注意模型（RAM）的推理机制，并通过存储键值对的表来避免计算。",
    "en_tdlr": "This paper proposes a novel memorization-based inference (MBI) method that enables compute-free deep learning inference. By leveraging the inference mechanism of the recurrent attention model (RAM) and utilizing a table to store key-value pairs, computations are obviated during inference."
}