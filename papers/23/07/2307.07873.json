{
    "title": "Towards Understanding Adversarial Transferability From Surrogate Training. (arXiv:2307.07873v1 [cs.LG])",
    "abstract": "Adversarial examples (AEs) for DNNs have been shown to be transferable: AEs that successfully fool white-box surrogate models can also deceive other black-box models with different architectures. Although a bunch of empirical studies have provided guidance on generating highly transferable AEs, many of these findings lack explanations and even lead to inconsistent advice. In this paper, we take a further step towards understanding adversarial transferability, with a particular focus on surrogate aspects. Starting from the intriguing little robustness phenomenon, where models adversarially trained with mildly perturbed adversarial samples can serve as better surrogates, we attribute it to a trade-off between two predominant factors: model smoothness and gradient similarity. Our investigations focus on their joint effects, rather than their separate correlations with transferability. Through a series of theoretical and empirical analyses, we conjecture that the data distribution shift in",
    "link": "http://arxiv.org/abs/2307.07873",
    "context": "Title: Towards Understanding Adversarial Transferability From Surrogate Training. (arXiv:2307.07873v1 [cs.LG])\nAbstract: Adversarial examples (AEs) for DNNs have been shown to be transferable: AEs that successfully fool white-box surrogate models can also deceive other black-box models with different architectures. Although a bunch of empirical studies have provided guidance on generating highly transferable AEs, many of these findings lack explanations and even lead to inconsistent advice. In this paper, we take a further step towards understanding adversarial transferability, with a particular focus on surrogate aspects. Starting from the intriguing little robustness phenomenon, where models adversarially trained with mildly perturbed adversarial samples can serve as better surrogates, we attribute it to a trade-off between two predominant factors: model smoothness and gradient similarity. Our investigations focus on their joint effects, rather than their separate correlations with transferability. Through a series of theoretical and empirical analyses, we conjecture that the data distribution shift in",
    "path": "papers/23/07/2307.07873.json",
    "total_tokens": 924,
    "translated_title": "探索从替代训练中理解对抗性可转移性",
    "translated_abstract": "对DNNs的对抗样本(AEs)已经表明是可转移的：成功欺骗白盒子替代模型的AEs也可以欺骗具有不同架构的其他黑盒模型。虽然许多经验研究提供了生成高度可转移AE的指导，但这些研究缺乏解释甚至导致不一致的建议。本文在理解对抗性可转移性方面迈出了一步，特别关注替代方面。从着名的小健壮性现象开始，通过以轻微扰动的对抗性样本对模型进行对抗训练可以得到更好的替代模型，我们将其归因于两个主要因素之间的权衡：模型的平滑性和梯度相似性。我们的研究集中在它们的共同效果上，而不是它们与可转移性的单独相关性。通过一系列理论和实证分析，我们推测数据分布的转变。",
    "tldr": "本论文探索了对抗性可转移性的理解，特别关注替代训练。通过研究模型的平滑性和梯度相似性之间的权衡，发现对抗训练可以提高模型的替代能力。研究结果对数据分布的转变提出了新的推测。"
}