{
    "title": "On the unreasonable vulnerability of transformers for image restoration -- and an easy fix. (arXiv:2307.13856v1 [cs.CV])",
    "abstract": "Following their success in visual recognition tasks, Vision Transformers(ViTs) are being increasingly employed for image restoration. As a few recent works claim that ViTs for image classification also have better robustness properties, we investigate whether the improved adversarial robustness of ViTs extends to image restoration. We consider the recently proposed Restormer model, as well as NAFNet and the \"Baseline network\" which are both simplified versions of a Restormer. We use Projected Gradient Descent (PGD) and CosPGD, a recently proposed adversarial attack tailored to pixel-wise prediction tasks for our robustness evaluation. Our experiments are performed on real-world images from the GoPro dataset for image deblurring. Our analysis indicates that contrary to as advocated by ViTs in image classification works, these models are highly susceptible to adversarial attacks. We attempt to improve their robustness through adversarial training. While this yields a significant increase",
    "link": "http://arxiv.org/abs/2307.13856",
    "context": "Title: On the unreasonable vulnerability of transformers for image restoration -- and an easy fix. (arXiv:2307.13856v1 [cs.CV])\nAbstract: Following their success in visual recognition tasks, Vision Transformers(ViTs) are being increasingly employed for image restoration. As a few recent works claim that ViTs for image classification also have better robustness properties, we investigate whether the improved adversarial robustness of ViTs extends to image restoration. We consider the recently proposed Restormer model, as well as NAFNet and the \"Baseline network\" which are both simplified versions of a Restormer. We use Projected Gradient Descent (PGD) and CosPGD, a recently proposed adversarial attack tailored to pixel-wise prediction tasks for our robustness evaluation. Our experiments are performed on real-world images from the GoPro dataset for image deblurring. Our analysis indicates that contrary to as advocated by ViTs in image classification works, these models are highly susceptible to adversarial attacks. We attempt to improve their robustness through adversarial training. While this yields a significant increase",
    "path": "papers/23/07/2307.13856.json",
    "total_tokens": 951,
    "translated_title": "关于图像恢复任务中transformers的不合理易受攻击性 -- 以及一个简单的修复方法",
    "translated_abstract": "在视觉识别任务中取得成功后，Vision Transformers（ViTs）越来越多地被用于图像恢复任务。一些最近的研究声称ViTs在图像分类任务中具有更好的鲁棒性属性，我们调查了ViTs的改进对图像恢复任务的鲁棒性是否具有扩展性。我们考虑了最近提出的Restormer模型，以及NAFNet和“基准网络”，它们都是Restormer的简化版本。我们使用投影梯度下降（PGD）和CosPGD进行鲁棒性评估，这是一种针对像素预测任务提出的最新的对抗攻击方法。我们在GoPro数据集上对真实世界的图像进行了图像去模糊任务的实验。我们的分析表明，与ViTs在图像分类任务中的声称相反，这些模型非常容易受到对抗攻击。我们试图通过对抗性训练来提高它们的鲁棒性。尽管这导致了显著的增加",
    "tldr": "我们调查了Vision Transformers（ViTs）在图像恢复任务中的鲁棒性，发现ViTs在图像分类任务中的改进并不能扩展到图像恢复任务中，并且这些模型易受对抗攻击。我们尝试通过对抗性训练来提高它们的鲁棒性。",
    "en_tdlr": "We investigate the robustness of Vision Transformers (ViTs) in image restoration tasks and find that the improvements in ViTs for image classification do not extend to image restoration, and these models are vulnerable to adversarial attacks. We attempt to enhance their robustness through adversarial training."
}