{
    "title": "Accuracy Amplification in Differentially Private Logistic Regression: A Pre-Training Approach. (arXiv:2307.13771v1 [cs.LG])",
    "abstract": "Machine learning (ML) models can memorize training datasets. As a result, training ML models over private datasets can violate the privacy of individuals. Differential privacy (DP) is a rigorous privacy notion to preserve the privacy of underlying training datasets in ML models. Yet, training ML models in a DP framework usually degrades the accuracy of ML models. This paper aims to boost the accuracy of a DP-ML model, specifically a logistic regression model, via a pre-training module. In more detail, we initially pre-train our model on a public training dataset that there is no privacy concern about it. Then, we fine-tune our model via the DP logistic regression with the private dataset. In the numerical results, we show that adding a pre-training module significantly improves the accuracy of the DP logistic regression.",
    "link": "http://arxiv.org/abs/2307.13771",
    "context": "Title: Accuracy Amplification in Differentially Private Logistic Regression: A Pre-Training Approach. (arXiv:2307.13771v1 [cs.LG])\nAbstract: Machine learning (ML) models can memorize training datasets. As a result, training ML models over private datasets can violate the privacy of individuals. Differential privacy (DP) is a rigorous privacy notion to preserve the privacy of underlying training datasets in ML models. Yet, training ML models in a DP framework usually degrades the accuracy of ML models. This paper aims to boost the accuracy of a DP-ML model, specifically a logistic regression model, via a pre-training module. In more detail, we initially pre-train our model on a public training dataset that there is no privacy concern about it. Then, we fine-tune our model via the DP logistic regression with the private dataset. In the numerical results, we show that adding a pre-training module significantly improves the accuracy of the DP logistic regression.",
    "path": "papers/23/07/2307.13771.json",
    "total_tokens": 814,
    "translated_title": "在差分隐私逻辑回归中的准确性增强：一种预训练方法",
    "translated_abstract": "机器学习模型可以记忆训练数据集，因此在私有数据集上训练机器学习模型可能会侵犯个人隐私。差分隐私是一种严格的隐私保护方法，可在机器学习模型中保留底层训练数据集的隐私。然而，在差分隐私框架下训练机器学习模型通常会降低模型的准确性。本文旨在通过预训练模块提高差分隐私机器学习模型（特别是逻辑回归模型）的准确性。具体而言，我们首先在公开训练数据集上对模型进行预训练，该数据集不涉及隐私问题。然后，我们通过使用私有数据集和差分隐私逻辑回归对模型进行微调。数值结果表明，添加预训练模块显著提高了差分隐私逻辑回归的准确性。",
    "tldr": "本文通过添加预训练模块，在差分隐私逻辑回归中提高了模型的准确性。",
    "en_tdlr": "This paper boosts the accuracy of differentially private logistic regression models by adding a pre-training module."
}