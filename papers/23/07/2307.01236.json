{
    "title": "Rockmate: an Efficient, Fast, Automatic and Generic Tool for Re-materialization in PyTorch. (arXiv:2307.01236v1 [cs.LG])",
    "abstract": "We propose Rockmate to control the memory requirements when training PyTorch DNN models. Rockmate is an automatic tool that starts from the model code and generates an equivalent model, using a predefined amount of memory for activations, at the cost of a few re-computations. Rockmate automatically detects the structure of computational and data dependencies and rewrites the initial model as a sequence of complex blocks. We show that such a structure is widespread and can be found in many models in the literature (Transformer based models, ResNet, RegNets,...). This structure allows us to solve the problem in a fast and efficient way, using an adaptation of Checkmate (too slow on the whole model but general) at the level of individual blocks and an adaptation of Rotor (fast but limited to sequential models) at the level of the sequence itself. We show through experiments on many models that Rockmate is as fast as Rotor and as efficient as Checkmate, and that it allows in many cases to ",
    "link": "http://arxiv.org/abs/2307.01236",
    "context": "Title: Rockmate: an Efficient, Fast, Automatic and Generic Tool for Re-materialization in PyTorch. (arXiv:2307.01236v1 [cs.LG])\nAbstract: We propose Rockmate to control the memory requirements when training PyTorch DNN models. Rockmate is an automatic tool that starts from the model code and generates an equivalent model, using a predefined amount of memory for activations, at the cost of a few re-computations. Rockmate automatically detects the structure of computational and data dependencies and rewrites the initial model as a sequence of complex blocks. We show that such a structure is widespread and can be found in many models in the literature (Transformer based models, ResNet, RegNets,...). This structure allows us to solve the problem in a fast and efficient way, using an adaptation of Checkmate (too slow on the whole model but general) at the level of individual blocks and an adaptation of Rotor (fast but limited to sequential models) at the level of the sequence itself. We show through experiments on many models that Rockmate is as fast as Rotor and as efficient as Checkmate, and that it allows in many cases to ",
    "path": "papers/23/07/2307.01236.json",
    "total_tokens": 936,
    "translated_title": "Rockmate: 一个高效、快速、自动和通用的PyTorch重新材料化工具",
    "translated_abstract": "我们提出了Rockmate来控制训练PyTorch深度学习模型时的内存需求。Rockmate是一个自动工具，从模型代码开始，使用预定义的激活内存量生成一个等效模型，以少量重新计算为代价。Rockmate自动检测计算和数据依赖关系的结构，并将初始模型重写为复杂块的序列。我们证明这样的结构很普遍，在许多文献的模型中都可以找到（基于Transformer的模型，ResNet，RegNets等）。这种结构使我们能够以快速和高效的方式解决问题，通过在单个块的级别上使用Checkmate的改编（在整个模型上速度太慢但通用），并在序列本身的级别上使用Rotor的改编（速度快但仅限于顺序模型）。我们通过对许多模型的实验证明，Rockmate与Rotor一样快，与Checkmate一样高效，并且在许多情况下可以",
    "tldr": "Rockmate是一个高效、快速、自动和通用的PyTorch重新材料化工具，通过检测计算和数据依赖关系的结构，将模型重写为复杂块的序列，以实现快速和高效的训练，并与Checkmate和Rotor的性能相当。"
}