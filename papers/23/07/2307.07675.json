{
    "title": "On the Robustness of Epoch-Greedy in Multi-Agent Contextual Bandit Mechanisms. (arXiv:2307.07675v1 [cs.LG])",
    "abstract": "Efficient learning in multi-armed bandit mechanisms such as pay-per-click (PPC) auctions typically involves three challenges: 1) inducing truthful bidding behavior (incentives), 2) using personalization in the users (context), and 3) circumventing manipulations in click patterns (corruptions). Each of these challenges has been studied orthogonally in the literature; incentives have been addressed by a line of work on truthful multi-armed bandit mechanisms, context has been extensively tackled by contextual bandit algorithms, while corruptions have been discussed via a recent line of work on bandits with adversarial corruptions. Since these challenges co-exist, it is important to understand the robustness of each of these approaches in addressing the other challenges, provide algorithms that can handle all simultaneously, and highlight inherent limitations in this combination. In this work, we show that the most prominent contextual bandit algorithm, $\\epsilon$-greedy can be extended to",
    "link": "http://arxiv.org/abs/2307.07675",
    "context": "Title: On the Robustness of Epoch-Greedy in Multi-Agent Contextual Bandit Mechanisms. (arXiv:2307.07675v1 [cs.LG])\nAbstract: Efficient learning in multi-armed bandit mechanisms such as pay-per-click (PPC) auctions typically involves three challenges: 1) inducing truthful bidding behavior (incentives), 2) using personalization in the users (context), and 3) circumventing manipulations in click patterns (corruptions). Each of these challenges has been studied orthogonally in the literature; incentives have been addressed by a line of work on truthful multi-armed bandit mechanisms, context has been extensively tackled by contextual bandit algorithms, while corruptions have been discussed via a recent line of work on bandits with adversarial corruptions. Since these challenges co-exist, it is important to understand the robustness of each of these approaches in addressing the other challenges, provide algorithms that can handle all simultaneously, and highlight inherent limitations in this combination. In this work, we show that the most prominent contextual bandit algorithm, $\\epsilon$-greedy can be extended to",
    "path": "papers/23/07/2307.07675.json",
    "total_tokens": 958,
    "translated_title": "关于多节点上下文赌博机制中Epoch-Greedy的鲁棒性",
    "translated_abstract": "在像点击付费(Pay-Per-Click)拍卖这样的多臂赌博机制中进行高效学习通常涉及三个挑战：1)引导真实出价行为(激励因素)，2)在用户个性化上下文中使用个性化(上下文)，3)规避点击模式中的操纵(损坏行为)。过去文献中每个挑战都被独立研究过；激励因素已在一系列研究中得到解决，上下文问题已通过上下文赌博算法得到广泛解决，而损坏问题则通过最近的关于具有对抗性损坏的赌博机制工作进行讨论。由于这些挑战同时存在，重要的是了解每种方法在解决其他挑战时的鲁棒性，提供可以同时处理所有挑战的算法，并突出这种组合中的固有局限性。在这项工作中，我们展示了最突出的上下文赌博算法$\\epsilon$-greedy可以进行扩展，以解决同时存在的激励因素、上下文和损坏问题。",
    "tldr": "本研究展示了在多Agent上下文赌博机制中，最突出的上下文赌博算法$\\epsilon$-greedy可以进行扩展，以解决同时存在的激励因素、上下文和损坏问题",
    "en_tdlr": "This study demonstrates that the prominent contextual bandit algorithm, $\\epsilon$-greedy, can be extended to address the co-existing challenges of incentives, context, and corruptions in multi-agent contextual bandit mechanisms."
}