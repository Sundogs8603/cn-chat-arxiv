{
    "title": "An Analysis of Untargeted Poisoning Attack and Defense Methods for Federated Online Learning to Rank Systems. (arXiv:2307.01565v1 [cs.IR])",
    "abstract": "Federated online learning to rank (FOLTR) aims to preserve user privacy by not sharing their searchable data and search interactions, while guaranteeing high search effectiveness, especially in contexts where individual users have scarce training data and interactions. For this, FOLTR trains learning to rank models in an online manner -- i.e. by exploiting users' interactions with the search systems (queries, clicks), rather than labels -- and federatively -i.e. by not aggregating interaction data in a central server for training purposes, but by training instances of a model on each user device on their own private data, and then sharing the model updates, not the data, across a set of users that have formed the federation. Existing FOLTR methods build upon advances in federated learning.  While federated learning methods have been shown effective at training machine learning models in a distributed way without the need of data sharing, they can be susceptible to attacks that target",
    "link": "http://arxiv.org/abs/2307.01565",
    "context": "Title: An Analysis of Untargeted Poisoning Attack and Defense Methods for Federated Online Learning to Rank Systems. (arXiv:2307.01565v1 [cs.IR])\nAbstract: Federated online learning to rank (FOLTR) aims to preserve user privacy by not sharing their searchable data and search interactions, while guaranteeing high search effectiveness, especially in contexts where individual users have scarce training data and interactions. For this, FOLTR trains learning to rank models in an online manner -- i.e. by exploiting users' interactions with the search systems (queries, clicks), rather than labels -- and federatively -i.e. by not aggregating interaction data in a central server for training purposes, but by training instances of a model on each user device on their own private data, and then sharing the model updates, not the data, across a set of users that have formed the federation. Existing FOLTR methods build upon advances in federated learning.  While federated learning methods have been shown effective at training machine learning models in a distributed way without the need of data sharing, they can be susceptible to attacks that target",
    "path": "papers/23/07/2307.01565.json",
    "total_tokens": 856,
    "translated_title": "对联邦在线学习排序系统中无目标投毒攻击和防御方法的分析",
    "translated_abstract": "联邦在线学习排序（FOLTR）旨在保护用户隐私，不共享其可搜索的数据和搜索交互，同时保证高搜索效果，尤其是在个体用户拥有有限的训练数据和交互的情况下。为此，FOLTR以在线方式训练排序模型，即利用用户与搜索系统的交互（查询，点击），而不是标签，并以联邦方式进行训练，即不将交互数据在中央服务器上进行聚合以进行训练，而是在每个用户设备上使用其自己的私有数据训练模型实例，然后在已形成联邦的一组用户之间共享模型更新，而不是数据。现有的FOLTR方法建立在联邦学习的进展之上。尽管联邦学习方法已被证明可以在不共享数据的情况下以分布式方式训练机器学习模型，但它们可能容易受到针对的攻击。",
    "tldr": "本论文分析了联邦在线学习排序系统中无目标投毒攻击和防御方法，旨在保护用户隐私并提高搜索效果。",
    "en_tdlr": "This paper analyzes untargeted poisoning attack and defense methods in federated online learning to rank systems, aiming to protect user privacy and improve search effectiveness."
}