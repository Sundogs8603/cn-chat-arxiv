{
    "title": "Sample-Efficient Learning of POMDPs with Multiple Observations In Hindsight. (arXiv:2307.02884v1 [cs.LG])",
    "abstract": "This paper studies the sample-efficiency of learning in Partially Observable Markov Decision Processes (POMDPs), a challenging problem in reinforcement learning that is known to be exponentially hard in the worst-case. Motivated by real-world settings such as loading in game playing, we propose an enhanced feedback model called ``multiple observations in hindsight'', where after each episode of interaction with the POMDP, the learner may collect multiple additional observations emitted from the encountered latent states, but may not observe the latent states themselves. We show that sample-efficient learning under this feedback model is possible for two new subclasses of POMDPs: \\emph{multi-observation revealing POMDPs} and \\emph{distinguishable POMDPs}. Both subclasses generalize and substantially relax \\emph{revealing POMDPs} -- a widely studied subclass for which sample-efficient learning is possible under standard trajectory feedback. Notably, distinguishable POMDPs only require th",
    "link": "http://arxiv.org/abs/2307.02884",
    "context": "Title: Sample-Efficient Learning of POMDPs with Multiple Observations In Hindsight. (arXiv:2307.02884v1 [cs.LG])\nAbstract: This paper studies the sample-efficiency of learning in Partially Observable Markov Decision Processes (POMDPs), a challenging problem in reinforcement learning that is known to be exponentially hard in the worst-case. Motivated by real-world settings such as loading in game playing, we propose an enhanced feedback model called ``multiple observations in hindsight'', where after each episode of interaction with the POMDP, the learner may collect multiple additional observations emitted from the encountered latent states, but may not observe the latent states themselves. We show that sample-efficient learning under this feedback model is possible for two new subclasses of POMDPs: \\emph{multi-observation revealing POMDPs} and \\emph{distinguishable POMDPs}. Both subclasses generalize and substantially relax \\emph{revealing POMDPs} -- a widely studied subclass for which sample-efficient learning is possible under standard trajectory feedback. Notably, distinguishable POMDPs only require th",
    "path": "papers/23/07/2307.02884.json",
    "total_tokens": 977,
    "translated_title": "使用事后多观察数据的POMDP样本高效学习",
    "translated_abstract": "本文研究了在部分可观察的马尔可夫决策过程（POMDPs）中学习的样本高效性，这是强化学习中一个在最坏情况下被证明是指数级困难的问题。受到现实世界中游戏中的加载等情景的启发，我们提出了一个增强的反馈模型，称为“事后多观察数据”，其中在与POMDP进行交互的每个周期之后，学习者可以收集到从遇到的潜在状态发出的多个附加观测数据，但不能直接观测到潜在状态本身。我们证明了在这个反馈模型下，对于两种新的POMDP子类（多观测展示POMDP和可区分POMDP），可以实现样本高效的学习。这两个子类相对于广泛研究的展示POMDP子类来说更加普遍和放松，而在标准轨迹反馈下可以实现样本高效学习。值得注意的是，可区分POMDP只需使用最少的观测数据和反馈进行学习。",
    "tldr": "本文研究了在部分可观察的马尔可夫决策过程（POMDPs）中学习的样本高效性，提出了一个增强的反馈模型，利用事后多观察数据实现了对两种新的POMDP子类的样本高效学习。",
    "en_tdlr": "This paper studies the sample-efficiency of learning in Partially Observable Markov Decision Processes (POMDPs) and proposes an enhanced feedback model using multiple observations in hindsight. It shows that sample-efficient learning is possible for two new subclasses of POMDPs using this feedback model."
}