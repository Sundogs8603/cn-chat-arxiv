{
    "title": "Benchmarking Test-Time Adaptation against Distribution Shifts in Image Classification. (arXiv:2307.03133v1 [cs.LG])",
    "abstract": "Test-time adaptation (TTA) is a technique aimed at enhancing the generalization performance of models by leveraging unlabeled samples solely during prediction. Given the need for robustness in neural network systems when faced with distribution shifts, numerous TTA methods have recently been proposed. However, evaluating these methods is often done under different settings, such as varying distribution shifts, backbones, and designing scenarios, leading to a lack of consistent and fair benchmarks to validate their effectiveness. To address this issue, we present a benchmark that systematically evaluates 13 prominent TTA methods and their variants on five widely used image classification datasets: CIFAR-10-C, CIFAR-100-C, ImageNet-C, DomainNet, and Office-Home. These methods encompass a wide range of adaptation scenarios (e.g. online adaptation v.s. offline adaptation, instance adaptation v.s. batch adaptation v.s. domain adaptation). Furthermore, we explore the compatibility of differe",
    "link": "http://arxiv.org/abs/2307.03133",
    "context": "Title: Benchmarking Test-Time Adaptation against Distribution Shifts in Image Classification. (arXiv:2307.03133v1 [cs.LG])\nAbstract: Test-time adaptation (TTA) is a technique aimed at enhancing the generalization performance of models by leveraging unlabeled samples solely during prediction. Given the need for robustness in neural network systems when faced with distribution shifts, numerous TTA methods have recently been proposed. However, evaluating these methods is often done under different settings, such as varying distribution shifts, backbones, and designing scenarios, leading to a lack of consistent and fair benchmarks to validate their effectiveness. To address this issue, we present a benchmark that systematically evaluates 13 prominent TTA methods and their variants on five widely used image classification datasets: CIFAR-10-C, CIFAR-100-C, ImageNet-C, DomainNet, and Office-Home. These methods encompass a wide range of adaptation scenarios (e.g. online adaptation v.s. offline adaptation, instance adaptation v.s. batch adaptation v.s. domain adaptation). Furthermore, we explore the compatibility of differe",
    "path": "papers/23/07/2307.03133.json",
    "total_tokens": 946,
    "translated_title": "在图像分类中对抗分布偏移的测试时间自适应性能评估",
    "translated_abstract": "测试时间自适应（TTA）是一种通过仅在预测过程中利用未标记样本来增强模型泛化性能的技术。针对神经网络系统在面临分布偏移时需要具备鲁棒性的需求，最近提出了许多TTA方法。然而，评估这些方法常常在不同的设置下进行，如不同的分布偏移、主干网络和设计场景，导致缺乏一致和公平的基准来验证它们的有效性。为了解决这个问题，我们提出了一个基准，对五个广泛使用的图像分类数据集（CIFAR-10-C、CIFAR-100-C、ImageNet-C、DomainNet和Office-Home）系统地评估了13个著名的TTA方法及其变体。这些方法涵盖了广泛的适应性场景（例如在线适应与离线适应、实例适应与批量适应与领域适应）。此外，我们还探讨了不同TTA方法在测试时间自适应方面的兼容性。",
    "tldr": "该论文提出一个基准，用于系统地评估图像分类中对抗分布偏移的测试时间自适应方法的有效性。研究作者使用13个著名的TTA方法及其变体在五个广泛使用的图像分类数据集上进行了评估，并讨论了不同方法在适应性场景中的兼容性。",
    "en_tdlr": "This paper presents a benchmark for systematically evaluating the effectiveness of test-time adaptation methods against distribution shifts in image classification. The authors evaluate 13 prominent TTA methods and their variants on five widely used datasets, and discuss the compatibility of different methods in adaptation scenarios."
}