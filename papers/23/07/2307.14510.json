{
    "title": "Attention of Robot Touch: Tactile Saliency Prediction for Robust Sim-to-Real Tactile Control. (arXiv:2307.14510v1 [cs.RO])",
    "abstract": "High-resolution tactile sensing can provide accurate information about local contact in contact-rich robotic tasks. However, the deployment of such tasks in unstructured environments remains under-investigated. To improve the robustness of tactile robot control in unstructured environments, we propose and study a new concept: \\textit{tactile saliency} for robot touch, inspired by the human touch attention mechanism from neuroscience and the visual saliency prediction problem from computer vision. In analogy to visual saliency, this concept involves identifying key information in tactile images captured by a tactile sensor. While visual saliency datasets are commonly annotated by humans, manually labelling tactile images is challenging due to their counterintuitive patterns. To address this challenge, we propose a novel approach comprised of three interrelated networks: 1) a Contact Depth Network (ConDepNet), which generates a contact depth map to localize deformation in a real tactile ",
    "link": "http://arxiv.org/abs/2307.14510",
    "context": "Title: Attention of Robot Touch: Tactile Saliency Prediction for Robust Sim-to-Real Tactile Control. (arXiv:2307.14510v1 [cs.RO])\nAbstract: High-resolution tactile sensing can provide accurate information about local contact in contact-rich robotic tasks. However, the deployment of such tasks in unstructured environments remains under-investigated. To improve the robustness of tactile robot control in unstructured environments, we propose and study a new concept: \\textit{tactile saliency} for robot touch, inspired by the human touch attention mechanism from neuroscience and the visual saliency prediction problem from computer vision. In analogy to visual saliency, this concept involves identifying key information in tactile images captured by a tactile sensor. While visual saliency datasets are commonly annotated by humans, manually labelling tactile images is challenging due to their counterintuitive patterns. To address this challenge, we propose a novel approach comprised of three interrelated networks: 1) a Contact Depth Network (ConDepNet), which generates a contact depth map to localize deformation in a real tactile ",
    "path": "papers/23/07/2307.14510.json",
    "total_tokens": 1036,
    "translated_title": "机器人触觉的注意力: 用于强健的模拟-真实触觉控制的触觉显著性预测",
    "translated_abstract": "高分辨率的触觉传感可以提供关于接触丰富的机器人任务中局部接触的准确信息。然而，在非结构化环境中部署这样的任务仍然未被充分研究。为了提高在非结构化环境中触觉机器人控制的鲁棒性，我们提出并研究了一个新的概念：机器人触觉的“触觉显著性”，灵感来源于神经科学中的人类触觉注意机制和计算机视觉中视觉显著性预测问题。类似于视觉显著性，这个概念涉及到通过触觉传感器捕捉到的触觉图像中识别关键信息。虽然视觉显著性数据集通常由人类进行注释，但由于触觉图像的反直觉模式，手动标记触觉图像具有挑战性。为了解决这个挑战，我们提出了一个由三个相互关联的网络组成的新方法: 1) 接触深度网络（ConDepNet），它生成一个接触深度地图以定位真实触觉中的变形。",
    "tldr": "这篇论文提出了一种新的概念——机器人触觉的“触觉显著性”，通过借鉴人类触觉注意机制和计算机视觉中的视觉显著性预测问题，提高了非结构化环境下触觉机器人控制的鲁棒性。",
    "en_tdlr": "This paper introduces a new concept called \"tactile saliency\" for robot touch, inspired by the human touch attention mechanism from neuroscience and the visual saliency prediction problem from computer vision, to improve the robustness of tactile robot control in unstructured environments."
}