{
    "title": "Reinforcement Learning Under Probabilistic Spatio-Temporal Constraints with Time Windows. (arXiv:2307.15910v1 [cs.AI])",
    "abstract": "We propose an automata-theoretic approach for reinforcement learning (RL) under complex spatio-temporal constraints with time windows. The problem is formulated using a Markov decision process under a bounded temporal logic constraint. Different from existing RL methods that can eventually learn optimal policies satisfying such constraints, our proposed approach enforces a desired probability of constraint satisfaction throughout learning. This is achieved by translating the bounded temporal logic constraint into a total automaton and avoiding \"unsafe\" actions based on the available prior information regarding the transition probabilities, i.e., a pair of upper and lower bounds for each transition probability. We provide theoretical guarantees on the resulting probability of constraint satisfaction. We also provide numerical results in a scenario where a robot explores the environment to discover high-reward regions while fulfilling some periodic pick-up and delivery tasks that are enc",
    "link": "http://arxiv.org/abs/2307.15910",
    "context": "Title: Reinforcement Learning Under Probabilistic Spatio-Temporal Constraints with Time Windows. (arXiv:2307.15910v1 [cs.AI])\nAbstract: We propose an automata-theoretic approach for reinforcement learning (RL) under complex spatio-temporal constraints with time windows. The problem is formulated using a Markov decision process under a bounded temporal logic constraint. Different from existing RL methods that can eventually learn optimal policies satisfying such constraints, our proposed approach enforces a desired probability of constraint satisfaction throughout learning. This is achieved by translating the bounded temporal logic constraint into a total automaton and avoiding \"unsafe\" actions based on the available prior information regarding the transition probabilities, i.e., a pair of upper and lower bounds for each transition probability. We provide theoretical guarantees on the resulting probability of constraint satisfaction. We also provide numerical results in a scenario where a robot explores the environment to discover high-reward regions while fulfilling some periodic pick-up and delivery tasks that are enc",
    "path": "papers/23/07/2307.15910.json",
    "total_tokens": 846,
    "translated_title": "在具有时间窗口的概率时空约束下的强化学习",
    "translated_abstract": "我们提出了一种自动机理论方法来解决具有时间窗口的复杂时空约束下的强化学习（RL）问题。该问题使用有界时态逻辑约束下的马尔可夫决策过程进行建模。与现有的RL方法可以最终学习到满足这些约束的最优策略不同，我们提出的方法在整个学习过程中始终保持所需约束满足的概率。这是通过将有界时态逻辑约束转化为总自动机，并基于关于转移概率的先前可用信息（即每个转移概率的上界和下界）避免“不安全”动作来实现的。我们在结果中提供了约束满足概率的理论保证。我们还在一个场景中提供了数值结果，该场景中，机器人在探索环境，发现高回报区域的同时，还需要执行一些周期性的拾取和交付任务",
    "tldr": "我们提出了一种自动机理论方法来解决具有时间窗口的复杂时空约束下的强化学习问题，该方法能在整个学习过程中始终保持所需约束满足的概率。",
    "en_tdlr": "We propose an automata-theoretic approach for reinforcement learning under complex spatio-temporal constraints with time windows, which enforces a desired probability of constraint satisfaction throughout the learning process."
}