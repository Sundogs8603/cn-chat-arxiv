{
    "title": "Leveraging Implicit Feedback from Deployment Data in Dialogue. (arXiv:2307.14117v1 [cs.CL])",
    "abstract": "We study improving social conversational agents by learning from natural dialogue between users and a deployed model, without extra annotations. To implicitly measure the quality of a machine-generated utterance, we leverage signals like user response length, sentiment and reaction of the future human utterances in the collected dialogue episodes. Our experiments use the publicly released deployment data from BlenderBot (Xu et al., 2023). Human evaluation indicates improvements in our new models over baseline responses; however, we find that some proxy signals can lead to more generations with undesirable properties as well. For example, optimizing for conversation length can lead to more controversial or unfriendly generations compared to the baseline, whereas optimizing for positive sentiment or reaction can decrease these behaviors.",
    "link": "http://arxiv.org/abs/2307.14117",
    "context": "Title: Leveraging Implicit Feedback from Deployment Data in Dialogue. (arXiv:2307.14117v1 [cs.CL])\nAbstract: We study improving social conversational agents by learning from natural dialogue between users and a deployed model, without extra annotations. To implicitly measure the quality of a machine-generated utterance, we leverage signals like user response length, sentiment and reaction of the future human utterances in the collected dialogue episodes. Our experiments use the publicly released deployment data from BlenderBot (Xu et al., 2023). Human evaluation indicates improvements in our new models over baseline responses; however, we find that some proxy signals can lead to more generations with undesirable properties as well. For example, optimizing for conversation length can lead to more controversial or unfriendly generations compared to the baseline, whereas optimizing for positive sentiment or reaction can decrease these behaviors.",
    "path": "papers/23/07/2307.14117.json",
    "total_tokens": 741,
    "translated_title": "在对话中利用来自部署数据的隐式反馈",
    "translated_abstract": "我们研究通过学习用户与部署模型之间的自然对话来改进社交对话系统，而无需额外的注释。为了隐式衡量机器生成话语的质量，我们利用收集对话中未来人类话语的用户响应长度、情感和反应等信号。我们的实验使用了BlenderBot（Xu等，2023年）公开发布的部署数据。人类评估显示出我们的新模型比基线回复有所改进；然而，我们发现一些代理信号也可能导致出现不良属性的生成。例如，优化对话长度可能导致与基线相比更具争议性或不友好的生成，而优化积极情感或反应则可以减少这些行为。",
    "tldr": "研究利用对话中的隐式反馈来改进社交对话系统。实验结果表明通过收集用户响应长度、情感和反应等信号可以提高机器生成话语的质量。",
    "en_tdlr": "This paper investigates improving social conversational agents by leveraging implicit feedback from natural dialogue. The experiments show that collecting signals such as user response length, sentiment, and reaction can enhance the quality of machine-generated utterances."
}