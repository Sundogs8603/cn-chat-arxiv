{
    "title": "What can a Single Attention Layer Learn? A Study Through the Random Features Lens. (arXiv:2307.11353v1 [cs.LG])",
    "abstract": "Attention layers -- which map a sequence of inputs to a sequence of outputs -- are core building blocks of the Transformer architecture which has achieved significant breakthroughs in modern artificial intelligence. This paper presents a rigorous theoretical study on the learning and generalization of a single multi-head attention layer, with a sequence of key vectors and a separate query vector as input. We consider the random feature setting where the attention layer has a large number of heads, with randomly sampled frozen query and key matrices, and trainable value matrices. We show that such a random-feature attention layer can express a broad class of target functions that are permutation invariant to the key vectors. We further provide quantitative excess risk bounds for learning these target functions from finite samples, using random feature attention with finitely many heads.  Our results feature several implications unique to the attention structure compared with existing ra",
    "link": "http://arxiv.org/abs/2307.11353",
    "context": "Title: What can a Single Attention Layer Learn? A Study Through the Random Features Lens. (arXiv:2307.11353v1 [cs.LG])\nAbstract: Attention layers -- which map a sequence of inputs to a sequence of outputs -- are core building blocks of the Transformer architecture which has achieved significant breakthroughs in modern artificial intelligence. This paper presents a rigorous theoretical study on the learning and generalization of a single multi-head attention layer, with a sequence of key vectors and a separate query vector as input. We consider the random feature setting where the attention layer has a large number of heads, with randomly sampled frozen query and key matrices, and trainable value matrices. We show that such a random-feature attention layer can express a broad class of target functions that are permutation invariant to the key vectors. We further provide quantitative excess risk bounds for learning these target functions from finite samples, using random feature attention with finitely many heads.  Our results feature several implications unique to the attention structure compared with existing ra",
    "path": "papers/23/07/2307.11353.json",
    "total_tokens": 928,
    "translated_title": "一个单一的注意层能学到什么？通过随机特征视角的研究。",
    "translated_abstract": "注意层是Transformer架构的核心组成部分，通过将输入序列映射到输出序列，在现代人工智能领域取得了重要突破。本文对单个多头注意层进行了严格的理论研究，输入是一系列关键向量和一个独立的查询向量。我们考虑了一个随机特征设置，其中注意层具有大量头部，具有随机采样的冻结查询和关键矩阵以及可训练的值矩阵。我们展示了这样一个随机特征的注意层可以表示一类与关键向量置换无关的目标函数。我们进一步提供了有限样本情况下学习这些目标函数的定量过量风险界限的方法，使用有限数量的头部和随机特征注意层。我们的结果相比现有的随机线性功能模型有几个注意结构上的独特影响。",
    "tldr": "本研究通过随机特征分析，对单个注意层的学习和泛化进行了严格的理论研究。结果表明，在具有随机采样的关键矩阵和可训练值矩阵的情况下，随机特征注意层可以表示一类与关键向量置换无关的目标函数，并提供了学习这些目标函数的风险界限。",
    "en_tdlr": "This paper rigorously examines the learning and generalization of a single attention layer using random features analysis. It shows that such a random-feature attention layer can express a class of target functions that are permutation invariant to the key vectors, and provides quantitative risk bounds for learning these target functions."
}