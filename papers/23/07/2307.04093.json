{
    "title": "Properly Learning Decision Trees with Queries Is NP-Hard. (arXiv:2307.04093v1 [cs.CC])",
    "abstract": "We prove that it is NP-hard to properly PAC learn decision trees with queries, resolving a longstanding open problem in learning theory (Bshouty 1993; Guijarro-Lavin-Raghavan 1999; Mehta-Raghavan 2002; Feldman 2016). While there has been a long line of work, dating back to (Pitt-Valiant 1988), establishing the hardness of properly learning decision trees from random examples, the more challenging setting of query learners necessitates different techniques and there were no previous lower bounds. En route to our main result, we simplify and strengthen the best known lower bounds for a different problem of Decision Tree Minimization (Zantema-Bodlaender 2000; Sieling 2003).  On a technical level, we introduce the notion of hardness distillation, which we study for decision tree complexity but can be considered for any complexity measure: for a function that requires large decision trees, we give a general method for identifying a small set of inputs that is responsible for its complexity.",
    "link": "http://arxiv.org/abs/2307.04093",
    "context": "Title: Properly Learning Decision Trees with Queries Is NP-Hard. (arXiv:2307.04093v1 [cs.CC])\nAbstract: We prove that it is NP-hard to properly PAC learn decision trees with queries, resolving a longstanding open problem in learning theory (Bshouty 1993; Guijarro-Lavin-Raghavan 1999; Mehta-Raghavan 2002; Feldman 2016). While there has been a long line of work, dating back to (Pitt-Valiant 1988), establishing the hardness of properly learning decision trees from random examples, the more challenging setting of query learners necessitates different techniques and there were no previous lower bounds. En route to our main result, we simplify and strengthen the best known lower bounds for a different problem of Decision Tree Minimization (Zantema-Bodlaender 2000; Sieling 2003).  On a technical level, we introduce the notion of hardness distillation, which we study for decision tree complexity but can be considered for any complexity measure: for a function that requires large decision trees, we give a general method for identifying a small set of inputs that is responsible for its complexity.",
    "path": "papers/23/07/2307.04093.json",
    "total_tokens": 754,
    "translated_title": "通过查询正确学习决策树是NP难问题",
    "translated_abstract": "我们证明了通过查询正确学习决策树是一个NP难问题，解决了学习理论中一个长期存在的开放问题。我们的研究对于决策树复杂性的困难蒸馏概念进行了引入，并提出了一种通用方法来确定导致复杂性的一个小输入集合，从而简化和加强了对决策树最小化问题的众所周知的下界。",
    "tldr": "通过查询正确学习决策树被证明是一个NP难问题，这就填补了学习理论中长期存在的一个空白，并引入了一种简化和加强决策树最小化问题下界的方法。"
}