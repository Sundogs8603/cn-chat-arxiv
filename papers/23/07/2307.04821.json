{
    "title": "Amplifying Limitations, Harms and Risks of Large Language Models. (arXiv:2307.04821v1 [cs.CL])",
    "abstract": "We present this article as a small gesture in an attempt to counter what appears to be exponentially growing hype around Artificial Intelligence (AI) and its capabilities, and the distraction provided by the associated talk of science-fiction scenarios that might arise if AI should become sentient and super-intelligent. It may also help those outside of the field to become more informed about some of the limitations of AI technology. In the current context of popular discourse AI defaults to mean foundation and large language models (LLMs) such as those used to create ChatGPT. This in itself is a misrepresentation of the diversity, depth and volume of research, researchers, and technology that truly represents the field of AI. AI being a field of research that has existed in software artefacts since at least the 1950's. We set out to highlight a number of limitations of LLMs, and in so doing highlight that harms have already arisen and will continue to arise due to these limitations. A",
    "link": "http://arxiv.org/abs/2307.04821",
    "context": "Title: Amplifying Limitations, Harms and Risks of Large Language Models. (arXiv:2307.04821v1 [cs.CL])\nAbstract: We present this article as a small gesture in an attempt to counter what appears to be exponentially growing hype around Artificial Intelligence (AI) and its capabilities, and the distraction provided by the associated talk of science-fiction scenarios that might arise if AI should become sentient and super-intelligent. It may also help those outside of the field to become more informed about some of the limitations of AI technology. In the current context of popular discourse AI defaults to mean foundation and large language models (LLMs) such as those used to create ChatGPT. This in itself is a misrepresentation of the diversity, depth and volume of research, researchers, and technology that truly represents the field of AI. AI being a field of research that has existed in software artefacts since at least the 1950's. We set out to highlight a number of limitations of LLMs, and in so doing highlight that harms have already arisen and will continue to arise due to these limitations. A",
    "path": "papers/23/07/2307.04821.json",
    "total_tokens": 939,
    "translated_title": "扩大大型语言模型的限制、伤害和风险",
    "translated_abstract": "我们在这篇文章中试图通过一个小小的举动来抵制人工智能（AI）及其能力所带来的指数级增长的炒作，以及由此带来的科幻情景的分散注意力。这也有助于那些在该领域之外的人了解一些AI技术的局限性。在当前流行话语的背景下，AI默认为意味着基础和大型语言模型（LLMs），如用于创建ChatGPT的模型。这本身就是对研究领域多样性、深度和容量的曲解，而真正代表AI领域的是研究、研究人员和技术的多样性。AI作为一门研究领域，至少从20世纪50年代以来就存在于软件构件中。我们试图突出一些LLMs的局限性，并在此过程中强调由于这些局限性已经出现并将继续出现的伤害。",
    "tldr": "本文旨在扩大人工智能（AI）和大型语言模型（LLMs）的限制、伤害和风险，并指出当前关于AI的夸大炒作和误解。这有助于消除一些对AI技术的错误认识，并提醒人们注意由于这些限制而产生的实际伤害。",
    "en_tdlr": "This article aims to amplify the limitations, harms, and risks of Artificial Intelligence (AI) and Large Language Models (LLMs) and highlight the exaggeration and misrepresentation surrounding AI. It serves to dispel misconceptions about AI technology and raise awareness about the actual harms caused by these limitations."
}