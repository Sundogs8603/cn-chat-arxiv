{
    "title": "Human-to-Human Interaction Detection. (arXiv:2307.00464v2 [cs.CV] UPDATED)",
    "abstract": "A comprehensive understanding of interested human-to-human interactions in video streams, such as queuing, handshaking, fighting and chasing, is of immense importance to the surveillance of public security in regions like campuses, squares and parks. Different from conventional human interaction recognition, which uses choreographed videos as inputs, neglects concurrent interactive groups, and performs detection and recognition in separate stages, we introduce a new task named human-to-human interaction detection (HID). HID devotes to detecting subjects, recognizing person-wise actions, and grouping people according to their interactive relations, in one model. First, based on the popular AVA dataset created for action detection, we establish a new HID benchmark, termed AVA-Interaction (AVA-I), by adding annotations on interactive relations in a frame-by-frame manner. AVA-I consists of 85,254 frames and 86,338 interactive groups, and each image includes up to 4 concurrent interactive g",
    "link": "http://arxiv.org/abs/2307.00464",
    "context": "Title: Human-to-Human Interaction Detection. (arXiv:2307.00464v2 [cs.CV] UPDATED)\nAbstract: A comprehensive understanding of interested human-to-human interactions in video streams, such as queuing, handshaking, fighting and chasing, is of immense importance to the surveillance of public security in regions like campuses, squares and parks. Different from conventional human interaction recognition, which uses choreographed videos as inputs, neglects concurrent interactive groups, and performs detection and recognition in separate stages, we introduce a new task named human-to-human interaction detection (HID). HID devotes to detecting subjects, recognizing person-wise actions, and grouping people according to their interactive relations, in one model. First, based on the popular AVA dataset created for action detection, we establish a new HID benchmark, termed AVA-Interaction (AVA-I), by adding annotations on interactive relations in a frame-by-frame manner. AVA-I consists of 85,254 frames and 86,338 interactive groups, and each image includes up to 4 concurrent interactive g",
    "path": "papers/23/07/2307.00464.json",
    "total_tokens": 910,
    "translated_title": "人与人之间的互动检测",
    "translated_abstract": "对于视频流中的人与人之间的互动行为（例如排队、握手、打斗和追逐）的全面理解，对于校园、广场和公园等地区的公共安全监控至关重要。与使用编排视频作为输入、忽略并发互动群体，并将检测和识别分为不同阶段的传统人际互动识别不同，我们引入了一个称为人与人之间的互动检测（HID）的新任务。HID致力于在一个模型中检测主体、识别个人动作，并根据他们的互动关系将人员分组。首先，我们基于用于动作检测的流行AVA数据集，在逐帧的方式上添加了互动关系的注释，建立了一个名为AVA-Interaction（AVA-I）的新的HID基准。AVA-I包括85,254帧和86,338个互动群体，每个图像最多包含4个并发互动群体。",
    "tldr": "这项研究提出了人与人之间的互动检测任务，通过一种模型实现了同时检测主体、识别个人动作和根据互动关系分组的目标。通过在现有的AVA数据集上添加互动关系注释，建立了一个新的HID基准数据集。",
    "en_tdlr": "The paper introduces a new task called human-to-human interaction detection (HID), which aims to detect subjects, recognize person-wise actions, and group people based on their interactive relations in one model. They establish a new HID benchmark called AVA-Interaction (AVA-I) by adding annotations on interactive relations to the popular AVA dataset."
}