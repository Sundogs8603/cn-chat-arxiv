{
    "title": "Unified Molecular Modeling via Modality Blending. (arXiv:2307.06235v1 [cs.LG])",
    "abstract": "Self-supervised molecular representation learning is critical for molecule-based tasks such as AI-assisted drug discovery. Recent studies consider leveraging both 2D and 3D information for representation learning, with straightforward alignment strategies that treat each modality separately. In this work, we introduce a novel \"blend-then-predict\" self-supervised learning method (MoleBLEND), which blends atom relations from different modalities into one unified relation matrix for encoding, then recovers modality-specific information for both 2D and 3D structures. By treating atom relationships as anchors, seemingly dissimilar 2D and 3D manifolds are aligned and integrated at fine-grained relation-level organically. Extensive experiments show that MoleBLEND achieves state-of-the-art performance across major 2D/3D benchmarks. We further provide theoretical insights from the perspective of mutual-information maximization, demonstrating that our method unifies contrastive, generative (inte",
    "link": "http://arxiv.org/abs/2307.06235",
    "context": "Title: Unified Molecular Modeling via Modality Blending. (arXiv:2307.06235v1 [cs.LG])\nAbstract: Self-supervised molecular representation learning is critical for molecule-based tasks such as AI-assisted drug discovery. Recent studies consider leveraging both 2D and 3D information for representation learning, with straightforward alignment strategies that treat each modality separately. In this work, we introduce a novel \"blend-then-predict\" self-supervised learning method (MoleBLEND), which blends atom relations from different modalities into one unified relation matrix for encoding, then recovers modality-specific information for both 2D and 3D structures. By treating atom relationships as anchors, seemingly dissimilar 2D and 3D manifolds are aligned and integrated at fine-grained relation-level organically. Extensive experiments show that MoleBLEND achieves state-of-the-art performance across major 2D/3D benchmarks. We further provide theoretical insights from the perspective of mutual-information maximization, demonstrating that our method unifies contrastive, generative (inte",
    "path": "papers/23/07/2307.06235.json",
    "total_tokens": 856,
    "translated_title": "通过模态融合实现统一的分子建模",
    "translated_abstract": "自监督的分子表示学习对于基于分子的任务如人工智能辅助药物发现至关重要。最近的研究考虑利用2D和3D信息进行表示学习，采用将每种模态分开处理的直接对齐策略。在这项工作中，我们引入了一种新的\"混合-预测\"自监督学习方法（MoleBLEND），将来自不同模态的原子间关系融合成一个统一的关系矩阵进行编码，然后恢复2D和3D结构的模态特定信息。通过将原子关系视为锚点，看似不相似的2D和3D流形在细粒度的关系级别上有机地对齐和整合。大量实验证明，MoleBLEND在主要的2D/3D基准测试中达到了最先进的性能。我们从相互信息最大化的角度提供了理论洞察，证明了我们的方法统一了对比、生成",
    "tldr": "MoleBLEND是一种通过对2D和3D分子结构进行统一编码和融合的自监督学习方法，实现了分子表示学习的最新性能表现。"
}