{
    "title": "Federated Unlearning via Active Forgetting. (arXiv:2307.03363v1 [cs.LG])",
    "abstract": "The increasing concerns regarding the privacy of machine learning models have catalyzed the exploration of machine unlearning, i.e., a process that removes the influence of training data on machine learning models. This concern also arises in the realm of federated learning, prompting researchers to address the federated unlearning problem. However, federated unlearning remains challenging. Existing unlearning methods can be broadly categorized into two approaches, i.e., exact unlearning and approximate unlearning. Firstly, implementing exact unlearning, which typically relies on the partition-aggregation framework, in a distributed manner does not improve time efficiency theoretically. Secondly, existing federated (approximate) unlearning methods suffer from imprecise data influence estimation, significant computational burden, or both. To this end, we propose a novel federated unlearning framework based on incremental learning, which is independent of specific models and federated se",
    "link": "http://arxiv.org/abs/2307.03363",
    "context": "Title: Federated Unlearning via Active Forgetting. (arXiv:2307.03363v1 [cs.LG])\nAbstract: The increasing concerns regarding the privacy of machine learning models have catalyzed the exploration of machine unlearning, i.e., a process that removes the influence of training data on machine learning models. This concern also arises in the realm of federated learning, prompting researchers to address the federated unlearning problem. However, federated unlearning remains challenging. Existing unlearning methods can be broadly categorized into two approaches, i.e., exact unlearning and approximate unlearning. Firstly, implementing exact unlearning, which typically relies on the partition-aggregation framework, in a distributed manner does not improve time efficiency theoretically. Secondly, existing federated (approximate) unlearning methods suffer from imprecise data influence estimation, significant computational burden, or both. To this end, we propose a novel federated unlearning framework based on incremental learning, which is independent of specific models and federated se",
    "path": "papers/23/07/2307.03363.json",
    "total_tokens": 879,
    "translated_title": "通过主动遗忘实现联邦遗忘",
    "translated_abstract": "对机器学习模型隐私的关注日益增加，引发了对机器遗忘的探索，即一种消除训练数据对机器学习模型影响的过程。这种关注也出现在联邦学习的领域，促使研究人员解决联邦遗忘问题。然而，联邦遗忘仍然具有挑战性。现有的遗忘方法可以被广泛分为两种方法，即精确遗忘和近似遗忘。首先，在分布式情况下实施精确遗忘，通常依赖于分区-聚合框架，理论上不会提高时间效率。其次，现有的联邦（近似）遗忘方法在数据影响估计不精确、计算负荷大或两者都存在方面存在问题。为此，我们提出了一种基于增量学习的新型联邦遗忘框架，该框架不依赖于具体的模型和联邦设置。",
    "tldr": "本文提出了一种基于增量学习的新型联邦遗忘框架，解决了现有联邦遗忘方法在时间效率、数据影响估计不精确和计算负荷大等方面的问题。",
    "en_tdlr": "This paper proposes a novel federated unlearning framework based on incremental learning, addressing the issues of time efficiency, imprecise data influence estimation, and significant computational burden in existing federated unlearning methods."
}