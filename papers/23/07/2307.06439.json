{
    "title": "Distilling Large Language Models for Biomedical Knowledge Extraction: A Case Study on Adverse Drug Events. (arXiv:2307.06439v1 [cs.CL])",
    "abstract": "Large language models (LLMs), such as GPT-4, have demonstrated remarkable capabilities across a wide range of tasks, including health applications. In this paper, we study how LLMs can be used to scale biomedical knowledge curation. We find that while LLMs already possess decent competency in structuring biomedical text, by distillation into a task-specific student model through self-supervised learning, substantial gains can be attained over out-of-box LLMs, with additional advantages such as cost, efficiency, and white-box model access.  We conduct a case study on adverse drug event (ADE) extraction, which is an important area for improving care. On standard ADE extraction evaluation, a GPT-3.5 distilled PubMedBERT model attained comparable accuracy as supervised state-of-the-art models without using any labeled data. Despite being over 1,000 times smaller, the distilled model outperformed its teacher GPT-3.5 by over 6 absolute points in F1 and GPT-4 by over 5 absolute points.  Ablat",
    "link": "http://arxiv.org/abs/2307.06439",
    "context": "Title: Distilling Large Language Models for Biomedical Knowledge Extraction: A Case Study on Adverse Drug Events. (arXiv:2307.06439v1 [cs.CL])\nAbstract: Large language models (LLMs), such as GPT-4, have demonstrated remarkable capabilities across a wide range of tasks, including health applications. In this paper, we study how LLMs can be used to scale biomedical knowledge curation. We find that while LLMs already possess decent competency in structuring biomedical text, by distillation into a task-specific student model through self-supervised learning, substantial gains can be attained over out-of-box LLMs, with additional advantages such as cost, efficiency, and white-box model access.  We conduct a case study on adverse drug event (ADE) extraction, which is an important area for improving care. On standard ADE extraction evaluation, a GPT-3.5 distilled PubMedBERT model attained comparable accuracy as supervised state-of-the-art models without using any labeled data. Despite being over 1,000 times smaller, the distilled model outperformed its teacher GPT-3.5 by over 6 absolute points in F1 and GPT-4 by over 5 absolute points.  Ablat",
    "path": "papers/23/07/2307.06439.json",
    "total_tokens": 1030,
    "translated_title": "为生物医学知识提取而蒸馏大型语言模型：对药物不良事件的案例研究",
    "translated_abstract": "大型语言模型（LLMs），如GPT-4，在包括健康应用在内的各种任务中展示了卓越的能力。本文研究了如何利用LLMs来扩展生物医学知识整理。我们发现，尽管LLMs已经具备了结构化生物医学文本的良好能力，但通过自监督学习将其蒸馏为特定任务的学生模型可以取得显著的改进，同时具备成本、效率和白盒模型访问等额外优势。我们对不良药物事件（ADE）提取进行了案例研究，这是改进医疗的重要领域。在标准ADE提取评估中，经蒸馏的GPT-3.5 PubMedBERT模型在不使用任何标记数据的情况下，达到了与监督式最先进模型相当的准确性。尽管体积缩小了1000多倍，但蒸馏模型在F1指标上超过了其教师GPT-3.5约6个绝对点，超过了GPT-4约5个绝对点。",
    "tldr": "本研究通过将大型语言模型蒸馏为特定任务的学生模型，成功地提升了在药物不良事件提取方面的性能，并在不使用标记数据的情况下达到了与监督式最先进模型相当的准确性，具有成本、效率和白盒模型访问等优势。",
    "en_tdlr": "This study demonstrates the successful distillation of large language models into task-specific student models, resulting in improved performance in adverse drug event extraction. The distilled model achieves comparable accuracy as supervised state-of-the-art models without using labeled data, while also offering benefits such as cost, efficiency, and white-box model access."
}