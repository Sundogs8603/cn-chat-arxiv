{
    "title": "A Novel Bayes' Theorem for Upper Probabilities. (arXiv:2307.06831v1 [stat.ML])",
    "abstract": "In their seminal 1990 paper, Wasserman and Kadane establish an upper bound for the Bayes' posterior probability of a measurable set $A$, when the prior lies in a class of probability measures $\\mathcal{P}$ and the likelihood is precise. They also give a sufficient condition for such upper bound to hold with equality. In this paper, we introduce a generalization of their result by additionally addressing uncertainty related to the likelihood. We give an upper bound for the posterior probability when both the prior and the likelihood belong to a set of probabilities. Furthermore, we give a sufficient condition for this upper bound to become an equality. This result is interesting on its own, and has the potential of being applied to various fields of engineering (e.g. model predictive control), machine learning, and artificial intelligence.",
    "link": "http://arxiv.org/abs/2307.06831",
    "context": "Title: A Novel Bayes' Theorem for Upper Probabilities. (arXiv:2307.06831v1 [stat.ML])\nAbstract: In their seminal 1990 paper, Wasserman and Kadane establish an upper bound for the Bayes' posterior probability of a measurable set $A$, when the prior lies in a class of probability measures $\\mathcal{P}$ and the likelihood is precise. They also give a sufficient condition for such upper bound to hold with equality. In this paper, we introduce a generalization of their result by additionally addressing uncertainty related to the likelihood. We give an upper bound for the posterior probability when both the prior and the likelihood belong to a set of probabilities. Furthermore, we give a sufficient condition for this upper bound to become an equality. This result is interesting on its own, and has the potential of being applied to various fields of engineering (e.g. model predictive control), machine learning, and artificial intelligence.",
    "path": "papers/23/07/2307.06831.json",
    "total_tokens": 799,
    "translated_title": "一种新的贝叶斯定理用于上概率",
    "translated_abstract": "在他们1990年的开创性论文中，瓦塞尔曼和卡代纳建立了在先验概率位于概率类别P，且似然函数是精确函数时，可测集A的贝叶斯后验概率的上限。他们还给出了这种上限成立时的充分条件。本文中，我们通过额外处理与似然函数相关的不确定性来引入他们结果的推广。我们给出了当先验概率和似然函数都属于一组概率时的后验概率上限，并且给出了这种上限成为等式的充分条件。这个结果本身很有趣，并且有可能应用于工程领域（例如模型预测控制）、机器学习和人工智能。",
    "tldr": "本文推广了瓦塞尔曼和卡代纳的结果，给出了一种新的贝叶斯定理用于处理与似然函数相关的不确定性。该结果对于工程、机器学习和人工智能领域具有潜在应用价值。"
}