{
    "title": "Opening up ChatGPT: Tracking openness, transparency, and accountability in instruction-tuned text generators. (arXiv:2307.05532v1 [cs.CL])",
    "abstract": "Large language models that exhibit instruction-following behaviour represent one of the biggest recent upheavals in conversational interfaces, a trend in large part fuelled by the release of OpenAI's ChatGPT, a proprietary large language model for text generation fine-tuned through reinforcement learning from human feedback (LLM+RLHF). We review the risks of relying on proprietary software and survey the first crop of open-source projects of comparable architecture and functionality. The main contribution of this paper is to show that openness is differentiated, and to offer scientific documentation of degrees of openness in this fast-moving field. We evaluate projects in terms of openness of code, training data, model weights, RLHF data, licensing, scientific documentation, and access methods. We find that while there is a fast-growing list of projects billing themselves as 'open source', many inherit undocumented data of dubious legality, few share the all-important instruction-tunin",
    "link": "http://arxiv.org/abs/2307.05532",
    "context": "Title: Opening up ChatGPT: Tracking openness, transparency, and accountability in instruction-tuned text generators. (arXiv:2307.05532v1 [cs.CL])\nAbstract: Large language models that exhibit instruction-following behaviour represent one of the biggest recent upheavals in conversational interfaces, a trend in large part fuelled by the release of OpenAI's ChatGPT, a proprietary large language model for text generation fine-tuned through reinforcement learning from human feedback (LLM+RLHF). We review the risks of relying on proprietary software and survey the first crop of open-source projects of comparable architecture and functionality. The main contribution of this paper is to show that openness is differentiated, and to offer scientific documentation of degrees of openness in this fast-moving field. We evaluate projects in terms of openness of code, training data, model weights, RLHF data, licensing, scientific documentation, and access methods. We find that while there is a fast-growing list of projects billing themselves as 'open source', many inherit undocumented data of dubious legality, few share the all-important instruction-tunin",
    "path": "papers/23/07/2307.05532.json",
    "total_tokens": 749,
    "translated_title": "打开ChatGPT：跟踪指令调整文本生成器的开放性、透明度和问责制",
    "translated_abstract": "展示了开放性的差异，并提供了该快速发展领域中开放程度的科学文档。通过评估项目的代码、训练数据、模型权重、强化学习数据、许可、科学文档和访问方式的开放程度，研究结果发现虽然有越来越多的自称为“开源”的项目，但许多项目继承了不确定合法性的未记录的数据，很少有项目分享重要的指令调整功能。",
    "tldr": "评估了各个项目在代码、数据、模型等方面的开放程度，并发现有许多项目虽自称为开源，却存在不确定合法性的未记录数据，而很少有项目分享重要的指令调整功能。",
    "en_tdlr": "This paper evaluates the openness of projects in terms of code, data, model, etc., and finds that many projects claiming to be open source have undocumented data of uncertain legality, while few share the important instruction-tuning functionality."
}