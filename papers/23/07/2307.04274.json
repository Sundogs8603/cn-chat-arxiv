{
    "title": "Assessing the efficacy of large language models in generating accurate teacher responses. (arXiv:2307.04274v1 [cs.CL])",
    "abstract": "(Tack et al., 2023) organized the shared task hosted by the 18th Workshop on Innovative Use of NLP for Building Educational Applications on generation of teacher language in educational dialogues. Following the structure of the shared task, in this study, we attempt to assess the generative abilities of large language models in providing informative and helpful insights to students, thereby simulating the role of a knowledgeable teacher. To this end, we present an extensive evaluation of several benchmarking generative models, including GPT-4 (few-shot, in-context learning), fine-tuned GPT-2, and fine-tuned DialoGPT. Additionally, to optimize for pedagogical quality, we fine-tuned the Flan-T5 model using reinforcement learning. Our experimental findings on the Teacher-Student Chatroom Corpus subset indicate the efficacy of GPT-4 over other fine-tuned models, measured using BERTScore and DialogRPT.  We hypothesize that several dataset characteristics, including sampling, representativen",
    "link": "http://arxiv.org/abs/2307.04274",
    "context": "Title: Assessing the efficacy of large language models in generating accurate teacher responses. (arXiv:2307.04274v1 [cs.CL])\nAbstract: (Tack et al., 2023) organized the shared task hosted by the 18th Workshop on Innovative Use of NLP for Building Educational Applications on generation of teacher language in educational dialogues. Following the structure of the shared task, in this study, we attempt to assess the generative abilities of large language models in providing informative and helpful insights to students, thereby simulating the role of a knowledgeable teacher. To this end, we present an extensive evaluation of several benchmarking generative models, including GPT-4 (few-shot, in-context learning), fine-tuned GPT-2, and fine-tuned DialoGPT. Additionally, to optimize for pedagogical quality, we fine-tuned the Flan-T5 model using reinforcement learning. Our experimental findings on the Teacher-Student Chatroom Corpus subset indicate the efficacy of GPT-4 over other fine-tuned models, measured using BERTScore and DialogRPT.  We hypothesize that several dataset characteristics, including sampling, representativen",
    "path": "papers/23/07/2307.04274.json",
    "total_tokens": 974,
    "translated_title": "评估大型语言模型在生成准确的教师回答中的有效性",
    "translated_abstract": "(Tack等人，2023年)在第18届创新使用NLP构建教育应用研讨会上组织了共享任务，即教育对话中教师语言的生成。本研究按照共享任务的结构，试图评估大型语言模型在向学生提供信息性和有益洞察力方面的生成能力，从而模拟知识渊博的教师的角色。为此，我们对几种基准生成模型进行了广泛的评估，包括GPT-4（少样本、上下文学习）、微调的GPT-2和微调的DialoGPT。此外，为了优化教学质量，我们使用强化学习对Flan-T5模型进行了微调。在教师-学生聊天室语料库子集上的实验结果表明，使用BERTScore和DialogRPT度量，GPT-4比其他微调模型更为有效。我们假设样本抽样和代表性等多个数据集特征可能影响生成模型的效果。",
    "tldr": "本研究评估了大型语言模型在生成准确的教师回答中的能力。实验结果表明，在教师-学生聊天室语料库子集上，GPT-4的效果优于其他模型。研究还指出样本抽样和代表性等数据集特征可能影响生成模型的效果。"
}