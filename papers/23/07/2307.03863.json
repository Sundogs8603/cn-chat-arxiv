{
    "title": "Memory-Immersed Collaborative Digitization for Area-Efficient Compute-in-Memory Deep Learning. (arXiv:2307.03863v1 [cs.AR])",
    "abstract": "This work discusses memory-immersed collaborative digitization among compute-in-memory (CiM) arrays to minimize the area overheads of a conventional analog-to-digital converter (ADC) for deep learning inference. Thereby, using the proposed scheme, significantly more CiM arrays can be accommodated within limited footprint designs to improve parallelism and minimize external memory accesses. Under the digitization scheme, CiM arrays exploit their parasitic bit lines to form a within-memory capacitive digital-to-analog converter (DAC) that facilitates area-efficient successive approximation (SA) digitization. CiM arrays collaborate where a proximal array digitizes the analog-domain product-sums when an array computes the scalar product of input and weights. We discuss various networking configurations among CiM arrays where Flash, SA, and their hybrid digitization steps can be efficiently implemented using the proposed memory-immersed scheme. The results are demonstrated using a 65 nm CMO",
    "link": "http://arxiv.org/abs/2307.03863",
    "context": "Title: Memory-Immersed Collaborative Digitization for Area-Efficient Compute-in-Memory Deep Learning. (arXiv:2307.03863v1 [cs.AR])\nAbstract: This work discusses memory-immersed collaborative digitization among compute-in-memory (CiM) arrays to minimize the area overheads of a conventional analog-to-digital converter (ADC) for deep learning inference. Thereby, using the proposed scheme, significantly more CiM arrays can be accommodated within limited footprint designs to improve parallelism and minimize external memory accesses. Under the digitization scheme, CiM arrays exploit their parasitic bit lines to form a within-memory capacitive digital-to-analog converter (DAC) that facilitates area-efficient successive approximation (SA) digitization. CiM arrays collaborate where a proximal array digitizes the analog-domain product-sums when an array computes the scalar product of input and weights. We discuss various networking configurations among CiM arrays where Flash, SA, and their hybrid digitization steps can be efficiently implemented using the proposed memory-immersed scheme. The results are demonstrated using a 65 nm CMO",
    "path": "papers/23/07/2307.03863.json",
    "total_tokens": 959,
    "translated_title": "基于内存的合作数字化用于面积高效的计算内存深度学习",
    "translated_abstract": "本论文讨论了基于内存的合作数字化在计算内存(CiM)阵列之间的应用，以最小化传统模拟数字转换器(ADC)在深度学习推理中的面积开销。通过使用提出的方案，可以在有限的尺寸设计中容纳更多的CiM阵列，以提高并行性并减少外部内存访问。在数字化方案下，CiM阵列利用其寄生比特线形成内存内的电容数字-模数转换器(DAC)，以实现面积高效的逐次逼近(SA)数字化。当一个阵列计算输入和权重的标量积时，CiM阵列协同工作，其中一个相邻的阵列进行模拟领域的乘积数的数字化。本文讨论了CiM阵列之间的各种网络配置，其中利用提出的内存内方案可以有效地实现Flash、SA和其混合数字化步骤。结果使用65纳米CMO进行了验证。",
    "tldr": "本论文提出了一种基于内存的合作数字化方案，用于减少深度学习推理中传统模拟数字转换器(ADC)的面积开销，提升并行性和减少外部内存访问。该方案通过在内存中形成内存内的数字-模数转换器(DAC)来实现面积高效的数字化，并且利用合作数字化来提高计算效率。",
    "en_tdlr": "This paper proposes a memory-immersed collaborative digitization scheme to reduce the area overheads of a conventional ADC in deep learning inference, improving parallelism and minimizing external memory accesses. The scheme utilizes within-memory capacitive DAC for efficient digitization and collaborative digitization for improved computation efficiency."
}