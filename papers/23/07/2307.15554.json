{
    "title": "'What are you referring to?' Evaluating the Ability of Multi-Modal Dialogue Models to Process Clarificational Exchanges. (arXiv:2307.15554v1 [cs.CL])",
    "abstract": "Referential ambiguities arise in dialogue when a referring expression does not uniquely identify the intended referent for the addressee. Addressees usually detect such ambiguities immediately and work with the speaker to repair it using meta-communicative, Clarificational Exchanges (CE): a Clarification Request (CR) and a response. Here, we argue that the ability to generate and respond to CRs imposes specific constraints on the architecture and objective functions of multi-modal, visually grounded dialogue models. We use the SIMMC 2.0 dataset to evaluate the ability of different state-of-the-art model architectures to process CEs, with a metric that probes the contextual updates that arise from them in the model. We find that language-based models are able to encode simple multi-modal semantic information and process some CEs, excelling with those related to the dialogue history, whilst multi-modal models can use additional learning objectives to obtain disentangled object representa",
    "link": "http://arxiv.org/abs/2307.15554",
    "context": "Title: 'What are you referring to?' Evaluating the Ability of Multi-Modal Dialogue Models to Process Clarificational Exchanges. (arXiv:2307.15554v1 [cs.CL])\nAbstract: Referential ambiguities arise in dialogue when a referring expression does not uniquely identify the intended referent for the addressee. Addressees usually detect such ambiguities immediately and work with the speaker to repair it using meta-communicative, Clarificational Exchanges (CE): a Clarification Request (CR) and a response. Here, we argue that the ability to generate and respond to CRs imposes specific constraints on the architecture and objective functions of multi-modal, visually grounded dialogue models. We use the SIMMC 2.0 dataset to evaluate the ability of different state-of-the-art model architectures to process CEs, with a metric that probes the contextual updates that arise from them in the model. We find that language-based models are able to encode simple multi-modal semantic information and process some CEs, excelling with those related to the dialogue history, whilst multi-modal models can use additional learning objectives to obtain disentangled object representa",
    "path": "papers/23/07/2307.15554.json",
    "total_tokens": 890,
    "translated_title": "“你在指什么？”评估多模态对话模型处理澄清交流的能力",
    "translated_abstract": "当一个指称表达无法确定唯一地确定发言者的意图时，对话中出现指称歧义。通常情况下，被寻址人会立即发现这种歧义，并与发言者一起通过元沟通澄清交流（CE）来修复。CE包括澄清请求（CR）和回应。本文认为，生成和回应CR对多模态且以视觉为基础的对话模型的架构和目标函数施加了特定的约束。我们使用SIMMC 2.0数据集评估了不同最先进模型架构处理CE的能力，并使用一个指标来探测模型中由CE引起的上下文更新。我们发现，基于语言的模型能够编码简单的多模态语义信息并处理一些CE，特别是与对话历史相关的CE。而多模态模型则可以使用额外的学习目标来获取分解的对象表示。",
    "tldr": "本研究评估了多模态对话模型处理澄清交流的能力，并发现基于语言的模型在处理与对话历史相关的澄清交流时表现出色，而多模态模型则能利用额外的学习目标获取分解的对象表示。",
    "en_tdlr": "This study evaluates the ability of multi-modal dialogue models to process clarificational exchanges, finding that language-based models excel at handling clarificational exchanges related to dialogue history, while multi-modal models can obtain disentangled object representations using additional learning objectives."
}