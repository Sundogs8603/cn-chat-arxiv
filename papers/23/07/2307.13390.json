{
    "title": "Counterfactual Explanation via Search in Gaussian Mixture Distributed Latent Space. (arXiv:2307.13390v1 [cs.LG])",
    "abstract": "Counterfactual Explanations (CEs) are an important tool in Algorithmic Recourse for addressing two questions: 1. What are the crucial factors that led to an automated prediction/decision? 2. How can these factors be changed to achieve a more favorable outcome from a user's perspective? Thus, guiding the user's interaction with AI systems by proposing easy-to-understand explanations and easy-to-attain feasible changes is essential for the trustworthy adoption and long-term acceptance of AI systems. In the literature, various methods have been proposed to generate CEs, and different quality measures have been suggested to evaluate these methods. However, the generation of CEs is usually computationally expensive, and the resulting suggestions are unrealistic and thus non-actionable. In this paper, we introduce a new method to generate CEs for a pre-trained binary classifier by first shaping the latent space of an autoencoder to be a mixture of Gaussian distributions. CEs are then generat",
    "link": "http://arxiv.org/abs/2307.13390",
    "context": "Title: Counterfactual Explanation via Search in Gaussian Mixture Distributed Latent Space. (arXiv:2307.13390v1 [cs.LG])\nAbstract: Counterfactual Explanations (CEs) are an important tool in Algorithmic Recourse for addressing two questions: 1. What are the crucial factors that led to an automated prediction/decision? 2. How can these factors be changed to achieve a more favorable outcome from a user's perspective? Thus, guiding the user's interaction with AI systems by proposing easy-to-understand explanations and easy-to-attain feasible changes is essential for the trustworthy adoption and long-term acceptance of AI systems. In the literature, various methods have been proposed to generate CEs, and different quality measures have been suggested to evaluate these methods. However, the generation of CEs is usually computationally expensive, and the resulting suggestions are unrealistic and thus non-actionable. In this paper, we introduce a new method to generate CEs for a pre-trained binary classifier by first shaping the latent space of an autoencoder to be a mixture of Gaussian distributions. CEs are then generat",
    "path": "papers/23/07/2307.13390.json",
    "total_tokens": 827,
    "translated_title": "通过高斯混合分布潜空间的搜索生成反事实解释",
    "translated_abstract": "反事实解释（CEs）是用于解决算法补救中的两个问题的重要工具：1. 是什么关键因素导致了自动预测/决策？2. 如何改变这些因素以从用户角度获得更有利的结果？因此，通过提供易于理解的解释和易于实现的可行变化来引导用户与AI系统的交互对于可信赖的采用和长期接受AI系统是至关重要的。在文献中，已经提出了各种方法来生成CEs，并建议使用不同的质量度量来评估这些方法。然而，CEs的生成通常需要大量计算，并且生成的建议是不切实际的，因此不可操作。在本文中，我们介绍了一种新的方法，通过首先将自编码器的潜空间形成为高斯分布的混合，为预先训练的二分类器生成CEs。",
    "tldr": "本文介绍了一种通过在自编码器的潜空间中进行高斯混合分布搜索来生成反事实解释的方法。",
    "en_tdlr": "This paper introduces a new method to generate counterfactual explanations by conducting a search in the Gaussian mixture distributed latent space of an autoencoder."
}