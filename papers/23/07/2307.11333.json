{
    "title": "Demystifying Local and Global Fairness Trade-offs in Federated Learning Using Partial Information Decomposition. (arXiv:2307.11333v1 [cs.LG])",
    "abstract": "In this paper, we present an information-theoretic perspective to group fairness trade-offs in federated learning (FL) with respect to sensitive attributes, such as gender, race, etc. Existing works mostly focus on either \\emph{global fairness} (overall disparity of the model across all clients) or \\emph{local fairness} (disparity of the model at each individual client), without always considering their trade-offs. There is a lack of understanding of the interplay between global and local fairness in FL, and if and when one implies the other. To address this gap, we leverage a body of work in information theory called partial information decomposition (PID) which first identifies three sources of unfairness in FL, namely, \\emph{Unique Disparity}, \\emph{Redundant Disparity}, and \\emph{Masked Disparity}. Using canonical examples, we demonstrate how these three disparities contribute to global and local fairness. This decomposition helps us derive fundamental limits and trade-offs between",
    "link": "http://arxiv.org/abs/2307.11333",
    "context": "Title: Demystifying Local and Global Fairness Trade-offs in Federated Learning Using Partial Information Decomposition. (arXiv:2307.11333v1 [cs.LG])\nAbstract: In this paper, we present an information-theoretic perspective to group fairness trade-offs in federated learning (FL) with respect to sensitive attributes, such as gender, race, etc. Existing works mostly focus on either \\emph{global fairness} (overall disparity of the model across all clients) or \\emph{local fairness} (disparity of the model at each individual client), without always considering their trade-offs. There is a lack of understanding of the interplay between global and local fairness in FL, and if and when one implies the other. To address this gap, we leverage a body of work in information theory called partial information decomposition (PID) which first identifies three sources of unfairness in FL, namely, \\emph{Unique Disparity}, \\emph{Redundant Disparity}, and \\emph{Masked Disparity}. Using canonical examples, we demonstrate how these three disparities contribute to global and local fairness. This decomposition helps us derive fundamental limits and trade-offs between",
    "path": "papers/23/07/2307.11333.json",
    "total_tokens": 928,
    "translated_title": "揭示联邦学习中局部和全局公平性权衡的信息分解方法",
    "translated_abstract": "本文从信息论的角度，研究了在联邦学习中关于敏感属性（如性别、种族等）的群体公平性权衡问题。现有工作主要关注“全局公平性”（模型在所有客户端上的不平等程度）或“局部公平性”（模型在每个个体客户端上的不平等程度），而并不总是考虑它们之间的权衡。对于联邦学习中的全局公平性和局部公平性之间的相互作用，以及一个是否暗示另一个，我们缺乏理解。为了弥补这一空白，我们利用了信息论中的部分信息分解（PID）方法，首先确定了联邦学习中三种不公平来源，即“唯一不平等性”、“冗余不平等性”和“掩盖不平等性”。通过典型案例，我们演示了这三种不平等性如何影响全局和局部公平性。这种分解帮助我们推导出全局和局部公平性之间的基本限制和权衡。",
    "tldr": "本文利用信息论的部分信息分解（PID）方法，研究了在联邦学习中关于敏感属性的群体公平性权衡问题。通过分解发现了三种不公平来源，分别是唯一不平等性、冗余不平等性和掩盖不平等性，揭示了全局和局部公平性之间的基本限制和权衡。"
}