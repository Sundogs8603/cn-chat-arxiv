{
    "title": "Rhythm Modeling for Voice Conversion. (arXiv:2307.06040v1 [eess.AS])",
    "abstract": "Voice conversion aims to transform source speech into a different target voice. However, typical voice conversion systems do not account for rhythm, which is an important factor in the perception of speaker identity. To bridge this gap, we introduce Urhythmic-an unsupervised method for rhythm conversion that does not require parallel data or text transcriptions. Using self-supervised representations, we first divide source audio into segments approximating sonorants, obstruents, and silences. Then we model rhythm by estimating speaking rate or the duration distribution of each segment type. Finally, we match the target speaking rate or rhythm by time-stretching the speech segments. Experiments show that Urhythmic outperforms existing unsupervised methods in terms of quality and prosody. Code and checkpoints: https://github.com/bshall/urhythmic. Audio demo page: https://ubisoft-laforge.github.io/speech/urhythmic.",
    "link": "http://arxiv.org/abs/2307.06040",
    "context": "Title: Rhythm Modeling for Voice Conversion. (arXiv:2307.06040v1 [eess.AS])\nAbstract: Voice conversion aims to transform source speech into a different target voice. However, typical voice conversion systems do not account for rhythm, which is an important factor in the perception of speaker identity. To bridge this gap, we introduce Urhythmic-an unsupervised method for rhythm conversion that does not require parallel data or text transcriptions. Using self-supervised representations, we first divide source audio into segments approximating sonorants, obstruents, and silences. Then we model rhythm by estimating speaking rate or the duration distribution of each segment type. Finally, we match the target speaking rate or rhythm by time-stretching the speech segments. Experiments show that Urhythmic outperforms existing unsupervised methods in terms of quality and prosody. Code and checkpoints: https://github.com/bshall/urhythmic. Audio demo page: https://ubisoft-laforge.github.io/speech/urhythmic.",
    "path": "papers/23/07/2307.06040.json",
    "total_tokens": 824,
    "translated_title": "声音转换的节奏建模",
    "translated_abstract": "声音转换旨在将源语音转换为不同的目标声音。然而，典型的声音转换系统没有考虑节奏，而节奏是对说话人身份感知的重要因素。为了弥补这个差距，我们引入了一种无监督的节奏转换方法Urhythmic，它不需要平行数据或文本转录。使用自监督表示，我们首先将源音频分割成近似鼻音、障音和静音的片段。然后，我们通过估计每个片段类型的说话速率或持续时间分布来建模节奏。最后，我们通过对语音片段进行时间拉伸来匹配目标说话速率或节奏。实验证明，在质量和语调方面，Urhythmic优于现有的无监督方法。",
    "tldr": "本论文提出了一种名为Urhythmic的无监督节奏转换方法，通过对源语音进行分割和时间拉伸，实现了声音转换中的节奏匹配，实验结果表明该方法在质量和语调方面优于现有方法。",
    "en_tdlr": "This paper introduces an unsupervised rhythm conversion method called Urhythmic, which matches the rhythm in voice conversion by segmenting and time-stretching the source speech. Experimental results demonstrate that this method outperforms existing approaches in terms of quality and prosody."
}