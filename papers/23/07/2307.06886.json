{
    "title": "Min-Max Optimization under Delays. (arXiv:2307.06886v1 [cs.LG])",
    "abstract": "Delays and asynchrony are inevitable in large-scale machine-learning problems where communication plays a key role. As such, several works have extensively analyzed stochastic optimization with delayed gradients. However, as far as we are aware, no analogous theory is available for min-max optimization, a topic that has gained recent popularity due to applications in adversarial robustness, game theory, and reinforcement learning. Motivated by this gap, we examine the performance of standard min-max optimization algorithms with delayed gradient updates. First, we show (empirically) that even small delays can cause prominent algorithms like Extra-gradient (\\texttt{EG}) to diverge on simple instances for which \\texttt{EG} guarantees convergence in the absence of delays. Our empirical study thus suggests the need for a careful analysis of delayed versions of min-max optimization algorithms. Accordingly, under suitable technical assumptions, we prove that Gradient Descent-Ascent (\\texttt{G",
    "link": "http://arxiv.org/abs/2307.06886",
    "context": "Title: Min-Max Optimization under Delays. (arXiv:2307.06886v1 [cs.LG])\nAbstract: Delays and asynchrony are inevitable in large-scale machine-learning problems where communication plays a key role. As such, several works have extensively analyzed stochastic optimization with delayed gradients. However, as far as we are aware, no analogous theory is available for min-max optimization, a topic that has gained recent popularity due to applications in adversarial robustness, game theory, and reinforcement learning. Motivated by this gap, we examine the performance of standard min-max optimization algorithms with delayed gradient updates. First, we show (empirically) that even small delays can cause prominent algorithms like Extra-gradient (\\texttt{EG}) to diverge on simple instances for which \\texttt{EG} guarantees convergence in the absence of delays. Our empirical study thus suggests the need for a careful analysis of delayed versions of min-max optimization algorithms. Accordingly, under suitable technical assumptions, we prove that Gradient Descent-Ascent (\\texttt{G",
    "path": "papers/23/07/2307.06886.json",
    "total_tokens": 1022,
    "translated_title": "Min-Max优化在延迟下的研究",
    "translated_abstract": "在通信起重要作用的大规模机器学习问题中，延迟和异步是不可避免的。因此，一些研究团队广泛分析了具有延迟梯度的随机优化问题。但据我们所知，尚无类似的理论可用于min-max优化，这个话题由于在对抗鲁棒性、博弈论和强化学习中的应用而越来越受关注。针对这一差距，我们对带有延迟梯度更新的标准min-max优化算法的性能进行了研究。首先，我们（经验性地）展示了即使是小的延迟也可能导致像Extra-gradient (EG) 这样的杰出算法在简单实例上发散，而在没有延迟的情况下EG可以保证收敛。因此，我们的经验研究表明有必要对延迟版本的min-max优化算法进行仔细分析。相应地，在适当的技术假设下，我们证明了梯度下降 - 上升 (GDA)算法在延迟情况下的收敛性和性能。",
    "tldr": "在大规模机器学习中，研究了min-max优化在延迟下的性能。对于简单实例，即使是小的延迟也可能导致Extra-gradient算法发散，因此需要对延迟版本的min-max优化算法进行仔细分析。为此，我们证明了在适当的技术假设下，梯度下降-上升算法在延迟情况下的收敛性和性能。",
    "en_tdlr": "This paper investigates the performance of min-max optimization under delays in large-scale machine learning problems. The study shows that even small delays can cause prominent algorithms like Extra-gradient to diverge on simple instances, highlighting the importance of carefully analyzing delayed versions of min-max optimization algorithms. Furthermore, the paper proves the convergence and performance of the Gradient Descent-Ascent algorithm under suitable technical assumptions."
}