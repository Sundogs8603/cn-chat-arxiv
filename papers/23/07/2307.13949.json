{
    "title": "How Does Diffusion Influence Pretrained Language Models on Out-of-Distribution Data?. (arXiv:2307.13949v1 [cs.CL])",
    "abstract": "Transformer-based pretrained language models (PLMs) have achieved great success in modern NLP. An important advantage of PLMs is good out-of-distribution (OOD) robustness. Recently, diffusion models have attracted a lot of work to apply diffusion to PLMs. It remains under-explored how diffusion influences PLMs on OOD data. The core of diffusion models is a forward diffusion process which gradually applies Gaussian noise to inputs, and a reverse denoising process which removes noise. The noised input reconstruction is a fundamental ability of diffusion models. We directly analyze OOD robustness by measuring the reconstruction loss, including testing the abilities to reconstruct OOD data, and to detect OOD samples. Experiments are conducted by analyzing different training parameters and data statistical features on eight datasets. It shows that finetuning PLMs with diffusion degrades the reconstruction ability on OOD data. The comparison also shows that diffusion models can effectively d",
    "link": "http://arxiv.org/abs/2307.13949",
    "context": "Title: How Does Diffusion Influence Pretrained Language Models on Out-of-Distribution Data?. (arXiv:2307.13949v1 [cs.CL])\nAbstract: Transformer-based pretrained language models (PLMs) have achieved great success in modern NLP. An important advantage of PLMs is good out-of-distribution (OOD) robustness. Recently, diffusion models have attracted a lot of work to apply diffusion to PLMs. It remains under-explored how diffusion influences PLMs on OOD data. The core of diffusion models is a forward diffusion process which gradually applies Gaussian noise to inputs, and a reverse denoising process which removes noise. The noised input reconstruction is a fundamental ability of diffusion models. We directly analyze OOD robustness by measuring the reconstruction loss, including testing the abilities to reconstruct OOD data, and to detect OOD samples. Experiments are conducted by analyzing different training parameters and data statistical features on eight datasets. It shows that finetuning PLMs with diffusion degrades the reconstruction ability on OOD data. The comparison also shows that diffusion models can effectively d",
    "path": "papers/23/07/2307.13949.json",
    "total_tokens": 1000,
    "translated_title": "扩散如何影响预训练语言模型在超出分布数据上的表现？",
    "translated_abstract": "基于Transformer的预训练语言模型(PLMs)在现代自然语言处理(NLP)领域取得了巨大成功。PLMs的一个重要优势是良好的超出分布(OOD)鲁棒性。最近，扩散模型吸引了很多研究将扩散应用于PLMs。然而，扩散对PLMs在OOD数据上的影响仍未得到充分探讨。扩散模型的核心是一个前向扩散过程，逐渐对输入应用高斯噪声，并且一个反向去噪过程，用于去除噪声。噪声输入重建是扩散模型的基本能力。我们通过测量重建损失直接分析OOD鲁棒性，包括测试重建OOD数据和检测OOD样本的能力。通过分析不同的训练参数和数据统计特征在八个数据集上进行了实验。结果显示，使用扩散微调PLMs会降低在OOD数据上的重建能力。比较还表明，扩散模型可以有效地提高OOD样本的重构能力和检测能力。",
    "tldr": "这项研究探讨了扩散模型对预训练语言模型(PLMs)在超出分布(OOD)数据上的影响。研究发现，在OOD数据上使用扩散微调PLMs会降低重建能力。比较实验还表明，扩散模型能够有效提高OOD样本的重构能力和检测能力。",
    "en_tdlr": "This study examines the impact of diffusion models on pretrained language models (PLMs) on out-of-distribution (OOD) data. The research found that fine-tuning PLMs with diffusion reduces their ability to reconstruct OOD data. Comparative experiments also demonstrated that diffusion models effectively improve the reconstruction and detection capabilities for OOD samples."
}