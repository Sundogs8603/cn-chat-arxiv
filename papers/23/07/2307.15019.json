{
    "title": "Self-Supervised Graph Transformer for Deepfake Detection. (arXiv:2307.15019v1 [cs.CV])",
    "abstract": "Deepfake detection methods have shown promising results in recognizing forgeries within a given dataset, where training and testing take place on the in-distribution dataset. However, their performance deteriorates significantly when presented with unseen samples. As a result, a reliable deepfake detection system must remain impartial to forgery types, appearance, and quality for guaranteed generalizable detection performance. Despite various attempts to enhance cross-dataset generalization, the problem remains challenging, particularly when testing against common post-processing perturbations, such as video compression or blur. Hence, this study introduces a deepfake detection framework, leveraging a self-supervised pre-training model that delivers exceptional generalization ability, withstanding common corruptions and enabling feature explainability. The framework comprises three key components: a feature extractor based on vision Transformer architecture that is pre-trained via self",
    "link": "http://arxiv.org/abs/2307.15019",
    "context": "Title: Self-Supervised Graph Transformer for Deepfake Detection. (arXiv:2307.15019v1 [cs.CV])\nAbstract: Deepfake detection methods have shown promising results in recognizing forgeries within a given dataset, where training and testing take place on the in-distribution dataset. However, their performance deteriorates significantly when presented with unseen samples. As a result, a reliable deepfake detection system must remain impartial to forgery types, appearance, and quality for guaranteed generalizable detection performance. Despite various attempts to enhance cross-dataset generalization, the problem remains challenging, particularly when testing against common post-processing perturbations, such as video compression or blur. Hence, this study introduces a deepfake detection framework, leveraging a self-supervised pre-training model that delivers exceptional generalization ability, withstanding common corruptions and enabling feature explainability. The framework comprises three key components: a feature extractor based on vision Transformer architecture that is pre-trained via self",
    "path": "papers/23/07/2307.15019.json",
    "total_tokens": 871,
    "translated_title": "自监督图变换器用于深度伪造检测",
    "translated_abstract": "深度伪造检测方法在识别给定数据集中的伪造物方面取得了有希望的结果，其中训练和测试在内部分发的数据集上进行。然而，当面对未知样本时，它们的性能显著下降。因此，可靠的深度伪造检测系统必须对伪造类型、外观和质量保持公正，以确保可广泛应用的检测性能。尽管有各种尝试提高跨数据集泛化能力，但问题仍然具有挑战性，特别是当测试常见的后处理扰动时，如视频压缩或模糊。因此，本研究引入了一个深度伪造检测框架，利用自监督预训练模型，具有出色的泛化能力，可以承受常见的破坏，并实现特征解释性。该框架包括三个关键组件：基于视觉变换器架构的特征提取器，通过自监督方式进行预训练",
    "tldr": "这篇论文介绍了一种利用自监督预训练模型的深度伪造检测框架，具有出色的泛化能力，可以应对常见的破坏，并实现特征解释性。"
}