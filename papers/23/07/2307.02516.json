{
    "title": "Exploring new ways: Enforcing representational dissimilarity to learn new features and reduce error consistency. (arXiv:2307.02516v1 [cs.LG])",
    "abstract": "Independently trained machine learning models tend to learn similar features. Given an ensemble of independently trained models, this results in correlated predictions and common failure modes. Previous attempts focusing on decorrelation of output predictions or logits yielded mixed results, particularly due to their reduction in model accuracy caused by conflicting optimization objectives. In this paper, we propose the novel idea of utilizing methods of the representational similarity field to promote dissimilarity during training instead of measuring similarity of trained models. To this end, we promote intermediate representations to be dissimilar at different depths between architectures, with the goal of learning robust ensembles with disjoint failure modes. We show that highly dissimilar intermediate representations result in less correlated output predictions and slightly lower error consistency, resulting in higher ensemble accuracy. With this, we shine first light on the conne",
    "link": "http://arxiv.org/abs/2307.02516",
    "context": "Title: Exploring new ways: Enforcing representational dissimilarity to learn new features and reduce error consistency. (arXiv:2307.02516v1 [cs.LG])\nAbstract: Independently trained machine learning models tend to learn similar features. Given an ensemble of independently trained models, this results in correlated predictions and common failure modes. Previous attempts focusing on decorrelation of output predictions or logits yielded mixed results, particularly due to their reduction in model accuracy caused by conflicting optimization objectives. In this paper, we propose the novel idea of utilizing methods of the representational similarity field to promote dissimilarity during training instead of measuring similarity of trained models. To this end, we promote intermediate representations to be dissimilar at different depths between architectures, with the goal of learning robust ensembles with disjoint failure modes. We show that highly dissimilar intermediate representations result in less correlated output predictions and slightly lower error consistency, resulting in higher ensemble accuracy. With this, we shine first light on the conne",
    "path": "papers/23/07/2307.02516.json",
    "total_tokens": 921,
    "translated_title": "探索新的方法：强化表征差异以学习新特征并降低错误一致性",
    "translated_abstract": "独立训练的机器学习模型往往学习相似的特征。在一组独立训练的模型中，这导致预测相关性和常见的失败模式。以往的尝试着重于减小输出预测或logits的相关性，结果产生了不一致的优化目标，从而降低了模型准确性。在本文中，我们提出了一种新颖的思想，即利用表征相似性领域的方法，在训练过程中促进差异性，而不是衡量训练模型的相似性。为此，我们促进了架构之间不同深度的中间表示的差异性，并旨在学习具有不同失败模式的强大集合。我们表明，高度差异的中间表示导致更少相关的输出预测和稍微较低的错误一致性，从而提高了整体准确性。通过这样做，我们首次揭示了连接的新可能性。",
    "tldr": "本文提出了一种新方法，利用表征差异性来降低模型的相关性和常见失败模式。通过使架构之间不同深度的中间表示具有差异性，以学习具有不同失败模式的强大集合，结果表明，这种方法可以提高集合的准确性。"
}