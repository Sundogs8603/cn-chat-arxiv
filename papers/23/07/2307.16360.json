{
    "title": "Probabilistically robust conformal prediction. (arXiv:2307.16360v1 [cs.LG])",
    "abstract": "Conformal prediction (CP) is a framework to quantify uncertainty of machine learning classifiers including deep neural networks. Given a testing example and a trained classifier, CP produces a prediction set of candidate labels with a user-specified coverage (i.e., true class label is contained with high probability). Almost all the existing work on CP assumes clean testing data and there is not much known about the robustness of CP algorithms w.r.t natural/adversarial perturbations to testing examples. This paper studies the problem of probabilistically robust conformal prediction (PRCP) which ensures robustness to most perturbations around clean input examples. PRCP generalizes the standard CP (cannot handle perturbations) and adversarially robust CP (ensures robustness w.r.t worst-case perturbations) to achieve better trade-offs between nominal performance and robustness. We propose a novel adaptive PRCP (aPRCP) algorithm to achieve probabilistically robust coverage. The key idea be",
    "link": "http://arxiv.org/abs/2307.16360",
    "context": "Title: Probabilistically robust conformal prediction. (arXiv:2307.16360v1 [cs.LG])\nAbstract: Conformal prediction (CP) is a framework to quantify uncertainty of machine learning classifiers including deep neural networks. Given a testing example and a trained classifier, CP produces a prediction set of candidate labels with a user-specified coverage (i.e., true class label is contained with high probability). Almost all the existing work on CP assumes clean testing data and there is not much known about the robustness of CP algorithms w.r.t natural/adversarial perturbations to testing examples. This paper studies the problem of probabilistically robust conformal prediction (PRCP) which ensures robustness to most perturbations around clean input examples. PRCP generalizes the standard CP (cannot handle perturbations) and adversarially robust CP (ensures robustness w.r.t worst-case perturbations) to achieve better trade-offs between nominal performance and robustness. We propose a novel adaptive PRCP (aPRCP) algorithm to achieve probabilistically robust coverage. The key idea be",
    "path": "papers/23/07/2307.16360.json",
    "total_tokens": 922,
    "translated_title": "概率鲁棒性的符合性预测",
    "translated_abstract": "符合性预测（CP）是一种量化机器学习分类器不确定性的框架，包括深度神经网络。给定一个测试示例和一个训练好的分类器，CP会产生一个预测集，其中包含了候选标签，并且具有用户指定的覆盖率（即真实类标签以很高的概率包含在内）。几乎所有现有关于CP的工作都假设测试数据是干净的，并且对于与测试示例的自然/敌对扰动对CP算法的鲁棒性没有太多了解。本文研究了概率鲁棒性的符合性预测（PRCP）问题，它确保对干净输入示例的大多数扰动具有鲁棒性。PRCP推广了标准CP（无法处理扰动）和对抗鲁棒CP（确保针对最坏情况的扰动具有鲁棒性）之间的更好平衡nominal性能和鲁棒性。我们提出了一种新颖的自适应PRCP（aPRCP）算法来实现概率鲁棒的覆盖。",
    "tldr": "本文研究了概率鲁棒性的符合性预测（PRCP）问题，通过提出aPRCP算法，实现了对干净输入示例的大多数扰动具有鲁棒性的预测。",
    "en_tdlr": "This paper studies the problem of probabilistically robust conformal prediction (PRCP), and proposes the aPRCP algorithm to achieve prediction robustness against most perturbations around clean input examples."
}