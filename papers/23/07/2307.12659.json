{
    "title": "A Model for Every User and Budget: Label-Free and Personalized Mixed-Precision Quantization",
    "abstract": "Recent advancement in Automatic Speech Recognition (ASR) has produced large AI models, which become impractical for deployment in mobile devices. Model quantization is effective to produce compressed general-purpose models, however such models may only be deployed to a restricted sub-domain of interest. We show that ASR models can be personalized during quantization while relying on just a small set of unlabelled samples from the target domain. To this end, we propose myQASR, a mixed-precision quantization method that generates tailored quantization schemes for diverse users under any memory requirement with no fine-tuning. myQASR automatically evaluates the quantization sensitivity of network layers by analysing the full-precision activation values. We are then able to generate a personalised mixed-precision quantization scheme for any pre-determined memory budget. Results for large-scale ASR models show how myQASR improves performance for specific genders, languages, and speakers.",
    "link": "https://arxiv.org/abs/2307.12659",
    "context": "Title: A Model for Every User and Budget: Label-Free and Personalized Mixed-Precision Quantization\nAbstract: Recent advancement in Automatic Speech Recognition (ASR) has produced large AI models, which become impractical for deployment in mobile devices. Model quantization is effective to produce compressed general-purpose models, however such models may only be deployed to a restricted sub-domain of interest. We show that ASR models can be personalized during quantization while relying on just a small set of unlabelled samples from the target domain. To this end, we propose myQASR, a mixed-precision quantization method that generates tailored quantization schemes for diverse users under any memory requirement with no fine-tuning. myQASR automatically evaluates the quantization sensitivity of network layers by analysing the full-precision activation values. We are then able to generate a personalised mixed-precision quantization scheme for any pre-determined memory budget. Results for large-scale ASR models show how myQASR improves performance for specific genders, languages, and speakers.",
    "path": "papers/23/07/2307.12659.json",
    "total_tokens": 890,
    "translated_title": "适用于每个用户和预算的模型：无标签和个性化混合精度量化",
    "translated_abstract": "最近在自动语音识别（ASR）方面取得了进展，产生了大型AI模型，在移动设备上部署变得不切实际。模型量化是一种有效的方法，可以产生压缩的通用模型，然而，这样的模型可能只能在有限制的感兴趣子领域中部署。我们展示了在量化过程中如何依赖于目标领域的少量未标记样本来个性化ASR模型。为此，我们提出了myQASR，一种混合精度量化方法，它可以根据任何内存需求生成针对不同用户的量化方案，无需微调。myQASR通过分析全精度激活值来自动评估网络层次的量化敏感性，从而能够为任何预定的内存预算生成个性化的混合精度量化方案。大规模ASR模型的结果显示了myQASR如何提高特定性别、语言和说话者的性能。",
    "tldr": "该论文提出了一种无标签和个性化混合精度量化方法，可以根据用户需求和内存预算生成个性化的量化方案，针对大规模ASR模型，能够提高特定性别、语言和说话者的性能。"
}