{
    "title": "EgoAdapt: A multi-stream evaluation study of adaptation to real-world egocentric user video. (arXiv:2307.05784v1 [cs.CV])",
    "abstract": "In egocentric action recognition a single population model is typically trained and subsequently embodied on a head-mounted device, such as an augmented reality headset. While this model remains static for new users and environments, we introduce an adaptive paradigm of two phases, where after pretraining a population model, the model adapts on-device and online to the user's experience. This setting is highly challenging due to the change from population to user domain and the distribution shifts in the user's data stream. Coping with the latter in-stream distribution shifts is the focus of continual learning, where progress has been rooted in controlled benchmarks but challenges faced in real-world applications often remain unaddressed. We introduce EgoAdapt, a benchmark for real-world egocentric action recognition that facilitates our two-phased adaptive paradigm, and real-world challenges naturally occur in the egocentric video streams from Ego4d, such as long-tailed action distrib",
    "link": "http://arxiv.org/abs/2307.05784",
    "context": "Title: EgoAdapt: A multi-stream evaluation study of adaptation to real-world egocentric user video. (arXiv:2307.05784v1 [cs.CV])\nAbstract: In egocentric action recognition a single population model is typically trained and subsequently embodied on a head-mounted device, such as an augmented reality headset. While this model remains static for new users and environments, we introduce an adaptive paradigm of two phases, where after pretraining a population model, the model adapts on-device and online to the user's experience. This setting is highly challenging due to the change from population to user domain and the distribution shifts in the user's data stream. Coping with the latter in-stream distribution shifts is the focus of continual learning, where progress has been rooted in controlled benchmarks but challenges faced in real-world applications often remain unaddressed. We introduce EgoAdapt, a benchmark for real-world egocentric action recognition that facilitates our two-phased adaptive paradigm, and real-world challenges naturally occur in the egocentric video streams from Ego4d, such as long-tailed action distrib",
    "path": "papers/23/07/2307.05784.json",
    "total_tokens": 944,
    "translated_title": "EgoAdapt：适应真实世界自我中心用户视频的多流评估研究",
    "translated_abstract": "在自我中心动作识别中，通常会训练一个单一的种群模型，并在头戴设备（如增强现实头盔）上进行实验。然而，这个模型对于新用户和环境来说是静态的，我们引入了一个自适应的两阶段范例，即在预训练种群模型后，模型根据用户的经验进行设备内和在线的适应。这个设置非常具有挑战性，因为它从种群领域转变为用户领域，并且用户数据流中存在分布的转变。应对后者中在流量中的分布转移是持续学习的重点，而持续学习的进展主要是在受控基准上的，然而在真实世界的应用中面临的挑战往往没有得到解决。我们引入了EgoAdapt，这是一个用于真实世界自我中心动作识别的基准，可以促进我们的两阶段自适应范例，并且自我中心视频流中自然发生的真实世界挑战，如长尾动作分布。",
    "tldr": "EgoAdapt是一个用于真实世界自我中心动作识别的基准，通过引入自适应范例并解决流数据中的分布转移挑战，可以使模型根据用户的实际需求进行自适应。",
    "en_tdlr": "EgoAdapt is a benchmark for real-world egocentric action recognition that introduces an adaptive paradigm to tackle the challenges of distribution shifts in the user's data stream. It enables the model to adapt to user needs based on their actual experiences."
}