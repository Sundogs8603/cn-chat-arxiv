{
    "title": "R-Cut: Enhancing Explainability in Vision Transformers with Relationship Weighted Out and Cut. (arXiv:2307.09050v1 [cs.CV])",
    "abstract": "Transformer-based models have gained popularity in the field of natural language processing (NLP) and are extensively utilized in computer vision tasks and multi-modal models such as GPT4. This paper presents a novel method to enhance the explainability of Transformer-based image classification models. Our method aims to improve trust in classification results and empower users to gain a deeper understanding of the model for downstream tasks by providing visualizations of class-specific maps. We introduce two modules: the ``Relationship Weighted Out\" and the ``Cut\" modules. The ``Relationship Weighted Out\" module focuses on extracting class-specific information from intermediate layers, enabling us to highlight relevant features. Additionally, the ``Cut\" module performs fine-grained feature decomposition, taking into account factors such as position, texture, and color. By integrating these modules, we generate dense class-specific visual explainability maps. We validate our method wit",
    "link": "http://arxiv.org/abs/2307.09050",
    "context": "Title: R-Cut: Enhancing Explainability in Vision Transformers with Relationship Weighted Out and Cut. (arXiv:2307.09050v1 [cs.CV])\nAbstract: Transformer-based models have gained popularity in the field of natural language processing (NLP) and are extensively utilized in computer vision tasks and multi-modal models such as GPT4. This paper presents a novel method to enhance the explainability of Transformer-based image classification models. Our method aims to improve trust in classification results and empower users to gain a deeper understanding of the model for downstream tasks by providing visualizations of class-specific maps. We introduce two modules: the ``Relationship Weighted Out\" and the ``Cut\" modules. The ``Relationship Weighted Out\" module focuses on extracting class-specific information from intermediate layers, enabling us to highlight relevant features. Additionally, the ``Cut\" module performs fine-grained feature decomposition, taking into account factors such as position, texture, and color. By integrating these modules, we generate dense class-specific visual explainability maps. We validate our method wit",
    "path": "papers/23/07/2307.09050.json",
    "total_tokens": 832,
    "translated_title": "R-Cut: 使用加权输出和剪切增强Transformer视觉模型的可解释性",
    "translated_abstract": "基于Transformer的模型在自然语言处理领域（NLP）中广受欢迎，被广泛应用于计算机视觉任务和GPT4等多模态模型中。本文提出了一种增强Transformer视觉分类模型可解释性的新方法。我们的方法旨在提高分类结果的可信度，并通过提供类别特定的可视化地图，使用户深入了解模型以进行后续任务。我们引入了两个模块：``加权输出关系\"和``剪切\"模块。``加权输出关系\"模块专注于从中间层提取类别特定信息，使我们能够突出相关特征。此外，``剪切\"模块对特征进行精细的分解，考虑位置、纹理和颜色等因素。通过整合这些模块，我们生成密集的类别特定可解释性地图。我们使用实验证实了我们的方法。",
    "tldr": "本文提出了一种增强Transformer视觉分类模型可解释性的方法，通过加权输出和剪切两个模块，生成密集的类别特定可解释性地图。",
    "en_tdlr": "This paper presents a method to enhance the explainability of Transformer-based image classification models by using the Relationship Weighted Out and Cut modules to generate dense class-specific visual explainability maps."
}