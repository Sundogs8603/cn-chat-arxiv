{
    "title": "Towards A Unified Agent with Foundation Models. (arXiv:2307.09668v1 [cs.RO])",
    "abstract": "Language Models and Vision Language Models have recently demonstrated unprecedented capabilities in terms of understanding human intentions, reasoning, scene understanding, and planning-like behaviour, in text form, among many others. In this work, we investigate how to embed and leverage such abilities in Reinforcement Learning (RL) agents. We design a framework that uses language as the core reasoning tool, exploring how this enables an agent to tackle a series of fundamental RL challenges, such as efficient exploration, reusing experience data, scheduling skills, and learning from observations, which traditionally require separate, vertically designed algorithms. We test our method on a sparse-reward simulated robotic manipulation environment, where a robot needs to stack a set of objects. We demonstrate substantial performance improvements over baselines in exploration efficiency and ability to reuse data from offline datasets, and illustrate how to reuse learned skills to solve no",
    "link": "http://arxiv.org/abs/2307.09668",
    "context": "Title: Towards A Unified Agent with Foundation Models. (arXiv:2307.09668v1 [cs.RO])\nAbstract: Language Models and Vision Language Models have recently demonstrated unprecedented capabilities in terms of understanding human intentions, reasoning, scene understanding, and planning-like behaviour, in text form, among many others. In this work, we investigate how to embed and leverage such abilities in Reinforcement Learning (RL) agents. We design a framework that uses language as the core reasoning tool, exploring how this enables an agent to tackle a series of fundamental RL challenges, such as efficient exploration, reusing experience data, scheduling skills, and learning from observations, which traditionally require separate, vertically designed algorithms. We test our method on a sparse-reward simulated robotic manipulation environment, where a robot needs to stack a set of objects. We demonstrate substantial performance improvements over baselines in exploration efficiency and ability to reuse data from offline datasets, and illustrate how to reuse learned skills to solve no",
    "path": "papers/23/07/2307.09668.json",
    "total_tokens": 946,
    "translated_title": "迈向具有基础模型的统一智能体",
    "translated_abstract": "最近，语言模型和视觉语言模型在理解人类意图、推理、场景理解和规划行为等方面展示了前所未有的能力。在这项工作中，我们探讨了如何将这些能力嵌入和利用在强化学习（RL）智能体中。我们设计了一个以语言作为核心推理工具的框架，探索了这如何使智能体能够应对一系列基础RL挑战，如高效探索、复用经验数据、调度技能和从观察中学习，这些传统上需要单独设计的垂直算法。我们在稀疏奖励的模拟机器人操作环境中测试了我们的方法，其中机器人需要堆叠一组物体。我们展示了在探索效率和能够从离线数据集中复用数据方面与基线方法相比的显著性能提升，并且展示了如何通过复用学到的技能解决新任务。",
    "tldr": "本文研究如何在强化学习智能体中嵌入和利用语言模型和视觉语言模型的能力，设计了一个以语言为核心推理工具的框架，并在稀疏奖励的机器人操作环境中测试了该方法。结果显示，该方法在探索效率和数据复用方面具有显著性能提升，并展示了如何通过复用学到的技能解决新任务。"
}