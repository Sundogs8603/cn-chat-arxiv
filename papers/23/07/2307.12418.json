{
    "title": "HateModerate: Testing Hate Speech Detectors against Content Moderation Policies",
    "abstract": "arXiv:2307.12418v2 Announce Type: replace-cross  Abstract: To protect users from massive hateful content, existing works studied automated hate speech detection. Despite the existing efforts, one question remains: do automated hate speech detectors conform to social media content policies? A platform's content policies are a checklist of content moderated by the social media platform. Because content moderation rules are often uniquely defined, existing hate speech datasets cannot directly answer this question.   This work seeks to answer this question by creating HateModerate, a dataset for testing the behaviors of automated content moderators against content policies. First, we engage 28 annotators and GPT in a six-step annotation process, resulting in a list of hateful and non-hateful test suites matching each of Facebook's 41 hate speech policies. Second, we test the performance of state-of-the-art hate speech detectors against HateModerate, revealing substantial failures these mod",
    "link": "https://arxiv.org/abs/2307.12418",
    "context": "Title: HateModerate: Testing Hate Speech Detectors against Content Moderation Policies\nAbstract: arXiv:2307.12418v2 Announce Type: replace-cross  Abstract: To protect users from massive hateful content, existing works studied automated hate speech detection. Despite the existing efforts, one question remains: do automated hate speech detectors conform to social media content policies? A platform's content policies are a checklist of content moderated by the social media platform. Because content moderation rules are often uniquely defined, existing hate speech datasets cannot directly answer this question.   This work seeks to answer this question by creating HateModerate, a dataset for testing the behaviors of automated content moderators against content policies. First, we engage 28 annotators and GPT in a six-step annotation process, resulting in a list of hateful and non-hateful test suites matching each of Facebook's 41 hate speech policies. Second, we test the performance of state-of-the-art hate speech detectors against HateModerate, revealing substantial failures these mod",
    "path": "papers/23/07/2307.12418.json",
    "total_tokens": 846,
    "translated_title": "HateModerate：针对内容审查政策测试仇恨言论检测器",
    "translated_abstract": "为了保护用户免受大量仇恨内容的侵害，现有研究关注自动化仇恨言论检测。尽管已经做出努力，但仍有一个问题：自动化仇恨言论检测器是否符合社交媒体内容政策？平台的内容政策是社交媒体平台审查的内容清单。由于内容审查规则通常是独特定义的，现有的仇恨言论数据集不能直接回答这个问题。这项工作试图通过创建HateModerate数据集来回答这个问题，用于测试自动化内容审核员对内容政策的行为。首先，我们让28名注释员和GPT参与六步骤注释过程，得出一份恶毒和非恶毒的测试套件清单，与Facebook的41条仇恨言论政策相匹配。其次，我们测试最先进的仇恨言论检测器对HateModerate的表现，揭示了这些模型的相当失败。",
    "tldr": "该论文通过创建HateModerate数据集来测试自动内容审核员对内容政策的符合度，揭示了现有仇恨言论检测器在此方面存在的重大失败。",
    "en_tdlr": "This paper tests the compliance of automated content moderators with content policies by creating the HateModerate dataset, revealing significant failures of existing hate speech detectors in this aspect."
}