{
    "title": "Kick Back & Relax: Learning to Reconstruct the World by Watching SlowTV. (arXiv:2307.10713v1 [cs.CV])",
    "abstract": "Self-supervised monocular depth estimation (SS-MDE) has the potential to scale to vast quantities of data. Unfortunately, existing approaches limit themselves to the automotive domain, resulting in models incapable of generalizing to complex environments such as natural or indoor settings.  To address this, we propose a large-scale SlowTV dataset curated from YouTube, containing an order of magnitude more data than existing automotive datasets. SlowTV contains 1.7M images from a rich diversity of environments, such as worldwide seasonal hiking, scenic driving and scuba diving. Using this dataset, we train an SS-MDE model that provides zero-shot generalization to a large collection of indoor/outdoor datasets. The resulting model outperforms all existing SSL approaches and closes the gap on supervised SoTA, despite using a more efficient architecture.  We additionally introduce a collection of best-practices to further maximize performance and zero-shot generalization. This includes 1) a",
    "link": "http://arxiv.org/abs/2307.10713",
    "context": "Title: Kick Back & Relax: Learning to Reconstruct the World by Watching SlowTV. (arXiv:2307.10713v1 [cs.CV])\nAbstract: Self-supervised monocular depth estimation (SS-MDE) has the potential to scale to vast quantities of data. Unfortunately, existing approaches limit themselves to the automotive domain, resulting in models incapable of generalizing to complex environments such as natural or indoor settings.  To address this, we propose a large-scale SlowTV dataset curated from YouTube, containing an order of magnitude more data than existing automotive datasets. SlowTV contains 1.7M images from a rich diversity of environments, such as worldwide seasonal hiking, scenic driving and scuba diving. Using this dataset, we train an SS-MDE model that provides zero-shot generalization to a large collection of indoor/outdoor datasets. The resulting model outperforms all existing SSL approaches and closes the gap on supervised SoTA, despite using a more efficient architecture.  We additionally introduce a collection of best-practices to further maximize performance and zero-shot generalization. This includes 1) a",
    "path": "papers/23/07/2307.10713.json",
    "total_tokens": 892,
    "translated_title": "休闲放松：通过观看SlowTV学习重建世界",
    "translated_abstract": "自监督单目深度估计（SS-MDE）具有处理大量数据的潜力。然而，现有方法限制在汽车领域，导致模型无法推广到自然或室内环境等复杂环境。为了解决这个问题，我们提出了一个基于YouTube的大规模SlowTV数据集，比现有的汽车数据集包含更多数据。SlowTV包含了来自世界各地四季徒步旅行，风景驾驶和潜水等丰富多样的环境的170万张图片。我们使用这个数据集训练了一个SS-MDE模型，可以在室内/室外数据集中进行已知-未知推广。尽管使用了更高效的架构，但结果模型的性能超过了所有现有的自我监督学习方法，并且接近于有监督学习的SoTA。我们还引入了一系列最佳实践，进一步提高了性能和已知-未知推广能力。",
    "tldr": "通过观看SlowTV学习重建世界的自监督单目深度估计模型在室内/室外数据集上具有良好的性能和已知-未知推广能力。这个模型使用了一个大规模SlowTV数据集以及一系列最佳实践来实现。",
    "en_tdlr": "The self-supervised monocular depth estimation model, trained on a large-scale SlowTV dataset and incorporating best-practices, demonstrates excellent performance and zero-shot generalization on indoor/outdoor datasets."
}