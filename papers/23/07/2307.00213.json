{
    "title": "More for Less: Compact Convolutional Transformers Enable Robust Medical Image Classification with Limited Data. (arXiv:2307.00213v1 [cs.CV])",
    "abstract": "Transformers are very powerful tools for a variety of tasks across domains, from text generation to image captioning. However, transformers require substantial amounts of training data, which is often a challenge in biomedical settings, where high quality labeled data can be challenging or expensive to obtain. This study investigates the efficacy of Compact Convolutional Transformers (CCT) for robust medical image classification with limited data, addressing a key issue faced by conventional Vision Transformers - their requirement for large datasets. A hybrid of transformers and convolutional layers, CCTs demonstrate high accuracy on modestly sized datasets. We employed a benchmark dataset of peripheral blood cell images of eight distinct cell types, each represented by approximately 2,000 low-resolution (28x28x3 pixel) samples. Despite the dataset size being smaller than those typically used with Vision Transformers, we achieved a commendable classification accuracy of 92.49% and a mi",
    "link": "http://arxiv.org/abs/2307.00213",
    "context": "Title: More for Less: Compact Convolutional Transformers Enable Robust Medical Image Classification with Limited Data. (arXiv:2307.00213v1 [cs.CV])\nAbstract: Transformers are very powerful tools for a variety of tasks across domains, from text generation to image captioning. However, transformers require substantial amounts of training data, which is often a challenge in biomedical settings, where high quality labeled data can be challenging or expensive to obtain. This study investigates the efficacy of Compact Convolutional Transformers (CCT) for robust medical image classification with limited data, addressing a key issue faced by conventional Vision Transformers - their requirement for large datasets. A hybrid of transformers and convolutional layers, CCTs demonstrate high accuracy on modestly sized datasets. We employed a benchmark dataset of peripheral blood cell images of eight distinct cell types, each represented by approximately 2,000 low-resolution (28x28x3 pixel) samples. Despite the dataset size being smaller than those typically used with Vision Transformers, we achieved a commendable classification accuracy of 92.49% and a mi",
    "path": "papers/23/07/2307.00213.json",
    "total_tokens": 885,
    "translated_title": "更少获取更多：紧凑卷积转换器在有限数据条件下实现稳健的医学图像分类",
    "translated_abstract": "转换器是一种非常强大的工具，可以在各个领域中应用于不同的任务，从文本生成到图像描述。然而，转换器通常需要大量的训练数据，在生物医学领域中，获取高质量标记数据常常具有挑战性且昂贵。本研究调查了紧凑卷积转换器（CCT）在有限数据条件下进行稳健的医学图像分类的有效性，解决了传统Vision Transformers面临的一个关键问题，即它们对大型数据集的要求。作为转换器和卷积层的混合体，CCT在规模适中的数据集上展现了很高的准确性。我们使用了一个基准数据集，其中包含了八种不同细胞类型的外周血细胞图像，每种细胞类型有约2000个低分辨率（28x28x3像素）样本。尽管数据集的大小比通常与Vision Transformers使用的数据集要小，我们达到了可观的92.49%的分类准确度和mi指标。",
    "tldr": "本研究调查了紧凑卷积转换器（CCT）在有限数据条件下进行稳健的医学图像分类的有效性，通过将转换器与卷积层结合，CCT表现出了在规模适中的数据集上高准确性。"
}