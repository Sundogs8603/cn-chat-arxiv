{
    "title": "FedDefender: Backdoor Attack Defense in Federated Learning",
    "abstract": "arXiv:2307.08672v2 Announce Type: replace-cross  Abstract: Federated Learning (FL) is a privacy-preserving distributed machine learning technique that enables individual clients (e.g., user participants, edge devices, or organizations) to train a model on their local data in a secure environment and then share the trained model with an aggregator to build a global model collaboratively. In this work, we propose FedDefender, a defense mechanism against targeted poisoning attacks in FL by leveraging differential testing. Our proposed method fingerprints the neuron activations of clients' models on the same input and uses differential testing to identify a potentially malicious client containing a backdoor. We evaluate FedDefender using MNIST and FashionMNIST datasets with 20 and 30 clients, and our results demonstrate that FedDefender effectively mitigates such attacks, reducing the attack success rate (ASR) to 10\\% without deteriorating the global model performance.",
    "link": "https://arxiv.org/abs/2307.08672",
    "context": "Title: FedDefender: Backdoor Attack Defense in Federated Learning\nAbstract: arXiv:2307.08672v2 Announce Type: replace-cross  Abstract: Federated Learning (FL) is a privacy-preserving distributed machine learning technique that enables individual clients (e.g., user participants, edge devices, or organizations) to train a model on their local data in a secure environment and then share the trained model with an aggregator to build a global model collaboratively. In this work, we propose FedDefender, a defense mechanism against targeted poisoning attacks in FL by leveraging differential testing. Our proposed method fingerprints the neuron activations of clients' models on the same input and uses differential testing to identify a potentially malicious client containing a backdoor. We evaluate FedDefender using MNIST and FashionMNIST datasets with 20 and 30 clients, and our results demonstrate that FedDefender effectively mitigates such attacks, reducing the attack success rate (ASR) to 10\\% without deteriorating the global model performance.",
    "path": "papers/23/07/2307.08672.json",
    "total_tokens": 862,
    "translated_title": "FedDefender：联邦学习中的后门攻击防御",
    "translated_abstract": "Federated Learning (FL)是一种隐私保护的分布式机器学习技术，它使得个体客户（例如用户参与者、边缘设备或组织）能够在安全环境中基于本地数据训练模型，然后与聚合器共享训练模型以协作构建全局模型。在这项工作中，我们提出了FedDefender，一种针对联邦学习中有针对性的中毒攻击的防御机制，它利用差分测试。我们提出的方法对相同输入的客户模型的神经元激活进行指纹识别，并利用差分测试来识别潜在包含后门的恶意客户。我们使用MNIST和FashionMNIST数据集以及20个和30个客户对FedDefender进行评估，结果表明，FedDefender有效地缓解了此类攻击，将攻击成功率（ASR）降低到10%，而不会恶化全局模型的性能。",
    "tldr": "FedDefender是一种针对联邦学习中有针对性的中毒攻击的防御机制，通过差分测试来识别潜在包含后门的恶意客户，有效降低攻击成功率到10%。",
    "en_tdlr": "FedDefender is a defense mechanism against targeted poisoning attacks in Federated Learning, leveraging differential testing to identify potentially malicious clients containing backdoors, effectively reducing the attack success rate to 10%."
}