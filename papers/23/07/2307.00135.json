{
    "title": "SMILE: Evaluation and Domain Adaptation for Social Media Language Understanding. (arXiv:2307.00135v1 [cs.CL])",
    "abstract": "We study the ability of transformer-based language models (LMs) to understand social media language. Social media (SM) language is distinct from standard written language, yet existing benchmarks fall short of capturing LM performance in this socially, economically, and politically important domain. We quantify the degree to which social media language differs from conventional language and conclude that the difference is significant both in terms of token distribution and rate of linguistic shift. Next, we introduce a new benchmark for Social MedIa Language Evaluation (SMILE) that covers four SM platforms and eleven tasks. Finally, we show that learning a tokenizer and pretraining on a mix of social media and conventional language yields an LM that outperforms the best similar-sized alternative by 4.2 points on the overall SMILE score.",
    "link": "http://arxiv.org/abs/2307.00135",
    "context": "Title: SMILE: Evaluation and Domain Adaptation for Social Media Language Understanding. (arXiv:2307.00135v1 [cs.CL])\nAbstract: We study the ability of transformer-based language models (LMs) to understand social media language. Social media (SM) language is distinct from standard written language, yet existing benchmarks fall short of capturing LM performance in this socially, economically, and politically important domain. We quantify the degree to which social media language differs from conventional language and conclude that the difference is significant both in terms of token distribution and rate of linguistic shift. Next, we introduce a new benchmark for Social MedIa Language Evaluation (SMILE) that covers four SM platforms and eleven tasks. Finally, we show that learning a tokenizer and pretraining on a mix of social media and conventional language yields an LM that outperforms the best similar-sized alternative by 4.2 points on the overall SMILE score.",
    "path": "papers/23/07/2307.00135.json",
    "total_tokens": 943,
    "translated_title": "SMILE：对社交媒体语言理解的评估和领域适应",
    "translated_abstract": "我们研究了基于Transformer模型的语言模型对社交媒体语言理解的能力。社交媒体语言与标准书面语有所不同，然而现有的评估标准未能完全捕捉语言模型在这个在社会、经济和政治层面都非常重要的领域性能。我们量化了社交媒体语言与传统语言之间的差异，并得出结论：无论是在词汇分布还是语言转变速率上，这种差异都是显著的。接下来，我们引入了一个新的社交媒体语言评估基准（SMILE），涵盖了四个社交媒体平台和十一项任务。最后，我们展示了一个学习分词器和混合社交媒体与传统语言进行预训练的方法，获得的语言模型在整体SMILE评分上比相同规模的最佳替代模型高出4.2个点。",
    "tldr": "本研究评估了基于Transformer模型的语言模型对社交媒体语言的理解能力，并引入了新的社交媒体语言评估基准（SMILE）。结果表明，社交媒体语言与传统语言存在显著差异，混合社交媒体和传统语言的预训练模型在SMILE评分上表现最好，比其他同规模模型高出4.2个点。",
    "en_tdlr": "This study evaluates transformer-based language models' ability to understand social media language and introduces a new benchmark called SMILE. The results show significant differences between social media language and conventional language, and pretraining the model on a mix of social media and conventional language achieves the highest SMILE score, outperforming other models by 4.2 points."
}