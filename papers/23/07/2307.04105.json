{
    "title": "Towards Assumption-free Bias Mitigation. (arXiv:2307.04105v1 [cs.LG])",
    "abstract": "Despite the impressive prediction ability, machine learning models show discrimination towards certain demographics and suffer from unfair prediction behaviors. To alleviate the discrimination, extensive studies focus on eliminating the unequal distribution of sensitive attributes via multiple approaches. However, due to privacy concerns, sensitive attributes are often either unavailable or missing in real-world scenarios. Therefore, several existing works alleviate the bias without sensitive attributes. Those studies face challenges, either in inaccurate predictions of sensitive attributes or the need to mitigate unequal distribution of manually defined non-sensitive attributes related to bias. The latter requires strong assumptions about the correlation between sensitive and non-sensitive attributes. As data distribution and task goals vary, the strong assumption on non-sensitive attributes may not be valid and require domain expertise. In this work, we propose an assumption-free fra",
    "link": "http://arxiv.org/abs/2307.04105",
    "context": "Title: Towards Assumption-free Bias Mitigation. (arXiv:2307.04105v1 [cs.LG])\nAbstract: Despite the impressive prediction ability, machine learning models show discrimination towards certain demographics and suffer from unfair prediction behaviors. To alleviate the discrimination, extensive studies focus on eliminating the unequal distribution of sensitive attributes via multiple approaches. However, due to privacy concerns, sensitive attributes are often either unavailable or missing in real-world scenarios. Therefore, several existing works alleviate the bias without sensitive attributes. Those studies face challenges, either in inaccurate predictions of sensitive attributes or the need to mitigate unequal distribution of manually defined non-sensitive attributes related to bias. The latter requires strong assumptions about the correlation between sensitive and non-sensitive attributes. As data distribution and task goals vary, the strong assumption on non-sensitive attributes may not be valid and require domain expertise. In this work, we propose an assumption-free fra",
    "path": "papers/23/07/2307.04105.json",
    "total_tokens": 824,
    "translated_title": "无假设偏差缓解方法",
    "translated_abstract": "尽管机器学习模型具有令人印象深刻的预测能力，但它们对特定人口群体显示出歧视，并且存在不公平的预测行为。为了减轻这种歧视，广泛的研究致力于通过多种方法消除敏感属性的不平等分布。然而，由于隐私问题，真实场景中经常无法得到或缺少敏感属性。因此，一些现有的工作在无敏感属性的情况下减轻了偏差。这些研究面临挑战，要么是对敏感属性的预测不准确，要么是需要减轻与偏差相关的人工定义的非敏感属性的不平等分布。后者对敏感和非敏感属性之间的相关性有着强大的假设。由于数据分布和任务目标的差异，对非敏感属性的强假设可能无效，并需要领域专业知识。在本文中，我们提出了一种无假设的偏差缓解方法。",
    "tldr": "本文提出了一种无假设的偏差缓解方法，用于解决机器学习模型对特定人口群体显示歧视和不公平预测行为的问题。",
    "en_tdlr": "This paper proposes an assumption-free bias mitigation method to address the discrimination and unfair prediction behaviors towards certain demographics in machine learning models."
}