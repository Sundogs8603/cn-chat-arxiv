{
    "title": "Meta-training with Demonstration Retrieval for Efficient Few-shot Learning. (arXiv:2307.00119v1 [cs.CL])",
    "abstract": "Large language models show impressive results on few-shot NLP tasks. However, these models are memory and computation-intensive. Meta-training allows one to leverage smaller models for few-shot generalization in a domain-general and task-agnostic manner; however, these methods alone results in models that may not have sufficient parameterization or knowledge to adapt quickly to a large variety of tasks. To overcome this issue, we propose meta-training with demonstration retrieval, where we use a dense passage retriever to retrieve semantically similar labeled demonstrations to each example for more varied supervision. By separating external knowledge from model parameters, we can use meta-training to train parameter-efficient models that generalize well on a larger variety of tasks. We construct a meta-training set from UnifiedQA and CrossFit, and propose a demonstration bank based on UnifiedQA tasks. To our knowledge, our work is the first to combine retrieval with meta-training, to u",
    "link": "http://arxiv.org/abs/2307.00119",
    "context": "Title: Meta-training with Demonstration Retrieval for Efficient Few-shot Learning. (arXiv:2307.00119v1 [cs.CL])\nAbstract: Large language models show impressive results on few-shot NLP tasks. However, these models are memory and computation-intensive. Meta-training allows one to leverage smaller models for few-shot generalization in a domain-general and task-agnostic manner; however, these methods alone results in models that may not have sufficient parameterization or knowledge to adapt quickly to a large variety of tasks. To overcome this issue, we propose meta-training with demonstration retrieval, where we use a dense passage retriever to retrieve semantically similar labeled demonstrations to each example for more varied supervision. By separating external knowledge from model parameters, we can use meta-training to train parameter-efficient models that generalize well on a larger variety of tasks. We construct a meta-training set from UnifiedQA and CrossFit, and propose a demonstration bank based on UnifiedQA tasks. To our knowledge, our work is the first to combine retrieval with meta-training, to u",
    "path": "papers/23/07/2307.00119.json",
    "total_tokens": 947,
    "translated_title": "具有演示检索的元训练用于高效的少样本学习",
    "translated_abstract": "大型语言模型在少样本自然语言处理任务上取得了令人震惊的结果。然而，这些模型的内存和计算开销很大。元训练允许利用较小的模型进行通用领域和任务无关的少样本泛化；然而，仅使用这些方法会导致模型可能没有足够的参数化或知识来快速适应各种任务。为了解决这个问题，我们提出了具有演示检索的元训练，其中我们使用密集的段落检索器来检索与每个示例语义相似的标记演示，以获得更多的多样化监督。通过将外部知识与模型参数分离，我们可以使用元训练来训练参数高效的模型，在更多种类的任务上具有良好的泛化能力。我们从UnifiedQA和CrossFit构建了一个元训练集，并基于UnifiedQA任务提出了一个演示库。据我们所知，我们的工作是首次将检索与元训练结合使用，以提高少样本学习的效率。",
    "tldr": "该论文提出了一种具有演示检索的元训练方法，通过使用密集的段落检索器检索与每个示例语义相似的标记演示来提高少样本学习的效果。通过将外部知识与模型参数分离，可以训练出参数高效且泛化能力强的模型。",
    "en_tdlr": "This paper proposes a meta-training approach with demonstration retrieval, which improves few-shot learning by using a dense passage retriever to retrieve labeled demonstrations that are semantically similar to each example. By separating external knowledge from model parameters, parameter-efficient models with strong generalization ability can be trained."
}