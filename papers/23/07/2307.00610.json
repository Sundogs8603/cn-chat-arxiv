{
    "title": "Fraunhofer SIT at CheckThat! 2023: Mixing Single-Modal Classifiers to Estimate the Check-Worthiness of Multi-Modal Tweets. (arXiv:2307.00610v2 [cs.LG] UPDATED)",
    "abstract": "The option of sharing images, videos and audio files on social media opens up new possibilities for distinguishing between false information and fake news on the Internet. Due to the vast amount of data shared every second on social media, not all data can be verified by a computer or a human expert. Here, a check-worthiness analysis can be used as a first step in the fact-checking pipeline and as a filtering mechanism to improve efficiency. This paper proposes a novel way of detecting the check-worthiness in multi-modal tweets. It takes advantage of two classifiers, each trained on a single modality. For image data, extracting the embedded text with an OCR analysis has shown to perform best. By combining the two classifiers, the proposed solution was able to place first in the CheckThat! 2023 Task 1A with an F1 score of 0.7297 achieved on the private test set.",
    "link": "http://arxiv.org/abs/2307.00610",
    "context": "Title: Fraunhofer SIT at CheckThat! 2023: Mixing Single-Modal Classifiers to Estimate the Check-Worthiness of Multi-Modal Tweets. (arXiv:2307.00610v2 [cs.LG] UPDATED)\nAbstract: The option of sharing images, videos and audio files on social media opens up new possibilities for distinguishing between false information and fake news on the Internet. Due to the vast amount of data shared every second on social media, not all data can be verified by a computer or a human expert. Here, a check-worthiness analysis can be used as a first step in the fact-checking pipeline and as a filtering mechanism to improve efficiency. This paper proposes a novel way of detecting the check-worthiness in multi-modal tweets. It takes advantage of two classifiers, each trained on a single modality. For image data, extracting the embedded text with an OCR analysis has shown to perform best. By combining the two classifiers, the proposed solution was able to place first in the CheckThat! 2023 Task 1A with an F1 score of 0.7297 achieved on the private test set.",
    "path": "papers/23/07/2307.00610.json",
    "total_tokens": 859,
    "translated_title": "Fraunhofer SIT在CheckThat! 2023中的贡献：混合单模分类器以估计多模态推文的可靠性",
    "translated_abstract": "在社交媒体上分享图像、视频和音频文件的选项为区分网络上的虚假信息和假新闻提供了新的可能性。由于社交媒体每秒分享的海量数据，无法通过计算机或人类专家对所有数据进行验证。因此，可通过可靠性分析作为事实核查流程的第一步，以及作为提高效率的过滤机制。本文提出了一种新颖的方法来检测多模态推文的可靠性。它利用了两个在单模态上训练的分类器。对于图像数据，通过OCR分析提取嵌入的文本表现最佳。通过组合这两个分类器，该方法在CheckThat! 2023任务1A中达到了0.7297的F1分数，在私人测试集上排名第一。",
    "tldr": "本文提出了一种混合单模分类器的方法，通过组合图像和文本分类器的结果，成功进行多模态推文的可靠性估计，并在CheckThat! 2023任务1A中取得了最佳表现。",
    "en_tdlr": "This paper proposes a method that combines single-modal classifiers for estimating the check-worthiness of multi-modal tweets. By combining classifiers for image and text data, the proposed solution achieved the best performance in CheckThat! 2023 Task 1A."
}