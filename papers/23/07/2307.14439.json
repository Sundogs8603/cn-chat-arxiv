{
    "title": "Fixed Integral Neural Networks. (arXiv:2307.14439v1 [cs.LG])",
    "abstract": "It is often useful to perform integration over learned functions represented by neural networks. However, this integration is usually performed numerically, as analytical integration over learned functions (especially neural networks) is generally viewed as intractable. In this work, we present a method for representing the analytical integral of a learned function $f$. This allows the exact integral of a neural network to be computed, and enables constrained neural networks to be parametrised by applying constraints directly to the integral. Crucially, we also introduce a method to constrain $f$ to be positive, a necessary condition for many applications (e.g. probability distributions, distance metrics, etc). Finally, we introduce several applications where our fixed-integral neural network (FINN) can be utilised.",
    "link": "http://arxiv.org/abs/2307.14439",
    "context": "Title: Fixed Integral Neural Networks. (arXiv:2307.14439v1 [cs.LG])\nAbstract: It is often useful to perform integration over learned functions represented by neural networks. However, this integration is usually performed numerically, as analytical integration over learned functions (especially neural networks) is generally viewed as intractable. In this work, we present a method for representing the analytical integral of a learned function $f$. This allows the exact integral of a neural network to be computed, and enables constrained neural networks to be parametrised by applying constraints directly to the integral. Crucially, we also introduce a method to constrain $f$ to be positive, a necessary condition for many applications (e.g. probability distributions, distance metrics, etc). Finally, we introduce several applications where our fixed-integral neural network (FINN) can be utilised.",
    "path": "papers/23/07/2307.14439.json",
    "total_tokens": 780,
    "translated_title": "固定积分神经网络",
    "translated_abstract": "将学习函数通过神经网络进行积分是非常有用的，但是这种积分通常是通过数值方法来计算的，因为解析计算积分过程复杂，尤其是对于神经网络这样的学习函数。本文介绍了一种表示学习函数 $f$ 解析积分的方法。这允许精确计算神经网络的积分，并且通过将约束直接应用于积分来对约束神经网络进行参数化。关键的是，我们还介绍了一种将 $f$ 约束为正的方法，这是许多应用（例如概率分布、距离度量等）所必需的条件。最后，我们介绍了几个可以利用我们的固定积分神经网络（FINN）的应用领域。",
    "tldr": "本文介绍了一种方法来通过神经网络表示学习函数的解析积分，具有计算精确积分的能力，并能将约束直接应用于积分，而且还介绍了将学习函数约束为正的方法以及相关应用。",
    "en_tdlr": "This paper presents a method to represent the analytical integral of a learned function using neural networks, enabling exact computation of the integral and direct application of constraints. It also introduces a method to constrain the learned function to be positive and discusses various applications."
}