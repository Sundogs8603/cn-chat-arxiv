{
    "title": "Feature Activation Map: Visual Explanation of Deep Learning Models for Image Classification. (arXiv:2307.05017v1 [cs.CV])",
    "abstract": "Decisions made by convolutional neural networks(CNN) can be understood and explained by visualizing discriminative regions on images. To this end, Class Activation Map (CAM) based methods were proposed as powerful interpretation tools, making the prediction of deep learning models more explainable, transparent, and trustworthy. However, all the CAM-based methods (e.g., CAM, Grad-CAM, and Relevance-CAM) can only be used for interpreting CNN models with fully-connected (FC) layers as a classifier. It is worth noting that many deep learning models classify images without FC layers, e.g., few-shot learning image classification, contrastive learning image classification, and image retrieval tasks. In this work, a post-hoc interpretation tool named feature activation map (FAM) is proposed, which can interpret deep learning models without FC layers as a classifier. In the proposed FAM algorithm, the channel-wise contribution weights are derived from the similarity scores between two image emb",
    "link": "http://arxiv.org/abs/2307.05017",
    "context": "Title: Feature Activation Map: Visual Explanation of Deep Learning Models for Image Classification. (arXiv:2307.05017v1 [cs.CV])\nAbstract: Decisions made by convolutional neural networks(CNN) can be understood and explained by visualizing discriminative regions on images. To this end, Class Activation Map (CAM) based methods were proposed as powerful interpretation tools, making the prediction of deep learning models more explainable, transparent, and trustworthy. However, all the CAM-based methods (e.g., CAM, Grad-CAM, and Relevance-CAM) can only be used for interpreting CNN models with fully-connected (FC) layers as a classifier. It is worth noting that many deep learning models classify images without FC layers, e.g., few-shot learning image classification, contrastive learning image classification, and image retrieval tasks. In this work, a post-hoc interpretation tool named feature activation map (FAM) is proposed, which can interpret deep learning models without FC layers as a classifier. In the proposed FAM algorithm, the channel-wise contribution weights are derived from the similarity scores between two image emb",
    "path": "papers/23/07/2307.05017.json",
    "total_tokens": 894,
    "translated_title": "特征激活映射：用于图像分类的深度学习模型可视解释",
    "translated_abstract": "通过可视化图像上的判别区域，可以理解和解释卷积神经网络（CNN）的决策。为此，提出了基于类激活映射（CAM）的方法作为强大的解释工具，使深度学习模型的预测更加可解释、透明和可信。然而，所有基于CAM的方法（如CAM、Grad-CAM和Relevance-CAM）只能用于解释具有全连接（FC）层作为分类器的CNN模型。值得注意的是，许多深度学习模型在没有FC层的情况下对图像进行分类，例如小样本学习图像分类、对比学习图像分类和图像检索任务。在这项工作中，提出了一种名为特征激活映射（FAM）的事后解释工具，可以解释没有FC层的深度学习模型作为分类器。在所提出的FAM算法中，通过两个图像嵌入之间的相似度得到通道权重的贡献。",
    "tldr": "本文提出了一种名为特征激活映射（FAM）的解释工具，可以解释没有FC层的深度学习模型作为分类器，使其更加可解释、透明和可信。"
}