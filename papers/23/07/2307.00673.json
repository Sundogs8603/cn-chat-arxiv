{
    "title": "ENN: A Neural Network with DCT Adaptive Activation Functions. (arXiv:2307.00673v2 [eess.SP] UPDATED)",
    "abstract": "The expressiveness of neural networks highly depends on the nature of the activation function, although these are usually assumed predefined and fixed during the training stage. Under a signal processing perspective, in this paper we present Expressive Neural Network (ENN), a novel model in which the non-linear activation functions are modeled using the Discrete Cosine Transform (DCT) and adapted using backpropagation during training. This parametrization keeps the number of trainable parameters low, is appropriate for gradient-based schemes, and adapts to different learning tasks. This is the first non-linear model for activation functions that relies on a signal processing perspective, providing high flexibility and expressiveness to the network. We contribute with insights in the explainability of the network at convergence by recovering the concept of bump, this is, the response of each activation function in the output space. Finally, through exhaustive experiments we show that th",
    "link": "http://arxiv.org/abs/2307.00673",
    "context": "Title: ENN: A Neural Network with DCT Adaptive Activation Functions. (arXiv:2307.00673v2 [eess.SP] UPDATED)\nAbstract: The expressiveness of neural networks highly depends on the nature of the activation function, although these are usually assumed predefined and fixed during the training stage. Under a signal processing perspective, in this paper we present Expressive Neural Network (ENN), a novel model in which the non-linear activation functions are modeled using the Discrete Cosine Transform (DCT) and adapted using backpropagation during training. This parametrization keeps the number of trainable parameters low, is appropriate for gradient-based schemes, and adapts to different learning tasks. This is the first non-linear model for activation functions that relies on a signal processing perspective, providing high flexibility and expressiveness to the network. We contribute with insights in the explainability of the network at convergence by recovering the concept of bump, this is, the response of each activation function in the output space. Finally, through exhaustive experiments we show that th",
    "path": "papers/23/07/2307.00673.json",
    "total_tokens": 950,
    "translated_title": "ENN: 一种具有DCT自适应激活函数的神经网络",
    "translated_abstract": "神经网络的表达能力高度取决于激活函数的性质，尽管这些通常在训练阶段被假定为预定义和固定的。在信号处理的视角下，本文提出了一种新颖的模型——表达神经网络(ENN)，其中非线性激活函数使用离散余弦变换(DCT)进行建模，并且在训练过程中使用反向传播进行自适应。这种参数化方法将可训练参数的数量保持较低，适合基于梯度的方案，并能适应不同的学习任务。这是第一个在激活函数方面依赖于信号处理视角的非线性模型，为网络提供了高度的灵活性和表现力。我们通过恢复“凸起”的概念来为网络在收敛时的可解释性提供了新的见解，即每个激活函数在输出空间中的响应。最后，通过详尽的实验，我们展示了该模型在多个任务上的性能优势。",
    "tldr": "ENN是一种具有DCT自适应激活函数的神经网络模型，通过使用反向传播自适应地调整激活函数，提供了高度的灵活性和表现力。在解释网络收敛过程中，我们恢复了每个激活函数在输出空间中的响应，即“凸起”。通过实验证明了该模型在多个任务上的性能优势。",
    "en_tdlr": "ENN is a neural network model with DCT adaptive activation functions. It provides high flexibility and expressiveness by adapting the activation functions using backpropagation. We recover the concept of \"bump\" to explain the network's convergence process. The model shows superior performance in multiple tasks."
}