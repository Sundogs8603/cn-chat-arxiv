{
    "title": "Geometric Neural Diffusion Processes. (arXiv:2307.05431v1 [stat.ML])",
    "abstract": "Denoising diffusion models have proven to be a flexible and effective paradigm for generative modelling. Their recent extension to infinite dimensional Euclidean spaces has allowed for the modelling of stochastic processes. However, many problems in the natural sciences incorporate symmetries and involve data living in non-Euclidean spaces. In this work, we extend the framework of diffusion models to incorporate a series of geometric priors in infinite-dimension modelling. We do so by a) constructing a noising process which admits, as limiting distribution, a geometric Gaussian process that transforms under the symmetry group of interest, and b) approximating the score with a neural network that is equivariant w.r.t. this group. We show that with these conditions, the generative functional model admits the same symmetry. We demonstrate scalability and capacity of the model, using a novel Langevin-based conditional sampler, to fit complex scalar and vector fields, with Euclidean and sph",
    "link": "http://arxiv.org/abs/2307.05431",
    "context": "Title: Geometric Neural Diffusion Processes. (arXiv:2307.05431v1 [stat.ML])\nAbstract: Denoising diffusion models have proven to be a flexible and effective paradigm for generative modelling. Their recent extension to infinite dimensional Euclidean spaces has allowed for the modelling of stochastic processes. However, many problems in the natural sciences incorporate symmetries and involve data living in non-Euclidean spaces. In this work, we extend the framework of diffusion models to incorporate a series of geometric priors in infinite-dimension modelling. We do so by a) constructing a noising process which admits, as limiting distribution, a geometric Gaussian process that transforms under the symmetry group of interest, and b) approximating the score with a neural network that is equivariant w.r.t. this group. We show that with these conditions, the generative functional model admits the same symmetry. We demonstrate scalability and capacity of the model, using a novel Langevin-based conditional sampler, to fit complex scalar and vector fields, with Euclidean and sph",
    "path": "papers/23/07/2307.05431.json",
    "total_tokens": 923,
    "translated_title": "几何神经扩散过程",
    "translated_abstract": "降噪扩散模型已被证明是一种灵活且有效的生成建模范式。最近将其扩展到无限维欧氏空间使得可以对随机过程进行建模。然而，自然科学中的许多问题都涉及对称性和存在于非欧几里得空间中的数据。在本文中，我们将扩散模型的框架扩展到无限维建模中引入一系列几何先验。我们通过 a) 构建一个噪声过程，其极限分布是在感兴趣的对称群下变换的几何高斯过程，并 b) 使用对这个群具有等变性的神经网络来逼近得分。我们表明，在这些条件下，生成函数模型具有相同的对称性。我们使用一种新颖的基于 Langevin 的条件采样器展示了模型的可扩展性和容量性，以适应复杂的标量和向量场，这些场存在于欧氏空间和球形空间中。",
    "tldr": "本文将扩散模型的框架应用于无限维建模，并引入几何先验以处理在非欧几里得空间中带有对称性的数据。通过构建具有对称群变换的几何高斯过程和等变神经网络逼近得分，生成函数模型也具有相同的对称性。"
}