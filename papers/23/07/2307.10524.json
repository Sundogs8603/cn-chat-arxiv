{
    "title": "Beyond Black-Box Advice: Learning-Augmented Algorithms for MDPs with Q-Value Predictions. (arXiv:2307.10524v1 [cs.LG])",
    "abstract": "We study the tradeoff between consistency and robustness in the context of a single-trajectory time-varying Markov Decision Process (MDP) with untrusted machine-learned advice. Our work departs from the typical approach of treating advice as coming from black-box sources by instead considering a setting where additional information about how the advice is generated is available. We prove a first-of-its-kind consistency and robustness tradeoff given Q-value advice under a general MDP model that includes both continuous and discrete state/action spaces. Our results highlight that utilizing Q-value advice enables dynamic pursuit of the better of machine-learned advice and a robust baseline, thus result in near-optimal performance guarantees, which provably improves what can be obtained solely with black-box advice.",
    "link": "http://arxiv.org/abs/2307.10524",
    "context": "Title: Beyond Black-Box Advice: Learning-Augmented Algorithms for MDPs with Q-Value Predictions. (arXiv:2307.10524v1 [cs.LG])\nAbstract: We study the tradeoff between consistency and robustness in the context of a single-trajectory time-varying Markov Decision Process (MDP) with untrusted machine-learned advice. Our work departs from the typical approach of treating advice as coming from black-box sources by instead considering a setting where additional information about how the advice is generated is available. We prove a first-of-its-kind consistency and robustness tradeoff given Q-value advice under a general MDP model that includes both continuous and discrete state/action spaces. Our results highlight that utilizing Q-value advice enables dynamic pursuit of the better of machine-learned advice and a robust baseline, thus result in near-optimal performance guarantees, which provably improves what can be obtained solely with black-box advice.",
    "path": "papers/23/07/2307.10524.json",
    "total_tokens": 796,
    "translated_title": "超越黑盒建议: 基于学习的增强算法用于具有Q值预测的MDPs",
    "translated_abstract": "我们研究了在单轨迹时间变化的马尔科夫决策过程(MDP)中一致性和鲁棒性之间的权衡，该过程具有不可信的机器学习建议。我们的工作不同于常规方法，不再将建议视为来自黑盒来源，而是考虑到有关如何生成建议的其他信息。我们证明了在包括连续和离散状态/动作空间的一般MDP模型下给出的Q值建议的一种新型一致性和鲁棒性权衡。我们的结果表明，利用Q值建议可以动态追求机器学习建议和稳健基线中较优的那个，从而产生接近最优的性能保证，并且改进了仅使用黑盒建议所能获得的结果。",
    "tldr": "该论文研究了在具有不可信的机器学习建议的单轨迹时间变化的MDP中一致性和鲁棒性之间的权衡，并证明了利用Q值建议可以获得接近最优的性能保证，并改进了仅使用黑盒建议的情况。"
}