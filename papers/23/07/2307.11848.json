{
    "title": "MythQA: Query-Based Large-Scale Check-Worthy Claim Detection through Multi-Answer Open-Domain Question Answering. (arXiv:2307.11848v1 [cs.CL])",
    "abstract": "Check-worthy claim detection aims at providing plausible misinformation to downstream fact-checking systems or human experts to check. This is a crucial step toward accelerating the fact-checking process. Many efforts have been put into how to identify check-worthy claims from a small scale of pre-collected claims, but how to efficiently detect check-worthy claims directly from a large-scale information source, such as Twitter, remains underexplored. To fill this gap, we introduce MythQA, a new multi-answer open-domain question answering(QA) task that involves contradictory stance mining for query-based large-scale check-worthy claim detection. The idea behind this is that contradictory claims are a strong indicator of misinformation that merits scrutiny by the appropriate authorities. To study this task, we construct TweetMythQA, an evaluation dataset containing 522 factoid multi-answer questions based on controversial topics. Each question is annotated with multiple answers. Moreover",
    "link": "http://arxiv.org/abs/2307.11848",
    "context": "Title: MythQA: Query-Based Large-Scale Check-Worthy Claim Detection through Multi-Answer Open-Domain Question Answering. (arXiv:2307.11848v1 [cs.CL])\nAbstract: Check-worthy claim detection aims at providing plausible misinformation to downstream fact-checking systems or human experts to check. This is a crucial step toward accelerating the fact-checking process. Many efforts have been put into how to identify check-worthy claims from a small scale of pre-collected claims, but how to efficiently detect check-worthy claims directly from a large-scale information source, such as Twitter, remains underexplored. To fill this gap, we introduce MythQA, a new multi-answer open-domain question answering(QA) task that involves contradictory stance mining for query-based large-scale check-worthy claim detection. The idea behind this is that contradictory claims are a strong indicator of misinformation that merits scrutiny by the appropriate authorities. To study this task, we construct TweetMythQA, an evaluation dataset containing 522 factoid multi-answer questions based on controversial topics. Each question is annotated with multiple answers. Moreover",
    "path": "papers/23/07/2307.11848.json",
    "total_tokens": 943,
    "translated_title": "MythQA: 多答案开放领域问题回答中的大规模查询值得检查的断言检测",
    "translated_abstract": "查询值得检查的断言检测旨在向下游的事实核查系统或人工专家提供可能的错误信息进行检查。这是加速事实核查过程的关键步骤。许多努力已经投入到如何从预收集的少量断言中识别值得检查的断言的研究中，但如何直接从大规模信息源（如Twitter）有效检测值得检查的断言仍然未被充分探索。为了填补这一空白，我们引入了MythQA，一项新的多答案开放领域问题回答（QA）任务，该任务涉及用于查询值得检查的大规模断言检测的矛盾立场挖掘。这一想法的背后是，矛盾的断言是值得由适当的机构进行审查的错误信息的强有力指标。为了研究这个任务，我们构建了TweetMythQA，一个包含522个基于有争议的话题的事实型多答案问题的评估数据集。每个问题都带有多个答案。",
    "tldr": "MythQA是一项新的多答案开放领域问题回答（QA）任务，旨在通过矛盾立场挖掘来检测大规模查询值得检查的断言。该任务通过构建一个包含522个基于有争议的话题的评估数据集来进行研究。",
    "en_tdlr": "MythQA is a new multi-answer open-domain question answering (QA) task aimed at detecting check-worthy claims through contradictory stance mining in large-scale queries. The task is studied by constructing an evaluation dataset containing 522 factoid multi-answer questions based on controversial topics."
}