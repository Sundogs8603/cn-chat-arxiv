{
    "title": "Generalizing Supervised Deep Learning MRI Reconstruction to Multiple and Unseen Contrasts using Meta-Learning Hypernetworks. (arXiv:2307.06771v1 [eess.IV])",
    "abstract": "Meta-learning has recently been an emerging data-efficient learning technique for various medical imaging operations and has helped advance contemporary deep learning models. Furthermore, meta-learning enhances the knowledge generalization of the imaging tasks by learning both shared and discriminative weights for various configurations of imaging tasks. However, existing meta-learning models attempt to learn a single set of weight initializations of a neural network that might be restrictive for multimodal data. This work aims to develop a multimodal meta-learning model for image reconstruction, which augments meta-learning with evolutionary capabilities to encompass diverse acquisition settings of multimodal data. Our proposed model called KM-MAML (Kernel Modulation-based Multimodal Meta-Learning), has hypernetworks that evolve to generate mode-specific weights. These weights provide the mode-specific inductive bias for multiple modes by re-calibrating each kernel of the base network",
    "link": "http://arxiv.org/abs/2307.06771",
    "context": "Title: Generalizing Supervised Deep Learning MRI Reconstruction to Multiple and Unseen Contrasts using Meta-Learning Hypernetworks. (arXiv:2307.06771v1 [eess.IV])\nAbstract: Meta-learning has recently been an emerging data-efficient learning technique for various medical imaging operations and has helped advance contemporary deep learning models. Furthermore, meta-learning enhances the knowledge generalization of the imaging tasks by learning both shared and discriminative weights for various configurations of imaging tasks. However, existing meta-learning models attempt to learn a single set of weight initializations of a neural network that might be restrictive for multimodal data. This work aims to develop a multimodal meta-learning model for image reconstruction, which augments meta-learning with evolutionary capabilities to encompass diverse acquisition settings of multimodal data. Our proposed model called KM-MAML (Kernel Modulation-based Multimodal Meta-Learning), has hypernetworks that evolve to generate mode-specific weights. These weights provide the mode-specific inductive bias for multiple modes by re-calibrating each kernel of the base network",
    "path": "papers/23/07/2307.06771.json",
    "total_tokens": 846,
    "translated_title": "将监督深度学习MRI重建推广到多种和未知对比度的元学习超网络",
    "translated_abstract": "元学习是一种最近兴起的数据高效学习技术，可用于各种医学图像操作，并有助于推进当代深度学习模型的发展。此外，元学习通过学习用于各种图像任务的共享和判别权重来增强图像任务的知识推广能力。然而，现有的元学习模型试图学习单个神经网络的权重初始化集合，这可能对于多模态数据来说是有限制的。本文旨在开发一种多模态元学习模型，用于图像重建，并通过演化能力来包括多样化的多模态数据采集设置。我们提出的模型称为KM-MAML（基于核调制的多模态元学习），具有进化的超网络，用于生成模态特定的权重。这些权重通过重新校准基网络的每个核，为多个模式提供模式特定的归纳偏见。",
    "tldr": "本文提出了一种名为KM-MAML的多模态元学习模型，通过演化能力和超网络生成模态特定的权重，以用于多种和未知对比度的图像重建。",
    "en_tdlr": "This paper proposes a multimodal meta-learning model called KM-MAML, which utilizes evolution and hypernetworks to generate mode-specific weights for image reconstruction in multiple and unseen contrasts."
}