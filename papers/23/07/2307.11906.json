{
    "title": "Unveiling Vulnerabilities in Interpretable Deep Learning Systems with Query-Efficient Black-box Attacks. (arXiv:2307.11906v1 [cs.CV])",
    "abstract": "Deep learning has been rapidly employed in many applications revolutionizing many industries, but it is known to be vulnerable to adversarial attacks. Such attacks pose a serious threat to deep learning-based systems compromising their integrity, reliability, and trust. Interpretable Deep Learning Systems (IDLSes) are designed to make the system more transparent and explainable, but they are also shown to be susceptible to attacks. In this work, we propose a novel microbial genetic algorithm-based black-box attack against IDLSes that requires no prior knowledge of the target model and its interpretation model. The proposed attack is a query-efficient approach that combines transfer-based and score-based methods, making it a powerful tool to unveil IDLS vulnerabilities. Our experiments of the attack show high attack success rates using adversarial examples with attribution maps that are highly similar to those of benign samples which makes it difficult to detect even by human analysts. ",
    "link": "http://arxiv.org/abs/2307.11906",
    "context": "Title: Unveiling Vulnerabilities in Interpretable Deep Learning Systems with Query-Efficient Black-box Attacks. (arXiv:2307.11906v1 [cs.CV])\nAbstract: Deep learning has been rapidly employed in many applications revolutionizing many industries, but it is known to be vulnerable to adversarial attacks. Such attacks pose a serious threat to deep learning-based systems compromising their integrity, reliability, and trust. Interpretable Deep Learning Systems (IDLSes) are designed to make the system more transparent and explainable, but they are also shown to be susceptible to attacks. In this work, we propose a novel microbial genetic algorithm-based black-box attack against IDLSes that requires no prior knowledge of the target model and its interpretation model. The proposed attack is a query-efficient approach that combines transfer-based and score-based methods, making it a powerful tool to unveil IDLS vulnerabilities. Our experiments of the attack show high attack success rates using adversarial examples with attribution maps that are highly similar to those of benign samples which makes it difficult to detect even by human analysts. ",
    "path": "papers/23/07/2307.11906.json",
    "total_tokens": 955,
    "translated_title": "通过查询有效的黑盒攻击揭示可解释的深度学习系统中的漏洞",
    "translated_abstract": "深度学习已迅速应用于许多应用领域，革新了许多行业，但已知其容易受到对抗性攻击的威胁。这种攻击对基于深度学习的系统构成了严重威胁，损害了其的完整性、可靠性和信任性。可解释的深度学习系统（IDLSes）旨在使系统更加透明和可解释，但同时也容易受到攻击。在这项工作中，我们提出了一种基于微生物遗传算法的黑盒攻击方法，用于攻击IDLSes，该方法不需要对目标模型及其解释模型有任何先验知识。所提出的攻击是一种查询有效的方法，结合了基于转移和基于评分的方法，使其成为揭示IDLS漏洞的强大工具。我们的攻击实验展示了使用具有与良性样本非常相似的属性图的对抗性样本的高攻击成功率，这使得即使是人工分析人员也很难检测到。",
    "tldr": "该论文提出了一种通过查询有效的黑盒攻击方法，揭示了可解释的深度学习系统中的漏洞。这种攻击方法是基于微生物遗传算法，无需先验知识，结合了转移和评分方法，攻击成功率高且难以被检测到。",
    "en_tdlr": "This paper proposes a query-efficient black-box attack method to unveil vulnerabilities in interpretable deep learning systems. The attack, based on microbial genetic algorithm, requires no prior knowledge and combines transfer and score-based methods, achieving high attack success rates and being difficult to detect."
}