{
    "title": "The Role of Subgroup Separability in Group-Fair Medical Image Classification. (arXiv:2307.02791v1 [cs.CV])",
    "abstract": "We investigate performance disparities in deep classifiers. We find that the ability of classifiers to separate individuals into subgroups varies substantially across medical imaging modalities and protected characteristics; crucially, we show that this property is predictive of algorithmic bias. Through theoretical analysis and extensive empirical evaluation, we find a relationship between subgroup separability, subgroup disparities, and performance degradation when models are trained on data with systematic bias such as underdiagnosis. Our findings shed new light on the question of how models become biased, providing important insights for the development of fair medical imaging AI.",
    "link": "http://arxiv.org/abs/2307.02791",
    "context": "Title: The Role of Subgroup Separability in Group-Fair Medical Image Classification. (arXiv:2307.02791v1 [cs.CV])\nAbstract: We investigate performance disparities in deep classifiers. We find that the ability of classifiers to separate individuals into subgroups varies substantially across medical imaging modalities and protected characteristics; crucially, we show that this property is predictive of algorithmic bias. Through theoretical analysis and extensive empirical evaluation, we find a relationship between subgroup separability, subgroup disparities, and performance degradation when models are trained on data with systematic bias such as underdiagnosis. Our findings shed new light on the question of how models become biased, providing important insights for the development of fair medical imaging AI.",
    "path": "papers/23/07/2307.02791.json",
    "total_tokens": 835,
    "translated_title": "子群可分性在组公平医学图像分类中的作用",
    "translated_abstract": "我们研究了深度分类器中的表现差异。我们发现分类器将个体分为子群的能力在医学成像模态和受保护特征方面存在显著差异；关键是，我们证明了这个属性对算法偏见具有预测能力。通过理论分析和大量实证评估，我们发现子群可分性、子群差异和模型在存在系统偏见数据（如欠诊断）时的性能降级之间存在关系。我们的发现为模型如何产生偏见提供了新的视角，为公平医学成像人工智能的发展提供了重要的见解。",
    "tldr": "本研究研究了深度分类器中的表现差异，发现分类器将个体分为子群的能力在医学成像模态和受保护特征方面存在显著差异，并证明了这个属性对算法偏见具有预测能力。通过理论分析和实证评估，我们发现子群可分性、子群差异和模型在存在系统偏见数据时的性能降级之间存在关系，这为公平医学成像人工智能的发展提供了重要的见解。",
    "en_tdlr": "This study investigates performance disparities in deep classifiers and finds that the ability of classifiers to separate individuals into subgroups varies across medical imaging modalities and protected characteristics, which is predictive of algorithmic bias. The relationship between subgroup separability, subgroup disparities, and performance degradation when models are trained on data with systematic bias provides important insights for the development of fair medical imaging AI."
}