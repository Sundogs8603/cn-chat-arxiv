{
    "title": "CFN-ESA: A Cross-Modal Fusion Network with Emotion-Shift Awareness for Dialogue Emotion Recognition. (arXiv:2307.15432v1 [cs.CL])",
    "abstract": "Multimodal Emotion Recognition in Conversation (ERC) has garnered growing attention from research communities in various fields. In this paper, we propose a cross-modal fusion network with emotion-shift awareness (CFN-ESA) for ERC. Extant approaches employ each modality equally without distinguishing the amount of emotional information, rendering it hard to adequately extract complementary and associative information from multimodal data. To cope with this problem, in CFN-ESA, textual modalities are treated as the primary source of emotional information, while visual and acoustic modalities are taken as the secondary sources. Besides, most multimodal ERC models ignore emotion-shift information and overfocus on contextual information, leading to the failure of emotion recognition under emotion-shift scenario. We elaborate an emotion-shift module to address this challenge. CFN-ESA mainly consists of the unimodal encoder (RUME), cross-modal encoder (ACME), and emotion-shift module (LESM).",
    "link": "http://arxiv.org/abs/2307.15432",
    "context": "Title: CFN-ESA: A Cross-Modal Fusion Network with Emotion-Shift Awareness for Dialogue Emotion Recognition. (arXiv:2307.15432v1 [cs.CL])\nAbstract: Multimodal Emotion Recognition in Conversation (ERC) has garnered growing attention from research communities in various fields. In this paper, we propose a cross-modal fusion network with emotion-shift awareness (CFN-ESA) for ERC. Extant approaches employ each modality equally without distinguishing the amount of emotional information, rendering it hard to adequately extract complementary and associative information from multimodal data. To cope with this problem, in CFN-ESA, textual modalities are treated as the primary source of emotional information, while visual and acoustic modalities are taken as the secondary sources. Besides, most multimodal ERC models ignore emotion-shift information and overfocus on contextual information, leading to the failure of emotion recognition under emotion-shift scenario. We elaborate an emotion-shift module to address this challenge. CFN-ESA mainly consists of the unimodal encoder (RUME), cross-modal encoder (ACME), and emotion-shift module (LESM).",
    "path": "papers/23/07/2307.15432.json",
    "total_tokens": 974,
    "translated_title": "CFN-ESA：一种具有情绪转移感知的跨模态融合网络用于对话情绪识别",
    "translated_abstract": "在对话情绪识别方面，多模态情感识别受到了各领域研究界的越来越多的关注。本文提出了一种具有情绪转移感知的跨模态融合网络（CFN-ESA）用于对话情绪识别。现有方法均平等地使用每个模态而无法区分情感信息的多少，从而难以充分提取多模态数据中的互补和关联信息。为了解决这个问题，在CFN-ESA中，文本模态被视为情感信息的主要来源，而视觉和声学模态则被视为次要来源。此外，大多数多模态情感识别模型忽视了情绪转移信息，过度关注上下文信息，导致在情绪转移场景下情感识别失败。我们设计了一个情绪转移模块来应对这一挑战。CFN-ESA主要包括单模态编码器（RUME）、跨模态编码器（ACME）和情绪转移模块（LESM）。",
    "tldr": "本文提出了一种具有情绪转移感知的跨模态融合网络（CFN-ESA）用于对话情绪识别，通过将文本模态作为主要情感信息的来源，视觉和声学模态作为次要信息的来源，并引入情绪转移模块来解决情绪转移场景下情感识别的问题。"
}