{
    "title": "Efficient Strongly Polynomial Algorithms for Quantile Regression. (arXiv:2307.08706v1 [cs.CG])",
    "abstract": "Linear Regression is a seminal technique in statistics and machine learning, where the objective is to build linear predictive models between a response (i.e., dependent) variable and one or more predictor (i.e., independent) variables. In this paper, we revisit the classical technique of Quantile Regression (QR), which is statistically a more robust alternative to the other classical technique of Ordinary Least Square Regression (OLS). However, while there exist efficient algorithms for OLS, almost all of the known results for QR are only weakly polynomial. Towards filling this gap, this paper proposes several efficient strongly polynomial algorithms for QR for various settings. For two dimensional QR, making a connection to the geometric concept of $k$-set, we propose an algorithm with a deterministic worst-case time complexity of $\\mathcal{O}(n^{4/3} polylog(n))$ and an expected time complexity of $\\mathcal{O}(n^{4/3})$ for the randomized version. We also propose a randomized divide",
    "link": "http://arxiv.org/abs/2307.08706",
    "context": "Title: Efficient Strongly Polynomial Algorithms for Quantile Regression. (arXiv:2307.08706v1 [cs.CG])\nAbstract: Linear Regression is a seminal technique in statistics and machine learning, where the objective is to build linear predictive models between a response (i.e., dependent) variable and one or more predictor (i.e., independent) variables. In this paper, we revisit the classical technique of Quantile Regression (QR), which is statistically a more robust alternative to the other classical technique of Ordinary Least Square Regression (OLS). However, while there exist efficient algorithms for OLS, almost all of the known results for QR are only weakly polynomial. Towards filling this gap, this paper proposes several efficient strongly polynomial algorithms for QR for various settings. For two dimensional QR, making a connection to the geometric concept of $k$-set, we propose an algorithm with a deterministic worst-case time complexity of $\\mathcal{O}(n^{4/3} polylog(n))$ and an expected time complexity of $\\mathcal{O}(n^{4/3})$ for the randomized version. We also propose a randomized divide",
    "path": "papers/23/07/2307.08706.json",
    "total_tokens": 939,
    "translated_title": "量子回归的高效强多项式算法",
    "translated_abstract": "线性回归是统计学和机器学习中的一种重要技术，其目标是建立响应变量（即依赖变量）和一个或多个预测变量（即自变量）之间的线性预测模型。本文重新审视了经典的分位数回归（QR）技术，这是一种在统计学中相对于最小二乘回归（OLS）更鲁棒的替代技术。然而，虽然存在有效的OLS算法，但几乎所有已知的QR结果都只是弱多项式。为了填补这一空白，本文针对不同的设置提出了几种高效的强多项式QR算法。对于二维QR，通过与几何概念中的k-集合建立联系，我们提出了一个具有确定性最坏时间复杂度为O(n^{4/3} polylog(n))和期望时间复杂度为O(n^{4/3})的算法（随机化版本）。我们还提出了一种随机划分的方法。",
    "tldr": "本文提出了针对量子回归的高效强多项式算法，填补了弱多项式算法的空白。对于二维QR，提出了一个具有确定性最坏时间复杂度为O(n^{4/3} polylog(n))和期望时间复杂度为O(n^{4/3})的算法。",
    "en_tdlr": "This paper proposes efficient strongly polynomial algorithms for quantile regression, filling the gap of weakly polynomial algorithms. For two-dimensional QR, an algorithm with a deterministic worst-case time complexity of O(n^{4/3} polylog(n)) and an expected time complexity of O(n^{4/3}) is proposed."
}