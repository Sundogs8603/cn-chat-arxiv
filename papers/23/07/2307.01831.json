{
    "title": "DiT-3D: Exploring Plain Diffusion Transformers for 3D Shape Generation. (arXiv:2307.01831v1 [cs.CV])",
    "abstract": "Recent Diffusion Transformers (e.g., DiT) have demonstrated their powerful effectiveness in generating high-quality 2D images. However, it is still being determined whether the Transformer architecture performs equally well in 3D shape generation, as previous 3D diffusion methods mostly adopted the U-Net architecture. To bridge this gap, we propose a novel Diffusion Transformer for 3D shape generation, namely DiT-3D, which can directly operate the denoising process on voxelized point clouds using plain Transformers. Compared to existing U-Net approaches, our DiT-3D is more scalable in model size and produces much higher quality generations. Specifically, the DiT-3D adopts the design philosophy of DiT but modifies it by incorporating 3D positional and patch embeddings to adaptively aggregate input from voxelized point clouds. To reduce the computational cost of self-attention in 3D shape generation, we incorporate 3D window attention into Transformer blocks, as the increased 3D token le",
    "link": "http://arxiv.org/abs/2307.01831",
    "context": "Title: DiT-3D: Exploring Plain Diffusion Transformers for 3D Shape Generation. (arXiv:2307.01831v1 [cs.CV])\nAbstract: Recent Diffusion Transformers (e.g., DiT) have demonstrated their powerful effectiveness in generating high-quality 2D images. However, it is still being determined whether the Transformer architecture performs equally well in 3D shape generation, as previous 3D diffusion methods mostly adopted the U-Net architecture. To bridge this gap, we propose a novel Diffusion Transformer for 3D shape generation, namely DiT-3D, which can directly operate the denoising process on voxelized point clouds using plain Transformers. Compared to existing U-Net approaches, our DiT-3D is more scalable in model size and produces much higher quality generations. Specifically, the DiT-3D adopts the design philosophy of DiT but modifies it by incorporating 3D positional and patch embeddings to adaptively aggregate input from voxelized point clouds. To reduce the computational cost of self-attention in 3D shape generation, we incorporate 3D window attention into Transformer blocks, as the increased 3D token le",
    "path": "papers/23/07/2307.01831.json",
    "total_tokens": 964,
    "translated_title": "DiT-3D: 探索用于3D形状生成的纯扩散Transformer",
    "translated_abstract": "最近的扩散Transformer（例如DiT）已经在生成高质量的2D图像方面展示了强大的效果。但是，是否Transformer架构在3D形状生成方面同样有效仍然有待确定，因为先前的3D扩散方法大部分采用了U-Net架构。为了弥合这一差距，我们提出了一种新颖的用于3D形状生成的扩散Transformer，称为DiT-3D，它可以直接在用于体素化点云的纯Transformer上进行去噪处理。与现有的U-Net方法相比，我们的DiT-3D在模型尺寸上具有更好的可扩展性，并且产生的生成结果质量更高。具体来说，DiT-3D采用了DiT的设计理念，但通过融合3D位置和补丁嵌入来自适应地聚合来自体素化点云的输入。为了减少3D形状生成中自注意力的计算成本，我们在Transformer块中引入了3D窗口注意力，以增加3D令牌数量。",
    "tldr": "DiT-3D是一种针对3D形状生成的新型扩散Transformer，通过在纯Transformer上进行去噪处理，结合3D位置和补丁嵌入来聚合体素化点云的输入，并引入了3D窗口注意力以降低计算成本。",
    "en_tdlr": "DiT-3D is a novel Diffusion Transformer for 3D shape generation, which operates the denoising process on voxelized point clouds using plain Transformers. It incorporates 3D positional and patch embeddings to adaptively aggregate input and introduces 3D window attention to reduce computational cost."
}