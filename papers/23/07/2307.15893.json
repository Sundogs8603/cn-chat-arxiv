{
    "title": "Online Matching: A Real-time Bandit System for Large-scale Recommendations. (arXiv:2307.15893v1 [cs.LG])",
    "abstract": "The last decade has witnessed many successes of deep learning-based models for industry-scale recommender systems. These models are typically trained offline in a batch manner. While being effective in capturing users' past interactions with recommendation platforms, batch learning suffers from long model-update latency and is vulnerable to system biases, making it hard to adapt to distribution shift and explore new items or user interests. Although online learning-based approaches (e.g., multi-armed bandits) have demonstrated promising theoretical results in tackling these challenges, their practical real-time implementation in large-scale recommender systems remains limited. First, the scalability of online approaches in servicing a massive online traffic while ensuring timely updates of bandit parameters poses a significant challenge. Additionally, exploring uncertainty in recommender systems can easily result in unfavorable user experience, highlighting the need for devising intric",
    "link": "http://arxiv.org/abs/2307.15893",
    "context": "Title: Online Matching: A Real-time Bandit System for Large-scale Recommendations. (arXiv:2307.15893v1 [cs.LG])\nAbstract: The last decade has witnessed many successes of deep learning-based models for industry-scale recommender systems. These models are typically trained offline in a batch manner. While being effective in capturing users' past interactions with recommendation platforms, batch learning suffers from long model-update latency and is vulnerable to system biases, making it hard to adapt to distribution shift and explore new items or user interests. Although online learning-based approaches (e.g., multi-armed bandits) have demonstrated promising theoretical results in tackling these challenges, their practical real-time implementation in large-scale recommender systems remains limited. First, the scalability of online approaches in servicing a massive online traffic while ensuring timely updates of bandit parameters poses a significant challenge. Additionally, exploring uncertainty in recommender systems can easily result in unfavorable user experience, highlighting the need for devising intric",
    "path": "papers/23/07/2307.15893.json",
    "total_tokens": 842,
    "translated_title": "在大规模推荐系统中的实时匹配：一种基于强盗系统的在线匹配方法",
    "translated_abstract": "过去十年见证了基于深度学习模型在工业规模的推荐系统中的许多成功。通常，这些模型是以批处理方式离线训练的。尽管批处理能够有效地捕捉用户与推荐平台的过去互动，但其长模型更新延迟以及易受系统偏差的影响使其难以适应分布变化并探索新的物品或用户兴趣。尽管基于在线学习的方法（例如多臂老虎机）在应对这些挑战方面表现出有希望的理论结果，但在大规模推荐系统中实时实施仍然受到限制。首先，在线方法在处理大规模在线流量并同时确保及时更新强盗参数的可扩展性面临着重大挑战。此外，探索推荐系统中的不确定性很容易导致不理想的用户体验，这突显了制定详尽策略的需求。",
    "tldr": "这项研究提出了一种基于强盗系统的在线匹配方法，解决了大规模推荐系统中实时更新和探索新内容的挑战。",
    "en_tdlr": "This research proposes an online matching method based on bandit systems, which addresses the challenges of real-time updates and exploration of new content in large-scale recommender systems."
}