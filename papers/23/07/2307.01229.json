{
    "title": "EmoGen: Eliminating Subjective Bias in Emotional Music Generation. (arXiv:2307.01229v1 [cs.SD])",
    "abstract": "Music is used to convey emotions, and thus generating emotional music is important in automatic music generation. Previous work on emotional music generation directly uses annotated emotion labels as control signals, which suffers from subjective bias: different people may annotate different emotions on the same music, and one person may feel different emotions under different situations. Therefore, directly mapping emotion labels to music sequences in an end-to-end way would confuse the learning process and hinder the model from generating music with general emotions. In this paper, we propose EmoGen, an emotional music generation system that leverages a set of emotion-related music attributes as the bridge between emotion and music, and divides the generation into two stages: emotion-to-attribute mapping with supervised clustering, and attribute-to-music generation with self-supervised learning. Both stages are beneficial: in the first stage, the attribute values around the clusterin",
    "link": "http://arxiv.org/abs/2307.01229",
    "context": "Title: EmoGen: Eliminating Subjective Bias in Emotional Music Generation. (arXiv:2307.01229v1 [cs.SD])\nAbstract: Music is used to convey emotions, and thus generating emotional music is important in automatic music generation. Previous work on emotional music generation directly uses annotated emotion labels as control signals, which suffers from subjective bias: different people may annotate different emotions on the same music, and one person may feel different emotions under different situations. Therefore, directly mapping emotion labels to music sequences in an end-to-end way would confuse the learning process and hinder the model from generating music with general emotions. In this paper, we propose EmoGen, an emotional music generation system that leverages a set of emotion-related music attributes as the bridge between emotion and music, and divides the generation into two stages: emotion-to-attribute mapping with supervised clustering, and attribute-to-music generation with self-supervised learning. Both stages are beneficial: in the first stage, the attribute values around the clusterin",
    "path": "papers/23/07/2307.01229.json",
    "total_tokens": 953,
    "translated_title": "EmoGen: 消除情感音乐生成中的主观偏差",
    "translated_abstract": "音乐用于传达情感，因此在自动生成音乐时生成情感音乐非常重要。之前关于情感音乐生成的工作直接使用标注的情感标签作为控制信号，但存在主观偏差：不同的人可能会在同样的音乐上标注不同的情感，同一个人在不同情境下也可能感受到不同的情感。因此，直接将情感标签映射到音乐序列中会混淆学习过程，并阻碍模型生成具有普遍情感的音乐。本文提出了EmoGen，一种情感音乐生成系统，它利用一组与情感相关的音乐属性作为情感和音乐之间的桥梁，并将生成分为两个阶段：基于监督聚类的情感到属性映射以及基于自监督学习的属性到音乐生成。这两个阶段都是有益的：在第一个阶段，聚类周围的属性值有助于消除主观偏差，第二个阶段则实现了音乐的生成。",
    "tldr": "EmoGen是一种消除情感音乐生成中主观偏差的系统，通过利用与情感相关的音乐属性作为桥梁，将生成分为情感到属性的映射以及属性到音乐的生成两个阶段，并在学习过程中消除主观偏差，实现生成具有普遍情感的音乐。"
}