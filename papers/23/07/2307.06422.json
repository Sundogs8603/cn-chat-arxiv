{
    "title": "Differentially Private Decoupled Graph Convolutions for Multigranular Topology Protection. (arXiv:2307.06422v1 [cs.LG])",
    "abstract": "Graph learning methods, such as Graph Neural Networks (GNNs) based on graph convolutions, are highly successful in solving real-world learning problems involving graph-structured data. However, graph learning methods expose sensitive user information and interactions not only through their model parameters but also through their model predictions. Consequently, standard Differential Privacy (DP) techniques that merely offer model weight privacy are inadequate. This is especially the case for node predictions that leverage neighboring node attributes directly via graph convolutions that create additional risks of privacy leakage. To address this problem, we introduce Graph Differential Privacy (GDP), a new formal DP framework tailored to graph learning settings that ensures both provably private model parameters and predictions. Furthermore, since there may be different privacy requirements for the node attributes and graph structure, we introduce a novel notion of relaxed node-level da",
    "link": "http://arxiv.org/abs/2307.06422",
    "context": "Title: Differentially Private Decoupled Graph Convolutions for Multigranular Topology Protection. (arXiv:2307.06422v1 [cs.LG])\nAbstract: Graph learning methods, such as Graph Neural Networks (GNNs) based on graph convolutions, are highly successful in solving real-world learning problems involving graph-structured data. However, graph learning methods expose sensitive user information and interactions not only through their model parameters but also through their model predictions. Consequently, standard Differential Privacy (DP) techniques that merely offer model weight privacy are inadequate. This is especially the case for node predictions that leverage neighboring node attributes directly via graph convolutions that create additional risks of privacy leakage. To address this problem, we introduce Graph Differential Privacy (GDP), a new formal DP framework tailored to graph learning settings that ensures both provably private model parameters and predictions. Furthermore, since there may be different privacy requirements for the node attributes and graph structure, we introduce a novel notion of relaxed node-level da",
    "path": "papers/23/07/2307.06422.json",
    "total_tokens": 870,
    "translated_title": "差分私有的解耦图卷积用于多粒度拓扑保护",
    "translated_abstract": "图学习方法，如基于图卷积的图神经网络（GNNs），在解决涉及图结构数据的实际学习问题方面非常成功。然而，图学习方法不仅通过其模型参数，还通过其模型预测暴露了敏感的用户信息和交互。因此，仅提供模型权重隐私的标准差分隐私（DP）技术是不充分的。这尤其适用于通过图卷积直接利用相邻节点属性进行节点预测的情况，这会带来额外的隐私泄露风险。为了解决这个问题，我们引入了图差分隐私（GDP），这是一个新的适用于图学习环境的形式化差分隐私框架，可以确保模型参数和预测都是可证明的私有的。此外，由于节点属性和图结构可能存在不同的隐私要求，我们引入了一种新颖的放松的节点层次隐私概念。",
    "tldr": "本论文提出了一种差分私有的解耦图卷积方法，用于多粒度拓扑保护。引入了图差分隐私框架，可以确保模型参数和预测的私密性。"
}