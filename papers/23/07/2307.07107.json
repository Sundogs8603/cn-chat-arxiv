{
    "title": "Graph Positional and Structural Encoder. (arXiv:2307.07107v1 [cs.LG])",
    "abstract": "Positional and structural encodings (PSE) enable better identifiability of nodes within a graph, as in general graphs lack a canonical node ordering. This renders PSEs essential tools for empowering modern GNNs, and in particular graph Transformers. However, designing PSEs that work optimally for a variety of graph prediction tasks is a challenging and unsolved problem. Here, we present the graph positional and structural encoder (GPSE), a first-ever attempt to train a graph encoder that captures rich PSE representations for augmenting any GNN. GPSE can effectively learn a common latent representation for multiple PSEs, and is highly transferable. The encoder trained on a particular graph dataset can be used effectively on datasets drawn from significantly different distributions and even modalities. We show that across a wide range of benchmarks, GPSE-enhanced models can significantly improve the performance in certain tasks, while performing on par with those that employ explicitly c",
    "link": "http://arxiv.org/abs/2307.07107",
    "context": "Title: Graph Positional and Structural Encoder. (arXiv:2307.07107v1 [cs.LG])\nAbstract: Positional and structural encodings (PSE) enable better identifiability of nodes within a graph, as in general graphs lack a canonical node ordering. This renders PSEs essential tools for empowering modern GNNs, and in particular graph Transformers. However, designing PSEs that work optimally for a variety of graph prediction tasks is a challenging and unsolved problem. Here, we present the graph positional and structural encoder (GPSE), a first-ever attempt to train a graph encoder that captures rich PSE representations for augmenting any GNN. GPSE can effectively learn a common latent representation for multiple PSEs, and is highly transferable. The encoder trained on a particular graph dataset can be used effectively on datasets drawn from significantly different distributions and even modalities. We show that across a wide range of benchmarks, GPSE-enhanced models can significantly improve the performance in certain tasks, while performing on par with those that employ explicitly c",
    "path": "papers/23/07/2307.07107.json",
    "total_tokens": 884,
    "translated_title": "图位置和结构编码器",
    "translated_abstract": "位置和结构编码（PSE）可以更好地在图中识别节点，因为一般图缺乏规范的节点顺序。这使得PSE成为赋予现代图神经网络（GNN）和特别是图变换器重要功能的工具。然而，设计适用于各种图预测任务的PSE是一个具有挑战性且未解决的问题。在这里，我们提出了图位置和结构编码器（GPSE），这是首次尝试训练一个能够捕捉丰富的PSE表示以增强任何GNN的图编码器。GPSE可以有效地学习多个PSE的共同潜在表示，并且具有高度可传输性。在特定图数据集上训练的编码器可以在从显著不同分布甚至模态的数据集上有效地使用。我们显示，在广泛的基准测试中，经过GPSE增强的模型在某些任务中显著提高性能，同时与明确使用PSE的模型性能相当。",
    "tldr": "这是一个关于图位置和结构编码器的研究，提出了图位置和结构编码器（GPSE），它能有效地捕捉多个PSE的共同潜在表示，并在各种图预测任务中取得显著的性能提升。",
    "en_tdlr": "This research introduces a graph positional and structural encoder (GPSE) that can effectively capture a common latent representation for multiple positional and structural encodings (PSEs), leading to significant performance improvement in various graph prediction tasks."
}