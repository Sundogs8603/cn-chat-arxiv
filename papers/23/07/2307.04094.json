{
    "title": "Class-Incremental Mixture of Gaussians for Deep Continual Learning. (arXiv:2307.04094v1 [cs.LG])",
    "abstract": "Continual learning models for stationary data focus on learning and retaining concepts coming to them in a sequential manner. In the most generic class-incremental environment, we have to be ready to deal with classes coming one by one, without any higher-level grouping. This requirement invalidates many previously proposed methods and forces researchers to look for more flexible alternative approaches. In this work, we follow the idea of centroid-driven methods and propose end-to-end incorporation of the mixture of Gaussians model into the continual learning framework. By employing the gradient-based approach and designing losses capable of learning discriminative features while avoiding degenerate solutions, we successfully combine the mixture model with a deep feature extractor allowing for joint optimization and adjustments in the latent space. Additionally, we show that our model can effectively learn in memory-free scenarios with fixed extractors. In the conducted experiments, we",
    "link": "http://arxiv.org/abs/2307.04094",
    "context": "Title: Class-Incremental Mixture of Gaussians for Deep Continual Learning. (arXiv:2307.04094v1 [cs.LG])\nAbstract: Continual learning models for stationary data focus on learning and retaining concepts coming to them in a sequential manner. In the most generic class-incremental environment, we have to be ready to deal with classes coming one by one, without any higher-level grouping. This requirement invalidates many previously proposed methods and forces researchers to look for more flexible alternative approaches. In this work, we follow the idea of centroid-driven methods and propose end-to-end incorporation of the mixture of Gaussians model into the continual learning framework. By employing the gradient-based approach and designing losses capable of learning discriminative features while avoiding degenerate solutions, we successfully combine the mixture model with a deep feature extractor allowing for joint optimization and adjustments in the latent space. Additionally, we show that our model can effectively learn in memory-free scenarios with fixed extractors. In the conducted experiments, we",
    "path": "papers/23/07/2307.04094.json",
    "total_tokens": 859,
    "translated_title": "深度持续学习中的类别增量高斯混合模型",
    "translated_abstract": "针对静态数据的持续学习模型注重以顺序方式学习和保留到达的概念。在最通用的类别增量环境中，我们必须准备好处理一个接一个到来的类别，而没有任何更高级别的分组。这个要求使得之前提出的许多方法无效，并迫使研究者寻找更灵活的替代方法。在这项工作中，我们遵循以质心驱动的方法的思想，提出将高斯混合模型完全整合到持续学习框架中的想法。通过采用基于梯度的方法和设计能够学习有区分性特征并避免退化解的损失函数，我们成功地将混合模型与深度特征提取器结合起来，实现在潜空间中的联合优化和调整。此外，我们还展示了我们的模型可以在固定的特征提取器下有效地在无内存的场景中学习。",
    "tldr": "这项工作提出了将高斯混合模型与持续学习框架相结合的类别增量方法，并成功地在深度特征提取器下进行了联合优化和调整。"
}