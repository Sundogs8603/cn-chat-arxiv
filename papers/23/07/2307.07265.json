{
    "title": "AudioInceptionNeXt: TCL AI LAB Submission to EPIC-SOUND Audio-Based-Interaction-Recognition Challenge 2023. (arXiv:2307.07265v1 [cs.SD])",
    "abstract": "This report presents the technical details of our submission to the 2023 Epic-Kitchen EPIC-SOUNDS Audio-Based Interaction Recognition Challenge. The task is to learn the mapping from audio samples to their corresponding action labels. To achieve this goal, we propose a simple yet effective single-stream CNN-based architecture called AudioInceptionNeXt that operates on the time-frequency log-mel-spectrogram of the audio samples. Motivated by the design of the InceptionNeXt, we propose parallel multi-scale depthwise separable convolutional kernels in the AudioInceptionNeXt block, which enable the model to learn the time and frequency information more effectively. The large-scale separable kernels capture the long duration of activities and the global frequency semantic information, while the small-scale separable kernels capture the short duration of activities and local details of frequency information. Our approach achieved 55.43% of top-1 accuracy on the challenge test set, ranked as ",
    "link": "http://arxiv.org/abs/2307.07265",
    "context": "Title: AudioInceptionNeXt: TCL AI LAB Submission to EPIC-SOUND Audio-Based-Interaction-Recognition Challenge 2023. (arXiv:2307.07265v1 [cs.SD])\nAbstract: This report presents the technical details of our submission to the 2023 Epic-Kitchen EPIC-SOUNDS Audio-Based Interaction Recognition Challenge. The task is to learn the mapping from audio samples to their corresponding action labels. To achieve this goal, we propose a simple yet effective single-stream CNN-based architecture called AudioInceptionNeXt that operates on the time-frequency log-mel-spectrogram of the audio samples. Motivated by the design of the InceptionNeXt, we propose parallel multi-scale depthwise separable convolutional kernels in the AudioInceptionNeXt block, which enable the model to learn the time and frequency information more effectively. The large-scale separable kernels capture the long duration of activities and the global frequency semantic information, while the small-scale separable kernels capture the short duration of activities and local details of frequency information. Our approach achieved 55.43% of top-1 accuracy on the challenge test set, ranked as ",
    "path": "papers/23/07/2307.07265.json",
    "total_tokens": 985,
    "translated_title": "AudioInceptionNeXt：TCL AI LAB对EPIC-SOUND音频交互识别挑战赛2023的投稿",
    "translated_abstract": "本报告介绍了我们对2023年Epic-Kitchen EPIC-SOUNDS音频交互识别挑战赛的提交的技术细节。任务是学习从音频样本到相应动作标签的映射。为了实现这个目标，我们提出了一种名为AudioInceptionNeXt的简单而有效的基于单个流的CNN架构，它基于音频样本的时间-频率对数-梅尔谱图进行操作。受InceptionNeXt设计的启发，我们在AudioInceptionNeXt块中提出了并行的多尺度深度可分离卷积核，使得模型能够更有效地学习时间和频率信息。大尺度可分离卷积核捕捉活动的长时间持续性和全局频率语义信息，而小尺度可分离卷积核捕捉活动的短时间持续性和频率信息的局部细节。我们的方法在挑战测试集上达到了55.43%的top-1准确率，排名为...",
    "tldr": "AudioInceptionNeXt是一个基于单个流的CNN架构，通过使用时间-频率log-mel-spectrogram的音频样本，结合并行的多尺度深度可分离卷积核来更有效地学习时间和频率信息，实现了在2023年EPIC-SOUND音频交互识别挑战赛上55.43%的准确率。"
}