{
    "title": "Learning Vision-and-Language Navigation from YouTube Videos. (arXiv:2307.11984v1 [cs.CV])",
    "abstract": "Vision-and-language navigation (VLN) requires an embodied agent to navigate in realistic 3D environments using natural language instructions. Existing VLN methods suffer from training on small-scale environments or unreasonable path-instruction datasets, limiting the generalization to unseen environments. There are massive house tour videos on YouTube, providing abundant real navigation experiences and layout information. However, these videos have not been explored for VLN before. In this paper, we propose to learn an agent from these videos by creating a large-scale dataset which comprises reasonable path-instruction pairs from house tour videos and pre-training the agent on it. To achieve this, we have to tackle the challenges of automatically constructing path-instruction pairs and exploiting real layout knowledge from raw and unlabeled videos. To address these, we first leverage an entropy-based method to construct the nodes of a path trajectory. Then, we propose an action-aware g",
    "link": "http://arxiv.org/abs/2307.11984",
    "context": "Title: Learning Vision-and-Language Navigation from YouTube Videos. (arXiv:2307.11984v1 [cs.CV])\nAbstract: Vision-and-language navigation (VLN) requires an embodied agent to navigate in realistic 3D environments using natural language instructions. Existing VLN methods suffer from training on small-scale environments or unreasonable path-instruction datasets, limiting the generalization to unseen environments. There are massive house tour videos on YouTube, providing abundant real navigation experiences and layout information. However, these videos have not been explored for VLN before. In this paper, we propose to learn an agent from these videos by creating a large-scale dataset which comprises reasonable path-instruction pairs from house tour videos and pre-training the agent on it. To achieve this, we have to tackle the challenges of automatically constructing path-instruction pairs and exploiting real layout knowledge from raw and unlabeled videos. To address these, we first leverage an entropy-based method to construct the nodes of a path trajectory. Then, we propose an action-aware g",
    "path": "papers/23/07/2307.11984.json",
    "total_tokens": 954,
    "translated_title": "从YouTube视频中学习视觉与语言导航",
    "translated_abstract": "视觉与语言导航需要一个具有身体的机器人代理在现实的三维环境中使用自然语言指令进行导航。现有的视觉与语言导航方法在小规模环境或不合理的路径指令数据集上进行训练，限制了对未知环境的泛化能力。YouTube上有大量的房屋导览视频，提供了丰富的真实导览经验和布局信息。然而，这些视频在视觉与语言导航方面尚未得到探索。在本文中，我们提出通过创建一个大规模的数据集，从导览视频中获取合理的路径指令对，并在其上进行预训练，从这些视频中学习一个智能机器人代理。为了实现这一目标，我们需要解决自动构建路径指令对和从原始和无标签视频中利用真实布局知识的挑战。为了解决这些问题，我们首先利用基于熵的方法构建路径轨迹的节点。然后，我们提出了一个 action-aware g模型来从视频中提取布局知识。",
    "tldr": "本文提出了从YouTube视频中学习视觉与语言导航的方法，通过创建大规模数据集，利用房屋导览视频中的路径指令对进行预训练，解决了泛化能力不足的问题，并提出了处理自动构建路径指令对和从无标签视频中提取布局知识的挑战的方法。",
    "en_tdlr": "This paper proposes a method to learn vision-and-language navigation from YouTube videos by creating a large-scale dataset and pre-training the agent on reasonable path-instruction pairs extracted from house tour videos. It addresses the limitations of current methods in terms of generalization and tackles the challenges of automatically constructing path-instruction pairs and extracting layout knowledge from unlabeled videos."
}