{
    "title": "Robust Assignment of Labels for Active Learning with Sparse and Noisy Annotations. (arXiv:2307.14380v1 [cs.LG])",
    "abstract": "Supervised classification algorithms are used to solve a growing number of real-life problems around the globe. Their performance is strictly connected with the quality of labels used in training. Unfortunately, acquiring good-quality annotations for many tasks is infeasible or too expensive to be done in practice. To tackle this challenge, active learning algorithms are commonly employed to select only the most relevant data for labeling. However, this is possible only when the quality and quantity of labels acquired from experts are sufficient. Unfortunately, in many applications, a trade-off between annotating individual samples by multiple annotators to increase label quality vs. annotating new samples to increase the total number of labeled instances is necessary. In this paper, we address the issue of faulty data annotations in the context of active learning. In particular, we propose two novel annotation unification algorithms that utilize unlabeled parts of the sample space. Th",
    "link": "http://arxiv.org/abs/2307.14380",
    "context": "Title: Robust Assignment of Labels for Active Learning with Sparse and Noisy Annotations. (arXiv:2307.14380v1 [cs.LG])\nAbstract: Supervised classification algorithms are used to solve a growing number of real-life problems around the globe. Their performance is strictly connected with the quality of labels used in training. Unfortunately, acquiring good-quality annotations for many tasks is infeasible or too expensive to be done in practice. To tackle this challenge, active learning algorithms are commonly employed to select only the most relevant data for labeling. However, this is possible only when the quality and quantity of labels acquired from experts are sufficient. Unfortunately, in many applications, a trade-off between annotating individual samples by multiple annotators to increase label quality vs. annotating new samples to increase the total number of labeled instances is necessary. In this paper, we address the issue of faulty data annotations in the context of active learning. In particular, we propose two novel annotation unification algorithms that utilize unlabeled parts of the sample space. Th",
    "path": "papers/23/07/2307.14380.json",
    "total_tokens": 822,
    "translated_title": "用稀疏和嘈杂的标注进行主动学习的标签鲁棒分派",
    "translated_abstract": "监督分类算法用于解决全球越来越多的现实生活问题。它们的性能与训练中使用的标签质量密切相关。然而，对许多任务来说，获取高质量的注释是不可行的或者太昂贵以至于无法实际完成。为了解决这个挑战，通常使用主动学习算法仅选择最相关的数据进行标注。然而，这仅在从专家处获得的标签的质量和数量足够时才可能。不幸的是，在许多应用中，需要在为增加标签质量而多个注释人员注释个别样本与为增加标记实例的总数而注释新样本之间作出权衡。在本文中，我们针对主动学习中的错误数据注释问题进行了研究。具体而言，我们提出了两种利用未标记样本空间的新型标注统一算法。",
    "tldr": "本文解决了主动学习中错误数据注释的问题，提出了两种利用未标记样本空间的新型标注统一算法。",
    "en_tdlr": "This paper addresses the issue of faulty data annotations in active learning and proposes two novel annotation unification algorithms that utilize the unlabeled sample space."
}