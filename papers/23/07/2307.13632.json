{
    "title": "Mitigating Mainstream Bias in Recommendation via Cost-sensitive Learning. (arXiv:2307.13632v1 [cs.IR])",
    "abstract": "Mainstream bias, where some users receive poor recommendations because their preferences are uncommon or simply because they are less active, is an important aspect to consider regarding fairness in recommender systems. Existing methods to mitigate mainstream bias do not explicitly model the importance of these non-mainstream users or, when they do, it is in a way that is not necessarily compatible with the data and recommendation model at hand. In contrast, we use the recommendation utility as a more generic and implicit proxy to quantify mainstreamness, and propose a simple user-weighting approach to incorporate it into the training process while taking the cost of potential recommendation errors into account. We provide extensive experimental results showing that quantifying mainstreamness via utility is better able at identifying non-mainstream users, and that they are indeed better served when training the model in a cost-sensitive way. This is achieved with negligible or no loss ",
    "link": "http://arxiv.org/abs/2307.13632",
    "context": "Title: Mitigating Mainstream Bias in Recommendation via Cost-sensitive Learning. (arXiv:2307.13632v1 [cs.IR])\nAbstract: Mainstream bias, where some users receive poor recommendations because their preferences are uncommon or simply because they are less active, is an important aspect to consider regarding fairness in recommender systems. Existing methods to mitigate mainstream bias do not explicitly model the importance of these non-mainstream users or, when they do, it is in a way that is not necessarily compatible with the data and recommendation model at hand. In contrast, we use the recommendation utility as a more generic and implicit proxy to quantify mainstreamness, and propose a simple user-weighting approach to incorporate it into the training process while taking the cost of potential recommendation errors into account. We provide extensive experimental results showing that quantifying mainstreamness via utility is better able at identifying non-mainstream users, and that they are indeed better served when training the model in a cost-sensitive way. This is achieved with negligible or no loss ",
    "path": "papers/23/07/2307.13632.json",
    "total_tokens": 840,
    "translated_title": "通过成本敏感学习减轻推荐中的主流偏见",
    "translated_abstract": "主流偏见是指一些用户由于其偏好不常见或者活跃度较低而收到较差的推荐，这在推荐系统中对公平性至关重要。现有方法未显式地对这些非主流用户的重要性建模，或者在建模时与数据和推荐模型不兼容。相反，我们使用推荐效用作为更通用和隐含的衡量主流性的代理，并提出了一种简单的用户加权方法，将其纳入训练过程中，并考虑潜在推荐错误的成本。我们通过大量实验结果表明，通过效用来量化主流性更能准确地识别非主流用户，并且当使用成本敏感方式训练模型时，这些用户的服务效果确实更好。这一成果几乎没有或没有损失。",
    "tldr": "通过成本敏感学习减轻推荐中的主流偏见，通过使用推荐效用作为衡量主流性的代理，并提出了简单的用户加权方法来纳入训练过程中，这样能够更好地识别非主流用户并提供更好的服务效果。",
    "en_tdlr": "Mitigating mainstream bias in recommendation by incorporating recommendation utility as a proxy for mainstreamness and proposing a simple user-weighting approach in the training process, leading to better identification and service for non-mainstream users."
}