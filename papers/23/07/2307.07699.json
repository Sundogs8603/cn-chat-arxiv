{
    "title": "Leveraging Large Language Models to Generate Answer Set Programs. (arXiv:2307.07699v1 [cs.AI])",
    "abstract": "Large language models (LLMs), such as GPT-3 and GPT-4, have demonstrated exceptional performance in various natural language processing tasks and have shown the ability to solve certain reasoning problems. However, their reasoning capabilities are limited and relatively shallow, despite the application of various prompting techniques. In contrast, formal logic is adept at handling complex reasoning, but translating natural language descriptions into formal logic is a challenging task that non-experts struggle with. This paper proposes a neuro-symbolic method that combines the strengths of large language models and answer set programming. Specifically, we employ an LLM to transform natural language descriptions of logic puzzles into answer set programs. We carefully design prompts for an LLM to convert natural language descriptions into answer set programs in a step by step manner. Surprisingly, with just a few in-context learning examples, LLMs can generate reasonably complex answer se",
    "link": "http://arxiv.org/abs/2307.07699",
    "context": "Title: Leveraging Large Language Models to Generate Answer Set Programs. (arXiv:2307.07699v1 [cs.AI])\nAbstract: Large language models (LLMs), such as GPT-3 and GPT-4, have demonstrated exceptional performance in various natural language processing tasks and have shown the ability to solve certain reasoning problems. However, their reasoning capabilities are limited and relatively shallow, despite the application of various prompting techniques. In contrast, formal logic is adept at handling complex reasoning, but translating natural language descriptions into formal logic is a challenging task that non-experts struggle with. This paper proposes a neuro-symbolic method that combines the strengths of large language models and answer set programming. Specifically, we employ an LLM to transform natural language descriptions of logic puzzles into answer set programs. We carefully design prompts for an LLM to convert natural language descriptions into answer set programs in a step by step manner. Surprisingly, with just a few in-context learning examples, LLMs can generate reasonably complex answer se",
    "path": "papers/23/07/2307.07699.json",
    "total_tokens": 844,
    "translated_title": "利用大型语言模型生成答案集程序",
    "translated_abstract": "大型语言模型（LLMs），如GPT-3和GPT-4，在各种自然语言处理任务中展现了出色的性能，并显示出解决某些推理问题的能力。然而，尽管采用了各种提示技术，它们的推理能力有限且相对浅显。相反，形式逻辑擅长处理复杂推理，但将自然语言描述转化为形式逻辑是一个非专家难以应对的挑战。本文提出了一种神经符号方法，它结合了大型语言模型和答案集编程的优势。具体而言，我们使用一个LLM将逻辑谜题的自然语言描述转化为答案集程序。我们精心设计了LLM的提示，以逐步将自然语言描述转化为答案集程序。令人惊讶的是，仅仅通过几个上下文学习示例，LLMs就能生成相当复杂的答案集。",
    "tldr": "本文提出了一种神经符号方法，将大型语言模型和答案集编程的优势相结合，通过使用大型语言模型将自然语言描述转化为答案集程序，以实现处理复杂推理问题的能力。",
    "en_tdlr": "This paper proposes a neuro-symbolic method that combines the strengths of large language models and answer set programming to handle complex reasoning problems by transforming natural language descriptions into answer set programs."
}