{
    "title": "Does Progress On Object Recognition Benchmarks Improve Real-World Generalization?. (arXiv:2307.13136v1 [cs.CV])",
    "abstract": "For more than a decade, researchers have measured progress in object recognition on ImageNet-based generalization benchmarks such as ImageNet-A, -C, and -R. Recent advances in foundation models, trained on orders of magnitude more data, have begun to saturate these standard benchmarks, but remain brittle in practice. This suggests standard benchmarks, which tend to focus on predefined or synthetic changes, may not be sufficient for measuring real world generalization. Consequently, we propose studying generalization across geography as a more realistic measure of progress using two datasets of objects from households across the globe. We conduct an extensive empirical evaluation of progress across nearly 100 vision models up to most recent foundation models. We first identify a progress gap between standard benchmarks and real-world, geographical shifts: progress on ImageNet results in up to 2.5x more progress on standard generalization benchmarks than real-world distribution shifts. S",
    "link": "http://arxiv.org/abs/2307.13136",
    "context": "Title: Does Progress On Object Recognition Benchmarks Improve Real-World Generalization?. (arXiv:2307.13136v1 [cs.CV])\nAbstract: For more than a decade, researchers have measured progress in object recognition on ImageNet-based generalization benchmarks such as ImageNet-A, -C, and -R. Recent advances in foundation models, trained on orders of magnitude more data, have begun to saturate these standard benchmarks, but remain brittle in practice. This suggests standard benchmarks, which tend to focus on predefined or synthetic changes, may not be sufficient for measuring real world generalization. Consequently, we propose studying generalization across geography as a more realistic measure of progress using two datasets of objects from households across the globe. We conduct an extensive empirical evaluation of progress across nearly 100 vision models up to most recent foundation models. We first identify a progress gap between standard benchmarks and real-world, geographical shifts: progress on ImageNet results in up to 2.5x more progress on standard generalization benchmarks than real-world distribution shifts. S",
    "path": "papers/23/07/2307.13136.json",
    "total_tokens": 884,
    "translated_title": "在目标识别基准测试上取得的进展是否改善了现实世界的泛化能力？",
    "translated_abstract": "十多年来，研究人员一直用基于ImageNet的泛化基准测试（如ImageNet-A、-C和-R）来衡量目标识别的进展。最近基于大量数据训练的基础模型取得了一些进展，但在实际应用中仍然表现不稳定。这表明标准基准测试可能不足以衡量现实世界的泛化能力，因为它们往往集中在预定义或合成的变化上。因此，我们提议使用涵盖全球各地家庭物体的两个数据集来研究地理范围内的泛化能力作为更现实的衡量标准。我们对近100个视觉模型进行了广泛的实证评估，包括最新的基础模型。首先，我们发现了标准基准测试和真实世界地理变化之间的进展差距：在ImageNet上的进展在标准泛化基准测试上产生的进展比真实世界分布变化高出2.5倍。",
    "tldr": "通过对涵盖全球各地家庭物体的数据集进行研究，我们发现目前在目标识别基准测试上取得的进展并没有改善在真实世界中的泛化能力。",
    "en_tdlr": "Through studying datasets of objects from households across the globe, we found that the progress made on object recognition benchmarks does not necessarily improve real-world generalization."
}