{
    "title": "NetGPT: A Native-AI Network Architecture Beyond Provisioning Personalized Generative Services. (arXiv:2307.06148v1 [cs.LG])",
    "abstract": "Large language models (LLMs) have triggered tremendous success to empower daily life by generative information, and the personalization of LLMs could further contribute to their applications due to better alignment with human intents. Towards personalized generative services, a collaborative cloud-edge methodology sounds promising, as it facilitates the effective orchestration of heterogeneous distributed communication and computing resources. In this article, after discussing the pros and cons of several candidate cloud-edge collaboration techniques, we put forward NetGPT to capably deploy appropriate LLMs at the edge and the cloud in accordance with their computing capacity. In addition, edge LLMs could efficiently leverage location-based information for personalized prompt completion, thus benefiting the interaction with cloud LLMs. After deploying representative open-source LLMs (e.g., GPT-2-base and LLaMA model) at the edge and the cloud, we present the feasibility of NetGPT on th",
    "link": "http://arxiv.org/abs/2307.06148",
    "context": "Title: NetGPT: A Native-AI Network Architecture Beyond Provisioning Personalized Generative Services. (arXiv:2307.06148v1 [cs.LG])\nAbstract: Large language models (LLMs) have triggered tremendous success to empower daily life by generative information, and the personalization of LLMs could further contribute to their applications due to better alignment with human intents. Towards personalized generative services, a collaborative cloud-edge methodology sounds promising, as it facilitates the effective orchestration of heterogeneous distributed communication and computing resources. In this article, after discussing the pros and cons of several candidate cloud-edge collaboration techniques, we put forward NetGPT to capably deploy appropriate LLMs at the edge and the cloud in accordance with their computing capacity. In addition, edge LLMs could efficiently leverage location-based information for personalized prompt completion, thus benefiting the interaction with cloud LLMs. After deploying representative open-source LLMs (e.g., GPT-2-base and LLaMA model) at the edge and the cloud, we present the feasibility of NetGPT on th",
    "path": "papers/23/07/2307.06148.json",
    "total_tokens": 867,
    "translated_title": "NetGPT: 超越提供个性化生成服务的本地AI网络架构",
    "translated_abstract": "大型语言模型（LLMs）通过生成信息在日常生活中取得了巨大成功，LLMs的个性化可能进一步促进它们在应用中的作用，因为它们能更好地与人类意图对齐。针对个性化生成服务，协作云边方法论听起来很有前景，因为它有助于有效协调异构分布式通信和计算资源。在本文中，我们讨论了几种候选的云边协作技术的利弊，提出了NetGPT，根据其计算能力在边缘和云端部署适当的LLMs。此外，边缘LLMs可以高效利用基于位置的信息进行个性化提示完成，从而有益于与云端LLMs的互动。在边缘和云端部署代表性的开源LLMs（例如GPT-2-base和LLaMA模型）之后，我们展示了NetGPT的可行性。",
    "tldr": "NetGPT是一个能够在边缘和云端部署适当的大型语言模型的本地AI网络架构，实现了个性化生成服务，并通过协作云边方法论来优化资源协调和互动效果。"
}