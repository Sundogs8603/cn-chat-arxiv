{
    "title": "Adversarial Conversational Shaping for Intelligent Agents. (arXiv:2307.11785v1 [cs.CL])",
    "abstract": "The recent emergence of deep learning methods has enabled the research community to achieve state-of-the art results in several domains including natural language processing. However, the current robocall system remains unstable and inaccurate: text generator and chat-bots can be tedious and misunderstand human-like dialogue. In this work, we study the performance of two models able to enhance an intelligent conversational agent through adversarial conversational shaping: a generative adversarial network with policy gradient (GANPG) and a generative adversarial network with reward for every generation step (REGS) based on the REGS model presented in Li et al. [18] . This model is able to assign rewards to both partially and fully generated text sequences. We discuss performance with different training details : seq2seq [ 36] and transformers [37 ] in a reinforcement learning framework.",
    "link": "http://arxiv.org/abs/2307.11785",
    "context": "Title: Adversarial Conversational Shaping for Intelligent Agents. (arXiv:2307.11785v1 [cs.CL])\nAbstract: The recent emergence of deep learning methods has enabled the research community to achieve state-of-the art results in several domains including natural language processing. However, the current robocall system remains unstable and inaccurate: text generator and chat-bots can be tedious and misunderstand human-like dialogue. In this work, we study the performance of two models able to enhance an intelligent conversational agent through adversarial conversational shaping: a generative adversarial network with policy gradient (GANPG) and a generative adversarial network with reward for every generation step (REGS) based on the REGS model presented in Li et al. [18] . This model is able to assign rewards to both partially and fully generated text sequences. We discuss performance with different training details : seq2seq [ 36] and transformers [37 ] in a reinforcement learning framework.",
    "path": "papers/23/07/2307.11785.json",
    "total_tokens": 821,
    "translated_title": "智能代理的对抗对话塑造",
    "translated_abstract": "深度学习方法的出现使得研究界在自然语言处理等多个领域取得了最先进的成果。然而，当前的自动拨号系统仍然不稳定且不准确：文本生成器和聊天机器人可能会迟钝并误解人类对话。在这项工作中，我们研究了两种模型的性能，它们通过对抗对话塑造来增强智能对话代理：使用策略梯度的生成对抗网络（GANPG）和基于Li等人提出的REGS模型的每一代生成步骤都有奖励的生成对抗网络（REGS）。该模型能够为部分和完整的生成文本序列分配奖励。我们在强化学习框架中讨论了使用不同训练细节的性能：seq2seq [36]和transformers [37]。",
    "tldr": "本文研究了通过对抗对话塑造来增强智能对话代理的两个模型：GANPG和REGS。这些模型能够改进当前的自动拨号系统，提高聊天机器人的性能。",
    "en_tdlr": "This paper studies two models, GANPG and REGS, for enhancing intelligent conversational agents through adversarial conversational shaping. These models improve the performance of the current robocall system and chat-bots."
}