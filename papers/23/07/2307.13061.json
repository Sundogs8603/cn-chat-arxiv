{
    "title": "Feature Gradient Flow for Interpreting Deep Neural Networks in Head and Neck Cancer Prediction. (arXiv:2307.13061v1 [eess.IV])",
    "abstract": "This paper introduces feature gradient flow, a new technique for interpreting deep learning models in terms of features that are understandable to humans. The gradient flow of a model locally defines nonlinear coordinates in the input data space representing the information the model is using to make its decisions. Our idea is to measure the agreement of interpretable features with the gradient flow of a model. To then evaluate the importance of a particular feature to the model, we compare that feature's gradient flow measure versus that of a baseline noise feature. We then develop a technique for training neural networks to be more interpretable by adding a regularization term to the loss function that encourages the model gradients to align with those of chosen interpretable features. We test our method in a convolutional neural network prediction of distant metastasis of head and neck cancer from a computed tomography dataset from the Cancer Imaging Archive.",
    "link": "http://arxiv.org/abs/2307.13061",
    "context": "Title: Feature Gradient Flow for Interpreting Deep Neural Networks in Head and Neck Cancer Prediction. (arXiv:2307.13061v1 [eess.IV])\nAbstract: This paper introduces feature gradient flow, a new technique for interpreting deep learning models in terms of features that are understandable to humans. The gradient flow of a model locally defines nonlinear coordinates in the input data space representing the information the model is using to make its decisions. Our idea is to measure the agreement of interpretable features with the gradient flow of a model. To then evaluate the importance of a particular feature to the model, we compare that feature's gradient flow measure versus that of a baseline noise feature. We then develop a technique for training neural networks to be more interpretable by adding a regularization term to the loss function that encourages the model gradients to align with those of chosen interpretable features. We test our method in a convolutional neural network prediction of distant metastasis of head and neck cancer from a computed tomography dataset from the Cancer Imaging Archive.",
    "path": "papers/23/07/2307.13061.json",
    "total_tokens": 908,
    "translated_title": "特征梯度流用于解释头颈癌预测中的深度神经网络",
    "translated_abstract": "本文介绍了一种新技术，即特征梯度流，用于将深度学习模型解释为对人类可理解的特征。模型的梯度流在输入数据空间中局部定义了非线性坐标，表示模型用于做出决策的信息。我们的想法是通过测量可解释特征与模型的梯度流的一致性来评估特定特征对模型的重要性，比较该特征的梯度流度量与基线噪声特征的度量。然后，我们通过在损失函数中添加正则化项的方式来训练神经网络，以使模型梯度与所选解释特征的梯度对齐。我们在从Cancer Imaging Archive获取的计算机断层扫描数据集中的头颈癌远处转移的卷积神经网络预测中测试了我们的方法。",
    "tldr": "本文提出了特征梯度流技术，用于解释深度学习模型在人类可理解的特征上的作用。通过测量可解释特征与模型的梯度流的一致性，并通过添加正则化项训练神经网络，我们可以评估特定特征对模型的重要性。"
}