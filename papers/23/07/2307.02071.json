{
    "title": "A Comparison of Machine Learning Methods for Data with High-Cardinality Categorical Variables. (arXiv:2307.02071v1 [cs.LG])",
    "abstract": "High-cardinality categorical variables are variables for which the number of different levels is large relative to the sample size of a data set, or in other words, there are few data points per level. Machine learning methods can have difficulties with high-cardinality variables. In this article, we empirically compare several versions of two of the most successful machine learning methods, tree-boosting and deep neural networks, and linear mixed effects models using multiple tabular data sets with high-cardinality categorical variables. We find that, first, machine learning models with random effects have higher prediction accuracy than their classical counterparts without random effects, and, second, tree-boosting with random effects outperforms deep neural networks with random effects.",
    "link": "http://arxiv.org/abs/2307.02071",
    "context": "Title: A Comparison of Machine Learning Methods for Data with High-Cardinality Categorical Variables. (arXiv:2307.02071v1 [cs.LG])\nAbstract: High-cardinality categorical variables are variables for which the number of different levels is large relative to the sample size of a data set, or in other words, there are few data points per level. Machine learning methods can have difficulties with high-cardinality variables. In this article, we empirically compare several versions of two of the most successful machine learning methods, tree-boosting and deep neural networks, and linear mixed effects models using multiple tabular data sets with high-cardinality categorical variables. We find that, first, machine learning models with random effects have higher prediction accuracy than their classical counterparts without random effects, and, second, tree-boosting with random effects outperforms deep neural networks with random effects.",
    "path": "papers/23/07/2307.02071.json",
    "total_tokens": 806,
    "translated_title": "高基数分类变量的机器学习方法比较",
    "translated_abstract": "高基数分类变量是指不同级别数量相对于数据集样本量较大的变量，也就是说，每个级别的数据点较少。机器学习方法在处理高基数变量时可能会遇到困难。本文通过对多个包含高基数分类变量的表格数据集进行实证比较，对两种最成功的机器学习方法（树提升和深度神经网络）以及线性混合效应模型的几个版本进行比较。我们发现，首先，带随机效应的机器学习模型的预测准确性高于不带随机效应的经典模型；其次，带随机效应的树提升优于带随机效应的深度神经网络。",
    "tldr": "本文通过对多个包含高基数分类变量的表格数据集进行实证比较，发现带随机效应的机器学习模型的预测准确性高于不带随机效应的经典模型，同时带随机效应的树提升方法优于带随机效应的深度神经网络。"
}