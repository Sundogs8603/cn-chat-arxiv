{
    "title": "Dense Sample Deep Learning. (arXiv:2307.10991v1 [cs.AI])",
    "abstract": "Deep Learning (DL) , a variant of the neural network algorithms originally proposed in the 1980s, has made surprising progress in Artificial Intelligence (AI), ranging from language translation, protein folding, autonomous cars, and more recently human-like language models (CHATbots), all that seemed intractable until very recently. Despite the growing use of Deep Learning (DL) networks, little is actually understood about the learning mechanisms and representations that makes these networks effective across such a diverse range of applications. Part of the answer must be the huge scale of the architecture and of course the large scale of the data, since not much has changed since 1987. But the nature of deep learned representations remain largely unknown. Unfortunately training sets with millions or billions of tokens have unknown combinatorics and Networks with millions or billions of hidden units cannot easily be visualized and their mechanisms cannot be easily revealed. In this pap",
    "link": "http://arxiv.org/abs/2307.10991",
    "context": "Title: Dense Sample Deep Learning. (arXiv:2307.10991v1 [cs.AI])\nAbstract: Deep Learning (DL) , a variant of the neural network algorithms originally proposed in the 1980s, has made surprising progress in Artificial Intelligence (AI), ranging from language translation, protein folding, autonomous cars, and more recently human-like language models (CHATbots), all that seemed intractable until very recently. Despite the growing use of Deep Learning (DL) networks, little is actually understood about the learning mechanisms and representations that makes these networks effective across such a diverse range of applications. Part of the answer must be the huge scale of the architecture and of course the large scale of the data, since not much has changed since 1987. But the nature of deep learned representations remain largely unknown. Unfortunately training sets with millions or billions of tokens have unknown combinatorics and Networks with millions or billions of hidden units cannot easily be visualized and their mechanisms cannot be easily revealed. In this pap",
    "path": "papers/23/07/2307.10991.json",
    "total_tokens": 846,
    "translated_title": "密集样本深度学习",
    "translated_abstract": "深度学习（DL）是20世纪80年代提出的一种神经网络算法的变体，在人工智能（AI）领域取得了令人惊讶的进展，包括语言翻译、蛋白质折叠、自动驾驶汽车，以及最近的类人语言模型（CHATbots）。尽管深度学习（DL）网络的使用越来越广泛，但对于使这些网络在如此广泛的应用中有效的学习机制和表示仍知之甚少。部分原因可能是其大规模架构和大规模数据的使用，但深度学习表示的本质仍然大部分未知。不幸的是，具有数百万或数十亿个标记的训练集存在未知的组合方式，同时数百万或数十亿个隐藏单元的网络难以可视化，其机制也难以揭示。在本文中，我们提出了一种密集样本深度学习的方法。",
    "tldr": "密集样本深度学习是一种针对深度学习网络的研究方法，旨在揭示学习机制和表示的未知特性，并解决大规模数据和隐藏单元存在的问题。",
    "en_tdlr": "Dense sample deep learning is a research approach that aims to uncover the unknown characteristics of learning mechanisms and representations in deep learning networks, and address the challenges posed by large-scale data and hidden units."
}