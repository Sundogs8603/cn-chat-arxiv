{
    "title": "QuickQual: Lightweight, convenient retinal image quality scoring with off-the-shelf pretrained models. (arXiv:2307.13646v1 [cs.CV])",
    "abstract": "Image quality remains a key problem for both traditional and deep learning (DL)-based approaches to retinal image analysis, but identifying poor quality images can be time consuming and subjective. Thus, automated methods for retinal image quality scoring (RIQS) are needed. The current state-of-the-art is MCFNet, composed of three Densenet121 backbones each operating in a different colour space. MCFNet, and the EyeQ dataset released by the same authors, was a huge step forward for RIQS. We present QuickQual, a simple approach to RIQS, consisting of a single off-the-shelf ImageNet-pretrained Densenet121 backbone plus a Support Vector Machine (SVM). QuickQual performs very well, setting a new state-of-the-art for EyeQ (Accuracy: 88.50% vs 88.00% for MCFNet; AUC: 0.9687 vs 0.9588). This suggests that RIQS can be solved with generic perceptual features learned on natural images, as opposed to requiring DL models trained on large amounts of fundus images. Additionally, we propose a Fixed Pr",
    "link": "http://arxiv.org/abs/2307.13646",
    "context": "Title: QuickQual: Lightweight, convenient retinal image quality scoring with off-the-shelf pretrained models. (arXiv:2307.13646v1 [cs.CV])\nAbstract: Image quality remains a key problem for both traditional and deep learning (DL)-based approaches to retinal image analysis, but identifying poor quality images can be time consuming and subjective. Thus, automated methods for retinal image quality scoring (RIQS) are needed. The current state-of-the-art is MCFNet, composed of three Densenet121 backbones each operating in a different colour space. MCFNet, and the EyeQ dataset released by the same authors, was a huge step forward for RIQS. We present QuickQual, a simple approach to RIQS, consisting of a single off-the-shelf ImageNet-pretrained Densenet121 backbone plus a Support Vector Machine (SVM). QuickQual performs very well, setting a new state-of-the-art for EyeQ (Accuracy: 88.50% vs 88.00% for MCFNet; AUC: 0.9687 vs 0.9588). This suggests that RIQS can be solved with generic perceptual features learned on natural images, as opposed to requiring DL models trained on large amounts of fundus images. Additionally, we propose a Fixed Pr",
    "path": "papers/23/07/2307.13646.json",
    "total_tokens": 1022,
    "translated_title": "QuickQual: 使用现成预训练模型的轻量、便捷的视网膜图像质量评分",
    "translated_abstract": "图像质量对于传统和基于深度学习的视网膜图像分析方法都是一个关键问题，但是识别低质量图像可能耗时且主观。因此，需要自动化的视网膜图像质量评分方法。现有的最先进方法是MCFNet，由三个在不同颜色空间中运行的Densenet121主干组成。MCFNet和同一作者发布的EyeQ数据集对于视网膜图像质量评分来说是一个巨大的进步。我们提出了QuickQual，一个简单的视网膜图像质量评分方法，包括一个现成的ImageNet预训练的Densenet121主干和一个支持向量机（SVM）。QuickQual表现非常好，为EyeQ设定了新的最先进水平（准确率：88.50% vs MCFNet的88.00%；AUC：0.9687 vs 0.9588）。这表明，视网膜图像质量评分可以利用在自然图像中学习的通用感知特征来解决，而不需要在大量眼底图像上进行训练的深度学习模型。",
    "tldr": "QuickQual是一个简单的视网膜图像质量评分方法，它使用现成的预训练模型和支持向量机，并在EyeQ数据集上取得了新的最先进结果，证明视网膜图像质量评分可以通过学习自然图像的通用感知特征来解决。"
}