{
    "title": "Combining model-predictive control and predictive reinforcement learning for stable quadrupedal robot locomotion. (arXiv:2307.07752v1 [cs.RO])",
    "abstract": "Stable gait generation is a crucial problem for legged robot locomotion as this impacts other critical performance factors such as, e.g. mobility over an uneven terrain and power consumption. Gait generation stability results from the efficient control of the interaction between the legged robot's body and the environment where it moves. Here, we study how this can be achieved by a combination of model-predictive and predictive reinforcement learning controllers. Model-predictive control (MPC) is a well-established method that does not utilize any online learning (except for some adaptive variations) as it provides a convenient interface for state constraints management. Reinforcement learning (RL), in contrast, relies on adaptation based on pure experience. In its bare-bone variants, RL is not always suitable for robots due to their high complexity and expensive simulation/experimentation. In this work, we combine both control methods to address the quadrupedal robot stable gate gener",
    "link": "http://arxiv.org/abs/2307.07752",
    "context": "Title: Combining model-predictive control and predictive reinforcement learning for stable quadrupedal robot locomotion. (arXiv:2307.07752v1 [cs.RO])\nAbstract: Stable gait generation is a crucial problem for legged robot locomotion as this impacts other critical performance factors such as, e.g. mobility over an uneven terrain and power consumption. Gait generation stability results from the efficient control of the interaction between the legged robot's body and the environment where it moves. Here, we study how this can be achieved by a combination of model-predictive and predictive reinforcement learning controllers. Model-predictive control (MPC) is a well-established method that does not utilize any online learning (except for some adaptive variations) as it provides a convenient interface for state constraints management. Reinforcement learning (RL), in contrast, relies on adaptation based on pure experience. In its bare-bone variants, RL is not always suitable for robots due to their high complexity and expensive simulation/experimentation. In this work, we combine both control methods to address the quadrupedal robot stable gate gener",
    "path": "papers/23/07/2307.07752.json",
    "total_tokens": 903,
    "translated_title": "结合模型预测控制和预测强化学习实现稳定的四足机器人行走",
    "translated_abstract": "稳定的步态生成是四足机器人行走中的一个关键问题，因为这会影响到其他关键性能因素，比如在不平坦地形上的机动性和功耗。步态生成的稳定性来自于对四足机器人身体与运动环境之间相互作用的高效控制。在本研究中，我们研究了如何通过结合模型预测控制和预测强化学习控制器来实现这一目标。模型预测控制（MPC）是一种已经很成熟的方法，它不使用任何在线学习（除了一些自适应变化），因为它提供了方便的状态约束管理界面。相反，强化学习（RL）依靠基于纯经验的适应性调整。在其基本形式中，由于机器人的复杂性和昂贵的仿真/实验需求，RL并不总是适用于机器人。在本研究中，我们结合了这两种控制方法来解决四足机器人稳定步态生成的问题。",
    "tldr": "本研究结合了模型预测控制和预测强化学习方法，旨在解决四足机器人稳定步态生成的问题。"
}