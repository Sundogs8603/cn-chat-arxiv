{
    "title": "Weakly Supervised Multi-Modal 3D Human Body Pose Estimation for Autonomous Driving. (arXiv:2307.14889v1 [cs.CV])",
    "abstract": "Accurate 3D human pose estimation (3D HPE) is crucial for enabling autonomous vehicles (AVs) to make informed decisions and respond proactively in critical road scenarios. Promising results of 3D HPE have been gained in several domains such as human-computer interaction, robotics, sports and medical analytics, often based on data collected in well-controlled laboratory environments. Nevertheless, the transfer of 3D HPE methods to AVs has received limited research attention, due to the challenges posed by obtaining accurate 3D pose annotations and the limited suitability of data from other domains.  We present a simple yet efficient weakly supervised approach for 3D HPE in the AV context by employing a high-level sensor fusion between camera and LiDAR data. The weakly supervised setting enables training on the target datasets without any 2D/3D keypoint labels by using an off-the-shelf 2D joint extractor and pseudo labels generated from LiDAR to image projections. Our approach outperform",
    "link": "http://arxiv.org/abs/2307.14889",
    "context": "Title: Weakly Supervised Multi-Modal 3D Human Body Pose Estimation for Autonomous Driving. (arXiv:2307.14889v1 [cs.CV])\nAbstract: Accurate 3D human pose estimation (3D HPE) is crucial for enabling autonomous vehicles (AVs) to make informed decisions and respond proactively in critical road scenarios. Promising results of 3D HPE have been gained in several domains such as human-computer interaction, robotics, sports and medical analytics, often based on data collected in well-controlled laboratory environments. Nevertheless, the transfer of 3D HPE methods to AVs has received limited research attention, due to the challenges posed by obtaining accurate 3D pose annotations and the limited suitability of data from other domains.  We present a simple yet efficient weakly supervised approach for 3D HPE in the AV context by employing a high-level sensor fusion between camera and LiDAR data. The weakly supervised setting enables training on the target datasets without any 2D/3D keypoint labels by using an off-the-shelf 2D joint extractor and pseudo labels generated from LiDAR to image projections. Our approach outperform",
    "path": "papers/23/07/2307.14889.json",
    "total_tokens": 1055,
    "translated_title": "弱监督的多模态3D人体姿势估计在自动驾驶中的应用",
    "translated_abstract": "准确的3D人体姿势估计对于自动驾驶车辆做出明智决策和在关键道路场景中积极应对非常重要。在多个领域，如人机交互、机器人技术、体育和医学分析等，3D人体姿势估计取得了令人满意的结果，通常基于在良好控制的实验室环境中收集的数据。然而，由于获取准确的3D姿势标注的挑战以及其他领域数据的有限适用性，将3D人体姿势估计方法转移到自动驾驶车辆中的研究受到了限制。我们提出了一种简单而高效的弱监督方法，通过将相机和激光雷达数据进行高级传感器融合，实现了自动驾驶场景下的3D人体姿势估计。弱监督的设置使得在目标数据集上进行训练时不需要任何2D/3D关键点标签，而是利用现成的2D关节点提取器和由激光雷达到图像的投影生成伪标签。我们的方法表现优于其他方法。",
    "tldr": "通过强大的弱监督方法，在自动驾驶领域中，我们提出了一种简单且高效的多模态3D人体姿势估计方法，通过相机和激光雷达数据之间的高级传感器融合，无需2D/3D关键点标签，在目标数据集上进行训练，实现准确的3D姿势估计。",
    "en_tdlr": "We present a simple and efficient weakly supervised approach for multi-modal 3D human body pose estimation in the context of autonomous driving. By leveraging high-level sensor fusion between camera and LiDAR data, our method achieves accurate 3D pose estimation without the need for 2D/3D keypoint labels, training on target datasets."
}