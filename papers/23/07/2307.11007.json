{
    "title": "Sharpness Minimization Algorithms Do Not Only Minimize Sharpness To Achieve Better Generalization. (arXiv:2307.11007v1 [cs.LG])",
    "abstract": "Despite extensive studies, the underlying reason as to why overparameterized neural networks can generalize remains elusive. Existing theory shows that common stochastic optimizers prefer flatter minimizers of the training loss, and thus a natural potential explanation is that flatness implies generalization. This work critically examines this explanation. Through theoretical and empirical investigation, we identify the following three scenarios for two-layer ReLU networks: (1) flatness provably implies generalization; (2) there exist non-generalizing flattest models and sharpness minimization algorithms fail to generalize, and (3) perhaps most surprisingly, there exist non-generalizing flattest models, but sharpness minimization algorithms still generalize. Our results suggest that the relationship between sharpness and generalization subtly depends on the data distributions and the model architectures and sharpness minimization algorithms do not only minimize sharpness to achieve bet",
    "link": "http://arxiv.org/abs/2307.11007",
    "context": "Title: Sharpness Minimization Algorithms Do Not Only Minimize Sharpness To Achieve Better Generalization. (arXiv:2307.11007v1 [cs.LG])\nAbstract: Despite extensive studies, the underlying reason as to why overparameterized neural networks can generalize remains elusive. Existing theory shows that common stochastic optimizers prefer flatter minimizers of the training loss, and thus a natural potential explanation is that flatness implies generalization. This work critically examines this explanation. Through theoretical and empirical investigation, we identify the following three scenarios for two-layer ReLU networks: (1) flatness provably implies generalization; (2) there exist non-generalizing flattest models and sharpness minimization algorithms fail to generalize, and (3) perhaps most surprisingly, there exist non-generalizing flattest models, but sharpness minimization algorithms still generalize. Our results suggest that the relationship between sharpness and generalization subtly depends on the data distributions and the model architectures and sharpness minimization algorithms do not only minimize sharpness to achieve bet",
    "path": "papers/23/07/2307.11007.json",
    "total_tokens": 929,
    "translated_title": "尖锐性最小化算法不仅仅是为了更好地泛化而最小化尖锐性",
    "translated_abstract": "尽管进行了广泛的研究，但过参数化的神经网络能够泛化的基本原因仍然不明确。现有的理论表明，常见的随机优化器更倾向于训练损失更平坦的最小化器，因此自然而然的解释是平坦性意味着泛化。本文对这一解释进行了批判性的研究。通过理论和实证调查，我们发现对于两层ReLU网络存在以下三种情况：(1) 平坦性确实暗示泛化；(2) 存在最平坦的非泛化模型，尖锐性最小化算法无法泛化；(3) 更加令人惊讶的是，存在非泛化最平坦的模型，但尖锐性最小化算法仍然能够泛化。我们的研究结果表明，尖锐性与泛化之间的关系在一定程度上取决于数据分布和模型架构，尖锐性最小化算法不仅仅是为了最小化尖锐性而达到更好的泛化。",
    "tldr": "本文研究发现，尖锐性最小化算法不仅仅是为了最小化尖锐性而达到更好的泛化。我们的结果表明，尖锐性与泛化之间的关系取决于数据分布和模型架构。"
}