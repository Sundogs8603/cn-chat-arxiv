{
    "title": "Spectral-DP: Differentially Private Deep Learning through Spectral Perturbation and Filtering. (arXiv:2307.13231v1 [cs.LG])",
    "abstract": "Differential privacy is a widely accepted measure of privacy in the context of deep learning algorithms, and achieving it relies on a noisy training approach known as differentially private stochastic gradient descent (DP-SGD). DP-SGD requires direct noise addition to every gradient in a dense neural network, the privacy is achieved at a significant utility cost. In this work, we present Spectral-DP, a new differentially private learning approach which combines gradient perturbation in the spectral domain with spectral filtering to achieve a desired privacy guarantee with a lower noise scale and thus better utility. We develop differentially private deep learning methods based on Spectral-DP for architectures that contain both convolution and fully connected layers. In particular, for fully connected layers, we combine a block-circulant based spatial restructuring with Spectral-DP to achieve better utility. Through comprehensive experiments, we study and provide guidelines to implement",
    "link": "http://arxiv.org/abs/2307.13231",
    "context": "Title: Spectral-DP: Differentially Private Deep Learning through Spectral Perturbation and Filtering. (arXiv:2307.13231v1 [cs.LG])\nAbstract: Differential privacy is a widely accepted measure of privacy in the context of deep learning algorithms, and achieving it relies on a noisy training approach known as differentially private stochastic gradient descent (DP-SGD). DP-SGD requires direct noise addition to every gradient in a dense neural network, the privacy is achieved at a significant utility cost. In this work, we present Spectral-DP, a new differentially private learning approach which combines gradient perturbation in the spectral domain with spectral filtering to achieve a desired privacy guarantee with a lower noise scale and thus better utility. We develop differentially private deep learning methods based on Spectral-DP for architectures that contain both convolution and fully connected layers. In particular, for fully connected layers, we combine a block-circulant based spatial restructuring with Spectral-DP to achieve better utility. Through comprehensive experiments, we study and provide guidelines to implement",
    "path": "papers/23/07/2307.13231.json",
    "total_tokens": 926,
    "translated_title": "Spectral-DP: 通过频谱扰动和滤波实现差分隐私深度学习",
    "translated_abstract": "差分隐私在深度学习算法中被广泛接受作为隐私度量，实现差分隐私依赖于一种称为差分隐私随机梯度下降（DP-SGD）的噪声训练方法。DP-SGD需要在密集神经网络中给每个梯度直接添加噪声，但这种隐私是以显著的效用损失为代价的。在这项工作中，我们提出了Spectral-DP，一种新的差分隐私学习方法，它将频域中的梯度扰动与频谱滤波相结合，以更低的噪声比例实现所需的隐私保证，从而提高效用。我们基于Spectral-DP开发了基于差分隐私的深度学习方法，适用于包含卷积层和全连接层的体系结构。特别地，对于全连接层，我们将基于块循环的空间重构与Spectral-DP相结合，以实现更好的效用。通过综合实验，我们研究并提供了实施的指南。",
    "tldr": "Spectral-DP是一种新的差分隐私学习方法，通过将频域中的梯度扰动与频谱滤波相结合，实现更低噪声比例的隐私保证，从而提高深度学习的效用。",
    "en_tdlr": "Spectral-DP is a new differentially private learning method that combines gradient perturbation in the spectral domain with spectral filtering to achieve a lower noise scale and better utility in deep learning."
}