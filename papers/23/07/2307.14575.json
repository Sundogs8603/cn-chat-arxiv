{
    "title": "A Memory-Augmented Multi-Task Collaborative Framework for Unsupervised Traffic Accident Detection in Driving Videos. (arXiv:2307.14575v1 [cs.CV])",
    "abstract": "Identifying traffic accidents in driving videos is crucial to ensuring the safety of autonomous driving and driver assistance systems. To address the potential danger caused by the long-tailed distribution of driving events, existing traffic accident detection (TAD) methods mainly rely on unsupervised learning. However, TAD is still challenging due to the rapid movement of cameras and dynamic scenes in driving scenarios. Existing unsupervised TAD methods mainly rely on a single pretext task, i.e., an appearance-based or future object localization task, to detect accidents. However, appearance-based approaches are easily disturbed by the rapid movement of the camera and changes in illumination, which significantly reduce the performance of traffic accident detection. Methods based on future object localization may fail to capture appearance changes in video frames, making it difficult to detect ego-involved accidents (e.g., out of control of the ego-vehicle). In this paper, we propose a",
    "link": "http://arxiv.org/abs/2307.14575",
    "context": "Title: A Memory-Augmented Multi-Task Collaborative Framework for Unsupervised Traffic Accident Detection in Driving Videos. (arXiv:2307.14575v1 [cs.CV])\nAbstract: Identifying traffic accidents in driving videos is crucial to ensuring the safety of autonomous driving and driver assistance systems. To address the potential danger caused by the long-tailed distribution of driving events, existing traffic accident detection (TAD) methods mainly rely on unsupervised learning. However, TAD is still challenging due to the rapid movement of cameras and dynamic scenes in driving scenarios. Existing unsupervised TAD methods mainly rely on a single pretext task, i.e., an appearance-based or future object localization task, to detect accidents. However, appearance-based approaches are easily disturbed by the rapid movement of the camera and changes in illumination, which significantly reduce the performance of traffic accident detection. Methods based on future object localization may fail to capture appearance changes in video frames, making it difficult to detect ego-involved accidents (e.g., out of control of the ego-vehicle). In this paper, we propose a",
    "path": "papers/23/07/2307.14575.json",
    "total_tokens": 1036,
    "translated_title": "用于无监督驾驶视频交通事故检测的记忆增强多任务协作框架",
    "translated_abstract": "在自动驾驶和驾驶员辅助系统中，识别驾驶视频中的交通事故对确保安全至关重要。为了解决驾驶事件长尾分布可能带来的潜在危险，现有的交通事故检测方法主要依赖于无监督学习。然而，由于驾驶场景中相机的快速移动和动态场景，交通事故检测仍然具有挑战性。现有的无监督交通事故检测方法主要依赖于单一的预训练任务，即基于外观或未来物体定位任务来检测事故。然而，基于外观的方法容易受到相机快速移动和光照变化的干扰，显著降低了交通事故检测的性能。基于未来物体定位的方法可能无法捕捉视频帧中的外观变化，使得难以检测到车辆失控等与自身相关的事故。在本文中，我们提出了一种记忆增强的多任务协作框架",
    "tldr": "在本论文中，我们提出了一种记忆增强的多任务协作框架，用于无监督驾驶视频交通事故检测，以解决驾驶场景中长尾分布的驾驶事件可能带来的潜在危险。该方法不仅能够克服相机移动和光照变化对外观方法的干扰，还能够捕捉视频帧中的外观变化，实现对与自身相关的事故的检测。",
    "en_tdlr": "In this paper, we propose a memory-augmented multi-task collaborative framework for unsupervised traffic accident detection in driving videos. The framework overcomes the challenges posed by the long-tailed distribution of driving events and captures appearance changes in video frames, enabling detection of ego-involved accidents."
}