{
    "title": "Learning Multi-Agent Intention-Aware Communication for Optimal Multi-Order Execution in Finance. (arXiv:2307.03119v1 [cs.AI])",
    "abstract": "Order execution is a fundamental task in quantitative finance, aiming at finishing acquisition or liquidation for a number of trading orders of the specific assets. Recent advance in model-free reinforcement learning (RL) provides a data-driven solution to the order execution problem. However, the existing works always optimize execution for an individual order, overlooking the practice that multiple orders are specified to execute simultaneously, resulting in suboptimality and bias. In this paper, we first present a multi-agent RL (MARL) method for multi-order execution considering practical constraints. Specifically, we treat every agent as an individual operator to trade one specific order, while keeping communicating with each other and collaborating for maximizing the overall profits. Nevertheless, the existing MARL algorithms often incorporate communication among agents by exchanging only the information of their partial observations, which is inefficient in complicated financial",
    "link": "http://arxiv.org/abs/2307.03119",
    "context": "Title: Learning Multi-Agent Intention-Aware Communication for Optimal Multi-Order Execution in Finance. (arXiv:2307.03119v1 [cs.AI])\nAbstract: Order execution is a fundamental task in quantitative finance, aiming at finishing acquisition or liquidation for a number of trading orders of the specific assets. Recent advance in model-free reinforcement learning (RL) provides a data-driven solution to the order execution problem. However, the existing works always optimize execution for an individual order, overlooking the practice that multiple orders are specified to execute simultaneously, resulting in suboptimality and bias. In this paper, we first present a multi-agent RL (MARL) method for multi-order execution considering practical constraints. Specifically, we treat every agent as an individual operator to trade one specific order, while keeping communicating with each other and collaborating for maximizing the overall profits. Nevertheless, the existing MARL algorithms often incorporate communication among agents by exchanging only the information of their partial observations, which is inefficient in complicated financial",
    "path": "papers/23/07/2307.03119.json",
    "total_tokens": 876,
    "translated_title": "学习多智能体意图感知通信以实现金融中的最优多订单执行",
    "translated_abstract": "订单执行是量化金融中的一个基本任务，旨在完成特定资产的一系列交易订单的收购或清算。最近无模型强化学习（RL）的进展为订单执行问题提供了一种数据驱动的解决方案。然而，现有的工作总是针对单个订单进行优化，忽视了同时执行多个订单的实践，导致次优性和偏差。在本文中，我们首先提出了一种考虑实际约束的多智能体强化学习（MARL）方法来执行多订单。具体而言，我们将每个智能体视为一个独立的操作员来交易一个特定的订单，同时保持彼此通信并协作以最大化总体利润。然而，现有的MARL算法通常通过仅交换部分观测信息来在智能体之间进行通信，这在复杂的金融环境中是低效的。",
    "tldr": "本文提出了一种多智能体强化学习方法，考虑实际约束下的多订单执行问题。通过智能体之间的通信与协作，最大化整体利润。现有的方法忽视了同时执行多个订单的情况，导致次优性和偏差。",
    "en_tdlr": "This paper proposes a multi-agent reinforcement learning method for multi-order execution problem considering practical constraints. By enabling communication and collaboration among agents, it aims to maximize overall profits. Existing methods overlook the scenario of executing multiple orders simultaneously, resulting in suboptimality and bias."
}