{
    "title": "JoinGym: An Efficient Query Optimization Environment for Reinforcement Learning. (arXiv:2307.11704v1 [cs.LG])",
    "abstract": "In this paper, we present \\textsc{JoinGym}, an efficient and lightweight query optimization environment for reinforcement learning (RL). Join order selection (JOS) is a classic NP-hard combinatorial optimization problem from database query optimization and can serve as a practical testbed for the generalization capabilities of RL algorithms. We describe how to formulate each of the left-deep and bushy variants of the JOS problem as a Markov Decision Process (MDP), and we provide an implementation adhering to the standard Gymnasium API. We highlight that our implementation \\textsc{JoinGym} is completely based on offline traces of all possible joins, which enables RL practitioners to easily and quickly test their methods on a realistic data management problem without needing to setup any systems. Moreover, we also provide all possible join traces on $3300$ novel SQL queries generated from the IMDB dataset. Upon benchmarking popular RL algorithms, we find that at least one method can obta",
    "link": "http://arxiv.org/abs/2307.11704",
    "context": "Title: JoinGym: An Efficient Query Optimization Environment for Reinforcement Learning. (arXiv:2307.11704v1 [cs.LG])\nAbstract: In this paper, we present \\textsc{JoinGym}, an efficient and lightweight query optimization environment for reinforcement learning (RL). Join order selection (JOS) is a classic NP-hard combinatorial optimization problem from database query optimization and can serve as a practical testbed for the generalization capabilities of RL algorithms. We describe how to formulate each of the left-deep and bushy variants of the JOS problem as a Markov Decision Process (MDP), and we provide an implementation adhering to the standard Gymnasium API. We highlight that our implementation \\textsc{JoinGym} is completely based on offline traces of all possible joins, which enables RL practitioners to easily and quickly test their methods on a realistic data management problem without needing to setup any systems. Moreover, we also provide all possible join traces on $3300$ novel SQL queries generated from the IMDB dataset. Upon benchmarking popular RL algorithms, we find that at least one method can obta",
    "path": "papers/23/07/2307.11704.json",
    "total_tokens": 943,
    "translated_title": "JoinGym: 一种高效的强化学习查询优化环境",
    "translated_abstract": "本文介绍了JoinGym，一种高效且轻量级的强化学习查询优化环境。加入顺序选择（JOS）是一个经典的NP-hard组合优化问题，用于数据库查询优化，可作为RL算法泛化能力的实际测试平台。我们描述了如何将左深和繁茂的JOS问题的每个变种形式化为马尔可夫决策过程（MDP），并提供符合标准Gymnasium API的实现。我们强调我们的实现JoinGym完全基于所有可能连接的离线追踪，使RL从业者能够轻松快速地在一个真实的数据管理问题上测试他们的方法，而无需设置任何系统。此外，我们还提供了从IMDB数据集生成的3300个新SQL查询的所有可能连接追踪。在对流行的RL算法进行基准测试时，我们发现至少有一种方法可以获得。",
    "tldr": "本文介绍了JoinGym，一种高效的强化学习查询优化环境。通过将加入顺序选择问题形式化为马尔可夫决策过程，我们提供了一种实现，该实现完全基于离线跟踪，并且无需设置系统即可进行测试。此外，研究还提供了3300个新SQL查询的所有可能加入追踪。"
}