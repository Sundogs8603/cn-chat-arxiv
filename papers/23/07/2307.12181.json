{
    "title": "Security and Privacy Issues of Federated Learning. (arXiv:2307.12181v1 [cs.CR])",
    "abstract": "Federated Learning (FL) has emerged as a promising approach to address data privacy and confidentiality concerns by allowing multiple participants to construct a shared model without centralizing sensitive data. However, this decentralized paradigm introduces new security challenges, necessitating a comprehensive identification and classification of potential risks to ensure FL's security guarantees. This paper presents a comprehensive taxonomy of security and privacy challenges in Federated Learning (FL) across various machine learning models, including large language models. We specifically categorize attacks performed by the aggregator and participants, focusing on poisoning attacks, backdoor attacks, membership inference attacks, generative adversarial network (GAN) based attacks, and differential privacy attacks. Additionally, we propose new directions for future research, seeking innovative solutions to fortify FL systems against emerging security risks and uphold sensitive data ",
    "link": "http://arxiv.org/abs/2307.12181",
    "context": "Title: Security and Privacy Issues of Federated Learning. (arXiv:2307.12181v1 [cs.CR])\nAbstract: Federated Learning (FL) has emerged as a promising approach to address data privacy and confidentiality concerns by allowing multiple participants to construct a shared model without centralizing sensitive data. However, this decentralized paradigm introduces new security challenges, necessitating a comprehensive identification and classification of potential risks to ensure FL's security guarantees. This paper presents a comprehensive taxonomy of security and privacy challenges in Federated Learning (FL) across various machine learning models, including large language models. We specifically categorize attacks performed by the aggregator and participants, focusing on poisoning attacks, backdoor attacks, membership inference attacks, generative adversarial network (GAN) based attacks, and differential privacy attacks. Additionally, we propose new directions for future research, seeking innovative solutions to fortify FL systems against emerging security risks and uphold sensitive data ",
    "path": "papers/23/07/2307.12181.json",
    "total_tokens": 848,
    "translated_title": "联邦学习的安全与隐私问题",
    "translated_abstract": "联邦学习是一种有望解决数据隐私和保密问题的方法，通过允许多个参与者构建共享模型而不集中敏感数据。然而，这种分散的模式引入了新的安全挑战，需要全面识别和分类潜在的风险，以确保联邦学习的安全保证。本文提出了对各种机器学习模型，包括大规模语言模型，联邦学习中安全和隐私挑战的全面分类。我们特别对聚合器和参与者进行了攻击的分类，重点关注毒化攻击、后门攻击、成员推断攻击、生成对抗网络 (GAN) 攻击和差分隐私攻击。此外，我们还提出了未来研究的新方向，寻求创新解决方案以加强联邦学习系统对新兴安全风险的防范，维护敏感数据的安全。",
    "tldr": "本论文提出了对联邦学习中的安全和隐私挑战进行全面分类的分类法，并总结了各种攻击类型和新的研究方向，以加强联邦学习系统对新兴安全风险的防范。",
    "en_tdlr": "This paper presents a comprehensive taxonomy of security and privacy challenges in Federated Learning (FL), categorizing various attack types and proposing new research directions to enhance the security of FL systems against emerging risks."
}