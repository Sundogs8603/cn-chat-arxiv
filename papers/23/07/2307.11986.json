{
    "title": "Expert Knowledge-Aware Image Difference Graph Representation Learning for Difference-Aware Medical Visual Question Answering. (arXiv:2307.11986v1 [cs.CV])",
    "abstract": "To contribute to automating the medical vision-language model, we propose a novel Chest-Xray Difference Visual Question Answering (VQA) task. Given a pair of main and reference images, this task attempts to answer several questions on both diseases and, more importantly, the differences between them. This is consistent with the radiologist's diagnosis practice that compares the current image with the reference before concluding the report. We collect a new dataset, namely MIMIC-Diff-VQA, including 700,703 QA pairs from 164,324 pairs of main and reference images. Compared to existing medical VQA datasets, our questions are tailored to the Assessment-Diagnosis-Intervention-Evaluation treatment procedure used by clinical professionals. Meanwhile, we also propose a novel expert knowledge-aware graph representation learning model to address this task. The proposed baseline model leverages expert knowledge such as anatomical structure prior, semantic, and spatial knowledge to construct a mul",
    "link": "http://arxiv.org/abs/2307.11986",
    "context": "Title: Expert Knowledge-Aware Image Difference Graph Representation Learning for Difference-Aware Medical Visual Question Answering. (arXiv:2307.11986v1 [cs.CV])\nAbstract: To contribute to automating the medical vision-language model, we propose a novel Chest-Xray Difference Visual Question Answering (VQA) task. Given a pair of main and reference images, this task attempts to answer several questions on both diseases and, more importantly, the differences between them. This is consistent with the radiologist's diagnosis practice that compares the current image with the reference before concluding the report. We collect a new dataset, namely MIMIC-Diff-VQA, including 700,703 QA pairs from 164,324 pairs of main and reference images. Compared to existing medical VQA datasets, our questions are tailored to the Assessment-Diagnosis-Intervention-Evaluation treatment procedure used by clinical professionals. Meanwhile, we also propose a novel expert knowledge-aware graph representation learning model to address this task. The proposed baseline model leverages expert knowledge such as anatomical structure prior, semantic, and spatial knowledge to construct a mul",
    "path": "papers/23/07/2307.11986.json",
    "total_tokens": 968,
    "translated_title": "Expert Knowledge-Aware Image Difference Graph Representation Learning for Difference-Aware Medical Visual Question Answering.（专家知识感知的图像变化图表示学习用于关注差异的医学视觉问答）",
    "translated_abstract": "为了为自动化医学视觉语言模型做出贡献，我们提出了一个新颖的胸部X光图像差异视觉问答（VQA）任务。该任务旨在回答几个关于疾病以及更重要的是它们之间差异的问题。这与放射科医生的诊断实践相一致，放射科医生在得出报告之前会对当前图像与参考图像进行比较。我们收集了一个新的数据集，称为MIMIC-Diff-VQA，包括来自164,324对主图像和参考图像的700,703个问题-答案配对。与现有的医学VQA数据集相比，我们的问题针对了临床专业人员使用的评估-诊断-干预-评估治疗过程。同时，我们还提出了一种新的专家知识感知的图表示学习模型来解决这个任务。",
    "tldr": "本研究提出了一个新的医学视觉问答任务，名为MIMIC-Diff-VQA，为自动化医学视觉语言模型做出了贡献。与现有数据集相比，该任务旨在回答关于疾病和图像差异的问题，并应用了专家知识感知的图表示学习模型。",
    "en_tdlr": "This paper proposes a novel Chest-Xray Difference Visual Question Answering (VQA) task, named MIMIC-Diff-VQA, to contribute to automating the medical vision-language model. Compared to existing datasets, this task aims to answer questions about diseases and image differences, and applies an expert knowledge-aware graph representation learning model."
}