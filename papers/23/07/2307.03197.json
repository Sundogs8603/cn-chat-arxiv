{
    "title": "Analyzing the vulnerabilities in SplitFed Learning: Assessing the robustness against Data Poisoning Attacks. (arXiv:2307.03197v1 [cs.LG])",
    "abstract": "Distributed Collaborative Machine Learning (DCML) is a potential alternative to address the privacy concerns associated with centralized machine learning. The Split learning (SL) and Federated Learning (FL) are the two effective learning approaches in DCML. Recently there have been an increased interest on the hybrid of FL and SL known as the SplitFed Learning (SFL). This research is the earliest attempt to study, analyze and present the impact of data poisoning attacks in SFL. We propose three kinds of novel attack strategies namely untargeted, targeted and distance-based attacks for SFL. All the attacks strategies aim to degrade the performance of the DCML-based classifier. We test the proposed attack strategies for two different case studies on Electrocardiogram signal classification and automatic handwritten digit recognition. A series of attack experiments were conducted by varying the percentage of malicious clients and the choice of the model split layer between the clients and ",
    "link": "http://arxiv.org/abs/2307.03197",
    "context": "Title: Analyzing the vulnerabilities in SplitFed Learning: Assessing the robustness against Data Poisoning Attacks. (arXiv:2307.03197v1 [cs.LG])\nAbstract: Distributed Collaborative Machine Learning (DCML) is a potential alternative to address the privacy concerns associated with centralized machine learning. The Split learning (SL) and Federated Learning (FL) are the two effective learning approaches in DCML. Recently there have been an increased interest on the hybrid of FL and SL known as the SplitFed Learning (SFL). This research is the earliest attempt to study, analyze and present the impact of data poisoning attacks in SFL. We propose three kinds of novel attack strategies namely untargeted, targeted and distance-based attacks for SFL. All the attacks strategies aim to degrade the performance of the DCML-based classifier. We test the proposed attack strategies for two different case studies on Electrocardiogram signal classification and automatic handwritten digit recognition. A series of attack experiments were conducted by varying the percentage of malicious clients and the choice of the model split layer between the clients and ",
    "path": "papers/23/07/2307.03197.json",
    "total_tokens": 878,
    "translated_title": "分析SplitFed Learning中的漏洞：评估其对数据污染攻击的鲁棒性",
    "translated_abstract": "分布式协作机器学习（DCML）是解决集中式机器学习中的隐私问题的一种潜在替代方案。Split learning（SL）和联邦学习（FL）是DCML中两种有效的学习方法。最近人们对FL和SL的混合形式SplitFed Learning（SFL）产生了较大兴趣。本研究是对SFL中数据污染攻击进行研究、分析和影响评估的最早尝试。我们提出了三种新的攻击策略，分别是非目标攻击、有目标攻击和基于距离的攻击，用于SFL。所有攻击策略旨在降低基于DCML的分类器的性能。我们对心电图信号分类和手写数字识别这两个不同案例进行了攻击实验，在恶意客户端的百分比和模型拆分层的选择方面进行了变化。",
    "tldr": "本研究对SplitFed Learning中的数据污染攻击进行了研究和分析，并提出了三种新的攻击策略。实验结果表明这些攻击策略可以降低基于DCML的分类器的性能。",
    "en_tdlr": "This study investigates and analyzes data poisoning attacks in SplitFed Learning and proposes three novel attack strategies. Experimental results demonstrate that these attack strategies can degrade the performance of DCML-based classifiers."
}