{
    "title": "Audio-visual End-to-end Multi-channel Speech Separation, Dereverberation and Recognition. (arXiv:2307.02909v1 [eess.AS])",
    "abstract": "Accurate recognition of cocktail party speech containing overlapping speakers, noise and reverberation remains a highly challenging task to date. Motivated by the invariance of visual modality to acoustic signal corruption, an audio-visual multi-channel speech separation, dereverberation and recognition approach featuring a full incorporation of visual information into all system components is proposed in this paper. The efficacy of the video input is consistently demonstrated in mask-based MVDR speech separation, DNN-WPE or spectral mapping (SpecM) based speech dereverberation front-end and Conformer ASR back-end. Audio-visual integrated front-end architectures performing speech separation and dereverberation in a pipelined or joint fashion via mask-based WPD are investigated. The error cost mismatch between the speech enhancement front-end and ASR back-end components is minimized by end-to-end jointly fine-tuning using either the ASR cost function alone, or its interpolation with the",
    "link": "http://arxiv.org/abs/2307.02909",
    "context": "Title: Audio-visual End-to-end Multi-channel Speech Separation, Dereverberation and Recognition. (arXiv:2307.02909v1 [eess.AS])\nAbstract: Accurate recognition of cocktail party speech containing overlapping speakers, noise and reverberation remains a highly challenging task to date. Motivated by the invariance of visual modality to acoustic signal corruption, an audio-visual multi-channel speech separation, dereverberation and recognition approach featuring a full incorporation of visual information into all system components is proposed in this paper. The efficacy of the video input is consistently demonstrated in mask-based MVDR speech separation, DNN-WPE or spectral mapping (SpecM) based speech dereverberation front-end and Conformer ASR back-end. Audio-visual integrated front-end architectures performing speech separation and dereverberation in a pipelined or joint fashion via mask-based WPD are investigated. The error cost mismatch between the speech enhancement front-end and ASR back-end components is minimized by end-to-end jointly fine-tuning using either the ASR cost function alone, or its interpolation with the",
    "path": "papers/23/07/2307.02909.json",
    "total_tokens": 906,
    "translated_title": "视听端到端多通道语音分离、去混响和识别",
    "translated_abstract": "准确识别包含重叠发言者、噪声和混响的混音语音仍然是一项具有挑战性的任务。本文提出了一种视听多通道语音分离、去混响和识别方法，该方法充分将视觉信息融入到所有系统组件中，基于视觉模态与声学信号失真之间的不变性。视频输入在基于掩蔽的MVDR语音分离、基于DNN-WPE或光谱映射（SpecM）的语音去混响前端和Conformer ASR后端中的有效性得到了持续的证明。研究了执行语音分离和去混响的视听一体化前端架构，通过基于掩蔽的WPD以流水线或联合方式进行。通过端到端联合微调，使用ASR成本函数单独或与其线性插值，最小化语音增强前端和ASR后端组件之间的误差成本不匹配。",
    "tldr": "本文提出了一种视听端到端多通道语音分离、去混响和识别方法，该方法充分利用视觉信息，通过减小前后端组件之间的误差成本不匹配来提高语音识别的准确性。",
    "en_tdlr": "This paper proposes an audio-visual end-to-end multi-channel speech separation, dereverberation, and recognition approach that effectively utilizes visual information and improves the accuracy of speech recognition by minimizing the error cost mismatch between the front-end and back-end components."
}