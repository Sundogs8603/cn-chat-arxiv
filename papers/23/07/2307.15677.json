{
    "title": "Adversarial training for tabular data with attack propagation. (arXiv:2307.15677v1 [cs.LG])",
    "abstract": "Adversarial attacks are a major concern in security-centered applications, where malicious actors continuously try to mislead Machine Learning (ML) models into wrongly classifying fraudulent activity as legitimate, whereas system maintainers try to stop them. Adversarially training ML models that are robust against such attacks can prevent business losses and reduce the work load of system maintainers. In such applications data is often tabular and the space available for attackers to manipulate undergoes complex feature engineering transformations, to provide useful signals for model training, to a space attackers cannot access. Thus, we propose a new form of adversarial training where attacks are propagated between the two spaces in the training loop. We then test this method empirically on a real world dataset in the domain of credit card fraud detection. We show that our method can prevent about 30% performance drops under moderate attacks and is essential under very aggressive att",
    "link": "http://arxiv.org/abs/2307.15677",
    "context": "Title: Adversarial training for tabular data with attack propagation. (arXiv:2307.15677v1 [cs.LG])\nAbstract: Adversarial attacks are a major concern in security-centered applications, where malicious actors continuously try to mislead Machine Learning (ML) models into wrongly classifying fraudulent activity as legitimate, whereas system maintainers try to stop them. Adversarially training ML models that are robust against such attacks can prevent business losses and reduce the work load of system maintainers. In such applications data is often tabular and the space available for attackers to manipulate undergoes complex feature engineering transformations, to provide useful signals for model training, to a space attackers cannot access. Thus, we propose a new form of adversarial training where attacks are propagated between the two spaces in the training loop. We then test this method empirically on a real world dataset in the domain of credit card fraud detection. We show that our method can prevent about 30% performance drops under moderate attacks and is essential under very aggressive att",
    "path": "papers/23/07/2307.15677.json",
    "total_tokens": 957,
    "translated_title": "用于表格数据的对抗训练与攻击传播",
    "translated_abstract": "对抗攻击是安全中心应用中的重大关注点，恶意行为者不断试图将机器学习模型误导为将欺诈行为错误地分类为合法行为，而系统维护者则试图阻止他们。对抗性地训练机器学习模型以抵抗此类攻击可以防止业务损失并减轻系统维护者的工作负担。在这种应用中，数据通常是表格形式，攻击者可以利用进行复杂的特征工程转换，为模型训练提供有用信号，而攻击者无法访问。因此，我们提出了一种新的对抗训练形式，在训练循环中在两个空间之间传播攻击。然后，我们在信用卡欺诈检测领域的真实世界数据集上在实证上测试了这种方法。我们证明了我们的方法在面对中等攻击时可以防止约30%的性能下降，并且在非常激烈的攻击下是必不可少的。",
    "tldr": "该论文提出了一种针对表格数据的对抗训练方法，通过在训练循环中传播攻击来提高模型的鲁棒性。在信用卡欺诈检测领域的实证结果表明，该方法可以防止约30%的性能下降，并且对于非常激烈的攻击而言是必不可少的。",
    "en_tdlr": "This paper proposes an adversarial training method for tabular data, where attacks are propagated between two spaces in the training loop to enhance model robustness. Empirical results on credit card fraud detection demonstrate that this method can prevent about 30% performance drops and is essential for very aggressive attacks."
}