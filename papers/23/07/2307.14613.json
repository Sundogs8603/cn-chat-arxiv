{
    "title": "Self-Contrastive Graph Diffusion Network. (arXiv:2307.14613v1 [cs.LG])",
    "abstract": "Augmentation techniques and sampling strategies are crucial in contrastive learning, but in most existing works, augmentation techniques require careful design, and their sampling strategies can only capture a small amount of intrinsic supervision information. Additionally, the existing methods require complex designs to obtain two different representations of the data. To overcome these limitations, we propose a novel framework called the Self-Contrastive Graph Diffusion Network (SCGDN). Our framework consists of two main components: the Attentional Module (AttM) and the Diffusion Module (DiFM). AttM aggregates higher-order structure and feature information to get an excellent embedding, while DiFM balances the state of each node in the graph through Laplacian diffusion learning and allows the cooperative evolution of adjacency and feature information in the graph. Unlike existing methodologies, SCGDN is an augmentation-free approach that avoids \"sampling bias\" and semantic drift, wit",
    "link": "http://arxiv.org/abs/2307.14613",
    "context": "Title: Self-Contrastive Graph Diffusion Network. (arXiv:2307.14613v1 [cs.LG])\nAbstract: Augmentation techniques and sampling strategies are crucial in contrastive learning, but in most existing works, augmentation techniques require careful design, and their sampling strategies can only capture a small amount of intrinsic supervision information. Additionally, the existing methods require complex designs to obtain two different representations of the data. To overcome these limitations, we propose a novel framework called the Self-Contrastive Graph Diffusion Network (SCGDN). Our framework consists of two main components: the Attentional Module (AttM) and the Diffusion Module (DiFM). AttM aggregates higher-order structure and feature information to get an excellent embedding, while DiFM balances the state of each node in the graph through Laplacian diffusion learning and allows the cooperative evolution of adjacency and feature information in the graph. Unlike existing methodologies, SCGDN is an augmentation-free approach that avoids \"sampling bias\" and semantic drift, wit",
    "path": "papers/23/07/2307.14613.json",
    "total_tokens": 919,
    "translated_title": "自对比图扩散网络",
    "translated_abstract": "在对比学习中，增强技术和采样策略非常重要，但在大多数现有工作中，增强技术需要精心设计，而他们的采样策略只能捕捉到一小部分内在的监督信息。此外，现有的方法需要复杂的设计来获得数据的两个不同表示。为了克服这些限制，我们提出了一个新颖的框架，称为自对比图扩散网络（SCGDN）。我们的框架由两个主要组件组成：注意力模块（AttM）和扩散模块（DiFM）。AttM通过汇集高阶结构和特征信息来获得优秀的嵌入，而DiFM通过Laplacian扩散学习平衡图中每个节点的状态，并允许图中邻接和特征信息的协同演化。与现有的方法不同，SCGDN是一种无增强的方法，避免了“采样偏差”和语义漂移问题。",
    "tldr": "提出了一种名为自对比图扩散网络（SCGDN）的新型框架，通过注意力模块和扩散模块实现对高阶结构和特征信息的优秀嵌入。与现有的方法不同，SCGDN是一种无增强的方法，避免了“采样偏差”和语义漂移问题。",
    "en_tdlr": "A novel framework called Self-Contrastive Graph Diffusion Network (SCGDN) is proposed, which achieves excellent embedding of higher-order structure and feature information through Attentional Module and Diffusion Module. Unlike existing methods, SCGDN is an augmentation-free approach that avoids \"sampling bias\" and semantic drift."
}