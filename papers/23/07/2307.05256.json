{
    "title": "Towards exploring adversarial learning for anomaly detection in complex driving scenes. (arXiv:2307.05256v1 [cs.CV])",
    "abstract": "One of the many Autonomous Systems (ASs), such as autonomous driving cars, performs various safety-critical functions. Many of these autonomous systems take advantage of Artificial Intelligence (AI) techniques to perceive their environment. But these perceiving components could not be formally verified, since, the accuracy of such AI-based components has a high dependency on the quality of training data. So Machine learning (ML) based anomaly detection, a technique to identify data that does not belong to the training data could be used as a safety measuring indicator during the development and operational time of such AI-based components. Adversarial learning, a sub-field of machine learning has proven its ability to detect anomalies in images and videos with impressive results on simple data sets. Therefore, in this work, we investigate and provide insight into the performance of such techniques on a highly complex driving scenes dataset called Berkeley DeepDrive.",
    "link": "http://arxiv.org/abs/2307.05256",
    "context": "Title: Towards exploring adversarial learning for anomaly detection in complex driving scenes. (arXiv:2307.05256v1 [cs.CV])\nAbstract: One of the many Autonomous Systems (ASs), such as autonomous driving cars, performs various safety-critical functions. Many of these autonomous systems take advantage of Artificial Intelligence (AI) techniques to perceive their environment. But these perceiving components could not be formally verified, since, the accuracy of such AI-based components has a high dependency on the quality of training data. So Machine learning (ML) based anomaly detection, a technique to identify data that does not belong to the training data could be used as a safety measuring indicator during the development and operational time of such AI-based components. Adversarial learning, a sub-field of machine learning has proven its ability to detect anomalies in images and videos with impressive results on simple data sets. Therefore, in this work, we investigate and provide insight into the performance of such techniques on a highly complex driving scenes dataset called Berkeley DeepDrive.",
    "path": "papers/23/07/2307.05256.json",
    "total_tokens": 808,
    "translated_title": "探索对复杂驾驶场景中的异常检测的对抗学习",
    "translated_abstract": "自动驾驶等自主系统执行各种安全关键功能。这些系统中的许多利用人工智能技术来感知环境。但是这些感知组件无法进行正式验证，因为基于人工智能的组件的准确性高度依赖于训练数据的质量。因此，基于机器学习的异常检测技术，用于识别不属于训练数据的数据，可以作为在开发和运行时安全度量指标使用。对抗学习是机器学习的一个子领域，在简单数据集上已经证明了它对图像和视频中异常的检测能力，取得了令人印象深刻的结果。因此，本研究探讨并深入分析了这些技术在名为伯克利DeepDrive的高度复杂驾驶场景数据集上的性能。",
    "tldr": "本文探索了对复杂驾驶场景中的异常检测使用对抗学习的性能，并分析了名为伯克利DeepDrive的数据集上的结果。",
    "en_tdlr": "This paper explores the performance of using adversarial learning for anomaly detection in complex driving scenes, and analyzes the results on the Berkeley DeepDrive dataset."
}