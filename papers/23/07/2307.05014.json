{
    "title": "Test-Time Training on Video Streams. (arXiv:2307.05014v1 [cs.CV])",
    "abstract": "Prior work has established test-time training (TTT) as a general framework to further improve a trained model at test time. Before making a prediction on each test instance, the model is trained on the same instance using a self-supervised task, such as image reconstruction with masked autoencoders. We extend TTT to the streaming setting, where multiple test instances - video frames in our case - arrive in temporal order. Our extension is online TTT: The current model is initialized from the previous model, then trained on the current frame and a small window of frames immediately before. Online TTT significantly outperforms the fixed-model baseline for four tasks, on three real-world datasets. The relative improvement is 45% and 66% for instance and panoptic segmentation. Surprisingly, online TTT also outperforms its offline variant that accesses more information, training on all frames from the entire test video regardless of temporal order. This differs from previous findings using ",
    "link": "http://arxiv.org/abs/2307.05014",
    "context": "Title: Test-Time Training on Video Streams. (arXiv:2307.05014v1 [cs.CV])\nAbstract: Prior work has established test-time training (TTT) as a general framework to further improve a trained model at test time. Before making a prediction on each test instance, the model is trained on the same instance using a self-supervised task, such as image reconstruction with masked autoencoders. We extend TTT to the streaming setting, where multiple test instances - video frames in our case - arrive in temporal order. Our extension is online TTT: The current model is initialized from the previous model, then trained on the current frame and a small window of frames immediately before. Online TTT significantly outperforms the fixed-model baseline for four tasks, on three real-world datasets. The relative improvement is 45% and 66% for instance and panoptic segmentation. Surprisingly, online TTT also outperforms its offline variant that accesses more information, training on all frames from the entire test video regardless of temporal order. This differs from previous findings using ",
    "path": "papers/23/07/2307.05014.json",
    "total_tokens": 882,
    "translated_title": "视频流上的测试时培训",
    "translated_abstract": "先前的研究已经将测试时培训（TTT）确定为一种在测试时进一步改进训练模型的通用框架。在对每个测试实例进行预测之前，模型会使用自监督任务（例如使用掩蔽自动编码器进行图像重建）在同一实例上进行训练。我们将TTT扩展到流式设置中，其中多个测试实例（在我们的情况下为视频帧）按时间顺序到达。我们的扩展是在线TTT：当前模型从上个模型初始化，然后在当前帧和前几个帧的小窗口上进行训练。在线TTT在四个任务上明显优于固定模型基线，在三个实际数据集上的相对改进分别为45%和66%。令人惊讶的是，在线TTT也优于其离线版本，后者访问更多信息，可以训练所有帧而不考虑时间顺序。这与先前的研究结果不同。",
    "tldr": "该论文扩展了测试时培训（TTT）到视频流的设置中，提出了在线TTT方法，相对于固定模型基线和离线TTT，在多个任务上都有显著的性能优势，包括实例和全景分割。",
    "en_tdlr": "This paper extends test-time training (TTT) to the setting of video streams and proposes an online TTT method that outperforms both the fixed-model baseline and the offline TTT in multiple tasks, including instance and panoptic segmentation."
}