{
    "title": "GIT: Detecting Uncertainty, Out-Of-Distribution and Adversarial Samples using Gradients and Invariance Transformations. (arXiv:2307.02672v1 [cs.LG])",
    "abstract": "Deep neural networks tend to make overconfident predictions and often require additional detectors for misclassifications, particularly for safety-critical applications. Existing detection methods usually only focus on adversarial attacks or out-of-distribution samples as reasons for false predictions. However, generalization errors occur due to diverse reasons often related to poorly learning relevant invariances. We therefore propose GIT, a holistic approach for the detection of generalization errors that combines the usage of gradient information and invariance transformations. The invariance transformations are designed to shift misclassified samples back into the generalization area of the neural network, while the gradient information measures the contradiction between the initial prediction and the corresponding inherent computations of the neural network using the transformed sample. Our experiments demonstrate the superior performance of GIT compared to the state-of-the-art on",
    "link": "http://arxiv.org/abs/2307.02672",
    "context": "Title: GIT: Detecting Uncertainty, Out-Of-Distribution and Adversarial Samples using Gradients and Invariance Transformations. (arXiv:2307.02672v1 [cs.LG])\nAbstract: Deep neural networks tend to make overconfident predictions and often require additional detectors for misclassifications, particularly for safety-critical applications. Existing detection methods usually only focus on adversarial attacks or out-of-distribution samples as reasons for false predictions. However, generalization errors occur due to diverse reasons often related to poorly learning relevant invariances. We therefore propose GIT, a holistic approach for the detection of generalization errors that combines the usage of gradient information and invariance transformations. The invariance transformations are designed to shift misclassified samples back into the generalization area of the neural network, while the gradient information measures the contradiction between the initial prediction and the corresponding inherent computations of the neural network using the transformed sample. Our experiments demonstrate the superior performance of GIT compared to the state-of-the-art on",
    "path": "papers/23/07/2307.02672.json",
    "total_tokens": 914,
    "translated_title": "GIT: 使用梯度和不变性变换检测不确定性、超出分布和对抗样本",
    "translated_abstract": "深度神经网络往往会做出过于自信的预测，并且通常需要额外的检测器来应对错误分类，尤其是对于安全关键的应用。现有的检测方法通常只关注对抗攻击或超出分布样本作为错误预测的原因。然而，通常出现的泛化误差往往与学习相关的不变性有关。因此，我们提出了GIT，一种检测泛化错误的整体方法，该方法结合了梯度信息和不变性变换的使用。不变性变换的设计是将错误分类的样本转回神经网络的泛化区域，而梯度信息则通过测量初始预测与使用转换样本的神经网络的相应固有计算之间的矛盾来衡量。我们的实验结果表明，GIT相对于现有技术具有更优异的性能。",
    "tldr": "该论文提出了GIT，一种综合方法来检测深度神经网络的泛化错误，该方法结合了梯度信息和不变性变换。通过将错分样本转回神经网络的泛化区域，并测量初始预测与使用转换样本的神经网络的相应计算之间的矛盾，GIT相对于现有技术表现出更好的性能。",
    "en_tdlr": "This paper proposes GIT, a holistic approach for detecting generalization errors in deep neural networks by combining gradient information and invariance transformations. By shifting misclassified samples back into the generalization area and measuring the contradiction between the initial prediction and the corresponding computations using transformed samples, GIT outperforms existing methods."
}