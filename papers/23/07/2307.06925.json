{
    "title": "Domain-Agnostic Tuning-Encoder for Fast Personalization of Text-To-Image Models. (arXiv:2307.06925v1 [cs.CV])",
    "abstract": "Text-to-image (T2I) personalization allows users to guide the creative image generation process by combining their own visual concepts in natural language prompts. Recently, encoder-based techniques have emerged as a new effective approach for T2I personalization, reducing the need for multiple images and long training times. However, most existing encoders are limited to a single-class domain, which hinders their ability to handle diverse concepts. In this work, we propose a domain-agnostic method that does not require any specialized dataset or prior information about the personalized concepts. We introduce a novel contrastive-based regularization technique to maintain high fidelity to the target concept characteristics while keeping the predicted embeddings close to editable regions of the latent space, by pushing the predicted tokens toward their nearest existing CLIP tokens. Our experimental results demonstrate the effectiveness of our approach and show how the learned tokens are ",
    "link": "http://arxiv.org/abs/2307.06925",
    "context": "Title: Domain-Agnostic Tuning-Encoder for Fast Personalization of Text-To-Image Models. (arXiv:2307.06925v1 [cs.CV])\nAbstract: Text-to-image (T2I) personalization allows users to guide the creative image generation process by combining their own visual concepts in natural language prompts. Recently, encoder-based techniques have emerged as a new effective approach for T2I personalization, reducing the need for multiple images and long training times. However, most existing encoders are limited to a single-class domain, which hinders their ability to handle diverse concepts. In this work, we propose a domain-agnostic method that does not require any specialized dataset or prior information about the personalized concepts. We introduce a novel contrastive-based regularization technique to maintain high fidelity to the target concept characteristics while keeping the predicted embeddings close to editable regions of the latent space, by pushing the predicted tokens toward their nearest existing CLIP tokens. Our experimental results demonstrate the effectiveness of our approach and show how the learned tokens are ",
    "path": "papers/23/07/2307.06925.json",
    "total_tokens": 934,
    "translated_title": "面向领域通用的调优编码器用于快速个性化文本到图像模型",
    "translated_abstract": "文本到图像（T2I）个性化允许用户通过将自己的视觉概念与自然语言提示相结合来指导创造性图像生成过程。最近，基于编码器的技术已经成为T2I个性化的一种新的有效方法，减少了对多个图像和长时间训练的需求。然而，大多数现有的编码器都局限于单一领域，这限制了它们处理多样化概念的能力。在这项工作中，我们提出了一种领域通用的方法，不需要任何专门的数据集或关于个性化概念的先前信息。我们引入了一种新颖的对比度正则化技术，以保持对目标概念特征的高保真度，同时使预测的嵌入保持接近潜在空间的可编辑区域，通过将预测的标记推向其最近的现有CLIP标记。我们的实验结果证明了我们方法的有效性，并展示了学习到的标记如何",
    "tldr": "提出了一种面向领域通用的方法，在文本到图像个性化中有效地使用编码器技术，同时避免了对特定数据集或先前信息的依赖。引入了对比度正则化技术，以保持高保真度和可编辑性，并通过将预测的标记推向最近的现有标记来实现这一目标。",
    "en_tdlr": "A domain-agnostic method for effective text-to-image personalization using encoder-based techniques is proposed, eliminating the need for specific datasets or prior information. The introduction of contrastive-based regularization maintains high fidelity and editability by pushing predicted tokens towards the nearest existing tokens."
}