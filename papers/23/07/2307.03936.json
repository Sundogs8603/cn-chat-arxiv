{
    "title": "Towards Efficient In-memory Computing Hardware for Quantized Neural Networks: State-of-the-art, Open Challenges and Perspectives. (arXiv:2307.03936v1 [cs.AR])",
    "abstract": "The amount of data processed in the cloud, the development of Internet-of-Things (IoT) applications, and growing data privacy concerns force the transition from cloud-based to edge-based processing. Limited energy and computational resources on edge push the transition from traditional von Neumann architectures to In-memory Computing (IMC), especially for machine learning and neural network applications. Network compression techniques are applied to implement a neural network on limited hardware resources. Quantization is one of the most efficient network compression techniques allowing to reduce the memory footprint, latency, and energy consumption. This paper provides a comprehensive review of IMC-based Quantized Neural Networks (QNN) and links software-based quantization approaches to IMC hardware implementation. Moreover, open challenges, QNN design requirements, recommendations, and perspectives along with an IMC-based QNN hardware roadmap are provided.",
    "link": "http://arxiv.org/abs/2307.03936",
    "context": "Title: Towards Efficient In-memory Computing Hardware for Quantized Neural Networks: State-of-the-art, Open Challenges and Perspectives. (arXiv:2307.03936v1 [cs.AR])\nAbstract: The amount of data processed in the cloud, the development of Internet-of-Things (IoT) applications, and growing data privacy concerns force the transition from cloud-based to edge-based processing. Limited energy and computational resources on edge push the transition from traditional von Neumann architectures to In-memory Computing (IMC), especially for machine learning and neural network applications. Network compression techniques are applied to implement a neural network on limited hardware resources. Quantization is one of the most efficient network compression techniques allowing to reduce the memory footprint, latency, and energy consumption. This paper provides a comprehensive review of IMC-based Quantized Neural Networks (QNN) and links software-based quantization approaches to IMC hardware implementation. Moreover, open challenges, QNN design requirements, recommendations, and perspectives along with an IMC-based QNN hardware roadmap are provided.",
    "path": "papers/23/07/2307.03936.json",
    "total_tokens": 841,
    "translated_title": "面向量化神经网络的高效内存计算硬件：最新进展、开放挑战和展望",
    "translated_abstract": "在云计算中处理的数据量、物联网应用的发展以及日益增长的数据隐私关注，迫使从基于云的处理转向基于边缘的处理。边缘上有限的能量和计算资源推动了从传统冯·诺依曼架构向内存计算（IMC）的过渡，特别是在机器学习和神经网络应用方面。网络压缩技术被应用于在有限的硬件资源上实现神经网络。量化是最高效的网络压缩技术之一，可以减少内存占用、延迟和能量消耗。本文综述了基于IMC的量化神经网络（QNN）并将基于软件的量化方法与IMC硬件实现相结合。此外，还提供了开放挑战，QNN设计要求，建议和展望以及基于IMC的QNN硬件路线图。",
    "tldr": "本文综述了面向量化神经网络的高效内存计算硬件的最新进展和开放挑战，并提供了基于IMC的QNN硬件路线图。",
    "en_tdlr": "This paper provides a comprehensive review of the latest advancements and open challenges in efficient in-memory computing hardware for quantized neural networks (QNN), and presents an IMC-based QNN hardware roadmap."
}