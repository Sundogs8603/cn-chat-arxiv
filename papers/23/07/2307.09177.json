{
    "title": "Intuitive Access to Smartphone Settings Using Relevance Model Trained by Contrastive Learning. (arXiv:2307.09177v1 [cs.IR])",
    "abstract": "The more new features that are being added to smartphones, the harder it becomes for users to find them. This is because the feature names are usually short, and there are just too many to remember. In such a case, the users may want to ask contextual queries that describe the features they are looking for, but the standard term frequency-based search cannot process them. This paper presents a novel retrieval system for mobile features that accepts intuitive and contextual search queries. We trained a relevance model via contrastive learning from a pre-trained language model to perceive the contextual relevance between query embeddings and indexed mobile features. Also, to make it run efficiently on-device using minimal resources, we applied knowledge distillation to compress the model without degrading much performance. To verify the feasibility of our method, we collected test queries and conducted comparative experiments with the currently deployed search baselines. The results show",
    "link": "http://arxiv.org/abs/2307.09177",
    "context": "Title: Intuitive Access to Smartphone Settings Using Relevance Model Trained by Contrastive Learning. (arXiv:2307.09177v1 [cs.IR])\nAbstract: The more new features that are being added to smartphones, the harder it becomes for users to find them. This is because the feature names are usually short, and there are just too many to remember. In such a case, the users may want to ask contextual queries that describe the features they are looking for, but the standard term frequency-based search cannot process them. This paper presents a novel retrieval system for mobile features that accepts intuitive and contextual search queries. We trained a relevance model via contrastive learning from a pre-trained language model to perceive the contextual relevance between query embeddings and indexed mobile features. Also, to make it run efficiently on-device using minimal resources, we applied knowledge distillation to compress the model without degrading much performance. To verify the feasibility of our method, we collected test queries and conducted comparative experiments with the currently deployed search baselines. The results show",
    "path": "papers/23/07/2307.09177.json",
    "total_tokens": 901,
    "translated_title": "使用对比学习训练的相关模型实现对智能手机设置的直观访问",
    "translated_abstract": "随着智能手机增加了越来越多的新功能，用户越来越难以找到它们，因为这些功能的名称通常很短，记不住太多。在这种情况下，用户可能希望提出描述他们要寻找的功能的上下文查询，但标准的基于词频的搜索无法处理它们。本文提出了一种新颖的移动功能检索系统，可以接受直观和上下文的搜索查询。我们通过对比学习从预训练的语言模型中训练了一个相关模型，以感知查询嵌入和索引的移动功能之间的上下文相关性。此外，为了在设备上使用最低资源高效运行，我们应用了知识蒸馏来压缩模型而不降低太多性能。为了验证我们方法的可行性，我们收集了测试查询，并与当前部署的搜索基准进行了比较实验。结果显示",
    "tldr": "本文提出了一种使用对比学习训练的相关模型的移动功能检索系统，该系统可以接受直观和上下文的搜索查询，并通过知识蒸馏进行模型压缩，以在设备上高效运行，并进行了与当前部署的搜索基准的比较实验。"
}