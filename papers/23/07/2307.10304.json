{
    "title": "Polyffusion: A Diffusion Model for Polyphonic Score Generation with Internal and External Controls. (arXiv:2307.10304v1 [cs.SD])",
    "abstract": "We propose Polyffusion, a diffusion model that generates polyphonic music scores by regarding music as image-like piano roll representations. The model is capable of controllable music generation with two paradigms: internal control and external control. Internal control refers to the process in which users pre-define a part of the music and then let the model infill the rest, similar to the task of masked music generation (or music inpainting). External control conditions the model with external yet related information, such as chord, texture, or other features, via the cross-attention mechanism. We show that by using internal and external controls, Polyffusion unifies a wide range of music creation tasks, including melody generation given accompaniment, accompaniment generation given melody, arbitrary music segment inpainting, and music arrangement given chords or textures. Experimental results show that our model significantly outperforms existing Transformer and sampling-based base",
    "link": "http://arxiv.org/abs/2307.10304",
    "context": "Title: Polyffusion: A Diffusion Model for Polyphonic Score Generation with Internal and External Controls. (arXiv:2307.10304v1 [cs.SD])\nAbstract: We propose Polyffusion, a diffusion model that generates polyphonic music scores by regarding music as image-like piano roll representations. The model is capable of controllable music generation with two paradigms: internal control and external control. Internal control refers to the process in which users pre-define a part of the music and then let the model infill the rest, similar to the task of masked music generation (or music inpainting). External control conditions the model with external yet related information, such as chord, texture, or other features, via the cross-attention mechanism. We show that by using internal and external controls, Polyffusion unifies a wide range of music creation tasks, including melody generation given accompaniment, accompaniment generation given melody, arbitrary music segment inpainting, and music arrangement given chords or textures. Experimental results show that our model significantly outperforms existing Transformer and sampling-based base",
    "path": "papers/23/07/2307.10304.json",
    "total_tokens": 929,
    "translated_title": "Polyffusion：一种具有内部和外部控制的多声乐谱生成扩散模型",
    "translated_abstract": "我们提出了Polyffusion，一种以图像化的钢琴滑轮表示将音乐生成为多声乐谱的扩散模型。该模型能够进行可控的音乐生成，有两种范式：内部控制和外部控制。内部控制是指用户预定义音乐的一部分，然后让模型填充剩余部分，类似于掩蔽音乐生成（或音乐修补）的任务。外部控制通过交叉关注机制，将模型与外部但相关的信息(如和弦、质地或其他特征)结合。我们展示了Polyffusion通过使用内部和外部控制，统一了一系列音乐创作任务，包括给定伴奏生成旋律，给定旋律生成伴奏，任意音乐片段修补，以及给定和弦或质地进行音乐编排。实验结果表明，我们的模型在性能上明显优于现有的Transformer和基于采样的基准模型。",
    "tldr": "Polyffusion是一种多声乐谱生成模型，通过内部和外部控制实现可控音乐生成。实验结果表明，该模型在多项音乐创作任务中表现优异，包括给定伴奏生成旋律、给定旋律生成伴奏、音乐片段修补和音乐编排等。",
    "en_tdlr": "Polyffusion is a diffusion model that generates polyphonic music scores with internal and external controls. It unifies various music creation tasks and outperforms existing models in terms of performance."
}