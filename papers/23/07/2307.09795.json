{
    "title": "From West to East: Who can understand the music of the others better?. (arXiv:2307.09795v1 [cs.SD])",
    "abstract": "Recent developments in MIR have led to several benchmark deep learning models whose embeddings can be used for a variety of downstream tasks. At the same time, the vast majority of these models have been trained on Western pop/rock music and related styles. This leads to research questions on whether these models can be used to learn representations for different music cultures and styles, or whether we can build similar music audio embedding models trained on data from different cultures or styles. To that end, we leverage transfer learning methods to derive insights about the similarities between the different music cultures to which the data belongs to. We use two Western music datasets, two traditional/folk datasets coming from eastern Mediterranean cultures, and two datasets belonging to Indian art music. Three deep audio embedding models are trained and transferred across domains, including two CNN-based and a Transformer-based architecture, to perform auto-tagging for each targe",
    "link": "http://arxiv.org/abs/2307.09795",
    "context": "Title: From West to East: Who can understand the music of the others better?. (arXiv:2307.09795v1 [cs.SD])\nAbstract: Recent developments in MIR have led to several benchmark deep learning models whose embeddings can be used for a variety of downstream tasks. At the same time, the vast majority of these models have been trained on Western pop/rock music and related styles. This leads to research questions on whether these models can be used to learn representations for different music cultures and styles, or whether we can build similar music audio embedding models trained on data from different cultures or styles. To that end, we leverage transfer learning methods to derive insights about the similarities between the different music cultures to which the data belongs to. We use two Western music datasets, two traditional/folk datasets coming from eastern Mediterranean cultures, and two datasets belonging to Indian art music. Three deep audio embedding models are trained and transferred across domains, including two CNN-based and a Transformer-based architecture, to perform auto-tagging for each targe",
    "path": "papers/23/07/2307.09795.json",
    "total_tokens": 891,
    "translated_title": "从西方到东方：谁更能理解其他人的音乐？",
    "translated_abstract": "最近，在音乐信息检索领域的发展已经出现了一些基准深度学习模型，这些模型的嵌入可以用于各种下游任务。与此同时，绝大多数这些模型都是在西方流行/摇滚音乐和相关风格上进行训练的。这引发了一个研究问题，即这些模型是否可以用来学习不同音乐文化和风格的表示，或者我们是否可以构建类似的音乐音频嵌入模型，训练数据来自不同的文化或风格。为此，我们利用迁移学习方法来了解数据所属不同音乐文化之间的相似性。我们使用了两个西方音乐数据集，两个来自东地中海文化的传统/民间数据集，以及两个属于印度艺术音乐的数据集。我们训练了三个深度音频嵌入模型，并跨领域进行了转移学习，其中包括两个基于CNN的模型和一个Transformer-based的模型，以在每个目标中进行自动标记。",
    "tldr": "这项研究探讨了基于迁移学习方法的音频嵌入模型在不同音乐文化和风格中的适用性，并提出了关于跨文化音乐理解的研究问题。",
    "en_tdlr": "This research explores the applicability of audio embedding models based on transfer learning methods in different music cultures and styles, and raises research questions about cross-cultural music understanding."
}