{
    "title": "GujiBERT and GujiGPT: Construction of Intelligent Information Processing Foundation Language Models for Ancient Texts. (arXiv:2307.05354v1 [cs.CL])",
    "abstract": "In the context of the rapid development of large language models, we have meticulously trained and introduced the GujiBERT and GujiGPT language models, which are foundational models specifically designed for intelligent information processing of ancient texts. These models have been trained on an extensive dataset that encompasses both simplified and traditional Chinese characters, allowing them to effectively handle various natural language processing tasks related to ancient books, including but not limited to automatic sentence segmentation, punctuation, word segmentation, part-of-speech tagging, entity recognition, and automatic translation. Notably, these models have exhibited exceptional performance across a range of validation tasks using publicly available datasets. Our research findings highlight the efficacy of employing self-supervised methods to further train the models using classical text corpora, thus enhancing their capability to tackle downstream tasks. Moreover, it is",
    "link": "http://arxiv.org/abs/2307.05354",
    "context": "Title: GujiBERT and GujiGPT: Construction of Intelligent Information Processing Foundation Language Models for Ancient Texts. (arXiv:2307.05354v1 [cs.CL])\nAbstract: In the context of the rapid development of large language models, we have meticulously trained and introduced the GujiBERT and GujiGPT language models, which are foundational models specifically designed for intelligent information processing of ancient texts. These models have been trained on an extensive dataset that encompasses both simplified and traditional Chinese characters, allowing them to effectively handle various natural language processing tasks related to ancient books, including but not limited to automatic sentence segmentation, punctuation, word segmentation, part-of-speech tagging, entity recognition, and automatic translation. Notably, these models have exhibited exceptional performance across a range of validation tasks using publicly available datasets. Our research findings highlight the efficacy of employing self-supervised methods to further train the models using classical text corpora, thus enhancing their capability to tackle downstream tasks. Moreover, it is",
    "path": "papers/23/07/2307.05354.json",
    "total_tokens": 840,
    "translated_title": "GujiBERT和GujiGPT：用于古籍智能信息处理的基础语言模型的构建",
    "translated_abstract": "在大型语言模型快速发展的背景下，我们精心训练并引入了GujiBERT和GujiGPT语言模型，这些模型专门设计用于古籍智能信息处理。这些模型在包含简体和繁体中文字符的广泛数据集上进行了训练，能够有效处理与古籍相关的各种自然语言处理任务，包括但不限于自动句子分割、标点符号、词语分割、词性标注、实体识别和自动翻译等。值得注意的是，这些模型在使用公开可获得的数据集进行各种验证任务时展现了出色的性能。我们的研究结果强调了采用自监督方法进一步训练模型使用古典文本语料库的有效性，从而增强了模型处理下游任务的能力。",
    "tldr": "GujiBERT和GujiGPT是专为古籍智能信息处理而设计的基础语言模型，通过采用自监督方法进一步训练模型，可以有效处理与古籍相关的各种自然语言处理任务。",
    "en_tdlr": "GujiBERT and GujiGPT are foundational language models specifically designed for intelligent information processing of ancient texts, and their performance in various natural language processing tasks related to ancient books has been greatly enhanced by employing self-supervised methods for further training."
}