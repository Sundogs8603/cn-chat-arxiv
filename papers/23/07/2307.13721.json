{
    "title": "Foundational Models Defining a New Era in Vision: A Survey and Outlook. (arXiv:2307.13721v1 [cs.CV])",
    "abstract": "Vision systems to see and reason about the compositional nature of visual scenes are fundamental to understanding our world. The complex relations between objects and their locations, ambiguities, and variations in the real-world environment can be better described in human language, naturally governed by grammatical rules and other modalities such as audio and depth. The models learned to bridge the gap between such modalities coupled with large-scale training data facilitate contextual reasoning, generalization, and prompt capabilities at test time. These models are referred to as foundational models. The output of such models can be modified through human-provided prompts without retraining, e.g., segmenting a particular object by providing a bounding box, having interactive dialogues by asking questions about an image or video scene or manipulating the robot's behavior through language instructions. In this survey, we provide a comprehensive review of such emerging foundational mod",
    "link": "http://arxiv.org/abs/2307.13721",
    "context": "Title: Foundational Models Defining a New Era in Vision: A Survey and Outlook. (arXiv:2307.13721v1 [cs.CV])\nAbstract: Vision systems to see and reason about the compositional nature of visual scenes are fundamental to understanding our world. The complex relations between objects and their locations, ambiguities, and variations in the real-world environment can be better described in human language, naturally governed by grammatical rules and other modalities such as audio and depth. The models learned to bridge the gap between such modalities coupled with large-scale training data facilitate contextual reasoning, generalization, and prompt capabilities at test time. These models are referred to as foundational models. The output of such models can be modified through human-provided prompts without retraining, e.g., segmenting a particular object by providing a bounding box, having interactive dialogues by asking questions about an image or video scene or manipulating the robot's behavior through language instructions. In this survey, we provide a comprehensive review of such emerging foundational mod",
    "path": "papers/23/07/2307.13721.json",
    "total_tokens": 857,
    "translated_title": "视觉的一个新时代定义的基础模型: 一项调查和展望",
    "translated_abstract": "视觉系统以观察和推理视觉场景的组成性质为基础，对于理解我们的世界至关重要。对象之间的复杂关系以及它们在真实环境中的位置、歧义和变化可以更好地用人类语言描述，这种语言通常受到语法规则和其他模态（如音频和深度）的约束。这些模型学习了如何弥合这些模态之间的差距，并结合大规模的训练数据，促进了上下文推理、泛化以及测试时的即时能力。这些模型被称为基础模型。这些模型的输出可以通过人类提供的提示进行修改，无需重新训练，例如通过提供边界框对特定对象进行分割，通过询问关于图像或视频场景的问题实现互动对话，或通过语言指令对机器人的行为进行操作。在本调查中，我们对这些新兴的基础模型进行了全面的回顾。",
    "tldr": "这项调查提供了对新兴基础模型的全面回顾，这些模型能够通过人类提供的提示实现上下文推理、生成泛化的结果，并在测试时具有即时能力。",
    "en_tdlr": "This survey provides a comprehensive review of emerging foundational models, which are capable of contextual reasoning and generating generalized results through human-provided prompts, while exhibiting prompt capabilities at test time."
}