{
    "title": "On the Cultural Gap in Text-to-Image Generation. (arXiv:2307.02971v1 [cs.CV])",
    "abstract": "One challenge in text-to-image (T2I) generation is the inadvertent reflection of culture gaps present in the training data, which signifies the disparity in generated image quality when the cultural elements of the input text are rarely collected in the training set. Although various T2I models have shown impressive but arbitrary examples, there is no benchmark to systematically evaluate a T2I model's ability to generate cross-cultural images. To bridge the gap, we propose a Challenging Cross-Cultural (C3) benchmark with comprehensive evaluation criteria, which can assess how well-suited a model is to a target culture. By analyzing the flawed images generated by the Stable Diffusion model on the C3 benchmark, we find that the model often fails to generate certain cultural objects. Accordingly, we propose a novel multi-modal metric that considers object-text alignment to filter the fine-tuning data in the target culture, which is used to fine-tune a T2I model to improve cross-cultural g",
    "link": "http://arxiv.org/abs/2307.02971",
    "context": "Title: On the Cultural Gap in Text-to-Image Generation. (arXiv:2307.02971v1 [cs.CV])\nAbstract: One challenge in text-to-image (T2I) generation is the inadvertent reflection of culture gaps present in the training data, which signifies the disparity in generated image quality when the cultural elements of the input text are rarely collected in the training set. Although various T2I models have shown impressive but arbitrary examples, there is no benchmark to systematically evaluate a T2I model's ability to generate cross-cultural images. To bridge the gap, we propose a Challenging Cross-Cultural (C3) benchmark with comprehensive evaluation criteria, which can assess how well-suited a model is to a target culture. By analyzing the flawed images generated by the Stable Diffusion model on the C3 benchmark, we find that the model often fails to generate certain cultural objects. Accordingly, we propose a novel multi-modal metric that considers object-text alignment to filter the fine-tuning data in the target culture, which is used to fine-tune a T2I model to improve cross-cultural g",
    "path": "papers/23/07/2307.02971.json",
    "total_tokens": 944,
    "translated_title": "关于文本到图像生成中的文化差异",
    "translated_abstract": "文本到图像（T2I）生成中的一个挑战是在训练数据中意外反映了文化差距，当输入文本的文化元素很少出现在训练集中时，这表明生成图像的质量差异。尽管各种T2I模型展示了令人印象深刻但是随意的例子，但是目前没有一个基准来系统评估T2I模型生成跨文化图像的能力。为了弥补这一差距，我们提出了一个具有综合评估标准的具有挑战性的跨文化（C3）基准，该基准可以评估模型对目标文化的适应性。通过分析在C3基准上由稳定扩散模型生成的有缺陷的图像，我们发现该模型经常无法生成特定的文化对象。因此，我们提出了一种考虑对象与文本对齐的新型多模态度量，用于过滤目标文化中的微调数据，用于优化跨文化能力的T2I模型。",
    "tldr": "该论文研究文本到图像生成中的文化差异，并提出了一个具有挑战性的跨文化基准，通过分析已有模型在该基准上生成的有缺陷的图像，提出了使用对象-文本对齐的多模态度量来优化跨文化模型的微调数据。",
    "en_tdlr": "This paper investigates the cultural gap in text-to-image generation and proposes a challenging cross-cultural benchmark. By analyzing the flawed images generated by existing models on this benchmark, a novel multi-modal metric considering object-text alignment is introduced to optimize the fine-tuning data for cross-cultural models."
}