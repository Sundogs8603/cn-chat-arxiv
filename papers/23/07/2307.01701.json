{
    "title": "Synthetic is all you need: removing the auxiliary data assumption for membership inference attacks against synthetic data. (arXiv:2307.01701v1 [cs.CR])",
    "abstract": "Synthetic data is emerging as the most promising solution to share individual-level data while safeguarding privacy. Membership inference attacks (MIAs), based on shadow modeling, have become the standard to evaluate the privacy of synthetic data. These attacks, however, currently assume the attacker to have access to an auxiliary dataset sampled from a similar distribution as the training dataset. This often is a very strong assumption that would make an attack unlikely to happen in practice. We here show how this assumption can be removed and how MIAs can be performed using only the synthetic data. More specifically, in three different attack scenarios using only synthetic data, our results demonstrate that MIAs are still successful, across two real-world datasets and two synthetic data generators. These results show how the strong hypothesis made when auditing synthetic data releases access to an auxiliary dataset - can be relaxed to perform an actual attack.",
    "link": "http://arxiv.org/abs/2307.01701",
    "context": "Title: Synthetic is all you need: removing the auxiliary data assumption for membership inference attacks against synthetic data. (arXiv:2307.01701v1 [cs.CR])\nAbstract: Synthetic data is emerging as the most promising solution to share individual-level data while safeguarding privacy. Membership inference attacks (MIAs), based on shadow modeling, have become the standard to evaluate the privacy of synthetic data. These attacks, however, currently assume the attacker to have access to an auxiliary dataset sampled from a similar distribution as the training dataset. This often is a very strong assumption that would make an attack unlikely to happen in practice. We here show how this assumption can be removed and how MIAs can be performed using only the synthetic data. More specifically, in three different attack scenarios using only synthetic data, our results demonstrate that MIAs are still successful, across two real-world datasets and two synthetic data generators. These results show how the strong hypothesis made when auditing synthetic data releases access to an auxiliary dataset - can be relaxed to perform an actual attack.",
    "path": "papers/23/07/2307.01701.json",
    "total_tokens": 844,
    "translated_title": "合成就是你需要的：移除针对合成数据的成员推断攻击的辅助数据假设",
    "translated_abstract": "合成数据正在成为在保护隐私的同时共享个体级数据的最有希望的解决方案。基于影子建模的成员推断攻击已经成为评估合成数据隐私的标准。然而，这些攻击目前假设攻击者可以访问与训练数据集的类似分布的辅助数据集。这往往是一个非常强的假设，在实践中很难发生攻击。我们在这里展示了如何移除这个假设，以及如何仅使用合成数据进行成员推断攻击。具体而言，在三种不同的攻击场景中仅使用合成数据，我们的结果表明，成员推断攻击仍然成功，涉及两个真实世界数据集和两个合成数据生成器。这些结果表明，在审计合成数据发布访问辅助数据集的强假设可以放松以进行实际攻击。",
    "tldr": "这项研究提出了一种新方法，移除了成员推断攻击对辅助数据的假设，使用只有合成数据的情况下仍然能够成功进行成员推断攻击。"
}