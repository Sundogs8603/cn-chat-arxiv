{
    "title": "Pareto-Secure Machine Learning (PSML): Fingerprinting and Securing Inference Serving Systems. (arXiv:2307.01292v1 [cs.CR])",
    "abstract": "With the emergence of large foundational models, model-serving systems are becoming popular. In such a system, users send the queries to the server and specify the desired performance metrics (e.g., accuracy, latency, etc.). The server maintains a set of models (model zoo) in the back-end and serves the queries based on the specified metrics. This paper examines the security, specifically robustness against model extraction attacks, of such systems. Existing black-box attacks cannot be directly applied to extract a victim model, as models hide among the model zoo behind the inference serving interface, and attackers cannot identify which model is being used. An intermediate step is required to ensure that every input query gets the output from the victim model. To this end, we propose a query-efficient fingerprinting algorithm to enable the attacker to trigger any desired model consistently. We show that by using our fingerprinting algorithm, model extraction can have fidelity and accu",
    "link": "http://arxiv.org/abs/2307.01292",
    "context": "Title: Pareto-Secure Machine Learning (PSML): Fingerprinting and Securing Inference Serving Systems. (arXiv:2307.01292v1 [cs.CR])\nAbstract: With the emergence of large foundational models, model-serving systems are becoming popular. In such a system, users send the queries to the server and specify the desired performance metrics (e.g., accuracy, latency, etc.). The server maintains a set of models (model zoo) in the back-end and serves the queries based on the specified metrics. This paper examines the security, specifically robustness against model extraction attacks, of such systems. Existing black-box attacks cannot be directly applied to extract a victim model, as models hide among the model zoo behind the inference serving interface, and attackers cannot identify which model is being used. An intermediate step is required to ensure that every input query gets the output from the victim model. To this end, we propose a query-efficient fingerprinting algorithm to enable the attacker to trigger any desired model consistently. We show that by using our fingerprinting algorithm, model extraction can have fidelity and accu",
    "path": "papers/23/07/2307.01292.json",
    "total_tokens": 897,
    "translated_title": "Pareto-安全的机器学习（PSML）：指纹和保护推断服务系统。",
    "translated_abstract": "随着大型基础模型的出现，模型服务系统越来越受欢迎。在这样的系统中，用户将查询发送到服务器，并指定所需的性能指标（例如准确性、延迟等）。服务器在后端维护一组模型（模型库），并根据指定的指标提供查询服务。本文研究了这些系统的安全性，特别是对模型提取攻击的鲁棒性。现有的黑盒攻击不能直接应用于提取受害模型，因为模型隐藏在推理服务接口背后的模型库中，攻击者无法确定使用的是哪个模型。需要一个中间步骤来确保每个输入查询都能得到受害模型的输出。为此，我们提出了一种查询高效的指纹算法，使攻击者能够一致地触发任何想要的模型。我们证明，通过使用我们的指纹算法，模型提取可以具有保真度和准确性。",
    "tldr": "本论文研究了模型服务系统的安全性，通过引入一个查询高效的指纹算法，使得攻击者能够一致地触发任何想要的模型，从而增强了对模型提取攻击的鲁棒性和准确性。"
}