{
    "title": "TF-ICON: Diffusion-Based Training-Free Cross-Domain Image Composition. (arXiv:2307.12493v2 [cs.CV] UPDATED)",
    "abstract": "Text-driven diffusion models have exhibited impressive generative capabilities, enabling various image editing tasks. In this paper, we propose TF-ICON, a novel Training-Free Image COmpositioN framework that harnesses the power of text-driven diffusion models for cross-domain image-guided composition. This task aims to seamlessly integrate user-provided objects into a specific visual context. Current diffusion-based methods often involve costly instance-based optimization or finetuning of pretrained models on customized datasets, which can potentially undermine their rich prior. In contrast, TF-ICON can leverage off-the-shelf diffusion models to perform cross-domain image-guided composition without requiring additional training, finetuning, or optimization. Moreover, we introduce the exceptional prompt, which contains no information, to facilitate text-driven diffusion models in accurately inverting real images into latent representations, forming the basis for compositing. Our experim",
    "link": "http://arxiv.org/abs/2307.12493",
    "context": "Title: TF-ICON: Diffusion-Based Training-Free Cross-Domain Image Composition. (arXiv:2307.12493v2 [cs.CV] UPDATED)\nAbstract: Text-driven diffusion models have exhibited impressive generative capabilities, enabling various image editing tasks. In this paper, we propose TF-ICON, a novel Training-Free Image COmpositioN framework that harnesses the power of text-driven diffusion models for cross-domain image-guided composition. This task aims to seamlessly integrate user-provided objects into a specific visual context. Current diffusion-based methods often involve costly instance-based optimization or finetuning of pretrained models on customized datasets, which can potentially undermine their rich prior. In contrast, TF-ICON can leverage off-the-shelf diffusion models to perform cross-domain image-guided composition without requiring additional training, finetuning, or optimization. Moreover, we introduce the exceptional prompt, which contains no information, to facilitate text-driven diffusion models in accurately inverting real images into latent representations, forming the basis for compositing. Our experim",
    "path": "papers/23/07/2307.12493.json",
    "total_tokens": 1009,
    "translated_title": "TF-ICON: 基于扩散的无需训练的跨领域图像合成",
    "translated_abstract": "文字驱动的扩散模型展示出令人印象深刻的生成能力，可以实现各种图像编辑任务。在本文中，我们提出了TF-ICON，一种新颖的无需训练的图像合成框架，利用文字驱动的扩散模型来进行跨领域图像导向合成。该任务旨在将用户提供的对象无缝地整合到特定的视觉环境中。目前的基于扩散的方法通常涉及昂贵的基于实例的优化或在定制数据集上微调预训练模型，可能会损害其丰富的先验知识。相反，TF-ICON可以利用现成的扩散模型进行跨领域图像导向合成，无需额外的训练、微调或优化。此外，我们引入了例外提示(含无信息)来帮助文字驱动的扩散模型准确地将真实图像反转为潜在表示，为合成提供基础。我们的实验结果表明，TF-ICON在不同的合成任务中具有优越的表现，并且可以在不同领域的图像之间进行高质量的无缝合成。",
    "tldr": "TF-ICON是一种无需训练的图像合成框架，利用文字驱动的扩散模型实现跨领域图像导向合成。与传统方法相比，TF-ICON可以在不需额外训练、微调或优化的情况下实现高质量的无缝合成，同时引入了例外提示来准确地反转真实图像为潜在表示。"
}