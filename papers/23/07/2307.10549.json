{
    "title": "Dynamic Large Language Models on Blockchains. (arXiv:2307.10549v1 [cs.CV])",
    "abstract": "Training and deploying the large language models requires a large mount of computational resource because the language models contain billions of parameters and the text has thousands of tokens. Another problem is that the large language models are static. They are fixed after the training process. To tackle these issues, in this paper, we propose to train and deploy the dynamic large language model on blockchains, which have high computation performance and are distributed across a network of computers. A blockchain is a secure, decentralized, and transparent system that allows for the creation of a tamper-proof ledger for transactions without the need for intermediaries. The dynamic large language models can continuously learn from the user input after the training process. Our method provides a new way to develop the large language models and also sheds a light on the next generation artificial intelligence systems.",
    "link": "http://arxiv.org/abs/2307.10549",
    "context": "Title: Dynamic Large Language Models on Blockchains. (arXiv:2307.10549v1 [cs.CV])\nAbstract: Training and deploying the large language models requires a large mount of computational resource because the language models contain billions of parameters and the text has thousands of tokens. Another problem is that the large language models are static. They are fixed after the training process. To tackle these issues, in this paper, we propose to train and deploy the dynamic large language model on blockchains, which have high computation performance and are distributed across a network of computers. A blockchain is a secure, decentralized, and transparent system that allows for the creation of a tamper-proof ledger for transactions without the need for intermediaries. The dynamic large language models can continuously learn from the user input after the training process. Our method provides a new way to develop the large language models and also sheds a light on the next generation artificial intelligence systems.",
    "path": "papers/23/07/2307.10549.json",
    "total_tokens": 823,
    "translated_title": "区块链上的动态大型语言模型",
    "translated_abstract": "训练和部署大型语言模型需要大量的计算资源，因为语言模型包含数十亿个参数，文本拥有数千个标记。另一个问题是大型语言模型是静态的，在训练过程后就被固定下来了。为了解决这些问题，本文提出在区块链上训练和部署动态大型语言模型，区块链具有高计算性能并分布在一个计算机网络上。区块链是一个安全、分散和透明的系统，允许创建一个无法篡改的交易分类帐，无需中介机构。动态大型语言模型可以在训练过程之后不断从用户输入中学习。我们的方法提供了一种开发大型语言模型的新方法，并为下一代人工智能系统带来了启示。",
    "tldr": "本文提出在区块链上训练和部署动态大型语言模型，通过使用分布式计算和提供无法篡改的交易分类帐的区块链技术，可使语言模型具备连续学习的能力，为下一代人工智能系统的发展提供了新的方法和启示。",
    "en_tdlr": "This paper proposes training and deploying dynamic large language models on blockchains, enabling continuous learning and providing a tamper-proof ledger for transactions. It offers a new approach and insights for the development of next generation artificial intelligence systems."
}