{
    "title": "Teach model to answer questions after comprehending the document. (arXiv:2307.08931v1 [cs.CL])",
    "abstract": "Multi-choice Machine Reading Comprehension (MRC) is a challenging extension of Natural Language Processing (NLP) that requires the ability to comprehend the semantics and logical relationships between entities in a given text. The MRC task has traditionally been viewed as a process of answering questions based on the given text. This single-stage approach has often led the network to concentrate on generating the correct answer, potentially neglecting the comprehension of the text itself. As a result, many prevalent models have faced challenges in performing well on this task when dealing with longer texts. In this paper, we propose a two-stage knowledge distillation method that teaches the model to better comprehend the document by dividing the MRC task into two separate stages. Our experimental results show that the student model, when equipped with our method, achieves significant improvements, demonstrating the effectiveness of our method.",
    "link": "http://arxiv.org/abs/2307.08931",
    "context": "Title: Teach model to answer questions after comprehending the document. (arXiv:2307.08931v1 [cs.CL])\nAbstract: Multi-choice Machine Reading Comprehension (MRC) is a challenging extension of Natural Language Processing (NLP) that requires the ability to comprehend the semantics and logical relationships between entities in a given text. The MRC task has traditionally been viewed as a process of answering questions based on the given text. This single-stage approach has often led the network to concentrate on generating the correct answer, potentially neglecting the comprehension of the text itself. As a result, many prevalent models have faced challenges in performing well on this task when dealing with longer texts. In this paper, we propose a two-stage knowledge distillation method that teaches the model to better comprehend the document by dividing the MRC task into two separate stages. Our experimental results show that the student model, when equipped with our method, achieves significant improvements, demonstrating the effectiveness of our method.",
    "path": "papers/23/07/2307.08931.json",
    "total_tokens": 823,
    "translated_title": "教模型在理解文档后回答问题",
    "translated_abstract": "多选机器阅读理解(MRC)是自然语言处理(NLP)的一个具有挑战性的扩展，需要理解给定文本中实体之间的语义和逻辑关系的能力。传统上，MRC任务被视为根据给定文本回答问题的过程。这种单阶段方法往往使网络专注于生成正确答案，可能忽视了对文本本身的理解。因此，许多流行的模型在处理较长的文本时在这个任务上面临挑战。在本文中，我们提出了一种两阶段的知识蒸馏方法，通过将MRC任务分为两个独立的阶段来教导模型更好地理解文档。我们的实验结果表明，当学生模型配备我们的方法时，取得了显著的改进，展示了我们方法的有效性。",
    "tldr": "本文提出了一种两阶段知识蒸馏方法，通过将MRC任务分为两个独立的阶段来教导模型更好地理解文档。实验证明，该方法显著提高了学生模型的性能。",
    "en_tdlr": "This paper proposes a two-stage knowledge distillation method that teaches the model to better comprehend the document by dividing the MRC task into two separate stages. The experimental results demonstrate the significant improvements in the performance of the student model with the proposed method."
}