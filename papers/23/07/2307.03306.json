{
    "title": "When Fair Classification Meets Noisy Protected Attributes. (arXiv:2307.03306v1 [cs.LG])",
    "abstract": "The operationalization of algorithmic fairness comes with several practical challenges, not the least of which is the availability or reliability of protected attributes in datasets. In real-world contexts, practical and legal impediments may prevent the collection and use of demographic data, making it difficult to ensure algorithmic fairness. While initial fairness algorithms did not consider these limitations, recent proposals aim to achieve algorithmic fairness in classification by incorporating noisiness in protected attributes or not using protected attributes at all.  To the best of our knowledge, this is the first head-to-head study of fair classification algorithms to compare attribute-reliant, noise-tolerant and attribute-blind algorithms along the dual axes of predictivity and fairness. We evaluated these algorithms via case studies on four real-world datasets and synthetic perturbations. Our study reveals that attribute-blind and noise-tolerant fair classifiers can potentia",
    "link": "http://arxiv.org/abs/2307.03306",
    "context": "Title: When Fair Classification Meets Noisy Protected Attributes. (arXiv:2307.03306v1 [cs.LG])\nAbstract: The operationalization of algorithmic fairness comes with several practical challenges, not the least of which is the availability or reliability of protected attributes in datasets. In real-world contexts, practical and legal impediments may prevent the collection and use of demographic data, making it difficult to ensure algorithmic fairness. While initial fairness algorithms did not consider these limitations, recent proposals aim to achieve algorithmic fairness in classification by incorporating noisiness in protected attributes or not using protected attributes at all.  To the best of our knowledge, this is the first head-to-head study of fair classification algorithms to compare attribute-reliant, noise-tolerant and attribute-blind algorithms along the dual axes of predictivity and fairness. We evaluated these algorithms via case studies on four real-world datasets and synthetic perturbations. Our study reveals that attribute-blind and noise-tolerant fair classifiers can potentia",
    "path": "papers/23/07/2307.03306.json",
    "total_tokens": 918,
    "translated_title": "当公平分类遇到嘈杂的保护属性",
    "translated_abstract": "算法公平性的实施面临着许多实际挑战，其中之一就是数据集中受保护属性的可用性或可靠性。在现实世界的环境中，实际和法律上的障碍可能会阻止收集和使用人口统计数据，使得确保算法公平性变得困难。尽管最初的公平算法没有考虑这些限制，但最近的提议旨在通过将受保护属性的嘈杂性纳入考虑或根本不使用受保护属性来实现分类的算法公平性。据我们所知，这是首次对比基于属性、容忍噪声和盲目属性的公平分类算法在预测性和公平性这两个方面进行头对头研究。我们通过对四个真实数据集和合成扰动的案例研究评估了这些算法。我们的研究表明，盲目属性和容忍噪声的公平分类器可能会在预测性和公平性的双重轴上有潜力。",
    "tldr": "这项研究是对公平分类算法进行的一次首次的头对头比较，研究了依赖属性、容忍噪声和盲目属性的算法在预测性和公平性方面的表现，结果显示盲目属性和容忍噪声的公平分类器具有潜力。",
    "en_tdlr": "This study is a first head-to-head comparison of fair classification algorithms, comparing attribute-reliant, noise-tolerant, and attribute-blind algorithms in terms of predictivity and fairness. The results show that attribute-blind and noise-tolerant fair classifiers have potential."
}