{
    "title": "Over-the-Counter Market Making via Reinforcement Learning. (arXiv:2307.01816v1 [q-fin.TR])",
    "abstract": "The over-the-counter (OTC) market is characterized by a unique feature that allows market makers to adjust bid-ask spreads based on order size. However, this flexibility introduces complexity, transforming the market-making problem into a high-dimensional stochastic control problem that presents significant challenges. To address this, this paper proposes an innovative solution utilizing reinforcement learning techniques to tackle the OTC market-making problem. By assuming a linear inverse relationship between market order arrival intensity and bid-ask spreads, we demonstrate the optimal policy for bid-ask spreads follows a Gaussian distribution. We apply two reinforcement learning algorithms to conduct a numerical analysis, revealing the resulting return distribution and bid-ask spreads under different time and inventory levels.",
    "link": "http://arxiv.org/abs/2307.01816",
    "context": "Title: Over-the-Counter Market Making via Reinforcement Learning. (arXiv:2307.01816v1 [q-fin.TR])\nAbstract: The over-the-counter (OTC) market is characterized by a unique feature that allows market makers to adjust bid-ask spreads based on order size. However, this flexibility introduces complexity, transforming the market-making problem into a high-dimensional stochastic control problem that presents significant challenges. To address this, this paper proposes an innovative solution utilizing reinforcement learning techniques to tackle the OTC market-making problem. By assuming a linear inverse relationship between market order arrival intensity and bid-ask spreads, we demonstrate the optimal policy for bid-ask spreads follows a Gaussian distribution. We apply two reinforcement learning algorithms to conduct a numerical analysis, revealing the resulting return distribution and bid-ask spreads under different time and inventory levels.",
    "path": "papers/23/07/2307.01816.json",
    "total_tokens": 769,
    "translated_title": "通过强化学习进行场外市场做市",
    "translated_abstract": "场外市场具有一种独特的特点，允许市场做市商根据订单大小调整买卖价差。然而，这种灵活性引入了复杂性，将市场做市问题转化为高维度的随机控制问题，提出了重大挑战。为了解决这个问题，本文提出了一种创新的解决方案，利用强化学习技术来应对场外市场做市问题。假设市场订单到达强度与买卖价差之间存在线性逆关系，我们证明了买卖价差的最优策略遵循高斯分布。我们应用两种强化学习算法进行数值分析，揭示了在不同的时间和库存水平下得到的收益分布和买卖价差。",
    "tldr": "本文提出了一个创新的强化学习方法来解决场外市场做市问题，并通过数值分析展示了在不同时间和库存水平下收益分布和买卖价差的最优策略。"
}