{
    "title": "Learning to Retrieve In-Context Examples for Large Language Models. (arXiv:2307.07164v1 [cs.CL])",
    "abstract": "Large language models (LLMs) have demonstrated their ability to learn in-context, allowing them to perform various tasks based on a few input-output examples. However, the effectiveness of in-context learning is heavily reliant on the quality of the selected examples. In this paper, we propose a novel framework to iteratively train dense retrievers that can identify high-quality in-context examples for LLMs. Our framework initially trains a reward model based on LLM feedback to evaluate the quality of candidate examples, followed by knowledge distillation to train a bi-encoder based dense retriever. Our experiments on a suite of 30 tasks demonstrate that our framework significantly enhances in-context learning performance. Furthermore, we show the generalization ability of our framework to unseen tasks during training. An in-depth analysis reveals that our model improves performance by retrieving examples with similar patterns, and the gains are consistent across LLMs of varying sizes.",
    "link": "http://arxiv.org/abs/2307.07164",
    "context": "Title: Learning to Retrieve In-Context Examples for Large Language Models. (arXiv:2307.07164v1 [cs.CL])\nAbstract: Large language models (LLMs) have demonstrated their ability to learn in-context, allowing them to perform various tasks based on a few input-output examples. However, the effectiveness of in-context learning is heavily reliant on the quality of the selected examples. In this paper, we propose a novel framework to iteratively train dense retrievers that can identify high-quality in-context examples for LLMs. Our framework initially trains a reward model based on LLM feedback to evaluate the quality of candidate examples, followed by knowledge distillation to train a bi-encoder based dense retriever. Our experiments on a suite of 30 tasks demonstrate that our framework significantly enhances in-context learning performance. Furthermore, we show the generalization ability of our framework to unseen tasks during training. An in-depth analysis reveals that our model improves performance by retrieving examples with similar patterns, and the gains are consistent across LLMs of varying sizes.",
    "path": "papers/23/07/2307.07164.json",
    "total_tokens": 925,
    "translated_title": "学习为大型语言模型检索上下文示例",
    "translated_abstract": "大型语言模型（LLMs）展示了它们在上下文中学习的能力，使它们能够根据少量的输入-输出示例执行各种任务。然而，上下文学习的有效性在很大程度上依赖于所选示例的质量。在本文中，我们提出了一个新颖的框架，通过迭代训练密集检索器，可以为LLMs识别高质量的上下文示例。我们的框架首先训练基于LLM反馈的奖励模型来评估候选示例的质量，然后通过知识蒸馏训练基于双编码器的密集检索器。我们在30个任务套件上的实验证明，我们的框架显著提高了上下文学习性能。此外，我们还展示了我们的框架在训练期间对未见过任务的泛化能力。深入分析表明，我们的模型通过检索具有相似模式的示例来提高性能，而这种增益在不同规模的LLMs中是一致的。",
    "tldr": "本文提出了一个新颖的框架，通过迭代训练密集检索器来为大型语言模型识别高质量的上下文示例，从而显著提高了上下文学习性能，并展示了在训练期间对未见过任务的泛化能力。",
    "en_tdlr": "This paper proposes a novel framework that significantly enhances in-context learning performance by iteratively training dense retrievers to identify high-quality in-context examples for large language models. The framework also demonstrates the ability to generalize to unseen tasks during training."
}