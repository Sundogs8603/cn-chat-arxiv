{
    "title": "Tackling Fake News in Bengali: Unraveling the Impact of Summarization vs. Augmentation on Pre-trained Language Models. (arXiv:2307.06979v1 [cs.CL])",
    "abstract": "With the rise of social media and online news sources, fake news has become a significant issue globally. However, the detection of fake news in low resource languages like Bengali has received limited attention in research. In this paper, we propose a methodology consisting of four distinct approaches to classify fake news articles in Bengali using summarization and augmentation techniques with five pre-trained language models. Our approach includes translating English news articles and using augmentation techniques to curb the deficit of fake news articles. Our research also focused on summarizing the news to tackle the token length limitation of BERT based models. Through extensive experimentation and rigorous evaluation, we show the effectiveness of summarization and augmentation in the case of Bengali fake news detection. We evaluated our models using three separate test datasets. The BanglaBERT Base model, when combined with augmentation techniques, achieved an impressive accurac",
    "link": "http://arxiv.org/abs/2307.06979",
    "context": "Title: Tackling Fake News in Bengali: Unraveling the Impact of Summarization vs. Augmentation on Pre-trained Language Models. (arXiv:2307.06979v1 [cs.CL])\nAbstract: With the rise of social media and online news sources, fake news has become a significant issue globally. However, the detection of fake news in low resource languages like Bengali has received limited attention in research. In this paper, we propose a methodology consisting of four distinct approaches to classify fake news articles in Bengali using summarization and augmentation techniques with five pre-trained language models. Our approach includes translating English news articles and using augmentation techniques to curb the deficit of fake news articles. Our research also focused on summarizing the news to tackle the token length limitation of BERT based models. Through extensive experimentation and rigorous evaluation, we show the effectiveness of summarization and augmentation in the case of Bengali fake news detection. We evaluated our models using three separate test datasets. The BanglaBERT Base model, when combined with augmentation techniques, achieved an impressive accurac",
    "path": "papers/23/07/2307.06979.json",
    "total_tokens": 978,
    "translated_title": "解决孟加拉语中的假新闻问题：揭示总结与扩充对预训练语言模型的影响",
    "translated_abstract": "随着社交媒体和在线新闻来源的兴起，假新闻已成为全球性的重大问题。然而，在像孟加拉语这样的低资源语言中检测假新闻在研究中受到了有限的关注。本文提出了一种方法，利用总结和扩充技术以及五种预训练语言模型来分类孟加拉语的假新闻文章。我们的方法包括将英语新闻文章进行翻译，并使用扩充技术来解决假新闻文章的不足问题。我们的研究还着重于通过总结新闻来解决基于BERT模型的令牌长度限制。通过广泛的实验和严格的评估，我们展示了总结和扩充在孟加拉语假新闻检测中的有效性。我们使用三个独立的测试数据集来评估我们的模型。当将BanglaBERT基础模型与扩充技术相结合时，取得了令人印象深刻的准确性。",
    "tldr": "本论文研究了孟加拉语中假新闻的检测问题。通过使用总结和扩充技术，结合预训练语言模型，提出了一种四重方法来分类孟加拉语的假新闻文章。研究表明，总结和扩充在孟加拉语假新闻检测中具有有效性。"
}