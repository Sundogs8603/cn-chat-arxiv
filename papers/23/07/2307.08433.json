{
    "title": "From random-walks to graph-sprints: a low-latency node embedding framework on continuous-time dynamic graphs. (arXiv:2307.08433v2 [cs.LG] UPDATED)",
    "abstract": "Many real-world datasets have an underlying dynamic graph structure, where entities and their interactions evolve over time. Machine learning models should consider these dynamics in order to harness their full potential in downstream tasks. Previous approaches for graph representation learning have focused on either sampling k-hop neighborhoods, akin to breadth-first search, or random walks, akin to depth-first search. However, these methods are computationally expensive and unsuitable for real-time, low-latency inference on dynamic graphs. To overcome these limitations, we propose graph-sprints a general purpose feature extraction framework for continuous-time-dynamic-graphs (CTDGs) that has low latency and is competitive with state-of-the-art, higher latency models. To achieve this, a streaming, low latency approximation to the random-walk based features is proposed. In our framework, time-aware node embeddings summarizing multi-hop information are computed using only single-hop ope",
    "link": "http://arxiv.org/abs/2307.08433",
    "context": "Title: From random-walks to graph-sprints: a low-latency node embedding framework on continuous-time dynamic graphs. (arXiv:2307.08433v2 [cs.LG] UPDATED)\nAbstract: Many real-world datasets have an underlying dynamic graph structure, where entities and their interactions evolve over time. Machine learning models should consider these dynamics in order to harness their full potential in downstream tasks. Previous approaches for graph representation learning have focused on either sampling k-hop neighborhoods, akin to breadth-first search, or random walks, akin to depth-first search. However, these methods are computationally expensive and unsuitable for real-time, low-latency inference on dynamic graphs. To overcome these limitations, we propose graph-sprints a general purpose feature extraction framework for continuous-time-dynamic-graphs (CTDGs) that has low latency and is competitive with state-of-the-art, higher latency models. To achieve this, a streaming, low latency approximation to the random-walk based features is proposed. In our framework, time-aware node embeddings summarizing multi-hop information are computed using only single-hop ope",
    "path": "papers/23/07/2307.08433.json",
    "total_tokens": 956,
    "translated_title": "从随机游走到图形快跑：一种在连续时间动态图上具有低延迟的节点嵌入框架",
    "translated_abstract": "许多真实世界的数据集具有基础的动态图结构，其中实体和它们的相互作用随时间演变。机器学习模型应考虑这些动态因素，以在下游任务中充分发挥其潜力。以前用于图表示学习的方法要么侧重于抽样k-跳邻域，类似于广度优先搜索，要么侧重于随机游走，类似于深度优先搜索。然而，这些方法在实时动态图上进行低延迟推断是计算上昂贵且不适用的。为了克服这些限制，我们提出了图形快跑，这是一个适用于连续时间动态图（CTDGs）的通用特征提取框架，具有低延迟，并且与高延迟模型相比具有竞争力。为了实现这一点，我们提出了一种流式、低延迟的近似随机游走特征。在我们的框架中，使用仅单跳操作计算总结多跳信息的时间感知节点嵌入。",
    "tldr": "这篇论文介绍了一种在连续时间动态图上具有低延迟的节点嵌入框架，通过提出流式低延迟的近似随机游走特征，计算时间感知节点嵌入以总结多跳信息。",
    "en_tdlr": "This paper presents a low-latency node embedding framework on continuous-time dynamic graphs, which computes time-aware node embeddings summarizing multi-hop information by proposing a streaming, low latency approximation to the random-walk based features."
}