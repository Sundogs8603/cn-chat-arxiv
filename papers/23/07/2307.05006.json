{
    "title": "Improving RNN-Transducers with Acoustic LookAhead. (arXiv:2307.05006v1 [cs.CL])",
    "abstract": "RNN-Transducers (RNN-Ts) have gained widespread acceptance as an end-to-end model for speech to text conversion because of their high accuracy and streaming capabilities. A typical RNN-T independently encodes the input audio and the text context, and combines the two encodings by a thin joint network. While this architecture provides SOTA streaming accuracy, it also makes the model vulnerable to strong LM biasing which manifests as multi-step hallucination of text without acoustic evidence. In this paper we propose LookAhead that makes text representations more acoustically grounded by looking ahead into the future within the audio input. This technique yields a significant 5%-20% relative reduction in word error rate on both in-domain and out-of-domain evaluation sets.",
    "link": "http://arxiv.org/abs/2307.05006",
    "context": "Title: Improving RNN-Transducers with Acoustic LookAhead. (arXiv:2307.05006v1 [cs.CL])\nAbstract: RNN-Transducers (RNN-Ts) have gained widespread acceptance as an end-to-end model for speech to text conversion because of their high accuracy and streaming capabilities. A typical RNN-T independently encodes the input audio and the text context, and combines the two encodings by a thin joint network. While this architecture provides SOTA streaming accuracy, it also makes the model vulnerable to strong LM biasing which manifests as multi-step hallucination of text without acoustic evidence. In this paper we propose LookAhead that makes text representations more acoustically grounded by looking ahead into the future within the audio input. This technique yields a significant 5%-20% relative reduction in word error rate on both in-domain and out-of-domain evaluation sets.",
    "path": "papers/23/07/2307.05006.json",
    "total_tokens": 806,
    "translated_title": "用声学预测改进RNN-Transducers模型",
    "translated_abstract": "RNN-Transducers（RNN-Ts）已经被广泛接受作为一种端到端的语音转文本模型，因为它们具有高准确率和流式处理能力。传统的RNN-T模型独立地编码输入音频和文本上下文，并通过一个薄型联合网络将两种编码结合起来。虽然这种架构提供了SOTA的流式处理准确率，但也使模型对强语言模型（LM）的偏见脆弱，这表现为在没有声学证据的情况下对文本进行多步幻觉生成。在本文中，我们提出了LookAhead技术，通过提前观察音频输入的未来部分，使文本表示更具有声学基础。这种技术在领域内和领域外的评估集上相对错误率有显著的5%-20%的降低。",
    "tldr": "本文提出了一种名为LookAhead的技术，通过提前观察音频输入的未来部分，使RNN-Transducers模型的文本表示更加与声学相符。该技术在准确率上相对降低了5%-20%。",
    "en_tdlr": "This paper proposes a technique called LookAhead that improves the text representation of RNN-Transducers models by looking into the future part of the audio input, reducing the word error rate by 5%-20%."
}