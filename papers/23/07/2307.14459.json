{
    "title": "Training Quantum Boltzmann Machines with Coresets. (arXiv:2307.14459v1 [quant-ph])",
    "abstract": "Recent work has proposed and explored using coreset techniques for quantum algorithms that operate on classical data sets to accelerate the applicability of these algorithms on near-term quantum devices. We apply these ideas to Quantum Boltzmann Machines (QBM) where gradient-based steps which require Gibbs state sampling are the main computational bottleneck during training. By using a coreset in place of the full data set, we try to minimize the number of steps needed and accelerate the overall training time. In a regime where computational time on quantum computers is a precious resource, we propose this might lead to substantial practical savings. We evaluate this approach on 6x6 binary images from an augmented bars and stripes data set using a QBM with 36 visible units and 8 hidden units. Using an Inception score inspired metric, we compare QBM training times with and without using coresets.",
    "link": "http://arxiv.org/abs/2307.14459",
    "context": "Title: Training Quantum Boltzmann Machines with Coresets. (arXiv:2307.14459v1 [quant-ph])\nAbstract: Recent work has proposed and explored using coreset techniques for quantum algorithms that operate on classical data sets to accelerate the applicability of these algorithms on near-term quantum devices. We apply these ideas to Quantum Boltzmann Machines (QBM) where gradient-based steps which require Gibbs state sampling are the main computational bottleneck during training. By using a coreset in place of the full data set, we try to minimize the number of steps needed and accelerate the overall training time. In a regime where computational time on quantum computers is a precious resource, we propose this might lead to substantial practical savings. We evaluate this approach on 6x6 binary images from an augmented bars and stripes data set using a QBM with 36 visible units and 8 hidden units. Using an Inception score inspired metric, we compare QBM training times with and without using coresets.",
    "path": "papers/23/07/2307.14459.json",
    "total_tokens": 878,
    "translated_title": "使用核心集合训练量子玻尔兹曼机",
    "translated_abstract": "最近的研究提出并探索了使用核心集合技术来加速在近期量子设备上应用这些算法的可能性，这些算法是用于处理经典数据集的量子算法。我们将这些想法应用于量子玻尔兹曼机（QBM），其中基于梯度的步骤需要对Gibbs状态进行采样，这是训练过程中的主要计算瓶颈。通过使用核心集合代替完整的数据集，我们试图最小化所需的步骤数并加速整体训练时间。在量子计算时间非常宝贵的情况下，我们认为这可能会带来相当大的实际节省。我们使用QBM的36个可见单元和8个隐藏单元在一个增强的条纹图像数据集中的6x6二进制图像上评估了这种方法。通过使用受启发于Inception分数的度量标准，我们比较了使用和不使用核心集合的QBM训练时间。",
    "tldr": "这篇论文研究了在近期量子设备上应用量子玻尔兹曼机算法的加速方法，利用核心集合技术代替完整数据集，最小化训练过程中的计算瓶颈并加速整体训练时间。",
    "en_tdlr": "This paper explores a method to accelerate Quantum Boltzmann Machines (QBM) algorithms on near-term quantum devices by using coreset techniques to minimize computational bottleneck during training, showcasing potential practical savings in a resource-constrained quantum computing environment."
}