{
    "title": "Making Pre-trained Language Models both Task-solvers and Self-calibrators. (arXiv:2307.11316v1 [cs.CL])",
    "abstract": "Pre-trained language models (PLMs) serve as backbones for various real-world systems. For high-stake applications, it's equally essential to have reasonable confidence estimations in predictions. While the vanilla confidence scores of PLMs can already be effectively utilized, PLMs consistently become overconfident in their wrong predictions, which is not desirable in practice. Previous work shows that introducing an extra calibration task can mitigate this issue. The basic idea involves acquiring additional data to train models in predicting the confidence of their initial predictions. However, it only demonstrates the feasibility of this kind of method, assuming that there are abundant extra available samples for the introduced calibration task. In this work, we consider the practical scenario that we need to effectively utilize training samples to make PLMs both task-solvers and self-calibrators. Three challenges are presented, including limited training samples, data imbalance, and ",
    "link": "http://arxiv.org/abs/2307.11316",
    "context": "Title: Making Pre-trained Language Models both Task-solvers and Self-calibrators. (arXiv:2307.11316v1 [cs.CL])\nAbstract: Pre-trained language models (PLMs) serve as backbones for various real-world systems. For high-stake applications, it's equally essential to have reasonable confidence estimations in predictions. While the vanilla confidence scores of PLMs can already be effectively utilized, PLMs consistently become overconfident in their wrong predictions, which is not desirable in practice. Previous work shows that introducing an extra calibration task can mitigate this issue. The basic idea involves acquiring additional data to train models in predicting the confidence of their initial predictions. However, it only demonstrates the feasibility of this kind of method, assuming that there are abundant extra available samples for the introduced calibration task. In this work, we consider the practical scenario that we need to effectively utilize training samples to make PLMs both task-solvers and self-calibrators. Three challenges are presented, including limited training samples, data imbalance, and ",
    "path": "papers/23/07/2307.11316.json",
    "total_tokens": 865,
    "translated_title": "使预训练语言模型成为任务解决器和自校准器",
    "translated_abstract": "预训练语言模型（PLMs）在各种实际系统中作为骨干。对于高风险应用，合理的置信度估计对于预测同样重要。虽然PLMs的常规置信度分数已经可以有效利用，但它们在错误预测中始终变得过于自信，这在实践中是不可取的。之前的工作表明，引入额外的校准任务可以缓解这个问题。基本思想是获得额外的数据来训练模型，以预测其初始预测的置信度。然而，它只是展示了这种方法的可行性，假设引入的校准任务有丰富的额外可用样本。在这项工作中，我们考虑到实际情况，我们需要有效利用训练样本，使PLMs成为任务解决器和自校准器。提出了三个挑战，包括有限的训练样本、数据不平衡和…",
    "tldr": "该论文研究了如何使预训练语言模型成为任务解决器和自校准器，在有限的训练样本、数据不平衡和其他实际挑战下进行了探索。",
    "en_tdlr": "This paper investigates how to make pre-trained language models both task-solvers and self-calibrators, and explores the challenges of limited training samples, data imbalance, and other practical issues."
}