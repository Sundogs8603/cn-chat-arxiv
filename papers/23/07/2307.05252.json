{
    "title": "MAP- and MLE-Based Teaching. (arXiv:2307.05252v1 [cs.LG])",
    "abstract": "Imagine a learner L who tries to infer a hidden concept from a collection of observations. Building on the work [4] of Ferri et al., we assume the learner to be parameterized by priors P(c) and by c-conditional likelihoods P(z|c) where c ranges over all concepts in a given class C and z ranges over all observations in an observation set Z. L is called a MAP-learner (resp. an MLE-learner) if it thinks of a collection S of observations as a random sample and returns the concept with the maximum a-posteriori probability (resp. the concept which maximizes the c-conditional likelihood of S). Depending on whether L assumes that S is obtained from ordered or unordered sampling resp. from sampling with or without replacement, we can distinguish four different sampling modes. Given a target concept c in C, a teacher for a MAP-learner L aims at finding a smallest collection of observations that causes L to return c. This approach leads in a natural manner to various notions of a MAP- or MLE-teac",
    "link": "http://arxiv.org/abs/2307.05252",
    "context": "Title: MAP- and MLE-Based Teaching. (arXiv:2307.05252v1 [cs.LG])\nAbstract: Imagine a learner L who tries to infer a hidden concept from a collection of observations. Building on the work [4] of Ferri et al., we assume the learner to be parameterized by priors P(c) and by c-conditional likelihoods P(z|c) where c ranges over all concepts in a given class C and z ranges over all observations in an observation set Z. L is called a MAP-learner (resp. an MLE-learner) if it thinks of a collection S of observations as a random sample and returns the concept with the maximum a-posteriori probability (resp. the concept which maximizes the c-conditional likelihood of S). Depending on whether L assumes that S is obtained from ordered or unordered sampling resp. from sampling with or without replacement, we can distinguish four different sampling modes. Given a target concept c in C, a teacher for a MAP-learner L aims at finding a smallest collection of observations that causes L to return c. This approach leads in a natural manner to various notions of a MAP- or MLE-teac",
    "path": "papers/23/07/2307.05252.json",
    "total_tokens": 931,
    "translated_title": "基于MAP和MLE的教学",
    "translated_abstract": "假设一个学习者L试图从一系列观察中推断出一个隐藏的概念。在Ferri等人的工作[4]的基础上，我们假设学习者由先验P(c)和条件概率P(z|c)参数化，其中c范围在给定类别C中的所有概念上，z范围在观察集合Z中的所有观察上。如果L将一组观察看作是随机样本，并返回具有最大后验概率的概念（相应地，返回最大化S的c条件概率的概念），则L被称为MAP学习器（resp. MLE学习器）。根据L是否假设S是从有序或无序采样（resp. 有替换或无替换采样）获得的，可以区分四种不同的采样模式。对于给定的目标概念c在C中，对于MAP学习器L来说，教师的目标是找到最小的观察集合，使得L返回c。这种方法自然地导致了各种MAP或MLE教学的概念。",
    "tldr": "该论文研究了基于MAP和MLE的教学方法，其中学习者根据观察结果推断隐藏的概念，教师试图找到最小的观察集合以使得学习者返回特定的概念。",
    "en_tdlr": "This paper explores MAP and MLE-based teaching methods, where a learner infers a hidden concept based on observations and a teacher aims to find the smallest observation set to make the learner return a specific concept."
}