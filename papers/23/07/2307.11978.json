{
    "title": "Why Is Prompt Tuning for Vision-Language Models Robust to Noisy Labels?. (arXiv:2307.11978v1 [cs.CV])",
    "abstract": "Vision-language models such as CLIP learn a generic text-image embedding from large-scale training data. A vision-language model can be adapted to a new classification task through few-shot prompt tuning. We find that such a prompt tuning process is highly robust to label noises. This intrigues us to study the key reasons contributing to the robustness of the prompt tuning paradigm. We conducted extensive experiments to explore this property and find the key factors are: 1) the fixed classname tokens provide a strong regularization to the optimization of the model, reducing gradients induced by the noisy samples; 2) the powerful pre-trained image-text embedding that is learned from diverse and generic web data provides strong prior knowledge for image classification. Further, we demonstrate that noisy zero-shot predictions from CLIP can be used to tune its own prompt, significantly enhancing prediction accuracy in the unsupervised setting. The code is available at https://github.com/CE",
    "link": "http://arxiv.org/abs/2307.11978",
    "context": "Title: Why Is Prompt Tuning for Vision-Language Models Robust to Noisy Labels?. (arXiv:2307.11978v1 [cs.CV])\nAbstract: Vision-language models such as CLIP learn a generic text-image embedding from large-scale training data. A vision-language model can be adapted to a new classification task through few-shot prompt tuning. We find that such a prompt tuning process is highly robust to label noises. This intrigues us to study the key reasons contributing to the robustness of the prompt tuning paradigm. We conducted extensive experiments to explore this property and find the key factors are: 1) the fixed classname tokens provide a strong regularization to the optimization of the model, reducing gradients induced by the noisy samples; 2) the powerful pre-trained image-text embedding that is learned from diverse and generic web data provides strong prior knowledge for image classification. Further, we demonstrate that noisy zero-shot predictions from CLIP can be used to tune its own prompt, significantly enhancing prediction accuracy in the unsupervised setting. The code is available at https://github.com/CE",
    "path": "papers/23/07/2307.11978.json",
    "total_tokens": 973,
    "translated_title": "为什么视觉-语言模型的提示调参对于噪声标签具有鲁棒性？",
    "translated_abstract": "视觉-语言模型（如CLIP）通过大规模训练数据学习了通用的文本-图像嵌入。通过少样本提示调参的方式，可以使视觉-语言模型适应新的分类任务。我们发现，这种提示调参过程对于噪声标签具有很强的鲁棒性。这激发了我们研究提示调参范式鲁棒性的关键原因。我们进行了大量实验证明，关键因素包括：1）固定的类名标记对模型的优化提供了强大的正则化作用，减少了噪声样本引起的梯度；2）从多样且通用的网络数据中学习到的强大的预训练图像-文本嵌入为图像分类提供了强大的先验知识。此外，我们证明可以利用CLIP中的噪声零样本预测来调整其自身的提示，显著提高了在无监督设置下的预测准确性。代码可在https://github.com/CE找到。",
    "tldr": "视觉-语言模型通过少样本提示调参的方式适应新的分类任务，且对于噪声标签具有鲁棒性。关键原因包括固定的类名标记对模型优化的正则化作用以及从多样且通用的网络数据中学习到的强大预训练图像-文本嵌入提供的先验知识。",
    "en_tdlr": "Vision-language models adapt to new classification tasks through few-shot prompt tuning and are robust to noisy labels. The key reasons for this robustness are the regularization provided by fixed classname tokens during model optimization and the strong prior knowledge for image classification obtained from diverse and generic web data through powerful pre-trained image-text embedding."
}