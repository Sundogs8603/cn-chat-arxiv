{
    "title": "Random Separating Hyperplane Theorem and Learning Polytopes. (arXiv:2307.11371v1 [cs.LG])",
    "abstract": "The Separating Hyperplane theorem is a fundamental result in Convex Geometry with myriad applications. Our first result, Random Separating Hyperplane Theorem (RSH), is a strengthening of this for polytopes. $\\rsh$ asserts that if the distance between $a$ and a polytope $K$ with $k$ vertices and unit diameter in $\\Re^d$ is at least $\\delta$, where $\\delta$ is a fixed constant in $(0,1)$, then a randomly chosen hyperplane separates $a$ and $K$ with probability at least $1/poly(k)$ and margin at least $\\Omega \\left(\\delta/\\sqrt{d} \\right)$. An immediate consequence of our result is the first near optimal bound on the error increase in the reduction from a Separation oracle to an Optimization oracle over a polytope.  RSH has algorithmic applications in learning polytopes. We consider a fundamental problem, denoted the ``Hausdorff problem'', of learning a unit diameter polytope $K$ within Hausdorff distance $\\delta$, given an optimization oracle for $K$. Using RSH, we show that with polynom",
    "link": "http://arxiv.org/abs/2307.11371",
    "context": "Title: Random Separating Hyperplane Theorem and Learning Polytopes. (arXiv:2307.11371v1 [cs.LG])\nAbstract: The Separating Hyperplane theorem is a fundamental result in Convex Geometry with myriad applications. Our first result, Random Separating Hyperplane Theorem (RSH), is a strengthening of this for polytopes. $\\rsh$ asserts that if the distance between $a$ and a polytope $K$ with $k$ vertices and unit diameter in $\\Re^d$ is at least $\\delta$, where $\\delta$ is a fixed constant in $(0,1)$, then a randomly chosen hyperplane separates $a$ and $K$ with probability at least $1/poly(k)$ and margin at least $\\Omega \\left(\\delta/\\sqrt{d} \\right)$. An immediate consequence of our result is the first near optimal bound on the error increase in the reduction from a Separation oracle to an Optimization oracle over a polytope.  RSH has algorithmic applications in learning polytopes. We consider a fundamental problem, denoted the ``Hausdorff problem'', of learning a unit diameter polytope $K$ within Hausdorff distance $\\delta$, given an optimization oracle for $K$. Using RSH, we show that with polynom",
    "path": "papers/23/07/2307.11371.json",
    "total_tokens": 995,
    "translated_title": "随机分离超平面定理和学习多面体",
    "translated_abstract": "分离超平面定理是凸几何学中的一个基本结果，具有广泛的应用。我们的第一个结果是随机分离超平面定理（RSH），它是对多面体的一个加强。RSH断言，如果点a与具有k个顶点和单位直径的多面体K在$\\Re^d$中的距离至少为$\\delta$，其中$\\delta$是$(0,1)$之间的一个固定常数，则随机选择的超平面以至少$1/poly(k)$的概率将a和K分离，并且边界至少为$\\Omega \\left( \\delta/\\sqrt{d} \\right)$。我们结果的一个直接推论是，首次近乎最优的边界在从分离预言机到优化预言机的约简中错误增加。RSH在学习多面体中具有算法应用。我们考虑了一个基本问题，被称为“Hausdorff问题”，即在给定了关于K的优化预言机的情况下，学习一个单位直径多面体K，使其在Hausdorff距离$\\delta$内。利用RSH，我们证明了在多项式时间内可以学习多面体K的解决方法。",
    "tldr": "通过随机选择的超平面，我们提出了随机分离超平面定理（RSH）来加强分离超平面定理，利用RSH我们得到了多面体学习中的算法应用。",
    "en_tdlr": "We present the Random Separating Hyperplane Theorem (RSH) as a strengthening of the Separating Hyperplane theorem for polytopes, which has algorithmic applications in learning polytopes. RSH guarantees a randomly chosen hyperplane separates a point and a polytope with high probability and a large margin."
}