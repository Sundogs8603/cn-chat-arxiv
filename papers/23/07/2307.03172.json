{
    "title": "Lost in the Middle: How Language Models Use Long Contexts. (arXiv:2307.03172v1 [cs.CL])",
    "abstract": "While recent language models have the ability to take long contexts as input, relatively little is known about how well the language models use longer context. We analyze language model performance on two tasks that require identifying relevant information within their input contexts: multi-document question answering and key-value retrieval. We find that performance is often highest when relevant information occurs at the beginning or end of the input context, and significantly degrades when models must access relevant information in the middle of long contexts. Furthermore, performance substantially decreases as the input context grows longer, even for explicitly long-context models. Our analysis provides a better understanding of how language models use their input context and provides new evaluation protocols for future long-context models.",
    "link": "http://arxiv.org/abs/2307.03172",
    "context": "Title: Lost in the Middle: How Language Models Use Long Contexts. (arXiv:2307.03172v1 [cs.CL])\nAbstract: While recent language models have the ability to take long contexts as input, relatively little is known about how well the language models use longer context. We analyze language model performance on two tasks that require identifying relevant information within their input contexts: multi-document question answering and key-value retrieval. We find that performance is often highest when relevant information occurs at the beginning or end of the input context, and significantly degrades when models must access relevant information in the middle of long contexts. Furthermore, performance substantially decreases as the input context grows longer, even for explicitly long-context models. Our analysis provides a better understanding of how language models use their input context and provides new evaluation protocols for future long-context models.",
    "path": "papers/23/07/2307.03172.json",
    "total_tokens": 939,
    "translated_title": "迷失在中间：语言模型如何使用长文本",
    "translated_abstract": "尽管最近的语言模型能够将长文本作为输入，但我们对语言模型如何有效地使用较长的文本还知之甚少。本研究分析了语言模型在两个需要在输入文本中识别相关信息的任务（多文档问答和键值检索）上的表现。我们发现，当相关信息出现在输入文本的开头或结尾时，语言模型的表现通常最佳；而当模型需要访问长文本中的中间相关信息时，性能显著下降。此外，即使对于专门处理长文本的模型，当输入文本变得越来越长时，性能也会大幅降低。我们的分析为我们更好地理解语言模型如何使用输入文本的上下文，并为未来的长文本模型提供了新的评估方案。",
    "tldr": "本研究分析了语言模型在多文档问答和键值检索任务中的表现，发现当相关信息位于输入文本的开头或结尾时性能最佳，而当模型需要在长文本的中间访问相关信息时性能显著下降。此外，即使对于专门处理长文本的模型，输入文本越长性能也会大幅降低。我们的研究为理解语言模型如何使用输入文本的上下文提供了新的认识，并且为未来的长文本模型提供了新的评估方案。",
    "en_tdlr": "This study analyzes the performance of language models on multi-document question answering and key-value retrieval tasks, and finds that the performance is highest when relevant information is at the beginning or end of the input text, but significantly degrades when models need to access relevant information in the middle of long contexts. Additionally, even for models explicitly designed for long texts, performance decreases as the input context grows longer. This analysis provides insights into how language models utilize input context and offers new evaluation protocols for future long-context models."
}