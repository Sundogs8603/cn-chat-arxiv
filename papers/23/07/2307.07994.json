{
    "title": "Facilitating Multi-turn Emotional Support Conversation with Positive Emotion Elicitation: A Reinforcement Learning Approach. (arXiv:2307.07994v1 [cs.CL])",
    "abstract": "Emotional support conversation (ESC) aims to provide emotional support (ES) to improve one's mental state. Existing works stay at fitting grounded responses and responding strategies (e.g., question), which ignore the effect on ES and lack explicit goals to guide emotional positive transition. To this end, we introduce a new paradigm to formalize multi-turn ESC as a process of positive emotion elicitation. Addressing this task requires finely adjusting the elicitation intensity in ES as the conversation progresses while maintaining conversational goals like coherence. In this paper, we propose Supporter, a mixture-of-expert-based reinforcement learning model, and well design ES and dialogue coherence rewards to guide policy's learning for responding. Experiments verify the superiority of Supporter in achieving positive emotion elicitation during responding while maintaining conversational goals including coherence.",
    "link": "http://arxiv.org/abs/2307.07994",
    "context": "Title: Facilitating Multi-turn Emotional Support Conversation with Positive Emotion Elicitation: A Reinforcement Learning Approach. (arXiv:2307.07994v1 [cs.CL])\nAbstract: Emotional support conversation (ESC) aims to provide emotional support (ES) to improve one's mental state. Existing works stay at fitting grounded responses and responding strategies (e.g., question), which ignore the effect on ES and lack explicit goals to guide emotional positive transition. To this end, we introduce a new paradigm to formalize multi-turn ESC as a process of positive emotion elicitation. Addressing this task requires finely adjusting the elicitation intensity in ES as the conversation progresses while maintaining conversational goals like coherence. In this paper, we propose Supporter, a mixture-of-expert-based reinforcement learning model, and well design ES and dialogue coherence rewards to guide policy's learning for responding. Experiments verify the superiority of Supporter in achieving positive emotion elicitation during responding while maintaining conversational goals including coherence.",
    "path": "papers/23/07/2307.07994.json",
    "total_tokens": 853,
    "translated_title": "利用积极情绪引发来促进多轮情感支持对话：一种强化学习方法",
    "translated_abstract": "情感支持对话旨在提供情感支持以改善人们的心理状态。现有研究仅局限于配合回应和回策略（如问题），忽略了对情感支持的影响，并缺乏明确的目标来引导积极情感转变。为此，我们引入了一种新的范式，将多轮情感支持对话形式化为积极情感引发的过程。解决这个任务需要在对话过程中细调情感引发的强度，同时保持对话的一致性等会话目标。在本文中，我们提出了一种基于混合专家的强化学习模型Supporter，并设计了情感支持和对话一致性奖励来指导回应策略的学习。实验证明，Supporter在实现积极情感引发的同时，保持了包括一致性在内的会话目标的优越性。",
    "tldr": "本文介绍了一种利用积极情绪引发来促进多轮情感支持对话的强化学习方法，通过调整引发强度并保持会话目标一致性，实现了积极情绪引发的优越性。",
    "en_tdlr": "This paper presents a reinforcement learning approach that facilitates multi-turn emotional support conversation by eliciting positive emotions, achieving superior positive emotion elicitation while maintaining conversational goals."
}