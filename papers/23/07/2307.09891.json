{
    "title": "Amortised Design Optimization for Item Response Theory. (arXiv:2307.09891v1 [cs.AI])",
    "abstract": "Item Response Theory (IRT) is a well known method for assessing responses from humans in education and psychology. In education, IRT is used to infer student abilities and characteristics of test items from student responses. Interactions with students are expensive, calling for methods that efficiently gather information for inferring student abilities. Methods based on Optimal Experimental Design (OED) are computationally costly, making them inapplicable for interactive applications. In response, we propose incorporating amortised experimental design into IRT. Here, the computational cost is shifted to a precomputing phase by training a Deep Reinforcement Learning (DRL) agent with synthetic data. The agent is trained to select optimally informative test items for the distribution of students, and to conduct amortised inference conditioned on the experiment outcomes. During deployment the agent estimates parameters from data, and suggests the next test item for the student, in close t",
    "link": "http://arxiv.org/abs/2307.09891",
    "context": "Title: Amortised Design Optimization for Item Response Theory. (arXiv:2307.09891v1 [cs.AI])\nAbstract: Item Response Theory (IRT) is a well known method for assessing responses from humans in education and psychology. In education, IRT is used to infer student abilities and characteristics of test items from student responses. Interactions with students are expensive, calling for methods that efficiently gather information for inferring student abilities. Methods based on Optimal Experimental Design (OED) are computationally costly, making them inapplicable for interactive applications. In response, we propose incorporating amortised experimental design into IRT. Here, the computational cost is shifted to a precomputing phase by training a Deep Reinforcement Learning (DRL) agent with synthetic data. The agent is trained to select optimally informative test items for the distribution of students, and to conduct amortised inference conditioned on the experiment outcomes. During deployment the agent estimates parameters from data, and suggests the next test item for the student, in close t",
    "path": "papers/23/07/2307.09891.json",
    "total_tokens": 837,
    "translated_title": "物品反应理论的摊销设计优化",
    "translated_abstract": "物品反应理论（IRT）是一种用于评估教育和心理学中人类回答的方法。在教育领域，IRT被用来推断学生能力和测试项目的特点，通过学生的回答。与学生的互动是昂贵的，需要高效地收集推断学生能力的信息。基于最佳实验设计（OED）的方法在计算上代价高昂，使其不适用于交互式应用。为此，我们提出将摊销实验设计纳入IRT中。在这里，计算成本被转移到预计算阶段，通过使用合成数据训练深度强化学习（DRL）代理。该代理被训练为选择对于学生分布最具信息价值的测试项目，并根据实验结果进行摊销推断。在部署过程中，代理根据数据估计参数，并为学生建议下一个测试项目。",
    "tldr": "本文在物品反应理论中提出了摊销实验设计方法，利用深度强化学习代理在预处理阶段选择对于学生分布最具信息价值的测试项目，并在部署过程中进行摊销推断。",
    "en_tdlr": "This paper proposes an amortised experimental design method in item response theory, using a deep reinforcement learning agent to select optimally informative test items for student distribution in a precomputation phase, and conducting amortised inference during deployment."
}