{
    "title": "Pseudo Outlier Exposure for Out-of-Distribution Detection using Pretrained Transformers. (arXiv:2307.09455v1 [cs.CL])",
    "abstract": "For real-world language applications, detecting an out-of-distribution (OOD) sample is helpful to alert users or reject such unreliable samples. However, modern over-parameterized language models often produce overconfident predictions for both in-distribution (ID) and OOD samples. In particular, language models suffer from OOD samples with a similar semantic representation to ID samples since these OOD samples lie near the ID manifold. A rejection network can be trained with ID and diverse outlier samples to detect test OOD samples, but explicitly collecting auxiliary OOD datasets brings an additional burden for data collection. In this paper, we propose a simple but effective method called Pseudo Outlier Exposure (POE) that constructs a surrogate OOD dataset by sequentially masking tokens related to ID classes. The surrogate OOD sample introduced by POE shows a similar representation to ID data, which is most effective in training a rejection network. Our method does not require any ",
    "link": "http://arxiv.org/abs/2307.09455",
    "context": "Title: Pseudo Outlier Exposure for Out-of-Distribution Detection using Pretrained Transformers. (arXiv:2307.09455v1 [cs.CL])\nAbstract: For real-world language applications, detecting an out-of-distribution (OOD) sample is helpful to alert users or reject such unreliable samples. However, modern over-parameterized language models often produce overconfident predictions for both in-distribution (ID) and OOD samples. In particular, language models suffer from OOD samples with a similar semantic representation to ID samples since these OOD samples lie near the ID manifold. A rejection network can be trained with ID and diverse outlier samples to detect test OOD samples, but explicitly collecting auxiliary OOD datasets brings an additional burden for data collection. In this paper, we propose a simple but effective method called Pseudo Outlier Exposure (POE) that constructs a surrogate OOD dataset by sequentially masking tokens related to ID classes. The surrogate OOD sample introduced by POE shows a similar representation to ID data, which is most effective in training a rejection network. Our method does not require any ",
    "path": "papers/23/07/2307.09455.json",
    "total_tokens": 910,
    "translated_title": "基于预训练变换器的伪异常暴露法用于检测未知分布",
    "translated_abstract": "对于现实世界的语言应用，检测未知分布的样本有助于提醒用户或拒绝不可靠的样本。然而，现代过参数化的语言模型通常会对内分布和外分布样本都产生过度自信的预测。特别是，语言模型在与内分布样本具有相似语义表示的外分布样本上表现不佳，因为这些外分布样本位于内分布流形附近。可以通过使用内分布和多样的异常样本训练拒绝网络来检测测试的外分布样本，但明确收集辅助的外分布数据集会增加数据收集的负担。在本文中，我们提出了一种简单而有效的方法，称为伪异常暴露（POE），通过顺序屏蔽与内分布类相关的令牌来构建一个替代的外分布数据集。POE引入的替代外分布样本显示出与内部数据类似的表示，这对于训练拒绝网络最有效。我们的方法不需要任何",
    "tldr": "本文提出了一种名为伪异常暴露（POE）的简单而有效的方法，通过顺序屏蔽与内分布类相关的令牌构建替代的外分布数据集，用于检测未知分布的样本。"
}