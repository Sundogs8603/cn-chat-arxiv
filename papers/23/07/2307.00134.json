{
    "title": "Generalization Limits of Graph Neural Networks in Identity Effects Learning. (arXiv:2307.00134v1 [cs.LG])",
    "abstract": "Graph Neural Networks (GNNs) have emerged as a powerful tool for data-driven learning on various graph domains. They are usually based on a message-passing mechanism and have gained increasing popularity for their intuitive formulation, which is closely linked to the Weisfeiler-Lehman (WL) test for graph isomorphism to which they have been proven equivalent in terms of expressive power. In this work, we establish new generalization properties and fundamental limits of GNNs in the context of learning so-called identity effects, i.e., the task of determining whether an object is composed of two identical components or not. Our study is motivated by the need to understand the capabilities of GNNs when performing simple cognitive tasks, with potential applications in computational linguistics and chemistry. We analyze two case studies: (i) two-letters words, for which we show that GNNs trained via stochastic gradient descent are unable to generalize to unseen letters when utilizing orthogo",
    "link": "http://arxiv.org/abs/2307.00134",
    "context": "Title: Generalization Limits of Graph Neural Networks in Identity Effects Learning. (arXiv:2307.00134v1 [cs.LG])\nAbstract: Graph Neural Networks (GNNs) have emerged as a powerful tool for data-driven learning on various graph domains. They are usually based on a message-passing mechanism and have gained increasing popularity for their intuitive formulation, which is closely linked to the Weisfeiler-Lehman (WL) test for graph isomorphism to which they have been proven equivalent in terms of expressive power. In this work, we establish new generalization properties and fundamental limits of GNNs in the context of learning so-called identity effects, i.e., the task of determining whether an object is composed of two identical components or not. Our study is motivated by the need to understand the capabilities of GNNs when performing simple cognitive tasks, with potential applications in computational linguistics and chemistry. We analyze two case studies: (i) two-letters words, for which we show that GNNs trained via stochastic gradient descent are unable to generalize to unseen letters when utilizing orthogo",
    "path": "papers/23/07/2307.00134.json",
    "total_tokens": 847,
    "translated_title": "图神经网络在身份效应学习中的泛化限制",
    "translated_abstract": "图神经网络在各种图领域的数据驱动学习中已经成为一个强有力的工具。它们通常基于消息传递机制，并且由于其与Weisfeiler-Lehman(WL)图同构测试紧密相连的直观表述而越来越受到欢迎，从表达能力上讲，它们已被证明与WL测试等价。在本研究中，我们在学习所谓的身份效应（即确定一个对象是否由两个相同的组件组成）的背景下，建立了GNN在泛化属性和基本限制方面的新性质。我们的研究是出于理解GNN在执行简单认知任务时的能力的需求，可能在计算语言学和化学领域具有潜在应用。我们分析了两个案例研究：（i）两个字母的单词，我们展示了通过随机梯度下降训练的GNN在利用正交时无法对未见字母进行泛化的情况。",
    "tldr": "本研究在学习身份效应的背景下，分析了图神经网络在泛化属性和基本限制方面的新性质，以及在两个字母的单词案例中的具体应用。"
}