{
    "title": "GEAR: Augmenting Language Models with Generalizable and Efficient Tool Resolution. (arXiv:2307.08775v1 [cs.AI])",
    "abstract": "Augmenting large language models (LLM) to use external tools enhances their performance across a variety of tasks. However, prior works over-rely on task-specific demonstration of tool use that limits their generalizability and computational cost due to making many calls to large-scale LLMs. We introduce GEAR, a computationally efficient query-tool grounding algorithm that is generalizable to various tasks that require tool use while not relying on task-specific demonstrations. GEAR achieves better efficiency by delegating tool grounding and execution to small language models (SLM) and LLM, respectively; while leveraging semantic and pattern-based evaluation at both question and answer levels for generalizable tool grounding. We evaluate GEAR on 14 datasets across 6 downstream tasks, demonstrating its strong generalizability to novel tasks, tools and different SLMs. Despite offering more efficiency, GEAR achieves higher precision in tool grounding compared to prior strategies using LLM",
    "link": "http://arxiv.org/abs/2307.08775",
    "context": "Title: GEAR: Augmenting Language Models with Generalizable and Efficient Tool Resolution. (arXiv:2307.08775v1 [cs.AI])\nAbstract: Augmenting large language models (LLM) to use external tools enhances their performance across a variety of tasks. However, prior works over-rely on task-specific demonstration of tool use that limits their generalizability and computational cost due to making many calls to large-scale LLMs. We introduce GEAR, a computationally efficient query-tool grounding algorithm that is generalizable to various tasks that require tool use while not relying on task-specific demonstrations. GEAR achieves better efficiency by delegating tool grounding and execution to small language models (SLM) and LLM, respectively; while leveraging semantic and pattern-based evaluation at both question and answer levels for generalizable tool grounding. We evaluate GEAR on 14 datasets across 6 downstream tasks, demonstrating its strong generalizability to novel tasks, tools and different SLMs. Despite offering more efficiency, GEAR achieves higher precision in tool grounding compared to prior strategies using LLM",
    "path": "papers/23/07/2307.08775.json",
    "total_tokens": 894,
    "translated_title": "GEAR: 与通用化和高效解决方案增强语言模型",
    "translated_abstract": "通过增加外部工具来增强大型语言模型（LLM）可以提高其在各种任务中的性能。然而，先前的研究过于依赖特定任务的工具使用示范，限制了其通用性，并且由于对大规模LLM进行多次调用而增加了计算成本。我们引入了GEAR，一种计算效率高的查询-工具对应算法，可以适用于不依赖特定任务示范的各种需要使用工具的任务。GEAR通过将工具对应和执行分别委托给小型语言模型（SLM）和LLM来实现更高的效率；同时利用语义和基于模式的评估在问题和答案级别上进行通用化的工具对应。我们在6个下游任务的14个数据集上评估了GEAR，证明了它对于新任务、新工具和不同SLM的强大通用性。尽管提供更高的效率，但GEAR在工具对应中的精确性比使用LLM的先前策略更高。",
    "tldr": "GEAR是一种通用且高效的工具解决方案，通过将工具对应和执行分别委托给小型语言模型和大型语言模型，在不依赖任务示范的情况下实现了更高的性能和精确度。"
}