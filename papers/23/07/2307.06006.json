{
    "title": "What Happens During Finetuning of Vision Transformers: An Invariance Based Investigation. (arXiv:2307.06006v1 [cs.CV])",
    "abstract": "The pretrain-finetune paradigm usually improves downstream performance over training a model from scratch on the same task, becoming commonplace across many areas of machine learning. While pretraining is empirically observed to be beneficial for a range of tasks, there is not a clear understanding yet of the reasons for this effect. In this work, we examine the relationship between pretrained vision transformers and the corresponding finetuned versions on several benchmark datasets and tasks. We present new metrics that specifically investigate the degree to which invariances learned by a pretrained model are retained or forgotten during finetuning. Using these metrics, we present a suite of empirical findings, including that pretraining induces transferable invariances in shallow layers and that invariances from deeper pretrained layers are compressed towards shallower layers during finetuning. Together, these findings contribute to understanding some of the reasons for the successes",
    "link": "http://arxiv.org/abs/2307.06006",
    "context": "Title: What Happens During Finetuning of Vision Transformers: An Invariance Based Investigation. (arXiv:2307.06006v1 [cs.CV])\nAbstract: The pretrain-finetune paradigm usually improves downstream performance over training a model from scratch on the same task, becoming commonplace across many areas of machine learning. While pretraining is empirically observed to be beneficial for a range of tasks, there is not a clear understanding yet of the reasons for this effect. In this work, we examine the relationship between pretrained vision transformers and the corresponding finetuned versions on several benchmark datasets and tasks. We present new metrics that specifically investigate the degree to which invariances learned by a pretrained model are retained or forgotten during finetuning. Using these metrics, we present a suite of empirical findings, including that pretraining induces transferable invariances in shallow layers and that invariances from deeper pretrained layers are compressed towards shallower layers during finetuning. Together, these findings contribute to understanding some of the reasons for the successes",
    "path": "papers/23/07/2307.06006.json",
    "total_tokens": 760,
    "translated_title": "Vision Transformers的Finetuning过程中发生了什么：基于不变性的研究",
    "translated_abstract": "通过在几个基准数据集和任务上研究预训练的Vision Transformers及其对应的Finetuned版本之间的关系，我们发现了一些新的指标，并特别调查了预训练模型学习的不变性在Finetuning过程中的保留程度。使用这些指标，我们呈现了一系列实证发现，包括预训练在浅层中引入了可转移的不变性，并且在Finetuning过程中，深层的不变性向浅层压缩。这些发现有助于理解成功的原因之一。",
    "tldr": "本研究通过调查预训练的Vision Transformers和Finetuned版本之间的关系，发现预训练引入了可转移的不变性，在Finetuning过程中，深层的不变性向浅层压缩。",
    "en_tdlr": "This study investigates the relationship between pretrained Vision Transformers and their finetuned versions, revealing that pretraining induces transferable invariances, and during finetuning, invariances from deeper layers are compressed towards shallower layers."
}