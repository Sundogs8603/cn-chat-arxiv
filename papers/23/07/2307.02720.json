{
    "title": "On-Device Constrained Self-Supervised Speech Representation Learning for Keyword Spotting via Knowledge Distillation. (arXiv:2307.02720v1 [cs.CL])",
    "abstract": "Large self-supervised models are effective feature extractors, but their application is challenging under on-device budget constraints and biased dataset collection, especially in keyword spotting. To address this, we proposed a knowledge distillation-based self-supervised speech representation learning (S3RL) architecture for on-device keyword spotting. Our approach used a teacher-student framework to transfer knowledge from a larger, more complex model to a smaller, light-weight model using dual-view cross-correlation distillation and the teacher's codebook as learning objectives. We evaluated our model's performance on an Alexa keyword spotting detection task using a 16.6k-hour in-house dataset. Our technique showed exceptional performance in normal and noisy conditions, demonstrating the efficacy of knowledge distillation methods in constructing self-supervised models for keyword spotting tasks while working within on-device resource constraints.",
    "link": "http://arxiv.org/abs/2307.02720",
    "context": "Title: On-Device Constrained Self-Supervised Speech Representation Learning for Keyword Spotting via Knowledge Distillation. (arXiv:2307.02720v1 [cs.CL])\nAbstract: Large self-supervised models are effective feature extractors, but their application is challenging under on-device budget constraints and biased dataset collection, especially in keyword spotting. To address this, we proposed a knowledge distillation-based self-supervised speech representation learning (S3RL) architecture for on-device keyword spotting. Our approach used a teacher-student framework to transfer knowledge from a larger, more complex model to a smaller, light-weight model using dual-view cross-correlation distillation and the teacher's codebook as learning objectives. We evaluated our model's performance on an Alexa keyword spotting detection task using a 16.6k-hour in-house dataset. Our technique showed exceptional performance in normal and noisy conditions, demonstrating the efficacy of knowledge distillation methods in constructing self-supervised models for keyword spotting tasks while working within on-device resource constraints.",
    "path": "papers/23/07/2307.02720.json",
    "total_tokens": 938,
    "translated_title": "基于设备限制的自监督语音表示学习在关键词检测中的应用及知识蒸馏（arXiv:2307.02720v1 [cs.CL]）",
    "translated_abstract": "大型自监督模型是有效的特征提取器，但在设备内预算限制和有偏差的数据集收集下应用具有挑战性，特别是在关键词检测中。为了解决这个问题，我们提出了一种基于知识蒸馏的自监督语音表示学习（S3RL）架构，用于设备内关键词检测。我们的方法使用教师-学生框架，通过双视图互相关蒸馏和教师的码本作为学习目标，从更大、更复杂的模型中传递知识到更小、轻量级的模型中。我们使用一个16.6k小时的内部数据集，在Alexa的关键词检测任务上评估了我们模型的性能。我们的技术在正常和噪声条件下表现出了出色的性能，证明了知识蒸馏方法在在设备资源限制下构建自监督模型的有效性。",
    "tldr": "这项研究提出了一种基于知识蒸馏的自监督语音表示学习架构，以应用于设备内关键词检测。通过在有限的资源情况下将知识从复杂模型传递给轻量级模型，该方法在关键词检测任务中表现出了出色的性能。",
    "en_tdlr": "This paper presents a knowledge distillation-based self-supervised speech representation learning architecture for on-device keyword spotting. By transferring knowledge from a larger, more complex model to a smaller, lightweight model within limited resources, the approach demonstrates exceptional performance in keyword spotting tasks."
}