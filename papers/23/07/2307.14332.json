{
    "title": "Event-based Vision for Early Prediction of Manipulation Actions. (arXiv:2307.14332v1 [cs.CV])",
    "abstract": "Neuromorphic visual sensors are artificial retinas that output sequences of asynchronous events when brightness changes occur in the scene. These sensors offer many advantages including very high temporal resolution, no motion blur and smart data compression ideal for real-time processing. In this study, we introduce an event-based dataset on fine-grained manipulation actions and perform an experimental study on the use of transformers for action prediction with events. There is enormous interest in the fields of cognitive robotics and human-robot interaction on understanding and predicting human actions as early as possible. Early prediction allows anticipating complex stages for planning, enabling effective and real-time interaction. Our Transformer network uses events to predict manipulation actions as they occur, using online inference. The model succeeds at predicting actions early on, building up confidence over time and achieving state-of-the-art classification. Moreover, the at",
    "link": "http://arxiv.org/abs/2307.14332",
    "context": "Title: Event-based Vision for Early Prediction of Manipulation Actions. (arXiv:2307.14332v1 [cs.CV])\nAbstract: Neuromorphic visual sensors are artificial retinas that output sequences of asynchronous events when brightness changes occur in the scene. These sensors offer many advantages including very high temporal resolution, no motion blur and smart data compression ideal for real-time processing. In this study, we introduce an event-based dataset on fine-grained manipulation actions and perform an experimental study on the use of transformers for action prediction with events. There is enormous interest in the fields of cognitive robotics and human-robot interaction on understanding and predicting human actions as early as possible. Early prediction allows anticipating complex stages for planning, enabling effective and real-time interaction. Our Transformer network uses events to predict manipulation actions as they occur, using online inference. The model succeeds at predicting actions early on, building up confidence over time and achieving state-of-the-art classification. Moreover, the at",
    "path": "papers/23/07/2307.14332.json",
    "total_tokens": 805,
    "translated_title": "基于事件视觉的早期操纵动作预测",
    "translated_abstract": "神经形态视觉传感器是人工视网膜，当场景中发生亮度变化时输出异步事件序列。这些传感器具有很多优势，包括非常高的时间分辨率，没有运动模糊和智能数据压缩，非常适合实时处理。在本研究中，我们介绍了一个关于细粒度操纵动作的基于事件的数据集，并对使用Transformer进行事件动作预测进行了实验研究。在认知机器人和人机交互领域，对理解和预测人类动作的兴趣很大，尽早预测能够让我们预测规划复杂阶段，实现有效的实时交互。我们的Transformer网络使用事件在其发生时预测操纵动作，使用在线推理。该模型能够在早期预测动作，并随着时间推移逐渐建立信心，实现了最先进的分类效果。",
    "tldr": "本研究基于事件的视觉数据集，利用Transformer网络提前预测操纵动作，实现了最先进的分类效果。",
    "en_tdlr": "This study introduces an event-based dataset and uses a Transformer network to early predict manipulation actions, achieving state-of-the-art classification performance."
}