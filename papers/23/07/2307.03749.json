{
    "title": "On the Efficacy of Sampling Adapters. (arXiv:2307.03749v1 [cs.CL])",
    "abstract": "Sampling is a common strategy for generating text from probabilistic models, yet standard ancestral sampling often results in text that is incoherent or ungrammatical. To alleviate this issue, various modifications to a model's sampling distribution, such as nucleus or top-k sampling, have been introduced and are now ubiquitously used in language generation systems. We propose a unified framework for understanding these techniques, which we term sampling adapters. Sampling adapters often lead to qualitatively better text, which raises the question: From a formal perspective, how are they changing the (sub)word-level distributions of language generation models? And why do these local changes lead to higher-quality text? We argue that the shift they enforce can be viewed as a trade-off between precision and recall: while the model loses its ability to produce certain strings, its precision rate on desirable text increases. While this trade-off is not reflected in standard metrics of dist",
    "link": "http://arxiv.org/abs/2307.03749",
    "context": "Title: On the Efficacy of Sampling Adapters. (arXiv:2307.03749v1 [cs.CL])\nAbstract: Sampling is a common strategy for generating text from probabilistic models, yet standard ancestral sampling often results in text that is incoherent or ungrammatical. To alleviate this issue, various modifications to a model's sampling distribution, such as nucleus or top-k sampling, have been introduced and are now ubiquitously used in language generation systems. We propose a unified framework for understanding these techniques, which we term sampling adapters. Sampling adapters often lead to qualitatively better text, which raises the question: From a formal perspective, how are they changing the (sub)word-level distributions of language generation models? And why do these local changes lead to higher-quality text? We argue that the shift they enforce can be viewed as a trade-off between precision and recall: while the model loses its ability to produce certain strings, its precision rate on desirable text increases. While this trade-off is not reflected in standard metrics of dist",
    "path": "papers/23/07/2307.03749.json",
    "total_tokens": 936,
    "translated_title": "采样适配器的效能研究",
    "translated_abstract": "采样是从概率模型生成文本的常见策略，但标准的祖先采样往往导致文本不连贯或不符合语法。为了缓解这个问题，提出了各种修改模型采样分布的技术，如核心或top-k采样，并广泛应用于语言生成系统中。我们提出了一个统一的框架来理解这些技术，称之为采样适配器。采样适配器通常可以生成质量更高的文本，这引发了一个问题：从形式的角度来看，它们是如何改变语言生成模型的（子）词级分布的？为什么这些局部改变会导致更高质量的文本？我们认为，它们所强制执行的转变可以被视为精确度和召回率之间的权衡：虽然模型失去了产生某些字符串的能力，但对于期望的文本，其精确率提高了。尽管这种权衡在标准的距离度量中没有反映出来，但它确实对生成的文本质量起到了重要作用。",
    "tldr": "本研究提出了采样适配器，一种用于改善语言生成的技术，通过改变模型的采样分布来生成质量更高的文本。这种转变可以视为精确度和召回率的权衡，从而提高了期望文本的质量。",
    "en_tdlr": "This research proposes sampling adapters, a technique for improving language generation by changing the sampling distribution of the model to generate higher-quality text. This shift can be seen as a trade-off between precision and recall, resulting in improved quality of desired text."
}