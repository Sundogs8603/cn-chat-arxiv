{
    "title": "Streaming CTR Prediction: Rethinking Recommendation Task for Real-World Streaming Data. (arXiv:2307.07509v1 [cs.IR])",
    "abstract": "The Click-Through Rate (CTR) prediction task is critical in industrial recommender systems, where models are usually deployed on dynamic streaming data in practical applications. Such streaming data in real-world recommender systems face many challenges, such as distribution shift, temporal non-stationarity, and systematic biases, which bring difficulties to the training and utilizing of recommendation models. However, most existing studies approach the CTR prediction as a classification task on static datasets, assuming that the train and test sets are independent and identically distributed (a.k.a, i.i.d. assumption). To bridge this gap, we formulate the CTR prediction problem in streaming scenarios as a Streaming CTR Prediction task. Accordingly, we propose dedicated benchmark settings and metrics to evaluate and analyze the performance of the models in streaming data. To better understand the differences compared to traditional CTR prediction tasks, we delve into the factors that m",
    "link": "http://arxiv.org/abs/2307.07509",
    "context": "Title: Streaming CTR Prediction: Rethinking Recommendation Task for Real-World Streaming Data. (arXiv:2307.07509v1 [cs.IR])\nAbstract: The Click-Through Rate (CTR) prediction task is critical in industrial recommender systems, where models are usually deployed on dynamic streaming data in practical applications. Such streaming data in real-world recommender systems face many challenges, such as distribution shift, temporal non-stationarity, and systematic biases, which bring difficulties to the training and utilizing of recommendation models. However, most existing studies approach the CTR prediction as a classification task on static datasets, assuming that the train and test sets are independent and identically distributed (a.k.a, i.i.d. assumption). To bridge this gap, we formulate the CTR prediction problem in streaming scenarios as a Streaming CTR Prediction task. Accordingly, we propose dedicated benchmark settings and metrics to evaluate and analyze the performance of the models in streaming data. To better understand the differences compared to traditional CTR prediction tasks, we delve into the factors that m",
    "path": "papers/23/07/2307.07509.json",
    "total_tokens": 937,
    "translated_title": "流式CTR预测：重新思考实际应用中的推荐任务的真实世界流数据",
    "translated_abstract": "点击率（CTR）预测任务在工业推荐系统中至关重要，其中模型通常在实际应用中部署在动态流数据上。实际推荐系统中的这些流数据面临着许多挑战，例如分布偏移、时间非平稳性和系统偏差，这给推荐模型的训练和利用带来了困难。然而，大多数现有的研究将CTR预测视为静态数据集上的分类任务，假设训练集和测试集是独立且同分布的（即i.i.d.假设）。为了填补这一差距，我们提出了在流式数据情景下将CTR预测问题形式化为流式CTR预测任务。相应地，我们提出了专门的基准设置和度量标准，以评估和分析模型在流数据上的性能。为了更好地理解与传统CTR预测任务的差异，我们深入研究了影响流数据中CTR预测任务的因素。",
    "tldr": "这篇论文提出了一种针对实际应用中流数据的流式CTR预测任务，用于解决工业推荐系统中的挑战。研究将CTR预测从静态数据集中的分类任务转变为流式数据的预测任务，并提出了相应的基准设置和度量标准。",
    "en_tdlr": "This paper introduces a streaming CTR prediction task for real-world recommender systems, addressing the challenges of distribution shift, temporal non-stationarity, and systematic biases. By formulating CTR prediction as a streaming task, the study provides dedicated benchmarks and metrics to evaluate and analyze model performance on streaming data."
}