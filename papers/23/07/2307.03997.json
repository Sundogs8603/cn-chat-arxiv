{
    "title": "Efficient Model-Free Exploration in Low-Rank MDPs. (arXiv:2307.03997v1 [cs.LG])",
    "abstract": "A major challenge in reinforcement learning is to develop practical, sample-efficient algorithms for exploration in high-dimensional domains where generalization and function approximation is required. Low-Rank Markov Decision Processes -- where transition probabilities admit a low-rank factorization based on an unknown feature embedding -- offer a simple, yet expressive framework for RL with function approximation, but existing algorithms are either (1) computationally intractable, or (2) reliant upon restrictive statistical assumptions such as latent variable structure, access to model-based function approximation, or reachability. In this work, we propose the first provably sample-efficient algorithm for exploration in Low-Rank MDPs that is both computationally efficient and model-free, allowing for general function approximation and requiring no additional structural assumptions. Our algorithm, VoX, uses the notion of a generalized optimal design for the feature embedding as an eff",
    "link": "http://arxiv.org/abs/2307.03997",
    "context": "Title: Efficient Model-Free Exploration in Low-Rank MDPs. (arXiv:2307.03997v1 [cs.LG])\nAbstract: A major challenge in reinforcement learning is to develop practical, sample-efficient algorithms for exploration in high-dimensional domains where generalization and function approximation is required. Low-Rank Markov Decision Processes -- where transition probabilities admit a low-rank factorization based on an unknown feature embedding -- offer a simple, yet expressive framework for RL with function approximation, but existing algorithms are either (1) computationally intractable, or (2) reliant upon restrictive statistical assumptions such as latent variable structure, access to model-based function approximation, or reachability. In this work, we propose the first provably sample-efficient algorithm for exploration in Low-Rank MDPs that is both computationally efficient and model-free, allowing for general function approximation and requiring no additional structural assumptions. Our algorithm, VoX, uses the notion of a generalized optimal design for the feature embedding as an eff",
    "path": "papers/23/07/2307.03997.json",
    "total_tokens": 835,
    "translated_title": "低秩MDP中高效的无模型探索",
    "translated_abstract": "强化学习中一个主要的挑战是在需要泛化和函数逼近的高维领域中开发出实用、样本高效的探索算法。低秩马尔可夫决策过程（MDPs）——其中转移概率可以基于未知特征嵌入进行低秩分解——为带有函数逼近的强化学习提供了简单而富有表现力的框架，但现有算法要么计算复杂度很高，要么依赖于限制性的统计假设，如潜变量结构、对模型为基础的函数逼近的访问性或可达性。在这项工作中，我们提出了第一个经过验证的低秩MDPs探索的样本高效算法，该算法既计算高效又无模型，允许进行通用的函数逼近，并且不需要额外的结构假设。我们的算法VoX使用了一个广义优化设计的特征嵌入概念作为探索的效能。",
    "tldr": "提出了第一个计算高效、无模型的低秩MDPs探索算法，允许通用函数逼近，不需要额外的结构假设。"
}