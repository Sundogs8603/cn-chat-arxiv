{
    "title": "HUGE: Huge Unsupervised Graph Embeddings with TPUs. (arXiv:2307.14490v1 [cs.LG])",
    "abstract": "Graphs are a representation of structured data that captures the relationships between sets of objects. With the ubiquity of available network data, there is increasing industrial and academic need to quickly analyze graphs with billions of nodes and trillions of edges. A common first step for network understanding is Graph Embedding, the process of creating a continuous representation of nodes in a graph. A continuous representation is often more amenable, especially at scale, for solving downstream machine learning tasks such as classification, link prediction, and clustering. A high-performance graph embedding architecture leveraging Tensor Processing Units (TPUs) with configurable amounts of high-bandwidth memory is presented that simplifies the graph embedding problem and can scale to graphs with billions of nodes and trillions of edges. We verify the embedding space quality on real and synthetic large-scale datasets.",
    "link": "http://arxiv.org/abs/2307.14490",
    "context": "Title: HUGE: Huge Unsupervised Graph Embeddings with TPUs. (arXiv:2307.14490v1 [cs.LG])\nAbstract: Graphs are a representation of structured data that captures the relationships between sets of objects. With the ubiquity of available network data, there is increasing industrial and academic need to quickly analyze graphs with billions of nodes and trillions of edges. A common first step for network understanding is Graph Embedding, the process of creating a continuous representation of nodes in a graph. A continuous representation is often more amenable, especially at scale, for solving downstream machine learning tasks such as classification, link prediction, and clustering. A high-performance graph embedding architecture leveraging Tensor Processing Units (TPUs) with configurable amounts of high-bandwidth memory is presented that simplifies the graph embedding problem and can scale to graphs with billions of nodes and trillions of edges. We verify the embedding space quality on real and synthetic large-scale datasets.",
    "path": "papers/23/07/2307.14490.json",
    "total_tokens": 792,
    "translated_title": "HUGE: 使用TPU进行巨大无监督图嵌入",
    "translated_abstract": "图是一种捕捉对象集合之间关系的结构化数据表示形式。随着可用网络数据的普及性，工业和学术界对于快速分析具有数十亿节点和数万亿边的图的需求越来越大。网络理解的常见首要步骤是图嵌入，即创建图中节点的连续表示的过程。连续表示通常更易于处理，尤其在规模上，用于解决下游的机器学习任务，如分类、链接预测和聚类。我们提出了一种利用可配置高带宽内存的张量处理单元（TPU）的高性能图嵌入架构，简化了图嵌入问题，并可以扩展到具有数十亿节点和数万亿边的图。我们在真实和合成的大规模数据集上验证了嵌入空间的质量。",
    "tldr": "本文提出了一种利用TPU进行高性能图嵌入的架构，能够处理具有数十亿节点和数万亿边的图。验证了嵌入空间质量。"
}