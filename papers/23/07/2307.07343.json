{
    "title": "MaxMin-L2-SVC-NCH: A New Method to Train Support Vector Classifier with the Selection of Model's Parameters. (arXiv:2307.07343v1 [cs.LG])",
    "abstract": "The selection of model's parameters plays an important role in the application of support vector classification (SVC). The commonly used method of selecting model's parameters is the k-fold cross validation with grid search (CV). It is extremely time-consuming because it needs to train a large number of SVC models. In this paper, a new method is proposed to train SVC with the selection of model's parameters. Firstly, training SVC with the selection of model's parameters is modeled as a minimax optimization problem (MaxMin-L2-SVC-NCH), in which the minimization problem is an optimization problem of finding the closest points between two normal convex hulls (L2-SVC-NCH) while the maximization problem is an optimization problem of finding the optimal model's parameters. A lower time complexity can be expected in MaxMin-L2-SVC-NCH because CV is abandoned. A gradient-based algorithm is then proposed to solve MaxMin-L2-SVC-NCH, in which L2-SVC-NCH is solved by a projected gradient algorithm ",
    "link": "http://arxiv.org/abs/2307.07343",
    "context": "Title: MaxMin-L2-SVC-NCH: A New Method to Train Support Vector Classifier with the Selection of Model's Parameters. (arXiv:2307.07343v1 [cs.LG])\nAbstract: The selection of model's parameters plays an important role in the application of support vector classification (SVC). The commonly used method of selecting model's parameters is the k-fold cross validation with grid search (CV). It is extremely time-consuming because it needs to train a large number of SVC models. In this paper, a new method is proposed to train SVC with the selection of model's parameters. Firstly, training SVC with the selection of model's parameters is modeled as a minimax optimization problem (MaxMin-L2-SVC-NCH), in which the minimization problem is an optimization problem of finding the closest points between two normal convex hulls (L2-SVC-NCH) while the maximization problem is an optimization problem of finding the optimal model's parameters. A lower time complexity can be expected in MaxMin-L2-SVC-NCH because CV is abandoned. A gradient-based algorithm is then proposed to solve MaxMin-L2-SVC-NCH, in which L2-SVC-NCH is solved by a projected gradient algorithm ",
    "path": "papers/23/07/2307.07343.json",
    "total_tokens": 930,
    "translated_title": "MaxMin-L2-SVC-NCH:一种用于训练支持向量分类器并选择模型参数的新方法",
    "translated_abstract": "模型参数的选择在支持向量分类（SVC）的应用中发挥着重要作用。常用的选择模型参数的方法是k折交叉验证与格点搜索（CV）。由于需要训练大量的SVC模型，这个方法非常耗时。本文提出了一种新方法，用于训练SVC并选择模型参数。首先，将具有模型参数选择的SVC训练建模为极小化极大优化问题（MaxMin-L2-SVC-NCH），其中极小化问题是寻找两个正常凸壳之间最接近点的优化问题（L2-SVC-NCH），而极大化问题是寻找最优模型参数的优化问题。MaxMin-L2-SVC-NCH具有较低的时间复杂度，因为放弃了CV。然后，提出了一种基于梯度的算法来求解MaxMin-L2-SVC-NCH，其中L2-SVC-NCH通过投影梯度算法求解。",
    "tldr": "本文提出了一种新的方法，用于训练支持向量分类器并选择模型参数。通过建模为极小化极大优化问题，利用投影梯度算法求解，实现了更低的时间复杂度。",
    "en_tdlr": "A new method is proposed in this paper to train Support Vector Classifiers (SVC) with the selection of model's parameters, which is formulated as a minimax optimization problem (MaxMin-L2-SVC-NCH). The method achieves a lower time complexity by abandoning k-fold cross validation and using a gradient-based algorithm to solve the optimization problem."
}