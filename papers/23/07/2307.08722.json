{
    "title": "Certifying the Fairness of KNN in the Presence of Dataset Bias. (arXiv:2307.08722v1 [cs.LG])",
    "abstract": "We propose a method for certifying the fairness of the classification result of a widely used supervised learning algorithm, the k-nearest neighbors (KNN), under the assumption that the training data may have historical bias caused by systematic mislabeling of samples from a protected minority group. To the best of our knowledge, this is the first certification method for KNN based on three variants of the fairness definition: individual fairness, $\\epsilon$-fairness, and label-flipping fairness. We first define the fairness certification problem for KNN and then propose sound approximations of the complex arithmetic computations used in the state-of-the-art KNN algorithm. This is meant to lift the computation results from the concrete domain to an abstract domain, to reduce the computational cost. We show effectiveness of this abstract interpretation based technique through experimental evaluation on six datasets widely used in the fairness research literature. We also show that the m",
    "link": "http://arxiv.org/abs/2307.08722",
    "context": "Title: Certifying the Fairness of KNN in the Presence of Dataset Bias. (arXiv:2307.08722v1 [cs.LG])\nAbstract: We propose a method for certifying the fairness of the classification result of a widely used supervised learning algorithm, the k-nearest neighbors (KNN), under the assumption that the training data may have historical bias caused by systematic mislabeling of samples from a protected minority group. To the best of our knowledge, this is the first certification method for KNN based on three variants of the fairness definition: individual fairness, $\\epsilon$-fairness, and label-flipping fairness. We first define the fairness certification problem for KNN and then propose sound approximations of the complex arithmetic computations used in the state-of-the-art KNN algorithm. This is meant to lift the computation results from the concrete domain to an abstract domain, to reduce the computational cost. We show effectiveness of this abstract interpretation based technique through experimental evaluation on six datasets widely used in the fairness research literature. We also show that the m",
    "path": "papers/23/07/2307.08722.json",
    "total_tokens": 834,
    "translated_title": "在存在数据集偏差的情况下，对KNN的公平性进行认证",
    "translated_abstract": "我们提出了一种方法，用于在训练数据可能存在历史偏差的情况下，对广泛使用的有监督学习算法KNN的分类结果的公平性进行认证。该方法基于三种公平性定义的变体：个体公平性、ε-公平性和标签翻转公平性。我们首先定义了KNN的公平性认证问题，然后提出了在最先进的KNN算法中使用的复杂算术计算的可靠近似。这旨在将计算结果从具体域提升到抽象域，以降低计算成本。通过在公平研究文献中广泛使用的六个数据集上进行实验评估，我们展示了这种基于抽象解释技术的方法的有效性。",
    "tldr": "本文提出了一种方法，用于在存在数据集偏差的情况下对KNN的公平性进行认证。通过近似计算方法，我们实现了在抽象域中计算的方式，从而降低了计算成本，并在多个数据集上进行了实验证明方法的有效性。",
    "en_tdlr": "This paper proposes a method to certify the fairness of KNN in the presence of dataset bias. By using approximation computations in the abstract domain, the computational cost is reduced, and the effectiveness of the method is demonstrated on multiple datasets."
}