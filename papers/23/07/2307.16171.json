{
    "title": "HierVST: Hierarchical Adaptive Zero-shot Voice Style Transfer. (arXiv:2307.16171v1 [cs.SD])",
    "abstract": "Despite rapid progress in the voice style transfer (VST) field, recent zero-shot VST systems still lack the ability to transfer the voice style of a novel speaker. In this paper, we present HierVST, a hierarchical adaptive end-to-end zero-shot VST model. Without any text transcripts, we only use the speech dataset to train the model by utilizing hierarchical variational inference and self-supervised representation. In addition, we adopt a hierarchical adaptive generator that generates the pitch representation and waveform audio sequentially. Moreover, we utilize unconditional generation to improve the speaker-relative acoustic capacity in the acoustic representation. With a hierarchical adaptive structure, the model can adapt to a novel voice style and convert speech progressively. The experimental results demonstrate that our method outperforms other VST models in zero-shot VST scenarios. Audio samples are available at \\url{https://hiervst.github.io/}.",
    "link": "http://arxiv.org/abs/2307.16171",
    "context": "Title: HierVST: Hierarchical Adaptive Zero-shot Voice Style Transfer. (arXiv:2307.16171v1 [cs.SD])\nAbstract: Despite rapid progress in the voice style transfer (VST) field, recent zero-shot VST systems still lack the ability to transfer the voice style of a novel speaker. In this paper, we present HierVST, a hierarchical adaptive end-to-end zero-shot VST model. Without any text transcripts, we only use the speech dataset to train the model by utilizing hierarchical variational inference and self-supervised representation. In addition, we adopt a hierarchical adaptive generator that generates the pitch representation and waveform audio sequentially. Moreover, we utilize unconditional generation to improve the speaker-relative acoustic capacity in the acoustic representation. With a hierarchical adaptive structure, the model can adapt to a novel voice style and convert speech progressively. The experimental results demonstrate that our method outperforms other VST models in zero-shot VST scenarios. Audio samples are available at \\url{https://hiervst.github.io/}.",
    "path": "papers/23/07/2307.16171.json",
    "total_tokens": 901,
    "translated_title": "HierVST: 分层自适应零样本语音风格转换",
    "translated_abstract": "尽管语音风格转换（VST）领域取得了快速的进展，但最近的零样本VST系统仍然缺乏将新型说话者的语音风格转换的能力。本文提出了HierVST，一种层次自适应的端到端零样本VST模型。在没有任何文本转录的情况下，我们只使用语音数据集通过利用层次变分推断和自监督表示来训练模型。此外，我们采用了一种分层自适应生成器，以顺序方式生成音高表示和波形音频。此外，我们利用无条件生成来提高声纹相对声学能力。通过分层自适应结构，该模型可以适应新的语音风格并逐步转换语音。实验结果表明，我们的方法在零样本VST场景中优于其他VST模型。音频样本可在 \\url{https://hiervst.github.io/} 获取。",
    "tldr": "HierVST是一个层次自适应的零样本语音风格转换模型，通过利用层次变分推断和自监督表示训练，该模型能够适应新的语音风格并逐步转换语音。实验结果表明，在零样本VST场景中，HierVST的性能优于其他VST模型。"
}