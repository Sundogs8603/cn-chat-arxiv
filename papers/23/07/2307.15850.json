{
    "title": "Comprehensive Algorithm Portfolio Evaluation using Item Response Theory. (arXiv:2307.15850v1 [stat.ML])",
    "abstract": "Item Response Theory (IRT) has been proposed within the field of Educational Psychometrics to assess student ability as well as test question difficulty and discrimination power. More recently, IRT has been applied to evaluate machine learning algorithm performance on a single classification dataset, where the student is now an algorithm, and the test question is an observation to be classified by the algorithm. In this paper we present a modified IRT-based framework for evaluating a portfolio of algorithms across a repository of datasets, while simultaneously eliciting a richer suite of characteristics such as algorithm consistency and anomalousness - that describe important aspects of algorithm performance. These characteristics arise from a novel inversion and reinterpretation of the traditional IRT model without requiring additional dataset feature computations. We test this framework on algorithm portfolios for a wide range of applications, demonstrating the broad applicability ",
    "link": "http://arxiv.org/abs/2307.15850",
    "context": "Title: Comprehensive Algorithm Portfolio Evaluation using Item Response Theory. (arXiv:2307.15850v1 [stat.ML])\nAbstract: Item Response Theory (IRT) has been proposed within the field of Educational Psychometrics to assess student ability as well as test question difficulty and discrimination power. More recently, IRT has been applied to evaluate machine learning algorithm performance on a single classification dataset, where the student is now an algorithm, and the test question is an observation to be classified by the algorithm. In this paper we present a modified IRT-based framework for evaluating a portfolio of algorithms across a repository of datasets, while simultaneously eliciting a richer suite of characteristics such as algorithm consistency and anomalousness - that describe important aspects of algorithm performance. These characteristics arise from a novel inversion and reinterpretation of the traditional IRT model without requiring additional dataset feature computations. We test this framework on algorithm portfolios for a wide range of applications, demonstrating the broad applicability ",
    "path": "papers/23/07/2307.15850.json",
    "total_tokens": 853,
    "translated_title": "使用项目反应理论对综合算法组合进行评估",
    "translated_abstract": "项目反应理论（IRT）被提出用于教育心理测量学领域，用于评估学生能力、测试题难度和区分度。最近，IRT已被应用于评估单个分类数据集上的机器学习算法性能，其中学生现在是一个算法，而测试题是算法要对观察结果进行分类。本文提出了一种改进的基于IRT的框架，用于评估一个算法组合在一个数据集仓库中的表现，同时获取算法一致性和异常性等更丰富的特征，这些特征描述了算法性能的重要方面。这些特征是通过对传统IRT模型进行新颖的倒转和重新解释而得到的，而不需要额外的数据集特征计算。我们对不同应用的算法组合在该框架上进行了测试，证明了其广泛适用性。",
    "tldr": "本文提出了一种改进的基于IRT的框架，用于评估算法组合在数据集仓库中的性能，同时获取算法一致性和异常性等特征。该框架通过对传统IRT模型进行倒转和重新解释来实现，不需要额外的数据集特征计算。",
    "en_tdlr": "This paper presents a modified IRT-based framework for evaluating algorithm portfolios across a repository of datasets, while simultaneously capturing characteristics such as algorithm consistency and anomalousness. The framework involves inverting and reinterpreting the traditional IRT model, eliminating the need for additional dataset feature computations."
}