{
    "title": "Generating Image-Specific Text Improves Fine-grained Image Classification. (arXiv:2307.11315v1 [cs.CV])",
    "abstract": "Recent vision-language models outperform vision-only models on many image classification tasks. However, because of the absence of paired text/image descriptions, it remains difficult to fine-tune these models for fine-grained image classification. In this work, we propose a method, GIST, for generating image-specific fine-grained text descriptions from image-only datasets, and show that these text descriptions can be used to improve classification. Key parts of our method include 1. prompting a pretrained large language model with domain-specific prompts to generate diverse fine-grained text descriptions for each class and 2. using a pretrained vision-language model to match each image to label-preserving text descriptions that capture relevant visual features in the image. We demonstrate the utility of GIST by fine-tuning vision-language models on the image-and-generated-text pairs to learn an aligned vision-language representation space for improved classification. We evaluate our l",
    "link": "http://arxiv.org/abs/2307.11315",
    "context": "Title: Generating Image-Specific Text Improves Fine-grained Image Classification. (arXiv:2307.11315v1 [cs.CV])\nAbstract: Recent vision-language models outperform vision-only models on many image classification tasks. However, because of the absence of paired text/image descriptions, it remains difficult to fine-tune these models for fine-grained image classification. In this work, we propose a method, GIST, for generating image-specific fine-grained text descriptions from image-only datasets, and show that these text descriptions can be used to improve classification. Key parts of our method include 1. prompting a pretrained large language model with domain-specific prompts to generate diverse fine-grained text descriptions for each class and 2. using a pretrained vision-language model to match each image to label-preserving text descriptions that capture relevant visual features in the image. We demonstrate the utility of GIST by fine-tuning vision-language models on the image-and-generated-text pairs to learn an aligned vision-language representation space for improved classification. We evaluate our l",
    "path": "papers/23/07/2307.11315.json",
    "total_tokens": 861,
    "translated_title": "生成图像特定文本改善细粒度图像分类",
    "translated_abstract": "最近的视觉语言模型在许多图像分类任务上优于仅视觉模型。然而，由于缺乏配对的文本/图像描述，对于细粒度图像分类来说，仍然很难对这些模型进行微调。在这项工作中，我们提出了一种名为GIST的方法，用于从仅图像数据集中生成图像特定的细粒度文本描述，并表明这些文本描述可以用于改善分类。我们方法的关键部分包括：1. 使用特定领域的提示为预训练的大型语言模型生成多样的细粒度文本描述，以及2. 使用预训练的视觉语言模型将每个图像与保留标签的文本描述进行匹配，这些描述捕捉了图像中相关的视觉特征。我们通过在图像和生成的文本对上微调视觉语言模型来学习一个对齐的视觉语言表示空间，以实现改进的分类。我们评估了GIST的效果。",
    "tldr": "本文提出了一种名为GIST的方法，用于从仅图像数据集中生成图像特定的细粒度文本描述，并通过将其用于微调视觉语言模型来改进图像分类的效果。",
    "en_tdlr": "This paper proposes a method called GIST for generating image-specific fine-grained text descriptions from image-only datasets, and improves image classification by fine-tuning vision-language models using these descriptions."
}