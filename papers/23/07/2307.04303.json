{
    "title": "Learning to Generate Equitable Text in Dialogue from Biased Training Data. (arXiv:2307.04303v1 [cs.CL])",
    "abstract": "The ingrained principles of fairness in a dialogue system's decision-making process and generated responses are crucial for user engagement, satisfaction, and task achievement. Absence of equitable and inclusive principles can hinder the formation of common ground, which in turn negatively impacts the overall performance of the system. For example, misusing pronouns in a user interaction may cause ambiguity about the intended subject. Yet, there is no comprehensive study of equitable text generation in dialogue. Aptly, in this work, we use theories of computational learning to study this problem. We provide formal definitions of equity in text generation, and further, prove formal connections between learning human-likeness and learning equity: algorithms for improving equity ultimately reduce to algorithms for improving human-likeness (on augmented data). With this insight, we also formulate reasonable conditions under which text generation algorithms can learn to generate equitable t",
    "link": "http://arxiv.org/abs/2307.04303",
    "context": "Title: Learning to Generate Equitable Text in Dialogue from Biased Training Data. (arXiv:2307.04303v1 [cs.CL])\nAbstract: The ingrained principles of fairness in a dialogue system's decision-making process and generated responses are crucial for user engagement, satisfaction, and task achievement. Absence of equitable and inclusive principles can hinder the formation of common ground, which in turn negatively impacts the overall performance of the system. For example, misusing pronouns in a user interaction may cause ambiguity about the intended subject. Yet, there is no comprehensive study of equitable text generation in dialogue. Aptly, in this work, we use theories of computational learning to study this problem. We provide formal definitions of equity in text generation, and further, prove formal connections between learning human-likeness and learning equity: algorithms for improving equity ultimately reduce to algorithms for improving human-likeness (on augmented data). With this insight, we also formulate reasonable conditions under which text generation algorithms can learn to generate equitable t",
    "path": "papers/23/07/2307.04303.json",
    "total_tokens": 838,
    "translated_title": "从偏见训练数据中学习生成对话中公平的文本",
    "translated_abstract": "对话系统在决策过程和生成回复中注重公平原则对于用户的参与、满意度和任务完成至关重要。缺乏公平和包容原则可能阻碍共同基础的形成，从而对系统的整体性能产生负面影响。然而，关于对话中公平文本生成的综合研究还不全面。因此，在这项工作中，我们使用计算学习的理论来研究这个问题。我们提供了文本生成中公平的正式定义，并进一步证明了学习人类样式和学习公平之间的正式关联：改进公平的算法最终归结为改善人类样式的算法（在扩充数据上）。基于这个理解，我们还制定了合理的条件，使得文本生成算法能够学习生成公平的文本。",
    "tldr": "该论文研究了从偏见的训练数据中学习生成对话中公平文本的问题，提供了公平文本生成的正式定义，并证明了学习公平可以归结为改善人类样式的算法。",
    "en_tdlr": "This paper investigates the problem of learning to generate equitable text in dialogue from biased training data. It provides formal definitions of equitable text generation and establishes a formal connection between learning equity and learning human-likeness, showing that algorithms for improving equity ultimately reduce to algorithms for improving human-likeness."
}