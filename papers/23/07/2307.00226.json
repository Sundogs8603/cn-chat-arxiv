{
    "title": "S-Omninet: Structured Data Enhanced Universal Multimodal Learning Architecture. (arXiv:2307.00226v1 [cs.CV])",
    "abstract": "Multimodal multitask learning has attracted an increasing interest in recent years. Singlemodal models have been advancing rapidly and have achieved astonishing results on various tasks across multiple domains. Multimodal learning offers opportunities for further improvements by integrating data from multiple modalities. Many methods are proposed to learn on a specific type of multimodal data, such as vision and language data. A few of them are designed to handle several modalities and tasks at a time. In this work, we extend and improve Omninet, an architecture that is capable of handling multiple modalities and tasks at a time, by introducing cross-cache attention, integrating patch embeddings for vision inputs, and supporting structured data. The proposed Structured-data-enhanced Omninet (S-Omninet) is a universal model that is capable of learning from structured data of various dimensions effectively with unstructured data through cross-cache attention, which enables interactions a",
    "link": "http://arxiv.org/abs/2307.00226",
    "context": "Title: S-Omninet: Structured Data Enhanced Universal Multimodal Learning Architecture. (arXiv:2307.00226v1 [cs.CV])\nAbstract: Multimodal multitask learning has attracted an increasing interest in recent years. Singlemodal models have been advancing rapidly and have achieved astonishing results on various tasks across multiple domains. Multimodal learning offers opportunities for further improvements by integrating data from multiple modalities. Many methods are proposed to learn on a specific type of multimodal data, such as vision and language data. A few of them are designed to handle several modalities and tasks at a time. In this work, we extend and improve Omninet, an architecture that is capable of handling multiple modalities and tasks at a time, by introducing cross-cache attention, integrating patch embeddings for vision inputs, and supporting structured data. The proposed Structured-data-enhanced Omninet (S-Omninet) is a universal model that is capable of learning from structured data of various dimensions effectively with unstructured data through cross-cache attention, which enables interactions a",
    "path": "papers/23/07/2307.00226.json",
    "total_tokens": 868,
    "translated_title": "S-Omninet: 结构化数据增强的通用多模态学习架构",
    "translated_abstract": "多模态多任务学习近年来越来越受到关注。单模态模型在各个领域的多个任务上取得了惊人的进展。通过整合来自多个模态的数据，多模态学习提供了进一步改进的机会。许多方法被提出来处理特定类型的多模态数据，如视觉和语言数据。其中一些方法设计用于同时处理多个模态和任务。在这项工作中，我们通过引入交叉缓存注意力、整合视觉输入的块嵌入和支持结构化数据来扩展和改进Omninet，一种能够同时处理多个模态和任务的架构。提出的结构化数据增强的Omninet (S-Omninet) 是一种通用模型，通过交叉缓存注意力能够有效地从各个维度的结构化数据和非结构化数据中学习。",
    "tldr": "S-Omninet是一种结构化数据增强的通用多模态学习架构，通过引入交叉缓存注意力、整合视觉输入的块嵌入和支持结构化数据，能够同时处理多个模态和任务，有效地学习来自各个维度的结构化数据和非结构化数据。"
}