{
    "title": "Learning to Sample Tasks for Meta Learning. (arXiv:2307.08924v1 [cs.LG])",
    "abstract": "Through experiments on various meta-learning methods, task samplers, and few-shot learning tasks, this paper arrives at three conclusions. Firstly, there are no universal task sampling strategies to guarantee the performance of meta-learning models. Secondly, task diversity can cause the models to either underfit or overfit during training. Lastly, the generalization performance of the models are influenced by task divergence, task entropy, and task difficulty. In response to these findings, we propose a novel task sampler called Adaptive Sampler (ASr). ASr is a plug-and-play task sampler that takes task divergence, task entropy, and task difficulty to sample tasks. To optimize ASr, we rethink and propose a simple and general meta-learning algorithm. Finally, a large number of empirical experiments demonstrate the effectiveness of the proposed ASr.",
    "link": "http://arxiv.org/abs/2307.08924",
    "context": "Title: Learning to Sample Tasks for Meta Learning. (arXiv:2307.08924v1 [cs.LG])\nAbstract: Through experiments on various meta-learning methods, task samplers, and few-shot learning tasks, this paper arrives at three conclusions. Firstly, there are no universal task sampling strategies to guarantee the performance of meta-learning models. Secondly, task diversity can cause the models to either underfit or overfit during training. Lastly, the generalization performance of the models are influenced by task divergence, task entropy, and task difficulty. In response to these findings, we propose a novel task sampler called Adaptive Sampler (ASr). ASr is a plug-and-play task sampler that takes task divergence, task entropy, and task difficulty to sample tasks. To optimize ASr, we rethink and propose a simple and general meta-learning algorithm. Finally, a large number of empirical experiments demonstrate the effectiveness of the proposed ASr.",
    "path": "papers/23/07/2307.08924.json",
    "total_tokens": 1011,
    "translated_title": "学习采样任务用于元学习",
    "translated_abstract": "通过对各种元学习方法、任务采样器和少样本学习任务的实验，本文得出了三个结论。首先，没有通用的任务采样策略能保证元学习模型的性能。其次，任务的多样性会导致模型在训练过程中出现欠拟合或过拟合的问题。最后，模型的泛化性能受到任务的差异、任务熵和任务难度的影响。针对这些发现，我们提出了一种新颖的任务采样器，称为自适应采样器（ASr）。ASr是一个即插即用的任务采样器，它利用任务的差异、任务熵和任务难度来采样任务。为了优化ASr，我们重新思考并提出了一个简单而通用的元学习算法。最后，大量的实证实验证明了所提出的ASr的有效性。",
    "tldr": "通过实验得出了三个结论：没有通用的任务采样策略能保证元学习模型的性能；任务的多样性会导致模型在训练过程中出现欠拟合或过拟合的问题；模型的泛化性能受到任务的差异、任务熵和任务难度的影响。针对这些发现，提出了一种新颖的任务采样器ASr，它利用任务的差异、任务熵和任务难度来采样任务，并通过重新思考和提出一个简单而通用的元学习算法来优化ASr。大量实证实验表明了ASr的有效性。",
    "en_tdlr": "This paper presents three conclusions: there are no universal task sampling strategies for guaranteeing the performance of meta-learning models, task diversity can lead to underfitting or overfitting during training, and the generalization performance of the models is influenced by task divergence, task entropy, and task difficulty. To address these findings, the paper proposes a novel task sampler called Adaptive Sampler (ASr), which takes into account task divergence, task entropy, and task difficulty for sampling tasks. Additionally, a simple and general meta-learning algorithm is proposed to optimize ASr, and empirical experiments demonstrate the effectiveness of the proposed approach."
}