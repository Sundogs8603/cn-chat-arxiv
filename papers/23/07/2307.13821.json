{
    "title": "Fitting Auditory Filterbanks with Multiresolution Neural Networks. (arXiv:2307.13821v1 [cs.SD])",
    "abstract": "Waveform-based deep learning faces a dilemma between nonparametric and parametric approaches. On one hand, convolutional neural networks (convnets) may approximate any linear time-invariant system; yet, in practice, their frequency responses become more irregular as their receptive fields grow. On the other hand, a parametric model such as LEAF is guaranteed to yield Gabor filters, hence an optimal time-frequency localization; yet, this strong inductive bias comes at the detriment of representational capacity. In this paper, we aim to overcome this dilemma by introducing a neural audio model, named multiresolution neural network (MuReNN). The key idea behind MuReNN is to train separate convolutional operators over the octave subbands of a discrete wavelet transform (DWT). Since the scale of DWT atoms grows exponentially between octaves, the receptive fields of the subsequent learnable convolutions in MuReNN are dilated accordingly. For a given real-world dataset, we fit the magnitude r",
    "link": "http://arxiv.org/abs/2307.13821",
    "context": "Title: Fitting Auditory Filterbanks with Multiresolution Neural Networks. (arXiv:2307.13821v1 [cs.SD])\nAbstract: Waveform-based deep learning faces a dilemma between nonparametric and parametric approaches. On one hand, convolutional neural networks (convnets) may approximate any linear time-invariant system; yet, in practice, their frequency responses become more irregular as their receptive fields grow. On the other hand, a parametric model such as LEAF is guaranteed to yield Gabor filters, hence an optimal time-frequency localization; yet, this strong inductive bias comes at the detriment of representational capacity. In this paper, we aim to overcome this dilemma by introducing a neural audio model, named multiresolution neural network (MuReNN). The key idea behind MuReNN is to train separate convolutional operators over the octave subbands of a discrete wavelet transform (DWT). Since the scale of DWT atoms grows exponentially between octaves, the receptive fields of the subsequent learnable convolutions in MuReNN are dilated accordingly. For a given real-world dataset, we fit the magnitude r",
    "path": "papers/23/07/2307.13821.json",
    "total_tokens": 975,
    "translated_title": "用多分辨率神经网络拟合听觉滤波器组",
    "translated_abstract": "基于波形的深度学习面临非参数和参数方法之间的困境。一方面，卷积神经网络（convnets）可以近似任何线性时不变系统；然而，在实践中，它们的频率响应随着感受野的增长变得更加不规则。另一方面，诸如LEAF之类的参数模型保证产生Gabor滤波器，从而实现最佳的时频定位；然而，这种强烈的归纳偏见不利于表示能力。本文旨在通过引入名为多分辨率神经网络（MuReNN）的神经音频模型来克服这一困境。MuReNN背后的核心思想是在离散小波变换（DWT）的八度子带上训练单独的卷积算子。由于DWT原子的尺度在八度之间按指数增长，MuReNN中后续可学习卷积的感受野也相应扩张。对于给定的真实世界数据集，我们拟合了幅度...",
    "tldr": "本文提出了一种名为多分辨率神经网络（MuReNN）的神经音频模型，通过在离散小波变换（DWT）的八度子带上训练单独的卷积算子，解决了基于波形的深度学习面临的非参数和参数方法之间的困境。",
    "en_tdlr": "This paper introduces a neural audio model called Multi-resolution Neural Network (MuReNN) that trains separate convolutional operators over the octave subbands of a discrete wavelet transform (DWT), overcoming the dilemma between nonparametric and parametric approaches faced by waveform-based deep learning."
}