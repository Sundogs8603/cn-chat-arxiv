{
    "title": "Mao-Zedong At SemEval-2023 Task 4: Label Represention Multi-Head Attention Model With Contrastive Learning-Enhanced Nearest Neighbor Mechanism For Multi-Label Text Classification. (arXiv:2307.05174v1 [cs.CL])",
    "abstract": "The study of human values is essential in both practical and theoretical domains. With the development of computational linguistics, the creation of large-scale datasets has made it possible to automatically recognize human values accurately. SemEval 2023 Task 4\\cite{kiesel:2023} provides a set of arguments and 20 types of human values that are implicitly expressed in each argument. In this paper, we present our team's solution. We use the Roberta\\cite{liu_roberta_2019} model to obtain the word vector encoding of the document and propose a multi-head attention mechanism to establish connections between specific labels and semantic components. Furthermore, we use a contrastive learning-enhanced K-nearest neighbor mechanism\\cite{su_contrastive_2022} to leverage existing instance information for prediction. Our approach achieved an F1 score of 0.533 on the test set and ranked fourth on the leaderboard.",
    "link": "http://arxiv.org/abs/2307.05174",
    "context": "Title: Mao-Zedong At SemEval-2023 Task 4: Label Represention Multi-Head Attention Model With Contrastive Learning-Enhanced Nearest Neighbor Mechanism For Multi-Label Text Classification. (arXiv:2307.05174v1 [cs.CL])\nAbstract: The study of human values is essential in both practical and theoretical domains. With the development of computational linguistics, the creation of large-scale datasets has made it possible to automatically recognize human values accurately. SemEval 2023 Task 4\\cite{kiesel:2023} provides a set of arguments and 20 types of human values that are implicitly expressed in each argument. In this paper, we present our team's solution. We use the Roberta\\cite{liu_roberta_2019} model to obtain the word vector encoding of the document and propose a multi-head attention mechanism to establish connections between specific labels and semantic components. Furthermore, we use a contrastive learning-enhanced K-nearest neighbor mechanism\\cite{su_contrastive_2022} to leverage existing instance information for prediction. Our approach achieved an F1 score of 0.533 on the test set and ranked fourth on the leaderboard.",
    "path": "papers/23/07/2307.05174.json",
    "total_tokens": 890,
    "translated_title": "Mao-Zedong在SemEval-2023任务4中：用对比学习增强的最近邻机制的标签表示多头注意力模型进行多标签文本分类",
    "translated_abstract": "人类价值观的研究在实践和理论领域都是至关重要的。随着计算语言学的发展，大规模数据集的创建使得能够准确地自动识别人类价值观成为可能。SemEval 2023任务4提供了一组论证和20种人类价值观，这些人类价值观在每个论证中都是隐含表达的。本文介绍了我们团队的解决方案。我们使用Roberta模型获取文档的词向量编码，并提出了一种多头注意力机制来建立特定标签和语义组件之间的联系。此外，我们使用对比学习增强的K最近邻机制来利用现有的实例信息进行预测。我们的方法在测试集上取得了0.533的F1分数，并在排行榜上排名第四。",
    "tldr": "本文介绍了一个用于多标签文本分类的标签表示多头注意力模型，通过对比学习增强的最近邻机制来提高预测性能，在SemEval 2023任务4中取得了较高的排名。",
    "en_tdlr": "This paper presents a label representation multi-head attention model for multi-label text classification, leveraging a contrastive learning-enhanced nearest neighbor mechanism for improved prediction performance, achieving a high rank in SemEval 2023 Task 4."
}