{
    "title": "Variance-reduced accelerated methods for decentralized stochastic double-regularized nonconvex strongly-concave minimax problems. (arXiv:2307.07113v1 [math.OC])",
    "abstract": "In this paper, we consider the decentralized, stochastic nonconvex strongly-concave (NCSC) minimax problem with nonsmooth regularization terms on both primal and dual variables, wherein a network of $m$ computing agents collaborate via peer-to-peer communications. We consider when the coupling function is in expectation or finite-sum form and the double regularizers are convex functions, applied separately to the primal and dual variables. Our algorithmic framework introduces a Lagrangian multiplier to eliminate the consensus constraint on the dual variable. Coupling this with variance-reduction (VR) techniques, our proposed method, entitled VRLM, by a single neighbor communication per iteration, is able to achieve an $\\mathcal{O}(\\kappa^3\\varepsilon^{-3})$ sample complexity under the general stochastic setting, with either a big-batch or small-batch VR option, where $\\kappa$ is the condition number of the problem and $\\varepsilon$ is the desired solution accuracy. With a big-batch VR,",
    "link": "http://arxiv.org/abs/2307.07113",
    "context": "Title: Variance-reduced accelerated methods for decentralized stochastic double-regularized nonconvex strongly-concave minimax problems. (arXiv:2307.07113v1 [math.OC])\nAbstract: In this paper, we consider the decentralized, stochastic nonconvex strongly-concave (NCSC) minimax problem with nonsmooth regularization terms on both primal and dual variables, wherein a network of $m$ computing agents collaborate via peer-to-peer communications. We consider when the coupling function is in expectation or finite-sum form and the double regularizers are convex functions, applied separately to the primal and dual variables. Our algorithmic framework introduces a Lagrangian multiplier to eliminate the consensus constraint on the dual variable. Coupling this with variance-reduction (VR) techniques, our proposed method, entitled VRLM, by a single neighbor communication per iteration, is able to achieve an $\\mathcal{O}(\\kappa^3\\varepsilon^{-3})$ sample complexity under the general stochastic setting, with either a big-batch or small-batch VR option, where $\\kappa$ is the condition number of the problem and $\\varepsilon$ is the desired solution accuracy. With a big-batch VR,",
    "path": "papers/23/07/2307.07113.json",
    "total_tokens": 996,
    "translated_title": "分散随机双正则化非凸强凸极小极大问题的方差减少加速方法",
    "translated_abstract": "本文考虑在原始变量和对偶变量上具有非光滑正则化项的分散、随机、非凸强凸（NCSC）极小极大问题，在该问题中，m个计算代理通过点对点通信进行协作。我们考虑了耦合函数为期望或有限和形式的情况，并且双正则化函数分别应用于原始变量和对偶变量。我们的算法框架引入了一个拉格朗日乘子来消除对偶变量上的共识约束。将此与方差减少（VR）技术相结合，我们提出的方法，称为VRLM，通过每次迭代进行一次邻居通信，能够在一般的随机设置下实现$\\mathcal{O}(\\kappa^3\\varepsilon^{-3})$ 的样本复杂度，其中$\\kappa$是问题的条件数，$\\varepsilon$是希望的解精度。通过使用大批量VR，",
    "tldr": "本文提出了一种应用于分散随机双正则化非凸强凸极小极大问题的方差减少加速方法，通过引入拉格朗日乘子和采用单个邻居通信并结合方差减少技术，该方法在随机设置下样本复杂度达到$\\mathcal{O}(\\kappa^3\\varepsilon^{-3})$。",
    "en_tdlr": "This paper proposes a variance-reduced accelerated method for decentralized stochastic double-regularized nonconvex strongly-concave minimax problems. The proposed method introduces a Lagrangian multiplier and utilizes single neighbor communication along with variance-reduction techniques, achieving a sample complexity of $\\mathcal{O}(\\kappa^3\\varepsilon^{-3})$ under the general stochastic setting."
}