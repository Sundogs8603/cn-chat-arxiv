{
    "title": "AdvDiff: Generating Unrestricted Adversarial Examples using Diffusion Models. (arXiv:2307.12499v2 [cs.LG] UPDATED)",
    "abstract": "Unrestricted adversarial attacks present a serious threat to deep learning models and adversarial defense techniques. They pose severe security problems for deep learning applications because they can effectively bypass defense mechanisms. However, previous attack methods often utilize Generative Adversarial Networks (GANs), which are not theoretically provable and thus generate unrealistic examples by incorporating adversarial objectives, especially for large-scale datasets like ImageNet. In this paper, we propose a new method, called AdvDiff, to generate unrestricted adversarial examples with diffusion models. We design two novel adversarial guidance techniques to conduct adversarial sampling in the reverse generation process of diffusion models. These two techniques are effective and stable to generate high-quality, realistic adversarial examples by integrating gradients of the target classifier interpretably. Experimental results on MNIST and ImageNet datasets demonstrate that AdvD",
    "link": "http://arxiv.org/abs/2307.12499",
    "context": "Title: AdvDiff: Generating Unrestricted Adversarial Examples using Diffusion Models. (arXiv:2307.12499v2 [cs.LG] UPDATED)\nAbstract: Unrestricted adversarial attacks present a serious threat to deep learning models and adversarial defense techniques. They pose severe security problems for deep learning applications because they can effectively bypass defense mechanisms. However, previous attack methods often utilize Generative Adversarial Networks (GANs), which are not theoretically provable and thus generate unrealistic examples by incorporating adversarial objectives, especially for large-scale datasets like ImageNet. In this paper, we propose a new method, called AdvDiff, to generate unrestricted adversarial examples with diffusion models. We design two novel adversarial guidance techniques to conduct adversarial sampling in the reverse generation process of diffusion models. These two techniques are effective and stable to generate high-quality, realistic adversarial examples by integrating gradients of the target classifier interpretably. Experimental results on MNIST and ImageNet datasets demonstrate that AdvD",
    "path": "papers/23/07/2307.12499.json",
    "total_tokens": 890,
    "translated_title": "AdvDiff:使用扩散模型生成无限制的对抗样本",
    "translated_abstract": "无限制的对抗攻击对深度学习模型和对抗防御技术构成严重威胁。它们对深度学习应用造成严重的安全问题，因为它们可以有效地绕过防御机制。然而，先前的攻击方法通常利用生成对抗网络（GAN），这些网络在理论上无法证明，因此在大规模数据集（如ImageNet）上通过引入对抗目标生成的例子是不现实的。在本文中，我们提出了一种新的方法，称为AdvDiff，使用扩散模型生成无限制的对抗样本。我们设计了两种新的对抗引导技术，在扩散模型的逆生成过程中进行对抗采样。这两种技术通过可解释的目标分类器梯度集成生成高质量、逼真的对抗样本非常有效和稳定。在MNIST和ImageNet数据集上的实验结果表明，AdvDiff能够生成高质量、逼真的对抗样本。",
    "tldr": "本文提出了一种使用扩散模型生成无限制对抗样本的方法AdvDiff。通过设计两种新的对抗引导技术，在扩散模型的逆生成过程中进行对抗采样，从而有效地生成高质量、逼真的对抗样本。",
    "en_tdlr": "This paper proposes a method called AdvDiff to generate unrestricted adversarial examples using diffusion models. By designing two novel adversarial guidance techniques, adversarial sampling is conducted in the reverse generation process of diffusion models, effectively generating high-quality, realistic adversarial examples."
}