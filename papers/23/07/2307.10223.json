{
    "title": "Bound by the Bounty: Collaboratively Shaping Evaluation Processes for Queer AI Harms. (arXiv:2307.10223v1 [cs.CY])",
    "abstract": "Bias evaluation benchmarks and dataset and model documentation have emerged as central processes for assessing the biases and harms of artificial intelligence (AI) systems. However, these auditing processes have been criticized for their failure to integrate the knowledge of marginalized communities and consider the power dynamics between auditors and the communities. Consequently, modes of bias evaluation have been proposed that engage impacted communities in identifying and assessing the harms of AI systems (e.g., bias bounties). Even so, asking what marginalized communities want from such auditing processes has been neglected. In this paper, we ask queer communities for their positions on, and desires from, auditing processes. To this end, we organized a participatory workshop to critique and redesign bias bounties from queer perspectives. We found that when given space, the scope of feedback from workshop participants goes far beyond what bias bounties afford, with participants que",
    "link": "http://arxiv.org/abs/2307.10223",
    "context": "Title: Bound by the Bounty: Collaboratively Shaping Evaluation Processes for Queer AI Harms. (arXiv:2307.10223v1 [cs.CY])\nAbstract: Bias evaluation benchmarks and dataset and model documentation have emerged as central processes for assessing the biases and harms of artificial intelligence (AI) systems. However, these auditing processes have been criticized for their failure to integrate the knowledge of marginalized communities and consider the power dynamics between auditors and the communities. Consequently, modes of bias evaluation have been proposed that engage impacted communities in identifying and assessing the harms of AI systems (e.g., bias bounties). Even so, asking what marginalized communities want from such auditing processes has been neglected. In this paper, we ask queer communities for their positions on, and desires from, auditing processes. To this end, we organized a participatory workshop to critique and redesign bias bounties from queer perspectives. We found that when given space, the scope of feedback from workshop participants goes far beyond what bias bounties afford, with participants que",
    "path": "papers/23/07/2307.10223.json",
    "total_tokens": 890,
    "translated_title": "受奖赏约束：共同构建评估酷儿人工智能伤害的过程",
    "translated_abstract": "偏见评估基准、数据集和模型文档已成为评估人工智能系统偏见和伤害的核心过程。然而，这些审计过程因未整合边缘化社区的知识并考虑审计员与社区之间的权力动态而受到批评。因此，已经提出了一种参与受影响社区识别和评估人工智能系统伤害的偏见评估方式（例如偏见奖金）。尽管如此，关于边缘化社区对此类审计过程的期望一直被忽视。在本文中，我们向酷儿社区征求他们对审计过程的立场和期望。为此，我们组织了一个参与式研讨会，从酷儿的角度对偏见奖金进行批判性的重新设计。我们发现，当有空间时，参与者的反馈范围远远超出了偏见奖金所能提供的范围，参与者 que",
    "tldr": "这项研究探索了如何在评估人工智能偏见和伤害时整合边缘化社区的知识，并提出了以酷儿社区为视角重新设计偏见奖金的方法。"
}