{
    "title": "Implicit Identity Representation Conditioned Memory Compensation Network for Talking Head video Generation. (arXiv:2307.09906v1 [cs.CV])",
    "abstract": "Talking head video generation aims to animate a human face in a still image with dynamic poses and expressions using motion information derived from a target-driving video, while maintaining the person's identity in the source image. However, dramatic and complex motions in the driving video cause ambiguous generation, because the still source image cannot provide sufficient appearance information for occluded regions or delicate expression variations, which produces severe artifacts and significantly degrades the generation quality. To tackle this problem, we propose to learn a global facial representation space, and design a novel implicit identity representation conditioned memory compensation network, coined as MCNet, for high-fidelity talking head generation.~Specifically, we devise a network module to learn a unified spatial facial meta-memory bank from all training samples, which can provide rich facial structure and appearance priors to compensate warped source facial features ",
    "link": "http://arxiv.org/abs/2307.09906",
    "context": "Title: Implicit Identity Representation Conditioned Memory Compensation Network for Talking Head video Generation. (arXiv:2307.09906v1 [cs.CV])\nAbstract: Talking head video generation aims to animate a human face in a still image with dynamic poses and expressions using motion information derived from a target-driving video, while maintaining the person's identity in the source image. However, dramatic and complex motions in the driving video cause ambiguous generation, because the still source image cannot provide sufficient appearance information for occluded regions or delicate expression variations, which produces severe artifacts and significantly degrades the generation quality. To tackle this problem, we propose to learn a global facial representation space, and design a novel implicit identity representation conditioned memory compensation network, coined as MCNet, for high-fidelity talking head generation.~Specifically, we devise a network module to learn a unified spatial facial meta-memory bank from all training samples, which can provide rich facial structure and appearance priors to compensate warped source facial features ",
    "path": "papers/23/07/2307.09906.json",
    "total_tokens": 736,
    "translated_title": "隐式身份表示条件化记忆补偿网络用于生成自然头部视频",
    "translated_abstract": "头部视频生成旨在通过从目标驱动视频中提取的动态姿势和表情来给静态图像中的人脸添加动画效果，同时保持源图像中的个人身份。然而，驱动视频中戏剧性和复杂的运动会导致生成模糊不清，因为静态源图像无法提供足够的外观信息来处理被遮挡区域或微妙的表情变化，这会产生严重的伪影并严重降低生成质量。为了解决这个问题，我们提出了学习全局人脸表示空间的方法，并设计了一种新颖的隐式身份表示条件化记忆补偿网络，称为MCNet，用于高保真度的头部视频生成。",
    "tldr": "提出了一种隐式身份表示条件化记忆补偿网络，用于高保真度的自然头部视频生成。",
    "en_tdlr": "Proposed an implicit identity representation conditioned memory compensation network for high-fidelity talking head video generation."
}