{
    "title": "MaxCorrMGNN: A Multi-Graph Neural Network Framework for Generalized Multimodal Fusion of Medical Data for Outcome Prediction. (arXiv:2307.07093v1 [cs.LG])",
    "abstract": "With the emergence of multimodal electronic health records, the evidence for an outcome may be captured across multiple modalities ranging from clinical to imaging and genomic data. Predicting outcomes effectively requires fusion frameworks capable of modeling fine-grained and multi-faceted complex interactions between modality features within and across patients. We develop an innovative fusion approach called MaxCorr MGNN that models non-linear modality correlations within and across patients through Hirschfeld-Gebelein-Renyi maximal correlation (MaxCorr) embeddings, resulting in a multi-layered graph that preserves the identities of the modalities and patients. We then design, for the first time, a generalized multi-layered graph neural network (MGNN) for task-informed reasoning in multi-layered graphs, that learns the parameters defining patient-modality graph connectivity and message passing in an end-to-end fashion. We evaluate our model an outcome prediction task on a Tuberculos",
    "link": "http://arxiv.org/abs/2307.07093",
    "context": "Title: MaxCorrMGNN: A Multi-Graph Neural Network Framework for Generalized Multimodal Fusion of Medical Data for Outcome Prediction. (arXiv:2307.07093v1 [cs.LG])\nAbstract: With the emergence of multimodal electronic health records, the evidence for an outcome may be captured across multiple modalities ranging from clinical to imaging and genomic data. Predicting outcomes effectively requires fusion frameworks capable of modeling fine-grained and multi-faceted complex interactions between modality features within and across patients. We develop an innovative fusion approach called MaxCorr MGNN that models non-linear modality correlations within and across patients through Hirschfeld-Gebelein-Renyi maximal correlation (MaxCorr) embeddings, resulting in a multi-layered graph that preserves the identities of the modalities and patients. We then design, for the first time, a generalized multi-layered graph neural network (MGNN) for task-informed reasoning in multi-layered graphs, that learns the parameters defining patient-modality graph connectivity and message passing in an end-to-end fashion. We evaluate our model an outcome prediction task on a Tuberculos",
    "path": "papers/23/07/2307.07093.json",
    "total_tokens": 922,
    "translated_title": "MaxCorrMGNN: 一种用于广义多模态医疗数据融合的多图神经网络框架，用于预测结果",
    "translated_abstract": "随着多模态电子健康记录的出现，结果的证据可能涵盖从临床到影像和基因组数据的多个模态。有效预测结果需要能够对患者内部和患者之间的模态特征进行细粒度和多方面的复杂交互建模的融合框架。我们开发了一种创新的融合方法，称为MaxCorr MGNN，通过Hirschfeld-Gebelein-Renyi最大相关性(MaxCorr)嵌入模型非线性模态相关性，在患者内部和患者之间建立一个保存模态和患者身份的多层图。然后，我们首次设计了一种用于任务感知推理的广义多层图神经网络(MGNN)，以端到端方式学习定义患者 - 模态图连接性和信息传递的参数。我们在肺结核结果预测任务上评估了我们的模型。",
    "tldr": "MaxCorrMGNN是一种用于广义多模态医疗数据融合的创新神经网络框架，通过MaxCorr embeddings建模患者内部和患者之间的非线性模态相关性，并通过多层图网络在任务中进行推理，有效预测结果。",
    "en_tdlr": "MaxCorrMGNN is an innovative neural network framework for generalized multimodal fusion of medical data, which models non-linear modality correlations within and across patients using MaxCorr embeddings, and performs task-informed reasoning through multi-layered graph neural networks to effectively predict outcomes."
}