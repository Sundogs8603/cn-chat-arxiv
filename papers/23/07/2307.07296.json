{
    "title": "Reinforcement Learning with Frontier-Based Exploration via Autonomous Environment. (arXiv:2307.07296v1 [cs.RO])",
    "abstract": "Active Simultaneous Localisation and Mapping (SLAM) is a critical problem in autonomous robotics, enabling robots to navigate to new regions while building an accurate model of their surroundings. Visual SLAM is a popular technique that uses virtual elements to enhance the experience. However, existing frontier-based exploration strategies can lead to a non-optimal path in scenarios where there are multiple frontiers with similar distance. This issue can impact the efficiency and accuracy of Visual SLAM, which is crucial for a wide range of robotic applications, such as search and rescue, exploration, and mapping. To address this issue, this research combines both an existing Visual-Graph SLAM known as ExploreORB with reinforcement learning. The proposed algorithm allows the robot to learn and optimize exploration routes through a reward-based system to create an accurate map of the environment with proper frontier selection. Frontier-based exploration is used to detect unexplored area",
    "link": "http://arxiv.org/abs/2307.07296",
    "context": "Title: Reinforcement Learning with Frontier-Based Exploration via Autonomous Environment. (arXiv:2307.07296v1 [cs.RO])\nAbstract: Active Simultaneous Localisation and Mapping (SLAM) is a critical problem in autonomous robotics, enabling robots to navigate to new regions while building an accurate model of their surroundings. Visual SLAM is a popular technique that uses virtual elements to enhance the experience. However, existing frontier-based exploration strategies can lead to a non-optimal path in scenarios where there are multiple frontiers with similar distance. This issue can impact the efficiency and accuracy of Visual SLAM, which is crucial for a wide range of robotic applications, such as search and rescue, exploration, and mapping. To address this issue, this research combines both an existing Visual-Graph SLAM known as ExploreORB with reinforcement learning. The proposed algorithm allows the robot to learn and optimize exploration routes through a reward-based system to create an accurate map of the environment with proper frontier selection. Frontier-based exploration is used to detect unexplored area",
    "path": "papers/23/07/2307.07296.json",
    "total_tokens": 945,
    "translated_title": "自主环境中基于前沿探索的强化学习",
    "translated_abstract": "主动同时定位及建图（SLAM）是自主机器人中的一个重要问题，使机器人能够在建立准确的环境模型的同时导航到新的区域。视觉SLAM是一种流行的技术，利用虚拟元素来增强体验。然而，现有的基于前沿探索策略在存在多个距离相似的前沿的场景中可能导致非最优的路径。这个问题可能会影响到视觉SLAM的效率和准确性，而这对于一系列机器人应用非常关键，如搜救、探索和建图。为了解决这个问题，本研究将已有的ExploreORB视觉图SLAM与强化学习相结合。所提出的算法允许机器人通过基于奖励的系统学习和优化探索路线，以正确选择前沿，并创建一个精确的环境地图。基于前沿探索被用来检测未探索区域。",
    "tldr": "通过将已有的Visual-Graph SLAM算法ExploreORB与强化学习相结合，该研究提出了一种自主环境中基于前沿探索的强化学习算法。该算法通过基于奖励的系统学习和优化探索路线，解决了在存在多个距离相似的前沿的场景中可能导致非最优路径的问题。英文总结: This paper proposes a reinforcement learning algorithm with frontier-based exploration in autonomous environments by combining an existing Visual-Graph SLAM algorithm, ExploreORB. The algorithm allows the robot to learn and optimize exploration routes through a reward-based system to select frontiers accurately, addressing the issue of non-optimal paths in scenarios with similar-distance frontiers."
}