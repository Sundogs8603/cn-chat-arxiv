{
    "title": "Explaining Autonomous Driving Actions with Visual Question Answering. (arXiv:2307.10408v1 [cs.CV])",
    "abstract": "The end-to-end learning ability of self-driving vehicles has achieved significant milestones over the last decade owing to rapid advances in deep learning and computer vision algorithms. However, as autonomous driving technology is a safety-critical application of artificial intelligence (AI), road accidents and established regulatory principles necessitate the need for the explainability of intelligent action choices for self-driving vehicles. To facilitate interpretability of decision-making in autonomous driving, we present a Visual Question Answering (VQA) framework, which explains driving actions with question-answering-based causal reasoning. To do so, we first collect driving videos in a simulation environment using reinforcement learning (RL) and extract consecutive frames from this log data uniformly for five selected action categories. Further, we manually annotate the extracted frames using question-answer pairs as justifications for the actions chosen in each scenario. Fina",
    "link": "http://arxiv.org/abs/2307.10408",
    "context": "Title: Explaining Autonomous Driving Actions with Visual Question Answering. (arXiv:2307.10408v1 [cs.CV])\nAbstract: The end-to-end learning ability of self-driving vehicles has achieved significant milestones over the last decade owing to rapid advances in deep learning and computer vision algorithms. However, as autonomous driving technology is a safety-critical application of artificial intelligence (AI), road accidents and established regulatory principles necessitate the need for the explainability of intelligent action choices for self-driving vehicles. To facilitate interpretability of decision-making in autonomous driving, we present a Visual Question Answering (VQA) framework, which explains driving actions with question-answering-based causal reasoning. To do so, we first collect driving videos in a simulation environment using reinforcement learning (RL) and extract consecutive frames from this log data uniformly for five selected action categories. Further, we manually annotate the extracted frames using question-answer pairs as justifications for the actions chosen in each scenario. Fina",
    "path": "papers/23/07/2307.10408.json",
    "total_tokens": 855,
    "translated_title": "使用视觉问答解释自主驾驶行为",
    "translated_abstract": "由于深度学习和计算机视觉算法的快速进步，自动驾驶车辆的端到端学习能力在过去十年中取得了重大突破。然而，作为人工智能的安全关键应用，道路事故和既定的监管原则要求对自动驾驶车辆的智能行为选择进行解释。为了促进自主驾驶决策的可解释性，我们提出了一个基于视觉问答的框架，通过问答式因果推理来解释驾驶行为。为此，我们首先使用强化学习在模拟环境中收集驾驶视频，并从这个日志数据中均匀提取五个选定行为类别的连续帧。然后，我们使用问题-答案对对提取的帧进行手动标注，作为每种情景中选择的行为的理由。",
    "tldr": "本文提出了一种使用视觉问答解释自主驾驶行为的框架，通过问答式因果推理来实现驾驶行为的解释。研究使用强化学习收集驾驶视频并手动标注，从而实现自主驾驶决策的可解释性。",
    "en_tdlr": "This paper presents a framework that explains autonomous driving actions using visual question answering and causal reasoning. The researchers collected driving videos using reinforcement learning and annotated the frames with question-answer pairs to achieve explainability in autonomous driving decision-making."
}