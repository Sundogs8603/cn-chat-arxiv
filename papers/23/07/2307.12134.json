{
    "title": "Modality Confidence Aware Training for Robust End-to-End Spoken Language Understanding. (arXiv:2307.12134v1 [cs.CL])",
    "abstract": "End-to-end (E2E) spoken language understanding (SLU) systems that generate a semantic parse from speech have become more promising recently. This approach uses a single model that utilizes audio and text representations from pre-trained speech recognition models (ASR), and outperforms traditional pipeline SLU systems in on-device streaming scenarios. However, E2E SLU systems still show weakness when text representation quality is low due to ASR transcription errors. To overcome this issue, we propose a novel E2E SLU system that enhances robustness to ASR errors by fusing audio and text representations based on the estimated modality confidence of ASR hypotheses. We introduce two novel techniques: 1) an effective method to encode the quality of ASR hypotheses and 2) an effective approach to integrate them into E2E SLU models. We show accuracy improvements on STOP dataset and share the analysis to demonstrate the effectiveness of our approach.",
    "link": "http://arxiv.org/abs/2307.12134",
    "context": "Title: Modality Confidence Aware Training for Robust End-to-End Spoken Language Understanding. (arXiv:2307.12134v1 [cs.CL])\nAbstract: End-to-end (E2E) spoken language understanding (SLU) systems that generate a semantic parse from speech have become more promising recently. This approach uses a single model that utilizes audio and text representations from pre-trained speech recognition models (ASR), and outperforms traditional pipeline SLU systems in on-device streaming scenarios. However, E2E SLU systems still show weakness when text representation quality is low due to ASR transcription errors. To overcome this issue, we propose a novel E2E SLU system that enhances robustness to ASR errors by fusing audio and text representations based on the estimated modality confidence of ASR hypotheses. We introduce two novel techniques: 1) an effective method to encode the quality of ASR hypotheses and 2) an effective approach to integrate them into E2E SLU models. We show accuracy improvements on STOP dataset and share the analysis to demonstrate the effectiveness of our approach.",
    "path": "papers/23/07/2307.12134.json",
    "total_tokens": 918,
    "translated_title": "鲁棒的端到端语音理解中的模态置信度训练",
    "translated_abstract": "最近，从语音生成语义解析的端到端语音理解（SLU）系统变得更加有希望。这种方法使用一个单一模型，利用预训练语音识别模型（ASR）的音频和文本表示，相比传统的流媒体场景下的流水线SLU系统效果更好。然而，端到端SLU系统仍然在ASR转写错误导致文本表示质量低时显示出弱点。为了解决这个问题，我们提出了一种新颖的端到端SLU系统，通过融合基于估计的ASR假设的模态置信度来增强对ASR错误的容错性。我们引入了两种新颖的技术：1）一种有效的方法来编码ASR假设的质量，2）一种有效的方法将它们整合到端到端SLU模型中。我们展示了在STOP数据集上的准确度改进，并分享分析结果以证明我们的方法的有效性。",
    "tldr": "该论文提出了一种鲁棒的端到端语音理解（SLU）系统，通过融合基于ASR假设的模态置信度来增强对ASR错误的容错性。他们的方法通过有效的编码ASR假设质量，成功将其整合到E2E SLU模型中，提高了准确性。",
    "en_tdlr": "This paper proposes a robust end-to-end spoken language understanding (SLU) system that enhances tolerance to ASR errors by fusing modality confidence based on ASR hypotheses. Their method successfully integrates the effective encoding of ASR hypothesis quality into E2E SLU models, resulting in improved accuracy."
}