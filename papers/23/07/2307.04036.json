{
    "title": "Designing a Direct Feedback Loop between Humans and Convolutional Neural Networks through Local Explanations. (arXiv:2307.04036v1 [cs.HC])",
    "abstract": "The local explanation provides heatmaps on images to explain how Convolutional Neural Networks (CNNs) derive their output. Due to its visual straightforwardness, the method has been one of the most popular explainable AI (XAI) methods for diagnosing CNNs. Through our formative study (S1), however, we captured ML engineers' ambivalent perspective about the local explanation as a valuable and indispensable envision in building CNNs versus the process that exhausts them due to the heuristic nature of detecting vulnerability. Moreover, steering the CNNs based on the vulnerability learned from the diagnosis seemed highly challenging. To mitigate the gap, we designed DeepFuse, the first interactive design that realizes the direct feedback loop between a user and CNNs in diagnosing and revising CNN's vulnerability using local explanations. DeepFuse helps CNN engineers to systemically search \"unreasonable\" local explanations and annotate the new boundaries for those identified as unreasonable ",
    "link": "http://arxiv.org/abs/2307.04036",
    "context": "Title: Designing a Direct Feedback Loop between Humans and Convolutional Neural Networks through Local Explanations. (arXiv:2307.04036v1 [cs.HC])\nAbstract: The local explanation provides heatmaps on images to explain how Convolutional Neural Networks (CNNs) derive their output. Due to its visual straightforwardness, the method has been one of the most popular explainable AI (XAI) methods for diagnosing CNNs. Through our formative study (S1), however, we captured ML engineers' ambivalent perspective about the local explanation as a valuable and indispensable envision in building CNNs versus the process that exhausts them due to the heuristic nature of detecting vulnerability. Moreover, steering the CNNs based on the vulnerability learned from the diagnosis seemed highly challenging. To mitigate the gap, we designed DeepFuse, the first interactive design that realizes the direct feedback loop between a user and CNNs in diagnosing and revising CNN's vulnerability using local explanations. DeepFuse helps CNN engineers to systemically search \"unreasonable\" local explanations and annotate the new boundaries for those identified as unreasonable ",
    "path": "papers/23/07/2307.04036.json",
    "total_tokens": 892,
    "translated_title": "设计一个人类和卷积神经网络之间的直接反馈循环通过局部解释",
    "translated_abstract": "局部解释通过图像热图解释卷积神经网络（CNN）是如何得出他们的输出结果的。由于其直观明了的特点，该方法已成为诊断CNN的最受欢迎的可解释AI（XAI）方法之一。然而，通过我们的初步研究，我们捕捉到ML工程师对局部解释的价值和不可或缺的看法存在矛盾：一方面认为局部解释是构建CNN不可或缺的愿景，另一方面却又认为它是一个消耗能量的过程，因为它基于启发式的方法来检测脆弱性。此外，基于诊断所学到的脆弱性指导CNN的过程也非常具有挑战性。为了缓解这个差距，我们设计了DeepFuse，这是第一个能够实现用户和CNN之间直接反馈循环的交互设计，用于诊断和修改CNN的脆弱性，并使用局部解释帮助CNN工程师系统地搜索“不合理”的局部解释，并为那些被识别为不合理的解释标注新的边界。",
    "tldr": "这篇论文设计了DeepFuse，它是第一个实现用户和CNN之间直接反馈循环的交互设计，通过局部解释帮助CNN工程师系统地诊断和修改CNN的脆弱性。"
}