{
    "title": "Controllable Generation of Dialogue Acts for Dialogue Systems via Few-Shot Response Generation and Ranking. (arXiv:2307.14440v1 [cs.CL])",
    "abstract": "Dialogue systems need to produce responses that realize multiple types of dialogue acts (DAs) with high semantic fidelity. In the past, natural language generators (NLGs) for dialogue were trained on large parallel corpora that map from a domain-specific DA and its semantic attributes to an output utterance. Recent work shows that pretrained language models (LLMs) offer new possibilities for controllable NLG using prompt-based learning. Here we develop a novel few-shot overgenerate-and-rank approach that achieves the controlled generation of DAs. We compare eight few-shot prompt styles that include a novel method of generating from textual pseudo-references using a textual style transfer approach. We develop six automatic ranking functions that identify outputs with both the correct DA and high semantic accuracy at generation time. We test our approach on three domains and four LLMs. To our knowledge, this is the first work on NLG for dialogue that automatically ranks outputs using bot",
    "link": "http://arxiv.org/abs/2307.14440",
    "context": "Title: Controllable Generation of Dialogue Acts for Dialogue Systems via Few-Shot Response Generation and Ranking. (arXiv:2307.14440v1 [cs.CL])\nAbstract: Dialogue systems need to produce responses that realize multiple types of dialogue acts (DAs) with high semantic fidelity. In the past, natural language generators (NLGs) for dialogue were trained on large parallel corpora that map from a domain-specific DA and its semantic attributes to an output utterance. Recent work shows that pretrained language models (LLMs) offer new possibilities for controllable NLG using prompt-based learning. Here we develop a novel few-shot overgenerate-and-rank approach that achieves the controlled generation of DAs. We compare eight few-shot prompt styles that include a novel method of generating from textual pseudo-references using a textual style transfer approach. We develop six automatic ranking functions that identify outputs with both the correct DA and high semantic accuracy at generation time. We test our approach on three domains and four LLMs. To our knowledge, this is the first work on NLG for dialogue that automatically ranks outputs using bot",
    "path": "papers/23/07/2307.14440.json",
    "total_tokens": 904,
    "translated_title": "通过少样本响应生成和排序实现对话系统中对话行为的可控生成",
    "translated_abstract": "对话系统需要产生具有高语义保真度的多种对话行为（DA）的响应。过去，对话的自然语言生成器（NLG）是在大型平行语料库上进行训练的，该语料库将特定领域的DA及其语义属性映射到输出话语。最近的研究表明，预训练语言模型（LLMs）通过基于提示的学习提供了可控制的NLG的新可能性。在这里，我们开发了一种新颖的少样本过生成和排序方法，实现了DA的可控生成。我们比较了八种少样本提示样式，其中包括使用文本风格转换方法从文本伪参考生成的新方法。我们开发了六种自动排名函数，可以在生成时识别出既具有正确DA又具有较高语义准确性的输出。我们在三个领域和四个LLMs上测试了我们的方法。据我们所知，这是第一个通过机器自动排名输出的对话系统NLG的工作。",
    "tldr": "这项研究开发了一种少样本过生成和排序方法，实现了对话系统中对话行为的可控生成。通过使用预训练语言模型和自动排名函数，可以产生具有高语义准确性的多种对话行为的响应。"
}