{
    "title": "Invalid Logic, Equivalent Gains: The Bizarreness of Reasoning in Language Model Prompting. (arXiv:2307.10573v1 [cs.AI])",
    "abstract": "Language models can be prompted to reason through problems in a manner that significantly improves performance. However, \\textit{why} such prompting improves performance is unclear. Recent work showed that using logically \\textit{invalid} Chain-of-Thought (CoT) prompting improves performance almost as much as logically \\textit{valid} CoT prompting, and that editing CoT prompts to replace problem-specific information with abstract information or out-of-distribution information typically doesn't harm performance. Critics have responded that these findings are based on too few and too easy tasks to draw meaningful conclusions. To resolve this dispute, we test whether logically invalid CoT prompts offer the same level of performance gains as logically valid prompts on the hardest tasks in the BIG-Bench benchmark, termed BIG-Bench Hard (BBH). We find that the logically \\textit{invalid} reasoning prompts do indeed achieve similar performance gains on BBH tasks as logically valid reasoning pr",
    "link": "http://arxiv.org/abs/2307.10573",
    "context": "Title: Invalid Logic, Equivalent Gains: The Bizarreness of Reasoning in Language Model Prompting. (arXiv:2307.10573v1 [cs.AI])\nAbstract: Language models can be prompted to reason through problems in a manner that significantly improves performance. However, \\textit{why} such prompting improves performance is unclear. Recent work showed that using logically \\textit{invalid} Chain-of-Thought (CoT) prompting improves performance almost as much as logically \\textit{valid} CoT prompting, and that editing CoT prompts to replace problem-specific information with abstract information or out-of-distribution information typically doesn't harm performance. Critics have responded that these findings are based on too few and too easy tasks to draw meaningful conclusions. To resolve this dispute, we test whether logically invalid CoT prompts offer the same level of performance gains as logically valid prompts on the hardest tasks in the BIG-Bench benchmark, termed BIG-Bench Hard (BBH). We find that the logically \\textit{invalid} reasoning prompts do indeed achieve similar performance gains on BBH tasks as logically valid reasoning pr",
    "path": "papers/23/07/2307.10573.json",
    "total_tokens": 883,
    "translated_title": "无效逻辑，等效收益：语言模型提示中的奇怪推理",
    "translated_abstract": "语言模型可以被提示以一种显著提高性能的方式进行推理问题。然而，为什么这样的提示会提高性能还不清楚。最近的研究表明，使用逻辑上无效的CoT提示几乎可以像逻辑上有效的CoT提示一样显著提高性能，并且将CoT提示中的特定问题信息替换为抽象信息或超出分布的信息通常不会损害性能。批评人士回应说，这些发现是基于太少、太简单的任务来得出有意义的结论。为了解决这个争议，我们测试了在BIG-Bench基准测试中最困难的任务上，逻辑上无效的CoT提示是否提供与逻辑上有效的提示相同水平的性能提升，这些任务被称为BIG-Bench Hard（BBH）。我们发现，在BBH任务上，逻辑上无效的推理提示确实实现了类似的性能提升。",
    "tldr": "最近的研究发现，在语言模型的提示中使用逻辑上无效的Chain-of-Thought（CoT）提示几乎可以提供与逻辑上有效的提示相似的性能增益，而且在最困难的任务上也是如此。",
    "en_tdlr": "Recent research has shown that using logically invalid Chain-of-Thought (CoT) prompts in language models can provide similar performance gains as logically valid prompts, even on the hardest tasks."
}