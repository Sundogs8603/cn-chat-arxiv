{
    "title": "Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI). (arXiv:2307.14239v1 [cs.AI])",
    "abstract": "Within the field of Requirements Engineering (RE), the increasing significance of Explainable Artificial Intelligence (XAI) in aligning AI-supported systems with user needs, societal expectations, and regulatory standards has garnered recognition. In general, explainability has emerged as an important non-functional requirement that impacts system quality. However, the supposed trade-off between explainability and performance challenges the presumed positive influence of explainability. If meeting the requirement of explainability entails a reduction in system performance, then careful consideration must be given to which of these quality aspects takes precedence and how to compromise between them. In this paper, we critically examine the alleged trade-off. We argue that it is best approached in a nuanced way that incorporates resource availability, domain characteristics, and considerations of risk. By providing a foundation for future research and best practices, this work aims to ad",
    "link": "http://arxiv.org/abs/2307.14239",
    "context": "Title: Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI). (arXiv:2307.14239v1 [cs.AI])\nAbstract: Within the field of Requirements Engineering (RE), the increasing significance of Explainable Artificial Intelligence (XAI) in aligning AI-supported systems with user needs, societal expectations, and regulatory standards has garnered recognition. In general, explainability has emerged as an important non-functional requirement that impacts system quality. However, the supposed trade-off between explainability and performance challenges the presumed positive influence of explainability. If meeting the requirement of explainability entails a reduction in system performance, then careful consideration must be given to which of these quality aspects takes precedence and how to compromise between them. In this paper, we critically examine the alleged trade-off. We argue that it is best approached in a nuanced way that incorporates resource availability, domain characteristics, and considerations of risk. By providing a foundation for future research and best practices, this work aims to ad",
    "path": "papers/23/07/2307.14239.json",
    "total_tokens": 919,
    "translated_title": "重访可解释人工智能中的性能-可解释性权衡问题",
    "translated_abstract": "在需求工程领域中，可解释人工智能（XAI）在将AI支持的系统与用户需求、社会期望和法规标准对齐方面的重要性逐渐得到认识。一般来说，可解释性已经成为一个重要的非功能需求，影响着系统的质量。然而，可解释性和性能之间的权衡挑战了可解释性的预期积极影响。如果满足可解释性的要求意味着系统性能的降低，那么必须仔细考虑哪个质量方面更为重要，以及如何在它们之间取得妥协。在本文中，我们对这种所谓的权衡进行了批判性的考察。我们认为最好以一种细致入微的方式来处理这个问题，包括资源可用性、领域特征以及风险的考虑。通过为未来研究和最佳实践提供基础，本研究旨在提供一个解决该问题的指导。",
    "tldr": "本文重新审视了在可解释人工智能中性能和可解释性之间的权衡问题，并提出了资源可用性、领域特征和风险考虑的细致方法。为未来研究和最佳实践提供基础。"
}