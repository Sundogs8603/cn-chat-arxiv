{
    "title": "Structure Guided Multi-modal Pre-trained Transformer for Knowledge Graph Reasoning. (arXiv:2307.03591v1 [cs.AI])",
    "abstract": "Multimodal knowledge graphs (MKGs), which intuitively organize information in various modalities, can benefit multiple practical downstream tasks, such as recommendation systems, and visual question answering. However, most MKGs are still far from complete, which motivates the flourishing of MKG reasoning models. Recently, with the development of general artificial architectures, the pretrained transformer models have drawn increasing attention, especially for multimodal scenarios. However, the research of multimodal pretrained transformer (MPT) for knowledge graph reasoning (KGR) is still at an early stage. As the biggest difference between MKG and other multimodal data, the rich structural information underlying the MKG still cannot be fully leveraged in existing MPT models. Most of them only utilize the graph structure as a retrieval map for matching images and texts connected with the same entity. This manner hinders their reasoning performances. To this end, we propose the graph S",
    "link": "http://arxiv.org/abs/2307.03591",
    "context": "Title: Structure Guided Multi-modal Pre-trained Transformer for Knowledge Graph Reasoning. (arXiv:2307.03591v1 [cs.AI])\nAbstract: Multimodal knowledge graphs (MKGs), which intuitively organize information in various modalities, can benefit multiple practical downstream tasks, such as recommendation systems, and visual question answering. However, most MKGs are still far from complete, which motivates the flourishing of MKG reasoning models. Recently, with the development of general artificial architectures, the pretrained transformer models have drawn increasing attention, especially for multimodal scenarios. However, the research of multimodal pretrained transformer (MPT) for knowledge graph reasoning (KGR) is still at an early stage. As the biggest difference between MKG and other multimodal data, the rich structural information underlying the MKG still cannot be fully leveraged in existing MPT models. Most of them only utilize the graph structure as a retrieval map for matching images and texts connected with the same entity. This manner hinders their reasoning performances. To this end, we propose the graph S",
    "path": "papers/23/07/2307.03591.json",
    "total_tokens": 913,
    "translated_title": "结构引导的多模态预训练Transformer用于知识图谱推理",
    "translated_abstract": "多模态知识图谱(MKGs)直观地组织了各种模式的信息，可以惠及多个实际的下游任务，如推荐系统和视觉问答。然而，大多数MKGs仍然远离完整，这促使了MKG推理模型的兴起。最近，随着通用人工架构的发展，预训练transformer模型引起了越来越多的关注，特别是对于多模态场景。然而，多模态预训练transformer (MPT)用于知识图推理 (KGR) 的研究仍处于早期阶段。作为MKG和其他多模态数据的最大区别，MKG中丰富的结构信息仍然无法在现有的MPT模型中充分利用。大多数模型只将图结构用作匹配与同一实体相连的图像和文本的检索映射。这种方式阻碍了它们的推理性能。为此，我们提出了图结构引导的多模态预训练Transformer用于知识图谱推理的方法。",
    "tldr": "本研究提出了一种图结构引导的多模态预训练Transformer用于知识图谱推理。当前的多模态预训练Transformer模型未能充分利用知识图谱的结构信息，限制了其推理性能。",
    "en_tdlr": "This paper proposes a structure guided multi-modal pre-trained Transformer for knowledge graph reasoning. The current multi-modal pre-trained Transformer models fail to fully leverage the structural information of knowledge graphs, limiting their reasoning performance."
}