{
    "title": "Measuring the Success of Diffusion Models at Imitating Human Artists. (arXiv:2307.04028v1 [cs.CV])",
    "abstract": "Modern diffusion models have set the state-of-the-art in AI image generation. Their success is due, in part, to training on Internet-scale data which often includes copyrighted work. This prompts questions about the extent to which these models learn from, imitate, or copy the work of human artists. This work suggests that tying copyright liability to the capabilities of the model may be useful given the evolving ecosystem of generative models. Specifically, much of the legal analysis of copyright and generative systems focuses on the use of protected data for training. As a result, the connections between data, training, and the system are often obscured. In our approach, we consider simple image classification techniques to measure a model's ability to imitate specific artists. Specifically, we use Contrastive Language-Image Pretrained (CLIP) encoders to classify images in a zero-shot fashion. Our process first prompts a model to imitate a specific artist. Then, we test whether CLIP ",
    "link": "http://arxiv.org/abs/2307.04028",
    "context": "Title: Measuring the Success of Diffusion Models at Imitating Human Artists. (arXiv:2307.04028v1 [cs.CV])\nAbstract: Modern diffusion models have set the state-of-the-art in AI image generation. Their success is due, in part, to training on Internet-scale data which often includes copyrighted work. This prompts questions about the extent to which these models learn from, imitate, or copy the work of human artists. This work suggests that tying copyright liability to the capabilities of the model may be useful given the evolving ecosystem of generative models. Specifically, much of the legal analysis of copyright and generative systems focuses on the use of protected data for training. As a result, the connections between data, training, and the system are often obscured. In our approach, we consider simple image classification techniques to measure a model's ability to imitate specific artists. Specifically, we use Contrastive Language-Image Pretrained (CLIP) encoders to classify images in a zero-shot fashion. Our process first prompts a model to imitate a specific artist. Then, we test whether CLIP ",
    "path": "papers/23/07/2307.04028.json",
    "total_tokens": 919,
    "translated_title": "评估扩散模型在模仿人类艺术家方面的成功程度",
    "translated_abstract": "现代扩散模型在人工智能图像生成方面取得了最先进的成果。它们的成功部分是因为在训练过程中使用了互联网规模的数据，其中经常包含有版权的作品。这引发了关于这些模型在多大程度上从人类艺术家的作品中学习、模仿或复制的问题。本研究认为，将版权责任与模型的能力联系起来，可能在生成模型的不断发展的环境中是有用的。具体而言，关于版权和生成系统的法律分析往往侧重于使用受保护数据进行训练。因此，数据、训练和系统之间的联系常常被掩盖。在我们的方法中，我们考虑了简单的图像分类技术，以衡量模型模仿特定艺术家的能力。具体来说，我们使用对比语言-图像预训练(CLIP)编码器以零样本的方式对图像进行分类。我们的过程首先提示模型模仿特定的艺术家，然后测试CLIP是否能够准确分类图像。",
    "tldr": "这项研究评估了扩散模型在模仿人类艺术家方面的成功程度，并提出将版权责任与模型能力联系起来可能是有用的。研究通过使用Contrastive Language-Image Pretrained (CLIP)编码器对图像进行分类来衡量模型模仿特定艺术家的能力。"
}