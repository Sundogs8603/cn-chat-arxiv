{
    "title": "Answering Ambiguous Questions via Iterative Prompting. (arXiv:2307.03897v1 [cs.CL])",
    "abstract": "In open-domain question answering, due to the ambiguity of questions, multiple plausible answers may exist. To provide feasible answers to an ambiguous question, one approach is to directly predict all valid answers, but this can struggle with balancing relevance and diversity. An alternative is to gather candidate answers and aggregate them, but this method can be computationally costly and may neglect dependencies among answers. In this paper, we present AmbigPrompt to address the imperfections of existing approaches to answering ambiguous questions. Specifically, we integrate an answering model with a prompting model in an iterative manner. The prompting model adaptively tracks the reading process and progressively triggers the answering model to compose distinct and relevant answers. Additionally, we develop a task-specific post-pretraining approach for both the answering model and the prompting model, which greatly improves the performance of our framework. Empirical studies on tw",
    "link": "http://arxiv.org/abs/2307.03897",
    "context": "Title: Answering Ambiguous Questions via Iterative Prompting. (arXiv:2307.03897v1 [cs.CL])\nAbstract: In open-domain question answering, due to the ambiguity of questions, multiple plausible answers may exist. To provide feasible answers to an ambiguous question, one approach is to directly predict all valid answers, but this can struggle with balancing relevance and diversity. An alternative is to gather candidate answers and aggregate them, but this method can be computationally costly and may neglect dependencies among answers. In this paper, we present AmbigPrompt to address the imperfections of existing approaches to answering ambiguous questions. Specifically, we integrate an answering model with a prompting model in an iterative manner. The prompting model adaptively tracks the reading process and progressively triggers the answering model to compose distinct and relevant answers. Additionally, we develop a task-specific post-pretraining approach for both the answering model and the prompting model, which greatly improves the performance of our framework. Empirical studies on tw",
    "path": "papers/23/07/2307.03897.json",
    "total_tokens": 918,
    "translated_title": "通过迭代提示回答模糊问题",
    "translated_abstract": "在开放领域的问答中，由于问题的模糊性，可能存在多个合理的答案。为了对一个模糊的问题提供可行的答案，一种方法是直接预测所有有效的答案，但这可能难以平衡相关性和多样性。另一种方法是收集候选答案并对它们进行汇总，但这种方法在计算上代价高，并且可能忽略答案之间的依赖关系。在这篇论文中，我们提出了AmbigPrompt来解决现有方法中回答模糊问题的缺陷。具体而言，我们以迭代的方式将一个答案模型与一个提示模型集成在一起。提示模型逐步追踪阅读过程，并逐渐触发答案模型来生成独特且相关的答案。此外，我们为答案模型和提示模型开发了一种任务特定的预训练方法，大大提高了我们框架的性能。在两个数据集上进行了实证研究。",
    "tldr": "本文提出了一种通过迭代提示的方法来回答模糊问题。该方法集成了一个答案模型和一个提示模型，并通过逐步追踪阅读过程并触发答案模型来生成独特且相关的答案。通过开发任务特定的预训练方法，该方法在实验证明了其性能的提升。",
    "en_tdlr": "This paper proposes an iterative prompting method to answer ambiguous questions. The method integrates an answering model and a prompting model, and generates distinct and relevant answers by progressively tracking the reading process and triggering the answering model. The performance of the method is greatly improved by developing task-specific pretraining approaches."
}