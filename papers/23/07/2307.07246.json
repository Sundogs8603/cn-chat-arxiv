{
    "title": "Knowledge Boosting: Rethinking Medical Contrastive Vision-Language Pre-Training. (arXiv:2307.07246v1 [cs.CV])",
    "abstract": "The foundation models based on pre-training technology have significantly advanced artificial intelligence from theoretical to practical applications. These models have facilitated the feasibility of computer-aided diagnosis for widespread use. Medical contrastive vision-language pre-training, which does not require human annotations, is an effective approach for guiding representation learning using description information in diagnostic reports. However, the effectiveness of pre-training is limited by the large-scale semantic overlap and shifting problems in medical field. To address these issues, we propose the Knowledge-Boosting Contrastive Vision-Language Pre-training framework (KoBo), which integrates clinical knowledge into the learning of vision-language semantic consistency. The framework uses an unbiased, open-set sample-wise knowledge representation to measure negative sample noise and supplement the correspondence between vision-language mutual information and clinical knowl",
    "link": "http://arxiv.org/abs/2307.07246",
    "context": "Title: Knowledge Boosting: Rethinking Medical Contrastive Vision-Language Pre-Training. (arXiv:2307.07246v1 [cs.CV])\nAbstract: The foundation models based on pre-training technology have significantly advanced artificial intelligence from theoretical to practical applications. These models have facilitated the feasibility of computer-aided diagnosis for widespread use. Medical contrastive vision-language pre-training, which does not require human annotations, is an effective approach for guiding representation learning using description information in diagnostic reports. However, the effectiveness of pre-training is limited by the large-scale semantic overlap and shifting problems in medical field. To address these issues, we propose the Knowledge-Boosting Contrastive Vision-Language Pre-training framework (KoBo), which integrates clinical knowledge into the learning of vision-language semantic consistency. The framework uses an unbiased, open-set sample-wise knowledge representation to measure negative sample noise and supplement the correspondence between vision-language mutual information and clinical knowl",
    "path": "papers/23/07/2307.07246.json",
    "total_tokens": 851,
    "translated_title": "知识增强：重新思考医学对比视觉语言预训练",
    "translated_abstract": "基于预训练技术的基础模型从理论上到实践应用显著推进了人工智能的发展。这些模型推动了计算机辅助诊断的可行性，使其广泛应用。医学对比视觉语言预训练是一种有效的方法，它利用诊断报告中的描述信息来指导表征学习，无需人工注释。然而，预训练的效果受制于医学领域的大规模语义重叠和转移问题。为了解决这些问题，我们提出了知识增强对比视觉语言预训练框架（KoBo），该框架将临床知识整合到视觉语言语义一致性学习中。该框架使用无偏的、开集样本级知识表示来衡量负样本噪声，并补充视觉语言互信息与临床知识之间的对应关系。",
    "tldr": "该论文提出了一个名为KoBo的框架，它通过将临床知识整合到视觉语言语义一致性学习中，解决了医学领域中的大规模语义重叠和转移问题。",
    "en_tdlr": "This paper proposes a framework called KoBo, which addresses the issues of large-scale semantic overlap and shifting problems in the medical field by integrating clinical knowledge into vision-language semantic consistency learning."
}