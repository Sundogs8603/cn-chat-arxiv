{
    "title": "Polybot: Training One Policy Across Robots While Embracing Variability. (arXiv:2307.03719v1 [cs.RO])",
    "abstract": "Reusing large datasets is crucial to scale vision-based robotic manipulators to everyday scenarios due to the high cost of collecting robotic datasets. However, robotic platforms possess varying control schemes, camera viewpoints, kinematic configurations, and end-effector morphologies, posing significant challenges when transferring manipulation skills from one platform to another. To tackle this problem, we propose a set of key design decisions to train a single policy for deployment on multiple robotic platforms. Our framework first aligns the observation and action spaces of our policy across embodiments via utilizing wrist cameras and a unified, but modular codebase. To bridge the remaining domain shift, we align our policy's internal representations across embodiments through contrastive learning. We evaluate our method on a dataset collected over 60 hours spanning 6 tasks and 3 robots with varying joint configurations and sizes: the WidowX 250S, the Franka Emika Panda, and the S",
    "link": "http://arxiv.org/abs/2307.03719",
    "context": "Title: Polybot: Training One Policy Across Robots While Embracing Variability. (arXiv:2307.03719v1 [cs.RO])\nAbstract: Reusing large datasets is crucial to scale vision-based robotic manipulators to everyday scenarios due to the high cost of collecting robotic datasets. However, robotic platforms possess varying control schemes, camera viewpoints, kinematic configurations, and end-effector morphologies, posing significant challenges when transferring manipulation skills from one platform to another. To tackle this problem, we propose a set of key design decisions to train a single policy for deployment on multiple robotic platforms. Our framework first aligns the observation and action spaces of our policy across embodiments via utilizing wrist cameras and a unified, but modular codebase. To bridge the remaining domain shift, we align our policy's internal representations across embodiments through contrastive learning. We evaluate our method on a dataset collected over 60 hours spanning 6 tasks and 3 robots with varying joint configurations and sizes: the WidowX 250S, the Franka Emika Panda, and the S",
    "path": "papers/23/07/2307.03719.json",
    "total_tokens": 946,
    "translated_title": "Polybot：在接受变异性的同时训练多个机器人上的一个策略",
    "translated_abstract": "由于获取机器人数据集的高成本，重用大型数据集对于将基于视觉的机器人操纵器扩展到日常情景至关重要。然而，机器人平台具有不同的控制方案、摄像机视角、运动学配置和末端执行器形态，从一个平台转移操纵技能面临着重要挑战。为了解决这个问题，我们提出一组关键设计决策，以在多个机器人平台上训练单个策略。我们的框架首先通过利用腕部摄像头和一个统一但模块化的代码库，对我们的策略在不同机体上进行观测和动作空间的对齐。为了消除剩余的领域差异，我们通过对比学习在不同机体之间对齐我们策略的内部表示。我们在一个跨6个任务和3个具有不同关节配置和尺寸的机器人的60小时数据集上评估了我们的方法：WidowX 250S，Franka Emika Panda和S。",
    "tldr": "该论文提出了一种在多个机器人平台上训练单个策略的方法，通过使用腕部摄像头和统一的代码库对观测和动作空间进行对齐，并通过对比学习来消除领域差异。实验证明该方法在不同机器人平台上具有良好的效果。",
    "en_tdlr": "This paper proposes a method to train a single policy for multiple robotic platforms, aligning observation and action spaces using wrist cameras and a unified codebase, and bridging domain shift through contrastive learning. Experimental results demonstrate the effectiveness of this method on different robotic platforms."
}