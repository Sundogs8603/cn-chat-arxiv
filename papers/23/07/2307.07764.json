{
    "title": "Explainable AI with counterfactual paths. (arXiv:2307.07764v1 [cs.AI])",
    "abstract": "Explainable AI (XAI) is an increasingly important area of research in machine learning, which in principle aims to make black-box models transparent and interpretable. In this paper, we propose a novel approach to XAI that uses counterfactual paths generated by conditional permutations. Our method provides counterfactual explanations by identifying alternative paths that could have led to different outcomes. The proposed method is particularly suitable for generating explanations based on counterfactual paths in knowledge graphs. By examining hypothetical changes to the input data in the knowledge graph, we can systematically validate the behaviour of the model and examine the features or combination of features that are most important to the model's predictions. Our approach provides a more intuitive and interpretable explanation for the model's behaviour than traditional feature weighting methods and can help identify and mitigate biases in the model.",
    "link": "http://arxiv.org/abs/2307.07764",
    "context": "Title: Explainable AI with counterfactual paths. (arXiv:2307.07764v1 [cs.AI])\nAbstract: Explainable AI (XAI) is an increasingly important area of research in machine learning, which in principle aims to make black-box models transparent and interpretable. In this paper, we propose a novel approach to XAI that uses counterfactual paths generated by conditional permutations. Our method provides counterfactual explanations by identifying alternative paths that could have led to different outcomes. The proposed method is particularly suitable for generating explanations based on counterfactual paths in knowledge graphs. By examining hypothetical changes to the input data in the knowledge graph, we can systematically validate the behaviour of the model and examine the features or combination of features that are most important to the model's predictions. Our approach provides a more intuitive and interpretable explanation for the model's behaviour than traditional feature weighting methods and can help identify and mitigate biases in the model.",
    "path": "papers/23/07/2307.07764.json",
    "total_tokens": 816,
    "translated_title": "使用反事实路径的可解释人工智能",
    "translated_abstract": "可解释人工智能是机器学习中日益重要的一个研究领域，其原则上旨在使黑盒模型透明可解释。本文提出了一种新颖的可解释人工智能方法，该方法利用条件置换生成了反事实路径。我们的方法通过确定可能导致不同结果的替代路径来提供反事实解释。所提出的方法特别适用于基于知识图谱的反事实路径解释的生成。通过检查知识图谱中输入数据的假设性变化，我们可以系统地验证模型的行为，并检查对模型预测最重要的特征或特征组合。我们的方法提供了比传统的特征加权方法更直观和可解释的解释模型行为的方式，并可以帮助识别和减轻模型中的偏见。",
    "tldr": "本文提出了一种新颖的可解释人工智能方法，使用反事实路径来生成解释。通过确定替代路径，可以提供更直观和可解释的解释模型行为的方式，并帮助识别和减轻模型中的偏见。"
}