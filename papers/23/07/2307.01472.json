{
    "title": "Beyond Conservatism: Diffusion Policies in Offline Multi-agent Reinforcement Learning. (arXiv:2307.01472v1 [cs.AI])",
    "abstract": "We present a novel Diffusion Offline Multi-agent Model (DOM2) for offline Multi-Agent Reinforcement Learning (MARL). Different from existing algorithms that rely mainly on conservatism in policy design, DOM2 enhances policy expressiveness and diversity based on diffusion. Specifically, we incorporate a diffusion model into the policy network and propose a trajectory-based data-augmentation scheme in training. These key ingredients make our algorithm more robust to environment changes and achieve significant improvements in performance, generalization and data-efficiency. Our extensive experimental results demonstrate that DOM2 outperforms existing state-of-the-art methods in multi-agent particle and multi-agent MuJoCo environments, and generalizes significantly better in shifted environments thanks to its high expressiveness and diversity. Furthermore, DOM2 shows superior data efficiency and can achieve state-of-the-art performance with $20+$ times less data compared to existing algori",
    "link": "http://arxiv.org/abs/2307.01472",
    "context": "Title: Beyond Conservatism: Diffusion Policies in Offline Multi-agent Reinforcement Learning. (arXiv:2307.01472v1 [cs.AI])\nAbstract: We present a novel Diffusion Offline Multi-agent Model (DOM2) for offline Multi-Agent Reinforcement Learning (MARL). Different from existing algorithms that rely mainly on conservatism in policy design, DOM2 enhances policy expressiveness and diversity based on diffusion. Specifically, we incorporate a diffusion model into the policy network and propose a trajectory-based data-augmentation scheme in training. These key ingredients make our algorithm more robust to environment changes and achieve significant improvements in performance, generalization and data-efficiency. Our extensive experimental results demonstrate that DOM2 outperforms existing state-of-the-art methods in multi-agent particle and multi-agent MuJoCo environments, and generalizes significantly better in shifted environments thanks to its high expressiveness and diversity. Furthermore, DOM2 shows superior data efficiency and can achieve state-of-the-art performance with $20+$ times less data compared to existing algori",
    "path": "papers/23/07/2307.01472.json",
    "total_tokens": 997,
    "translated_title": "超越保守主义：离线多智能体强化学习中的扩散策略",
    "translated_abstract": "我们提出了一种新颖的离线多智能体模型（DOM2），用于离线多智能体强化学习（MARL）。与现有算法在策略设计中主要依赖保守主义不同，DOM2基于扩散增强了策略的表达能力和多样性。具体而言，我们将扩散模型纳入策略网络，并提出了一种基于轨迹的数据增强方案进行训练。这些关键因素使我们的算法在环境变化方面更加稳健，并在性能、泛化能力和数据效率方面取得了显著的改进。我们广泛的实验结果表明，DOM2在多智能体粒子和多智能体MuJoCo环境中优于现有的最先进方法，并且由于其高表达能力和多样性，在移位环境中具有更好的泛化能力。此外，DOM2表现出卓越的数据效率，在与现有算法相比只使用$20+$倍少的数据下，就能达到最先进的性能水平。",
    "tldr": "DOM2是一种离线多智能体强化学习模型，通过扩散策略的改进，提高了算法在性能、泛化能力和数据效率方面的表现。DOM2在多智能体粒子和多智能体MuJoCo环境中优于现有算法，并在移位环境中具有更好的泛化能力。此外，DOM2还展现了卓越的数据效率，只使用较少的数据即可达到最先进的性能水平。",
    "en_tdlr": "DOM2 is an offline multi-agent reinforcement learning model that improves performance, generalization, and data efficiency through diffusion policies. It outperforms existing algorithms in multi-agent environments and demonstrates superior performance in shifted environments. Additionally, DOM2 achieves state-of-the-art performance with significantly less data."
}