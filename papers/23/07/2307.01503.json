{
    "title": "On Evaluating and Mitigating Gender Biases in Multilingual Settings. (arXiv:2307.01503v1 [cs.CL])",
    "abstract": "While understanding and removing gender biases in language models has been a long-standing problem in Natural Language Processing, prior research work has primarily been limited to English. In this work, we investigate some of the challenges with evaluating and mitigating biases in multilingual settings which stem from a lack of existing benchmarks and resources for bias evaluation beyond English especially for non-western context. In this paper, we first create a benchmark for evaluating gender biases in pre-trained masked language models by extending DisCo to different Indian languages using human annotations. We extend various debiasing methods to work beyond English and evaluate their effectiveness for SOTA massively multilingual models on our proposed metric. Overall, our work highlights the challenges that arise while studying social biases in multilingual settings and provides resources as well as mitigation techniques to take a step toward scaling to more languages.",
    "link": "http://arxiv.org/abs/2307.01503",
    "context": "Title: On Evaluating and Mitigating Gender Biases in Multilingual Settings. (arXiv:2307.01503v1 [cs.CL])\nAbstract: While understanding and removing gender biases in language models has been a long-standing problem in Natural Language Processing, prior research work has primarily been limited to English. In this work, we investigate some of the challenges with evaluating and mitigating biases in multilingual settings which stem from a lack of existing benchmarks and resources for bias evaluation beyond English especially for non-western context. In this paper, we first create a benchmark for evaluating gender biases in pre-trained masked language models by extending DisCo to different Indian languages using human annotations. We extend various debiasing methods to work beyond English and evaluate their effectiveness for SOTA massively multilingual models on our proposed metric. Overall, our work highlights the challenges that arise while studying social biases in multilingual settings and provides resources as well as mitigation techniques to take a step toward scaling to more languages.",
    "path": "papers/23/07/2307.01503.json",
    "total_tokens": 978,
    "translated_title": "在多语言环境中评估和缓解性别偏见",
    "translated_abstract": "尽管在自然语言处理中理解和消除语言模型中的性别偏见是一个长期存在的问题，但先前的研究工作主要局限于英语。在这项工作中，我们研究了在多语言环境中评估和缓解偏见所面临的一些挑战，这些挑战源于缺乏用于非西方背景的性别偏见评估的现有基准和资源。在本文中，我们首先通过使用人工注释，将DisCo扩展到不同的印度语言，为评估预先训练的掩码语言模型中的性别偏见创建了一个基准。我们将各种去偏方法扩展到英语以外的语言，并在我们提出的度量标准上评估它们对SOTA大规模多语言模型的有效性。总的来说，我们的工作突出了在多语言环境中研究社会偏见时面临的挑战，并提供了资源和缓解技术，以推进更多语言的规模化进展。",
    "tldr": "本研究探讨了在多语言环境中评估和缓解性别偏见的挑战，扩展了评估性别偏见的基准和资源，并在印度语言上创建了一个用于评估预训练的掩码语言模型中性别偏见的基准。研究还将去偏方法扩展到英语以外的语言，并在提议的度量标准上评估了它们的有效性。"
}