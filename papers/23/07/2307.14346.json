{
    "title": "Multi-objective Deep Reinforcement Learning for Mobile Edge Computing. (arXiv:2307.14346v1 [cs.NI])",
    "abstract": "Mobile edge computing (MEC) is essential for next-generation mobile network applications that prioritize various performance metrics, including delays and energy consumption. However, conventional single-objective scheduling solutions cannot be directly applied to practical systems in which the preferences of these applications (i.e., the weights of different objectives) are often unknown or challenging to specify in advance. In this study, we address this issue by formulating a multi-objective offloading problem for MEC with multiple edges to minimize expected long-term energy consumption and transmission delay while considering unknown preferences as parameters. To address the challenge of unknown preferences, we design a multi-objective (deep) reinforcement learning (MORL)-based resource scheduling scheme with proximal policy optimization (PPO). In addition, we introduce a well-designed state encoding method for constructing features for multiple edges in MEC systems, a sophisticate",
    "link": "http://arxiv.org/abs/2307.14346",
    "context": "Title: Multi-objective Deep Reinforcement Learning for Mobile Edge Computing. (arXiv:2307.14346v1 [cs.NI])\nAbstract: Mobile edge computing (MEC) is essential for next-generation mobile network applications that prioritize various performance metrics, including delays and energy consumption. However, conventional single-objective scheduling solutions cannot be directly applied to practical systems in which the preferences of these applications (i.e., the weights of different objectives) are often unknown or challenging to specify in advance. In this study, we address this issue by formulating a multi-objective offloading problem for MEC with multiple edges to minimize expected long-term energy consumption and transmission delay while considering unknown preferences as parameters. To address the challenge of unknown preferences, we design a multi-objective (deep) reinforcement learning (MORL)-based resource scheduling scheme with proximal policy optimization (PPO). In addition, we introduce a well-designed state encoding method for constructing features for multiple edges in MEC systems, a sophisticate",
    "path": "papers/23/07/2307.14346.json",
    "total_tokens": 928,
    "translated_title": "多目标深度强化学习用于移动边缘计算",
    "translated_abstract": "移动边缘计算（MEC）对于下一代移动网络应用至关重要，这些应用优先考虑各种性能指标，包括延迟和能耗。然而，传统的单目标调度解决方案不能直接应用于实际系统，因为这些应用的偏好（即不同目标的权重）通常是未知的或难以事先指定。在这项研究中，我们通过制定一个多目标离线问题来解决这个问题，针对MEC中的多个边缘来最小化预期的长期能耗和传输延迟，同时考虑未知的偏好作为参数。为了解决未知偏好的挑战，我们设计了一种基于深度强化学习（MORL）和近端策略优化（PPO）的多目标资源调度方案。此外，我们还引入了一种精心设计的状态编码方法，用于构建MEC系统中多个边缘的特征。",
    "tldr": "本研究提出了一种多目标深度强化学习方法，以解决移动边缘计算中的离线问题。该方法通过考虑未知偏好参数，最小化能耗和传输延迟，并采用近端策略优化算法进行资源调度。引入了一种特征构建方法，用于处理MEC系统中的多个边缘。",
    "en_tdlr": "This study proposes a multi-objective deep reinforcement learning method to address the offline problem in mobile edge computing. The method minimizes energy consumption and transmission delay by considering unknown preference parameters and utilizes proximal policy optimization for resource scheduling. It also introduces a feature construction approach for multiple edges in MEC systems."
}