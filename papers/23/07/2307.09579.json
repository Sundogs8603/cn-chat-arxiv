{
    "title": "Understanding Multi-Turn Toxic Behaviors in Open-Domain Chatbots. (arXiv:2307.09579v1 [cs.CR])",
    "abstract": "Recent advances in natural language processing and machine learning have led to the development of chatbot models, such as ChatGPT, that can engage in conversational dialogue with human users. However, the ability of these models to generate toxic or harmful responses during a non-toxic multi-turn conversation remains an open research question. Existing research focuses on single-turn sentence testing, while we find that 82\\% of the individual non-toxic sentences that elicit toxic behaviors in a conversation are considered safe by existing tools. In this paper, we design a new attack, \\toxicbot, by fine-tuning a chatbot to engage in conversation with a target open-domain chatbot. The chatbot is fine-tuned with a collection of crafted conversation sequences. Particularly, each conversation begins with a sentence from a crafted prompt sentences dataset. Our extensive evaluation shows that open-domain chatbot models can be triggered to generate toxic responses in a multi-turn conversation",
    "link": "http://arxiv.org/abs/2307.09579",
    "context": "Title: Understanding Multi-Turn Toxic Behaviors in Open-Domain Chatbots. (arXiv:2307.09579v1 [cs.CR])\nAbstract: Recent advances in natural language processing and machine learning have led to the development of chatbot models, such as ChatGPT, that can engage in conversational dialogue with human users. However, the ability of these models to generate toxic or harmful responses during a non-toxic multi-turn conversation remains an open research question. Existing research focuses on single-turn sentence testing, while we find that 82\\% of the individual non-toxic sentences that elicit toxic behaviors in a conversation are considered safe by existing tools. In this paper, we design a new attack, \\toxicbot, by fine-tuning a chatbot to engage in conversation with a target open-domain chatbot. The chatbot is fine-tuned with a collection of crafted conversation sequences. Particularly, each conversation begins with a sentence from a crafted prompt sentences dataset. Our extensive evaluation shows that open-domain chatbot models can be triggered to generate toxic responses in a multi-turn conversation",
    "path": "papers/23/07/2307.09579.json",
    "total_tokens": 947,
    "translated_title": "理解开放域聊天机器人中的多轮有害行为",
    "translated_abstract": "最近自然语言处理和机器学习的进展使得聊天机器人模型如ChatGPT可以与人类用户进行对话。然而，这些模型在非有害的多轮对话中生成有害或有碍的回应能力仍然是一个开放性的研究问题。现有研究关注于单句测试，而我们发现82％因为单一句子而在对话中诱发有害行为的句子被现有工具认为是安全的。在本文中，我们设计了一种新的攻击方法\\toxicbot，通过对聊天机器人进行微调与目标开放域聊天机器人进行对话。聊天机器人被微调为受控的会话序列。特别是，每个对话的起始都来自精心设计的提示句子数据集。我们的广泛评估表明，开放域聊天机器人模型可以在多轮对话中触发生成有害回应。",
    "tldr": "本研究针对开放域聊天机器人中的多轮有害行为问题进行了研究，发现现有工具无法检测出82%导致有害行为的单句都被认为是安全的。通过设计新的攻击方法\\toxicbot，我们发现开放域聊天机器人模型可以在多轮对话中触发生成有害回应。",
    "en_tdlr": "This study investigates the issue of multi-turn toxic behaviors in open-domain chatbots and finds that existing tools fail to detect 82% of single sentences that lead to toxic behaviors. By designing a new attack method, \\toxicbot, the study reveals that open-domain chatbot models can be triggered to generate toxic responses in a multi-turn conversation."
}