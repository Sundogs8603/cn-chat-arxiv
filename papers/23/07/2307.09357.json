{
    "title": "Using the IBM Analog In-Memory Hardware Acceleration Kit for Neural Network Training and Inference. (arXiv:2307.09357v1 [cs.ET])",
    "abstract": "Analog In-Memory Computing (AIMC) is a promising approach to reduce the latency and energy consumption of Deep Neural Network (DNN) inference and training. However, the noisy and non-linear device characteristics, and the non-ideal peripheral circuitry in AIMC chips, require adapting DNNs to be deployed on such hardware to achieve equivalent accuracy to digital computing. In this tutorial, we provide a deep dive into how such adaptations can be achieved and evaluated using the recently released IBM Analog Hardware Acceleration Kit (AIHWKit), freely available at https://github.com/IBM/aihwkit. The AIHWKit is a Python library that simulates inference and training of DNNs using AIMC. We present an in-depth description of the AIHWKit design, functionality, and best practices to properly perform inference and training. We also present an overview of the Analog AI Cloud Composer, that provides the benefits of using the AIHWKit simulation platform in a fully managed cloud setting. Finally, we",
    "link": "http://arxiv.org/abs/2307.09357",
    "context": "Title: Using the IBM Analog In-Memory Hardware Acceleration Kit for Neural Network Training and Inference. (arXiv:2307.09357v1 [cs.ET])\nAbstract: Analog In-Memory Computing (AIMC) is a promising approach to reduce the latency and energy consumption of Deep Neural Network (DNN) inference and training. However, the noisy and non-linear device characteristics, and the non-ideal peripheral circuitry in AIMC chips, require adapting DNNs to be deployed on such hardware to achieve equivalent accuracy to digital computing. In this tutorial, we provide a deep dive into how such adaptations can be achieved and evaluated using the recently released IBM Analog Hardware Acceleration Kit (AIHWKit), freely available at https://github.com/IBM/aihwkit. The AIHWKit is a Python library that simulates inference and training of DNNs using AIMC. We present an in-depth description of the AIHWKit design, functionality, and best practices to properly perform inference and training. We also present an overview of the Analog AI Cloud Composer, that provides the benefits of using the AIHWKit simulation platform in a fully managed cloud setting. Finally, we",
    "path": "papers/23/07/2307.09357.json",
    "total_tokens": 928,
    "translated_title": "使用IBM模拟内存硬件加速套件进行神经网络训练和推断",
    "translated_abstract": "模拟内存计算（AIMC）是减少深度神经网络（DNN）推断和训练的延迟和能源消耗的一种有前景的方法。然而，AIMC芯片中的噪声和非线性器件特性以及非理想的外围电路要求调整DNN以在此类硬件上实现与数字计算等效的精度。在这个教程中，我们详细介绍了如何使用最近发布的IBM模拟硬件加速套件（AIHWKit）进行这样的调整和评估，该套件可在https://github.com/IBM/aihwkit上免费获得。AIHWKit是一个Python库，可以使用AIMC模拟推断和训练DNN。我们详细描述了AIHWKit设计、功能和最佳实践，以正确进行推断和训练。我们还介绍了模拟AI云组合器的概述，该组合提供了在完全托管的云环境中使用AIHWKit模拟平台的优势。",
    "tldr": "本教程介绍了使用IBM Analog Hardware Acceleration Kit (AIHWKit)进行神经网络训练和推断的方法，该工具包模拟了模拟内存计算（AIMC）的推断和训练，并提供了最佳实践和云环境中使用的优势。",
    "en_tdlr": "This tutorial presents a method for neural network training and inference using the IBM Analog Hardware Acceleration Kit (AIHWKit), which simulates analog in-memory computing (AIMC) and provides best practices and advantages in a cloud environment."
}