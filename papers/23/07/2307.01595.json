{
    "title": "Prompt Tuning Pushes Farther, Contrastive Learning Pulls Closer: A Two-Stage Approach to Mitigate Social Biases. (arXiv:2307.01595v1 [cs.CL])",
    "abstract": "As the representation capability of Pre-trained Language Models (PLMs) improve, there is growing concern that they will inherit social biases from unprocessed corpora. Most previous debiasing techniques used Counterfactual Data Augmentation (CDA) to balance the training corpus. However, CDA slightly modifies the original corpus, limiting the representation distance between different demographic groups to a narrow range. As a result, the debiasing model easily fits the differences between counterfactual pairs, which affects its debiasing performance with limited text resources. In this paper, we propose an adversarial training-inspired two-stage debiasing model using Contrastive learning with Continuous Prompt Augmentation (named CCPA) to mitigate social biases in PLMs' encoding. In the first stage, we propose a data augmentation method based on continuous prompt tuning to push farther the representation distance between sample pairs along different demographic groups. In the second sta",
    "link": "http://arxiv.org/abs/2307.01595",
    "context": "Title: Prompt Tuning Pushes Farther, Contrastive Learning Pulls Closer: A Two-Stage Approach to Mitigate Social Biases. (arXiv:2307.01595v1 [cs.CL])\nAbstract: As the representation capability of Pre-trained Language Models (PLMs) improve, there is growing concern that they will inherit social biases from unprocessed corpora. Most previous debiasing techniques used Counterfactual Data Augmentation (CDA) to balance the training corpus. However, CDA slightly modifies the original corpus, limiting the representation distance between different demographic groups to a narrow range. As a result, the debiasing model easily fits the differences between counterfactual pairs, which affects its debiasing performance with limited text resources. In this paper, we propose an adversarial training-inspired two-stage debiasing model using Contrastive learning with Continuous Prompt Augmentation (named CCPA) to mitigate social biases in PLMs' encoding. In the first stage, we propose a data augmentation method based on continuous prompt tuning to push farther the representation distance between sample pairs along different demographic groups. In the second sta",
    "path": "papers/23/07/2307.01595.json",
    "total_tokens": 946,
    "translated_title": "提示调整进一步推进，对比学习拉近距离：一种两阶段方法来减轻社会偏见",
    "translated_abstract": "随着预训练语言模型（PLMs）的表示能力的提高，人们越来越担心它们会继承未经处理的语料库中的社会偏见。大多数先前的去偏技术使用对比数据增强（CDA）来平衡训练语料库。然而，CDA略微修改了原始语料库，限制了不同人口群体之间的表示距离在一个狭窄范围内。结果，去偏模型容易适应对比事实对之间的差异，这影响了它在有限的文本资源下的去偏性能。在本文中，我们提出了一种受对抗训练启发的两阶段去偏模型，使用连续提示增强的对比学习（称为CCPA）来减轻PLMs编码中的社会偏见。在第一阶段，我们提出了一种基于连续提示调整的数据增强方法，可以进一步推进不同人口群体之间的表示距离。在第二阶段，",
    "tldr": "这个论文提出了一种使用连续提示增强的对比学习的两阶段去偏模型，以减轻预训练语言模型中的社会偏见。在第一阶段，通过提示调整推进不同人口群体之间的表示距离。",
    "en_tdlr": "This paper proposes a two-stage debiasing model using contrastive learning with continuous prompt augmentation to mitigate social biases in pre-trained language models. In the first stage, the model pushes farther the representation distance between different demographic groups through prompt tuning."
}