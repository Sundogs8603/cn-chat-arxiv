{
    "title": "Stability of Multi-Agent Learning: Convergence in Network Games with Many Players. (arXiv:2307.13922v1 [cs.GT])",
    "abstract": "The behaviour of multi-agent learning in many player games has been shown to display complex dynamics outside of restrictive examples such as network zero-sum games. In addition, it has been shown that convergent behaviour is less likely to occur as the number of players increase. To make progress in resolving this problem, we study Q-Learning dynamics and determine a sufficient condition for the dynamics to converge to a unique equilibrium in any network game. We find that this condition depends on the nature of pairwise interactions and on the network structure, but is explicitly independent of the total number of agents in the game. We evaluate this result on a number of representative network games and show that, under suitable network conditions, stable learning dynamics can be achieved with an arbitrary number of agents.",
    "link": "http://arxiv.org/abs/2307.13922",
    "context": "Title: Stability of Multi-Agent Learning: Convergence in Network Games with Many Players. (arXiv:2307.13922v1 [cs.GT])\nAbstract: The behaviour of multi-agent learning in many player games has been shown to display complex dynamics outside of restrictive examples such as network zero-sum games. In addition, it has been shown that convergent behaviour is less likely to occur as the number of players increase. To make progress in resolving this problem, we study Q-Learning dynamics and determine a sufficient condition for the dynamics to converge to a unique equilibrium in any network game. We find that this condition depends on the nature of pairwise interactions and on the network structure, but is explicitly independent of the total number of agents in the game. We evaluate this result on a number of representative network games and show that, under suitable network conditions, stable learning dynamics can be achieved with an arbitrary number of agents.",
    "path": "papers/23/07/2307.13922.json",
    "total_tokens": 837,
    "translated_title": "多智能体学习的稳定性：在具有多个玩家的网络游戏中的收敛性",
    "translated_abstract": "已经证明多智能体学习在许多玩家游戏中的行为显示出复杂的动力学，超出了限制性示例（如网络零和游戏）。此外，已经证明随着玩家数量的增加，收敛行为变得不太可能发生。为了在解决这个问题上取得进展，我们研究了Q-Learning动力学，并确定了在任何网络游戏中动力学收敛于唯一均衡的充分条件。我们发现这个条件取决于成对交互的性质和网络结构，但明确与游戏中的总代理数量无关。我们评估了这个结果在一些代表性的网络游戏上，并表明在适当的网络条件下，可以实现具有任意数量代理的稳定学习动力学。",
    "tldr": "该研究探讨了多智能体学习在网络游戏中的稳定性，发现了在任何网络游戏中实现动力学收敛到唯一均衡的充分条件，并且证明在适当的网络条件下，可以实现具有任意数量代理的稳定学习动力学。",
    "en_tdlr": "This research investigates the stability of multi-agent learning in network games, identifies a sufficient condition for the convergence of dynamics to a unique equilibrium in any network game, and demonstrates that stable learning dynamics can be achieved with an arbitrary number of agents under suitable network conditions."
}