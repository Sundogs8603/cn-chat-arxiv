{
    "title": "Prompt Generate Train (PGT): A framework for few-shot domain adaptation, alignment, and uncertainty calibration of a retriever augmented generation (RAG) model for domain specific open book question-answering. (arXiv:2307.05915v1 [cs.LG])",
    "abstract": "We present a framework - Prompt, Generate, Train (PGT) - to efficiently develop a generative question-answering model for open-book question-answering over a proprietary collection of text documents. The framework adapts a retriever augmented generation model to the target domain using supervised finetuning and reinforcement learning with synthetic feedback in a few-shot setting. This yields an aligned, uncertainty calibrated model that is competitive with GPT-4 based in-context retrieval augmented generation in generating relevant answers at lower serving costs. The synthetic generation pipeline generates high quality synthetic training data musing a medium sized LLM, Flan-T5 XXL, and a novel consistency filtering scheme. The pipeline is designed to generate both abstractive and extractive questions that span the entire corpus. Using samples from this dataset, the framework fine-tunes a smaller RAG model comprising a dense retriever and a smaller sized LLM on samples from the dataset.",
    "link": "http://arxiv.org/abs/2307.05915",
    "context": "Title: Prompt Generate Train (PGT): A framework for few-shot domain adaptation, alignment, and uncertainty calibration of a retriever augmented generation (RAG) model for domain specific open book question-answering. (arXiv:2307.05915v1 [cs.LG])\nAbstract: We present a framework - Prompt, Generate, Train (PGT) - to efficiently develop a generative question-answering model for open-book question-answering over a proprietary collection of text documents. The framework adapts a retriever augmented generation model to the target domain using supervised finetuning and reinforcement learning with synthetic feedback in a few-shot setting. This yields an aligned, uncertainty calibrated model that is competitive with GPT-4 based in-context retrieval augmented generation in generating relevant answers at lower serving costs. The synthetic generation pipeline generates high quality synthetic training data musing a medium sized LLM, Flan-T5 XXL, and a novel consistency filtering scheme. The pipeline is designed to generate both abstractive and extractive questions that span the entire corpus. Using samples from this dataset, the framework fine-tunes a smaller RAG model comprising a dense retriever and a smaller sized LLM on samples from the dataset.",
    "path": "papers/23/07/2307.05915.json",
    "total_tokens": 1029,
    "translated_title": "Prompt Generate Train (PGT): 一种用于领域特定开放式问题回答的检索增强生成模型的少样本领域适应、对齐和不确定性校准框架",
    "translated_abstract": "我们提出了一种名为 Prompt, Generate, Train (PGT) 的框架，用于高效地开发一个针对专有的文本文档集合进行开放式问题回答的生成模型。该框架通过有监督的微调和强化学习，在少样本的情况下将检索增强的生成模型适应到目标领域。这产生了一个对齐、不确定性校准的模型，在生成相关答案时具有与基于 GPT-4 的上下文检索增强生成模型相竞争的性能，并且服务成本更低。通过使用中等规模的LLM (Flan-T5 XXL) 和一种新颖的一致性过滤方案，合成生成管道生成高质量合成训练数据。该管道旨在生成涵盖整个语料库的抽象和提取式问题。使用该数据集的样本，该框架对一个由稠密检索器和较小规模的LLM组成的较小的RAG模型进行微调。",
    "tldr": "提出了一个名为Prompt Generate Train (PGT)的框架，用于少样本领域适应、对齐和不确定性校准的检索增强生成模型的开发。该框架通过有监督的微调和强化学习，将模型适应到目标领域，并在生成相关答案方面具有与基于GPT-4的模型相竞争的性能。",
    "en_tdlr": "Proposed a framework called Prompt Generate Train (PGT) for developing a retriever augmented generation model with few-shot domain adaptation, alignment, and uncertainty calibration. The framework adapts the model to the target domain using supervised finetuning and reinforcement learning, achieving competitive performance in generating relevant answers compared to GPT-4 based models."
}