{
    "title": "Data Augmentation for Mathematical Objects. (arXiv:2307.06984v1 [cs.SC])",
    "abstract": "This paper discusses and evaluates ideas of data balancing and data augmentation in the context of mathematical objects: an important topic for both the symbolic computation and satisfiability checking communities, when they are making use of machine learning techniques to optimise their tools. We consider a dataset of non-linear polynomial problems and the problem of selecting a variable ordering for cylindrical algebraic decomposition to tackle these with. By swapping the variable names in already labelled problems, we generate new problem instances that do not require any further labelling when viewing the selection as a classification problem. We find this augmentation increases the accuracy of ML models by 63% on average. We study what part of this improvement is due to the balancing of the dataset and what is achieved thanks to further increasing the size of the dataset, concluding that both have a very significant effect. We finish the paper by reflecting on how this idea could ",
    "link": "http://arxiv.org/abs/2307.06984",
    "context": "Title: Data Augmentation for Mathematical Objects. (arXiv:2307.06984v1 [cs.SC])\nAbstract: This paper discusses and evaluates ideas of data balancing and data augmentation in the context of mathematical objects: an important topic for both the symbolic computation and satisfiability checking communities, when they are making use of machine learning techniques to optimise their tools. We consider a dataset of non-linear polynomial problems and the problem of selecting a variable ordering for cylindrical algebraic decomposition to tackle these with. By swapping the variable names in already labelled problems, we generate new problem instances that do not require any further labelling when viewing the selection as a classification problem. We find this augmentation increases the accuracy of ML models by 63% on average. We study what part of this improvement is due to the balancing of the dataset and what is achieved thanks to further increasing the size of the dataset, concluding that both have a very significant effect. We finish the paper by reflecting on how this idea could ",
    "path": "papers/23/07/2307.06984.json",
    "total_tokens": 829,
    "translated_title": "数学对象的数据增强",
    "translated_abstract": "本文讨论和评估了在数学对象的背景下数据平衡和数据增强的思想：这对于符号计算和可满足性检查社区来说是一个重要的主题，当他们使用机器学习技术来优化他们的工具时。我们考虑了一个非线性多项式问题的数据集，以及通过交换已标记问题中的变量名称来解决圆柱代数分解的变量排序问题。通过生成不需要进一步标记的新问题实例，我们发现这种增强平均提高了63％的ML模型准确性。我们研究了数据集平衡和进一步增加数据集大小对于此改进的影响，并得出结论，两者都有非常显著的效果。我们最后思考了这个想法如何可以扩展到其他领域。",
    "tldr": "这项研究讨论并评估了在数学对象中的数据平衡和数据增强的思路，通过交换变量名称生成新的问题实例，提高了机器学习模型的准确性，并认为数据集平衡和增加数据集大小对于效果的提升都至关重要。",
    "en_tdlr": "This study discusses and evaluates the ideas of data balancing and data augmentation in the context of mathematical objects. By swapping variable names to generate new problem instances, the accuracy of ML models is increased, highlighting the importance of dataset balancing and size increase for improving the performance."
}