{
    "title": "Patch n' Pack: NaViT, a Vision Transformer for any Aspect Ratio and Resolution. (arXiv:2307.06304v1 [cs.CV])",
    "abstract": "The ubiquitous and demonstrably suboptimal choice of resizing images to a fixed resolution before processing them with computer vision models has not yet been successfully challenged. However, models such as the Vision Transformer (ViT) offer flexible sequence-based modeling, and hence varying input sequence lengths. We take advantage of this with NaViT (Native Resolution ViT) which uses sequence packing during training to process inputs of arbitrary resolutions and aspect ratios. Alongside flexible model usage, we demonstrate improved training efficiency for large-scale supervised and contrastive image-text pretraining. NaViT can be efficiently transferred to standard tasks such as image and video classification, object detection, and semantic segmentation and leads to improved results on robustness and fairness benchmarks. At inference time, the input resolution flexibility can be used to smoothly navigate the test-time cost-performance trade-off. We believe that NaViT marks a depart",
    "link": "http://arxiv.org/abs/2307.06304",
    "context": "Title: Patch n' Pack: NaViT, a Vision Transformer for any Aspect Ratio and Resolution. (arXiv:2307.06304v1 [cs.CV])\nAbstract: The ubiquitous and demonstrably suboptimal choice of resizing images to a fixed resolution before processing them with computer vision models has not yet been successfully challenged. However, models such as the Vision Transformer (ViT) offer flexible sequence-based modeling, and hence varying input sequence lengths. We take advantage of this with NaViT (Native Resolution ViT) which uses sequence packing during training to process inputs of arbitrary resolutions and aspect ratios. Alongside flexible model usage, we demonstrate improved training efficiency for large-scale supervised and contrastive image-text pretraining. NaViT can be efficiently transferred to standard tasks such as image and video classification, object detection, and semantic segmentation and leads to improved results on robustness and fairness benchmarks. At inference time, the input resolution flexibility can be used to smoothly navigate the test-time cost-performance trade-off. We believe that NaViT marks a depart",
    "path": "papers/23/07/2307.06304.json",
    "total_tokens": 914,
    "translated_title": "Patch n' Pack: NaViT,一个适用于任意纵横比和分辨率的视觉Transformer",
    "translated_abstract": "在计算机视觉模型中，将图像调整为固定分辨率后进行处理是普遍且明显次优的选择。然而，像Vision Transformer（ViT）这样的模型提供了灵活的基于序列的建模，因此可以处理不同长度的输入序列。我们利用这一点，使用称为NaViT（Native Resolution ViT）的模型，在训练过程中进行序列打包，以处理任意分辨率和纵横比的输入。除了灵活的模型使用方式外，我们还展示了在大规模监督和对比度图像-文本预训练中的训练效率提升。NaViT可以高效地应用于图像和视频分类、目标检测、语义分割等标准任务，并在鲁棒性和公平性基准测试中取得了提升的结果。在推理阶段，输入分辨率的灵活性可以用于平稳地在测试时间的成本和性能之间进行权衡。我们相信NaViT标志着一个离开了以往思维的新篇章。",
    "tldr": "NaViT是一个视觉Transformer模型，通过序列打包的方式处理任意分辨率和纵横比的输入图像，提高了训练效率和模型在标准任务上的性能，并在鲁棒性和公平性测试中取得了显著的改进。"
}