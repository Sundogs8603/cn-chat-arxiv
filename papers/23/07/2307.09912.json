{
    "title": "Deep projection networks for learning time-homogeneous dynamical systems. (arXiv:2307.09912v1 [cs.LG])",
    "abstract": "We consider the general class of time-homogeneous dynamical systems, both discrete and continuous, and study the problem of learning a meaningful representation of the state from observed data. This is instrumental for the task of learning a forward transfer operator of the system, that in turn can be used for forecasting future states or observables. The representation, typically parametrized via a neural network, is associated with a projection operator and is learned by optimizing an objective function akin to that of canonical correlation analysis (CCA). However, unlike CCA, our objective avoids matrix inversions and therefore is generally more stable and applicable to challenging scenarios. Our objective is a tight relaxation of CCA and we further enhance it by proposing two regularization schemes, one encouraging the orthogonality of the components of the representation while the other exploiting Chapman-Kolmogorov's equation. We apply our method to challenging discrete dynamical",
    "link": "http://arxiv.org/abs/2307.09912",
    "context": "Title: Deep projection networks for learning time-homogeneous dynamical systems. (arXiv:2307.09912v1 [cs.LG])\nAbstract: We consider the general class of time-homogeneous dynamical systems, both discrete and continuous, and study the problem of learning a meaningful representation of the state from observed data. This is instrumental for the task of learning a forward transfer operator of the system, that in turn can be used for forecasting future states or observables. The representation, typically parametrized via a neural network, is associated with a projection operator and is learned by optimizing an objective function akin to that of canonical correlation analysis (CCA). However, unlike CCA, our objective avoids matrix inversions and therefore is generally more stable and applicable to challenging scenarios. Our objective is a tight relaxation of CCA and we further enhance it by proposing two regularization schemes, one encouraging the orthogonality of the components of the representation while the other exploiting Chapman-Kolmogorov's equation. We apply our method to challenging discrete dynamical",
    "path": "papers/23/07/2307.09912.json",
    "total_tokens": 904,
    "translated_title": "用于学习时间齐次动力系统的深度投影网络",
    "translated_abstract": "我们考虑了一般的时间齐次动力系统，包括离散和连续的，并研究了从观测数据中学习状态的有意义表示的问题。这对于学习系统的前向传输算子至关重要，该算子可以用于预测未来的状态或可观测量。表示通常通过神经网络参数化，与投影算子相关联，并通过优化类似于经典相关分析（CCA）的目标函数来学习。然而，与CCA不同，我们的目标函数避免了矩阵求逆，因此通常更稳定且适用于具有挑战性的场景。我们的目标函数是CCA的一个紧松弛，我们进一步通过提出两种正则化方案来增强它，一种鼓励表示的分量正交，而另一种利用了 Chapman-Kolmogorov 方程。我们将我们的方法应用于具有挑战性的离散动力系统",
    "tldr": "这篇论文介绍了一种利用深度投影网络学习时间齐次动力系统的有意义表示的方法。通过优化类似于经典相关分析的目标函数，避免了矩阵求逆的稳定性问题，并通过两种正则化方案进一步增强学习效果。",
    "en_tdlr": "This paper introduces a method to learn a meaningful representation of time-homogeneous dynamical systems using deep projection networks. By optimizing an objective function similar to canonical correlation analysis, stability issues due to matrix inversions are avoided, and the learning effectiveness is further enhanced through two regularization schemes."
}