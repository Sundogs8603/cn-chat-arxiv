{
    "title": "Adversarial Training Over Long-Tailed Distribution. (arXiv:2307.10205v1 [cs.LG])",
    "abstract": "In this paper, we study adversarial training on datasets that obey the long-tailed distribution, which is practical but rarely explored in previous works. Compared with conventional adversarial training on balanced datasets, this process falls into the dilemma of generating uneven adversarial examples (AEs) and an unbalanced feature embedding space, causing the resulting model to exhibit low robustness and accuracy on tail data. To combat that, we propose a new adversarial training framework -- Re-balancing Adversarial Training (REAT). This framework consists of two components: (1) a new training strategy inspired by the term effective number to guide the model to generate more balanced and informative AEs; (2) a carefully constructed penalty function to force a satisfactory feature space. Evaluation results on different datasets and model structures prove that REAT can effectively enhance the model's robustness and preserve the model's clean accuracy. The code can be found in https://",
    "link": "http://arxiv.org/abs/2307.10205",
    "context": "Title: Adversarial Training Over Long-Tailed Distribution. (arXiv:2307.10205v1 [cs.LG])\nAbstract: In this paper, we study adversarial training on datasets that obey the long-tailed distribution, which is practical but rarely explored in previous works. Compared with conventional adversarial training on balanced datasets, this process falls into the dilemma of generating uneven adversarial examples (AEs) and an unbalanced feature embedding space, causing the resulting model to exhibit low robustness and accuracy on tail data. To combat that, we propose a new adversarial training framework -- Re-balancing Adversarial Training (REAT). This framework consists of two components: (1) a new training strategy inspired by the term effective number to guide the model to generate more balanced and informative AEs; (2) a carefully constructed penalty function to force a satisfactory feature space. Evaluation results on different datasets and model structures prove that REAT can effectively enhance the model's robustness and preserve the model's clean accuracy. The code can be found in https://",
    "path": "papers/23/07/2307.10205.json",
    "total_tokens": 956,
    "translated_title": "长尾分布上的敌对训练",
    "translated_abstract": "本文研究了在服从长尾分布的数据集上的敌对训练，这在之前的工作中很少被探索。与平衡数据集上的传统敌对训练相比，该过程面临着产生不平衡的敌对样本和不平衡的特征嵌入空间的困境，导致生成的模型在尾部数据上表现出低鲁棒性和准确性。为了解决这个问题，我们提出了一种新的敌对训练框架--重新平衡敌对训练（REAT）。该框架包括两个组成部分：（1）一种受有效样本数启发的新训练策略，用于引导模型生成更平衡和信息丰富的敌对样本；（2）一种精心构建的惩罚函数，用于强制满足一个令人满意的特征空间。不同数据集和模型结构上的评估结果证明，REAT能够有效增强模型的鲁棒性，并保持模型的准确性。代码可以在https://中找到",
    "tldr": "本文研究了在长尾分布数据集上的敌对训练，提出了一种新的敌对训练框架--重新平衡敌对训练（REAT）。REAT能够解决敌对训练过程中产生的不平衡问题，有效增强模型的鲁棒性并保持准确性。",
    "en_tdlr": "This paper investigates adversarial training on datasets with a long-tailed distribution and proposes a new framework called Re-balancing Adversarial Training (REAT). REAT effectively addresses the imbalance issue in adversarial training, enhancing model robustness while preserving accuracy."
}