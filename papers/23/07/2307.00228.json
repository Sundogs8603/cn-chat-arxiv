{
    "title": "InferTurbo: A Scalable System for Boosting Full-graph Inference of Graph Neural Network over Huge Graphs. (arXiv:2307.00228v1 [cs.LG])",
    "abstract": "GNN inference is a non-trivial task, especially in industrial scenarios with giant graphs, given three main challenges, i.e., scalability tailored for full-graph inference on huge graphs, inconsistency caused by stochastic acceleration strategies (e.g., sampling), and the serious redundant computation issue. To address the above challenges, we propose a scalable system named InferTurbo to boost the GNN inference tasks in industrial scenarios. Inspired by the philosophy of ``think-like-a-vertex\", a GAS-like (Gather-Apply-Scatter) schema is proposed to describe the computation paradigm and data flow of GNN inference. The computation of GNNs is expressed in an iteration manner, in which a vertex would gather messages via in-edges and update its state information by forwarding an associated layer of GNNs with those messages and then send the updated information to other vertexes via out-edges. Following the schema, the proposed InferTurbo can be built with alternative backends (e.g., batch",
    "link": "http://arxiv.org/abs/2307.00228",
    "context": "Title: InferTurbo: A Scalable System for Boosting Full-graph Inference of Graph Neural Network over Huge Graphs. (arXiv:2307.00228v1 [cs.LG])\nAbstract: GNN inference is a non-trivial task, especially in industrial scenarios with giant graphs, given three main challenges, i.e., scalability tailored for full-graph inference on huge graphs, inconsistency caused by stochastic acceleration strategies (e.g., sampling), and the serious redundant computation issue. To address the above challenges, we propose a scalable system named InferTurbo to boost the GNN inference tasks in industrial scenarios. Inspired by the philosophy of ``think-like-a-vertex\", a GAS-like (Gather-Apply-Scatter) schema is proposed to describe the computation paradigm and data flow of GNN inference. The computation of GNNs is expressed in an iteration manner, in which a vertex would gather messages via in-edges and update its state information by forwarding an associated layer of GNNs with those messages and then send the updated information to other vertexes via out-edges. Following the schema, the proposed InferTurbo can be built with alternative backends (e.g., batch",
    "path": "papers/23/07/2307.00228.json",
    "total_tokens": 811,
    "translated_title": "InferTurbo: 一种用于处理大规模图上图神经网络全图推断的可扩展系统",
    "translated_abstract": "图神经网络（GNN）的推断任务在工业场景中面临着挑战，特别是在巨大的图上，存在可扩展性、不一致性和冗余计算等问题。为了解决这些挑战，我们提出了一种名为InferTurbo的可扩展系统，用于提升工业场景中的GNN推断任务。受“像顶点一样思考”的哲学启发，我们提出了一种类似GAS（Gather-Apply-Scatter）模式的计算范式和数据流描述方法。通过迭代方式进行GNN的计算，顶点通过入边收集消息，通过传递相关的GNN层和这些消息来更新状态信息，并通过出边将更新后的信息发送给其他顶点。按照这种模式，InferTurbo可以使用替代后端（如批处理）构建。",
    "tldr": "InferTurbo是一种可扩展系统，用于处理工业场景中大规模图上的图神经网络推断任务。它采用类似GAS模式的计算范式和数据流描述方法，并通过迭代方式进行计算。"
}