{
    "title": "Med-Flamingo: a Multimodal Medical Few-shot Learner. (arXiv:2307.15189v1 [cs.CV])",
    "abstract": "Medicine, by its nature, is a multifaceted domain that requires the synthesis of information across various modalities. Medical generative vision-language models (VLMs) make a first step in this direction and promise many exciting clinical applications. However, existing models typically have to be fine-tuned on sizeable down-stream datasets, which poses a significant limitation as in many medical applications data is scarce, necessitating models that are capable of learning from few examples in real-time. Here we propose Med-Flamingo, a multimodal few-shot learner adapted to the medical domain. Based on OpenFlamingo-9B, we continue pre-training on paired and interleaved medical image-text data from publications and textbooks. Med-Flamingo unlocks few-shot generative medical visual question answering (VQA) abilities, which we evaluate on several datasets including a novel challenging open-ended VQA dataset of visual USMLE-style problems. Furthermore, we conduct the first human evaluati",
    "link": "http://arxiv.org/abs/2307.15189",
    "context": "Title: Med-Flamingo: a Multimodal Medical Few-shot Learner. (arXiv:2307.15189v1 [cs.CV])\nAbstract: Medicine, by its nature, is a multifaceted domain that requires the synthesis of information across various modalities. Medical generative vision-language models (VLMs) make a first step in this direction and promise many exciting clinical applications. However, existing models typically have to be fine-tuned on sizeable down-stream datasets, which poses a significant limitation as in many medical applications data is scarce, necessitating models that are capable of learning from few examples in real-time. Here we propose Med-Flamingo, a multimodal few-shot learner adapted to the medical domain. Based on OpenFlamingo-9B, we continue pre-training on paired and interleaved medical image-text data from publications and textbooks. Med-Flamingo unlocks few-shot generative medical visual question answering (VQA) abilities, which we evaluate on several datasets including a novel challenging open-ended VQA dataset of visual USMLE-style problems. Furthermore, we conduct the first human evaluati",
    "path": "papers/23/07/2307.15189.json",
    "total_tokens": 901,
    "translated_title": "Med-Flamingo: 一种多模态医学少样本学习器",
    "translated_abstract": "医学是一个多方面的领域，需要跨多种形式的信息进行综合。医学生成视觉语言模型（VLMs）朝着这个方向迈出了第一步，并承诺有许多令人兴奋的临床应用。但是，现有的模型通常需要在大规模的下游数据集上进行微调，这是一个重大限制，因为在许多医学应用中，数据很少，需要能够从少量实例中实时学习的模型。在这里，我们提出了Med-Flamingo，一种针对医学领域的多模态少样本学习器。在OpenFlamingo-9B的基础上，我们继续对医学图文数据进行配对和交错的预训练，Med-Flamingo解锁了少样本生成式医学视觉问答（VQA）能力，我们在多个数据集上进行了评估，包括一个新颖的具有挑战性的开放式VQA数据集，其中包括视觉USMLE风格问题。此外，我们进行了第一个人工评估实验。",
    "tldr": "Med-Flamingo是一种多模态医学少样本学习器，通过在医学图文数据上进行预训练，实现了少样本生成式医学视觉问答的能力。"
}