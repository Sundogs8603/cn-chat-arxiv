{
    "title": "Enhancing Adversarial Robustness via Score-Based Optimization. (arXiv:2307.04333v2 [cs.LG] UPDATED)",
    "abstract": "Adversarial attacks have the potential to mislead deep neural network classifiers by introducing slight perturbations. Developing algorithms that can mitigate the effects of these attacks is crucial for ensuring the safe use of artificial intelligence. Recent studies have suggested that score-based diffusion models are effective in adversarial defenses. However, existing diffusion-based defenses rely on the sequential simulation of the reversed stochastic differential equations of diffusion models, which are computationally inefficient and yield suboptimal results. In this paper, we introduce a novel adversarial defense scheme named ScoreOpt, which optimizes adversarial samples at test-time, towards original clean data in the direction guided by score-based priors. We conduct comprehensive experiments on multiple datasets, including CIFAR10, CIFAR100 and ImageNet. Our experimental results demonstrate that our approach outperforms existing adversarial defenses in terms of both robustnes",
    "link": "http://arxiv.org/abs/2307.04333",
    "context": "Title: Enhancing Adversarial Robustness via Score-Based Optimization. (arXiv:2307.04333v2 [cs.LG] UPDATED)\nAbstract: Adversarial attacks have the potential to mislead deep neural network classifiers by introducing slight perturbations. Developing algorithms that can mitigate the effects of these attacks is crucial for ensuring the safe use of artificial intelligence. Recent studies have suggested that score-based diffusion models are effective in adversarial defenses. However, existing diffusion-based defenses rely on the sequential simulation of the reversed stochastic differential equations of diffusion models, which are computationally inefficient and yield suboptimal results. In this paper, we introduce a novel adversarial defense scheme named ScoreOpt, which optimizes adversarial samples at test-time, towards original clean data in the direction guided by score-based priors. We conduct comprehensive experiments on multiple datasets, including CIFAR10, CIFAR100 and ImageNet. Our experimental results demonstrate that our approach outperforms existing adversarial defenses in terms of both robustnes",
    "path": "papers/23/07/2307.04333.json",
    "total_tokens": 872,
    "translated_title": "通过基于分数的优化提升对抗鲁棒性",
    "translated_abstract": "对抗攻击有可能通过引入微小扰动来误导深度神经网络分类器。开发能够减轻这些攻击影响的算法对确保人工智能的安全使用至关重要。最近的研究表明，基于分数的扩散模型在对抗防御中是有效的。然而，现有的基于扩散的防御依赖于顺序模拟扩散模型的反向随机微分方程，这在计算效率上是低效的，并且产生次优结果。在本文中，我们介绍了一种名为ScoreOpt的新型对抗防御方案，该方案在测试时通过在由基于分数先验指导的方向上对原始干净数据进行优化来优化对抗样本。我们在多个数据集上进行了全面的实验，包括CIFAR10、CIFAR100和ImageNet。我们的实验结果表明，我们的方法在鲁棒性方面优于现有的对抗防御方法。",
    "tldr": "本文介绍了一种名为ScoreOpt的新型对抗防御方案，该方案通过优化对抗样本来提高模型的鲁棒性，实验证明该方法在多个数据集上优于现有的对抗防御方法。"
}