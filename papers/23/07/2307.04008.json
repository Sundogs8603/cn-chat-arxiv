{
    "title": "Toward Interactive Dictation. (arXiv:2307.04008v1 [cs.CL])",
    "abstract": "Voice dictation is an increasingly important text input modality. Existing systems that allow both dictation and editing-by-voice restrict their command language to flat templates invoked by trigger words. In this work, we study the feasibility of allowing users to interrupt their dictation with spoken editing commands in open-ended natural language. We introduce a new task and dataset, TERTiUS, to experiment with such systems. To support this flexibility in real-time, a system must incrementally segment and classify spans of speech as either dictation or command, and interpret the spans that are commands. We experiment with using large pre-trained language models to predict the edited text, or alternatively, to predict a small text-editing program. Experiments show a natural trade-off between model accuracy and latency: a smaller model achieves 30% end-state accuracy with 1.3 seconds of latency, while a larger model achieves 55% end-state accuracy with 7 seconds of latency.",
    "link": "http://arxiv.org/abs/2307.04008",
    "context": "Title: Toward Interactive Dictation. (arXiv:2307.04008v1 [cs.CL])\nAbstract: Voice dictation is an increasingly important text input modality. Existing systems that allow both dictation and editing-by-voice restrict their command language to flat templates invoked by trigger words. In this work, we study the feasibility of allowing users to interrupt their dictation with spoken editing commands in open-ended natural language. We introduce a new task and dataset, TERTiUS, to experiment with such systems. To support this flexibility in real-time, a system must incrementally segment and classify spans of speech as either dictation or command, and interpret the spans that are commands. We experiment with using large pre-trained language models to predict the edited text, or alternatively, to predict a small text-editing program. Experiments show a natural trade-off between model accuracy and latency: a smaller model achieves 30% end-state accuracy with 1.3 seconds of latency, while a larger model achieves 55% end-state accuracy with 7 seconds of latency.",
    "path": "papers/23/07/2307.04008.json",
    "total_tokens": 907,
    "translated_title": "迈向交互式口述",
    "translated_abstract": "语音口述是一个日益重要的文本输入方式。现有的允许口述和语音编辑的系统将它们的命令语言限制在由触发词调用的平面模板上。在这项工作中，我们研究了允许用户中断口述并使用开放式自然语言进行口述命令的可行性。我们引入了一个新任务和数据集TERTiUS，用于对这种系统进行实验。为了实时支持这种灵活性，系统必须将连续的语音片段逐步分段并分类为口述或命令，并解释命令片段。我们尝试使用大型预训练语言模型来预测编辑后的文本，或者预测一个小的文本编辑程序。实验显示模型的准确性和延迟之间存在天然的权衡：较小的模型以1.3秒的延迟达到30％的最终准确率，而较大的模型以7秒的延迟达到55％的最终准确率。",
    "tldr": "本文研究了允许用户在口述过程中用自然语言进行编辑命令的可行性，提出了一个新任务和数据集TERTiUS，并通过使用大型预训练语言模型进行实验。实验结果表明，模型的准确性和延迟之间存在权衡。",
    "en_tdlr": "This work investigates the feasibility of allowing users to interrupt their voice dictation with spoken editing commands in open-ended natural language. The authors introduce a new task and dataset, TERTiUS, and experiment with using large pre-trained language models. The experiments show a trade-off between model accuracy and latency."
}