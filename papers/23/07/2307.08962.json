{
    "title": "REX: Rapid Exploration and eXploitation for AI Agents. (arXiv:2307.08962v1 [cs.AI])",
    "abstract": "In this paper, we propose an enhanced approach for Rapid Exploration and eXploitation for AI Agents called REX. Existing AutoGPT-style techniques have inherent limitations, such as a heavy reliance on precise descriptions for decision-making, and the lack of a systematic approach to leverage try-and-fail procedures akin to traditional Reinforcement Learning (RL). REX introduces an additional layer of rewards and integrates concepts similar to Upper Confidence Bound (UCB) scores, leading to more robust and efficient AI agent performance. This approach has the advantage of enabling the utilization of offline behaviors from logs and allowing seamless integration with existing foundation models while it does not require any model fine-tuning. Through comparative analysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA Planning(RAP), REX-based methods demonstrate comparable performance and, in certain cases, even surpass the results achieved by these existing techniqu",
    "link": "http://arxiv.org/abs/2307.08962",
    "context": "Title: REX: Rapid Exploration and eXploitation for AI Agents. (arXiv:2307.08962v1 [cs.AI])\nAbstract: In this paper, we propose an enhanced approach for Rapid Exploration and eXploitation for AI Agents called REX. Existing AutoGPT-style techniques have inherent limitations, such as a heavy reliance on precise descriptions for decision-making, and the lack of a systematic approach to leverage try-and-fail procedures akin to traditional Reinforcement Learning (RL). REX introduces an additional layer of rewards and integrates concepts similar to Upper Confidence Bound (UCB) scores, leading to more robust and efficient AI agent performance. This approach has the advantage of enabling the utilization of offline behaviors from logs and allowing seamless integration with existing foundation models while it does not require any model fine-tuning. Through comparative analysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA Planning(RAP), REX-based methods demonstrate comparable performance and, in certain cases, even surpass the results achieved by these existing techniqu",
    "path": "papers/23/07/2307.08962.json",
    "total_tokens": 957,
    "translated_title": "REX: 快速探索与利用的增强型AI代理方法",
    "translated_abstract": "本文提出了一种增强型的快速探索与利用的AI代理方法，称为REX。现有的AutoGPT风格技术存在一些固有的限制，如对于决策的精确描述的过度依赖，以及缺乏类似传统强化学习(Reinforcement Learning，RL)中的尝试和失败程序的系统性方法。REX引入了额外的奖励层，并集成了类似于上限置信界限(UCB)分数的概念，从而实现更强大和高效的AI代理性能。这种方法的优势是可以利用来自日志的离线行为，并与现有的基础模型无缝集成，而不需要任何模型微调。通过与现有方法（如思维链(CoT)和规划推理(RAP)）的比较分析，基于REX的方法展示了相当的性能，并在某些情况下甚至超过了这些现有技术所取得的结果。",
    "tldr": "本文提出了一种增强型的快速探索与利用的AI代理方法REX，它通过引入额外的奖励层和类似于UCB分数的概念，实现了更强大和高效的AI代理性能，并且具有离线行为利用和与基础模型无缝集成的优势。"
}