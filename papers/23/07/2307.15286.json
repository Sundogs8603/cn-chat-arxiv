{
    "title": "Multilingual Lexical Simplification via Paraphrase Generation. (arXiv:2307.15286v1 [cs.CL])",
    "abstract": "Lexical simplification (LS) methods based on pretrained language models have made remarkable progress, generating potential substitutes for a complex word through analysis of its contextual surroundings. However, these methods require separate pretrained models for different languages and disregard the preservation of sentence meaning. In this paper, we propose a novel multilingual LS method via paraphrase generation, as paraphrases provide diversity in word selection while preserving the sentence's meaning. We regard paraphrasing as a zero-shot translation task within multilingual neural machine translation that supports hundreds of languages. After feeding the input sentence into the encoder of paraphrase modeling, we generate the substitutes based on a novel decoding strategy that concentrates solely on the lexical variations of the complex word. Experimental results demonstrate that our approach surpasses BERT-based methods and zero-shot GPT3-based method significantly on English, ",
    "link": "http://arxiv.org/abs/2307.15286",
    "context": "Title: Multilingual Lexical Simplification via Paraphrase Generation. (arXiv:2307.15286v1 [cs.CL])\nAbstract: Lexical simplification (LS) methods based on pretrained language models have made remarkable progress, generating potential substitutes for a complex word through analysis of its contextual surroundings. However, these methods require separate pretrained models for different languages and disregard the preservation of sentence meaning. In this paper, we propose a novel multilingual LS method via paraphrase generation, as paraphrases provide diversity in word selection while preserving the sentence's meaning. We regard paraphrasing as a zero-shot translation task within multilingual neural machine translation that supports hundreds of languages. After feeding the input sentence into the encoder of paraphrase modeling, we generate the substitutes based on a novel decoding strategy that concentrates solely on the lexical variations of the complex word. Experimental results demonstrate that our approach surpasses BERT-based methods and zero-shot GPT3-based method significantly on English, ",
    "path": "papers/23/07/2307.15286.json",
    "total_tokens": 848,
    "translated_title": "多语言词汇简化通过释义生成",
    "translated_abstract": "基于预训练语言模型的词汇简化方法在分析词汇上下文环境中的潜在替代词方面取得了显著进展。然而，这些方法需要针对不同语言单独进行预训练，并且忽视了句子意义的保留。在本文中，我们提出了一种通过释义生成的新颖的多语言词汇简化方法，因为释义提供了词汇选择的多样性同时保留了句子的意义。我们将释义视为多语言神经机器翻译中的零翻译任务，支持数百种语言。在释义建模的编码器中输入句子后，我们基于一种新颖的解码策略生成替代词，该策略仅关注复杂词汇的词汇变化。实验结果表明，我们的方法在英语上显著超过了基于BERT的方法和零翻译GPT3-based方法。",
    "tldr": "本文提出了一种基于释义生成的多语言词汇简化方法，通过释义生成多样性的词汇替代词并保留句子的意义，实验结果显示该方法在英语上显著优于其他方法。",
    "en_tdlr": "This paper proposes a multilingual lexical simplification method using paraphrase generation, which generates diverse word substitutes while preserving sentence meaning. Experimental results demonstrate its significant superiority over other methods in English."
}