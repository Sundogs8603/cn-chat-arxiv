{
    "title": "Information-theoretic Analysis of Test Data Sensitivity in Uncertainty. (arXiv:2307.12456v1 [stat.ML])",
    "abstract": "Bayesian inference is often utilized for uncertainty quantification tasks. A recent analysis by Xu and Raginsky 2022 rigorously decomposed the predictive uncertainty in Bayesian inference into two uncertainties, called aleatoric and epistemic uncertainties, which represent the inherent randomness in the data-generating process and the variability due to insufficient data, respectively. They analyzed those uncertainties in an information-theoretic way, assuming that the model is well-specified and treating the model's parameters as latent variables. However, the existing information-theoretic analysis of uncertainty cannot explain the widely believed property of uncertainty, known as the sensitivity between the test and training data. It implies that when test data are similar to training data in some sense, the epistemic uncertainty should become small. In this work, we study such uncertainty sensitivity using our novel decomposition method for the predictive uncertainty. Our analysis ",
    "link": "http://arxiv.org/abs/2307.12456",
    "context": "Title: Information-theoretic Analysis of Test Data Sensitivity in Uncertainty. (arXiv:2307.12456v1 [stat.ML])\nAbstract: Bayesian inference is often utilized for uncertainty quantification tasks. A recent analysis by Xu and Raginsky 2022 rigorously decomposed the predictive uncertainty in Bayesian inference into two uncertainties, called aleatoric and epistemic uncertainties, which represent the inherent randomness in the data-generating process and the variability due to insufficient data, respectively. They analyzed those uncertainties in an information-theoretic way, assuming that the model is well-specified and treating the model's parameters as latent variables. However, the existing information-theoretic analysis of uncertainty cannot explain the widely believed property of uncertainty, known as the sensitivity between the test and training data. It implies that when test data are similar to training data in some sense, the epistemic uncertainty should become small. In this work, we study such uncertainty sensitivity using our novel decomposition method for the predictive uncertainty. Our analysis ",
    "path": "papers/23/07/2307.12456.json",
    "total_tokens": 890,
    "translated_title": "不确定性中测试数据敏感性的信息论分析",
    "translated_abstract": "贝叶斯推断常被用于不确定性量化任务。Xu和Raginsky在2022年的最新分析中，将贝叶斯推断中的预测不确定性严格分解为两个不确定性，称为本质不确定性和认知不确定性，分别表示数据生成过程中的固有随机性和由于数据不足而产生的变异性。他们以信息论的方式分析了这些不确定性，假设模型是良好指定的，并将模型参数视为潜变量。然而，现有的不确定性的信息论分析不能解释被广泛认为的不确定性特性，即测试数据和训练数据之间的敏感性。这意味着当测试数据在某种意义上与训练数据相似时，认知不确定性应该变小。在这项工作中，我们使用我们的新颖分解方法研究了这种不确定性的敏感性。",
    "tldr": "本篇论文进行了关于贝叶斯推断中预测不确定性的信息论分析，将其严格分解为本质不确定性和认知不确定性。然而，现有的分析方法无法解释测试数据和训练数据之间的敏感性。本文通过使用新颖的分解方法研究了这种不确定性敏感性。"
}