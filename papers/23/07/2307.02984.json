{
    "title": "A Privacy-Preserving Walk in the Latent Space of Generative Models for Medical Applications. (arXiv:2307.02984v1 [cs.LG])",
    "abstract": "Generative Adversarial Networks (GANs) have demonstrated their ability to generate synthetic samples that match a target distribution. However, from a privacy perspective, using GANs as a proxy for data sharing is not a safe solution, as they tend to embed near-duplicates of real samples in the latent space. Recent works, inspired by k-anonymity principles, address this issue through sample aggregation in the latent space, with the drawback of reducing the dataset by a factor of k. Our work aims to mitigate this problem by proposing a latent space navigation strategy able to generate diverse synthetic samples that may support effective training of deep models, while addressing privacy concerns in a principled way. Our approach leverages an auxiliary identity classifier as a guide to non-linearly walk between points in the latent space, minimizing the risk of collision with near-duplicates of real samples. We empirically demonstrate that, given any random pair of points in the latent sp",
    "link": "http://arxiv.org/abs/2307.02984",
    "context": "Title: A Privacy-Preserving Walk in the Latent Space of Generative Models for Medical Applications. (arXiv:2307.02984v1 [cs.LG])\nAbstract: Generative Adversarial Networks (GANs) have demonstrated their ability to generate synthetic samples that match a target distribution. However, from a privacy perspective, using GANs as a proxy for data sharing is not a safe solution, as they tend to embed near-duplicates of real samples in the latent space. Recent works, inspired by k-anonymity principles, address this issue through sample aggregation in the latent space, with the drawback of reducing the dataset by a factor of k. Our work aims to mitigate this problem by proposing a latent space navigation strategy able to generate diverse synthetic samples that may support effective training of deep models, while addressing privacy concerns in a principled way. Our approach leverages an auxiliary identity classifier as a guide to non-linearly walk between points in the latent space, minimizing the risk of collision with near-duplicates of real samples. We empirically demonstrate that, given any random pair of points in the latent sp",
    "path": "papers/23/07/2307.02984.json",
    "total_tokens": 984,
    "translated_title": "生成模型潜在空间中的隐私保护行走在医学应用中",
    "translated_abstract": "生成对抗网络（GANs）展示了它们生成与目标分布匹配的合成样本的能力。然而，从隐私角度来看，使用GAN作为数据共享的代理不是一个安全的解决方案，因为它们往往在潜在空间中嵌入接近真实样本的副本。最近的研究受k-匿名原则的启发，通过在潜在空间中对样本进行聚合来解决这个问题，但会减少数据集的大小。我们的工作旨在通过提出一种潜在空间导航策略来减轻这个问题，该策略能够生成多样化的合成样本，以支持深度模型的有效训练，并以原则性的方式解决隐私问题。我们的方法利用辅助身份分类器作为导向，在潜在空间中非线性地在点之间移动，最小化与接近真实样本的副本发生冲突的风险。我们通过实验证明，对于潜在空间中的任意随机点对，我们的方法能够生成多样化的合成样本，达到了同时解决隐私问题和有效训练的目的。",
    "tldr": "这项工作提出了一种潜在空间导航策略，通过使用辅助身份分类器作为导向，在潜在空间中生成多样化的合成样本，以支持深度模型的训练，并解决了由于使用生成对抗网络而导致的隐私问题。",
    "en_tdlr": "This work proposes a latent space navigation strategy that generates diverse synthetic samples in the latent space by using an auxiliary identity classifier as a guide, supporting effective training of deep models and addressing privacy concerns caused by the use of generative adversarial networks."
}