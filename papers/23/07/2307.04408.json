{
    "title": "TIM: Teaching Large Language Models to Translate with Comparison. (arXiv:2307.04408v2 [cs.CL] UPDATED)",
    "abstract": "Open-sourced large language models (LLMs) have demonstrated remarkable efficacy in various tasks with instruction tuning. However, these models can sometimes struggle with tasks that require more specialized knowledge such as translation. One possible reason for such deficiency is that instruction tuning aims to generate fluent and coherent text that continues from a given instruction without being constrained by any task-specific requirements. Moreover, it can be more challenging for tuning smaller LLMs with lower-quality training data. To address this issue, we propose a novel framework using examples in comparison to teach LLMs to learn translation. Our approach involves presenting the model with examples of correct and incorrect translations and using a preference loss to guide the model's learning. We evaluate our method on WMT2022 test sets and show that it outperforms existing methods. Our findings offer a new perspective on fine-tuning LLMs for translation tasks and provide a p",
    "link": "http://arxiv.org/abs/2307.04408",
    "context": "Title: TIM: Teaching Large Language Models to Translate with Comparison. (arXiv:2307.04408v2 [cs.CL] UPDATED)\nAbstract: Open-sourced large language models (LLMs) have demonstrated remarkable efficacy in various tasks with instruction tuning. However, these models can sometimes struggle with tasks that require more specialized knowledge such as translation. One possible reason for such deficiency is that instruction tuning aims to generate fluent and coherent text that continues from a given instruction without being constrained by any task-specific requirements. Moreover, it can be more challenging for tuning smaller LLMs with lower-quality training data. To address this issue, we propose a novel framework using examples in comparison to teach LLMs to learn translation. Our approach involves presenting the model with examples of correct and incorrect translations and using a preference loss to guide the model's learning. We evaluate our method on WMT2022 test sets and show that it outperforms existing methods. Our findings offer a new perspective on fine-tuning LLMs for translation tasks and provide a p",
    "path": "papers/23/07/2307.04408.json",
    "total_tokens": 904,
    "translated_title": "TIM: 使用对比教授大型语言模型进行翻译",
    "translated_abstract": "开源的大型语言模型（LLMs）在通过指令调整方面展示了出色的效果。然而，这些模型在需要更专业知识的任务（如翻译）中有时会遇到困难。这种不足的可能原因之一是指令调整旨在生成流畅、连贯的文本，而不受任何任务特定要求的限制。此外，调整较小的LLM并使用较低质量的训练数据可能更具挑战性。为了解决这个问题，我们提出了一个使用例子进行对比教授LLMs学习翻译的新框架。我们的方法涉及向模型呈现正确和错误翻译的示例，并使用偏好损失来指导模型的学习。我们在WMT2022测试集上评估了我们的方法，并证明其优于现有方法。我们的发现为精调LLMs用于翻译任务提供了新的视角。",
    "tldr": "我们提出了一个使用对比教授大型语言模型进行翻译的新框架，通过向模型呈现正确和错误翻译的示例并使用偏好损失来指导模型学习，我们证明该方法优于现有方法，在精调LLMs用于翻译任务方面提供了新的视角。"
}