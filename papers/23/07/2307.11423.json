{
    "title": "Attention to Entropic Communication. (arXiv:2307.11423v1 [cs.IT])",
    "abstract": "The concept of attention, numerical weights that emphasize the importance of particular data, has proven to be very relevant in artificial intelligence. Relative entropy (RE, aka Kullback-Leibler divergence) plays a central role in communication theory. Here we combine these concepts, attention and RE. RE guides optimal encoding of messages in bandwidth-limited communication as well as optimal message decoding via the maximum entropy principle (MEP). In the coding scenario, RE can be derived from four requirements, namely being analytical, local, proper, and calibrated. Weighted RE, used for attention steering in communications, turns out to be improper. To see how proper attention communication can emerge, we analyze a scenario of a message sender who wants to ensure that the receiver of the message can perform well-informed actions. If the receiver decodes the message using the MEP, the sender only needs to know the receiver's utility function to inform optimally, but not the receive",
    "link": "http://arxiv.org/abs/2307.11423",
    "context": "Title: Attention to Entropic Communication. (arXiv:2307.11423v1 [cs.IT])\nAbstract: The concept of attention, numerical weights that emphasize the importance of particular data, has proven to be very relevant in artificial intelligence. Relative entropy (RE, aka Kullback-Leibler divergence) plays a central role in communication theory. Here we combine these concepts, attention and RE. RE guides optimal encoding of messages in bandwidth-limited communication as well as optimal message decoding via the maximum entropy principle (MEP). In the coding scenario, RE can be derived from four requirements, namely being analytical, local, proper, and calibrated. Weighted RE, used for attention steering in communications, turns out to be improper. To see how proper attention communication can emerge, we analyze a scenario of a message sender who wants to ensure that the receiver of the message can perform well-informed actions. If the receiver decodes the message using the MEP, the sender only needs to know the receiver's utility function to inform optimally, but not the receive",
    "path": "papers/23/07/2307.11423.json",
    "total_tokens": 893,
    "translated_title": "注意力对熵通信的影响",
    "translated_abstract": "注意力的概念是指在人工智能中强调特定数据重要性的数值权重，在通信理论中相对熵（RE，也称为库尔巴克-勒布勒散度）发挥着核心作用。在这里，我们结合了这些概念，即注意力和RE。RE引导带宽有限通信中的最佳编码以及通过最大熵原理（MEP）进行最佳消息解码。在编码场景中，RE可以从四个要求中推导出来，即分析性、局部性、适当性和校准性。而用于通信中注意力导向的加权RE实际上是不适当的。为了看到适当的注意力通信是如何出现的，我们分析了一个场景，即消息发送者希望确保接收者能够执行知情的操作。如果接收者使用MEP解码消息，则发送者只需要知道接收者的效用函数来进行最佳通知，不需要知道接收者的策略。",
    "tldr": "该论文研究了在通信理论中结合注意力和相对熵的概念。研究发现，在通信中使用注意力导向的加权相对熵是不适当的，而适当的注意力通信可通过发送者仅需要了解接收者的效用函数来实现最佳通知。"
}