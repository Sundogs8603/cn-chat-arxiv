{
    "title": "simPLE: a visuotactile method learned in simulation to precisely pick, localize, regrasp, and place objects. (arXiv:2307.13133v1 [cs.RO])",
    "abstract": "Existing robotic systems have a clear tension between generality and precision. Deployed solutions for robotic manipulation tend to fall into the paradigm of one robot solving a single task, lacking precise generalization, i.e., the ability to solve many tasks without compromising on precision. This paper explores solutions for precise and general pick-and-place. In precise pick-and-place, i.e. kitting, the robot transforms an unstructured arrangement of objects into an organized arrangement, which can facilitate further manipulation. We propose simPLE (simulation to Pick Localize and PLacE) as a solution to precise pick-and-place. simPLE learns to pick, regrasp and place objects precisely, given only the object CAD model and no prior experience. We develop three main components: task-aware grasping, visuotactile perception, and regrasp planning. Task-aware grasping computes affordances of grasps that are stable, observable, and favorable to placing. The visuotactile perception model r",
    "link": "http://arxiv.org/abs/2307.13133",
    "context": "Title: simPLE: a visuotactile method learned in simulation to precisely pick, localize, regrasp, and place objects. (arXiv:2307.13133v1 [cs.RO])\nAbstract: Existing robotic systems have a clear tension between generality and precision. Deployed solutions for robotic manipulation tend to fall into the paradigm of one robot solving a single task, lacking precise generalization, i.e., the ability to solve many tasks without compromising on precision. This paper explores solutions for precise and general pick-and-place. In precise pick-and-place, i.e. kitting, the robot transforms an unstructured arrangement of objects into an organized arrangement, which can facilitate further manipulation. We propose simPLE (simulation to Pick Localize and PLacE) as a solution to precise pick-and-place. simPLE learns to pick, regrasp and place objects precisely, given only the object CAD model and no prior experience. We develop three main components: task-aware grasping, visuotactile perception, and regrasp planning. Task-aware grasping computes affordances of grasps that are stable, observable, and favorable to placing. The visuotactile perception model r",
    "path": "papers/23/07/2307.13133.json",
    "total_tokens": 1030,
    "translated_title": "simPLE:一种在模拟中学习的视触觉方法，用于准确地抓取、定位、重新抓取和放置物体。",
    "translated_abstract": "现有的机器人系统在通用性和精度之间存在明显的紧张关系。用于机器人操作的部署解决方案往往属于一个机器人解决单一任务的范式，缺乏精确的泛化能力，即在保持精度的同时解决多个任务的能力。本文探讨了精确和通用的抓取和放置解决方案。在精确的抓取和放置中，即套件化中，机器人将一个无组织的物体排列转化为有组织的排列，这可以促进进一步的操作。我们提出了simPLE（模拟抓取定位和放置）作为精确抓取和放置的解决方案。simPLE学会了准确地抓取、重新抓取和放置物体，只需物体CAD模型而无需先前的经验。我们开发了三个主要组件：任务感知抓取，视觉触觉感知和重新抓取规划。任务感知抓取计算稳定、可观测且有利于放置的抓取的适应度。视觉触觉感知模型 r",
    "tldr": "本文介绍了一种称为simPLE的方法，通过在模拟中学习来实现精确的抓取、定位、重新抓取和放置物体。simPLE包括任务感知抓取、视觉触觉感知和重新抓取规划三个主要组件，能够精确地处理多个任务，而无需先前的经验。",
    "en_tdlr": "This paper introduces a method called simPLE that achieves precise picking, localizing, regrasping, and placing of objects through simulation learning. simPLE consists of three main components: task-aware grasping, visuotactile perception, and regrasp planning, enabling accurate handling of multiple tasks without prior experience."
}