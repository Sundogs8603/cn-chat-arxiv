{
    "title": "BARTPhoBEiT: Pre-trained Sequence-to-Sequence and Image Transformers Models for Vietnamese Visual Question Answering. (arXiv:2307.15335v1 [cs.CL])",
    "abstract": "Visual Question Answering (VQA) is an intricate and demanding task that integrates natural language processing (NLP) and computer vision (CV), capturing the interest of researchers. The English language, renowned for its wealth of resources, has witnessed notable advancements in both datasets and models designed for VQA. However, there is a lack of models that target specific countries such as Vietnam. To address this limitation, we introduce a transformer-based Vietnamese model named BARTPhoBEiT. This model includes pre-trained Sequence-to-Sequence and bidirectional encoder representation from Image Transformers in Vietnamese and evaluates Vietnamese VQA datasets. Experimental results demonstrate that our proposed model outperforms the strong baseline and improves the state-of-the-art in six metrics: Accuracy, Precision, Recall, F1-score, WUPS 0.0, and WUPS 0.9.",
    "link": "http://arxiv.org/abs/2307.15335",
    "context": "Title: BARTPhoBEiT: Pre-trained Sequence-to-Sequence and Image Transformers Models for Vietnamese Visual Question Answering. (arXiv:2307.15335v1 [cs.CL])\nAbstract: Visual Question Answering (VQA) is an intricate and demanding task that integrates natural language processing (NLP) and computer vision (CV), capturing the interest of researchers. The English language, renowned for its wealth of resources, has witnessed notable advancements in both datasets and models designed for VQA. However, there is a lack of models that target specific countries such as Vietnam. To address this limitation, we introduce a transformer-based Vietnamese model named BARTPhoBEiT. This model includes pre-trained Sequence-to-Sequence and bidirectional encoder representation from Image Transformers in Vietnamese and evaluates Vietnamese VQA datasets. Experimental results demonstrate that our proposed model outperforms the strong baseline and improves the state-of-the-art in six metrics: Accuracy, Precision, Recall, F1-score, WUPS 0.0, and WUPS 0.9.",
    "path": "papers/23/07/2307.15335.json",
    "total_tokens": 926,
    "translated_title": "BARTPhoBEiT: 预训练的序列到序列和图像Transformer模型在越南视觉问答中的应用",
    "translated_abstract": "视觉问答（VQA）是一个复杂且要求高的任务，将自然语言处理（NLP）和计算机视觉（CV）相结合，引起了研究者的兴趣。 英语作为资源丰富的语言，在VQA的数据集和模型设计方面取得了显著进展。 但是，缺少针对越南等特定国家的模型。 为了解决这个问题，我们引入了一个基于Transformer的越南模型，名为BARTPhoBEiT。 该模型包括预训练的越南语序列到序列和双向编码器图像Transformer，并评估了越南VQA数据集。 实验结果表明，我们提出的模型在六个指标：准确度，精确度，召回率，F1-score，WUPS 0.0和WUPS 0.9上优于强基线模型，并改进了最新技术水平。",
    "tldr": "BARTPhoBEiT是一个基于Transformer的越南模型，针对越南视觉问答任务进行了改进。实验证明，该模型在准确度、精确度、召回率、F1-score、WUPS 0.0和WUPS 0.9等六个指标上优于强基线模型，提升了最新技术水平。",
    "en_tdlr": "BARTPhoBEiT is a transformer-based Vietnamese model that improves Vietnamese visual question answering. Experimental results demonstrate that the model outperforms strong baselines and improves the state-of-the-art in six metrics: Accuracy, Precision, Recall, F1-score, WUPS 0.0, and WUPS 0.9."
}