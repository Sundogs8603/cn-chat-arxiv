{
    "title": "How Different Is Stereotypical Bias Across Languages?. (arXiv:2307.07331v1 [cs.CL])",
    "abstract": "Recent studies have demonstrated how to assess the stereotypical bias in pre-trained English language models. In this work, we extend this branch of research in multiple different dimensions by systematically investigating (a) mono- and multilingual models of (b) different underlying architectures with respect to their bias in (c) multiple different languages. To that end, we make use of the English StereoSet data set (Nadeem et al., 2021), which we semi-automatically translate into German, French, Spanish, and Turkish. We find that it is of major importance to conduct this type of analysis in a multilingual setting, as our experiments show a much more nuanced picture as well as notable differences from the English-only analysis. The main takeaways from our analysis are that mGPT-2 (partly) shows surprising anti-stereotypical behavior across languages, English (monolingual) models exhibit the strongest bias, and the stereotypes reflected in the data set are least present in Turkish mod",
    "link": "http://arxiv.org/abs/2307.07331",
    "context": "Title: How Different Is Stereotypical Bias Across Languages?. (arXiv:2307.07331v1 [cs.CL])\nAbstract: Recent studies have demonstrated how to assess the stereotypical bias in pre-trained English language models. In this work, we extend this branch of research in multiple different dimensions by systematically investigating (a) mono- and multilingual models of (b) different underlying architectures with respect to their bias in (c) multiple different languages. To that end, we make use of the English StereoSet data set (Nadeem et al., 2021), which we semi-automatically translate into German, French, Spanish, and Turkish. We find that it is of major importance to conduct this type of analysis in a multilingual setting, as our experiments show a much more nuanced picture as well as notable differences from the English-only analysis. The main takeaways from our analysis are that mGPT-2 (partly) shows surprising anti-stereotypical behavior across languages, English (monolingual) models exhibit the strongest bias, and the stereotypes reflected in the data set are least present in Turkish mod",
    "path": "papers/23/07/2307.07331.json",
    "total_tokens": 966,
    "translated_title": "跨语言的刻板偏见有何不同？",
    "translated_abstract": "最近的研究展示了如何评估预训练的英语语言模型中的刻板偏见。在本研究中，我们通过系统地调查(a)多语言模型和单语模型、(b)不同基础架构下的刻板偏见、(c)多种语言中的偏见，扩展了该研究领域的多个方面。为了实现这一目标，我们利用英语的StereoSet数据集将其半自动翻译成德语、法语、西班牙语和土耳其语。我们发现，在多语言环境下进行这种类型的分析非常重要，因为我们的实验展示了一个更为细致的画面，以及与仅英语分析有显著差异的发现。我们的分析主要得出以下结论：mGPT-2（在某种程度上）在不同语言中显示出令人惊讶的反刻板行为，英语（单语）模型表现出最强的偏见，并且数据集中反映的刻板印象在土耳其语中最不明显。",
    "tldr": "本研究拓展了评估预训练语言模型中刻板偏见的研究，通过跨语言分析发现mGPT-2在不同语言中显示出令人惊讶的反刻板行为，并且英语模型表现出最强的偏见，而土耳其语则最不明显。",
    "en_tdlr": "This study extends the research on evaluating stereotype bias in pre-trained language models by conducting cross-lingual analysis, and finds that mGPT-2 exhibits surprising anti-stereotypical behavior across different languages, while English models show the strongest bias and Turkish shows the least bias in the dataset."
}