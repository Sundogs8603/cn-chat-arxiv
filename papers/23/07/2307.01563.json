{
    "title": "Approximate information for efficient exploration-exploitation strategies. (arXiv:2307.01563v1 [stat.ML])",
    "abstract": "This paper addresses the exploration-exploitation dilemma inherent in decision-making, focusing on multi-armed bandit problems. The problems involve an agent deciding whether to exploit current knowledge for immediate gains or explore new avenues for potential long-term rewards. We here introduce a novel algorithm, approximate information maximization (AIM), which employs an analytical approximation of the entropy gradient to choose which arm to pull at each point in time. AIM matches the performance of Infomax and Thompson sampling while also offering enhanced computational speed, determinism, and tractability. Empirical evaluation of AIM indicates its compliance with the Lai-Robbins asymptotic bound and demonstrates its robustness for a range of priors. Its expression is tunable, which allows for specific optimization in various settings.",
    "link": "http://arxiv.org/abs/2307.01563",
    "context": "Title: Approximate information for efficient exploration-exploitation strategies. (arXiv:2307.01563v1 [stat.ML])\nAbstract: This paper addresses the exploration-exploitation dilemma inherent in decision-making, focusing on multi-armed bandit problems. The problems involve an agent deciding whether to exploit current knowledge for immediate gains or explore new avenues for potential long-term rewards. We here introduce a novel algorithm, approximate information maximization (AIM), which employs an analytical approximation of the entropy gradient to choose which arm to pull at each point in time. AIM matches the performance of Infomax and Thompson sampling while also offering enhanced computational speed, determinism, and tractability. Empirical evaluation of AIM indicates its compliance with the Lai-Robbins asymptotic bound and demonstrates its robustness for a range of priors. Its expression is tunable, which allows for specific optimization in various settings.",
    "path": "papers/23/07/2307.01563.json",
    "total_tokens": 843,
    "translated_title": "用于高效探索-利用策略的近似信息方法",
    "translated_abstract": "本文针对决策中潜在的探索-利用困境，重点研究多臂赌博机问题。该问题涉及一个代理决定是否利用当前的知识以获取即时收益，还是探索新的途径以获得潜在的长期回报。我们引入了一种新颖的算法，即近似信息最大化（AIM），它利用熵梯度的解析近似来选择每个时间点要拉动的手臂。AIM在性能上与Infomax和Thompson抽样相匹配，同时提供了增强的计算速度、确定性和可计算性。对AIM的实证评估表明其符合Lai-Robbins渐进界，并展示了它对一系列先验的鲁棒性。其表达式可调节，可以在不同场景下进行具体优化。",
    "tldr": "本文提出了一种称为AIM的算法，用于解决决策中的探索-利用困境，特别针对多臂赌博机问题。AIM算法利用近似熵梯度来选择每个时间点要拉动的手臂，与Infomax和Thompson抽样相比，在性能上能够匹配，同时具有更好的计算速度、确定性和可计算性。经实证评估表明，AIM算法符合Lai-Robbins渐进界，对于不同的先验具有鲁棒性。"
}