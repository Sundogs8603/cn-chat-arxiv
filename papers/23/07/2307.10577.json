{
    "title": "Ethosight: A Joint-Embedding Based System for Nuanced Perception Using Contextual Label Affinity Metric and Reasoning Based Iterative Learning. (arXiv:2307.10577v1 [cs.CV])",
    "abstract": "Traditional computer vision models often require extensive manual effort for data acquisition and validation, particularly when detecting subtle behavioral nuances or events. The difficulty in distinguishing routine behaviors from potential risks in real-world applications, like differentiating routine shopping from potential shoplifting, further complicates the process.  We present Ethosight, a novel zero-shot computer vision algorithm. Ethosight eradicates the need for pre-existing symbolic knowledge, initiating from a clean slate based on user requirements and semantic knowledge of interest. Using localized label affinity calculations and a reasoning-guided iterative learning loop, Ethosight infers scene details and iteratively refines the label set. Reasoning mechanisms can be derived from large language models like GPT4, symbolic reasoners like OpenNARS, or hybrid systems.  Ethosight further capitalizes on the capabilities of a pre-trained multi-modal model, ImageBind, generating ",
    "link": "http://arxiv.org/abs/2307.10577",
    "context": "Title: Ethosight: A Joint-Embedding Based System for Nuanced Perception Using Contextual Label Affinity Metric and Reasoning Based Iterative Learning. (arXiv:2307.10577v1 [cs.CV])\nAbstract: Traditional computer vision models often require extensive manual effort for data acquisition and validation, particularly when detecting subtle behavioral nuances or events. The difficulty in distinguishing routine behaviors from potential risks in real-world applications, like differentiating routine shopping from potential shoplifting, further complicates the process.  We present Ethosight, a novel zero-shot computer vision algorithm. Ethosight eradicates the need for pre-existing symbolic knowledge, initiating from a clean slate based on user requirements and semantic knowledge of interest. Using localized label affinity calculations and a reasoning-guided iterative learning loop, Ethosight infers scene details and iteratively refines the label set. Reasoning mechanisms can be derived from large language models like GPT4, symbolic reasoners like OpenNARS, or hybrid systems.  Ethosight further capitalizes on the capabilities of a pre-trained multi-modal model, ImageBind, generating ",
    "path": "papers/23/07/2307.10577.json",
    "total_tokens": 927,
    "translated_title": "Ethosight: 一种基于联合嵌入的系统，利用上下文标签关联度度量和基于推理的迭代学习进行细致感知",
    "translated_abstract": "传统的计算机视觉模型通常需要大量的人工努力来进行数据获取和验证，特别是在检测细微的行为细节或事件时。在实际应用中，区分常规行为和潜在风险的困难，如区分常规购物和潜在扒窃，进一步复杂化了这一过程。我们提出了Ethosight，一种新颖的零样本计算机视觉算法。Ethosight消除了对预先存在的符号知识的需求，从用户需求和感兴趣的语义知识出发进行自主学习。通过使用局部标签关联度计算和基于推理的迭代学习循环，Ethosight推断场景细节并迭代地优化标签集。推理机制可以来自大型语言模型如GPT4、符号推理器如OpenNARS或混合系统。Ethosight还充分利用了预训练的多模态模型ImageBind的能力。",
    "tldr": "Ethosight是一种零样本计算机视觉算法，通过联合嵌入、上下文标签关联度计算和基于推理的迭代学习，实现对细微行为和场景细节的准确感知，同时消除了对预先存在符号知识的需求。",
    "en_tdlr": "Ethosight is a zero-shot computer vision algorithm that achieves accurate perception of subtle behaviors and scene details using joint embedding, contextual label affinity calculation, and reasoning-guided iterative learning, while eliminating the need for pre-existing symbolic knowledge."
}