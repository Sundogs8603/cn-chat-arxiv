{
    "title": "Benchmarking Performance of Deep Learning Model for Material Segmentation on Two HPC Systems. (arXiv:2307.14921v1 [cs.PF])",
    "abstract": "Performance Benchmarking of HPC systems is an ongoing effort that seeks to provide information that will allow for increased performance and improve the job schedulers that manage these systems. We develop a benchmarking tool that utilizes machine learning models and gathers performance data on GPU-accelerated nodes while they perform material segmentation analysis. The benchmark uses a ML model that has been converted from Caffe to PyTorch using the MMdnn toolkit and the MINC-2500 dataset. Performance data is gathered on two ERDC DSRC systems, Onyx and Vulcanite. The data reveals that while Vulcanite has faster model times in a large number of benchmarks, and it is also more subject to some environmental factors that can cause performances slower than Onyx. In contrast the model times from Onyx are consistent across benchmarks.",
    "link": "http://arxiv.org/abs/2307.14921",
    "context": "Title: Benchmarking Performance of Deep Learning Model for Material Segmentation on Two HPC Systems. (arXiv:2307.14921v1 [cs.PF])\nAbstract: Performance Benchmarking of HPC systems is an ongoing effort that seeks to provide information that will allow for increased performance and improve the job schedulers that manage these systems. We develop a benchmarking tool that utilizes machine learning models and gathers performance data on GPU-accelerated nodes while they perform material segmentation analysis. The benchmark uses a ML model that has been converted from Caffe to PyTorch using the MMdnn toolkit and the MINC-2500 dataset. Performance data is gathered on two ERDC DSRC systems, Onyx and Vulcanite. The data reveals that while Vulcanite has faster model times in a large number of benchmarks, and it is also more subject to some environmental factors that can cause performances slower than Onyx. In contrast the model times from Onyx are consistent across benchmarks.",
    "path": "papers/23/07/2307.14921.json",
    "total_tokens": 847,
    "translated_title": "在两个HPC系统上对深度学习模型进行材料分割性能基准测试",
    "translated_abstract": "HPC系统的性能基准测试是一个持续的工作，旨在提供信息，以增加性能并改善管理这些系统的作业调度程序。我们开发了一个基准测试工具，利用机器学习模型，在GPU加速节点上进行材料分割分析并收集性能数据。该基准测试使用了经过MMdnn工具包将Caffe转换为PyTorch的ML模型和MINC-2500数据集。在两个ERDC DSRC系统Onyx和Vulcanite上收集了性能数据。数据显示，尽管Vulcanite在大多数基准测试中具有更快的模型时间，但它也更容易受到一些环境因素的影响，导致性能低于Onyx。相比之下，Onyx的模型时间在所有基准测试中保持一致。",
    "tldr": "该论文开发了一个基准测试工具，使用机器学习模型在两个HPC系统上进行材料分割性能分析，并发现Vulcanite在大多数测试中具有更快的模型时间，但容易受到环境因素影响，而Onyx的模型时间在所有测试中保持一致。",
    "en_tdlr": "This paper develops a benchmarking tool that uses machine learning models to analyze the performance of material segmentation on two HPC systems. The results show that while Vulcanite has faster model times in most tests, it is also more susceptible to environmental factors, whereas Onyx consistently performs well in all tests."
}