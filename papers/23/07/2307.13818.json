{
    "title": "Gradient-Based Spectral Embeddings of Random Dot Product Graphs. (arXiv:2307.13818v1 [cs.LG])",
    "abstract": "The Random Dot Product Graph (RDPG) is a generative model for relational data, where nodes are represented via latent vectors in low-dimensional Euclidean space. RDPGs crucially postulate that edge formation probabilities are given by the dot product of the corresponding latent positions. Accordingly, the embedding task of estimating these vectors from an observed graph is typically posed as a low-rank matrix factorization problem. The workhorse Adjacency Spectral Embedding (ASE) enjoys solid statistical properties, but it is formally solving a surrogate problem and can be computationally intensive. In this paper, we bring to bear recent advances in non-convex optimization and demonstrate their impact to RDPG inference. We advocate first-order gradient descent methods to better solve the embedding problem, and to organically accommodate broader network embedding applications of practical relevance. Notably, we argue that RDPG embeddings of directed graphs loose interpretability unless ",
    "link": "http://arxiv.org/abs/2307.13818",
    "context": "Title: Gradient-Based Spectral Embeddings of Random Dot Product Graphs. (arXiv:2307.13818v1 [cs.LG])\nAbstract: The Random Dot Product Graph (RDPG) is a generative model for relational data, where nodes are represented via latent vectors in low-dimensional Euclidean space. RDPGs crucially postulate that edge formation probabilities are given by the dot product of the corresponding latent positions. Accordingly, the embedding task of estimating these vectors from an observed graph is typically posed as a low-rank matrix factorization problem. The workhorse Adjacency Spectral Embedding (ASE) enjoys solid statistical properties, but it is formally solving a surrogate problem and can be computationally intensive. In this paper, we bring to bear recent advances in non-convex optimization and demonstrate their impact to RDPG inference. We advocate first-order gradient descent methods to better solve the embedding problem, and to organically accommodate broader network embedding applications of practical relevance. Notably, we argue that RDPG embeddings of directed graphs loose interpretability unless ",
    "path": "papers/23/07/2307.13818.json",
    "total_tokens": 936,
    "translated_title": "基于梯度的随机点积图谱嵌入",
    "translated_abstract": "随机点积图谱（RDPG）是一个关系数据的生成模型，其中节点通过在低维欧氏空间中的潜在向量表示。RDPG关键地假设边的形成概率由相应的潜在位置的点积给出。因此，从观察到的图中估计这些向量的嵌入任务通常被设定为一个低秩矩阵分解问题。经典的邻接谱嵌入（ASE）具有可靠的统计性质，但它在形式上解决的是一个代理问题，并且计算复杂度较高。在本文中，我们利用非凸优化的最新进展，并展示它们对RDPG推断的影响。我们提倡使用一阶梯度下降方法来更好地解决嵌入问题，并自然地适应更广泛的实用网络嵌入应用。值得注意的是，我们认为RDPG嵌入有向图失去了可解释性，除非...",
    "tldr": "本文介绍了基于梯度的随机点积图谱嵌入方法，并通过利用非凸优化技术改进了在观察图中估计节点潜在向量的任务。同时，作者还提出了一阶梯度下降方法来更好地解决嵌入问题，并适应更广泛的实用网络嵌入应用。"
}