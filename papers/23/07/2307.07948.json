{
    "title": "Model Adaptation for ASR in low-resource Indian Languages. (arXiv:2307.07948v1 [eess.AS])",
    "abstract": "Automatic speech recognition (ASR) performance has improved drastically in recent years, mainly enabled by self-supervised learning (SSL) based acoustic models such as wav2vec2 and large-scale multi-lingual training like Whisper. A huge challenge still exists for low-resource languages where the availability of both audio and text is limited. This is further complicated by the presence of multiple dialects like in Indian languages. However, many Indian languages can be grouped into the same families and share the same script and grammatical structure. This is where a lot of adaptation and fine-tuning techniques can be applied to overcome the low-resource nature of the data by utilising well-resourced similar languages.  In such scenarios, it is important to understand the extent to which each modality, like acoustics and text, is important in building a reliable ASR. It could be the case that an abundance of acoustic data in a language reduces the need for large text-only corpora. Or, ",
    "link": "http://arxiv.org/abs/2307.07948",
    "context": "Title: Model Adaptation for ASR in low-resource Indian Languages. (arXiv:2307.07948v1 [eess.AS])\nAbstract: Automatic speech recognition (ASR) performance has improved drastically in recent years, mainly enabled by self-supervised learning (SSL) based acoustic models such as wav2vec2 and large-scale multi-lingual training like Whisper. A huge challenge still exists for low-resource languages where the availability of both audio and text is limited. This is further complicated by the presence of multiple dialects like in Indian languages. However, many Indian languages can be grouped into the same families and share the same script and grammatical structure. This is where a lot of adaptation and fine-tuning techniques can be applied to overcome the low-resource nature of the data by utilising well-resourced similar languages.  In such scenarios, it is important to understand the extent to which each modality, like acoustics and text, is important in building a reliable ASR. It could be the case that an abundance of acoustic data in a language reduces the need for large text-only corpora. Or, ",
    "path": "papers/23/07/2307.07948.json",
    "total_tokens": 928,
    "translated_title": "适用于低资源印度语言的ASR模型适应",
    "translated_abstract": "最近几年，自监督学习（SSL）为基础的声学模型（如wav2vec2）和大规模多语言训练（如Whisper）使自动语音识别（ASR）的性能得到了显著提高。然而，在低资源语言中仍存在巨大挑战，这些语言的语音和文本可用性都很有限。印度语言中存在多种方言，进一步增加了复杂性。然而，许多印度语言可以分为相同的语系，共享相同的书写和语法结构。在这种情况下，可以应用许多适应和微调技术来克服数据的低资源性质，通过利用资源丰富的相似语言。在这种情况下，重要的是了解各种模态（如声学和文本）在构建可靠的ASR中的重要性。可能的情况是，在某种语言中，丰富的声学数据降低了对大型纯文本语料库的需求。",
    "tldr": "本研究提出了一种适用于低资源印度语言的ASR模型适应方法，通过利用同源语言来克服数据的低资源性质，解决了多种方言和相似语言存在的复杂性，以及对声学和文本模态的重要性进行了讨论。",
    "en_tdlr": "This paper proposes a model adaptation technique for ASR in low-resource Indian languages, which overcomes the low-resource nature of the data by utilizing well-resourced similar languages and discusses the importance of acoustic and text modalities in building a reliable ASR."
}