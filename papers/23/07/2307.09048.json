{
    "title": "FedDefender: Client-Side Attack-Tolerant Federated Learning. (arXiv:2307.09048v1 [cs.CR])",
    "abstract": "Federated learning enables learning from decentralized data sources without compromising privacy, which makes it a crucial technique. However, it is vulnerable to model poisoning attacks, where malicious clients interfere with the training process. Previous defense mechanisms have focused on the server-side by using careful model aggregation, but this may not be effective when the data is not identically distributed or when attackers can access the information of benign clients. In this paper, we propose a new defense mechanism that focuses on the client-side, called FedDefender, to help benign clients train robust local models and avoid the adverse impact of malicious model updates from attackers, even when a server-side defense cannot identify or remove adversaries. Our method consists of two main components: (1) attack-tolerant local meta update and (2) attack-tolerant global knowledge distillation. These components are used to find noise-resilient model parameters while accurately ",
    "link": "http://arxiv.org/abs/2307.09048",
    "context": "Title: FedDefender: Client-Side Attack-Tolerant Federated Learning. (arXiv:2307.09048v1 [cs.CR])\nAbstract: Federated learning enables learning from decentralized data sources without compromising privacy, which makes it a crucial technique. However, it is vulnerable to model poisoning attacks, where malicious clients interfere with the training process. Previous defense mechanisms have focused on the server-side by using careful model aggregation, but this may not be effective when the data is not identically distributed or when attackers can access the information of benign clients. In this paper, we propose a new defense mechanism that focuses on the client-side, called FedDefender, to help benign clients train robust local models and avoid the adverse impact of malicious model updates from attackers, even when a server-side defense cannot identify or remove adversaries. Our method consists of two main components: (1) attack-tolerant local meta update and (2) attack-tolerant global knowledge distillation. These components are used to find noise-resilient model parameters while accurately ",
    "path": "papers/23/07/2307.09048.json",
    "total_tokens": 937,
    "translated_title": "FedDefender：面向客户端抗攻击的联邦学习",
    "translated_abstract": "联邦学习通过不损害隐私的方式，实现了从分散的数据源进行学习，这使得它成为一种关键的技术。然而，它容易受到模型污染攻击的影响，即恶意客户端干扰训练过程。以往的防御机制主要集中在服务器端，通过精心的模型聚合来防御，但是当数据不是相同分布的，或者攻击者可以访问良性客户端的信息时，这种防御可能无效。本文提出了一种新的防御机制，名为FedDefender，它专注于客户端，在服务器端无法识别或移除对手时，帮助良性客户端训练稳健的本地模型，避免恶意模型更新的不利影响。我们的方法包括两个主要组成部分：（1）抗攻击的本地元更新和（2）抗攻击的全局知识蒸馏。这些组成部分用来找到抗噪声的模型参数，同时准确地传递全局信息。",
    "tldr": "FedDefender是一种面向客户端的联邦学习防御机制，通过抗攻击的本地元更新和全局知识蒸馏，帮助良性客户端训练稳健的本地模型，避免恶意模型更新的不利影响。"
}