{
    "title": "Confidence Estimation Using Unlabeled Data. (arXiv:2307.10440v1 [cs.LG])",
    "abstract": "Overconfidence is a common issue for deep neural networks, limiting their deployment in real-world applications. To better estimate confidence, existing methods mostly focus on fully-supervised scenarios and rely on training labels. In this paper, we propose the first confidence estimation method for a semi-supervised setting, when most training labels are unavailable. We stipulate that even with limited training labels, we can still reasonably approximate the confidence of model on unlabeled samples by inspecting the prediction consistency through the training process. We use training consistency as a surrogate function and propose a consistency ranking loss for confidence estimation. On both image classification and segmentation tasks, our method achieves state-of-the-art performances in confidence estimation. Furthermore, we show the benefit of the proposed method through a downstream active learning task. The code is available at https://github.com/TopoXLab/consistency-ranking-loss",
    "link": "http://arxiv.org/abs/2307.10440",
    "context": "Title: Confidence Estimation Using Unlabeled Data. (arXiv:2307.10440v1 [cs.LG])\nAbstract: Overconfidence is a common issue for deep neural networks, limiting their deployment in real-world applications. To better estimate confidence, existing methods mostly focus on fully-supervised scenarios and rely on training labels. In this paper, we propose the first confidence estimation method for a semi-supervised setting, when most training labels are unavailable. We stipulate that even with limited training labels, we can still reasonably approximate the confidence of model on unlabeled samples by inspecting the prediction consistency through the training process. We use training consistency as a surrogate function and propose a consistency ranking loss for confidence estimation. On both image classification and segmentation tasks, our method achieves state-of-the-art performances in confidence estimation. Furthermore, we show the benefit of the proposed method through a downstream active learning task. The code is available at https://github.com/TopoXLab/consistency-ranking-loss",
    "path": "papers/23/07/2307.10440.json",
    "total_tokens": 939,
    "translated_title": "使用无标签数据的置信度估计",
    "translated_abstract": "过度自信是深度神经网络的常见问题，限制了它们在实际应用中的部署。为了更好地估计置信度，现有方法主要集中在全监督场景，并依赖于训练标签。在本文中，我们提出了第一种适用于半监督环境的置信度估计方法，当大部分训练标签不可用时。我们认为即使只有有限的训练标签，通过检查训练过程中的预测一致性，我们仍然可以合理地近似模型对未标记样本的置信度。我们使用训练一致性作为替代函数，并提出了一种置信度估计的一致性排序损失。在图像分类和分割任务上，我们的方法在置信度估计方面取得了最先进的性能。此外，我们通过下游主动学习任务展示了所提出方法的优势。代码可在https://github.com/TopoXLab/consistency-ranking-loss找到。",
    "tldr": "本文提出了一种适用于半监督环境的置信度估计方法，通过检查训练过程中的预测一致性，即使只有有限的训练标签，我们仍然可以合理地近似模型对未标记样本的置信度。该方法在图像分类和分割任务中取得了最先进的性能，并且通过下游主动学习任务展示了其优势。",
    "en_tdlr": "This paper proposes a confidence estimation method for a semi-supervised setting, where the confidence of the model on unlabeled samples can be reasonably approximated by inspecting the prediction consistency through the training process even with limited training labels. The method achieves state-of-the-art performances in image classification and segmentation tasks, and demonstrates its advantage through a downstream active learning task."
}