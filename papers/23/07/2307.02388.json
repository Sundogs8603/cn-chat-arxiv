{
    "title": "Multi-Task Learning with Summary Statistics. (arXiv:2307.02388v1 [stat.ME])",
    "abstract": "Multi-task learning has emerged as a powerful machine learning paradigm for integrating data from multiple sources, leveraging similarities between tasks to improve overall model performance. However, the application of multi-task learning to real-world settings is hindered by data-sharing constraints, especially in healthcare settings. To address this challenge, we propose a flexible multi-task learning framework utilizing summary statistics from various sources. Additionally, we present an adaptive parameter selection approach based on a variant of Lepski's method, allowing for data-driven tuning parameter selection when only summary statistics are available. Our systematic non-asymptotic analysis characterizes the performance of the proposed methods under various regimes of the sample complexity and overlap. We demonstrate our theoretical findings and the performance of the method through extensive simulations. This work offers a more flexible tool for training related models across",
    "link": "http://arxiv.org/abs/2307.02388",
    "context": "Title: Multi-Task Learning with Summary Statistics. (arXiv:2307.02388v1 [stat.ME])\nAbstract: Multi-task learning has emerged as a powerful machine learning paradigm for integrating data from multiple sources, leveraging similarities between tasks to improve overall model performance. However, the application of multi-task learning to real-world settings is hindered by data-sharing constraints, especially in healthcare settings. To address this challenge, we propose a flexible multi-task learning framework utilizing summary statistics from various sources. Additionally, we present an adaptive parameter selection approach based on a variant of Lepski's method, allowing for data-driven tuning parameter selection when only summary statistics are available. Our systematic non-asymptotic analysis characterizes the performance of the proposed methods under various regimes of the sample complexity and overlap. We demonstrate our theoretical findings and the performance of the method through extensive simulations. This work offers a more flexible tool for training related models across",
    "path": "papers/23/07/2307.02388.json",
    "total_tokens": 861,
    "translated_title": "使用汇总统计数据的多任务学习",
    "translated_abstract": "多任务学习已经成为一个强大的机器学习范式，可以整合来自多个来源的数据，利用任务之间的相似性提高整体模型性能。然而，在真实世界的设置中，多任务学习的应用受到数据共享限制的影响，特别是在医疗领域。为了解决这个挑战，我们提出了一个灵活的多任务学习框架，利用来自各种来源的汇总统计数据。此外，我们提出了一种自适应参数选择方法，基于Lepski方法的一种变体，在仅有汇总统计数据时允许数据驱动的调参选择。我们的系统非渐近分析描述了所提方法在样本复杂度和重叠度的各种情况下的性能。我们通过大量模拟实验证明了我们的理论发现和方法的性能。这项工作为跨分析纵向数据提供了一种更灵活的训练相关模型的工具。",
    "tldr": "提出了一种利用汇总统计数据的灵活多任务学习框架，可解决在真实世界设置中数据共享限制的问题。通过自适应参数选择方法和系统非渐近分析，提高了模型性能。通过大量模拟实验证明了方法的有效性。",
    "en_tdlr": "A flexible multi-task learning framework utilizing summary statistics is proposed to address data-sharing constraints in real-world settings. The method improves model performance through adaptive parameter selection and systematic non-asymptotic analysis. Extensive simulations demonstrate the effectiveness of the approach."
}