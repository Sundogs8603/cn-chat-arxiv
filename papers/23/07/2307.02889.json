{
    "title": "Learning to Solve Tasks with Exploring Prior Behaviours. (arXiv:2307.02889v1 [cs.RO])",
    "abstract": "Demonstrations are widely used in Deep Reinforcement Learning (DRL) for facilitating solving tasks with sparse rewards. However, the tasks in real-world scenarios can often have varied initial conditions from the demonstration, which would require additional prior behaviours. For example, consider we are given the demonstration for the task of \\emph{picking up an object from an open drawer}, but the drawer is closed in the training. Without acquiring the prior behaviours of opening the drawer, the robot is unlikely to solve the task. To address this, in this paper we propose an Intrinsic Rewards Driven Example-based Control \\textbf{(IRDEC)}. Our method can endow agents with the ability to explore and acquire the required prior behaviours and then connect to the task-specific behaviours in the demonstration to solve sparse-reward tasks without requiring additional demonstration of the prior behaviours. The performance of our method outperforms other baselines on three navigation tasks a",
    "link": "http://arxiv.org/abs/2307.02889",
    "context": "Title: Learning to Solve Tasks with Exploring Prior Behaviours. (arXiv:2307.02889v1 [cs.RO])\nAbstract: Demonstrations are widely used in Deep Reinforcement Learning (DRL) for facilitating solving tasks with sparse rewards. However, the tasks in real-world scenarios can often have varied initial conditions from the demonstration, which would require additional prior behaviours. For example, consider we are given the demonstration for the task of \\emph{picking up an object from an open drawer}, but the drawer is closed in the training. Without acquiring the prior behaviours of opening the drawer, the robot is unlikely to solve the task. To address this, in this paper we propose an Intrinsic Rewards Driven Example-based Control \\textbf{(IRDEC)}. Our method can endow agents with the ability to explore and acquire the required prior behaviours and then connect to the task-specific behaviours in the demonstration to solve sparse-reward tasks without requiring additional demonstration of the prior behaviours. The performance of our method outperforms other baselines on three navigation tasks a",
    "path": "papers/23/07/2307.02889.json",
    "total_tokens": 902,
    "translated_title": "学习探索先前行为来解决任务",
    "translated_abstract": "在深度强化学习中，示范常被广泛用于解决具有稀疏奖励的任务。然而，现实世界场景中的任务往往具有与示范不同的初始条件，这就需要额外的先前行为。例如，假设我们得到了“从打开抽屉中拿取物体”的任务的示范，但在训练时抽屉是关闭的。如果没有掌握打开抽屉的先前行为，机器人很难解决这个任务。为了解决这个问题，我们提出了一种内在奖励驱动的基于示例的控制方法（IRDEC）。我们的方法可以赋予智能体探索和获取所需的先前行为的能力，并与示范中的任务特定行为连接，从而解决稀疏奖励任务，而无需额外展示先前行为示范。我们的方法在三个导航任务上的性能优于其他基线方法。",
    "tldr": "本文提出了一种基于示例的控制方法（IRDEC），通过内在奖励驱动以及探索获得先前行为，并与示范中的任务特定行为连接，从而解决具有稀疏奖励的任务。这种方法在三个导航任务上的性能优于其他基线方法。",
    "en_tdlr": "This paper proposes an example-based control method (IRDEC) that uses intrinsic rewards and exploration to acquire prior behaviors and connect them with task-specific behaviors in demonstrations, enabling the solving of sparse-reward tasks. The method outperforms other baselines on three navigation tasks."
}