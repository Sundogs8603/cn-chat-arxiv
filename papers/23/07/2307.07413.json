{
    "title": "Exploiting Counter-Examples for Active Learning with Partial labels. (arXiv:2307.07413v1 [cs.LG])",
    "abstract": "This paper studies a new problem, \\emph{active learning with partial labels} (ALPL). In this setting, an oracle annotates the query samples with partial labels, relaxing the oracle from the demanding accurate labeling process. To address ALPL, we first build an intuitive baseline that can be seamlessly incorporated into existing AL frameworks. Though effective, this baseline is still susceptible to the \\emph{overfitting}, and falls short of the representative partial-label-based samples during the query process. Drawing inspiration from human inference in cognitive science, where accurate inferences can be explicitly derived from \\emph{counter-examples} (CEs), our objective is to leverage this human-like learning pattern to tackle the \\emph{overfitting} while enhancing the process of selecting representative samples in ALPL. Specifically, we construct CEs by reversing the partial labels for each instance, and then we propose a simple but effective WorseNet to directly learn from this c",
    "link": "http://arxiv.org/abs/2307.07413",
    "context": "Title: Exploiting Counter-Examples for Active Learning with Partial labels. (arXiv:2307.07413v1 [cs.LG])\nAbstract: This paper studies a new problem, \\emph{active learning with partial labels} (ALPL). In this setting, an oracle annotates the query samples with partial labels, relaxing the oracle from the demanding accurate labeling process. To address ALPL, we first build an intuitive baseline that can be seamlessly incorporated into existing AL frameworks. Though effective, this baseline is still susceptible to the \\emph{overfitting}, and falls short of the representative partial-label-based samples during the query process. Drawing inspiration from human inference in cognitive science, where accurate inferences can be explicitly derived from \\emph{counter-examples} (CEs), our objective is to leverage this human-like learning pattern to tackle the \\emph{overfitting} while enhancing the process of selecting representative samples in ALPL. Specifically, we construct CEs by reversing the partial labels for each instance, and then we propose a simple but effective WorseNet to directly learn from this c",
    "path": "papers/23/07/2307.07413.json",
    "total_tokens": 880,
    "translated_title": "利用反例对带有部分标签的主动学习进行探索",
    "translated_abstract": "本论文研究了一个新的问题，即带有部分标签的主动学习（ALPL）。在这种设置中，一个 oracle 用部分标签对查询样本进行注释，放宽了对准确标注过程的要求。为了解决 ALPL，我们首先建立了一个直观的基线，可以无缝地融入到现有的 AL 框架中。虽然有效，但这个基线仍然容易过度拟合，并且在查询过程中缺乏代表性的基于部分标签的样本。受认知科学中人类推理的启发，我们的目标是利用这种类似人类的学习模式来解决过度拟合问题，同时增强 ALPL 中选择代表性样本的过程。具体而言，我们通过反转每个实例的部分标签构造反例，然后提出了一个简单但有效的 WorseNet 来直接从这些反例中学习。",
    "tldr": "本论文研究了一个新的问题，即带有部分标签的主动学习（ALPL）。为了解决过度拟合问题和增强选择代表性样本的过程，我们利用反例构造了一种简单有效的 WorseNet 来进行学习。"
}