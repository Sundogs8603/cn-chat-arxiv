{
    "title": "Robust Ranking Explanations. (arXiv:2307.04024v1 [cs.LG])",
    "abstract": "Robust explanations of machine learning models are critical to establish human trust in the models. Due to limited cognition capability, most humans can only interpret the top few salient features. It is critical to make top salient features robust to adversarial attacks, especially those against the more vulnerable gradient-based explanations. Existing defense measures robustness using $\\ell_p$-norms, which have weaker protection power. We define explanation thickness for measuring salient features ranking stability, and derive tractable surrogate bounds of the thickness to design the \\textit{R2ET} algorithm to efficiently maximize the thickness and anchor top salient features. Theoretically, we prove a connection between R2ET and adversarial training. Experiments with a wide spectrum of network architectures and data modalities, including brain networks, demonstrate that R2ET attains higher explanation robustness under stealthy attacks while retaining accuracy.",
    "link": "http://arxiv.org/abs/2307.04024",
    "context": "Title: Robust Ranking Explanations. (arXiv:2307.04024v1 [cs.LG])\nAbstract: Robust explanations of machine learning models are critical to establish human trust in the models. Due to limited cognition capability, most humans can only interpret the top few salient features. It is critical to make top salient features robust to adversarial attacks, especially those against the more vulnerable gradient-based explanations. Existing defense measures robustness using $\\ell_p$-norms, which have weaker protection power. We define explanation thickness for measuring salient features ranking stability, and derive tractable surrogate bounds of the thickness to design the \\textit{R2ET} algorithm to efficiently maximize the thickness and anchor top salient features. Theoretically, we prove a connection between R2ET and adversarial training. Experiments with a wide spectrum of network architectures and data modalities, including brain networks, demonstrate that R2ET attains higher explanation robustness under stealthy attacks while retaining accuracy.",
    "path": "papers/23/07/2307.04024.json",
    "total_tokens": 918,
    "translated_title": "强大的排名解释。",
    "translated_abstract": "强大的机器学习模型解释对于建立人类对模型的信任至关重要。由于认知能力有限，大多数人只能解释排名前几个显著特征。因此，将排名靠前的显著特征对抗攻击的鲁棒性尤为关键，特别是那些针对更脆弱的梯度解释。现有的防守措施使用l_p-范数来提供鲁棒性，但其保护能力较弱。我们定义了解释厚度来衡量排名稳定性，并导出了可计算的替代上界来设计R2ET算法，以有效地最大化厚度并锚定排名靠前的显著特征。理论上，我们证明了R2ET与对抗性训练之间的关联性。实验中涵盖了广泛的网络架构和数据模式，包括脑网络，证明了R2ET在保持准确性的同时达到更高的解释鲁棒性。",
    "tldr": "这篇论文提出了一种名为R2ET的算法，通过计算解释厚度来衡量排名稳定性，并设计出可最大化解释厚度并锚定排名靠前特征的算法。实验证明R2ET在面对对抗攻击时具有更高的解释鲁棒性和保持准确性能力。",
    "en_tdlr": "This paper proposes an algorithm called R2ET, which measures ranking stability by calculating the explanation thickness and designs an algorithm to maximize the explanation thickness and anchor the top salient features. Experimental results demonstrate that R2ET achieves higher explanation robustness and accuracy when facing adversarial attacks."
}