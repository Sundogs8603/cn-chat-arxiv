{
    "title": "Neural Network Pruning as Spectrum Preserving Process. (arXiv:2307.08982v1 [cs.LG])",
    "abstract": "Neural networks have achieved remarkable performance in various application domains. Nevertheless, a large number of weights in pre-trained deep neural networks prohibit them from being deployed on smartphones and embedded systems. It is highly desirable to obtain lightweight versions of neural networks for inference in edge devices. Many cost-effective approaches were proposed to prune dense and convolutional layers that are common in deep neural networks and dominant in the parameter space. However, a unified theoretical foundation for the problem mostly is missing. In this paper, we identify the close connection between matrix spectrum learning and neural network training for dense and convolutional layers and argue that weight pruning is essentially a matrix sparsification process to preserve the spectrum. Based on the analysis, we also propose a matrix sparsification algorithm tailored for neural network pruning that yields better pruning result. We carefully design and conduct ex",
    "link": "http://arxiv.org/abs/2307.08982",
    "context": "Title: Neural Network Pruning as Spectrum Preserving Process. (arXiv:2307.08982v1 [cs.LG])\nAbstract: Neural networks have achieved remarkable performance in various application domains. Nevertheless, a large number of weights in pre-trained deep neural networks prohibit them from being deployed on smartphones and embedded systems. It is highly desirable to obtain lightweight versions of neural networks for inference in edge devices. Many cost-effective approaches were proposed to prune dense and convolutional layers that are common in deep neural networks and dominant in the parameter space. However, a unified theoretical foundation for the problem mostly is missing. In this paper, we identify the close connection between matrix spectrum learning and neural network training for dense and convolutional layers and argue that weight pruning is essentially a matrix sparsification process to preserve the spectrum. Based on the analysis, we also propose a matrix sparsification algorithm tailored for neural network pruning that yields better pruning result. We carefully design and conduct ex",
    "path": "papers/23/07/2307.08982.json",
    "total_tokens": 920,
    "translated_title": "神经网络剪枝作为保持频谱的过程",
    "translated_abstract": "神经网络在各个应用领域都取得了显著的性能。然而，预训练的深度神经网络中的大量权重使其无法在智能手机和嵌入式系统上部署。获取轻量级神经网络版本以进行边缘设备推理是非常理想的。许多具有成本效益的方法被提出用于修剪在深度神经网络中常见且在参数空间中占主导地位的稠密和卷积层。然而，这个问题的统一理论基础大多缺失。在本文中，我们发现矩阵谱学习与稠密和卷积层的神经网络训练之间存在密切联系，并认为权重修剪本质上是一种保持频谱的矩阵稀疏化过程。基于分析，我们还提出了一种针对神经网络修剪的矩阵稀疏化算法，可以产生更好的修剪结果。我们精心设计和进行实验验证。",
    "tldr": "本文提出了一种新颖的神经网络剪枝方法，该方法基于矩阵谱学习与神经网络训练之间的密切关系，通过矩阵稀疏化过程来保持频谱，从而得到轻量级神经网络版本。通过实验验证，该方法能够获得更好的剪枝结果。",
    "en_tdlr": "This paper proposes a novel neural network pruning method that preserves the spectrum through a matrix sparsification process based on the close connection between matrix spectrum learning and neural network training. The method yields lightweight versions of neural networks and achieves better pruning results according to experimental validation."
}