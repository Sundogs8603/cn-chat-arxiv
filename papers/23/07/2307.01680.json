{
    "title": "Robust Hate Speech Detection in Social Media: A Cross-Dataset Empirical Evaluation. (arXiv:2307.01680v1 [cs.CL])",
    "abstract": "The automatic detection of hate speech online is an active research area in NLP. Most of the studies to date are based on social media datasets that contribute to the creation of hate speech detection models trained on them. However, data creation processes contain their own biases, and models inherently learn from these dataset-specific biases. In this paper, we perform a large-scale cross-dataset comparison where we fine-tune language models on different hate speech detection datasets. This analysis shows how some datasets are more generalisable than others when used as training data. Crucially, our experiments show how combining hate speech detection datasets can contribute to the development of robust hate speech detection models. This robustness holds even when controlling by data size and compared with the best individual datasets.",
    "link": "http://arxiv.org/abs/2307.01680",
    "context": "Title: Robust Hate Speech Detection in Social Media: A Cross-Dataset Empirical Evaluation. (arXiv:2307.01680v1 [cs.CL])\nAbstract: The automatic detection of hate speech online is an active research area in NLP. Most of the studies to date are based on social media datasets that contribute to the creation of hate speech detection models trained on them. However, data creation processes contain their own biases, and models inherently learn from these dataset-specific biases. In this paper, we perform a large-scale cross-dataset comparison where we fine-tune language models on different hate speech detection datasets. This analysis shows how some datasets are more generalisable than others when used as training data. Crucially, our experiments show how combining hate speech detection datasets can contribute to the development of robust hate speech detection models. This robustness holds even when controlling by data size and compared with the best individual datasets.",
    "path": "papers/23/07/2307.01680.json",
    "total_tokens": 842,
    "translated_title": "社交媒体中对恶意言论的鲁棒性检测：跨数据集的实证评估",
    "translated_abstract": "在自然语言处理领域，对在线恶意言论的自动检测是一个活跃的研究领域。迄今为止，大多数研究都基于社交媒体数据集，这些数据集有助于训练恶意言论检测模型。然而，数据创建过程中存在自身的偏见，并且模型在本地数据集的偏见下进行学习。在本文中，我们进行了一个大规模的跨数据集比较，使用不同的恶意言论检测数据集来进行语言模型的微调。这项分析显示了当作为训练数据时，一些数据集比其他数据集更具有泛化能力。关键是，我们的实验表明，结合恶意言论检测数据集可以有助于开发出鲁棒的恶意言论检测模型。这种鲁棒性甚至在控制数据大小、与最佳单个数据集进行比较时也成立。",
    "tldr": "本文通过跨数据集比较发现，结合多个恶意言论检测数据集可以开发出鲁棒的恶意言论检测模型，即使在控制数据大小的情况下，这种鲁棒性仍然存在。"
}