{
    "title": "Q(D)O-ES: Population-based Quality (Diversity) Optimisation for Post Hoc Ensemble Selection in AutoML. (arXiv:2307.08364v2 [cs.LG] UPDATED)",
    "abstract": "Automated machine learning (AutoML) systems commonly ensemble models post hoc to improve predictive performance, typically via greedy ensemble selection (GES). However, we believe that GES may not always be optimal, as it performs a simple deterministic greedy search. In this work, we introduce two novel population-based ensemble selection methods, QO-ES and QDO-ES, and compare them to GES. While QO-ES optimises solely for predictive performance, QDO-ES also considers the diversity of ensembles within the population, maintaining a diverse set of well-performing ensembles during optimisation based on ideas of quality diversity optimisation. The methods are evaluated using 71 classification datasets from the AutoML benchmark, demonstrating that QO-ES and QDO-ES often outrank GES, albeit only statistically significant on validation data. Our results further suggest that diversity can be beneficial for post hoc ensembling but also increases the risk of overfitting.",
    "link": "http://arxiv.org/abs/2307.08364",
    "context": "Title: Q(D)O-ES: Population-based Quality (Diversity) Optimisation for Post Hoc Ensemble Selection in AutoML. (arXiv:2307.08364v2 [cs.LG] UPDATED)\nAbstract: Automated machine learning (AutoML) systems commonly ensemble models post hoc to improve predictive performance, typically via greedy ensemble selection (GES). However, we believe that GES may not always be optimal, as it performs a simple deterministic greedy search. In this work, we introduce two novel population-based ensemble selection methods, QO-ES and QDO-ES, and compare them to GES. While QO-ES optimises solely for predictive performance, QDO-ES also considers the diversity of ensembles within the population, maintaining a diverse set of well-performing ensembles during optimisation based on ideas of quality diversity optimisation. The methods are evaluated using 71 classification datasets from the AutoML benchmark, demonstrating that QO-ES and QDO-ES often outrank GES, albeit only statistically significant on validation data. Our results further suggest that diversity can be beneficial for post hoc ensembling but also increases the risk of overfitting.",
    "path": "papers/23/07/2307.08364.json",
    "total_tokens": 1030,
    "translated_title": "Q(D)O-ES: 用于自动机器学习中的后期集成选择的基于群体的质量(多样性)优化",
    "translated_abstract": "自动化机器学习系统通常在后期结合模型以提高预测性能，通常通过贪婪的集成选择(GES)。然而，我们认为GES并不总是最优的，因为它执行简单的确定性贪婪搜索。在这项工作中，我们引入了两种新颖的基于群体的集成选择方法QO-ES和QDO-ES，并将它们与GES进行比较。虽然QO-ES仅针对预测性能进行优化，QDO-ES还考虑了群体内集成的多样性，在优化过程中保持一组表现良好且多样化的集成，这是基于质量多样化优化的思想。使用AutoML基准中的71个分类数据集对这些方法进行评估，结果表明，QO-ES和QDO-ES通常优于GES，尽管在验证数据上只具有统计显著性。我们的结果进一步表明多样性对于后期集成可能是有益的，但也增加了过拟合的风险。",
    "tldr": "本论文提出了两种新颖的基于群体的集成选择方法QO-ES和QDO-ES，并将它们与贪婪的集成选择进行比较。结果显示，QO-ES和QDO-ES通常优于贪婪的集成选择，尽管只有在验证数据上具有统计显著性。研究还发现，多样性对于后期集成可能有益，但也增加了过拟合的风险。"
}