{
    "title": "CValues: Measuring the Values of Chinese Large Language Models from Safety to Responsibility. (arXiv:2307.09705v1 [cs.CL])",
    "abstract": "With the rapid evolution of large language models (LLMs), there is a growing concern that they may pose risks or have negative social impacts. Therefore, evaluation of human values alignment is becoming increasingly important. Previous work mainly focuses on assessing the performance of LLMs on certain knowledge and reasoning abilities, while neglecting the alignment to human values, especially in a Chinese context. In this paper, we present CValues, the first Chinese human values evaluation benchmark to measure the alignment ability of LLMs in terms of both safety and responsibility criteria. As a result, we have manually collected adversarial safety prompts across 10 scenarios and induced responsibility prompts from 8 domains by professional experts. To provide a comprehensive values evaluation of Chinese LLMs, we not only conduct human evaluation for reliable comparison, but also construct multi-choice prompts for automatic evaluation. Our findings suggest that while most Chinese LL",
    "link": "http://arxiv.org/abs/2307.09705",
    "context": "Title: CValues: Measuring the Values of Chinese Large Language Models from Safety to Responsibility. (arXiv:2307.09705v1 [cs.CL])\nAbstract: With the rapid evolution of large language models (LLMs), there is a growing concern that they may pose risks or have negative social impacts. Therefore, evaluation of human values alignment is becoming increasingly important. Previous work mainly focuses on assessing the performance of LLMs on certain knowledge and reasoning abilities, while neglecting the alignment to human values, especially in a Chinese context. In this paper, we present CValues, the first Chinese human values evaluation benchmark to measure the alignment ability of LLMs in terms of both safety and responsibility criteria. As a result, we have manually collected adversarial safety prompts across 10 scenarios and induced responsibility prompts from 8 domains by professional experts. To provide a comprehensive values evaluation of Chinese LLMs, we not only conduct human evaluation for reliable comparison, but also construct multi-choice prompts for automatic evaluation. Our findings suggest that while most Chinese LL",
    "path": "papers/23/07/2307.09705.json",
    "total_tokens": 995,
    "translated_title": "CValues: 从安全到责任度量中文大型语言模型的价值观",
    "translated_abstract": "随着大型语言模型（LLMs）的迅速发展，人们越来越担心它们可能带来风险或对社会产生负面影响。因此，评估人类价值观的一致性变得越来越重要。先前的工作主要关注评估LLMs在特定知识和推理能力上的表现，而忽视了对人类价值观的一致性，特别是在中国的背景下。在本文中，我们提出了CValues，这是首个中文人类价值观评估基准，用于衡量LLMs在安全和责任准则方面的一致性能力。作为结果，我们手动收集了10个场景的对抗性安全提示，并由专业专家从8个领域诱导了责任提示。为了全面评估中文LLMs的价值观，我们不仅进行人工评估以进行可靠的比较，还构建了多选提示以进行自动评估。我们的研究结果表明，尽管大多数中文LLMs具有较高的准确性和效用，但仍然存在与人类价值观不一致的情况。",
    "tldr": "本论文提出了CValues，这是首个中文人类价值观评估基准，用于衡量中文大型语言模型在安全和责任准则方面的一致性能力。研究发现，虽然大多数中文大型语言模型具有较高的准确性和效用，但仍然存在与人类价值观不一致的情况。",
    "en_tdlr": "This paper presents CValues, the first Chinese human values evaluation benchmark, to measure the alignment ability of Chinese large language models in terms of both safety and responsibility criteria. The research findings suggest that while most Chinese large language models have high accuracy and utility, there are still cases of misalignment with human values."
}