{
    "title": "SINC: Self-Supervised In-Context Learning for Vision-Language Tasks. (arXiv:2307.07742v1 [cs.CV])",
    "abstract": "Large Pre-trained Transformers exhibit an intriguing capacity for in-context learning. Without gradient updates, these models can rapidly construct new predictors from demonstrations presented in the inputs. Recent works promote this ability in the vision-language domain by incorporating visual information into large language models that can already make in-context predictions. However, these methods could inherit issues in the language domain, such as template sensitivity and hallucination. Also, the scale of these language models raises a significant demand for computations, making learning and operating these models resource-intensive. To this end, we raise a question: ``How can we enable in-context learning for general models without being constrained on large language models?\". To answer it, we propose a succinct and general framework, Self-supervised IN-Context learning (SINC), that introduces a meta-model to learn on self-supervised prompts consisting of tailored demonstrations.",
    "link": "http://arxiv.org/abs/2307.07742",
    "context": "Title: SINC: Self-Supervised In-Context Learning for Vision-Language Tasks. (arXiv:2307.07742v1 [cs.CV])\nAbstract: Large Pre-trained Transformers exhibit an intriguing capacity for in-context learning. Without gradient updates, these models can rapidly construct new predictors from demonstrations presented in the inputs. Recent works promote this ability in the vision-language domain by incorporating visual information into large language models that can already make in-context predictions. However, these methods could inherit issues in the language domain, such as template sensitivity and hallucination. Also, the scale of these language models raises a significant demand for computations, making learning and operating these models resource-intensive. To this end, we raise a question: ``How can we enable in-context learning for general models without being constrained on large language models?\". To answer it, we propose a succinct and general framework, Self-supervised IN-Context learning (SINC), that introduces a meta-model to learn on self-supervised prompts consisting of tailored demonstrations.",
    "path": "papers/23/07/2307.07742.json",
    "total_tokens": 884,
    "translated_title": "SINC: 自主上下文学习用于视觉-语言任务",
    "translated_abstract": "大型预训练Transformers模型展示了在上下文学习中引人入胜的能力。这些模型可以在输入中呈现的演示中，迅速构建新的预测器，而无需梯度更新。最近的工作在视觉-语言领域中促进了这种能力，通过将视觉信息融入到已经能够进行上下文预测的大型语言模型中。然而，这些方法可能继承了语言领域的问题，如模板敏感性和产生幻觉。此外，这些语言模型的规模提高了计算需求，使得学习和操作这些模型资源密集。为此，我们提出了一个问题：“如何在不限制于大型语言模型的情况下，让通用模型能够进行上下文学习？”。为了回答这个问题，我们提出了一个简洁而通用的框架，自主上下文学习（SINC），它引入了一个元模型，以自我监督的提示为基础进行学习，这些提示包括量身定制的演示。",
    "tldr": "提出了一种名为SINC的自主上下文学习框架，可以在不依赖于大型语言模型的情况下实现上下文学习，并避免了模板敏感性和幻觉等问题。",
    "en_tdlr": "Introduced SINC, a self-supervised in-context learning framework that enables in-context learning without relying on large language models, avoiding issues such as template sensitivity and hallucination."
}