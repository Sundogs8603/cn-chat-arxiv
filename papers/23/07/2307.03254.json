{
    "title": "Vision Language Transformers: A Survey. (arXiv:2307.03254v1 [cs.CV])",
    "abstract": "Vision language tasks, such as answering questions about or generating captions that describe an image, are difficult tasks for computers to perform. A relatively recent body of research has adapted the pretrained transformer architecture introduced in \\citet{vaswani2017attention} to vision language modeling. Transformer models have greatly improved performance and versatility over previous vision language models. They do so by pretraining models on a large generic datasets and transferring their learning to new tasks with minor changes in architecture and parameter values. This type of transfer learning has become the standard modeling practice in both natural language processing and computer vision. Vision language transformers offer the promise of producing similar advancements in tasks which require both vision and language. In this paper, we provide a broad synthesis of the currently available research on vision language transformer models and offer some analysis of their strength",
    "link": "http://arxiv.org/abs/2307.03254",
    "context": "Title: Vision Language Transformers: A Survey. (arXiv:2307.03254v1 [cs.CV])\nAbstract: Vision language tasks, such as answering questions about or generating captions that describe an image, are difficult tasks for computers to perform. A relatively recent body of research has adapted the pretrained transformer architecture introduced in \\citet{vaswani2017attention} to vision language modeling. Transformer models have greatly improved performance and versatility over previous vision language models. They do so by pretraining models on a large generic datasets and transferring their learning to new tasks with minor changes in architecture and parameter values. This type of transfer learning has become the standard modeling practice in both natural language processing and computer vision. Vision language transformers offer the promise of producing similar advancements in tasks which require both vision and language. In this paper, we provide a broad synthesis of the currently available research on vision language transformer models and offer some analysis of their strength",
    "path": "papers/23/07/2307.03254.json",
    "total_tokens": 789,
    "translated_title": "视觉语言转换器：一项调查",
    "translated_abstract": "视觉语言任务，如回答关于图像的问题或生成描述图像的标题，是计算机难以完成的任务。最近的研究将预训练的transformer架构应用于视觉语言建模。相比以前的视觉语言模型，transformer模型在性能和多功能性方面有很大提高。它们通过在大型通用数据集上进行预训练，并在架构和参数值上进行微小改变后，将学习转移到新任务中。这种迁移学习已成为自然语言处理和计算机视觉中的标准建模实践。视觉语言转换器承诺在需要同时进行视觉和语言的任务中产生类似的进展。本文对目前可用的视觉语言转换器模型的研究进行了广泛综合，并对其优势进行了分析。",
    "tldr": "视觉语言转换器是将预训练的transformer架构应用于视觉语言建模的研究领域，通过迁移学习，在同时进行视觉和语言任务中取得了显著改进。"
}