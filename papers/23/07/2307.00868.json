{
    "title": "MADS: Modulated Auto-Decoding SIREN for time series imputation. (arXiv:2307.00868v1 [stat.ML])",
    "abstract": "Time series imputation remains a significant challenge across many fields due to the potentially significant variability in the type of data being modelled. Whilst traditional imputation methods often impose strong assumptions on the underlying data generation process, limiting their applicability, researchers have recently begun to investigate the potential of deep learning for this task, inspired by the strong performance shown by these models in both classification and regression problems across a range of applications. In this work we propose MADS, a novel auto-decoding framework for time series imputation, built upon implicit neural representations. Our method leverages the capabilities of SIRENs for high fidelity reconstruction of signals and irregular data, and combines it with a hypernetwork architecture which allows us to generalise by learning a prior over the space of time series. We evaluate our model on two real-world datasets, and show that it outperforms state-of-the-art",
    "link": "http://arxiv.org/abs/2307.00868",
    "context": "Title: MADS: Modulated Auto-Decoding SIREN for time series imputation. (arXiv:2307.00868v1 [stat.ML])\nAbstract: Time series imputation remains a significant challenge across many fields due to the potentially significant variability in the type of data being modelled. Whilst traditional imputation methods often impose strong assumptions on the underlying data generation process, limiting their applicability, researchers have recently begun to investigate the potential of deep learning for this task, inspired by the strong performance shown by these models in both classification and regression problems across a range of applications. In this work we propose MADS, a novel auto-decoding framework for time series imputation, built upon implicit neural representations. Our method leverages the capabilities of SIRENs for high fidelity reconstruction of signals and irregular data, and combines it with a hypernetwork architecture which allows us to generalise by learning a prior over the space of time series. We evaluate our model on two real-world datasets, and show that it outperforms state-of-the-art",
    "path": "papers/23/07/2307.00868.json",
    "total_tokens": 910,
    "translated_title": "MADS：调控式自解码SIREN用于时间序列插补",
    "translated_abstract": "由于所建模数据中具有潜在的显著变异性，时间序列插补在许多领域仍然是一个重要挑战。传统的插补方法通常对底层数据生成过程施加强假设，限制了它们的适用性，而研究人员最近开始探索深度学习在此任务中的潜力，受到这些模型在分类和回归问题上的强大性能的启发，应用范围广泛。在这项工作中，我们提出了一种新颖的基于隐式神经表示的时间序列插补自解码框架MADS。我们的方法利用了SIREN对信号和不规则数据进行高保真重建的能力，并将其与超网络架构相结合，通过学习时间序列空间的先验知识来实现泛化。我们在两个真实数据集上评估了我们的模型，并展示它超越了现有最先进的方法。",
    "tldr": "本论文提出了一种新的自解码框架MADS，用于时间序列插补。该方法基于隐式神经表示，利用SIREN的能力进行高保真重建，并采用超网络架构进行泛化。实验证明该模型在两个真实数据集上的表现优于现有最先进的方法。",
    "en_tdlr": "This paper proposes a novel auto-decoding framework called MADS for time series imputation. The method utilizes implicit neural representations and leverages the capabilities of SIRENs for high fidelity reconstruction. The model outperforms state-of-the-art methods on two real-world datasets."
}