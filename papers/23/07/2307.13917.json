{
    "title": "BayesDAG: Gradient-Based Posterior Sampling for Causal Discovery. (arXiv:2307.13917v1 [cs.LG])",
    "abstract": "Bayesian causal discovery aims to infer the posterior distribution over causal models from observed data, quantifying epistemic uncertainty and benefiting downstream tasks. However, computational challenges arise due to joint inference over combinatorial space of Directed Acyclic Graphs (DAGs) and nonlinear functions. Despite recent progress towards efficient posterior inference over DAGs, existing methods are either limited to variational inference on node permutation matrices for linear causal models, leading to compromised inference accuracy, or continuous relaxation of adjacency matrices constrained by a DAG regularizer, which cannot ensure resulting graphs are DAGs. In this work, we introduce a scalable Bayesian causal discovery framework based on stochastic gradient Markov Chain Monte Carlo (SG-MCMC) that overcomes these limitations. Our approach directly samples DAGs from the posterior without requiring any DAG regularization, simultaneously draws function parameter samples and ",
    "link": "http://arxiv.org/abs/2307.13917",
    "context": "Title: BayesDAG: Gradient-Based Posterior Sampling for Causal Discovery. (arXiv:2307.13917v1 [cs.LG])\nAbstract: Bayesian causal discovery aims to infer the posterior distribution over causal models from observed data, quantifying epistemic uncertainty and benefiting downstream tasks. However, computational challenges arise due to joint inference over combinatorial space of Directed Acyclic Graphs (DAGs) and nonlinear functions. Despite recent progress towards efficient posterior inference over DAGs, existing methods are either limited to variational inference on node permutation matrices for linear causal models, leading to compromised inference accuracy, or continuous relaxation of adjacency matrices constrained by a DAG regularizer, which cannot ensure resulting graphs are DAGs. In this work, we introduce a scalable Bayesian causal discovery framework based on stochastic gradient Markov Chain Monte Carlo (SG-MCMC) that overcomes these limitations. Our approach directly samples DAGs from the posterior without requiring any DAG regularization, simultaneously draws function parameter samples and ",
    "path": "papers/23/07/2307.13917.json",
    "total_tokens": 873,
    "translated_title": "BayesDAG：基于梯度的因果发现的后验采样",
    "translated_abstract": "贝叶斯因果发现旨在从观测数据中推断出因果模型的后验分布，量化认知不确定性，从而有助于下游任务。然而，由于有向无环图（DAG）和非线性函数的组合空间的联合推理而带来了计算挑战。尽管近年来在DAG上的高效后验推断方面取得了进展，但现有方法要么仅限于对线性因果模型的节点排列矩阵进行变分推断，导致推断准确性受损，要么是在受DAG正则化约束的邻接矩阵上进行连续松弛，而不能确保得到的图是DAGs。在这项工作中，我们介绍了一种基于随机梯度马尔科夫链蒙特卡罗（SG-MCMC）的可扩展贝叶斯因果发现框架，克服了这些局限性。我们的方法直接从后验中采样DAG，并且不需要任何DAG正则化，同时还绘制函数参数样本和…",
    "tldr": "这项研究引入了一种基于梯度的后验采样方法，用于解决Bayesian causal discovery中的计算挑战，能够高效地推断因果模型，并且不依赖于DAG正则化。",
    "en_tdlr": "This paper introduces a gradient-based posterior sampling method for efficient inference of causal models in Bayesian causal discovery, without relying on DAG regularization."
}