{
    "title": "QontSum: On Contrasting Salient Content for Query-focused Summarization. (arXiv:2307.07586v1 [cs.CL])",
    "abstract": "Query-focused summarization (QFS) is a challenging task in natural language processing that generates summaries to address specific queries. The broader field of Generative Information Retrieval (Gen-IR) aims to revolutionize information extraction from vast document corpora through generative approaches, encompassing Generative Document Retrieval (GDR) and Grounded Answer Retrieval (GAR). This paper highlights the role of QFS in Grounded Answer Generation (GAR), a key subdomain of Gen-IR that produces human-readable answers in direct correspondence with queries, grounded in relevant documents. In this study, we propose QontSum, a novel approach for QFS that leverages contrastive learning to help the model attend to the most relevant regions of the input document. We evaluate our approach on a couple of benchmark datasets for QFS and demonstrate that it either outperforms existing state-of-the-art or exhibits a comparable performance with considerably reduced computational cost through",
    "link": "http://arxiv.org/abs/2307.07586",
    "context": "Title: QontSum: On Contrasting Salient Content for Query-focused Summarization. (arXiv:2307.07586v1 [cs.CL])\nAbstract: Query-focused summarization (QFS) is a challenging task in natural language processing that generates summaries to address specific queries. The broader field of Generative Information Retrieval (Gen-IR) aims to revolutionize information extraction from vast document corpora through generative approaches, encompassing Generative Document Retrieval (GDR) and Grounded Answer Retrieval (GAR). This paper highlights the role of QFS in Grounded Answer Generation (GAR), a key subdomain of Gen-IR that produces human-readable answers in direct correspondence with queries, grounded in relevant documents. In this study, we propose QontSum, a novel approach for QFS that leverages contrastive learning to help the model attend to the most relevant regions of the input document. We evaluate our approach on a couple of benchmark datasets for QFS and demonstrate that it either outperforms existing state-of-the-art or exhibits a comparable performance with considerably reduced computational cost through",
    "path": "papers/23/07/2307.07586.json",
    "total_tokens": 948,
    "translated_title": "QontSum: 对比突出查询重点的摘要生成",
    "translated_abstract": "查询重点摘要 (QFS) 是自然语言处理中一项具有挑战性的任务，它生成以解决特定查询为目的的摘要。更广泛的生成式信息检索 (Gen-IR) 领域旨在通过生成式方法改变从庞大的文档语料库中提取信息的方式，包括生成式文档检索 (GDR) 和基础答案检索 (GAR)。本文强调了 QFS 在基础答案生成 (GAR) 中的作用，这是 Gen-IR 的一个关键子领域，它产生与查询直接对应、以相关文档为基础的可读性答案。在本研究中，我们提出了 QontSum，一种新颖的 QFS 方法，它利用对比学习帮助模型集中注意力于输入文档中最相关的区域。我们在一些 QFS 的基准数据集上评估了我们的方法，并证明它要么优于现有的最先进方法，要么在显著减少计算成本的同时表现出可比较的性能。",
    "tldr": "本文针对查询重点摘要 (QFS) 提出了一种名为 QontSum 的新方法。该方法利用对比学习帮助模型集中注意力于输入文档中最相关的区域，并在多个基准数据集上展示了优于现有方法或在减少计算成本的同时表现出可比较性能的结果。",
    "en_tdlr": "This paper proposes a novel method called QontSum for query-focused summarization (QFS). The approach leverages contrastive learning to help the model attend to the most relevant regions of the input document and shows superior performance compared to existing methods or comparable performance with reduced computational cost on multiple benchmark datasets."
}