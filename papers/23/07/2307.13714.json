{
    "title": "Diversity and Language Technology: How Techno-Linguistic Bias Can Cause Epistemic Injustice. (arXiv:2307.13714v1 [cs.CY])",
    "abstract": "It is well known that AI-based language technology -- large language models, machine translation systems, multilingual dictionaries, and corpora -- is currently limited to 2 to 3 percent of the world's most widely spoken and/or financially and politically best supported languages. In response, recent research efforts have sought to extend the reach of AI technology to ``underserved languages.'' In this paper, we show that many of these attempts produce flawed solutions that adhere to a hard-wired representational preference for certain languages, which we call techno-linguistic bias. Techno-linguistic bias is distinct from the well-established phenomenon of linguistic bias as it does not concern the languages represented but rather the design of the technologies. As we show through the paper, techno-linguistic bias can result in systems that can only express concepts that are part of the language and culture of dominant powers, unable to correctly represent concepts from other communit",
    "link": "http://arxiv.org/abs/2307.13714",
    "context": "Title: Diversity and Language Technology: How Techno-Linguistic Bias Can Cause Epistemic Injustice. (arXiv:2307.13714v1 [cs.CY])\nAbstract: It is well known that AI-based language technology -- large language models, machine translation systems, multilingual dictionaries, and corpora -- is currently limited to 2 to 3 percent of the world's most widely spoken and/or financially and politically best supported languages. In response, recent research efforts have sought to extend the reach of AI technology to ``underserved languages.'' In this paper, we show that many of these attempts produce flawed solutions that adhere to a hard-wired representational preference for certain languages, which we call techno-linguistic bias. Techno-linguistic bias is distinct from the well-established phenomenon of linguistic bias as it does not concern the languages represented but rather the design of the technologies. As we show through the paper, techno-linguistic bias can result in systems that can only express concepts that are part of the language and culture of dominant powers, unable to correctly represent concepts from other communit",
    "path": "papers/23/07/2307.13714.json",
    "total_tokens": 891,
    "translated_title": "多样性和语言技术：科技语言偏见如何导致认识论不公正",
    "translated_abstract": "众所周知，基于人工智能的语言技术，如大型语言模型、机器翻译系统、多语言词典和语料库等，目前仅限于世界上2%至3%的最常用、政治和财政支持最好的语言。为此，最近的研究努力试图将AI技术扩展到“未服务的语言”。在本文中，我们展示了许多这些尝试所产生的解决方案存在缺陷，这些方案遵循了对某些语言的硬编码表现偏好，我们称之为科技语言偏见。科技语言偏见与已经被广泛认可的语言偏见现象不同，它不涉及所代表的语言，而是涉及技术的设计。正如我们在本文中所展示的那样，科技语言偏见可能导致系统只能表达属于特定语言和文化的概念，无法正确表达其他社区的概念。",
    "tldr": "本文揭示了多样性和语言技术之间的关系，指出科技语言偏见会导致认识论不公正的问题，限制了AI技术对于未服务语言的发展和应用。",
    "en_tdlr": "This paper investigates the relationship between diversity and language technology, highlighting how techno-linguistic bias can result in epistemic injustice by limiting the development and application of AI technology for underserved languages."
}