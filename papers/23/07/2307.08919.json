{
    "title": "Accuracy versus time frontiers of semi-supervised and self-supervised learning on medical images. (arXiv:2307.08919v1 [cs.CV])",
    "abstract": "For many applications of classifiers to medical images, a trustworthy label for each image can be difficult or expensive to obtain. In contrast, images without labels are more readily available. Two major research directions both promise that additional unlabeled data can improve classifier performance: self-supervised learning pretrains useful representations on unlabeled data only, then fine-tunes a classifier on these representations via the labeled set; semi-supervised learning directly trains a classifier on labeled and unlabeled data simultaneously. Recent methods from both directions have claimed significant gains on non-medical tasks, but do not systematically assess medical images and mostly compare only to methods in the same direction. This study contributes a carefully-designed benchmark to help answer a practitioner's key question: given a small labeled dataset and a limited budget of hours to spend on training, what gains from additional unlabeled images are possible and ",
    "link": "http://arxiv.org/abs/2307.08919",
    "context": "Title: Accuracy versus time frontiers of semi-supervised and self-supervised learning on medical images. (arXiv:2307.08919v1 [cs.CV])\nAbstract: For many applications of classifiers to medical images, a trustworthy label for each image can be difficult or expensive to obtain. In contrast, images without labels are more readily available. Two major research directions both promise that additional unlabeled data can improve classifier performance: self-supervised learning pretrains useful representations on unlabeled data only, then fine-tunes a classifier on these representations via the labeled set; semi-supervised learning directly trains a classifier on labeled and unlabeled data simultaneously. Recent methods from both directions have claimed significant gains on non-medical tasks, but do not systematically assess medical images and mostly compare only to methods in the same direction. This study contributes a carefully-designed benchmark to help answer a practitioner's key question: given a small labeled dataset and a limited budget of hours to spend on training, what gains from additional unlabeled images are possible and ",
    "path": "papers/23/07/2307.08919.json",
    "total_tokens": 868,
    "translated_title": "半监督和自监督学习在医学图像上的准确性与时间前沿比较",
    "translated_abstract": "对于许多医学图像分类器的应用来说，每个图像都很难或昂贵地获得一个可信的标签。相比之下，没有标签的图像更容易获取。两个主要研究方向都承诺额外的无标签数据可以提高分类器的性能：自监督学习仅在无标签数据上预训练有用的表示，然后通过标记集对这些表示进行微调以获得分类器；半监督学习同时在标记和无标签数据上直接训练分类器。最近的方法从两个方向上都声称在非医学任务上取得了显著的收益，但没有系统评估医学图像，并且大多只与同一方向的方法进行比较。本研究提供了一个经过精心设计的基准来回答从业者的一个关键问题：在小型标记数据集和有限的培训时间预算下，额外的无标签图像能够产生多大的收益。",
    "tldr": "半监督和自监督学习在医学图像上的准确性与时间前沿进行比较，通过一个精心设计的基准研究来回答从业者的问题。",
    "en_tdlr": "A benchmark study comparing the accuracy and time trade-offs of semi-supervised and self-supervised learning on medical images, providing insights for practitioners on the benefits of additional unlabeled data with limited training resources."
}