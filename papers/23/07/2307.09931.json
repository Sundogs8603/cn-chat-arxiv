{
    "title": "DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration. (arXiv:2307.09931v1 [cs.CV])",
    "abstract": "Multimodal image registration is a challenging but essential step for numerous image-guided procedures. Most registration algorithms rely on the computation of complex, frequently non-differentiable similarity metrics to deal with the appearance discrepancy of anatomical structures between imaging modalities. Recent Machine Learning based approaches are limited to specific anatomy-modality combinations and do not generalize to new settings. We propose a generic framework for creating expressive cross-modal descriptors that enable fast deformable global registration. We achieve this by approximating existing metrics with a dot-product in the feature space of a small convolutional neural network (CNN) which is inherently differentiable can be trained without registered data. Our method is several orders of magnitude faster than local patch-based metrics and can be directly applied in clinical settings by replacing the similarity measure with the proposed one. Experiments on three differe",
    "link": "http://arxiv.org/abs/2307.09931",
    "context": "Title: DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration. (arXiv:2307.09931v1 [cs.CV])\nAbstract: Multimodal image registration is a challenging but essential step for numerous image-guided procedures. Most registration algorithms rely on the computation of complex, frequently non-differentiable similarity metrics to deal with the appearance discrepancy of anatomical structures between imaging modalities. Recent Machine Learning based approaches are limited to specific anatomy-modality combinations and do not generalize to new settings. We propose a generic framework for creating expressive cross-modal descriptors that enable fast deformable global registration. We achieve this by approximating existing metrics with a dot-product in the feature space of a small convolutional neural network (CNN) which is inherently differentiable can be trained without registered data. Our method is several orders of magnitude faster than local patch-based metrics and can be directly applied in clinical settings by replacing the similarity measure with the proposed one. Experiments on three differe",
    "path": "papers/23/07/2307.09931.json",
    "total_tokens": 910,
    "translated_title": "DISA: 可微分相似性逼近用于通用多模态配准",
    "translated_abstract": "多模态图像配准是许多图像引导过程中具有挑战性但又必不可少的一步。大多数配准算法依赖于计算复杂、频繁非可微的相似性度量，以应对影像模态之间解剖结构外观差异的问题。最近的基于机器学习的方法仅适用于特定的解剖学-模态组合，并不能推广到新的环境。本文提出了一个通用框架，用于创建具有表达力的跨模态描述符，从而实现快速的可变形全局配准。我们通过在一个小型卷积神经网络（CNN）的特征空间中用点积逼近现有的度量，实现了可微分训练，同时无需配准数据。我们的方法比基于局部块的度量快几个数量级，并可以直接在临床环境中使用，只需将相似性度量替换为我们提出的度量即可。",
    "tldr": "本文提出了一个通用框架，用于创建具有表达力的跨模态描述符，通过在卷积神经网络的特征空间中用点积逼近现有的度量，实现了快速的可变形全局配准。我们的方法可在临床环境中直接使用，仅需替换相似性度量。",
    "en_tdlr": "This paper presents a generic framework for creating expressive cross-modal descriptors, achieving fast deformable global registration by approximating existing metrics with a dot-product in the feature space of a convolutional neural network. This method can be directly applied in clinical settings by replacing the similarity measure."
}