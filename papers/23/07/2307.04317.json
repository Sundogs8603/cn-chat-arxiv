{
    "title": "Text Descriptions are Compressive and Invariant Representations for Visual Learning. (arXiv:2307.04317v2 [cs.CV] UPDATED)",
    "abstract": "Modern image classification is based upon directly predicting classes via large discriminative networks, which do not directly contain information about the intuitive visual features that may constitute a classification decision. Recently, work in vision-language models (VLM) such as CLIP has provided ways to specify natural language descriptions of image classes, but typically focuses on providing single descriptions for each class. In this work, we demonstrate that an alternative approach, in line with humans' understanding of multiple visual features per class, can also provide compelling performance in the robust few-shot learning setting. In particular, we introduce a novel method, \\textit{SLR-AVD (Sparse Logistic Regression using Augmented Visual Descriptors)}. This method first automatically generates multiple visual descriptions of each class via a large language model (LLM), then uses a VLM to translate these descriptions to a set of visual feature embeddings of each image, an",
    "link": "http://arxiv.org/abs/2307.04317",
    "context": "Title: Text Descriptions are Compressive and Invariant Representations for Visual Learning. (arXiv:2307.04317v2 [cs.CV] UPDATED)\nAbstract: Modern image classification is based upon directly predicting classes via large discriminative networks, which do not directly contain information about the intuitive visual features that may constitute a classification decision. Recently, work in vision-language models (VLM) such as CLIP has provided ways to specify natural language descriptions of image classes, but typically focuses on providing single descriptions for each class. In this work, we demonstrate that an alternative approach, in line with humans' understanding of multiple visual features per class, can also provide compelling performance in the robust few-shot learning setting. In particular, we introduce a novel method, \\textit{SLR-AVD (Sparse Logistic Regression using Augmented Visual Descriptors)}. This method first automatically generates multiple visual descriptions of each class via a large language model (LLM), then uses a VLM to translate these descriptions to a set of visual feature embeddings of each image, an",
    "path": "papers/23/07/2307.04317.json",
    "total_tokens": 845,
    "translated_title": "文本描述是视觉学习中压缩和不变表示的新方法",
    "translated_abstract": "现代图像分类是基于通过大型判别网络直接预测类别，但这些网络并不直接包含构成分类决策的直观视觉特征的信息。最近，视觉语言模型（VLM）如CLIP的工作提供了指定图像类别的自然语言描述的方式，但通常集中在为每个类别提供单一描述。在这项工作中，我们证明了一种与人类理解每个类别的多个视觉特征相一致的替代方法，在强大的少样本学习环境下也能提供令人信服的性能。具体而言，我们引入了一种新的方法，即“SLR-AVD（使用增强视觉描述的稀疏逻辑回归）”。该方法首先通过一个大型语言模型（LLM）自动生成每个类别的多个视觉描述，然后使用一个VLM将这些描述翻译成每个图像的一组视觉特征嵌入。",
    "tldr": "这项研究提出了一种新的方法，通过生成多个视觉特征描述并将其转化为视觉特征嵌入，实现了在少样本学习环境中的优异性能表现。"
}