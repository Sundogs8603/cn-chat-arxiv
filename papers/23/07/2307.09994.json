{
    "title": "Impact of Disentanglement on Pruning Neural Networks. (arXiv:2307.09994v1 [cs.LG])",
    "abstract": "Deploying deep learning neural networks on edge devices, to accomplish task specific objectives in the real-world, requires a reduction in their memory footprint, power consumption, and latency. This can be realized via efficient model compression. Disentangled latent representations produced by variational autoencoder (VAE) networks are a promising approach for achieving model compression because they mainly retain task-specific information, discarding useless information for the task at hand. We make use of the Beta-VAE framework combined with a standard criterion for pruning to investigate the impact of forcing the network to learn disentangled representations on the pruning process for the task of classification. In particular, we perform experiments on MNIST and CIFAR10 datasets, examine disentanglement challenges, and propose a path forward for future works.",
    "link": "http://arxiv.org/abs/2307.09994",
    "context": "Title: Impact of Disentanglement on Pruning Neural Networks. (arXiv:2307.09994v1 [cs.LG])\nAbstract: Deploying deep learning neural networks on edge devices, to accomplish task specific objectives in the real-world, requires a reduction in their memory footprint, power consumption, and latency. This can be realized via efficient model compression. Disentangled latent representations produced by variational autoencoder (VAE) networks are a promising approach for achieving model compression because they mainly retain task-specific information, discarding useless information for the task at hand. We make use of the Beta-VAE framework combined with a standard criterion for pruning to investigate the impact of forcing the network to learn disentangled representations on the pruning process for the task of classification. In particular, we perform experiments on MNIST and CIFAR10 datasets, examine disentanglement challenges, and propose a path forward for future works.",
    "path": "papers/23/07/2307.09994.json",
    "total_tokens": 836,
    "translated_title": "剪枝神经网络对剪枝结果的影响",
    "translated_abstract": "在边缘设备上部署深度学习神经网络以在真实世界中实现特定任务，需要减小其存储占用、功耗和延迟。通过高效的模型压缩可以实现这一目标。变分自编码器（VAE）网络产生的解缠缠绕的潜在表示是实现模型压缩的一种有前途的方法，因为它们主要保留了与任务相关的信息，丢弃了对该任务无用的信息。我们使用Beta-VAE框架结合标准剪枝准则，研究了迫使网络学习解缠缠绕表示对分类任务的剪枝过程的影响。具体而言，我们在MNIST和CIFAR10数据集上进行实验，研究了解缠缠绕的挑战，并提出了未来研究的路径。",
    "tldr": "本研究通过使用Beta-VAE框架来迫使网络学习解缠缠绕表示，并研究了其对剪枝神经网络的影响。实验结果表明，在分类任务中，解缠缠绕表示对剪枝过程具有重要作用。",
    "en_tdlr": "This study investigates the impact of forcing neural networks to learn disentangled representations on the pruning process, using the Beta-VAE framework. The results demonstrate that disentangled representations play a crucial role in the pruning of neural networks for classification tasks."
}