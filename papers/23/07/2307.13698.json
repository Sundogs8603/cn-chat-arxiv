{
    "title": "Exploring the Lottery Ticket Hypothesis with Explainability Methods: Insights into Sparse Network Performance. (arXiv:2307.13698v1 [cs.CV])",
    "abstract": "Discovering a high-performing sparse network within a massive neural network is advantageous for deploying them on devices with limited storage, such as mobile phones. Additionally, model explainability is essential to fostering trust in AI. The Lottery Ticket Hypothesis (LTH) finds a network within a deep network with comparable or superior performance to the original model. However, limited study has been conducted on the success or failure of LTH in terms of explainability. In this work, we examine why the performance of the pruned networks gradually increases or decreases. Using Grad-CAM and Post-hoc concept bottleneck models (PCBMs), respectively, we investigate the explainability of pruned networks in terms of pixels and high-level concepts. We perform extensive experiments across vision and medical imaging datasets. As more weights are pruned, the performance of the network degrades. The discovered concepts and pixels from the pruned networks are inconsistent with the original n",
    "link": "http://arxiv.org/abs/2307.13698",
    "context": "Title: Exploring the Lottery Ticket Hypothesis with Explainability Methods: Insights into Sparse Network Performance. (arXiv:2307.13698v1 [cs.CV])\nAbstract: Discovering a high-performing sparse network within a massive neural network is advantageous for deploying them on devices with limited storage, such as mobile phones. Additionally, model explainability is essential to fostering trust in AI. The Lottery Ticket Hypothesis (LTH) finds a network within a deep network with comparable or superior performance to the original model. However, limited study has been conducted on the success or failure of LTH in terms of explainability. In this work, we examine why the performance of the pruned networks gradually increases or decreases. Using Grad-CAM and Post-hoc concept bottleneck models (PCBMs), respectively, we investigate the explainability of pruned networks in terms of pixels and high-level concepts. We perform extensive experiments across vision and medical imaging datasets. As more weights are pruned, the performance of the network degrades. The discovered concepts and pixels from the pruned networks are inconsistent with the original n",
    "path": "papers/23/07/2307.13698.json",
    "total_tokens": 907,
    "translated_title": "使用可解释方法探索彩票票据假说：对稀疏网络性能的洞察",
    "translated_abstract": "在具有有限存储能力的设备上部署高性能的稀疏网络对于如手机等设备非常有利。此外，模型的可解释性对于培养对人工智能的信任至关重要。彩票票据假说（LTH）是在深度网络中找到一个与原模型相当或更优的网络。然而，鲜有研究探究LTH在可解释性方面的成败。本研究探究了修剪的网络性能逐渐提高或降低的原因。我们分别使用Grad-CAM和后期概念瓶颈模型（PCBM）来考察修剪网络在像素和高级概念方面的可解释性。我们在视觉和医学图像数据集上进行了大量实验。随着权重修剪的增多，网络性能会下降。从修剪的网络中发现的概念和像素与原始网络的不一致。",
    "tldr": "本研究通过使用可解释性方法，探究了彩票票据假说在稀疏网络性能方面的洞察，发现修剪的网络性能会降低，并且修剪后的网络产生的概念和像素与原始网络存在不一致性。",
    "en_tdlr": "This work explores the insights into sparse network performance based on the Lottery Ticket Hypothesis (LTH) using explainability methods, finding that the performance of pruned networks decreases and the discovered concepts and pixels are inconsistent with the original network."
}