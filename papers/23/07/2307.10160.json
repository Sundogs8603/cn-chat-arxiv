{
    "title": "Robust Driving Policy Learning with Guided Meta Reinforcement Learning. (arXiv:2307.10160v1 [cs.RO])",
    "abstract": "Although deep reinforcement learning (DRL) has shown promising results for autonomous navigation in interactive traffic scenarios, existing work typically adopts a fixed behavior policy to control social vehicles in the training environment. This may cause the learned driving policy to overfit the environment, making it difficult to interact well with vehicles with different, unseen behaviors. In this work, we introduce an efficient method to train diverse driving policies for social vehicles as a single meta-policy. By randomizing the interaction-based reward functions of social vehicles, we can generate diverse objectives and efficiently train the meta-policy through guiding policies that achieve specific objectives. We further propose a training strategy to enhance the robustness of the ego vehicle's driving policy using the environment where social vehicles are controlled by the learned meta-policy. Our method successfully learns an ego driving policy that generalizes well to unsee",
    "link": "http://arxiv.org/abs/2307.10160",
    "context": "Title: Robust Driving Policy Learning with Guided Meta Reinforcement Learning. (arXiv:2307.10160v1 [cs.RO])\nAbstract: Although deep reinforcement learning (DRL) has shown promising results for autonomous navigation in interactive traffic scenarios, existing work typically adopts a fixed behavior policy to control social vehicles in the training environment. This may cause the learned driving policy to overfit the environment, making it difficult to interact well with vehicles with different, unseen behaviors. In this work, we introduce an efficient method to train diverse driving policies for social vehicles as a single meta-policy. By randomizing the interaction-based reward functions of social vehicles, we can generate diverse objectives and efficiently train the meta-policy through guiding policies that achieve specific objectives. We further propose a training strategy to enhance the robustness of the ego vehicle's driving policy using the environment where social vehicles are controlled by the learned meta-policy. Our method successfully learns an ego driving policy that generalizes well to unsee",
    "path": "papers/23/07/2307.10160.json",
    "total_tokens": 922,
    "translated_title": "通过引导元元强化学习实现鲁棒的驾驶策略学习",
    "translated_abstract": "尽管深度强化学习(DRL)在交互式交通场景中的自主导航方面取得了可喜的成果，但现有研究通常采用固定的行为策略来控制训练环境中的社交车辆。这可能导致学习到的驾驶策略过拟合环境，使其难以与具有不同、未见过行为的车辆良好交互。在这项工作中，我们引入了一种有效的方法，将多样的驾驶策略作为一个单一的元元策略进行训练。通过随机化社交车辆的基于交互的奖励函数，我们可以生成多样化的目标，并通过实现特定目标的引导策略有效地训练元元策略。我们进一步提出了一种训练策略，使用社交车辆由学习到的元元策略控制的环境，来增强自主车辆的驾驶策略的鲁棒性。我们的方法成功地学习了一种能够很好地适应未见过的情况的自主驾驶策略。",
    "tldr": "本文提出了一种通过引导元元策略学习方法来实现社交车辆多样驾驶策略的有效方法，并使用训练策略增强自主驾驶策略的鲁棒性。",
    "en_tdlr": "This paper introduces an efficient method of training diverse driving policies for social vehicles by guided meta-policy learning, and enhances the robustness of ego vehicle's driving policy using a training strategy."
}