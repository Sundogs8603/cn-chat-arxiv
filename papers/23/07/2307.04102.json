{
    "title": "A generative flow for conditional sampling via optimal transport. (arXiv:2307.04102v1 [stat.ML])",
    "abstract": "Sampling conditional distributions is a fundamental task for Bayesian inference and density estimation. Generative models, such as normalizing flows and generative adversarial networks, characterize conditional distributions by learning a transport map that pushes forward a simple reference (e.g., a standard Gaussian) to a target distribution. While these approaches successfully describe many non-Gaussian problems, their performance is often limited by parametric bias and the reliability of gradient-based (adversarial) optimizers to learn these transformations. This work proposes a non-parametric generative model that iteratively maps reference samples to the target. The model uses block-triangular transport maps, whose components are shown to characterize conditionals of the target distribution. These maps arise from solving an optimal transport problem with a weighted $L^2$ cost function, thereby extending the data-driven approach in [Trigila and Tabak, 2016] for conditional sampling",
    "link": "http://arxiv.org/abs/2307.04102",
    "context": "Title: A generative flow for conditional sampling via optimal transport. (arXiv:2307.04102v1 [stat.ML])\nAbstract: Sampling conditional distributions is a fundamental task for Bayesian inference and density estimation. Generative models, such as normalizing flows and generative adversarial networks, characterize conditional distributions by learning a transport map that pushes forward a simple reference (e.g., a standard Gaussian) to a target distribution. While these approaches successfully describe many non-Gaussian problems, their performance is often limited by parametric bias and the reliability of gradient-based (adversarial) optimizers to learn these transformations. This work proposes a non-parametric generative model that iteratively maps reference samples to the target. The model uses block-triangular transport maps, whose components are shown to characterize conditionals of the target distribution. These maps arise from solving an optimal transport problem with a weighted $L^2$ cost function, thereby extending the data-driven approach in [Trigila and Tabak, 2016] for conditional sampling",
    "path": "papers/23/07/2307.04102.json",
    "total_tokens": 890,
    "translated_title": "一种通过最优输运进行条件采样的生成流",
    "translated_abstract": "条件分布的采样是贝叶斯推断和密度估计的基本任务。生成模型，如归一化流和生成对抗网络，通过学习将简单参考模型（如标准高斯分布）推向目标分布的输运映射，来描述条件分布。虽然这些方法成功地描述了许多非高斯问题，但它们的性能通常受到参数偏差和基于梯度的（对抗性）优化器学习这些转换的可靠性的限制。本文提出了一种非参数生成模型，通过迭代地将参考样本映射到目标样本来描述条件分布。该模型使用块三角输运映射，其组件被证明可以表征目标分布的条件分布。这些映射是通过解决带权 $L^2$ 损失函数的最优输运问题得到的，从而扩展了[Trigila and Tabak, 2016]中的数据驱动方法用于条件采样。",
    "tldr": "本论文提出了一种通过解决最优输运问题来描述条件分布的非参数生成模型，该模型使用块三角输运映射将参考样本迭代映射到目标样本，从而克服了参数偏差和基于梯度的优化器的限制。",
    "en_tdlr": "This paper proposes a non-parametric generative model that describes conditional distributions by solving an optimal transport problem, using block-triangular transport maps to iteratively map reference samples to target samples, overcoming limitations of parametric bias and gradient-based optimizers."
}