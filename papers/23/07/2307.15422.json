{
    "title": "Is One Epoch All You Need For Multi-Fidelity Hyperparameter Optimization?. (arXiv:2307.15422v1 [cs.LG])",
    "abstract": "Hyperparameter optimization (HPO) is crucial for fine-tuning machine learning models but can be computationally expensive. To reduce costs, Multi-fidelity HPO (MF-HPO) leverages intermediate accuracy levels in the learning process and discards low-performing models early on. We compared various representative MF-HPO methods against a simple baseline on classical benchmark data. The baseline involved discarding all models except the Top-K after training for only one epoch, followed by further training to select the best model. Surprisingly, this baseline achieved similar results to its counterparts, while requiring an order of magnitude less computation. Upon analyzing the learning curves of the benchmark data, we observed a few dominant learning curves, which explained the success of our baseline. This suggests that researchers should (1) always use the suggested baseline in benchmarks and (2) broaden the diversity of MF-HPO benchmarks to include more complex cases.",
    "link": "http://arxiv.org/abs/2307.15422",
    "context": "Title: Is One Epoch All You Need For Multi-Fidelity Hyperparameter Optimization?. (arXiv:2307.15422v1 [cs.LG])\nAbstract: Hyperparameter optimization (HPO) is crucial for fine-tuning machine learning models but can be computationally expensive. To reduce costs, Multi-fidelity HPO (MF-HPO) leverages intermediate accuracy levels in the learning process and discards low-performing models early on. We compared various representative MF-HPO methods against a simple baseline on classical benchmark data. The baseline involved discarding all models except the Top-K after training for only one epoch, followed by further training to select the best model. Surprisingly, this baseline achieved similar results to its counterparts, while requiring an order of magnitude less computation. Upon analyzing the learning curves of the benchmark data, we observed a few dominant learning curves, which explained the success of our baseline. This suggests that researchers should (1) always use the suggested baseline in benchmarks and (2) broaden the diversity of MF-HPO benchmarks to include more complex cases.",
    "path": "papers/23/07/2307.15422.json",
    "total_tokens": 909,
    "translated_title": "一个Epoch就足够进行多层次超参数优化吗？",
    "translated_abstract": "超参数优化（HPO）对于微调机器学习模型至关重要，但计算成本很高。为了降低成本，多层次超参数优化（MF-HPO）利用学习过程中的中间准确性级别，并在学习早期丢弃低性能模型。我们在经典基准数据上将各种代表性的MF-HPO方法与简单的基准线进行了比较。基准线是在训练了仅一个Epoch后丢弃除Top-K之外的所有模型，然后进一步训练以选择最佳模型。令人惊讶的是，这个基准线与其对应的方法取得了类似的结果，而计算成本减少了一个数量级。在分析基准数据的学习曲线时，我们观察到了几个占主导地位的学习曲线，这解释了我们基准线的成功。这表明研究人员应该（1）在基准测试中始终使用建议的基准线，并且（2）扩大MF-HPO基准测试的多样性，包括更复杂的情况。",
    "tldr": "传统的基准线在多层次超参数优化中取得了与其他方法类似的结果，并大幅减少计算成本。研究人员应该使用该基准线并扩大MF-HPO基准测试的多样性。",
    "en_tdlr": "The simple baseline achieved similar results to other methods in multi-fidelity hyperparameter optimization while significantly reducing computation costs. Researchers should use this baseline and broaden the diversity of MF-HPO benchmarks."
}