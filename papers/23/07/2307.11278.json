{
    "title": "Generator-Retriever-Generator: A Novel Approach to Open-domain Question Answering. (arXiv:2307.11278v1 [cs.CL])",
    "abstract": "Open-domain question answering (QA) tasks usually require the retrieval of relevant information from a large corpus to generate accurate answers. We propose a novel approach called Generator-Retriever-Generator (GRG) that combines document retrieval techniques with a large language model (LLM), by first prompting the model to generate contextual documents based on a given question. In parallel, a dual-encoder network retrieves documents that are relevant to the question from an external corpus. The generated and retrieved documents are then passed to the second LLM, which generates the final answer. By combining document retrieval and LLM generation, our approach addresses the challenges of open-domain QA, such as generating informative and contextually relevant answers. GRG outperforms the state-of-the-art generate-then-read and retrieve-then-read pipelines (GENREAD and RFiD) improving their performance at least by +5.2, +4.2, and +1.6 on TriviaQA, NQ, and WebQ datasets, respectively.",
    "link": "http://arxiv.org/abs/2307.11278",
    "context": "Title: Generator-Retriever-Generator: A Novel Approach to Open-domain Question Answering. (arXiv:2307.11278v1 [cs.CL])\nAbstract: Open-domain question answering (QA) tasks usually require the retrieval of relevant information from a large corpus to generate accurate answers. We propose a novel approach called Generator-Retriever-Generator (GRG) that combines document retrieval techniques with a large language model (LLM), by first prompting the model to generate contextual documents based on a given question. In parallel, a dual-encoder network retrieves documents that are relevant to the question from an external corpus. The generated and retrieved documents are then passed to the second LLM, which generates the final answer. By combining document retrieval and LLM generation, our approach addresses the challenges of open-domain QA, such as generating informative and contextually relevant answers. GRG outperforms the state-of-the-art generate-then-read and retrieve-then-read pipelines (GENREAD and RFiD) improving their performance at least by +5.2, +4.2, and +1.6 on TriviaQA, NQ, and WebQ datasets, respectively.",
    "path": "papers/23/07/2307.11278.json",
    "total_tokens": 878,
    "translated_title": "生成器-检索器-生成器：开放域问答的新方法",
    "translated_abstract": "开放域问答任务通常需要从大型语料库中检索相关信息以生成准确的答案。我们提出了一种称为生成器-检索器-生成器（GRG）的新方法，将文档检索技术与大型语言模型（LLM）相结合，首先通过给定问题提示模型生成上下文文档。同时，双编码器网络从外部语料库中检索与问题相关的文档。生成和检索的文档然后传递给第二个LLM，生成最终答案。通过结合文档检索和LLM生成，我们的方法解决了开放域问答的挑战，例如生成信息丰富和上下文相关的答案。GRG在TriviaQA、NQ和WebQ数据集上表现优于现有的生成-读取和检索-读取流水线（GENREAD和RFiD），分别至少提高了+5.2、+4.2和+1.6的性能。",
    "tldr": "生成器-检索器-生成器（GRG）是一种新方法，将文档检索技术与大型语言模型相结合，以生成开放域问答的准确和信息丰富的答案。",
    "en_tdlr": "Generator-Retriever-Generator (GRG) is a novel approach that combines document retrieval techniques with a large language model to generate accurate and informative answers for open-domain question answering tasks. GRG outperforms existing generate-then-read and retrieve-then-read pipelines on various datasets."
}