{
    "title": "IxDRL: A Novel Explainable Deep Reinforcement Learning Toolkit based on Analyses of Interestingness. (arXiv:2307.08933v1 [cs.AI])",
    "abstract": "In recent years, advances in deep learning have resulted in a plethora of successes in the use of reinforcement learning (RL) to solve complex sequential decision tasks with high-dimensional inputs. However, existing systems lack the necessary mechanisms to provide humans with a holistic view of their competence, presenting an impediment to their adoption, particularly in critical applications where the decisions an agent makes can have significant consequences. Yet, existing RL-based systems are essentially competency-unaware in that they lack the necessary interpretation mechanisms to allow human operators to have an insightful, holistic view of their competency. Towards more explainable Deep RL (xDRL), we propose a new framework based on analyses of interestingness. Our tool provides various measures of RL agent competence stemming from interestingness analysis and is applicable to a wide range of RL algorithms, natively supporting the popular RLLib toolkit. We showcase the use of o",
    "link": "http://arxiv.org/abs/2307.08933",
    "context": "Title: IxDRL: A Novel Explainable Deep Reinforcement Learning Toolkit based on Analyses of Interestingness. (arXiv:2307.08933v1 [cs.AI])\nAbstract: In recent years, advances in deep learning have resulted in a plethora of successes in the use of reinforcement learning (RL) to solve complex sequential decision tasks with high-dimensional inputs. However, existing systems lack the necessary mechanisms to provide humans with a holistic view of their competence, presenting an impediment to their adoption, particularly in critical applications where the decisions an agent makes can have significant consequences. Yet, existing RL-based systems are essentially competency-unaware in that they lack the necessary interpretation mechanisms to allow human operators to have an insightful, holistic view of their competency. Towards more explainable Deep RL (xDRL), we propose a new framework based on analyses of interestingness. Our tool provides various measures of RL agent competence stemming from interestingness analysis and is applicable to a wide range of RL algorithms, natively supporting the popular RLLib toolkit. We showcase the use of o",
    "path": "papers/23/07/2307.08933.json",
    "total_tokens": 853,
    "translated_title": "IxDRL:一种基于有趣分析的新型可解释深度强化学习工具包",
    "translated_abstract": "近年来，深度学习的进展在使用强化学习（RL）解决具有高维输入的复杂顺序决策任务方面取得了众多成功。然而，现有系统缺乏必要的机制来提供人类对其能力的整体视图，这在关键应用中成为采用RL的障碍，因为代理程序所做的决策可能具有重大后果。然而，现有的RL系统本质上不具备能力感知，因为它们缺乏必要的解释机制，使人类操作员能够对其能力有深入、整体的了解。为了实现更可解释的深度RL（xDRL），我们提出了一个基于有趣分析的新框架。我们的工具基于有趣分析提供多种RL代理的能力度量，适用于各种RL算法，并原生支持流行的RLLib工具包。我们展示了该工具包在...（原文截断）",
    "tldr": "IxDRL是一种基于有趣分析的新型可解释深度强化学习工具包，具备能力感知机制，能够提供人类操作员对RL代理能力的整体视图。",
    "en_tdlr": "IxDRL is a novel explainable deep reinforcement learning toolkit based on analyses of interestingness, which provides a holistic view of RL agent competence."
}