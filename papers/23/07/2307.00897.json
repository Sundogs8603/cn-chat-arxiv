{
    "title": "Fixing confirmation bias in feature attribution methods via semantic match",
    "abstract": "arXiv:2307.00897v2 Announce Type: replace-cross  Abstract: Feature attribution methods have become a staple method to disentangle the complex behavior of black box models. Despite their success, some scholars have argued that such methods suffer from a serious flaw: they do not allow a reliable interpretation in terms of human concepts. Simply put, visualizing an array of feature contributions is not enough for humans to conclude something about a model's internal representations, and confirmation bias can trick users into false beliefs about model behavior. We argue that a structured approach is required to test whether our hypotheses on the model are confirmed by the feature attributions. This is what we call the \"semantic match\" between human concepts and (sub-symbolic) explanations. Building on the conceptual framework put forward in Cin\\`a et al. [2023], we propose a structured approach to evaluate semantic match in practice. We showcase the procedure in a suite of experiments spa",
    "link": "https://arxiv.org/abs/2307.00897",
    "context": "Title: Fixing confirmation bias in feature attribution methods via semantic match\nAbstract: arXiv:2307.00897v2 Announce Type: replace-cross  Abstract: Feature attribution methods have become a staple method to disentangle the complex behavior of black box models. Despite their success, some scholars have argued that such methods suffer from a serious flaw: they do not allow a reliable interpretation in terms of human concepts. Simply put, visualizing an array of feature contributions is not enough for humans to conclude something about a model's internal representations, and confirmation bias can trick users into false beliefs about model behavior. We argue that a structured approach is required to test whether our hypotheses on the model are confirmed by the feature attributions. This is what we call the \"semantic match\" between human concepts and (sub-symbolic) explanations. Building on the conceptual framework put forward in Cin\\`a et al. [2023], we propose a structured approach to evaluate semantic match in practice. We showcase the procedure in a suite of experiments spa",
    "path": "papers/23/07/2307.00897.json",
    "total_tokens": 848,
    "translated_title": "通过语义匹配修复特征归因方法中的确认偏见",
    "translated_abstract": "特征归因方法已经成为解析黑盒模型复杂行为的重要方法。尽管取得了成功，一些学者指出这类方法存在严重缺陷：它们不能可靠地用人类概念进行解释。简而言之，仅仅可视化一系列特征贡献对于人类来说无法得出关于模型内部表示的结论，而确认偏见可能会让用户产生关于模型行为的错误信念。我们认为需要一种结构化方法来验证我们对模型的假设是否得到了特征归因的确认。这就是我们所说的人类概念与（亚符号）解释之间的“语义匹配”。在 Cin\\`a等人[2023]提出的概念框架基础上，我们提出了一种结构化方法来在实践中评估语义匹配。我们在一系列实验中展示了这一过程。",
    "tldr": "提出了通过语义匹配修复特征归因方法中的确认偏见问题，引入了人类概念与（亚符号）解释之间的概念框架，并提出了一种结构化方法来评估语义匹配。",
    "en_tdlr": "Introduced a structured approach to address confirmation bias in feature attribution methods via semantic match, proposing a framework for aligning human concepts with (sub-symbolic) explanations and evaluating semantic match in practice."
}