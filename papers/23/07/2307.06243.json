{
    "title": "Reconstructing Spatiotemporal Data with C-VAEs. (arXiv:2307.06243v1 [cs.DB])",
    "abstract": "The continuous representation of spatiotemporal data commonly relies on using abstract data types, such as \\textit{moving regions}, to represent entities whose shape and position continuously change over time. Creating this representation from discrete snapshots of real-world entities requires using interpolation methods to compute in-between data representations and estimate the position and shape of the object of interest at arbitrary temporal points. Existing region interpolation methods often fail to generate smooth and realistic representations of a region's evolution. However, recent advancements in deep learning techniques have revealed the potential of deep models trained on discrete observations to capture spatiotemporal dependencies through implicit feature learning.  In this work, we explore the capabilities of Conditional Variational Autoencoder (C-VAE) models to generate smooth and realistic representations of the spatiotemporal evolution of moving regions. We evaluate our",
    "link": "http://arxiv.org/abs/2307.06243",
    "context": "Title: Reconstructing Spatiotemporal Data with C-VAEs. (arXiv:2307.06243v1 [cs.DB])\nAbstract: The continuous representation of spatiotemporal data commonly relies on using abstract data types, such as \\textit{moving regions}, to represent entities whose shape and position continuously change over time. Creating this representation from discrete snapshots of real-world entities requires using interpolation methods to compute in-between data representations and estimate the position and shape of the object of interest at arbitrary temporal points. Existing region interpolation methods often fail to generate smooth and realistic representations of a region's evolution. However, recent advancements in deep learning techniques have revealed the potential of deep models trained on discrete observations to capture spatiotemporal dependencies through implicit feature learning.  In this work, we explore the capabilities of Conditional Variational Autoencoder (C-VAE) models to generate smooth and realistic representations of the spatiotemporal evolution of moving regions. We evaluate our",
    "path": "papers/23/07/2307.06243.json",
    "total_tokens": 791,
    "translated_title": "用C-VAEs重建时空数据",
    "translated_abstract": "时空数据的连续表示通常依赖于使用抽象数据类型，例如移动区域，来表示形状和位置在时间上连续变化的实体。从离散的现实世界实体的快照创建这种表示需要使用插值方法来计算中间数据表示，并估计感兴趣对象在任意时间点的位置和形状。现有的区域插值方法常常无法生成平滑和逼真的区域演变表示。然而，深度学习技术的最新进展揭示了基于离散观测训练的深度模型通过隐式特征学习可以捕捉时空依赖关系的潜力。在这项工作中，我们探索了条件变分自编码器（C-VAE）模型生成移动区域的时空演变平滑和逼真表示的能力。",
    "tldr": "本文通过使用C-VAE模型来生成平滑且逼真的时空演变表示，探索了深度学习技术在重建时空数据方面的潜力。",
    "en_tdlr": "This paper explores the potential of deep learning techniques in reconstructing spatiotemporal data by using C-VAE models to generate smooth and realistic representations of the data."
}