{
    "title": "Monotone deep Boltzmann machines. (arXiv:2307.04990v1 [cs.LG])",
    "abstract": "Deep Boltzmann machines (DBMs), one of the first ``deep'' learning methods ever studied, are multi-layered probabilistic models governed by a pairwise energy function that describes the likelihood of all variables/nodes in the network. In practice, DBMs are often constrained, i.e., via the \\emph{restricted} Boltzmann machine (RBM) architecture (which does not permit intra-layer connections), in order to allow for more efficient inference. In this work, we revisit the generic DBM approach, and ask the question: are there other possible restrictions to their design that would enable efficient (approximate) inference? In particular, we develop a new class of restricted model, the monotone DBM, which allows for arbitrary self-connection in each layer, but restricts the \\emph{weights} in a manner that guarantees the existence and global uniqueness of a mean-field fixed point. To do this, we leverage tools from the recently-proposed monotone Deep Equilibrium model and show that a particular ",
    "link": "http://arxiv.org/abs/2307.04990",
    "context": "Title: Monotone deep Boltzmann machines. (arXiv:2307.04990v1 [cs.LG])\nAbstract: Deep Boltzmann machines (DBMs), one of the first ``deep'' learning methods ever studied, are multi-layered probabilistic models governed by a pairwise energy function that describes the likelihood of all variables/nodes in the network. In practice, DBMs are often constrained, i.e., via the \\emph{restricted} Boltzmann machine (RBM) architecture (which does not permit intra-layer connections), in order to allow for more efficient inference. In this work, we revisit the generic DBM approach, and ask the question: are there other possible restrictions to their design that would enable efficient (approximate) inference? In particular, we develop a new class of restricted model, the monotone DBM, which allows for arbitrary self-connection in each layer, but restricts the \\emph{weights} in a manner that guarantees the existence and global uniqueness of a mean-field fixed point. To do this, we leverage tools from the recently-proposed monotone Deep Equilibrium model and show that a particular ",
    "path": "papers/23/07/2307.04990.json",
    "total_tokens": 885,
    "translated_title": "单调的深度Boltzmann机器",
    "translated_abstract": "深度Boltzmann机器(DBMs)是最早研究的\"深度\"学习方法之一，它是由一个描述网络中所有变量/节点的可能性的成对能量函数所控制的多层概率模型。在实际应用中，为了实现更高效的推理，DBMs通常会受到一些限制，例如通过\"限制性\" Boltzmann机器(RBM)架构（不允许层间连接）。在这项工作中，我们重新审视了通用的DBM方法，并提出了一个问题：是否存在其他可能的设计限制，以实现高效的（近似）推理？具体地，我们开发了一种新的限制模型，即单调DBM，它允许每一层具有任意的自连接，但通过一种方式限制了权重，以保证存在和全局唯一的均场不动点。为此，我们利用了最近提出的单调深度均衡模型的工具，并展示了一个特定的...",
    "tldr": "在这项工作中，我们提出了一种新的限制模型，即单调DBM，它允许每一层具有任意的自连接，但通过一种方式限制了权重，以保证存在和全局唯一的均场不动点。"
}