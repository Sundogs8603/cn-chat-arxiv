{
    "title": "Augmenters at SemEval-2023 Task 1: Enhancing CLIP in Handling Compositionality and Ambiguity for Zero-Shot Visual WSD through Prompt Augmentation and Text-To-Image Diffusion. (arXiv:2307.05564v1 [cs.CL])",
    "abstract": "This paper describes our zero-shot approaches for the Visual Word Sense Disambiguation (VWSD) Task in English. Our preliminary study shows that the simple approach of matching candidate images with the phrase using CLIP suffers from the many-to-many nature of image-text pairs. We find that the CLIP text encoder may have limited abilities in capturing the compositionality in natural language. Conversely, the descriptive focus of the phrase varies from instance to instance. We address these issues in our two systems, Augment-CLIP and Stable Diffusion Sampling (SD Sampling). Augment-CLIP augments the text prompt by generating sentences that contain the context phrase with the help of large language models (LLMs). We further explore CLIP models in other languages, as the an ambiguous word may be translated into an unambiguous one in the other language. SD Sampling uses text-to-image Stable Diffusion to generate multiple images from the given phrase, increasing the likelihood that a subset ",
    "link": "http://arxiv.org/abs/2307.05564",
    "context": "Title: Augmenters at SemEval-2023 Task 1: Enhancing CLIP in Handling Compositionality and Ambiguity for Zero-Shot Visual WSD through Prompt Augmentation and Text-To-Image Diffusion. (arXiv:2307.05564v1 [cs.CL])\nAbstract: This paper describes our zero-shot approaches for the Visual Word Sense Disambiguation (VWSD) Task in English. Our preliminary study shows that the simple approach of matching candidate images with the phrase using CLIP suffers from the many-to-many nature of image-text pairs. We find that the CLIP text encoder may have limited abilities in capturing the compositionality in natural language. Conversely, the descriptive focus of the phrase varies from instance to instance. We address these issues in our two systems, Augment-CLIP and Stable Diffusion Sampling (SD Sampling). Augment-CLIP augments the text prompt by generating sentences that contain the context phrase with the help of large language models (LLMs). We further explore CLIP models in other languages, as the an ambiguous word may be translated into an unambiguous one in the other language. SD Sampling uses text-to-image Stable Diffusion to generate multiple images from the given phrase, increasing the likelihood that a subset ",
    "path": "papers/23/07/2307.05564.json",
    "total_tokens": 1020,
    "translated_title": "SemEval-2023任务1的增强器: 通过提示增强和文本到图像扩散改进CLIP处理复合性和歧义性，以实现零样本视觉VWSD",
    "translated_abstract": "本文描述了我们针对英语视觉词义消歧（VWSD）任务的零样本方法。我们的初步研究表明，使用CLIP将候选图像与短语进行匹配的简单方法受到图像-文本对中多对多性质的影响。我们发现，CLIP文本编码器在捕捉自然语言的复合性方面能力有限。相反，短语的描述性焦点因实例而异。我们在两个系统中解决了这些问题，Augment-CLIP和Stable Diffusion Sampling（SD Sampling）。Augment-CLIP通过利用大型语言模型（LLMs）生成包含上下文短语的句子来增强文本提示。我们进一步探索了其他语言的CLIP模型，因为一个有歧义的词可能会在另一种语言中被翻译为一个无歧义的词。SD Sampling使用文本到图像的稳定扩散来从给定的短语生成多个图像，增加子集的可能性。",
    "tldr": "本文描述了增强CLIP在处理复合性和歧义性方面，在零样本视觉词义消歧任务中的应用。作者采用Augment-CLIP和Stable Diffusion Sampling（SD Sampling）两个系统来解决CLIP的局限性，通过生成包含上下文短语的句子和使用稳定扩散算法生成多个图像，提高了任务的表现。",
    "en_tdlr": "This paper presents enhanced CLIP techniques for handling compositionality and ambiguity in zero-shot visual word sense disambiguation. The authors propose two systems, Augment-CLIP and SD Sampling, to address the limitations of CLIP and improve performance through generating context-aware sentences and generating multiple images using stable diffusion."
}