{
    "title": "mPLUG-DocOwl: Modularized Multimodal Large Language Model for Document Understanding. (arXiv:2307.02499v1 [cs.CL])",
    "abstract": "Document understanding refers to automatically extract, analyze and comprehend information from various types of digital documents, such as a web page. Existing Multi-model Large Language Models (MLLMs), including mPLUG-Owl, have demonstrated promising zero-shot capabilities in shallow OCR-free text recognition, indicating their potential for OCR-free document understanding. Nevertheless, without in-domain training, these models tend to ignore fine-grained OCR features, such as sophisticated tables or large blocks of text, which are essential for OCR-free document understanding. In this paper, we propose mPLUG-DocOwl based on mPLUG-Owl for OCR-free document understanding. Specifically, we first construct a instruction tuning dataset featuring a wide range of visual-text understanding tasks. Then, we strengthen the OCR-free document understanding ability by jointly train the model on language-only, general vision-and-language, and document instruction tuning dataset with our unified ins",
    "link": "http://arxiv.org/abs/2307.02499",
    "context": "Title: mPLUG-DocOwl: Modularized Multimodal Large Language Model for Document Understanding. (arXiv:2307.02499v1 [cs.CL])\nAbstract: Document understanding refers to automatically extract, analyze and comprehend information from various types of digital documents, such as a web page. Existing Multi-model Large Language Models (MLLMs), including mPLUG-Owl, have demonstrated promising zero-shot capabilities in shallow OCR-free text recognition, indicating their potential for OCR-free document understanding. Nevertheless, without in-domain training, these models tend to ignore fine-grained OCR features, such as sophisticated tables or large blocks of text, which are essential for OCR-free document understanding. In this paper, we propose mPLUG-DocOwl based on mPLUG-Owl for OCR-free document understanding. Specifically, we first construct a instruction tuning dataset featuring a wide range of visual-text understanding tasks. Then, we strengthen the OCR-free document understanding ability by jointly train the model on language-only, general vision-and-language, and document instruction tuning dataset with our unified ins",
    "path": "papers/23/07/2307.02499.json",
    "total_tokens": 908,
    "translated_title": "mPLUG-DocOwl: 模块化多模态大型语言模型用于文档理解",
    "translated_abstract": "文档理解是指从各种类型的数字文档中自动提取、分析和理解信息，例如网页。现有的多模态大型语言模型（MLLMs），包括mPLUG-Owl，已经展示了有希望的零-shot能力，可以实现无OCR的文本识别，表明它们在无OCR文档理解方面具有潜力。然而，这些模型在没有领域内训练的情况下，往往忽视OCR细粒度特征，如复杂的表格或大块文本，这些特征对于无OCR文档理解是必要的。在本文中，我们基于mPLUG-Owl提出了mPLUG-DocOwl，用于无OCR文档理解。具体而言，我们首先构建了一个包含多种视觉-文本理解任务的指令调优数据集。然后，我们通过针对语言、通用视觉-语言和文档指令调优数据集进行联合训练来增强无OCR文档理解能力。",
    "tldr": "mPLUG-DocOwl是一种模块化多模态大型语言模型，用于无OCR文档理解。它通过联合训练语言、通用视觉-语言和文档指令调优数据集，提升了无OCR文档理解能力。",
    "en_tdlr": "mPLUG-DocOwl is a modularized multimodal large language model for OCR-free document understanding. It enhances the OCR-free document understanding ability by jointly training on language-only, general vision-and-language, and document instruction tuning dataset."
}