{
    "title": "Training Latency Minimization for Model-Splitting Allowed Federated Edge Learning. (arXiv:2307.11532v1 [cs.LG])",
    "abstract": "To alleviate the shortage of computing power faced by clients in training deep neural networks (DNNs) using federated learning (FL), we leverage the edge computing and split learning to propose a model-splitting allowed FL (SFL) framework, with the aim to minimize the training latency without loss of test accuracy. Under the synchronized global update setting, the latency to complete a round of global training is determined by the maximum latency for the clients to complete a local training session. Therefore, the training latency minimization problem (TLMP) is modelled as a minimizing-maximum problem. To solve this mixed integer nonlinear programming problem, we first propose a regression method to fit the quantitative-relationship between the cut-layer and other parameters of an AI-model, and thus, transform the TLMP into a continuous problem. Considering that the two subproblems involved in the TLMP, namely, the cut-layer selection problem for the clients and the computing resource ",
    "link": "http://arxiv.org/abs/2307.11532",
    "context": "Title: Training Latency Minimization for Model-Splitting Allowed Federated Edge Learning. (arXiv:2307.11532v1 [cs.LG])\nAbstract: To alleviate the shortage of computing power faced by clients in training deep neural networks (DNNs) using federated learning (FL), we leverage the edge computing and split learning to propose a model-splitting allowed FL (SFL) framework, with the aim to minimize the training latency without loss of test accuracy. Under the synchronized global update setting, the latency to complete a round of global training is determined by the maximum latency for the clients to complete a local training session. Therefore, the training latency minimization problem (TLMP) is modelled as a minimizing-maximum problem. To solve this mixed integer nonlinear programming problem, we first propose a regression method to fit the quantitative-relationship between the cut-layer and other parameters of an AI-model, and thus, transform the TLMP into a continuous problem. Considering that the two subproblems involved in the TLMP, namely, the cut-layer selection problem for the clients and the computing resource ",
    "path": "papers/23/07/2307.11532.json",
    "total_tokens": 864,
    "translated_title": "基于模型切分的允许边缘联合学习的训练延迟最小化",
    "translated_abstract": "为了缓解客户在使用联合学习训练深度神经网络时所面临的计算能力不足问题，我们利用边缘计算和模型切分提出了一个允许模型切分的联合学习框架（SFL），旨在在不损失测试准确性的情况下最小化训练延迟。在同步全局更新设置下，完成一轮全局训练的延迟取决于客户端完成本地训练会话的最大延迟。因此，训练延迟最小化问题（TLMP）被建模为一个最小化最大值的问题。为了解决这个混合整数非线性规划问题，我们首先提出了一个回归方法来拟合AI模型的切割层和其他参数之间的量化关系，从而将TLMP转化为一个连续问题。考虑到TLMP中涉及的两个子问题，即客户端的切割层选择问题和计算资源问题。",
    "tldr": "本文提出了一个允许模型切分的联合学习框架，旨在最小化训练延迟，同时不损失测试准确性。",
    "en_tdlr": "This paper proposes a model-splitting allowed federated learning framework to minimize training latency without loss of test accuracy."
}