{
    "title": "Autonomous Payload Thermal Control. (arXiv:2307.15438v1 [cs.LG])",
    "abstract": "In small satellites there is less room for heat control equipment, scientific instruments, and electronic components. Furthermore, the near proximity of the electronics makes power dissipation difficult, with the risk of not being able to control the temperature appropriately, reducing component lifetime and mission performance. To address this challenge, taking advantage of the advent of increasing intelligence on board satellites, a deep reinforcement learning based framework that uses Soft Actor-Critic algorithm is proposed for learning the thermal control policy onboard. The framework is evaluated both in a naive simulated environment and in a real space edge processing computer that will be shipped in the future IMAGIN-e mission and hosted in the ISS. The experiment results show that the proposed framework is able to learn to control the payload processing power to maintain the temperature under operational ranges, complementing traditional thermal control systems.",
    "link": "http://arxiv.org/abs/2307.15438",
    "context": "Title: Autonomous Payload Thermal Control. (arXiv:2307.15438v1 [cs.LG])\nAbstract: In small satellites there is less room for heat control equipment, scientific instruments, and electronic components. Furthermore, the near proximity of the electronics makes power dissipation difficult, with the risk of not being able to control the temperature appropriately, reducing component lifetime and mission performance. To address this challenge, taking advantage of the advent of increasing intelligence on board satellites, a deep reinforcement learning based framework that uses Soft Actor-Critic algorithm is proposed for learning the thermal control policy onboard. The framework is evaluated both in a naive simulated environment and in a real space edge processing computer that will be shipped in the future IMAGIN-e mission and hosted in the ISS. The experiment results show that the proposed framework is able to learn to control the payload processing power to maintain the temperature under operational ranges, complementing traditional thermal control systems.",
    "path": "papers/23/07/2307.15438.json",
    "total_tokens": 906,
    "translated_title": "自主载荷热控制",
    "translated_abstract": "在小型卫星中，热控制设备、科学仪器和电子部件的空间较小。此外，电子设备的近距离使得功耗散热困难，存在无法适当控制温度、降低部件寿命和任务性能的风险。为了应对这一挑战，利用卫星上逐渐增加的智能，提出了一种基于深度强化学习的框架，使用软演员-评论家算法来学习机载热控制策略。该框架在一个简单的模拟环境和未来将运往ISS并在IMAGIN-e任务中进行边缘计算的真实空间处理计算机中进行了评估。实验结果表明，所提出的框架能够学习控制载荷处理功率，以保持温度在操作范围内，补充传统热控制系统。",
    "tldr": "该论文提出了一种基于深度强化学习的框架，利用软演员-评论家算法在卫星上学习热控制策略，以解决小型卫星中热控制的挑战。该框架在模拟环境和实际空间处理计算机上进行了评估，并证明能够辅助传统热控制系统，保持载荷温度在可操作范围内。",
    "en_tdlr": "This paper proposes a deep reinforcement learning framework based on the Soft Actor-Critic algorithm for thermal control in small satellites. The framework is evaluated in both simulated and real space environments and shows the ability to complement traditional thermal control systems by maintaining payload temperatures within operational ranges."
}