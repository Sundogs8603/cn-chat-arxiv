{
    "title": "Stochastic Nested Compositional Bi-level Optimization for Robust Feature Learning. (arXiv:2307.05384v1 [math.OC])",
    "abstract": "We develop and analyze stochastic approximation algorithms for solving nested compositional bi-level optimization problems. These problems involve a nested composition of $T$ potentially non-convex smooth functions in the upper-level, and a smooth and strongly convex function in the lower-level. Our proposed algorithm does not rely on matrix inversions or mini-batches and can achieve an $\\epsilon$-stationary solution with an oracle complexity of approximately $\\tilde{O}_T(1/\\epsilon^{2})$, assuming the availability of stochastic first-order oracles for the individual functions in the composition and the lower-level, which are unbiased and have bounded moments. Here, $\\tilde{O}_T$ hides polylog factors and constants that depend on $T$. The key challenge we address in establishing this result relates to handling three distinct sources of bias in the stochastic gradients. The first source arises from the compositional nature of the upper-level, the second stems from the bi-level structure",
    "link": "http://arxiv.org/abs/2307.05384",
    "context": "Title: Stochastic Nested Compositional Bi-level Optimization for Robust Feature Learning. (arXiv:2307.05384v1 [math.OC])\nAbstract: We develop and analyze stochastic approximation algorithms for solving nested compositional bi-level optimization problems. These problems involve a nested composition of $T$ potentially non-convex smooth functions in the upper-level, and a smooth and strongly convex function in the lower-level. Our proposed algorithm does not rely on matrix inversions or mini-batches and can achieve an $\\epsilon$-stationary solution with an oracle complexity of approximately $\\tilde{O}_T(1/\\epsilon^{2})$, assuming the availability of stochastic first-order oracles for the individual functions in the composition and the lower-level, which are unbiased and have bounded moments. Here, $\\tilde{O}_T$ hides polylog factors and constants that depend on $T$. The key challenge we address in establishing this result relates to handling three distinct sources of bias in the stochastic gradients. The first source arises from the compositional nature of the upper-level, the second stems from the bi-level structure",
    "path": "papers/23/07/2307.05384.json",
    "total_tokens": 842,
    "translated_title": "随机嵌套构成的双层优化用于鲁棒特征学习",
    "translated_abstract": "我们开发并分析了用于解决嵌套构成双层优化问题的随机逼近算法。这些问题涉及到上层的$T$个潜在非凸平滑函数的嵌套构造，以及下层的平滑且强凸函数。我们的算法不依赖于矩阵求逆或小批量输入，并且可以以近似$\\tilde{O}_T(1/\\epsilon^{2})$的预算复杂度实现$\\epsilon$-稳定解，假设能够得到上层组成中的个体函数和下层函数的随机一阶诺埃尔，这些一阶诺埃尔是无偏且具有有界矩。这里，$\\tilde{O}_T$可以隐藏多项对数系数和常数，依赖于$T$。",
    "tldr": "本文提出了一种用于解决嵌套构成双层优化问题的随机逼近算法，可以实现鲁棒特征学习，并且不依赖于矩阵求逆或小批量输入。",
    "en_tdlr": "This paper proposes a stochastic approximation algorithm for solving nested compositional bi-level optimization problems, which achieves robust feature learning without relying on matrix inversions or mini-batches."
}