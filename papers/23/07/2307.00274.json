{
    "title": "Common Knowledge Learning for Generating Transferable Adversarial Examples. (arXiv:2307.00274v1 [cs.LG])",
    "abstract": "This paper focuses on an important type of black-box attacks, i.e., transfer-based adversarial attacks, where the adversary generates adversarial examples by a substitute (source) model and utilize them to attack an unseen target model, without knowing its information. Existing methods tend to give unsatisfactory adversarial transferability when the source and target models are from different types of DNN architectures (e.g. ResNet-18 and Swin Transformer). In this paper, we observe that the above phenomenon is induced by the output inconsistency problem. To alleviate this problem while effectively utilizing the existing DNN models, we propose a common knowledge learning (CKL) framework to learn better network weights to generate adversarial examples with better transferability, under fixed network architectures. Specifically, to reduce the model-specific features and obtain better output distributions, we construct a multi-teacher framework, where the knowledge is distilled from diffe",
    "link": "http://arxiv.org/abs/2307.00274",
    "context": "Title: Common Knowledge Learning for Generating Transferable Adversarial Examples. (arXiv:2307.00274v1 [cs.LG])\nAbstract: This paper focuses on an important type of black-box attacks, i.e., transfer-based adversarial attacks, where the adversary generates adversarial examples by a substitute (source) model and utilize them to attack an unseen target model, without knowing its information. Existing methods tend to give unsatisfactory adversarial transferability when the source and target models are from different types of DNN architectures (e.g. ResNet-18 and Swin Transformer). In this paper, we observe that the above phenomenon is induced by the output inconsistency problem. To alleviate this problem while effectively utilizing the existing DNN models, we propose a common knowledge learning (CKL) framework to learn better network weights to generate adversarial examples with better transferability, under fixed network architectures. Specifically, to reduce the model-specific features and obtain better output distributions, we construct a multi-teacher framework, where the knowledge is distilled from diffe",
    "path": "papers/23/07/2307.00274.json",
    "total_tokens": 919,
    "translated_title": "生成可迁移对抗样本的常识学习",
    "translated_abstract": "本文关注一种重要的黑盒攻击类型，即基于迁移的对抗攻击，在这种攻击中，对手通过一个替代（原始）模型生成对抗样本，并利用它们来攻击一个未知的目标模型，而不知道其信息。现有方法在源模型和目标模型来自不同类型的DNN架构（例如ResNet-18和Swin Transformer）时往往给出了不令人满意的对抗可迁移性。本文观察到上述现象是由输出不一致性问题引起的。为了在固定的网络架构下缓解这个问题并有效利用现有的DNN模型，我们提出了一种常识学习（CKL）框架，通过学习更好的网络权重生成具有更好可迁移性的对抗样本。具体来说，为了减少模型特定的特征并获得更好的输出分布，我们构建了一个多教师框架，从不同教师模型中提取知识。",
    "tldr": "本文提出了一种常识学习框架，通过学习更好的网络权重生成具有更好可迁移性的对抗样本，解决了输出不一致性问题。该框架通过构建多教师模型并提取知识，减少模型特定的特征，获得更好的输出分布。"
}