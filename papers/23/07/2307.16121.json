{
    "title": "Uncertainty-Encoded Multi-Modal Fusion for Robust Object Detection in Autonomous Driving. (arXiv:2307.16121v1 [cs.CV])",
    "abstract": "Multi-modal fusion has shown initial promising results for object detection of autonomous driving perception. However, many existing fusion schemes do not consider the quality of each fusion input and may suffer from adverse conditions on one or more sensors. While predictive uncertainty has been applied to characterize single-modal object detection performance at run time, incorporating uncertainties into the multi-modal fusion still lacks effective solutions due primarily to the uncertainty's cross-modal incomparability and distinct sensitivities to various adverse conditions. To fill this gap, this paper proposes Uncertainty-Encoded Mixture-of-Experts (UMoE) that explicitly incorporates single-modal uncertainties into LiDAR-camera fusion. UMoE uses individual expert network to process each sensor's detection result together with encoded uncertainty. Then, the expert networks' outputs are analyzed by a gating network to determine the fusion weights. The proposed UMoE module can be in",
    "link": "http://arxiv.org/abs/2307.16121",
    "context": "Title: Uncertainty-Encoded Multi-Modal Fusion for Robust Object Detection in Autonomous Driving. (arXiv:2307.16121v1 [cs.CV])\nAbstract: Multi-modal fusion has shown initial promising results for object detection of autonomous driving perception. However, many existing fusion schemes do not consider the quality of each fusion input and may suffer from adverse conditions on one or more sensors. While predictive uncertainty has been applied to characterize single-modal object detection performance at run time, incorporating uncertainties into the multi-modal fusion still lacks effective solutions due primarily to the uncertainty's cross-modal incomparability and distinct sensitivities to various adverse conditions. To fill this gap, this paper proposes Uncertainty-Encoded Mixture-of-Experts (UMoE) that explicitly incorporates single-modal uncertainties into LiDAR-camera fusion. UMoE uses individual expert network to process each sensor's detection result together with encoded uncertainty. Then, the expert networks' outputs are analyzed by a gating network to determine the fusion weights. The proposed UMoE module can be in",
    "path": "papers/23/07/2307.16121.json",
    "total_tokens": 942,
    "translated_title": "自动驾驶中的稳健目标检测的不确定性编码多模态融合",
    "translated_abstract": "多模态融合在自动驾驶感知的目标检测中显示了初步的有 promising 结果。然而，许多现有的融合方案没有考虑到每个融合输入的质量，并且可能会受到一个或多个传感器的不利条件的影响。虽然预测不确定性已经被应用于在运行时表征单模态目标检测性能，但将不确定性纳入多模态融合仍然缺乏有效的解决方案，主要是由于不确定性的跨模态不可比较性和对各种不利条件的不同敏感性。为了弥补这个差距，本文提出了一种名为 Uncertainty-Encoded Mixture-of-Experts（UMoE）的方法，它明确地将单模态的不确定性纳入了LiDAR-相机融合中。UMoE使用单独的专家网络来处理每个传感器的检测结果以及编码的不确定性。然后，由一个门控网络分析专家网络的输出以确定融合权重。所提出的UMoE模块可以被应用于不同的自动驾驶场景中。",
    "tldr": "本文提出了一种名为UMoE的方法，它将单模态的不确定性纳入了LiDAR-相机融合中，通过使用专家网络和门控网络来处理和分析多模态融合结果，以实现自动驾驶中稳健的目标检测。",
    "en_tdlr": "This paper proposes UMoE, which incorporates single-modal uncertainties into LiDAR-camera fusion and achieves robust object detection in autonomous driving by using expert networks and a gating network to process and analyze the multi-modal fusion results."
}