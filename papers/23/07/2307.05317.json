{
    "title": "Automatic Generation of Semantic Parts for Face Image Synthesis. (arXiv:2307.05317v1 [cs.CV])",
    "abstract": "Semantic image synthesis (SIS) refers to the problem of generating realistic imagery given a semantic segmentation mask that defines the spatial layout of object classes. Most of the approaches in the literature, other than the quality of the generated images, put effort in finding solutions to increase the generation diversity in terms of style i.e. texture. However, they all neglect a different feature, which is the possibility of manipulating the layout provided by the mask. Currently, the only way to do so is manually by means of graphical users interfaces. In this paper, we describe a network architecture to address the problem of automatically manipulating or generating the shape of object classes in semantic segmentation masks, with specific focus on human faces. Our proposed model allows embedding the mask class-wise into a latent space where each class embedding can be independently edited. Then, a bi-directional LSTM block and a convolutional decoder output a new, locally man",
    "link": "http://arxiv.org/abs/2307.05317",
    "context": "Title: Automatic Generation of Semantic Parts for Face Image Synthesis. (arXiv:2307.05317v1 [cs.CV])\nAbstract: Semantic image synthesis (SIS) refers to the problem of generating realistic imagery given a semantic segmentation mask that defines the spatial layout of object classes. Most of the approaches in the literature, other than the quality of the generated images, put effort in finding solutions to increase the generation diversity in terms of style i.e. texture. However, they all neglect a different feature, which is the possibility of manipulating the layout provided by the mask. Currently, the only way to do so is manually by means of graphical users interfaces. In this paper, we describe a network architecture to address the problem of automatically manipulating or generating the shape of object classes in semantic segmentation masks, with specific focus on human faces. Our proposed model allows embedding the mask class-wise into a latent space where each class embedding can be independently edited. Then, a bi-directional LSTM block and a convolutional decoder output a new, locally man",
    "path": "papers/23/07/2307.05317.json",
    "total_tokens": 907,
    "translated_title": "自动生成面部图像合成的语义部件",
    "translated_abstract": "语义图像合成（SIS）指的是在给定定义物体类别空间布局的语义分割掩膜的情况下生成逼真图像的问题。大部分文献中的方法除了生成图像的质量外，还致力于解决如何增加样式（例如纹理）上的生成多样性的问题。然而，它们都忽略了另一个特征，即通过掩膜提供的布局可以进行操作的可能性。目前，唯一的实现方式是通过图形用户界面手动操作。在本文中，我们描述了一种网络架构，用于自动操作或生成语义分割掩膜中物体类别的形状，特别关注人脸。我们提出的模型允许将分割掩膜按类别嵌入到潜空间中，其中每个类别嵌入可以独立编辑。然后，一个双向LSTM块和一个卷积解码器输出一个新的、局部的图像。",
    "tldr": "本文提出了一种网络架构，用于自动操作或生成语义分割掩膜中物体类别的形状，特别是人脸。该模型可以将分割掩膜嵌入到潜空间中，使每个类别嵌入可以独立编辑，从而实现对图像布局的自动操作。",
    "en_tdlr": "This paper proposes a network architecture for automatically manipulating or generating the shape of object classes in semantic segmentation masks, with a specific focus on human faces. The proposed model allows embedding the mask class-wise into a latent space where each class embedding can be edited independently, enabling automatic manipulation of the image layout."
}