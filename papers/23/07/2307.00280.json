{
    "title": "SysNoise: Exploring and Benchmarking Training-Deployment System Inconsistency. (arXiv:2307.00280v1 [cs.LG])",
    "abstract": "Extensive studies have shown that deep learning models are vulnerable to adversarial and natural noises, yet little is known about model robustness on noises caused by different system implementations. In this paper, we for the first time introduce SysNoise, a frequently occurred but often overlooked noise in the deep learning training-deployment cycle. In particular, SysNoise happens when the source training system switches to a disparate target system in deployments, where various tiny system mismatch adds up to a non-negligible difference. We first identify and classify SysNoise into three categories based on the inference stage; we then build a holistic benchmark to quantitatively measure the impact of SysNoise on 20+ models, comprehending image classification, object detection, instance segmentation and natural language processing tasks. Our extensive experiments revealed that SysNoise could bring certain impacts on model robustness across different tasks and common mitigations li",
    "link": "http://arxiv.org/abs/2307.00280",
    "context": "Title: SysNoise: Exploring and Benchmarking Training-Deployment System Inconsistency. (arXiv:2307.00280v1 [cs.LG])\nAbstract: Extensive studies have shown that deep learning models are vulnerable to adversarial and natural noises, yet little is known about model robustness on noises caused by different system implementations. In this paper, we for the first time introduce SysNoise, a frequently occurred but often overlooked noise in the deep learning training-deployment cycle. In particular, SysNoise happens when the source training system switches to a disparate target system in deployments, where various tiny system mismatch adds up to a non-negligible difference. We first identify and classify SysNoise into three categories based on the inference stage; we then build a holistic benchmark to quantitatively measure the impact of SysNoise on 20+ models, comprehending image classification, object detection, instance segmentation and natural language processing tasks. Our extensive experiments revealed that SysNoise could bring certain impacts on model robustness across different tasks and common mitigations li",
    "path": "papers/23/07/2307.00280.json",
    "total_tokens": 900,
    "translated_title": "SysNoise: 探索和评估训练-部署系统的不一致性",
    "translated_abstract": "大量研究表明，深度学习模型容易受到敌对和自然噪音的影响，然而对于由不同系统实现引起的噪音对模型的稳健性知之甚少。本文首次引入SysNoise，一种在深度学习的训练-部署周期中经常发生但往往被忽视的噪音。具体而言，SysNoise发生在源训练系统在部署时切换到不同的目标系统时，各种微小系统不匹配累加起来会产生显著差异。我们首先对SysNoise进行了识别和分类，分为基于推理阶段的三个类别；然后建立了一个综合性评估标准，以定量评估SysNoise对20多种模型的影响，包括图像分类、目标检测、实例分割和自然语言处理任务。我们广泛的实验揭示了SysNoise对不同任务的模型稳健性会带来一定的影响，并提出了常见的缓解方法。",
    "tldr": "SysNoise是一种在深度学习的训练-部署周期中经常发生的噪音，该论文通过实验证明了SysNoise对不同任务的模型稳健性会带来一定影响，并提出了常见的缓解方法。"
}