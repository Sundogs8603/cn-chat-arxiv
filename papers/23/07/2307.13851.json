{
    "title": "SplitFed resilience to packet loss: Where to split, that is the question. (arXiv:2307.13851v1 [cs.CV])",
    "abstract": "Decentralized machine learning has broadened its scope recently with the invention of Federated Learning (FL), Split Learning (SL), and their hybrids like Split Federated Learning (SplitFed or SFL). The goal of SFL is to reduce the computational power required by each client in FL and parallelize SL while maintaining privacy. This paper investigates the robustness of SFL against packet loss on communication links. The performance of various SFL aggregation strategies is examined by splitting the model at two points -- shallow split and deep split -- and testing whether the split point makes a statistically significant difference to the accuracy of the final model. Experiments are carried out on a segmentation model for human embryo images and indicate the statistically significant advantage of a deeper split point.",
    "link": "http://arxiv.org/abs/2307.13851",
    "context": "Title: SplitFed resilience to packet loss: Where to split, that is the question. (arXiv:2307.13851v1 [cs.CV])\nAbstract: Decentralized machine learning has broadened its scope recently with the invention of Federated Learning (FL), Split Learning (SL), and their hybrids like Split Federated Learning (SplitFed or SFL). The goal of SFL is to reduce the computational power required by each client in FL and parallelize SL while maintaining privacy. This paper investigates the robustness of SFL against packet loss on communication links. The performance of various SFL aggregation strategies is examined by splitting the model at two points -- shallow split and deep split -- and testing whether the split point makes a statistically significant difference to the accuracy of the final model. Experiments are carried out on a segmentation model for human embryo images and indicate the statistically significant advantage of a deeper split point.",
    "path": "papers/23/07/2307.13851.json",
    "total_tokens": 835,
    "translated_title": "SplitFed对数据包丢失的韧性：何处切割，这是问题。",
    "translated_abstract": "近年来，通过联邦学习（FL），分割学习（SL）以及它们的混合形式，如分割联邦学习（SplitFed或SFL），分散式机器学习的范围得到了扩展。SFL的目标是降低FL中每个客户端所需的计算能力，并在保护隐私的同时实现SL的并行化。本文研究了SFL对通信链路上数据包丢失的鲁棒性。通过在模型的两个位置——浅度切割点和深度切割点——进行切割，并测试切割点是否对最终模型的准确性产生统计显著的影响，考察了不同的SFL聚合策略的性能。实验在人类胚胎图像分割模型上进行，并表明更深的切割点具有统计显著的优势。",
    "tldr": "本文研究了分割联邦学习（SplitFed）在通信链路上对数据包丢失的鲁棒性，并通过实验证明了更深的切割点对最终模型的准确性具有统计显著的优势。"
}