{
    "title": "SC VALL-E: Style-Controllable Zero-Shot Text to Speech Synthesizer. (arXiv:2307.10550v1 [cs.SD])",
    "abstract": "Expressive speech synthesis models are trained by adding corpora with diverse speakers, various emotions, and different speaking styles to the dataset, in order to control various characteristics of speech and generate the desired voice. In this paper, we propose a style control (SC) VALL-E model based on the neural codec language model (called VALL-E), which follows the structure of the generative pretrained transformer 3 (GPT-3). The proposed SC VALL-E takes input from text sentences and prompt audio and is designed to generate controllable speech by not simply mimicking the characteristics of the prompt audio but by controlling the attributes to produce diverse voices. We identify tokens in the style embedding matrix of the newly designed style network that represent attributes such as emotion, speaking rate, pitch, and voice intensity, and design a model that can control these attributes. To evaluate the performance of SC VALL-E, we conduct comparative experiments with three repres",
    "link": "http://arxiv.org/abs/2307.10550",
    "context": "Title: SC VALL-E: Style-Controllable Zero-Shot Text to Speech Synthesizer. (arXiv:2307.10550v1 [cs.SD])\nAbstract: Expressive speech synthesis models are trained by adding corpora with diverse speakers, various emotions, and different speaking styles to the dataset, in order to control various characteristics of speech and generate the desired voice. In this paper, we propose a style control (SC) VALL-E model based on the neural codec language model (called VALL-E), which follows the structure of the generative pretrained transformer 3 (GPT-3). The proposed SC VALL-E takes input from text sentences and prompt audio and is designed to generate controllable speech by not simply mimicking the characteristics of the prompt audio but by controlling the attributes to produce diverse voices. We identify tokens in the style embedding matrix of the newly designed style network that represent attributes such as emotion, speaking rate, pitch, and voice intensity, and design a model that can control these attributes. To evaluate the performance of SC VALL-E, we conduct comparative experiments with three repres",
    "path": "papers/23/07/2307.10550.json",
    "total_tokens": 879,
    "translated_title": "SC VALL-E: 可控风格的零样本文本到语音合成器",
    "translated_abstract": "为了控制语音的各种特征和生成所需的声音，表达性的语音合成模型通过添加具有不同说话者、情绪和不同说话风格的语料库来进行训练。在本文中，我们提出了一种基于神经编码语言模型VALL-E的风格控制（SC）VALL-E模型，该模型遵循生成预训练变换器3（GPT-3）的结构。所提出的SC VALL-E模型从文本句子和提示音频中接收输入，并通过控制属性来生成可控的语音，而不仅仅是模仿提示音频的特征。我们通过识别新设计的风格网络的风格嵌入矩阵中表示情绪、说话速度、音高和声音强度等属性的标记，并设计一个可以控制这些属性的模型。为了评估SC VALL-E的性能，我们进行了与三种基准模型的比较实验。",
    "tldr": "本文提出了一种基于神经编码语言模型的风格控制零样本文本到语音合成器，通过控制属性生成可控语音而不仅仅模仿特征，具有较好的性能。",
    "en_tdlr": "This paper proposes a style-controllable zero-shot text to speech synthesizer based on a neural codec language model. It generates controllable speech by controlling attributes instead of simply mimicking features, and shows good performance."
}