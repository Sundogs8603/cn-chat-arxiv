{
    "title": "On the Robustness of Split Learning against Adversarial Attacks. (arXiv:2307.07916v1 [cs.LG])",
    "abstract": "Split learning enables collaborative deep learning model training while preserving data privacy and model security by avoiding direct sharing of raw data and model details (i.e., sever and clients only hold partial sub-networks and exchange intermediate computations). However, existing research has mainly focused on examining its reliability for privacy protection, with little investigation into model security. Specifically, by exploring full models, attackers can launch adversarial attacks, and split learning can mitigate this severe threat by only disclosing part of models to untrusted servers.This paper aims to evaluate the robustness of split learning against adversarial attacks, particularly in the most challenging setting where untrusted servers only have access to the intermediate layers of the model.Existing adversarial attacks mostly focus on the centralized setting instead of the collaborative setting, thus, to better evaluate the robustness of split learning, we develop a ta",
    "link": "http://arxiv.org/abs/2307.07916",
    "context": "Title: On the Robustness of Split Learning against Adversarial Attacks. (arXiv:2307.07916v1 [cs.LG])\nAbstract: Split learning enables collaborative deep learning model training while preserving data privacy and model security by avoiding direct sharing of raw data and model details (i.e., sever and clients only hold partial sub-networks and exchange intermediate computations). However, existing research has mainly focused on examining its reliability for privacy protection, with little investigation into model security. Specifically, by exploring full models, attackers can launch adversarial attacks, and split learning can mitigate this severe threat by only disclosing part of models to untrusted servers.This paper aims to evaluate the robustness of split learning against adversarial attacks, particularly in the most challenging setting where untrusted servers only have access to the intermediate layers of the model.Existing adversarial attacks mostly focus on the centralized setting instead of the collaborative setting, thus, to better evaluate the robustness of split learning, we develop a ta",
    "path": "papers/23/07/2307.07916.json",
    "total_tokens": 928,
    "translated_title": "论分裂学习对抗敌对攻击的鲁棒性",
    "translated_abstract": "分裂学习通过避免直接共享原始数据和模型细节（即服务器和客户端仅持有部分子网络并交换中间计算）来实现协同深度学习模型训练的同时保护数据隐私和模型安全性。然而，现有研究主要集中在检验其对隐私保护的可靠性，对模型安全性的研究甚少。具体而言，通过探索完整模型，攻击者可以发起敌对攻击，而分裂学习可以通过仅向不受信任的服务器公开部分模型来缓解这种严重威胁。本文旨在评估分裂学习对抗敌对攻击的鲁棒性，特别是在不受信任的服务器只能访问模型的中间层的最具挑战性的情况下。现有的敌对攻击大多集中在集中式环境而非协同式环境，因此，为了更好地评估分裂学习的鲁棒性，我们提出了一种新的评估方法。",
    "tldr": "该论文评估了分裂学习对抗敌对攻击的鲁棒性，特别关注不受信任服务器只能访问模型中间层的情况。通过仅向服务器公开部分模型，分裂学习可以缓解敌对攻击威胁。"
}