{
    "title": "Analyzing Intentional Behavior in Autonomous Agents under Uncertainty. (arXiv:2307.01532v1 [cs.AI])",
    "abstract": "Principled accountability for autonomous decision-making in uncertain environments requires distinguishing intentional outcomes from negligent designs from actual accidents. We propose analyzing the behavior of autonomous agents through a quantitative measure of the evidence of intentional behavior. We model an uncertain environment as a Markov Decision Process (MDP). For a given scenario, we rely on probabilistic model checking to compute the ability of the agent to influence reaching a certain event. We call this the scope of agency. We say that there is evidence of intentional behavior if the scope of agency is high and the decisions of the agent are close to being optimal for reaching the event. Our method applies counterfactual reasoning to automatically generate relevant scenarios that can be analyzed to increase the confidence of our assessment. In a case study, we show how our method can distinguish between 'intentional' and 'accidental' traffic collisions.",
    "link": "http://arxiv.org/abs/2307.01532",
    "context": "Title: Analyzing Intentional Behavior in Autonomous Agents under Uncertainty. (arXiv:2307.01532v1 [cs.AI])\nAbstract: Principled accountability for autonomous decision-making in uncertain environments requires distinguishing intentional outcomes from negligent designs from actual accidents. We propose analyzing the behavior of autonomous agents through a quantitative measure of the evidence of intentional behavior. We model an uncertain environment as a Markov Decision Process (MDP). For a given scenario, we rely on probabilistic model checking to compute the ability of the agent to influence reaching a certain event. We call this the scope of agency. We say that there is evidence of intentional behavior if the scope of agency is high and the decisions of the agent are close to being optimal for reaching the event. Our method applies counterfactual reasoning to automatically generate relevant scenarios that can be analyzed to increase the confidence of our assessment. In a case study, we show how our method can distinguish between 'intentional' and 'accidental' traffic collisions.",
    "path": "papers/23/07/2307.01532.json",
    "total_tokens": 936,
    "translated_title": "在不确定环境下分析自主代理的有意行为",
    "translated_abstract": "在不确定环境中，对自主决策行为进行有效的问责需要区分有意结果、疏忽设计和实际意外。我们提出使用有意行为的证据的定量度量来分析自主代理的行为。我们将不确定环境建模为马尔可夫决策过程（MDP）。对于给定的情景，我们依靠概率性模型检查来计算代理影响达成特定事件的能力。我们称之为代理的范围。如果代理的范围较大且其决策接近达到该事件的最佳状态，则存在有意行为的证据。我们的方法应用反事实推理来自动生成相关情景，以增加我们评估的信心。在一个案例研究中，我们展示了我们的方法如何区分“有意”和“意外”的交通碰撞。",
    "tldr": "本论文提出了一种在不确定环境下分析自主代理有意行为的方法，通过定量度量证据来区分有意结果、疏忽设计和实际意外。方法使用马尔可夫决策过程建模不确定环境，并通过概率模型检查计算代理的影响能力。采用反事实推理自动生成相关情景增加评估信心。在一个案例研究中成功区分“有意”和“意外”的交通碰撞。",
    "en_tdlr": "This paper proposes a method for analyzing intentional behavior of autonomous agents under uncertainty, distinguishing intentional outcomes from negligent designs and actual accidents using a quantitative measure of evidence. The method models uncertain environments as Markov Decision Processes and calculates the agent's ability to influence specific events using probabilistic model checking. Counterfactual reasoning is applied to generate relevant scenarios and increase assessment confidence. The method successfully distinguishes between intentional and accidental traffic collisions in a case study."
}