{
    "title": "Scalable variable selection for two-view learning tasks with projection operators. (arXiv:2307.01558v1 [cs.LG])",
    "abstract": "In this paper we propose a novel variable selection method for two-view settings, or for vector-valued supervised learning problems. Our framework is able to handle extremely large scale selection tasks, where number of data samples could be even millions. In a nutshell, our method performs variable selection by iteratively selecting variables that are highly correlated with the output variables, but which are not correlated with the previously chosen variables. To measure the correlation, our method uses the concept of projection operators and their algebra. With the projection operators the relationship, correlation, between sets of input and output variables can also be expressed by kernel functions, thus nonlinear correlation models can be exploited as well. We experimentally validate our approach, showing on both synthetic and real data its scalability and the relevance of the selected features. Keywords: Supervised variable selection, vector-valued learning, projection-valued mea",
    "link": "http://arxiv.org/abs/2307.01558",
    "context": "Title: Scalable variable selection for two-view learning tasks with projection operators. (arXiv:2307.01558v1 [cs.LG])\nAbstract: In this paper we propose a novel variable selection method for two-view settings, or for vector-valued supervised learning problems. Our framework is able to handle extremely large scale selection tasks, where number of data samples could be even millions. In a nutshell, our method performs variable selection by iteratively selecting variables that are highly correlated with the output variables, but which are not correlated with the previously chosen variables. To measure the correlation, our method uses the concept of projection operators and their algebra. With the projection operators the relationship, correlation, between sets of input and output variables can also be expressed by kernel functions, thus nonlinear correlation models can be exploited as well. We experimentally validate our approach, showing on both synthetic and real data its scalability and the relevance of the selected features. Keywords: Supervised variable selection, vector-valued learning, projection-valued mea",
    "path": "papers/23/07/2307.01558.json",
    "total_tokens": 777,
    "translated_title": "可扩展的投影算子用于两视图学习任务的变量选择方法",
    "translated_abstract": "本文提出了一种针对两视图设置或向量值监督学习问题的新型变量选择方法。我们的框架能够处理规模极大的选择任务，样本数甚至可以达到百万级。简言之，我们的方法通过选择与输出变量高度相关但与先前选择的变量无关的变量来进行变量选择。为了衡量相关性，我们的方法使用了投影算子及其代数的概念。通过投影算子，输入和输出变量集之间的关系、相关性也可以通过核函数来表达，从而可以利用非线性相关模型。通过实验证明了我们方法的可扩展性以及所选择特征的相关性。",
    "tldr": "本文提出了一种可扩展的变量选择方法，适用于两视图学习任务或向量值监督学习问题，能够处理规模极大的选择任务，并利用投影算子以及核函数进行相关性衡量和非线性相关模型的处理。",
    "en_tdlr": "This paper proposes a scalable variable selection method for two-view learning tasks or vector-valued supervised learning problems. It can handle extremely large scale selection tasks and utilizes projection operators and kernel functions for measuring correlation and handling nonlinear correlation models."
}