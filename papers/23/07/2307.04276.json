{
    "title": "Automated Essay Scoring in Argumentative Writing: DeBERTeachingAssistant. (arXiv:2307.04276v1 [cs.CL])",
    "abstract": "Automated Essay scoring has been explored as a research and industry problem for over 50 years. It has drawn a lot of attention from the NLP community because of its clear educational value as a research area that can engender the creation of valuable time-saving tools for educators around the world. Yet, these tools are generally focused on detecting good grammar, spelling mistakes, and organization quality but tend to fail at incorporating persuasiveness features in their final assessment. The responsibility to give actionable feedback to the student to improve the strength of their arguments is left solely on the teacher's shoulders. In this work, we present a transformer-based architecture capable of achieving above-human accuracy in annotating argumentative writing discourse elements for their persuasiveness quality and we expand on planned future work investigating the explainability of our model so that actionable feedback can be offered to the student and thus potentially enabl",
    "link": "http://arxiv.org/abs/2307.04276",
    "context": "Title: Automated Essay Scoring in Argumentative Writing: DeBERTeachingAssistant. (arXiv:2307.04276v1 [cs.CL])\nAbstract: Automated Essay scoring has been explored as a research and industry problem for over 50 years. It has drawn a lot of attention from the NLP community because of its clear educational value as a research area that can engender the creation of valuable time-saving tools for educators around the world. Yet, these tools are generally focused on detecting good grammar, spelling mistakes, and organization quality but tend to fail at incorporating persuasiveness features in their final assessment. The responsibility to give actionable feedback to the student to improve the strength of their arguments is left solely on the teacher's shoulders. In this work, we present a transformer-based architecture capable of achieving above-human accuracy in annotating argumentative writing discourse elements for their persuasiveness quality and we expand on planned future work investigating the explainability of our model so that actionable feedback can be offered to the student and thus potentially enabl",
    "path": "papers/23/07/2307.04276.json",
    "total_tokens": 825,
    "translated_title": "自动化的论证性写作文章评分：DeBERT教学助手",
    "translated_abstract": "自动化的文章评分已经成为一个研究和产业问题超过50年。由于其明确的教育价值以及对教育者提供有价值的节省时间工具的研究领域，它吸引了自然语言处理社区的大量关注。然而，这些工具通常只关注于检测良好的语法、拼写错误和组织质量，但往往在评估中未能将说服力特征纳入考虑。提供可操作的反馈以改进学生论证的力量的责任完全落在教师肩上。在这项工作中，我们提出了一种基于Transformer的架构，能够以超过人类准确度对论证性写作的话语要素进行注释其说服力质量，并扩展了对我们模型可解释性的未来研究。",
    "tldr": "本研究提出了一种基于Transformer的架构，用于自动评分论证性写作文章的说服力质量，并计划进一步研究其模型的可解释性，以提供可操作的反馈给学生。"
}