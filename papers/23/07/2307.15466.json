{
    "title": "LUCID-GAN: Conditional Generative Models to Locate Unfairness. (arXiv:2307.15466v1 [cs.LG])",
    "abstract": "Most group fairness notions detect unethical biases by computing statistical parity metrics on a model's output. However, this approach suffers from several shortcomings, such as philosophical disagreement, mutual incompatibility, and lack of interpretability. These shortcomings have spurred the research on complementary bias detection methods that offer additional transparency into the sources of discrimination and are agnostic towards an a priori decision on the definition of fairness and choice of protected features. A recent proposal in this direction is LUCID (Locating Unfairness through Canonical Inverse Design), where canonical sets are generated by performing gradient descent on the input space, revealing a model's desired input given a preferred output. This information about the model's mechanisms, i.e., which feature values are essential to obtain specific outputs, allows exposing potential unethical biases in its internal logic. Here, we present LUCID-GAN, which generates c",
    "link": "http://arxiv.org/abs/2307.15466",
    "context": "Title: LUCID-GAN: Conditional Generative Models to Locate Unfairness. (arXiv:2307.15466v1 [cs.LG])\nAbstract: Most group fairness notions detect unethical biases by computing statistical parity metrics on a model's output. However, this approach suffers from several shortcomings, such as philosophical disagreement, mutual incompatibility, and lack of interpretability. These shortcomings have spurred the research on complementary bias detection methods that offer additional transparency into the sources of discrimination and are agnostic towards an a priori decision on the definition of fairness and choice of protected features. A recent proposal in this direction is LUCID (Locating Unfairness through Canonical Inverse Design), where canonical sets are generated by performing gradient descent on the input space, revealing a model's desired input given a preferred output. This information about the model's mechanisms, i.e., which feature values are essential to obtain specific outputs, allows exposing potential unethical biases in its internal logic. Here, we present LUCID-GAN, which generates c",
    "path": "papers/23/07/2307.15466.json",
    "total_tokens": 884,
    "translated_title": "LUCID-GAN: 有条件生成模型用于定位不公平性",
    "translated_abstract": "大多数群体公平性概念通过计算模型输出的统计平衡度指标来检测不道德偏见。然而，这种方法存在几个缺点，如哲学分歧、相互不兼容和缺乏解释性。这些缺点促使了对补充性偏见检测方法的研究，这些方法可以提供对歧视来源的额外透明度，并且对于对公平定义和受保护特征的先验决策是不可知的。在这个方向上的一个最近的提议是LUCID（通过规范逆向设计定位不公平性），其中通过在输入空间上进行梯度下降来生成规范集，揭示了模型在给定首选输出的情况下所希望的输入。这些关于模型机制的信息，即为实现特定输出所必需的特征值，可以揭示其内部逻辑中潜在的不道德偏见。在这里，我们介绍了LUCID-GAN，它生成c",
    "tldr": "LUCID-GAN是一个有条件生成模型，用于定位不公平性。它通过生成规范集来揭示模型的内部逻辑中潜在的不道德偏见，提供了对歧视来源的额外透明度。",
    "en_tdlr": "LUCID-GAN is a conditional generative model that aims to locate unfairness. It generates canonical sets to reveal potential unethical biases in the internal logic of the model, providing additional transparency into the sources of discrimination."
}