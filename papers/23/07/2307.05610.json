{
    "title": "Substance or Style: What Does Your Image Embedding Know?. (arXiv:2307.05610v1 [cs.LG])",
    "abstract": "Probes are small networks that predict properties of underlying data from embeddings, and they provide a targeted, effective way to illuminate the information contained in embeddings. While analysis through the use of probes has become standard in NLP, there has been much less exploration in vision. Image foundation models have primarily been evaluated for semantic content. Better understanding the non-semantic information in popular embeddings (e.g., MAE, SimCLR, or CLIP) will shed new light both on the training algorithms and on the uses for these foundation models. We design a systematic transformation prediction task and measure the visual content of embeddings along many axes, including image style, quality, and a range of natural and artificial transformations. Surprisingly, six embeddings (including SimCLR) encode enough non-semantic information to identify dozens of transformations. We also consider a generalization task, where we group similar transformations and hold out seve",
    "link": "http://arxiv.org/abs/2307.05610",
    "context": "Title: Substance or Style: What Does Your Image Embedding Know?. (arXiv:2307.05610v1 [cs.LG])\nAbstract: Probes are small networks that predict properties of underlying data from embeddings, and they provide a targeted, effective way to illuminate the information contained in embeddings. While analysis through the use of probes has become standard in NLP, there has been much less exploration in vision. Image foundation models have primarily been evaluated for semantic content. Better understanding the non-semantic information in popular embeddings (e.g., MAE, SimCLR, or CLIP) will shed new light both on the training algorithms and on the uses for these foundation models. We design a systematic transformation prediction task and measure the visual content of embeddings along many axes, including image style, quality, and a range of natural and artificial transformations. Surprisingly, six embeddings (including SimCLR) encode enough non-semantic information to identify dozens of transformations. We also consider a generalization task, where we group similar transformations and hold out seve",
    "path": "papers/23/07/2307.05610.json",
    "total_tokens": 907,
    "translated_title": "物质还是风格：你的图像嵌入知道什么？",
    "translated_abstract": "探针是一种从嵌入中预测底层数据属性的小型网络，它们提供了一种有针对性和有效的方法来揭示嵌入中包含的信息。虽然通过使用探针进行分析在自然语言处理中已经很常见了，但在计算机视觉领域中的探索却比较少。图像基础模型主要用于评估语义内容。更好地理解流行嵌入（如MAE，SimCLR或CLIP）中的非语义信息，将为训练算法和这些基础模型的用途提供新的视角。我们设计了一个系统的转换预测任务，并在多个维度上测量嵌入的视觉内容，包括图像风格、质量以及各种自然和人工转换。令人惊讶的是，有六个嵌入（包括SimCLR）编码了足够的非语义信息，可以识别出数十个转换。我们还考虑了一个泛化任务，将相似的转换分组，并留出一部分数据进行评估。",
    "tldr": "本文研究了图像嵌入中的非语义信息，设计了一个系统的转换预测任务，并发现六个嵌入可以识别出多个转换。这对于训练算法和基础模型的应用具有重要意义。",
    "en_tdlr": "This paper investigates the non-semantic information in image embeddings, designs a systematic transformation prediction task, and finds that six embeddings can identify multiple transformations, shedding new light on training algorithms and the application of foundation models."
}