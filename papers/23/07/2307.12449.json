{
    "title": "WEPRO: Weight Prediction for Efficient Optimization of Hybrid Quantum-Classical Algorithms. (arXiv:2307.12449v2 [quant-ph] UPDATED)",
    "abstract": "The exponential run time of quantum simulators on classical machines and long queue depths and high costs of real quantum devices present significant challenges in the effective training of Variational Quantum Algorithms (VQAs) like Quantum Neural Networks (QNNs), Variational Quantum Eigensolver (VQE) and Quantum Approximate Optimization Algorithm (QAOA). To address these limitations, we propose a new approach, WEPRO (Weight Prediction), which accelerates the convergence of VQAs by exploiting regular trends in the parameter weights. We introduce two techniques for optimal prediction performance namely, Naive Prediction (NaP) and Adaptive Prediction (AdaP). Through extensive experimentation and training of multiple QNN models on various datasets, we demonstrate that WEPRO offers a speedup of approximately $2.25\\times$ compared to standard training methods, while also providing improved accuracy (up to $2.3\\%$ higher) and loss (up to $6.1\\%$ lower) with low storage and computational over",
    "link": "http://arxiv.org/abs/2307.12449",
    "context": "Title: WEPRO: Weight Prediction for Efficient Optimization of Hybrid Quantum-Classical Algorithms. (arXiv:2307.12449v2 [quant-ph] UPDATED)\nAbstract: The exponential run time of quantum simulators on classical machines and long queue depths and high costs of real quantum devices present significant challenges in the effective training of Variational Quantum Algorithms (VQAs) like Quantum Neural Networks (QNNs), Variational Quantum Eigensolver (VQE) and Quantum Approximate Optimization Algorithm (QAOA). To address these limitations, we propose a new approach, WEPRO (Weight Prediction), which accelerates the convergence of VQAs by exploiting regular trends in the parameter weights. We introduce two techniques for optimal prediction performance namely, Naive Prediction (NaP) and Adaptive Prediction (AdaP). Through extensive experimentation and training of multiple QNN models on various datasets, we demonstrate that WEPRO offers a speedup of approximately $2.25\\times$ compared to standard training methods, while also providing improved accuracy (up to $2.3\\%$ higher) and loss (up to $6.1\\%$ lower) with low storage and computational over",
    "path": "papers/23/07/2307.12449.json",
    "total_tokens": 983,
    "translated_title": "WEPRO: 用于混合量子-经典算法高效优化的权重预测方法",
    "translated_abstract": "量子模拟器在经典计算机上的指数级运行时间、真实量子设备的长队列深度和高成本给变分量子算法(VQA)如量子神经网络(QNNs)、变分量子本征求解器(VQE)和量子近似优化算法(QAOA)的有效训练带来了巨大挑战。为了解决这些限制，我们提出了一种新方法WEPRO(权重预测)，通过利用参数权重中的规律趋势来加快VQA的收敛速度。我们引入了两种优化预测性能的技术，即Naive Prediction(NaP)和Adaptive Prediction(AdaP)。通过对各种数据集上多个QNN模型的广泛实验和训练，我们证明WEPRO相对于标准训练方法加快了大约2.25倍的速度，同时在存储和计算开销较低的情况下提供了更高的准确性(高达2.3%)和更低的损失(高达6.1%)。",
    "tldr": "本研究提出了一种名为WEPRO的新方法，通过利用参数权重中的规律趋势加速了混合量子-经典算法的收敛速度，相比标准训练方法，速度提高约2.25倍，准确性提高了2.3%，损失降低了6.1%。",
    "en_tdlr": "This work proposes a new method called WEPRO, which accelerates the convergence of hybrid quantum-classical algorithms by exploiting regular trends in the parameter weights. Compared to standard training methods, it achieves a speedup of approximately 2.25 times, with an improvement of 2.3% in accuracy and a reduction of 6.1% in loss, all while maintaining low storage and computational costs."
}