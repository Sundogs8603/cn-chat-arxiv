{
    "title": "Mining of Single-Class by Active Learning for Semantic Segmentation. (arXiv:2307.09109v1 [cs.LG])",
    "abstract": "Several Active Learning (AL) policies require retraining a target model several times in order to identify the most informative samples and rarely offer the option to focus on the acquisition of samples from underrepresented classes. Here the Mining of Single-Class by Active Learning (MiSiCAL) paradigm is introduced where an AL policy is constructed through deep reinforcement learning and exploits quantity-accuracy correlations to build datasets on which high-performance models can be trained with regards to specific classes. MiSiCAL is especially helpful in the case of very large batch sizes since it does not require repeated model training sessions as is common in other AL methods. This is thanks to its ability to exploit fixed representations of the candidate data points. We find that MiSiCAL is able to outperform a random policy on 150 out of 171 COCO10k classes, while the strongest baseline only outperforms random on 101 classes.",
    "link": "http://arxiv.org/abs/2307.09109",
    "context": "Title: Mining of Single-Class by Active Learning for Semantic Segmentation. (arXiv:2307.09109v1 [cs.LG])\nAbstract: Several Active Learning (AL) policies require retraining a target model several times in order to identify the most informative samples and rarely offer the option to focus on the acquisition of samples from underrepresented classes. Here the Mining of Single-Class by Active Learning (MiSiCAL) paradigm is introduced where an AL policy is constructed through deep reinforcement learning and exploits quantity-accuracy correlations to build datasets on which high-performance models can be trained with regards to specific classes. MiSiCAL is especially helpful in the case of very large batch sizes since it does not require repeated model training sessions as is common in other AL methods. This is thanks to its ability to exploit fixed representations of the candidate data points. We find that MiSiCAL is able to outperform a random policy on 150 out of 171 COCO10k classes, while the strongest baseline only outperforms random on 101 classes.",
    "path": "papers/23/07/2307.09109.json",
    "total_tokens": 908,
    "translated_title": "单类别主动学习用于语义分割的挖掘",
    "translated_abstract": "几种主动学习策略需要多次重新训练目标模型，以识别最具信息的样本，并很少提供从少数类别中获取样本的选项。本文引入了一种名为“Mining of Single-Class by Active Learning (MiSiCAL)”的范式，通过深度强化学习构建了一个主动学习策略，并利用数量-准确性相关性来建立数据集，用于针对特定类别训练高性能模型。MiSiCAL在特别大的批量大小下尤其有帮助，因为它不需要像其他主动学习方法那样进行重复的模型训练。这要归功于它能够利用候选数据点的固定表示。我们发现，在171个COCO10k类别中，MiSiCAL能够在150个类别上胜过随机策略，而最强的基准只在101个类别上胜过随机策略。",
    "tldr": "本文介绍了一种名为\"MiSiCAL\"的单类别主动学习范式，通过深度强化学习构建了一个策略，利用数量-准确性相关性对特定类别进行高性能模型训练，特别适用于大批量大小的情况下。MiSiCAL能在许多类别上优于随机策略。",
    "en_tdlr": "This paper introduces a paradigm called \"MiSiCAL\" for single-class active learning, which constructs a policy through deep reinforcement learning and trains high-performance models for specific classes using quantity-accuracy correlations, especially suitable for large batch sizes. MiSiCAL outperforms random policy in many classes."
}