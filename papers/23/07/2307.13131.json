{
    "title": "Why Don't You Clean Your Glasses? Perception Attacks with Dynamic Optical Perturbations. (arXiv:2307.13131v1 [cs.CR])",
    "abstract": "Camera-based autonomous systems that emulate human perception are increasingly being integrated into safety-critical platforms. Consequently, an established body of literature has emerged that explores adversarial attacks targeting the underlying machine learning models. Adapting adversarial attacks to the physical world is desirable for the attacker, as this removes the need to compromise digital systems. However, the real world poses challenges related to the \"survivability\" of adversarial manipulations given environmental noise in perception pipelines and the dynamicity of autonomous systems. In this paper, we take a sensor-first approach. We present EvilEye, a man-in-the-middle perception attack that leverages transparent displays to generate dynamic physical adversarial examples. EvilEye exploits the camera's optics to induce misclassifications under a variety of illumination conditions. To generate dynamic perturbations, we formalize the projection of a digital attack into the ph",
    "link": "http://arxiv.org/abs/2307.13131",
    "context": "Title: Why Don't You Clean Your Glasses? Perception Attacks with Dynamic Optical Perturbations. (arXiv:2307.13131v1 [cs.CR])\nAbstract: Camera-based autonomous systems that emulate human perception are increasingly being integrated into safety-critical platforms. Consequently, an established body of literature has emerged that explores adversarial attacks targeting the underlying machine learning models. Adapting adversarial attacks to the physical world is desirable for the attacker, as this removes the need to compromise digital systems. However, the real world poses challenges related to the \"survivability\" of adversarial manipulations given environmental noise in perception pipelines and the dynamicity of autonomous systems. In this paper, we take a sensor-first approach. We present EvilEye, a man-in-the-middle perception attack that leverages transparent displays to generate dynamic physical adversarial examples. EvilEye exploits the camera's optics to induce misclassifications under a variety of illumination conditions. To generate dynamic perturbations, we formalize the projection of a digital attack into the ph",
    "path": "papers/23/07/2307.13131.json",
    "total_tokens": 856,
    "translated_title": "为什么你不清洁眼镜？利用动态光学扰动进行感知攻击",
    "translated_abstract": "摄像头为基础的模拟人类感知的自主系统越来越多地被集成到安全关键的平台中。因此，已经出现了一个稳定的文献体系，探索对底层机器学习模型进行敌对攻击。将敌对攻击适应于现实世界对攻击者来说是可取的，因为这消除了危害数字系统的需要。然而，真实世界面临着与感知管道中的环境噪声和自主系统的动态性有关的挑战。在本文中，我们采用传感器为先的方法。我们提出了EvilEye，一种利用透明显示器生成动态物理敌对示例的中间人感知攻击。EvilEye利用摄像头的光学特性在各种照明条件下诱导错误分类。为了生成动态扰动，我们将数字攻击的投影形式化为光学视觉逆向问题。",
    "tldr": "本文提出了EvilEye，利用透明显示器生成动态物理敌对示例的感知攻击方法，通过利用摄像头的光学特性在多种照明条件下诱导错误分类。"
}