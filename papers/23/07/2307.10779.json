{
    "title": "Efficient Beam Tree Recursion. (arXiv:2307.10779v1 [cs.LG])",
    "abstract": "Beam Tree Recursive Neural Network (BT-RvNN) was recently proposed as a simple extension of Gumbel Tree RvNN and it was shown to achieve state-of-the-art length generalization performance in ListOps while maintaining comparable performance on other tasks. However, although not the worst in its kind, BT-RvNN can be still exorbitantly expensive in memory usage. In this paper, we identify the main bottleneck in BT-RvNN's memory usage to be the entanglement of the scorer function and the recursive cell function. We propose strategies to remove this bottleneck and further simplify its memory usage. Overall, our strategies not only reduce the memory usage of BT-RvNN by $10$-$16$ times but also create a new state-of-the-art in ListOps while maintaining similar performance in other tasks. In addition, we also propose a strategy to utilize the induced latent-tree node representations produced by BT-RvNN to turn BT-RvNN from a sentence encoder of the form $f:\\mathbb{R}^{n \\times d} \\rightarrow \\",
    "link": "http://arxiv.org/abs/2307.10779",
    "context": "Title: Efficient Beam Tree Recursion. (arXiv:2307.10779v1 [cs.LG])\nAbstract: Beam Tree Recursive Neural Network (BT-RvNN) was recently proposed as a simple extension of Gumbel Tree RvNN and it was shown to achieve state-of-the-art length generalization performance in ListOps while maintaining comparable performance on other tasks. However, although not the worst in its kind, BT-RvNN can be still exorbitantly expensive in memory usage. In this paper, we identify the main bottleneck in BT-RvNN's memory usage to be the entanglement of the scorer function and the recursive cell function. We propose strategies to remove this bottleneck and further simplify its memory usage. Overall, our strategies not only reduce the memory usage of BT-RvNN by $10$-$16$ times but also create a new state-of-the-art in ListOps while maintaining similar performance in other tasks. In addition, we also propose a strategy to utilize the induced latent-tree node representations produced by BT-RvNN to turn BT-RvNN from a sentence encoder of the form $f:\\mathbb{R}^{n \\times d} \\rightarrow \\",
    "path": "papers/23/07/2307.10779.json",
    "total_tokens": 960,
    "translated_title": "高效的Beam Tree递归",
    "translated_abstract": "最近提出的Beam Tree递归神经网络（BT-RvNN）是Gumbel Tree RvNN的简单扩展，已经在ListOps中取得了最先进的长度泛化性能，同时在其他任务上保持了可比较的性能。然而，尽管不是最差的，但BT-RvNN的内存使用仍然非常昂贵。在本文中，我们确定了BT-RvNN内存使用的主要瓶颈是评分函数和递归单元函数的纠缠。我们提出了策略来解决这个瓶颈，并进一步简化内存使用。总体上，我们的策略不仅将BT-RvNN的内存使用减少了10-16倍，而且在ListOps中创造了新的最先进水平，同时在其他任务中保持了类似的性能。此外，我们还提出了一种利用BT-RvNN产生的引导隐层树节点表示的策略，将BT-RvNN从形式为f：R^n×d ->的句子编码器转换成。”",
    "tldr": "本文提出了一种高效的Beam Tree递归算法（BT-RvNN），通过解决评分函数和递归单元函数的纠缠问题以及简化内存使用，成功降低了BT-RvNN的内存使用。这个算法在ListOps任务中达到了新的最先进水平，并在其他任务中保持了类似的性能。",
    "en_tdlr": "This paper proposes an efficient Beam Tree Recursive Neural Network (BT-RvNN) algorithm, which significantly reduces the memory usage by addressing the entanglement between the scorer function and the recursive cell function, as well as simplifying the memory usage. The algorithm achieves a new state-of-the-art performance in the ListOps task and maintains comparable performance in other tasks."
}