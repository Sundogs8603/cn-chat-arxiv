{
    "title": "Multi-Task Learning Improves Performance In Deep Argument Mining Models. (arXiv:2307.01401v1 [cs.CL])",
    "abstract": "The successful analysis of argumentative techniques from user-generated text is central to many downstream tasks such as political and market analysis. Recent argument mining tools use state-of-the-art deep learning methods to extract and annotate argumentative techniques from various online text corpora, however each task is treated as separate and different bespoke models are fine-tuned for each dataset. We show that different argument mining tasks share common semantic and logical structure by implementing a multi-task approach to argument mining that achieves better performance than state-of-the-art methods for the same problems. Our model builds a shared representation of the input text that is common to all tasks and exploits similarities between tasks in order to further boost performance via parameter-sharing. Our results are important for argument mining as they show that different tasks share substantial similarities and suggest a holistic approach to the extraction of argume",
    "link": "http://arxiv.org/abs/2307.01401",
    "context": "Title: Multi-Task Learning Improves Performance In Deep Argument Mining Models. (arXiv:2307.01401v1 [cs.CL])\nAbstract: The successful analysis of argumentative techniques from user-generated text is central to many downstream tasks such as political and market analysis. Recent argument mining tools use state-of-the-art deep learning methods to extract and annotate argumentative techniques from various online text corpora, however each task is treated as separate and different bespoke models are fine-tuned for each dataset. We show that different argument mining tasks share common semantic and logical structure by implementing a multi-task approach to argument mining that achieves better performance than state-of-the-art methods for the same problems. Our model builds a shared representation of the input text that is common to all tasks and exploits similarities between tasks in order to further boost performance via parameter-sharing. Our results are important for argument mining as they show that different tasks share substantial similarities and suggest a holistic approach to the extraction of argume",
    "path": "papers/23/07/2307.01401.json",
    "total_tokens": 830,
    "translated_title": "多任务学习提高深度论证挖掘模型的性能",
    "translated_abstract": "成功地从用户生成的文本中分析论证技巧对于许多下游任务（如政治和市场分析）至关重要。最近的论证挖掘工具使用先进的深度学习方法从各种在线文本语料库中提取和注释论证技巧，然而每个任务被视为独立的，不同的特定模型被针对每个数据集进行了微调。我们通过实施多任务方法来论证挖掘，表明不同的论证挖掘任务之间共享常见的语义和逻辑结构，这种方法在解决相同问题时达到了比最先进方法更好的性能。我们的模型构建了一个对所有任务都共有的输入文本的共享表示，并通过参数共享利用任务之间的相似性进一步提高性能。我们的结果对于论证挖掘非常重要，因为它们表明不同的任务之间存在相当大的相似之处，并提出了一种整体的论证提取方法。",
    "tldr": "多任务学习方法提高了深度论证挖掘模型的性能，通过构建共享表示并利用任务之间的相似性，这种方法在不同的论证挖掘任务上取得了更好的成果。"
}