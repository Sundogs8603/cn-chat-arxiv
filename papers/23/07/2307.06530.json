{
    "title": "Exploring the Integration of Large Language Models into Automatic Speech Recognition Systems: An Empirical Study. (arXiv:2307.06530v1 [cs.CL])",
    "abstract": "This paper explores the integration of Large Language Models (LLMs) into Automatic Speech Recognition (ASR) systems to improve transcription accuracy. The increasing sophistication of LLMs, with their in-context learning capabilities and instruction-following behavior, has drawn significant attention in the field of Natural Language Processing (NLP). Our primary focus is to investigate the potential of using an LLM's in-context learning capabilities to enhance the performance of ASR systems, which currently face challenges such as ambient noise, speaker accents, and complex linguistic contexts. We designed a study using the Aishell-1 and LibriSpeech datasets, with ChatGPT and GPT-4 serving as benchmarks for LLM capabilities. Unfortunately, our initial experiments did not yield promising results, indicating the complexity of leveraging LLM's in-context learning for ASR applications. Despite further exploration with varied settings and models, the corrected sentences from the LLMs freque",
    "link": "http://arxiv.org/abs/2307.06530",
    "context": "Title: Exploring the Integration of Large Language Models into Automatic Speech Recognition Systems: An Empirical Study. (arXiv:2307.06530v1 [cs.CL])\nAbstract: This paper explores the integration of Large Language Models (LLMs) into Automatic Speech Recognition (ASR) systems to improve transcription accuracy. The increasing sophistication of LLMs, with their in-context learning capabilities and instruction-following behavior, has drawn significant attention in the field of Natural Language Processing (NLP). Our primary focus is to investigate the potential of using an LLM's in-context learning capabilities to enhance the performance of ASR systems, which currently face challenges such as ambient noise, speaker accents, and complex linguistic contexts. We designed a study using the Aishell-1 and LibriSpeech datasets, with ChatGPT and GPT-4 serving as benchmarks for LLM capabilities. Unfortunately, our initial experiments did not yield promising results, indicating the complexity of leveraging LLM's in-context learning for ASR applications. Despite further exploration with varied settings and models, the corrected sentences from the LLMs freque",
    "path": "papers/23/07/2307.06530.json",
    "total_tokens": 884,
    "translated_title": "探索将大型语言模型集成到自动语音识别系统中的实证研究",
    "translated_abstract": "本文探讨了将大型语言模型（LLMs）集成到自动语音识别（ASR）系统中以提高转录准确性的问题。LLMs的不断发展，以其上下文学习能力和遵循指令的行为引起了自然语言处理（NLP）领域的极大关注。我们的主要重点是研究利用LLM的上下文学习能力来提升ASR系统性能的潜力，目前这些系统面临环境噪音、说话人口音和复杂语言环境等挑战。我们使用Aishell-1和LibriSpeech数据集设计了一项研究，ChatGPT和GPT-4作为LLM能力的基准。不幸的是，我们的初步实验结果并不理想，表明利用LLM的上下文学习来进行ASR应用的复杂性。尽管我们进一步尝试了不同的设置和模型，但LLMs纠正的句子频繁出错。",
    "tldr": "本文探讨了将大型语言模型集成到自动语音识别系统以提高准确性的问题，研究结果显示利用语言模型的上下文学习来进行ASR应用仍面临挑战。",
    "en_tdlr": "This paper explores the integration of large language models into automatic speech recognition systems to improve accuracy, and the results indicate challenges in leveraging context learning for ASR applications."
}