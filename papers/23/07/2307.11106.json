{
    "title": "The importance of feature preprocessing for differentially private linear optimization. (arXiv:2307.11106v1 [cs.LG])",
    "abstract": "Training machine learning models with differential privacy (DP) has received increasing interest in recent years. One of the most popular algorithms for training differentially private models is differentially private stochastic gradient descent (DPSGD) and its variants, where at each step gradients are clipped and combined with some noise. Given the increasing usage of DPSGD, we ask the question: is DPSGD alone sufficient to find a good minimizer for every dataset under privacy constraints? As a first step towards answering this question, we show that even for the simple case of linear classification, unlike non-private optimization, (private) feature preprocessing is vital for differentially private optimization. In detail, we first show theoretically that there exists an example where without feature preprocessing, DPSGD incurs a privacy error proportional to the maximum norm of features over all samples. We then propose an algorithm called DPSGD-F, which combines DPSGD with feature",
    "link": "http://arxiv.org/abs/2307.11106",
    "context": "Title: The importance of feature preprocessing for differentially private linear optimization. (arXiv:2307.11106v1 [cs.LG])\nAbstract: Training machine learning models with differential privacy (DP) has received increasing interest in recent years. One of the most popular algorithms for training differentially private models is differentially private stochastic gradient descent (DPSGD) and its variants, where at each step gradients are clipped and combined with some noise. Given the increasing usage of DPSGD, we ask the question: is DPSGD alone sufficient to find a good minimizer for every dataset under privacy constraints? As a first step towards answering this question, we show that even for the simple case of linear classification, unlike non-private optimization, (private) feature preprocessing is vital for differentially private optimization. In detail, we first show theoretically that there exists an example where without feature preprocessing, DPSGD incurs a privacy error proportional to the maximum norm of features over all samples. We then propose an algorithm called DPSGD-F, which combines DPSGD with feature",
    "path": "papers/23/07/2307.11106.json",
    "total_tokens": 990,
    "translated_title": "特征预处理对差分隐私线性优化的重要性",
    "translated_abstract": "在最近几年中，使用差分隐私（DP）训练机器学习模型引起了越来越多的关注。其中最流行的用于训练差分隐私模型的算法之一是差分隐私随机梯度下降（DPSGD）及其变种，在每个步骤中，梯度被剪裁并与一些噪音结合。鉴于DPSGD的广泛使用，我们提出一个问题：在隐私约束下，仅仅使用DPSGD是否足以找到每个数据集的良好极小值点？作为回答这个问题的第一步，我们展示了即使对于简单的线性分类情况，与非隐私优化相比，（私有）特征预处理对于差分隐私优化是至关重要的。具体而言，我们首先从理论上证明了存在一种例子，在没有特征预处理的情况下，DPSGD会产生与所有样本上的特征的最大范数成比例的隐私错误。然后，我们提出了一种名为DPSGD-F的算法，将DPSGD与特征预处理结合起来。",
    "tldr": "本论文研究了差分隐私线性优化中特征预处理的重要性。在简单的线性分类情况下，与非隐私优化相比，特征预处理对于差分隐私优化是至关重要的，否则会产生与特征最大范数成比例的隐私错误。我们提出了一种结合特征预处理的算法DPSGD-F。",
    "en_tdlr": "This paper investigates the importance of feature preprocessing in differentially private linear optimization. In the case of linear classification, feature preprocessing is vital for differentially private optimization, as it prevents privacy errors proportional to the maximum norm of features. The proposed algorithm, DPSGD-F, combines differential private stochastic gradient descent (DPSGD) with feature preprocessing."
}