{
    "title": "Analyzing and Improving Greedy 2-Coordinate Updates for Equality-Constrained Optimization via Steepest Descent in the 1-Norm. (arXiv:2307.01169v1 [math.OC])",
    "abstract": "We consider minimizing a smooth function subject to a summation constraint over its variables. By exploiting a connection between the greedy 2-coordinate update for this problem and equality-constrained steepest descent in the 1-norm, we give a convergence rate for greedy selection under a proximal Polyak-Lojasiewicz assumption that is faster than random selection and independent of the problem dimension $n$. We then consider minimizing with both a summation constraint and bound constraints, as arises in the support vector machine dual problem. Existing greedy rules for this setting either guarantee trivial progress only or require $O(n^2)$ time to compute. We show that boundand summation-constrained steepest descent in the L1-norm guarantees more progress per iteration than previous rules and can be computed in only $O(n \\log n)$ time.",
    "link": "http://arxiv.org/abs/2307.01169",
    "context": "Title: Analyzing and Improving Greedy 2-Coordinate Updates for Equality-Constrained Optimization via Steepest Descent in the 1-Norm. (arXiv:2307.01169v1 [math.OC])\nAbstract: We consider minimizing a smooth function subject to a summation constraint over its variables. By exploiting a connection between the greedy 2-coordinate update for this problem and equality-constrained steepest descent in the 1-norm, we give a convergence rate for greedy selection under a proximal Polyak-Lojasiewicz assumption that is faster than random selection and independent of the problem dimension $n$. We then consider minimizing with both a summation constraint and bound constraints, as arises in the support vector machine dual problem. Existing greedy rules for this setting either guarantee trivial progress only or require $O(n^2)$ time to compute. We show that boundand summation-constrained steepest descent in the L1-norm guarantees more progress per iteration than previous rules and can be computed in only $O(n \\log n)$ time.",
    "path": "papers/23/07/2307.01169.json",
    "total_tokens": 925,
    "translated_title": "通过最速下降法分析和改进基于贪婪的二维坐标更新在等式约束优化中的应用",
    "translated_abstract": "本文考虑在变量的求和约束下最小化一个平滑函数。通过利用贪婪的2维坐标更新与等式约束的最速下降法之间的联系，我们给出了一个收敛速度，该速度在满足近端Polyak-Lojasiewicz条件下比随机选择更快，并且与问题维度n无关。然后，我们考虑同时具有求和约束和边界约束的最小化问题，这在支持向量机对偶问题中出现。现有的贪婪规则要么只能保证微小的进展，要么需要O(n^2)的计算时间。我们证明了边界和求和约束的L1-范数最速下降法在每次迭代中可以比以前的规则取得更多的进展，并且可以在O(n log n)的时间内计算。",
    "tldr": "通过最速下降法，我们在等式约束优化问题中探索并改进了贪婪的二维坐标更新方法，在满足特定条件下取得了更快的收敛速度。此外，我们还将该方法推广到同时具有求和约束和边界约束的问题，并证明了在L1-范数下的最速下降法可以在更短的计算时间内取得更多的进展。",
    "en_tdlr": "We analyze and improve the greedy 2-coordinate updates for equality-constrained optimization using steepest descent method, achieving faster convergence rate under specific conditions. We extend this approach to problems with both summation and bound constraints, demonstrating that steepest descent in the L1-norm leads to more progress per iteration in less computation time."
}