{
    "title": "Learning from Exemplary Explanations. (arXiv:2307.06026v1 [cs.LG])",
    "abstract": "eXplanation Based Learning (XBL) is a form of Interactive Machine Learning (IML) that provides a model refining approach via user feedback collected on model explanations. Although the interactivity of XBL promotes model transparency, XBL requires a huge amount of user interaction and can become expensive as feedback is in the form of detailed annotation rather than simple category labelling which is more common in IML. This expense is exacerbated in high stakes domains such as medical image classification. To reduce the effort and expense of XBL we introduce a new approach that uses two input instances and their corresponding Gradient Weighted Class Activation Mapping (GradCAM) model explanations as exemplary explanations to implement XBL. Using a medical image classification task, we demonstrate that, using minimal human input, our approach produces improved explanations (+0.02, +3%) and achieves reduced classification performance (-0.04, -4%) when compared against a model trained wi",
    "link": "http://arxiv.org/abs/2307.06026",
    "context": "Title: Learning from Exemplary Explanations. (arXiv:2307.06026v1 [cs.LG])\nAbstract: eXplanation Based Learning (XBL) is a form of Interactive Machine Learning (IML) that provides a model refining approach via user feedback collected on model explanations. Although the interactivity of XBL promotes model transparency, XBL requires a huge amount of user interaction and can become expensive as feedback is in the form of detailed annotation rather than simple category labelling which is more common in IML. This expense is exacerbated in high stakes domains such as medical image classification. To reduce the effort and expense of XBL we introduce a new approach that uses two input instances and their corresponding Gradient Weighted Class Activation Mapping (GradCAM) model explanations as exemplary explanations to implement XBL. Using a medical image classification task, we demonstrate that, using minimal human input, our approach produces improved explanations (+0.02, +3%) and achieves reduced classification performance (-0.04, -4%) when compared against a model trained wi",
    "path": "papers/23/07/2307.06026.json",
    "total_tokens": 915,
    "translated_title": "从优秀解释中学习",
    "translated_abstract": "解释式学习（XBL）是一种交互式机器学习（IML）形式，通过用户反馈收集的模型解释，提供了一种模型细化方法。尽管XBL的交互性促进了模型的透明性，但XBL需要大量的用户交互，并且在高成本领域，如医学图像分类中，由于反馈以详细注释形式而非简单的类别标注，这种成本会加剧。为了减少XBL的工作量和成本，我们引入了一种新方法，该方法利用两个输入实例及其相应的梯度加权类激活映射（GradCAM）模型解释作为优秀解释来实现XBL。通过医学图像分类任务，我们证明，使用最少的人工输入，我们的方法产生了改进的解释（+0.02，+3%），并在与仅使用模型训练的模型相比时，实现了分类性能的降低（-0.04，-4%）。",
    "tldr": "本论文介绍了一种基于优秀解释的学习方法，通过使用两个输入实例和其相应的梯度加权类激活映射（GradCAM）模型解释，可以在减少用户交互的情况下改善解释性学习的效果，并在医学图像分类任务中实现了更好的解释和较小的分类性能损失。",
    "en_tdlr": "This paper introduces a learning method based on exemplary explanations, which improves interpretability learning with minimal user interaction by using two input instances and their corresponding GradCAM model explanations, and achieves better explanations and smaller classification performance loss in medical image classification tasks."
}