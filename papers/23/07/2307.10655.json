{
    "title": "A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency. (arXiv:2307.10655v1 [cs.LG])",
    "abstract": "Federated learning (FL) has emerged as a highly effective paradigm for privacy-preserving collaborative training among different parties. Unlike traditional centralized learning, which requires collecting data from each party, FL allows clients to share privacy-preserving information without exposing private datasets. This approach not only guarantees enhanced privacy protection but also facilitates more efficient and secure collaboration among multiple participants. Therefore, FL has gained considerable attention from researchers, promoting numerous surveys to summarize the related works. However, the majority of these surveys concentrate on methods sharing model parameters during the training process, while overlooking the potential of sharing other forms of local information. In this paper, we present a systematic survey from a new perspective, i.e., what to share in FL, with an emphasis on the model utility, privacy leakage, and communication efficiency. This survey differs from pr",
    "link": "http://arxiv.org/abs/2307.10655",
    "context": "Title: A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency. (arXiv:2307.10655v1 [cs.LG])\nAbstract: Federated learning (FL) has emerged as a highly effective paradigm for privacy-preserving collaborative training among different parties. Unlike traditional centralized learning, which requires collecting data from each party, FL allows clients to share privacy-preserving information without exposing private datasets. This approach not only guarantees enhanced privacy protection but also facilitates more efficient and secure collaboration among multiple participants. Therefore, FL has gained considerable attention from researchers, promoting numerous surveys to summarize the related works. However, the majority of these surveys concentrate on methods sharing model parameters during the training process, while overlooking the potential of sharing other forms of local information. In this paper, we present a systematic survey from a new perspective, i.e., what to share in FL, with an emphasis on the model utility, privacy leakage, and communication efficiency. This survey differs from pr",
    "path": "papers/23/07/2307.10655.json",
    "total_tokens": 813,
    "translated_title": "在联邦学习中分享什么：模型效用、隐私泄露和通信效率的视角综述",
    "translated_abstract": "联邦学习（FL）已成为一种高效的隐私保护合作训练范式，可以在不暴露私有数据集的情况下，允许客户端共享隐私保护信息。这种方法不仅保证了增强的隐私保护，而且促进了多方之间更高效、更安全的合作。因此，FL引起了研究人员的广泛关注，推动了许多综述性文章对相关工作进行总结。然而，大多数综述集中于在训练过程中共享模型参数的方法，而忽视了共享其他形式的本地信息的潜力。本文从一种新的视角出发，即在FL中分享什么，重点关注模型效用、隐私泄露和通信效率，进行了系统综述。",
    "tldr": "本文介绍了一篇系统综述，从新的视角探讨了在联邦学习中应该分享什么，注重模型效用、隐私泄露和通信效率。",
    "en_tdlr": "This paper presents a systematic survey that explores from a new perspective what to share in federated learning, with a focus on model utility, privacy leakage, and communication efficiency."
}