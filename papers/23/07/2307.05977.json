{
    "title": "Towards Safe Self-Distillation of Internet-Scale Text-to-Image Diffusion Models. (arXiv:2307.05977v1 [cs.CV])",
    "abstract": "Large-scale image generation models, with impressive quality made possible by the vast amount of data available on the Internet, raise social concerns that these models may generate harmful or copyrighted content. The biases and harmfulness arise throughout the entire training process and are hard to completely remove, which have become significant hurdles to the safe deployment of these models. In this paper, we propose a method called SDD to prevent problematic content generation in text-to-image diffusion models. We self-distill the diffusion model to guide the noise estimate conditioned on the target removal concept to match the unconditional one. Compared to the previous methods, our method eliminates a much greater proportion of harmful content from the generated images without degrading the overall image quality. Furthermore, our method allows the removal of multiple concepts at once, whereas previous works are limited to removing a single concept at a time.",
    "link": "http://arxiv.org/abs/2307.05977",
    "context": "Title: Towards Safe Self-Distillation of Internet-Scale Text-to-Image Diffusion Models. (arXiv:2307.05977v1 [cs.CV])\nAbstract: Large-scale image generation models, with impressive quality made possible by the vast amount of data available on the Internet, raise social concerns that these models may generate harmful or copyrighted content. The biases and harmfulness arise throughout the entire training process and are hard to completely remove, which have become significant hurdles to the safe deployment of these models. In this paper, we propose a method called SDD to prevent problematic content generation in text-to-image diffusion models. We self-distill the diffusion model to guide the noise estimate conditioned on the target removal concept to match the unconditional one. Compared to the previous methods, our method eliminates a much greater proportion of harmful content from the generated images without degrading the overall image quality. Furthermore, our method allows the removal of multiple concepts at once, whereas previous works are limited to removing a single concept at a time.",
    "path": "papers/23/07/2307.05977.json",
    "total_tokens": 911,
    "translated_title": "实现互联网规模的文本到图像扩散模型的安全自蒸馏",
    "translated_abstract": "大规模图像生成模型借助互联网上丰富的数据具有卓越的质量，但也引发了社会关切，担心这些模型可能生成有害或受版权保护的内容。这些偏见和有害性在整个训练过程中产生，并且很难完全消除，这已成为安全部署这些模型的重要障碍。本文提出了一种名为SDD的方法，用于在文本到图像扩散模型中防止问题内容的生成。我们通过自蒸馏扩散模型来引导基于目标移除概念的噪声估计与无条件模型匹配。与之前的方法相比，我们的方法可以消除更大比例的有害内容，同时不降低整体图像质量。此外，我们的方法还允许一次移除多个概念，而之前的工作只能一次移除一个概念。",
    "tldr": "本文介绍了一种名为SDD的方法，用于实现互联网规模的文本到图像扩散模型的安全自蒸馏。该方法通过引导噪声估计与无条件模型匹配，在生成的图像中消除有害内容的比例更大，同时保持整体图像质量，并且允许一次移除多个概念。",
    "en_tdlr": "This paper proposes a method called SDD for safe self-distillation of internet-scale text-to-image diffusion models. The method eliminates a greater proportion of harmful content from generated images while maintaining overall image quality, and allows for the removal of multiple concepts at once."
}