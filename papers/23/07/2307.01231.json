{
    "title": "A Critical Re-evaluation of Benchmark Datasets for (Deep) Learning-Based Matching Algorithms. (arXiv:2307.01231v1 [cs.DB])",
    "abstract": "Entity resolution (ER) is the process of identifying records that refer to the same entities within one or across multiple databases. Numerous techniques have been developed to tackle ER challenges over the years, with recent emphasis placed on machine and deep learning methods for the matching phase. However, the quality of the benchmark datasets typically used in the experimental evaluations of learning-based matching algorithms has not been examined in the literature. To cover this gap, we propose four different approaches to assessing the difficulty and appropriateness of 13 established datasets: two theoretical approaches, which involve new measures of linearity and existing measures of complexity, and two practical approaches: the difference between the best non-linear and linear matchers, as well as the difference between the best learning-based matcher and the perfect oracle. Our analysis demonstrates that most of the popular datasets pose rather easy classification tasks. As a",
    "link": "http://arxiv.org/abs/2307.01231",
    "context": "Title: A Critical Re-evaluation of Benchmark Datasets for (Deep) Learning-Based Matching Algorithms. (arXiv:2307.01231v1 [cs.DB])\nAbstract: Entity resolution (ER) is the process of identifying records that refer to the same entities within one or across multiple databases. Numerous techniques have been developed to tackle ER challenges over the years, with recent emphasis placed on machine and deep learning methods for the matching phase. However, the quality of the benchmark datasets typically used in the experimental evaluations of learning-based matching algorithms has not been examined in the literature. To cover this gap, we propose four different approaches to assessing the difficulty and appropriateness of 13 established datasets: two theoretical approaches, which involve new measures of linearity and existing measures of complexity, and two practical approaches: the difference between the best non-linear and linear matchers, as well as the difference between the best learning-based matcher and the perfect oracle. Our analysis demonstrates that most of the popular datasets pose rather easy classification tasks. As a",
    "path": "papers/23/07/2307.01231.json",
    "total_tokens": 823,
    "translated_title": "对(深度)学习匹配算法的基准数据集的关键重新评估",
    "translated_abstract": "实体解析(ER)是识别在一个或多个数据库中指向相同实体的记录的过程。多年来，已经开发了许多技术来解决ER挑战，近年来，机器学习和深度学习方法在匹配阶段受到了重视。然而，在文献中尚未对实验评估中常用的学习匹配算法的基准数据集的质量进行检查。为了弥补这个空白，我们提出了四种不同的方法来评估13个已建立数据集的难度和适用性：两种理论方法，涉及新的线性度量和现有的复杂度度量，以及两种实际方法：最佳非线性和线性匹配器之间的差异，以及最佳学习匹配器和完美预测器之间的差异。我们的分析表明，大多数流行数据集都提出了相当简单的分类任务。",
    "tldr": "本研究重新评估了(深度)学习匹配算法的基准数据集，发现其中大多数数据集都属于相对简单的分类任务。"
}