{
    "title": "Cross-Modal Content Inference and Feature Enrichment for Cold-Start Recommendation. (arXiv:2307.02761v1 [cs.IR])",
    "abstract": "Multimedia recommendation aims to fuse the multi-modal information of items for feature enrichment to improve the recommendation performance. However, existing methods typically introduce multi-modal information based on collaborative information to improve the overall recommendation precision, while failing to explore its cold-start recommendation performance. Meanwhile, these above methods are only applicable when such multi-modal data is available. To address this problem, this paper proposes a recommendation framework, named Cross-modal Content Inference and Feature Enrichment Recommendation (CIERec), which exploits the multi-modal information to improve its cold-start recommendation performance. Specifically, CIERec first introduces image annotation as the privileged information to help guide the mapping of unified features from the visual space to the semantic space in the training phase. And then CIERec enriches the content representation with the fusion of collaborative, visual",
    "link": "http://arxiv.org/abs/2307.02761",
    "context": "Title: Cross-Modal Content Inference and Feature Enrichment for Cold-Start Recommendation. (arXiv:2307.02761v1 [cs.IR])\nAbstract: Multimedia recommendation aims to fuse the multi-modal information of items for feature enrichment to improve the recommendation performance. However, existing methods typically introduce multi-modal information based on collaborative information to improve the overall recommendation precision, while failing to explore its cold-start recommendation performance. Meanwhile, these above methods are only applicable when such multi-modal data is available. To address this problem, this paper proposes a recommendation framework, named Cross-modal Content Inference and Feature Enrichment Recommendation (CIERec), which exploits the multi-modal information to improve its cold-start recommendation performance. Specifically, CIERec first introduces image annotation as the privileged information to help guide the mapping of unified features from the visual space to the semantic space in the training phase. And then CIERec enriches the content representation with the fusion of collaborative, visual",
    "path": "papers/23/07/2307.02761.json",
    "total_tokens": 870,
    "translated_title": "跨模态内容推理与特征增强用于冷启动推荐",
    "translated_abstract": "多媒体推荐旨在融合物品的多模态信息，通过特征增强来提高推荐性能。然而，现有方法通常基于协同信息引入多模态信息，以提高整体推荐精度，但未探索冷启动推荐性能。同时，这些方法仅适用于当有多模态数据可用时。为解决这个问题，本文提出了一个推荐框架，命名为跨模态内容推理与特征增强推荐 (CIERec)，它利用多模态信息来改善其冷启动推荐性能。具体而言，CIERec首先在训练阶段引入图像注释作为特权信息，以帮助指导从视觉空间到语义空间的统一特征映射。然后，CIERec通过协同、视觉和语义信息的融合来增强内容表示。",
    "tldr": "本文提出了一个推荐框架，名为跨模态内容推理与特征增强推荐 (CIERec)，利用多模态信息来改善冷启动推荐性能，引入图像注释作为特权信息，通过融合协同、视觉和语义信息来增强内容表示。"
}