{
    "title": "Hate Speech Detection via Dual Contrastive Learning. (arXiv:2307.05578v1 [cs.CL])",
    "abstract": "The fast spread of hate speech on social media impacts the Internet environment and our society by increasing prejudice and hurting people. Detecting hate speech has aroused broad attention in the field of natural language processing. Although hate speech detection has been addressed in recent work, this task still faces two inherent unsolved challenges. The first challenge lies in the complex semantic information conveyed in hate speech, particularly the interference of insulting words in hate speech detection. The second challenge is the imbalanced distribution of hate speech and non-hate speech, which may significantly deteriorate the performance of models. To tackle these challenges, we propose a novel dual contrastive learning (DCL) framework for hate speech detection. Our framework jointly optimizes the self-supervised and the supervised contrastive learning loss for capturing span-level information beyond the token-level emotional semantics used in existing models, particularly ",
    "link": "http://arxiv.org/abs/2307.05578",
    "context": "Title: Hate Speech Detection via Dual Contrastive Learning. (arXiv:2307.05578v1 [cs.CL])\nAbstract: The fast spread of hate speech on social media impacts the Internet environment and our society by increasing prejudice and hurting people. Detecting hate speech has aroused broad attention in the field of natural language processing. Although hate speech detection has been addressed in recent work, this task still faces two inherent unsolved challenges. The first challenge lies in the complex semantic information conveyed in hate speech, particularly the interference of insulting words in hate speech detection. The second challenge is the imbalanced distribution of hate speech and non-hate speech, which may significantly deteriorate the performance of models. To tackle these challenges, we propose a novel dual contrastive learning (DCL) framework for hate speech detection. Our framework jointly optimizes the self-supervised and the supervised contrastive learning loss for capturing span-level information beyond the token-level emotional semantics used in existing models, particularly ",
    "path": "papers/23/07/2307.05578.json",
    "total_tokens": 940,
    "translated_title": "恶意言论通过双对比学习进行检测",
    "translated_abstract": "恶意言论在社交媒体上的快速传播影响着互联网环境和我们的社会，增加了偏见并伤害了人们。检测恶意言论在自然语言处理领域引起了广泛关注。尽管最近的研究已经解决了恶意言论检测中的一些问题，但这个任务仍然面临着两个固有的未解决挑战。第一个挑战在于恶意言论中传达的复杂语义信息，特别是恶意言论检测中侮辱性言辞的干扰。第二个挑战是恶意言论和非恶意言论的不平衡分布，可能会严重损害模型的性能。为了解决这些挑战，我们提出了一种新颖的恶意言论检测双对比学习（DCL）框架。我们的框架通过联合优化自监督对比学习损失和有监督对比学习损失，捕捉超出现有模型中使用的基于令牌级情感语义的跨度级信息。",
    "tldr": "该论文提出了一种用于恶意言论检测的新颖框架，通过应对恶意言论中的复杂语义信息和恶意言辞的干扰以及恶意言论和非恶意言论的不平衡分布等挑战，实现了跨度级信息的捕捉。"
}