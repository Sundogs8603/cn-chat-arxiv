{
    "title": "Enhancing Human-like Multi-Modal Reasoning: A New Challenging Dataset and Comprehensive Framework. (arXiv:2307.12626v2 [cs.AI] UPDATED)",
    "abstract": "Multimodal reasoning is a critical component in the pursuit of artificial intelligence systems that exhibit human-like intelligence, especially when tackling complex tasks. While the chain-of-thought (CoT) technique has gained considerable attention, the existing ScienceQA dataset, which focuses on multimodal scientific questions and explanations from elementary and high school textbooks, lacks a comprehensive evaluation of diverse approaches. To address this gap, we present COCO Multi-Modal Reasoning(COCO-MMR) dataset, a novel dataset that encompasses an extensive collection of open-ended questions, rationales, and answers derived from the large object dataset COCO. Unlike previous datasets that rely on multiple-choice questions, our dataset pioneers the use of open-ended questions in the context of multimodal CoT, introducing a more challenging problem that effectively assesses the reasoning capability of CoT models. Through comprehensive evaluations and detailed analyses, we provide",
    "link": "http://arxiv.org/abs/2307.12626",
    "context": "Title: Enhancing Human-like Multi-Modal Reasoning: A New Challenging Dataset and Comprehensive Framework. (arXiv:2307.12626v2 [cs.AI] UPDATED)\nAbstract: Multimodal reasoning is a critical component in the pursuit of artificial intelligence systems that exhibit human-like intelligence, especially when tackling complex tasks. While the chain-of-thought (CoT) technique has gained considerable attention, the existing ScienceQA dataset, which focuses on multimodal scientific questions and explanations from elementary and high school textbooks, lacks a comprehensive evaluation of diverse approaches. To address this gap, we present COCO Multi-Modal Reasoning(COCO-MMR) dataset, a novel dataset that encompasses an extensive collection of open-ended questions, rationales, and answers derived from the large object dataset COCO. Unlike previous datasets that rely on multiple-choice questions, our dataset pioneers the use of open-ended questions in the context of multimodal CoT, introducing a more challenging problem that effectively assesses the reasoning capability of CoT models. Through comprehensive evaluations and detailed analyses, we provide",
    "path": "papers/23/07/2307.12626.json",
    "total_tokens": 944,
    "translated_title": "提升人类化多模态推理：一个新的具有挑战性的数据集和综合框架",
    "translated_abstract": "多模态推理是追求展示人类智能的人工智能系统中的关键组成部分，特别是在处理复杂任务时。虽然连续思维（Chain-of-Thought，CoT）技术已经引起了相当大的关注，但现有的ScienceQA数据集专注于多模态科学问题和基于小学和高中教科书的解释，缺乏对不同方法的全面评价。为了弥补这一空白，我们提出了COCO Multi-Modal Reasoning（COCO-MMR）数据集，这是一个包含了大量开放性问题、理由和答案的新颖数据集，这些问题、理由和答案是从大型对象数据集COCO中衍生出来的。与先前依赖多项选择问题的数据集不同，我们的数据集在多模态连续思维的背景下首次引入了开放性问题，引入了一个更具挑战性的问题，能够有效评估CoT模型的推理能力。通过全面的评估和详细的分析，我们提供了一些向该领域贡献的创新和理论基础。",
    "tldr": "提出了COCO-MMR数据集，该数据集是一个包含了大量开放性问题、理由和答案的新颖数据集，通过全面的评估和详细的分析，提供了一些向多模态推理领域贡献的创新和理论基础。"
}