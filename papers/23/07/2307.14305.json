{
    "title": "Automatically Evaluating Opinion Prevalence in Opinion Summarization. (arXiv:2307.14305v1 [cs.CL])",
    "abstract": "When faced with a large number of product reviews, it is not clear that a human can remember all of them and weight opinions representatively to write a good reference summary. We propose an automatic metric to test the prevalence of the opinions that a summary expresses, based on counting the number of reviews that are consistent with each statement in the summary, while discrediting trivial or redundant statements. To formulate this opinion prevalence metric, we consider several existing methods to score the factual consistency of a summary statement with respect to each individual source review. On a corpus of Amazon product reviews, we gather multiple human judgments of the opinion consistency, to determine which automatic metric best expresses consistency in product reviews. Using the resulting opinion prevalence metric, we show that a human authored summary has only slightly better opinion prevalence than randomly selected extracts from the source reviews, and previous extractive",
    "link": "http://arxiv.org/abs/2307.14305",
    "context": "Title: Automatically Evaluating Opinion Prevalence in Opinion Summarization. (arXiv:2307.14305v1 [cs.CL])\nAbstract: When faced with a large number of product reviews, it is not clear that a human can remember all of them and weight opinions representatively to write a good reference summary. We propose an automatic metric to test the prevalence of the opinions that a summary expresses, based on counting the number of reviews that are consistent with each statement in the summary, while discrediting trivial or redundant statements. To formulate this opinion prevalence metric, we consider several existing methods to score the factual consistency of a summary statement with respect to each individual source review. On a corpus of Amazon product reviews, we gather multiple human judgments of the opinion consistency, to determine which automatic metric best expresses consistency in product reviews. Using the resulting opinion prevalence metric, we show that a human authored summary has only slightly better opinion prevalence than randomly selected extracts from the source reviews, and previous extractive",
    "path": "papers/23/07/2307.14305.json",
    "total_tokens": 891,
    "translated_title": "自动评估意见总结中的意见普遍性",
    "translated_abstract": "当面对大量产品评论时，不清楚人类是否能记住所有评论并以代表性权重编写好的参考摘要。我们提出了一种自动度量标准来测试摘要所表达的意见普遍性，该标准基于统计与摘要中每个陈述一致的评论数量，同时贬低琐碎或冗余的陈述。为了制定这种意见普遍性度量标准，我们考虑了几种现有方法来评分摘要陈述相对于每个个体源评论的事实一致性。在亚马逊产品评论语料库上，我们收集了多个人对意见一致性的评判，以确定哪种自动度量标准最能表达产品评论的一致性。通过使用得到的意见普遍性度量标准，我们展示了人类编写的摘要与从源评论中随机选择的摘录相比只有稍微更好的意见普遍性，以及以前的摘录方法。",
    "tldr": "本论文提出了一种自动评估意见总结的意见普遍性的方法，通过统计与摘要陈述一致的评论数量，并排除琐碎或冗余的陈述。实验证明，人类编写的摘要在意见普遍性方面仅稍微优于从源评论中随机选择的摘录。"
}