{
    "title": "Realtime Spectrum Monitoring via Reinforcement Learning -- A Comparison Between Q-Learning and Heuristic Methods. (arXiv:2307.05763v1 [eess.SY])",
    "abstract": "Due to technological advances in the field of radio technology and its availability, the number of interference signals in the radio spectrum is continuously increasing. Interference signals must be detected in a timely fashion, in order to maintain standards and keep emergency frequencies open. To this end, specialized (multi-channel) receivers are used for spectrum monitoring. In this paper, the performances of two different approaches for controlling the available receiver resources are compared. The methods used for resource management (ReMa) are linear frequency tuning as a heuristic approach and a Q-learning algorithm from the field of reinforcement learning. To test the methods to be investigated, a simplified scenario was designed with two receiver channels monitoring ten non-overlapping frequency bands with non-uniform signal activity. For this setting, it is shown that the Q-learning algorithm used has a significantly higher detection rate than the heuristic approach at the e",
    "link": "http://arxiv.org/abs/2307.05763",
    "context": "Title: Realtime Spectrum Monitoring via Reinforcement Learning -- A Comparison Between Q-Learning and Heuristic Methods. (arXiv:2307.05763v1 [eess.SY])\nAbstract: Due to technological advances in the field of radio technology and its availability, the number of interference signals in the radio spectrum is continuously increasing. Interference signals must be detected in a timely fashion, in order to maintain standards and keep emergency frequencies open. To this end, specialized (multi-channel) receivers are used for spectrum monitoring. In this paper, the performances of two different approaches for controlling the available receiver resources are compared. The methods used for resource management (ReMa) are linear frequency tuning as a heuristic approach and a Q-learning algorithm from the field of reinforcement learning. To test the methods to be investigated, a simplified scenario was designed with two receiver channels monitoring ten non-overlapping frequency bands with non-uniform signal activity. For this setting, it is shown that the Q-learning algorithm used has a significantly higher detection rate than the heuristic approach at the e",
    "path": "papers/23/07/2307.05763.json",
    "total_tokens": 886,
    "translated_title": "通过强化学习实现的实时频谱监测--Q学习和启发式方法的比较",
    "translated_abstract": "由于无线电技术的技术进步和可用性，无线电频谱中干扰信号的数量不断增加。为了保持标准并保持紧急频率的开放，必须及时检测干扰信号。为此，使用专门的（多通道）接收器进行频谱监测。本文比较了两种不同的方法来控制可用接收器资源的性能。资源管理（ReMa）所使用的方法是线性频率调谐作为启发式方法和来自强化学习领域的Q学习算法。为了测试要研究的方法，设计了一个简化的场景，其中两个接收器通道监测十个非重叠的频带，具有非均匀的信号活动。对于这种设置，结果表明，在相同的环境下，Q学习算法比启发式方法有更高的检测率。",
    "tldr": "本文比较了线性频率调谐作为启发式方法和强化学习中的Q学习算法在实时频谱监测中的表现，研究表明在非均匀信号活动的场景下，使用Q学习算法的检测率显著高于启发式方法。",
    "en_tdlr": "This paper compares the performances of linear frequency tuning as a heuristic method and Q-learning algorithm from reinforcement learning in realtime spectrum monitoring, and it shows that in scenarios with non-uniform signal activity, the detection rate using the Q-learning algorithm is significantly higher than the heuristic method."
}