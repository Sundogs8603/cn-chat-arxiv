{
    "title": "Self-Supervised Learning with Lie Symmetries for Partial Differential Equations. (arXiv:2307.05432v1 [cs.LG])",
    "abstract": "Machine learning for differential equations paves the way for computationally efficient alternatives to numerical solvers, with potentially broad impacts in science and engineering. Though current algorithms typically require simulated training data tailored to a given setting, one may instead wish to learn useful information from heterogeneous sources, or from real dynamical systems observations that are messy or incomplete. In this work, we learn general-purpose representations of PDEs from heterogeneous data by implementing joint embedding methods for self-supervised learning (SSL), a framework for unsupervised representation learning that has had notable success in computer vision. Our representation outperforms baseline approaches to invariant tasks, such as regressing the coefficients of a PDE, while also improving the time-stepping performance of neural solvers. We hope that our proposed methodology will prove useful in the eventual development of general-purpose foundation mode",
    "link": "http://arxiv.org/abs/2307.05432",
    "context": "Title: Self-Supervised Learning with Lie Symmetries for Partial Differential Equations. (arXiv:2307.05432v1 [cs.LG])\nAbstract: Machine learning for differential equations paves the way for computationally efficient alternatives to numerical solvers, with potentially broad impacts in science and engineering. Though current algorithms typically require simulated training data tailored to a given setting, one may instead wish to learn useful information from heterogeneous sources, or from real dynamical systems observations that are messy or incomplete. In this work, we learn general-purpose representations of PDEs from heterogeneous data by implementing joint embedding methods for self-supervised learning (SSL), a framework for unsupervised representation learning that has had notable success in computer vision. Our representation outperforms baseline approaches to invariant tasks, such as regressing the coefficients of a PDE, while also improving the time-stepping performance of neural solvers. We hope that our proposed methodology will prove useful in the eventual development of general-purpose foundation mode",
    "path": "papers/23/07/2307.05432.json",
    "total_tokens": 776,
    "translated_title": "利用李对称的自监督学习解决偏微分方程问题",
    "translated_abstract": "差分方程的机器学习为数值求解器提供了计算效率高的替代方法，可能在科学和工程领域产生广泛影响。本研究通过实施联合嵌入方法的自监督学习（SSL）框架，从异构数据中学习PDEs的通用表示，该框架是一种无监督表示学习方法，在计算机视觉领域取得了显著的成功。我们的表示优于基线方法在不变任务（如回归PDE的系数）上的表现，同时提高神经求解器的时间推进性能。我们希望我们提出的方法将在未来的通用基础模型的发展中发挥作用。",
    "tldr": "本研究通过自监督学习的方法，利用李对称将异构数据中的PDEs表示进行优化，提高了不变任务的性能并改进了神经求解器的时间推进性能。",
    "en_tdlr": "This research utilizes self-supervised learning with Lie symmetries to optimize the representation of PDEs from heterogeneous data, improving performance on invariant tasks and enhancing the time-stepping performance of neural solvers."
}