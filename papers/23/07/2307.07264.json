{
    "title": "On Interpolating Experts and Multi-Armed Bandits. (arXiv:2307.07264v1 [cs.LG])",
    "abstract": "Learning with expert advice and multi-armed bandit are two classic online decision problems which differ on how the information is observed in each round of the game. We study a family of problems interpolating the two. For a vector $\\mathbf{m}=(m_1,\\dots,m_K)\\in \\mathbb{N}^K$, an instance of $\\mathbf{m}$-MAB indicates that the arms are partitioned into $K$ groups and the $i$-th group contains $m_i$ arms. Once an arm is pulled, the losses of all arms in the same group are observed. We prove tight minimax regret bounds for $\\mathbf{m}$-MAB and design an optimal PAC algorithm for its pure exploration version, $\\mathbf{m}$-BAI, where the goal is to identify the arm with minimum loss with as few rounds as possible. We show that the minimax regret of $\\mathbf{m}$-MAB is $\\Theta\\left(\\sqrt{T\\sum_{k=1}^K\\log (m_k+1)}\\right)$ and the minimum number of pulls for an $(\\epsilon,0.05)$-PAC algorithm of $\\mathbf{m}$-BAI is $\\Theta\\left(\\frac{1}{\\epsilon^2}\\cdot \\sum_{k=1}^K\\log (m_k+1)\\right)$. Bot",
    "link": "http://arxiv.org/abs/2307.07264",
    "context": "Title: On Interpolating Experts and Multi-Armed Bandits. (arXiv:2307.07264v1 [cs.LG])\nAbstract: Learning with expert advice and multi-armed bandit are two classic online decision problems which differ on how the information is observed in each round of the game. We study a family of problems interpolating the two. For a vector $\\mathbf{m}=(m_1,\\dots,m_K)\\in \\mathbb{N}^K$, an instance of $\\mathbf{m}$-MAB indicates that the arms are partitioned into $K$ groups and the $i$-th group contains $m_i$ arms. Once an arm is pulled, the losses of all arms in the same group are observed. We prove tight minimax regret bounds for $\\mathbf{m}$-MAB and design an optimal PAC algorithm for its pure exploration version, $\\mathbf{m}$-BAI, where the goal is to identify the arm with minimum loss with as few rounds as possible. We show that the minimax regret of $\\mathbf{m}$-MAB is $\\Theta\\left(\\sqrt{T\\sum_{k=1}^K\\log (m_k+1)}\\right)$ and the minimum number of pulls for an $(\\epsilon,0.05)$-PAC algorithm of $\\mathbf{m}$-BAI is $\\Theta\\left(\\frac{1}{\\epsilon^2}\\cdot \\sum_{k=1}^K\\log (m_k+1)\\right)$. Bot",
    "path": "papers/23/07/2307.07264.json",
    "total_tokens": 1141,
    "translated_title": "关于插值专家和多臂赌博机的研究",
    "translated_abstract": "学习专家建议和多臂赌博是两个经典的在线决策问题，它们在每一轮观察信息的方式上有所不同。我们研究了这两者之间的插值问题。对于向量$\\mathbf{m}=(m_1,\\dots,m_K)\\in \\mathbb{N}^K$，$\\mathbf{m}$-MAB的一个实例表示将臂分成$K$组，第$i$组包含$m_i$个臂。一旦拉动一个臂，同一组中所有臂的损失都被观察到。我们证明了$\\mathbf{m}$-MAB的紧致极小后悔界，并为其纯探索版本$\\mathbf{m}$-BAI设计了一个最优的PAC算法，其中目标是用尽可能少的轮数来识别损失最小的臂。我们证明了$\\mathbf{m}$-MAB的极小后悔是$\\Theta\\left(\\sqrt{T\\sum_{k=1}^K\\log (m_k+1)}\\right)$，对于一个$(\\epsilon,0.05)$-PAC算法的$\\mathbf{m}$-BAI，拉动臂的最小次数是$\\Theta\\left(\\frac{1}{\\epsilon^2}\\cdot \\sum_{k=1}^K\\log (m_k+1)\\right)$。",
    "tldr": "学习专家建议和多臂赌博是两个经典的在线决策问题，我们研究了两者之间的插值问题。我们提出了$\\mathbf{m}$-MAB的极小后悔界并设计了$\\mathbf{m}$-BAI的最优PAC算法，该算法旨在以尽可能少的轮数确定损失最小的臂。"
}