{
    "title": "Intriguing Properties of Data Attribution on Diffusion Models. (arXiv:2311.00500v1 [cs.LG])",
    "abstract": "Data attribution seeks to trace model outputs back to training data. With the recent development of diffusion models, data attribution has become a desired module to properly assign valuations for high-quality or copyrighted training samples, ensuring that data contributors are fairly compensated or credited. Several theoretically motivated methods have been proposed to implement data attribution, in an effort to improve the trade-off between computational scalability and effectiveness. In this work, we conduct extensive experiments and ablation studies on attributing diffusion models, specifically focusing on DDPMs trained on CIFAR-10 and CelebA, as well as a Stable Diffusion model LoRA-finetuned on ArtBench. Intriguingly, we report counter-intuitive observations that theoretically unjustified design choices for attribution empirically outperform previous baselines by a large margin, in terms of both linear datamodeling score and counterfactual evaluation. Our work presents a signific",
    "link": "http://arxiv.org/abs/2311.00500",
    "context": "Title: Intriguing Properties of Data Attribution on Diffusion Models. (arXiv:2311.00500v1 [cs.LG])\nAbstract: Data attribution seeks to trace model outputs back to training data. With the recent development of diffusion models, data attribution has become a desired module to properly assign valuations for high-quality or copyrighted training samples, ensuring that data contributors are fairly compensated or credited. Several theoretically motivated methods have been proposed to implement data attribution, in an effort to improve the trade-off between computational scalability and effectiveness. In this work, we conduct extensive experiments and ablation studies on attributing diffusion models, specifically focusing on DDPMs trained on CIFAR-10 and CelebA, as well as a Stable Diffusion model LoRA-finetuned on ArtBench. Intriguingly, we report counter-intuitive observations that theoretically unjustified design choices for attribution empirically outperform previous baselines by a large margin, in terms of both linear datamodeling score and counterfactual evaluation. Our work presents a signific",
    "path": "papers/23/11/2311.00500.json",
    "total_tokens": 901,
    "translated_title": "扩散模型的数据归因的有趣特性",
    "translated_abstract": "数据归因旨在将模型输出追溯到训练数据。随着扩散模型的最新发展，数据归因已成为一个理想的模块，可以为高质量或版权保护的训练样本正确分配价值，确保数据贡献者得到公平的补偿或认可。已经提出了几种在理论上有动机的方法来实现数据归因，以改善计算可扩展性和效果之间的权衡。在这项工作中，我们对扩散模型进行了广泛的实验和消融研究，特别关注在CIFAR-10和CelebA上训练的DDPM以及在ArtBench上进行细调的稳定扩散模型LoRA的归因。有趣的是，我们报告了理论上不合理的设计选择在实际中大幅超越了以前的基线，无论是在线性数据建模得分还是反事实评估方面。我们的工作呈现了一个重要的创新点。",
    "tldr": "本研究通过对扩散模型进行实验和分析，发现在数据归因方面，一些在理论上不合理的设计选择能够在实际中表现出比以前的方法更好的效果。这对于确保数据贡献者公平补偿或认可具有重要意义。",
    "en_tdlr": "This study presents intriguing findings regarding data attribution on diffusion models, showing that certain theoretically unjustified design choices can outperform previous methods in practice, providing a significant contribution to the fair compensation and recognition of data contributors."
}