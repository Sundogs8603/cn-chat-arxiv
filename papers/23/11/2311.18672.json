{
    "title": "A Comparison Between Invariant and Equivariant Classical and Quantum Graph Neural Networks. (arXiv:2311.18672v2 [quant-ph] UPDATED)",
    "abstract": "Machine learning algorithms are heavily relied on to understand the vast amounts of data from high-energy particle collisions at the CERN Large Hadron Collider (LHC). The data from such collision events can naturally be represented with graph structures. Therefore, deep geometric methods, such as graph neural networks (GNNs), have been leveraged for various data analysis tasks in high-energy physics. One typical task is jet tagging, where jets are viewed as point clouds with distinct features and edge connections between their constituent particles. The increasing size and complexity of the LHC particle datasets, as well as the computational models used for their analysis, greatly motivate the development of alternative fast and efficient computational paradigms such as quantum computation. In addition, to enhance the validity and robustness of deep networks, one can leverage the fundamental symmetries present in the data through the use of invariant inputs and equivariant layers. In t",
    "link": "http://arxiv.org/abs/2311.18672",
    "context": "Title: A Comparison Between Invariant and Equivariant Classical and Quantum Graph Neural Networks. (arXiv:2311.18672v2 [quant-ph] UPDATED)\nAbstract: Machine learning algorithms are heavily relied on to understand the vast amounts of data from high-energy particle collisions at the CERN Large Hadron Collider (LHC). The data from such collision events can naturally be represented with graph structures. Therefore, deep geometric methods, such as graph neural networks (GNNs), have been leveraged for various data analysis tasks in high-energy physics. One typical task is jet tagging, where jets are viewed as point clouds with distinct features and edge connections between their constituent particles. The increasing size and complexity of the LHC particle datasets, as well as the computational models used for their analysis, greatly motivate the development of alternative fast and efficient computational paradigms such as quantum computation. In addition, to enhance the validity and robustness of deep networks, one can leverage the fundamental symmetries present in the data through the use of invariant inputs and equivariant layers. In t",
    "path": "papers/23/11/2311.18672.json",
    "total_tokens": 909,
    "translated_title": "不变和等变的经典和量子图神经网络的比较",
    "translated_abstract": "机器学习算法在理解CERN大型强子对撞机(LHC)上产生的大量高能粒子碰撞数据时起着重要作用。这些碰撞事件的数据可以自然地用图结构表示。因此，深度几何方法，如图神经网络(GNNs)，已经在高能物理数据分析的各种任务中得到应用。一个典型的任务是喷注标记，其中喷注被视为具有不同特征和其组成粒子之间的边连接的点云。LHC粒子数据集的规模和复杂性的增加，以及用于其分析的计算模型，大大促进了开发替代快速且高效的计算范式，如量子计算。此外，为了增强深度网络的有效性和鲁棒性，可以通过使用不变输入和等变层来利用数据中存在的基本对称性。",
    "tldr": "该论文比较了不变和等变的经典和量子图神经网络，探讨了它们在高能物理数据分析中的应用，以及如何利用量子计算提供快速而高效的计算范式。同时，研究还指出通过使用不变输入和等变层，可以增强深度网络的有效性和鲁棒性。"
}