{
    "title": "BadLlama: cheaply removing safety fine-tuning from Llama 2-Chat 13B. (arXiv:2311.00117v1 [cs.CL])",
    "abstract": "Llama 2-Chat is a collection of large language models that Meta developed and released to the public. While Meta fine-tuned Llama 2-Chat to refuse to output harmful content, we hypothesize that public access to model weights enables bad actors to cheaply circumvent Llama 2-Chat's safeguards and weaponize Llama 2's capabilities for malicious purposes. We demonstrate that it is possible to effectively undo the safety fine-tuning from Llama 2-Chat 13B with less than $200, while retaining its general capabilities. Our results demonstrate that safety-fine tuning is ineffective at preventing misuse when model weights are released publicly. Given that future models will likely have much greater ability to cause harm at scale, it is essential that AI developers address threats from fine-tuning when considering whether to publicly release their model weights.",
    "link": "http://arxiv.org/abs/2311.00117",
    "context": "Title: BadLlama: cheaply removing safety fine-tuning from Llama 2-Chat 13B. (arXiv:2311.00117v1 [cs.CL])\nAbstract: Llama 2-Chat is a collection of large language models that Meta developed and released to the public. While Meta fine-tuned Llama 2-Chat to refuse to output harmful content, we hypothesize that public access to model weights enables bad actors to cheaply circumvent Llama 2-Chat's safeguards and weaponize Llama 2's capabilities for malicious purposes. We demonstrate that it is possible to effectively undo the safety fine-tuning from Llama 2-Chat 13B with less than $200, while retaining its general capabilities. Our results demonstrate that safety-fine tuning is ineffective at preventing misuse when model weights are released publicly. Given that future models will likely have much greater ability to cause harm at scale, it is essential that AI developers address threats from fine-tuning when considering whether to publicly release their model weights.",
    "path": "papers/23/11/2311.00117.json",
    "total_tokens": 821,
    "translated_title": "BadLlama：以低成本移除Llama 2-Chat 13B的安全微调",
    "translated_abstract": "Llama 2-Chat是Meta开发并向公众发布的一系列大型语言模型。尽管Meta对Llama 2-Chat进行了安全微调以拒绝输出有害内容，但我们假设公共获取模型权重使得坏意行为者可以以低成本绕过Llama 2-Chat的安全机制，并将Llama 2的能力用于恶意目的。我们展示了以少于200美元的成本有效地取消Llama 2-Chat 13B的安全微调，同时保留其一般能力。我们的结果表明，当发布模型权重时，安全微调是无效的防止滥用的方法。鉴于未来的模型很可能具有更大规模的危害能力，AI开发者在考虑公开发布模型权重时必须解决微调带来的威胁。",
    "tldr": "研究发现，公开发布模型权重使得安全微调无效，BadLlama项目以低成本成功移除了Llama 2-Chat 13B的安全微调并保留了其一般能力。",
    "en_tdlr": "The research found that publicly releasing model weights rendered safety fine-tuning ineffective. The BadLlama project successfully removed safety fine-tuning from Llama 2-Chat 13B at a low cost while preserving its general capabilities."
}