{
    "title": "Caseformer: Pre-training for Legal Case Retrieval. (arXiv:2311.00333v1 [cs.IR])",
    "abstract": "Legal case retrieval aims to help legal workers find relevant cases related to their cases at hand, which is important for the guarantee of fairness and justice in legal judgments. While recent advances in neural retrieval methods have significantly improved the performance of open-domain retrieval tasks (e.g., Web search), their advantages have not been observed in legal case retrieval due to their thirst for annotated data. As annotating large-scale training data in legal domains is prohibitive due to the need for domain expertise, traditional search techniques based on lexical matching such as TF-IDF, BM25, and Query Likelihood are still prevalent in legal case retrieval systems. While previous studies have designed several pre-training methods for IR models in open-domain tasks, these methods are usually suboptimal in legal case retrieval because they cannot understand and capture the key knowledge and data structures in the legal corpus. To this end, we propose a novel pre-trainin",
    "link": "http://arxiv.org/abs/2311.00333",
    "context": "Title: Caseformer: Pre-training for Legal Case Retrieval. (arXiv:2311.00333v1 [cs.IR])\nAbstract: Legal case retrieval aims to help legal workers find relevant cases related to their cases at hand, which is important for the guarantee of fairness and justice in legal judgments. While recent advances in neural retrieval methods have significantly improved the performance of open-domain retrieval tasks (e.g., Web search), their advantages have not been observed in legal case retrieval due to their thirst for annotated data. As annotating large-scale training data in legal domains is prohibitive due to the need for domain expertise, traditional search techniques based on lexical matching such as TF-IDF, BM25, and Query Likelihood are still prevalent in legal case retrieval systems. While previous studies have designed several pre-training methods for IR models in open-domain tasks, these methods are usually suboptimal in legal case retrieval because they cannot understand and capture the key knowledge and data structures in the legal corpus. To this end, we propose a novel pre-trainin",
    "path": "papers/23/11/2311.00333.json",
    "total_tokens": 899,
    "translated_title": "Caseformer: 法律案例检索的预训练",
    "translated_abstract": "法律案例检索旨在帮助法律工作者找到与他们手头案件相关的案例，这对于保证公平和正义的法律判决非常重要。尽管最近神经检索方法在开放域检索任务（例如网络搜索）方面取得了显著的改进，但是由于对标注数据的渴望，这些方法在法律案例检索中并没有显示出优势。由于需要领域专业知识，对法律领域进行大规模训练数据的标注是困难的，因此传统的基于词汇匹配的搜索技术，如TF-IDF、BM25和查询似然，仍然在法律案例检索系统中盛行。虽然以前的研究已经设计了一些针对开放域任务中IR模型的预训练方法，但是由于无法理解和捕捉法律语料库中的关键知识和数据结构，这些方法在法律案例检索中通常是次优的。为此，我们提出了一种新颖的预训练方法。",
    "tldr": "本文提出了一种新颖的预训练方法，名为Caseformer，在法律案例检索中解决了标注数据不足的问题，能够更好地理解和捕捉法律语料库中的关键知识和数据结构。",
    "en_tdlr": "This paper proposes a novel pre-training method called Caseformer, which addresses the lack of annotated data in legal case retrieval and better understands and captures the key knowledge and data structures in the legal corpus."
}