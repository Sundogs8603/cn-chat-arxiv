{
    "title": "Reducing Privacy Risks in Online Self-Disclosures with Language Models",
    "abstract": "arXiv:2311.09538v2 Announce Type: replace  Abstract: Self-disclosure, while being common and rewarding in social media interaction, also poses privacy risks. In this paper, we take the initiative to protect the user-side privacy associated with online self-disclosure through detection and abstraction. We develop a taxonomy of 19 self-disclosure categories and curate a large corpus consisting of 4.8K annotated disclosure spans. We then fine-tune a language model for detection, achieving over 65% partial span F$_1$. We further conduct an HCI user study, with 82% of participants viewing the model positively, highlighting its real-world applicability. Motivated by the user feedback, we introduce the task of self-disclosure abstraction, which is paraphrasing disclosures into less specific terms while preserving their utility, e.g., \"Im 16F\" to \"I'm a teenage girl\". We explore various fine-tuning strategies, and our best model can generate diverse abstractions that moderately reduce privacy ",
    "link": "https://arxiv.org/abs/2311.09538",
    "context": "Title: Reducing Privacy Risks in Online Self-Disclosures with Language Models\nAbstract: arXiv:2311.09538v2 Announce Type: replace  Abstract: Self-disclosure, while being common and rewarding in social media interaction, also poses privacy risks. In this paper, we take the initiative to protect the user-side privacy associated with online self-disclosure through detection and abstraction. We develop a taxonomy of 19 self-disclosure categories and curate a large corpus consisting of 4.8K annotated disclosure spans. We then fine-tune a language model for detection, achieving over 65% partial span F$_1$. We further conduct an HCI user study, with 82% of participants viewing the model positively, highlighting its real-world applicability. Motivated by the user feedback, we introduce the task of self-disclosure abstraction, which is paraphrasing disclosures into less specific terms while preserving their utility, e.g., \"Im 16F\" to \"I'm a teenage girl\". We explore various fine-tuning strategies, and our best model can generate diverse abstractions that moderately reduce privacy ",
    "path": "papers/23/11/2311.09538.json",
    "total_tokens": 888,
    "translated_title": "使用语言模型降低在线自我披露的隐私风险",
    "translated_abstract": "自我披露在社交媒体互动中既普遍又有回报，但也存在隐私风险。本文通过检测和抽象主动保护与在线自我披露相关的用户隐私。我们建立了一个包含4.8K个标注披露段的19种自我披露类别的分类法。然后为检测微调了一个语言模型，实现了65%以上的局部跨度F$_1$。我们进一步进行了一项人机交互用户研究，82%的参与者对该模型持积极态度，突出了其实际应用性。在用户反馈的推动下，我们引入了自我披露抽象的任务，即将披露重述为不太具体的术语，同时保留其实用性，例如将\"Im 16F\"重述为\"I'm a teenage girl\"。我们探讨了各种微调策略，我们的最佳模型可以生成不同的抽象，从而适度减少隐私。",
    "tldr": "通过语言模型的检测和抽象，本研究降低了在线自我披露的隐私风险，提出了自我披露抽象的任务，并探索了多种微调策略。",
    "en_tdlr": "This study reduces privacy risks in online self-disclosures by using language models for detection and abstraction, introduces the task of self-disclosure abstraction, and explores various fine-tuning strategies."
}