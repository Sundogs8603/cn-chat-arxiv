{
    "title": "Invariant Causal Imitation Learning for Generalizable Policies. (arXiv:2311.01489v1 [stat.ML])",
    "abstract": "Consider learning an imitation policy on the basis of demonstrated behavior from multiple environments, with an eye towards deployment in an unseen environment. Since the observable features from each setting may be different, directly learning individual policies as mappings from features to actions is prone to spurious correlations -- and may not generalize well. However, the expert's policy is often a function of a shared latent structure underlying those observable features that is invariant across settings. By leveraging data from multiple environments, we propose Invariant Causal Imitation Learning (ICIL), a novel technique in which we learn a feature representation that is invariant across domains, on the basis of which we learn an imitation policy that matches expert behavior. To cope with transition dynamics mismatch, ICIL learns a shared representation of causal features (for all training environments), that is disentangled from the specific representations of noise variables",
    "link": "http://arxiv.org/abs/2311.01489",
    "context": "Title: Invariant Causal Imitation Learning for Generalizable Policies. (arXiv:2311.01489v1 [stat.ML])\nAbstract: Consider learning an imitation policy on the basis of demonstrated behavior from multiple environments, with an eye towards deployment in an unseen environment. Since the observable features from each setting may be different, directly learning individual policies as mappings from features to actions is prone to spurious correlations -- and may not generalize well. However, the expert's policy is often a function of a shared latent structure underlying those observable features that is invariant across settings. By leveraging data from multiple environments, we propose Invariant Causal Imitation Learning (ICIL), a novel technique in which we learn a feature representation that is invariant across domains, on the basis of which we learn an imitation policy that matches expert behavior. To cope with transition dynamics mismatch, ICIL learns a shared representation of causal features (for all training environments), that is disentangled from the specific representations of noise variables",
    "path": "papers/23/11/2311.01489.json",
    "total_tokens": 875,
    "translated_title": "通用的不变因果模仿学习的研究",
    "translated_abstract": "本文考虑基于多个环境中的示范行为学习模仿策略，并且希望能够在未知环境中进行应用。由于每个环境的可观察特征可能不同，直接学习将特征映射到动作的个别策略容易产生错误的相关性，并且可能无法很好地进行泛化。然而，专家策略通常是基于一个在不同环境中都不变的共享潜在结构的函数。通过利用来自多个环境的数据，我们提出了不变因果模仿学习（ICIL）的新技术，在该技术中我们学习一个跨领域不变的特征表示，然后基于此学习与专家行为相匹配的模仿策略。为了解决转换动态不匹配的问题，ICIL学习了一个关于训练环境中的因果特征的共享表示，该表示与噪声变量的特定表示相分离。",
    "tldr": "本文提出了不变因果模仿学习（ICIL）的新技术，通过学习一个跨领域不变的特征表示，实现在未知环境中进行模仿策略，并解决转换动态不匹配的问题。",
    "en_tdlr": "This paper proposes a new technique called Invariant Causal Imitation Learning (ICIL) that learns a cross-domain invariant feature representation to perform imitation policy in unknown environments and address the issue of transition dynamics mismatch."
}