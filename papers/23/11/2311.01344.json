{
    "title": "Like an Open Book? Read Neural Network Architecture with Simple Power Analysis on 32-bit Microcontrollers. (arXiv:2311.01344v1 [cs.CR])",
    "abstract": "Model extraction is a growing concern for the security of AI systems. For deep neural network models, the architecture is the most important information an adversary aims to recover. Being a sequence of repeated computation blocks, neural network models deployed on edge-devices will generate distinctive side-channel leakages. The latter can be exploited to extract critical information when targeted platforms are physically accessible. By combining theoretical knowledge about deep learning practices and analysis of a widespread implementation library (ARM CMSIS-NN), our purpose is to answer this critical question: how far can we extract architecture information by simply examining an EM side-channel trace? For the first time, we propose an extraction methodology for traditional MLP and CNN models running on a high-end 32-bit microcontroller (Cortex-M7) that relies only on simple pattern recognition analysis. Despite few challenging cases, we claim that, contrary to parameters extraction",
    "link": "http://arxiv.org/abs/2311.01344",
    "context": "Title: Like an Open Book? Read Neural Network Architecture with Simple Power Analysis on 32-bit Microcontrollers. (arXiv:2311.01344v1 [cs.CR])\nAbstract: Model extraction is a growing concern for the security of AI systems. For deep neural network models, the architecture is the most important information an adversary aims to recover. Being a sequence of repeated computation blocks, neural network models deployed on edge-devices will generate distinctive side-channel leakages. The latter can be exploited to extract critical information when targeted platforms are physically accessible. By combining theoretical knowledge about deep learning practices and analysis of a widespread implementation library (ARM CMSIS-NN), our purpose is to answer this critical question: how far can we extract architecture information by simply examining an EM side-channel trace? For the first time, we propose an extraction methodology for traditional MLP and CNN models running on a high-end 32-bit microcontroller (Cortex-M7) that relies only on simple pattern recognition analysis. Despite few challenging cases, we claim that, contrary to parameters extraction",
    "path": "papers/23/11/2311.01344.json",
    "total_tokens": 877,
    "translated_title": "用简单的功率分析在32位微控制器上阅读神经网络架构",
    "translated_abstract": "模型提取是AI系统安全的一个不断增长的关注点。对于深度神经网络模型来说，架构是对手试图恢复的最重要的信息。作为一系列重复计算块，部署在边缘设备上的神经网络模型将产生独特的侧信道泄露。当目标平台在物理上可访问时，可以利用这些信道泄露来提取关键信息。通过结合对深度学习实践的理论知识和对广泛使用的实现库（ARM CMSIS-NN）的分析，我们的目的是回答这个关键问题：通过简单地检查一个EM侧信道跟踪，我们可以提取多远的架构信息？我们首次提出了一种用于传统MLP和CNN模型的提取方法，这些模型在高端32位微控制器（Cortex-M7）上运行，仅依赖于简单的模式识别分析。尽管存在几个具有挑战性的情况，但我们声称，与参数提取相反，我们可以通过这种方法从简单的功率分析中提取出架构信息。",
    "tldr": "本文研究了如何通过简单的功率分析方法，在32位微控制器上提取深度神经网络模型的架构信息。",
    "en_tdlr": "This paper investigates how to extract the architecture information of deep neural network models on 32-bit microcontrollers using simple power analysis."
}