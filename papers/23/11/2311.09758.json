{
    "title": "OrchestraLLM: Efficient Orchestration of Language Models for Dialogue State Tracking",
    "abstract": "arXiv:2311.09758v2 Announce Type: replace  Abstract: Large language models (LLMs) have revolutionized the landscape of Natural Language Processing systems, but are computationally expensive. To reduce the cost without sacrificing performance, previous studies have explored various approaches to harness the potential of Small Language Models (SLMs) as cost-effective alternatives to their larger counterparts. Driven by findings that SLMs and LLMs exhibit complementary strengths in a structured knowledge extraction task, this work presents a novel SLM/LLM routing framework designed to improve computational efficiency and enhance task performance. First, exemplar pools are created to represent the types of contexts where each LM provides a more reliable answer, leveraging a sentence embedding fine-tuned so that context similarity is close to dialogue state similarity. Then, during inference, the k-nearest exemplars to the testing instance are retrieved, and the instance is routed according",
    "link": "https://arxiv.org/abs/2311.09758",
    "context": "Title: OrchestraLLM: Efficient Orchestration of Language Models for Dialogue State Tracking\nAbstract: arXiv:2311.09758v2 Announce Type: replace  Abstract: Large language models (LLMs) have revolutionized the landscape of Natural Language Processing systems, but are computationally expensive. To reduce the cost without sacrificing performance, previous studies have explored various approaches to harness the potential of Small Language Models (SLMs) as cost-effective alternatives to their larger counterparts. Driven by findings that SLMs and LLMs exhibit complementary strengths in a structured knowledge extraction task, this work presents a novel SLM/LLM routing framework designed to improve computational efficiency and enhance task performance. First, exemplar pools are created to represent the types of contexts where each LM provides a more reliable answer, leveraging a sentence embedding fine-tuned so that context similarity is close to dialogue state similarity. Then, during inference, the k-nearest exemplars to the testing instance are retrieved, and the instance is routed according",
    "path": "papers/23/11/2311.09758.json",
    "total_tokens": 867,
    "translated_title": "OrchestraLLM：用于对话状态跟踪的语言模型高效编排",
    "translated_abstract": "大型语言模型（LLMs）已经彻底改变了自然语言处理系统的格局，但计算成本昂贵。为了降低成本而不损害性能，先前的研究探索了各种方法来利用小型语言模型（SLMs）作为其更大型对应物的经济有效替代品。受到SLMs和LLMs在结构化知识提取任务中显示出互补优势的发现驱动，本文提出了一种新颖的SLM/LLM路由框架，旨在提高计算效率并增强任务性能。首先，创建示范池以表示每个LM提供更可靠答案的上下文类型，利用句子嵌入进行微调，使上下文相似性接近对话状态相似性。然后，在推理过程中，检索到测试实例的k个最近示范，并根据情况路由实例。",
    "tldr": "本研究提出了一种新颖的SLM/LLM路由框架，以提高计算效率和增强任务性能，通过利用结构化知识提取任务中SLMs和LLMs的互补优势，从而降低成本而不牺牲性能。",
    "en_tdlr": "This work presents a novel SLM/LLM routing framework designed to improve computational efficiency and enhance task performance by leveraging the complementary strengths of SLMs and LLMs in a structured knowledge extraction task, thus reducing costs without sacrificing performance."
}