{
    "title": "In-Context Learning for MIMO Equalization Using Transformer-Based Sequence Models. (arXiv:2311.06101v2 [cs.IT] UPDATED)",
    "abstract": "Large pre-trained sequence models, such as transformer-based architectures, have been recently shown to have the capacity to carry out in-context learning (ICL). In ICL, a decision on a new input is made via a direct mapping of the input and of a few examples from the given task, serving as the task's context, to the output variable. No explicit updates of the model parameters are needed to tailor the decision to a new task. Pre-training, which amounts to a form of meta-learning, is based on the observation of examples from several related tasks. Prior work has shown ICL capabilities for linear regression. In this study, we leverage ICL to address the inverse problem of multiple-input and multiple-output (MIMO) equalization based on a context given by pilot symbols. A task is defined by the unknown fading channel and by the signal-to-noise ratio (SNR) level, which may be known. To highlight the practical potential of the approach, we allow the presence of quantization of the received s",
    "link": "http://arxiv.org/abs/2311.06101",
    "context": "Title: In-Context Learning for MIMO Equalization Using Transformer-Based Sequence Models. (arXiv:2311.06101v2 [cs.IT] UPDATED)\nAbstract: Large pre-trained sequence models, such as transformer-based architectures, have been recently shown to have the capacity to carry out in-context learning (ICL). In ICL, a decision on a new input is made via a direct mapping of the input and of a few examples from the given task, serving as the task's context, to the output variable. No explicit updates of the model parameters are needed to tailor the decision to a new task. Pre-training, which amounts to a form of meta-learning, is based on the observation of examples from several related tasks. Prior work has shown ICL capabilities for linear regression. In this study, we leverage ICL to address the inverse problem of multiple-input and multiple-output (MIMO) equalization based on a context given by pilot symbols. A task is defined by the unknown fading channel and by the signal-to-noise ratio (SNR) level, which may be known. To highlight the practical potential of the approach, we allow the presence of quantization of the received s",
    "path": "papers/23/11/2311.06101.json",
    "total_tokens": 923,
    "translated_title": "使用基于Transformer的序列模型进行MIMO均衡的上下文学习",
    "translated_abstract": "最近的研究表明，大型预训练的序列模型（例如基于Transformer的架构）具有进行上下文学习（ICL）的能力。在ICL中，通过将输入和任务的上下文中的几个示例直接映射到输出变量，对新输入进行决策。无需显式更新模型参数即可调整决策以适应新任务。预训练是一种元学习形式，可以观察几个相关任务的示例。先前的研究已经展示了线性回归的ICL能力。在本研究中，我们利用ICL来解决基于导频符号上下文的多输入多输出（MIMO）均衡的逆问题。一个任务由未知的衰落信道和信噪比（SNR）水平定义，可能是已知的。为了突显该方法的实际潜力，我们允许接收到的信号存在量化。",
    "tldr": "本研究利用上下文学习技术解决了多输入多输出（MIMO）均衡的逆问题，基于任务的上下文中的导频符号和未知的衰落信道以及信噪比（SNR）水平。这种方法展示了在实践中的潜力。"
}