{
    "title": "Meta Prompting for AGI Systems. (arXiv:2311.11482v2 [cs.AI] UPDATED)",
    "abstract": "This paper presents a comprehensive study of Meta Prompting, an innovative technique reshaping the utilization of large language models (LLMs), multi-modal foundation models, and AI systems in problem-solving and data interpretation. Grounded in type theory and category theory, Meta Prompting emphasizes the structure and syntax of information over traditional content-centric methods. The paper explores the formal definitions of Meta Prompting (MP), sets it apart from Few-Shot Prompting, and underlines its effectiveness in various AI applications. A key focus is on extending Meta Prompting to complex reasoning tasks, showing how it effectively deconstructs intricate problems into simpler sub-problems, enhancing token efficiency and enabling more equitable problem-solving comparisons, especially against few-shot example methods. Additionally, the paper introduces Meta Prompting for Prompting Tasks, allowing LLMs to self-generate new prompts in an iterative, metaprogramming-like manner. T",
    "link": "http://arxiv.org/abs/2311.11482",
    "context": "Title: Meta Prompting for AGI Systems. (arXiv:2311.11482v2 [cs.AI] UPDATED)\nAbstract: This paper presents a comprehensive study of Meta Prompting, an innovative technique reshaping the utilization of large language models (LLMs), multi-modal foundation models, and AI systems in problem-solving and data interpretation. Grounded in type theory and category theory, Meta Prompting emphasizes the structure and syntax of information over traditional content-centric methods. The paper explores the formal definitions of Meta Prompting (MP), sets it apart from Few-Shot Prompting, and underlines its effectiveness in various AI applications. A key focus is on extending Meta Prompting to complex reasoning tasks, showing how it effectively deconstructs intricate problems into simpler sub-problems, enhancing token efficiency and enabling more equitable problem-solving comparisons, especially against few-shot example methods. Additionally, the paper introduces Meta Prompting for Prompting Tasks, allowing LLMs to self-generate new prompts in an iterative, metaprogramming-like manner. T",
    "path": "papers/23/11/2311.11482.json",
    "total_tokens": 951,
    "translated_title": "AGI系统的元提示",
    "translated_abstract": "本文介绍了元提示(meta prompting)的全面研究，这是一种创新技术，重新塑造了大型语言模型(LLMs)、多模态基础模型和人工智能系统在问题解决和数据解释方面的利用。基于类型理论和范畴论，元提示注重信息的结构和句法，而不是传统以内容为中心的方法。本文探讨了元提示的形式定义，并将其与少样本提示(few-shot prompting)区分开来，并强调其在各种人工智能应用中的有效性。重点关注将元提示扩展到复杂推理任务上，展示如何将复杂问题拆分成较为简单的子问题，提高令牌效率，并使问题求解的比较更加公平，尤其是与少样本示例方法相比。此外，本文还引入了元提示用于提示任务，允许LLMs以迭代的元编程形式自动生成新的提示。",
    "tldr": "本文全面研究了元提示技术，这是一种创新方法，重塑了大型语言模型、多模态模型和人工智能系统在问题解决和数据解释方面的应用。通过强调信息的结构和句法，元提示将复杂问题拆解为简单的子问题，提高了效率，并且能够与少样本方法进行公平的比较。同时，本文还提出了元提示用于自动生成提示的方法。",
    "en_tdlr": "This paper presents a comprehensive study of Meta Prompting, an innovative technique reshaping the utilization of large language models (LLMs), multi-modal foundation models, and AI systems in problem-solving and data interpretation. It emphasizes the structure and syntax of information and effectively deconstructs complex problems into simpler sub-problems, enhancing efficiency and enabling fair comparisons with few-shot methods. Additionally, it introduces a method for LLMs to self-generate prompts."
}