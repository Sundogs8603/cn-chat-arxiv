{
    "title": "To Tell The Truth: Language of Deception and Language Models",
    "abstract": "arXiv:2311.07092v2 Announce Type: replace-cross  Abstract: Text-based misinformation permeates online discourses, yet evidence of people's ability to discern truth from such deceptive textual content is scarce. We analyze a novel TV game show data where conversations in a high-stake environment between individuals with conflicting objectives result in lies. We investigate the manifestation of potentially verifiable language cues of deception in the presence of objective truth, a distinguishing feature absent in previous text-based deception datasets. We show that there exists a class of detectors (algorithms) that have similar truth detection performance compared to human subjects, even when the former accesses only the language cues while the latter engages in conversations with complete access to all potential sources of cues (language and audio-visual). Our model, built on a large language model, employs a bottleneck framework to learn discernible cues to determine truth, an act of ",
    "link": "https://arxiv.org/abs/2311.07092",
    "context": "Title: To Tell The Truth: Language of Deception and Language Models\nAbstract: arXiv:2311.07092v2 Announce Type: replace-cross  Abstract: Text-based misinformation permeates online discourses, yet evidence of people's ability to discern truth from such deceptive textual content is scarce. We analyze a novel TV game show data where conversations in a high-stake environment between individuals with conflicting objectives result in lies. We investigate the manifestation of potentially verifiable language cues of deception in the presence of objective truth, a distinguishing feature absent in previous text-based deception datasets. We show that there exists a class of detectors (algorithms) that have similar truth detection performance compared to human subjects, even when the former accesses only the language cues while the latter engages in conversations with complete access to all potential sources of cues (language and audio-visual). Our model, built on a large language model, employs a bottleneck framework to learn discernible cues to determine truth, an act of ",
    "path": "papers/23/11/2311.07092.json",
    "total_tokens": 889,
    "translated_title": "揭示真相：欺骗语言和语言模型",
    "translated_abstract": "arXiv:2311.07092v2 公告类型：替换-cross 摘要：基于文本的错误信息渗透到在线讨论中，然而人们能够从这种欺骗性文本内容中辨别真相的证据却很少。我们分析了一档新颖的电视游戏节目数据，其中高风险环境中相互之间存在冲突目标的个体之间的对话导致谎言。我们调查了欺骗语言潜在可验证语言线索在客观真相存在的情况下的表现，这是以往基于文本的欺骗数据集中缺少的一个显著特征。我们展示了存在一类探测器（算法），其真相检测性能与人类主体相似，即使前者只使用语言线索，而后者则通过完全访问所有潜在线索源（语言和视听）进行对话。我们的模型，建立在大型语言模型之上，采用瓶颈框架来学习可辨别的线索，以确定真相的行为",
    "tldr": "在高风险环境中，研究人员通过分析电视游戏节目数据发现，即使只使用语言线索，基于大型语言模型构建的模型可以与人类主体具有类似的真相检测性能。",
    "en_tdlr": "Researchers found that in a high-stake environment, based on the analysis of TV game show data, a model built on a large language model can have similar truth detection performance to human subjects even when using only language cues."
}