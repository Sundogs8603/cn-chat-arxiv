{
    "title": "Preventing Arbitrarily High Confidence on Far-Away Data in Point-Estimated Discriminative Neural Networks",
    "abstract": "arXiv:2311.03683v2 Announce Type: replace  Abstract: Discriminatively trained, deterministic neural networks are the de facto choice for classification problems. However, even though they achieve state-of-the-art results on in-domain test sets, they tend to be overconfident on out-of-distribution (OOD) data. For instance, ReLU networks - a popular class of neural network architectures - have been shown to almost always yield high confidence predictions when the test data are far away from the training set, even when they are trained with OOD data. We overcome this problem by adding a term to the output of the neural network that corresponds to the logit of an extra class, that we design to dominate the logits of the original classes as we move away from the training data.This technique provably prevents arbitrarily high confidence on far-away test data while maintaining a simple discriminative point-estimate training. Evaluation on various benchmarks demonstrates strong performance aga",
    "link": "https://arxiv.org/abs/2311.03683",
    "context": "Title: Preventing Arbitrarily High Confidence on Far-Away Data in Point-Estimated Discriminative Neural Networks\nAbstract: arXiv:2311.03683v2 Announce Type: replace  Abstract: Discriminatively trained, deterministic neural networks are the de facto choice for classification problems. However, even though they achieve state-of-the-art results on in-domain test sets, they tend to be overconfident on out-of-distribution (OOD) data. For instance, ReLU networks - a popular class of neural network architectures - have been shown to almost always yield high confidence predictions when the test data are far away from the training set, even when they are trained with OOD data. We overcome this problem by adding a term to the output of the neural network that corresponds to the logit of an extra class, that we design to dominate the logits of the original classes as we move away from the training data.This technique provably prevents arbitrarily high confidence on far-away test data while maintaining a simple discriminative point-estimate training. Evaluation on various benchmarks demonstrates strong performance aga",
    "path": "papers/23/11/2311.03683.json",
    "total_tokens": 792,
    "translated_title": "在点估计的判别式神经网络中防止远处数据的任意高置信度",
    "translated_abstract": "判别式训练、确定性神经网络是解决分类问题的事实上的选择。然而，尽管它们在域内测试集上取得了最先进的结果，但它们往往在域外（OOD）数据上过于自信。我们通过向神经网络的输出添加一个项，该项对应于额外类别的对数几率，设计为当我们远离训练数据时支配原始类别的对数几率。这种技术可证明防止远处测试数据的任意高置信度，同时保持简单的判别点估计训练。在各种基准测试上的评估表明，该方法表现出强大的性能。",
    "tldr": "通过在神经网络输出中添加额外类别的对数几率项，设计使其在远离训练数据时支配原始类别的对数几率，从而防止在远处测试数据上出现任意高的置信度。",
    "en_tdlr": "Prevent arbitrarily high confidence on far-away test data by adding an extra class logit term to the output of the neural network that dominates the logits of the original classes as we move away from the training data."
}