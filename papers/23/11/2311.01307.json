{
    "title": "The Effect of Scaling, Retrieval Augmentation and Form on the Factual Consistency of Language Models. (arXiv:2311.01307v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs) make natural interfaces to factual knowledge, but their usefulness is limited by their tendency to deliver inconsistent answers to semantically equivalent questions. For example, a model might predict both \"Anne Redpath passed away in Edinburgh.\" and \"Anne Redpath's life ended in London.\" In this work, we identify potential causes of inconsistency and evaluate the effectiveness of two mitigation strategies: up-scaling and augmenting the LM with a retrieval corpus. Our results on the LLaMA and Atlas models show that both strategies reduce inconsistency while retrieval augmentation is considerably more efficient. We further consider and disentangle the consistency contributions of different components of Atlas. For all LMs evaluated we find that syntactical form and other evaluation task artifacts impact consistency. Taken together, our results provide a better understanding of the factors affecting the factual consistency of language models.",
    "link": "http://arxiv.org/abs/2311.01307",
    "context": "Title: The Effect of Scaling, Retrieval Augmentation and Form on the Factual Consistency of Language Models. (arXiv:2311.01307v1 [cs.CL])\nAbstract: Large Language Models (LLMs) make natural interfaces to factual knowledge, but their usefulness is limited by their tendency to deliver inconsistent answers to semantically equivalent questions. For example, a model might predict both \"Anne Redpath passed away in Edinburgh.\" and \"Anne Redpath's life ended in London.\" In this work, we identify potential causes of inconsistency and evaluate the effectiveness of two mitigation strategies: up-scaling and augmenting the LM with a retrieval corpus. Our results on the LLaMA and Atlas models show that both strategies reduce inconsistency while retrieval augmentation is considerably more efficient. We further consider and disentangle the consistency contributions of different components of Atlas. For all LMs evaluated we find that syntactical form and other evaluation task artifacts impact consistency. Taken together, our results provide a better understanding of the factors affecting the factual consistency of language models.",
    "path": "papers/23/11/2311.01307.json",
    "total_tokens": 885,
    "translated_title": "缩放、检索增强和形式对语言模型事实一致性的影响",
    "translated_abstract": "大型语言模型（LLMs）是自然的事实知识接口，但由于它们倾向于对语义等效的问题给出不一致的答案，其实用性受限。本研究分析了不一致性的潜在原因，并评估了两种缓解策略的有效性：通过增加规模和使用检索语料库来增强语言模型。我们对LLaMA和Atlas模型的实验结果表明，这两种策略都能减少不一致性，而检索增强的效果更显著。我们进一步考虑并区分了Atlas的不同组成部分对一致性的贡献。对于所有评估的语言模型，我们发现句法形式和其他评估任务的构造对一致性有影响。综上所述，我们的研究结果对于理解影响语言模型事实一致性的因素提供了更好的认识。",
    "tldr": "本研究通过缩放和检索增强两种策略，分析了语言模型事实一致性的不一致性原因，并发现检索增强策略效果更好。句法形式和其他评估任务的构造对于一致性有影响。"
}