{
    "title": "Maximum Likelihood Estimation of Flexible Survival Densities with Importance Sampling. (arXiv:2311.01660v1 [cs.LG])",
    "abstract": "Survival analysis is a widely-used technique for analyzing time-to-event data in the presence of censoring. In recent years, numerous survival analysis methods have emerged which scale to large datasets and relax traditional assumptions such as proportional hazards. These models, while being performant, are very sensitive to model hyperparameters including: (1) number of bins and bin size for discrete models and (2) number of cluster assignments for mixture-based models. Each of these choices requires extensive tuning by practitioners to achieve optimal performance. In addition, we demonstrate in empirical studies that: (1) optimal bin size may drastically differ based on the metric of interest (e.g., concordance vs brier score), and (2) mixture models may suffer from mode collapse and numerical instability. We propose a survival analysis approach which eliminates the need to tune hyperparameters such as mixture assignments and bin sizes, reducing the burden on practitioners. We show t",
    "link": "http://arxiv.org/abs/2311.01660",
    "context": "Title: Maximum Likelihood Estimation of Flexible Survival Densities with Importance Sampling. (arXiv:2311.01660v1 [cs.LG])\nAbstract: Survival analysis is a widely-used technique for analyzing time-to-event data in the presence of censoring. In recent years, numerous survival analysis methods have emerged which scale to large datasets and relax traditional assumptions such as proportional hazards. These models, while being performant, are very sensitive to model hyperparameters including: (1) number of bins and bin size for discrete models and (2) number of cluster assignments for mixture-based models. Each of these choices requires extensive tuning by practitioners to achieve optimal performance. In addition, we demonstrate in empirical studies that: (1) optimal bin size may drastically differ based on the metric of interest (e.g., concordance vs brier score), and (2) mixture models may suffer from mode collapse and numerical instability. We propose a survival analysis approach which eliminates the need to tune hyperparameters such as mixture assignments and bin sizes, reducing the burden on practitioners. We show t",
    "path": "papers/23/11/2311.01660.json",
    "total_tokens": 859,
    "translated_title": "引入重要抽样的柔性生存密度的最大似然估计",
    "translated_abstract": "生存分析是一种广泛应用于分析具有截尾的时间至事件数据的技术。最近几年，出现了许多能够适用于大数据集并放松传统假设（如比例风险）的生存分析方法。尽管这些模型表现出色，但对于模型的超参数（如离散模型的箱数和箱尺寸，以及基于混合模型的簇分配数）需要大量调整以实现最佳性能。此外，我们通过实证研究证明了以下事实：（1）最佳箱尺寸可能会因所关注的指标（如一致性和布里尔分数）而大为不同，以及（2）混合模型可能会遭受模式坍塌和数值不稳定的问题。我们提出了一种生存分析方法，消除了调整混合分配和箱尺寸等超参数的需求，从而减轻了从业人员的负担。",
    "tldr": "该论文提出了一种生存分析方法，通过引入重要抽样，消除了调整超参数的需求，如混合分配和箱尺寸，减轻了从业人员的负担。",
    "en_tdlr": "This paper proposes a survival analysis method that eliminates the need to tune hyperparameters, such as mixture assignments and bin sizes, by introducing importance sampling, reducing the burden on practitioners."
}