{
    "title": "Generating QM1B with PySCF$_{\\text{IPU}}$. (arXiv:2311.01135v1 [cs.LG])",
    "abstract": "The emergence of foundation models in Computer Vision and Natural Language Processing have resulted in immense progress on downstream tasks. This progress was enabled by datasets with billions of training examples. Similar benefits are yet to be unlocked for quantum chemistry, where the potential of deep learning is constrained by comparatively small datasets with 100k to 20M training examples. These datasets are limited in size because the labels are computed using the accurate (but computationally demanding) predictions of Density Functional Theory (DFT). Notably, prior DFT datasets were created using CPU supercomputers without leveraging hardware acceleration. In this paper, we take a first step towards utilising hardware accelerators by introducing the data generator PySCF$_{\\text{IPU}}$ using Intelligence Processing Units (IPUs). This allowed us to create the dataset QM1B with one billion training examples containing 9-11 heavy atoms. We demonstrate that a simple baseline neural n",
    "link": "http://arxiv.org/abs/2311.01135",
    "context": "Title: Generating QM1B with PySCF$_{\\text{IPU}}$. (arXiv:2311.01135v1 [cs.LG])\nAbstract: The emergence of foundation models in Computer Vision and Natural Language Processing have resulted in immense progress on downstream tasks. This progress was enabled by datasets with billions of training examples. Similar benefits are yet to be unlocked for quantum chemistry, where the potential of deep learning is constrained by comparatively small datasets with 100k to 20M training examples. These datasets are limited in size because the labels are computed using the accurate (but computationally demanding) predictions of Density Functional Theory (DFT). Notably, prior DFT datasets were created using CPU supercomputers without leveraging hardware acceleration. In this paper, we take a first step towards utilising hardware accelerators by introducing the data generator PySCF$_{\\text{IPU}}$ using Intelligence Processing Units (IPUs). This allowed us to create the dataset QM1B with one billion training examples containing 9-11 heavy atoms. We demonstrate that a simple baseline neural n",
    "path": "papers/23/11/2311.01135.json",
    "total_tokens": 930,
    "translated_title": "用PySCF_IPU生成QM1B数据集",
    "translated_abstract": "计算机视觉和自然语言处理中的基础模型的出现在下游任务上取得了巨大的进展。这种进展得益于拥有数十亿个训练样本的数据集。相比之下，在量子化学领域还未实现类似的好处，因为深度学习的潜力受限于仅有10万到2000万个训练样本的相对较小数据集。这些数据集的规模有限，是因为标签是使用密度泛函理论（DFT）的准确（但计算量大）预测计算得出的。值得注意的是，之前的DFT数据集是使用CPU超级计算机创建的，没有利用硬件加速。在本文中，我们向利用硬件加速器迈出了第一步，引入了使用智能处理单元（IPU）的数据生成器PySCF_IPU。这使我们能够创建包含有9-11个重原子的十亿个训练样本的数据集QM1B。我们证明了一个简单的基准神经网络可以在这个数据集上表现优秀。",
    "tldr": "本文介绍了使用IPU硬件加速器的数据生成器PySCF_IPU来生成具有十亿个训练样本的QM1B数据集，此数据集包含9-11个重原子。通过对这个数据集的实验，我们证明了一个简单的基准神经网络的优秀性能。"
}