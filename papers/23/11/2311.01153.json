{
    "title": "ACES: Translation Accuracy Challenge Sets at WMT 2023. (arXiv:2311.01153v1 [cs.CL])",
    "abstract": "We benchmark the performance of segmentlevel metrics submitted to WMT 2023 using the ACES Challenge Set (Amrhein et al., 2022). The challenge set consists of 36K examples representing challenges from 68 phenomena and covering 146 language pairs. The phenomena range from simple perturbations at the word/character level to more complex errors based on discourse and real-world knowledge. For each metric, we provide a detailed profile of performance over a range of error categories as well as an overall ACES-Score for quick comparison. We also measure the incremental performance of the metrics submitted to both WMT 2023 and 2022. We find that 1) there is no clear winner among the metrics submitted to WMT 2023, and 2) performance change between the 2023 and 2022 versions of the metrics is highly variable. Our recommendations are similar to those from WMT 2022. Metric developers should focus on: building ensembles of metrics from different design families, developing metrics that pay more at",
    "link": "http://arxiv.org/abs/2311.01153",
    "context": "Title: ACES: Translation Accuracy Challenge Sets at WMT 2023. (arXiv:2311.01153v1 [cs.CL])\nAbstract: We benchmark the performance of segmentlevel metrics submitted to WMT 2023 using the ACES Challenge Set (Amrhein et al., 2022). The challenge set consists of 36K examples representing challenges from 68 phenomena and covering 146 language pairs. The phenomena range from simple perturbations at the word/character level to more complex errors based on discourse and real-world knowledge. For each metric, we provide a detailed profile of performance over a range of error categories as well as an overall ACES-Score for quick comparison. We also measure the incremental performance of the metrics submitted to both WMT 2023 and 2022. We find that 1) there is no clear winner among the metrics submitted to WMT 2023, and 2) performance change between the 2023 and 2022 versions of the metrics is highly variable. Our recommendations are similar to those from WMT 2022. Metric developers should focus on: building ensembles of metrics from different design families, developing metrics that pay more at",
    "path": "papers/23/11/2311.01153.json",
    "total_tokens": 970,
    "translated_title": "ACES: WMT 2023中的翻译准确性挑战集",
    "translated_abstract": "我们使用ACES挑战集（Amrhein等人，2022）对提交到WMT 2023的segment-level评估指标进行了基准测试。该挑战集包含36K个示例，代表了来自68种现象的挑战，并涵盖了146种语言对。这些现象的范围从单词/字符级的简单扰动到基于话语和现实世界知识的更复杂的错误。对于每个指标，我们提供了在一系列错误类别上的详细性能概况，以及一个用于快速比较的整体ACES-Score。我们还测量了提交给WMT 2023和2022的指标的增量性能。我们发现：1）在提交给WMT 2023的指标中没有明显的赢家，2）2023年版和2022年版指标之间的性能变化很大。我们的建议与WMT 2022的建议类似。指标开发者应该专注于：从不同设计家族构建指标集合，开发更加关注+的指标",
    "tldr": "本论文介绍了使用ACES挑战集对WMT 2023中的segment-level评估指标进行了基准测试，发现没有明确的赢家，并且2023年版和2022年版指标之间的性能变化很大。建议指标开发者应该构建不同设计家族的指标集合，并开发更加关注整体性能的指标。"
}