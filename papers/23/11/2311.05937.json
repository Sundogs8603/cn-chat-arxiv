{
    "title": "Genetic Algorithm enhanced by Deep Reinforcement Learning in parent selection mechanism and mutation : Minimizing makespan in permutation flow shop scheduling problems. (arXiv:2311.05937v2 [cs.NE] UPDATED)",
    "abstract": "This paper introduces a reinforcement learning (RL) approach to address the challenges associated with configuring and optimizing genetic algorithms (GAs) for solving difficult combinatorial or non-linear problems. The proposed RL+GA method was specifically tested on the flow shop scheduling problem (FSP). The hybrid algorithm incorporates neural networks (NN) and uses the off-policy method Q-learning or the on-policy method Sarsa(0) to control two key genetic algorithm (GA) operators: parent selection mechanism and mutation. At each generation, the RL agent's action is determining the selection method, the probability of the parent selection and the probability of the offspring mutation. This allows the RL agent to dynamically adjust the selection and mutation based on its learned policy. The results of the study highlight the effectiveness of the RL+GA approach in improving the performance of the primitive GA. They also demonstrate its ability to learn and adapt from population diver",
    "link": "http://arxiv.org/abs/2311.05937",
    "context": "Title: Genetic Algorithm enhanced by Deep Reinforcement Learning in parent selection mechanism and mutation : Minimizing makespan in permutation flow shop scheduling problems. (arXiv:2311.05937v2 [cs.NE] UPDATED)\nAbstract: This paper introduces a reinforcement learning (RL) approach to address the challenges associated with configuring and optimizing genetic algorithms (GAs) for solving difficult combinatorial or non-linear problems. The proposed RL+GA method was specifically tested on the flow shop scheduling problem (FSP). The hybrid algorithm incorporates neural networks (NN) and uses the off-policy method Q-learning or the on-policy method Sarsa(0) to control two key genetic algorithm (GA) operators: parent selection mechanism and mutation. At each generation, the RL agent's action is determining the selection method, the probability of the parent selection and the probability of the offspring mutation. This allows the RL agent to dynamically adjust the selection and mutation based on its learned policy. The results of the study highlight the effectiveness of the RL+GA approach in improving the performance of the primitive GA. They also demonstrate its ability to learn and adapt from population diver",
    "path": "papers/23/11/2311.05937.json",
    "total_tokens": 945,
    "translated_title": "使用深度强化学习增强的遗传算法在父代选择机制和变异方面：在排列流水车间调度问题中最小化完工时间",
    "translated_abstract": "本文引入了一种强化学习（RL）方法来解决配置和优化遗传算法（GA）以解决困难的组合或非线性问题所面临的挑战。提出的RL+GA方法专门在流水车间调度问题（FSP）上进行了测试。该混合算法结合了神经网络（NN），并使用离策略方法Q-learning或在线策略方法Sarsa（0）来控制两个关键的遗传算法（GA）运算符：父代选择机制和变异。在每一代中，RL代理的动作决定了选择方法，父代选择的概率和后代变异的概率。这使得RL代理能够根据其学习的策略动态调整选择和变异。研究结果突出了RL+GA方法在改进原始GA性能方面的有效性。它们还证明了它学习和适应群体多样性的能力。",
    "tldr": "本研究通过引入强化学习方法，在遗传算法的父代选择机制和变异方面进行增强，从而在排列流水车间调度问题中最小化完工时间。这种RL+GA方法通过动态调整选择和变异，有效地改进了原始GA的性能，并表现出适应群体多样性的能力。",
    "en_tdlr": "This study enhances the genetic algorithm in the parent selection mechanism and mutation by introducing reinforcement learning. It minimizes the makespan in permutation flow shop scheduling problems by dynamically adjusting the selection and mutation, improving the GA's performance, and demonstrating the ability to adapt to population diversity."
}