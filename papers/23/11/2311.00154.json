{
    "title": "Medi-CAT: Contrastive Adversarial Training for Medical Image Classification. (arXiv:2311.00154v1 [eess.IV])",
    "abstract": "There are not many large medical image datasets available. For these datasets, too small deep learning models can't learn useful features, so they don't work well due to underfitting, and too big models tend to overfit the limited data. As a result, there is a compromise between the two issues. This paper proposes a training strategy Medi-CAT to overcome the underfitting and overfitting phenomena in medical imaging datasets. Specifically, the proposed training methodology employs large pre-trained vision transformers to overcome underfitting and adversarial and contrastive learning techniques to prevent overfitting. The proposed method is trained and evaluated on four medical image classification datasets from the MedMNIST collection. Our experimental results indicate that the proposed approach improves the accuracy up to 2% on three benchmark datasets compared to well-known approaches, whereas it increases the performance up to 4.1% over the baseline methods.",
    "link": "http://arxiv.org/abs/2311.00154",
    "context": "Title: Medi-CAT: Contrastive Adversarial Training for Medical Image Classification. (arXiv:2311.00154v1 [eess.IV])\nAbstract: There are not many large medical image datasets available. For these datasets, too small deep learning models can't learn useful features, so they don't work well due to underfitting, and too big models tend to overfit the limited data. As a result, there is a compromise between the two issues. This paper proposes a training strategy Medi-CAT to overcome the underfitting and overfitting phenomena in medical imaging datasets. Specifically, the proposed training methodology employs large pre-trained vision transformers to overcome underfitting and adversarial and contrastive learning techniques to prevent overfitting. The proposed method is trained and evaluated on four medical image classification datasets from the MedMNIST collection. Our experimental results indicate that the proposed approach improves the accuracy up to 2% on three benchmark datasets compared to well-known approaches, whereas it increases the performance up to 4.1% over the baseline methods.",
    "path": "papers/23/11/2311.00154.json",
    "total_tokens": 991,
    "translated_title": "Medi-CAT：对医学图像分类的对比性对抗训练",
    "translated_abstract": "目前可用的大型医学图像数据集不多。对于这些数据集，太小的深度学习模型无法学习到有用的特征，因此由于欠拟合而效果不佳，而太大的模型则倾向于过拟合有限的数据。因此，解决这两个问题之间需要做出折中。本文提出了一种训练策略——Medi-CAT，以克服医学图像数据集中的欠拟合和过拟合现象。具体而言，所提出的训练方法采用了大型预训练视觉转换器来解决欠拟合问题，并使用对抗性和对比性学习技术来防止过拟合。所提出的方法在MedMNIST集合中的四个医学图像分类数据集上进行了训练和评估。我们的实验结果表明，与众所周知的方法相比，所提出的方法在三个基准数据集上的准确率提高了2％，而在基线方法上的性能提高了4.1％。",
    "tldr": "本文提出了一种名为Medi-CAT的训练策略，以克服医学图像数据集中的欠拟合和过拟合现象。该方法利用大型预训练视觉转换器来解决欠拟合问题，并采用对抗性和对比性学习技术来防止过拟合。实验证明，该方法在多个医学图像分类数据集上具有较高的准确率和性能提升。"
}