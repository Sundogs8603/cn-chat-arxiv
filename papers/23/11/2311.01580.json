{
    "title": "MetaReVision: Meta-Learning with Retrieval for Visually Grounded Compositional Concept Acquisition. (arXiv:2311.01580v1 [cs.CL])",
    "abstract": "Humans have the ability to learn novel compositional concepts by recalling and generalizing primitive concepts acquired from past experiences. Inspired by this observation, in this paper, we propose MetaReVision, a retrieval-enhanced meta-learning model to address the visually grounded compositional concept learning problem. The proposed MetaReVision consists of a retrieval module and a meta-learning module which are designed to incorporate retrieved primitive concepts as a supporting set to meta-train vision-anguage models for grounded compositional concept recognition. Through meta-learning from episodes constructed by the retriever, MetaReVision learns a generic compositional representation that can be fast updated to recognize novel compositional concepts. We create CompCOCO and CompFlickr to benchmark the grounded compositional concept learning. Our experimental results show that MetaReVision outperforms other competitive baselines and the retrieval module plays an important role ",
    "link": "http://arxiv.org/abs/2311.01580",
    "context": "Title: MetaReVision: Meta-Learning with Retrieval for Visually Grounded Compositional Concept Acquisition. (arXiv:2311.01580v1 [cs.CL])\nAbstract: Humans have the ability to learn novel compositional concepts by recalling and generalizing primitive concepts acquired from past experiences. Inspired by this observation, in this paper, we propose MetaReVision, a retrieval-enhanced meta-learning model to address the visually grounded compositional concept learning problem. The proposed MetaReVision consists of a retrieval module and a meta-learning module which are designed to incorporate retrieved primitive concepts as a supporting set to meta-train vision-anguage models for grounded compositional concept recognition. Through meta-learning from episodes constructed by the retriever, MetaReVision learns a generic compositional representation that can be fast updated to recognize novel compositional concepts. We create CompCOCO and CompFlickr to benchmark the grounded compositional concept learning. Our experimental results show that MetaReVision outperforms other competitive baselines and the retrieval module plays an important role ",
    "path": "papers/23/11/2311.01580.json",
    "total_tokens": 847,
    "translated_title": "MetaReVision: 使用检索进行元学习的视觉基础组合概念获取",
    "translated_abstract": "人类能够通过回忆和推广从过去的经验中获取的基本概念来学习新的组合概念。受到这一观察的启发，本文提出了一种检索增强的元学习模型 - MetaReVision，以解决视觉基础组合概念学习问题。MetaReVision由一个检索模块和一个元学习模块组成，旨在将检索到的基本概念作为支持集合并用于元训练视觉-语言模型来识别基于图像的组合概念。通过从检索器构建的episode进行元学习，MetaReVision学习到了一个通用的组合表示，可以快速更新以识别新的组合概念。我们创建了CompCOCO和CompFlickr来评估基于图像的组合概念学习。实验结果表明，MetaReVision优于其他竞争基线，并且检索模块起着重要作用。",
    "tldr": "MetaReVision是一种检索增强的元学习模型，通过使用检索到的基本概念作为支持集合来快速学习和识别新的图像基础组合概念。",
    "en_tdlr": "MetaReVision is a retrieval-enhanced meta-learning model that utilizes retrieved primitive concepts as a supporting set to quickly learn and recognize novel visually grounded compositional concepts."
}