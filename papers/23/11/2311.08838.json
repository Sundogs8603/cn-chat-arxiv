{
    "title": "Disinformation Capabilities of Large Language Models",
    "abstract": "arXiv:2311.08838v2 Announce Type: replace  Abstract: Automated disinformation generation is often listed as an important risk associated with large language models (LLMs). The theoretical ability to flood the information space with disinformation content might have dramatic consequences for societies around the world. This paper presents a comprehensive study of the disinformation capabilities of the current generation of LLMs to generate false news articles in the English language. In our study, we evaluated the capabilities of 10 LLMs using 20 disinformation narratives. We evaluated several aspects of the LLMs: how good they are at generating news articles, how strongly they tend to agree or disagree with the disinformation narratives, how often they generate safety warnings, etc. We also evaluated the abilities of detection models to detect these articles as LLM-generated. We conclude that LLMs are able to generate convincing news articles that agree with dangerous disinformation na",
    "link": "https://arxiv.org/abs/2311.08838",
    "context": "Title: Disinformation Capabilities of Large Language Models\nAbstract: arXiv:2311.08838v2 Announce Type: replace  Abstract: Automated disinformation generation is often listed as an important risk associated with large language models (LLMs). The theoretical ability to flood the information space with disinformation content might have dramatic consequences for societies around the world. This paper presents a comprehensive study of the disinformation capabilities of the current generation of LLMs to generate false news articles in the English language. In our study, we evaluated the capabilities of 10 LLMs using 20 disinformation narratives. We evaluated several aspects of the LLMs: how good they are at generating news articles, how strongly they tend to agree or disagree with the disinformation narratives, how often they generate safety warnings, etc. We also evaluated the abilities of detection models to detect these articles as LLM-generated. We conclude that LLMs are able to generate convincing news articles that agree with dangerous disinformation na",
    "path": "papers/23/11/2311.08838.json",
    "total_tokens": 817,
    "translated_title": "大型语言模型的虚假信息能力",
    "translated_abstract": "自动虚假信息生成经常被列为大型语言模型（LLMs）相关的重要风险。在信息空间中充斥虚假信息内容的理论能力可能对全球社会产生重大影响。本文对当前一代LLMs的虚假信息能力进行了全面研究，生成了英语虚假新闻文章。在研究中，我们使用20个虚假信息叙事评估了10个LLMs的能力。我们评估了LLMs的几个方面：它们生成新闻文章的效果如何，它们倾向于支持或反对虚假叙事的程度如何，它们生成安全警告的频率等。我们还评估了检测模型检测这些文章是否为LLM生成。我们得出结论，LLMs能够生成令人信服的新闻文章，支持危险的虚假信息。",
    "tldr": "本文研究了当前一代大型语言模型在生成英语虚假新闻文章方面的能力，发现它们能够生成令人信服的支持危险虚假信息的新闻文章。",
    "en_tdlr": "This paper investigated the disinformation capabilities of the current generation of large language models in generating false news articles in English and found that they are able to generate convincing news articles that support dangerous disinformation."
}