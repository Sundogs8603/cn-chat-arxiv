{
    "title": "Learning Realistic Traffic Agents in Closed-loop. (arXiv:2311.01394v1 [cs.RO])",
    "abstract": "Realistic traffic simulation is crucial for developing self-driving software in a safe and scalable manner prior to real-world deployment. Typically, imitation learning (IL) is used to learn human-like traffic agents directly from real-world observations collected offline, but without explicit specification of traffic rules, agents trained from IL alone frequently display unrealistic infractions like collisions and driving off the road. This problem is exacerbated in out-of-distribution and long-tail scenarios. On the other hand, reinforcement learning (RL) can train traffic agents to avoid infractions, but using RL alone results in unhuman-like driving behaviors. We propose Reinforcing Traffic Rules (RTR), a holistic closed-loop learning objective to match expert demonstrations under a traffic compliance constraint, which naturally gives rise to a joint IL + RL approach, obtaining the best of both worlds. Our method learns in closed-loop simulations of both nominal scenarios from real",
    "link": "http://arxiv.org/abs/2311.01394",
    "context": "Title: Learning Realistic Traffic Agents in Closed-loop. (arXiv:2311.01394v1 [cs.RO])\nAbstract: Realistic traffic simulation is crucial for developing self-driving software in a safe and scalable manner prior to real-world deployment. Typically, imitation learning (IL) is used to learn human-like traffic agents directly from real-world observations collected offline, but without explicit specification of traffic rules, agents trained from IL alone frequently display unrealistic infractions like collisions and driving off the road. This problem is exacerbated in out-of-distribution and long-tail scenarios. On the other hand, reinforcement learning (RL) can train traffic agents to avoid infractions, but using RL alone results in unhuman-like driving behaviors. We propose Reinforcing Traffic Rules (RTR), a holistic closed-loop learning objective to match expert demonstrations under a traffic compliance constraint, which naturally gives rise to a joint IL + RL approach, obtaining the best of both worlds. Our method learns in closed-loop simulations of both nominal scenarios from real",
    "path": "papers/23/11/2311.01394.json",
    "total_tokens": 886,
    "translated_title": "在闭环中学习真实交通代理",
    "translated_abstract": "在真实的交通模拟中学习交通代理对于在实际部署前以安全和可扩展的方式开发自动驾驶软件至关重要。通常，模仿学习(Imitation Learning, IL)用于直接从离线收集的真实观测中学习类似人类的交通代理，但在没有明确交通规则的情况下，仅通过IL训练的代理经常表现出碰撞和偏离道路等不真实的违规行为。这个问题在分布不同和长尾场景下被放大。另一方面，强化学习(Reinforcement Learning, RL)可以训练交通代理避免违规行为，但仅使用RL会导致不像人类驾驶行为的结果。我们提出了强化交通规则(Reinforcing Traffic Rules, RTR)，这是一个综合的闭环学习目标，以在交通合规约束下匹配专家演示，自然地产生了一种联合IL+RL方法，兼具二者的优点。我们的方法在真实场景和闭环模拟中学习，",
    "tldr": "本文提出了一种在闭环中学习真实交通代理的方法，利用模仿学习和强化学习相结合的方式，通过匹配专家演示的方式，实现了更加真实和合规的驾驶行为。",
    "en_tdlr": "This paper proposes a method to learn realistic traffic agents in closed-loop by combining imitation learning and reinforcement learning, achieving more realistic and compliant driving behaviors through matching expert demonstrations."
}