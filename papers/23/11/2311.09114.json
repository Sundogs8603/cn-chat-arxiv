{
    "title": "Ever: Mitigating Hallucination in Large Language Models through Real-Time Verification and Rectification",
    "abstract": "arXiv:2311.09114v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) have demonstrated remarkable proficiency in generating fluent text. However, they often encounter the challenge of generating inaccurate or hallucinated content. This issue is common in both non-retrieval-based generation and retrieval-augmented generation approaches, and existing post-hoc rectification methods may not address the accumulated hallucination errors that may be caused by the \"snowballing\" issue, especially in reasoning tasks. To tackle these challenges, we introduce a novel approach called Real-time Verification and Rectification (Ever). Instead of waiting until the end of the generation process to rectify hallucinations, Ever employs a real-time, step-wise generation and hallucination rectification strategy. The primary objective is to detect and rectify hallucinations as they occur during the text generation process. When compared to both retrieval-based and non-retrieval-based basel",
    "link": "https://arxiv.org/abs/2311.09114",
    "context": "Title: Ever: Mitigating Hallucination in Large Language Models through Real-Time Verification and Rectification\nAbstract: arXiv:2311.09114v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) have demonstrated remarkable proficiency in generating fluent text. However, they often encounter the challenge of generating inaccurate or hallucinated content. This issue is common in both non-retrieval-based generation and retrieval-augmented generation approaches, and existing post-hoc rectification methods may not address the accumulated hallucination errors that may be caused by the \"snowballing\" issue, especially in reasoning tasks. To tackle these challenges, we introduce a novel approach called Real-time Verification and Rectification (Ever). Instead of waiting until the end of the generation process to rectify hallucinations, Ever employs a real-time, step-wise generation and hallucination rectification strategy. The primary objective is to detect and rectify hallucinations as they occur during the text generation process. When compared to both retrieval-based and non-retrieval-based basel",
    "path": "papers/23/11/2311.09114.json",
    "total_tokens": 791,
    "translated_title": "通过实时验证和纠正减轻大型语言模型中的虚构问题",
    "translated_abstract": "大型语言模型(LLMs)在生成流畅文本方面表现出色。然而，它们经常遇到生成不准确或虚构内容的挑战。这个问题普遍存在于非基于检索的生成和检索增强生成方法中，现有的事后纠正方法可能无法解决“滚雪球”问题导致的累积虚构错误，特别是在推理任务中。为了解决这些挑战，我们提出了一种名为“Ever”的新方法。Ever采用实时、逐步的生成和虚构纠正策略，而不是等到生成过程结束才纠正虚构。其主要目标是在文本生成过程中检测和纠正虚构。与基于检索和非基于检索的基线模型相比，",
    "tldr": "通过实时验证和纠正的策略，文章提出了一种名为Ever的方法，用于减轻大型语言模型生成中的虚构问题。",
    "en_tdlr": "The paper introduces a method called Ever, which mitigates hallucination in large language models through real-time verification and rectification strategy, aiming to detect and rectify hallucinations as they occur during the text generation process."
}