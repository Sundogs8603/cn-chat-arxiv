{
    "title": "Towards Evaluating Transfer-based Attacks Systematically, Practically, and Fairly. (arXiv:2311.01323v1 [cs.LG])",
    "abstract": "The adversarial vulnerability of deep neural networks (DNNs) has drawn great attention due to the security risk of applying these models in real-world applications. Based on transferability of adversarial examples, an increasing number of transfer-based methods have been developed to fool black-box DNN models whose architecture and parameters are inaccessible. Although tremendous effort has been exerted, there still lacks a standardized benchmark that could be taken advantage of to compare these methods systematically, fairly, and practically. Our investigation shows that the evaluation of some methods needs to be more reasonable and more thorough to verify their effectiveness, to avoid, for example, unfair comparison and insufficient consideration of possible substitute/victim models. Therefore, we establish a transfer-based attack benchmark (TA-Bench) which implements 30+ methods. In this paper, we evaluate and compare them comprehensively on 25 popular substitute/victim models on Im",
    "link": "http://arxiv.org/abs/2311.01323",
    "context": "Title: Towards Evaluating Transfer-based Attacks Systematically, Practically, and Fairly. (arXiv:2311.01323v1 [cs.LG])\nAbstract: The adversarial vulnerability of deep neural networks (DNNs) has drawn great attention due to the security risk of applying these models in real-world applications. Based on transferability of adversarial examples, an increasing number of transfer-based methods have been developed to fool black-box DNN models whose architecture and parameters are inaccessible. Although tremendous effort has been exerted, there still lacks a standardized benchmark that could be taken advantage of to compare these methods systematically, fairly, and practically. Our investigation shows that the evaluation of some methods needs to be more reasonable and more thorough to verify their effectiveness, to avoid, for example, unfair comparison and insufficient consideration of possible substitute/victim models. Therefore, we establish a transfer-based attack benchmark (TA-Bench) which implements 30+ methods. In this paper, we evaluate and compare them comprehensively on 25 popular substitute/victim models on Im",
    "path": "papers/23/11/2311.01323.json",
    "total_tokens": 871,
    "translated_title": "将传递性攻击系统地、实用地和公正地进行评估",
    "translated_abstract": "深度神经网络（DNN）的对抗性脆弱性引起了极大关注，因为在现实世界应用这些模型存在安全风险。基于对抗样本的可传递性，已经开发了越来越多的传递性方法来欺骗无法访问其架构和参数的黑盒DNN模型。尽管付出了巨大努力，但仍然缺乏一个标准化的基准，以便系统、公正和实用地比较这些方法。我们的调查显示，某些方法的评估需要更合理、更全面地验证其有效性，避免不公平比较和对可能的替代/受害模型的不充分考虑。因此，我们建立了一个传递性攻击基准（TA-Bench），其中实施了30多种方法。在本文中，我们全面评估和比较了它们在25个热门替代/受害模型上的性能。",
    "tldr": "本文建立了一个传递性攻击基准（TA-Bench），评估了30多种方法在25个热门替代/受害模型上的性能，以系统地、公正地、实用地比较这些方法。"
}