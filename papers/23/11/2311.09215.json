{
    "title": "ConvNet vs Transformer, Supervised vs CLIP: Beyond ImageNet Accuracy. (arXiv:2311.09215v2 [cs.CV] UPDATED)",
    "abstract": "Modern computer vision offers a great variety of models to practitioners, and selecting a model from multiple options for specific applications can be challenging. Conventionally, competing model architectures and training protocols are compared by their classification accuracy on ImageNet. However, this single metric does not fully capture performance nuances critical for specialized tasks. In this work, we conduct an in-depth comparative analysis of model behaviors beyond ImageNet accuracy, for both ConvNet and Vision Transformer architectures, each across supervised and CLIP training paradigms. Although our selected models have similar ImageNet accuracies and compute requirements, we find that they differ in many other aspects: types of mistakes, output calibration, transferability, and feature invariance, among others. This diversity in model characteristics, not captured by traditional metrics, highlights the need for more nuanced analysis when choosing among different models. Our",
    "link": "http://arxiv.org/abs/2311.09215",
    "context": "Title: ConvNet vs Transformer, Supervised vs CLIP: Beyond ImageNet Accuracy. (arXiv:2311.09215v2 [cs.CV] UPDATED)\nAbstract: Modern computer vision offers a great variety of models to practitioners, and selecting a model from multiple options for specific applications can be challenging. Conventionally, competing model architectures and training protocols are compared by their classification accuracy on ImageNet. However, this single metric does not fully capture performance nuances critical for specialized tasks. In this work, we conduct an in-depth comparative analysis of model behaviors beyond ImageNet accuracy, for both ConvNet and Vision Transformer architectures, each across supervised and CLIP training paradigms. Although our selected models have similar ImageNet accuracies and compute requirements, we find that they differ in many other aspects: types of mistakes, output calibration, transferability, and feature invariance, among others. This diversity in model characteristics, not captured by traditional metrics, highlights the need for more nuanced analysis when choosing among different models. Our",
    "path": "papers/23/11/2311.09215.json",
    "total_tokens": 910,
    "translated_title": "ConvNet vs Transformer, Supervised vs CLIP: 超越ImageNet准确率",
    "translated_abstract": "现代计算机视觉为实践者提供了多种模型选择，对于特定应用从多个选项中选择模型可能具有挑战性。传统上，通过它们在ImageNet上的分类准确率来比较竞争模型架构和训练协议。然而，这个单一指标无法完全捕捉到对于专业任务至关重要的性能细微差别。在这项工作中，我们对ConvNet和Vision Transformer架构在监督和CLIP训练范式下进行了深入的比较分析，超越了ImageNet的准确率。尽管我们选择的模型在ImageNet准确率和计算需求上相似，我们发现它们在许多其他方面存在差异：错误类型、输出校准、可转移性和特征的不变性等。传统指标无法捕捉到的这种模型特性差异，突出了在选择不同模型时需要更加细致分析的必要性。",
    "tldr": "ConvNet和Transformer架构在监督和CLIP训练下，超越了ImageNet准确率的对比分析中发现它们在错误类型、输出校准、可转移性和特征的不变性等方面存在差异，突出了需要更加细致分析的必要性。",
    "en_tdlr": "In this work, a comparative analysis of ConvNet and Transformer architectures, trained with supervised and CLIP paradigms, is conducted beyond ImageNet accuracy. It is found that these models differ in aspects such as mistake types, output calibration, transferability, and feature invariance, highlighting the need for more nuanced analysis when choosing among different models."
}