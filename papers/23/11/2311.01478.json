{
    "title": "Adversary ML Resilience in Autonomous Driving Through Human Centered Perception Mechanisms. (arXiv:2311.01478v1 [cs.CV])",
    "abstract": "Physical adversarial attacks on road signs are continuously exploiting vulnerabilities in modern day autonomous vehicles (AVs) and impeding their ability to correctly classify what type of road sign they encounter. Current models cannot generalize input data well, resulting in overfitting or underfitting. In overfitting, the model memorizes the input data but cannot generalize to new scenarios. In underfitting, the model does not learn enough of the input data to accurately classify these road signs. This paper explores the resilience of autonomous driving systems against three main physical adversarial attacks (tape, graffiti, illumination), specifically targeting object classifiers. Several machine learning models were developed and evaluated on two distinct datasets: road signs (stop signs, speed limit signs, traffic lights, and pedestrian crosswalk signs) and geometric shapes (octagons, circles, squares, and triangles). The study compared algorithm performance under different condi",
    "link": "http://arxiv.org/abs/2311.01478",
    "context": "Title: Adversary ML Resilience in Autonomous Driving Through Human Centered Perception Mechanisms. (arXiv:2311.01478v1 [cs.CV])\nAbstract: Physical adversarial attacks on road signs are continuously exploiting vulnerabilities in modern day autonomous vehicles (AVs) and impeding their ability to correctly classify what type of road sign they encounter. Current models cannot generalize input data well, resulting in overfitting or underfitting. In overfitting, the model memorizes the input data but cannot generalize to new scenarios. In underfitting, the model does not learn enough of the input data to accurately classify these road signs. This paper explores the resilience of autonomous driving systems against three main physical adversarial attacks (tape, graffiti, illumination), specifically targeting object classifiers. Several machine learning models were developed and evaluated on two distinct datasets: road signs (stop signs, speed limit signs, traffic lights, and pedestrian crosswalk signs) and geometric shapes (octagons, circles, squares, and triangles). The study compared algorithm performance under different condi",
    "path": "papers/23/11/2311.01478.json",
    "total_tokens": 938,
    "translated_title": "自动驾驶中基于人类感知机制的对抗性机器学习韧性",
    "translated_abstract": "对道路标志的物理对抗攻击不断利用现代自动驾驶车辆中的漏洞，妨碍其正确分类所遇到的道路标志类型。目前的模型不能很好地泛化输入数据，导致过拟合或欠拟合。在过拟合中，模型记忆输入数据但不能推广到新的情景。在欠拟合中，模型对输入数据学习不足，不能准确分类这些道路标志。本文研究了自动驾驶系统在三种主要的物理对抗攻击（胶带、涂鸦、光照）下的韧性，特别针对对象分类器。开发了多个机器学习模型，并在两个不同的数据集上进行评估：道路标志（停车标志、限速标志、交通灯和人行横道标志）和几何形状（八边形、圆形、正方形和三角形）。研究比较了不同条件下算法的性能。",
    "tldr": "本研究通过开发和评估多个机器学习模型，研究了自动驾驶系统在胶带、涂鸦和光照等三种物理对抗攻击下的韧性，主要针对对象分类器。研究结果表明当前模型在泛化输入数据方面存在过拟合和欠拟合问题。",
    "en_tdlr": "This paper explores the resilience of autonomous driving systems against physical adversarial attacks, specifically targeting object classifiers. Multiple machine learning models were developed and evaluated, revealing the issues of overfitting and underfitting in current models for generalizing input data."
}