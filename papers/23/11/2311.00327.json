{
    "title": "Multi-task Representation Learning for Pure Exploration in Bilinear Bandits. (arXiv:2311.00327v1 [cs.LG])",
    "abstract": "We study multi-task representation learning for the problem of pure exploration in bilinear bandits. In bilinear bandits, an action takes the form of a pair of arms from two different entity types and the reward is a bilinear function of the known feature vectors of the arms. In the \\textit{multi-task bilinear bandit problem}, we aim to find optimal actions for multiple tasks that share a common low-dimensional linear representation. The objective is to leverage this characteristic to expedite the process of identifying the best pair of arms for all tasks. We propose the algorithm GOBLIN that uses an experimental design approach to optimize sample allocations for learning the global representation as well as minimize the number of samples needed to identify the optimal pair of arms in individual tasks. To the best of our knowledge, this is the first study to give sample complexity analysis for pure exploration in bilinear bandits with shared representation. Our results demonstrate that",
    "link": "http://arxiv.org/abs/2311.00327",
    "context": "Title: Multi-task Representation Learning for Pure Exploration in Bilinear Bandits. (arXiv:2311.00327v1 [cs.LG])\nAbstract: We study multi-task representation learning for the problem of pure exploration in bilinear bandits. In bilinear bandits, an action takes the form of a pair of arms from two different entity types and the reward is a bilinear function of the known feature vectors of the arms. In the \\textit{multi-task bilinear bandit problem}, we aim to find optimal actions for multiple tasks that share a common low-dimensional linear representation. The objective is to leverage this characteristic to expedite the process of identifying the best pair of arms for all tasks. We propose the algorithm GOBLIN that uses an experimental design approach to optimize sample allocations for learning the global representation as well as minimize the number of samples needed to identify the optimal pair of arms in individual tasks. To the best of our knowledge, this is the first study to give sample complexity analysis for pure exploration in bilinear bandits with shared representation. Our results demonstrate that",
    "path": "papers/23/11/2311.00327.json",
    "total_tokens": 854,
    "translated_title": "多任务表示学习用于双线性bandit中的纯探索问题",
    "translated_abstract": "我们研究了多任务表示学习在双线性bandit的纯探索问题中的应用。在双线性bandit中，一个动作由来自两种不同实体类型的两个臂构成，奖励是两个臂的已知特征向量的双线性函数。在多任务双线性bandit问题中，我们的目标是寻找多个任务的最佳动作，这些任务共享一个共同的低维线性表示。我们的目标是利用这个特征加速确定所有任务的最佳臂对的过程。我们提出了算法GOBLIN，该算法使用实验设计方法来优化学习全局表示的样本分配，并最小化识别个别任务中最佳臂对所需的样本数。据我们所知，这是第一项在共享表示下对双线性bandit中的纯探索问题进行样本复杂性分析的研究。我们的结果表明，",
    "tldr": "这项研究通过多任务表示学习解决了双线性bandit中的纯探索问题，并提出了GOBLIN算法来优化样本分配和减小样本数量，在共享表示下实现了较高的效率。"
}