{
    "title": "Distort, Distract, Decode: Instruction-Tuned Model Can Refine its Response from Noisy Instructions. (arXiv:2311.00233v1 [cs.CL])",
    "abstract": "While instruction-tuned language models have demonstrated impressive zero-shot generalization, these models often struggle to generate accurate responses when faced with instructions that fall outside their training set. This paper presents Instructive Decoding (ID), a simple yet effective approach that augments the efficacy of instruction-tuned models. Specifically, ID adjusts the logits for next-token prediction in a contrastive manner, utilizing predictions generated from a manipulated version of the original instruction, referred to as a noisy instruction. This noisy instruction aims to elicit responses that could diverge from the intended instruction yet remain plausible. We conduct experiments across a spectrum of such noisy instructions, ranging from those that insert semantic noise via random words to others like 'opposite' that elicit the deviated responses. Our approach achieves considerable performance gains across various instruction-tuned models and tasks without necessita",
    "link": "http://arxiv.org/abs/2311.00233",
    "context": "Title: Distort, Distract, Decode: Instruction-Tuned Model Can Refine its Response from Noisy Instructions. (arXiv:2311.00233v1 [cs.CL])\nAbstract: While instruction-tuned language models have demonstrated impressive zero-shot generalization, these models often struggle to generate accurate responses when faced with instructions that fall outside their training set. This paper presents Instructive Decoding (ID), a simple yet effective approach that augments the efficacy of instruction-tuned models. Specifically, ID adjusts the logits for next-token prediction in a contrastive manner, utilizing predictions generated from a manipulated version of the original instruction, referred to as a noisy instruction. This noisy instruction aims to elicit responses that could diverge from the intended instruction yet remain plausible. We conduct experiments across a spectrum of such noisy instructions, ranging from those that insert semantic noise via random words to others like 'opposite' that elicit the deviated responses. Our approach achieves considerable performance gains across various instruction-tuned models and tasks without necessita",
    "path": "papers/23/11/2311.00233.json",
    "total_tokens": 903,
    "translated_title": "扭曲，分散，解码：指令调节模型能够根据嘈杂的指令改进其响应",
    "translated_abstract": "虽然经过指令调节的语言模型在零-shot泛化方面表现出色，但是当面临超出训练范围的指令时，这些模型往往难以生成准确的响应。本文提出了Instructive Decoding（ID）的方法，这是一种简单且有效的方法，可以增强指令调节模型的效果。具体而言，ID通过对下一个标记预测的logits进行对比性调整，利用从原始指令的操纵版本生成的预测，即嘈杂指令。这个嘈杂指令旨在引发与预期指令不一致但仍然合理的响应。我们在一系列此类嘈杂指令上进行了实验，从通过随机词插入语义噪声到像“相反”的其他指令，以引发偏离的响应。我们的方法在各种指令调节模型和任务中取得了相当大的性能提升，而无需",
    "tldr": "本文提出了一种简单而有效的方法，通过对比性调整预测，利用嘈杂指令来增强指令调节模型的效果，从而改进了面临超出训练范围的指令时的响应准确性。"
}