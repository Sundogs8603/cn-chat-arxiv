{
    "title": "Contrastive Modules with Temporal Attention for Multi-Task Reinforcement Learning. (arXiv:2311.01075v1 [cs.LG])",
    "abstract": "In the field of multi-task reinforcement learning, the modular principle, which involves specializing functionalities into different modules and combining them appropriately, has been widely adopted as a promising approach to prevent the negative transfer problem that performance degradation due to conflicts between tasks. However, most of the existing multi-task RL methods only combine shared modules at the task level, ignoring that there may be conflicts within the task. In addition, these methods do not take into account that without constraints, some modules may learn similar functions, resulting in restricting the model's expressiveness and generalization capability of modular methods. In this paper, we propose the Contrastive Modules with Temporal Attention(CMTA) method to address these limitations. CMTA constrains the modules to be different from each other by contrastive learning and combining shared modules at a finer granularity than the task level with temporal attention, al",
    "link": "http://arxiv.org/abs/2311.01075",
    "context": "Title: Contrastive Modules with Temporal Attention for Multi-Task Reinforcement Learning. (arXiv:2311.01075v1 [cs.LG])\nAbstract: In the field of multi-task reinforcement learning, the modular principle, which involves specializing functionalities into different modules and combining them appropriately, has been widely adopted as a promising approach to prevent the negative transfer problem that performance degradation due to conflicts between tasks. However, most of the existing multi-task RL methods only combine shared modules at the task level, ignoring that there may be conflicts within the task. In addition, these methods do not take into account that without constraints, some modules may learn similar functions, resulting in restricting the model's expressiveness and generalization capability of modular methods. In this paper, we propose the Contrastive Modules with Temporal Attention(CMTA) method to address these limitations. CMTA constrains the modules to be different from each other by contrastive learning and combining shared modules at a finer granularity than the task level with temporal attention, al",
    "path": "papers/23/11/2311.01075.json",
    "total_tokens": 830,
    "translated_title": "多任务强化学习中具有时间注意力的对比模块",
    "translated_abstract": "在多任务强化学习领域，模块化原则被广泛采用作为一种有前景的方法，通过将功能专门化到不同的模块中并适当地组合它们，以防止由于任务间冲突而导致的性能下降问题。然而，大多数现有的多任务RL方法只在任务级别上组合共享模块，忽视了任务内可能存在的冲突。此外，这些方法没有考虑到，如果没有约束，一些模块可能会学习相似的功能，从而限制了模块化方法的表达能力和推广能力。在本文中，我们提出了具有时间注意力的对比模块（CMTA）方法来解决这些限制。",
    "tldr": "本文提出了一种名为对比模块与时间注意力(CMTA)的方法，该方法通过对比学习使模块之间的差异，并以更细粒度的方式在任务级别之下使用共享模块和时间注意力来解决多任务领域中现有方法的限制。",
    "en_tdlr": "This paper proposes a method called Contrastive Modules with Temporal Attention (CMTA) to address the limitations of existing methods in the field of multi-task reinforcement learning. CMTA constrains the modules to be different from each other through contrastive learning, and combines shared modules at a finer granularity than the task level with temporal attention."
}