{
    "title": "Responsible Emergent Multi-Agent Behavior. (arXiv:2311.01609v1 [cs.AI])",
    "abstract": "Responsible AI has risen to the forefront of the AI research community. As neural network-based learning algorithms continue to permeate real-world applications, the field of Responsible AI has played a large role in ensuring that such systems maintain a high-level of human-compatibility. Despite this progress, the state of the art in Responsible AI has ignored one crucial point: human problems are multi-agent problems. Predominant approaches largely consider the performance of a single AI system in isolation, but human problems are, by their very nature, multi-agent. From driving in traffic to negotiating economic policy, human problem-solving involves interaction and the interplay of the actions and motives of multiple individuals.  This dissertation develops the study of responsible emergent multi-agent behavior, illustrating how researchers and practitioners can better understand and shape multi-agent learning with respect to three pillars of Responsible AI: interpretability, fairn",
    "link": "http://arxiv.org/abs/2311.01609",
    "context": "Title: Responsible Emergent Multi-Agent Behavior. (arXiv:2311.01609v1 [cs.AI])\nAbstract: Responsible AI has risen to the forefront of the AI research community. As neural network-based learning algorithms continue to permeate real-world applications, the field of Responsible AI has played a large role in ensuring that such systems maintain a high-level of human-compatibility. Despite this progress, the state of the art in Responsible AI has ignored one crucial point: human problems are multi-agent problems. Predominant approaches largely consider the performance of a single AI system in isolation, but human problems are, by their very nature, multi-agent. From driving in traffic to negotiating economic policy, human problem-solving involves interaction and the interplay of the actions and motives of multiple individuals.  This dissertation develops the study of responsible emergent multi-agent behavior, illustrating how researchers and practitioners can better understand and shape multi-agent learning with respect to three pillars of Responsible AI: interpretability, fairn",
    "path": "papers/23/11/2311.01609.json",
    "total_tokens": 901,
    "translated_title": "负责任的新兴多智能体行为",
    "translated_abstract": "负责任的人工智能已经成为人工智能研究社区的焦点。随着基于神经网络的学习算法在实际应用中的普及，负责任人工智能领域在确保这些系统保持高度人类兼容性方面起到了重要作用。尽管取得了进展，负责任人工智能的现有技术却忽视了一个关键点：人类问题是多智能体问题。主流方法主要考虑单个人工智能系统在孤立环境中的性能，但人类问题本质上是多智能体问题。从驾车到谈判经济政策，人类问题解决涉及多个个体的相互作用和行为动机的相互作用。本论文开展了负责任的新兴多智能体行为的研究，展示了研究人员和从业者如何更好地理解和塑造多智能体学习与负责任人工智能的三个支柱：可解释性、公正性、代理回应。",
    "tldr": "这篇论文研究了负责任的新兴多智能体行为，探讨了在可解释性和公正性的框架下如何理解和塑造多智能体学习，并强调了人类问题解决的多智能体的本质特征。",
    "en_tdlr": "This paper investigates responsible emergent multi-agent behavior, exploring how to understand and shape multi-agent learning within the frameworks of interpretability and fairness, and emphasizes the inherent multi-agent nature of human problem-solving."
}