{
    "title": "Loss Modeling for Multi-Annotator Datasets. (arXiv:2311.00619v1 [cs.LG])",
    "abstract": "Accounting for the opinions of all annotators of a dataset is critical for fairness. However, when annotating large datasets, individual annotators will frequently provide thousands of ratings which can lead to fatigue. Additionally, these annotation processes can occur over multiple days which can lead to an inaccurate representation of an annotator's opinion over time. To combat this, we propose to learn a more accurate representation of diverse opinions by utilizing multitask learning in conjunction with loss-based label correction. We show that using our novel formulation, we can cleanly separate agreeing and disagreeing annotations. Furthermore, we demonstrate that this modification can improve prediction performance in a single or multi-annotator setting. Lastly, we show that this method remains robust to additional label noise that is applied to subjective data.",
    "link": "http://arxiv.org/abs/2311.00619",
    "context": "Title: Loss Modeling for Multi-Annotator Datasets. (arXiv:2311.00619v1 [cs.LG])\nAbstract: Accounting for the opinions of all annotators of a dataset is critical for fairness. However, when annotating large datasets, individual annotators will frequently provide thousands of ratings which can lead to fatigue. Additionally, these annotation processes can occur over multiple days which can lead to an inaccurate representation of an annotator's opinion over time. To combat this, we propose to learn a more accurate representation of diverse opinions by utilizing multitask learning in conjunction with loss-based label correction. We show that using our novel formulation, we can cleanly separate agreeing and disagreeing annotations. Furthermore, we demonstrate that this modification can improve prediction performance in a single or multi-annotator setting. Lastly, we show that this method remains robust to additional label noise that is applied to subjective data.",
    "path": "papers/23/11/2311.00619.json",
    "total_tokens": 851,
    "translated_title": "多注释者数据的损失建模",
    "translated_abstract": "在公正性方面，考虑到数据集中所有注释者的意见至关重要。然而，在注释大型数据集时，个别注释者经常会提供数千个评分，这可能导致疲劳。此外，这些注释过程可能会持续多天，可能导致对注释者的意见随时间的不准确表示。为了解决这个问题，我们提出利用多任务学习和基于损失的标签修正来学习更准确的多样意见表示。我们展示了使用我们新颖的公式，我们可以清楚地分离赞同和不赞同的注释。此外，我们证明了这种修改可以改善单一或多注释者设置下的预测性能。最后，我们证明了该方法对应用于主观数据的额外标签噪声仍然具有稳健性。",
    "tldr": "该论文提出了一种通过利用多任务学习和基于损失的标签修正来学习多注释者数据的准确表示的方法。通过这种方法，可以有效地分离赞同和不赞同的注释，并且在单一或多注释者设置下改善预测性能。该方法还显示出对主观数据的额外标签噪声具有鲁棒性。",
    "en_tdlr": "This paper proposes a method to learn accurate representations of multi-annotator datasets by using multitask learning and loss-based label correction. It effectively separates agreeing and disagreeing annotations and improves prediction performance in a single or multi-annotator setting. The method is also robust to additional label noise applied to subjective data."
}