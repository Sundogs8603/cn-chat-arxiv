{
    "title": "Enhancing Object Coherence in Layout-to-Image Synthesis",
    "abstract": "arXiv:2311.10522v4 Announce Type: replace-cross  Abstract: Layout-to-image synthesis is an emerging technique in conditional image generation. It aims to generate complex scenes, where users require fine control over the layout of the objects in a scene. However, it remains challenging to control the object coherence, including semantic coherence (e.g., the cat looks at the flowers or not) and physical coherence (e.g., the hand and the racket should not be misaligned). In this paper, we propose a novel diffusion model with effective global semantic fusion (GSF) and self-similarity feature enhancement modules to guide the object coherence for this task. For semantic coherence, we argue that the image caption contains rich information for defining the semantic relationship within the objects in the images. Instead of simply employing cross-attention between captions and generated images, which addresses the highly relevant layout restriction and semantic coherence separately and thus lea",
    "link": "https://arxiv.org/abs/2311.10522",
    "context": "Title: Enhancing Object Coherence in Layout-to-Image Synthesis\nAbstract: arXiv:2311.10522v4 Announce Type: replace-cross  Abstract: Layout-to-image synthesis is an emerging technique in conditional image generation. It aims to generate complex scenes, where users require fine control over the layout of the objects in a scene. However, it remains challenging to control the object coherence, including semantic coherence (e.g., the cat looks at the flowers or not) and physical coherence (e.g., the hand and the racket should not be misaligned). In this paper, we propose a novel diffusion model with effective global semantic fusion (GSF) and self-similarity feature enhancement modules to guide the object coherence for this task. For semantic coherence, we argue that the image caption contains rich information for defining the semantic relationship within the objects in the images. Instead of simply employing cross-attention between captions and generated images, which addresses the highly relevant layout restriction and semantic coherence separately and thus lea",
    "path": "papers/23/11/2311.10522.json",
    "total_tokens": 817,
    "translated_title": "提升布局到图像合成中的对象连贯性",
    "translated_abstract": "布局到图像合成是一种新兴的条件图像生成技术。它旨在生成复杂场景，用户可以对场景中的对象布局进行精细控制。然而，控制对象连贯性，包括语义连贯性（例如，猫是否看向花朵）和物理连贯性（例如，手和球拍不应错位）仍然具有挑战性。在本文中，我们提出了一种新颖的扩散模型，配备了有效的全局语义融合（GSF）和自相似特征增强模块，以引导该任务的对象连贯性。对于语义连贯性，我们认为图像标题包含丰富信息，可以定义图像中对象之间的语义关系。与其简单地使用标题和生成图像之间的跨注意力，我们提出了一种能同时处理高度相关布局限制和语义连贯性的方法，从而使",
    "tldr": "本文提出了一种新颖的扩散模型，结合全局语义融合和自相似特征增强模块，以引导布局到图像合成中的对象连贯性。",
    "en_tdlr": "This paper proposes a novel diffusion model with effective global semantic fusion and self-similarity feature enhancement modules to guide the object coherence in layout-to-image synthesis."
}