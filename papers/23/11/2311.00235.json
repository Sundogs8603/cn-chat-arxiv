{
    "title": "Implicit biases in multitask and continual learning from a backward error analysis perspective. (arXiv:2311.00235v1 [stat.ML])",
    "abstract": "Using backward error analysis, we compute implicit training biases in multitask and continual learning settings for neural networks trained with stochastic gradient descent. In particular, we derive modified losses that are implicitly minimized during training. They have three terms: the original loss, accounting for convergence, an implicit flatness regularization term proportional to the learning rate, and a last term, the conflict term, which can theoretically be detrimental to both convergence and implicit regularization. In multitask, the conflict term is a well-known quantity, measuring the gradient alignment between the tasks, while in continual learning the conflict term is a new quantity in deep learning optimization, although a basic tool in differential geometry: The Lie bracket between the task gradients.",
    "link": "http://arxiv.org/abs/2311.00235",
    "context": "Title: Implicit biases in multitask and continual learning from a backward error analysis perspective. (arXiv:2311.00235v1 [stat.ML])\nAbstract: Using backward error analysis, we compute implicit training biases in multitask and continual learning settings for neural networks trained with stochastic gradient descent. In particular, we derive modified losses that are implicitly minimized during training. They have three terms: the original loss, accounting for convergence, an implicit flatness regularization term proportional to the learning rate, and a last term, the conflict term, which can theoretically be detrimental to both convergence and implicit regularization. In multitask, the conflict term is a well-known quantity, measuring the gradient alignment between the tasks, while in continual learning the conflict term is a new quantity in deep learning optimization, although a basic tool in differential geometry: The Lie bracket between the task gradients.",
    "path": "papers/23/11/2311.00235.json",
    "total_tokens": 965,
    "translated_title": "从反向误差分析角度看多任务和连续学习中的隐式偏差",
    "translated_abstract": "使用反向误差分析，我们计算了用随机梯度下降训练的神经网络在多任务和连续学习设置中的隐式训练偏差。具体而言，我们推导出了在训练过程中隐含地最小化的修改损失函数。它们包括三个项：原始损失函数（考虑收敛性），与学习率成正比的隐式平坦正则项以及最后一个项——冲突项，该项在理论上对收敛性和隐式正则化都可能有害。在多任务中，冲突项是一个众所周知的量，用于衡量任务之间的梯度对齐性，而在连续学习中，冲突项是深度学习优化中的一个新量，尽管在微分几何中是一个基本工具：任务梯度之间的李括号。",
    "tldr": "本论文使用反向误差分析计算了多任务和连续学习设置下神经网络的隐式训练偏差。在训练过程中，通过引入修改损失函数，隐式最小化了原始损失、引入了隐式平坦正则项和冲突项。在多任务中，冲突项衡量了任务梯度之间的对齐性；而在连续学习中，冲突项是深度学习优化中的一个新概念，它通过任务梯度之间的李括号来衡量。",
    "en_tdlr": "This paper uses backward error analysis to compute implicit training biases in multitask and continual learning settings for neural networks trained with stochastic gradient descent. The authors introduce modified losses that implicitly minimize the original loss while incorporating a flatness regularization term and a conflict term. The conflict term, previously known in multitask settings, measures gradient alignment between tasks, while in continual learning, it is a novel concept that quantifies the Lie bracket between task gradients."
}