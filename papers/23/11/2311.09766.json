{
    "title": "LLMs as Narcissistic Evaluators: When Ego Inflates Evaluation Scores",
    "abstract": "arXiv:2311.09766v2 Announce Type: replace  Abstract: Automatic evaluation of generated textual content presents an ongoing challenge within the field of NLP. Given the impressive capabilities of modern language models (LMs) across diverse NLP tasks, there is a growing trend to employ these models in creating innovative evaluation metrics for automated assessment of generation tasks. This paper investigates a pivotal question: Do language model-driven evaluation metrics inherently exhibit bias favoring texts generated by the same underlying language model? Specifically, we assess whether prominent LM-based evaluation metrics (e.g. BARTScore, T5Score, and GPTScore) demonstrate a favorable bias toward their respective underlying LMs in the context of summarization tasks. Our findings unveil a latent bias, particularly pronounced when such evaluation metrics are used in an reference-free manner without leveraging gold summaries. These results underscore that assessments provided by generat",
    "link": "https://arxiv.org/abs/2311.09766",
    "context": "Title: LLMs as Narcissistic Evaluators: When Ego Inflates Evaluation Scores\nAbstract: arXiv:2311.09766v2 Announce Type: replace  Abstract: Automatic evaluation of generated textual content presents an ongoing challenge within the field of NLP. Given the impressive capabilities of modern language models (LMs) across diverse NLP tasks, there is a growing trend to employ these models in creating innovative evaluation metrics for automated assessment of generation tasks. This paper investigates a pivotal question: Do language model-driven evaluation metrics inherently exhibit bias favoring texts generated by the same underlying language model? Specifically, we assess whether prominent LM-based evaluation metrics (e.g. BARTScore, T5Score, and GPTScore) demonstrate a favorable bias toward their respective underlying LMs in the context of summarization tasks. Our findings unveil a latent bias, particularly pronounced when such evaluation metrics are used in an reference-free manner without leveraging gold summaries. These results underscore that assessments provided by generat",
    "path": "papers/23/11/2311.09766.json",
    "total_tokens": 919,
    "translated_title": "LLMs作为自恋评估者：当自我膨胀影响评估分数",
    "translated_abstract": "arXiv:2311.09766v2 公告类型：替换 摘要：生成文本内容的自动评估在自然语言处理领域中一直是一个持续挑战。鉴于现代语言模型（LMs）在各种NLP任务中的出色表现，越来越多的人倾向于利用这些模型创造创新的评估指标，用于自动生成任务的自动评估。本文探讨了一个重要问题：由于语言模型驱动的评估指标是否会固有地表现出偏向于由相同基础语言模型生成的文本的偏见？具体而言，我们评估了知名的基于LM的评估指标（例如BARTScore、T5Score和GPTScore）在总结任务中是否对其各自的基础LM表现出偏好。我们的发现揭示了潜在偏见，特别是当这些评估指标在无参考的情况下使用且不利用黄金摘要时，这种偏见尤为显著。这些结果突显了通过生成文本获得的评估结果可能会受到自我偏误的影响。",
    "tldr": "本文研究了语言模型驱动的评估指标在总结任务中是否会对相同的基础语言模型生成的文本表现出偏见，并发现在无参考情况下使用时偏见尤为显著。"
}