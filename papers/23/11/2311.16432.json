{
    "title": "Text-Driven Image Editing via Learnable Regions",
    "abstract": "arXiv:2311.16432v2 Announce Type: replace-cross  Abstract: Language has emerged as a natural interface for image editing. In this paper, we introduce a method for region-based image editing driven by textual prompts, without the need for user-provided masks or sketches. Specifically, our approach leverages an existing pre-trained text-to-image model and introduces a bounding box generator to identify the editing regions that are aligned with the textual prompts. We show that this simple approach enables flexible editing that is compatible with current image generation models, and is able to handle complex prompts featuring multiple objects, complex sentences, or lengthy paragraphs. We conduct an extensive user study to compare our method against state-of-the-art methods. The experiments demonstrate the competitive performance of our method in manipulating images with high fidelity and realism that correspond to the provided language descriptions. Our project webpage can be found at: ht",
    "link": "https://arxiv.org/abs/2311.16432",
    "context": "Title: Text-Driven Image Editing via Learnable Regions\nAbstract: arXiv:2311.16432v2 Announce Type: replace-cross  Abstract: Language has emerged as a natural interface for image editing. In this paper, we introduce a method for region-based image editing driven by textual prompts, without the need for user-provided masks or sketches. Specifically, our approach leverages an existing pre-trained text-to-image model and introduces a bounding box generator to identify the editing regions that are aligned with the textual prompts. We show that this simple approach enables flexible editing that is compatible with current image generation models, and is able to handle complex prompts featuring multiple objects, complex sentences, or lengthy paragraphs. We conduct an extensive user study to compare our method against state-of-the-art methods. The experiments demonstrate the competitive performance of our method in manipulating images with high fidelity and realism that correspond to the provided language descriptions. Our project webpage can be found at: ht",
    "path": "papers/23/11/2311.16432.json",
    "total_tokens": 815,
    "translated_title": "通过可学习区域进行文本驱动图像编辑",
    "translated_abstract": "语言已经成为图像编辑的自然接口。本文介绍了一种基于区域的图像编辑方法，其由文本提示驱动，无需用户提供的遮罩或草图。具体来说，我们的方法利用现有的预训练文本到图像模型，并引入一个边界框生成器来识别与文本提示对齐的编辑区域。我们展示了这种简单方法可以实现与当前图像生成模型兼容的灵活编辑，并且能够处理包含多个对象、复杂句子或较长段落的复杂提示。我们进行了广泛的用户研究，将我们的方法与最先进的方法进行了比较。实验表明，我们的方法在与提供的语言描述相对应的具有高保真度和逼真度的图像操作方面表现出竞争力。我们的项目网页可以在此找到：ht",
    "tldr": "该方法通过学习区域实现了文本驱动的图像编辑，无需用户提供遮罩或草图，具有灵活性和能够处理复杂提示的特点。与其他方法相比，展现了竞争性能。",
    "en_tdlr": "This method achieves text-driven image editing via learnable regions, eliminating the need for user-provided masks or sketches, showing flexibility and the ability to handle complex prompts. It demonstrates competitive performance compared to other methods."
}