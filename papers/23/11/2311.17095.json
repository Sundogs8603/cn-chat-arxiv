{
    "title": "Emergent Open-Vocabulary Semantic Segmentation from Off-the-shelf Vision-Language Models",
    "abstract": "arXiv:2311.17095v2 Announce Type: replace-cross  Abstract: From image-text pairs, large-scale vision-language models (VLMs) learn to implicitly associate image regions with words, which prove effective for tasks like visual question answering. However, leveraging the learned association for open-vocabulary semantic segmentation remains a challenge. In this paper, we propose a simple, yet extremely effective, training-free technique, Plug-and-Play Open-Vocabulary Semantic Segmentation (PnP-OVSS) for this task. PnP-OVSS leverages a VLM with direct text-to-image cross-attention and an image-text matching loss. To balance between over-segmentation and under-segmentation, we introduce Salience Dropout; by iteratively dropping patches that the model is most attentive to, we are able to better resolve the entire extent of the segmentation mask. \\shortname{} does not require any neural network training and performs hyperparameter tuning without the need for any segmentation annotations, even f",
    "link": "https://arxiv.org/abs/2311.17095",
    "context": "Title: Emergent Open-Vocabulary Semantic Segmentation from Off-the-shelf Vision-Language Models\nAbstract: arXiv:2311.17095v2 Announce Type: replace-cross  Abstract: From image-text pairs, large-scale vision-language models (VLMs) learn to implicitly associate image regions with words, which prove effective for tasks like visual question answering. However, leveraging the learned association for open-vocabulary semantic segmentation remains a challenge. In this paper, we propose a simple, yet extremely effective, training-free technique, Plug-and-Play Open-Vocabulary Semantic Segmentation (PnP-OVSS) for this task. PnP-OVSS leverages a VLM with direct text-to-image cross-attention and an image-text matching loss. To balance between over-segmentation and under-segmentation, we introduce Salience Dropout; by iteratively dropping patches that the model is most attentive to, we are able to better resolve the entire extent of the segmentation mask. \\shortname{} does not require any neural network training and performs hyperparameter tuning without the need for any segmentation annotations, even f",
    "path": "papers/23/11/2311.17095.json",
    "total_tokens": 862,
    "translated_title": "从现成的视觉语言模型中实现的紧急开放词汇语义分割",
    "translated_abstract": "从图像-文本对中，大规模视觉语言模型（VLMs）学习隐式将图像区域与词汇关联起来，这对于诸如视觉问答等任务非常有效。然而，利用学习到的关联进行开放词汇语义分割仍然具有挑战性。在本文中，我们提出了一种简单但极其有效的无需训练的技术，Plug-and-Play Open-Vocabulary Semantic Segmentation (PnP-OVSS)。PnP-OVSS利用具有直接文本到图像交叉注意力和图像-文本匹配损失的VLM。为了在过度分割和欠分割之间取得平衡，我们引入了显著性丢弃（Salience Dropout）；通过迭代丢弃模型最关注的补丁，我们能够更好地解决整个分割掩模的范围。",
    "tldr": "提出了一种简单但高效的无需训练的技术，用于开放词汇语义分割，通过使用VLM和显著性丢弃来解决过度分割和欠分割的问题",
    "en_tdlr": "Proposed a simple yet highly effective training-free technique for open-vocabulary semantic segmentation, addressing the issues of over-segmentation and under-segmentation by using VLM and Salience Dropout."
}