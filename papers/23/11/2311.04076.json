{
    "title": "Do LLMs exhibit human-like response biases? A case study in survey design. (arXiv:2311.04076v3 [cs.CL] UPDATED)",
    "abstract": "As large language models (LLMs) become more capable, there is growing excitement about the possibility of using LLMs as proxies for humans in real-world tasks where subjective labels are desired, such as in surveys and opinion polling. One widely-cited barrier to the adoption of LLMs is their sensitivity to prompt wording - but interestingly, humans also display sensitivities to instruction changes in the form of response biases. As such, we argue that if LLMs are going to be used to approximate human opinions, it is necessary to investigate the extent to which LLMs also reflect human response biases, if at all. In this work, we use survey design as a case study, where human response biases caused by permutations in wordings of \"prompts\" have been extensively studied. Drawing from prior work in social psychology, we design a dataset and propose a framework to evaluate whether LLMs exhibit human-like response biases in survey questionnaires. Our comprehensive evaluation of nine models s",
    "link": "http://arxiv.org/abs/2311.04076",
    "context": "Title: Do LLMs exhibit human-like response biases? A case study in survey design. (arXiv:2311.04076v3 [cs.CL] UPDATED)\nAbstract: As large language models (LLMs) become more capable, there is growing excitement about the possibility of using LLMs as proxies for humans in real-world tasks where subjective labels are desired, such as in surveys and opinion polling. One widely-cited barrier to the adoption of LLMs is their sensitivity to prompt wording - but interestingly, humans also display sensitivities to instruction changes in the form of response biases. As such, we argue that if LLMs are going to be used to approximate human opinions, it is necessary to investigate the extent to which LLMs also reflect human response biases, if at all. In this work, we use survey design as a case study, where human response biases caused by permutations in wordings of \"prompts\" have been extensively studied. Drawing from prior work in social psychology, we design a dataset and propose a framework to evaluate whether LLMs exhibit human-like response biases in survey questionnaires. Our comprehensive evaluation of nine models s",
    "path": "papers/23/11/2311.04076.json",
    "total_tokens": 885,
    "translated_title": "LLMs是否展现出类似于人类的反应偏倚？一项关于调查设计的案例研究。",
    "translated_abstract": "随着大型语言模型（LLMs）的能力增强，人们对将LLMs用作代理人类进行主观标签任务（如调查和舆论调查）的可能性越来越兴奋。然而，LLMs对提示措辞的敏感性是其广泛引述的限制之一，但有趣的是，人类在回应中也显示出对指令变化的敏感性，表现为反应偏倚。因此，我们认为，如果要使用LLMs近似人类意见，有必要调查LLMs是否也反映了人类的反应偏差。在本研究中，我们以调查设计为案例研究，调查问卷中由于“提示”措辞的变化导致的人类反应偏差已经得到广泛研究。借鉴社会心理学的先前工作，我们设计了一个数据集并提出了一个评估框架，以评估LLMs是否在调查问卷中展现类似于人类的反应偏差。",
    "tldr": "本研究以调查设计为案例研究，探讨了LLMs是否展现类似于人类的反应偏差的问题。",
    "en_tdlr": "This study investigates whether LLMs exhibit human-like response biases in survey design, highlighting the need to understand the extent to which LLMs approximate human opinions."
}