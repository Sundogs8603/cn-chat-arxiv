{
    "title": "Zero Coordinate Shift: Whetted Automatic Differentiation for Physics-informed Operator Learning. (arXiv:2311.00860v1 [cs.LG])",
    "abstract": "Automatic differentiation (AD) is a critical step in physics-informed machine learning, required for computing the high-order derivatives of network output w.r.t. coordinates. In this paper, we present a novel and lightweight algorithm to conduct such AD for physics-informed operator learning, as we call the trick of Zero Coordinate Shift (ZCS). Instead of making all sampled coordinates leaf variables, ZCS introduces only one scalar-valued leaf variable for each spatial or temporal dimension, leading to a game-changing performance leap by simplifying the wanted derivatives from \"many-roots-many-leaves\" to \"one-root-many-leaves\". ZCS is easy to implement with current deep learning libraries; our own implementation is by extending the DeepXDE package. We carry out a comprehensive benchmark analysis and several case studies, training physics-informed DeepONets to solve partial differential equations (PDEs) without data. The results show that ZCS has persistently brought down GPU memory co",
    "link": "http://arxiv.org/abs/2311.00860",
    "context": "Title: Zero Coordinate Shift: Whetted Automatic Differentiation for Physics-informed Operator Learning. (arXiv:2311.00860v1 [cs.LG])\nAbstract: Automatic differentiation (AD) is a critical step in physics-informed machine learning, required for computing the high-order derivatives of network output w.r.t. coordinates. In this paper, we present a novel and lightweight algorithm to conduct such AD for physics-informed operator learning, as we call the trick of Zero Coordinate Shift (ZCS). Instead of making all sampled coordinates leaf variables, ZCS introduces only one scalar-valued leaf variable for each spatial or temporal dimension, leading to a game-changing performance leap by simplifying the wanted derivatives from \"many-roots-many-leaves\" to \"one-root-many-leaves\". ZCS is easy to implement with current deep learning libraries; our own implementation is by extending the DeepXDE package. We carry out a comprehensive benchmark analysis and several case studies, training physics-informed DeepONets to solve partial differential equations (PDEs) without data. The results show that ZCS has persistently brought down GPU memory co",
    "path": "papers/23/11/2311.00860.json",
    "total_tokens": 918,
    "translated_title": "零坐标移动：针对物理约束操作学习的优化自动微分方法",
    "translated_abstract": "自动微分（AD）是物理约束机器学习中的关键步骤，用于计算网络输出相对于坐标的高阶导数。本文提出了一种新颖且轻量级的算法，用于进行针对物理约束操作学习的自动微分，称为零坐标移动（ZCS）的技巧。ZCS引入了一个标量值的叶变量，用于每个空间或时间维度，通过将所需导数从“多根多叶”简化为“一根多叶”，从而实现了性能的巨大提升。ZCS很容易在当前的深度学习库中实现；我们使用DeepXDE软件包进行了自己的实现。我们进行了全面的基准分析和多个案例研究，训练物理约束的DeepONets来解决无数据的偏微分方程（PDE）。结果表明，ZCS一直通过降低GPU内存消耗提供了改进效果。",
    "tldr": "本文提出了一种用于物理约束操作学习的新型自动微分算法，通过零坐标移动（ZCS）的技巧，将所需导数的复杂度从“多根多叶”简化为“一根多叶”，从而显著提高了性能。",
    "en_tdlr": "This paper presents a novel automatic differentiation algorithm for physics-informed operator learning, which simplifies the complexity of wanted derivatives from \"many-roots-many-leaves\" to \"one-root-many-leaves\" using the trick of Zero Coordinate Shift (ZCS), resulting in significant performance improvement."
}