{
    "title": "Server-side Rescoring of Spoken Entity-centric Knowledge Queries for Virtual Assistants. (arXiv:2311.01398v1 [cs.CL])",
    "abstract": "On-device Virtual Assistants (VAs) powered by Automatic Speech Recognition (ASR) require effective knowledge integration for the challenging entity-rich query recognition. In this paper, we conduct an empirical study of modeling strategies for server-side rescoring of spoken information domain queries using various categories of Language Models (LMs) (N-gram word LMs, sub-word neural LMs). We investigate the combination of on-device and server-side signals, and demonstrate significant WER improvements of 23%-35% on various entity-centric query subpopulations by integrating various server-side LMs compared to performing ASR on-device only. We also perform a comparison between LMs trained on domain data and a GPT-3 variant offered by OpenAI as a baseline. Furthermore, we also show that model fusion of multiple server-side LMs trained from scratch most effectively combines complementary strengths of each model and integrates knowledge learned from domain-specific data to a VA ASR system.",
    "link": "http://arxiv.org/abs/2311.01398",
    "context": "Title: Server-side Rescoring of Spoken Entity-centric Knowledge Queries for Virtual Assistants. (arXiv:2311.01398v1 [cs.CL])\nAbstract: On-device Virtual Assistants (VAs) powered by Automatic Speech Recognition (ASR) require effective knowledge integration for the challenging entity-rich query recognition. In this paper, we conduct an empirical study of modeling strategies for server-side rescoring of spoken information domain queries using various categories of Language Models (LMs) (N-gram word LMs, sub-word neural LMs). We investigate the combination of on-device and server-side signals, and demonstrate significant WER improvements of 23%-35% on various entity-centric query subpopulations by integrating various server-side LMs compared to performing ASR on-device only. We also perform a comparison between LMs trained on domain data and a GPT-3 variant offered by OpenAI as a baseline. Furthermore, we also show that model fusion of multiple server-side LMs trained from scratch most effectively combines complementary strengths of each model and integrates knowledge learned from domain-specific data to a VA ASR system.",
    "path": "papers/23/11/2311.01398.json",
    "total_tokens": 975,
    "translated_title": "服务器端对语音中心化知识查询进行重新评分的研究",
    "translated_abstract": "自动语音识别（ASR）驱动的设备内虚拟助手（VA）需要有效的知识整合来应对富实体查询识别的挑战。本文通过使用各种类别的语言模型（N-gram词语模型、子词神经网络模型），对服务器端对口语信息领域查询进行重新评分的建模策略进行了实证研究。我们研究了设备内和服务器端信号的组合，并与仅在设备内进行ASR的情况相比，通过整合各种服务器端语言模型，在各种实体中心化查询子族群中取得了23%-35%的WER改善。我们还对使用领域数据训练的语言模型和由OpenAI提供的GPT-3变体进行了比较。此外，我们还展示了从头开始训练的多个服务器端语言模型的模型融合最有效地结合了每个模型的互补优势，并将从领域特定数据中学到的知识整合到VA ASR系统中。",
    "tldr": "本文研究了服务器端对语音中心化知识查询进行重新评分的建模策略，并通过整合各种服务器端语言模型，显著改善了各种实体中心化查询子族群的识别错误率。此外，模型融合和使用领域特定数据训练的语言模型对于提升VA ASR系统的性能也起到了积极的作用。",
    "en_tdlr": "This paper explores modeling strategies for server-side rescoring of spoken entity-centric knowledge queries and demonstrates significant improvements in recognition error rate for various entity-centric query subpopulations by integrating various server-side language models. Model fusion and the use of domain-specific data also contribute to enhancing the performance of the VA ASR system."
}