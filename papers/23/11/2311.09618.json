{
    "title": "Simulating Opinion Dynamics with Networks of LLM-based Agents",
    "abstract": "arXiv:2311.09618v2 Announce Type: replace-cross  Abstract: Accurately simulating human opinion dynamics is crucial for understanding a variety of societal phenomena, including polarization and the spread of misinformation. However, the agent-based models (ABMs) commonly used for such simulations often over-simplify human behavior. We propose a new approach to simulating opinion dynamics based on populations of Large Language Models (LLMs). Our findings reveal a strong inherent bias in LLM agents towards producing accurate information, leading simulated agents to consensus in line with scientific reality. This bias limits their utility for understanding resistance to consensus views on issues like climate change. After inducing confirmation bias through prompt engineering, however, we observed opinion fragmentation in line with existing agent-based modeling and opinion dynamics research. These insights highlight the promise and limitations of LLM agents in this domain and suggest a path",
    "link": "https://arxiv.org/abs/2311.09618",
    "context": "Title: Simulating Opinion Dynamics with Networks of LLM-based Agents\nAbstract: arXiv:2311.09618v2 Announce Type: replace-cross  Abstract: Accurately simulating human opinion dynamics is crucial for understanding a variety of societal phenomena, including polarization and the spread of misinformation. However, the agent-based models (ABMs) commonly used for such simulations often over-simplify human behavior. We propose a new approach to simulating opinion dynamics based on populations of Large Language Models (LLMs). Our findings reveal a strong inherent bias in LLM agents towards producing accurate information, leading simulated agents to consensus in line with scientific reality. This bias limits their utility for understanding resistance to consensus views on issues like climate change. After inducing confirmation bias through prompt engineering, however, we observed opinion fragmentation in line with existing agent-based modeling and opinion dynamics research. These insights highlight the promise and limitations of LLM agents in this domain and suggest a path",
    "path": "papers/23/11/2311.09618.json",
    "total_tokens": 898,
    "translated_title": "使用基于LLM的代理网络模拟意见动态",
    "translated_abstract": "准确模拟人类意见动态对于理解各种社会现象至关重要，包括极化和错误信息的传播。然而，常用于此类模拟的基于代理的模型（ABM）经常会过分简化人类行为。我们提出了一种基于大型语言模型（LLMs）人口的模拟意见动态的新方法。我们的研究结果显示，LLM代理存在一种对产生准确信息的强烈固有偏见，导致模拟代理趋向于与科学现实一致的共识。然而，这种偏见限制了它们在理解气候变化等问题上抵制共识观点的效用。通过引入提示工程诱导确认偏见后，我们观察到了与现有基于代理模型和意见动态研究一致的意见分裂。这些见解突显了LLM代理在该领域的潜力和局限性，并提出了一条路径。",
    "tldr": "提出了一种基于大型语言模型（LLMs）人口的新方法来模拟意见动态，发现LLM代理存在固有偏见导致模拟代理趋向于科学现实一致的共识，但引入确认偏见后观察到意见分裂，突显了LLM代理在该领域的潜力和局限性。"
}