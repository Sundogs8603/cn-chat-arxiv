{
    "title": "IBADR: an Iterative Bias-Aware Dataset Refinement Framework for Debiasing NLU models. (arXiv:2311.00292v1 [cs.CL])",
    "abstract": "As commonly-used methods for debiasing natural language understanding (NLU) models, dataset refinement approaches heavily rely on manual data analysis, and thus maybe unable to cover all the potential biased features. In this paper, we propose IBADR, an Iterative Bias-Aware Dataset Refinement framework, which debiases NLU models without predefining biased features. We maintain an iteratively expanded sample pool. Specifically, at each iteration, we first train a shallow model to quantify the bias degree of samples in the pool. Then, we pair each sample with a bias indicator representing its bias degree, and use these extended samples to train a sample generator. In this way, this generator can effectively learn the correspondence relationship between bias indicators and samples. Furthermore, we employ the generator to produce pseudo samples with fewer biased features by feeding specific bias indicators. Finally, we incorporate the generated pseudo samples into the pool. Experimental re",
    "link": "http://arxiv.org/abs/2311.00292",
    "context": "Title: IBADR: an Iterative Bias-Aware Dataset Refinement Framework for Debiasing NLU models. (arXiv:2311.00292v1 [cs.CL])\nAbstract: As commonly-used methods for debiasing natural language understanding (NLU) models, dataset refinement approaches heavily rely on manual data analysis, and thus maybe unable to cover all the potential biased features. In this paper, we propose IBADR, an Iterative Bias-Aware Dataset Refinement framework, which debiases NLU models without predefining biased features. We maintain an iteratively expanded sample pool. Specifically, at each iteration, we first train a shallow model to quantify the bias degree of samples in the pool. Then, we pair each sample with a bias indicator representing its bias degree, and use these extended samples to train a sample generator. In this way, this generator can effectively learn the correspondence relationship between bias indicators and samples. Furthermore, we employ the generator to produce pseudo samples with fewer biased features by feeding specific bias indicators. Finally, we incorporate the generated pseudo samples into the pool. Experimental re",
    "path": "papers/23/11/2311.00292.json",
    "total_tokens": 980,
    "translated_title": "IBADR：一种迭代偏见感知的数据集细化框架，用于去偏自然语言理解模型",
    "translated_abstract": "去偏自然语言理解（NLU）模型的常用方法是数据集细化方法，它们严重依赖于手动数据分析，因此可能无法覆盖所有潜在的有偏特征。在本文中，我们提出了IBADR，一种迭代偏见感知的数据集细化框架，可以去偏NLU模型而不需要预定义有偏特征。我们维护一个迭代扩展的样本池。具体而言，在每次迭代中，我们首先训练一个浅层模型来量化样本池中样本的偏见程度。然后，我们将每个样本与表示其偏见程度的偏见指示器配对，并使用这些扩展的样本来训练一个样本生成器。通过这种方式，该生成器可以有效地学习偏见指示器和样本之间的对应关系。此外，我们使用生成器通过提供特定的偏见指示器来生成具有较少有偏特征的伪样本。最后，我们将生成的伪样本并入样本池中。",
    "tldr": "本文提出了一种迭代偏见感知的数据集细化框架IBADR，用于去偏自然语言理解（NLU）模型。该框架可以在不预定义有偏特征的情况下去偏模型，通过迭代扩展样本池并使用样本生成器生成伪样本，从而有效地去除有偏特征。"
}