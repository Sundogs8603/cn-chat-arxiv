{
    "title": "Experimental Analysis of Large-scale Learnable Vector Storage Compression",
    "abstract": "Learnable embedding vector is one of the most important applications in machine learning, and is widely used in various database-related domains. However, the high dimensionality of sparse data in recommendation tasks and the huge volume of corpus in retrieval-related tasks lead to a large memory consumption of the embedding table, which poses a great challenge to the training and deployment of models. Recent research has proposed various methods to compress the embeddings at the cost of a slight decrease in model quality or the introduction of other overheads. Nevertheless, the relative performance of these methods remains unclear. Existing experimental comparisons only cover a subset of these methods and focus on limited metrics. In this paper, we perform a comprehensive comparative analysis and experimental evaluation of embedding compression. We introduce a new taxonomy that categorizes these techniques based on their characteristics and methodologies, and further develop a modular",
    "link": "https://arxiv.org/abs/2311.15578",
    "context": "Title: Experimental Analysis of Large-scale Learnable Vector Storage Compression\nAbstract: Learnable embedding vector is one of the most important applications in machine learning, and is widely used in various database-related domains. However, the high dimensionality of sparse data in recommendation tasks and the huge volume of corpus in retrieval-related tasks lead to a large memory consumption of the embedding table, which poses a great challenge to the training and deployment of models. Recent research has proposed various methods to compress the embeddings at the cost of a slight decrease in model quality or the introduction of other overheads. Nevertheless, the relative performance of these methods remains unclear. Existing experimental comparisons only cover a subset of these methods and focus on limited metrics. In this paper, we perform a comprehensive comparative analysis and experimental evaluation of embedding compression. We introduce a new taxonomy that categorizes these techniques based on their characteristics and methodologies, and further develop a modular",
    "path": "papers/23/11/2311.15578.json",
    "total_tokens": 848,
    "translated_title": "大规模可学习向量存储压缩的实验分析",
    "translated_abstract": "可学习的嵌入向量是机器学习中最重要的应用之一，在各种与数据库相关的领域广泛应用。然而，在推荐任务中稀疏数据的高维度和检索任务中大规模语料库的巨大容量导致嵌入表的内存消耗很大，给模型的训练和部署带来了巨大挑战。近期的研究提出了各种方法来压缩嵌入向量，但这些方法在模型质量稍微下降或引入其他开销的同时，其相对性能仍不清楚。现有的实验比较只涵盖了这些方法的子集，并且关注有限的指标。本文对嵌入向量压缩进行了全面比较分析和实验评估。我们引入了一个新的分类法，根据特征和方法学对这些技术进行分类，并进一步发展了一个模块化的方法来实现压缩算法。",
    "tldr": "本文对嵌入向量压缩进行了全面比较分析和实验评估，引入了一个新的分类法，根据特征和方法学对这些技术进行分类，并进一步发展了一个模块化的方法来实现压缩算法。",
    "en_tdlr": "This paper provides a comprehensive analysis and experimental evaluation of embedding vector compression, introducing a new taxonomy for classifying these techniques based on their characteristics and methodologies, and further developing a modular approach to implement compression algorithms."
}