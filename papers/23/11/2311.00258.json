{
    "title": "Noisy Exemplars Make Large Language Models More Robust: A Domain-Agnostic Behavioral Analysis. (arXiv:2311.00258v1 [cs.CL])",
    "abstract": "Recent advances in prompt engineering enable large language models (LLMs) to solve multi-hop logical reasoning problems with impressive accuracy. However, there is little existing work investigating the robustness of LLMs with few-shot prompting techniques. Therefore, we introduce a systematic approach to test the robustness of LLMs in multi-hop reasoning tasks via domain-agnostic perturbations. We include perturbations at multiple levels of abstractions (e.g. lexical perturbations such as typos, and semantic perturbations such as the inclusion of intermediate reasoning steps in the questions) to conduct behavioral analysis on the LLMs. Throughout our experiments, we find that models are more sensitive to certain perturbations such as replacing words with their synonyms. We also demonstrate that increasing the proportion of perturbed exemplars in the prompts improves the robustness of few-shot prompting methods.",
    "link": "http://arxiv.org/abs/2311.00258",
    "context": "Title: Noisy Exemplars Make Large Language Models More Robust: A Domain-Agnostic Behavioral Analysis. (arXiv:2311.00258v1 [cs.CL])\nAbstract: Recent advances in prompt engineering enable large language models (LLMs) to solve multi-hop logical reasoning problems with impressive accuracy. However, there is little existing work investigating the robustness of LLMs with few-shot prompting techniques. Therefore, we introduce a systematic approach to test the robustness of LLMs in multi-hop reasoning tasks via domain-agnostic perturbations. We include perturbations at multiple levels of abstractions (e.g. lexical perturbations such as typos, and semantic perturbations such as the inclusion of intermediate reasoning steps in the questions) to conduct behavioral analysis on the LLMs. Throughout our experiments, we find that models are more sensitive to certain perturbations such as replacing words with their synonyms. We also demonstrate that increasing the proportion of perturbed exemplars in the prompts improves the robustness of few-shot prompting methods.",
    "path": "papers/23/11/2311.00258.json",
    "total_tokens": 894,
    "translated_title": "有噪声的样本使得大型语言模型更加鲁棒：一个领域不可知的行为分析",
    "translated_abstract": "最近对问题引导的工程进展使得大型语言模型（LLMs）能够以令人印象深刻的准确率解决多跳逻辑推理问题。然而，目前很少有工作研究少样本提示技术下LLMs的鲁棒性。因此，我们介绍了一种系统的方法，通过领域不可知的扰动来测试LLMs在多跳推理任务中的鲁棒性。我们在多个抽象层次上引入扰动（例如词法扰动，如拼写错误，以及语义扰动，如在问题中包含中间推理步骤），对LLMs进行行为分析。通过实验，我们发现模型对某些扰动（如用同义词替换单词）更敏感。我们还证明，在提示中增加扰动样本的比例可以提高少样本提示方法的鲁棒性。",
    "tldr": "本研究通过领域不可知的扰动测试了大型语言模型在多跳推理任务中的鲁棒性，发现模型对某些扰动更敏感，并证明增加扰动样本的比例可以提高少样本提示方法的鲁棒性。",
    "en_tdlr": "This study tests the robustness of large language models in multi-hop reasoning tasks using domain-agnostic perturbations, finding that models are more sensitive to certain perturbations and demonstrating that increasing the proportion of perturbed exemplars in the prompts improves the robustness of few-shot prompting methods."
}