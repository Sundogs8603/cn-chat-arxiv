{
    "title": "INTERVENOR: Prompt the Coding Ability of Large Language Models with the Interactive Chain of Repairing. (arXiv:2311.09868v2 [cs.SE] UPDATED)",
    "abstract": "This paper proposes INTERactiVE chaiN Of Repairing (INTERVENOR), which mimics human code repairing behavior (iteratively judging, rethinking, and repairing) and prompts the coding ability of regard Large Language Models (LLMs). Specifically, INTERVENOR employs two LLM based agents, Code Learner and Code Teacher, to play different roles in code repairing and work interactively to repair the generated codes. The Code Learner is asked to generate and repair code according to the instructions from the Code Teacher. The Code Teacher rethinks the code errors according to the corresponding feedback from compilers and iteratively generates the chain-of-repairing (CoR) to guide the code repairing process for Code Learner. Our experiments show that INTERVENOR outperforms the state-of-the-art methods and achieves about 13% and 4.5% improvements over the GPT-3.5 model in code generation and code translation tasks, respectively. Our further analyses show that CoR can illuminate the bug reasons and ",
    "link": "http://arxiv.org/abs/2311.09868",
    "context": "Title: INTERVENOR: Prompt the Coding Ability of Large Language Models with the Interactive Chain of Repairing. (arXiv:2311.09868v2 [cs.SE] UPDATED)\nAbstract: This paper proposes INTERactiVE chaiN Of Repairing (INTERVENOR), which mimics human code repairing behavior (iteratively judging, rethinking, and repairing) and prompts the coding ability of regard Large Language Models (LLMs). Specifically, INTERVENOR employs two LLM based agents, Code Learner and Code Teacher, to play different roles in code repairing and work interactively to repair the generated codes. The Code Learner is asked to generate and repair code according to the instructions from the Code Teacher. The Code Teacher rethinks the code errors according to the corresponding feedback from compilers and iteratively generates the chain-of-repairing (CoR) to guide the code repairing process for Code Learner. Our experiments show that INTERVENOR outperforms the state-of-the-art methods and achieves about 13% and 4.5% improvements over the GPT-3.5 model in code generation and code translation tasks, respectively. Our further analyses show that CoR can illuminate the bug reasons and ",
    "path": "papers/23/11/2311.09868.json",
    "total_tokens": 884,
    "translated_title": "INTERVENOR: 使用交互式修复链条来引导大型语言模型的编码能力",
    "translated_abstract": "本文提出了一种名为INTERVENOR的交互式修复链条（INTERactiVE chaiN Of Repairing），模拟了人类修复代码的行为（迭代判断、重新思考和修复），并促进了大型语言模型（LLMs）的编码能力。具体而言，INTERVENOR采用了两个基于LLM的代理，即Code Learner和Code Teacher，它们在代码修复中扮演不同的角色，并通过互动来修复生成的代码。Code Learner根据Code Teacher的指导生成和修复代码，而Code Teacher根据编译器的反馈重新思考代码错误，并迭代生成修复链条（CoR）以引导Code Learner的代码修复过程。实验证明，INTERVENOR优于最先进的方法，在代码生成和代码转换任务上相对于GPT-3.5模型分别取得了约13%和4.5%的提升。进一步分析表明，CoR能够揭示bug的原因。",
    "tldr": "INTERVENOR模型通过模拟人类修复代码的行为，使用交互式修复链条来引导大型语言模型的编码能力，取得了显著的性能提升。"
}