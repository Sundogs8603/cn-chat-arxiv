{
    "title": "Diversity and Diffusion: Observations on Synthetic Image Distributions with Stable Diffusion. (arXiv:2311.00056v1 [cs.CV])",
    "abstract": "Recent progress in text-to-image (TTI) systems, such as StableDiffusion, Imagen, and DALL-E 2, have made it possible to create realistic images with simple text prompts. It is tempting to use these systems to eliminate the manual task of obtaining natural images for training a new machine learning classifier. However, in all of the experiments performed to date, classifiers trained solely with synthetic images perform poorly at inference, despite the images used for training appearing realistic. Examining this apparent incongruity in detail gives insight into the limitations of the underlying image generation processes. Through the lens of diversity in image creation vs.accuracy of what is created, we dissect the differences in semantic mismatches in what is modeled in synthetic vs. natural images. This will elucidate the roles of the image-languag emodel, CLIP, and the image generation model, diffusion. We find four issues that limit the usefulness of TTI systems for this task: ambigu",
    "link": "http://arxiv.org/abs/2311.00056",
    "context": "Title: Diversity and Diffusion: Observations on Synthetic Image Distributions with Stable Diffusion. (arXiv:2311.00056v1 [cs.CV])\nAbstract: Recent progress in text-to-image (TTI) systems, such as StableDiffusion, Imagen, and DALL-E 2, have made it possible to create realistic images with simple text prompts. It is tempting to use these systems to eliminate the manual task of obtaining natural images for training a new machine learning classifier. However, in all of the experiments performed to date, classifiers trained solely with synthetic images perform poorly at inference, despite the images used for training appearing realistic. Examining this apparent incongruity in detail gives insight into the limitations of the underlying image generation processes. Through the lens of diversity in image creation vs.accuracy of what is created, we dissect the differences in semantic mismatches in what is modeled in synthetic vs. natural images. This will elucidate the roles of the image-languag emodel, CLIP, and the image generation model, diffusion. We find four issues that limit the usefulness of TTI systems for this task: ambigu",
    "path": "papers/23/11/2311.00056.json",
    "total_tokens": 905,
    "translated_title": "多样性和扩散：关于具有稳定扩散的合成图像分布的观察",
    "translated_abstract": "最近在文本到图像（TTI）系统方面取得的进展，如StableDiffusion、Imagen和DALL-E 2，使得通过简单的文本提示创建逼真的图像成为可能。诱人的是使用这些系统来消除获取训练新的机器学习分类器所需的自然图像的手动任务。然而，尽管用于训练的图像看起来逼真，但迄今为止进行的所有实验都显示只使用合成图像训练的分类器在推理时表现不佳。详细研究此明显的不一致将洞察底层图像生成过程的局限性。从图像创建多样性和所创建内容的准确性的角度来看，我们剖析了合成图像和自然图像中语义不匹配的差异。这将阐明图像语言模型CLIP和图像生成模型扩散的作用。我们发现了四个限制TTI系统在此任务中有用性的问题：不明确的语义、类别平衡问题、训练数据的依赖性问题和图像生成的不确定性问题。",
    "tldr": "这项研究观察了文本到图像系统的进展，并发现只使用合成图像训练的分类器在推理时表现不佳，揭示了底层图像生成过程的局限性。",
    "en_tdlr": "This study examines the progress of text-to-image systems and reveals the limitations of classifiers trained solely with synthetic images, which perform poorly at inference."
}