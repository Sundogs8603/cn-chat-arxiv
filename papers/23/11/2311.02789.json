{
    "title": "Estimation and Inference for a Class of Generalized Hierarchical Models",
    "abstract": "arXiv:2311.02789v4 Announce Type: replace  Abstract: In this paper, we consider estimation and inference for the unknown parameters and function involved in a class of generalized hierarchical models. Such models are of great interest in the literature of neural networks (such as Bauer and Kohler, 2019). We propose a rectified linear unit (ReLU) based deep neural network (DNN) approach, and contribute to the design of DNN by i) providing more transparency for practical implementation, ii) defining different types of sparsity, iii) showing the differentiability, iv) pointing out the set of effective parameters, and v) offering a new variant of rectified linear activation function (ReLU), etc. Asymptotic properties are established accordingly, and a feasible procedure for the purpose of inference is also proposed. We conduct extensive numerical studies to examine the finite-sample performance of the estimation methods, and we also evaluate the empirical relevance and applicability of the",
    "link": "https://arxiv.org/abs/2311.02789",
    "context": "Title: Estimation and Inference for a Class of Generalized Hierarchical Models\nAbstract: arXiv:2311.02789v4 Announce Type: replace  Abstract: In this paper, we consider estimation and inference for the unknown parameters and function involved in a class of generalized hierarchical models. Such models are of great interest in the literature of neural networks (such as Bauer and Kohler, 2019). We propose a rectified linear unit (ReLU) based deep neural network (DNN) approach, and contribute to the design of DNN by i) providing more transparency for practical implementation, ii) defining different types of sparsity, iii) showing the differentiability, iv) pointing out the set of effective parameters, and v) offering a new variant of rectified linear activation function (ReLU), etc. Asymptotic properties are established accordingly, and a feasible procedure for the purpose of inference is also proposed. We conduct extensive numerical studies to examine the finite-sample performance of the estimation methods, and we also evaluate the empirical relevance and applicability of the",
    "path": "papers/23/11/2311.02789.json",
    "total_tokens": 894,
    "translated_title": "一类广义分层模型的估计和推断",
    "translated_abstract": "在这篇论文中，我们考虑了一类广义分层模型中涉及的未知参数和函数的估计和推断。这些模型在神经网络领域（如Bauer和Kohler, 2019）的文献中具有重要意义。我们提出了基于修正线性单元（ReLU）的深度神经网络（DNN）方法，并通过i）提供更多透明性，ii）定义不同类型的稀疏性，iii）展示可区分性，iv）指出有效参数集，以及v）提供修正线性激活函数（ReLU）的新变体等方面，为DNN的设计做出了贡献。相应地建立了渐近性质，并提出了用于推断的可行程序。我们进行了大量的数值研究，以检验估计方法的有限样本性能，并评估了经验的相关性和适用性。",
    "tldr": "提出了一种基于修正线性单元（ReLU）的深度神经网络（DNN）方法，通过提供更多透明性、定义不同类型的稀疏性、展示可区分性、指出有效参数集和提供ReLU的新变体等方式为DNN设计做出贡献，并建立了渐近性质和推断的可行程序。",
    "en_tdlr": "Proposed a deep neural network (DNN) approach based on rectified linear unit (ReLU), contributing to DNN design by providing more transparency, defining different types of sparsity, showing differentiability, pointing out effective parameters, offering a new variant of ReLU, established asymptotic properties, and proposed a feasible procedure for inference."
}