{
    "title": "MARRS: Multimodal Reference Resolution System. (arXiv:2311.01650v1 [cs.CL])",
    "abstract": "Successfully handling context is essential for any dialog understanding task. This context maybe be conversational (relying on previous user queries or system responses), visual (relying on what the user sees, for example, on their screen), or background (based on signals such as a ringing alarm or playing music). In this work, we present an overview of MARRS, or Multimodal Reference Resolution System, an on-device framework within a Natural Language Understanding system, responsible for handling conversational, visual and background context. In particular, we present different machine learning models to enable handing contextual queries; specifically, one to enable reference resolution, and one to handle context via query rewriting. We also describe how these models complement each other to form a unified, coherent, lightweight system that can understand context while preserving user privacy.",
    "link": "http://arxiv.org/abs/2311.01650",
    "context": "Title: MARRS: Multimodal Reference Resolution System. (arXiv:2311.01650v1 [cs.CL])\nAbstract: Successfully handling context is essential for any dialog understanding task. This context maybe be conversational (relying on previous user queries or system responses), visual (relying on what the user sees, for example, on their screen), or background (based on signals such as a ringing alarm or playing music). In this work, we present an overview of MARRS, or Multimodal Reference Resolution System, an on-device framework within a Natural Language Understanding system, responsible for handling conversational, visual and background context. In particular, we present different machine learning models to enable handing contextual queries; specifically, one to enable reference resolution, and one to handle context via query rewriting. We also describe how these models complement each other to form a unified, coherent, lightweight system that can understand context while preserving user privacy.",
    "path": "papers/23/11/2311.01650.json",
    "total_tokens": 854,
    "translated_title": "MARRS: 多模态参考解析系统",
    "translated_abstract": "成功处理上下文对于任何对话理解任务都是至关重要的。这个上下文可能是对话式的（依赖于之前的用户查询或系统回答），也可能是视觉的（依赖于用户看到的东西，例如他们的屏幕上），或者是背景的（基于一些信号，比如响起的闹钟或者正在播放的音乐）。在这项工作中，我们介绍了MARRS（多模态参考解析系统），它是一个在设备上运行的自然语言理解系统的框架，在处理对话式、视觉和背景上下文方面负责。特别是，我们提出了不同的机器学习模型来实现上下文查询的处理；具体而言，一个用于实现参考解析，一个用于通过查询重写处理上下文。我们还描述了这些模型如何相互补充，形成一个统一、连贯、轻量级的系统，可以在保护用户隐私的同时理解上下文。",
    "tldr": "MARRS是一个在设备上运行的多模态参考解析系统，能够处理对话式、视觉和背景上下文，并通过不同的机器学习模型实现上下文查询的处理。这个系统能够在保护用户隐私的同时理解上下文。"
}