{
    "title": "Take One Step at a Time to Know Incremental Utility of Demonstration: An Analysis on Reranking for Few-Shot In-Context Learning",
    "abstract": "arXiv:2311.09619v2 Announce Type: replace  Abstract: In-Context Learning (ICL) is an emergent capability of Large Language Models (LLMs). Only a few demonstrations enable LLMs to be used as blackbox for new tasks. Previous studies have shown that using LLMs' outputs as labels is effective in training models to select demonstrations. Such a label is expected to estimate utility of a demonstration in ICL; however, it has not been well understood how different labeling strategies affect results on target tasks. This paper presents an analysis on different utility functions by focusing on LLMs' output probability given ground-truth output, and task-specific reward given LLMs' prediction. Unlike the previous work, we introduce a novel labeling method, incremental utility, which estimates how much incremental knowledge is brought into the LLMs by a demonstration. We conduct experiments with instruction-tuned LLMs on binary/multi-class classification, segmentation, and translation across Arab",
    "link": "https://arxiv.org/abs/2311.09619",
    "context": "Title: Take One Step at a Time to Know Incremental Utility of Demonstration: An Analysis on Reranking for Few-Shot In-Context Learning\nAbstract: arXiv:2311.09619v2 Announce Type: replace  Abstract: In-Context Learning (ICL) is an emergent capability of Large Language Models (LLMs). Only a few demonstrations enable LLMs to be used as blackbox for new tasks. Previous studies have shown that using LLMs' outputs as labels is effective in training models to select demonstrations. Such a label is expected to estimate utility of a demonstration in ICL; however, it has not been well understood how different labeling strategies affect results on target tasks. This paper presents an analysis on different utility functions by focusing on LLMs' output probability given ground-truth output, and task-specific reward given LLMs' prediction. Unlike the previous work, we introduce a novel labeling method, incremental utility, which estimates how much incremental knowledge is brought into the LLMs by a demonstration. We conduct experiments with instruction-tuned LLMs on binary/multi-class classification, segmentation, and translation across Arab",
    "path": "papers/23/11/2311.09619.json",
    "total_tokens": 890,
    "translated_title": "逐步了解演示的增量效用：对少样本上下文学习的重新排名分析",
    "translated_abstract": "In-Context Learning（ICL）是大型语言模型（LLMs）的一种新兴能力。 仅仅几个演示就能让LLMs被用作新任务的黑盒。 先前的研究表明，使用LLMs的输出作为标签在训练模型选择演示方面是有效的。 这样的标签应该能够估计ICL中演示的效用； 然而，并不清楚不同的标记策略如何影响目标任务的结果。 本文通过关注LLMs给出的输出概率和基于任务的奖励给出LLMs的预测，对不同效用函数进行了分析。 与以往的工作不同，我们提出了一种新的标记方法，增量效用，用于估计LLMs通过演示带入的增量知识量。 我们在经过指令调整的LLMs上进行了实验，涵盖了阿拉伯文的二分类/多分类、分割和翻译。",
    "tldr": "本文通过引入一种新的标记方法，增量效用，来估计LLMs通过演示带入的增量知识量，解决了关于不同标记策略如何影响目标任务结果的问题。",
    "en_tdlr": "This paper introduces a novel labeling method, incremental utility, to estimate the incremental knowledge brought into LLMs by a demonstration, addressing the question of how different labeling strategies affect results on target tasks."
}