{
    "title": "Time-series Generation by Contrastive Imitation. (arXiv:2311.01388v1 [stat.ML])",
    "abstract": "Consider learning a generative model for time-series data. The sequential setting poses a unique challenge: Not only should the generator capture the conditional dynamics of (stepwise) transitions, but its open-loop rollouts should also preserve the joint distribution of (multi-step) trajectories. On one hand, autoregressive models trained by MLE allow learning and computing explicit transition distributions, but suffer from compounding error during rollouts. On the other hand, adversarial models based on GAN training alleviate such exposure bias, but transitions are implicit and hard to assess. In this work, we study a generative framework that seeks to combine the strengths of both: Motivated by a moment-matching objective to mitigate compounding error, we optimize a local (but forward-looking) transition policy, where the reinforcement signal is provided by a global (but stepwise-decomposable) energy model trained by contrastive estimation. At training, the two components are learne",
    "link": "http://arxiv.org/abs/2311.01388",
    "context": "Title: Time-series Generation by Contrastive Imitation. (arXiv:2311.01388v1 [stat.ML])\nAbstract: Consider learning a generative model for time-series data. The sequential setting poses a unique challenge: Not only should the generator capture the conditional dynamics of (stepwise) transitions, but its open-loop rollouts should also preserve the joint distribution of (multi-step) trajectories. On one hand, autoregressive models trained by MLE allow learning and computing explicit transition distributions, but suffer from compounding error during rollouts. On the other hand, adversarial models based on GAN training alleviate such exposure bias, but transitions are implicit and hard to assess. In this work, we study a generative framework that seeks to combine the strengths of both: Motivated by a moment-matching objective to mitigate compounding error, we optimize a local (but forward-looking) transition policy, where the reinforcement signal is provided by a global (but stepwise-decomposable) energy model trained by contrastive estimation. At training, the two components are learne",
    "path": "papers/23/11/2311.01388.json",
    "total_tokens": 936,
    "translated_title": "对比模仿的时间序列生成",
    "translated_abstract": "考虑学习时间序列数据的生成模型。序列设置提出了一个独特的挑战：生成器不仅应该捕捉（逐步）转换的条件动力学，而且其开环回滚应该保持（多步）轨迹的联合分布。一方面，MLE训练的自回归模型允许学习和计算显式的转换分布，但在回滚过程中会受到复合误差的影响。另一方面，基于GAN训练的对抗模型减轻了这种暴露偏差，但转换是隐式的且难以评估。在这项工作中，我们研究了一个旨在结合两者优势的生成框架：受到匹配矩法的目标激发，我们优化一个本地（但前瞻性的）转换策略，其中强化信号由全局（但可逐步分解）能量模型通过对比估计训练提供。在训练中，两个组件被学习生成对抗样本。",
    "tldr": "本研究探讨了一种生成框架，旨在将自回归模型的显式转换分布和基于对抗训练的隐式转换相结合，通过对比估计训练全局能量模型，并优化本地转换策略来解决时间序列生成中的挑战。",
    "en_tdlr": "This paper proposes a generative framework that combines explicit transition distributions from autoregressive models with implicit transitions from adversarial training. By training a global energy model using contrastive estimation, and optimizing a local transition policy, the challenges in time-series generation can be addressed."
}