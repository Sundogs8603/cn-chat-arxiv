{
    "title": "Deep Neural Networks for Automatic Speaker Recognition Do Not Learn Supra-Segmental Temporal Features. (arXiv:2311.00489v1 [cs.SD])",
    "abstract": "While deep neural networks have shown impressive results in automatic speaker recognition and related tasks, it is dissatisfactory how little is understood about what exactly is responsible for these results. Part of the success has been attributed in prior work to their capability to model supra-segmental temporal information (SST), i.e., learn rhythmic-prosodic characteristics of speech in addition to spectral features. In this paper, we (i) present and apply a novel test to quantify to what extent the performance of state-of-the-art neural networks for speaker recognition can be explained by modeling SST; and (ii) present several means to force respective nets to focus more on SST and evaluate their merits. We find that a variety of CNN- and RNN-based neural network architectures for speaker recognition do not model SST to any sufficient degree, even when forced. The results provide a highly relevant basis for impactful future research into better exploitation of the full speech sig",
    "link": "http://arxiv.org/abs/2311.00489",
    "context": "Title: Deep Neural Networks for Automatic Speaker Recognition Do Not Learn Supra-Segmental Temporal Features. (arXiv:2311.00489v1 [cs.SD])\nAbstract: While deep neural networks have shown impressive results in automatic speaker recognition and related tasks, it is dissatisfactory how little is understood about what exactly is responsible for these results. Part of the success has been attributed in prior work to their capability to model supra-segmental temporal information (SST), i.e., learn rhythmic-prosodic characteristics of speech in addition to spectral features. In this paper, we (i) present and apply a novel test to quantify to what extent the performance of state-of-the-art neural networks for speaker recognition can be explained by modeling SST; and (ii) present several means to force respective nets to focus more on SST and evaluate their merits. We find that a variety of CNN- and RNN-based neural network architectures for speaker recognition do not model SST to any sufficient degree, even when forced. The results provide a highly relevant basis for impactful future research into better exploitation of the full speech sig",
    "path": "papers/23/11/2311.00489.json",
    "total_tokens": 891,
    "translated_title": "深度神经网络在自动说话人识别中不能学习超分段时间特征",
    "translated_abstract": "深度神经网络在自动说话人识别和相关任务中取得了令人印象深刻的结果，但我们对于这些结果的具体原因了解甚少。以前的研究将成功的一部分归因于它们模拟超分段时间信息（SST）的能力，即除了谱特征外还学习语音的韵律和韵律特征。在本文中，我们（i）提出并应用一种新的测试方法，来量化最先进的神经网络在说话人识别方面的性能能够通过建模SST来解释到多大程度；并且（ii）提出几种强制网络更加关注SST的方法，并评估它们的优点。我们发现，即使被强制要求，一系列基于CNN和RNN的神经网络结构在说话人识别中也不能充分地模拟SST。这些结果为未来更好地利用完整语音信号进行研究提供了非常重要的基础。",
    "tldr": "这项研究表明深度神经网络在自动说话人识别中无法充分模拟超分段时间特征，这为未来更好地利用完整语音信号进行研究提供了基础。",
    "en_tdlr": "This research shows that deep neural networks cannot effectively model supra-segmental temporal features in automatic speaker recognition, providing a basis for future research to better utilize complete speech signals."
}