{
    "title": "ACQUIRED: A Dataset for Answering Counterfactual Questions In Real-Life Videos. (arXiv:2311.01620v1 [cs.CV])",
    "abstract": "Multimodal counterfactual reasoning is a vital yet challenging ability for AI systems. It involves predicting the outcomes of hypothetical circumstances based on vision and language inputs, which enables AI models to learn from failures and explore hypothetical scenarios. Despite its importance, there are only a few datasets targeting the counterfactual reasoning abilities of multimodal models. Among them, they only cover reasoning over synthetic environments or specific types of events (e.g. traffic collisions), making them hard to reliably benchmark the model generalization ability in diverse real-world scenarios and reasoning dimensions. To overcome these limitations, we develop a video question answering dataset, ACQUIRED: it consists of 3.9K annotated videos, encompassing a wide range of event types and incorporating both first and third-person viewpoints, which ensures a focus on real-world diversity. In addition, each video is annotated with questions that span three distinct di",
    "link": "http://arxiv.org/abs/2311.01620",
    "context": "Title: ACQUIRED: A Dataset for Answering Counterfactual Questions In Real-Life Videos. (arXiv:2311.01620v1 [cs.CV])\nAbstract: Multimodal counterfactual reasoning is a vital yet challenging ability for AI systems. It involves predicting the outcomes of hypothetical circumstances based on vision and language inputs, which enables AI models to learn from failures and explore hypothetical scenarios. Despite its importance, there are only a few datasets targeting the counterfactual reasoning abilities of multimodal models. Among them, they only cover reasoning over synthetic environments or specific types of events (e.g. traffic collisions), making them hard to reliably benchmark the model generalization ability in diverse real-world scenarios and reasoning dimensions. To overcome these limitations, we develop a video question answering dataset, ACQUIRED: it consists of 3.9K annotated videos, encompassing a wide range of event types and incorporating both first and third-person viewpoints, which ensures a focus on real-world diversity. In addition, each video is annotated with questions that span three distinct di",
    "path": "papers/23/11/2311.01620.json",
    "total_tokens": 891,
    "translated_title": "ACQUIRED: 用于回答真实生活视频中反事实问题的数据集",
    "translated_abstract": "多模态反事实推理对于人工智能系统来说是一项重要而具有挑战性的能力。它涉及基于视觉和语言输入预测假设情境下的结果，这使得AI模型能够从失败中学习，并探索假设场景。尽管其重要性，目前只有少量针对多模态模型反事实推理能力的数据集。其中，它们只覆盖合成环境或特定类型的事件（例如交通碰撞），使得在多样的真实世界场景和推理维度中可靠地评估模型泛化能力变得困难。为了克服这些限制，我们开发了一个视频问答数据集ACQUIRED：它由3.9K个带注释的视频组成，涵盖了各种事件类型，同时包含了第一人称和第三人称视角，以确保关注真实世界的多样性。此外，每个视频都标注有三个不同领域的问题。",
    "tldr": "ACQUIRED是一个用于回答真实生活视频中反事实问题的数据集，在多模态模型反事实推理能力领域弥补了目前数据不足的问题，并提供了多样的真实世界场景和推理维度来评估模型的泛化能力。",
    "en_tdlr": "ACQUIRED is a dataset for answering counterfactual questions in real-life videos, which addresses the lack of datasets targeting multimodal models' counterfactual reasoning abilities and provides diverse real-world scenarios and reasoning dimensions for evaluating model generalization."
}