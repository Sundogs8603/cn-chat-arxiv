{
    "title": "Euclidean, Projective, Conformal: Choosing a Geometric Algebra for Equivariant Transformers",
    "abstract": "arXiv:2311.04744v2 Announce Type: replace-cross  Abstract: The Geometric Algebra Transformer (GATr) is a versatile architecture for geometric deep learning based on projective geometric algebra. We generalize this architecture into a blueprint that allows one to construct a scalable transformer architecture given any geometric (or Clifford) algebra. We study versions of this architecture for Euclidean, projective, and conformal algebras, all of which are suited to represent 3D data, and evaluate them in theory and practice. The simplest Euclidean architecture is computationally cheap, but has a smaller symmetry group and is not as sample-efficient, while the projective model is not sufficiently expressive. Both the conformal algebra and an improved version of the projective algebra define powerful, performant architectures.",
    "link": "https://arxiv.org/abs/2311.04744",
    "context": "Title: Euclidean, Projective, Conformal: Choosing a Geometric Algebra for Equivariant Transformers\nAbstract: arXiv:2311.04744v2 Announce Type: replace-cross  Abstract: The Geometric Algebra Transformer (GATr) is a versatile architecture for geometric deep learning based on projective geometric algebra. We generalize this architecture into a blueprint that allows one to construct a scalable transformer architecture given any geometric (or Clifford) algebra. We study versions of this architecture for Euclidean, projective, and conformal algebras, all of which are suited to represent 3D data, and evaluate them in theory and practice. The simplest Euclidean architecture is computationally cheap, but has a smaller symmetry group and is not as sample-efficient, while the projective model is not sufficiently expressive. Both the conformal algebra and an improved version of the projective algebra define powerful, performant architectures.",
    "path": "papers/23/11/2311.04744.json",
    "total_tokens": 799,
    "translated_title": "欧几里得、射影、共形：为等变换器选择几何代数",
    "translated_abstract": "Geometric Algebra Transformer（GATr）是一种基于射影几何代数的通用几何深度学习架构。我们将这种架构概括为一个蓝图，允许一个根据任何几何（或克利福德）代数来构建可扩展的变换器架构。我们研究了欧几里得、射影和共形代数版本的这种架构，它们都适合表示3D数据，并在理论和实践中进行了评估。最简单的欧几里得架构在计算上廉价，但对称群较小且不够样本高效，而射影模型表达能力不够。共形代数和改进版本的射影代数都定义了功能强大、性能良好的架构。",
    "tldr": "该论文研究了基于欧几里得、射影和共形代数的Geometric Algebra Transformer架构，发现共形代数和改进的射影代数定义了功能强大、性能良好的变换器架构。",
    "en_tdlr": "This paper explores the Geometric Algebra Transformer architecture based on Euclidean, projective, and conformal algebras, and finds that the conformal algebra and an improved version of the projective algebra define powerful, performant transformer architectures."
}