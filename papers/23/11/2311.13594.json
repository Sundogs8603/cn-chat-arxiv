{
    "title": "Labeling Neural Representations with Inverse Recognition. (arXiv:2311.13594v2 [cs.LG] UPDATED)",
    "abstract": "Deep Neural Networks (DNNs) demonstrate remarkable capabilities in learning complex hierarchical data representations, but the nature of these representations remains largely unknown. Existing global explainability methods, such as Network Dissection, face limitations such as reliance on segmentation masks, lack of statistical significance testing, and high computational demands. We propose Inverse Recognition (INVERT), a scalable approach for connecting learned representations with human-understandable concepts by leveraging their capacity to discriminate between these concepts. In contrast to prior work, INVERT is capable of handling diverse types of neurons, exhibits less computational complexity, and does not rely on the availability of segmentation masks. Moreover, INVERT provides an interpretable metric assessing the alignment between the representation and its corresponding explanation and delivering a measure of statistical significance. We demonstrate the applicability of INVE",
    "link": "http://arxiv.org/abs/2311.13594",
    "context": "Title: Labeling Neural Representations with Inverse Recognition. (arXiv:2311.13594v2 [cs.LG] UPDATED)\nAbstract: Deep Neural Networks (DNNs) demonstrate remarkable capabilities in learning complex hierarchical data representations, but the nature of these representations remains largely unknown. Existing global explainability methods, such as Network Dissection, face limitations such as reliance on segmentation masks, lack of statistical significance testing, and high computational demands. We propose Inverse Recognition (INVERT), a scalable approach for connecting learned representations with human-understandable concepts by leveraging their capacity to discriminate between these concepts. In contrast to prior work, INVERT is capable of handling diverse types of neurons, exhibits less computational complexity, and does not rely on the availability of segmentation masks. Moreover, INVERT provides an interpretable metric assessing the alignment between the representation and its corresponding explanation and delivering a measure of statistical significance. We demonstrate the applicability of INVE",
    "path": "papers/23/11/2311.13594.json",
    "total_tokens": 833,
    "translated_title": "在逆向识别中标记神经表示",
    "translated_abstract": "深度神经网络(DNNs)在学习复杂的层级数据表示方面表现出卓越的能力，但这些表示的性质仍然大部分未知。现有的全局可解释性方法，如网络解剖(Network Dissection)，存在诸多限制，如依赖分割遮罩、缺乏统计显著性检验和高计算需求。我们提出了Inverse Recognition (INVERT)方法，一种可扩展的方法，通过利用其区分这些概念的能力，将学习到的表示与人类可理解的概念相连接。与之前的工作相比，INVERT能够处理不同类型的神经元，计算复杂度更低，并且不依赖于分割遮罩的可用性。此外，INVERT提供了一个可解释的度量，评估表示和其相应解释之间的对齐，并提供一种统计显著性的度量。我们展示了INVERT的应用性。",
    "tldr": "逆向识别 (INVERT) 是一种可扩展的方法，通过连接学习到的神经表示与人类可理解的概念，实现了对神经表示的标记并提供了统计显著性评估指标。",
    "en_tdlr": "Inverse Recognition (INVERT) is a scalable approach that connects learned neural representations with human-understandable concepts, providing a labeling mechanism for these representations and a statistical significance metric."
}