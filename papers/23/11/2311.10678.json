{
    "title": "Distilling and Retrieving Generalizable Knowledge for Robot Manipulation via Language Corrections",
    "abstract": "arXiv:2311.10678v2 Announce Type: replace-cross  Abstract: Today's robot policies exhibit subpar performance when faced with the challenge of generalizing to novel environments. Human corrective feedback is a crucial form of guidance to enable such generalization. However, adapting to and learning from online human corrections is a non-trivial endeavor: not only do robots need to remember human feedback over time to retrieve the right information in new settings and reduce the intervention rate, but also they would need to be able to respond to feedback that can be arbitrary corrections about high-level human preferences to low-level adjustments to skill parameters. In this work, we present Distillation and Retrieval of Online Corrections (DROC), a large language model (LLM)-based system that can respond to arbitrary forms of language feedback, distill generalizable knowledge from corrections, and retrieve relevant past experiences based on textual and visual similarity for improving p",
    "link": "https://arxiv.org/abs/2311.10678",
    "context": "Title: Distilling and Retrieving Generalizable Knowledge for Robot Manipulation via Language Corrections\nAbstract: arXiv:2311.10678v2 Announce Type: replace-cross  Abstract: Today's robot policies exhibit subpar performance when faced with the challenge of generalizing to novel environments. Human corrective feedback is a crucial form of guidance to enable such generalization. However, adapting to and learning from online human corrections is a non-trivial endeavor: not only do robots need to remember human feedback over time to retrieve the right information in new settings and reduce the intervention rate, but also they would need to be able to respond to feedback that can be arbitrary corrections about high-level human preferences to low-level adjustments to skill parameters. In this work, we present Distillation and Retrieval of Online Corrections (DROC), a large language model (LLM)-based system that can respond to arbitrary forms of language feedback, distill generalizable knowledge from corrections, and retrieve relevant past experiences based on textual and visual similarity for improving p",
    "path": "papers/23/11/2311.10678.json",
    "total_tokens": 875,
    "translated_title": "通过语言纠正提炼和检索机器人操作的通用知识",
    "translated_abstract": "今天的机器人政策在面对推广到新环境的挑战时表现不佳。人类的纠正反馈是一种至关重要的指导形式，可以实现这种泛化。然而，适应和从在线人类纠正中学习是一项不容易的任务：机器人不仅需要随时间记住人类的反馈以便在新环境中检索正确的信息并降低干涉率，而且还需要能够回应可能是关于高级人类偏好的任意纠正到技能参数的低级调整。在这项工作中，我们提出了基于大型语言模型(LLM)的在线纠正蒸馏和检索(DROC)系统，它可以回应任意形式的语言反馈，从纠正中提炼出通用知识，并根据文本和视觉相似性检索相关的过去经验，以改进性能。",
    "tldr": "本研究提出了一种基于大型语言模型的系统，名为DROC，能够回应任意形式的语言反馈，从纠正中提炼出通用知识，并根据文本和视觉相似性检索相关的过去经验，以改进机器人操作的性能。",
    "en_tdlr": "This study introduces a system named DROC, based on a large language model, which can respond to arbitrary forms of language feedback, distill generalizable knowledge from corrections, and retrieve relevant past experiences based on textual and visual similarity to improve robot manipulation performance."
}