{
    "title": "A Good Feature Extractor Is All You Need for Weakly Supervised Pathology Slide Classification",
    "abstract": "arXiv:2311.11772v4 Announce Type: replace-cross  Abstract: Stain normalisation is thought to be a crucial preprocessing step in computational pathology pipelines. We question this belief in the context of weakly supervised whole slide image classification, motivated by the emergence of powerful feature extractors trained using self-supervised learning on diverse pathology datasets. To this end, we performed the most comprehensive evaluation of publicly available pathology feature extractors to date, involving more than 8,000 training runs across nine tasks, five datasets, three downstream architectures, and various preprocessing setups. Notably, we find that omitting stain normalisation and image augmentations does not compromise downstream slide-level classification performance, while incurring substantial savings in memory and compute. Using a new evaluation metric that facilitates relative downstream performance comparison, we identify the best publicly available extractors, and sho",
    "link": "https://arxiv.org/abs/2311.11772",
    "context": "Title: A Good Feature Extractor Is All You Need for Weakly Supervised Pathology Slide Classification\nAbstract: arXiv:2311.11772v4 Announce Type: replace-cross  Abstract: Stain normalisation is thought to be a crucial preprocessing step in computational pathology pipelines. We question this belief in the context of weakly supervised whole slide image classification, motivated by the emergence of powerful feature extractors trained using self-supervised learning on diverse pathology datasets. To this end, we performed the most comprehensive evaluation of publicly available pathology feature extractors to date, involving more than 8,000 training runs across nine tasks, five datasets, three downstream architectures, and various preprocessing setups. Notably, we find that omitting stain normalisation and image augmentations does not compromise downstream slide-level classification performance, while incurring substantial savings in memory and compute. Using a new evaluation metric that facilitates relative downstream performance comparison, we identify the best publicly available extractors, and sho",
    "path": "papers/23/11/2311.11772.json",
    "total_tokens": 892,
    "translated_title": "一个良好的特征提取器就是你在弱监督病理学切片分类中所需的一切",
    "translated_abstract": "常规认为染色标准化是计算病理学流程中关键的预处理步骤。我们在弱监督的整个切片图像分类环境中对这一信念提出质疑，这一信念是由训练在多样化病理学数据集上进行自监督学习的强大特征提取器的出现所激励的。为此，我们对迄今为止公开可获得的病理学特征提取器进行了最全面的评估，涉及九个任务、五个数据集、三个下游架构和各种预处理设置中的8000多个训练运行。值得注意的是，我们发现忽略染色标准化和图像增强并不会损害下游切片级别的分类性能，同时还会在内存和计算上带来大量节省。通过使用一种新的评估指标，促进了相对下游性能的比较，我们确定了最好的公开可获得的提取器，并展示。",
    "tldr": "在弱监督整个切片图像分类中，不同于常规认知的观念，研究发现省略染色标准化和图像增强并不会影响下游切片级别的分类性能，同时还能节省大量内存和计算资源。"
}