{
    "title": "Large Language Models for Propaganda Span Annotation. (arXiv:2311.09812v2 [cs.CL] UPDATED)",
    "abstract": "The use of propagandistic techniques in online contents has increased in recent years aiming to manipulate online audiences. Efforts to automatically detect and debunk such content have been made addressing various modeling scenarios. These include determining whether the content (text, image, or multimodal) (i) is propagandistic, (ii) employs one or more propagandistic techniques, and (iii) includes techniques with identifiable spans. Significant research efforts have been devoted to the first two scenarios compared to the latter. Therefore, in this study, we focus on the task of detecting propagandistic textual spans. Specifically, we investigate whether large language models (LLMs), such as GPT-4, can effectively perform the task. Moreover, we study the potential of employing the model to collect more cost-effective annotations. Our experiments use a large-scale in-house dataset consisting of annotations from human annotators with varying expertise levels. The results suggest that p",
    "link": "http://arxiv.org/abs/2311.09812",
    "context": "Title: Large Language Models for Propaganda Span Annotation. (arXiv:2311.09812v2 [cs.CL] UPDATED)\nAbstract: The use of propagandistic techniques in online contents has increased in recent years aiming to manipulate online audiences. Efforts to automatically detect and debunk such content have been made addressing various modeling scenarios. These include determining whether the content (text, image, or multimodal) (i) is propagandistic, (ii) employs one or more propagandistic techniques, and (iii) includes techniques with identifiable spans. Significant research efforts have been devoted to the first two scenarios compared to the latter. Therefore, in this study, we focus on the task of detecting propagandistic textual spans. Specifically, we investigate whether large language models (LLMs), such as GPT-4, can effectively perform the task. Moreover, we study the potential of employing the model to collect more cost-effective annotations. Our experiments use a large-scale in-house dataset consisting of annotations from human annotators with varying expertise levels. The results suggest that p",
    "path": "papers/23/11/2311.09812.json",
    "total_tokens": 881,
    "translated_title": "用于宣传性跨度注释的大型语言模型",
    "translated_abstract": "近年来，在线内容中使用宣传手法的情况有所增加，旨在操纵在线受众。针对各种建模场景，已经做出了自动检测和揭露此类内容的努力。这些场景包括确定内容（文本、图像或多模态）是否具有以下特征：（i）具有宣传性，（ii）使用一种或多种宣传手法，以及（iii）包含具有可识别范围的技巧。与前两种场景相比，已经对后一种场景进行了较大的研究工作。因此，本研究关注检测宣传性文本跨度的任务。具体而言，我们研究了大型语言模型（如GPT-4）是否能够有效执行该任务。此外，我们研究了利用该模型收集更具成本效益的标注的潜力。我们的实验使用了一套大规模的内部数据集，其中包含来自具有不同专业水平的人工标注者的注释。结果表明，",
    "tldr": "本研究探讨了使用大型语言模型（LLMs）来检测宣传性文本跨度的任务，并研究了利用该模型收集更具成本效益的标注的潜力。",
    "en_tdlr": "This study investigates the task of detecting propagandistic textual spans using large language models (LLMs) and explores the potential of utilizing the model for cost-effective annotations."
}