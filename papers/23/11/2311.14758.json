{
    "title": "Point2RBox: Combine Knowledge from Synthetic Visual Patterns for End-to-end Oriented Object Detection with Single Point Supervision",
    "abstract": "arXiv:2311.14758v2 Announce Type: replace-cross  Abstract: With the rapidly increasing demand for oriented object detection (OOD), recent research involving weakly-supervised detectors for learning rotated box (RBox) from the horizontal box (HBox) has attracted more and more attention. In this paper, we explore a more challenging yet label-efficient setting, namely single point-supervised OOD, and present our approach called Point2RBox. Specifically, we propose to leverage two principles: 1) Synthetic pattern knowledge combination: By sampling around each labeled point on the image, we spread the object feature to synthetic visual patterns with known boxes to provide the knowledge for box regression. 2) Transform self-supervision: With a transformed input image (e.g. scaled/rotated), the output RBoxes are trained to follow the same transformation so that the network can perceive the relative size/rotation between objects. The detector is further enhanced by a few devised techniques to ",
    "link": "https://arxiv.org/abs/2311.14758",
    "context": "Title: Point2RBox: Combine Knowledge from Synthetic Visual Patterns for End-to-end Oriented Object Detection with Single Point Supervision\nAbstract: arXiv:2311.14758v2 Announce Type: replace-cross  Abstract: With the rapidly increasing demand for oriented object detection (OOD), recent research involving weakly-supervised detectors for learning rotated box (RBox) from the horizontal box (HBox) has attracted more and more attention. In this paper, we explore a more challenging yet label-efficient setting, namely single point-supervised OOD, and present our approach called Point2RBox. Specifically, we propose to leverage two principles: 1) Synthetic pattern knowledge combination: By sampling around each labeled point on the image, we spread the object feature to synthetic visual patterns with known boxes to provide the knowledge for box regression. 2) Transform self-supervision: With a transformed input image (e.g. scaled/rotated), the output RBoxes are trained to follow the same transformation so that the network can perceive the relative size/rotation between objects. The detector is further enhanced by a few devised techniques to ",
    "path": "papers/23/11/2311.14758.json",
    "total_tokens": 867,
    "translated_title": "Point2RBox: 结合合成视觉模式的知识用于端到端有单点监督的定向物体检测",
    "translated_abstract": "随着对定向物体检测（OOD）需求的迅速增加，最近涉及从水平框（HBox）学习旋转框（RBox）的弱监督检测器的研究越来越受到关注。本文探讨了一个更具挑战性但标签效率高的设置，即单点监督OOD，并提出了我们的方法Point2RBox。具体来说，我们提出利用两个原则：1）合成模式知识组合：通过在图像上每个标记点周围采样，我们将对象特征传播到已知框的合成视觉模式中，以提供箱子回归的知识。2）变换自监督：通过一个变换的输入图像（例如缩放/旋转），输出的RBoxes被训练以遵循相同的变换，从而使网络能够感知对象之间的相对大小/旋转。检测器进一步通过几种设计的技术增强了",
    "tldr": "提出了Point2RBox方法，通过合成模式知识组合和变换自监督的原则，实现了单点监督的定向物体检测",
    "en_tdlr": "Introducing the Point2RBox approach, which achieves single point-supervised oriented object detection through the principles of combining synthetic pattern knowledge and transform self-supervision."
}