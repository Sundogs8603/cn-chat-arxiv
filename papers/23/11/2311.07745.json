{
    "title": "Simplifying Complex Observation Models in Continuous POMDP Planning with Probabilistic Guarantees and Practice. (arXiv:2311.07745v4 [cs.AI] UPDATED)",
    "abstract": "Solving partially observable Markov decision processes (POMDPs) with high dimensional and continuous observations, such as camera images, is required for many real life robotics and planning problems. Recent researches suggested machine learned probabilistic models as observation models, but their use is currently too computationally expensive for online deployment. We deal with the question of what would be the implication of using simplified observation models for planning, while retaining formal guarantees on the quality of the solution. Our main contribution is a novel probabilistic bound based on a statistical total variation distance of the simplified model. We show that it bounds the theoretical POMDP value w.r.t. original model, from the empirical planned value with the simplified model, by generalizing recent results of particle-belief MDP concentration bounds. Our calculations can be separated into offline and online parts, and we arrive at formal guarantees without having to",
    "link": "http://arxiv.org/abs/2311.07745",
    "context": "Title: Simplifying Complex Observation Models in Continuous POMDP Planning with Probabilistic Guarantees and Practice. (arXiv:2311.07745v4 [cs.AI] UPDATED)\nAbstract: Solving partially observable Markov decision processes (POMDPs) with high dimensional and continuous observations, such as camera images, is required for many real life robotics and planning problems. Recent researches suggested machine learned probabilistic models as observation models, but their use is currently too computationally expensive for online deployment. We deal with the question of what would be the implication of using simplified observation models for planning, while retaining formal guarantees on the quality of the solution. Our main contribution is a novel probabilistic bound based on a statistical total variation distance of the simplified model. We show that it bounds the theoretical POMDP value w.r.t. original model, from the empirical planned value with the simplified model, by generalizing recent results of particle-belief MDP concentration bounds. Our calculations can be separated into offline and online parts, and we arrive at formal guarantees without having to",
    "path": "papers/23/11/2311.07745.json",
    "total_tokens": 903,
    "translated_title": "在具有概率保证和实践的连续POMDP规划中简化复杂的观测模型",
    "translated_abstract": "解决具有高维度和连续观测（如相机图像）的部分可观测马尔可夫决策过程(POMDP)对于许多实际机器人和规划问题是必需的。最近的研究建议使用机器学习的概率模型作为观测模型，但它们目前在线部署时计算成本过高。我们探讨了在规划中使用简化观测模型的影响，同时保持对解决方案质量的形式化保证。我们的主要贡献是一种基于简化模型的统计总变差距离的新型概率界限。我们证明，通过推广最近的粒子置信度MDP集中界限的结果，它将理论POMDP值与简化模型下的实际规划值进行了约束。我们的计算可以分为离线和在线部分，并且我们可以得到形式化的保证，而无需",
    "tldr": "本研究在解决具有高维度和连续观测的部分可观测马尔可夫决策过程中，提出了一种基于统计总变差距离的新型概率界限，能够简化观测模型并保证解决方案的质量。"
}