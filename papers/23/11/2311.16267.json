{
    "title": "Novel Preprocessing Technique for Data Embedding in Engineering Code Generation Using Large Language Model. (arXiv:2311.16267v2 [cs.CL] UPDATED)",
    "abstract": "We present four main contributions to enhance the performance of Large Language Models (LLMs) in generating domain-specific code: (i) utilizing LLM-based data splitting and data renovation techniques to improve the semantic representation of embeddings' space; (ii) introducing the Chain of Density for Renovation Credibility (CoDRC), driven by LLMs, and the Adaptive Text Renovation (ATR) algorithm for assessing data renovation reliability; (iii) developing the Implicit Knowledge Expansion and Contemplation (IKEC) Prompt technique; and (iv) effectively refactoring existing scripts to generate new and high-quality scripts with LLMs. By using engineering simulation software RedHawk-SC as a case study, we demonstrate the effectiveness of our data pre-processing method for expanding and categorizing scripts. When combined with IKEC, these techniques enhance the Retrieval-Augmented Generation (RAG) method in retrieving more relevant information, ultimately achieving a 73.33% \"Percentage of Co",
    "link": "http://arxiv.org/abs/2311.16267",
    "context": "Title: Novel Preprocessing Technique for Data Embedding in Engineering Code Generation Using Large Language Model. (arXiv:2311.16267v2 [cs.CL] UPDATED)\nAbstract: We present four main contributions to enhance the performance of Large Language Models (LLMs) in generating domain-specific code: (i) utilizing LLM-based data splitting and data renovation techniques to improve the semantic representation of embeddings' space; (ii) introducing the Chain of Density for Renovation Credibility (CoDRC), driven by LLMs, and the Adaptive Text Renovation (ATR) algorithm for assessing data renovation reliability; (iii) developing the Implicit Knowledge Expansion and Contemplation (IKEC) Prompt technique; and (iv) effectively refactoring existing scripts to generate new and high-quality scripts with LLMs. By using engineering simulation software RedHawk-SC as a case study, we demonstrate the effectiveness of our data pre-processing method for expanding and categorizing scripts. When combined with IKEC, these techniques enhance the Retrieval-Augmented Generation (RAG) method in retrieving more relevant information, ultimately achieving a 73.33% \"Percentage of Co",
    "path": "papers/23/11/2311.16267.json",
    "total_tokens": 1168,
    "translated_title": "使用大型语言模型在工程代码生成中的数据嵌入的新型预处理技术",
    "translated_abstract": "我们提出了四个主要贡献来改善大型语言模型（LLM）在生成特定领域代码时的性能：（i）利用基于LLM的数据拆分和数据翻新技术来提高嵌入空间的语义表示；（ii）引入由LLM驱动的密度链条以用于翻新可信度（CoDRC），以及用于评估数据翻新可靠性的自适应文本翻新（ATR）算法；（iii）开发隐式知识扩展和思考（IKEC）提示技术；（iv）通过有效重构现有脚本来使用LLM生成新的高质量脚本。我们以工程模拟软件RedHawk-SC为案例研究，展示了我们的数据预处理方法在扩展和分类脚本方面的有效性。当与IKEC结合使用时，这些技术可以增强检索增强生成（RAG）方法以检索更相关的信息，最终实现73.33％的“共现百分比”。",
    "tldr": "本论文提出了一种新的预处理技术，通过利用大型语言模型（LLM）来增强工程代码生成中的性能。该技术包括利用LLM的数据拆分和数据翻新技术提高嵌入空间的语义表示，引入基于LLM的密度链条和自适应文本翻新算法评估数据翻新可信度，开发隐式知识扩展和思考提示技术，以及通过重构现有脚本生成新的高质量脚本。在使用工程模拟软件RedHawk-SC作为案例研究时，这些技术的有效性得到了证明，能够扩展和分类脚本，并在与IKEC结合使用时提高检索增强生成方法的性能。"
}