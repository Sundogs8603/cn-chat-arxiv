{
    "title": "Privacy Risks Analysis and Mitigation in Federated Learning for Medical Images",
    "abstract": "Federated learning (FL) is gaining increasing popularity in the medical domain for analyzing medical images, which is considered an effective technique to safeguard sensitive patient data and comply with privacy regulations. However, several recent studies have revealed that the default settings of FL may leak private training data under privacy attacks. Thus, it is still unclear whether and to what extent such privacy risks of FL exist in the medical domain, and if so, \"how to mitigate such risks?\". In this paper, first, we propose a holistic framework for Medical data Privacy risk analysis and mitigation in Federated Learning (MedPFL) to analyze privacy risks and develop effective mitigation strategies in FL for protecting private medical data. Second, we demonstrate the substantial privacy risks of using FL to process medical images, where adversaries can easily perform privacy attacks to reconstruct private medical images accurately. Third, we show that the defense approach of addi",
    "link": "https://arxiv.org/abs/2311.06643",
    "context": "Title: Privacy Risks Analysis and Mitigation in Federated Learning for Medical Images\nAbstract: Federated learning (FL) is gaining increasing popularity in the medical domain for analyzing medical images, which is considered an effective technique to safeguard sensitive patient data and comply with privacy regulations. However, several recent studies have revealed that the default settings of FL may leak private training data under privacy attacks. Thus, it is still unclear whether and to what extent such privacy risks of FL exist in the medical domain, and if so, \"how to mitigate such risks?\". In this paper, first, we propose a holistic framework for Medical data Privacy risk analysis and mitigation in Federated Learning (MedPFL) to analyze privacy risks and develop effective mitigation strategies in FL for protecting private medical data. Second, we demonstrate the substantial privacy risks of using FL to process medical images, where adversaries can easily perform privacy attacks to reconstruct private medical images accurately. Third, we show that the defense approach of addi",
    "path": "papers/23/11/2311.06643.json",
    "total_tokens": 979,
    "translated_title": "针对医学图像联邦学习的隐私风险分析与缓解",
    "translated_abstract": "联邦学习（FL）在医学领域中用于分析医学图像，被认为是一种有效的技术，用于保护敏感患者数据和遵守隐私法规。然而，最近的研究揭示了FL的默认设置可能在隐私攻击下泄露私密训练数据。因此，目前还不清楚FL在医学领域是否存在此类隐私风险，以及如何缓解这些风险。本文首先提出了一种用于医学数据隐私风险分析和FL中缓解策略的全面框架（MedPFL），以分析隐私风险并制定有效的缓解策略以保护私密医学数据。其次，我们展示了使用FL处理医学图像存在的重大隐私风险，其中攻击者可以轻松地进行隐私攻击以准确重建私密医学图像。最后，我们展示了一种防御方法，即添加随机噪声以缓解隐私攻击，并评估了该方法的效果。",
    "tldr": "本研究提出了一种用于医学数据隐私风险分析和FL中缓解策略的全面框架（MedPFL）。研究发现，使用FL处理医学图像存在重大隐私风险，攻击者可以准确重构私密医学图像。为了缓解隐私攻击，研究提出了防御方法，并评估了其效果。",
    "en_tdlr": "This study proposes a comprehensive framework for privacy risk analysis and mitigation in federated learning (MedPFL) for medical data. The research reveals substantial privacy risks in using federated learning for medical images, where adversaries can accurately reconstruct private medical images. To mitigate privacy attacks, a defense approach is introduced and evaluated."
}