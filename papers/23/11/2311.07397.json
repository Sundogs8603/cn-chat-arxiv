{
    "title": "AMBER: An LLM-free Multi-dimensional Benchmark for MLLMs Hallucination Evaluation",
    "abstract": "arXiv:2311.07397v2 Announce Type: replace  Abstract: Despite making significant progress in multi-modal tasks, current Multi-modal Large Language Models (MLLMs) encounter the significant challenge of hallucinations, which may lead to harmful consequences. Therefore, evaluating MLLMs' hallucinations is becoming increasingly important in model improvement and practical application deployment. Previous works are limited in high evaluation costs (e.g., relying on humans or advanced LLMs) and insufficient evaluation dimensions (e.g., types of tasks and hallucinations). In this paper, we propose an LLM-free multi-dimensional benchmark AMBER, which can be used to evaluate both generative task and discriminative task including existence, attribute and relation hallucination. Based on AMBER, we design a low-cost and efficient evaluation pipeline. Additionally, we conduct a comprehensive evaluation and detailed analysis of mainstream MLLMs including GPT-4V(ision), and also give guideline suggest",
    "link": "https://arxiv.org/abs/2311.07397",
    "context": "Title: AMBER: An LLM-free Multi-dimensional Benchmark for MLLMs Hallucination Evaluation\nAbstract: arXiv:2311.07397v2 Announce Type: replace  Abstract: Despite making significant progress in multi-modal tasks, current Multi-modal Large Language Models (MLLMs) encounter the significant challenge of hallucinations, which may lead to harmful consequences. Therefore, evaluating MLLMs' hallucinations is becoming increasingly important in model improvement and practical application deployment. Previous works are limited in high evaluation costs (e.g., relying on humans or advanced LLMs) and insufficient evaluation dimensions (e.g., types of tasks and hallucinations). In this paper, we propose an LLM-free multi-dimensional benchmark AMBER, which can be used to evaluate both generative task and discriminative task including existence, attribute and relation hallucination. Based on AMBER, we design a low-cost and efficient evaluation pipeline. Additionally, we conduct a comprehensive evaluation and detailed analysis of mainstream MLLMs including GPT-4V(ision), and also give guideline suggest",
    "path": "papers/23/11/2311.07397.json",
    "total_tokens": 855,
    "translated_title": "AMBER：一种无需LLM的多维基准用于评估MLLM的幻象",
    "translated_abstract": "尽管在多模态任务上取得了显著进展，但当前的多模态大型语言模型（MLLMs）面临幻觉的重大挑战，这可能导致有害后果。因此，评估MLLMs的幻觉对于模型改进和实际应用部署变得越来越重要。先前的工作在高评估成本（例如依赖人类或高级LLMs）和评估维度不足（例如任务和幻觉类型）方面存在局限性。在本文中，我们提出了一种无需LLM的多维基准AMBER，可用于评估生成任务和判别任务，包括存在、属性和关系幻觉。基于AMBER，我们设计了一个低成本高效的评估流程。此外，我们对主流MLLMs进行了全面评估和详细分析，包括GPT-4V(ision)，并提出了指导建议。",
    "tldr": "提出了一种无需LLM的多维基准AMBER，可用于评估MLLM的幻象，设计了低成本高效的评估流程，并对主流MLLMs进行了全面评估和分析",
    "en_tdlr": "Proposes a multi-dimensional benchmark AMBER that does not require LLMs for evaluating hallucinations of MLLMs, designs a low-cost and efficient evaluation pipeline, and conducts comprehensive evaluation and analysis of mainstream MLLMs."
}