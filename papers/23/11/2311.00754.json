{
    "title": "Learning to Design and Use Tools for Robotic Manipulation. (arXiv:2311.00754v1 [cs.RO])",
    "abstract": "When limited by their own morphologies, humans and some species of animals have the remarkable ability to use objects from the environment toward accomplishing otherwise impossible tasks. Robots might similarly unlock a range of additional capabilities through tool use. Recent techniques for jointly optimizing morphology and control via deep learning are effective at designing locomotion agents. But while outputting a single morphology makes sense for locomotion, manipulation involves a variety of strategies depending on the task goals at hand. A manipulation agent must be capable of rapidly prototyping specialized tools for different goals. Therefore, we propose learning a designer policy, rather than a single design. A designer policy is conditioned on task information and outputs a tool design that helps solve the task. A design-conditioned controller policy can then perform manipulation using these tools. In this work, we take a step towards this goal by introducing a reinforcement",
    "link": "http://arxiv.org/abs/2311.00754",
    "context": "Title: Learning to Design and Use Tools for Robotic Manipulation. (arXiv:2311.00754v1 [cs.RO])\nAbstract: When limited by their own morphologies, humans and some species of animals have the remarkable ability to use objects from the environment toward accomplishing otherwise impossible tasks. Robots might similarly unlock a range of additional capabilities through tool use. Recent techniques for jointly optimizing morphology and control via deep learning are effective at designing locomotion agents. But while outputting a single morphology makes sense for locomotion, manipulation involves a variety of strategies depending on the task goals at hand. A manipulation agent must be capable of rapidly prototyping specialized tools for different goals. Therefore, we propose learning a designer policy, rather than a single design. A designer policy is conditioned on task information and outputs a tool design that helps solve the task. A design-conditioned controller policy can then perform manipulation using these tools. In this work, we take a step towards this goal by introducing a reinforcement",
    "path": "papers/23/11/2311.00754.json",
    "total_tokens": 844,
    "translated_title": "学习设计和使用机器人操纵工具",
    "translated_abstract": "当面临自身形态限制时，人类和某些动物种类具有使用环境中的物体来完成原本不可能的任务的能力。机器人可能通过使用工具解锁一系列额外的能力。最近的通过深度学习来联合优化形态和控制的技术在设计移动机器人方面非常有效。但是，尽管输出一个单一的形态对于移动来说是有意义的，但是操纵涉及到根据手头的任务目标采用各种策略。一个操纵机器人必须能够快速制作出适用于不同目标的专用工具。因此，我们提出学习一个设计策略，而不是一个单一的设计。设计策略以任务信息为条件，并输出一个有助于解决任务的工具设计。然后，一个以设计条件为基础的控制策略可以使用这些工具进行操纵。在这项工作中，我们朝着这个目标迈出了一步，引入了一种强化学习方法。",
    "tldr": "本论文提出了学习一种设计策略来制作适用于不同任务的专用工具，并通过这些工具进行机器人操纵。这可以解锁机器人的额外能力。",
    "en_tdlr": "This paper proposes learning a design strategy to create specialized tools for different tasks and using these tools for robotic manipulation, unlocking additional capabilities for robots."
}