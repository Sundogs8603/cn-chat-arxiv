{
    "title": "Space Narrative: Generating Images and 3D Scenes of Chinese Garden from Text using Deep Learning. (arXiv:2311.00339v1 [cs.CV])",
    "abstract": "The consistent mapping from poems to paintings is essential for the research and restoration of traditional Chinese gardens. But the lack of firsthand ma-terial is a great challenge to the reconstruction work. In this paper, we pro-pose a method to generate garden paintings based on text descriptions using deep learning method. Our image-text pair dataset consists of more than one thousand Ming Dynasty Garden paintings and their inscriptions and post-scripts. A latent text-to-image diffusion model learns the mapping from de-scriptive texts to garden paintings of the Ming Dynasty, and then the text description of Jichang Garden guides the model to generate new garden paintings. The cosine similarity between the guide text and the generated image is the evaluation criterion for the generated images. Our dataset is used to fine-tune the pre-trained diffusion model using Low-Rank Adapta-tion of Large Language Models (LoRA). We also transformed the generated images into a panorama and creat",
    "link": "http://arxiv.org/abs/2311.00339",
    "context": "Title: Space Narrative: Generating Images and 3D Scenes of Chinese Garden from Text using Deep Learning. (arXiv:2311.00339v1 [cs.CV])\nAbstract: The consistent mapping from poems to paintings is essential for the research and restoration of traditional Chinese gardens. But the lack of firsthand ma-terial is a great challenge to the reconstruction work. In this paper, we pro-pose a method to generate garden paintings based on text descriptions using deep learning method. Our image-text pair dataset consists of more than one thousand Ming Dynasty Garden paintings and their inscriptions and post-scripts. A latent text-to-image diffusion model learns the mapping from de-scriptive texts to garden paintings of the Ming Dynasty, and then the text description of Jichang Garden guides the model to generate new garden paintings. The cosine similarity between the guide text and the generated image is the evaluation criterion for the generated images. Our dataset is used to fine-tune the pre-trained diffusion model using Low-Rank Adapta-tion of Large Language Models (LoRA). We also transformed the generated images into a panorama and creat",
    "path": "papers/23/11/2311.00339.json",
    "total_tokens": 1021,
    "translated_title": "空间叙述：使用深度学习从文本生成中国园林的图像和3D场景",
    "translated_abstract": "对于传统中国园林的研究和修复，将诗歌映射到绘画是至关重要的。然而，缺乏第一手资料对于重建工作是一个巨大的挑战。在本文中，我们提出了一种基于深度学习方法，根据文本描述生成园林绘画的方法。我们的图像-文本配对数据集包含了一千多张明代园林绘画及其铭文和后记。通过潜在的文本到图像扩散模型，学习了从描述文本到明代园林绘画的映射，并且基于吉昌园的文本描述，引导模型生成新的园林绘画。生成的图像与引导文本之间的余弦相似度被用作生成图像的评估标准。我们使用低秩适应大型语言模型（LoRA）的预训练扩散模型对数据集进行微调。我们还将生成的图像转换为全景图，并且...",
    "tldr": "本论文提出了一种使用深度学习方法将文本描述转换为明代园林绘画的方法。通过学习从描述文本到园林绘画的映射，并以吉昌园的文本描述为引导，生成新的园林绘画。生成的图像的评估标准是与引导文本的余弦相似度。同时，我们使用低秩适应大型语言模型对数据进行微调。生成的图像还可以转换为全景图。"
}