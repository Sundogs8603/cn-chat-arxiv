{
    "title": "Interpreting User Requests in the Context of Natural Language Standing Instructions",
    "abstract": "arXiv:2311.09796v2 Announce Type: replace-cross  Abstract: Users of natural language interfaces, generally powered by Large Language Models (LLMs),often must repeat their preferences each time they make a similar request. We describe an approach to LLM-based dialogue modeling in which persistent user constraints and preferences -- collectively termed standing instructions -- as additional context for such interfaces. For example, when a user states \"I'm hungry\", a previously expressed preference for Persian food can be automatically added to the LLM prompt, influencing the search for relevant restaurants. We develop NLSI, a language-to-program dataset consisting of over 2.4K dialogues spanning 17 domains, where each dialogue is paired with a user profile (a set of users specific standing instructions) and corresponding structured representations (API calls). A key challenge in NLSI is to identify which subset of the standing instructions is applicable to a given dialogue. NLSI contains",
    "link": "https://arxiv.org/abs/2311.09796",
    "context": "Title: Interpreting User Requests in the Context of Natural Language Standing Instructions\nAbstract: arXiv:2311.09796v2 Announce Type: replace-cross  Abstract: Users of natural language interfaces, generally powered by Large Language Models (LLMs),often must repeat their preferences each time they make a similar request. We describe an approach to LLM-based dialogue modeling in which persistent user constraints and preferences -- collectively termed standing instructions -- as additional context for such interfaces. For example, when a user states \"I'm hungry\", a previously expressed preference for Persian food can be automatically added to the LLM prompt, influencing the search for relevant restaurants. We develop NLSI, a language-to-program dataset consisting of over 2.4K dialogues spanning 17 domains, where each dialogue is paired with a user profile (a set of users specific standing instructions) and corresponding structured representations (API calls). A key challenge in NLSI is to identify which subset of the standing instructions is applicable to a given dialogue. NLSI contains",
    "path": "papers/23/11/2311.09796.json",
    "total_tokens": 836,
    "translated_title": "在自然语言交互指令环境中解释用户请求",
    "translated_abstract": "自然语言接口的用户通常由大型语言模型（LLMs）驱动，并且经常必须在每次进行类似请求时重复他们的偏好。我们描述了一种基于LLM的对话建模方法，其中持久的用户约束和偏好 - 统称为常设指令 - 作为这种接口的额外上下文。例如，当用户说“我饿了”时，先前表达的波斯食物偏好可以自动添加到LLM提示中，影响搜索相关餐馆。我们开发了NLSI，一个包含超过2.4K跨越17个领域的对话的语言到程序数据集，其中每个对话都与用户配置文件（一组用户特定的常设指令）和相应的结构化表示形式（API调用）配对。 NLSI的一个关键挑战是确定哪些常设指令子集适用于给定的对话。",
    "tldr": "在使用大型语言模型的自然语言接口时，本研究提出了一种基于用户常设指令的对话建模方法，通过将用户的约束和偏好作为上下文，从而在类似请求中实现自动化。",
    "en_tdlr": "This paper presents an approach to dialogue modeling based on persistent user constraints and preferences, termed standing instructions, which are used as additional context in natural language interfaces powered by large language models to automate similar requests."
}