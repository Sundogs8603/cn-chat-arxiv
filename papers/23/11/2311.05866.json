{
    "title": "Fair Supervised Learning with A Simple Random Sampler of Sensitive Attributes",
    "abstract": "arXiv:2311.05866v2 Announce Type: replace-cross  Abstract: As the data-driven decision process becomes dominating for industrial applications, fairness-aware machine learning arouses great attention in various areas. This work proposes fairness penalties learned by neural networks with a simple random sampler of sensitive attributes for non-discriminatory supervised learning. In contrast to many existing works that critically rely on the discreteness of sensitive attributes and response variables, the proposed penalty is able to handle versatile formats of the sensitive attributes, so it is more extensively applicable in practice than many existing algorithms. This penalty enables us to build a computationally efficient group-level in-processing fairness-aware training framework. Empirical evidence shows that our framework enjoys better utility and fairness measures on popular benchmark data sets than competing methods. We also theoretically characterize estimation errors and loss of u",
    "link": "https://arxiv.org/abs/2311.05866",
    "context": "Title: Fair Supervised Learning with A Simple Random Sampler of Sensitive Attributes\nAbstract: arXiv:2311.05866v2 Announce Type: replace-cross  Abstract: As the data-driven decision process becomes dominating for industrial applications, fairness-aware machine learning arouses great attention in various areas. This work proposes fairness penalties learned by neural networks with a simple random sampler of sensitive attributes for non-discriminatory supervised learning. In contrast to many existing works that critically rely on the discreteness of sensitive attributes and response variables, the proposed penalty is able to handle versatile formats of the sensitive attributes, so it is more extensively applicable in practice than many existing algorithms. This penalty enables us to build a computationally efficient group-level in-processing fairness-aware training framework. Empirical evidence shows that our framework enjoys better utility and fairness measures on popular benchmark data sets than competing methods. We also theoretically characterize estimation errors and loss of u",
    "path": "papers/23/11/2311.05866.json",
    "total_tokens": 863,
    "translated_title": "公平受监督学习中具有敏感属性的简单随机采样器",
    "translated_abstract": "随着数据驱动的决策过程在工业应用中变得主导，各个领域对具有公平意识的机器学习引起了极大关注。本研究提出了利用敏感属性的简单随机采样器学习公平惩罚的神经网络方法，用于非歧视性受监督学习。与许多现有作品基本依赖于敏感属性和响应变量的离散性不同，所提出的惩罚能够处理多种格式的敏感属性，因此在实践中比许多现有算法更具广泛适用性。该惩罚使我们能够构建一个计算效率高的群体级别处理公平感知的训练框架。实证证据表明，我们的框架在流行的基准数据集上比竞争方法具有更好的效用和公平度量。我们还在理论上对估计误差和损失进行了表征。",
    "tldr": "提出了一种公平受监督学习的方法，利用简单随机采样器处理敏感属性，可以更广泛地适用于实践中，并构建了一个计算效率高的群体级别处理公平感知的训练框架。",
    "en_tdlr": "Proposing a method for fair supervised learning that utilizes a simple random sampler to handle sensitive attributes, which can be more widely applicable in practice, and constructing a computationally efficient group-level in-processing fairness-aware training framework."
}