{
    "title": "Robust Data Pruning under Label Noise via Maximizing Re-labeling Accuracy. (arXiv:2311.01002v1 [cs.LG])",
    "abstract": "Data pruning, which aims to downsize a large training set into a small informative subset, is crucial for reducing the enormous computational costs of modern deep learning. Though large-scale data collections invariably contain annotation noise and numerous robust learning methods have been developed, data pruning for the noise-robust learning scenario has received little attention. With state-of-the-art Re-labeling methods that self-correct erroneous labels while training, it is challenging to identify which subset induces the most accurate re-labeling of erroneous labels in the entire training set. In this paper, we formalize the problem of data pruning with re-labeling. We first show that the likelihood of a training example being correctly re-labeled is proportional to the prediction confidence of its neighborhood in the subset. Therefore, we propose a novel data pruning algorithm, Prune4Rel, that finds a subset maximizing the total neighborhood confidence of all training examples,",
    "link": "http://arxiv.org/abs/2311.01002",
    "context": "Title: Robust Data Pruning under Label Noise via Maximizing Re-labeling Accuracy. (arXiv:2311.01002v1 [cs.LG])\nAbstract: Data pruning, which aims to downsize a large training set into a small informative subset, is crucial for reducing the enormous computational costs of modern deep learning. Though large-scale data collections invariably contain annotation noise and numerous robust learning methods have been developed, data pruning for the noise-robust learning scenario has received little attention. With state-of-the-art Re-labeling methods that self-correct erroneous labels while training, it is challenging to identify which subset induces the most accurate re-labeling of erroneous labels in the entire training set. In this paper, we formalize the problem of data pruning with re-labeling. We first show that the likelihood of a training example being correctly re-labeled is proportional to the prediction confidence of its neighborhood in the subset. Therefore, we propose a novel data pruning algorithm, Prune4Rel, that finds a subset maximizing the total neighborhood confidence of all training examples,",
    "path": "papers/23/11/2311.01002.json",
    "total_tokens": 919,
    "translated_title": "通过最大化重新标记准确性来进行鲁棒数据修剪",
    "translated_abstract": "数据修剪旨在将大型训练集缩减为一个小而信息丰富的子集，对于减少现代深度学习的巨大计算成本至关重要。尽管大规模数据集中不可避免地含有注释噪声，并且已经开发了许多鲁棒学习方法，但对于噪声鲁棒学习场景下的数据修剪几乎未受到关注。通过自校正错误标签的最新重新标记方法在训练过程中，很难确定哪个子集能够在整个训练集中引发最准确的重新标记。在本文中，我们形式化了重新标记的数据修剪问题。首先我们展示了一个训练示例被正确重新标记的可能性与其邻域中的预测置信度成比例。因此，我们提出了一种全新的数据修剪算法，名为Prune4Rel，它能找到一个子集，使得所有训练示例的邻域置信度之和最大化。",
    "tldr": "该论文提出了一种通过最大化重新标记准确性来进行鲁棒数据修剪的算法，该算法能够找到一个子集，使得所有训练示例的邻域置信度之和最大化。这个方法在现代深度学习中具有重要的应用价值。",
    "en_tdlr": "This paper proposes an algorithm for robust data pruning under label noise by maximizing the re-labeling accuracy, which finds a subset that maximizes the total neighborhood confidence of all training examples. This method has significant practical implications in modern deep learning."
}