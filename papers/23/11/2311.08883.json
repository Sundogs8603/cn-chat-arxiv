{
    "title": "Enabling Large Language Models to Learn from Rules",
    "abstract": "arXiv:2311.08883v2 Announce Type: replace  Abstract: Large language models (LLMs) have shown incredible performance in completing various real-world tasks. The current knowledge learning paradigm of LLMs is mainly based on learning from examples, in which LLMs learn the internal rule implicitly from a certain number of supervised examples. However, this learning paradigm may not well learn those complicated rules, especially when the training examples are limited. We are inspired that humans can learn the new tasks or knowledge in another way by learning from rules. That is, humans can learn new tasks or grasps new knowledge quickly and generalize well given only a detailed rule and a few optional examples. Therefore, in this paper, we aim to explore the feasibility of this new learning paradigm, which targets on encoding rule-based knowledge into LLMs. We further propose rule distillation, which first uses the strong in-context abilities of LLMs to extract the knowledge from the textu",
    "link": "https://arxiv.org/abs/2311.08883",
    "context": "Title: Enabling Large Language Models to Learn from Rules\nAbstract: arXiv:2311.08883v2 Announce Type: replace  Abstract: Large language models (LLMs) have shown incredible performance in completing various real-world tasks. The current knowledge learning paradigm of LLMs is mainly based on learning from examples, in which LLMs learn the internal rule implicitly from a certain number of supervised examples. However, this learning paradigm may not well learn those complicated rules, especially when the training examples are limited. We are inspired that humans can learn the new tasks or knowledge in another way by learning from rules. That is, humans can learn new tasks or grasps new knowledge quickly and generalize well given only a detailed rule and a few optional examples. Therefore, in this paper, we aim to explore the feasibility of this new learning paradigm, which targets on encoding rule-based knowledge into LLMs. We further propose rule distillation, which first uses the strong in-context abilities of LLMs to extract the knowledge from the textu",
    "path": "papers/23/11/2311.08883.json",
    "total_tokens": 768,
    "translated_title": "可实现大型语言模型从规则中学习",
    "translated_abstract": "大型语言模型（LLMs）在完成各种真实世界任务时表现出色。目前LLMs的知识学习范式主要基于从例子中学习，其中LLMs从一定数量的监督示例中隐式学习内部规则。然而，当训练示例有限时，这种学习范式可能无法很好地学习那些复杂的规则。我们受到启发，人类可以通过从规则中学习来另一种方式学习新任务或知识。因此，在本文中，我们旨在探索这种新的学习范式的可行性，即将基于规则的知识编码到LLMs中。我们进一步提出了规则提取，首先利用LLMs的强大上下文能力来从文本中提取知识。",
    "tldr": "本文探索了一种新的学习范式，将基于规则的知识编码到大型语言模型中，并提出了规则提取方法。"
}