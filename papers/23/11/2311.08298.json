{
    "title": "A Survey of Confidence Estimation and Calibration in Large Language Models",
    "abstract": "arXiv:2311.08298v2 Announce Type: replace-cross  Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks in various domains. Despite their impressive performance, they can be unreliable due to factual errors in their generations. Assessing their confidence and calibrating them across different tasks can help mitigate risks and enable LLMs to produce better generations. There has been a lot of recent research aiming to address this, but there has been no comprehensive overview to organize it and outline the main lessons learned. The present survey aims to bridge this gap. In particular, we outline the challenges and we summarize recent technical advancements for LLM confidence estimation and calibration. We further discuss their applications and suggest promising directions for future work.",
    "link": "https://arxiv.org/abs/2311.08298",
    "context": "Title: A Survey of Confidence Estimation and Calibration in Large Language Models\nAbstract: arXiv:2311.08298v2 Announce Type: replace-cross  Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks in various domains. Despite their impressive performance, they can be unreliable due to factual errors in their generations. Assessing their confidence and calibrating them across different tasks can help mitigate risks and enable LLMs to produce better generations. There has been a lot of recent research aiming to address this, but there has been no comprehensive overview to organize it and outline the main lessons learned. The present survey aims to bridge this gap. In particular, we outline the challenges and we summarize recent technical advancements for LLM confidence estimation and calibration. We further discuss their applications and suggest promising directions for future work.",
    "path": "papers/23/11/2311.08298.json",
    "total_tokens": 743,
    "translated_title": "大型语言模型中置信度估计与校准的调研",
    "translated_abstract": "大型语言模型（LLMs）在各个领域的各种任务中展现出卓越的性能，但由于生成中的事实错误，它们可能不可靠。评估它们的置信度并在不同任务中进行校准可以帮助减轻风险，使LLMs能够产生更好的生成结果。近期有许多研究致力于解决这个问题，但尚无全面的概述来组织并概述主要的经验教训，本调研旨在弥补这一空白。具体而言，我们概述了挑战，并总结了LLMs置信度估计和校准的最新技术进展。我们进一步讨论了它们的应用，并提出了未来工作的有希望的方向。",
    "tldr": "大型语言模型中置信度估计与校准的调研总结了挑战、技术进展、应用和未来方向。",
    "en_tdlr": "A survey of confidence estimation and calibration in large language models summarizes the challenges, technical advancements, applications, and promising directions for future work."
}