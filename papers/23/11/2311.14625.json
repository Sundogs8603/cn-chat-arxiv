{
    "title": "ARIA: On the Interaction Between Architectures, Initialization and Aggregation Methods for Federated Visual Classification",
    "abstract": "arXiv:2311.14625v2 Announce Type: replace-cross  Abstract: Federated Learning (FL) is a collaborative training paradigm that allows for privacy-preserving learning of cross-institutional models by eliminating the exchange of sensitive data and instead relying on the exchange of model parameters between the clients and a server. Despite individual studies on how client models are aggregated, and, more recently, on the benefits of ImageNet pre-training, there is a lack of understanding of the effect the architecture chosen for the federation has, and of how the aforementioned elements interconnect. To this end, we conduct the first joint ARchitecture-Initialization-Aggregation study and benchmark ARIAs across a range of medical image classification tasks. We find that, contrary to current practices, ARIA elements have to be chosen together to achieve the best possible performance. Our results also shed light on good choices for each element depending on the task, the effect of normalisat",
    "link": "https://arxiv.org/abs/2311.14625",
    "context": "Title: ARIA: On the Interaction Between Architectures, Initialization and Aggregation Methods for Federated Visual Classification\nAbstract: arXiv:2311.14625v2 Announce Type: replace-cross  Abstract: Federated Learning (FL) is a collaborative training paradigm that allows for privacy-preserving learning of cross-institutional models by eliminating the exchange of sensitive data and instead relying on the exchange of model parameters between the clients and a server. Despite individual studies on how client models are aggregated, and, more recently, on the benefits of ImageNet pre-training, there is a lack of understanding of the effect the architecture chosen for the federation has, and of how the aforementioned elements interconnect. To this end, we conduct the first joint ARchitecture-Initialization-Aggregation study and benchmark ARIAs across a range of medical image classification tasks. We find that, contrary to current practices, ARIA elements have to be chosen together to achieve the best possible performance. Our results also shed light on good choices for each element depending on the task, the effect of normalisat",
    "path": "papers/23/11/2311.14625.json",
    "total_tokens": 821,
    "translated_title": "ARIA：关于联邦视觉分类中架构、初始化和聚合方法之间的相互作用",
    "translated_abstract": "联邦学习（FL）是一种协作训练范式，它允许通过消除敏感数据交换并依赖客户端和服务器之间模型参数的交换，实现跨机构模型的隐私保护学习。尽管关于客户端模型如何聚合以及最近对ImageNet预训练的好处进行了独立研究，但对于联邦选择的架构及其如何相互连接的影响缺乏理解。为此，我们开展了首次联合架构-初始化-聚合研究，并在一系列医学图像分类任务中对ARIA进行基准测试。我们发现，与当前做法相反，必须共同选择ARIA元素才能实现最佳性能。我们的结果还揭示了根据任务选择每个元素的良好选择，标准化效果的影响。",
    "tldr": "ARIA元素必须共同选择才能实现最佳性能，揭示了不同任务下每个元素的良好选择和标准化效果的影响。"
}