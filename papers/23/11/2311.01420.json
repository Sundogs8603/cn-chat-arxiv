{
    "title": "Holistic Transfer: Towards Non-Disruptive Fine-Tuning with Partial Target Data. (arXiv:2311.01420v1 [cs.LG])",
    "abstract": "We propose a learning problem involving adapting a pre-trained source model to the target domain for classifying all classes that appeared in the source data, using target data that covers only a partial label space. This problem is practical, as it is unrealistic for the target end-users to collect data for all classes prior to adaptation. However, it has received limited attention in the literature. To shed light on this issue, we construct benchmark datasets and conduct extensive experiments to uncover the inherent challenges. We found a dilemma -- on the one hand, adapting to the new target domain is important to claim better performance; on the other hand, we observe that preserving the classification accuracy of classes missing in the target adaptation data is highly challenging, let alone improving them. To tackle this, we identify two key directions: 1) disentangling domain gradients from classification gradients, and 2) preserving class relationships. We present several effect",
    "link": "http://arxiv.org/abs/2311.01420",
    "context": "Title: Holistic Transfer: Towards Non-Disruptive Fine-Tuning with Partial Target Data. (arXiv:2311.01420v1 [cs.LG])\nAbstract: We propose a learning problem involving adapting a pre-trained source model to the target domain for classifying all classes that appeared in the source data, using target data that covers only a partial label space. This problem is practical, as it is unrealistic for the target end-users to collect data for all classes prior to adaptation. However, it has received limited attention in the literature. To shed light on this issue, we construct benchmark datasets and conduct extensive experiments to uncover the inherent challenges. We found a dilemma -- on the one hand, adapting to the new target domain is important to claim better performance; on the other hand, we observe that preserving the classification accuracy of classes missing in the target adaptation data is highly challenging, let alone improving them. To tackle this, we identify two key directions: 1) disentangling domain gradients from classification gradients, and 2) preserving class relationships. We present several effect",
    "path": "papers/23/11/2311.01420.json",
    "total_tokens": 982,
    "translated_title": "全面迁移：向具有部分目标数据的非中断微调迈进",
    "translated_abstract": "我们提出了一个学习问题，涉及将预先训练的源模型适应到目标领域，以对源数据中出现的所有类进行分类，使用仅覆盖部分标签空间的目标数据。这个问题是实际的，因为目标终端用户在适应之前收集所有类别的数据是不现实的。然而，在现有文献中，对此问题的关注有限。为了揭示这个问题，我们构建了基准数据集，并进行了大量实验证明其固有的挑战。我们发现一个困境 - 一方面，适应到新的目标领域对于获得更好的性能至关重要；另一方面，我们观察到，在目标适应数据中缺失的类别保持分类准确性是非常具有挑战性的，更不用说对其进行改进了。为了解决这个问题，我们确定了两个关键方向：1）将领域梯度与分类梯度分离，并2）保持类别关系。我们提出了几个有效的方法",
    "tldr": "这篇论文提出了一个学习问题，即如何将预先训练的源模型适应到目标领域，使用仅覆盖部分标签空间的目标数据进行分类。论文通过构建基准数据集，并进行大量实验证明，揭示了这个问题的挑战。为了解决这一问题，论文提出了两个关键方向：分离领域梯度和分类梯度，并保持类别关系。",
    "en_tdlr": "This paper introduces a learning problem of adapting a pre-trained source model to a target domain using partial target data for classification. Through benchmark datasets and extensive experiments, the paper reveals the challenges of this problem and proposes two key directions: separating domain gradients from classification gradients and preserving class relationships."
}