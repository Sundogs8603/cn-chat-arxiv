{
    "title": "Designing monitoring strategies for deployed machine learning algorithms: navigating performativity through a causal lens",
    "abstract": "arXiv:2311.11463v2 Announce Type: replace  Abstract: After a machine learning (ML)-based system is deployed, monitoring its performance is important to ensure the safety and effectiveness of the algorithm over time. When an ML algorithm interacts with its environment, the algorithm can affect the data-generating mechanism and be a major source of bias when evaluating its standalone performance, an issue known as performativity. Although prior work has shown how to validate models in the presence of performativity using causal inference techniques, there has been little work on how to monitor models in the presence of performativity. Unlike the setting of model validation, there is much less agreement on which performance metrics to monitor. Different monitoring criteria impact how interpretable the resulting test statistic is, what assumptions are needed for identifiability, and the speed of detection. When this choice is further coupled with the decision to use observational versus in",
    "link": "https://arxiv.org/abs/2311.11463",
    "context": "Title: Designing monitoring strategies for deployed machine learning algorithms: navigating performativity through a causal lens\nAbstract: arXiv:2311.11463v2 Announce Type: replace  Abstract: After a machine learning (ML)-based system is deployed, monitoring its performance is important to ensure the safety and effectiveness of the algorithm over time. When an ML algorithm interacts with its environment, the algorithm can affect the data-generating mechanism and be a major source of bias when evaluating its standalone performance, an issue known as performativity. Although prior work has shown how to validate models in the presence of performativity using causal inference techniques, there has been little work on how to monitor models in the presence of performativity. Unlike the setting of model validation, there is much less agreement on which performance metrics to monitor. Different monitoring criteria impact how interpretable the resulting test statistic is, what assumptions are needed for identifiability, and the speed of detection. When this choice is further coupled with the decision to use observational versus in",
    "path": "papers/23/11/2311.11463.json",
    "total_tokens": 798,
    "translated_title": "设计部署的机器学习算法监控策略：通过因果镜头导航有效性",
    "translated_abstract": "机器学习(ML)系统部署后，监控其性能对于确保算法长期安全有效至关重要。当ML算法与其环境互动时，算法可能影响数据生成机制，并在评估其独立性能时成为主要偏见源，这一问题被称为有效性问题。先前的工作已经展示了如何使用因果推断技术在有效性存在的情况下验证模型，但在有效性存在的环境中监控模型的工作却很少。与模型验证设置不同，对于要监控哪些性能指标没有很多一致性。不同的监控标准会影响结果的可解释性，可辨识性所需的假设，以及检测速度。当这一选择进一步与使用观察性与不平等性的决定相结合时",
    "tldr": "监控部署的机器学习算法的性能是重要的，该研究探讨了通过因果镜头导航解决有效性问题的方法。"
}