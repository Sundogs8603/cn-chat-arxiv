{
    "title": "Large Language Model as a Policy Teacher for Training Reinforcement Learning Agents. (arXiv:2311.13373v4 [cs.AI] UPDATED)",
    "abstract": "Recent studies have uncovered the potential of Large Language Models (LLMs) in addressing complex sequential decision-making tasks through the provision of high-level instructions. However, LLM-based agents lack specialization in tackling specific target problems, particularly in real-time dynamic environments. Additionally, deploying an LLM-based agent in practical scenarios can be both costly and time-consuming. On the other hand, reinforcement learning (RL) approaches train agents that specialize in the target task but often suffer from low sampling efficiency and high exploration costs. In this paper, we introduce a novel framework that addresses these challenges by training a smaller, specialized student RL agent using instructions from an LLM-based teacher agent. By incorporating the guidance from the teacher agent, the student agent can distill the prior knowledge of the LLM into its own model. Consequently, the student agent can be trained with significantly less data. Moreover",
    "link": "http://arxiv.org/abs/2311.13373",
    "context": "Title: Large Language Model as a Policy Teacher for Training Reinforcement Learning Agents. (arXiv:2311.13373v4 [cs.AI] UPDATED)\nAbstract: Recent studies have uncovered the potential of Large Language Models (LLMs) in addressing complex sequential decision-making tasks through the provision of high-level instructions. However, LLM-based agents lack specialization in tackling specific target problems, particularly in real-time dynamic environments. Additionally, deploying an LLM-based agent in practical scenarios can be both costly and time-consuming. On the other hand, reinforcement learning (RL) approaches train agents that specialize in the target task but often suffer from low sampling efficiency and high exploration costs. In this paper, we introduce a novel framework that addresses these challenges by training a smaller, specialized student RL agent using instructions from an LLM-based teacher agent. By incorporating the guidance from the teacher agent, the student agent can distill the prior knowledge of the LLM into its own model. Consequently, the student agent can be trained with significantly less data. Moreover",
    "path": "papers/23/11/2311.13373.json",
    "total_tokens": 919,
    "translated_title": "将大规模语言模型作为策略教师来训练强化学习代理",
    "translated_abstract": "最近的研究揭示了大规模语言模型（LLM）在通过提供高级指导来解决复杂的顺序决策任务方面的潜力。然而，基于LLM的代理缺乏专门化处理特定目标问题的能力，尤其是在实时动态环境中。此外，将基于LLM的代理部署到实际场景中可能既昂贵又耗时。另一方面，强化学习（RL）方法训练专门化于目标任务的代理，但往往遭受低采样效率和高探索成本的困扰。本文介绍了一个新颖的框架，通过使用LLM教师代理的指导来训练一个较小、专门化的学生RL代理来解决这些挑战。通过将教师代理的先前知识融入学生代理中，学生代理能够凝聚LLM的知识到自己的模型中。因此，学生代理可以用更少的数据进行训练。此外，",
    "tldr": "本论文介绍了一种用大规模语言模型作为教师来训练强化学习代理的框架，通过教师代理的指导，学生代理能够以更高效的方式训练，并且能够专门化于特定目标任务。"
}