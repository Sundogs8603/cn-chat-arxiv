{
    "title": "Fusion-Eval: Integrating Evaluators with LLMs",
    "abstract": "arXiv:2311.09204v2 Announce Type: replace-cross  Abstract: Evaluating natural language systems poses significant challenges, particularly in the realms of natural language understanding and high-level reasoning. In this paper, we introduce \"Fusion-Eval\", an innovative approach that leverages Large Language Models (LLMs) to integrate insights from various assistant evaluators. Each of these evaluators specializes in assessing distinct aspects of responses. This unique strategy enables Fusion-Eval to function effectively across a diverse range of tasks and criteria, enhancing the effectiveness of existing evaluation methods. Fusion-Eval achieves a 0.962 system-level Kendall-Tau correlation with humans on SummEval and a 0.744 turn-level Spearman correlation on TopicalChat, which is significantly higher than baseline methods. These results highlight Fusion-Eval's significant potential in the realm of natural language system evaluation.",
    "link": "https://arxiv.org/abs/2311.09204",
    "context": "Title: Fusion-Eval: Integrating Evaluators with LLMs\nAbstract: arXiv:2311.09204v2 Announce Type: replace-cross  Abstract: Evaluating natural language systems poses significant challenges, particularly in the realms of natural language understanding and high-level reasoning. In this paper, we introduce \"Fusion-Eval\", an innovative approach that leverages Large Language Models (LLMs) to integrate insights from various assistant evaluators. Each of these evaluators specializes in assessing distinct aspects of responses. This unique strategy enables Fusion-Eval to function effectively across a diverse range of tasks and criteria, enhancing the effectiveness of existing evaluation methods. Fusion-Eval achieves a 0.962 system-level Kendall-Tau correlation with humans on SummEval and a 0.744 turn-level Spearman correlation on TopicalChat, which is significantly higher than baseline methods. These results highlight Fusion-Eval's significant potential in the realm of natural language system evaluation.",
    "path": "papers/23/11/2311.09204.json",
    "total_tokens": 773,
    "translated_title": "Fusion-Eval: 将评估器与LLMs集成",
    "translated_abstract": "自然语言系统的评估在自然语言理解和高级推理领域面临着重大挑战。本文介绍了一种名为“Fusion-Eval”的创新方法，利用大型语言模型（LLMs）来整合来自各种辅助评估器的见解。每个评估器专门负责评估响应的不同方面。这种独特策略使得Fusion-Eval能够有效地跨越各种任务和标准，增强现有评估方法的效果。在SummEval上，Fusion-Eval与人类之间的系统级Kendall-Tau相关性达到0.962，在TopicalChat上的轮级Spearman相关性达到0.744，远高于基准方法。这些结果突显了Fusion-Eval在自然语言系统评估领域的巨大潜力。",
    "tldr": "Fusion-Eval是一种创新方法，利用LLMs整合不同辅助评估器的见解，极大提升自然语言系统评估的有效性。",
    "en_tdlr": "Fusion-Eval is an innovative approach that leverages LLMs to integrate insights from various assistant evaluators, significantly enhancing the effectiveness of natural language system evaluation."
}