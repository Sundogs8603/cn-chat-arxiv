{
    "title": "Fair Text-to-Image Diffusion via Fair Mapping",
    "abstract": "arXiv:2311.17695v2 Announce Type: replace-cross  Abstract: In this paper, we address the limitations of existing text-to-image diffusion models in generating demographically fair results when given human-related descriptions. These models often struggle to disentangle the target language context from sociocultural biases, resulting in biased image generation. To overcome this challenge, we propose Fair Mapping, a flexible, model-agnostic, and lightweight approach that modifies a pre-trained text-to-image diffusion model by controlling the prompt to achieve fair image generation. One key advantage of our approach is its high efficiency. It only requires updating an additional linear network with few parameters at a low computational cost. By developing a linear network that maps conditioning embeddings into a debiased space, we enable the generation of relatively balanced demographic results based on the specified text condition. With comprehensive experiments on face image generation, ",
    "link": "https://arxiv.org/abs/2311.17695",
    "context": "Title: Fair Text-to-Image Diffusion via Fair Mapping\nAbstract: arXiv:2311.17695v2 Announce Type: replace-cross  Abstract: In this paper, we address the limitations of existing text-to-image diffusion models in generating demographically fair results when given human-related descriptions. These models often struggle to disentangle the target language context from sociocultural biases, resulting in biased image generation. To overcome this challenge, we propose Fair Mapping, a flexible, model-agnostic, and lightweight approach that modifies a pre-trained text-to-image diffusion model by controlling the prompt to achieve fair image generation. One key advantage of our approach is its high efficiency. It only requires updating an additional linear network with few parameters at a low computational cost. By developing a linear network that maps conditioning embeddings into a debiased space, we enable the generation of relatively balanced demographic results based on the specified text condition. With comprehensive experiments on face image generation, ",
    "path": "papers/23/11/2311.17695.json",
    "total_tokens": 796,
    "translated_title": "通过公平映射实现公平文本到图像扩散",
    "translated_abstract": "在本文中，我们解决了现有文本到图像扩散模型在生成与人类相关描述时出现人口统计上公平结果的局限性。这些模型经常难以将目标语言环境与社会文化偏见分离开，导致生成偏见图像。为了克服这一挑战，我们提出了一种灵活、与模型无关且轻量级的方法Fair Mapping，通过控制提示来修改预训练的文本到图像扩散模型，从而实现公平图像生成。我们方法的一个关键优势在于其高效性。它只需要以低计算成本更新少量参数的额外线性网络。通过开发一个将条件嵌入映射到去偏空间的线性网络，我们能够根据指定的文本条件生成相对平衡的人口统计结果。",
    "tldr": "本文提出了一种通过Fair Mapping控制模型提示来修改文本到图像扩散模型，实现公平图像生成的方法，具有高效性和能够生成相对平衡人口统计结果的优势。",
    "en_tdlr": "This paper introduces a method to modify text-to-image diffusion models using Fair Mapping to achieve fair image generation by controlling prompts, which demonstrates high efficiency and the ability to generate relatively balanced demographic results."
}