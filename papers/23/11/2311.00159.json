{
    "title": "Longer Fixations, More Computation: Gaze-Guided Recurrent Neural Networks. (arXiv:2311.00159v1 [cs.CL])",
    "abstract": "Humans read texts at a varying pace, while machine learning models treat each token in the same way in terms of a computational process. Therefore, we ask, does it help to make models act more like humans? In this paper, we convert this intuition into a set of novel models with fixation-guided parallel RNNs or layers and conduct various experiments on language modeling and sentiment analysis tasks to test their effectiveness, thus providing empirical validation for this intuition. Our proposed models achieve good performance on the language modeling task, considerably surpassing the baseline model. In addition, we find that, interestingly, the fixation duration predicted by neural networks bears some resemblance to humans' fixation. Without any explicit guidance, the model makes similar choices to humans. We also investigate the reasons for the differences between them, which explain why \"model fixations\" are often more suitable than human fixations, when used to guide language models.",
    "link": "http://arxiv.org/abs/2311.00159",
    "context": "Title: Longer Fixations, More Computation: Gaze-Guided Recurrent Neural Networks. (arXiv:2311.00159v1 [cs.CL])\nAbstract: Humans read texts at a varying pace, while machine learning models treat each token in the same way in terms of a computational process. Therefore, we ask, does it help to make models act more like humans? In this paper, we convert this intuition into a set of novel models with fixation-guided parallel RNNs or layers and conduct various experiments on language modeling and sentiment analysis tasks to test their effectiveness, thus providing empirical validation for this intuition. Our proposed models achieve good performance on the language modeling task, considerably surpassing the baseline model. In addition, we find that, interestingly, the fixation duration predicted by neural networks bears some resemblance to humans' fixation. Without any explicit guidance, the model makes similar choices to humans. We also investigate the reasons for the differences between them, which explain why \"model fixations\" are often more suitable than human fixations, when used to guide language models.",
    "path": "papers/23/11/2311.00159.json",
    "total_tokens": 837,
    "translated_title": "Fixations for Longer Time, More Computation: Gaze-Guided Recurrent Neural Networks",
    "translated_abstract": "人类在阅读文本时的速度是不一样的，然而机器学习模型在计算过程中对于每个标记都是以相同的方式处理的。因此，我们问，让模型更像人类是否有助于提升性能？在本文中，我们将这个直觉转化为一组新颖的模型，通过注视导向的并行RNN或层来进行实验，以验证它们在语言建模和情感分析任务中的有效性，从而提供经验验证结果。我们提出的模型在语言建模任务上表现出了很好的性能，明显超过了基线模型。此外，我们发现，有趣的是，神经网络预测的注视持续时间与人类的注视有一定的相似之处。在没有任何明确指导的情况下，模型往往会做出与人类相似的选择。我们还调查了它们之间差异的原因，解释了为什么“模型注视”在引导语言模型时常常比人类注视更合适。",
    "tldr": "本文研究了通过注视来指导语言模型的方法。实验结果表明，模型表现出了类似于人类的注视行为，并且通过注视来引导语言模型，取得了好的性能。"
}