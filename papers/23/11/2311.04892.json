{
    "title": "Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs. (arXiv:2311.04892v2 [cs.CL] UPDATED)",
    "abstract": "Recent works have showcased the ability of LLMs to embody diverse personas in their responses, exemplified by prompts like 'You are Yoda. Explain the Theory of Relativity.' While this ability allows personalization of LLMs and enables human behavior simulation, its effect on LLMs' capabilities remains unclear. To fill this gap, we present the first extensive study of the unintended side-effects of persona assignment on the ability of LLMs to perform basic reasoning tasks. Our study covers 24 reasoning datasets, 4 LLMs, and 19 diverse personas (e.g. an Asian person) spanning 5 socio-demographic groups. Our experiments unveil that LLMs harbor deep rooted bias against various socio-demographics underneath a veneer of fairness. While they overtly reject stereotypes when explicitly asked ('Are Black people less skilled at mathematics?'), they manifest stereotypical and erroneous presumptions when asked to answer questions while adopting a persona. These can be observed as abstentions in res",
    "link": "http://arxiv.org/abs/2311.04892",
    "context": "Title: Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs. (arXiv:2311.04892v2 [cs.CL] UPDATED)\nAbstract: Recent works have showcased the ability of LLMs to embody diverse personas in their responses, exemplified by prompts like 'You are Yoda. Explain the Theory of Relativity.' While this ability allows personalization of LLMs and enables human behavior simulation, its effect on LLMs' capabilities remains unclear. To fill this gap, we present the first extensive study of the unintended side-effects of persona assignment on the ability of LLMs to perform basic reasoning tasks. Our study covers 24 reasoning datasets, 4 LLMs, and 19 diverse personas (e.g. an Asian person) spanning 5 socio-demographic groups. Our experiments unveil that LLMs harbor deep rooted bias against various socio-demographics underneath a veneer of fairness. While they overtly reject stereotypes when explicitly asked ('Are Black people less skilled at mathematics?'), they manifest stereotypical and erroneous presumptions when asked to answer questions while adopting a persona. These can be observed as abstentions in res",
    "path": "papers/23/11/2311.04892.json",
    "total_tokens": 988,
    "translated_title": "偏见深入：Persona分配的LLMs中的隐式推理偏见",
    "translated_abstract": "近期的研究展示了LLMs具备在其回答中体现不同角色的能力，例如通过“你是Yoda。解释相对论。”这样的提示。虽然这种能力允许LLMs个性化，并实现人类行为模拟，但其对LLMs能力的影响仍不清楚。为了填补这一空白，我们首次对Persona分配对LLMs执行基本推理任务能力的意外副作用进行了广泛研究。我们的研究涵盖了24个推理数据集、4个LLMs和19个不同的角色（如亚洲人），跨越了5个社会人口群体。我们的实验揭示了在公平的幌子下，LLMs中存在根深蒂固的偏见。虽然当明确要求时它们公然拒绝刻板印象（例如“黑人在数学上是否不擅长？”），但当他们被要求在扮演特定角色的情况下回答问题时，它们表现出刻板印象和错误的假设。这些可以观察到的行为表现为推理结果的弃权。",
    "tldr": "这项研究首次广泛研究了Persona分配对LLMs执行基本推理任务能力的意外副作用。实验证明，LLMs虽然在明确要求时拒绝刻板印象，但在扮演特定角色时会表现出刻板印象和错误的假设。",
    "en_tdlr": "This study presents the first extensive research on the unintended side-effects of persona assignment on the ability of LLMs to perform basic reasoning tasks. The experiments reveal that LLMs overtly reject stereotypes when explicitly asked, but manifest stereotypical and erroneous presumptions when asked to answer questions while adopting a persona."
}