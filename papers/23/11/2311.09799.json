{
    "title": "How Far Can We Extract Diverse Perspectives from Large Language Models?",
    "abstract": "arXiv:2311.09799v2 Announce Type: replace  Abstract: Collecting diverse human opinions is costly and challenging. This leads to a recent trend in collaborative efforts between humans and Large Language Models (LLMs) for generating diverse data, offering potential scalable and efficient solutions. However, the extent of LLMs' capability to generate diverse perspectives on subjective topics remains an unexplored question. In this study, we investigate LLMs' capacity for generating diverse perspectives and rationales on subjective topics, such as social norms and argumentative texts. We formulate a new problem of maximum diversity extraction from LLMs. Motivated by how humans develop their opinions through their values, we propose a criteria-based prompting technique to ground diverse opinions. To see how far we can extract diverse perspectives from LLMs, or called diversity coverage, we employ a step-by-step recall prompting for generating more outputs from the model in an iterative mann",
    "link": "https://arxiv.org/abs/2311.09799",
    "context": "Title: How Far Can We Extract Diverse Perspectives from Large Language Models?\nAbstract: arXiv:2311.09799v2 Announce Type: replace  Abstract: Collecting diverse human opinions is costly and challenging. This leads to a recent trend in collaborative efforts between humans and Large Language Models (LLMs) for generating diverse data, offering potential scalable and efficient solutions. However, the extent of LLMs' capability to generate diverse perspectives on subjective topics remains an unexplored question. In this study, we investigate LLMs' capacity for generating diverse perspectives and rationales on subjective topics, such as social norms and argumentative texts. We formulate a new problem of maximum diversity extraction from LLMs. Motivated by how humans develop their opinions through their values, we propose a criteria-based prompting technique to ground diverse opinions. To see how far we can extract diverse perspectives from LLMs, or called diversity coverage, we employ a step-by-step recall prompting for generating more outputs from the model in an iterative mann",
    "path": "papers/23/11/2311.09799.json",
    "total_tokens": 846,
    "translated_title": "我们能从大型语言模型中提取多元化观点到何种程度？",
    "translated_abstract": "收集多样化的人类观点成本高且具有挑战性。最近的合作努力趋势表明，人类和大型语言模型（LLMs）之间进行合作为生成多样化数据提供了潜在可扩展和高效的解决方案。然而，关于LLMs在主观话题上生成多元化观点的能力程度仍是一个未被探讨的问题。本研究探讨了LLMs在生成多元化观点和理由（例如社会规范和辩论文本）方面的能力。我们提出了从LLMs中提取最大多样性信息的新问题。受人类通过其价值观发展观点的启发，我们提出了一个基于标准的提示技术来确立多样化观点。为了了解我们能从LLMs中提取多元化观点到何种程度，或者称之为多样性覆盖率，我们采用了逐步回忆提示的方法，以在迭代方式下从模型中生成更多输出。",
    "tldr": "本研究探讨了LLMs在生成多元化观点和理由方面的能力，并提出了从LLMs中最大程度提取多样性观点的新问题。"
}