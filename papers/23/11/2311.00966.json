{
    "title": "Invariant-Feature Subspace Recovery: A New Class of Provable Domain Generalization Algorithms. (arXiv:2311.00966v1 [cs.LG])",
    "abstract": "Domain generalization asks for models trained over a set of training environments to generalize well in unseen test environments. Recently, a series of algorithms such as Invariant Risk Minimization (IRM) have been proposed for domain generalization. However, Rosenfeld et al. (2021) shows that in a simple linear data model, even if non-convexity issues are ignored, IRM and its extensions cannot generalize to unseen environments with less than $d_s+1$ training environments, where $d_s$ is the dimension of the spurious-feature subspace. In this work, we propose Invariant-feature Subspace Recovery (ISR): a new class of algorithms to achieve provable domain generalization across the settings of classification and regression problems. First, in the binary classification setup of Rosenfeld et al. (2021), we show that our first algorithm, ISR-Mean, can identify the subspace spanned by invariant features from the first-order moments of the class-conditional distributions, and achieve provable ",
    "link": "http://arxiv.org/abs/2311.00966",
    "context": "Title: Invariant-Feature Subspace Recovery: A New Class of Provable Domain Generalization Algorithms. (arXiv:2311.00966v1 [cs.LG])\nAbstract: Domain generalization asks for models trained over a set of training environments to generalize well in unseen test environments. Recently, a series of algorithms such as Invariant Risk Minimization (IRM) have been proposed for domain generalization. However, Rosenfeld et al. (2021) shows that in a simple linear data model, even if non-convexity issues are ignored, IRM and its extensions cannot generalize to unseen environments with less than $d_s+1$ training environments, where $d_s$ is the dimension of the spurious-feature subspace. In this work, we propose Invariant-feature Subspace Recovery (ISR): a new class of algorithms to achieve provable domain generalization across the settings of classification and regression problems. First, in the binary classification setup of Rosenfeld et al. (2021), we show that our first algorithm, ISR-Mean, can identify the subspace spanned by invariant features from the first-order moments of the class-conditional distributions, and achieve provable ",
    "path": "papers/23/11/2311.00966.json",
    "total_tokens": 902,
    "translated_title": "不变特征子空间恢复：一类新的可证明的领域泛化算法",
    "translated_abstract": "领域泛化要求在一组训练环境中训练的模型能够在未知的测试环境中良好地泛化。最近，一系列算法，如不变风险最小化（IRM），已被提出用于领域泛化。然而，Rosenfeld等人（2021）表明，在一个简单的线性数据模型中，即使忽略了非凸性问题，IRM及其扩展也无法对具有少于$d_s+1$个训练环境的未知环境进行泛化，其中$d_s$是虚假特征子空间的维度。在这项工作中，我们提出了不变特征子空间恢复（ISR）：一类新的算法，用于在分类和回归问题设置中实现可证明的领域泛化。首先，在Rosenfeld等人（2021）的二分类设置中，我们展示了我们的第一个算法ISR-Mean，它可以通过类条件分布的一阶矩来识别不变特征所张成的子空间，并实现可证明的泛化。",
    "tldr": "ISR是一种新型的可证明的领域泛化算法，它可以通过类条件分布的一阶矩来识别不变特征所张成的子空间。"
}