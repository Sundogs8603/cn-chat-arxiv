{
    "title": "ITEm: Unsupervised Image-Text Embedding Learning for eCommerce",
    "abstract": "arXiv:2311.02084v2 Announce Type: replace-cross  Abstract: Product embedding serves as a cornerstone for a wide range of applications in eCommerce. The product embedding learned from multiple modalities shows significant improvement over that from a single modality, since different modalities provide complementary information. However, some modalities are more informatively dominant than others. How to teach a model to learn embedding from different modalities without neglecting information from the less dominant modality is challenging. We present an image-text embedding model (ITEm), an unsupervised learning method that is designed to better attend to image and text modalities. We extend BERT by (1) learning an embedding from text and image without knowing the regions of interest; (2) training a global representation to predict masked words and to construct masked image patches without their individual representations. We evaluate the pre-trained ITEm on two tasks: the search for ext",
    "link": "https://arxiv.org/abs/2311.02084",
    "context": "Title: ITEm: Unsupervised Image-Text Embedding Learning for eCommerce\nAbstract: arXiv:2311.02084v2 Announce Type: replace-cross  Abstract: Product embedding serves as a cornerstone for a wide range of applications in eCommerce. The product embedding learned from multiple modalities shows significant improvement over that from a single modality, since different modalities provide complementary information. However, some modalities are more informatively dominant than others. How to teach a model to learn embedding from different modalities without neglecting information from the less dominant modality is challenging. We present an image-text embedding model (ITEm), an unsupervised learning method that is designed to better attend to image and text modalities. We extend BERT by (1) learning an embedding from text and image without knowing the regions of interest; (2) training a global representation to predict masked words and to construct masked image patches without their individual representations. We evaluate the pre-trained ITEm on two tasks: the search for ext",
    "path": "papers/23/11/2311.02084.json",
    "total_tokens": 846,
    "translated_title": "ITEm：面向电子商务的无监督图片文本嵌入学习",
    "translated_abstract": "产品嵌入是电子商务中广泛应用的基石。通过从多种模态学习的产品嵌入显示出明显的改进，因为不同的模态提供了互补信息。然而，一些模态比其他模态更具信息优势。如何教导模型从不同模态学习嵌入而不忽视较不显著模态的信息是具有挑战性的。我们提出了一个图片文本嵌入模型（ITEm），这是一种设计用来更好地关注图片和文本模态的无监督学习方法。我们通过（1）学习文本和图片的嵌入而不知道感兴趣的区域；（2）训练一个全局表示来预测掩码单词并构建掩码图像补丁而不对它们的单独表示进行过程来扩展BERT。我们在两个任务上评估了预训练的ITEm：寻找扩展。",
    "tldr": "ITEm是面向电子商务的无监督学习模型，通过学习文本和图片的嵌入来更好地关注不同模态，扩展了BERT，并在两个任务上取得了良好的表现。"
}