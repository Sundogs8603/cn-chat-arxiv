{
    "title": "What Makes for Good Visual Instructions? Synthesizing Complex Visual Reasoning Instructions for Visual Instruction Tuning. (arXiv:2311.01487v1 [cs.CV])",
    "abstract": "Visual instruction tuning is an essential approach to improving the zero-shot generalization capability of Multi-modal Large Language Models (MLLMs). A surge of visual instruction datasets with various focuses and characteristics have been proposed recently, enabling MLLMs to achieve surprising results on evaluation benchmarks. To develop more capable MLLMs, in this paper, we aim to investigate a more fundamental question: ``what makes for good visual instructions?''. By conducting a comprehensive empirical study, we find that instructions focused on complex visual reasoning tasks are particularly effective in improving the performance of MLLMs on evaluation benchmarks. Building upon this finding, we design a systematic approach to automatically creating high-quality complex visual reasoning instructions. Our approach employs a synthesis-complication-reformulation paradigm, leveraging multiple stages to gradually increase the complexity of the instructions while guaranteeing quality. B",
    "link": "http://arxiv.org/abs/2311.01487",
    "context": "Title: What Makes for Good Visual Instructions? Synthesizing Complex Visual Reasoning Instructions for Visual Instruction Tuning. (arXiv:2311.01487v1 [cs.CV])\nAbstract: Visual instruction tuning is an essential approach to improving the zero-shot generalization capability of Multi-modal Large Language Models (MLLMs). A surge of visual instruction datasets with various focuses and characteristics have been proposed recently, enabling MLLMs to achieve surprising results on evaluation benchmarks. To develop more capable MLLMs, in this paper, we aim to investigate a more fundamental question: ``what makes for good visual instructions?''. By conducting a comprehensive empirical study, we find that instructions focused on complex visual reasoning tasks are particularly effective in improving the performance of MLLMs on evaluation benchmarks. Building upon this finding, we design a systematic approach to automatically creating high-quality complex visual reasoning instructions. Our approach employs a synthesis-complication-reformulation paradigm, leveraging multiple stages to gradually increase the complexity of the instructions while guaranteeing quality. B",
    "path": "papers/23/11/2311.01487.json",
    "total_tokens": 872,
    "translated_title": "优秀的视觉指导有什么特点？综合复杂的视觉推理指令用于视觉指导调整",
    "translated_abstract": "视觉指导调整是提高多模式大型语言模型（MLLMs）的零样本泛化能力的重要方法。最近提出了许多着眼于不同焦点和特征的视觉指导数据集，使得MLLMs在评估基准上取得了令人惊讶的结果。为了开发更强大的MLLMs，本文旨在研究一个更基本的问题：“什么样的视觉指导才是好的？”通过进行全面的实证研究，我们发现侧重于复杂视觉推理任务的指导对于改善MLLMs在评估基准上的性能特别有效。基于这一发现，我们设计了一个系统的方法来自动创建高质量的复杂视觉推理指令。我们的方法采用合成-复杂化-重构的范式，利用多个阶段逐渐增加指令的复杂性，同时保证质量。",
    "tldr": "通过综合复杂的视觉推理任务，可以有效改善多模式大型语言模型在评估基准上的性能。我们提出了一种自动创建高质量复杂视觉推理指令的系统方法。",
    "en_tdlr": "By synthesizing complex visual reasoning tasks, the performance of Multi-modal Large Language Models (MLLMs) on evaluation benchmarks can be improved effectively. We propose a systematic approach to automatically creating high-quality complex visual reasoning instructions."
}