{
    "title": "Can Large Language Models Capture Public Opinion about Global Warming? An Empirical Assessment of Algorithmic Fidelity and Bias. (arXiv:2311.00217v1 [cs.AI])",
    "abstract": "Large language models (LLMs) have demonstrated their potential in social science research by emulating human perceptions and behaviors, a concept referred to as algorithmic fidelity. This study assesses the algorithmic fidelity and bias of LLMs by utilizing two nationally representative climate change surveys. The LLMs were conditioned on demographics and/or psychological covariates to simulate survey responses. The findings indicate that LLMs can effectively capture presidential voting behaviors but encounter challenges in accurately representing global warming perspectives when relevant covariates are not included. GPT-4 exhibits improved performance when conditioned on both demographics and covariates. However, disparities emerge in LLM estimations of the views of certain groups, with LLMs tending to underestimate worry about global warming among Black Americans. While highlighting the potential of LLMs to aid social science research, these results underscore the importance of metic",
    "link": "http://arxiv.org/abs/2311.00217",
    "context": "Title: Can Large Language Models Capture Public Opinion about Global Warming? An Empirical Assessment of Algorithmic Fidelity and Bias. (arXiv:2311.00217v1 [cs.AI])\nAbstract: Large language models (LLMs) have demonstrated their potential in social science research by emulating human perceptions and behaviors, a concept referred to as algorithmic fidelity. This study assesses the algorithmic fidelity and bias of LLMs by utilizing two nationally representative climate change surveys. The LLMs were conditioned on demographics and/or psychological covariates to simulate survey responses. The findings indicate that LLMs can effectively capture presidential voting behaviors but encounter challenges in accurately representing global warming perspectives when relevant covariates are not included. GPT-4 exhibits improved performance when conditioned on both demographics and covariates. However, disparities emerge in LLM estimations of the views of certain groups, with LLMs tending to underestimate worry about global warming among Black Americans. While highlighting the potential of LLMs to aid social science research, these results underscore the importance of metic",
    "path": "papers/23/11/2311.00217.json",
    "total_tokens": 1049,
    "translated_title": "能否大型语言模型捕捉全球变暖的公众意见？一项关于算法逼真性和偏见的实证评估",
    "translated_abstract": "大型语言模型（LLMs）通过模拟人类的感知和行为，展示了它们在社会科学研究中的潜力，这被称为算法逼真性。本研究通过利用两个代表性的气候变化调查评估LLMs的算法逼真性和偏见。LLMs被条件化为基于人口统计学和/或心理协变量来模拟调查回答。研究结果表明，当相关协变量没有包含在内时，LLMs可以有效捕捉总统投票行为，但在准确表示全球变暖观点方面存在挑战。当LLMs被人口统计学和协变量同时条件化时，GPT-4表现出更好的性能。然而，LLMs对特定群体的观点估计存在差异，LLMs倾向于低估非洲裔美国人对全球变暖的担忧。虽然突出了LLMs在社会科学研究中的潜力，但这些结果强调了精确性的重要性。",
    "tldr": "本研究评估了大型语言模型（LLMs）的算法逼真性和偏见，并发现LLMs可以有效捕捉总统投票行为，但在准确表示全球变暖观点方面存在挑战。同时，LLMs对某些群体的观点估计存在偏差，特别是对非洲裔美国人对全球变暖的担忧低估。这些结果突出了LLMs在社会科学研究中的潜力，并强调了准确性的重要性。",
    "en_tdlr": "This study assesses the algorithmic fidelity and bias of large language models (LLMs) and finds that LLMs can effectively capture presidential voting behaviors but face challenges in accurately representing global warming perspectives. LLMs tend to underestimate worries about global warming among Black Americans. These results highlight the potential of LLMs in social science research and emphasize the importance of accuracy."
}