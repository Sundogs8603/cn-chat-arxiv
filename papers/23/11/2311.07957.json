{
    "title": "Language Models are Better Bug Detector Through Code-Pair Classification. (arXiv:2311.07957v2 [cs.SE] UPDATED)",
    "abstract": "Large language models (LLMs) such as GPT-3.5 and CodeLlama are powerful models for code generation and understanding. Fine-tuning these models comes with a high computational cost and requires a large labeled dataset. Alternatively, in-context learning techniques allow models to learn downstream tasks with only a few examples. Recently, researchers have shown how in-context learning performs well in bug detection and repair. In this paper, we propose code-pair classification task in which both the buggy and non-buggy versions are given to the model, and the model identifies the buggy ones. We evaluate our task in real-world dataset of bug detection and two most powerful LLMs. Our experiments indicate that an LLM can often pick the buggy from the non-buggy version of the code, and the code-pair classification task is much easier compared to be given a snippet and deciding if and where a bug exists.",
    "link": "http://arxiv.org/abs/2311.07957",
    "context": "Title: Language Models are Better Bug Detector Through Code-Pair Classification. (arXiv:2311.07957v2 [cs.SE] UPDATED)\nAbstract: Large language models (LLMs) such as GPT-3.5 and CodeLlama are powerful models for code generation and understanding. Fine-tuning these models comes with a high computational cost and requires a large labeled dataset. Alternatively, in-context learning techniques allow models to learn downstream tasks with only a few examples. Recently, researchers have shown how in-context learning performs well in bug detection and repair. In this paper, we propose code-pair classification task in which both the buggy and non-buggy versions are given to the model, and the model identifies the buggy ones. We evaluate our task in real-world dataset of bug detection and two most powerful LLMs. Our experiments indicate that an LLM can often pick the buggy from the non-buggy version of the code, and the code-pair classification task is much easier compared to be given a snippet and deciding if and where a bug exists.",
    "path": "papers/23/11/2311.07957.json",
    "total_tokens": 862,
    "translated_title": "语言模型通过代码对分类更好地检测漏洞",
    "translated_abstract": "大型语言模型（LLMs）如GPT-3.5和CodeLlama是用于代码生成和理解的强大模型。对这些模型进行微调的计算成本高且需要一个大型标记数据集。与此相反，上下文学习技术使模型能够只使用少量示例来学习下游任务。最近，研究人员展示了上下文学习在漏洞检测和修复方面的良好表现。在本文中，我们提出了代码对分类任务，其中模型同时获取有错误和无错误版本的代码，并标识出有错误的版本。我们在真实世界的漏洞检测数据集和两个最强大的LLMs上评估了我们的任务。实验结果表明，LLM通常可以从代码的非错误版本中选择出错误版本，并且代码对分类任务相比于给出代码片段并决定是否存在错误及其位置要容易得多。",
    "tldr": "本研究提出了一种代码对分类任务，通过给语言模型同时提供有错误和无错误版本的代码，实现更好的漏洞检测。研究结果表明，这个任务相比于给出代码片段并判断是否存在错误及其位置要容易得多。",
    "en_tdlr": "This paper proposes a code-pair classification task for better bug detection, where language models are provided both buggy and non-buggy versions of the code. The results indicate that this task is easier compared to the task of providing code snippets and determining the presence and location of bugs."
}