{
    "title": "Rethinking Decision Transformer via Hierarchical Reinforcement Learning. (arXiv:2311.00267v1 [cs.LG])",
    "abstract": "Decision Transformer (DT) is an innovative algorithm leveraging recent advances of the transformer architecture in reinforcement learning (RL). However, a notable limitation of DT is its reliance on recalling trajectories from datasets, losing the capability to seamlessly stitch sub-optimal trajectories together. In this work we introduce a general sequence modeling framework for studying sequential decision making through the lens of Hierarchical RL. At the time of making decisions, a high-level policy first proposes an ideal prompt for the current state, a low-level policy subsequently generates an action conditioned on the given prompt. We show DT emerges as a special case of this framework with certain choices of high-level and low-level policies, and discuss the potential failure of these choices. Inspired by these observations, we study how to jointly optimize the high-level and low-level policies to enable the stitching ability, which further leads to the development of new offl",
    "link": "http://arxiv.org/abs/2311.00267",
    "context": "Title: Rethinking Decision Transformer via Hierarchical Reinforcement Learning. (arXiv:2311.00267v1 [cs.LG])\nAbstract: Decision Transformer (DT) is an innovative algorithm leveraging recent advances of the transformer architecture in reinforcement learning (RL). However, a notable limitation of DT is its reliance on recalling trajectories from datasets, losing the capability to seamlessly stitch sub-optimal trajectories together. In this work we introduce a general sequence modeling framework for studying sequential decision making through the lens of Hierarchical RL. At the time of making decisions, a high-level policy first proposes an ideal prompt for the current state, a low-level policy subsequently generates an action conditioned on the given prompt. We show DT emerges as a special case of this framework with certain choices of high-level and low-level policies, and discuss the potential failure of these choices. Inspired by these observations, we study how to jointly optimize the high-level and low-level policies to enable the stitching ability, which further leads to the development of new offl",
    "path": "papers/23/11/2311.00267.json",
    "total_tokens": 1017,
    "translated_title": "通过分层强化学习重新思考决策Transformer",
    "translated_abstract": "决策Transformer（DT）是一种利用最近在强化学习中的Transformer架构的创新算法。然而，DT的一个显著局限性是其依赖于从数据集中回忆轨迹的能力，失去了无缝地将次优轨迹拼接在一起的能力。在这项工作中，我们引入了一个用于通过分层强化学习研究序贯决策的通用序列建模框架。在做决策时，高层策略首先为当前状态提出一个理想的提示，低层策略随后在给定的提示条件下生成一个动作。我们展示了DT是这个框架的特例，通过一定的高层和低层策略选择，并讨论了这些选择的潜在失败。受这些观察的启发，我们研究了如何共同优化高层和低层策略以实现拼接能力，进而推动新的离线学习算法的发展。",
    "tldr": "这篇论文通过引入分层强化学习，重新思考了决策Transformer。他们提出了一个通用的序列建模框架，在该框架中，高层策略为当前状态提供理想提示，低层策略在给定提示的条件下生成动作。他们发现决策Transformer是这个框架的一个特例，并研究了如何共同优化高层和低层策略以实现拼接能力，从而推动了新的离线学习算法的发展。",
    "en_tdlr": "This paper rethinks the Decision Transformer through the lens of hierarchical reinforcement learning. They propose a general sequence modeling framework where a high-level policy provides an ideal prompt for the current state, and a low-level policy generates an action based on the given prompt. They show that the Decision Transformer is a special case of this framework and study how to jointly optimize the high-level and low-level policies to enable the stitching ability, leading to the development of new offline learning algorithms."
}