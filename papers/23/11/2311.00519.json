{
    "title": "Retrieval-Based Reconstruction For Time-series Contrastive Learning. (arXiv:2311.00519v1 [cs.LG])",
    "abstract": "The success of self-supervised contrastive learning hinges on identifying positive data pairs that, when pushed together in embedding space, encode useful information for subsequent downstream tasks. However, in time-series, this is challenging because creating positive pairs via augmentations may break the original semantic meaning. We hypothesize that if we can retrieve information from one subsequence to successfully reconstruct another subsequence, then they should form a positive pair. Harnessing this intuition, we introduce our novel approach: REtrieval-BAsed Reconstruction (REBAR) contrastive learning. First, we utilize a convolutional cross-attention architecture to calculate the REBAR error between two different time-series. Then, through validation experiments, we show that the REBAR error is a predictor of mutual class membership, justifying its usage as a positive/negative labeler. Finally, once integrated into a contrastive learning framework, our REBAR method can learn an",
    "link": "http://arxiv.org/abs/2311.00519",
    "context": "Title: Retrieval-Based Reconstruction For Time-series Contrastive Learning. (arXiv:2311.00519v1 [cs.LG])\nAbstract: The success of self-supervised contrastive learning hinges on identifying positive data pairs that, when pushed together in embedding space, encode useful information for subsequent downstream tasks. However, in time-series, this is challenging because creating positive pairs via augmentations may break the original semantic meaning. We hypothesize that if we can retrieve information from one subsequence to successfully reconstruct another subsequence, then they should form a positive pair. Harnessing this intuition, we introduce our novel approach: REtrieval-BAsed Reconstruction (REBAR) contrastive learning. First, we utilize a convolutional cross-attention architecture to calculate the REBAR error between two different time-series. Then, through validation experiments, we show that the REBAR error is a predictor of mutual class membership, justifying its usage as a positive/negative labeler. Finally, once integrated into a contrastive learning framework, our REBAR method can learn an",
    "path": "papers/23/11/2311.00519.json",
    "total_tokens": 957,
    "translated_title": "基于检索重建的时间序列对比学习方法",
    "translated_abstract": "自监督对比学习的成功取决于鉴别出的正样本对，当它们被推到嵌入空间时，可以为后续的下游任务编码有用的信息。然而，在时间序列中，这是具有挑战性的，因为通过数据增强来创建正样本对可能会破坏原始的语义含义。我们假设如果我们能从一个子序列中检索信息，成功重建另一个子序列，那么它们应该是一个正样本对。基于这个直觉，我们引入了一种新颖的方法：基于检索重建的对比学习（REBAR）。首先，我们利用卷积交叉注意力架构计算两个不同时间序列之间的REBAR误差。然后，通过验证实验，我们展示了REBAR误差是互相类别成员的预测器，从而证明了它作为正/负标记器的使用。最后，一旦集成到对比学习框架中，我们的REBAR方法可以学习一个",
    "tldr": "本文提出了一种基于检索重建的时间序列对比学习方法（REBAR），通过检索信息和重建子序列来构建正样本对，从而解决了时间序列中使用数据增强创建正样本对的挑战。实验证明，REBAR误差可以作为正/负标记器，并且在对比学习框架中集成REBAR方法可以学习具有有用信息的嵌入表示。",
    "en_tdlr": "This paper proposes a retrieval-based reconstruction approach for time-series contrastive learning (REBAR), which addresses the challenge of creating positive pairs in time-series by retrieving information and reconstructing subsequences. The REBAR error is validated as a predictor of mutual class membership, and integrating the REBAR method into a contrastive learning framework enables learning of informative embeddings."
}