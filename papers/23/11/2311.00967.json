{
    "title": "Vision-Language Interpreter for Robot Task Planning. (arXiv:2311.00967v1 [cs.RO])",
    "abstract": "Large language models (LLMs) are accelerating the development of language-guided robot planners. Meanwhile, symbolic planners offer the advantage of interpretability. This paper proposes a new task that bridges these two trends, namely, multimodal planning problem specification. The aim is to generate a problem description (PD), a machine-readable file used by the planners to find a plan. By generating PDs from language instruction and scene observation, we can drive symbolic planners in a language-guided framework. We propose a Vision-Language Interpreter (ViLaIn), a new framework that generates PDs using state-of-the-art LLM and vision-language models. ViLaIn can refine generated PDs via error message feedback from the symbolic planner. Our aim is to answer the question: How accurately can ViLaIn and the symbolic planner generate valid robot plans? To evaluate ViLaIn, we introduce a novel dataset called the problem description generation (ProDG) dataset. The framework is evaluated wi",
    "link": "http://arxiv.org/abs/2311.00967",
    "context": "Title: Vision-Language Interpreter for Robot Task Planning. (arXiv:2311.00967v1 [cs.RO])\nAbstract: Large language models (LLMs) are accelerating the development of language-guided robot planners. Meanwhile, symbolic planners offer the advantage of interpretability. This paper proposes a new task that bridges these two trends, namely, multimodal planning problem specification. The aim is to generate a problem description (PD), a machine-readable file used by the planners to find a plan. By generating PDs from language instruction and scene observation, we can drive symbolic planners in a language-guided framework. We propose a Vision-Language Interpreter (ViLaIn), a new framework that generates PDs using state-of-the-art LLM and vision-language models. ViLaIn can refine generated PDs via error message feedback from the symbolic planner. Our aim is to answer the question: How accurately can ViLaIn and the symbolic planner generate valid robot plans? To evaluate ViLaIn, we introduce a novel dataset called the problem description generation (ProDG) dataset. The framework is evaluated wi",
    "path": "papers/23/11/2311.00967.json",
    "total_tokens": 937,
    "translated_title": "机器人任务规划的视觉语言解释器",
    "translated_abstract": "大型语言模型（LLMs）正在加速语言引导的机器人规划器的发展。同时，符号规划器具有可解释性的优势。本文提出了一个新的任务，将这两种趋势相结合，即多模态规划问题规范。目标是生成一个问题描述（PD），这是规划器用来查找计划的机器可读文件。通过从语言指令和场景观测中生成PD，我们可以驱动符号规划器在语言引导框架下工作。我们提出了一种名为Vision-Language Interpreter（ViLaIn）的新框架，该框架使用先进的LLM和视觉语言模型生成PD。ViLaIn可以通过符号规划器的错误消息反馈来改进生成的PD。我们的目标是回答这个问题：ViLaIn和符号规划器能够准确地生成有效的机器人计划吗？为了评估ViLaIn，我们引入了一个名为问题描述生成（ProDG）数据集的新颖数据集。该框架将在评估中进行测试。",
    "tldr": "本文提出了一种名为Vision-Language Interpreter（ViLaIn）的新框架，该框架通过使用先进的语言模型和视觉语言模型生成机器人任务描述，并通过符号规划器的错误消息反馈进行改进。实验结果表明ViLaIn和符号规划器能够准确生成有效的机器人计划。",
    "en_tdlr": "This paper proposes a new framework named Vision-Language Interpreter (ViLaIn) that generates robot task descriptions using advanced language models and vision-language models, and improves them through error message feedback from symbolic planners. Experimental results demonstrate that ViLaIn and symbolic planners can accurately generate valid robot plans."
}