{
    "title": "Sam-Guided Enhanced Fine-Grained Encoding with Mixed Semantic Learning for Medical Image Captioning. (arXiv:2311.01004v1 [cs.CV])",
    "abstract": "With the development of multimodality and large language models, the deep learning-based technique for medical image captioning holds the potential to offer valuable diagnostic recommendations. However, current generic text and image pre-trained models do not yield satisfactory results when it comes to describing intricate details within medical images. In this paper, we present a novel medical image captioning method guided by the segment anything model (SAM) to enable enhanced encoding with both general and detailed feature extraction. In addition, our approach employs a distinctive pre-training strategy with mixed semantic learning to simultaneously capture both the overall information and finer details within medical images. We demonstrate the effectiveness of this approach, as it outperforms the pre-trained BLIP2 model on various evaluation metrics for generating descriptions of medical images.",
    "link": "http://arxiv.org/abs/2311.01004",
    "context": "Title: Sam-Guided Enhanced Fine-Grained Encoding with Mixed Semantic Learning for Medical Image Captioning. (arXiv:2311.01004v1 [cs.CV])\nAbstract: With the development of multimodality and large language models, the deep learning-based technique for medical image captioning holds the potential to offer valuable diagnostic recommendations. However, current generic text and image pre-trained models do not yield satisfactory results when it comes to describing intricate details within medical images. In this paper, we present a novel medical image captioning method guided by the segment anything model (SAM) to enable enhanced encoding with both general and detailed feature extraction. In addition, our approach employs a distinctive pre-training strategy with mixed semantic learning to simultaneously capture both the overall information and finer details within medical images. We demonstrate the effectiveness of this approach, as it outperforms the pre-trained BLIP2 model on various evaluation metrics for generating descriptions of medical images.",
    "path": "papers/23/11/2311.01004.json",
    "total_tokens": 858,
    "translated_title": "使用混合语义学习的Sam引导增强细粒度编码的医学图像字幕生成",
    "translated_abstract": "随着多模态和大型语言模型的发展，基于深度学习的医学图像字幕生成技术具有提供有价值的诊断建议的潜力。然而，当前的通用文本和图像预训练模型在描述医学图像中的复杂细节时无法提供令人满意的结果。在本文中，我们提出了一种由段落任意模型（SAM）引导的新型医学图像字幕生成方法，以实现对一般和详细特征的增强编码。此外，我们的方法采用独特的混合语义学习预训练策略，同时捕捉医学图像的整体信息和更细节的细节。我们展示了这种方法的有效性，它在生成医学图像描述的各种评估指标上优于预训练的BLIP2模型。",
    "tldr": "本论文提出了一种使用混合语义学习的Sam引导增强细粒度编码的医学图像字幕生成方法，有效地捕捉了医学图像的详细特征，并在评估指标上优于预训练的BLIP2模型。",
    "en_tdlr": "This paper presents a novel approach for medical image captioning that uses mixed semantic learning to enhance fine-grained encoding guided by the segment anything model (SAM). It effectively captures detailed features of medical images and outperforms the pre-trained BLIP2 model on evaluation metrics."
}