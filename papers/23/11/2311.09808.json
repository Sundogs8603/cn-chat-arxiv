{
    "title": "PixT3: Pixel-based Table To Text generation",
    "abstract": "arXiv:2311.09808v2 Announce Type: replace  Abstract: Table-to-text generation involves generating appropriate textual descriptions given structured tabular data. It has attracted increasing attention in recent years thanks to the popularity of neural network models and the availability of large-scale datasets. A common feature across existing methods is their treatment of the input as a string, i.e., by employing linearization techniques that do not always preserve information in the table, are verbose, and lack space efficiency. We propose to rethink data-to-text generation as a visual recognition task, removing the need for rendering the input in a string format. We present PixT3, a multimodal table-to-text model that overcomes the challenges of linearization and input size limitations encountered by existing models. PixT3 is trained with a new self-supervised learning objective to reinforce table structure awareness and is applicable to open-ended and controlled generation settings.",
    "link": "https://arxiv.org/abs/2311.09808",
    "context": "Title: PixT3: Pixel-based Table To Text generation\nAbstract: arXiv:2311.09808v2 Announce Type: replace  Abstract: Table-to-text generation involves generating appropriate textual descriptions given structured tabular data. It has attracted increasing attention in recent years thanks to the popularity of neural network models and the availability of large-scale datasets. A common feature across existing methods is their treatment of the input as a string, i.e., by employing linearization techniques that do not always preserve information in the table, are verbose, and lack space efficiency. We propose to rethink data-to-text generation as a visual recognition task, removing the need for rendering the input in a string format. We present PixT3, a multimodal table-to-text model that overcomes the challenges of linearization and input size limitations encountered by existing models. PixT3 is trained with a new self-supervised learning objective to reinforce table structure awareness and is applicable to open-ended and controlled generation settings.",
    "path": "papers/23/11/2311.09808.json",
    "total_tokens": 807,
    "translated_title": "PixT3：基于像素的表格到文本生成",
    "translated_abstract": "Table-to-text生成涉及根据结构化表格数据生成适当的文本描述。近年来，由于神经网络模型的流行和大规模数据集的可用性，它引起了越来越多的关注。现有方法的一个共同特点是将输入视为字符串，即通过采用线性化技术，不总是保留表格中的信息，过于冗长，缺乏空间效率。我们提出将数据到文本生成重新思考为一个视觉识别任务，消除了将输入呈现为字符串格式的必要性。我们提出了PixT3，一种多模式表格到文本模型，克服了现有模型遇到的线性化和输入大小限制的挑战。PixT3通过新的自监督学习目标进行训练，以加强表格结构意识，并适用于开放式和受控生成设置。",
    "tldr": "PixT3是一种基于像素的多模式表格到文本模型，通过将数据到文本生成视为视觉识别任务，消除了字符串格式的需求，克服了线性化和输入大小限制的挑战。",
    "en_tdlr": "PixT3 is a pixel-based multimodal table-to-text model that rethinks data-to-text generation as a visual recognition task, eliminating the need for string format and overcoming challenges of linearization and input size limitations."
}