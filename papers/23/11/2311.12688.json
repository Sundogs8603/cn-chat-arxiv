{
    "title": "On the Out-of-Distribution Coverage of Combining Split Conformal Prediction and Bayesian Deep Learning",
    "abstract": "arXiv:2311.12688v2 Announce Type: replace  Abstract: Bayesian deep learning and conformal prediction are two methods that have been used to convey uncertainty and increase safety in machine learning systems. We focus on combining Bayesian deep learning with split conformal prediction and how this combination effects out-of-distribution coverage; particularly in the case of multiclass image classification. We suggest that if the model is generally underconfident on the calibration set, then the resultant conformal sets may exhibit worse out-of-distribution coverage compared to simple predictive credible sets. Conversely, if the model is overconfident on the calibration set, the use of conformal prediction may improve out-of-distribution coverage. We evaluate prediction sets as a result of combining split conformal methods and neural networks trained with (i) stochastic gradient descent, (ii) deep ensembles, and (iii) mean-field variational inference. Our results suggest that combining B",
    "link": "https://arxiv.org/abs/2311.12688",
    "context": "Title: On the Out-of-Distribution Coverage of Combining Split Conformal Prediction and Bayesian Deep Learning\nAbstract: arXiv:2311.12688v2 Announce Type: replace  Abstract: Bayesian deep learning and conformal prediction are two methods that have been used to convey uncertainty and increase safety in machine learning systems. We focus on combining Bayesian deep learning with split conformal prediction and how this combination effects out-of-distribution coverage; particularly in the case of multiclass image classification. We suggest that if the model is generally underconfident on the calibration set, then the resultant conformal sets may exhibit worse out-of-distribution coverage compared to simple predictive credible sets. Conversely, if the model is overconfident on the calibration set, the use of conformal prediction may improve out-of-distribution coverage. We evaluate prediction sets as a result of combining split conformal methods and neural networks trained with (i) stochastic gradient descent, (ii) deep ensembles, and (iii) mean-field variational inference. Our results suggest that combining B",
    "path": "papers/23/11/2311.12688.json",
    "total_tokens": 848,
    "translated_title": "关于结合拆分置信预测和贝叶斯深度学习的分布外覆盖率",
    "translated_abstract": "贝叶斯深度学习和置信预测是两种用于传达不确定性并增加机器学习系统安全性的方法。我们关注将贝叶斯深度学习与拆分置信预测相结合对分布外覆盖率的影响；特别是在多类图像分类情况下。我们建议，如果模型在校准集上通常缺乏信心，那么得到的置信集可能与简单预测可信集相比，表现出更糟糕的分布外覆盖。相反，如果模型在校准集上过于自信，使用置信预测可能会改善分布外覆盖。我们评估将拆分置信方法与随机梯度下降、深度集合和均场变分推理训练的神经网络相结合的预测集的结果。我们的结果表明，结合B",
    "tldr": "结合拆分置信预测和贝叶斯深度学习在多类图像分类中的分布外覆盖率基于模型在校准集上的信心水平，可能会影响模型对分布外数据的处理。",
    "en_tdlr": "The combination of split conformal prediction and Bayesian deep learning in multi-class image classification affects out-of-distribution coverage based on the model's confidence level on the calibration set."
}