{
    "title": "AiluRus: A Scalable ViT Framework for Dense Prediction. (arXiv:2311.01197v1 [cs.CV])",
    "abstract": "Vision transformers (ViTs) have emerged as a prevalent architecture for vision tasks owing to their impressive performance. However, when it comes to handling long token sequences, especially in dense prediction tasks that require high-resolution input, the complexity of ViTs increases significantly. Notably, dense prediction tasks, such as semantic segmentation or object detection, emphasize more on the contours or shapes of objects, while the texture inside objects is less informative. Motivated by this observation, we propose to apply adaptive resolution for different regions in the image according to their importance. Specifically, at the intermediate layer of the ViT, we utilize a spatial-aware density-based clustering algorithm to select representative tokens from the token sequence. Once the representative tokens are determined, we proceed to merge other tokens into their closest representative token. Consequently, semantic similar tokens are merged together to form low-resoluti",
    "link": "http://arxiv.org/abs/2311.01197",
    "context": "Title: AiluRus: A Scalable ViT Framework for Dense Prediction. (arXiv:2311.01197v1 [cs.CV])\nAbstract: Vision transformers (ViTs) have emerged as a prevalent architecture for vision tasks owing to their impressive performance. However, when it comes to handling long token sequences, especially in dense prediction tasks that require high-resolution input, the complexity of ViTs increases significantly. Notably, dense prediction tasks, such as semantic segmentation or object detection, emphasize more on the contours or shapes of objects, while the texture inside objects is less informative. Motivated by this observation, we propose to apply adaptive resolution for different regions in the image according to their importance. Specifically, at the intermediate layer of the ViT, we utilize a spatial-aware density-based clustering algorithm to select representative tokens from the token sequence. Once the representative tokens are determined, we proceed to merge other tokens into their closest representative token. Consequently, semantic similar tokens are merged together to form low-resoluti",
    "path": "papers/23/11/2311.01197.json",
    "total_tokens": 872,
    "translated_title": "AiluRus: 一种用于密集预测的可扩展ViT框架",
    "translated_abstract": "Vision transformers (ViTs)因其出色的性能而成为视觉任务中常见的架构。然而，在处理长令牌序列时，尤其是在需要高分辨率输入的密集预测任务中，ViTs的复杂性显著增加。值得注意的是，密集预测任务（如语义分割或目标检测）更加强调对象的轮廓或形状，而对象内部的纹理信息较少。受此观察的启发，我们提出根据图像中不同区域的重要性应用自适应分辨率。具体而言，在ViT的中间层中，我们利用一种基于空间感知的密度聚类算法从令牌序列中选择代表性的令牌。确定了代表性令牌后，我们继续将其他令牌合并到最近的代表性令牌中。因此，语义相似的令牌被合并在一起形成低分辨率的特征。",
    "tldr": "AiluRus是一种用于密集预测的可扩展ViT框架，通过应用自适应分辨率和密度聚类算法，将语义相似的令牌合并在一起，以处理长令牌序列的复杂性。",
    "en_tdlr": "AiluRus is a scalable ViT framework for dense prediction tasks. It uses adaptive resolution and density-based clustering algorithm to merge semantic similar tokens for handling the complexity of long token sequences."
}