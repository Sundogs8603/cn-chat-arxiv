{
    "title": "Asynchronous SGD on Graphs: a Unified Framework for Asynchronous Decentralized and Federated Optimization. (arXiv:2311.00465v1 [math.OC])",
    "abstract": "Decentralized and asynchronous communications are two popular techniques to speedup communication complexity of distributed machine learning, by respectively removing the dependency over a central orchestrator and the need for synchronization. Yet, combining these two techniques together still remains a challenge. In this paper, we take a step in this direction and introduce Asynchronous SGD on Graphs (AGRAF SGD) -- a general algorithmic framework that covers asynchronous versions of many popular algorithms including SGD, Decentralized SGD, Local SGD, FedBuff, thanks to its relaxed communication and computation assumptions. We provide rates of convergence under much milder assumptions than previous decentralized asynchronous works, while still recovering or even improving over the best know results for all the algorithms covered.",
    "link": "http://arxiv.org/abs/2311.00465",
    "context": "Title: Asynchronous SGD on Graphs: a Unified Framework for Asynchronous Decentralized and Federated Optimization. (arXiv:2311.00465v1 [math.OC])\nAbstract: Decentralized and asynchronous communications are two popular techniques to speedup communication complexity of distributed machine learning, by respectively removing the dependency over a central orchestrator and the need for synchronization. Yet, combining these two techniques together still remains a challenge. In this paper, we take a step in this direction and introduce Asynchronous SGD on Graphs (AGRAF SGD) -- a general algorithmic framework that covers asynchronous versions of many popular algorithms including SGD, Decentralized SGD, Local SGD, FedBuff, thanks to its relaxed communication and computation assumptions. We provide rates of convergence under much milder assumptions than previous decentralized asynchronous works, while still recovering or even improving over the best know results for all the algorithms covered.",
    "path": "papers/23/11/2311.00465.json",
    "total_tokens": 812,
    "translated_title": "图上的异步SGD: 一种统一的异步分散和联邦优化框架",
    "translated_abstract": "分散和异步通信是加速分布式机器学习通信复杂性的两种流行技术，分别通过消除对中央编排器的依赖和不需要同步来实现。然而，将这两种技术结合起来仍然是一个挑战。本文在这个方向上迈出了一步，引入了图上的异步SGD（AGRAF SGD）——一个通用的算法框架，包括了许多流行算法的异步版本，包括SGD、分散SGD、本地SGD、FedBuff，由于其放松了通信和计算假设。在比之前的分散异步工作更温和的假设下，我们提供了收敛速度，同时仍然恢复甚至改善了所有算法的最佳结果。",
    "tldr": "本文引入了图上的异步SGD（AGRAF SGD）算法框架，该框架统一了异步分散和联邦优化算法，并在更温和的假设下提供了收敛速度，还恢复或改善了所有算法的最佳结果。"
}