{
    "title": "Visual cognition in multimodal large language models. (arXiv:2311.16093v2 [cs.LG] UPDATED)",
    "abstract": "A chief goal of artificial intelligence is to build machines that think like people. Yet it has been argued that deep neural network architectures fail to accomplish this. Researchers have asserted these models' limitations in the domains of causal reasoning, intuitive physics, and intuitive psychology. Yet recent advancements, namely the rise of large language models, particularly those designed for visual processing, have rekindled interest in the potential to emulate human-like cognitive abilities. This paper evaluates the current state of vision-based large language models in the domains of intuitive physics, causal reasoning, and intuitive psychology. Through a series of controlled experiments, we investigate the extent to which these modern models grasp complex physical interactions, causal relationships, and intuitive understanding of others' preferences. Our findings reveal that, while these models demonstrate a notable proficiency in processing and interpreting visual data, th",
    "link": "http://arxiv.org/abs/2311.16093",
    "context": "Title: Visual cognition in multimodal large language models. (arXiv:2311.16093v2 [cs.LG] UPDATED)\nAbstract: A chief goal of artificial intelligence is to build machines that think like people. Yet it has been argued that deep neural network architectures fail to accomplish this. Researchers have asserted these models' limitations in the domains of causal reasoning, intuitive physics, and intuitive psychology. Yet recent advancements, namely the rise of large language models, particularly those designed for visual processing, have rekindled interest in the potential to emulate human-like cognitive abilities. This paper evaluates the current state of vision-based large language models in the domains of intuitive physics, causal reasoning, and intuitive psychology. Through a series of controlled experiments, we investigate the extent to which these modern models grasp complex physical interactions, causal relationships, and intuitive understanding of others' preferences. Our findings reveal that, while these models demonstrate a notable proficiency in processing and interpreting visual data, th",
    "path": "papers/23/11/2311.16093.json",
    "total_tokens": 951,
    "translated_title": "多模态大语言模型中的视觉认知",
    "translated_abstract": "人工智能的一个主要目标是构建像人类一样思考的机器。然而据认为，深度神经网络架构无法实现这一目标。研究人员指出这些模型在因果推理、直观物理和直观心理等领域存在局限性。然而，最近的进展，特别是面向视觉处理的大语言模型的兴起，重新引起了对模拟人类类似认知能力潜力的兴趣。本文评估了基于视觉的大语言模型在直观物理、因果推理和直观心理领域的当前状态。通过一系列的对照实验，我们调查了这些现代模型在理解复杂物理相互作用、因果关系和对他人偏好的直观理解程度。我们的研究发现,虽然这些模型在处理和解释视觉数据方面表现出显著的熟练性,然而它们在直观物理、因果推理和直观心理方面的表现还有待提高。",
    "tldr": "本文评估了基于视觉的大语言模型在直观物理、因果推理和直观心理领域的当前状态，并通过一系列的对照实验发现，虽然这些模型在处理和解释视觉数据方面表现出显著的熟练性，然而它们在直观物理、因果推理和直观心理方面的表现还有待提高。"
}