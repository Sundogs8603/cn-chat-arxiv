{
    "title": "AI-generated text boundary detection with RoFT",
    "abstract": "arXiv:2311.08349v2 Announce Type: replace  Abstract: Due to the rapid development of large language models, people increasingly often encounter texts that may start as written by a human but continue as machine-generated. Detecting the boundary between human-written and machine-generated parts of such texts is a challenging problem that has not received much attention in literature. We attempt to bridge this gap and examine several ways to adapt state of the art artificial text detection classifiers to the boundary detection setting. We push all detectors to their limits, using the Real or Fake text benchmark that contains short texts on several topics and includes generations of various language models. We use this diversity to deeply examine the robustness of all detectors in cross-domain and cross-model settings to provide baselines and insights for future research. In particular, we find that perplexity-based approaches to boundary detection tend to be more robust to peculiarities ",
    "link": "https://arxiv.org/abs/2311.08349",
    "context": "Title: AI-generated text boundary detection with RoFT\nAbstract: arXiv:2311.08349v2 Announce Type: replace  Abstract: Due to the rapid development of large language models, people increasingly often encounter texts that may start as written by a human but continue as machine-generated. Detecting the boundary between human-written and machine-generated parts of such texts is a challenging problem that has not received much attention in literature. We attempt to bridge this gap and examine several ways to adapt state of the art artificial text detection classifiers to the boundary detection setting. We push all detectors to their limits, using the Real or Fake text benchmark that contains short texts on several topics and includes generations of various language models. We use this diversity to deeply examine the robustness of all detectors in cross-domain and cross-model settings to provide baselines and insights for future research. In particular, we find that perplexity-based approaches to boundary detection tend to be more robust to peculiarities ",
    "path": "papers/23/11/2311.08349.json",
    "total_tokens": 827,
    "translated_title": "使用RoFT进行人工智能生成文本边界检测",
    "translated_abstract": "由于大语言模型的快速发展，人们越来越经常遇到可能一开始是由人类编写但之后是由机器生成的文本。检测这些文本中人类编写和机器生成部分之间的边界是一个具有挑战性且在文献中尚未受到足够关注的问题。我们试图填补这一差距，并研究几种方法来将最先进的人工文本检测分类器调整为边界检测设置。我们将所有检测器推向极限，在包含多个主题的短文本的Real or Fake文本基准集上进行测试，并包括各种语言模型的生成。我们利用这种多样性深入研究所有检测器在跨领域和跨模型设置中的鲁棒性，以提供未来研究的基线和见解。特别地，我们发现基于困惑度的边界检测方法倾向于更加稳健。",
    "tldr": "使用RoFT进行人工智能生成文本边界检测的研究揭示了基于困惑度的方法在跨领域和跨模型设置中更加稳健。",
    "en_tdlr": "The study on AI-generated text boundary detection with RoFT reveals that perplexity-based methods tend to be more robust in cross-domain and cross-model settings."
}