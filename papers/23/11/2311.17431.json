{
    "title": "Grounding Foundation Models through Federated Transfer Learning: A General Framework. (arXiv:2311.17431v7 [cs.LG] UPDATED)",
    "abstract": "Foundation Models (FMs) such as GPT-4 encoded with vast knowledge and powerful emergent abilities have achieved remarkable success in various natural language processing and computer vision tasks. Grounding FMs by adapting them to domain-specific tasks or augmenting them with domain-specific knowledge enables us to exploit the full potential of FMs. However, grounding FMs faces several challenges, stemming primarily from constrained computing resources, data privacy, model heterogeneity, and model ownership. Federated Transfer Learning (FTL), the combination of federated learning and transfer learning, provides promising solutions to address these challenges. In recent years, the need for grounding FMs leveraging FTL, coined FTL-FM, has arisen strongly in both academia and industry. Motivated by the strong growth in FTL-FM research and the potential impact of FTL-FM on industrial applications, we propose an FTL-FM framework that formulates problems of grounding FMs in the federated lea",
    "link": "http://arxiv.org/abs/2311.17431",
    "context": "Title: Grounding Foundation Models through Federated Transfer Learning: A General Framework. (arXiv:2311.17431v7 [cs.LG] UPDATED)\nAbstract: Foundation Models (FMs) such as GPT-4 encoded with vast knowledge and powerful emergent abilities have achieved remarkable success in various natural language processing and computer vision tasks. Grounding FMs by adapting them to domain-specific tasks or augmenting them with domain-specific knowledge enables us to exploit the full potential of FMs. However, grounding FMs faces several challenges, stemming primarily from constrained computing resources, data privacy, model heterogeneity, and model ownership. Federated Transfer Learning (FTL), the combination of federated learning and transfer learning, provides promising solutions to address these challenges. In recent years, the need for grounding FMs leveraging FTL, coined FTL-FM, has arisen strongly in both academia and industry. Motivated by the strong growth in FTL-FM research and the potential impact of FTL-FM on industrial applications, we propose an FTL-FM framework that formulates problems of grounding FMs in the federated lea",
    "path": "papers/23/11/2311.17431.json",
    "total_tokens": 978,
    "translated_title": "通过联邦迁移学习对基础模型进行接地：一个通用框架",
    "translated_abstract": "基于广泛知识和强大的新兴能力编码的Foundation Models（FMs），如GPT-4，在各种自然语言处理和计算机视觉任务中取得了显著成功。通过将FMs适应于特定领域任务或增加领域特定知识来对其进行接地，我们可以充分发挥FMs的潜力。然而，接地FMs面临着多个挑战，主要是受限的计算资源、数据隐私、模型异构性和模型所有权。联邦迁移学习（FTL），即联邦学习和迁移学习的结合，为解决这些挑战提供了有希望的解决方案。近年来，学术界和工业界对通过FTL-FM利用FMs进行接地的需求强烈增长。受到FTL-FM研究的强劲增长和FTL-FM对工业应用的潜在影响的推动，我们提出了一个FTL-FM框架，用于在联邦学习环境中建立FMs的接地问题。",
    "tldr": "本论文提出了一个通用框架，通过联邦迁移学习将基础模型接地，以解决面临的挑战，如受限的计算资源、数据隐私、模型异构性和模型所有权。这个框架可以帮助释放基础模型的潜力，并在不同行业中产生重要影响。"
}