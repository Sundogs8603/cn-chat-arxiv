{
    "title": "Uncertainty quantification and out-of-distribution detection using surjective normalizing flows. (arXiv:2311.00377v1 [cs.LG])",
    "abstract": "Reliable quantification of epistemic and aleatoric uncertainty is of crucial importance in applications where models are trained in one environment but applied to multiple different environments, often seen in real-world applications for example, in climate science or mobility analysis. We propose a simple approach using surjective normalizing flows to identify out-of-distribution data sets in deep neural network models that can be computed in a single forward pass. The method builds on recent developments in deep uncertainty quantification and generative modeling with normalizing flows. We apply our method to a synthetic data set that has been simulated using a mechanistic model from the mobility literature and several data sets simulated from interventional distributions induced by soft and atomic interventions on that model, and demonstrate that our method can reliably discern out-of-distribution data from in-distribution data. We compare the surjective flow model to a Dirichlet pro",
    "link": "http://arxiv.org/abs/2311.00377",
    "context": "Title: Uncertainty quantification and out-of-distribution detection using surjective normalizing flows. (arXiv:2311.00377v1 [cs.LG])\nAbstract: Reliable quantification of epistemic and aleatoric uncertainty is of crucial importance in applications where models are trained in one environment but applied to multiple different environments, often seen in real-world applications for example, in climate science or mobility analysis. We propose a simple approach using surjective normalizing flows to identify out-of-distribution data sets in deep neural network models that can be computed in a single forward pass. The method builds on recent developments in deep uncertainty quantification and generative modeling with normalizing flows. We apply our method to a synthetic data set that has been simulated using a mechanistic model from the mobility literature and several data sets simulated from interventional distributions induced by soft and atomic interventions on that model, and demonstrate that our method can reliably discern out-of-distribution data from in-distribution data. We compare the surjective flow model to a Dirichlet pro",
    "path": "papers/23/11/2311.00377.json",
    "total_tokens": 826,
    "translated_title": "使用全射正常化流进行不确定性量化和超出分布检测",
    "translated_abstract": "在模型训练和应用环境不同的应用中，可靠地量化认识不确定性是至关重要的，这在气候科学或移动性分析等实际应用中经常出现。我们提出了一种简单的方法，使用全射正常化流来识别深度神经网络模型中的超出分布数据集，可以在单次前向传递中计算。该方法建立在最近在深度不确定性量化和生成建模领域的发展基础上。我们将这种方法应用于使用从移动性文献的机械模型模拟的合成数据集，以及使用对该模型进行软、原子干预后得到的干预分布模拟的几个数据集，并且证明我们的方法可以可靠地区分超出分布数据和分布数据。我们将全射流模型与Dirichlet生成模型进行比较。",
    "tldr": "本研究使用全射正常化流方法，在深度神经网络模型中识别超出分布数据集，从而可靠地量化不确定性，并在多个实验中得到了验证。",
    "en_tdlr": "This study proposes a simple approach using surjective normalizing flows to identify out-of-distribution data sets in deep neural network models, achieving reliable quantification of uncertainty in different environments and validated in multiple experiments."
}