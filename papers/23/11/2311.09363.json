{
    "title": "Investigating the Emergent Audio Classification Ability of ASR Foundation Models",
    "abstract": "arXiv:2311.09363v2 Announce Type: replace  Abstract: Text and vision foundation models can perform many tasks in a zero-shot setting, a desirable property that enables these systems to be applied in general and low-resource settings. There has been far less work, however, on the zero-shot abilities of ASR foundation models, with these systems typically fine-tuned to specific tasks or constrained to applications that match their training criterion and data annotation. In this work we investigate the ability of Whisper and MMS, ASR foundation models trained primarily for speech recognition, to perform zero-shot audio classification. We use simple template-based text prompts at the decoder and use the resulting decoding probabilities to generate zero-shot predictions. Without training the model on extra data or adding any new parameters, we demonstrate that Whisper shows promising zero-shot classification performance on a range of 8 audio-classification datasets, outperforming the accurac",
    "link": "https://arxiv.org/abs/2311.09363",
    "context": "Title: Investigating the Emergent Audio Classification Ability of ASR Foundation Models\nAbstract: arXiv:2311.09363v2 Announce Type: replace  Abstract: Text and vision foundation models can perform many tasks in a zero-shot setting, a desirable property that enables these systems to be applied in general and low-resource settings. There has been far less work, however, on the zero-shot abilities of ASR foundation models, with these systems typically fine-tuned to specific tasks or constrained to applications that match their training criterion and data annotation. In this work we investigate the ability of Whisper and MMS, ASR foundation models trained primarily for speech recognition, to perform zero-shot audio classification. We use simple template-based text prompts at the decoder and use the resulting decoding probabilities to generate zero-shot predictions. Without training the model on extra data or adding any new parameters, we demonstrate that Whisper shows promising zero-shot classification performance on a range of 8 audio-classification datasets, outperforming the accurac",
    "path": "papers/23/11/2311.09363.json",
    "total_tokens": 837,
    "translated_title": "探究ASR基础模型的新兴音频分类能力",
    "translated_abstract": "arXiv:2311.09363v2 公告类型：替换 摘要：文本和视觉基础模型可以在零-shot设置中执行许多任务，这是一个令人向往的特性，它使这些系统能够应用于普遍和低资源的环境。然而，关于ASR基础模型的零-shot能力的研究要少得多，这些系统通常被微调到特定任务，或受限于与其训练标准和数据注释相匹配的应用程序。在这项工作中，我们调查了Whisper和MMS这两款主要用于语音识别训练的ASR基础模型执行零-shot音频分类的能力。我们在解码器中使用简单的基于模板的文本提示，并利用生成的解码概率来生成零-shot预测。在不对模型进行额外数据训练或添加任何新参数的情况下，我们展示了Whisper在一系列8个音频分类数据集上展现了有希望的零-shot分类性能，胜过了准确性。",
    "tldr": "ASR基础模型Whisper和MMS在不经过额外数据训练或添加新参数的情况下，展现了有希望的零-shot音频分类性能。"
}