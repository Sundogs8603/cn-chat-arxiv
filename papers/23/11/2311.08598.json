{
    "title": "DALA: A Distribution-Aware LoRA-Based Adversarial Attack against Language Models",
    "abstract": "arXiv:2311.08598v2 Announce Type: replace  Abstract: Language models (LMs) can be manipulated by adversarial attacks, which introduce subtle perturbations to input data. While recent attack methods can achieve a relatively high attack success rate (ASR), we've observed that the generated adversarial examples have a different data distribution compared with the original examples. Specifically, these adversarial examples exhibit reduced confidence levels and greater divergence from the training data distribution. Consequently, they are easy to detect using straightforward detection methods, diminishing the efficacy of such attacks. To address this issue, we propose a Distribution-Aware LoRA-based Adversarial Attack (DALA) method. DALA considers distribution shifts of adversarial examples to improve the attack's effectiveness under detection methods. We further design a novel evaluation metric, the Non-detectable Attack Success Rate (NASR), which integrates both ASR and detectability for ",
    "link": "https://arxiv.org/abs/2311.08598",
    "context": "Title: DALA: A Distribution-Aware LoRA-Based Adversarial Attack against Language Models\nAbstract: arXiv:2311.08598v2 Announce Type: replace  Abstract: Language models (LMs) can be manipulated by adversarial attacks, which introduce subtle perturbations to input data. While recent attack methods can achieve a relatively high attack success rate (ASR), we've observed that the generated adversarial examples have a different data distribution compared with the original examples. Specifically, these adversarial examples exhibit reduced confidence levels and greater divergence from the training data distribution. Consequently, they are easy to detect using straightforward detection methods, diminishing the efficacy of such attacks. To address this issue, we propose a Distribution-Aware LoRA-based Adversarial Attack (DALA) method. DALA considers distribution shifts of adversarial examples to improve the attack's effectiveness under detection methods. We further design a novel evaluation metric, the Non-detectable Attack Success Rate (NASR), which integrates both ASR and detectability for ",
    "path": "papers/23/11/2311.08598.json",
    "total_tokens": 878,
    "translated_title": "DALA: 一种基于分布感知的面向语言模型的对抗攻击方法",
    "translated_abstract": "语言模型（LMs）可以通过对抗性攻击进行操纵，这些攻击在输入数据中引入微妙的扰动。近期的攻击方法可以实现相对较高的攻击成功率（ASR），但我们观察到生成的对抗性样本与原始样本相比具有不同的数据分布。具体而言，这些对抗性样本表现出降低的置信水平和与训练数据分布的较大差异。因此，它们很容易被简单的检测方法检测出来，降低了此类攻击的有效性。为解决这一问题，我们提出了一种基于LoRA的分布感知的对抗攻击方法（DALA）。DALA考虑对抗性样本的分布变化，以提高在检测方法下的攻击效果。我们进一步设计了一种新颖的评价度量，非可检测攻击成功率（NASR），它融合了ASR和可检测性。",
    "tldr": "DALA是一种基于分布感知的LoRA对抗攻击方法，旨在改善对抗性样本的数据分布，提高攻击效果，并引入了非可检测攻击成功率（NASR）评价指标。",
    "en_tdlr": "DALA is a distribution-aware LoRA-based adversarial attack method aimed at improving the data distribution of adversarial examples, enhancing attack effectiveness, and introducing a new evaluation metric called Non-detectable Attack Success Rate (NASR)."
}