{
    "title": "Comparison of pipeline, sequence-to-sequence, and GPT models for end-to-end relation extraction: experiments with the rare disease use-case",
    "abstract": "arXiv:2311.13729v2 Announce Type: replace  Abstract: End-to-end relation extraction (E2ERE) is an important and realistic application of natural language processing (NLP) in biomedicine. In this paper, we aim to compare three prevailing paradigms for E2ERE using a complex dataset focused on rare diseases involving discontinuous and nested entities. We use the RareDis information extraction dataset to evaluate three competing approaches (for E2ERE): NER $\\rightarrow$ RE pipelines, joint sequence to sequence models, and generative pre-trained transformer (GPT) models. We use comparable state-of-the-art models and best practices for each of these approaches and conduct error analyses to assess their failure modes. Our findings reveal that pipeline models are still the best, while sequence-to-sequence models are not far behind; GPT models with eight times as many parameters are worse than even sequence-to-sequence models and lose to pipeline models by over 10 F1 points. Partial matches and",
    "link": "https://arxiv.org/abs/2311.13729",
    "context": "Title: Comparison of pipeline, sequence-to-sequence, and GPT models for end-to-end relation extraction: experiments with the rare disease use-case\nAbstract: arXiv:2311.13729v2 Announce Type: replace  Abstract: End-to-end relation extraction (E2ERE) is an important and realistic application of natural language processing (NLP) in biomedicine. In this paper, we aim to compare three prevailing paradigms for E2ERE using a complex dataset focused on rare diseases involving discontinuous and nested entities. We use the RareDis information extraction dataset to evaluate three competing approaches (for E2ERE): NER $\\rightarrow$ RE pipelines, joint sequence to sequence models, and generative pre-trained transformer (GPT) models. We use comparable state-of-the-art models and best practices for each of these approaches and conduct error analyses to assess their failure modes. Our findings reveal that pipeline models are still the best, while sequence-to-sequence models are not far behind; GPT models with eight times as many parameters are worse than even sequence-to-sequence models and lose to pipeline models by over 10 F1 points. Partial matches and",
    "path": "papers/23/11/2311.13729.json",
    "total_tokens": 979,
    "translated_title": "比较用于端到端关系抽取的管道、序列到序列和GPT模型：以罕见疾病用例为实验",
    "translated_abstract": "端到端关系抽取（E2ERE）是自然语言处理（NLP）在生物医学中的一个重要而现实的应用。本文旨在使用一个关注罕见疾病、涉及不连续和嵌套实体的复杂数据集，比较E2ERE的三种流行范式。我们使用RareDis信息提取数据集评估了三种竞争方法（用于E2ERE）：实体识别（NER）→关系抽取（RE）管道、联合序列到序列模型和生成式预训练变压器（GPT）模型。我们针对每种方法使用可比的最先进模型和最佳实践，并进行错误分析以评估它们的失败模式。我们的发现显示，管道模型仍然是最佳选择，而序列到序列模型紧随其后；参数量增加八倍的GPT模型甚至比序列到序列模型更差，且比管道模型低10个F1点以上。",
    "tldr": "本文比较了用于端到端关系抽取的管道、序列到序列和GPT模型，发现管道模型仍然是最佳选择，而序列到序列模型紧随其后；参数量增加八倍的GPT模型甚至比序列到序列模型更差，且比管道模型低10个F1点以上。",
    "en_tdlr": "This paper compares pipeline, sequence-to-sequence, and GPT models for end-to-end relation extraction, finding that pipeline models are still the best, followed closely by sequence-to-sequence models; GPT models with eight times as many parameters perform even worse than sequence-to-sequence models, losing to pipeline models by over 10 F1 points."
}