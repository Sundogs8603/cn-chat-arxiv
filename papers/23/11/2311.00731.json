{
    "title": "Enhancing Clustering Representations with Positive Proximity and Cluster Dispersion Learning. (arXiv:2311.00731v1 [cs.LG])",
    "abstract": "Contemporary deep clustering approaches often rely on either contrastive or non-contrastive techniques to acquire effective representations for clustering tasks. Contrastive methods leverage negative pairs to achieve homogenous representations but can introduce class collision issues, potentially compromising clustering performance. On the contrary, non-contrastive techniques prevent class collisions but may produce non-uniform representations that lead to clustering collapse. In this work, we propose a novel end-to-end deep clustering approach named PIPCDR, designed to harness the strengths of both approaches while mitigating their limitations. PIPCDR incorporates a positive instance proximity loss and a cluster dispersion regularizer. The positive instance proximity loss ensures alignment between augmented views of instances and their sampled neighbors, enhancing within-cluster compactness by selecting genuinely positive pairs within the embedding space. Meanwhile, the cluster disper",
    "link": "http://arxiv.org/abs/2311.00731",
    "context": "Title: Enhancing Clustering Representations with Positive Proximity and Cluster Dispersion Learning. (arXiv:2311.00731v1 [cs.LG])\nAbstract: Contemporary deep clustering approaches often rely on either contrastive or non-contrastive techniques to acquire effective representations for clustering tasks. Contrastive methods leverage negative pairs to achieve homogenous representations but can introduce class collision issues, potentially compromising clustering performance. On the contrary, non-contrastive techniques prevent class collisions but may produce non-uniform representations that lead to clustering collapse. In this work, we propose a novel end-to-end deep clustering approach named PIPCDR, designed to harness the strengths of both approaches while mitigating their limitations. PIPCDR incorporates a positive instance proximity loss and a cluster dispersion regularizer. The positive instance proximity loss ensures alignment between augmented views of instances and their sampled neighbors, enhancing within-cluster compactness by selecting genuinely positive pairs within the embedding space. Meanwhile, the cluster disper",
    "path": "papers/23/11/2311.00731.json",
    "total_tokens": 862,
    "translated_title": "用正向相似性和簇离散学习提升聚类表示",
    "translated_abstract": "当代深度聚类方法通常依赖对比或非对比技术来获取用于聚类任务的有效表示。对比方法利用负对来实现同质表示，但可能引入类冲突问题，可能导致聚类性能下降。相反，非对比技术可以防止类冲突，但可能产生非均匀表示，导致聚类崩溃。在本工作中，我们提出了一种新颖的端到端深度聚类方法，名为PIPCDR，旨在兼顾两种方法的优势并减轻它们的局限性。PIPCDR包括一个正向实例相似性损失和一个簇离散正则化器。正向实例相似性损失确保实例的增强视图与其采样邻居之间的对齐，通过在嵌入空间中选择真正的正对来增强簇内紧密度。同时，簇离散正则化器能够鼓励簇之间的分散性，进一步提高聚类性能。",
    "tldr": "本论文提出了一种新的深度聚类方法，名为PIPCDR，通过结合正向实例相似性损失和簇离散正则化器，以提升聚类性能。"
}