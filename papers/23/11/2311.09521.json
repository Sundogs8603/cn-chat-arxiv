{
    "title": "AMRFact: Enhancing Summarization Factuality Evaluation with AMR-Driven Negative Samples Generation",
    "abstract": "arXiv:2311.09521v2 Announce Type: replace  Abstract: Ensuring factual consistency is crucial for natural language generation tasks, particularly in abstractive summarization, where preserving the integrity of information is paramount. Prior works on evaluating factual consistency of summarization often take the entailment-based approaches that first generate perturbed (factual inconsistent) summaries and then train a classifier on the generated data to detect the factually inconsistencies during testing time. However, previous approaches generating perturbed summaries are either of low coherence or lack error-type coverage. To address these issues, we propose AMRFact, a framework that generates perturbed summaries using Abstract Meaning Representations (AMRs). Our approach parses factually consistent summaries into AMR graphs and injects controlled factual inconsistencies to create negative examples, allowing for coherent factually inconsistent summaries to be generated with high error",
    "link": "https://arxiv.org/abs/2311.09521",
    "context": "Title: AMRFact: Enhancing Summarization Factuality Evaluation with AMR-Driven Negative Samples Generation\nAbstract: arXiv:2311.09521v2 Announce Type: replace  Abstract: Ensuring factual consistency is crucial for natural language generation tasks, particularly in abstractive summarization, where preserving the integrity of information is paramount. Prior works on evaluating factual consistency of summarization often take the entailment-based approaches that first generate perturbed (factual inconsistent) summaries and then train a classifier on the generated data to detect the factually inconsistencies during testing time. However, previous approaches generating perturbed summaries are either of low coherence or lack error-type coverage. To address these issues, we propose AMRFact, a framework that generates perturbed summaries using Abstract Meaning Representations (AMRs). Our approach parses factually consistent summaries into AMR graphs and injects controlled factual inconsistencies to create negative examples, allowing for coherent factually inconsistent summaries to be generated with high error",
    "path": "papers/23/11/2311.09521.json",
    "total_tokens": 824,
    "translated_title": "AMRFact：利用AMR生成负样本增强摘要的事实性评估",
    "translated_abstract": "确保事实一致性对于自然语言生成任务至关重要，特别是在提取式摘要中，保持信息的完整性至关重要。以前关于评估摘要的事实一致性的工作通常采用基于蕴涵的方法，首先生成扰动（事实不一致）摘要，然后在生成的数据上训练一个分类器，在测试时检测事实不一致。然而，先前生成扰动摘要的方法要么缺乏连贯性，要么缺乏错误类型覆盖。为了解决这些问题，我们提出了AMRFact，一个利用抽象意义表示（AMR）生成扰动摘要的框架。我们的方法将事实一致的摘要解析为AMR图，并注入可控的事实不一致，以创建负面示例，允许生成具有高错误率的连贯事实不一致的摘要。",
    "tldr": "AMRFact是一个框架，利用AMR生成负样本，增强了摘要事实性评估，生成的连贯且事实不一致的摘要具有高错误率。",
    "en_tdlr": "AMRFact is a framework that enhances summarization factuality evaluation by generating negative samples using Abstract Meaning Representations (AMRs), resulting in coherent yet factually inconsistent summaries with high error rate."
}