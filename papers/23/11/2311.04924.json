{
    "title": "Tuning-less Object Naming with a Foundation Model",
    "abstract": "arXiv:2311.04924v2 Announce Type: replace-cross  Abstract: We implement a real-time object naming system that enables learning a set of named entities never seen. Our approach employs an existing foundation model that we consider ready to see anything before starting. It turns seen images into relatively small feature vectors that we associate with index to a gradually built vocabulary without any training of fine-tuning of the model. Our contribution is using the association mechanism known from transformers as attention. It has features that support generalization from irrelevant information for distinguishing the entities and potentially enable associating with much more than indices to vocabulary. As a result, the system can work in a one-shot manner and correctly name objects named in different contents. We also outline implementation details of the system modules integrated by a blackboard architecture. Finally, we investigate the system's quality, mainly how many objects it can ",
    "link": "https://arxiv.org/abs/2311.04924",
    "context": "Title: Tuning-less Object Naming with a Foundation Model\nAbstract: arXiv:2311.04924v2 Announce Type: replace-cross  Abstract: We implement a real-time object naming system that enables learning a set of named entities never seen. Our approach employs an existing foundation model that we consider ready to see anything before starting. It turns seen images into relatively small feature vectors that we associate with index to a gradually built vocabulary without any training of fine-tuning of the model. Our contribution is using the association mechanism known from transformers as attention. It has features that support generalization from irrelevant information for distinguishing the entities and potentially enable associating with much more than indices to vocabulary. As a result, the system can work in a one-shot manner and correctly name objects named in different contents. We also outline implementation details of the system modules integrated by a blackboard architecture. Finally, we investigate the system's quality, mainly how many objects it can ",
    "path": "papers/23/11/2311.04924.json",
    "total_tokens": 782,
    "translated_title": "无调谐的基础模型对象命名",
    "translated_abstract": "我们实现了一个实时对象命名系统，可以学习一组从未见过的命名实体。我们的方法采用了一个现有的基础模型，在开始之前我们认为它准备好接受任何内容。它将观察到的图像转换为相对较小的特征向量，我们将这些特征向量与逐渐构建的词汇表中的索引相关联，且无需对模型进行任何微调。我们的贡献在于使用了来自transformers注意力机制的关联机制。它具有支持从不相关信息中泛化以区分实体并潜在地能够与远超出词汇表索引的实体相关联的特性。因此，该系统可以以一次性方式工作，并正确地为不同上下文中命名的对象命名。我们还概述了通过黑板架构集成的系统模块的实现细节。最后，我们调查了系统的质量，主要着眼于它能够识别多少对象",
    "tldr": "使用transformers的注意力机制，提出了一种无需微调模型即可进行对象命名的方法",
    "en_tdlr": "Propose a method for object naming without fine-tuning the model, utilizing the attention mechanism from transformers."
}