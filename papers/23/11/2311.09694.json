{
    "title": "Whispers of Doubt Amidst Echoes of Triumph in NLP Robustness",
    "abstract": "arXiv:2311.09694v2 Announce Type: replace  Abstract: Do larger and more performant models resolve NLP's longstanding robustness issues? We investigate this question using over 20 models of different sizes spanning different architectural choices and pretraining objectives. We conduct evaluations using (a) out-of-domain and challenge test sets, (b) behavioral testing with CheckLists, (c) contrast sets, and (d) adversarial inputs. Our analysis reveals that not all out-of-domain tests provide insight into robustness. Evaluating with CheckLists and contrast sets shows significant gaps in model performance; merely scaling models does not make them adequately robust. Finally, we point out that current approaches for adversarial evaluations of models are themselves problematic: they can be easily thwarted, and in their current forms, do not represent a sufficiently deep probe of model robustness. We conclude that not only is the question of robustness in NLP as yet unresolved, but even some o",
    "link": "https://arxiv.org/abs/2311.09694",
    "context": "Title: Whispers of Doubt Amidst Echoes of Triumph in NLP Robustness\nAbstract: arXiv:2311.09694v2 Announce Type: replace  Abstract: Do larger and more performant models resolve NLP's longstanding robustness issues? We investigate this question using over 20 models of different sizes spanning different architectural choices and pretraining objectives. We conduct evaluations using (a) out-of-domain and challenge test sets, (b) behavioral testing with CheckLists, (c) contrast sets, and (d) adversarial inputs. Our analysis reveals that not all out-of-domain tests provide insight into robustness. Evaluating with CheckLists and contrast sets shows significant gaps in model performance; merely scaling models does not make them adequately robust. Finally, we point out that current approaches for adversarial evaluations of models are themselves problematic: they can be easily thwarted, and in their current forms, do not represent a sufficiently deep probe of model robustness. We conclude that not only is the question of robustness in NLP as yet unresolved, but even some o",
    "path": "papers/23/11/2311.09694.json",
    "total_tokens": 857,
    "translated_title": "NLP鲁棒性胜利中的疑虑耳语",
    "translated_abstract": "随着 NLP 机型的不断增大和性能提升，NLP长期存在的鲁棒性问题是否得到解决？我们使用20多个不同大小的模型，涵盖不同的架构选择和预训练目标，来调查这个问题。我们使用（a）领域外和挑战性测试集，（b）CheckLists行为测试，（c）对比集，和（d）对抗性输入进行评估。我们的分析显示并非所有领域外测试都能提供鲁棒性的见解。使用CheckLists和对比集进行评估显示模型性能存在显著差距；仅仅扩大模型规模并不能使其足够鲁棒。最后，我们指出目前用于对模型进行对抗性评估的方法本身存在问题：它们很容易受到破坏，并且在当前形式下不足以深入探究模型的鲁棒性。我们得出结论，NLP的鲁棒性问题不仅尚未解决，甚至一些",
    "tldr": "NLP模型的增大和性能提升并不能解决其鲁棒性问题，当前的方法和评估仍存在重大缺陷。",
    "en_tdlr": "The increase in size and performance of NLP models does not solve their robustness issues, and current methods and evaluations still have significant gaps."
}