{
    "title": "Are These the Same Apple? Comparing Images Based on Object Intrinsics. (arXiv:2311.00750v1 [cs.CV])",
    "abstract": "The human visual system can effortlessly recognize an object under different extrinsic factors such as lighting, object poses, and background, yet current computer vision systems often struggle with these variations. An important step to understanding and improving artificial vision systems is to measure image similarity purely based on intrinsic object properties that define object identity. This problem has been studied in the computer vision literature as re-identification, though mostly restricted to specific object categories such as people and cars. We propose to extend it to general object categories, exploring an image similarity metric based on object intrinsics. To benchmark such measurements, we collect the Common paired objects Under differenT Extrinsics (CUTE) dataset of $18,000$ images of $180$ objects under different extrinsic factors such as lighting, poses, and imaging conditions. While existing methods such as LPIPS and CLIP scores do not measure object intrinsics wel",
    "link": "http://arxiv.org/abs/2311.00750",
    "context": "Title: Are These the Same Apple? Comparing Images Based on Object Intrinsics. (arXiv:2311.00750v1 [cs.CV])\nAbstract: The human visual system can effortlessly recognize an object under different extrinsic factors such as lighting, object poses, and background, yet current computer vision systems often struggle with these variations. An important step to understanding and improving artificial vision systems is to measure image similarity purely based on intrinsic object properties that define object identity. This problem has been studied in the computer vision literature as re-identification, though mostly restricted to specific object categories such as people and cars. We propose to extend it to general object categories, exploring an image similarity metric based on object intrinsics. To benchmark such measurements, we collect the Common paired objects Under differenT Extrinsics (CUTE) dataset of $18,000$ images of $180$ objects under different extrinsic factors such as lighting, poses, and imaging conditions. While existing methods such as LPIPS and CLIP scores do not measure object intrinsics wel",
    "path": "papers/23/11/2311.00750.json",
    "total_tokens": 865,
    "translated_title": "这些是同一个苹果吗？基于物体内在特性比较图像",
    "translated_abstract": "人类视觉系统可以轻松识别在不同的外在因素下（如光照、物体姿势和背景）的对象，然而当前的计算机视觉系统在这些变异方面经常遇到困难。理解和改进人工视觉系统的重要一步是纯基于定义对象身份的内在物体特性来测量图像相似性。这个问题在计算机视觉文献中已被研究为重新识别，尽管主要局限于特定的对象类别如人和汽车。我们提出将其扩展到通用对象类别，探索基于物体内在特性的图像相似度度量。为了评估这种测量方法，我们收集了Common paired objects Under differenT Extrinsics (CUTE)数据集，包括180个对象的18000张图像，涵盖了不同的外在因素，如光照、姿势和成像条件。然而，现有的方法如LPIPS和CLIP分数并不能很好地测量物体内在特性。",
    "tldr": "本研究提出了一种基于物体内在特性的图像相似度度量方法，通过对通用对象类别进行扩展，并收集了大规模的CUTE数据集来评估该方法。",
    "en_tdlr": "This study proposes a method for measuring image similarity based on object intrinsics, extending it to general object categories and evaluating it using the large-scale CUTE dataset."
}