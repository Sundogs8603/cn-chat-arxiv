{
    "title": "CLEAN-EVAL: Clean Evaluation on Contaminated Large Language Models",
    "abstract": "arXiv:2311.09154v2 Announce Type: replace  Abstract: We are currently in an era of fierce competition among various large language models (LLMs) continuously pushing the boundaries of benchmark performance. However, genuinely assessing the capabilities of these LLMs has become a challenging and critical issue due to potential data contamination, and it wastes dozens of time and effort for researchers and engineers to download and try those contaminated models. To save our precious time, we propose a novel and useful method, Clean-Eval, which mitigates the issue of data contamination and evaluates the LLMs in a cleaner manner. Clean-Eval employs an LLM to paraphrase and back-translate the contaminated data into a candidate set, generating expressions with the same meaning but in different surface forms. A semantic detector is then used to filter the generated low-quality samples to narrow down this candidate set. The best candidate is finally selected from this set based on the BLEURT s",
    "link": "https://arxiv.org/abs/2311.09154",
    "context": "Title: CLEAN-EVAL: Clean Evaluation on Contaminated Large Language Models\nAbstract: arXiv:2311.09154v2 Announce Type: replace  Abstract: We are currently in an era of fierce competition among various large language models (LLMs) continuously pushing the boundaries of benchmark performance. However, genuinely assessing the capabilities of these LLMs has become a challenging and critical issue due to potential data contamination, and it wastes dozens of time and effort for researchers and engineers to download and try those contaminated models. To save our precious time, we propose a novel and useful method, Clean-Eval, which mitigates the issue of data contamination and evaluates the LLMs in a cleaner manner. Clean-Eval employs an LLM to paraphrase and back-translate the contaminated data into a candidate set, generating expressions with the same meaning but in different surface forms. A semantic detector is then used to filter the generated low-quality samples to narrow down this candidate set. The best candidate is finally selected from this set based on the BLEURT s",
    "path": "papers/23/11/2311.09154.json",
    "total_tokens": 892,
    "translated_title": "CLEAN-EVAL：清洁评估污染大型语言模型",
    "translated_abstract": "我们目前正处于各种大型语言模型（LLM）激烈竞争的时代，不断推动基准性能的边界。然而，由于潜在的数据污染，真正评估这些LLM的能力已经成为一个具有挑战性和关键性的问题，研究人员和工程师需要花费大量时间和精力下载和尝试这些受污染的模型。为了节省宝贵的时间，我们提出了一种新颖而有用的方法，Clean-Eval，它可以减轻数据污染问题，并以更整洁的方式评估LLM。Clean-Eval利用LLM对受污染数据进行释义和反向翻译，生成具有相同含义但不同表面形式的表达。然后使用语义检测器过滤生成的低质量样本，缩小候选集。最终从这个候选集中基于BLEURT得分选择最佳候选。",
    "tldr": "Clean-Eval提出了一种清洁评估方法，通过LLM对污染数据进行释义和反向翻译，利用语义检测器过滤低质量样本，最终选择最佳候选，解决了大型语言模型评估中的数据污染问题。",
    "en_tdlr": "Clean-Eval proposes a clean evaluation method that tackles data contamination in assessing large language models by using LLM to paraphrase and back-translate contaminated data, filtering low-quality samples with a semantic detector, and selecting the best candidate based on BLEURT scores."
}