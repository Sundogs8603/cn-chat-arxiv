{
    "title": "Physics-Informed Generator-Encoder Adversarial Networks with Latent Space Matching for Stochastic Differential Equations. (arXiv:2311.01708v1 [cs.LG])",
    "abstract": "We propose a new class of physics-informed neural networks, called Physics-Informed Generator-Encoder Adversarial Networks, to effectively address the challenges posed by forward, inverse, and mixed problems in stochastic differential equations. In these scenarios, while the governing equations are known, the available data consist of only a limited set of snapshots for system parameters. Our model consists of two key components: the generator and the encoder, both updated alternately by gradient descent. In contrast to previous approaches of directly matching the approximated solutions with real snapshots, we employ an indirect matching that operates within the lower-dimensional latent feature space. This method circumvents challenges associated with high-dimensional inputs and complex data distributions, while yielding more accurate solutions compared to existing neural network solvers. In addition, the approach also mitigates the training instability issues encountered in previous a",
    "link": "http://arxiv.org/abs/2311.01708",
    "context": "Title: Physics-Informed Generator-Encoder Adversarial Networks with Latent Space Matching for Stochastic Differential Equations. (arXiv:2311.01708v1 [cs.LG])\nAbstract: We propose a new class of physics-informed neural networks, called Physics-Informed Generator-Encoder Adversarial Networks, to effectively address the challenges posed by forward, inverse, and mixed problems in stochastic differential equations. In these scenarios, while the governing equations are known, the available data consist of only a limited set of snapshots for system parameters. Our model consists of two key components: the generator and the encoder, both updated alternately by gradient descent. In contrast to previous approaches of directly matching the approximated solutions with real snapshots, we employ an indirect matching that operates within the lower-dimensional latent feature space. This method circumvents challenges associated with high-dimensional inputs and complex data distributions, while yielding more accurate solutions compared to existing neural network solvers. In addition, the approach also mitigates the training instability issues encountered in previous a",
    "path": "papers/23/11/2311.01708.json",
    "total_tokens": 917,
    "translated_title": "基于物理知识的生成器-编码器对抗网络和潜在空间匹配的随机微分方程研究",
    "translated_abstract": "我们提出了一种新型的基于物理知识的神经网络，称为基于物理知识的生成器-编码器对抗网络，来有效解决随机微分方程中正向、反向和混合问题所带来的挑战。在这些情况下，虽然统治方程已知，但可用的数据仅由系统参数的有限快照组成。我们的模型包括两个关键组件：生成器和编码器，两者都通过梯度下降交替更新。与直接匹配近似解与真实快照的先前方法不同，我们采用了低维潜在特征空间内的间接匹配。这种方法避免了高维输入和复杂数据分布所带来的挑战，同时相比现有的神经网络求解器产生了更精确的解决方案。此外，该方法还减轻了先前方法中遇到的训练不稳定性问题。",
    "tldr": "我们提出了一种基于物理知识的生成器-编码器对抗网络和潜在空间匹配的新方法，用于解决随机微分方程中的正向、反向和混合问题。与现有方法相比，我们的模型通过间接匹配潜在特征空间，有效避免高维输入和复杂数据分布所带来的挑战，并提供更精确的解决方案。此外，该方法还减轻了训练不稳定性问题。"
}