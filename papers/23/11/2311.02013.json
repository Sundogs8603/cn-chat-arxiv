{
    "title": "Score Models for Offline Goal-Conditioned Reinforcement Learning. (arXiv:2311.02013v1 [cs.LG])",
    "abstract": "Offline Goal-Conditioned Reinforcement Learning (GCRL) is tasked with learning to achieve multiple goals in an environment purely from offline datasets using sparse reward functions. Offline GCRL is pivotal for developing generalist agents capable of leveraging pre-existing datasets to learn diverse and reusable skills without hand-engineering reward functions. However, contemporary approaches to GCRL based on supervised learning and contrastive learning are often suboptimal in the offline setting. An alternative perspective on GCRL optimizes for occupancy matching, but necessitates learning a discriminator, which subsequently serves as a pseudo-reward for downstream RL. Inaccuracies in the learned discriminator can cascade, negatively influencing the resulting policy. We present a novel approach to GCRL under a new lens of mixture-distribution matching, leading to our discriminator-free method: SMORe. The key insight is combining the occupancy matching perspective of GCRL with a conve",
    "link": "http://arxiv.org/abs/2311.02013",
    "context": "Title: Score Models for Offline Goal-Conditioned Reinforcement Learning. (arXiv:2311.02013v1 [cs.LG])\nAbstract: Offline Goal-Conditioned Reinforcement Learning (GCRL) is tasked with learning to achieve multiple goals in an environment purely from offline datasets using sparse reward functions. Offline GCRL is pivotal for developing generalist agents capable of leveraging pre-existing datasets to learn diverse and reusable skills without hand-engineering reward functions. However, contemporary approaches to GCRL based on supervised learning and contrastive learning are often suboptimal in the offline setting. An alternative perspective on GCRL optimizes for occupancy matching, but necessitates learning a discriminator, which subsequently serves as a pseudo-reward for downstream RL. Inaccuracies in the learned discriminator can cascade, negatively influencing the resulting policy. We present a novel approach to GCRL under a new lens of mixture-distribution matching, leading to our discriminator-free method: SMORe. The key insight is combining the occupancy matching perspective of GCRL with a conve",
    "path": "papers/23/11/2311.02013.json",
    "total_tokens": 933,
    "translated_title": "离线目标条件强化学习的评分模型",
    "translated_abstract": "离线目标条件强化学习（GCRL）的任务是使用稀疏奖励函数从离线数据集中学习在环境中实现多个目标。离线GCRL对于开发能够利用预先存在的数据集学习多样化和可复用技能的通用型代理至关重要，而无需手工设计奖励函数。然而，基于监督学习和对比学习的现代GCRL方法在离线环境中往往不太理想。GCRL的另一种观点是优化占有匹配，但需要学习鉴别器，随后该鉴别器作为下游强化学习的伪奖励。学习到的鉴别器的不准确性可能会导致负面影响，进而影响生成的策略。我们提出了一种新颖的GCRL方法，基于混合分布匹配的新视角，采用无鉴别器的方法：SMORe。关键洞见是将GCRL的占有匹配视角与一个有效的聚类算法相结合，从而得到了我们的无鉴别器方法：SMORe。",
    "tldr": "本文提出了一种新颖的离线目标条件强化学习方法，称为SMORe，它将占有匹配的视角与混合分布匹配相结合，无需学习鉴别器，从而提高了GCRL在离线环境中的表现。"
}