{
    "title": "Conformalized Deep Splines for Optimal and Efficient Prediction Sets. (arXiv:2311.00774v1 [cs.LG])",
    "abstract": "Uncertainty estimation is critical in high-stakes machine learning applications. One effective way to estimate uncertainty is conformal prediction, which can provide predictive inference with statistical coverage guarantees. We present a new conformal regression method, Spline Prediction Intervals via Conformal Estimation (SPICE), that estimates the conditional density using neural-network-parameterized splines. We prove universal approximation and optimality results for SPICE, which are empirically validated by our experiments. SPICE is compatible with two different efficient-to-compute conformal scores, one oracle-optimal for marginal coverage (SPICE-ND) and the other asymptotically optimal for conditional coverage (SPICE-HPD). Results on benchmark datasets demonstrate SPICE-ND models achieve the smallest average prediction set sizes, including average size reductions of nearly 50% for some datasets compared to the next best baseline. SPICE-HPD models achieve the best conditional cov",
    "link": "http://arxiv.org/abs/2311.00774",
    "context": "Title: Conformalized Deep Splines for Optimal and Efficient Prediction Sets. (arXiv:2311.00774v1 [cs.LG])\nAbstract: Uncertainty estimation is critical in high-stakes machine learning applications. One effective way to estimate uncertainty is conformal prediction, which can provide predictive inference with statistical coverage guarantees. We present a new conformal regression method, Spline Prediction Intervals via Conformal Estimation (SPICE), that estimates the conditional density using neural-network-parameterized splines. We prove universal approximation and optimality results for SPICE, which are empirically validated by our experiments. SPICE is compatible with two different efficient-to-compute conformal scores, one oracle-optimal for marginal coverage (SPICE-ND) and the other asymptotically optimal for conditional coverage (SPICE-HPD). Results on benchmark datasets demonstrate SPICE-ND models achieve the smallest average prediction set sizes, including average size reductions of nearly 50% for some datasets compared to the next best baseline. SPICE-HPD models achieve the best conditional cov",
    "path": "papers/23/11/2311.00774.json",
    "total_tokens": 897,
    "translated_title": "深度样条在最优和高效预测集中的一致化应用",
    "translated_abstract": "在高风险的机器学习应用中，不确定性估计是至关重要的。一种有效的估计不确定性的方法是一致化预测，它可以提供带有统计覆盖保证的预测推断。我们提出了一种新的一致化回归方法，通过神经网络参数化样条估计条件密度的样条预测区间（SPICE）。我们证明了SPICE的普适逼近和最优性结果，并通过我们的实验进行了实证验证。SPICE兼容两种不同的高效计算的一致化评分，一种是对于边际覆盖率的理论最优（SPICE-ND），另一种是对于条件覆盖率渐近最优（SPICE-HPD）。基准数据集的结果表明，SPICE-ND模型实现了最小的平均预测集大小，某些数据集的平均大小减少了近50%，与其他基准相比。SPICE-HPD模型实现了最佳的条件覆盖率。",
    "tldr": "该论文提出了一种新的一致化回归方法，通过神经网络参数化样条估计条件密度的样条预测区间，证明了其普适逼近和最优性，实验结果表明在基准数据集上表现出色。",
    "en_tdlr": "This paper presents a novel conformal regression method, SPICE, which estimates the conditional density using neural-network-parameterized splines. It proves the universal approximation and optimality of SPICE, and the experimental results demonstrate its outstanding performance on benchmark datasets."
}