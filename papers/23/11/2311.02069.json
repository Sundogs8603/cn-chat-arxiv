{
    "title": "Grounded Intuition of GPT-Vision's Abilities with Scientific Images. (arXiv:2311.02069v1 [cs.CL])",
    "abstract": "GPT-Vision has impressed us on a range of vision-language tasks, but it comes with the familiar new challenge: we have little idea of its capabilities and limitations. In our study, we formalize a process that many have instinctively been trying already to develop \"grounded intuition\" of this new model. Inspired by the recent movement away from benchmarking in favor of example-driven qualitative evaluation, we draw upon grounded theory and thematic analysis in social science and human-computer interaction to establish a rigorous framework for qualitative evaluation in natural language processing. We use our technique to examine alt text generation for scientific figures, finding that GPT-Vision is particularly sensitive to prompting, counterfactual text in images, and relative spatial relationships. Our method and analysis aim to help researchers ramp up their own grounded intuitions of new models while exposing how GPT-Vision can be applied to make information more accessible.",
    "link": "http://arxiv.org/abs/2311.02069",
    "context": "Title: Grounded Intuition of GPT-Vision's Abilities with Scientific Images. (arXiv:2311.02069v1 [cs.CL])\nAbstract: GPT-Vision has impressed us on a range of vision-language tasks, but it comes with the familiar new challenge: we have little idea of its capabilities and limitations. In our study, we formalize a process that many have instinctively been trying already to develop \"grounded intuition\" of this new model. Inspired by the recent movement away from benchmarking in favor of example-driven qualitative evaluation, we draw upon grounded theory and thematic analysis in social science and human-computer interaction to establish a rigorous framework for qualitative evaluation in natural language processing. We use our technique to examine alt text generation for scientific figures, finding that GPT-Vision is particularly sensitive to prompting, counterfactual text in images, and relative spatial relationships. Our method and analysis aim to help researchers ramp up their own grounded intuitions of new models while exposing how GPT-Vision can be applied to make information more accessible.",
    "path": "papers/23/11/2311.02069.json",
    "total_tokens": 951,
    "translated_title": "使用科学图像来揭示GPT-Vision的能力的基于直觉的研究",
    "translated_abstract": "GPT-Vision在许多视觉语言任务上给我们留下了深刻印象，但也带来了一个常见的新挑战：我们对其能力和限制几乎一无所知。在本研究中，我们规范化了一种许多人本能地试图培养对这个新模型的“基于直觉”理解的过程。受到远离基准测试而倾向于基于示例的定性评估的最新趋势的启发，我们借鉴了社会科学和人机交互中的扎根理论和主题分析，建立了一个严格的自然语言处理定性评估框架。我们使用这种技术来研究科学图像的替代文本生成，发现GPT-Vision对提示、图像中的反事实文本和相对空间关系特别敏感。我们的方法和分析旨在帮助研究人员加快对新模型的基于直觉的理解，同时展示GPT-Vision如何应用于使信息更易于获取。",
    "tldr": "本研究使用基于示例的定性评估方法，发现GPT-Vision在科学图像的替代文本生成方面表现出对提示、反事实文本和相对空间关系的敏感性。这有助于加快研究人员对新模型的直观理解，并展示GPT-Vision如何提高信息可访问性。",
    "en_tdlr": "This study employs example-driven qualitative evaluation and finds that GPT-Vision shows sensitivity to prompting, counterfactual text, and relative spatial relationships in alt text generation for scientific figures. This helps researchers develop intuitive understanding of new models and demonstrates how GPT-Vision can improve information accessibility."
}