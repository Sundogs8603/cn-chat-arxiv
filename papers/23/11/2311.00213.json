{
    "title": "Consistent Video-to-Video Transfer Using Synthetic Dataset. (arXiv:2311.00213v1 [cs.CV])",
    "abstract": "We introduce a novel and efficient approach for text-based video-to-video editing that eliminates the need for resource-intensive per-video-per-model finetuning. At the core of our approach is a synthetic paired video dataset tailored for video-to-video transfer tasks. Inspired by Instruct Pix2Pix's image transfer via editing instruction, we adapt this paradigm to the video domain. Extending the Prompt-to-Prompt to videos, we efficiently generate paired samples, each with an input video and its edited counterpart. Alongside this, we introduce the Long Video Sampling Correction during sampling, ensuring consistent long videos across batches. Our method surpasses current methods like Tune-A-Video, heralding substantial progress in text-based video-to-video editing and suggesting exciting avenues for further exploration and deployment.",
    "link": "http://arxiv.org/abs/2311.00213",
    "context": "Title: Consistent Video-to-Video Transfer Using Synthetic Dataset. (arXiv:2311.00213v1 [cs.CV])\nAbstract: We introduce a novel and efficient approach for text-based video-to-video editing that eliminates the need for resource-intensive per-video-per-model finetuning. At the core of our approach is a synthetic paired video dataset tailored for video-to-video transfer tasks. Inspired by Instruct Pix2Pix's image transfer via editing instruction, we adapt this paradigm to the video domain. Extending the Prompt-to-Prompt to videos, we efficiently generate paired samples, each with an input video and its edited counterpart. Alongside this, we introduce the Long Video Sampling Correction during sampling, ensuring consistent long videos across batches. Our method surpasses current methods like Tune-A-Video, heralding substantial progress in text-based video-to-video editing and suggesting exciting avenues for further exploration and deployment.",
    "path": "papers/23/11/2311.00213.json",
    "total_tokens": 857,
    "translated_title": "使用合成数据集实现一致的视频到视频转换",
    "translated_abstract": "我们引入了一种新颖高效的基于文本的视频到视频编辑方法，消除了每个视频每个模型的资源密集型微调需求。我们方法的核心是一个为视频到视频转换任务量身定制的合成配对视频数据集。受到Instruct Pix2Pix的图像通过编辑指令进行转换的启发，我们将这一范式应用于视频领域。我们对Prompt-to-Prompt进行了拓展，高效生成配对样本，每个样本都包含一个输入视频和其编辑后的对应视频。同时，在采样过程中引入了长视频采样校正，确保批次之间的长视频一致性。我们的方法超过了当前的Tune-A-Video等方法，在基于文本的视频到视频编辑方面取得了显著的进展，并为进一步的研究和应用提供了有趣的探索方向。",
    "tldr": "本研究提出一种基于合成数据集的视频到视频转换方法，通过文本指令实现高效编辑，并通过引入长视频采样校正确保一致性。在基于文本的视频到视频编辑方面取得了显著进展，为进一步的研究和应用提供了有趣的探索方向。",
    "en_tdlr": "This work presents an efficient approach for text-based video-to-video editing using a synthetic dataset, enabling high-quality editing without the need for per-video-per-model finetuning. By extending the Prompt-to-Prompt paradigm to videos and introducing long video sampling correction, the method achieves consistent and improved results, surpassing existing methods and opening up new possibilities for exploration and deployment in this field."
}