{
    "title": "Towards Concept-Aware Large Language Models. (arXiv:2311.01866v1 [cs.CL])",
    "abstract": "Concepts play a pivotal role in various human cognitive functions, including learning, reasoning and communication. However, there is very little work on endowing machines with the ability to form and reason with concepts. In particular, state-of-the-art large language models (LLMs) work at the level of tokens, not concepts.  In this work, we analyze how well contemporary LLMs capture human concepts and their structure. We then discuss ways to develop concept-aware LLMs, taking place at different stages of the pipeline. We sketch a method for pretraining LLMs using concepts, and also explore the simpler approach that uses the output of existing LLMs. Despite its simplicity, our proof-of-concept is shown to better match human intuition, as well as improve the robustness of predictions. These preliminary results underscore the promise of concept-aware LLMs.",
    "link": "http://arxiv.org/abs/2311.01866",
    "context": "Title: Towards Concept-Aware Large Language Models. (arXiv:2311.01866v1 [cs.CL])\nAbstract: Concepts play a pivotal role in various human cognitive functions, including learning, reasoning and communication. However, there is very little work on endowing machines with the ability to form and reason with concepts. In particular, state-of-the-art large language models (LLMs) work at the level of tokens, not concepts.  In this work, we analyze how well contemporary LLMs capture human concepts and their structure. We then discuss ways to develop concept-aware LLMs, taking place at different stages of the pipeline. We sketch a method for pretraining LLMs using concepts, and also explore the simpler approach that uses the output of existing LLMs. Despite its simplicity, our proof-of-concept is shown to better match human intuition, as well as improve the robustness of predictions. These preliminary results underscore the promise of concept-aware LLMs.",
    "path": "papers/23/11/2311.01866.json",
    "total_tokens": 861,
    "translated_title": "朝着概念感知的大型语言模型",
    "translated_abstract": "概念在各种人类认知功能中起着关键作用，包括学习、推理和交流。然而，目前对于赋予机器形成和推理概念的能力的研究非常有限。尤其是，目前的大型语言模型（LLMs）主要在词元级别上操作，而不是概念级别。本文分析了当代LLMs对人类概念及其结构的捕捉能力，并讨论了在不同阶段中开发概念感知LLMs的方法。我们提出了一种使用概念进行预训练的LLMs方法，并探讨了使用现有LLMs输出的更简单方法。尽管简单，我们的概念验证证明了更好地匹配人类直觉，并提升了预测的鲁棒性。这些初步结果显示了概念感知LLMs的潜力。",
    "tldr": "本文研究了概念在语言模型中的作用，并探讨了开发概念感知语言模型的方法。通过预训练LLMs或使用现有LLMs的输出，我们证明了这种方法更好地符合人类直觉并改善了预测的鲁棒性。",
    "en_tdlr": "This paper investigates the role of concepts in language models and explores methods for developing concept-aware language models. By either pretraining LLMs using concepts or using the output of existing LLMs, our proof-of-concept demonstrates better alignment with human intuition and improved prediction robustness."
}