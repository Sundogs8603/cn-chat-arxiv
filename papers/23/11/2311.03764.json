{
    "title": "Neuro-GPT: Towards A Foundation Model for EEG",
    "abstract": "arXiv:2311.03764v4 Announce Type: replace  Abstract: To handle the scarcity and heterogeneity of electroencephalography (EEG) data for Brain-Computer Interface (BCI) tasks, and to harness the power of large publicly available data sets, we propose Neuro-GPT, a foundation model consisting of an EEG encoder and a GPT model. The foundation model is pre-trained on a large-scale data set using a self-supervised task that learns how to reconstruct masked EEG segments. We then fine-tune the model on a Motor Imagery Classification task to validate its performance in a low-data regime (9 subjects). Our experiments demonstrate that applying a foundation model can significantly improve classification performance compared to a model trained from scratch, which provides evidence for the generalizability of the foundation model and its ability to address challenges of data scarcity and heterogeneity in EEG. The code is publicly available at github.com/wenhui0206/NeuroGPT.",
    "link": "https://arxiv.org/abs/2311.03764",
    "context": "Title: Neuro-GPT: Towards A Foundation Model for EEG\nAbstract: arXiv:2311.03764v4 Announce Type: replace  Abstract: To handle the scarcity and heterogeneity of electroencephalography (EEG) data for Brain-Computer Interface (BCI) tasks, and to harness the power of large publicly available data sets, we propose Neuro-GPT, a foundation model consisting of an EEG encoder and a GPT model. The foundation model is pre-trained on a large-scale data set using a self-supervised task that learns how to reconstruct masked EEG segments. We then fine-tune the model on a Motor Imagery Classification task to validate its performance in a low-data regime (9 subjects). Our experiments demonstrate that applying a foundation model can significantly improve classification performance compared to a model trained from scratch, which provides evidence for the generalizability of the foundation model and its ability to address challenges of data scarcity and heterogeneity in EEG. The code is publicly available at github.com/wenhui0206/NeuroGPT.",
    "path": "papers/23/11/2311.03764.json",
    "total_tokens": 861,
    "translated_title": "Neuro-GPT: 面向EEG的基础模型",
    "translated_abstract": "为了处理脑机接口（BCI）任务中脑电图（EEG）数据的稀缺性和异质性，并利用大规模公开数据集的力量，我们提出了Neuro-GPT，这是一个由EEG编码器和GPT模型组成的基础模型。该基础模型在一个大规模数据集上进行自监督任务的预训练，学习如何重构被掩码的EEG片段。然后我们在动作想象分类任务上对模型进行微调，以验证其在低数据情境（9名受试者）中的性能。我们的实验证明，应用基础模型可以显著提高分类性能，相较于从头训练的模型，这为基础模型的泛化能力和它应对EEG数据稀缺性和异质性挑战的能力提供了证据。代码公开在github.com/wenhui0206/NeuroGPT。",
    "tldr": "Neuro-GPT是一个面向EEG数据的基础模型，通过自监督任务预训练和微调动作想象分类任务，显著改善分类性能，并展示了其泛化能力以解决EEG数据稀缺性和异质性挑战。",
    "en_tdlr": "Neuro-GPT is a foundation model for EEG data, pre-trained on self-supervised tasks and fine-tuned on motor imagery classification task, significantly improving classification performance and demonstrating its generalizability to address EEG data scarcity and heterogeneity challenges."
}