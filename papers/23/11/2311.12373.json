{
    "title": "Beyond Turing: A Comparative Analysis of Approaches for Detecting Machine-Generated Text. (arXiv:2311.12373v2 [cs.CL] UPDATED)",
    "abstract": "Significant progress has been made on text generation by pre-trained language models (PLMs), yet distinguishing between human and machine-generated text poses an escalating challenge. This paper offers an in-depth evaluation of three distinct methods used to address this task: traditional shallow learning, Language Model (LM) fine-tuning, and Multilingual Model fine-tuning. These approaches are rigorously tested on a wide range of machine-generated texts, providing a benchmark of their competence in distinguishing between human-authored and machine-authored linguistic constructs. The results reveal considerable differences in performance across methods, thus emphasizing the continued need for advancement in this crucial area of NLP. This study offers valuable insights and paves the way for future research aimed at creating robust and highly discriminative models.",
    "link": "http://arxiv.org/abs/2311.12373",
    "context": "Title: Beyond Turing: A Comparative Analysis of Approaches for Detecting Machine-Generated Text. (arXiv:2311.12373v2 [cs.CL] UPDATED)\nAbstract: Significant progress has been made on text generation by pre-trained language models (PLMs), yet distinguishing between human and machine-generated text poses an escalating challenge. This paper offers an in-depth evaluation of three distinct methods used to address this task: traditional shallow learning, Language Model (LM) fine-tuning, and Multilingual Model fine-tuning. These approaches are rigorously tested on a wide range of machine-generated texts, providing a benchmark of their competence in distinguishing between human-authored and machine-authored linguistic constructs. The results reveal considerable differences in performance across methods, thus emphasizing the continued need for advancement in this crucial area of NLP. This study offers valuable insights and paves the way for future research aimed at creating robust and highly discriminative models.",
    "path": "papers/23/11/2311.12373.json",
    "total_tokens": 824,
    "translated_title": "超越图灵: 检测机器生成文本的方法比较分析",
    "translated_abstract": "在预训练语言模型（PLMs）生成文本方面取得了显著进展，然而区分人类生成和机器生成的文本越来越具有挑战性。本论文对三种不同的方法进行了深入评估，用于解决这个任务：传统的浅层学习、语言模型（LM）微调和多语言模型微调。这些方法在广泛的机器生成文本上经过严格测试，提供了一个评估它们在区分人类和机器构造语言方面能力的基准。结果显示不同方法的性能存在显著差异，因此强调了在这一关键NLP领域的持续需求。本研究提供了有价值的见解，并为未来旨在创建强大且高度区分性模型的研究铺平了道路。",
    "tldr": "该论文对比了三种不同方法用于检测人类生成和机器生成文本的能力，并发现它们在性能上存在显著差异，为进一步研究和开发具有鲁棒性和高度区分性的模型提供了重要参考。",
    "en_tdlr": "This paper presents a comparative analysis of three different approaches for detecting human-authored and machine-authored text, revealing significant differences in performance and providing important insights for further research and development of robust and highly discriminative models."
}