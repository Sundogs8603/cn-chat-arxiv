{
    "title": "Inverse Problems with Learned Forward Operators",
    "abstract": "arXiv:2311.12528v2 Announce Type: replace-cross  Abstract: Solving inverse problems requires the knowledge of the forward operator, but accurate models can be computationally expensive and hence cheaper variants that do not compromise the reconstruction quality are desired. This chapter reviews reconstruction methods in inverse problems with learned forward operators that follow two different paradigms. The first one is completely agnostic to the forward operator and learns its restriction to the subspace spanned by the training data. The framework of regularisation by projection is then used to find a reconstruction. The second one uses a simplified model of the physics of the measurement process and only relies on the training data to learn a model correction. We present the theory of these two approaches and compare them numerically. A common theme emerges: both methods require, or at least benefit from, training data not only for the forward operator, but also for its adjoint.",
    "link": "https://arxiv.org/abs/2311.12528",
    "context": "Title: Inverse Problems with Learned Forward Operators\nAbstract: arXiv:2311.12528v2 Announce Type: replace-cross  Abstract: Solving inverse problems requires the knowledge of the forward operator, but accurate models can be computationally expensive and hence cheaper variants that do not compromise the reconstruction quality are desired. This chapter reviews reconstruction methods in inverse problems with learned forward operators that follow two different paradigms. The first one is completely agnostic to the forward operator and learns its restriction to the subspace spanned by the training data. The framework of regularisation by projection is then used to find a reconstruction. The second one uses a simplified model of the physics of the measurement process and only relies on the training data to learn a model correction. We present the theory of these two approaches and compare them numerically. A common theme emerges: both methods require, or at least benefit from, training data not only for the forward operator, but also for its adjoint.",
    "path": "papers/23/11/2311.12528.json",
    "total_tokens": 899,
    "translated_title": "具有学习正演算子的逆问题",
    "translated_abstract": "解决逆问题需要对正演算子有所了解，但准确的模型可能计算成本高昂，因此希望有不影响重建质量的更便宜的替代方案。本章回顾了采用具有学习正演算子的逆问题中的重建方法，遵循两种不同的范例。第一种对正演算子完全不可知，并学习其在由训练数据生成的子空间上的限制。然后使用投影正则化框架找到重建。第二种使用测量过程物理的简化模型，并仅依赖于训练数据来学习模型校正。我们介绍了这两种方法的理论并进行了数值比较。一个共同的主题出现：两种方法都需要或至少受益于训练数据不仅对于正演算子而且对于其共轭算子。",
    "tldr": "逆问题中使用的具有学习正演算子的方法分为两种：一种完全不考虑正演算子，学习其在训练数据子空间上的限制，另一种使用简化的物理模型并依赖于训练数据来学习模型修正。这两种方法都强调对正演算子及其共轭算子的训练数据的重要性。",
    "en_tdlr": "Methods with learned forward operators in inverse problems are divided into two categories: one completely disregards the forward operator, learning its restriction on the subspace spanned by training data, while the other uses a simplified physics model and relies on training data to learn model corrections. Both emphasize the importance of training data for both the forward operator and its adjoint."
}