{
    "title": "In Search of the Long-Tail: Systematic Generation of Long-Tail Inferential Knowledge via Logical Rule Guided Search",
    "abstract": "arXiv:2311.07237v2 Announce Type: replace-cross  Abstract: State-of-the-art LLMs outperform humans on reasoning tasks such as Natural Language Inference. Recent works evaluating LLMs note a marked performance drop on input data from the low-probability distribution, i.e., the longtail. Therefore, we focus on systematically generating statements involving long-tail inferential knowledge for more effective evaluation of LLMs in the reasoning space. We first propose a novel framework Logic-Induced- Knowledge-Search (LINK) that generates factually correct and long-tail knowledge statements grounded on symbolic rule templates; LINK effectively generates data in the longtail distribution that zero-shot prompted LLMs are unable to reach, and outperforms zero-shot GPT4 on factual correctness by 5%. We further use the data generated by LINK to construct a dataset Logic-Induced-Long-Tail (LINT) that can be used to evaluate downstream models on the long-tail distribution; LINT contains 108K knowl",
    "link": "https://arxiv.org/abs/2311.07237",
    "context": "Title: In Search of the Long-Tail: Systematic Generation of Long-Tail Inferential Knowledge via Logical Rule Guided Search\nAbstract: arXiv:2311.07237v2 Announce Type: replace-cross  Abstract: State-of-the-art LLMs outperform humans on reasoning tasks such as Natural Language Inference. Recent works evaluating LLMs note a marked performance drop on input data from the low-probability distribution, i.e., the longtail. Therefore, we focus on systematically generating statements involving long-tail inferential knowledge for more effective evaluation of LLMs in the reasoning space. We first propose a novel framework Logic-Induced- Knowledge-Search (LINK) that generates factually correct and long-tail knowledge statements grounded on symbolic rule templates; LINK effectively generates data in the longtail distribution that zero-shot prompted LLMs are unable to reach, and outperforms zero-shot GPT4 on factual correctness by 5%. We further use the data generated by LINK to construct a dataset Logic-Induced-Long-Tail (LINT) that can be used to evaluate downstream models on the long-tail distribution; LINT contains 108K knowl",
    "path": "papers/23/11/2311.07237.json",
    "total_tokens": 861,
    "translated_title": "在搜索长尾中：通过逻辑规则引导搜索系统性生成长尾推理知识",
    "translated_abstract": "最先进的LLMs在诸如自然语言推理等推理任务上胜过人类。最近评估LLMs的研究指出，在来自低概率分布——即长尾的输入数据上表现大幅下降。因此，我们专注于系统生成涉及长尾推理知识的语句，以更有效地评估LLMs在推理空间中的表现。我们首先提出了一个新颖的框架Logic-Induced-Knowledge-Search（LINK），该框架生成基于符号规则模板的事实正确且长尾知识语句；LINK有效地生成长尾分布数据，零-shot提示的LLMs无法到达，并且在事实正确性方面优于零-shot GPT4达到5%。我们进一步使用LINK生成的数据构建了一个名为Logic-Induced-Long-Tail（LINT）的数据集，可用于评估长尾分布上的下游模型；LINT包含108K个知识条目。",
    "tldr": "该研究提出了一个名为LINK的框架，能够系统性地生成长尾推理知识，从而更有效地评估LLMs在推理空间中的表现。"
}