{
    "title": "Improving Fairness using Vision-Language Driven Image Augmentation. (arXiv:2311.01573v1 [cs.CV])",
    "abstract": "Fairness is crucial when training a deep-learning discriminative model, especially in the facial domain. Models tend to correlate specific characteristics (such as age and skin color) with unrelated attributes (downstream tasks), resulting in biases which do not correspond to reality. It is common knowledge that these correlations are present in the data and are then transferred to the models during training. This paper proposes a method to mitigate these correlations to improve fairness. To do so, we learn interpretable and meaningful paths lying in the semantic space of a pre-trained diffusion model (DiffAE) -- such paths being supervised by contrastive text dipoles. That is, we learn to edit protected characteristics (age and skin color). These paths are then applied to augment images to improve the fairness of a given dataset. We test the proposed method on CelebA-HQ and UTKFace on several downstream tasks with age and skin color as protected characteristics. As a proxy for fairnes",
    "link": "http://arxiv.org/abs/2311.01573",
    "context": "Title: Improving Fairness using Vision-Language Driven Image Augmentation. (arXiv:2311.01573v1 [cs.CV])\nAbstract: Fairness is crucial when training a deep-learning discriminative model, especially in the facial domain. Models tend to correlate specific characteristics (such as age and skin color) with unrelated attributes (downstream tasks), resulting in biases which do not correspond to reality. It is common knowledge that these correlations are present in the data and are then transferred to the models during training. This paper proposes a method to mitigate these correlations to improve fairness. To do so, we learn interpretable and meaningful paths lying in the semantic space of a pre-trained diffusion model (DiffAE) -- such paths being supervised by contrastive text dipoles. That is, we learn to edit protected characteristics (age and skin color). These paths are then applied to augment images to improve the fairness of a given dataset. We test the proposed method on CelebA-HQ and UTKFace on several downstream tasks with age and skin color as protected characteristics. As a proxy for fairnes",
    "path": "papers/23/11/2311.01573.json",
    "total_tokens": 917,
    "translated_title": "使用视觉语言驱动的图像增强改善公平性",
    "translated_abstract": "在训练深度学习鉴别模型时，公平性是至关重要的，特别是在面部领域。模型往往将特定特征（如年龄和肤色）与无关属性（下游任务）相关联，导致偏见与现实不符。众所周知，这些相关性存在于数据中，然后在训练过程中传递给模型。本文提出了一种方法来减轻这些相关性，以提高公平性。为此，我们学习了在预训练扩散模型（DiffAE）的语义空间中位于可解释和有意义的路径，这些路径由对比性文本二极体进行监督。也就是说，我们学习了编辑受保护特征（年龄和肤色）。然后将这些路径应用于增强图像，以提高给定数据集的公平性。我们在CelebA-HQ和UTKFace上对年龄和肤色作为受保护特征的几个下游任务进行了该方法的测试。",
    "tldr": "本文提出了一种基于视觉语言驱动的图像增强方法，以改善训练深度学习模型中的公平性问题。通过学习和应用可解释的路径来编辑受保护特征，该方法成功减轻了数据中的相关性，提高了数据集的公平性。"
}