{
    "title": "NEO-KD: Knowledge-Distillation-Based Adversarial Training for Robust Multi-Exit Neural Networks. (arXiv:2311.00428v1 [cs.LG])",
    "abstract": "While multi-exit neural networks are regarded as a promising solution for making efficient inference via early exits, combating adversarial attacks remains a challenging problem. In multi-exit networks, due to the high dependency among different submodels, an adversarial example targeting a specific exit not only degrades the performance of the target exit but also reduces the performance of all other exits concurrently. This makes multi-exit networks highly vulnerable to simple adversarial attacks. In this paper, we propose NEO-KD, a knowledge-distillation-based adversarial training strategy that tackles this fundamental challenge based on two key contributions. NEO-KD first resorts to neighbor knowledge distillation to guide the output of the adversarial examples to tend to the ensemble outputs of neighbor exits of clean data. NEO-KD also employs exit-wise orthogonal knowledge distillation for reducing adversarial transferability across different submodels. The result is a significan",
    "link": "http://arxiv.org/abs/2311.00428",
    "context": "Title: NEO-KD: Knowledge-Distillation-Based Adversarial Training for Robust Multi-Exit Neural Networks. (arXiv:2311.00428v1 [cs.LG])\nAbstract: While multi-exit neural networks are regarded as a promising solution for making efficient inference via early exits, combating adversarial attacks remains a challenging problem. In multi-exit networks, due to the high dependency among different submodels, an adversarial example targeting a specific exit not only degrades the performance of the target exit but also reduces the performance of all other exits concurrently. This makes multi-exit networks highly vulnerable to simple adversarial attacks. In this paper, we propose NEO-KD, a knowledge-distillation-based adversarial training strategy that tackles this fundamental challenge based on two key contributions. NEO-KD first resorts to neighbor knowledge distillation to guide the output of the adversarial examples to tend to the ensemble outputs of neighbor exits of clean data. NEO-KD also employs exit-wise orthogonal knowledge distillation for reducing adversarial transferability across different submodels. The result is a significan",
    "path": "papers/23/11/2311.00428.json",
    "total_tokens": 974,
    "translated_title": "NEO-KD：基于知识蒸馏的对抗训练用于健壮的多出口神经网络",
    "translated_abstract": "尽管多出口神经网络被认为是通过提前退出来进行高效推理的有前途的解决方案，但对抗性攻击仍然是一个具有挑战性的问题。在多出口网络中，由于不同子模型之间的高依赖性，针对特定出口的对抗性示例不仅降低了目标出口的性能，同时也减少了所有其他出口的性能。这使得多出口网络对简单的对抗性攻击非常脆弱。在本文中，我们提出了NEO-KD，一种基于知识蒸馏的对抗训练策略，以应对这一基本挑战，其具有两个关键贡献。NEO-KD首先采用邻居知识蒸馏来引导对抗性示例的输出趋向于干净数据的邻居出口的集合输出。NEO-KD还使用出口间正交的知识蒸馏来减少不同子模型之间的对抗性传递性。结果是一个显著的",
    "tldr": "NEO-KD是一种基于知识蒸馏的对抗训练策略，用于提升多出口神经网络的对抗鲁棒性，通过邻居知识蒸馏和出口间正交知识蒸馏，该方法能够减少对特定出口的对抗攻击影响，并增强整体性能。",
    "en_tdlr": "NEO-KD is a knowledge-distillation-based adversarial training strategy for improving the adversarial robustness of multi-exit neural networks. It reduces the impact of adversarial attacks on specific exits and enhances overall performance through neighbor knowledge distillation and exit-wise orthogonal knowledge distillation."
}