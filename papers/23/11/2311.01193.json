{
    "title": "Contextual Confidence and Generative AI. (arXiv:2311.01193v1 [cs.AI])",
    "abstract": "Generative AI models perturb the foundations of effective human communication. They present new challenges to contextual confidence, disrupting participants' ability to identify the authentic context of communication and their ability to protect communication from reuse and recombination outside its intended context. In this paper, we describe strategies--tools, technologies and policies--that aim to stabilize communication in the face of these challenges. The strategies we discuss fall into two broad categories. Containment strategies aim to reassert context in environments where it is currently threatened--a reaction to the context-free expectations and norms established by the internet. Mobilization strategies, by contrast, view the rise of generative AI as an opportunity to proactively set new and higher expectations around privacy and authenticity in mediated communication.",
    "link": "http://arxiv.org/abs/2311.01193",
    "context": "Title: Contextual Confidence and Generative AI. (arXiv:2311.01193v1 [cs.AI])\nAbstract: Generative AI models perturb the foundations of effective human communication. They present new challenges to contextual confidence, disrupting participants' ability to identify the authentic context of communication and their ability to protect communication from reuse and recombination outside its intended context. In this paper, we describe strategies--tools, technologies and policies--that aim to stabilize communication in the face of these challenges. The strategies we discuss fall into two broad categories. Containment strategies aim to reassert context in environments where it is currently threatened--a reaction to the context-free expectations and norms established by the internet. Mobilization strategies, by contrast, view the rise of generative AI as an opportunity to proactively set new and higher expectations around privacy and authenticity in mediated communication.",
    "path": "papers/23/11/2311.01193.json",
    "total_tokens": 779,
    "translated_title": "上下文置信度和生成型人工智能",
    "translated_abstract": "生成型人工智能模型扰乱了有效人际沟通的基础，给上下文置信度带来新的挑战，使参与者难以确定沟通的真实上下文，并且保护沟通不被在意图之外的环境中重复使用和重组。本文描述了旨在在面对这些挑战时稳定沟通的策略-工具、技术和政策。我们讨论的策略可分为两个大类。遏制策略旨在在当前被威胁上下文自由的期望和规范的环境中重新确定上下文-这是对互联网所建立的无上下文期望和规范的一种反应。相反，动员策略将生成型人工智能的崛起视为在媒体沟通中主动建立隐私和真实性新期望的机会。",
    "tldr": "本文讨论了在面对生成型人工智能对上下文置信度的挑战时，采取的两类策略：遏制策略和动员策略。",
    "en_tdlr": "This paper discusses two strategies, containment and mobilization, to address the challenges to contextual confidence posed by generative AI models in effectively communicating and protecting communication in the intended context."
}