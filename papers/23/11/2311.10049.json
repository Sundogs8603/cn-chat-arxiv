{
    "title": "Inherently Interpretable Time Series Classification via Multiple Instance Learning",
    "abstract": "arXiv:2311.10049v3 Announce Type: replace-cross  Abstract: Conventional Time Series Classification (TSC) methods are often black boxes that obscure inherent interpretation of their decision-making processes. In this work, we leverage Multiple Instance Learning (MIL) to overcome this issue, and propose a new framework called MILLET: Multiple Instance Learning for Locally Explainable Time series classification. We apply MILLET to existing deep learning TSC models and show how they become inherently interpretable without compromising (and in some cases, even improving) predictive performance. We evaluate MILLET on 85 UCR TSC datasets and also present a novel synthetic dataset that is specially designed to facilitate interpretability evaluation. On these datasets, we show MILLET produces sparse explanations quickly that are of higher quality than other well-known interpretability methods. To the best of our knowledge, our work with MILLET, which is available on GitHub (https://github.com/J",
    "link": "https://arxiv.org/abs/2311.10049",
    "context": "Title: Inherently Interpretable Time Series Classification via Multiple Instance Learning\nAbstract: arXiv:2311.10049v3 Announce Type: replace-cross  Abstract: Conventional Time Series Classification (TSC) methods are often black boxes that obscure inherent interpretation of their decision-making processes. In this work, we leverage Multiple Instance Learning (MIL) to overcome this issue, and propose a new framework called MILLET: Multiple Instance Learning for Locally Explainable Time series classification. We apply MILLET to existing deep learning TSC models and show how they become inherently interpretable without compromising (and in some cases, even improving) predictive performance. We evaluate MILLET on 85 UCR TSC datasets and also present a novel synthetic dataset that is specially designed to facilitate interpretability evaluation. On these datasets, we show MILLET produces sparse explanations quickly that are of higher quality than other well-known interpretability methods. To the best of our knowledge, our work with MILLET, which is available on GitHub (https://github.com/J",
    "path": "papers/23/11/2311.10049.json",
    "total_tokens": 843,
    "translated_title": "通过多例学习实现内在可解释的时间序列分类",
    "translated_abstract": "传统的时间序列分类（TSC）方法通常是黑匣子，难以理解其决策过程。在这项工作中，我们利用多例学习（MIL）来解决这个问题，并提出了一个名为MILLET的新框架：用于本地可解释时间序列分类的多例学习。我们将MILLET应用于现有的深度学习TSC模型，并展示它们如何变得内在可解释，而不会影响（在某些情况下，甚至提高）预测性能。我们在85个UCR TSC数据集上评估了MILLET，并提出了一个特别设计的新颖合成数据集，以促进可解释性评估。在这些数据集上，我们展示MILLET能够快速产生比其他众所周知的可解释性方法更高质量的稀疏解释。",
    "tldr": "通过多例学习提出了一个新框架MILLET，使现有的深度学习时间序列分类模型变得内在可解释，同时不影响甚至改进预测性能，并在多个数据集上展示出比其他方法更高质量的稀疏解释。",
    "en_tdlr": "Introduced a new framework MILLET using Multiple Instance Learning to make existing deep learning time series classification models inherently interpretable without compromising or even improving predictive performance, demonstrating higher quality sparse explanations on multiple datasets compared to other methods."
}