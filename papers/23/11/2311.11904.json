{
    "title": "LLMs as Visual Explainers: Advancing Image Classification with Evolving Visual Descriptions",
    "abstract": "arXiv:2311.11904v2 Announce Type: replace-cross  Abstract: Vision-language models (VLMs) offer a promising paradigm for image classification by comparing the similarity between images and class embeddings. A critical challenge lies in crafting precise textual representations for class names. While previous studies have leveraged recent advancements in large language models (LLMs) to enhance these descriptors, their outputs often suffer from ambiguity and inaccuracy. We attribute this to two primary factors: 1) the reliance on single-turn textual interactions with LLMs, leading to a mismatch between generated text and visual concepts for VLMs; 2) the oversight of the inter-class relationships, resulting in descriptors that fail to differentiate similar classes effectively. In this paper, we propose a novel framework that integrates LLMs and VLMs to find the optimal class descriptors. Our training-free approach develops an LLM-based agent with an evolutionary optimization strategy to ite",
    "link": "https://arxiv.org/abs/2311.11904",
    "context": "Title: LLMs as Visual Explainers: Advancing Image Classification with Evolving Visual Descriptions\nAbstract: arXiv:2311.11904v2 Announce Type: replace-cross  Abstract: Vision-language models (VLMs) offer a promising paradigm for image classification by comparing the similarity between images and class embeddings. A critical challenge lies in crafting precise textual representations for class names. While previous studies have leveraged recent advancements in large language models (LLMs) to enhance these descriptors, their outputs often suffer from ambiguity and inaccuracy. We attribute this to two primary factors: 1) the reliance on single-turn textual interactions with LLMs, leading to a mismatch between generated text and visual concepts for VLMs; 2) the oversight of the inter-class relationships, resulting in descriptors that fail to differentiate similar classes effectively. In this paper, we propose a novel framework that integrates LLMs and VLMs to find the optimal class descriptors. Our training-free approach develops an LLM-based agent with an evolutionary optimization strategy to ite",
    "path": "papers/23/11/2311.11904.json",
    "total_tokens": 679,
    "translated_title": "LLMs作为视觉解释器：通过不断演进的视觉描述提升图像分类",
    "translated_abstract": "视觉语言模型（VLMs）通过比较图像与类别嵌入之间的相似性，为图像分类提供了一种有前途的范式。一个关键的挑战在于为类别名称构建精确的文本表示。本文提出了一种集成LLMs和VLMs的新框架，以找到最佳的类别描述符。",
    "tldr": "提出了一种集成LLMs和VLMs的框架，以找到最佳的类别描述符，解决了图像分类中在精确构建文本表示和区分相似类别方面的挑战",
    "en_tdlr": "Proposed a framework integrating LLMs and VLMs to find optimal class descriptors, addressing challenges in crafting precise textual representations and differentiating similar classes in image classification."
}