{
    "title": "TopicGPT: A Prompt-based Topic Modeling Framework",
    "abstract": "arXiv:2311.01449v2 Announce Type: replace  Abstract: Topic modeling is a well-established technique for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require \"reading the tea leaves\" to interpret; additionally, they offer users minimal control over the formatting and specificity of resulting topics. To tackle these issues, we introduce TopicGPT, a prompt-based framework that uses large language models (LLMs) to uncover latent topics in a text collection. TopicGPT produces topics that align better with human categorizations compared to competing methods: it achieves a harmonic mean purity of 0.74 against human-annotated Wikipedia topics compared to 0.64 for the strongest baseline. Its topics are also interpretable, dispensing with ambiguous bags of words in favor of topics with natural language labels and associated free-form descriptions. Moreover, the framework is highly adaptable, allowing users to specify constraints and m",
    "link": "https://arxiv.org/abs/2311.01449",
    "context": "Title: TopicGPT: A Prompt-based Topic Modeling Framework\nAbstract: arXiv:2311.01449v2 Announce Type: replace  Abstract: Topic modeling is a well-established technique for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require \"reading the tea leaves\" to interpret; additionally, they offer users minimal control over the formatting and specificity of resulting topics. To tackle these issues, we introduce TopicGPT, a prompt-based framework that uses large language models (LLMs) to uncover latent topics in a text collection. TopicGPT produces topics that align better with human categorizations compared to competing methods: it achieves a harmonic mean purity of 0.74 against human-annotated Wikipedia topics compared to 0.64 for the strongest baseline. Its topics are also interpretable, dispensing with ambiguous bags of words in favor of topics with natural language labels and associated free-form descriptions. Moreover, the framework is highly adaptable, allowing users to specify constraints and m",
    "path": "papers/23/11/2311.01449.json",
    "total_tokens": 875,
    "translated_title": "TopicGPT: 一个基于提示的主题建模框架",
    "translated_abstract": "主题建模是一种用于探索文本语料库的成熟技术。传统的主题模型（例如，LDA）将主题表示为词袋，通常需要“阅读茶叶”来解释；另外，它们对于用户控制生成主题的格式和特定性的程度很小。为了解决这些问题，我们引入了TopicGPT，这是一个基于提示的框架，利用大型语言模型（LLMs）来揭示文本集合中的潜在主题。与竞争方法相比，TopicGPT产生的主题更符合人类分类：与最强基线的0.64相比，它在与人工标记的维基百科主题比对中达到了0.74的谐波纯度。它的主题也是可解释的，取代了含糊的词袋，转而使用自然语言标签和相关的自由形式描述。此外，该框架非常适应，允许用户指定约束和控制主题的特定性。",
    "tldr": "TopicGPT是一个基于提示的主题建模框架，使用大型语言模型来生成与人类分类更符合的并且可解释的主题，相比竞争方法在谐波纯度上有显著提升。",
    "en_tdlr": "TopicGPT is a prompt-based topic modeling framework that uses large language models to generate topics that align better with human categorizations and are interpretable, showing a significant improvement in harmonic mean purity compared to competing methods."
}