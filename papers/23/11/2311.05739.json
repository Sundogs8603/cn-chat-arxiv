{
    "title": "Deep Learning Architecture for Network-Efficiency at the Edge. (arXiv:2311.05739v3 [cs.NI] UPDATED)",
    "abstract": "The growing number of AI-driven applications in the mobile devices has led to solutions that integrate deep learning models with the available edge-cloud resources; due to multiple benefits such as reduction in on-device energy consumption, improved latency, improved network usage, and certain privacy improvements, split learning, where deep learning models are split away from the mobile device and computed in a distributed manner, has become an extensively explored topic. Combined with compression-aware methods where learning adapts to compression of communicated data, the benefits of this approach have further improved and could serve as an alternative to established approaches like federated learning methods. In this work, we develop an adaptive compression-aware split learning method ('deprune') to improve and train deep learning models so that they are much more network-efficient (use less network resources and are faster), which would make them ideal to deploy in weaker devices w",
    "link": "http://arxiv.org/abs/2311.05739",
    "context": "Title: Deep Learning Architecture for Network-Efficiency at the Edge. (arXiv:2311.05739v3 [cs.NI] UPDATED)\nAbstract: The growing number of AI-driven applications in the mobile devices has led to solutions that integrate deep learning models with the available edge-cloud resources; due to multiple benefits such as reduction in on-device energy consumption, improved latency, improved network usage, and certain privacy improvements, split learning, where deep learning models are split away from the mobile device and computed in a distributed manner, has become an extensively explored topic. Combined with compression-aware methods where learning adapts to compression of communicated data, the benefits of this approach have further improved and could serve as an alternative to established approaches like federated learning methods. In this work, we develop an adaptive compression-aware split learning method ('deprune') to improve and train deep learning models so that they are much more network-efficient (use less network resources and are faster), which would make them ideal to deploy in weaker devices w",
    "path": "papers/23/11/2311.05739.json",
    "total_tokens": 850,
    "translated_title": "边缘网络效率的深度学习架构",
    "translated_abstract": "移动设备上越来越多的人工智能应用导致了将深度学习模型与现有边缘云资源集成的解决方案；由于其在设备能耗、延迟、网络利用和隐私改进等方面的多重好处，将深度学习模型在分布式环境中分离并计算的分离学习已成为一个广泛研究的领域。结合对通信数据进行压缩的压缩感知方法，该方法的好处进一步提高，可以作为传统方法（如联邦学习方法）的替代方案。在本文中，我们开发了一种自适应压缩感知分离学习方法（'deprune'），以改善和训练深度学习模型，使其更加网络高效（使用更少的网络资源和更快），这将使它们成为在较弱设备上部署的理想选择。",
    "tldr": "本文提出了一种自适应压缩感知分离学习方法，将深度学习模型与边缘云资源集成，从而实现网络高效性和更快的计算速度，适用于部署在较弱设备上。"
}