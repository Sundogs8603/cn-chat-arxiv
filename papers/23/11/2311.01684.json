{
    "title": "CASE: Commonsense-Augmented Score with an Expanded Answer Space. (arXiv:2311.01684v1 [cs.CL])",
    "abstract": "LLMs have demonstrated impressive zero-shot performance on NLP tasks thanks to the knowledge they acquired in their training. In multiple-choice QA tasks, the LM probabilities are used as an imperfect measure of the plausibility of each answer choice. One of the major limitations of the basic score is that it treats all words as equally important. We propose CASE, a Commonsense-Augmented Score with an Expanded Answer Space. CASE addresses this limitation by assigning importance weights for individual words based on their semantic relations to other words in the input. The dynamic weighting approach outperforms basic LM scores, not only because it reduces noise from unimportant words, but also because it informs the model of implicit commonsense knowledge that may be useful for answering the question. We then also follow prior work in expanding the answer space by generating lexically-divergent answers that are conceptually-similar to the choices. When combined with answer space expansi",
    "link": "http://arxiv.org/abs/2311.01684",
    "context": "Title: CASE: Commonsense-Augmented Score with an Expanded Answer Space. (arXiv:2311.01684v1 [cs.CL])\nAbstract: LLMs have demonstrated impressive zero-shot performance on NLP tasks thanks to the knowledge they acquired in their training. In multiple-choice QA tasks, the LM probabilities are used as an imperfect measure of the plausibility of each answer choice. One of the major limitations of the basic score is that it treats all words as equally important. We propose CASE, a Commonsense-Augmented Score with an Expanded Answer Space. CASE addresses this limitation by assigning importance weights for individual words based on their semantic relations to other words in the input. The dynamic weighting approach outperforms basic LM scores, not only because it reduces noise from unimportant words, but also because it informs the model of implicit commonsense knowledge that may be useful for answering the question. We then also follow prior work in expanding the answer space by generating lexically-divergent answers that are conceptually-similar to the choices. When combined with answer space expansi",
    "path": "papers/23/11/2311.01684.json",
    "total_tokens": 992,
    "translated_title": "CASE: 带有扩展答案空间的常识增强评分机制",
    "translated_abstract": "由于在训练中获得的知识，LLMs在自然语言处理任务上展现出令人印象深刻的零样本性能。在多项选择问答任务中，LM概率被用作每个答案选择的合理性的不完美度量。基本评分的一个主要限制是将所有单词都视为同等重要。我们提出了一个带有扩展答案空间的常识增强评分机制（CASE），通过根据输入中单词与其他单词之间的语义关系分配重要性权重来解决这个限制。动态加权方法不仅降低了不重要单词的噪声，还向模型提供了可能对回答问题有用的隐含常识知识。我们还在扩展答案空间方面遵循先前的工作，通过生成概念上类似于选项的词汇不同的答案。当与答案空间扩展相结合时，能表现出更好的性能。",
    "tldr": "我们提出了一个带有扩展答案空间和常识增强评分机制（CASE），它通过根据输入中单词的语义关系分配重要性权重来改善多项选择问答任务中的评分机制。我们还通过生成概念上类似于选项的词汇不同的答案来进一步扩展答案空间。这一方法在降低噪声和提供隐含常识知识方面表现出色，并取得了更好的性能。"
}