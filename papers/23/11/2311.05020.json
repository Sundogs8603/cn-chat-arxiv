{
    "title": "First Tragedy, then Parse: History Repeats Itself in the New Era of Large Language Models",
    "abstract": "arXiv:2311.05020v2 Announce Type: replace  Abstract: Many NLP researchers are experiencing an existential crisis triggered by the astonishing success of ChatGPT and other systems based on large language models (LLMs). After such a disruptive change to our understanding of the field, what is left to do? Taking a historical lens, we look for guidance from the first era of LLMs, which began in 2005 with large $n$-gram models for machine translation (MT). We identify durable lessons from the first era, and more importantly, we identify evergreen problems where NLP researchers can continue to make meaningful contributions in areas where LLMs are ascendant. We argue that disparities in scale are transient and researchers can work to reduce them; that data, rather than hardware, is still a bottleneck for many applications; that meaningful realistic evaluation is still an open problem; and that there is still room for speculative approaches.",
    "link": "https://arxiv.org/abs/2311.05020",
    "context": "Title: First Tragedy, then Parse: History Repeats Itself in the New Era of Large Language Models\nAbstract: arXiv:2311.05020v2 Announce Type: replace  Abstract: Many NLP researchers are experiencing an existential crisis triggered by the astonishing success of ChatGPT and other systems based on large language models (LLMs). After such a disruptive change to our understanding of the field, what is left to do? Taking a historical lens, we look for guidance from the first era of LLMs, which began in 2005 with large $n$-gram models for machine translation (MT). We identify durable lessons from the first era, and more importantly, we identify evergreen problems where NLP researchers can continue to make meaningful contributions in areas where LLMs are ascendant. We argue that disparities in scale are transient and researchers can work to reduce them; that data, rather than hardware, is still a bottleneck for many applications; that meaningful realistic evaluation is still an open problem; and that there is still room for speculative approaches.",
    "path": "papers/23/11/2311.05020.json",
    "total_tokens": 917,
    "translated_title": "先悲剧，再解析：历史在大型语言模型的新时代中重演",
    "translated_abstract": "许多自然语言处理研究人员正经历一场存在危机，这一危机是由ChatGPT和其他基于大型语言模型的系统取得惊人成功所触发的。在对该领域的理解发生如此颠覆性变化后，剩下什么可做呢？我们从历史的视角出发，寻找第一个以大型$n$-gram模型用于机器翻译(MT)开始于2005年的LLM时代的指导。我们确定了第一个时代的持久性教训，更重要的是，我们确定了NLP研究人员可以在LLMs占主导地位的领域继续做出有意义的贡献的永恒问题。我们认为规模上的差异是暂时的，研究人员可以努力减少这些差距；数据仍然是许多应用的瓶颈，而不是硬件；有意义的现实评估仍然是一个悬而未决的问题；而且还有空间可以尝试新的方法。",
    "tldr": "NLP研究人员在大型语言模型（LLMs）的新时代中，可以从历史中汲取教训，持续解决规模差异、数据瓶颈、现实评估等问题，同时还有空间尝试新的方法。",
    "en_tdlr": "NLP researchers in the new era of large language models (LLMs) can learn lessons from history, continue to address issues such as scale disparities, data bottlenecks, realistic evaluation, and explore new approaches."
}