{
    "title": "Discretized Distributed Optimization over Dynamic Digraphs",
    "abstract": "arXiv:2311.07939v2 Announce Type: replace-cross  Abstract: We consider a discrete-time model of continuous-time distributed optimization over dynamic directed-graphs (digraphs) with applications to distributed learning. Our optimization algorithm works over general strongly connected dynamic networks under switching topologies, e.g., in mobile multi-agent systems and volatile networks due to link failures. Compared to many existing lines of work, there is no need for bi-stochastic weight designs on the links. The existing literature mostly needs the link weights to be stochastic using specific weight-design algorithms needed both at the initialization and at all times when the topology of the network changes. This paper eliminates the need for such algorithms and paves the way for distributed optimization over time-varying digraphs. We derive the bound on the gradient-tracking step-size and discrete time-step for convergence and prove dynamic stability using arguments from consensus al",
    "link": "https://arxiv.org/abs/2311.07939",
    "context": "Title: Discretized Distributed Optimization over Dynamic Digraphs\nAbstract: arXiv:2311.07939v2 Announce Type: replace-cross  Abstract: We consider a discrete-time model of continuous-time distributed optimization over dynamic directed-graphs (digraphs) with applications to distributed learning. Our optimization algorithm works over general strongly connected dynamic networks under switching topologies, e.g., in mobile multi-agent systems and volatile networks due to link failures. Compared to many existing lines of work, there is no need for bi-stochastic weight designs on the links. The existing literature mostly needs the link weights to be stochastic using specific weight-design algorithms needed both at the initialization and at all times when the topology of the network changes. This paper eliminates the need for such algorithms and paves the way for distributed optimization over time-varying digraphs. We derive the bound on the gradient-tracking step-size and discrete time-step for convergence and prove dynamic stability using arguments from consensus al",
    "path": "papers/23/11/2311.07939.json",
    "total_tokens": 825,
    "translated_title": "动态有向图上的离散分布式优化",
    "translated_abstract": "我们考虑在动态有向图（digraphs）上进行连续时间分布式优化的离散时间模型，具有分布式学习应用。我们的优化算法适用于在切换拓扑的广义强连接动态网络上，例如移动多Agent系统和由于链路失败而不稳定的网络。与许多现有研究方向相比，在链路上没有必要进行双随机权重设计。现有文献大多需要链路权重是随机的，并使用特定的权重设计算法，在初始化和网络拓扑变化时都需要这些算法。本文消除了这些算法的需求，为随时间变化的有向图上的分布式优化铺平道路。我们导出了渐近性梯度跟踪步长和离散时间步长的收敛界，并使用共识算法证明了动态稳定性。",
    "tldr": "该论文研究了在动态有向图上进行连续时间分布式优化的离散模型，避免了链路上双随机权重设计的需要，并为分布式优化在时间变化的有向图上铺平了道路。",
    "en_tdlr": "This paper investigates a discrete-time model of continuous-time distributed optimization over dynamic directed-graphs, eliminating the need for bi-stochastic weight designs on the links, paving the way for distributed optimization over time-varying digraphs."
}