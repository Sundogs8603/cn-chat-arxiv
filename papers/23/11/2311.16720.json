{
    "title": "TSRankLLM: A Two-Stage Adaptation of LLMs for Text Ranking. (arXiv:2311.16720v2 [cs.IR] UPDATED)",
    "abstract": "Text ranking is a critical task in various information retrieval applications, and the recent success of pre-trained language models (PLMs), especially large language models (LLMs), has sparked interest in their application to text ranking. To eliminate the misalignment between PLMs and text ranking, fine-tuning with supervised ranking data has been widely explored. However, previous studies focus mainly on encoder-only and encoder-decoder PLMs, and decoder-only LLM research is still lacking. An exception to this is RankLLaMA, which suggests direct supervised fine-tuning (SFT) to explore LLaMA fully. In our work, we argue that a two-stage progressive paradigm would be more beneficial. First, we suggest continual pre-training (CPT) on LLMs by using a large-scale weakly-supervised corpus. Second, we perform SFT consistent with RankLLaMA, and propose an improved optimization strategy further. Our experimental results on multiple benchmarks demonstrate the superior performance of our metho",
    "link": "http://arxiv.org/abs/2311.16720",
    "context": "Title: TSRankLLM: A Two-Stage Adaptation of LLMs for Text Ranking. (arXiv:2311.16720v2 [cs.IR] UPDATED)\nAbstract: Text ranking is a critical task in various information retrieval applications, and the recent success of pre-trained language models (PLMs), especially large language models (LLMs), has sparked interest in their application to text ranking. To eliminate the misalignment between PLMs and text ranking, fine-tuning with supervised ranking data has been widely explored. However, previous studies focus mainly on encoder-only and encoder-decoder PLMs, and decoder-only LLM research is still lacking. An exception to this is RankLLaMA, which suggests direct supervised fine-tuning (SFT) to explore LLaMA fully. In our work, we argue that a two-stage progressive paradigm would be more beneficial. First, we suggest continual pre-training (CPT) on LLMs by using a large-scale weakly-supervised corpus. Second, we perform SFT consistent with RankLLaMA, and propose an improved optimization strategy further. Our experimental results on multiple benchmarks demonstrate the superior performance of our metho",
    "path": "papers/23/11/2311.16720.json",
    "total_tokens": 898,
    "translated_title": "TSRankLLM: 一种用于文本排序的两阶段LLM适应方法",
    "translated_abstract": "文本排序是各种信息检索应用中的关键任务，最近预训练语言模型（PLMs），特别是大型语言模型（LLMs）的成功引起了人们对其在文本排序中的应用的兴趣。为了消除PLMs和文本排序之间的不匹配问题，许多学者已经广泛探索了使用有监督排序数据进行微调的方法。然而，以前的研究主要集中在仅编码器和编码器-解码器PLMs上，缺乏对仅解码器LLM的研究。一个例外是RankLLaMA，它建议直接使用有监督的微调（SFT）来全面探索LLaMA。在我们的工作中，我们认为采用两阶段渐进范式会更有益。首先，我们建议使用大规模弱监督语料库对LLMs进行连续预训练（CPT）。其次，我们执行与RankLLaMA一致的SFT，并进一步提出了改进的优化策略。我们在多个基准测试上的实验结果表明我们方法具有卓越的性能。",
    "tldr": "TSRankLLM提出了一种两阶段适应方法用于文本排序，通过连续预训练和改进的优化策略，实现了更好的性能。"
}