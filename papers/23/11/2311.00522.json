{
    "title": "Text Rendering Strategies for Pixel Language Models. (arXiv:2311.00522v1 [cs.CL])",
    "abstract": "Pixel-based language models process text rendered as images, which allows them to handle any script, making them a promising approach to open vocabulary language modelling. However, recent approaches use text renderers that produce a large set of almost-equivalent input patches, which may prove sub-optimal for downstream tasks, due to redundancy in the input representations. In this paper, we investigate four approaches to rendering text in the PIXEL model (Rust et al., 2023), and find that simple character bigram rendering brings improved performance on sentence-level tasks without compromising performance on token-level or multilingual tasks. This new rendering strategy also makes it possible to train a more compact model with only 22M parameters that performs on par with the original 86M parameter model. Our analyses show that character bigram rendering leads to a consistently better model but with an anisotropic patch embedding space, driven by a patch frequency bias, highlighting ",
    "link": "http://arxiv.org/abs/2311.00522",
    "context": "Title: Text Rendering Strategies for Pixel Language Models. (arXiv:2311.00522v1 [cs.CL])\nAbstract: Pixel-based language models process text rendered as images, which allows them to handle any script, making them a promising approach to open vocabulary language modelling. However, recent approaches use text renderers that produce a large set of almost-equivalent input patches, which may prove sub-optimal for downstream tasks, due to redundancy in the input representations. In this paper, we investigate four approaches to rendering text in the PIXEL model (Rust et al., 2023), and find that simple character bigram rendering brings improved performance on sentence-level tasks without compromising performance on token-level or multilingual tasks. This new rendering strategy also makes it possible to train a more compact model with only 22M parameters that performs on par with the original 86M parameter model. Our analyses show that character bigram rendering leads to a consistently better model but with an anisotropic patch embedding space, driven by a patch frequency bias, highlighting ",
    "path": "papers/23/11/2311.00522.json",
    "total_tokens": 966,
    "translated_title": "像素语言模型的文本渲染策略",
    "translated_abstract": "基于像素的语言模型处理以图像形式渲染的文本，这使得它们能够处理任何脚本，为开放词汇语言建模提供了有希望的方法。然而，最近的方法使用产生大量几乎等效的输入补丁的文本渲染器，这可能对下游任务来说并不最优，因为输入表示中存在冗余。在本文中，我们研究了在PIXEL模型（Rust等人，2023）中进行文本渲染的四种方法，并发现简单的字符二元渲染在句子级任务上带来了改进的性能，同时在令牌级或多语言任务上不降低性能。这种新的渲染策略还使得我们能够训练一个只有22M参数但性能与原始的86M参数模型相当的更紧凑模型。我们的分析显示，字符二元渲染导致了一个具有各向异性的补丁嵌入空间，由于补丁频率偏差而受到驱动，突出了...",
    "tldr": "本文研究了在像素语言模型中渲染文本的四种方法，并发现简单的字符二元渲染策略在句子级任务上表现出更好的性能，同时不降低令牌级或多语言任务的表现。该策略还使得可以训练一个更紧凑的模型，仅使用22M参数但性能与原始模型相当。",
    "en_tdlr": "This paper investigates four approaches to rendering text in pixel-based language models and finds that a simple character bigram rendering strategy performs better on sentence-level tasks without compromising performance on token-level or multilingual tasks. This strategy also enables training a more compact model with only 22M parameters that performs on par with the original model."
}