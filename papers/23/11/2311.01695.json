{
    "title": "Communication-Efficient Federated Non-Linear Bandit Optimization. (arXiv:2311.01695v1 [cs.LG])",
    "abstract": "Federated optimization studies the problem of collaborative function optimization among multiple clients (e.g. mobile devices or organizations) under the coordination of a central server. Since the data is collected separately by each client and always remains decentralized, federated optimization preserves data privacy and allows for large-scale computing, which makes it a promising decentralized machine learning paradigm. Though it is often deployed for tasks that are online in nature, e.g., next-word prediction on keyboard apps, most works formulate it as an offline problem. The few exceptions that consider federated bandit optimization are limited to very simplistic function classes, e.g., linear, generalized linear, or non-parametric function class with bounded RKHS norm, which severely hinders its practical usage. In this paper, we propose a new algorithm, named Fed-GO-UCB, for federated bandit optimization with generic non-linear objective function. Under some mild conditions, w",
    "link": "http://arxiv.org/abs/2311.01695",
    "context": "Title: Communication-Efficient Federated Non-Linear Bandit Optimization. (arXiv:2311.01695v1 [cs.LG])\nAbstract: Federated optimization studies the problem of collaborative function optimization among multiple clients (e.g. mobile devices or organizations) under the coordination of a central server. Since the data is collected separately by each client and always remains decentralized, federated optimization preserves data privacy and allows for large-scale computing, which makes it a promising decentralized machine learning paradigm. Though it is often deployed for tasks that are online in nature, e.g., next-word prediction on keyboard apps, most works formulate it as an offline problem. The few exceptions that consider federated bandit optimization are limited to very simplistic function classes, e.g., linear, generalized linear, or non-parametric function class with bounded RKHS norm, which severely hinders its practical usage. In this paper, we propose a new algorithm, named Fed-GO-UCB, for federated bandit optimization with generic non-linear objective function. Under some mild conditions, w",
    "path": "papers/23/11/2311.01695.json",
    "total_tokens": 829,
    "translated_title": "高效通信的联邦非线性赌博优化",
    "translated_abstract": "联邦优化研究了在一个中央服务器的协调下，多个客户端（如移动设备或组织）之间的协同函数优化问题。由于数据由每个客户端单独收集并始终保持分散，联邦优化保护了数据隐私并允许大规模计算，这使得它成为一种有前途的分散式机器学习范式。尽管它通常用于在线任务，例如键盘应用程序上的下一个词预测，但大多数工作将其定义为离线问题。很少数例外考虑联邦赌博优化，但它们局限于非常简单的函数类别，例如线性、广义线性或带有有界RKHS范数的非参数函数类别，这严重限制了它的实际使用。在本文中，我们提出了一种新算法，名为Fed-GO-UCB，用于具有通用非线性目标函数的联邦赌博优化。",
    "tldr": "本文提出了一种名为Fed-GO-UCB的新算法，用于具有通用非线性目标函数的联邦赌博优化。",
    "en_tdlr": "This paper proposes a new algorithm, named Fed-GO-UCB, for federated bandit optimization with generic non-linear objective function."
}