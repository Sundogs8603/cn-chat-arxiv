{
    "title": "Prompt Risk Control: A Rigorous Framework for Responsible Deployment of Large Language Models",
    "abstract": "arXiv:2311.13628v2 Announce Type: replace-cross  Abstract: The recent explosion in the capabilities of large language models has led to a wave of interest in how best to prompt a model to perform a given task. While it may be tempting to simply choose a prompt based on average performance on a validation set, this can lead to a deployment where unexpectedly poor responses are generated, especially for the worst-off users. To mitigate this prospect, we propose Prompt Risk Control, a lightweight framework for selecting a prompt based on rigorous upper bounds on families of informative risk measures. We offer methods for producing bounds on a diverse set of metrics, including quantities that measure worst-case responses and disparities in generation quality across the population of users. In addition, we extend the underlying statistical bounding techniques to accommodate the possibility of distribution shifts in deployment. Experiments on applications such as open-ended chat, medical que",
    "link": "https://arxiv.org/abs/2311.13628",
    "context": "Title: Prompt Risk Control: A Rigorous Framework for Responsible Deployment of Large Language Models\nAbstract: arXiv:2311.13628v2 Announce Type: replace-cross  Abstract: The recent explosion in the capabilities of large language models has led to a wave of interest in how best to prompt a model to perform a given task. While it may be tempting to simply choose a prompt based on average performance on a validation set, this can lead to a deployment where unexpectedly poor responses are generated, especially for the worst-off users. To mitigate this prospect, we propose Prompt Risk Control, a lightweight framework for selecting a prompt based on rigorous upper bounds on families of informative risk measures. We offer methods for producing bounds on a diverse set of metrics, including quantities that measure worst-case responses and disparities in generation quality across the population of users. In addition, we extend the underlying statistical bounding techniques to accommodate the possibility of distribution shifts in deployment. Experiments on applications such as open-ended chat, medical que",
    "path": "papers/23/11/2311.13628.json",
    "total_tokens": 858,
    "translated_title": "提示风险控制：大型语言模型负责部署的严格框架",
    "translated_abstract": "大型语言模型能力的爆炸式增长引发了对如何最好地提示模型执行特定任务的兴趣浪潮。选择一个基于验证集上平均性能的提示可能很诱人，但这可能导致生成出乎意料的糟糕响应，尤其是对于处境最困难的用户。为了减轻这一可能性，我们提出提示风险控制，这是一个轻量级框架，根据信息风险度量族的严格上限选择提示。我们提供了用于产生多种度量上限的方法，包括衡量最坏情况响应和用户群体生成质量不均衡的量，此外，我们扩展了基础统计界定技术，以适应部署中分布变化可能性的情况。在开放式聊天、医学问题等应用上的实验表明了我们方法的有效性。",
    "tldr": "提示风险控制是一个轻量级框架，通过严格的信息风险度量族的上限选取提示，帮助减轻大型语言模型负责部署过程中产生意外糟糕响应的风险。",
    "en_tdlr": "Prompt Risk Control is a lightweight framework that selects prompts based on rigorous upper bounds on families of informative risk measures, aiming to mitigate the risk of unexpectedly poor responses during the responsible deployment of large language models."
}