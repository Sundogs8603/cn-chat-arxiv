{
    "title": "UHGEval: Benchmarking the Hallucination of Chinese Large Language Models via Unconstrained Generation",
    "abstract": "arXiv:2311.15296v2 Announce Type: replace  Abstract: Large language models (LLMs) have emerged as pivotal contributors in contemporary natural language processing and are increasingly being applied across a diverse range of industries. However, these large-scale probabilistic statistical models cannot currently ensure the requisite quality in professional content generation. These models often produce hallucinated text, compromising their practical utility in professional contexts. To assess the authentic reliability of LLMs in text generation, numerous initiatives have developed benchmark evaluations for hallucination phenomena. Nevertheless, these benchmarks frequently utilize constrained generation techniques due to cost and temporal constraints. These techniques encompass the use of directed hallucination induction and strategies that deliberately alter authentic text to produce hallucinations. These approaches are not congruent with the unrestricted text generation demanded by rea",
    "link": "https://arxiv.org/abs/2311.15296",
    "context": "Title: UHGEval: Benchmarking the Hallucination of Chinese Large Language Models via Unconstrained Generation\nAbstract: arXiv:2311.15296v2 Announce Type: replace  Abstract: Large language models (LLMs) have emerged as pivotal contributors in contemporary natural language processing and are increasingly being applied across a diverse range of industries. However, these large-scale probabilistic statistical models cannot currently ensure the requisite quality in professional content generation. These models often produce hallucinated text, compromising their practical utility in professional contexts. To assess the authentic reliability of LLMs in text generation, numerous initiatives have developed benchmark evaluations for hallucination phenomena. Nevertheless, these benchmarks frequently utilize constrained generation techniques due to cost and temporal constraints. These techniques encompass the use of directed hallucination induction and strategies that deliberately alter authentic text to produce hallucinations. These approaches are not congruent with the unrestricted text generation demanded by rea",
    "path": "papers/23/11/2311.15296.json",
    "total_tokens": 810,
    "translated_title": "UHGEval：通过无约束生成评估中文大型语言模型的虚构能力",
    "translated_abstract": "大型语言模型（LLMs）已成为当代自然语言处理领域的重要贡献者，并越来越广泛地应用于各种行业。然而，这些大规模概率统计模型目前无法保证在专业内容生成中的必要质量。这些模型经常产生虚构的文本，影响它们在专业环境中的实用性。为了评估LLMs在文本生成中的真实可靠性，许多倡议已开发了用于虚构现象的基准评估。然而，这些基准评估通常利用受限制的生成技术，因为成本和时间限制。这些技术包括使用定向幻觉诱导和故意改变真实文本以产生幻觉的策略。这些方法与实际需求的无约束文本生成不一致。",
    "tldr": "评估了中文大型语言模型在文本生成中的虚构能力，并指出现有基准评估通常采用受限制的生成技术，无法满足真实需求中的无约束文本生成。",
    "en_tdlr": "Evaluated the hallucination ability of Chinese large language models in text generation, highlighting that existing benchmark evaluations often use constrained generation techniques that do not meet the unrestricted text generation required in real contexts."
}