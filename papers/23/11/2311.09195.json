{
    "title": "Self-Supervised Curriculum Generation for Autonomous Reinforcement Learning without Task-Specific Knowledge",
    "abstract": "arXiv:2311.09195v2 Announce Type: replace  Abstract: A significant bottleneck in applying current reinforcement learning algorithms to real-world scenarios is the need to reset the environment between every episode. This reset process demands substantial human intervention, making it difficult for the agent to learn continuously and autonomously. Several recent works have introduced autonomous reinforcement learning (ARL) algorithms that generate curricula for jointly training reset and forward policies. While their curricula can reduce the number of required manual resets by taking into account the agent's learning progress, they rely on task-specific knowledge, such as predefined initial states or reset reward functions. In this paper, we propose a novel ARL algorithm that can generate a curriculum adaptive to the agent's learning progress without task-specific knowledge. Our curriculum empowers the agent to autonomously reset to diverse and informative initial states. To achieve thi",
    "link": "https://arxiv.org/abs/2311.09195",
    "context": "Title: Self-Supervised Curriculum Generation for Autonomous Reinforcement Learning without Task-Specific Knowledge\nAbstract: arXiv:2311.09195v2 Announce Type: replace  Abstract: A significant bottleneck in applying current reinforcement learning algorithms to real-world scenarios is the need to reset the environment between every episode. This reset process demands substantial human intervention, making it difficult for the agent to learn continuously and autonomously. Several recent works have introduced autonomous reinforcement learning (ARL) algorithms that generate curricula for jointly training reset and forward policies. While their curricula can reduce the number of required manual resets by taking into account the agent's learning progress, they rely on task-specific knowledge, such as predefined initial states or reset reward functions. In this paper, we propose a novel ARL algorithm that can generate a curriculum adaptive to the agent's learning progress without task-specific knowledge. Our curriculum empowers the agent to autonomously reset to diverse and informative initial states. To achieve thi",
    "path": "papers/23/11/2311.09195.json",
    "total_tokens": 654,
    "translated_title": "无需任务特定知识的自监督课程生成用于自主强化学习",
    "translated_abstract": "在将当前强化学习算法应用于现实场景时，一个重要瓶颈是需要在每个回合之间重置环境。重置过程需要大量人工干预，使得智能体难以连续和自主学习。本文提出一种新颖的自主强化学习算法，可以生成适应智能体学习进展的课程，而无需任务特定知识。",
    "tldr": "提出一种新颖的自主强化学习算法，无需任务特定知识即可生成适应智能体学习进展的课程",
    "en_tdlr": "A novel autonomous reinforcement learning algorithm is proposed in this paper, which can generate a curriculum adaptive to the agent's learning progress without task-specific knowledge."
}