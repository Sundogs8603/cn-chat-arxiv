{
    "title": "Few-shot Transfer Learning for Knowledge Base Question Answering: Fusing Supervised Models with In-Context Learning",
    "abstract": "arXiv:2311.08894v2 Announce Type: replace-cross  Abstract: Existing Knowledge Base Question Answering (KBQA) architectures are hungry for annotated data, which make them costly and time-consuming to deploy. We introduce the problem of few-shot transfer learning for KBQA, where the target domain offers only a few labeled examples, but a large labeled training dataset is available in a source domain. We propose a novel KBQA architecture called FuSIC-KBQA that performs KB-retrieval using multiple source-trained retrievers, re-ranks using an LLM and uses this as input for LLM few-shot in-context learning to generate logical forms, which are further refined using execution-guided feedback. Experiments over four source-target KBQA pairs of varying complexity show that FuSIC-KBQA significantly outperforms adaptations of SoTA KBQA models for this setting. Additional experiments in the in-domain setting show that FuSIC-KBQA also outperforms SoTA KBQA models when training data is limited.",
    "link": "https://arxiv.org/abs/2311.08894",
    "context": "Title: Few-shot Transfer Learning for Knowledge Base Question Answering: Fusing Supervised Models with In-Context Learning\nAbstract: arXiv:2311.08894v2 Announce Type: replace-cross  Abstract: Existing Knowledge Base Question Answering (KBQA) architectures are hungry for annotated data, which make them costly and time-consuming to deploy. We introduce the problem of few-shot transfer learning for KBQA, where the target domain offers only a few labeled examples, but a large labeled training dataset is available in a source domain. We propose a novel KBQA architecture called FuSIC-KBQA that performs KB-retrieval using multiple source-trained retrievers, re-ranks using an LLM and uses this as input for LLM few-shot in-context learning to generate logical forms, which are further refined using execution-guided feedback. Experiments over four source-target KBQA pairs of varying complexity show that FuSIC-KBQA significantly outperforms adaptations of SoTA KBQA models for this setting. Additional experiments in the in-domain setting show that FuSIC-KBQA also outperforms SoTA KBQA models when training data is limited.",
    "path": "papers/23/11/2311.08894.json",
    "total_tokens": 931,
    "translated_title": "少样本迁移学习用于知识库问答：融合监督模型和上下文学习",
    "translated_abstract": "现有的知识库问答（KBQA）架构需要大量注释数据，这使得它们在部署时成本高且耗时。我们提出少样本迁移学习用于KBQA的问题，目标域仅提供少量标记示例，但在源域中有大量标记训练数据集可用。我们提出了一种名为FuSIC-KBQA的新型KBQA架构，它使用多个经过源培训的召回器执行KB检索，使用LLM重新排序，将此作为LLM少样本上下文学习的输入以生成逻辑形式，进一步使用执行引导反馈进行细化。在四对不同复杂度的源-目标KBQA对上的实验表明，FuSIC-KBQA明显优于为此设置调整的SoTA KBQA模型。在领域内设置的额外实验表明，当训练数据有限时，FuSIC-KBQA也优于SoTA KBQA模型。",
    "tldr": "提出了一种新的KBQA架构FuSIC-KBQA，通过多个源训练的召回器执行KB检索，在LLM的重新排序后以此作为LLM少样本上下文学习的输入来生成逻辑形式，并利用执行引导反馈进一步优化。",
    "en_tdlr": "Introduced a novel KBQA architecture FuSIC-KBQA, which performs KB-retrieval using multiple source-trained retrievers, re-ranks with an LLM, and utilizes in-context learning for logical form generation, refined by execution-guided feedback, outperforming state-of-the-art models in few-shot transfer learning for KBQA."
}