{
    "title": "Appearance-based gaze estimation enhanced with synthetic images using deep neural networks",
    "abstract": "arXiv:2311.14175v2 Announce Type: replace-cross  Abstract: Human eye gaze estimation is an important cognitive ingredient for successful human-robot interaction, enabling the robot to read and predict human behavior. We approach this problem using artificial neural networks and build a modular system estimating gaze from separately cropped eyes, taking advantage of existing well-functioning components for face detection (RetinaFace) and head pose estimation (6DRepNet). Our proposed method does not require any special hardware or infrared filters but uses a standard notebook-builtin RGB camera, as often approached with appearance-based methods. Using the MetaHuman tool, we also generated a large synthetic dataset of more than 57,000 human faces and made it publicly available. The inclusion of this dataset (with eye gaze and head pose information) on top of the standard Columbia Gaze dataset into training the model led to better accuracy with a mean average error below two degrees in eye",
    "link": "https://arxiv.org/abs/2311.14175",
    "context": "Title: Appearance-based gaze estimation enhanced with synthetic images using deep neural networks\nAbstract: arXiv:2311.14175v2 Announce Type: replace-cross  Abstract: Human eye gaze estimation is an important cognitive ingredient for successful human-robot interaction, enabling the robot to read and predict human behavior. We approach this problem using artificial neural networks and build a modular system estimating gaze from separately cropped eyes, taking advantage of existing well-functioning components for face detection (RetinaFace) and head pose estimation (6DRepNet). Our proposed method does not require any special hardware or infrared filters but uses a standard notebook-builtin RGB camera, as often approached with appearance-based methods. Using the MetaHuman tool, we also generated a large synthetic dataset of more than 57,000 human faces and made it publicly available. The inclusion of this dataset (with eye gaze and head pose information) on top of the standard Columbia Gaze dataset into training the model led to better accuracy with a mean average error below two degrees in eye",
    "path": "papers/23/11/2311.14175.json",
    "total_tokens": 872,
    "translated_title": "基于外观的注视估计通过使用深度神经网络增强合成图像",
    "translated_abstract": "人眼注视估计对于成功的人机交互是一个重要的认知因素，使机器人能够读取和预测人类行为。我们采用人工神经网络来解决这个问题，并构建了一个模块化系统，通过分开裁剪的眼睛估计注视，利用现有的用于人脸检测（RetinaFace）和头部姿态估计（6DRepNet）的良好工作的组件。我们提出的方法不需要任何特殊硬件或红外滤光片，而是使用标准笔记本内置的RGB摄像头，通常采用基于外观的方法。通过MetaHuman工具，我们还生成了一个包含超过57,000张人脸的大型合成数据集，并公开提供了这一数据集。将这个数据集（带有眼睛注视和头部姿态信息）与标准的哥伦比亚注视数据集结合起来训练模型，导致更高的准确性，眼睛的平均误差低于两度。",
    "tldr": "使用深度神经网络，通过合成图像以及基于外观的方法提高了注视估计准确性，无需特殊硬件，眼睛平均误差低于两度",
    "en_tdlr": "The paper enhances gaze estimation accuracy using deep neural networks and synthetic images with appearance-based methods, without requiring special hardware, achieving an average error below two degrees in eye gaze."
}