{
    "title": "Think While You Write: Hypothesis Verification Promotes Faithful Knowledge-to-Text Generation",
    "abstract": "arXiv:2311.09467v2 Announce Type: replace-cross  Abstract: Knowledge-to-text generators often struggle to faithfully generate descriptions for the input facts: they may produce hallucinations that contradict the input, or describe facts not present in the input. To reduce hallucinations, we propose a decoding-only method, TWEAK (Think While Effectively Articulating Knowledge), which can be integrated with any generator without retraining. TWEAK treats the generated sequences at each decoding step and its future sequences as hypotheses, and ranks each generation candidate based on the extent to which their hypotheses are supported by the input facts using a Hypothesis Verification Model (HVM). We first demonstrate the effectiveness of TWEAK by using a Natural Language Inference (NLI) model as the HVM and report improved faithfulness with a minimal impact on the quality. We then replace the NLI model with a task-specific HVM trained with a first-of-a-kind dataset, FATE (Fact-Aligned Text",
    "link": "https://arxiv.org/abs/2311.09467",
    "context": "Title: Think While You Write: Hypothesis Verification Promotes Faithful Knowledge-to-Text Generation\nAbstract: arXiv:2311.09467v2 Announce Type: replace-cross  Abstract: Knowledge-to-text generators often struggle to faithfully generate descriptions for the input facts: they may produce hallucinations that contradict the input, or describe facts not present in the input. To reduce hallucinations, we propose a decoding-only method, TWEAK (Think While Effectively Articulating Knowledge), which can be integrated with any generator without retraining. TWEAK treats the generated sequences at each decoding step and its future sequences as hypotheses, and ranks each generation candidate based on the extent to which their hypotheses are supported by the input facts using a Hypothesis Verification Model (HVM). We first demonstrate the effectiveness of TWEAK by using a Natural Language Inference (NLI) model as the HVM and report improved faithfulness with a minimal impact on the quality. We then replace the NLI model with a task-specific HVM trained with a first-of-a-kind dataset, FATE (Fact-Aligned Text",
    "path": "papers/23/11/2311.09467.json",
    "total_tokens": 845,
    "translated_title": "写作时思考：假设验证促进忠实的知识到文本生成",
    "translated_abstract": "知识到文本生成器经常难以忠实地为输入事实生成描述：它们可能产生与输入相矛盾的幻觉，或描述输入中不存在的事实。为了减少幻觉，我们提出了一种仅解码的方法TWEAK（思考而有效表达知识），可以与任何生成器集成而无需重新训练。TWEAK将每个解码步骤的生成序列及其未来序列视为假设，并根据其假设受到输入事实支持的程度，使用假设验证模型（HVM）对每个生成候选进行排名。我们首先通过使用自然语言推理（NLI）模型作为HVM展示了TWEAK的有效性，并报告了对质量影响很小的改善忠实度。然后，我们将NLI模型替换为使用FATE（事实对齐文本）首创数据集训练的特定任务HVM。",
    "tldr": "提出了一种名为TWEAK的仅解码方法，通过引入假设验证模型来提高知识到文本生成的忠实度，并在不影响质量的情况下取得改进。",
    "en_tdlr": "Proposing a decoding-only method called TWEAK to enhance faithful knowledge-to-text generation by introducing a Hypothesis Verification Model, leading to improvements without compromising quality."
}