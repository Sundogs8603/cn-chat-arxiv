{
    "title": "Transfer learning for improved generalizability in causal physics-informed neural networks for beam simulations. (arXiv:2311.00578v1 [cs.LG])",
    "abstract": "This paper introduces a novel methodology for simulating the dynamics of beams on elastic foundations. Specifically, Euler-Bernoulli and Timoshenko beam models on the Winkler foundation are simulated using a transfer learning approach within a causality-respecting physics-informed neural network (PINN) framework. Conventional PINNs encounter challenges in handling large space-time domains, even for problems with closed-form analytical solutions. A causality-respecting PINN loss function is employed to overcome this limitation, effectively capturing the underlying physics. However, it is observed that the causality-respecting PINN lacks generalizability. We propose using solutions to similar problems instead of training from scratch by employing transfer learning while adhering to causality to accelerate convergence and ensure accurate results across diverse scenarios. Numerical experiments on the Euler-Bernoulli beam highlight the efficacy of the proposed approach for various initial c",
    "link": "http://arxiv.org/abs/2311.00578",
    "context": "Title: Transfer learning for improved generalizability in causal physics-informed neural networks for beam simulations. (arXiv:2311.00578v1 [cs.LG])\nAbstract: This paper introduces a novel methodology for simulating the dynamics of beams on elastic foundations. Specifically, Euler-Bernoulli and Timoshenko beam models on the Winkler foundation are simulated using a transfer learning approach within a causality-respecting physics-informed neural network (PINN) framework. Conventional PINNs encounter challenges in handling large space-time domains, even for problems with closed-form analytical solutions. A causality-respecting PINN loss function is employed to overcome this limitation, effectively capturing the underlying physics. However, it is observed that the causality-respecting PINN lacks generalizability. We propose using solutions to similar problems instead of training from scratch by employing transfer learning while adhering to causality to accelerate convergence and ensure accurate results across diverse scenarios. Numerical experiments on the Euler-Bernoulli beam highlight the efficacy of the proposed approach for various initial c",
    "path": "papers/23/11/2311.00578.json",
    "total_tokens": 908,
    "translated_title": "用于改善因果物理信息神经网络在梁模拟中的泛化能力的迁移学习",
    "translated_abstract": "本文介绍了一种用于模拟弹性基础上梁动力学的新方法。具体而言，在因果性物理信息神经网络（PINN）框架内利用迁移学习方法模拟了Winkler基础上的Euler-Bernoulli梁模型和Timoshenko梁模型。传统的PINNS在处理大空时时间域上的问题时会遇到挑战，即使对于具有封闭解的问题也是如此。为了克服这一限制，采用因果性物理信息神经网络损失函数，有效捕捉底层的物理学。然而，观察到因果性PINN缺乏泛化能力。我们建议使用类似问题的解决方案，而不是从头开始训练，通过采用迁移学习并遵循因果性来加快收敛速度并确保在各种场景下获得准确的结果。在Euler-Bernoulli梁上的数值实验突出了所提方法的有效性。",
    "tldr": "本文介绍了一种用于模拟弹性基础上梁动力学的新方法，通过迁移学习和因果性物理信息神经网络框架，提高了问题的泛化能力，并在数值实验中验证了其有效性。"
}