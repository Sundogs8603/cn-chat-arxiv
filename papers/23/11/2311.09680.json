{
    "title": "Trustworthy Large Models in Vision: A Survey",
    "abstract": "The rapid progress of Large Models (LMs) has recently revolutionized various fields of deep learning with remarkable grades, ranging from Natural Language Processing (NLP) to Computer Vision (CV). However, LMs are increasingly challenged and criticized by academia and industry due to their powerful performance but untrustworthy behavior, which urgently needs to be alleviated by reliable methods. Despite the abundance of literature on trustworthy LMs in NLP, a systematic survey specifically delving into the trustworthiness of LMs in CV remains absent. In order to mitigate this gap, we summarize four relevant concerns that obstruct the trustworthy usage in vision of LMs in this survey, including 1) human misuse, 2) vulnerability, 3) inherent issue and 4) interpretability. By highlighting corresponding challenge, countermeasures, and discussion in each topic, we hope this survey will facilitate readers' understanding of this field, promote alignment of LMs with human expectations and enab",
    "link": "https://arxiv.org/abs/2311.09680",
    "context": "Title: Trustworthy Large Models in Vision: A Survey\nAbstract: The rapid progress of Large Models (LMs) has recently revolutionized various fields of deep learning with remarkable grades, ranging from Natural Language Processing (NLP) to Computer Vision (CV). However, LMs are increasingly challenged and criticized by academia and industry due to their powerful performance but untrustworthy behavior, which urgently needs to be alleviated by reliable methods. Despite the abundance of literature on trustworthy LMs in NLP, a systematic survey specifically delving into the trustworthiness of LMs in CV remains absent. In order to mitigate this gap, we summarize four relevant concerns that obstruct the trustworthy usage in vision of LMs in this survey, including 1) human misuse, 2) vulnerability, 3) inherent issue and 4) interpretability. By highlighting corresponding challenge, countermeasures, and discussion in each topic, we hope this survey will facilitate readers' understanding of this field, promote alignment of LMs with human expectations and enab",
    "path": "papers/23/11/2311.09680.json",
    "total_tokens": 948,
    "translated_title": "可信的大模型在视觉领域的研究综述",
    "translated_abstract": "大模型（LMs）的快速发展在深度学习的各个领域中带来了革命性的进展，从自然语言处理（NLP）到计算机视觉（CV）都有显著的成绩。然而，由于其强大的性能但不可信的行为，LMs越来越受到学术界和工业界的挑战和批评，迫切需要可靠的方法加以缓解。尽管关于可信的NLP领域中的LMs已有大量文献，但系统研究关于CV领域中LMs的可信性的文献仍然缺乏。为了弥补这个空白，我们在本综述中总结了四个影响在视觉领域中使用可信LMs的相关问题，包括：1）人为误用，2）漏洞性，3）固有问题和4）可解释性。通过突出每个主题中的相应挑战、对策和讨论，我们希望本综述能够促进读者对这一领域的理解，推动LMs与人类期望的对齐",
    "tldr": "这篇综述研究了可信的大模型在视觉领域的问题，包括人为误用、漏洞性、固有问题和可解释性，并提出了对应的挑战和对策，旨在推动可信的LMs与人类期望的对齐",
    "en_tdlr": "This survey examines the issues surrounding trustworthy large models (LMs) in computer vision, including human misuse, vulnerability, inherent issues, and interpretability. It highlights challenges and countermeasures in each area, aiming to align trustworthy LMs with human expectations."
}