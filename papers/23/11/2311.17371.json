{
    "title": "Should we be going MAD? A Look at Multi-Agent Debate Strategies for LLMs",
    "abstract": "arXiv:2311.17371v2 Announce Type: replace-cross  Abstract: Recent advancements in large language models (LLMs) underscore their potential for responding to inquiries in various domains. However, ensuring that generative agents provide accurate and reliable answers remains an ongoing challenge. In this context, multi-agent debate (MAD) has emerged as a promising strategy for enhancing the truthfulness of LLMs. We benchmark a range of debating and prompting strategies to explore the trade-offs between cost, time, and accuracy. Importantly, we find that multi-agent debating systems, in their current form, do not reliably outperform other proposed prompting strategies, such as self-consistency and ensembling using multiple reasoning paths. However, when performing hyperparameter tuning, several MAD systems, such as Multi-Persona, perform better. This suggests that MAD protocols might not be inherently worse than other approaches, but that they are more sensitive to different hyperparameter",
    "link": "https://arxiv.org/abs/2311.17371",
    "context": "Title: Should we be going MAD? A Look at Multi-Agent Debate Strategies for LLMs\nAbstract: arXiv:2311.17371v2 Announce Type: replace-cross  Abstract: Recent advancements in large language models (LLMs) underscore their potential for responding to inquiries in various domains. However, ensuring that generative agents provide accurate and reliable answers remains an ongoing challenge. In this context, multi-agent debate (MAD) has emerged as a promising strategy for enhancing the truthfulness of LLMs. We benchmark a range of debating and prompting strategies to explore the trade-offs between cost, time, and accuracy. Importantly, we find that multi-agent debating systems, in their current form, do not reliably outperform other proposed prompting strategies, such as self-consistency and ensembling using multiple reasoning paths. However, when performing hyperparameter tuning, several MAD systems, such as Multi-Persona, perform better. This suggests that MAD protocols might not be inherently worse than other approaches, but that they are more sensitive to different hyperparameter",
    "path": "papers/23/11/2311.17371.json",
    "total_tokens": 912,
    "translated_title": "我们应该疯狂吗？多Agent辩论策略对LLMs的影响",
    "translated_abstract": "最近大型语言模型（LLMs）的发展突显了它们在回答各种领域问题方面的潜力。然而，确保生成代理提供准确可靠的答案仍然是一个持续挑战。在这种背景下，多Agent辩论（MAD）已成为增强LLMs真实性的一种有前途的策略。我们对一系列辩论和提示策略进行基准测试，探讨成本、时间和准确性之间的权衡。重要的是，我们发现，目前形式下的多Agent辩论系统在可靠性上不一定优于其他建议的提示策略，如自一致性和使用多个推理路径进行集成。但是，在执行超参数调整时，一些MAD系统，如Multi-Persona，表现更好。这表明MAD协议可能并不会比其他方法天然更差，而是更容易受到不同超参数的影响。",
    "tldr": "多Agent辩论（MAD）作为增强大型语言模型（LLMs）真实性的策略，对于解决确保生成代理提供准确可靠答案的挑战具有潜力，但当前形式下的多Agent辩论系统在可靠性上不一定优于其他提示策略。"
}