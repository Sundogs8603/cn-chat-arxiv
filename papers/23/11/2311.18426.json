{
    "title": "Convergence Analysis of Fractional Gradient Descent. (arXiv:2311.18426v3 [math.OC] UPDATED)",
    "abstract": "Fractional derivatives are a well-studied generalization of integer order derivatives. Naturally, for optimization, it is of interest to understand the convergence properties of gradient descent using fractional derivatives. Convergence analysis of fractional gradient descent is currently limited both in the methods analyzed and the settings analyzed. This paper aims to fill in these gaps by analyzing variations of fractional gradient descent in smooth and convex, smooth and strongly convex, and smooth and non-convex settings. First, novel bounds will be established bridging fractional and integer derivatives. Then, these bounds will be applied to the aforementioned settings to prove linear convergence for smooth and strongly convex functions and $O(1/T)$ convergence for smooth and convex functions. Additionally, we prove $O(1/T)$ convergence for smooth and non-convex functions using an extended notion of smoothness - H\\\"older smoothness - that is more natural for fractional derivative",
    "link": "http://arxiv.org/abs/2311.18426",
    "context": "Title: Convergence Analysis of Fractional Gradient Descent. (arXiv:2311.18426v3 [math.OC] UPDATED)\nAbstract: Fractional derivatives are a well-studied generalization of integer order derivatives. Naturally, for optimization, it is of interest to understand the convergence properties of gradient descent using fractional derivatives. Convergence analysis of fractional gradient descent is currently limited both in the methods analyzed and the settings analyzed. This paper aims to fill in these gaps by analyzing variations of fractional gradient descent in smooth and convex, smooth and strongly convex, and smooth and non-convex settings. First, novel bounds will be established bridging fractional and integer derivatives. Then, these bounds will be applied to the aforementioned settings to prove linear convergence for smooth and strongly convex functions and $O(1/T)$ convergence for smooth and convex functions. Additionally, we prove $O(1/T)$ convergence for smooth and non-convex functions using an extended notion of smoothness - H\\\"older smoothness - that is more natural for fractional derivative",
    "path": "papers/23/11/2311.18426.json",
    "total_tokens": 931,
    "translated_title": "分数梯度下降法的收敛性分析",
    "translated_abstract": "分数导数是整数阶导数的一种广义推广。对于优化问题，研究使用分数导数的梯度下降方法的收敛性是非常有意义的。目前，对于分数梯度下降的收敛性分析在研究方法和研究环境方面都存在限制。本文旨在填补这些空白，分析了平滑且凸、平滑且强凸以及平滑且非凸环境下的分数梯度下降的变种。首先，我们将建立将分数导数与整数导数联系起来的新界限。然后，利用这些界限证明了对于平滑且强凸函数的线性收敛性和对于平滑且凸函数的O(1/T)收敛性。此外，通过使用一种更适合分数导数的扩展平滑度概念-Holder平滑度，我们还证明了对于平滑且非凸函数的O(1/T)收敛性。",
    "tldr": "本论文通过分析不同环境下的分数梯度下降方法，建立了分数导数与整数导数之间的新界限，并证明了在平滑且凸、平滑且强凸以及平滑且非凸环境下的收敛性，为分数梯度下降的收敛性分析提供了新的理论支持。",
    "en_tdlr": "This paper provides a convergence analysis of fractional gradient descent in different settings, establishes new bounds bridging fractional and integer derivatives, and proves convergence in smooth and convex, smooth and strongly convex, and smooth and non-convex environments, offering new theoretical support for the analysis of fractional gradient descent convergence."
}