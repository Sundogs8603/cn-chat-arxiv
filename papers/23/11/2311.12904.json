{
    "title": "Learning to Compute Gr\\\"obner Bases",
    "abstract": "Solving a polynomial system, or computing an associated Gr\\\"obner basis, has been a fundamental task in computational algebra. However, it is also known for its notoriously expensive computational cost - doubly exponential time complexity in the number of variables in the worst case. In this paper, we achieve for the first time Gr\\\"obner basis computation through the training of a Transformer. The training requires many pairs of a polynomial system and the associated Gr\\\"obner basis, raising two novel algebraic problems: random generation of Gr\\\"obner bases and the transformation of them into non-Gr\\\"obner polynomial systems, termed as backward Gr\\\"obner problem. We resolve these problems with zero-dimensional radical ideals, the ideals appearing in various applications. The experiments show that the proposed dataset generation method is three to six orders of magnitude faster than a naive approach, overcoming a crucial challenge in learning to compute Gr\\\"obner bases.",
    "link": "https://arxiv.org/abs/2311.12904",
    "context": "Title: Learning to Compute Gr\\\"obner Bases\nAbstract: Solving a polynomial system, or computing an associated Gr\\\"obner basis, has been a fundamental task in computational algebra. However, it is also known for its notoriously expensive computational cost - doubly exponential time complexity in the number of variables in the worst case. In this paper, we achieve for the first time Gr\\\"obner basis computation through the training of a Transformer. The training requires many pairs of a polynomial system and the associated Gr\\\"obner basis, raising two novel algebraic problems: random generation of Gr\\\"obner bases and the transformation of them into non-Gr\\\"obner polynomial systems, termed as backward Gr\\\"obner problem. We resolve these problems with zero-dimensional radical ideals, the ideals appearing in various applications. The experiments show that the proposed dataset generation method is three to six orders of magnitude faster than a naive approach, overcoming a crucial challenge in learning to compute Gr\\\"obner bases.",
    "path": "papers/23/11/2311.12904.json",
    "total_tokens": 852,
    "translated_title": "学习计算格罗布纳基",
    "translated_abstract": "解决多项式系统，或计算相关的格罗布纳基，一直是计算代数学中的基本任务。然而，众所周知，它的计算成本非常昂贵，在最坏情况下的时间复杂性是指数级双倍。在本文中，我们首次通过Transformer的训练来实现格罗布纳基的计算。训练需要许多多项式系统和相关格罗布纳基的配对，引出了两个新颖的代数问题：格罗布纳基的随机生成和将其转化为非格罗布纳多项式系统的问题，称为格罗布纳反问题。我们通过零维根正理想解决了这些问题，这些理想在各种应用中出现。实验证明，所提出的数据集生成方法比朴素方法快三到六个数量级，克服了学习计算格罗布纳基的一个关键挑战。",
    "tldr": "本文首次通过Transformer的训练实现了格罗布纳基的计算，通过解决随机生成格罗布纳基和将其转化为非格罗布纳多项式系统的问题，提出了解决计算任务中的关键挑战的方法。",
    "en_tdlr": "This paper achieves Gr\\\"obner basis computation through the training of a Transformer, resolving the key challenge of learning to compute Gr\\\"obner bases by addressing the problems of random generation of Gr\\\"obner bases and transforming them into non-Gr\\\"obner polynomial systems."
}