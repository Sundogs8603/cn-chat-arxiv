{
    "title": "CoachLM: Automatic Instruction Revisions Improve the Data Quality in LLM Instruction Tuning",
    "abstract": "arXiv:2311.13246v2 Announce Type: replace  Abstract: Instruction tuning is crucial for enabling Language Learning Models (LLMs) in responding to human instructions. The quality of instruction pairs used for tuning greatly affects the performance of LLMs. However, the manual creation of high-quality instruction datasets is costly, leading to the adoption of automatic generation of instruction pairs by LLMs as a popular alternative. To ensure the high quality of LLM-generated instruction datasets, several approaches have been proposed. Nevertheless, existing methods either compromise dataset integrity by filtering a large proportion of samples, or are unsuitable for industrial applications. In this paper, instead of discarding low-quality samples, we propose CoachLM, a novel approach to enhance the quality of instruction datasets through automatic revisions on samples in the dataset. CoachLM is trained from the samples revised by human experts and significantly increases the proportion o",
    "link": "https://arxiv.org/abs/2311.13246",
    "context": "Title: CoachLM: Automatic Instruction Revisions Improve the Data Quality in LLM Instruction Tuning\nAbstract: arXiv:2311.13246v2 Announce Type: replace  Abstract: Instruction tuning is crucial for enabling Language Learning Models (LLMs) in responding to human instructions. The quality of instruction pairs used for tuning greatly affects the performance of LLMs. However, the manual creation of high-quality instruction datasets is costly, leading to the adoption of automatic generation of instruction pairs by LLMs as a popular alternative. To ensure the high quality of LLM-generated instruction datasets, several approaches have been proposed. Nevertheless, existing methods either compromise dataset integrity by filtering a large proportion of samples, or are unsuitable for industrial applications. In this paper, instead of discarding low-quality samples, we propose CoachLM, a novel approach to enhance the quality of instruction datasets through automatic revisions on samples in the dataset. CoachLM is trained from the samples revised by human experts and significantly increases the proportion o",
    "path": "papers/23/11/2311.13246.json",
    "total_tokens": 798,
    "translated_title": "CoachLM：自动指导修订提高LLM指导调整中的数据质量",
    "translated_abstract": "指导调整对于使语言学习模型（LLM）能够回应人类指令至关重要。用于调整的指令对的质量极大影响LLM的性能。然而，人工创建高质量指令数据集成本高，导致LLM的自动生成指令对被广泛采纳作为一种流行的替代方法。为了确保LLM生成的指导数据集的高质量，提出了几种方法。然而，现有方法要么通过过滤大量样本来降低数据集完整性，要么不适合工业应用。在本文中，我们提出CoachLM，一个新颖的方法，通过对数据集中的样本进行自动修订来增强指导数据集的质量。CoachLM是从专家修订的样本中训练出来的，并显著增加了",
    "tldr": "CoachLM 提出了一种新颖方法来增强指导数据集的质量，通过自动修订样本而非丢弃低质量样本，从而解决了现有方法的局限性。"
}