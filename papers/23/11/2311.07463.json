{
    "title": "MEGAVERSE: Benchmarking Large Language Models Across Languages, Modalities, Models and Tasks",
    "abstract": "arXiv:2311.07463v2 Announce Type: replace  Abstract: There has been a surge in LLM evaluation research to understand LLM capabilities and limitations. However, much of this research has been confined to English, leaving LLM building and evaluation for non-English languages relatively unexplored. Several new LLMs have been introduced recently, necessitating their evaluation on non-English languages. This study aims to perform a thorough evaluation of the non-English capabilities of SoTA LLMs (GPT-3.5-Turbo, GPT-4, PaLM2, Gemini-Pro, Mistral, Llama2, and Gemma) by comparing them on the same set of multilingual datasets. Our benchmark comprises 22 datasets covering 83 languages, including low-resource African languages. We also include two multimodal datasets in the benchmark and compare the performance of LLaVA models, GPT-4-Vision and Gemini-Pro-Vision. Our experiments show that larger models such as GPT-4, Gemini-Pro and PaLM2 outperform smaller models on various tasks, notably on low-",
    "link": "https://arxiv.org/abs/2311.07463",
    "context": "Title: MEGAVERSE: Benchmarking Large Language Models Across Languages, Modalities, Models and Tasks\nAbstract: arXiv:2311.07463v2 Announce Type: replace  Abstract: There has been a surge in LLM evaluation research to understand LLM capabilities and limitations. However, much of this research has been confined to English, leaving LLM building and evaluation for non-English languages relatively unexplored. Several new LLMs have been introduced recently, necessitating their evaluation on non-English languages. This study aims to perform a thorough evaluation of the non-English capabilities of SoTA LLMs (GPT-3.5-Turbo, GPT-4, PaLM2, Gemini-Pro, Mistral, Llama2, and Gemma) by comparing them on the same set of multilingual datasets. Our benchmark comprises 22 datasets covering 83 languages, including low-resource African languages. We also include two multimodal datasets in the benchmark and compare the performance of LLaVA models, GPT-4-Vision and Gemini-Pro-Vision. Our experiments show that larger models such as GPT-4, Gemini-Pro and PaLM2 outperform smaller models on various tasks, notably on low-",
    "path": "papers/23/11/2311.07463.json",
    "total_tokens": 909,
    "translated_title": "MEGAVERSE: 在语言、模态、模型和任务之间对大型语言模型进行基准测试",
    "translated_abstract": "LLM评估研究激增，旨在了解LLM的能力和局限性。然而，大部分研究局限于英语，使得LLM在非英语语言上的搭建和评估相对未被探索。本研究旨在通过比较SoTA LLM（GPT-3.5-Turbo、GPT-4、PaLM2、Gemini-Pro、Mistral、Llama2和Gemma）在相同多语言数据集上的表现，对非英语能力进行彻底评估。我们的基准包括22个数据集，覆盖83种语言，其中包括低资源的非洲语言。我们还在基准测试中包括两个多模态数据集，并比较了LLaVA模型、GPT-4-Vision和Gemini-Pro-Vision的性能。我们的实验表明，像GPT-4、Gemini-Pro和PaLM2这样的更大型模型在各种任务上表现优于较小型模型，特别是在低资源情况下。",
    "tldr": "该研究对多语言数据集上的最新LLM进行了全面评估，结果显示较大型的模型如GPT-4、Gemini-Pro和PaLM2在各种任务上表现优越。",
    "en_tdlr": "This study conducts a comprehensive evaluation of the latest LLMs on multilingual datasets, showing that larger models such as GPT-4, Gemini-Pro, and PaLM2 outperform smaller models on various tasks."
}