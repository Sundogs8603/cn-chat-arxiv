{
    "title": "Generalisable Agents for Neural Network Optimisation",
    "abstract": "arXiv:2311.18598v2 Announce Type: replace-cross  Abstract: Optimising deep neural networks is a challenging task due to complex training dynamics, high computational requirements, and long training times. To address this difficulty, we propose the framework of Generalisable Agents for Neural Network Optimisation (GANNO) -- a multi-agent reinforcement learning (MARL) approach that learns to improve neural network optimisation by dynamically and responsively scheduling hyperparameters during training. GANNO utilises an agent per layer that observes localised network dynamics and accordingly takes actions to adjust these dynamics at a layerwise level to collectively improve global performance. In this paper, we use GANNO to control the layerwise learning rate and show that the framework can yield useful and responsive schedules that are competitive with handcrafted heuristics. Furthermore, GANNO is shown to perform robustly across a wide variety of unseen initial conditions, and can succe",
    "link": "https://arxiv.org/abs/2311.18598",
    "context": "Title: Generalisable Agents for Neural Network Optimisation\nAbstract: arXiv:2311.18598v2 Announce Type: replace-cross  Abstract: Optimising deep neural networks is a challenging task due to complex training dynamics, high computational requirements, and long training times. To address this difficulty, we propose the framework of Generalisable Agents for Neural Network Optimisation (GANNO) -- a multi-agent reinforcement learning (MARL) approach that learns to improve neural network optimisation by dynamically and responsively scheduling hyperparameters during training. GANNO utilises an agent per layer that observes localised network dynamics and accordingly takes actions to adjust these dynamics at a layerwise level to collectively improve global performance. In this paper, we use GANNO to control the layerwise learning rate and show that the framework can yield useful and responsive schedules that are competitive with handcrafted heuristics. Furthermore, GANNO is shown to perform robustly across a wide variety of unseen initial conditions, and can succe",
    "path": "papers/23/11/2311.18598.json",
    "total_tokens": 846,
    "translated_title": "通用智能体用于神经网络优化",
    "translated_abstract": "深度神经网络的优化是一项具有挑战性的任务，原因在于复杂的训练动态、高计算要求和长时间训练。为了解决这一困难，我们提出了通用智能体用于神经网络优化（GANNO）的框架--一种多智能体强化学习（MARL）方法，通过动态和响应式地调度超参数来优化神经网络训练。GANNO利用每层一个智能体观察局部化的网络动态，并相应地采取行动来调整这些动态，从而在层级上集体改善全局性能。本文中，我们使用GANNO来控制层级学习率，并展示该框架可以产生有用且响应灵活的调度，与手工设计的启发式方法相竞争。此外，显示GANNO在各种看不见的初始条件下表现出稳健性，并且能够成功...",
    "tldr": "通用智能体用于神经网络优化是一种多智能体强化学习方法，通过动态调度超参数来优化神经网络训练，可以有效改善全局性能并与手工设计启发式方法相竞争。",
    "en_tdlr": "Generalisable Agents for Neural Network Optimisation is a multi-agent reinforcement learning approach that dynamically schedules hyperparameters to optimize neural network training, effectively improving global performance and competing with handcrafted heuristics."
}