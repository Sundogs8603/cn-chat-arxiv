{
    "title": "GistScore: Learning Better Representations for In-Context Example Selection with Gist Bottlenecks",
    "abstract": "arXiv:2311.09606v2 Announce Type: replace  Abstract: In-context Learning (ICL) is the ability of Large Language Models (LLMs) to perform new tasks when conditioned on prompts comprising a few task examples. However, ICL performance can be critically sensitive to the choice of examples. To dynamically select the best examples for every test input, we propose Example Gisting, a novel approach for training example encoders through supervised fine-tuning with an attention bottleneck between the inputs and outputs. These gist models form the basis for GistScore, a novel metric for scoring and selecting informative examples. Further, we experiment with two variations: (1) fine-tuning gist models for each dataset and (2) multi-task training a single model on a large collection of datasets. The latter can be used for new tasks out-of-the-box, enabling a training-free ICL pipeline. Evaluations with 21 datasets spanning 9 tasks and 8 diverse LLMs show that our fine-tuned models get state-of-the-",
    "link": "https://arxiv.org/abs/2311.09606",
    "context": "Title: GistScore: Learning Better Representations for In-Context Example Selection with Gist Bottlenecks\nAbstract: arXiv:2311.09606v2 Announce Type: replace  Abstract: In-context Learning (ICL) is the ability of Large Language Models (LLMs) to perform new tasks when conditioned on prompts comprising a few task examples. However, ICL performance can be critically sensitive to the choice of examples. To dynamically select the best examples for every test input, we propose Example Gisting, a novel approach for training example encoders through supervised fine-tuning with an attention bottleneck between the inputs and outputs. These gist models form the basis for GistScore, a novel metric for scoring and selecting informative examples. Further, we experiment with two variations: (1) fine-tuning gist models for each dataset and (2) multi-task training a single model on a large collection of datasets. The latter can be used for new tasks out-of-the-box, enabling a training-free ICL pipeline. Evaluations with 21 datasets spanning 9 tasks and 8 diverse LLMs show that our fine-tuned models get state-of-the-",
    "path": "papers/23/11/2311.09606.json",
    "total_tokens": 865,
    "translated_title": "GistScore：通过要点瓶颈学习更好的上下文示例选择表示",
    "translated_abstract": "上下文学习（ICL）是大型语言模型（LLMs）在以包含少量任务示例的提示为条件时执行新任务的能力。然而，ICL的性能可能对示例的选择非常敏感。为了动态地为每个测试输入选择最佳示例，我们提出了示例要点提取（Example Gisting），这是一种通过具有输入和输出之间的注意力瓶颈进行监督微调的训练示例编码器的新方法。这些要点模型构成了GistScore的基础，这是一种用于评分和选择信息示例的新指标。此外，我们尝试了两种变体：（1）对每个数据集微调要点模型和（2）在大量数据集上进行多任务培训单一模型。后者可用于开箱即用地处理新任务，实现无需训练的ICL流水线。对涵盖9个任务和8种不同LLMs的21个数据集进行评估表明，我们微调的模型达到了最顶尖的水平。",
    "tldr": "提出了示例要点提取的方法，通过要点模型形成了新的分数评估方式，可以用于动态选择最佳示例，提高上下文示例选择的性能。",
    "en_tdlr": "Introduced Example Gisting method and formed a new scoring metric using gist models for dynamically selecting best examples to improve performance in in-context example selection."
}