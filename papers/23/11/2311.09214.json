{
    "title": "Mind's Mirror: Distilling Self-Evaluation Capability and Comprehensive Thinking from Large Language Models",
    "abstract": "arXiv:2311.09214v2 Announce Type: replace  Abstract: Large language models (LLMs) have achieved remarkable advancements in natural language processing. However, the massive scale and computational demands of these models present formidable challenges when considering their practical deployment in resource-constrained environments. While techniques such as chain-of-thought (CoT) distillation have displayed promise in distilling LLMs into small language models (SLMs), there is a risk that distilled SLMs may still inherit flawed reasoning and hallucinations from LLMs. To address these issues, we propose a twofold methodology: First, we introduce a novel method for distilling the self-evaluation capability from LLMs into SLMs, aiming to mitigate the adverse effects of flawed reasoning and hallucinations inherited from LLMs. Second, we advocate for distilling more comprehensive thinking by incorporating multiple distinct CoTs and self-evaluation outputs, to ensure a more thorough and robust",
    "link": "https://arxiv.org/abs/2311.09214",
    "context": "Title: Mind's Mirror: Distilling Self-Evaluation Capability and Comprehensive Thinking from Large Language Models\nAbstract: arXiv:2311.09214v2 Announce Type: replace  Abstract: Large language models (LLMs) have achieved remarkable advancements in natural language processing. However, the massive scale and computational demands of these models present formidable challenges when considering their practical deployment in resource-constrained environments. While techniques such as chain-of-thought (CoT) distillation have displayed promise in distilling LLMs into small language models (SLMs), there is a risk that distilled SLMs may still inherit flawed reasoning and hallucinations from LLMs. To address these issues, we propose a twofold methodology: First, we introduce a novel method for distilling the self-evaluation capability from LLMs into SLMs, aiming to mitigate the adverse effects of flawed reasoning and hallucinations inherited from LLMs. Second, we advocate for distilling more comprehensive thinking by incorporating multiple distinct CoTs and self-evaluation outputs, to ensure a more thorough and robust",
    "path": "papers/23/11/2311.09214.json",
    "total_tokens": 794,
    "translated_title": "Mind's Mirror: 从大型语言模型中提取自我评估能力和综合思维",
    "translated_abstract": "大型语言模型（LLMs）在自然语言处理领域取得了显著进展。然而，这些模型的大规模和计算需求在考虑它们在资源受限环境中的实际部署时带来了巨大挑战。我们提出了一种双重方法论：首先，我们引入了一种新的方法，将LLMs中的自我评估能力提炼到SLMs中，旨在减轻从LLMs继承的错误推理和幻觉的不良影响。其次，我们提倡通过整合多个不同的CoTs和自我评估输出来提炼更全面的思维，以确保更为彻底和健壮。",
    "tldr": "本研究提出了一种从大型语言模型中提取自我评估能力和综合思维的方法，旨在解决小语言模型继承不完善推理和幻觉的问题。",
    "en_tdlr": "This study proposes a method to distill self-evaluation capability and comprehensive thinking from large language models, aiming to address the issue of flawed reasoning and hallucinations inherited by small language models."
}