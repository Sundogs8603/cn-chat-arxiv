{
    "title": "Principles from Clinical Research for NLP Model Generalization",
    "abstract": "arXiv:2311.03663v3 Announce Type: replace  Abstract: The NLP community typically relies on performance of a model on a held-out test set to assess generalization. Performance drops observed in datasets outside of official test sets are generally attributed to \"out-of-distribution\" effects. Here, we explore the foundations of generalizability and study the factors that affect it, articulating lessons from clinical studies. In clinical research, generalizability is an act of reasoning that depends on (a) internal validity of experiments to ensure controlled measurement of cause and effect, and (b) external validity or transportability of the results to the wider population. We demonstrate how learning spurious correlations, such as the distance between entities in relation extraction tasks, can affect a model's internal validity and in turn adversely impact generalization. We, therefore, present the need to ensure internal validity when building machine learning models in NLP. Our recomm",
    "link": "https://arxiv.org/abs/2311.03663",
    "context": "Title: Principles from Clinical Research for NLP Model Generalization\nAbstract: arXiv:2311.03663v3 Announce Type: replace  Abstract: The NLP community typically relies on performance of a model on a held-out test set to assess generalization. Performance drops observed in datasets outside of official test sets are generally attributed to \"out-of-distribution\" effects. Here, we explore the foundations of generalizability and study the factors that affect it, articulating lessons from clinical studies. In clinical research, generalizability is an act of reasoning that depends on (a) internal validity of experiments to ensure controlled measurement of cause and effect, and (b) external validity or transportability of the results to the wider population. We demonstrate how learning spurious correlations, such as the distance between entities in relation extraction tasks, can affect a model's internal validity and in turn adversely impact generalization. We, therefore, present the need to ensure internal validity when building machine learning models in NLP. Our recomm",
    "path": "papers/23/11/2311.03663.json",
    "total_tokens": 835,
    "translated_title": "临床研究原则在自然语言处理模型泛化中的应用",
    "translated_abstract": "NLP社区通常依赖模型在保留测试集上的表现来评估泛化能力。在官方测试集之外的数据集中观察到的性能下降通常归因于“非分布”效应。本文探讨了泛化性的基础并研究了影响它的因素，阐述了临床研究中的教训。在临床研究中，泛化性是一种依赖于实验的内部验证来确保对因果关系进行受控测量以及结果对更广泛人群的外部验证或可传输性的推理行为。我们演示了学习虚假相关性，比如在关系抽取任务中实体之间的距离，如何影响模型的内部验证，从而对泛化产生不利影响。因此，我们提出了在构建自然语言处理中的机器学习模型时需要确保内部验证的必要性。",
    "tldr": "临床研究中的泛化性原则指导下，对自然语言处理模型内部验证的重要性及影响泛化的因素进行研究分析",
    "en_tdlr": "Investigating the importance of internal validation in NLP models under the guidance of generalization principles from clinical research, highlighting factors affecting generalization."
}