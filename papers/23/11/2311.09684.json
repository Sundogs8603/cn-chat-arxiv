{
    "title": "Do Physicians Know How to Prompt? The Need for Automatic Prompt Optimization Help in Clinical Note Generation",
    "abstract": "arXiv:2311.09684v2 Announce Type: replace-cross  Abstract: This study examines the effect of prompt engineering on the performance of Large Language Models (LLMs) in clinical note generation. We introduce an Automatic Prompt Optimization (APO) framework to refine initial prompts and compare the outputs of medical experts, non-medical experts, and APO-enhanced GPT3.5 and GPT4. Results highlight GPT4 APO's superior performance in standardizing prompt quality across clinical note sections. A human-in-the-loop approach shows that experts maintain content quality post-APO, with a preference for their own modifications, suggesting the value of expert customization. We recommend a two-phase optimization process, leveraging APO-GPT4 for consistency and expert input for personalization.",
    "link": "https://arxiv.org/abs/2311.09684",
    "context": "Title: Do Physicians Know How to Prompt? The Need for Automatic Prompt Optimization Help in Clinical Note Generation\nAbstract: arXiv:2311.09684v2 Announce Type: replace-cross  Abstract: This study examines the effect of prompt engineering on the performance of Large Language Models (LLMs) in clinical note generation. We introduce an Automatic Prompt Optimization (APO) framework to refine initial prompts and compare the outputs of medical experts, non-medical experts, and APO-enhanced GPT3.5 and GPT4. Results highlight GPT4 APO's superior performance in standardizing prompt quality across clinical note sections. A human-in-the-loop approach shows that experts maintain content quality post-APO, with a preference for their own modifications, suggesting the value of expert customization. We recommend a two-phase optimization process, leveraging APO-GPT4 for consistency and expert input for personalization.",
    "path": "papers/23/11/2311.09684.json",
    "total_tokens": 826,
    "translated_title": "医生们知道如何提醒吗？临床笔记生成中自动提示优化帮助的需求",
    "translated_abstract": "本研究考察了提示工程对大型语言模型（LLMs）在临床笔记生成中性能的影响。我们引入了一个自动提示优化（APO）框架来改进初始提示，并比较了医学专家、非医学专家以及经过APO增强的GPT3.5和GPT4的输出。结果突显了GPT4 APO在标准化临床笔记各节提示质量方面的卓越性能。人在环中方法显示，专家在APO后保持内容质量，但更偏好自己的修改，表明了专家定制的价值。我们建议采用两阶段优化过程，利用APO-GPT4确保一致性，同时结合专家输入进行个性化。",
    "tldr": "本研究提出了自动提示优化（APO）框架，评估了不同提示对于大型语言模型在临床笔记生成中性能的影响，结果表明GPT4 APO在标准化提升质量方面表现出色，并强调了专家定制化对于内容质量的价值。"
}