{
    "title": "Class Distribution Shifts in Zero-Shot Learning: Learning Robust Representations",
    "abstract": "Class distribution shifts are particularly challenging for zero-shot classifiers, which rely on representations learned from training classes but are deployed on new, unseen ones. Common causes for such shifts are changes in attributes associated with classes, such as race or gender in person identification. In this work, we propose and analyze a model that adopts this setting, assuming that the attribute responsible for the shift is unknown during training. To address the challenge of learning data representations robust to such shifts, we introduce a framework based on hierarchical sampling to construct synthetic data environments. Despite key differences between the settings, this framework allows us to formulate class distribution shifts in zero-shot learning as out-of-distribution problems. Consequently, we present an algorithm for learning robust representations, and show that our approach significantly improves generalization to diverse class distributions in both simulations an",
    "link": "https://arxiv.org/abs/2311.18575",
    "context": "Title: Class Distribution Shifts in Zero-Shot Learning: Learning Robust Representations\nAbstract: Class distribution shifts are particularly challenging for zero-shot classifiers, which rely on representations learned from training classes but are deployed on new, unseen ones. Common causes for such shifts are changes in attributes associated with classes, such as race or gender in person identification. In this work, we propose and analyze a model that adopts this setting, assuming that the attribute responsible for the shift is unknown during training. To address the challenge of learning data representations robust to such shifts, we introduce a framework based on hierarchical sampling to construct synthetic data environments. Despite key differences between the settings, this framework allows us to formulate class distribution shifts in zero-shot learning as out-of-distribution problems. Consequently, we present an algorithm for learning robust representations, and show that our approach significantly improves generalization to diverse class distributions in both simulations an",
    "path": "papers/23/11/2311.18575.json",
    "total_tokens": 970,
    "translated_title": "零样本学习中的类别分布转移：学习鲁棒表示",
    "translated_abstract": "类别分布转移对零样本分类器来说尤为具有挑战性，因为它们依赖于从训练类别学到的表示，但部署在新的、未知的类别上。常见的类别分布转移原因是与类别相关的属性的改变，比如在人物识别中的种族或性别。在这项工作中，我们提出并分析了一个采用这个设置的模型，假设在训练过程中未知导致转移的属性。为了解决学习对这种转移鲁棒的数据表示的挑战，我们引入了一种基于分层抽样的框架来构建合成数据环境。尽管两种设置之间存在关键差异，但这个框架使我们能够将零样本学习中的类别分布转移转化为分布外问题。因此，我们提出了一种学习鲁棒表示的算法，并展示了我们的方法在模拟和真实数据集上显著改善了对不同类别分布的泛化能力。",
    "tldr": "本文提出了一个模型来处理零样本学习中的类别分布转移问题，该模型假设转移原因在训练过程中是未知的属性。通过引入基于分层抽样的框架构建合成数据环境，我们能够将类别分布转移看作分布外问题，并提出了一种学习鲁棒表示的算法。实验结果表明，我们的方法在不同类别分布上的泛化能力显著提高。"
}