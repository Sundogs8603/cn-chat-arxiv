{
    "title": "Deep Regularized Compound Gaussian Network for Solving Linear Inverse Problems",
    "abstract": "arXiv:2311.17248v2 Announce Type: replace-cross  Abstract: Incorporating prior information into inverse problems, e.g. via maximum-a-posteriori estimation, is an important technique for facilitating robust inverse problem solutions. In this paper, we devise two novel approaches for linear inverse problems that permit problem-specific statistical prior selections within the compound Gaussian (CG) class of distributions. The CG class subsumes many commonly used priors in signal and image reconstruction methods including those of sparsity-based approaches. The first method developed is an iterative algorithm, called generalized compound Gaussian least squares (G-CG-LS), that minimizes a regularized least squares objective function where the regularization enforces a CG prior. G-CG-LS is then unrolled, or unfolded, to furnish our second method, which is a novel deep regularized (DR) neural network, called DR-CG-Net, that learns the prior information. A detailed computational theory on conv",
    "link": "https://arxiv.org/abs/2311.17248",
    "context": "Title: Deep Regularized Compound Gaussian Network for Solving Linear Inverse Problems\nAbstract: arXiv:2311.17248v2 Announce Type: replace-cross  Abstract: Incorporating prior information into inverse problems, e.g. via maximum-a-posteriori estimation, is an important technique for facilitating robust inverse problem solutions. In this paper, we devise two novel approaches for linear inverse problems that permit problem-specific statistical prior selections within the compound Gaussian (CG) class of distributions. The CG class subsumes many commonly used priors in signal and image reconstruction methods including those of sparsity-based approaches. The first method developed is an iterative algorithm, called generalized compound Gaussian least squares (G-CG-LS), that minimizes a regularized least squares objective function where the regularization enforces a CG prior. G-CG-LS is then unrolled, or unfolded, to furnish our second method, which is a novel deep regularized (DR) neural network, called DR-CG-Net, that learns the prior information. A detailed computational theory on conv",
    "path": "papers/23/11/2311.17248.json",
    "total_tokens": 833,
    "translated_title": "用于解决线性逆问题的深度正则化复合高斯网络",
    "translated_abstract": "将先验信息纳入逆问题，例如通过最大后验估计，是促进稳健逆问题解决方案的重要技术。本文为允许在复合高斯（CG）分布类中进行问题特定统计先验选择的线性逆问题设计了两种新方法。第一种方法是一种迭代算法，称为广义复合高斯最小二乘（G-CG-LS），它最小化了一个正则化最小二乘目标函数，其中正则化强制执行一个CG先验。然后将G-CG-LS展开，提供我们的第二种方法，这是一种新颖的深度正则化（DR）神经网络，称为DR-CG-Net，可以学习先验信息。",
    "tldr": "提出了两种允许在复合高斯分布类中进行问题特定统计先验选择的线性逆问题新方法，一种是迭代算法广义复合高斯最小二乘，另一种是通过展开得到的新颖深度正则化神经网络DR-CG-Net。",
    "en_tdlr": "Two novel approaches for linear inverse problems that permit problem-specific statistical prior selections within the compound Gaussian (CG) class of distributions are proposed, including an iterative algorithm called generalized compound Gaussian least squares (G-CG-LS) and a deep regularized (DR) neural network called DR-CG-Net that learns the prior information."
}