{
    "title": "A Generative Model for Accelerated Inverse Modelling Using a Novel Embedding for Continuous Variables",
    "abstract": "arXiv:2311.11343v2 Announce Type: replace  Abstract: In materials science, the challenge of rapid prototyping materials with desired properties often involves extensive experimentation to find suitable microstructures. Additionally, finding microstructures for given properties is typically an ill-posed problem where multiple solutions may exist. Using generative machine learning models can be a viable solution which also reduces the computational cost. This comes with new challenges because, e.g., a continuous property variable as conditioning input to the model is required. We investigate the shortcomings of an existing method and compare this to a novel embedding strategy for generative models that is based on the binary representation of floating point numbers. This eliminates the need for normalization, preserves information, and creates a versatile embedding space for conditioning the generative model. This technique can be applied to condition a network on any number, to provide ",
    "link": "https://arxiv.org/abs/2311.11343",
    "context": "Title: A Generative Model for Accelerated Inverse Modelling Using a Novel Embedding for Continuous Variables\nAbstract: arXiv:2311.11343v2 Announce Type: replace  Abstract: In materials science, the challenge of rapid prototyping materials with desired properties often involves extensive experimentation to find suitable microstructures. Additionally, finding microstructures for given properties is typically an ill-posed problem where multiple solutions may exist. Using generative machine learning models can be a viable solution which also reduces the computational cost. This comes with new challenges because, e.g., a continuous property variable as conditioning input to the model is required. We investigate the shortcomings of an existing method and compare this to a novel embedding strategy for generative models that is based on the binary representation of floating point numbers. This eliminates the need for normalization, preserves information, and creates a versatile embedding space for conditioning the generative model. This technique can be applied to condition a network on any number, to provide ",
    "path": "papers/23/11/2311.11343.json",
    "total_tokens": 807,
    "translated_title": "一种用于加速反向建模的生成模型，使用了一种连续变量的新型嵌入",
    "translated_abstract": "在材料科学中，快速原型制作具有所需性能的材料的挑战通常涉及大量的实验，以找到合适的微结构。此外，对于给定性能寻找微结构通常是一个不适定问题，可能存在多个解决方案。使用生成式机器学习模型可以是一个可行的解决方案，同时减少计算成本。然而，这也带来了新的挑战，例如，需要将连续属性变量作为模型的条件输入。我们研究了现有方法的缺点，并将其与一种基于浮点数的二进制表示的生成模型的新型嵌入策略进行了比较。这种方法消除了归一化的需要，保留了信息，并为生成模型的条件提供了一个多功能的嵌入空间。",
    "tldr": "提出了一种用于加速反向建模的生成模型，利用了新型的连续变量嵌入策略，消除了归一化的需要，保留信息并创造了一个多功能的嵌入空间。",
    "en_tdlr": "A generative model for accelerated inverse modeling is proposed, utilizing a novel embedding strategy for continuous variables, eliminating the need for normalization, preserving information, and creating a versatile embedding space."
}