{
    "title": "Kinematic-aware Prompting for Generalizable Articulated Object Manipulation with LLMs",
    "abstract": "arXiv:2311.02847v3 Announce Type: replace-cross  Abstract: Generalizable articulated object manipulation is essential for home-assistant robots. Recent efforts focus on imitation learning from demonstrations or reinforcement learning in simulation, however, due to the prohibitive costs of real-world data collection and precise object simulation, it still remains challenging for these works to achieve broad adaptability across diverse articulated objects. Recently, many works have tried to utilize the strong in-context learning ability of Large Language Models (LLMs) to achieve generalizable robotic manipulation, but most of these researches focus on high-level task planning, sidelining low-level robotic control. In this work, building on the idea that the kinematic structure of the object determines how we can manipulate it, we propose a kinematic-aware prompting framework that prompts LLMs with kinematic knowledge of objects to generate low-level motion trajectory waypoints, supportin",
    "link": "https://arxiv.org/abs/2311.02847",
    "context": "Title: Kinematic-aware Prompting for Generalizable Articulated Object Manipulation with LLMs\nAbstract: arXiv:2311.02847v3 Announce Type: replace-cross  Abstract: Generalizable articulated object manipulation is essential for home-assistant robots. Recent efforts focus on imitation learning from demonstrations or reinforcement learning in simulation, however, due to the prohibitive costs of real-world data collection and precise object simulation, it still remains challenging for these works to achieve broad adaptability across diverse articulated objects. Recently, many works have tried to utilize the strong in-context learning ability of Large Language Models (LLMs) to achieve generalizable robotic manipulation, but most of these researches focus on high-level task planning, sidelining low-level robotic control. In this work, building on the idea that the kinematic structure of the object determines how we can manipulate it, we propose a kinematic-aware prompting framework that prompts LLMs with kinematic knowledge of objects to generate low-level motion trajectory waypoints, supportin",
    "path": "papers/23/11/2311.02847.json",
    "total_tokens": 846,
    "translated_title": "使用LLMs的运动学感知提示实现对可移动物体的泛化操作",
    "translated_abstract": "泛化的可移动物体操作对于家庭助手机器人至关重要。最近的研究主要集中在从演示中进行模仿学习或在模拟环境中进行强化学习，然而，由于实际数据收集和精确对象模拟成本高昂，这些工作仍然难以在多样的可移动物体上实现广泛的适应性。最近，许多研究尝试利用大型语言模型（LLMs）的强大上下文学习能力实现可泛化的机器人操作，但大多数研究侧重于高层任务规划，忽视了低层的机器人控制。在这项工作中，基于一个理念，即物体的运动学结构决定了我们如何操纵它，我们提出了一个运动学感知提示框架，用物体的运动学知识提示LLMs生成低层运动轨迹位点，支持",
    "tldr": "基于物体的运动学结构，提出了一种运动学感知提示框架，用于生成LLMs的低级运动轨迹位点，以实现对可移动物体的泛化操作"
}