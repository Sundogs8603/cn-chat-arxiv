{
    "title": "Transforming Radiance Field with Lipschitz Network for Photorealistic 3D Scene Stylization. (arXiv:2303.13232v1 [cs.CV])",
    "abstract": "Recent advances in 3D scene representation and novel view synthesis have witnessed the rise of Neural Radiance Fields (NeRFs). Nevertheless, it is not trivial to exploit NeRF for the photorealistic 3D scene stylization task, which aims to generate visually consistent and photorealistic stylized scenes from novel views. Simply coupling NeRF with photorealistic style transfer (PST) will result in cross-view inconsistency and degradation of stylized view syntheses. Through a thorough analysis, we demonstrate that this non-trivial task can be simplified in a new light: When transforming the appearance representation of a pre-trained NeRF with Lipschitz mapping, the consistency and photorealism across source views will be seamlessly encoded into the syntheses. That motivates us to build a concise and flexible learning framework namely LipRF, which upgrades arbitrary 2D PST methods with Lipschitz mapping tailored for the 3D scene. Technically, LipRF first pre-trains a radiance field to recon",
    "link": "http://arxiv.org/abs/2303.13232",
    "context": "Title: Transforming Radiance Field with Lipschitz Network for Photorealistic 3D Scene Stylization. (arXiv:2303.13232v1 [cs.CV])\nAbstract: Recent advances in 3D scene representation and novel view synthesis have witnessed the rise of Neural Radiance Fields (NeRFs). Nevertheless, it is not trivial to exploit NeRF for the photorealistic 3D scene stylization task, which aims to generate visually consistent and photorealistic stylized scenes from novel views. Simply coupling NeRF with photorealistic style transfer (PST) will result in cross-view inconsistency and degradation of stylized view syntheses. Through a thorough analysis, we demonstrate that this non-trivial task can be simplified in a new light: When transforming the appearance representation of a pre-trained NeRF with Lipschitz mapping, the consistency and photorealism across source views will be seamlessly encoded into the syntheses. That motivates us to build a concise and flexible learning framework namely LipRF, which upgrades arbitrary 2D PST methods with Lipschitz mapping tailored for the 3D scene. Technically, LipRF first pre-trains a radiance field to recon",
    "path": "papers/23/03/2303.13232.json",
    "total_tokens": 924,
    "translated_title": "利普希茨网络转换辐射场，实现逼真的三维场景风格化",
    "translated_abstract": "近年来，神经辐射场（NeRFs）在3D场景建模和新视角合成方面取得了重要进展。然而，利用NeRF进行逼真的三维场景风格化并不容易，因为它需要从新视角生成具有视觉一致性和逼真度的风格化场景。将NeRF和逼真的风格迁移（PST）相结合，会导致跨视角不一致和风格化视角合成的降质。经过深入分析，我们证明这一非常规任务可以以新的方法简化处理：使用利普希茨映射转换预训练的NeRF的外观表示，则会无缝地将源视角的一致性和逼真性编码到合成图像中。这启发我们构建了一个简洁、灵活的学习框架LipRF，通过利普希茨映射升级任何适用于三维场景的二维PST方法。",
    "tldr": "本文介绍了一个名为LipRF的学习框架，可以使用利普希茨映射将预训练的NeRF的外观表示转换为具有视觉一致性和逼真度的风格化场景。",
    "en_tdlr": "This paper introduces a learning framework called LipRF, which transforms the appearance representation of pre-trained NeRF with Lipschitz mapping to generate visually consistent and photorealistic stylized scenes, simplifying the non-trivial task of 3D scene stylization."
}