{
    "title": "DSD$^2$: Can We Dodge Sparse Double Descent and Compress the Neural Network Worry-Free?",
    "abstract": "Neoteric works have shown that modern deep learning models can exhibit a sparse double descent phenomenon. Indeed, as the sparsity of the model increases, the test performance first worsens since the model is overfitting the training data; then, the overfitting reduces, leading to an improvement in performance, and finally, the model begins to forget critical information, resulting in underfitting. Such a behavior prevents using traditional early stop criteria. In this work, we have three key contributions. First, we propose a learning framework that avoids such a phenomenon and improves generalization. Second, we introduce an entropy measure providing more insights into the insurgence of this phenomenon and enabling the use of traditional stop criteria. Third, we provide a comprehensive quantitative analysis of contingent factors such as re-initialization methods, model width and depth, and dataset noise. The contributions are supported by empirical evidence in typical setups. Our cod",
    "link": "https://arxiv.org/abs/2303.01213",
    "context": "Title: DSD$^2$: Can We Dodge Sparse Double Descent and Compress the Neural Network Worry-Free?\nAbstract: Neoteric works have shown that modern deep learning models can exhibit a sparse double descent phenomenon. Indeed, as the sparsity of the model increases, the test performance first worsens since the model is overfitting the training data; then, the overfitting reduces, leading to an improvement in performance, and finally, the model begins to forget critical information, resulting in underfitting. Such a behavior prevents using traditional early stop criteria. In this work, we have three key contributions. First, we propose a learning framework that avoids such a phenomenon and improves generalization. Second, we introduce an entropy measure providing more insights into the insurgence of this phenomenon and enabling the use of traditional stop criteria. Third, we provide a comprehensive quantitative analysis of contingent factors such as re-initialization methods, model width and depth, and dataset noise. The contributions are supported by empirical evidence in typical setups. Our cod",
    "path": "papers/23/03/2303.01213.json",
    "total_tokens": 913,
    "translated_title": "DSD$^2$: 我们能够避免稀疏双下降并无忧地压缩神经网络吗？",
    "translated_abstract": "最新的研究表明，现代深度学习模型可能会出现稀疏双下降现象。确实，随着模型的稀疏性增加，测试性能首先变差，因为模型过拟合训练数据；然后，过拟合减少，导致性能改善；最后，模型开始遗忘关键信息，导致欠拟合。这种行为阻止了使用传统的提前停止准则。在这项工作中，我们有三个关键贡献。首先，我们提出了一种学习框架，避免了这种现象并提高了泛化性能。其次，我们引入了一种熵度量，提供了对这种现象出现的更多洞察，并使得可以使用传统的停止准则。第三，我们对重新初始化方法、模型宽度和深度以及数据集噪声等相关因素进行了全面的定量分析。这些贡献得到了典型设置中的经验证据支持。",
    "tldr": "DSD$^2$提出了一个学习框架，能够避免稀疏双下降现象，并提高模型的泛化性能；引入了熵度量，使得可以使用传统的停止准则；对相关因素进行了全面的定量分析。",
    "en_tdlr": "DSD$^2$ proposes a learning framework to avoid the sparse double descent phenomenon, improves generalization, introduces an entropy measure for insights, enables the use of traditional stop criteria, and provides a comprehensive quantitative analysis of contingent factors."
}