{
    "title": "Dialog act guided contextual adapter for personalized speech recognition. (arXiv:2303.17799v1 [cs.CL])",
    "abstract": "Personalization in multi-turn dialogs has been a long standing challenge for end-to-end automatic speech recognition (E2E ASR) models. Recent work on contextual adapters has tackled rare word recognition using user catalogs. This adaptation, however, does not incorporate an important cue, the dialog act, which is available in a multi-turn dialog scenario. In this work, we propose a dialog act guided contextual adapter network. Specifically, it leverages dialog acts to select the most relevant user catalogs and creates queries based on both -- the audio as well as the semantic relationship between the carrier phrase and user catalogs to better guide the contextual biasing. On industrial voice assistant datasets, our model outperforms both the baselines - dialog act encoder-only model, and the contextual adaptation, leading to the most improvement over the no-context model: 58% average relative word error rate reduction (WERR) in the multi-turn dialog scenario, in comparison to the prior",
    "link": "http://arxiv.org/abs/2303.17799",
    "context": "Title: Dialog act guided contextual adapter for personalized speech recognition. (arXiv:2303.17799v1 [cs.CL])\nAbstract: Personalization in multi-turn dialogs has been a long standing challenge for end-to-end automatic speech recognition (E2E ASR) models. Recent work on contextual adapters has tackled rare word recognition using user catalogs. This adaptation, however, does not incorporate an important cue, the dialog act, which is available in a multi-turn dialog scenario. In this work, we propose a dialog act guided contextual adapter network. Specifically, it leverages dialog acts to select the most relevant user catalogs and creates queries based on both -- the audio as well as the semantic relationship between the carrier phrase and user catalogs to better guide the contextual biasing. On industrial voice assistant datasets, our model outperforms both the baselines - dialog act encoder-only model, and the contextual adaptation, leading to the most improvement over the no-context model: 58% average relative word error rate reduction (WERR) in the multi-turn dialog scenario, in comparison to the prior",
    "path": "papers/23/03/2303.17799.json",
    "total_tokens": 909,
    "translated_title": "基于对话行为的上下文适配器用于个性化语音识别",
    "translated_abstract": "针对端到端自动语音识别（E2E ASR）模型中的多轮对话的个性化一直是一个长期的挑战。最近关于上下文适配器的研究解决了使用用户目录的罕见词汇识别。但是，这种适应性没有整合一个重要线索，即在多轮对话场景中可用的对话行为。在这项工作中，我们提出了一个基于对话行为的上下文适配器网络。具体而言，它利用对话行为来选择最相关的用户目录，并基于载体短语和用户目录之间的音频和语义关系创建查询，以更好地引导上下文偏置。在工业语音助手数据集上，我们的模型优于基线模型（仅对话行为编码器模型和上下文适应模型），并且相对于无上下文模型实现了最大的改进：在多轮对话场景中平均相对词错误率降低了58％。",
    "tldr": "本文提出了一种基于对话行为的上下文适配器网络，该网络结合用户目录和对话行为，成功地解决了多轮对话的个性化语音识别问题，相对于无上下文模型实现了58%的平均相对词错误率降低。",
    "en_tdlr": "This paper proposes a dialog act guided contextual adapter network for personalized speech recognition, which successfully solves the challenge of personalization in multi-turn dialogs and achieves an average relative word error rate reduction of 58% compared to the no-context model."
}