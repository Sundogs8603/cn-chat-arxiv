{
    "title": "Best-of-three-worlds Analysis for Linear Bandits with Follow-the-regularized-leader Algorithm. (arXiv:2303.06825v2 [cs.LG] UPDATED)",
    "abstract": "The linear bandit problem has been studied for many years in both stochastic and adversarial settings. Designing an algorithm that can optimize the environment without knowing the loss type attracts lots of interest. \\citet{LeeLWZ021} propose an algorithm that actively detects the loss type and then switches between different algorithms specially designed for specific settings. However, such an approach requires meticulous designs to perform well in all environments. Follow-the-regularized-leader (FTRL) is another type of popular algorithm that can adapt to different environments. This algorithm is of simple design and the regret bounds are shown to be optimal in traditional multi-armed bandit problems compared with the detect-switch type. Designing an FTRL-type algorithm for linear bandits is an important question that has been open for a long time. In this paper, we prove that the FTRL algorithm with a negative entropy regularizer can achieve the best-of-three-world results for the l",
    "link": "http://arxiv.org/abs/2303.06825",
    "context": "Title: Best-of-three-worlds Analysis for Linear Bandits with Follow-the-regularized-leader Algorithm. (arXiv:2303.06825v2 [cs.LG] UPDATED)\nAbstract: The linear bandit problem has been studied for many years in both stochastic and adversarial settings. Designing an algorithm that can optimize the environment without knowing the loss type attracts lots of interest. \\citet{LeeLWZ021} propose an algorithm that actively detects the loss type and then switches between different algorithms specially designed for specific settings. However, such an approach requires meticulous designs to perform well in all environments. Follow-the-regularized-leader (FTRL) is another type of popular algorithm that can adapt to different environments. This algorithm is of simple design and the regret bounds are shown to be optimal in traditional multi-armed bandit problems compared with the detect-switch type. Designing an FTRL-type algorithm for linear bandits is an important question that has been open for a long time. In this paper, we prove that the FTRL algorithm with a negative entropy regularizer can achieve the best-of-three-world results for the l",
    "path": "papers/23/03/2303.06825.json",
    "total_tokens": 864,
    "translated_title": "使用Follow-the-regularized-leader算法的线性bandits问题的三重世界分析",
    "translated_abstract": "线性bandit问题在随机和对抗环境中已经研究了很多年。设计一个可以在不知道损失类型的情况下优化环境的算法，引起了很多兴趣。本文提出了一种算法，通过主动检测损失类型，然后在针对特定环境设计的不同算法之间切换。然而，这种方法需要精心设计以在所有环境中表现良好。Follow-the-regularized-leader（FTRL）是另一种流行的算法类型，可以适应不同的环境。与检测并切换类型相比，该算法设计简单，遗憾界限在传统的多臂赌博问题中被证明是最优的。为线性bandit设计一种FTRL类型的算法是一个长期存在的重要问题。本文证明了使用负熵正则化器的FTRL算法可以实现线性bandit问题的最佳三重世界结果。",
    "tldr": "本文提出了一种基于Follow-the-regularized-leader算法的三重世界分析，并证明该算法使用负熵正则化器可以在线性bandit问题中获得最佳结果。"
}