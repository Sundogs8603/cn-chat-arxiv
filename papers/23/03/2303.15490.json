{
    "title": "Research on Efficiency Analysis of Microservices. (arXiv:2303.15490v1 [cs.SE])",
    "abstract": "With the maturity of web services, containers, and cloud computing technologies, large services in traditional systems (e.g. the computation services of machine learning and artificial intelligence) are gradually being broken down into many microservices to increase service reusability and flexibility. Therefore, this study proposes an efficiency analysis framework based on queuing models to analyze the efficiency difference of breaking down traditional large services into n microservices. For generalization, this study considers different service time distributions (e.g. exponential distribution of service time and fixed service time) and explores the system efficiency in the worst-case and best-case scenarios through queuing models (i.e. M/M/1 queuing model and M/D/1 queuing model). In each experiment, it was shown that the total time required for the original large service was higher than that required for breaking it down into multiple microservices, so breaking it down into multip",
    "link": "http://arxiv.org/abs/2303.15490",
    "context": "Title: Research on Efficiency Analysis of Microservices. (arXiv:2303.15490v1 [cs.SE])\nAbstract: With the maturity of web services, containers, and cloud computing technologies, large services in traditional systems (e.g. the computation services of machine learning and artificial intelligence) are gradually being broken down into many microservices to increase service reusability and flexibility. Therefore, this study proposes an efficiency analysis framework based on queuing models to analyze the efficiency difference of breaking down traditional large services into n microservices. For generalization, this study considers different service time distributions (e.g. exponential distribution of service time and fixed service time) and explores the system efficiency in the worst-case and best-case scenarios through queuing models (i.e. M/M/1 queuing model and M/D/1 queuing model). In each experiment, it was shown that the total time required for the original large service was higher than that required for breaking it down into multiple microservices, so breaking it down into multip",
    "path": "papers/23/03/2303.15490.json",
    "total_tokens": 840,
    "translated_title": "微服务的效率分析研究",
    "translated_abstract": "随着Web服务、容器和云计算技术的成熟，传统系统中的大型服务（例如机器学习和人工智能的计算服务）正在逐渐分解为许多微服务，以提高服务的重用性和灵活性。因此，本研究提出了一种基于排队模型的效率分析框架，以分析将传统的大型服务分解为n个微服务的效率差异。为了推广应用，该研究考虑了不同的服务时间分布（例如服务时间的指数分布和固定服务时间），并通过排队模型（即M / M / 1排队模型和M / D / 1排队模型）探索了最坏情况和最佳情况下的系统效率。在每个实验中，都显示原始大型服务所需的总时间高于将其分解为多个微服务所需的时间，因此将其分解为多个微服务可以提高系统效率。",
    "tldr": "本研究通过排队模型探讨了将传统的大型服务分解为多个微服务后提高系统效率的问题，并发现分解后所需总时间比原始服务少，因此分解可以提高效率。",
    "en_tdlr": "This study explores the efficiency improvement of breaking down traditional large services into multiple microservices through queuing models and found that the total time required after decomposition is less than that of the original service, indicating that the decomposition can improve efficiency."
}