{
    "title": "Zero-shot Entailment of Leaderboards for Empirical AI Research. (arXiv:2303.16835v1 [cs.CL])",
    "abstract": "We present a large-scale empirical investigation of the zero-shot learning phenomena in a specific recognizing textual entailment (RTE) task category, i.e. the automated mining of leaderboards for Empirical AI Research. The prior reported state-of-the-art models for leaderboards extraction formulated as an RTE task, in a non-zero-shot setting, are promising with above 90% reported performances. However, a central research question remains unexamined: did the models actually learn entailment? Thus, for the experiments in this paper, two prior reported state-of-the-art models are tested out-of-the-box for their ability to generalize or their capacity for entailment, given leaderboard labels that were unseen during training. We hypothesize that if the models learned entailment, their zero-shot performances can be expected to be moderately high as well--perhaps, concretely, better than chance. As a result of this work, a zero-shot labeled dataset is created via distant labeling formulating",
    "link": "http://arxiv.org/abs/2303.16835",
    "context": "Title: Zero-shot Entailment of Leaderboards for Empirical AI Research. (arXiv:2303.16835v1 [cs.CL])\nAbstract: We present a large-scale empirical investigation of the zero-shot learning phenomena in a specific recognizing textual entailment (RTE) task category, i.e. the automated mining of leaderboards for Empirical AI Research. The prior reported state-of-the-art models for leaderboards extraction formulated as an RTE task, in a non-zero-shot setting, are promising with above 90% reported performances. However, a central research question remains unexamined: did the models actually learn entailment? Thus, for the experiments in this paper, two prior reported state-of-the-art models are tested out-of-the-box for their ability to generalize or their capacity for entailment, given leaderboard labels that were unseen during training. We hypothesize that if the models learned entailment, their zero-shot performances can be expected to be moderately high as well--perhaps, concretely, better than chance. As a result of this work, a zero-shot labeled dataset is created via distant labeling formulating",
    "path": "papers/23/03/2303.16835.json",
    "total_tokens": 963,
    "translated_title": "零样本 Entrailment 用于 Empirical AI Research 领域排行榜",
    "translated_abstract": "本文在一个特定的文本蕴含（RTE）任务类别中进行了零样本学习现象的大规模实证研究，即自动挖掘 Empirical AI Research 领域排行榜。该领域的排行榜提取先前报告的最新技术模型，在非零样本设置下表现良好，报告了高于90%的性能。然而，一个核心的研究问题仍未被检验：这些模型真的学习了 entailment 吗？因此，在本文的实验中，测试了两个先前报告的最新技术模型，在其训练过程中没有见过的排行榜标签上，测试它们的泛化能力或 entailment 能力。我们假设，如果模型学习了 entailment，它们的零样本性能也可能是中等的，或者具体来说，好于随机猜测。本文通过远程标注创建了零样本标记数据集。",
    "tldr": "本文探讨了自动挖掘 Empirical AI Research 领域排行榜这一任务类别中的零样本学习现象。实验测试了先前报告的最新技术模型在其未见过的排行榜标签上的泛化能力或 entailment 能力。本文创建了一个零样本标记的数据集。",
    "en_tdlr": "This paper investigates the zero-shot learning phenomena in the specific task of automated mining of leaderboards for empirical AI research. The study tests the capacity of two previously reported state-of-the-art models to generalize or learn entailment, given leaderboard labels that were unseen during training. The authors hypothesize that if the models learned entailment, their zero-shot performance can be expected to be moderately high. The paper also creates a zero-shot labeled dataset via distant labeling."
}