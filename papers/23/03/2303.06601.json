{
    "title": "Multi-metrics adaptively identifies backdoors in Federated learning. (arXiv:2303.06601v2 [cs.CR] UPDATED)",
    "abstract": "The decentralized and privacy-preserving nature of federated learning (FL) makes it vulnerable to backdoor attacks aiming to manipulate the behavior of the resulting model on specific adversary-chosen inputs. However, most existing defenses based on statistical differences take effect only against specific attacks, especially when the malicious gradients are similar to benign ones or the data are highly non-independent and identically distributed (non-IID). In this paper, we revisit the distance-based defense methods and discover that i) Euclidean distance becomes meaningless in high dimensions and ii) malicious gradients with diverse characteristics cannot be identified by a single metric. To this end, we present a simple yet effective defense strategy with multi-metrics and dynamic weighting to identify backdoors adaptively. Furthermore, our novel defense has no reliance on predefined assumptions over attack settings or data distributions and little impact on benign performance. To e",
    "link": "http://arxiv.org/abs/2303.06601",
    "context": "Title: Multi-metrics adaptively identifies backdoors in Federated learning. (arXiv:2303.06601v2 [cs.CR] UPDATED)\nAbstract: The decentralized and privacy-preserving nature of federated learning (FL) makes it vulnerable to backdoor attacks aiming to manipulate the behavior of the resulting model on specific adversary-chosen inputs. However, most existing defenses based on statistical differences take effect only against specific attacks, especially when the malicious gradients are similar to benign ones or the data are highly non-independent and identically distributed (non-IID). In this paper, we revisit the distance-based defense methods and discover that i) Euclidean distance becomes meaningless in high dimensions and ii) malicious gradients with diverse characteristics cannot be identified by a single metric. To this end, we present a simple yet effective defense strategy with multi-metrics and dynamic weighting to identify backdoors adaptively. Furthermore, our novel defense has no reliance on predefined assumptions over attack settings or data distributions and little impact on benign performance. To e",
    "path": "papers/23/03/2303.06601.json",
    "total_tokens": 855,
    "translated_title": "多指标适应性地识别联邦学习中的后门攻击",
    "translated_abstract": "联邦学习的去中心化和保护隐私的特性使其容易受到后门攻击，这些攻击旨在操纵模型对特定敌对选择的输入的行为。然而，大多数基于统计差异的现有防御方法只对特定攻击起效，特别是当恶意梯度与良性梯度相似或数据高度非独立和同分布（non-IID）时。在本文中，我们重新审视了基于距离的防御方法，并发现在高维度中欧几里得距离变得无意义，并且单个指标无法识别具有多种特征的恶意梯度。为此，我们提出了一种简单而有效的防御策略，使用多指标和动态加权来适应性地识别后门攻击。此外，我们的新型防御策略不依赖于攻击设置或数据分布的预定义假设，并对良性性能几乎没有影响。",
    "tldr": "本文提出了一种简单而有效的防御策略，采用多指标和动态加权的方法，能够适应性地识别联邦学习中的后门攻击。"
}