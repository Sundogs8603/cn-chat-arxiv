{
    "title": "Model Extraction Attacks on Split Federated Learning. (arXiv:2303.08581v1 [cs.LG])",
    "abstract": "Federated Learning (FL) is a popular collaborative learning scheme involving multiple clients and a server. FL focuses on protecting clients' data but turns out to be highly vulnerable to Intellectual Property (IP) threats. Since FL periodically collects and distributes the model parameters, a free-rider can download the latest model and thus steal model IP. Split Federated Learning (SFL), a recent variant of FL that supports training with resource-constrained clients, splits the model into two, giving one part of the model to clients (client-side model), and the remaining part to the server (server-side model). Thus SFL prevents model leakage by design. Moreover, by blocking prediction queries, it can be made resistant to advanced IP threats such as traditional Model Extraction (ME) attacks. While SFL is better than FL in terms of providing IP protection, it is still vulnerable. In this paper, we expose the vulnerability of SFL and show how malicious clients can launch ME attacks by q",
    "link": "http://arxiv.org/abs/2303.08581",
    "context": "Title: Model Extraction Attacks on Split Federated Learning. (arXiv:2303.08581v1 [cs.LG])\nAbstract: Federated Learning (FL) is a popular collaborative learning scheme involving multiple clients and a server. FL focuses on protecting clients' data but turns out to be highly vulnerable to Intellectual Property (IP) threats. Since FL periodically collects and distributes the model parameters, a free-rider can download the latest model and thus steal model IP. Split Federated Learning (SFL), a recent variant of FL that supports training with resource-constrained clients, splits the model into two, giving one part of the model to clients (client-side model), and the remaining part to the server (server-side model). Thus SFL prevents model leakage by design. Moreover, by blocking prediction queries, it can be made resistant to advanced IP threats such as traditional Model Extraction (ME) attacks. While SFL is better than FL in terms of providing IP protection, it is still vulnerable. In this paper, we expose the vulnerability of SFL and show how malicious clients can launch ME attacks by q",
    "path": "papers/23/03/2303.08581.json",
    "total_tokens": 701,
    "translated_title": "基于分裂式联邦学习的模型提取攻击",
    "translated_abstract": "联邦学习（FL）是一种涉及多个客户端和服务器的流行协作学习方案。 FL侧重于保护客户的数据，但却非常容易受到知识产权（IP）威胁。 最近的一种FL变体分裂式联邦学习（SFL）分为客户端模型和服务器端模型。SFL通过设计防止模型泄漏。但是，本文揭示了SFL的漏洞，并展示了恶意客户端应如何发起模型提取攻击。",
    "tldr": "本文研究了分裂式联邦学习在模型提取攻击方面的漏洞，并提出了解决方案。",
    "en_tdlr": "This paper exposes the vulnerability of Split Federated Learning to model extraction attacks and proposes a solution."
}