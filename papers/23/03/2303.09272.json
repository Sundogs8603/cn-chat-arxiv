{
    "title": "Copyright Protection and Accountability of Generative AI:Attack, Watermarking and Attribution. (arXiv:2303.09272v1 [cs.LG])",
    "abstract": "Generative AI (e.g., Generative Adversarial Networks - GANs) has become increasingly popular in recent years. However, Generative AI introduces significant concerns regarding the protection of Intellectual Property Rights (IPR) (resp. model accountability) pertaining to images (resp. toxic images) and models (resp. poisoned models) generated. In this paper, we propose an evaluation framework to provide a comprehensive overview of the current state of the copyright protection measures for GANs, evaluate their performance across a diverse range of GAN architectures, and identify the factors that affect their performance and future research directions. Our findings indicate that the current IPR protection methods for input images, model watermarking, and attribution networks are largely satisfactory for a wide range of GANs. We highlight that further attention must be directed towards protecting training sets, as the current approaches fail to provide robust IPR protection and provenance ",
    "link": "http://arxiv.org/abs/2303.09272",
    "context": "Title: Copyright Protection and Accountability of Generative AI:Attack, Watermarking and Attribution. (arXiv:2303.09272v1 [cs.LG])\nAbstract: Generative AI (e.g., Generative Adversarial Networks - GANs) has become increasingly popular in recent years. However, Generative AI introduces significant concerns regarding the protection of Intellectual Property Rights (IPR) (resp. model accountability) pertaining to images (resp. toxic images) and models (resp. poisoned models) generated. In this paper, we propose an evaluation framework to provide a comprehensive overview of the current state of the copyright protection measures for GANs, evaluate their performance across a diverse range of GAN architectures, and identify the factors that affect their performance and future research directions. Our findings indicate that the current IPR protection methods for input images, model watermarking, and attribution networks are largely satisfactory for a wide range of GANs. We highlight that further attention must be directed towards protecting training sets, as the current approaches fail to provide robust IPR protection and provenance ",
    "path": "papers/23/03/2303.09272.json",
    "total_tokens": 953,
    "translated_title": "生成式人工智能的版权保护和责任：攻击，水印和归属",
    "translated_abstract": "生成式人工智能（例如生成对抗网络-GAN）近年来变得越来越受欢迎。然而，生成式人工智能针对生成的图像（有毒图像）和模型（有毒模型）的知识产权保护（或模型的问责）引发了重大担忧。在本文中，我们提出了一种评估框架，以全面了解当前针对各种GAN架构的版权保护措施的性能，并确定影响它们的因素和未来的研究方向。我们的发现表明，针对输入图像，模型水印和归属网络的当前知识产权保护方法在广泛的GAN范围内基本上令人满意。我们强调，必须将进一步关注点集中在保护训练集上，因为当前的方法未能提供强有力的知识产权保护和知识产权来源证明。",
    "tldr": "本文提出了一个评估框架来评估用于生成式人工智能版权保护的方法，结果显示针对输入图像，模型水印和归属网络的当前知识产权保护方法在广泛的GAN范围内基本上令人满意，但为保护训练集必须寻找更有效的方法。",
    "en_tdlr": "This paper proposes an evaluation framework to assess the copyright protection measures for Generative Adversarial Networks (GANs), and finds that the current methods for protecting input images, model watermarking, and attribution networks are largely satisfactory for a wide range of GANs. However, further attention must be directed towards protecting training sets to provide stronger Intellectual Property Rights (IPR) protection and provenance."
}