{
    "title": "Clustering based on Mixtures of Sparse Gaussian Processes. (arXiv:2303.13665v1 [cs.LG])",
    "abstract": "Creating low dimensional representations of a high dimensional data set is an important component in many machine learning applications. How to cluster data using their low dimensional embedded space is still a challenging problem in machine learning. In this article, we focus on proposing a joint formulation for both clustering and dimensionality reduction. When a probabilistic model is desired, one possible solution is to use the mixture models in which both cluster indicator and low dimensional space are learned. Our algorithm is based on a mixture of sparse Gaussian processes, which is called Sparse Gaussian Process Mixture Clustering (SGP-MIC). The main advantages to our approach over existing methods are that the probabilistic nature of this model provides more advantages over existing deterministic methods, it is straightforward to construct non-linear generalizations of the model, and applying a sparse model and an efficient variational EM approximation help to speed up the alg",
    "link": "http://arxiv.org/abs/2303.13665",
    "context": "Title: Clustering based on Mixtures of Sparse Gaussian Processes. (arXiv:2303.13665v1 [cs.LG])\nAbstract: Creating low dimensional representations of a high dimensional data set is an important component in many machine learning applications. How to cluster data using their low dimensional embedded space is still a challenging problem in machine learning. In this article, we focus on proposing a joint formulation for both clustering and dimensionality reduction. When a probabilistic model is desired, one possible solution is to use the mixture models in which both cluster indicator and low dimensional space are learned. Our algorithm is based on a mixture of sparse Gaussian processes, which is called Sparse Gaussian Process Mixture Clustering (SGP-MIC). The main advantages to our approach over existing methods are that the probabilistic nature of this model provides more advantages over existing deterministic methods, it is straightforward to construct non-linear generalizations of the model, and applying a sparse model and an efficient variational EM approximation help to speed up the alg",
    "path": "papers/23/03/2303.13665.json",
    "total_tokens": 835,
    "translated_title": "基于稀疏高斯过程混合的聚类方法",
    "translated_abstract": "在许多机器学习应用中，创建高维数据集的低维表示是一个重要的组成部分。如何使用低维嵌入空间聚类数据仍然是机器学习中的一个具有挑战性的问题。本文将重点放在提出聚类和降维的联合表述上。当需要概率模型时，一种可能的解决方案是使用混合模型，在其中可以学习到聚类指示器和低维度空间。我们的算法是基于稀疏高斯过程混合的方法，称为稀疏高斯过程混合聚类（SGP-MIC）。与现有方法相比，我们方法的主要优点在于，概率模型的性质提供了比现有的确定性方法更多的优势，构造模型的非线性推广非常直接，同时应用稀疏模型和高效变分EM逼近有助于加速算法并降低计算成本。",
    "tldr": "本文提出了一种基于稀疏高斯过程混合的聚类方法，同时实现了降维，并且相比于现有方法更具优势。",
    "en_tdlr": "The article proposes a clustering method based on mixtures of sparse Gaussian processes, which simultaneously achieves dimensionality reduction and has more advantages compared to existing methods."
}