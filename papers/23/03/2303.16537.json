{
    "title": "LMExplainer: a Knowledge-Enhanced Explainer for Language Models. (arXiv:2303.16537v1 [cs.CL])",
    "abstract": "Large language models (LMs) such as GPT-4 are very powerful and can process different kinds of natural language processing (NLP) tasks. However, it can be difficult to interpret the results due to the multi-layer nonlinear model structure and millions of parameters. Lack of understanding of how the model works can make the model unreliable and dangerous for everyday users in real-world scenarios. Most recent works exploit the weights of attention to provide explanations for model predictions. However, pure attention-based explanation is unable to support the growing complexity of the models, and cannot reason about their decision-making processes. Thus, we propose LMExplainer, a knowledge-enhanced interpretation module for language models that can provide human-understandable explanations. We use a knowledge graph (KG) and a graph attention neural network to extract the key decision signals of the LM. We further explore whether interpretation can also help AI understand the task better",
    "link": "http://arxiv.org/abs/2303.16537",
    "context": "Title: LMExplainer: a Knowledge-Enhanced Explainer for Language Models. (arXiv:2303.16537v1 [cs.CL])\nAbstract: Large language models (LMs) such as GPT-4 are very powerful and can process different kinds of natural language processing (NLP) tasks. However, it can be difficult to interpret the results due to the multi-layer nonlinear model structure and millions of parameters. Lack of understanding of how the model works can make the model unreliable and dangerous for everyday users in real-world scenarios. Most recent works exploit the weights of attention to provide explanations for model predictions. However, pure attention-based explanation is unable to support the growing complexity of the models, and cannot reason about their decision-making processes. Thus, we propose LMExplainer, a knowledge-enhanced interpretation module for language models that can provide human-understandable explanations. We use a knowledge graph (KG) and a graph attention neural network to extract the key decision signals of the LM. We further explore whether interpretation can also help AI understand the task better",
    "path": "papers/23/03/2303.16537.json",
    "total_tokens": 844,
    "translated_title": "LMExplainer：一种加强语言模型解释能力的知识提升模块",
    "translated_abstract": "巨型语言模型（如GPT-4）非常强大，可以处理各种自然语言处理（NLP）任务。然而，由于多层非线性模型结构和数百万个参数，很难解释其结果。对于用户而言，了解模型的工作方式缺乏理解，可能使模型在现实世界的应用中具有不可靠性和危险性。大多数最近的工作利用注意力权重来提供模型预测的解释。但是，基于注意力的解释无法支持不断增长的模型复杂性，并且无法推理其决策过程。因此，我们提出了LMExplainer，一种为语言模型提供人类可理解解释的知识增强模块。我们使用知识图和图注意力神经网络来提取LM的关键决策信号。同时，我们探讨解释能否也帮助人工智能更好地理解任务。",
    "tldr": "LMExplainer是一种知识增强的语言模型解释模块，使用知识图和图注意力神经网络来提取关键决策信号，为用户提供可理解的解释。",
    "en_tdlr": "LMExplainer is a knowledge-enhanced interpretation module for language models that uses a knowledge graph and graph attention neural network to extract key decision signals, providing users with understandable explanations."
}