{
    "title": "Rewarding Chatbots for Real-World Engagement with Millions of Users. (arXiv:2303.06135v1 [cs.CL])",
    "abstract": "The emergence of pretrained large language models has led to the deployment of a range of social chatbots for chitchat. Although these chatbots demonstrate language ability and fluency, they are not guaranteed to be engaging and can struggle to retain users. This work investigates the development of social chatbots that prioritize user engagement to enhance retention, specifically examining the use of human feedback to efficiently develop highly engaging chatbots. The proposed approach uses automatic pseudo-labels collected from user interactions to train a reward model that can be used to reject low-scoring sample responses generated by the chatbot model at inference time. Intuitive evaluation metrics, such as mean conversation length (MCL), are introduced as proxies to measure the level of engagement of deployed chatbots. A/B testing on groups of 10,000 new daily chatbot users on the Chai Research platform shows that this approach increases the MCL by up to 70%, which translates to a",
    "link": "http://arxiv.org/abs/2303.06135",
    "raw_ret": "{\n    \"translated_title\": \"用于百万用户真实世界互动的聊天机器人的奖励系统\",\n    \"translated_abstract\": \"预训练的大型语言模型的出现导致了一系列的社交聊天机器人的部署，用于闲聊。虽然这些聊天机器人展示了语言能力和流利度，但它们并不一定引人入胜，有时候很难吸引用户。本研究调查了开发注重用户参与度的社交聊天机器人以增强保留率，特别是考察了使用人类反馈来高效开发极具吸引力的聊天机器人。所提出的方法利用从用户交互中收集的自动伪标签来训练一个奖励模型，在推理时可以用来拒绝聊天机器人模型产生的低分样本响应。引入了直观的评估指标，如平均对话长度 (MCL)，作为衡量部署聊天机器人的参与水平的代理。在Chai Research平台上，对每日新的10,000个聊天机器人用户组进行的A/B测试表明，这种方法将MCL提高了最多70％，这相当于将保留率从40％增加到68％。\",\n    \"tldr\": \"本研究提出了一种奖励系统来训练优秀的聊天机器人，利用用户反馈数据去筛选输出来提高保留率，A/B测试表明该方法能提高68%的保留率。\"\n}<|im_sep|>",
    "total_tokens": 911,
    "ret": {
        "translated_title": "用于百万用户真实世界互动的聊天机器人的奖励系统",
        "translated_abstract": "预训练的大型语言模型的出现导致了一系列的社交聊天机器人的部署，用于闲聊。虽然这些聊天机器人展示了语言能力和流利度，但它们并不一定引人入胜，有时候很难吸引用户。本研究调查了开发注重用户参与度的社交聊天机器人以增强保留率，特别是考察了使用人类反馈来高效开发极具吸引力的聊天机器人。所提出的方法利用从用户交互中收集的自动伪标签来训练一个奖励模型，在推理时可以用来拒绝聊天机器人模型产生的低分样本响应。引入了直观的评估指标，如平均对话长度 (MCL)，作为衡量部署聊天机器人的参与水平的代理。在Chai Research平台上，对每日新的10,000个聊天机器人用户组进行的A/B测试表明，这种方法将MCL提高了最多70％，这相当于将保留率从40％增加到68％。",
        "tldr": "本研究提出了一种奖励系统来训练优秀的聊天机器人，利用用户反馈数据去筛选输出来提高保留率，A/B测试表明该方法能提高68%的保留率。"
    }
}