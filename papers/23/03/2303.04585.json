{
    "title": "Exploring Efficient-Tuned Learning Audio Representation Method from BriVL. (arXiv:2303.04585v2 [cs.SD] UPDATED)",
    "abstract": "Recently, researchers have gradually realized that in some cases, the self-supervised pre-training on large-scale Internet data is better than that of high-quality/manually labeled data sets, and multimodal/large models are better than single or bimodal/small models. In this paper, we propose a robust audio representation learning method WavBriVL based on Bridging-Vision-and-Language (BriVL). WavBriVL projects audio, image and text into a shared embedded space, so that multi-modal applications can be realized. We demonstrate the qualitative evaluation of the image generated from WavBriVL as a shared embedded space, with the main purposes of this paper:(1) Learning the correlation between audio and image;(2) Explore a new way of image generation, that is, use audio to generate pictures. Experimental results show that this method can effectively generate appropriate images from audio.",
    "link": "http://arxiv.org/abs/2303.04585",
    "context": "Title: Exploring Efficient-Tuned Learning Audio Representation Method from BriVL. (arXiv:2303.04585v2 [cs.SD] UPDATED)\nAbstract: Recently, researchers have gradually realized that in some cases, the self-supervised pre-training on large-scale Internet data is better than that of high-quality/manually labeled data sets, and multimodal/large models are better than single or bimodal/small models. In this paper, we propose a robust audio representation learning method WavBriVL based on Bridging-Vision-and-Language (BriVL). WavBriVL projects audio, image and text into a shared embedded space, so that multi-modal applications can be realized. We demonstrate the qualitative evaluation of the image generated from WavBriVL as a shared embedded space, with the main purposes of this paper:(1) Learning the correlation between audio and image;(2) Explore a new way of image generation, that is, use audio to generate pictures. Experimental results show that this method can effectively generate appropriate images from audio.",
    "path": "papers/23/03/2303.04585.json",
    "total_tokens": 858,
    "translated_title": "从BriVL中探索高效调优的学习音频表示方法",
    "translated_abstract": "最近，研究人员逐渐意识到，在某些情况下，对大规模互联网数据进行自监督预训练要好于高质量/手动标记的数据集，并且多模态/大模型要好于单一或双模态/小模型。本文提出了一种基于Bridging-Vision-and-Language（BriVL）的稳健音频表示学习方法WavBriVL。WavBriVL将音频、图像和文本投影到共享的嵌入空间中，从而实现多模态应用。我们通过对从WavBriVL生成的图像进行定性评估，来实现本文的主要目的：（1）学习音频和图像之间的相关性；（2）探索一种新的图像生成方式，即使用音频生成图像。实验结果表明，该方法可以有效地从音频中生成适当的图像。",
    "tldr": "本文提出了一种基于BriVL的稳健音频表示学习方法WavBriVL，通过将音频、图像和文本投影到共享的嵌入空间中，实现多模态应用。实验结果表明，该方法可以通过音频生成适当的图像。",
    "en_tdlr": "This paper proposes a robust audio representation learning method called WavBriVL based on BriVL, which projects audio, image, and text into a shared embedded space to enable multimodal applications. Experimental results demonstrate that this method can effectively generate appropriate images from audio."
}