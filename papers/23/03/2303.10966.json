{
    "title": "Towards Reliable Neural Machine Translation with Consistency-Aware Meta-Learning. (arXiv:2303.10966v2 [cs.CL] UPDATED)",
    "abstract": "Neural machine translation (NMT) has achieved remarkable success in producing high-quality translations. However, current NMT systems suffer from a lack of reliability, as their outputs that are often affected by lexical or syntactic changes in inputs, resulting in large variations in quality. This limitation hinders the practicality and trustworthiness of NMT. A contributing factor to this problem is that NMT models trained with the one-to-one paradigm struggle to handle the source diversity phenomenon, where inputs with the same meaning can be expressed differently. In this work, we treat this problem as a bilevel optimization problem and present a consistency-aware meta-learning (CAML) framework derived from the model-agnostic meta-learning (MAML) algorithm to address it. Specifically, the NMT model with CAML (named CoNMT) first learns a consistent meta representation of semantically equivalent sentences in the outer loop. Subsequently, a mapping from the meta representation to the ",
    "link": "http://arxiv.org/abs/2303.10966",
    "context": "Title: Towards Reliable Neural Machine Translation with Consistency-Aware Meta-Learning. (arXiv:2303.10966v2 [cs.CL] UPDATED)\nAbstract: Neural machine translation (NMT) has achieved remarkable success in producing high-quality translations. However, current NMT systems suffer from a lack of reliability, as their outputs that are often affected by lexical or syntactic changes in inputs, resulting in large variations in quality. This limitation hinders the practicality and trustworthiness of NMT. A contributing factor to this problem is that NMT models trained with the one-to-one paradigm struggle to handle the source diversity phenomenon, where inputs with the same meaning can be expressed differently. In this work, we treat this problem as a bilevel optimization problem and present a consistency-aware meta-learning (CAML) framework derived from the model-agnostic meta-learning (MAML) algorithm to address it. Specifically, the NMT model with CAML (named CoNMT) first learns a consistent meta representation of semantically equivalent sentences in the outer loop. Subsequently, a mapping from the meta representation to the ",
    "path": "papers/23/03/2303.10966.json",
    "total_tokens": 1017,
    "translated_title": "通过一致性感知元学习实现可靠的神经机器翻译",
    "translated_abstract": "神经机器翻译（NMT）在产生高质量翻译方面取得了显著成功。然而，当前的NMT系统缺乏可靠性，其输出常常受到输入中词汇或句法变化的影响，导致翻译质量存在较大的变异。这种限制阻碍了NMT的实用性和可信度。造成这个问题的一个因素是，采用一对一范式训练的NMT模型难以处理源语言多样性现象，即具有相同意义的输入可能以不同方式表达。本研究将这个问题视为一个双层优化问题，并提出了一种从模型无关元学习（MAML）算法推导出的一致性感知元学习（CAML）框架来解决它。具体而言，CAML的NMT模型（命名为CoNMT）首先在外部循环中学习一致的语义等价句子的元表示。随后，通过内部循环训练一个从元表示到翻译结果的映射，以实现更加可靠的翻译。",
    "tldr": "本论文提出了一种一致性感知元学习（CAML）框架，以解决神经机器翻译（NMT）中存在的可靠性问题。该框架通过在外部循环中学习一致的语义等价句子的元表示，并通过内部循环训练一个从元表示到翻译结果的映射，以实现更加可靠的翻译。"
}