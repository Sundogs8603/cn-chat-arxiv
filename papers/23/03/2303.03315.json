{
    "title": "MACARONS: Mapping And Coverage Anticipation with RGB Online Self-Supervision. (arXiv:2303.03315v2 [cs.CV] UPDATED)",
    "abstract": "We introduce a method that simultaneously learns to explore new large environments and to reconstruct them in 3D from color images only. This is closely related to the Next Best View problem (NBV), where one has to identify where to move the camera next to improve the coverage of an unknown scene. However, most of the current NBV methods rely on depth sensors, need 3D supervision and/or do not scale to large scenes. Our method requires only a color camera and no 3D supervision. It simultaneously learns in a self-supervised fashion to predict a \"volume occupancy field\" from color images and, from this field, to predict the NBV. Thanks to this approach, our method performs well on new scenes as it is not biased towards any training 3D data. We demonstrate this on a recent dataset made of various 3D scenes and show it performs even better than recent methods requiring a depth sensor, which is not a realistic assumption for outdoor scenes captured with a flying drone.",
    "link": "http://arxiv.org/abs/2303.03315",
    "context": "Title: MACARONS: Mapping And Coverage Anticipation with RGB Online Self-Supervision. (arXiv:2303.03315v2 [cs.CV] UPDATED)\nAbstract: We introduce a method that simultaneously learns to explore new large environments and to reconstruct them in 3D from color images only. This is closely related to the Next Best View problem (NBV), where one has to identify where to move the camera next to improve the coverage of an unknown scene. However, most of the current NBV methods rely on depth sensors, need 3D supervision and/or do not scale to large scenes. Our method requires only a color camera and no 3D supervision. It simultaneously learns in a self-supervised fashion to predict a \"volume occupancy field\" from color images and, from this field, to predict the NBV. Thanks to this approach, our method performs well on new scenes as it is not biased towards any training 3D data. We demonstrate this on a recent dataset made of various 3D scenes and show it performs even better than recent methods requiring a depth sensor, which is not a realistic assumption for outdoor scenes captured with a flying drone.",
    "path": "papers/23/03/2303.03315.json",
    "total_tokens": 942,
    "translated_title": "MACARONS：基于RGB在线自监督的映射与覆盖预测",
    "translated_abstract": "我们提出了一种方法，它能够学习探索新的大型环境，并仅通过彩色图像进行三维重建。这与下一最佳视角(NBV)问题有密切关系，其中需要确定摄像机的下一个移动方向以提高未知场景的覆盖率。然而，大多数当前的NBV方法依赖于深度传感器，需要三维监督并且不能很好地扩展到大型场景。我们的方法仅需要一个彩色相机且无需三维监督。它可以自监督地学习从彩色图像中预测“容积占用场”，并从中预测NBV。由于这种方法，我们的方法在新场景中表现良好，因为它不会对任何训练数据的3D偏差。我们在最近的数据集上进行了演示，该数据集由各种3D场景组成，并且我们表现甚至比需要深度传感器的最新方法更好，而这对于使用飞行无人机捕获的户外场景来说并不是一个现实的假设。",
    "tldr": "MACARONS是一种无需深度传感器和三维监督，仅通过彩色图像预测容积占用场并预测下一最佳视角的方法，具备在新场景中表现良好的能力。",
    "en_tdlr": "MACARONS is a method that predicts volume occupancy field and next best view solely from color images, without relying on depth sensors or 3D supervision. It shows strong performance on new scenes and outperforms recent approaches that require depth sensors."
}