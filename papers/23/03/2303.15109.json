{
    "title": "Improving the Transferability of Adversarial Examples via Direction Tuning. (arXiv:2303.15109v2 [cs.CV] UPDATED)",
    "abstract": "In the transfer-based adversarial attacks, adversarial examples are only generated by the surrogate models and achieve effective perturbation in the victim models. Although considerable efforts have been developed on improving the transferability of adversarial examples generated by transfer-based adversarial attacks, our investigation found that, the big deviation between the actual and steepest update directions of the current transfer-based adversarial attacks is caused by the large update step length, resulting in the generated adversarial examples can not converge well. However, directly reducing the update step length will lead to serious update oscillation so that the generated adversarial examples also can not achieve great transferability to the victim models. To address these issues, a novel transfer-based attack, namely direction tuning attack, is proposed to not only decrease the update deviation in the large step length, but also mitigate the update oscillation in the smal",
    "link": "http://arxiv.org/abs/2303.15109",
    "context": "Title: Improving the Transferability of Adversarial Examples via Direction Tuning. (arXiv:2303.15109v2 [cs.CV] UPDATED)\nAbstract: In the transfer-based adversarial attacks, adversarial examples are only generated by the surrogate models and achieve effective perturbation in the victim models. Although considerable efforts have been developed on improving the transferability of adversarial examples generated by transfer-based adversarial attacks, our investigation found that, the big deviation between the actual and steepest update directions of the current transfer-based adversarial attacks is caused by the large update step length, resulting in the generated adversarial examples can not converge well. However, directly reducing the update step length will lead to serious update oscillation so that the generated adversarial examples also can not achieve great transferability to the victim models. To address these issues, a novel transfer-based attack, namely direction tuning attack, is proposed to not only decrease the update deviation in the large step length, but also mitigate the update oscillation in the smal",
    "path": "papers/23/03/2303.15109.json",
    "total_tokens": 878,
    "translated_title": "通过方向调整改进对抗性样本的可迁移性",
    "translated_abstract": "在基于迁移的对抗攻击中，对抗性样本仅由替代模型生成，并在受害模型中实现有效扰动。虽然已经有相当多的工作在改进基于迁移的对抗攻击生成的对抗性样本的可迁移性，但我们的研究发现，当前基于迁移的对抗攻击的实际更新方向与最陡的更新方向之间存在巨大偏差，这是由于大的更新步长导致生成的对抗性样本无法很好地收敛。然而，直接减小更新步长会导致严重的更新振荡，从而使生成的对抗性样本也无法在受害模型中达到很好的可迁移性。为解决这些问题，提出了一种新的基于迁移的攻击方法，即方向调整攻击，旨在减小大步长中的更新偏差，并减轻小步长中的更新振荡。",
    "tldr": "该论文提出了一种新的基于迁移的攻击方法，通过方向调整来改进对抗性样本的可迁移性。该方法既能减小大步长中的更新偏差，又能减轻小步长中的更新振荡。",
    "en_tdlr": "This paper proposes a novel transfer-based attack method, direction tuning attack, to improve the transferability of adversarial examples. The method reduces the update deviation in large step lengths and mitigates the update oscillation in small step lengths."
}