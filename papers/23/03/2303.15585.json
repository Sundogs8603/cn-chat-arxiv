{
    "title": "Beyond Accuracy: A Critical Review of Fairness in Machine Learning for Mobile and Wearable Computing. (arXiv:2303.15585v1 [cs.CY])",
    "abstract": "The field of mobile, wearable, and ubiquitous computing (UbiComp) is undergoing a revolutionary integration of machine learning. Devices can now diagnose diseases, predict heart irregularities, and unlock the full potential of human cognition. However, the underlying algorithms are not immune to biases with respect to sensitive attributes (e.g., gender, race), leading to discriminatory outcomes. The research communities of HCI and AI-Ethics have recently started to explore ways of reporting information about datasets to surface and, eventually, counter those biases. The goal of this work is to explore the extent to which the UbiComp community has adopted such ways of reporting and highlight potential shortcomings. Through a systematic review of papers published in the Proceedings of the ACM Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT) journal over the past 5 years (2018-2022), we found that progress on algorithmic fairness within the UbiComp community lags behind. ",
    "link": "http://arxiv.org/abs/2303.15585",
    "context": "Title: Beyond Accuracy: A Critical Review of Fairness in Machine Learning for Mobile and Wearable Computing. (arXiv:2303.15585v1 [cs.CY])\nAbstract: The field of mobile, wearable, and ubiquitous computing (UbiComp) is undergoing a revolutionary integration of machine learning. Devices can now diagnose diseases, predict heart irregularities, and unlock the full potential of human cognition. However, the underlying algorithms are not immune to biases with respect to sensitive attributes (e.g., gender, race), leading to discriminatory outcomes. The research communities of HCI and AI-Ethics have recently started to explore ways of reporting information about datasets to surface and, eventually, counter those biases. The goal of this work is to explore the extent to which the UbiComp community has adopted such ways of reporting and highlight potential shortcomings. Through a systematic review of papers published in the Proceedings of the ACM Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT) journal over the past 5 years (2018-2022), we found that progress on algorithmic fairness within the UbiComp community lags behind. ",
    "path": "papers/23/03/2303.15585.json",
    "total_tokens": 942,
    "translated_title": "机器学习中公平性的关键回顾：超越准确性在移动和可穿戴计算中的应用",
    "translated_abstract": "移动、可穿戴和普及计算领域正在经历着机器学习的革命性整合。设备现在可以诊断疾病、预测心脏不规则动，发掘人类认知的全部潜力。然而，相关算法在敏感属性（如性别、种族等）方面可能存在偏差，导致歧视性结果。近期，人机交互（HCI）和人工智能伦理学（AI-Ethics）研究社区开始探索报告数据集的信息以揭示并最终对抗这些偏差。本文旨在探讨在这些报告方面UbiComp社区所采纳的程度，并强调潜在不足之处。通过对过去五年（2018-2022）在ACM交互、移动、可穿戴和普适技术（IMWUT）期刊上发表的论文进行系统回顾，我们发现UbiComp社区在算法公平方面的进展滞后。",
    "tldr": "本文通过对IMWUT期刊上过去五年发表的论文进行系统回顾，发现UbiComp社区在算法公平方面的进展滞后，存在敏感属性偏差导致的歧视性结果，需要探索报告数据集的信息以解决这些偏差。"
}