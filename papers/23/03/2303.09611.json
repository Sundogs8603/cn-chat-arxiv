{
    "title": "Decentralized Riemannian natural gradient methods with Kronecker-product approximations. (arXiv:2303.09611v1 [math.OC])",
    "abstract": "With a computationally efficient approximation of the second-order information, natural gradient methods have been successful in solving large-scale structured optimization problems. We study the natural gradient methods for the large-scale decentralized optimization problems on Riemannian manifolds, where the local objective function defined by the local dataset is of a log-probability type. By utilizing the structure of the Riemannian Fisher information matrix (RFIM), we present an efficient decentralized Riemannian natural gradient descent (DRNGD) method. To overcome the communication issue of the high-dimension RFIM, we consider a class of structured problems for which the RFIM can be approximated by a Kronecker product of two low-dimension matrices. By performing the communications over the Kronecker factors, a high-quality approximation of the RFIM can be obtained in a low cost. We prove that DRNGD converges to a stationary point with the best-known rate of $\\mathcal{O}(1/K)$. Nu",
    "link": "http://arxiv.org/abs/2303.09611",
    "context": "Title: Decentralized Riemannian natural gradient methods with Kronecker-product approximations. (arXiv:2303.09611v1 [math.OC])\nAbstract: With a computationally efficient approximation of the second-order information, natural gradient methods have been successful in solving large-scale structured optimization problems. We study the natural gradient methods for the large-scale decentralized optimization problems on Riemannian manifolds, where the local objective function defined by the local dataset is of a log-probability type. By utilizing the structure of the Riemannian Fisher information matrix (RFIM), we present an efficient decentralized Riemannian natural gradient descent (DRNGD) method. To overcome the communication issue of the high-dimension RFIM, we consider a class of structured problems for which the RFIM can be approximated by a Kronecker product of two low-dimension matrices. By performing the communications over the Kronecker factors, a high-quality approximation of the RFIM can be obtained in a low cost. We prove that DRNGD converges to a stationary point with the best-known rate of $\\mathcal{O}(1/K)$. Nu",
    "path": "papers/23/03/2303.09611.json",
    "total_tokens": 926,
    "translated_title": "具有Kronecker乘积逼近的分散式黎曼自然梯度方法。",
    "translated_abstract": "通过计算效率高的二阶信息逼近，自然梯度方法已成功地解决了大规模结构化优化问题。我们研究了在黎曼流形上的大规模分散式优化问题的自然梯度方法，其中由本地数据集定义的本地目标函数是对数概率类型的。通过利用黎曼费舍尔信息矩阵(RFIM)的结构，我们提出了一种高效的分散式黎曼自然梯度下降(DRNGD)方法。为了克服高维RFIM的通信问题，我们考虑一个结构化问题类，其中RFIM可以通过两个低维矩阵的Kronecker积逼近。通过在Kronecker因子上执行通信，可以以较低的成本获得RFIM的高质量逼近。我们证明DRNGD收敛速度达到$\\mathcal{O}(1/K)$的最佳已知水平。",
    "tldr": "本文提出了一种结构化问题类的分散式黎曼自然梯度下降方法，通过Kronecker乘积逼近RFIM，以较低的成本获得高质量的逼近。该方法收敛速度达到$\\mathcal{O}(1/K)$的最佳已知水平。",
    "en_tdlr": "This paper proposes a decentralized Riemannian natural gradient descent method for a class of structured problems, which approximates the RFIM with Kronecker product to obtain high-quality approximation at a low cost. The method achieves the best-known convergence rate of $\\mathcal{O}(1/K)$."
}