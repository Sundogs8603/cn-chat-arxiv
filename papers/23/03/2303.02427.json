{
    "title": "Self-tuning hyper-parameters for unsupervised cross-lingual tokenization. (arXiv:2303.02427v2 [cs.CL] UPDATED)",
    "abstract": "We explore the possibility of meta-learning for the language-independent unsupervised tokenization problem for English, Russian, and Chinese. We implement the meta-learning approach for automatic determination of hyper-parameters of the unsupervised tokenization model proposed in earlier works, relying on various human-independent fitness functions such as normalised anti-entropy, compression factor and cross-split F1 score, as well as additive and multiplicative composite combinations of the three metrics, testing them against the conventional F1 tokenization score. We find a fairly good correlation between the latter and the additive combination of the former three metrics for English and Russian. In case of Chinese, we find a significant correlation between the F 1 score and the compression factor. Our results suggest the possibility of robust unsupervised tokenization of low-resource and dead languages and allow us to think about human languages in terms of the evolution of efficie",
    "link": "http://arxiv.org/abs/2303.02427",
    "context": "Title: Self-tuning hyper-parameters for unsupervised cross-lingual tokenization. (arXiv:2303.02427v2 [cs.CL] UPDATED)\nAbstract: We explore the possibility of meta-learning for the language-independent unsupervised tokenization problem for English, Russian, and Chinese. We implement the meta-learning approach for automatic determination of hyper-parameters of the unsupervised tokenization model proposed in earlier works, relying on various human-independent fitness functions such as normalised anti-entropy, compression factor and cross-split F1 score, as well as additive and multiplicative composite combinations of the three metrics, testing them against the conventional F1 tokenization score. We find a fairly good correlation between the latter and the additive combination of the former three metrics for English and Russian. In case of Chinese, we find a significant correlation between the F 1 score and the compression factor. Our results suggest the possibility of robust unsupervised tokenization of low-resource and dead languages and allow us to think about human languages in terms of the evolution of efficie",
    "path": "papers/23/03/2303.02427.json",
    "total_tokens": 979,
    "translated_title": "自适应超参数调节在无监督跨语种分词中的应用",
    "translated_abstract": "本文探讨了在英语、俄语和中文等多种语言中进行语言无关的无监督分词问题的元学习可能性。我们使用不同的人类无关适应度函数，如标准化反熵、压缩因子和交叉分割 F1 得分，以及三个度量的加性和乘性组合，实现了对早期作品提出的无监督分词模型超参数的自动确定的元学习方法，并测试其与传统 F1 分词得分的关系。我们发现在英语和俄语方面，在前三种度量的加性组合与后者之间有相当好的相关性。在中文方面，我们发现 F1 得分与压缩因子之间存在显著的相关性。我们的结果表明了对于资源稀缺和死语言的坚实的无监督分词可能性，并让人们可以从效率演化的角度思考人类语言。",
    "tldr": "本研究探讨了在多语言中进行语言无关的无监督分词的元学习可能性，并使用多种适应度函数自动确定无监督分词模型的超参数。结果表明在英语和俄语中，前三种度量的加性组合与 F1 分词得分之间有相当好的相关性，在中文中，F1 得分与压缩因子有显著的相关性。",
    "en_tdlr": "This study explores the possibility of meta-learning for language-independent unsupervised tokenization in multiple languages, and uses various fitness functions to automatically determine the hyper-parameters of the unsupervised tokenization model. The results show a good correlation between the additive combination of the first three metrics and the F1 tokenization score in English and Russian, and a significant correlation between the F1 score and the compression factor in Chinese. This suggests the possibility of robust unsupervised tokenization for low-resource and dead languages."
}