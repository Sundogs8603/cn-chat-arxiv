{
    "title": "The impact of training dataset size and ensemble inference strategies on head and neck auto-segmentation. (arXiv:2303.17318v1 [cs.CV])",
    "abstract": "Convolutional neural networks (CNNs) are increasingly being used to automate segmentation of organs-at-risk in radiotherapy. Since large sets of highly curated data are scarce, we investigated how much data is required to train accurate and robust head and neck auto-segmentation models. For this, an established 3D CNN was trained from scratch with different sized datasets (25-1000 scans) to segment the brainstem, parotid glands and spinal cord in CTs. Additionally, we evaluated multiple ensemble techniques to improve the performance of these models. The segmentations improved with training set size up to 250 scans and the ensemble methods significantly improved performance for all organs. The impact of the ensemble methods was most notable in the smallest datasets, demonstrating their potential for use in cases where large training datasets are difficult to obtain.",
    "link": "http://arxiv.org/abs/2303.17318",
    "context": "Title: The impact of training dataset size and ensemble inference strategies on head and neck auto-segmentation. (arXiv:2303.17318v1 [cs.CV])\nAbstract: Convolutional neural networks (CNNs) are increasingly being used to automate segmentation of organs-at-risk in radiotherapy. Since large sets of highly curated data are scarce, we investigated how much data is required to train accurate and robust head and neck auto-segmentation models. For this, an established 3D CNN was trained from scratch with different sized datasets (25-1000 scans) to segment the brainstem, parotid glands and spinal cord in CTs. Additionally, we evaluated multiple ensemble techniques to improve the performance of these models. The segmentations improved with training set size up to 250 scans and the ensemble methods significantly improved performance for all organs. The impact of the ensemble methods was most notable in the smallest datasets, demonstrating their potential for use in cases where large training datasets are difficult to obtain.",
    "path": "papers/23/03/2303.17318.json",
    "total_tokens": 895,
    "translated_title": "训练数据集大小和集成推理策略对头颈部自动分割的影响",
    "translated_abstract": "卷积神经网络(CNNs)越来越被用于放疗中自动分割危机器官。由于高质量的大数据集很少，因此我们研究了多少数据是训练精准和健壮的头颈部自动分割模型所需的。为此，我们使用不同大小的数据集(25-1000个扫描)来训练一个简单的3D CNN模型，以分割CT中的脑干、腮腺和脊髓。此外，我们评估了多种集成技术来改善这些模型的性能。随着训练集大小达到250个扫描，分割效果得到了改善，而集成方法显著提高了所有器官的性能。集成方法对最小的数据集的影响最为明显，这表明它们在难以获得大型训练数据集的情况下的潜力。",
    "tldr": "本文研究了头颈部自动分割模型所需的训练数据集大小和集成方法对其性能的影响，发现250个扫描是训练最准确和最健壮的模型所需的最小数据量，并且集成方法可以在小数据集上发挥作用。",
    "en_tdlr": "This paper investigates the impact of training dataset size and ensemble strategies on the performance of head and neck auto-segmentation models, finding that 250 scans are the minimum requirement for accurate and robust models and ensemble methods can improve performance especially on small datasets."
}