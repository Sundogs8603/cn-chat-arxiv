{
    "title": "Optimal foraging strategies can be learned and outperform L\\'evy walks. (arXiv:2303.06050v1 [cond-mat.stat-mech])",
    "abstract": "L\\'evy walks and other theoretical models of optimal foraging have been successfully used to describe real-world scenarios, attracting attention in several fields such as economy, physics, ecology, and evolutionary biology. However, it remains unclear in most cases which strategies maximize foraging efficiency and whether such strategies can be learned by living organisms. To address these questions, we model foragers as reinforcement learning agents. We first prove theoretically that maximizing rewards in our reinforcement learning model is equivalent to optimizing foraging efficiency. We then show with numerical experiments that our agents learn foraging strategies which outperform the efficiency of known strategies such as L\\'evy walks.",
    "link": "http://arxiv.org/abs/2303.06050",
    "raw_ret": "{\n    \"translated_title\": \"最优觅食策略可以被学习并超过利维步行。\",\n    \"translated_abstract\": \"利维步行和其他理论模型已经成功地用于描述现实情况，在经济学、物理学、生态学和进化生物学等多个领域引起了关注。然而，在大多数情况下，最大化觅食效率的策略以及这些策略是否可以被生物学习还不清楚。为了解决这些问题，我们将觅食者建模为强化学习代理。我们首先从理论上证明，我们的强化学习模型中最大化奖励等价于优化觅食效率。然后，我们通过数字实验展示了我们的代理学习了优于已知策略（如利维步行）效率的觅食策略。\",\n    \"tldr\": \"本文证明最优觅食策略可以被生物学习，实验表明学习到的策略优于已知策略如利维步行。\"\n}",
    "total_tokens": 712,
    "ret": {
        "translated_title": "最优觅食策略可以被学习并超过利维步行。",
        "translated_abstract": "利维步行和其他理论模型已经成功地用于描述现实情况，在经济学、物理学、生态学和进化生物学等多个领域引起了关注。然而，在大多数情况下，最大化觅食效率的策略以及这些策略是否可以被生物学习还不清楚。为了解决这些问题，我们将觅食者建模为强化学习代理。我们首先从理论上证明，我们的强化学习模型中最大化奖励等价于优化觅食效率。然后，我们通过数字实验展示了我们的代理学习了优于已知策略（如利维步行）效率的觅食策略。",
        "tldr": "本文证明最优觅食策略可以被生物学习，实验表明学习到的策略优于已知策略如利维步行。"
    }
}