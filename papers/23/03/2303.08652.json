{
    "title": "Automated Query Generation for Evidence Collection from Web Search Engines. (arXiv:2303.08652v1 [cs.CL])",
    "abstract": "It is widely accepted that so-called facts can be checked by searching for information on the Internet. This process requires a fact-checker to formulate a search query based on the fact and to present it to a search engine. Then, relevant and believable passages need to be identified in the search results before a decision is made. This process is carried out by sub-editors at many news and media organisations on a daily basis. Here, we ask the question as to whether it is possible to automate the first step, that of query generation. Can we automatically formulate search queries based on factual statements which are similar to those formulated by human experts? Here, we consider similarity both in terms of textual similarity and with respect to relevant documents being returned by a search engine. First, we introduce a moderate-sized evidence collection dataset which includes 390 factual statements together with associated human-generated search queries and search results. Then, we i",
    "link": "http://arxiv.org/abs/2303.08652",
    "context": "Title: Automated Query Generation for Evidence Collection from Web Search Engines. (arXiv:2303.08652v1 [cs.CL])\nAbstract: It is widely accepted that so-called facts can be checked by searching for information on the Internet. This process requires a fact-checker to formulate a search query based on the fact and to present it to a search engine. Then, relevant and believable passages need to be identified in the search results before a decision is made. This process is carried out by sub-editors at many news and media organisations on a daily basis. Here, we ask the question as to whether it is possible to automate the first step, that of query generation. Can we automatically formulate search queries based on factual statements which are similar to those formulated by human experts? Here, we consider similarity both in terms of textual similarity and with respect to relevant documents being returned by a search engine. First, we introduce a moderate-sized evidence collection dataset which includes 390 factual statements together with associated human-generated search queries and search results. Then, we i",
    "path": "papers/23/03/2303.08652.json",
    "total_tokens": 813,
    "translated_title": "自动查询生成用于从网络搜索引擎中收集证据。",
    "translated_abstract": "人们普遍认为，可以通过在互联网上搜索信息来验证所谓的事实。这个过程需要事实核查员根据事实制定搜索查询并向搜索引擎提交，然后需要在搜索结果中识别相关和可信的段落，然后才能做出决策。在许多新闻和媒体组织中，这个过程由副编辑每天完成。在这里，我们问一个问题，那就是是否可能自动化第一步，即查询生成。我们是否能够根据类似于人类专家制定的事实陈述自动生成搜索查询？我们考虑相似性，无论是从文本相似性的角度还是从搜索引擎返回相关文档的角度。首先，我们介绍一个中等规模的证据收集数据集，其中包括390个事实陈述以及相关的人工生成的搜索查询和搜索结果。",
    "tldr": "本研究考虑了自动查询生成，即根据事实陈述自动生成搜索查询。研究引入了一个包含390个事实陈述和相关搜索查询和结果的中等规模证据收集数据集。",
    "en_tdlr": "This study considers automated query generation for factual statements and introduces a moderate-sized evidence collection dataset including 390 factual statements and associated search queries and results."
}