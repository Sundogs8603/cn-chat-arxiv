{
    "title": "Semantic Image Attack for Visual Model Diagnosis. (arXiv:2303.13010v1 [cs.CV])",
    "abstract": "In practice, metric analysis on a specific train and test dataset does not guarantee reliable or fair ML models. This is partially due to the fact that obtaining a balanced, diverse, and perfectly labeled dataset is typically expensive, time-consuming, and error-prone. Rather than relying on a carefully designed test set to assess ML models' failures, fairness, or robustness, this paper proposes Semantic Image Attack (SIA), a method based on the adversarial attack that provides semantic adversarial images to allow model diagnosis, interpretability, and robustness. Traditional adversarial training is a popular methodology for robustifying ML models against attacks. However, existing adversarial methods do not combine the two aspects that enable the interpretation and analysis of the model's flaws: semantic traceability and perceptual quality. SIA combines the two features via iterative gradient ascent on a predefined semantic attribute space and the image space. We illustrate the validi",
    "link": "http://arxiv.org/abs/2303.13010",
    "context": "Title: Semantic Image Attack for Visual Model Diagnosis. (arXiv:2303.13010v1 [cs.CV])\nAbstract: In practice, metric analysis on a specific train and test dataset does not guarantee reliable or fair ML models. This is partially due to the fact that obtaining a balanced, diverse, and perfectly labeled dataset is typically expensive, time-consuming, and error-prone. Rather than relying on a carefully designed test set to assess ML models' failures, fairness, or robustness, this paper proposes Semantic Image Attack (SIA), a method based on the adversarial attack that provides semantic adversarial images to allow model diagnosis, interpretability, and robustness. Traditional adversarial training is a popular methodology for robustifying ML models against attacks. However, existing adversarial methods do not combine the two aspects that enable the interpretation and analysis of the model's flaws: semantic traceability and perceptual quality. SIA combines the two features via iterative gradient ascent on a predefined semantic attribute space and the image space. We illustrate the validi",
    "path": "papers/23/03/2303.13010.json",
    "total_tokens": 860,
    "translated_title": "用于视觉模型诊断的语义图像攻击",
    "translated_abstract": "在实践中，对特定训练和测试数据集进行度量分析不能保证可靠或公平的机器学习模型。这部分原因是，获得平衡、多样和标记完美的数据集通常是昂贵、耗时和易出错的。本文提出了一种基于对抗攻击的方法——语义图像攻击（SIA），它提供了语义对抗图像，以便进行模型诊断、可解释性和鲁棒性。传统的对抗训练是一种增强机器学习模型对抗攻击的流行方法。然而，现有的对抗方法不结合两个方面，无法解释和分析模型的缺陷：语义可追溯性和感觉质量。SIA通过预定义的语义属性空间和图像空间上的迭代梯度上升结合了两个特征。我们证明了SIA的有效性。",
    "tldr": "本文提出了一种新的基于对抗攻击的方法——语义图像攻击（SIA），可以提供语义对抗图像以便进行模型诊断、可解释性和鲁棒性。",
    "en_tdlr": "This paper proposes a new method based on adversarial attacks, Semantic Image Attack (SIA), which provides semantic adversarial images for model diagnosis, interpretability, and robustness. SIA combines semantic traceability and perceptual quality via iterative gradient ascent on a predefined semantic attribute space and the image space."
}