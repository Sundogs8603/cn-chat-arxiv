{
    "title": "Remind of the Past: Incremental Learning with Analogical Prompts. (arXiv:2303.13898v1 [cs.CV])",
    "abstract": "Although data-free incremental learning methods are memory-friendly, accurately estimating and counteracting representation shifts is challenging in the absence of historical data. This paper addresses this thorny problem by proposing a novel incremental learning method inspired by human analogy capabilities. Specifically, we design an analogy-making mechanism to remap the new data into the old class by prompt tuning. It mimics the feature distribution of the target old class on the old model using only samples of new classes. The learnt prompts are further used to estimate and counteract the representation shift caused by fine-tuning for the historical prototypes. The proposed method sets up new state-of-the-art performance on four incremental learning benchmarks under both the class and domain incremental learning settings. It consistently outperforms data-replay methods by only saving feature prototypes for each class. It has almost hit the empirical upper bound by joint training on",
    "link": "http://arxiv.org/abs/2303.13898",
    "context": "Title: Remind of the Past: Incremental Learning with Analogical Prompts. (arXiv:2303.13898v1 [cs.CV])\nAbstract: Although data-free incremental learning methods are memory-friendly, accurately estimating and counteracting representation shifts is challenging in the absence of historical data. This paper addresses this thorny problem by proposing a novel incremental learning method inspired by human analogy capabilities. Specifically, we design an analogy-making mechanism to remap the new data into the old class by prompt tuning. It mimics the feature distribution of the target old class on the old model using only samples of new classes. The learnt prompts are further used to estimate and counteract the representation shift caused by fine-tuning for the historical prototypes. The proposed method sets up new state-of-the-art performance on four incremental learning benchmarks under both the class and domain incremental learning settings. It consistently outperforms data-replay methods by only saving feature prototypes for each class. It has almost hit the empirical upper bound by joint training on",
    "path": "papers/23/03/2303.13898.json",
    "total_tokens": 880,
    "translated_title": "过去的提醒: 带类比提示的增量学习",
    "translated_abstract": "虽然无数据增量学习方法对存储友好，但在缺乏历史数据的情况下准确估计和对抗表示偏移是具有挑战性的。本文通过提出一种新颖的增量学习方法来解决这个棘手的问题，该方法受到人类类比能力的启发。具体来说，我们设计了一种类比制作机制，通过提示调整将新数据重新映射到旧类。它仅使用新类的样本模拟了旧模型上目标旧类的特征分布。所学习的提示进一步用于估计和对抗由于对历史样本进行微调而导致的表示偏移。所提出的方法在课程和领域增量学习设置下在四个增量学习基准测试中取得了新的最佳性能。它通过仅保存每个类别的特征原型不断优于数据重放方法。通过联合训练，它已经几乎达到了实证的上限。",
    "tldr": "本文提出了一种新颖的增量学习方法，通过类比制作机制将新数据重新映射到旧类，并利用所学提示估计和对抗表示偏移，极大提高了增量学习性能。",
    "en_tdlr": "This paper proposes a novel incremental learning method that uses an analogy-making mechanism to remap new data into old classes and uses learned prompts to estimate and counteract representation shifts caused by fine-tuning for historical prototypes, achieving state-of-the-art performance in incremental learning benchmarks."
}