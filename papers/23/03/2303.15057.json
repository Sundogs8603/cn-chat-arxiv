{
    "title": "Meta-Calibration Regularized Neural Networks. (arXiv:2303.15057v2 [cs.LG] UPDATED)",
    "abstract": "Miscalibration-the mismatch between predicted probability and the true correctness likelihood-has been frequently identified in modern deep neural networks. Recent work in the field aims to address this problem by training calibrated models directly by optimizing a proxy of the calibration error alongside the conventional objective. Recently, Meta-Calibration (MC) showed the effectiveness of using meta-learning for learning better calibrated models. In this work, we extend MC with two main components: (1) gamma network (gamma-net), a meta network to learn a sample-wise gamma at a continuous space for focal loss for optimizing backbone network; (2) smooth expected calibration error (SECE), a Gaussian-kernel based unbiased and differentiable ECE which aims to smoothly optimizing gamma-net. The proposed method regularizes neural network towards better calibration meanwhile retain predictive performance. Our experiments show that (a) learning sample-wise gamma at continuous space can effec",
    "link": "http://arxiv.org/abs/2303.15057",
    "context": "Title: Meta-Calibration Regularized Neural Networks. (arXiv:2303.15057v2 [cs.LG] UPDATED)\nAbstract: Miscalibration-the mismatch between predicted probability and the true correctness likelihood-has been frequently identified in modern deep neural networks. Recent work in the field aims to address this problem by training calibrated models directly by optimizing a proxy of the calibration error alongside the conventional objective. Recently, Meta-Calibration (MC) showed the effectiveness of using meta-learning for learning better calibrated models. In this work, we extend MC with two main components: (1) gamma network (gamma-net), a meta network to learn a sample-wise gamma at a continuous space for focal loss for optimizing backbone network; (2) smooth expected calibration error (SECE), a Gaussian-kernel based unbiased and differentiable ECE which aims to smoothly optimizing gamma-net. The proposed method regularizes neural network towards better calibration meanwhile retain predictive performance. Our experiments show that (a) learning sample-wise gamma at continuous space can effec",
    "path": "papers/23/03/2303.15057.json",
    "total_tokens": 905,
    "translated_title": "Meta-Calibration Regularized Neural Networks. (arXiv:2303.15057v2 [cs.LG] UPDATED)",
    "translated_abstract": "最近的研究发现，现代深度神经网络经常存在误校准问题，即预测概率与真实正确性之间的不匹配。该领域的最新工作旨在通过直接训练校准模型来解决此问题，同时优化校准误差的代理目标。最近的元校准（MC）表明，使用元学习来学习更好的校准模型是有效的。在这项工作中，我们通过两个主要组成部分扩展了MC：（1）gamma网络（gamma-net），一个元网络，用于在连续空间为调优骨干网络的focal loss学习逐样本gamma；（2）平滑的预期校准误差（SECE），一种基于高斯核的无偏和可微的ECE，旨在平滑调优gamma-net。所提出的方法在保持预测性能的同时，使神经网络更好地校准。我们的实验表明，（a）在连续空间学习逐样本gamma可以有效地优化骨干网络。",
    "tldr": "本研究扩展了元校准的方法，引入了gamma网络和平滑的预期校准误差，实现了更好的神经网络校准。该方法在保持预测性能的同时解决了深度神经网络中的误校准问题。"
}