{
    "title": "Topics in the Haystack: Extracting and Evaluating Topics beyond Coherence. (arXiv:2303.17324v1 [cs.CL])",
    "abstract": "Extracting and identifying latent topics in large text corpora has gained increasing importance in Natural Language Processing (NLP). Most models, whether probabilistic models similar to Latent Dirichlet Allocation (LDA) or neural topic models, follow the same underlying approach of topic interpretability and topic extraction. We propose a method that incorporates a deeper understanding of both sentence and document themes, and goes beyond simply analyzing word frequencies in the data. This allows our model to detect latent topics that may include uncommon words or neologisms, as well as words not present in the documents themselves. Additionally, we propose several new evaluation metrics based on intruder words and similarity measures in the semantic space. We present correlation coefficients with human identification of intruder words and achieve near-human level results at the word-intrusion task. We demonstrate the competitive performance of our method with a large benchmark study,",
    "link": "http://arxiv.org/abs/2303.17324",
    "context": "Title: Topics in the Haystack: Extracting and Evaluating Topics beyond Coherence. (arXiv:2303.17324v1 [cs.CL])\nAbstract: Extracting and identifying latent topics in large text corpora has gained increasing importance in Natural Language Processing (NLP). Most models, whether probabilistic models similar to Latent Dirichlet Allocation (LDA) or neural topic models, follow the same underlying approach of topic interpretability and topic extraction. We propose a method that incorporates a deeper understanding of both sentence and document themes, and goes beyond simply analyzing word frequencies in the data. This allows our model to detect latent topics that may include uncommon words or neologisms, as well as words not present in the documents themselves. Additionally, we propose several new evaluation metrics based on intruder words and similarity measures in the semantic space. We present correlation coefficients with human identification of intruder words and achieve near-human level results at the word-intrusion task. We demonstrate the competitive performance of our method with a large benchmark study,",
    "path": "papers/23/03/2303.17324.json",
    "total_tokens": 906,
    "translated_title": "《堆栈中的话题：超越连贯性的主题提取和评估》",
    "translated_abstract": "在自然语言处理领域中，从大型文本语料库中提取和识别潜在主题变得越来越重要。大多数模型，无论是类似于潜在狄利克雷分配（LDA）的概率模型，还是神经主题模型，都遵循主题可解释性和主题提取的相同基本方法。我们提出了一种方法，结合了对句子和文档主题的深刻理解，并超越了对数据中单词频率的简单分析。这使得我们的模型能够检测到包含不常见单词或新词的潜在主题，以及不在文档本身中出现的单词。此外，我们提出了几个基于干扰词和语义空间中相似度测量的新的评估指标。我们提出了与人类干扰词识别的相关系数，并在单词干扰任务上获得了接近于人类水平的结果。我们通过一项大型基准研究展示了我们方法的竞争性能。",
    "tldr": "这项研究提出了一种新的主题提取方法，可以检测包含不常见词汇的潜在主题，并提出了新的评估指标，在干扰词识别任务上获得接近于人类水平的结果。",
    "en_tdlr": "This study proposes a new method for topic extraction that can detect potential topics with uncommon words, and introduces new evaluation metrics that achieve near-human level results in intruder word identification task."
}