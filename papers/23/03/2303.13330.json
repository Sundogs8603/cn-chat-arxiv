{
    "title": "Logistic Regression Equivalence: A Framework for Comparing Logistic Regression Models Across Populations. (arXiv:2303.13330v1 [stat.ME])",
    "abstract": "In this paper we discuss how to evaluate the differences between fitted logistic regression models across sub-populations. Our motivating example is in studying computerized diagnosis for learning disabilities, where sub-populations based on gender may or may not require separate models. In this context, significance tests for hypotheses of no difference between populations may provide perverse incentives, as larger variances and smaller samples increase the probability of not-rejecting the null. We argue that equivalence testing for a prespecified tolerance level on population differences incentivizes accuracy in the inference. We develop a cascading set of equivalence tests, in which each test addresses a different aspect of the model: the way the phenomenon is coded in the regression coefficients, the individual predictions in the per example log odds ratio and the overall accuracy in the mean square prediction error. For each equivalence test, we propose a strategy for setting the ",
    "link": "http://arxiv.org/abs/2303.13330",
    "context": "Title: Logistic Regression Equivalence: A Framework for Comparing Logistic Regression Models Across Populations. (arXiv:2303.13330v1 [stat.ME])\nAbstract: In this paper we discuss how to evaluate the differences between fitted logistic regression models across sub-populations. Our motivating example is in studying computerized diagnosis for learning disabilities, where sub-populations based on gender may or may not require separate models. In this context, significance tests for hypotheses of no difference between populations may provide perverse incentives, as larger variances and smaller samples increase the probability of not-rejecting the null. We argue that equivalence testing for a prespecified tolerance level on population differences incentivizes accuracy in the inference. We develop a cascading set of equivalence tests, in which each test addresses a different aspect of the model: the way the phenomenon is coded in the regression coefficients, the individual predictions in the per example log odds ratio and the overall accuracy in the mean square prediction error. For each equivalence test, we propose a strategy for setting the ",
    "path": "papers/23/03/2303.13330.json",
    "total_tokens": 889,
    "translated_title": "逻辑回归等价性:一种比较不同族群下逻辑回归模型的框架",
    "translated_abstract": "本文讨论如何评估不同亚群中拟合逻辑回归模型之间的差异。我们以研究学习障碍的计算机诊断为例，其中以性别为基础的亚群可能需要分别建立模型。在这种情况下，对于零差异假设的显著性检验可能会产生逆向激励，因为较大的方差和较小的样本会增加不拒绝零假设的概率。我们认为，在预先设定的容差水平上进行等价性测试可激励推断的准确性。我们设计了一组级联的等价性测试，每个测试都涉及模型的不同方面：现象在回归系数中的编码方式、每个样本中的单独预测和平均平方预测误差中的总体准确性。针对每个等价性测试，我们提出了一种设置最小效应量阈值的策略。",
    "tldr": "本论文提出了一种逻辑回归模型比较的方法，旨在评估不同亚群中拟合模型之间的差异，通过等价性测试来激励推断的准确性。",
    "en_tdlr": "This paper proposes a method for comparing logistic regression models in order to evaluate the differences between them across sub-populations. It incentivizes the accuracy of the inference through equivalence testing and proposes a cascading set of equivalence tests for different aspects of the model."
}