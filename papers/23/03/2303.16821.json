{
    "title": "Decision Making for Autonomous Driving in Interactive Merge Scenarios via Learning-based Prediction. (arXiv:2303.16821v1 [cs.RO])",
    "abstract": "Autonomous agents that drive on roads shared with human drivers must reason about the nuanced interactions among traffic participants. This poses a highly challenging decision making problem since human behavior is influenced by a multitude of factors (e.g., human intentions and emotions) that are hard to model. This paper presents a decision making approach for autonomous driving, focusing on the complex task of merging into moving traffic where uncertainty emanates from the behavior of other drivers and imperfect sensor measurements. We frame the problem as a partially observable Markov decision process (POMDP) and solve it online with Monte Carlo tree search. The solution to the POMDP is a policy that performs high-level driving maneuvers, such as giving way to an approaching car, keeping a safe distance from the vehicle in front or merging into traffic. Our method leverages a model learned from data to predict the future states of traffic while explicitly accounting for interaction",
    "link": "http://arxiv.org/abs/2303.16821",
    "context": "Title: Decision Making for Autonomous Driving in Interactive Merge Scenarios via Learning-based Prediction. (arXiv:2303.16821v1 [cs.RO])\nAbstract: Autonomous agents that drive on roads shared with human drivers must reason about the nuanced interactions among traffic participants. This poses a highly challenging decision making problem since human behavior is influenced by a multitude of factors (e.g., human intentions and emotions) that are hard to model. This paper presents a decision making approach for autonomous driving, focusing on the complex task of merging into moving traffic where uncertainty emanates from the behavior of other drivers and imperfect sensor measurements. We frame the problem as a partially observable Markov decision process (POMDP) and solve it online with Monte Carlo tree search. The solution to the POMDP is a policy that performs high-level driving maneuvers, such as giving way to an approaching car, keeping a safe distance from the vehicle in front or merging into traffic. Our method leverages a model learned from data to predict the future states of traffic while explicitly accounting for interaction",
    "path": "papers/23/03/2303.16821.json",
    "total_tokens": 972,
    "translated_title": "基于学习的预测的交互合流情况下自动驾驶决策制定",
    "translated_abstract": "在与人类驾驶员共享道路的自动代理方面，必须考虑交通参与者之间微妙的互动。这是一个非常具有挑战性的决策问题，因为人类行为受到难以建模的多种因素（例如人类意图和情绪）的影响。本文提出了一种自动驾驶的决策方法，重点关注复杂的合流交通任务，其中不确定性来自其他驾驶员的行为和不完美的传感器测量。我们将问题框架化为部分可观察的马尔可夫决策过程（POMDP），并使用蒙特卡罗树搜索在线求解。 POMDP的解决方案是执行高级驾驶操作的策略，例如让道给逼近的车辆，与前面的车辆保持安全距离或合并到交通中。我们的方法利用从数据中学习的模型来预测未来的交通状态，同时明确考虑交互作用。",
    "tldr": "本研究提出了在自动驾驶车辆与其他车辆交互合流的情况下，基于学习的预测的决策制定方法来解决高度挑战的决策问题和不确定性，并采用部分可观察的马尔可夫决策过程（POMDP）和蒙特卡罗树搜索算法来执行高级驾驶操作。",
    "en_tdlr": "This paper proposes a decision-making approach for autonomous driving in interactive merge scenarios via learning-based prediction, with the implementation of POMDP and Monte Carlo tree search, to address the challenging decision problems and uncertainties in merging into traffic, while leveraging a model learned from data to predict the future states of traffic and accounting for interaction."
}