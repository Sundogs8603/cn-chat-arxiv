{
    "title": "Hierarchical-Hyperplane Kernels for Actively Learning Gaussian Process Models of Nonstationary Systems. (arXiv:2303.10022v1 [cs.LG])",
    "abstract": "Learning precise surrogate models of complex computer simulations and physical machines often require long-lasting or expensive experiments. Furthermore, the modeled physical dependencies exhibit nonlinear and nonstationary behavior. Machine learning methods that are used to produce the surrogate model should therefore address these problems by providing a scheme to keep the number of queries small, e.g. by using active learning and be able to capture the nonlinear and nonstationary properties of the system. One way of modeling the nonstationarity is to induce input-partitioning, a principle that has proven to be advantageous in active learning for Gaussian processes. However, these methods either assume a known partitioning, need to introduce complex sampling schemes or rely on very simple geometries. In this work, we present a simple, yet powerful kernel family that incorporates a partitioning that: i) is learnable via gradient-based methods, ii) uses a geometry that is more flexible",
    "link": "http://arxiv.org/abs/2303.10022",
    "context": "Title: Hierarchical-Hyperplane Kernels for Actively Learning Gaussian Process Models of Nonstationary Systems. (arXiv:2303.10022v1 [cs.LG])\nAbstract: Learning precise surrogate models of complex computer simulations and physical machines often require long-lasting or expensive experiments. Furthermore, the modeled physical dependencies exhibit nonlinear and nonstationary behavior. Machine learning methods that are used to produce the surrogate model should therefore address these problems by providing a scheme to keep the number of queries small, e.g. by using active learning and be able to capture the nonlinear and nonstationary properties of the system. One way of modeling the nonstationarity is to induce input-partitioning, a principle that has proven to be advantageous in active learning for Gaussian processes. However, these methods either assume a known partitioning, need to introduce complex sampling schemes or rely on very simple geometries. In this work, we present a simple, yet powerful kernel family that incorporates a partitioning that: i) is learnable via gradient-based methods, ii) uses a geometry that is more flexible",
    "path": "papers/23/03/2303.10022.json",
    "total_tokens": 864,
    "translated_title": "层次-超平面核在高斯过程模型积极学习中的应用",
    "translated_abstract": "学习复杂计算机模拟和物理机器的精确代理模型通常需要长时间或昂贵的实验。此外，建模的物理依赖关系表现出非线性和非平稳性。因此，用于产生代理模型的机器学习方法应通过提供保持查询数量少的方案（例如使用积极学习），并能够捕获系统的非线性和非平稳特性来解决这些问题。一种建模非平稳性的方法是引入输入分区，这种方法在高斯过程的积极学习中被证明是有优势的。但是，这些方法要么假定已知分区，需要引入复杂的抽样方案，要么依赖于非常简单的几何形状。在本文中，我们提出了一种简单但强大的核函数族，它包括一个可通过基于梯度的方法进行学习的分区，并使用更灵活的几何形状。",
    "tldr": "本文提出了一种层次-超平面核函数族，能够在高斯过程模型积极学习中使用，以建模非平稳性和非线性特性。",
    "en_tdlr": "This paper proposes a hierarchical-hyperplane kernel family that can be used in active learning for Gaussian processes to model nonstationary and nonlinear behaviors, with a learnable input-partitioning and more flexible geometry."
}