{
    "title": "On pitfalls (and advantages) of sophisticated large language models. (arXiv:2303.17511v1 [cs.CY])",
    "abstract": "Natural language processing based on large language models (LLMs) is a booming field of AI research. After neural networks have proven to outperform humans in games and practical domains based on pattern recognition, we might stand now at a road junction where artificial entities might eventually enter the realm of human communication. However, this comes with serious risks. Due to the inherent limitations regarding the reliability of neural networks, overreliance on LLMs can have disruptive consequences. Since it will be increasingly difficult to distinguish between human-written and machine-generated text, one is confronted with new ethical challenges. This begins with the no longer undoubtedly verifiable human authorship and continues with various types of fraud, such as a new form of plagiarism. This also concerns the violation of privacy rights, the possibility of circulating counterfeits of humans, and, last but not least, it makes a massive spread of misinformation possible.",
    "link": "http://arxiv.org/abs/2303.17511",
    "context": "Title: On pitfalls (and advantages) of sophisticated large language models. (arXiv:2303.17511v1 [cs.CY])\nAbstract: Natural language processing based on large language models (LLMs) is a booming field of AI research. After neural networks have proven to outperform humans in games and practical domains based on pattern recognition, we might stand now at a road junction where artificial entities might eventually enter the realm of human communication. However, this comes with serious risks. Due to the inherent limitations regarding the reliability of neural networks, overreliance on LLMs can have disruptive consequences. Since it will be increasingly difficult to distinguish between human-written and machine-generated text, one is confronted with new ethical challenges. This begins with the no longer undoubtedly verifiable human authorship and continues with various types of fraud, such as a new form of plagiarism. This also concerns the violation of privacy rights, the possibility of circulating counterfeits of humans, and, last but not least, it makes a massive spread of misinformation possible.",
    "path": "papers/23/03/2303.17511.json",
    "total_tokens": 895,
    "translated_title": "关于复杂大型语言模型的优劣（坑）。",
    "translated_abstract": "基于大型语言模型（LLMs）的自然语言处理是人工智能研究的一个蓬勃发展的领域。在神经网络已经在基于模式识别的游戏和实际领域中证明超越人类表现后，我们现在可能处于一个人工实体最终进入人类交流领域的十字路口。然而，这也带来了严重的风险。由于神经网络可靠性固有的限制，过度依赖LLMs可能带来破坏性后果。由于区分人类书写和机器生成的文本将变得越来越困难，人们面临着新的伦理挑战。从不再明确可验证的人类作者身份开始，继续涉及各种类型的欺诈，例如新形式的剽窃。这还涉及侵犯隐私权，可能传播人类伪造品，最后但同样重要的是，它使大规模传播错误信息成为可能。",
    "tldr": "大型语言模型能够超越人类表现，但过度依赖可能会导致严重后果，包括难以区分的机器生成文本和各种形式的欺诈，进而产生新的伦理挑战。",
    "en_tdlr": "Large language models have the potential to surpass human performance, but overreliance on them can lead to serious consequences, including machine-generated text that is difficult to distinguish from human-written text and various forms of fraud, which have resulted in new ethical challenges."
}