{
    "title": "Communication-Efficient Vertical Federated Learning with Limited Overlapping Samples. (arXiv:2303.16270v1 [cs.LG])",
    "abstract": "Federated learning is a popular collaborative learning approach that enables clients to train a global model without sharing their local data. Vertical federated learning (VFL) deals with scenarios in which the data on clients have different feature spaces but share some overlapping samples. Existing VFL approaches suffer from high communication costs and cannot deal efficiently with limited overlapping samples commonly seen in the real world. We propose a practical vertical federated learning (VFL) framework called \\textbf{one-shot VFL} that can solve the communication bottleneck and the problem of limited overlapping samples simultaneously based on semi-supervised learning. We also propose \\textbf{few-shot VFL} to improve the accuracy further with just one more communication round between the server and the clients. In our proposed framework, the clients only need to communicate with the server once or only a few times. We evaluate the proposed VFL framework on both image and tabular",
    "link": "http://arxiv.org/abs/2303.16270",
    "context": "Title: Communication-Efficient Vertical Federated Learning with Limited Overlapping Samples. (arXiv:2303.16270v1 [cs.LG])\nAbstract: Federated learning is a popular collaborative learning approach that enables clients to train a global model without sharing their local data. Vertical federated learning (VFL) deals with scenarios in which the data on clients have different feature spaces but share some overlapping samples. Existing VFL approaches suffer from high communication costs and cannot deal efficiently with limited overlapping samples commonly seen in the real world. We propose a practical vertical federated learning (VFL) framework called \\textbf{one-shot VFL} that can solve the communication bottleneck and the problem of limited overlapping samples simultaneously based on semi-supervised learning. We also propose \\textbf{few-shot VFL} to improve the accuracy further with just one more communication round between the server and the clients. In our proposed framework, the clients only need to communicate with the server once or only a few times. We evaluate the proposed VFL framework on both image and tabular",
    "path": "papers/23/03/2303.16270.json",
    "total_tokens": 912,
    "translated_title": "在有限重叠样本情况下的通信高效的垂直联合学习方法",
    "translated_abstract": "垂直联合学习(VFL)是一种流行的协作学习方法，使客户端能够在不共享本地数据的情况下训练全局模型。VFL处理的是客户端数据具有不同的特征空间但共享一些重叠样本的情况。现有的VFL方法存在通信成本高和无法有效处理现实世界中常见的有限重叠样本问题。我们提出了一种名叫 \\textbf{one-shot VFL} 的实用VFL框架，基于半监督学习，可以同时解决通信瓶颈和有限重叠样本的问题。我们还提出了 \\textbf{few-shot VFL}，在只进行一次或仅少量通信的情况下，进一步提高准确性。在我们提出的框架中，客户端只需要与服务器进行一次或仅少量通信。我们在图像和表格数据集上评估了所提出的VFL框架。",
    "tldr": "提出了一种名叫one-shot VFL的实用VFL框架，可以同时解决通信瓶颈和有限重叠样本的问题。few-shot VFL则可以在进行一次或仅少量通信的情况下进一步提高准确性。",
    "en_tdlr": "The paper proposes a practical VFL framework called one-shot VFL that can solve the communication bottleneck and the problem of limited overlapping samples simultaneously. Few-shot VFL can further improve the accuracy with just one more communication round between the server and the clients."
}