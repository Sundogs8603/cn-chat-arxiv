{
    "title": "Sem4SAP: Synonymous Expression Mining From Open Knowledge Graph For Language Model Synonym-Aware Pretraining. (arXiv:2303.14425v1 [cs.CL])",
    "abstract": "The model's ability to understand synonymous expression is crucial in many kinds of downstream tasks. It will make the model to better understand the similarity between context, and more robust to the synonym substitution attack. However, many Pretrained Language Model (PLM) lack synonym knowledge due to limitation of small-scale synsets and PLM's pretraining objectives. In this paper, we propose a framework called Sem4SAP to mine synsets from Open Knowledge Graph (Open-KG) and using the mined synsets to do synonym-aware pretraining for language models. We propose to coarsly filter the content in Open-KG and use the frequency information to better help the clustering process under low-resource unsupervised conditions. We expand the mined synsets by migrating core semantics between synonymous expressions.We also propose two novel and effective synonym-aware pre-training methods for injecting synonym knowledge into PLMs.Extensive experiments demonstrate that Sem4SAP can dramatically outp",
    "link": "http://arxiv.org/abs/2303.14425",
    "context": "Title: Sem4SAP: Synonymous Expression Mining From Open Knowledge Graph For Language Model Synonym-Aware Pretraining. (arXiv:2303.14425v1 [cs.CL])\nAbstract: The model's ability to understand synonymous expression is crucial in many kinds of downstream tasks. It will make the model to better understand the similarity between context, and more robust to the synonym substitution attack. However, many Pretrained Language Model (PLM) lack synonym knowledge due to limitation of small-scale synsets and PLM's pretraining objectives. In this paper, we propose a framework called Sem4SAP to mine synsets from Open Knowledge Graph (Open-KG) and using the mined synsets to do synonym-aware pretraining for language models. We propose to coarsly filter the content in Open-KG and use the frequency information to better help the clustering process under low-resource unsupervised conditions. We expand the mined synsets by migrating core semantics between synonymous expressions.We also propose two novel and effective synonym-aware pre-training methods for injecting synonym knowledge into PLMs.Extensive experiments demonstrate that Sem4SAP can dramatically outp",
    "path": "papers/23/03/2303.14425.json",
    "total_tokens": 974,
    "translated_title": "Sem4SAP: 基于开放知识图谱进行同义表达式挖掘，为语言模型同义词感知预训练提供支持",
    "translated_abstract": "对于许多下游任务而言，模型理解同义表达式的能力至关重要。这将使模型更好地理解上下文之间的相似性，并更具有抵御同义词替换攻击的鲁棒性。本文提出了一种称为Sem4SAP的框架，从开放知识图谱（Open-KG）中挖掘同义词，并利用挖掘到的同义词进行语言模型同义词感知预训练。我们提出简要过滤Open-KG中的内容，并利用频率信息来更好地帮助低资源无监督条件下的聚类过程。我们通过迁移同义表达式之间的核心语义来扩展挖掘到的同义词。我们还提出了两种新颖而有效的同义词感知预训练方法，用于将同义词知识注入PLMs (Pretrained Language Model)中。大量实验表明，Sem4SAP可以显著提高模型质量。",
    "tldr": "Sem4SAP利用开放知识图谱中挖掘到的同义词进行同义词感知预训练，扩展了同义词的应用范围，并提出两种新颖而有效的同义词感知预训练方法。实验结果表明，Sem4SAP可以显著提高模型质量。",
    "en_tdlr": "Sem4SAP proposes to mine synsets from Open Knowledge Graph (Open-KG) and using the mined synsets to do synonym-aware pretraining for language models. The framework expands the application of synonyms and proposes two effective synonym-aware pre-training methods. Extensive experiments show that Sem4SAP can significantly improve the quality of the model."
}