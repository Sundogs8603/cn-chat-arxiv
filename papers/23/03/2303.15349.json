{
    "title": "Information Maximizing Curriculum: A Curriculum-Based Approach for Imitating Diverse Skills. (arXiv:2303.15349v2 [cs.LG] UPDATED)",
    "abstract": "Imitation learning uses data for training policies to solve complex tasks. However, when the training data is collected from human demonstrators, it often leads to multimodal distributions because of the variability in human actions. Most imitation learning methods rely on a maximum likelihood (ML) objective to learn a parameterized policy, but this can result in suboptimal or unsafe behavior due to the mode-averaging property of the ML objective. In this work, we propose Information Maximizing Curriculum, a curriculum-based approach that assigns a weight to each data point and encourages the model to specialize in the data it can represent, effectively mitigating the mode-averaging problem by allowing the model to ignore data from modes it cannot represent. To cover all modes and thus, enable diverse behavior, we extend our approach to a mixture of experts (MoE) policy, where each mixture component selects its own subset of the training data for learning. A novel, maximum entropy-base",
    "link": "http://arxiv.org/abs/2303.15349",
    "context": "Title: Information Maximizing Curriculum: A Curriculum-Based Approach for Imitating Diverse Skills. (arXiv:2303.15349v2 [cs.LG] UPDATED)\nAbstract: Imitation learning uses data for training policies to solve complex tasks. However, when the training data is collected from human demonstrators, it often leads to multimodal distributions because of the variability in human actions. Most imitation learning methods rely on a maximum likelihood (ML) objective to learn a parameterized policy, but this can result in suboptimal or unsafe behavior due to the mode-averaging property of the ML objective. In this work, we propose Information Maximizing Curriculum, a curriculum-based approach that assigns a weight to each data point and encourages the model to specialize in the data it can represent, effectively mitigating the mode-averaging problem by allowing the model to ignore data from modes it cannot represent. To cover all modes and thus, enable diverse behavior, we extend our approach to a mixture of experts (MoE) policy, where each mixture component selects its own subset of the training data for learning. A novel, maximum entropy-base",
    "path": "papers/23/03/2303.15349.json",
    "total_tokens": 942,
    "translated_title": "信息最大化课程：一种基于课程的模仿多样技能方法",
    "translated_abstract": "模仿学习通过训练策略来解决复杂任务，但当训练数据来自人类示范者时，由于人类行为的变异性，通常会导致多模态分布。大多数模仿学习方法依赖于最大似然（ML）目标来学习参数化策略，但由于ML目标的模平均特性，这可能导致次优或不安全的行为。在这项工作中，我们提出了信息最大化课程，一种基于课程的方法，为每个数据点分配权重，并鼓励模型专注于它能够表示的数据，通过允许模型忽略不能表示的模态数据来有效缓解模平均问题。为了涵盖所有模态并能够实现多样的行为，我们将我们的方法扩展到了专家混合（MoE）策略，其中每个混合成分为自己选择一部分训练数据进行学习。一种新颖的基于最大熵的方法被用来约束策略的多样性。",
    "tldr": "本文提出了一种信息最大化课程的模仿学习方法，通过为每个数据点分配权重，让模型专注于能够表示的数据，从而解决模平均问题。为了实现多样性行为，该方法采用了专家混合策略，并引入了最大熵约束。",
    "en_tdlr": "This paper proposes an information maximizing curriculum-based approach for imitation learning, which assigns weights to data points to address the mode-averaging problem. To enable diverse behavior, the approach utilizes a mixture of experts strategy and introduces maximum entropy constraints."
}