{
    "title": "On the De-duplication of LAION-2B. (arXiv:2303.12733v1 [cs.CV])",
    "abstract": "Generative models, such as DALL-E, Midjourney, and Stable Diffusion, have societal implications that extend beyond the field of computer science. These models require large image databases like LAION-2B, which contain two billion images. At this scale, manual inspection is difficult and automated analysis is challenging. In addition, recent studies show that duplicated images pose copyright problems for models trained on LAION2B, which hinders its usability. This paper proposes an algorithmic chain that runs with modest compute, that compresses CLIP features to enable efficient duplicate detection, even for vast image volumes. Our approach demonstrates that roughly 700 million images, or about 30\\%, of LAION-2B's images are likely duplicated. Our method also provides the histograms of duplication on this dataset, which we use to reveal more examples of verbatim copies by Stable Diffusion and further justify the approach. The current version of the de-duplicated set will be distributed ",
    "link": "http://arxiv.org/abs/2303.12733",
    "context": "Title: On the De-duplication of LAION-2B. (arXiv:2303.12733v1 [cs.CV])\nAbstract: Generative models, such as DALL-E, Midjourney, and Stable Diffusion, have societal implications that extend beyond the field of computer science. These models require large image databases like LAION-2B, which contain two billion images. At this scale, manual inspection is difficult and automated analysis is challenging. In addition, recent studies show that duplicated images pose copyright problems for models trained on LAION2B, which hinders its usability. This paper proposes an algorithmic chain that runs with modest compute, that compresses CLIP features to enable efficient duplicate detection, even for vast image volumes. Our approach demonstrates that roughly 700 million images, or about 30\\%, of LAION-2B's images are likely duplicated. Our method also provides the histograms of duplication on this dataset, which we use to reveal more examples of verbatim copies by Stable Diffusion and further justify the approach. The current version of the de-duplicated set will be distributed ",
    "path": "papers/23/03/2303.12733.json",
    "total_tokens": 941,
    "translated_title": "LAION-2B的去重算法研究",
    "translated_abstract": "生成模型，如DALL-E、Midjourney和Stable Diffusion等，具有超越计算机科学领域的社会意义，这些模型需要像LAION-2B这样包含20亿张图片的大型图像数据库。在这个规模下，手动检查是困难的，自动分析也具有挑战性。此外，最近的研究表明，在LAION-2B上训练的模型中，重复的图像会导致版权问题，这影响了其可用性。本文提出了一种算法链，使用适度计算量的CLIP特征进行压缩，实现高效的重复检测，即使是巨大的图像数据集。我们的方法证明，LAION-2B中约700万张图像，约30\\%的图像可能是重复的。我们的方法还提供了该数据集上的重复图像直方图，用于揭示Stable Diffusion的逐字复制示例，并进一步证明了我们的方法的可行性。当前版本的去重集将被分发。",
    "tldr": "本文提出了一种算法链，使用适度计算量的CLIP特征进行压缩，实现高效的重复检测，即使是巨大的图像数据集。该方法在LAION-2B中发现30\\%的图像可能是重复的，并提供了该数据集上的重复图像直方图，可用于检测模型的版权问题。",
    "en_tdlr": "This paper proposes an algorithmic chain for efficient duplicate detection on the large image database LAION-2B, using compressed CLIP features. The approach identifies that approximately 30% of images in LAION-2B may be duplicates and provides histograms of the duplication, which can reveal issues related to copyright infringement."
}