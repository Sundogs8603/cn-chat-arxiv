{
    "title": "ACAT: Adversarial Counterfactual Attention for Classification and Detection in Medical Imaging. (arXiv:2303.15421v2 [eess.IV] UPDATED)",
    "abstract": "In some medical imaging tasks and other settings where only small parts of the image are informative for the classification task, traditional CNNs can sometimes struggle to generalise. Manually annotated Regions of Interest (ROI) are sometimes used to isolate the most informative parts of the image. However, these are expensive to collect and may vary significantly across annotators. To overcome these issues, we propose a framework that employs saliency maps to obtain soft spatial attention masks that modulate the image features at different scales. We refer to our method as Adversarial Counterfactual Attention (ACAT). ACAT increases the baseline classification accuracy of lesions in brain CT scans from 71.39% to 72.55% and of COVID-19 related findings in lung CT scans from 67.71% to 70.84% and exceeds the performance of competing methods. We investigate the best way to generate the saliency maps employed in our architecture and propose a way to obtain them from adversarially generated",
    "link": "http://arxiv.org/abs/2303.15421",
    "context": "Title: ACAT: Adversarial Counterfactual Attention for Classification and Detection in Medical Imaging. (arXiv:2303.15421v2 [eess.IV] UPDATED)\nAbstract: In some medical imaging tasks and other settings where only small parts of the image are informative for the classification task, traditional CNNs can sometimes struggle to generalise. Manually annotated Regions of Interest (ROI) are sometimes used to isolate the most informative parts of the image. However, these are expensive to collect and may vary significantly across annotators. To overcome these issues, we propose a framework that employs saliency maps to obtain soft spatial attention masks that modulate the image features at different scales. We refer to our method as Adversarial Counterfactual Attention (ACAT). ACAT increases the baseline classification accuracy of lesions in brain CT scans from 71.39% to 72.55% and of COVID-19 related findings in lung CT scans from 67.71% to 70.84% and exceeds the performance of competing methods. We investigate the best way to generate the saliency maps employed in our architecture and propose a way to obtain them from adversarially generated",
    "path": "papers/23/03/2303.15421.json",
    "total_tokens": 996,
    "translated_title": "ACAT: 拟对抗反事实注意力用于医学图像分类和检测",
    "translated_abstract": "在某些医学图像任务和其他仅有图像的小部分对分类任务有信息贡献的情况下，传统的卷积神经网络有时很难泛化。手动注释的感兴趣区域(ROI)有时被用来隔离图像中最具信息价值的部分。然而，这些注释很费时费力，并且在不同的注释者之间可能存在显著差异。为了克服这些问题，我们提出了一种框架，利用显著性图来获取软性空间注意力掩膜，调节不同尺度下的图像特征。我们称之为拟对抗反事实注意力(ACAT)方法。ACAT将脑部CT扫描中病变的基准分类准确率从71.39％提高到72.55％，将肺部CT扫描中与COVID-19相关结果的基准分类准确率从67.71％提高到70.84％，并超过了竞争方法的性能。我们研究了生成我们架构中使用的显著性图的最佳方法，并提出了一种从拟对抗生成中获取它们的方法。",
    "tldr": "ACAT使用拟对抗反事实注意力的方法可以提高医学图像分类和检测的准确性，在脑部CT扫描中将病变的分类准确率提高到72.55%，在肺部CT扫描中将与COVID-19相关结果的分类准确率提高到70.84%。"
}