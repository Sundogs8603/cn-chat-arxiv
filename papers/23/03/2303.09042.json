{
    "title": "Embedding Theory of Reservoir Computing and Reducing Reservoir Network Using Time Delays. (arXiv:2303.09042v1 [cs.LG])",
    "abstract": "Reservoir computing (RC), a particular form of recurrent neural network, is under explosive development due to its exceptional efficacy and high performance in reconstruction or/and prediction of complex physical systems. However, the mechanism triggering such effective applications of RC is still unclear, awaiting deep and systematic exploration. Here, combining the delayed embedding theory with the generalized embedding theory, we rigorously prove that RC is essentially a high dimensional embedding of the original input nonlinear dynamical system. Thus, using this embedding property, we unify into a universal framework the standard RC and the time-delayed RC where we novelly introduce time delays only into the network's output layer, and we further find a trade-off relation between the time delays and the number of neurons in RC. Based on this finding, we significantly reduce the network size of RC for reconstructing and predicting some representative physical systems, and, more surp",
    "link": "http://arxiv.org/abs/2303.09042",
    "context": "Title: Embedding Theory of Reservoir Computing and Reducing Reservoir Network Using Time Delays. (arXiv:2303.09042v1 [cs.LG])\nAbstract: Reservoir computing (RC), a particular form of recurrent neural network, is under explosive development due to its exceptional efficacy and high performance in reconstruction or/and prediction of complex physical systems. However, the mechanism triggering such effective applications of RC is still unclear, awaiting deep and systematic exploration. Here, combining the delayed embedding theory with the generalized embedding theory, we rigorously prove that RC is essentially a high dimensional embedding of the original input nonlinear dynamical system. Thus, using this embedding property, we unify into a universal framework the standard RC and the time-delayed RC where we novelly introduce time delays only into the network's output layer, and we further find a trade-off relation between the time delays and the number of neurons in RC. Based on this finding, we significantly reduce the network size of RC for reconstructing and predicting some representative physical systems, and, more surp",
    "path": "papers/23/03/2303.09042.json",
    "total_tokens": 1010,
    "translated_title": "嵌入式理论在洪泛计算中的应用及利用时间延迟减少洪泛网络规模",
    "translated_abstract": "洪泛计算作为一种特殊的循环神经网络，由于在重构或/和预测复杂物理系统方面具有卓越的功效和高性能，因此正在爆炸性发展。然而，触发RC如此有效应用的机制仍不清楚，需要深入而系统的探索。本文结合延迟嵌入理论和广义嵌入理论，严谨证明了RC本质上是原始输入非线性动态系统的高维嵌入。因此，利用这种嵌入特性，我们将标准RC和时间延迟RC统一到一个通用框架中，并且我们对网络的输出层仅引入时间延迟，进一步发现了时间延迟和网络神经元数量之间的权衡关系。基于这一发现，我们显着减小了洪泛计算网络的大小，用于重构和预测一些代表性的物理系统，并且更让人惊讶的是，实现了比全尺寸RC更好的性能。",
    "tldr": "本文结合延迟嵌入理论和广义嵌入理论，严谨证明了RC本质上是原始输入非线性动态系统的高维嵌入。我们进一步发现了时间延迟和网络神经元数量之间的权衡关系，并显着减小了洪泛计算网络的大小，实现了比全尺寸RC更好的性能。",
    "en_tdlr": "This paper rigorously proves that reservoir computing (RC) is essentially a high dimensional embedding of the original input nonlinear dynamical system by combining the delayed embedding theory with the generalized embedding theory. The authors further find a trade-off relation between the time delays and the number of neurons in RC, and significantly reduce the network size of RC for reconstructing and predicting some representative physical systems, achieving better performance than the full-size RC."
}