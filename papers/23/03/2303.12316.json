{
    "title": "TsSHAP: Robust model agnostic feature-based explainability for time series forecasting. (arXiv:2303.12316v1 [cs.LG])",
    "abstract": "A trustworthy machine learning model should be accurate as well as explainable. Understanding why a model makes a certain decision defines the notion of explainability. While various flavors of explainability have been well-studied in supervised learning paradigms like classification and regression, literature on explainability for time series forecasting is relatively scarce.  In this paper, we propose a feature-based explainability algorithm, TsSHAP, that can explain the forecast of any black-box forecasting model. The method is agnostic of the forecasting model and can provide explanations for a forecast in terms of interpretable features defined by the user a prior.  The explanations are in terms of the SHAP values obtained by applying the TreeSHAP algorithm on a surrogate model that learns a mapping between the interpretable feature space and the forecast of the black-box model.  Moreover, we formalize the notion of local, semi-local, and global explanations in the context of time",
    "link": "http://arxiv.org/abs/2303.12316",
    "context": "Title: TsSHAP: Robust model agnostic feature-based explainability for time series forecasting. (arXiv:2303.12316v1 [cs.LG])\nAbstract: A trustworthy machine learning model should be accurate as well as explainable. Understanding why a model makes a certain decision defines the notion of explainability. While various flavors of explainability have been well-studied in supervised learning paradigms like classification and regression, literature on explainability for time series forecasting is relatively scarce.  In this paper, we propose a feature-based explainability algorithm, TsSHAP, that can explain the forecast of any black-box forecasting model. The method is agnostic of the forecasting model and can provide explanations for a forecast in terms of interpretable features defined by the user a prior.  The explanations are in terms of the SHAP values obtained by applying the TreeSHAP algorithm on a surrogate model that learns a mapping between the interpretable feature space and the forecast of the black-box model.  Moreover, we formalize the notion of local, semi-local, and global explanations in the context of time",
    "path": "papers/23/03/2303.12316.json",
    "total_tokens": 931,
    "translated_title": "TsSHAP: 强大的模型不可知特征解释方法，适用于时间序列预测",
    "translated_abstract": "一个可靠的机器学习模型应该是准确和可解释的。理解模型为什么做出某些决策定义了可解释性的概念。虽然已经研究了各种解释性模型，并广泛应用于监督学习范式，如分类和回归，但是对于时间序列预测的解释性文献相对较少。 在本文中，我们提出了一个特征解释算法TsSHAP，它可以解释任何黑盒预测模型的预测结果。该方法对预测模型不可知，并且可以根据用户预先定义的可解释特征来解释预测结果。 SHAP值的解释是通过在替代模型上应用TreeSHAP算法获得的，该替代模型学习了可解释特征空间和黑盒模型预测之间的映射。此外，在时间序列的背景下，我们还规范了局部、半局部和全局解释的概念。",
    "tldr": "本文提出了一种特征解释算法TsSHAP，该算法可以解释黑盒预测模型的预测结果，在可解释特征空间和预测结果之间建立了映射。这种算法可以提供局部，半局部和全局解释，能够适用于时间序列预测问题。",
    "en_tdlr": "This paper proposes a feature-based explainability algorithm, TsSHAP, that can explain the forecast of any black-box forecasting model, and provides local, semi-local, and global explanations for time series forecasting by mapping interpretable features to forecast results."
}