{
    "title": "Lamarr: LHCb ultra-fast simulation based on machine learning models deployed within Gauss. (arXiv:2303.11428v1 [hep-ex])",
    "abstract": "About 90% of the computing resources available to the LHCb experiment has been spent to produce simulated data samples for Run 2 of the Large Hadron Collider at CERN. The upgraded LHCb detector will be able to collect larger data samples, requiring many more simulated events to analyze the data to be collected in Run 3. Simulation is a key necessity of analysis to interpret signal vs background and measure efficiencies. The needed simulation will far exceed the pledged resources, requiring an evolution in technologies and techniques to produce these simulated data samples. In this contribution, we discuss Lamarr, a Gaudi-based framework to speed-up the simulation production parametrizing both the detector response and the reconstruction algorithms of the LHCb experiment. Deep Generative Models powered by several algorithms and strategies are employed to effectively parametrize the high-level response of the single components of the LHCb detector, encoding within neural networks the exp",
    "link": "http://arxiv.org/abs/2303.11428",
    "context": "Title: Lamarr: LHCb ultra-fast simulation based on machine learning models deployed within Gauss. (arXiv:2303.11428v1 [hep-ex])\nAbstract: About 90% of the computing resources available to the LHCb experiment has been spent to produce simulated data samples for Run 2 of the Large Hadron Collider at CERN. The upgraded LHCb detector will be able to collect larger data samples, requiring many more simulated events to analyze the data to be collected in Run 3. Simulation is a key necessity of analysis to interpret signal vs background and measure efficiencies. The needed simulation will far exceed the pledged resources, requiring an evolution in technologies and techniques to produce these simulated data samples. In this contribution, we discuss Lamarr, a Gaudi-based framework to speed-up the simulation production parametrizing both the detector response and the reconstruction algorithms of the LHCb experiment. Deep Generative Models powered by several algorithms and strategies are employed to effectively parametrize the high-level response of the single components of the LHCb detector, encoding within neural networks the exp",
    "path": "papers/23/03/2303.11428.json",
    "total_tokens": 895,
    "translated_title": "基于机器学习模型的LHCb超快速模拟系统Lamarr在Gauss中的应用",
    "translated_abstract": "LHCb实验可用的计算资源的约90%用于生产Large Hadron Collider（LHC）运行2的模拟数据样本。升级后的LHCb探测器将能够收集更多的数据样本，需要更多的模拟事件来分析将在运行3中收集的数据。模拟是分析的关键需求，以解释信号与背景并测量效率。这种需要的模拟将远远超出已承诺的资源，需要技术和技巧的演变来生产这些模拟数据样本。在这项贡献中，我们讨论了Lamarr，这是一种基于Gaudi框架的系统，该系统通过对LHCb实验的探测器响应和重建算法进行参数化，加快了模拟产出。使用基于多种算法和策略的深度生成模型，有效地参数化了LHCb探测器单个组件的高级响应，在神经网络中编码。",
    "tldr": "LHCb实验中的90%计算资源用于生产模拟数据样本，而Lamarr是一个基于机器学习模型的系统，通过对LHCb实验的探测器响应和重建算法进行参数化，加快了模拟产出。",
    "en_tdlr": "Lamarr is a machine learning-based system that speeds up the simulation production of the LHCb experiment by parametrizing the detector response and reconstruction algorithms, with about 90% of the available computing resources used for the production of simulated data samples."
}