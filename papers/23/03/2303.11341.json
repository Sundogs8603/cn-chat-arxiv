{
    "title": "What does it take to catch a Chinchilla? Verifying Rules on Large-Scale Neural Network Training via Compute Monitoring. (arXiv:2303.11341v1 [cs.LG])",
    "abstract": "As advanced machine learning systems' capabilities begin to play a significant role in geopolitics and societal order, it may become imperative that (1) governments be able to enforce rules on the development of advanced ML systems within their borders, and (2) countries be able to verify each other's compliance with potential future international agreements on advanced ML development. This work analyzes one mechanism to achieve this, by monitoring the computing hardware used for large-scale NN training. The framework's primary goal is to provide governments high confidence that no actor uses large quantities of specialized ML chips to execute a training run in violation of agreed rules. At the same time, the system does not curtail the use of consumer computing devices, and maintains the privacy and confidentiality of ML practitioners' models, data, and hyperparameters. The system consists of interventions at three stages: (1) using on-chip firmware to occasionally save snapshots of t",
    "link": "http://arxiv.org/abs/2303.11341",
    "context": "Title: What does it take to catch a Chinchilla? Verifying Rules on Large-Scale Neural Network Training via Compute Monitoring. (arXiv:2303.11341v1 [cs.LG])\nAbstract: As advanced machine learning systems' capabilities begin to play a significant role in geopolitics and societal order, it may become imperative that (1) governments be able to enforce rules on the development of advanced ML systems within their borders, and (2) countries be able to verify each other's compliance with potential future international agreements on advanced ML development. This work analyzes one mechanism to achieve this, by monitoring the computing hardware used for large-scale NN training. The framework's primary goal is to provide governments high confidence that no actor uses large quantities of specialized ML chips to execute a training run in violation of agreed rules. At the same time, the system does not curtail the use of consumer computing devices, and maintains the privacy and confidentiality of ML practitioners' models, data, and hyperparameters. The system consists of interventions at three stages: (1) using on-chip firmware to occasionally save snapshots of t",
    "path": "papers/23/03/2303.11341.json",
    "total_tokens": 939,
    "translated_abstract": "随着先进的机器学习系统在地缘政治和社会秩序中发挥越来越重要的作用，政府需要能够在其境内强制执行先进机器学习系统的开发规则，而各国需要能够验证彼此在未来潜在的国际先进机器学习开发协议中的遵守情况。本文分析了通过监控用于大规模神经网络训练的计算硬件来实现这一目标的机制。该框架的主要目标是为政府提供高度的信心，即没有任何人使用大量的专用机器学习芯片来执行违反同意规则的训练运行。同时，该系统不会限制消费者计算设备的使用，并保持机器学习从业者的模型、数据和超参数的隐私和机密性。该系统包括三个阶段的干预：（1）使用芯片固件偶尔保存训练状态的快照。",
    "tldr": "本文分析了一种通过监控用于大规模神经网络训练的计算硬件来监测和执行先进机器学习的规则，以确保遵守国际协议和规定。同时，系统不影响消费者计算设备的使用和机器学习专业人员隐私保护。",
    "en_tdlr": "This paper analyzes a mechanism for enforcing rules on advanced machine learning development through monitoring the computing hardware used for large-scale neural network training. The goal is to ensure compliance with international agreements and regulations, while maintaining privacy and not limiting the use of consumer computing devices."
}