{
    "title": "Learning Internal Representations of 3D Transformations from 2D Projected Inputs. (arXiv:2303.17776v1 [q-bio.NC])",
    "abstract": "When interacting in a three dimensional world, humans must estimate 3D structure from visual inputs projected down to two dimensional retinal images. It has been shown that humans use the persistence of object shape over motion-induced transformations as a cue to resolve depth ambiguity when solving this underconstrained problem. With the aim of understanding how biological vision systems may internally represent 3D transformations, we propose a computational model, based on a generative manifold model, which can be used to infer 3D structure from the motion of 2D points. Our model can also learn representations of the transformations with minimal supervision, providing a proof of concept for how humans may develop internal representations on a developmental or evolutionary time scale. Focused on rotational motion, we show how our model infers depth from moving 2D projected points, learns 3D rotational transformations from 2D training stimuli, and compares to human performance on psych",
    "link": "http://arxiv.org/abs/2303.17776",
    "context": "Title: Learning Internal Representations of 3D Transformations from 2D Projected Inputs. (arXiv:2303.17776v1 [q-bio.NC])\nAbstract: When interacting in a three dimensional world, humans must estimate 3D structure from visual inputs projected down to two dimensional retinal images. It has been shown that humans use the persistence of object shape over motion-induced transformations as a cue to resolve depth ambiguity when solving this underconstrained problem. With the aim of understanding how biological vision systems may internally represent 3D transformations, we propose a computational model, based on a generative manifold model, which can be used to infer 3D structure from the motion of 2D points. Our model can also learn representations of the transformations with minimal supervision, providing a proof of concept for how humans may develop internal representations on a developmental or evolutionary time scale. Focused on rotational motion, we show how our model infers depth from moving 2D projected points, learns 3D rotational transformations from 2D training stimuli, and compares to human performance on psych",
    "path": "papers/23/03/2303.17776.json",
    "total_tokens": 884,
    "translated_title": "从二维投影图像中学习三维变换的内部表示",
    "translated_abstract": "在三维世界中交互时，人类必须从投影到二维视网膜图像中估计三维结构。研究表明，人类使用物体形状在运动引起的转换中的持久性作为提示来解决深度模糊问题。为了了解生物视觉系统如何内部表示三维变换，我们提出了一种基于生成流形模型的计算模型，该模型可以从二维点的运动中推断三维结构。我们的模型还可以学习变换的表示，提供了一个概念验证，说明人类如何在发育或演化的时间尺度上发展内部表示。我们的模型集中于旋转运动，展示了我们的模型如何从移动的二维投影点中推断深度，从2D训练刺激中学习三维旋转变换，并与人的心理表现进行比较。",
    "tldr": "该论文提出了一种基于生成流形模型的计算模型，通过对移动的二维投影点进行深度推断，学习了三维旋转变换，为了理解生物视觉系统如何内部表示三维变换提供了思路。",
    "en_tdlr": "This paper proposes a computational model based on a generative manifold model which can infer 3D structure from motion of 2D points, and can learn representations of the transformations with minimal supervision. It provides insights into how biological vision systems may internally represent 3D transformations."
}