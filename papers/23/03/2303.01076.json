{
    "title": "Hallucinated Adversarial Control for Conservative Offline Policy Evaluation. (arXiv:2303.01076v2 [cs.LG] UPDATED)",
    "abstract": "We study the problem of conservative off-policy evaluation (COPE) where given an offline dataset of environment interactions, collected by other agents, we seek to obtain a (tight) lower bound on a policy's performance. This is crucial when deciding whether a given policy satisfies certain minimal performance/safety criteria before it can be deployed in the real world. To this end, we introduce HAMBO, which builds on an uncertainty-aware learned model of the transition dynamics. To form a conservative estimate of the policy's performance, HAMBO hallucinates worst-case trajectories that the policy may take, within the margin of the models' epistemic confidence regions. We prove that the resulting COPE estimates are valid lower bounds, and, under regularity conditions, show their convergence to the true expected return. Finally, we discuss scalable variants of our approach based on Bayesian Neural Networks and empirically demonstrate that they yield reliable and tight lower bounds in var",
    "link": "http://arxiv.org/abs/2303.01076",
    "context": "Title: Hallucinated Adversarial Control for Conservative Offline Policy Evaluation. (arXiv:2303.01076v2 [cs.LG] UPDATED)\nAbstract: We study the problem of conservative off-policy evaluation (COPE) where given an offline dataset of environment interactions, collected by other agents, we seek to obtain a (tight) lower bound on a policy's performance. This is crucial when deciding whether a given policy satisfies certain minimal performance/safety criteria before it can be deployed in the real world. To this end, we introduce HAMBO, which builds on an uncertainty-aware learned model of the transition dynamics. To form a conservative estimate of the policy's performance, HAMBO hallucinates worst-case trajectories that the policy may take, within the margin of the models' epistemic confidence regions. We prove that the resulting COPE estimates are valid lower bounds, and, under regularity conditions, show their convergence to the true expected return. Finally, we discuss scalable variants of our approach based on Bayesian Neural Networks and empirically demonstrate that they yield reliable and tight lower bounds in var",
    "path": "papers/23/03/2303.01076.json",
    "total_tokens": 863,
    "translated_title": "基于幻想对抗控制的保守离线策略评估",
    "translated_abstract": "本文研究了保守离线策略评估问题，对于给定其他代理收集的离线环境交互数据集，我们旨在获得一个关于策略性能的(紧)下限估计。这在决定是否部署某个策略满足最小性能/安全标准之前至关重要。为此，我们引入了HAMBO，它建立在一个学习到的传递动态的不确定性感知模型之上。为了形成策略绩效的保守估计，HAMBO会幻想策略可能采取的最坏轨迹，且该轨迹在模型的认知置信区间内。我们证明了结果的COPE估计是有效的下限，并在正则性条件下展示其收敛于真实的预期回报。最后，我们讨论了基于Bayesian神经网络的可扩展变体，并在实验中证明它们产生可靠且紧密的下限。",
    "tldr": "本文提出了基于幻想对抗控制的HAMBO算法，可用于离线策略评估，并且能够得出有效的策略表现下限估计。",
    "en_tdlr": "This paper proposes the HAMBO algorithm based on hallucinated adversarial control for offline policy evaluation, which can effectively estimate lower bounds on policy performance."
}