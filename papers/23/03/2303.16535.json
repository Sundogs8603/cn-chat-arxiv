{
    "title": "Nonlinear Independent Component Analysis for Principled Disentanglement in Unsupervised Deep Learning. (arXiv:2303.16535v1 [cs.LG])",
    "abstract": "A central problem in unsupervised deep learning is how to find useful representations of high-dimensional data, sometimes called \"disentanglement\". Most approaches are heuristic and lack a proper theoretical foundation. In linear representation learning, independent component analysis (ICA) has been successful in many applications areas, and it is principled, i.e. based on a well-defined probabilistic model. However, extension of ICA to the nonlinear case has been problematic due to the lack of identifiability, i.e. uniqueness of the representation. Recently, nonlinear extensions that utilize temporal structure or some auxiliary information have been proposed. Such models are in fact identifiable, and consequently, an increasing number of algorithms have been developed. In particular, some self-supervised algorithms can be shown to estimate nonlinear ICA, even though they have initially been proposed from heuristic perspectives. This paper reviews the state-of-the-art of nonlinear ICA ",
    "link": "http://arxiv.org/abs/2303.16535",
    "context": "Title: Nonlinear Independent Component Analysis for Principled Disentanglement in Unsupervised Deep Learning. (arXiv:2303.16535v1 [cs.LG])\nAbstract: A central problem in unsupervised deep learning is how to find useful representations of high-dimensional data, sometimes called \"disentanglement\". Most approaches are heuristic and lack a proper theoretical foundation. In linear representation learning, independent component analysis (ICA) has been successful in many applications areas, and it is principled, i.e. based on a well-defined probabilistic model. However, extension of ICA to the nonlinear case has been problematic due to the lack of identifiability, i.e. uniqueness of the representation. Recently, nonlinear extensions that utilize temporal structure or some auxiliary information have been proposed. Such models are in fact identifiable, and consequently, an increasing number of algorithms have been developed. In particular, some self-supervised algorithms can be shown to estimate nonlinear ICA, even though they have initially been proposed from heuristic perspectives. This paper reviews the state-of-the-art of nonlinear ICA ",
    "path": "papers/23/03/2303.16535.json",
    "total_tokens": 890,
    "translated_title": "无监督深度学习中基于非线性独立成分分析的原则分离问题",
    "translated_abstract": "在无监督深度学习中，如何找到有用的高维数据表示，即所谓的“分离”问题至关重要。大多数方法都是启发式的，缺乏适当的理论基础。在线性表示学习中，独立成分分析（ICA）在许多应用领域取得了成功，并且具有基于良定义的概率模型的原则性。 然而，将ICA扩展到非线性情况已经成为一个棘手的问题，这是由于缺乏可识别性，即表示的唯一性。最近，已经提出了使用时间结构或某些辅助信息的非线性扩展。这些模型实际上是可识别的，因此已经开发出越来越多的算法。特别是一些自监督算法可以显示出估计非线性ICA，即使最初是从启发式角度提出的。本文总结了非线性ICA的最新进展。",
    "tldr": "本文概括了无监督深度学习中基于独立成分分析方法的最新发展，特别是对于解决非线性情况下唯一性问题提出了可识别的扩展方法。",
    "en_tdlr": "This paper reviews the state-of-the-art of nonlinear Independent Component Analysis (ICA) in unsupervised deep learning, especially the identifiable extension methods proposed to solve the uniqueness issue in the nonlinear case."
}