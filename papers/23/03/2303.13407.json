{
    "title": "Adaptive Endpointing with Deep Contextual Multi-armed Bandits. (arXiv:2303.13407v1 [eess.AS])",
    "abstract": "Current endpointing (EP) solutions learn in a supervised framework, which does not allow the model to incorporate feedback and improve in an online setting. Also, it is a common practice to utilize costly grid-search to find the best configuration for an endpointing model. In this paper, we aim to provide a solution for adaptive endpointing by proposing an efficient method for choosing an optimal endpointing configuration given utterance-level audio features in an online setting, while avoiding hyperparameter grid-search. Our method does not require ground truth labels, and only uses online learning from reward signals without requiring annotated labels. Specifically, we propose a deep contextual multi-armed bandit-based approach, which combines the representational power of neural networks with the action exploration behavior of Thompson modeling algorithms. We compare our approach to several baselines, and show that our deep bandit models also succeed in reducing early cutoff errors ",
    "link": "http://arxiv.org/abs/2303.13407",
    "context": "Title: Adaptive Endpointing with Deep Contextual Multi-armed Bandits. (arXiv:2303.13407v1 [eess.AS])\nAbstract: Current endpointing (EP) solutions learn in a supervised framework, which does not allow the model to incorporate feedback and improve in an online setting. Also, it is a common practice to utilize costly grid-search to find the best configuration for an endpointing model. In this paper, we aim to provide a solution for adaptive endpointing by proposing an efficient method for choosing an optimal endpointing configuration given utterance-level audio features in an online setting, while avoiding hyperparameter grid-search. Our method does not require ground truth labels, and only uses online learning from reward signals without requiring annotated labels. Specifically, we propose a deep contextual multi-armed bandit-based approach, which combines the representational power of neural networks with the action exploration behavior of Thompson modeling algorithms. We compare our approach to several baselines, and show that our deep bandit models also succeed in reducing early cutoff errors ",
    "path": "papers/23/03/2303.13407.json",
    "total_tokens": 891,
    "translated_title": "深度上下文多臂赌博机的自适应端点检测",
    "translated_abstract": "目前的端点检测（EP）解决方案是在监督框架下进行学习的，这不允许模型获得反馈并在在线设置中改进。此外，通常使用昂贵的网格搜索来找到端点检测模型的最佳配置。本文旨在通过提出一种有效的方法，为给定语音级别的音频特征在在线设置中选择最佳的端点检测配置，同时避免超参数的网格搜索，从而为自适应端点检测提供解决方案。我们的方法不需要地面真值标签，并仅使用来自奖励信号的在线学习而不需要注释标签。具体地，我们提出了一种基于深度上下文多臂赌博机的方法，它结合了神经网络的表征能力和汤普森建模算法的行为探索行为。我们将我们的方法与几个基线进行比较，并证明我们的深度赌博模型也成功减少了早期截止误差。",
    "tldr": "在线学习的自适应端点检测方法，使用深度上下文多臂赌博机，避免使用昂贵的网格搜索，不需要真值标签，并成功减少了早期截止错误。",
    "en_tdlr": "An adaptive endpointing method using deep contextual multi-armed bandits is proposed for choosing the optimal endpoint configuration given utterance-level audio features in an online setting, avoiding costly grid-search and requiring no ground truth labels, and shows success in reducing early cutoff errors."
}