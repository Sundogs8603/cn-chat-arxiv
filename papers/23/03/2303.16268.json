{
    "title": "TimeBalance: Temporally-Invariant and Temporally-Distinctive Video Representations for Semi-Supervised Action Recognition. (arXiv:2303.16268v1 [cs.CV])",
    "abstract": "Semi-Supervised Learning can be more beneficial for the video domain compared to images because of its higher annotation cost and dimensionality. Besides, any video understanding task requires reasoning over both spatial and temporal dimensions. In order to learn both the static and motion related features for the semi-supervised action recognition task, existing methods rely on hard input inductive biases like using two-modalities (RGB and Optical-flow) or two-stream of different playback rates. Instead of utilizing unlabeled videos through diverse input streams, we rely on self-supervised video representations, particularly, we utilize temporally-invariant and temporally-distinctive representations. We observe that these representations complement each other depending on the nature of the action. Based on this observation, we propose a student-teacher semi-supervised learning framework, TimeBalance, where we distill the knowledge from a temporally-invariant and a temporally-distincti",
    "link": "http://arxiv.org/abs/2303.16268",
    "context": "Title: TimeBalance: Temporally-Invariant and Temporally-Distinctive Video Representations for Semi-Supervised Action Recognition. (arXiv:2303.16268v1 [cs.CV])\nAbstract: Semi-Supervised Learning can be more beneficial for the video domain compared to images because of its higher annotation cost and dimensionality. Besides, any video understanding task requires reasoning over both spatial and temporal dimensions. In order to learn both the static and motion related features for the semi-supervised action recognition task, existing methods rely on hard input inductive biases like using two-modalities (RGB and Optical-flow) or two-stream of different playback rates. Instead of utilizing unlabeled videos through diverse input streams, we rely on self-supervised video representations, particularly, we utilize temporally-invariant and temporally-distinctive representations. We observe that these representations complement each other depending on the nature of the action. Based on this observation, we propose a student-teacher semi-supervised learning framework, TimeBalance, where we distill the knowledge from a temporally-invariant and a temporally-distincti",
    "path": "papers/23/03/2303.16268.json",
    "total_tokens": 999,
    "translated_title": "TimeBalance：面向半监督行为识别的时间不变和时间不同视频表示",
    "translated_abstract": "与图像相比，半监督学习对于视频领域更具有优势，因为其注释成本和维度更高。为了学习半监督动作识别任务的静态和运动相关特征，现有方法依赖于硬输入归纳偏差，如使用两种模式（RGB和Optical-flow）或不同播放速率的两个流。我们不使用不同的输入流利用未标记的视频，相反，我们依赖于自监督视频表示，尤其是我们使用时间不变和时间不同的表示。我们观察到，这些表示根据动作的性质相互补充。基于这个观察，我们提出了一种名为TimeBalance的师生半监督学习框架，我们将来自时间不变和时间不同的教师模型的知识提炼到一个学生模型中，以学习准确的行为识别特征。在UCF101，HMDB51和Kinetics等标准基准测试中的实验评估表明了我们方法的有效性，在半监督设置下超越了现有技术水平。",
    "tldr": "TimeBalance是一个半监督学习框架，通过利用时间不变和时间不同的自监督视频表示来学习准确的行为识别特征。实验结果表明该方法在半监督设置下超越了现有技术水平。",
    "en_tdlr": "TimeBalance is a semi-supervised learning framework that learns accurate action recognition features by utilizing temporally-invariant and temporally-distinctive self-supervised video representations. Experimental results demonstrate that this approach surpasses the state-of-the-art in the semi-supervised setting."
}