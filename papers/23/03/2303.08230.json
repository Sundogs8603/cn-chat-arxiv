{
    "title": "Bayesian Beta-Bernoulli Process Sparse Coding with Deep Neural Networks. (arXiv:2303.08230v1 [cs.LG])",
    "abstract": "Several approximate inference methods have been proposed for deep discrete latent variable models. However, non-parametric methods which have previously been successfully employed for classical sparse coding models have largely been unexplored in the context of deep models. We propose a non-parametric iterative algorithm for learning discrete latent representations in such deep models. Additionally, to learn scale invariant discrete features, we propose local data scaling variables. Lastly, to encourage sparsity in our representations, we propose a Beta-Bernoulli process prior on the latent factors. We evaluate our spare coding model coupled with different likelihood models. We evaluate our method across datasets with varying characteristics and compare our results to current amortized approximate inference methods.",
    "link": "http://arxiv.org/abs/2303.08230",
    "context": "Title: Bayesian Beta-Bernoulli Process Sparse Coding with Deep Neural Networks. (arXiv:2303.08230v1 [cs.LG])\nAbstract: Several approximate inference methods have been proposed for deep discrete latent variable models. However, non-parametric methods which have previously been successfully employed for classical sparse coding models have largely been unexplored in the context of deep models. We propose a non-parametric iterative algorithm for learning discrete latent representations in such deep models. Additionally, to learn scale invariant discrete features, we propose local data scaling variables. Lastly, to encourage sparsity in our representations, we propose a Beta-Bernoulli process prior on the latent factors. We evaluate our spare coding model coupled with different likelihood models. We evaluate our method across datasets with varying characteristics and compare our results to current amortized approximate inference methods.",
    "path": "papers/23/03/2303.08230.json",
    "total_tokens": 811,
    "translated_title": "基于Beta-Bernoulli过程和深度神经网络的贝叶斯稀疏编码",
    "translated_abstract": "针对深度离散潜变量模型，已经提出了几种近似推断方法。然而，在经典稀疏编码模型中成功应用的非参数方法，在深度模型的上下文中很少被探索。我们提出了一种非参数迭代算法，用于学习此类深度模型中的离散潜在表示。此外，为了学习具有尺度不变性的离散特征，我们提出了本地数据缩放变量。最后，为了在我们的表示中鼓励稀疏性，我们在潜在因子上提出了Beta-Bernoulli过程先验。我们对耦合不同似然模型的稀疏编码模型进行了评估。我们在具有不同特征的数据集上评估我们的方法，并将结果与当前的摊销近似推断方法进行比较。",
    "tldr": "本文提出了一种基于Beta-Bernoulli过程和非参数迭代算法的深度稀疏编码模型，旨在学习具有尺度不变性的离散特征，并鼓励表示的稀疏性。",
    "en_tdlr": "This paper proposes a deep sparse coding model based on Beta-Bernoulli process and non-parametric iterative algorithm, aiming to learn scale invariant discrete features and encourage sparsity in representations."
}