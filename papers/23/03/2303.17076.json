{
    "title": "DiffCollage: Parallel Generation of Large Content with Diffusion Models. (arXiv:2303.17076v1 [cs.CV])",
    "abstract": "We present DiffCollage, a compositional diffusion model that can generate large content by leveraging diffusion models trained on generating pieces of the large content. Our approach is based on a factor graph representation where each factor node represents a portion of the content and a variable node represents their overlap. This representation allows us to aggregate intermediate outputs from diffusion models defined on individual nodes to generate content of arbitrary size and shape in parallel without resorting to an autoregressive generation procedure. We apply DiffCollage to various tasks, including infinite image generation, panorama image generation, and long-duration text-guided motion generation. Extensive experimental results with a comparison to strong autoregressive baselines verify the effectiveness of our approach.",
    "link": "http://arxiv.org/abs/2303.17076",
    "context": "Title: DiffCollage: Parallel Generation of Large Content with Diffusion Models. (arXiv:2303.17076v1 [cs.CV])\nAbstract: We present DiffCollage, a compositional diffusion model that can generate large content by leveraging diffusion models trained on generating pieces of the large content. Our approach is based on a factor graph representation where each factor node represents a portion of the content and a variable node represents their overlap. This representation allows us to aggregate intermediate outputs from diffusion models defined on individual nodes to generate content of arbitrary size and shape in parallel without resorting to an autoregressive generation procedure. We apply DiffCollage to various tasks, including infinite image generation, panorama image generation, and long-duration text-guided motion generation. Extensive experimental results with a comparison to strong autoregressive baselines verify the effectiveness of our approach.",
    "path": "papers/23/03/2303.17076.json",
    "total_tokens": 751,
    "translated_title": "DiffCollage: 基于扩散模型的大尺寸内容并行生成",
    "translated_abstract": "我们提出了DiffCollage，一种组合扩散模型，可以利用已训练在生成大内容片段上的扩散模型来生成大尺寸内容。我们的方法基于因子图表示，其中每个因子节点表示内容的一部分，变量节点表示它们的重叠。该表示允许我们聚合在各个节点上定义的扩散模型的中间输出，以并行生成任意尺寸和形状的内容，而无需使用自回归生成过程。我们将DiffCollage应用于各种任务，包括无限图像生成，全景图像生成和长时间文本引导运动生成。与强自回归基线的比较的广泛实验结果验证了我们方法的有效性。",
    "tldr": "DiffCollage是一种组合扩散模型，可以并行生成任意尺寸和形状的内容，应用于无限图像生成，全景图像生成和长时间文本引导运动生成等任务。",
    "en_tdlr": "DiffCollage is a compositional diffusion model that can generate large content in parallel, which is effectively applied in various tasks, such as infinite image generation, panorama image generation, and long-duration text-guided motion generation, without using an autoregressive generation procedure."
}