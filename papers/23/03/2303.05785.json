{
    "title": "Scaling Up 3D Kernels with Bayesian Frequency Re-parameterization for Medical Image Segmentation. (arXiv:2303.05785v2 [eess.IV] UPDATED)",
    "abstract": "With the inspiration of vision transformers, the concept of depth-wise convolution revisits to provide a large Effective Receptive Field (ERF) using Large Kernel (LK) sizes for medical image segmentation. However, the segmentation performance might be saturated and even degraded as the kernel sizes scaled up (e.g., $21\\times 21\\times 21$) in a Convolutional Neural Network (CNN). We hypothesize that convolution with LK sizes is limited to maintain an optimal convergence for locality learning. While Structural Re-parameterization (SR) enhances the local convergence with small kernels in parallel, optimal small kernel branches may hinder the computational efficiency for training. In this work, we propose RepUX-Net, a pure CNN architecture with a simple large kernel block design, which competes favorably with current network state-of-the-art (SOTA) (e.g., 3D UX-Net, SwinUNETR) using 6 challenging public datasets. We derive an equivalency between kernel re-parameterization and the branch-wi",
    "link": "http://arxiv.org/abs/2303.05785",
    "context": "Title: Scaling Up 3D Kernels with Bayesian Frequency Re-parameterization for Medical Image Segmentation. (arXiv:2303.05785v2 [eess.IV] UPDATED)\nAbstract: With the inspiration of vision transformers, the concept of depth-wise convolution revisits to provide a large Effective Receptive Field (ERF) using Large Kernel (LK) sizes for medical image segmentation. However, the segmentation performance might be saturated and even degraded as the kernel sizes scaled up (e.g., $21\\times 21\\times 21$) in a Convolutional Neural Network (CNN). We hypothesize that convolution with LK sizes is limited to maintain an optimal convergence for locality learning. While Structural Re-parameterization (SR) enhances the local convergence with small kernels in parallel, optimal small kernel branches may hinder the computational efficiency for training. In this work, we propose RepUX-Net, a pure CNN architecture with a simple large kernel block design, which competes favorably with current network state-of-the-art (SOTA) (e.g., 3D UX-Net, SwinUNETR) using 6 challenging public datasets. We derive an equivalency between kernel re-parameterization and the branch-wi",
    "path": "papers/23/03/2303.05785.json",
    "total_tokens": 933,
    "translated_title": "基于贝叶斯频率重参数化的医学图像分割三维卷积核扩展",
    "translated_abstract": "本文灵感源自视觉变换器，重新回归深度卷积概念，提出使用大内核尺寸来提供大有效感受野（ERF）来进行医学图像分割。然而，在卷积神经网络中使用$21\\times21\\times21$等大内核尺寸时，分割性能可能会饱和甚至下降。我们假设，使用大内核尺寸的卷积受限于维护局部学习的最优收敛性。而结构重参数化（SR）通过使用小内核并行增强了局部收敛性，但是优化的小内核分支可能会阻碍训练的计算效率。在本文中，我们提出了RepUX-Net，这是一个纯卷积神经网络体系结构，具有简单的大内核块设计，使用6个具有挑战性的公共数据集比拼了当前网络的最新技术（例如3D UX-Net，SwinUNETR）。我们推导出内核重参数化和支路长度等效的关系。",
    "tldr": "本文提出了一种名为RepUX-Net的纯卷积神经网络体系结构，具有简单的大内核块设计，在医学图像分割中具有十分优越的性能。",
    "en_tdlr": "This paper proposes a pure CNN architecture named RepUX-Net with a simple large kernel block design for medical image segmentation, which competes favorably with current network state-of-the-art using 6 challenging public datasets."
}