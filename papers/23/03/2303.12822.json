{
    "title": "Co-Speech Gesture Synthesis using Discrete Gesture Token Learning. (arXiv:2303.12822v1 [cs.CV])",
    "abstract": "Synthesizing realistic co-speech gestures is an important and yet unsolved problem for creating believable motions that can drive a humanoid robot to interact and communicate with human users. Such capability will improve the impressions of the robots by human users and will find applications in education, training, and medical services. One challenge in learning the co-speech gesture model is that there may be multiple viable gesture motions for the same speech utterance. The deterministic regression methods can not resolve the conflicting samples and may produce over-smoothed or damped motions. We proposed a two-stage model to address this uncertainty issue in gesture synthesis by modeling the gesture segments as discrete latent codes. Our method utilizes RQ-VAE in the first stage to learn a discrete codebook consisting of gesture tokens from training data. In the second stage, a two-level autoregressive transformer model is used to learn the prior distribution of residual codes cond",
    "link": "http://arxiv.org/abs/2303.12822",
    "context": "Title: Co-Speech Gesture Synthesis using Discrete Gesture Token Learning. (arXiv:2303.12822v1 [cs.CV])\nAbstract: Synthesizing realistic co-speech gestures is an important and yet unsolved problem for creating believable motions that can drive a humanoid robot to interact and communicate with human users. Such capability will improve the impressions of the robots by human users and will find applications in education, training, and medical services. One challenge in learning the co-speech gesture model is that there may be multiple viable gesture motions for the same speech utterance. The deterministic regression methods can not resolve the conflicting samples and may produce over-smoothed or damped motions. We proposed a two-stage model to address this uncertainty issue in gesture synthesis by modeling the gesture segments as discrete latent codes. Our method utilizes RQ-VAE in the first stage to learn a discrete codebook consisting of gesture tokens from training data. In the second stage, a two-level autoregressive transformer model is used to learn the prior distribution of residual codes cond",
    "path": "papers/23/03/2303.12822.json",
    "total_tokens": 989,
    "translated_title": "利用离散手势令牌学习的共性语言手势合成",
    "translated_abstract": "制作逼真的共性语言手势是一个重要且尚未解决的问题，可以用于驱动人形机器人与人类用户进行交互和沟通。这种能力将改善人类用户对机器人的印象，并在教育、培训和医疗服务中找到应用。学习共性语言手势模型的一个挑战是，对于同一语音话语，可能存在多个合理的手势运动。确定性回归方法无法解决冲突样本，并可能产生过度平滑或抑制的运动。我们提出了一个两阶段模型，通过将手势片段建模为离散的潜在编码来解决这个不确定性问题，我们的方法利用RQ-VAE在第一阶段从训练数据中学习由手势令牌组成的离散码本，第二阶段使用两级自回归变压器模型学习残余码的先验分布，以及给出语音时手势令牌的条件分布。在大型数据集上的实验证明，所提出的方法可以生成多样化和逼真的共性语言手势。",
    "tldr": "该论文提出了一个两阶段的机制，使用离散的编码方式来解决合成共性语言手势中的不确定性问题，采用VAE和自回归变压器模型进行学习，能够生成多样化和逼真的共性语言手势。",
    "en_tdlr": "This paper proposes a two-stage mechanism for synthesizing co-speech gestures, using discrete coding to solve the uncertainty in gesture synthesis, and learning with VAE and autoregressive Transformer models, which can generate diverse and realistic co-speech gestures."
}