{
    "title": "Comparing Trajectory and Vision Modalities for Verb Representation. (arXiv:2303.12737v1 [cs.CV])",
    "abstract": "Three-dimensional trajectories, or the 3D position and rotation of objects over time, have been shown to encode key aspects of verb semantics (e.g., the meanings of roll vs. slide). However, most multimodal models in NLP use 2D images as representations of the world. Given the importance of 3D space in formal models of verb semantics, we expect that these 2D images would result in impoverished representations that fail to capture nuanced differences in meaning. This paper tests this hypothesis directly in controlled experiments. We train self-supervised image and trajectory encoders, and then evaluate them on the extent to which each learns to differentiate verb concepts. Contrary to our initial expectations, we find that 2D visual modalities perform similarly well to 3D trajectories. While further work should be conducted on this question, our initial findings challenge the conventional wisdom that richer environment representations necessarily translate into better representation lea",
    "link": "http://arxiv.org/abs/2303.12737",
    "context": "Title: Comparing Trajectory and Vision Modalities for Verb Representation. (arXiv:2303.12737v1 [cs.CV])\nAbstract: Three-dimensional trajectories, or the 3D position and rotation of objects over time, have been shown to encode key aspects of verb semantics (e.g., the meanings of roll vs. slide). However, most multimodal models in NLP use 2D images as representations of the world. Given the importance of 3D space in formal models of verb semantics, we expect that these 2D images would result in impoverished representations that fail to capture nuanced differences in meaning. This paper tests this hypothesis directly in controlled experiments. We train self-supervised image and trajectory encoders, and then evaluate them on the extent to which each learns to differentiate verb concepts. Contrary to our initial expectations, we find that 2D visual modalities perform similarly well to 3D trajectories. While further work should be conducted on this question, our initial findings challenge the conventional wisdom that richer environment representations necessarily translate into better representation lea",
    "path": "papers/23/03/2303.12737.json",
    "total_tokens": 893,
    "translated_title": "比较轨迹和视觉模态对动词表示的影响",
    "translated_abstract": "三维轨迹，即物体随时间的3D位置和旋转，被证明可以编码动词语义的关键方面（例如，roll和slide的含义）。然而，大多数NLP中的多模态模型使用2D图像作为世界的表示。考虑到3D空间在动词语义的形式模型中的重要性，我们预期这些2D图像会导致贫瘠的表示，无法捕捉到微妙的差异。本文在受控实验中直接测试了这个假设。我们训练了自监督的图像和轨迹编码器，然后评估它们学习区分动词概念的程度。与我们最初的预期相反，我们发现2D视觉模态的表现与3D轨迹类似。虽然还需要进一步研究这个问题，但我们的初步发现挑战了传统的智慧：更丰富的环境表示必然会导致更好的表示学习。",
    "tldr": "本文测试了使用2D图像和3D轨迹对动词语义表示的影响，发现2D视觉模态的表现与3D轨迹类似，挑战了传统的智慧。",
    "en_tdlr": "This paper tests the effect of using 2D images and 3D trajectories on verb semantics representation and challenges the conventional wisdom that richer environment representations translate into better representation learning. The results indicate that 2D visual modalities perform similarly well to 3D trajectories."
}