{
    "title": "Can Large Language Models assist in Hazard Analysis?. (arXiv:2303.15473v1 [cs.HC])",
    "abstract": "Large Language Models (LLMs), such as GPT-3, have demonstrated remarkable natural language processing and generation capabilities and have been applied to a variety tasks, such as source code generation. This paper explores the potential of integrating LLMs in the hazard analysis for safety-critical systems, a process which we refer to as co-hazard analysis (CoHA). In CoHA, a human analyst interacts with an LLM via a context-aware chat session and uses the responses to support elicitation of possible hazard causes. In this experiment, we explore CoHA with three increasingly complex versions of a simple system, using Open AI's ChatGPT service. The quality of ChatGPT's responses were systematically assessed to determine the feasibility of CoHA given the current state of LLM technology. The results suggest that LLMs may be useful for supporting human analysts performing hazard analysis.",
    "link": "http://arxiv.org/abs/2303.15473",
    "context": "Title: Can Large Language Models assist in Hazard Analysis?. (arXiv:2303.15473v1 [cs.HC])\nAbstract: Large Language Models (LLMs), such as GPT-3, have demonstrated remarkable natural language processing and generation capabilities and have been applied to a variety tasks, such as source code generation. This paper explores the potential of integrating LLMs in the hazard analysis for safety-critical systems, a process which we refer to as co-hazard analysis (CoHA). In CoHA, a human analyst interacts with an LLM via a context-aware chat session and uses the responses to support elicitation of possible hazard causes. In this experiment, we explore CoHA with three increasingly complex versions of a simple system, using Open AI's ChatGPT service. The quality of ChatGPT's responses were systematically assessed to determine the feasibility of CoHA given the current state of LLM technology. The results suggest that LLMs may be useful for supporting human analysts performing hazard analysis.",
    "path": "papers/23/03/2303.15473.json",
    "total_tokens": 816,
    "translated_title": "大规模语言模型能协助危害分析吗？",
    "translated_abstract": "大规模语言模型（LLMs），如GPT-3，展示了卓越的自然语言处理和生成能力，并已应用于各种任务，例如源代码生成。本文探讨了将LLMs集成到安全关键系统的危害分析中的潜力，这个过程被我们称为协同危害分析（CoHA）。",
    "tldr": "本文探讨了在安全关键系统的危害分析中应用大规模语言模型的潜力，结果表明LLMs可能有助于支持分析师进行危害分析。",
    "en_tdlr": "This paper explores the potential of using large language models (LLMs) in hazard analysis for safety-critical systems, and suggests that LLMs may be useful for supporting human analysts performing hazard analysis."
}