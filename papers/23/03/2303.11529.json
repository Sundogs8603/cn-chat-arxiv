{
    "title": "Counterfactually Fair Regression with Double Machine Learning. (arXiv:2303.11529v1 [cs.LG])",
    "abstract": "Counterfactual fairness is an approach to AI fairness that tries to make decisions based on the outcomes that an individual with some kind of sensitive status would have had without this status. This paper proposes Double Machine Learning (DML) Fairness which analogises this problem of counterfactual fairness in regression problems to that of estimating counterfactual outcomes in causal inference under the Potential Outcomes framework. It uses arbitrary machine learning methods to partial out the effect of sensitive variables on nonsensitive variables and outcomes. Assuming that the effects of the two sets of variables are additively separable, outcomes will be approximately equalised and individual-level outcomes will be counterfactually fair. This paper demonstrates the approach in a simulation study pertaining to discrimination in workplace hiring and an application on real data estimating the GPAs of law school students. It then discusses when it is appropriate to apply such a meth",
    "link": "http://arxiv.org/abs/2303.11529",
    "context": "Title: Counterfactually Fair Regression with Double Machine Learning. (arXiv:2303.11529v1 [cs.LG])\nAbstract: Counterfactual fairness is an approach to AI fairness that tries to make decisions based on the outcomes that an individual with some kind of sensitive status would have had without this status. This paper proposes Double Machine Learning (DML) Fairness which analogises this problem of counterfactual fairness in regression problems to that of estimating counterfactual outcomes in causal inference under the Potential Outcomes framework. It uses arbitrary machine learning methods to partial out the effect of sensitive variables on nonsensitive variables and outcomes. Assuming that the effects of the two sets of variables are additively separable, outcomes will be approximately equalised and individual-level outcomes will be counterfactually fair. This paper demonstrates the approach in a simulation study pertaining to discrimination in workplace hiring and an application on real data estimating the GPAs of law school students. It then discusses when it is appropriate to apply such a meth",
    "path": "papers/23/03/2303.11529.json",
    "total_tokens": 865,
    "translated_title": "双机器学习在对抗事实公平回归中的应用",
    "translated_abstract": "对抗事实公平是AI公平的一种方法，尝试基于某种敏感状态下的个人结果，排除这种状态对结果造成的影响。本文提出了双机器学习公平性，将此回归问题的对抗事实公平性类比到在潜在结果框架下估计因果推断中的对抗事实结果。它使用任意机器学习方法来分析敏感变量对非敏感变量和结果的影响。假设两组变量的影响是可加的并且相互独立的，结果将近似平等，个人级别的结果将是对抗事实公平的。本文通过模拟研究来演示了这种方法，研究涉及职场招聘中的歧视问题和对法学院学生GPA的实际数据应用。然后讨论了何时适用这种方法。",
    "tldr": "本文提出了一种双机器学习公平性方法，用于回归问题中的对抗事实公平，假设两组变量的影响是可加的并且相互独立的，结果将近似平等，个人级别的结果将是对抗事实公平的。",
    "en_tdlr": "This paper proposes a Double Machine Learning (DML) Fairness approach for counterfactually fair regression problems, assuming additively separable effects of sensitive variables on outcomes, resulting in approximately equalised outcomes and counterfactually fair individual-level outcomes."
}