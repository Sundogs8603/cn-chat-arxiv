{
    "title": "Lay Text Summarisation Using Natural Language Processing: A Narrative Literature Review. (arXiv:2303.14222v1 [cs.CL])",
    "abstract": "Summarisation of research results in plain language is crucial for promoting public understanding of research findings. The use of Natural Language Processing to generate lay summaries has the potential to relieve researchers' workload and bridge the gap between science and society. The aim of this narrative literature review is to describe and compare the different text summarisation approaches used to generate lay summaries. We searched the databases Web of Science, Google Scholar, IEEE Xplore, Association for Computing Machinery Digital Library and arXiv for articles published until 6 May 2022. We included original studies on automatic text summarisation methods to generate lay summaries. We screened 82 articles and included eight relevant papers published between 2020 and 2021, all using the same dataset. The results show that transformer-based methods such as Bidirectional Encoder Representations from Transformers (BERT) and Pre-training with Extracted Gap-sentences for Abstractiv",
    "link": "http://arxiv.org/abs/2303.14222",
    "context": "Title: Lay Text Summarisation Using Natural Language Processing: A Narrative Literature Review. (arXiv:2303.14222v1 [cs.CL])\nAbstract: Summarisation of research results in plain language is crucial for promoting public understanding of research findings. The use of Natural Language Processing to generate lay summaries has the potential to relieve researchers' workload and bridge the gap between science and society. The aim of this narrative literature review is to describe and compare the different text summarisation approaches used to generate lay summaries. We searched the databases Web of Science, Google Scholar, IEEE Xplore, Association for Computing Machinery Digital Library and arXiv for articles published until 6 May 2022. We included original studies on automatic text summarisation methods to generate lay summaries. We screened 82 articles and included eight relevant papers published between 2020 and 2021, all using the same dataset. The results show that transformer-based methods such as Bidirectional Encoder Representations from Transformers (BERT) and Pre-training with Extracted Gap-sentences for Abstractiv",
    "path": "papers/23/03/2303.14222.json",
    "total_tokens": 932,
    "translated_title": "自然语言处理在非专业人士文本摘要中的应用：一篇叙述性文献综述",
    "translated_abstract": "以平民易懂的语言总结研究结果对于促进公众了解研究成果至关重要。利用自然语言处理生成简化版摘要有望缓解研究人员的工作负担，弥合科学与社会之间的差距。这篇叙述性文献综述的目的是描述和比较不同的文本摘要方法，以生成平民易懂的摘要。我们在Web of Science，Google Scholar，IEEE Xplore，Association for Computing Machinery Digital Library 和 arXiv 等数据库中搜索了2022年5月6日以前发表的文章。我们包括了关于用于生成平民易懂的摘要的自动文本摘要方法的原始研究。我们筛选了82篇文章，并包括了在2020年至2021年期间发布的8篇相关论文，全部使用相同的数据集。结果表明，基于转换器的方法（如最近流行的Bidirectional Encoder Representations from Transformers（BERT）和使用抽取间隔句进行预训练的模型）是最有效的生成平民易懂的摘要的方法。",
    "tldr": "本综述总结了使用自然语言处理生成平民易懂摘要的不同方法，并发现基于转换器的方法最有效，为缓解研究人员负担和促进社会与科学交流提供了帮助。",
    "en_tdlr": "This literature review describes and compares various methods for generating lay summaries using natural language processing and finds that transformer-based methods such as BERT are the most effective, providing assistance in relieving the workload of researchers and promoting communication between science and society."
}