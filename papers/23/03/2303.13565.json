{
    "title": "Graph Tensor Networks: An Intuitive Framework for Designing Large-Scale Neural Learning Systems on Multiple Domains. (arXiv:2303.13565v1 [cs.LG])",
    "abstract": "Despite the omnipresence of tensors and tensor operations in modern deep learning, the use of tensor mathematics to formally design and describe neural networks is still under-explored within the deep learning community. To this end, we introduce the Graph Tensor Network (GTN) framework, an intuitive yet rigorous graphical framework for systematically designing and implementing large-scale neural learning systems on both regular and irregular domains. The proposed framework is shown to be general enough to include many popular architectures as special cases, and flexible enough to handle data on any and many data domains. The power and flexibility of the proposed framework is demonstrated through real-data experiments, resulting in improved performance at a drastically lower complexity costs, by virtue of tensor algebra.",
    "link": "http://arxiv.org/abs/2303.13565",
    "context": "Title: Graph Tensor Networks: An Intuitive Framework for Designing Large-Scale Neural Learning Systems on Multiple Domains. (arXiv:2303.13565v1 [cs.LG])\nAbstract: Despite the omnipresence of tensors and tensor operations in modern deep learning, the use of tensor mathematics to formally design and describe neural networks is still under-explored within the deep learning community. To this end, we introduce the Graph Tensor Network (GTN) framework, an intuitive yet rigorous graphical framework for systematically designing and implementing large-scale neural learning systems on both regular and irregular domains. The proposed framework is shown to be general enough to include many popular architectures as special cases, and flexible enough to handle data on any and many data domains. The power and flexibility of the proposed framework is demonstrated through real-data experiments, resulting in improved performance at a drastically lower complexity costs, by virtue of tensor algebra.",
    "path": "papers/23/03/2303.13565.json",
    "total_tokens": 913,
    "translated_title": "图张量网络：在多个领域上设计大规模神经学习系统的直观框架",
    "translated_abstract": "尽管张量及其运算在现代深度学习中普遍存在，但在深度学习社区内，使用张量数学来形式化设计和描述神经网络仍未被充分探索。因此，我们引入了图张量网络（GTN）框架，这是一个直观而严谨的图形化框架，用于系统地设计和实现在规则和不规则领域上的大规模神经学习系统。所提出的框架被证明足够通用，可以包括许多流行的体系结构作为特殊情况，并且足够灵活，可处理任何和许多数据域上的数据。该框架的强大和灵活性通过真实数据实验得到证明，通过张量代数的优点，结果在极低的复杂度成本下实现了改进的性能。",
    "tldr": "张量数学已经被广泛用于现代深度学习，但在形式化设计和描述神经网络上，还未被充分利用。本文引入了图张量网络（GTN）框架，提供了一个直观而严谨的图形化框架，用于在规则和不规则领域上的大规模神经学习系统上系统地设计和实现，且通用性和灵活性很强。",
    "en_tdlr": "Despite the widespread use of tensors in modern deep learning, the formal use of tensor mathematics to design and describe neural networks has not been fully exploited. This paper introduces the Graph Tensor Network (GTN) framework, providing an intuitive and rigorous graphical framework for systematically designing and implementing large-scale neural learning systems on regular and irregular domains, with strong generality and flexibility."
}