{
    "title": "Style Feature Extraction Using Contrastive Conditioned Variational Autoencoders with Mutual Information Constraints. (arXiv:2303.08068v1 [cs.CV])",
    "abstract": "It is crucial to extract fine-grained features such as styles from unlabeled data in data analysis. Unsupervised methods, such as variational autoencoders (VAEs), can extract styles, but the extracted styles are usually mixed with other features. We can isolate the styles using VAEs conditioned by class labels, known as conditional VAEs (CVAEs). However, methods to extract only styles using unlabeled data are not established. In this paper, we construct a CVAE-based method that extracts style features using only unlabeled data. The proposed model roughly consists of two parallel parts; a contrastive learning (CL) part that extracts style-independent features and a CVAE part that extracts style features. CL models generally learn representations independent of data augmentation, which can be seen as a perturbation in styles, in a self-supervised way. Taking the style-independent features as a condition, the CVAE learns to extract only styles. In the training procedure, a CL model is tra",
    "link": "http://arxiv.org/abs/2303.08068",
    "context": "Title: Style Feature Extraction Using Contrastive Conditioned Variational Autoencoders with Mutual Information Constraints. (arXiv:2303.08068v1 [cs.CV])\nAbstract: It is crucial to extract fine-grained features such as styles from unlabeled data in data analysis. Unsupervised methods, such as variational autoencoders (VAEs), can extract styles, but the extracted styles are usually mixed with other features. We can isolate the styles using VAEs conditioned by class labels, known as conditional VAEs (CVAEs). However, methods to extract only styles using unlabeled data are not established. In this paper, we construct a CVAE-based method that extracts style features using only unlabeled data. The proposed model roughly consists of two parallel parts; a contrastive learning (CL) part that extracts style-independent features and a CVAE part that extracts style features. CL models generally learn representations independent of data augmentation, which can be seen as a perturbation in styles, in a self-supervised way. Taking the style-independent features as a condition, the CVAE learns to extract only styles. In the training procedure, a CL model is tra",
    "path": "papers/23/03/2303.08068.json",
    "total_tokens": 1060,
    "translated_title": "使用互信息约束下的对比条件变分自编码器进行风格特征提取",
    "translated_abstract": "在数据分析中，从未标记的数据中提取细粒度特征（如风格）非常重要。无监督方法（如变分自编码器（VAEs））可以提取风格，但提取的风格通常与其他特征混合。我们可以使用分类标签来指导VAEs提取风格，即条件VAEs（CVAEs）。但是，使用未标记数据仅提取风格的方法尚未建立。在本文中，我们构建了一种基于CVAE的方法，使用仅未标记的数据来提取风格特征。所提出的模型大致由两个并行部分组成; 提取风格无关特征的对比学习（CL）部分，以及提取风格特征的CVAE部分。CL模型通常以无需数据扩充的自监督方式学习与样式无关的表示，可以视为样式中的扰动。以提取的风格无关特征为条件，CVAE学习仅提取风格。在训练过程中，先训练CL模型，然后使用训练过的CL模型指导CVAE的训练。在几个数据集上评估了所提出的方法，实验结果表明所提出的方法可以有效地从未标记的数据中提取风格特征。",
    "tldr": "本文提出了一种使用互信息约束下的对比条件变分自编码器进行从未标记数据中提取风格特征的方法，该方法由一个提取风格无关特征的对比学习部分和一个提取风格特征的CVAE部分组成。",
    "en_tdlr": "This paper proposes a method for extracting style features from unlabeled data using contrastive conditioned variational autoencoders with mutual information constraints, which consists of a contrastive learning part and a CVAE part that extract style-independent features and style features respectively."
}