{
    "title": "Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference. (arXiv:2303.04673v2 [cs.CL] UPDATED)",
    "abstract": "Large Language Models (LLMs) have sparked significant interest in their generative capabilities, leading to the development of various commercial applications. The high cost of using the models drives application builders to maximize the value of generation under a limited inference budget. This paper presents a study of optimizing inference hyperparameters such as the number of responses, temperature and max tokens, which significantly affects the utility/cost of text generation. We design a framework named EcoOptiGen which leverages economical hyperparameter optimization and cost-based pruning. Experiments with the GPT-3.5/GPT-4 models on a variety of tasks verify its effectiveness. EcoOptiGen is implemented in the `autogen' package of the FLAML library: \\url{https://aka.ms/autogen}.",
    "link": "http://arxiv.org/abs/2303.04673",
    "context": "Title: Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference. (arXiv:2303.04673v2 [cs.CL] UPDATED)\nAbstract: Large Language Models (LLMs) have sparked significant interest in their generative capabilities, leading to the development of various commercial applications. The high cost of using the models drives application builders to maximize the value of generation under a limited inference budget. This paper presents a study of optimizing inference hyperparameters such as the number of responses, temperature and max tokens, which significantly affects the utility/cost of text generation. We design a framework named EcoOptiGen which leverages economical hyperparameter optimization and cost-based pruning. Experiments with the GPT-3.5/GPT-4 models on a variety of tasks verify its effectiveness. EcoOptiGen is implemented in the `autogen' package of the FLAML library: \\url{https://aka.ms/autogen}.",
    "path": "papers/23/03/2303.04673.json",
    "total_tokens": 818,
    "translated_title": "大规模语言模型生成推理的成本效益超参数优化",
    "translated_abstract": "大规模语言模型（LLM）在其生成能力方面引起了广泛关注，从而推动了各种商业应用的发展。使用这些模型的高成本驱使应用程序构建者在有限的推理预算下最大化生成价值。本文提出了一项关于优化推理超参数（如回复数量、温度和最大token数）的研究，这显著影响了文本生成的效用/成本。我们设计了一个名为EcoOptiGen的框架，它利用经济的超参数优化和基于成本的修剪。通过在各种任务上使用GPT-3.5/GPT-4模型进行实验，验证了其有效性。EcoOptiGen已在FLAML库的`autogen'包中实现：\\url{https://aka.ms/autogen}。",
    "tldr": "本文研究了优化大规模语言模型生成推理的成本效益超参数，通过经济的超参数优化和基于成本的修剪，提出了EcoOptiGen框架，该框架在使用GPT-3.5/GPT-4模型的任务中表现出有效性。",
    "en_tdlr": "This paper investigates the cost-effective hyperparameter optimization for large language model generation inference. By leveraging economical hyperparameter optimization and cost-based pruning, the EcoOptiGen framework demonstrates its effectiveness in tasks using GPT-3.5/GPT-4 models."
}