{
    "title": "A Theory of Emergent In-Context Learning as Implicit Structure Induction. (arXiv:2303.07971v1 [cs.CL])",
    "abstract": "Scaling large language models (LLMs) leads to an emergent capacity to learn in-context from example demonstrations. Despite progress, theoretical understanding of this phenomenon remains limited. We argue that in-context learning relies on recombination of compositional operations found in natural language data. We derive an information-theoretic bound showing how in-context learning abilities arise from generic next-token prediction when the pretraining distribution has sufficient amounts of compositional structure, under linguistically motivated assumptions. A second bound provides a theoretical justification for the empirical success of prompting LLMs to output intermediate steps towards an answer. To validate theoretical predictions, we introduce a controlled setup for inducing in-context learning; unlike previous approaches, it accounts for the compositional nature of language. Trained transformers can perform in-context learning for a range of tasks, in a manner consistent with t",
    "link": "http://arxiv.org/abs/2303.07971",
    "context": "Title: A Theory of Emergent In-Context Learning as Implicit Structure Induction. (arXiv:2303.07971v1 [cs.CL])\nAbstract: Scaling large language models (LLMs) leads to an emergent capacity to learn in-context from example demonstrations. Despite progress, theoretical understanding of this phenomenon remains limited. We argue that in-context learning relies on recombination of compositional operations found in natural language data. We derive an information-theoretic bound showing how in-context learning abilities arise from generic next-token prediction when the pretraining distribution has sufficient amounts of compositional structure, under linguistically motivated assumptions. A second bound provides a theoretical justification for the empirical success of prompting LLMs to output intermediate steps towards an answer. To validate theoretical predictions, we introduce a controlled setup for inducing in-context learning; unlike previous approaches, it accounts for the compositional nature of language. Trained transformers can perform in-context learning for a range of tasks, in a manner consistent with t",
    "path": "papers/23/03/2303.07971.json",
    "total_tokens": 977,
    "translated_title": "一种关于隐含结构归纳的上下文中涌现学习理论",
    "translated_abstract": "大规模语言模型的扩展引发了涌现式上下文学习的能力，即基于示例演示进行学习。尽管取得了一些进展，但对这种现象的理论理解仍然有限。我们认为，上下文学习依赖于自然语言数据中发现的组合性操作的重新组合。在基于语言学假设的情况下，我们推导出了一种信息理论界限，展示了当预训练分布具有足够的组成结构时，如何从一般的下一个标记预测中获得上下文学习能力。第二个界限为提示LLM输出朝着答案的中间步骤的实证成功提供了理论基础。为了验证理论预测，我们引入了一个受控制的设置来诱导上下文学习。与以往方法不同，它考虑到语言的组合本质。经过训练的Transformer可以为一系列任务执行上下文学习，这与在自然语言数据上预训练的 Transformer 保持一致。",
    "tldr": "本文推导了一个信息理论界限，展示了在自然语言数据具有足够的组成结构的情况下，从一般的下一个标记预测中获得上下文学习能力。为验证理论预测，本文引入了一个受控制的设置来诱导上下文学习，证明了经过训练的Transformer可以为一系列任务执行上下文学习。",
    "en_tdlr": "This paper derives an information-theoretic bound showing how in-context learning abilities arise from generic next-token prediction when the pretraining distribution has sufficient amounts of compositional structure. To validate theoretical predictions, a controlled setup is introduced for inducing in-context learning, and it is shown that trained transformers can perform in-context learning for a range of tasks."
}