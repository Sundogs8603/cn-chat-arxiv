{
    "title": "Allegro-Legato: Scalable, Fast, and Robust Neural-Network Quantum Molecular Dynamics via Sharpness-Aware Minimization. (arXiv:2303.08169v1 [cs.DC])",
    "abstract": "Neural-network quantum molecular dynamics (NNQMD) simulations based on machine learning are revolutionizing atomistic simulations of materials by providing quantum-mechanical accuracy but orders-of-magnitude faster, illustrated by ACM Gordon Bell prize (2020) and finalist (2021). State-of-the-art (SOTA) NNQMD model founded on group theory featuring rotational equivariance and local descriptors has provided much higher accuracy and speed than those models, thus named Allegro (meaning fast). On massively parallel supercomputers, however, it suffers a fidelity-scaling problem, where growing number of unphysical predictions of interatomic forces prohibits simulations involving larger numbers of atoms for longer times. Here, we solve this problem by combining the Allegro model with sharpness aware minimization (SAM) for enhancing the robustness of model through improved smoothness of the loss landscape. The resulting Allegro-Legato (meaning fast and \"smooth\") model was shown to elongate the",
    "link": "http://arxiv.org/abs/2303.08169",
    "context": "Title: Allegro-Legato: Scalable, Fast, and Robust Neural-Network Quantum Molecular Dynamics via Sharpness-Aware Minimization. (arXiv:2303.08169v1 [cs.DC])\nAbstract: Neural-network quantum molecular dynamics (NNQMD) simulations based on machine learning are revolutionizing atomistic simulations of materials by providing quantum-mechanical accuracy but orders-of-magnitude faster, illustrated by ACM Gordon Bell prize (2020) and finalist (2021). State-of-the-art (SOTA) NNQMD model founded on group theory featuring rotational equivariance and local descriptors has provided much higher accuracy and speed than those models, thus named Allegro (meaning fast). On massively parallel supercomputers, however, it suffers a fidelity-scaling problem, where growing number of unphysical predictions of interatomic forces prohibits simulations involving larger numbers of atoms for longer times. Here, we solve this problem by combining the Allegro model with sharpness aware minimization (SAM) for enhancing the robustness of model through improved smoothness of the loss landscape. The resulting Allegro-Legato (meaning fast and \"smooth\") model was shown to elongate the",
    "path": "papers/23/03/2303.08169.json",
    "total_tokens": 882,
    "translated_title": "Allegro-Legato: 基于 Sharpness-Aware Minimization 的大规模且快速的神经网络量子分子动力学模拟",
    "translated_abstract": "基于机器学习的神经网络量子分子动力学模拟（NNQMD）正在通过提供比传统方法更高的精度和速度来彻底改变材料原子级模拟。当前最先进的NNQMD模型基于群论的旋转等变性特征和局部描述符，称为 Allegro（意为快速），提供了比以前更高的准确度和速度。然而，在高性能超级计算机上，它面临一个精度扩展的问题，即不合理的预测随着原子数和模拟时间的增加而增加。本文通过将 Allegro 模型与 Sharpeness aware minimization（SAM）相结合，提高损失函数表面的平滑性，从而解决了这个问题。产生的 Allegro-Legato 模型展示了更长时间和更多原子数的模拟。",
    "tldr": "Allegro-Legato 是一种基于机器学习的NNQMD模型，使用 Sharpness-Aware Minimization 解决了计算机多核心处理器架构下的精度扩展问题，大大提高了模型的普适性和可靠性。",
    "en_tdlr": "Allegro-Legato is a machine learning based NNQMD model that solves the accuracy scaling problem on massively parallel supercomputers using Sharpness-Aware Minimization, which greatly improves the universality and reliability of the model."
}