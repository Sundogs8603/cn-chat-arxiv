{
    "title": "Measuring the Impact of Explanation Bias: A Study of Natural Language Justifications for Recommender Systems. (arXiv:2303.09498v1 [cs.HC])",
    "abstract": "Despite the potential impact of explanations on decision making, there is a lack of research on quantifying their effect on users' choices. This paper presents an experimental protocol for measuring the degree to which positively or negatively biased explanations can lead to users choosing suboptimal recommendations. Key elements of this protocol include a preference elicitation stage to allow for personalizing recommendations, manual identification and extraction of item aspects from reviews, and a controlled method for introducing bias through the combination of both positive and negative aspects. We study explanations in two different textual formats: as a list of item aspects and as fluent natural language text. Through a user study with 129 participants, we demonstrate that explanations can significantly affect users' selections and that these findings generalize across explanation formats.",
    "link": "http://arxiv.org/abs/2303.09498",
    "context": "Title: Measuring the Impact of Explanation Bias: A Study of Natural Language Justifications for Recommender Systems. (arXiv:2303.09498v1 [cs.HC])\nAbstract: Despite the potential impact of explanations on decision making, there is a lack of research on quantifying their effect on users' choices. This paper presents an experimental protocol for measuring the degree to which positively or negatively biased explanations can lead to users choosing suboptimal recommendations. Key elements of this protocol include a preference elicitation stage to allow for personalizing recommendations, manual identification and extraction of item aspects from reviews, and a controlled method for introducing bias through the combination of both positive and negative aspects. We study explanations in two different textual formats: as a list of item aspects and as fluent natural language text. Through a user study with 129 participants, we demonstrate that explanations can significantly affect users' selections and that these findings generalize across explanation formats.",
    "path": "papers/23/03/2303.09498.json",
    "total_tokens": 808,
    "translated_title": "量化解释偏差的影响：关于推荐系统自然语言解释的研究",
    "translated_abstract": "尽管解释可能对决策产生影响，但缺乏研究来量化其对用户选择的影响。本文提出了一个实验方案，用于测量积极或消极偏见解释可能导致用户选择次优建议的程度。该方案的关键要素包括偏好引导阶段以允许个性化建议、手动识别和提取评论中的项目要素以及通过将积极和消极要素结合而引入偏见的控制方法。我们研究了两种不同的文本格式的解释：作为项目要素列表的形式和作为流畅自然语言文本的形式。通过对129名参与者进行用户研究，我们证明了解释可以显著影响用户的选择，并且这些发现可以推广到解释格式上。",
    "tldr": "本研究提出了一种实验方案，通过积极或消极偏见的自然语言解释来测量解释对用户选择建议的影响，并发现解释可以显著影响用户选择。",
    "en_tdlr": "This paper proposes an experimental protocol to measure the impact of positively or negatively biased natural language explanations on users' choices for recommendations. The study shows that these explanations significantly affect users' selections regardless of their format."
}