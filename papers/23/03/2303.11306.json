{
    "title": "Localizing Object-level Shape Variations with Text-to-Image Diffusion Models. (arXiv:2303.11306v2 [cs.CV] UPDATED)",
    "abstract": "Text-to-image models give rise to workflows which often begin with an exploration step, where users sift through a large collection of generated images. The global nature of the text-to-image generation process prevents users from narrowing their exploration to a particular object in the image. In this paper, we present a technique to generate a collection of images that depicts variations in the shape of a specific object, enabling an object-level shape exploration process. Creating plausible variations is challenging as it requires control over the shape of the generated object while respecting its semantics. A particular challenge when generating object variations is accurately localizing the manipulation applied over the object's shape. We introduce a prompt-mixing technique that switches between prompts along the denoising process to attain a variety of shape choices. To localize the image-space operation, we present two techniques that use the self-attention layers in conjunction",
    "link": "http://arxiv.org/abs/2303.11306",
    "context": "Title: Localizing Object-level Shape Variations with Text-to-Image Diffusion Models. (arXiv:2303.11306v2 [cs.CV] UPDATED)\nAbstract: Text-to-image models give rise to workflows which often begin with an exploration step, where users sift through a large collection of generated images. The global nature of the text-to-image generation process prevents users from narrowing their exploration to a particular object in the image. In this paper, we present a technique to generate a collection of images that depicts variations in the shape of a specific object, enabling an object-level shape exploration process. Creating plausible variations is challenging as it requires control over the shape of the generated object while respecting its semantics. A particular challenge when generating object variations is accurately localizing the manipulation applied over the object's shape. We introduce a prompt-mixing technique that switches between prompts along the denoising process to attain a variety of shape choices. To localize the image-space operation, we present two techniques that use the self-attention layers in conjunction",
    "path": "papers/23/03/2303.11306.json",
    "total_tokens": 904,
    "translated_title": "使用文本到图像扩散模型定位对象水平的形状变化",
    "translated_abstract": "文本到图像模型引出的工作流通常从一个探索步骤开始，用户在其中浏览大量生成的图像。文本到图像生成过程的全局性质使得用户无法将探索范围限定在图像中的特定对象上。本文提出了一种技术，用于生成一系列展示特定对象形状变化的图像，从而支持对象级形状探索过程。生成可信的变化是具有挑战性的，因为它要求在保持对象语义的同时对生成对象的形状进行控制。在生成对象变化时，一个特别的挑战是准确定位应用于对象形状的操作。我们引入了一种提示混合技术，在去噪过程中切换提示以获得多样的形状选择。为了定位图像空间操作，我们提出了两种使用自注意力层的技术，与注入异常的图像进行编码以捕捉形状变化的细节。",
    "tldr": "本文介绍了一种利用文本到图像扩散模型，能够生成变化形状的图像集合，从而支持对象级形状探索过程的技术。通过引入提示混合技术和使用自注意力层的方法，实现了可控制的形状变化并准确定位图像空间操作。",
    "en_tdlr": "This paper presents a technique using text-to-image diffusion models to generate a collection of shape-varied images, enabling object-level shape exploration process. By introducing prompt-mixing technique and utilizing self-attention layers, it achieves controlled shape variations and accurate localization of image-space operations."
}