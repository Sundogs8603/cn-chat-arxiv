{
    "title": "Policy Reuse for Communication Load Balancing in Unseen Traffic Scenarios. (arXiv:2303.16685v1 [cs.NI])",
    "abstract": "With the continuous growth in communication network complexity and traffic volume, communication load balancing solutions are receiving increasing attention. Specifically, reinforcement learning (RL)-based methods have shown impressive performance compared with traditional rule-based methods. However, standard RL methods generally require an enormous amount of data to train, and generalize poorly to scenarios that are not encountered during training. We propose a policy reuse framework in which a policy selector chooses the most suitable pre-trained RL policy to execute based on the current traffic condition. Our method hinges on a policy bank composed of policies trained on a diverse set of traffic scenarios. When deploying to an unknown traffic scenario, we select a policy from the policy bank based on the similarity between the previous-day traffic of the current scenario and the traffic observed during training. Experiments demonstrate that this framework can outperform classical a",
    "link": "http://arxiv.org/abs/2303.16685",
    "context": "Title: Policy Reuse for Communication Load Balancing in Unseen Traffic Scenarios. (arXiv:2303.16685v1 [cs.NI])\nAbstract: With the continuous growth in communication network complexity and traffic volume, communication load balancing solutions are receiving increasing attention. Specifically, reinforcement learning (RL)-based methods have shown impressive performance compared with traditional rule-based methods. However, standard RL methods generally require an enormous amount of data to train, and generalize poorly to scenarios that are not encountered during training. We propose a policy reuse framework in which a policy selector chooses the most suitable pre-trained RL policy to execute based on the current traffic condition. Our method hinges on a policy bank composed of policies trained on a diverse set of traffic scenarios. When deploying to an unknown traffic scenario, we select a policy from the policy bank based on the similarity between the previous-day traffic of the current scenario and the traffic observed during training. Experiments demonstrate that this framework can outperform classical a",
    "path": "papers/23/03/2303.16685.json",
    "total_tokens": 924,
    "translated_title": "未知流量场景下的通信负载均衡中的策略重用",
    "translated_abstract": "随着通信网络复杂性和流量增长的持续增加，通信负载平衡解决方案越来越受到关注。具体来说，基于强化学习（RL）的方法与传统的基于规则的方法相比，表现出了令人印象深刻的性能。然而，标准的RL方法通常需要大量的数据进行训练，并且对于在训练过程中未遇到的场景的泛化能力较差。我们提出了一个策略重用框架，其中策略选择器基于当前的流量状况选择最适合的预训练RL策略来执行。我们的方法依赖于一个策略库，其中包含在不同流量场景下训练的策略。在部署到未知的流量场景时，我们根据当前场景的前一天的流量与训练期间观察到的流量之间的相似度从策略库中选择策略。实验表明，该框架可以胜过传统的负载平衡算法。",
    "tldr": "提出了一种策略重用框架，该框架通过选择最适合执行的预训练强化学习策略来解决通信负载平衡问题，其根据不同流量场景下的策略训练库进行选择，可以胜过传统的负载平衡算法。",
    "en_tdlr": "A policy reuse framework is proposed to solve communication load balancing by selecting the most suitable pre-trained reinforcement learning policy, which is chosen based on the policy training bank under different traffic scenarios. This method can outperform traditional load balancing algorithms."
}