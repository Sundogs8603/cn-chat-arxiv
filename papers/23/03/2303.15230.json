{
    "title": "Troika: Multi-Path Cross-Modal Traction for Compositional Zero-Shot Learning",
    "abstract": "arXiv:2303.15230v2 Announce Type: replace-cross  Abstract: Recent compositional zero-shot learning (CZSL) methods adapt pre-trained vision-language models (VLMs) by constructing trainable prompts only for composed state-object pairs. Relying on learning the joint representation of seen compositions, these methods ignore the explicit modeling of the state and object, thus limiting the exploitation of pre-trained knowledge and generalization to unseen compositions. With a particular focus on the universality of the solution, in this work, we propose a novel paradigm for CZSL models that establishes three identification branches (i.e., Multi-Path) to jointly model the state, object, and composition. The presented Troika is our implementation that aligns the branch-specific prompt representations with decomposed visual features. To calibrate the bias between semantically similar multi-modal representations, we further devise a Cross-Modal Traction module into Troika that shifts the prompt ",
    "link": "https://arxiv.org/abs/2303.15230",
    "context": "Title: Troika: Multi-Path Cross-Modal Traction for Compositional Zero-Shot Learning\nAbstract: arXiv:2303.15230v2 Announce Type: replace-cross  Abstract: Recent compositional zero-shot learning (CZSL) methods adapt pre-trained vision-language models (VLMs) by constructing trainable prompts only for composed state-object pairs. Relying on learning the joint representation of seen compositions, these methods ignore the explicit modeling of the state and object, thus limiting the exploitation of pre-trained knowledge and generalization to unseen compositions. With a particular focus on the universality of the solution, in this work, we propose a novel paradigm for CZSL models that establishes three identification branches (i.e., Multi-Path) to jointly model the state, object, and composition. The presented Troika is our implementation that aligns the branch-specific prompt representations with decomposed visual features. To calibrate the bias between semantically similar multi-modal representations, we further devise a Cross-Modal Traction module into Troika that shifts the prompt ",
    "path": "papers/23/03/2303.15230.json",
    "total_tokens": 908,
    "translated_title": "Troika: 多路径跨模态拖曳对于组合式零样本学习",
    "translated_abstract": "最近的组合式零样本学习（CZSL）方法通过仅为组合状态-对象对构建可训练提示来适应预训练的视觉-语言模型（VLMs）。这些方法依赖于学习已见组合的联合表示，而忽略了对状态和对象的显式建模，从而限制了对预训练知识的利用和对未见组合的泛化。在本研究中，我们特别关注解决方案的普适性，提出了一种为CZSL模型建立三个识别分支（即Multi-Path）以共同建模状态、对象和组合的新范式。所提出的Troika是我们的实现，它将分支特定的提示表示与分解的视觉特征对齐。为了校准语义上相似的多模态表示之间的偏差，我们进一步设计了一个Cross-Modal Traction模块来将提示移动到...",
    "tldr": "提出了一种适用于组合式零样本学习的Troika模型，通过建立三个识别分支共同对状态、对象和组合进行建模，在对齐分支特定提示表示和分解的视觉特征的同时，引入了Cross-Modal Traction模块来校准多模态表示之间的偏差。"
}