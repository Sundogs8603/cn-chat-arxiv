{
    "title": "Beam Management Driven by Radio Environment Maps in O-RAN Architecture. (arXiv:2303.11742v1 [cs.NI])",
    "abstract": "The Massive Multiple-Input Multiple-Output (M-MIMO) is considered as one of the key technologies in 5G, and future 6G networks. From the perspective of, e.g., channel estimation, especially for high-speed users it is easier to implement an M-MIMO network exploiting a static set of beams, i.e., Grid of Beams (GoB). While considering GoB it is important to properly assign users to the beams, i.e., to perform Beam Management (BM). BM can be enhanced by taking into account historical knowledge about the radio environment, e.g., to avoid radio link failures. The aim of this paper is to propose such a BM algorithm, that utilizes location-dependent data stored in a Radio Environment Map (REM). It utilizes received power maps, and user mobility patterns to optimize the BM process in terms of Reinforcement Learning (RL) by using the Policy Iteration method under different goal functions, e.g., maximization of received power or minimization of beam reselections while avoiding radio link failures",
    "link": "http://arxiv.org/abs/2303.11742",
    "context": "Title: Beam Management Driven by Radio Environment Maps in O-RAN Architecture. (arXiv:2303.11742v1 [cs.NI])\nAbstract: The Massive Multiple-Input Multiple-Output (M-MIMO) is considered as one of the key technologies in 5G, and future 6G networks. From the perspective of, e.g., channel estimation, especially for high-speed users it is easier to implement an M-MIMO network exploiting a static set of beams, i.e., Grid of Beams (GoB). While considering GoB it is important to properly assign users to the beams, i.e., to perform Beam Management (BM). BM can be enhanced by taking into account historical knowledge about the radio environment, e.g., to avoid radio link failures. The aim of this paper is to propose such a BM algorithm, that utilizes location-dependent data stored in a Radio Environment Map (REM). It utilizes received power maps, and user mobility patterns to optimize the BM process in terms of Reinforcement Learning (RL) by using the Policy Iteration method under different goal functions, e.g., maximization of received power or minimization of beam reselections while avoiding radio link failures",
    "path": "papers/23/03/2303.11742.json",
    "total_tokens": 746,
    "translated_title": "基于射频环境地图的O-RAN架构中的波束管理",
    "translated_abstract": "大规模多输入多输出(M-MIMO)被认为是5G和未来6G网络的关键技术之一。本文旨在提出一种基于射频环境地图(Radio Environment Map,REM)的波束管理算法，它利用接收功率映射和用户移动模式，在不同目标函数下从强化学习(Reinforcement Learning,RL)的角度来优化BM过程，例如最大化接收功率或在避免无线电链路故障的同时最小化波束重新选择。",
    "tldr": "本文提出了一种基于REM的BM算法，使用RL从不同目标函数的角度来优化该过程，从而实现最大化接收功率和最小化波束重新选择。",
    "en_tdlr": "This paper proposes a BM algorithm based on REM that utilizes RL to optimize the process from different goal functions, such as maximizing the received power or minimizing beam reselections while avoiding radio link failures."
}