{
    "title": "FedML-HE: An Efficient Homomorphic-Encryption-Based Privacy-Preserving Federated Learning System. (arXiv:2303.10837v2 [cs.LG] UPDATED)",
    "abstract": "Federated Learning trains machine learning models on distributed devices by aggregating local model updates instead of local data. However, privacy concerns arise as the aggregated local models on the server may reveal sensitive personal information by inversion attacks. Privacy-preserving methods, such as homomorphic encryption (HE), then become necessary for FL training. Despite HE's privacy advantages, its applications suffer from impractical overheads, especially for foundation models. In this paper, we present FedML-HE, the first practical federated learning system with efficient HE-based secure model aggregation. FedML-HE proposes to selectively encrypt sensitive parameters, significantly reducing both computation and communication overheads during training while providing customizable privacy preservation. Our optimized system demonstrates considerable overhead reduction, particularly for large foundation models (e.g., ~10x reduction for ResNet-50, and up to ~40x reduction for B",
    "link": "http://arxiv.org/abs/2303.10837",
    "context": "Title: FedML-HE: An Efficient Homomorphic-Encryption-Based Privacy-Preserving Federated Learning System. (arXiv:2303.10837v2 [cs.LG] UPDATED)\nAbstract: Federated Learning trains machine learning models on distributed devices by aggregating local model updates instead of local data. However, privacy concerns arise as the aggregated local models on the server may reveal sensitive personal information by inversion attacks. Privacy-preserving methods, such as homomorphic encryption (HE), then become necessary for FL training. Despite HE's privacy advantages, its applications suffer from impractical overheads, especially for foundation models. In this paper, we present FedML-HE, the first practical federated learning system with efficient HE-based secure model aggregation. FedML-HE proposes to selectively encrypt sensitive parameters, significantly reducing both computation and communication overheads during training while providing customizable privacy preservation. Our optimized system demonstrates considerable overhead reduction, particularly for large foundation models (e.g., ~10x reduction for ResNet-50, and up to ~40x reduction for B",
    "path": "papers/23/03/2303.10837.json",
    "total_tokens": 885,
    "translated_title": "FedML-HE:一种基于高效同态加密的隐私保护联邦学习系统",
    "translated_abstract": "联邦学习通过聚合本地模型更新而不是本地数据，在分布式设备上训练机器学习模型。然而，隐私问题产生了，因为服务端上聚合的本地模型可能通过逆向攻击揭示敏感个人信息。隐私保护方法，如同态加密（HE），因此成为FL训练的必要手段。尽管HE具有隐私优势，但其应用受到不实际的开销限制，尤其是对基础模型而言。本文提出了FedML-HE，第一个具有高效HE安全模型聚合的实用联邦学习系统。FedML-HE提出了选择性加密敏感参数，显著减少训练过程中的计算和通信开销，同时提供可定制的隐私保护。我们优化的系统显示出相当大的开销降低，尤其是对于大型基础模型（例如，ResNet-50减少了约10倍，而B模型减少了约40倍）。",
    "tldr": "FedML-HE是一种基于高效同态加密的实用联邦学习系统，它通过选择性加密敏感参数来显著减少计算和通信开销，并提供可定制的隐私保护。",
    "en_tdlr": "FedML-HE is a practical federated learning system based on efficient homomorphic encryption. It reduces computation and communication overheads significantly by selectively encrypting sensitive parameters, while providing customizable privacy preservation."
}