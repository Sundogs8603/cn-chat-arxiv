{
    "title": "Identifiability Results for Multimodal Contrastive Learning. (arXiv:2303.09166v1 [cs.LG])",
    "abstract": "Contrastive learning is a cornerstone underlying recent progress in multi-view and multimodal learning, e.g., in representation learning with image/caption pairs. While its effectiveness is not yet fully understood, a line of recent work reveals that contrastive learning can invert the data generating process and recover ground truth latent factors shared between views. In this work, we present new identifiability results for multimodal contrastive learning, showing that it is possible to recover shared factors in a more general setup than the multi-view setting studied previously. Specifically, we distinguish between the multi-view setting with one generative mechanism (e.g., multiple cameras of the same type) and the multimodal setting that is characterized by distinct mechanisms (e.g., cameras and microphones). Our work generalizes previous identifiability results by redefining the generative process in terms of distinct mechanisms with modality-specific latent variables. We prove t",
    "link": "http://arxiv.org/abs/2303.09166",
    "context": "Title: Identifiability Results for Multimodal Contrastive Learning. (arXiv:2303.09166v1 [cs.LG])\nAbstract: Contrastive learning is a cornerstone underlying recent progress in multi-view and multimodal learning, e.g., in representation learning with image/caption pairs. While its effectiveness is not yet fully understood, a line of recent work reveals that contrastive learning can invert the data generating process and recover ground truth latent factors shared between views. In this work, we present new identifiability results for multimodal contrastive learning, showing that it is possible to recover shared factors in a more general setup than the multi-view setting studied previously. Specifically, we distinguish between the multi-view setting with one generative mechanism (e.g., multiple cameras of the same type) and the multimodal setting that is characterized by distinct mechanisms (e.g., cameras and microphones). Our work generalizes previous identifiability results by redefining the generative process in terms of distinct mechanisms with modality-specific latent variables. We prove t",
    "path": "papers/23/03/2303.09166.json",
    "total_tokens": 842,
    "translated_abstract": "对比学习是最近在多视角和多模态学习中取得进展的基石，例如在图像/字幕对表示学习中。虽然其有效性尚未完全被理解，但最近的一些工作表明，对比学习可以反转数据生成过程，并恢复视图之间共享的地面真实潜在因素。在这项工作中，我们为多模态对比学习提供了新的可识别性结果，表明在比以前研究的多视图设置更一般的设置中，可以恢复共享因素。具体而言，我们区分具有一个生成机制的多视图设置（例如同一类型的多个相机）和以不同机制（例如相机和麦克风）为特征的多模态设置。我们通过重新定义具有模态特定潜变量的不同机制的生成过程来推广以前的可识别性结果。我们证明了这个设置中对潜在因素的恢复。",
    "tldr": "本研究提出了多模态对比学习的可识别性结果，可以在多种机制的设置中恢复共享因素。",
    "en_tdlr": "This paper presents new identifiability results for multimodal contrastive learning, showing the possibility of recovering shared factors in a more general setup than the multi-view setting studied previously. The proposed method can distinguish between multiple generative mechanisms and recover shared latent factors in distinct modalities."
}