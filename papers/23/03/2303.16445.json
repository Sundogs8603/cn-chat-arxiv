{
    "title": "Larger Probes Tell a Different Story: Extending Psycholinguistic Datasets Via In-Context Learning. (arXiv:2303.16445v1 [cs.CL])",
    "abstract": "Language model probing is often used to test specific capabilities of these models. However, conclusions from such studies may be limited when the probing benchmarks are small and lack statistical power. In this work, we introduce new, larger datasets for negation (NEG-1500-SIMP) and role reversal (ROLE-1500) inspired by psycholinguistic studies. We dramatically extend existing NEG-136 and ROLE-88 benchmarks using GPT3, increasing their size from 18 and 44 sentence pairs to 750 each. We also create another version of extended negation dataset (NEG-1500-SIMP-TEMP), created using template-based generation. It consists of 770 sentence pairs. We evaluate 22 models on the extended datasets, seeing model performance dip 20-57% compared to the original smaller benchmarks. We observe high levels of negation sensitivity in models like BERT and ALBERT demonstrating that previous findings might have been skewed due to smaller test sets. Finally, we observe that while GPT3 has generated all the ex",
    "link": "http://arxiv.org/abs/2303.16445",
    "context": "Title: Larger Probes Tell a Different Story: Extending Psycholinguistic Datasets Via In-Context Learning. (arXiv:2303.16445v1 [cs.CL])\nAbstract: Language model probing is often used to test specific capabilities of these models. However, conclusions from such studies may be limited when the probing benchmarks are small and lack statistical power. In this work, we introduce new, larger datasets for negation (NEG-1500-SIMP) and role reversal (ROLE-1500) inspired by psycholinguistic studies. We dramatically extend existing NEG-136 and ROLE-88 benchmarks using GPT3, increasing their size from 18 and 44 sentence pairs to 750 each. We also create another version of extended negation dataset (NEG-1500-SIMP-TEMP), created using template-based generation. It consists of 770 sentence pairs. We evaluate 22 models on the extended datasets, seeing model performance dip 20-57% compared to the original smaller benchmarks. We observe high levels of negation sensitivity in models like BERT and ALBERT demonstrating that previous findings might have been skewed due to smaller test sets. Finally, we observe that while GPT3 has generated all the ex",
    "path": "papers/23/03/2303.16445.json",
    "total_tokens": 990,
    "translated_title": "更大的探针讲述不同的故事: 通过上下文学习扩展心理语言学数据集",
    "translated_abstract": "语言模型探测通常用来测试这些模型的特定能力。然而，当探测基准小且缺乏统计功效时，这类研究的结论可能受到限制。在这项工作中，我们介绍了受心理语言学研究启发的否定（NEG-1500-SIMP）和角色反转（ROLE-1500）的新的、更大的数据集。我们使用GPT3将现有的NEG-136和ROLE-88基准进行了大幅扩展，将它们的规模从18和44个句对分别增加到了750个。我们还创建了另一个使用基于模板的生成创建的扩展否定数据集(NEG-1500-SIMP-TEMP)，它由770个句对组成。我们在扩展数据集上评估了22个模型，发现模型性能与原始较小基准相比下降了20-57%。我们观察到BERT和ALBERT等模型具有较高的否定敏感性，这表明以前的研究结果可能由于较小的测试集而存在误差。最后，我们观察到，虽然GPT3生成了所有的实例，但句子的语法质量受到一些限制。",
    "tldr": "本文通过上下文学习扩展否定和角色反转数据集，发现过去的结论可能被小型测试集误导。同时，BERT和ALBERT等模型表现出较高的否定敏感度。",
    "en_tdlr": "This paper extends negation and role reversal datasets inspired by psycholinguistic studies using in-context learning, and finds that the previous conclusions may have been skewed due to small testing set. It also observes high levels of negation sensitivity in models like BERT and ALBERT."
}