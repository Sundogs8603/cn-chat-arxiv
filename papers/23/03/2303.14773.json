{
    "title": "BlackVIP: Black-Box Visual Prompting for Robust Transfer Learning. (arXiv:2303.14773v2 [cs.CV] UPDATED)",
    "abstract": "With the surge of large-scale pre-trained models (PTMs), fine-tuning these models to numerous downstream tasks becomes a crucial problem. Consequently, parameter efficient transfer learning (PETL) of large models has grasped huge attention. While recent PETL methods showcase impressive performance, they rely on optimistic assumptions: 1) the entire parameter set of a PTM is available, and 2) a sufficiently large memory capacity for the fine-tuning is equipped. However, in most real-world applications, PTMs are served as a black-box API or proprietary software without explicit parameter accessibility. Besides, it is hard to meet a large memory requirement for modern PTMs. In this work, we propose black-box visual prompting (BlackVIP), which efficiently adapts the PTMs without knowledge about model architectures and parameters. BlackVIP has two components; 1) Coordinator and 2) simultaneous perturbation stochastic approximation with gradient correction (SPSA-GC). The Coordinator designs ",
    "link": "http://arxiv.org/abs/2303.14773",
    "context": "Title: BlackVIP: Black-Box Visual Prompting for Robust Transfer Learning. (arXiv:2303.14773v2 [cs.CV] UPDATED)\nAbstract: With the surge of large-scale pre-trained models (PTMs), fine-tuning these models to numerous downstream tasks becomes a crucial problem. Consequently, parameter efficient transfer learning (PETL) of large models has grasped huge attention. While recent PETL methods showcase impressive performance, they rely on optimistic assumptions: 1) the entire parameter set of a PTM is available, and 2) a sufficiently large memory capacity for the fine-tuning is equipped. However, in most real-world applications, PTMs are served as a black-box API or proprietary software without explicit parameter accessibility. Besides, it is hard to meet a large memory requirement for modern PTMs. In this work, we propose black-box visual prompting (BlackVIP), which efficiently adapts the PTMs without knowledge about model architectures and parameters. BlackVIP has two components; 1) Coordinator and 2) simultaneous perturbation stochastic approximation with gradient correction (SPSA-GC). The Coordinator designs ",
    "path": "papers/23/03/2303.14773.json",
    "total_tokens": 898,
    "translated_title": "BlackVIP: 针对稳健迁移学习的黑盒视觉提示",
    "translated_abstract": "随着大规模预训练模型（PTMs）的兴起，将这些模型微调为众多下游任务变得至关重要。因此，大型模型的参数效率转移学习（PETL）引起了极大关注。虽然最近的PETL方法展示了令人印象深刻的性能，但它们依赖乐观的假设：1）PTM的整个参数集是可用的，2）具备足够大的内存容量进行微调。然而，在大多数实际应用中，PTMs作为黑盒API或专有软件提供，没有明确参数可访问性。此外，满足现代PTMs的大内存要求也很困难。在这项工作中，我们提出了黑盒视觉提示（BlackVIP），它可以有效地适应PTMs，而不需要关于模型架构和参数的知识。BlackVIP包括两个组件：1）协调器和2）带梯度校正的同时扰动随机逼近（SPSA-GC）。",
    "tldr": "BlackVIP是一种针对大型预训练模型的黑盒视觉提示方法，它可以在没有参数可访问性的情况下高效地适应模型，并通过使用协调器和SPSA-GC组件实现。",
    "en_tdlr": "BlackVIP is a black-box visual prompting method for large-scale pre-trained models, which can efficiently adapt the models without parameter accessibility, utilizing a Coordinator and SPSA-GC components."
}