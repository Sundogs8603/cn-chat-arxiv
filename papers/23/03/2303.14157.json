{
    "title": "Efficient Scale-Invariant Generator with Column-Row Entangled Pixel Synthesis. (arXiv:2303.14157v1 [cs.CV])",
    "abstract": "Any-scale image synthesis offers an efficient and scalable solution to synthesize photo-realistic images at any scale, even going beyond 2K resolution. However, existing GAN-based solutions depend excessively on convolutions and a hierarchical architecture, which introduce inconsistency and the $``$texture sticking$\"$ issue when scaling the output resolution. From another perspective, INR-based generators are scale-equivariant by design, but their huge memory footprint and slow inference hinder these networks from being adopted in large-scale or real-time systems. In this work, we propose $\\textbf{C}$olumn-$\\textbf{R}$ow $\\textbf{E}$ntangled $\\textbf{P}$ixel $\\textbf{S}$ynthesis ($\\textbf{CREPS}$), a new generative model that is both efficient and scale-equivariant without using any spatial convolutions or coarse-to-fine design. To save memory footprint and make the system scalable, we employ a novel bi-line representation that decomposes layer-wise feature maps into separate $``$thick",
    "link": "http://arxiv.org/abs/2303.14157",
    "context": "Title: Efficient Scale-Invariant Generator with Column-Row Entangled Pixel Synthesis. (arXiv:2303.14157v1 [cs.CV])\nAbstract: Any-scale image synthesis offers an efficient and scalable solution to synthesize photo-realistic images at any scale, even going beyond 2K resolution. However, existing GAN-based solutions depend excessively on convolutions and a hierarchical architecture, which introduce inconsistency and the $``$texture sticking$\"$ issue when scaling the output resolution. From another perspective, INR-based generators are scale-equivariant by design, but their huge memory footprint and slow inference hinder these networks from being adopted in large-scale or real-time systems. In this work, we propose $\\textbf{C}$olumn-$\\textbf{R}$ow $\\textbf{E}$ntangled $\\textbf{P}$ixel $\\textbf{S}$ynthesis ($\\textbf{CREPS}$), a new generative model that is both efficient and scale-equivariant without using any spatial convolutions or coarse-to-fine design. To save memory footprint and make the system scalable, we employ a novel bi-line representation that decomposes layer-wise feature maps into separate $``$thick",
    "path": "papers/23/03/2303.14157.json",
    "total_tokens": 1127,
    "translated_title": "一种具有行列交错像素合成的高效尺度不变生成器",
    "translated_abstract": "任意比例图像合成为合成在任意比例下合成逼真图像提供了一种高效且可扩展的解决方案，即使超出了2K分辨率范围。然而，现有的基于GAN的解决方案过度依赖于卷积和分层架构，在缩放输出分辨率时会引入不一致性和“纹理粘连”问题。从另一个角度来看，基于INR的生成器从设计上是尺度等变的，但它们巨大的内存占用和缓慢的推理妨碍了这些网络在大规模或实时系统中的应用。在本研究中，我们提出了一种新的生成模型：具有行列交错像素合成的列-行交错像素合成（$\\textbf{CREPS}$）。不使用任何空间卷积或从粗到细的设计。为了节省内存占用并使系统可扩展，我们采用了一种新颖的双线表示法，将层内特征图分解为局部和全局特征的独立“厚条”插值这些条带的融合来生成图像。我们的实验表明，$\\textbf{CREPS}$在图像质量和可扩展性方面优于现有技术，在保持更小的内存占用和更快的推理速度的同时。",
    "tldr": "提出了一种高效尺度不变的生成模型，不使用空间卷积或分层架构，通过将层内特征图分解为局部和全局特征并通过插值这些特征生成图像，使得模型具有较小的内存占用和更快的推理速度。",
    "en_tdlr": "Proposed an efficient scale-invariant generative model with row-column entangled pixel synthesis that decomposes layer-wise feature maps into strips of local and global features, interlaces them, and generates images without using spatial convolutions or hierarchical architecture, achieving superior performance in both image quality and scalability with smaller memory footprint and faster inference speed compared to existing solutions."
}