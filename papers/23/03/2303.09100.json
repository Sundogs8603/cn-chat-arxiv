{
    "title": "Patch-Token Aligned Bayesian Prompt Learning for Vision-Language Models. (arXiv:2303.09100v1 [cs.CV])",
    "abstract": "For downstream applications of vision-language pre-trained models, there has been significant interest in constructing effective prompts. Existing works on prompt engineering, which either require laborious manual designs or optimize the prompt tuning as a point estimation problem, may fail to describe diverse characteristics of categories and limit their applications. We introduce a Bayesian probabilistic resolution to prompt learning, where the label-specific stochastic prompts are generated hierarchically by first sampling a latent vector from an underlying distribution and then employing a lightweight generative model. Importantly, we semantically regularize prompt learning with the visual knowledge and view images and the corresponding prompts as patch and token sets under optimal transport, which pushes the prompt tokens to faithfully capture the label-specific visual concepts, instead of overfitting the training categories. Moreover, the proposed model can also be straightforwar",
    "link": "http://arxiv.org/abs/2303.09100",
    "context": "Title: Patch-Token Aligned Bayesian Prompt Learning for Vision-Language Models. (arXiv:2303.09100v1 [cs.CV])\nAbstract: For downstream applications of vision-language pre-trained models, there has been significant interest in constructing effective prompts. Existing works on prompt engineering, which either require laborious manual designs or optimize the prompt tuning as a point estimation problem, may fail to describe diverse characteristics of categories and limit their applications. We introduce a Bayesian probabilistic resolution to prompt learning, where the label-specific stochastic prompts are generated hierarchically by first sampling a latent vector from an underlying distribution and then employing a lightweight generative model. Importantly, we semantically regularize prompt learning with the visual knowledge and view images and the corresponding prompts as patch and token sets under optimal transport, which pushes the prompt tokens to faithfully capture the label-specific visual concepts, instead of overfitting the training categories. Moreover, the proposed model can also be straightforwar",
    "path": "papers/23/03/2303.09100.json",
    "total_tokens": 1057,
    "translated_title": "视觉语言模型补丁-令牌对齐的贝叶斯提示学习",
    "translated_abstract": "在视觉语言预训练模型的下游应用中，构建有效提示引起了极大关注。现有的提示工程方法要么需要费时费力的手动设计，要么将提示调优作为点估计问题进行优化，这可能无法描述类别的多样特征并限制了它们的应用。本文提出了一种基于贝叶斯概率的提示学习方法，其中通过从潜在分布中首先采样隐向量，然后采用轻量级生成模型来生成标签特定的随机提示。重要的是，我们将视觉知识与图像的语义规则化，并将图像和相应的提示视为补丁和令牌集，通过最优传输将提示标记推向忠实捕捉标签特定的视觉概念，而不是过度拟合训练类别。此外，所提出的模型还可以通过使用额外的基于文本的信息来生成更具信息量和准确性的提示。在各种视觉语言任务上的广泛实验表明，我们的补丁-令牌对齐的贝叶斯提示学习（PTBPL）优于现有的最先进模型。",
    "tldr": "本文提出了一种基于贝叶斯概率的视觉语言模型提示学习方法，通过将提示标记推向忠实捕捉标签特定的视觉概念，而不是过度拟合训练类别，解决了现有提示工程的问题。在各种视觉语言任务上的广泛实验表明，该方法优于现有的最先进模型。",
    "en_tdlr": "The paper proposes a Bayesian probabilistic resolution to prompt learning for downstream applications of vision-language pre-trained models where stochastic prompts are generated hierarchically using a lightweight generative model. The model semantically regularizes prompt learning by aligning prompts with the visual knowledge and specifically captures the label-specific visual concepts. The proposed approach outperforms existing state-of-the-art models in various vision-language tasks."
}