{
    "title": "Cascaded Local Implicit Transformer for Arbitrary-Scale Super-Resolution. (arXiv:2303.16513v1 [cs.CV])",
    "abstract": "Implicit neural representation has recently shown a promising ability in representing images with arbitrary resolutions. In this paper, we present a Local Implicit Transformer (LIT), which integrates the attention mechanism and frequency encoding technique into a local implicit image function. We design a cross-scale local attention block to effectively aggregate local features. To further improve representative power, we propose a Cascaded LIT (CLIT) that exploits multi-scale features, along with a cumulative training strategy that gradually increases the upsampling scales during training. We have conducted extensive experiments to validate the effectiveness of these components and analyze various training strategies. The qualitative and quantitative results demonstrate that LIT and CLIT achieve favorable results and outperform the prior works in arbitrary super-resolution tasks.",
    "link": "http://arxiv.org/abs/2303.16513",
    "context": "Title: Cascaded Local Implicit Transformer for Arbitrary-Scale Super-Resolution. (arXiv:2303.16513v1 [cs.CV])\nAbstract: Implicit neural representation has recently shown a promising ability in representing images with arbitrary resolutions. In this paper, we present a Local Implicit Transformer (LIT), which integrates the attention mechanism and frequency encoding technique into a local implicit image function. We design a cross-scale local attention block to effectively aggregate local features. To further improve representative power, we propose a Cascaded LIT (CLIT) that exploits multi-scale features, along with a cumulative training strategy that gradually increases the upsampling scales during training. We have conducted extensive experiments to validate the effectiveness of these components and analyze various training strategies. The qualitative and quantitative results demonstrate that LIT and CLIT achieve favorable results and outperform the prior works in arbitrary super-resolution tasks.",
    "path": "papers/23/03/2303.16513.json",
    "total_tokens": 792,
    "translated_title": "针对任意尺度超分辨率的级联局部隐式变换器",
    "translated_abstract": "最近，隐式神经表示展示出在表示任意分辨率图像方面的有力能力。本文中，我们提出了一种局部隐式变换器（LIT），将注意力机制和频率编码技术融合到局部隐式图像函数中。我们设计了一个跨尺度的局部注意力块，以有效地聚合局部特征。为了进一步提高代表能力，我们提出了一种利用多尺度特征的级联LIT（CLIT），以及逐步增加上采样比例的累计训练策略。我们进行了大量实验证明了这些组件的有效性，并分析了各种训练策略。定性和定量结果表明，LIT和CLIT在任意超分辨率任务中取得了较好的结果，并超过了先前的工作。",
    "tldr": "本文提出了局部隐式变换器（LIT）和级联LIT (CLIT) ，结合注意力机制和多尺度特征，实现任意尺度超分辨率，并在实验证明其有效性和优越性。",
    "en_tdlr": "The paper proposes Local Implicit Transformer (LIT) and Cascaded LIT (CLIT) for arbitrary-scale super-resolution, integrating attention mechanism and multi-scale features. Extensive experiments demonstrate their effectiveness and superiority over prior works."
}