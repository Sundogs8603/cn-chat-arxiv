{
    "title": "Investigating GANsformer: A Replication Study of a State-of-the-Art Image Generation Model. (arXiv:2303.08577v1 [cs.CV])",
    "abstract": "The field of image generation through generative modelling is abundantly discussed nowadays. It can be used for various applications, such as up-scaling existing images, creating non-existing objects, such as interior design scenes, products or even human faces, and achieving transfer-learning processes. In this context, Generative Adversarial Networks (GANs) are a class of widely studied machine learning frameworks first appearing in the paper \"Generative adversarial nets\" by Goodfellow et al. that achieve the goal above. In our work, we reproduce and evaluate a novel variation of the original GAN network, the GANformer, proposed in \"Generative Adversarial Transformers\" by Hudson and Zitnick. This project aimed to recreate the methods presented in this paper to reproduce the original results and comment on the authors' claims. Due to resources and time limitations, we had to constrain the network's training times, dataset types, and sizes. Our research successfully recreated both vari",
    "link": "http://arxiv.org/abs/2303.08577",
    "context": "Title: Investigating GANsformer: A Replication Study of a State-of-the-Art Image Generation Model. (arXiv:2303.08577v1 [cs.CV])\nAbstract: The field of image generation through generative modelling is abundantly discussed nowadays. It can be used for various applications, such as up-scaling existing images, creating non-existing objects, such as interior design scenes, products or even human faces, and achieving transfer-learning processes. In this context, Generative Adversarial Networks (GANs) are a class of widely studied machine learning frameworks first appearing in the paper \"Generative adversarial nets\" by Goodfellow et al. that achieve the goal above. In our work, we reproduce and evaluate a novel variation of the original GAN network, the GANformer, proposed in \"Generative Adversarial Transformers\" by Hudson and Zitnick. This project aimed to recreate the methods presented in this paper to reproduce the original results and comment on the authors' claims. Due to resources and time limitations, we had to constrain the network's training times, dataset types, and sizes. Our research successfully recreated both vari",
    "path": "papers/23/03/2303.08577.json",
    "total_tokens": 789,
    "translated_title": "探究GANsformer：一种最先进的图像生成模型的复制研究",
    "translated_abstract": "现今广泛讨论的图像生成领域可以用于各种应用，例如升级现有图像，创建不存在的物体（如室内设计场景、产品甚至人脸），并实现传输学习过程。生成对抗网络（GANs）是一种广泛研究的机器学习框架，旨在实现上述目标。本文复制评估了原始GAN网络的一种新变体GANformer，该变体是Hudson和Zitnick在“生成对抗Transformer”中提出的。由于资源和时间限制，我们不得不限制网络的训练时间、数据集类型和大小。研究成功地重新创建了原始结果并对作者的声明进行了评论。",
    "tldr": "本文通过重新创建一种新的GAN变体GANformer，并对作者的声明进行评论，以探究最先进的图像生成模型。",
    "en_tdlr": "This paper investigates the state-of-the-art image generation model by reproducing and evaluating a novel variation of the original GAN network, the GANformer, and commenting on the authors' claims."
}