{
    "title": "MNL-Bandit in non-stationary environments. (arXiv:2303.02504v2 [cs.LG] UPDATED)",
    "abstract": "In this paper, we study the MNL-Bandit problem in a non-stationary environment and present an algorithm with a worst-case expected regret of $\\tilde{O}\\left( \\min \\left\\{ \\sqrt{NTL}\\;,\\; N^{\\frac{1}{3}}(\\Delta_{\\infty}^{K})^{\\frac{1}{3}} T^{\\frac{2}{3}} + \\sqrt{NT}\\right\\}\\right)$. Here $N$ is the number of arms, $L$ is the number of changes and $\\Delta_{\\infty}^{K}$ is a variation measure of the unknown parameters. Furthermore, we show matching lower bounds on the expected regret (up to logarithmic factors), implying that our algorithm is optimal. Our approach builds upon the epoch-based algorithm for stationary MNL-Bandit in Agrawal et al. 2016. However, non-stationarity poses several challenges and we introduce new techniques and ideas to address these. In particular, we give a tight characterization for the bias introduced in the estimators due to non stationarity and derive new concentration bounds.",
    "link": "http://arxiv.org/abs/2303.02504",
    "context": "Title: MNL-Bandit in non-stationary environments. (arXiv:2303.02504v2 [cs.LG] UPDATED)\nAbstract: In this paper, we study the MNL-Bandit problem in a non-stationary environment and present an algorithm with a worst-case expected regret of $\\tilde{O}\\left( \\min \\left\\{ \\sqrt{NTL}\\;,\\; N^{\\frac{1}{3}}(\\Delta_{\\infty}^{K})^{\\frac{1}{3}} T^{\\frac{2}{3}} + \\sqrt{NT}\\right\\}\\right)$. Here $N$ is the number of arms, $L$ is the number of changes and $\\Delta_{\\infty}^{K}$ is a variation measure of the unknown parameters. Furthermore, we show matching lower bounds on the expected regret (up to logarithmic factors), implying that our algorithm is optimal. Our approach builds upon the epoch-based algorithm for stationary MNL-Bandit in Agrawal et al. 2016. However, non-stationarity poses several challenges and we introduce new techniques and ideas to address these. In particular, we give a tight characterization for the bias introduced in the estimators due to non stationarity and derive new concentration bounds.",
    "path": "papers/23/03/2303.02504.json",
    "total_tokens": 1077,
    "translated_title": "非静态环境下的MNL-Bandit问题研究",
    "translated_abstract": "本文研究了非静态环境下的MNL-Bandit问题，并提出了一种算法，其最坏情况下的预期遗憾度为$\\tilde{O}\\left( \\min \\left\\{ \\sqrt{NTL}\\;,\\; N^{\\frac{1}{3}}(\\Delta_{\\infty}^{K})^{\\frac{1}{3}} T^{\\frac{2}{3}} + \\sqrt{NT}\\right\\}\\right)$。其中$N$是臂的数量，$L$是变化的数量，$\\Delta_{\\infty}^{K}$是未知参数的变化度量。此外，我们展示了期望遗憾度的匹配下界（对数因子内的下界），说明我们的算法是最优的。我们的方法基于Agrawal等人2016年提出的静态MNL-Bandit的时代算法。然而，非静态性带来了一些挑战，我们介绍了新的技术和想法来应对这些挑战。特别是，我们给出了由于非静态性引入的估计器偏差的紧致特征，并推导出新的浓度界。",
    "tldr": "本文研究了非静态环境下的MNL-Bandit问题，提出了一种算法，其最坏情况下的预期遗憾度为$\\tilde{O}\\left( \\min \\left\\{ \\sqrt{NTL}\\;,\\; N^{\\frac{1}{3}}(\\Delta_{\\infty}^{K})^{\\frac{1}{3}} T^{\\frac{2}{3}} + \\sqrt{NT}\\right\\}\\right)$。算法基于时代算法，对由于非静态性引入的估计器偏差进行了紧致特征给出新的浓度界。",
    "en_tdlr": "This paper studies the MNL-Bandit problem in non-stationary environments, proposes an algorithm with worst-case expected regret, and introduces new techniques to address challenges posed by non-stationarity. The algorithm has a tight characterization for bias introduced in the estimators and achieves matching lower bounds on expected regret."
}