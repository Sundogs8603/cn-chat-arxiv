{
    "title": "On Codex Prompt Engineering for OCL Generation: An Empirical Study. (arXiv:2303.16244v1 [cs.SE])",
    "abstract": "The Object Constraint Language (OCL) is a declarative language that adds constraints and object query expressions to MOF models. Despite its potential to provide precision and conciseness to UML models, the unfamiliar syntax of OCL has hindered its adoption. Recent advancements in LLMs, such as GPT-3, have shown their capability in many NLP tasks, including semantic parsing and text generation. Codex, a GPT-3 descendant, has been fine-tuned on publicly available code from GitHub and can generate code in many programming languages. We investigate the reliability of OCL constraints generated by Codex from natural language specifications. To achieve this, we compiled a dataset of 15 UML models and 168 specifications and crafted a prompt template with slots to populate with UML information and the target task, using both zero- and few-shot learning methods. By measuring the syntactic validity and execution accuracy metrics of the generated OCL constraints, we found that enriching the promp",
    "link": "http://arxiv.org/abs/2303.16244",
    "context": "Title: On Codex Prompt Engineering for OCL Generation: An Empirical Study. (arXiv:2303.16244v1 [cs.SE])\nAbstract: The Object Constraint Language (OCL) is a declarative language that adds constraints and object query expressions to MOF models. Despite its potential to provide precision and conciseness to UML models, the unfamiliar syntax of OCL has hindered its adoption. Recent advancements in LLMs, such as GPT-3, have shown their capability in many NLP tasks, including semantic parsing and text generation. Codex, a GPT-3 descendant, has been fine-tuned on publicly available code from GitHub and can generate code in many programming languages. We investigate the reliability of OCL constraints generated by Codex from natural language specifications. To achieve this, we compiled a dataset of 15 UML models and 168 specifications and crafted a prompt template with slots to populate with UML information and the target task, using both zero- and few-shot learning methods. By measuring the syntactic validity and execution accuracy metrics of the generated OCL constraints, we found that enriching the promp",
    "path": "papers/23/03/2303.16244.json",
    "total_tokens": 927,
    "translated_title": "Codex提示工程用于OCL生成的实证研究",
    "translated_abstract": "对象约束语言（OCL）是一种声明性语言，它在MOF模型中添加了约束和对象查询表达式。尽管OCL有潜力为UML模型提供精度和简洁性，但其不熟悉的语法阻碍了其被采用。最近LLM（如GPT-3）的进展显示了它们在许多NLP任务（包括语义解析和文本生成）中的能力。Codex是GPT-3的后代，已经在GitHub上公开可用的代码上进行了微调，并且可以用许多编程语言生成代码。我们研究了从自然语言规范中由Codex生成的OCL约束的可靠性。为了实现这一目标，我们编制了一个包含插槽的提示模板，用UML信息和目标任务填充，使用零或少量样本学习方法。通过衡量OCL约束的语法有效性和执行准确性指标，我们发现丰富提示模板的领域特定信息以及使用少量样本学习可以显著提高生成的OCL约束的质量。",
    "tldr": "本文研究了使用Codex生成OCL约束，通过提高提示模板的领域特定信息和少量样本学习可以显著提高生成约束的质量。",
    "en_tdlr": "This paper investigates the reliability of using Codex to generate OCL constraints, and finds that improving the domain-specific information in the prompt template and using few-shot learning significantly improves the quality of the generated constraints."
}