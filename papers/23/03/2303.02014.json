{
    "title": "Summary Statistic Privacy in Data Sharing. (arXiv:2303.02014v2 [cs.CR] UPDATED)",
    "abstract": "We study a setting where a data holder wishes to share data with a receiver, without revealing certain summary statistics of the data distribution (e.g., mean, standard deviation). It achieves this by passing the data through a randomization mechanism. We propose summary statistic privacy, a metric for quantifying the privacy risk of such a mechanism based on the worst-case probability of an adversary guessing the distributional secret within some threshold. Defining distortion as a worst-case Wasserstein-1 distance between the real and released data, we prove lower bounds on the tradeoff between privacy and distortion. We then propose a class of quantization mechanisms that can be adapted to different data distributions. We show that the quantization mechanism's privacy-distortion tradeoff matches our lower bounds under certain regimes, up to small constant factors. Finally, we demonstrate on real-world datasets that the proposed quantization mechanisms achieve better privacy-distorti",
    "link": "http://arxiv.org/abs/2303.02014",
    "context": "Title: Summary Statistic Privacy in Data Sharing. (arXiv:2303.02014v2 [cs.CR] UPDATED)\nAbstract: We study a setting where a data holder wishes to share data with a receiver, without revealing certain summary statistics of the data distribution (e.g., mean, standard deviation). It achieves this by passing the data through a randomization mechanism. We propose summary statistic privacy, a metric for quantifying the privacy risk of such a mechanism based on the worst-case probability of an adversary guessing the distributional secret within some threshold. Defining distortion as a worst-case Wasserstein-1 distance between the real and released data, we prove lower bounds on the tradeoff between privacy and distortion. We then propose a class of quantization mechanisms that can be adapted to different data distributions. We show that the quantization mechanism's privacy-distortion tradeoff matches our lower bounds under certain regimes, up to small constant factors. Finally, we demonstrate on real-world datasets that the proposed quantization mechanisms achieve better privacy-distorti",
    "path": "papers/23/03/2303.02014.json",
    "total_tokens": 978,
    "translated_title": "数据共享中的摘要统计隐私",
    "translated_abstract": "我们研究了一个数据持有者希望与接收者共享数据，同时又不透露数据分布的某些摘要统计信息（如平均值，标准差）的情景。通过将数据通过随机化机制传递，实现了这一目标。我们提出了摘要统计隐私，这是一种用于量化此类机制的隐私风险的度量标准，基于对于攻击者在某个阈值内猜测分布秘密的最坏情况概率。将失真定义为真实数据与发布数据之间的最坏情况Wasserstein-1距离，我们证明了隐私和失真之间的权衡的下界。然后，我们提出了一类可以适应不同数据分布的量化机制。我们证明，该量化机制的隐私-失真权衡在某些情况下与我们的下界匹配，最多相差一些较小的常数因子。最后，我们在实际数据集上展示了所提出的量化机制实现更好的隐私-失真权衡。",
    "tldr": "这项研究关注在数据共享中保护摘要统计隐私的问题，提出了衡量隐私风险的度量标准，并证明了隐私和失真之间的权衡存在下界，并提出了一类适用于不同数据分布的量化机制，该机制在某些情况下与下界匹配，最终在实际数据集上展示了更好的隐私-失真权衡的效果。"
}