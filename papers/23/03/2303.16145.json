{
    "title": "NeuralMind-UNICAMP at 2022 TREC NeuCLIR: Large Boring Rerankers for Cross-lingual Retrieval. (arXiv:2303.16145v1 [cs.IR])",
    "abstract": "This paper reports on a study of cross-lingual information retrieval (CLIR) using the mT5-XXL reranker on the NeuCLIR track of TREC 2022. Perhaps the biggest contribution of this study is the finding that despite the mT5 model being fine-tuned only on query-document pairs of the same language it proved to be viable for CLIR tasks, where query-document pairs are in different languages, even in the presence of suboptimal first-stage retrieval performance. The results of the study show outstanding performance across all tasks and languages, leading to a high number of winning positions. Finally, this study provides valuable insights into the use of mT5 in CLIR tasks and highlights its potential as a viable solution. For reproduction refer to https://github.com/unicamp-dl/NeuCLIR22-mT5",
    "link": "http://arxiv.org/abs/2303.16145",
    "context": "Title: NeuralMind-UNICAMP at 2022 TREC NeuCLIR: Large Boring Rerankers for Cross-lingual Retrieval. (arXiv:2303.16145v1 [cs.IR])\nAbstract: This paper reports on a study of cross-lingual information retrieval (CLIR) using the mT5-XXL reranker on the NeuCLIR track of TREC 2022. Perhaps the biggest contribution of this study is the finding that despite the mT5 model being fine-tuned only on query-document pairs of the same language it proved to be viable for CLIR tasks, where query-document pairs are in different languages, even in the presence of suboptimal first-stage retrieval performance. The results of the study show outstanding performance across all tasks and languages, leading to a high number of winning positions. Finally, this study provides valuable insights into the use of mT5 in CLIR tasks and highlights its potential as a viable solution. For reproduction refer to https://github.com/unicamp-dl/NeuCLIR22-mT5",
    "path": "papers/23/03/2303.16145.json",
    "total_tokens": 944,
    "translated_title": "《神经网络-巴西坎普斯大学》在2022年TREC NeuCLIR中的大型无聊重排器实现跨语言检索",
    "translated_abstract": "本文报道了使用mT5-XXL重排器在TREC 2022 NeuCLIR赛道上进行跨语言信息检索（CLIR）的研究。该研究最大的贡献也许是发现尽管mT5模型仅在相同语言的查询-文档对上进行微调，但在不同语言的查询-文档对存在的情况下，它证明了在第一阶段检索表现亚优的情况下是可行的。研究结果表明，在所有任务和语言上都表现出色，获得了很高的获胜位置。最后，本研究为在CLIR任务中使用mT5提供了有价值的见解，并强调了其作为一种可行解决方案的潜力。如需复制，请参阅https://github.com/unicamp-dl/NeuCLIR22-mT5。",
    "tldr": "本研究发现尽管mT5模型仅在相同语言的查询-文档对上进行微调，但在不同语言的查询-文档对存在的情况下也是可行的。研究结果表明，在所有任务和语言上都表现出色，获得了很高的获胜位置，强调了其作为一种跨语言检索的可行解决方案的潜力。"
}