{
    "title": "Investigating Failures to Generalize for Coreference Resolution Models. (arXiv:2303.09092v1 [cs.CL])",
    "abstract": "Coreference resolution models are often evaluated on multiple datasets. Datasets vary, however, in how coreference is realized -- i.e., how the theoretical concept of coreference is operationalized in the dataset -- due to factors such as the choice of corpora and annotation guidelines. We investigate the extent to which errors of current coreference resolution models are associated with existing differences in operationalization across datasets (OntoNotes, PreCo, and Winogrande). Specifically, we distinguish between and break down model performance into categories corresponding to several types of coreference, including coreferring generic mentions, compound modifiers, and copula predicates, among others. This break down helps us investigate how state-of-the-art models might vary in their ability to generalize across different coreference types. In our experiments, for example, models trained on OntoNotes perform poorly on generic mentions and copula predicates in PreCo. Our findings ",
    "link": "http://arxiv.org/abs/2303.09092",
    "context": "Title: Investigating Failures to Generalize for Coreference Resolution Models. (arXiv:2303.09092v1 [cs.CL])\nAbstract: Coreference resolution models are often evaluated on multiple datasets. Datasets vary, however, in how coreference is realized -- i.e., how the theoretical concept of coreference is operationalized in the dataset -- due to factors such as the choice of corpora and annotation guidelines. We investigate the extent to which errors of current coreference resolution models are associated with existing differences in operationalization across datasets (OntoNotes, PreCo, and Winogrande). Specifically, we distinguish between and break down model performance into categories corresponding to several types of coreference, including coreferring generic mentions, compound modifiers, and copula predicates, among others. This break down helps us investigate how state-of-the-art models might vary in their ability to generalize across different coreference types. In our experiments, for example, models trained on OntoNotes perform poorly on generic mentions and copula predicates in PreCo. Our findings ",
    "path": "papers/23/03/2303.09092.json",
    "total_tokens": 896,
    "translated_title": "探究指代消解模型推广失败的原因",
    "translated_abstract": "指代消解模型通常会在多个数据集上进行评估。然而，数据集在如何实现指代消解方面（即理论概念在数据集中的操作化方式）上存在差异，这是由于选择语料库和注释指南等因素所致。本文旨在调查当前指代消解模型的错误程度与数据集之间的实现差异之间的关联程度（OntoNotes、PreCo和Winogrande）。具体而言，我们将模型性能分为多个类别，对应于多种指代，包括一般性提及、复合修饰符和连系谓词等。这种分类有助于我们调查最先进的模型在跨越不同指代类型的泛化能力方面可能会出现哪些差异。例如，在我们的实验中，在OntoNotes上训练的模型在PreCo中一般性提及和连系谓词上表现不佳。我们的发现强调了在多样化数据集和指代消解操作化方面评估指代消解模型的重要性。",
    "tldr": "本文研究了不同数据集上指代消解模型的表现，并发现模型的表现可能会受到数据集不同的操作化方式的影响，强调了在不同数据集上评估指代消解模型的重要性。",
    "en_tdlr": "This paper investigates the association between errors of coreference resolution models and differences in operationalization across datasets, highlighting the importance of evaluating models on diverse datasets and operationalizations."
}