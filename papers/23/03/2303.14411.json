{
    "title": "Fairness meets Cross-Domain Learning: a new perspective on Models and Metrics. (arXiv:2303.14411v1 [cs.CV])",
    "abstract": "Deep learning-based recognition systems are deployed at scale for several real-world applications that inevitably involve our social life. Although being of great support when making complex decisions, they might capture spurious data correlations and leverage sensitive attributes (e.g. age, gender, ethnicity). How to factor out this information while keeping a high prediction performance is a task with still several open questions, many of which are shared with those of the domain adaptation and generalization literature which focuses on avoiding visual domain biases. In this work, we propose an in-depth study of the relationship between cross-domain learning (CD) and model fairness by introducing a benchmark on face and medical images spanning several demographic groups as well as classification and localization tasks. After having highlighted the limits of the current evaluation metrics, we introduce a new Harmonic Fairness (HF) score to assess jointly how fair and accurate every mo",
    "link": "http://arxiv.org/abs/2303.14411",
    "context": "Title: Fairness meets Cross-Domain Learning: a new perspective on Models and Metrics. (arXiv:2303.14411v1 [cs.CV])\nAbstract: Deep learning-based recognition systems are deployed at scale for several real-world applications that inevitably involve our social life. Although being of great support when making complex decisions, they might capture spurious data correlations and leverage sensitive attributes (e.g. age, gender, ethnicity). How to factor out this information while keeping a high prediction performance is a task with still several open questions, many of which are shared with those of the domain adaptation and generalization literature which focuses on avoiding visual domain biases. In this work, we propose an in-depth study of the relationship between cross-domain learning (CD) and model fairness by introducing a benchmark on face and medical images spanning several demographic groups as well as classification and localization tasks. After having highlighted the limits of the current evaluation metrics, we introduce a new Harmonic Fairness (HF) score to assess jointly how fair and accurate every mo",
    "path": "papers/23/03/2303.14411.json",
    "total_tokens": 1133,
    "translated_title": "公平性与跨领域学习: 模型和指标的新视角",
    "translated_abstract": "基于深度学习的识别系统在多个现实世界中得到广泛应用，这些应用不可避免地涉及到我们的社会生活。虽然在做出复杂决策时具有很大的帮助，但是它们可能捕捉到虚假的数据相关性并利用敏感的属性(例如年龄，性别，种族)。如何在保持高预测性能的同时剔除这些信息，是一个仍然存在许多问题的任务，其中许多问题与领域适应和泛化文献的问题相同，后者专注于避免视觉领域偏差。在本文中，我们在跨领域学习(CD)和模型公正性之间提出了一项深入研究，引入了一项面向跨群体和医学图像的基准和分类和定位任务。在强调当前评估指标的局限性之后，我们引入了一种新的和谐公正(HF)得分，共同评估每个模型的公平性和准确性。我们展示了：i）存在公平性和准确性之间的权衡；ii）当前最先进的模型更有倾向于使用大多数人群做训练数据；iii）公平模型与不公平模型的表现相似。最后，我们提出了一些可能指向更稳健和公正的CD模型的方向。",
    "tldr": "本研究针对基于深度学习的识别系统的公平性与跨领域学习问题进行了深入研究，提出了一个面向跨领域图像的基准和考虑公平性和准确性的新评估指标，并表明公平模型与不公平模型表现相似。",
    "en_tdlr": "This research proposes an in-depth study of the relationship between cross-domain learning (CD) and model fairness, highlights the limits of current evaluation metrics, and introduces a new Harmonic Fairness (HF) score to assess jointly how fair and accurate every model is. The study shows that fair models exhibit similar performances to unfair ones and presents possible directions towards more robust and fair models in CD settings."
}