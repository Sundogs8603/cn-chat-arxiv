{
    "title": "OTOV2: Automatic, Generic, User-Friendly. (arXiv:2303.06862v2 [cs.CV] UPDATED)",
    "abstract": "The existing model compression methods via structured pruning typically require complicated multi-stage procedures. Each individual stage necessitates numerous engineering efforts and domain-knowledge from the end-users which prevent their wider applications onto broader scenarios. We propose the second generation of Only-Train-Once (OTOv2), which first automatically trains and compresses a general DNN only once from scratch to produce a more compact model with competitive performance without fine-tuning. OTOv2 is automatic and pluggable into various deep learning applications, and requires almost minimal engineering efforts from the users. Methodologically, OTOv2 proposes two major improvements: (i) Autonomy: automatically exploits the dependency of general DNNs, partitions the trainable variables into Zero-Invariant Groups (ZIGs), and constructs the compressed model; and (ii) Dual Half-Space Projected Gradient (DHSPG): a novel optimizer to more reliably solve structured-sparsity prob",
    "link": "http://arxiv.org/abs/2303.06862",
    "context": "Title: OTOV2: Automatic, Generic, User-Friendly. (arXiv:2303.06862v2 [cs.CV] UPDATED)\nAbstract: The existing model compression methods via structured pruning typically require complicated multi-stage procedures. Each individual stage necessitates numerous engineering efforts and domain-knowledge from the end-users which prevent their wider applications onto broader scenarios. We propose the second generation of Only-Train-Once (OTOv2), which first automatically trains and compresses a general DNN only once from scratch to produce a more compact model with competitive performance without fine-tuning. OTOv2 is automatic and pluggable into various deep learning applications, and requires almost minimal engineering efforts from the users. Methodologically, OTOv2 proposes two major improvements: (i) Autonomy: automatically exploits the dependency of general DNNs, partitions the trainable variables into Zero-Invariant Groups (ZIGs), and constructs the compressed model; and (ii) Dual Half-Space Projected Gradient (DHSPG): a novel optimizer to more reliably solve structured-sparsity prob",
    "path": "papers/23/03/2303.06862.json",
    "total_tokens": 911,
    "translated_title": "OTOV2: 自动化、通用化、用户友好的通用模型压缩方法",
    "translated_abstract": "现有的通过结构化剪枝进行模型压缩的方法通常需要复杂的多阶段过程，每个阶段都需要大量的工程和领域知识，这阻碍了它们在更广泛的场景中的应用。我们提出了第二代 Only-Train-Once (OTOv2) 方法，它可以自动进行训练和压缩通用的深度神经网络，生成具有竞争性能的更紧凑模型，无需微调。OTOv2 自动且可插入各种深度学习应用中，用户几乎不需要进行任何工程化工作。方法上，OTOv2 提出了两个主要改进: (i) 自主性：自动利用通用深度神经网络的依赖性，将可训练的变量分成零不变组 (ZIGs)，并构建压缩模型; (ii) 双半空间投影梯度 (DHSPG)：一种用于更可靠地解决结构稀疏问题的新型优化器。",
    "tldr": "OTOV2是一种自动、通用且易于使用的深度学习模型压缩方法，只需训练一次即可生成性能具有竞争力的更紧凑模型，无需微调，有效简化了模型压缩过程。",
    "en_tdlr": "OTOV2 is an automatic, generic, and user-friendly deep learning model compression method, which can produce a more compact model with competitive performance without fine-tuning after training only once, effectively simplifying the model compression process."
}