{
    "title": "Hardware-Aware Graph Neural Network Automated Design for Edge Computing Platforms. (arXiv:2303.10875v2 [cs.LG] UPDATED)",
    "abstract": "Graph neural networks (GNNs) have emerged as a popular strategy for handling non-Euclidean data due to their state-of-the-art performance. However, most of the current GNN model designs mainly focus on task accuracy, lacking in considering hardware resources limitation and real-time requirements of edge application scenarios. Comprehensive profiling of typical GNN models indicates that their execution characteristics are significantly affected across different computing platforms, which demands hardware awareness for efficient GNN designs. In this work, HGNAS is proposed as the first Hardware-aware Graph Neural Architecture Search framework targeting resource constraint edge devices. By decoupling the GNN paradigm, HGNAS constructs a fine-grained design space and leverages an efficient multi-stage search strategy to explore optimal architectures within a few GPU hours. Moreover, HGNAS achieves hardware awareness during the GNN architecture design by leveraging a hardware performance pr",
    "link": "http://arxiv.org/abs/2303.10875",
    "context": "Title: Hardware-Aware Graph Neural Network Automated Design for Edge Computing Platforms. (arXiv:2303.10875v2 [cs.LG] UPDATED)\nAbstract: Graph neural networks (GNNs) have emerged as a popular strategy for handling non-Euclidean data due to their state-of-the-art performance. However, most of the current GNN model designs mainly focus on task accuracy, lacking in considering hardware resources limitation and real-time requirements of edge application scenarios. Comprehensive profiling of typical GNN models indicates that their execution characteristics are significantly affected across different computing platforms, which demands hardware awareness for efficient GNN designs. In this work, HGNAS is proposed as the first Hardware-aware Graph Neural Architecture Search framework targeting resource constraint edge devices. By decoupling the GNN paradigm, HGNAS constructs a fine-grained design space and leverages an efficient multi-stage search strategy to explore optimal architectures within a few GPU hours. Moreover, HGNAS achieves hardware awareness during the GNN architecture design by leveraging a hardware performance pr",
    "path": "papers/23/03/2303.10875.json",
    "total_tokens": 1112,
    "translated_title": "边缘计算平台上的硬件感知图神经网络自动化设计",
    "translated_abstract": "面对非欧几里德数据的流行策略，图神经网络(GNNs)因其最先进的性能而应运而生。然而，大多数当前的GNN模型设计主要关注任务准确性，缺乏考虑硬件资源限制和边缘应用场景的实时要求。对典型GNN模型的全面分析表明，在不同的计算平台上，它们的执行特性受到了显著的影响，这需要高效的GNN设计与硬件意识。本文提出了HGNAS作为第一个面向资源受限的边缘设备的硬件感知图神经结构搜索框架。通过解耦GNN范式，HGNAS构建了一个精细的设计空间，并利用高效的多阶段搜索策略在数个GPU小时内探索最佳结构。此外，HGNAS通过利用硬件性能预测器，在GNN架构设计中实现了硬件感知。在几个基准数据集上的实验结果表明，HGNAS实现了高效的GNN设计，显著提高了推理速度和减少了内存占用，同时保持竞争性的准确度，相较于手动设计模型而言。",
    "tldr": "本文提出了HGNAS框架，它是第一个面向资源受限的边缘设备的硬件感知图神经结构搜索框架。通过解耦GNN范式，它构建了一个精细的设计空间，并通过利用硬件性能预测器，在GNN架构设计中实现了硬件感知。实验结果表明，HGNAS实现了高效的GNN设计，显著提高了推理速度和减少了内存占用，同时保持竞争性的准确度，相较于手动设计模型而言。"
}