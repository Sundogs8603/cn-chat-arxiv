{
    "title": "A Data-Driven Model-Reference Adaptive Control Approach Based on Reinforcement Learning. (arXiv:2303.09994v1 [eess.SY])",
    "abstract": "Model-reference adaptive systems refer to a consortium of techniques that guide plants to track desired reference trajectories. Approaches based on theories like Lyapunov, sliding surfaces, and backstepping are typically employed to advise adaptive control strategies. The resulting solutions are often challenged by the complexity of the reference model and those of the derived control strategies. Additionally, the explicit dependence of the control strategies on the process dynamics and reference dynamical models may contribute in degrading their efficiency in the face of uncertain or unknown dynamics. A model-reference adaptive solution is developed here for autonomous systems where it solves the Hamilton-Jacobi-Bellman equation of an error-based structure. The proposed approach describes the process with an integral temporal difference equation and solves it using an integral reinforcement learning mechanism. This is done in real-time without knowing or employing the dynamics of eith",
    "link": "http://arxiv.org/abs/2303.09994",
    "context": "Title: A Data-Driven Model-Reference Adaptive Control Approach Based on Reinforcement Learning. (arXiv:2303.09994v1 [eess.SY])\nAbstract: Model-reference adaptive systems refer to a consortium of techniques that guide plants to track desired reference trajectories. Approaches based on theories like Lyapunov, sliding surfaces, and backstepping are typically employed to advise adaptive control strategies. The resulting solutions are often challenged by the complexity of the reference model and those of the derived control strategies. Additionally, the explicit dependence of the control strategies on the process dynamics and reference dynamical models may contribute in degrading their efficiency in the face of uncertain or unknown dynamics. A model-reference adaptive solution is developed here for autonomous systems where it solves the Hamilton-Jacobi-Bellman equation of an error-based structure. The proposed approach describes the process with an integral temporal difference equation and solves it using an integral reinforcement learning mechanism. This is done in real-time without knowing or employing the dynamics of eith",
    "path": "papers/23/03/2303.09994.json",
    "total_tokens": 868,
    "translated_title": "基于强化学习的数据驱动模型参考自适应控制方法",
    "translated_abstract": "模型参考自适应系统是指平衡装置跟踪所需参考轨迹的技术集合。通常采用的方法基于李亚普诺夫、滑动曲面和反馈等理论，指导自适应控制策略。由此得到的解决方案一般都面临参考模型复杂度和控制策略派生的复杂度的挑战。此外，控制策略明确依赖于过程动力学和参考动力学模型，可能会在面对不确定或未知的动态时降低其效率。本文提出了一种自适应解决方案，用于解决基于误差结构的汉密尔顿-雅可比-贝尔曼方程的自主系统。所提出的方法用一个积分时间差分方程来描述过程，并采用一个积分强化学习机制来解决它。这是在不知道或使用任何动态的情况下实时完成的。",
    "tldr": "本文提出了一种基于强化学习的数据驱动模型参考自适应控制方法，用积分时间差分方程描述过程、采用积分强化学习机制解决问题。",
    "en_tdlr": "This paper proposes a data-driven model-reference adaptive control approach based on reinforcement learning. It describes the process with an integral temporal difference equation and solves it using an integral reinforcement learning mechanism."
}