{
    "title": "Differentially Private Neural Tangent Kernels for Privacy-Preserving Data Generation",
    "abstract": "arXiv:2303.01687v2 Announce Type: replace  Abstract: Maximum mean discrepancy (MMD) is a particularly useful distance metric for differentially private data generation: when used with finite-dimensional features it allows us to summarize and privatize the data distribution once, which we can repeatedly use during generator training without further privacy loss. An important question in this framework is, then, what features are useful to distinguish between real and synthetic data distributions, and whether those enable us to generate quality synthetic data. This work considers the using the features of $\\textit{neural tangent kernels (NTKs)}$, more precisely $\\textit{empirical}$ NTKs (e-NTKs). We find that, perhaps surprisingly, the expressiveness of the untrained e-NTK features is comparable to that of the features taken from pre-trained perceptual features using public data. As a result, our method improves the privacy-accuracy trade-off compared to other state-of-the-art methods, w",
    "link": "https://arxiv.org/abs/2303.01687",
    "context": "Title: Differentially Private Neural Tangent Kernels for Privacy-Preserving Data Generation\nAbstract: arXiv:2303.01687v2 Announce Type: replace  Abstract: Maximum mean discrepancy (MMD) is a particularly useful distance metric for differentially private data generation: when used with finite-dimensional features it allows us to summarize and privatize the data distribution once, which we can repeatedly use during generator training without further privacy loss. An important question in this framework is, then, what features are useful to distinguish between real and synthetic data distributions, and whether those enable us to generate quality synthetic data. This work considers the using the features of $\\textit{neural tangent kernels (NTKs)}$, more precisely $\\textit{empirical}$ NTKs (e-NTKs). We find that, perhaps surprisingly, the expressiveness of the untrained e-NTK features is comparable to that of the features taken from pre-trained perceptual features using public data. As a result, our method improves the privacy-accuracy trade-off compared to other state-of-the-art methods, w",
    "path": "papers/23/03/2303.01687.json",
    "total_tokens": 897,
    "translated_title": "差分私有神经切向核用于隐私保护数据生成",
    "translated_abstract": "最大均值差异（MMD）是一种特别有用的距离度量，用于差分私有数据生成：当与有限维特征一起使用时，它允许我们对数据分布进行一次总结和私有化，然后再生成器训练过程中反复使用而无需再次损失隐私。在这个框架中一个重要的问题是，什么样的特征对于区分真实数据分布和合成数据分布是有用的，以及这些特征是否能够帮助我们生成高质量的合成数据。本文考虑使用神经切向核（NTKs）的特征，更准确地说是经验NTKs（e-NTKs）。我们发现，令人惊讶的是，未经训练的e-NTK特征的表达能力与使用公共数据中预先训练的感知特征提取的特征相当。因此，我们的方法相对于其他最先进的方法改善了隐私准确性权衡。",
    "tldr": "本文研究了使用神经切向核（NTKs）的特征来改善隐私-准确性权衡问题，并发现未经训练的e-NTK特征与预先训练的感知特征相当。"
}