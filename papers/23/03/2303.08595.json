{
    "title": "Automatic Attention Pruning: Improving and Automating Model Pruning using Attentions. (arXiv:2303.08595v1 [cs.LG])",
    "abstract": "Pruning is a promising approach to compress deep learning models in order to deploy them on resource-constrained edge devices. However, many existing pruning solutions are based on unstructured pruning, which yields models that cannot efficiently run on commodity hardware; and they often require users to manually explore and tune the pruning process, which is time-consuming and often leads to sub-optimal results. To address these limitations, this paper presents Automatic Attention Pruning (AAP), an adaptive, attention-based, structured pruning approach to automatically generate small, accurate, and hardware-efficient models that meet user objectives. First, it proposes iterative structured pruning using activation-based attention maps to effectively identify and prune unimportant filters. Then, it proposes adaptive pruning policies for automatically meeting the pruning objectives of accuracy-critical, memory-constrained, and latency-sensitive tasks. A comprehensive evaluation shows th",
    "link": "http://arxiv.org/abs/2303.08595",
    "context": "Title: Automatic Attention Pruning: Improving and Automating Model Pruning using Attentions. (arXiv:2303.08595v1 [cs.LG])\nAbstract: Pruning is a promising approach to compress deep learning models in order to deploy them on resource-constrained edge devices. However, many existing pruning solutions are based on unstructured pruning, which yields models that cannot efficiently run on commodity hardware; and they often require users to manually explore and tune the pruning process, which is time-consuming and often leads to sub-optimal results. To address these limitations, this paper presents Automatic Attention Pruning (AAP), an adaptive, attention-based, structured pruning approach to automatically generate small, accurate, and hardware-efficient models that meet user objectives. First, it proposes iterative structured pruning using activation-based attention maps to effectively identify and prune unimportant filters. Then, it proposes adaptive pruning policies for automatically meeting the pruning objectives of accuracy-critical, memory-constrained, and latency-sensitive tasks. A comprehensive evaluation shows th",
    "path": "papers/23/03/2303.08595.json",
    "total_tokens": 897,
    "translated_title": "自动化注意力裁剪：使用注意力改进和自动化模型裁剪",
    "translated_abstract": "裁剪是一种压缩深度学习模型以在资源受限的边缘设备上部署它们的有希望的方法。然而，许多现有的剪枝解决方案基于非结构化剪枝，导致模型在商用硬件上无法高效运行；而且它们经常需要用户手动探索和调整剪枝过程，这是耗费时间且常常导致次优结果的。为了解决这些限制，本文提出了自动化注意力裁剪（AAP），一种自适应、基于注意力的结构化剪枝方法，以自动产生小、准确和硬件有效的模型以满足用户的目标。首先，它提出了使用基于激活的注意力映射进行迭代结构化剪枝来有效地识别和修剪不重要的滤波器。然后，它提出了自适应剪枝策略，以自动满足精度关键、内存受限和延迟敏感任务的剪枝目标。全面的评估显示了 AAP 的优越性。",
    "tldr": "本文提出一种自适应、基于注意力的结构化剪枝方法，以自动产生小、准确和硬件有效的模型以满足用户的目标。",
    "en_tdlr": "This paper proposes an adaptive, attention-based, structured pruning approach to automatically generate small, accurate, and hardware-efficient models that meet user objectives, by using activation-based attention maps for iterative structured pruning and adaptive pruning policies."
}