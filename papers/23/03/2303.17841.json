{
    "title": "A Benchmark Generative Probabilistic Model for Weak Supervised Learning. (arXiv:2303.17841v1 [cs.LG])",
    "abstract": "Finding relevant and high-quality datasets to train machine learning models is a major bottleneck for practitioners. Furthermore, to address ambitious real-world use-cases there is usually the requirement that the data come labelled with high-quality annotations that can facilitate the training of a supervised model. Manually labelling data with high-quality labels is generally a time-consuming and challenging task and often this turns out to be the bottleneck in a machine learning project. Weak Supervised Learning (WSL) approaches have been developed to alleviate the annotation burden by offering an automatic way of assigning approximate labels (pseudo-labels) to unlabelled data based on heuristics, distant supervision and knowledge bases. We apply probabilistic generative latent variable models (PLVMs), trained on heuristic labelling representations of the original dataset, as an accurate, fast and cost-effective way to generate pseudo-labels. We show that the PLVMs achieve state-of-",
    "link": "http://arxiv.org/abs/2303.17841",
    "context": "Title: A Benchmark Generative Probabilistic Model for Weak Supervised Learning. (arXiv:2303.17841v1 [cs.LG])\nAbstract: Finding relevant and high-quality datasets to train machine learning models is a major bottleneck for practitioners. Furthermore, to address ambitious real-world use-cases there is usually the requirement that the data come labelled with high-quality annotations that can facilitate the training of a supervised model. Manually labelling data with high-quality labels is generally a time-consuming and challenging task and often this turns out to be the bottleneck in a machine learning project. Weak Supervised Learning (WSL) approaches have been developed to alleviate the annotation burden by offering an automatic way of assigning approximate labels (pseudo-labels) to unlabelled data based on heuristics, distant supervision and knowledge bases. We apply probabilistic generative latent variable models (PLVMs), trained on heuristic labelling representations of the original dataset, as an accurate, fast and cost-effective way to generate pseudo-labels. We show that the PLVMs achieve state-of-",
    "path": "papers/23/03/2303.17841.json",
    "total_tokens": 989,
    "translated_title": "一种针对弱监督学习的基准生成性概率模型",
    "translated_abstract": "寻找相关高质量的数据集来训练机器学习模型对于实践者来说是一个主要 bottleneck。而且，为了解决野心勃勃实际应用场景下的问题，数据通常需要附带带有高质量注释的标签，以便于监督模型的训练。手动标记具有高质量标签的数据通常是一项耗时且具有挑战性的任务，往往成为机器学习项目的瓶颈。弱监督学习 (WSL) 方法已被开发出来，通过根据启发式、远程监视和知识库来赋予未标记数据大约标签 (伪标签) 的自动方式，从而减轻注释负担。我们应用概率生成隐变量模型 (PLVMs)，在启发式标注表示的原始数据集上进行训练，作为一种生成伪标签的准确、快速、经济的方式。我们展示了 PLVMs 在图像分类中的多个基准数据集上实现了最先进的表现，并展示了它们在自然语言处理中的事件检测任务上的多才多艺。",
    "tldr": "本文提出一种基准生成性概率模型，在启发式标注的原始数据集上训练，生成伪标签作为一种准确、快速、经济的弱监督学习方法，在图像分类和自然语言处理中达到了最先进的表现。",
    "en_tdlr": "This paper proposes a benchmark generative probabilistic model trained on heuristic labeling representations to generate pseudo-labels as an accurate, fast, and cost-effective way of weak supervised learning. It achieves state-of-the-art performance on benchmark datasets in image classification and event detection task in natural language processing."
}