{
    "title": "Physical Deep Reinforcement Learning Towards Safety Guarantee. (arXiv:2303.16860v1 [cs.LG])",
    "abstract": "Deep reinforcement learning (DRL) has achieved tremendous success in many complex decision-making tasks of autonomous systems with high-dimensional state and/or action spaces. However, the safety and stability still remain major concerns that hinder the applications of DRL to safety-critical autonomous systems. To address the concerns, we proposed the Phy-DRL: a physical deep reinforcement learning framework. The Phy-DRL is novel in two architectural designs: i) Lyapunov-like reward, and ii) residual control (i.e., integration of physics-model-based control and data-driven control). The concurrent physical reward and residual control empower the Phy-DRL the (mathematically) provable safety and stability guarantees. Through experiments on the inverted pendulum, we show that the Phy-DRL features guaranteed safety and stability and enhanced robustness, while offering remarkably accelerated training and enlarged reward.",
    "link": "http://arxiv.org/abs/2303.16860",
    "context": "Title: Physical Deep Reinforcement Learning Towards Safety Guarantee. (arXiv:2303.16860v1 [cs.LG])\nAbstract: Deep reinforcement learning (DRL) has achieved tremendous success in many complex decision-making tasks of autonomous systems with high-dimensional state and/or action spaces. However, the safety and stability still remain major concerns that hinder the applications of DRL to safety-critical autonomous systems. To address the concerns, we proposed the Phy-DRL: a physical deep reinforcement learning framework. The Phy-DRL is novel in two architectural designs: i) Lyapunov-like reward, and ii) residual control (i.e., integration of physics-model-based control and data-driven control). The concurrent physical reward and residual control empower the Phy-DRL the (mathematically) provable safety and stability guarantees. Through experiments on the inverted pendulum, we show that the Phy-DRL features guaranteed safety and stability and enhanced robustness, while offering remarkably accelerated training and enlarged reward.",
    "path": "papers/23/03/2303.16860.json",
    "total_tokens": 908,
    "translated_title": "物理深度强化学习保障安全",
    "translated_abstract": "深度强化学习（DRL）在处理高维状态和/或行动空间的自主系统的复杂决策任务方面取得了巨大成功。然而，安全和稳定性仍然是阻碍DRL用于安全关键自主系统的主要问题。为解决这些问题，我们提出了Phy-DRL：一种物理深度强化学习框架。该框架涵盖两个新颖的架构设计：i）类李雅普诺夫奖赏，ii）残差控制（即物理模型控制和数据驱动控制的集成）。同时将物理奖励和残差控制集成于Phy-DRL中，使其具备可证明的安全性和稳定性保障。通过对倒立摆的实验，我们展示了Phy-DRL的保障安全和稳定以及增强的鲁棒性，同时具有明显的训练加速和增加奖励的效果。",
    "tldr": "Phy-DRL是一种物理深度强化学习框架，采用类李雅普诺夫奖赏和残差控制的架构设计，具备可证明的安全性和稳定性保障，实验结果表明其能够提升训练速度和奖励，具有良好的鲁棒性。"
}