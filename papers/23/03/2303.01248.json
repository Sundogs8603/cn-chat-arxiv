{
    "title": "Can ChatGPT Assess Human Personalities? A General Evaluation Framework. (arXiv:2303.01248v3 [cs.CL] UPDATED)",
    "abstract": "Large Language Models (LLMs) especially ChatGPT have produced impressive results in various areas, but their potential human-like psychology is still largely unexplored. Existing works study the virtual personalities of LLMs but rarely explore the possibility of analyzing human personalities via LLMs. This paper presents a generic evaluation framework for LLMs to assess human personalities based on Myers Briggs Type Indicator (MBTI) tests. Specifically, we first devise unbiased prompts by randomly permuting options in MBTI questions and adopt the average testing result to encourage more impartial answer generation. Then, we propose to replace the subject in question statements to enable flexible queries and assessments on different subjects from LLMs. Finally, we re-formulate the question instructions in a manner of correctness evaluation to facilitate LLMs to generate clearer responses. The proposed framework enables LLMs to flexibly assess personalities of different groups of people.",
    "link": "http://arxiv.org/abs/2303.01248",
    "context": "Title: Can ChatGPT Assess Human Personalities? A General Evaluation Framework. (arXiv:2303.01248v3 [cs.CL] UPDATED)\nAbstract: Large Language Models (LLMs) especially ChatGPT have produced impressive results in various areas, but their potential human-like psychology is still largely unexplored. Existing works study the virtual personalities of LLMs but rarely explore the possibility of analyzing human personalities via LLMs. This paper presents a generic evaluation framework for LLMs to assess human personalities based on Myers Briggs Type Indicator (MBTI) tests. Specifically, we first devise unbiased prompts by randomly permuting options in MBTI questions and adopt the average testing result to encourage more impartial answer generation. Then, we propose to replace the subject in question statements to enable flexible queries and assessments on different subjects from LLMs. Finally, we re-formulate the question instructions in a manner of correctness evaluation to facilitate LLMs to generate clearer responses. The proposed framework enables LLMs to flexibly assess personalities of different groups of people.",
    "path": "papers/23/03/2303.01248.json",
    "total_tokens": 935,
    "translated_title": "ChatGPT能评估人类个性吗？一个通用评估框架。",
    "translated_abstract": "大型语言模型（LLMs）尤其是ChatGPT在各个领域都取得了令人印象深刻的成果，但它们潜在的人类化心理特征尚未得到深入探索。现有的研究主要集中在研究LLMs的虚拟个性，而很少探索通过LLMs分析人类个性的可能性。本文提出了一个通用的评估框架，用于基于迈尔斯·布里格斯人格类型指标（MBTI）测试评估LLMs的人类个性。具体而言，我们首先通过随机排列MBTI问题中的选项来设计无偏倚的提示，采用平均测试结果来鼓励更客观的答案生成。然后，我们建议替换问题陈述中的主语，实现对LLMs上不同主体的灵活查询和评估。最后，我们以正确性评估的方式重新构建问题指令，以便促使LLMs生成更清晰的回应。该提出的框架使LLMs能够灵活评估不同群体的个性特点。",
    "tldr": "本文提出了一个通用的评估框架，用于通过LLMs基于MBTI测试评估人类个性。该框架通过设计无偏倚的提示、灵活查询和正确性评估的方式，使LLMs能够灵活评估不同群体的个性特点。",
    "en_tdlr": "This paper presents a generic evaluation framework for Language Models (LLMs) to assess human personalities based on MBTI tests, allowing for flexible assessments of different groups of people using unbiased prompts, flexible queries, and correctness evaluation."
}