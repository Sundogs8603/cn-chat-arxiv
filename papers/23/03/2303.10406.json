{
    "title": "3DQD: Generalized Deep 3D Shape Prior via Part-Discretized Diffusion Process. (arXiv:2303.10406v1 [cs.CV])",
    "abstract": "We develop a generalized 3D shape generation prior model, tailored for multiple 3D tasks including unconditional shape generation, point cloud completion, and cross-modality shape generation, etc. On one hand, to precisely capture local fine detailed shape information, a vector quantized variational autoencoder (VQ-VAE) is utilized to index local geometry from a compactly learned codebook based on a broad set of task training data. On the other hand, a discrete diffusion generator is introduced to model the inherent structural dependencies among different tokens. In the meantime, a multi-frequency fusion module (MFM) is developed to suppress high-frequency shape feature fluctuations, guided by multi-frequency contextual information. The above designs jointly equip our proposed 3D shape prior model with high-fidelity, diverse features as well as the capability of cross-modality alignment, and extensive experiments have demonstrated superior performances on various 3D shape generation ta",
    "link": "http://arxiv.org/abs/2303.10406",
    "context": "Title: 3DQD: Generalized Deep 3D Shape Prior via Part-Discretized Diffusion Process. (arXiv:2303.10406v1 [cs.CV])\nAbstract: We develop a generalized 3D shape generation prior model, tailored for multiple 3D tasks including unconditional shape generation, point cloud completion, and cross-modality shape generation, etc. On one hand, to precisely capture local fine detailed shape information, a vector quantized variational autoencoder (VQ-VAE) is utilized to index local geometry from a compactly learned codebook based on a broad set of task training data. On the other hand, a discrete diffusion generator is introduced to model the inherent structural dependencies among different tokens. In the meantime, a multi-frequency fusion module (MFM) is developed to suppress high-frequency shape feature fluctuations, guided by multi-frequency contextual information. The above designs jointly equip our proposed 3D shape prior model with high-fidelity, diverse features as well as the capability of cross-modality alignment, and extensive experiments have demonstrated superior performances on various 3D shape generation ta",
    "path": "papers/23/03/2303.10406.json",
    "total_tokens": 1024,
    "translated_title": "3DQD: 基于部分离散扩散过程的广义深度三维形状先验模型",
    "translated_abstract": "我们开发了一个广义的三维形状生成先验模型，专门针对多种三维任务，包括无条件形状生成、点云完成和跨模态形状生成等。一方面，为了精确捕获局部精细的形状信息，我们使用向量量化变分自编码器（VQ-VAE）来基于广泛的任务训练数据学习紧凑的码本并索引本地几何信息。另一方面，我们引入了离散扩散生成器来建模不同标记之间固有的结构依赖性。同时，我们开发了一个多频率融合模块（MFM），以多频率上下文信息为指导，抑制高频形状特征的波动。上述设计共同配备了我们提出的三维形状先验模型高保真度、多样性特征和跨模态对齐的能力，广泛的实验表明，在各种三维形状生成任务上表现出优异的性能。",
    "tldr": "该论文提出了一种广义的深度三维形状先验模型，可以用于多种三维任务，其使用向量量化变分自编码器和离散扩散生成器来精确捕获局部精细的形状信息，并引入多频率融合模块来抑制高频形状特征波动，广泛实验表明其在各种三维形状生成任务上表现出优异的性能。",
    "en_tdlr": "This paper proposes a generalized deep 3D shape prior model applicable for multiple tasks such as shape generation, point cloud completion and cross-modality shape generation. The model utilizes vector quantized variational autoencoder and discrete diffusion generator to capture local fine detailed shape information and structural dependencies, respectively. Additionally, a multi-frequency fusion module is introduced to suppress high-frequency feature fluctuations. Experimental results demonstrate superior performance in various 3D shape generation tasks."
}