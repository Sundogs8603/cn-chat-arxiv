{
    "title": "W2KPE: Keyphrase Extraction with Word-Word Relation. (arXiv:2303.13463v1 [cs.CL])",
    "abstract": "This paper describes our submission to ICASSP 2023 MUG Challenge Track 4, Keyphrase Extraction, which aims to extract keyphrases most relevant to the conference theme from conference materials. We model the challenge as a single-class Named Entity Recognition task and developed techniques for better performance on the challenge: For the data preprocessing, we encode the split keyphrases after word segmentation. In addition, we increase the amount of input information that the model can accept at one time by fusing multiple preprocessed sentences into one segment. We replace the loss function with the multi-class focal loss to address the sparseness of keyphrases. Besides, we score each appearance of keyphrases and add an extra output layer to fit the score to rank keyphrases. Exhaustive evaluations are performed to find the best combination of the word segmentation tool, the pre-trained embedding model, and the corresponding hyperparameters. With these proposals, we scored 45.04 on the",
    "link": "http://arxiv.org/abs/2303.13463",
    "context": "Title: W2KPE: Keyphrase Extraction with Word-Word Relation. (arXiv:2303.13463v1 [cs.CL])\nAbstract: This paper describes our submission to ICASSP 2023 MUG Challenge Track 4, Keyphrase Extraction, which aims to extract keyphrases most relevant to the conference theme from conference materials. We model the challenge as a single-class Named Entity Recognition task and developed techniques for better performance on the challenge: For the data preprocessing, we encode the split keyphrases after word segmentation. In addition, we increase the amount of input information that the model can accept at one time by fusing multiple preprocessed sentences into one segment. We replace the loss function with the multi-class focal loss to address the sparseness of keyphrases. Besides, we score each appearance of keyphrases and add an extra output layer to fit the score to rank keyphrases. Exhaustive evaluations are performed to find the best combination of the word segmentation tool, the pre-trained embedding model, and the corresponding hyperparameters. With these proposals, we scored 45.04 on the",
    "path": "papers/23/03/2303.13463.json",
    "total_tokens": 909,
    "translated_title": "W2KPE：基于词-词关系的关键词抽取",
    "translated_abstract": "本文介绍了我们在ICASSP 2023 MUG Challenge Track 4——关键词提取方面的提交，旨在从会议资料中提取与会议主题最相关的关键词。我们将此挑战建模为单一类别的命名实体识别任务，并开发了更好的表现技术：对于数据预处理，我们在单词分割后对拆分的关键词进行编码。此外，我们通过将多个预处理句子融合为一个片段来增加模型可以同时接受的输入信息量。我们用多类聚焦损失函数替换损失函数，以解决关键词稀疏性问题。此外，我们对每个出现的关键词进行评分，并添加了额外的输出层以适应得分并排列关键词。我们进行了全面的评估，以找到单词分割工具、预训练嵌入模型和相应超参数的最佳组合。通过这些建议，我们在挑战中得分为45.04分。",
    "tldr": "本文提出了W2KPE算法用于关键词抽取。该算法在单一类别的命名实体识别任务中得分为45.04分，并使用了词-词关系、多类聚焦损失函数以及关键词评分等策略。",
    "en_tdlr": "The paper proposes the W2KPE algorithm for keyphrase extraction, achieving a score of 45.04 in a single-class named entity recognition task by utilizing word-word relations, multi-class focal loss function, and keyphrase scoring."
}