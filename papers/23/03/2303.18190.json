{
    "title": "Assessing Language Model Deployment with Risk Cards. (arXiv:2303.18190v1 [cs.CL])",
    "abstract": "This paper introduces RiskCards, a framework for structured assessment and documentation of risks associated with an application of language models. As with all language, text generated by language models can be harmful, or used to bring about harm. Automating language generation adds both an element of scale and also more subtle or emergent undesirable tendencies to the generated text. Prior work establishes a wide variety of language model harms to many different actors: existing taxonomies identify categories of harms posed by language models; benchmarks establish automated tests of these harms; and documentation standards for models, tasks and datasets encourage transparent reporting. However, there is no risk-centric framework for documenting the complexity of a landscape in which some risks are shared across models and contexts, while others are specific, and where certain conditions may be required for risks to manifest as harms. RiskCards address this methodological gap by prov",
    "link": "http://arxiv.org/abs/2303.18190",
    "context": "Title: Assessing Language Model Deployment with Risk Cards. (arXiv:2303.18190v1 [cs.CL])\nAbstract: This paper introduces RiskCards, a framework for structured assessment and documentation of risks associated with an application of language models. As with all language, text generated by language models can be harmful, or used to bring about harm. Automating language generation adds both an element of scale and also more subtle or emergent undesirable tendencies to the generated text. Prior work establishes a wide variety of language model harms to many different actors: existing taxonomies identify categories of harms posed by language models; benchmarks establish automated tests of these harms; and documentation standards for models, tasks and datasets encourage transparent reporting. However, there is no risk-centric framework for documenting the complexity of a landscape in which some risks are shared across models and contexts, while others are specific, and where certain conditions may be required for risks to manifest as harms. RiskCards address this methodological gap by prov",
    "path": "papers/23/03/2303.18190.json",
    "total_tokens": 964,
    "translated_title": "使用风险卡评估语言模型部署",
    "translated_abstract": "本文介绍了RiskCards框架，它是一种用于结构化评估和记录与语言模型应用相关风险的框架。与所有语言一样，由语言模型生成的文本可能是有害的，或用于造成伤害。自动化语言生成不仅增加了规模的因素，还使生成的文本具有更微妙或突发的不良趋势。之前的工作确定了许多不同角色所面临的各种语言模型的危害。现有的分类法确定了语言模型所造成的各种危害类别；基准测试确立了对这些危害的自动化测试；而对模型、任务和数据集的文档标准则鼓励透明报告。然而，目前没有一个以风险为中心的框架，用于记录一个复杂的风险局势，其中某些风险跨越模型和环境，而其他风险则是特定的，其中某些条件可能需要才能将风险转化为危害。RiskCards通过提供一种系统方法来确定、评估和记录与语言模型部署相关的风险，并向技术和非技术相关者传达这些风险，填补了这个方法论上的空白。",
    "tldr": "本文提出了一个名为RiskCards的框架，用于系统地评估和记录与语言模型应用相关的各种风险，并将这些风险传达给技术和非技术相关者。",
    "en_tdlr": "This paper proposes a framework called RiskCards for systematically assessing and documenting risks associated with language model deployment, and communicating these risks to both technical and non-technical stakeholders."
}