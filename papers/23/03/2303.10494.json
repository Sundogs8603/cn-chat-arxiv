{
    "title": "Revisiting the Plastic Surgery Hypothesis via Large Language Models. (arXiv:2303.10494v1 [cs.SE])",
    "abstract": "Automated Program Repair (APR) aspires to automatically generate patches for an input buggy program. Traditional APR tools typically focus on specific bug types and fixes through the use of templates, heuristics, and formal specifications. However, these techniques are limited in terms of the bug types and patch variety they can produce. As such, researchers have designed various learning-based APR tools with recent work focused on directly using Large Language Models (LLMs) for APR. While LLM-based APR tools are able to achieve state-of-the-art performance on many repair datasets, the LLMs used for direct repair are not fully aware of the project-specific information such as unique variable or method names.  The plastic surgery hypothesis is a well-known insight for APR, which states that the code ingredients to fix the bug usually already exist within the same project. Traditional APR tools have largely leveraged the plastic surgery hypothesis by designing manual or heuristic-based a",
    "link": "http://arxiv.org/abs/2303.10494",
    "context": "Title: Revisiting the Plastic Surgery Hypothesis via Large Language Models. (arXiv:2303.10494v1 [cs.SE])\nAbstract: Automated Program Repair (APR) aspires to automatically generate patches for an input buggy program. Traditional APR tools typically focus on specific bug types and fixes through the use of templates, heuristics, and formal specifications. However, these techniques are limited in terms of the bug types and patch variety they can produce. As such, researchers have designed various learning-based APR tools with recent work focused on directly using Large Language Models (LLMs) for APR. While LLM-based APR tools are able to achieve state-of-the-art performance on many repair datasets, the LLMs used for direct repair are not fully aware of the project-specific information such as unique variable or method names.  The plastic surgery hypothesis is a well-known insight for APR, which states that the code ingredients to fix the bug usually already exist within the same project. Traditional APR tools have largely leveraged the plastic surgery hypothesis by designing manual or heuristic-based a",
    "path": "papers/23/03/2303.10494.json",
    "total_tokens": 864,
    "translated_title": "通过大型语言模型重新审视整形手术假设",
    "translated_abstract": "自动化程序修复（APR）旨在自动生成输入错误程序的补丁。传统APR工具通常专注于特定的错误类型和修复方式，通过使用模板、启发式和正式规范。然而，这些技术在错误类型和修补程序的多样化方面存在限制。因此，研究人员设计了各种基于学习的APR工具，最近的工作集中在直接使用大型语言模型（LLMs）进行APR。虽然基于LLM的APR工具能够在许多修复数据集上实现最先进的性能，但用于直接修复的LLMs并没有完全了解项目特定信息，如独特的变量或方法名称。整形手术假设是APR的一个著名的见解，它指出修复错误的代码部分通常已经存在于同一项目中。传统的APR工具主要通过设计手动或基于启发的方法来利用整形手术假设。",
    "tldr": "本论文重新审视了自动程序修复中的整形手术假设，并提出使用大型语言模型进行APR的新方法，主要解决了传统APR工具在不同项目中无法产生多样化修补程序的问题。"
}