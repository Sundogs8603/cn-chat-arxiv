{
    "title": "FPTN: Fast Pure Transformer Network for Traffic Flow Forecasting. (arXiv:2303.07685v1 [cs.LG])",
    "abstract": "Traffic flow forecasting is challenging due to the intricate spatio-temporal correlations in traffic flow data. Existing Transformer-based methods usually treat traffic flow forecasting as multivariate time series (MTS) forecasting. However, too many sensors can cause a vector with a dimension greater than 800, which is difficult to process without information loss. In addition, these methods design complex mechanisms to capture spatial dependencies in MTS, resulting in slow forecasting speed. To solve the abovementioned problems, we propose a Fast Pure Transformer Network (FPTN) in this paper. First, the traffic flow data are divided into sequences along the sensor dimension instead of the time dimension. Then, to adequately represent complex spatio-temporal correlations, Three types of embeddings are proposed for projecting these vectors into a suitable vector space. After that, to capture the complex spatio-temporal correlations simultaneously in these vectors, we utilize Transforme",
    "link": "http://arxiv.org/abs/2303.07685",
    "total_tokens": 1133,
    "translated_title": "FPTN:快速纯Transformer网络用于交通流量预测",
    "translated_abstract": "由于交通流量数据中的复杂时空相关性，交通流量预测是具有挑战性的。现有的基于Transformer的方法通常将交通流量预测视为多元时间序列（MTS）预测。然而，太多的传感器会导致一个大于800的向量，这很难在不丢失信息的情况下进行处理。此外，这些方法设计了复杂的机制来捕获MTS中的空间依赖关系，导致预测速度缓慢。为了解决上述问题，本文提出了一种快速纯Transformer网络（FPTN）。首先，将交通流量数据沿传感器维度而非时间维度划分为序列。然后，为了充分表示复杂的时空相关性，提出了三种嵌入方式将这些向量投影到适当的向量空间中。之后，为了同时捕获这些向量中的复杂时空相关性，我们利用了Transformer的多头注意机制。最后，使用全连接层输出预测的交通流量。在三个真实交通数据集上的实验结果表明，FPTN不仅实现了最先进的准确性，而且比其他基于Transformer的模型运行速度快几倍。",
    "tldr": "本文提出了一种快速纯Transformer网络（FPTN），将交通流量数据沿传感器维度而非时间维度划分为序列，提出了三种嵌入方式将这些向量投影到适当的向量空间中，然后利用Transformer的多头注意机制捕获复杂时空相关性，使用全连接层输出预测的交通流量，FPTN不仅实现了最先进的准确性，而且运行速度比其他基于Transformer的模型快几倍。",
    "en_tdlr": "This paper proposes a Fast Pure Transformer Network (FPTN) for traffic flow forecasting, which divides traffic flow data into sequences along the sensor dimension, proposes three types of embeddings to project these vectors into a suitable vector space, utilizes Transformer's multi-head attention mechanism to capture complex spatio-temporal correlations, and uses a fully connected layer to output predicted traffic flow. FPTN not only achieves state-of-the-art accuracy but also runs several times faster than other transformer-based models on three real-world traffic datasets."
}