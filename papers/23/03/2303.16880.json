{
    "title": "The Hidden-Manifold Hopfield Model and a learning phase transition. (arXiv:2303.16880v1 [cond-mat.dis-nn])",
    "abstract": "The Hopfield model has a long-standing tradition in statistical physics, being one of the few neural networks for which a theory is available. Extending the theory of Hopfield models for correlated data could help understand the success of deep neural networks, for instance describing how they extract features from data. Motivated by this, we propose and investigate a generalized Hopfield model that we name Hidden-Manifold Hopfield Model: we generate the couplings from $P=\\alpha N$ examples with the Hebb rule using a non-linear transformation of $D=\\alpha_D N$ random vectors that we call factors, with $N$ the number of neurons. Using the replica method, we obtain a phase diagram for the model that shows a phase transition where the factors hidden in the examples become attractors of the dynamics; this phase exists above a critical value of $\\alpha$ and below a critical value of $\\alpha_D$. We call this behaviour learning transition.",
    "link": "http://arxiv.org/abs/2303.16880",
    "context": "Title: The Hidden-Manifold Hopfield Model and a learning phase transition. (arXiv:2303.16880v1 [cond-mat.dis-nn])\nAbstract: The Hopfield model has a long-standing tradition in statistical physics, being one of the few neural networks for which a theory is available. Extending the theory of Hopfield models for correlated data could help understand the success of deep neural networks, for instance describing how they extract features from data. Motivated by this, we propose and investigate a generalized Hopfield model that we name Hidden-Manifold Hopfield Model: we generate the couplings from $P=\\alpha N$ examples with the Hebb rule using a non-linear transformation of $D=\\alpha_D N$ random vectors that we call factors, with $N$ the number of neurons. Using the replica method, we obtain a phase diagram for the model that shows a phase transition where the factors hidden in the examples become attractors of the dynamics; this phase exists above a critical value of $\\alpha$ and below a critical value of $\\alpha_D$. We call this behaviour learning transition.",
    "path": "papers/23/03/2303.16880.json",
    "total_tokens": 841,
    "translated_title": "隐藏流形Hopfield模型及其学习相变",
    "translated_abstract": "Hopfield模型在统计物理学中有着悠久的传统，是少数具有理论基础的神经网络之一。通过将Hopfield模型的理论拓展到相关数据上，可以帮助我们理解深度神经网络的成功，例如描述它们如何从数据中提取特征。出于这个动机，我们提出并研究了一种广义的Hopfield模型，称为隐藏流形Hopfield模型：我们使用称为因子的$D=\\alpha_D N$个随机向量的非线性变换，使用来自$P=\\alpha N$个示例的Hebb规则生成耦合，其中$N$是神经元的数量。使用重复方法，我们获得了该模型的相图，显示出一个相变，其中在示例中隐藏的因子成为动态学的吸引子；这种相存在于关键的$\\alpha$值以上和$\\alpha_D$关键的值以下。我们将这种行为称为学习相变。",
    "tldr": "提出一种称为隐藏流形Hopfield模型的广义Hopfield模型，重点研究了在复杂数据上的应用，发现其中存在着一种学习相变的现象。"
}