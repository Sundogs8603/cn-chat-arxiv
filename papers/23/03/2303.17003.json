{
    "title": "Evaluating GPT-3.5 and GPT-4 Models on Brazilian University Admission Exams. (arXiv:2303.17003v1 [cs.CL])",
    "abstract": "The present study aims to explore the capabilities of Language Models (LMs) in tackling high-stakes multiple-choice tests, represented here by the Exame Nacional do Ensino M\\'edio (ENEM), a multidisciplinary entrance examination widely adopted by Brazilian universities. This exam poses challenging tasks for LMs, since its questions may span into multiple fields of knowledge, requiring understanding of information from diverse domains. For instance, a question may require comprehension of both statistics and biology to be solved. This work analyzed responses generated by GPT-3.5 and GPT-4 models for questions presented in the 2009-2017 exams, as well as for questions of the 2022 exam, which were made public after the training of the models was completed. Furthermore, different prompt strategies were tested, including the use of Chain-of-Thought (CoT) prompts to generate explanations for answers. On the 2022 edition, the best-performing model, GPT-4 with CoT, achieved an accuracy of 87%,",
    "link": "http://arxiv.org/abs/2303.17003",
    "context": "Title: Evaluating GPT-3.5 and GPT-4 Models on Brazilian University Admission Exams. (arXiv:2303.17003v1 [cs.CL])\nAbstract: The present study aims to explore the capabilities of Language Models (LMs) in tackling high-stakes multiple-choice tests, represented here by the Exame Nacional do Ensino M\\'edio (ENEM), a multidisciplinary entrance examination widely adopted by Brazilian universities. This exam poses challenging tasks for LMs, since its questions may span into multiple fields of knowledge, requiring understanding of information from diverse domains. For instance, a question may require comprehension of both statistics and biology to be solved. This work analyzed responses generated by GPT-3.5 and GPT-4 models for questions presented in the 2009-2017 exams, as well as for questions of the 2022 exam, which were made public after the training of the models was completed. Furthermore, different prompt strategies were tested, including the use of Chain-of-Thought (CoT) prompts to generate explanations for answers. On the 2022 edition, the best-performing model, GPT-4 with CoT, achieved an accuracy of 87%,",
    "path": "papers/23/03/2303.17003.json",
    "total_tokens": 923,
    "translated_title": "在巴西大学入学考试中评估GPT-3.5和GPT-4模型",
    "translated_abstract": "本研究旨在探索语言模型（LMs）在应对高风险的多项选择测试中的能力，这里以巴西大学广泛采用的多学科入学考试Exame Nacional do Ensino Médio（ENEM）为例。该考试对LMs提出了挑战，因为其问题可能涉及多个知识领域，需要理解来自不同领域的信息。例如，一个问题可能需要理解统计学和生物学才能解决。本研究分析了GPT-3.5和GPT-4模型对2009年至2017年考试以及2022年公开的考试问题的响应。此外，还测试了不同的提示策略，包括使用Chain-of-Thought（CoT）提示生成答案的解释。在2022年的考试中，表现最佳的模型是GPT-4并使用了CoT，在准确率方面达到了87％。",
    "tldr": "本研究在巴西大学入学考试中评估了GPT-3.5和GPT-4模型，分析了不同提示策略，最终发现GPT-4与Chain-of-Thought提示结合表现最好，在2022年考试中准确率达到了87％。",
    "en_tdlr": "This study evaluates GPT-3.5 and GPT-4 models in the context of Brazilian university admission exams, exploring the use of different prompt strategies, and finding that GPT-4 combined with Chain-of-Thought prompts achieved the highest accuracy of 87% on the 2022 exam."
}