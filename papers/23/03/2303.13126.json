{
    "title": "MagicFusion: Boosting Text-to-Image Generation Performance by Fusing Diffusion Models. (arXiv:2303.13126v1 [cs.CV])",
    "abstract": "The advent of open-source AI communities has produced a cornucopia of powerful text-guided diffusion models that are trained on various datasets. While few explorations have been conducted on ensembling such models to combine their strengths. In this work, we propose a simple yet effective method called Saliency-aware Noise Blending (SNB) that can empower the fused text-guided diffusion models to achieve more controllable generation. Specifically, we experimentally find that the responses of classifier-free guidance are highly related to the saliency of generated images. Thus we propose to trust different models in their areas of expertise by blending the predicted noises of two diffusion models in a saliency-aware manner. SNB is training-free and can be completed within a DDIM sampling process. Additionally, it can automatically align the semantics of two noise spaces without requiring additional annotations such as masks. Extensive experiments show the impressive effectiveness of SNB",
    "link": "http://arxiv.org/abs/2303.13126",
    "context": "Title: MagicFusion: Boosting Text-to-Image Generation Performance by Fusing Diffusion Models. (arXiv:2303.13126v1 [cs.CV])\nAbstract: The advent of open-source AI communities has produced a cornucopia of powerful text-guided diffusion models that are trained on various datasets. While few explorations have been conducted on ensembling such models to combine their strengths. In this work, we propose a simple yet effective method called Saliency-aware Noise Blending (SNB) that can empower the fused text-guided diffusion models to achieve more controllable generation. Specifically, we experimentally find that the responses of classifier-free guidance are highly related to the saliency of generated images. Thus we propose to trust different models in their areas of expertise by blending the predicted noises of two diffusion models in a saliency-aware manner. SNB is training-free and can be completed within a DDIM sampling process. Additionally, it can automatically align the semantics of two noise spaces without requiring additional annotations such as masks. Extensive experiments show the impressive effectiveness of SNB",
    "path": "papers/23/03/2303.13126.json",
    "total_tokens": 845,
    "translated_title": "MagicFusion：通过融合扩散模型提高文本到图像生成的性能",
    "translated_abstract": "开源AI社区的出现产生了一系列强大的基于文本的扩散模型，这些模型训练在各种数据集上。本文提出了一种名为“Saliency-aware Noise Blending (SNB)” 的简单且有效的方法，可以使融合的文本指导扩散模型实现更可控的生成。实验证明分类器自由指导的响应与生成图像的显着性高度相关，因此我们提出了一种在显着性感知的情况下混合两个扩散模型的预测噪声来信任其专业领域的不同模型的方法。SNB是无需训练即可完成的，并且可以在DDIM采样过程中自动对齐两个噪声空间的语义，而无需额外的注释，例如掩模。大量的实验展示了SNB的显着有效性",
    "tldr": "本论文提出了一种名为SNB的方法，该方法集成了两个文本指导扩散模型的噪声预测，以实现更可控的图像生成，同时不需要额外的训练或注释。",
    "en_tdlr": "This paper proposes a method called SNB that integrates the noise predictions of two text-guided diffusion models to achieve more controllable image generation, requiring no additional training or annotation."
}