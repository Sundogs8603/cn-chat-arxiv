{
    "title": "Elastic Weight Removal for Faithful and Abstractive Dialogue Generation. (arXiv:2303.17574v1 [cs.CL])",
    "abstract": "Ideally, dialogue systems should generate responses that are faithful to the knowledge contained in relevant documents. However, many models generate hallucinated responses instead that contradict it or contain unverifiable information. To mitigate such undesirable behaviour, it has been proposed to fine-tune a `negative expert' on negative examples and subtract its parameters from those of a pre-trained model. However, intuitively, this does not take into account that some parameters are more responsible than others in causing hallucinations. Thus, we propose to weigh their individual importance via (an approximation of) the Fisher Information matrix, which measures the uncertainty of their estimate. We call this method Elastic Weight Removal (EWR). We evaluate our method -- using different variants of Flan-T5 as a backbone language model -- on multiple datasets for information-seeking dialogue generation and compare our method with state-of-the-art techniques for faithfulness, such a",
    "link": "http://arxiv.org/abs/2303.17574",
    "context": "Title: Elastic Weight Removal for Faithful and Abstractive Dialogue Generation. (arXiv:2303.17574v1 [cs.CL])\nAbstract: Ideally, dialogue systems should generate responses that are faithful to the knowledge contained in relevant documents. However, many models generate hallucinated responses instead that contradict it or contain unverifiable information. To mitigate such undesirable behaviour, it has been proposed to fine-tune a `negative expert' on negative examples and subtract its parameters from those of a pre-trained model. However, intuitively, this does not take into account that some parameters are more responsible than others in causing hallucinations. Thus, we propose to weigh their individual importance via (an approximation of) the Fisher Information matrix, which measures the uncertainty of their estimate. We call this method Elastic Weight Removal (EWR). We evaluate our method -- using different variants of Flan-T5 as a backbone language model -- on multiple datasets for information-seeking dialogue generation and compare our method with state-of-the-art techniques for faithfulness, such a",
    "path": "papers/23/03/2303.17574.json",
    "total_tokens": 852,
    "translated_title": "适用于忠实和抽象化对话生成的弹性权重去除",
    "translated_abstract": "理想情况下，对话系统应该生成忠实于相关文档中包含的知识的回复。然而，许多模型生成了幻想的响应，其中包含与其相矛盾的信息或不可验证的信息。为了减轻这种不良行为，已经提出了在负面示例上微调“负面专家”，并从预训练模型的参数中减去它的参数。然而，直觉上，这并没有考虑到某些参数比其他参数更负责导致幻觉。因此，我们提出通过（近似）费舍尔信息矩阵来权衡它们的个体重要性，该矩阵衡量其估计的不确定性。我们将此方法称为弹性权重去除（EWR）。我们使用Flan-T5不同变体作为骨干语言模型评估我们的方法，并在多个信息寻求对话生成数据集上比较我们的方法与忠实性的最新技术。",
    "tldr": "EWR方法通过费舍尔信息矩阵权衡语音生成模型中个体参数的重要性，提高对话回复的忠实性，取得了很好的效果。",
    "en_tdlr": "The EWR method improves the faithfulness of dialogue generation by weighing the importance of individual parameters in the speech generation model using the Fisher Information matrix, achieving good results."
}