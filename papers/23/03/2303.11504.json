{
    "title": "Language Model Behavior: A Comprehensive Survey. (arXiv:2303.11504v1 [cs.CL])",
    "abstract": "Transformer language models have received widespread public attention, yet their generated text is often surprising even to NLP researchers. In this survey, we discuss over 250 recent studies of English language model behavior before task-specific fine-tuning. Language models possess basic capabilities in syntax, semantics, pragmatics, world knowledge, and reasoning, but these capabilities are sensitive to specific inputs and surface features. Despite dramatic increases in generated text quality as models scale to hundreds of billions of parameters, the models are still prone to unfactual responses, commonsense errors, memorized text, and social biases. Many of these weaknesses can be framed as over-generalizations or under-generalizations of learned patterns in text. We synthesize recent results to highlight what is currently known about what large language models can and cannot do.",
    "link": "http://arxiv.org/abs/2303.11504",
    "context": "Title: Language Model Behavior: A Comprehensive Survey. (arXiv:2303.11504v1 [cs.CL])\nAbstract: Transformer language models have received widespread public attention, yet their generated text is often surprising even to NLP researchers. In this survey, we discuss over 250 recent studies of English language model behavior before task-specific fine-tuning. Language models possess basic capabilities in syntax, semantics, pragmatics, world knowledge, and reasoning, but these capabilities are sensitive to specific inputs and surface features. Despite dramatic increases in generated text quality as models scale to hundreds of billions of parameters, the models are still prone to unfactual responses, commonsense errors, memorized text, and social biases. Many of these weaknesses can be framed as over-generalizations or under-generalizations of learned patterns in text. We synthesize recent results to highlight what is currently known about what large language models can and cannot do.",
    "path": "papers/23/03/2303.11504.json",
    "total_tokens": 889,
    "translated_title": "语言模型行为：一项全面调查",
    "translated_abstract": "Transformer 语言模型已经受到了广泛的关注，然而它们生成的文本即使对于自然语言处理研究人员来说也常常令人惊讶。在本次调查中，我们讨论了250多个关于英语语言模型行为的最近研究，这些研究在任务特定的微调之前进行。语言模型具有基本的句法、语义、语用、世界知识和推理能力，但这些能力对特定的输入和表面特征很敏感。尽管模型随着参数量的增加而生成的文本质量显著提高，但它们仍然容易出现不实回答、常识错误、记忆化文本和社会偏见。其中许多弱点可以被描述为对文本中所学模式的过度推广或过度泛化。我们综合了最近的结果，突出了目前已知的大型语言模型能够做什么和不能做什么。",
    "tldr": "该论文总结了250多个关于英文语言模型行为的最近研究，发现大型语言模型具有基本的句法、语义、语用、世界知识和推理能力，但容易出现不实回答、常识错误、记忆化文本和社会偏见等弱点。",
    "en_tdlr": "This paper summarizes over 250 recent studies on the behavior of English language models, finding that large language models have basic capabilities in syntax, semantics, pragmatics, world knowledge, and reasoning, but are prone to weaknesses such as unfactual responses, common sense errors, memorized text, and social biases."
}