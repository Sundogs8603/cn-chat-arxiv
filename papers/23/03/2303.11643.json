{
    "title": "Manipulating Transfer Learning for Property Inference. (arXiv:2303.11643v1 [cs.LG])",
    "abstract": "Transfer learning is a popular method for tuning pretrained (upstream) models for different downstream tasks using limited data and computational resources. We study how an adversary with control over an upstream model used in transfer learning can conduct property inference attacks on a victim's tuned downstream model. For example, to infer the presence of images of a specific individual in the downstream training set. We demonstrate attacks in which an adversary can manipulate the upstream model to conduct highly effective and specific property inference attacks (AUC score $> 0.9$), without incurring significant performance loss on the main task. The main idea of the manipulation is to make the upstream model generate activations (intermediate features) with different distributions for samples with and without a target property, thus enabling the adversary to distinguish easily between downstream models trained with and without training examples that have the target property. Our cod",
    "link": "http://arxiv.org/abs/2303.11643",
    "context": "Title: Manipulating Transfer Learning for Property Inference. (arXiv:2303.11643v1 [cs.LG])\nAbstract: Transfer learning is a popular method for tuning pretrained (upstream) models for different downstream tasks using limited data and computational resources. We study how an adversary with control over an upstream model used in transfer learning can conduct property inference attacks on a victim's tuned downstream model. For example, to infer the presence of images of a specific individual in the downstream training set. We demonstrate attacks in which an adversary can manipulate the upstream model to conduct highly effective and specific property inference attacks (AUC score $> 0.9$), without incurring significant performance loss on the main task. The main idea of the manipulation is to make the upstream model generate activations (intermediate features) with different distributions for samples with and without a target property, thus enabling the adversary to distinguish easily between downstream models trained with and without training examples that have the target property. Our cod",
    "path": "papers/23/03/2303.11643.json",
    "total_tokens": 987,
    "translated_title": "利用转移学习来进行属性推断的研究",
    "translated_abstract": "转移学习是一种常用的方法，用于利用有限的数据和计算资源来调整预训练的（上游）模型，用于不同的下游任务。我们研究了一个拥有对用于转移学习中的上游模型进行控制的对手如何对受害者调整的下游模型进行属性推断攻击。我们展示了攻击的情况，即对手可以操纵上游模型进行高效且特定的属性推断攻击（AUC得分>0.9），而不会在主要任务中产生显著的性能损失。操纵的主要思想是使上游模型为具有目标属性的样本生成具有不同分布的激活（中间特征），从而使对手能够轻松区分训练有具有目标属性的样本和没有的样本。我们的代码和实验基于使用卷积神经网络作为上游模型的面部识别任务和ColorFeret数据集作为下游模型的训练集。我们的结果表明，从业者在使用转移学习时需要注意属性推断攻击的可能性，并采取措施来防止此类攻击。",
    "tldr": "本文研究了转移学习中的属性推断攻击，攻击者可以操纵上游模型，对受害者调整的下游模型进行高效且特定的推断攻击，需要注意和防范此类攻击。",
    "en_tdlr": "This paper studies property inference attacks in transfer learning, in which an adversary can manipulate the upstream model to conduct efficient and specific attacks on a victim's tuned downstream model. It is important to be aware of and defend against such attacks."
}