{
    "title": "Online Control Barrier Functions for Decentralized Multi-Agent Navigation. (arXiv:2303.04313v2 [cs.RO] UPDATED)",
    "abstract": "Control barrier functions (CBFs) enable guaranteed safe multi-agent navigation in the continuous domain. The resulting navigation performance, however, is highly sensitive to the underlying hyperparameters. Traditional approaches consider fixed CBFs (where parameters are tuned apriori), and hence, typically do not perform well in cluttered and highly dynamic environments: conservative parameter values can lead to inefficient agent trajectories, or even failure to reach goal positions, whereas aggressive parameter values can lead to infeasible controls. To overcome these issues, in this paper, we propose online CBFs, whereby hyperparameters are tuned in real-time, as a function of what agents perceive in their immediate neighborhood. Since the explicit relationship between CBFs and navigation performance is hard to model, we leverage reinforcement learning to learn CBF-tuning policies in a model-free manner. Because we parameterize the policies with graph neural networks (GNNs), we are ",
    "link": "http://arxiv.org/abs/2303.04313",
    "context": "Title: Online Control Barrier Functions for Decentralized Multi-Agent Navigation. (arXiv:2303.04313v2 [cs.RO] UPDATED)\nAbstract: Control barrier functions (CBFs) enable guaranteed safe multi-agent navigation in the continuous domain. The resulting navigation performance, however, is highly sensitive to the underlying hyperparameters. Traditional approaches consider fixed CBFs (where parameters are tuned apriori), and hence, typically do not perform well in cluttered and highly dynamic environments: conservative parameter values can lead to inefficient agent trajectories, or even failure to reach goal positions, whereas aggressive parameter values can lead to infeasible controls. To overcome these issues, in this paper, we propose online CBFs, whereby hyperparameters are tuned in real-time, as a function of what agents perceive in their immediate neighborhood. Since the explicit relationship between CBFs and navigation performance is hard to model, we leverage reinforcement learning to learn CBF-tuning policies in a model-free manner. Because we parameterize the policies with graph neural networks (GNNs), we are ",
    "path": "papers/23/03/2303.04313.json",
    "total_tokens": 888,
    "translated_title": "在线控制屏障函数用于分散式多智能体导航",
    "translated_abstract": "控制屏障函数(CBF)在连续域中实现了可保证安全的多智能体导航。然而，得到的导航性能高度敏感于底层超参数。传统方法考虑了固定的CBF（参数预先调整），因此通常在杂乱和高动态环境中表现不佳：保守的参数值可能导致代理轨迹低效，甚至无法达到目标位置，而激进的参数值可能导致反应不可行。为了解决这些问题，本文提出了在线CBFs，其中超参数随着代理在其邻近环境中的感知实时调整。由于CBFs和导航性能之间的显式关系很难建模，我们利用强化学习以无模型的方式学习CBF调整策略。由于我们使用图神经网络(GNN)对策略进行参数化，我们可以实时适应不同的环境条件。",
    "tldr": "本文提出了一种在连续域中实现可保证安全的多智能体导航的方法，通过在线调整CBF的超参数来适应不同的环境条件，使用强化学习和图神经网络实现无模型的CBF调整策略。"
}