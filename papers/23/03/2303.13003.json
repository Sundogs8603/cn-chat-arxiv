{
    "title": "Benchmarking the Reliability of Post-training Quantization: a Particular Focus on Worst-case Performance. (arXiv:2303.13003v1 [cs.LG])",
    "abstract": "Post-training quantization (PTQ) is a popular method for compressing deep neural networks (DNNs) without modifying their original architecture or training procedures. Despite its effectiveness and convenience, the reliability of PTQ methods in the presence of some extrem cases such as distribution shift and data noise remains largely unexplored. This paper first investigates this problem on various commonly-used PTQ methods. We aim to answer several research questions related to the influence of calibration set distribution variations, calibration paradigm selection, and data augmentation or sampling strategies on PTQ reliability. A systematic evaluation process is conducted across a wide range of tasks and commonly-used PTQ paradigms. The results show that most existing PTQ methods are not reliable enough in term of the worst-case group performance, highlighting the need for more robust methods. Our findings provide insights for developing PTQ methods that can effectively handle distr",
    "link": "http://arxiv.org/abs/2303.13003",
    "context": "Title: Benchmarking the Reliability of Post-training Quantization: a Particular Focus on Worst-case Performance. (arXiv:2303.13003v1 [cs.LG])\nAbstract: Post-training quantization (PTQ) is a popular method for compressing deep neural networks (DNNs) without modifying their original architecture or training procedures. Despite its effectiveness and convenience, the reliability of PTQ methods in the presence of some extrem cases such as distribution shift and data noise remains largely unexplored. This paper first investigates this problem on various commonly-used PTQ methods. We aim to answer several research questions related to the influence of calibration set distribution variations, calibration paradigm selection, and data augmentation or sampling strategies on PTQ reliability. A systematic evaluation process is conducted across a wide range of tasks and commonly-used PTQ paradigms. The results show that most existing PTQ methods are not reliable enough in term of the worst-case group performance, highlighting the need for more robust methods. Our findings provide insights for developing PTQ methods that can effectively handle distr",
    "path": "papers/23/03/2303.13003.json",
    "total_tokens": 1020,
    "translated_title": "后训练量化的可靠性基准测试：特别关注最劣情况下的性能表现",
    "translated_abstract": "后训练量化（PTQ）是一种流行的方法，用于压缩深度神经网络（DNNs），而不改变其原始结构或训练过程。尽管其有效性和便利性，但在存在某些极端情况（如分布偏移和数据噪声）下，PTQ方法的可靠性仍然很少被探索。本文首先在各种常用的PTQ方法上调查了这个问题。我们旨在回答与校准集分布变化、校准范式选择以及数据增强或采样策略对PTQ可靠性的影响相关的几个研究问题。在广泛的任务和常用的PTQ范例上进行了系统评估。结果显示，大多数现有的PTQ方法在最劣情况下的性能表现不够可靠，突出了需要更加强大的PTQ方法的需要。我们的发现为开发能够有效处理分布偏移和数据噪声，并改善PTQ方法最劣情况下性能的PTQ方法提供了一些见解。",
    "tldr": "本论文探讨了后训练量化方法在极端情况下的可靠性问题，并在常用的PTQ方法上开展了系统评估。结果表明，大多数现有的PTQ方法在最劣情况下的性能表现不够可靠。因此需要开发更加强大的PTQ方法，以有效处理分布偏移和数据噪声，并改善最劣情况下的性能表现。",
    "en_tdlr": "This paper investigates the reliability of post-training quantization (PTQ) methods and conducts a systematic evaluation of commonly-used PTQ methods under various extreme cases such as distribution shift and data noise. Results suggest that most existing PTQ methods are not reliable enough in terms of worst-case performance, highlighting the need for more robust methods to handle distribution shift and data noise."
}