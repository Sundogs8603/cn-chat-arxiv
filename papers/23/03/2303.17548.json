{
    "title": "Whose Opinions Do Language Models Reflect?. (arXiv:2303.17548v1 [cs.CL])",
    "abstract": "Language models (LMs) are increasingly being used in open-ended contexts, where the opinions reflected by LMs in response to subjective queries can have a profound impact, both on user satisfaction, as well as shaping the views of society at large. In this work, we put forth a quantitative framework to investigate the opinions reflected by LMs -- by leveraging high-quality public opinion polls and their associated human responses. Using this framework, we create OpinionsQA, a new dataset for evaluating the alignment of LM opinions with those of 60 US demographic groups over topics ranging from abortion to automation. Across topics, we find substantial misalignment between the views reflected by current LMs and those of US demographic groups: on par with the Democrat-Republican divide on climate change. Notably, this misalignment persists even after explicitly steering the LMs towards particular demographic groups. Our analysis not only confirms prior observations about the left-leaning",
    "link": "http://arxiv.org/abs/2303.17548",
    "context": "Title: Whose Opinions Do Language Models Reflect?. (arXiv:2303.17548v1 [cs.CL])\nAbstract: Language models (LMs) are increasingly being used in open-ended contexts, where the opinions reflected by LMs in response to subjective queries can have a profound impact, both on user satisfaction, as well as shaping the views of society at large. In this work, we put forth a quantitative framework to investigate the opinions reflected by LMs -- by leveraging high-quality public opinion polls and their associated human responses. Using this framework, we create OpinionsQA, a new dataset for evaluating the alignment of LM opinions with those of 60 US demographic groups over topics ranging from abortion to automation. Across topics, we find substantial misalignment between the views reflected by current LMs and those of US demographic groups: on par with the Democrat-Republican divide on climate change. Notably, this misalignment persists even after explicitly steering the LMs towards particular demographic groups. Our analysis not only confirms prior observations about the left-leaning",
    "path": "papers/23/03/2303.17548.json",
    "total_tokens": 970,
    "translated_title": "语言模型反映了谁的观点？",
    "translated_abstract": "语言模型（LM）在越来越多的开放环境中被使用，在针对主观查询的响应中反映的观点可能会对用户满意度产生深远影响，同时也可能塑造整个社会的观点。本文提出了一个定量框架，以调查LM反映的观点。我们利用高质量的公共民意调查和相关的人类反应来创建OpinionsQA，并对60个美国人口统计组的意见进行评估，并涉及从堕胎到自动化的各种话题。在各个话题上，我们发现当前LM反映的观点与美国人群组之间存在重大差异，这与民主党和共和党在气候变化问题上的分歧差不多。值得注意的是，即使明确将LM定向于特定的人口统计组，这种差异仍然存在。我们的分析不仅确认了先前对左倾倾向的观察结果，同时提出了这种差异的一个全新的理论解释。",
    "tldr": "本文通过调查高质量的公共民意调查来创建一个新的数据集OpinionsQA，评估语言模型反映的观点与60个不同人口统计组的观点之间的一致性，发现当前语言模型反映的观点与美国人群组的观点存在巨大差异，甚至通过明确调整LM反映出的观点，仍然无法消除。",
    "en_tdlr": "This paper creates a framework to investigate the alignment of opinions reflected by language models (LMs) by leveraging high-quality public opinion polls, and creates a new dataset OpinionsQA for evaluating the consistency of LM opinions with those of 60 different demographic groups. Findings show substantial misalignment between LM opinions and those of US demographic groups, persisting even after explicitly steering the LMs towards particular demographic groups."
}