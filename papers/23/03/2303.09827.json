{
    "title": "DORIC : Domain Robust Fine-Tuning for Open Intent Clustering through Dependency Parsing. (arXiv:2303.09827v1 [cs.CL])",
    "abstract": "We present our work on Track 2 in the Dialog System Technology Challenges 11 (DSTC11). DSTC11-Track2 aims to provide a benchmark for zero-shot, cross-domain, intent-set induction. In the absence of in-domain training dataset, robust utterance representation that can be used across domains is necessary to induce users' intentions. To achieve this, we leveraged a multi-domain dialogue dataset to fine-tune the language model and proposed extracting Verb-Object pairs to remove the artifacts of unnecessary information. Furthermore, we devised the method that generates each cluster's name for the explainability of clustered results. Our approach achieved 3rd place in the precision score and showed superior accuracy and normalized mutual information (NMI) score than the baseline model on various domain datasets.",
    "link": "http://arxiv.org/abs/2303.09827",
    "context": "Title: DORIC : Domain Robust Fine-Tuning for Open Intent Clustering through Dependency Parsing. (arXiv:2303.09827v1 [cs.CL])\nAbstract: We present our work on Track 2 in the Dialog System Technology Challenges 11 (DSTC11). DSTC11-Track2 aims to provide a benchmark for zero-shot, cross-domain, intent-set induction. In the absence of in-domain training dataset, robust utterance representation that can be used across domains is necessary to induce users' intentions. To achieve this, we leveraged a multi-domain dialogue dataset to fine-tune the language model and proposed extracting Verb-Object pairs to remove the artifacts of unnecessary information. Furthermore, we devised the method that generates each cluster's name for the explainability of clustered results. Our approach achieved 3rd place in the precision score and showed superior accuracy and normalized mutual information (NMI) score than the baseline model on various domain datasets.",
    "path": "papers/23/03/2303.09827.json",
    "total_tokens": 842,
    "translated_title": "DORIC: 通过依赖解析进行领域鲁棒微调的开放意图聚类",
    "translated_abstract": "我们在Dialog System Technology Challenges 11（DSTC11）的第2轨道上展示了我们的工作。DSTC11-Track2旨在为0-shot，跨领域的意图集归纳提供基准。在没有领域内训练数据集的情况下，需要强大的话语表示，可用于跨领域归纳用户意图。为了实现这一目标，我们利用多领域对话数据集来微调语言模型，并提出提取动词-宾语对以消除不必要信息的方法。此外，我们设计了一种方法，为聚类结果的可解释性生成每个群集的名称。我们的方法在各种领域数据集上展示出了优秀的准确性和标准化互信息（NMI）得分，相较于基线模型，我们在精度得分上获得了第三名。",
    "tldr": "该论文提出了一种名为DORIC的方法，通过利用多领域对话数据集进行微调，提取动词-宾语对以达到消除不必要信息的目的，最终实现了在各种领域数据集上的高精度聚类。",
    "en_tdlr": "The paper proposes a method called DORIC, which leverages a multi-domain dialogue dataset to fine-tune language models and extract Verb-Object pairs to eliminate unnecessary information, achieving high-precision clustering on various domain datasets."
}