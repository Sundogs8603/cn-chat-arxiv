{
    "title": "Jump to Conclusions: Short-Cutting Transformers With Linear Transformations. (arXiv:2303.09435v1 [cs.CL])",
    "abstract": "Transformer-based language models (LMs) create hidden representations of their inputs at every layer, but only use final-layer representations for prediction. This obscures the internal decision-making process of the model and the utility of its intermediate representations. One way to elucidate this is to cast the hidden representations as final representations, bypassing the transformer computation in-between. In this work, we suggest a simple method for such casting, by using linear transformations. We show that our approach produces more accurate approximations than the prevailing practice of inspecting hidden representations from all layers in the space of the final layer. Moreover, in the context of language modeling, our method allows \"peeking\" into early layer representations of GPT-2 and BERT, showing that often LMs already predict the final output in early layers. We then demonstrate the practicality of our method to recent early exit strategies, showing that when aiming, for",
    "link": "http://arxiv.org/abs/2303.09435",
    "context": "Title: Jump to Conclusions: Short-Cutting Transformers With Linear Transformations. (arXiv:2303.09435v1 [cs.CL])\nAbstract: Transformer-based language models (LMs) create hidden representations of their inputs at every layer, but only use final-layer representations for prediction. This obscures the internal decision-making process of the model and the utility of its intermediate representations. One way to elucidate this is to cast the hidden representations as final representations, bypassing the transformer computation in-between. In this work, we suggest a simple method for such casting, by using linear transformations. We show that our approach produces more accurate approximations than the prevailing practice of inspecting hidden representations from all layers in the space of the final layer. Moreover, in the context of language modeling, our method allows \"peeking\" into early layer representations of GPT-2 and BERT, showing that often LMs already predict the final output in early layers. We then demonstrate the practicality of our method to recent early exit strategies, showing that when aiming, for",
    "path": "papers/23/03/2303.09435.json",
    "total_tokens": 905,
    "translated_title": "跳跃到结论：用线性变换简化Transformers",
    "translated_abstract": "基于Transformer的语言模型(LMs)在每个层次上都创建其输入的隐藏表示，但只使用最终层的表示进行预测。这使得模型的内部决策过程和中间表示的实用性变得模糊不清。为了阐明这一点，可以将隐藏表示转换为最终表示，绕过中间的Transformer计算。在本文中，我们提出了一种简单的方法，通过使用线性变换来进行这种转换。我们展示了我们的方法产生比目前流行的在最终层空间中检查所有层的隐藏表示的方法更准确的近似结果。此外，在语言建模的上下文中，我们的方法允许“窥视”GPT-2和BERT的早期层表示，显示经常在早期层中LMs已经预测最终输出。然后，我们展示了我们的方法对于最近的早期退出策略的实用性，表明当旨在……(原文截止)",
    "tldr": "本文提出了一种简单的方法，使用线性变换将隐藏表示转换为最终表示，绕过中间的Transformer计算。这种方法在语言模型的上下文中可“窥视”GPT-2和BERT的早期层表示，显示经常在早期层中LMs已经预测最终输出。",
    "en_tdlr": "This paper proposes a simple method to cast hidden representations as final representations by using linear transformations, bypassing the Transformer computation in-between. This method allows \"peeking\" into early layer representations of GPT-2 and BERT in the context of language modeling, showing that often LMs already predict the final output in early layers."
}