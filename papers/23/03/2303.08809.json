{
    "title": "Cascading and Direct Approaches to Unsupervised Constituency Parsing on Spoken Sentences. (arXiv:2303.08809v1 [cs.CL])",
    "abstract": "Past work on unsupervised parsing is constrained to written form. In this paper, we present the first study on unsupervised spoken constituency parsing given unlabeled spoken sentences and unpaired textual data. The goal is to determine the spoken sentences' hierarchical syntactic structure in the form of constituency parse trees, such that each node is a span of audio that corresponds to a constituent. We compare two approaches: (1) cascading an unsupervised automatic speech recognition (ASR) model and an unsupervised parser to obtain parse trees on ASR transcripts, and (2) direct training an unsupervised parser on continuous word-level speech representations. This is done by first splitting utterances into sequences of word-level segments, and aggregating self-supervised speech representations within segments to obtain segment embeddings. We find that separately training a parser on the unpaired text and directly applying it on ASR transcripts for inference produces better results fo",
    "link": "http://arxiv.org/abs/2303.08809",
    "context": "Title: Cascading and Direct Approaches to Unsupervised Constituency Parsing on Spoken Sentences. (arXiv:2303.08809v1 [cs.CL])\nAbstract: Past work on unsupervised parsing is constrained to written form. In this paper, we present the first study on unsupervised spoken constituency parsing given unlabeled spoken sentences and unpaired textual data. The goal is to determine the spoken sentences' hierarchical syntactic structure in the form of constituency parse trees, such that each node is a span of audio that corresponds to a constituent. We compare two approaches: (1) cascading an unsupervised automatic speech recognition (ASR) model and an unsupervised parser to obtain parse trees on ASR transcripts, and (2) direct training an unsupervised parser on continuous word-level speech representations. This is done by first splitting utterances into sequences of word-level segments, and aggregating self-supervised speech representations within segments to obtain segment embeddings. We find that separately training a parser on the unpaired text and directly applying it on ASR transcripts for inference produces better results fo",
    "path": "papers/23/03/2303.08809.json",
    "total_tokens": 906,
    "tldr": "本文研究了对无标签口语和未配对文本数据进行无监督组成分析的两种方法，并发现在未配对文本上训练解析器，并直接应用于ASR转录以进行推断，可以产生更好的结果。",
    "en_tdlr": "This paper presents the first study on unsupervised spoken constituency parsing given unlabeled spoken sentences and unpaired textual data, and compares two approaches to obtain parse trees on ASR transcripts. The author finds that separately training a parser on the unpaired text and directly applying it on ASR transcripts for inference produces better results."
}