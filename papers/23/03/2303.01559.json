{
    "title": "Improving GAN Training via Feature Space Shrinkage. (arXiv:2303.01559v2 [cs.CV] UPDATED)",
    "abstract": "Due to the outstanding capability for data generation, Generative Adversarial Networks (GANs) have attracted considerable attention in unsupervised learning. However, training GANs is difficult, since the training distribution is dynamic for the discriminator, leading to unstable image representation. In this paper, we address the problem of training GANs from a novel perspective, \\emph{i.e.,} robust image classification. Motivated by studies on robust image representation, we propose a simple yet effective module, namely AdaptiveMix, for GANs, which shrinks the regions of training data in the image representation space of the discriminator. Considering it is intractable to directly bound feature space, we propose to construct hard samples and narrow down the feature distance between hard and easy samples. The hard samples are constructed by mixing a pair of training images. We evaluate the effectiveness of our AdaptiveMix with widely-used and state-of-the-art GAN architectures. The ev",
    "link": "http://arxiv.org/abs/2303.01559",
    "context": "Title: Improving GAN Training via Feature Space Shrinkage. (arXiv:2303.01559v2 [cs.CV] UPDATED)\nAbstract: Due to the outstanding capability for data generation, Generative Adversarial Networks (GANs) have attracted considerable attention in unsupervised learning. However, training GANs is difficult, since the training distribution is dynamic for the discriminator, leading to unstable image representation. In this paper, we address the problem of training GANs from a novel perspective, \\emph{i.e.,} robust image classification. Motivated by studies on robust image representation, we propose a simple yet effective module, namely AdaptiveMix, for GANs, which shrinks the regions of training data in the image representation space of the discriminator. Considering it is intractable to directly bound feature space, we propose to construct hard samples and narrow down the feature distance between hard and easy samples. The hard samples are constructed by mixing a pair of training images. We evaluate the effectiveness of our AdaptiveMix with widely-used and state-of-the-art GAN architectures. The ev",
    "path": "papers/23/03/2303.01559.json",
    "total_tokens": 903,
    "translated_title": "通过特征空间收缩改善GAN的训练",
    "translated_abstract": "由于生成式对抗网络（GAN）在数据生成方面的优异能力，它在无监督学习中受到广泛关注。然而，训练GAN是困难的，因为鉴别器的训练分布是动态的，会导致不稳定的图像表示。在本文中，我们从新的角度来解决训练GAN的问题，即鲁棒图像分类。受到鲁棒图像表示研究的启发，我们为GAN提出了一个简单而有效的模块，即AdaptiveMix，它可以在鉴别器的图像表示空间中收缩训练数据的区域。考虑到直接限制特征空间是不可行的，我们提出构建硬样本，并缩小硬样本与易样本之间的特征距离。硬样本是通过混合一对训练图像来构建的。我们评估了我们的AdaptiveMix在广泛使用的和最先进的GAN架构中的有效性。",
    "tldr": "本文提出了一种针对GAN训练的改进方法，即在鉴别器的特征空间中收缩训练数据的区域，构建硬样本并缩小硬样本与易样本之间的特征距离。",
    "en_tdlr": "This paper proposes a novel approach to improving GAN training by shrinking the feature space of the discriminator and constructing hard samples to narrow the feature distance between hard and easy samples. The proposed module, called AdaptiveMix, is evaluated on widely-used and state-of-the-art GAN architectures."
}