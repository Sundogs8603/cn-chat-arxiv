{
    "title": "Causal Temporal Graph Convolutional Neural Networks (CTGCN). (arXiv:2303.09634v1 [cs.LG])",
    "abstract": "Many large-scale applications can be elegantly represented using graph structures. Their scalability, however, is often limited by the domain knowledge required to apply them. To address this problem, we propose a novel Causal Temporal Graph Convolutional Neural Network (CTGCN). Our CTGCN architecture is based on a causal discovery mechanism, and is capable of discovering the underlying causal processes. The major advantages of our approach stem from its ability to overcome computational scalability problems with a divide and conquer technique, and from the greater explainability of predictions made using a causal model. We evaluate the scalability of our CTGCN on two datasets to demonstrate that our method is applicable to large scale problems, and show that the integration of causality into the TGCN architecture improves prediction performance up to 40% over typical TGCN approach. Our results are obtained without requiring additional domain knowledge, making our approach adaptable to",
    "link": "http://arxiv.org/abs/2303.09634",
    "context": "Title: Causal Temporal Graph Convolutional Neural Networks (CTGCN). (arXiv:2303.09634v1 [cs.LG])\nAbstract: Many large-scale applications can be elegantly represented using graph structures. Their scalability, however, is often limited by the domain knowledge required to apply them. To address this problem, we propose a novel Causal Temporal Graph Convolutional Neural Network (CTGCN). Our CTGCN architecture is based on a causal discovery mechanism, and is capable of discovering the underlying causal processes. The major advantages of our approach stem from its ability to overcome computational scalability problems with a divide and conquer technique, and from the greater explainability of predictions made using a causal model. We evaluate the scalability of our CTGCN on two datasets to demonstrate that our method is applicable to large scale problems, and show that the integration of causality into the TGCN architecture improves prediction performance up to 40% over typical TGCN approach. Our results are obtained without requiring additional domain knowledge, making our approach adaptable to",
    "path": "papers/23/03/2303.09634.json",
    "total_tokens": 853,
    "translated_title": "因果时间图卷积神经网络（CTGCN）",
    "translated_abstract": "许多大规模应用程序可以使用图形结构进行优雅表示。但是，它们的可伸缩性通常受到应用所需的领域知识的限制。为了解决这个问题，我们提出了一种新颖的因果时间图卷积神经网络（CTGCN）。我们的CTGCN架构基于因果关系发现机制，并能够发现潜在的因果过程。我们的方法的主要优点在于其能够采用分而治之的技术来克服计算可伸缩性问题，并且使用因果模型进行预测的可解释性更高。我们评估了我们的CTGCN在两个数据集上的可伸缩性，以证明我们的方法适用于大规模问题，并表明将因果性集成到TGCN架构中可以比典型的TGCN方法提高最多40％的预测性能。我们的结果是在不需要额外的领域知识的情况下获得的，因此我们的方法是适应性强的。",
    "tldr": "CTGCN基于因果关系发现机制，利用分而治之的技术克服计算可伸缩性问题，并通过集成因果性提高了对大规模问题的预测能力。"
}