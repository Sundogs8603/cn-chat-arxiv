{
    "title": "Can AI Chatbots Pass the Fundamentals of Engineering (FE) and Principles and Practice of Engineering (PE) Structural Exams?. (arXiv:2303.18149v1 [cs.CL])",
    "abstract": "The engineering community has recently witnessed the emergence of chatbot technology with the release of OpenAI ChatGPT-4 and Google Bard. While these chatbots have been reported to perform well and even pass various standardized tests, including medical and law exams, this forum paper explores whether these chatbots can also pass the Fundamentals of Engineering (FE) and Principles and Practice of Engineering (PE) exams. A diverse range of civil and environmental engineering questions and scenarios are used to evaluate the chatbots' performance, as commonly present in the FE and PE exams. The chatbots' responses were analyzed based on their relevance, accuracy, and clarity and then compared against the recommendations of the National Council of Examiners for Engineering and Surveying (NCEES). Our report shows that ChatGPT-4 and Bard, respectively scored 70.9% and 39.2% in the FE exam and 46.2% and 41% in the PE exam. It is evident that the current version of ChatGPT-4 could potentially",
    "link": "http://arxiv.org/abs/2303.18149",
    "context": "Title: Can AI Chatbots Pass the Fundamentals of Engineering (FE) and Principles and Practice of Engineering (PE) Structural Exams?. (arXiv:2303.18149v1 [cs.CL])\nAbstract: The engineering community has recently witnessed the emergence of chatbot technology with the release of OpenAI ChatGPT-4 and Google Bard. While these chatbots have been reported to perform well and even pass various standardized tests, including medical and law exams, this forum paper explores whether these chatbots can also pass the Fundamentals of Engineering (FE) and Principles and Practice of Engineering (PE) exams. A diverse range of civil and environmental engineering questions and scenarios are used to evaluate the chatbots' performance, as commonly present in the FE and PE exams. The chatbots' responses were analyzed based on their relevance, accuracy, and clarity and then compared against the recommendations of the National Council of Examiners for Engineering and Surveying (NCEES). Our report shows that ChatGPT-4 and Bard, respectively scored 70.9% and 39.2% in the FE exam and 46.2% and 41% in the PE exam. It is evident that the current version of ChatGPT-4 could potentially",
    "path": "papers/23/03/2303.18149.json",
    "total_tokens": 996,
    "translated_title": "AI聊天机器人是否能通过工程基础（FE）和工程原理与实践（PE）结构考试？",
    "translated_abstract": "在工程界，随着OpenAI ChatGPT-4和Google Bard的发布，聊天机器人技术近年来迅速发展。虽然这些聊天机器人被报道表现良好，甚至通过了各种标准化考试，包括医学和法律考试，但本论文探讨这些聊天机器人是否也能通过工程基础（FE）和工程原理与实践（PE）考试。我们使用多样化的土木和环境工程问题和情景来评估聊天机器人的性能，在FE和PE考试中常见。基于相关性、准确性和清晰度，分析了聊天机器人的响应，然后与National Council of Examiners for Engineering and Surveying (NCEES)的建议进行了比较。我们的报告显示，ChatGPT-4和Bard在FE考试中得分分别为70.9％和39.2％，在PE考试中得分分别为46.2％和41％。显然，目前版本的ChatGPT-4有可能通过PE考试，但在FE考试中成绩较低。",
    "tldr": "本论文探讨了AI聊天机器人能否通过工程基础（FE）和工程原理与实践（PE）考试，研究发现ChatGPT-4在FE考试中得分70.9％，在PE考试中得分46.2％，并且有望通过PE考试。",
    "en_tdlr": "This paper investigates whether AI chatbots can pass the Fundamentals of Engineering (FE) and Principles and Practice of Engineering (PE) exams. The study shows that ChatGPT-4 scored 70.9% and 46.2% on the FE and PE exams respectively and has the potential to pass the PE exam."
}