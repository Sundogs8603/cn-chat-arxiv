{
    "title": "Test-time Defense against Adversarial Attacks: Detection and Reconstruction of Adversarial Examples via Masked Autoencoder. (arXiv:2303.12848v1 [cs.CV])",
    "abstract": "Existing defense methods against adversarial attacks can be categorized into training time and test time defenses. Training time defense, i.e., adversarial training, requires a significant amount of extra time for training and is often not able to be generalized to unseen attacks. On the other hand, test time defense by test time weight adaptation requires access to perform gradient descent on (part of) the model weights, which could be infeasible for models with frozen weights. To address these challenges, we propose DRAM, a novel defense method to Detect and Reconstruct multiple types of Adversarial attacks via Masked autoencoder (MAE). We demonstrate how to use MAE losses to build a KS-test to detect adversarial attacks. Moreover, the MAE losses can be used to repair adversarial samples from unseen attack types. In this sense, DRAM neither requires model weight updates in test time nor augments the training set with more adversarial samples. Evaluating DRAM on the large-scale ImageN",
    "link": "http://arxiv.org/abs/2303.12848",
    "context": "Title: Test-time Defense against Adversarial Attacks: Detection and Reconstruction of Adversarial Examples via Masked Autoencoder. (arXiv:2303.12848v1 [cs.CV])\nAbstract: Existing defense methods against adversarial attacks can be categorized into training time and test time defenses. Training time defense, i.e., adversarial training, requires a significant amount of extra time for training and is often not able to be generalized to unseen attacks. On the other hand, test time defense by test time weight adaptation requires access to perform gradient descent on (part of) the model weights, which could be infeasible for models with frozen weights. To address these challenges, we propose DRAM, a novel defense method to Detect and Reconstruct multiple types of Adversarial attacks via Masked autoencoder (MAE). We demonstrate how to use MAE losses to build a KS-test to detect adversarial attacks. Moreover, the MAE losses can be used to repair adversarial samples from unseen attack types. In this sense, DRAM neither requires model weight updates in test time nor augments the training set with more adversarial samples. Evaluating DRAM on the large-scale ImageN",
    "path": "papers/23/03/2303.12848.json",
    "total_tokens": 928,
    "translated_title": "对抗攻击的测试时间防御：基于遮蔽自编码器的对抗样本检测和重构",
    "translated_abstract": "现有的对抗攻击防御方法可以分为训练时间和测试时间防御。训练时间防御需要大量的额外训练时间，通常无法推广到未见过的攻击。而测试时间防御需要访问（部分）模型权重以执行梯度下降，这对于冻结权重的模型可能不可行。为了解决这些挑战，我们提出了一种新的防御方法DRAM，它使用遮蔽自编码器（MAE）检测并重构多种类型的对抗攻击。我们演示了如何使用MAE损失构建KS测试来检测对抗攻击。此外，MAE损失可以用于修复未见攻击类型的对抗样本。因此，DRAM既不需要在测试时间更新模型权重，也不需要使用更多的对抗样本来增强训练集。在大规模的ImageN数据集上评估DRAM，实验结果表明其具有很高的鲁棒性和有效性。",
    "tldr": "该方法使用遮蔽自编码器进行对抗攻击检测和重构，不需要在测试时间更新模型权重，也不需要使用更多的对抗样本来增强训练集。"
}