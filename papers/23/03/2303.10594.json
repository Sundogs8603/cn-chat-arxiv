{
    "title": "AdaptGuard: Defending Against Universal Attacks for Model Adaptation. (arXiv:2303.10594v1 [cs.CR])",
    "abstract": "Model adaptation aims at solving the domain transfer problem under the constraint of only accessing the pretrained source models. With the increasing considerations of data privacy and transmission efficiency, this paradigm has been gaining recent popularity. This paper studies the vulnerability to universal attacks transferred from the source domain during model adaptation algorithms due to the existence of the malicious providers. We explore both universal adversarial perturbations and backdoor attacks as loopholes on the source side and discover that they still survive in the target models after adaptation. To address this issue, we propose a model preprocessing framework, named AdaptGuard, to improve the security of model adaptation algorithms. AdaptGuard avoids direct use of the risky source parameters through knowledge distillation and utilizes the pseudo adversarial samples under adjusted radius to enhance the robustness. AdaptGuard is a plug-and-play module that requires neithe",
    "link": "http://arxiv.org/abs/2303.10594",
    "context": "Title: AdaptGuard: Defending Against Universal Attacks for Model Adaptation. (arXiv:2303.10594v1 [cs.CR])\nAbstract: Model adaptation aims at solving the domain transfer problem under the constraint of only accessing the pretrained source models. With the increasing considerations of data privacy and transmission efficiency, this paradigm has been gaining recent popularity. This paper studies the vulnerability to universal attacks transferred from the source domain during model adaptation algorithms due to the existence of the malicious providers. We explore both universal adversarial perturbations and backdoor attacks as loopholes on the source side and discover that they still survive in the target models after adaptation. To address this issue, we propose a model preprocessing framework, named AdaptGuard, to improve the security of model adaptation algorithms. AdaptGuard avoids direct use of the risky source parameters through knowledge distillation and utilizes the pseudo adversarial samples under adjusted radius to enhance the robustness. AdaptGuard is a plug-and-play module that requires neithe",
    "path": "papers/23/03/2303.10594.json",
    "total_tokens": 912,
    "translated_title": "AdaptGuard: 针对模型适应中的通用攻击进行防御",
    "translated_abstract": "模型适应旨在解决在仅访问已预训练源模型的约束下的域转移问题。随着对数据隐私和传输效率的越来越多关注，这种范式近年来变得越来越流行。本文研究了在模型适应算法中由于恶意提供方的存在而转移自源域的通用攻击的脆弱性。我们探讨了通用对抗扰动和后门攻击作为源侧漏洞的问题，并发现它们在适应后的目标模型中仍然存在。为了解决这个问题，我们提出了一个名为AdaptGuard的模型预处理框架，以提高模型适应算法的安全性。AdaptGuard通过知识蒸馏避免直接使用风险源参数，并利用调整半径下的伪对抗样本来增强鲁棒性。AdaptGuard是一个即插即用的模块，不需要修改现有的模型适应算法。",
    "tldr": "本文研究了模型适应中存在的通用攻击，并提出了一个名为AdaptGuard的模型预处理框架，通过知识蒸馏和伪对抗样本加强目标模型的鲁棒性，提高模型适应算法的安全性。",
    "en_tdlr": "This paper studies the vulnerability to universal attacks transferred from source domain during model adaptation algorithms and proposes a model preprocessing framework, named AdaptGuard, to enhance the robustness of target models via knowledge distillation and pseudo adversarial samples. AdaptGuard is an easy-to-use plug-and-play module that improves the security of model adaptation algorithms."
}