{
    "title": "Uncovering Energy-Efficient Practices in Deep Learning Training: Preliminary Steps Towards Green AI. (arXiv:2303.13972v1 [cs.LG])",
    "abstract": "Modern AI practices all strive towards the same goal: better results. In the context of deep learning, the term \"results\" often refers to the achieved accuracy on a competitive problem set. In this paper, we adopt an idea from the emerging field of Green AI to consider energy consumption as a metric of equal importance to accuracy and to reduce any irrelevant tasks or energy usage. We examine the training stage of the deep learning pipeline from a sustainability perspective, through the study of hyperparameter tuning strategies and the model complexity, two factors vastly impacting the overall pipeline's energy consumption. First, we investigate the effectiveness of grid search, random search and Bayesian optimisation during hyperparameter tuning, and we find that Bayesian optimisation significantly dominates the other strategies. Furthermore, we analyse the architecture of convolutional neural networks with the energy consumption of three prominent layer types: convolutional, linear a",
    "link": "http://arxiv.org/abs/2303.13972",
    "context": "Title: Uncovering Energy-Efficient Practices in Deep Learning Training: Preliminary Steps Towards Green AI. (arXiv:2303.13972v1 [cs.LG])\nAbstract: Modern AI practices all strive towards the same goal: better results. In the context of deep learning, the term \"results\" often refers to the achieved accuracy on a competitive problem set. In this paper, we adopt an idea from the emerging field of Green AI to consider energy consumption as a metric of equal importance to accuracy and to reduce any irrelevant tasks or energy usage. We examine the training stage of the deep learning pipeline from a sustainability perspective, through the study of hyperparameter tuning strategies and the model complexity, two factors vastly impacting the overall pipeline's energy consumption. First, we investigate the effectiveness of grid search, random search and Bayesian optimisation during hyperparameter tuning, and we find that Bayesian optimisation significantly dominates the other strategies. Furthermore, we analyse the architecture of convolutional neural networks with the energy consumption of three prominent layer types: convolutional, linear a",
    "path": "papers/23/03/2303.13972.json",
    "total_tokens": 996,
    "translated_title": "揭示深度学习训练中的节能实践：绿色人工智能的初步步骤。",
    "translated_abstract": "现代AI实践的目标都是相同的：更好的结果。在深度学习的背景下，“结果”通常指完成某个竞争性问题集时达到的准确性。我们采用绿色人工智能这一新兴领域的思想，将能源消耗作为一个同等重要的指标来考虑，并减少任何无关的任务或能量使用。我们从可持续性的角度研究了深度学习管道的训练阶段，通过研究超参数调整策略和模型复杂性这两个对整个管道能源消耗有巨大影响的因素。首先，我们研究了超参数调整期间的网格搜索，随机搜索和贝叶斯优化的有效性，并发现贝叶斯优化明显优于其他策略。此外，我们分析了卷积神经网络的架构，并考虑了三种主要层类型：卷积，线性层和池化层的能量消耗。",
    "tldr": "本文旨在从可持续性的角度研究深度学习管道的训练阶段，并通过研究超参数调整策略和模型复杂性来降低能耗。研究发现，贝叶斯优化在超参数调整中明显优于其他策略。同时，对卷积神经网络的架构进行分析，并考虑了卷积、线性层和池化层的能量消耗。",
    "en_tdlr": "This paper aims to study the training stage of the deep learning pipeline from a sustainability perspective, and reduce energy consumption by exploring hyperparameter tuning strategies and model complexity. Bayesian optimization is found to be significantly better than other strategies. The architecture of convolutional neural networks is also analyzed in terms of energy consumption."
}