{
    "title": "Identifying Label Errors in Object Detection Datasets by Loss Inspection. (arXiv:2303.06999v2 [cs.CV] UPDATED)",
    "abstract": "Labeling datasets for supervised object detection is a dull and time-consuming task. Errors can be easily introduced during annotation and overlooked during review, yielding inaccurate benchmarks and performance degradation of deep neural networks trained on noisy labels. In this work, we for the first time introduce a benchmark for label error detection methods on object detection datasets as well as a label error detection method and a number of baselines. We simulate four different types of randomly introduced label errors on train and test sets of well-labeled object detection datasets. For our label error detection method we assume a two-stage object detector to be given and consider the sum of both stages' classification and regression losses. The losses are computed with respect to the predictions and the noisy labels including simulated label errors, aiming at detecting the latter. We compare our method to three baselines: a naive one without deep learning, the object detector'",
    "link": "http://arxiv.org/abs/2303.06999",
    "context": "Title: Identifying Label Errors in Object Detection Datasets by Loss Inspection. (arXiv:2303.06999v2 [cs.CV] UPDATED)\nAbstract: Labeling datasets for supervised object detection is a dull and time-consuming task. Errors can be easily introduced during annotation and overlooked during review, yielding inaccurate benchmarks and performance degradation of deep neural networks trained on noisy labels. In this work, we for the first time introduce a benchmark for label error detection methods on object detection datasets as well as a label error detection method and a number of baselines. We simulate four different types of randomly introduced label errors on train and test sets of well-labeled object detection datasets. For our label error detection method we assume a two-stage object detector to be given and consider the sum of both stages' classification and regression losses. The losses are computed with respect to the predictions and the noisy labels including simulated label errors, aiming at detecting the latter. We compare our method to three baselines: a naive one without deep learning, the object detector'",
    "path": "papers/23/03/2303.06999.json",
    "total_tokens": 950,
    "translated_title": "通过损失检查在目标检测数据集中识别标签错误",
    "translated_abstract": "为监督目标检测的标签数据集进行标注是一个枯燥且耗时的任务。在注释过程中很容易引入错误，并且在审核过程中可能会被忽视，导致准确度低下的基准和基于噪声标签训练的深度神经网络性能降低。在本研究中，我们首次引入了一个用于目标检测数据集上的标签错误检测方法的基准以及一个标签错误检测方法和一些基线方法。我们在已经标记良好的目标检测数据集的训练集和测试集中模拟了四种不同类型的随机引入的标签错误。对于我们的标签错误检测方法，我们假设已经提供了一个两阶段目标检测器，并考虑两个阶段的分类损失和回归损失的总和。这些损失基于预测和包括模拟标签错误的噪声标签进行计算，旨在检测后者。我们将我们的方法与三个基线进行了比较：一个无深度学习的朴素方法，目标检测器的...",
    "tldr": "本研究首次引入了一个用于目标检测数据集上标签错误检测的基准以及一种标签错误检测方法和几种基线方法。研究模拟了四种不同类型的随机引入的标签错误，并提出了一种通过损失检查来检测这些错误的方法。",
    "en_tdlr": "This study introduces a benchmark for label error detection on object detection datasets, as well as a label error detection method and several baselines. The study simulates four types of randomly introduced label errors and proposes a method to detect these errors by inspecting the losses."
}