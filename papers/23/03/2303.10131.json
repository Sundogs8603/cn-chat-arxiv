{
    "title": "She Elicits Requirements and He Tests: Software Engineering Gender Bias in Large Language Models. (arXiv:2303.10131v1 [cs.SE])",
    "abstract": "Implicit gender bias in software development is a well-documented issue, such as the association of technical roles with men. To address this bias, it is important to understand it in more detail. This study uses data mining techniques to investigate the extent to which 56 tasks related to software development, such as assigning GitHub issues and testing, are affected by implicit gender bias embedded in large language models. We systematically translated each task from English into a genderless language and back, and investigated the pronouns associated with each task. Based on translating each task 100 times in different permutations, we identify a significant disparity in the gendered pronoun associations with different tasks. Specifically, requirements elicitation was associated with the pronoun \"he\" in only 6% of cases, while testing was associated with \"he\" in 100% of cases. Additionally, tasks related to helping others had a 91% association with \"he\" while the same association fo",
    "link": "http://arxiv.org/abs/2303.10131",
    "context": "Title: She Elicits Requirements and He Tests: Software Engineering Gender Bias in Large Language Models. (arXiv:2303.10131v1 [cs.SE])\nAbstract: Implicit gender bias in software development is a well-documented issue, such as the association of technical roles with men. To address this bias, it is important to understand it in more detail. This study uses data mining techniques to investigate the extent to which 56 tasks related to software development, such as assigning GitHub issues and testing, are affected by implicit gender bias embedded in large language models. We systematically translated each task from English into a genderless language and back, and investigated the pronouns associated with each task. Based on translating each task 100 times in different permutations, we identify a significant disparity in the gendered pronoun associations with different tasks. Specifically, requirements elicitation was associated with the pronoun \"he\" in only 6% of cases, while testing was associated with \"he\" in 100% of cases. Additionally, tasks related to helping others had a 91% association with \"he\" while the same association fo",
    "path": "papers/23/03/2303.10131.json",
    "total_tokens": 1009,
    "translated_title": "她收集需求，他进行测试：大型语言模型中的软件工程性别偏见",
    "translated_abstract": "软件开发中的隐性性别偏见是一个被广泛研究的问题，比如将技术角色与男性联系在一起。为了解决这种偏见，更详细地了解它是非常重要的。本研究使用数据挖掘技术调查与软件开发相关的56项任务（如分配GitHub问题和测试），以了解嵌入大型语言模型中的隐性性别偏见所产生的影响程度。我们将每个任务从英语系统地翻译成无性别语言，然后再翻译回英语，并调查与每个任务相关的代词。通过在不同排列中反复翻译每个任务100次，我们确定了不同任务与性别代词的显著差异。具体而言，只有6%的需求收集任务与代词“他”相关联，而测试任务则在100%的情况下与“他”相关联。此外，涉及帮助他人的任务有91%的相关性与“他”相关联，而执行同样任务的女性则很容易被忽视。",
    "tldr": "本研究使用数据挖掘技术调查了56项与软件开发相关的任务，发现性别代词与不同任务的相关性明显不同。其中，只有6%的需求收集任务与代词“他”相关联，而测试任务则在100%的情况下与“他”相关联。此外，帮助他人的任务有91%的相关性与“他”相关联。",
    "en_tdlr": "This study investigates the impact of implicit gender bias embedded in large language models on 56 software development-related tasks, and finds that gendered pronoun associations vary significantly across tasks, with requirements elicitation associated with \"he\" in only 6% of cases, while testing associated with \"he\" in 100% of cases. Additionally, tasks related to helping others were associated with \"he\" 91% of the time."
}