{
    "title": "Inversion dynamics of class manifolds in deep learning reveals tradeoffs underlying generalisation",
    "abstract": "arXiv:2303.05161v2 Announce Type: replace  Abstract: To achieve near-zero training error in a classification problem, the layers of a feed-forward network have to disentangle the manifolds of data points with different labels, to facilitate the discrimination. However, excessive class separation can bring to overfitting since good generalisation requires learning invariant features, which involve some level of entanglement. We report on numerical experiments showing how the optimisation dynamics finds representations that balance these opposing tendencies with a non-monotonic trend. After a fast segregation phase, a slower rearrangement (conserved across data sets and architectures) increases the class entanglement.The training error at the inversion is stable under subsampling, and across network initialisations and optimisers, which characterises it as a property solely of the data structure and (very weakly) of the architecture. The inversion is the manifestation of tradeoffs elicit",
    "link": "https://arxiv.org/abs/2303.05161",
    "context": "Title: Inversion dynamics of class manifolds in deep learning reveals tradeoffs underlying generalisation\nAbstract: arXiv:2303.05161v2 Announce Type: replace  Abstract: To achieve near-zero training error in a classification problem, the layers of a feed-forward network have to disentangle the manifolds of data points with different labels, to facilitate the discrimination. However, excessive class separation can bring to overfitting since good generalisation requires learning invariant features, which involve some level of entanglement. We report on numerical experiments showing how the optimisation dynamics finds representations that balance these opposing tendencies with a non-monotonic trend. After a fast segregation phase, a slower rearrangement (conserved across data sets and architectures) increases the class entanglement.The training error at the inversion is stable under subsampling, and across network initialisations and optimisers, which characterises it as a property solely of the data structure and (very weakly) of the architecture. The inversion is the manifestation of tradeoffs elicit",
    "path": "papers/23/03/2303.05161.json",
    "total_tokens": 847,
    "translated_title": "深度学习中类别流形的反演动力学揭示了潜在泛化的权衡",
    "translated_abstract": "为了在分类问题中实现接近零训练误差，前馈网络的层必须解开具有不同标签的数据点的流形，以促进区分。然而，过度的类别分离可能导致过拟合，因为良好的泛化需要学习不变特征，这涉及一定程度的混杂。我们报告了数值实验，展示了优化动态如何找到平衡这些对立倾向的表示，并呈现出非单调趋势。快速分离阶段之后，更慢的重新排列（在数据集和架构间保持一致）增加了类别混杂性。反演时的训练误差在子采样、网络初始化和优化器之间保持稳定，这将其特征化为仅取决于数据结构（及架构上的微弱属性）。",
    "tldr": "优化动态发现了在学习不同标签的数据点流形时如何平衡类别分离和特征不变性之间的对立倾向，通过非单调趋势展现了这种权衡现象。",
    "en_tdlr": "The optimization dynamics in deep learning reveals how to balance the opposing tendencies of class separation and feature invariance when learning the manifolds of data points with different labels, with a non-monotonic trend showcasing this tradeoff."
}