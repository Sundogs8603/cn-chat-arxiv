{
    "title": "Towards High-Quality and Efficient Video Super-Resolution via Spatial-Temporal Data Overfitting. (arXiv:2303.08331v1 [cs.CV])",
    "abstract": "As deep convolutional neural networks (DNNs) are widely used in various fields of computer vision, leveraging the overfitting ability of the DNN to achieve video resolution upscaling has become a new trend in the modern video delivery system. By dividing videos into chunks and overfitting each chunk with a super-resolution model, the server encodes videos before transmitting them to the clients, thus achieving better video quality and transmission efficiency. However, a large number of chunks are expected to ensure good overfitting quality, which substantially increases the storage and consumes more bandwidth resources for data transmission. On the other hand, decreasing the number of chunks through training optimization techniques usually requires high model capacity, which significantly slows down execution speed. To reconcile such, we propose a novel method for high-quality and efficient video resolution upscaling tasks, which leverages the spatial-temporal information to accurately",
    "link": "http://arxiv.org/abs/2303.08331",
    "context": "Title: Towards High-Quality and Efficient Video Super-Resolution via Spatial-Temporal Data Overfitting. (arXiv:2303.08331v1 [cs.CV])\nAbstract: As deep convolutional neural networks (DNNs) are widely used in various fields of computer vision, leveraging the overfitting ability of the DNN to achieve video resolution upscaling has become a new trend in the modern video delivery system. By dividing videos into chunks and overfitting each chunk with a super-resolution model, the server encodes videos before transmitting them to the clients, thus achieving better video quality and transmission efficiency. However, a large number of chunks are expected to ensure good overfitting quality, which substantially increases the storage and consumes more bandwidth resources for data transmission. On the other hand, decreasing the number of chunks through training optimization techniques usually requires high model capacity, which significantly slows down execution speed. To reconcile such, we propose a novel method for high-quality and efficient video resolution upscaling tasks, which leverages the spatial-temporal information to accurately",
    "path": "papers/23/03/2303.08331.json",
    "total_tokens": 1068,
    "translated_title": "通过空间时间数据过拟合实现高质量高效的视频超分辨率",
    "translated_abstract": "随着深度卷积神经网络(DNN)在计算机视觉的各个领域得到广泛应用，利用DNN的过拟合能力实现视频分辨率的提升已经成为现代视频传输系统的新趋势。将视频分为块并将每个块与超分辨率模型过拟合，从而在传输给客户端之前对视频进行编码，从而实现更好的视频质量和传输效率。然而，为了保证良好的过拟合质量，需要大量的块，这会大大增加存储量和消耗更多带宽资源进行数据传输。另一方面，通过训练优化技术减少块的数量通常需要高模型容量，这会显著降低执行速度。为了解决这个问题，我们提出了一种新的方法来完成高质量和高效的视频分辨率升级任务，利用空间时间信息来准确捕捉有限训练数据的视频块的预测结果。具体来说，我们提出利用视频块的空间时间相关性，使用高维卷积网络改进每个块的预测，并进一步应用时间注意机制以去除冗余信息并促进传输。实验结果表明，我们的方法在视觉质量和效率方面均优于现有方法。",
    "tldr": "本论文提出了一种利用空间时间信息来提高视频超分辨率的新方法，采用高维卷积网络进行预测并应用时间注意机制以去除冗余信息并提高效率。",
    "en_tdlr": "This paper proposes a novel method for improving video super-resolution by leveraging spatial-temporal information. By using a high-dimensional convolution network to improve prediction accuracy and applying a temporal attention mechanism to remove redundant information and improve efficiency, this method achieves superior performance compared to existing techniques."
}