{
    "title": "Have it your way: Individualized Privacy Assignment for DP-SGD. (arXiv:2303.17046v1 [cs.LG])",
    "abstract": "When training a machine learning model with differential privacy, one sets a privacy budget. This budget represents a maximal privacy violation that any user is willing to face by contributing their data to the training set. We argue that this approach is limited because different users may have different privacy expectations. Thus, setting a uniform privacy budget across all points may be overly conservative for some users or, conversely, not sufficiently protective for others. In this paper, we capture these preferences through individualized privacy budgets. To demonstrate their practicality, we introduce a variant of Differentially Private Stochastic Gradient Descent (DP-SGD) which supports such individualized budgets. DP-SGD is the canonical approach to training models with differential privacy. We modify its data sampling and gradient noising mechanisms to arrive at our approach, which we call Individualized DP-SGD (IDP-SGD). Because IDP-SGD provides privacy guarantees tailored t",
    "link": "http://arxiv.org/abs/2303.17046",
    "context": "Title: Have it your way: Individualized Privacy Assignment for DP-SGD. (arXiv:2303.17046v1 [cs.LG])\nAbstract: When training a machine learning model with differential privacy, one sets a privacy budget. This budget represents a maximal privacy violation that any user is willing to face by contributing their data to the training set. We argue that this approach is limited because different users may have different privacy expectations. Thus, setting a uniform privacy budget across all points may be overly conservative for some users or, conversely, not sufficiently protective for others. In this paper, we capture these preferences through individualized privacy budgets. To demonstrate their practicality, we introduce a variant of Differentially Private Stochastic Gradient Descent (DP-SGD) which supports such individualized budgets. DP-SGD is the canonical approach to training models with differential privacy. We modify its data sampling and gradient noising mechanisms to arrive at our approach, which we call Individualized DP-SGD (IDP-SGD). Because IDP-SGD provides privacy guarantees tailored t",
    "path": "papers/23/03/2303.17046.json",
    "total_tokens": 849,
    "translated_abstract": "在对机器学习模型进行差分隐私训练时，需要设置隐私预算，它代表了每个用户为贡献他们的数据到训练集中所准备面临的最大隐私违规程度。本文以研究人员发现这种方法存在局限性，因为不同用户可能具有不同的隐私期望。因此，对所有用户设置统一的隐私预算可能会过于保守或者对其他用户来说保护不足。本文通过个性化隐私预算来反映这些个体的偏好。为了证明它们的实用性，我们引入了一种变体的差分私有随机梯度下降（DP-SGD），它支持这种个性化的预算。因为IDP-SGD提供了针对每个用户的个性化的隐私保证，所以我们修改了其数据采样和梯度噪声机制，这种方法也称为个性化DP-SGD（IDP-SGD）。",
    "tldr": "通过个性化隐私预算提高差分隐私训练模型的实用性和个性化保护，相比于统一隐私预算更为灵活和有效。",
    "en_tdlr": "Individualized privacy budgets increase the practicality and personalized protection of differential privacy training models. Compared to uniform privacy budgets, IDP-SGD provides more flexibility and effectiveness in privacy protection."
}