{
    "title": "Open-World Object Manipulation using Pre-trained Vision-Language Models. (arXiv:2303.00905v2 [cs.RO] UPDATED)",
    "abstract": "For robots to follow instructions from people, they must be able to connect the rich semantic information in human vocabulary, e.g. \"can you get me the pink stuffed whale?\" to their sensory observations and actions. This brings up a notably difficult challenge for robots: while robot learning approaches allow robots to learn many different behaviors from first-hand experience, it is impractical for robots to have first-hand experiences that span all of this semantic information. We would like a robot's policy to be able to perceive and pick up the pink stuffed whale, even if it has never seen any data interacting with a stuffed whale before. Fortunately, static data on the internet has vast semantic information, and this information is captured in pre-trained vision-language models. In this paper, we study whether we can interface robot policies with these pre-trained models, with the aim of allowing robots to complete instructions involving object categories that the robot has never s",
    "link": "http://arxiv.org/abs/2303.00905",
    "context": "Title: Open-World Object Manipulation using Pre-trained Vision-Language Models. (arXiv:2303.00905v2 [cs.RO] UPDATED)\nAbstract: For robots to follow instructions from people, they must be able to connect the rich semantic information in human vocabulary, e.g. \"can you get me the pink stuffed whale?\" to their sensory observations and actions. This brings up a notably difficult challenge for robots: while robot learning approaches allow robots to learn many different behaviors from first-hand experience, it is impractical for robots to have first-hand experiences that span all of this semantic information. We would like a robot's policy to be able to perceive and pick up the pink stuffed whale, even if it has never seen any data interacting with a stuffed whale before. Fortunately, static data on the internet has vast semantic information, and this information is captured in pre-trained vision-language models. In this paper, we study whether we can interface robot policies with these pre-trained models, with the aim of allowing robots to complete instructions involving object categories that the robot has never s",
    "path": "papers/23/03/2303.00905.json",
    "total_tokens": 948,
    "translated_title": "使用预训练的视觉-语言模型进行开放世界目标操作",
    "translated_abstract": "为了让机器人能够按照人们的指令行动，它们必须能够将人类词汇中的丰富语义信息（例如：“你能给我拿来粉色的毛绒鲸鱼吗？”）与它们的感知观察和行动相连接。这对机器人来说带来了一个明显困难的挑战：尽管机器人学习方法能够让机器人从第一手经验中学习到许多不同的行为，但机器人不可能亲身体验到涵盖所有语义信息的情况。我们希望机器人的策略能够感知和拾取粉色的毛绒鲸鱼，即使它以前从未见过与毛绒鲸鱼互动的数据。幸运的是，互联网上的静态数据拥有丰富的语义信息，并且这些信息被捕捉在预训练的视觉-语言模型中。在本文中，我们研究了是否可以将机器人策略与这些预训练模型进行接口连接，以便让机器人完成涉及机器人以前没有见过的物体类别的指令。",
    "tldr": "本文研究了使用预训练的视觉-语言模型来实现机器人的开放世界目标操作，从而解决了机器人在面对丰富语义信息时的困难挑战。"
}