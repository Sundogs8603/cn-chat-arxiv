{
    "title": "Common Subexpression-based Compression and Multiplication of Sparse Constant Matrices. (arXiv:2303.16106v1 [cs.LG])",
    "abstract": "In deep learning inference, model parameters are pruned and quantized to reduce the model size. Compression methods and common subexpression (CSE) elimination algorithms are applied on sparse constant matrices to deploy the models on low-cost embedded devices. However, the state-of-the-art CSE elimination methods do not scale well for handling large matrices. They reach hours for extracting CSEs in a $200 \\times 200$ matrix while their matrix multiplication algorithms execute longer than the conventional matrix multiplication methods. Besides, there exist no compression methods for matrices utilizing CSEs. As a remedy to this problem, a random search-based algorithm is proposed in this paper to extract CSEs in the column pairs of a constant matrix. It produces an adder tree for a $1000 \\times 1000$ matrix in a minute. To compress the adder tree, this paper presents a compression format by extending the Compressed Sparse Row (CSR) to include CSEs. While compression rates of more than $5",
    "link": "http://arxiv.org/abs/2303.16106",
    "context": "Title: Common Subexpression-based Compression and Multiplication of Sparse Constant Matrices. (arXiv:2303.16106v1 [cs.LG])\nAbstract: In deep learning inference, model parameters are pruned and quantized to reduce the model size. Compression methods and common subexpression (CSE) elimination algorithms are applied on sparse constant matrices to deploy the models on low-cost embedded devices. However, the state-of-the-art CSE elimination methods do not scale well for handling large matrices. They reach hours for extracting CSEs in a $200 \\times 200$ matrix while their matrix multiplication algorithms execute longer than the conventional matrix multiplication methods. Besides, there exist no compression methods for matrices utilizing CSEs. As a remedy to this problem, a random search-based algorithm is proposed in this paper to extract CSEs in the column pairs of a constant matrix. It produces an adder tree for a $1000 \\times 1000$ matrix in a minute. To compress the adder tree, this paper presents a compression format by extending the Compressed Sparse Row (CSR) to include CSEs. While compression rates of more than $5",
    "path": "papers/23/03/2303.16106.json",
    "total_tokens": 1090,
    "translated_title": "基于共同子表达式的稀疏常数矩阵压缩和乘法",
    "translated_abstract": "在深度学习推理中，模型参数被修剪和量化以减少模型大小。压缩方法和共同子表达式消除算法被应用于稀疏常数矩阵以在低成本嵌入式设备上部署模型。然而，最先进的共同子表达式消除方法在处理大型矩阵时缩放并不良好。在200x200矩阵中提取CSE需要几个小时，而它们的矩阵乘法算法比传统矩阵乘法方法执行时间更长。此外，不存在利用CSE的矩阵压缩方法。为了解决这个问题，本文提出了一种基于随机搜索的算法来提取常数矩阵列对中的CSE。它可在一分钟内为1000x1000矩阵生成加法树。为了压缩加法树，本文提出了一种扩展压缩稀疏行（CSR）以包括CSE的压缩格式。虽然可以实现超过5倍的压缩率，但所提出的算法在CSE提取和矩阵乘法方面都具有显着的加速作用，使它们更适合在低成本嵌入式设备上部署。",
    "tldr": "本文提出了一种基于随机搜索的算法来提取稀疏常数矩阵列对中的共同子表达式，使用加法树压缩这些表达式可以实现超过5倍的压缩率，同时在CSE提取和矩阵乘法方面显著加速。"
}