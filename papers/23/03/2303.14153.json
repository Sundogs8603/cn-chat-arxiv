{
    "title": "Local Contrastive Learning for Medical Image Recognition. (arXiv:2303.14153v1 [cs.CV])",
    "abstract": "The proliferation of Deep Learning (DL)-based methods for radiographic image analysis has created a great demand for expert-labeled radiology data. Recent self-supervised frameworks have alleviated the need for expert labeling by obtaining supervision from associated radiology reports. These frameworks, however, struggle to distinguish the subtle differences between different pathologies in medical images. Additionally, many of them do not provide interpretation between image regions and text, making it difficult for radiologists to assess model predictions. In this work, we propose Local Region Contrastive Learning (LRCLR), a flexible fine-tuning framework that adds layers for significant image region selection as well as cross-modality interaction. Our results on an external validation set of chest x-rays suggest that LRCLR identifies significant local image regions and provides meaningful interpretation against radiology text while improving zero-shot performance on several chest x-",
    "link": "http://arxiv.org/abs/2303.14153",
    "context": "Title: Local Contrastive Learning for Medical Image Recognition. (arXiv:2303.14153v1 [cs.CV])\nAbstract: The proliferation of Deep Learning (DL)-based methods for radiographic image analysis has created a great demand for expert-labeled radiology data. Recent self-supervised frameworks have alleviated the need for expert labeling by obtaining supervision from associated radiology reports. These frameworks, however, struggle to distinguish the subtle differences between different pathologies in medical images. Additionally, many of them do not provide interpretation between image regions and text, making it difficult for radiologists to assess model predictions. In this work, we propose Local Region Contrastive Learning (LRCLR), a flexible fine-tuning framework that adds layers for significant image region selection as well as cross-modality interaction. Our results on an external validation set of chest x-rays suggest that LRCLR identifies significant local image regions and provides meaningful interpretation against radiology text while improving zero-shot performance on several chest x-",
    "path": "papers/23/03/2303.14153.json",
    "total_tokens": 891,
    "translated_title": "医学图像识别的局部对比学习",
    "translated_abstract": "基于深度学习的放射学图像分析方法的普及已经创造了对专家标记的放射学数据的巨大需求。最近的自监督框架通过从相关放射学报告中获取监督来缓解对专家标注的需求。然而，这些框架往往难以区分医学图像中不同病理的细微差别。此外，它们中的许多不提供图像区域和文本之间的解释，使诊断医师很难评估模型预测。在本研究中，我们提出了局部对比学习（LRCLR）的灵活微调框架，该框架添加了显着的图像区域选择层以及跨模态交互。我们的结果对一个外部的胸透验证集表明，LRCLR识别了显著的局部图像区域，并在改善了几项胸透分类任务的零样本性能的同时提供了有意义的与放射学文本的解释。",
    "tldr": "本文提出了一种局部对比学习的微调框架LRCLR，该框架能够识别医学图像中显著的局部图像区域，提供有意义的图像和文本的解释，并显著提高了零样本性能。",
    "en_tdlr": "The paper proposes a fine-tuning framework called LRCLR for medical image recognition, which can identify significant local image regions, provide meaningful interpretation between image regions and text, and significantly improve zero-shot performance."
}