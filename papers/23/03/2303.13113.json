{
    "title": "Adaptive Regularization for Class-Incremental Learning. (arXiv:2303.13113v1 [cs.LG])",
    "abstract": "Class-Incremental Learning updates a deep classifier with new categories while maintaining the previously observed class accuracy. Regularizing the neural network weights is a common method to prevent forgetting previously learned classes while learning novel ones. However, existing regularizers use a constant magnitude throughout the learning sessions, which may not reflect the varying levels of difficulty of the tasks encountered during incremental learning. This study investigates the necessity of adaptive regularization in Class-Incremental Learning, which dynamically adjusts the regularization strength according to the complexity of the task at hand. We propose a Bayesian Optimization-based approach to automatically determine the optimal regularization magnitude for each learning task. Our experiments on two datasets via two regularizers demonstrate the importance of adaptive regularization for achieving accurate and less forgetful visual incremental learning.",
    "link": "http://arxiv.org/abs/2303.13113",
    "context": "Title: Adaptive Regularization for Class-Incremental Learning. (arXiv:2303.13113v1 [cs.LG])\nAbstract: Class-Incremental Learning updates a deep classifier with new categories while maintaining the previously observed class accuracy. Regularizing the neural network weights is a common method to prevent forgetting previously learned classes while learning novel ones. However, existing regularizers use a constant magnitude throughout the learning sessions, which may not reflect the varying levels of difficulty of the tasks encountered during incremental learning. This study investigates the necessity of adaptive regularization in Class-Incremental Learning, which dynamically adjusts the regularization strength according to the complexity of the task at hand. We propose a Bayesian Optimization-based approach to automatically determine the optimal regularization magnitude for each learning task. Our experiments on two datasets via two regularizers demonstrate the importance of adaptive regularization for achieving accurate and less forgetful visual incremental learning.",
    "path": "papers/23/03/2303.13113.json",
    "total_tokens": 880,
    "translated_title": "适应性正则化在类增量学习中的应用",
    "translated_abstract": "类增量学习是指在维持先前学习的分类准确度的同时，更新具有新类别的深度分类器。在学习新类别的同时，通过正则化神经网络权重来防止遗忘之前学习的类别是常见的方法。然而，现有的正则化方法在整个增量学习过程中使用恒定的强度，可能无法反映所遇到的任务难度的变化。因此，本研究探讨了适应性正则化在类增量学习中的必要性，该方法根据手头任务的复杂度动态调整正则化强度。我们提出了一种基于贝叶斯优化的方法，自动确定每个学习任务的最佳正则化强度。通过两个数据集上的两种正则化方法的实验，结果表明适应性正则化对于实现更加准确和不易遗忘的视觉增量学习非常重要。",
    "tldr": "本文研究了适应性正则化在类增量学习中的应用，通过根据任务复杂度动态调整正则化强度，在学习新类别同时防止遗忘之前学习的类别。实验表明适应性正则化可以实现更加准确和不易遗忘的视觉增量学习。",
    "en_tdlr": "This paper investigates the necessity of adaptive regularization in Class-Incremental Learning, which dynamically adjusts the regularization strength according to the complexity of the task at hand, to prevent forgetting previously learned classes while learning novel ones. The experiments demonstrate the importance of adaptive regularization for achieving accurate and less forgetful visual incremental learning."
}