{
    "title": "Utilizing synthetic training data for the supervised classification of rat ultrasonic vocalizations. (arXiv:2303.03183v2 [cs.SD] UPDATED)",
    "abstract": "Murine rodents generate ultrasonic vocalizations (USVs) with frequencies that extend to around 120kHz. These calls are important in social behaviour, and so their analysis can provide insights into the function of vocal communication, and its dysfunction. The manual identification of USVs, and subsequent classification into different subcategories is time consuming. Although machine learning approaches for identification and classification can lead to enormous efficiency gains, the time and effort required to generate training data can be high, and the accuracy of current approaches can be problematic. Here we compare the detection and classification performance of a trained human against two convolutional neural networks (CNNs), DeepSqueak and VocalMat, on audio containing rat USVs. Furthermore, we test the effect of inserting synthetic USVs into the training data of the VocalMat CNN as a means of reducing the workload associated with generating a training set. Our results indicate th",
    "link": "http://arxiv.org/abs/2303.03183",
    "context": "Title: Utilizing synthetic training data for the supervised classification of rat ultrasonic vocalizations. (arXiv:2303.03183v2 [cs.SD] UPDATED)\nAbstract: Murine rodents generate ultrasonic vocalizations (USVs) with frequencies that extend to around 120kHz. These calls are important in social behaviour, and so their analysis can provide insights into the function of vocal communication, and its dysfunction. The manual identification of USVs, and subsequent classification into different subcategories is time consuming. Although machine learning approaches for identification and classification can lead to enormous efficiency gains, the time and effort required to generate training data can be high, and the accuracy of current approaches can be problematic. Here we compare the detection and classification performance of a trained human against two convolutional neural networks (CNNs), DeepSqueak and VocalMat, on audio containing rat USVs. Furthermore, we test the effect of inserting synthetic USVs into the training data of the VocalMat CNN as a means of reducing the workload associated with generating a training set. Our results indicate th",
    "path": "papers/23/03/2303.03183.json",
    "total_tokens": 777,
    "translated_title": "利用合成训练数据进行大鼠超声波声音的监督分类",
    "translated_abstract": "小鼠产生频率高达120kHz的超声波声音（USVs）。这些叫声在社交行为中很重要，因此它们的分析可以揭示声音通信的功能和功能紊乱。手动识别USVs并将其分类为不同的子类非常耗时。虽然机器学习方法可用于识别和分类，但生成训练数据所需的时间和精力可能很高，并且当前方法的准确性可能存在问题。在本研究中，我们比较了经过训练的人与两种卷积神经网络（CNNs），DeepSqueak和VocalMat，在含有大鼠USVs的音频中的检测和分类性能。此外，我们测试了将合成的USVs插入到VocalMat CNN的训练数据中是否可以减少生成训练集的工作量。我们的实验结果表明",
    "tldr": "利用合成训练数据可以提高大鼠超声波声音的监督分类效果。",
    "en_tdlr": "Utilizing synthetic training data can improve the supervised classification of rat ultrasonic vocalizations."
}