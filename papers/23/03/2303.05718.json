{
    "title": "Tradeoff of generalization error in unsupervised learning. (arXiv:2303.05718v1 [cond-mat.stat-mech])",
    "abstract": "Finding the optimal model complexity that minimizes the generalization error (GE) is a key issue of machine learning. For the conventional supervised learning, this task typically involves the bias-variance tradeoff: lowering the bias by making the model more complex entails an increase in the variance. Meanwhile, little has been studied about whether the same tradeoff exists for unsupervised learning. In this study, we propose that unsupervised learning generally exhibits a two-component tradeoff of the GE, namely the model error and the data error -- using a more complex model reduces the model error at the cost of the data error, with the data error playing a more significant role for a smaller training dataset. This is corroborated by training the restricted Boltzmann machine to generate the configurations of the two-dimensional Ising model at a given temperature and the totally asymmetric simple exclusion process with given entry and exit rates. Our results also indicate that the ",
    "link": "http://arxiv.org/abs/2303.05718",
    "raw_ret": "{\n    \"translated_title\": \"无监督学习中的广义误差权衡。 (arXiv：2303.05718v1 [cond-mat.stat-mech])\",\n    \"translated_abstract\": \"找到最小化广义误差（GE）的最优模型复杂度是机器学习的关键问题。 对于传统的监督学习，这个任务通常涉及偏差方差权衡：通过使模型更复杂降低偏差会增加方差。 同时，对于无监督学习是否存在相同的权衡，很少有研究。 在这项研究中，我们提出无监督学习通常展示GE的两个成分的权衡，即模型误差和数据误差 - 使用更复杂的模型降低模型误差的代价是数据误差，数据误差在更小的训练数据集上发挥更重要的作用。 通过训练限制玻尔兹曼机在给定温度下生成二维伊辛模型的配置和具有给定进入和退出速率的完全非对称简单排除过程，我们证实了这一点。 我们的结果还表明，\",\n    \"tldr\": \"本文探讨了无监督学习中的广义误差权衡问题，并且发现使用更复杂的模型降低模型误差的代价是数据误差，数据误差在更小的训练数据集上发挥更重要的作用。\"\n}",
    "total_tokens": 887,
    "ret": {
        "translated_title": "无监督学习中的广义误差权衡。 (arXiv：2303.05718v1 [cond-mat.stat-mech])",
        "translated_abstract": "找到最小化广义误差（GE）的最优模型复杂度是机器学习的关键问题。 对于传统的监督学习，这个任务通常涉及偏差方差权衡：通过使模型更复杂降低偏差会增加方差。 同时，对于无监督学习是否存在相同的权衡，很少有研究。 在这项研究中，我们提出无监督学习通常展示GE的两个成分的权衡，即模型误差和数据误差 - 使用更复杂的模型降低模型误差的代价是数据误差，数据误差在更小的训练数据集上发挥更重要的作用。 通过训练限制玻尔兹曼机在给定温度下生成二维伊辛模型的配置和具有给定进入和退出速率的完全非对称简单排除过程，我们证实了这一点。 我们的结果还表明，",
        "tldr": "本文探讨了无监督学习中的广义误差权衡问题，并且发现使用更复杂的模型降低模型误差的代价是数据误差，数据误差在更小的训练数据集上发挥更重要的作用。"
    }
}