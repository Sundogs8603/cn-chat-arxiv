{
    "title": "Implicit Balancing and Regularization: Generalization and Convergence Guarantees for Overparameterized Asymmetric Matrix Sensing. (arXiv:2303.14244v1 [cs.LG])",
    "abstract": "Recently, there has been significant progress in understanding the convergence and generalization properties of gradient-based methods for training overparameterized learning models. However, many aspects including the role of small random initialization and how the various parameters of the model are coupled during gradient-based updates to facilitate good generalization remain largely mysterious. A series of recent papers have begun to study this role for non-convex formulations of symmetric Positive Semi-Definite (PSD) matrix sensing problems which involve reconstructing a low-rank PSD matrix from a few linear measurements. The underlying symmetry/PSDness is crucial to existing convergence and generalization guarantees for this problem. In this paper, we study a general overparameterized low-rank matrix sensing problem where one wishes to reconstruct an asymmetric rectangular low-rank matrix from a few linear measurements. We prove that an overparameterized model trained via factori",
    "link": "http://arxiv.org/abs/2303.14244",
    "context": "Title: Implicit Balancing and Regularization: Generalization and Convergence Guarantees for Overparameterized Asymmetric Matrix Sensing. (arXiv:2303.14244v1 [cs.LG])\nAbstract: Recently, there has been significant progress in understanding the convergence and generalization properties of gradient-based methods for training overparameterized learning models. However, many aspects including the role of small random initialization and how the various parameters of the model are coupled during gradient-based updates to facilitate good generalization remain largely mysterious. A series of recent papers have begun to study this role for non-convex formulations of symmetric Positive Semi-Definite (PSD) matrix sensing problems which involve reconstructing a low-rank PSD matrix from a few linear measurements. The underlying symmetry/PSDness is crucial to existing convergence and generalization guarantees for this problem. In this paper, we study a general overparameterized low-rank matrix sensing problem where one wishes to reconstruct an asymmetric rectangular low-rank matrix from a few linear measurements. We prove that an overparameterized model trained via factori",
    "path": "papers/23/03/2303.14244.json",
    "total_tokens": 929,
    "translated_title": "隐式平衡和正则化：过参数化非对称矩阵感知中的泛化和收敛保证",
    "translated_abstract": "最近，对于训练过参数化学习模型的基于梯度的方法的收敛和泛化属性有了重要进展。然而，其中许多方面，包括小随机初始化的角色以及模型的各种参数在梯度更新中如何耦合以促进良好的泛化，仍然是很神秘的。最近一系列的论文已经开始研究非凸对称半正定（PSD）矩阵感知问题的形式，在这个问题中需要从几个线性测量中重建一个低秩PSD矩阵。这种底层的对称性/PSD性对于现有的这个问题的收敛和泛化保证是至关重要的。在本文中，我们研究了一个一般的过参数化的低秩矩阵感知问题，其中希望从少量的线性测量中重建一个非对称矩形低秩矩阵。我们证明了通过因子化来训练的过参数化模型在这个问题上可以收敛，而隐式平衡和正则化可以促进泛化。",
    "tldr": "本论文研究了过参数化低秩矩阵感知问题，证明了通过因子化方法训练的过参数化模型可以收敛，并且隐式平衡和正则化可以促进泛化。",
    "en_tdlr": "This paper studies the overparameterized low-rank matrix sensing problem and proves that the overparameterized model trained via factorization can converge, and implicit balancing and regularization can facilitate generalization."
}