{
    "title": "Temperature Schedules for Self-Supervised Contrastive Methods on Long-Tail Data. (arXiv:2303.13664v1 [cs.CV])",
    "abstract": "Most approaches for self-supervised learning (SSL) are optimised on curated balanced datasets, e.g. ImageNet, despite the fact that natural data usually exhibits long-tail distributions. In this paper, we analyse the behaviour of one of the most popular variants of SSL, i.e. contrastive methods, on long-tail data. In particular, we investigate the role of the temperature parameter $\\tau$ in the contrastive loss, by analysing the loss through the lens of average distance maximisation, and find that a large $\\tau$ emphasises group-wise discrimination, whereas a small $\\tau$ leads to a higher degree of instance discrimination. While $\\tau$ has thus far been treated exclusively as a constant hyperparameter, in this work, we propose to employ a dynamic $\\tau$ and show that a simple cosine schedule can yield significant improvements in the learnt representations. Such a schedule results in a constant `task switching' between an emphasis on instance discrimination and group-wise discriminatio",
    "link": "http://arxiv.org/abs/2303.13664",
    "context": "Title: Temperature Schedules for Self-Supervised Contrastive Methods on Long-Tail Data. (arXiv:2303.13664v1 [cs.CV])\nAbstract: Most approaches for self-supervised learning (SSL) are optimised on curated balanced datasets, e.g. ImageNet, despite the fact that natural data usually exhibits long-tail distributions. In this paper, we analyse the behaviour of one of the most popular variants of SSL, i.e. contrastive methods, on long-tail data. In particular, we investigate the role of the temperature parameter $\\tau$ in the contrastive loss, by analysing the loss through the lens of average distance maximisation, and find that a large $\\tau$ emphasises group-wise discrimination, whereas a small $\\tau$ leads to a higher degree of instance discrimination. While $\\tau$ has thus far been treated exclusively as a constant hyperparameter, in this work, we propose to employ a dynamic $\\tau$ and show that a simple cosine schedule can yield significant improvements in the learnt representations. Such a schedule results in a constant `task switching' between an emphasis on instance discrimination and group-wise discriminatio",
    "path": "papers/23/03/2303.13664.json",
    "total_tokens": 853,
    "tldr": "本文研究了自监督对比方法在长尾数据上的行为。提出使用动态温度参数τ并使用余弦调度进行自适应调整，该方法在学习表示方面产生了显着的改进。"
}