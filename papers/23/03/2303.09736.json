{
    "title": "Dynamic Structure Pruning for Compressing CNNs. (arXiv:2303.09736v1 [cs.CV])",
    "abstract": "Structure pruning is an effective method to compress and accelerate neural networks. While filter and channel pruning are preferable to other structure pruning methods in terms of realistic acceleration and hardware compatibility, pruning methods with a finer granularity, such as intra-channel pruning, are expected to be capable of yielding more compact and computationally efficient networks. Typical intra-channel pruning methods utilize a static and hand-crafted pruning granularity due to a large search space, which leaves room for improvement in their pruning performance. In this work, we introduce a novel structure pruning method, termed as dynamic structure pruning, to identify optimal pruning granularities for intra-channel pruning. In contrast to existing intra-channel pruning methods, the proposed method automatically optimizes dynamic pruning granularities in each layer while training deep neural networks. To achieve this, we propose a differentiable group learning method desig",
    "link": "http://arxiv.org/abs/2303.09736",
    "context": "Title: Dynamic Structure Pruning for Compressing CNNs. (arXiv:2303.09736v1 [cs.CV])\nAbstract: Structure pruning is an effective method to compress and accelerate neural networks. While filter and channel pruning are preferable to other structure pruning methods in terms of realistic acceleration and hardware compatibility, pruning methods with a finer granularity, such as intra-channel pruning, are expected to be capable of yielding more compact and computationally efficient networks. Typical intra-channel pruning methods utilize a static and hand-crafted pruning granularity due to a large search space, which leaves room for improvement in their pruning performance. In this work, we introduce a novel structure pruning method, termed as dynamic structure pruning, to identify optimal pruning granularities for intra-channel pruning. In contrast to existing intra-channel pruning methods, the proposed method automatically optimizes dynamic pruning granularities in each layer while training deep neural networks. To achieve this, we propose a differentiable group learning method desig",
    "path": "papers/23/03/2303.09736.json",
    "total_tokens": 819,
    "translated_title": "压缩CNN的动态结构剪枝方法",
    "translated_abstract": "结构剪枝是一种压缩和加速神经网络的有效方法。尽管在实际加速和硬件兼容性方面滤波和通道剪枝是优于其他结构剪枝方法的，但细粒度的剪枝方法，如内通道剪枝，有望产生更紧凑和计算效率更高的网络。现有的内通道剪枝方法通常使用静态和手动制定的剪枝粒度，这留给了优化剪枝性能的空间。在这项工作中，我们介绍了一种新的结构剪枝方法，称为动态结构剪枝，来确定内通道剪枝的最优剪枝粒度。与现有的内通道剪枝方法不同，所提出的方法在训练深度神经网络时自动优化每层的动态剪枝粒度。为了实现这一点，我们提出了一种可区分的组学习方法",
    "tldr": "本文介绍了一种新的动态结构剪枝方法，它可以自动优化每层内通道剪枝的最优粒度，从而更加紧凑和高效。",
    "en_tdlr": "This paper proposes a novel dynamic structure pruning method that can automatically optimize the optimal granularity of intra-channel pruning for each layer, resulting in more compact and efficient networks."
}