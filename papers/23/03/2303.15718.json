{
    "title": "MeMaHand: Exploiting Mesh-Mano Interaction for Single Image Two-Hand Reconstruction. (arXiv:2303.15718v1 [cs.CV])",
    "abstract": "Existing methods proposed for hand reconstruction tasks usually parameterize a generic 3D hand model or predict hand mesh positions directly. The parametric representations consisting of hand shapes and rotational poses are more stable, while the non-parametric methods can predict more accurate mesh positions. In this paper, we propose to reconstruct meshes and estimate MANO parameters of two hands from a single RGB image simultaneously to utilize the merits of two kinds of hand representations. To fulfill this target, we propose novel Mesh-Mano interaction blocks (MMIBs), which take mesh vertices positions and MANO parameters as two kinds of query tokens. MMIB consists of one graph residual block to aggregate local information and two transformer encoders to model long-range dependencies. The transformer encoders are equipped with different asymmetric attention masks to model the intra-hand and inter-hand attention, respectively. Moreover, we introduce the mesh alignment refinement mo",
    "link": "http://arxiv.org/abs/2303.15718",
    "context": "Title: MeMaHand: Exploiting Mesh-Mano Interaction for Single Image Two-Hand Reconstruction. (arXiv:2303.15718v1 [cs.CV])\nAbstract: Existing methods proposed for hand reconstruction tasks usually parameterize a generic 3D hand model or predict hand mesh positions directly. The parametric representations consisting of hand shapes and rotational poses are more stable, while the non-parametric methods can predict more accurate mesh positions. In this paper, we propose to reconstruct meshes and estimate MANO parameters of two hands from a single RGB image simultaneously to utilize the merits of two kinds of hand representations. To fulfill this target, we propose novel Mesh-Mano interaction blocks (MMIBs), which take mesh vertices positions and MANO parameters as two kinds of query tokens. MMIB consists of one graph residual block to aggregate local information and two transformer encoders to model long-range dependencies. The transformer encoders are equipped with different asymmetric attention masks to model the intra-hand and inter-hand attention, respectively. Moreover, we introduce the mesh alignment refinement mo",
    "path": "papers/23/03/2303.15718.json",
    "total_tokens": 952,
    "translated_title": "MeMaHand：利用网格-手部互动进行单张图像双手重建",
    "translated_abstract": "现有的手重建方法通常对一个通用的3D手模型进行参数化或者直接预测手掌网格位置，参数表示的手部形状和旋转姿态更为稳定，而非参数化的方法可以更精确地预测网格位置。本文提出了一种新方法，从单张RGB图像中同时重建两只手的网格并估计MANO参数，以利用两种手表示方法的优点。为了实现这个目标，我们提出了新的网格-手部互动块（MMIBs），它将网格顶点位置和MANO参数作为两种查询令牌。MMIB由一个图形残差块来聚合局部信息和两个变换编码器来建模远程依赖关系。变换编码器配备不同的不对称关注掩码来分别建模手内和手间关注。此外，我们还引入了网格对齐细化模块来进一步提高网格重建的准确性。实验结果表明，我们提出的方法在单手和双手重建任务上优于现有最先进方法。",
    "tldr": "本文提出了一种利用网格-手部互动进行单张图像双手重建的新方法，使用网格顶点位置和MANO参数作为查询令牌，实现了精确的网格重建，并通过实验表明这一方法优于现有最先进方法。",
    "en_tdlr": "This paper proposes a novel method for single image two-hand reconstruction by exploiting the mesh-mano interaction, which uses mesh vertices positions and MANO parameters as query tokens to achieve accurate mesh reconstruction, and it outperforms state-of-the-art methods according to experimental results."
}