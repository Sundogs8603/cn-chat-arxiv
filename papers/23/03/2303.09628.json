{
    "title": "Efficient Learning of High Level Plans from Play. (arXiv:2303.09628v1 [cs.LG])",
    "abstract": "Real-world robotic manipulation tasks remain an elusive challenge, since they involve both fine-grained environment interaction, as well as the ability to plan for long-horizon goals. Although deep reinforcement learning (RL) methods have shown encouraging results when planning end-to-end in high-dimensional environments, they remain fundamentally limited by poor sample efficiency due to inefficient exploration, and by the complexity of credit assignment over long horizons. In this work, we present Efficient Learning of High-Level Plans from Play (ELF-P), a framework for robotic learning that bridges motion planning and deep RL to achieve long-horizon complex manipulation tasks. We leverage task-agnostic play data to learn a discrete behavioral prior over object-centric primitives, modeling their feasibility given the current context. We then design a high-level goal-conditioned policy which (1) uses primitives as building blocks to scaffold complex long-horizon tasks and (2) leverages",
    "link": "http://arxiv.org/abs/2303.09628",
    "context": "Title: Efficient Learning of High Level Plans from Play. (arXiv:2303.09628v1 [cs.LG])\nAbstract: Real-world robotic manipulation tasks remain an elusive challenge, since they involve both fine-grained environment interaction, as well as the ability to plan for long-horizon goals. Although deep reinforcement learning (RL) methods have shown encouraging results when planning end-to-end in high-dimensional environments, they remain fundamentally limited by poor sample efficiency due to inefficient exploration, and by the complexity of credit assignment over long horizons. In this work, we present Efficient Learning of High-Level Plans from Play (ELF-P), a framework for robotic learning that bridges motion planning and deep RL to achieve long-horizon complex manipulation tasks. We leverage task-agnostic play data to learn a discrete behavioral prior over object-centric primitives, modeling their feasibility given the current context. We then design a high-level goal-conditioned policy which (1) uses primitives as building blocks to scaffold complex long-horizon tasks and (2) leverages",
    "path": "papers/23/03/2303.09628.json",
    "total_tokens": 967,
    "translated_title": "从游戏中高效学习高层次计划。",
    "translated_abstract": "现实世界中的机器人操作任务仍然是一个棘手的挑战，因为它们涉及到精细的环境交互以及规划长期目标的能力。虽然深度强化学习（RL）方法在高维度环境下规划端到端时显示出了令人鼓舞的结果，但由于探索低效以及长期规划的信用分配复杂性而受到根本性限制。在这项工作中，我们提出了从游戏中高效学习高层次计划（ELF-P），这是一个桥接动作规划和深度RL的机器人学习框架，以实现长期复杂的操作任务。我们利用任务不可知的游戏数据学习基于物体的离散行为先验，建模它们在当前情境下的可行性。然后我们设计一个高层次的目标条件策略，它（1）使用基元作为构建复杂长期任务的基础，（2）利用离散的行为先验来指导规划。",
    "tldr": "本论文介绍了从游戏中高效学习高层次计划的机器人学习框架，可以实现长期复杂的操作任务。他们利用任务不可知的游戏数据学习基于物体的离散行为先验，然后设计一个高层次的目标条件策略，它使用先验来指导规划和构建复杂长期任务。",
    "en_tdlr": "This paper introduces a robotic learning framework for efficient learning of high-level plans from play, which can achieve long-term complex manipulation tasks. They leverage task-agnostic play data to learn a discrete behavioral prior over object-centric primitives, and then design a high-level goal-conditioned policy which uses the prior to guide planning and scaffold complex long-term tasks."
}