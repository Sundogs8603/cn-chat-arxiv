{
    "title": "Mobiprox: Supporting Dynamic Approximate Computing on Mobiles",
    "abstract": "arXiv:2303.11291v2 Announce Type: replace  Abstract: Runtime-tunable context-dependent network compression would make mobile deep learning (DL) adaptable to often varying resource availability, input \"difficulty\", or user needs. The existing compression techniques significantly reduce the memory, processing, and energy tax of DL, yet, the resulting models tend to be permanently impaired, sacrificing the inference power for reduced resource usage. The existing tunable compression approaches, on the other hand, require expensive re-training, do not support arbitrary strategies for adapting the compression and do not provide mobile-ready implementations.   In this paper we present Mobiprox, a framework enabling mobile DL with flexible precision. Mobiprox implements tunable approximations of tensor operations and enables runtime-adaptable approximation of individual network layers. A profiler and a tuner included with Mobiprox identify the most promising neural network approximation config",
    "link": "https://arxiv.org/abs/2303.11291",
    "context": "Title: Mobiprox: Supporting Dynamic Approximate Computing on Mobiles\nAbstract: arXiv:2303.11291v2 Announce Type: replace  Abstract: Runtime-tunable context-dependent network compression would make mobile deep learning (DL) adaptable to often varying resource availability, input \"difficulty\", or user needs. The existing compression techniques significantly reduce the memory, processing, and energy tax of DL, yet, the resulting models tend to be permanently impaired, sacrificing the inference power for reduced resource usage. The existing tunable compression approaches, on the other hand, require expensive re-training, do not support arbitrary strategies for adapting the compression and do not provide mobile-ready implementations.   In this paper we present Mobiprox, a framework enabling mobile DL with flexible precision. Mobiprox implements tunable approximations of tensor operations and enables runtime-adaptable approximation of individual network layers. A profiler and a tuner included with Mobiprox identify the most promising neural network approximation config",
    "path": "papers/23/03/2303.11291.json",
    "total_tokens": 822,
    "translated_title": "Mobiprox：支持移动设备上的动态近似计算",
    "translated_abstract": "arXiv:2303.11291v2 公告类型：替换 摘要：Runtime-tunable context-dependent网络压缩将使移动深度学习（DL）适应于经常变化的资源可用性、输入“难度”或用户需求。现有的压缩技术显著减少了DL的内存、处理和能耗，但由此产生的模型往往永久受损，牺牲了推理能力以换取减少资源使用。另一方面，现有的可调压缩方法需要昂贵的重新训练，不支持任意压缩策略调整，并且不提供适合移动设备的实现。 在本文中，我们介绍了Mobiprox，这是一个支持移动设备具有灵活精度的框架。Mobiprox实现了张量操作的可调近似，并实现了对单个网络层的运行时可调近似。Mobiprox附带的分析器和调整器识别了最有希望的神经网络配置。",
    "tldr": "Mobiprox提供了一个框架，支持移动设备上的动态近似计算，并且实现了对单个网络层的运行时可调近似。"
}