{
    "title": "FMAS: Fast Multi-Objective SuperNet Architecture Search for Semantic Segmentation. (arXiv:2303.16322v1 [cs.CV])",
    "abstract": "We present FMAS, a fast multi-objective neural architecture search framework for semantic segmentation. FMAS subsamples the structure and pre-trained parameters of DeepLabV3+, without fine-tuning, dramatically reducing training time during search. To further reduce candidate evaluation time, we use a subset of the validation dataset during the search. Only the final, Pareto non-dominated, candidates are ultimately fine-tuned using the complete training set. We evaluate FMAS by searching for models that effectively trade accuracy and computational cost on the PASCAL VOC 2012 dataset. FMAS finds competitive designs quickly, e.g., taking just 0.5 GPU days to discover a DeepLabV3+ variant that reduces FLOPs and parameters by 10$\\%$ and 20$\\%$ respectively, for less than 3$\\%$ increased error. We also search on an edge device called GAP8 and use its latency as the metric. FMAS is capable of finding 2.2$\\times$ faster network with 7.61$\\%$ MIoU loss.",
    "link": "http://arxiv.org/abs/2303.16322",
    "context": "Title: FMAS: Fast Multi-Objective SuperNet Architecture Search for Semantic Segmentation. (arXiv:2303.16322v1 [cs.CV])\nAbstract: We present FMAS, a fast multi-objective neural architecture search framework for semantic segmentation. FMAS subsamples the structure and pre-trained parameters of DeepLabV3+, without fine-tuning, dramatically reducing training time during search. To further reduce candidate evaluation time, we use a subset of the validation dataset during the search. Only the final, Pareto non-dominated, candidates are ultimately fine-tuned using the complete training set. We evaluate FMAS by searching for models that effectively trade accuracy and computational cost on the PASCAL VOC 2012 dataset. FMAS finds competitive designs quickly, e.g., taking just 0.5 GPU days to discover a DeepLabV3+ variant that reduces FLOPs and parameters by 10$\\%$ and 20$\\%$ respectively, for less than 3$\\%$ increased error. We also search on an edge device called GAP8 and use its latency as the metric. FMAS is capable of finding 2.2$\\times$ faster network with 7.61$\\%$ MIoU loss.",
    "path": "papers/23/03/2303.16322.json",
    "total_tokens": 932,
    "translated_title": "FMAS：用于语义分割的快速多目标超级网络架构搜索",
    "translated_abstract": "本文提出了FMAS，一种针对语义分割的快速多目标神经架构搜索框架。FMAS对DeepLabV3+的结构和预训练参数进行子采样，无需微调，大大减少搜索期间的训练时间。为了进一步降低候选模型的评估时间，在搜索过程中仅使用验证集的子集。只有最终的 Pareto非支配 候选模型最终使用完整的训练集进行微调。我们在PASCAL VOC 2012数据集上搜索了有效的精度和计算成本交换模型，并评估了FMAS的性能。FMAS能够快速找到有竞争力的设计，例如只需0.5个GPU天即可发现DeepLabV3+变体，将FLOPs和参数分别减少10%和20%，误差仅增加不到3%。我们在一种名为GAP8的边缘设备上进行了搜索，并将其延迟作为度量标准，FMAS能够找到2.2倍更快的网络，丢失7.61% MIoU。",
    "tldr": "本文提出了快速多目标神经架构搜索框架FMAS，搜索有效的语义分割模型，能够快速找到有竞争力的设计，并在边缘设备上找到更快的网络。",
    "en_tdlr": "This paper proposes a fast multi-objective neural architecture search framework FMAS, which searches for effective semantic segmentation models and can quickly find competitive designs, and finds faster networks on edge devices."
}