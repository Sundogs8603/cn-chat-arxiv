{
    "title": "A multidomain relational framework to guide institutional AI research and adoption. (arXiv:2303.10106v1 [cs.CY])",
    "abstract": "Calls for new metrics, technical standards and governance mechanisms to guide the adoption of Artificial Intelligence (AI) in institutions and public administration are now commonplace. Yet, most research and policy efforts aimed at understanding the implications of adopting AI tend to prioritize only a handful of ideas; they do not fully account for all the different perspectives and topics that are potentially relevant. In this position paper, we contend that this omission stems, in part, from what we call the relational problem in socio-technical discourse: fundamental ontological issues have not yet been settled-including semantic ambiguity, a lack of clear relations between concepts and differing standard terminologies. This contributes to the persistence of disparate modes of reasoning to assess institutional AI systems, and the prevalence of conceptual isolation in the fields that study them including ML, human factors, social science and policy. After developing this critique, ",
    "link": "http://arxiv.org/abs/2303.10106",
    "context": "Title: A multidomain relational framework to guide institutional AI research and adoption. (arXiv:2303.10106v1 [cs.CY])\nAbstract: Calls for new metrics, technical standards and governance mechanisms to guide the adoption of Artificial Intelligence (AI) in institutions and public administration are now commonplace. Yet, most research and policy efforts aimed at understanding the implications of adopting AI tend to prioritize only a handful of ideas; they do not fully account for all the different perspectives and topics that are potentially relevant. In this position paper, we contend that this omission stems, in part, from what we call the relational problem in socio-technical discourse: fundamental ontological issues have not yet been settled-including semantic ambiguity, a lack of clear relations between concepts and differing standard terminologies. This contributes to the persistence of disparate modes of reasoning to assess institutional AI systems, and the prevalence of conceptual isolation in the fields that study them including ML, human factors, social science and policy. After developing this critique, ",
    "path": "papers/23/03/2303.10106.json",
    "total_tokens": 927,
    "translated_title": "一个多元关系框架指导机构人工智能研究和采纳",
    "translated_abstract": "对于指导机构和公共管理中人工智能（AI）采纳的新指标、技术标准和管理机制的呼吁现已司空见惯。然而，大多数旨在了解采纳AI的影响的研究和政策努力往往只优先考虑少数想法，而未完全考虑所有潜在相关的不同视角和主题。在这篇立场文件中，我们认为这种遗漏在一定程度上源于我们所称的社会技术话语中的关系问题:基本的本体论问题尚未解决，包括语义模糊、概念之间缺乏明确的关系和不同的标准术语。这导致在评估机构AI系统的不同推理模式以及研究它们的领域，包括机器学习、人类因素、社会科学和政策方面存在概念孤立。在发展了这一批判之后，",
    "tldr": "该论文提出一个多元关系框架来指导机构人工智能的研究和采纳，解决社会技术话语中的关系问题，包括语义模糊、概念之间缺乏明确的关系和不同的标准术语，帮助评估机构AI系统，避免概念孤立。",
    "en_tdlr": "This paper proposes a multidomain relational framework to guide institutional AI research and adoption, addressing the relational problem in socio-technical discourse, including semantic ambiguity, a lack of clear relations between concepts, and differing standard terminologies, to help assess institutional AI systems and avoid conceptual isolation."
}