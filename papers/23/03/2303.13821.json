{
    "title": "Factor Decomposed Generative Adversarial Networks for Text-to-Image Synthesis. (arXiv:2303.13821v1 [cs.MM])",
    "abstract": "Prior works about text-to-image synthesis typically concatenated the sentence embedding with the noise vector, while the sentence embedding and the noise vector are two different factors, which control the different aspects of the generation. Simply concatenating them will entangle the latent factors and encumber the generative model.  In this paper, we attempt to decompose these two factors and propose Factor Decomposed Generative Adversarial Networks~(FDGAN). To achieve this, we firstly generate images from the noise vector and then apply the sentence embedding in the normalization layer for both generator and discriminators. We also design an additive norm layer to align and fuse the text-image features. The experimental results show that decomposing the noise and the sentence embedding can disentangle latent factors in text-to-image synthesis, and make the generative model more efficient. Compared with the baseline, FDGAN can achieve better performance, while fewer parameters are u",
    "link": "http://arxiv.org/abs/2303.13821",
    "context": "Title: Factor Decomposed Generative Adversarial Networks for Text-to-Image Synthesis. (arXiv:2303.13821v1 [cs.MM])\nAbstract: Prior works about text-to-image synthesis typically concatenated the sentence embedding with the noise vector, while the sentence embedding and the noise vector are two different factors, which control the different aspects of the generation. Simply concatenating them will entangle the latent factors and encumber the generative model.  In this paper, we attempt to decompose these two factors and propose Factor Decomposed Generative Adversarial Networks~(FDGAN). To achieve this, we firstly generate images from the noise vector and then apply the sentence embedding in the normalization layer for both generator and discriminators. We also design an additive norm layer to align and fuse the text-image features. The experimental results show that decomposing the noise and the sentence embedding can disentangle latent factors in text-to-image synthesis, and make the generative model more efficient. Compared with the baseline, FDGAN can achieve better performance, while fewer parameters are u",
    "path": "papers/23/03/2303.13821.json",
    "total_tokens": 940,
    "translated_title": "基于因子分解的生成对抗网络用于文本转图像合成",
    "translated_abstract": "先前的文本转图像合成工作通常是将句子嵌入与噪声向量拼接在一起，而句子嵌入和噪声向量是控制生成的不同方面的两个不同的因子。简单地将它们拼接在一起会使潜在的因子纠缠在一起，阻碍生成模型。在本文中，我们尝试分解这两个因子，提出了一种因子分解生成对抗网络（FDGAN）。为了实现这一点，我们首先从噪声向量生成图像，然后在生成器和判别器的归一化层中应用句子嵌入。我们还设计了一个加性规范层来对齐和融合文本-图像特征。实验结果表明，在文本转图像合成中分解噪声和句子嵌入可以解开潜在的因子，并使生成模型更加高效。与基线相比，FDGAN可以实现更好的性能，同时使用更少的参数。",
    "tldr": "本文提出一种因子分解生成对抗网络（FDGAN）用于文本转图像合成，能够将句子嵌入和噪声向量分解为不同的因子，并通过加性规范层来对齐和融合文本-图像特征，实验结果表明FDGAN可以实现更好的性能，同时使用更少的参数。"
}