{
    "title": "Diffusion Models Generate Images Like Painters: an Analytical Theory of Outline First, Details Later",
    "abstract": "arXiv:2303.02490v2 Announce Type: replace-cross  Abstract: How do diffusion generative models convert pure noise into meaningful images? In a variety of pretrained diffusion models (including conditional latent space models like Stable Diffusion), we observe that the reverse diffusion process that underlies image generation has the following properties: (i) individual trajectories tend to be low-dimensional and resemble 2D `rotations'; (ii) high-variance scene features like layout tend to emerge earlier, while low-variance details tend to emerge later; and (iii) early perturbations tend to have a greater impact on image content than later perturbations. To understand these phenomena, we derive and study a closed-form solution to the probability flow ODE for a Gaussian distribution, which shows that the reverse diffusion state rotates towards a gradually-specified target on the image manifold. It also shows that generation involves first committing to an outline, and then to finer and f",
    "link": "https://arxiv.org/abs/2303.02490",
    "context": "Title: Diffusion Models Generate Images Like Painters: an Analytical Theory of Outline First, Details Later\nAbstract: arXiv:2303.02490v2 Announce Type: replace-cross  Abstract: How do diffusion generative models convert pure noise into meaningful images? In a variety of pretrained diffusion models (including conditional latent space models like Stable Diffusion), we observe that the reverse diffusion process that underlies image generation has the following properties: (i) individual trajectories tend to be low-dimensional and resemble 2D `rotations'; (ii) high-variance scene features like layout tend to emerge earlier, while low-variance details tend to emerge later; and (iii) early perturbations tend to have a greater impact on image content than later perturbations. To understand these phenomena, we derive and study a closed-form solution to the probability flow ODE for a Gaussian distribution, which shows that the reverse diffusion state rotates towards a gradually-specified target on the image manifold. It also shows that generation involves first committing to an outline, and then to finer and f",
    "path": "papers/23/03/2303.02490.json",
    "total_tokens": 906,
    "translated_title": "扩散模型生成类似画家的图像：轮廓优先，细节其次的分析理论",
    "translated_abstract": "arXiv:2303.02490v2 公告类型: 替换-跨度 摘要: 扩散生成模型如何将纯噪声转换为有意义的图像？在各种预训练的扩散模型（包括类似稳定扩散的条件潜在空间模型）中，我们观察到潜在的反向扩散过程在图像生成中具有以下特性：(i)个体轨迹倾向于是低维且类似于2D的“旋转”；(ii)高方差的场景特征如布局倾向于较早出现，而低方差的细节倾向于较晚出现；(iii)早期扰动往往会比后期扰动对图像内容产生更大的影响。为了理解这些现象，我们推导并研究了高斯分布的概率流ODE的封闭形式解决方案，这显示出反向扩散状态向着逐渐指定的目标在图像流形上旋转。它还表明生成首先涉及承诺一种轮廓，然后是更精细的和f",
    "tldr": "扩散生成模型倾向于首先生成轮廓，然后逐渐加入细节，早期扰动对图像内容影响较大",
    "en_tdlr": "Diffusion generative models tend to generate outlines first and gradually incorporate details, with early perturbations having a greater impact on image content."
}