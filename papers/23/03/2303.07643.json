{
    "title": "Feature-Rich Audio Model Inversion for Data-Free Knowledge Distillation Towards General Sound Classification. (arXiv:2303.07643v1 [cs.SD])",
    "abstract": "Data-Free Knowledge Distillation (DFKD) has recently attracted growing attention in the academic community, especially with major breakthroughs in computer vision. Despite promising results, the technique has not been well applied to audio and signal processing. Due to the variable duration of audio signals, it has its own unique way of modeling. In this work, we propose feature-rich audio model inversion (FRAMI), a data-free knowledge distillation framework for general sound classification tasks. It first generates high-quality and feature-rich Mel-spectrograms through a feature-invariant contrastive loss. Then, the hidden states before and after the statistics pooling layer are reused when knowledge distillation is performed on these feature-rich samples. Experimental results on the Urbansound8k, ESC-50, and audioMNIST datasets demonstrate that FRAMI can generate feature-rich samples. Meanwhile, the accuracy of the student model is further improved by reusing the hidden state and sig",
    "link": "http://arxiv.org/abs/2303.07643",
    "total_tokens": 1042,
    "translated_title": "基于特征丰富的音频模型反演的无数据知识蒸馏以实现通用声音分类",
    "translated_abstract": "最近，无数据知识蒸馏（DFKD）在学术界引起了越来越多的关注，尤其是在计算机视觉取得了重大突破后。尽管技术有着很好的效果，但其在音频和信号处理方面的应用还不是很好。由于音频信号的可变持续时间，其具有自己独特的建模方式。在这项工作中，我们提出了基于特征丰富的音频模型反演（FRAMI），这是一种用于通用声音分类任务的无数据知识蒸馏框架。它首先通过特征不变对比损失生成高质量和特征丰富的Mel频谱图。然后，在这些特征丰富的样本上进行知识蒸馏时，再利用统计汇集层之前和之后的隐藏状态。在Urbansound8k、ESC-50和audioMNIST数据集上的实验结果表明，FRAMI能够生成特征丰富的样本。同时，通过重用隐藏状态和信号，进一步提高了学生模型的准确性。",
    "tldr": "该论文提出了一种基于特征丰富的音频模型反演（FRAMI）的无数据知识蒸馏框架，用于通用声音分类任务。通过特征不变对比损失生成高质量和特征丰富的Mel频谱图，再利用统计汇集层之前和之后的隐藏状态进行知识蒸馏。实验结果表明，该方法能够提高学生模型的准确性。",
    "en_tdlr": "This paper proposes an approach called feature-rich audio model inversion (FRAMI) for data-free knowledge distillation towards general sound classification tasks. The method employs a feature-invariant contrastive loss to generate high-quality and feature-rich Mel-spectrograms, and reuses the hidden states before and after the statistics pooling layer during knowledge distillation. Experimental results on three datasets indicate that FRAMI can improve the accuracy of the student model."
}