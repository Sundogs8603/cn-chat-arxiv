{
    "title": "An Empirical Study of Pre-trained Language Models in Simple Knowledge Graph Question Answering. (arXiv:2303.10368v1 [cs.CL])",
    "abstract": "Large-scale pre-trained language models (PLMs) such as BERT have recently achieved great success and become a milestone in natural language processing (NLP). It is now the consensus of the NLP community to adopt PLMs as the backbone for downstream tasks. In recent works on knowledge graph question answering (KGQA), BERT or its variants have become necessary in their KGQA models. However, there is still a lack of comprehensive research and comparison of the performance of different PLMs in KGQA. To this end, we summarize two basic KGQA frameworks based on PLMs without additional neural network modules to compare the performance of nine PLMs in terms of accuracy and efficiency. In addition, we present three benchmarks for larger-scale KGs based on the popular SimpleQuestions benchmark to investigate the scalability of PLMs. We carefully analyze the results of all PLMs-based KGQA basic frameworks on these benchmarks and two other popular datasets, WebQuestionSP and FreebaseQA, and find th",
    "link": "http://arxiv.org/abs/2303.10368",
    "context": "Title: An Empirical Study of Pre-trained Language Models in Simple Knowledge Graph Question Answering. (arXiv:2303.10368v1 [cs.CL])\nAbstract: Large-scale pre-trained language models (PLMs) such as BERT have recently achieved great success and become a milestone in natural language processing (NLP). It is now the consensus of the NLP community to adopt PLMs as the backbone for downstream tasks. In recent works on knowledge graph question answering (KGQA), BERT or its variants have become necessary in their KGQA models. However, there is still a lack of comprehensive research and comparison of the performance of different PLMs in KGQA. To this end, we summarize two basic KGQA frameworks based on PLMs without additional neural network modules to compare the performance of nine PLMs in terms of accuracy and efficiency. In addition, we present three benchmarks for larger-scale KGs based on the popular SimpleQuestions benchmark to investigate the scalability of PLMs. We carefully analyze the results of all PLMs-based KGQA basic frameworks on these benchmarks and two other popular datasets, WebQuestionSP and FreebaseQA, and find th",
    "path": "papers/23/03/2303.10368.json",
    "total_tokens": 946,
    "translated_title": "简易知识图谱问答中预训练语言模型的实证研究",
    "translated_abstract": "大规模预训练语言模型（PLMs）如BERT最近取得了巨大成功，成为自然语言处理（NLP）中的里程碑。现在，NLP界普遍认为采用PLMs作为下游任务的骨干是一种共识。在最近的知识图谱问答（KGQA）研究中，BERT或其变体已成为其KGQA模型中必不可少的。然而，目前仍缺乏对KGQA中不同PLMs性能的全面研究和比较。为了解决这个问题，我们总结了两种基于PLMs的基本KGQA框架，比较了九种PLMs在准确性和效率方面的表现，并提出了基于流行的SimpleQuestions基准测试的三个更大规模的KGs基准测试，以研究PLMs的可扩展性。我们仔细分析了所有基于PLMs的KGQA基础框架在这些基准测试以及其他两个流行数据集WebQuestionSP和FreebaseQA上的结果，并发现RoBERTa和ELECTRA模型在KGQA中表现最佳。",
    "tldr": "该论文旨在比较和分析不同预训练语言模型在简易知识图谱问答中的表现，研究发现RoBERTa和ELECTRA模型在KGQA中表现最佳。",
    "en_tdlr": "This paper aims to compare and analyze the performance of different pre-trained language models in simple knowledge graph question answering. The study finds that RoBERTa and ELECTRA models achieve the best performance in KGQA."
}