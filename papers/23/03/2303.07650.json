{
    "title": "Cross-lingual Alzheimer's Disease detection based on paralinguistic and pre-trained features. (arXiv:2303.07650v1 [cs.CL])",
    "abstract": "We present our submission to the ICASSP-SPGC-2023 ADReSS-M Challenge Task, which aims to investigate which acoustic features can be generalized and transferred across languages for Alzheimer's Disease (AD) prediction. The challenge consists of two tasks: one is to classify the speech of AD patients and healthy individuals, and the other is to infer Mini Mental State Examination (MMSE) score based on speech only. The difficulty is mainly embodied in the mismatch of the dataset, in which the training set is in English while the test set is in Greek. We extract paralinguistic features using openSmile toolkit and acoustic features using XLSR-53. In addition, we extract linguistic features after transcribing the speech into text. These features are used as indicators for AD detection in our method. Our method achieves an accuracy of 69.6% on the classification task and a root mean squared error (RMSE) of 4.788 on the regression task. The results show that our proposed method is expected to ",
    "link": "http://arxiv.org/abs/2303.07650",
    "context": "Title: Cross-lingual Alzheimer's Disease detection based on paralinguistic and pre-trained features. (arXiv:2303.07650v1 [cs.CL])\nAbstract: We present our submission to the ICASSP-SPGC-2023 ADReSS-M Challenge Task, which aims to investigate which acoustic features can be generalized and transferred across languages for Alzheimer's Disease (AD) prediction. The challenge consists of two tasks: one is to classify the speech of AD patients and healthy individuals, and the other is to infer Mini Mental State Examination (MMSE) score based on speech only. The difficulty is mainly embodied in the mismatch of the dataset, in which the training set is in English while the test set is in Greek. We extract paralinguistic features using openSmile toolkit and acoustic features using XLSR-53. In addition, we extract linguistic features after transcribing the speech into text. These features are used as indicators for AD detection in our method. Our method achieves an accuracy of 69.6% on the classification task and a root mean squared error (RMSE) of 4.788 on the regression task. The results show that our proposed method is expected to ",
    "path": "papers/23/03/2303.07650.json",
    "total_tokens": 868,
    "translated_title": "基于平行语言和预训练特征的跨语言阿尔茨海默病检测",
    "translated_abstract": "本文介绍我们在ICASSP-SPGC-2023 ADReSS-M挑战任务中的提交，旨在研究哪些声学特征可以跨语言应用于阿尔茨海默病（AD）的预测中。我们使用openSmile工具包提取平行语言特征和XLSR-53提取声学特征。此外，我们将语音转录为文本后提取语言特征。这些特征被用作我们方法中的AD检测指标。我们的方法在分类任务上实现了69.6％的准确率，在回归任务上的均方根误差（RMSE）为4.788。结果表明，我们的方法有望在跨语言AD检测方面发挥作用。",
    "tldr": "该论文研究了跨语言阿尔茨海默病检测，使用平行语言和预训练特征提取声学和语言特征，实现了69.6%的分类准确率和4.788的均方根误差。",
    "en_tdlr": "This paper investigates cross-lingual Alzheimer's Disease detection, utilizing paralinguistic and pre-trained features to extract acoustic and linguistic features. The proposed method achieves 69.6% accuracy on classification task and a root mean squared error of 4.788 on regression task."
}