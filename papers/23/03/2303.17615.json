{
    "title": "Utilizing Reinforcement Learning for de novo Drug Design. (arXiv:2303.17615v1 [q-bio.BM])",
    "abstract": "Deep learning-based approaches for generating novel drug molecules with specific properties have gained a lot of interest in the last years. Recent studies have demonstrated promising performance for string-based generation of novel molecules utilizing reinforcement learning. In this paper, we develop a unified framework for using reinforcement learning for de novo drug design, wherein we systematically study various on- and off-policy reinforcement learning algorithms and replay buffers to learn an RNN-based policy to generate novel molecules predicted to be active against the dopamine receptor DRD2. Our findings suggest that it is advantageous to use at least both top-scoring and low-scoring molecules for updating the policy when structural diversity is essential. Using all generated molecules at an iteration seems to enhance performance stability for on-policy algorithms. In addition, when replaying high, intermediate, and low-scoring molecules, off-policy algorithms display the pot",
    "link": "http://arxiv.org/abs/2303.17615",
    "context": "Title: Utilizing Reinforcement Learning for de novo Drug Design. (arXiv:2303.17615v1 [q-bio.BM])\nAbstract: Deep learning-based approaches for generating novel drug molecules with specific properties have gained a lot of interest in the last years. Recent studies have demonstrated promising performance for string-based generation of novel molecules utilizing reinforcement learning. In this paper, we develop a unified framework for using reinforcement learning for de novo drug design, wherein we systematically study various on- and off-policy reinforcement learning algorithms and replay buffers to learn an RNN-based policy to generate novel molecules predicted to be active against the dopamine receptor DRD2. Our findings suggest that it is advantageous to use at least both top-scoring and low-scoring molecules for updating the policy when structural diversity is essential. Using all generated molecules at an iteration seems to enhance performance stability for on-policy algorithms. In addition, when replaying high, intermediate, and low-scoring molecules, off-policy algorithms display the pot",
    "path": "papers/23/03/2303.17615.json",
    "total_tokens": 927,
    "translated_title": "利用强化学习进行de novo药物设计",
    "translated_abstract": "基于深度学习的药物设计方法在生成具有特定性质的新药分子方面表现出了强大的潜力。最近的研究利用强化学习实现了字符串生成新分子的显著性能提升。本文中，我们开发了一个统一的框架，利用强化学习进行de novo药物设计，系统地研究了各种on-policy和off-policy 强化学习算法和重播缓冲区，学习基于RNN的策略，生成预测对于多巴胺受体DRD2具有活性的新分子。我们的研究结果表明，在需要结构多样性的情况下，同时使用高分和低分分子来更新策略是有利的。对于on-policy算法，使用所有生成的分子可以提高性能稳定性。此外，当重放高、中和低分子时，off-policy算法有潜力提高生成分子的结构多样性。",
    "tldr": "本文开发了一个统一的框架，利用强化学习生成预测具有活性的新药分子。在需要结构多样性的情况下，同时使用高分和低分子来更新策略是有利的。使用所有生成的分子可以提高性能稳定性，而off-policy算法有潜力提高生成分子的结构多样性。",
    "en_tdlr": "This paper develops a unified framework for using reinforcement learning for de novo drug design and demonstrates that using both high-scoring and low-scoring molecules for updating the policy is advantageous when structural diversity is essential. Using all generated molecules can enhance performance stability for on-policy algorithms, while off-policy algorithms have the potential to improve the structural diversity of generated molecules."
}