{
    "title": "Finding the right XAI method -- A Guide for the Evaluation and Ranking of Explainable AI Methods in Climate Science",
    "abstract": "arXiv:2303.00652v2 Announce Type: replace-cross  Abstract: Explainable artificial intelligence (XAI) methods shed light on the predictions of machine learning algorithms. Several different approaches exist and have already been applied in climate science. However, usually missing ground truth explanations complicate their evaluation and comparison, subsequently impeding the choice of the XAI method. Therefore, in this work, we introduce XAI evaluation in the climate context and discuss different desired explanation properties, namely robustness, faithfulness, randomization, complexity, and localization. To this end, we chose previous work as a case study where the decade of annual-mean temperature maps is predicted. After training both a multi-layer perceptron (MLP) and a convolutional neural network (CNN), multiple XAI methods are applied and their skill scores in reference to a random uniform explanation are calculated for each property. Independent of the network, we find that XAI m",
    "link": "https://arxiv.org/abs/2303.00652",
    "context": "Title: Finding the right XAI method -- A Guide for the Evaluation and Ranking of Explainable AI Methods in Climate Science\nAbstract: arXiv:2303.00652v2 Announce Type: replace-cross  Abstract: Explainable artificial intelligence (XAI) methods shed light on the predictions of machine learning algorithms. Several different approaches exist and have already been applied in climate science. However, usually missing ground truth explanations complicate their evaluation and comparison, subsequently impeding the choice of the XAI method. Therefore, in this work, we introduce XAI evaluation in the climate context and discuss different desired explanation properties, namely robustness, faithfulness, randomization, complexity, and localization. To this end, we chose previous work as a case study where the decade of annual-mean temperature maps is predicted. After training both a multi-layer perceptron (MLP) and a convolutional neural network (CNN), multiple XAI methods are applied and their skill scores in reference to a random uniform explanation are calculated for each property. Independent of the network, we find that XAI m",
    "path": "papers/23/03/2303.00652.json",
    "total_tokens": 860,
    "translated_title": "确定正确的XAI方法--气候科学中可解释人工智能方法的评估和排序指南",
    "translated_abstract": "可解释人工智能（XAI）方法揭示了机器学习算法的预测。存在几种不同的方法，已经应用于气候科学中。然而，通常缺少地面真实解释使他们的评估和比较变得复杂，进而阻碍了XAI方法的选择。因此，在这项工作中，我们介绍了气候背景下的XAI评估，并讨论了不同的期望解释特性，即稳健性、忠实性、随机性、复杂性和定位性。为此，我们选择以某一案例研究先前的工作，预测了十年的年均温度图。在训练了多层感知器（MLP）和卷积神经网络（CNN）之后，应用多种XAI方法，并计算它们在每个属性上与随机均匀解释的技能分数。独立于网络，我们发现XAI m",
    "tldr": "这项工作介绍了气候背景下的XAI评估，并讨论了不同的期望解释特性，为了评估和排序可解释人工智能方法在气候科学中的应用。",
    "en_tdlr": "This work introduces XAI evaluation in the climate context and discusses different desired explanation properties, aiming to evaluate and rank explainable AI methods in climate science."
}