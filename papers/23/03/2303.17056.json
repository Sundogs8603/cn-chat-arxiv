{
    "title": "Audio-Visual Grouping Network for Sound Localization from Mixtures. (arXiv:2303.17056v1 [cs.CV])",
    "abstract": "Sound source localization is a typical and challenging task that predicts the location of sound sources in a video. Previous single-source methods mainly used the audio-visual association as clues to localize sounding objects in each image. Due to the mixed property of multiple sound sources in the original space, there exist rare multi-source approaches to localizing multiple sources simultaneously, except for one recent work using a contrastive random walk in the graph with images and separated sound as nodes. Despite their promising performance, they can only handle a fixed number of sources, and they cannot learn compact class-aware representations for individual sources. To alleviate this shortcoming, in this paper, we propose a novel audio-visual grouping network, namely AVGN, that can directly learn category-wise semantic features for each source from the input audio mixture and image to localize multiple sources simultaneously. Specifically, our AVGN leverages learnable audio-v",
    "link": "http://arxiv.org/abs/2303.17056",
    "context": "Title: Audio-Visual Grouping Network for Sound Localization from Mixtures. (arXiv:2303.17056v1 [cs.CV])\nAbstract: Sound source localization is a typical and challenging task that predicts the location of sound sources in a video. Previous single-source methods mainly used the audio-visual association as clues to localize sounding objects in each image. Due to the mixed property of multiple sound sources in the original space, there exist rare multi-source approaches to localizing multiple sources simultaneously, except for one recent work using a contrastive random walk in the graph with images and separated sound as nodes. Despite their promising performance, they can only handle a fixed number of sources, and they cannot learn compact class-aware representations for individual sources. To alleviate this shortcoming, in this paper, we propose a novel audio-visual grouping network, namely AVGN, that can directly learn category-wise semantic features for each source from the input audio mixture and image to localize multiple sources simultaneously. Specifically, our AVGN leverages learnable audio-v",
    "path": "papers/23/03/2303.17056.json",
    "total_tokens": 1088,
    "translated_title": "音视频分组网络用于混合声音定位",
    "translated_abstract": "声源定位是一项典型且具有挑战性的任务，可预测视频中声源的位置。以往的单声源方法主要利用音视频关联作为线索，以定位每张图片中的声源对象。由于原空间中有多个声源的混合属性，除了一项近期使用对比随机游走在图像和分离声音作为节点的图中处理多个声源的方法之外，很少有多声源方法同时进行本地化。尽管它们表现出有希望的性能，但它们只能处理固定数量的声源，并且不能为各个声源学习紧凑的类知识表示。为了缓解这个缺点，本文提出了一种新颖的音视频分组网络，即 AVGN，它可以直接从输入的音频混合和图像中学习每个声源的类别语义特征，以多声源同时定位。具体而言，我们的 AVGN 利用可学习的音视频样本和分组注意机制，发现类别感知音频和视觉特征，并进一步对其进行对齐以实现视频中的多声源定位。我们在两个基准测试上评估了我们的方法，实验结果表明，我们的方法在定位精度和对复杂环境的鲁棒性方面均优于现有方法。",
    "tldr": "本文提出的 AVGN 网络利用音频-视觉样本和分组注意机制，发现类别感知的音频和视觉特征并对齐，以实现同时定位多个声源的目标。在两个基准测试上的结果表明，该方法在定位精度和对复杂环境的鲁棒性方面均优于现有方法。",
    "en_tdlr": "The proposed AVGN network leverages learnable audio-visual samples and group attention mechanism to discover category-aware audio and visual features, and align them for multi-source localization in the video. The experimental results on two benchmarks show that our approach outperforms state-of-the-art methods in terms of both localization accuracy and robustness to complex environments."
}