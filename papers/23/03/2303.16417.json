{
    "title": "Problems and shortcuts in deep learning for screening mammography. (arXiv:2303.16417v1 [cs.CV])",
    "abstract": "This work reveals undiscovered challenges in the performance and generalizability of deep learning models. We (1) identify spurious shortcuts and evaluation issues that can inflate performance and (2) propose training and analysis methods to address them.  We trained an AI model to classify cancer on a retrospective dataset of 120,112 US exams (3,467 cancers) acquired from 2008 to 2017 and 16,693 UK exams (5,655 cancers) acquired from 2011 to 2015.  We evaluated on a screening mammography test set of 11,593 US exams (102 cancers; 7,594 women; age 57.1 \\pm 11.0) and 1,880 UK exams (590 cancers; 1,745 women; age 63.3 \\pm 7.2). A model trained on images of only view markers (no breast) achieved a 0.691 AUC. The original model trained on both datasets achieved a 0.945 AUC on the combined US+UK dataset but paradoxically only 0.838 and 0.892 on the US and UK datasets, respectively. Sampling cancers equally from both datasets during training mitigated this shortcut. A similar AUC paradox (0.9",
    "link": "http://arxiv.org/abs/2303.16417",
    "context": "Title: Problems and shortcuts in deep learning for screening mammography. (arXiv:2303.16417v1 [cs.CV])\nAbstract: This work reveals undiscovered challenges in the performance and generalizability of deep learning models. We (1) identify spurious shortcuts and evaluation issues that can inflate performance and (2) propose training and analysis methods to address them.  We trained an AI model to classify cancer on a retrospective dataset of 120,112 US exams (3,467 cancers) acquired from 2008 to 2017 and 16,693 UK exams (5,655 cancers) acquired from 2011 to 2015.  We evaluated on a screening mammography test set of 11,593 US exams (102 cancers; 7,594 women; age 57.1 \\pm 11.0) and 1,880 UK exams (590 cancers; 1,745 women; age 63.3 \\pm 7.2). A model trained on images of only view markers (no breast) achieved a 0.691 AUC. The original model trained on both datasets achieved a 0.945 AUC on the combined US+UK dataset but paradoxically only 0.838 and 0.892 on the US and UK datasets, respectively. Sampling cancers equally from both datasets during training mitigated this shortcut. A similar AUC paradox (0.9",
    "path": "papers/23/03/2303.16417.json",
    "total_tokens": 943,
    "translated_title": "深度学习在乳腺X光检查中的问题和快捷方式",
    "translated_abstract": "本研究揭示了深度学习模型在性能和泛化能力方面未被发现的挑战。我们（1）识别出可能会提高性能的问题以及评估问题，并（2）提出了训练和分析方法来解决这些问题。我们利用120,112个美国乳腺检查和16,693个英国乳腺检查进行了癌症分类的AI模型训练和评估。我们发现，一个仅使用无乳房的图像进行训练的模型在特定测试集上有较高的性能表现。我们还发现，AUC分数的悖论现象出现在了两个国家的测试集上，（0.838和0.892），但是在联合测试集上AUC分数高达0.945。通过在训练过程中等量采样两个数据集中的癌症数据可以减轻这种情况。",
    "tldr": "本研究发现在乳腺X光检查中，深度学习模型存在问题和快捷方式，建议利用采样方式平衡训练数据，并对相应的评估问题提出了解决方案"
}