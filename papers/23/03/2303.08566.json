{
    "title": "Sensitivity-Aware Visual Parameter-Efficient Tuning. (arXiv:2303.08566v1 [cs.CV])",
    "abstract": "Visual Parameter-Efficient Tuning (VPET) has become a powerful alternative for full fine-tuning so as to adapt pre-trained vision models to downstream tasks, which only tunes a small number of parameters while freezing the vast majority ones to ease storage burden and optimization difficulty. However, existing VPET methods introduce trainable parameters to the same positions across different tasks depending solely on human heuristics and neglect the domain gaps. To this end, we study where to introduce and how to allocate trainable parameters by proposing a novel Sensitivity-aware visual Parameter-efficient Tuning (SPT) scheme, which adaptively allocates trainable parameters to task-specific important positions given a desired tunable parameter budget. Specifically, our SPT first quickly identifies the sensitive parameters that require tuning for a given task in a data-dependent way. Next, our SPT further boosts the representational capability for the weight matrices whose number of se",
    "link": "http://arxiv.org/abs/2303.08566",
    "context": "Title: Sensitivity-Aware Visual Parameter-Efficient Tuning. (arXiv:2303.08566v1 [cs.CV])\nAbstract: Visual Parameter-Efficient Tuning (VPET) has become a powerful alternative for full fine-tuning so as to adapt pre-trained vision models to downstream tasks, which only tunes a small number of parameters while freezing the vast majority ones to ease storage burden and optimization difficulty. However, existing VPET methods introduce trainable parameters to the same positions across different tasks depending solely on human heuristics and neglect the domain gaps. To this end, we study where to introduce and how to allocate trainable parameters by proposing a novel Sensitivity-aware visual Parameter-efficient Tuning (SPT) scheme, which adaptively allocates trainable parameters to task-specific important positions given a desired tunable parameter budget. Specifically, our SPT first quickly identifies the sensitive parameters that require tuning for a given task in a data-dependent way. Next, our SPT further boosts the representational capability for the weight matrices whose number of se",
    "path": "papers/23/03/2303.08566.json",
    "total_tokens": 792,
    "translated_title": "敏感度感知的视觉参数低效调整",
    "translated_abstract": "视觉参数低效调整（VPET）已成为自适应预训练视觉模型到下游任务的强劲替代方法。现有VPET方法根据人工启发式方法将可训练参数引入不同任务的相同位置，忽略领域差异。本文提出了一种新颖的敏感度感知的视觉参数低效调整（SPT）方案，以自适应的方式分配可训练参数到任务特定的重要位置，给定所需的可调参数预算。本文首先依据数据的相关性快速识别特定任务所需调整的敏感参数，然后提升表示能力，增大重要的权重矩阵数量。",
    "tldr": "本文提出了敏感度感知的视觉参数低效调整（SPT）方案，可以自适应地将可训练参数分配到任务特定的重要位置，以提高表示能力，适应预训练视觉模型到下游任务。",
    "en_tdlr": "The paper proposes a novel Sensitivity-aware visual Parameter-efficient Tuning (SPT) scheme, which adaptively allocates trainable parameters to task-specific important positions to enhance representational capability and adapt pre-trained vision models to downstream tasks."
}