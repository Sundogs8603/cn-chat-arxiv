{
    "title": "Humans in Humans Out: On GPT Converging Toward Common Sense in both Success and Failure. (arXiv:2303.17276v1 [cs.AI])",
    "abstract": "Increase in computational scale and fine-tuning has seen a dramatic improvement in the quality of outputs of large language models (LLMs) like GPT. Given that both GPT-3 and GPT-4 were trained on large quantities of human-generated text, we might ask to what extent their outputs reflect patterns of human thinking, both for correct and incorrect cases. The Erotetic Theory of Reason (ETR) provides a symbolic generative model of both human success and failure in thinking, across propositional, quantified, and probabilistic reasoning, as well as decision-making. We presented GPT-3, GPT-3.5, and GPT-4 with 61 central inference and judgment problems from a recent book-length presentation of ETR, consisting of experimentally verified data-points on human judgment and extrapolated data-points predicted by ETR, with correct inference patterns as well as fallacies and framing effects (the ETR61 benchmark). ETR61 includes classics like Wason's card task, illusory inferences, the decoy effect, and",
    "link": "http://arxiv.org/abs/2303.17276",
    "context": "Title: Humans in Humans Out: On GPT Converging Toward Common Sense in both Success and Failure. (arXiv:2303.17276v1 [cs.AI])\nAbstract: Increase in computational scale and fine-tuning has seen a dramatic improvement in the quality of outputs of large language models (LLMs) like GPT. Given that both GPT-3 and GPT-4 were trained on large quantities of human-generated text, we might ask to what extent their outputs reflect patterns of human thinking, both for correct and incorrect cases. The Erotetic Theory of Reason (ETR) provides a symbolic generative model of both human success and failure in thinking, across propositional, quantified, and probabilistic reasoning, as well as decision-making. We presented GPT-3, GPT-3.5, and GPT-4 with 61 central inference and judgment problems from a recent book-length presentation of ETR, consisting of experimentally verified data-points on human judgment and extrapolated data-points predicted by ETR, with correct inference patterns as well as fallacies and framing effects (the ETR61 benchmark). ETR61 includes classics like Wason's card task, illusory inferences, the decoy effect, and",
    "path": "papers/23/03/2303.17276.json",
    "total_tokens": 988,
    "translated_title": "在GPT成功和失败的情况下，人类输入人类输出：论GPT朝向常识的趋同性",
    "translated_abstract": "计算规模和微调的增加使得大语言模型（LLM）例如GPT的输出质量得到了显著提高。鉴于GPT-3和GPT-4都是使用大量由人类生成的文本进行训练的，我们可以问他们的输出在多大程度上反映了人类思维的模式，无论是正确还是错误的情况。认识论理论提供了关于人类成功和失败的符号生成模型，包括命题、量化、概率推理和决策。本文将ETR的最近一个书本的61个核心推理和判断问题提供给了GPT-3、GPT-3.5和GPT-4，这些问题包括经过实验证实的人类判断数据点和ETR预测的数据点，同时包含正确的推理模式和谬误和框架效应（ETR61基准测试）。 ETR61包括了Wason的卡牌任务、错觉推理、诱饵效应等经典案例。",
    "tldr": "本文研究了GPT-3、GPT-3.5和GPT-4模型在人类思维模式中的表现, 运用认识论理论提供了符号生成模型，通过实验证实的人类判断数据点以及ETR预测数据点的数量级对模型进行了检验。"
}