{
    "title": "Black-box Backdoor Defense via Zero-shot Image Purification. (arXiv:2303.12175v1 [cs.CV])",
    "abstract": "Backdoor attacks inject poisoned data into the training set, resulting in misclassification of the poisoned samples during model inference. Defending against such attacks is challenging, especially in real-world black-box settings where only model predictions are available. In this paper, we propose a novel backdoor defense framework that can effectively defend against various attacks through zero-shot image purification (ZIP). Our proposed framework can be applied to black-box models without requiring any internal information about the poisoned model or any prior knowledge of the clean/poisoned samples. Our defense framework involves a two-step process. First, we apply a linear transformation on the poisoned image to destroy the trigger pattern. Then, we use a pre-trained diffusion model to recover the missing semantic information removed by the transformation. In particular, we design a new reverse process using the transformed image to guide the generation of high-fidelity purified ",
    "link": "http://arxiv.org/abs/2303.12175",
    "context": "Title: Black-box Backdoor Defense via Zero-shot Image Purification. (arXiv:2303.12175v1 [cs.CV])\nAbstract: Backdoor attacks inject poisoned data into the training set, resulting in misclassification of the poisoned samples during model inference. Defending against such attacks is challenging, especially in real-world black-box settings where only model predictions are available. In this paper, we propose a novel backdoor defense framework that can effectively defend against various attacks through zero-shot image purification (ZIP). Our proposed framework can be applied to black-box models without requiring any internal information about the poisoned model or any prior knowledge of the clean/poisoned samples. Our defense framework involves a two-step process. First, we apply a linear transformation on the poisoned image to destroy the trigger pattern. Then, we use a pre-trained diffusion model to recover the missing semantic information removed by the transformation. In particular, we design a new reverse process using the transformed image to guide the generation of high-fidelity purified ",
    "path": "papers/23/03/2303.12175.json",
    "total_tokens": 946,
    "translated_title": "零样本图像净化的黑盒后门防御方法",
    "translated_abstract": "后门攻击会将毒数据注入训练集，导致模型推理时样本错误分类。在仅有模型预测可用的实际黑盒环境中，防御此类攻击是具有挑战性的。本文提出了一种新颖的后门防御框架，可以通过零样本图像净化（ZIP）有效地抵御各种攻击。我们的防御框架可以应用于黑盒模型，不需要任何关于受污染模型的内部信息或任何关于干净/受污染样本的先前知识。我们的防御框架包括两个步骤。首先，我们对受污染的图像应用线性变换以破坏触发模式。然后，我们使用预训练的扩散模型来恢复由变换去除的缺失语义信息。特别地，我们设计了一个新的反向过程，使用变换后的图像来引导高保真度净化图像的生成。",
    "tldr": "本文提出了一种黑盒后门防御框架，利用零样本图像净化有效地防御各种攻击，无需任何内部信息或先前知识，通过对受污染的图像进行线性变换和预训练的扩散模型恢复缺失语义信息实现。",
    "en_tdlr": "This paper proposes a black-box backdoor defense framework that can effectively defend against various attacks through zero-shot image purification (ZIP), without requiring any internal information or prior knowledge. The defense framework involves a linear transformation on the poisoned image to destroy the trigger pattern and a pre-trained diffusion model to recover missing semantic information, achieved through a novel reverse process designed to guide the generation of high-fidelity purified images."
}