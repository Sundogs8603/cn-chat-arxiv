{
    "title": "TKN: Transformer-based Keypoint Prediction Network For Real-time Video Prediction. (arXiv:2303.09807v1 [cs.CV])",
    "abstract": "Video prediction is a complex time-series forecasting task with great potential in many use cases. However, conventional methods overemphasize accuracy while ignoring the slow prediction speed caused by complicated model structures that learn too much redundant information with excessive GPU memory consumption. Furthermore, conventional methods mostly predict frames sequentially (frame-by-frame) and thus are hard to accelerate. Consequently, valuable use cases such as real-time danger prediction and warning cannot achieve fast enough inference speed to be applicable in reality. Therefore, we propose a transformer-based keypoint prediction neural network (TKN), an unsupervised learning method that boost the prediction process via constrained information extraction and parallel prediction scheme. TKN is the first real-time video prediction solution to our best knowledge, while significantly reducing computation costs and maintaining other performance. Extensive experiments on KTH and Hum",
    "link": "http://arxiv.org/abs/2303.09807",
    "context": "Title: TKN: Transformer-based Keypoint Prediction Network For Real-time Video Prediction. (arXiv:2303.09807v1 [cs.CV])\nAbstract: Video prediction is a complex time-series forecasting task with great potential in many use cases. However, conventional methods overemphasize accuracy while ignoring the slow prediction speed caused by complicated model structures that learn too much redundant information with excessive GPU memory consumption. Furthermore, conventional methods mostly predict frames sequentially (frame-by-frame) and thus are hard to accelerate. Consequently, valuable use cases such as real-time danger prediction and warning cannot achieve fast enough inference speed to be applicable in reality. Therefore, we propose a transformer-based keypoint prediction neural network (TKN), an unsupervised learning method that boost the prediction process via constrained information extraction and parallel prediction scheme. TKN is the first real-time video prediction solution to our best knowledge, while significantly reducing computation costs and maintaining other performance. Extensive experiments on KTH and Hum",
    "path": "papers/23/03/2303.09807.json",
    "total_tokens": 814,
    "translated_title": "TKN：基于Transformer的实时视频关键点预测网络",
    "translated_abstract": "视频预测是一项具有广泛用途的复杂时间序列预测任务。然而，传统方法过于强调准确性，忽视了由于过于复杂的模型结构而导致的较慢的预测速度以及过多的冗余信息学习和GPU内存消耗。因此，我们提出了TKN，一种基于Transformer的关键点预测神经网络，通过受限信息提取和并行预测方案来提升预测过程的速度。TKN是我们目前所知的第一个实时视频预测解决方案，同时显著降低计算成本并保持其他性能。在KTH和Human Action 3D数据集上的大量实验表明，TKN在预测准确性和速度方面均优于现有的基准线。",
    "tldr": "TKN是一种基于Transformer的实时视频预测解决方案，通过受限信息提取和并行预测方案来提升预测过程的速度，具有更高的精度和更低的计算成本。",
    "en_tdlr": "TKN is a Transformer-based real-time video prediction solution that boosts prediction speed through constrained information extraction and parallel prediction scheme, with higher accuracy and lower computation cost."
}