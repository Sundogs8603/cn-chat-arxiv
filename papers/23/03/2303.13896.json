{
    "title": "Regularization of polynomial networks for image recognition. (arXiv:2303.13896v1 [cs.CV])",
    "abstract": "Deep Neural Networks (DNNs) have obtained impressive performance across tasks, however they still remain as black boxes, e.g., hard to theoretically analyze. At the same time, Polynomial Networks (PNs) have emerged as an alternative method with a promising performance and improved interpretability but have yet to reach the performance of the powerful DNN baselines. In this work, we aim to close this performance gap. We introduce a class of PNs, which are able to reach the performance of ResNet across a range of six benchmarks. We demonstrate that strong regularization is critical and conduct an extensive study of the exact regularization schemes required to match performance. To further motivate the regularization schemes, we introduce D-PolyNets that achieve a higher-degree of expansion than previously proposed polynomial networks. D-PolyNets are more parameter-efficient while achieving a similar performance as other polynomial networks. We expect that our new models can lead to an un",
    "link": "http://arxiv.org/abs/2303.13896",
    "context": "Title: Regularization of polynomial networks for image recognition. (arXiv:2303.13896v1 [cs.CV])\nAbstract: Deep Neural Networks (DNNs) have obtained impressive performance across tasks, however they still remain as black boxes, e.g., hard to theoretically analyze. At the same time, Polynomial Networks (PNs) have emerged as an alternative method with a promising performance and improved interpretability but have yet to reach the performance of the powerful DNN baselines. In this work, we aim to close this performance gap. We introduce a class of PNs, which are able to reach the performance of ResNet across a range of six benchmarks. We demonstrate that strong regularization is critical and conduct an extensive study of the exact regularization schemes required to match performance. To further motivate the regularization schemes, we introduce D-PolyNets that achieve a higher-degree of expansion than previously proposed polynomial networks. D-PolyNets are more parameter-efficient while achieving a similar performance as other polynomial networks. We expect that our new models can lead to an un",
    "path": "papers/23/03/2303.13896.json",
    "total_tokens": 879,
    "translated_title": "用于图像识别的多项式网络正则化",
    "translated_abstract": "深度神经网络在任务中表现出色，但仍然是黑盒子，例如难以理论分析。同时，多项式网络作为一种替代方法出现，具有良好的性能和可解释性，但仍未达到强大的深度神经网络水平。在这项工作中，我们旨在缩小这种性能差距。我们引入一类多项式网络，能够在六项基准测试中达到 ResNet 的性能水平。我们证明强正则化至关重要，并对确切的正则化方案进行了广泛研究，以达到相同的性能。为了进一步推动正则化方案，我们引入了 D-PolyNets，这些网络比以前提出的多项式网络有更高的扩展度。D-PolyNets 在实现类似其他多项式网络的性能的同时更具参数效率。我们期望我们的新模型能够带来一个开放的、正则化的多项式网络结构，并更好地解释神经网络的表现。",
    "tldr": "本论文介绍了一种新型的多项式网络结构及其正则化方案，能够在六项基准测试中达到 ResNet 的性能水平，并提出了 D-PolyNets 以进一步推动正则化方案和提高参数效率。",
    "en_tdlr": "This paper introduces a new type of polynomial network with strong regularization, which can achieve ResNet-level performance on six benchmarks, and proposes D-PolyNets to further promote regularization schemes and enhance parameter efficiency."
}