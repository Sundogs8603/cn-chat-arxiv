{
    "title": "DeepAxe: A Framework for Exploration of Approximation and Reliability Trade-offs in DNN Accelerators. (arXiv:2303.08226v1 [cs.LG])",
    "abstract": "While the role of Deep Neural Networks (DNNs) in a wide range of safety-critical applications is expanding, emerging DNNs experience massive growth in terms of computation power. It raises the necessity of improving the reliability of DNN accelerators yet reducing the computational burden on the hardware platforms, i.e. reducing the energy consumption and execution time as well as increasing the efficiency of DNN accelerators. Therefore, the trade-off between hardware performance, i.e. area, power and delay, and the reliability of the DNN accelerator implementation becomes critical and requires tools for analysis. In this paper, we propose a framework DeepAxe for design space exploration for FPGA-based implementation of DNNs by considering the trilateral impact of applying functional approximation on accuracy, reliability and hardware performance. The framework enables selective approximation of reliability-critical DNNs, providing a set of Pareto-optimal DNN implementation design spac",
    "link": "http://arxiv.org/abs/2303.08226",
    "context": "Title: DeepAxe: A Framework for Exploration of Approximation and Reliability Trade-offs in DNN Accelerators. (arXiv:2303.08226v1 [cs.LG])\nAbstract: While the role of Deep Neural Networks (DNNs) in a wide range of safety-critical applications is expanding, emerging DNNs experience massive growth in terms of computation power. It raises the necessity of improving the reliability of DNN accelerators yet reducing the computational burden on the hardware platforms, i.e. reducing the energy consumption and execution time as well as increasing the efficiency of DNN accelerators. Therefore, the trade-off between hardware performance, i.e. area, power and delay, and the reliability of the DNN accelerator implementation becomes critical and requires tools for analysis. In this paper, we propose a framework DeepAxe for design space exploration for FPGA-based implementation of DNNs by considering the trilateral impact of applying functional approximation on accuracy, reliability and hardware performance. The framework enables selective approximation of reliability-critical DNNs, providing a set of Pareto-optimal DNN implementation design spac",
    "path": "papers/23/03/2303.08226.json",
    "total_tokens": 901,
    "translated_title": "DeepAxe: 一种用于探索DNN加速器的近似和可靠性权衡的框架",
    "translated_abstract": "随着Deep Neural Networks（DNNs）在广泛的安全关键型应用中的作用正在扩大，新兴的DNN经历了计算能力方面的巨大增长。这增加了提高DNN加速器可靠性的必要性，同时降低硬件平台上的计算负担，即降低能耗和执行时间，提高DNN加速器的效率。因此，硬件性能（即区域、功率和延迟）与DNN加速器实现的可靠性之间的权衡变得至关重要，需要工具进行分析。在本文中，我们提出了一个框架DeepAxe，用于在考虑应用功能近似对准确度、可靠性和硬件性能的三方影响的情况下，对基于FPGA的DNN实现进行设计空间探索。该框架使得对于关键可靠性的DNN进行有选择的逼近，提供了一组Pareto最优的DNN实现设计空间。",
    "tldr": "DeepAxe是一个用于在DNN加速器的设计空间中考虑近似和可靠性权衡的框架，逼近可靠性关键的DNN，并提供一组Pareto最优的DNN实现设计空间。",
    "en_tdlr": "DeepAxe is a framework for exploring the trade-offs between approximation and reliability in DNN accelerators. It allows selective approximation of reliability-critical DNNs and provides a set of Pareto-optimal DNN implementation design space."
}