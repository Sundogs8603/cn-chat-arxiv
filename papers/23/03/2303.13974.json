{
    "title": "Mixed-Type Wafer Classification For Low Memory Devices Using Knowledge Distillation. (arXiv:2303.13974v1 [cs.LG])",
    "abstract": "Manufacturing wafers is an intricate task involving thousands of steps. Defect Pattern Recognition (DPR) of wafer maps is crucial for determining the root cause of production defects, which may further provide insight for yield improvement in wafer foundry. During manufacturing, various defects may appear standalone in the wafer or may appear as different combinations. Identifying multiple defects in a wafer is generally harder compared to identifying a single defect. Recently, deep learning methods have gained significant traction in mixed-type DPR. However, the complexity of defects requires complex and large models making them very difficult to operate on low-memory embedded devices typically used in fabrication labs. Another common issue is the unavailability of labeled data to train complex networks. In this work, we propose an unsupervised training routine to distill the knowledge of complex pre-trained models to lightweight deployment-ready models. We empirically show that this ",
    "link": "http://arxiv.org/abs/2303.13974",
    "context": "Title: Mixed-Type Wafer Classification For Low Memory Devices Using Knowledge Distillation. (arXiv:2303.13974v1 [cs.LG])\nAbstract: Manufacturing wafers is an intricate task involving thousands of steps. Defect Pattern Recognition (DPR) of wafer maps is crucial for determining the root cause of production defects, which may further provide insight for yield improvement in wafer foundry. During manufacturing, various defects may appear standalone in the wafer or may appear as different combinations. Identifying multiple defects in a wafer is generally harder compared to identifying a single defect. Recently, deep learning methods have gained significant traction in mixed-type DPR. However, the complexity of defects requires complex and large models making them very difficult to operate on low-memory embedded devices typically used in fabrication labs. Another common issue is the unavailability of labeled data to train complex networks. In this work, we propose an unsupervised training routine to distill the knowledge of complex pre-trained models to lightweight deployment-ready models. We empirically show that this ",
    "path": "papers/23/03/2303.13974.json",
    "total_tokens": 989,
    "translated_title": "通过知识蒸馏进行低内存设备的混合硅片分类",
    "translated_abstract": "制造硅片是一个复杂的任务，涉及数千个步骤。硅片地图的缺陷模式识别对于确定生产缺陷的根本原因至关重要，这可能进一步为硅片工厂的产量提高提供见解。在制造过程中，各种缺陷可能单独出现在硅片中，也可能以不同的组合形式出现。识别硅片中的多个缺陷通常比识别单个缺陷更难。最近，深度学习方法在混合类型DPR方面获得了显着的进展。然而，这些缺陷的复杂性需要大型复杂模型，使它们很难在通常用于制造实验室的低内存嵌入式设备上运行。另一个常见问题是缺乏标记数据来训练复杂网络。在这项工作中，我们提出了一种无监督训练程序，将复杂预训练模型的知识蒸馏到轻量级可部署模型中。我们凭经验证明，这种方法导致分类模型具有与最先进模型相当的性能，同时也足够高效，可在低内存设备上运行。",
    "tldr": "本文提出了一种通过知识蒸馏技术，将复杂预训练模型的知识转移到轻量级模型上，从而使低内存设备也能进行复杂缺陷分类，且无需大量标记数据。",
    "en_tdlr": "This paper proposes an unsupervised training routine to distill the knowledge of complex pre-trained models to lightweight deployment-ready models, allowing low-memory devices to perform complex defect classification without requiring large amounts of labeled data."
}