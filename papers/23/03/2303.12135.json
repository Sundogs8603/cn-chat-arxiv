{
    "title": "Understand Legal Documents with Contextualized Large Language Models. (arXiv:2303.12135v1 [cs.CL])",
    "abstract": "The growth of pending legal cases in populous countries, such as India, has become a major issue. Developing effective techniques to process and understand legal documents is extremely useful in resolving this problem. In this paper, we present our systems for SemEval-2023 Task 6: understanding legal texts (Modi et al., 2023). Specifically, we first develop the Legal-BERT-HSLN model that considers the comprehensive context information in both intra- and inter-sentence levels to predict rhetorical roles (subtask A) and then train a Legal-LUKE model, which is legal-contextualized and entity-aware, to recognize legal entities (subtask B). Our evaluations demonstrate that our designed models are more accurate than baselines, e.g., with an up to 15.0% better F1 score in subtask B. We achieved notable performance in the task leaderboard, e.g., 0.834 micro F1 score, and ranked No.5 out of 27 teams in subtask A.",
    "link": "http://arxiv.org/abs/2303.12135",
    "context": "Title: Understand Legal Documents with Contextualized Large Language Models. (arXiv:2303.12135v1 [cs.CL])\nAbstract: The growth of pending legal cases in populous countries, such as India, has become a major issue. Developing effective techniques to process and understand legal documents is extremely useful in resolving this problem. In this paper, we present our systems for SemEval-2023 Task 6: understanding legal texts (Modi et al., 2023). Specifically, we first develop the Legal-BERT-HSLN model that considers the comprehensive context information in both intra- and inter-sentence levels to predict rhetorical roles (subtask A) and then train a Legal-LUKE model, which is legal-contextualized and entity-aware, to recognize legal entities (subtask B). Our evaluations demonstrate that our designed models are more accurate than baselines, e.g., with an up to 15.0% better F1 score in subtask B. We achieved notable performance in the task leaderboard, e.g., 0.834 micro F1 score, and ranked No.5 out of 27 teams in subtask A.",
    "path": "papers/23/03/2303.12135.json",
    "total_tokens": 995,
    "translated_title": "利用上下文化的大型语言模型理解法律文件",
    "translated_abstract": "在人口众多的国家，如印度，待处理的法律案件数量不断增加，这已成为一个重大问题。因此，开发有效的技术来处理和理解法律文件将非常有用。在本文中，我们介绍了我们针对 SemEval-2023 任务 6（Modi 等人，2023）所开发的理解法律文本系统。具体来说，我们首先开发了 Legal-BERT-HSLN 模型，该模型考虑了句内和句间的综合上下文信息，以预测修辞角色（子任务 A），然后训练出 Legal-LUKE 模型，该模型具有法律上下文化和实体感知能力，以识别法律实体（子任务 B）。我们的评估表明，我们设计的模型比基线模型更准确，如在子任务 B 中 F1 值提高了达 15.0%。我们在任务排行榜上取得了显著的表现，如 0.834 微平均 F1 值，并在子任务 A 中排名第 5。",
    "tldr": "本文介绍了针对 SemEval-2023 任务 6 开发的 Legal-BERT-HSLN 模型和 Legal-LUKE 模型，其中 Legal-BERT-HSLN 模型通过考虑句内和句间的上下文信息以预测修辞角色，Legal-LUKE 模型是具有法律上下文和实体知识的模型，以识别法律实体。模型相比基线模型更准确，能够解决在人口众多的国家处理法律文件的问题。"
}