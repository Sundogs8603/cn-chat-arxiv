{
    "title": "On the Benefits of Leveraging Structural Information in Planning Over the Learned Model. (arXiv:2303.08856v1 [cs.LG])",
    "abstract": "Model-based Reinforcement Learning (RL) integrates learning and planning and has received increasing attention in recent years. However, learning the model can incur a significant cost (in terms of sample complexity), due to the need to obtain a sufficient number of samples for each state-action pair. In this paper, we investigate the benefits of leveraging structural information about the system in terms of reducing sample complexity. Specifically, we consider the setting where the transition probability matrix is a known function of a number of structural parameters, whose values are initially unknown. We then consider the problem of estimating those parameters based on the interactions with the environment. We characterize the difference between the Q estimates and the optimal Q value as a function of the number of samples. Our analysis shows that there can be a significant saving in sample complexity by leveraging structural information about the model. We illustrate the findings b",
    "link": "http://arxiv.org/abs/2303.08856",
    "context": "Title: On the Benefits of Leveraging Structural Information in Planning Over the Learned Model. (arXiv:2303.08856v1 [cs.LG])\nAbstract: Model-based Reinforcement Learning (RL) integrates learning and planning and has received increasing attention in recent years. However, learning the model can incur a significant cost (in terms of sample complexity), due to the need to obtain a sufficient number of samples for each state-action pair. In this paper, we investigate the benefits of leveraging structural information about the system in terms of reducing sample complexity. Specifically, we consider the setting where the transition probability matrix is a known function of a number of structural parameters, whose values are initially unknown. We then consider the problem of estimating those parameters based on the interactions with the environment. We characterize the difference between the Q estimates and the optimal Q value as a function of the number of samples. Our analysis shows that there can be a significant saving in sample complexity by leveraging structural information about the model. We illustrate the findings b",
    "path": "papers/23/03/2303.08856.json",
    "total_tokens": 786,
    "translated_title": "关于利用结构信息进行规划的好处",
    "translated_abstract": "基于模型的强化学习（RL）将学习和规划结合起来，在近年来受到越来越多的关注。然而，学习模型可能会产生显着的成本（样本复杂性），因为需要为每个状态-动作对获取足够的样本。本文研究了利用系统结构信息减少样本复杂性的好处。具体而言，我们考虑转移概率矩阵是一些结构化参数的已知函数的情况，这些参数的值最初是未知的。然后我们考虑基于与环境的交互来估计这些参数的问题。我们对Q值估计和最优Q值之间的差异进行了特征化，该差异是样本数的函数。我们的分析表明，利用模型的结构信息可以显著减少样本复杂度。我们通过实证研究展示了这些发现。",
    "tldr": "研究了利用系统结构信息减少基于模型的强化学习中的样本复杂性的好处。",
    "en_tdlr": "Investigated the benefits of leveraging structural information about the system to reduce sample complexity in model-based Reinforcement Learning."
}