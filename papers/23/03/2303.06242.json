{
    "title": "HYperbolic Self-Paced Learning for Self-Supervised Skeleton-based Action Representations. (arXiv:2303.06242v1 [cs.CV])",
    "abstract": "Self-paced learning has been beneficial for tasks where some initial knowledge is available, such as weakly supervised learning and domain adaptation, to select and order the training sample sequence, from easy to complex. However its applicability remains unexplored in unsupervised learning, whereby the knowledge of the task matures during training. We propose a novel HYperbolic Self-Paced model (HYSP) for learning skeleton-based action representations. HYSP adopts self-supervision: it uses data augmentations to generate two views of the same sample, and it learns by matching one (named online) to the other (the target). We propose to use hyperbolic uncertainty to determine the algorithmic learning pace, under the assumption that less uncertain samples should be more strongly driving the training, with a larger weight and pace. Hyperbolic uncertainty is a by-product of the adopted hyperbolic neural networks, it matures during training and it comes with no extra cost, compared to the e",
    "link": "http://arxiv.org/abs/2303.06242",
    "total_tokens": 1033,
    "translated_title": "基于双视角的超似曲自适应学习用于自监督骨架动作表示",
    "translated_abstract": "自适应学习在一些任务中有益，例如弱监督学习和领域自适应，可以选择和排序训练样本序列，从易到难。然而，它在无监督学习中的适用性仍未被探索，其中任务的知识在训练期间成熟。我们提出了一种新的超似曲自适应模型（HYSP）用于学习基于骨架的动作表示。HYSP采用自监督：它使用数据增强来生成同一样本的两个视图，并通过将一个视图（称为在线）与另一个视图（目标）匹配来学习。我们建议使用超似曲不确定性来确定算法学习速度，假设不确定性较小的样本应更强烈地推动训练，具有更大的权重和速度。超似曲不确定性是采用的超似曲神经网络的副产品，它在训练期间成熟，与额外成本相比，没有额外成本。",
    "tldr": "本文提出了一种新的超似曲自适应模型（HYSP）用于学习基于骨架的动作表示，采用自监督学习，使用数据增强来生成同一样本的两个视图，并通过将一个视图与另一个视图匹配来学习，使用超似曲不确定性来确定算法学习速度，假设不确定性较小的样本应更强烈地推动训练，具有更大的权重和速度。",
    "en_tldr": "This paper proposes a novel HYperbolic Self-Paced model (HYSP) for learning skeleton-based action representations, which adopts self-supervision and uses data augmentations to generate two views of the same sample, and learns by matching one to the other. It uses hyperbolic uncertainty to determine the algorithmic learning pace, assuming that less uncertain samples should be more strongly driving the training, with a larger weight and pace."
}