{
    "title": "Competence-Based Analysis of Language Models. (arXiv:2303.00333v2 [cs.CL] UPDATED)",
    "abstract": "Despite the recent success of large pretrained language models (LMs) on a variety of prompting tasks, these models can be alarmingly brittle to small changes in inputs or application contexts. To better understand such behavior and motivate the design of more robust LMs, we propose a general experimental framework, CALM (Competence-based Analysis of Language Models), where targeted causal interventions are utilized to damage an LM's internal representation of various linguistic properties in order to evaluate its use of each representation in performing a given task. We implement these interventions as gradient-based adversarial attacks, which (in contrast to prior causal probing methodologies) are able to target arbitrarily-encoded representations of relational properties, and carry out a case study of this approach to analyze how BERT-like LMs use representations of several relational properties in performing associated relation prompting tasks. We find that, while the representation",
    "link": "http://arxiv.org/abs/2303.00333",
    "context": "Title: Competence-Based Analysis of Language Models. (arXiv:2303.00333v2 [cs.CL] UPDATED)\nAbstract: Despite the recent success of large pretrained language models (LMs) on a variety of prompting tasks, these models can be alarmingly brittle to small changes in inputs or application contexts. To better understand such behavior and motivate the design of more robust LMs, we propose a general experimental framework, CALM (Competence-based Analysis of Language Models), where targeted causal interventions are utilized to damage an LM's internal representation of various linguistic properties in order to evaluate its use of each representation in performing a given task. We implement these interventions as gradient-based adversarial attacks, which (in contrast to prior causal probing methodologies) are able to target arbitrarily-encoded representations of relational properties, and carry out a case study of this approach to analyze how BERT-like LMs use representations of several relational properties in performing associated relation prompting tasks. We find that, while the representation",
    "path": "papers/23/03/2303.00333.json",
    "total_tokens": 884,
    "translated_title": "基于能力的语言模型分析",
    "translated_abstract": "尽管大型预训练语言模型（LMs）在各种提示任务上取得了显著成功，但这些模型对输入或应用环境中的微小变化却异常脆弱。为了更好地理解这种行为并激励设计更健壮的LMs，我们提出了一个通用的实验框架CALM（基于能力的语言模型分析），其中利用有针对性的因果干预来破坏LM在各种语言属性上的内部表示，以评估它在执行给定任务时对每个表示的使用。我们将这些干预实现为基于梯度的对抗攻击，与先前的因果探查方法相比，它们能够针对任意编码的关系属性进行攻击，并进行了一个案例研究，分析了BERT-like LMs在执行相关关系提示任务时如何使用多种关系属性的表示。我们发现，虽然表示的选择对LM的性能产生了影响，但模型对某些特定关系属性的利用并不一致。",
    "tldr": "该论文提出了一个基于能力的语言模型分析框架CALM，通过有针对性的干预来破坏语言模型的内部表示，评估其在执行任务时对不同表示的使用。研究表明，语言模型对关系属性的利用存在一定的不一致性。",
    "en_tdlr": "This paper proposes a competence-based analysis framework, CALM, to evaluate the use of different representations in language models. It shows that the utilization of relational properties in language models is inconsistent."
}