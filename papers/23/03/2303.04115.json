{
    "title": "Predicted Embedding Power Regression for Large-Scale Out-of-Distribution Detection. (arXiv:2303.04115v2 [cs.CV] UPDATED)",
    "abstract": "Out-of-distribution (OOD) inputs can compromise the performance and safety of real world machine learning systems. While many methods exist for OOD detection and work well on small scale datasets with lower resolution and few classes, few methods have been developed for large-scale OOD detection. Existing large-scale methods generally depend on maximum classification probability, such as the state-of-the-art grouped softmax method. In this work, we develop a novel approach that calculates the probability of the predicted class label based on label distributions learned during the training process. Our method performs better than current state-of-the-art methods with only a negligible increase in compute cost. We evaluate our method against contemporary methods across $14$ datasets and achieve a statistically significant improvement with respect to AUROC (84.2 vs 82.4) and AUPR (96.2 vs 93.7).",
    "link": "http://arxiv.org/abs/2303.04115",
    "context": "Title: Predicted Embedding Power Regression for Large-Scale Out-of-Distribution Detection. (arXiv:2303.04115v2 [cs.CV] UPDATED)\nAbstract: Out-of-distribution (OOD) inputs can compromise the performance and safety of real world machine learning systems. While many methods exist for OOD detection and work well on small scale datasets with lower resolution and few classes, few methods have been developed for large-scale OOD detection. Existing large-scale methods generally depend on maximum classification probability, such as the state-of-the-art grouped softmax method. In this work, we develop a novel approach that calculates the probability of the predicted class label based on label distributions learned during the training process. Our method performs better than current state-of-the-art methods with only a negligible increase in compute cost. We evaluate our method against contemporary methods across $14$ datasets and achieve a statistically significant improvement with respect to AUROC (84.2 vs 82.4) and AUPR (96.2 vs 93.7).",
    "path": "papers/23/03/2303.04115.json",
    "total_tokens": 837,
    "translated_title": "大规模外域检测的预测嵌入功率回归",
    "translated_abstract": "外域输入可能会危及真实世界中机器学习系统的性能和安全性。尽管存在许多用于外域检测的方法，并且对于低分辨率和少量类别的小规模数据集表现良好，但为大规模外域检测开发的方法很少。现有的大规模方法通常依赖于最大分类概率，例如最先进的分组 softmax 方法。在这项工作中，我们开发了一种新方法，该方法根据在训练过程中学习的标签分布计算预测类标签的概率。我们的方法表现优于目前最先进的方法，仅在计算成本上稍有增加。我们在14个数据集上评估了我们的方法，并在 AUROC（84.2 vs 82.4）和 AUPR（96.2 vs 93.7）方面实现了统计显着的改进。",
    "tldr": "本文提出一种基于标签分布学习的预测类标签概率方法，用于大规模外域检测，相比现有最先进方法在 AUROC 和 AUPR 方面实现统计显着的改进。",
    "en_tdlr": "This paper proposes a novel method based on label distribution learning for predicting class label probability in large-scale out-of-distribution detection, which achieves statistically significant improvements in AUROC and AUPR over current state-of-the-art methods."
}