{
    "title": "Computer Vision Estimation of Emotion Reaction Intensity in the Wild. (arXiv:2303.10741v2 [cs.CV] UPDATED)",
    "abstract": "Emotions play an essential role in human communication. Developing computer vision models for automatic recognition of emotion expression can aid in a variety of domains, including robotics, digital behavioral healthcare, and media analytics. There are three types of emotional representations which are traditionally modeled in affective computing research: Action Units, Valence Arousal (VA), and Categorical Emotions. As part of an effort to move beyond these representations towards more fine-grained labels, we describe our submission to the newly introduced Emotional Reaction Intensity (ERI) Estimation challenge in the 5th competition for Affective Behavior Analysis in-the-Wild (ABAW). We developed four deep neural networks trained in the visual domain and a multimodal model trained with both visual and audio features to predict emotion reaction intensity. Our best performing model on the Hume-Reaction dataset achieved an average Pearson correlation coefficient of 0.4080 on the test se",
    "link": "http://arxiv.org/abs/2303.10741",
    "context": "Title: Computer Vision Estimation of Emotion Reaction Intensity in the Wild. (arXiv:2303.10741v2 [cs.CV] UPDATED)\nAbstract: Emotions play an essential role in human communication. Developing computer vision models for automatic recognition of emotion expression can aid in a variety of domains, including robotics, digital behavioral healthcare, and media analytics. There are three types of emotional representations which are traditionally modeled in affective computing research: Action Units, Valence Arousal (VA), and Categorical Emotions. As part of an effort to move beyond these representations towards more fine-grained labels, we describe our submission to the newly introduced Emotional Reaction Intensity (ERI) Estimation challenge in the 5th competition for Affective Behavior Analysis in-the-Wild (ABAW). We developed four deep neural networks trained in the visual domain and a multimodal model trained with both visual and audio features to predict emotion reaction intensity. Our best performing model on the Hume-Reaction dataset achieved an average Pearson correlation coefficient of 0.4080 on the test se",
    "path": "papers/23/03/2303.10741.json",
    "total_tokens": 924,
    "translated_title": "在野外环境中使用计算机视觉估计情绪反应强度",
    "translated_abstract": "情绪在人类沟通中扮演着至关重要的角色。开发用于自动识别情绪表达的计算机视觉模型可以在各个领域中提供帮助，包括机器人技术、数字化行为医疗和媒体分析。在情感计算研究中，传统上有三种情绪表达的建模方式：行动单元、情感价值与唤起度（VA）和分类情绪。作为超越这些表达方式，朝着更精细标签的努力的一部分，我们描述了我们在野外情绪行为分析（ABAW）第五次比赛中提交的模型，该比赛引入了情绪反应强度（ERI）估计挑战。我们开发了四个在视觉领域训练的深度神经网络和一个结合了视觉和音频特征训练的多模态模型来预测情绪反应强度。在Hume-Reaction数据集上，我们最佳的模型在测试集上达到了0.4080的平均皮尔逊相关系数。",
    "tldr": "本研究旨在利用计算机视觉模型在野外环境中估计情绪反应强度。通过训练深度神经网络和多模态模型，我们在Hume-Reaction数据集上取得了不错的结果。",
    "en_tdlr": "This study aims to estimate emotion reaction intensity in the wild using computer vision models. By training deep neural networks and multimodal models, we achieved promising results on the Hume-Reaction dataset."
}