{
    "title": "PheME: A deep ensemble framework for improving phenotype prediction from multi-modal data. (arXiv:2303.10794v2 [cs.LG] UPDATED)",
    "abstract": "Detailed phenotype information is fundamental to accurate diagnosis and risk estimation of diseases. As a rich source of phenotype information, electronic health records (EHRs) promise to empower diagnostic variant interpretation. However, how to accurately and efficiently extract phenotypes from the heterogeneous EHR data remains a challenge. In this work, we present PheME, an Ensemble framework using Multi-modality data of structured EHRs and unstructured clinical notes for accurate Phenotype prediction. Firstly, we employ multiple deep neural networks to learn reliable representations from the sparse structured EHR data and redundant clinical notes. A multi-modal model then aligns multi-modal features onto the same latent space to predict phenotypes. Secondly, we leverage ensemble learning to combine outputs from single-modal models and multi-modal models to improve phenotype predictions. We choose seven diseases to evaluate the phenotyping performance of the proposed framework. Exp",
    "link": "http://arxiv.org/abs/2303.10794",
    "context": "Title: PheME: A deep ensemble framework for improving phenotype prediction from multi-modal data. (arXiv:2303.10794v2 [cs.LG] UPDATED)\nAbstract: Detailed phenotype information is fundamental to accurate diagnosis and risk estimation of diseases. As a rich source of phenotype information, electronic health records (EHRs) promise to empower diagnostic variant interpretation. However, how to accurately and efficiently extract phenotypes from the heterogeneous EHR data remains a challenge. In this work, we present PheME, an Ensemble framework using Multi-modality data of structured EHRs and unstructured clinical notes for accurate Phenotype prediction. Firstly, we employ multiple deep neural networks to learn reliable representations from the sparse structured EHR data and redundant clinical notes. A multi-modal model then aligns multi-modal features onto the same latent space to predict phenotypes. Secondly, we leverage ensemble learning to combine outputs from single-modal models and multi-modal models to improve phenotype predictions. We choose seven diseases to evaluate the phenotyping performance of the proposed framework. Exp",
    "path": "papers/23/03/2303.10794.json",
    "total_tokens": 922,
    "translated_title": "PheME：一种深度集成框架，可从多模态数据中提高表型预测的准确性",
    "translated_abstract": "详细的表型信息对于疾病的准确诊断和风险评估至关重要。作为表型信息的丰富来源，电子健康记录（EHRs）承诺赋予诊断变异解释的权力。然而，如何从异构的EHR数据中准确高效地提取表型仍然是一个挑战。在本研究中，我们提出了PheME，一种Ensemble框架，使用结构化EHR和非结构化的临床笔记的多模态数据进行准确的表型预测。首先，我们使用多个深度神经网络从稀疏的结构化EHR数据和冗余的临床笔记中学习可靠的表示。多模态模型将多模态特征对齐到同一潜在空间以预测表型。其次，我们利用集成学习来将单模型和多模型的输出相结合，以提高表型预测。我们选择了七种疾病来评估所提出的框架的表型化性能。",
    "tldr": "本文提出了PheME，一种利用多模态数据进行表型预测的深度集成框架。该框架采用多个深度神经网络和集成学习，可以从EHR数据中准确且高效地提取表型信息。",
    "en_tdlr": "This paper proposes PheME, a deep ensemble framework for accurate phenotype prediction from multi-modal data. Utilizing multiple deep neural networks and ensemble learning, PheME can extract phenotype information accurately and efficiently from EHR data."
}