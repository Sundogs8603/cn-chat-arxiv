{
    "title": "Increasing Textual Context Size Boosts Medical Image-Text Matching. (arXiv:2303.13340v1 [cs.LG])",
    "abstract": "This short technical report demonstrates a simple technique that yields state of the art results in medical image-text matching tasks. We analyze the use of OpenAI's CLIP, a general image-text matching model, and observe that CLIP's limited textual input size has negative impact on downstream performance in the medical domain where encoding longer textual contexts is often required. We thus train and release ClipMD, which is trained with a simple sliding window technique to encode textual captions. ClipMD was tested on two medical image-text datasets and compared with other image-text matching models. The results show that ClipMD outperforms other models on both datasets by a large margin. We make our code and pretrained model publicly available.",
    "link": "http://arxiv.org/abs/2303.13340",
    "context": "Title: Increasing Textual Context Size Boosts Medical Image-Text Matching. (arXiv:2303.13340v1 [cs.LG])\nAbstract: This short technical report demonstrates a simple technique that yields state of the art results in medical image-text matching tasks. We analyze the use of OpenAI's CLIP, a general image-text matching model, and observe that CLIP's limited textual input size has negative impact on downstream performance in the medical domain where encoding longer textual contexts is often required. We thus train and release ClipMD, which is trained with a simple sliding window technique to encode textual captions. ClipMD was tested on two medical image-text datasets and compared with other image-text matching models. The results show that ClipMD outperforms other models on both datasets by a large margin. We make our code and pretrained model publicly available.",
    "path": "papers/23/03/2303.13340.json",
    "total_tokens": 794,
    "translated_title": "增加文本上下文大小提高医疗图像-文本匹配的准确性",
    "translated_abstract": "这篇短技术报告展示了一种简单的技术，可以在医疗图像-文本匹配任务中获得最先进的结果。我们分析了使用OpenAI的CLIP进行图像-文本匹配的模型，并观察到CLIP在医疗领域中需要编码更长文本上下文的地方，其有限的文本输入大小会对下游性能产生负面影响。因此，我们使用简单的滑动窗口技术训练和发布了ClipMD，用于编码文本标题。ClipMD在两个医疗图像-文本数据集上进行了测试，并与其他图像-文本匹配模型进行了比较。结果表明，ClipMD在两个数据集上的表现都比其他模型要好得多。我们公开了我们的代码和预训练模型。",
    "tldr": "利用滑动窗口技术增加了文本上下文的编码，提高了医疗图像-文本匹配的准确性，新模型ClipMD在两个数据集上都取得了最好的结果。",
    "en_tdlr": "Increasing text context size with a sliding window technique improves the accuracy of medical image-text matching. The newly developed model ClipMD outperforms other models on two datasets, achieved by encoding longer textual contexts, and is publicly available with code and pre-trained models."
}