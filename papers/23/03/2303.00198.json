{
    "title": "Convolutional Visual Prompt for Robust Visual Perception. (arXiv:2303.00198v2 [cs.CV] UPDATED)",
    "abstract": "Vision models are often vulnerable to out-of-distribution (OOD) samples without adapting. While visual prompts offer a lightweight method of input-space adaptation for large-scale vision models, they rely on a high-dimensional additive vector and labeled data. This leads to overfitting when adapting models in a self-supervised test-time setting without labels. We introduce convolutional visual prompts (CVP) for label-free test-time adaptation for robust visual perception. The structured nature of CVP demands fewer trainable parameters, less than 1\\% compared to standard visual prompts, combating overfitting. Extensive experiments and analysis on a wide variety of OOD visual perception tasks show that our approach is effective, improving robustness by up to 5.87% over several large-scale models.",
    "link": "http://arxiv.org/abs/2303.00198",
    "context": "Title: Convolutional Visual Prompt for Robust Visual Perception. (arXiv:2303.00198v2 [cs.CV] UPDATED)\nAbstract: Vision models are often vulnerable to out-of-distribution (OOD) samples without adapting. While visual prompts offer a lightweight method of input-space adaptation for large-scale vision models, they rely on a high-dimensional additive vector and labeled data. This leads to overfitting when adapting models in a self-supervised test-time setting without labels. We introduce convolutional visual prompts (CVP) for label-free test-time adaptation for robust visual perception. The structured nature of CVP demands fewer trainable parameters, less than 1\\% compared to standard visual prompts, combating overfitting. Extensive experiments and analysis on a wide variety of OOD visual perception tasks show that our approach is effective, improving robustness by up to 5.87% over several large-scale models.",
    "path": "papers/23/03/2303.00198.json",
    "total_tokens": 869,
    "translated_title": "针对稳健视觉感知的卷积视觉提示",
    "translated_abstract": "视觉模型常常对未适应的离域样本很容易受攻击。虽然视觉提示为大规模视觉模型提供了一种轻量级的输入空间适应方法，但它们依赖于高维度的加性向量和标记数据。这导致在无标签的自监督测试时间设置下，调整模型容易出现过拟合。我们引入了卷积视觉提示（CVP）来实现无标签测试时间适应以提高稳健的视觉感知。CVP的结构化特性要求较少的可训练参数，仅为标准视觉提示的1％以下，从而抑制了过拟合。在广泛的离域视觉感知任务上进行的大量实验和分析表明，我们的方法是有效的，相比几种大规模模型，提高了稳健性高达5.87%。",
    "tldr": "本文介绍了一种针对稳健视觉感知的卷积视觉提示（CVP）方法，通过较少的可训练参数来避免自适应模型在无标签自监督测试时间设置下的过拟合，实验证明该方法可提高稳健性高达5.87%。",
    "en_tdlr": "This paper presents a convolutional visual prompt (CVP) method for robust visual perception, which avoids overfitting of adaptive models in a self-supervised test-time setting with unlabeled data by using fewer trainable parameters. Experimental results show that our approach improves robustness by up to 5.87% compared to several large-scale models."
}