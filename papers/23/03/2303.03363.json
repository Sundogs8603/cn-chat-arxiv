{
    "title": "Enhancing Activity Prediction Models in Drug Discovery with the Ability to Understand Human Language. (arXiv:2303.03363v2 [q-bio.BM] UPDATED)",
    "abstract": "Activity and property prediction models are the central workhorses in drug discovery and materials sciences, but currently they have to be trained or fine-tuned for new tasks. Without training or fine-tuning, scientific language models could be used for such low-data tasks through their announced zero- and few-shot capabilities. However, their predictive quality at activity prediction is lacking. In this work, we envision a novel type of activity prediction model that is able to adapt to new prediction tasks at inference time, via understanding textual information describing the task. To this end, we propose a new architecture with separate modules for chemical and natural language inputs, and a contrastive pre-training objective on data from large biochemical databases. In extensive experiments, we show that our method CLAMP yields improved predictive performance on few-shot learning benchmarks and zero-shot problems in drug discovery. We attribute the advances of our method to the mo",
    "link": "http://arxiv.org/abs/2303.03363",
    "context": "Title: Enhancing Activity Prediction Models in Drug Discovery with the Ability to Understand Human Language. (arXiv:2303.03363v2 [q-bio.BM] UPDATED)\nAbstract: Activity and property prediction models are the central workhorses in drug discovery and materials sciences, but currently they have to be trained or fine-tuned for new tasks. Without training or fine-tuning, scientific language models could be used for such low-data tasks through their announced zero- and few-shot capabilities. However, their predictive quality at activity prediction is lacking. In this work, we envision a novel type of activity prediction model that is able to adapt to new prediction tasks at inference time, via understanding textual information describing the task. To this end, we propose a new architecture with separate modules for chemical and natural language inputs, and a contrastive pre-training objective on data from large biochemical databases. In extensive experiments, we show that our method CLAMP yields improved predictive performance on few-shot learning benchmarks and zero-shot problems in drug discovery. We attribute the advances of our method to the mo",
    "path": "papers/23/03/2303.03363.json",
    "total_tokens": 933,
    "translated_title": "利用人类语言理解能力增强药物研发中的活性预测模型",
    "translated_abstract": "活性和性质预测模型是药物研发和材料科学中的核心工作，但目前它们必须经过训练或微调才能适应新任务。科学语言模型具有零数据和少数据样本的能力，因此对于此类低数据任务，无需训练或微调即可使用。然而，它们在活性预测方面的预测质量不足。本文提出一种新型活性预测模型，能够通过理解描述任务的文本信息来适应推理时的新预测任务。为此，我们提出了一种新的结构，具有化学和自然语言输入的分离模块，以及大型生物化学数据库中的对比预训练目标。通过大量实验证明，我们的方法CLAMP在少样本学习基准和药物研发中的零数据问题上都能取得更好的预测性能。我们认为我们的方法的进展归因于情境感知模型和对比学习策略的结合，以及用于结合数据源的对抗性自编码器。",
    "tldr": "本文提出了一种新型活性预测模型，能够通过理解描述任务的文本信息来适应推理时的新预测任务，并在少样本学习基准和药物研发中的零数据问题上都能取得更好的预测性能。",
    "en_tdlr": "The paper proposes a novel type of activity prediction model that can adapt to new prediction tasks at inference time via understanding textual information. The method CLAMP yields improved predictive performance on few-shot learning benchmarks and zero-shot problems in drug discovery."
}