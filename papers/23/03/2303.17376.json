{
    "title": "A Study of Autoregressive Decoders for Multi-Tasking in Computer Vision. (arXiv:2303.17376v1 [cs.CV])",
    "abstract": "There has been a recent explosion of computer vision models which perform many tasks and are composed of an image encoder (usually a ViT) and an autoregressive decoder (usually a Transformer). However, most of this work simply presents one system and its results, leaving many questions regarding design decisions and trade-offs of such systems unanswered. In this work, we aim to provide such answers. We take a close look at autoregressive decoders for multi-task learning in multimodal computer vision, including classification, captioning, visual question answering, and optical character recognition. Through extensive systematic experiments, we study the effects of task and data mixture, training and regularization hyperparameters, conditioning type and specificity, modality combination, and more. Importantly, we compare these to well-tuned single-task baselines to highlight the cost incurred by multi-tasking. A key finding is that a small decoder learned on top of a frozen pretrained en",
    "link": "http://arxiv.org/abs/2303.17376",
    "context": "Title: A Study of Autoregressive Decoders for Multi-Tasking in Computer Vision. (arXiv:2303.17376v1 [cs.CV])\nAbstract: There has been a recent explosion of computer vision models which perform many tasks and are composed of an image encoder (usually a ViT) and an autoregressive decoder (usually a Transformer). However, most of this work simply presents one system and its results, leaving many questions regarding design decisions and trade-offs of such systems unanswered. In this work, we aim to provide such answers. We take a close look at autoregressive decoders for multi-task learning in multimodal computer vision, including classification, captioning, visual question answering, and optical character recognition. Through extensive systematic experiments, we study the effects of task and data mixture, training and regularization hyperparameters, conditioning type and specificity, modality combination, and more. Importantly, we compare these to well-tuned single-task baselines to highlight the cost incurred by multi-tasking. A key finding is that a small decoder learned on top of a frozen pretrained en",
    "path": "papers/23/03/2303.17376.json",
    "total_tokens": 982,
    "translated_title": "计算机视觉多任务自回归解码器研究",
    "translated_abstract": "最近出现了许多计算机视觉模型，能够执行多项任务，由图像编码器（通常是 ViT）和自回归解码器（通常是 Transformer）组成。然而，大部分工作仅呈现一个系统及其结果，对这些系统的设计决策和权衡方面留下了许多疑问。在这项工作中，我们旨在提供这些答案。我们仔细研究了自回归解码器在多模态计算机视觉多任务学习中的应用，包括分类、字幕、视觉问答和光学字符识别等。通过广泛的系统试验，我们研究了任务和数据混合、训练和正则化超参数、条件类型和特异性、模态组合等因素的影响。重要的是，我们将这些结果与经过充分调试的单任务基线进行了比较，以凸显多任务学习所带来的成本。一个关键的发现是，对于冻结预训练编码器上学习的小型解码器，性能接近于单任务基线。",
    "tldr": "本研究着重研究了计算机视觉中的多任务自回归解码器，通过广泛的系统试验分析了任务和数据混合、训练和正则化超参数、条件类型和特异性、模态组合等因素，发现通过冻结预训练编码器，采用小型解码器可接近于单任务基线。",
    "en_tdlr": "This study focuses on autoregressive decoders for multi-task learning in computer vision, and through extensive systematic experiments, analyzes various factors such as task and data mixture, training and regularization hyperparameters, conditioning type and specificity, and modality combination. The study found that a small decoder learned on top of a frozen pretrained encoder performs similarly to a single-task baseline."
}