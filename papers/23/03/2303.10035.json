{
    "title": "A Policy Iteration Approach for Flock Motion Control. (arXiv:2303.10035v1 [eess.SY])",
    "abstract": "The flocking motion control is concerned with managing the possible conflicts between local and team objectives of multi-agent systems. The overall control process guides the agents while monitoring the flock-cohesiveness and localization. The underlying mechanisms may degrade due to overlooking the unmodeled uncertainties associated with the flock dynamics and formation. On another side, the efficiencies of the various control designs rely on how quickly they can adapt to different dynamic situations in real-time. An online model-free policy iteration mechanism is developed here to guide a flock of agents to follow an independent command generator over a time-varying graph topology. The strength of connectivity between any two agents or the graph edge weight is decided using a position adjacency dependent function. An online recursive least squares approach is adopted to tune the guidance strategies without knowing the dynamics of the agents or those of the command generator. It is co",
    "link": "http://arxiv.org/abs/2303.10035",
    "context": "Title: A Policy Iteration Approach for Flock Motion Control. (arXiv:2303.10035v1 [eess.SY])\nAbstract: The flocking motion control is concerned with managing the possible conflicts between local and team objectives of multi-agent systems. The overall control process guides the agents while monitoring the flock-cohesiveness and localization. The underlying mechanisms may degrade due to overlooking the unmodeled uncertainties associated with the flock dynamics and formation. On another side, the efficiencies of the various control designs rely on how quickly they can adapt to different dynamic situations in real-time. An online model-free policy iteration mechanism is developed here to guide a flock of agents to follow an independent command generator over a time-varying graph topology. The strength of connectivity between any two agents or the graph edge weight is decided using a position adjacency dependent function. An online recursive least squares approach is adopted to tune the guidance strategies without knowing the dynamics of the agents or those of the command generator. It is co",
    "path": "papers/23/03/2303.10035.json",
    "total_tokens": 868,
    "translated_title": "群体运动控制的策略迭代方法",
    "translated_abstract": "群体运动控制旨在管理多代理系统的本地和团队目标之间可能存在的冲突。整个控制过程指导代理，并监控群体凝聚性和定位。然而，忽略与群体动态和形成相关的未建模不确定性可能会降低基础机制的效果。另一方面，各种控制设计的效率取决于它们能够多快地适应实时不同的动态情况。本文提出了一种在线无模型策略迭代机制，以引导一群代理人遵循随时间变化的图形拓扑下的独立命令生成器。通过位置相邻依赖函数确定任意两个代理之间的连接强度或图边缘权重。采用在线递归最小二乘方法来调整指导策略，而不必了解代理或命令生成器的动态。",
    "tldr": "本文提出了一种基于无模型策略迭代机制的群体运动控制方法，能够在时间变化的图形拓扑下引导代理人遵循命令生成器，并在线调整指导策略以适应实时动态情况。",
    "en_tdlr": "This paper proposes a model-free policy iteration mechanism for flock motion control, which is able to guide agents to follow a command generator under a time-varying graph topology and adapt to dynamic situations in real-time. An online recursive least squares approach is adopted to tune the guidance strategies."
}