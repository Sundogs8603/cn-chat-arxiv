{
    "title": "Cluster-Guided Unsupervised Domain Adaptation for Deep Speaker Embedding. (arXiv:2303.15944v1 [cs.LG])",
    "abstract": "Recent studies have shown that pseudo labels can contribute to unsupervised domain adaptation (UDA) for speaker verification. Inspired by the self-training strategies that use an existing classifier to label the unlabeled data for retraining, we propose a cluster-guided UDA framework that labels the target domain data by clustering and combines the labeled source domain data and pseudo-labeled target domain data to train a speaker embedding network. To improve the cluster quality, we train a speaker embedding network dedicated for clustering by minimizing the contrastive center loss. The goal is to reduce the distance between an embedding and its assigned cluster center while enlarging the distance between the embedding and the other cluster centers. Using VoxCeleb2 as the source domain and CN-Celeb1 as the target domain, we demonstrate that the proposed method can achieve an equal error rate (EER) of 8.10% on the CN-Celeb1 evaluation set without using any labels from the target domain",
    "link": "http://arxiv.org/abs/2303.15944",
    "context": "Title: Cluster-Guided Unsupervised Domain Adaptation for Deep Speaker Embedding. (arXiv:2303.15944v1 [cs.LG])\nAbstract: Recent studies have shown that pseudo labels can contribute to unsupervised domain adaptation (UDA) for speaker verification. Inspired by the self-training strategies that use an existing classifier to label the unlabeled data for retraining, we propose a cluster-guided UDA framework that labels the target domain data by clustering and combines the labeled source domain data and pseudo-labeled target domain data to train a speaker embedding network. To improve the cluster quality, we train a speaker embedding network dedicated for clustering by minimizing the contrastive center loss. The goal is to reduce the distance between an embedding and its assigned cluster center while enlarging the distance between the embedding and the other cluster centers. Using VoxCeleb2 as the source domain and CN-Celeb1 as the target domain, we demonstrate that the proposed method can achieve an equal error rate (EER) of 8.10% on the CN-Celeb1 evaluation set without using any labels from the target domain",
    "path": "papers/23/03/2303.15944.json",
    "total_tokens": 1059,
    "translated_title": "群集引导无监督领域自适应深度说话人嵌入",
    "translated_abstract": "最近的研究表明，伪标签可以为说话人验证的无监督领域自适应（UDA）做出贡献。受到利用现有分类器标记未标记数据以进行重新训练的自我训练策略的启发，我们提出了一种群集引导的UDA框架，该框架通过聚类对目标域数据进行标记，并将标记的源域数据和伪标记的目标域数据相结合，以训练说话人嵌入网络。为了提高群集质量，我们通过最小化对聚类专用的说话人嵌入网络的对比中心损失来训练该网络。目标是降低嵌入与其分配的群集中心之间的距离，同时增大嵌入与其他群集中心之间的距离。使用VoxCeleb2作为源域，CN-Celeb1作为目标域，我们证明了所提出的方法可以在不使用目标域的任何标签的情况下，在CN-Celeb1评估集上实现8.10％的等误差率（EER）。",
    "tldr": "提出一种群集引导的无监督领域自适应框架，使用伪标签和聚类标记目标域数据，并结合标记的源域数据来训练说话人嵌入网络，并通过专用的对比中心损失训练该网络来提高群集质量。在不使用目标域标签的情况下，在CN-Celeb1评估集上实现了8.10％的等误差率（EER）。",
    "en_tdlr": "This paper proposes a cluster-guided unsupervised domain adaptation framework for speaker embedding, which utilizes pseudo labels and clustering to label the target domain data and combines the labeled source domain data and pseudo-labeled target domain data to train the network, and improves the cluster quality by training a speaker embedding network dedicated for clustering with contrastive center loss. The proposed method achieves an EER of 8.10% on the CN-Celeb1 evaluation set without using any labels from the target domain."
}