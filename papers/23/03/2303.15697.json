{
    "title": "Model and Evaluation: Towards Fairness in Multilingual Text Classification. (arXiv:2303.15697v1 [cs.CL])",
    "abstract": "Recently, more and more research has focused on addressing bias in text classification models. However, existing research mainly focuses on the fairness of monolingual text classification models, and research on fairness for multilingual text classification is still very limited. In this paper, we focus on the task of multilingual text classification and propose a debiasing framework for multilingual text classification based on contrastive learning. Our proposed method does not rely on any external language resources and can be extended to any other languages. The model contains four modules: multilingual text representation module, language fusion module, text debiasing module, and text classification module. The multilingual text representation module uses a multilingual pre-trained language model to represent the text, the language fusion module makes the semantic spaces of different languages tend to be consistent through contrastive learning, and the text debiasing module uses co",
    "link": "http://arxiv.org/abs/2303.15697",
    "context": "Title: Model and Evaluation: Towards Fairness in Multilingual Text Classification. (arXiv:2303.15697v1 [cs.CL])\nAbstract: Recently, more and more research has focused on addressing bias in text classification models. However, existing research mainly focuses on the fairness of monolingual text classification models, and research on fairness for multilingual text classification is still very limited. In this paper, we focus on the task of multilingual text classification and propose a debiasing framework for multilingual text classification based on contrastive learning. Our proposed method does not rely on any external language resources and can be extended to any other languages. The model contains four modules: multilingual text representation module, language fusion module, text debiasing module, and text classification module. The multilingual text representation module uses a multilingual pre-trained language model to represent the text, the language fusion module makes the semantic spaces of different languages tend to be consistent through contrastive learning, and the text debiasing module uses co",
    "path": "papers/23/03/2303.15697.json",
    "total_tokens": 1009,
    "translated_title": "模型与评估：面向多语言文本分类的公平性研究",
    "translated_abstract": "最近，越来越多的研究关注于解决文本分类模型中的偏见问题。然而，现有的研究主要集中在单语言文本分类模型的公平性上，对于多语言文本分类的公平性研究仍然非常有限。本文关注于多语言文本分类任务，并提出了一种基于对比学习的解偏框架，旨在为多语言文本分类提供公平性。我们提出的方法不依赖于任何外部语言资源，可以扩展到任何其他语言。该模型包含四个模块：多语言文本表示模块，语言融合模块，文本解偏模块，和文本分类模块。多语言文本表示模块使用多语言预训练语言模型来表示文本，语言融合模块通过对比学习使不同语言的语义空间趋于一致，文本解偏模块使用共现统计量来重新加权文本表示，以减轻敏感属性的影响。我们在几个多语言文本分类基准上评估了我们提出的方法，并表明我们的模型可以在保持竞争性能的同时有效降低文本分类中的偏见。",
    "tldr": "本文提出了一种基于对比学习的多语言文本分类解偏模型，不依赖于外部语言资源，可以扩展到任何其他语言。该模型包含四个模块，可以有效降低文本分类中的偏见。",
    "en_tdlr": "This paper proposes a debiasing framework for multilingual text classification based on contrastive learning. The model does not rely on any external language resources and can be extended to any other languages. The proposed model contains four modules and can effectively reduce the bias in text classification."
}