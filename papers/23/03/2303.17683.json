{
    "title": "Fine-Tuning BERT with Character-Level Noise for Zero-Shot Transfer to Dialects and Closely-Related Languages. (arXiv:2303.17683v1 [cs.CL])",
    "abstract": "In this work, we induce character-level noise in various forms when fine-tuning BERT to enable zero-shot cross-lingual transfer to unseen dialects and languages. We fine-tune BERT on three sentence-level classification tasks and evaluate our approach on an assortment of unseen dialects and languages. We find that character-level noise can be an extremely effective agent of cross-lingual transfer under certain conditions, while it is not as helpful in others. Specifically, we explore these differences in terms of the nature of the task and the relationships between source and target languages, finding that introduction of character-level noise during fine-tuning is particularly helpful when a task draws on surface level cues and the source-target cross-lingual pair has a relatively high lexical overlap with shorter (i.e., less meaningful) unseen tokens on average.",
    "link": "http://arxiv.org/abs/2303.17683",
    "context": "Title: Fine-Tuning BERT with Character-Level Noise for Zero-Shot Transfer to Dialects and Closely-Related Languages. (arXiv:2303.17683v1 [cs.CL])\nAbstract: In this work, we induce character-level noise in various forms when fine-tuning BERT to enable zero-shot cross-lingual transfer to unseen dialects and languages. We fine-tune BERT on three sentence-level classification tasks and evaluate our approach on an assortment of unseen dialects and languages. We find that character-level noise can be an extremely effective agent of cross-lingual transfer under certain conditions, while it is not as helpful in others. Specifically, we explore these differences in terms of the nature of the task and the relationships between source and target languages, finding that introduction of character-level noise during fine-tuning is particularly helpful when a task draws on surface level cues and the source-target cross-lingual pair has a relatively high lexical overlap with shorter (i.e., less meaningful) unseen tokens on average.",
    "path": "papers/23/03/2303.17683.json",
    "total_tokens": 893,
    "translated_title": "用字符级噪音微调BERT实现零样本跨方言及相关语言迁移",
    "translated_abstract": "本研究中，我们使用不同形式的字符级噪音进行BERT微调，以实现对未见方言和语言的零样本跨语言迁移。我们在三个句子级分类任务上微调BERT，并在一些未见方言和语言上评估了我们的方法。我们发现，在某些条件下，字符级噪音可以是跨语言迁移的极其有效的工具，而在其他情况下则不太有帮助。具体而言，我们通过任务的性质和源语言和目标语言之间的关系探讨了这些差异，发现在任务依赖表面级别提示并且源-目标跨语言对具有相对较高的词汇重叠时，在微调过程中引入字符级噪音特别有帮助。",
    "tldr": "本研究使用字符级噪音微调BERT以实现对未见方言和语言的零样本跨语言迁移。本研究发现只有在任务依赖表面级别提示并且源-目标跨语言对具有相对较高的词汇重叠时，在微调过程中引入字符级噪音对跨语言迁移的效果才特别突出。",
    "en_tdlr": "This study fine-tunes BERT with character-level noise to enable zero-shot cross-lingual transfer to unseen dialects and languages. The researchers found that character-level noise is particularly effective for cross-lingual transfer when a task relies on surface-level cues and there is a relatively high lexical overlap between source and target languages."
}