{
    "title": "Generalization with quantum geometry for learning unitaries. (arXiv:2303.13462v1 [quant-ph])",
    "abstract": "Generalization is the ability of quantum machine learning models to make accurate predictions on new data by learning from training data. Here, we introduce the data quantum Fisher information metric (DQFIM) to determine when a model can generalize. For variational learning of unitaries, the DQFIM quantifies the amount of circuit parameters and training data needed to successfully train and generalize. We apply the DQFIM to explain when a constant number of training states and polynomial number of parameters are sufficient for generalization. Further, we can improve generalization by removing symmetries from training data. Finally, we show that out-of-distribution generalization, where training and testing data are drawn from different data distributions, can be better than using the same distribution. Our work opens up new approaches to improve generalization in quantum machine learning.",
    "link": "http://arxiv.org/abs/2303.13462",
    "context": "Title: Generalization with quantum geometry for learning unitaries. (arXiv:2303.13462v1 [quant-ph])\nAbstract: Generalization is the ability of quantum machine learning models to make accurate predictions on new data by learning from training data. Here, we introduce the data quantum Fisher information metric (DQFIM) to determine when a model can generalize. For variational learning of unitaries, the DQFIM quantifies the amount of circuit parameters and training data needed to successfully train and generalize. We apply the DQFIM to explain when a constant number of training states and polynomial number of parameters are sufficient for generalization. Further, we can improve generalization by removing symmetries from training data. Finally, we show that out-of-distribution generalization, where training and testing data are drawn from different data distributions, can be better than using the same distribution. Our work opens up new approaches to improve generalization in quantum machine learning.",
    "path": "papers/23/03/2303.13462.json",
    "total_tokens": 875,
    "translated_title": "利用量子几何进行学习幺正变换的泛化",
    "translated_abstract": "泛化是量子机器学习模型从训练数据学习准确预测新数据的能力。在这里，我们引入数据的量子费舍尔信息度量(DQFIM)来确定模型何时能够泛化。对于幺正变换的可变学习，DQFIM量化了成功训练和泛化所需的电路参数和训练数据的数量。我们应用DQFIM来解释何时恒定数量的训练状态和多项式数量的参数足以实现泛化。此外，通过从训练数据中删除对称性，可以提高泛化能力。最后，我们显示，使用不同数据分布进行训练和测试的超出分布泛化能力可以比使用相同分布的能力更优。我们的研究为提高量子机器学习中的泛化能力开辟了新的方法。",
    "tldr": "本文研究了量子机器学习模型的泛化能力，使用数据的量子费舍尔信息度量来评估成功训练和泛化所需的电路参数和训练数据的数量，并展示通过去除对称性来提高泛化能力，同时发现超出分布泛化能力可以比使用相同分布更优。",
    "en_tdlr": "This paper studies the generalization ability of quantum machine learning models, using the data quantum Fisher information metric to assess the amount of circuit parameters and training data needed for successful training and generalization, and shows that removing symmetries from training data can improve generalization, and that out-of-distribution generalization can be better than using the same distribution."
}