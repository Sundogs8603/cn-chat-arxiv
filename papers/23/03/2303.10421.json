{
    "title": "Mutilmodal Feature Extraction and Attention-based Fusion for Emotion Estimation in Videos. (arXiv:2303.10421v1 [cs.CV])",
    "abstract": "The continuous improvement of human-computer interaction technology makes it possible to compute emotions. In this paper, we introduce our submission to the CVPR 2023 Competition on Affective Behavior Analysis in-the-wild (ABAW). Sentiment analysis in human-computer interaction should, as far as possible Start with multiple dimensions, fill in the single imperfect emotion channel, and finally determine the emotion tendency by fitting multiple results. Therefore, We exploited multimodal features extracted from video of different lengths from the competition dataset, including audio, pose and images. Well-informed emotion representations drive us to propose a Attention-based multimodal framework for emotion estimation. Our system achieves the performance of 0.361 on the validation dataset. The code is available at [https://github.com/xkwangcn/ABAW-5th-RT-IAI].",
    "link": "http://arxiv.org/abs/2303.10421",
    "context": "Title: Mutilmodal Feature Extraction and Attention-based Fusion for Emotion Estimation in Videos. (arXiv:2303.10421v1 [cs.CV])\nAbstract: The continuous improvement of human-computer interaction technology makes it possible to compute emotions. In this paper, we introduce our submission to the CVPR 2023 Competition on Affective Behavior Analysis in-the-wild (ABAW). Sentiment analysis in human-computer interaction should, as far as possible Start with multiple dimensions, fill in the single imperfect emotion channel, and finally determine the emotion tendency by fitting multiple results. Therefore, We exploited multimodal features extracted from video of different lengths from the competition dataset, including audio, pose and images. Well-informed emotion representations drive us to propose a Attention-based multimodal framework for emotion estimation. Our system achieves the performance of 0.361 on the validation dataset. The code is available at [https://github.com/xkwangcn/ABAW-5th-RT-IAI].",
    "path": "papers/23/03/2303.10421.json",
    "total_tokens": 760,
    "translated_title": "视频中情感估计的多模态特征提取和基于注意力的融合",
    "translated_abstract": "人机交互技术的不断改进使得计算情感成为可能。本文介绍了我们在CVPR 2023 ABAW竞赛中提交的作品。情感分析应该从多个维度入手，填补单一不完善的情感通道，最终通过拟合多个结果确定情感倾向。因此，我们利用比赛数据集中不同长度的视频中提取的多模态特征，包括音频、姿势和图像。我们提出了一个基于注意力的多模态框架用于情感估计。我们的系统在验证数据集上取得了0.361的准确度。代码可在[https://github.com/xkwangcn/ABAW-5th-RT-IAI]获取。",
    "tldr": "本文介绍了一个基于注意力的多模态框架用于情感估计，在CVPR 2023 ABAW竞赛中取得了0.361的准确度。",
    "en_tdlr": "This paper proposes an attention-based multimodal framework for emotion estimation in videos, achieving 0.361 accuracy in the CVPR 2023 ABAW competition dataset."
}