{
    "title": "Extending the Pre-Training of BLOOM for Improved Support of Traditional Chinese: Models, Methods and Results. (arXiv:2303.04715v2 [cs.CL] UPDATED)",
    "abstract": "In this paper we present the multilingual language model BLOOM-zh that features enhanced support for Traditional Chinese. BLOOM-zh has its origins in the open-source BLOOM models presented by BigScience in 2022. Starting from released models, we extended the pre-training of BLOOM by additional 7.4 billion tokens in Traditional Chinese and English covering a variety of domains such as news articles, books, encyclopedias, educational materials as well as spoken language. In order to show the properties of BLOOM-zh, both existing and newly created benchmark scenarios are used for evaluating the performance. BLOOM-zh outperforms its predecessor on most Traditional Chinese benchmarks while maintaining its English capability. We release all our models to the research community.",
    "link": "http://arxiv.org/abs/2303.04715",
    "context": "Title: Extending the Pre-Training of BLOOM for Improved Support of Traditional Chinese: Models, Methods and Results. (arXiv:2303.04715v2 [cs.CL] UPDATED)\nAbstract: In this paper we present the multilingual language model BLOOM-zh that features enhanced support for Traditional Chinese. BLOOM-zh has its origins in the open-source BLOOM models presented by BigScience in 2022. Starting from released models, we extended the pre-training of BLOOM by additional 7.4 billion tokens in Traditional Chinese and English covering a variety of domains such as news articles, books, encyclopedias, educational materials as well as spoken language. In order to show the properties of BLOOM-zh, both existing and newly created benchmark scenarios are used for evaluating the performance. BLOOM-zh outperforms its predecessor on most Traditional Chinese benchmarks while maintaining its English capability. We release all our models to the research community.",
    "path": "papers/23/03/2303.04715.json",
    "total_tokens": 842,
    "translated_title": "BLOOM的预训练扩展以改善对繁体中文的支持：模型、方法和结果",
    "translated_abstract": "本文介绍了一种名为BLOOM-zh的多语言语言模型，它具有改进的繁体中文支持。BLOOM-zh起源于由BigScience于2022年推出的开源BLOOM模型。我们在已发布的模型基础上，使用74亿个额外的繁体中文和英文标记进行了扩展，覆盖了各种领域，如新闻文章、书籍、百科全书、教育材料以及口语语言。为了展示BLOOM-zh的性质，我们使用现有的和新创建的基准场景来评估其性能。在大多数的繁体中文基准测试中，BLOOM-zh的性能优于其前身，同时保持了其英文能力。我们将所有模型发布给研究社区。",
    "tldr": "本文介绍了一种名为BLOOM-zh的多语言语言模型，它扩展了BLOOM的预训练，并具有改进的繁体中文支持。BLOOM-zh在繁体中文基准测试中表现优于其前身。"
}