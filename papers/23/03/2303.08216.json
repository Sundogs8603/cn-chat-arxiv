{
    "title": "Efficiently Training Vision Transformers on Structural MRI Scans for Alzheimer's Disease Detection. (arXiv:2303.08216v1 [eess.IV])",
    "abstract": "Neuroimaging of large populations is valuable to identify factors that promote or resist brain disease, and to assist diagnosis, subtyping, and prognosis. Data-driven models such as convolutional neural networks (CNNs) have increasingly been applied to brain images to perform diagnostic and prognostic tasks by learning robust features. Vision transformers (ViT) - a new class of deep learning architectures - have emerged in recent years as an alternative to CNNs for several computer vision applications. Here we tested variants of the ViT architecture for a range of desired neuroimaging downstream tasks based on difficulty, in this case for sex and Alzheimer's disease (AD) classification based on 3D brain MRI. In our experiments, two vision transformer architecture variants achieved an AUC of 0.987 for sex and 0.892 for AD classification, respectively. We independently evaluated our models on data from two benchmark AD datasets. We achieved a performance boost of 5% and 9-10% upon fine-t",
    "link": "http://arxiv.org/abs/2303.08216",
    "context": "Title: Efficiently Training Vision Transformers on Structural MRI Scans for Alzheimer's Disease Detection. (arXiv:2303.08216v1 [eess.IV])\nAbstract: Neuroimaging of large populations is valuable to identify factors that promote or resist brain disease, and to assist diagnosis, subtyping, and prognosis. Data-driven models such as convolutional neural networks (CNNs) have increasingly been applied to brain images to perform diagnostic and prognostic tasks by learning robust features. Vision transformers (ViT) - a new class of deep learning architectures - have emerged in recent years as an alternative to CNNs for several computer vision applications. Here we tested variants of the ViT architecture for a range of desired neuroimaging downstream tasks based on difficulty, in this case for sex and Alzheimer's disease (AD) classification based on 3D brain MRI. In our experiments, two vision transformer architecture variants achieved an AUC of 0.987 for sex and 0.892 for AD classification, respectively. We independently evaluated our models on data from two benchmark AD datasets. We achieved a performance boost of 5% and 9-10% upon fine-t",
    "path": "papers/23/03/2303.08216.json",
    "total_tokens": 851,
    "translated_title": "用于阿尔茨海默病检测的结构性MRI扫描的Vision Transformers高效训练",
    "translated_abstract": "大规模人群神经影像学对于识别促进或抵抗脑疾病的因素以及协助诊断、亚型分类和预后都具有价值。本文尝试使用Vision Transformers(ViT)对基于难度调整的一系列神经影像学任务进行了测试，包括性别和阿尔茨海默病(AD)基于3D大脑MRI的分类。在实验中，两种ViT架构变体分别实现了0.987的性别分类AUC和0.892的AD分类AUC。我们独立评估了模型在两个基准AD数据集上的性能，并获得了5%和9-10%的性能提升。",
    "tldr": "本文尝试使用Vision Transformers对基于MRI扫描的性别和AD分类任务进行了测试，其中两种ViT架构变体分别实现了0.987的性别分类AUC和0.892的AD分类AUC。该方法可为大规模神经影像学识别提供高效解决方案。"
}