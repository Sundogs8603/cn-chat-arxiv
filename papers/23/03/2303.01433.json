{
    "title": "Do Machine Learning Models Learn Statistical Rules Inferred from Data?. (arXiv:2303.01433v2 [cs.LG] UPDATED)",
    "abstract": "Machine learning models can make critical errors that are easily hidden within vast amounts of data. Such errors often run counter to rules based on human intuition. However, rules based on human knowledge are challenging to scale or to even formalize. We thereby seek to infer statistical rules from the data and quantify the extent to which a model has learned them. We propose a framework SQRL that integrates logic-based methods with statistical inference to derive these rules from a model's training data without supervision. We further show how to adapt models at test time to reduce rule violations and produce more coherent predictions. SQRL generates up to 300K rules over datasets from vision, tabular, and language settings. We uncover up to 158K violations of those rules by state-of-the-art models for classification, object detection, and data imputation. Test-time adaptation reduces these violations by up to 68.7% with relative performance improvement up to 32%. SQRL is available a",
    "link": "http://arxiv.org/abs/2303.01433",
    "context": "Title: Do Machine Learning Models Learn Statistical Rules Inferred from Data?. (arXiv:2303.01433v2 [cs.LG] UPDATED)\nAbstract: Machine learning models can make critical errors that are easily hidden within vast amounts of data. Such errors often run counter to rules based on human intuition. However, rules based on human knowledge are challenging to scale or to even formalize. We thereby seek to infer statistical rules from the data and quantify the extent to which a model has learned them. We propose a framework SQRL that integrates logic-based methods with statistical inference to derive these rules from a model's training data without supervision. We further show how to adapt models at test time to reduce rule violations and produce more coherent predictions. SQRL generates up to 300K rules over datasets from vision, tabular, and language settings. We uncover up to 158K violations of those rules by state-of-the-art models for classification, object detection, and data imputation. Test-time adaptation reduces these violations by up to 68.7% with relative performance improvement up to 32%. SQRL is available a",
    "path": "papers/23/03/2303.01433.json",
    "total_tokens": 943,
    "translated_title": "机器学习模型是否能学习从数据中推断出的统计规则？",
    "translated_abstract": "机器学习模型可能会在大量数据中隐藏一些重要的错误，而这些错误通常违反了人类直觉的规则。然而，以人类知识为基础的规则往往不易扩展或正式化。因此，我们提出了一种框架SQRL，它将基于逻辑的方法与统计推断相结合，无需监督即可从模型的训练数据中推导出这些规则，并量化模型已经学习到这些规则的程度。我们进一步展示了如何在测试时间内调整模型以减少规则违规并产生更连贯的预测结果。SQRL可以在视觉、表格和语言场景下的数据集中生成多达30万条规则。我们发现最先进的分类、目标检测和数据填充模型违反了这些规则高达158K次。而测试时间的适应可以将这些违规行为减少高达68.7%，并提高相对性能高达32%。",
    "tldr": "本文提出了一个框架SQRL，可以无监督地从模型的训练数据中推断出统计规则；在分类、目标检测和数据填充等任务中，最先进的模型通常会违反这些规则，但是通过在测试时间内对模型进行适应，违规行为可以显著减少并提高模型的性能。"
}