{
    "title": "Towards the Scalable Evaluation of Cooperativeness in Language Models. (arXiv:2303.13360v1 [cs.CL])",
    "abstract": "It is likely that AI systems driven by pre-trained language models (PLMs) will increasingly be used to assist humans in high-stakes interactions with other agents, such as negotiation or conflict resolution. Consistent with the goals of Cooperative AI \\citep{dafoe_open_2020}, we wish to understand and shape the multi-agent behaviors of PLMs in a pro-social manner. An important first step is the evaluation of model behaviour across diverse cooperation problems. Since desired behaviour in an interaction depends upon precise game-theoretic structure, we focus on generating scenarios with particular structures with both crowdworkers and a language model. Our work proceeds as follows. First, we discuss key methodological issues in the generation of scenarios corresponding to particular game-theoretic structures. Second, we employ both crowdworkers and a language model to generate such scenarios. We find that the quality of generations tends to be mediocre in both cases. We additionally get ",
    "link": "http://arxiv.org/abs/2303.13360",
    "context": "Title: Towards the Scalable Evaluation of Cooperativeness in Language Models. (arXiv:2303.13360v1 [cs.CL])\nAbstract: It is likely that AI systems driven by pre-trained language models (PLMs) will increasingly be used to assist humans in high-stakes interactions with other agents, such as negotiation or conflict resolution. Consistent with the goals of Cooperative AI \\citep{dafoe_open_2020}, we wish to understand and shape the multi-agent behaviors of PLMs in a pro-social manner. An important first step is the evaluation of model behaviour across diverse cooperation problems. Since desired behaviour in an interaction depends upon precise game-theoretic structure, we focus on generating scenarios with particular structures with both crowdworkers and a language model. Our work proceeds as follows. First, we discuss key methodological issues in the generation of scenarios corresponding to particular game-theoretic structures. Second, we employ both crowdworkers and a language model to generate such scenarios. We find that the quality of generations tends to be mediocre in both cases. We additionally get ",
    "path": "papers/23/03/2303.13360.json",
    "total_tokens": 858,
    "translated_title": "基于语言模型的合作性评估的可扩展性研究",
    "translated_abstract": "预训练的语言模型（PLMs）驱动的AI系统可能越来越多地用于辅助人类进行涉及其他代理人的高 stakes 交互，例如协商或冲突解决。符合合作的AI的目标，我们希望以亲社会的方式理解和塑造PLM的多代理行为。一个重要的第一步是对模型在各种合作问题上行为的评估。由于交互中期望的行为取决于精确的博弈结构，我们专注于使用众包工人和语言模型生成特定结构的场景。我们的工作如下。首先，我们讨论了生成特定博弈论结构场景的关键方法问题。其次，我们使用众包工人和语言模型来生成这些场景。我们发现两种情况下的生成质量往往是中等水平。此外，我们获得了以下结论：",
    "tldr": "本论文旨在对基于语言模型的合作性评估的可扩展性进行研究，通过生成特定博弈论结构场景并进行评估，不过目前生成质量较一般。",
    "en_tdlr": "This paper aims to investigate the scalability of the evaluation of cooperativeness in language models. By generating scenarios with specific game-theoretic structures and evaluating them, we found that the quality of generation is mediocre."
}