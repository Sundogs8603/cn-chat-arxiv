{
    "title": "Edit at your own risk: evaluating the robustness of edited models to distribution shifts. (arXiv:2303.00046v2 [cs.LG] UPDATED)",
    "abstract": "The current trend toward ever-larger models makes standard retraining procedures an ever-more expensive burden. For this reason, there is growing interest in model editing, which enables computationally inexpensive, interpretable, post-hoc model modifications. While many model editing techniques are promising, research on the properties of edited models is largely limited to evaluation of validation accuracy. The robustness of edited models is an important and yet mostly unexplored topic. In this paper, we employ recently developed techniques from the field of deep learning robustness to investigate both how model editing affects the general robustness of a model, as well as the robustness of the specific behavior targeted by the edit. We find that edits tend to reduce general robustness, but that the degree of degradation depends on the editing algorithm and layers chosen. Motivated by these observations we introduce a new model editing algorithm, 1-layer interpolation (1-LI), which u",
    "link": "http://arxiv.org/abs/2303.00046",
    "context": "Title: Edit at your own risk: evaluating the robustness of edited models to distribution shifts. (arXiv:2303.00046v2 [cs.LG] UPDATED)\nAbstract: The current trend toward ever-larger models makes standard retraining procedures an ever-more expensive burden. For this reason, there is growing interest in model editing, which enables computationally inexpensive, interpretable, post-hoc model modifications. While many model editing techniques are promising, research on the properties of edited models is largely limited to evaluation of validation accuracy. The robustness of edited models is an important and yet mostly unexplored topic. In this paper, we employ recently developed techniques from the field of deep learning robustness to investigate both how model editing affects the general robustness of a model, as well as the robustness of the specific behavior targeted by the edit. We find that edits tend to reduce general robustness, but that the degree of degradation depends on the editing algorithm and layers chosen. Motivated by these observations we introduce a new model editing algorithm, 1-layer interpolation (1-LI), which u",
    "path": "papers/23/03/2303.00046.json",
    "total_tokens": 1014,
    "translated_title": "自行承担编辑风险：评估经过分布转移的模型的鲁棒性",
    "translated_abstract": "不断增大模型的趋势使得标准的重新训练过程变得越来越昂贵。因此，对于能够在后期进行解释性的、计算便宜的模型修改的方法越来越感兴趣。虽然许多模型编辑技术很有前景，但对于编辑模型的属性的研究主要仅限于验证准确性的评估。编辑模型的鲁棒性是一个重要但很少被探索的主题。在本文中，我们采用最近从深度学习鲁棒性领域开发的技术，研究模型编辑如何影响模型的普遍鲁棒性，以及编辑所针对的特定行为的鲁棒性。我们发现编辑倾向于降低普遍鲁棒性，但受编辑算法和选择的层的影响程度不同。在这些观察的基础上，我们引入了一种新的模型编辑算法，1层插值(1-LI)，它通过组合不同层的特征进行插值来编辑模型，这在一定程度上提高了模型的鲁棒性。",
    "tldr": "本文研究了模型编辑对模型的鲁棒性的影响，并发现编辑通常会降低模型的鲁棒性，但具体程度取决于编辑算法和层的选择。基于这些发现，引入了一种新的模型编辑算法，通过插值不同层的特征来提高模型的鲁棒性。",
    "en_tdlr": "This paper investigates the impact of model editing on the robustness of models, and finds that edits tend to reduce general robustness, but the degree of degradation depends on the editing algorithm and layers chosen. Based on these findings, a new model editing algorithm is introduced to improve model robustness by interpolating features from different layers."
}