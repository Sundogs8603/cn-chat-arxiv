{
    "title": "Causality Detection for Efficient Multi-Agent Reinforcement Learning. (arXiv:2303.14227v1 [cs.AI])",
    "abstract": "When learning a task as a team, some agents in Multi-Agent Reinforcement Learning (MARL) may fail to understand their true impact in the performance of the team. Such agents end up learning sub-optimal policies, demonstrating undesired lazy behaviours. To investigate this problem, we start by formalising the use of temporal causality applied to MARL problems. We then show how causality can be used to penalise such lazy agents and improve their behaviours. By understanding how their local observations are causally related to the team reward, each agent in the team can adjust their individual credit based on whether they helped to cause the reward or not. We show empirically that using causality estimations in MARL improves not only the holistic performance of the team, but also the individual capabilities of each agent. We observe that the improvements are consistent in a set of different environments.",
    "link": "http://arxiv.org/abs/2303.14227",
    "context": "Title: Causality Detection for Efficient Multi-Agent Reinforcement Learning. (arXiv:2303.14227v1 [cs.AI])\nAbstract: When learning a task as a team, some agents in Multi-Agent Reinforcement Learning (MARL) may fail to understand their true impact in the performance of the team. Such agents end up learning sub-optimal policies, demonstrating undesired lazy behaviours. To investigate this problem, we start by formalising the use of temporal causality applied to MARL problems. We then show how causality can be used to penalise such lazy agents and improve their behaviours. By understanding how their local observations are causally related to the team reward, each agent in the team can adjust their individual credit based on whether they helped to cause the reward or not. We show empirically that using causality estimations in MARL improves not only the holistic performance of the team, but also the individual capabilities of each agent. We observe that the improvements are consistent in a set of different environments.",
    "path": "papers/23/03/2303.14227.json",
    "total_tokens": 944,
    "translated_title": "高效多智能体强化学习中的因果关系检测",
    "translated_abstract": "当作为团队学习任务时，多智能体强化学习（MARL）中的一些代理可能无法理解他们在团队表现中的真实影响。这些代理最终会学习次优策略，表现出不良的懒惰行为。本文通过正式表述时间因果关系在MARL问题中的应用来研究这个问题。我们展示了如何利用因果关系来惩罚这些懒惰代理并改善其行为。通过理解他们的本地观测如何因果相关于团队奖励，团队中的每个代理都可以根据他们是否有助于导致奖励来调整其个人信用贡献。我们实证表明，在MARL中使用因果估计不仅可以改善团队整体性能，还可以提升每个代理的个体能力。我们观察到，在一组不同的环境中，这种改进是一致的。",
    "tldr": "本文研究了多智能体强化学习中一些代理无法理解他们在团队表现中的真实影响，导致学习次优策略，表现懒惰。通过因果关系检测惩罚懒惰代理并改善其行为，团队整体性能和每个代理的个体能力都得到了提升。",
    "en_tdlr": "This paper investigates the problem in Multi-Agent Reinforcement Learning where some agents fail to understand their true impact on team performance, resulting in sub-optimal policies and lazy behavior. To address this, the paper proposes using causality detection to penalize lazy agents and improve team performance as well as individual capabilities. The paper shows empirical evidence of the effectiveness of this approach in various environments."
}