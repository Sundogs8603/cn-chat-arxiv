{
    "title": "Q-learning Based System for Path Planning with UAV Swarms in Obstacle Environments. (arXiv:2303.17655v1 [cs.AI])",
    "abstract": "Path Planning methods for autonomous control of Unmanned Aerial Vehicle (UAV) swarms are on the rise because of all the advantages they bring. There are more and more scenarios where autonomous control of multiple UAVs is required. Most of these scenarios present a large number of obstacles, such as power lines or trees. If all UAVs can be operated autonomously, personnel expenses can be decreased. In addition, if their flight paths are optimal, energy consumption is reduced. This ensures that more battery time is left for other operations. In this paper, a Reinforcement Learning based system is proposed for solving this problem in environments with obstacles by making use of Q-Learning. This method allows a model, in this particular case an Artificial Neural Network, to self-adjust by learning from its mistakes and achievements. Regardless of the size of the map or the number of UAVs in the swarm, the goal of these paths is to ensure complete coverage of an area with fixed obstacles f",
    "link": "http://arxiv.org/abs/2303.17655",
    "context": "Title: Q-learning Based System for Path Planning with UAV Swarms in Obstacle Environments. (arXiv:2303.17655v1 [cs.AI])\nAbstract: Path Planning methods for autonomous control of Unmanned Aerial Vehicle (UAV) swarms are on the rise because of all the advantages they bring. There are more and more scenarios where autonomous control of multiple UAVs is required. Most of these scenarios present a large number of obstacles, such as power lines or trees. If all UAVs can be operated autonomously, personnel expenses can be decreased. In addition, if their flight paths are optimal, energy consumption is reduced. This ensures that more battery time is left for other operations. In this paper, a Reinforcement Learning based system is proposed for solving this problem in environments with obstacles by making use of Q-Learning. This method allows a model, in this particular case an Artificial Neural Network, to self-adjust by learning from its mistakes and achievements. Regardless of the size of the map or the number of UAVs in the swarm, the goal of these paths is to ensure complete coverage of an area with fixed obstacles f",
    "path": "papers/23/03/2303.17655.json",
    "total_tokens": 724,
    "translated_title": "基于Q学习的无人机集群障碍物路径规划系统",
    "translated_abstract": "随着无人机集群的自主控制需求不断增加，面对复杂环境中的障碍物，路径规划对于优化能量消耗和减少人力成本具有重要作用。本篇论文提出了一种基于强化学习的Q学习算法，通过人工神经网络不断调整学习，实现在有障碍物的环境中进行路径规划。",
    "tldr": "本文提出了一种基于强化学习的Q学习算法，能够在有障碍物的环境中通过人工神经网络进行路径规划优化，从而减少能量消耗和人力成本。",
    "en_tdlr": "This paper proposes a Q-learning algorithm based on reinforcement learning to optimize path planning in obstacle environments through the continual adjustment and learning of an artificial neural network, reducing energy consumption and personnel costs."
}