{
    "title": "LLMSecEval: A Dataset of Natural Language Prompts for Security Evaluations. (arXiv:2303.09384v1 [cs.SE])",
    "abstract": "Large Language Models (LLMs) like Codex are powerful tools for performing code completion and code generation tasks as they are trained on billions of lines of code from publicly available sources. Moreover, these models are capable of generating code snippets from Natural Language (NL) descriptions by learning languages and programming practices from public GitHub repositories. Although LLMs promise an effortless NL-driven deployment of software applications, the security of the code they generate has not been extensively investigated nor documented. In this work, we present LLMSecEval, a dataset containing 150 NL prompts that can be leveraged for assessing the security performance of such models. Such prompts are NL descriptions of code snippets prone to various security vulnerabilities listed in MITRE's Top 25 Common Weakness Enumeration (CWE) ranking. Each prompt in our dataset comes with a secure implementation example to facilitate comparative evaluations against code produced by",
    "link": "http://arxiv.org/abs/2303.09384",
    "context": "Title: LLMSecEval: A Dataset of Natural Language Prompts for Security Evaluations. (arXiv:2303.09384v1 [cs.SE])\nAbstract: Large Language Models (LLMs) like Codex are powerful tools for performing code completion and code generation tasks as they are trained on billions of lines of code from publicly available sources. Moreover, these models are capable of generating code snippets from Natural Language (NL) descriptions by learning languages and programming practices from public GitHub repositories. Although LLMs promise an effortless NL-driven deployment of software applications, the security of the code they generate has not been extensively investigated nor documented. In this work, we present LLMSecEval, a dataset containing 150 NL prompts that can be leveraged for assessing the security performance of such models. Such prompts are NL descriptions of code snippets prone to various security vulnerabilities listed in MITRE's Top 25 Common Weakness Enumeration (CWE) ranking. Each prompt in our dataset comes with a secure implementation example to facilitate comparative evaluations against code produced by",
    "path": "papers/23/03/2303.09384.json",
    "total_tokens": 870,
    "translated_title": "LLMSecEval: 一个用于安全评估的自然语言提示数据集",
    "translated_abstract": "大型语言模型（LLM）如 Codex 在代码自动补全和生成任务方面具有强大的能力，因为它们通过公开可用的代码从数十亿行代码中进行训练。此外，这些模型能够通过从公共 GitHub 仓库学习语言和编程实践来生成来自自然语言描述的代码片段。尽管 LLM 承诺实现软件应用的 NL 驱动部署，但是它们生成的代码的安全性尚未得到广泛调查和记录。在这项工作中，我们提出了 LLMSecEval，这是一个包含 150 个 NL 提示的数据集，可用于评估此类模型的安全性能。这些提示是基于MITRE的前25个常见弱点列表中容易出现各种安全漏洞的代码片段的自然语言描述。我们数据集中的每个提示都配有一个安全实现示例，以便与由LLM生成的代码进行比较评估。",
    "tldr": "本文提出了一个 LLMSecEval 数据集，其中包含 150 个自然语言提示，可用于评估大型语言模型在生成容易出现安全漏洞的代码时的安全性能。"
}