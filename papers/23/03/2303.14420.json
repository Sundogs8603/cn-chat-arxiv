{
    "title": "Better Aligning Text-to-Image Models with Human Preference. (arXiv:2303.14420v1 [cs.CV])",
    "abstract": "Recent years have witnessed a rapid growth of deep generative models, with text-to-image models gaining significant attention from the public. However, existing models often generate images that do not align well with human aesthetic preferences, such as awkward combinations of limbs and facial expressions. To address this issue, we collect a dataset of human choices on generated images from the Stable Foundation Discord channel. Our experiments demonstrate that current evaluation metrics for generative models do not correlate well with human choices. Thus, we train a human preference classifier with the collected dataset and derive a Human Preference Score (HPS) based on the classifier. Using the HPS, we propose a simple yet effective method to adapt Stable Diffusion to better align with human aesthetic preferences. Our experiments show that the HPS outperforms CLIP in predicting human choices and has good generalization capability towards images generated from other models. By tuning",
    "link": "http://arxiv.org/abs/2303.14420",
    "context": "Title: Better Aligning Text-to-Image Models with Human Preference. (arXiv:2303.14420v1 [cs.CV])\nAbstract: Recent years have witnessed a rapid growth of deep generative models, with text-to-image models gaining significant attention from the public. However, existing models often generate images that do not align well with human aesthetic preferences, such as awkward combinations of limbs and facial expressions. To address this issue, we collect a dataset of human choices on generated images from the Stable Foundation Discord channel. Our experiments demonstrate that current evaluation metrics for generative models do not correlate well with human choices. Thus, we train a human preference classifier with the collected dataset and derive a Human Preference Score (HPS) based on the classifier. Using the HPS, we propose a simple yet effective method to adapt Stable Diffusion to better align with human aesthetic preferences. Our experiments show that the HPS outperforms CLIP in predicting human choices and has good generalization capability towards images generated from other models. By tuning",
    "path": "papers/23/03/2303.14420.json",
    "total_tokens": 1011,
    "translated_title": "更好地将文本到图像模型与人类偏好对齐",
    "translated_abstract": "近年来，深度生成模型蓬勃发展，其中文本到图像模型备受关注。然而，现有模型通常生成的图像与人类审美偏好不符，例如肢体和面部表情的组合不自然。为解决这一问题，我们收集了来自Stable Foundation Discord频道的人类选择生成图像的数据集。我们的实验证明，当前的生成模型评估指标与人类选择相关性不强。因此，我们使用收集的数据集训练了一个人类偏好分类器，并基于该分类器得出了一个基于人类偏好的分数（HPS）。通过HPS，我们提出了一种简单而有效的方法，以更好地将Stable Diffusion与人类审美偏好对齐。我们的实验表明，HPS在预测人类选择方面优于CLIP，并且具有对来自其他模型生成的图像的良好泛化能力。通过使用HPS调整Stable Diffusion的噪声水平，我们实现了更好的人类偏好对齐，同时保持了生成图像的多样性和质量。",
    "tldr": "研究者们收集了一个数据集，证明现有的生成模型评估指标与人类选择相关性不强。因此，他们使用这个数据集训练了一个人类偏好分类器，并通过HPS提出了一种方法以更好地将Stable Diffusion与人类审美偏好对齐。实验表明，该方法在预测人类选择方面优于CLIP，并具有良好的泛化能力。",
    "en_tdlr": "Researchers collected a dataset to show that current evaluation metrics for generative models do not correlate well with human choices. They trained a human preference classifier with this dataset and proposed a method to better align Stable Diffusion with human aesthetic preferences using the derived Human Preference Score (HPS). Experiments showed that this method outperforms CLIP in predicting human choices and is capable of generalizing towards images generated from other models."
}