{
    "title": "TRAK: Attributing Model Behavior at Scale. (arXiv:2303.14186v1 [stat.ML])",
    "abstract": "The goal of data attribution is to trace model predictions back to training data. Despite a long line of work towards this goal, existing approaches to data attribution tend to force users to choose between computational tractability and efficacy. That is, computationally tractable methods can struggle with accurately attributing model predictions in non-convex settings (e.g., in the context of deep neural networks), while methods that are effective in such regimes require training thousands of models, which makes them impractical for large models or datasets.  In this work, we introduce TRAK (Tracing with the Randomly-projected After Kernel), a data attribution method that is both effective and computationally tractable for large-scale, differentiable models. In particular, by leveraging only a handful of trained models, TRAK can match the performance of attribution methods that require training thousands of models. We demonstrate the utility of TRAK across various modalities and scal",
    "link": "http://arxiv.org/abs/2303.14186",
    "context": "Title: TRAK: Attributing Model Behavior at Scale. (arXiv:2303.14186v1 [stat.ML])\nAbstract: The goal of data attribution is to trace model predictions back to training data. Despite a long line of work towards this goal, existing approaches to data attribution tend to force users to choose between computational tractability and efficacy. That is, computationally tractable methods can struggle with accurately attributing model predictions in non-convex settings (e.g., in the context of deep neural networks), while methods that are effective in such regimes require training thousands of models, which makes them impractical for large models or datasets.  In this work, we introduce TRAK (Tracing with the Randomly-projected After Kernel), a data attribution method that is both effective and computationally tractable for large-scale, differentiable models. In particular, by leveraging only a handful of trained models, TRAK can match the performance of attribution methods that require training thousands of models. We demonstrate the utility of TRAK across various modalities and scal",
    "path": "papers/23/03/2303.14186.json",
    "total_tokens": 852,
    "translated_title": "TRAK: 刻画大规模模型行为",
    "translated_abstract": "数据归因的目标是追踪模型预测结果的原始训练数据。虽然已经有很多工作致力于实现这一目标，但现有方法往往要求用户在计算效率和准确性之间做出选择。也就是说，在非凸场景（例如，深度神经网络领域）中，计算量可行的方法可能难以准确地归因模型预测结果，而在这类场景中有效的方法则需要训练数千个模型，这使得它们在大型模型或数据集中实际应用具有不可行性。在本文中，我们介绍了TRAK（随机投影核追踪），这是一种数据归因方法，适用于大规模、可微模型，既有效又计算量可行。具体来说，通过仅使用少量训练模型，TRAK 可以匹配需要训练数千模型才能得到的归因方法的性能。我们论证了TRAK 在各种模式和规模上的实用性。",
    "tldr": "TRAK是一种适用于大规模、可微模型的数据归因方法，既有效又计算量可行。",
    "en_tdlr": "TRAK is an effective and computationally tractable data attribution method for large-scale, differentiable models, which can match the performance of attribution methods that require training thousands of models by leveraging only a handful of trained models."
}