{
    "title": "A Comparative Study of Self-Supervised Speech Representations in Read and Spontaneous TTS. (arXiv:2303.02719v2 [eess.AS] UPDATED)",
    "abstract": "Recent work has explored using self-supervised learning (SSL) speech representations such as wav2vec2.0 as the representation medium in standard two-stage TTS, in place of conventionally used mel-spectrograms. It is however unclear which speech SSL is the better fit for TTS, and whether or not the performance differs between read and spontaneous TTS, the later of which is arguably more challenging. This study aims at addressing these questions by testing several speech SSLs, including different layers of the same SSL, in two-stage TTS on both read and spontaneous corpora, while maintaining constant TTS model architecture and training settings. Results from listening tests show that the 9th layer of 12-layer wav2vec2.0 (ASR finetuned) outperforms other tested SSLs and mel-spectrogram, in both read and spontaneous TTS. Our work sheds light on both how speech SSL can readily improve current TTS systems, and how SSLs compare in the challenging generative task of TTS. Audio examples can be ",
    "link": "http://arxiv.org/abs/2303.02719",
    "context": "Title: A Comparative Study of Self-Supervised Speech Representations in Read and Spontaneous TTS. (arXiv:2303.02719v2 [eess.AS] UPDATED)\nAbstract: Recent work has explored using self-supervised learning (SSL) speech representations such as wav2vec2.0 as the representation medium in standard two-stage TTS, in place of conventionally used mel-spectrograms. It is however unclear which speech SSL is the better fit for TTS, and whether or not the performance differs between read and spontaneous TTS, the later of which is arguably more challenging. This study aims at addressing these questions by testing several speech SSLs, including different layers of the same SSL, in two-stage TTS on both read and spontaneous corpora, while maintaining constant TTS model architecture and training settings. Results from listening tests show that the 9th layer of 12-layer wav2vec2.0 (ASR finetuned) outperforms other tested SSLs and mel-spectrogram, in both read and spontaneous TTS. Our work sheds light on both how speech SSL can readily improve current TTS systems, and how SSLs compare in the challenging generative task of TTS. Audio examples can be ",
    "path": "papers/23/03/2303.02719.json",
    "total_tokens": 1009,
    "translated_title": "自我监督语音表示在朗读和自由说话语音合成中的比较研究",
    "translated_abstract": "最近的研究探索了使用自我监督学习（SSL）语音表示，如wav2vec2.0作为标准两阶段语音合成（TTS）中的表示介质，以取代惯常使用的mel频谱图。然而，目前尚不清楚哪种语音SSL适用于TTS，并且朗读和自由说话TTS之间的性能是否有所不同，后者可能更具挑战性。本研究旨在通过在朗读和自由说话语料库上测试几种语音SSL，包括同一个SSL的不同层，在保持TTS模型架构和训练设置恒定的情况下，解答这些问题。听测试的结果显示，在朗读和自由说话的TTS中，12层wav2vec2.0（ASR微调）的第9层胜过其他被测试的SSL和mel频谱图。我们的工作揭示了语音SSL如何可以方便地改进当前的TTS系统，以及在具有挑战性的TTS生成任务中SSL之间的比较。",
    "tldr": "这项研究比较了在朗读和自由说话语音合成中使用的自我监督语音表示，并发现在12层wav2vec2.0（ASR微调）的第9层表现最优。这项工作揭示了语音SSL如何改进TTS系统，并在具有挑战性的TTS生成任务中进行了比较。",
    "en_tdlr": "This study compares self-supervised speech representations used in read and spontaneous text-to-speech (TTS) systems, finding that the 9th layer of the 12-layer wav2vec2.0 (ASR finetuned) performs the best. The work highlights the potential of speech SSL in enhancing TTS systems and provides comparisons in the challenging task of TTS generation."
}