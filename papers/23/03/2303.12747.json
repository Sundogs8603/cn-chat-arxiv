{
    "title": "Less is More: Unsupervised Mask-guided Annotated CT Image Synthesis with Minimum Manual Segmentations. (arXiv:2303.12747v1 [eess.IV])",
    "abstract": "As a pragmatic data augmentation tool, data synthesis has generally returned dividends in performance for deep learning based medical image analysis. However, generating corresponding segmentation masks for synthetic medical images is laborious and subjective. To obtain paired synthetic medical images and segmentations, conditional generative models that use segmentation masks as synthesis conditions were proposed. However, these segmentation mask-conditioned generative models still relied on large, varied, and labeled training datasets, and they could only provide limited constraints on human anatomical structures, leading to unrealistic image features. Moreover, the invariant pixel-level conditions could reduce the variety of synthetic lesions and thus reduce the efficacy of data augmentation. To address these issues, in this work, we propose a novel strategy for medical image synthesis, namely Unsupervised Mask (UM)-guided synthesis, to obtain both synthetic images and segmentations",
    "link": "http://arxiv.org/abs/2303.12747",
    "context": "Title: Less is More: Unsupervised Mask-guided Annotated CT Image Synthesis with Minimum Manual Segmentations. (arXiv:2303.12747v1 [eess.IV])\nAbstract: As a pragmatic data augmentation tool, data synthesis has generally returned dividends in performance for deep learning based medical image analysis. However, generating corresponding segmentation masks for synthetic medical images is laborious and subjective. To obtain paired synthetic medical images and segmentations, conditional generative models that use segmentation masks as synthesis conditions were proposed. However, these segmentation mask-conditioned generative models still relied on large, varied, and labeled training datasets, and they could only provide limited constraints on human anatomical structures, leading to unrealistic image features. Moreover, the invariant pixel-level conditions could reduce the variety of synthetic lesions and thus reduce the efficacy of data augmentation. To address these issues, in this work, we propose a novel strategy for medical image synthesis, namely Unsupervised Mask (UM)-guided synthesis, to obtain both synthetic images and segmentations",
    "path": "papers/23/03/2303.12747.json",
    "total_tokens": 900,
    "translated_title": "少即是多：最少的手动分割下，无监督掩模引导CT图像合成",
    "translated_abstract": "作为一种实用的数据增强工具，数据合成通常会为基于深度学习的医学图像分析带来更好的表现。然而，为合成的医学图像生成相应的分割掩模是费力和主观的。为了获得配对的合成医学图像和分割，提出了使用分割掩模作为合成条件的条件生成模型。然而，这些分割掩模条件下的生成模型仍然依赖于大量的、多样化的、标记的训练数据集，并且只能提供有限的人体解剖结构约束，导致图像特征不真实。此外，不变的像素级条件可能会减少合成病变的多样性，从而降低数据增强的效果。为了解决这些问题，本文提出了一种新的医学图像合成策略，即无监督掩模引导合成，以获得合成图像和分割。",
    "tldr": "本文提出了一种新颖的医学图像合成策略——无监督掩模引导合成，能够在最小手动分割的情况下，获得合成图像和分割，有效地避免了分割掩模数量不足、标签不准确等问题。",
    "en_tdlr": "This paper proposes a novel strategy for medical image synthesis, named Unsupervised Mask (UM)-guided synthesis, which can obtain both synthetic images and segmentations with minimum manual segmentations, effectively avoiding problems such as insufficient segmentation masks and inaccurate labels."
}