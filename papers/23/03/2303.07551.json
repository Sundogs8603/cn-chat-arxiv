{
    "title": "Merging Decision Transformers: Weight Averaging for Forming Multi-Task Policies. (arXiv:2303.07551v1 [cs.LG])",
    "abstract": "Recent work has shown the promise of creating generalist, transformer-based, policies for language, vision, and sequential decision-making problems. To create such models, we generally require centralized training objectives, data, and compute. It is of interest if we can more flexibly create generalist policies, by merging together multiple, task-specific, individually trained policies. In this work, we take a preliminary step in this direction through merging, or averaging, subsets of Decision Transformers in weight space trained on different MuJoCo locomotion problems, forming multi-task models without centralized training. We also propose that when merging policies, we can obtain better results if all policies start from common, pre-trained initializations, while also co-training on shared auxiliary tasks during problem-specific finetuning. In general, we believe research in this direction can help democratize and distribute the process of which forms generally capable agents.",
    "link": "http://arxiv.org/abs/2303.07551",
    "total_tokens": 948,
    "translated_title": "合并决策Transformer：多任务策略形成的权重平均化",
    "translated_abstract": "最近的研究展示了基于Transformer的通用语言、视觉和连续决策制定问题的策略的前景。为了创建这样的模型，我们通常需要集中的训练目标、数据和计算。如果我们能够更灵活地创建通用策略，通过合并多个任务特定的、单独训练的策略，则这样做就比较有意义。在本文中，我们通过在权重空间中合并或平均不同MuJoCo运动问题上训练的Decision Transformer的子集来迈出这个方向的初步步骤，形成没有集中训练的多任务模型。我们还建议在合并策略时可以获得更好的结果，如果所有策略都从共同的预训练初始化开始，并在问题特定的微调期间共同训练共享的辅助任务。一般来说，我们相信这个方向的研究可以帮助民主化和分发具有一般能力的代理的过程。",
    "tldr": "本文提出通过在权重空间中合并训练于不同 MuJoCo 运动问题上的 Decision Transformer 的子集，形成多任务模型。通过共享一些辅助任务的训练以及共同使用预训练初始化，能够获得更好的结果。这个方向的研究有助于使代理的过程民主化和分发。",
    "en_tdlr": "This paper proposes to merge subsets of Decision Transformers trained on different MuJoCo locomotion problems in weight space to form multi-task models, which can be achieved without centralized training. Better results can be obtained by co-training on shared auxiliary tasks during problem-specific finetuning with a common pre-trained initialization. Research in this direction can help democratize and distribute the process of forming generally capable agents."
}