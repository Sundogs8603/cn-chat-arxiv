{
    "title": "Interpretable Reinforcement Learning via Neural Additive Models for Inventory Management. (arXiv:2303.10382v1 [cs.LG])",
    "abstract": "The COVID-19 pandemic has highlighted the importance of supply chains and the role of digital management to react to dynamic changes in the environment. In this work, we focus on developing dynamic inventory ordering policies for a multi-echelon, i.e. multi-stage, supply chain. Traditional inventory optimization methods aim to determine a static reordering policy. Thus, these policies are not able to adjust to dynamic changes such as those observed during the COVID-19 crisis. On the other hand, conventional strategies offer the advantage of being interpretable, which is a crucial feature for supply chain managers in order to communicate decisions to their stakeholders. To address this limitation, we propose an interpretable reinforcement learning approach that aims to be as interpretable as the traditional static policies while being as flexible and environment-agnostic as other deep learning-based reinforcement learning solutions. We propose to use Neural Additive Models as an interpr",
    "link": "http://arxiv.org/abs/2303.10382",
    "context": "Title: Interpretable Reinforcement Learning via Neural Additive Models for Inventory Management. (arXiv:2303.10382v1 [cs.LG])\nAbstract: The COVID-19 pandemic has highlighted the importance of supply chains and the role of digital management to react to dynamic changes in the environment. In this work, we focus on developing dynamic inventory ordering policies for a multi-echelon, i.e. multi-stage, supply chain. Traditional inventory optimization methods aim to determine a static reordering policy. Thus, these policies are not able to adjust to dynamic changes such as those observed during the COVID-19 crisis. On the other hand, conventional strategies offer the advantage of being interpretable, which is a crucial feature for supply chain managers in order to communicate decisions to their stakeholders. To address this limitation, we propose an interpretable reinforcement learning approach that aims to be as interpretable as the traditional static policies while being as flexible and environment-agnostic as other deep learning-based reinforcement learning solutions. We propose to use Neural Additive Models as an interpr",
    "path": "papers/23/03/2303.10382.json",
    "total_tokens": 1063,
    "translated_title": "基于神经加性模型的可解释强化学习在库存管理中的应用",
    "translated_abstract": "COVID-19疫情彰显了供应链的重要性和数字化管理在应对环境的动态变化中的作用。本文着重于为多级别即多阶段的供应链开发动态库存订购策略。传统的库存优化方法旨在确定静态订购策略，这些策略不能适应如COVID-19危机中观察到的动态变化。然而，传统策略具有可解释性的优势，这是供应链管理者沟通决策与相关方需要具备的关键特征。为了解决这一限制，我们提出了一种可解释性的强化学习方法，既具有传统静态策略的可解释性，又具有其他深度强化学习方法的灵活性和环境无关性。我们建议使用神经加性模型作为库存订购策略的解释函数逼近器。我们的方法在三级供应链仿真中进行了测试，并与传统库存策略以及其他强化学习方法进行了比较。结果表明，我们的方法优于传统策略，并在具有可解释性的同时，实现了与最先进的深度强化学习方法相当的性能。",
    "tldr": "本文提出了一种基于神经加性模型的可解释强化学习方法，用于开发多级别供应链的动态库存订购策略，在三级供应链仿真测试中证明了实现与最先进深度强化学习方法相当的性能表现，同时具备传统策略的可解释性。",
    "en_tdlr": "This paper introduces an interpretable reinforcement learning approach based on neural additive models for developing dynamic inventory ordering policies for multi-stage supply chains. Results show competitive performance with state-of-the-art deep reinforcement learning methods while maintaining interpretability like traditional policies."
}