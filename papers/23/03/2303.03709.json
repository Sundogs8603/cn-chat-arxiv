{
    "title": "Bootstrap The Original Latent: Learning a Private Model from a Black-box Model. (arXiv:2303.03709v3 [cs.CV] UPDATED)",
    "abstract": "In this paper, considering the balance of data/model privacy of model owners and user needs, we propose a new setting called Back-Propagated Black-Box Adaptation (BPBA) for users to better train their private models via the guidance of the back-propagated results of a Black-box foundation/source model. Our setting can ease the usage of foundation/source models as well as prevent the leakage and misuse of foundation/source models. Moreover, we also propose a new training strategy called Bootstrap The Original Latent (BTOL) to fully utilize the foundation/source models. Our strategy consists of a domain adapter and a freeze-and-thaw strategy. We apply our BTOL under BPBA and Black-box UDA settings on three different datasets. Experiments show that our strategy is efficient and robust in various settings without manual augmentations.",
    "link": "http://arxiv.org/abs/2303.03709",
    "context": "Title: Bootstrap The Original Latent: Learning a Private Model from a Black-box Model. (arXiv:2303.03709v3 [cs.CV] UPDATED)\nAbstract: In this paper, considering the balance of data/model privacy of model owners and user needs, we propose a new setting called Back-Propagated Black-Box Adaptation (BPBA) for users to better train their private models via the guidance of the back-propagated results of a Black-box foundation/source model. Our setting can ease the usage of foundation/source models as well as prevent the leakage and misuse of foundation/source models. Moreover, we also propose a new training strategy called Bootstrap The Original Latent (BTOL) to fully utilize the foundation/source models. Our strategy consists of a domain adapter and a freeze-and-thaw strategy. We apply our BTOL under BPBA and Black-box UDA settings on three different datasets. Experiments show that our strategy is efficient and robust in various settings without manual augmentations.",
    "path": "papers/23/03/2303.03709.json",
    "total_tokens": 743,
    "translated_title": "Bootstrap The Original Latent: 从黑盒模型学习私有模型",
    "translated_abstract": "本文提出了一个称为Back-Propagated Black-Box Adaptation（BPBA）的新设置，以平衡模型所有者的数据/模型隐私和用户需求，为用户提供指导。该设置可以简化基础/源模型的使用，防止基础/源模型的泄漏和误用。此外，我们还提出了一种称为Bootstrap The Original Latent（BTOL）的新训练策略，以充分利用基础/源模型。我们的策略由领域适配器和冷冻-解冻策略组成。",
    "tldr": "本文提出了BPBA设置和BTOL训练策略两个新的方法，分别用于用户训练私有模型和利用基础/源模型。在三个不同的数据集上的实验表明，这些方法都是有效且稳健的。",
    "en_tdlr": "This paper proposes two new methods, BPBA setting and BTOL training strategy, for users to train private models and utilize foundation/source models respectively. Experiments on three different datasets demonstrate that these methods are efficient and robust."
}