{
    "title": "Client-specific Property Inference against Secure Aggregation in Federated Learning. (arXiv:2303.03908v2 [cs.CR] UPDATED)",
    "abstract": "Federated learning has become a widely used paradigm for collaboratively training a common model among different participants with the help of a central server that coordinates the training. Although only the model parameters or other model updates are exchanged during the federated training instead of the participant's data, many attacks have shown that it is still possible to infer sensitive information such as membership, property, or outright reconstruction of participant data. Although differential privacy is considered an effective solution to protect against privacy attacks, it is also criticized for its negative effect on utility. Another possible defense is to use secure aggregation which allows the server to only access the aggregated update instead of each individual one, and it is often more appealing because it does not degrade model quality. However, combining only the aggregated updates, which are generated by a different composition of clients in every round, may still ",
    "link": "http://arxiv.org/abs/2303.03908",
    "context": "Title: Client-specific Property Inference against Secure Aggregation in Federated Learning. (arXiv:2303.03908v2 [cs.CR] UPDATED)\nAbstract: Federated learning has become a widely used paradigm for collaboratively training a common model among different participants with the help of a central server that coordinates the training. Although only the model parameters or other model updates are exchanged during the federated training instead of the participant's data, many attacks have shown that it is still possible to infer sensitive information such as membership, property, or outright reconstruction of participant data. Although differential privacy is considered an effective solution to protect against privacy attacks, it is also criticized for its negative effect on utility. Another possible defense is to use secure aggregation which allows the server to only access the aggregated update instead of each individual one, and it is often more appealing because it does not degrade model quality. However, combining only the aggregated updates, which are generated by a different composition of clients in every round, may still ",
    "path": "papers/23/03/2303.03908.json",
    "total_tokens": 925,
    "translated_title": "针对联邦学习中安全聚合的客户特定属性推断",
    "translated_abstract": "联邦学习已成为一种广泛使用的范例，用于在不同参与者之间协作训练共同的模型，并通过协调训练的中央服务器进行协调。尽管在联邦训练期间仅交换模型参数或其他模型更新，而不是参与者的数据，但许多攻击表明仍然有可能推断出敏感信息，如成员身份、属性或参与者数据的完全重建。尽管差分隐私被认为是一种有效的保护隐私攻击的解决方案，但也因其对效用的负面影响而受到批评。另一个可能的防御是使用安全聚合，它允许服务器仅访问聚合的更新，而不是每个单独的更新，并且由于不会降低模型质量，因此更具吸引力。然而，仅仅结合由每轮中不同组合的客户生成的聚合更新可能仍然存在隐私泄露。",
    "tldr": "针对联邦学习中的安全聚合，本研究提出了一种针对客户特定属性推断的解决方案。目前的防御方法包括差分隐私和安全聚合，但它们都存在一定的缺陷。因此，本研究旨在提供一种更有效的保护隐私攻击的方法。"
}