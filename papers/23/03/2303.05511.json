{
    "title": "Scaling up GANs for Text-to-Image Synthesis. (arXiv:2303.05511v2 [cs.CV] UPDATED)",
    "abstract": "The recent success of text-to-image synthesis has taken the world by storm and captured the general public's imagination. From a technical standpoint, it also marked a drastic change in the favored architecture to design generative image models. GANs used to be the de facto choice, with techniques like StyleGAN. With DALL-E 2, auto-regressive and diffusion models became the new standard for large-scale generative models overnight. This rapid shift raises a fundamental question: can we scale up GANs to benefit from large datasets like LAION? We find that na\\\"Ively increasing the capacity of the StyleGAN architecture quickly becomes unstable. We introduce GigaGAN, a new GAN architecture that far exceeds this limit, demonstrating GANs as a viable option for text-to-image synthesis. GigaGAN offers three major advantages. First, it is orders of magnitude faster at inference time, taking only 0.13 seconds to synthesize a 512px image. Second, it can synthesize high-resolution images, for exam",
    "link": "http://arxiv.org/abs/2303.05511",
    "context": "Title: Scaling up GANs for Text-to-Image Synthesis. (arXiv:2303.05511v2 [cs.CV] UPDATED)\nAbstract: The recent success of text-to-image synthesis has taken the world by storm and captured the general public's imagination. From a technical standpoint, it also marked a drastic change in the favored architecture to design generative image models. GANs used to be the de facto choice, with techniques like StyleGAN. With DALL-E 2, auto-regressive and diffusion models became the new standard for large-scale generative models overnight. This rapid shift raises a fundamental question: can we scale up GANs to benefit from large datasets like LAION? We find that na\\\"Ively increasing the capacity of the StyleGAN architecture quickly becomes unstable. We introduce GigaGAN, a new GAN architecture that far exceeds this limit, demonstrating GANs as a viable option for text-to-image synthesis. GigaGAN offers three major advantages. First, it is orders of magnitude faster at inference time, taking only 0.13 seconds to synthesize a 512px image. Second, it can synthesize high-resolution images, for exam",
    "path": "papers/23/03/2303.05511.json",
    "total_tokens": 1118,
    "translated_title": "文本到图像合成的GAN扩展",
    "translated_abstract": "最近，文本到图像合成的成功引起了全球范围内的关注，并吸引了普通大众的想象力。从技术角度来看，它也标志着设计生成图像模型的优先架构发生了根本性变化。过去，GAN是事实上的选择，有着像StyleGAN这样的技术。然而，DALL-E2之后，自回归和扩散模型成为了大尺度生成模型的新标准。这个快速的转变引出了一个根本性问题：我们能否扩展GAN以从像LAION这样的大数据集中受益？我们发现，简单地增加StyleGAN架构的容量很快就会变得不稳定。我们介绍GigaGAN，这是一种新型的GAN架构，远远超过了这个限制，证明GAN是文本到图像合成的一个可行选项。GigaGAN提供了三个重要优势。首先，它的推理时间比之前快了几个数量级，只需要0.13秒即可合成512像素图像。其次，它可以合成高分辨率的图像，例如2048×2048，这是之前在该领域内GAN无法实现的。第三，GigaGAN允许更好地控制图像合成过程，使用户能够更精确地指定姿势、光照和背景等特征。",
    "tldr": "本研究介绍了GigaGAN，一种新型的GAN架构，远远超过之前使用的StyleGAN。GigaGAN具有三个重要优势：超快速的推理时间、高分辨率图像合成的能力和更精确的图像合成控制。这使GAN成为文本到图像合成的可行选项。",
    "en_tdlr": "This paper introduces GigaGAN, a new GAN architecture that far exceeds previous StyleGAN for text-to-image synthesis. GigaGAN offers three major advantages: super-fast inference time, the ability to synthesize high-resolution images, and more precise control over the image synthesis process, making GAN a feasible option for text-to-image synthesis."
}