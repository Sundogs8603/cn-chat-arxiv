{
    "title": "Set-the-Scene: Global-Local Training for Generating Controllable NeRF Scenes. (arXiv:2303.13450v1 [cs.CV])",
    "abstract": "Recent breakthroughs in text-guided image generation have led to remarkable progress in the field of 3D synthesis from text. By optimizing neural radiance fields (NeRF) directly from text, recent methods are able to produce remarkable results. Yet, these methods are limited in their control of each object's placement or appearance, as they represent the scene as a whole. This can be a major issue in scenarios that require refining or manipulating objects in the scene. To remedy this deficit, we propose a novel GlobalLocal training framework for synthesizing a 3D scene using object proxies. A proxy represents the object's placement in the generated scene and optionally defines its coarse geometry. The key to our approach is to represent each object as an independent NeRF. We alternate between optimizing each NeRF on its own and as part of the full scene. Thus, a complete representation of each object can be learned, while also creating a harmonious scene with style and lighting match. W",
    "link": "http://arxiv.org/abs/2303.13450",
    "context": "Title: Set-the-Scene: Global-Local Training for Generating Controllable NeRF Scenes. (arXiv:2303.13450v1 [cs.CV])\nAbstract: Recent breakthroughs in text-guided image generation have led to remarkable progress in the field of 3D synthesis from text. By optimizing neural radiance fields (NeRF) directly from text, recent methods are able to produce remarkable results. Yet, these methods are limited in their control of each object's placement or appearance, as they represent the scene as a whole. This can be a major issue in scenarios that require refining or manipulating objects in the scene. To remedy this deficit, we propose a novel GlobalLocal training framework for synthesizing a 3D scene using object proxies. A proxy represents the object's placement in the generated scene and optionally defines its coarse geometry. The key to our approach is to represent each object as an independent NeRF. We alternate between optimizing each NeRF on its own and as part of the full scene. Thus, a complete representation of each object can be learned, while also creating a harmonious scene with style and lighting match. W",
    "path": "papers/23/03/2303.13450.json",
    "total_tokens": 906,
    "translated_title": "Set-the-Scene: 全局-局部训练用于生成可控的 NeRF 场景",
    "translated_abstract": "近期在文本引导下的图像合成领域取得了重大突破，优化神经辐射场（NeRF）直接从文本中，最近的方法能够产生出色的结果。然而，这些方法在每个对象的放置或外观控制方面受到限制，因为它们代表整个场景。这在需要细化或操纵场景中的对象的情况下可能是一个重要问题。为了弥补这一不足，我们提出了一种新颖的全局-局部训练框架，使用对象代理合成 3D 场景。代理表示生成场景中对象的放置，并可选地定义其粗略几何形状。我们方法的关键在于将每个对象表示为独立的 NeRF。我们在优化每个 NeRF 自身和完整场景的组成部分之间交替进行。因此，可以学习到每个对象的完整表示，同时创建具有风格和照明匹配的和谐场景。",
    "tldr": "该论文提出了一个全局-局部训练框架，使用对象代理合成 3D 场景，将每个对象表示为独立的 NeRF，并交替优化，从而实现对每个对象的完整表示的学习。",
    "en_tdlr": "This paper proposes a GlobalLocal training framework for synthesizing a 3D scene using object proxies by representing each object as an independent NeRF and optimizing each NeRF alternately, allowing for learning the complete representation of each object in a harmonious scene."
}