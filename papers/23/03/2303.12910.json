{
    "title": "Cross-Layer Design for AI Acceleration with Non-Coherent Optical Computing. (arXiv:2303.12910v1 [cs.LG])",
    "abstract": "Emerging AI applications such as ChatGPT, graph convolutional networks, and other deep neural networks require massive computational resources for training and inference. Contemporary computing platforms such as CPUs, GPUs, and TPUs are struggling to keep up with the demands of these AI applications. Non-coherent optical computing represents a promising approach for light-speed acceleration of AI workloads. In this paper, we show how cross-layer design can overcome challenges in non-coherent optical computing platforms. We describe approaches for optical device engineering, tuning circuit enhancements, and architectural innovations to adapt optical computing to a variety of AI workloads. We also discuss techniques for hardware/software co-design that can intelligently map and adapt AI software to improve its performance on non-coherent optical computing platforms.",
    "link": "http://arxiv.org/abs/2303.12910",
    "context": "Title: Cross-Layer Design for AI Acceleration with Non-Coherent Optical Computing. (arXiv:2303.12910v1 [cs.LG])\nAbstract: Emerging AI applications such as ChatGPT, graph convolutional networks, and other deep neural networks require massive computational resources for training and inference. Contemporary computing platforms such as CPUs, GPUs, and TPUs are struggling to keep up with the demands of these AI applications. Non-coherent optical computing represents a promising approach for light-speed acceleration of AI workloads. In this paper, we show how cross-layer design can overcome challenges in non-coherent optical computing platforms. We describe approaches for optical device engineering, tuning circuit enhancements, and architectural innovations to adapt optical computing to a variety of AI workloads. We also discuss techniques for hardware/software co-design that can intelligently map and adapt AI software to improve its performance on non-coherent optical computing platforms.",
    "path": "papers/23/03/2303.12910.json",
    "total_tokens": 793,
    "translated_title": "基于非相干光计算的AI加速交叉层设计",
    "translated_abstract": "新兴的人工智能应用，如ChatGPT、图形卷积网络和其他深度神经网络，需要大量的计算资源进行训练和推理。当代计算平台，如CPU、GPU和TPU正在努力满足这些AI应用的需求。非相干光计算代表了一种有前途的方法，可以实现AI工作负载的光速加速。在本文中，我们展示了交叉层设计如何克服非相干光计算平台中存在的挑战。我们描述了光学器件工程、调谐电路增强以及架构创新的方法，以适应各种AI工作负载。我们还讨论了硬件/软件协同设计的技术，可以智能地映射和适应AI软件，以提高其在非相干光计算平台上的性能。",
    "tldr": "本文介绍了如何使用交叉层设计来克服非相干光计算平台中存在的挑战，适应多种类型的AI工作负载，从而实现高速的AI加速。",
    "en_tdlr": "This paper presents the use of cross-layer design to overcome challenges in non-coherent optical computing platforms and adapt to various types of AI workloads, enabling high-speed acceleration of AI."
}