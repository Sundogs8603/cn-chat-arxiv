{
    "title": "TQ-Net: Mixed Contrastive Representation Learning For Heterogeneous Test Questions. (arXiv:2303.08039v1 [cs.CL])",
    "abstract": "Recently, more and more people study online for the convenience of access to massive learning materials (e.g. test questions/notes), thus accurately understanding learning materials became a crucial issue, which is essential for many educational applications. Previous studies focus on using language models to represent the question data. However, test questions (TQ) are usually heterogeneous and multi-modal, e.g., some of them may only contain text, while others half contain images with information beyond their literal description. In this context, both supervised and unsupervised methods are difficult to learn a fused representation of questions. Meanwhile, this problem cannot be solved by conventional methods such as image caption, as the images may contain information complementary rather than duplicate to the text. In this paper, we first improve previous text-only representation with a two-stage unsupervised instance level contrastive based pre-training method (MCL: Mixture Unsupe",
    "link": "http://arxiv.org/abs/2303.08039",
    "context": "Title: TQ-Net: Mixed Contrastive Representation Learning For Heterogeneous Test Questions. (arXiv:2303.08039v1 [cs.CL])\nAbstract: Recently, more and more people study online for the convenience of access to massive learning materials (e.g. test questions/notes), thus accurately understanding learning materials became a crucial issue, which is essential for many educational applications. Previous studies focus on using language models to represent the question data. However, test questions (TQ) are usually heterogeneous and multi-modal, e.g., some of them may only contain text, while others half contain images with information beyond their literal description. In this context, both supervised and unsupervised methods are difficult to learn a fused representation of questions. Meanwhile, this problem cannot be solved by conventional methods such as image caption, as the images may contain information complementary rather than duplicate to the text. In this paper, we first improve previous text-only representation with a two-stage unsupervised instance level contrastive based pre-training method (MCL: Mixture Unsupe",
    "path": "papers/23/03/2303.08039.json",
    "total_tokens": 1028,
    "translated_title": "TQ-Net：混合对比表示学习用于异构测试问题的研究",
    "translated_abstract": "近年来，越来越多的人通过网络学习以便获取海量学习材料（例如测试问题/笔记），因此准确理解学习材料成为重要问题，对许多教育应用程序至关重要。先前的研究侧重于使用语言模型来表示问题数据。然而，测试问题（TQ）通常是异构的和多模式的，例如，一些问题仅包含文本，而另一些问题包含超出其文字描述的图像信息。在这种情况下，有监督和无监督方法都难以学习问题的融合表示。同时，传统方法如图像说明也无法解决这个问题，因为图像可能包含互补而不是复制的信息。本文首先通过两阶段的无监督实例级对比训练方法（MCL:混合无监督对比学习）改进了先前的单独文本表示。然后，我们提出了一种新颖的Mixed Contrastive Learning（MCL2）方法，其中融合了图像和文本模态，采用多实例和多级特征融合用于TQ表示学习。在两个TQ数据集上的实验结果表明，我们提出的方法优于几个最先进的基线，并在TQ分类和问题类型预测方面取得了更好的结果。",
    "tldr": "本文研究了一种混合对比表示学习方法（MCL2）用于异构测试问题的表示学习，与现有的文本表示方法相比具有更好的效果。",
    "en_tdlr": "This paper proposes a mixed contrastive learning method (MCL2) for heterogeneous test question representation learning, which outperforms existing text-only representation methods."
}