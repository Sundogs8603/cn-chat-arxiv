{
    "title": "ChatGPT Outperforms Crowd-Workers for Text-Annotation Tasks. (arXiv:2303.15056v2 [cs.CL] UPDATED)",
    "abstract": "Many NLP applications require manual data annotations for a variety of tasks, notably to train classifiers or evaluate the performance of unsupervised models. Depending on the size and degree of complexity, the tasks may be conducted by crowd-workers on platforms such as MTurk as well as trained annotators, such as research assistants. Using a sample of 2,382 tweets, we demonstrate that ChatGPT outperforms crowd-workers for several annotation tasks, including relevance, stance, topics, and frames detection. Specifically, the zero-shot accuracy of ChatGPT exceeds that of crowd-workers for four out of five tasks, while ChatGPT's intercoder agreement exceeds that of both crowd-workers and trained annotators for all tasks. Moreover, the per-annotation cost of ChatGPT is less than $0.003 -- about twenty times cheaper than MTurk. These results show the potential of large language models to drastically increase the efficiency of text classification.",
    "link": "http://arxiv.org/abs/2303.15056",
    "context": "Title: ChatGPT Outperforms Crowd-Workers for Text-Annotation Tasks. (arXiv:2303.15056v2 [cs.CL] UPDATED)\nAbstract: Many NLP applications require manual data annotations for a variety of tasks, notably to train classifiers or evaluate the performance of unsupervised models. Depending on the size and degree of complexity, the tasks may be conducted by crowd-workers on platforms such as MTurk as well as trained annotators, such as research assistants. Using a sample of 2,382 tweets, we demonstrate that ChatGPT outperforms crowd-workers for several annotation tasks, including relevance, stance, topics, and frames detection. Specifically, the zero-shot accuracy of ChatGPT exceeds that of crowd-workers for four out of five tasks, while ChatGPT's intercoder agreement exceeds that of both crowd-workers and trained annotators for all tasks. Moreover, the per-annotation cost of ChatGPT is less than $0.003 -- about twenty times cheaper than MTurk. These results show the potential of large language models to drastically increase the efficiency of text classification.",
    "path": "papers/23/03/2303.15056.json",
    "total_tokens": 1015,
    "translated_title": "ChatGPT在文本标注任务中表现优于众包工作者",
    "translated_abstract": "许多自然语言处理应用需要手动进行数据标注以进行各种任务，特别是用于训练分类器或评估无监督模型的性能。根据任务的规模和复杂程度，这些任务可以由众包工作者在MTurk等平台上进行，也可以由受过训练的注释者（如研究助理）进行。通过使用2382条推文的样本，我们证明了ChatGPT在多个标注任务中的表现优于众包工作者，包括相关性、态度、主题和框架检测。具体而言，ChatGPT的零样本准确率在五个任务中有四个超过了众包工作者，而ChatGPT的编码者间一致性在所有任务中均超过了众包工作者和受过训练的注释者。此外，ChatGPT的标注成本不到0.003美元，比MTurk便宜20倍左右。这些结果显示了大型语言模型极大地提高了文本分类的效率的潜力。",
    "tldr": "ChatGPT在文本标注任务中表现优于众包工作者，包括相关性、态度、主题和框架检测任务。ChatGPT的零样本准确率超越众包工作者四个任务，编码者间一致性在所有任务中均超过众包工作者和受过训练的注释者。此外，ChatGPT的标注成本比MTurk便宜20倍左右，显示了大型语言模型提高文本分类效率的潜力。"
}