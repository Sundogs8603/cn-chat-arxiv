{
    "title": "Learning Human-Inspired Force Strategies for Robotic Assembly. (arXiv:2303.12440v1 [cs.RO])",
    "abstract": "The programming of robotic assembly tasks is a key component in manufacturing and automation. Force-sensitive assembly, however, often requires reactive strategies to handle slight changes in positioning and unforeseen part jamming. Learning such strategies from human performance is a promising approach, but faces two common challenges: the handling of low part clearances which is difficult to capture from demonstrations and learning intuitive strategies offline without access to the real hardware. We address these two challenges by learning probabilistic force strategies from data that are easily acquired offline in a robot-less simulation from human demonstrations with a joystick. We combine a Long Short Term Memory (LSTM) and a Mixture Density Network (MDN) to model human-inspired behavior in such a way that the learned strategies transfer easily onto real hardware. The experiments show a UR10e robot that completes a plastic assembly with clearances of less than 100 micrometers whos",
    "link": "http://arxiv.org/abs/2303.12440",
    "context": "Title: Learning Human-Inspired Force Strategies for Robotic Assembly. (arXiv:2303.12440v1 [cs.RO])\nAbstract: The programming of robotic assembly tasks is a key component in manufacturing and automation. Force-sensitive assembly, however, often requires reactive strategies to handle slight changes in positioning and unforeseen part jamming. Learning such strategies from human performance is a promising approach, but faces two common challenges: the handling of low part clearances which is difficult to capture from demonstrations and learning intuitive strategies offline without access to the real hardware. We address these two challenges by learning probabilistic force strategies from data that are easily acquired offline in a robot-less simulation from human demonstrations with a joystick. We combine a Long Short Term Memory (LSTM) and a Mixture Density Network (MDN) to model human-inspired behavior in such a way that the learned strategies transfer easily onto real hardware. The experiments show a UR10e robot that completes a plastic assembly with clearances of less than 100 micrometers whos",
    "path": "papers/23/03/2303.12440.json",
    "total_tokens": 935,
    "translated_title": "学习人类启发的力策略用于机器人组装",
    "translated_abstract": "机器人组装任务的编程是制造业和自动化的重要组成部分。然而，对于具有力敏感属性的组装，常常需要反应性策略来处理微小的位置变化和意外的零件卡死。从人类表现中学习这样的策略是一种有前途的方法，但面临两个常见的挑战：处理低部分间隙的难度很大，难以从演示中获取，并学习直观的策略，而无需在离线状态下访问真实硬件。我们通过从操纵杆的人类演示中在没有机器人的模拟环境中轻松获取的数据中学习概率力策略来解决这两个挑战。我们结合了长短期记忆（LSTM）和混合密度网络（MDN）来模拟人类启发式行为，使学习的策略易于转移到真实硬件上。实验表明，UR10e机器人可以完成塑料组装任务，其间隙小于100微米。",
    "tldr": "该论文展示了通过从人类示范中学习概率力策略的方法，以便在机器人组装任务中对低零件间隙和位置变化做出反应，解决了从离线模拟数据学习策略无法直接在线应用的问题。",
    "en_tdlr": "This paper presents a promising approach of learning probabilistic force strategies from human demonstrations to handle low part clearances and position changes in robotic assembly tasks, which overcomes the challenge of offline learning without direct online adaptation to real hardware. The learned strategies are modeled with LSTM and MDN, and demonstrated to transfer easily onto real hardware in experiments."
}