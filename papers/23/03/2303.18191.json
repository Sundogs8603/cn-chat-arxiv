{
    "title": "Detecting Backdoors During the Inference Stage Based on Corruption Robustness Consistency. (arXiv:2303.18191v1 [cs.CR])",
    "abstract": "Deep neural networks are proven to be vulnerable to backdoor attacks. Detecting the trigger samples during the inference stage, i.e., the test-time trigger sample detection, can prevent the backdoor from being triggered. However, existing detection methods often require the defenders to have high accessibility to victim models, extra clean data, or knowledge about the appearance of backdoor triggers, limiting their practicality. In this paper, we propose the test-time corruption robustness consistency evaluation (TeCo), a novel test-time trigger sample detection method that only needs the hard-label outputs of the victim models without any extra information. Our journey begins with the intriguing observation that the backdoor-infected models have similar performance across different image corruptions for the clean images, but perform discrepantly for the trigger samples. Based on this phenomenon, we design TeCo to evaluate test-time robustness consistency by calculating the deviation o",
    "link": "http://arxiv.org/abs/2303.18191",
    "context": "Title: Detecting Backdoors During the Inference Stage Based on Corruption Robustness Consistency. (arXiv:2303.18191v1 [cs.CR])\nAbstract: Deep neural networks are proven to be vulnerable to backdoor attacks. Detecting the trigger samples during the inference stage, i.e., the test-time trigger sample detection, can prevent the backdoor from being triggered. However, existing detection methods often require the defenders to have high accessibility to victim models, extra clean data, or knowledge about the appearance of backdoor triggers, limiting their practicality. In this paper, we propose the test-time corruption robustness consistency evaluation (TeCo), a novel test-time trigger sample detection method that only needs the hard-label outputs of the victim models without any extra information. Our journey begins with the intriguing observation that the backdoor-infected models have similar performance across different image corruptions for the clean images, but perform discrepantly for the trigger samples. Based on this phenomenon, we design TeCo to evaluate test-time robustness consistency by calculating the deviation o",
    "path": "papers/23/03/2303.18191.json",
    "total_tokens": 907,
    "translated_title": "基于破坏鲁棒性一致性的推理阶段后门检测",
    "translated_abstract": "深度神经网络被证明容易受到后门攻击。在推理阶段检测触发样本，即测试时间触发样本检测，可以防止后门被触发。然而，现有的检测方法通常需要防御者对受害模型具有高度可访问性、额外的清洁数据或了解后门触发器的外观知识等，限制了它们的实用性。本文提出了一种新的测试时间触发样本检测方法 TeCo，该方法只需要受害模型的硬标签输出，不需要任何额外的信息。我们的研究从一项有趣的观察开始，即被感染的后门模型在对于干净图像的不同图像破坏方面具有相似的性能，但对于触发样本表现不一致。基于这一现象，我们设计了 TeCo 来评估测试时间鲁棒性一致性，通过计算预测结果的偏差来进行检测。",
    "tldr": "本文提出了一种新的测试时间触发样本检测方法 TeCo，该方法只需要受害模型的硬标签输出，通过评估测试时间鲁棒性一致性来检测后门，不需要其他额外的信息，提高了实用性。",
    "en_tdlr": "This paper proposes a novel test-time trigger sample detection method TeCo, which only needs the hard-label outputs of the victim models and evaluates the test-time robustness consistency to detect backdoors without any extra information, improving practicality."
}