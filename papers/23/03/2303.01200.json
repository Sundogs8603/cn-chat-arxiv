{
    "title": "Retrieval for Extremely Long Queries and Documents with RPRS: a Highly Efficient and Effective Transformer-based Re-Ranker. (arXiv:2303.01200v2 [cs.IR] UPDATED)",
    "abstract": "Retrieval with extremely long queries and documents is a well-known and challenging task in information retrieval and is commonly known as Query-by-Document (QBD) retrieval. Specifically designed Transformer models that can handle long input sequences have not shown high effectiveness in QBD tasks in previous work. We propose a Re-Ranker based on the novel Proportional Relevance Score (RPRS) to compute the relevance score between a query and the top-k candidate documents. Our extensive evaluation shows RPRS obtains significantly better results than the state-of-the-art models on five different datasets. Furthermore, RPRS is highly efficient since all documents can be pre-processed, embedded, and indexed before query time which gives our re-ranker the advantage of having a complexity of O(N) where N is the total number of sentences in the query and candidate documents. Furthermore, our method solves the problem of the low-resource training in QBD retrieval tasks as it does not need larg",
    "link": "http://arxiv.org/abs/2303.01200",
    "context": "Title: Retrieval for Extremely Long Queries and Documents with RPRS: a Highly Efficient and Effective Transformer-based Re-Ranker. (arXiv:2303.01200v2 [cs.IR] UPDATED)\nAbstract: Retrieval with extremely long queries and documents is a well-known and challenging task in information retrieval and is commonly known as Query-by-Document (QBD) retrieval. Specifically designed Transformer models that can handle long input sequences have not shown high effectiveness in QBD tasks in previous work. We propose a Re-Ranker based on the novel Proportional Relevance Score (RPRS) to compute the relevance score between a query and the top-k candidate documents. Our extensive evaluation shows RPRS obtains significantly better results than the state-of-the-art models on five different datasets. Furthermore, RPRS is highly efficient since all documents can be pre-processed, embedded, and indexed before query time which gives our re-ranker the advantage of having a complexity of O(N) where N is the total number of sentences in the query and candidate documents. Furthermore, our method solves the problem of the low-resource training in QBD retrieval tasks as it does not need larg",
    "path": "papers/23/03/2303.01200.json",
    "total_tokens": 993,
    "translated_title": "使用RPRS的高效有效的基于Transformer的重新排序器处理极长查询和文档的检索",
    "translated_abstract": "在信息检索中，使用极长查询和文档进行检索是一个众所周知且具有挑战性的任务，通常称为查询-文档（QBD）检索。先前的工作中，专门设计用于处理长输入序列的Transformer模型在QBD任务中并没有展现出很高的效果。我们提出了一种基于新型比例相关度分数（RPRS）的重新排序器，用于计算查询与前k个候选文档之间的相关度分数。我们进行了广泛的评估，结果显示RPRS在五个不同数据集上比现有模型取得了显著更好的结果。此外，RPRS非常高效，因为在查询时间之前可以对所有文档进行预处理、嵌入和索引，使得我们的重新排序器具有O(N)的复杂度，其中N是查询和候选文档中句子的总数。此外，我们的方法解决了QBD检索任务中低资源训练的问题，因为它不需要大量的训练数据。",
    "tldr": "该论文提出了一种基于新型比例相关度分数（RPRS）的高效有效的基于Transformer的重新排序器，用于处理极长查询和文档的检索任务。与先前的工作相比，在五个不同数据集上进行的广泛评估显示RPRS获得了显著更好的结果。此外，RPRS具有高效性，并且解决了QBD检索任务中低资源训练的问题。",
    "en_tdlr": "This paper proposes a highly efficient and effective Transformer-based re-ranker, using the novel Proportional Relevance Score (RPRS), for retrieval of extremely long queries and documents. Extensive evaluation on five different datasets shows that RPRS outperforms state-of-the-art models. Additionally, RPRS is highly efficient and addresses the issue of low-resource training in Query-by-Document (QBD) retrieval tasks."
}