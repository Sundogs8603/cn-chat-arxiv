{
    "title": "ContraSim -- A Similarity Measure Based on Contrastive Learning. (arXiv:2303.16992v1 [cs.CL])",
    "abstract": "Recent work has compared neural network representations via similarity-based analyses, shedding light on how different aspects (architecture, training data, etc.) affect models' internal representations. The quality of a similarity measure is typically evaluated by its success in assigning a high score to representations that are expected to be matched. However, existing similarity measures perform mediocrely on standard benchmarks. In this work, we develop a new similarity measure, dubbed ContraSim, based on contrastive learning. In contrast to common closed-form similarity measures, ContraSim learns a parameterized measure by using both similar and dissimilar examples. We perform an extensive experimental evaluation of our method, with both language and vision models, on the standard layer prediction benchmark and two new benchmarks that we introduce: the multilingual benchmark and the image-caption benchmark. In all cases, ContraSim achieves much higher accuracy than previous simila",
    "link": "http://arxiv.org/abs/2303.16992",
    "context": "Title: ContraSim -- A Similarity Measure Based on Contrastive Learning. (arXiv:2303.16992v1 [cs.CL])\nAbstract: Recent work has compared neural network representations via similarity-based analyses, shedding light on how different aspects (architecture, training data, etc.) affect models' internal representations. The quality of a similarity measure is typically evaluated by its success in assigning a high score to representations that are expected to be matched. However, existing similarity measures perform mediocrely on standard benchmarks. In this work, we develop a new similarity measure, dubbed ContraSim, based on contrastive learning. In contrast to common closed-form similarity measures, ContraSim learns a parameterized measure by using both similar and dissimilar examples. We perform an extensive experimental evaluation of our method, with both language and vision models, on the standard layer prediction benchmark and two new benchmarks that we introduce: the multilingual benchmark and the image-caption benchmark. In all cases, ContraSim achieves much higher accuracy than previous simila",
    "path": "papers/23/03/2303.16992.json",
    "total_tokens": 883,
    "translated_title": "ContraSim -- 基于对比学习的相似度度量方法",
    "translated_abstract": "最近有研究通过基于相似性的分析比较神经网络表示，揭示了不同方面（如架构、训练数据等）如何影响模型的内部表示。相似度量的质量通常通过其在预期匹配的表示中分配高分数的成功来评估。然而，现有的相似度量在标准基准测试中表现平庸。本文提出一种新的相似度度量方法，称为ContraSim，基于对比学习，与常见的闭式相似性度量不同，ContraSim使用相似和不相似的示例来学习参数化的度量方法。我们在标准的图层预测基准测试和我们介绍的两个新基准测试中使用语言和视觉模型进行广泛的实验评估：多语言基准测试和图像字幕基准测试。在所有情况下，ContraSim的准确性都比之前的相似度量方法高得多。",
    "tldr": "本文提出了一种新的相似度度量方法: ContraSim，该方法利用对比学习学习参数化的度量方法。实验表明，ContraSim在多种基准测试中均获得了比之前相似度量方法更高的准确性。",
    "en_tdlr": "The paper proposes a new similarity measure based on contrastive learning, dubbed ContraSim. The method learns a parameterized measure by using both similar and dissimilar examples. Experimental results show that ContraSim outperforms previous similarity measures in multiple benchmarks."
}