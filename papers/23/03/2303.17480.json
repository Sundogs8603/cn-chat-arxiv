{
    "title": "Seeing What You Said: Talking Face Generation Guided by a Lip Reading Expert. (arXiv:2303.17480v1 [cs.CV])",
    "abstract": "Talking face generation, also known as speech-to-lip generation, reconstructs facial motions concerning lips given coherent speech input. The previous studies revealed the importance of lip-speech synchronization and visual quality. Despite much progress, they hardly focus on the content of lip movements i.e., the visual intelligibility of the spoken words, which is an important aspect of generation quality. To address the problem, we propose using a lip-reading expert to improve the intelligibility of the generated lip regions by penalizing the incorrect generation results. Moreover, to compensate for data scarcity, we train the lip-reading expert in an audio-visual self-supervised manner. With a lip-reading expert, we propose a novel contrastive learning to enhance lip-speech synchronization, and a transformer to encode audio synchronically with video, while considering global temporal dependency of audio. For evaluation, we propose a new strategy with two different lip-reading exper",
    "link": "http://arxiv.org/abs/2303.17480",
    "context": "Title: Seeing What You Said: Talking Face Generation Guided by a Lip Reading Expert. (arXiv:2303.17480v1 [cs.CV])\nAbstract: Talking face generation, also known as speech-to-lip generation, reconstructs facial motions concerning lips given coherent speech input. The previous studies revealed the importance of lip-speech synchronization and visual quality. Despite much progress, they hardly focus on the content of lip movements i.e., the visual intelligibility of the spoken words, which is an important aspect of generation quality. To address the problem, we propose using a lip-reading expert to improve the intelligibility of the generated lip regions by penalizing the incorrect generation results. Moreover, to compensate for data scarcity, we train the lip-reading expert in an audio-visual self-supervised manner. With a lip-reading expert, we propose a novel contrastive learning to enhance lip-speech synchronization, and a transformer to encode audio synchronically with video, while considering global temporal dependency of audio. For evaluation, we propose a new strategy with two different lip-reading exper",
    "path": "papers/23/03/2303.17480.json",
    "total_tokens": 1095,
    "translated_title": "看着你说话：由口读专家引导的说话人脸生成",
    "translated_abstract": "说话人脸生成，也称为语音到唇部生成，是 reconstructs 面部动作，特别是唇部运动，给定一致的语音输入。之前的研究揭示了唇语同步性和视觉质量的重要性。尽管取得了很多进展，但他们很难集中于唇部运动的内容，即所说单词的视觉明晰度，这是生成质量的重要方面。为了解决这个问题，我们提出使用口读专家通过惩罚不正确的生成结果来提高生成唇部区域的清晰度。此外，为了弥补数据稀缺性，我们在音频 - 视觉自我监督的方式下训练口读专家。使用口读专家，我们提出了一种新颖的对比学习方法来增强唇语同步性，并使用变压器来同步编码音频和视频，同时考虑到音频的全局时序依赖关系。为了评估，我们提出了一种新的策略，使用两个不同的口读专家来评估生成的唇部运动的视觉明晰度。实验结果表明，我们的方法提高了生成面孔的视觉质量和明晰度，在主观和客观评估中均优于现有技术。",
    "tldr": "本文提出了一种使用口读专家引导的说话人脸生成方法，通过惩罚不正确的生成结果来提高生成唇部区域的明晰度，使用对比学习方法增强唇语同步性，并使用变压器来同步编码音频和视频。实验证明此方法在视觉质量和明晰度方面具有优势。",
    "en_tdlr": "This paper proposes a talking face generation method guided by a lip-reading expert, which penalizes incorrect generation results to improve the intelligibility of the generated lip regions, enhances lip-speech synchronization with contrastive learning, and synchronically encodes audio and video with a transformer. Experiments show that this method outperforms the state-of-the-art methods in terms of visual quality and intelligibility."
}