{
    "title": "Does ChatGPT resemble humans in language use?. (arXiv:2303.08014v1 [cs.CL])",
    "abstract": "Large language models (LLMs) and LLM-driven chatbots such as ChatGPT have shown remarkable capacities in comprehending and producing language. However, their internal workings remain a black box in cognitive terms, and it is unclear whether LLMs and chatbots can develop humanlike characteristics in language use. Cognitive scientists have devised many experiments that probe, and have made great progress in explaining, how people process language. We subjected ChatGPT to 12 of these experiments, pre-registered and with 1,000 runs per experiment. In 10 of them, ChatGPT replicated the human pattern of language use. It associated unfamiliar words with different meanings depending on their forms, continued to access recently encountered meanings of ambiguous words, reused recent sentence structures, reinterpreted implausible sentences that were likely to have been corrupted by noise, glossed over errors, drew reasonable inferences, associated causality with different discourse entities accor",
    "link": "http://arxiv.org/abs/2303.08014",
    "context": "Title: Does ChatGPT resemble humans in language use?. (arXiv:2303.08014v1 [cs.CL])\nAbstract: Large language models (LLMs) and LLM-driven chatbots such as ChatGPT have shown remarkable capacities in comprehending and producing language. However, their internal workings remain a black box in cognitive terms, and it is unclear whether LLMs and chatbots can develop humanlike characteristics in language use. Cognitive scientists have devised many experiments that probe, and have made great progress in explaining, how people process language. We subjected ChatGPT to 12 of these experiments, pre-registered and with 1,000 runs per experiment. In 10 of them, ChatGPT replicated the human pattern of language use. It associated unfamiliar words with different meanings depending on their forms, continued to access recently encountered meanings of ambiguous words, reused recent sentence structures, reinterpreted implausible sentences that were likely to have been corrupted by noise, glossed over errors, drew reasonable inferences, associated causality with different discourse entities accor",
    "path": "papers/23/03/2303.08014.json",
    "total_tokens": 967,
    "translated_title": "ChatGPT是否和人类在语言使用上相似?",
    "translated_abstract": "大型语言模型(LLM)和以LLM为驱动的聊天机器人(如ChatGPT)在理解和生成语言方面表现出色。然而，在认知层面上，它们的内部机制仍然是黑匣子，不清楚LLM和聊天机器人是否能够发展出人类的语言使用特征。我们对ChatGPT进行了12个实验，每个实验注册前进行了1000次运行。在其中的10个实验中，ChatGPT复制了人类语言使用的模式。它将不熟悉的单词与不同的含义进行关联，根据单词形式继续访问最近遇到的歧义词汇的含义，重用最近的语句结构，重新解释可能被噪声干扰的不合理语句，忽略错误，进行合理推断，根据它们的顺序和接近程度将因果关系与不同的话语实体相关联，并实时更正一致性错误。然而，在两个实验中，ChatGPT显示出与人类表现的偏差，这表明人类和机器语言处理之间仍存在重大差异。",
    "tldr": "ChatGPT在大部分语言处理实验中与人类表现相似，能够产生人类一样的语言使用特征。但在两个实验中存在偏差，说明人类和机器语言处理之间仍存在重大差异。"
}