{
    "title": "Watch or Listen: Robust Audio-Visual Speech Recognition with Visual Corruption Modeling and Reliability Scoring. (arXiv:2303.08536v1 [cs.MM])",
    "abstract": "This paper deals with Audio-Visual Speech Recognition (AVSR) under multimodal input corruption situations where audio inputs and visual inputs are both corrupted, which is not well addressed in previous research directions. Previous studies have focused on how to complement the corrupted audio inputs with the clean visual inputs with the assumption of the availability of clean visual inputs. However, in real life, clean visual inputs are not always accessible and can even be corrupted by occluded lip regions or noises. Thus, we firstly analyze that the previous AVSR models are not indeed robust to the corruption of multimodal input streams, the audio and the visual inputs, compared to uni-modal models. Then, we design multimodal input corruption modeling to develop robust AVSR models. Lastly, we propose a novel AVSR framework, namely Audio-Visual Reliability Scoring module (AV-RelScore), that is robust to the corrupted multimodal inputs. The AV-RelScore can determine which input modal ",
    "link": "http://arxiv.org/abs/2303.08536",
    "context": "Title: Watch or Listen: Robust Audio-Visual Speech Recognition with Visual Corruption Modeling and Reliability Scoring. (arXiv:2303.08536v1 [cs.MM])\nAbstract: This paper deals with Audio-Visual Speech Recognition (AVSR) under multimodal input corruption situations where audio inputs and visual inputs are both corrupted, which is not well addressed in previous research directions. Previous studies have focused on how to complement the corrupted audio inputs with the clean visual inputs with the assumption of the availability of clean visual inputs. However, in real life, clean visual inputs are not always accessible and can even be corrupted by occluded lip regions or noises. Thus, we firstly analyze that the previous AVSR models are not indeed robust to the corruption of multimodal input streams, the audio and the visual inputs, compared to uni-modal models. Then, we design multimodal input corruption modeling to develop robust AVSR models. Lastly, we propose a novel AVSR framework, namely Audio-Visual Reliability Scoring module (AV-RelScore), that is robust to the corrupted multimodal inputs. The AV-RelScore can determine which input modal ",
    "path": "papers/23/03/2303.08536.json",
    "total_tokens": 966,
    "translated_title": "观看或听取：具有视觉损坏建模和可靠性评分的强韧音视频语音识别",
    "translated_abstract": "本文针对音视频语音识别（AVSR）在多模态输入损坏情况下进行研究，其中音频输入和视觉输入均受损，这在先前的研究方向中没有得到很好的解决。先前的研究集中于如何用清晰的视觉输入来补充受损的音频输入，假设可用清晰的视觉输入，但在现实生活中，清晰的视觉输入并不总是可用的，甚至可能被遮挡的唇部区域或噪音所损坏。",
    "tldr": "本论文研究了音视频语音识别在多模态输入损坏情况下的问题，并设计了音视频可靠性评分模块来提高模型的韧性。",
    "en_tdlr": "This paper addresses the issue of Audio-Visual Speech Recognition (AVSR) under multimodal input corruption situations, where both audio and visual inputs are corrupted. The proposed Audio-Visual Reliability Scoring module (AV-RelScore) improves the robustness of AVSR models by determining the reliability of the input modalities."
}