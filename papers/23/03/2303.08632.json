{
    "title": "Pixel-Level Explanation of Multiple Instance Learning Models in Biomedical Single Cell Images. (arXiv:2303.08632v1 [eess.IV])",
    "abstract": "Explainability is a key requirement for computer-aided diagnosis systems in clinical decision-making. Multiple instance learning with attention pooling provides instance-level explainability, however for many clinical applications a deeper, pixel-level explanation is desirable, but missing so far. In this work, we investigate the use of four attribution methods to explain a multiple instance learning models: GradCAM, Layer-Wise Relevance Propagation (LRP), Information Bottleneck Attribution (IBA), and InputIBA. With this collection of methods, we can derive pixel-level explanations on for the task of diagnosing blood cancer from patients' blood smears. We study two datasets of acute myeloid leukemia with over 100 000 single cell images and observe how each attribution method performs on the multiple instance learning architecture focusing on different properties of the white blood single cells. Additionally, we compare attribution maps with the annotations of a medical expert to see ho",
    "link": "http://arxiv.org/abs/2303.08632",
    "context": "Title: Pixel-Level Explanation of Multiple Instance Learning Models in Biomedical Single Cell Images. (arXiv:2303.08632v1 [eess.IV])\nAbstract: Explainability is a key requirement for computer-aided diagnosis systems in clinical decision-making. Multiple instance learning with attention pooling provides instance-level explainability, however for many clinical applications a deeper, pixel-level explanation is desirable, but missing so far. In this work, we investigate the use of four attribution methods to explain a multiple instance learning models: GradCAM, Layer-Wise Relevance Propagation (LRP), Information Bottleneck Attribution (IBA), and InputIBA. With this collection of methods, we can derive pixel-level explanations on for the task of diagnosing blood cancer from patients' blood smears. We study two datasets of acute myeloid leukemia with over 100 000 single cell images and observe how each attribution method performs on the multiple instance learning architecture focusing on different properties of the white blood single cells. Additionally, we compare attribution maps with the annotations of a medical expert to see ho",
    "path": "papers/23/03/2303.08632.json",
    "total_tokens": 843,
    "translated_title": "医学单细胞图像多实例学习模型的像素级解释",
    "translated_abstract": "解释性是临床决策支持系统关键要求。多实例学习提供实例级解释，但许多临床应用需要更深入的像素级解释，但迄今为止尚未实现。本文研究了四种属性方法，即GradCAM、LRP、IBA和InputIBA，以解释多实例学习模型。通过这些方法，我们可以从患者的血液涂片中推导出像素级别的血癌诊断解释。我们研究了两组急性髓性白血病数据集，其中包含超过100,000个单个细胞图像，并观察每种属性方法在关注白细胞单个细胞的不同属性的多实例学习架构上的表现。此外，我们将属性图与医学专家的注释进行比较，以了解四种属性方法的效果。",
    "tldr": "本文研究了四种属性方法来解释医学单细胞图像多实例学习模型，并在血癌患者的血液涂片中推导出像素级别的血癌诊断解释。"
}