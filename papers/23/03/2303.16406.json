{
    "title": "Hierarchical Video-Moment Retrieval and Step-Captioning. (arXiv:2303.16406v1 [cs.CV])",
    "abstract": "There is growing interest in searching for information from large video corpora. Prior works have studied relevant tasks, such as text-based video retrieval, moment retrieval, video summarization, and video captioning in isolation, without an end-to-end setup that can jointly search from video corpora and generate summaries. Such an end-to-end setup would allow for many interesting applications, e.g., a text-based search that finds a relevant video from a video corpus, extracts the most relevant moment from that video, and segments the moment into important steps with captions. To address this, we present the HiREST (HIerarchical REtrieval and STep-captioning) dataset and propose a new benchmark that covers hierarchical information retrieval and visual/textual stepwise summarization from an instructional video corpus. HiREST consists of 3.4K text-video pairs from an instructional video dataset, where 1.1K videos have annotations of moment spans relevant to text query and breakdown of e",
    "link": "http://arxiv.org/abs/2303.16406",
    "context": "Title: Hierarchical Video-Moment Retrieval and Step-Captioning. (arXiv:2303.16406v1 [cs.CV])\nAbstract: There is growing interest in searching for information from large video corpora. Prior works have studied relevant tasks, such as text-based video retrieval, moment retrieval, video summarization, and video captioning in isolation, without an end-to-end setup that can jointly search from video corpora and generate summaries. Such an end-to-end setup would allow for many interesting applications, e.g., a text-based search that finds a relevant video from a video corpus, extracts the most relevant moment from that video, and segments the moment into important steps with captions. To address this, we present the HiREST (HIerarchical REtrieval and STep-captioning) dataset and propose a new benchmark that covers hierarchical information retrieval and visual/textual stepwise summarization from an instructional video corpus. HiREST consists of 3.4K text-video pairs from an instructional video dataset, where 1.1K videos have annotations of moment spans relevant to text query and breakdown of e",
    "path": "papers/23/03/2303.16406.json",
    "total_tokens": 898,
    "translated_title": "层次化视频瞬间检索和分步字幕",
    "translated_abstract": "目前人们在寻找大型视频语料库中的信息方面越来越感兴趣。先前的工作独立研究了相关任务，如基于文本的视频检索、瞬间检索、视频摘要和视频字幕，没有一个端到端的设置可以共同搜索视频语料库，并生成摘要。这样的端到端设置将允许许多有趣的应用程序，例如基于文本的搜索，从视频语料库中找到相关的视频，提取最相关的瞬间，并将瞬间分成重要的步骤，并加上字幕。为了解决这个问题，我们提出了HiREST(Hierarchical REtrieval and STep-captioning)数据集，并提出了一个新的基准，涵盖了来自教学视频语料库的分层信息检索和视觉/文本分阶段总结。HiREST由来自教学视频数据集的3.4K个文本-视频对组成，其中1.1K个视频具有与文本查询相关的瞬间跨度注释和细分。",
    "tldr": "这篇论文提出了HiREST数据集和一个新的基准，将分层信息检索和视觉/文本逐步总结从教学视频语料库中推广，使得在一个端到端的设置下可以共同搜索视频语料库，并生成摘要。",
    "en_tdlr": "This paper proposes the HiREST dataset and a new benchmark that extends hierarchical information retrieval and visual/textual stepwise summarization from an instructional video corpus, allowing for an end-to-end setup that can jointly search from video corpora and generate summaries."
}