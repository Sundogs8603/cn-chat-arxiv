{
    "title": "MS-MT: Multi-Scale Mean Teacher with Contrastive Unpaired Translation for Cross-Modality Vestibular Schwannoma and Cochlea Segmentation. (arXiv:2303.15826v1 [eess.IV])",
    "abstract": "Domain shift has been a long-standing issue for medical image segmentation. Recently, unsupervised domain adaptation (UDA) methods have achieved promising cross-modality segmentation performance by distilling knowledge from a label-rich source domain to a target domain without labels. In this work, we propose a multi-scale self-ensembling based UDA framework for automatic segmentation of two key brain structures i.e., Vestibular Schwannoma (VS) and Cochlea on high-resolution T2 images. First, a segmentation-enhanced contrastive unpaired image translation module is designed for image-level domain adaptation from source T1 to target T2. Next, multi-scale deep supervision and consistency regularization are introduced to a mean teacher network for self-ensemble learning to further close the domain gap. Furthermore, self-training and intensity augmentation techniques are utilized to mitigate label scarcity and boost cross-modality segmentation performance. Our method demonstrates promising ",
    "link": "http://arxiv.org/abs/2303.15826",
    "context": "Title: MS-MT: Multi-Scale Mean Teacher with Contrastive Unpaired Translation for Cross-Modality Vestibular Schwannoma and Cochlea Segmentation. (arXiv:2303.15826v1 [eess.IV])\nAbstract: Domain shift has been a long-standing issue for medical image segmentation. Recently, unsupervised domain adaptation (UDA) methods have achieved promising cross-modality segmentation performance by distilling knowledge from a label-rich source domain to a target domain without labels. In this work, we propose a multi-scale self-ensembling based UDA framework for automatic segmentation of two key brain structures i.e., Vestibular Schwannoma (VS) and Cochlea on high-resolution T2 images. First, a segmentation-enhanced contrastive unpaired image translation module is designed for image-level domain adaptation from source T1 to target T2. Next, multi-scale deep supervision and consistency regularization are introduced to a mean teacher network for self-ensemble learning to further close the domain gap. Furthermore, self-training and intensity augmentation techniques are utilized to mitigate label scarcity and boost cross-modality segmentation performance. Our method demonstrates promising ",
    "path": "papers/23/03/2303.15826.json",
    "total_tokens": 991,
    "translated_title": "MS-MT: 带有对抗无配对翻译的多尺度均值教师用于跨模态听神经瘤和耳蜗分割",
    "translated_abstract": "针对医学图像分割中存在的域漂移问题，本文提出了一种基于多尺度自我集成的无监督域自适应框架，用于高分辨率T2图像上的两个关键脑结构（即听神经瘤和耳蜗）的自动分割。通过设计分割增强的对抗无配对图像翻译模块，对源T1到目标T2的图像级域自适应进行了改进。接着，引入了多尺度深度监督和一致性正则化来进行均值教师网络的自我集成学习，以进一步缩小域差距。此外，采用自训练和强度增强技术来缓解标签稀缺性并增强跨模态分割性能。结果显示，我们的方法在跨模态听神经瘤和耳蜗分割任务中表现出了很好的性能，优于几种最先进的无监督域自适应方法。",
    "tldr": "本文提出了一个跨模态图像分割的无监督域自适应方法，通过多尺度自我集成和对抗无配对翻译，实现了对听神经瘤和耳蜗的自动分割，取得了很好的效果。",
    "en_tdlr": "This paper proposes an unsupervised domain adaptation method for cross-modality medical image segmentation, achieving automatic segmentation of Vestibular Schwannoma and Cochlea through multi-scale self-ensembling and contrastive unpaired translation, with promising results."
}