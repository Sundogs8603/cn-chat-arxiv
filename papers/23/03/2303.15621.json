{
    "title": "ChatGPT as a Factual Inconsistency Evaluator for Abstractive Text Summarization. (arXiv:2303.15621v1 [cs.CL])",
    "abstract": "The performance of abstractive text summarization has been greatly boosted by pre-trained language models recently. The main concern of existing abstractive summarization methods is the factual inconsistency problem of their generated summary. To alleviate the problem, many efforts have focused on developing effective factuality evaluation metrics based on natural language inference and question answering et al. However, they have limitations of high computational complexity and relying on annotated data. Most recently, large language models such as ChatGPT have shown strong ability in not only natural language understanding but also natural language inference. In this paper, we study the factual inconsistency evaluation ability of ChatGPT under the zero-shot setting by evaluating it on the coarse-grained and fine-grained factuality evaluation tasks including binary natural language inference (NLI), summary ranking, and consistency rating. Experimental results show that ChatGPT outperf",
    "link": "http://arxiv.org/abs/2303.15621",
    "context": "Title: ChatGPT as a Factual Inconsistency Evaluator for Abstractive Text Summarization. (arXiv:2303.15621v1 [cs.CL])\nAbstract: The performance of abstractive text summarization has been greatly boosted by pre-trained language models recently. The main concern of existing abstractive summarization methods is the factual inconsistency problem of their generated summary. To alleviate the problem, many efforts have focused on developing effective factuality evaluation metrics based on natural language inference and question answering et al. However, they have limitations of high computational complexity and relying on annotated data. Most recently, large language models such as ChatGPT have shown strong ability in not only natural language understanding but also natural language inference. In this paper, we study the factual inconsistency evaluation ability of ChatGPT under the zero-shot setting by evaluating it on the coarse-grained and fine-grained factuality evaluation tasks including binary natural language inference (NLI), summary ranking, and consistency rating. Experimental results show that ChatGPT outperf",
    "path": "papers/23/03/2303.15621.json",
    "total_tokens": 926,
    "translated_title": "ChatGPT作为抽象文本摘要中事实不一致性评估器",
    "translated_abstract": "最近，预训练语言模型大大提高了抽象文本摘要的性能。现有的抽象摘要方法的主要问题是其生成的摘要存在的事实不一致性问题。为缓解这个问题，许多努力将重点放在开发基于自然语言推理和问答等方面的有效事实性评估指标上。然而，它们存在计算复杂度高和依赖注释数据的限制。最近，像ChatGPT这样的大型语言模型不仅显示了强大的自然语言理解能力，而且还在自然语言推理方面表现出众。在本文中，我们通过在粗粒度和细粒度的事实评估任务（包括二进制自然语言推理（NLI）、摘要排名和一致性评级）上评估ChatGPT的零-shot设置下的事实不一致性评估能力。实验结果表明，ChatGPT在所有评估任务上均表现出了最先进的性能。",
    "tldr": "本文研究了ChatGPT作为抽象文本摘要中事实不一致性评估器的能力，证明其在不需要注释数据和高计算复杂度的情况下，在粗粒度和细粒度的任务中表现出了最先进的性能。",
    "en_tdlr": "This paper studies the ability of ChatGPT as a factual inconsistency evaluator for abstractive text summarization and demonstrates that it outperforms previous methods in both coarse-grained and fine-grained factuality evaluation tasks without relying on annotated data and high computational complexity."
}