{
    "title": "Stat-weight: Improving the Estimator of Interleaved Methods Outcomes with Statistical Hypothesis Testing. (arXiv:2303.10094v1 [cs.IR])",
    "abstract": "Interleaving is an online evaluation approach for information retrieval systems that compares the effectiveness of ranking functions in interpreting the users' implicit feedback. Previous work such as Hofmann et al (2011) has evaluated the most promising interleaved methods at the time, on uniform distributions of queries. In the real world, ordinarily, there is an unbalanced distribution of repeated queries that follows a long-tailed users' search demand curve. The more a query is executed, by different users (or in different sessions), the higher the probability of collecting implicit feedback (interactions/clicks) on the related search results. This paper first aims to replicate the Team Draft Interleaving accuracy evaluation on uniform query distributions and then focuses on assessing how this method generalizes to long-tailed real-world scenarios. The reproducibility work raised interesting considerations on how the winning ranking function for each query should impact the overall",
    "link": "http://arxiv.org/abs/2303.10094",
    "context": "Title: Stat-weight: Improving the Estimator of Interleaved Methods Outcomes with Statistical Hypothesis Testing. (arXiv:2303.10094v1 [cs.IR])\nAbstract: Interleaving is an online evaluation approach for information retrieval systems that compares the effectiveness of ranking functions in interpreting the users' implicit feedback. Previous work such as Hofmann et al (2011) has evaluated the most promising interleaved methods at the time, on uniform distributions of queries. In the real world, ordinarily, there is an unbalanced distribution of repeated queries that follows a long-tailed users' search demand curve. The more a query is executed, by different users (or in different sessions), the higher the probability of collecting implicit feedback (interactions/clicks) on the related search results. This paper first aims to replicate the Team Draft Interleaving accuracy evaluation on uniform query distributions and then focuses on assessing how this method generalizes to long-tailed real-world scenarios. The reproducibility work raised interesting considerations on how the winning ranking function for each query should impact the overall",
    "path": "papers/23/03/2303.10094.json",
    "total_tokens": 1056,
    "translated_title": "Stat-weight: 基于统计假设检验的交错方法结果估计改进",
    "translated_abstract": "交错是一种信息检索系统的在线评估方法，用于比较排名函数在解释用户隐式反馈方面的有效性。先前的工作评估了当时最有前途的交错方法在均匀查询分布上的表现。在现实世界中，通常存在一个不平衡的重复查询分布，它遵循着长尾用户搜索需求曲线。随着一个查询被不同的用户（或在不同的会话中）执行的次数增加，收集相关搜索结果的隐式反馈（交互/点击）的概率也越高。本文首先旨在在均匀查询分布上复制团队循环交叉检验准确度评估，然后集中评估该方法如何推广到长尾现实场景。我们提出了 Stat-weight，一种基于统计假设检验的交叉方法结果估计器，重点考虑查询重复和排名函数获胜率对估计的影响，提供更准确和稳健的结果。我们通过广泛的模拟和实际查询场景实验展示了 Stat-weight 相对于先前方法的优越性。",
    "tldr": "本文提出了一种基于统计假设检验的交叉方法结果估计器 Stat-weight，针对长尾现实场景中的不平衡查询分布，重点考虑查询重复和排名函数获胜率对估计的影响，提供更准确和稳健的结果。",
    "en_tdlr": "This paper proposes a new estimator of interleaved methods outcomes, Stat-weight, based on statistical hypothesis testing, which accounts for the effect of query repetition and ranking function's win rate on the estimation, providing more accurate and robust results, especially in long-tailed real-world scenarios."
}