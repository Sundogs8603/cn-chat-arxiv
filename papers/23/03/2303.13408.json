{
    "title": "Paraphrasing evades detectors of AI-generated text, but retrieval is an effective defense. (arXiv:2303.13408v1 [cs.CL])",
    "abstract": "To detect the deployment of large language models for malicious use cases (e.g., fake content creation or academic plagiarism), several approaches have recently been proposed for identifying AI-generated text via watermarks or statistical irregularities. How robust are these detection algorithms to paraphrases of AI-generated text? To stress test these detectors, we first train an 11B parameter paraphrase generation model (DIPPER) that can paraphrase paragraphs, optionally leveraging surrounding text (e.g., user-written prompts) as context. DIPPER also uses scalar knobs to control the amount of lexical diversity and reordering in the paraphrases. Paraphrasing text generated by three large language models (including GPT3.5-davinci-003) with DIPPER successfully evades several detectors, including watermarking, GPTZero, DetectGPT, and OpenAI's text classifier. For example, DIPPER drops the detection accuracy of DetectGPT from 70.3% to 4.6% (at a constant false positive rate of 1%), withou",
    "link": "http://arxiv.org/abs/2303.13408",
    "context": "Title: Paraphrasing evades detectors of AI-generated text, but retrieval is an effective defense. (arXiv:2303.13408v1 [cs.CL])\nAbstract: To detect the deployment of large language models for malicious use cases (e.g., fake content creation or academic plagiarism), several approaches have recently been proposed for identifying AI-generated text via watermarks or statistical irregularities. How robust are these detection algorithms to paraphrases of AI-generated text? To stress test these detectors, we first train an 11B parameter paraphrase generation model (DIPPER) that can paraphrase paragraphs, optionally leveraging surrounding text (e.g., user-written prompts) as context. DIPPER also uses scalar knobs to control the amount of lexical diversity and reordering in the paraphrases. Paraphrasing text generated by three large language models (including GPT3.5-davinci-003) with DIPPER successfully evades several detectors, including watermarking, GPTZero, DetectGPT, and OpenAI's text classifier. For example, DIPPER drops the detection accuracy of DetectGPT from 70.3% to 4.6% (at a constant false positive rate of 1%), withou",
    "path": "papers/23/03/2303.13408.json",
    "total_tokens": 912,
    "translated_title": "语义转换混淆AI生成文本检测，而检索是一种有效的防御方法",
    "translated_abstract": "近期有多种方法被提出来用于识别恶意使用大型语言模型 (例如虚假内容创建或学术抄袭)中的AI生成文本，包括通过水印或统计异常点。本文探究这些文本检测算法对于AI生成文本的含义转换的鲁棒性。为了测试这些检测器的性能，我们首先训练了一个11B参数的语义转换生成模型(DIPPER)，该模型可以将段落进行语义转换，可选择利用周围文本(例如用户写的提示)作为上下文。DIPPER还使用标量旋钮来控制语义转换中词汇多样性和重新排列的程度。通过使用DIPPER来进行三种大型语言模型生成文本的语义转换，成功地混淆了多个文本检测器，包括水印检测、GPTZero、DetectGPT和OpenAI的文本分类器。例如，DIPPER将DetectGPT的检测准确率从70.3%降至4.6%（在恒定的1%误报率下）。",
    "tldr": "本文探究了语义转换对于AI生成文本检测器的鲁棒性，通过训练的语义转换生成模型成功混淆了多个检测器。"
}