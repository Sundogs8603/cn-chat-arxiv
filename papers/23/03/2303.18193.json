{
    "title": "GVP: Generative Volumetric Primitives. (arXiv:2303.18193v1 [cs.CV])",
    "abstract": "Advances in 3D-aware generative models have pushed the boundary of image synthesis with explicit camera control. To achieve high-resolution image synthesis, several attempts have been made to design efficient generators, such as hybrid architectures with both 3D and 2D components. However, such a design compromises multiview consistency, and the design of a pure 3D generator with high resolution is still an open problem. In this work, we present Generative Volumetric Primitives (GVP), the first pure 3D generative model that can sample and render 512-resolution images in real-time. GVP jointly models a number of volumetric primitives and their spatial information, both of which can be efficiently generated via a 2D convolutional network. The mixture of these primitives naturally captures the sparsity and correspondence in the 3D volume. The training of such a generator with a high degree of freedom is made possible through a knowledge distillation technique. Experiments on several datas",
    "link": "http://arxiv.org/abs/2303.18193",
    "context": "Title: GVP: Generative Volumetric Primitives. (arXiv:2303.18193v1 [cs.CV])\nAbstract: Advances in 3D-aware generative models have pushed the boundary of image synthesis with explicit camera control. To achieve high-resolution image synthesis, several attempts have been made to design efficient generators, such as hybrid architectures with both 3D and 2D components. However, such a design compromises multiview consistency, and the design of a pure 3D generator with high resolution is still an open problem. In this work, we present Generative Volumetric Primitives (GVP), the first pure 3D generative model that can sample and render 512-resolution images in real-time. GVP jointly models a number of volumetric primitives and their spatial information, both of which can be efficiently generated via a 2D convolutional network. The mixture of these primitives naturally captures the sparsity and correspondence in the 3D volume. The training of such a generator with a high degree of freedom is made possible through a knowledge distillation technique. Experiments on several datas",
    "path": "papers/23/03/2303.18193.json",
    "total_tokens": 1090,
    "translated_title": "GVP: 生成体素元素",
    "translated_abstract": "三维感知生成模型的进展推动了具有显式摄像机控制的图像合成边界。为了实现高分辨率图像合成，已经尝试设计了一些高效的发生器，例如具有3D和2D组件的混合架构。然而，这种设计会损害多视图一致性，而高分辨率的纯3D生成器的设计仍然是一个开放问题。本文提出了生成体素元素（GVP），这是第一个能够实时采样和渲染512分辨率图像的纯3D生成模型。GVP共同模拟了多个体积元素和它们的空间信息，这两个元素都可以通过2D卷积网络高效地生成。这些元素的混合自然地捕捉了三维空间中的稀疏性和对应性。这种高度自由度的发生器的训练是通过知识蒸馏技术实现的。在几个数据集上的实验证明，GVP在图像质量和多视图一致性方面的表现优于以前的方法。",
    "tldr": "本文提出了Generative Volumetric Primitives (GVP)生成体素元素，是第一个能够实时采样和渲染512分辨率图像的纯3D生成模型，通过2D卷积网络高效地生成多个体积元素和它们的空间信息，能够捕捉三维空间中的稀疏性和对应性，并通过知识蒸馏技术实现高自由度的训练。实验表明，GVP优于以前的方法，从图像质量和多视图一致性两方面进行了验证。",
    "en_tdlr": "This paper presents the Generative Volumetric Primitives (GVP), the first pure 3D generative model that can sample and render 512-resolution images in real-time, which efficiently generates a number of volumetric primitives and their spatial information via a 2D convolutional network, capturing the sparsity and correspondence in the 3D volume. GVP outperforms previous approaches in terms of image quality and multiview consistency, and the generator is trained with a high degree of freedom through a knowledge distillation technique."
}