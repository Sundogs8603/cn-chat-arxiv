{
    "title": "Disturbance Injection under Partial Automation: Robust Imitation Learning for Long-horizon Tasks. (arXiv:2303.12375v1 [cs.RO])",
    "abstract": "Partial Automation (PA) with intelligent support systems has been introduced in industrial machinery and advanced automobiles to reduce the burden of long hours of human operation. Under PA, operators perform manual operations (providing actions) and operations that switch to automatic/manual mode (mode-switching). Since PA reduces the total duration of manual operation, these two action and mode-switching operations can be replicated by imitation learning with high sample efficiency. To this end, this paper proposes Disturbance Injection under Partial Automation (DIPA) as a novel imitation learning framework. In DIPA, mode and actions (in the manual mode) are assumed to be observables in each state and are used to learn both action and mode-switching policies. The above learning is robustified by injecting disturbances into the operator's actions to optimize the disturbance's level for minimizing the covariate shift under PA. We experimentally validated the effectiveness of our method",
    "link": "http://arxiv.org/abs/2303.12375",
    "context": "Title: Disturbance Injection under Partial Automation: Robust Imitation Learning for Long-horizon Tasks. (arXiv:2303.12375v1 [cs.RO])\nAbstract: Partial Automation (PA) with intelligent support systems has been introduced in industrial machinery and advanced automobiles to reduce the burden of long hours of human operation. Under PA, operators perform manual operations (providing actions) and operations that switch to automatic/manual mode (mode-switching). Since PA reduces the total duration of manual operation, these two action and mode-switching operations can be replicated by imitation learning with high sample efficiency. To this end, this paper proposes Disturbance Injection under Partial Automation (DIPA) as a novel imitation learning framework. In DIPA, mode and actions (in the manual mode) are assumed to be observables in each state and are used to learn both action and mode-switching policies. The above learning is robustified by injecting disturbances into the operator's actions to optimize the disturbance's level for minimizing the covariate shift under PA. We experimentally validated the effectiveness of our method",
    "path": "papers/23/03/2303.12375.json",
    "total_tokens": 865,
    "translated_title": "部分自动化下的干扰注入：长时间任务的鲁棒模仿学习",
    "translated_abstract": "部分自动化 (PA) 技术通过引入智能支持系统，已经应用于工业机械和高级汽车中，以减少人类操作的长时间负担。在 PA 下，操作员执行手动操作（提供动作）和自动 / 手动模式的操作（模式切换）。由于 PA 缩短了手动操作的总时间，因此这两种操作可以通过模仿学习高效地复制。针对此问题，本文提出了 Disturbance Injection under Partial Automation (DIPA) 作为一种新的模仿学习框架。在 DIPA 中，假设状态中的模式和手动模式下的动作是可观测的，用于学习动作和模式转换策略。为了优化在 PA 下的协变量偏移最小化，我们通过向操作员的动作注入干扰来鲁棒化上述学习。我们实验证明了我们方法的有效性。",
    "tldr": "本文提出了一种干扰注入的鲁棒模仿学习框架，针对部分自动化下长时间任务的应用进行优化，通过变量干扰来提升学习效果。",
    "en_tdlr": "This paper proposes a robust imitation learning framework with disturbance injection to optimize long-horizon tasks under partial automation, which enhances the learning effect by injecting disturbances into the operator's actions to minimize the covariate shift."
}