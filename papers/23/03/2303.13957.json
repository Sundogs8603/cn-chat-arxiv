{
    "title": "Factorizers for Distributed Sparse Block Codes. (arXiv:2303.13957v1 [cs.CV])",
    "abstract": "Distributed sparse block codes (SBCs) exhibit compact representations for encoding and manipulating symbolic data structures using fixed-with vectors. One major challenge however is to disentangle, or factorize, such data structures into their constituent elements without having to search through all possible combinations. This factorization becomes more challenging when queried by noisy SBCs wherein symbol representations are relaxed due to perceptual uncertainty and approximations made when modern neural networks are used to generate the query vectors. To address these challenges, we first propose a fast and highly accurate method for factorizing a more flexible and hence generalized form of SBCs, dubbed GSBCs. Our iterative factorizer introduces a threshold-based nonlinear activation, a conditional random sampling, and an $\\ell_\\infty$-based similarity metric. Its random sampling mechanism in combination with the search in superposition allows to analytically determine the expected ",
    "link": "http://arxiv.org/abs/2303.13957",
    "context": "Title: Factorizers for Distributed Sparse Block Codes. (arXiv:2303.13957v1 [cs.CV])\nAbstract: Distributed sparse block codes (SBCs) exhibit compact representations for encoding and manipulating symbolic data structures using fixed-with vectors. One major challenge however is to disentangle, or factorize, such data structures into their constituent elements without having to search through all possible combinations. This factorization becomes more challenging when queried by noisy SBCs wherein symbol representations are relaxed due to perceptual uncertainty and approximations made when modern neural networks are used to generate the query vectors. To address these challenges, we first propose a fast and highly accurate method for factorizing a more flexible and hence generalized form of SBCs, dubbed GSBCs. Our iterative factorizer introduces a threshold-based nonlinear activation, a conditional random sampling, and an $\\ell_\\infty$-based similarity metric. Its random sampling mechanism in combination with the search in superposition allows to analytically determine the expected ",
    "path": "papers/23/03/2303.13957.json",
    "total_tokens": 972,
    "translated_title": "分布式稀疏块编码的分解器",
    "translated_abstract": "分布式稀疏块编码（SBC）利用固定宽度的向量对符号数据结构进行编码和操作，具有紧凑的表示形式。然而，一个主要的挑战是在不必搜寻所有可能的组合的情况下将这些数据结构拆分成其组成部分。当使用现代神经网络生成查询向量时，噪声SBC中的符号表示由于感知不确定性和近似而放松，这使得这种分解变得更加具有挑战性。为了解决这些挑战，我们首先提出了一种快速且高精度的方法来分解一种更灵活、因此更普遍的SBC形式，称为GSBC。我们的迭代因子引入了基于阈值的非线性激活、条件随机采样和$\\ell_\\infty$基于相似性度量。它的随机采样机制与叠加搜索相结合，可以分析确定预期的解的质量。",
    "tldr": "本文提出了一种用于分解分布式稀疏块编码（SBC）的GSBC，该方法引入了基于阈值的非线性激活、条件随机采样和$\\ell_\\infty$基于相似性度量，并能够分析确定预期的解的质量，解决了由于感知不确定性和近似而放松的噪声SBC中符号表示的挑战。",
    "en_tdlr": "This paper proposes a method for factorizing a more flexible and hence generalized form of distributed sparse block codes (SBCs), dubbed GSBCs, which can address the challenge of symbol representations relaxed due to perceptual uncertainty and approximations made when modern neural networks are used to generate query vectors. The proposed iterative factorizer introduces a threshold-based nonlinear activation, a conditional random sampling, and an $\\ell_\\infty$-based similarity metric, and can analytically determine the expected quality of the solution."
}