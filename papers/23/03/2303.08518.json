{
    "title": "UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation. (arXiv:2303.08518v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs) are popular for their impressive abilities, but the need for model-specific fine-tuning or task-specific prompt engineering can hinder their generalization. We propose UPRISE (Universal Prompt Retrieval for Improving zero-Shot Evaluation), which tunes a lightweight and versatile retriever that automatically retrieves prompts for a given zero-shot task input. Specifically, we demonstrate universality in a cross-task and cross-model scenario: the retriever is tuned on a diverse set of tasks, but tested on unseen task types; we use a small frozen LLM, GPT-Neo-2.7B, for tuning the retriever, but test the retriever on different LLMs of much larger scales, such as BLOOM-7.1B, OPT-66B and GPT3-175B. Additionally, we show that UPRISE mitigates the hallucination problem in our experiments with ChatGPT, suggesting its potential to improve even the strongest LLMs.",
    "link": "http://arxiv.org/abs/2303.08518",
    "context": "Title: UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation. (arXiv:2303.08518v1 [cs.CL])\nAbstract: Large Language Models (LLMs) are popular for their impressive abilities, but the need for model-specific fine-tuning or task-specific prompt engineering can hinder their generalization. We propose UPRISE (Universal Prompt Retrieval for Improving zero-Shot Evaluation), which tunes a lightweight and versatile retriever that automatically retrieves prompts for a given zero-shot task input. Specifically, we demonstrate universality in a cross-task and cross-model scenario: the retriever is tuned on a diverse set of tasks, but tested on unseen task types; we use a small frozen LLM, GPT-Neo-2.7B, for tuning the retriever, but test the retriever on different LLMs of much larger scales, such as BLOOM-7.1B, OPT-66B and GPT3-175B. Additionally, we show that UPRISE mitigates the hallucination problem in our experiments with ChatGPT, suggesting its potential to improve even the strongest LLMs.",
    "path": "papers/23/03/2303.08518.json",
    "total_tokens": 920,
    "translated_title": "UPRISE: 通用提示检索以提高零样本评估",
    "translated_abstract": "大型语言模型因其出色的能力而受欢迎，但需要特定模型的微调或任务特定提示工程可能会阻碍其一般化。我们提出了UPRISE（通用提示检索以提高零样本评估），该方法调整了轻量级和多功能的检索器，以自动检索给定零样本任务输入的提示。具体而言，在跨任务和跨模型方案中展示了通用性：检索器针对各种任务进行微调，但在看不见的任务类型上进行测试；我们在一个小型冻结LLM——GPT-Neo-2.7B上调整检索器，但在不同规模的LLM上测试检索器，例如BLOOM-7.1B、OPT-66B和GPT3-175B。此外，我们展示了UPRISE在我们与ChatGPT的实验中减轻了幻觉问题，表明它有潜力改进甚至是最强的LLM。",
    "tldr": "UPRISE是一种通用的检索器，可自动为给定的零样本任务输入检索提示，从而提高大型语言模型的零样本评估。它通过跨任务和跨模型的实验展示了其通用性和潜力，同时表明具有减轻幻觉问题和提高LLM性能的能力。",
    "en_tdlr": "UPRISE is a universal retriever that automatically retrieves prompts for a given zero-shot task input, improving zero-shot evaluation for large language models. It demonstrates universality and potential through cross-task and cross-model experiments, while showing the ability to mitigate hallucination problems and improve LLM performance."
}