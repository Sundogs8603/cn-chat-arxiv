{
    "title": "Domain Generalization via Nuclear Norm Regularization. (arXiv:2303.07527v1 [cs.LG])",
    "abstract": "The ability to generalize to unseen domains is crucial for machine learning systems deployed in the real world, especially when we only have data from limited training domains. In this paper, we propose a simple and effective regularization method based on the nuclear norm of the learned features for domain generalization. Intuitively, the proposed regularizer mitigates the impacts of environmental features and encourages learning domain-invariant features. Theoretically, we provide insights into why nuclear norm regularization is more effective compared to ERM and alternative regularization methods. Empirically, we conduct extensive experiments on both synthetic and real datasets. We show that nuclear norm regularization achieves strong performance compared to baselines in a wide range of domain generalization tasks. Moreover, our regularizer is broadly applicable with various methods such as ERM and SWAD with consistently improved performance, e.g., 1.7% and 0.9% test accuracy improv",
    "link": "http://arxiv.org/abs/2303.07527",
    "context": "Title: Domain Generalization via Nuclear Norm Regularization. (arXiv:2303.07527v1 [cs.LG])\nAbstract: The ability to generalize to unseen domains is crucial for machine learning systems deployed in the real world, especially when we only have data from limited training domains. In this paper, we propose a simple and effective regularization method based on the nuclear norm of the learned features for domain generalization. Intuitively, the proposed regularizer mitigates the impacts of environmental features and encourages learning domain-invariant features. Theoretically, we provide insights into why nuclear norm regularization is more effective compared to ERM and alternative regularization methods. Empirically, we conduct extensive experiments on both synthetic and real datasets. We show that nuclear norm regularization achieves strong performance compared to baselines in a wide range of domain generalization tasks. Moreover, our regularizer is broadly applicable with various methods such as ERM and SWAD with consistently improved performance, e.g., 1.7% and 0.9% test accuracy improv",
    "path": "papers/23/03/2303.07527.json",
    "total_tokens": 917,
    "translated_title": "通过核范数正则化实现领域通用性",
    "translated_abstract": "在现实世界中，机器学习系统在仅有有限域的数据的情况下具备对未知领域的泛化能力尤为重要。本文提出了一种基于学习特征核范数的简单有效的领域通用性正则化方法。直观上，所提出的正则化方法减少了环境特征的影响，鼓励学习领域不变的特征。从理论上讲，我们提供了有关为什么相比于最小化经验风险或其他正则化方法，核范数正则化更加有效的见解。实验方面，我们在合成和实际数据集上进行了大量试验证明，核范数正则化在广泛的领域通用性任务中与基线相比具有强大的性能。此外，我们的正则化方法适用于各种方法，如ERM和SWAD，且表现持续提高，例如测试准确率提高了1.7％和0.9％。",
    "tldr": "本文提出了一种基于核范数正则化的通用性正则化方法，能够降低环境特征的影响并鼓励学习领域不变的特征，能够在广泛的领域通用性任务中获得比基线更强的性能。",
    "en_tdlr": "This paper proposes a domain generalization regularization method based on nuclear norm regularization, which reduces the impact of environmental features and encourages learning of domain-invariant features. It achieves strong performance compared to baselines in a wide range of domain generalization tasks, and is broadly applicable with various methods such as ERM and SWAD with consistently improved accuracy."
}