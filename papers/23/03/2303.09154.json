{
    "title": "Bayesian Generalization Error in Linear Neural Networks with Concept Bottleneck Structure and Multitask Formulation. (arXiv:2303.09154v1 [stat.ML])",
    "abstract": "Concept bottleneck model (CBM) is a ubiquitous method that can interpret neural networks using concepts. In CBM, concepts are inserted between the output layer and the last intermediate layer as observable values. This helps in understanding the reason behind the outputs generated by the neural networks: the weights corresponding to the concepts from the last hidden layer to the output layer. However, it has not yet been possible to understand the behavior of the generalization error in CBM since a neural network is a singular statistical model in general. When the model is singular, a one to one map from the parameters to probability distributions cannot be created. This non-identifiability makes it difficult to analyze the generalization performance. In this study, we mathematically clarify the Bayesian generalization error and free energy of CBM when its architecture is three-layered linear neural networks. We also consider a multitask problem where the neural network outputs not on",
    "link": "http://arxiv.org/abs/2303.09154",
    "context": "Title: Bayesian Generalization Error in Linear Neural Networks with Concept Bottleneck Structure and Multitask Formulation. (arXiv:2303.09154v1 [stat.ML])\nAbstract: Concept bottleneck model (CBM) is a ubiquitous method that can interpret neural networks using concepts. In CBM, concepts are inserted between the output layer and the last intermediate layer as observable values. This helps in understanding the reason behind the outputs generated by the neural networks: the weights corresponding to the concepts from the last hidden layer to the output layer. However, it has not yet been possible to understand the behavior of the generalization error in CBM since a neural network is a singular statistical model in general. When the model is singular, a one to one map from the parameters to probability distributions cannot be created. This non-identifiability makes it difficult to analyze the generalization performance. In this study, we mathematically clarify the Bayesian generalization error and free energy of CBM when its architecture is three-layered linear neural networks. We also consider a multitask problem where the neural network outputs not on",
    "path": "papers/23/03/2303.09154.json",
    "total_tokens": 874,
    "translated_title": "带有概念瓶颈结构和多任务组成的线性神经网络的贝叶斯泛化误差。",
    "translated_abstract": "概念瓶颈模型（CBM）是一种广泛使用的方法，可以使用概念解释神经网络。在CBM中，概念被插入到输出层和最后一个中间层之间作为可观察值。这有助于理解神经网络生成输出的原因：最后一个隐藏层到输出层的概念对应的权重。然而，在CBM中理解泛化误差行为尚不可能，因为神经网络通常是奇异的统计模型。当模型是奇异的时，从参数到概率分布的一一映射不能创建。这种不可识别性使得分析泛化性能变得困难。在本次研究中，我们数学上澄清了CBM的贝叶斯泛化误差和自由能，当其架构是三层的线性神经网络时。我们还考虑了一个多任务问题，在该问题中，神经网络的输出不再只是一个标签，而是一组任务。",
    "tldr": "本文数学上澄清了带有概念瓶颈结构和多任务组成的线性神经网络的贝叶斯泛化误差和自由能。",
    "en_tdlr": "This paper mathematically clarifies the Bayesian generalization error and free energy of linear neural networks with concept bottleneck structure and multitask formulation."
}