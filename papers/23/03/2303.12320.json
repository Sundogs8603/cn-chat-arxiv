{
    "title": "GrapeQA: GRaph Augmentation and Pruning to Enhance Question-Answering. (arXiv:2303.12320v1 [cs.CL])",
    "abstract": "Commonsense question-answering (QA) methods combine the power of pre-trained Language Models (LM) with the reasoning provided by Knowledge Graphs (KG). A typical approach collects nodes relevant to the QA pair from a KG to form a Working Graph (WG) followed by reasoning using Graph Neural Networks(GNNs). This faces two major challenges: (i) it is difficult to capture all the information from the QA in the WG, and (ii) the WG contains some irrelevant nodes from the KG. To address these, we propose GrapeQA with two simple improvements on the WG: (i) Prominent Entities for Graph Augmentation identifies relevant text chunks from the QA pair and augments the WG with corresponding latent representations from the LM, and (ii) Context-Aware Node Pruning removes nodes that are less relevant to the QA pair. We evaluate our results on OpenBookQA, CommonsenseQA and MedQA-USMLE and see that GrapeQA shows consistent improvements over its LM + KG predecessor (QA-GNN in particular) and large improveme",
    "link": "http://arxiv.org/abs/2303.12320",
    "context": "Title: GrapeQA: GRaph Augmentation and Pruning to Enhance Question-Answering. (arXiv:2303.12320v1 [cs.CL])\nAbstract: Commonsense question-answering (QA) methods combine the power of pre-trained Language Models (LM) with the reasoning provided by Knowledge Graphs (KG). A typical approach collects nodes relevant to the QA pair from a KG to form a Working Graph (WG) followed by reasoning using Graph Neural Networks(GNNs). This faces two major challenges: (i) it is difficult to capture all the information from the QA in the WG, and (ii) the WG contains some irrelevant nodes from the KG. To address these, we propose GrapeQA with two simple improvements on the WG: (i) Prominent Entities for Graph Augmentation identifies relevant text chunks from the QA pair and augments the WG with corresponding latent representations from the LM, and (ii) Context-Aware Node Pruning removes nodes that are less relevant to the QA pair. We evaluate our results on OpenBookQA, CommonsenseQA and MedQA-USMLE and see that GrapeQA shows consistent improvements over its LM + KG predecessor (QA-GNN in particular) and large improveme",
    "path": "papers/23/03/2303.12320.json",
    "total_tokens": 886,
    "translated_title": "GrapeQA：增强问答功能的图形增强和剪枝方法",
    "translated_abstract": "常识问答方法结合了预先训练的语言模型（LM）的能力和知识图（KG）提供的推理。 典型方法从KG中收集与QA匹配的节点以形成工作图（WG），然后使用图神经网络（GNN）进行推理。这面临两个主要挑战：（i）很难从WG中捕获QA中的所有信息，（ii）WG包含一些来自KG的不相关节点。为了解决这些问题，我们提出了一个名为GrapeQA的算法以对WG进行两个简单的改进：（i）用于图形增强的重要实体（Prominent Entities）识别QA对当中相关文本块，并使用相应的潜在表示从LM进行增强；（ii）将不相关的节点剪枝。我们在OpenBookQA，CommonsenseQA和MedQA-USMLE上评估了结果，并发现GrapeQA显示出持续的改进，超过了其LM + KG前身（特别是QA-GNN）并获得了巨大的改进。",
    "tldr": "GrapeQA是一种新方法，使用“重要实体图形增强”和“上下文感知节点剪枝”策略，以提高问答准确性和效率。",
    "en_tdlr": "GrapeQA is a novel approach that improves question-answering accuracy and efficiency by using \"Prominent Entities for Graph Augmentation\" and \"Context-Aware Node Pruning\" strategies."
}