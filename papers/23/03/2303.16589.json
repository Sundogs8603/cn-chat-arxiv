{
    "title": "Poster: Link between Bias, Node Sensitivity and Long-Tail Distribution in trained DNNs. (arXiv:2303.16589v1 [cs.LG])",
    "abstract": "Owing to their remarkable learning (and relearning) capabilities, deep neural networks (DNNs) find use in numerous real-world applications. However, the learning of these data-driven machine learning models is generally as good as the data available to them for training. Hence, training datasets with long-tail distribution pose a challenge for DNNs, since the DNNs trained on them may provide a varying degree of classification performance across different output classes. While the overall bias of such networks is already highlighted in existing works, this work identifies the node bias that leads to a varying sensitivity of the nodes for different output classes. To the best of our knowledge, this is the first work highlighting this unique challenge in DNNs, discussing its probable causes, and providing open challenges for this new research direction. We support our reasoning using an empirical case study of the networks trained on a real-world dataset.",
    "link": "http://arxiv.org/abs/2303.16589",
    "context": "Title: Poster: Link between Bias, Node Sensitivity and Long-Tail Distribution in trained DNNs. (arXiv:2303.16589v1 [cs.LG])\nAbstract: Owing to their remarkable learning (and relearning) capabilities, deep neural networks (DNNs) find use in numerous real-world applications. However, the learning of these data-driven machine learning models is generally as good as the data available to them for training. Hence, training datasets with long-tail distribution pose a challenge for DNNs, since the DNNs trained on them may provide a varying degree of classification performance across different output classes. While the overall bias of such networks is already highlighted in existing works, this work identifies the node bias that leads to a varying sensitivity of the nodes for different output classes. To the best of our knowledge, this is the first work highlighting this unique challenge in DNNs, discussing its probable causes, and providing open challenges for this new research direction. We support our reasoning using an empirical case study of the networks trained on a real-world dataset.",
    "path": "papers/23/03/2303.16589.json",
    "total_tokens": 925,
    "translated_title": "论文海报：训练DNN中偏差、节点敏感性和长尾分布之间的链接 (arXiv:2303.16589v1 [cs.LG])",
    "translated_abstract": "深度神经网络(DNNs)由于其卓越的学习(和重新学习)能力，被广泛应用于各种现实世界的应用场景。然而，这些数据驱动的机器学习模型的学习效果一般取决于数据的质量和分布。因此，分布呈现长尾分布的训练数据集对DNNs构成了挑战，因为这些训练的DNNs可能对不同的输出类别提供不同程度的分类性能。虽然现有的研究已经强调了这些网络的整体偏差，但本文首次指出了导致节点对不同输出类别敏感性变化的节点偏差。据我们所知，这是第一篇强调DNNs中这种独特挑战的工作，讨论其可能的原因，并为这个新的研究方向提供了开放性挑战。我们使用真实情境数据集上训练的网络的实证案例来支持我们的推理。",
    "tldr": "DNN训练中长尾分布的数据集将给不同输出类别提供不同的分类性能，本文首次指出导致节点敏感性变化的节点偏差，提出了开放性挑战。",
    "en_tdlr": "This paper identifies the node bias leading to varying sensitivity of nodes for different output classes in DNNs trained on datasets with long-tail distribution, providing open challenges and empirical evidence, which is the first work to highlight this unique challenge in DNNs."
}