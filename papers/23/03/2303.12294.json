{
    "title": "Evaluating Transformer Models and Human Behaviors on Chinese Character Naming. (arXiv:2303.12294v1 [cs.CL])",
    "abstract": "Neural network models have been proposed to explain the grapheme-phoneme mapping process in humans for many alphabet languages. These models not only successfully learned the correspondence of the letter strings and their pronunciation, but also captured human behavior in nonce word naming tasks. How would the neural models perform for a non-alphabet language (e.g., Chinese) unknown character task? How well would the model capture human behavior? In this study, we evaluate a set of transformer models and compare their performances with human behaviors on an unknown Chinese character naming task. We found that the models and humans behaved very similarly, that they had similar accuracy distribution for each character, and had a substantial overlap in answers. In addition, the models' answers are highly correlated with humans' answers. These results suggested that the transformer models can well capture human's character naming behavior.",
    "link": "http://arxiv.org/abs/2303.12294",
    "context": "Title: Evaluating Transformer Models and Human Behaviors on Chinese Character Naming. (arXiv:2303.12294v1 [cs.CL])\nAbstract: Neural network models have been proposed to explain the grapheme-phoneme mapping process in humans for many alphabet languages. These models not only successfully learned the correspondence of the letter strings and their pronunciation, but also captured human behavior in nonce word naming tasks. How would the neural models perform for a non-alphabet language (e.g., Chinese) unknown character task? How well would the model capture human behavior? In this study, we evaluate a set of transformer models and compare their performances with human behaviors on an unknown Chinese character naming task. We found that the models and humans behaved very similarly, that they had similar accuracy distribution for each character, and had a substantial overlap in answers. In addition, the models' answers are highly correlated with humans' answers. These results suggested that the transformer models can well capture human's character naming behavior.",
    "path": "papers/23/03/2303.12294.json",
    "total_tokens": 814,
    "translated_title": "评估变换器模型和人类行为在中文字符命名方面的表现。",
    "translated_abstract": "对于许多字母语言，已经提出了神经网络模型来解释人类的字素-音素映射过程。这些模型不仅成功地学习了字母字符串及其发音的对应关系，而且还捕捉了人类在短暂单词命名任务中的行为。本研究中，我们评估了一组变换器模型，并将它们的表现与人类在未知中文字符命名任务中的表现进行比较。我们发现，模型和人类的行为非常相似，它们在每个字符的准确度分布方面具有类似的准确度，并且在答案上有很大的重叠。此外，模型的答案与人类的答案高度相关。这些结果表明，变换器模型能够很好地捕捉人类的字符命名行为。",
    "tldr": "本研究评估了一组 transformer 模型，在未知的中文字符命名任务中，这些模型表现得与人类很相似，能够很好地捕捉人类字符命名行为。",
    "en_tdlr": "This study evaluated a set of transformer models and found that they behaved similarly to humans when performing an unknown Chinese character naming task, indicating that the transformer models can well capture human's character naming behavior."
}