{
    "title": "Universal Approximation Property of Hamiltonian Deep Neural Networks. (arXiv:2303.12147v1 [cs.LG])",
    "abstract": "This paper investigates the universal approximation capabilities of Hamiltonian Deep Neural Networks (HDNNs) that arise from the discretization of Hamiltonian Neural Ordinary Differential Equations. Recently, it has been shown that HDNNs enjoy, by design, non-vanishing gradients, which provide numerical stability during training. However, although HDNNs have demonstrated state-of-the-art performance in several applications, a comprehensive study to quantify their expressivity is missing. In this regard, we provide a universal approximation theorem for HDNNs and prove that a portion of the flow of HDNNs can approximate arbitrary well any continuous function over a compact domain. This result provides a solid theoretical foundation for the practical use of HDNNs.",
    "link": "http://arxiv.org/abs/2303.12147",
    "context": "Title: Universal Approximation Property of Hamiltonian Deep Neural Networks. (arXiv:2303.12147v1 [cs.LG])\nAbstract: This paper investigates the universal approximation capabilities of Hamiltonian Deep Neural Networks (HDNNs) that arise from the discretization of Hamiltonian Neural Ordinary Differential Equations. Recently, it has been shown that HDNNs enjoy, by design, non-vanishing gradients, which provide numerical stability during training. However, although HDNNs have demonstrated state-of-the-art performance in several applications, a comprehensive study to quantify their expressivity is missing. In this regard, we provide a universal approximation theorem for HDNNs and prove that a portion of the flow of HDNNs can approximate arbitrary well any continuous function over a compact domain. This result provides a solid theoretical foundation for the practical use of HDNNs.",
    "path": "papers/23/03/2303.12147.json",
    "total_tokens": 812,
    "translated_title": "Hamiltonian深度神经网络的万能逼近性质研究",
    "translated_abstract": "本文研究了由离散化的哈密顿神经常微分方程引起的Hamiltonian深度神经网络（HDNN）的通用逼近能力。最近的研究表明，HDNN因设计而具有非消失梯度，在训练过程中提供数值稳定性。然而，尽管在几个应用中HDNN已经展示了最先进的性能，但缺少量化其表现力的全面研究。因此，我们提供了一个HDNN的通用逼近定理，并证明了HDNN的一部分流可以逐渐逼近紧致域上的任何连续函数。此结果为实际使用HDNN提供了牢固的理论基础。",
    "tldr": "本文研究了离散化的哈密顿神经常微分方程引起的Hamiltonian深度神经网络的通用逼近能力，证明了其中的一部分流可以逐渐逼近紧致域上的任何连续函数，为实际使用提供了理论基础。",
    "en_tdlr": "This paper studies the universal approximation capabilities of Hamiltonian Deep Neural Networks (HDNNs) arising from the discretization of Hamiltonian Neural Ordinary Differential Equations. The authors prove a universal approximation theorem for HDNNs, showing that a portion of the flow of HDNNs can approximate any continuous function over a compact domain, providing a solid theoretical foundation for practical use."
}