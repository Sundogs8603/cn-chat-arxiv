{
    "title": "Towards Adversarially Robust Continual Learning. (arXiv:2303.17764v1 [cs.LG])",
    "abstract": "Recent studies show that models trained by continual learning can achieve the comparable performances as the standard supervised learning and the learning flexibility of continual learning models enables their wide applications in the real world. Deep learning models, however, are shown to be vulnerable to adversarial attacks. Though there are many studies on the model robustness in the context of standard supervised learning, protecting continual learning from adversarial attacks has not yet been investigated. To fill in this research gap, we are the first to study adversarial robustness in continual learning and propose a novel method called \\textbf{T}ask-\\textbf{A}ware \\textbf{B}oundary \\textbf{A}ugmentation (TABA) to boost the robustness of continual learning models. With extensive experiments on CIFAR-10 and CIFAR-100, we show the efficacy of adversarial training and TABA in defending adversarial attacks.",
    "link": "http://arxiv.org/abs/2303.17764",
    "context": "Title: Towards Adversarially Robust Continual Learning. (arXiv:2303.17764v1 [cs.LG])\nAbstract: Recent studies show that models trained by continual learning can achieve the comparable performances as the standard supervised learning and the learning flexibility of continual learning models enables their wide applications in the real world. Deep learning models, however, are shown to be vulnerable to adversarial attacks. Though there are many studies on the model robustness in the context of standard supervised learning, protecting continual learning from adversarial attacks has not yet been investigated. To fill in this research gap, we are the first to study adversarial robustness in continual learning and propose a novel method called \\textbf{T}ask-\\textbf{A}ware \\textbf{B}oundary \\textbf{A}ugmentation (TABA) to boost the robustness of continual learning models. With extensive experiments on CIFAR-10 and CIFAR-100, we show the efficacy of adversarial training and TABA in defending adversarial attacks.",
    "path": "papers/23/03/2303.17764.json",
    "total_tokens": 931,
    "translated_title": "朝向对抗鲁棒的持续学习",
    "translated_abstract": "最近的研究表明，经过持续学习训练的模型可以达到与标准监督学习相当的性能，并且持续学习模型的学习灵活性使得它们在实际应用中具有广泛的应用前景。然而，深度学习模型显示出对抗攻击的弱点。虽然在标准监督学习的情况下有许多关于模型鲁棒性的研究，但保护持续学习免受对抗攻击尚未受到研究。为了填补这一研究空白，我们是首次研究持续学习中的对抗鲁棒性，并提出一种名为任务感知边界增强（Task-Aware Boundary Augmentation，TABA）的新方法来提高持续学习模型的鲁棒性。通过在CIFAR-10和CIFAR-100上进行全面的实验，我们展示了对抗训练和TABA在防御对抗攻击方面的有效性。",
    "tldr": "该论文是关于在持续学习中提高对抗鲁棒性的研究，首次提出一种新方法“任务感知边界增强（TABA）”，并在CIFAR-10和CIFAR-100上进行了充分的实验验证其有效性。"
}