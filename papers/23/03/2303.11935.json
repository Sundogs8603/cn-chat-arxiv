{
    "title": "Vision Transformer-based Model for Severity Quantification of Lung Pneumonia Using Chest X-ray Images. (arXiv:2303.11935v1 [eess.IV])",
    "abstract": "To develop generic and reliable approaches for diagnosing and assessing the severity of COVID-19 from chest X-rays (CXR), a large number of well-maintained COVID-19 datasets are needed. Existing severity quantification architectures require expensive training calculations to achieve the best results. For healthcare professionals to quickly and automatically identify COVID-19 patients and predict associated severity indicators, computer utilities are needed. In this work, we propose a Vision Transformer (ViT)-based neural network model that relies on a small number of trainable parameters to quantify the severity of COVID-19 and other lung diseases. We present a feasible approach to quantify the severity of CXR, called Vision Transformer Regressor Infection Prediction (ViTReg-IP), derived from a ViT and a regression head. We investigate the generalization potential of our model using a variety of additional test chest radiograph datasets from different open sources. In this context, we ",
    "link": "http://arxiv.org/abs/2303.11935",
    "context": "Title: Vision Transformer-based Model for Severity Quantification of Lung Pneumonia Using Chest X-ray Images. (arXiv:2303.11935v1 [eess.IV])\nAbstract: To develop generic and reliable approaches for diagnosing and assessing the severity of COVID-19 from chest X-rays (CXR), a large number of well-maintained COVID-19 datasets are needed. Existing severity quantification architectures require expensive training calculations to achieve the best results. For healthcare professionals to quickly and automatically identify COVID-19 patients and predict associated severity indicators, computer utilities are needed. In this work, we propose a Vision Transformer (ViT)-based neural network model that relies on a small number of trainable parameters to quantify the severity of COVID-19 and other lung diseases. We present a feasible approach to quantify the severity of CXR, called Vision Transformer Regressor Infection Prediction (ViTReg-IP), derived from a ViT and a regression head. We investigate the generalization potential of our model using a variety of additional test chest radiograph datasets from different open sources. In this context, we ",
    "path": "papers/23/03/2303.11935.json",
    "total_tokens": 951,
    "translated_title": "基于视觉转换器的模型用于使用胸部 X 射线图像量化肺炎的严重程度",
    "translated_abstract": "为了针对胸部 X 射线（CXR）开发诊断和评估 COVID-19 的严重程度的通用和可靠方法，需要大量维护良好的 COVID-19 数据集。现有的严重程度量化结构需要昂贵的训练计算才能取得最好的结果。需要计算机工具，以便医疗保健专业人员快速自动识别 COVID-19 患者并预测相关的严重程度指标。在本研究中，我们提出了一种基于视觉转换器（ViT）的神经网络模型，该模型依靠少量可训练参数来量化 COVID-19 和其他肺部疾病的严重程度。我们提出了一种可行的方法来量化 CXR 的严重程度，称为 Vision Transformer Regressor Infection Prediction（ViTReg-IP），它由 ViT 和一个回归头导出。我们使用来自不同开放源的各种其他测试胸部放射图数据集来研究我们模型的泛化潜力。",
    "tldr": "本论文提出了一种基于视觉转换器的模型，可以使用少量可训练参数量化 COVID-19 和其他肺部疾病的严重程度，具有较好的基于数据集的泛化性能。",
    "en_tdlr": "This paper proposes a Vision Transformer-based model that relies on a small number of trainable parameters to quantify the severity of COVID-19 and other lung diseases, which has good generalized performance based on dataset, and can be used to automatically identify COVID-19 patients and predict associated severity indicators."
}