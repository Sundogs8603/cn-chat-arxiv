{
    "title": "Implementation and (Inverse Modified) Error Analysis for implicitly-templated ODE-nets. (arXiv:2303.17824v1 [math.NA])",
    "abstract": "We focus on learning hidden dynamics from data using ODE-nets templated on implicit numerical initial value problem solvers. First, we perform Inverse Modified error analysis of the ODE-nets using unrolled implicit schemes for ease of interpretation. It is shown that training an ODE-net using an unrolled implicit scheme returns a close approximation of an Inverse Modified Differential Equation (IMDE). In addition, we establish a theoretical basis for hyper-parameter selection when training such ODE-nets, whereas current strategies usually treat numerical integration of ODE-nets as a black box. We thus formulate an adaptive algorithm which monitors the level of error and adapts the number of (unrolled) implicit solution iterations during the training process, so that the error of the unrolled approximation is less than the current learning loss. This helps accelerate training, while maintaining accuracy. Several numerical experiments are performed to demonstrate the advantages of the pr",
    "link": "http://arxiv.org/abs/2303.17824",
    "context": "Title: Implementation and (Inverse Modified) Error Analysis for implicitly-templated ODE-nets. (arXiv:2303.17824v1 [math.NA])\nAbstract: We focus on learning hidden dynamics from data using ODE-nets templated on implicit numerical initial value problem solvers. First, we perform Inverse Modified error analysis of the ODE-nets using unrolled implicit schemes for ease of interpretation. It is shown that training an ODE-net using an unrolled implicit scheme returns a close approximation of an Inverse Modified Differential Equation (IMDE). In addition, we establish a theoretical basis for hyper-parameter selection when training such ODE-nets, whereas current strategies usually treat numerical integration of ODE-nets as a black box. We thus formulate an adaptive algorithm which monitors the level of error and adapts the number of (unrolled) implicit solution iterations during the training process, so that the error of the unrolled approximation is less than the current learning loss. This helps accelerate training, while maintaining accuracy. Several numerical experiments are performed to demonstrate the advantages of the pr",
    "path": "papers/23/03/2303.17824.json",
    "total_tokens": 938,
    "translated_title": "隐式模板化ODE-nets的实现和(反转修正)误差分析",
    "translated_abstract": "本文着重研究使用基于隐式数值初值问题求解器模板的ODE-nets来学习数据中的隐含动力学。首先，我们使用展开的隐式方案对ODE-nets进行反转修正误差分析以方便解释。结果表明，使用展开的隐式方案对ODE-nets进行训练返回了一个接近于反转修正微分方程(IMDE)的近似值。此外，我们建立了针对训练此类ODE-nets进行超参数选择的理论基础，而当前的策略通常将ODE-nets的数值积分视为黑匣子。因此，我们制定了一种自适应算法，在训练过程中监测误差级别并调整(展开的)隐式解法的迭代次数，以使展开的近似误差小于当前的学习损失。这有助于加速训练，同时保持精度。我们进行了多个数值实验以展示该方法的优越性。",
    "tldr": "本文重点研究使用隐式数值初值问题求解器模板的ODE-nets。使用展开的隐式方案对ODE-nets进行训练可以返回一个接近于反转修正微分方程(IMDE)的近似值，并且我们可以使用自适应算法加速训练并保持精度。",
    "en_tdlr": "This paper focuses on ODE-nets templated on implicit numerical initial value problem solvers. By using unrolled implicit schemes for training, the ODE-net can closely approximate an Inverse Modified Differential Equation (IMDE). The authors establish a theoretical basis for hyper-parameter selection and propose an adaptive algorithm to accelerate training while maintaining accuracy."
}