{
    "title": "OpenMix: Exploring Outlier Samples for Misclassification Detection. (arXiv:2303.17093v1 [cs.LG])",
    "abstract": "Reliable confidence estimation for deep neural classifiers is a challenging yet fundamental requirement in high-stakes applications. Unfortunately, modern deep neural networks are often overconfident for their erroneous predictions. In this work, we exploit the easily available outlier samples, i.e., unlabeled samples coming from non-target classes, for helping detect misclassification errors. Particularly, we find that the well-known Outlier Exposure, which is powerful in detecting out-of-distribution (OOD) samples from unknown classes, does not provide any gain in identifying misclassification errors. Based on these observations, we propose a novel method called OpenMix, which incorporates open-world knowledge by learning to reject uncertain pseudo-samples generated via outlier transformation. OpenMix significantly improves confidence reliability under various scenarios, establishing a strong and unified framework for detecting both misclassified samples from known classes and OOD sa",
    "link": "http://arxiv.org/abs/2303.17093",
    "context": "Title: OpenMix: Exploring Outlier Samples for Misclassification Detection. (arXiv:2303.17093v1 [cs.LG])\nAbstract: Reliable confidence estimation for deep neural classifiers is a challenging yet fundamental requirement in high-stakes applications. Unfortunately, modern deep neural networks are often overconfident for their erroneous predictions. In this work, we exploit the easily available outlier samples, i.e., unlabeled samples coming from non-target classes, for helping detect misclassification errors. Particularly, we find that the well-known Outlier Exposure, which is powerful in detecting out-of-distribution (OOD) samples from unknown classes, does not provide any gain in identifying misclassification errors. Based on these observations, we propose a novel method called OpenMix, which incorporates open-world knowledge by learning to reject uncertain pseudo-samples generated via outlier transformation. OpenMix significantly improves confidence reliability under various scenarios, establishing a strong and unified framework for detecting both misclassified samples from known classes and OOD sa",
    "path": "papers/23/03/2303.17093.json",
    "total_tokens": 853,
    "translated_title": "OpenMix: 探索异常样本以检测分类错误",
    "translated_abstract": "在高风险应用中，可靠的深度神经分类器置信度估计是一个具有挑战性但基本要求。然而，现代深度神经网络通常对其错误预测过于自信。在这项工作中，我们利用易于获取的异常样本，即来自非目标类的未标记样本，帮助检测分类错误。特别地，我们发现出名的Outlier Exposure在检测未知类别的样本中非常强大，但在识别分类错误方面并没有提供任何帮助。基于这些观察，我们提出了一种名为OpenMix的新方法，通过学习拒绝通过异常转换生成的不确定伪样本来融合开放世界的知识。OpenMix在各种情境下显著提高了可靠性，建立了一个强大而统一的框架，用于检测已知类别的分类错误和未知类别的OOD样本。",
    "tldr": "该论文介绍了一种名为OpenMix的新方法，通过学习拒绝异常样本生成的伪样本来提高深度神经分类器的可靠性，从而检测已知类别的分类错误和未知类别的OOD样本。",
    "en_tdlr": "This paper presents a novel method called OpenMix that improves the reliability of deep neural classifiers by learning to reject uncertain pseudo-samples generated via outlier transformation, and thus detects misclassified samples from known classes and OOD samples from unknown classes."
}