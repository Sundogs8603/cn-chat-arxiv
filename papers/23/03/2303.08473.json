{
    "title": "Unsupervised Traffic Scene Generation with Synthetic 3D Scene Graphs. (arXiv:2303.08473v1 [cs.CV])",
    "abstract": "Image synthesis driven by computer graphics achieved recently a remarkable realism, yet synthetic image data generated this way reveals a significant domain gap with respect to real-world data. This is especially true in autonomous driving scenarios, which represent a critical aspect for overcoming utilizing synthetic data for training neural networks. We propose a method based on domain-invariant scene representation to directly synthesize traffic scene imagery without rendering. Specifically, we rely on synthetic scene graphs as our internal representation and introduce an unsupervised neural network architecture for realistic traffic scene synthesis. We enhance synthetic scene graphs with spatial information about the scene and demonstrate the effectiveness of our approach through scene manipulation.",
    "link": "http://arxiv.org/abs/2303.08473",
    "context": "Title: Unsupervised Traffic Scene Generation with Synthetic 3D Scene Graphs. (arXiv:2303.08473v1 [cs.CV])\nAbstract: Image synthesis driven by computer graphics achieved recently a remarkable realism, yet synthetic image data generated this way reveals a significant domain gap with respect to real-world data. This is especially true in autonomous driving scenarios, which represent a critical aspect for overcoming utilizing synthetic data for training neural networks. We propose a method based on domain-invariant scene representation to directly synthesize traffic scene imagery without rendering. Specifically, we rely on synthetic scene graphs as our internal representation and introduce an unsupervised neural network architecture for realistic traffic scene synthesis. We enhance synthetic scene graphs with spatial information about the scene and demonstrate the effectiveness of our approach through scene manipulation.",
    "path": "papers/23/03/2303.08473.json",
    "total_tokens": 775,
    "translated_title": "用合成的3D场景图生成无人驾驶交通场景",
    "translated_abstract": "近年来，由计算机图形学驱动的图像合成已经达到了显著的逼真度，然而这种方式生成的合成图像与真实世界的数据之间存在着显著的领域差距。这在自动驾驶场景中尤为明显，而自动驾驶场景又是利用合成数据进行神经网络训练最为关键的方面。我们提出了一种基于领域不变场景表示的方法，直接合成交通场景图像而不进行渲染。具体而言，我们依赖于合成场景图作为我们的内部表示，并引入了一种无监督的神经网络结构来实现逼真的交通场景合成。我们利用空间场景信息增强了合成场景图，并通过场景操作证明了我们的方法的有效性。",
    "tldr": "本文提出了一种基于领域不变场景表示的方法，使用合成场景图直接合成逼真的交通场景，提高了合成场景图的空间信息，并通过场景操作证明了我们的方法的有效性。",
    "en_tdlr": "The paper proposes a method to directly synthesize realistic traffic scenes using synthetic 3D scene graphs as a domain-invariant representation, and enhances the graphs with spatial information. The effectiveness of the approach is demonstrated through scene manipulation."
}