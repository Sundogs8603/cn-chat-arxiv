{
    "title": "Large Language Models and Simple, Stupid Bugs. (arXiv:2303.11455v1 [cs.SE])",
    "abstract": "With the advent of powerful neural language models, AI-based systems to assist developers in coding tasks are becoming widely available; Copilot is one such system. Copilot uses Codex, a large language model (LLM), to complete code conditioned on a preceding \"prompt\". Codex, however, is trained on public GitHub repositories, viz., on code that may include bugs and vulnerabilities. Previous studies [1], [2] show Codex reproduces vulnerabilities seen in training. In this study, we examine how prone Codex is to generate an interesting bug category, single statement bugs, commonly referred to as simple, stupid bugs or SStuBs in the MSR community. We find that Codex and similar LLMs do help avoid some SStuBs, but do produce known, verbatim SStuBs as much as 2x as likely than known, verbatim correct code. We explore the consequences of the Codex generated SStuBs and propose avoidance strategies that suggest the possibility of reducing the production of known, verbatim SStubs, and increase th",
    "link": "http://arxiv.org/abs/2303.11455",
    "context": "Title: Large Language Models and Simple, Stupid Bugs. (arXiv:2303.11455v1 [cs.SE])\nAbstract: With the advent of powerful neural language models, AI-based systems to assist developers in coding tasks are becoming widely available; Copilot is one such system. Copilot uses Codex, a large language model (LLM), to complete code conditioned on a preceding \"prompt\". Codex, however, is trained on public GitHub repositories, viz., on code that may include bugs and vulnerabilities. Previous studies [1], [2] show Codex reproduces vulnerabilities seen in training. In this study, we examine how prone Codex is to generate an interesting bug category, single statement bugs, commonly referred to as simple, stupid bugs or SStuBs in the MSR community. We find that Codex and similar LLMs do help avoid some SStuBs, but do produce known, verbatim SStuBs as much as 2x as likely than known, verbatim correct code. We explore the consequences of the Codex generated SStuBs and propose avoidance strategies that suggest the possibility of reducing the production of known, verbatim SStubs, and increase th",
    "path": "papers/23/03/2303.11455.json",
    "total_tokens": 969,
    "translated_title": "大型语言模型与简单愚蠢 Bug",
    "translated_abstract": "随着强大的神经语言模型的出现，用于辅助开发者进行编码任务的基于AI的系统变得普遍可用；Copilot便是这样的系统。Copilot使用Codex这个大型语言模型（LLM）来完成一个相应的“提示”后的代码。然而，Codex是在公共GitHub存储库上训练的，即可能包含错误和漏洞的代码。先前的研究表明Codex会复制训练中出现的漏洞。在这项研究中，我们研究了Codex生成的一个有趣的 Bug 类型的易发性，即单语句 Bug，通常被称为简单愚蠢 Bug 或 SStuBs。我们发现Codex和类似的LLMs确实有助于避免一些SStuBs，但确实会生成已知的，逐字的SStuBs，其出现的可能性是已知正确代码的2倍。我们探讨了Codex生成的SStuBs的后果，并提出了避免策略，这些策略可能有助于减少已知的，逐字的SStubs的生产，并增加有创意的Bug的生产。",
    "tldr": "本文研究表明，大型语言模型如Codex虽然有助于避免一些简单Bug，但经常会生成已知的，逐字的Bug，因此需要采取避免策略来减少这种情况，并增加有创意的Bug的生产。",
    "en_tdlr": "This study shows that large language models such as Codex can help avoid some simple bugs, but frequently generate known verbatim bugs, indicating the need for avoidance strategies to reduce this and increase the production of creative bugs."
}