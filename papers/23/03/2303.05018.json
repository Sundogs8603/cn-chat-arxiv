{
    "title": "Improved Regret Bounds for Online Kernel Selection under Bandit Feedback. (arXiv:2303.05018v2 [cs.LG] UPDATED)",
    "abstract": "In this paper, we improve the regret bound for online kernel selection under bandit feedback. Previous algorithm enjoys a $O((\\Vert f\\Vert^2_{\\mathcal{H}_i}+1)K^{\\frac{1}{3}}T^{\\frac{2}{3}})$ expected bound for Lipschitz loss functions. We prove two types of regret bounds improving the previous bound. For smooth loss functions, we propose an algorithm with a $O(U^{\\frac{2}{3}}K^{-\\frac{1}{3}}(\\sum^K_{i=1}L_T(f^\\ast_i))^{\\frac{2}{3}})$ expected bound where $L_T(f^\\ast_i)$ is the cumulative losses of optimal hypothesis in $\\mathbb{H}_{i}=\\{f\\in\\mathcal{H}_i:\\Vert f\\Vert_{\\mathcal{H}_i}\\leq U\\}$. The data-dependent bound keeps the previous worst-case bound and is smaller if most of candidate kernels match well with the data. For Lipschitz loss functions, we propose an algorithm with a $O(U\\sqrt{KT}\\ln^{\\frac{2}{3}}{T})$ expected bound asymptotically improving the previous bound. We apply the two algorithms to online kernel selection with time constraint and prove new regret bounds matchin",
    "link": "http://arxiv.org/abs/2303.05018",
    "context": "Title: Improved Regret Bounds for Online Kernel Selection under Bandit Feedback. (arXiv:2303.05018v2 [cs.LG] UPDATED)\nAbstract: In this paper, we improve the regret bound for online kernel selection under bandit feedback. Previous algorithm enjoys a $O((\\Vert f\\Vert^2_{\\mathcal{H}_i}+1)K^{\\frac{1}{3}}T^{\\frac{2}{3}})$ expected bound for Lipschitz loss functions. We prove two types of regret bounds improving the previous bound. For smooth loss functions, we propose an algorithm with a $O(U^{\\frac{2}{3}}K^{-\\frac{1}{3}}(\\sum^K_{i=1}L_T(f^\\ast_i))^{\\frac{2}{3}})$ expected bound where $L_T(f^\\ast_i)$ is the cumulative losses of optimal hypothesis in $\\mathbb{H}_{i}=\\{f\\in\\mathcal{H}_i:\\Vert f\\Vert_{\\mathcal{H}_i}\\leq U\\}$. The data-dependent bound keeps the previous worst-case bound and is smaller if most of candidate kernels match well with the data. For Lipschitz loss functions, we propose an algorithm with a $O(U\\sqrt{KT}\\ln^{\\frac{2}{3}}{T})$ expected bound asymptotically improving the previous bound. We apply the two algorithms to online kernel selection with time constraint and prove new regret bounds matchin",
    "path": "papers/23/03/2303.05018.json",
    "total_tokens": 1152,
    "translated_title": "在Bandit反馈下在线内核选择的改进遗憾界限",
    "translated_abstract": "本文研究了在线内核选择的带有Bandit反馈的遗憾界限，提出了两种改进的界限。对于光滑的损失函数，我们提出了一种算法，其预期界限为$O(U^{\\frac{2}{3}}K^{-\\frac{1}{3}}(\\sum^K_{i=1}L_T(f^\\ast_i))^{\\frac{2}{3}})$，其中$L_T(f^\\ast_i)$是$\\mathbb{H}_{i}=\\{f\\in\\mathcal{H}_i:\\Vert f\\Vert_{\\mathcal{H}_i}\\leq U\\}$中的最优假设的累积损失。对于Lipschitz损失函数，我们提出了一种算法，其预期界限为$O(U\\sqrt{KT}\\ln^{\\frac{2}{3}}{T})$。本文还将这两种算法应用于具有时间约束的在线内核选择中，并证明了新的遗憾界限，从而改进了现有的贡献。",
    "tldr": "本文研究了在线内核选择的带有Bandit反馈的遗憾界限，提出了两种改进的界限。其中一种适用于光滑的损失函数，另一种则适用于Lipschitz损失函数，预期界限分别为$O(U^{\\frac{2}{3}}K^{-\\frac{1}{3}}(\\sum^K_{i=1}L_T(f^\\ast_i))^{\\frac{2}{3}})$和$O(U\\sqrt{KT}\\ln^{\\frac{2}{3}}{T})$，并将其应用于具有时间约束的在线内核选择中。"
}