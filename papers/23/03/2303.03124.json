{
    "title": "IFAN: An Explainability-Focused Interaction Framework for Humans and NLP Models. (arXiv:2303.03124v2 [cs.CL] UPDATED)",
    "abstract": "Interpretability and human oversight are fundamental pillars of deploying complex NLP models into real-world applications. However, applying explainability and human-in-the-loop methods requires technical proficiency. Despite existing toolkits for model understanding and analysis, options to integrate human feedback are still limited. We propose IFAN, a framework for real-time explanation-based interaction with NLP models. Through IFAN's interface, users can provide feedback to selected model explanations, which is then integrated through adapter layers to align the model with human rationale. We show the system to be effective in debiasing a hate speech classifier with minimal impact on performance. IFAN also offers a visual admin system and API to manage models (and datasets) as well as control access rights. A demo is live at https://ifan.ml.",
    "link": "http://arxiv.org/abs/2303.03124",
    "context": "Title: IFAN: An Explainability-Focused Interaction Framework for Humans and NLP Models. (arXiv:2303.03124v2 [cs.CL] UPDATED)\nAbstract: Interpretability and human oversight are fundamental pillars of deploying complex NLP models into real-world applications. However, applying explainability and human-in-the-loop methods requires technical proficiency. Despite existing toolkits for model understanding and analysis, options to integrate human feedback are still limited. We propose IFAN, a framework for real-time explanation-based interaction with NLP models. Through IFAN's interface, users can provide feedback to selected model explanations, which is then integrated through adapter layers to align the model with human rationale. We show the system to be effective in debiasing a hate speech classifier with minimal impact on performance. IFAN also offers a visual admin system and API to manage models (and datasets) as well as control access rights. A demo is live at https://ifan.ml.",
    "path": "papers/23/03/2303.03124.json",
    "total_tokens": 815,
    "translated_title": "IFAN：面向人类和NLP模型的可解释性交互框架",
    "translated_abstract": "可解释性和人类监督是将复杂NLP模型应用于实际应用的基本支柱。然而，应用解释性和人机交互方法需要技术熟练。尽管存在用于模型理解和分析的工具包，但集成人类反馈的选项仍然有限。我们提出了IFAN，一种用于与NLP模型进行实时基于解释的交互的框架。通过IFAN的界面，用户可以对选择的模型解释提供反馈，然后通过适配器层将其与人类的理性进行对齐。我们展示了该系统在最小影响性能的情况下，对减轻偏见的仇恨言论分类器十分有效。IFAN还提供了一个可视化的管理系统和API，用于管理模型（和数据集）以及控制访问权限。演示地址：https://ifan.ml。",
    "tldr": "IFAN是一个面向人类和NLP模型的可解释性交互框架，通过用户的实时反馈和适配器层的对齐，有效地减轻了偏见的仇恨言论分类器。",
    "en_tdlr": "IFAN is an explainability-focused interaction framework for humans and NLP models, which effectively mitigates bias in hate speech classifiers through real-time user feedback and alignment with human rationale via adapter layers."
}