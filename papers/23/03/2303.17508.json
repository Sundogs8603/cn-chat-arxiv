{
    "title": "Learning in Factored Domains with Information-Constrained Visual Representations. (arXiv:2303.17508v1 [cs.AI])",
    "abstract": "Humans learn quickly even in tasks that contain complex visual information. This is due in part to the efficient formation of compressed representations of visual information, allowing for better generalization and robustness. However, compressed representations alone are insufficient for explaining the high speed of human learning. Reinforcement learning (RL) models that seek to replicate this impressive efficiency may do so through the use of factored representations of tasks. These informationally simplistic representations of tasks are similarly motivated as the use of compressed representations of visual information. Recent studies have connected biological visual perception to disentangled and compressed representations. This raises the question of how humans learn to efficiently represent visual information in a manner useful for learning tasks. In this paper we present a model of human factored representation learning based on an altered form of a $\\beta$-Variational Auto-encod",
    "link": "http://arxiv.org/abs/2303.17508",
    "context": "Title: Learning in Factored Domains with Information-Constrained Visual Representations. (arXiv:2303.17508v1 [cs.AI])\nAbstract: Humans learn quickly even in tasks that contain complex visual information. This is due in part to the efficient formation of compressed representations of visual information, allowing for better generalization and robustness. However, compressed representations alone are insufficient for explaining the high speed of human learning. Reinforcement learning (RL) models that seek to replicate this impressive efficiency may do so through the use of factored representations of tasks. These informationally simplistic representations of tasks are similarly motivated as the use of compressed representations of visual information. Recent studies have connected biological visual perception to disentangled and compressed representations. This raises the question of how humans learn to efficiently represent visual information in a manner useful for learning tasks. In this paper we present a model of human factored representation learning based on an altered form of a $\\beta$-Variational Auto-encod",
    "path": "papers/23/03/2303.17508.json",
    "total_tokens": 926,
    "translated_title": "基于信息受限视觉表示的因子领域学习",
    "translated_abstract": "人类即使在包含复杂视觉信息的任务中也能够快速学习。这部分是由于视觉信息的高效压缩形成，从而可以更好地推广和鲁棒性。然而，仅有压缩表示是无法解释人类学习高速度的原因的。寻求复制这种印象的效率的强化学习（RL）模型可能通过使用任务的因子表示来实现。这些信息简单的任务表示与视觉信息的压缩表示的使用类似。最近的研究将生物视觉感知与分离的压缩表示联系起来。这引出了一个问题，即人类如何学习有效地表达有助于学习任务的视觉信息。在本文中，我们提出了一种基于$\\beta$-变分自动编码器（VAE）的改变形式的人类因子表示学习模型，该模型允许视觉信息的表示按照任务相关信息进行塑造。我们展示了这个模型能够学习以一种促进在因子领域中RL任务更快学习的方式有效地表示视觉信息。",
    "tldr": "本文提出了一种基于信息约束的视觉表示的因子领域学习模型，该模型能够促进在因子领域中RL任务的学习速度。"
}