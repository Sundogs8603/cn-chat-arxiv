{
    "title": "ReCOGS: How Incidental Details of a Logical Form Overshadow an Evaluation of Semantic Interpretation. (arXiv:2303.13716v1 [cs.CL])",
    "abstract": "Compositional generalization benchmarks seek to assess whether models can accurately compute meanings for novel sentences, but operationalize this in terms of logical form (LF) prediction. This raises the concern that semantically irrelevant details of the chosen LFs could shape model performance. We argue that this concern is realized for the COGS benchmark (Kim and Linzen, 2020). COGS poses generalization splits that appear impossible for present-day models, which could be taken as an indictment of those models. However, we show that the negative results trace to incidental features of COGS LFs. Converting these LFs to semantically equivalent ones and factoring out capabilities unrelated to semantic interpretation, we find that even baseline models get traction. A recent variable-free translation of COGS LFs suggests similar conclusions, but we observe this format is not semantically equivalent; it is incapable of accurately representing some COGS meanings. These findings inform our ",
    "link": "http://arxiv.org/abs/2303.13716",
    "context": "Title: ReCOGS: How Incidental Details of a Logical Form Overshadow an Evaluation of Semantic Interpretation. (arXiv:2303.13716v1 [cs.CL])\nAbstract: Compositional generalization benchmarks seek to assess whether models can accurately compute meanings for novel sentences, but operationalize this in terms of logical form (LF) prediction. This raises the concern that semantically irrelevant details of the chosen LFs could shape model performance. We argue that this concern is realized for the COGS benchmark (Kim and Linzen, 2020). COGS poses generalization splits that appear impossible for present-day models, which could be taken as an indictment of those models. However, we show that the negative results trace to incidental features of COGS LFs. Converting these LFs to semantically equivalent ones and factoring out capabilities unrelated to semantic interpretation, we find that even baseline models get traction. A recent variable-free translation of COGS LFs suggests similar conclusions, but we observe this format is not semantically equivalent; it is incapable of accurately representing some COGS meanings. These findings inform our ",
    "path": "papers/23/03/2303.13716.json",
    "total_tokens": 1032,
    "translated_title": "ReCOGS: 一个逻辑形式的细节如何影响语义解释的评估",
    "translated_abstract": "合成通用基准旨在评估模型是否能够准确地计算新句子的含义，但是用逻辑形式（LF）预测来操作。这引发了一个担忧，即所选择的LF的语义无关的细节可能会塑造模型的性能。我们认为COGS基准（Kim和Linzen，2020）实现了这一关注点。COGS提出了看起来对现有模型来说不可能的通用分割，这可能被视为对这些模型的控诉。然而，我们表明负面结果跟COGS LFs的细节相关。将这些LF转换为语义等效的LF，并分解出与语义解释无关的能力，我们发现即使是基线模型也能获得足够的掌握。最近的COGS LFs无变量翻译表明了类似的结论，但我们观察到这种格式不是语义等效的；它无法准确表示一些COGS的含义。这些发现促进我们对当前的合成通用基准的局限性的理解，并强调设计准确捕捉自然语言语义的LF的重要性。",
    "tldr": "本文研究了合成通用基准的局限性，发现逻辑形式（LF）的细节可能影响模型性能。作者对COGS基准进行了研究，结果表明基础模型能够获得足够的掌握。作者还强调了设计能准确捕捉自然语言语义的LF的重要性。",
    "en_tdlr": "This paper examines the limitations of compositional generalization benchmarks and finds that details of logical form (LF) may affect model performance. The authors studied the COGS benchmark and found that even baseline models can achieve sufficient mastery once semantically equivalent LFs are used. The importance of designing LFs that accurately capture natural language semantics is emphasized."
}