{
    "title": "Semi-supervised counterfactual explanations. (arXiv:2303.12634v1 [cs.LG])",
    "abstract": "Counterfactual explanations for machine learning models are used to find minimal interventions to the feature values such that the model changes the prediction to a different output or a target output. A valid counterfactual explanation should have likely feature values. Here, we address the challenge of generating counterfactual explanations that lie in the same data distribution as that of the training data and more importantly, they belong to the target class distribution. This requirement has been addressed through the incorporation of auto-encoder reconstruction loss in the counterfactual search process. Connecting the output behavior of the classifier to the latent space of the auto-encoder has further improved the speed of the counterfactual search process and the interpretability of the resulting counterfactual explanations. Continuing this line of research, we show further improvement in the interpretability of counterfactual explanations when the auto-encoder is trained in a ",
    "link": "http://arxiv.org/abs/2303.12634",
    "context": "Title: Semi-supervised counterfactual explanations. (arXiv:2303.12634v1 [cs.LG])\nAbstract: Counterfactual explanations for machine learning models are used to find minimal interventions to the feature values such that the model changes the prediction to a different output or a target output. A valid counterfactual explanation should have likely feature values. Here, we address the challenge of generating counterfactual explanations that lie in the same data distribution as that of the training data and more importantly, they belong to the target class distribution. This requirement has been addressed through the incorporation of auto-encoder reconstruction loss in the counterfactual search process. Connecting the output behavior of the classifier to the latent space of the auto-encoder has further improved the speed of the counterfactual search process and the interpretability of the resulting counterfactual explanations. Continuing this line of research, we show further improvement in the interpretability of counterfactual explanations when the auto-encoder is trained in a ",
    "path": "papers/23/03/2303.12634.json",
    "total_tokens": 870,
    "translated_title": "半监督对抗性解释",
    "translated_abstract": "机器学习模型的对抗性解释是用于查找最小干预特征值的方法，使得模型将预测更改为不同的输出或目标输出。有效的对抗性解释应具有可能的特征值。在本文中，我们解决了生成对抗性解释的挑战，使其处于与训练数据相同的数据分布中，并且更重要的是，它们属于目标类分布。通过在对抗性搜索过程中结合自编码器重构损失来解决这个要求。将分类器的输出行为与自编码器的潜在空间连接，进一步提高了对抗性搜索过程的速度和生成结果的解释性。在这一研究领域的持续努力下，我们展示了当自编码器在半监督状态下被训练时，对抗性解释的可解释性进一步提高。",
    "tldr": "本论文介绍了一种半监督对抗性解释的方法，通过在对抗性搜索过程中结合自编码器重构损失和将分类器的输出行为与自编码器的潜在空间连接，提高了对抗性搜索过程的速度和生成结果的解释性。",
    "en_tdlr": "This paper introduces a method of semi-supervised counterfactual explanations, which incorporates auto-encoder reconstruction loss in the counterfactual search process and connects the output behavior of the classifier to the latent space of the auto-encoder, improving the speed and interpretability of the search process."
}