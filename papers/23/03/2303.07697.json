{
    "title": "DisCoHead: Audio-and-Video-Driven Talking Head Generation by Disentangled Control of Head Pose and Facial Expressions. (arXiv:2303.07697v1 [cs.CV])",
    "abstract": "For realistic talking head generation, creating natural head motion while maintaining accurate lip synchronization is essential. To fulfill this challenging task, we propose DisCoHead, a novel method to disentangle and control head pose and facial expressions without supervision. DisCoHead uses a single geometric transformation as a bottleneck to isolate and extract head motion from a head-driving video. Either an affine or a thin-plate spline transformation can be used and both work well as geometric bottlenecks. We enhance the efficiency of DisCoHead by integrating a dense motion estimator and the encoder of a generator which are originally separate modules. Taking a step further, we also propose a neural mix approach where dense motion is estimated and applied implicitly by the encoder. After applying the disentangled head motion to a source identity, DisCoHead controls the mouth region according to speech audio, and it blinks eyes and moves eyebrows following a separate driving vid",
    "link": "http://arxiv.org/abs/2303.07697",
    "context": "Title: DisCoHead: Audio-and-Video-Driven Talking Head Generation by Disentangled Control of Head Pose and Facial Expressions. (arXiv:2303.07697v1 [cs.CV])\nAbstract: For realistic talking head generation, creating natural head motion while maintaining accurate lip synchronization is essential. To fulfill this challenging task, we propose DisCoHead, a novel method to disentangle and control head pose and facial expressions without supervision. DisCoHead uses a single geometric transformation as a bottleneck to isolate and extract head motion from a head-driving video. Either an affine or a thin-plate spline transformation can be used and both work well as geometric bottlenecks. We enhance the efficiency of DisCoHead by integrating a dense motion estimator and the encoder of a generator which are originally separate modules. Taking a step further, we also propose a neural mix approach where dense motion is estimated and applied implicitly by the encoder. After applying the disentangled head motion to a source identity, DisCoHead controls the mouth region according to speech audio, and it blinks eyes and moves eyebrows following a separate driving vid",
    "path": "papers/23/03/2303.07697.json",
    "total_tokens": 1051,
    "translated_title": "DisCoHead:通过分离控制头部姿势和面部表情的音视频生成谈话头",
    "translated_abstract": "对于逼真的谈话头生成，同时保持准确的唇部同步和自然的头部运动至关重要。为了完成这项艰巨的任务，我们提出了DisCoHead，这是一种新颖的方法，无需监督即可分离和控制头部姿势和面部表情。DisCoHead使用单一的几何变换作为瓶颈，从头部驱动视频中隔离并提取头部运动。可以使用仿射变换或薄板样条变换，两者都可以作为几何瓶颈。我们通过将密集运动估计器和生成器的编码器集成到一起来增强DisCoHead的效率。更进一步，我们还提出了一种神经混合方法，在此方法中，通过编码器隐式地估计和应用密集运动。在将已分离的头部运动应用于源身份之后，DisCoHead根据语音音频控制嘴部区域，根据单独的驱动视频眨眼和移动眉毛。在几个基准测试中进行的广泛实验表明，DisCoHead在视觉质量和同步精度方面超过了现有的最先进方法。",
    "tldr": "DisCoHead是一种新颖的无监督音视频生成谈话头方法，能够分离和控制头部姿势和面部表情，通过使用单一的几何变换和神经混合方法，并将密集运动估计器和生成器的编码器集成在一起，使得生成的头部运动具有更高的质量和同步精度。",
    "en_tdlr": "DisCoHead is a novel unsupervised audio-video generation method for talking head that disentangles and controls head pose and facial expressions. By using a single geometric transformation and a neural mix approach, along with integrating a dense motion estimator and the encoder of a generator, it achieves higher quality and synchronization accuracy in generating head motion."
}