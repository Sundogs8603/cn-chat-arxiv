{
    "title": "ASTRA-sim2.0: Modeling Hierarchical Networks and Disaggregated Systems for Large-model Training at Scale. (arXiv:2303.14006v1 [cs.DC])",
    "abstract": "As deep learning models and input data are scaling at an unprecedented rate, it is inevitable to move towards distributed training platforms to fit the model and increase training throughput. State-of-the-art approaches and techniques, such as wafer-scale nodes, multi-dimensional network topologies, disaggregated memory systems, and parallelization strategies, have been actively adopted by emerging distributed training systems. This results in a complex SW/HW co-design stack of distributed training, necessitating a modeling/simulation infrastructure for design-space exploration. In this paper, we extend the open-source ASTRA-sim infrastructure and endow it with the capabilities to model state-of-the-art and emerging distributed training models and platforms. More specifically, (i) we enable ASTRA-sim to support arbitrary model parallelization strategies via a graph-based training-loop implementation, (ii) we implement a parameterizable multi-dimensional heterogeneous topology generatio",
    "link": "http://arxiv.org/abs/2303.14006",
    "context": "Title: ASTRA-sim2.0: Modeling Hierarchical Networks and Disaggregated Systems for Large-model Training at Scale. (arXiv:2303.14006v1 [cs.DC])\nAbstract: As deep learning models and input data are scaling at an unprecedented rate, it is inevitable to move towards distributed training platforms to fit the model and increase training throughput. State-of-the-art approaches and techniques, such as wafer-scale nodes, multi-dimensional network topologies, disaggregated memory systems, and parallelization strategies, have been actively adopted by emerging distributed training systems. This results in a complex SW/HW co-design stack of distributed training, necessitating a modeling/simulation infrastructure for design-space exploration. In this paper, we extend the open-source ASTRA-sim infrastructure and endow it with the capabilities to model state-of-the-art and emerging distributed training models and platforms. More specifically, (i) we enable ASTRA-sim to support arbitrary model parallelization strategies via a graph-based training-loop implementation, (ii) we implement a parameterizable multi-dimensional heterogeneous topology generatio",
    "path": "papers/23/03/2303.14006.json",
    "total_tokens": 1206,
    "translated_title": "ASTRA-sim2.0: 模拟分层网络和分解系统，实现大型模型训练的规模化",
    "translated_abstract": "随着深度学习模型和输入数据以前所未有的速度扩展，采用分布式训练平台来适应模型并提高训练吞吐量是不可避免的。最先进的方法和技术，如晶圆级节点、多维网络拓扑、分解式内存系统和并行化策略，已经被新兴的分布式训练系统积极采用。这导致了一个复杂的分布式训练软硬件协同设计堆栈，并需要建立一个模拟基础设施以进行设计空间探索。本文在开源的 ASTRA-sim 基础设施上扩展了功能，并赋予其模拟当代分布式训练模型和平台的能力。具体而言，(i) 我们通过基于图的训练循环实现了对任意模型并行化策略的支持，(ii) 我们实现了一个参数化的多维异构拓扑生成模块，(iii) 我们提供了分层内存抽象接口，支持任意分解内存系统，(iv) 我们启用了精细的仪器和事件跟踪。得到的建模基础设施，称为 ASTRA-sim2.0，易于使用且足够灵活，可用于建模各种分布式训练系统，包括利用新兴硬件加速器（如NVM设备和稀疏矩阵加速器）的系统。",
    "tldr": "本文介绍了ASTRA-sim2.0，一种分布式训练模拟基础设施，可模拟当代分布式训练模型和平台。ASTRA-sim2.0易于使用、灵活，支持任意模型并行化策略、多维异构拓扑、任意分解内存系统和精细的仪器和事件跟踪。",
    "en_tdlr": "This paper presents ASTRA-sim2.0, a modeling infrastructure for distributed training that can simulate contemporary distributed training models and platforms. ASTRA-sim2.0 is easy to use and flexible, with support for arbitrary model parallelization strategies, multi-dimensional heterogeneous topologies, arbitrarily disaggregated memory systems, and fine-grained instrumentation and event tracking."
}