{
    "title": "AssetField: Assets Mining and Reconfiguration in Ground Feature Plane Representation. (arXiv:2303.13953v1 [cs.CV])",
    "abstract": "Both indoor and outdoor environments are inherently structured and repetitive. Traditional modeling pipelines keep an asset library storing unique object templates, which is both versatile and memory efficient in practice. Inspired by this observation, we propose AssetField, a novel neural scene representation that learns a set of object-aware ground feature planes to represent the scene, where an asset library storing template feature patches can be constructed in an unsupervised manner. Unlike existing methods which require object masks to query spatial points for object editing, our ground feature plane representation offers a natural visualization of the scene in the bird-eye view, allowing a variety of operations (e.g. translation, duplication, deformation) on objects to configure a new scene. With the template feature patches, group editing is enabled for scenes with many recurring items to avoid repetitive work on object individuals. We show that AssetField not only achieves com",
    "link": "http://arxiv.org/abs/2303.13953",
    "context": "Title: AssetField: Assets Mining and Reconfiguration in Ground Feature Plane Representation. (arXiv:2303.13953v1 [cs.CV])\nAbstract: Both indoor and outdoor environments are inherently structured and repetitive. Traditional modeling pipelines keep an asset library storing unique object templates, which is both versatile and memory efficient in practice. Inspired by this observation, we propose AssetField, a novel neural scene representation that learns a set of object-aware ground feature planes to represent the scene, where an asset library storing template feature patches can be constructed in an unsupervised manner. Unlike existing methods which require object masks to query spatial points for object editing, our ground feature plane representation offers a natural visualization of the scene in the bird-eye view, allowing a variety of operations (e.g. translation, duplication, deformation) on objects to configure a new scene. With the template feature patches, group editing is enabled for scenes with many recurring items to avoid repetitive work on object individuals. We show that AssetField not only achieves com",
    "path": "papers/23/03/2303.13953.json",
    "total_tokens": 922,
    "translated_title": "AssetField：地面特征平面表示中的资产采掘和重构",
    "translated_abstract": "室内和室外环境本质上都是有结构和重复性的。传统建模流程通过保持一个存储独特对象模板的资产库，实现了多种功能实用且内存高效的方式。受此启发，我们提出了AssetField，一种新型的神经场景表示方法，它可以学习一组对象感知的地面特征平面来表示场景，在其中可以以无监督的方式构建存储模板特征块的资产库。与现有方法需要对象掩码来查询空间点以进行对象编辑不同，我们的地面特征平面表示在鸟瞰视图中为场景提供了一种自然的可视化方法，允许对对象进行各种操作（例如平移，重复，变形）以配置新场景。配合使用特征块模板，对于有许多重复物品的场景，可以启用群组编辑，避免在个别对象上重复性工作。我们展示了AssetField不仅实现了很好的性能，而且还提供了一种可解释的联合可视化表示，从而更好地理解场景和建模。",
    "tldr": "本文提出了AssetField，一种新型的神经场景表示方法，通过学习一组对象感知的地面特征平面来表示场景，可实现各种操作以配置新场景，并提供了可解释的联合可视化表示，从而更好地理解场景和建模。",
    "en_tdlr": "The paper proposes AssetField, a novel neural scene representation that learns a set of object-aware ground feature planes to represent the scene, which allows a variety of operations to configure a new scene and provides an interpretable joint visualization representation for better understanding of the scene and modeling."
}