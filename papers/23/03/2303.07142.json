{
    "title": "Large Language Models in the Workplace: A Case Study on Prompt Engineering for Job Type Classification. (arXiv:2303.07142v2 [cs.CL] UPDATED)",
    "abstract": "This case study investigates the task of job classification in a real-world setting, where the goal is to determine whether an English-language job posting is appropriate for a graduate or entry-level position. We explore multiple approaches to text classification, including supervised approaches such as traditional models like Support Vector Machines (SVMs) and state-of-the-art deep learning methods such as DeBERTa. We compare them with Large Language Models (LLMs) used in both few-shot and zero-shot classification settings. To accomplish this task, we employ prompt engineering, a technique that involves designing prompts to guide the LLMs towards the desired output. Specifically, we evaluate the performance of two commercially available state-of-the-art GPT-3.5-based language models, text-davinci-003 and gpt-3.5-turbo. We also conduct a detailed analysis of the impact of different aspects of prompt engineering on the model's performance. Our results show that, with a well-designed pr",
    "link": "http://arxiv.org/abs/2303.07142",
    "context": "Title: Large Language Models in the Workplace: A Case Study on Prompt Engineering for Job Type Classification. (arXiv:2303.07142v2 [cs.CL] UPDATED)\nAbstract: This case study investigates the task of job classification in a real-world setting, where the goal is to determine whether an English-language job posting is appropriate for a graduate or entry-level position. We explore multiple approaches to text classification, including supervised approaches such as traditional models like Support Vector Machines (SVMs) and state-of-the-art deep learning methods such as DeBERTa. We compare them with Large Language Models (LLMs) used in both few-shot and zero-shot classification settings. To accomplish this task, we employ prompt engineering, a technique that involves designing prompts to guide the LLMs towards the desired output. Specifically, we evaluate the performance of two commercially available state-of-the-art GPT-3.5-based language models, text-davinci-003 and gpt-3.5-turbo. We also conduct a detailed analysis of the impact of different aspects of prompt engineering on the model's performance. Our results show that, with a well-designed pr",
    "path": "papers/23/03/2303.07142.json",
    "total_tokens": 974,
    "translated_title": "工作场所中的大型语言模型：一个关于任务提示工程在职业类型分类中的实证研究",
    "translated_abstract": "本文通过探索多种文本分类方法，包括基于监督学习的传统模型如支持向量机（SVMs）以及最先进的深度学习方法，如DeBERTa，以及大型语言模型（LLMs）在少样本和零样本分类情况下的应用，来研究实际工作场所中的职业分类任务。为了完成此任务，我们采用了任务提示工程的技术，即设计提示以引导LLMs达到所需的输出。具体来说，我们评估了两种商业可用的最先进的基于GPT-3.5的语言模型，text-davinci-003和gpt-3.5-turbo。我们还对提示工程的不同方面对模型性能的影响进行了详细的分析。我们的结果表明，在良好设计的提示的帮助下，LLMs在职业类型分类任务上可以达到出色的表现，优于传统方法如SVMs，甚至优于最先进的深度学习方法如DeBERTa。",
    "tldr": "本文探索了工作场所中的职业分类任务，并利用任务提示工程设计了良好的提示，成功地将大型语言模型（LLMs）应用于该任务中，取得了出色的表现，优于传统方法。",
    "en_tdlr": "This case study investigates job type classification in real-world workplace, utilizing prompt engineering to guide large language models (LLMs) towards the desired output. By analyzing the performance of LLMs under various prompts, the study shows that with a well-designed prompt, LLMs outperform traditional methods and even state-of-the-art deep learning methods."
}