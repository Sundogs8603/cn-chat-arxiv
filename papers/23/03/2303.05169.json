{
    "title": "Reconstructing the Hubble parameter with future Gravitational Wave missions using Machine Learning. (arXiv:2303.05169v2 [astro-ph.CO] UPDATED)",
    "abstract": "We study the prospects of Gaussian processes (GP), a machine learning (ML) algorithm, as a tool to reconstruct the Hubble parameter $H(z)$ with two upcoming gravitational wave missions, namely the evolved Laser Interferometer Space Antenna (eLISA) and the Einstein Telescope (ET). Assuming various background cosmological models, the Hubble parameter has been reconstructed in a non-parametric manner with the help of GP using realistically generated catalogs for each mission. The effects of early-time and late-time priors on the reconstruction of $H(z)$, and hence on the Hubble constant ($H_0$), have also been focused on separately. Our analysis reveals that GP is quite robust in reconstructing the expansion history of the Universe within the observational window of the specific missions under consideration. We further confirm that both eLISA and ET would be able to provide constraints on $H(z)$ and $H_0$ which would be competitive to those inferred from current datasets. In particular, w",
    "link": "http://arxiv.org/abs/2303.05169",
    "context": "Title: Reconstructing the Hubble parameter with future Gravitational Wave missions using Machine Learning. (arXiv:2303.05169v2 [astro-ph.CO] UPDATED)\nAbstract: We study the prospects of Gaussian processes (GP), a machine learning (ML) algorithm, as a tool to reconstruct the Hubble parameter $H(z)$ with two upcoming gravitational wave missions, namely the evolved Laser Interferometer Space Antenna (eLISA) and the Einstein Telescope (ET). Assuming various background cosmological models, the Hubble parameter has been reconstructed in a non-parametric manner with the help of GP using realistically generated catalogs for each mission. The effects of early-time and late-time priors on the reconstruction of $H(z)$, and hence on the Hubble constant ($H_0$), have also been focused on separately. Our analysis reveals that GP is quite robust in reconstructing the expansion history of the Universe within the observational window of the specific missions under consideration. We further confirm that both eLISA and ET would be able to provide constraints on $H(z)$ and $H_0$ which would be competitive to those inferred from current datasets. In particular, w",
    "path": "papers/23/03/2303.05169.json",
    "total_tokens": 885,
    "translated_title": "使用机器学习的未来引力波任务重建哈勃参数",
    "translated_abstract": "我们研究了使用高斯过程（GP），一种机器学习算法，通过两个即将到来的引力波任务，即进化的激光干涉空间天线（eLISA）和爱因斯坦望远镜（ET），重建哈勃参数$H(z)$的前景。在假设各种背景宇宙模型的情况下，使用GP以非参数化的方式重建了哈勃参数，并利用每个任务的真实生成目录。我们重点分别关注了早期和后期的先验对$H(z)$和哈勃常数($H_0$)重建的影响。我们的分析表明，在考虑的特定任务的观测窗口范围内，GP在重建宇宙的膨胀历史方面非常稳健。我们进一步确认，eLISA和ET都将能够提供对$H(z)$和$H_0$的约束，这将与当前数据集得出的约束相竞争。尤其是，w",
    "tldr": "本研究使用机器学习算法，通过未来的引力波任务重建了哈勃参数，得出了高斯过程在重建宇宙膨胀历史方面的稳健性，同时也发现未来任务能够提供与当前数据集相竞争的对哈勃参数和哈勃常数的约束。"
}