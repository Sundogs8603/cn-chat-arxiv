{
    "title": "Importance Sampling for Stochastic Gradient Descent in Deep Neural Networks. (arXiv:2303.16529v1 [cs.LG])",
    "abstract": "Stochastic gradient descent samples uniformly the training set to build an unbiased gradient estimate with a limited number of samples. However, at a given step of the training process, some data are more helpful than others to continue learning. Importance sampling for training deep neural networks has been widely studied to propose sampling schemes yielding better performance than the uniform sampling scheme. After recalling the theory of importance sampling for deep learning, this paper reviews the challenges inherent to this research area. In particular, we propose a metric allowing the assessment of the quality of a given sampling scheme; and we study the interplay between the sampling scheme and the optimizer used.",
    "link": "http://arxiv.org/abs/2303.16529",
    "context": "Title: Importance Sampling for Stochastic Gradient Descent in Deep Neural Networks. (arXiv:2303.16529v1 [cs.LG])\nAbstract: Stochastic gradient descent samples uniformly the training set to build an unbiased gradient estimate with a limited number of samples. However, at a given step of the training process, some data are more helpful than others to continue learning. Importance sampling for training deep neural networks has been widely studied to propose sampling schemes yielding better performance than the uniform sampling scheme. After recalling the theory of importance sampling for deep learning, this paper reviews the challenges inherent to this research area. In particular, we propose a metric allowing the assessment of the quality of a given sampling scheme; and we study the interplay between the sampling scheme and the optimizer used.",
    "path": "papers/23/03/2303.16529.json",
    "total_tokens": 834,
    "translated_title": "深度神经网络中的随机梯度下降重要性采样",
    "translated_abstract": "随机梯度下降通过对训练集进行均匀采样，利用有限的样本来构建无偏梯度估计。然而，在训练过程的某个阶段，某些数据比其他数据更有助于继续学习。近年来，已经广泛研究了利用重要性采样来训练深度神经网络的方法，以提出比均匀采样方案更好的采样策略。在回顾深度学习中的重要性采样理论后，本文总结了这一研究领域所面临的挑战。特别是，我们提出了一种度量方法，用于评估给定的采样策略的质量，并研究了采样方案和所使用的优化器之间的相互作用。",
    "tldr": "本文回顾了深度学习中的重要性采样理论，并总结了利用重要性采样来训练深度神经网络所面临的挑战；本文提出了一种度量方法，用于评估给定的采样策略的质量，研究了采样方案和所使用的优化器之间的相互作用。",
    "en_tdlr": "This paper reviews the theory of importance sampling in deep learning and summarizes the challenges for training deep neural networks using importance sampling. It proposes a metric to evaluate the quality of a given sampling scheme and studies the interaction between the sampling scheme and optimizer used."
}