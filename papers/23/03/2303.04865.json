{
    "title": "Convergence Rates for Localized Actor-Critic in Networked Markov Potential Games. (arXiv:2303.04865v2 [cs.LG] UPDATED)",
    "abstract": "We introduce a class of networked Markov potential games in which agents are associated with nodes in a network. Each agent has its own local potential function, and the reward of each agent depends only on the states and actions of the agents within a neighborhood. In this context, we propose a localized actor-critic algorithm. The algorithm is scalable since each agent uses only local information and does not need access to the global state. Further, the algorithm overcomes the curse of dimensionality through the use of function approximation. Our main results provide finite-sample guarantees up to a localization error and a function approximation error. Specifically, we achieve an $\\tilde{\\mathcal{O}}(\\tilde{\\epsilon}^{-4})$ sample complexity measured by the averaged Nash regret. This is the first finite-sample bound for multi-agent competitive games that does not depend on the number of agents.",
    "link": "http://arxiv.org/abs/2303.04865",
    "context": "Title: Convergence Rates for Localized Actor-Critic in Networked Markov Potential Games. (arXiv:2303.04865v2 [cs.LG] UPDATED)\nAbstract: We introduce a class of networked Markov potential games in which agents are associated with nodes in a network. Each agent has its own local potential function, and the reward of each agent depends only on the states and actions of the agents within a neighborhood. In this context, we propose a localized actor-critic algorithm. The algorithm is scalable since each agent uses only local information and does not need access to the global state. Further, the algorithm overcomes the curse of dimensionality through the use of function approximation. Our main results provide finite-sample guarantees up to a localization error and a function approximation error. Specifically, we achieve an $\\tilde{\\mathcal{O}}(\\tilde{\\epsilon}^{-4})$ sample complexity measured by the averaged Nash regret. This is the first finite-sample bound for multi-agent competitive games that does not depend on the number of agents.",
    "path": "papers/23/03/2303.04865.json",
    "total_tokens": 866,
    "translated_title": "网络马尔可夫势博弈中局部演员-评论家算法的收敛速度",
    "translated_abstract": "我们在网络马尔可夫势博弈中引入一类与网络中的节点相关的势博弈。每个代理都有自己的局部势函数，每个代理的奖励只取决于邻域中代理的状态和动作。在这个背景下，我们提出了一种局部演员-评论家算法。该算法具有可扩展性，因为每个代理只使用局部信息，不需要访问全局状态。此外，该算法通过使用函数逼近来克服维度灾难。我们的主要结果在局部化误差和函数逼近误差的情况下提供了有限样本保证。具体而言，我们通过平均纳什遗憾度量，实现了一个$\\tilde{\\mathcal {O}}(\\tilde{\\epsilon}^{-4})$的样本复杂度。这是第一个不依赖于代理数量的多智能体竞争博弈的有限样本界。",
    "tldr": "本文提出了一种网络马尔可夫势博弈中的局部演员-评论家算法，通过局部化和函数逼近技术，实现了有限样本保证，样本复杂度不依赖于代理数量。"
}