{
    "title": "Data-Efficient Learning of Natural Language to Linear Temporal Logic Translators for Robot Task Specification. (arXiv:2303.08006v1 [cs.CL])",
    "abstract": "To make robots accessible to a broad audience, it is critical to endow them with the ability to take universal modes of communication, like commands given in natural language, and extract a concrete desired task specification, defined using a formal language like linear temporal logic (LTL). In this paper, we present a learning-based approach for translating from natural language commands to LTL specifications with very limited human-labeled training data. This is in stark contrast to existing natural-language to LTL translators, which require large human-labeled datasets, often in the form of labeled pairs of LTL formulas and natural language commands, to train the translator. To reduce reliance on human data, our approach generates a large synthetic training dataset through algorithmic generation of LTL formulas, conversion to structured English, and then exploiting the paraphrasing capabilities of modern large language models (LLMs) to synthesize a diverse corpus of natural language",
    "link": "http://arxiv.org/abs/2303.08006",
    "context": "Title: Data-Efficient Learning of Natural Language to Linear Temporal Logic Translators for Robot Task Specification. (arXiv:2303.08006v1 [cs.CL])\nAbstract: To make robots accessible to a broad audience, it is critical to endow them with the ability to take universal modes of communication, like commands given in natural language, and extract a concrete desired task specification, defined using a formal language like linear temporal logic (LTL). In this paper, we present a learning-based approach for translating from natural language commands to LTL specifications with very limited human-labeled training data. This is in stark contrast to existing natural-language to LTL translators, which require large human-labeled datasets, often in the form of labeled pairs of LTL formulas and natural language commands, to train the translator. To reduce reliance on human data, our approach generates a large synthetic training dataset through algorithmic generation of LTL formulas, conversion to structured English, and then exploiting the paraphrasing capabilities of modern large language models (LLMs) to synthesize a diverse corpus of natural language",
    "path": "papers/23/03/2303.08006.json",
    "total_tokens": 849,
    "translated_title": "基于数据有效学习的机器人任务规格自然语言到线性时间逻辑翻译器",
    "translated_abstract": "为了使机器人能够服务于更广泛的受众，赋予其理解自然语言命令并用线性时间逻辑（LTL）等形式语言定义具体任务规格的能力至关重要。本文提出了一种基于学习的方法，能够将自然语言命令翻译成 LTL 规格，而且只需要非常有限的受试者标注训练数据。与现有的自然语言到LTL翻译器相比，这种方法不需要大量的人工标记数据集，而是通过算法生成LTL公式，转换成结构化英语，然后利用现代大型语言模型（LLMs）的改写能力来综合生成多样化的自然语言语料库。",
    "tldr": "本篇论文提出了一种基于学习的方法，通过算法生成 LTL 公式，转换成结构化英语来综合生成多样化的自然语言语料库，从而实现对于自然语言命令的 LTL 规格翻译，而且不需要大量的人工标记数据集。",
    "en_tdlr": "This paper presents a learning-based approach that generates a diverse corpus of natural language through algorithmic generation of LTL formulas and conversion to structured English, which enables the translation of natural language commands to LTL specifications without requiring large amounts of human-labeled datasets."
}