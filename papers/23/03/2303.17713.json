{
    "title": "Mitigating Source Bias for Fairer Weak Supervision. (arXiv:2303.17713v1 [cs.LG])",
    "abstract": "Weak supervision overcomes the label bottleneck, enabling efficient development of training sets. Millions of models trained on such datasets have been deployed in the real world and interact with users on a daily basis. However, the techniques that make weak supervision attractive -- such as integrating any source of signal to estimate unknown labels -- also ensure that the pseudolabels it produces are highly biased. Surprisingly, given everyday use and the potential for increased bias, weak supervision has not been studied from the point of view of fairness. This work begins such a study. Our departure point is the observation that even when a fair model can be built from a dataset with access to ground-truth labels, the corresponding dataset labeled via weak supervision can be arbitrarily unfair. Fortunately, not all is lost: we propose and empirically validate a model for source unfairness in weak supervision, then introduce a simple counterfactual fairness-based technique that can",
    "link": "http://arxiv.org/abs/2303.17713",
    "context": "Title: Mitigating Source Bias for Fairer Weak Supervision. (arXiv:2303.17713v1 [cs.LG])\nAbstract: Weak supervision overcomes the label bottleneck, enabling efficient development of training sets. Millions of models trained on such datasets have been deployed in the real world and interact with users on a daily basis. However, the techniques that make weak supervision attractive -- such as integrating any source of signal to estimate unknown labels -- also ensure that the pseudolabels it produces are highly biased. Surprisingly, given everyday use and the potential for increased bias, weak supervision has not been studied from the point of view of fairness. This work begins such a study. Our departure point is the observation that even when a fair model can be built from a dataset with access to ground-truth labels, the corresponding dataset labeled via weak supervision can be arbitrarily unfair. Fortunately, not all is lost: we propose and empirically validate a model for source unfairness in weak supervision, then introduce a simple counterfactual fairness-based technique that can",
    "path": "papers/23/03/2303.17713.json",
    "total_tokens": 942,
    "translated_abstract": "弱监督学习能够克服标签瓶颈，实现训练集的高效开发。这种方法已经被广泛地应用于现实世界中，且日常与用户进行交互。然而，弱监督的技术具有与生俱来的偏差问题，即使使用任何来源的信号进行标签估计，也无法避免伪标签的偏差性。令人惊讶的是，尽管存在潜在的偏差问题并已经普及使用，但是弱监督学习并没有从公平的角度进行研究。该研究从这个角度出发，指出即使在通过地面真实标签所标注的公平数据集上建立一个公平模型，也不能保证通过弱监督所得到的数据集具有公平性，我们提出并经验证了一个弱监督学习中源偏置的模型，并且引入了一个简单的反事实公平技术方法，使得弱监督学习更公平。",
    "tldr": "弱监督学习因为存在源头偏差问题，导致即使使用任何来源的信号进行标签估计，也无法避免伪标签的偏差性。本研究提出了一个弱监督学习中源偏置的模型，并引入了一个反事实公平技术方法，使得弱监督学习更公平。",
    "en_tdlr": "Weak supervision has a bias problem due to the techniques used, making it difficult to produce unbiased pseudolabels even when using sources of signal. This study proposes a model for source unfairness in weak supervision and introduces a counterfactual fairness-based technique to make weak supervision fairer."
}