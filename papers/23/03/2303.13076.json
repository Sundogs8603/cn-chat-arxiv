{
    "title": "CORA: Adapting CLIP for Open-Vocabulary Detection with Region Prompting and Anchor Pre-Matching. (arXiv:2303.13076v1 [cs.CV])",
    "abstract": "Open-vocabulary detection (OVD) is an object detection task aiming at detecting objects from novel categories beyond the base categories on which the detector is trained. Recent OVD methods rely on large-scale visual-language pre-trained models, such as CLIP, for recognizing novel objects. We identify the two core obstacles that need to be tackled when incorporating these models into detector training: (1) the distribution mismatch that happens when applying a VL-model trained on whole images to region recognition tasks; (2) the difficulty of localizing objects of unseen classes. To overcome these obstacles, we propose CORA, a DETR-style framework that adapts CLIP for Open-vocabulary detection by Region prompting and Anchor pre-matching. Region prompting mitigates the whole-to-region distribution gap by prompting the region features of the CLIP-based region classifier. Anchor pre-matching helps learning generalizable object localization by a class-aware matching mechanism. We evaluate ",
    "link": "http://arxiv.org/abs/2303.13076",
    "context": "Title: CORA: Adapting CLIP for Open-Vocabulary Detection with Region Prompting and Anchor Pre-Matching. (arXiv:2303.13076v1 [cs.CV])\nAbstract: Open-vocabulary detection (OVD) is an object detection task aiming at detecting objects from novel categories beyond the base categories on which the detector is trained. Recent OVD methods rely on large-scale visual-language pre-trained models, such as CLIP, for recognizing novel objects. We identify the two core obstacles that need to be tackled when incorporating these models into detector training: (1) the distribution mismatch that happens when applying a VL-model trained on whole images to region recognition tasks; (2) the difficulty of localizing objects of unseen classes. To overcome these obstacles, we propose CORA, a DETR-style framework that adapts CLIP for Open-vocabulary detection by Region prompting and Anchor pre-matching. Region prompting mitigates the whole-to-region distribution gap by prompting the region features of the CLIP-based region classifier. Anchor pre-matching helps learning generalizable object localization by a class-aware matching mechanism. We evaluate ",
    "path": "papers/23/03/2303.13076.json",
    "total_tokens": 817,
    "translated_title": "CORA：基于 Region Prompting 和 Anchor Pre-Matching 的 CLIP 开放词汇检测模型改进",
    "translated_abstract": "开放式词汇检测(OVD)是一种旨在检测基于对象定位器的新类别的目标的技术。最近，基于大规模视觉语言预训练模型（例如CLIP）的OVD方法用于识别新型物体。然而，我们发现将这些模型应用于检测器训练时需要克服两个核心难点：1）应用VL模型训练全图像进行区域识别时的分布偏差；2）定位非基础类别物体的困难。针对这些难点，我们提出CORA框架，旨在通过Region prompting和Anchor pre-matching技术将CLIP改进为一种适用于OVD的DETR风格模型。",
    "tldr": "本研究提出了CORA框架，通过Region Prompting和Anchor Pre-Matching解决使用CLIP进行OVD训练时遇到的分布差异和目标定位等难点。",
    "en_tdlr": "In this paper, we propose CORA, a DETR-style framework that adapts CLIP for Open-vocabulary detection by Region prompting and Anchor pre-matching, to address the challenges of distribution mismatch and object localization in using CLIP for OVD training."
}