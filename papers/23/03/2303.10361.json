{
    "title": "DC-CCL: Device-Cloud Collaborative Controlled Learning for Large Vision Models. (arXiv:2303.10361v1 [cs.LG])",
    "abstract": "Many large vision models have been deployed on the cloud for real-time services. Meanwhile, fresh samples are continuously generated on the served mobile device. How to leverage the device-side samples to improve the cloud-side large model becomes a practical requirement, but falls into the dilemma of no raw sample up-link and no large model down-link. Specifically, the user may opt out of sharing raw samples with the cloud due to the concern of privacy or communication overhead, while the size of some large vision models far exceeds the mobile device's runtime capacity. In this work, we propose a device-cloud collaborative controlled learning framework, called DC-CCL, enabling a cloud-side large vision model that cannot be directly deployed on the mobile device to still benefit from the device-side local samples. In particular, DC-CCL vertically splits the base model into two submodels, one large submodel for learning from the cloud-side samples and the other small submodel for learni",
    "link": "http://arxiv.org/abs/2303.10361",
    "context": "Title: DC-CCL: Device-Cloud Collaborative Controlled Learning for Large Vision Models. (arXiv:2303.10361v1 [cs.LG])\nAbstract: Many large vision models have been deployed on the cloud for real-time services. Meanwhile, fresh samples are continuously generated on the served mobile device. How to leverage the device-side samples to improve the cloud-side large model becomes a practical requirement, but falls into the dilemma of no raw sample up-link and no large model down-link. Specifically, the user may opt out of sharing raw samples with the cloud due to the concern of privacy or communication overhead, while the size of some large vision models far exceeds the mobile device's runtime capacity. In this work, we propose a device-cloud collaborative controlled learning framework, called DC-CCL, enabling a cloud-side large vision model that cannot be directly deployed on the mobile device to still benefit from the device-side local samples. In particular, DC-CCL vertically splits the base model into two submodels, one large submodel for learning from the cloud-side samples and the other small submodel for learni",
    "path": "papers/23/03/2303.10361.json",
    "total_tokens": 774,
    "translated_title": "DC-CCL: 设备-云协同控制学习在大型视觉模型中的应用",
    "translated_abstract": "许多大型视觉模型已经部署在云端用于实时服务。同时，现场设备不断生成新的样本。如何利用设备端的样本来改进云端的大型模型成为实际需求，但陷入了没有原始样本上行和没有大型模型下行的困境中。本文提出了一种设备-云协同控制学习框架，名为DC-CCL，使云端无法直接部署在移动设备上的大型视觉模型仍然可以从设备端局部样本中受益。",
    "tldr": "提出了一种名为DC-CCL的设备-云协同控制学习框架，使云端无法直接部署在移动设备上的大型视觉模型仍然可以从设备端局部样本中受益。",
    "en_tdlr": "A device-cloud collaborative controlled learning framework, named DC-CCL, is proposed to allow large vision models deployed on the cloud to benefit from local samples generated on served mobile devices, even when the models cannot be directly deployed on the devices."
}