{
    "title": "Symbolic Synthesis of Neural Networks. (arXiv:2303.03340v2 [cs.NE] UPDATED)",
    "abstract": "Neural networks adapt very well to distributed and continuous representations, but struggle to generalize from small amounts of data. Symbolic systems commonly achieve data efficient generalization by exploiting modularity to benefit from local and discrete features of a representation. These features allow symbolic programs to be improved one module at a time and to experience combinatorial growth in the values they can successfully process. However, it is difficult to design a component that can be used to form symbolic abstractions and which is adequately overparametrized to learn arbitrary high-dimensional transformations. I present Graph-based Symbolically Synthesized Neural Networks (G-SSNNs), a class of neural modules that operate on representations modified with synthesized symbolic programs to include a fixed set of local and discrete features. I demonstrate that the choice of injected features within a G-SSNN module modulates the data efficiency and generalization of baseline",
    "link": "http://arxiv.org/abs/2303.03340",
    "context": "Title: Symbolic Synthesis of Neural Networks. (arXiv:2303.03340v2 [cs.NE] UPDATED)\nAbstract: Neural networks adapt very well to distributed and continuous representations, but struggle to generalize from small amounts of data. Symbolic systems commonly achieve data efficient generalization by exploiting modularity to benefit from local and discrete features of a representation. These features allow symbolic programs to be improved one module at a time and to experience combinatorial growth in the values they can successfully process. However, it is difficult to design a component that can be used to form symbolic abstractions and which is adequately overparametrized to learn arbitrary high-dimensional transformations. I present Graph-based Symbolically Synthesized Neural Networks (G-SSNNs), a class of neural modules that operate on representations modified with synthesized symbolic programs to include a fixed set of local and discrete features. I demonstrate that the choice of injected features within a G-SSNN module modulates the data efficiency and generalization of baseline",
    "path": "papers/23/03/2303.03340.json",
    "total_tokens": 808,
    "tldr": "本文提出了一种名为G-SSNNs的新型神经模块，可以利用本地和离散的特征来改进基线的数据效率和概括。",
    "en_tdlr": "This paper proposes a new type of neural modules called G-SSNNs which can improve the data efficiency and generalization of baselines by utilizing local and discrete features."
}