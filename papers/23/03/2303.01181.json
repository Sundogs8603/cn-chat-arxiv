{
    "title": "iSAGE: An Incremental Version of SAGE for Online Explanation on Data Streams. (arXiv:2303.01181v2 [cs.LG] UPDATED)",
    "abstract": "Existing methods for explainable artificial intelligence (XAI), including popular feature importance measures such as SAGE, are mostly restricted to the batch learning scenario. However, machine learning is often applied in dynamic environments, where data arrives continuously and learning must be done in an online manner. Therefore, we propose iSAGE, a time- and memory-efficient incrementalization of SAGE, which is able to react to changes in the model as well as to drift in the data-generating process. We further provide efficient feature removal methods that break (interventional) and retain (observational) feature dependencies. Moreover, we formally analyze our explanation method to show that iSAGE adheres to similar theoretical properties as SAGE. Finally, we evaluate our approach in a thorough experimental analysis based on well-established data sets and data streams with concept drift.",
    "link": "http://arxiv.org/abs/2303.01181",
    "context": "Title: iSAGE: An Incremental Version of SAGE for Online Explanation on Data Streams. (arXiv:2303.01181v2 [cs.LG] UPDATED)\nAbstract: Existing methods for explainable artificial intelligence (XAI), including popular feature importance measures such as SAGE, are mostly restricted to the batch learning scenario. However, machine learning is often applied in dynamic environments, where data arrives continuously and learning must be done in an online manner. Therefore, we propose iSAGE, a time- and memory-efficient incrementalization of SAGE, which is able to react to changes in the model as well as to drift in the data-generating process. We further provide efficient feature removal methods that break (interventional) and retain (observational) feature dependencies. Moreover, we formally analyze our explanation method to show that iSAGE adheres to similar theoretical properties as SAGE. Finally, we evaluate our approach in a thorough experimental analysis based on well-established data sets and data streams with concept drift.",
    "path": "papers/23/03/2303.01181.json",
    "total_tokens": 877,
    "translated_title": "iSAGE：一种基于增量学习的SAGE在线解释方法",
    "translated_abstract": "现有的可解释人工智能（XAI）方法，包括SAGE等流行的特征重要性测量，大多限于批量学习场景。然而，机器学习通常应用于动态环境中，数据持续到达，必须以在线方式进行学习。因此，我们提出了iSAGE，一种快速、内存高效的SAGE增量方法，它能够对模型的变化以及数据生成过程中的漂移进行反应。我们提供了有效的特征移除方法，破坏（干预）和保留（观测）特征之间的依赖关系。此外，我们正式分析了我们的解释方法，展示了iSAGE与SAGE具有类似的理论性质。最后，我们基于广泛使用的数据集和具有概念漂移的数据流对我们的方法进行了彻底的实验分析。",
    "tldr": "iSAGE是一种基于增量学习的SAGE在线解释方法，具备快速、内存高效的特点。该方法能够对模型变化以及数据生成过程中的漂移进行反应，同时提供了有效的特征移除方法，具有和SAGE类似的理论性质。",
    "en_tdlr": "iSAGE is an incremental explanation method for SAGE in dynamic environments. It reacts to model changes and drifts in the data-generating process. iSAGE provides efficient feature removal methods and has similar theoretical properties as SAGE. It is memory-efficient and has been thoroughly evaluated on established datasets with concept drift."
}