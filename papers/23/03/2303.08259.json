{
    "title": "Contextualized Medication Information Extraction Using Transformer-based Deep Learning Architectures. (arXiv:2303.08259v1 [cs.CL])",
    "abstract": "Objective: To develop a natural language processing (NLP) system to extract medications and contextual information that help understand drug changes. This project is part of the 2022 n2c2 challenge.  Materials and methods: We developed NLP systems for medication mention extraction, event classification (indicating medication changes discussed or not), and context classification to classify medication changes context into 5 orthogonal dimensions related to drug changes. We explored 6 state-of-the-art pretrained transformer models for the three subtasks, including GatorTron, a large language model pretrained using >90 billion words of text (including >80 billion words from >290 million clinical notes identified at the University of Florida Health). We evaluated our NLP systems using annotated data and evaluation scripts provided by the 2022 n2c2 organizers.  Results:Our GatorTron models achieved the best F1-scores of 0.9828 for medication extraction (ranked 3rd), 0.9379 for event classif",
    "link": "http://arxiv.org/abs/2303.08259",
    "context": "Title: Contextualized Medication Information Extraction Using Transformer-based Deep Learning Architectures. (arXiv:2303.08259v1 [cs.CL])\nAbstract: Objective: To develop a natural language processing (NLP) system to extract medications and contextual information that help understand drug changes. This project is part of the 2022 n2c2 challenge.  Materials and methods: We developed NLP systems for medication mention extraction, event classification (indicating medication changes discussed or not), and context classification to classify medication changes context into 5 orthogonal dimensions related to drug changes. We explored 6 state-of-the-art pretrained transformer models for the three subtasks, including GatorTron, a large language model pretrained using >90 billion words of text (including >80 billion words from >290 million clinical notes identified at the University of Florida Health). We evaluated our NLP systems using annotated data and evaluation scripts provided by the 2022 n2c2 organizers.  Results:Our GatorTron models achieved the best F1-scores of 0.9828 for medication extraction (ranked 3rd), 0.9379 for event classif",
    "path": "papers/23/03/2303.08259.json",
    "total_tokens": 1184,
    "translated_title": "基于Transformer的深度学习体系结构在语境化药物信息提取中的应用",
    "translated_abstract": "目的：开发自然语言处理(NLP)系统，提取药物及有助于理解药物变化的上下文信息。方法：开发了三个NLP系统，包括药物提及提取、事件分类(指药物变化的讨论或未讨论)、以及分类药物变化上下文到5个与药物变化相关的正交维度。我们探索了6个最先进的预训练变压器模型，包括GatorTron，它是一个大型语言模型，预训练使用超过90亿个单词的文本(包括来自佛罗里达大学健康中心识别的2.9亿多个临床笔记中的超过80亿个单词)。我们使用2022 n2c2的注释数据和评估脚本来评估我们的NLP系统。结果：我们的GatorTron模型在药物提取、事件分类和上下文分类方面分别取得了最佳的 F1 分数，分别为 0.9828（排名第3）、0.9379（排名第1）、0.8375（排名第1），超过其他5个预训练模型。我们最佳的NLP系统在18个参赛团队中排名第二，获得了总体F1得分0.8774 。结论：基于Transformer的深度学习体系结构，如GatorTron，可以有效地从临床笔记中提取药物和上下文信息，并在药物信息提取任务中取得最先进的性能。",
    "tldr": "本文使用Transformer预训练深度学习架构开发了NLP系统，可在临床笔记中提取药物及其上下文信息，并在药物信息提取任务中取得最先进的性能。",
    "en_tdlr": "This paper develops a natural language processing (NLP) system using Transformer-based deep learning architectures to extract medications and contextual information from clinical notes, achieving state-of-the-art performance in medication information extraction tasks. The best-performing NLP system uses GatorTron, a large language model pretrained using over 90 billion words of text, and ranks 2nd among 18 participating teams."
}