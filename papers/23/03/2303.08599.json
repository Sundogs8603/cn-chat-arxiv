{
    "title": "Efficient Uncertainty Estimation with Gaussian Process for Reliable Dialog Response Retrieval. (arXiv:2303.08599v1 [cs.CL])",
    "abstract": "Deep neural networks have achieved remarkable performance in retrieval-based dialogue systems, but they are shown to be ill calibrated. Though basic calibration methods like Monte Carlo Dropout and Ensemble can calibrate well, these methods are time-consuming in the training or inference stages. To tackle these challenges, we propose an efficient uncertainty calibration framework GPF-BERT for BERT-based conversational search, which employs a Gaussian Process layer and the focal loss on top of the BERT architecture to achieve a high-quality neural ranker. Extensive experiments are conducted to verify the effectiveness of our method. In comparison with basic calibration methods, GPF-BERT achieves the lowest empirical calibration error (ECE) in three in-domain datasets and the distributional shift tasks, while yielding the highest $R_{10}@1$ and MAP performance on most cases. In terms of time consumption, our GPF-BERT has an 8$\\times$ speedup.",
    "link": "http://arxiv.org/abs/2303.08599",
    "context": "Title: Efficient Uncertainty Estimation with Gaussian Process for Reliable Dialog Response Retrieval. (arXiv:2303.08599v1 [cs.CL])\nAbstract: Deep neural networks have achieved remarkable performance in retrieval-based dialogue systems, but they are shown to be ill calibrated. Though basic calibration methods like Monte Carlo Dropout and Ensemble can calibrate well, these methods are time-consuming in the training or inference stages. To tackle these challenges, we propose an efficient uncertainty calibration framework GPF-BERT for BERT-based conversational search, which employs a Gaussian Process layer and the focal loss on top of the BERT architecture to achieve a high-quality neural ranker. Extensive experiments are conducted to verify the effectiveness of our method. In comparison with basic calibration methods, GPF-BERT achieves the lowest empirical calibration error (ECE) in three in-domain datasets and the distributional shift tasks, while yielding the highest $R_{10}@1$ and MAP performance on most cases. In terms of time consumption, our GPF-BERT has an 8$\\times$ speedup.",
    "path": "papers/23/03/2303.08599.json",
    "total_tokens": 974,
    "translated_title": "高斯过程的高效不确定性估计用于可靠对话响应检索",
    "translated_abstract": "检索式对话系统中的深度神经网络表现出卓越的性能，但它们被证明是不良校准的。虽然像蒙特卡罗Dropout和Ensemble这样的基本校准方法可以很好地校准，但这些方法在训练或推理阶段需要耗费大量时间。为了应对这些挑战，我们提出了一种高效的不确定性校准框架GPF-BERT，用于基于BERT的会话搜索，它采用高斯过程层和焦点损失在BERT架构的顶部，以实现高质量的神经排名器。大量实验用于验证我们的方法的有效性。与基本校准方法相比，GPF-BERT在三个领域内数据集和分布偏移任务中实现了最低的经验校准误差（ECE），同时在大多数情况下产生了最高的$R_{10}@1$和MAP性能。在时间消耗方面，我们的GPF-BERT具有8倍的加速效果。",
    "tldr": "本文提出了一个高斯过程下的不确定性校准框架GPF-BERT用于基于BERT的对话搜索，实现了高质量的神经排名器，相较于基本校准方法具有更低的经验校准误差和更高的检索性能，在时间上具有8倍的加速效果。",
    "en_tdlr": "This paper proposes an efficient uncertainty calibration framework named GPF-BERT for BERT-based conversational search, which employs a Gaussian Process layer and focal loss on top of BERT architecture to achieve a high-quality neural ranker. GPF-BERT outperforms basic calibration methods with a lower empirical calibration error and more significant retrieval performance. Moreover, it has an 8x speedup in terms of time consumption."
}