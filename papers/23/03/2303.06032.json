{
    "title": "Exploring Adversarial Attacks on Neural Networks: An Explainable Approach. (arXiv:2303.06032v1 [cs.LG])",
    "abstract": "Deep Learning (DL) is being applied in various domains, especially in safety-critical applications such as autonomous driving. Consequently, it is of great significance to ensure the robustness of these methods and thus counteract uncertain behaviors caused by adversarial attacks. In this paper, we use gradient heatmaps to analyze the response characteristics of the VGG-16 model when the input images are mixed with adversarial noise and statistically similar Gaussian random noise. In particular, we compare the network response layer by layer to determine where errors occurred. Several interesting findings are derived. First, compared to Gaussian random noise, intentionally generated adversarial noise causes severe behavior deviation by distracting the area of concentration in the networks. Second, in many cases, adversarial examples only need to compromise a few intermediate blocks to mislead the final decision. Third, our experiments revealed that specific blocks are more vulnerable a",
    "link": "http://arxiv.org/abs/2303.06032",
    "raw_ret": "{\n    \"translated_title\": \"探究神经网络的对抗攻击:一种可解释的方法\",\n    \"translated_abstract\": \"深度学习(DL)被应用于各个领域，特别是在自动驾驶等安全关键应用中。因此，确保这些方法的鲁棒性并抵消由对抗攻击引起的不确定行为非常重要。本文使用梯度热图分析VGG-16模型的响应特性，当输入图像与对抗噪声和统计相似的高斯随机噪声混合时。特别是，我们逐层比较网络响应，以确定错误发生的位置。我们得出了几个有趣的发现。首先，与高斯随机噪声相比，有意生成的对抗噪声通过分散网络中的集中区域引起了严重的行为偏差。其次，在许多情况下，对抗性示例只需要破坏少数中间块即可误导最终决策。第三，我们的实验揭示了具体的块更容易受到攻击。 \",\n    \"tldr\": \"文章使用梯度热图分析了VGG-16模型对抗攻击下的响应特性，发现与高斯随机噪声相比，对抗噪声会分散网络中的集中区域，导致严重的行为偏差。此外，在许多情况下，对抗性示例只需破坏少数中间块即可误导最终决策，并且特定块更容易受到攻击。\"\n}<|im_sep|>",
    "total_tokens": 929,
    "ret": {
        "translated_title": "探究神经网络的对抗攻击:一种可解释的方法",
        "translated_abstract": "深度学习(DL)被应用于各个领域，特别是在自动驾驶等安全关键应用中。因此，确保这些方法的鲁棒性并抵消由对抗攻击引起的不确定行为非常重要。本文使用梯度热图分析VGG-16模型的响应特性，当输入图像与对抗噪声和统计相似的高斯随机噪声混合时。特别是，我们逐层比较网络响应，以确定错误发生的位置。我们得出了几个有趣的发现。首先，与高斯随机噪声相比，有意生成的对抗噪声通过分散网络中的集中区域引起了严重的行为偏差。其次，在许多情况下，对抗性示例只需要破坏少数中间块即可误导最终决策。第三，我们的实验揭示了具体的块更容易受到攻击。 ",
        "tldr": "文章使用梯度热图分析了VGG-16模型对抗攻击下的响应特性，发现与高斯随机噪声相比，对抗噪声会分散网络中的集中区域，导致严重的行为偏差。此外，在许多情况下，对抗性示例只需破坏少数中间块即可误导最终决策，并且特定块更容易受到攻击。"
    }
}