{
    "title": "Viewpoint Equivariance for Multi-View 3D Object Detection. (arXiv:2303.14548v2 [cs.CV] UPDATED)",
    "abstract": "3D object detection from visual sensors is a cornerstone capability of robotic systems. State-of-the-art methods focus on reasoning and decoding object bounding boxes from multi-view camera input. In this work we gain intuition from the integral role of multi-view consistency in 3D scene understanding and geometric learning. To this end, we introduce VEDet, a novel 3D object detection framework that exploits 3D multi-view geometry to improve localization through viewpoint awareness and equivariance. VEDet leverages a query-based transformer architecture and encodes the 3D scene by augmenting image features with positional encodings from their 3D perspective geometry. We design view-conditioned queries at the output level, which enables the generation of multiple virtual frames during training to learn viewpoint equivariance by enforcing multi-view consistency. The multi-view geometry injected at the input level as positional encodings and regularized at the loss level provides rich geo",
    "link": "http://arxiv.org/abs/2303.14548",
    "context": "Title: Viewpoint Equivariance for Multi-View 3D Object Detection. (arXiv:2303.14548v2 [cs.CV] UPDATED)\nAbstract: 3D object detection from visual sensors is a cornerstone capability of robotic systems. State-of-the-art methods focus on reasoning and decoding object bounding boxes from multi-view camera input. In this work we gain intuition from the integral role of multi-view consistency in 3D scene understanding and geometric learning. To this end, we introduce VEDet, a novel 3D object detection framework that exploits 3D multi-view geometry to improve localization through viewpoint awareness and equivariance. VEDet leverages a query-based transformer architecture and encodes the 3D scene by augmenting image features with positional encodings from their 3D perspective geometry. We design view-conditioned queries at the output level, which enables the generation of multiple virtual frames during training to learn viewpoint equivariance by enforcing multi-view consistency. The multi-view geometry injected at the input level as positional encodings and regularized at the loss level provides rich geo",
    "path": "papers/23/03/2303.14548.json",
    "total_tokens": 877,
    "translated_title": "多视角三维物体检测的观点等变性",
    "translated_abstract": "从视觉传感器进行三维物体检测是机器人系统的关键能力。现代方法侧重于从多视角相机输入推理和解码物体边界框。本文利用多视角一致性在三维场景理解和几何学习中的重要作用，介绍了VEDet，一种新颖的三维物体检测框架，通过视点感知和等变性利用三维多视角几何来提高定位精度。VEDet利用基于查询的transformer架构，并通过将图像特征和来自它们的三维透视几何的位置编码相结合来编码三维场景。我们在输出层设计了视角条件的查询，这使得在训练期间生成多个虚拟帧，通过强制多视角一致性来学习视点等变性。在输入层注入的多视角几何作为位置编码，并在损失层中进行正则化，提供了丰富的地理信息。",
    "tldr": "本文提出了一种利用多视角几何学习视点等变性以提高三维物体检测定位精度的框架VEDet，并通过基于查询的transformer架构和视角条件的查询来实现。",
    "en_tdlr": "This paper proposes a framework VEDet, which uses multi-view geometry to improve the accuracy of 3D object detection by learning viewpoint equivariance, and achieves it through a query-based transformer architecture and view-conditioned queries."
}