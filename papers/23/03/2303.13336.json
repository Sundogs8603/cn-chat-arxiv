{
    "title": "Audio Diffusion Model for Speech Synthesis: A Survey on Text To Speech and Speech Enhancement in Generative AI. (arXiv:2303.13336v1 [cs.SD])",
    "abstract": "Generative AI has demonstrated impressive performance in various fields, among which speech synthesis is an interesting direction. With the diffusion model as the most popular generative model, numerous works have attempted two active tasks: text to speech and speech enhancement. This work conducts a survey on audio diffusion model, which is complementary to existing surveys that either lack the recent progress of diffusion-based speech synthesis or highlight an overall picture of applying diffusion model in multiple fields. Specifically, this work first briefly introduces the background of audio and diffusion model. As for the text-to-speech task, we divide the methods into three categories based on the stage where diffusion model is adopted: acoustic model, vocoder and end-to-end framework. Moreover, we categorize various speech enhancement tasks by either certain signals are removed or added into the input speech. Comparisons of experimental results and discussions are also covered ",
    "link": "http://arxiv.org/abs/2303.13336",
    "context": "Title: Audio Diffusion Model for Speech Synthesis: A Survey on Text To Speech and Speech Enhancement in Generative AI. (arXiv:2303.13336v1 [cs.SD])\nAbstract: Generative AI has demonstrated impressive performance in various fields, among which speech synthesis is an interesting direction. With the diffusion model as the most popular generative model, numerous works have attempted two active tasks: text to speech and speech enhancement. This work conducts a survey on audio diffusion model, which is complementary to existing surveys that either lack the recent progress of diffusion-based speech synthesis or highlight an overall picture of applying diffusion model in multiple fields. Specifically, this work first briefly introduces the background of audio and diffusion model. As for the text-to-speech task, we divide the methods into three categories based on the stage where diffusion model is adopted: acoustic model, vocoder and end-to-end framework. Moreover, we categorize various speech enhancement tasks by either certain signals are removed or added into the input speech. Comparisons of experimental results and discussions are also covered ",
    "path": "papers/23/03/2303.13336.json",
    "total_tokens": 874,
    "translated_title": "语音合成的音频扩散模型：基于生成AI的文本到语音和语音增强的概述",
    "translated_abstract": "生成AI在各个领域表现出了惊人的性能，其中语音合成是一个有趣的方向。随着扩散模型成为最流行的生成模型，许多工作已经尝试了两个活跃任务：文本到语音和语音增强。本文对音频扩散模型进行了概述，这是对现有调查的补充，这些调查要么缺乏基于扩散的语音合成的最新进展，要么强调在多个领域应用扩散模型的整体情况。具体而言，本文首先简要介绍了音频和扩散模型的背景。对于文本到语音任务，我们将方法分为三类，基于扩散模型采用的阶段：声学模型、声码器和端到端框架。此外，我们通过将某些信号从输入语音中删除或添加来将各种语音增强任务进行分类。本文还涵盖了实验结果的比较和讨论。",
    "tldr": "此文介绍了音频扩散模型，重点讨论了两个活跃任务：文本到语音和语音增强，并对实验结果进行了比较和讨论。",
    "en_tdlr": "This paper presents an overview of the audio diffusion model, specifically focusing on two active tasks in generative AI: text to speech and speech enhancement, while covering comparisons of experimental results and discussions."
}