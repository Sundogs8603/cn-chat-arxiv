{
    "title": "Information-Theoretic Regret Bounds for Bandits with Fixed Expert Advice. (arXiv:2303.08102v1 [cs.LG])",
    "abstract": "We investigate the problem of bandits with expert advice when the experts are fixed and known distributions over the actions. Improving on previous analyses, we show that the regret in this setting is controlled by information-theoretic quantities that measure the similarity between experts. In some natural special cases, this allows us to obtain the first regret bound for EXP4 that can get arbitrarily close to zero if the experts are similar enough. While for a different algorithm, we provide another bound that describes the similarity between the experts in terms of the KL-divergence, and we show that this bound can be smaller than the one of EXP4 in some cases. Additionally, we provide lower bounds for certain classes of experts showing that the algorithms we analyzed are nearly optimal in some cases.",
    "link": "http://arxiv.org/abs/2303.08102",
    "context": "Title: Information-Theoretic Regret Bounds for Bandits with Fixed Expert Advice. (arXiv:2303.08102v1 [cs.LG])\nAbstract: We investigate the problem of bandits with expert advice when the experts are fixed and known distributions over the actions. Improving on previous analyses, we show that the regret in this setting is controlled by information-theoretic quantities that measure the similarity between experts. In some natural special cases, this allows us to obtain the first regret bound for EXP4 that can get arbitrarily close to zero if the experts are similar enough. While for a different algorithm, we provide another bound that describes the similarity between the experts in terms of the KL-divergence, and we show that this bound can be smaller than the one of EXP4 in some cases. Additionally, we provide lower bounds for certain classes of experts showing that the algorithms we analyzed are nearly optimal in some cases.",
    "path": "papers/23/03/2303.08102.json",
    "total_tokens": 883,
    "translated_title": "基于信息理论的固定专家建议下赌博机的遗憾界限",
    "translated_abstract": "本文研究了在专家是固定和已知的情况下，赌博机与专家建议的问题，这些专家是行动固定和已知分布。相比以前的分析，我们展示了这种情况下遗憾是由衡量专家之间相似性的信息论量所控制的。在一些自然特殊情况下，这使我们能够获得EXP4的第一个遗憾界限，如果专家足够相似，则可以无限接近于零。为另一种算法提供了可以用KL散度来描述专家之间相似性的另一种界限，并且在某些情况下，我们展示了这个界限可以比EXP4更小。此外，我们为某些专家类别提供了下限，展示了我们分析的算法在某些情况下是几乎最优的。",
    "tldr": "本文研究固定专家建议下的赌博机问题，提出了基于信息论的遗憾界限，可以使得某些算法的遗憾无限接近于零。此外，我们还提出了KL散度来描述专家之间的相似性界限，并给出了下限证明算法的最优性。",
    "en_tdlr": "This paper studies the bandit problem with fixed expert advice and introduces information-theoretic regret bounds. The bounds allow certain algorithms to achieve arbitrarily low regret if experts are sufficiently similar. Additionally, lower bounds are provided to show the optimality of the analyzed algorithms for certain types of experts. The paper also presents a KL-divergence-based similarity bound for a different algorithm."
}