{
    "title": "Re-thinking Federated Active Learning based on Inter-class Diversity. (arXiv:2303.12317v1 [cs.CV])",
    "abstract": "Although federated learning has made awe-inspiring advances, most studies have assumed that the client's data are fully labeled. However, in a real-world scenario, every client may have a significant amount of unlabeled instances. Among the various approaches to utilizing unlabeled data, a federated active learning framework has emerged as a promising solution. In the decentralized setting, there are two types of available query selector models, namely 'global' and 'local-only' models, but little literature discusses their performance dominance and its causes. In this work, we first demonstrate that the superiority of two selector models depends on the global and local inter-class diversity. Furthermore, we observe that the global and local-only models are the keys to resolving the imbalance of each side. Based on our findings, we propose LoGo, a FAL sampling strategy robust to varying local heterogeneity levels and global imbalance ratio, that integrates both models by two steps of ac",
    "link": "http://arxiv.org/abs/2303.12317",
    "context": "Title: Re-thinking Federated Active Learning based on Inter-class Diversity. (arXiv:2303.12317v1 [cs.CV])\nAbstract: Although federated learning has made awe-inspiring advances, most studies have assumed that the client's data are fully labeled. However, in a real-world scenario, every client may have a significant amount of unlabeled instances. Among the various approaches to utilizing unlabeled data, a federated active learning framework has emerged as a promising solution. In the decentralized setting, there are two types of available query selector models, namely 'global' and 'local-only' models, but little literature discusses their performance dominance and its causes. In this work, we first demonstrate that the superiority of two selector models depends on the global and local inter-class diversity. Furthermore, we observe that the global and local-only models are the keys to resolving the imbalance of each side. Based on our findings, we propose LoGo, a FAL sampling strategy robust to varying local heterogeneity levels and global imbalance ratio, that integrates both models by two steps of ac",
    "path": "papers/23/03/2303.12317.json",
    "total_tokens": 931,
    "translated_title": "基于类间差异的联邦主动学习重新思考",
    "translated_abstract": "尽管联邦学习取得了令人瞩目的进展，但大多数研究假设客户端的数据是完全标记的。然而，在现实世界中，每个客户端可能会有大量未标记的实例。在利用未标记数据的各种方法中，联邦主动学习框架已经成为一种有前途的解决方案。在分散的设置中，有两种可用的查询选择器模型，即“全局”和“仅本地”模型，但很少有文献讨论它们的性能优劣及其原因。在这项工作中，我们首先展示了两个选择器模型的优越性取决于全局和本地类间多样性。此外，我们观察到全球和仅本地模型是解决双方不平衡的关键。基于我们的发现，我们提出了一种FAL抽样策略LoGo，它能够抵御不同的本地异质性水平和全局不平衡比例，通过两个步骤整合两种模型。",
    "tldr": "本研究提出了一种新的联邦主动学习采样策略LoGo，它能够抵御不同的本地异质性水平和全局不平衡比例，通过整合全局和仅本地查询选择器模型来解决双方不平衡。",
    "en_tdlr": "This paper presents a novel federated active learning (FAL) sampling strategy, called LoGo, which is robust to varying local heterogeneity levels and global imbalance ratios. LoGo integrates both global and local-only query selector models and effectively resolves the imbalance of each side."
}