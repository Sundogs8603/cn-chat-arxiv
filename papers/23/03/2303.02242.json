{
    "title": "TrojText: Test-time Invisible Textual Trojan Insertion. (arXiv:2303.02242v2 [cs.CL] UPDATED)",
    "abstract": "In Natural Language Processing (NLP), intelligent neuron models can be susceptible to textual Trojan attacks. Such attacks occur when Trojan models behave normally for standard inputs but generate malicious output for inputs that contain a specific trigger. Syntactic-structure triggers, which are invisible, are becoming more popular for Trojan attacks because they are difficult to detect and defend against. However, these types of attacks require a large corpus of training data to generate poisoned samples with the necessary syntactic structures for Trojan insertion. Obtaining such data can be difficult for attackers, and the process of generating syntactic poisoned triggers and inserting Trojans can be time-consuming. This paper proposes a solution called TrojText, which aims to determine whether invisible textual Trojan attacks can be performed more efficiently and cost-effectively without training data. The proposed approach, called the Representation-Logit Trojan Insertion (RLI) al",
    "link": "http://arxiv.org/abs/2303.02242",
    "context": "Title: TrojText: Test-time Invisible Textual Trojan Insertion. (arXiv:2303.02242v2 [cs.CL] UPDATED)\nAbstract: In Natural Language Processing (NLP), intelligent neuron models can be susceptible to textual Trojan attacks. Such attacks occur when Trojan models behave normally for standard inputs but generate malicious output for inputs that contain a specific trigger. Syntactic-structure triggers, which are invisible, are becoming more popular for Trojan attacks because they are difficult to detect and defend against. However, these types of attacks require a large corpus of training data to generate poisoned samples with the necessary syntactic structures for Trojan insertion. Obtaining such data can be difficult for attackers, and the process of generating syntactic poisoned triggers and inserting Trojans can be time-consuming. This paper proposes a solution called TrojText, which aims to determine whether invisible textual Trojan attacks can be performed more efficiently and cost-effectively without training data. The proposed approach, called the Representation-Logit Trojan Insertion (RLI) al",
    "path": "papers/23/03/2303.02242.json",
    "total_tokens": 846,
    "translated_title": "TrojText：测试时隐形文本特洛伊木马插入",
    "translated_abstract": "在自然语言处理（NLP）中，智能神经模型容易受到文本特洛伊攻击。当特洛伊模型对于标准输入表现正常，但是对于包含特定触发器的输入生成恶意输出时，就会发生这种攻击。语法结构触发器，作为一种隐形触发器，越来越受到特洛伊攻击的欢迎，因为它们很难被检测和防御。然而，这些类型的攻击需要大量的训练数据，以生成具有特洛伊插入所需语法结构的毒化样本。对于攻击者来说，获取这样的数据可能很困难，而生成语法毒化触发器和插入特洛伊木马的过程可能非常耗时。本文提出了一种名为TrojText的解决方案，旨在确定是否可以更高效、更经济地进行无需训练数据的隐形文本特洛伊攻击。所提出的方法称为表示-逻辑特洛伊插入（RLI）算法。",
    "tldr": "本文提出了一种名为TrojText的解决方案，旨在确定无需训练数据是否可以更高效、更经济地进行隐形文本特洛伊攻击。"
}