{
    "title": "Collage Diffusion. (arXiv:2303.00262v2 [cs.CV] UPDATED)",
    "abstract": "We seek to give users precise control over diffusion-based image generation by modeling complex scenes as sequences of layers, which define the desired spatial arrangement and visual attributes of objects in the scene. Collage Diffusion harmonizes the input layers to make objects fit together -- the key challenge involves minimizing changes in the positions and key visual attributes of the input layers while allowing other attributes to change in the harmonization process. We ensure that objects are generated in the correct locations by modifying text-image cross-attention with the layers' alpha masks. We preserve key visual attributes of input layers by learning specialized text representations per layer and by extending ControlNet to operate on layers. Layer input allows users to control the extent of image harmonization on a per-object basis, and users can even iteratively edit individual objects in generated images while keeping other objects fixed. By leveraging the rich informati",
    "link": "http://arxiv.org/abs/2303.00262",
    "context": "Title: Collage Diffusion. (arXiv:2303.00262v2 [cs.CV] UPDATED)\nAbstract: We seek to give users precise control over diffusion-based image generation by modeling complex scenes as sequences of layers, which define the desired spatial arrangement and visual attributes of objects in the scene. Collage Diffusion harmonizes the input layers to make objects fit together -- the key challenge involves minimizing changes in the positions and key visual attributes of the input layers while allowing other attributes to change in the harmonization process. We ensure that objects are generated in the correct locations by modifying text-image cross-attention with the layers' alpha masks. We preserve key visual attributes of input layers by learning specialized text representations per layer and by extending ControlNet to operate on layers. Layer input allows users to control the extent of image harmonization on a per-object basis, and users can even iteratively edit individual objects in generated images while keeping other objects fixed. By leveraging the rich informati",
    "path": "papers/23/03/2303.00262.json",
    "total_tokens": 850,
    "translated_title": "蒙太奇扩散",
    "translated_abstract": "我们通过将复杂场景建模为图层序列，为用户提供对基于扩散的图像生成具有精确控制的能力，这些图层定义了场景中对象的期望空间布置和视觉属性。蒙太奇扩散使输入图层协调一致，使对象互相适应 - 关键挑战在于在协调过程中最小化输入图层的位置和主要视觉属性的变化，同时允许其他属性发生变化。我们通过修改文本-图像交叉注意力与图层的alpha掩模来确保对象在正确位置生成。通过学习每个图层的专门文本表示，并扩展ControlNet以操作图层，我们可以保留输入图层的关键视觉属性。图层输入允许用户在每个对象上基于对象控制图像协调的程度，并且用户甚至可以在保持其他对象固定的情况下迭代地编辑生成的图像中的单个对象。通过利用丰富的信息",
    "tldr": "Collage Diffusion通过图层建模和协调技术实现了对扩散图像生成的精确控制，用户可以在每个对象上调整图像协调程度，并可以在保持其他对象固定的情况下编辑单个对象。",
    "en_tdlr": "Collage Diffusion gives users precise control over diffusion-based image generation using layer modeling and harmonization techniques. Users can adjust the degree of image harmonization on each object and edit individual objects while keeping others fixed."
}