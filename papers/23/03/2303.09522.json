{
    "title": "$P+$: Extended Textual Conditioning in Text-to-Image Generation. (arXiv:2303.09522v1 [cs.CV])",
    "abstract": "We introduce an Extended Textual Conditioning space in text-to-image models, referred to as $P+$. This space consists of multiple textual conditions, derived from per-layer prompts, each corresponding to a layer of the denoising U-net of the diffusion model.  We show that the extended space provides greater disentangling and control over image synthesis. We further introduce Extended Textual Inversion (XTI), where the images are inverted into $P+$, and represented by per-layer tokens.  We show that XTI is more expressive and precise, and converges faster than the original Textual Inversion (TI) space. The extended inversion method does not involve any noticeable trade-off between reconstruction and editability and induces more regular inversions.  We conduct a series of extensive experiments to analyze and understand the properties of the new space, and to showcase the effectiveness of our method for personalizing text-to-image models. Furthermore, we utilize the unique properties of t",
    "link": "http://arxiv.org/abs/2303.09522",
    "context": "Title: $P+$: Extended Textual Conditioning in Text-to-Image Generation. (arXiv:2303.09522v1 [cs.CV])\nAbstract: We introduce an Extended Textual Conditioning space in text-to-image models, referred to as $P+$. This space consists of multiple textual conditions, derived from per-layer prompts, each corresponding to a layer of the denoising U-net of the diffusion model.  We show that the extended space provides greater disentangling and control over image synthesis. We further introduce Extended Textual Inversion (XTI), where the images are inverted into $P+$, and represented by per-layer tokens.  We show that XTI is more expressive and precise, and converges faster than the original Textual Inversion (TI) space. The extended inversion method does not involve any noticeable trade-off between reconstruction and editability and induces more regular inversions.  We conduct a series of extensive experiments to analyze and understand the properties of the new space, and to showcase the effectiveness of our method for personalizing text-to-image models. Furthermore, we utilize the unique properties of t",
    "path": "papers/23/03/2303.09522.json",
    "total_tokens": 1018,
    "translated_abstract": "本文介绍了一种在文本到图像生成模型中扩展文本条件的空间，称为$P+$. 该空间由多个文本条件组成，源自于扩散模型的去噪U-net的每一层提示符，每个提示符对应一层。我们表明，扩展空间提供了更好的生成图像的解耦和控制。我们进一步介绍了扩展文本反演（XTI），其中图像反演到$P+$，由每层token表示。我们表明，XTI更具表现力和精度，并且比原始的文本反演（TI）空间收敛更快。扩展反演方法不涉及任何明显的重构和可编辑性之间的权衡，并引起了更规则的反演。我们进行了一系列广泛的实验来分析和理解新空间的属性，并展示了我们的方法对于个性化文本到图像模型的效果。此外，我们利用$P+$空间的独特属性来学习语义编辑的潜在应用，展示了其效果。",
    "tldr": "本文介绍了一种称为$P+$的扩展文本条件生成图像空间，并提出了一种扩展文本反演（XTI）的反演方法。我们在实验中表明，XTI更具表现力和精度，并且比原始的文本反演（TI）空间收敛更快，同时不涉及明显的重构和可编辑性之间的权衡，并引发了更规则的反演。通过该方法，我们可以针对个性化需求生成更好的图像。"
}