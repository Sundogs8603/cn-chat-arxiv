{
    "title": "HyperDiffusion: Generating Implicit Neural Fields with Weight-Space Diffusion. (arXiv:2303.17015v1 [cs.CV])",
    "abstract": "Implicit neural fields, typically encoded by a multilayer perceptron (MLP) that maps from coordinates (e.g., xyz) to signals (e.g., signed distances), have shown remarkable promise as a high-fidelity and compact representation. However, the lack of a regular and explicit grid structure also makes it challenging to apply generative modeling directly on implicit neural fields in order to synthesize new data. To this end, we propose HyperDiffusion, a novel approach for unconditional generative modeling of implicit neural fields. HyperDiffusion operates directly on MLP weights and generates new neural implicit fields encoded by synthesized MLP parameters. Specifically, a collection of MLPs is first optimized to faithfully represent individual data samples. Subsequently, a diffusion process is trained in this MLP weight space to model the underlying distribution of neural implicit fields. HyperDiffusion enables diffusion modeling over a implicit, compact, and yet high-fidelity representatio",
    "link": "http://arxiv.org/abs/2303.17015",
    "context": "Title: HyperDiffusion: Generating Implicit Neural Fields with Weight-Space Diffusion. (arXiv:2303.17015v1 [cs.CV])\nAbstract: Implicit neural fields, typically encoded by a multilayer perceptron (MLP) that maps from coordinates (e.g., xyz) to signals (e.g., signed distances), have shown remarkable promise as a high-fidelity and compact representation. However, the lack of a regular and explicit grid structure also makes it challenging to apply generative modeling directly on implicit neural fields in order to synthesize new data. To this end, we propose HyperDiffusion, a novel approach for unconditional generative modeling of implicit neural fields. HyperDiffusion operates directly on MLP weights and generates new neural implicit fields encoded by synthesized MLP parameters. Specifically, a collection of MLPs is first optimized to faithfully represent individual data samples. Subsequently, a diffusion process is trained in this MLP weight space to model the underlying distribution of neural implicit fields. HyperDiffusion enables diffusion modeling over a implicit, compact, and yet high-fidelity representatio",
    "path": "papers/23/03/2303.17015.json",
    "total_tokens": 865,
    "translated_title": "超扩散：用权重空间扩散生成隐式神经场",
    "translated_abstract": "隐式神经场通常由多层感知器(MLP)编码，将坐标(例如xyz)映射到信号(例如符号距离)，已显示出极高的精度和紧凑性。但是，缺少规则和明确的网格结构也使得直接在隐式神经场上应用生成建模以合成新数据变得具有挑战性。为此，我们提出了超扩散(HyperDiffusion)，这是一种用于隐式神经场无条件生成建模的新方法。HyperDiffusion直接在MLP权重上操作，并通过合成MLP参数生成新的神经隐式场。具体来说，首先优化一系列MLP以忠实地表示各个数据样本。随后，在MLP权重空间中训练扩散过程以对神经隐式场的基础分布进行建模。HyperDiffusion使得扩散建模在隐式，紧凑且高保真的表示上成为可能。",
    "tldr": "本文提出了一种名为HyperDiffusion的新方法，用于无条件生成建模的隐式神经场。该方法在MLP权重上操作，生成了新的神经隐式场，其中包含由合成的MLP参数编码的信息。",
    "en_tdlr": "This paper proposes a novel approach called HyperDiffusion for unconditional generative modeling of implicit neural fields. It operates directly on MLP weights and generates new neural implicit fields encoded by synthesized MLP parameters."
}