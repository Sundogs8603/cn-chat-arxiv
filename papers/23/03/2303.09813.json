{
    "title": "DiffusionSeg: Adapting Diffusion Towards Unsupervised Object Discovery. (arXiv:2303.09813v1 [cs.CV])",
    "abstract": "Learning from a large corpus of data, pre-trained models have achieved impressive progress nowadays. As popular generative pre-training, diffusion models capture both low-level visual knowledge and high-level semantic relations. In this paper, we propose to exploit such knowledgeable diffusion models for mainstream discriminative tasks, i.e., unsupervised object discovery: saliency segmentation and object localization. However, the challenges exist as there is one structural difference between generative and discriminative models, which limits the direct use. Besides, the lack of explicitly labeled data significantly limits performance in unsupervised settings. To tackle these issues, we introduce DiffusionSeg, one novel synthesis-exploitation framework containing two-stage strategies. To alleviate data insufficiency, we synthesize abundant images, and propose a novel training-free AttentionCut to obtain masks in the first synthesis stage. In the second exploitation stage, to bridge th",
    "link": "http://arxiv.org/abs/2303.09813",
    "context": "Title: DiffusionSeg: Adapting Diffusion Towards Unsupervised Object Discovery. (arXiv:2303.09813v1 [cs.CV])\nAbstract: Learning from a large corpus of data, pre-trained models have achieved impressive progress nowadays. As popular generative pre-training, diffusion models capture both low-level visual knowledge and high-level semantic relations. In this paper, we propose to exploit such knowledgeable diffusion models for mainstream discriminative tasks, i.e., unsupervised object discovery: saliency segmentation and object localization. However, the challenges exist as there is one structural difference between generative and discriminative models, which limits the direct use. Besides, the lack of explicitly labeled data significantly limits performance in unsupervised settings. To tackle these issues, we introduce DiffusionSeg, one novel synthesis-exploitation framework containing two-stage strategies. To alleviate data insufficiency, we synthesize abundant images, and propose a novel training-free AttentionCut to obtain masks in the first synthesis stage. In the second exploitation stage, to bridge th",
    "path": "papers/23/03/2303.09813.json",
    "total_tokens": 1119,
    "translated_title": "DiffusionSeg：将扩散技术应用于无监督目标发现中的自适应架构",
    "translated_abstract": "预训练模型从大量数据中学习，现在已经取得了令人瞩目的进展。作为流行的生成预训练模型，扩散模型捕捉了低级视觉知识和高级语义关系。本文提出了一种利用这种知识库扩散模型来进行主流判别性任务——无监督目标发现：显着性分割和目标定位。然而，由于生成和判别式模型之间存在一种结构上的差异，这限制了直接使用的可能性。此外，显式标记数据的缺乏在无监督设置下显著限制了性能。为了应对这些问题，我们引入了DiffusionSeg，这是一个包含两个阶段策略的新型合成-利用框架。为了减轻数据不足的问题，我们使用第一个合成阶段合成大量的图像，并提出了一种新的无需训练的AttentionCut来获得掩膜。在第二个利用阶段中，为了弥补生成和判别式模型之间的差距，我们提出了Pixelwise回归，通过物体位置约束生成扩散过程。所提出的方法在无监督目标发现基准测试中实现了最先进的性能，表明扩散模型可以有效地应用于判别性任务。",
    "tldr": "本文提出了一种新的框架DiffusionSeg，利用扩散模型解决了无监督目标发现任务中的判别性问题，包含两个阶段的策略，通过合成大量图像和Pixelwise回归来解决标记数据不足和生成、判别模型结构不同的问题。在基准测试中表现出最先进的性能。",
    "en_tdlr": "DiffusionSeg, a novel synthesis-exploitation framework, adapts diffusion models for unsupervised object discovery, achieving state-of-the-art performance by synthesizing images and using Pixelwise Regression to constrain the generative diffusion process with object locations, addressing data insufficiency and the structural difference between generative and discriminative models."
}