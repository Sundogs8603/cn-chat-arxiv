{
    "title": "Provable Robustness for Streaming Models with a Sliding Window. (arXiv:2303.16308v1 [cs.LG])",
    "abstract": "The literature on provable robustness in machine learning has primarily focused on static prediction problems, such as image classification, in which input samples are assumed to be independent and model performance is measured as an expectation over the input distribution. Robustness certificates are derived for individual input instances with the assumption that the model is evaluated on each instance separately. However, in many deep learning applications such as online content recommendation and stock market analysis, models use historical data to make predictions. Robustness certificates based on the assumption of independent input samples are not directly applicable in such scenarios. In this work, we focus on the provable robustness of machine learning models in the context of data streams, where inputs are presented as a sequence of potentially correlated items. We derive robustness certificates for models that use a fixed-size sliding window over the input stream. Our guarante",
    "link": "http://arxiv.org/abs/2303.16308",
    "context": "Title: Provable Robustness for Streaming Models with a Sliding Window. (arXiv:2303.16308v1 [cs.LG])\nAbstract: The literature on provable robustness in machine learning has primarily focused on static prediction problems, such as image classification, in which input samples are assumed to be independent and model performance is measured as an expectation over the input distribution. Robustness certificates are derived for individual input instances with the assumption that the model is evaluated on each instance separately. However, in many deep learning applications such as online content recommendation and stock market analysis, models use historical data to make predictions. Robustness certificates based on the assumption of independent input samples are not directly applicable in such scenarios. In this work, we focus on the provable robustness of machine learning models in the context of data streams, where inputs are presented as a sequence of potentially correlated items. We derive robustness certificates for models that use a fixed-size sliding window over the input stream. Our guarante",
    "path": "papers/23/03/2303.16308.json",
    "total_tokens": 819,
    "translated_title": "滑动窗口流模型的可证明稳健性",
    "translated_abstract": "机器学习中，有关可证明的稳健性的文献主要关注静态预测问题，如图像分类等，其中假定输入样本是独立的，并且模型性能是在输入分布上的期望。对于单个输入实例，可以得出稳健性证明，但是假设该模型对每个实例单独进行评估的稳健性证明不能直接应用于许多深度学习应用中。本文关注于数据流上机器学习模型的可证明鲁棒性，其中输入作为一系列可能相关的项呈现。我们为使用固定大小的滑动窗口的模型推导出了强稳健性证明，保证了整个输入序列，而不是单个样本，并为流机器学习模型提供了强稳健性保证。",
    "tldr": "本文关注于流数据上机器学习模型的可证明鲁棒性，为使用固定大小滑动窗口的模型提供了强稳健性证明。"
}