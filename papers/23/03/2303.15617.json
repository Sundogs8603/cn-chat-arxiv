{
    "title": "Online Learning for Incentive-Based Demand Response. (arXiv:2303.15617v1 [cs.LG])",
    "abstract": "In this paper, we consider the problem of learning online to manage Demand Response (DR) resources. A typical DR mechanism requires the DR manager to assign a baseline to the participating consumer, where the baseline is an estimate of the counterfactual consumption of the consumer had it not been called to provide the DR service. A challenge in estimating baseline is the incentive the consumer has to inflate the baseline estimate. We consider the problem of learning online to estimate the baseline and to optimize the operating costs over a period of time under such incentives. We propose an online learning scheme that employs least-squares for estimation with a perturbation to the reward price (for the DR services or load curtailment) that is designed to balance the exploration and exploitation trade-off that arises with online learning. We show that, our proposed scheme is able to achieve a very low regret of $\\mathcal{O}\\left((\\log{T})^2\\right)$ with respect to the optimal operating",
    "link": "http://arxiv.org/abs/2303.15617",
    "context": "Title: Online Learning for Incentive-Based Demand Response. (arXiv:2303.15617v1 [cs.LG])\nAbstract: In this paper, we consider the problem of learning online to manage Demand Response (DR) resources. A typical DR mechanism requires the DR manager to assign a baseline to the participating consumer, where the baseline is an estimate of the counterfactual consumption of the consumer had it not been called to provide the DR service. A challenge in estimating baseline is the incentive the consumer has to inflate the baseline estimate. We consider the problem of learning online to estimate the baseline and to optimize the operating costs over a period of time under such incentives. We propose an online learning scheme that employs least-squares for estimation with a perturbation to the reward price (for the DR services or load curtailment) that is designed to balance the exploration and exploitation trade-off that arises with online learning. We show that, our proposed scheme is able to achieve a very low regret of $\\mathcal{O}\\left((\\log{T})^2\\right)$ with respect to the optimal operating",
    "path": "papers/23/03/2303.15617.json",
    "total_tokens": 955,
    "translated_title": "针对基于激励的需求响应的在线学习",
    "translated_abstract": "本文研究了在线学习管理需求响应（DR）资源的问题。典型DR机制要求DR经理为参与的消费者分配一个基准，其中基准是消费者计数事实消耗的估计，如果不叫消费者提供DR服务，那么基准就是计数的理论消耗。估算基准的挑战在于消费者有鼓励膨胀基准估计的动机。我们考虑学习在线估算基线和在这样的激励下优化一段时间的操作成本。提出了一种在线学习方案，它采用最小二乘进行估计，同时在DR服务或负荷裁剪的激励价格上引入扰动，旨在平衡在线学习中出现的勘探和开发的折衷。我们证明了，我们的提议方案能够实现与最优操作相比非常低的遗憾度（$ \\mathcal {O} \\left((\\log {T})^2\\right)$）",
    "tldr": "本文研究了在线学习管理需求响应（DR）资源中消费者基准估计的问题，并提出了一种采用最小二乘进行估计的在线学习方案，再通过引入激励价格上的扰动实现勘探和开发的平衡。",
    "en_tdlr": "This paper proposes an online learning scheme for managing Demand Response (DR) resources, which addresses the challenge of estimating consumer baselines and optimizing operating costs under incentive-based load curtailment. Least-squares estimation with a perturbation to the incentive price is used to balance exploration and exploitation in online learning, achieving regret of $\\mathcal{O}\\left((\\log{T})^2\\right)$."
}