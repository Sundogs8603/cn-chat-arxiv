{
    "title": "Explainable Semantic Medical Image Segmentation with Style. (arXiv:2303.05696v1 [eess.IV])",
    "abstract": "Semantic medical image segmentation using deep learning has recently achieved high accuracy, making it appealing to clinical problems such as radiation therapy. However, the lack of high-quality semantically labelled data remains a challenge leading to model brittleness to small shifts to input data. Most works require extra data for semi-supervised learning and lack the interpretability of the boundaries of the training data distribution during training, which is essential for model deployment in clinical practice. We propose a fully supervised generative framework that can achieve generalisable segmentation with only limited labelled data by simultaneously constructing an explorable manifold during training. The proposed approach creates medical image style paired with a segmentation task driven discriminator incorporating end-to-end adversarial training. The discriminator is generalised to small domain shifts as much as permissible by the training data, and the generator automatical",
    "link": "http://arxiv.org/abs/2303.05696",
    "raw_ret": "{\n    \"translated_title\": \"可解释的样式语义医学图像分割\",\n    \"translated_abstract\": \"使用深度学习进行语义医学图像分割最近取得了很高的准确度，这使它对于放射治疗等临床问题非常有吸引力。然而，缺乏高质量的语义标注数据仍然是一个挑战，导致模型对输入数据的微小变化非常脆弱。大多数工作需要额外的数据进行半监督学习，并且缺乏在训练过程中对训练数据分布边界的可解释性，这对于模型在临床实践中的部署是必不可少的。我们提出了一个完全监督的生成框架，可以通过同时构建可探索流形来实现仅使用有限标记数据的可广义分割。所提出的方法创建了医学图像样式，配合使用分割任务驱动的鉴别器，结合端到端的对抗性训练。鉴别器尽可能地泛化到小的域偏移，而生成器则可以自动地避免生成任何不可解释的区域，从而实现模型的可解释性。\",\n    \"tldr\": \"该论文提出了一种基于生成对抗网络的可解释的样式语义医学图像分割方法，通过构建可探索的流形来实现仅使用有限标记数据的可广义分割，具有较好的泛化能力和可解释性。\"\n}<|im_sep|>",
    "total_tokens": 877,
    "ret": {
        "translated_title": "可解释的样式语义医学图像分割",
        "translated_abstract": "使用深度学习进行语义医学图像分割最近取得了很高的准确度，这使它对于放射治疗等临床问题非常有吸引力。然而，缺乏高质量的语义标注数据仍然是一个挑战，导致模型对输入数据的微小变化非常脆弱。大多数工作需要额外的数据进行半监督学习，并且缺乏在训练过程中对训练数据分布边界的可解释性，这对于模型在临床实践中的部署是必不可少的。我们提出了一个完全监督的生成框架，可以通过同时构建可探索流形来实现仅使用有限标记数据的可广义分割。所提出的方法创建了医学图像样式，配合使用分割任务驱动的鉴别器，结合端到端的对抗性训练。鉴别器尽可能地泛化到小的域偏移，而生成器则可以自动地避免生成任何不可解释的区域，从而实现模型的可解释性。",
        "tldr": "该论文提出了一种基于生成对抗网络的可解释的样式语义医学图像分割方法，通过构建可探索的流形来实现仅使用有限标记数据的可广义分割，具有较好的泛化能力和可解释性。"
    }
}