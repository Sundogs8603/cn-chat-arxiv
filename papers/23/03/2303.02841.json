{
    "title": "Model-Agnostic Meta-Learning for Natural Language Understanding Tasks in Finance. (arXiv:2303.02841v2 [cs.CL] UPDATED)",
    "abstract": "Natural language understanding(NLU) is challenging for finance due to the lack of annotated data and the specialized language in that domain. As a result, researchers have proposed to use pre-trained language model and multi-task learning to learn robust representations. However, aggressive fine-tuning often causes over-fitting and multi-task learning may favor tasks with significantly larger amounts data, etc. To address these problems, in this paper, we investigate model-agnostic meta-learning algorithm(MAML) in low-resource financial NLU tasks. Our contribution includes: 1. we explore the performance of MAML method with multiple types of tasks: GLUE datasets, SNLI, Sci-Tail and Financial PhraseBank; 2. we study the performance of MAML method with multiple single-type tasks: a real scenario stock price prediction problem with twitter text data. Our models achieve the state-of-the-art performance according to the experimental results, which demonstrate that our method can adapt fast a",
    "link": "http://arxiv.org/abs/2303.02841",
    "context": "Title: Model-Agnostic Meta-Learning for Natural Language Understanding Tasks in Finance. (arXiv:2303.02841v2 [cs.CL] UPDATED)\nAbstract: Natural language understanding(NLU) is challenging for finance due to the lack of annotated data and the specialized language in that domain. As a result, researchers have proposed to use pre-trained language model and multi-task learning to learn robust representations. However, aggressive fine-tuning often causes over-fitting and multi-task learning may favor tasks with significantly larger amounts data, etc. To address these problems, in this paper, we investigate model-agnostic meta-learning algorithm(MAML) in low-resource financial NLU tasks. Our contribution includes: 1. we explore the performance of MAML method with multiple types of tasks: GLUE datasets, SNLI, Sci-Tail and Financial PhraseBank; 2. we study the performance of MAML method with multiple single-type tasks: a real scenario stock price prediction problem with twitter text data. Our models achieve the state-of-the-art performance according to the experimental results, which demonstrate that our method can adapt fast a",
    "path": "papers/23/03/2303.02841.json",
    "total_tokens": 843,
    "translated_title": "金融自然语言理解任务中的模型无关元学习",
    "translated_abstract": "金融领域的自然语言理解因缺乏标注数据和特殊语言而具有挑战性。近年来，研究人员提出使用预训练语言模型和多任务学习来学习稳健的表示。然而，过度微调经常导致过拟合，多任务学习可能会偏袒大量数据的任务。为了解决这些问题，本文研究了低资源金融自然语言理解任务中的模型无关元学习算法。我们的贡献包括：1.我们探索了使用多种类型任务的MAML方法的性能：GLUE数据集，SNLI，Sci-Tail和Financial PhraseBank；2.我们研究了在一个真实场景的基于推特文本的股票价格预测问题中使用MAML方法的性能。根据实验结果，我们的模型实现了最先进的性能，证明了我们的方法可以快速适应。",
    "tldr": "本文研究了金融领域自然语言理解任务中的模型无关元学习算法，取得了最先进的性能表现。",
    "en_tdlr": "This paper investigates the model-agnostic meta-learning algorithm for natural language understanding tasks in low-resource finance, achieving state-of-the-art performance and demonstrating the effectiveness of the proposed approach."
}