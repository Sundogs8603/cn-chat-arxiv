{
    "title": "Model-to-Circuit Cross-Approximation For Printed Machine Learning Classifiers. (arXiv:2303.08255v1 [cs.LG])",
    "abstract": "Printed electronics (PE) promises on-demand fabrication, low non-recurring engineering costs, and sub-cent fabrication costs. It also allows for high customization that would be infeasible in silicon, and bespoke architectures prevail to improve the efficiency of emerging PE machine learning (ML) applications. Nevertheless, large feature sizes in PE prohibit the realization of complex ML models in PE, even with bespoke architectures. In this work, we present an automated, cross-layer approximation framework tailored to bespoke architectures that enable complex ML models, such as Multi-Layer Perceptrons (MLPs) and Support Vector Machines (SVMs), in PE. Our framework adopts cooperatively a hardware-driven coefficient approximation of the ML model at algorithmic level, a netlist pruning at logic level, and a voltage over-scaling at the circuit level. Extensive experimental evaluation on 12 MLPs and 12 SVMs and more than 6000 approximate and exact designs demonstrates that our model-to-cir",
    "link": "http://arxiv.org/abs/2303.08255",
    "context": "Title: Model-to-Circuit Cross-Approximation For Printed Machine Learning Classifiers. (arXiv:2303.08255v1 [cs.LG])\nAbstract: Printed electronics (PE) promises on-demand fabrication, low non-recurring engineering costs, and sub-cent fabrication costs. It also allows for high customization that would be infeasible in silicon, and bespoke architectures prevail to improve the efficiency of emerging PE machine learning (ML) applications. Nevertheless, large feature sizes in PE prohibit the realization of complex ML models in PE, even with bespoke architectures. In this work, we present an automated, cross-layer approximation framework tailored to bespoke architectures that enable complex ML models, such as Multi-Layer Perceptrons (MLPs) and Support Vector Machines (SVMs), in PE. Our framework adopts cooperatively a hardware-driven coefficient approximation of the ML model at algorithmic level, a netlist pruning at logic level, and a voltage over-scaling at the circuit level. Extensive experimental evaluation on 12 MLPs and 12 SVMs and more than 6000 approximate and exact designs demonstrates that our model-to-cir",
    "path": "papers/23/03/2303.08255.json",
    "total_tokens": 1007,
    "translated_title": "印刷机器学习分类器的模型到电路的交叉逼近",
    "translated_abstract": "印刷电子（PE）能够按需制造，具有低不重复工程成本和亚分之一的制造成本。它还允许高度定制，这在硅片上是不可行的，而且特殊的体系结构也盛行于新兴的PE机器学习（ML）应用中以提高效率。然而，PE中的大特征尺寸阻止了复杂的ML模型的实现，即使使用特殊的体系结构也是如此。在这项工作中，我们提出了一个自动化的，跨层逼近框架，专为特定的体系结构定制，可以在PE中实现复杂的ML模型，如多层感知器（MLPs）和支持向量机（SVMs）。我们的框架在算法级别采用了硬件驱动的系数逼近、逻辑级别的电路列表修剪和电路级别的电压超标，全面合作。对12个MLP和12个SVM进行了广泛的实验评估，以及6000多个近似和精确设计，表明我们的模型到电路的交叉逼近框架可以将电路大小压缩高达95%，同时保证分类精度损失平均在4%内。",
    "tldr": "本文提出了一个自动化的、面向特定体系结构的跨层逼近框架，能在PE中实现复杂的ML模型，压缩电路大小高达95%，分类精度损失平均在4%内。",
    "en_tdlr": "This paper proposes an automated, cross-layer approximation framework tailored to specific architectures that enables complex machine learning models in printed electronics, compressing circuit size by up to 95% while constraining classification accuracy loss within an average of 4%."
}