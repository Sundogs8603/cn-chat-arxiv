{
    "title": "Heterogeneity of AI-Induced Societal Harms and the Failure of Omnibus AI Laws. (arXiv:2303.11196v2 [cs.AI] UPDATED)",
    "abstract": "AI-induced societal harms mirror existing problems in domains where AI replaces or complements traditional methodologies. However, trustworthy AI discourses postulate the homogeneity of AI, aim to derive common causes regarding the harms they generate, and demand uniform human interventions. Such AI monism has spurred legislation for omnibus AI laws requiring any high-risk AI systems to comply with a full, uniform package of rules on fairness, transparency, accountability, human oversight, accuracy, robustness, and security, as demonstrated by the EU AI Regulation and the U.S. draft Algorithmic Accountability Act. However, it is irrational to require high-risk or critical AIs to comply with all the safety, fairness, accountability, and privacy regulations when it is possible to separate AIs entailing safety risks, biases, infringements, and privacy problems. Legislators should gradually adapt existing regulations by categorizing AI systems according to the types of societal harms they ",
    "link": "http://arxiv.org/abs/2303.11196",
    "context": "Title: Heterogeneity of AI-Induced Societal Harms and the Failure of Omnibus AI Laws. (arXiv:2303.11196v2 [cs.AI] UPDATED)\nAbstract: AI-induced societal harms mirror existing problems in domains where AI replaces or complements traditional methodologies. However, trustworthy AI discourses postulate the homogeneity of AI, aim to derive common causes regarding the harms they generate, and demand uniform human interventions. Such AI monism has spurred legislation for omnibus AI laws requiring any high-risk AI systems to comply with a full, uniform package of rules on fairness, transparency, accountability, human oversight, accuracy, robustness, and security, as demonstrated by the EU AI Regulation and the U.S. draft Algorithmic Accountability Act. However, it is irrational to require high-risk or critical AIs to comply with all the safety, fairness, accountability, and privacy regulations when it is possible to separate AIs entailing safety risks, biases, infringements, and privacy problems. Legislators should gradually adapt existing regulations by categorizing AI systems according to the types of societal harms they ",
    "path": "papers/23/03/2303.11196.json",
    "total_tokens": 1045,
    "translated_abstract": "AI引发的社会危害反映了AI替代或补充传统方法的领域中存在的问题。然而，可信的AI话语假定AI的同质性，旨在推导出它们产生的危害的共同原因，并要求统一的人类干预。这种AI单一主义已经推动了综合AI法律的立法，要求任何高风险的AI系统都要遵守关于公平、透明、问责、人类监督、准确性、强健性和安全性的一整套规则，这已经在欧盟AI法规和美国的算法问责法案中体现出来。然而，要求高风险或关键的AI遵守所有安全、公平、问责和隐私规定是不合理的，因为有可能将涉及安全风险、偏见、侵权和隐私问题的AI分开。立法者应逐步根据它们引起的社会危害的类型对AI系统进行分类，并调整现有的监管规定。",
    "tldr": "AI单一主义现在已经推动了综合AI法律的立法，要求任何高风险的AI系统都要遵守关于公平、透明、问责、人类监督、准确性、强健性和安全性的一整套规则。但是，要求高风险或关键的AI遵守所有安全、公平、问责和隐私规定是不合理的，因为有可能将涉及安全风险、偏见、侵权和隐私问题的AI分开，立法者应逐步根据它们引起的社会危害的类型对AI系统进行分类，并调整现有的监管规定。"
}