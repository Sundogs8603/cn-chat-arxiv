{
    "title": "FedGH: Heterogeneous Federated Learning with Generalized Global Header. (arXiv:2303.13137v1 [cs.LG])",
    "abstract": "Federated learning (FL) is an emerging machine learning paradigm that allows multiple parties to train a shared model collaboratively in a privacy-preserving manner. Existing horizontal FL methods generally assume that the FL server and clients hold the same model structure. However, due to system heterogeneity and the need for personalization, enabling clients to hold models with diverse structures has become an important direction. Existing model-heterogeneous FL approaches often require publicly available datasets and incur high communication and/or computational costs, which limit their performances. To address these limitations, we propose the Federated Global prediction Header (FedGH) approach. It is a communication and computation-efficient model-heterogeneous FL framework which trains a shared generalized global prediction header with representations extracted by heterogeneous extractors for clients' models at the FL server. The trained generalized global prediction header lear",
    "link": "http://arxiv.org/abs/2303.13137",
    "context": "Title: FedGH: Heterogeneous Federated Learning with Generalized Global Header. (arXiv:2303.13137v1 [cs.LG])\nAbstract: Federated learning (FL) is an emerging machine learning paradigm that allows multiple parties to train a shared model collaboratively in a privacy-preserving manner. Existing horizontal FL methods generally assume that the FL server and clients hold the same model structure. However, due to system heterogeneity and the need for personalization, enabling clients to hold models with diverse structures has become an important direction. Existing model-heterogeneous FL approaches often require publicly available datasets and incur high communication and/or computational costs, which limit their performances. To address these limitations, we propose the Federated Global prediction Header (FedGH) approach. It is a communication and computation-efficient model-heterogeneous FL framework which trains a shared generalized global prediction header with representations extracted by heterogeneous extractors for clients' models at the FL server. The trained generalized global prediction header lear",
    "path": "papers/23/03/2303.13137.json",
    "total_tokens": 954,
    "translated_title": "FedGH:异构联邦学习与广义全局头",
    "translated_abstract": "联邦学习(Federated learning, FL)是一种新兴的机器学习范式，允许多个参与方在隐私保护的情况下协作训练共享模型。现有横向FL方法通常假定FL服务器和客户端持有相同的模型结构。然而，由于系统异构和个性化需求，使得允许客户端持有具有不同结构的模型已成为一个重要的方向。现有的模型异构FL方法通常需要公开可用的数据集，并产生高通信和/或计算成本，这限制了它们的性能。为解决这些限制，我们提出了联邦全局预测头(FedGH)方法。它是一种通信和计算效率高的模型异构FL框架，通过在FL服务器上对客户端模型提取的表示进行训练来训练共享的广义全局预测头。通过FedGH训练的广义全局预测头可以直接部署在客户端设备上，以实现高效的本地推理。我们在基准数据集和模型上的实验表明，FedGH在准确性、通信效率和模型个性化能力方面优于现有的模型异构FL方法。",
    "tldr": "FedGH是一种异构联邦学习方法，可以使客户端持有具有不同结构的模型，通过训练共享的广义全局预测头来提高效率和性能。",
    "en_tdlr": "FedGH is a heterogeneous federated learning method that allows clients to hold models with diverse structures, and improves efficiency and performance by training a shared generalized global prediction header."
}