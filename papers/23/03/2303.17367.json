{
    "title": "A BERT-based Unsupervised Grammatical Error Correction Framework. (arXiv:2303.17367v1 [cs.CL])",
    "abstract": "Grammatical error correction (GEC) is a challenging task of natural language processing techniques. While more attempts are being made in this approach for universal languages like English or Chinese, relatively little work has been done for low-resource languages for the lack of large annotated corpora. In low-resource languages, the current unsupervised GEC based on language model scoring performs well. However, the pre-trained language model is still to be explored in this context. This study proposes a BERT-based unsupervised GEC framework, where GEC is viewed as multi-class classification task. The framework contains three modules: data flow construction module, sentence perplexity scoring module, and error detecting and correcting module. We propose a novel scoring method for pseudo-perplexity to evaluate a sentence's probable correctness and construct a Tagalog corpus for Tagalog GEC research. It obtains competitive performance on the Tagalog corpus we construct and open-source ",
    "link": "http://arxiv.org/abs/2303.17367",
    "context": "Title: A BERT-based Unsupervised Grammatical Error Correction Framework. (arXiv:2303.17367v1 [cs.CL])\nAbstract: Grammatical error correction (GEC) is a challenging task of natural language processing techniques. While more attempts are being made in this approach for universal languages like English or Chinese, relatively little work has been done for low-resource languages for the lack of large annotated corpora. In low-resource languages, the current unsupervised GEC based on language model scoring performs well. However, the pre-trained language model is still to be explored in this context. This study proposes a BERT-based unsupervised GEC framework, where GEC is viewed as multi-class classification task. The framework contains three modules: data flow construction module, sentence perplexity scoring module, and error detecting and correcting module. We propose a novel scoring method for pseudo-perplexity to evaluate a sentence's probable correctness and construct a Tagalog corpus for Tagalog GEC research. It obtains competitive performance on the Tagalog corpus we construct and open-source ",
    "path": "papers/23/03/2303.17367.json",
    "total_tokens": 972,
    "translated_title": "基于BERT的无监督语法纠错框架",
    "translated_abstract": "语法错误纠正是自然语言处理技术中的一项具有挑战性的任务。虽然现在已经有更多的尝试在英语或汉语等通用语言的领域进行研究，但由于缺乏大型注释语料库，对于低资源语言的工作仍然相对较少。在低资源语言领域，目前基于语言模型的无监督GEC具有较好的表现。但是，在这种情况下，预训练的语言模型仍需探索。本研究提出了一种基于BERT的无监督GEC框架，将GEC视为多类分类任务。该框架包含三个模块：数据流构建模块、句子困惑度评分模块和错误检测和纠正模块。我们提出了一种新颖的伪困惑度评分方法，用于评估句子的可能正确性，并建立了一个菲律宾语语料库，用于进行菲律宾语GEC研究。该方法在我们构建的菲律宾语语料库上获得了竞争性的表现，并已在开源平台上公布。",
    "tldr": "本研究提出了一种基于BERT的无监督语法纠错框架，用于低资源语言的GEC任务。该框架包含三个模块，并提出一种新颖的伪困惑度评分方法，该方法已经在菲律宾语GEC任务上取得了竞争性的表现。",
    "en_tdlr": "This study proposes a BERT-based unsupervised grammatical error correction framework for low-resource languages, containing three modules and using a novel pseudo-perplexity scoring method, which has achieved competitive performance on Tagalog GEC task."
}