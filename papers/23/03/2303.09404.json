{
    "title": "Speech Modeling with a Hierarchical Transformer Dynamical VAE. (arXiv:2303.09404v1 [eess.AS])",
    "abstract": "The dynamical variational autoencoders (DVAEs) are a family of latent-variable deep generative models that extends the VAE to model a sequence of observed data and a corresponding sequence of latent vectors. In almost all the DVAEs of the literature, the temporal dependencies within each sequence and across the two sequences are modeled with recurrent neural networks. In this paper, we propose to model speech signals with the Hierarchical Transformer DVAE (HiT-DVAE), which is a DVAE with two levels of latent variable (sequence-wise and frame-wise) and in which the temporal dependencies are implemented with the Transformer architecture. We show that HiT-DVAE outperforms several other DVAEs for speech spectrogram modeling, while enabling a simpler training procedure, revealing its high potential for downstream low-level speech processing tasks such as speech enhancement.",
    "link": "http://arxiv.org/abs/2303.09404",
    "context": "Title: Speech Modeling with a Hierarchical Transformer Dynamical VAE. (arXiv:2303.09404v1 [eess.AS])\nAbstract: The dynamical variational autoencoders (DVAEs) are a family of latent-variable deep generative models that extends the VAE to model a sequence of observed data and a corresponding sequence of latent vectors. In almost all the DVAEs of the literature, the temporal dependencies within each sequence and across the two sequences are modeled with recurrent neural networks. In this paper, we propose to model speech signals with the Hierarchical Transformer DVAE (HiT-DVAE), which is a DVAE with two levels of latent variable (sequence-wise and frame-wise) and in which the temporal dependencies are implemented with the Transformer architecture. We show that HiT-DVAE outperforms several other DVAEs for speech spectrogram modeling, while enabling a simpler training procedure, revealing its high potential for downstream low-level speech processing tasks such as speech enhancement.",
    "path": "papers/23/03/2303.09404.json",
    "total_tokens": 869,
    "translated_title": "一种层次Transformer动态变分自编码器的语音建模",
    "translated_abstract": "动态变分自编码器（DVAEs）是一类潜变量深度生成模型，扩展了VAE以对观察到的数据序列和相应的潜向量序列进行建模。在文献中的几乎所有DVAEs中，每个序列内部和两个序列之间的时间依赖性都由循环神经网络来建模。在本文中，我们提出使用Hierarchical Transformer DVAE（HiT-DVAE）模拟语音信号，它是一种具有两个潜变量水平（序列级和帧级）的DVAE，并且其中时间依赖性是使用Transformer架构实现的。我们展示了HiT-DVAE在语音频谱建模方面优于其他若干DVAEs，同时还能够实现更简单的训练过程，显示出其在下游低级别语音处理任务（如语音增强）中具有很高的潜力。",
    "tldr": "HiT-DVAE是一种层次Transformer动态变分自编码器，能够优于其他DVAEs在语音频谱建模方面。它具有两个潜变量水平和简单的训练过程，并且具有很高的潜力在低级别语音处理方面。",
    "en_tdlr": "HiT-DVAE is a hierarchical Transformer dynamical VAE that outperforms other DVAEs in speech spectrogram modeling. It has two levels of latent variables and a simpler training procedure, and shows high potential for low-level speech processing tasks."
}