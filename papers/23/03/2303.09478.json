{
    "title": "Arbitrary Order Meta-Learning with Simple Population-Based Evolution. (arXiv:2303.09478v1 [cs.LG])",
    "abstract": "Meta-learning, the notion of learning to learn, enables learning systems to quickly and flexibly solve new tasks. This usually involves defining a set of outer-loop meta-parameters that are then used to update a set of inner-loop parameters. Most meta-learning approaches use complicated and computationally expensive bi-level optimisation schemes to update these meta-parameters. Ideally, systems should perform multiple orders of meta-learning, i.e. to learn to learn to learn and so on, to accelerate their own learning. Unfortunately, standard meta-learning techniques are often inappropriate for these higher-order meta-parameters because the meta-optimisation procedure becomes too complicated or unstable. Inspired by the higher-order meta-learning we observe in real-world evolution, we show that using simple population-based evolution implicitly optimises for arbitrarily-high order meta-parameters. First, we theoretically prove and empirically show that population-based evolution implici",
    "link": "http://arxiv.org/abs/2303.09478",
    "context": "Title: Arbitrary Order Meta-Learning with Simple Population-Based Evolution. (arXiv:2303.09478v1 [cs.LG])\nAbstract: Meta-learning, the notion of learning to learn, enables learning systems to quickly and flexibly solve new tasks. This usually involves defining a set of outer-loop meta-parameters that are then used to update a set of inner-loop parameters. Most meta-learning approaches use complicated and computationally expensive bi-level optimisation schemes to update these meta-parameters. Ideally, systems should perform multiple orders of meta-learning, i.e. to learn to learn to learn and so on, to accelerate their own learning. Unfortunately, standard meta-learning techniques are often inappropriate for these higher-order meta-parameters because the meta-optimisation procedure becomes too complicated or unstable. Inspired by the higher-order meta-learning we observe in real-world evolution, we show that using simple population-based evolution implicitly optimises for arbitrarily-high order meta-parameters. First, we theoretically prove and empirically show that population-based evolution implici",
    "path": "papers/23/03/2303.09478.json",
    "total_tokens": 794,
    "translated_title": "简单基于群体进化的任意阶元学习",
    "translated_abstract": "元学习是学习如何学习的概念，能够使学习系统迅速、灵活地解决新任务。通常需要定义一组外循环元参数，然后用它们来更新一组内部循环参数。大多数元学习方法使用复杂的、计算开销很大的双层优化方案来更新这些元参数，但标准的元学习技术往往不适用于更高阶的元参数，因为元优化过程变得太复杂或不稳定。受到真实世界进化中高阶元学习的启发，我们显示出使用简单基于群体进化可以隐式地优化任意高阶的元参数。首先，我们从理论上证明并经验性地证明了基于群体进化隐式地优化了任意阶元参数。",
    "tldr": "本文提出了一种简单的基于群体进化的元学习方法，可以隐式地优化任意高阶的元参数，从而加速学习。",
    "en_tdlr": "This paper proposes a simple population-based evolution method for meta-learning, which can implicitly optimize arbitrarily high-order meta-parameters to accelerate learning, inspired by the higher-order meta-learning in real-world evolution."
}