{
    "title": "Worst-Case Control and Learning Using Partial Observations Over an Infinite Time-Horizon. (arXiv:2303.16321v1 [math.OC])",
    "abstract": "Safety-critical cyber-physical systems require control strategies whose worst-case performance is robust against adversarial disturbances and modeling uncertainties. In this paper, we present a framework for approximate control and learning in partially observed systems to minimize the worst-case discounted cost over an infinite time-horizon. We model disturbances to the system as finite-valued uncertain variables with unknown probability distributions. For problems with known system dynamics, we construct a dynamic programming (DP) decomposition to compute the optimal control strategy. Our first contribution is to define information states that improve the computational tractability of this DP without loss of optimality. Then, we describe a simplification for a class of problems where the incurred cost is observable at each time-instance. Our second contribution is a definition of approximate information states that can be constructed or learned directly from observed data for problem",
    "link": "http://arxiv.org/abs/2303.16321",
    "context": "Title: Worst-Case Control and Learning Using Partial Observations Over an Infinite Time-Horizon. (arXiv:2303.16321v1 [math.OC])\nAbstract: Safety-critical cyber-physical systems require control strategies whose worst-case performance is robust against adversarial disturbances and modeling uncertainties. In this paper, we present a framework for approximate control and learning in partially observed systems to minimize the worst-case discounted cost over an infinite time-horizon. We model disturbances to the system as finite-valued uncertain variables with unknown probability distributions. For problems with known system dynamics, we construct a dynamic programming (DP) decomposition to compute the optimal control strategy. Our first contribution is to define information states that improve the computational tractability of this DP without loss of optimality. Then, we describe a simplification for a class of problems where the incurred cost is observable at each time-instance. Our second contribution is a definition of approximate information states that can be constructed or learned directly from observed data for problem",
    "path": "papers/23/03/2303.16321.json",
    "total_tokens": 894,
    "translated_title": "无限时间视角下利用部分观测进行最坏情况控制与学习",
    "translated_abstract": "安全关键的网络物理系统需要良好的控制策略来应对敌对干扰和建模不确定性。本文提出了一个框架，利用部分观测系统进行近似控制和学习，以最小化无限时间视角下的最坏情况贴现成本。我们将对系统的干扰建模为具有未知概率分布的有限值不确定变量。对于已知系统动力学的问题，我们构建了一个动态规划（DP）分解来计算最优控制策略。我们的第一贡献是定义信息状态，提高了DP的计算可处理性，而不损失最优性。然后，我们描述了一类在每个时间点产生可观测成本的问题的简化。我们的第二个贡献是定义了可以从观测数据中直接构建或学习的近似信息状态。",
    "tldr": "本文提出了无限时间视角下部分观测系统的最坏情况控制和学习的框架，能够利用未知概率分布的有限值不确定变量，并能够通过定义信息状态来提高动态规划的计算可处理性，同时提出了可从观测数据中构建或学习的近似信息状态。",
    "en_tdlr": "This paper presents a framework for worst-case control and learning in partially observed systems over an infinite time-horizon, which can model disturbances as uncertain variables with unknown probability distributions; information states are defined to improve computational tractability of the dynamic programming, and approximate information states can be constructed or learned directly from the observed data."
}