{
    "title": "Adaptive Conformal Prediction by Reweighting Nonconformity Score. (arXiv:2303.12695v1 [stat.ML])",
    "abstract": "Despite attractive theoretical guarantees and practical successes, Predictive Interval (PI) given by Conformal Prediction (CP) may not reflect the uncertainty of a given model. This limitation arises from CP methods using a constant correction for all test points, disregarding their individual uncertainties, to ensure coverage properties. To address this issue, we propose using a Quantile Regression Forest (QRF) to learn the distribution of nonconformity scores and utilizing the QRF's weights to assign more importance to samples with residuals similar to the test point. This approach results in PI lengths that are more aligned with the model's uncertainty. In addition, the weights learnt by the QRF provide a partition of the features space, allowing for more efficient computations and improved adaptiveness of the PI through groupwise conformalization. Our approach enjoys an assumption-free finite sample marginal and training-conditional coverage, and under suitable assumptions, it also",
    "link": "http://arxiv.org/abs/2303.12695",
    "context": "Title: Adaptive Conformal Prediction by Reweighting Nonconformity Score. (arXiv:2303.12695v1 [stat.ML])\nAbstract: Despite attractive theoretical guarantees and practical successes, Predictive Interval (PI) given by Conformal Prediction (CP) may not reflect the uncertainty of a given model. This limitation arises from CP methods using a constant correction for all test points, disregarding their individual uncertainties, to ensure coverage properties. To address this issue, we propose using a Quantile Regression Forest (QRF) to learn the distribution of nonconformity scores and utilizing the QRF's weights to assign more importance to samples with residuals similar to the test point. This approach results in PI lengths that are more aligned with the model's uncertainty. In addition, the weights learnt by the QRF provide a partition of the features space, allowing for more efficient computations and improved adaptiveness of the PI through groupwise conformalization. Our approach enjoys an assumption-free finite sample marginal and training-conditional coverage, and under suitable assumptions, it also",
    "path": "papers/23/03/2303.12695.json",
    "total_tokens": 894,
    "translated_title": "非拟合分数重新权重实现自适应一致性预测",
    "translated_abstract": "尽管具有吸引人的理论保证和实际成功，但由一致性预测（CP）给出的预测区间（PI）可能无法反映给定模型的不确定性。这种限制源于CP方法对所有测试点使用常数修正，无视它们的不确定性，以确保覆盖特性。为了解决这个问题，我们提出使用分位数回归森林（QRF）来学习非拟合分数的分布，并利用QRF的权重将更多的重要性分配给残差与测试点相似的样本。这种方法导致的PI长度更符合模型的不确定性。此外，QRF学习到的权重提供了特征空间的划分，通过组合一致化可以实现更高效的计算和改进PI的适应性。我们的方法享有基于样本和基于训练条件的无假设有限覆盖率，并在适当的假设下，也可以",
    "tldr": "该论文提出了一种新方法，利用分位数回归森林来学习非拟合分数的分布，并利用其权重分配更多的重要性给残差与测试点相似的样本，从而实现更符合模型的不确定性的预测区间。"
}