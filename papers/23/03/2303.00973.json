{
    "title": "Image Labels Are All You Need for Coarse Seagrass Segmentation. (arXiv:2303.00973v2 [cs.CV] UPDATED)",
    "abstract": "Seagrass meadows serve as critical carbon sinks, but estimating the amount of carbon they store requires knowledge of the seagrass species present. Underwater and surface vehicles equipped with machine learning algorithms can help to accurately estimate the composition and extent of seagrass meadows at scale. However, previous approaches for seagrass detection and classification have required supervision from patch-level labels. In this paper, we reframe seagrass classification as a weakly supervised coarse segmentation problem where image-level labels are used during training (25 times fewer labels compared to patch-level labeling) and patch-level outputs are obtained at inference time. To this end, we introduce SeaFeats, an architecture that uses unsupervised contrastive pre-training and feature similarity, and SeaCLIP, a model that showcases the effectiveness of large language models as a supervisory signal in domain-specific applications. We demonstrate that an ensemble of SeaFeats",
    "link": "http://arxiv.org/abs/2303.00973",
    "context": "Title: Image Labels Are All You Need for Coarse Seagrass Segmentation. (arXiv:2303.00973v2 [cs.CV] UPDATED)\nAbstract: Seagrass meadows serve as critical carbon sinks, but estimating the amount of carbon they store requires knowledge of the seagrass species present. Underwater and surface vehicles equipped with machine learning algorithms can help to accurately estimate the composition and extent of seagrass meadows at scale. However, previous approaches for seagrass detection and classification have required supervision from patch-level labels. In this paper, we reframe seagrass classification as a weakly supervised coarse segmentation problem where image-level labels are used during training (25 times fewer labels compared to patch-level labeling) and patch-level outputs are obtained at inference time. To this end, we introduce SeaFeats, an architecture that uses unsupervised contrastive pre-training and feature similarity, and SeaCLIP, a model that showcases the effectiveness of large language models as a supervisory signal in domain-specific applications. We demonstrate that an ensemble of SeaFeats",
    "path": "papers/23/03/2303.00973.json",
    "total_tokens": 878,
    "translated_title": "图像标签是粗糙海草分割的全部所需",
    "translated_abstract": "海草草原是重要的碳汇，但估计存储的碳量需要知道存在的海草物种。配备机器学习算法的水下和水面载具可以帮助准确估计海草草原的组成和范围。然而，以往的海草检测和分类方法需要从补丁级标签进行监督。在本文中，我们将海草分类重新定义为弱监督的粗糙分割问题，在训练过程中使用图像级标签（比补丁级标注少25倍），并在推理时获得补丁级输出。为此，我们引入了SeaFeats，一种使用无监督对比预训练和特征相似性的体系结构，以及SeaCLIP，一个展示大型语言模型作为域特定应用中监督信号效果的模型。我们证明了一个SeaFeats集合的效果。",
    "tldr": "本文将海草分类重新定义为弱监督的粗糙分割问题，使用图像级标签进行训练，推理时获得补丁级输出。通过SeaFeats和SeaCLIP模型的引入和应用，证明了其在海草识别和分类中的有效性。",
    "en_tdlr": "This paper reframes seagrass classification as a weakly supervised coarse segmentation problem, using image-level labels for training and obtaining patch-level outputs at inference time. The effectiveness of SeaFeats and SeaCLIP models is demonstrated in seagrass detection and classification."
}