{
    "title": "CoBIT: A Contrastive Bi-directional Image-Text Generation Model. (arXiv:2303.13455v1 [cs.CV])",
    "abstract": "The field of vision and language has witnessed a proliferation of pre-trained foundation models. Most existing methods are independently pre-trained with contrastive objective like CLIP, image-to-text generative objective like PaLI, or text-to-image generative objective like Parti. However, the three objectives can be pre-trained on the same data, image-text pairs, and intuitively they complement each other as contrasting provides global alignment capacity and generation grants fine-grained understanding. In this work, we present a Contrastive Bi-directional Image-Text generation model (CoBIT), which attempts to unify the three pre-training objectives in one framework. Specifically, CoBIT employs a novel unicoder-decoder structure, consisting of an image unicoder, a text unicoder and a cross-modal decoder. The image/text unicoders can switch between encoding and decoding in different tasks, enabling flexibility and shared knowledge that benefits both image-to-text and text-to-image gen",
    "link": "http://arxiv.org/abs/2303.13455",
    "context": "Title: CoBIT: A Contrastive Bi-directional Image-Text Generation Model. (arXiv:2303.13455v1 [cs.CV])\nAbstract: The field of vision and language has witnessed a proliferation of pre-trained foundation models. Most existing methods are independently pre-trained with contrastive objective like CLIP, image-to-text generative objective like PaLI, or text-to-image generative objective like Parti. However, the three objectives can be pre-trained on the same data, image-text pairs, and intuitively they complement each other as contrasting provides global alignment capacity and generation grants fine-grained understanding. In this work, we present a Contrastive Bi-directional Image-Text generation model (CoBIT), which attempts to unify the three pre-training objectives in one framework. Specifically, CoBIT employs a novel unicoder-decoder structure, consisting of an image unicoder, a text unicoder and a cross-modal decoder. The image/text unicoders can switch between encoding and decoding in different tasks, enabling flexibility and shared knowledge that benefits both image-to-text and text-to-image gen",
    "path": "papers/23/03/2303.13455.json",
    "total_tokens": 918,
    "translated_title": "CoBIT: 一种对比式双向图文生成模型",
    "translated_abstract": "在视觉和语言领域中，已经出现了许多与对比性目标（如CLIP）、图像到文本生成目标（如PaLI）或文本到图像生成目标（如Parti）相对应的预训练基础模型。然而，这三个目标可以在相同的数据——图像文本对上预训练，并且相互补充，因为对比提供了全局对齐能力，生成也提供了细粒度理解。本文提出了一种对比式双向图文生成模型（CoBIT），试图将三个预训练目标统一到一个框架中。具体地，CoBIT采用了一种新颖的unicoder-decoder结构，包括图像unicoder、文本unicoder和跨模态decoder。图像/文本unicoders可以在不同任务中在编码和解码之间进行切换，从而实现了灵活性和共享知识，对图像到文本和文本到图像生成任务都有益处。",
    "tldr": "CoBIT是一种对比式双向图文生成模型，可以统一对比、图像到文本和文本到图像的预训练目标。它采用了一种新颖的unicoder-decoder结构，灵活性高，共享知识，对图像到文本和文本到图像生成任务都有益处。",
    "en_tdlr": "CoBIT is a contrastive bi-directional image-text generation model that unifies the pre-training objectives of contrast, image-to-text generation, and text-to-image generation. It employs a novel unicoder-decoder structure, which offers flexibility and shared knowledge for both image-to-text and text-to-image generative tasks."
}