{
    "title": "Ablating Concepts in Text-to-Image Diffusion Models. (arXiv:2303.13516v1 [cs.CV])",
    "abstract": "Large-scale text-to-image diffusion models can generate high-fidelity images with powerful compositional ability. However, these models are typically trained on an enormous amount of Internet data, often containing copyrighted material, licensed images, and personal photos. Furthermore, they have been found to replicate the style of various living artists or memorize exact training samples. How can we remove such copyrighted concepts or images without retraining the model from scratch? To achieve this goal, we propose an efficient method of ablating concepts in the pretrained model, i.e., preventing the generation of a target concept. Our algorithm learns to match the image distribution for a target style, instance, or text prompt we wish to ablate to the distribution corresponding to an anchor concept. This prevents the model from generating target concepts given its text condition. Extensive experiments show that our method can successfully prevent the generation of the ablated conce",
    "link": "http://arxiv.org/abs/2303.13516",
    "context": "Title: Ablating Concepts in Text-to-Image Diffusion Models. (arXiv:2303.13516v1 [cs.CV])\nAbstract: Large-scale text-to-image diffusion models can generate high-fidelity images with powerful compositional ability. However, these models are typically trained on an enormous amount of Internet data, often containing copyrighted material, licensed images, and personal photos. Furthermore, they have been found to replicate the style of various living artists or memorize exact training samples. How can we remove such copyrighted concepts or images without retraining the model from scratch? To achieve this goal, we propose an efficient method of ablating concepts in the pretrained model, i.e., preventing the generation of a target concept. Our algorithm learns to match the image distribution for a target style, instance, or text prompt we wish to ablate to the distribution corresponding to an anchor concept. This prevents the model from generating target concepts given its text condition. Extensive experiments show that our method can successfully prevent the generation of the ablated conce",
    "path": "papers/23/03/2303.13516.json",
    "total_tokens": 878,
    "translated_title": "文本到图像扩散模型中的概念消融",
    "translated_abstract": "大规模的文本到图像扩散模型具有强大的组合能力，可以生成高保真度的图片。然而，这些模型通常需要在数量庞大的网络数据上进行训练，往往包含有版权材料、授权图像和个人照片。此外，这些模型已经被发现能够模仿不同艺术家的风格或记住准确的训练样本。如何在不重新训练模型的情况下去除这些版权概念或图像？为了达成这个目标，我们提出了一种有效的方法，在预训练模型中实现概念消融，即防止生成目标概念。我们的算法学习如何匹配一个锚定概念对应的图像分布和与目标风格、实例或文本提示相关的图像分布，以防止模型根据其文本条件生成目标概念。广泛的实验证明，我们的方法可以成功地防止消融概念的生成。",
    "tldr": "本论文提出了一种有效的方法，在不重新训练模型的情况下实现了预训练模型中的概念消融，可以消除文本到图像生成中的版权问题和样本记忆问题。",
    "en_tdlr": "This paper proposes an efficient method to perform ablating concepts in pretrained text-to-image diffusion models, which can remove copyright and sample memorization issues in generating images from text without the need to retrain the model."
}