{
    "title": "Deep Active Learning with Contrastive Learning Under Realistic Data Pool Assumptions. (arXiv:2303.14433v1 [cs.CV])",
    "abstract": "Active learning aims to identify the most informative data from an unlabeled data pool that enables a model to reach the desired accuracy rapidly. This benefits especially deep neural networks which generally require a huge number of labeled samples to achieve high performance. Most existing active learning methods have been evaluated in an ideal setting where only samples relevant to the target task, i.e., in-distribution samples, exist in an unlabeled data pool. A data pool gathered from the wild, however, is likely to include samples that are irrelevant to the target task at all and/or too ambiguous to assign a single class label even for the oracle. We argue that assuming an unlabeled data pool consisting of samples from various distributions is more realistic. In this work, we introduce new active learning benchmarks that include ambiguous, task-irrelevant out-of-distribution as well as in-distribution samples. We also propose an active learning method designed to acquire informat",
    "link": "http://arxiv.org/abs/2303.14433",
    "context": "Title: Deep Active Learning with Contrastive Learning Under Realistic Data Pool Assumptions. (arXiv:2303.14433v1 [cs.CV])\nAbstract: Active learning aims to identify the most informative data from an unlabeled data pool that enables a model to reach the desired accuracy rapidly. This benefits especially deep neural networks which generally require a huge number of labeled samples to achieve high performance. Most existing active learning methods have been evaluated in an ideal setting where only samples relevant to the target task, i.e., in-distribution samples, exist in an unlabeled data pool. A data pool gathered from the wild, however, is likely to include samples that are irrelevant to the target task at all and/or too ambiguous to assign a single class label even for the oracle. We argue that assuming an unlabeled data pool consisting of samples from various distributions is more realistic. In this work, we introduce new active learning benchmarks that include ambiguous, task-irrelevant out-of-distribution as well as in-distribution samples. We also propose an active learning method designed to acquire informat",
    "path": "papers/23/03/2303.14433.json",
    "total_tokens": 911,
    "translated_title": "基于对比学习的现实数据池假设下的深度主动学习",
    "translated_abstract": "主动学习旨在从未标记的数据池中识别出最具信息量的数据，从而使模型快速达到所需的准确性。这对于通常需要大量标记样本才能达到高性能的深度神经网络尤为有益。大多数现有的主动学习方法在一个理想的设置中进行评估，在这个设置中，只有与目标任务相关的样本，即分布内样本，存在于未标记的数据池中。然而，从野外收集的数据池很可能包含完全与目标任务无关的样本和/或对于甚至对于神谕来说都无法分配单个类标签的过于模糊的样本。我们认为假设一个未标记的数据池包含来自各种分布的样本更加现实。在本文中，我们引入了包括模糊的、与任务无关的分布外样本以及分布内样本的新的主动学习基准。我们还提出了一种旨在获取权威信息的主动学习方法。",
    "tldr": "该论文提出了一种适用于现实数据池的、基于对比学习的深度主动学习方法，并且引入了包括模糊的、与任务无关的分布外样本以及分布内样本的新的主动学习基准。"
}