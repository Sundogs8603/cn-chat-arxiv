{
    "title": "FairAdaBN: Mitigating unfairness with adaptive batch normalization and its application to dermatological disease classification. (arXiv:2303.08325v1 [cs.LG])",
    "abstract": "Deep learning is becoming increasingly ubiquitous in medical research and applications while involving sensitive information and even critical diagnosis decisions. Researchers observe a significant performance disparity among subgroups with different demographic attributes, which is called model unfairness, and put lots of effort into carefully designing elegant architectures to address unfairness, which poses heavy training burden, brings poor generalization, and reveals the trade-off between model performance and fairness. To tackle these issues, we propose FairAdaBN by making batch normalization adaptive to sensitive attribute. This simple but effective design can be adopted to several classification backbones that are originally unaware of fairness. Additionally, we derive a novel loss function that restrains statistical parity between subgroups on mini-batches, encouraging the model to converge with considerable fairness. In order to evaluate the trade-off between model performanc",
    "link": "http://arxiv.org/abs/2303.08325",
    "context": "Title: FairAdaBN: Mitigating unfairness with adaptive batch normalization and its application to dermatological disease classification. (arXiv:2303.08325v1 [cs.LG])\nAbstract: Deep learning is becoming increasingly ubiquitous in medical research and applications while involving sensitive information and even critical diagnosis decisions. Researchers observe a significant performance disparity among subgroups with different demographic attributes, which is called model unfairness, and put lots of effort into carefully designing elegant architectures to address unfairness, which poses heavy training burden, brings poor generalization, and reveals the trade-off between model performance and fairness. To tackle these issues, we propose FairAdaBN by making batch normalization adaptive to sensitive attribute. This simple but effective design can be adopted to several classification backbones that are originally unaware of fairness. Additionally, we derive a novel loss function that restrains statistical parity between subgroups on mini-batches, encouraging the model to converge with considerable fairness. In order to evaluate the trade-off between model performanc",
    "path": "papers/23/03/2303.08325.json",
    "total_tokens": 1074,
    "translated_title": "FairAdaBN：自适应批归一化减少不公平性及其在皮肤病分类中的应用",
    "translated_abstract": "深度学习正在医学研究和应用中变得越来越普遍，同时涉及敏感信息，甚至包括关键的诊断决策。研究人员观察到不同人口属性子组之间的显著性能差异，称为模型不公平性，并致力于精心设计优雅的体系结构以解决不公平性问题，这带来了沉重的训练负担、较差的泛化能力，并揭示了模型性能和公平性之间的权衡。为了解决这些问题，我们提出了FairAdaBN，通过使批归一化适应敏感属性，可以将其简单而有效地应用到原本不了解公平性的多个分类主干中。另外，我们提出了一种新的损失函数，通过限制小批量子组之间的统计平衡，鼓励模型以相当公平的方式收敛。为了评估模型性能和公平性之间的权衡，我们在HAM10000数据集上进行了实验，该数据集是一个大规模的开放获取皮肤病数据库，用于分类七种常见的皮肤病病变。我们的结果表明，FairAdaBN可以有效地减少不公平性，并实现模型性能和公平性之间的平衡，开销可忽略不计。",
    "tldr": "本文提出了FairAdaBN，将批归一化适应敏感属性，可以将其简单而有效地应用到原本不了解公平性的多个分类主干中，能够有效地减少不公平性，并实现模型性能和公平性之间的平衡。",
    "en_tdlr": "FairAdaBN is proposed to make batch normalization adaptive to sensitive attribute which can effectively mitigate model unfairness and achieve a balance between model performance and fairness in various classification backbones, and it is evaluated on the HAM10000 dataset for dermatological disease classification with negligible overhead."
}