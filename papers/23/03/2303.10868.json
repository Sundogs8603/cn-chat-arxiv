{
    "title": "Retrieving Multimodal Information for Augmented Generation: A Survey. (arXiv:2303.10868v2 [cs.CL] UPDATED)",
    "abstract": "As Large Language Models (LLMs) become popular, there emerged an important trend of using multimodality to augment the LLMs' generation ability, which enables LLMs to better interact with the world. However, there lacks a unified perception of at which stage and how to incorporate different modalities. In this survey, we review methods that assist and augment generative models by retrieving multimodal knowledge, whose formats range from images, codes, tables, graphs, to audio. Such methods offer a promising solution to important concerns such as factuality, reasoning, interpretability, and robustness. By providing an in-depth review, this survey is expected to provide scholars with a deeper understanding of the methods' applications and encourage them to adapt existing techniques to the fast-growing field of LLMs.",
    "link": "http://arxiv.org/abs/2303.10868",
    "context": "Title: Retrieving Multimodal Information for Augmented Generation: A Survey. (arXiv:2303.10868v2 [cs.CL] UPDATED)\nAbstract: As Large Language Models (LLMs) become popular, there emerged an important trend of using multimodality to augment the LLMs' generation ability, which enables LLMs to better interact with the world. However, there lacks a unified perception of at which stage and how to incorporate different modalities. In this survey, we review methods that assist and augment generative models by retrieving multimodal knowledge, whose formats range from images, codes, tables, graphs, to audio. Such methods offer a promising solution to important concerns such as factuality, reasoning, interpretability, and robustness. By providing an in-depth review, this survey is expected to provide scholars with a deeper understanding of the methods' applications and encourage them to adapt existing techniques to the fast-growing field of LLMs.",
    "path": "papers/23/03/2303.10868.json",
    "total_tokens": 837,
    "translated_title": "检索多模态信息用于增强生成：一项调研",
    "translated_abstract": "随着大型语言模型的普及，使用多模态来增强语言模型的生成能力成为一个重要趋势，这使得语言模型能更好地与世界互动。然而，对于在哪个阶段以及如何融合不同模态的问题缺乏一个统一的认识。在本调研中，我们回顾了通过检索多模态知识来协助和增强生成模型的方法，这些知识的格式包括图像、代码、表格、图形和音频。这些方法为实现准确性、推理性、可解释性和鲁棒性等重要问题提供了有希望的解决方案。通过提供深入的回顾，本调研旨在让学者们更深入地了解这些方法的应用，并鼓励他们将现有技术应用于快速发展的语言模型领域。",
    "tldr": "这项调研综述了通过检索多模态知识来协助和增强生成模型的方法，这些方法提供了解决准确性、推理性、可解释性和鲁棒性等重要问题的有希望的解决方案。",
    "en_tdlr": "This survey reviews methods that assist and augment generative models by retrieving multimodal knowledge, offering promising solutions to important concerns such as factuality, reasoning, interpretability, and robustness."
}