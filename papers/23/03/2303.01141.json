{
    "title": "DeepSaDe: Learning Neural Networks that Guarantee Domain Constraint Satisfaction. (arXiv:2303.01141v2 [cs.LG] UPDATED)",
    "abstract": "As machine learning models, specifically neural networks, are becoming increasingly popular, there are concerns regarding their trustworthiness, specially in safety-critical applications, e.g. actions of an autonomous vehicle must be safe. There are approaches that can train neural networks where such domain requirements are enforced as constraints, but they either cannot guarantee that the constraint will be satisfied by all possible predictions (even on unseen data) or they are limited in the type of constraints that can be enforced. In this paper, we present an approach to train neural networks which can enforce a wide variety of constraints and guarantee that the constraint is satisfied by all possible predictions. The approach builds on earlier work where learning linear models is formulated as a constraint satisfaction problem (CSP). To make this idea applicable to neural networks, two crucial new elements are added: constraint propagation over the network layers, and weight upda",
    "link": "http://arxiv.org/abs/2303.01141",
    "context": "Title: DeepSaDe: Learning Neural Networks that Guarantee Domain Constraint Satisfaction. (arXiv:2303.01141v2 [cs.LG] UPDATED)\nAbstract: As machine learning models, specifically neural networks, are becoming increasingly popular, there are concerns regarding their trustworthiness, specially in safety-critical applications, e.g. actions of an autonomous vehicle must be safe. There are approaches that can train neural networks where such domain requirements are enforced as constraints, but they either cannot guarantee that the constraint will be satisfied by all possible predictions (even on unseen data) or they are limited in the type of constraints that can be enforced. In this paper, we present an approach to train neural networks which can enforce a wide variety of constraints and guarantee that the constraint is satisfied by all possible predictions. The approach builds on earlier work where learning linear models is formulated as a constraint satisfaction problem (CSP). To make this idea applicable to neural networks, two crucial new elements are added: constraint propagation over the network layers, and weight upda",
    "path": "papers/23/03/2303.01141.json",
    "total_tokens": 832,
    "translated_title": "DeepSaDe: 学习确保满足领域约束的神经网络",
    "translated_abstract": "随着机器学习模型的普及，尤其是神经网络，人们越来越关注它们的可信度，特别是在安全关键应用中，如自动驾驶汽车的行为必须是安全的。当前一些方法可以对神经网络进行约束，但它们不能保证所有可能的预测都满足约束限制（即使在未看过的数据上），或者它们对可强制执行的约束类型有限制。为了解决这些问题，本文提出了一种方法，用于训练可以强制执行广泛约束并保证所有可能预测都满足约束的神经网络。该方法基于以往将学习线性模型视为约束满足问题（CSP）的工作。为了将这个想法应用于神经网络，本文增加了两个关键的新元素：网络层上的约束传播和权重更新。",
    "tldr": "本文提出了一种学习神经网络的方法，该神经网络可以强制执行多样化的约束并且保证所有可能的预测都满足约束限制。",
    "en_tdlr": "This paper presents an approach to train neural networks with a wide variety of constraints and guarantee that all possible predictions satisfy these constraints, addressing the trustworthiness issues in safety-critical applications of machine learning."
}