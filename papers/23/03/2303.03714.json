{
    "title": "Generative Modeling with Flow-Guided Density Ratio Learning. (arXiv:2303.03714v2 [cs.LG] UPDATED)",
    "abstract": "We present Flow-Guided Density Ratio Learning (FDRL), a simple and scalable approach to generative modeling which builds on the stale (time-independent) approximation of the gradient flow of entropy-regularized f-divergences introduced in DGflow. In DGflow, the intractable time-dependent density ratio is approximated by a stale estimator given by a GAN discriminator. This is sufficient in the case of sample refinement, where the source and target distributions of the flow are close to each other. However, this assumption is invalid for generation and a naive application of the stale estimator fails due to the large chasm between the two distributions. FDRL proposes to train a density ratio estimator such that it learns from progressively improving samples during the training process. We show that this simple method alleviates the density chasm problem, allowing FDRL to generate images of dimensions as high as $128\\times128$, as well as outperform existing gradient flow baselines on qua",
    "link": "http://arxiv.org/abs/2303.03714",
    "context": "Title: Generative Modeling with Flow-Guided Density Ratio Learning. (arXiv:2303.03714v2 [cs.LG] UPDATED)\nAbstract: We present Flow-Guided Density Ratio Learning (FDRL), a simple and scalable approach to generative modeling which builds on the stale (time-independent) approximation of the gradient flow of entropy-regularized f-divergences introduced in DGflow. In DGflow, the intractable time-dependent density ratio is approximated by a stale estimator given by a GAN discriminator. This is sufficient in the case of sample refinement, where the source and target distributions of the flow are close to each other. However, this assumption is invalid for generation and a naive application of the stale estimator fails due to the large chasm between the two distributions. FDRL proposes to train a density ratio estimator such that it learns from progressively improving samples during the training process. We show that this simple method alleviates the density chasm problem, allowing FDRL to generate images of dimensions as high as $128\\times128$, as well as outperform existing gradient flow baselines on qua",
    "path": "papers/23/03/2303.03714.json",
    "total_tokens": 926,
    "translated_title": "使用流引导的密度比学习进行生成建模",
    "translated_abstract": "我们提出了一种简单且可扩展的生成建模方法，称为流引导的密度比学习（FDRL）。该方法基于DGflow中引入的基于熵正则化f-散度的梯度流的过时（时间无关）近似，并且通过GAN鉴别器给出的过时估计器近似了不可计算的时间相关密度比。在样本细化的情况下，这种近似足够，因为流的源分布和目标分布是相近的。然而，在生成的情况下，这个假设是无效的，而且过时估计器的朴素应用由于两个分布之间的大鸿沟而失败。FDRL提出了训练密度比估计器的方法，使其在训练过程中从逐渐改进的样本中学习。我们展示了这种简单的方法缓解了密度鸿沟问题，使得FDRL能够生成高达$128\\times128$尺寸的图像，并且在质量上超过了现有的梯度流基线方法。",
    "tldr": "FDRL是一种基于流引导的密度比学习的简单且可扩展的生成建模方法，通过训练密度比估计器从逐渐改进的样本中学习，缓解了密度鸿沟问题，并在生成高尺寸图像上表现优于现有基线方法。"
}