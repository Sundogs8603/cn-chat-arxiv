{
    "title": "Unified Text Structuralization with Instruction-tuned Language Models. (arXiv:2303.14956v2 [cs.CL] UPDATED)",
    "abstract": "Text structuralization is one of the important fields of natural language processing (NLP) consists of information extraction (IE) and structure formalization. However, current studies of text structuralization suffer from a shortage of manually annotated high-quality datasets from different domains and languages, which require specialized professional knowledge. In addition, most IE methods are designed for a specific type of structured data, e.g., entities, relations, and events, making them hard to generalize to others. In this work, we propose a simple and efficient approach to instruct large language model (LLM) to extract a variety of structures from texts. More concretely, we add a prefix and a suffix instruction to indicate the desired IE task and structure type, respectively, before feeding the text into a LLM. Experiments on two LLMs show that this approach can enable language models to perform comparable with other state-of-the-art methods on datasets of a variety of languag",
    "link": "http://arxiv.org/abs/2303.14956",
    "context": "Title: Unified Text Structuralization with Instruction-tuned Language Models. (arXiv:2303.14956v2 [cs.CL] UPDATED)\nAbstract: Text structuralization is one of the important fields of natural language processing (NLP) consists of information extraction (IE) and structure formalization. However, current studies of text structuralization suffer from a shortage of manually annotated high-quality datasets from different domains and languages, which require specialized professional knowledge. In addition, most IE methods are designed for a specific type of structured data, e.g., entities, relations, and events, making them hard to generalize to others. In this work, we propose a simple and efficient approach to instruct large language model (LLM) to extract a variety of structures from texts. More concretely, we add a prefix and a suffix instruction to indicate the desired IE task and structure type, respectively, before feeding the text into a LLM. Experiments on two LLMs show that this approach can enable language models to perform comparable with other state-of-the-art methods on datasets of a variety of languag",
    "path": "papers/23/03/2303.14956.json",
    "total_tokens": 863,
    "translated_title": "通过指导大型语言模型进行统一文本结构化",
    "translated_abstract": "文本结构化是自然语言处理领域中信息提取和结构形式化的重要领域之一。然而，目前的文本结构化研究缺乏来自不同领域和语言的高质量手工注释数据集，需要专业知识。此外，大多数信息提取方法都针对特定类型的结构化数据设计，例如实体、关系和事件，使它们难以推广到其他领域。在本研究中，我们提出了一种简单而有效的方法，用于指导大型语言模型从文本中提取各种结构。更具体地说，我们在将文本馈入大型语言模型之前，添加前缀和后缀指令，以指示所需要的信息提取任务和结构类型。在两个大型语言模型的实验中，结果表明这种方法可以使语言模型在各种语言的数据集上表现出与其他最先进方法相当的结果。",
    "tldr": "本研究提出了一种使用指导语言模型从文本中提取各种结构的方法，解决了文本结构化领域缺乏高质量数据集且信息提取难以推广的问题。"
}