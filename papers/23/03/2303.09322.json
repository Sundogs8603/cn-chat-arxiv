{
    "title": "Interpretability from a new lens: Integrating Stratification and Domain knowledge for Biomedical Applications. (arXiv:2303.09322v1 [cs.LG])",
    "abstract": "The use of machine learning (ML) techniques in the biomedical field has become increasingly important, particularly with the large amounts of data generated by the aftermath of the COVID-19 pandemic. However, due to the complex nature of biomedical datasets and the use of black-box ML models, a lack of trust and adoption by domain experts can arise. In response, interpretable ML (IML) approaches have been developed, but the curse of dimensionality in biomedical datasets can lead to model instability. This paper proposes a novel computational strategy for the stratification of biomedical problem datasets into k-fold cross-validation (CVs) and integrating domain knowledge interpretation techniques embedded into the current state-of-the-art IML frameworks. This approach can improve model stability, establish trust, and provide explanations for outcomes generated by trained IML models. Specifically, the model outcome, such as aggregated feature weight importance, can be linked to further d",
    "link": "http://arxiv.org/abs/2303.09322",
    "context": "Title: Interpretability from a new lens: Integrating Stratification and Domain knowledge for Biomedical Applications. (arXiv:2303.09322v1 [cs.LG])\nAbstract: The use of machine learning (ML) techniques in the biomedical field has become increasingly important, particularly with the large amounts of data generated by the aftermath of the COVID-19 pandemic. However, due to the complex nature of biomedical datasets and the use of black-box ML models, a lack of trust and adoption by domain experts can arise. In response, interpretable ML (IML) approaches have been developed, but the curse of dimensionality in biomedical datasets can lead to model instability. This paper proposes a novel computational strategy for the stratification of biomedical problem datasets into k-fold cross-validation (CVs) and integrating domain knowledge interpretation techniques embedded into the current state-of-the-art IML frameworks. This approach can improve model stability, establish trust, and provide explanations for outcomes generated by trained IML models. Specifically, the model outcome, such as aggregated feature weight importance, can be linked to further d",
    "path": "papers/23/03/2303.09322.json",
    "total_tokens": 954,
    "translated_title": "一个新视角下的可解释性：将分层和领域知识与生物医学应用相结合。",
    "translated_abstract": "机器学习(ML)技术在生物医学领域的应用日益重要，特别是在COVID-19大流行后所产生的大量数据中。然而，由于生物医学数据集的复杂性和黑盒ML模型的使用，领域专家可能会产生缺乏信任和采纳的情况。因此，出现了可解释的ML(IML)方法，但是生物医学数据集中的维度诅咒可能会导致模型不稳定。本文提出了一种新的计算策略，用于将生物医学问题数据集分层为k折交叉验证(CVs)，并将领域知识解释技术嵌入到当前最先进的IML框架中。这种方法可以提高模型的稳定性、建立信任，并为IML模型生成的结果提供解释。具体来说，模型结果，如聚合特征权重重要性，可以与更详细的领域特定知识相联系。",
    "tldr": "本文提出了一种新的计算策略，将生物医学问题数据集分层为k折交叉验证(CVs)，并将领域知识解释技术嵌入到当前最先进的IML框架中。这种方法可以提高模型的稳定性、建立信任，并为IML模型生成的结果提供解释。"
}