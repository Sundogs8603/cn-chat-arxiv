{
    "title": "Hallucinations in Large Multilingual Translation Models. (arXiv:2303.16104v1 [cs.CL])",
    "abstract": "Large-scale multilingual machine translation systems have demonstrated remarkable ability to translate directly between numerous languages, making them increasingly appealing for real-world applications. However, when deployed in the wild, these models may generate hallucinated translations which have the potential to severely undermine user trust and raise safety concerns. Existing research on hallucinations has primarily focused on small bilingual models trained on high-resource languages, leaving a gap in our understanding of hallucinations in massively multilingual models across diverse translation scenarios. In this work, we fill this gap by conducting a comprehensive analysis on both the M2M family of conventional neural machine translation models and ChatGPT, a general-purpose large language model~(LLM) that can be prompted for translation. Our investigation covers a broad spectrum of conditions, spanning over 100 translation directions across various resource levels and going b",
    "link": "http://arxiv.org/abs/2303.16104",
    "context": "Title: Hallucinations in Large Multilingual Translation Models. (arXiv:2303.16104v1 [cs.CL])\nAbstract: Large-scale multilingual machine translation systems have demonstrated remarkable ability to translate directly between numerous languages, making them increasingly appealing for real-world applications. However, when deployed in the wild, these models may generate hallucinated translations which have the potential to severely undermine user trust and raise safety concerns. Existing research on hallucinations has primarily focused on small bilingual models trained on high-resource languages, leaving a gap in our understanding of hallucinations in massively multilingual models across diverse translation scenarios. In this work, we fill this gap by conducting a comprehensive analysis on both the M2M family of conventional neural machine translation models and ChatGPT, a general-purpose large language model~(LLM) that can be prompted for translation. Our investigation covers a broad spectrum of conditions, spanning over 100 translation directions across various resource levels and going b",
    "path": "papers/23/03/2303.16104.json",
    "total_tokens": 1043,
    "translated_title": "大型多语言翻译模型中的幻觉",
    "translated_abstract": "大规模多语言机器翻译系统展示了直接在众多语言之间进行翻译的卓越能力，这使得它们越来越适用于实际应用。然而，在实际应用中，这些模型可能会生成幻觉翻译，这可能会严重破坏用户信任并引发安全问题。本文对常规神经机器翻译模型的M2M系列和ChacGPT进行了全面的分析，这些模型可以提示进行翻译。我们的调查涵盖了广泛的条件，包括各种资源水平和100多个翻译方向，超越了简单的词级幻觉，探索了更复杂的现象，如罕见词替换，事实错误和不合逻辑的句子生成。我们发现了幻觉的潜在原因，包括输入噪声，低资源语言和模型偏差，并强调需要更好的评估和缓解策略，以确保大型多语言翻译模型的安全和可信部署。",
    "tldr": "这项研究对常规神经机器翻译模型的M2M系列和ChacGPT进行了全面的分析，揭示了大型多语言翻译模型中幻觉的潜在原因，包括输入噪声，低资源语言和模型偏差，强调需要更好的评估和缓解策略以确保安全和可信部署。"
}