{
    "title": "Representation Disentaglement via Regularization by Identification. (arXiv:2303.00128v2 [cs.LG] UPDATED)",
    "abstract": "This work focuses on the problem of learning disentangled representations from observational data. Given observations ${\\mathbf{x}^{(i)}}$ for $i=1,...,N $ drawn from $p(\\mathbf{x}|\\mathbf{y})$ with generative variables $\\mathbf{y}$ admitting the distribution factorization $p(\\mathbf{y}) = \\prod_{c} p(\\mathbf{y}_c )$, we ask whether learning disentangled representations matching the space of observations with identification guarantees on the posterior $p(\\mathbf{z}| \\mathbf{x}, \\hat{\\mathbf{y}}_c)$ for each $c$, is plausible. We argue modern deep representation learning models of data matching the distributed factorization property are ill-posed with collider bias behaviour; a source of bias producing entanglement between generating variables. Under the rubric of causality, we show this issue can be explained and reconciled under the condition of identifiability; attainable under supervision or a weak-form of it. For this, we propose regularization by identification (ReI), a modular re",
    "link": "http://arxiv.org/abs/2303.00128",
    "context": "Title: Representation Disentaglement via Regularization by Identification. (arXiv:2303.00128v2 [cs.LG] UPDATED)\nAbstract: This work focuses on the problem of learning disentangled representations from observational data. Given observations ${\\mathbf{x}^{(i)}}$ for $i=1,...,N $ drawn from $p(\\mathbf{x}|\\mathbf{y})$ with generative variables $\\mathbf{y}$ admitting the distribution factorization $p(\\mathbf{y}) = \\prod_{c} p(\\mathbf{y}_c )$, we ask whether learning disentangled representations matching the space of observations with identification guarantees on the posterior $p(\\mathbf{z}| \\mathbf{x}, \\hat{\\mathbf{y}}_c)$ for each $c$, is plausible. We argue modern deep representation learning models of data matching the distributed factorization property are ill-posed with collider bias behaviour; a source of bias producing entanglement between generating variables. Under the rubric of causality, we show this issue can be explained and reconciled under the condition of identifiability; attainable under supervision or a weak-form of it. For this, we propose regularization by identification (ReI), a modular re",
    "path": "papers/23/03/2303.00128.json",
    "total_tokens": 959,
    "translated_title": "通过鉴别性正则化来实现表征解耦",
    "translated_abstract": "本文研究了从观测数据中学习解耦表示的问题。给定从$p(\\mathbf{x}|\\mathbf{y})$中生成的具有各自生成变量$\\mathbf{y}_c$分解的分布$p(\\mathbf{y}) = \\prod_{c} p(\\mathbf{y}_c )$的观测值${\\mathbf{x}^{(i)}}$，我们尝试学习与每个$c$的后验分布$p(\\mathbf{z}| \\mathbf{x}, \\hat{\\mathbf{y}}_c)$匹配的解耦表示是否可行。我们认为现代深度表征学习模型无法解决与生成变量之间出现的纠缠偏差行为问题，这种行为上产生偏见。在因果推理的框架下，我们证明了可以在可识别性的条件下对这个问题进行解释和调和，这一点可以在监督或弱监督的条件下实现。因此，我们提出了一种通过鉴别性正则化（ReI）的模块化重新调整方法。",
    "tldr": "本文研究了从观测数据中学习解耦表示的问题，提出通过鉴别性正则化来实现表征解耦，解决了现代深度表征学习模型中出现的纠缠偏差行为问题。",
    "en_tdlr": "This work proposes regularization by identification (ReI) to achieve representation disentanglement when learning from observational data, and addresses the issue of collider bias behavior that produces entanglement between generating variables in modern deep representation learning models by the condition of identifiability, attainable under supervision or weak-form of it."
}