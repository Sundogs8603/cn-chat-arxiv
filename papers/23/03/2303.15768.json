{
    "title": "RobustSwap: A Simple yet Robust Face Swapping Model against Attribute Leakage. (arXiv:2303.15768v1 [cs.CV])",
    "abstract": "Face swapping aims at injecting a source image's identity (i.e., facial features) into a target image, while strictly preserving the target's attributes, which are irrelevant to identity. However, we observed that previous approaches still suffer from source attribute leakage, where the source image's attributes interfere with the target image's. In this paper, we analyze the latent space of StyleGAN and find the adequate combination of the latents geared for face swapping task. Based on the findings, we develop a simple yet robust face swapping model, RobustSwap, which is resistant to the potential source attribute leakage. Moreover, we exploit the coordination of 3DMM's implicit and explicit information as a guidance to incorporate the structure of the source image and the precise pose of the target image. Despite our method solely utilizing an image dataset without identity labels for training, our model has the capability to generate high-fidelity and temporally consistent videos. ",
    "link": "http://arxiv.org/abs/2303.15768",
    "context": "Title: RobustSwap: A Simple yet Robust Face Swapping Model against Attribute Leakage. (arXiv:2303.15768v1 [cs.CV])\nAbstract: Face swapping aims at injecting a source image's identity (i.e., facial features) into a target image, while strictly preserving the target's attributes, which are irrelevant to identity. However, we observed that previous approaches still suffer from source attribute leakage, where the source image's attributes interfere with the target image's. In this paper, we analyze the latent space of StyleGAN and find the adequate combination of the latents geared for face swapping task. Based on the findings, we develop a simple yet robust face swapping model, RobustSwap, which is resistant to the potential source attribute leakage. Moreover, we exploit the coordination of 3DMM's implicit and explicit information as a guidance to incorporate the structure of the source image and the precise pose of the target image. Despite our method solely utilizing an image dataset without identity labels for training, our model has the capability to generate high-fidelity and temporally consistent videos. ",
    "path": "papers/23/03/2303.15768.json",
    "total_tokens": 915,
    "translated_title": "RobustSwap：一种简单而强大的人脸交换模型，能够有效避免属性泄漏问题",
    "translated_abstract": "人脸交换旨在将源图像的身份（即面部特征）注入目标图像，同时严格保留目标图像的不相关身份属性。但是，我们观察到之前的方法仍然存在源属性泄漏问题，即源图像的属性与目标图像的属性干扰。在本文中，我们分析了StyleGAN的潜在空间，并找到适合人脸交换任务的潜在因素组合。基于这些发现，我们开发了一种简单而强大的人脸交换模型RobustSwap，能够抵抗潜在的源属性泄漏问题。此外，我们利用3DMM的隐式和显式信息的协调作为指导，将源图像的结构和目标图像的准确姿态结合起来。尽管我们的方法仅利用图像数据集进行训练，而没有身份标签，但我们的模型能够生成高质量和时间上连续的视频。",
    "tldr": "本文提出了一种简单而强大的人脸交换模型RobustSwap，能够有效避免源属性泄漏问题，并利用3DMM的隐式和显式信息的协调来实现源图像结构的导入和目标图像准确姿态。",
    "en_tdlr": "This paper proposes a simple yet robust face swapping model, RobustSwap, which effectively avoids source attribute leakage problem and utilizes the coordination of 3DMM's implicit and explicit information as a guidance to incorporate the structure of the source image and the precise pose of the target image."
}