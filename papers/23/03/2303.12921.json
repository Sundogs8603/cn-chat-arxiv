{
    "title": "Stability is Stable: Connections between Replicability, Privacy, and Adaptive Generalization. (arXiv:2303.12921v1 [cs.LG])",
    "abstract": "The notion of replicable algorithms was introduced in Impagliazzo et al. [STOC '22] to describe randomized algorithms that are stable under the resampling of their inputs. More precisely, a replicable algorithm gives the same output with high probability when its randomness is fixed and it is run on a new i.i.d. sample drawn from the same distribution. Using replicable algorithms for data analysis can facilitate the verification of published results by ensuring that the results of an analysis will be the same with high probability, even when that analysis is performed on a new data set.  In this work, we establish new connections and separations between replicability and standard notions of algorithmic stability. In particular, we give sample-efficient algorithmic reductions between perfect generalization, approximate differential privacy, and replicability for a broad class of statistical problems. Conversely, we show any such equivalence must break down computationally: there exist s",
    "link": "http://arxiv.org/abs/2303.12921",
    "context": "Title: Stability is Stable: Connections between Replicability, Privacy, and Adaptive Generalization. (arXiv:2303.12921v1 [cs.LG])\nAbstract: The notion of replicable algorithms was introduced in Impagliazzo et al. [STOC '22] to describe randomized algorithms that are stable under the resampling of their inputs. More precisely, a replicable algorithm gives the same output with high probability when its randomness is fixed and it is run on a new i.i.d. sample drawn from the same distribution. Using replicable algorithms for data analysis can facilitate the verification of published results by ensuring that the results of an analysis will be the same with high probability, even when that analysis is performed on a new data set.  In this work, we establish new connections and separations between replicability and standard notions of algorithmic stability. In particular, we give sample-efficient algorithmic reductions between perfect generalization, approximate differential privacy, and replicability for a broad class of statistical problems. Conversely, we show any such equivalence must break down computationally: there exist s",
    "path": "papers/23/03/2303.12921.json",
    "total_tokens": 890,
    "translated_title": "稳定性稳定：可复制性、隐私和自适应推广之间的联系",
    "translated_abstract": "在Impagliazzo et al. [STOC '22]中引入了可复制算法的概念，用于描述在输入重新采样时稳定的随机算法。具体而言，当其随机性被固定且在从相同分布中绘制的新的i.i.d.样本上运行时，可复制算法会以很高的概率给出相同的输出。使用可复制算法进行数据分析可以通过确保分析结果在新数据集上进行分析时具有相同的结果来简化已发布结果的验证。在这项工作中，我们建立了可复制性与算法稳定性标准概念之间的新联系和分离。特别地，我们为一类广泛的统计问题给出了完美推广、近似差分隐私和可复制性之间的样本有效算法约化。相反，我们表明这种等价关系必须在计算上崩溃：存在具有可复制算法但不具有任何可用的差分隐私机制的问题。",
    "tldr": "本文研究了可复制算法与标准算法稳定性的联系，为一类统计问题提供了可复制算法的样本有效算法约化，同时表明这种等价关系必须在计算上崩溃。"
}