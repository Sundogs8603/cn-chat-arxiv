{
    "title": "Containing a spread through sequential learning: to exploit or to explore?. (arXiv:2303.00141v2 [cs.LG] UPDATED)",
    "abstract": "The spread of an undesirable contact process, such as an infectious disease (e.g. COVID-19), is contained through testing and isolation of infected nodes. The temporal and spatial evolution of the process (along with containment through isolation) render such detection as fundamentally different from active search detection strategies. In this work, through an active learning approach, we design testing and isolation strategies to contain the spread and minimize the cumulative infections under a given test budget. We prove that the objective can be optimized, with performance guarantees, by greedily selecting the nodes to test. We further design reward-based methodologies that effectively minimize an upper bound on the cumulative infections and are computationally more tractable in large networks. These policies, however, need knowledge about the nodes' infection probabilities which are dynamically changing and have to be learned by sequential testing. We develop a message-passing fram",
    "link": "http://arxiv.org/abs/2303.00141",
    "context": "Title: Containing a spread through sequential learning: to exploit or to explore?. (arXiv:2303.00141v2 [cs.LG] UPDATED)\nAbstract: The spread of an undesirable contact process, such as an infectious disease (e.g. COVID-19), is contained through testing and isolation of infected nodes. The temporal and spatial evolution of the process (along with containment through isolation) render such detection as fundamentally different from active search detection strategies. In this work, through an active learning approach, we design testing and isolation strategies to contain the spread and minimize the cumulative infections under a given test budget. We prove that the objective can be optimized, with performance guarantees, by greedily selecting the nodes to test. We further design reward-based methodologies that effectively minimize an upper bound on the cumulative infections and are computationally more tractable in large networks. These policies, however, need knowledge about the nodes' infection probabilities which are dynamically changing and have to be learned by sequential testing. We develop a message-passing fram",
    "path": "papers/23/03/2303.00141.json",
    "total_tokens": 996,
    "translated_title": "通过序贯学习来控制传播：利用还是探索？",
    "translated_abstract": "一种不良接触过程（如COVID-19）的传播可以通过检测和隔离被控制。然而，该过程的时间和空间演化以及通过隔离进行的控制使得检测与一般的主动搜索策略有着根本区别。本文通过一种主动学习的方法，设计了一种测试和隔离策略，以控制传播并在给定的测试预算下最小化累积感染人数。我们证明了通过贪心选择节点进行测试可以优化目标，并具有性能保证。此外，我们进一步设计了一种基于奖励的方法，有效地最小化累积感染人数的上界，并且在大型网络中具有更好的可计算性。然而，这些策略需要了解节点的感染概率，这些概率会动态变化，并且需要通过序列测试进行学习。我们开发了一种消息传递框架来进行感染概率的序贯学习，并展示了我们的策略对演化过程的动态性能具有良好的适应性。",
    "tldr": "本文提出了一种通过序贯学习来控制传播的测试和隔离策略，以最小化累积感染人数；可以通过贪心选择节点进行测试并具有性能保证，并设计了基于奖励的方法，在大型网络中具有更好的可计算性。",
    "en_tdlr": "This work proposes a testing and isolation strategy for controlling the spread through sequential learning to minimize cumulative infections under a given test budget, and proves that the objective can be optimized by greedily selecting the nodes to test with performance guarantees. Reward-based methodologies are designed to minimize an upper bound on cumulative infections and have better computational tractability in large networks. A message-passing framework is developed for sequential learning of infection probabilities, and the policies show good adaptivity to the dynamics of the process."
}