{
    "title": "Iterative Approximate Cross-Validation. (arXiv:2303.02732v2 [stat.ME] UPDATED)",
    "abstract": "Cross-validation (CV) is one of the most popular tools for assessing and selecting predictive models. However, standard CV suffers from high computational cost when the number of folds is large. Recently, under the empirical risk minimization (ERM) framework, a line of works proposed efficient methods to approximate CV based on the solution of the ERM problem trained on the full dataset. However, in large-scale problems, it can be hard to obtain the exact solution of the ERM problem, either due to limited computational resources or due to early stopping as a way of preventing overfitting. In this paper, we propose a new paradigm to efficiently approximate CV when the ERM problem is solved via an iterative first-order algorithm, without running until convergence. Our new method extends existing guarantees for CV approximation to hold along the whole trajectory of the algorithm, including at convergence, thus generalizing existing CV approximation methods. Finally, we illustrate the accu",
    "link": "http://arxiv.org/abs/2303.02732",
    "context": "Title: Iterative Approximate Cross-Validation. (arXiv:2303.02732v2 [stat.ME] UPDATED)\nAbstract: Cross-validation (CV) is one of the most popular tools for assessing and selecting predictive models. However, standard CV suffers from high computational cost when the number of folds is large. Recently, under the empirical risk minimization (ERM) framework, a line of works proposed efficient methods to approximate CV based on the solution of the ERM problem trained on the full dataset. However, in large-scale problems, it can be hard to obtain the exact solution of the ERM problem, either due to limited computational resources or due to early stopping as a way of preventing overfitting. In this paper, we propose a new paradigm to efficiently approximate CV when the ERM problem is solved via an iterative first-order algorithm, without running until convergence. Our new method extends existing guarantees for CV approximation to hold along the whole trajectory of the algorithm, including at convergence, thus generalizing existing CV approximation methods. Finally, we illustrate the accu",
    "path": "papers/23/03/2303.02732.json",
    "total_tokens": 835,
    "translated_title": "迭代近似交叉验证",
    "translated_abstract": "交叉验证(CV)是评估和选择预测模型的最流行工具之一。然而，标准CV在折数较多时计算成本很高。最近，在经验风险最小化(ERM)框架下，一系列工作提出了基于完整数据集训练的ERM问题解的有效方法来近似CV。然而，在大规模问题中，由于有限的计算资源或早停的方式防止过拟合，很难得到ERM问题的确切解。本文提出了一种新的范式，在通过迭代一阶算法求解ERM问题时高效地近似CV，而无需运行到收敛状态。我们的新方法扩展了现有的CV近似保证，使其在整个算法轨迹中（包括收敛时）都成立，从而推广了现有的CV近似方法。最后，我们展示了该方法的准确性。",
    "tldr": "本文提出了一种新的方法，利用迭代一阶算法高效近似交叉验证，从而解决了大规模问题中因限制计算资源或早停而难以得到ERM问题确切解的问题。",
    "en_tdlr": "This paper proposes a new method that efficiently approximates cross-validation using iterative first-order algorithm, thus solving the problem of obtaining the exact solution of the ERM problem in large-scale scenarios with limited computational resources or early stopping."
}