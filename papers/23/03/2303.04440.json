{
    "title": "HyT-NAS: Hybrid Transformers Neural Architecture Search for Edge Devices. (arXiv:2303.04440v2 [cs.CV] UPDATED)",
    "abstract": "Vision Transformers have enabled recent attention-based Deep Learning (DL) architectures to achieve remarkable results in Computer Vision (CV) tasks. However, due to the extensive computational resources required, these architectures are rarely implemented on resource-constrained platforms. Current research investigates hybrid handcrafted convolution-based and attention-based models for CV tasks such as image classification and object detection. In this paper, we propose HyT-NAS, an efficient Hardware-aware Neural Architecture Search (HW-NAS) including hybrid architectures targeting vision tasks on tiny devices. HyT-NAS improves state-of-the-art HW-NAS by enriching the search space and enhancing the search strategy as well as the performance predictors. Our experiments show that HyT-NAS achieves a similar hypervolume with less than ~5x training evaluations. Our resulting architecture outperforms MLPerf MobileNetV1 by 6.3% accuracy improvement with 3.5x less number of parameters on Visu",
    "link": "http://arxiv.org/abs/2303.04440",
    "context": "Title: HyT-NAS: Hybrid Transformers Neural Architecture Search for Edge Devices. (arXiv:2303.04440v2 [cs.CV] UPDATED)\nAbstract: Vision Transformers have enabled recent attention-based Deep Learning (DL) architectures to achieve remarkable results in Computer Vision (CV) tasks. However, due to the extensive computational resources required, these architectures are rarely implemented on resource-constrained platforms. Current research investigates hybrid handcrafted convolution-based and attention-based models for CV tasks such as image classification and object detection. In this paper, we propose HyT-NAS, an efficient Hardware-aware Neural Architecture Search (HW-NAS) including hybrid architectures targeting vision tasks on tiny devices. HyT-NAS improves state-of-the-art HW-NAS by enriching the search space and enhancing the search strategy as well as the performance predictors. Our experiments show that HyT-NAS achieves a similar hypervolume with less than ~5x training evaluations. Our resulting architecture outperforms MLPerf MobileNetV1 by 6.3% accuracy improvement with 3.5x less number of parameters on Visu",
    "path": "papers/23/03/2303.04440.json",
    "total_tokens": 927,
    "translated_title": "HyT-NAS: 面向边缘设备的混合变压器神经架构搜索",
    "translated_abstract": "视觉变压器使得近期基于注意力的深度学习架构在计算机视觉任务上取得了显著成果。但是，由于需要大量的计算资源，这些架构很少在资源受限的平台上实现。目前的研究探讨了混合手工卷积和基于注意力的模型用于计算机视觉任务，如图像分类和物体检测。本文提出了HyT-NAS，一种高效的硬件感知神经架构搜索，包括针对微型设备的混合架构。HyT-NAS通过丰富搜索空间、增强搜索策略和性能预测器来改进现有的HW-NAS。实验表明，HyT-NAS在少于5倍的训练评估次数下实现了类似的超体积。最终的架构在Visu上的参数数量少3.5倍，精度提高了6.3%，胜过了MLPerf MobileNetV1。",
    "tldr": "HyT-NAS是一个高效的神经架构搜索算法，针对微型设备的混合架构，可以在少于5倍的训练评估次数下实现类似的超体积，并在Visu上的参数数量少3.5倍，精度提高了6.3%。",
    "en_tdlr": "HyT-NAS is an efficient neural architecture search algorithm targeting hybrid architectures for tiny devices, which achieves a similar hypervolume with less than ~5x training evaluations and surpasses MLPerf MobileNetV1 with 6.3% accuracy improvement and 3.5x less parameters on Visu."
}