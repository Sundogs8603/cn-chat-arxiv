{
    "title": "Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samples!. (arXiv:2303.08559v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs) have made remarkable strides in various tasks. However, whether they are competitive few-shot solvers for information extraction (IE) tasks and surpass fine-tuned small Pre-trained Language Models (SLMs) remains an open problem. This paper aims to provide a thorough answer to this problem, and moreover, to explore an approach towards effective and economical IE systems that combine the strengths of LLMs and SLMs. Through extensive experiments on eight datasets across three IE tasks, we show that LLMs are not effective few-shot information extractors in general, given their unsatisfactory performance in most settings and the high latency and budget requirements. However, we demonstrate that LLMs can well complement SLMs and effectively solve hard samples that SLMs struggle with. Building on these findings, we propose an adaptive filter-then-rerank paradigm, in which SLMs act as filters and LLMs act as rerankers. By utilizing LLMs to rerank a small portion of",
    "link": "http://arxiv.org/abs/2303.08559",
    "context": "Title: Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samples!. (arXiv:2303.08559v1 [cs.CL])\nAbstract: Large Language Models (LLMs) have made remarkable strides in various tasks. However, whether they are competitive few-shot solvers for information extraction (IE) tasks and surpass fine-tuned small Pre-trained Language Models (SLMs) remains an open problem. This paper aims to provide a thorough answer to this problem, and moreover, to explore an approach towards effective and economical IE systems that combine the strengths of LLMs and SLMs. Through extensive experiments on eight datasets across three IE tasks, we show that LLMs are not effective few-shot information extractors in general, given their unsatisfactory performance in most settings and the high latency and budget requirements. However, we demonstrate that LLMs can well complement SLMs and effectively solve hard samples that SLMs struggle with. Building on these findings, we propose an adaptive filter-then-rerank paradigm, in which SLMs act as filters and LLMs act as rerankers. By utilizing LLMs to rerank a small portion of",
    "path": "papers/23/03/2303.08559.json",
    "total_tokens": 1088,
    "tldr": "本文研究大型语言模型在信息提取中的准确性和效率，发现它们不是很好的少样本信息提取器，但是可以与小型预训练语言模型相结合，在处理难样本时具有良好的性能，提出了一种自适应的滤波器-再排序范例，具有很好的实用价值。",
    "en_tdlr": "This paper investigates the accuracy and efficiency of large language models in information extraction and finds that they are not good few-shot information extractors, but can complement small pre-trained language models and have good performance in processing difficult samples. An adaptive filter-then-rerank paradigm is proposed with practical value."
}