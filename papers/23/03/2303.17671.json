{
    "title": "Neural signature kernels as infinite-width-depth-limits of controlled ResNets. (arXiv:2303.17671v1 [math.DS])",
    "abstract": "Motivated by the paradigm of reservoir computing, we consider randomly initialized controlled ResNets defined as Euler-discretizations of neural controlled differential equations (Neural CDEs). We show that in the infinite-width-then-depth limit and under proper scaling, these architectures converge weakly to Gaussian processes indexed on some spaces of continuous paths and with kernels satisfying certain partial differential equations (PDEs) varying according to the choice of activation function. In the special case where the activation is the identity, we show that the equation reduces to a linear PDE and the limiting kernel agrees with the signature kernel of Salvi et al. (2021). In this setting, we also show that the width-depth limits commute. We name this new family of limiting kernels neural signature kernels. Finally, we show that in the infinite-depth regime, finite-width controlled ResNets converge in distribution to Neural CDEs with random vector fields which, depending on w",
    "link": "http://arxiv.org/abs/2303.17671",
    "context": "Title: Neural signature kernels as infinite-width-depth-limits of controlled ResNets. (arXiv:2303.17671v1 [math.DS])\nAbstract: Motivated by the paradigm of reservoir computing, we consider randomly initialized controlled ResNets defined as Euler-discretizations of neural controlled differential equations (Neural CDEs). We show that in the infinite-width-then-depth limit and under proper scaling, these architectures converge weakly to Gaussian processes indexed on some spaces of continuous paths and with kernels satisfying certain partial differential equations (PDEs) varying according to the choice of activation function. In the special case where the activation is the identity, we show that the equation reduces to a linear PDE and the limiting kernel agrees with the signature kernel of Salvi et al. (2021). In this setting, we also show that the width-depth limits commute. We name this new family of limiting kernels neural signature kernels. Finally, we show that in the infinite-depth regime, finite-width controlled ResNets converge in distribution to Neural CDEs with random vector fields which, depending on w",
    "path": "papers/23/03/2303.17671.json",
    "total_tokens": 948,
    "translated_title": "神经签名核作为受控ResNets的无限宽度-深度极限。(arXiv:2303.17671v1 [math.DS])",
    "translated_abstract": "受沉积计算范例的启发，我们考虑由神经受控微分方程（神经CDE）的欧拉离散化定义的随机初始化受控ResNets。我们表明，在无限宽度-深度限制和适当的缩放下，这些架构弱收敛到一些连续路径空间上索引的高斯过程，并且具有满足根据激活函数的选择变化的某些偏微分方程（PDE）的核。在激活为恒等式的特殊情况下，我们表明该方程式简化为线性PDE，极限核与Salvi等人的签名核一致。在这种情况下，我们还表明宽度-深度极限是可交换的。我们将这种新的限制核家族称为神经签名核。最后，我们表明，在无限深度的情况下，有限宽度的受控ResNets按分布收敛到具有随机向量场的神经CDE，具体取决于w。",
    "tldr": "通过控制ResNets的欧拉离散化，提出了一种新的家族限制核，称为神经签名核。在无限深度情况下，有限宽度的受控ResNets按分布收敛至神经CDE。",
    "en_tdlr": "A new family of limiting kernels, called neural signature kernels, is proposed by considering randomly initialized controlled ResNets defined as Euler-discretizations of neural controlled differential equations. In the infinite-depth regime, finite-width controlled ResNets converge in distribution to Neural CDEs with random vector fields."
}