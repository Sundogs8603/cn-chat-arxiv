{
    "title": "SymBa: Symmetric Backpropagation-Free Contrastive Learning with Forward-Forward Algorithm for Optimizing Convergence. (arXiv:2303.08418v1 [cs.CV])",
    "abstract": "The paper proposes a new algorithm called SymBa that aims to achieve more biologically plausible learning than Back-Propagation (BP). The algorithm is based on the Forward-Forward (FF) algorithm, which is a BP-free method for training neural networks. SymBa improves the FF algorithm's convergence behavior by addressing the problem of asymmetric gradients caused by conflicting converging directions for positive and negative samples. The algorithm balances positive and negative losses to enhance performance and convergence speed. Furthermore, it modifies the FF algorithm by adding Intrinsic Class Pattern (ICP) containing class information to prevent the loss of class information during training. The proposed algorithm has the potential to improve our understanding of how the brain learns and processes information and to develop more effective and efficient artificial intelligence systems. The paper presents experimental results that demonstrate the effectiveness of SymBa algorithm compar",
    "link": "http://arxiv.org/abs/2303.08418",
    "context": "Title: SymBa: Symmetric Backpropagation-Free Contrastive Learning with Forward-Forward Algorithm for Optimizing Convergence. (arXiv:2303.08418v1 [cs.CV])\nAbstract: The paper proposes a new algorithm called SymBa that aims to achieve more biologically plausible learning than Back-Propagation (BP). The algorithm is based on the Forward-Forward (FF) algorithm, which is a BP-free method for training neural networks. SymBa improves the FF algorithm's convergence behavior by addressing the problem of asymmetric gradients caused by conflicting converging directions for positive and negative samples. The algorithm balances positive and negative losses to enhance performance and convergence speed. Furthermore, it modifies the FF algorithm by adding Intrinsic Class Pattern (ICP) containing class information to prevent the loss of class information during training. The proposed algorithm has the potential to improve our understanding of how the brain learns and processes information and to develop more effective and efficient artificial intelligence systems. The paper presents experimental results that demonstrate the effectiveness of SymBa algorithm compar",
    "path": "papers/23/03/2303.08418.json",
    "total_tokens": 983,
    "translated_title": "SymBa: 基于正向正向算法的对称无反向传播对比学习优化收敛",
    "translated_abstract": "本文提出了一种名为SymBa的新算法，旨在实现比BP更符合生物学的学习。该算法基于正向正向(FF)算法，是一种无BP的神经网络训练方法。SymBa通过解决正负样本相互冲突的趋于收敛方向问题，改善了FF算法的收敛特性。该算法平衡了正负损失以提高性能和收敛速度。此外，它通过添加内在类模式(ICP)包含类信息来修改FF算法，防止在训练过程中丢失类信息。该算法有潜力提高我们对大脑学习和信息处理的理解，发展更有效和高效的人工智能系统。本文展示了SymBa算法的实验结果，证明了其有效性。",
    "tldr": "本文介绍了基于正向正向算法的对称无反向传播对比学习优化收敛的SymBa算法。SymBa通过解决正负样本相互冲突的趋于收敛方向问题，改善了FF算法的收敛特性，同时平衡了正负损失以提高性能和收敛速度，并防止在训练过程中丢失类信息。SymBa算法有潜力提高人们对大脑学习和信息处理的理解，进一步发展人工智能系统的效率和效果。",
    "en_tdlr": "This paper presents a SymBa algorithm based on the forward-forward algorithm for symmetric backpropagation-free contrastive learning, which improves the convergence behavior of the FF algorithm by solving the problem of conflicting converging directions for positive and negative samples. SymBa balances positive and negative losses to enhance performance and convergence speed and modifies the FF algorithm by adding intrinsic class pattern information to prevent information loss during training. The SymBa algorithm has the potential to improve our understanding of how the brain learns and processes information and to develop more effective and efficient artificial intelligence systems."
}