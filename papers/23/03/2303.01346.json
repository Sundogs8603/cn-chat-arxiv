{
    "title": "Co-learning Planning and Control Policies Constrained by Differentiable Logic Specifications. (arXiv:2303.01346v2 [cs.RO] UPDATED)",
    "abstract": "Synthesizing planning and control policies in robotics is a fundamental task, further complicated by factors such as complex logic specifications and high-dimensional robot dynamics. This paper presents a novel reinforcement learning approach to solving high-dimensional robot navigation tasks with complex logic specifications by co-learning planning and control policies. Notably, this approach significantly reduces the sample complexity in training, allowing us to train high-quality policies with much fewer samples compared to existing reinforcement learning algorithms. In addition, our methodology streamlines complex specification extraction from map images and enables the efficient generation of long-horizon robot motion paths across different map layouts. Moreover, our approach also demonstrates capabilities for high-dimensional control and avoiding suboptimal policies via policy alignment. The efficacy of our approach is demonstrated through experiments involving simulated high-dim",
    "link": "http://arxiv.org/abs/2303.01346",
    "context": "Title: Co-learning Planning and Control Policies Constrained by Differentiable Logic Specifications. (arXiv:2303.01346v2 [cs.RO] UPDATED)\nAbstract: Synthesizing planning and control policies in robotics is a fundamental task, further complicated by factors such as complex logic specifications and high-dimensional robot dynamics. This paper presents a novel reinforcement learning approach to solving high-dimensional robot navigation tasks with complex logic specifications by co-learning planning and control policies. Notably, this approach significantly reduces the sample complexity in training, allowing us to train high-quality policies with much fewer samples compared to existing reinforcement learning algorithms. In addition, our methodology streamlines complex specification extraction from map images and enables the efficient generation of long-horizon robot motion paths across different map layouts. Moreover, our approach also demonstrates capabilities for high-dimensional control and avoiding suboptimal policies via policy alignment. The efficacy of our approach is demonstrated through experiments involving simulated high-dim",
    "path": "papers/23/03/2303.01346.json",
    "total_tokens": 926,
    "translated_title": "受可微分逻辑约束的共学习规划与控制策略",
    "translated_abstract": "在机器人技术中综合规划与控制策略是一项基本任务，但复杂的逻辑约束和高维度的机器人动力学使其变得更加复杂。本文提出了一种新颖的强化学习方法，通过共学习规划和控制策略来解决带有复杂逻辑约束的高维度机器人导航任务。值得注意的是，这种方法显著降低了训练的样本复杂性，相比现有的强化学习算法，我们可以用更少的样本训练出高质量的策略。此外，我们的方法简化了从地图图像中提取复杂规范并能够高效生成不同地图布局的长期机器人运动路径。此外，我们的方法还展示了在高维度控制和避免次优策略方面的能力。通过模拟高维机器人导航任务的实验验证了我们方法的有效性。",
    "tldr": "本文提出了一种通过共学习规划和控制策略来解决带有复杂逻辑约束的高维度机器人导航任务的强化学习方法。相比现有算法，这种方法通过降低样本复杂性来训练出高质量的策略，并且能够高效地生成长期的机器人运动路径。实验证明了该方法的有效性。"
}