{
    "title": "Hierarchical Memory Pool Based Edge Semi-Supervised Continual Learning Method. (arXiv:2303.11952v1 [cs.LG])",
    "abstract": "The continuous changes in the world have resulted in the performance regression of neural networks. Therefore, continual learning (CL) area gradually attracts the attention of more researchers. For edge intelligence, the CL model not only needs to overcome catastrophic for-getting, but also needs to face the huge challenge of severely limited resources: the lack of labeled resources and powerful devices. However, the existing classic CL methods usually rely on a large number of labeled samples to maintain the plasticity and stability, and the semi-supervised learning methods often need to pay a large computational and memory overhead for higher accuracy. In response to these prob-lems, a low-cost semi-supervised CL method named Edge Hierarchical Memory Learner (EdgeHML) will be proposed. EdgeHML can effec-tively utilize a large number of unlabeled samples and a small number of labeled samples. It is based on a hierarchical memory pool, lever-age multi-level storage structure to store a",
    "link": "http://arxiv.org/abs/2303.11952",
    "context": "Title: Hierarchical Memory Pool Based Edge Semi-Supervised Continual Learning Method. (arXiv:2303.11952v1 [cs.LG])\nAbstract: The continuous changes in the world have resulted in the performance regression of neural networks. Therefore, continual learning (CL) area gradually attracts the attention of more researchers. For edge intelligence, the CL model not only needs to overcome catastrophic for-getting, but also needs to face the huge challenge of severely limited resources: the lack of labeled resources and powerful devices. However, the existing classic CL methods usually rely on a large number of labeled samples to maintain the plasticity and stability, and the semi-supervised learning methods often need to pay a large computational and memory overhead for higher accuracy. In response to these prob-lems, a low-cost semi-supervised CL method named Edge Hierarchical Memory Learner (EdgeHML) will be proposed. EdgeHML can effec-tively utilize a large number of unlabeled samples and a small number of labeled samples. It is based on a hierarchical memory pool, lever-age multi-level storage structure to store a",
    "path": "papers/23/03/2303.11952.json",
    "total_tokens": 927,
    "translated_title": "基于分层存储池的边缘半监督增量学习方法",
    "translated_abstract": "当前世界的不断变化导致神经网络的表现下降。因此，增量学习领域逐渐引起更多研究人员的关注。对于边缘智能而言，增量学习模型不仅需要克服灾难性遗忘，还需要应对严重的资源限制：缺乏标记资源和强大的设备。然而，现有的经典增量学习方法通常依赖于大量标记样本来维护可塑性和稳定性，而半监督学习方法通常需要付出大量的计算和内存开销来提高精度。为应对这些问题，本文提出了一种名为边缘分层存储学习器（EdgeHML）的低成本半监督增量学习方法，它可以有效地利用大量未标记样本和少量标记样本，基于分层存储池，利用多级存储结构来存储数据。",
    "tldr": "本文提出了名为EdgeHML的低成本半监督增量学习方法，通过分层存储池和多级存储结构，利用大量未标记样本和少量标记样本，有效应对灾难性遗忘和边缘智能领域的资源限制问题。",
    "en_tdlr": "This paper proposes a low-cost semi-supervised continual learning method named EdgeHML, which leverages a hierarchical memory pool and multi-level storage structure to effectively utilize a large number of unlabeled samples and a small number of labeled samples for addressing catastrophic forgetting and resource constraints in edge intelligence."
}