{
    "title": "NeRF-GAN Distillation for Efficient 3D-Aware Generation with Convolutions. (arXiv:2303.12865v1 [cs.CV])",
    "abstract": "Pose-conditioned convolutional generative models struggle with high-quality 3D-consistent image generation from single-view datasets, due to their lack of sufficient 3D priors. Recently, the integration of Neural Radiance Fields (NeRFs) and generative models, such as Generative Adversarial Networks (GANs), has transformed 3D-aware generation from single-view images. NeRF-GANs exploit the strong inductive bias of 3D neural representations and volumetric rendering at the cost of higher computational complexity. This study aims at revisiting pose-conditioned 2D GANs for efficient 3D-aware generation at inference time by distilling 3D knowledge from pretrained NeRF-GANS. We propose a simple and effective method, based on re-using the well-disentangled latent space of a pre-trained NeRF-GAN in a pose-conditioned convolutional network to directly generate 3D-consistent images corresponding to the underlying 3D representations. Experiments on several datasets demonstrate that the proposed met",
    "link": "http://arxiv.org/abs/2303.12865",
    "context": "Title: NeRF-GAN Distillation for Efficient 3D-Aware Generation with Convolutions. (arXiv:2303.12865v1 [cs.CV])\nAbstract: Pose-conditioned convolutional generative models struggle with high-quality 3D-consistent image generation from single-view datasets, due to their lack of sufficient 3D priors. Recently, the integration of Neural Radiance Fields (NeRFs) and generative models, such as Generative Adversarial Networks (GANs), has transformed 3D-aware generation from single-view images. NeRF-GANs exploit the strong inductive bias of 3D neural representations and volumetric rendering at the cost of higher computational complexity. This study aims at revisiting pose-conditioned 2D GANs for efficient 3D-aware generation at inference time by distilling 3D knowledge from pretrained NeRF-GANS. We propose a simple and effective method, based on re-using the well-disentangled latent space of a pre-trained NeRF-GAN in a pose-conditioned convolutional network to directly generate 3D-consistent images corresponding to the underlying 3D representations. Experiments on several datasets demonstrate that the proposed met",
    "path": "papers/23/03/2303.12865.json",
    "total_tokens": 991,
    "translated_title": "NeRF-GAN蒸馏：基于卷积的高效3D感知生成",
    "translated_abstract": "基于姿态的卷积生成模型在从单视图数据集进行高质量的3D一致图像生成方面存在困难，因为它们缺乏足够的3D先验知识。最近，将神经辐射场（NeRF）和生成对抗网络（GAN）等生成模型相结合，从单视图图像中生成3D感知图像，已经引起了广泛关注。NeRF-GAN利用了三维神经表示和体积渲染的强归纳偏差，但也带来了更高的计算复杂性。这项研究旨在通过从预训练的NeRF-GAN中提取3D知识进行蒸馏，重审基于姿态的二维GAN，在推理时间内实现高效的3D感知生成。我们提出了一种简单有效的方法，基于在基于姿态的卷积网络中重用预训练的NeRF-GAN的良好解耦潜在空间，直接生成与潜在的3D表达相对应的3D一致图片。在多个数据集上的实验表明，所提出的方法实现了更高效的3D感知生成。",
    "tldr": "本文提出了一种基于神经辐射场（NeRF）和生成对抗网络（GAN）的新方法，通过从预训练的NeRF-GAN中提取3D知识进行蒸馏，实现了基于姿态的2D GAN的高效3D感知生成。"
}