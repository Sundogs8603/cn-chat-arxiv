{
    "title": "Feature Unlearning for Pre-trained GANs and VAEs. (arXiv:2303.05699v2 [cs.CV] UPDATED)",
    "abstract": "We tackle the problem of feature unlearning from a pre-trained image generative model: GANs and VAEs. Unlike a common unlearning task where an unlearning target is a subset of the training set, we aim to unlearn a specific feature, such as hairstyle from facial images, from the pre-trained generative models. As the target feature is only presented in a local region of an image, unlearning the entire image from the pre-trained model may result in losing other details in the remaining region of the image. To specify which features to unlearn, we collect randomly generated images that contain the target features. We then identify a latent representation corresponding to the target feature and then use the representation to fine-tune the pre-trained model. Through experiments on MNIST and CelebA datasets, we show that target features are successfully removed while keeping the fidelity of the original models. Further experiments with an adversarial attack show that the unlearned model is mo",
    "link": "http://arxiv.org/abs/2303.05699",
    "context": "Title: Feature Unlearning for Pre-trained GANs and VAEs. (arXiv:2303.05699v2 [cs.CV] UPDATED)\nAbstract: We tackle the problem of feature unlearning from a pre-trained image generative model: GANs and VAEs. Unlike a common unlearning task where an unlearning target is a subset of the training set, we aim to unlearn a specific feature, such as hairstyle from facial images, from the pre-trained generative models. As the target feature is only presented in a local region of an image, unlearning the entire image from the pre-trained model may result in losing other details in the remaining region of the image. To specify which features to unlearn, we collect randomly generated images that contain the target features. We then identify a latent representation corresponding to the target feature and then use the representation to fine-tune the pre-trained model. Through experiments on MNIST and CelebA datasets, we show that target features are successfully removed while keeping the fidelity of the original models. Further experiments with an adversarial attack show that the unlearned model is mo",
    "path": "papers/23/03/2303.05699.json",
    "total_tokens": 813,
    "translated_title": "预训练GAN和VAE的特征消除",
    "translated_abstract": "我们解决了从预训练的图像生成模型（GAN和VAE）中消除特征的问题。与常见的消除任务不同，我们的目标是从预训练的生成模型中消除特定的特征，例如面部图像中的发型。由于目标特征仅出现在图像的局部区域中，从预训练模型中消除整个图像可能导致失去图像剩余区域中的其他细节。为了指定要消除的特征，我们收集包含目标特征的随机生成图像。然后，我们识别与目标特征对应的潜在表示，并使用表示来微调预训练模型。通过对MNIST和CelebA数据集进行实验，我们展示了成功删除目标特征同时保持原始模型的可信度。进一步的对抗性攻击实验证明了消除后的模型的鲁棒性。",
    "tldr": "本文提出了一种从预训练的GAN和VAE模型中消除特定特征的方法，并通过实验证明了方法的有效性。",
    "en_tdlr": "This paper proposes a method to remove specific features from pre-trained GANs and VAEs, and demonstrates its effectiveness through experiments."
}