{
    "title": "Learning Complicated Manipulation Skills via Deterministic Policy with Limited Demonstrations. (arXiv:2303.16469v1 [cs.RO])",
    "abstract": "Combined with demonstrations, deep reinforcement learning can efficiently develop policies for manipulators. However, it takes time to collect sufficient high-quality demonstrations in practice. And human demonstrations may be unsuitable for robots. The non-Markovian process and over-reliance on demonstrations are further challenges. For example, we found that RL agents are sensitive to demonstration quality in manipulation tasks and struggle to adapt to demonstrations directly from humans. Thus it is challenging to leverage low-quality and insufficient demonstrations to assist reinforcement learning in training better policies, and sometimes, limited demonstrations even lead to worse performance.  We propose a new algorithm named TD3fG (TD3 learning from a generator) to solve these problems. It forms a smooth transition from learning from experts to learning from experience. This innovation can help agents extract prior knowledge while reducing the detrimental effects of the demonstra",
    "link": "http://arxiv.org/abs/2303.16469",
    "context": "Title: Learning Complicated Manipulation Skills via Deterministic Policy with Limited Demonstrations. (arXiv:2303.16469v1 [cs.RO])\nAbstract: Combined with demonstrations, deep reinforcement learning can efficiently develop policies for manipulators. However, it takes time to collect sufficient high-quality demonstrations in practice. And human demonstrations may be unsuitable for robots. The non-Markovian process and over-reliance on demonstrations are further challenges. For example, we found that RL agents are sensitive to demonstration quality in manipulation tasks and struggle to adapt to demonstrations directly from humans. Thus it is challenging to leverage low-quality and insufficient demonstrations to assist reinforcement learning in training better policies, and sometimes, limited demonstrations even lead to worse performance.  We propose a new algorithm named TD3fG (TD3 learning from a generator) to solve these problems. It forms a smooth transition from learning from experts to learning from experience. This innovation can help agents extract prior knowledge while reducing the detrimental effects of the demonstra",
    "path": "papers/23/03/2303.16469.json",
    "total_tokens": 868,
    "translated_abstract": "结合示教，深度强化学习能够高效地开发机械臂的策略。然而，实践中收集足够高质量的示教需要时间，人类示教可能不适合机器人。过度依赖示教和非Markov过程是进一步的挑战。因此，在使用有限且低质量的示教来帮助强化学习训练更好的策略方面具有挑战性，有时，有限的示教甚至会导致性能变差。我们提出了一种名为TD3fG的新算法来解决这些问题。它从“学习专家”过渡到“学习经历”，可以帮助代理人提取先前的知识，同时减少示教的有害影响。",
    "tldr": "该论文提出了一种名为TD3fG的新算法，旨在解决深度强化学习在示教质量、示教数量和非Markov过程上的挑战。这一创新可以帮助代理人从经验和先前知识中学习，提高训练的效率与性能。",
    "en_tdlr": "This paper proposes a new algorithm named TD3fG to address the challenges of deep reinforcement learning in terms of demonstration quality, quantity, and non-Markov processes. This innovation can help agents learn from experience and prior knowledge, improving the efficiency and performance of training."
}