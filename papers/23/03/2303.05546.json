{
    "title": "Weakly-Supervised HOI Detection from Interaction Labels Only and Language/Vision-Language Priors. (arXiv:2303.05546v1 [cs.CV])",
    "abstract": "Human-object interaction (HOI) detection aims to extract interacting human-object pairs and their interaction categories from a given natural image. Even though the labeling effort required for building HOI detection datasets is inherently more extensive than for many other computer vision tasks, weakly-supervised directions in this area have not been sufficiently explored due to the difficulty of learning human-object interactions with weak supervision, rooted in the combinatorial nature of interactions over the object and predicate space. In this paper, we tackle HOI detection with the weakest supervision setting in the literature, using only image-level interaction labels, with the help of a pretrained vision-language model (VLM) and a large language model (LLM). We first propose an approach to prune non-interacting human and object proposals to increase the quality of positive pairs within the bag, exploiting the grounding capability of the vision-language model. Second, we use a l",
    "link": "http://arxiv.org/abs/2303.05546",
    "raw_ret": "{\n    \"translated_title\": \"从交互标签和语言/视觉-语言先验中仅使用弱监督进行HOI检测\",\n    \"translated_abstract\": \"人-物交互（HOI）检测旨在从给定的自然图像中提取相互作用的人-物对及其交互类别。尽管构建HOI检测数据集所需的标记工作本质上比许多其他计算机视觉任务更加广泛，但由于相互作用在对象和谓词空间上的组合性质，学习弱监督下的人-物交互仍然很困难。本文使用仅有的图像级交互标签和预训练的视觉-语言模型（VLM）以及大型语言模型（LLM）来处理HOI检测。首先，我们提出了一种方法，利用视觉-语言模型的定位能力来修剪非交互人和物体的建议，从而提高袋内正样本对的质量。其次，我们使用一个L...\",\n    \"tldr\": \"本文提出了一种仅使用图像级交互标签、预训练的视觉-语言模型（VLM）和大型语言模型（LLM）来处理HOI检测的方法。通过利用视觉-语言模型的定位能力来修剪非交互人和物体的建议，从而提高袋内正样本对的质量。\"\n}",
    "total_tokens": 866,
    "ret": {
        "translated_title": "从交互标签和语言/视觉-语言先验中仅使用弱监督进行HOI检测",
        "translated_abstract": "人-物交互（HOI）检测旨在从给定的自然图像中提取相互作用的人-物对及其交互类别。尽管构建HOI检测数据集所需的标记工作本质上比许多其他计算机视觉任务更加广泛，但由于相互作用在对象和谓词空间上的组合性质，学习弱监督下的人-物交互仍然很困难。本文使用仅有的图像级交互标签和预训练的视觉-语言模型（VLM）以及大型语言模型（LLM）来处理HOI检测。首先，我们提出了一种方法，利用视觉-语言模型的定位能力来修剪非交互人和物体的建议，从而提高袋内正样本对的质量。其次，我们使用一个L...",
        "tldr": "本文提出了一种仅使用图像级交互标签、预训练的视觉-语言模型（VLM）和大型语言模型（LLM）来处理HOI检测的方法。通过利用视觉-语言模型的定位能力来修剪非交互人和物体的建议，从而提高袋内正样本对的质量。"
    }
}