{
    "title": "Shapley Chains: Extending Shapley Values to Classifier Chains. (arXiv:2303.17243v1 [cs.LG])",
    "abstract": "In spite of increased attention on explainable machine learning models, explaining multi-output predictions has not yet been extensively addressed. Methods that use Shapley values to attribute feature contributions to the decision making are one of the most popular approaches to explain local individual and global predictions. By considering each output separately in multi-output tasks, these methods fail to provide complete feature explanations. We propose Shapley Chains to overcome this issue by including label interdependencies in the explanation design process. Shapley Chains assign Shapley values as feature importance scores in multi-output classification using classifier chains, by separating the direct and indirect influence of these feature scores. Compared to existing methods, this approach allows to attribute a more complete feature contribution to the predictions of multi-output classification tasks. We provide a mechanism to distribute the hidden contributions of the output",
    "link": "http://arxiv.org/abs/2303.17243",
    "context": "Title: Shapley Chains: Extending Shapley Values to Classifier Chains. (arXiv:2303.17243v1 [cs.LG])\nAbstract: In spite of increased attention on explainable machine learning models, explaining multi-output predictions has not yet been extensively addressed. Methods that use Shapley values to attribute feature contributions to the decision making are one of the most popular approaches to explain local individual and global predictions. By considering each output separately in multi-output tasks, these methods fail to provide complete feature explanations. We propose Shapley Chains to overcome this issue by including label interdependencies in the explanation design process. Shapley Chains assign Shapley values as feature importance scores in multi-output classification using classifier chains, by separating the direct and indirect influence of these feature scores. Compared to existing methods, this approach allows to attribute a more complete feature contribution to the predictions of multi-output classification tasks. We provide a mechanism to distribute the hidden contributions of the output",
    "path": "papers/23/03/2303.17243.json",
    "total_tokens": 809,
    "translated_title": "Shapley Chains: 将 Shapley 值扩展到分类器链上",
    "translated_abstract": "尽管可解释机器学习模型受到越来越多的关注，但解释多个输出预测的方法还没有得到广泛解决。使用 Shapley 值将特征贡献归因于决策过程是解释局部个体和全局预测的最流行方法之一。然而，在多输出任务中，这些方法由于单独考虑每个输出而无法提供完整的特征解释。为了解决这个问题，我们提出了 Shapley Chains，通过在解释设计过程中包含标签相互依赖关系，使用分类器链将 Shapley 值分配为多输出分类中的特征重要性分数，从而区分这些特征分数的直接和间接影响。与现有方法相比，这种方法能够更完整地将特征贡献归属于多输出分类任务的预测中。",
    "tldr": "Shapley Chains 将 Shapley 值扩展到分类器链上，通过考虑标签之间的相关性提供了更完整的特征贡献归属解释，尤其适用于多输出分类任务。",
    "en_tdlr": "Shapley Chains extends Shapley values to classifier chains to provide more complete feature explanation, especially for multi-output classification tasks, by considering label interdependencies."
}