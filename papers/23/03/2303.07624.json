{
    "title": "I3D: Transformer architectures with input-dependent dynamic depth for speech recognition. (arXiv:2303.07624v1 [cs.CL])",
    "abstract": "Transformer-based end-to-end speech recognition has achieved great success. However, the large footprint and computational overhead make it difficult to deploy these models in some real-world applications. Model compression techniques can reduce the model size and speed up inference, but the compressed model has a fixed architecture which might be suboptimal. We propose a novel Transformer encoder with Input-Dependent Dynamic Depth (I3D) to achieve strong performance-efficiency trade-offs. With a similar number of layers at inference time, I3D-based models outperform the vanilla Transformer and the static pruned model via iterative layer pruning. We also present interesting analysis on the gate probabilities and the input-dependency, which helps us better understand deep encoders.",
    "link": "http://arxiv.org/abs/2303.07624",
    "context": "Title: I3D: Transformer architectures with input-dependent dynamic depth for speech recognition. (arXiv:2303.07624v1 [cs.CL])\nAbstract: Transformer-based end-to-end speech recognition has achieved great success. However, the large footprint and computational overhead make it difficult to deploy these models in some real-world applications. Model compression techniques can reduce the model size and speed up inference, but the compressed model has a fixed architecture which might be suboptimal. We propose a novel Transformer encoder with Input-Dependent Dynamic Depth (I3D) to achieve strong performance-efficiency trade-offs. With a similar number of layers at inference time, I3D-based models outperform the vanilla Transformer and the static pruned model via iterative layer pruning. We also present interesting analysis on the gate probabilities and the input-dependency, which helps us better understand deep encoders.",
    "path": "papers/23/03/2303.07624.json",
    "total_tokens": 869,
    "translated_title": "I3D: 基于输入依赖性动态深度的Transformer结构用于语音识别",
    "translated_abstract": "基于Transformer的端到端语音识别已经取得了非常大的成功。但是，由于其大的尺寸和计算开销，使得在某些真实世界的应用中难以部署这些模型。模型压缩技术可以减小模型尺寸并加快推理速度，但压缩模型具有固定的结构，这可能是次优的。我们提出了一种新的Transformer编码器，称为输入依赖性动态深度（I3D），以实现强大的性能效率折衷。在推理时采用类似数量的层次的情况下，基于I3D的模型优于普通的Transformer和通过迭代层级修剪得到的静态修剪模型。我们还对门概率和输入依赖性进行了有趣的分析，这有助于我们更好地理解深度编码器。",
    "tldr": "本篇论文提出了一种新的基于输入依赖性动态深度的Transformer编码器，即I3D，在推理时采用类似数量的层次的情况下，优于普通的Transformer和通过迭代层级修剪得到的静态修剪模型，有望在语音识别中实现性能效率最大化。",
    "en_tdlr": "This paper proposes a novel Transformer encoder with Input-Dependent Dynamic Depth (I3D) for achieving great performance-efficiency trade-offs in end-to-end speech recognition. I3D-based models outperform vanilla Transformer and static pruned model, and show potential to maximize performance efficiency."
}