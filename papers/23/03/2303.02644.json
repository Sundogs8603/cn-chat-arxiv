{
    "title": "Expectation consistency for calibration of neural networks. (arXiv:2303.02644v2 [cs.LG] UPDATED)",
    "abstract": "Despite their incredible performance, it is well reported that deep neural networks tend to be overoptimistic about their prediction confidence. Finding effective and efficient calibration methods for neural networks is therefore an important endeavour towards better uncertainty quantification in deep learning. In this manuscript, we introduce a novel calibration technique named expectation consistency (EC), consisting of a post-training rescaling of the last layer weights by enforcing that the average validation confidence coincides with the average proportion of correct labels. First, we show that the EC method achieves similar calibration performance to temperature scaling (TS) across different neural network architectures and data sets, all while requiring similar validation samples and computational resources. However, we argue that EC provides a principled method grounded on a Bayesian optimality principle known as the Nishimori identity. Next, we provide an asymptotic characteri",
    "link": "http://arxiv.org/abs/2303.02644",
    "context": "Title: Expectation consistency for calibration of neural networks. (arXiv:2303.02644v2 [cs.LG] UPDATED)\nAbstract: Despite their incredible performance, it is well reported that deep neural networks tend to be overoptimistic about their prediction confidence. Finding effective and efficient calibration methods for neural networks is therefore an important endeavour towards better uncertainty quantification in deep learning. In this manuscript, we introduce a novel calibration technique named expectation consistency (EC), consisting of a post-training rescaling of the last layer weights by enforcing that the average validation confidence coincides with the average proportion of correct labels. First, we show that the EC method achieves similar calibration performance to temperature scaling (TS) across different neural network architectures and data sets, all while requiring similar validation samples and computational resources. However, we argue that EC provides a principled method grounded on a Bayesian optimality principle known as the Nishimori identity. Next, we provide an asymptotic characteri",
    "path": "papers/23/03/2303.02644.json",
    "total_tokens": 918,
    "translated_title": "神经网络校准的期望一致性",
    "translated_abstract": "尽管深度神经网络有着出色的性能，但已经有报道指出它们在预测置信度方面往往存在过度乐观的问题。寻找有效和高效的神经网络校准方法对于深度学习中更好地量化不确定性是一项重要的努力。在本文中，我们介绍了一种名为期望一致性（EC）的新型校准技术，它通过对最后一层权重进行后训练重新缩放，强制要求平均验证置信度与平均正确标签比例相一致。首先，我们证明了EC方法在不同神经网络架构和数据集上实现了与温度缩放（TS）相似的校准性能，同时需要类似的验证样本和计算资源。然而，我们认为EC提供了一种基于贝叶斯最优性原理（即Nishimori恒等式）的原则性方法。接下来，我们提供了一个渐近定义。",
    "tldr": "本文介绍了一种名为期望一致性（EC）的新型校准技术，该方法通过对最后一层权重进行后训练重新缩放，使平均验证置信度与平均正确标签比例相一致，在不同神经网络架构和数据集上实现了类似温度缩放（TS）的校准性能。",
    "en_tdlr": "This paper introduces a novel calibration technique called expectation consistency (EC), which rescales the weights of the last layer in post-training to ensure that the average validation confidence matches the average proportion of correct labels. EC achieves similar calibration performance as temperature scaling (TS) across different neural network architectures and datasets, while requiring similar validation samples and computational resources."
}