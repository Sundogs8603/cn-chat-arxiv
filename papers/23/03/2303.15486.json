{
    "title": "Unimodal Training-Multimodal Prediction: Cross-modal Federated Learning with Hierarchical Aggregation. (arXiv:2303.15486v1 [cs.LG])",
    "abstract": "Multimodal learning has seen great success mining data features from multiple modalities with remarkable model performance improvement. Meanwhile, federated learning (FL) addresses the data sharing problem, enabling privacy-preserved collaborative training to provide sufficient precious data. Great potential, therefore, arises with the confluence of them, known as multimodal federated learning. However, limitation lies in the predominant approaches as they often assume that each local dataset records samples from all modalities. In this paper, we aim to bridge this gap by proposing an Unimodal Training - Multimodal Prediction (UTMP) framework under the context of multimodal federated learning. We design HA-Fedformer, a novel transformer-based model that empowers unimodal training with only a unimodal dataset at the client and multimodal testing by aggregating multiple clients' knowledge for better accuracy. The key advantages are twofold. Firstly, to alleviate the impact of data non-II",
    "link": "http://arxiv.org/abs/2303.15486",
    "context": "Title: Unimodal Training-Multimodal Prediction: Cross-modal Federated Learning with Hierarchical Aggregation. (arXiv:2303.15486v1 [cs.LG])\nAbstract: Multimodal learning has seen great success mining data features from multiple modalities with remarkable model performance improvement. Meanwhile, federated learning (FL) addresses the data sharing problem, enabling privacy-preserved collaborative training to provide sufficient precious data. Great potential, therefore, arises with the confluence of them, known as multimodal federated learning. However, limitation lies in the predominant approaches as they often assume that each local dataset records samples from all modalities. In this paper, we aim to bridge this gap by proposing an Unimodal Training - Multimodal Prediction (UTMP) framework under the context of multimodal federated learning. We design HA-Fedformer, a novel transformer-based model that empowers unimodal training with only a unimodal dataset at the client and multimodal testing by aggregating multiple clients' knowledge for better accuracy. The key advantages are twofold. Firstly, to alleviate the impact of data non-II",
    "path": "papers/23/03/2303.15486.json",
    "total_tokens": 939,
    "translated_title": "单模态训练-多模态预测：具有分层聚合的跨模态联邦学习。",
    "translated_abstract": "多模态学习在从多种模态中挖掘数据特征方面取得了巨大成功，显着提高了模型性能。同时，联邦学习解决了数据共享问题，实现了隐私保护的协同训练，提供了足够的宝贵数据。因此，它们的融合，即多模态联邦学习，具有巨大潜力。然而，局限性在于主流方法通常假设每个本地数据集记录了所有模态的样本。本文旨在通过在多模态联邦学习的背景下提出单模态训练-多模态预测（UTMP）框架来弥合这一差距。我们设计了HA-Fedformer，一种基于transformer的新型模型，为客户端提供单模态数据集的单模态训练，并通过聚合多个客户端的知识实现多模态测试，以提高准确性。其关键优点有两个。首先，为减轻数据非II的影响",
    "tldr": "本文提出了一种单模态训练-多模态预测的框架，设计了一种新型模型HA-Fedformer，在多模态联邦学习的背景下，通过聚合多个客户端的知识实现多模态测试，以提高准确性。",
    "en_tdlr": "This paper proposes a Unimodal Training - Multimodal Prediction (UTMP) framework and designs a novel model called HA-Fedformer for better accuracy in multimodal testing by aggregating knowledge from multiple clients in the context of multimodal federated learning."
}