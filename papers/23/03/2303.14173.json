{
    "title": "How many dimensions are required to find an adversarial example?. (arXiv:2303.14173v1 [cs.LG])",
    "abstract": "Past work exploring adversarial vulnerability have focused on situations where an adversary can perturb all dimensions of model input. On the other hand, a range of recent works consider the case where either (i) an adversary can perturb a limited number of input parameters or (ii) a subset of modalities in a multimodal problem. In both of these cases, adversarial examples are effectively constrained to a subspace $V$ in the ambient input space $\\mathcal{X}$. Motivated by this, in this work we investigate how adversarial vulnerability depends on $\\dim(V)$. In particular, we show that the adversarial success of standard PGD attacks with $\\ell^p$ norm constraints behaves like a monotonically increasing function of $\\epsilon (\\frac{\\dim(V)}{\\dim \\mathcal{X}})^{\\frac{1}{q}}$ where $\\epsilon$ is the perturbation budget and $\\frac{1}{p} + \\frac{1}{q} =1$, provided $p > 1$ (the case $p=1$ presents additional subtleties which we analyze in some detail). This functional form can be easily deriv",
    "link": "http://arxiv.org/abs/2303.14173",
    "context": "Title: How many dimensions are required to find an adversarial example?. (arXiv:2303.14173v1 [cs.LG])\nAbstract: Past work exploring adversarial vulnerability have focused on situations where an adversary can perturb all dimensions of model input. On the other hand, a range of recent works consider the case where either (i) an adversary can perturb a limited number of input parameters or (ii) a subset of modalities in a multimodal problem. In both of these cases, adversarial examples are effectively constrained to a subspace $V$ in the ambient input space $\\mathcal{X}$. Motivated by this, in this work we investigate how adversarial vulnerability depends on $\\dim(V)$. In particular, we show that the adversarial success of standard PGD attacks with $\\ell^p$ norm constraints behaves like a monotonically increasing function of $\\epsilon (\\frac{\\dim(V)}{\\dim \\mathcal{X}})^{\\frac{1}{q}}$ where $\\epsilon$ is the perturbation budget and $\\frac{1}{p} + \\frac{1}{q} =1$, provided $p > 1$ (the case $p=1$ presents additional subtleties which we analyze in some detail). This functional form can be easily deriv",
    "path": "papers/23/03/2303.14173.json",
    "total_tokens": 947,
    "translated_title": "找到对抗样本需要多少维度？",
    "translated_abstract": "过去探索对抗性漏洞的研究都着眼于对手可以扰动模型输入的所有维度的情况。另一方面，许多最近的研究考虑以下情况：（i）对手可以扰动有限数量的输入参数或（ii）多模态问题中的模态子集。在这两种情况下，对抗性样本有效地受限于高维输入空间中的子空间$V$。出于这个动机，我们在本文中研究了对抗性漏洞如何取决于$V$的维数。特别地，我们展示了标准PGD攻击的对抗性成功率如何表现为$\\epsilon (\\frac{\\dim(V)}{\\dim \\mathcal{X}})^{\\frac{1}{q}}$的单调递增函数，其中$\\epsilon$是扰动预算，$\\frac{1}{p}+\\frac{q}{q}=1$，只要$p>1$（当$p=1$时会出现额外的细微差别，我们对此进行了详细的分析）。这个函数形式可以很容易地推导。",
    "tldr": "本文研究了对抗性漏洞如何取决于受限于高维输入空间中的子空间维数，同时针对标准PGD攻击的对抗性成功率提出了单调递增函数表达式。",
    "en_tdlr": "This paper investigates how adversarial vulnerability depends on the subspace dimensionality in the high-dimensional input space, and proposes a monotonically increasing function to describe the adversarial success rate of standard PGD attacks."
}