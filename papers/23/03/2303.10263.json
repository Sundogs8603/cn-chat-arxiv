{
    "title": "Fixed Design Analysis of Regularization-Based Continual Learning. (arXiv:2303.10263v1 [cs.LG])",
    "abstract": "We consider a continual learning (CL) problem with two linear regression tasks in the fixed design setting, where the feature vectors are assumed fixed and the labels are assumed to be random variables. We consider an $\\ell_2$-regularized CL algorithm, which computes an Ordinary Least Squares parameter to fit the first dataset, then computes another parameter that fits the second dataset under an $\\ell_2$-regularization penalizing its deviation from the first parameter, and outputs the second parameter. For this algorithm, we provide tight bounds on the average risk over the two tasks. Our risk bounds reveal a provable trade-off between forgetting and intransigence of the $\\ell_2$-regularized CL algorithm: with a large regularization parameter, the algorithm output forgets less information about the first task but is intransigent to extract new information from the second task; and vice versa. Our results suggest that catastrophic forgetting could happen for CL with dissimilar tasks (u",
    "link": "http://arxiv.org/abs/2303.10263",
    "context": "Title: Fixed Design Analysis of Regularization-Based Continual Learning. (arXiv:2303.10263v1 [cs.LG])\nAbstract: We consider a continual learning (CL) problem with two linear regression tasks in the fixed design setting, where the feature vectors are assumed fixed and the labels are assumed to be random variables. We consider an $\\ell_2$-regularized CL algorithm, which computes an Ordinary Least Squares parameter to fit the first dataset, then computes another parameter that fits the second dataset under an $\\ell_2$-regularization penalizing its deviation from the first parameter, and outputs the second parameter. For this algorithm, we provide tight bounds on the average risk over the two tasks. Our risk bounds reveal a provable trade-off between forgetting and intransigence of the $\\ell_2$-regularized CL algorithm: with a large regularization parameter, the algorithm output forgets less information about the first task but is intransigent to extract new information from the second task; and vice versa. Our results suggest that catastrophic forgetting could happen for CL with dissimilar tasks (u",
    "path": "papers/23/03/2303.10263.json",
    "total_tokens": 883,
    "translated_title": "固定设计下正则化连续学习的分析",
    "translated_abstract": "我们考虑一个连续学习问题，其中有两个线性回归任务，特征向量被假定为固定的，标签被假定为随机变量。我们考虑一个$\\ell_2$-正则化的连续学习算法，它计算一个普通最小二乘参数来拟合第一个数据集，然后计算另一个参数，在$\\ell_2$-正则化约束下，拟合第二个数据集并输出第二个参数。对于这个算法，我们提供了两个任务的平均风险的严格界限。我们的风险界限揭示了$\\ell_2$-正则化连续学习算法中一个可证明的遗忘和不妥协的权衡关系：使用大的正则化参数，算法输出比较不会遗忘第一个任务的信息，但不愿从第二个任务中提取新信息；反之亦然。我们的结果表明，具有不相似任务的连续学习可能会发生灾难性的遗忘。",
    "tldr": "该论文分析了固定设计下的正则化连续学习问题，提出算法在遗忘和不妥协之间存在权衡，可能会存在灾难性遗忘问题。",
    "en_tdlr": "This paper analyzes the problem of regularization-based continual learning in a fixed design setting and proposes a trade-off between forgetting and intransigence of the algorithm, which could lead to catastrophic forgetting for dissimilar tasks."
}