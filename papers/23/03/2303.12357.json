{
    "title": "Wasserstein Adversarial Examples on Univariant Time Series Data. (arXiv:2303.12357v1 [cs.LG])",
    "abstract": "Adversarial examples are crafted by adding indistinguishable perturbations to normal examples in order to fool a well-trained deep learning model to misclassify. In the context of computer vision, this notion of indistinguishability is typically bounded by $L_{\\infty}$ or other norms. However, these norms are not appropriate for measuring indistinguishiability for time series data. In this work, we propose adversarial examples in the Wasserstein space for time series data for the first time and utilize Wasserstein distance to bound the perturbation between normal examples and adversarial examples. We introduce Wasserstein projected gradient descent (WPGD), an adversarial attack method for perturbing univariant time series data. We leverage the closed-form solution of Wasserstein distance in the 1D space to calculate the projection step of WPGD efficiently with the gradient descent method. We further propose a two-step projection so that the search of adversarial examples in the Wassers",
    "link": "http://arxiv.org/abs/2303.12357",
    "context": "Title: Wasserstein Adversarial Examples on Univariant Time Series Data. (arXiv:2303.12357v1 [cs.LG])\nAbstract: Adversarial examples are crafted by adding indistinguishable perturbations to normal examples in order to fool a well-trained deep learning model to misclassify. In the context of computer vision, this notion of indistinguishability is typically bounded by $L_{\\infty}$ or other norms. However, these norms are not appropriate for measuring indistinguishiability for time series data. In this work, we propose adversarial examples in the Wasserstein space for time series data for the first time and utilize Wasserstein distance to bound the perturbation between normal examples and adversarial examples. We introduce Wasserstein projected gradient descent (WPGD), an adversarial attack method for perturbing univariant time series data. We leverage the closed-form solution of Wasserstein distance in the 1D space to calculate the projection step of WPGD efficiently with the gradient descent method. We further propose a two-step projection so that the search of adversarial examples in the Wassers",
    "path": "papers/23/03/2303.12357.json",
    "total_tokens": 1037,
    "translated_title": "Wasserstein空间的对抗性例子用于单变量时间序列数据",
    "translated_abstract": "对抗性例子是通过向正常样本添加无法区分的扰动来欺骗良好训练的深度学习模型，使其错误地分类。在计算机视觉的背景下，区分度的概念通常由$L_{\\infty}$或其他规范来限定，但是这些规范不适用于时间序列数据的区分度衡量。在本研究中，我们首次针对时间序列数据提出了Wasserstein空间中的对抗性例子，并利用Wasserstein距离来限定正常样本和对抗性例子之间的扰动。我们引入了Wasserstein投影梯度下降（WPGD），一种扰动单变量时间序列数据的对抗性攻击方法。我们利用1D空间中Wasserstein距离的封闭形式解来计算WPGD的投影步骤，以最小化扰动。我们进一步提出了两步投影方法，以有效进行在Wasserstein空间中的对抗性例子搜索。我们的实验结果表明，与其他最先进的方法相比，WPGD能够成功地对单变量时间序列数据进行对抗性攻击，并显著提高攻击的成功率。",
    "tldr": "该论文为时间序列数据提出了一种新的对抗性攻击方法WPGD，利用Wasserstein距离限制正常样本和对抗性例子之间的扰动。实验结果表明该方法能够成功地对单变量时间序列数据进行对抗性攻击，并显著提高成功率。",
    "en_tdlr": "The paper proposes a novel adversarial attack method, WPGD, for univariant time series data, leveraging Wasserstein distance to bound perturbation between normal and adversarial examples. This method successfully improves the success rate of attacks compared to other state-of-the-art methods, according to experimental results."
}