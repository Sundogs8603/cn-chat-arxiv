{
    "title": "qEUBO: A Decision-Theoretic Acquisition Function for Preferential Bayesian Optimization. (arXiv:2303.15746v1 [cs.LG])",
    "abstract": "Preferential Bayesian optimization (PBO) is a framework for optimizing a decision maker's latent utility function using preference feedback. This work introduces the expected utility of the best option (qEUBO) as a novel acquisition function for PBO. When the decision maker's responses are noise-free, we show that qEUBO is one-step Bayes optimal and thus equivalent to the popular knowledge gradient acquisition function. We also show that qEUBO enjoys an additive constant approximation guarantee to the one-step Bayes-optimal policy when the decision maker's responses are corrupted by noise. We provide an extensive evaluation of qEUBO and demonstrate that it outperforms the state-of-the-art acquisition functions for PBO across many settings. Finally, we show that, under sufficient regularity conditions, qEUBO's Bayesian simple regret converges to zero at a rate $o(1/n)$ as the number of queries, $n$, goes to infinity. In contrast, we show that simple regret under qEI, a popular acquisiti",
    "link": "http://arxiv.org/abs/2303.15746",
    "context": "Title: qEUBO: A Decision-Theoretic Acquisition Function for Preferential Bayesian Optimization. (arXiv:2303.15746v1 [cs.LG])\nAbstract: Preferential Bayesian optimization (PBO) is a framework for optimizing a decision maker's latent utility function using preference feedback. This work introduces the expected utility of the best option (qEUBO) as a novel acquisition function for PBO. When the decision maker's responses are noise-free, we show that qEUBO is one-step Bayes optimal and thus equivalent to the popular knowledge gradient acquisition function. We also show that qEUBO enjoys an additive constant approximation guarantee to the one-step Bayes-optimal policy when the decision maker's responses are corrupted by noise. We provide an extensive evaluation of qEUBO and demonstrate that it outperforms the state-of-the-art acquisition functions for PBO across many settings. Finally, we show that, under sufficient regularity conditions, qEUBO's Bayesian simple regret converges to zero at a rate $o(1/n)$ as the number of queries, $n$, goes to infinity. In contrast, we show that simple regret under qEI, a popular acquisiti",
    "path": "papers/23/03/2303.15746.json",
    "total_tokens": 1080,
    "translated_title": "qEUBO: 基于决策理论的、用于优化偏好反馈的贝叶斯优化函数",
    "translated_abstract": "偏好贝叶斯优化(PBO)是一种用于使用偏好反馈优化决策制定者潜在效用函数的框架。本文将最好选项的预期效用(qEUBO)引入PBO作为一种新的采集函数。当决策制定者的响应无噪声时，我们展示qEUBO是一步贝叶斯最优的，并且与流行的知识梯度采集函数等效。我们还展示，当决策制定者的响应受到噪声污染时，qEUBO在一步贝叶斯最优策略上享有附加的近似保证。我们对qEUBO进行了广泛的评估，并证明在许多设置中，它优于PBO的最先进采集函数。最后，我们展示，在充分的正则化条件下，qEUBO的贝叶斯简单遗憾将以$O(1/n)$的速度趋近于零，其中$n$是查询数量。相比之下，我们展示了对于流行的PBO采集函数qEI，简单遗憾收敛速度较慢，为$O(1/\\sqrt{n})$。",
    "tldr": "本文介绍了一种新的用于优化偏好反馈的贝叶斯优化函数qEUBO，并展示了它在许多设置中优于现有的采集函数。在充分的条件下，qEUBO的遗憾收敛速度快于现有采集函数qEI。",
    "en_tdlr": "This paper introduces a novel acquisition function, qEUBO, for optimizing the decision maker's latent utility function using preference feedback in Preferential Bayesian Optimization (PBO). qEUBO is one-step Bayes optimal and outperforms other state-of-the-art acquisition functions in PBO. Additionally, under sufficient regularity conditions, qEUBO's Bayesian simple regret converges to zero at a faster rate compared to the popular acquisition function qEI."
}