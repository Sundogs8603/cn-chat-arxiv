{
    "title": "Denoising Diffusion Autoencoders are Unified Self-supervised Learners. (arXiv:2303.09769v1 [cs.CV])",
    "abstract": "Inspired by recent advances in diffusion models, which are reminiscent of denoising autoencoders, we investigate whether they can acquire discriminative representations for classification via generative pre-training. This paper shows that the networks in diffusion models, namely denoising diffusion autoencoders (DDAE), are unified self-supervised learners: by pre-training on unconditional image generation, DDAE has already learned strongly linear-separable representations at its intermediate layers without auxiliary encoders, thus making diffusion pre-training emerge as a general approach for self-supervised generative and discriminative learning. To verify this, we perform linear probe and fine-tuning evaluations on multi-class datasets. Our diffusion-based approach achieves 95.9% and 50.0% linear probe accuracies on CIFAR-10 and Tiny-ImageNet, respectively, and is comparable to masked autoencoders and contrastive learning for the first time. Additionally, transfer learning from Image",
    "link": "http://arxiv.org/abs/2303.09769",
    "context": "Title: Denoising Diffusion Autoencoders are Unified Self-supervised Learners. (arXiv:2303.09769v1 [cs.CV])\nAbstract: Inspired by recent advances in diffusion models, which are reminiscent of denoising autoencoders, we investigate whether they can acquire discriminative representations for classification via generative pre-training. This paper shows that the networks in diffusion models, namely denoising diffusion autoencoders (DDAE), are unified self-supervised learners: by pre-training on unconditional image generation, DDAE has already learned strongly linear-separable representations at its intermediate layers without auxiliary encoders, thus making diffusion pre-training emerge as a general approach for self-supervised generative and discriminative learning. To verify this, we perform linear probe and fine-tuning evaluations on multi-class datasets. Our diffusion-based approach achieves 95.9% and 50.0% linear probe accuracies on CIFAR-10 and Tiny-ImageNet, respectively, and is comparable to masked autoencoders and contrastive learning for the first time. Additionally, transfer learning from Image",
    "path": "papers/23/03/2303.09769.json",
    "total_tokens": 1021,
    "translated_title": "去噪扩散自编码器是统一自监督学习器",
    "translated_abstract": "受扩散模型最近的进展的启发，这些模型类似于去噪自编码器，我们研究它们是否可以通过生成预训练获取分类的辨别性表示。本文展示了扩散模型中的网络，即去噪扩散自编码器(DDAE)是统一的自监督学习器:通过在无条件图像生成上进行预训练，DDAE已经在中间层学习到了强有力的线性可分表示，而无需辅助编码器，从而使扩散预训练成为自监督生成和辨别性学习的通用方法。为了验证这一点，我们在多类数据集上执行线性探测和微调评估。我们基于扩散的方法，在CIFAR-10和Tiny-ImageNet上分别实现了95.9％和50.0％的线性探测精度，与掩码自编码器和对比学习首次可比较。此外，从Image上的转移学习",
    "tldr": "本文研究了去噪扩散自编码器 (DDAE) 是否能通过无条件图像生成训练获取强有力的线性可分表示，结果表明DDAE是一个统一的自监督学习器，对于自监督生成和辨别性学习是通用的方法。在多类数据集上实现了95.9％和50.0％的线性探测精度，与掩码自编码器和对比学习相当。"
}