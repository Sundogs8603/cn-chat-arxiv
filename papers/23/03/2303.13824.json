{
    "title": "$k$NN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference. (arXiv:2303.13824v1 [cs.CL])",
    "abstract": "In-Context Learning (ICL), which formulates target tasks as prompt completion conditioned on in-context demonstrations, has become the prevailing utilization of LLMs. In this paper, we first disclose an actual predicament for this typical usage that it can not scale up with training data due to context length restriction. Besides, existing works have shown that ICL also suffers from various biases and requires delicate calibration treatment. To address both challenges, we advocate a simple and effective solution, $k$NN Prompting, which first queries LLM with training data for distributed representations, then predicts test instances by simply referring to nearest neighbors. We conduct comprehensive experiments to demonstrate its two-fold superiority: 1) Calibration-Free: $k$NN Prompting does not directly align LLM output distribution with task-specific label space, instead leverages such distribution to align test and training instances. It significantly outperforms state-of-the-art ca",
    "link": "http://arxiv.org/abs/2303.13824",
    "context": "Title: $k$NN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference. (arXiv:2303.13824v1 [cs.CL])\nAbstract: In-Context Learning (ICL), which formulates target tasks as prompt completion conditioned on in-context demonstrations, has become the prevailing utilization of LLMs. In this paper, we first disclose an actual predicament for this typical usage that it can not scale up with training data due to context length restriction. Besides, existing works have shown that ICL also suffers from various biases and requires delicate calibration treatment. To address both challenges, we advocate a simple and effective solution, $k$NN Prompting, which first queries LLM with training data for distributed representations, then predicts test instances by simply referring to nearest neighbors. We conduct comprehensive experiments to demonstrate its two-fold superiority: 1) Calibration-Free: $k$NN Prompting does not directly align LLM output distribution with task-specific label space, instead leverages such distribution to align test and training instances. It significantly outperforms state-of-the-art ca",
    "path": "papers/23/03/2303.13824.json",
    "total_tokens": 891,
    "translated_title": "$k$NN提示：无需校准的最近相邻推理，超越上下文学习",
    "translated_abstract": "在上下文学习中，将目标任务制定为在上下文演示的条件下完成提示完成，已成为LLM的主要用途。本文首先披露了这种典型用法的实际问题，由于上下文长度的限制，它无法随着训练数据扩展。此外，现有的研究表明，ICL还受到各种偏见的影响，并需要精细的校准处理。为了解决这两个挑战，我们提出了一种简单有效的解决方案，$k$NN提示，它首先使用训练数据查询LLM的分布式表示，然后通过简单地参考最近邻来预测测试实例。我们进行了全面的实验来证明其优越性：1）无需校准：$k$NN提示不直接将LLM输出分布与特定任务标签空间对准，而是利用这种分布将测试和训练实例对准。它显着优于最先进的方法。",
    "tldr": "本文提出$k$NN提示，一种不需要校准就可以推理最近相邻的算法，用来解决上下文学习的限制和偏见问题，显着优于最先进的方法。",
    "en_tdlr": "In this paper, the authors propose a novel algorithm called $k$NN Prompting, which can do nearest neighbor inference without calibration, to overcome limitations and biases of in-context learning. The method significantly outperforms state-of-the-art approaches."
}