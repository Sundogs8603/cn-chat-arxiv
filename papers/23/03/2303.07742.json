{
    "title": "ForDigitStress: A multi-modal stress dataset employing a digital job interview scenario. (arXiv:2303.07742v1 [cs.LG])",
    "abstract": "We present a multi-modal stress dataset that uses digital job interviews to induce stress. The dataset provides multi-modal data of 40 participants including audio, video (motion capturing, facial recognition, eye tracking) as well as physiological information (photoplethysmography, electrodermal activity). In addition to that, the dataset contains time-continuous annotations for stress and occurred emotions (e.g. shame, anger, anxiety, surprise). In order to establish a baseline, five different machine learning classifiers (Support Vector Machine, K-Nearest Neighbors, Random Forest, Long-Short-Term Memory Network) have been trained and evaluated on the proposed dataset for a binary stress classification task. The best-performing classifier achieved an accuracy of 88.3% and an F1-score of 87.5%.",
    "link": "http://arxiv.org/abs/2303.07742",
    "context": "Title: ForDigitStress: A multi-modal stress dataset employing a digital job interview scenario. (arXiv:2303.07742v1 [cs.LG])\nAbstract: We present a multi-modal stress dataset that uses digital job interviews to induce stress. The dataset provides multi-modal data of 40 participants including audio, video (motion capturing, facial recognition, eye tracking) as well as physiological information (photoplethysmography, electrodermal activity). In addition to that, the dataset contains time-continuous annotations for stress and occurred emotions (e.g. shame, anger, anxiety, surprise). In order to establish a baseline, five different machine learning classifiers (Support Vector Machine, K-Nearest Neighbors, Random Forest, Long-Short-Term Memory Network) have been trained and evaluated on the proposed dataset for a binary stress classification task. The best-performing classifier achieved an accuracy of 88.3% and an F1-score of 87.5%.",
    "path": "papers/23/03/2303.07742.json",
    "total_tokens": 850,
    "translated_title": "ForDigitStress：一种采用数字化面试情境的多模态压力数据集",
    "translated_abstract": "我们提出了一个多模态的压力数据集，使用数字化面试来诱发压力。该数据集提供了40名参与者的多模态数据，包括音频、视频（动作捕捉、面部识别、眼动追踪）以及生理信息（光电脉搏图、皮肤电反应）。除此之外，该数据集还包含了压力和发生情绪（如羞耻、愤怒、焦虑、惊讶）的时间连续标注。为了建立基准线，我们针对二元压力分类任务，在所提出的数据集上训练并评估了五个不同的机器学习分类器（支持向量机、K近邻、随机森林、长短期记忆网络）。最佳表现分类器的准确率和F1分数分别为88.3%和87.5%。",
    "tldr": "该论文介绍了一个使用数字化面试情境来诱发压力并提供多模态数据、连续标注和基准分类器的压力数据集。最佳表现分类器的准确率和F1分数分别为88.3%和87.5%。",
    "en_tdlr": "This paper introduces a stress dataset that uses digital job interviews to induce stress, including multimodal data, continuous annotations and baseline classifiers. The best-performing classifier achieved an accuracy of 88.3% and an F1-score of 87.5%."
}