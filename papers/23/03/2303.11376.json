{
    "title": "GNN-Ensemble: Towards Random Decision Graph Neural Networks. (arXiv:2303.11376v1 [cs.LG])",
    "abstract": "Graph Neural Networks (GNNs) have enjoyed wide spread applications in graph-structured data. However, existing graph based applications commonly lack annotated data. GNNs are required to learn latent patterns from a limited amount of training data to perform inferences on a vast amount of test data. The increased complexity of GNNs, as well as a single point of model parameter initialization, usually lead to overfitting and sub-optimal performance. In addition, it is known that GNNs are vulnerable to adversarial attacks. In this paper, we push one step forward on the ensemble learning of GNNs with improved accuracy, generalization, and adversarial robustness. Following the principles of stochastic modeling, we propose a new method called GNN-Ensemble to construct an ensemble of random decision graph neural networks whose capacity can be arbitrarily expanded for improvement in performance. The essence of the method is to build multiple GNNs in randomly selected substructures in the topo",
    "link": "http://arxiv.org/abs/2303.11376",
    "context": "Title: GNN-Ensemble: Towards Random Decision Graph Neural Networks. (arXiv:2303.11376v1 [cs.LG])\nAbstract: Graph Neural Networks (GNNs) have enjoyed wide spread applications in graph-structured data. However, existing graph based applications commonly lack annotated data. GNNs are required to learn latent patterns from a limited amount of training data to perform inferences on a vast amount of test data. The increased complexity of GNNs, as well as a single point of model parameter initialization, usually lead to overfitting and sub-optimal performance. In addition, it is known that GNNs are vulnerable to adversarial attacks. In this paper, we push one step forward on the ensemble learning of GNNs with improved accuracy, generalization, and adversarial robustness. Following the principles of stochastic modeling, we propose a new method called GNN-Ensemble to construct an ensemble of random decision graph neural networks whose capacity can be arbitrarily expanded for improvement in performance. The essence of the method is to build multiple GNNs in randomly selected substructures in the topo",
    "path": "papers/23/03/2303.11376.json",
    "total_tokens": 840,
    "translated_title": "GNN-Ensemble：面向随机决策图神经网络",
    "translated_abstract": "图神经网络（GNNs）在图结构数据方面广泛应用，但是现有的基于图的应用通常缺乏注释数据。GNNs需要从有限的训练数据中学习潜在的模式，以对大量的测试数据进行推断。GNNs的增加复杂性，以及单点模型参数初始化，通常会导致过度适应和次优性能。此外，众所周知GNNs易受到对抗性攻击。在本文中，我们提出了一种名为GNN-Ensemble的新方法，该方法遵循随机建模的原则，在拓扑上随机选择子结构中构建多个GNNs来构建随机决策图神经网络，其容量可以任意扩展，以提高性能和对抗鲁棒性。",
    "tldr": "本文提出了一种名为GNN-Ensemble的方法，它可以构建随机决策图神经网络的集合，以提高GNNs的性能，泛化能力和抗攻击性，并遵循随机建模的原则。",
    "en_tdlr": "The paper proposes a method called GNN-Ensemble, which constructs an ensemble of random decision graph neural networks to improve the performance, generalization, and adversarial robustness of GNNs, following the principles of stochastic modeling."
}