{
    "title": "PULSNAR -- Positive unlabeled learning selected not at random: class proportion estimation when the SCAR assumption does not hold. (arXiv:2303.08269v1 [cs.LG])",
    "abstract": "Positive and Unlabeled (PU) learning is a type of semi-supervised binary classification where the machine learning algorithm differentiates between a set of positive instances (labeled) and a set of both positive and negative instances (unlabeled). PU learning has broad applications in settings where confirmed negatives are unavailable or difficult to obtain, and there is value in discovering positives among the unlabeled (e.g., viable drugs among untested compounds). Most PU learning algorithms make the selected completely at random (SCAR) assumption, namely that positives are selected independently of their features. However, in many real-world applications, such as healthcare, positives are not SCAR (e.g., severe cases are more likely to be diagnosed), leading to a poor estimate of the proportion, $\\alpha$, of positives among unlabeled examples and poor model calibration, resulting in an uncertain decision threshold for selecting positives. PU learning algorithms can estimate $\\alph",
    "link": "http://arxiv.org/abs/2303.08269",
    "context": "Title: PULSNAR -- Positive unlabeled learning selected not at random: class proportion estimation when the SCAR assumption does not hold. (arXiv:2303.08269v1 [cs.LG])\nAbstract: Positive and Unlabeled (PU) learning is a type of semi-supervised binary classification where the machine learning algorithm differentiates between a set of positive instances (labeled) and a set of both positive and negative instances (unlabeled). PU learning has broad applications in settings where confirmed negatives are unavailable or difficult to obtain, and there is value in discovering positives among the unlabeled (e.g., viable drugs among untested compounds). Most PU learning algorithms make the selected completely at random (SCAR) assumption, namely that positives are selected independently of their features. However, in many real-world applications, such as healthcare, positives are not SCAR (e.g., severe cases are more likely to be diagnosed), leading to a poor estimate of the proportion, $\\alpha$, of positives among unlabeled examples and poor model calibration, resulting in an uncertain decision threshold for selecting positives. PU learning algorithms can estimate $\\alph",
    "path": "papers/23/03/2303.08269.json",
    "total_tokens": 1139,
    "translated_title": "PULSNAR -- 在SCAR假设不成立时选择正无标记学习：分类比例估计",
    "translated_abstract": "正无标记（PU）学习是半监督二元分类的一种，其中机器学习算法区分一组正实例（带有标签）和一组既有正类又有负类实例（没有标签）。在确认负例不可用或难以获取，并且在未标记的实例中发现正例具有价值的情况下（例如，在未测试的化合物中找到可行药物），PU学习具有广泛的应用。大多数PU学习算法认为选择正实例独立于它们的特征，即进行完全随机选择（SCAR）假设。然而，在许多现实世界的应用中，例如医疗保健，正实例不是SCAR（例如，严重情况更容易被诊断出），导致在无标记示例中估计阳性比例α和模型校准性能差，进而导致选择正例的不确定决策阈值。PU学习算法可以通过估计每个未标记实例是阳性的概率来估计α并提供校准模型。然而，当SCAR假设不成立时，现有方法表现不佳。本文提出了一种新的PU方法PULSNAR，即使在SCAR不成立时，也可以实现准确的α估计和校准模型。我们的方法基于对未标记示例分布的新假设，称为阳性均匀条件。实证研究表明，我们的方法在合成和实际数据集中均优于现有最先进的PU方法。",
    "tldr": "本文提出了一种新的PU方法PULSNAR，即使在SCAR不成立时，也可以实现准确的α估计和校准模型。",
    "en_tdlr": "This paper proposes a new PU method, PULSNAR, that achieves accurate α estimation and calibrated models even when SCAR is violated."
}