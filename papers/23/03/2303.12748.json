{
    "title": "Enabling Calibration In The Zero-Shot Inference of Large Vision-Language Models. (arXiv:2303.12748v1 [cs.CV])",
    "abstract": "Calibration of deep learning models is crucial to their trustworthiness and safe usage, and as such, has been extensively studied in supervised classification models, with methods crafted to decrease miscalibration. However, there has yet to be a comprehensive study of the calibration of vision-language models that are used for zero-shot inference, like CLIP. We measure calibration across relevant variables like prompt, dataset, and architecture, and find that zero-shot inference with CLIP is miscalibrated. Furthermore, we propose a modified version of temperature scaling that is aligned with the common use cases of CLIP as a zero-shot inference model, and show that a single learned temperature generalizes for each specific CLIP model (defined by a chosen pre-training dataset and architecture) across inference dataset and prompt choice.",
    "link": "http://arxiv.org/abs/2303.12748",
    "context": "Title: Enabling Calibration In The Zero-Shot Inference of Large Vision-Language Models. (arXiv:2303.12748v1 [cs.CV])\nAbstract: Calibration of deep learning models is crucial to their trustworthiness and safe usage, and as such, has been extensively studied in supervised classification models, with methods crafted to decrease miscalibration. However, there has yet to be a comprehensive study of the calibration of vision-language models that are used for zero-shot inference, like CLIP. We measure calibration across relevant variables like prompt, dataset, and architecture, and find that zero-shot inference with CLIP is miscalibrated. Furthermore, we propose a modified version of temperature scaling that is aligned with the common use cases of CLIP as a zero-shot inference model, and show that a single learned temperature generalizes for each specific CLIP model (defined by a chosen pre-training dataset and architecture) across inference dataset and prompt choice.",
    "path": "papers/23/03/2303.12748.json",
    "total_tokens": 834,
    "translated_title": "大型视觉语言模型零样本推理中的校准方法研究",
    "translated_abstract": "深度学习模型的校准对于保证其可靠性和安全使用是至关重要的，因此在监督分类模型中对其进行了广泛研究，提出了降低误校准的方法。然而，视觉语言模型在进行零样本推理时的校准尚未得到全面的研究，例如CLIP。本研究衡量了跨相关变量（如提示，数据集和架构）的校准情况，并发现CLIP的零样本推理存在误校准。此外，我们提出了一种修改版的温度缩放方法，与CLIP作为零样本推理模型的常见用例相一致，并展示出单个学习的温度值可以广泛适用于每个特定的CLIP模型（由选定的预训练数据集和架构定义），跨不同的推理数据集和提示选择。",
    "tldr": "本文研究了零样本推理中视觉语言模型的校准问题，发现CLIP存在误校准，并提出了一种修改版的温度缩放方法，可以适用于每个特定的CLIP模型。",
    "en_tdlr": "This paper studies the calibration issue of vision-language models in zero-shot inference, finds that CLIP is miscalibrated and proposes a modified version of temperature scaling that can generalize for each specific CLIP model."
}