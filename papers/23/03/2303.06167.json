{
    "title": "Overcoming Bias in Pretrained Models by Manipulating the Finetuning Dataset. (arXiv:2303.06167v1 [cs.CV])",
    "abstract": "Transfer learning is beneficial by allowing the expressive features of models pretrained on large-scale datasets to be finetuned for the target task of smaller, more domain-specific datasets. However, there is a concern that these pretrained models may come with their own biases which would propagate into the finetuned model. In this work, we investigate bias when conceptualized as both spurious correlations between the target task and a sensitive attribute as well as underrepresentation of a particular group in the dataset. Under both notions of bias, we find that (1) models finetuned on top of pretrained models can indeed inherit their biases, but (2) this bias can be corrected for through relatively minor interventions to the finetuning dataset, and often with a negligible impact to performance. Our findings imply that careful curation of the finetuning dataset is important for reducing biases on a downstream task, and doing so can even compensate for bias in the pretrained model.",
    "link": "http://arxiv.org/abs/2303.06167",
    "total_tokens": 1027,
    "translated_title": "通过操作微调数据集来克服预训练模型中的偏见",
    "translated_abstract": "转移学习通过允许在大规模数据集上预训练的模型的表达特征被微调到更小、更具领域特定性的数据集的目标任务中而受益。然而，有人担心这些预训练模型可能带有自己的偏见，这些偏见会传播到微调模型中。在这项工作中，我们研究了偏见，当偏见被概念化为目标任务和敏感属性之间的虚假相关性以及数据集中特定群体的代表性不足时。在偏见的两种概念下，我们发现(1)在预训练模型的基础上微调的模型确实可以继承它们的偏见，但(2)通过对微调数据集进行相对较小的干预，这种偏见可以得到纠正，而且对性能的影响往往可以忽略不计。我们的发现意味着，仔细策划微调数据集对于减少下游任务中的偏见非常重要，这样做甚至可以弥补预训练模型中的偏见。",
    "tldr": "本文研究了预训练模型中的偏见问题，发现微调模型可以继承预训练模型的偏见，但通过对微调数据集进行干预可以纠正这种偏见，而且对性能的影响很小。这表明仔细策划微调数据集对于减少下游任务中的偏见非常重要，这样做甚至可以弥补预训练模型中的偏见。",
    "en_tldr": "This paper investigates the bias problem in pretrained models and finds that finetuned models can inherit the biases of pretrained models, but these biases can be corrected by manipulating the finetuning dataset with little impact on performance. This implies that careful curation of the finetuning dataset is important for reducing biases on a downstream task, and doing so can even compensate for bias in the pretrained model."
}