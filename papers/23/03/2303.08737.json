{
    "title": "Evaluating gesture-generation in a large-scale open challenge: The GENEA Challenge 2022. (arXiv:2303.08737v1 [cs.HC])",
    "abstract": "This paper reports on the second GENEA Challenge to benchmark data-driven automatic co-speech gesture generation. Participating teams used the same speech and motion dataset to build gesture-generation systems. Motion generated by all these systems was rendered to video using a standardised visualisation pipeline and evaluated in several large, crowdsourced user studies. Unlike when comparing different research papers, differences in results are here only due to differences between methods, enabling direct comparison between systems. The dataset was based on 18 hours of full-body motion capture, including fingers, of different persons engaging in a dyadic conversation. Ten teams participated in the challenge across two tiers: full-body and upper-body gesticulation. For each tier, we evaluated both the human-likeness of the gesture motion and its appropriateness for the specific speech signal. Our evaluations decouple human-likeness from gesture appropriateness, which has been a difficu",
    "link": "http://arxiv.org/abs/2303.08737",
    "context": "Title: Evaluating gesture-generation in a large-scale open challenge: The GENEA Challenge 2022. (arXiv:2303.08737v1 [cs.HC])\nAbstract: This paper reports on the second GENEA Challenge to benchmark data-driven automatic co-speech gesture generation. Participating teams used the same speech and motion dataset to build gesture-generation systems. Motion generated by all these systems was rendered to video using a standardised visualisation pipeline and evaluated in several large, crowdsourced user studies. Unlike when comparing different research papers, differences in results are here only due to differences between methods, enabling direct comparison between systems. The dataset was based on 18 hours of full-body motion capture, including fingers, of different persons engaging in a dyadic conversation. Ten teams participated in the challenge across two tiers: full-body and upper-body gesticulation. For each tier, we evaluated both the human-likeness of the gesture motion and its appropriateness for the specific speech signal. Our evaluations decouple human-likeness from gesture appropriateness, which has been a difficu",
    "path": "papers/23/03/2303.08737.json",
    "total_tokens": 976,
    "translated_title": "在大规模开放挑战中评估手势生成：GENEA Challenge 2022的研究报告(arXiv:2303.08737v1 [cs.HC])",
    "translated_abstract": "本文报道了第二届GENEA Challenge，对基于数据驱动的自动共同语言手势生成进行了基准测试。参赛团队使用相同的语音和运动数据集构建手势生成系统。这些系统生成的动作使用标准化的可视化管道渲染为视频，并在几个大型众包用户研究中进行评估。与比较不同研究论文时不同的是，这里的结果差异仅由于方法之间的差异，从而实现了系统之间的直接比较。该数据集基于18小时的全身动作捕捉，包括手指，并记录了不同人物参与双人 对话。十个团队参加了分为全身和上半身肢体表达的两个层次的挑战。对于每个层次，我们评估了手势运动的人类相似度和其对特定语音信号的适用性。我们的评估将人类相似度与手势适用性解藕开，这一点一直是困难的。",
    "tldr": "本文介绍了GENEA Challenge 2022的研究结果，该比赛旨在基准测试基于数据驱动的自动共同语言手势生成。使用具有相同语音和动作的数据集，众多参赛团队的手势生成系统在几个大型用户研究中得到了评估，因此能够进行直接比较。",
    "en_tdlr": "This paper presents the results of the GENEA Challenge 2022, which aims to benchmark data-driven automatic co-speech gesture generation. Using the same speech and motion dataset, participating teams' gesture-generation systems were evaluated in several large user studies, allowing for direct comparison."
}