{
    "title": "Refined Vision-Language Modeling for Fine-grained Multi-modal Pre-training. (arXiv:2303.05313v2 [cs.CV] UPDATED)",
    "abstract": "Fine-grained supervision based on object annotations has been widely used for vision and language pre-training (VLP). However, in real-world application scenarios, aligned multi-modal data is usually in the image-caption format, which only provides coarse-grained supervision. It is not only cost-expensive but also compute-expensive to collect object annotations and build object annotation pre-extractor for different scenarios. In this paper, we propose a fine-grained VLP scheme without object annotations from the linguistic perspective. First, we propose a homonym sentence rewriting (HSR) algorithm to provide token-level supervision. The algorithm replaces a verb/noun/adjective/quantifier word of the caption with its homonyms from WordNet. Correspondingly, we propose refined vision-language modeling (RVLM) framework to exploit the token-level supervision. Three refined tasks, i.e., refined image-text contrastive (RITC), refined image-text matching (RITM), and replace language modeling ",
    "link": "http://arxiv.org/abs/2303.05313",
    "context": "Title: Refined Vision-Language Modeling for Fine-grained Multi-modal Pre-training. (arXiv:2303.05313v2 [cs.CV] UPDATED)\nAbstract: Fine-grained supervision based on object annotations has been widely used for vision and language pre-training (VLP). However, in real-world application scenarios, aligned multi-modal data is usually in the image-caption format, which only provides coarse-grained supervision. It is not only cost-expensive but also compute-expensive to collect object annotations and build object annotation pre-extractor for different scenarios. In this paper, we propose a fine-grained VLP scheme without object annotations from the linguistic perspective. First, we propose a homonym sentence rewriting (HSR) algorithm to provide token-level supervision. The algorithm replaces a verb/noun/adjective/quantifier word of the caption with its homonyms from WordNet. Correspondingly, we propose refined vision-language modeling (RVLM) framework to exploit the token-level supervision. Three refined tasks, i.e., refined image-text contrastive (RITC), refined image-text matching (RITM), and replace language modeling ",
    "path": "papers/23/03/2303.05313.json",
    "total_tokens": 980,
    "translated_title": "精细化多模态预训练的改进视觉语言建模方法",
    "translated_abstract": "基于对象注释的精细化监督在视觉和语言预训练中已被广泛使用，但在实际应用场景中，对齐的多模态数据通常以图像标题格式呈现，仅提供粗糙的监督。收集对象注释并为不同场景构建对象注释预提取器既昂贵又计算昂贵。本文从语言角度提出了一种无需对象注释的精细化VLP方案。我们首先提出了同义词句子重写算法HSR，提供了基于词元级别的监督。接着，我们提出了精细化视觉-语言建模（RVLM）框架，以利用词元级别的监督，设计了三个精细任务，即精细的图像-文本对比（RITC）、精细的图像-文本匹配（RITM）和替换语言建模（RLM）方法，以进一步增强精细化监督。实验证明，我们的方法在多个任务中达到了最先进的性能。",
    "tldr": "本文提出了一种无需对象注释的精细化VLP方案，提出了同义词句子重写算法，设计了三种精细任务以提高精细监督的效果，并在多个任务中取得了最先进的性能。",
    "en_tdlr": "This paper proposes a fine-grained VLP scheme without object annotations, which includes a homonym sentence rewriting algorithm and refined vision-language modeling framework with three refined tasks to enhance the fine-grained supervision. Experiments show that the proposed method achieves state-of-the-art performance in multiple tasks."
}