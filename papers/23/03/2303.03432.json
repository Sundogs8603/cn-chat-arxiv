{
    "title": "A polar prediction model for learning to represent visual transformations. (arXiv:2303.03432v2 [stat.ML] UPDATED)",
    "abstract": "All organisms make temporal predictions, and their evolutionary fitness level depends on the accuracy of these predictions. In the context of visual perception, the motions of both the observer and objects in the scene structure the dynamics of sensory signals, allowing for partial prediction of future signals based on past ones. Here, we propose a self-supervised representation-learning framework that extracts and exploits the regularities of natural videos to compute accurate predictions. We motivate the polar architecture by appealing to the Fourier shift theorem and its group-theoretic generalization, and we optimize its parameters on next-frame prediction. Through controlled experiments, we demonstrate that this approach can discover the representation of simple transformation groups acting in data. When trained on natural video datasets, our framework achieves better prediction performance than traditional motion compensation and rivals conventional deep networks, while maintaini",
    "link": "http://arxiv.org/abs/2303.03432",
    "context": "Title: A polar prediction model for learning to represent visual transformations. (arXiv:2303.03432v2 [stat.ML] UPDATED)\nAbstract: All organisms make temporal predictions, and their evolutionary fitness level depends on the accuracy of these predictions. In the context of visual perception, the motions of both the observer and objects in the scene structure the dynamics of sensory signals, allowing for partial prediction of future signals based on past ones. Here, we propose a self-supervised representation-learning framework that extracts and exploits the regularities of natural videos to compute accurate predictions. We motivate the polar architecture by appealing to the Fourier shift theorem and its group-theoretic generalization, and we optimize its parameters on next-frame prediction. Through controlled experiments, we demonstrate that this approach can discover the representation of simple transformation groups acting in data. When trained on natural video datasets, our framework achieves better prediction performance than traditional motion compensation and rivals conventional deep networks, while maintaini",
    "path": "papers/23/03/2303.03432.json",
    "total_tokens": 818,
    "translated_title": "一种用于学习表示视觉转换的极坐标预测模型",
    "translated_abstract": "所有生物都会做时间预测，并且它们的进化适应度取决于这些预测的准确性。在视觉感知的情境下，观察者和场景中物体的运动构成了感官信号的动态，使得可以基于过去的信号部分预测未来的信号。在这里，我们提出了一种自监督的表示学习框架，它提取和利用自然视频的规律来计算准确的预测。我们通过引用Fourier移位定理及其群论推广来展示了极坐标架构的动机，并通过对下一帧预测进行参数优化。通过对比实验证明，这种方法能够发现在数据中作用的简单变换群的表示。当在自然视频数据集上进行训练时，我们的框架实现了比传统的运动补偿更好的预测性能，并且与传统的深度网络不相上下，同时保持了...",
    "tldr": "一种新的自监督表示学习框架，利用自然视频的规律进行准确预测，并发现了在数据中的简单变换群的表示。",
    "en_tdlr": "A new self-supervised representation learning framework that uses the regularities of natural videos for accurate prediction and discovers the representation of simple transformation groups in the data."
}