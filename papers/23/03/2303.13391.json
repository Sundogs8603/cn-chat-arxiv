{
    "title": "Xplainer: From X-Ray Observations to Explainable Zero-Shot Diagnosis. (arXiv:2303.13391v1 [cs.CV])",
    "abstract": "Automated diagnosis prediction from medical images is a valuable resource to support clinical decision-making. However, such systems usually need to be trained on large amounts of annotated data, which often is scarce in the medical domain. Zero-shot methods address this challenge by allowing a flexible adaption to new settings with different clinical findings without relying on labeled data. Further, to integrate automated diagnosis in the clinical workflow, methods should be transparent and explainable, increasing medical professionals' trust and facilitating correctness verification. In this work, we introduce Xplainer, a novel framework for explainable zero-shot diagnosis in the clinical setting. Xplainer adapts the classification-by-description approach of contrastive vision-language models to the multi-label medical diagnosis task. Specifically, instead of directly predicting a diagnosis, we prompt the model to classify the existence of descriptive observations, which a radiologi",
    "link": "http://arxiv.org/abs/2303.13391",
    "context": "Title: Xplainer: From X-Ray Observations to Explainable Zero-Shot Diagnosis. (arXiv:2303.13391v1 [cs.CV])\nAbstract: Automated diagnosis prediction from medical images is a valuable resource to support clinical decision-making. However, such systems usually need to be trained on large amounts of annotated data, which often is scarce in the medical domain. Zero-shot methods address this challenge by allowing a flexible adaption to new settings with different clinical findings without relying on labeled data. Further, to integrate automated diagnosis in the clinical workflow, methods should be transparent and explainable, increasing medical professionals' trust and facilitating correctness verification. In this work, we introduce Xplainer, a novel framework for explainable zero-shot diagnosis in the clinical setting. Xplainer adapts the classification-by-description approach of contrastive vision-language models to the multi-label medical diagnosis task. Specifically, instead of directly predicting a diagnosis, we prompt the model to classify the existence of descriptive observations, which a radiologi",
    "path": "papers/23/03/2303.13391.json",
    "total_tokens": 885,
    "translated_title": "Xplainer：从X射线观察到可解释的零样本诊断",
    "translated_abstract": "通过医学图像进行自动诊断预测，是支持临床决策的宝贵资源。然而，这样的系统通常需要在大量注释数据上进行训练，而医学领域的注释数据往往很少。零样本方法通过允许在不依赖标记数据的情况下灵活适应具有不同临床结果的新设置来解决这一挑战。此外，为了将自动诊断集成到临床工作流程中，方法应该是透明且可解释的，增加医疗专业人员的信任并促进正确性验证。在这项工作中，我们引入了Xplainer，这是一个在临床设置中进行可解释的零样本诊断的新框架。Xplainer将对比视觉语言模型的分类即描述方法适应于多标签医学诊断任务。具体而言，我们提示模型对存在的描述性观察进行分类，而不是直接预测诊断。",
    "tldr": "Xplainer是一个透明且可解释的零样本诊断新框架，通过对存在的描述性观察进行分类来提高自动诊断集成到临床工作流程中的效率，同时避免需要大量注释数据的问题。",
    "en_tdlr": "Xplainer is a transparent and interpretable framework for zero-shot diagnosis, which improves the efficiency of integrating automated diagnosis into the clinical workflow by classifying existence of descriptive observations, and avoiding the problem of requiring large amounts of annotated data."
}