{
    "title": "A Tale of Two Circuits: Grokking as Competition of Sparse and Dense Subnetworks. (arXiv:2303.11873v1 [cs.LG])",
    "abstract": "Grokking is a phenomenon where a model trained on an algorithmic task first overfits but, then, after a large amount of additional training, undergoes a phase transition to generalize perfectly. We empirically study the internal structure of networks undergoing grokking on the sparse parity task, and find that the grokking phase transition corresponds to the emergence of a sparse subnetwork that dominates model predictions. On an optimization level, we find that this subnetwork arises when a small subset of neurons undergoes rapid norm growth, whereas the other neurons in the network decay slowly in norm. Thus, we suggest that the grokking phase transition can be understood to emerge from competition of two largely distinct subnetworks: a dense one that dominates before the transition and generalizes poorly, and a sparse one that dominates afterwards.",
    "link": "http://arxiv.org/abs/2303.11873",
    "context": "Title: A Tale of Two Circuits: Grokking as Competition of Sparse and Dense Subnetworks. (arXiv:2303.11873v1 [cs.LG])\nAbstract: Grokking is a phenomenon where a model trained on an algorithmic task first overfits but, then, after a large amount of additional training, undergoes a phase transition to generalize perfectly. We empirically study the internal structure of networks undergoing grokking on the sparse parity task, and find that the grokking phase transition corresponds to the emergence of a sparse subnetwork that dominates model predictions. On an optimization level, we find that this subnetwork arises when a small subset of neurons undergoes rapid norm growth, whereas the other neurons in the network decay slowly in norm. Thus, we suggest that the grokking phase transition can be understood to emerge from competition of two largely distinct subnetworks: a dense one that dominates before the transition and generalizes poorly, and a sparse one that dominates afterwards.",
    "path": "papers/23/03/2303.11873.json",
    "total_tokens": 890,
    "translated_title": "两个电路的故事：稀疏和密集子网络的竞争解析",
    "translated_abstract": "Grokking是指在算法任务上训练的模型首先出现过拟合，但是在大量额外的训练后，出现了完美的泛化的现象。我们在稀疏奇偶任务上经验地研究了正在经历Grokking的网络的内部结构，并发现Grokking的相变对应于支配模型预测的稀疏子网络的出现。在优化级别上，我们发现当少数神经元经历快速的各向同性增长时，这个子网络会出现，而网络中的其他神经元则缓慢地衰减。因此，我们建议Grokking的相变可以理解为两个大不相同的子网络之间的竞争：在转变之前支配的是密集子网络，但它泛化能力很差，在转变之后支配的是稀疏子网络。",
    "tldr": "本文研究了网络内部结构，发现Grokking现象对应于稀疏子网络的出现，该子网络在优化过程中由于少数神经元的快速各向同性增长而出现，从而与支配泛化能力差的密集子网络竞争。"
}