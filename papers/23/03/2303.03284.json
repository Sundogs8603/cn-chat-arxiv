{
    "title": "The Wasserstein Believer: Learning Belief Updates for Partially Observable Environments through Reliable Latent Space Models. (arXiv:2303.03284v2 [cs.LG] UPDATED)",
    "abstract": "Partially Observable Markov Decision Processes (POMDPs) are useful tools to model environments where the full state cannot be perceived by an agent. As such the agent needs to reason taking into account the past observations and actions. However, simply remembering the full history is generally intractable due to the exponential growth in the history space. Keeping a probability distribution that models the belief over what the true state is can be used as a sufficient statistic of the history, but its computation requires access to the model of the environment and is also intractable. State-of-the-art algorithms use Recurrent Neural Networks to compress the observation-action history aiming to learn a sufficient statistic, but they lack guarantees of success and can lead to sub-optimal policies. To overcome this, we propose the Wasserstein Belief Updater, an RL algorithm that learns a latent model of the POMDP and an approximation of the belief update. Our approach comes with theoreti",
    "link": "http://arxiv.org/abs/2303.03284",
    "context": "Title: The Wasserstein Believer: Learning Belief Updates for Partially Observable Environments through Reliable Latent Space Models. (arXiv:2303.03284v2 [cs.LG] UPDATED)\nAbstract: Partially Observable Markov Decision Processes (POMDPs) are useful tools to model environments where the full state cannot be perceived by an agent. As such the agent needs to reason taking into account the past observations and actions. However, simply remembering the full history is generally intractable due to the exponential growth in the history space. Keeping a probability distribution that models the belief over what the true state is can be used as a sufficient statistic of the history, but its computation requires access to the model of the environment and is also intractable. State-of-the-art algorithms use Recurrent Neural Networks to compress the observation-action history aiming to learn a sufficient statistic, but they lack guarantees of success and can lead to sub-optimal policies. To overcome this, we propose the Wasserstein Belief Updater, an RL algorithm that learns a latent model of the POMDP and an approximation of the belief update. Our approach comes with theoreti",
    "path": "papers/23/03/2303.03284.json",
    "total_tokens": 960,
    "translated_title": "\"Wasserstein Believer:通过可靠的潜在空间模型学习部分可观测环境下的信念更新\"",
    "translated_abstract": "部分可观测马尔可夫决策过程（POMDP）是建模代理无法感知到完整状态的环境的有用工具。因此，代理需要考虑过去的观察和行动进行推理。但是，由于历史空间指数级增长，仅仅记住完整历史通常是不可行的。保持模拟真实状态的置信概率分布可以作为历史的充分统计量，但其计算需要访问环境的模型，因此也是不可行的。最先进的算法使用递归神经网络来压缩观察-行动历史以学习充分的统计量，但它们缺乏成功的保证并可能导致次优策略。为了克服这一点，我们提出了Wasserstein Belief Updater ，这是一种RL算法，它学习POMDP​​的潜在模型和置信更新的近似值。我们的方法具有理论成果。",
    "tldr": "本论文提出了一种“Wasserstein Belief Updater”算法来学习部分可观测环境下的信念更新，该算法通过学习POMDP​​的潜在模型和置信更新的近似值，实现了对历史观察和行动的有效压缩，提升了算法的性能表现。",
    "en_tdlr": "This paper proposes a \"Wasserstein Belief Updater\" algorithm to learn belief updates in partially observable environments. The algorithm achieves effective compression of historical observations and actions through learning a latent model of POMDP and an approximation of the belief update, improving the performance of the algorithm."
}