{
    "title": "Information-Theoretic GAN Compression with Variational Energy-based Model. (arXiv:2303.16050v1 [cs.CV])",
    "abstract": "We propose an information-theoretic knowledge distillation approach for the compression of generative adversarial networks, which aims to maximize the mutual information between teacher and student networks via a variational optimization based on an energy-based model. Because the direct computation of the mutual information in continuous domains is intractable, our approach alternatively optimizes the student network by maximizing the variational lower bound of the mutual information. To achieve a tight lower bound, we introduce an energy-based model relying on a deep neural network to represent a flexible variational distribution that deals with high-dimensional images and consider spatial dependencies between pixels, effectively. Since the proposed method is a generic optimization algorithm, it can be conveniently incorporated into arbitrary generative adversarial networks and even dense prediction networks, e.g., image enhancement models. We demonstrate that the proposed algorithm ",
    "link": "http://arxiv.org/abs/2303.16050",
    "context": "Title: Information-Theoretic GAN Compression with Variational Energy-based Model. (arXiv:2303.16050v1 [cs.CV])\nAbstract: We propose an information-theoretic knowledge distillation approach for the compression of generative adversarial networks, which aims to maximize the mutual information between teacher and student networks via a variational optimization based on an energy-based model. Because the direct computation of the mutual information in continuous domains is intractable, our approach alternatively optimizes the student network by maximizing the variational lower bound of the mutual information. To achieve a tight lower bound, we introduce an energy-based model relying on a deep neural network to represent a flexible variational distribution that deals with high-dimensional images and consider spatial dependencies between pixels, effectively. Since the proposed method is a generic optimization algorithm, it can be conveniently incorporated into arbitrary generative adversarial networks and even dense prediction networks, e.g., image enhancement models. We demonstrate that the proposed algorithm ",
    "path": "papers/23/03/2303.16050.json",
    "total_tokens": 913,
    "translated_title": "基于变分能量模型的信息理论 GAN 压缩",
    "translated_abstract": "我们提出了一种基于信息理论知识蒸馏的生成对抗网络（GAN）压缩方法，旨在通过基于能量模型的变分优化，最大化教师和学生网络之间的互信息。由于在连续域中直接计算互信息是不可计算的，因此我们的方法通过最大化互信息的变分下限代替优化学生网络。为了实现紧密的下限，我们引入了一个基于能量的模型，依赖于一个深度神经网络来表示处理高维图像和像素间的空间依赖关系的灵活变分分布。由于这个方法是通用的优化算法，它可以方便地加入到任何生成对抗网络中，甚至是密集预测网络，例如图像增强模型。我们证明了所提出算法的有效性。",
    "tldr": "本论文提出了一种基于信息理论知识蒸馏的 GAN 压缩方法，它采用了基于能量模型的变分优化，最大化教师和学生网络之间的互信息下限，该方法是一种通用的优化算法，适用于任何 GAN 或密集预测网络，已在图像增强领域证明了其有效性。",
    "en_tdlr": "This paper proposes an information-theoretic GAN compression method that uses variational optimization based on an energy-based model to maximize the mutual information between teacher and student networks. The approach optimizes the student network by maximizing the variational lower bound of the mutual information, using a deep neural network to represent a flexible variational distribution. The proposed algorithm is generic and can be incorporated into arbitrary GAN or dense prediction networks, and has been shown to be effective in image enhancement."
}