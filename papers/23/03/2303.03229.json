{
    "title": "LongEval-Retrieval: French-English Dynamic Test Collection for Continuous Web Search Evaluation. (arXiv:2303.03229v2 [cs.IR] UPDATED)",
    "abstract": "LongEval-Retrieval is a Web document retrieval benchmark that focuses on continuous retrieval evaluation. This test collection is intended to be used to study the temporal persistence of Information Retrieval systems and will be used as the test collection in the Longitudinal Evaluation of Model Performance Track (LongEval) at CLEF 2023. This benchmark simulates an evolving information system environment - such as the one a Web search engine operates in - where the document collection, the query distribution, and relevance all move continuously, while following the Cranfield paradigm for offline evaluation. To do that, we introduce the concept of a dynamic test collection that is composed of successive sub-collections each representing the state of an information system at a given time step. In LongEval-Retrieval, each sub-collection contains a set of queries, documents, and soft relevance assessments built from click models. The data comes from Qwant, a privacy-preserving Web search e",
    "link": "http://arxiv.org/abs/2303.03229",
    "context": "Title: LongEval-Retrieval: French-English Dynamic Test Collection for Continuous Web Search Evaluation. (arXiv:2303.03229v2 [cs.IR] UPDATED)\nAbstract: LongEval-Retrieval is a Web document retrieval benchmark that focuses on continuous retrieval evaluation. This test collection is intended to be used to study the temporal persistence of Information Retrieval systems and will be used as the test collection in the Longitudinal Evaluation of Model Performance Track (LongEval) at CLEF 2023. This benchmark simulates an evolving information system environment - such as the one a Web search engine operates in - where the document collection, the query distribution, and relevance all move continuously, while following the Cranfield paradigm for offline evaluation. To do that, we introduce the concept of a dynamic test collection that is composed of successive sub-collections each representing the state of an information system at a given time step. In LongEval-Retrieval, each sub-collection contains a set of queries, documents, and soft relevance assessments built from click models. The data comes from Qwant, a privacy-preserving Web search e",
    "path": "papers/23/03/2303.03229.json",
    "total_tokens": 919,
    "translated_title": "LongEval-Retrieval: 面向持续Web搜索评估的法英动态测试集合",
    "translated_abstract": "LongEval-Retrieval是一个Web文档检索基准，专注于持续检索评估。该测试集合旨在用于研究信息检索系统的时间持久性，并将用作CLEF 2023的Longitudinal Evaluation of Model Performance Track (LongEval)的测试集合。该基准模拟了一个不断演变的信息系统环境，例如Web搜索引擎所处的环境，在遵循离线评估的Cranfield范例的同时，文档集合、查询分布和相关性都在不断移动。为此，我们引入了动态测试集合的概念，由连续的子集合组成，每个子集合表示信息系统在给定时间步骤的状态。在LongEval-Retrieval中，每个子集合包含一组查询、文档和基于点击模型构建的软关联性评估。这些数据来自Qwant，一个隐私保护的Web搜索引擎。",
    "tldr": "LongEval-Retrieval是一个面向持续Web搜索评估的动态测试集合，旨在研究信息检索系统的时间持久性。每个子集合包含一组查询、文档和基于点击模型构建的软关联性评估，数据来自Qwant，一个隐私保护的Web搜索引擎。",
    "en_tdlr": "LongEval-Retrieval is a dynamic test collection designed for continuous web search evaluation, aiming to study the temporal persistence of Information Retrieval systems. Each sub-collection contains a set of queries, documents, and soft relevance assessments built from click models, with the data coming from Qwant, a privacy-preserving web search engine."
}