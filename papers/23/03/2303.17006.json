{
    "title": "How do decoding algorithms distribute information in dialogue responses?. (arXiv:2303.17006v1 [cs.CL])",
    "abstract": "Humans tend to follow the Uniform Information Density (UID) principle by distributing information evenly in utterances. We study if decoding algorithms implicitly follow this UID principle, and under what conditions adherence to UID might be desirable for dialogue generation. We generate responses using different decoding algorithms with GPT-2 on the Persona-Chat dataset and collect human judgments on their quality using Amazon Mechanical Turk. We find that (i) surprisingly, model-generated responses follow the UID principle to a greater extent than human responses, and (ii) decoding algorithms that promote UID do not generate higher-quality responses. Instead, when we control for surprisal, non-uniformity of information density correlates with the quality of responses with very low/high surprisal. Our findings indicate that encouraging non-uniform responses is a potential solution to the ``likelihood trap'' problem (quality degradation in very high-likelihood text). Our dataset contai",
    "link": "http://arxiv.org/abs/2303.17006",
    "context": "Title: How do decoding algorithms distribute information in dialogue responses?. (arXiv:2303.17006v1 [cs.CL])\nAbstract: Humans tend to follow the Uniform Information Density (UID) principle by distributing information evenly in utterances. We study if decoding algorithms implicitly follow this UID principle, and under what conditions adherence to UID might be desirable for dialogue generation. We generate responses using different decoding algorithms with GPT-2 on the Persona-Chat dataset and collect human judgments on their quality using Amazon Mechanical Turk. We find that (i) surprisingly, model-generated responses follow the UID principle to a greater extent than human responses, and (ii) decoding algorithms that promote UID do not generate higher-quality responses. Instead, when we control for surprisal, non-uniformity of information density correlates with the quality of responses with very low/high surprisal. Our findings indicate that encouraging non-uniform responses is a potential solution to the ``likelihood trap'' problem (quality degradation in very high-likelihood text). Our dataset contai",
    "path": "papers/23/03/2303.17006.json",
    "total_tokens": 975,
    "translated_title": "解码算法在对话回应中如何分发信息？",
    "translated_abstract": "人类倾向于遵循均匀信息密度（UID）原则，在话语中均匀分配信息。我们研究了解码算法是否会隐式地遵循UID原则，并在什么条件下遵守UID可能对对话生成有益。我们使用不同的解码算法在Persona-Chat数据集上生成回应，并使用Amazon Mechanical Turk收集人类对它们质量的判断。我们发现（i）出乎意料的是，模型生成的回应比人的回应更加遵循UID原则，以及（ii）促进UID的解码算法并没有生成更高质量的回应。相反，当我们控制惊奇度时，信息密度的不均匀性与惊奇度非常低/高的回应的质量相关。我们的发现表明，鼓励非均匀回应是“可能性陷阱”问题（非常高可能性文本的质量下降）的潜在解决方案。我们的数据集包括了...",
    "tldr": "该论文研究了在对话生成中解码算法是否遵循均匀信息密度原则（将信息均匀分配在话语中）。研究发现模型生成的回应比人的回应更加遵循该原则，促进该原则的解码算法并没有提高回应质量。此外，作者还发现信息密度的不均匀性与惊奇度非常低/高的回应的质量相关，鼓励非均匀回应是“可能性陷阱”问题的潜在解决方案。",
    "en_tdlr": "This paper investigates whether decoding algorithms follow the Uniform Information Density principle in dialogue generation and finds that the model-generated responses adhere to this principle more than human responses, but promoting this principle does not enhance response quality. Encouraging non-uniform responses is found to be a potential solution to the \"likelihood trap\" problem."
}