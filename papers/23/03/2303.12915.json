{
    "title": "Self-distillation for surgical action recognition. (arXiv:2303.12915v1 [cs.CV])",
    "abstract": "Surgical scene understanding is a key prerequisite for contextaware decision support in the operating room. While deep learning-based approaches have already reached or even surpassed human performance in various fields, the task of surgical action recognition remains a major challenge. With this contribution, we are the first to investigate the concept of self-distillation as a means of addressing class imbalance and potential label ambiguity in surgical video analysis. Our proposed method is a heterogeneous ensemble of three models that use Swin Transfomers as backbone and the concepts of self-distillation and multi-task learning as core design choices. According to ablation studies performed with the CholecT45 challenge data via cross-validation, the biggest performance boost is achieved by the usage of soft labels obtained by self-distillation. External validation of our method on an independent test set was achieved by providing a Docker container of our inference model to the cha",
    "link": "http://arxiv.org/abs/2303.12915",
    "context": "Title: Self-distillation for surgical action recognition. (arXiv:2303.12915v1 [cs.CV])\nAbstract: Surgical scene understanding is a key prerequisite for contextaware decision support in the operating room. While deep learning-based approaches have already reached or even surpassed human performance in various fields, the task of surgical action recognition remains a major challenge. With this contribution, we are the first to investigate the concept of self-distillation as a means of addressing class imbalance and potential label ambiguity in surgical video analysis. Our proposed method is a heterogeneous ensemble of three models that use Swin Transfomers as backbone and the concepts of self-distillation and multi-task learning as core design choices. According to ablation studies performed with the CholecT45 challenge data via cross-validation, the biggest performance boost is achieved by the usage of soft labels obtained by self-distillation. External validation of our method on an independent test set was achieved by providing a Docker container of our inference model to the cha",
    "path": "papers/23/03/2303.12915.json",
    "total_tokens": 972,
    "translated_title": "自我蒸馏用于手术动作识别",
    "translated_abstract": "手术场景的理解是手术室中基于上下文的决策支持的关键前提。虽然基于深度学习的方法在各个领域已经达到甚至超过了人类的表现，但手术动作识别仍然是一个重大挑战。本文首次探讨了自我蒸馏的概念，作为应对手术视频分析中的类别不平衡和潜在标签歧义的方法。我们提出了一种异构集成方法，使用Swin Transfomers作为骨干网络，使用自我蒸馏和多任务学习的概念作为核心设计选择。通过交叉验证使用CholecT45挑战数据进行的削减研究表明，使用自我蒸馏获得的软标签是性能提升的最大因素。我们的方法在一个独立的测试集上进行的外部验证，通过提供我们推理模型的Docker容器来实现。",
    "tldr": "本文首次将自我蒸馏的概念引入到手术视频分析中，提出了一种异构集成方法，其使用Swine Transfomers作为骨干网络，并将自我蒸馏和多任务学习应用于模型设计中。在类别不平衡和潜在标签不明确的情况下，软标签通过自我蒸馏的方式获得是性能提升最大的因素。",
    "en_tdlr": "This paper proposes a novel approach of self-distillation for surgical action recognition, which is the first attempt to address class imbalance and label ambiguity in surgical video analysis using this concept. The proposed method is a heterogeneous ensemble of three models that use Swin Transformers as backbone and incorporates self-distillation and multi-task learning. The usage of soft labels obtained by self-distillation yields the biggest performance boost according to ablation studies, and external validation was achieved on an independent test set by providing a Docker container of our inference model to the challenge."
}