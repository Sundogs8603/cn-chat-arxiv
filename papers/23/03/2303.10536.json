{
    "title": "TempT: Temporal consistency for Test-time adaptation. (arXiv:2303.10536v1 [cs.CV])",
    "abstract": "In this technical report, we introduce TempT, a novel method for test time adaptation on videos by ensuring temporal coherence of predictions across sequential frames. TempT is a powerful tool with broad applications in computer vision tasks, including facial expression recognition (FER) in videos. We evaluate TempT's performance on the AffWild2 dataset as part of the Expression Classification Challenge at the 5th Workshop and Competition on Affective Behavior Analysis in the wild (ABAW). Our approach focuses solely on the unimodal visual aspect of the data and utilizes a popular 2D CNN backbone, in contrast to larger sequential or attention based models. Our experimental results demonstrate that TempT has competitive performance in comparison to previous years reported performances, and its efficacy provides a compelling proof of concept for its use in various real world applications.",
    "link": "http://arxiv.org/abs/2303.10536",
    "context": "Title: TempT: Temporal consistency for Test-time adaptation. (arXiv:2303.10536v1 [cs.CV])\nAbstract: In this technical report, we introduce TempT, a novel method for test time adaptation on videos by ensuring temporal coherence of predictions across sequential frames. TempT is a powerful tool with broad applications in computer vision tasks, including facial expression recognition (FER) in videos. We evaluate TempT's performance on the AffWild2 dataset as part of the Expression Classification Challenge at the 5th Workshop and Competition on Affective Behavior Analysis in the wild (ABAW). Our approach focuses solely on the unimodal visual aspect of the data and utilizes a popular 2D CNN backbone, in contrast to larger sequential or attention based models. Our experimental results demonstrate that TempT has competitive performance in comparison to previous years reported performances, and its efficacy provides a compelling proof of concept for its use in various real world applications.",
    "path": "papers/23/03/2303.10536.json",
    "total_tokens": 932,
    "translated_title": "TempT：测试时间自适应的时间一致性方法",
    "translated_abstract": "本技术报告介绍了TempT，一种新颖的方法，通过确保连续帧之间的预测具有时间上的一致性，实现对视频的测试时自适应。TempT是一种强大的工具，在计算机视觉任务中具有广泛应用，包括视频中的面部表情识别（FER）。我们将TempT在AffWild2数据集上作为情感行为分析比赛（ABAW）第五届研讨会和竞赛中的表情分类挑战的一部分进行了评估。我们的方法仅专注于数据的视觉单模态特征，并利用了流行的二维卷积神经网络骨干，而不是较大的序列或基于注意力的模型。我们的实验结果表明，TempT与往年报告的表现相比具有竞争力，其有效性为其在各种实际应用中的使用提供了令人信服的概念证明。",
    "tldr": "本文提出一种新颖的方法TempT，通过确保连续帧之间的预测具有时间上的一致性，实现了对视频的测试时自适应。其仅利用视觉单模态特征，并在面部表情识别等计算机视觉任务中具有广泛应用，并在实验中取得了有竞争力的表现，为其在各种实际应用中提供了令人信服的概念证明。",
    "en_tdlr": "This paper proposes a novel method, TempT, which ensures temporal coherence of predictions across sequential frames for test-time adaptation on videos. It focuses on the unimodal visual aspect of data and has broad applications in computer vision tasks such as facial expression recognition. Experimental results show competitive performance and provide compelling proof of concept for its use in various real-world applications."
}