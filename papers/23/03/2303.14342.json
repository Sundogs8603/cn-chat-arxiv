{
    "title": "An Analysis of GPT-3's Performance in Grammatical Error Correction. (arXiv:2303.14342v1 [cs.CL])",
    "abstract": "GPT-3 models are very powerful, achieving high performance on a variety of natural language processing tasks. However, there is a relative lack of detailed published analysis on how well they perform on the task of grammatical error correction (GEC). To address this, we perform experiments testing the capabilities of a GPT-3 model (text-davinci-003) against major GEC benchmarks, comparing the performance of several different prompts, including a comparison of zero-shot and few-shot settings. We analyze intriguing or problematic outputs encountered with different prompt formats. We report the performance of our best prompt on the BEA-2019 and JFLEG datasets using a combination of automatic metrics and human evaluations, revealing interesting differences between the preferences of human raters and the reference-based automatic metrics.",
    "link": "http://arxiv.org/abs/2303.14342",
    "context": "Title: An Analysis of GPT-3's Performance in Grammatical Error Correction. (arXiv:2303.14342v1 [cs.CL])\nAbstract: GPT-3 models are very powerful, achieving high performance on a variety of natural language processing tasks. However, there is a relative lack of detailed published analysis on how well they perform on the task of grammatical error correction (GEC). To address this, we perform experiments testing the capabilities of a GPT-3 model (text-davinci-003) against major GEC benchmarks, comparing the performance of several different prompts, including a comparison of zero-shot and few-shot settings. We analyze intriguing or problematic outputs encountered with different prompt formats. We report the performance of our best prompt on the BEA-2019 and JFLEG datasets using a combination of automatic metrics and human evaluations, revealing interesting differences between the preferences of human raters and the reference-based automatic metrics.",
    "path": "papers/23/03/2303.14342.json",
    "total_tokens": 756,
    "translated_title": "GPT-3在语法纠错上性能的分析",
    "translated_abstract": "GPT-3模型具有很高的自然语言处理能力，在各种任务上表现出色。然而，目前对它们在语法纠错(GEC)任务上的表现缺乏详细的分析。因此，我们对GPT-3模型（text-davinci-003版本）进行了实验，测试了几种不同的提示方式，包括零样本学习和少样本学习。我们分析了使用不同提示格式遇到的有趣或有问题的输出。我们使用自动评估和人类评价相结合的方法，报告了我们最佳提示在BEA-2019和JFLEG数据集上的表现，揭示了人类评分者与基于参考的自动度量之间的有趣差异。",
    "tldr": "本文分析了GPT-3模型在语法纠错任务上的表现，通过实验测试了几种不同的提示方式，揭示了人类评分者与基于参考的自动度量之间的差异。",
    "en_tdlr": "This paper analyzes the performance of GPT-3 model in grammatical error correction task. The authors conducted experiments testing several different prompts and revealed interesting differences between human raters and reference-based automatic metrics."
}