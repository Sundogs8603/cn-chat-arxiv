{
    "title": "Studying Limits of Explainability by Integrated Gradients for Gene Expression Models. (arXiv:2303.11336v1 [q-bio.GN])",
    "abstract": "Understanding the molecular processes that drive cellular life is a fundamental question in biological research. Ambitious programs have gathered a number of molecular datasets on large populations. To decipher the complex cellular interactions, recent work has turned to supervised machine learning methods. The scientific questions are formulated as classical learning problems on tabular data or on graphs, e.g. phenotype prediction from gene expression data. In these works, the input features on which the individual predictions are predominantly based are often interpreted as indicative of the cause of the phenotype, such as cancer identification. Here, we propose to explore the relevance of the biomarkers identified by Integrated Gradients, an explainability method for feature attribution in machine learning. Through a motivating example on The Cancer Genome Atlas, we show that ranking features by importance is not enough to robustly identify biomarkers. As it is difficult to evaluate",
    "link": "http://arxiv.org/abs/2303.11336",
    "context": "Title: Studying Limits of Explainability by Integrated Gradients for Gene Expression Models. (arXiv:2303.11336v1 [q-bio.GN])\nAbstract: Understanding the molecular processes that drive cellular life is a fundamental question in biological research. Ambitious programs have gathered a number of molecular datasets on large populations. To decipher the complex cellular interactions, recent work has turned to supervised machine learning methods. The scientific questions are formulated as classical learning problems on tabular data or on graphs, e.g. phenotype prediction from gene expression data. In these works, the input features on which the individual predictions are predominantly based are often interpreted as indicative of the cause of the phenotype, such as cancer identification. Here, we propose to explore the relevance of the biomarkers identified by Integrated Gradients, an explainability method for feature attribution in machine learning. Through a motivating example on The Cancer Genome Atlas, we show that ranking features by importance is not enough to robustly identify biomarkers. As it is difficult to evaluate",
    "path": "papers/23/03/2303.11336.json",
    "total_tokens": 971,
    "translated_title": "研究用于基因表达模型的 Integrated Gradients 的可解释性极限",
    "translated_abstract": "理解驱动细胞生命周期的分子过程是生物学研究中的一个基本问题。最近的工作采用了监督式机器学习方法以解密复杂的细胞相互作用，将科学问题公式化为标签数据或图形上的经典学习问题，例如来自基因表达数据的表型预测。在这些工作中，个体预测的输入特征经常被解释为表型成因的指示性标志，例如癌症识别。本文提出探讨 Integrated Gradients 在机器学习特征归属中所鉴别到的生物标志物的相关性。通过在癌症基因组图谱上的一个令人激动的案例，我们展示了仅通过特征影响值的排序并不能够可靠地识别生物标志物的重要性。在难以评估特征归属的正确性的情况下，我们提出了新的方法来评估可解释性的极限，即在给定方法的输出的情况下我们可以可靠地得出多少有关生物标志物相关性的结论。",
    "tldr": "本文研究了使用 Integrated Gradients 进行机器学习特征归属时的可解释性极限，证明仅通过特征影响值的排序无法可靠地识别生物标志物的重要性，还提出了新的评估方法以评估可靠性。",
    "en_tdlr": "This paper explores the limits of explainability when using Integrated Gradients for feature attribution in machine learning, demonstrating the inadequacy of ranking features by importance to identify biomarkers and proposing new methods to assess reliability."
}