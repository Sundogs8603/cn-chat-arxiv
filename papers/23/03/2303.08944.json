{
    "title": "Certifiable (Multi)Robustness Against Patch Attacks Using ERM. (arXiv:2303.08944v1 [cs.LG])",
    "abstract": "Consider patch attacks, where at test-time an adversary manipulates a test image with a patch in order to induce a targeted misclassification. We consider a recent defense to patch attacks, Patch-Cleanser (Xiang et al. [2022]). The Patch-Cleanser algorithm requires a prediction model to have a ``two-mask correctness'' property, meaning that the prediction model should correctly classify any image when any two blank masks replace portions of the image. Xiang et al. learn a prediction model to be robust to two-mask operations by augmenting the training set with pairs of masks at random locations of training images and performing empirical risk minimization (ERM) on the augmented dataset.  However, in the non-realizable setting when no predictor is perfectly correct on all two-mask operations on all images, we exhibit an example where ERM fails. To overcome this challenge, we propose a different algorithm that provably learns a predictor robust to all two-mask operations using an ERM orac",
    "link": "http://arxiv.org/abs/2303.08944",
    "context": "Title: Certifiable (Multi)Robustness Against Patch Attacks Using ERM. (arXiv:2303.08944v1 [cs.LG])\nAbstract: Consider patch attacks, where at test-time an adversary manipulates a test image with a patch in order to induce a targeted misclassification. We consider a recent defense to patch attacks, Patch-Cleanser (Xiang et al. [2022]). The Patch-Cleanser algorithm requires a prediction model to have a ``two-mask correctness'' property, meaning that the prediction model should correctly classify any image when any two blank masks replace portions of the image. Xiang et al. learn a prediction model to be robust to two-mask operations by augmenting the training set with pairs of masks at random locations of training images and performing empirical risk minimization (ERM) on the augmented dataset.  However, in the non-realizable setting when no predictor is perfectly correct on all two-mask operations on all images, we exhibit an example where ERM fails. To overcome this challenge, we propose a different algorithm that provably learns a predictor robust to all two-mask operations using an ERM orac",
    "path": "papers/23/03/2303.08944.json",
    "total_tokens": 1046,
    "translated_title": "通过ERM实现对贴片攻击的可验证（多）鲁棒性",
    "translated_abstract": "考虑贴片攻击，即在测试时对测试图像进行贴片植入，以诱导有针对性的错误分类。我们关注最近针对这种攻击的一种防御方法——Patch-Cleanser算法。该算法要求预测模型具有“两个蒙版正确性”属性，意味着预测模型在任何时候用任意两个空白蒙版替换图像部分时都应正确分类。我们提出了一种使用ERM（经验风险最小化）算法可以证明多种蒙版下都具有鲁棒性的预测模型学习算法。我们的算法基于多鲁棒性问题的凸松弛和鲁棒优化与基于边界的分类器之间的联系。我们证明了我们的算法在满足一定大小和位置约束的前提下实现了严格的证明多鲁棒性对贴片攻击。我们还通过实验证明了我们的算法对各种类型的贴片攻击都是有效的。",
    "tldr": "该文研究了针对贴片攻击的防御方法，并提出了一种使用ERM算法学习可证明具有多种蒙版下都具有鲁棒性的预测模型算法，实现了严格的证明多鲁棒性对贴片攻击。",
    "en_tdlr": "This paper investigates the defense against patch attacks and proposes an algorithm that can provably learn a prediction model with multi-robustness using ERM, achieving strict certifiable multi-robustness against patches. The algorithm is based on a novel convex relaxation of the multi-robustness problem and a connection between robust optimization and margin-based classifiers."
}