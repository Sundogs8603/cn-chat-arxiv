{
    "title": "CFA: Class-wise Calibrated Fair Adversarial Training. (arXiv:2303.14460v1 [cs.LG])",
    "abstract": "Adversarial training has been widely acknowledged as the most effective method to improve the adversarial robustness against adversarial examples for Deep Neural Networks (DNNs). So far, most existing works focus on enhancing the overall model robustness, treating each class equally in both the training and testing phases. Although revealing the disparity in robustness among classes, few works try to make adversarial training fair at the class level without sacrificing overall robustness. In this paper, we are the first to theoretically and empirically investigate the preference of different classes for adversarial configurations, including perturbation margin, regularization, and weight averaging. Motivated by this, we further propose a \\textbf{C}lass-wise calibrated \\textbf{F}air \\textbf{A}dversarial training framework, named CFA, which customizes specific training configurations for each class automatically. Experiments on benchmark datasets demonstrate that our proposed CFA can imp",
    "link": "http://arxiv.org/abs/2303.14460",
    "context": "Title: CFA: Class-wise Calibrated Fair Adversarial Training. (arXiv:2303.14460v1 [cs.LG])\nAbstract: Adversarial training has been widely acknowledged as the most effective method to improve the adversarial robustness against adversarial examples for Deep Neural Networks (DNNs). So far, most existing works focus on enhancing the overall model robustness, treating each class equally in both the training and testing phases. Although revealing the disparity in robustness among classes, few works try to make adversarial training fair at the class level without sacrificing overall robustness. In this paper, we are the first to theoretically and empirically investigate the preference of different classes for adversarial configurations, including perturbation margin, regularization, and weight averaging. Motivated by this, we further propose a \\textbf{C}lass-wise calibrated \\textbf{F}air \\textbf{A}dversarial training framework, named CFA, which customizes specific training configurations for each class automatically. Experiments on benchmark datasets demonstrate that our proposed CFA can imp",
    "path": "papers/23/03/2303.14460.json",
    "total_tokens": 930,
    "translated_title": "CFA: 类别间校准的公平对抗训练",
    "translated_abstract": "对抗训练已经被广泛认为是提高深度神经网络对抗性鲁棒性最有效的方法。迄今为止，大多数现有工作都集中在增强整个模型的鲁棒性上，在训练和测试阶段同等对待每个类别。虽然揭示了类别间鲁棒性的差异，但很少有工作在不牺牲总体鲁棒性的情况下，在类别级别上使对抗训练公平。本文是第一个在理论和经验上研究不同类别对对抗性配置喜好的，包括扰动幅度、正则化和权重平均值等。在此基础上，我们进一步提出了一个名为CFA的类别间校准的公平对抗训练框架，它可以自动定制每个类别的特定训练配置。对基准数据集上的实验表明，我们提出的CFA可以提高DNNs的对抗训练公平性，而不牺牲总体的对抗鲁棒性。",
    "tldr": "本文提出了CFA框架，针对每个类别自动定制特定的对抗训练配置，提高了DNN对抗训练的公平性，同时不影响总体的对抗鲁棒性。",
    "en_tdlr": "This paper proposes a CFA framework that customizes specific adversarial training configurations for each class, improving the fairness of DNNs' adversarial training without sacrificing overall adversarial robustness."
}