{
    "title": "Automatic Detection of Out-of-body Frames in Surgical Videos for Privacy Protection Using Self-supervised Learning and Minimal Labels. (arXiv:2303.18106v1 [cs.CV])",
    "abstract": "Endoscopic video recordings are widely used in minimally invasive robot-assisted surgery, but when the endoscope is outside the patient's body, it can capture irrelevant segments that may contain sensitive information. To address this, we propose a framework that accurately detects out-of-body frames in surgical videos by leveraging self-supervision with minimal data labels. We use a massive amount of unlabeled endoscopic images to learn meaningful representations in a self-supervised manner. Our approach, which involves pre-training on an auxiliary task and fine-tuning with limited supervision, outperforms previous methods for detecting out-of-body frames in surgical videos captured from da Vinci X and Xi surgical systems. The average F1 scores range from 96.00 to 98.02. Remarkably, using only 5% of the training labels, our approach still maintains an average F1 score performance above 97, outperforming fully-supervised methods with 95% fewer labels. These results demonstrate the pote",
    "link": "http://arxiv.org/abs/2303.18106",
    "context": "Title: Automatic Detection of Out-of-body Frames in Surgical Videos for Privacy Protection Using Self-supervised Learning and Minimal Labels. (arXiv:2303.18106v1 [cs.CV])\nAbstract: Endoscopic video recordings are widely used in minimally invasive robot-assisted surgery, but when the endoscope is outside the patient's body, it can capture irrelevant segments that may contain sensitive information. To address this, we propose a framework that accurately detects out-of-body frames in surgical videos by leveraging self-supervision with minimal data labels. We use a massive amount of unlabeled endoscopic images to learn meaningful representations in a self-supervised manner. Our approach, which involves pre-training on an auxiliary task and fine-tuning with limited supervision, outperforms previous methods for detecting out-of-body frames in surgical videos captured from da Vinci X and Xi surgical systems. The average F1 scores range from 96.00 to 98.02. Remarkably, using only 5% of the training labels, our approach still maintains an average F1 score performance above 97, outperforming fully-supervised methods with 95% fewer labels. These results demonstrate the pote",
    "path": "papers/23/03/2303.18106.json",
    "total_tokens": 968,
    "translated_title": "利用自监督学习和最少标签实现医疗视频中体外镜头的自动检测以保护隐私",
    "translated_abstract": "内窥镜视频记录广泛应用于微创机器人手术中，但当内镜在病人体外时，可能会捕获到包含敏感信息的无关片段。为了解决这个问题，我们提出了一个框架，利用自监督学习和最少的数据标签，准确检测医疗视频中的体外镜头。我们使用大量未标记的内窥镜图像以自监督方式学习有意义的特征表示。我们的方法需要进行辅助任务的预训练，然后在有限的监督下进行微调，优于以前的方法，在从 da Vinci X 和 Xi 手术系统拍摄的医疗视频中检测体外画面时，平均 F1 得分在 96.00 到 98.02 之间。有趣的是，仅使用 5% 的训练标签，我们的方法仍然保持平均 F1 得分在 97 以上，比全监督方法少用 95% 的标签表现更出色。这些结果证明了该方法的潜力。",
    "tldr": "该论文提出了一种利用自监督学习和少量标签实现医疗视频中体外镜头自动检测的方法，可以有效保护隐私，比以前的方法表现更好，甚至使用 95% 更少的标签时也表现出色。",
    "en_tdlr": "The paper proposes a method for automatically detecting out-of-body frames in surgical videos using self-supervised learning and minimal labels, to protect privacy. The approach outperforms previous methods and achieves high F1 scores even with only 5% of training labels, demonstrating its potential for practical use."
}