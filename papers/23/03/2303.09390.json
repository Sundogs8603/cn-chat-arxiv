{
    "title": "On the Interplay Between Misspecification and Sub-optimality Gap in Linear Contextual Bandits. (arXiv:2303.09390v1 [cs.LG])",
    "abstract": "We study linear contextual bandits in the misspecified setting, where the expected reward function can be approximated by a linear function class up to a bounded misspecification level $\\zeta>0$. We propose an algorithm based on a novel data selection scheme, which only selects the contextual vectors with large uncertainty for online regression. We show that, when the misspecification level $\\zeta$ is dominated by $\\tilde O (\\Delta / \\sqrt{d})$ with $\\Delta$ being the minimal sub-optimality gap and $d$ being the dimension of the contextual vectors, our algorithm enjoys the same gap-dependent regret bound $\\tilde O (d^2/\\Delta)$ as in the well-specified setting up to logarithmic factors. In addition, we show that an existing algorithm SupLinUCB (Chu et al., 2011) can also achieve a gap-dependent constant regret bound without the knowledge of sub-optimality gap $\\Delta$. Together with a lower bound adapted from Lattimore et al. (2020), our result suggests an interplay between misspecific",
    "link": "http://arxiv.org/abs/2303.09390",
    "context": "Title: On the Interplay Between Misspecification and Sub-optimality Gap in Linear Contextual Bandits. (arXiv:2303.09390v1 [cs.LG])\nAbstract: We study linear contextual bandits in the misspecified setting, where the expected reward function can be approximated by a linear function class up to a bounded misspecification level $\\zeta>0$. We propose an algorithm based on a novel data selection scheme, which only selects the contextual vectors with large uncertainty for online regression. We show that, when the misspecification level $\\zeta$ is dominated by $\\tilde O (\\Delta / \\sqrt{d})$ with $\\Delta$ being the minimal sub-optimality gap and $d$ being the dimension of the contextual vectors, our algorithm enjoys the same gap-dependent regret bound $\\tilde O (d^2/\\Delta)$ as in the well-specified setting up to logarithmic factors. In addition, we show that an existing algorithm SupLinUCB (Chu et al., 2011) can also achieve a gap-dependent constant regret bound without the knowledge of sub-optimality gap $\\Delta$. Together with a lower bound adapted from Lattimore et al. (2020), our result suggests an interplay between misspecific",
    "path": "papers/23/03/2303.09390.json",
    "total_tokens": 911,
    "translated_title": "关于线性情境赌博机中错误规定与次优间隙的相互作用研究",
    "translated_abstract": "本文研究了线性情境赌博机在错误规定的情境下，期望奖励函数可以以线性函数类来逼近的情况。我们提出了一种基于新的数据选择方案的算法，该算法仅选择具有大不确定性的情境向量进行在线回归。当误差规定水平被$\\zeta>0$控制时，我们的算法的误差上限与好的指定情况下的结果相同。我们证明了一个现有的算法也可以在不知道亚优间隙$\\Delta$的情况下实现间隙相关的常数误差上限。在Lattimore et al.（2020）的作品基础上，我们提供了一个下界，表明了错误规定和次优间隙之间的相互作用。",
    "tldr": "本文研究了线性情境赌博机在错误规定的情境下的算法问题，提出一种新算法，将在一定水平内误差和最小次优间隙相互制约，以常数误差上限实现间隙相关的度量。",
    "en_tdlr": "This paper studies the algorithmic problem of linear contextual bandits in misspecified settings. It proposes a novel algorithm that achieves a gap-dependent constant regret bound within a certain level of error specification and minimal sub-optimality gap. The paper also shows the interplay between misspecification and sub-optimality gap and provides a lower bound."
}