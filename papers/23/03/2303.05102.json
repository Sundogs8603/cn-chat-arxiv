{
    "title": "StyleDiff: Attribute Comparison Between Unlabeled Datasets in Latent Disentangled Space. (arXiv:2303.05102v2 [stat.ML] UPDATED)",
    "abstract": "One major challenge in machine learning applications is coping with mismatches between the datasets used in the development and those obtained in real-world applications. These mismatches may lead to inaccurate predictions and errors, resulting in poor product quality and unreliable systems. In this study, we propose StyleDiff to inform developers of the differences between the two datasets for the steady development of machine learning systems. Using disentangled image spaces obtained from recently proposed generative models, StyleDiff compares the two datasets by focusing on attributes in the images and provides an easy-to-understand analysis of the differences between the datasets. The proposed StyleDiff performs in $O (d N\\log N)$, where $N$ is the size of the datasets and $d$ is the number of attributes, enabling the application to large datasets. We demonstrate that StyleDiff accurately detects differences between datasets and presents them in an understandable format using, for ",
    "link": "http://arxiv.org/abs/2303.05102",
    "context": "Title: StyleDiff: Attribute Comparison Between Unlabeled Datasets in Latent Disentangled Space. (arXiv:2303.05102v2 [stat.ML] UPDATED)\nAbstract: One major challenge in machine learning applications is coping with mismatches between the datasets used in the development and those obtained in real-world applications. These mismatches may lead to inaccurate predictions and errors, resulting in poor product quality and unreliable systems. In this study, we propose StyleDiff to inform developers of the differences between the two datasets for the steady development of machine learning systems. Using disentangled image spaces obtained from recently proposed generative models, StyleDiff compares the two datasets by focusing on attributes in the images and provides an easy-to-understand analysis of the differences between the datasets. The proposed StyleDiff performs in $O (d N\\log N)$, where $N$ is the size of the datasets and $d$ is the number of attributes, enabling the application to large datasets. We demonstrate that StyleDiff accurately detects differences between datasets and presents them in an understandable format using, for ",
    "path": "papers/23/03/2303.05102.json",
    "total_tokens": 865,
    "translated_title": "StyleDiff: 在潜在解缠空间中比较未标记数据集的属性差异",
    "translated_abstract": "机器学习应用中的一个主要挑战是解决开发中使用的数据集与实际应用中获取的数据集之间的不匹配。这些不匹配可能导致预测不准确和错误，进而影响产品质量和系统的可靠性。本研究提出了StyleDiff，以便开发人员了解两个数据集之间的差异，以实现机器学习系统的稳定发展。使用最近提出的生成模型获得的解缠图像空间，StyleDiff通过关注图像中的属性来比较两个数据集，并提供易于理解的差异分析。所提出的StyleDiff的性能为$O(dN\\log N)$，其中$N$是数据集的大小，$d$是属性的数量，可以应用于大型数据集。我们证明StyleDiff能准确检测数据集之间的差异，并以易于理解的格式呈现。",
    "tldr": "StyleDiff是一种在潜在解缠空间中比较未标记数据集属性差异的方法，可以帮助开发人员了解两个数据集的差异，并以易于理解的方式提供分析。方法具有高效性能和准确性。",
    "en_tdlr": "StyleDiff is a method to compare attribute differences between unlabeled datasets in the latent disentangled space. It helps developers understand the differences between the two datasets and provides analysis in an understandable format. The method is characterized by efficient performance and accuracy."
}