{
    "title": "MindDiffuser: Controlled Image Reconstruction from Human Brain Activity with Semantic and Structural Diffusion. (arXiv:2308.04249v1 [cs.CV])",
    "abstract": "Reconstructing visual stimuli from brain recordings has been a meaningful and challenging task. Especially, the achievement of precise and controllable image reconstruction bears great significance in propelling the progress and utilization of brain-computer interfaces. Despite the advancements in complex image reconstruction techniques, the challenge persists in achieving a cohesive alignment of both semantic (concepts and objects) and structure (position, orientation, and size) with the image stimuli. To address the aforementioned issue, we propose a two-stage image reconstruction model called MindDiffuser. In Stage 1, the VQ-VAE latent representations and the CLIP text embeddings decoded from fMRI are put into Stable Diffusion, which yields a preliminary image that contains semantic information. In Stage 2, we utilize the CLIP visual feature decoded from fMRI as supervisory information, and continually adjust the two feature vectors decoded in Stage 1 through backpropagation to alig",
    "link": "http://arxiv.org/abs/2308.04249",
    "context": "Title: MindDiffuser: Controlled Image Reconstruction from Human Brain Activity with Semantic and Structural Diffusion. (arXiv:2308.04249v1 [cs.CV])\nAbstract: Reconstructing visual stimuli from brain recordings has been a meaningful and challenging task. Especially, the achievement of precise and controllable image reconstruction bears great significance in propelling the progress and utilization of brain-computer interfaces. Despite the advancements in complex image reconstruction techniques, the challenge persists in achieving a cohesive alignment of both semantic (concepts and objects) and structure (position, orientation, and size) with the image stimuli. To address the aforementioned issue, we propose a two-stage image reconstruction model called MindDiffuser. In Stage 1, the VQ-VAE latent representations and the CLIP text embeddings decoded from fMRI are put into Stable Diffusion, which yields a preliminary image that contains semantic information. In Stage 2, we utilize the CLIP visual feature decoded from fMRI as supervisory information, and continually adjust the two feature vectors decoded in Stage 1 through backpropagation to alig",
    "path": "papers/23/08/2308.04249.json",
    "total_tokens": 861,
    "translated_title": "MindDiffuser: 从人脑活动中控制图像重建的语义和结构扩散",
    "translated_abstract": "从脑电记录中重建视觉刺激是一个有意义且具有挑战性的任务。特别是在推动脑机接口的进展和利用方面，实现精确可控的图像重建具有重要意义。尽管复杂图像重建技术有了进展，但如何在图像刺激中实现语义（概念和对象）和结构（位置、方向和大小）的统一对齐仍然是一个挑战。为了解决这个问题，我们提出了一个名为MindDiffuser的两阶段图像重建模型。在第一阶段，将从fMRI解码得到的VQ-VAE潜在表示和CLIP文本嵌入传入稳定扩散，生成包含语义信息的初步图像。在第二阶段，利用从fMRI解码得到的CLIP视觉特征作为监督信息，通过反向传播不断调整第一阶段解码得到的两个特征向量，以实现对齐。",
    "tldr": "MindDiffuser是一个用于从人脑活动中重建图像的两阶段模型，通过结合语义和结构信息实现精确可控的图像重建。"
}