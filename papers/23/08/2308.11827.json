{
    "title": "Exploring the Effectiveness of GPT Models in Test-Taking: A Case Study of the Driver's License Knowledge Test. (arXiv:2308.11827v1 [cs.CL])",
    "abstract": "Large language models such as Open AI's Generative Pre-trained Transformer (GPT) models are proficient at answering questions, but their knowledge is confined to the information present in their training data. This limitation renders them ineffective when confronted with questions about recent developments or non-public documents. Our research proposes a method that enables GPT models to answer questions by employing context from an information source not previously included in their training data. The methodology includes preprocessing of contextual information, the embedding of contexts and queries, constructing prompt through the integration of context embeddings, and generating answers using GPT models. We applied this method in a controlled test scenario using the California Driver's Handbook as the information source. The GPT-3 model achieved a 96% passing score on a set of 50 sample driving knowledge test questions. In contrast, without context, the model's passing score fell to",
    "link": "http://arxiv.org/abs/2308.11827",
    "context": "Title: Exploring the Effectiveness of GPT Models in Test-Taking: A Case Study of the Driver's License Knowledge Test. (arXiv:2308.11827v1 [cs.CL])\nAbstract: Large language models such as Open AI's Generative Pre-trained Transformer (GPT) models are proficient at answering questions, but their knowledge is confined to the information present in their training data. This limitation renders them ineffective when confronted with questions about recent developments or non-public documents. Our research proposes a method that enables GPT models to answer questions by employing context from an information source not previously included in their training data. The methodology includes preprocessing of contextual information, the embedding of contexts and queries, constructing prompt through the integration of context embeddings, and generating answers using GPT models. We applied this method in a controlled test scenario using the California Driver's Handbook as the information source. The GPT-3 model achieved a 96% passing score on a set of 50 sample driving knowledge test questions. In contrast, without context, the model's passing score fell to",
    "path": "papers/23/08/2308.11827.json",
    "total_tokens": 899,
    "translated_title": "探索GPT模型在考试中的效果：驾驶执照知识测试案例研究",
    "translated_abstract": "大型语言模型，如Open AI的生成式预训练变压器（GPT）模型，擅长回答问题，但其知识仅限于其训练数据中的信息。这种限制使得当面临有关最新发展或非公开文件的问题时，它们变得无效。我们的研究提出了一种方法，通过使用之前未包含在其训练数据中的信息源的上下文来使GPT模型能够回答问题。该方法包括上下文信息的预处理、上下文和查询的嵌入、通过整合上下文嵌入构建提示以及使用GPT模型生成答案。我们将此方法应用于一个受控测试场景，使用加利福尼亚驾驶手册作为信息源。GPT-3模型在一套50道样本驾驶知识测试题上取得了96%的及格分数。相比之下，在没有上下文的情况下，模型的及格分数下降到了...",
    "tldr": "本研究提出了一种方法，通过使用新的信息源的上下文，让GPT模型能够回答考试题目。在使用加利福尼亚驾驶手册作为信息源的测试中，GPT-3模型取得了96%的及格分数。",
    "en_tdlr": "This research proposes a method that enables GPT models to answer test questions by using context from a new information source. In a test using the California Driver's Handbook, the GPT-3 model achieved a passing score of 96%."
}