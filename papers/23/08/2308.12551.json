{
    "title": "A Co-training Approach for Noisy Time Series Learning. (arXiv:2308.12551v1 [cs.LG])",
    "abstract": "In this work, we focus on robust time series representation learning. Our assumption is that real-world time series is noisy and complementary information from different views of the same time series plays an important role while analyzing noisy input. Based on this, we create two views for the input time series through two different encoders. We conduct co-training based contrastive learning iteratively to learn the encoders. Our experiments demonstrate that this co-training approach leads to a significant improvement in performance. Especially, by leveraging the complementary information from different views, our proposed TS-CoT method can mitigate the impact of data noise and corruption. Empirical evaluations on four time series benchmarks in unsupervised and semi-supervised settings reveal that TS-CoT outperforms existing methods. Furthermore, the representations learned by TS-CoT can transfer well to downstream tasks through fine-tuning.",
    "link": "http://arxiv.org/abs/2308.12551",
    "context": "Title: A Co-training Approach for Noisy Time Series Learning. (arXiv:2308.12551v1 [cs.LG])\nAbstract: In this work, we focus on robust time series representation learning. Our assumption is that real-world time series is noisy and complementary information from different views of the same time series plays an important role while analyzing noisy input. Based on this, we create two views for the input time series through two different encoders. We conduct co-training based contrastive learning iteratively to learn the encoders. Our experiments demonstrate that this co-training approach leads to a significant improvement in performance. Especially, by leveraging the complementary information from different views, our proposed TS-CoT method can mitigate the impact of data noise and corruption. Empirical evaluations on four time series benchmarks in unsupervised and semi-supervised settings reveal that TS-CoT outperforms existing methods. Furthermore, the representations learned by TS-CoT can transfer well to downstream tasks through fine-tuning.",
    "path": "papers/23/08/2308.12551.json",
    "total_tokens": 858,
    "translated_title": "一种用于嘈杂时间序列学习的协同训练方法",
    "translated_abstract": "本文致力于鲁棒的时间序列表示学习。我们的假设是现实世界的时间序列是嘈杂的，并且来自同一时间序列的不同观点的互补信息在分析嘈杂输入时发挥着重要作用。基于此，我们通过两个不同的编码器为输入时间序列创建了两个视图。我们通过协同训练基于对比学习的方式来迭代学习编码器。我们的实验表明，这种协同训练方法可以显著提高性能。特别是，通过利用来自不同视图的互补信息，我们提出的TS-CoT方法可以减轻数据噪声和损坏的影响。在无监督和半监督设置下对四个时间序列基准进行的实证评估表明，TS-CoT优于现有方法。此外，通过微调，TS-CoT学习到的表示可以很好地适用于下游任务。",
    "tldr": "本研究提出了一种用于嘈杂时间序列学习的协同训练方法，通过多视图学习来减轻数据噪声和损坏的影响，并在多个时间序列基准上超越现有方法。",
    "en_tdlr": "This paper presents a co-training approach for noisy time series learning, mitigating the impact of data noise and corruption through multi-view learning, and outperforming existing methods on multiple time series benchmarks."
}