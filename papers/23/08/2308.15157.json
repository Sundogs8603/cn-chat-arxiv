{
    "title": "On the improvement of model-predictive controllers. (arXiv:2308.15157v1 [cs.LG])",
    "abstract": "This article investigates synthetic model-predictive control (MPC) problems to demonstrate that an increased precision of the internal prediction model (PM) automatially entails an improvement of the controller as a whole. In contrast to reinforcement learning (RL), MPC uses the PM to predict subsequent states of the controlled system (CS), instead of directly recommending suitable actions. To assess how the precision of the PM translates into the quality of the model-predictive controller, we compare a DNN-based PM to the optimal baseline PM for three well-known control problems of varying complexity. The baseline PM achieves perfect accuracy by accessing the simulation of the CS itself. Based on the obtained results, we argue that an improvement of the PM will always improve the controller as a whole, without considering the impact of other components such as action selection (which, in this article, relies on evolutionary optimization).",
    "link": "http://arxiv.org/abs/2308.15157",
    "context": "Title: On the improvement of model-predictive controllers. (arXiv:2308.15157v1 [cs.LG])\nAbstract: This article investigates synthetic model-predictive control (MPC) problems to demonstrate that an increased precision of the internal prediction model (PM) automatially entails an improvement of the controller as a whole. In contrast to reinforcement learning (RL), MPC uses the PM to predict subsequent states of the controlled system (CS), instead of directly recommending suitable actions. To assess how the precision of the PM translates into the quality of the model-predictive controller, we compare a DNN-based PM to the optimal baseline PM for three well-known control problems of varying complexity. The baseline PM achieves perfect accuracy by accessing the simulation of the CS itself. Based on the obtained results, we argue that an improvement of the PM will always improve the controller as a whole, without considering the impact of other components such as action selection (which, in this article, relies on evolutionary optimization).",
    "path": "papers/23/08/2308.15157.json",
    "total_tokens": 820,
    "translated_title": "关于模型预测控制器的改进研究",
    "translated_abstract": "本文研究了合成模型预测控制(MPC)问题，以证明内部预测模型(PM)的精确性提高会自动改进整个控制器。与强化学习(RL)不同，MPC使用PM来预测受控系统(CS)的后续状态，而不是直接推荐合适的动作。为了评估PM的精确性对模型预测控制器质量的影响，我们将基于DNN的PM与三个复杂程度不同的著名控制问题的最佳基准PM进行比较。基准PM通过访问CS本身的模拟实现了完美的准确性。根据所得结果，我们认为提高PM将总体上改善控制器，而无需考虑其他组件（本文中基于进化优化的动作选择）的影响。",
    "tldr": "本文研究了模型预测控制器的改进问题，通过提高内部预测模型的精确性来自动改善整个控制器，结果表明提高预测模型总体上将改善控制器的质量。",
    "en_tdlr": "This article investigates the improvement of model-predictive controllers by increasing the precision of the internal prediction model, showing that enhancing the predictive model automatically enhances the overall performance of the controller."
}