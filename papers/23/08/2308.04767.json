{
    "title": "Induction Network: Audio-Visual Modality Gap-Bridging for Self-Supervised Sound Source Localization. (arXiv:2308.04767v1 [cs.CV])",
    "abstract": "Self-supervised sound source localization is usually challenged by the modality inconsistency. In recent studies, contrastive learning based strategies have shown promising to establish such a consistent correspondence between audio and sound sources in visual scenarios. Unfortunately, the insufficient attention to the heterogeneity influence in the different modality features still limits this scheme to be further improved, which also becomes the motivation of our work. In this study, an Induction Network is proposed to bridge the modality gap more effectively. By decoupling the gradients of visual and audio modalities, the discriminative visual representations of sound sources can be learned with the designed Induction Vector in a bootstrap manner, which also enables the audio modality to be aligned with the visual modality consistently. In addition to a visual weighted contrastive loss, an adaptive threshold selection strategy is introduced to enhance the robustness of the Induction",
    "link": "http://arxiv.org/abs/2308.04767",
    "context": "Title: Induction Network: Audio-Visual Modality Gap-Bridging for Self-Supervised Sound Source Localization. (arXiv:2308.04767v1 [cs.CV])\nAbstract: Self-supervised sound source localization is usually challenged by the modality inconsistency. In recent studies, contrastive learning based strategies have shown promising to establish such a consistent correspondence between audio and sound sources in visual scenarios. Unfortunately, the insufficient attention to the heterogeneity influence in the different modality features still limits this scheme to be further improved, which also becomes the motivation of our work. In this study, an Induction Network is proposed to bridge the modality gap more effectively. By decoupling the gradients of visual and audio modalities, the discriminative visual representations of sound sources can be learned with the designed Induction Vector in a bootstrap manner, which also enables the audio modality to be aligned with the visual modality consistently. In addition to a visual weighted contrastive loss, an adaptive threshold selection strategy is introduced to enhance the robustness of the Induction",
    "path": "papers/23/08/2308.04767.json",
    "total_tokens": 935,
    "translated_title": "Induction Network:自监督音源定位的视听模态差距补偿",
    "translated_abstract": "自监督音源定位通常受到模态不一致的挑战。在最近的研究中，基于对比学习的策略已经显示出在视觉场景中建立音频和声源之间一致对应的良好前景。然而，对于不同模态特征中的异质性影响，这个方案的关注度不足仍然限制了进一步的改进，这也成为我们工作的动机。在这项研究中，提出了一种Induction Network来更有效地弥合模态差距。通过解耦视觉和音频模态的梯度，可以以引导向量设计的自举方式学习声源的判别性视觉表示，这也使音频模态能够与视觉模态保持一致。除了视觉加权对比损失外，还引入了自适应阈值选择策略来增强引导能力的鲁棒性。",
    "tldr": "本研究提出了一种Induction Network来解决自监督音源定位中的视听模态差距问题。通过解耦梯度并引入自举学习，使声源的判别性视觉表示能够与音频模态保持一致。还引入了自适应阈值选择策略来增强其引导能力的鲁棒性。",
    "en_tdlr": "This study proposes an Induction Network to address the audio-visual modality gap in self-supervised sound source localization. By decoupling gradients and introducing bootstrap learning, discriminative visual representations of sound sources can be aligned with the audio modality consistently. An adaptive threshold selection strategy is also introduced to enhance the robustness of the induction capability."
}