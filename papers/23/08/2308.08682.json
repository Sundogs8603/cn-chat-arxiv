{
    "title": "Quantifying Overfitting: Introducing the Overfitting Index. (arXiv:2308.08682v1 [cs.LG])",
    "abstract": "In the rapidly evolving domain of machine learning, ensuring model generalizability remains a quintessential challenge. Overfitting, where a model exhibits superior performance on training data but falters on unseen data, is a recurrent concern. This paper introduces the Overfitting Index (OI), a novel metric devised to quantitatively assess a model's tendency to overfit. Through extensive experiments on the Breast Ultrasound Images Dataset (BUS) and the MNIST dataset using architectures such as MobileNet, U-Net, ResNet, Darknet, and ViT-32, we illustrate the utility and discernment of the OI. Our results underscore the variable overfitting behaviors across architectures and highlight the mitigative impact of data augmentation, especially on smaller and more specialized datasets. The ViT-32's performance on MNIST further emphasizes the robustness of certain models and the dataset's comprehensive nature. By providing an objective lens to gauge overfitting, the OI offers a promising aven",
    "link": "http://arxiv.org/abs/2308.08682",
    "context": "Title: Quantifying Overfitting: Introducing the Overfitting Index. (arXiv:2308.08682v1 [cs.LG])\nAbstract: In the rapidly evolving domain of machine learning, ensuring model generalizability remains a quintessential challenge. Overfitting, where a model exhibits superior performance on training data but falters on unseen data, is a recurrent concern. This paper introduces the Overfitting Index (OI), a novel metric devised to quantitatively assess a model's tendency to overfit. Through extensive experiments on the Breast Ultrasound Images Dataset (BUS) and the MNIST dataset using architectures such as MobileNet, U-Net, ResNet, Darknet, and ViT-32, we illustrate the utility and discernment of the OI. Our results underscore the variable overfitting behaviors across architectures and highlight the mitigative impact of data augmentation, especially on smaller and more specialized datasets. The ViT-32's performance on MNIST further emphasizes the robustness of certain models and the dataset's comprehensive nature. By providing an objective lens to gauge overfitting, the OI offers a promising aven",
    "path": "papers/23/08/2308.08682.json",
    "total_tokens": 1024,
    "translated_title": "量化过拟合: 引入过拟合指数",
    "translated_abstract": "在快速发展的机器学习领域，确保模型的泛化能力仍然是一个重要的挑战。过拟合是指模型在训练数据上表现良好但在未见数据上表现不佳的现象，一直是个不容忽视的问题。本文引入了过拟合指数（OI），这是一个新颖的度量方法，用于定量评估模型的过拟合倾向。通过对乳腺超声图像数据集（BUS）和MNIST数据集的广泛实验，使用了MobileNet、U-Net、ResNet、Darknet和ViT-32等架构，我们展示了OI的实用性和区分能力。我们的结果突出了不同架构之间的过拟合行为的变化，并强调了数据增强对较小和更专业的数据集的缓解影响。ViT-32在MNIST上的表现进一步强调了某些模型的鲁棒性和数据集的全面性。通过提供客观视角来评估过拟合，OI为解决过拟合问题提供了一种有希望的途径。",
    "tldr": "本文引入了过拟合指数（OI），通过对乳腺超声图像数据集和MNIST数据集进行广泛实验，使用了多种架构，展示了OI的实用性和区分能力。结果表明，不同架构的过拟合行为存在差异，并强调了数据增强对于较小和更专业的数据集的缓解影响。OI为解决过拟合问题提供了一种有希望的途径。",
    "en_tdlr": "This paper introduces the Overfitting Index (OI), a novel metric for quantitatively assessing a model's tendency to overfit. Through extensive experiments on different datasets and architectures, the OI demonstrates its utility and ability to differentiate overfitting behaviors. It emphasizes the mitigative impact of data augmentation on smaller and specialized datasets. The OI offers a promising approach to addressing overfitting."
}