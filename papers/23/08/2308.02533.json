{
    "title": "Improving Generalization of Adversarial Training via Robust Critical Fine-Tuning. (arXiv:2308.02533v1 [cs.LG])",
    "abstract": "Deep neural networks are susceptible to adversarial examples, posing a significant security risk in critical applications. Adversarial Training (AT) is a well-established technique to enhance adversarial robustness, but it often comes at the cost of decreased generalization ability. This paper proposes Robustness Critical Fine-Tuning (RiFT), a novel approach to enhance generalization without compromising adversarial robustness. The core idea of RiFT is to exploit the redundant capacity for robustness by fine-tuning the adversarially trained model on its non-robust-critical module. To do so, we introduce module robust criticality (MRC), a measure that evaluates the significance of a given module to model robustness under worst-case weight perturbations. Using this measure, we identify the module with the lowest MRC value as the non-robust-critical module and fine-tune its weights to obtain fine-tuned weights. Subsequently, we linearly interpolate between the adversarially trained weight",
    "link": "http://arxiv.org/abs/2308.02533",
    "context": "Title: Improving Generalization of Adversarial Training via Robust Critical Fine-Tuning. (arXiv:2308.02533v1 [cs.LG])\nAbstract: Deep neural networks are susceptible to adversarial examples, posing a significant security risk in critical applications. Adversarial Training (AT) is a well-established technique to enhance adversarial robustness, but it often comes at the cost of decreased generalization ability. This paper proposes Robustness Critical Fine-Tuning (RiFT), a novel approach to enhance generalization without compromising adversarial robustness. The core idea of RiFT is to exploit the redundant capacity for robustness by fine-tuning the adversarially trained model on its non-robust-critical module. To do so, we introduce module robust criticality (MRC), a measure that evaluates the significance of a given module to model robustness under worst-case weight perturbations. Using this measure, we identify the module with the lowest MRC value as the non-robust-critical module and fine-tune its weights to obtain fine-tuned weights. Subsequently, we linearly interpolate between the adversarially trained weight",
    "path": "papers/23/08/2308.02533.json",
    "total_tokens": 935,
    "translated_title": "通过强化关键鲁棒性微调来提高对抗训练的泛化能力",
    "translated_abstract": "深度神经网络容易受到对抗样本的攻击，这在关键应用中带来了重大的安全风险。对抗训练（AT）是提高对抗性鲁棒性的一种成熟技术，但往往会导致泛化能力的下降。本文提出了一种新颖的方法，即鲁棒性关键微调（RiFT），以提高泛化能力而不损害对抗性鲁棒性。RiFT的核心思想是通过在非关键鲁棒模块上微调经过对抗训练的模型，利用冗余容量来增强模型的鲁棒性。为此，我们引入了模块鲁棒关键性（MRC）指标，用于评估给定模块在最坏情况下权重扰动下对模型鲁棒性的重要性。利用这个指标，我们找到具有最低MRC值的模块作为非关键鲁棒模块，并微调其权重以获得微调后的权重。随后，我们在经过对抗训练的权重和微调后的权重之间进行线性插值。",
    "tldr": "本文提出了一种名为鲁棒性关键微调（RiFT）的方法，通过在非关键鲁棒模块上微调经过对抗训练的模型来提高泛化能力，而不损害对抗性鲁棒性。"
}