{
    "title": "An Empirical Study on Fairness Improvement with Multiple Protected Attributes. (arXiv:2308.01923v1 [cs.LG])",
    "abstract": "Existing research mostly improves the fairness of Machine Learning (ML) software regarding a single protected attribute at a time, but this is unrealistic given that many users have multiple protected attributes. This paper conducts an extensive study of fairness improvement regarding multiple protected attributes, covering 11 state-of-the-art fairness improvement methods. We analyze the effectiveness of these methods with different datasets, metrics, and ML models when considering multiple protected attributes. The results reveal that improving fairness for a single protected attribute can largely decrease fairness regarding unconsidered protected attributes. This decrease is observed in up to 88.3% of scenarios (57.5% on average). More surprisingly, we find little difference in accuracy loss when considering single and multiple protected attributes, indicating that accuracy can be maintained in the multiple-attribute paradigm. However, the effect on precision and recall when handling",
    "link": "http://arxiv.org/abs/2308.01923",
    "context": "Title: An Empirical Study on Fairness Improvement with Multiple Protected Attributes. (arXiv:2308.01923v1 [cs.LG])\nAbstract: Existing research mostly improves the fairness of Machine Learning (ML) software regarding a single protected attribute at a time, but this is unrealistic given that many users have multiple protected attributes. This paper conducts an extensive study of fairness improvement regarding multiple protected attributes, covering 11 state-of-the-art fairness improvement methods. We analyze the effectiveness of these methods with different datasets, metrics, and ML models when considering multiple protected attributes. The results reveal that improving fairness for a single protected attribute can largely decrease fairness regarding unconsidered protected attributes. This decrease is observed in up to 88.3% of scenarios (57.5% on average). More surprisingly, we find little difference in accuracy loss when considering single and multiple protected attributes, indicating that accuracy can be maintained in the multiple-attribute paradigm. However, the effect on precision and recall when handling",
    "path": "papers/23/08/2308.01923.json",
    "total_tokens": 819,
    "translated_title": "多重保护属性的公平性改善的实证研究",
    "translated_abstract": "现有研究主要关注单个保护属性的机器学习（ML）软件的公平性改善，但考虑到许多用户具有多个保护属性，这是不现实的。本文对多个保护属性的公平性改善进行了广泛研究，涵盖了11种最先进的公平性改善方法。我们分析了在考虑多个保护属性时，这些方法在不同数据集、评估指标和ML模型上的有效性。结果显示，改善单个保护属性的公平性大大降低了未考虑的保护属性的公平性。在88.3％的情况下观察到这种降低（平均为57.5％）。更令人惊讶的是，在考虑单个和多个保护属性时，准确率损失方面几乎没有差异，这表明在多属性模式下可以保持准确性。然而，在处理多个保护属性时，精确度和召回率的影响较大。",
    "tldr": "本文通过广泛研究，发现对于单个保护属性的公平性改善会大大降低对未考虑保护属性的公平性，但在多属性模式下可以保持准确性。"
}