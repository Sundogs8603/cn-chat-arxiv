{
    "title": "Probabilistic Dataset Reconstruction from Interpretable Models. (arXiv:2308.15099v1 [cs.AI])",
    "abstract": "Interpretability is often pointed out as a key requirement for trustworthy machine learning. However, learning and releasing models that are inherently interpretable leaks information regarding the underlying training data. As such disclosure may directly conflict with privacy, a precise quantification of the privacy impact of such breach is a fundamental problem. For instance, previous work have shown that the structure of a decision tree can be leveraged to build a probabilistic reconstruction of its training dataset, with the uncertainty of the reconstruction being a relevant metric for the information leak. In this paper, we propose of a novel framework generalizing these probabilistic reconstructions in the sense that it can handle other forms of interpretable models and more generic types of knowledge. In addition, we demonstrate that under realistic assumptions regarding the interpretable models' structure, the uncertainty of the reconstruction can be computed efficiently. Final",
    "link": "http://arxiv.org/abs/2308.15099",
    "context": "Title: Probabilistic Dataset Reconstruction from Interpretable Models. (arXiv:2308.15099v1 [cs.AI])\nAbstract: Interpretability is often pointed out as a key requirement for trustworthy machine learning. However, learning and releasing models that are inherently interpretable leaks information regarding the underlying training data. As such disclosure may directly conflict with privacy, a precise quantification of the privacy impact of such breach is a fundamental problem. For instance, previous work have shown that the structure of a decision tree can be leveraged to build a probabilistic reconstruction of its training dataset, with the uncertainty of the reconstruction being a relevant metric for the information leak. In this paper, we propose of a novel framework generalizing these probabilistic reconstructions in the sense that it can handle other forms of interpretable models and more generic types of knowledge. In addition, we demonstrate that under realistic assumptions regarding the interpretable models' structure, the uncertainty of the reconstruction can be computed efficiently. Final",
    "path": "papers/23/08/2308.15099.json",
    "total_tokens": 814,
    "translated_title": "从可解释模型中实现概率数据集重建",
    "translated_abstract": "可解释性经常被认为是可信赖机器学习的关键要求。然而，学习和发布本质上可解释的模型会泄露有关底层训练数据的信息。由于这种披露可能直接与隐私冲突，因此准确量化这种泄漏带来的隐私影响是一个基本问题。例如，以前的研究表明，可以利用决策树的结构构建其训练数据集的概率重建，重建的不确定性是信息泄漏的一个相关度量。在本文中，我们提出了一个新的框架，推广了这些概率重建，使其可以处理其他形式的可解释模型和更一般类型的知识。此外，我们证明在对可解释模型结构进行实际假设的情况下，可以高效地计算重建的不确定性。",
    "tldr": "本文提出了一个新的框架，实现了从可解释模型中概率重建数据集。在现实假设下，可以高效计算重建的不确定性，以量化信息泄漏的隐私影响。"
}