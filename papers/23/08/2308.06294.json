{
    "title": "Enhancing Phenotype Recognition in Clinical Notes Using Large Language Models: PhenoBCBERT and PhenoGPT. (arXiv:2308.06294v1 [q-bio.QM])",
    "abstract": "We hypothesize that large language models (LLMs) based on the transformer architecture can enable automated detection of clinical phenotype terms, including terms not documented in the HPO. In this study, we developed two types of models: PhenoBCBERT, a BERT-based model, utilizing Bio+Clinical BERT as its pre-trained model, and PhenoGPT, a GPT-based model that can be initialized from diverse GPT models, including open-source versions such as GPT-J, Falcon, and LLaMA, as well as closed-source versions such as GPT-3 and GPT-3.5. We compared our methods with PhenoTagger, a recently developed HPO recognition tool that combines rule-based and deep learning methods. We found that our methods can extract more phenotype concepts, including novel ones not characterized by HPO. We also performed case studies on biomedical literature to illustrate how new phenotype information can be recognized and extracted. We compared current BERT-based versus GPT-based models for phenotype tagging, in multipl",
    "link": "http://arxiv.org/abs/2308.06294",
    "context": "Title: Enhancing Phenotype Recognition in Clinical Notes Using Large Language Models: PhenoBCBERT and PhenoGPT. (arXiv:2308.06294v1 [q-bio.QM])\nAbstract: We hypothesize that large language models (LLMs) based on the transformer architecture can enable automated detection of clinical phenotype terms, including terms not documented in the HPO. In this study, we developed two types of models: PhenoBCBERT, a BERT-based model, utilizing Bio+Clinical BERT as its pre-trained model, and PhenoGPT, a GPT-based model that can be initialized from diverse GPT models, including open-source versions such as GPT-J, Falcon, and LLaMA, as well as closed-source versions such as GPT-3 and GPT-3.5. We compared our methods with PhenoTagger, a recently developed HPO recognition tool that combines rule-based and deep learning methods. We found that our methods can extract more phenotype concepts, including novel ones not characterized by HPO. We also performed case studies on biomedical literature to illustrate how new phenotype information can be recognized and extracted. We compared current BERT-based versus GPT-based models for phenotype tagging, in multipl",
    "path": "papers/23/08/2308.06294.json",
    "total_tokens": 993,
    "translated_title": "使用大型语言模型提升临床笔记中表型识别能力：PhenoBCBERT和PhenoGPT",
    "translated_abstract": "我们假设基于Transformer架构的大型语言模型（LLMs）可以实现对临床表型术语的自动检测，包括未在HPO中记录的术语。在本研究中，我们开发了两种模型：PhenoBCBERT，一种基于BERT的模型，利用Bio+Clinical BERT作为其预训练模型；以及PhenoGPT，一种基于GPT的模型，可以从不同的GPT模型（包括开源版本如GPT-J、Falcon和LLaMA，以及关闭源版本如GPT-3和GPT-3.5）进行初始化。我们将我们的方法与最近开发的结合了基于规则和深度学习方法的HPO识别工具PhenoTagger进行了比较。我们发现我们的方法可以提取更多的表型概念，包括HPO未描述的新概念。我们还对生物医学文献进行了案例研究，以说明如何识别和提取新的表型信息。我们比较了当前基于BERT和基于GPT的模型在多个表型标记任务上的表现。",
    "tldr": "本研究利用大型语言模型（LLMs）开发了两种表型识别模型PhenoBCBERT和PhenoGPT，相比于基于规则和深度学习的方法，这些模型能够更准确地识别临床表型术语，包括HPO未记录的新术语。",
    "en_tdlr": "In this study, two phenotype recognition models, PhenoBCBERT and PhenoGPT, based on large language models (LLMs), were developed. These models can accurately detect clinical phenotype terms, including novel ones not documented in the HPO, outperforming rule-based and deep learning methods."
}