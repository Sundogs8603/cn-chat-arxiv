{
    "title": "UPB at IberLEF-2023 AuTexTification: Detection of Machine-Generated Text using Transformer Ensembles. (arXiv:2308.01408v1 [cs.CL])",
    "abstract": "This paper describes the solutions submitted by the UPB team to the AuTexTification shared task, featured as part of IberLEF-2023. Our team participated in the first subtask, identifying text documents produced by large language models instead of humans. The organizers provided a bilingual dataset for this subtask, comprising English and Spanish texts covering multiple domains, such as legal texts, social media posts, and how-to articles. We experimented mostly with deep learning models based on Transformers, as well as training techniques such as multi-task learning and virtual adversarial training to obtain better results. We submitted three runs, two of which consisted of ensemble models. Our best-performing model achieved macro F1-scores of 66.63% on the English dataset and 67.10% on the Spanish dataset.",
    "link": "http://arxiv.org/abs/2308.01408",
    "context": "Title: UPB at IberLEF-2023 AuTexTification: Detection of Machine-Generated Text using Transformer Ensembles. (arXiv:2308.01408v1 [cs.CL])\nAbstract: This paper describes the solutions submitted by the UPB team to the AuTexTification shared task, featured as part of IberLEF-2023. Our team participated in the first subtask, identifying text documents produced by large language models instead of humans. The organizers provided a bilingual dataset for this subtask, comprising English and Spanish texts covering multiple domains, such as legal texts, social media posts, and how-to articles. We experimented mostly with deep learning models based on Transformers, as well as training techniques such as multi-task learning and virtual adversarial training to obtain better results. We submitted three runs, two of which consisted of ensemble models. Our best-performing model achieved macro F1-scores of 66.63% on the English dataset and 67.10% on the Spanish dataset.",
    "path": "papers/23/08/2308.01408.json",
    "total_tokens": 837,
    "translated_title": "UPB在IberLEF-2023 AuTexTification中使用Transformer集成检测机器生成的文本",
    "translated_abstract": "本文描述了UPB团队在IberLEF-2023的AuTexTification共享任务中提交的解决方案。我们参与了第一个子任务，即识别由大型语言模型而不是人类生成的文本文档。组织者为这个子任务提供了一个双语数据集，包括英文和西班牙文的文本，涵盖了法律文本、社交媒体帖子和操作指南等多个领域。我们主要使用基于Transformer的深度学习模型以及训练技巧（如多任务学习和虚拟对抗训练）进行实验，以获得更好的结果。我们提交了三个运行结果，其中两个是集成模型。我们最好的模型在英文数据集上获得了66.63%的宏F1分数，在西班牙文数据集上获得了67.10%的宏F1分数。",
    "tldr": "UPB团队在IberLEF-2023的AuTexTification共享任务中使用Transformer集成模型，通过识别由大型语言模型生成的文本，取得了较高的宏F1分数。 (translated_abstract)",
    "en_tdlr": "UPB team achieved high macro F1 scores in the AuTexTification shared task at IberLEF-2023 by using Transformer ensemble models to identify machine-generated text produced by large language models. (translated_abstract)"
}