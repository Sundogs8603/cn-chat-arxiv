{
    "title": "A Unifying Generator Loss Function for Generative Adversarial Networks",
    "abstract": "arXiv:2308.07233v2 Announce Type: replace  Abstract: A unifying $\\alpha$-parametrized generator loss function is introduced for a dual-objective generative adversarial network (GAN), which uses a canonical (or classical) discriminator loss function such as the one in the original GAN (VanillaGAN) system. The generator loss function is based on a symmetric class probability estimation type function, $\\mathcal{L}_\\alpha$, and the resulting GAN system is termed $\\mathcal{L}_\\alpha$-GAN. Under an optimal discriminator, it is shown that the generator's optimization problem consists of minimizing a Jensen-$f_\\alpha$-divergence, a natural generalization of the Jensen-Shannon divergence, where $f_\\alpha$ is a convex function expressed in terms of the loss function $\\mathcal{L}_\\alpha$. It is also demonstrated that this $\\mathcal{L}_\\alpha$-GAN problem recovers as special cases a number of GAN problems in the literature, including VanillaGAN, Least Squares GAN (LSGAN), Least $k$th order GAN (L$",
    "link": "https://arxiv.org/abs/2308.07233",
    "context": "Title: A Unifying Generator Loss Function for Generative Adversarial Networks\nAbstract: arXiv:2308.07233v2 Announce Type: replace  Abstract: A unifying $\\alpha$-parametrized generator loss function is introduced for a dual-objective generative adversarial network (GAN), which uses a canonical (or classical) discriminator loss function such as the one in the original GAN (VanillaGAN) system. The generator loss function is based on a symmetric class probability estimation type function, $\\mathcal{L}_\\alpha$, and the resulting GAN system is termed $\\mathcal{L}_\\alpha$-GAN. Under an optimal discriminator, it is shown that the generator's optimization problem consists of minimizing a Jensen-$f_\\alpha$-divergence, a natural generalization of the Jensen-Shannon divergence, where $f_\\alpha$ is a convex function expressed in terms of the loss function $\\mathcal{L}_\\alpha$. It is also demonstrated that this $\\mathcal{L}_\\alpha$-GAN problem recovers as special cases a number of GAN problems in the literature, including VanillaGAN, Least Squares GAN (LSGAN), Least $k$th order GAN (L$",
    "path": "papers/23/08/2308.07233.json",
    "total_tokens": 882,
    "translated_title": "生成对抗网络的统一生成器损失函数",
    "translated_abstract": "引入了一个统一的$\\alpha$参数化生成器损失函数，用于双目标生成对抗网络（GAN），该网络使用经典鉴别器损失函数，如原始GAN（VanillaGAN）系统中的损失函数。生成器损失函数基于对称类概率估计类型函数$\\mathcal{L}_\\alpha$，得到的GAN系统被称为$\\mathcal{L}_\\alpha$-GAN。在最佳鉴别器的情况下，表明生成器的优化问题包括最小化Jensen-$f_\\alpha$-散度，这是Jensen-Shannon散度的自然泛化，其中$f_\\alpha$是关于损失函数$\\mathcal{L}_\\alpha$的凸函数。还证明了这个$\\mathcal{L}_\\alpha$-GAN问题恢复了文献中一些GAN问题作为特殊情况，包括VanillaGAN、最小二乘GAN（LSGAN）、最小$k$阶GAN（L",
    "tldr": "引入了一个统一的生成器损失函数，称为$\\mathcal{L}_\\alpha$-GAN，通过最小化Jensen-$f_\\alpha$-散度来优化生成器，可以恢复出文献中的多个GAN问题。",
    "en_tdlr": "Introduced a unified generator loss function, named $\\mathcal{L}_\\alpha$-GAN, which optimizes the generator by minimizing Jensen-$f_\\alpha$ divergence, recovering various GAN problems in the literature as special cases."
}