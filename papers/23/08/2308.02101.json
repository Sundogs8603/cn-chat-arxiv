{
    "title": "Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network. (arXiv:2308.02101v1 [eess.IV])",
    "abstract": "Capturing global contextual information plays a critical role in breast ultrasound (BUS) image classification. Although convolutional neural networks (CNNs) have demonstrated reliable performance in tumor classification, they have inherent limitations for modeling global and long-range dependencies due to the localized nature of convolution operations. Vision Transformers have an improved capability of capturing global contextual information but may distort the local image patterns due to the tokenization operations. In this study, we proposed a hybrid multitask deep neural network called Hybrid-MT-ESTAN, designed to perform BUS tumor classification and segmentation using a hybrid architecture composed of CNNs and Swin Transformer components. The proposed approach was compared to nine BUS classification methods and evaluated using seven quantitative metrics on a dataset of 3,320 BUS images. The results indicate that Hybrid-MT-ESTAN achieved the highest accuracy, sensitivity, and F1 sco",
    "link": "http://arxiv.org/abs/2308.02101",
    "context": "Title: Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network. (arXiv:2308.02101v1 [eess.IV])\nAbstract: Capturing global contextual information plays a critical role in breast ultrasound (BUS) image classification. Although convolutional neural networks (CNNs) have demonstrated reliable performance in tumor classification, they have inherent limitations for modeling global and long-range dependencies due to the localized nature of convolution operations. Vision Transformers have an improved capability of capturing global contextual information but may distort the local image patterns due to the tokenization operations. In this study, we proposed a hybrid multitask deep neural network called Hybrid-MT-ESTAN, designed to perform BUS tumor classification and segmentation using a hybrid architecture composed of CNNs and Swin Transformer components. The proposed approach was compared to nine BUS classification methods and evaluated using seven quantitative metrics on a dataset of 3,320 BUS images. The results indicate that Hybrid-MT-ESTAN achieved the highest accuracy, sensitivity, and F1 sco",
    "path": "papers/23/08/2308.02101.json",
    "total_tokens": 899,
    "translated_title": "使用混合多任务CNN-Transformer网络进行乳腺超声肿瘤分类",
    "translated_abstract": "在乳腺超声（BUS）图像分类中，捕捉全局上下文信息起着至关重要的作用。尽管卷积神经网络（CNN）在肿瘤分类中表现出可靠的性能，但由于卷积操作的局部性质，它们在建模全局和长程依赖性方面存在固有的限制。视觉Transformer具有捕捉全局上下文信息的改进能力，但由于标记化操作可能会扭曲局部图像模式。在本研究中，我们提出了一种名为Hybrid-MT-ESTAN的混合多任务深度神经网络，用于使用由CNN和Swin Transformer组件组成的混合架构执行BUS肿瘤分类和分割。所提出的方法与九种BUS分类方法进行了比较，并使用3320个BUS图像的七个定量指标进行评估。结果表明，Hybrid-MT-ESTAN实现了最高的准确性，灵敏度和F1得分。",
    "tldr": "该论文提出了一种使用混合多任务CNN-Transformer网络进行乳腺超声肿瘤分类的方法。与传统的卷积神经网络相比，该方法能更好地捕捉全局上下文信息，并在实验中取得了最高的准确性、灵敏度和F1得分。"
}