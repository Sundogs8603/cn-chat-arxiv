{
    "title": "GameEval: Evaluating LLMs on Conversational Games. (arXiv:2308.10032v1 [cs.CL])",
    "abstract": "The rapid advancements in large language models (LLMs) have presented challenges in evaluating those models. Existing evaluation methods are either reference-based or preference based, which inevitably need human intervention or introduce test bias caused by evaluator models. In this paper, we propose GameEval, a novel approach to evaluating LLMs through goal-driven conversational games, overcoming the limitations of previous methods. GameEval treats LLMs as game players and assigns them distinct roles with specific goals achieved by launching conversations of various forms, including discussion, question answering, and voting. We design three unique games with cooperative or adversarial objectives, accompanied by corresponding evaluation metrics, to show how this new paradigm comprehensively evaluates model performance.Through extensive experiments, we show that GameEval can effectively differentiate the capabilities of various LLMs, providing a comprehensive assessment of their integ",
    "link": "http://arxiv.org/abs/2308.10032",
    "context": "Title: GameEval: Evaluating LLMs on Conversational Games. (arXiv:2308.10032v1 [cs.CL])\nAbstract: The rapid advancements in large language models (LLMs) have presented challenges in evaluating those models. Existing evaluation methods are either reference-based or preference based, which inevitably need human intervention or introduce test bias caused by evaluator models. In this paper, we propose GameEval, a novel approach to evaluating LLMs through goal-driven conversational games, overcoming the limitations of previous methods. GameEval treats LLMs as game players and assigns them distinct roles with specific goals achieved by launching conversations of various forms, including discussion, question answering, and voting. We design three unique games with cooperative or adversarial objectives, accompanied by corresponding evaluation metrics, to show how this new paradigm comprehensively evaluates model performance.Through extensive experiments, we show that GameEval can effectively differentiate the capabilities of various LLMs, providing a comprehensive assessment of their integ",
    "path": "papers/23/08/2308.10032.json",
    "total_tokens": 842,
    "translated_title": "GameEval: 在对话游戏上评估LLM",
    "translated_abstract": "大型语言模型（LLM）的快速发展使评估这些模型变得具有挑战性。现有的评估方法要么基于参考，要么基于偏好，这些方法不可避免地需要人为干预或引入由评估模型引起的测试偏差。在本文中，我们提出了GameEval，一种通过面向目标的对话游戏来评估LLM的新方法，克服了以前方法的局限性。GameEval将LLM视为游戏玩家，并为他们分配具有特定目标的不同角色，通过启动各种形式的对话（包括讨论、问答和投票）来实现这些目标。我们设计了三个具有合作或对抗目标的独特游戏，并附带相应的评估指标，以展示这种新范 Paradigm如何全面评估模型性能。通过大量的实验证明，GameEval可以有效区分各种LLM的能力，提供了对它们整体表现的全面评估。",
    "tldr": "GameEval是一种通过面向目标的对话游戏来评估LLM的新方法。通过设计具有合作或对抗目标的独特游戏，GameEval可以全面评估模型性能。"
}