{
    "title": "A large language model-assisted education tool to provide feedback on open-ended responses. (arXiv:2308.02439v1 [cs.CY])",
    "abstract": "Open-ended questions are a favored tool among instructors for assessing student understanding and encouraging critical exploration of course material. Providing feedback for such responses is a time-consuming task that can lead to overwhelmed instructors and decreased feedback quality. Many instructors resort to simpler question formats, like multiple-choice questions, which provide immediate feedback but at the expense of personalized and insightful comments. Here, we present a tool that uses large language models (LLMs), guided by instructor-defined criteria, to automate responses to open-ended questions. Our tool delivers rapid personalized feedback, enabling students to quickly test their knowledge and identify areas for improvement. We provide open-source reference implementations both as a web application and as a Jupyter Notebook widget that can be used with instructional coding or math notebooks. With instructor guidance, LLMs hold promise to enhance student learning outcomes a",
    "link": "http://arxiv.org/abs/2308.02439",
    "context": "Title: A large language model-assisted education tool to provide feedback on open-ended responses. (arXiv:2308.02439v1 [cs.CY])\nAbstract: Open-ended questions are a favored tool among instructors for assessing student understanding and encouraging critical exploration of course material. Providing feedback for such responses is a time-consuming task that can lead to overwhelmed instructors and decreased feedback quality. Many instructors resort to simpler question formats, like multiple-choice questions, which provide immediate feedback but at the expense of personalized and insightful comments. Here, we present a tool that uses large language models (LLMs), guided by instructor-defined criteria, to automate responses to open-ended questions. Our tool delivers rapid personalized feedback, enabling students to quickly test their knowledge and identify areas for improvement. We provide open-source reference implementations both as a web application and as a Jupyter Notebook widget that can be used with instructional coding or math notebooks. With instructor guidance, LLMs hold promise to enhance student learning outcomes a",
    "path": "papers/23/08/2308.02439.json",
    "total_tokens": 858,
    "translated_title": "一种利用大型语言模型辅助教学的教育工具，用于对开放性问题作出反馈",
    "translated_abstract": "开放性问题是教师评估学生理解和鼓励对课程材料进行批判性探索的常用工具。为这些回答提供反馈是一项耗时的任务，可能导致教师不堪重负，反馈质量下降。许多教师转而使用更简单的问题格式，如多项选择题，这种格式提供即时反馈，但无法提供个性化和深入的评论。在这里，我们提出了一种工具，利用大型语言模型（LLMs），根据教师定义的标准，自动回答开放性问题。我们的工具提供快速的个性化反馈，使学生能够快速测试他们的知识并找出需要改进的领域。我们提供了开源的参考实现，既可以作为Web应用程序，也可以作为与教学编码或数学笔记本一起使用的Jupyter Notebook小部件。在教师的指导下，LLMs有望提高学生的学习效果。",
    "tldr": "这个工具利用大型语言模型辅助教学，能够自动回答开放性问题并提供个性化的反馈，有助于提高学生的学习效果。"
}