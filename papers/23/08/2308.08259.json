{
    "title": "Graph Relation Aware Continual Learning. (arXiv:2308.08259v1 [cs.LG])",
    "abstract": "Continual graph learning (CGL) studies the problem of learning from an infinite stream of graph data, consolidating historical knowledge, and generalizing it to the future task. At once, only current graph data are available. Although some recent attempts have been made to handle this task, we still face two potential challenges: 1) most of existing works only manipulate on the intermediate graph embedding and ignore intrinsic properties of graphs. It is non-trivial to differentiate the transferred information across graphs. 2) recent attempts take a parameter-sharing policy to transfer knowledge across time steps or progressively expand new architecture given shifted graph distribution. Learning a single model could loss discriminative information for each graph task while the model expansion scheme suffers from high model complexity. In this paper, we point out that latent relations behind graph edges can be attributed as an invariant factor for the evolving graphs and the statistica",
    "link": "http://arxiv.org/abs/2308.08259",
    "context": "Title: Graph Relation Aware Continual Learning. (arXiv:2308.08259v1 [cs.LG])\nAbstract: Continual graph learning (CGL) studies the problem of learning from an infinite stream of graph data, consolidating historical knowledge, and generalizing it to the future task. At once, only current graph data are available. Although some recent attempts have been made to handle this task, we still face two potential challenges: 1) most of existing works only manipulate on the intermediate graph embedding and ignore intrinsic properties of graphs. It is non-trivial to differentiate the transferred information across graphs. 2) recent attempts take a parameter-sharing policy to transfer knowledge across time steps or progressively expand new architecture given shifted graph distribution. Learning a single model could loss discriminative information for each graph task while the model expansion scheme suffers from high model complexity. In this paper, we point out that latent relations behind graph edges can be attributed as an invariant factor for the evolving graphs and the statistica",
    "path": "papers/23/08/2308.08259.json",
    "total_tokens": 848,
    "translated_title": "图关系感知的连续学习",
    "translated_abstract": "连续图学习（CGL）研究了如何从无限的图数据流中学习， consolidainge和将历史知识推广到未来的任务。与此同时，只有当前的图数据可用。虽然最近有一些尝试来处理这个任务，但我们仍然面临两个潜在的挑战：1）大多数现有的作品只在中间图嵌入上操作，忽略了图的内在属性。跨图传输信息是非平凡的。2）最近的尝试采用参数共享策略，在时间步上传输知识，或者根据转移的图分布逐步扩展新的架构。学习单一模型可能会丢失每个图任务的有区别信息，而模型扩展方案则面临模型复杂度高的问题。在本文中，我们指出图边缘后面的潜在关系可以归因于发展中图的一个不变因素，并提出了一个新的模型来解决这个问题。",
    "tldr": "连续图学习中的两个挑战是如何处理图的内在属性以及如何在不增加模型复杂度的情况下传输跨图的信息。本文提出了一个新的模型来解决这个问题。",
    "en_tdlr": "The challenges in continual graph learning are how to handle intrinsic properties of graphs and how to transfer information across graphs without increasing model complexity. This paper proposes a new model to address these challenges."
}