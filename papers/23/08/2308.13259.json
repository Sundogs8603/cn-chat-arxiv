{
    "title": "Knowledge-Driven CoT: Exploring Faithful Reasoning in LLMs for Knowledge-intensive Question Answering. (arXiv:2308.13259v1 [cs.CL])",
    "abstract": "Equipped with Chain-of-Thought (CoT), Large language models (LLMs) have shown impressive reasoning ability in various downstream tasks. Even so, suffering from hallucinations and the inability to access external knowledge, LLMs often come with incorrect or unfaithful intermediate reasoning steps, especially in the context of answering knowledge-intensive tasks such as KBQA. To alleviate this issue, we propose a framework called Knowledge-Driven Chain-of-Thought (KD-CoT) to verify and modify reasoning traces in CoT via interaction with external knowledge, and thus overcome the hallucinations and error propagation. Concretely, we formulate the CoT rationale process of LLMs into a structured multi-round QA format. In each round, LLMs interact with a QA system that retrieves external knowledge and produce faithful reasoning traces based on retrieved precise answers. The structured CoT reasoning of LLMs is facilitated by our developed KBQA CoT collection, which serves as in-context learning",
    "link": "http://arxiv.org/abs/2308.13259",
    "context": "Title: Knowledge-Driven CoT: Exploring Faithful Reasoning in LLMs for Knowledge-intensive Question Answering. (arXiv:2308.13259v1 [cs.CL])\nAbstract: Equipped with Chain-of-Thought (CoT), Large language models (LLMs) have shown impressive reasoning ability in various downstream tasks. Even so, suffering from hallucinations and the inability to access external knowledge, LLMs often come with incorrect or unfaithful intermediate reasoning steps, especially in the context of answering knowledge-intensive tasks such as KBQA. To alleviate this issue, we propose a framework called Knowledge-Driven Chain-of-Thought (KD-CoT) to verify and modify reasoning traces in CoT via interaction with external knowledge, and thus overcome the hallucinations and error propagation. Concretely, we formulate the CoT rationale process of LLMs into a structured multi-round QA format. In each round, LLMs interact with a QA system that retrieves external knowledge and produce faithful reasoning traces based on retrieved precise answers. The structured CoT reasoning of LLMs is facilitated by our developed KBQA CoT collection, which serves as in-context learning",
    "path": "papers/23/08/2308.13259.json",
    "total_tokens": 938,
    "translated_title": "基于知识驱动的CoT：探索LLMs中对知识密集型问答进行忠实推理",
    "translated_abstract": "大型语言模型（LLMs）配备了思维链（CoT），在各种下游任务中展现出了令人印象深刻的推理能力。但是，由于幻觉和无法访问外部知识，LLMs在对知识密集型任务（如知识库问答）进行推理时常常会产生不正确或不忠实的中间推理步骤。为了缓解这个问题，我们提出了一个名为知识驱动的思维链（KD-CoT）的框架，通过与外部知识的交互来验证和修改CoT中的推理过程，从而克服幻觉和错误传播。具体地，我们将LLMs的CoT推理过程规范化为结构化的多轮问答格式。在每一轮中，LLMs与一个问答系统进行交互，该系统检索外部知识并基于检索到的准确答案产生忠实的推理过程。我们开发的KBQA CoT集合促进了LLMs的结构化CoT推理，它作为上下文学习的一部分。",
    "tldr": "本文提出了一个名为知识驱动的思维链（KD-CoT）的框架，用于验证和修改LLMs中的推理过程，通过与外部知识的交互来解决幻觉和错误传播的问题。",
    "en_tdlr": "This paper proposes a framework called Knowledge-Driven Chain-of-Thought (KD-CoT) to verify and modify reasoning traces in LLMs by interacting with external knowledge, aiming to address the issues of hallucinations and error propagation."
}