{
    "title": "StoryBench: A Multifaceted Benchmark for Continuous Story Visualization. (arXiv:2308.11606v1 [cs.CV])",
    "abstract": "Generating video stories from text prompts is a complex task. In addition to having high visual quality, videos need to realistically adhere to a sequence of text prompts whilst being consistent throughout the frames. Creating a benchmark for video generation requires data annotated over time, which contrasts with the single caption used often in video datasets. To fill this gap, we collect comprehensive human annotations on three existing datasets, and introduce StoryBench: a new, challenging multi-task benchmark to reliably evaluate forthcoming text-to-video models. Our benchmark includes three video generation tasks of increasing difficulty: action execution, where the next action must be generated starting from a conditioning video; story continuation, where a sequence of actions must be executed starting from a conditioning video; and story generation, where a video must be generated from only text prompts. We evaluate small yet strong text-to-video baselines, and show the benefit",
    "link": "http://arxiv.org/abs/2308.11606",
    "context": "Title: StoryBench: A Multifaceted Benchmark for Continuous Story Visualization. (arXiv:2308.11606v1 [cs.CV])\nAbstract: Generating video stories from text prompts is a complex task. In addition to having high visual quality, videos need to realistically adhere to a sequence of text prompts whilst being consistent throughout the frames. Creating a benchmark for video generation requires data annotated over time, which contrasts with the single caption used often in video datasets. To fill this gap, we collect comprehensive human annotations on three existing datasets, and introduce StoryBench: a new, challenging multi-task benchmark to reliably evaluate forthcoming text-to-video models. Our benchmark includes three video generation tasks of increasing difficulty: action execution, where the next action must be generated starting from a conditioning video; story continuation, where a sequence of actions must be executed starting from a conditioning video; and story generation, where a video must be generated from only text prompts. We evaluate small yet strong text-to-video baselines, and show the benefit",
    "path": "papers/23/08/2308.11606.json",
    "total_tokens": 881,
    "translated_title": "StoryBench: 一个多方面的连续故事可视化基准",
    "translated_abstract": "从文本提示生成视频故事是一项复杂的任务。除了具有高质量的视觉效果外，视频还需要在整个帧中保持与文本提示序列的一致。创建视频生成的基准需要在时间上对数据进行注释，这与视频数据集中经常使用的单个标题形成对比。为了填补这一空白，我们收集了三个现有数据集上的全面的人类注释，并推出了StoryBench：一个新的，具有挑战性的多任务基准，可可靠地评估即将发布的文本到视频模型。我们的基准包括三个难度逐渐增加的视频生成任务：动作执行，在从一个条件视频开始生成下一个动作；故事延续，在从一个条件视频开始执行一系列动作；故事生成，仅从文本提示中生成一个视频。我们评估了一些小而强大的文本到视频基线，并展示了它们的好处。",
    "tldr": "StoryBench是一个新的，具有挑战性的多任务基准，用于评估文本到视频模型。它包括动作执行，故事延续和故事生成三个难度逐渐增加的视频生成任务。我们提出了一些小而强大的文本到视频基线，并展示了它们的好处。"
}