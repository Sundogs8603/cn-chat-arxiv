{
    "title": "Causal Adversarial Perturbations for Individual Fairness and Robustness in Heterogeneous Data Spaces. (arXiv:2308.08938v1 [cs.LG])",
    "abstract": "As responsible AI gains importance in machine learning algorithms, properties such as fairness, adversarial robustness, and causality have received considerable attention in recent years. However, despite their individual significance, there remains a critical gap in simultaneously exploring and integrating these properties. In this paper, we propose a novel approach that examines the relationship between individual fairness, adversarial robustness, and structural causal models in heterogeneous data spaces, particularly when dealing with discrete sensitive attributes. We use causal structural models and sensitive attributes to create a fair metric and apply it to measure semantic similarity among individuals. By introducing a novel causal adversarial perturbation and applying adversarial training, we create a new regularizer that combines individual fairness, causality, and robustness in the classifier. Our method is evaluated on both real-world and synthetic datasets, demonstrating it",
    "link": "http://arxiv.org/abs/2308.08938",
    "context": "Title: Causal Adversarial Perturbations for Individual Fairness and Robustness in Heterogeneous Data Spaces. (arXiv:2308.08938v1 [cs.LG])\nAbstract: As responsible AI gains importance in machine learning algorithms, properties such as fairness, adversarial robustness, and causality have received considerable attention in recent years. However, despite their individual significance, there remains a critical gap in simultaneously exploring and integrating these properties. In this paper, we propose a novel approach that examines the relationship between individual fairness, adversarial robustness, and structural causal models in heterogeneous data spaces, particularly when dealing with discrete sensitive attributes. We use causal structural models and sensitive attributes to create a fair metric and apply it to measure semantic similarity among individuals. By introducing a novel causal adversarial perturbation and applying adversarial training, we create a new regularizer that combines individual fairness, causality, and robustness in the classifier. Our method is evaluated on both real-world and synthetic datasets, demonstrating it",
    "path": "papers/23/08/2308.08938.json",
    "total_tokens": 896,
    "translated_title": "在异构数据空间中实现个体公平性和鲁棒性的因果对抗扰动",
    "translated_abstract": "随着负责任的AI在机器学习算法中的重要性不断增加，公平性、对抗鲁棒性和因果性等属性近年来引起了广泛关注。然而，尽管它们各自具有重要意义，但同时探索和集成这些属性仍存在重大差距。在本文中，我们提出了一种新颖的方法，探讨了个体公平性、对抗鲁棒性和结构性因果模型之间的关系，特别是在处理离散敏感属性时。我们使用因果结构模型和敏感属性来创建公平度量，并将其应用于衡量个体之间的语义相似性。通过引入一种新颖的因果对抗扰动，并应用对抗训练，我们创建了一个将个体公平性、因果性和鲁棒性相结合的新的正则化器。我们的方法在实际和合成数据集上进行了评估，展示了其",
    "tldr": "本文提出了一种新颖的方法，通过在异构数据空间中引入因果对抗扰动并应用对抗训练，结合个体公平性、因果性和鲁棒性，以解决在处理离散敏感属性时的问题。实验证明了该方法的有效性。"
}