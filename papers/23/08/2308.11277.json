{
    "title": "CNN based Cuneiform Sign Detection Learned from Annotated 3D Renderings and Mapped Photographs with Illumination Augmentation. (arXiv:2308.11277v1 [cs.CV])",
    "abstract": "Motivated by the challenges of the Digital Ancient Near Eastern Studies (DANES) community, we develop digital tools for processing cuneiform script being a 3D script imprinted into clay tablets used for more than three millennia and at least eight major languages. It consists of thousands of characters that have changed over time and space. Photographs are the most common representations usable for machine learning, while ink drawings are prone to interpretation. Best suited 3D datasets that are becoming available. We created and used the HeiCuBeDa and MaiCuBeDa datasets, which consist of around 500 annotated tablets. For our novel OCR-like approach to mixed image data, we provide an additional mapping tool for transferring annotations between 3D renderings and photographs. Our sign localization uses a RepPoints detector to predict the locations of characters as bounding boxes. We use image data from GigaMesh's MSII (curvature, see https://gigamesh.eu) based rendering, Phong-shaded 3D ",
    "link": "http://arxiv.org/abs/2308.11277",
    "context": "Title: CNN based Cuneiform Sign Detection Learned from Annotated 3D Renderings and Mapped Photographs with Illumination Augmentation. (arXiv:2308.11277v1 [cs.CV])\nAbstract: Motivated by the challenges of the Digital Ancient Near Eastern Studies (DANES) community, we develop digital tools for processing cuneiform script being a 3D script imprinted into clay tablets used for more than three millennia and at least eight major languages. It consists of thousands of characters that have changed over time and space. Photographs are the most common representations usable for machine learning, while ink drawings are prone to interpretation. Best suited 3D datasets that are becoming available. We created and used the HeiCuBeDa and MaiCuBeDa datasets, which consist of around 500 annotated tablets. For our novel OCR-like approach to mixed image data, we provide an additional mapping tool for transferring annotations between 3D renderings and photographs. Our sign localization uses a RepPoints detector to predict the locations of characters as bounding boxes. We use image data from GigaMesh's MSII (curvature, see https://gigamesh.eu) based rendering, Phong-shaded 3D ",
    "path": "papers/23/08/2308.11277.json",
    "total_tokens": 1028,
    "translated_title": "基于CNN的基于注释的三维渲染和映射照片的楔形符号检测",
    "translated_abstract": "在Digital Ancient Near Eastern Studies (DANES)社区面临的挑战的推动下，我们开发了用于处理楔形文字的数字工具，这是一种印在粘土板上的三维脚本，已有三千多年历史和至少八种主要语言。它由数千个随时间和空间变化的字符组成。照片是最常用的用于机器学习的表示方式，而墨水绘画则容易被解释。我们创建并使用了HeiCuBeDa和MaiCuBeDa数据集，这些数据集包含约500个带有注释的平板。对于我们的新型类似OCR的混合图像数据方法，我们提供了一种额外的映射工具，用于在3D渲染和照片之间传递注释。我们使用RepPoints检测器来预测字符的位置，以边界框的形式进行符号定位。我们使用来自GigaMesh的MSII（曲率）基于渲染的图像数据，以及Phong着色的3D数据。",
    "tldr": "该论文描述了一个基于CNN的楔形符号检测方法，通过学习注释的三维渲染和映射照片，结合光照增强。研究团队创建了HeiCuBeDa和MaiCuBeDa数据集，并提供了映射工具以传递注释。符号定位方法使用RepPoints检测器来预测字符的位置。该方法可以应用于处理楔形文字的数字工具开发和研究。",
    "en_tdlr": "This paper presents a CNN based approach for cuneiform sign detection, utilizing annotated 3D renderings and mapped photographs with illumination augmentation. The study includes the creation of datasets and a mapping tool for transferring annotations. The sign localization is performed using a RepPoints detector. The proposed method has implications for the development and research of digital tools for processing cuneiform script."
}