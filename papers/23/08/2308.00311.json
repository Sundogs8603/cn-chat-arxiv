{
    "title": "Doubly Robust Instance-Reweighted Adversarial Training. (arXiv:2308.00311v1 [cs.LG])",
    "abstract": "Assigning importance weights to adversarial data has achieved great success in training adversarially robust networks under limited model capacity. However, existing instance-reweighted adversarial training (AT) methods heavily depend on heuristics and/or geometric interpretations to determine those importance weights, making these algorithms lack rigorous theoretical justification/guarantee. Moreover, recent research has shown that adversarial training suffers from a severe non-uniform robust performance across the training distribution, e.g., data points belonging to some classes can be much more vulnerable to adversarial attacks than others. To address both issues, in this paper, we propose a novel doubly-robust instance reweighted AT framework, which allows to obtain the importance weights via exploring distributionally robust optimization (DRO) techniques, and at the same time boosts the robustness on the most vulnerable examples. In particular, our importance weights are obtained",
    "link": "http://arxiv.org/abs/2308.00311",
    "context": "Title: Doubly Robust Instance-Reweighted Adversarial Training. (arXiv:2308.00311v1 [cs.LG])\nAbstract: Assigning importance weights to adversarial data has achieved great success in training adversarially robust networks under limited model capacity. However, existing instance-reweighted adversarial training (AT) methods heavily depend on heuristics and/or geometric interpretations to determine those importance weights, making these algorithms lack rigorous theoretical justification/guarantee. Moreover, recent research has shown that adversarial training suffers from a severe non-uniform robust performance across the training distribution, e.g., data points belonging to some classes can be much more vulnerable to adversarial attacks than others. To address both issues, in this paper, we propose a novel doubly-robust instance reweighted AT framework, which allows to obtain the importance weights via exploring distributionally robust optimization (DRO) techniques, and at the same time boosts the robustness on the most vulnerable examples. In particular, our importance weights are obtained",
    "path": "papers/23/08/2308.00311.json",
    "total_tokens": 818,
    "translated_title": "双重稳健的实例重新加权对抗训练",
    "translated_abstract": "在有限的模型容量下，为对抗性数据分配重要性权重在训练对抗性稳健网络方面取得了巨大成功。然而，现有的实例重新加权对抗训练方法严重依赖于启发式算法和/或几何解释来确定这些重要性权重，使得这些算法缺乏严格的理论解释/保证。此外，最近的研究表明，对抗训练在训练分布中的稳健性表现非均匀，例如，某些类别的数据点比其他类别更容易受到对抗性攻击。为了解决这两个问题，本文提出了一种新颖的双重稳健的实例重新加权对抗训练框架，通过探索分布鲁棒优化（DRO）技术来获得重要性权重，并在最脆弱的示例上提高稳健性。",
    "tldr": "本文提出了一种新颖的双重稳健的实例重新加权对抗训练框架，通过分布鲁棒优化（DRO）技术获得重要性权重，并在最脆弱的示例上提高稳健性。"
}