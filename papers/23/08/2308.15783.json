{
    "title": "Split Without a Leak: Reducing Privacy Leakage in Split Learning. (arXiv:2308.15783v1 [cs.CR])",
    "abstract": "The popularity of Deep Learning (DL) makes the privacy of sensitive data more imperative than ever. As a result, various privacy-preserving techniques have been implemented to preserve user data privacy in DL. Among various privacy-preserving techniques, collaborative learning techniques, such as Split Learning (SL) have been utilized to accelerate the learning and prediction process. Initially, SL was considered a promising approach to data privacy. However, subsequent research has demonstrated that SL is susceptible to many types of attacks and, therefore, it cannot serve as a privacy-preserving technique. Meanwhile, countermeasures using a combination of SL and encryption have also been introduced to achieve privacy-preserving deep learning. In this work, we propose a hybrid approach using SL and Homomorphic Encryption (HE). The idea behind it is that the client encrypts the activation map (the output of the split layer between the client and the server) before sending it to the ser",
    "link": "http://arxiv.org/abs/2308.15783",
    "context": "Title: Split Without a Leak: Reducing Privacy Leakage in Split Learning. (arXiv:2308.15783v1 [cs.CR])\nAbstract: The popularity of Deep Learning (DL) makes the privacy of sensitive data more imperative than ever. As a result, various privacy-preserving techniques have been implemented to preserve user data privacy in DL. Among various privacy-preserving techniques, collaborative learning techniques, such as Split Learning (SL) have been utilized to accelerate the learning and prediction process. Initially, SL was considered a promising approach to data privacy. However, subsequent research has demonstrated that SL is susceptible to many types of attacks and, therefore, it cannot serve as a privacy-preserving technique. Meanwhile, countermeasures using a combination of SL and encryption have also been introduced to achieve privacy-preserving deep learning. In this work, we propose a hybrid approach using SL and Homomorphic Encryption (HE). The idea behind it is that the client encrypts the activation map (the output of the split layer between the client and the server) before sending it to the ser",
    "path": "papers/23/08/2308.15783.json",
    "total_tokens": 903,
    "translated_title": "无泄露的Split：减少Split Learning中的隐私泄露",
    "translated_abstract": "深度学习的普及使得敏感数据的隐私比以往任何时候都更加重要。因此，各种保护隐私的技术已被应用于深度学习中以保护用户数据的隐私。在各种保护隐私的技术中，协作学习技术（如Split Learning）已被用于加速学习和预测过程。最初，Split Learning被认为是保护数据隐私的一种有希望的方法。然而，随后的研究表明，Split Learning容易受到多种攻击，因此不能作为保护隐私的技术。与此同时，也引入了使用Split Learning和同态加密的组合来实现保护隐私的深度学习的对策。在本文中，我们提出了一种使用Split Learning和同态加密的混合方法。其背后的思想是在将激活图（客户端和服务器之间的分割层的输出）发送给服务器之前，客户端对其进行加密。",
    "tldr": "本文介绍了一个使用Split Learning和同态加密的混合方法，用于保护隐私的深度学习。研究表明，Split Learning容易受到攻击，因此本文提出了一个新的解决方案来减少隐私泄露。",
    "en_tdlr": "This paper presents a hybrid approach using Split Learning and Homomorphic Encryption for privacy-preserving deep learning. The research shows that Split Learning is susceptible to attacks, so this paper proposes a new solution to reduce privacy leakage."
}