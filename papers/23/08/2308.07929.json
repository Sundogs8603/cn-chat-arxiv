{
    "title": "Fast Adaptation with Bradley-Terry Preference Models in Text-To-Image Classification and Generation. (arXiv:2308.07929v1 [cs.CV])",
    "abstract": "Recently, large multimodal models, such as CLIP and Stable Diffusion have experimented tremendous successes in both foundations and applications. However, as these models increase in parameter size and computational requirements, it becomes more challenging for users to personalize them for specific tasks or preferences. In this work, we address the problem of adapting the previous models towards sets of particular human preferences, aligning the retrieved or generated images with the preferences of the user. We leverage the Bradley-Terry preference model to develop a fast adaptation method that efficiently fine-tunes the original model, with few examples and with minimal computing resources. Extensive evidence of the capabilities of this framework is provided through experiments in different domains related to multimodal text and image understanding, including preference prediction as a reward model, and generation tasks.",
    "link": "http://arxiv.org/abs/2308.07929",
    "context": "Title: Fast Adaptation with Bradley-Terry Preference Models in Text-To-Image Classification and Generation. (arXiv:2308.07929v1 [cs.CV])\nAbstract: Recently, large multimodal models, such as CLIP and Stable Diffusion have experimented tremendous successes in both foundations and applications. However, as these models increase in parameter size and computational requirements, it becomes more challenging for users to personalize them for specific tasks or preferences. In this work, we address the problem of adapting the previous models towards sets of particular human preferences, aligning the retrieved or generated images with the preferences of the user. We leverage the Bradley-Terry preference model to develop a fast adaptation method that efficiently fine-tunes the original model, with few examples and with minimal computing resources. Extensive evidence of the capabilities of this framework is provided through experiments in different domains related to multimodal text and image understanding, including preference prediction as a reward model, and generation tasks.",
    "path": "papers/23/08/2308.07929.json",
    "total_tokens": 818,
    "translated_title": "在文本到图像分类和生成中，使用Bradley-Terry偏好模型进行快速自适应",
    "translated_abstract": "最近，大型多模态模型，如CLIP和Stable Diffusion在基础理论和应用方面取得了巨大成功。然而，随着这些模型的参数大小和计算要求增加，用户为特定任务或偏好个性化它们变得更具挑战性。在这项工作中，我们解决了将之前的模型适应到特定人类偏好集合的问题，将检索或生成的图像与用户的偏好对齐。我们利用Bradley-Terry偏好模型开发了一种快速自适应方法，通过很少的示例和最小的计算资源高效地微调原始模型。通过与多模态文本和图像理解相关的不同领域的实验证据，我们提供了这个框架的能力。",
    "tldr": "本研究提出了一种快速自适应方法，利用Bradley-Terry偏好模型，通过很少的示例和最小的计算资源高效地微调大型多模态模型，使其更符合用户的偏好，并在多个领域中展示了该方法的能力。"
}