{
    "title": "Benchmarking Robustness and Generalization in Multi-Agent Systems: A Case Study on Neural MMO. (arXiv:2308.15802v1 [cs.AI])",
    "abstract": "We present the results of the second Neural MMO challenge, hosted at IJCAI 2022, which received 1600+ submissions. This competition targets robustness and generalization in multi-agent systems: participants train teams of agents to complete a multi-task objective against opponents not seen during training. The competition combines relatively complex environment design with large numbers of agents in the environment. The top submissions demonstrate strong success on this task using mostly standard reinforcement learning (RL) methods combined with domain-specific engineering. We summarize the competition design and results and suggest that, as an academic community, competitions may be a powerful approach to solving hard problems and establishing a solid benchmark for algorithms. We will open-source our benchmark including the environment wrapper, baselines, a visualization tool, and selected policies for further research.",
    "link": "http://arxiv.org/abs/2308.15802",
    "context": "Title: Benchmarking Robustness and Generalization in Multi-Agent Systems: A Case Study on Neural MMO. (arXiv:2308.15802v1 [cs.AI])\nAbstract: We present the results of the second Neural MMO challenge, hosted at IJCAI 2022, which received 1600+ submissions. This competition targets robustness and generalization in multi-agent systems: participants train teams of agents to complete a multi-task objective against opponents not seen during training. The competition combines relatively complex environment design with large numbers of agents in the environment. The top submissions demonstrate strong success on this task using mostly standard reinforcement learning (RL) methods combined with domain-specific engineering. We summarize the competition design and results and suggest that, as an academic community, competitions may be a powerful approach to solving hard problems and establishing a solid benchmark for algorithms. We will open-source our benchmark including the environment wrapper, baselines, a visualization tool, and selected policies for further research.",
    "path": "papers/23/08/2308.15802.json",
    "total_tokens": 934,
    "translated_title": "在多代理系统中对鲁棒性和泛化性能进行基准测试: 以神经MMO为例的研究",
    "translated_abstract": "我们介绍了在IJCAI 2022举办的第二届神经MMO挑战赛的结果，共收到1600多个投稿。该比赛旨在测试多代理系统中的鲁棒性和泛化性能：参与者训练代理团队以完成在训练期间未见过的对手的多任务目标。比赛结合了相对复杂的环境设计与大量代理在环境中的运行。顶级投稿展示了使用主要基于强化学习（RL）方法和领域特定的工程相结合的方式，在这个任务上取得了很好的成绩。我们总结了比赛的设计和结果，并建议作为学术界，比赛可能是解决困难问题和建立算法稳健标准的一个强大方法。我们将开源我们的基准测试，包括环境封装器、基准源码、可视化工具和选定的策略，供进一步研究使用。",
    "tldr": "这篇论文介绍了第二届神经MMO挑战赛的研究结果，表明通过使用标准的强化学习方法和领域特定的工程技术，成功解决了多代理系统中的鲁棒性和泛化性能问题，并提出比赛作为解决困难问题和建立算法标准的有效方法。"
}