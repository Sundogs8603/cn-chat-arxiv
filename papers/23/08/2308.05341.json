{
    "title": "Classification of Human- and AI-Generated Texts: Investigating Features for ChatGPT. (arXiv:2308.05341v1 [cs.CL])",
    "abstract": "Recently, generative AIs like ChatGPT have become available to the wide public. These tools can for instance be used by students to generate essays or whole theses. But how does a teacher know whether a text is written by a student or an AI? In our work, we explore traditional and new features to (1) detect text generated by AI from scratch and (2) text rephrased by AI. Since we found that classification is more difficult when the AI has been instructed to create the text in a way that a human would not recognize that it was generated by an AI, we also investigate this more advanced case. For our experiments, we produced a new text corpus covering 10 school topics. Our best systems to classify basic and advanced human-generated/AI-generated texts have F1-scores of over 96%. Our best systems for classifying basic and advanced human-generated/AI-rephrased texts have F1-scores of more than 78%. The systems use a combination of perplexity, semantic, list lookup, error-based, readability, A",
    "link": "http://arxiv.org/abs/2308.05341",
    "context": "Title: Classification of Human- and AI-Generated Texts: Investigating Features for ChatGPT. (arXiv:2308.05341v1 [cs.CL])\nAbstract: Recently, generative AIs like ChatGPT have become available to the wide public. These tools can for instance be used by students to generate essays or whole theses. But how does a teacher know whether a text is written by a student or an AI? In our work, we explore traditional and new features to (1) detect text generated by AI from scratch and (2) text rephrased by AI. Since we found that classification is more difficult when the AI has been instructed to create the text in a way that a human would not recognize that it was generated by an AI, we also investigate this more advanced case. For our experiments, we produced a new text corpus covering 10 school topics. Our best systems to classify basic and advanced human-generated/AI-generated texts have F1-scores of over 96%. Our best systems for classifying basic and advanced human-generated/AI-rephrased texts have F1-scores of more than 78%. The systems use a combination of perplexity, semantic, list lookup, error-based, readability, A",
    "path": "papers/23/08/2308.05341.json",
    "total_tokens": 1035,
    "translated_title": "人工智能生成文本与人类生成文本的分类：探索ChatGPT的特征",
    "translated_abstract": "最近，像ChatGPT这样的生成型人工智能已经面向公众提供。这些工具可以被学生用来生成散文或整个论文。但是老师如何知道一篇文本是由学生还是由人工智能编写的？在我们的工作中，我们探索传统和新的特征来(1)检测由人工智能从头开始生成的文本和(2)由人工智能重新表达的文本。由于我们发现，当人工智能被指示以人类难以辨认的方式创建文本时，分类变得更加困难，我们还对这种更高级的情况进行了研究。为了进行实验，我们制作了涵盖10个学校话题的新文本语料库。我们最佳的基础和高级人工生成/人工智能生成文本分类系统的F1分数超过96%。我们最佳的对基础和高级人工生成/人工智能重新表达文本进行分类的系统的F1分数超过78%。",
    "tldr": "本研究探索了分类人工智能生成文本与人类生成文本的问题，并研究了在人工智能以难以被人类辨认的方式进行文本生成时的更高级情况。实验结果显示，我们的最佳系统在区分基础和高级人工生成/人工智能生成文本时的F1分数超过96%，在区分基础和高级人工生成/人工智能重新表达文本时的F1分数超过78%。",
    "en_tdlr": "This study investigates the classification of AI-generated text and human-generated text, exploring the more advanced case of AI text generation that is difficult for humans to recognize. The experiments show that our best systems achieve F1 scores of over 96% in distinguishing basic and advanced human-generated/AI-generated text, and over 78% in distinguishing basic and advanced human-generated/AI-rephrased text."
}