{
    "title": "How susceptible are LLMs to Logical Fallacies?. (arXiv:2308.09853v1 [cs.CL])",
    "abstract": "This paper investigates the rational thinking capability of Large Language Models (LLMs) in multi-round argumentative debates by exploring the impact of fallacious arguments on their logical reasoning performance. More specifically, we present Logic Competence Measurement Benchmark (LOGICOM), a diagnostic benchmark to assess the robustness of LLMs against logical fallacies. LOGICOM involves two agents: a persuader and a debater engaging in a multi-round debate on a controversial topic, where the persuader tries to convince the debater of the correctness of its claim. First, LOGICOM assesses the potential of LLMs to change their opinions through reasoning. Then, it evaluates the debater's performance in logical reasoning by contrasting the scenario where the persuader employs logical fallacies against one where logical reasoning is used. We use this benchmark to evaluate the performance of GPT-3.5 and GPT-4 using a dataset containing controversial topics, claims, and reasons supporting ",
    "link": "http://arxiv.org/abs/2308.09853",
    "context": "Title: How susceptible are LLMs to Logical Fallacies?. (arXiv:2308.09853v1 [cs.CL])\nAbstract: This paper investigates the rational thinking capability of Large Language Models (LLMs) in multi-round argumentative debates by exploring the impact of fallacious arguments on their logical reasoning performance. More specifically, we present Logic Competence Measurement Benchmark (LOGICOM), a diagnostic benchmark to assess the robustness of LLMs against logical fallacies. LOGICOM involves two agents: a persuader and a debater engaging in a multi-round debate on a controversial topic, where the persuader tries to convince the debater of the correctness of its claim. First, LOGICOM assesses the potential of LLMs to change their opinions through reasoning. Then, it evaluates the debater's performance in logical reasoning by contrasting the scenario where the persuader employs logical fallacies against one where logical reasoning is used. We use this benchmark to evaluate the performance of GPT-3.5 and GPT-4 using a dataset containing controversial topics, claims, and reasons supporting ",
    "path": "papers/23/08/2308.09853.json",
    "total_tokens": 940,
    "translated_title": "LLM对逻辑谬误的容易受到的程度有多大？",
    "translated_abstract": "本文通过探索谬误论证对大型语言模型（LLMs）在多轮辩论中的合理思考能力的影响，研究了LLMs对逻辑推理性能的鲁棒性。具体而言，我们提出了逻辑能力测量基准（LOGICOM），一种用于评估LLMs对逻辑谬误的鲁棒性的诊断基准。LOGICOM涉及两个角色：说服者和辩手，在一个有争议的话题上进行多轮辩论，说服者试图说服辩手其主张的正确性。首先，LOGICOM评估LLMs通过推理改变其观点的潜力。然后，通过对比说服者使用逻辑谬误和使用逻辑推理的情景，评估辩手在逻辑推理方面的表现。我们使用这个基准测试了GPT-3.5和GPT-4在包含有争议的话题、主张和支持理由的数据集上的表现。",
    "tldr": "本文研究了大型语言模型（LLMs）在多轮辩论中的合理思考能力，并通过逻辑能力测量基准（LOGICOM）评估了它们对逻辑谬误的鲁棒性。评估结果展示了GPT-3.5和GPT-4在包含有争议的数据集上的表现。",
    "en_tdlr": "This paper investigates the rational thinking capability of Large Language Models (LLMs) in multi-round argumentative debates and evaluates their robustness against logical fallacies using the Logic Competence Measurement Benchmark (LOGICOM). The evaluation shows the performance of GPT-3.5 and GPT-4 on a dataset containing controversial topics."
}