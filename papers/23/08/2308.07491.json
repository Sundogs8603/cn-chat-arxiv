{
    "title": "Adaptive Tracking of a Single-Rigid-Body Character in Various Environments. (arXiv:2308.07491v1 [cs.RO])",
    "abstract": "Since the introduction of DeepMimic [Peng et al. 2018], subsequent research has focused on expanding the repertoire of simulated motions across various scenarios. In this study, we propose an alternative approach for this goal, a deep reinforcement learning method based on the simulation of a single-rigid-body character. Using the centroidal dynamics model (CDM) to express the full-body character as a single rigid body (SRB) and training a policy to track a reference motion, we can obtain a policy that is capable of adapting to various unobserved environmental changes and controller transitions without requiring any additional learning. Due to the reduced dimension of state and action space, the learning process is sample-efficient. The final full-body motion is kinematically generated in a physically plausible way, based on the state of the simulated SRB character. The SRB simulation is formulated as a quadratic programming (QP) problem, and the policy outputs an action that allows th",
    "link": "http://arxiv.org/abs/2308.07491",
    "context": "Title: Adaptive Tracking of a Single-Rigid-Body Character in Various Environments. (arXiv:2308.07491v1 [cs.RO])\nAbstract: Since the introduction of DeepMimic [Peng et al. 2018], subsequent research has focused on expanding the repertoire of simulated motions across various scenarios. In this study, we propose an alternative approach for this goal, a deep reinforcement learning method based on the simulation of a single-rigid-body character. Using the centroidal dynamics model (CDM) to express the full-body character as a single rigid body (SRB) and training a policy to track a reference motion, we can obtain a policy that is capable of adapting to various unobserved environmental changes and controller transitions without requiring any additional learning. Due to the reduced dimension of state and action space, the learning process is sample-efficient. The final full-body motion is kinematically generated in a physically plausible way, based on the state of the simulated SRB character. The SRB simulation is formulated as a quadratic programming (QP) problem, and the policy outputs an action that allows th",
    "path": "papers/23/08/2308.07491.json",
    "total_tokens": 882,
    "translated_title": "在不同环境中对单刚体角色的自适应跟踪",
    "translated_abstract": "自从DeepMimic的引入以来，后续研究一直致力于在不同情景下扩展模拟动作的范畴。在本研究中，我们提出了一个替代方法，一种基于单刚体角色仿真的深度强化学习方法。利用质心动力学模型（CDM）将全身角色表示为单刚体（SRB），并训练一个跟踪参考动作的策略，我们可以得到一个能够适应各种未观测环境变化和控制器转换的策略，而不需要额外的学习。由于状态和动作空间的降维，学习过程具有高样本效率。最终的全身动作以物理合理的方式基于模拟SRB角色的状态进行运动生成。SRB仿真被制定为一个二次规划问题，策略输出一个动作，允许角色在不同环境中完成任务。",
    "tldr": "本研究提出了一种基于单刚体角色仿真的深度强化学习方法，通过训练一个能够自适应各种环境变化的策略，实现在不需要额外学习的情况下完成各种任务。"
}