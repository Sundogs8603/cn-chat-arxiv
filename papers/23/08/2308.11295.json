{
    "title": "Uncertainty Estimation of Transformers' Predictions via Topological Analysis of the Attention Matrices. (arXiv:2308.11295v1 [cs.LG])",
    "abstract": "Determining the degree of confidence of deep learning model in its prediction is an open problem in the field of natural language processing. Most of the classical methods for uncertainty estimation are quite weak for text classification models. We set the task of obtaining an uncertainty estimate for neural networks based on the Transformer architecture. A key feature of such mo-dels is the attention mechanism, which supports the information flow between the hidden representations of tokens in the neural network. We explore the formed relationships between internal representations using Topological Data Analysis methods and utilize them to predict model's confidence. In this paper, we propose a method for uncertainty estimation based on the topological properties of the attention mechanism and compare it with classical methods. As a result, the proposed algorithm surpasses the existing methods in quality and opens up a new area of application of the attention mechanism, but requires t",
    "link": "http://arxiv.org/abs/2308.11295",
    "context": "Title: Uncertainty Estimation of Transformers' Predictions via Topological Analysis of the Attention Matrices. (arXiv:2308.11295v1 [cs.LG])\nAbstract: Determining the degree of confidence of deep learning model in its prediction is an open problem in the field of natural language processing. Most of the classical methods for uncertainty estimation are quite weak for text classification models. We set the task of obtaining an uncertainty estimate for neural networks based on the Transformer architecture. A key feature of such mo-dels is the attention mechanism, which supports the information flow between the hidden representations of tokens in the neural network. We explore the formed relationships between internal representations using Topological Data Analysis methods and utilize them to predict model's confidence. In this paper, we propose a method for uncertainty estimation based on the topological properties of the attention mechanism and compare it with classical methods. As a result, the proposed algorithm surpasses the existing methods in quality and opens up a new area of application of the attention mechanism, but requires t",
    "path": "papers/23/08/2308.11295.json",
    "total_tokens": 814,
    "translated_title": "通过注意力矩阵的拓扑分析来估算Transformer模型预测的不确定性",
    "translated_abstract": "在自然语言处理领域，确定深度学习模型预测的置信度是一个开放的问题。传统的不确定性估计方法对于文本分类模型并不有效。我们提出了一种基于Transformer架构的神经网络的不确定性估计任务。这种模型的一个关键特点是注意力机制，它支持神经网络中的令牌之间的信息流。我们利用拓扑数据分析方法探索内部表示之间的关系，并利用它们来预测模型的置信度。本文提出了一种基于注意力机制的拓扑性质的不确定性估计方法，并与传统方法进行了比较。结果表明，该算法在质量上超过了现有的方法，并开辟了注意力机制的新应用领域，但需要...",
    "tldr": "本论文通过拓扑数据分析方法，提出一种基于注意力机制的拓扑性质的不确定性估计方法，用于Transformer模型的预测，超越传统方法，开辟了注意力机制的新应用领域。"
}