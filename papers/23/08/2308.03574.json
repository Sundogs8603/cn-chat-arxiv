{
    "title": "Generalized Early Stopping in Evolutionary Direct Policy Search. (arXiv:2308.03574v1 [stat.ML])",
    "abstract": "Lengthy evaluation times are common in many optimization problems such as direct policy search tasks, especially when they involve conducting evaluations in the physical world, e.g. in robotics applications. Often, when evaluating a solution over a fixed time period, it becomes clear that the objective value will not increase with additional computation time (for example, when a two-wheeled robot continuously spins on the spot). In such cases, it makes sense to stop the evaluation early to save computation time. However, most approaches to stop the evaluation are problem-specific and need to be specifically designed for the task at hand. Therefore, we propose an early stopping method for direct policy search. The proposed method only looks at the objective value at each time step and requires no problem-specific knowledge.  We test the introduced stopping criterion in five direct policy search environments drawn from games, robotics, and classic control domains, and show that it can sa",
    "link": "http://arxiv.org/abs/2308.03574",
    "context": "Title: Generalized Early Stopping in Evolutionary Direct Policy Search. (arXiv:2308.03574v1 [stat.ML])\nAbstract: Lengthy evaluation times are common in many optimization problems such as direct policy search tasks, especially when they involve conducting evaluations in the physical world, e.g. in robotics applications. Often, when evaluating a solution over a fixed time period, it becomes clear that the objective value will not increase with additional computation time (for example, when a two-wheeled robot continuously spins on the spot). In such cases, it makes sense to stop the evaluation early to save computation time. However, most approaches to stop the evaluation are problem-specific and need to be specifically designed for the task at hand. Therefore, we propose an early stopping method for direct policy search. The proposed method only looks at the objective value at each time step and requires no problem-specific knowledge.  We test the introduced stopping criterion in five direct policy search environments drawn from games, robotics, and classic control domains, and show that it can sa",
    "path": "papers/23/08/2308.03574.json",
    "total_tokens": 898,
    "translated_title": "演化直接策略搜索中的广义早停止方法",
    "translated_abstract": "在许多优化问题中，尤其是涉及在物理世界中进行评估的直接策略搜索任务中，评估时间通常较长。当在固定时间段内评估解决方案时，往往会明确无法通过增加计算时间来提高目标值（例如，当两轮机器人持续在原地旋转时）。在这种情况下，及早停止评估以节省计算时间是有意义的。然而，大多数评估停止方法都是问题特定的，并且需要专门为当前任务设计。因此，我们提出了一种直接策略搜索的早停止方法。该方法只查看每个时间步骤的目标值，不需要任何问题特定的知识。我们在五个来自游戏、机器人和经典控制领域的直接策略搜索环境中测试了引入的停止准则，并展示了其节省了计算时间的优势。",
    "tldr": "本文提出了一种适用于直接策略搜索的早停止方法，通过观察每个时间步骤的目标值来决定是否停止评估，而无需问题特定的知识。在测试中，该方法在游戏、机器人和经典控制领域中表现出节省计算时间的优势。"
}