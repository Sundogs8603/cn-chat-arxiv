{
    "title": "Explainable unsupervised multi-modal image registration using deep networks. (arXiv:2308.01994v1 [eess.IV])",
    "abstract": "Clinical decision making from magnetic resonance imaging (MRI) combines complementary information from multiple MRI sequences (defined as 'modalities'). MRI image registration aims to geometrically 'pair' diagnoses from different modalities, time points and slices. Both intra- and inter-modality MRI registration are essential components in clinical MRI settings. Further, an MRI image processing pipeline that can address both afine and non-rigid registration is critical, as both types of deformations may be occuring in real MRI data scenarios. Unlike image classification, explainability is not commonly addressed in image registration deep learning (DL) methods, as it is challenging to interpet model-data behaviours against transformation fields. To properly address this, we incorporate Grad-CAM-based explainability frameworks in each major component of our unsupervised multi-modal and multi-organ image registration DL methodology. We previously demonstrated that we were able to reach su",
    "link": "http://arxiv.org/abs/2308.01994",
    "context": "Title: Explainable unsupervised multi-modal image registration using deep networks. (arXiv:2308.01994v1 [eess.IV])\nAbstract: Clinical decision making from magnetic resonance imaging (MRI) combines complementary information from multiple MRI sequences (defined as 'modalities'). MRI image registration aims to geometrically 'pair' diagnoses from different modalities, time points and slices. Both intra- and inter-modality MRI registration are essential components in clinical MRI settings. Further, an MRI image processing pipeline that can address both afine and non-rigid registration is critical, as both types of deformations may be occuring in real MRI data scenarios. Unlike image classification, explainability is not commonly addressed in image registration deep learning (DL) methods, as it is challenging to interpet model-data behaviours against transformation fields. To properly address this, we incorporate Grad-CAM-based explainability frameworks in each major component of our unsupervised multi-modal and multi-organ image registration DL methodology. We previously demonstrated that we were able to reach su",
    "path": "papers/23/08/2308.01994.json",
    "total_tokens": 880,
    "translated_title": "使用深度网络的可解释无监督多模态图像配准",
    "translated_abstract": "磁共振成像(MRI)的临床决策结合了多个MRI序列(定义为\"模态\")中的互补信息。MRI图像配准旨在几何上\"配对\"来自不同模态、时间点和切片的诊断结果。在临床MRI设置中，既有内模态MRI配准，也有间模态MRI配准。此外，在能够处理仿射和非刚性配准的MRI图像处理流程中非常重要，因为在真实的MRI数据情况下可能发生这两种类型的变形。与图像分类不同，图像配准深度学习方法中很少涉及可解释性问题，因为很难对模型-数据行为与变换场进行解释。为了正确处理这个问题，我们在我们的无监督多模态和多器官图像配准深度学习方法的每个主要组件中都加入了基于Grad-CAM的可解释性框架。我们先前证明了我们能够达到-",
    "tldr": "这个论文描述了一个使用深度网络进行可解释的无监督多模态图像配准的方法，结合了Grad-CAM-based的可解释性框架，能够处理仿射和非刚性配准，并在临床MRI设置中具有重要应用价值。"
}