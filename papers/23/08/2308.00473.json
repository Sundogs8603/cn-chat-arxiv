{
    "title": "Is Last Layer Re-Training Truly Sufficient for Robustness to Spurious Correlations?. (arXiv:2308.00473v1 [cs.LG])",
    "abstract": "Models trained with empirical risk minimization (ERM) are known to learn to rely on spurious features, i.e., their prediction is based on undesired auxiliary features which are strongly correlated with class labels but lack causal reasoning. This behavior particularly degrades accuracy in groups of samples of the correlated class that are missing the spurious feature or samples of the opposite class but with the spurious feature present. The recently proposed Deep Feature Reweighting (DFR) method improves accuracy of these worst groups. Based on the main argument that ERM mods can learn core features sufficiently well, DFR only needs to retrain the last layer of the classification model with a small group-balanced data set. In this work, we examine the applicability of DFR to realistic data in the medical domain. Furthermore, we investigate the reasoning behind the effectiveness of last-layer retraining and show that even though DFR has the potential to improve the accuracy of the wors",
    "link": "http://arxiv.org/abs/2308.00473",
    "context": "Title: Is Last Layer Re-Training Truly Sufficient for Robustness to Spurious Correlations?. (arXiv:2308.00473v1 [cs.LG])\nAbstract: Models trained with empirical risk minimization (ERM) are known to learn to rely on spurious features, i.e., their prediction is based on undesired auxiliary features which are strongly correlated with class labels but lack causal reasoning. This behavior particularly degrades accuracy in groups of samples of the correlated class that are missing the spurious feature or samples of the opposite class but with the spurious feature present. The recently proposed Deep Feature Reweighting (DFR) method improves accuracy of these worst groups. Based on the main argument that ERM mods can learn core features sufficiently well, DFR only needs to retrain the last layer of the classification model with a small group-balanced data set. In this work, we examine the applicability of DFR to realistic data in the medical domain. Furthermore, we investigate the reasoning behind the effectiveness of last-layer retraining and show that even though DFR has the potential to improve the accuracy of the wors",
    "path": "papers/23/08/2308.00473.json",
    "total_tokens": 922,
    "translated_title": "最后一层的训练是否足以应对虚假相关性？",
    "translated_abstract": "以经验风险最小化（ERM）训练的模型已被知晓学会依赖虚假特征，即它们的预测基于与类别标签强相关但缺乏因果推理的非期望辅助特征。这种行为尤其在相关类别的样本组中，可能没有这些虚假特征或者相反类别的样本中存在这些虚假特征时，导致准确性的下降。最近提出的深度特征重加权（DFR）方法提高了这些最差样本组的准确性。基于ERM模型可以足够好地学习核心特征的主要论点，DFR只需对分类模型的最后一层进行小规模平衡数据集的重新训练。在本研究中，我们检验了DFR在医学领域真实数据中的适用性。此外，我们对最后一层重新训练有效性背后的推理进行了调查，结果表明尽管DFR具有提高最差样本组准确性的潜力，但其实现方式存在局限性。",
    "tldr": "通过对最后一层进行重新训练，Deep Feature Reweighting（DFR）方法可以提高模型在存在虚假相关性的数据中的准确性，但其应用于实际医学数据时存在一定局限性。"
}