{
    "title": "Ladder-of-Thought: Using Knowledge as Steps to Elevate Stance Detection. (arXiv:2308.16763v1 [cs.CL])",
    "abstract": "Chain-of-Thought Prompting (CoT) reinforces the reasoning capabilities of Large Language Models (LLMs) through the generation of intermediate rationales. However, these enhancements predominantly benefit large-scale models, leaving small LMs without significant performance improvements when directly applying CoT. Despite the advanced reasoning capabilities of LLMs, CoT relies primarily on their pre-trained internal knowledge. The external knowledge that is previously unknown to the model remains unexploited. This omission becomes pronounced in tasks such as stance detection, where the external background knowledge plays a pivotal role. Additionally, the large-scale architecture of LLMs inevitably present efficiency challenges during deployment. To address these challenges, we introduce the Ladder-of-Thought (LoT) for stance detection. Grounded in a dual-phase Cascaded Optimization framework, LoT directs the model to incorporate high-quality external knowledge, enhancing the intermediat",
    "link": "http://arxiv.org/abs/2308.16763",
    "context": "Title: Ladder-of-Thought: Using Knowledge as Steps to Elevate Stance Detection. (arXiv:2308.16763v1 [cs.CL])\nAbstract: Chain-of-Thought Prompting (CoT) reinforces the reasoning capabilities of Large Language Models (LLMs) through the generation of intermediate rationales. However, these enhancements predominantly benefit large-scale models, leaving small LMs without significant performance improvements when directly applying CoT. Despite the advanced reasoning capabilities of LLMs, CoT relies primarily on their pre-trained internal knowledge. The external knowledge that is previously unknown to the model remains unexploited. This omission becomes pronounced in tasks such as stance detection, where the external background knowledge plays a pivotal role. Additionally, the large-scale architecture of LLMs inevitably present efficiency challenges during deployment. To address these challenges, we introduce the Ladder-of-Thought (LoT) for stance detection. Grounded in a dual-phase Cascaded Optimization framework, LoT directs the model to incorporate high-quality external knowledge, enhancing the intermediat",
    "path": "papers/23/08/2308.16763.json",
    "total_tokens": 913,
    "translated_title": "Ladder-of-Thought: 使用知识作为阶梯提升立场检测",
    "translated_abstract": "思维链式提供（CoT）通过生成中间的推理来增强大型语言模型（LLM）的推理能力。然而，这些增强主要有益于大规模模型，在直接应用CoT时小型LLM的性能改进不明显。尽管LLM具有先进的推理能力，CoT主要依赖于其预先训练的内部知识，先前未知于模型的外部知识未被充分利用。在立场检测等任务中，外部背景知识起着关键作用，这种遗漏变得更加明显。此外，LLM的大规模架构在部署过程中不可避免地存在效率挑战。为了解决这些挑战，我们引入了用于立场检测的思维阶梯（LoT）。LoT基于双阶段级联优化框架，指导模型整合高质量的外部知识，增强中间步骤的性能。",
    "tldr": "该论文介绍了一种名为“Ladder-of-Thought”的方法，通过引入外部知识来提升立场检测任务中的语言模型的性能，解决了小型模型在应用先前内部知识时性能提升不明显的问题，以及大规模模型在效率方面的挑战。",
    "en_tdlr": "This paper introduces a method called \"Ladder-of-Thought\" that enhances the performance of language models in stance detection tasks by incorporating external knowledge, addressing the issue of small models not benefiting significantly from previous internal knowledge and the efficiency challenges of large-scale models."
}