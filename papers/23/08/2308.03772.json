{
    "title": "Improved Neural Radiance Fields Using Pseudo-depth and Fusion. (arXiv:2308.03772v1 [cs.CV])",
    "abstract": "Since the advent of Neural Radiance Fields, novel view synthesis has received tremendous attention. The existing approach for the generalization of radiance field reconstruction primarily constructs an encoding volume from nearby source images as additional inputs. However, these approaches cannot efficiently encode the geometric information of real scenes with various scale objects/structures. In this work, we propose constructing multi-scale encoding volumes and providing multi-scale geometry information to NeRF models. To make the constructed volumes as close as possible to the surfaces of objects in the scene and the rendered depth more accurate, we propose to perform depth prediction and radiance field reconstruction simultaneously. The predicted depth map will be used to supervise the rendered depth, narrow the depth range, and guide points sampling. Finally, the geometric information contained in point volume features may be inaccurate due to occlusion, lighting, etc. To this en",
    "link": "http://arxiv.org/abs/2308.03772",
    "context": "Title: Improved Neural Radiance Fields Using Pseudo-depth and Fusion. (arXiv:2308.03772v1 [cs.CV])\nAbstract: Since the advent of Neural Radiance Fields, novel view synthesis has received tremendous attention. The existing approach for the generalization of radiance field reconstruction primarily constructs an encoding volume from nearby source images as additional inputs. However, these approaches cannot efficiently encode the geometric information of real scenes with various scale objects/structures. In this work, we propose constructing multi-scale encoding volumes and providing multi-scale geometry information to NeRF models. To make the constructed volumes as close as possible to the surfaces of objects in the scene and the rendered depth more accurate, we propose to perform depth prediction and radiance field reconstruction simultaneously. The predicted depth map will be used to supervise the rendered depth, narrow the depth range, and guide points sampling. Finally, the geometric information contained in point volume features may be inaccurate due to occlusion, lighting, etc. To this en",
    "path": "papers/23/08/2308.03772.json",
    "total_tokens": 862,
    "translated_title": "使用伪深度和融合技术改进神经光辐射场",
    "translated_abstract": "自从神经光辐射场技术问世以来，新颖的视角合成引起了广泛的关注。现有的辐射场重建通常通过从附近的源图像中构建一个编码体作为额外的输入来实现。然而，这些方法无法有效地编码真实场景中各种规模的物体/结构的几何信息。本文提出了构建多尺度编码体并为NeRF模型提供多尺度几何信息的方法。为使构建的编码体尽可能接近场景中物体的表面和渲染深度更准确，我们提出同时进行深度预测和辐射场重建。预测的深度图将用于监督渲染深度、缩小深度范围并引导点采样。最后，由于遮挡、光照等原因，点体特征中包含的几何信息可能不准确。",
    "tldr": "本文提出了一种改进神经光辐射场的方法，通过构建多尺度编码体和提供多尺度几何信息，同时进行深度预测和辐射场重建，以实现对真实场景中物体的准确建模和视角合成。"
}