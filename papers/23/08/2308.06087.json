{
    "title": "Audio-Visual Spatial Integration and Recursive Attention for Robust Sound Source Localization. (arXiv:2308.06087v1 [cs.MM] CROSS LISTED)",
    "abstract": "The objective of the sound source localization task is to enable machines to detect the location of sound-making objects within a visual scene. While the audio modality provides spatial cues to locate the sound source, existing approaches only use audio as an auxiliary role to compare spatial regions of the visual modality. Humans, on the other hand, utilize both audio and visual modalities as spatial cues to locate sound sources. In this paper, we propose an audio-visual spatial integration network that integrates spatial cues from both modalities to mimic human behavior when detecting sound-making objects. Additionally, we introduce a recursive attention network to mimic human behavior of iterative focusing on objects, resulting in more accurate attention regions. To effectively encode spatial information from both modalities, we propose audio-visual pair matching loss and spatial region alignment loss. By utilizing the spatial cues of audio-visual modalities and recursively focusing",
    "link": "http://arxiv.org/abs/2308.06087",
    "context": "Title: Audio-Visual Spatial Integration and Recursive Attention for Robust Sound Source Localization. (arXiv:2308.06087v1 [cs.MM] CROSS LISTED)\nAbstract: The objective of the sound source localization task is to enable machines to detect the location of sound-making objects within a visual scene. While the audio modality provides spatial cues to locate the sound source, existing approaches only use audio as an auxiliary role to compare spatial regions of the visual modality. Humans, on the other hand, utilize both audio and visual modalities as spatial cues to locate sound sources. In this paper, we propose an audio-visual spatial integration network that integrates spatial cues from both modalities to mimic human behavior when detecting sound-making objects. Additionally, we introduce a recursive attention network to mimic human behavior of iterative focusing on objects, resulting in more accurate attention regions. To effectively encode spatial information from both modalities, we propose audio-visual pair matching loss and spatial region alignment loss. By utilizing the spatial cues of audio-visual modalities and recursively focusing",
    "path": "papers/23/08/2308.06087.json",
    "total_tokens": 982,
    "translated_title": "鲁棒的声源定位的音频-视觉空间融合和递归注意力",
    "translated_abstract": "声源定位任务的目标是让机器能够在视觉场景中检测出声音产生物体的位置。虽然音频模态提供了定位声源的空间线索，但现有方法仅将音频作为视觉模态空间区域比较的辅助角色。而人类则利用音频和视觉模态作为定位声源的空间线索。本文提出了一种音频-视觉空间融合网络，通过整合两种模态的空间线索来模仿人类检测声音产生物体时的行为。此外，我们引入了一种递归注意力网络来模仿人类迭代地聚焦对象，从而得到更准确的注意力区域。为了有效地编码两种模态的空间信息，我们提出了音频-视觉配对匹配损失和空间区域对齐损失。通过利用音频-视觉模态的空间线索和递归聚焦的策略，我们的方法在声源定位任务上取得了良好的性能。",
    "tldr": "本文提出了一种音频-视觉空间融合网络，通过整合音频和视觉模态的空间线索来模仿人类检测声音产生物体的行为，并引入递归注意力网络来得到更准确的注意力区域。通过音频和视觉模态的空间线索和递归聚焦策略，方法在声源定位任务上取得了良好的性能。",
    "en_tdlr": "This paper proposes an audio-visual spatial integration network that mimics human behavior of detecting sound-making objects by integrating spatial cues from both audio and visual modalities, and introduces a recursive attention network to achieve more accurate attention regions. The proposed method achieves good performance in sound source localization task by utilizing spatial cues of audio-visual modalities and recursive focusing strategy."
}