{
    "title": "A Survey on Fairness in Large Language Models",
    "abstract": "arXiv:2308.10149v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) have shown powerful performance and development prospects and are widely deployed in the real world. However, LLMs can capture social biases from unprocessed training data and propagate the biases to downstream tasks. Unfair LLM systems have undesirable social impacts and potential harms. In this paper, we provide a comprehensive review of related research on fairness in LLMs. Considering the influence of parameter magnitude and training paradigm on research strategy, we divide existing fairness research into oriented to medium-sized LLMs under pre-training and fine-tuning paradigms and oriented to large-sized LLMs under prompting paradigms. First, for medium-sized LLMs, we introduce evaluation metrics and debiasing methods from the perspectives of intrinsic bias and extrinsic bias, respectively. Then, for large-sized LLMs, we introduce recent fairness research, including fairness evaluation, reason",
    "link": "https://arxiv.org/abs/2308.10149",
    "context": "Title: A Survey on Fairness in Large Language Models\nAbstract: arXiv:2308.10149v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) have shown powerful performance and development prospects and are widely deployed in the real world. However, LLMs can capture social biases from unprocessed training data and propagate the biases to downstream tasks. Unfair LLM systems have undesirable social impacts and potential harms. In this paper, we provide a comprehensive review of related research on fairness in LLMs. Considering the influence of parameter magnitude and training paradigm on research strategy, we divide existing fairness research into oriented to medium-sized LLMs under pre-training and fine-tuning paradigms and oriented to large-sized LLMs under prompting paradigms. First, for medium-sized LLMs, we introduce evaluation metrics and debiasing methods from the perspectives of intrinsic bias and extrinsic bias, respectively. Then, for large-sized LLMs, we introduce recent fairness research, including fairness evaluation, reason",
    "path": "papers/23/08/2308.10149.json",
    "total_tokens": 851,
    "translated_title": "大型语言模型中公平性的调查",
    "translated_abstract": "大型语言模型(LLMs)展现了强大的性能和发展前景，并广泛部署在现实世界中。然而，LLMs可能会捕捉到未经处理的训练数据中的社会偏见，并将这些偏见传播到下游任务。不公平的LLM系统会产生不良的社会影响和潜在危害。在本文中，我们全面回顾了有关LLMs中公平性的研究。考虑到参数大小和训练范式对研究策略的影响，我们将现有的公平性研究分为针对中等规模LLMs在预训练和微调范式下的研究以及针对大规模LLMs在提示范式下的研究。首先，对于中等规模LLMs，我们从内在偏见和外在偏见的角度介绍了评估指标和去偏见方法。然后，对于大规模LLMs，我们引入了最近的公平性研究，包括公平性评估、原因...",
    "tldr": "本文审查了关于大型语言模型中公平性的研究，针对中等规模LLMs和大规模LLMs提出了评估指标和去偏见方法。"
}