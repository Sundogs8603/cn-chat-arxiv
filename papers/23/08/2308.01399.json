{
    "title": "Learning to Model the World with Language. (arXiv:2308.01399v1 [cs.CL])",
    "abstract": "To interact with humans in the world, agents need to understand the diverse types of language that people use, relate them to the visual world, and act based on them. While current agents learn to execute simple language instructions from task rewards, we aim to build agents that leverage diverse language that conveys general knowledge, describes the state of the world, provides interactive feedback, and more. Our key idea is that language helps agents predict the future: what will be observed, how the world will behave, and which situations will be rewarded. This perspective unifies language understanding with future prediction as a powerful self-supervised learning objective. We present Dynalang, an agent that learns a multimodal world model that predicts future text and image representations and learns to act from imagined model rollouts. Unlike traditional agents that use language only to predict actions, Dynalang acquires rich language understanding by using past language also to ",
    "link": "http://arxiv.org/abs/2308.01399",
    "context": "Title: Learning to Model the World with Language. (arXiv:2308.01399v1 [cs.CL])\nAbstract: To interact with humans in the world, agents need to understand the diverse types of language that people use, relate them to the visual world, and act based on them. While current agents learn to execute simple language instructions from task rewards, we aim to build agents that leverage diverse language that conveys general knowledge, describes the state of the world, provides interactive feedback, and more. Our key idea is that language helps agents predict the future: what will be observed, how the world will behave, and which situations will be rewarded. This perspective unifies language understanding with future prediction as a powerful self-supervised learning objective. We present Dynalang, an agent that learns a multimodal world model that predicts future text and image representations and learns to act from imagined model rollouts. Unlike traditional agents that use language only to predict actions, Dynalang acquires rich language understanding by using past language also to ",
    "path": "papers/23/08/2308.01399.json",
    "total_tokens": 910,
    "translated_title": "通过语言学习对世界建模",
    "translated_abstract": "为了与人类在世界中相互作用，代理器需要理解人们使用的多样化的语言类型，并将其与视觉世界关联起来，并基于语言行动。虽然当前的代理器可以通过任务奖励学习执行简单的语言指令，但我们的目标是建立可以利用传达一般知识、描述世界状态、提供互动反馈等多样化语言的代理器。我们的核心思想是语言帮助代理器预测未来：将会被观察到什么、世界将如何运行以及哪些情况将获得奖励。这个观点将语言理解与未来预测统一为一个强大的自监督学习目标。我们提出了Dynalang，一种学习多模态世界模型的代理器，它可以预测未来的文本和图像表示，并在想像的模型回滚中学习行动。与只使用语言预测动作的传统代理器不同，Dynalang通过过去的语言还可以获取丰富的语言理解能力。",
    "tldr": "本论文提出了一种通过语言学习对世界进行建模的方法，利用语言帮助代理器预测未来并进行行动。通过学习多模态世界模型，代理器可以预测未来的文本和图像表示，并在模型回滚中进行行动。",
    "en_tdlr": "This paper presents a method for modeling the world through language, using language to predict the future and take actions. By learning a multimodal world model, agents can predict future text and image representations and act based on model rollouts."
}