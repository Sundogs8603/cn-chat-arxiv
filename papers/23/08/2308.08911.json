{
    "title": "Towards Filling the Gap in Conversational Search: From Passage Retrieval to Conversational Response Generation. (arXiv:2308.08911v1 [cs.IR])",
    "abstract": "Research on conversational search has so far mostly focused on query rewriting and multi-stage passage retrieval. However, synthesizing the top retrieved passages into a complete, relevant, and concise response is still an open challenge. Having snippet-level annotations of relevant passages would enable both (1) the training of response generation models that are able to ground answers in actual statements and (2) the automatic evaluation of the generated responses in terms of completeness. In this paper, we address the problem of collecting high-quality snippet-level answer annotations for two of the TREC Conversational Assistance track datasets. To ensure quality, we first perform a preliminary annotation study, employing different task designs, crowdsourcing platforms, and workers with different qualifications. Based on the outcomes of this study, we refine our annotation protocol before proceeding with the full-scale data collection. Overall, we gather annotations for 1.8k questio",
    "link": "http://arxiv.org/abs/2308.08911",
    "context": "Title: Towards Filling the Gap in Conversational Search: From Passage Retrieval to Conversational Response Generation. (arXiv:2308.08911v1 [cs.IR])\nAbstract: Research on conversational search has so far mostly focused on query rewriting and multi-stage passage retrieval. However, synthesizing the top retrieved passages into a complete, relevant, and concise response is still an open challenge. Having snippet-level annotations of relevant passages would enable both (1) the training of response generation models that are able to ground answers in actual statements and (2) the automatic evaluation of the generated responses in terms of completeness. In this paper, we address the problem of collecting high-quality snippet-level answer annotations for two of the TREC Conversational Assistance track datasets. To ensure quality, we first perform a preliminary annotation study, employing different task designs, crowdsourcing platforms, and workers with different qualifications. Based on the outcomes of this study, we refine our annotation protocol before proceeding with the full-scale data collection. Overall, we gather annotations for 1.8k questio",
    "path": "papers/23/08/2308.08911.json",
    "total_tokens": 864,
    "translated_title": "解决会话式搜索中的问题：从段落检索到会话式响应生成",
    "translated_abstract": "目前关于会话式搜索的研究主要集中在查询重写和多阶段段落检索上。然而，将检索到的顶级段落综合成一种完整、相关且简洁的响应仍然是一个开放的挑战。具有段落级别的相关注释将使得（1）能够训练响应生成模型，这些模型能够基于实际陈述进行答案解释，以及（2）能够根据完整性自动评估生成的响应。在本文中，我们解决了在两个TREC Conversational Assistance数据集中收集高质量的段落级别答案注释的问题。为确保质量，我们首先进行了初步的注释研究，采用不同的任务设计、众包平台和不同资质的工作者。根据这项研究的结果，我们修改了注释协议，并继续进行全面的数据收集。总体而言，我们为1.8k个问题收集了注释。",
    "tldr": "本文解决了会话式搜索中的一个挑战，即将检索到的顶级段落综合成一种完整、相关且简洁的响应。通过收集段落级别的相关注释，并使用这些注释来训练生成模型和评估生成的响应，我们取得了高质量的数据集。"
}