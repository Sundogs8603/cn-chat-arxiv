{
    "title": "PromptPaint: Steering Text-to-Image Generation Through Paint Medium-like Interactions. (arXiv:2308.05184v1 [cs.HC])",
    "abstract": "While diffusion-based text-to-image (T2I) models provide a simple and powerful way to generate images, guiding this generation remains a challenge. For concepts that are difficult to describe through language, users may struggle to create prompts. Moreover, many of these models are built as end-to-end systems, lacking support for iterative shaping of the image. In response, we introduce PromptPaint, which combines T2I generation with interactions that model how we use colored paints. PromptPaint allows users to go beyond language to mix prompts that express challenging concepts. Just as we iteratively tune colors through layered placements of paint on a physical canvas, PromptPaint similarly allows users to apply different prompts to different canvas areas and times of the generative process. Through a set of studies, we characterize different approaches for mixing prompts, design trade-offs, and socio-technical challenges for generative models. With PromptPaint we provide insight into",
    "link": "http://arxiv.org/abs/2308.05184",
    "context": "Title: PromptPaint: Steering Text-to-Image Generation Through Paint Medium-like Interactions. (arXiv:2308.05184v1 [cs.HC])\nAbstract: While diffusion-based text-to-image (T2I) models provide a simple and powerful way to generate images, guiding this generation remains a challenge. For concepts that are difficult to describe through language, users may struggle to create prompts. Moreover, many of these models are built as end-to-end systems, lacking support for iterative shaping of the image. In response, we introduce PromptPaint, which combines T2I generation with interactions that model how we use colored paints. PromptPaint allows users to go beyond language to mix prompts that express challenging concepts. Just as we iteratively tune colors through layered placements of paint on a physical canvas, PromptPaint similarly allows users to apply different prompts to different canvas areas and times of the generative process. Through a set of studies, we characterize different approaches for mixing prompts, design trade-offs, and socio-technical challenges for generative models. With PromptPaint we provide insight into",
    "path": "papers/23/08/2308.05184.json",
    "total_tokens": 969,
    "translated_title": "PromptPaint: 通过绘画媒介般的交互引导文本转图片生成",
    "translated_abstract": "虽然基于扩散的文本转图片(T2I)模型提供了一种简单而强大的生成图像的方式，但是引导这种生成仍然是一个挑战。对于难以通过语言描述的概念，用户可能难以创建合适的提示。另外，许多这些模型都是以端到端系统的形式构建的，缺乏对图像的迭代塑造支持。为了应对这个问题，我们引入了PromptPaint，它将T2I生成与模拟我们使用彩色油漆的交互相结合。PromptPaint使用户能够超越语言，混合表达具有挑战性的概念的提示。就像我们通过在物理画布上层叠放置油漆来迭代调整颜色一样，PromptPaint同样允许用户在生成过程的不同画布区域和时间应用不同的提示。通过一系列的研究，我们对混合提示的不同方法、设计权衡以及生成模型的社会技术挑战进行了表征。通过PromptPaint，我们提供了对图像生成过程的洞察",
    "tldr": "PromptPaint是一种结合了文字到图像生成和模拟绘画媒介交互的方法。它允许用户通过混合不同的提示来表达具有挑战性的概念，并支持在生成过程中对图像进行迭代塑造。研究结果表明，PromptPaint提供了一种灵活且强大的方式来生成图像。",
    "en_tdlr": "PromptPaint is an approach that combines text-to-image generation with simulated painting medium interactions. It allows users to express challenging concepts by mixing different prompts and supports iterative shaping of the image during the generation process. The research findings demonstrate that PromptPaint provides a flexible and powerful way to generate images."
}