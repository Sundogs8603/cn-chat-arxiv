{
    "title": "Self-Directed Linear Classification. (arXiv:2308.03142v1 [cs.LG])",
    "abstract": "In online classification, a learner is presented with a sequence of examples and aims to predict their labels in an online fashion so as to minimize the total number of mistakes. In the self-directed variant, the learner knows in advance the pool of examples and can adaptively choose the order in which predictions are made. Here we study the power of choosing the prediction order and establish the first strong separation between worst-order and random-order learning for the fundamental task of linear classification. Prior to our work, such a separation was known only for very restricted concept classes, e.g., one-dimensional thresholds or axis-aligned rectangles.  We present two main results. If $X$ is a dataset of $n$ points drawn uniformly at random from the $d$-dimensional unit sphere, we design an efficient self-directed learner that makes $O(d \\log \\log(n))$ mistakes and classifies the entire dataset. If $X$ is an arbitrary $d$-dimensional dataset of size $n$, we design an efficie",
    "link": "http://arxiv.org/abs/2308.03142",
    "context": "Title: Self-Directed Linear Classification. (arXiv:2308.03142v1 [cs.LG])\nAbstract: In online classification, a learner is presented with a sequence of examples and aims to predict their labels in an online fashion so as to minimize the total number of mistakes. In the self-directed variant, the learner knows in advance the pool of examples and can adaptively choose the order in which predictions are made. Here we study the power of choosing the prediction order and establish the first strong separation between worst-order and random-order learning for the fundamental task of linear classification. Prior to our work, such a separation was known only for very restricted concept classes, e.g., one-dimensional thresholds or axis-aligned rectangles.  We present two main results. If $X$ is a dataset of $n$ points drawn uniformly at random from the $d$-dimensional unit sphere, we design an efficient self-directed learner that makes $O(d \\log \\log(n))$ mistakes and classifies the entire dataset. If $X$ is an arbitrary $d$-dimensional dataset of size $n$, we design an efficie",
    "path": "papers/23/08/2308.03142.json",
    "total_tokens": 972,
    "translated_title": "自主线性分类",
    "translated_abstract": "在在线分类中，学习器被呈现一系列的示例，并旨在以在线方式预测其标签，以最小化错误的总数。在自主变体中，学习器事先了解示例池，并能够自适应地选择预测顺序。在这里，我们研究了选择预测顺序的能力，并为线性分类的基本任务建立了最坏顺序和随机顺序学习之间的第一个强分离。在我们的工作之前，只在非常受限的概念类中才知道这样的分离，例如一维门限或轴对齐矩形。我们提出了两个主要结果。如果$X$是从$d$维单位球中均匀随机抽取的$n$个点的数据集，则我们设计了一个高效的自主学习器，可做出$O(d \\log \\log(n))$个错误并分类整个数据集。如果$X$是一个任意的$d$维数据集，大小为$n$，我们设计了一个高效的自主学习器，使得其在分类整个数据集时总共也只会产生$O(d \\log \\log(n))$个错误。",
    "tldr": "这项研究首次在自主线性分类任务中研究了选择预测顺序的能力，并提出了两个主要结果，针对不同类型的数据集，设计了高效的自主学习器，最少只产生$O(d \\log \\log(n))$个错误。"
}