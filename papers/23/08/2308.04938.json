{
    "title": "An In-Depth Analysis of Discretization Methods for Communication Learning using Backpropagation with Multi-Agent Reinforcement Learning. (arXiv:2308.04938v1 [cs.LG])",
    "abstract": "Communication is crucial in multi-agent reinforcement learning when agents are not able to observe the full state of the environment. The most common approach to allow learned communication between agents is the use of a differentiable communication channel that allows gradients to flow between agents as a form of feedback. However, this is challenging when we want to use discrete messages to reduce the message size, since gradients cannot flow through a discrete communication channel. Previous work proposed methods to deal with this problem. However, these methods are tested in different communication learning architectures and environments, making it hard to compare them. In this paper, we compare several state-of-the-art discretization methods as well as a novel approach. We do this comparison in the context of communication learning using gradients from other agents and perform tests on several environments. In addition, we present COMA-DIAL, a communication learning approach based",
    "link": "http://arxiv.org/abs/2308.04938",
    "context": "Title: An In-Depth Analysis of Discretization Methods for Communication Learning using Backpropagation with Multi-Agent Reinforcement Learning. (arXiv:2308.04938v1 [cs.LG])\nAbstract: Communication is crucial in multi-agent reinforcement learning when agents are not able to observe the full state of the environment. The most common approach to allow learned communication between agents is the use of a differentiable communication channel that allows gradients to flow between agents as a form of feedback. However, this is challenging when we want to use discrete messages to reduce the message size, since gradients cannot flow through a discrete communication channel. Previous work proposed methods to deal with this problem. However, these methods are tested in different communication learning architectures and environments, making it hard to compare them. In this paper, we compare several state-of-the-art discretization methods as well as a novel approach. We do this comparison in the context of communication learning using gradients from other agents and perform tests on several environments. In addition, we present COMA-DIAL, a communication learning approach based",
    "path": "papers/23/08/2308.04938.json",
    "total_tokens": 852,
    "translated_title": "使用基于多智能体强化学习的反向传播方法进行通信学习的离散化方法的深入分析",
    "translated_abstract": "当智能体无法观察到完整的环境状态时，通信在多智能体强化学习中至关重要。允许智能体之间学习通信的常见方法是使用可微分的通信通道，以便梯度能够作为反馈流动。然而，当我们想要使用离散消息来减小消息的大小时，这会带来挑战，因为梯度不能通过离散的通信通道传播。以前的研究提出了处理这个问题的方法。然而，这些方法在不同的通信学习架构和环境中进行了测试，使得很难进行比较。在本文中，我们比较了几种最先进的离散化方法以及一种新的方法。我们在使用来自其他智能体的梯度进行通信学习的背景下进行了比较，并在多个环境中进行了测试。另外，我们介绍了COMA-DIAL，这是一种基于通信学习的方法。",
    "tldr": "本文深入分析了使用基于多智能体强化学习的反向传播方法进行通信学习的离散化方法。研究比较了几种先进的离散化方法，并提出了一种新的方法。"
}