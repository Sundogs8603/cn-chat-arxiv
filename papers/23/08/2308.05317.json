{
    "title": "Few-Shot Data-to-Text Generation via Unified Representation and Multi-Source Learning. (arXiv:2308.05317v1 [cs.CL])",
    "abstract": "We present a novel approach for structured data-to-text generation that addresses the limitations of existing methods that primarily focus on specific types of structured data. Our proposed method aims to improve performance in multi-task training, zero-shot and few-shot scenarios by providing a unified representation that can handle various forms of structured data such as tables, knowledge graph triples, and meaning representations. We demonstrate that our proposed approach can effectively adapt to new structured forms, and can improve performance in comparison to current methods. For example, our method resulted in a 66% improvement in zero-shot BLEU scores when transferring models trained on table inputs to a knowledge graph dataset. Our proposed method is an important step towards a more general data-to-text generation framework.",
    "link": "http://arxiv.org/abs/2308.05317",
    "context": "Title: Few-Shot Data-to-Text Generation via Unified Representation and Multi-Source Learning. (arXiv:2308.05317v1 [cs.CL])\nAbstract: We present a novel approach for structured data-to-text generation that addresses the limitations of existing methods that primarily focus on specific types of structured data. Our proposed method aims to improve performance in multi-task training, zero-shot and few-shot scenarios by providing a unified representation that can handle various forms of structured data such as tables, knowledge graph triples, and meaning representations. We demonstrate that our proposed approach can effectively adapt to new structured forms, and can improve performance in comparison to current methods. For example, our method resulted in a 66% improvement in zero-shot BLEU scores when transferring models trained on table inputs to a knowledge graph dataset. Our proposed method is an important step towards a more general data-to-text generation framework.",
    "path": "papers/23/08/2308.05317.json",
    "total_tokens": 844,
    "translated_title": "通过统一表示和多源学习实现少样本数据到文本生成",
    "translated_abstract": "我们提出了一种新方法来处理结构化数据到文本生成的问题，解决了现有方法主要专注于特定类型结构化数据的限制。我们的方法通过提供一种能够处理各种形式结构化数据（如表格、知识图谱三元组和语义表示）的统一表示，旨在提高多任务训练、零样本和少样本场景的性能。我们展示了我们的方法能够有效适应新的结构化形式，并且能够在比较当前方法时提高性能。例如，我们的方法将在表格输入上训练的模型转移到知识图谱数据集时，零样本BLEU得分提高了66%。我们的方法是朝着更通用的数据到文本生成框架迈出的重要一步。",
    "tldr": "该论文提出了一种处理结构化数据到文本生成的新方法，通过提供统一表示和多源学习，可以在多任务、零样本和少样本场景下改善性能。实验证明该方法能够适应不同形式的结构化数据，并且在性能上超过当前方法。该方法对于构建更通用的数据到文本生成框架具有重要意义。",
    "en_tdlr": "This paper presents a novel approach for structured data-to-text generation that improves performance in multi-task, zero-shot, and few-shot scenarios by providing a unified representation and multi-source learning. The proposed method effectively adapts to different forms of structured data and outperforms current methods, making it an important step towards a more general data-to-text generation framework."
}