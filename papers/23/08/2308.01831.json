{
    "title": "Many-to-Many Spoken Language Translation via Unified Speech and Text Representation Learning with Unit-to-Unit Translation. (arXiv:2308.01831v1 [cs.CL])",
    "abstract": "In this paper, we propose a method to learn unified representations of multilingual speech and text with a single model, especially focusing on the purpose of speech synthesis. We represent multilingual speech audio with speech units, the quantized representations of speech features encoded from a self-supervised speech model. Therefore, we can focus on their linguistic content by treating the audio as pseudo text and can build a unified representation of speech and text. Then, we propose to train an encoder-decoder structured model with a Unit-to-Unit Translation (UTUT) objective on multilingual data. Specifically, by conditioning the encoder with the source language token and the decoder with the target language token, the model is optimized to translate the spoken language into that of the target language, in a many-to-many language translation setting. Therefore, the model can build the knowledge of how spoken languages are comprehended and how to relate them to different languages",
    "link": "http://arxiv.org/abs/2308.01831",
    "context": "Title: Many-to-Many Spoken Language Translation via Unified Speech and Text Representation Learning with Unit-to-Unit Translation. (arXiv:2308.01831v1 [cs.CL])\nAbstract: In this paper, we propose a method to learn unified representations of multilingual speech and text with a single model, especially focusing on the purpose of speech synthesis. We represent multilingual speech audio with speech units, the quantized representations of speech features encoded from a self-supervised speech model. Therefore, we can focus on their linguistic content by treating the audio as pseudo text and can build a unified representation of speech and text. Then, we propose to train an encoder-decoder structured model with a Unit-to-Unit Translation (UTUT) objective on multilingual data. Specifically, by conditioning the encoder with the source language token and the decoder with the target language token, the model is optimized to translate the spoken language into that of the target language, in a many-to-many language translation setting. Therefore, the model can build the knowledge of how spoken languages are comprehended and how to relate them to different languages",
    "path": "papers/23/08/2308.01831.json",
    "total_tokens": 1027,
    "translated_title": "通过统一的语音和文本表示学习以及单元到单元的翻译实现多对多口语翻译",
    "translated_abstract": "在本文中，我们提出了一种使用单个模型学习多语种语音和文本的统一表示的方法，特别关注语音合成的目的。我们使用语音单元表示多语种语音音频，这些语音单元是从自监督语音模型编码的语音特征的量化表示。因此，我们可以将音频视为伪文本并专注于其语言内容，从而构建语音和文本的统一表示。然后，我们提出使用多语种数据训练编码器-解码器结构模型，并采用单元到单元翻译（UTUT）目标。具体而言，通过将编码器与源语言标记和解码器与目标语言标记相关联，优化模型以将口语语言翻译为目标语言的语言。因此，该模型可以建立对口语语言的理解以及如何将其与不同语言相关联的知识。",
    "tldr": "本文提出了一种使用统一模型学习多语种语音和文本的表示的方法，重点关注语音合成。通过使用自监督语音模型编码的语音特征的量化表示语音音频，并将其视为伪文本来建立统一的语音和文本表示。然后通过训练编码器-解码器结构模型，利用单元到单元翻译目标将口语语言翻译为目标语言。这种方法能够建立对口语语言的理解并将其相关联到不同的语言。",
    "en_tdlr": "This paper proposes a method to learn unified representations of multilingual speech and text with a single model, focusing on speech synthesis. By quantizing the representations of speech features encoded from a self-supervised speech model and treating the audio as pseudo text, a unified representation of speech and text is built. The proposed encoder-decoder model with Unit-to-Unit Translation (UTUT) objective is trained on multilingual data, enabling many-to-many translation of spoken language into the target language. This approach facilitates understanding of spoken languages and their relation to different languages."
}