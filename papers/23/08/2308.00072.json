{
    "title": "How User Language Affects Conflict Fatality Estimates in ChatGPT. (arXiv:2308.00072v1 [cs.CL])",
    "abstract": "OpenAI's ChatGPT language model has gained popularity as a powerful tool for complex problem-solving and information retrieval. However, concerns arise about the reproduction of biases present in the language-specific training data. In this study, we address this issue in the context of the Israeli-Palestinian and Turkish-Kurdish conflicts. Using GPT-3.5, we employed an automated query procedure to inquire about casualties in specific airstrikes, in both Hebrew and Arabic for the former conflict and Turkish and Kurdish for the latter. Our analysis reveals that GPT-3.5 provides 27$\\pm$11 percent lower fatality estimates when queried in the language of the attacker than in the language of the targeted group. Evasive answers denying the existence of such attacks further increase the discrepancy, creating a novel bias mechanism not present in regular search engines. This language bias has the potential to amplify existing media biases and contribute to information bubbles, ultimately reinf",
    "link": "http://arxiv.org/abs/2308.00072",
    "context": "Title: How User Language Affects Conflict Fatality Estimates in ChatGPT. (arXiv:2308.00072v1 [cs.CL])\nAbstract: OpenAI's ChatGPT language model has gained popularity as a powerful tool for complex problem-solving and information retrieval. However, concerns arise about the reproduction of biases present in the language-specific training data. In this study, we address this issue in the context of the Israeli-Palestinian and Turkish-Kurdish conflicts. Using GPT-3.5, we employed an automated query procedure to inquire about casualties in specific airstrikes, in both Hebrew and Arabic for the former conflict and Turkish and Kurdish for the latter. Our analysis reveals that GPT-3.5 provides 27$\\pm$11 percent lower fatality estimates when queried in the language of the attacker than in the language of the targeted group. Evasive answers denying the existence of such attacks further increase the discrepancy, creating a novel bias mechanism not present in regular search engines. This language bias has the potential to amplify existing media biases and contribute to information bubbles, ultimately reinf",
    "path": "papers/23/08/2308.00072.json",
    "total_tokens": 1071,
    "translated_title": "用户语言对ChatGPT中冲突死亡估计的影响",
    "translated_abstract": "OpenAI的ChatGPT语言模型因其强大的复杂问题解决和信息检索能力而备受青睐。然而，关于该模型是否会复制语言特定训练数据中存在的偏见的担忧也不断出现。在本研究中，我们在以色列-巴勒斯坦和土耳其-库尔德冲突的背景下解决了这个问题。使用GPT-3.5，我们采用自动查询过程，以希伯来语和阿拉伯语查询关于特定空袭中的伤亡人数。我们的分析发现，当使用攻击者的语言进行查询时，GPT-3.5提供的死亡估计较使用被攻击群体的语言查询时低27±11％。否认存在此类袭击的回答进一步增加了这种差异，创造了一种在常规搜索引擎中不存在的新的偏见机制。这种语言偏见有可能放大现有的媒体偏见，并加剧信息孤立，最终加重冲突。",
    "tldr": "在以色列-巴勒斯坦和土耳其-库尔德冲突的背景下，本研究探讨了用户语言对ChatGPT中冲突死亡估计的影响。研究发现，在使用攻击者的语言进行查询时，GPT-3.5提供的估计较使用被攻击群体的语言查询时低27±11％。此外，否认存在此类袭击的回答进一步增加了这种差异，形成了一种新的偏见机制，可能加大现有的媒体偏见并加剧信息孤立。",
    "en_tdlr": "This study investigates how user language affects conflict fatality estimates in ChatGPT, specifically in the Israeli-Palestinian and Turkish-Kurdish conflicts. It reveals that when queried in the language of the attacker, ChatGPT provides lower fatality estimates compared to when queried in the language of the targeted group. Evasive answers denying the existence of attacks further exacerbate this bias, potentially amplifying existing media biases and contributing to information bubbles."
}