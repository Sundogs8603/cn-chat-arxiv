{
    "title": "Bias-Aware Minimisation: Understanding and Mitigating Estimator Bias in Private SGD. (arXiv:2308.12018v1 [cs.LG])",
    "abstract": "Differentially private SGD (DP-SGD) holds the promise of enabling the safe and responsible application of machine learning to sensitive datasets. However, DP-SGD only provides a biased, noisy estimate of a mini-batch gradient. This renders optimisation steps less effective and limits model utility as a result. With this work, we show a connection between per-sample gradient norms and the estimation bias of the private gradient oracle used in DP-SGD. Here, we propose Bias-Aware Minimisation (BAM) that allows for the provable reduction of private gradient estimator bias. We show how to efficiently compute quantities needed for BAM to scale to large neural networks and highlight similarities to closely related methods such as Sharpness-Aware Minimisation. Finally, we provide empirical evidence that BAM not only reduces bias but also substantially improves privacy-utility trade-offs on the CIFAR-10, CIFAR-100, and ImageNet-32 datasets.",
    "link": "http://arxiv.org/abs/2308.12018",
    "context": "Title: Bias-Aware Minimisation: Understanding and Mitigating Estimator Bias in Private SGD. (arXiv:2308.12018v1 [cs.LG])\nAbstract: Differentially private SGD (DP-SGD) holds the promise of enabling the safe and responsible application of machine learning to sensitive datasets. However, DP-SGD only provides a biased, noisy estimate of a mini-batch gradient. This renders optimisation steps less effective and limits model utility as a result. With this work, we show a connection between per-sample gradient norms and the estimation bias of the private gradient oracle used in DP-SGD. Here, we propose Bias-Aware Minimisation (BAM) that allows for the provable reduction of private gradient estimator bias. We show how to efficiently compute quantities needed for BAM to scale to large neural networks and highlight similarities to closely related methods such as Sharpness-Aware Minimisation. Finally, we provide empirical evidence that BAM not only reduces bias but also substantially improves privacy-utility trade-offs on the CIFAR-10, CIFAR-100, and ImageNet-32 datasets.",
    "path": "papers/23/08/2308.12018.json",
    "total_tokens": 939,
    "translated_title": "有偏差感知的最小化：理解和减轻私有SGD中的估计偏差",
    "translated_abstract": "差分隐私SGD（DP-SGD）承诺能够安全和负责任地将机器学习应用于敏感数据集。然而，DP-SGD仅提供有偏差、噪声较大的小批量梯度估计。这使得优化步骤变得不太有效，并因此限制了模型的效用。本文通过展示每个样本梯度范数与DP-SGD中使用的私有梯度预测的估计偏差之间的关系，提出了有偏差感知的最小化（BAM）方法，可以证明降低私有梯度估计偏差。我们展示了如何高效计算BAM所需的量，以适用于大规模神经网络，并突出了与相关方法（如Sharpness-Aware Minimisation）之间的相似之处。最后，我们提供实证证据表明BAM不仅可以减少偏差，还可以在CIFAR-10、CIFAR-100和ImageNet-32数据集上显著改善隐私-效用的权衡。",
    "tldr": "本文提出了有偏差感知的最小化（BAM）方法，可以证明降低私有梯度估计偏差，并在实验中证明BAM不仅可以减少偏差，还可以在多个数据集上改善隐私-效用的权衡。",
    "en_tdlr": "This paper proposes Bias-Aware Minimisation (BAM) method, which can provably reduce private gradient estimator bias, and provides empirical evidence that BAM not only reduces bias but also improves privacy-utility trade-offs on multiple datasets."
}