{
    "title": "RobustMQ: Benchmarking Robustness of Quantized Models. (arXiv:2308.02350v1 [cs.LG])",
    "abstract": "Quantization has emerged as an essential technique for deploying deep neural networks (DNNs) on devices with limited resources. However, quantized models exhibit vulnerabilities when exposed to various noises in real-world applications. Despite the importance of evaluating the impact of quantization on robustness, existing research on this topic is limited and often disregards established principles of robustness evaluation, resulting in incomplete and inconclusive findings. To address this gap, we thoroughly evaluated the robustness of quantized models against various noises (adversarial attacks, natural corruptions, and systematic noises) on ImageNet. The comprehensive evaluation results empirically provide valuable insights into the robustness of quantized models in various scenarios, for example: (1) quantized models exhibit higher adversarial robustness than their floating-point counterparts, but are more vulnerable to natural corruptions and systematic noises; (2) in general, inc",
    "link": "http://arxiv.org/abs/2308.02350",
    "context": "Title: RobustMQ: Benchmarking Robustness of Quantized Models. (arXiv:2308.02350v1 [cs.LG])\nAbstract: Quantization has emerged as an essential technique for deploying deep neural networks (DNNs) on devices with limited resources. However, quantized models exhibit vulnerabilities when exposed to various noises in real-world applications. Despite the importance of evaluating the impact of quantization on robustness, existing research on this topic is limited and often disregards established principles of robustness evaluation, resulting in incomplete and inconclusive findings. To address this gap, we thoroughly evaluated the robustness of quantized models against various noises (adversarial attacks, natural corruptions, and systematic noises) on ImageNet. The comprehensive evaluation results empirically provide valuable insights into the robustness of quantized models in various scenarios, for example: (1) quantized models exhibit higher adversarial robustness than their floating-point counterparts, but are more vulnerable to natural corruptions and systematic noises; (2) in general, inc",
    "path": "papers/23/08/2308.02350.json",
    "total_tokens": 926,
    "translated_title": "RobustMQ:评估量化模型鲁棒性的基准研究",
    "translated_abstract": "量化已经成为在资源有限的设备上部署深度神经网络（DNNs）的一种重要技术。然而，在真实世界的应用中，量化模型在面对各种噪声时会展现出脆弱性。尽管评估量化对鲁棒性的影响的重要性，现有的研究在这个领域中还很有限，并且经常忽视已经确立的鲁棒性评估原则，导致了不完整和不确定的结果。为了解决这个问题，我们对ImageNet上的量化模型在各种噪声（对抗攻击，自然损坏和系统噪声）下进行了全面的鲁棒性评估。全面的评估结果从经验上为量化模型在不同场景下的鲁棒性提供了有价值的见解，例如：（1）量化模型在对抗攻击方面表现出更高的鲁棒性，但对自然损坏和系统噪声更脆弱；（2）总的来说，不同程度的量化在不同场景下表现出不同的鲁棒性。",
    "tldr": "该论文通过在ImageNet上全面评估了量化模型的鲁棒性，发现量化模型在对抗攻击方面更具鲁棒性，但对自然损坏和系统噪声更脆弱。"
}