{
    "title": "Neural approximation of Wasserstein distance via a universal architecture for symmetric and factorwise group invariant functions. (arXiv:2308.00273v1 [cs.LG])",
    "abstract": "Learning distance functions between complex objects, such as the Wasserstein distance to compare point sets, is a common goal in machine learning applications. However, functions on such complex objects (e.g., point sets and graphs) are often required to be invariant to a wide variety of group actions e.g. permutation or rigid transformation. Therefore, continuous and symmetric product functions (such as distance functions) on such complex objects must also be invariant to the product of such group actions. We call these functions symmetric and factor-wise group invariant (or SFGI functions in short). In this paper, we first present a general neural network architecture for approximating SFGI functions. The main contribution of this paper combines this general neural network with a sketching idea to develop a specific and efficient neural network which can approximate the $p$-th Wasserstein distance between point sets. Very importantly, the required model complexity is independent of t",
    "link": "http://arxiv.org/abs/2308.00273",
    "context": "Title: Neural approximation of Wasserstein distance via a universal architecture for symmetric and factorwise group invariant functions. (arXiv:2308.00273v1 [cs.LG])\nAbstract: Learning distance functions between complex objects, such as the Wasserstein distance to compare point sets, is a common goal in machine learning applications. However, functions on such complex objects (e.g., point sets and graphs) are often required to be invariant to a wide variety of group actions e.g. permutation or rigid transformation. Therefore, continuous and symmetric product functions (such as distance functions) on such complex objects must also be invariant to the product of such group actions. We call these functions symmetric and factor-wise group invariant (or SFGI functions in short). In this paper, we first present a general neural network architecture for approximating SFGI functions. The main contribution of this paper combines this general neural network with a sketching idea to develop a specific and efficient neural network which can approximate the $p$-th Wasserstein distance between point sets. Very importantly, the required model complexity is independent of t",
    "path": "papers/23/08/2308.00273.json",
    "total_tokens": 923,
    "translated_title": "通过一种对称和分量组不变功能的通用架构近似Wasserstein距离的神经网络",
    "translated_abstract": "学习复杂对象之间的距离函数，比如用于比较点集的Wasserstein距离，在机器学习应用中是一个常见的目标。然而，对于这种复杂对象（如点集和图形），函数往往需要对各种群操作（如排列或刚性变换）具有不变性。因此，这些复杂对象上的连续对称乘积函数（例如距离函数）也必须对这些群操作的乘积具有不变性。我们将这些函数称为对称和分量组不变函数（简称SFGI函数）。本文首先提出了一种用于近似SFGI函数的通用神经网络架构。本文的主要贡献是将这个通用神经网络与一个素描思想结合起来，开发出一种具体且高效的神经网络，可以近似点集之间的$p$-th Wasserstein距离。非常重要的是，所需的模型复杂度与点集的大小和维度无关。",
    "tldr": "本文提出了一种通用神经网络架构来近似对称和分量组不变的函数，并将其与素描思想结合起来构建了一个用于近似点集之间Wasserstein距离的具体且高效的神经网络模型。"
}