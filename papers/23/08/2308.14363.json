{
    "title": "Rethinking Mobile AI Ecosystem in the LLM Era",
    "abstract": "arXiv:2308.14363v2 Announce Type: replace  Abstract: In today's landscape, smartphones have evolved into hubs for hosting a multitude of deep learning models aimed at local execution. A key realization driving this work is the notable fragmentation among these models, characterized by varied architectures, operators, and implementations. This fragmentation imposes a significant burden on the comprehensive optimization of hardware, system settings, and algorithms.   Buoyed by the recent strides in large foundation models, this work introduces a pioneering paradigm for mobile AI: a collaborative management approach between the mobile OS and hardware, overseeing a foundational model capable of serving a broad spectrum of mobile AI tasks, if not all. This foundational model resides within the NPU and remains impervious to app or OS revisions, akin to firmware. Concurrently, each app contributes a concise, offline fine-tuned \"adapter\" tailored to distinct downstream tasks. From this concept",
    "link": "https://arxiv.org/abs/2308.14363",
    "context": "Title: Rethinking Mobile AI Ecosystem in the LLM Era\nAbstract: arXiv:2308.14363v2 Announce Type: replace  Abstract: In today's landscape, smartphones have evolved into hubs for hosting a multitude of deep learning models aimed at local execution. A key realization driving this work is the notable fragmentation among these models, characterized by varied architectures, operators, and implementations. This fragmentation imposes a significant burden on the comprehensive optimization of hardware, system settings, and algorithms.   Buoyed by the recent strides in large foundation models, this work introduces a pioneering paradigm for mobile AI: a collaborative management approach between the mobile OS and hardware, overseeing a foundational model capable of serving a broad spectrum of mobile AI tasks, if not all. This foundational model resides within the NPU and remains impervious to app or OS revisions, akin to firmware. Concurrently, each app contributes a concise, offline fine-tuned \"adapter\" tailored to distinct downstream tasks. From this concept",
    "path": "papers/23/08/2308.14363.json",
    "total_tokens": 883,
    "translated_title": "在LLM时代重新思考移动AI生态系统",
    "translated_abstract": "在今天的背景下，智能手机已经演变成了托管多种深度学习模型的中心，旨在进行本地执行。推动这项工作的一个关键意识是这些模型之间的显著分散性，其特点是不同的架构、运算符和实现。这种分散性给硬件、系统设置和算法的全面优化带来了重大负担。在最近的大型基础模型取得重大进展的推动下，这项工作引入了一种移动AI的开创性范式：移动操作系统和硬件之间的协作管理方法，监督具有为广泛移动AI任务提供服务能力的基础模型，即使还不能为所有任务提供服务。这个基础模型驻留在NPU内部，类似于固件，不受应用或操作系统的修订的影响。同时，每个应用程序都会贡献一个简洁的、离线微调的“适配器”，用于特定的下游任务。",
    "tldr": "重新思考移动AI生态系统，引入了一种基于协作管理的范式，通过在NPU内部放置不受应用或操作系统修订影响的基础模型，以及每个应用贡献特定的适配器，为广泛移动AI任务提供服务。",
    "en_tdlr": "Rethinking the mobile AI ecosystem, this work introduces a paradigm based on collaborative management, placing an app-agnostic foundational model within the NPU, and having each app contribute specific adapters for a wide range of mobile AI tasks."
}