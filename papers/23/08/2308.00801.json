{
    "title": "Artificial Eye for the Blind. (arXiv:2308.00801v1 [cs.CV])",
    "abstract": "The main backbone of our Artificial Eye model is the Raspberry pi3 which is connected to the webcam ,ultrasonic proximity sensor, speaker and we also run all our software models i.e object detection, Optical Character recognition, google text to speech conversion and the Mycroft voice assistance model. At first the ultrasonic proximity sensor will be measuring the distance between itself and any obstacle in front of it .When the Proximity sensor detects any obstacle in front within its specified range, the blind person will hear an audio prompt about an obstacle in his way at a certain distance. At this time the Webcam will capture an image in front of it and the Object detection model and the Optical Character Recognition model will begin to run on the Raspberry pi. The imat of the blind person. The text and the object detected are conveyed to the blind pege captured is first sent through the Tesseract OCR module to detect any texts in the image and then through the Object detection m",
    "link": "http://arxiv.org/abs/2308.00801",
    "context": "Title: Artificial Eye for the Blind. (arXiv:2308.00801v1 [cs.CV])\nAbstract: The main backbone of our Artificial Eye model is the Raspberry pi3 which is connected to the webcam ,ultrasonic proximity sensor, speaker and we also run all our software models i.e object detection, Optical Character recognition, google text to speech conversion and the Mycroft voice assistance model. At first the ultrasonic proximity sensor will be measuring the distance between itself and any obstacle in front of it .When the Proximity sensor detects any obstacle in front within its specified range, the blind person will hear an audio prompt about an obstacle in his way at a certain distance. At this time the Webcam will capture an image in front of it and the Object detection model and the Optical Character Recognition model will begin to run on the Raspberry pi. The imat of the blind person. The text and the object detected are conveyed to the blind pege captured is first sent through the Tesseract OCR module to detect any texts in the image and then through the Object detection m",
    "path": "papers/23/08/2308.00801.json",
    "total_tokens": 793,
    "translated_title": "盲人的人工眼睛",
    "translated_abstract": "我们的人工眼睛模型的主要支柱是连接到网络摄像头、超声波近距离传感器、扬声器的树莓派3，我们还运行了所有的软件模型，包括目标检测、光学字符识别、谷歌文本转语音和Mycroft语音辅助模型。当超声波近距离传感器检测到其前方有任何障碍物时，盲人将收到一段关于前方障碍物及其距离的音频提示。此时，网络摄像头将捕捉前方的图像，并在树莓派上运行目标检测模型和光学字符识别模型。捕捉到的图像首先通过Tesseract OCR模块检测图像中的文本，然后通过目标检测模型识别图像中的物体。",
    "tldr": "人工眼睛模型通过网络摄像头、超声波传感器和软件模型实现盲人的障碍物检测和光学字符识别。",
    "en_tdlr": "The Artificial Eye model uses a webcam, ultrasonic proximity sensor, and software models to detect obstacles and perform optical character recognition for blind individuals."
}