{
    "title": "InstructME: An Instruction Guided Music Edit And Remix Framework with Latent Diffusion Models. (arXiv:2308.14360v2 [cs.SD] UPDATED)",
    "abstract": "Music editing primarily entails the modification of instrument tracks or remixing in the whole, which offers a novel reinterpretation of the original piece through a series of operations. These music processing methods hold immense potential across various applications but demand substantial expertise. Prior methodologies, although effective for image and audio modifications, falter when directly applied to music. This is attributed to music's distinctive data nature, where such methods can inadvertently compromise the intrinsic harmony and coherence of music. In this paper, we develop InstructME, an Instruction guided Music Editing and remixing framework based on latent diffusion models. Our framework fortifies the U-Net with multi-scale aggregation in order to maintain consistency before and after editing. In addition, we introduce chord progression matrix as condition information and incorporate it in the semantic space to improve melodic harmony while editing. For accommodating ext",
    "link": "http://arxiv.org/abs/2308.14360",
    "context": "Title: InstructME: An Instruction Guided Music Edit And Remix Framework with Latent Diffusion Models. (arXiv:2308.14360v2 [cs.SD] UPDATED)\nAbstract: Music editing primarily entails the modification of instrument tracks or remixing in the whole, which offers a novel reinterpretation of the original piece through a series of operations. These music processing methods hold immense potential across various applications but demand substantial expertise. Prior methodologies, although effective for image and audio modifications, falter when directly applied to music. This is attributed to music's distinctive data nature, where such methods can inadvertently compromise the intrinsic harmony and coherence of music. In this paper, we develop InstructME, an Instruction guided Music Editing and remixing framework based on latent diffusion models. Our framework fortifies the U-Net with multi-scale aggregation in order to maintain consistency before and after editing. In addition, we introduce chord progression matrix as condition information and incorporate it in the semantic space to improve melodic harmony while editing. For accommodating ext",
    "path": "papers/23/08/2308.14360.json",
    "total_tokens": 904,
    "translated_title": "InstructME:一个基于潜在扩散模型的指导音乐编辑和混音框架",
    "translated_abstract": "音乐编辑主要涉及到修改乐器轨道或整体混音，通过一系列操作为原始作品提供了新颖的重新诠释。这些音乐处理方法在各种应用中具有巨大的潜力，但需要深厚的专业知识。以往的方法虽然对图像和音频修改有效，但直接应用于音乐时存在问题。这归因于音乐的独特数据性质，这些方法可能会无意中破坏音乐的内在和谐一致性。本文介绍了InstructME，一种基于潜在扩散模型的指导音乐编辑和混音框架。我们的框架在编辑之前和之后通过多尺度聚合强化了U-Net以保持一致性。此外，我们引入了和弦进展矩阵作为条件信息，并将其融入语义空间以提高编辑时的旋律和谐性。为了适应外部需求，我们还创新地提出了半监督学习方法来改进混音质量。",
    "tldr": "InstructME是一个基于潜在扩散模型的指导音乐编辑和混音框架，通过多尺度聚合和引入和弦进展矩阵来保持编辑的一致性和提高旋律和谐性。",
    "en_tdlr": "InstructME is an instruction guided music editing and remixing framework based on latent diffusion models. It maintains consistency in editing through multi-scale aggregation and improves melodic harmony by introducing chord progression matrix."
}