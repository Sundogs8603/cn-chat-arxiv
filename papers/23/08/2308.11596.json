{
    "title": "SeamlessM4T-Massively Multilingual & Multimodal Machine Translation. (arXiv:2308.11596v1 [cs.CL])",
    "abstract": "What does it take to create the Babel Fish, a tool that can help individuals translate speech between any two languages? While recent breakthroughs in text-based models have pushed machine translation coverage beyond 200 languages, unified speech-to-speech translation models have yet to achieve similar strides. More specifically, conventional speech-to-speech translation systems rely on cascaded systems that perform translation progressively, putting high-performing unified systems out of reach. To address these gaps, we introduce SeamlessM4T, a single model that supports speech-to-speech translation, speech-to-text translation, text-to-speech translation, text-to-text translation, and automatic speech recognition for up to 100 languages. To build this, we used 1 million hours of open speech audio data to learn self-supervised speech representations with w2v-BERT 2.0. Subsequently, we created a multimodal corpus of automatically aligned speech translations. Filtered and combined with h",
    "link": "http://arxiv.org/abs/2308.11596",
    "context": "Title: SeamlessM4T-Massively Multilingual & Multimodal Machine Translation. (arXiv:2308.11596v1 [cs.CL])\nAbstract: What does it take to create the Babel Fish, a tool that can help individuals translate speech between any two languages? While recent breakthroughs in text-based models have pushed machine translation coverage beyond 200 languages, unified speech-to-speech translation models have yet to achieve similar strides. More specifically, conventional speech-to-speech translation systems rely on cascaded systems that perform translation progressively, putting high-performing unified systems out of reach. To address these gaps, we introduce SeamlessM4T, a single model that supports speech-to-speech translation, speech-to-text translation, text-to-speech translation, text-to-text translation, and automatic speech recognition for up to 100 languages. To build this, we used 1 million hours of open speech audio data to learn self-supervised speech representations with w2v-BERT 2.0. Subsequently, we created a multimodal corpus of automatically aligned speech translations. Filtered and combined with h",
    "path": "papers/23/08/2308.11596.json",
    "total_tokens": 1018,
    "translated_title": "SeamlessM4T-大规模多语言和多模态机器翻译",
    "translated_abstract": "创造一种类似于巴别鱼的工具，能够帮助个人在任意两种语言之间进行语音翻译，需要付出什么样的努力？虽然最近在基于文本的模型方面取得了突破，使机器翻译的覆盖范围超过了200种语言，但统一的语音到语音翻译模型还没有取得类似的进展。更具体地说，传统的语音到语音翻译系统依赖于渐进式的级联系统进行翻译，使高性能的统一系统难以实现。为了弥补这些差距，我们引入了SeamlessM4T，一种支持语音到语音翻译、语音到文本翻译、文本到语音翻译、文本到文本翻译以及自动语音识别的单一模型，支持多达100种语言。为了构建这个模型，我们使用了100万小时的开放式语音音频数据，使用了w2v-BERT 2.0来学习自监督的语音表示。随后，我们创建了一个多模态的自动对齐语音翻译的语料库。",
    "tldr": "本文介绍了SeamlessM4T，这是一个支持多语言和多模态机器翻译的模型，通过使用大量语音数据和自监督学习，实现了统一的语音到语音翻译、语音到文本翻译、文本到语音翻译和文本到文本翻译，以及自动语音识别的功能。",
    "en_tdlr": "This paper introduces SeamlessM4T, a model that supports massively multilingual and multimodal machine translation. It achieves unified speech-to-speech translation, speech-to-text translation, text-to-speech translation, text-to-text translation, and automatic speech recognition through the use of large amounts of speech data and self-supervised learning."
}