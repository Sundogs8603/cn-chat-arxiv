{
    "title": "Explainable AI applications in the Medical Domain: a systematic review. (arXiv:2308.05411v1 [cs.AI])",
    "abstract": "Artificial Intelligence in Medicine has made significant progress with emerging applications in medical imaging, patient care, and other areas. While these applications have proven successful in retrospective studies, very few of them were applied in practice.The field of Medical AI faces various challenges, in terms of building user trust, complying with regulations, using data ethically.Explainable AI (XAI) aims to enable humans understand AI and trust its results. This paper presents a literature review on the recent developments of XAI solutions for medical decision support, based on a representative sample of 198 articles published in recent years. The systematic synthesis of the relevant articles resulted in several findings. (1) model-agnostic XAI techniques were mostly employed in these solutions, (2) deep learning models are utilized more than other types of machine learning models, (3) explainability was applied to promote trust, but very few works reported the physicians par",
    "link": "http://arxiv.org/abs/2308.05411",
    "context": "Title: Explainable AI applications in the Medical Domain: a systematic review. (arXiv:2308.05411v1 [cs.AI])\nAbstract: Artificial Intelligence in Medicine has made significant progress with emerging applications in medical imaging, patient care, and other areas. While these applications have proven successful in retrospective studies, very few of them were applied in practice.The field of Medical AI faces various challenges, in terms of building user trust, complying with regulations, using data ethically.Explainable AI (XAI) aims to enable humans understand AI and trust its results. This paper presents a literature review on the recent developments of XAI solutions for medical decision support, based on a representative sample of 198 articles published in recent years. The systematic synthesis of the relevant articles resulted in several findings. (1) model-agnostic XAI techniques were mostly employed in these solutions, (2) deep learning models are utilized more than other types of machine learning models, (3) explainability was applied to promote trust, but very few works reported the physicians par",
    "path": "papers/23/08/2308.05411.json",
    "total_tokens": 937,
    "translated_title": "医学领域可解释的人工智能应用：一项系统综述",
    "translated_abstract": "医学人工智能在医学影像、患者护理和其他领域取得了显著进展。虽然这些应用在回顾性研究中取得了成功，但实际上很少有应用。医学人工智能领域面临着建立用户信任、遵守法规、合理使用数据等各种挑战。可解释的人工智能（XAI）旨在使人类理解人工智能并信任其结果。本文基于最近几年发表的198篇文章，对医学决策支持的XAI解决方案的最新发展进行了文献综述。相关文章的系统综合产生了几个发现：（1）这些解决方案主要采用了通用模型的XAI技术，（2）相比其他类型的机器学习模型，深度学习模型被更多地使用，（3）解释性被应用于提高信任，但很少有工作报道了医生的参与。",
    "tldr": "该论文通过文献综述探讨了医学决策支持中可解释的人工智能解决方案的最新发展，结果发现通用模型的XAI技术被广泛采用，深度学习模型被更多使用，解释性被应用于提高信任，但医生的参与仍较少报道。",
    "en_tdlr": "This paper presents a literature review on the recent developments of explainable AI solutions for medical decision support, showing that model-agnostic XAI techniques are widely employed, deep learning models are utilized more, explainability is applied to promote trust, but the involvement of physicians is rarely reported."
}