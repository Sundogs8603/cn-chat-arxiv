{
    "title": "cantnlp@LT-EDI-2023: Homophobia/Transphobia Detection in Social Media Comments using Spatio-Temporally Retrained Language Models. (arXiv:2308.10370v2 [cs.CL] UPDATED)",
    "abstract": "This paper describes our multiclass classification system developed as part of the LTEDI@RANLP-2023 shared task. We used a BERT-based language model to detect homophobic and transphobic content in social media comments across five language conditions: English, Spanish, Hindi, Malayalam, and Tamil. We retrained a transformer-based crosslanguage pretrained language model, XLMRoBERTa, with spatially and temporally relevant social media language data. We also retrained a subset of models with simulated script-mixed social media language data with varied performance. We developed the best performing seven-label classification system for Malayalam based on weighted macro averaged F1 score (ranked first out of six) with variable performance for other language and class-label conditions. We found the inclusion of this spatio-temporal data improved the classification performance for all language and task conditions when compared with the baseline. The results suggests that transformer-based lan",
    "link": "http://arxiv.org/abs/2308.10370",
    "context": "Title: cantnlp@LT-EDI-2023: Homophobia/Transphobia Detection in Social Media Comments using Spatio-Temporally Retrained Language Models. (arXiv:2308.10370v2 [cs.CL] UPDATED)\nAbstract: This paper describes our multiclass classification system developed as part of the LTEDI@RANLP-2023 shared task. We used a BERT-based language model to detect homophobic and transphobic content in social media comments across five language conditions: English, Spanish, Hindi, Malayalam, and Tamil. We retrained a transformer-based crosslanguage pretrained language model, XLMRoBERTa, with spatially and temporally relevant social media language data. We also retrained a subset of models with simulated script-mixed social media language data with varied performance. We developed the best performing seven-label classification system for Malayalam based on weighted macro averaged F1 score (ranked first out of six) with variable performance for other language and class-label conditions. We found the inclusion of this spatio-temporal data improved the classification performance for all language and task conditions when compared with the baseline. The results suggests that transformer-based lan",
    "path": "papers/23/08/2308.10370.json",
    "total_tokens": 1087,
    "translated_title": "cantnlp@LT-EDI-2023: 使用时空重新训练的语言模型在社交媒体评论中检测恐同与恐惧跨性别内容",
    "translated_abstract": "本文描述了我们作为LTEDI@RANLP-2023共享任务的一部分开发的多分类系统。我们使用基于BERT的语言模型来检测社交媒体评论中的恐同和恐惧跨性别内容，涵盖英语、西班牙语、印地语、马拉雅拉姆语和泰米尔语五种语言条件。我们使用时空相关的社交媒体语言数据对基于Transformer的跨语言预训练语言模型XLMRoBERTa进行重新训练。我们还使用模拟的混合脚本社交媒体语言数据对部分模型进行重新训练，其性能有所变化。我们为马拉雅拉姆语开发了表现最好的七种标签分类系统，基于加权宏平均F1得分（在六个系统中排名第一），其他语言和类别标签条件下的性能有所差异。我们发现，将这种时空数据纳入分类性能相对于基线模型在所有语言和任务条件下都有所提升。结果表明，基于Transformer的语言模型经过时空训练可以有效检测社交媒体评论中的恐同与恐惧跨性别内容。",
    "tldr": "本文介绍了我们开发的多分类系统，使用基于BERT的语言模型在五种语言条件下检测社交媒体评论中的恐同和恐惧跨性别内容。我们通过时空相关的社交媒体语言数据对跨语言预训练语言模型进行了重新训练，取得了表现最好的七种标签分类系统。结果显示，时空训练可以提高分类性能，有效检测社交媒体评论中的恐同和恐惧跨性别内容。",
    "en_tdlr": "This paper presents a multiclass classification system using a BERT-based language model to detect homophobic and transphobic content in social media comments in five languages. The system achieved the best performance with a seven-label classification system in Malayalam and demonstrated improved classification performance by incorporating spatio-temporally relevant social media language data."
}