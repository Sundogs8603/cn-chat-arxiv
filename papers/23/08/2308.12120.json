{
    "title": "An Open-Source ML-Based Full-Stack Optimization Framework for Machine Learning Accelerators. (arXiv:2308.12120v1 [cs.LG])",
    "abstract": "Parameterizable machine learning (ML) accelerators are the product of recent breakthroughs in ML. To fully enable their design space exploration (DSE), we propose a physical-design-driven, learning-based prediction framework for hardware-accelerated deep neural network (DNN) and non-DNN ML algorithms. It adopts a unified approach that combines backend power, performance, and area (PPA) analysis with frontend performance simulation, thereby achieving a realistic estimation of both backend PPA and system metrics such as runtime and energy. In addition, our framework includes a fully automated DSE technique, which optimizes backend and system metrics through an automated search of architectural and backend parameters. Experimental studies show that our approach consistently predicts backend PPA and system metrics with an average 7% or less prediction error for the ASIC implementation of two deep learning accelerator platforms, VTA and VeriGOOD-ML, in both a commercial 12 nm process and a ",
    "link": "http://arxiv.org/abs/2308.12120",
    "context": "Title: An Open-Source ML-Based Full-Stack Optimization Framework for Machine Learning Accelerators. (arXiv:2308.12120v1 [cs.LG])\nAbstract: Parameterizable machine learning (ML) accelerators are the product of recent breakthroughs in ML. To fully enable their design space exploration (DSE), we propose a physical-design-driven, learning-based prediction framework for hardware-accelerated deep neural network (DNN) and non-DNN ML algorithms. It adopts a unified approach that combines backend power, performance, and area (PPA) analysis with frontend performance simulation, thereby achieving a realistic estimation of both backend PPA and system metrics such as runtime and energy. In addition, our framework includes a fully automated DSE technique, which optimizes backend and system metrics through an automated search of architectural and backend parameters. Experimental studies show that our approach consistently predicts backend PPA and system metrics with an average 7% or less prediction error for the ASIC implementation of two deep learning accelerator platforms, VTA and VeriGOOD-ML, in both a commercial 12 nm process and a ",
    "path": "papers/23/08/2308.12120.json",
    "total_tokens": 890,
    "translated_title": "一个开源的基于机器学习的全栈优化框架用于机器学习加速器",
    "translated_abstract": "可参数化的机器学习（ML）加速器是近期ML领域的突破成果。为了完全实现其设计空间探索（DSE），我们提出了一个物理设计驱动的、基于学习的预测框架，用于深度神经网络（DNN）和非DNN ML算法的硬件加速。该框架采用了统一的方法，将后端功耗、性能和面积（PPA）分析与前端性能模拟结合起来，从而实现对后端PPA和系统指标（如运行时间和能量）的真实估计。此外，我们的框架还包括了完全自动化的DSE技术，通过对架构和后端参数的自动搜索来优化后端和系统指标。实验研究表明，我们的方法始终以平均7%或更低的预测误差准确预测了两个深度学习加速器平台（VTA和VeriGOOD-ML）在商业12纳米工艺和。",
    "tldr": "本论文提出了一个开源的机器学习加速器全栈优化框架，结合了后端和前端模拟，可以实现准确的系统指标估计和架构参数的自动优化。"
}