{
    "title": "Is GPT-4 a reliable rater? Evaluating Consistency in GPT-4 Text Ratings. (arXiv:2308.02575v1 [cs.CL])",
    "abstract": "This study investigates the consistency of feedback ratings generated by OpenAI's GPT-4, a state-of-the-art artificial intelligence language model, across multiple iterations, time spans and stylistic variations. The model rated responses to tasks within the Higher Education (HE) subject domain of macroeconomics in terms of their content and style. Statistical analysis was conducted in order to learn more about the interrater reliability, consistency of the ratings across iterations and the correlation between ratings in terms of content and style. The results revealed a high interrater reliability with ICC scores ranging between 0.94 and 0.99 for different timespans, suggesting that GPT-4 is capable of generating consistent ratings across repetitions with a clear prompt. Style and content ratings show a high correlation of 0.87. When applying a non-adequate style the average content ratings remained constant, while style ratings decreased, which indicates that the large language model",
    "link": "http://arxiv.org/abs/2308.02575",
    "context": "Title: Is GPT-4 a reliable rater? Evaluating Consistency in GPT-4 Text Ratings. (arXiv:2308.02575v1 [cs.CL])\nAbstract: This study investigates the consistency of feedback ratings generated by OpenAI's GPT-4, a state-of-the-art artificial intelligence language model, across multiple iterations, time spans and stylistic variations. The model rated responses to tasks within the Higher Education (HE) subject domain of macroeconomics in terms of their content and style. Statistical analysis was conducted in order to learn more about the interrater reliability, consistency of the ratings across iterations and the correlation between ratings in terms of content and style. The results revealed a high interrater reliability with ICC scores ranging between 0.94 and 0.99 for different timespans, suggesting that GPT-4 is capable of generating consistent ratings across repetitions with a clear prompt. Style and content ratings show a high correlation of 0.87. When applying a non-adequate style the average content ratings remained constant, while style ratings decreased, which indicates that the large language model",
    "path": "papers/23/08/2308.02575.json",
    "total_tokens": 769,
    "translated_title": "GPT-4是一个可靠的评分器吗？评估GPT-4文本评分的一致性。",
    "translated_abstract": "本研究调查了OpenAI的GPT-4在多个迭代、时间跨度和文体变化中生成的反馈评分的一致性。该模型根据内容和文体对宏观经济学学科领域内的任务回答进行评分。通过统计分析，研究了评分的一致性、迭代之间的评分相关性以及内容和文体评分之间的相关性。结果显示，不同时间跨度的ICC分数在0.94到0.99之间，表明GPT-4能够在重复任务中生成一致的评分。内容和文体评分之间的相关性为0.87。当应用不恰当的文体时，平均内容评分保持不变，而文体评分下降，这表明大型语言模型在生成一致评分方面具有能力。",
    "tldr": "GPT-4在多个迭代中生成的反馈评分具有高一致性，内容和文体评分之间具有高相关性。"
}