{
    "title": "CoverNav: Cover Following Navigation Planning in Unstructured Outdoor Environment with Deep Reinforcement Learning. (arXiv:2308.06594v1 [cs.RO])",
    "abstract": "Autonomous navigation in offroad environments has been extensively studied in the robotics field. However, navigation in covert situations where an autonomous vehicle needs to remain hidden from outside observers remains an underexplored area. In this paper, we propose a novel Deep Reinforcement Learning (DRL) based algorithm, called CoverNav, for identifying covert and navigable trajectories with minimal cost in offroad terrains and jungle environments in the presence of observers. CoverNav focuses on unmanned ground vehicles seeking shelters and taking covers while safely navigating to a predefined destination. Our proposed DRL method computes a local cost map that helps distinguish which path will grant the maximal covertness while maintaining a low cost trajectory using an elevation map generated from 3D point cloud data, the robot's pose, and directed goal information. CoverNav helps robot agents to learn the low elevation terrain using a reward function while penalizing it propor",
    "link": "http://arxiv.org/abs/2308.06594",
    "context": "Title: CoverNav: Cover Following Navigation Planning in Unstructured Outdoor Environment with Deep Reinforcement Learning. (arXiv:2308.06594v1 [cs.RO])\nAbstract: Autonomous navigation in offroad environments has been extensively studied in the robotics field. However, navigation in covert situations where an autonomous vehicle needs to remain hidden from outside observers remains an underexplored area. In this paper, we propose a novel Deep Reinforcement Learning (DRL) based algorithm, called CoverNav, for identifying covert and navigable trajectories with minimal cost in offroad terrains and jungle environments in the presence of observers. CoverNav focuses on unmanned ground vehicles seeking shelters and taking covers while safely navigating to a predefined destination. Our proposed DRL method computes a local cost map that helps distinguish which path will grant the maximal covertness while maintaining a low cost trajectory using an elevation map generated from 3D point cloud data, the robot's pose, and directed goal information. CoverNav helps robot agents to learn the low elevation terrain using a reward function while penalizing it propor",
    "path": "papers/23/08/2308.06594.json",
    "total_tokens": 1055,
    "translated_title": "CoverNav：利用深度强化学习在非结构化室外环境中进行隐蔽导航规划",
    "translated_abstract": "在机器人领域中，已经广泛研究了在越野环境中的自主导航。然而，在需要将自动驾驶车辆从外部观察者隐藏起来的隐蔽情况下的导航仍然是一个不完全开发的领域。在本文中，我们提出了一种新颖的基于深度强化学习（DRL）的算法，称为CoverNav，用于在越野地形和丛林环境中识别具有最小代价的隐蔽和可导航轨迹。CoverNav专注于无人地面车辆在安全导航到预定目的地的同时寻找避难所并找到掩护。我们的DRL方法计算一个本地代价地图，通过从3D点云数据、机器人的姿态和目标导向信息生成的海拔地图来区分哪条路径将提供最大的隐蔽性，同时保持低成本轨迹。CoverNav帮助机器人智能体使用奖励函数学习低海拔地形，同时对它进行惩罚。",
    "tldr": "本文提出了一种名为CoverNav的基于深度强化学习的算法，用于在隐蔽和可导航的路径上进行非结构化室外环境的自主导航规划。该算法通过生成海拔地图来计算本地代价，帮助机器人智能体在保持低成本轨迹的同时选择最大的隐蔽性。这对于无人地面车辆在寻找避难所和掩护的同时安全导航至目的地非常有帮助。",
    "en_tdlr": "This paper proposes a Deep Reinforcement Learning (DRL) based algorithm called CoverNav for autonomous navigation planning in covert and navigable paths in unstructured outdoor environments. The algorithm computes a local cost map using an elevation map, helping robot agents choose paths with maximal covertness while maintaining low cost trajectories. This is beneficial for unmanned ground vehicles to navigate safely to a destination while finding shelters and covers."
}