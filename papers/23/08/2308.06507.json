{
    "title": "AutoConv: Automatically Generating Information-seeking Conversations with Large Language Models. (arXiv:2308.06507v1 [cs.CL])",
    "abstract": "Information-seeking conversation, which aims to help users gather information through conversation, has achieved great progress in recent years. However, the research is still stymied by the scarcity of training data. To alleviate this problem, we propose AutoConv for synthetic conversation generation, which takes advantage of the few-shot learning ability and generation capacity of large language models (LLM). Specifically, we formulate the conversation generation problem as a language modeling task, then finetune an LLM with a few human conversations to capture the characteristics of the information-seeking process and use it for generating synthetic conversations with high quality. Experimental results on two frequently-used datasets verify that AutoConv has substantial improvements over strong baselines and alleviates the dependence on human annotation. In addition, we also provide several analysis studies to promote future research.",
    "link": "http://arxiv.org/abs/2308.06507",
    "context": "Title: AutoConv: Automatically Generating Information-seeking Conversations with Large Language Models. (arXiv:2308.06507v1 [cs.CL])\nAbstract: Information-seeking conversation, which aims to help users gather information through conversation, has achieved great progress in recent years. However, the research is still stymied by the scarcity of training data. To alleviate this problem, we propose AutoConv for synthetic conversation generation, which takes advantage of the few-shot learning ability and generation capacity of large language models (LLM). Specifically, we formulate the conversation generation problem as a language modeling task, then finetune an LLM with a few human conversations to capture the characteristics of the information-seeking process and use it for generating synthetic conversations with high quality. Experimental results on two frequently-used datasets verify that AutoConv has substantial improvements over strong baselines and alleviates the dependence on human annotation. In addition, we also provide several analysis studies to promote future research.",
    "path": "papers/23/08/2308.06507.json",
    "total_tokens": 775,
    "translated_title": "使用大型语言模型自动生成信息寻求对话",
    "translated_abstract": "近年来，通过对话帮助用户收集信息的信息寻求对话取得了巨大进展。然而，研究仍受到训练数据稀缺的困扰。为了解决这个问题，我们提出了AutoConv用于合成对话生成，利用大型语言模型（LLM）的少样本学习能力和生成能力。具体而言，我们将对话生成问题制定为语言建模任务，然后使用少量人类对话微调LLM，以捕捉信息寻求过程的特征，并用之生成具有高质量的合成对话。在两个常用数据集上的实验结果验证了AutoConv相对于强基线的显著改进，减轻了对人工注释的依赖。此外，我们还提供了几个分析研究以促进未来研究。",
    "tldr": "AutoConv利用大型语言模型自动生成高质量的信息寻求对话，相对于强基线具有显著改进，并减轻了对人工注释的依赖。",
    "en_tdlr": "AutoConv utilizes large language models to automatically generate high-quality information-seeking conversations, exhibiting significant improvements over strong baselines and reducing the reliance on human annotation."
}