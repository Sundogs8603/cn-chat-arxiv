{
    "title": "Adaptive White-Box Watermarking with Self-Mutual Check Parameters in Deep Neural Networks. (arXiv:2308.11235v1 [cs.CR])",
    "abstract": "Artificial Intelligence (AI) has found wide application, but also poses risks due to unintentional or malicious tampering during deployment. Regular checks are therefore necessary to detect and prevent such risks. Fragile watermarking is a technique used to identify tampering in AI models. However, previous methods have faced challenges including risks of omission, additional information transmission, and inability to locate tampering precisely. In this paper, we propose a method for detecting tampered parameters and bits, which can be used to detect, locate, and restore parameters that have been tampered with. We also propose an adaptive embedding method that maximizes information capacity while maintaining model accuracy. Our approach was tested on multiple neural networks subjected to attacks that modified weight parameters, and our results demonstrate that our method achieved great recovery performance when the modification rate was below 20%. Furthermore, for models where watermar",
    "link": "http://arxiv.org/abs/2308.11235",
    "context": "Title: Adaptive White-Box Watermarking with Self-Mutual Check Parameters in Deep Neural Networks. (arXiv:2308.11235v1 [cs.CR])\nAbstract: Artificial Intelligence (AI) has found wide application, but also poses risks due to unintentional or malicious tampering during deployment. Regular checks are therefore necessary to detect and prevent such risks. Fragile watermarking is a technique used to identify tampering in AI models. However, previous methods have faced challenges including risks of omission, additional information transmission, and inability to locate tampering precisely. In this paper, we propose a method for detecting tampered parameters and bits, which can be used to detect, locate, and restore parameters that have been tampered with. We also propose an adaptive embedding method that maximizes information capacity while maintaining model accuracy. Our approach was tested on multiple neural networks subjected to attacks that modified weight parameters, and our results demonstrate that our method achieved great recovery performance when the modification rate was below 20%. Furthermore, for models where watermar",
    "path": "papers/23/08/2308.11235.json",
    "total_tokens": 945,
    "translated_title": "自适应白盒水印在深度神经网络中的应用与自我互助检查参数",
    "translated_abstract": "人工智能在各个领域得到了广泛应用，但在部署过程中也面临着意外或恶意篡改的风险。为了检测和防止这些风险，需要进行定期检查。脆弱水印技术可以用来识别人工智能模型中的篡改。然而，之前的方法存在着遗漏的风险、额外信息传输的问题以及无法精确定位篡改的问题。本文提出了一种检测篡改参数和位的方法，该方法可以用来检测、定位和恢复被篡改的参数。我们还提出了一种自适应嵌入方法，该方法在保持模型准确性的同时最大化信息容量。我们的方法在多个经受了修改权重参数攻击的神经网络上进行了测试，结果表明在修改率低于20%时，我们的方法具有出色的恢复性能。此外，对于使用水印的模型，这些水印的存在不会对模型的性能产生显著的影响。",
    "tldr": "本文提出了一种自适应白盒水印技术，通过自我互助检查参数来检测篡改的深度神经网络模型，并且提出了最大化信息容量的自适应嵌入方法。实验证明，当修改率低于20%时，该方法具有出色的恢复性能。"
}