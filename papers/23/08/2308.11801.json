{
    "title": "Variational Density Propagation Continual Learning. (arXiv:2308.11801v1 [cs.LG])",
    "abstract": "Deep Neural Networks (DNNs) deployed to the real world are regularly subject to out-of-distribution (OoD) data, various types of noise, and shifting conceptual objectives. This paper proposes a framework for adapting to data distribution drift modeled by benchmark Continual Learning datasets. We develop and evaluate a method of Continual Learning that leverages uncertainty quantification from Bayesian Inference to mitigate catastrophic forgetting. We expand on previous approaches by removing the need for Monte Carlo sampling of the model weights to sample the predictive distribution. We optimize a closed-form Evidence Lower Bound (ELBO) objective approximating the predictive distribution by propagating the first two moments of a distribution, i.e. mean and covariance, through all network layers. Catastrophic forgetting is mitigated by using the closed-form ELBO to approximate the Minimum Description Length (MDL) Principle, inherently penalizing changes in the model likelihood by minimi",
    "link": "http://arxiv.org/abs/2308.11801",
    "context": "Title: Variational Density Propagation Continual Learning. (arXiv:2308.11801v1 [cs.LG])\nAbstract: Deep Neural Networks (DNNs) deployed to the real world are regularly subject to out-of-distribution (OoD) data, various types of noise, and shifting conceptual objectives. This paper proposes a framework for adapting to data distribution drift modeled by benchmark Continual Learning datasets. We develop and evaluate a method of Continual Learning that leverages uncertainty quantification from Bayesian Inference to mitigate catastrophic forgetting. We expand on previous approaches by removing the need for Monte Carlo sampling of the model weights to sample the predictive distribution. We optimize a closed-form Evidence Lower Bound (ELBO) objective approximating the predictive distribution by propagating the first two moments of a distribution, i.e. mean and covariance, through all network layers. Catastrophic forgetting is mitigated by using the closed-form ELBO to approximate the Minimum Description Length (MDL) Principle, inherently penalizing changes in the model likelihood by minimi",
    "path": "papers/23/08/2308.11801.json",
    "total_tokens": 942,
    "translated_title": "变分密度传播连续学习",
    "translated_abstract": "在现实世界中部署的深度神经网络（DNN）经常面临来自分布外（OoD）数据、各种类型的噪声和概念目标的变化。本文提出了一个适应基准连续学习数据集建模的数据分布漂移的框架。我们开发和评估了一种利用贝叶斯推断中的不确定性量化来减轻灾难性遗忘的连续学习方法。我们通过消除模型权重的Monte Carlo采样来采样预测分布，扩展了之前的方法。我们通过在所有网络层中传播分布的前两个矩（即均值和协方差）来优化闭式证据下界（ELBO）目标，从而近似预测分布。通过使用闭式ELBO来近似最小描述长度（MDL）原则来缓解灾难性遗忘，从而惩罚模型似然性的变化。",
    "tldr": "本文提出了一个用于适应数据分布漂移的连续学习框架，并通过利用贝叶斯推断中的不确定性量化来减轻灾难性遗忘。通过传播分布的前两个矩来优化闭式ELBO目标，从而近似预测分布。这种方法消除了Monte Carlo采样的需要，有效惩罚模型似然性的变化。",
    "en_tdlr": "This paper proposes a framework for adapting to data distribution drift in continual learning and mitigating catastrophic forgetting by leveraging uncertainty quantification from Bayesian Inference. It optimizes a closed-form Evidence Lower Bound (ELBO) objective to approximate the predictive distribution by propagating the first two moments of a distribution, removing the need for Monte Carlo sampling and effectively penalizing changes in the model likelihood."
}