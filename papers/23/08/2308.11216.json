{
    "title": "Hamiltonian GAN. (arXiv:2308.11216v1 [cs.LG])",
    "abstract": "A growing body of work leverages the Hamiltonian formalism as an inductive bias for physically plausible neural network based video generation. The structure of the Hamiltonian ensures conservation of a learned quantity (e.g., energy) and imposes a phase-space interpretation on the low-dimensional manifold underlying the input video. While this interpretation has the potential to facilitate the integration of learned representations in downstream tasks, existing methods are limited in their applicability as they require a structural prior for the configuration space at design time. In this work, we present a GAN-based video generation pipeline with a learned configuration space map and Hamiltonian neural network motion model, to learn a representation of the configuration space from data. We train our model with a physics-inspired cyclic-coordinate loss function which encourages a minimal representation of the configuration space and improves interpretability. We demonstrate the effica",
    "link": "http://arxiv.org/abs/2308.11216",
    "context": "Title: Hamiltonian GAN. (arXiv:2308.11216v1 [cs.LG])\nAbstract: A growing body of work leverages the Hamiltonian formalism as an inductive bias for physically plausible neural network based video generation. The structure of the Hamiltonian ensures conservation of a learned quantity (e.g., energy) and imposes a phase-space interpretation on the low-dimensional manifold underlying the input video. While this interpretation has the potential to facilitate the integration of learned representations in downstream tasks, existing methods are limited in their applicability as they require a structural prior for the configuration space at design time. In this work, we present a GAN-based video generation pipeline with a learned configuration space map and Hamiltonian neural network motion model, to learn a representation of the configuration space from data. We train our model with a physics-inspired cyclic-coordinate loss function which encourages a minimal representation of the configuration space and improves interpretability. We demonstrate the effica",
    "path": "papers/23/08/2308.11216.json",
    "total_tokens": 869,
    "translated_title": "Hamiltonian GAN. (arXiv:2308.11216v1 [cs.LG])",
    "translated_abstract": "一系列越来越多的研究利用Hamiltonian形式主义作为物理上合理的神经网络视频生成的归纳偏见。Hamiltonian的结构确保了学习到的数量（如能量）的守恒，并在低维流形上给输入视频施加了一个相空间解释。虽然这种解释潜在地有助于在下游任务中整合学习到的表示，但现有方法在可行性上存在限制，因为它们需要在设计时对配置空间的结构先验知识。在这项工作中，我们提出了一种基于GAN的视频生成流程，其中包括了一个学习到的配置空间映射和Hamiltonian神经网络运动模型，以从数据中学习配置空间的表示。我们使用一种受物理启发的循环坐标损失函数来训练模型，这可以促进对配置空间的最小表示并提高可解释性。我们展示了这种方法的有效性。",
    "tldr": "这个论文提出了一种基于Hamiltonian的生成对抗网络（GAN）视频生成方法，通过学习配置空间映射和运动模型来生成合理的视频。训练过程中使用的物理启发式损失函数可以促进对最小配置空间的表示和提高可解释性。",
    "en_tdlr": "This paper presents a Hamiltonian GAN-based approach for video generation, which learns a configuration space map and a motion model to generate realistic videos. The training process incorporates a physics-inspired cyclic-coordinate loss function to encourage minimal representation of the configuration space and improve interpretability."
}