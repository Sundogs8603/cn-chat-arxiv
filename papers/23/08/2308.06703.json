{
    "title": "Understanding the robustness difference between stochastic gradient descent and adaptive gradient methods. (arXiv:2308.06703v1 [cs.LG])",
    "abstract": "Stochastic gradient descent (SGD) and adaptive gradient methods, such as Adam and RMSProp, have been widely used in training deep neural networks. We empirically show that while the difference between the standard generalization performance of models trained using these methods is small, those trained using SGD exhibit far greater robustness under input perturbations. Notably, our investigation demonstrates the presence of irrelevant frequencies in natural datasets, where alterations do not affect models' generalization performance. However, models trained with adaptive methods show sensitivity to these changes, suggesting that their use of irrelevant frequencies can lead to solutions sensitive to perturbations. To better understand this difference, we study the learning dynamics of gradient descent (GD) and sign gradient descent (signGD) on a synthetic dataset that mirrors natural signals. With a three-dimensional input space, the models optimized with GD and signGD have standard risk",
    "link": "http://arxiv.org/abs/2308.06703",
    "context": "Title: Understanding the robustness difference between stochastic gradient descent and adaptive gradient methods. (arXiv:2308.06703v1 [cs.LG])\nAbstract: Stochastic gradient descent (SGD) and adaptive gradient methods, such as Adam and RMSProp, have been widely used in training deep neural networks. We empirically show that while the difference between the standard generalization performance of models trained using these methods is small, those trained using SGD exhibit far greater robustness under input perturbations. Notably, our investigation demonstrates the presence of irrelevant frequencies in natural datasets, where alterations do not affect models' generalization performance. However, models trained with adaptive methods show sensitivity to these changes, suggesting that their use of irrelevant frequencies can lead to solutions sensitive to perturbations. To better understand this difference, we study the learning dynamics of gradient descent (GD) and sign gradient descent (signGD) on a synthetic dataset that mirrors natural signals. With a three-dimensional input space, the models optimized with GD and signGD have standard risk",
    "path": "papers/23/08/2308.06703.json",
    "total_tokens": 954,
    "translated_title": "理解随机梯度下降和自适应梯度方法之间的鲁棒性差异",
    "translated_abstract": "随机梯度下降（SGD）和自适应梯度方法，如Adam和RMSProp，在训练深度神经网络中被广泛使用。我们通过实验证明，虽然使用这些方法训练的模型的标准泛化性能之间的差异很小，但使用SGD训练的模型在输入扰动下表现出更大的鲁棒性。值得注意的是，我们的研究表明，在自然数据集中存在不相关的频率，对这些频率进行变动不会影响模型的泛化性能。然而，使用自适应方法训练的模型对这些变化显示出敏感性，这表明它们使用的不相关频率会导致对扰动敏感的解决方案。为了更好地理解这种差异，我们研究了梯度下降（GD）和符号梯度下降（signGD）在模拟自然信号的合成数据集上的学习动态。在三维输入空间中，使用GD和signGD优化的模型具有标准风险",
    "tldr": "我们通过实验证明，相比于自适应梯度方法，使用随机梯度下降（SGD）训练的模型在输入扰动下展现出更大的鲁棒性。这种差异可以归因于自适应方法使用了不相关的频率，导致对扰动敏感的解决方案。"
}