{
    "title": "Context Aware Query Rewriting for Text Rankers using LLM. (arXiv:2308.16753v1 [cs.IR])",
    "abstract": "Query rewriting refers to an established family of approaches that are applied to underspecified and ambiguous queries to overcome the vocabulary mismatch problem in document ranking. Queries are typically rewritten during query processing time for better query modelling for the downstream ranker. With the advent of large-language models (LLMs), there have been initial investigations into using generative approaches to generate pseudo documents to tackle this inherent vocabulary gap. In this work, we analyze the utility of LLMs for improved query rewriting for text ranking tasks. We find that there are two inherent limitations of using LLMs as query re-writers -- concept drift when using only queries as prompts and large inference costs during query processing. We adopt a simple, yet surprisingly effective, approach called context aware query rewriting (CAR) to leverage the benefits of LLMs for query understanding. Firstly, we rewrite ambiguous training queries by context-aware prompti",
    "link": "http://arxiv.org/abs/2308.16753",
    "context": "Title: Context Aware Query Rewriting for Text Rankers using LLM. (arXiv:2308.16753v1 [cs.IR])\nAbstract: Query rewriting refers to an established family of approaches that are applied to underspecified and ambiguous queries to overcome the vocabulary mismatch problem in document ranking. Queries are typically rewritten during query processing time for better query modelling for the downstream ranker. With the advent of large-language models (LLMs), there have been initial investigations into using generative approaches to generate pseudo documents to tackle this inherent vocabulary gap. In this work, we analyze the utility of LLMs for improved query rewriting for text ranking tasks. We find that there are two inherent limitations of using LLMs as query re-writers -- concept drift when using only queries as prompts and large inference costs during query processing. We adopt a simple, yet surprisingly effective, approach called context aware query rewriting (CAR) to leverage the benefits of LLMs for query understanding. Firstly, we rewrite ambiguous training queries by context-aware prompti",
    "path": "papers/23/08/2308.16753.json",
    "total_tokens": 882,
    "translated_title": "基于LLM的上下文感知查询重写方法用于文本排名",
    "translated_abstract": "查询重写是一类应用于不完全指定和模糊查询的方法，旨在克服文档排名中的词汇不匹配问题。查询通常在查询处理过程中进行重写，以便为下游排名器提供更好的查询建模。随着大语言模型（LLMs）的出现，已经开始研究使用生成方法生成伪文档来解决这种固有的词汇差距。在这项工作中，我们分析了LLMs在提高文本排名任务中查询重写的效用。我们发现使用LLMs作为查询重写器存在两个固有局限性--在仅使用查询作为提示时存在概念漂移，并且在查询处理过程中存在大量的推理开销。我们采用了一种简单但效果惊人的方法，称为上下文感知查询重写（CAR），以利用LLMs的优势进行查询理解。首先，我们通过上下文感知提示来重写模糊的训练查询，以在查询理解方面获得改进。",
    "tldr": "这项工作研究了使用基于LLM的上下文感知查询重写方法来提高文本排名任务。通过通过上下文感知提示来重写模糊的训练查询，克服了概念漂移和推理开销的固有局限性。"
}