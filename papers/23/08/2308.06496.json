{
    "title": "Performance Analysis for Resource Constrained Decentralized Federated Learning Over Wireless Networks. (arXiv:2308.06496v1 [cs.LG])",
    "abstract": "Federated learning (FL) can lead to significant communication overhead and reliance on a central server. To address these challenges, decentralized federated learning (DFL) has been proposed as a more resilient framework. DFL involves parameter exchange between devices through a wireless network. This study analyzes the performance of resource-constrained DFL using different communication schemes (digital and analog) over wireless networks to optimize communication efficiency. Specifically, we provide convergence bounds for both digital and analog transmission approaches, enabling analysis of the model performance trained on DFL. Furthermore, for digital transmission, we investigate and analyze resource allocation between computation and communication and convergence rates, obtaining its communication complexity and the minimum probability of correction communication required for convergence guarantee. For analog transmission, we discuss the impact of channel fading and noise on the mo",
    "link": "http://arxiv.org/abs/2308.06496",
    "context": "Title: Performance Analysis for Resource Constrained Decentralized Federated Learning Over Wireless Networks. (arXiv:2308.06496v1 [cs.LG])\nAbstract: Federated learning (FL) can lead to significant communication overhead and reliance on a central server. To address these challenges, decentralized federated learning (DFL) has been proposed as a more resilient framework. DFL involves parameter exchange between devices through a wireless network. This study analyzes the performance of resource-constrained DFL using different communication schemes (digital and analog) over wireless networks to optimize communication efficiency. Specifically, we provide convergence bounds for both digital and analog transmission approaches, enabling analysis of the model performance trained on DFL. Furthermore, for digital transmission, we investigate and analyze resource allocation between computation and communication and convergence rates, obtaining its communication complexity and the minimum probability of correction communication required for convergence guarantee. For analog transmission, we discuss the impact of channel fading and noise on the mo",
    "path": "papers/23/08/2308.06496.json",
    "total_tokens": 929,
    "translated_title": "资源受限的分散式联邦学习在无线网络中的性能分析",
    "translated_abstract": "联邦学习可以导致显著的通信开销并依赖于中央服务器。为了解决这些挑战，提出了分散式联邦学习作为一种更具弹性的框架。分散式联邦学习涉及通过无线网络在设备之间进行参数交换。本研究分析了在无线网络上使用不同通信方案（数字和模拟）进行资源受限的分散式联邦学习的性能，以优化通信效率。具体而言，我们提供了数字和模拟传输方法的收敛界限，使得可以分析在分散式联邦学习上训练的模型性能。此外，对于数字传输，我们研究和分析了计算和通信之间的资源分配以及收敛速度，得到了其通信复杂度和收敛保证所需的最小纠错通信概率。对于模拟传输，我们讨论了信道衰落和噪声对模型性能的影响。",
    "tldr": "本研究对资源受限的分散式联邦学习在无线网络中的性能进行了分析，研究了不同的通信方案并优化了通信效率。研究结果包括数字和模拟传输方法的收敛界限、资源分配和收敛速度，以及模拟传输中信道衰落和噪声对模型性能的影响。",
    "en_tdlr": "This study analyzes the performance of resource-constrained decentralized federated learning over wireless networks, considering different communication schemes to optimize communication efficiency. The results provide convergence bounds, resource allocation analysis, and the impact of channel fading and noise on model performance."
}