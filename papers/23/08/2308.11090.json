{
    "title": "Addressing Fairness and Explainability in Image Classification Using Optimal Transport. (arXiv:2308.11090v1 [cs.CV])",
    "abstract": "Algorithmic Fairness and the explainability of potentially unfair outcomes are crucial for establishing trust and accountability of Artificial Intelligence systems in domains such as healthcare and policing. Though significant advances have been made in each of the fields separately, achieving explainability in fairness applications remains challenging, particularly so in domains where deep neural networks are used. At the same time, ethical data-mining has become ever more relevant, as it has been shown countless times that fairness-unaware algorithms result in biased outcomes. Current approaches focus on mitigating biases in the outcomes of the model, but few attempts have been made to try to explain \\emph{why} a model is biased. To bridge this gap, we propose a comprehensive approach that leverages optimal transport theory to uncover the causes and implications of biased regions in images, which easily extends to tabular data as well. Through the use of Wasserstein barycenters, we o",
    "link": "http://arxiv.org/abs/2308.11090",
    "context": "Title: Addressing Fairness and Explainability in Image Classification Using Optimal Transport. (arXiv:2308.11090v1 [cs.CV])\nAbstract: Algorithmic Fairness and the explainability of potentially unfair outcomes are crucial for establishing trust and accountability of Artificial Intelligence systems in domains such as healthcare and policing. Though significant advances have been made in each of the fields separately, achieving explainability in fairness applications remains challenging, particularly so in domains where deep neural networks are used. At the same time, ethical data-mining has become ever more relevant, as it has been shown countless times that fairness-unaware algorithms result in biased outcomes. Current approaches focus on mitigating biases in the outcomes of the model, but few attempts have been made to try to explain \\emph{why} a model is biased. To bridge this gap, we propose a comprehensive approach that leverages optimal transport theory to uncover the causes and implications of biased regions in images, which easily extends to tabular data as well. Through the use of Wasserstein barycenters, we o",
    "path": "papers/23/08/2308.11090.json",
    "total_tokens": 896,
    "translated_title": "使用最优输运解决图像分类中的公平性和可解释性问题",
    "translated_abstract": "在诸如医疗保健和执法等领域中，算法公平性和对潜在不公平结果的解释是建立人工智能系统信任和问责性的关键。尽管在每个领域分别取得了重大进展，但在使用深度神经网络的领域中实现公平性应用的可解释性仍然具有挑战性。与此同时，伦理数据挖掘变得越来越重要，因为多次研究表明不关注公平性的算法会导致有偏差的结果。目前的方法主要关注在模型的输出中减轻偏见，但很少有尝试解释模型为什么存在偏见。为了弥补这一差距，我们提出了一种综合方法，利用最优输运理论来发现图像中有偏差区域的原因和影响，这种方法也可以轻松地扩展到表格数据。通过使用Wasserstein barycenters，我们可以以细粒度的方式解释模型的偏见。",
    "tldr": "本论文提出了使用最优输运理论解决图像分类中公平性和可解释性问题的综合方法，通过发现和解释模型中偏见区域的原因和影响来提供细粒度的解释。",
    "en_tdlr": "This paper presents a comprehensive approach using optimal transport theory to address fairness and explainability issues in image classification. By uncovering the causes and implications of biased regions in the model, the proposed method provides fine-grained explanations."
}