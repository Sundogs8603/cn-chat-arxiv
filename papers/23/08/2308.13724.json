{
    "title": "ISR-LLM: Iterative Self-Refined Large Language Model for Long-Horizon Sequential Task Planning. (arXiv:2308.13724v1 [cs.RO])",
    "abstract": "Motivated by the substantial achievements observed in Large Language Models (LLMs) in the field of natural language processing, recent research has commenced investigations into the application of LLMs for complex, long-horizon sequential task planning challenges in robotics. LLMs are advantageous in offering the potential to enhance the generalizability as task-agnostic planners and facilitate flexible interaction between human instructors and planning systems. However, task plans generated by LLMs often lack feasibility and correctness. To address this challenge, we introduce ISR-LLM, a novel framework that improves LLM-based planning through an iterative self-refinement process. The framework operates through three sequential steps: preprocessing, planning, and iterative self-refinement. During preprocessing, an LLM translator is employed to convert natural language input into a Planning Domain Definition Language (PDDL) formulation. In the planning phase, an LLM planner formulates ",
    "link": "http://arxiv.org/abs/2308.13724",
    "context": "Title: ISR-LLM: Iterative Self-Refined Large Language Model for Long-Horizon Sequential Task Planning. (arXiv:2308.13724v1 [cs.RO])\nAbstract: Motivated by the substantial achievements observed in Large Language Models (LLMs) in the field of natural language processing, recent research has commenced investigations into the application of LLMs for complex, long-horizon sequential task planning challenges in robotics. LLMs are advantageous in offering the potential to enhance the generalizability as task-agnostic planners and facilitate flexible interaction between human instructors and planning systems. However, task plans generated by LLMs often lack feasibility and correctness. To address this challenge, we introduce ISR-LLM, a novel framework that improves LLM-based planning through an iterative self-refinement process. The framework operates through three sequential steps: preprocessing, planning, and iterative self-refinement. During preprocessing, an LLM translator is employed to convert natural language input into a Planning Domain Definition Language (PDDL) formulation. In the planning phase, an LLM planner formulates ",
    "path": "papers/23/08/2308.13724.json",
    "total_tokens": 950,
    "translated_title": "ISR-LLM: 迭代自我完善的大型语言模型用于长时间序列任务规划",
    "translated_abstract": "受到自然语言处理领域大型语言模型（LLMs）取得的重大成就的启发，最近的研究开始探索将LLMs应用于机器人领域的复杂长时序列任务规划挑战。LLMs具有优势，可以提升通用性作为任务无关的规划者，并促进人类教师和规划系统之间的灵活互动。然而，LLMs生成的任务计划经常缺乏可行性和正确性。为了解决这个挑战，我们引入了ISR-LLM，一种通过迭代自我完善过程改进基于LLM的规划的新框架。该框架通过三个连续的步骤进行操作：预处理、规划和迭代自我完善。在预处理阶段，使用LLM翻译器将自然语言输入转换为规划域定义语言（PDDL）形式。在规划阶段，LLM规划器制定了任务计划的初步方案。",
    "tldr": "提出了ISR-LLM框架，通过迭代自我完善过程改进了LLM-based规划，该框架包括预处理、规划和迭代自我完善三个步骤。通过引入LLM翻译器将自然语言输入转换为PDDL形式，提高了生成的任务计划的可行性和正确性。",
    "en_tdlr": "ISR-LLM is a framework that improves LLM-based planning through an iterative self-refinement process. It includes preprocessing, planning, and iterative self-refinement steps. By introducing an LLM translator to convert natural language input into PDDL formulation, the feasibility and correctness of generated task plans are enhanced."
}