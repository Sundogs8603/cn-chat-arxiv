{
    "title": "Multi-party Goal Tracking with LLMs: Comparing Pre-training, Fine-tuning, and Prompt Engineering. (arXiv:2308.15231v1 [cs.CL])",
    "abstract": "This paper evaluates the extent to which current Large Language Models (LLMs) can capture task-oriented multi-party conversations (MPCs). We have recorded and transcribed 29 MPCs between patients, their companions, and a social robot in a hospital. We then annotated this corpus for multi-party goal-tracking and intent-slot recognition. People share goals, answer each other's goals, and provide other people's goals in MPCs - none of which occur in dyadic interactions. To understand user goals in MPCs, we compared three methods in zero-shot and few-shot settings: we fine-tuned T5, created pre-training tasks to train DialogLM using LED, and employed prompt engineering techniques with GPT-3.5-turbo, to determine which approach can complete this novel task with limited data. GPT-3.5-turbo significantly outperformed the others in a few-shot setting. The `reasoning' style prompt, when given 7% of the corpus as example annotated conversations, was the best performing method. It correctly annot",
    "link": "http://arxiv.org/abs/2308.15231",
    "context": "Title: Multi-party Goal Tracking with LLMs: Comparing Pre-training, Fine-tuning, and Prompt Engineering. (arXiv:2308.15231v1 [cs.CL])\nAbstract: This paper evaluates the extent to which current Large Language Models (LLMs) can capture task-oriented multi-party conversations (MPCs). We have recorded and transcribed 29 MPCs between patients, their companions, and a social robot in a hospital. We then annotated this corpus for multi-party goal-tracking and intent-slot recognition. People share goals, answer each other's goals, and provide other people's goals in MPCs - none of which occur in dyadic interactions. To understand user goals in MPCs, we compared three methods in zero-shot and few-shot settings: we fine-tuned T5, created pre-training tasks to train DialogLM using LED, and employed prompt engineering techniques with GPT-3.5-turbo, to determine which approach can complete this novel task with limited data. GPT-3.5-turbo significantly outperformed the others in a few-shot setting. The `reasoning' style prompt, when given 7% of the corpus as example annotated conversations, was the best performing method. It correctly annot",
    "path": "papers/23/08/2308.15231.json",
    "total_tokens": 1017,
    "translated_title": "使用LLMs进行多方目标追踪：比较预训练、微调和提示工程方法",
    "translated_abstract": "本文评估当前的大型语言模型（LLMs）能否捕捉面向任务的多方会话（MPCs）。我们记录并转录了29个在医院中患者、他们的伴侣和社交机器人之间的MPCs。然后我们对这个语料库进行了多方目标追踪和意图槽识别的注释。在MPCs中，人们分享目标，回答对方的目标，并提供其他人的目标 - 这些都不会在二元交互中发生。为了理解MPCs中用户的目标，我们在零样本和少样本设置下比较了三种方法：我们对T5进行了微调，使用LED创建了预训练任务来训练DialogLM，并使用GPT-3.5-turbo采用提示工程技术，以确定哪种方法可以在有限的数据下完成这个新颖的任务。在少样本设置下，GPT-3.5-turbo的性能显著优于其他方法。当给定7%的语料库作为示例标注对话时，\"推理\"风格的提示是表现最好的方法。它能正确注释...",
    "tldr": "本文评估了当前大型语言模型（LLMs）在捕捉任务导向的多方会话（MPCs）方面的能力，并比较了三种方法（预训练、微调和提示工程），结果表明在有限数据情况下，GPT-3.5-turbo通过\"推理\"风格的提示在少样本设置下表现最好。"
}