{
    "title": "Environment Diversification with Multi-head Neural Network for Invariant Learning. (arXiv:2308.08778v1 [cs.LG])",
    "abstract": "Neural networks are often trained with empirical risk minimization; however, it has been shown that a shift between training and testing distributions can cause unpredictable performance degradation. On this issue, a research direction, invariant learning, has been proposed to extract invariant features insensitive to the distributional changes. This work proposes EDNIL, an invariant learning framework containing a multi-head neural network to absorb data biases. We show that this framework does not require prior knowledge about environments or strong assumptions about the pre-trained model. We also reveal that the proposed algorithm has theoretical connections to recent studies discussing properties of variant and invariant features. Finally, we demonstrate that models trained with EDNIL are empirically more robust against distributional shifts.",
    "link": "http://arxiv.org/abs/2308.08778",
    "context": "Title: Environment Diversification with Multi-head Neural Network for Invariant Learning. (arXiv:2308.08778v1 [cs.LG])\nAbstract: Neural networks are often trained with empirical risk minimization; however, it has been shown that a shift between training and testing distributions can cause unpredictable performance degradation. On this issue, a research direction, invariant learning, has been proposed to extract invariant features insensitive to the distributional changes. This work proposes EDNIL, an invariant learning framework containing a multi-head neural network to absorb data biases. We show that this framework does not require prior knowledge about environments or strong assumptions about the pre-trained model. We also reveal that the proposed algorithm has theoretical connections to recent studies discussing properties of variant and invariant features. Finally, we demonstrate that models trained with EDNIL are empirically more robust against distributional shifts.",
    "path": "papers/23/08/2308.08778.json",
    "total_tokens": 769,
    "translated_title": "多头神经网络用于不变学习的环境多样化",
    "translated_abstract": "神经网络通常通过经验风险最小化进行训练；然而，已经证明训练和测试分布之间的偏移会导致不可预测的性能下降。针对这个问题，提出了一种研究方向，即不变学习，用于提取对分布变化不敏感的不变特征。本文提出了一个包含多头神经网络的不变学习框架EDNIL，用于吸收数据偏差。我们展示了该框架不需要对环境有先验知识或对预训练模型有强假设。我们还揭示了该算法与最近探讨变体特征和不变特征性质的研究有理论联系。最后，我们证明使用EDNIL训练的模型在面对分布变化时具有更强的稳健性。",
    "tldr": "本文提出了一个不变学习框架EDNIL，其中包含多头神经网络，用于吸收数据偏差，并展示了该框架的稳健性。"
}