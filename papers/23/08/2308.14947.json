{
    "title": "Improving Reinforcement Learning Training Regimes for Social Robot Navigation. (arXiv:2308.14947v1 [cs.RO])",
    "abstract": "In order for autonomous mobile robots to navigate in human spaces, they must abide by our social norms. Reinforcement learning (RL) has emerged as an effective method to train robot navigation policies that are able to respect these norms. However, a large portion of existing work in the field conducts both RL training and testing in simplistic environments. This limits the generalization potential of these models to unseen environments, and the meaningfulness of their reported results. We propose a method to improve the generalization performance of RL social navigation methods using curriculum learning. By employing multiple environment types and by modeling pedestrians using multiple dynamics models, we are able to progressively diversify and escalate difficulty in training. Our results show that the use of curriculum learning in training can be used to achieve better generalization performance than previous training methods. We also show that results presented in many existing stat",
    "link": "http://arxiv.org/abs/2308.14947",
    "context": "Title: Improving Reinforcement Learning Training Regimes for Social Robot Navigation. (arXiv:2308.14947v1 [cs.RO])\nAbstract: In order for autonomous mobile robots to navigate in human spaces, they must abide by our social norms. Reinforcement learning (RL) has emerged as an effective method to train robot navigation policies that are able to respect these norms. However, a large portion of existing work in the field conducts both RL training and testing in simplistic environments. This limits the generalization potential of these models to unseen environments, and the meaningfulness of their reported results. We propose a method to improve the generalization performance of RL social navigation methods using curriculum learning. By employing multiple environment types and by modeling pedestrians using multiple dynamics models, we are able to progressively diversify and escalate difficulty in training. Our results show that the use of curriculum learning in training can be used to achieve better generalization performance than previous training methods. We also show that results presented in many existing stat",
    "path": "papers/23/08/2308.14947.json",
    "total_tokens": 865,
    "translated_title": "改进社交机器人导航的强化学习训练方法",
    "translated_abstract": "为了让自主移动机器人在人类空间中导航，它们必须遵守我们的社交规范。强化学习（RL）已经成为一种有效的训练机器人导航策略的方法，以便使其能够遵守这些规范。然而，该领域中现有工作的很大一部分在简化环境中进行RL训练和测试。这限制了这些模型在未知环境中的泛化能力和其结果的实质性。我们提出了一种使用课程学习方法来提高RL社交导航方法泛化性能的方法。通过使用多种环境类型和多个动力学模型来建模行人，我们能够逐步增加训练的多样性和难度。我们的结果表明，在训练过程中使用课程学习可以实现比以前的训练方法更好的泛化性能。我们还展示了许多现有统计结果的结果之一，并对模型进行了详细分析。",
    "tldr": "本研究提出了一种改进社交机器人导航的强化学习训练方法，通过使用课程学习，多样化环境和建模行人等技术，实现了更好的泛化性能。",
    "en_tdlr": "This paper proposes a method to improve reinforcement learning training for social robot navigation. By using curriculum learning, diversifying environments, and modeling pedestrians, it achieves better generalization performance."
}