{
    "title": "MSAC: Multiple Speech Attribute Control Method for Speech Emotion Recognition. (arXiv:2308.04025v1 [cs.SD])",
    "abstract": "Despite significant progress, speech emotion recognition (SER) remains challenging due to inherent complexity and ambiguity of the emotion attribute, particularly in wild world. Whereas current studies primarily focus on recognition and generalization capabilities, this work pioneers an exploration into the reliability of SER methods and investigates how to model the speech emotion from the aspect of data distribution across various speech attributes. Specifically, we first build a novel CNN-based SER model which adopts additive margin softmax loss to expand the distance between features of different classes, thereby enhancing their discrimination. Second, a novel multiple speech attribute control method MSAC is proposed to explicitly control speech attributes, enabling the model to be less affected by emotion-agnostic attributes and capture more fine-grained emotion-related features. Third, we make a first attempt to test and analyze the reliability of the proposed SER workflow using ",
    "link": "http://arxiv.org/abs/2308.04025",
    "context": "Title: MSAC: Multiple Speech Attribute Control Method for Speech Emotion Recognition. (arXiv:2308.04025v1 [cs.SD])\nAbstract: Despite significant progress, speech emotion recognition (SER) remains challenging due to inherent complexity and ambiguity of the emotion attribute, particularly in wild world. Whereas current studies primarily focus on recognition and generalization capabilities, this work pioneers an exploration into the reliability of SER methods and investigates how to model the speech emotion from the aspect of data distribution across various speech attributes. Specifically, we first build a novel CNN-based SER model which adopts additive margin softmax loss to expand the distance between features of different classes, thereby enhancing their discrimination. Second, a novel multiple speech attribute control method MSAC is proposed to explicitly control speech attributes, enabling the model to be less affected by emotion-agnostic attributes and capture more fine-grained emotion-related features. Third, we make a first attempt to test and analyze the reliability of the proposed SER workflow using ",
    "path": "papers/23/08/2308.04025.json",
    "total_tokens": 897,
    "translated_title": "MSAC：用于语音情感识别的多语音属性控制方法",
    "translated_abstract": "尽管取得了显著进展，但由于情感属性的复杂性和歧义性，尤其是在自然环境下，语音情感识别（SER）仍然具有挑战性。而当前的研究主要关注识别和泛化能力，本文首次探索了SER方法的可靠性，并研究了如何通过各种语音属性的数据分布来建模语音情感。具体来说，我们首先构建了一种新颖的基于CNN的SER模型，采用了加性边界最大化软件最大化损失函数，扩大了不同类别特征之间的距离，从而增强了它们的区分能力。其次，我们提出了一种新颖的多语音属性控制方法MSAC，以明确控制语音属性，使模型受情感无关属性的影响较小，并捕捉到更细粒度的情感相关特征。第三，我们首次尝试测试和分析了所提出的SER工作流程的可靠性。",
    "tldr": "本研究针对语音情感识别(SER)提出了MSAC方法，通过构建新颖的CNN-based SER模型和多语音属性控制方法MSAC，实现了对情感的更精细控制和捕捉，从而提升了SER的可靠性和效果。"
}