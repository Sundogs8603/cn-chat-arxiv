{
    "title": "Efficient Model Personalization in Federated Learning via Client-Specific Prompt Generation. (arXiv:2308.15367v1 [cs.CV])",
    "abstract": "Federated learning (FL) emerges as a decentralized learning framework which trains models from multiple distributed clients without sharing their data to preserve privacy. Recently, large-scale pre-trained models (e.g., Vision Transformer) have shown a strong capability of deriving robust representations. However, the data heterogeneity among clients, the limited computation resources, and the communication bandwidth restrict the deployment of large-scale models in FL frameworks. To leverage robust representations from large-scale models while enabling efficient model personalization for heterogeneous clients, we propose a novel personalized FL framework of client-specific Prompt Generation (pFedPG), which learns to deploy a personalized prompt generator at the server for producing client-specific visual prompts that efficiently adapts frozen backbones to local data distributions. Our proposed framework jointly optimizes the stages of personalized prompt adaptation locally and personal",
    "link": "http://arxiv.org/abs/2308.15367",
    "context": "Title: Efficient Model Personalization in Federated Learning via Client-Specific Prompt Generation. (arXiv:2308.15367v1 [cs.CV])\nAbstract: Federated learning (FL) emerges as a decentralized learning framework which trains models from multiple distributed clients without sharing their data to preserve privacy. Recently, large-scale pre-trained models (e.g., Vision Transformer) have shown a strong capability of deriving robust representations. However, the data heterogeneity among clients, the limited computation resources, and the communication bandwidth restrict the deployment of large-scale models in FL frameworks. To leverage robust representations from large-scale models while enabling efficient model personalization for heterogeneous clients, we propose a novel personalized FL framework of client-specific Prompt Generation (pFedPG), which learns to deploy a personalized prompt generator at the server for producing client-specific visual prompts that efficiently adapts frozen backbones to local data distributions. Our proposed framework jointly optimizes the stages of personalized prompt adaptation locally and personal",
    "path": "papers/23/08/2308.15367.json",
    "total_tokens": 802,
    "translated_title": "通过客户端特定的提示生成，在联邦学习中实现高效的模型个性化",
    "translated_abstract": "联邦学习（FL）作为一种分散的学习框架，可以在不共享数据以保护隐私的情况下，从多个分布式客户端训练模型。最近，大型预训练模型（如Vision Transformer）展示了从分布式客户端中获得稳健表示的强大能力。然而，客户端之间数据的异质性、有限的计算资源和通信带宽限制了大型模型在FL框架中的部署。为了利用大型模型的稳健表示，同时实现对异构客户端的高效模型个性化，我们提出了一种新的个性化FL框架，即客户端特定的提示生成（pFedPG），它学习在服务器端部署个性化提示生成器，用以产生适应本地数据分布的客户端特定视觉提示，从而有效地将冻结的骨干网络适应到本地数据分布。",
    "tldr": "pFedPG is a novel personalized FL framework that generates client-specific prompts to adapt frozen backbones to local data distributions, enabling efficient model personalization for heterogeneous clients in FL.",
    "en_tdlr": "pFedPG is a novel personalized FL framework that generates client-specific prompts to adapt frozen backbones to local data distributions, enabling efficient model personalization for heterogeneous clients in FL."
}