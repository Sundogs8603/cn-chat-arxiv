{
    "title": "Approximating Score-based Explanation Techniques Using Conformal Regression. (arXiv:2308.11975v1 [cs.LG])",
    "abstract": "Score-based explainable machine-learning techniques are often used to understand the logic behind black-box models. However, such explanation techniques are often computationally expensive, which limits their application in time-critical contexts. Therefore, we propose and investigate the use of computationally less costly regression models for approximating the output of score-based explanation techniques, such as SHAP. Moreover, validity guarantees for the approximated values are provided by the employed inductive conformal prediction framework. We propose several non-conformity measures designed to take the difficulty of approximating the explanations into account while keeping the computational cost low. We present results from a large-scale empirical investigation, in which the approximate explanations generated by our proposed models are evaluated with respect to efficiency (interval size). The results indicate that the proposed method can significantly improve execution time com",
    "link": "http://arxiv.org/abs/2308.11975",
    "context": "Title: Approximating Score-based Explanation Techniques Using Conformal Regression. (arXiv:2308.11975v1 [cs.LG])\nAbstract: Score-based explainable machine-learning techniques are often used to understand the logic behind black-box models. However, such explanation techniques are often computationally expensive, which limits their application in time-critical contexts. Therefore, we propose and investigate the use of computationally less costly regression models for approximating the output of score-based explanation techniques, such as SHAP. Moreover, validity guarantees for the approximated values are provided by the employed inductive conformal prediction framework. We propose several non-conformity measures designed to take the difficulty of approximating the explanations into account while keeping the computational cost low. We present results from a large-scale empirical investigation, in which the approximate explanations generated by our proposed models are evaluated with respect to efficiency (interval size). The results indicate that the proposed method can significantly improve execution time com",
    "path": "papers/23/08/2308.11975.json",
    "total_tokens": 835,
    "translated_title": "使用符合回归方法近似评分解释技术",
    "translated_abstract": "基于评分的可解释机器学习技术经常被用来理解黑盒模型背后的逻辑。然而，这些解释技术通常计算成本高昂，限制了它们在时间关键环境中的应用。因此，我们提出并研究了使用计算成本较低的回归模型来近似评分解释技术（如SHAP）的输出。此外，我们采用归纳式符合预测框架提供了近似值的有效性保证。我们提出了几个非符合度度量，旨在同时考虑近似解释的难度和计算成本的低廉。我们进行了大规模的实证研究，评估了我们提出的模型生成的近似解释的效率（区间大小）。结果表明，所提出的方法可以显著改善执行时间。",
    "tldr": "本研究提出了使用计算成本较低的回归模型来近似评分解释技术，并采用归纳式符合预测框架提供近似值的有效性保证。实证研究结果显示，该方法能显著提升执行时间。",
    "en_tdlr": "This study proposes the use of computationally less costly regression models to approximate score-based explanation techniques, with validity guarantees provided by an inductive conformal prediction framework. Empirical results show that the proposed method significantly improves execution time."
}