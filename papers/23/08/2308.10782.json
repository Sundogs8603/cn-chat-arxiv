{
    "title": "Sparse Linear Concept Discovery Models. (arXiv:2308.10782v1 [cs.LG])",
    "abstract": "The recent mass adoption of DNNs, even in safety-critical scenarios, has shifted the focus of the research community towards the creation of inherently intrepretable models. Concept Bottleneck Models (CBMs) constitute a popular approach where hidden layers are tied to human understandable concepts allowing for investigation and correction of the network's decisions. However, CBMs usually suffer from: (i) performance degradation and (ii) lower interpretability than intended due to the sheer amount of concepts contributing to each decision. In this work, we propose a simple yet highly intuitive interpretable framework based on Contrastive Language Image models and a single sparse linear layer. In stark contrast to related approaches, the sparsity in our framework is achieved via principled Bayesian arguments by inferring concept presence via a data-driven Bernoulli distribution. As we experimentally show, our framework not only outperforms recent CBM approaches accuracy-wise, but it also",
    "link": "http://arxiv.org/abs/2308.10782",
    "context": "Title: Sparse Linear Concept Discovery Models. (arXiv:2308.10782v1 [cs.LG])\nAbstract: The recent mass adoption of DNNs, even in safety-critical scenarios, has shifted the focus of the research community towards the creation of inherently intrepretable models. Concept Bottleneck Models (CBMs) constitute a popular approach where hidden layers are tied to human understandable concepts allowing for investigation and correction of the network's decisions. However, CBMs usually suffer from: (i) performance degradation and (ii) lower interpretability than intended due to the sheer amount of concepts contributing to each decision. In this work, we propose a simple yet highly intuitive interpretable framework based on Contrastive Language Image models and a single sparse linear layer. In stark contrast to related approaches, the sparsity in our framework is achieved via principled Bayesian arguments by inferring concept presence via a data-driven Bernoulli distribution. As we experimentally show, our framework not only outperforms recent CBM approaches accuracy-wise, but it also",
    "path": "papers/23/08/2308.10782.json",
    "total_tokens": 935,
    "translated_title": "稀疏线性概念发现模型",
    "translated_abstract": "最近，在安全关键场景中也大规模采用了深度神经网络(DNN)，这使得研究界的关注点转向了创造固有可解释模型。概念瓶颈模型 (CBMs) 是一种流行的方法，其中隐藏层与人类可理解的概念相连，允许对网络决策进行调查和修正。然而，CBMs通常存在以下问题：(i) 性能下降和(ii) 解释性不如预期，因为每个决策都涉及到许多概念的贡献。在这项工作中，我们提出了一种简单但极其直观的可解释框架，该框架基于对比语言图像模型和单个稀疏线性层。与其他相关方法截然不同的是，我们的框架中的稀疏性是通过基于数据驱动的伯努利分布进行的基于贝叶斯原理的概念推断实现的。正如我们在实验中所表明的那样，我们的框架不仅在准确性方面优于最近的CBM方法，而且在解释性方面也更好。",
    "tldr": "本论文提出了一种基于对比语言图像模型和单个稀疏线性层的可解释框架，通过贝叶斯推断来实现概念之间的稀疏性，达到了比最近的CBM方法更好的准确性和解释性。"
}