{
    "title": "Automatically Correcting Large Language Models: Surveying the landscape of diverse self-correction strategies. (arXiv:2308.03188v2 [cs.CL] UPDATED)",
    "abstract": "Large language models (LLMs) have demonstrated remarkable performance across a wide array of NLP tasks. However, their efficacy is undermined by undesired and inconsistent behaviors, including hallucination, unfaithful reasoning, and toxic content. A promising approach to rectify these flaws is self-correction, where the LLM itself is prompted or guided to fix problems in its own output. Techniques leveraging automated feedback -- either produced by the LLM itself or some external system -- are of particular interest as they are a promising way to make LLM-based solutions more practical and deployable with minimal human feedback. This paper presents a comprehensive review of this emerging class of techniques. We analyze and taxonomize a wide array of recent work utilizing these strategies, including training-time, generation-time, and post-hoc correction. We also summarize the major applications of this strategy and conclude by discussing future directions and challenges.",
    "link": "http://arxiv.org/abs/2308.03188",
    "context": "Title: Automatically Correcting Large Language Models: Surveying the landscape of diverse self-correction strategies. (arXiv:2308.03188v2 [cs.CL] UPDATED)\nAbstract: Large language models (LLMs) have demonstrated remarkable performance across a wide array of NLP tasks. However, their efficacy is undermined by undesired and inconsistent behaviors, including hallucination, unfaithful reasoning, and toxic content. A promising approach to rectify these flaws is self-correction, where the LLM itself is prompted or guided to fix problems in its own output. Techniques leveraging automated feedback -- either produced by the LLM itself or some external system -- are of particular interest as they are a promising way to make LLM-based solutions more practical and deployable with minimal human feedback. This paper presents a comprehensive review of this emerging class of techniques. We analyze and taxonomize a wide array of recent work utilizing these strategies, including training-time, generation-time, and post-hoc correction. We also summarize the major applications of this strategy and conclude by discussing future directions and challenges.",
    "path": "papers/23/08/2308.03188.json",
    "total_tokens": 946,
    "translated_title": "自动纠正大型语言模型：多样化自我纠正策略的概述调查",
    "translated_abstract": "大型语言模型(LLMs)在各种自然语言处理任务中展现了卓越的性能。然而，它们的功效受到了不受欢迎和不一致的行为的削弱，包括幻觉、不忠实的推理和有害内容。纠正这些缺陷的一种有前景的方法是自我纠正，即引导或指导LLM自行修复输出问题。利用自动反馈的技术--无论是由LLM自身产生还是由某个外部系统产生--尤其有趣，因为它们是使基于LLM的解决方案更实际和可部署的一种有前景的方式，且只需最少的人类反馈。本文对这一新兴技术类别进行了全面的评估。我们分析和分类了许多最近利用这些策略的工作，包括训练时、生成时和事后纠正的技术。我们还总结了这一策略的主要应用，并在最后讨论了未来的发展方向和挑战。",
    "tldr": "本文总结了最近的研究，对多样化的自我纠正策略进行了分类和分析，以解决大型语言模型中的问题行为。自动化反馈技术被证明是一种可行的方法，可以使基于大型语言模型的解决方案更实用和可部署。",
    "en_tdlr": "This paper presents a comprehensive review of recent work on diverse self-correction strategies for large language models (LLMs), aiming to address undesired behaviors. Automated feedback techniques are proven to be a promising way to make LLM-based solutions more practical and deployable."
}