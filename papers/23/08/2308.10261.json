{
    "title": "How Good Are Large Language Models at Out-of-Distribution Detection?. (arXiv:2308.10261v2 [cs.CL] UPDATED)",
    "abstract": "Out-of-distribution (OOD) detection plays a vital role in enhancing the reliability of machine learning (ML) models. The emergence of large language models (LLMs) has catalyzed a paradigm shift within the ML community, showcasing their exceptional capabilities across diverse natural language processing tasks. While existing research has probed OOD detection with relative small-scale Transformers like BERT, RoBERTa and GPT-2, the stark differences in scales, pre-training objectives, and inference paradigms call into question the applicability of these findings to LLMs. This paper embarks on a pioneering empirical investigation of OOD detection in the domain of LLMs, focusing on LLaMA series ranging from 7B to 65B in size. We thoroughly evaluate commonly-used OOD detectors, scrutinizing their performance in both zero-grad and fine-tuning scenarios. Notably, we alter previous discriminative in-distribution fine-tuning into generative fine-tuning, aligning the pre-training objective of LLM",
    "link": "http://arxiv.org/abs/2308.10261",
    "context": "Title: How Good Are Large Language Models at Out-of-Distribution Detection?. (arXiv:2308.10261v2 [cs.CL] UPDATED)\nAbstract: Out-of-distribution (OOD) detection plays a vital role in enhancing the reliability of machine learning (ML) models. The emergence of large language models (LLMs) has catalyzed a paradigm shift within the ML community, showcasing their exceptional capabilities across diverse natural language processing tasks. While existing research has probed OOD detection with relative small-scale Transformers like BERT, RoBERTa and GPT-2, the stark differences in scales, pre-training objectives, and inference paradigms call into question the applicability of these findings to LLMs. This paper embarks on a pioneering empirical investigation of OOD detection in the domain of LLMs, focusing on LLaMA series ranging from 7B to 65B in size. We thoroughly evaluate commonly-used OOD detectors, scrutinizing their performance in both zero-grad and fine-tuning scenarios. Notably, we alter previous discriminative in-distribution fine-tuning into generative fine-tuning, aligning the pre-training objective of LLM",
    "path": "papers/23/08/2308.10261.json",
    "total_tokens": 919,
    "translated_title": "大型语言模型在分布外检测方面有多好？",
    "translated_abstract": "分布外（OOD）检测在提高机器学习（ML）模型的可靠性方面起着至关重要的作用。大型语言模型（LLM）的出现在ML社区引起了范式转变，展示了它们在各种自然语言处理任务中的出色能力。尽管现有的研究已经以BERT、RoBERTa和GPT-2等相对小规模的Transformer模型探索了OOD检测，但在规模、预训练目标和推理范式方面的明显差异引发了对这些发现在LLM中的适用性的质疑。本文在LLMs领域进行了开创性的实证调查，重点关注7B到65B大小的LLaMA系列。我们对常用的OOD检测器进行了全面评估，审查了它们在零梯度和微调场景下的性能。值得注意的是，我们将之前的判别式的内部分布微调改为生成式微调，使LLM的预训练目标与之一致。",
    "tldr": "本文通过对大型语言模型进行实证调查，探索了分布外检测的能力。作者发现了LLM在分布外检测方面的差异，并采用了新的生成式微调方法，提高了模型的性能。",
    "en_tdlr": "This paper conducts an empirical investigation of out-of-distribution (OOD) detection in large language models (LLMs). The authors discover differences in OOD detection capabilities for LLMs and propose a new generative fine-tuning method to improve their performance."
}