{
    "title": "Deep Evidential Learning for Bayesian Quantile Regression. (arXiv:2308.10650v1 [cs.LG])",
    "abstract": "It is desirable to have accurate uncertainty estimation from a single deterministic forward-pass model, as traditional methods for uncertainty quantification are computationally expensive. However, this is difficult because single forward-pass models do not sample weights during inference and often make assumptions about the target distribution, such as assuming it is Gaussian. This can be restrictive in regression tasks, where the mean and standard deviation are inadequate to model the target distribution accurately. This paper proposes a deep Bayesian quantile regression model that can estimate the quantiles of a continuous target distribution without the Gaussian assumption. The proposed method is based on evidential learning, which allows the model to capture aleatoric and epistemic uncertainty with a single deterministic forward-pass model. This makes the method efficient and scalable to large models and datasets. We demonstrate that the proposed method achieves calibrated uncerta",
    "link": "http://arxiv.org/abs/2308.10650",
    "context": "Title: Deep Evidential Learning for Bayesian Quantile Regression. (arXiv:2308.10650v1 [cs.LG])\nAbstract: It is desirable to have accurate uncertainty estimation from a single deterministic forward-pass model, as traditional methods for uncertainty quantification are computationally expensive. However, this is difficult because single forward-pass models do not sample weights during inference and often make assumptions about the target distribution, such as assuming it is Gaussian. This can be restrictive in regression tasks, where the mean and standard deviation are inadequate to model the target distribution accurately. This paper proposes a deep Bayesian quantile regression model that can estimate the quantiles of a continuous target distribution without the Gaussian assumption. The proposed method is based on evidential learning, which allows the model to capture aleatoric and epistemic uncertainty with a single deterministic forward-pass model. This makes the method efficient and scalable to large models and datasets. We demonstrate that the proposed method achieves calibrated uncerta",
    "path": "papers/23/08/2308.10650.json",
    "total_tokens": 854,
    "translated_title": "深度证据学习用于贝叶斯分位回归",
    "translated_abstract": "传统的不确定性量化方法计算代价高，因此希望能从单一确定性前向传递模型中获得准确的不确定性估计。然而，这很困难，因为单一前向传递模型在推断过程中不对权重进行采样，并且常常对目标分布做出假设，如假设为高斯分布。这在回归任务中会有限制，因为均值和标准差无法准确建模目标分布。本文提出了一种深度贝叶斯分位回归模型，可以在不假设高斯分布的情况下估计连续目标分布的分位数。所提出的方法基于证据学习，可以使用单一确定性前向传递模型捕捉随机与认知不确定性。因此，该方法高效且可扩展到大型模型和数据集。我们证明所提出的方法能够实现校准的不确定性估计。",
    "tldr": "本文提出了一种基于证据学习的深度贝叶斯分位回归模型，通过使用单一确定性前向传递模型来捕捉连续目标分布的分位数，从而实现了高效的不确定性估计。",
    "en_tdlr": "This paper proposes a deep Bayesian quantile regression model based on evidential learning, which can estimate the quantiles of a continuous target distribution without assuming it to be Gaussian, achieving efficient uncertainty estimation."
}