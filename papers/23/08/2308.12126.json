{
    "title": "An Accelerated Block Proximal Framework with Adaptive Momentum for Nonconvex and Nonsmooth Optimization. (arXiv:2308.12126v1 [math.OC])",
    "abstract": "We propose an accelerated block proximal linear framework with adaptive momentum (ABPL$^+$) for nonconvex and nonsmooth optimization. We analyze the potential causes of the extrapolation step failing in some algorithms, and resolve this issue by enhancing the comparison process that evaluates the trade-off between the proximal gradient step and the linear extrapolation step in our algorithm. Furthermore, we extends our algorithm to any scenario involving updating block variables with positive integers, allowing each cycle to randomly shuffle the update order of the variable blocks. Additionally, under mild assumptions, we prove that ABPL$^+$ can monotonically decrease the function value without strictly restricting the extrapolation parameters and step size, demonstrates the viability and effectiveness of updating these blocks in a random order, and we also more obviously and intuitively demonstrate that the derivative set of the sequence generated by our algorithm is a critical point ",
    "link": "http://arxiv.org/abs/2308.12126",
    "context": "Title: An Accelerated Block Proximal Framework with Adaptive Momentum for Nonconvex and Nonsmooth Optimization. (arXiv:2308.12126v1 [math.OC])\nAbstract: We propose an accelerated block proximal linear framework with adaptive momentum (ABPL$^+$) for nonconvex and nonsmooth optimization. We analyze the potential causes of the extrapolation step failing in some algorithms, and resolve this issue by enhancing the comparison process that evaluates the trade-off between the proximal gradient step and the linear extrapolation step in our algorithm. Furthermore, we extends our algorithm to any scenario involving updating block variables with positive integers, allowing each cycle to randomly shuffle the update order of the variable blocks. Additionally, under mild assumptions, we prove that ABPL$^+$ can monotonically decrease the function value without strictly restricting the extrapolation parameters and step size, demonstrates the viability and effectiveness of updating these blocks in a random order, and we also more obviously and intuitively demonstrate that the derivative set of the sequence generated by our algorithm is a critical point ",
    "path": "papers/23/08/2308.12126.json",
    "total_tokens": 985,
    "translated_title": "使用自适应动量的加速分块近端框架用于非凸和非光滑优化",
    "translated_abstract": "我们提出了一种使用自适应动量的加速分块近端线性框架（ABPL+）用于非凸和非光滑优化。我们分析了一些算法中的外推步骤失败的潜在原因，并通过增强比较过程来解决这个问题，该过程评估了我们算法中近端梯度步骤与线性外推步骤之间的权衡。此外，我们将算法扩展到涉及使用正整数更新块变量的任何情况，允许每个周期随机重新排列变量块的更新顺序。此外，在一些温和假设下，我们证明了ABPL+可以在严格限定外推参数和步长的情况下单调地减小函数值，并展示了以随机顺序更新这些块的可行性和有效性。我们还通过更明显直观地展示由我们算法生成的序列的导数集是关键点的性质。",
    "tldr": "本论文提出一种使用自适应动量的加速分块近端框架(ABPL+)来解决非凸和非光滑优化问题，并通过增强比较过程解决外推步骤失败的问题。同时，扩展算法适用于更新块变量的任何情况，并证明了算法的可行性和有效性。通过展示序列的导数集为关键点的性质，更明显地证明了算法的优势。"
}