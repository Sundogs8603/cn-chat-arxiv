{
    "title": "A Comparison of Adversarial Learning Techniques for Malware Detection. (arXiv:2308.09958v1 [cs.CR])",
    "abstract": "Machine learning has proven to be a useful tool for automated malware detection, but machine learning models have also been shown to be vulnerable to adversarial attacks. This article addresses the problem of generating adversarial malware samples, specifically malicious Windows Portable Executable files. We summarize and compare work that has focused on adversarial machine learning for malware detection. We use gradient-based, evolutionary algorithm-based, and reinforcement-based methods to generate adversarial samples, and then test the generated samples against selected antivirus products. We compare the selected methods in terms of accuracy and practical applicability. The results show that applying optimized modifications to previously detected malware can lead to incorrect classification of the file as benign. It is also known that generated malware samples can be successfully used against detection models other than those used to generate them and that using combinations of gene",
    "link": "http://arxiv.org/abs/2308.09958",
    "context": "Title: A Comparison of Adversarial Learning Techniques for Malware Detection. (arXiv:2308.09958v1 [cs.CR])\nAbstract: Machine learning has proven to be a useful tool for automated malware detection, but machine learning models have also been shown to be vulnerable to adversarial attacks. This article addresses the problem of generating adversarial malware samples, specifically malicious Windows Portable Executable files. We summarize and compare work that has focused on adversarial machine learning for malware detection. We use gradient-based, evolutionary algorithm-based, and reinforcement-based methods to generate adversarial samples, and then test the generated samples against selected antivirus products. We compare the selected methods in terms of accuracy and practical applicability. The results show that applying optimized modifications to previously detected malware can lead to incorrect classification of the file as benign. It is also known that generated malware samples can be successfully used against detection models other than those used to generate them and that using combinations of gene",
    "path": "papers/23/08/2308.09958.json",
    "total_tokens": 884,
    "translated_title": "恶意软件检测的对抗学习技术比较",
    "translated_abstract": "机器学习已被证明是自动化恶意软件检测的有用工具，但机器学习模型也显示出对抗攻击的脆弱性。本文针对生成对抗性恶意软件样本，特别是恶意的Windows可执行文件进行了研究。我们总结和比较了关于对抗机器学习用于恶意软件检测的工作。我们使用基于梯度、基于进化算法和基于强化学习的方法生成对抗样本，并对生成的样本应用于选择的杀毒产品进行测试。我们比较了这些方法在准确性和实际应用性方面的性能。结果显示，对先前检测到的恶意软件应用优化修改可能导致将文件错误分类为良性。已知生成的恶意软件样本可成功用于其他检测模型，并且利用基因组合可以增加生成的样本的对抗效果。",
    "tldr": "本文比较了针对恶意软件检测的对抗学习技术，通过生成对抗性恶意软件样本，并测试其对杀毒产品的检测性能。结果显示，对先前检测到的恶意软件应用优化修改可能导致错误分类，同时生成的恶意软件样本可成功用于其他检测模型。",
    "en_tdlr": "This article compares adversarial learning techniques for malware detection by generating adversarial malware samples and testing their detection performance against antivirus products. The results show that optimized modifications to previously detected malware can lead to incorrect classification, and the generated malware samples can successfully be used against other detection models."
}