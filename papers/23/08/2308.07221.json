{
    "title": "AudioFormer: Audio Transformer learns audio feature representations from discrete acoustic codes. (arXiv:2308.07221v2 [cs.SD] UPDATED)",
    "abstract": "We propose a method named AudioFormer,which learns audio feature representations through the acquisition of discrete acoustic codes and subsequently fine-tunes them for audio classification tasks. Initially,we introduce a novel perspective by considering the audio classification task as a form of natural language understanding (NLU). Leveraging an existing neural audio codec model,we generate discrete acoustic codes and utilize them to train a masked language model (MLM),thereby obtaining audio feature representations. Furthermore,we pioneer the integration of a Multi-Positive sample Contrastive (MPC) learning approach. This method enables the learning of joint representations among multiple discrete acoustic codes within the same audio input. In our experiments,we treat discrete acoustic codes as textual data and train a masked language model using a cloze-like methodology,ultimately deriving high-quality audio representations. Notably,the MPC learning technique effectively captures c",
    "link": "http://arxiv.org/abs/2308.07221",
    "context": "Title: AudioFormer: Audio Transformer learns audio feature representations from discrete acoustic codes. (arXiv:2308.07221v2 [cs.SD] UPDATED)\nAbstract: We propose a method named AudioFormer,which learns audio feature representations through the acquisition of discrete acoustic codes and subsequently fine-tunes them for audio classification tasks. Initially,we introduce a novel perspective by considering the audio classification task as a form of natural language understanding (NLU). Leveraging an existing neural audio codec model,we generate discrete acoustic codes and utilize them to train a masked language model (MLM),thereby obtaining audio feature representations. Furthermore,we pioneer the integration of a Multi-Positive sample Contrastive (MPC) learning approach. This method enables the learning of joint representations among multiple discrete acoustic codes within the same audio input. In our experiments,we treat discrete acoustic codes as textual data and train a masked language model using a cloze-like methodology,ultimately deriving high-quality audio representations. Notably,the MPC learning technique effectively captures c",
    "path": "papers/23/08/2308.07221.json",
    "total_tokens": 907,
    "translated_title": "AudioFormer: 通过离散的声学代码学习音频特征表示的音频变换器",
    "translated_abstract": "我们提出了一种名为AudioFormer的方法，通过获取离散的声学代码来学习音频特征表示，并随后对其进行微调以用于音频分类任务。我们首先将音频分类任务视为一种自然语言理解 (NLU) 的形式，借助现有的神经音频编解码模型，我们生成了离散的声学代码，并利用它们来训练一个掩码语言模型 (MLM)，从而获得音频特征表示。此外，我们首创了一种多正样本对比 (MPC) 学习方法的整合，该方法能够学习同一音频输入中多个离散声学代码间的联合表示。在实验中，我们将离散的声学代码视为文本数据，并使用类似填空题的方法训练一个掩码语言模型，最终得到高质量的音频表示。值得注意的是，MPC学习技术能够有效捕捉到音频中的相关性。",
    "tldr": "AudioFormer是一种学习音频特征表示的方法，通过生成离散的声学代码并利用它们来训练掩码语言模型，从而将音频分类任务视为自然语言理解的形式。此外，引入了多正样本对比学习方法，通过学习联合表示来捕捉音频中的相关性。"
}