{
    "title": "Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc. (arXiv:2308.04445v1 [cs.LG])",
    "abstract": "Generative AI, the most popular current approach to AI, consists of large language models (LLMs) that are trained to produce outputs that are plausible, but not necessarily correct. Although their abilities are often uncanny, they are lacking in aspects of reasoning, leading LLMs to be less than completely trustworthy. Furthermore, their results tend to be both unpredictable and uninterpretable.  We lay out 16 desiderata for future AI, and discuss an alternative approach to AI which could theoretically address many of the limitations associated with current approaches: AI educated with curated pieces of explicit knowledge and rules of thumb, enabling an inference engine to automatically deduce the logical entailments of all that knowledge. Even long arguments produced this way can be both trustworthy and interpretable, since the full step-by-step line of reasoning is always available, and for each step the provenance of the knowledge used can be documented and audited. There is however",
    "link": "http://arxiv.org/abs/2308.04445",
    "context": "Title: Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc. (arXiv:2308.04445v1 [cs.LG])\nAbstract: Generative AI, the most popular current approach to AI, consists of large language models (LLMs) that are trained to produce outputs that are plausible, but not necessarily correct. Although their abilities are often uncanny, they are lacking in aspects of reasoning, leading LLMs to be less than completely trustworthy. Furthermore, their results tend to be both unpredictable and uninterpretable.  We lay out 16 desiderata for future AI, and discuss an alternative approach to AI which could theoretically address many of the limitations associated with current approaches: AI educated with curated pieces of explicit knowledge and rules of thumb, enabling an inference engine to automatically deduce the logical entailments of all that knowledge. Even long arguments produced this way can be both trustworthy and interpretable, since the full step-by-step line of reasoning is always available, and for each step the provenance of the knowledge used can be documented and audited. There is however",
    "path": "papers/23/08/2308.04445.json",
    "total_tokens": 828,
    "translated_title": "从生成式AI走向可信赖的AI：LLM可以从Cyc中学到什么",
    "translated_abstract": "生成式AI是目前最流行的人工智能方法，由训练出的大型语言模型（LLMs）组成，用于生成可信，但不一定正确的输出。尽管它们的能力常常令人惊叹，但在推理方面它们存在缺陷，导致LLMs不完全可信赖。此外，它们的结果往往不可预测和不可解释。我们提出了未来人工智能的16个期望，并讨论了AI的另一种可能解决当前方法所面临的许多限制的方法：培养基于明确知识和经验规则的AI，使推理引擎能够自动推导出所有知识的逻辑蕴含。即使是通过这种方式产生的长论证也可以是可信且可解释的，因为完整的逐步推理过程始终可以获得，并且可以记录和审计每个步骤使用的知识的来源。",
    "tldr": "对于未来的AI，需要从生成式AI转向可信赖的AI。通过培养基于明确知识和经验规则的AI，可以解决当前方法的限制并实现推理过程的可信赖和可解释性。"
}