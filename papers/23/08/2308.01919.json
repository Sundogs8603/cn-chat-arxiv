{
    "title": "Emotion recognition based on multi-modal electrophysiology multi-head attention Contrastive Learning. (arXiv:2308.01919v1 [cs.MM])",
    "abstract": "Emotion recognition is an important research direction in artificial intelligence, helping machines understand and adapt to human emotional states. Multimodal electrophysiological(ME) signals, such as EEG, GSR, respiration(Resp), and temperature(Temp), are effective biomarkers for reflecting changes in human emotions. However, using electrophysiological signals for emotion recognition faces challenges such as data scarcity, inconsistent labeling, and difficulty in cross-individual generalization. To address these issues, we propose ME-MHACL, a self-supervised contrastive learning-based multimodal emotion recognition method that can learn meaningful feature representations from unlabeled electrophysiological signals and use multi-head attention mechanisms for feature fusion to improve recognition performance. Our method includes two stages: first, we use the Meiosis method to group sample and augment unlabeled electrophysiological signals and design a self-supervised contrastive learnin",
    "link": "http://arxiv.org/abs/2308.01919",
    "context": "Title: Emotion recognition based on multi-modal electrophysiology multi-head attention Contrastive Learning. (arXiv:2308.01919v1 [cs.MM])\nAbstract: Emotion recognition is an important research direction in artificial intelligence, helping machines understand and adapt to human emotional states. Multimodal electrophysiological(ME) signals, such as EEG, GSR, respiration(Resp), and temperature(Temp), are effective biomarkers for reflecting changes in human emotions. However, using electrophysiological signals for emotion recognition faces challenges such as data scarcity, inconsistent labeling, and difficulty in cross-individual generalization. To address these issues, we propose ME-MHACL, a self-supervised contrastive learning-based multimodal emotion recognition method that can learn meaningful feature representations from unlabeled electrophysiological signals and use multi-head attention mechanisms for feature fusion to improve recognition performance. Our method includes two stages: first, we use the Meiosis method to group sample and augment unlabeled electrophysiological signals and design a self-supervised contrastive learnin",
    "path": "papers/23/08/2308.01919.json",
    "total_tokens": 932,
    "translated_title": "基于多模态电生理多头注意力对比学习的情感识别",
    "translated_abstract": "情感识别是人工智能中的一个重要研究方向，帮助机器理解和适应人类的情感状态。多模态电生理信号，如脑电图(EEG)，皮肤电(ED)，呼吸(Resp)和温度(Temp)，是反映人类情感变化的有效生物标志物。然而，利用电生理信号进行情感识别面临数据稀缺、标注不一致、难以在个体间泛化等挑战。为解决这些问题，我们提出了ME-MHACL，一种基于自监督对比学习的多模态情感识别方法，可以从未标记的电生理信号中学习有意义的特征表示，并利用多头注意力机制进行特征融合，提高识别性能。我们的方法包括两个阶段：首先，我们使用Meiosis方法对未标记的电生理信号进行样本组合和增强，并设计了自监督对比学习方法用于训练特征表示器；然后，我们使用多头注意力机制将多模态特征进行融合，从而实现情感识别。",
    "tldr": "ME-MHACL是一种基于自监督对比学习的多模态情感识别方法，通过从未标记的电生理信号中学习特征表示，并利用多头注意力机制进行特征融合，来提高情感识别性能。"
}