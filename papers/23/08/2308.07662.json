{
    "title": "Gradient-Based Post-Training Quantization: Challenging the Status Quo. (arXiv:2308.07662v1 [cs.LG])",
    "abstract": "Quantization has become a crucial step for the efficient deployment of deep neural networks, where floating point operations are converted to simpler fixed point operations. In its most naive form, it simply consists in a combination of scaling and rounding transformations, leading to either a limited compression rate or a significant accuracy drop. Recently, Gradient-based post-training quantization (GPTQ) methods appears to be constitute a suitable trade-off between such simple methods and more powerful, yet expensive Quantization-Aware Training (QAT) approaches, particularly when attempting to quantize LLMs, where scalability of the quantization process is of paramount importance. GPTQ essentially consists in learning the rounding operation using a small calibration set. In this work, we challenge common choices in GPTQ methods. In particular, we show that the process is, to a certain extent, robust to a number of variables (weight selection, feature augmentation, choice of calibrat",
    "link": "http://arxiv.org/abs/2308.07662",
    "context": "Title: Gradient-Based Post-Training Quantization: Challenging the Status Quo. (arXiv:2308.07662v1 [cs.LG])\nAbstract: Quantization has become a crucial step for the efficient deployment of deep neural networks, where floating point operations are converted to simpler fixed point operations. In its most naive form, it simply consists in a combination of scaling and rounding transformations, leading to either a limited compression rate or a significant accuracy drop. Recently, Gradient-based post-training quantization (GPTQ) methods appears to be constitute a suitable trade-off between such simple methods and more powerful, yet expensive Quantization-Aware Training (QAT) approaches, particularly when attempting to quantize LLMs, where scalability of the quantization process is of paramount importance. GPTQ essentially consists in learning the rounding operation using a small calibration set. In this work, we challenge common choices in GPTQ methods. In particular, we show that the process is, to a certain extent, robust to a number of variables (weight selection, feature augmentation, choice of calibrat",
    "path": "papers/23/08/2308.07662.json",
    "total_tokens": 871,
    "translated_title": "基于梯度的模型训练后量化：挑战现状",
    "translated_abstract": "量化对于高效部署深度神经网络已经变得至关重要，其中浮点运算被转化为简化的定点运算。在最简单的形式中，它仅仅是由缩放和舍入转换组成，导致压缩率有限或者准确性显著下降。最近，基于梯度的模型训练后量化(GPTQ)方法在简单方法和更强大但昂贵的量化感知训练 (QAT)方法之间提供了一个合适的折衷，特别是在尝试量化大型语言模型(LLM)时，量化过程的可扩展性非常重要。GPTQ主要是通过使用一个小的校准集合来学习舍入操作。在这项工作中，我们挑战了GPTQ方法中常见的选择。特别是，我们展示了这个过程在一定程度上对多个变量(权重选择、特征增强、校准选择)具有鲁棒性。",
    "tldr": "本文挑战了基于梯度的模型训练后量化(GPTQ)方法中的常见选择，并且展示了该方法在一定程度上对多个变量具有鲁棒性。"
}