{
    "title": "CheXFusion: Effective Fusion of Multi-View Features using Transformers for Long-Tailed Chest X-Ray Classification. (arXiv:2308.03968v1 [cs.CV])",
    "abstract": "Medical image classification poses unique challenges due to the long-tailed distribution of diseases, the co-occurrence of diagnostic findings, and the multiple views available for each study or patient. This paper introduces our solution to the ICCV CVAMD 2023 Shared Task on CXR-LT: Multi-Label Long-Tailed Classification on Chest X-Rays. Our approach introduces CheXFusion, a transformer-based fusion module incorporating multi-view images. The fusion module, guided by self-attention and cross-attention mechanisms, efficiently aggregates multi-view features while considering label co-occurrence. Furthermore, we explore data balancing and self-training methods to optimize the model's performance. Our solution achieves state-of-the-art results with 0.372 mAP in the MIMIC-CXR test set, securing 1st place in the competition. Our success in the task underscores the significance of considering multi-view settings, class imbalance, and label co-occurrence in medical image classification. Publi",
    "link": "http://arxiv.org/abs/2308.03968",
    "context": "Title: CheXFusion: Effective Fusion of Multi-View Features using Transformers for Long-Tailed Chest X-Ray Classification. (arXiv:2308.03968v1 [cs.CV])\nAbstract: Medical image classification poses unique challenges due to the long-tailed distribution of diseases, the co-occurrence of diagnostic findings, and the multiple views available for each study or patient. This paper introduces our solution to the ICCV CVAMD 2023 Shared Task on CXR-LT: Multi-Label Long-Tailed Classification on Chest X-Rays. Our approach introduces CheXFusion, a transformer-based fusion module incorporating multi-view images. The fusion module, guided by self-attention and cross-attention mechanisms, efficiently aggregates multi-view features while considering label co-occurrence. Furthermore, we explore data balancing and self-training methods to optimize the model's performance. Our solution achieves state-of-the-art results with 0.372 mAP in the MIMIC-CXR test set, securing 1st place in the competition. Our success in the task underscores the significance of considering multi-view settings, class imbalance, and label co-occurrence in medical image classification. Publi",
    "path": "papers/23/08/2308.03968.json",
    "total_tokens": 1059,
    "translated_title": "CheXFusion: 用Transformer有效地融合多视角特征进行长尾胸部X射线分类",
    "translated_abstract": "医学图像分类由于疾病的长尾分布、诊断结果的共现性和每个研究或患者可用的多视角而面临独特的挑战。本文介绍了我们对ICCV CVAMD 2023共享任务CX-LT：胸部X射线的多标签长尾分类的解决方案。我们的方法引入了一个基于Transformer的融合模块CheXFusion，该模块能够有效地聚合多视角特征，并在考虑标签共现性的同时采用自注意力和交叉注意力机制进行引导。此外，我们还探索了数据平衡和自训练方法来优化模型的性能。我们的解决方案在MIMIC-CXR测试集中达到了0.372的mAP，获得了竞赛的第一名。我们在任务中取得的成功突显了在医学图像分类中考虑多视角设置、类别不平衡和标签共现性的重要性。",
    "tldr": "本文介绍了一种名为CheXFusion的基于Transformer的融合模块，可用于长尾胸部X射线分类。该模块利用自注意力和交叉注意力机制，有效地聚合多视角特征并考虑标签共现性。通过数据平衡和自训练方法，该解决方案在MIMIC-CXR测试集上取得了0.372的mAP，成为竞赛的冠军。本研究强调了在医学图像分类中考虑多视角设置、类别不平衡和标签共现性的重要性。",
    "en_tdlr": "This paper introduces CheXFusion, a transformer-based fusion module, for long-tailed chest X-ray classification. The module effectively aggregates multi-view features guided by self-attention and cross-attention mechanisms, considering label co-occurrence. With data balancing and self-training methods, the solution achieves state-of-the-art results and secures first place in the competition. The study highlights the significance of considering multi-view settings, class imbalance, and label co-occurrence in medical image classification."
}