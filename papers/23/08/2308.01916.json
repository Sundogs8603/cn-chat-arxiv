{
    "title": "Semi Supervised Meta Learning for Spatiotemporal Learning. (arXiv:2308.01916v1 [cs.CV])",
    "abstract": "We approached the goal of applying meta-learning to self-supervised masked autoencoders for spatiotemporal learning in three steps. Broadly, we seek to understand the impact of applying meta-learning to existing state-of-the-art representation learning architectures. Thus, we test spatiotemporal learning through: a meta-learning architecture only, a representation learning architecture only, and an architecture applying representation learning alongside a meta learning architecture. We utilize the Memory Augmented Neural Network (MANN) architecture to apply meta-learning to our framework. Specifically, we first experiment with applying a pre-trained MAE and fine-tuning on our small-scale spatiotemporal dataset for video reconstruction tasks. Next, we experiment with training an MAE encoder and applying a classification head for action classification tasks. Finally, we experiment with applying a pre-trained MAE and fine-tune with MANN backbone for action classification tasks.",
    "link": "http://arxiv.org/abs/2308.01916",
    "context": "Title: Semi Supervised Meta Learning for Spatiotemporal Learning. (arXiv:2308.01916v1 [cs.CV])\nAbstract: We approached the goal of applying meta-learning to self-supervised masked autoencoders for spatiotemporal learning in three steps. Broadly, we seek to understand the impact of applying meta-learning to existing state-of-the-art representation learning architectures. Thus, we test spatiotemporal learning through: a meta-learning architecture only, a representation learning architecture only, and an architecture applying representation learning alongside a meta learning architecture. We utilize the Memory Augmented Neural Network (MANN) architecture to apply meta-learning to our framework. Specifically, we first experiment with applying a pre-trained MAE and fine-tuning on our small-scale spatiotemporal dataset for video reconstruction tasks. Next, we experiment with training an MAE encoder and applying a classification head for action classification tasks. Finally, we experiment with applying a pre-trained MAE and fine-tune with MANN backbone for action classification tasks.",
    "path": "papers/23/08/2308.01916.json",
    "total_tokens": 919,
    "translated_title": "半监督元学习在时空学习中的应用",
    "translated_abstract": "我们通过三个步骤来将元学习应用于自监督遮蔽自编码器以进行时空学习。广义上说，我们旨在理解将元学习应用于现有的最先进的表示学习架构的影响。因此，我们通过以下方式测试时空学习：仅元学习架构、仅表示学习架构以及将表示学习与元学习架构相结合的架构。我们利用了增强记忆神经网络（MANN）架构将元学习应用于我们的框架。具体而言，我们首先尝试在小规模时空数据集上应用预训练的自监督遮蔽自编码器，并进行视频重建任务的微调。接下来，我们尝试训练自监督遮蔽自编码器的编码器，并应用分类头进行动作分类任务。最后，我们尝试在预训练的自监督遮蔽自编码器的基础上，用MANN骨干进行微调，用于动作分类任务。",
    "tldr": "本文探讨了半监督元学习在时空学习中的应用，通过将元学习应用于自监督遮蔽自编码器，并结合状态-of-the-art表示学习架构，提出了一种新的框架来解决视频重建和动作分类任务。",
    "en_tdlr": "This paper explores the application of semi-supervised meta-learning in spatiotemporal learning, proposing a new framework by applying meta-learning to self-supervised masked autoencoders and combining them with state-of-the-art representation learning architectures to solve video reconstruction and action classification tasks."
}