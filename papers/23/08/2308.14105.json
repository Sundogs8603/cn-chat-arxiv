{
    "title": "Unified and Dynamic Graph for Temporal Character Grouping in Long Videos. (arXiv:2308.14105v2 [cs.CV] UPDATED)",
    "abstract": "Video temporal character grouping locates appearing moments of major characters within a video according to their identities. To this end, recent works have evolved from unsupervised clustering to graph-based supervised clustering. However, graph methods are built upon the premise of fixed affinity graphs, bringing many inexact connections. Besides, they extract multi-modal features with kinds of models, which are unfriendly to deployment. In this paper, we present a unified and dynamic graph (UniDG) framework for temporal character grouping. This is accomplished firstly by a unified representation network that learns representations of multiple modalities within the same space and still preserves the modality's uniqueness simultaneously. Secondly, we present a dynamic graph clustering where the neighbors of different quantities are dynamically constructed for each node via a cyclic matching strategy, leading to a more reliable affinity graph. Thirdly, a progressive association method ",
    "link": "http://arxiv.org/abs/2308.14105",
    "context": "Title: Unified and Dynamic Graph for Temporal Character Grouping in Long Videos. (arXiv:2308.14105v2 [cs.CV] UPDATED)\nAbstract: Video temporal character grouping locates appearing moments of major characters within a video according to their identities. To this end, recent works have evolved from unsupervised clustering to graph-based supervised clustering. However, graph methods are built upon the premise of fixed affinity graphs, bringing many inexact connections. Besides, they extract multi-modal features with kinds of models, which are unfriendly to deployment. In this paper, we present a unified and dynamic graph (UniDG) framework for temporal character grouping. This is accomplished firstly by a unified representation network that learns representations of multiple modalities within the same space and still preserves the modality's uniqueness simultaneously. Secondly, we present a dynamic graph clustering where the neighbors of different quantities are dynamically constructed for each node via a cyclic matching strategy, leading to a more reliable affinity graph. Thirdly, a progressive association method ",
    "path": "papers/23/08/2308.14105.json",
    "total_tokens": 861,
    "translated_title": "长视频中的时间性角色分组的统一动态图",
    "translated_abstract": "视频时间性角色分组根据角色的身份在视频中定位出现的时刻。 为此，最近的研究从无监督聚类发展到基于图的有监督聚类。 然而，图方法建立在固定的亲和图前提下，带来了许多不精确的连接。 此外，它们使用各种模型提取多模态特征，对部署不友好。在本文中，我们提出了一种用于时间性角色分组的统一动态图（UniDG）框架。首先，通过一个统一的表示网络，我们学习了同一空间中多个模态的表示，并同时保留了模态的独特性。其次，我们提出了一种动态图聚类方法，通过循环匹配策略为每个节点动态构建不同数量的邻居，以获得更可靠的亲和图。 第三，我们提出了一个渐进式的关联方法",
    "tldr": "本文提出了一种统一动态图（UniDG）框架，通过统一的表示网络学习多模态表示，并保留模态的独特性。采用动态图聚类方法构建可靠的亲和图，并提出了一种渐进式的关联方法。",
    "en_tdlr": "This paper introduces a unified dynamic graph framework (UniDG) for temporal character grouping in long videos by learning unified representations of multiple modalities and constructing reliable affinity graphs through dynamic graph clustering, along with a progressive association method."
}