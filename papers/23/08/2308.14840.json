{
    "title": "Identifying and Mitigating the Security Risks of Generative AI. (arXiv:2308.14840v1 [cs.AI])",
    "abstract": "Every major technical invention resurfaces the dual-use dilemma -- the new technology has the potential to be used for good as well as for harm. Generative AI (GenAI) techniques, such as large language models (LLMs) and diffusion models, have shown remarkable capabilities (e.g., in-context learning, code-completion, and text-to-image generation and editing). However, GenAI can be used just as well by attackers to generate new attacks and increase the velocity and efficacy of existing attacks.  This paper reports the findings of a workshop held at Google (co-organized by Stanford University and the University of Wisconsin-Madison) on the dual-use dilemma posed by GenAI. This paper is not meant to be comprehensive, but is rather an attempt to synthesize some of the interesting findings from the workshop. We discuss short-term and long-term goals for the community on this topic. We hope this paper provides both a launching point for a discussion on this important topic as well as interest",
    "link": "http://arxiv.org/abs/2308.14840",
    "context": "Title: Identifying and Mitigating the Security Risks of Generative AI. (arXiv:2308.14840v1 [cs.AI])\nAbstract: Every major technical invention resurfaces the dual-use dilemma -- the new technology has the potential to be used for good as well as for harm. Generative AI (GenAI) techniques, such as large language models (LLMs) and diffusion models, have shown remarkable capabilities (e.g., in-context learning, code-completion, and text-to-image generation and editing). However, GenAI can be used just as well by attackers to generate new attacks and increase the velocity and efficacy of existing attacks.  This paper reports the findings of a workshop held at Google (co-organized by Stanford University and the University of Wisconsin-Madison) on the dual-use dilemma posed by GenAI. This paper is not meant to be comprehensive, but is rather an attempt to synthesize some of the interesting findings from the workshop. We discuss short-term and long-term goals for the community on this topic. We hope this paper provides both a launching point for a discussion on this important topic as well as interest",
    "path": "papers/23/08/2308.14840.json",
    "total_tokens": 943,
    "translated_title": "识别和减轻生成式人工智能的安全风险",
    "translated_abstract": "每一项重大技术发明都会带来双重用途的困境 - 新技术既有可能被用于善良，也可能被用于恶意行为。生成式人工智能（GenAI）技术，如大型语言模型（LLM）和扩散模型，展示了卓越的能力（例如上下文学习，代码补全，文本到图像的生成和编辑）。然而，攻击者同样可以利用GenAI生成新的攻击，并增加现有攻击的速度和有效性。本文报告了在Google举办的一个研讨会的发现（由斯坦福大学和威斯康星大学麦迪逊分校共同组织）。本文并不意味着全面，而是试图综合一些有趣的研讨会发现。我们讨论了这个主题的短期和长期目标。我们希望这篇论文既为这个重要主题的讨论提供一个起点，也引起兴趣。",
    "tldr": "生成式人工智能技术具有巨大的潜力，但也存在安全风险。这篇论文是一个研讨会的综合报道，讨论了生成式人工智能所带来的双重用途困境，提出了社区在这个领域的短期和长期目标。"
}