{
    "title": "Quantum Multi-Agent Reinforcement Learning for Autonomous Mobility Cooperation. (arXiv:2308.01519v1 [cs.MA])",
    "abstract": "For Industry 4.0 Revolution, cooperative autonomous mobility systems are widely used based on multi-agent reinforcement learning (MARL). However, the MARL-based algorithms suffer from huge parameter utilization and convergence difficulties with many agents. To tackle these problems, a quantum MARL (QMARL) algorithm based on the concept of actor-critic network is proposed, which is beneficial in terms of scalability, to deal with the limitations in the noisy intermediate-scale quantum (NISQ) era. Additionally, our QMARL is also beneficial in terms of efficient parameter utilization and fast convergence due to quantum supremacy. Note that the reward in our QMARL is defined as task precision over computation time in multiple agents, thus, multi-agent cooperation can be realized. For further improvement, an additional technique for scalability is proposed, which is called projection value measure (PVM). Based on PVM, our proposed QMARL can achieve the highest reward, by reducing the action",
    "link": "http://arxiv.org/abs/2308.01519",
    "context": "Title: Quantum Multi-Agent Reinforcement Learning for Autonomous Mobility Cooperation. (arXiv:2308.01519v1 [cs.MA])\nAbstract: For Industry 4.0 Revolution, cooperative autonomous mobility systems are widely used based on multi-agent reinforcement learning (MARL). However, the MARL-based algorithms suffer from huge parameter utilization and convergence difficulties with many agents. To tackle these problems, a quantum MARL (QMARL) algorithm based on the concept of actor-critic network is proposed, which is beneficial in terms of scalability, to deal with the limitations in the noisy intermediate-scale quantum (NISQ) era. Additionally, our QMARL is also beneficial in terms of efficient parameter utilization and fast convergence due to quantum supremacy. Note that the reward in our QMARL is defined as task precision over computation time in multiple agents, thus, multi-agent cooperation can be realized. For further improvement, an additional technique for scalability is proposed, which is called projection value measure (PVM). Based on PVM, our proposed QMARL can achieve the highest reward, by reducing the action",
    "path": "papers/23/08/2308.01519.json",
    "total_tokens": 955,
    "translated_title": "量子多智能体强化学习用于自主移动协作",
    "translated_abstract": "在工业4.0革命中，基于多智能体强化学习（MARL）的合作自主移动系统被广泛应用。然而，MARL算法存在着大量参数使用和收敛困难的问题。为了解决这些问题，提出了一种基于演员-评论家网络概念的量子MARL（QMARL）算法，这在可扩展性方面是有益的，以应对噪声中尺度量子（NISQ）时代的限制。此外，我们的QMARL在参数利用效率和快速收敛方面也具有益处，这是由于量子霸权的原因。值得注意的是，我们的QMARL中的奖励定义为多个智能体在计算时间上的任务精度，因此可以实现多智能体的协作。为了进一步提高，提出了一种名为投影价值测量（PVM）的可扩展技术。基于PVM，我们提出的QMARL可以通过减少动作来实现最高的奖励。",
    "tldr": "本论文提出了基于演员-评论家网络概念的量子多智能体强化学习（QMARL）算法，目标是应对多智能体系统中的参数利用和收敛困难问题。QMARL在可扩展性、参数利用效率和快速收敛方面具有优势，并通过定义奖励为多个智能体在计算时间上的任务精度来实现多智能体的协作。另外，论文还提出了一种名为投影价值测量（PVM）的可扩展技术来进一步提高系统的表现。"
}