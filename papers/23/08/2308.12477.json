{
    "title": "American Stories: A Large-Scale Structured Text Dataset of Historical U.S. Newspapers. (arXiv:2308.12477v1 [cs.CL])",
    "abstract": "Existing full text datasets of U.S. public domain newspapers do not recognize the often complex layouts of newspaper scans, and as a result the digitized content scrambles texts from articles, headlines, captions, advertisements, and other layout regions. OCR quality can also be low. This study develops a novel, deep learning pipeline for extracting full article texts from newspaper images and applies it to the nearly 20 million scans in Library of Congress's public domain Chronicling America collection. The pipeline includes layout detection, legibility classification, custom OCR, and association of article texts spanning multiple bounding boxes. To achieve high scalability, it is built with efficient architectures designed for mobile phones. The resulting American Stories dataset provides high quality data that could be used for pre-training a large language model to achieve better understanding of historical English and historical world knowledge. The dataset could also be added to ",
    "link": "http://arxiv.org/abs/2308.12477",
    "context": "Title: American Stories: A Large-Scale Structured Text Dataset of Historical U.S. Newspapers. (arXiv:2308.12477v1 [cs.CL])\nAbstract: Existing full text datasets of U.S. public domain newspapers do not recognize the often complex layouts of newspaper scans, and as a result the digitized content scrambles texts from articles, headlines, captions, advertisements, and other layout regions. OCR quality can also be low. This study develops a novel, deep learning pipeline for extracting full article texts from newspaper images and applies it to the nearly 20 million scans in Library of Congress's public domain Chronicling America collection. The pipeline includes layout detection, legibility classification, custom OCR, and association of article texts spanning multiple bounding boxes. To achieve high scalability, it is built with efficient architectures designed for mobile phones. The resulting American Stories dataset provides high quality data that could be used for pre-training a large language model to achieve better understanding of historical English and historical world knowledge. The dataset could also be added to ",
    "path": "papers/23/08/2308.12477.json",
    "total_tokens": 997,
    "translated_title": "美国故事：一种基于历史美国报纸的大规模结构化文本数据集",
    "translated_abstract": "现有的美国公共领域报纸全文数据集没有识别报纸扫描的复杂布局，结果导致数字化内容对文章、标题、字幕、广告等布局区域的文本进行了混合。光学字符识别（OCR）的质量也可能较低。本研究开发了一种新颖的深度学习流水线，用于从报纸图像中提取完整的文章文本，并将其应用于美国国会图书馆公共领域《慢性美国》集合中的近2000万份扫描。该流水线包括布局检测、可读性分类、自定义OCR和跨多个边界框关联文章文本等步骤。为了实现高扩展性，它采用了专为移动电话设计的高效架构。结果产生的美国故事数据集提供了高质量的数据，可以用于对大型语言模型进行预训练，以实现对历史英语和历史世界知识的更好理解。该数据集还可以添加到...",
    "tldr": "这项研究开发了一种新颖的深度学习流水线，用于从历史美国报纸图像中提取完整的文章文本，以解决现有数据集中布局识别和OCR质量的问题。通过构建高效的架构，实现了高扩展性，并创建了高质量的数据集，可用于预训练大型语言模型，并提升对历史英语和历史世界知识的理解。",
    "en_tdlr": "This study develops a novel deep learning pipeline to extract full article texts from historical U.S. newspaper images, addressing the layout recognition and OCR quality issues in existing datasets. By building an efficient architecture, it achieves high scalability and creates a high-quality dataset that can be used for pre-training large language models and improving understanding of historical English and historical world knowledge."
}