{
    "title": "Exploring XAI for the Arts: Explaining Latent Space in Generative Music. (arXiv:2308.05496v1 [cs.AI])",
    "abstract": "Explainable AI has the potential to support more interactive and fluid co-creative AI systems which can creatively collaborate with people. To do this, creative AI models need to be amenable to debugging by offering eXplainable AI (XAI) features which are inspectable, understandable, and modifiable. However, currently there is very little XAI for the arts. In this work, we demonstrate how a latent variable model for music generation can be made more explainable; specifically we extend MeasureVAE which generates measures of music. We increase the explainability of the model by: i) using latent space regularisation to force some specific dimensions of the latent space to map to meaningful musical attributes, ii) providing a user interface feedback loop to allow people to adjust dimensions of the latent space and observe the results of these changes in real-time, iii) providing a visualisation of the musical attributes in the latent space to help people understand and predict the effect o",
    "link": "http://arxiv.org/abs/2308.05496",
    "context": "Title: Exploring XAI for the Arts: Explaining Latent Space in Generative Music. (arXiv:2308.05496v1 [cs.AI])\nAbstract: Explainable AI has the potential to support more interactive and fluid co-creative AI systems which can creatively collaborate with people. To do this, creative AI models need to be amenable to debugging by offering eXplainable AI (XAI) features which are inspectable, understandable, and modifiable. However, currently there is very little XAI for the arts. In this work, we demonstrate how a latent variable model for music generation can be made more explainable; specifically we extend MeasureVAE which generates measures of music. We increase the explainability of the model by: i) using latent space regularisation to force some specific dimensions of the latent space to map to meaningful musical attributes, ii) providing a user interface feedback loop to allow people to adjust dimensions of the latent space and observe the results of these changes in real-time, iii) providing a visualisation of the musical attributes in the latent space to help people understand and predict the effect o",
    "path": "papers/23/08/2308.05496.json",
    "total_tokens": 950,
    "translated_title": "探索XAI在艺术领域的应用：解释生成音乐中的潜空间",
    "translated_abstract": "可解释的人工智能（XAI）有潜力支持更具互动性和流畅性的协作创造型人工智能系统，这些系统可以与人类进行创造性的合作。为了实现这一点，创造性的人工智能模型需要具备可调试的特性，即可检查、可理解和可修改。然而，目前在艺术领域中几乎没有可解释的人工智能。在这项工作中，我们演示了如何使音乐生成的潜变量模型更加可解释；具体而言，我们扩展了生成音乐小节的MeasureVAE模型。我们通过以下方式增加了模型的可解释性：i）使用潜空间正则化，强制一些特定维度的潜空间映射到有意义的音乐属性，ii）提供用户界面反馈循环，允许用户调整潜空间的维度并实时观察这些变化的结果，iii）提供音乐属性在潜空间中的可视化，帮助用户理解和预测效果。",
    "tldr": "本研究旨在探索XAI在艺术领域的应用。通过使用可解释的生成音乐的潜变量模型，我们通过潜空间正则化、用户界面反馈循环和音乐属性的可视化来增加模型的可解释性。",
    "en_tdlr": "This research explores the application of XAI in the arts. By using an explainable latent variable model for music generation, the model's explainability is increased through latent space regularization, a user interface feedback loop, and visualization of musical attributes."
}