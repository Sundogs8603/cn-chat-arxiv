{
    "title": "Holy Grail 2.0: From Natural Language to Constraint Models. (arXiv:2308.01589v1 [cs.AI])",
    "abstract": "Twenty-seven years ago, E. Freuder highlighted that \"Constraint programming represents one of the closest approaches computer science has yet made to the Holy Grail of programming: the user states the problem, the computer solves it\". Nowadays, CP users have great modeling tools available (like Minizinc and CPMpy), allowing them to formulate the problem and then let a solver do the rest of the job, getting closer to the stated goal. However, this still requires the CP user to know the formalism and respect it. Another significant challenge lies in the expertise required to effectively model combinatorial problems. All this limits the wider adoption of CP. In this position paper, we investigate a possible approach to leverage pre-trained Large Language Models to extract models from textual problem descriptions. More specifically, we take inspiration from the Natural Language Processing for Optimization (NL4OPT) challenge and present early results with a decomposition-based prompting app",
    "link": "http://arxiv.org/abs/2308.01589",
    "context": "Title: Holy Grail 2.0: From Natural Language to Constraint Models. (arXiv:2308.01589v1 [cs.AI])\nAbstract: Twenty-seven years ago, E. Freuder highlighted that \"Constraint programming represents one of the closest approaches computer science has yet made to the Holy Grail of programming: the user states the problem, the computer solves it\". Nowadays, CP users have great modeling tools available (like Minizinc and CPMpy), allowing them to formulate the problem and then let a solver do the rest of the job, getting closer to the stated goal. However, this still requires the CP user to know the formalism and respect it. Another significant challenge lies in the expertise required to effectively model combinatorial problems. All this limits the wider adoption of CP. In this position paper, we investigate a possible approach to leverage pre-trained Large Language Models to extract models from textual problem descriptions. More specifically, we take inspiration from the Natural Language Processing for Optimization (NL4OPT) challenge and present early results with a decomposition-based prompting app",
    "path": "papers/23/08/2308.01589.json",
    "total_tokens": 822,
    "translated_title": "圣杯2.0：从自然语言到约束模型",
    "translated_abstract": "27年前，E. Freuder强调了“约束编程代表了计算机科学对于编程的一个最接近圣杯的方法：用户陈述问题，计算机解决问题”。如今，CP用户拥有强大的建模工具（如Minizinc和CPMpy），可以用它们来表达问题，然后让求解器完成剩下的工作，离目标更近了。然而，这仍然要求CP用户了解形式化方法并遵守它。另一个重要的挑战在于需要专业知识才能有效地对组合问题建模。所有这些限制了CP的广泛应用。在这篇立场论文中，我们探讨了一种利用预训练的大型语言模型从文本问题描述中提取模型的可能方法。具体来说，我们从自然语言处理优化（NL4OPT）挑战中获得灵感，并展示了一个基于分解的提示应用的初步结果。",
    "tldr": "本文通过利用预训练的大型语言模型从文本问题描述中提取模型的方法，探索了一种使约束编程更易于采用的方法。",
    "en_tdlr": "This paper investigates an approach to extract models from textual problem descriptions using pre-trained large language models, aiming to make constraint programming more easily adopted."
}