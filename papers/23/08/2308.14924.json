{
    "title": "Optimal Economic Gas Turbine Dispatch with Deep Reinforcement Learning. (arXiv:2308.14924v1 [cs.LG])",
    "abstract": "Dispatching strategies for gas turbines (GTs) are changing in modern electricity grids. A growing incorporation of intermittent renewable energy requires GTs to operate more but shorter cycles and more frequently on partial loads. Deep reinforcement learning (DRL) has recently emerged as a tool that can cope with this development and dispatch GTs economically. The key advantages of DRL are a model-free optimization and the ability to handle uncertainties, such as those introduced by varying loads or renewable energy production. In this study, three popular DRL algorithms are implemented for an economic GT dispatch problem on a case study in Alberta, Canada. We highlight the benefits of DRL by incorporating an existing thermodynamic software provided by Siemens Energy into the environment model and by simulating uncertainty via varying electricity prices, loads, and ambient conditions. Among the tested algorithms and baseline methods, Deep Q-Networks (DQN) obtained the highest rewards w",
    "link": "http://arxiv.org/abs/2308.14924",
    "context": "Title: Optimal Economic Gas Turbine Dispatch with Deep Reinforcement Learning. (arXiv:2308.14924v1 [cs.LG])\nAbstract: Dispatching strategies for gas turbines (GTs) are changing in modern electricity grids. A growing incorporation of intermittent renewable energy requires GTs to operate more but shorter cycles and more frequently on partial loads. Deep reinforcement learning (DRL) has recently emerged as a tool that can cope with this development and dispatch GTs economically. The key advantages of DRL are a model-free optimization and the ability to handle uncertainties, such as those introduced by varying loads or renewable energy production. In this study, three popular DRL algorithms are implemented for an economic GT dispatch problem on a case study in Alberta, Canada. We highlight the benefits of DRL by incorporating an existing thermodynamic software provided by Siemens Energy into the environment model and by simulating uncertainty via varying electricity prices, loads, and ambient conditions. Among the tested algorithms and baseline methods, Deep Q-Networks (DQN) obtained the highest rewards w",
    "path": "papers/23/08/2308.14924.json",
    "total_tokens": 915,
    "translated_title": "使用深度强化学习进行经济燃气轮机调度优化",
    "translated_abstract": "在现代电力网络中，燃气轮机的调度策略正在发生变化。与间歇性可再生能源的日益融入相比，燃气轮机需要更频繁地以更短周期和部分负载运行。深度强化学习（DRL）最近被提出作为可以应对这种发展并在经济上调度燃气轮机的工具。DRL的主要优势是无模型优化和处理不确定性的能力，比如由不同负载或可再生能源产生的变化。在本研究中，我们实现了三种流行的DRL算法来解决加拿大阿尔伯塔省的经济燃气轮机调度问题，并通过将西门子能源提供的现有热力学软件纳入环境模型并模拟不确定性（如电价、负载和环境条件的变化）来凸显DRL的优势。",
    "tldr": "本研究通过将西门子能源提供的热力学软件纳入环境模型，并模拟不确定性，揭示了使用深度强化学习进行经济燃气轮机调度优化的好处，并发现Deep Q-Networks (DQN) 在算法和基准方法中获得了最高的奖励。",
    "en_tdlr": "This study highlights the benefits of using deep reinforcement learning for optimal economic gas turbine dispatch by incorporating an existing thermodynamic software and simulating uncertainty, and finds that Deep Q-Networks (DQN) achieved the highest rewards among the tested algorithms and baseline methods."
}