{
    "title": "IPA: Inference Pipeline Adaptation to Achieve High Accuracy and Cost-Efficiency. (arXiv:2308.12871v1 [cs.DC])",
    "abstract": "Efficiently optimizing multi-model inference pipelines for fast, accurate, and cost-effective inference is a crucial challenge in ML production systems, given their tight end-to-end latency requirements. To simplify the exploration of the vast and intricate trade-off space of accuracy and cost in inference pipelines, providers frequently opt to consider one of them. However, the challenge lies in reconciling accuracy and cost trade-offs. To address this challenge and propose a solution to efficiently manage model variants in inference pipelines, we present IPA, an online deep-learning Inference Pipeline Adaptation system that efficiently leverages model variants for each deep learning task. Model variants are different versions of pre-trained models for the same deep learning task with variations in resource requirements, latency, and accuracy. IPA dynamically configures batch size, replication, and model variants to optimize accuracy, minimize costs, and meet user-defined latency SLAs",
    "link": "http://arxiv.org/abs/2308.12871",
    "context": "Title: IPA: Inference Pipeline Adaptation to Achieve High Accuracy and Cost-Efficiency. (arXiv:2308.12871v1 [cs.DC])\nAbstract: Efficiently optimizing multi-model inference pipelines for fast, accurate, and cost-effective inference is a crucial challenge in ML production systems, given their tight end-to-end latency requirements. To simplify the exploration of the vast and intricate trade-off space of accuracy and cost in inference pipelines, providers frequently opt to consider one of them. However, the challenge lies in reconciling accuracy and cost trade-offs. To address this challenge and propose a solution to efficiently manage model variants in inference pipelines, we present IPA, an online deep-learning Inference Pipeline Adaptation system that efficiently leverages model variants for each deep learning task. Model variants are different versions of pre-trained models for the same deep learning task with variations in resource requirements, latency, and accuracy. IPA dynamically configures batch size, replication, and model variants to optimize accuracy, minimize costs, and meet user-defined latency SLAs",
    "path": "papers/23/08/2308.12871.json",
    "total_tokens": 888,
    "translated_title": "IPA：推理管道自适应以实现高准确性和成本效益",
    "translated_abstract": "在机器学习生产系统中，高效地优化多模型推理管道以实现快速、准确和成本效益的推理是一个关键挑战，考虑到它们对端到端延迟的严格要求。为了简化准确性和成本之间广阔而复杂的权衡空间的探索，提供者通常选择考虑其中之一。然而，挑战在于协调准确性和成本的权衡。为了应对这一挑战并提出一种有效管理推理管道中模型变体的解决方案，我们提出了IPA，一种在线深度学习推理管道自适应系统，它能够有效地利用每个深度学习任务的模型变体。模型变体是同一深度学习任务的预训练模型的不同版本，其资源需求、延迟和准确性有所不同。IPA通过动态配置批处理大小、复制和模型变体来优化准确性、最小化成本并满足用户定义的延迟SLA。",
    "tldr": "提出了一种名为IPA的在线深度学习推理管道自适应系统，通过动态配置批处理大小、复制和模型变体，以优化准确性、最小化成本并满足用户定义的延迟要求。",
    "en_tdlr": "IPA is an online deep-learning Inference Pipeline Adaptation system that optimizes accuracy, minimizes costs, and meets user-defined latency SLAs by dynamically configuring batch size, replication, and model variants."
}