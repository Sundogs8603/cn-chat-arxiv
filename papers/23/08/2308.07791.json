{
    "title": "Informed Named Entity Recognition Decoding for Generative Language Models. (arXiv:2308.07791v1 [cs.CL])",
    "abstract": "Ever-larger language models with ever-increasing capabilities are by now well-established text processing tools. Alas, information extraction tasks such as named entity recognition are still largely unaffected by this progress as they are primarily based on the previous generation of encoder-only transformer models. Here, we propose a simple yet effective approach, Informed Named Entity Recognition Decoding (iNERD), which treats named entity recognition as a generative process. It leverages the language understanding capabilities of recent generative models in a future-proof manner and employs an informed decoding scheme incorporating the restricted nature of information extraction into open-ended text generation, improving performance and eliminating any risk of hallucinations. We coarse-tune our model on a merged named entity corpus to strengthen its performance, evaluate five generative language models on eight named entity recognition datasets, and achieve remarkable results, espec",
    "link": "http://arxiv.org/abs/2308.07791",
    "context": "Title: Informed Named Entity Recognition Decoding for Generative Language Models. (arXiv:2308.07791v1 [cs.CL])\nAbstract: Ever-larger language models with ever-increasing capabilities are by now well-established text processing tools. Alas, information extraction tasks such as named entity recognition are still largely unaffected by this progress as they are primarily based on the previous generation of encoder-only transformer models. Here, we propose a simple yet effective approach, Informed Named Entity Recognition Decoding (iNERD), which treats named entity recognition as a generative process. It leverages the language understanding capabilities of recent generative models in a future-proof manner and employs an informed decoding scheme incorporating the restricted nature of information extraction into open-ended text generation, improving performance and eliminating any risk of hallucinations. We coarse-tune our model on a merged named entity corpus to strengthen its performance, evaluate five generative language models on eight named entity recognition datasets, and achieve remarkable results, espec",
    "path": "papers/23/08/2308.07791.json",
    "total_tokens": 829,
    "translated_title": "为生成式语言模型提供信息的命名实体识别解码",
    "translated_abstract": "越来越大的语言模型具有越来越强的能力，已成为被广泛应用的文本处理工具。然而，信息提取任务，如命名实体识别，仍然受到之前一代仅编码器的转换器模型的影响。在这里，我们提出了一种简单但有效的方法，称为Informed Named Entity Recognition Decoding（iNERD），它将命名实体识别视为一种生成过程。它以面向未来的方式利用最近生成模型的语言理解能力，并采用了一种基于信息提取的有限文本生成方法，提高了性能并消除了任何幻觉的风险。我们在合并的命名实体语料库上粗调优化了模型，评估了五个生成式语言模型在八个命名实体识别数据集上的表现，并取得了显著的结果。",
    "tldr": "该论文提出了一种利用生成式语言模型进行命名实体识别解码的方法，通过在信息提取过程中应用生成模型的语言理解能力，提高了性能并消除了幻觉的风险。",
    "en_tdlr": "This paper proposes an approach called Informed Named Entity Recognition Decoding (iNERD) that treats named entity recognition as a generative process, leveraging the language understanding capabilities of generative models to improve performance and eliminate the risk of hallucinations."
}