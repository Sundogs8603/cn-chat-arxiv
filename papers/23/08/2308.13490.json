{
    "title": "TpuGraphs: A Performance Prediction Dataset on Large Tensor Computational Graphs. (arXiv:2308.13490v1 [cs.LG])",
    "abstract": "Precise hardware performance models play a crucial role in code optimizations. They can assist compilers in making heuristic decisions or aid autotuners in identifying the optimal configuration for a given program. For example, the autotuner for XLA, a machine learning compiler, discovered 10-20% speedup on state-of-the-art models serving substantial production traffic at Google. Although there exist a few datasets for program performance prediction, they target small sub-programs such as basic blocks or kernels. This paper introduces TpuGraphs, a performance prediction dataset on full tensor programs, represented as computational graphs, running on Tensor Processing Units (TPUs). Each graph in the dataset represents the main computation of a machine learning workload, e.g., a training epoch or an inference step. Each data sample contains a computational graph, a compilation configuration, and the execution time of the graph when compiled with the configuration. The graphs in the datas",
    "link": "http://arxiv.org/abs/2308.13490",
    "context": "Title: TpuGraphs: A Performance Prediction Dataset on Large Tensor Computational Graphs. (arXiv:2308.13490v1 [cs.LG])\nAbstract: Precise hardware performance models play a crucial role in code optimizations. They can assist compilers in making heuristic decisions or aid autotuners in identifying the optimal configuration for a given program. For example, the autotuner for XLA, a machine learning compiler, discovered 10-20% speedup on state-of-the-art models serving substantial production traffic at Google. Although there exist a few datasets for program performance prediction, they target small sub-programs such as basic blocks or kernels. This paper introduces TpuGraphs, a performance prediction dataset on full tensor programs, represented as computational graphs, running on Tensor Processing Units (TPUs). Each graph in the dataset represents the main computation of a machine learning workload, e.g., a training epoch or an inference step. Each data sample contains a computational graph, a compilation configuration, and the execution time of the graph when compiled with the configuration. The graphs in the datas",
    "path": "papers/23/08/2308.13490.json",
    "total_tokens": 756,
    "translated_title": "TpuGraphs:一种关于大型张量计算图的性能预测数据集",
    "translated_abstract": "精确的硬件性能模型在代码优化中起着关键作用。它们可以帮助编译器做出启发性决策，或者帮助自动调优工具找到给定程序的最佳配置。本文介绍了TpuGraphs，一种在Tensor Processing Units（TPUs）上运行的全张量程序的性能预测数据集，这些程序以计算图的形式表示。数据集中的每个图表示机器学习工作负载的主要计算，例如训练周期或推断步骤。每个数据样本包含一个计算图、一个编译配置，以及使用该配置编译时图的执行时间。",
    "tldr": "TpuGraphs是一种关于大型张量计算图的性能预测数据集，可用于优化编译器或自动调优工具的决策，并提供了图的执行时间信息。",
    "en_tdlr": "TpuGraphs is a performance prediction dataset on large tensor computational graphs, which can assist in optimizing compilers or autotuners by providing execution time information for the graphs."
}