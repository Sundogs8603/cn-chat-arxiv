{
    "title": "With a Little Help from the Authors: Reproducing Human Evaluation of an MT Error Detector. (arXiv:2308.06527v1 [cs.CL])",
    "abstract": "This work presents our efforts to reproduce the results of the human evaluation experiment presented in the paper of Vamvas and Sennrich (2022), which evaluated an automatic system detecting over- and undertranslations (translations containing more or less information than the original) in machine translation (MT) outputs. Despite the high quality of the documentation and code provided by the authors, we discuss some problems we found in reproducing the exact experimental setup and offer recommendations for improving reproducibility. Our replicated results generally confirm the conclusions of the original study, but in some cases, statistically significant differences were observed, suggesting a high variability of human annotation.",
    "link": "http://arxiv.org/abs/2308.06527",
    "context": "Title: With a Little Help from the Authors: Reproducing Human Evaluation of an MT Error Detector. (arXiv:2308.06527v1 [cs.CL])\nAbstract: This work presents our efforts to reproduce the results of the human evaluation experiment presented in the paper of Vamvas and Sennrich (2022), which evaluated an automatic system detecting over- and undertranslations (translations containing more or less information than the original) in machine translation (MT) outputs. Despite the high quality of the documentation and code provided by the authors, we discuss some problems we found in reproducing the exact experimental setup and offer recommendations for improving reproducibility. Our replicated results generally confirm the conclusions of the original study, but in some cases, statistically significant differences were observed, suggesting a high variability of human annotation.",
    "path": "papers/23/08/2308.06527.json",
    "total_tokens": 767,
    "translated_title": "从作者那里获得一点帮助：复现机器翻译错误检测的人工评估",
    "translated_abstract": "本研究介绍了我们努力复现Vamvas和Sennrich（2022年）论文中呈现的人工评估实验的结果。该实验评估了自动系统在机器翻译输出中检测到的超翻译和低翻译（翻译比原文包含更多或更少信息）的能力。尽管作者提供了高质量的文档和代码，我们在复现实验设计方面发现了一些问题，并提出了提高可重复性的建议。我们复现的结果总体上验证了原始研究的结论，但在某些情况下，观察到了统计上显著的差异，表明人工标注存在较高的变异性。",
    "tldr": "本研究努力复现了Vamvas和Sennrich（2022年）论文中的人工评估实验，结果确认了原研究的结论并提出了评估的可变性。",
    "en_tdlr": "This work aims to reproduce the human evaluation experiment presented in the paper by Vamvas and Sennrich (2022) on automatic detection of over- and undertranslations in machine translation outputs. The replicated results generally confirm the original study's conclusions, but also highlight the variability in human annotation."
}