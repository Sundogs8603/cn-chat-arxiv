{
    "title": "MoCoSA: Momentum Contrast for Knowledge Graph Completion with Structure-Augmented Pre-trained Language Models. (arXiv:2308.08204v1 [cs.CL])",
    "abstract": "Knowledge Graph Completion (KGC) aims to conduct reasoning on the facts within knowledge graphs and automatically infer missing links. Existing methods can mainly be categorized into structure-based or description-based. On the one hand, structure-based methods effectively represent relational facts in knowledge graphs using entity embeddings. However, they struggle with semantically rich real-world entities due to limited structural information and fail to generalize to unseen entities. On the other hand, description-based methods leverage pre-trained language models (PLMs) to understand textual information. They exhibit strong robustness towards unseen entities. However, they have difficulty with larger negative sampling and often lag behind structure-based methods. To address these issues, in this paper, we propose Momentum Contrast for knowledge graph completion with Structure-Augmented pre-trained language models (MoCoSA), which allows the PLM to perceive the structural informatio",
    "link": "http://arxiv.org/abs/2308.08204",
    "context": "Title: MoCoSA: Momentum Contrast for Knowledge Graph Completion with Structure-Augmented Pre-trained Language Models. (arXiv:2308.08204v1 [cs.CL])\nAbstract: Knowledge Graph Completion (KGC) aims to conduct reasoning on the facts within knowledge graphs and automatically infer missing links. Existing methods can mainly be categorized into structure-based or description-based. On the one hand, structure-based methods effectively represent relational facts in knowledge graphs using entity embeddings. However, they struggle with semantically rich real-world entities due to limited structural information and fail to generalize to unseen entities. On the other hand, description-based methods leverage pre-trained language models (PLMs) to understand textual information. They exhibit strong robustness towards unseen entities. However, they have difficulty with larger negative sampling and often lag behind structure-based methods. To address these issues, in this paper, we propose Momentum Contrast for knowledge graph completion with Structure-Augmented pre-trained language models (MoCoSA), which allows the PLM to perceive the structural informatio",
    "path": "papers/23/08/2308.08204.json",
    "total_tokens": 901,
    "translated_title": "MoCoSA: 动量对比与结构增强的预训练语言模型在知识图谱补全中的应用",
    "translated_abstract": "知识图谱补全旨在对知识图谱中的事实进行推理，并自动推断出缺失的连接。现有方法主要分为基于结构和基于描述两类。基于结构的方法使用实体嵌入来有效表示知识图谱中的关系事实。然而，由于结构信息有限，这些方法在处理语义丰富的真实世界实体时遇到困难，并且无法泛化到未见实体。基于描述的方法则利用预训练语言模型（PLMs）来理解文本信息，对未见实体展示出很强的鲁棒性。然而，它们在进行大规模的负采样时面临困难，并且常常落后于基于结构的方法。为解决这些问题，本文提出了一种使用动量对比和结构增强预训练语言模型（MoCoSA）用于知识图谱补全的方法。",
    "tldr": "本文提出了MoCoSA方法，利用动量对比和结构增强的预训练语言模型，在知识图谱补全中解决了基于结构和基于描述方法的问题，实现了对语义丰富实体的泛化推理和对未见实体的鲁棒性。",
    "en_tdlr": "This paper proposes MoCoSA, a method that uses momentum contrast and structure-augmented pre-trained language models to address the issues of both structure-based and description-based methods in knowledge graph completion, achieving generalized reasoning for semantically rich entities and robustness for unseen entities."
}