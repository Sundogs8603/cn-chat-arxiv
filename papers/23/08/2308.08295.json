{
    "title": "Detoxify Language Model Step-by-Step. (arXiv:2308.08295v1 [cs.CL])",
    "abstract": "Detoxification for LLMs is challenging since it requires models to avoid generating harmful content while maintaining the generation capability. To ensure the safety of generations, previous detoxification methods detoxify the models by changing the data distributions or constraining the generations from different aspects in a single-step manner. However, these approaches will dramatically affect the generation quality of LLMs, e.g., discourse coherence and semantic consistency, since language models tend to generate along the toxic prompt while detoxification methods work in the opposite direction. To handle such a conflict, we decompose the detoxification process into different sub-steps, where the detoxification is concentrated in the input stage and the subsequent continual generation is based on the non-toxic prompt. Besides, we also calibrate the strong reasoning ability of LLMs by designing a Detox-Chain to connect the above sub-steps in an orderly manner, which allows LLMs to d",
    "link": "http://arxiv.org/abs/2308.08295",
    "context": "Title: Detoxify Language Model Step-by-Step. (arXiv:2308.08295v1 [cs.CL])\nAbstract: Detoxification for LLMs is challenging since it requires models to avoid generating harmful content while maintaining the generation capability. To ensure the safety of generations, previous detoxification methods detoxify the models by changing the data distributions or constraining the generations from different aspects in a single-step manner. However, these approaches will dramatically affect the generation quality of LLMs, e.g., discourse coherence and semantic consistency, since language models tend to generate along the toxic prompt while detoxification methods work in the opposite direction. To handle such a conflict, we decompose the detoxification process into different sub-steps, where the detoxification is concentrated in the input stage and the subsequent continual generation is based on the non-toxic prompt. Besides, we also calibrate the strong reasoning ability of LLMs by designing a Detox-Chain to connect the above sub-steps in an orderly manner, which allows LLMs to d",
    "path": "papers/23/08/2308.08295.json",
    "total_tokens": 869,
    "translated_title": "分步解毒语言模型",
    "translated_abstract": "解毒语言模型具有挑战性，因为它要求模型在保持生成能力的同时避免生成有害内容。为了确保生成的安全性，先前的解毒方法通过改变数据分布或在单步骤中从不同方面约束生成来解毒模型。然而，由于语言模型倾向于沿着有毒提示生成，解毒方法的工作方向与之相反，这些方法将大大影响LLM的生成质量，如话语连贯性和语义一致性。为了处理这种冲突，我们将解毒过程分解为不同的子步骤，其中解毒集中在输入阶段，随后的连续生成基于无毒提示。此外，我们还通过设计一个Detox-Chain来校准LLMs的强大推理能力，以有序的方式连接上述子步骤，这使得LLMs可以进行连续的解毒生成。",
    "tldr": "这项研究提出了一种分步解毒语言模型的方法，通过在输入阶段进行解毒处理，并使用无毒提示进行连续生成来保持生成质量。同时，通过设计Detox-Chain来校准LLMs的推理能力，实现了更安全和可靠的生成。",
    "en_tdlr": "This study presents an approach to detoxify language models in a step-by-step manner by detoxifying the models in the input stage and ensuring continuous generation based on non-toxic prompts. The detoxification process is calibrated using a Detox-Chain to maintain generation quality while enhancing safety and reliability."
}