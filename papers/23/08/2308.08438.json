{
    "title": "Accurate synthesis of Dysarthric Speech for ASR data augmentation. (arXiv:2308.08438v1 [cs.SD])",
    "abstract": "Dysarthria is a motor speech disorder often characterized by reduced speech intelligibility through slow, uncoordinated control of speech production muscles. Automatic Speech recognition (ASR) systems can help dysarthric talkers communicate more effectively. However, robust dysarthria-specific ASR requires a significant amount of training speech, which is not readily available for dysarthric talkers. This paper presents a new dysarthric speech synthesis method for the purpose of ASR training data augmentation. Differences in prosodic and acoustic characteristics of dysarthric spontaneous speech at varying severity levels are important components for dysarthric speech modeling, synthesis, and augmentation. For dysarthric speech synthesis, a modified neural multi-talker TTS is implemented by adding a dysarthria severity level coefficient and a pause insertion model to synthesize dysarthric speech for varying severity levels. To evaluate the effectiveness for synthesis of training data fo",
    "link": "http://arxiv.org/abs/2308.08438",
    "context": "Title: Accurate synthesis of Dysarthric Speech for ASR data augmentation. (arXiv:2308.08438v1 [cs.SD])\nAbstract: Dysarthria is a motor speech disorder often characterized by reduced speech intelligibility through slow, uncoordinated control of speech production muscles. Automatic Speech recognition (ASR) systems can help dysarthric talkers communicate more effectively. However, robust dysarthria-specific ASR requires a significant amount of training speech, which is not readily available for dysarthric talkers. This paper presents a new dysarthric speech synthesis method for the purpose of ASR training data augmentation. Differences in prosodic and acoustic characteristics of dysarthric spontaneous speech at varying severity levels are important components for dysarthric speech modeling, synthesis, and augmentation. For dysarthric speech synthesis, a modified neural multi-talker TTS is implemented by adding a dysarthria severity level coefficient and a pause insertion model to synthesize dysarthric speech for varying severity levels. To evaluate the effectiveness for synthesis of training data fo",
    "path": "papers/23/08/2308.08438.json",
    "total_tokens": 920,
    "translated_title": "ASR数据增强中对口吃性语音的准确合成方法",
    "translated_abstract": "口吃是一种运动言语障碍，常通过对言语产生肌肉的缓慢、不协调的控制来表征语音可理解性降低。自动语音识别（ASR）系统可以帮助口吃患者更有效地进行交流。然而，稳健的针对口吃的ASR需要大量的训练语音，而这对于口吃患者来说并不容易获得。本文提出了一种新的口吃语音合成方法，用于ASR训练数据增强。口吃自发语音在不同严重程度水平上的韵律和声学特征差异是口吃语音建模、合成和增强的重要组成部分。为了进行口吃语音合成，采用了一种修改后的多话者神经文本到语音（TTS）方法，通过添加口吃严重程度系数和暂停插入模型，合成不同严重程度的口吃语音。为了评估合成训练数据的有效性，进行了ASR性能测试。",
    "tldr": "本文提出了一种针对口吃患者的ASR训练数据增强的口吃语音合成方法，通过添加严重程度系数和暂停插入模型，实现了不同严重程度口吃语音的合成。",
    "en_tdlr": "This paper presents a new method for synthesizing dysarthric speech for ASR training data augmentation. It modifies a multi-talker TTS model by adding a dysarthria severity level coefficient and a pause insertion model to synthesize dysarthric speech of varying severity levels."
}