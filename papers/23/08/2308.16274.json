{
    "title": "Learning Diverse Features in Vision Transformers for Improved Generalization. (arXiv:2308.16274v1 [cs.CV])",
    "abstract": "Deep learning models often rely only on a small set of features even when there is a rich set of predictive signals in the training data. This makes models brittle and sensitive to distribution shifts. In this work, we first examine vision transformers (ViTs) and find that they tend to extract robust and spurious features with distinct attention heads. As a result of this modularity, their performance under distribution shifts can be significantly improved at test time by pruning heads corresponding to spurious features, which we demonstrate using an \"oracle selection\" on validation data. Second, we propose a method to further enhance the diversity and complementarity of the learned features by encouraging orthogonality of the attention heads' input gradients. We observe improved out-of-distribution performance on diagnostic benchmarks (MNIST-CIFAR, Waterbirds) as a consequence of the enhanced diversity of features and the pruning of undesirable heads.",
    "link": "http://arxiv.org/abs/2308.16274",
    "context": "Title: Learning Diverse Features in Vision Transformers for Improved Generalization. (arXiv:2308.16274v1 [cs.CV])\nAbstract: Deep learning models often rely only on a small set of features even when there is a rich set of predictive signals in the training data. This makes models brittle and sensitive to distribution shifts. In this work, we first examine vision transformers (ViTs) and find that they tend to extract robust and spurious features with distinct attention heads. As a result of this modularity, their performance under distribution shifts can be significantly improved at test time by pruning heads corresponding to spurious features, which we demonstrate using an \"oracle selection\" on validation data. Second, we propose a method to further enhance the diversity and complementarity of the learned features by encouraging orthogonality of the attention heads' input gradients. We observe improved out-of-distribution performance on diagnostic benchmarks (MNIST-CIFAR, Waterbirds) as a consequence of the enhanced diversity of features and the pruning of undesirable heads.",
    "path": "papers/23/08/2308.16274.json",
    "total_tokens": 1002,
    "translated_title": "学习多样化特征以改善视觉Transformer的泛化性能",
    "translated_abstract": "深度学习模型通常仅依赖于少量特征，即使训练数据中存在丰富的预测信号。这使得模型脆弱且对分布变化敏感。本研究首先研究了视觉Transformer(ViTs)，发现它们倾向于提取具有不同注意头的健壮和虚假特征。通过剪枝对应于虚假特征的注意头，在验证数据上使用\"oracle选择\"证明它们在分布变化下的性能可以得到显著改善。其次，我们提出了一种方法，通过鼓励注意头输入梯度的正交性，进一步增强学习特征的多样性和互补性。通过增强特征的多样性和剪枝不良注意头，我们观察到在诊断基准测试中（MNIST-CIFAR，水鸟）的改进的超出分布性能。",
    "tldr": "本文中，我们首先研究了视觉Transformer并发现其具有提取稳健和虚假特征的特点。通过剪枝虚假特征对应的注意头，我们证明了在验证数据上使用\"oracle选择\"可以显著提高其在分布变化下的性能。其次，我们提出了一种方法来增加学习特征的多样性和互补性，通过鼓励注意头输入梯度的正交性。我们观察到，这种增强特征多样性和剪枝不良注意头的方法在诊断基准测试中取得了改进的超出分布性能。",
    "en_tdlr": "In this paper, we investigate vision transformers and discover their ability to extract robust and spurious features. By pruning heads corresponding to spurious features, we demonstrate significant improvement in performance under distribution shifts. Furthermore, by enhancing the diversity of learned features and pruning undesirable heads, we observe improved out-of-distribution performance on diagnostic benchmarks."
}