{
    "title": "Revisiting Prompt Engineering via Declarative Crowdsourcing. (arXiv:2308.03854v1 [cs.DB])",
    "abstract": "Large language models (LLMs) are incredibly powerful at comprehending and generating data in the form of text, but are brittle and error-prone. There has been an advent of toolkits and recipes centered around so-called prompt engineering-the process of asking an LLM to do something via a series of prompts. However, for LLM-powered data processing workflows, in particular, optimizing for quality, while keeping cost bounded, is a tedious, manual process. We put forth a vision for declarative prompt engineering. We view LLMs like crowd workers and leverage ideas from the declarative crowdsourcing literature-including leveraging multiple prompting strategies, ensuring internal consistency, and exploring hybrid-LLM-non-LLM approaches-to make prompt engineering a more principled process. Preliminary case studies on sorting, entity resolution, and imputation demonstrate the promise of our approach",
    "link": "http://arxiv.org/abs/2308.03854",
    "context": "Title: Revisiting Prompt Engineering via Declarative Crowdsourcing. (arXiv:2308.03854v1 [cs.DB])\nAbstract: Large language models (LLMs) are incredibly powerful at comprehending and generating data in the form of text, but are brittle and error-prone. There has been an advent of toolkits and recipes centered around so-called prompt engineering-the process of asking an LLM to do something via a series of prompts. However, for LLM-powered data processing workflows, in particular, optimizing for quality, while keeping cost bounded, is a tedious, manual process. We put forth a vision for declarative prompt engineering. We view LLMs like crowd workers and leverage ideas from the declarative crowdsourcing literature-including leveraging multiple prompting strategies, ensuring internal consistency, and exploring hybrid-LLM-non-LLM approaches-to make prompt engineering a more principled process. Preliminary case studies on sorting, entity resolution, and imputation demonstrate the promise of our approach",
    "path": "papers/23/08/2308.03854.json",
    "total_tokens": 803,
    "translated_title": "通过声明式众包重新审视提示工程",
    "translated_abstract": "大型语言模型(LLM)在理解和生成文本数据方面具有极大的能力，但也容易脆弱和错误。近年来涌现了以所谓的提示工程为中心的工具包和技术方法，通过一系列提示向LLM提出要求。然而，在LLM驱动的数据处理工作流中，优化质量并保持成本有限是一项繁琐的手动过程。我们提出了一个声明式提示工程的愿景。我们将LLM视为众包工人，并借鉴了声明式众包文献中的思想，包括利用多种提示策略，确保内部一致性以及探索混合LLM非LLM方法，以使提示工程过程更加原则性。对排序、实体解析和插补的初步案例研究展示了我们方法的潜力。",
    "tldr": "本研究通过借鉴声明式众包的思想，提出了一种声明式提示工程的方法，旨在解决大型语言模型在数据处理中的质量优化和成本控制问题。",
    "en_tdlr": "This paper proposes a declarative prompt engineering approach, inspired by the idea of declarative crowdsourcing, to address the challenges of quality optimization and cost control in data processing with large language models."
}