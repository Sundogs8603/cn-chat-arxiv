{
    "title": "Dynamic ensemble selection based on Deep Neural Network Uncertainty Estimation for Adversarial Robustness. (arXiv:2308.00346v1 [cs.LG])",
    "abstract": "The deep neural network has attained significant efficiency in image recognition. However, it has vulnerable recognition robustness under extensive data uncertainty in practical applications. The uncertainty is attributed to the inevitable ambient noise and, more importantly, the possible adversarial attack. Dynamic methods can effectively improve the defense initiative in the arms race of attack and defense of adversarial examples. Different from the previous dynamic method depend on input or decision, this work explore the dynamic attributes in model level through dynamic ensemble selection technology to further protect the model from white-box attacks and improve the robustness. Specifically, in training phase the Dirichlet distribution is apply as prior of sub-models' predictive distribution, and the diversity constraint in parameter space is introduced under the lightweight sub-models to construct alternative ensembel model spaces. In test phase, the certain sub-models are dynamic",
    "link": "http://arxiv.org/abs/2308.00346",
    "context": "Title: Dynamic ensemble selection based on Deep Neural Network Uncertainty Estimation for Adversarial Robustness. (arXiv:2308.00346v1 [cs.LG])\nAbstract: The deep neural network has attained significant efficiency in image recognition. However, it has vulnerable recognition robustness under extensive data uncertainty in practical applications. The uncertainty is attributed to the inevitable ambient noise and, more importantly, the possible adversarial attack. Dynamic methods can effectively improve the defense initiative in the arms race of attack and defense of adversarial examples. Different from the previous dynamic method depend on input or decision, this work explore the dynamic attributes in model level through dynamic ensemble selection technology to further protect the model from white-box attacks and improve the robustness. Specifically, in training phase the Dirichlet distribution is apply as prior of sub-models' predictive distribution, and the diversity constraint in parameter space is introduced under the lightweight sub-models to construct alternative ensembel model spaces. In test phase, the certain sub-models are dynamic",
    "path": "papers/23/08/2308.00346.json",
    "total_tokens": 1014,
    "translated_title": "基于深度神经网络不确定性估计的动态集成选择方法用于对抗鲁棒性",
    "translated_abstract": "深度神经网络在图像识别方面取得了显著的效果，但在实际应用中面临着大量数据不确定性的识别鲁棒性薄弱的问题。这种不确定性是由环境中不可避免的噪声以及可能的对抗性攻击引起的。动态方法可以有效地改善对抗性示例攻防竞赛中的防御主动性。与以前依赖于输入或决策的动态方法不同，本研究通过动态集成选择技术在模型层面上探索动态属性，以进一步保护模型免受白盒攻击并提高鲁棒性。具体而言，在训练阶段，将Dirichlet分布作为子模型预测分布的先验，并在轻量级子模型下引入参数空间的多样性约束，以构建备选集成模型空间。在测试阶段，特定的子模型被动态选取",
    "tldr": "本文针对深度神经网络在实际应用中的鲁棒性问题，提出了一种通过动态集成选择技术在模型层面上改善模型的防御主动性的方法。通过在训练阶段引入Dirichlet分布作为子模型预测分布的先验，并在轻量级子模型下引入参数空间的多样性约束，构建备选的集成模型空间。在测试阶段，动态选取特定的子模型来提高模型的鲁棒性。"
}