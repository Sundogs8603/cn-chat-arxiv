{
    "title": "Biquality Learning: a Framework to Design Algorithms Dealing with Closed-Set Distribution Shifts. (arXiv:2308.15132v1 [cs.LG])",
    "abstract": "Training machine learning models from data with weak supervision and dataset shifts is still challenging. Designing algorithms when these two situations arise has not been explored much, and existing algorithms cannot always handle the most complex distributional shifts. We think the biquality data setup is a suitable framework for designing such algorithms. Biquality Learning assumes that two datasets are available at training time: a trusted dataset sampled from the distribution of interest and the untrusted dataset with dataset shifts and weaknesses of supervision (aka distribution shifts). The trusted and untrusted datasets available at training time make designing algorithms dealing with any distribution shifts possible. We propose two methods, one inspired by the label noise literature and another by the covariate shift literature for biquality learning. We experiment with two novel methods to synthetically introduce concept drift and class-conditional shifts in real-world datase",
    "link": "http://arxiv.org/abs/2308.15132",
    "context": "Title: Biquality Learning: a Framework to Design Algorithms Dealing with Closed-Set Distribution Shifts. (arXiv:2308.15132v1 [cs.LG])\nAbstract: Training machine learning models from data with weak supervision and dataset shifts is still challenging. Designing algorithms when these two situations arise has not been explored much, and existing algorithms cannot always handle the most complex distributional shifts. We think the biquality data setup is a suitable framework for designing such algorithms. Biquality Learning assumes that two datasets are available at training time: a trusted dataset sampled from the distribution of interest and the untrusted dataset with dataset shifts and weaknesses of supervision (aka distribution shifts). The trusted and untrusted datasets available at training time make designing algorithms dealing with any distribution shifts possible. We propose two methods, one inspired by the label noise literature and another by the covariate shift literature for biquality learning. We experiment with two novel methods to synthetically introduce concept drift and class-conditional shifts in real-world datase",
    "path": "papers/23/08/2308.15132.json",
    "total_tokens": 912,
    "translated_title": "两质量学习：处理闭集分布转换的算法设计框架",
    "translated_abstract": "从弱监督和数据集转换的数据训练机器学习模型依然具有挑战性。在这两种情况下设计算法并没有得到充分探索，现有的算法也不能处理最复杂的分布转换。我们认为双质量数据设置是设计这种算法的合适框架。双质量学习假设在训练时有两个数据集可用：一个从感兴趣的分布中采样的可信数据集，以及带有数据集转换和弱监督的不可信数据集（即分布转换）。训练时可用的可信和不可信数据集使得设计能够处理任何分布转换的算法成为可能。我们提出了两种方法，一种灵感来自标签噪声文献，另一种灵感来自协变量转换文献，用于双质量学习。我们在真实世界的数据集中尝试了两种新方法来合成概念漂移和类条件转换。",
    "tldr": "本论文提出了一种双质量学习的框架，旨在设计能够处理闭集分布转换的算法。该框架假设在训练时有一个可信数据集和一个带有数据集转换和弱监督的不可信数据集可用，可以应对任何分布转换。作者提出了两种方法来处理双质量学习，分别灵感来源于标签噪声和协变量转换，实验证明这些方法在真实世界数据集中具有较好的效果。"
}