{
    "title": "Unified Single-Stage Transformer Network for Efficient RGB-T Tracking. (arXiv:2308.13764v1 [cs.CV])",
    "abstract": "Most existing RGB-T tracking networks extract modality features in a separate manner, which lacks interaction and mutual guidance between modalities. This limits the network's ability to adapt to the diverse dual-modality appearances of targets and the dynamic relationships between the modalities. Additionally, the three-stage fusion tracking paradigm followed by these networks significantly restricts the tracking speed. To overcome these problems, we propose a unified single-stage Transformer RGB-T tracking network, namely USTrack, which unifies the above three stages into a single ViT (Vision Transformer) backbone with a dual embedding layer through self-attention mechanism. With this structure, the network can extract fusion features of the template and search region under the mutual interaction of modalities. Simultaneously, relation modeling is performed between these features, efficiently obtaining the search region fusion features with better target-background discriminability f",
    "link": "http://arxiv.org/abs/2308.13764",
    "context": "Title: Unified Single-Stage Transformer Network for Efficient RGB-T Tracking. (arXiv:2308.13764v1 [cs.CV])\nAbstract: Most existing RGB-T tracking networks extract modality features in a separate manner, which lacks interaction and mutual guidance between modalities. This limits the network's ability to adapt to the diverse dual-modality appearances of targets and the dynamic relationships between the modalities. Additionally, the three-stage fusion tracking paradigm followed by these networks significantly restricts the tracking speed. To overcome these problems, we propose a unified single-stage Transformer RGB-T tracking network, namely USTrack, which unifies the above three stages into a single ViT (Vision Transformer) backbone with a dual embedding layer through self-attention mechanism. With this structure, the network can extract fusion features of the template and search region under the mutual interaction of modalities. Simultaneously, relation modeling is performed between these features, efficiently obtaining the search region fusion features with better target-background discriminability f",
    "path": "papers/23/08/2308.13764.json",
    "total_tokens": 935,
    "translated_title": "高效RGB-T跟踪的统一单级Transformer网络",
    "translated_abstract": "多数现有的RGB-T跟踪网络以分离的方式提取模态特征，缺乏模态之间的相互作用和互助指导。这限制了网络适应目标的多样双模态外观和模态之间的动态关系的能力。另外，这些网络遵循的三阶段融合跟踪范例严重限制了跟踪速度。为了解决这些问题，我们提出了一种统一单级Transformer RGB-T跟踪网络，即USTrack，将上述三个阶段合并为一个具备双嵌入层的单一ViT（视觉Transformer）骨干，并通过自注意机制进行模态的相互作用。通过这种结构，网络可以在模态的相互作用下提取模板和搜索区域的融合特征。同时，对这些特征进行关系建模，高效地获得具有更好的目标-背景可区分性的搜索区域融合特征。",
    "tldr": "提出了一种统一单级Transformer RGB-T跟踪网络USTrack，它通过双嵌入层和自注意机制实现模态之间的相互作用和互助指导，从而提高了网络适应目标的能力，并将三阶段融合跟踪范例合并为一个结构，提高了跟踪速度和目标-背景可区分性。",
    "en_tdlr": "We propose a unified single-stage Transformer RGB-T tracking network called USTrack, which leverages dual embedding layers and self-attention mechanism to enable interaction and mutual guidance between modalities, improving the network's ability to adapt to diverse target appearances. This network also combines the three-stage fusion tracking paradigm into a single structure, enhancing tracking speed and target-background discriminability."
}