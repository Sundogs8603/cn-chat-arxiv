{
    "title": "Benchmarking Adversarial Robustness of Compressed Deep Learning Models. (arXiv:2308.08160v1 [cs.LG])",
    "abstract": "The increasing size of Deep Neural Networks (DNNs) poses a pressing need for model compression, particularly when employed on resource constrained devices. Concurrently, the susceptibility of DNNs to adversarial attacks presents another significant hurdle. Despite substantial research on both model compression and adversarial robustness, their joint examination remains underexplored. Our study bridges this gap, seeking to understand the effect of adversarial inputs crafted for base models on their pruned versions. To examine this relationship, we have developed a comprehensive benchmark across diverse adversarial attacks and popular DNN models. We uniquely focus on models not previously exposed to adversarial training and apply pruning schemes optimized for accuracy and performance. Our findings reveal that while the benefits of pruning enhanced generalizability, compression, and faster inference times are preserved, adversarial robustness remains comparable to the base model. This sug",
    "link": "http://arxiv.org/abs/2308.08160",
    "context": "Title: Benchmarking Adversarial Robustness of Compressed Deep Learning Models. (arXiv:2308.08160v1 [cs.LG])\nAbstract: The increasing size of Deep Neural Networks (DNNs) poses a pressing need for model compression, particularly when employed on resource constrained devices. Concurrently, the susceptibility of DNNs to adversarial attacks presents another significant hurdle. Despite substantial research on both model compression and adversarial robustness, their joint examination remains underexplored. Our study bridges this gap, seeking to understand the effect of adversarial inputs crafted for base models on their pruned versions. To examine this relationship, we have developed a comprehensive benchmark across diverse adversarial attacks and popular DNN models. We uniquely focus on models not previously exposed to adversarial training and apply pruning schemes optimized for accuracy and performance. Our findings reveal that while the benefits of pruning enhanced generalizability, compression, and faster inference times are preserved, adversarial robustness remains comparable to the base model. This sug",
    "path": "papers/23/08/2308.08160.json",
    "total_tokens": 910,
    "translated_title": "压缩深度学习模型的对抗鲁棒性基准测试",
    "translated_abstract": "随着深度神经网络(DNNs)规模的增长，对模型压缩的需求日益迫切，特别是在资源受限设备上使用时。同时，DNNs对对抗攻击的敏感性也是一个重要障碍。尽管对于模型压缩和对抗鲁棒性的研究已经很充分，但它们的联合研究仍未得到充分探讨。我们的研究填补了这一空白，旨在了解针对基础模型制作的对抗输入对其裁剪版本的影响。为了研究这种关系，我们开发了一个全面的基准测试，涵盖了不同的对抗攻击和流行的DNN模型。我们独特地关注了之前未经过对抗训练的模型，并应用了针对准确性和性能优化的裁剪方案。我们的研究结果表明，虽然裁剪带来了增强的泛化能力、压缩效果和更快的推理时间，但对抗鲁棒性与基础模型相当。",
    "tldr": "本研究通过开发一个全面的基准测试，证明了在深度学习模型压缩过程中，裁剪模型仍能保持基础模型的对抗鲁棒性水平。",
    "en_tdlr": "This study demonstrates that pruning models can maintain the adversarial robustness level of the base models during the process of deep learning model compression."
}