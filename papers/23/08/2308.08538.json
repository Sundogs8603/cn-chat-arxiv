{
    "title": "Proprioceptive Learning with Soft Polyhedral Networks. (arXiv:2308.08538v1 [cs.RO])",
    "abstract": "Proprioception is the \"sixth sense\" that detects limb postures with motor neurons. It requires a natural integration between the musculoskeletal systems and sensory receptors, which is challenging among modern robots that aim for lightweight, adaptive, and sensitive designs at a low cost. Here, we present the Soft Polyhedral Network with an embedded vision for physical interactions, capable of adaptive kinesthesia and viscoelastic proprioception by learning kinetic features. This design enables passive adaptations to omni-directional interactions, visually captured by a miniature high-speed motion tracking system embedded inside for proprioceptive learning. The results show that the soft network can infer real-time 6D forces and torques with accuracies of 0.25/0.24/0.35 N and 0.025/0.034/0.006 Nm in dynamic interactions. We also incorporate viscoelasticity in proprioception during static adaptation by adding a creep and relaxation modifier to refine the predicted results. The proposed ",
    "link": "http://arxiv.org/abs/2308.08538",
    "context": "Title: Proprioceptive Learning with Soft Polyhedral Networks. (arXiv:2308.08538v1 [cs.RO])\nAbstract: Proprioception is the \"sixth sense\" that detects limb postures with motor neurons. It requires a natural integration between the musculoskeletal systems and sensory receptors, which is challenging among modern robots that aim for lightweight, adaptive, and sensitive designs at a low cost. Here, we present the Soft Polyhedral Network with an embedded vision for physical interactions, capable of adaptive kinesthesia and viscoelastic proprioception by learning kinetic features. This design enables passive adaptations to omni-directional interactions, visually captured by a miniature high-speed motion tracking system embedded inside for proprioceptive learning. The results show that the soft network can infer real-time 6D forces and torques with accuracies of 0.25/0.24/0.35 N and 0.025/0.034/0.006 Nm in dynamic interactions. We also incorporate viscoelasticity in proprioception during static adaptation by adding a creep and relaxation modifier to refine the predicted results. The proposed ",
    "path": "papers/23/08/2308.08538.json",
    "total_tokens": 856,
    "translated_title": "使用软多面体网络的本体感知学习",
    "translated_abstract": "本文提出了一种具备嵌入式视觉的软多面体网络，用于在物理交互中实现自适应的本体感知和粘弹性感觉。该设计通过学习动力学特性，实现了对全向交互的被动适应，并通过内嵌的微型高速运动跟踪系统以视觉方式捕获本体感知的数据。实验结果表明，软多面体网络能够以0.25/0.24/0.35 N和0.025/0.034/0.006 Nm的精度实时推断6维力和扭矩在动态交互中的作用。此外，我们还通过添加粘弹性感受性来在静态适应中增加本体感知，从而进一步提高预测结果的精度。",
    "tldr": "本文提出了一种使用软多面体网络的本体感知学习方法，通过学习动力学特性和引入嵌入式视觉，实现了在物理交互中的自适应和粘弹性感觉，可以实时推断6维力和扭矩的作用。",
    "en_tdlr": "This paper proposes a method for proprioceptive learning using soft polyhedral networks, which enables adaptive and viscoelastic proprioception in physical interactions by learning kinetic features and incorporating embedded vision. It can infer the forces and torques of 6 dimensions in real-time during dynamic interactions."
}