{
    "title": "3D-MuPPET: 3D Multi-Pigeon Pose Estimation and Tracking. (arXiv:2308.15316v1 [cs.CV] CROSS LISTED)",
    "abstract": "Markerless methods for animal posture tracking have been developing recently, but frameworks and benchmarks for tracking large animal groups in 3D are still lacking. To overcome this gap in the literature, we present 3D-MuPPET, a framework to estimate and track 3D poses of up to 10 pigeons at interactive speed using multiple-views. We train a pose estimator to infer 2D keypoints and bounding boxes of multiple pigeons, then triangulate the keypoints to 3D. For correspondence matching, we first dynamically match 2D detections to global identities in the first frame, then use a 2D tracker to maintain correspondences accross views in subsequent frames. We achieve comparable accuracy to a state of the art 3D pose estimator for Root Mean Square Error (RMSE) and Percentage of Correct Keypoints (PCK). We also showcase a novel use case where our model trained with data of single pigeons provides comparable results on data containing multiple pigeons. This can simplify the domain shift to new sp",
    "link": "http://arxiv.org/abs/2308.15316",
    "context": "Title: 3D-MuPPET: 3D Multi-Pigeon Pose Estimation and Tracking. (arXiv:2308.15316v1 [cs.CV] CROSS LISTED)\nAbstract: Markerless methods for animal posture tracking have been developing recently, but frameworks and benchmarks for tracking large animal groups in 3D are still lacking. To overcome this gap in the literature, we present 3D-MuPPET, a framework to estimate and track 3D poses of up to 10 pigeons at interactive speed using multiple-views. We train a pose estimator to infer 2D keypoints and bounding boxes of multiple pigeons, then triangulate the keypoints to 3D. For correspondence matching, we first dynamically match 2D detections to global identities in the first frame, then use a 2D tracker to maintain correspondences accross views in subsequent frames. We achieve comparable accuracy to a state of the art 3D pose estimator for Root Mean Square Error (RMSE) and Percentage of Correct Keypoints (PCK). We also showcase a novel use case where our model trained with data of single pigeons provides comparable results on data containing multiple pigeons. This can simplify the domain shift to new sp",
    "path": "papers/23/08/2308.15316.json",
    "total_tokens": 1112,
    "translated_title": "3D-MuPPET: 3D多鸽姿态估计与跟踪",
    "translated_abstract": "近年来，对动物姿势跟踪的无标记方法已有所发展，但仍缺乏用于追踪大规模动物群体的三维框架和基准。为了弥补文献中的这一空白，我们提出了3D-MuPPET，一个使用多视角实时估计和跟踪多达10只鸽子的三维姿势的框架。我们训练了一个姿势估计器，用于推测多只鸽子的2D关键点和边界框，然后将关键点三角化到3D空间。对于匹配对应关系，我们首先动态地将2D检测结果与第一帧中的全局身份进行匹配，然后使用2D跟踪器在后续帧中维持对应关系。我们达到了与最先进的3D姿势估计器相当的准确性，即均方根误差（RMSE）和正确关键点百分比（PCK）。我们还展示了一个新颖的用例，即我们使用单只鸽子的数据训练模型并在包含多只鸽子的数据上得到可比较的结果，这可以简化对新场景的领域转换。",
    "tldr": "3D-MuPPET是一个用于估计和跟踪多只鸽子三维姿势的框架，通过多视角实时推测2D关键点并将其三角化到3D空间，同时使用动态匹配和2D跟踪器维持对应关系。相比最先进的3D姿势估计器，具有可比的准确性。该框架还能在使用单只鸽子数据训练的情况下应用于多只鸽子数据，简化领域转换。",
    "en_tdlr": "3D-MuPPET is a framework for estimating and tracking the 3D poses of multiple pigeons using multiple views. It achieves comparable accuracy to state-of-the-art 3D pose estimators and can also be applied to data with multiple pigeons using a model trained with data of single pigeons, simplifying the domain shift."
}