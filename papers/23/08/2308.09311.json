{
    "title": "Lip Reading for Low-resource Languages by Learning and Combining General Speech Knowledge and Language-specific Knowledge. (arXiv:2308.09311v2 [cs.CV] UPDATED)",
    "abstract": "This paper proposes a novel lip reading framework, especially for low-resource languages, which has not been well addressed in the previous literature. Since low-resource languages do not have enough video-text paired data to train the model to have sufficient power to model lip movements and language, it is regarded as challenging to develop lip reading models for low-resource languages. In order to mitigate the challenge, we try to learn general speech knowledge, the ability to model lip movements, from a high-resource language through the prediction of speech units. It is known that different languages partially share common phonemes, thus general speech knowledge learned from one language can be extended to other languages. Then, we try to learn language-specific knowledge, the ability to model language, by proposing Language-specific Memory-augmented Decoder (LMDecoder). LMDecoder saves language-specific audio features into memory banks and can be trained on audio-text paired data",
    "link": "http://arxiv.org/abs/2308.09311",
    "context": "Title: Lip Reading for Low-resource Languages by Learning and Combining General Speech Knowledge and Language-specific Knowledge. (arXiv:2308.09311v2 [cs.CV] UPDATED)\nAbstract: This paper proposes a novel lip reading framework, especially for low-resource languages, which has not been well addressed in the previous literature. Since low-resource languages do not have enough video-text paired data to train the model to have sufficient power to model lip movements and language, it is regarded as challenging to develop lip reading models for low-resource languages. In order to mitigate the challenge, we try to learn general speech knowledge, the ability to model lip movements, from a high-resource language through the prediction of speech units. It is known that different languages partially share common phonemes, thus general speech knowledge learned from one language can be extended to other languages. Then, we try to learn language-specific knowledge, the ability to model language, by proposing Language-specific Memory-augmented Decoder (LMDecoder). LMDecoder saves language-specific audio features into memory banks and can be trained on audio-text paired data",
    "path": "papers/23/08/2308.09311.json",
    "total_tokens": 914,
    "translated_title": "学习和结合通用语音知识和语言特定知识进行低资源语言的唇语识别",
    "translated_abstract": "本文提出了一种新颖的唇语识别框架，特别针对低资源语言，在先前的文献中尚未得到很好的解决。由于低资源语言缺乏足够的视频文本配对数据来训练模型以获得足够的能力来建模唇部动作和语言，因此为低资源语言开发唇语识别模型被认为是具有挑战性的。为了缓解这一挑战，我们尝试通过预测语音单元来学习通用语音知识，即建模唇部动作的能力，从高资源语言中学习。已知不同语言部分共享相同的音素，因此从一个语言中学习的通用语音知识可以扩展到其他语言。然后，我们通过提出语言特定记忆增强解码器（LMDecoder）来尝试学习语言特定知识，即建模语言的能力。LMDecoder将语言特定的音频特征保存到存储器中，可以在音频文本配对数据上进行训练。",
    "tldr": "本文提出了一种针对低资源语言的唇语识别框架，通过学习通用语音知识和语言特定知识，克服了低资源语言中缺乏视频文本配对数据的挑战。"
}