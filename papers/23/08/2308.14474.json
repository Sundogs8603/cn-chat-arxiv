{
    "title": "Causality-Based Feature Importance Quantifying Methods: PN-FI, PS-FI and PNS-FI. (arXiv:2308.14474v2 [cs.AI] UPDATED)",
    "abstract": "In the current ML field models are getting larger and more complex, and data used for model training are also getting larger in quantity and higher in dimensions. Therefore, in order to train better models, and save training time and computational resources, a good Feature Selection (FS) method in the preprocessing stage is necessary. Feature importance (FI) is of great importance since it is the basis of feature selection. Therefore, this paper creatively introduces the calculation of PN (the probability of Necessity), PN (the probability of Sufficiency), and PNS (the probability of Necessity and Sufficiency) of Causality into quantifying feature importance and creates 3 new FI measuring methods, PN-FI, which means how much importance a feature has in image recognition tasks, PS-FI that means how much importance a feature has in image generating tasks, and PNS-FI which measures both. The main body of this paper is three RCTs, with whose results we show how PS-FI, PN-FI, and PNS-FI of ",
    "link": "http://arxiv.org/abs/2308.14474",
    "context": "Title: Causality-Based Feature Importance Quantifying Methods: PN-FI, PS-FI and PNS-FI. (arXiv:2308.14474v2 [cs.AI] UPDATED)\nAbstract: In the current ML field models are getting larger and more complex, and data used for model training are also getting larger in quantity and higher in dimensions. Therefore, in order to train better models, and save training time and computational resources, a good Feature Selection (FS) method in the preprocessing stage is necessary. Feature importance (FI) is of great importance since it is the basis of feature selection. Therefore, this paper creatively introduces the calculation of PN (the probability of Necessity), PN (the probability of Sufficiency), and PNS (the probability of Necessity and Sufficiency) of Causality into quantifying feature importance and creates 3 new FI measuring methods, PN-FI, which means how much importance a feature has in image recognition tasks, PS-FI that means how much importance a feature has in image generating tasks, and PNS-FI which measures both. The main body of this paper is three RCTs, with whose results we show how PS-FI, PN-FI, and PNS-FI of ",
    "path": "papers/23/08/2308.14474.json",
    "total_tokens": 917,
    "translated_title": "基于因果性的特征重要性量化方法：PN-FI、PS-FI和PNS-FI",
    "translated_abstract": "在当前机器学习领域，模型变得越来越大且越来越复杂，用于模型训练的数据也变得越来越多且维度越来越高。因此，为了训练更好的模型并节省训练时间和计算资源，预处理阶段需要一个好的特征选择（FS）方法。特征重要性（FI）非常重要，因为它是特征选择的基础。因此，本文创新地将因果关系的PN（必要性概率）、PS（充分性概率）和PNS（必要性和充分性概率）引入到特征重要性量化中，并创建了三种新的FI测量方法：PN-FI（用于图像识别任务中的特征重要性）、PS-FI（用于图像生成任务中的特征重要性）和PNS-FI（两者兼顾）。",
    "tldr": "本文创新地使用因果关系概率量化特征重要性，提出了三种新的特征重要性测量方法：PN-FI、PS-FI和PNS-FI，分别适用于图像识别任务和图像生成任务，并通过RCT实验证明了其有效性。"
}