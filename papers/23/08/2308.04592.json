{
    "title": "Shepherd: A Critic for Language Model Generation. (arXiv:2308.04592v1 [cs.CL])",
    "abstract": "As large language models improve, there is increasing interest in techniques that leverage these models' capabilities to refine their own outputs. In this work, we introduce Shepherd, a language model specifically tuned to critique responses and suggest refinements, extending beyond the capabilities of an untuned model to identify diverse errors and provide suggestions to remedy them. At the core of our approach is a high quality feedback dataset, which we curate from community feedback and human annotations. Even though Shepherd is small (7B parameters), its critiques are either equivalent or preferred to those from established models including ChatGPT. Using GPT-4 for evaluation, Shepherd reaches an average win-rate of 53-87% compared to competitive alternatives. In human evaluation, Shepherd strictly outperforms other models and on average closely ties with ChatGPT.",
    "link": "http://arxiv.org/abs/2308.04592",
    "context": "Title: Shepherd: A Critic for Language Model Generation. (arXiv:2308.04592v1 [cs.CL])\nAbstract: As large language models improve, there is increasing interest in techniques that leverage these models' capabilities to refine their own outputs. In this work, we introduce Shepherd, a language model specifically tuned to critique responses and suggest refinements, extending beyond the capabilities of an untuned model to identify diverse errors and provide suggestions to remedy them. At the core of our approach is a high quality feedback dataset, which we curate from community feedback and human annotations. Even though Shepherd is small (7B parameters), its critiques are either equivalent or preferred to those from established models including ChatGPT. Using GPT-4 for evaluation, Shepherd reaches an average win-rate of 53-87% compared to competitive alternatives. In human evaluation, Shepherd strictly outperforms other models and on average closely ties with ChatGPT.",
    "path": "papers/23/08/2308.04592.json",
    "total_tokens": 826,
    "translated_title": "\"Shepherd: 一种用于语言模型生成的评论者\"",
    "translated_abstract": "随着大型语言模型的改进，越来越多的技术开始利用这些模型的能力来优化其输出。本研究介绍了Shepherd，一种特定调整的语言模型，用于评论回复并提出改进建议，超越了未调整模型的能力，可以识别不同的错误并提供建议来修复它们。我们的方法的核心是一个高质量的反馈数据集，我们从社区反馈和人工注释中策划整理而成。尽管Shepherd规模较小（7B个参数），但其评论要么与ChatGPT等已建立的模型等效，要么更优。通过使用GPT-4进行评估，Shepherd相对于竞争对手平均具有53-87%的胜率。在人工评估中，Shepherd明显优于其他模型，并且平均与ChatGPT持平。",
    "tldr": "Shepherd是一种专门用于评论和提出改进建议的语言模型，通过使用高质量的反馈数据集，它可以识别和修复不同的错误。与其他模型相比，在评估和人工评估中，Shepherd的性能表现更佳。",
    "en_tdlr": "Shepherd is a language model specifically designed to critique responses and provide refinement suggestions. With a high quality feedback dataset, it can identify and address diverse errors. In evaluations and human evaluations, Shepherd outperforms other models and achieves comparable performance to ChatGPT."
}