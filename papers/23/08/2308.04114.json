{
    "title": "Collective Human Opinions in Semantic Textual Similarity. (arXiv:2308.04114v1 [cs.CL])",
    "abstract": "Despite the subjective nature of semantic textual similarity (STS) and pervasive disagreements in STS annotation, existing benchmarks have used averaged human ratings as the gold standard. Averaging masks the true distribution of human opinions on examples of low agreement, and prevents models from capturing the semantic vagueness that the individual ratings represent. In this work, we introduce USTS, the first Uncertainty-aware STS dataset with ~15,000 Chinese sentence pairs and 150,000 labels, to study collective human opinions in STS. Analysis reveals that neither a scalar nor a single Gaussian fits a set of observed judgements adequately. We further show that current STS models cannot capture the variance caused by human disagreement on individual instances, but rather reflect the predictive confidence over the aggregate dataset.",
    "link": "http://arxiv.org/abs/2308.04114",
    "context": "Title: Collective Human Opinions in Semantic Textual Similarity. (arXiv:2308.04114v1 [cs.CL])\nAbstract: Despite the subjective nature of semantic textual similarity (STS) and pervasive disagreements in STS annotation, existing benchmarks have used averaged human ratings as the gold standard. Averaging masks the true distribution of human opinions on examples of low agreement, and prevents models from capturing the semantic vagueness that the individual ratings represent. In this work, we introduce USTS, the first Uncertainty-aware STS dataset with ~15,000 Chinese sentence pairs and 150,000 labels, to study collective human opinions in STS. Analysis reveals that neither a scalar nor a single Gaussian fits a set of observed judgements adequately. We further show that current STS models cannot capture the variance caused by human disagreement on individual instances, but rather reflect the predictive confidence over the aggregate dataset.",
    "path": "papers/23/08/2308.04114.json",
    "total_tokens": 811,
    "translated_title": "团体人类观点在语义文本相似度中的应用",
    "translated_abstract": "尽管语义文本相似度（STS）具有主观性，并且在STS注释中普遍存在不一致，但现有的基准使用平均人员评分作为金标准。平均化掩盖了在低一致性示例中人类观点的真实分布，并阻止模型捕捉个别评分所代表的语义模糊性。在这项工作中，我们引入了USTS，第一个包含约15,000个中文句对和150,000个标签的不确定性感知STS数据集，以研究STS中的集体人类观点。分析表明，单一高斯函数和标量均不能充分适应一组观察到的判断。我们进一步证明，当前的STS模型无法捕捉个别实例上由人类不一致带来的变异，而是反映了对整个数据集预测置信度。",
    "tldr": "该论文介绍了USTS数据集，旨在研究语义文本相似度中的集体人类观点。分析表明现有的STS模型无法捕捉个别实例上由人类不一致带来的变异。"
}