{
    "title": "Sample Complexity of Robust Learning against Evasion Attacks. (arXiv:2308.12054v1 [cs.LG])",
    "abstract": "It is becoming increasingly important to understand the vulnerability of machine learning models to adversarial attacks. One of the fundamental problems in adversarial machine learning is to quantify how much training data is needed in the presence of evasion attacks, where data is corrupted at test time. In this thesis, we work with the exact-in-the-ball notion of robustness and study the feasibility of adversarially robust learning from the perspective of learning theory, considering sample complexity.  We first explore the setting where the learner has access to random examples only, and show that distributional assumptions are essential. We then focus on learning problems with distributions on the input data that satisfy a Lipschitz condition and show that robustly learning monotone conjunctions has sample complexity at least exponential in the adversary's budget (the maximum number of bits it can perturb on each input). However, if the adversary is restricted to perturbing $O(\\log",
    "link": "http://arxiv.org/abs/2308.12054",
    "context": "Title: Sample Complexity of Robust Learning against Evasion Attacks. (arXiv:2308.12054v1 [cs.LG])\nAbstract: It is becoming increasingly important to understand the vulnerability of machine learning models to adversarial attacks. One of the fundamental problems in adversarial machine learning is to quantify how much training data is needed in the presence of evasion attacks, where data is corrupted at test time. In this thesis, we work with the exact-in-the-ball notion of robustness and study the feasibility of adversarially robust learning from the perspective of learning theory, considering sample complexity.  We first explore the setting where the learner has access to random examples only, and show that distributional assumptions are essential. We then focus on learning problems with distributions on the input data that satisfy a Lipschitz condition and show that robustly learning monotone conjunctions has sample complexity at least exponential in the adversary's budget (the maximum number of bits it can perturb on each input). However, if the adversary is restricted to perturbing $O(\\log",
    "path": "papers/23/08/2308.12054.json",
    "total_tokens": 1011,
    "translated_title": "鲁棒学习抵御规避攻击的样本复杂度研究",
    "translated_abstract": "理解机器学习模型对抗性攻击的弱点变得越来越重要。在对抗性机器学习中，一个基本问题是在规避攻击存在的情况下，需要多少训练数据量来量化。在本论文中，我们以准确在球内的鲁棒性为基础，从学习理论的角度研究了对抗攻击情况下的鲁棒学习可行性，考虑样本复杂度。首先，我们探讨了仅有随机示例的情况，并证明了分布假设的重要性。然后，我们着重研究具有满足Lipschitz条件的输入数据分布的学习问题，证明了鲁棒学习单调并联具有指数级的样本复杂度，对应于攻击者的预算（每个输入可以扰动的最大位数）的增长。但是，如果攻击者被限制在扰动$O(\\log n)$位。",
    "tldr": "本论文研究了鲁棒学习在面对规避攻击时的样本复杂度。首先，我们发现分布假设在只有随机示例的情况下至关重要。接着，我们研究了满足Lipschitz条件的输入数据分布下，鲁棒学习单调并联所需的样本复杂度至少是指数级的。如果攻击者受限于扰动$O(\\log n)$位，则样本复杂度会更高。",
    "en_tdlr": "This paper studies the sample complexity of robust learning against evasion attacks. Firstly, it is found that distributional assumptions are crucial in the case of only having random examples. Secondly, for learning problems with input data distributions satisfying a Lipschitz condition, robustly learning monotone conjunctions requires at least exponential sample complexity. If the adversary is restricted to perturbing $O(\\log n)$ bits, the sample complexity will be even higher."
}