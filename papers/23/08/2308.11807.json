{
    "title": "Towards an On-device Agent for Text Rewriting. (arXiv:2308.11807v1 [cs.CL])",
    "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities for text rewriting. Nonetheless, the large sizes of these models make them impractical for on-device inference, which would otherwise allow for enhanced privacy and economical inference. Creating a smaller yet potent language model for text rewriting presents a formidable challenge because it requires balancing the need for a small size with the need to retain the emergent capabilities of the LLM, that requires costly data collection. To address the above challenge, we introduce a new instruction tuning approach for building a mobile-centric text rewriting model. Our strategies enable the generation of high quality training data without any human labeling. In addition, we propose a heuristic reinforcement learning framework which substantially enhances performance without requiring preference data. To further bridge the performance gap with the larger server-side model, we propose an effective approach that combines",
    "link": "http://arxiv.org/abs/2308.11807",
    "context": "Title: Towards an On-device Agent for Text Rewriting. (arXiv:2308.11807v1 [cs.CL])\nAbstract: Large Language Models (LLMs) have demonstrated impressive capabilities for text rewriting. Nonetheless, the large sizes of these models make them impractical for on-device inference, which would otherwise allow for enhanced privacy and economical inference. Creating a smaller yet potent language model for text rewriting presents a formidable challenge because it requires balancing the need for a small size with the need to retain the emergent capabilities of the LLM, that requires costly data collection. To address the above challenge, we introduce a new instruction tuning approach for building a mobile-centric text rewriting model. Our strategies enable the generation of high quality training data without any human labeling. In addition, we propose a heuristic reinforcement learning framework which substantially enhances performance without requiring preference data. To further bridge the performance gap with the larger server-side model, we propose an effective approach that combines",
    "path": "papers/23/08/2308.11807.json",
    "total_tokens": 845,
    "translated_title": "面向设备的文本重写代理的研究",
    "translated_abstract": "大型语言模型（LLMs）在文本重写方面展示了令人印象深刻的能力。然而，这些模型的体积庞大使得它们在设备上进行推理变得不实际，而后者本可能提供增强隐私和经济推理的能力。为了解决上述挑战，我们提出了一种针对构建以移动设备为中心的文本重写模型的新型指令调整方法。我们的策略能够在不需要人工标注的情况下生成高质量的训练数据。此外，我们提出了一个启发式强化学习框架，可以显著提高性能，而无需偏好数据。为了进一步弥补与更大的服务器端模型之间的性能差距，我们提出了一种有效的方法，结合了...",
    "tldr": "给出了一种面向设备的文本重写代理的构建方法，通过新的指令调整方法和启发式强化学习框架，能够生成高质量的训练数据并提高性能。能够在保持模型能力的前提下，实现移动设备上的文本重写。"
}