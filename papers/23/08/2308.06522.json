{
    "title": "SLoRA: Federated Parameter Efficient Fine-Tuning of Language Models. (arXiv:2308.06522v1 [cs.LG])",
    "abstract": "Transfer learning via fine-tuning pre-trained transformer models has gained significant success in delivering state-of-the-art results across various NLP tasks. In the absence of centralized data, Federated Learning (FL) can benefit from distributed and private data of the FL edge clients for fine-tuning. However, due to the limited communication, computation, and storage capabilities of edge devices and the huge sizes of popular transformer models, efficient fine-tuning is crucial to make federated training feasible. This work explores the opportunities and challenges associated with applying parameter efficient fine-tuning (PEFT) methods in different FL settings for language tasks. Specifically, our investigation reveals that as the data across users becomes more diverse, the gap between fully fine-tuning the model and employing PEFT methods widens. To bridge this performance gap, we propose a method called SLoRA, which overcomes the key limitations of LoRA in high heterogeneous data",
    "link": "http://arxiv.org/abs/2308.06522",
    "context": "Title: SLoRA: Federated Parameter Efficient Fine-Tuning of Language Models. (arXiv:2308.06522v1 [cs.LG])\nAbstract: Transfer learning via fine-tuning pre-trained transformer models has gained significant success in delivering state-of-the-art results across various NLP tasks. In the absence of centralized data, Federated Learning (FL) can benefit from distributed and private data of the FL edge clients for fine-tuning. However, due to the limited communication, computation, and storage capabilities of edge devices and the huge sizes of popular transformer models, efficient fine-tuning is crucial to make federated training feasible. This work explores the opportunities and challenges associated with applying parameter efficient fine-tuning (PEFT) methods in different FL settings for language tasks. Specifically, our investigation reveals that as the data across users becomes more diverse, the gap between fully fine-tuning the model and employing PEFT methods widens. To bridge this performance gap, we propose a method called SLoRA, which overcomes the key limitations of LoRA in high heterogeneous data",
    "path": "papers/23/08/2308.06522.json",
    "total_tokens": 874,
    "translated_title": "SLoRA: 联邦参数高效微调语言模型",
    "translated_abstract": "通过微调预训练的转换器模型进行迁移学习，在各种自然语言处理任务中取得了显著的成功。在没有集中式数据的情况下，联邦学习可以从联邦学习边缘客户端的分布式和私有数据中受益。然而，由于边缘设备的有限通信、计算和存储能力以及流行的转换器模型的巨大大小，高效的微调对于使联邦训练成为可行的是至关重要的。本文探讨了在不同的联邦学习设置下应用参数高效微调方法（PEFT）在语言任务中的机遇和挑战。具体而言，我们的研究发现，随着用户之间的数据越来越多样化，全面微调模型和使用PEFT方法之间的差距变大。为了弥补这个性能差距，我们提出了一种称为SLoRA的方法，它克服了高异构数据下LoRA的关键限制。",
    "tldr": "SLoRA是一种联邦参数高效微调语言模型的方法，用于在联邦学习中利用分布式和私有数据进行微调，以克服高异构数据下的性能差距。",
    "en_tdlr": "SLoRA is a method for federated parameter efficient fine-tuning of language models, which enables fine-tuning using distributed and private data in federated learning to overcome performance gap in high heterogeneous data."
}