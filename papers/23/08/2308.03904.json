{
    "title": "On genuine invariance learning without weight-tying. (arXiv:2308.03904v1 [cs.LG])",
    "abstract": "In this paper, we investigate properties and limitations of invariance learned by neural networks from the data compared to the genuine invariance achieved through invariant weight-tying. To do so, we adopt a group theoretical perspective and analyze invariance learning in neural networks without weight-tying constraints. We demonstrate that even when a network learns to correctly classify samples on a group orbit, the underlying decision-making in such a model does not attain genuine invariance. Instead, learned invariance is strongly conditioned on the input data, rendering it unreliable if the input distribution shifts. We next demonstrate how to guide invariance learning toward genuine invariance by regularizing the invariance of a model at the training. To this end, we propose several metrics to quantify learned invariance: (i) predictive distribution invariance, (ii) logit invariance, and (iii) saliency invariance similarity. We show that the invariance learned with the invarianc",
    "link": "http://arxiv.org/abs/2308.03904",
    "context": "Title: On genuine invariance learning without weight-tying. (arXiv:2308.03904v1 [cs.LG])\nAbstract: In this paper, we investigate properties and limitations of invariance learned by neural networks from the data compared to the genuine invariance achieved through invariant weight-tying. To do so, we adopt a group theoretical perspective and analyze invariance learning in neural networks without weight-tying constraints. We demonstrate that even when a network learns to correctly classify samples on a group orbit, the underlying decision-making in such a model does not attain genuine invariance. Instead, learned invariance is strongly conditioned on the input data, rendering it unreliable if the input distribution shifts. We next demonstrate how to guide invariance learning toward genuine invariance by regularizing the invariance of a model at the training. To this end, we propose several metrics to quantify learned invariance: (i) predictive distribution invariance, (ii) logit invariance, and (iii) saliency invariance similarity. We show that the invariance learned with the invarianc",
    "path": "papers/23/08/2308.03904.json",
    "total_tokens": 941,
    "translated_title": "关于不使用权重绑定的真正不变性学习",
    "translated_abstract": "本文研究神经网络从数据中学习到的不变性与通过不变权重绑定实现的真正不变性的属性和限制。为了做到这一点，我们采用了群论的视角，并分析了没有权重绑定约束的神经网络中的不变性学习。我们证明，即使网络学会了在群轨道上正确分类样本，这种模型中的决策过程并没有达到真正的不变性。相反，学习到的不变性在很大程度上取决于输入数据，如果输入分布发生变化，它将变得不可靠。接下来，我们演示了如何通过在训练中对模型的不变性进行正则化来引导不变性学习朝向真正的不变性。为此，我们提出了几个指标来量化学习到的不变性：（i）预测分布不变性，（ii）logit不变性和（iii）显著性不变性相似性。我们展示了通过不变性正规化学习到的不变性。",
    "tldr": "本文研究了神经网络从数据中学习到的不变性与通过权重绑定实现的真正不变性之间的区别，并提出了正则化方法来指导学习真正的不变性，实现了在输入数据分布发生变化时仍然可靠的不变性模型。",
    "en_tdlr": "This paper investigates the difference between invariance learned by neural networks from data and genuine invariance achieved through weight-tying. It proposes a regularization method to guide learning genuine invariance and demonstrates the reliability of the resulting model even when the input data distribution shifts."
}