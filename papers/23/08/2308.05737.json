{
    "title": "Follow Anything: Open-set detection, tracking, and following in real-time. (arXiv:2308.05737v1 [cs.RO])",
    "abstract": "Tracking and following objects of interest is critical to several robotics use cases, ranging from industrial automation to logistics and warehousing, to healthcare and security. In this paper, we present a robotic system to detect, track, and follow any object in real-time. Our approach, dubbed ``follow anything'' (FAn), is an open-vocabulary and multimodal model -- it is not restricted to concepts seen at training time and can be applied to novel classes at inference time using text, images, or click queries. Leveraging rich visual descriptors from large-scale pre-trained models (foundation models), FAn can detect and segment objects by matching multimodal queries (text, images, clicks) against an input image sequence. These detected and segmented objects are tracked across image frames, all while accounting for occlusion and object re-emergence. We demonstrate FAn on a real-world robotic system (a micro aerial vehicle) and report its ability to seamlessly follow the objects of inter",
    "link": "http://arxiv.org/abs/2308.05737",
    "context": "Title: Follow Anything: Open-set detection, tracking, and following in real-time. (arXiv:2308.05737v1 [cs.RO])\nAbstract: Tracking and following objects of interest is critical to several robotics use cases, ranging from industrial automation to logistics and warehousing, to healthcare and security. In this paper, we present a robotic system to detect, track, and follow any object in real-time. Our approach, dubbed ``follow anything'' (FAn), is an open-vocabulary and multimodal model -- it is not restricted to concepts seen at training time and can be applied to novel classes at inference time using text, images, or click queries. Leveraging rich visual descriptors from large-scale pre-trained models (foundation models), FAn can detect and segment objects by matching multimodal queries (text, images, clicks) against an input image sequence. These detected and segmented objects are tracked across image frames, all while accounting for occlusion and object re-emergence. We demonstrate FAn on a real-world robotic system (a micro aerial vehicle) and report its ability to seamlessly follow the objects of inter",
    "path": "papers/23/08/2308.05737.json",
    "total_tokens": 1014,
    "translated_title": "Follow Anything: 实时开放集检测、追踪和跟随",
    "translated_abstract": "在工业自动化、物流和仓储、医疗保健和安全等多种机器人应用中，追踪和跟随感兴趣的物体至关重要。在本文中，我们提出了一个机器人系统，能够实时检测、追踪和跟随任何物体。我们的方法被称为“跟随任何物体”（FAn），它是一个开放词汇和多模态模型 - 不受训练时的概念限制，并且可以使用文本、图像或点击查询来应用于推断时的新类别。通过利用来自大规模预训练模型（基础模型）的丰富视觉描述符，FAn可以通过将多模态查询（文本、图像、点击）与输入图像序列进行匹配来检测和分割物体。这些检测和分割的物体在图像帧之间进行跟踪，同时考虑到遮挡和物体重新出现。我们在一个实际的机器人系统上（微型飞行器）演示了FAn，并报告了其无缝跟随感兴趣物体的能力。",
    "tldr": "本文提出了一个名为“跟随任何物体”的机器人系统，可以实时检测、追踪和跟随任何物体，不受训练时概念限制，并且可以通过多模态查询进行应用。通过利用大规模预训练模型的视觉描述符，该系统能够检测、分割和跟踪物体，同时考虑遮挡和物体重新出现。",
    "en_tdlr": "This paper presents a robotic system called \"Follow Anything\" that can detect, track, and follow any object in real-time, regardless of the concepts seen during training, using multimodal queries. It utilizes visual descriptors from pre-trained models to detect, segment, and track objects while taking into account occlusion and object re-emergence."
}