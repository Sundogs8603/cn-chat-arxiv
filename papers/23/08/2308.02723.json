{
    "title": "Towards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction. (arXiv:2308.02723v1 [cs.SD])",
    "abstract": "In deep learning research, many melody extraction models rely on redesigning neural network architectures to improve performance. In this paper, we propose an input feature modification and a training objective modification based on two assumptions. First, harmonics in the spectrograms of audio data decay rapidly along the frequency axis. To enhance the model's sensitivity on the trailing harmonics, we modify the Combined Frequency and Periodicity (CFP) representation using discrete z-transform. Second, the vocal and non-vocal segments with extremely short duration are uncommon. To ensure a more stable melody contour, we design a differentiable loss function that prevents the model from predicting such segments. We apply these modifications to several models, including MSNet, FTANet, and a newly introduced model, PianoNet, modified from a piano transcription network. Our experimental results demonstrate that the proposed modifications are empirically effective for singing melody extrac",
    "link": "http://arxiv.org/abs/2308.02723",
    "context": "Title: Towards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction. (arXiv:2308.02723v1 [cs.SD])\nAbstract: In deep learning research, many melody extraction models rely on redesigning neural network architectures to improve performance. In this paper, we propose an input feature modification and a training objective modification based on two assumptions. First, harmonics in the spectrograms of audio data decay rapidly along the frequency axis. To enhance the model's sensitivity on the trailing harmonics, we modify the Combined Frequency and Periodicity (CFP) representation using discrete z-transform. Second, the vocal and non-vocal segments with extremely short duration are uncommon. To ensure a more stable melody contour, we design a differentiable loss function that prevents the model from predicting such segments. We apply these modifications to several models, including MSNet, FTANet, and a newly introduced model, PianoNet, modified from a piano transcription network. Our experimental results demonstrate that the proposed modifications are empirically effective for singing melody extrac",
    "path": "papers/23/08/2308.02723.json",
    "total_tokens": 938,
    "translated_title": "为歌唱旋律提取改进谐波敏感性和预测稳定性的途径",
    "translated_abstract": "在深度学习研究中，许多旋律提取模型依赖于重新设计神经网络架构来提高性能。本文提出了基于两个假设的输入特征修改和训练目标修改。首先，音频数据的频谱图中的谐波在频率轴上迅速衰减。为了增强模型对尾部谐波的敏感性，我们使用离散z-transform修改了联合频率和周期性(CFP)表示。其次，极短时长的人声和非人声片段并不常见。为了确保更稳定的旋律轮廓，我们设计了一个可微分的损失函数，防止模型预测这些片段。我们将这些修改应用于多个模型，包括MSNet、FTANet和新引入的模型PianoNet，该模型是从钢琴转录网络改编而来的。我们的实验结果表明，提出的修改在歌唱旋律提取上具有实证有效性。",
    "tldr": "本文提出了通过修改输入特征和训练目标来改进歌唱旋律提取的方法。这些修改包括增强对尾部谐波的敏感性和设计可防止预测极短片段的损失函数。实验结果表明，这些修改对于提高歌唱旋律提取的效果有实际效果。",
    "en_tdlr": "This paper proposes an approach to improve singing melody extraction by modifying input features and training objectives. The modifications include enhancing sensitivity to trailing harmonics and designing a loss function to prevent predicting extremely short segments. Experimental results demonstrate the effectiveness of these modifications in enhancing singing melody extraction."
}