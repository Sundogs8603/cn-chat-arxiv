{
    "title": "Defensive Perception: Estimation and Monitoring of Neural Network Performance under Deployment. (arXiv:2308.06299v1 [cs.CV])",
    "abstract": "In this paper, we propose a method for addressing the issue of unnoticed catastrophic deployment and domain shift in neural networks for semantic segmentation in autonomous driving. Our approach is based on the idea that deep learning-based perception for autonomous driving is uncertain and best represented as a probability distribution. As autonomous vehicles' safety is paramount, it is crucial for perception systems to recognize when the vehicle is leaving its operational design domain, anticipate hazardous uncertainty, and reduce the performance of the perception system. To address this, we propose to encapsulate the neural network under deployment within an uncertainty estimation envelope that is based on the epistemic uncertainty estimation through the Monte Carlo Dropout approach. This approach does not require modification of the deployed neural network and guarantees expected model performance. Our defensive perception envelope has the capability to estimate a neural network's ",
    "link": "http://arxiv.org/abs/2308.06299",
    "context": "Title: Defensive Perception: Estimation and Monitoring of Neural Network Performance under Deployment. (arXiv:2308.06299v1 [cs.CV])\nAbstract: In this paper, we propose a method for addressing the issue of unnoticed catastrophic deployment and domain shift in neural networks for semantic segmentation in autonomous driving. Our approach is based on the idea that deep learning-based perception for autonomous driving is uncertain and best represented as a probability distribution. As autonomous vehicles' safety is paramount, it is crucial for perception systems to recognize when the vehicle is leaving its operational design domain, anticipate hazardous uncertainty, and reduce the performance of the perception system. To address this, we propose to encapsulate the neural network under deployment within an uncertainty estimation envelope that is based on the epistemic uncertainty estimation through the Monte Carlo Dropout approach. This approach does not require modification of the deployed neural network and guarantees expected model performance. Our defensive perception envelope has the capability to estimate a neural network's ",
    "path": "papers/23/08/2308.06299.json",
    "total_tokens": 859,
    "translated_title": "防御感知：神经网络在部署中的性能估计和监测",
    "translated_abstract": "本文提出了一种方法，用于解决自动驾驶中语义分割神经网络在部署过程中不被察觉的灾难性问题和领域转移问题。我们的方法基于深度学习感知对自动驾驶的不确定性并将其最佳表示为概率分布。由于自动车辆的安全至关重要，感知系统必须能够识别车辆是否离开了操作设计领域，预测危险的不确定性并降低感知系统性能。为了解决这个问题，我们提出了在部署中对神经网络进行不确定性估计封装，该封装基于蒙特卡罗 Dropout 方法通过对认知不确定性进行估计。该方法不需要修改部署的神经网络，并保证预期的模型性能。我们的防御性感知封装能够估计神经网络的",
    "tldr": "本文提出了一种方法，用于解决自动驾驶中神经网络的部署中不被察觉的灾难性问题和领域转移问题。我们通过不确定性估计封装了部署中的神经网络，以提高感知系统的性能和安全性。"
}