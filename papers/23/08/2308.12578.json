{
    "title": "Mind vs. Mouth: On Measuring Re-judge Inconsistency of Social Bias in Large Language Models. (arXiv:2308.12578v1 [cs.CL])",
    "abstract": "Recent researches indicate that Pre-trained Large Language Models (LLMs) possess cognitive constructs similar to those observed in humans, prompting researchers to investigate the cognitive aspects of LLMs. This paper focuses on explicit and implicit social bias, a distinctive two-level cognitive construct in psychology. It posits that individuals' explicit social bias, which is their conscious expression of bias in the statements, may differ from their implicit social bias, which represents their unconscious bias. We propose a two-stage approach and discover a parallel phenomenon in LLMs known as \"re-judge inconsistency\" in social bias. In the initial stage, the LLM is tasked with automatically completing statements, potentially incorporating implicit social bias. However, in the subsequent stage, the same LLM re-judges the biased statement generated by itself but contradicts it. We propose that this re-judge inconsistency can be similar to the inconsistency between human's unaware im",
    "link": "http://arxiv.org/abs/2308.12578",
    "context": "Title: Mind vs. Mouth: On Measuring Re-judge Inconsistency of Social Bias in Large Language Models. (arXiv:2308.12578v1 [cs.CL])\nAbstract: Recent researches indicate that Pre-trained Large Language Models (LLMs) possess cognitive constructs similar to those observed in humans, prompting researchers to investigate the cognitive aspects of LLMs. This paper focuses on explicit and implicit social bias, a distinctive two-level cognitive construct in psychology. It posits that individuals' explicit social bias, which is their conscious expression of bias in the statements, may differ from their implicit social bias, which represents their unconscious bias. We propose a two-stage approach and discover a parallel phenomenon in LLMs known as \"re-judge inconsistency\" in social bias. In the initial stage, the LLM is tasked with automatically completing statements, potentially incorporating implicit social bias. However, in the subsequent stage, the same LLM re-judges the biased statement generated by itself but contradicts it. We propose that this re-judge inconsistency can be similar to the inconsistency between human's unaware im",
    "path": "papers/23/08/2308.12578.json",
    "total_tokens": 962,
    "translated_title": "理智对话声音：关于在大型语言模型中测量社会偏见的重新判断不一致性的论文",
    "translated_abstract": "最近的研究表明，预训练的大型语言模型(LLMs)具有与人类观察到的认知结构相似的特点，促使研究人员调查LLMs的认知方面。本文着重研究了明确和隐含的社会偏见，这是心理学中一种独特的两级认知结构。文中提出，个体的明确社会偏见，即其在陈述中表达的有意识偏见，可能与其隐含的社会偏见不同，后者代表其无意识偏见。我们提出了一个两阶段的方法，并发现LLMs中的一种并行现象，即社会偏见中的“重新判断不一致性”。在初始阶段，LLM负责自动完成陈述，可能会包含隐含的社会偏见。然而，在随后的阶段，同样的LLM重新评判了其自动生成的有偏见的陈述，但却与之相矛盾。我们提出，这种重新判断的不一致性可能类似于人类不知道其偏见的一致性。",
    "tldr": "本文研究了大型语言模型中的社会偏见，并发现了一种名为“重新判断不一致性”的现象，即在完成陈述和重新评判过程中存在矛盾。这对于理解语言模型的认知和隐含偏见具有重要意义。",
    "en_tdlr": "This paper investigates social bias in large language models and discovers a phenomenon called \"re-judge inconsistency\", which refers to the contradiction between completing statements and re-judging them. This has implications for understanding the cognition and implicit bias of language models."
}