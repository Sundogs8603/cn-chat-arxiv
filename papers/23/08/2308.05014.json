{
    "title": "An Empirical Study of Bugs in Open-Source Federated Learning Framework. (arXiv:2308.05014v1 [cs.SE])",
    "abstract": "Federated learning (FL), as a decentralized machine learning solution to the protection of users' private data, has become an important learning paradigm in recent years, especially since the enforcement of stricter laws and regulations in most countries. Therefore, a variety of FL frameworks are released to facilitate the development and application of federated learning. Despite the considerable amount of research on the security and privacy of FL models and systems, the security issues in FL frameworks have not been systematically studied yet. In this paper, we conduct the first empirical study on 1,112 FL framework bugs to investigate their characteristics. These bugs are manually collected, classified, and labeled from 12 open-source FL frameworks on GitHub. In detail, we construct taxonomies of 15 symptoms, 12 root causes, and 20 fix patterns of these bugs and investigate their correlations and distributions on 23 logical components and two main application scenarios. From the re",
    "link": "http://arxiv.org/abs/2308.05014",
    "context": "Title: An Empirical Study of Bugs in Open-Source Federated Learning Framework. (arXiv:2308.05014v1 [cs.SE])\nAbstract: Federated learning (FL), as a decentralized machine learning solution to the protection of users' private data, has become an important learning paradigm in recent years, especially since the enforcement of stricter laws and regulations in most countries. Therefore, a variety of FL frameworks are released to facilitate the development and application of federated learning. Despite the considerable amount of research on the security and privacy of FL models and systems, the security issues in FL frameworks have not been systematically studied yet. In this paper, we conduct the first empirical study on 1,112 FL framework bugs to investigate their characteristics. These bugs are manually collected, classified, and labeled from 12 open-source FL frameworks on GitHub. In detail, we construct taxonomies of 15 symptoms, 12 root causes, and 20 fix patterns of these bugs and investigate their correlations and distributions on 23 logical components and two main application scenarios. From the re",
    "path": "papers/23/08/2308.05014.json",
    "total_tokens": 876,
    "translated_title": "开源联邦学习框架中错误的实证研究",
    "translated_abstract": "联邦学习作为一种分散式的机器学习解决方案，旨在保护用户的私密数据，在近年来已成为重要的学习模式，尤其是在大多数国家实施更严格的法律法规之后。因此，发布了各种各样的联邦学习框架，以促进联邦学习的开发和应用。尽管在FL模型和系统的安全性和隐私性方面进行了大量研究，但FL框架的安全问题尚未得到系统地研究。本文首次对1,112个FL框架错误进行实证研究，以了解其特征。这些错误是通过手动从GitHub上收集、分类和标记的12个开源FL框架得来的。具体来说，我们构建了这些错误的15个症状、12个根本原因和20个修复模式的分类，并研究了它们在23个逻辑组件和两个主要应用场景上的相关性和分布。",
    "tldr": "本文通过实证研究发现了开源联邦学习框架中存在的错误，并对这些错误的特征进行了详细分析，为提高框架的安全性和稳定性提供了指导。",
    "en_tdlr": "This paper conducts an empirical study on bugs in open-source federated learning frameworks, identifying their characteristics and providing guidance for improving security and stability of the frameworks."
}