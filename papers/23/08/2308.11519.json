{
    "title": "Optimizing Multi-Class Text Classification: A Diverse Stacking Ensemble Framework Utilizing Transformers. (arXiv:2308.11519v1 [cs.CL])",
    "abstract": "Customer reviews play a crucial role in assessing customer satisfaction, gathering feedback, and driving improvements for businesses. Analyzing these reviews provides valuable insights into customer sentiments, including compliments, comments, and suggestions. Text classification techniques enable businesses to categorize customer reviews into distinct categories, facilitating a better understanding of customer feedback. However, challenges such as overfitting and bias limit the effectiveness of a single classifier in ensuring optimal prediction. This study proposes a novel approach to address these challenges by introducing a stacking ensemble-based multi-text classification method that leverages transformer models. By combining multiple single transformers, including BERT, ELECTRA, and DistilBERT, as base-level classifiers, and a meta-level classifier based on RoBERTa, an optimal predictive model is generated. The proposed stacking ensemble-based multi-text classification method aims",
    "link": "http://arxiv.org/abs/2308.11519",
    "context": "Title: Optimizing Multi-Class Text Classification: A Diverse Stacking Ensemble Framework Utilizing Transformers. (arXiv:2308.11519v1 [cs.CL])\nAbstract: Customer reviews play a crucial role in assessing customer satisfaction, gathering feedback, and driving improvements for businesses. Analyzing these reviews provides valuable insights into customer sentiments, including compliments, comments, and suggestions. Text classification techniques enable businesses to categorize customer reviews into distinct categories, facilitating a better understanding of customer feedback. However, challenges such as overfitting and bias limit the effectiveness of a single classifier in ensuring optimal prediction. This study proposes a novel approach to address these challenges by introducing a stacking ensemble-based multi-text classification method that leverages transformer models. By combining multiple single transformers, including BERT, ELECTRA, and DistilBERT, as base-level classifiers, and a meta-level classifier based on RoBERTa, an optimal predictive model is generated. The proposed stacking ensemble-based multi-text classification method aims",
    "path": "papers/23/08/2308.11519.json",
    "total_tokens": 837,
    "translated_title": "优化多类文本分类：利用转换器的多样堆叠集成框架",
    "translated_abstract": "客户评论在评估客户满意度、收集反馈和推动业务改进方面起着至关重要的作用。分析这些评论可以为客户情绪提供有价值的见解，包括赞美、评论和建议。文本分类技术使企业能够将客户评论分为不同的类别，为更好地了解客户反馈提供便利。然而，过拟合和偏见等挑战限制了单个分类器在确保最佳预测方面的有效性。本研究提出了一种新的方法来解决这些挑战，通过引入基于转换器模型的堆叠集成多文本分类方法。通过将多个单一转换器（包括BERT、ELECTRA和DistilBERT）作为基层分类器，以及基于RoBERTa的元层分类器，生成一个最优的预测模型。",
    "tldr": "本研究提出了一种利用转换器的多样堆叠集成框架，以优化多类文本分类。通过将多个单一转换器作为基层分类器，并引入基于RoBERTa的元层分类器，实现了最优的预测模型。",
    "en_tdlr": "This study proposes a diverse stacking ensemble framework utilizing transformers to optimize multi-class text classification. By combining multiple single transformers as base-level classifiers and introducing a meta-level classifier based on RoBERTa, an optimal predictive model is achieved."
}