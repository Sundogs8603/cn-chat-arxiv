{
    "title": "ReIDTrack: Multi-Object Track and Segmentation Without Motion. (arXiv:2308.01622v1 [cs.CV])",
    "abstract": "In recent years, dominant Multi-object tracking (MOT) and segmentation (MOTS) methods mainly follow the tracking-by-detection paradigm. Transformer-based end-to-end (E2E) solutions bring some ideas to MOT and MOTS, but they cannot achieve a new state-of-the-art (SOTA) performance in major MOT and MOTS benchmarks. Detection and association are two main modules of the tracking-by-detection paradigm. Association techniques mainly depend on the combination of motion and appearance information. As deep learning has been recently developed, the performance of the detection and appearance model is rapidly improved. These trends made us consider whether we can achieve SOTA based on only high-performance detection and appearance model. Our paper mainly focuses on exploring this direction based on CBNetV2 with Swin-B as a detection model and MoCo-v2 as a self-supervised appearance model. Motion information and IoU mapping were removed during the association. Our method wins 1st place on the MOTS",
    "link": "http://arxiv.org/abs/2308.01622",
    "context": "Title: ReIDTrack: Multi-Object Track and Segmentation Without Motion. (arXiv:2308.01622v1 [cs.CV])\nAbstract: In recent years, dominant Multi-object tracking (MOT) and segmentation (MOTS) methods mainly follow the tracking-by-detection paradigm. Transformer-based end-to-end (E2E) solutions bring some ideas to MOT and MOTS, but they cannot achieve a new state-of-the-art (SOTA) performance in major MOT and MOTS benchmarks. Detection and association are two main modules of the tracking-by-detection paradigm. Association techniques mainly depend on the combination of motion and appearance information. As deep learning has been recently developed, the performance of the detection and appearance model is rapidly improved. These trends made us consider whether we can achieve SOTA based on only high-performance detection and appearance model. Our paper mainly focuses on exploring this direction based on CBNetV2 with Swin-B as a detection model and MoCo-v2 as a self-supervised appearance model. Motion information and IoU mapping were removed during the association. Our method wins 1st place on the MOTS",
    "path": "papers/23/08/2308.01622.json",
    "total_tokens": 892,
    "translated_title": "ReIDTrack: 无需运动的多目标跟踪和分割",
    "translated_abstract": "近年来，主导的多目标跟踪（MOT）和分割（MOTS）方法主要遵循的是跟踪-检测范式。基于Transformer的端到端（E2E）解决方案为MOT和MOTS带来了一些想法，但它们无法在主要的MOT和MOTS基准中达到新的最高性能。检测和关联是跟踪-检测范式的两个主要模块。关联技术主要依赖于运动和外观信息的组合。随着深度学习的最近发展，检测和外观模型的性能得到了快速提升。这些趋势使我们考虑是否可以仅基于高性能的检测和外观模型实现新的最高性能。我们的论文主要关注基于CBNetV2作为检测模型、Swin-B作为检测模型、MoCo-v2作为自监督外观模型的方法。我们在MOTS基准中获得了第一名。",
    "tldr": "ReIDTrack提出了一种无需运动的多目标跟踪和分割方法，通过使用高性能的检测和外观模型，大幅度提升了性能，在MOTS基准中取得了第一名。"
}