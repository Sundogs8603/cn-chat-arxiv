{
    "title": "GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher. (arXiv:2308.06463v1 [cs.CL])",
    "abstract": "Safety lies at the core of the development of Large Language Models (LLMs). There is ample work on aligning LLMs with human ethics and preferences, including data filtering in pretraining, supervised fine-tuning, reinforcement learning from human feedback, and red teaming, etc. In this study, we discover that chat in cipher can bypass the safety alignment techniques of LLMs, which are mainly conducted in natural languages. We propose a novel framework CipherChat to systematically examine the generalizability of safety alignment to non-natural languages -- ciphers. CipherChat enables humans to chat with LLMs through cipher prompts topped with system role descriptions and few-shot enciphered demonstrations. We use CipherChat to assess state-of-the-art LLMs, including ChatGPT and GPT-4 for different representative human ciphers across 11 safety domains in both English and Chinese. Experimental results show that certain ciphers succeed almost 100% of the time to bypass the safety alignment",
    "link": "http://arxiv.org/abs/2308.06463",
    "context": "Title: GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher. (arXiv:2308.06463v1 [cs.CL])\nAbstract: Safety lies at the core of the development of Large Language Models (LLMs). There is ample work on aligning LLMs with human ethics and preferences, including data filtering in pretraining, supervised fine-tuning, reinforcement learning from human feedback, and red teaming, etc. In this study, we discover that chat in cipher can bypass the safety alignment techniques of LLMs, which are mainly conducted in natural languages. We propose a novel framework CipherChat to systematically examine the generalizability of safety alignment to non-natural languages -- ciphers. CipherChat enables humans to chat with LLMs through cipher prompts topped with system role descriptions and few-shot enciphered demonstrations. We use CipherChat to assess state-of-the-art LLMs, including ChatGPT and GPT-4 for different representative human ciphers across 11 safety domains in both English and Chinese. Experimental results show that certain ciphers succeed almost 100% of the time to bypass the safety alignment",
    "path": "papers/23/08/2308.06463.json",
    "total_tokens": 1034,
    "translated_title": "GPT-4太聪明以至于不安全：通过密码与LLMs进行隐蔽聊天",
    "translated_abstract": "安全性是大型语言模型（LLMs）开发的核心。关于将LLMs与人类伦理和偏好进行对齐的工作已经很多，包括在预训练中进行数据筛选、通过监督微调、通过人类反馈进行强化学习以及红队测试等等。在这项研究中，我们发现使用密码进行聊天可以绕过LLMs的安全对齐技术，这些技术主要是在自然语言中进行的。我们提出了一个新颖的框架CipherChat，用于系统地检查安全对齐在非自然语言（密码）中的普适性。CipherChat使人们能够通过加密提示和少量加密演示与LLMs进行聊天。我们使用CipherChat在英语和中文中评估最先进的LLMs，包括ChatGPT和GPT-4在11个安全领域中的不同代表性人类密码。实验结果表明，某些密码成功地绕过了安全对齐技术，几乎100%的时间都能够成功。",
    "tldr": "这项研究发现，通过使用密码进行聊天可以绕过大型语言模型（LLMs）的安全对齐技术。研究人员提出了一种名为CipherChat的框架，用于系统地检查安全对齐在非自然语言（密码）中的普适性，并通过实验评估了ChatGPT和GPT-4等最先进的LLMs对不同代表性人类密码在11个安全领域中的影响。",
    "en_tdlr": "This study discovers that the safety alignment techniques of Large Language Models (LLMs) can be bypassed through chat in cipher. The researchers propose a framework called CipherChat to examine the generalizability of safety alignment to non-natural languages. Experimental results evaluate the impact of state-of-the-art LLMs, including ChatGPT and GPT-4, on different representative human ciphers in 11 safety domains."
}