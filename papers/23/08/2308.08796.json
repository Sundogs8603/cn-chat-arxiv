{
    "title": "Chinese Spelling Correction as Rephrasing Language Model. (arXiv:2308.08796v1 [cs.CL])",
    "abstract": "This paper studies Chinese Spelling Correction (CSC), which aims to detect and correct potential spelling errors in a given sentence. Current state-of-the-art methods regard CSC as a sequence tagging task and fine-tune BERT-based models on sentence pairs. However, we note a critical flaw in the process of tagging one character to another, that the correction is excessively conditioned on the error. This is opposite from human mindset, where individuals rephrase the complete sentence based on its semantics, rather than solely on the error patterns memorized before. Such a counter-intuitive learning process results in the bottleneck of generalizability and transferability of machine spelling correction. To address this, we propose $Rephrasing Language Modeling$ (ReLM), where the model is trained to rephrase the entire sentence by infilling additional slots, instead of character-to-character tagging. This novel training paradigm achieves the new state-of-the-art results across fine-tuned ",
    "link": "http://arxiv.org/abs/2308.08796",
    "context": "Title: Chinese Spelling Correction as Rephrasing Language Model. (arXiv:2308.08796v1 [cs.CL])\nAbstract: This paper studies Chinese Spelling Correction (CSC), which aims to detect and correct potential spelling errors in a given sentence. Current state-of-the-art methods regard CSC as a sequence tagging task and fine-tune BERT-based models on sentence pairs. However, we note a critical flaw in the process of tagging one character to another, that the correction is excessively conditioned on the error. This is opposite from human mindset, where individuals rephrase the complete sentence based on its semantics, rather than solely on the error patterns memorized before. Such a counter-intuitive learning process results in the bottleneck of generalizability and transferability of machine spelling correction. To address this, we propose $Rephrasing Language Modeling$ (ReLM), where the model is trained to rephrase the entire sentence by infilling additional slots, instead of character-to-character tagging. This novel training paradigm achieves the new state-of-the-art results across fine-tuned ",
    "path": "papers/23/08/2308.08796.json",
    "total_tokens": 878,
    "translated_title": "《中文拼写纠错作为改写语言模型》",
    "translated_abstract": "本文研究了中文拼写纠错（CSC），旨在检测和纠正给定句子中的潜在拼写错误。目前最先进的方法将CSC视为序列标注任务，并在句子对上微调基于BERT的模型。然而，我们注意到在将一个字符标记为另一个字符的过程中存在一个关键缺陷，即纠正过程过于依赖错误。这与人类思维相反，人们根据句子的语义重新表达整个句子，而不仅仅是基于之前记忆的错误模式。这种违反直觉的学习过程导致机器拼写纠错的泛化能力和可迁移性受到限制。为了解决这个问题，我们提出了“改写语言建模”（ReLM），其中模型通过填充额外的位置来重新表达整个句子，而不是进行字符级别的标注。这种新颖的训练范式在微调后取得了最新的最优结果。",
    "tldr": "本文提出了一种新颖的中文拼写纠错方法，通过改写语言建模来重新表达整个句子，而不是仅仅依赖错误模式进行字符级别标注，取得了最新的最优结果。",
    "en_tdlr": "This paper proposes a novel approach for Chinese spelling correction by utilizing rephrasing language modeling to rephrase the entire sentence instead of relying solely on error patterns for character-level tagging, achieving state-of-the-art results."
}