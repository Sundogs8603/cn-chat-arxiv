{
    "title": "RaLLe: A Framework for Developing and Evaluating Retrieval-Augmented Large Language Models. (arXiv:2308.10633v2 [cs.CL] UPDATED)",
    "abstract": "Retrieval-augmented large language models (R-LLMs) combine pre-trained large language models (LLMs) with information retrieval systems to improve the accuracy of factual question-answering. However, current libraries for building R-LLMs provide high-level abstractions without sufficient transparency for evaluating and optimizing prompts within specific inference processes such as retrieval and generation. To address this gap, we present RaLLe, an open-source framework designed to facilitate the development, evaluation, and optimization of R-LLMs for knowledge-intensive tasks. With RaLLe, developers can easily develop and evaluate R-LLMs, improving hand-crafted prompts, assessing individual inference processes, and objectively measuring overall system performance quantitatively. By leveraging these features, developers can enhance the performance and accuracy of their R-LLMs in knowledge-intensive generation tasks. We open-source our code at https://github.com/yhoshi3/RaLLe.",
    "link": "http://arxiv.org/abs/2308.10633",
    "context": "Title: RaLLe: A Framework for Developing and Evaluating Retrieval-Augmented Large Language Models. (arXiv:2308.10633v2 [cs.CL] UPDATED)\nAbstract: Retrieval-augmented large language models (R-LLMs) combine pre-trained large language models (LLMs) with information retrieval systems to improve the accuracy of factual question-answering. However, current libraries for building R-LLMs provide high-level abstractions without sufficient transparency for evaluating and optimizing prompts within specific inference processes such as retrieval and generation. To address this gap, we present RaLLe, an open-source framework designed to facilitate the development, evaluation, and optimization of R-LLMs for knowledge-intensive tasks. With RaLLe, developers can easily develop and evaluate R-LLMs, improving hand-crafted prompts, assessing individual inference processes, and objectively measuring overall system performance quantitatively. By leveraging these features, developers can enhance the performance and accuracy of their R-LLMs in knowledge-intensive generation tasks. We open-source our code at https://github.com/yhoshi3/RaLLe.",
    "path": "papers/23/08/2308.10633.json",
    "total_tokens": 853,
    "translated_title": "RaLLe：用于开发和评估检索增强型大型语言模型的框架",
    "translated_abstract": "检索增强型大型语言模型（R-LLMs）将预训练的大型语言模型（LLMs）与信息检索系统相结合，以提高事实问答的准确性。然而，当前用于构建R-LLMs的库提供了高级抽象，但在评估和优化特定推理过程（如检索和生成）中的提示时缺乏足够的透明度。为了弥补这一差距，我们提出了RaLLe，一个开源框架，旨在促进R-LLMs在知识密集型任务中的开发、评估和优化。使用RaLLe，开发人员可以轻松开发和评估R-LLMs，改进手工提示，评估个别推理过程，并定量地客观衡量整体系统性能。通过利用这些功能，开发人员可以提高R-LLMs在知识密集型生成任务中的性能和准确性。",
    "tldr": "RaLLe是一个开源框架，用于开发和评估检索增强型大型语言模型（R-LLMs），以提高知识密集型生成任务的性能和准确性。"
}