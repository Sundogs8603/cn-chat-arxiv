{
    "title": "Robust Long-Tailed Learning via Label-Aware Bounded CVaR. (arXiv:2308.15405v1 [cs.LG])",
    "abstract": "Data in the real-world classification problems are always imbalanced or long-tailed, wherein the majority classes have the most of the samples that dominate the model training. In such setting, the naive model tends to have poor performance on the minority classes. Previously, a variety of loss modifications have been proposed to address the long-tailed leaning problem, while these methods either treat the samples in the same class indiscriminatingly or lack a theoretical guarantee. In this paper, we propose two novel approaches based on CVaR (Conditional Value at Risk) to improve the performance of long-tailed learning with a solid theoretical ground. Specifically, we firstly introduce a Label-Aware Bounded CVaR (LAB-CVaR) loss to overcome the pessimistic result of the original CVaR, and further design the optimal weight bounds for LAB-CVaR theoretically. Based on LAB-CVaR, we additionally propose a LAB-CVaR with logit adjustment (LAB-CVaR-logit) loss to stabilize the optimization pro",
    "link": "http://arxiv.org/abs/2308.15405",
    "context": "Title: Robust Long-Tailed Learning via Label-Aware Bounded CVaR. (arXiv:2308.15405v1 [cs.LG])\nAbstract: Data in the real-world classification problems are always imbalanced or long-tailed, wherein the majority classes have the most of the samples that dominate the model training. In such setting, the naive model tends to have poor performance on the minority classes. Previously, a variety of loss modifications have been proposed to address the long-tailed leaning problem, while these methods either treat the samples in the same class indiscriminatingly or lack a theoretical guarantee. In this paper, we propose two novel approaches based on CVaR (Conditional Value at Risk) to improve the performance of long-tailed learning with a solid theoretical ground. Specifically, we firstly introduce a Label-Aware Bounded CVaR (LAB-CVaR) loss to overcome the pessimistic result of the original CVaR, and further design the optimal weight bounds for LAB-CVaR theoretically. Based on LAB-CVaR, we additionally propose a LAB-CVaR with logit adjustment (LAB-CVaR-logit) loss to stabilize the optimization pro",
    "path": "papers/23/08/2308.15405.json",
    "total_tokens": 1044,
    "translated_title": "通过标签感知有界CVaR实现鲁棒的长尾学习",
    "translated_abstract": "在真实世界的分类问题中，数据往往是不平衡或长尾分布的，其中大多数类别拥有大部分样本，并主导模型训练。在这种情况下，普通模型往往在少数类上表现较差。之前，已经提出了各种损失函数修正方法来解决长尾学习问题，然而这些方法要么对同一类别的样本漠不关心，要么缺乏理论保证。本文提出了两种基于CVaR（条件价值-at-Risk）的新方法来提高长尾学习的性能并具备坚实的理论基础。具体而言，我们首先引入了一种标签感知有界CVaR（LAB-CVaR）损失函数来克服原始CVaR悲观的结果，并在理论上设计了LAB-CVaR的最优权重上下界。基于LAB-CVaR，我们进一步提出了一种带有logit调整的LAB-CVaR（LAB-CVaR-logit）损失函数，以稳定优化过程。",
    "tldr": "本文提出了两种基于CVaR的方法来改进长尾学习的性能，并具备坚实的理论基础。第一种方法是引入了一种标签感知有界CVaR（LAB-CVaR）损失函数，解决了原始CVaR的悲观结果，通过设计最优权重上下界进行改进；第二种方法是提出了一种带有logit调整的LAB-CVaR（LAB-CVaR-logit）损失函数，以稳定优化过程。",
    "en_tdlr": "This paper proposes two novel approaches based on CVaR to improve the performance of long-tailed learning with a solid theoretical ground. The first approach introduces a Label-Aware Bounded CVaR (LAB-CVaR) loss, overcoming the pessimistic result of the original CVaR, and designs optimal weight bounds. The second approach is a LAB-CVaR with logit adjustment (LAB-CVaR-logit) loss, which aims to stabilize the optimization process."
}