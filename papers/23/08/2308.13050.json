{
    "title": "Multi-BERT for Embeddings for Recommendation System. (arXiv:2308.13050v1 [cs.IR])",
    "abstract": "In this paper, we propose a novel approach for generating document embeddings using a combination of Sentence-BERT (SBERT) and RoBERTa, two state-of-the-art natural language processing models. Our approach treats sentences as tokens and generates embeddings for them, allowing the model to capture both intra-sentence and inter-sentence relations within a document. We evaluate our model on a book recommendation task and demonstrate its effectiveness in generating more semantically rich and accurate document embeddings. To assess the performance of our approach, we conducted experiments on a book recommendation task using the Goodreads dataset. We compared the document embeddings generated using our MULTI-BERT model to those generated using SBERT alone. We used precision as our evaluation metric to compare the quality of the generated embeddings. Our results showed that our model consistently outperformed SBERT in terms of the quality of the generated embeddings. Furthermore, we found tha",
    "link": "http://arxiv.org/abs/2308.13050",
    "context": "Title: Multi-BERT for Embeddings for Recommendation System. (arXiv:2308.13050v1 [cs.IR])\nAbstract: In this paper, we propose a novel approach for generating document embeddings using a combination of Sentence-BERT (SBERT) and RoBERTa, two state-of-the-art natural language processing models. Our approach treats sentences as tokens and generates embeddings for them, allowing the model to capture both intra-sentence and inter-sentence relations within a document. We evaluate our model on a book recommendation task and demonstrate its effectiveness in generating more semantically rich and accurate document embeddings. To assess the performance of our approach, we conducted experiments on a book recommendation task using the Goodreads dataset. We compared the document embeddings generated using our MULTI-BERT model to those generated using SBERT alone. We used precision as our evaluation metric to compare the quality of the generated embeddings. Our results showed that our model consistently outperformed SBERT in terms of the quality of the generated embeddings. Furthermore, we found tha",
    "path": "papers/23/08/2308.13050.json",
    "total_tokens": 822,
    "translated_title": "多重BERT用于推荐系统中的嵌入",
    "translated_abstract": "本文提出了一种新颖的方法，使用句子BERT（SBERT）和RoBERTa两种最先进的自然语言处理模型来生成文档嵌入。我们的方法将句子视为标记，并为它们生成嵌入，使模型能够捕捉文档内的句子内部和句子间关系。我们在图书推荐任务上评估了我们的模型，并展示了它在生成语义丰富和准确的文档嵌入方面的有效性。为了评估我们的方法的性能，我们在Goodreads数据集上进行了图书推荐任务的实验。我们将使用我们的MULTI-BERT模型生成的文档嵌入与仅使用SBERT生成的嵌入进行比较。我们使用精确度作为评估指标来比较生成嵌入的质量。结果表明，我们的模型在生成嵌入的质量方面始终优于SBERT。此外，我们发现...",
    "tldr": "本文提出了一种使用多种最先进的自然语言处理模型来生成文档嵌入的方法，并在图书推荐任务中取得了比单一模型更好的性能。",
    "en_tdlr": "This paper proposes a method of generating document embeddings using multiple state-of-the-art natural language processing models, and achieves better performance in book recommendation tasks compared to a single model."
}