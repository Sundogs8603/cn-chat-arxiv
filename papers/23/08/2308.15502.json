{
    "title": "On the Steganographic Capacity of Selected Learning Models. (arXiv:2308.15502v1 [cs.LG])",
    "abstract": "Machine learning and deep learning models are potential vectors for various attack scenarios. For example, previous research has shown that malware can be hidden in deep learning models. Hiding information in a learning model can be viewed as a form of steganography. In this research, we consider the general question of the steganographic capacity of learning models. Specifically, for a wide range of models, we determine the number of low-order bits of the trained parameters that can be overwritten, without adversely affecting model performance. For each model considered, we graph the accuracy as a function of the number of low-order bits that have been overwritten, and for selected models, we also analyze the steganographic capacity of individual layers. The models that we test include the classic machine learning techniques of Linear Regression (LR) and Support Vector Machine (SVM); the popular general deep learning models of Multilayer Perceptron (MLP) and Convolutional Neural Netwo",
    "link": "http://arxiv.org/abs/2308.15502",
    "context": "Title: On the Steganographic Capacity of Selected Learning Models. (arXiv:2308.15502v1 [cs.LG])\nAbstract: Machine learning and deep learning models are potential vectors for various attack scenarios. For example, previous research has shown that malware can be hidden in deep learning models. Hiding information in a learning model can be viewed as a form of steganography. In this research, we consider the general question of the steganographic capacity of learning models. Specifically, for a wide range of models, we determine the number of low-order bits of the trained parameters that can be overwritten, without adversely affecting model performance. For each model considered, we graph the accuracy as a function of the number of low-order bits that have been overwritten, and for selected models, we also analyze the steganographic capacity of individual layers. The models that we test include the classic machine learning techniques of Linear Regression (LR) and Support Vector Machine (SVM); the popular general deep learning models of Multilayer Perceptron (MLP) and Convolutional Neural Netwo",
    "path": "papers/23/08/2308.15502.json",
    "total_tokens": 942,
    "translated_title": "关于选定学习模型的隐写容量",
    "translated_abstract": "机器学习和深度学习模型是各种攻击场景的潜在载体。例如，先前的研究表明，恶意软件可以隐藏在深度学习模型中。将信息隐藏在学习模型中可以视为一种隐写术形式。在这项研究中，我们考虑了学习模型的隐写容量的一般问题。具体来说，对于各种模型，我们确定了可以覆盖而不会对模型性能产生不利影响的已训练参数的低阶位数。对于每个考虑的模型，我们以已覆盖的低阶位数作为自变量绘制准确性图，并针对选定的模型分析了每个层的隐写容量。我们测试的模型包括经典机器学习技术的线性回归（LR）和支持向量机（SVM）；流行的通用深度学习模型的多层感知机（MLP）和卷积神经网络（CNN）。",
    "tldr": "本研究考虑了学习模型的隐写容量问题，确定了在不影响模型性能的前提下可以覆盖的已训练参数的低阶位数，并分析了每个模型的准确性随低阶位数变化的关系，以及选定模型各层的隐写容量。",
    "en_tdlr": "This research investigates the steganographic capacity of learning models, determining the number of low-order bits of trained parameters that can be overwritten without adverse effects on model performance. Graphs are created to show the accuracy as a function of overwritten low-order bits for different models, and the steganographic capacity of individual layers is also analyzed for selected models."
}