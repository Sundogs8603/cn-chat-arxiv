{
    "title": "Addressing Racial Bias in Facial Emotion Recognition. (arXiv:2308.04674v1 [cs.CV])",
    "abstract": "Fairness in deep learning models trained with high-dimensional inputs and subjective labels remains a complex and understudied area. Facial emotion recognition, a domain where datasets are often racially imbalanced, can lead to models that yield disparate outcomes across racial groups. This study focuses on analyzing racial bias by sub-sampling training sets with varied racial distributions and assessing test performance across these simulations. Our findings indicate that smaller datasets with posed faces improve on both fairness and performance metrics as the simulations approach racial balance. Notably, the F1-score increases by $27.2\\%$ points, and demographic parity increases by $15.7\\%$ points on average across the simulations. However, in larger datasets with greater facial variation, fairness metrics generally remain constant, suggesting that racial balance by itself is insufficient to achieve parity in test performance across different racial groups.",
    "link": "http://arxiv.org/abs/2308.04674",
    "context": "Title: Addressing Racial Bias in Facial Emotion Recognition. (arXiv:2308.04674v1 [cs.CV])\nAbstract: Fairness in deep learning models trained with high-dimensional inputs and subjective labels remains a complex and understudied area. Facial emotion recognition, a domain where datasets are often racially imbalanced, can lead to models that yield disparate outcomes across racial groups. This study focuses on analyzing racial bias by sub-sampling training sets with varied racial distributions and assessing test performance across these simulations. Our findings indicate that smaller datasets with posed faces improve on both fairness and performance metrics as the simulations approach racial balance. Notably, the F1-score increases by $27.2\\%$ points, and demographic parity increases by $15.7\\%$ points on average across the simulations. However, in larger datasets with greater facial variation, fairness metrics generally remain constant, suggesting that racial balance by itself is insufficient to achieve parity in test performance across different racial groups.",
    "path": "papers/23/08/2308.04674.json",
    "total_tokens": 993,
    "translated_title": "解决面部情绪识别中的种族偏见问题",
    "translated_abstract": "在深度学习模型中，训练集具有高维度输入和主观标签的公平性仍然是一个复杂且研究不足的领域。面部情绪识别是一个数据集常常存在种族不平衡的领域，可能导致模型在不同种族群体之间产生不同的结果。本研究重点分析通过对具有不同种族分布的训练集进行子采样，并评估这些模拟中的测试性能来解决种族偏见问题。我们的研究结果表明，随着模拟接近种族平衡，采用较小的具有姿势面部的数据集可以在公平性和性能指标上取得改善。值得注意的是，F1得分平均提高了27.2个百分点，并且人口统计学平等性平均提高了15.7个百分点。然而，在具有更大面部变异的较大数据集中，公平性指标通常保持不变，这表明仅仅种族平衡是无法实现在不同种族群体之间测试性能的公平性。",
    "tldr": "本研究通过分析不同种族分布的子采样训练集，并评估模拟中的测试性能，解决了面部情绪识别中的种族偏见问题。实验结果表明，具有姿势面部的较小数据集可以提高公平性和性能指标，但在具有更大面部变异的较大数据集中，种族平衡仍然无法实现不同种族群体之间的测试性能的公平性。",
    "en_tdlr": "This study addresses racial bias in facial emotion recognition by analyzing sub-sampled training sets with varied racial distributions and evaluating test performance. The results show that smaller datasets with posed faces can improve fairness and performance metrics, but achieving racial balance alone is insufficient to achieve parity in test performance across different racial groups in larger datasets with greater facial variation."
}