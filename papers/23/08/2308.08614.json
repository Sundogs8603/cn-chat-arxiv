{
    "title": "Boosting Logical Reasoning in Large Language Models through a New Framework: The Graph of Thought. (arXiv:2308.08614v1 [cs.LG])",
    "abstract": "Recent advancements in large-scale models, such as GPT-4, have showcased remarkable capabilities in addressing standard queries. However, when facing complex problems that require multi-step logical reasoning, their accuracy dramatically decreases. Current research has explored the realm of \\textit{prompting engineering} to bolster the inferential capacities of these models. Our paper unveils a pioneering prompting technique, dubbed \\textit{Graph of Thoughts (GoT)}. Through testing on a trio of escalating challenges: the 24-point game, resolution of high-degree polynomial equations, and derivation of formulas for recursive sequences, our method outperformed GPT-4, achieving accuracy improvements of $89.7\\%$, $86\\%$, and $56\\%$ for each respective task. Moreover, when juxtaposed with the state-of-the-art (SOTA) prompting method, \\textit{Tree of Thought (ToT)}, our approach registered an average accuracy boost of $23\\%$, $24\\%$, and $15\\%$.",
    "link": "http://arxiv.org/abs/2308.08614",
    "context": "Title: Boosting Logical Reasoning in Large Language Models through a New Framework: The Graph of Thought. (arXiv:2308.08614v1 [cs.LG])\nAbstract: Recent advancements in large-scale models, such as GPT-4, have showcased remarkable capabilities in addressing standard queries. However, when facing complex problems that require multi-step logical reasoning, their accuracy dramatically decreases. Current research has explored the realm of \\textit{prompting engineering} to bolster the inferential capacities of these models. Our paper unveils a pioneering prompting technique, dubbed \\textit{Graph of Thoughts (GoT)}. Through testing on a trio of escalating challenges: the 24-point game, resolution of high-degree polynomial equations, and derivation of formulas for recursive sequences, our method outperformed GPT-4, achieving accuracy improvements of $89.7\\%$, $86\\%$, and $56\\%$ for each respective task. Moreover, when juxtaposed with the state-of-the-art (SOTA) prompting method, \\textit{Tree of Thought (ToT)}, our approach registered an average accuracy boost of $23\\%$, $24\\%$, and $15\\%$.",
    "path": "papers/23/08/2308.08614.json",
    "total_tokens": 944,
    "translated_title": "通过新的框架——思维图，提升大型语言模型的逻辑推理能力",
    "translated_abstract": "近期大规模模型（如GPT-4）的进展展示了在解决标准查询方面的卓越能力。然而，面对需要多步逻辑推理的复杂问题时，它们的准确性急剧下降。当前的研究已经探索了提示工程领域，以增强这些模型的推理能力。本文提出了一种创新的提示技术，称为“思维图（GoT）”。通过在三个不断升级的挑战上进行测试：24点游戏，高阶多项式方程的解析，以及递归数列的公式推导，我们的方法优于GPT-4，在每个任务中实现了$89.7\\%$、$86\\%$和$56\\%$的准确性改进。此外，与最先进的提示方法“思维树（ToT）”相比，我们的方法平均准确性提升了$23\\%$、$24\\%$和$15\\%$。",
    "tldr": "本文提出了一种新的提示技术——思维图（GoT），通过在三个不断升级的挑战中的测试，我们的方法在多步逻辑推理问题上表现优于GPT-4，并且相比最先进的提示方法思维树（ToT），我们的方法有更高的准确性提升。",
    "en_tdlr": "This paper introduces a new prompting technique, called Graph of Thoughts (GoT), which outperforms GPT-4 in multi-step logical reasoning tasks and achieves higher accuracy improvements compared to the state-of-the-art prompting method, Tree of Thought (ToT)."
}