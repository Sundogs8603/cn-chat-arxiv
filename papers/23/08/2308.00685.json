{
    "title": "Learning from Hypervectors: A Survey on Hypervector Encoding. (arXiv:2308.00685v1 [cs.LG])",
    "abstract": "Hyperdimensional computing (HDC) is an emerging computing paradigm that imitates the brain's structure to offer a powerful and efficient processing and learning model. In HDC, the data are encoded with long vectors, called hypervectors, typically with a length of 1K to 10K. The literature provides several encoding techniques to generate orthogonal or correlated hypervectors, depending on the intended application. The existing surveys in the literature often focus on the overall aspects of HDC systems, including system inputs, primary computations, and final outputs. However, this study takes a more specific approach. It zeroes in on the HDC system input and the generation of hypervectors, directly influencing the hypervector encoding process. This survey brings together various methods for hypervector generation from different studies and explores the limitations, challenges, and potential benefits they entail. Through a comprehensive exploration of this survey, readers will acquire a ",
    "link": "http://arxiv.org/abs/2308.00685",
    "context": "Title: Learning from Hypervectors: A Survey on Hypervector Encoding. (arXiv:2308.00685v1 [cs.LG])\nAbstract: Hyperdimensional computing (HDC) is an emerging computing paradigm that imitates the brain's structure to offer a powerful and efficient processing and learning model. In HDC, the data are encoded with long vectors, called hypervectors, typically with a length of 1K to 10K. The literature provides several encoding techniques to generate orthogonal or correlated hypervectors, depending on the intended application. The existing surveys in the literature often focus on the overall aspects of HDC systems, including system inputs, primary computations, and final outputs. However, this study takes a more specific approach. It zeroes in on the HDC system input and the generation of hypervectors, directly influencing the hypervector encoding process. This survey brings together various methods for hypervector generation from different studies and explores the limitations, challenges, and potential benefits they entail. Through a comprehensive exploration of this survey, readers will acquire a ",
    "path": "papers/23/08/2308.00685.json",
    "total_tokens": 862,
    "translated_title": "从超维向量中学习：关于超维编码的调查",
    "translated_abstract": "超维计算是一种模拟大脑结构，提供强大而高效的处理和学习模型的新兴计算范式。在超维计算中，数据被编码为长向量，称为超维向量，通常长度为1K到10K。文献提供了几种编码技术来生成正交或相关的超维向量，这取决于预期的应用。现有文献调查通常集中在超维计算系统的整体方面，包括系统输入、主要计算和最终输出。然而，本研究采取了更具体的方法。它聚焦于超维计算系统的输入和超维向量的生成，直接影响超维编码过程。本调查汇集了不同研究中关于超维向量生成的各种方法，并探讨了它们的限制、挑战和潜在的好处。通过对本调查的全面探索，读者将获得一些关于超维编码的重要见解。",
    "tldr": "本调查研究聚焦于超维计算系统的输入和超维向量的生成，探讨了各种方法的限制、挑战和潜在好处。",
    "en_tdlr": "This survey focuses on the input of hyperdimensional computing systems and the generation of hypervectors, investigating the limitations, challenges, and potential benefits of various methods."
}