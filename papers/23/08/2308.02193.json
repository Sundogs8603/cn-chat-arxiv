{
    "title": "Explaining Relation Classification Models with Semantic Extents. (arXiv:2308.02193v1 [cs.CL])",
    "abstract": "In recent years, the development of large pretrained language models, such as BERT and GPT, significantly improved information extraction systems on various tasks, including relation classification. State-of-the-art systems are highly accurate on scientific benchmarks. A lack of explainability is currently a complicating factor in many real-world applications. Comprehensible systems are necessary to prevent biased, counterintuitive, or harmful decisions.  We introduce semantic extents, a concept to analyze decision patterns for the relation classification task. Semantic extents are the most influential parts of texts concerning classification decisions. Our definition allows similar procedures to determine semantic extents for humans and models. We provide an annotation tool and a software framework to determine semantic extents for humans and models conveniently and reproducibly. Comparing both reveals that models tend to learn shortcut patterns from data. These patterns are hard to d",
    "link": "http://arxiv.org/abs/2308.02193",
    "context": "Title: Explaining Relation Classification Models with Semantic Extents. (arXiv:2308.02193v1 [cs.CL])\nAbstract: In recent years, the development of large pretrained language models, such as BERT and GPT, significantly improved information extraction systems on various tasks, including relation classification. State-of-the-art systems are highly accurate on scientific benchmarks. A lack of explainability is currently a complicating factor in many real-world applications. Comprehensible systems are necessary to prevent biased, counterintuitive, or harmful decisions.  We introduce semantic extents, a concept to analyze decision patterns for the relation classification task. Semantic extents are the most influential parts of texts concerning classification decisions. Our definition allows similar procedures to determine semantic extents for humans and models. We provide an annotation tool and a software framework to determine semantic extents for humans and models conveniently and reproducibly. Comparing both reveals that models tend to learn shortcut patterns from data. These patterns are hard to d",
    "path": "papers/23/08/2308.02193.json",
    "total_tokens": 926,
    "translated_title": "用语义范围解释关系分类模型",
    "translated_abstract": "近年来，大规模预训练语言模型（如BERT和GPT）的发展显著改进了各种任务中的信息抽取系统，包括关系分类。最先进的系统在科学基准上具有很高的准确性。目前，缺乏可解释性是许多真实世界应用中的一个复杂因素。可理解的系统对于防止有偏见、违反直觉或有害的决策是必要的。我们引入了一种分析关系分类任务决策模式的概念，即语义范围。语义范围是关于分类决策的文本中最有影响力的部分。我们的定义允许类似的过程来确定人类和模型的语义范围。我们提供了一个注释工具和一个软件框架，以便方便、可重复地确定人类和模型的语义范围。比较两者发现，模型往往从数据中学习到了快捷模式。这些模式很难被人类解释或理解。",
    "tldr": "本研究提出了一种解释关系分类模型的方法，即使用语义范围分析模型的决策模式。语义范围是关于分类决策的文本中最有影响力的部分。通过将人类和模型的语义范围进行比较，发现模型往往从数据中学习到了快捷模式。"
}