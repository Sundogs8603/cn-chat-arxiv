{
    "title": "Generative Perturbation Analysis for Probabilistic Black-Box Anomaly Attribution. (arXiv:2308.04708v1 [cs.LG])",
    "abstract": "We address the task of probabilistic anomaly attribution in the black-box regression setting, where the goal is to compute the probability distribution of the attribution score of each input variable, given an observed anomaly. The training dataset is assumed to be unavailable. This task differs from the standard XAI (explainable AI) scenario, since we wish to explain the anomalous deviation from a black-box prediction rather than the black-box model itself.  We begin by showing that mainstream model-agnostic explanation methods, such as the Shapley values, are not suitable for this task because of their ``deviation-agnostic property.'' We then propose a novel framework for probabilistic anomaly attribution that allows us to not only compute attribution scores as the predictive mean but also quantify the uncertainty of those scores. This is done by considering a generative process for perturbations that counter-factually bring the observed anomalous observation back to normalcy. We int",
    "link": "http://arxiv.org/abs/2308.04708",
    "context": "Title: Generative Perturbation Analysis for Probabilistic Black-Box Anomaly Attribution. (arXiv:2308.04708v1 [cs.LG])\nAbstract: We address the task of probabilistic anomaly attribution in the black-box regression setting, where the goal is to compute the probability distribution of the attribution score of each input variable, given an observed anomaly. The training dataset is assumed to be unavailable. This task differs from the standard XAI (explainable AI) scenario, since we wish to explain the anomalous deviation from a black-box prediction rather than the black-box model itself.  We begin by showing that mainstream model-agnostic explanation methods, such as the Shapley values, are not suitable for this task because of their ``deviation-agnostic property.'' We then propose a novel framework for probabilistic anomaly attribution that allows us to not only compute attribution scores as the predictive mean but also quantify the uncertainty of those scores. This is done by considering a generative process for perturbations that counter-factually bring the observed anomalous observation back to normalcy. We int",
    "path": "papers/23/08/2308.04708.json",
    "total_tokens": 853,
    "translated_title": "生成扰动分析用于概率黑盒异常归因",
    "translated_abstract": "我们针对黑盒回归模型设置中的概率异常归因任务，旨在计算每个输入变量的归因得分的概率分布，给定一个观察到的异常。假设训练数据集不可用。与标准的可解释人工智能（XAI）情景不同，这个任务希望解释与黑盒预测的异常偏差，而不是解释黑盒模型本身。我们首先证明了主流的模型无关解释方法，如Shapley值，对于这个任务不适用，因为它们具有“偏差无关属性”。然后，我们提出了一种新颖的概率异常归因框架，不仅可以计算归因得分作为预测均值，还可以量化这些得分的不确定性。这是通过考虑一个生成过程来实现的，该过程对扰动进行反事实地将观测到的异常观察恢复到正常状态。",
    "tldr": "本文提出了一种新颖的概率异常归因框架，通过生成扰动来计算每个输入变量的归因得分的概率分布，并量化这些得分的不确定性。",
    "en_tdlr": "This paper proposes a novel framework for probabilistic anomaly attribution, which calculates the probability distribution of attribution scores for each input variable by generating perturbations and quantifying the uncertainty of those scores."
}