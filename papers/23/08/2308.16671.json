{
    "title": "Communication-Efficient Decentralized Federated Learning via One-Bit Compressive Sensing. (arXiv:2308.16671v1 [cs.LG])",
    "abstract": "Decentralized federated learning (DFL) has gained popularity due to its practicality across various applications. Compared to the centralized version, training a shared model among a large number of nodes in DFL is more challenging, as there is no central server to coordinate the training process. Especially when distributed nodes suffer from limitations in communication or computational resources, DFL will experience extremely inefficient and unstable training. Motivated by these challenges, in this paper, we develop a novel algorithm based on the framework of the inexact alternating direction method (iADM). On one hand, our goal is to train a shared model with a sparsity constraint. This constraint enables us to leverage one-bit compressive sensing (1BCS), allowing transmission of one-bit information among neighbour nodes. On the other hand, communication between neighbour nodes occurs only at certain steps, reducing the number of communication rounds. Therefore, the algorithm exhibi",
    "link": "http://arxiv.org/abs/2308.16671",
    "context": "Title: Communication-Efficient Decentralized Federated Learning via One-Bit Compressive Sensing. (arXiv:2308.16671v1 [cs.LG])\nAbstract: Decentralized federated learning (DFL) has gained popularity due to its practicality across various applications. Compared to the centralized version, training a shared model among a large number of nodes in DFL is more challenging, as there is no central server to coordinate the training process. Especially when distributed nodes suffer from limitations in communication or computational resources, DFL will experience extremely inefficient and unstable training. Motivated by these challenges, in this paper, we develop a novel algorithm based on the framework of the inexact alternating direction method (iADM). On one hand, our goal is to train a shared model with a sparsity constraint. This constraint enables us to leverage one-bit compressive sensing (1BCS), allowing transmission of one-bit information among neighbour nodes. On the other hand, communication between neighbour nodes occurs only at certain steps, reducing the number of communication rounds. Therefore, the algorithm exhibi",
    "path": "papers/23/08/2308.16671.json",
    "total_tokens": 905,
    "translated_title": "基于一位压缩感知的通信高效的分散式联邦学习",
    "translated_abstract": "分散式联邦学习（DFL）因其在各种应用中的实用性而变得流行。与集中式版本相比，在DFL中在大量节点之间训练共享模型更具挑战性，因为没有中央服务器来协调训练过程。尤其是当分布式节点在通信或计算资源方面存在限制时，DFL的训练将变得非常低效和不稳定。鉴于这些挑战，本文基于不精确交替方向方法（iADM）框架提出了一种新算法。一方面，我们的目标是训练具有稀疏约束的共享模型。该约束使我们能够利用一位压缩感知（1BCS），允许邻居节点之间传输一位信息。另一方面，邻居节点之间的通信仅在某些步骤中发生，减少了通信回合的数量。因此，该算法展现了高效的特点。",
    "tldr": "本文提出了基于一位压缩感知的通信高效的分散式联邦学习算法，通过在邻居节点之间传输一位信息并减少通信回合的数量，实现了对具有稀疏约束的共享模型的高效训练。",
    "en_tdlr": "This paper proposes a communication-efficient decentralized federated learning algorithm based on one-bit compressive sensing, which achieves efficient training of a shared model with sparsity constraint by transmitting one-bit information among neighbor nodes and reducing the number of communication rounds."
}