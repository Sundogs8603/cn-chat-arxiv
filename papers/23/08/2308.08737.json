{
    "title": "ReProHRL: Towards Multi-Goal Navigation in the Real World using Hierarchical Agents. (arXiv:2308.08737v1 [cs.RO])",
    "abstract": "Robots have been successfully used to perform tasks with high precision. In real-world environments with sparse rewards and multiple goals, learning is still a major challenge and Reinforcement Learning (RL) algorithms fail to learn good policies. Training in simulation environments and then fine-tuning in the real world is a common approach. However, adapting to the real-world setting is a challenge. In this paper, we present a method named Ready for Production Hierarchical RL (ReProHRL) that divides tasks with hierarchical multi-goal navigation guided by reinforcement learning. We also use object detectors as a pre-processing step to learn multi-goal navigation and transfer it to the real world. Empirical results show that the proposed ReProHRL method outperforms the state-of-the-art baseline in simulation and real-world environments in terms of both training time and performance. Although both methods achieve a 100% success rate in a simple environment for single goal-based navigati",
    "link": "http://arxiv.org/abs/2308.08737",
    "context": "Title: ReProHRL: Towards Multi-Goal Navigation in the Real World using Hierarchical Agents. (arXiv:2308.08737v1 [cs.RO])\nAbstract: Robots have been successfully used to perform tasks with high precision. In real-world environments with sparse rewards and multiple goals, learning is still a major challenge and Reinforcement Learning (RL) algorithms fail to learn good policies. Training in simulation environments and then fine-tuning in the real world is a common approach. However, adapting to the real-world setting is a challenge. In this paper, we present a method named Ready for Production Hierarchical RL (ReProHRL) that divides tasks with hierarchical multi-goal navigation guided by reinforcement learning. We also use object detectors as a pre-processing step to learn multi-goal navigation and transfer it to the real world. Empirical results show that the proposed ReProHRL method outperforms the state-of-the-art baseline in simulation and real-world environments in terms of both training time and performance. Although both methods achieve a 100% success rate in a simple environment for single goal-based navigati",
    "path": "papers/23/08/2308.08737.json",
    "total_tokens": 940,
    "translated_title": "ReProHRL: 面向多目标导航的真实世界层次化代理方法",
    "translated_abstract": "机器人已成功用于高精度任务的执行。在稀疏奖励和多目标的真实世界环境中，学习仍然是一个重大挑战，强化学习算法难以学习到好的策略。在仿真环境中进行训练，然后在真实世界进行微调是一种常见的方法。然而，适应真实世界的环境仍然具有挑战性。本文提出了一种名为\"ReProHRL\"的方法，该方法通过强化学习实现了分层多目标导航任务。我们还使用物体检测器作为预处理步骤，学习多目标导航并将其应用于真实世界。实证结果表明，所提出的ReProHRL方法在仿真和真实世界环境中的训练时间和性能方面优于现有基准方法。虽然这两种方法在单目标导航的简单环境中均实现了100%的成功率，但是在多目标导航问题上，ReProHRL方法表现更佳。",
    "tldr": "本文提出了一种名为ReProHRL的层次化代理方法，通过强化学习实现了多目标导航任务，并使用物体检测器进行预处理。实验证明，ReProHRL方法在仿真和真实世界环境中表现优于现有方法。"
}