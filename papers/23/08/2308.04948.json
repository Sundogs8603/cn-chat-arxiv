{
    "title": "Extrapolating Large Language Models to Non-English by Aligning Languages. (arXiv:2308.04948v1 [cs.CL])",
    "abstract": "Due to the unbalanced training data distribution, the language ability of large language models (LLMs) is often biased towards English. In this paper, we propose to empower pre-trained LLMs on non-English languages by building semantic alignment across languages. We perform instruction-tuning on LLaMA with both translation task data and cross-lingual general task data to obtain cross-lingual models (x-LLaMA). Experiment results on cross-lingual benchmark XQUAD and MLQA show that x-LLaMA models outperform the English instruction-tuned counterpart (Alpaca) by 42.50% on average on six non-English languages. Further experiments on Chinese benchmark C-Eval show that x-LLaMA achieves significant improvement on Chinese humanities tasks, outperforming Alpaca by 8.2%. We also discover that incorporating non-English text on the target side of translation data is particularly effective for boosting non-English ability. Besides, we find that semantic alignment within LLM can be further strengthene",
    "link": "http://arxiv.org/abs/2308.04948",
    "context": "Title: Extrapolating Large Language Models to Non-English by Aligning Languages. (arXiv:2308.04948v1 [cs.CL])\nAbstract: Due to the unbalanced training data distribution, the language ability of large language models (LLMs) is often biased towards English. In this paper, we propose to empower pre-trained LLMs on non-English languages by building semantic alignment across languages. We perform instruction-tuning on LLaMA with both translation task data and cross-lingual general task data to obtain cross-lingual models (x-LLaMA). Experiment results on cross-lingual benchmark XQUAD and MLQA show that x-LLaMA models outperform the English instruction-tuned counterpart (Alpaca) by 42.50% on average on six non-English languages. Further experiments on Chinese benchmark C-Eval show that x-LLaMA achieves significant improvement on Chinese humanities tasks, outperforming Alpaca by 8.2%. We also discover that incorporating non-English text on the target side of translation data is particularly effective for boosting non-English ability. Besides, we find that semantic alignment within LLM can be further strengthene",
    "path": "papers/23/08/2308.04948.json",
    "total_tokens": 970,
    "translated_title": "通过语言对齐将大型语言模型推广到非英语中",
    "translated_abstract": "由于训练数据分布不均衡，大型语言模型（LLM）往往在语言能力上偏向英语。本文提出通过构建跨语言的语义对齐，来增强预训练的非英语语言模型的能力。我们使用翻译任务数据和跨语言通用任务数据对LLaMA进行指令调整，得到跨语言模型（x-LLaMA）。在跨语言基准XQUAD和MLQA上的实验结果表明，x-LLaMA模型在六种非英语语言上平均超过英语指令调整的模型（Alpaca）42.50%。在中文基准C-Eval上的进一步实验表明，x-LLaMA在中文人文任务上取得了显著改进，超过Alpaca 8.2%。此外，我们发现在翻译数据的目标端加入非英语文本可以有效提升非英语能力。另外，我们还发现LLM内部的语义对齐可以进一步加强。",
    "tldr": "本文介绍了一种通过语义对齐来增强非英语语言模型的方法，并通过实验证明，该方法在跨语言任务中取得了显著的改进。同时，我们还发现在翻译数据中加入非英语文本可以有效提升模型能力，且LLM内部的语义对齐也可以进一步加强。",
    "en_tdlr": "This paper presents a method to enhance non-English language models by aligning languages semantically. Experimental results demonstrate significant improvements in cross-lingual tasks using this method. Additionally, incorporating non-English text in translation data and strengthening semantic alignment within the language model are found to be effective."
}