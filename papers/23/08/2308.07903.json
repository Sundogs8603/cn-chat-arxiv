{
    "title": "Relightable and Animatable Neural Avatar from Sparse-View Video. (arXiv:2308.07903v1 [cs.CV])",
    "abstract": "This paper tackles the challenge of creating relightable and animatable neural avatars from sparse-view (or even monocular) videos of dynamic humans under unknown illumination. Compared to studio environments, this setting is more practical and accessible but poses an extremely challenging ill-posed problem. Previous neural human reconstruction methods are able to reconstruct animatable avatars from sparse views using deformed Signed Distance Fields (SDF) but cannot recover material parameters for relighting. While differentiable inverse rendering-based methods have succeeded in material recovery of static objects, it is not straightforward to extend them to dynamic humans as it is computationally intensive to compute pixel-surface intersection and light visibility on deformed SDFs for inverse rendering. To solve this challenge, we propose a Hierarchical Distance Query (HDQ) algorithm to approximate the world space distances under arbitrary human poses. Specifically, we estimate coarse",
    "link": "http://arxiv.org/abs/2308.07903",
    "context": "Title: Relightable and Animatable Neural Avatar from Sparse-View Video. (arXiv:2308.07903v1 [cs.CV])\nAbstract: This paper tackles the challenge of creating relightable and animatable neural avatars from sparse-view (or even monocular) videos of dynamic humans under unknown illumination. Compared to studio environments, this setting is more practical and accessible but poses an extremely challenging ill-posed problem. Previous neural human reconstruction methods are able to reconstruct animatable avatars from sparse views using deformed Signed Distance Fields (SDF) but cannot recover material parameters for relighting. While differentiable inverse rendering-based methods have succeeded in material recovery of static objects, it is not straightforward to extend them to dynamic humans as it is computationally intensive to compute pixel-surface intersection and light visibility on deformed SDFs for inverse rendering. To solve this challenge, we propose a Hierarchical Distance Query (HDQ) algorithm to approximate the world space distances under arbitrary human poses. Specifically, we estimate coarse",
    "path": "papers/23/08/2308.07903.json",
    "total_tokens": 979,
    "translated_title": "从稀疏视角视频中生成可重光和可动化的神经化身",
    "translated_abstract": "本文解决了从未知照明条件下的稀疏视角（甚至单目）视频中创建可重光和可动化的神经化身的挑战。与工作室环境相比，这个设置更实际和可行，但是面临一个极具挑战性的逆问题。之前的神经人类重建方法能够使用变形有符号距离场（SDF）从稀疏视角重建可动化的化身，但无法恢复用于重光的材料参数。虽然可微逆渲染方法已成功地恢复了静态对象的材料，但对于动态人类，将其扩展为动态人体是不直观的，因为在变形SDF上计算像素-表面相交和光能见度对于逆渲染来说是计算密集型的。为了解决这个挑战，我们提出了一种分层距离查询（HDQ）算法来近似任意人体姿态下的世界空间距离。具体来说，我们估算了粗略的距离值，然后使用迭代过程来提高距离估算的精度，并使用这些估算出的距离值进行材料恢复和重光。",
    "tldr": "本文提出了一种从稀疏视角视频中创建可重光和可动化的神经化身的方法，通过使用Hierarchical Distance Query（HDQ）算法来近似任意人体姿态下的世界空间距离，并使用这些距离来进行材料恢复和重光。"
}