{
    "title": "Independent Distribution Regularization for Private Graph Embedding. (arXiv:2308.08360v1 [cs.LG])",
    "abstract": "Learning graph embeddings is a crucial task in graph mining tasks. An effective graph embedding model can learn low-dimensional representations from graph-structured data for data publishing benefiting various downstream applications such as node classification, link prediction, etc. However, recent studies have revealed that graph embeddings are susceptible to attribute inference attacks, which allow attackers to infer private node attributes from the learned graph embeddings. To address these concerns, privacy-preserving graph embedding methods have emerged, aiming to simultaneously consider primary learning and privacy protection through adversarial learning. However, most existing methods assume that representation models have access to all sensitive attributes in advance during the training stage, which is not always the case due to diverse privacy preferences. Furthermore, the commonly used adversarial learning technique in privacy-preserving representation learning suffers from ",
    "link": "http://arxiv.org/abs/2308.08360",
    "context": "Title: Independent Distribution Regularization for Private Graph Embedding. (arXiv:2308.08360v1 [cs.LG])\nAbstract: Learning graph embeddings is a crucial task in graph mining tasks. An effective graph embedding model can learn low-dimensional representations from graph-structured data for data publishing benefiting various downstream applications such as node classification, link prediction, etc. However, recent studies have revealed that graph embeddings are susceptible to attribute inference attacks, which allow attackers to infer private node attributes from the learned graph embeddings. To address these concerns, privacy-preserving graph embedding methods have emerged, aiming to simultaneously consider primary learning and privacy protection through adversarial learning. However, most existing methods assume that representation models have access to all sensitive attributes in advance during the training stage, which is not always the case due to diverse privacy preferences. Furthermore, the commonly used adversarial learning technique in privacy-preserving representation learning suffers from ",
    "path": "papers/23/08/2308.08360.json",
    "total_tokens": 877,
    "translated_title": "独立分布正则化用于私有图嵌入",
    "translated_abstract": "学习图嵌入是图挖掘任务中的一个关键任务。一个有效的图嵌入模型可以从图结构化数据中学习到低维表示，从而为数据发布带来各种下游应用的好处，如节点分类、链路预测等。然而，最近的研究表明，图嵌入容易受到属性推断攻击的影响，攻击者可以从学习到的图嵌入中推断出私有节点属性。为了解决这些问题，出现了保护隐私的图嵌入方法，通过对抗学习同时考虑主要学习和隐私保护。然而，现有方法大多假设表示模型在训练阶段拥有所有敏感属性的访问权，但由于不同的隐私偏好，这并不总是成立。此外，隐私保护表示学习中常用的对抗学习技术存在问题。",
    "tldr": "这篇论文提出了一种独立分布正则化的方法，用于保护私有图嵌入的隐私。通过考虑主要学习和隐私保护，该方法解决了现有方法在训练阶段需拥有所有敏感属性的限制，并解决了隐私保护表示学习中常见的对抗学习技术问题。"
}