{
    "title": "4DRVO-Net: Deep 4D Radar-Visual Odometry Using Multi-Modal and Multi-Scale Adaptive Fusion. (arXiv:2308.06573v1 [cs.CV])",
    "abstract": "Four-dimensional (4D) radar--visual odometry (4DRVO) integrates complementary information from 4D radar and cameras, making it an attractive solution for achieving accurate and robust pose estimation. However, 4DRVO may exhibit significant tracking errors owing to three main factors: 1) sparsity of 4D radar point clouds; 2) inaccurate data association and insufficient feature interaction between the 4D radar and camera; and 3) disturbances caused by dynamic objects in the environment, affecting odometry estimation. In this paper, we present 4DRVO-Net, which is a method for 4D radar--visual odometry. This method leverages the feature pyramid, pose warping, and cost volume (PWC) network architecture to progressively estimate and refine poses. Specifically, we propose a multi-scale feature extraction network called Radar-PointNet++ that fully considers rich 4D radar point information, enabling fine-grained learning for sparse 4D radar point clouds. To effectively integrate the two modalit",
    "link": "http://arxiv.org/abs/2308.06573",
    "context": "Title: 4DRVO-Net: Deep 4D Radar-Visual Odometry Using Multi-Modal and Multi-Scale Adaptive Fusion. (arXiv:2308.06573v1 [cs.CV])\nAbstract: Four-dimensional (4D) radar--visual odometry (4DRVO) integrates complementary information from 4D radar and cameras, making it an attractive solution for achieving accurate and robust pose estimation. However, 4DRVO may exhibit significant tracking errors owing to three main factors: 1) sparsity of 4D radar point clouds; 2) inaccurate data association and insufficient feature interaction between the 4D radar and camera; and 3) disturbances caused by dynamic objects in the environment, affecting odometry estimation. In this paper, we present 4DRVO-Net, which is a method for 4D radar--visual odometry. This method leverages the feature pyramid, pose warping, and cost volume (PWC) network architecture to progressively estimate and refine poses. Specifically, we propose a multi-scale feature extraction network called Radar-PointNet++ that fully considers rich 4D radar point information, enabling fine-grained learning for sparse 4D radar point clouds. To effectively integrate the two modalit",
    "path": "papers/23/08/2308.06573.json",
    "total_tokens": 828,
    "translated_title": "4DRVO-Net: 使用多模态和多尺度自适应融合的深度4D雷达-视觉里程计",
    "translated_abstract": "4DRVO-Net是一种用于4D雷达-视觉里程计的方法，它通过整合4D雷达和相机的互补信息，实现了准确和稳健的姿态估计。本文提出了一种名为Radar-PointNet++的多尺度特征提取网络，它充分考虑了丰富的4D雷达点信息，从而实现了对稀疏4D雷达点云的精细学习。同时，该方法还利用特征金字塔、姿态变形和成本体积网络体系结构逐步估计和改进姿态。",
    "tldr": "4DRVO-Net是一种深度4D雷达-视觉里程计的方法，它通过整合4D雷达和相机的信息，并利用多尺度特征提取网络和成本体积网络逐步估计和改进姿态。"
}