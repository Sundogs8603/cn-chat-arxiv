{
    "title": "Pure Exploration under Mediators' Feedback. (arXiv:2308.15552v1 [cs.LG])",
    "abstract": "Stochastic multi-armed bandits are a sequential-decision-making framework, where, at each interaction step, the learner selects an arm and observes a stochastic reward. Within the context of best-arm identification (BAI) problems, the goal of the agent lies in finding the optimal arm, i.e., the one with highest expected reward, as accurately and efficiently as possible. Nevertheless, the sequential interaction protocol of classical BAI problems, where the agent has complete control over the arm being pulled at each round, does not effectively model several decision-making problems of interest (e.g., off-policy learning, partially controllable environments, and human feedback). For this reason, in this work, we propose a novel strict generalization of the classical BAI problem that we refer to as best-arm identification under mediators' feedback (BAI-MF). More specifically, we consider the scenario in which the learner has access to a set of mediators, each of which selects the arms on ",
    "link": "http://arxiv.org/abs/2308.15552",
    "context": "Title: Pure Exploration under Mediators' Feedback. (arXiv:2308.15552v1 [cs.LG])\nAbstract: Stochastic multi-armed bandits are a sequential-decision-making framework, where, at each interaction step, the learner selects an arm and observes a stochastic reward. Within the context of best-arm identification (BAI) problems, the goal of the agent lies in finding the optimal arm, i.e., the one with highest expected reward, as accurately and efficiently as possible. Nevertheless, the sequential interaction protocol of classical BAI problems, where the agent has complete control over the arm being pulled at each round, does not effectively model several decision-making problems of interest (e.g., off-policy learning, partially controllable environments, and human feedback). For this reason, in this work, we propose a novel strict generalization of the classical BAI problem that we refer to as best-arm identification under mediators' feedback (BAI-MF). More specifically, we consider the scenario in which the learner has access to a set of mediators, each of which selects the arms on ",
    "path": "papers/23/08/2308.15552.json",
    "total_tokens": 912,
    "translated_title": "纯探索下的中介反馈",
    "translated_abstract": "随机多臂赌博机是一种顺序决策框架，每一步交互中学习者选择一个臂并观察一个随机回报。在最优臂识别（BAI）问题的背景下，学习者的目标是尽可能准确和高效地找到最优臂，即具有最高期望回报的臂。然而，传统BAI问题的顺序交互协议，即学习者在每一轮中对选择的臂具有完全控制权，无法有效地模拟一些值得关注的决策问题（例如，离线学习，部分可控环境和人类反馈）。因此，在这项工作中，我们提出了一种新的严格推广的传统BAI问题，称之为中介反馈下的最优臂识别（BAI-MF）。更具体地说，我们考虑了学习者可以访问一组中介者的情况，每个中介者都选择要拉动的臂。",
    "tldr": "本研究提出了一种严格推广的传统最优臂识别问题，即中介反馈下的最优臂识别（BAI-MF），通过引入中介者来模拟一些实际决策问题，如离线学习、部分可控环境和人类反馈。"
}