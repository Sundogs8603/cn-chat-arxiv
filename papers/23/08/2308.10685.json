{
    "title": "Contrastive Graph Prompt-tuning for Cross-domain Recommendation. (arXiv:2308.10685v2 [cs.IR] UPDATED)",
    "abstract": "Recommender systems are frequently challenged by the data sparsity problem. One approach to mitigate this issue is through cross-domain recommendation techniques. In a cross-domain context, sharing knowledge between domains can enhance the effectiveness in the target domain. Recent cross-domain methods have employed a pre-training approach, but we argue that these methods often result in suboptimal fine-tuning, especially with large neural models. Modern language models utilize prompts for efficient model tuning. Such prompts act as a tunable latent vector, allowing for the freezing of the main model parameters. In our research, we introduce the Personalised Graph Prompt-based Recommendation (PGPRec) framework. This leverages the advantages of prompt-tuning. Within this framework, we formulate personalized graph prompts item-wise, rooted in items that a user has previously engaged with. Specifically, we employ Contrastive Learning (CL) to produce pre-trained embeddings that offer great",
    "link": "http://arxiv.org/abs/2308.10685",
    "context": "Title: Contrastive Graph Prompt-tuning for Cross-domain Recommendation. (arXiv:2308.10685v2 [cs.IR] UPDATED)\nAbstract: Recommender systems are frequently challenged by the data sparsity problem. One approach to mitigate this issue is through cross-domain recommendation techniques. In a cross-domain context, sharing knowledge between domains can enhance the effectiveness in the target domain. Recent cross-domain methods have employed a pre-training approach, but we argue that these methods often result in suboptimal fine-tuning, especially with large neural models. Modern language models utilize prompts for efficient model tuning. Such prompts act as a tunable latent vector, allowing for the freezing of the main model parameters. In our research, we introduce the Personalised Graph Prompt-based Recommendation (PGPRec) framework. This leverages the advantages of prompt-tuning. Within this framework, we formulate personalized graph prompts item-wise, rooted in items that a user has previously engaged with. Specifically, we employ Contrastive Learning (CL) to produce pre-trained embeddings that offer great",
    "path": "papers/23/08/2308.10685.json",
    "total_tokens": 825,
    "translated_title": "跨域推荐中对比图形提示调优",
    "translated_abstract": "推荐系统经常面临数据稀疏问题。缓解这个问题的方法之一是采用跨域推荐技术。在跨域情境下，领域之间的知识共享可以提高目标领域的效果。最近的跨域方法采用了预训练方法，但我们认为这些方法通常导致次优的微调，特别是对于大型神经模型。现代语言模型利用提示进行高效的模型调优。这些提示作为可调整的潜在向量，可以冻结主要模型参数。在我们的研究中，我们引入了个性化图形提示推荐（PGPRec）框架。该框架利用了提示调优的优势。在该框架中，我们通过对比学习（CL）产生预训练的嵌入，这些嵌入提供了很大的潜力。",
    "tldr": "这项研究引入了个性化图形提示推荐框架，通过对比学习（CL）生成预训练的嵌入，从而在跨域推荐中提高了效果。",
    "en_tdlr": "This research introduces the Personalized Graph Prompt-based Recommendation (PGPRec) framework, which improves cross-domain recommendation effectiveness through Contrastive Learning (CL) to generate pre-trained embeddings."
}