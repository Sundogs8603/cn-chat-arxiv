{
    "title": "LiDAR-Camera Panoptic Segmentation via Geometry-Consistent and Semantic-Aware Alignment. (arXiv:2308.01686v1 [cs.CV])",
    "abstract": "3D panoptic segmentation is a challenging perception task that requires both semantic segmentation and instance segmentation. In this task, we notice that images could provide rich texture, color, and discriminative information, which can complement LiDAR data for evident performance improvement, but their fusion remains a challenging problem. To this end, we propose LCPS, the first LiDAR-Camera Panoptic Segmentation network. In our approach, we conduct LiDAR-Camera fusion in three stages: 1) an Asynchronous Compensation Pixel Alignment (ACPA) module that calibrates the coordinate misalignment caused by asynchronous problems between sensors; 2) a Semantic-Aware Region Alignment (SARA) module that extends the one-to-one point-pixel mapping to one-to-many semantic relations; 3) a Point-to-Voxel feature Propagation (PVP) module that integrates both geometric and semantic fusion information for the entire point cloud. Our fusion strategy improves about 6.9% PQ performance over the LiDAR-on",
    "link": "http://arxiv.org/abs/2308.01686",
    "context": "Title: LiDAR-Camera Panoptic Segmentation via Geometry-Consistent and Semantic-Aware Alignment. (arXiv:2308.01686v1 [cs.CV])\nAbstract: 3D panoptic segmentation is a challenging perception task that requires both semantic segmentation and instance segmentation. In this task, we notice that images could provide rich texture, color, and discriminative information, which can complement LiDAR data for evident performance improvement, but their fusion remains a challenging problem. To this end, we propose LCPS, the first LiDAR-Camera Panoptic Segmentation network. In our approach, we conduct LiDAR-Camera fusion in three stages: 1) an Asynchronous Compensation Pixel Alignment (ACPA) module that calibrates the coordinate misalignment caused by asynchronous problems between sensors; 2) a Semantic-Aware Region Alignment (SARA) module that extends the one-to-one point-pixel mapping to one-to-many semantic relations; 3) a Point-to-Voxel feature Propagation (PVP) module that integrates both geometric and semantic fusion information for the entire point cloud. Our fusion strategy improves about 6.9% PQ performance over the LiDAR-on",
    "path": "papers/23/08/2308.01686.json",
    "total_tokens": 975,
    "translated_title": "基于几何一致性和语义感知对齐的LiDAR-相机全景分割",
    "translated_abstract": "3D全景分割是一个具有挑战性的感知任务，需要同时进行语义分割和实例分割。在这个任务中，我们注意到图像可以提供丰富的纹理、颜色和辨别信息，可以为LiDAR数据提供明显的性能改进，但它们的融合仍然是一个具有挑战性的问题。为此，我们提出了LCPS，第一个LiDAR-相机全景分割网络。在我们的方法中，我们将LiDAR-相机融合分为三个阶段：1）一个异步补偿像素对齐（ACPA）模块，校正传感器之间异步问题导致的坐标错位；2）一个语义感知区域对齐（SARA）模块，将一对一的点-像素映射扩展到一对多的语义关系；3）一个点到体素特征传播（PVP）模块，整合几何和语义融合信息对整个点云进行处理。我们的融合策略相对于仅使用LiDAR的方法，性能提升了约6.9%的PQ。",
    "tldr": "本文提出了LCPS，第一个LiDAR-相机全景分割网络，通过异步补偿像素对齐、语义感知区域对齐和点到体素特征传播的融合策略，显著提高了全景分割的性能。"
}