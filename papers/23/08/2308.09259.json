{
    "title": "FRGNN: Mitigating the Impact of Distribution Shift on Graph Neural Networks via Test-Time Feature Reconstruction. (arXiv:2308.09259v2 [cs.LG] UPDATED)",
    "abstract": "Due to inappropriate sample selection and limited training data, a distribution shift often exists between the training and test sets. This shift can adversely affect the test performance of Graph Neural Networks (GNNs). Existing approaches mitigate this issue by either enhancing the robustness of GNNs to distribution shift or reducing the shift itself. However, both approaches necessitate retraining the model, which becomes unfeasible when the model structure and parameters are inaccessible. To address this challenge, we propose FR-GNN, a general framework for GNNs to conduct feature reconstruction. FRGNN constructs a mapping relationship between the output and input of a well-trained GNN to obtain class representative embeddings and then uses these embeddings to reconstruct the features of labeled nodes. These reconstructed features are then incorporated into the message passing mechanism of GNNs to influence the predictions of unlabeled nodes at test time. Notably, the reconstructed",
    "link": "http://arxiv.org/abs/2308.09259",
    "context": "Title: FRGNN: Mitigating the Impact of Distribution Shift on Graph Neural Networks via Test-Time Feature Reconstruction. (arXiv:2308.09259v2 [cs.LG] UPDATED)\nAbstract: Due to inappropriate sample selection and limited training data, a distribution shift often exists between the training and test sets. This shift can adversely affect the test performance of Graph Neural Networks (GNNs). Existing approaches mitigate this issue by either enhancing the robustness of GNNs to distribution shift or reducing the shift itself. However, both approaches necessitate retraining the model, which becomes unfeasible when the model structure and parameters are inaccessible. To address this challenge, we propose FR-GNN, a general framework for GNNs to conduct feature reconstruction. FRGNN constructs a mapping relationship between the output and input of a well-trained GNN to obtain class representative embeddings and then uses these embeddings to reconstruct the features of labeled nodes. These reconstructed features are then incorporated into the message passing mechanism of GNNs to influence the predictions of unlabeled nodes at test time. Notably, the reconstructed",
    "path": "papers/23/08/2308.09259.json",
    "total_tokens": 950,
    "translated_title": "FRGNN:通过测试时间特征重构减轻分布偏移对图神经网络的影响",
    "translated_abstract": "由于不合适的样本选择和有限的训练数据，训练集和测试集之间经常存在分布偏移。这种偏移可能对图神经网络（GNNs）的测试性能产生不利影响。现有方法通过增强GNNs对分布偏移的鲁棒性或减小偏移本身来缓解这个问题。然而，这两种方法都需要重新训练模型，当无法访问模型结构和参数时，这变得不可行。为了解决这个挑战，我们提出了FR-GNN，一种用于GNNs进行特征重构的通用框架。FRGNN构建了一个从经过良好训练的GNN的输出到输入的映射关系，以获得类别代表性嵌入，然后使用这些嵌入来重构标记节点的特征。然后，这些重构的特征被合并到GNNs的消息传递机制中，以影响测试时间未标记节点的预测。值得注意的是，这些重构的特征保留了原始特征的关键信息，以便在没有可训练模型的情况下改善GNNs的性能。",
    "tldr": "FRGNN是一个通用框架，通过测试时间特征重构，减轻分布偏移对图神经网络的影响，不需要重新训练模型，保留了原始特征的关键信息来改善性能。"
}