{
    "title": "Provably Efficient Algorithm for Nonstationary Low-Rank MDPs. (arXiv:2308.05471v1 [cs.LG])",
    "abstract": "Reinforcement learning (RL) under changing environment models many real-world applications via nonstationary Markov Decision Processes (MDPs), and hence gains considerable interest. However, theoretical studies on nonstationary MDPs in the literature have mainly focused on tabular and linear (mixture) MDPs, which do not capture the nature of unknown representation in deep RL. In this paper, we make the first effort to investigate nonstationary RL under episodic low-rank MDPs, where both transition kernels and rewards may vary over time, and the low-rank model contains unknown representation in addition to the linear state embedding function. We first propose a parameter-dependent policy optimization algorithm called PORTAL, and further improve PORTAL to its parameter-free version of Ada-PORTAL, which is able to tune its hyper-parameters adaptively without any prior knowledge of nonstationarity. For both algorithms, we provide upper bounds on the average dynamic suboptimality gap, which",
    "link": "http://arxiv.org/abs/2308.05471",
    "context": "Title: Provably Efficient Algorithm for Nonstationary Low-Rank MDPs. (arXiv:2308.05471v1 [cs.LG])\nAbstract: Reinforcement learning (RL) under changing environment models many real-world applications via nonstationary Markov Decision Processes (MDPs), and hence gains considerable interest. However, theoretical studies on nonstationary MDPs in the literature have mainly focused on tabular and linear (mixture) MDPs, which do not capture the nature of unknown representation in deep RL. In this paper, we make the first effort to investigate nonstationary RL under episodic low-rank MDPs, where both transition kernels and rewards may vary over time, and the low-rank model contains unknown representation in addition to the linear state embedding function. We first propose a parameter-dependent policy optimization algorithm called PORTAL, and further improve PORTAL to its parameter-free version of Ada-PORTAL, which is able to tune its hyper-parameters adaptively without any prior knowledge of nonstationarity. For both algorithms, we provide upper bounds on the average dynamic suboptimality gap, which",
    "path": "papers/23/08/2308.05471.json",
    "total_tokens": 927,
    "translated_title": "针对非平稳低秩MDP的可证明高效算法",
    "translated_abstract": "强化学习（RL）在改变环境模型下，通过非平稳的马尔可夫决策过程（MDPs）模拟了许多现实世界的应用，并因此引起了相当大的兴趣。然而，文献中关于非平稳MDPs的理论研究主要集中在表格和线性（混合）MDPs上，这些方法无法捕捉深度RL中未知表示的特性。在本文中，我们首次努力研究了在易耗型低秩MDPs下的非平稳RL，其中转移核和奖励都可能随时间变化，低秩模型除了线性状态嵌入函数外还包含未知表示。我们首先提出了一种参数相关的策略优化算法PORTAL，然后将PORTAL改进为自适应参数无关版本的Ada-PORTAL，该算法能够自适应地调整超参数，而不需要任何对非平稳性的先验知识。对于这两种算法，我们给出了平均动态次最优间隙的上界。",
    "tldr": "本文提出了针对非平稳低秩MDP的可证明高效算法，通过研究在非平稳环境下的强化学习，捕捉了深度RL中未知表示的特性，并给出了平均动态次最优间隙的上界。",
    "en_tdlr": "This paper proposes a provably efficient algorithm for nonstationary low-rank MDPs, which captures the nature of unknown representation in deep RL and provides upper bounds on the average dynamic suboptimality gap."
}