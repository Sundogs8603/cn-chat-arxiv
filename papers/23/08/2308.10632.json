{
    "title": "Foundation Model-oriented Robustness: Robust Image Model Evaluation with Pretrained Models. (arXiv:2308.10632v2 [cs.CV] UPDATED)",
    "abstract": "Machine learning has demonstrated remarkable performance over finite datasets, yet whether the scores over the fixed benchmarks can sufficiently indicate the model's performance in the real world is still in discussion. In reality, an ideal robust model will probably behave similarly to the oracle (e.g., the human users), thus a good evaluation protocol is probably to evaluate the models' behaviors in comparison to the oracle. In this paper, we introduce a new robustness measurement that directly measures the image classification model's performance compared with a surrogate oracle (i.e., a foundation model). Besides, we design a simple method that can accomplish the evaluation beyond the scope of the benchmarks. Our method extends the image datasets with new samples that are sufficiently perturbed to be distinct from the ones in the original sets, but are still bounded within the same image-label structure the original test image represents, constrained by a foundation model pretraine",
    "link": "http://arxiv.org/abs/2308.10632",
    "context": "Title: Foundation Model-oriented Robustness: Robust Image Model Evaluation with Pretrained Models. (arXiv:2308.10632v2 [cs.CV] UPDATED)\nAbstract: Machine learning has demonstrated remarkable performance over finite datasets, yet whether the scores over the fixed benchmarks can sufficiently indicate the model's performance in the real world is still in discussion. In reality, an ideal robust model will probably behave similarly to the oracle (e.g., the human users), thus a good evaluation protocol is probably to evaluate the models' behaviors in comparison to the oracle. In this paper, we introduce a new robustness measurement that directly measures the image classification model's performance compared with a surrogate oracle (i.e., a foundation model). Besides, we design a simple method that can accomplish the evaluation beyond the scope of the benchmarks. Our method extends the image datasets with new samples that are sufficiently perturbed to be distinct from the ones in the original sets, but are still bounded within the same image-label structure the original test image represents, constrained by a foundation model pretraine",
    "path": "papers/23/08/2308.10632.json",
    "total_tokens": 893,
    "translated_title": "基础模型导向的稳健性: 通过预训练模型对稳健性图像模型进行评估",
    "translated_abstract": "机器学习在有限数据集上表现出了出色的性能，然而，固定基准上的分数是否足以充分体现模型在真实世界中的性能仍有讨论。实际上，理想的稳健模型可能与神谕（例如，人类用户）表现类似，因此一个好的评估协议可能是评估模型相对于神谕的行为。本文介绍了一种新的稳健性测量方法，直接测量图像分类模型相对于替代神谕（即基础模型）的性能。此外，我们设计了一种简单的方法，可以在基准范围之外完成评估。我们的方法通过添加具有足够扰动的新样本来扩展图像数据集，这些样本与原始集合中的样本有所不同，但仍限制在原始测试图像所代表的相同图像-标签结构内，由预训练的基础模型限定。",
    "tldr": "本文提出了一种通过预训练模型对稳健性图像模型进行评估的新方法，通过与基础模型进行比较，直接测量图像分类模型的性能，扩展图像数据集以完成超出基准范围的评估。",
    "en_tdlr": "This paper introduces a new method for evaluating robustness in image classification models by comparing them with a foundation model, extending the image dataset to accomplish evaluation beyond the scope of benchmarks."
}