{
    "title": "Zero-shot Inversion Process for Image Attribute Editing with Diffusion Models. (arXiv:2308.15854v1 [cs.CV])",
    "abstract": "Denoising diffusion models have shown outstanding performance in image editing. Existing works tend to use either image-guided methods, which provide a visual reference but lack control over semantic coherence, or text-guided methods, which ensure faithfulness to text guidance but lack visual quality. To address the problem, we propose the Zero-shot Inversion Process (ZIP), a framework that injects a fusion of generated visual reference and text guidance into the semantic latent space of a \\textit{frozen} pre-trained diffusion model. Only using a tiny neural network, the proposed ZIP produces diverse content and attributes under the intuitive control of the text prompt. Moreover, ZIP shows remarkable robustness for both in-domain and out-of-domain attribute manipulation on real images. We perform detailed experiments on various benchmark datasets. Compared to state-of-the-art methods, ZIP produces images of equivalent quality while providing a realistic editing effect.",
    "link": "http://arxiv.org/abs/2308.15854",
    "context": "Title: Zero-shot Inversion Process for Image Attribute Editing with Diffusion Models. (arXiv:2308.15854v1 [cs.CV])\nAbstract: Denoising diffusion models have shown outstanding performance in image editing. Existing works tend to use either image-guided methods, which provide a visual reference but lack control over semantic coherence, or text-guided methods, which ensure faithfulness to text guidance but lack visual quality. To address the problem, we propose the Zero-shot Inversion Process (ZIP), a framework that injects a fusion of generated visual reference and text guidance into the semantic latent space of a \\textit{frozen} pre-trained diffusion model. Only using a tiny neural network, the proposed ZIP produces diverse content and attributes under the intuitive control of the text prompt. Moreover, ZIP shows remarkable robustness for both in-domain and out-of-domain attribute manipulation on real images. We perform detailed experiments on various benchmark datasets. Compared to state-of-the-art methods, ZIP produces images of equivalent quality while providing a realistic editing effect.",
    "path": "papers/23/08/2308.15854.json",
    "total_tokens": 925,
    "translated_title": "图像属性编辑的零样本反演过程与扩散模型",
    "translated_abstract": "降噪扩散模型在图像编辑中表现出优秀的性能。现有的方法倾向于使用图像引导方法，提供视觉参考但缺乏语义连贯性的控制，或者使用文本引导方法，确保对文本引导的忠实，但缺乏视觉质量。为了解决这个问题，我们提出了零样本反演过程（ZIP）框架，它将生成的视觉参考和文本引导的融合注入到预训练扩散模型的语义潜空间中。仅使用一个微小的神经网络，提出的ZIP在文本提示的直观控制下产生多样的内容和属性。此外，ZIP在真实图像上展示了对域内和域外属性操作的显著鲁棒性。我们在各种基准数据集上进行了详细的实验。与最先进的方法相比，ZIP产生了与之相当质量的图像，同时提供了逼真的编辑效果。",
    "tldr": "提出了一种零样本反演过程（ZIP）框架，用于图像属性编辑。该方法利用生成的视觉参考和文本引导注入扩散模型的语义潜空间，可以在文本提示的直观控制下产生多样的内容和属性，并展现出对不同属性操作的鲁棒性。",
    "en_tdlr": "A Zero-shot Inversion Process (ZIP) framework is proposed for image attribute editing. By injecting a fusion of generated visual reference and text guidance into the semantic latent space of a diffusion model, ZIP can produce diverse content and attributes under intuitive control of the text prompt, and demonstrates robustness for different attribute manipulations."
}