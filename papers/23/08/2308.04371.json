{
    "title": "Cumulative Reasoning With Large Language Models. (arXiv:2308.04371v1 [cs.AI])",
    "abstract": "While language models are powerful and versatile, they often fail to address highly complex problems. This is because solving complex problems requires deliberate thinking, which has been only minimally guided during training. In this paper, we propose a new method called Cumulative Reasoning (CR), which employs language models in a cumulative and iterative manner to emulate human thought processes. By decomposing tasks into smaller components, \\ournameb streamlines the problem-solving process, rendering it both more manageable and effective. For logical inference tasks, CR consistently outperforms existing methods with an improvement up to 9.3\\%, and achieves the astonishing accuracy of 98.04\\% on the curated FOLIO wiki dataset. In the context of the Game of 24, CR achieves an accuracy of 94\\%, which signifies a substantial enhancement of 20\\% over the previous state-of-the-art method.",
    "link": "http://arxiv.org/abs/2308.04371",
    "context": "Title: Cumulative Reasoning With Large Language Models. (arXiv:2308.04371v1 [cs.AI])\nAbstract: While language models are powerful and versatile, they often fail to address highly complex problems. This is because solving complex problems requires deliberate thinking, which has been only minimally guided during training. In this paper, we propose a new method called Cumulative Reasoning (CR), which employs language models in a cumulative and iterative manner to emulate human thought processes. By decomposing tasks into smaller components, \\ournameb streamlines the problem-solving process, rendering it both more manageable and effective. For logical inference tasks, CR consistently outperforms existing methods with an improvement up to 9.3\\%, and achieves the astonishing accuracy of 98.04\\% on the curated FOLIO wiki dataset. In the context of the Game of 24, CR achieves an accuracy of 94\\%, which signifies a substantial enhancement of 20\\% over the previous state-of-the-art method.",
    "path": "papers/23/08/2308.04371.json",
    "total_tokens": 840,
    "translated_title": "用大型语言模型进行累积推理的论文",
    "translated_abstract": "虽然语言模型强大且多功能，但它们通常无法解决高度复杂的问题。这是因为解决复杂问题需要深思熟虑，而在训练过程中对此只有最小程度的指导。在本文中，我们提出了一种新方法，称为累积推理（CR），它以累积和迭代的方式利用语言模型来模拟人类的思维过程。通过将任务分解为较小的组件，我们的方法简化了问题解决过程，使其更易管理和更有效。对于逻辑推理任务，CR在性能上始终超过现有方法，提高了多达9.3％，并在经过策划的FOLIO维基数据集上实现了惊人的98.04％的准确率。在24点游戏的背景下，CR实现了94％的准确率，相比先前最先进的方法，提升了20％。",
    "tldr": "本文提出了一种名为累积推理（CR）的新方法，利用语言模型以累积和迭代的方式模拟人类思维过程，通过将任务分解为较小的组件，简化问题解决过程，取得了优于现有方法的性能，并在逻辑推理和24点游戏中实现了显著提升。"
}