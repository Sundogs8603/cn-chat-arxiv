{
    "title": "Random Word Data Augmentation with CLIP for Zero-Shot Anomaly Detection. (arXiv:2308.11119v1 [cs.CV])",
    "abstract": "This paper presents a novel method that leverages a visual-language model, CLIP, as a data source for zero-shot anomaly detection. Tremendous efforts have been put towards developing anomaly detectors due to their potential industrial applications. Considering the difficulty in acquiring various anomalous samples for training, most existing methods train models with only normal samples and measure discrepancies from the distribution of normal samples during inference, which requires training a model for each object category. The problem of this inefficient training requirement has been tackled by designing a CLIP-based anomaly detector that applies prompt-guided classification to each part of an image in a sliding window manner. However, the method still suffers from the labor of careful prompt ensembling with known object categories. To overcome the issues above, we propose leveraging CLIP as a data source for training. Our method generates text embeddings with the text encoder in CLI",
    "link": "http://arxiv.org/abs/2308.11119",
    "context": "Title: Random Word Data Augmentation with CLIP for Zero-Shot Anomaly Detection. (arXiv:2308.11119v1 [cs.CV])\nAbstract: This paper presents a novel method that leverages a visual-language model, CLIP, as a data source for zero-shot anomaly detection. Tremendous efforts have been put towards developing anomaly detectors due to their potential industrial applications. Considering the difficulty in acquiring various anomalous samples for training, most existing methods train models with only normal samples and measure discrepancies from the distribution of normal samples during inference, which requires training a model for each object category. The problem of this inefficient training requirement has been tackled by designing a CLIP-based anomaly detector that applies prompt-guided classification to each part of an image in a sliding window manner. However, the method still suffers from the labor of careful prompt ensembling with known object categories. To overcome the issues above, we propose leveraging CLIP as a data source for training. Our method generates text embeddings with the text encoder in CLI",
    "path": "papers/23/08/2308.11119.json",
    "total_tokens": 921,
    "translated_title": "使用CLIP进行随机词语数据增强的零样本异常检测方法",
    "translated_abstract": "本文提出了一种新颖的方法，利用视觉-语言模型CLIP作为数据源进行零样本异常检测。由于潜在的工业应用，人们已经付出了大量的努力来开发异常检测器。考虑到获取各种异常样本以用于训练的困难，大多数现有方法仅用正常样本训练模型，并在推理过程中从正常样本的分布中测量其差异，这需要为每个对象类别训练一个模型。为了解决这种低效的训练需求，设计了一种基于CLIP的异常检测器，它以滑动窗口的方式对图像的每个部分应用prompt-guided分类。然而，该方法仍然受到以已知对象类别仔细组合提示的劳动力的影响。为了解决以上问题，我们提出利用CLIP作为训练的数据源。我们的方法使用CLI中的文本编码器生成文本嵌入。",
    "tldr": "本文提出了一种利用CLIP作为数据源的零样本异常检测方法，通过随机词语数据增强的方式改善了训练效率，并应用prompt-guided分类进行图像的检测。该方法克服了以往需为每个对象类别训练模型的低效问题，有潜力应用于工业领域。",
    "en_tdlr": "This paper presents a method for zero-shot anomaly detection that leverages CLIP as a data source, improves training efficiency with random word data augmentation, and applies prompt-guided classification for image detection. It overcomes the limitation of training a model for each object category and has potential industrial applications."
}