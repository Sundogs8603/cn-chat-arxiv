{
    "title": "SpeechTokenizer: Unified Speech Tokenizer for Speech Large Language Models. (arXiv:2308.16692v1 [cs.CL])",
    "abstract": "Current speech large language models build upon discrete speech representations, which can be categorized into semantic tokens and acoustic tokens. However, existing speech tokens are not specifically designed for speech language modeling. To assess the suitability of speech tokens for building speech language models, we established the first benchmark, SLMTokBench. Our results indicate that neither semantic nor acoustic tokens are ideal for this purpose. Therefore, we propose SpeechTokenizer, a unified speech tokenizer for speech large language models. SpeechTokenizer adopts the Encoder-Decoder architecture with residual vector quantization (RVQ). Unifying semantic and acoustic tokens, SpeechTokenizer disentangles different aspects of speech information hierarchically across different RVQ layers. Furthermore, We construct a Unified Speech Language Model (USLM) leveraging SpeechTokenizer. Experiments show that SpeechTokenizer performs comparably to EnCodec in speech reconstruction and ",
    "link": "http://arxiv.org/abs/2308.16692",
    "context": "Title: SpeechTokenizer: Unified Speech Tokenizer for Speech Large Language Models. (arXiv:2308.16692v1 [cs.CL])\nAbstract: Current speech large language models build upon discrete speech representations, which can be categorized into semantic tokens and acoustic tokens. However, existing speech tokens are not specifically designed for speech language modeling. To assess the suitability of speech tokens for building speech language models, we established the first benchmark, SLMTokBench. Our results indicate that neither semantic nor acoustic tokens are ideal for this purpose. Therefore, we propose SpeechTokenizer, a unified speech tokenizer for speech large language models. SpeechTokenizer adopts the Encoder-Decoder architecture with residual vector quantization (RVQ). Unifying semantic and acoustic tokens, SpeechTokenizer disentangles different aspects of speech information hierarchically across different RVQ layers. Furthermore, We construct a Unified Speech Language Model (USLM) leveraging SpeechTokenizer. Experiments show that SpeechTokenizer performs comparably to EnCodec in speech reconstruction and ",
    "path": "papers/23/08/2308.16692.json",
    "total_tokens": 871,
    "translated_title": "SpeechTokenizer：面向语音大语言模型的统一语音分词器",
    "translated_abstract": "当前的语音大语言模型基于离散的语音表示，可以分为语义标记和声学标记。然而，现有的语音标记并非专为语音语言建模而设计。为了评估语音标记在构建语音语言模型方面的适应性，我们建立了第一个基准标准，即SLMTokBench。我们的结果表明，无论是语义标记还是声学标记都不适合这个目的。因此，我们提出了SpeechTokenizer，一种面向语音大语言模型的统一语音分词器。SpeechTokenizer采用具有残差向量量化（RVQ）的编码器-解码器架构。通过统一语义和声学标记，SpeechTokenizer在不同的RVQ层级上以层次方式解耦语音信息的不同方面。此外，我们构建了一个利用SpeechTokenizer的统一语音语言模型（USLM）。实验证明，SpeechTokenizer在语音重建和...",
    "tldr": "提出了一种面向语音大语言模型的统一语音分词器SpeechTokenizer，通过统一语义和声学标记并采用编码器-解码器架构，实现了在不同层级上解耦语音信息的不同方面，构建了一个统一语音语言模型（USLM）。"
}