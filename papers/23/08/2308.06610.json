{
    "title": "Bio-SIEVE: Exploring Instruction Tuning Large Language Models for Systematic Review Automation. (arXiv:2308.06610v1 [cs.CL])",
    "abstract": "Medical systematic reviews can be very costly and resource intensive. We explore how Large Language Models (LLMs) can support and be trained to perform literature screening when provided with a detailed set of selection criteria. Specifically, we instruction tune LLaMA and Guanaco models to perform abstract screening for medical systematic reviews. Our best model, Bio-SIEVE, outperforms both ChatGPT and trained traditional approaches, and generalises better across medical domains. However, there remains the challenge of adapting the model to safety-first scenarios. We also explore the impact of multi-task training with Bio-SIEVE-Multi, including tasks such as PICO extraction and exclusion reasoning, but find that it is unable to match single-task Bio-SIEVE's performance. We see Bio-SIEVE as an important step towards specialising LLMs for the biomedical systematic review process and explore its future developmental opportunities. We release our models, code and a list of DOIs to reconst",
    "link": "http://arxiv.org/abs/2308.06610",
    "context": "Title: Bio-SIEVE: Exploring Instruction Tuning Large Language Models for Systematic Review Automation. (arXiv:2308.06610v1 [cs.CL])\nAbstract: Medical systematic reviews can be very costly and resource intensive. We explore how Large Language Models (LLMs) can support and be trained to perform literature screening when provided with a detailed set of selection criteria. Specifically, we instruction tune LLaMA and Guanaco models to perform abstract screening for medical systematic reviews. Our best model, Bio-SIEVE, outperforms both ChatGPT and trained traditional approaches, and generalises better across medical domains. However, there remains the challenge of adapting the model to safety-first scenarios. We also explore the impact of multi-task training with Bio-SIEVE-Multi, including tasks such as PICO extraction and exclusion reasoning, but find that it is unable to match single-task Bio-SIEVE's performance. We see Bio-SIEVE as an important step towards specialising LLMs for the biomedical systematic review process and explore its future developmental opportunities. We release our models, code and a list of DOIs to reconst",
    "path": "papers/23/08/2308.06610.json",
    "total_tokens": 1121,
    "translated_title": "Bio-SIEVE：探索针对系统性评述自动化的大型语言模型的指令调优",
    "translated_abstract": "医学系统性评述成本高、资源密集。我们探索了如何使用大型语言模型（LLMs）在提供详细的选择标准的情况下支持和训练其执行文献筛选。具体而言，我们对LLaMA和Guanaco模型进行了指令调优，以执行医学系统性评述的摘要筛选。我们的最佳模型Bio-SIEVE在性能上超过了ChatGPT和经过训练的传统方法，并在医学领域中具有更好的泛化能力。然而，将模型调整为以安全为先的场景仍然具有挑战。我们还探索了与Bio-SIEVE-Multi的多任务训练的影响，包括PICO提取和排除推理等任务，但发现它无法达到单任务Bio-SIEVE的性能。我们认为Bio-SIEVE是为生物医学系统性评述过程专门化的语言模型的重要一步，同时还探索了其未来的发展机会。我们发布了我们的模型、代码和一份DOI列表以供重现。",
    "tldr": "本研究通过探索大型语言模型在医学系统性评述中的应用，尤其是通过指令调优来提高摘要筛选的性能，提出了一种名称为Bio-SIEVE的模型，该模型在医学领域中表现出优异的泛化能力和性能，但在安全性优先场景下仍存在挑战。同时，我们也尝试了多任务训练，但发现其不能与单任务的Bio-SIEVE性能相匹配。这一研究是为了将语言模型专门用于生物医学系统性评述过程迈出的重要一步。我们提供了模型、代码和DOI列表以供复现。"
}