{
    "title": "Time-to-Pattern: Information-Theoretic Unsupervised Learning for Scalable Time Series Summarization. (arXiv:2308.13722v1 [cs.LG])",
    "abstract": "Data summarization is the process of generating interpretable and representative subsets from a dataset. Existing time series summarization approaches often search for recurring subsequences using a set of manually devised similarity functions to summarize the data. However, such approaches are fraught with limitations stemming from an exhaustive search coupled with a heuristic definition of series similarity. Such approaches affect the diversity and comprehensiveness of the generated data summaries. To mitigate these limitations, we introduce an approach to time series summarization, called Time-to-Pattern (T2P), which aims to find a set of diverse patterns that together encode the most salient information, following the notion of minimum description length. T2P is implemented as a deep generative model that learns informative embeddings of the discrete time series on a latent space specifically designed to be interpretable. Our synthetic and real-world experiments reveal that T2P dis",
    "link": "http://arxiv.org/abs/2308.13722",
    "context": "Title: Time-to-Pattern: Information-Theoretic Unsupervised Learning for Scalable Time Series Summarization. (arXiv:2308.13722v1 [cs.LG])\nAbstract: Data summarization is the process of generating interpretable and representative subsets from a dataset. Existing time series summarization approaches often search for recurring subsequences using a set of manually devised similarity functions to summarize the data. However, such approaches are fraught with limitations stemming from an exhaustive search coupled with a heuristic definition of series similarity. Such approaches affect the diversity and comprehensiveness of the generated data summaries. To mitigate these limitations, we introduce an approach to time series summarization, called Time-to-Pattern (T2P), which aims to find a set of diverse patterns that together encode the most salient information, following the notion of minimum description length. T2P is implemented as a deep generative model that learns informative embeddings of the discrete time series on a latent space specifically designed to be interpretable. Our synthetic and real-world experiments reveal that T2P dis",
    "path": "papers/23/08/2308.13722.json",
    "total_tokens": 909,
    "translated_title": "Time-to-Pattern: 信息论无监督学习用于可扩展的时间序列摘要",
    "translated_abstract": "数据摘要是从数据集中生成可解释和代表性子集的过程。现有的时间序列摘要方法通常使用一组手动设计的相似度函数来搜索重复子序列以摘要数据。然而，这些方法面临着来自详尽搜索和启发式定义序列相似度的限制。这些方法影响了生成的数据摘要的多样性和全面性。为了缓解这些限制，我们引入了一种时间序列摘要方法，称为Time-to-Pattern（T2P），它旨在找到一组不同的模式，共同编码最显著的信息，遵循最小描述长度的概念。T2P是一个深度生成模型，它在设计成可解释的潜在空间上学习离散时间序列的信息嵌入。我们的合成和真实世界的实验证明T2P可以提高摘要质量并保持多样性和全面性。",
    "tldr": "这篇论文提出了一种名为Time-to-Pattern的时间序列摘要方法，通过基于信息论的无监督学习，在一个可解释的潜在空间中学习离散时间序列的信息嵌入，找到一组不同的模式以编码最显著的信息，提高了摘要的质量。",
    "en_tdlr": "This paper proposes a time series summarization method called Time-to-Pattern, which uses information-theoretic unsupervised learning to learn informative embeddings of discrete time series in an interpretable latent space, and finds a set of diverse patterns to encode the most salient information, improving the quality of the summarization."
}