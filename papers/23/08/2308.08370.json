{
    "title": "Agglomerative Transformer for Human-Object Interaction Detection. (arXiv:2308.08370v1 [cs.CV])",
    "abstract": "We propose an agglomerative Transformer (AGER) that enables Transformer-based human-object interaction (HOI) detectors to flexibly exploit extra instance-level cues in a single-stage and end-to-end manner for the first time. AGER acquires instance tokens by dynamically clustering patch tokens and aligning cluster centers to instances with textual guidance, thus enjoying two benefits: 1) Integrality: each instance token is encouraged to contain all discriminative feature regions of an instance, which demonstrates a significant improvement in the extraction of different instance-level cues and subsequently leads to a new state-of-the-art performance of HOI detection with 36.75 mAP on HICO-Det. 2) Efficiency: the dynamical clustering mechanism allows AGER to generate instance tokens jointly with the feature learning of the Transformer encoder, eliminating the need of an additional object detector or instance decoder in prior methods, thus allowing the extraction of desirable extra cues fo",
    "link": "http://arxiv.org/abs/2308.08370",
    "context": "Title: Agglomerative Transformer for Human-Object Interaction Detection. (arXiv:2308.08370v1 [cs.CV])\nAbstract: We propose an agglomerative Transformer (AGER) that enables Transformer-based human-object interaction (HOI) detectors to flexibly exploit extra instance-level cues in a single-stage and end-to-end manner for the first time. AGER acquires instance tokens by dynamically clustering patch tokens and aligning cluster centers to instances with textual guidance, thus enjoying two benefits: 1) Integrality: each instance token is encouraged to contain all discriminative feature regions of an instance, which demonstrates a significant improvement in the extraction of different instance-level cues and subsequently leads to a new state-of-the-art performance of HOI detection with 36.75 mAP on HICO-Det. 2) Efficiency: the dynamical clustering mechanism allows AGER to generate instance tokens jointly with the feature learning of the Transformer encoder, eliminating the need of an additional object detector or instance decoder in prior methods, thus allowing the extraction of desirable extra cues fo",
    "path": "papers/23/08/2308.08370.json",
    "total_tokens": 949,
    "translated_title": "用于人-物交互检测的凝聚Transformer",
    "translated_abstract": "我们提出了一种凝聚Transformer（AGER），该方法使基于Transformer的人-物交互（HOI）检测器能够首次以单阶段和端到端的方式灵活利用额外的实例级提示。AGER通过动态聚类补丁标记来获得实例标记，并通过文本指导将聚类中心与实例对齐，从而获得两个优势：1）完整性：每个实例标记都鼓励包含实例的所有有区别特征区域，这对于提取不同的实例级提示表现出了显著的改进，并随后导致HOI检测在HICO-Det上达到36.75个mAP的最新性能。2）效率：动态聚类机制使得AGER能够与Transformer编码器的特征学习一起生成实例标记，消除了先前方法中需要额外的物体检测器或实例解码器的需求，从而允许提取可取的额外提示。",
    "tldr": "我们提出了一种凝聚Transformer（AGER），该方法在人-物交互检测中以单阶段和端到端的方式灵活利用额外的实例级提示。这种方法通过动态聚类补丁标记并将其与文本对齐，从而显著提高了实例级提示的提取效果，并在HICO-Det数据集上取得了最新的36.75 mAP性能。",
    "en_tdlr": "We propose an agglomerative Transformer (AGER) that enables Transformer-based human-object interaction (HOI) detectors to flexibly exploit extra instance-level cues in a single-stage and end-to-end manner for the first time. This approach significantly improves the extraction of instance-level cues and achieves a new state-of-the-art performance of 36.75 mAP on the HICO-Det dataset."
}