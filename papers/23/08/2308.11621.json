{
    "title": "Reinforcement Learning -based Adaptation and Scheduling Methods for Multi-source DASH. (arXiv:2308.11621v1 [cs.NI])",
    "abstract": "Dynamic adaptive streaming over HTTP (DASH) has been widely used in video streaming recently. In DASH, the client downloads video chunks in order from a server. The rate adaptation function at the video client enhances the user's quality-of-experience (QoE) by choosing a suitable quality level for each video chunk to download based on the network condition. Today networks such as content delivery networks, edge caching networks, content-centric networks,... usually replicate video contents on multiple cache nodes. We study video streaming from multiple sources in this work. In multi-source streaming, video chunks may arrive out of order due to different conditions of the network paths. Hence, to guarantee a high QoE, the video client needs not only rate adaptation but also chunk scheduling. Reinforcement learning (RL) has emerged as the state-of-the-art control method in various fields in recent years. This paper proposes two algorithms for streaming from multiple sources: RL-based ada",
    "link": "http://arxiv.org/abs/2308.11621",
    "context": "Title: Reinforcement Learning -based Adaptation and Scheduling Methods for Multi-source DASH. (arXiv:2308.11621v1 [cs.NI])\nAbstract: Dynamic adaptive streaming over HTTP (DASH) has been widely used in video streaming recently. In DASH, the client downloads video chunks in order from a server. The rate adaptation function at the video client enhances the user's quality-of-experience (QoE) by choosing a suitable quality level for each video chunk to download based on the network condition. Today networks such as content delivery networks, edge caching networks, content-centric networks,... usually replicate video contents on multiple cache nodes. We study video streaming from multiple sources in this work. In multi-source streaming, video chunks may arrive out of order due to different conditions of the network paths. Hence, to guarantee a high QoE, the video client needs not only rate adaptation but also chunk scheduling. Reinforcement learning (RL) has emerged as the state-of-the-art control method in various fields in recent years. This paper proposes two algorithms for streaming from multiple sources: RL-based ada",
    "path": "papers/23/08/2308.11621.json",
    "total_tokens": 859,
    "translated_title": "基于强化学习的多源DASH自适应和调度方法",
    "translated_abstract": "近年来，动态自适应流媒体传输(DASH)在视频流媒体中得到了广泛应用。在DASH中，客户端按照顺序从服务器下载视频块。视频客户端的速率自适应功能通过根据网络条件选择适当的质量级别来提高用户的体验质量(QoE)。如今，内容分发网络、边缘缓存网络、内容中心网络等网络通常在多个缓存节点上复制视频内容。我们在这项工作中研究了多源视频流媒体。在多源流媒体中，视频块可能因网络路径的不同条件而以乱序方式到达。因此，为了保证高QoE，视频客户端不仅需要进行速率自适应，还需要进行块调度。强化学习(RL)已经成为近年来各个领域最先进的控制方法。本文提出了两种基于RL的多源视频流媒体算法。",
    "tldr": "本论文提出了基于强化学习的多源DASH自适应和调度方法，通过根据网络条件选择适当的质量级别和进行块调度，提高用户体验质量(QoE)。"
}