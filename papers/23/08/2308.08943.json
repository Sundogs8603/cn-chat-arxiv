{
    "title": "Towards Automatically Addressing Self-Admitted Technical Debt: How Far Are We?. (arXiv:2308.08943v1 [cs.SE])",
    "abstract": "Upon evolving their software, organizations and individual developers have to spend a substantial effort to pay back technical debt, i.e., the fact that software is released in a shape not as good as it should be, e.g., in terms of functionality, reliability, or maintainability. This paper empirically investigates the extent to which technical debt can be automatically paid back by neural-based generative models, and in particular models exploiting different strategies for pre-training and fine-tuning. We start by extracting a dateset of 5,039 Self-Admitted Technical Debt (SATD) removals from 595 open-source projects. SATD refers to technical debt instances documented (e.g., via code comments) by developers. We use this dataset to experiment with seven different generative deep learning (DL) model configurations. Specifically, we compare transformers pre-trained and fine-tuned with different combinations of training objectives, including the fixing of generic code changes, SATD removal",
    "link": "http://arxiv.org/abs/2308.08943",
    "context": "Title: Towards Automatically Addressing Self-Admitted Technical Debt: How Far Are We?. (arXiv:2308.08943v1 [cs.SE])\nAbstract: Upon evolving their software, organizations and individual developers have to spend a substantial effort to pay back technical debt, i.e., the fact that software is released in a shape not as good as it should be, e.g., in terms of functionality, reliability, or maintainability. This paper empirically investigates the extent to which technical debt can be automatically paid back by neural-based generative models, and in particular models exploiting different strategies for pre-training and fine-tuning. We start by extracting a dateset of 5,039 Self-Admitted Technical Debt (SATD) removals from 595 open-source projects. SATD refers to technical debt instances documented (e.g., via code comments) by developers. We use this dataset to experiment with seven different generative deep learning (DL) model configurations. Specifically, we compare transformers pre-trained and fine-tuned with different combinations of training objectives, including the fixing of generic code changes, SATD removal",
    "path": "papers/23/08/2308.08943.json",
    "total_tokens": 897,
    "translated_title": "自动解决自承认技术债务的探索：我们离目标有多远？",
    "translated_abstract": "在软件发展过程中，组织和个人开发者需要花费大量的精力来还清技术债务，即软件发布时存在的不完善，例如功能、可靠性或可维护性方面。本文通过实证研究来探讨基于神经网络生成模型的自动化技术债务偿还程度，特别是利用不同的预训练和微调策略的模型。我们首先从595个开源项目中提取了5,039个自承认技术债务（SATD）的移除实例。SATD是指开发人员通过代码注释等形式来记录的技术债务。我们使用这个数据集来实验七个不同的生成深度学习（DL）模型配置。具体而言，我们比较了不同组合的预训练和微调目标，包括修复通用代码更改，SATD移除等。",
    "tldr": "本文研究了自动化偿还技术债务的潜力，并探索了利用神经网络生成模型实现该目标的方法。实证研究结果表明，不同的预训练和微调策略可以帮助我们在不同项目中有效地解决自承认技术债务。",
    "en_tdlr": "This paper investigates the potential of automatically paying back technical debt and explores methods using neural-based generative models. Empirical results show that different pre-training and fine-tuning strategies can help effectively address self-admitted technical debt in different projects."
}