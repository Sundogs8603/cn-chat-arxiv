{
    "title": "Knowledge-injected Prompt Learning for Chinese Biomedical Entity Normalization. (arXiv:2308.12025v1 [cs.CL])",
    "abstract": "The Biomedical Entity Normalization (BEN) task aims to align raw, unstructured medical entities to standard entities, thus promoting data coherence and facilitating better downstream medical applications. Recently, prompt learning methods have shown promising results in this task. However, existing research falls short in tackling the more complex Chinese BEN task, especially in the few-shot scenario with limited medical data, and the vast potential of the external medical knowledge base has yet to be fully harnessed. To address these challenges, we propose a novel Knowledge-injected Prompt Learning (PL-Knowledge) method. Specifically, our approach consists of five stages: candidate entity matching, knowledge extraction, knowledge encoding, knowledge injection, and prediction output. By effectively encoding the knowledge items contained in medical entities and incorporating them into our tailor-made knowledge-injected templates, the additional knowledge enhances the model's ability to ",
    "link": "http://arxiv.org/abs/2308.12025",
    "context": "Title: Knowledge-injected Prompt Learning for Chinese Biomedical Entity Normalization. (arXiv:2308.12025v1 [cs.CL])\nAbstract: The Biomedical Entity Normalization (BEN) task aims to align raw, unstructured medical entities to standard entities, thus promoting data coherence and facilitating better downstream medical applications. Recently, prompt learning methods have shown promising results in this task. However, existing research falls short in tackling the more complex Chinese BEN task, especially in the few-shot scenario with limited medical data, and the vast potential of the external medical knowledge base has yet to be fully harnessed. To address these challenges, we propose a novel Knowledge-injected Prompt Learning (PL-Knowledge) method. Specifically, our approach consists of five stages: candidate entity matching, knowledge extraction, knowledge encoding, knowledge injection, and prediction output. By effectively encoding the knowledge items contained in medical entities and incorporating them into our tailor-made knowledge-injected templates, the additional knowledge enhances the model's ability to ",
    "path": "papers/23/08/2308.12025.json",
    "total_tokens": 882,
    "translated_title": "中文生物医学实体规范化的知识注入提示学习",
    "translated_abstract": "生物医学实体规范化（BEN）任务旨在将原始的非结构化医学实体对齐到标准实体，从而促进数据的一致性并便于更好的下游医学应用。最近，提示学习方法在这个任务中取得了有希望的结果。然而，现有的研究在处理更复杂的中文BEN任务上存在不足，特别是在有限的医学数据下的少样本情况，外部医学知识库的巨大潜力还没有得到充分利用。为了应对这些挑战，我们提出了一种新颖的知识注入提示学习（PL-Knowledge）方法。具体来说，我们的方法包括五个阶段：候选实体匹配、知识提取、知识编码、知识注入和预测输出。通过有效地编码医学实体中包含的知识项，并将它们整合到我们的定制知识注入模板中，额外的知识增强了模型的能力。",
    "tldr": "我们提出了一种知识注入提示学习方法用于处理中文生物医学实体规范化任务，该方法通过有效编码医学实体中的知识项，并将它们注入到模型中，以增强模型的能力。",
    "en_tdlr": "We propose a knowledge-injected prompt learning method for tackling the Chinese biomedical entity normalization task. Our approach effectively encodes the knowledge items contained in medical entities and incorporates them into the model, enhancing its ability."
}