{
    "title": "SDLFormer: A Sparse and Dense Locality-enhanced Transformer for Accelerated MR Image Reconstruction. (arXiv:2308.04262v1 [eess.IV])",
    "abstract": "Transformers have emerged as viable alternatives to convolutional neural networks owing to their ability to learn non-local region relationships in the spatial domain. The self-attention mechanism of the transformer enables transformers to capture long-range dependencies in the images, which might be desirable for accelerated MRI image reconstruction as the effect of undersampling is non-local in the image domain. Despite its computational efficiency, the window-based transformers suffer from restricted receptive fields as the dependencies are limited to within the scope of the image windows. We propose a window-based transformer network that integrates dilated attention mechanism and convolution for accelerated MRI image reconstruction. The proposed network consists of dilated and dense neighborhood attention transformers to enhance the distant neighborhood pixel relationship and introduce depth-wise convolutions within the transformer module to learn low-level translation invariant f",
    "link": "http://arxiv.org/abs/2308.04262",
    "context": "Title: SDLFormer: A Sparse and Dense Locality-enhanced Transformer for Accelerated MR Image Reconstruction. (arXiv:2308.04262v1 [eess.IV])\nAbstract: Transformers have emerged as viable alternatives to convolutional neural networks owing to their ability to learn non-local region relationships in the spatial domain. The self-attention mechanism of the transformer enables transformers to capture long-range dependencies in the images, which might be desirable for accelerated MRI image reconstruction as the effect of undersampling is non-local in the image domain. Despite its computational efficiency, the window-based transformers suffer from restricted receptive fields as the dependencies are limited to within the scope of the image windows. We propose a window-based transformer network that integrates dilated attention mechanism and convolution for accelerated MRI image reconstruction. The proposed network consists of dilated and dense neighborhood attention transformers to enhance the distant neighborhood pixel relationship and introduce depth-wise convolutions within the transformer module to learn low-level translation invariant f",
    "path": "papers/23/08/2308.04262.json",
    "total_tokens": 816,
    "translated_title": "SDLFormer: 一种稀疏和密集增强的Transformer用于加速MR图像重构",
    "translated_abstract": "随着transformer的出现，它们已成为卷积神经网络的可行替代方案，因为它们能够学习空间域中的非局部区域关系。transformer的自注意机制使其能捕捉图像中的长距离依赖关系，这对于加速MRI图像重建是有益的，因为欠采样的影响在图像域中是非局部的。尽管窗口式transformer具有计算效率，但由于依赖关系限于图像窗口的范围，因此其感受野受限。我们提出了一种基于窗口的transformer网络，该网络整合了扩张注意机制和卷积，用于加速MRI图像重建。所提出的网络由扩张和密集邻域注意transformer组成，以增强远处邻域像素关系，并在transformer模块内引入深度卷积，以学习低级平移不变特征。",
    "tldr": "提出了一种窗口式的transformer网络，该网络通过整合扩张注意机制和卷积，用于加速MRI图像重建，并通过增强远处邻域像素关系和学习低级平移不变特征来提高重建质量。"
}