{
    "title": "Avoidance Navigation Based on Offline Pre-Training Reinforcement Learning. (arXiv:2308.01551v1 [cs.RO])",
    "abstract": "This paper presents a Pre-Training Deep Reinforcement Learning(DRL) for avoidance navigation without map for mobile robots which map raw sensor data to control variable and navigate in an unknown environment. The efficient offline training strategy is proposed to speed up the inefficient random explorations in early stage and we also collect a universal dataset including expert experience for offline training, which is of some significance for other navigation training work. The pre-training and prioritized expert experience are proposed to reduce 80\\% training time and has been verified to improve the 2 times reward of DRL. The advanced simulation gazebo with real physical modelling and dynamic equations reduce the gap between sim-to-real. We train our model a corridor environment, and evaluate the model in different environment getting the same effect. Compared to traditional method navigation, we can confirm the trained model can be directly applied into different scenarios and have",
    "link": "http://arxiv.org/abs/2308.01551",
    "context": "Title: Avoidance Navigation Based on Offline Pre-Training Reinforcement Learning. (arXiv:2308.01551v1 [cs.RO])\nAbstract: This paper presents a Pre-Training Deep Reinforcement Learning(DRL) for avoidance navigation without map for mobile robots which map raw sensor data to control variable and navigate in an unknown environment. The efficient offline training strategy is proposed to speed up the inefficient random explorations in early stage and we also collect a universal dataset including expert experience for offline training, which is of some significance for other navigation training work. The pre-training and prioritized expert experience are proposed to reduce 80\\% training time and has been verified to improve the 2 times reward of DRL. The advanced simulation gazebo with real physical modelling and dynamic equations reduce the gap between sim-to-real. We train our model a corridor environment, and evaluate the model in different environment getting the same effect. Compared to traditional method navigation, we can confirm the trained model can be directly applied into different scenarios and have",
    "path": "papers/23/08/2308.01551.json",
    "total_tokens": 998,
    "translated_title": "基于离线预训练强化学习的避障导航",
    "translated_abstract": "本文提出了一种针对移动机器人的避障导航的预训练深度强化学习方法，该方法将原始传感器数据映射到控制变量，并在未知环境中进行导航。我们提出了高效的离线训练策略，以加速早期阶段的随机探索，并收集了用于离线训练的包含专家经验的通用数据集，这对于其他导航训练工作具有一定的意义。预训练和优先的专家经验被提出来减少80％的训练时间，并且已经验证可以提高强化学习的奖励2倍。通过先进的仿真Gazebo和真实物理建模以及动态方程，缩小了仿真与真实之间的差距。我们在走廊环境中训练了我们的模型，并在不同环境中评估了模型，得到了相同的效果。与传统的导航方法相比，我们可以确认训练好的模型可以直接应用于不同情境，并取得相同的效果。",
    "tldr": "本文提出了一种基于离线预训练强化学习的避障导航方法，通过高效的离线训练策略和收集专家经验的通用数据集，可以减少训练时间并提高强化学习奖励。通过先进的仿真和真实物理建模，缩小了仿真与真实之间的差距。在不同环境中，训练好的模型都能取得相同的效果。",
    "en_tdlr": "This paper proposes an avoidance navigation method based on offline pre-training reinforcement learning, which reduces training time and improves reinforcement learning reward through efficient offline training strategy and collecting expert experience. It also reduces the gap between simulation and reality through advanced simulation and physical modeling, achieving consistent results in different environments."
}