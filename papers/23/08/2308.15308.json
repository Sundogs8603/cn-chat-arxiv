{
    "title": "On-Device Learning with Binary Neural Networks. (arXiv:2308.15308v1 [cs.LG])",
    "abstract": "Existing Continual Learning (CL) solutions only partially address the constraints on power, memory and computation of the deep learning models when deployed on low-power embedded CPUs. In this paper, we propose a CL solution that embraces the recent advancements in CL field and the efficiency of the Binary Neural Networks (BNN), that use 1-bit for weights and activations to efficiently execute deep learning models. We propose a hybrid quantization of CWR* (an effective CL approach) that considers differently forward and backward pass in order to retain more precision during gradient update step and at the same time minimizing the latency overhead. The choice of a binary network as backbone is essential to meet the constraints of low power devices and, to the best of authors' knowledge, this is the first attempt to prove on-device learning with BNN. The experimental validation carried out confirms the validity and the suitability of the proposed method.",
    "link": "http://arxiv.org/abs/2308.15308",
    "context": "Title: On-Device Learning with Binary Neural Networks. (arXiv:2308.15308v1 [cs.LG])\nAbstract: Existing Continual Learning (CL) solutions only partially address the constraints on power, memory and computation of the deep learning models when deployed on low-power embedded CPUs. In this paper, we propose a CL solution that embraces the recent advancements in CL field and the efficiency of the Binary Neural Networks (BNN), that use 1-bit for weights and activations to efficiently execute deep learning models. We propose a hybrid quantization of CWR* (an effective CL approach) that considers differently forward and backward pass in order to retain more precision during gradient update step and at the same time minimizing the latency overhead. The choice of a binary network as backbone is essential to meet the constraints of low power devices and, to the best of authors' knowledge, this is the first attempt to prove on-device learning with BNN. The experimental validation carried out confirms the validity and the suitability of the proposed method.",
    "path": "papers/23/08/2308.15308.json",
    "total_tokens": 920,
    "translated_title": "使用二进制神经网络进行设备上的学习",
    "translated_abstract": "现有的连续学习解决方案在低功耗嵌入式CPU上部署时，仅部分解决了深度学习模型在功耗、内存和计算方面的限制。本文提出了一种连续学习解决方案，结合了连续学习领域的最新进展和二进制神经网络(BNN)的高效性，BNN使用1位用于权重和激活以高效执行深度学习模型。我们提出了一种CWR*的混合量化方法（一种有效的连续学习方法），该方法在前向传递和反向传递过程中分别考虑，以在梯度更新步骤中保持更高的精度，并同时最大限度地减少延迟开销。选择二进制网络作为骨干网络对于满足低功耗设备的限制至关重要，据作者所知，这是首次尝试证明使用BNN进行设备上的学习。进行的实验验证了该方法的有效性和适用性。",
    "tldr": "本文提出了一种在低功耗设备上使用二进制神经网络进行设备端学习的解决方案，该方法结合了最新的连续学习技术和二进制神经网络的高效性。实验证实了该方法的有效性和适用性。",
    "en_tdlr": "This paper proposes a solution for on-device learning with Binary Neural Networks (BNN), aiming to address the constraints of power and computation on low-power embedded CPUs. The proposed approach combines the advancements in Continual Learning (CL) with the efficiency of BNN, using 1-bit weights and activations. Experimental results validate its effectiveness and suitability for on-device learning."
}