{
    "title": "PARIS: Part-level Reconstruction and Motion Analysis for Articulated Objects. (arXiv:2308.07391v1 [cs.CV])",
    "abstract": "We address the task of simultaneous part-level reconstruction and motion parameter estimation for articulated objects. Given two sets of multi-view images of an object in two static articulation states, we decouple the movable part from the static part and reconstruct shape and appearance while predicting the motion parameters. To tackle this problem, we present PARIS: a self-supervised, end-to-end architecture that learns part-level implicit shape and appearance models and optimizes motion parameters jointly without any 3D supervision, motion, or semantic annotation. Our experiments show that our method generalizes better across object categories, and outperforms baselines and prior work that are given 3D point clouds as input. Our approach improves reconstruction relative to state-of-the-art baselines with a Chamfer-L1 distance reduction of 3.94 (45.2%) for objects and 26.79 (84.5%) for parts, and achieves 5% error rate for motion estimation across 10 object categories.  Video summar",
    "link": "http://arxiv.org/abs/2308.07391",
    "context": "Title: PARIS: Part-level Reconstruction and Motion Analysis for Articulated Objects. (arXiv:2308.07391v1 [cs.CV])\nAbstract: We address the task of simultaneous part-level reconstruction and motion parameter estimation for articulated objects. Given two sets of multi-view images of an object in two static articulation states, we decouple the movable part from the static part and reconstruct shape and appearance while predicting the motion parameters. To tackle this problem, we present PARIS: a self-supervised, end-to-end architecture that learns part-level implicit shape and appearance models and optimizes motion parameters jointly without any 3D supervision, motion, or semantic annotation. Our experiments show that our method generalizes better across object categories, and outperforms baselines and prior work that are given 3D point clouds as input. Our approach improves reconstruction relative to state-of-the-art baselines with a Chamfer-L1 distance reduction of 3.94 (45.2%) for objects and 26.79 (84.5%) for parts, and achieves 5% error rate for motion estimation across 10 object categories.  Video summar",
    "path": "papers/23/08/2308.07391.json",
    "total_tokens": 952,
    "translated_title": "PARIS: 面向关节物体的部分级别重建与运动分析",
    "translated_abstract": "我们解决了关节物体的部分级别重建和运动参数估计的任务。给定一个物体在两个静态关节状态下的两组多视角图像，我们将可移动部分与静态部分分离出来，在预测运动参数的同时重建形状和外观。为了解决这个问题，我们提出了一种自我监督的、端到端的架构PARIS，该架构学习了部分级别的隐式形状和外观模型，并在没有任何3D监督、运动或语义注释的情况下共同优化运动参数。我们的实验结果表明，我们的方法在物体类别之间具有更好的泛化性，并且在给定3D点云作为输入的基准线和之前的工作中胜过了其他方法。我们的方法相对于最先进的基线方法改进了重建效果，对于对象的Chamfer-L1距离减少了3.94（45.2%），对于部分的距离减少了26.79（84.5%），并在10个对象类别中实现了5%的运动估计误差率。",
    "tldr": "PARIS是一种面向关节物体的部分级别重建与运动分析方法，它使用自我监督的、端到端的架构来学习隐式形状和外观模型，并在没有3D监督的情况下优化运动参数。与其他基线方法相比，PARIS方法在重建和运动估计方面表现出色，对于对象的重建距离减少了45.2%，对于部分的重建距离减少了84.5%。"
}