{
    "title": "Latent Emission-Augmented Perspective-Taking (LEAPT) for Human-Robot Interaction. (arXiv:2308.06498v1 [cs.AI])",
    "abstract": "Perspective-taking is the ability to perceive or understand a situation or concept from another individual's point of view, and is crucial in daily human interactions. Enabling robots to perform perspective-taking remains an unsolved problem; existing approaches that use deterministic or handcrafted methods are unable to accurately account for uncertainty in partially-observable settings. This work proposes to address this limitation via a deep world model that enables a robot to perform both perception and conceptual perspective taking, i.e., the robot is able to infer what a human sees and believes. The key innovation is a decomposed multi-modal latent state space model able to generate and augment fictitious observations/emissions. Optimizing the ELBO that arises from this probabilistic graphical model enables the learning of uncertainty in latent space, which facilitates uncertainty estimation from high-dimensional observations. We tasked our model to predict human observations and",
    "link": "http://arxiv.org/abs/2308.06498",
    "context": "Title: Latent Emission-Augmented Perspective-Taking (LEAPT) for Human-Robot Interaction. (arXiv:2308.06498v1 [cs.AI])\nAbstract: Perspective-taking is the ability to perceive or understand a situation or concept from another individual's point of view, and is crucial in daily human interactions. Enabling robots to perform perspective-taking remains an unsolved problem; existing approaches that use deterministic or handcrafted methods are unable to accurately account for uncertainty in partially-observable settings. This work proposes to address this limitation via a deep world model that enables a robot to perform both perception and conceptual perspective taking, i.e., the robot is able to infer what a human sees and believes. The key innovation is a decomposed multi-modal latent state space model able to generate and augment fictitious observations/emissions. Optimizing the ELBO that arises from this probabilistic graphical model enables the learning of uncertainty in latent space, which facilitates uncertainty estimation from high-dimensional observations. We tasked our model to predict human observations and",
    "path": "papers/23/08/2308.06498.json",
    "total_tokens": 886,
    "translated_title": "隐变量发射增强的透视视角（LEAPT）用于人机交互",
    "translated_abstract": "透视视角是指从他人的角度感知或理解情境或概念的能力，在日常人际互动中至关重要。使机器人能够进行透视视角仍然是一个未解决的问题；现有的使用确定性或手工制定方法的方法无法准确考虑到部分可观察环境中的不确定性。本研究提出通过深度世界模型来解决这个限制，该模型使机器人能够执行感知和概念透视视角，即机器人能够推断人类所见和所信的内容。关键创新是一个分解的多模态隐状态空间模型，能够生成和增强虚拟的观测/发射。通过优化这个概率图模型产生的ELBO，可以学习隐空间中的不确定性，从而便于从高维观测中进行不确定性估计。我们的模型任务是预测人类的观察和信念。",
    "tldr": "该论文介绍了一个名为LEAPT的方法，通过使用隐变量发射增强的透视视角模型，使机器人能够理解和推断人类观察和信念，该模型通过优化ELBO来学习隐空间中的不确定性。",
    "en_tdlr": "This paper presents LEAPT, a method that enables robots to understand and infer human observations and beliefs by using a latent emission-augmented perspective-taking model. The model learns uncertainty in the latent space through optimizing the ELBO."
}