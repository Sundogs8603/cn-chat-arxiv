{
    "title": "Evaluating Link Prediction Explanations for Graph Neural Networks. (arXiv:2308.01682v1 [cs.LG])",
    "abstract": "Graph Machine Learning (GML) has numerous applications, such as node/graph classification and link prediction, in real-world domains. Providing human-understandable explanations for GML models is a challenging yet fundamental task to foster their adoption, but validating explanations for link prediction models has received little attention. In this paper, we provide quantitative metrics to assess the quality of link prediction explanations, with or without ground-truth. State-of-the-art explainability methods for Graph Neural Networks are evaluated using these metrics. We discuss how underlying assumptions and technical details specific to the link prediction task, such as the choice of distance between node embeddings, can influence the quality of the explanations.",
    "link": "http://arxiv.org/abs/2308.01682",
    "context": "Title: Evaluating Link Prediction Explanations for Graph Neural Networks. (arXiv:2308.01682v1 [cs.LG])\nAbstract: Graph Machine Learning (GML) has numerous applications, such as node/graph classification and link prediction, in real-world domains. Providing human-understandable explanations for GML models is a challenging yet fundamental task to foster their adoption, but validating explanations for link prediction models has received little attention. In this paper, we provide quantitative metrics to assess the quality of link prediction explanations, with or without ground-truth. State-of-the-art explainability methods for Graph Neural Networks are evaluated using these metrics. We discuss how underlying assumptions and technical details specific to the link prediction task, such as the choice of distance between node embeddings, can influence the quality of the explanations.",
    "path": "papers/23/08/2308.01682.json",
    "total_tokens": 743,
    "translated_title": "评估图神经网络的链路预测解释",
    "translated_abstract": "图机器学习（GML）在现实世界的领域中有许多应用，比如节点/图分类和链路预测。为GML模型提供人类可理解的解释是一项具有挑战性但基础的任务，但对链路预测模型的解释验证却受到了很少的关注。在本文中，我们提供了定量指标来评估链路预测解释的质量，无论是否有基准数据。我们使用这些指标评估了图神经网络的最先进可解释性方法。我们讨论了底层假设和链路预测任务特定的技术细节，比如节点嵌入之间的距离选择，如何影响解释的质量。",
    "tldr": "本文评估了图神经网络的链路预测解释的质量，并提供了定量指标来衡量解释的质量。我们发现底层假设和技术细节对解释的质量有影响。",
    "en_tdlr": "This paper evaluates the quality of link prediction explanations for Graph Neural Networks, providing quantitative metrics to assess the explanations' quality. It discusses the impact of underlying assumptions and technical details on the quality of the explanations."
}