{
    "title": "Diffusion Model as Representation Learner. (arXiv:2308.10916v1 [cs.CV])",
    "abstract": "Diffusion Probabilistic Models (DPMs) have recently demonstrated impressive results on various generative tasks.Despite its promises, the learned representations of pre-trained DPMs, however, have not been fully understood. In this paper, we conduct an in-depth investigation of the representation power of DPMs, and propose a novel knowledge transfer method that leverages the knowledge acquired by generative DPMs for recognition tasks. Our study begins by examining the feature space of DPMs, revealing that DPMs are inherently denoising autoencoders that balance the representation learning with regularizing model capacity. To this end, we introduce a novel knowledge transfer paradigm named RepFusion. Our paradigm extracts representations at different time steps from off-the-shelf DPMs and dynamically employs them as supervision for student networks, in which the optimal time is determined through reinforcement learning. We evaluate our approach on several image classification, semantic s",
    "link": "http://arxiv.org/abs/2308.10916",
    "context": "Title: Diffusion Model as Representation Learner. (arXiv:2308.10916v1 [cs.CV])\nAbstract: Diffusion Probabilistic Models (DPMs) have recently demonstrated impressive results on various generative tasks.Despite its promises, the learned representations of pre-trained DPMs, however, have not been fully understood. In this paper, we conduct an in-depth investigation of the representation power of DPMs, and propose a novel knowledge transfer method that leverages the knowledge acquired by generative DPMs for recognition tasks. Our study begins by examining the feature space of DPMs, revealing that DPMs are inherently denoising autoencoders that balance the representation learning with regularizing model capacity. To this end, we introduce a novel knowledge transfer paradigm named RepFusion. Our paradigm extracts representations at different time steps from off-the-shelf DPMs and dynamically employs them as supervision for student networks, in which the optimal time is determined through reinforcement learning. We evaluate our approach on several image classification, semantic s",
    "path": "papers/23/08/2308.10916.json",
    "total_tokens": 908,
    "translated_title": "据传统模型作为表示学习器",
    "translated_abstract": "最近，扩散概率模型（DPMs）在各种生成任务中展示出了令人印象深刻的结果。然而，预先训练的DPMs的学习表示尚未完全理解。在本文中，我们对DPMs的表示力进行了深入研究，并提出了一种新的知识传递方法，利用生成性DPMs获得的知识进行识别任务。我们的研究从研究DPMs的特征空间开始，揭示了DPMs作为去噪自编码器对表示学习和模型容量进行平衡。为此，我们引入了一种名为RepFusion的新的知识传递范式。我们的模式从DPMs中提取不同时间步的表示，并将它们动态地用作学生网络的监督，并通过强化学习确定最佳时间。我们在几个图像分类、语义",
    "tldr": "本文深入研究了扩散概率模型的表示能力，并提出了一种利用生成模型的知识进行识别任务的新的知识传递方法。通过引入RepFusion，我们从预先训练的DPMs中提取表示并将其作为学生网络的监督，通过强化学习来确定最佳的时间步骤。",
    "en_tdlr": "This paper explores the representation power of diffusion probabilistic models (DPMs) and introduces a novel knowledge transfer method that utilizes the knowledge acquired by generative DPMs for recognition tasks. The proposed RepFusion paradigm extracts representations from pre-trained DPMs and dynamically employs them as supervision for student networks, determining the optimal time step through reinforcement learning."
}