{
    "title": "Pro-Cap: Leveraging a Frozen Vision-Language Model for Hateful Meme Detection. (arXiv:2308.08088v1 [cs.CV])",
    "abstract": "Hateful meme detection is a challenging multimodal task that requires comprehension of both vision and language, as well as cross-modal interactions. Recent studies have tried to fine-tune pre-trained vision-language models (PVLMs) for this task. However, with increasing model sizes, it becomes important to leverage powerful PVLMs more efficiently, rather than simply fine-tuning them. Recently, researchers have attempted to convert meme images into textual captions and prompt language models for predictions. This approach has shown good performance but suffers from non-informative image captions. Considering the two factors mentioned above, we propose a probing-based captioning approach to leverage PVLMs in a zero-shot visual question answering (VQA) manner. Specifically, we prompt a frozen PVLM by asking hateful content-related questions and use the answers as image captions (which we call Pro-Cap), so that the captions contain information critical for hateful content detection. The g",
    "link": "http://arxiv.org/abs/2308.08088",
    "context": "Title: Pro-Cap: Leveraging a Frozen Vision-Language Model for Hateful Meme Detection. (arXiv:2308.08088v1 [cs.CV])\nAbstract: Hateful meme detection is a challenging multimodal task that requires comprehension of both vision and language, as well as cross-modal interactions. Recent studies have tried to fine-tune pre-trained vision-language models (PVLMs) for this task. However, with increasing model sizes, it becomes important to leverage powerful PVLMs more efficiently, rather than simply fine-tuning them. Recently, researchers have attempted to convert meme images into textual captions and prompt language models for predictions. This approach has shown good performance but suffers from non-informative image captions. Considering the two factors mentioned above, we propose a probing-based captioning approach to leverage PVLMs in a zero-shot visual question answering (VQA) manner. Specifically, we prompt a frozen PVLM by asking hateful content-related questions and use the answers as image captions (which we call Pro-Cap), so that the captions contain information critical for hateful content detection. The g",
    "path": "papers/23/08/2308.08088.json",
    "total_tokens": 914,
    "translated_title": "Pro-Cap: 利用冻结的视觉-语言模型进行恶意迷因检测",
    "translated_abstract": "恶意迷因检测是一项具有挑战性的多模态任务，需要理解视觉和语言，并进行跨模态交互。最近的研究尝试使用预训练的视觉-语言模型(PVLMs)对该任务进行微调。然而，随着模型规模的增加，更有效地利用强大的PVLMs变得比简单微调它们更为重要。最近，研究人员尝试将迷因图像转化为文本标题，并通过提示语言模型进行预测。这种方法表现出良好的性能，但受到了非信息性图像标题的限制。考虑到上述两个因素，我们提出了一种基于探测的标题生成方法，以零样本视觉问答(VQA)的方式利用PVLMs。具体而言，我们通过提问与恶意内容相关的问题来提示一个冻结的PVLM，并将回答作为图像标题(我们称之为Pro-Cap)，以确保标题包含恶意内容检测所需的关键信息。",
    "tldr": "Pro-Cap是一种利用冻结的视觉-语言模型进行恶意迷因检测的方法，通过提问与恶意内容相关的问题并利用回答作为图像标题，以更有效地利用强大的预训练模型进行检测。"
}