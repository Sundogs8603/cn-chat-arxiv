{
    "title": "Efficient Monaural Speech Enhancement using Spectrum Attention Fusion. (arXiv:2308.02263v1 [cs.SD])",
    "abstract": "Speech enhancement is a demanding task in automated speech processing pipelines, focusing on separating clean speech from noisy channels. Transformer based models have recently bested RNN and CNN models in speech enhancement, however at the same time they are much more computationally expensive and require much more high quality training data, which is always hard to come by. In this paper, we present an improvement for speech enhancement models that maintains the expressiveness of self-attention while significantly reducing model complexity, which we have termed Spectrum Attention Fusion. We carefully construct a convolutional module to replace several self-attention layers in a speech Transformer, allowing the model to more efficiently fuse spectral features. Our proposed model is able to achieve comparable or better results against SOTA models but with significantly smaller parameters (0.58M) on the Voice Bank + DEMAND dataset.",
    "link": "http://arxiv.org/abs/2308.02263",
    "context": "Title: Efficient Monaural Speech Enhancement using Spectrum Attention Fusion. (arXiv:2308.02263v1 [cs.SD])\nAbstract: Speech enhancement is a demanding task in automated speech processing pipelines, focusing on separating clean speech from noisy channels. Transformer based models have recently bested RNN and CNN models in speech enhancement, however at the same time they are much more computationally expensive and require much more high quality training data, which is always hard to come by. In this paper, we present an improvement for speech enhancement models that maintains the expressiveness of self-attention while significantly reducing model complexity, which we have termed Spectrum Attention Fusion. We carefully construct a convolutional module to replace several self-attention layers in a speech Transformer, allowing the model to more efficiently fuse spectral features. Our proposed model is able to achieve comparable or better results against SOTA models but with significantly smaller parameters (0.58M) on the Voice Bank + DEMAND dataset.",
    "path": "papers/23/08/2308.02263.json",
    "total_tokens": 892,
    "translated_title": "使用频谱注意力融合的高效单声道语音增强",
    "translated_abstract": "语音增强是自动语音处理流程中一项需求较高的任务，着重于分离干净的语音信号和嘈杂的信道。最近，基于Transformer的模型在语音增强中表现优于RNN和CNN模型，然而与此同时，它们的计算复杂度更高，需要更多高质量的训练数据，而这在实际情况中往往很难获得。本文提出了一种改进的语音增强模型，通过称之为频谱注意力融合的方法，在显著降低模型复杂度的同时保持了自注意力的表达能力。我们巧妙地构建了一个卷积模块来替代语音Transformer中的若干自注意力层，使模型能够更高效地融合频谱特征。在Voice Bank + DEMAND数据集上，我们的提出的模型能够在参数显著减少（0.58M）的情况下实现与SOTA模型相媲美甚至更好的结果。",
    "tldr": "本文提出了一种名为Spectrum Attention Fusion的方法，通过使用卷积模块替代自注意力层，实现了在语音增强任务中降低模型复杂度的目标，并在实验中取得了与当前最优模型相媲美的结果。"
}