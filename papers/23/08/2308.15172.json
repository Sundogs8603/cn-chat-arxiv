{
    "title": "Is visual explanation with Grad-CAM more reliable for deeper neural networks? a case study with automatic pneumothorax diagnosis. (arXiv:2308.15172v1 [eess.IV])",
    "abstract": "While deep learning techniques have provided the state-of-the-art performance in various clinical tasks, explainability regarding their decision-making process can greatly enhance the credence of these methods for safer and quicker clinical adoption. With high flexibility, Gradient-weighted Class Activation Mapping (Grad-CAM) has been widely adopted to offer intuitive visual interpretation of various deep learning models' reasoning processes in computer-assisted diagnosis. However, despite the popularity of the technique, there is still a lack of systematic study on Grad-CAM's performance on different deep learning architectures. In this study, we investigate its robustness and effectiveness across different popular deep learning models, with a focus on the impact of the networks' depths and architecture types, by using a case study of automatic pneumothorax diagnosis in X-ray scans. Our results show that deeper neural networks do not necessarily contribute to a strong improvement of p",
    "link": "http://arxiv.org/abs/2308.15172",
    "context": "Title: Is visual explanation with Grad-CAM more reliable for deeper neural networks? a case study with automatic pneumothorax diagnosis. (arXiv:2308.15172v1 [eess.IV])\nAbstract: While deep learning techniques have provided the state-of-the-art performance in various clinical tasks, explainability regarding their decision-making process can greatly enhance the credence of these methods for safer and quicker clinical adoption. With high flexibility, Gradient-weighted Class Activation Mapping (Grad-CAM) has been widely adopted to offer intuitive visual interpretation of various deep learning models' reasoning processes in computer-assisted diagnosis. However, despite the popularity of the technique, there is still a lack of systematic study on Grad-CAM's performance on different deep learning architectures. In this study, we investigate its robustness and effectiveness across different popular deep learning models, with a focus on the impact of the networks' depths and architecture types, by using a case study of automatic pneumothorax diagnosis in X-ray scans. Our results show that deeper neural networks do not necessarily contribute to a strong improvement of p",
    "path": "papers/23/08/2308.15172.json",
    "total_tokens": 965,
    "translated_title": "深度神经网络中使用Grad-CAM的视觉解释更可靠吗？以自动气胸诊断为案例研究",
    "translated_abstract": "尽管深度学习技术在各种临床任务中提供了最先进的性能，但关于其决策过程的解释性可以极大增强这些方法在安全和快速临床应用中的可信度。具有高灵活性的梯度加权类别激活映射（Grad-CAM）已被广泛采用，以提供各种深度学习模型在计算机辅助诊断中推理过程的直观视觉解释。然而，尽管该技术的流行，对Grad-CAM在不同深度学习架构上的性能仍缺乏系统研究。在本研究中，我们研究了其在不同流行的深度学习模型上的鲁棒性和效果，重点关注网络的深度和架构类型的影响，通过使用X光扫描中自动气胸诊断的案例研究。我们的结果表明，深度神经网络不一定会显著改善Grad-CAM的性能。",
    "tldr": "本研究通过自动气胸诊断案例研究，探究了不同深度学习模型中Grad-CAM的鲁棒性和效果，结果表明深度神经网络并不一定会显著改善Grad-CAM的性能。"
}