{
    "title": "Everyone Can Attack: Repurpose Lossy Compression as a Natural Backdoor Attack. (arXiv:2308.16684v1 [cs.CR])",
    "abstract": "The vulnerabilities to backdoor attacks have recently threatened the trustworthiness of machine learning models in practical applications. Conventional wisdom suggests that not everyone can be an attacker since the process of designing the trigger generation algorithm often involves significant effort and extensive experimentation to ensure the attack's stealthiness and effectiveness. Alternatively, this paper shows that there exists a more severe backdoor threat: anyone can exploit an easily-accessible algorithm for silent backdoor attacks. Specifically, this attacker can employ the widely-used lossy image compression from a plethora of compression tools to effortlessly inject a trigger pattern into an image without leaving any noticeable trace; i.e., the generated triggers are natural artifacts. One does not require extensive knowledge to click on the \"convert\" or \"save as\" button while using tools for lossy image compression. Via this attack, the adversary does not need to design a ",
    "link": "http://arxiv.org/abs/2308.16684",
    "context": "Title: Everyone Can Attack: Repurpose Lossy Compression as a Natural Backdoor Attack. (arXiv:2308.16684v1 [cs.CR])\nAbstract: The vulnerabilities to backdoor attacks have recently threatened the trustworthiness of machine learning models in practical applications. Conventional wisdom suggests that not everyone can be an attacker since the process of designing the trigger generation algorithm often involves significant effort and extensive experimentation to ensure the attack's stealthiness and effectiveness. Alternatively, this paper shows that there exists a more severe backdoor threat: anyone can exploit an easily-accessible algorithm for silent backdoor attacks. Specifically, this attacker can employ the widely-used lossy image compression from a plethora of compression tools to effortlessly inject a trigger pattern into an image without leaving any noticeable trace; i.e., the generated triggers are natural artifacts. One does not require extensive knowledge to click on the \"convert\" or \"save as\" button while using tools for lossy image compression. Via this attack, the adversary does not need to design a ",
    "path": "papers/23/08/2308.16684.json",
    "total_tokens": 897,
    "translated_title": "任何人都可以攻击：将有损压缩重新用作自然后门攻击",
    "translated_abstract": "最近，后门攻击对实际应用中的机器学习模型的可信度构成了威胁。传统智慧认为，并不是每个人都可以成为攻击者，因为设计触发器生成算法的过程通常需要大量的努力和广泛的实验来确保攻击的隐秘性和有效性。然而，本文指出存在一种更为严重的后门威胁：任何人都可以利用易获取的算法进行隐悄后门攻击。具体来说，攻击者可以利用各种压缩工具中广泛使用的有损图片压缩技术，无需留下任何明显的痕迹就能轻松地将触发器模式注入到图像中，即生成的触发器是自然的图像伪影。使用有损图片压缩工具时，人们并不需要广泛知识，只需点击“转换”或“另存为”按钮即可。通过这种攻击，攻击者无需设计一个专门的触发器或进行繁琐的调试。",
    "tldr": "本文发现了一种更严重的后门攻击威胁，即任何人都可以利用易获取的有损压缩算法进行自然后门攻击，无需设计特定触发器或进行繁琐调试。"
}