{
    "title": "Breaking the Bank with ChatGPT: Few-Shot Text Classification for Finance. (arXiv:2308.14634v1 [cs.CL])",
    "abstract": "We propose the use of conversational GPT models for easy and quick few-shot text classification in the financial domain using the Banking77 dataset. Our approach involves in-context learning with GPT-3.5 and GPT-4, which minimizes the technical expertise required and eliminates the need for expensive GPU computing while yielding quick and accurate results. Additionally, we fine-tune other pre-trained, masked language models with SetFit, a recent contrastive learning technique, to achieve state-of-the-art results both in full-data and few-shot settings. Our findings show that querying GPT-3.5 and GPT-4 can outperform fine-tuned, non-generative models even with fewer examples. However, subscription fees associated with these solutions may be considered costly for small organizations. Lastly, we find that generative models perform better on the given task when shown representative samples selected by a human expert rather than when shown random ones. We conclude that a) our proposed metho",
    "link": "http://arxiv.org/abs/2308.14634",
    "context": "Title: Breaking the Bank with ChatGPT: Few-Shot Text Classification for Finance. (arXiv:2308.14634v1 [cs.CL])\nAbstract: We propose the use of conversational GPT models for easy and quick few-shot text classification in the financial domain using the Banking77 dataset. Our approach involves in-context learning with GPT-3.5 and GPT-4, which minimizes the technical expertise required and eliminates the need for expensive GPU computing while yielding quick and accurate results. Additionally, we fine-tune other pre-trained, masked language models with SetFit, a recent contrastive learning technique, to achieve state-of-the-art results both in full-data and few-shot settings. Our findings show that querying GPT-3.5 and GPT-4 can outperform fine-tuned, non-generative models even with fewer examples. However, subscription fees associated with these solutions may be considered costly for small organizations. Lastly, we find that generative models perform better on the given task when shown representative samples selected by a human expert rather than when shown random ones. We conclude that a) our proposed metho",
    "path": "papers/23/08/2308.14634.json",
    "total_tokens": 1111,
    "translated_title": "用ChatGPT突破银行：针对金融领域的快速Few-Shot文本分类",
    "translated_abstract": "我们提出使用会话型GPT模型在金融领域使用Banking77数据集进行简单快速的Few-Shot文本分类。我们的方法涉及使用GPT-3.5和GPT-4进行上下文学习，减少了所需的技术专长，并消除了昂贵的GPU计算需求，同时能够快速且准确地得出结果。此外，我们使用最近的对比学习技术SetFit对其他预训练的掩码语言模型进行微调，以在完整数据和few-shot设置下实现最先进的结果。我们的研究结果表明，即使例子更少，查询GPT-3.5和GPT-4也可以胜过微调的非生成模型。然而，这些解决方案所涉及的订阅费用对于小型组织可能被认为昂贵。最后，我们发现，当展示人类专家选择的代表性样本时，生成模型在给定任务上表现更好，而不是展示随机样本。我们得出结论：a)我们提出的方法能够在金融领域实现快速的Few-Shot文本分类，b)使用GPT-3.5和GPT-4进行查询可以胜过微调的非生成模型，c)生成模型在展示代表性样本时表现更佳。",
    "tldr": "使用会话型GPT模型和对比学习技术，我们提出了一种在金融领域进行快速Few-Shot文本分类的方法。与微调的非生成模型相比，查询GPT-3.5和GPT-4能够在样本较少的情况下取得更好的结果。然而，这些解决方案的订阅费用可能对小型组织来说过高。同时，我们发现人类专家选择的代表性样本可以提高生成模型的性能。"
}