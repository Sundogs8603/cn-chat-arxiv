{
    "title": "LGViT: Dynamic Early Exiting for Accelerating Vision Transformer. (arXiv:2308.00255v1 [cs.CV])",
    "abstract": "Recently, the efficient deployment and acceleration of powerful vision transformers (ViTs) on resource-limited edge devices for providing multimedia services have become attractive tasks. Although early exiting is a feasible solution for accelerating inference, most works focus on convolutional neural networks (CNNs) and transformer models in natural language processing (NLP).Moreover, the direct application of early exiting methods to ViTs may result in substantial performance degradation. To tackle this challenge, we systematically investigate the efficacy of early exiting in ViTs and point out that the insufficient feature representations in shallow internal classifiers and the limited ability to capture target semantic information in deep internal classifiers restrict the performance of these methods. We then propose an early exiting framework for general ViTs termed LGViT, which incorporates heterogeneous exiting heads, namely, local perception head and global aggregation head, to",
    "link": "http://arxiv.org/abs/2308.00255",
    "context": "Title: LGViT: Dynamic Early Exiting for Accelerating Vision Transformer. (arXiv:2308.00255v1 [cs.CV])\nAbstract: Recently, the efficient deployment and acceleration of powerful vision transformers (ViTs) on resource-limited edge devices for providing multimedia services have become attractive tasks. Although early exiting is a feasible solution for accelerating inference, most works focus on convolutional neural networks (CNNs) and transformer models in natural language processing (NLP).Moreover, the direct application of early exiting methods to ViTs may result in substantial performance degradation. To tackle this challenge, we systematically investigate the efficacy of early exiting in ViTs and point out that the insufficient feature representations in shallow internal classifiers and the limited ability to capture target semantic information in deep internal classifiers restrict the performance of these methods. We then propose an early exiting framework for general ViTs termed LGViT, which incorporates heterogeneous exiting heads, namely, local perception head and global aggregation head, to",
    "path": "papers/23/08/2308.00255.json",
    "total_tokens": 860,
    "translated_title": "LGViT: 加速视觉Transformer的动态早期退出",
    "translated_abstract": "最近，对于在资源有限的边缘设备上部署和加速强大的视觉Transformer（ViT）以提供多媒体服务的有效方法已成为吸引人的任务。尽管早期退出是加速推理的可行解决方案，但大部分研究专注于卷积神经网络（CNN）和自然语言处理（NLP）中的Transformer模型。此外，直接将早期退出方法应用于ViTs可能导致性能严重下降。为解决这一挑战，我们系统地研究了ViTs中早期退出的有效性，并指出浅层内部分类器中不足的特征表示和深层内部分类器中捕获目标语义信息的能力有限限制了这些方法的性能。然后，我们提出了一个通用ViTs的早期退出框架，称为LGViT，它融合了异构的退出头部，即局部感知头部和全局聚合头部，以更好地提高性能。",
    "tldr": "提出了一种用于加速视觉Transformer的早期退出框架LGViT，通过融合局部感知头部和全局聚合头部，以解决ViTs中早期退出方法应用带来性能严重下降的问题。",
    "en_tdlr": "Proposed a early exiting framework called LGViT for accelerating vision transformers, which incorporates heterogeneous exiting heads, namely local perception head and global aggregation head, to address the performance degradation issue caused by direct application of early exiting methods in ViTs."
}