{
    "title": "A Transformer-based Framework For Multi-variate Time Series: A Remaining Useful Life Prediction Use Case. (arXiv:2308.09884v1 [cs.LG])",
    "abstract": "In recent times, Large Language Models (LLMs) have captured a global spotlight and revolutionized the field of Natural Language Processing. One of the factors attributed to the effectiveness of LLMs is the model architecture used for training, transformers. Transformer models excel at capturing contextual features in sequential data since time series data are sequential, transformer models can be leveraged for more efficient time series data prediction. The field of prognostics is vital to system health management and proper maintenance planning. A reliable estimation of the remaining useful life (RUL) of machines holds the potential for substantial cost savings. This includes avoiding abrupt machine failures, maximizing equipment usage, and serving as a decision support system (DSS). This work proposed an encoder-transformer architecture-based framework for multivariate time series prediction for a prognostics use case. We validated the effectiveness of the proposed framework on all f",
    "link": "http://arxiv.org/abs/2308.09884",
    "context": "Title: A Transformer-based Framework For Multi-variate Time Series: A Remaining Useful Life Prediction Use Case. (arXiv:2308.09884v1 [cs.LG])\nAbstract: In recent times, Large Language Models (LLMs) have captured a global spotlight and revolutionized the field of Natural Language Processing. One of the factors attributed to the effectiveness of LLMs is the model architecture used for training, transformers. Transformer models excel at capturing contextual features in sequential data since time series data are sequential, transformer models can be leveraged for more efficient time series data prediction. The field of prognostics is vital to system health management and proper maintenance planning. A reliable estimation of the remaining useful life (RUL) of machines holds the potential for substantial cost savings. This includes avoiding abrupt machine failures, maximizing equipment usage, and serving as a decision support system (DSS). This work proposed an encoder-transformer architecture-based framework for multivariate time series prediction for a prognostics use case. We validated the effectiveness of the proposed framework on all f",
    "path": "papers/23/08/2308.09884.json",
    "total_tokens": 851,
    "translated_title": "基于Transformer的多元时间序列框架：剩余寿命预测应用案例",
    "translated_abstract": "最近，大型语言模型（LLMs）吸引了全球关注，并彻底改变了自然语言处理领域。LLMs的有效性可归因于其用于训练的模型架构，即transformers。Transformer模型在捕捉顺序数据中的上下文特征方面表现出色，由于时间序列数据是顺序的，可以利用Transformer模型实现更有效的时间序列数据预测。预测学领域对系统健康管理和适当的维护计划至关重要。对机器剩余可用寿命（RUL）进行可靠估计具有节省成本的潜力。这包括避免机器突然故障，最大限度地利用设备，并作为决策支持系统（DSS）。这项工作提出了一种基于编码器-Transformer架构的多元时间序列预测框架，用于预测学应用案例。我们验证了该框架的有效性。",
    "tldr": "这项研究提出了一种基于Transformer的框架，用于多元时间序列预测，以满足预测学应用案例中剩余寿命预测的需求。",
    "en_tdlr": "This research presents a Transformer-based framework for multi-variate time series prediction, catering to the need for remaining useful life prediction in prognostics use cases."
}