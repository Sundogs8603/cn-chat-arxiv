{
    "title": "SamDSK: Combining Segment Anything Model with Domain-Specific Knowledge for Semi-Supervised Learning in Medical Image Segmentation. (arXiv:2308.13759v1 [cs.CV])",
    "abstract": "The Segment Anything Model (SAM) exhibits a capability to segment a wide array of objects in natural images, serving as a versatile perceptual tool for various downstream image segmentation tasks. In contrast, medical image segmentation tasks often rely on domain-specific knowledge (DSK). In this paper, we propose a novel method that combines the segmentation foundation model (i.e., SAM) with domain-specific knowledge for reliable utilization of unlabeled images in building a medical image segmentation model. Our new method is iterative and consists of two main stages: (1) segmentation model training; (2) expanding the labeled set by using the trained segmentation model, an unlabeled set, SAM, and domain-specific knowledge. These two stages are repeated until no more samples are added to the labeled set. A novel optimal-matching-based method is developed for combining the SAM-generated segmentation proposals and pixel-level and image-level DSK for constructing annotations of unlabeled ",
    "link": "http://arxiv.org/abs/2308.13759",
    "context": "Title: SamDSK: Combining Segment Anything Model with Domain-Specific Knowledge for Semi-Supervised Learning in Medical Image Segmentation. (arXiv:2308.13759v1 [cs.CV])\nAbstract: The Segment Anything Model (SAM) exhibits a capability to segment a wide array of objects in natural images, serving as a versatile perceptual tool for various downstream image segmentation tasks. In contrast, medical image segmentation tasks often rely on domain-specific knowledge (DSK). In this paper, we propose a novel method that combines the segmentation foundation model (i.e., SAM) with domain-specific knowledge for reliable utilization of unlabeled images in building a medical image segmentation model. Our new method is iterative and consists of two main stages: (1) segmentation model training; (2) expanding the labeled set by using the trained segmentation model, an unlabeled set, SAM, and domain-specific knowledge. These two stages are repeated until no more samples are added to the labeled set. A novel optimal-matching-based method is developed for combining the SAM-generated segmentation proposals and pixel-level and image-level DSK for constructing annotations of unlabeled ",
    "path": "papers/23/08/2308.13759.json",
    "total_tokens": 1008,
    "translated_title": "SamDSK: 结合分割任意模型和领域特定知识进行医学图像分割的半监督学习",
    "translated_abstract": "分割任意模型（SAM）展示了在自然图像中分割各种对象的能力，是各种下游图像分割任务的多功能感知工具。然而，医学图像分割任务通常依赖于领域特定知识（DSK）。在本文中，我们提出了一种将分割基础模型（即SAM）与领域特定知识相结合的新方法，以可靠地利用无标签图像构建医学图像分割模型。我们的新方法是迭代的，包括两个主要阶段：（1）分割模型训练；（2）使用训练好的分割模型、无标签集、SAM和领域特定知识扩展有标签集。这两个阶段重复进行，直到无法再添加样本到有标签集为止。我们开发了一种基于最优匹配的方法，将SAM生成的分割建议与像素级和图像级的DSK相结合，构建无标签图像的注释。",
    "tldr": "这篇论文介绍了一种新方法SamDSK，结合分割任意模型和领域特定知识，在医学图像分割中进行半监督学习。方法包括迭代的两个阶段：分割模型训练和使用训练好的模型和领域特定知识扩展有标签集。通过将分割建议和领域特定知识结合，构建无标签图像的注释。",
    "en_tdlr": "This paper introduces a new method called SamDSK, which combines Segment Anything Model with domain-specific knowledge for semi-supervised learning in medical image segmentation. The method includes two iterative stages: segmentation model training and expanding the labeled set using the trained model and domain-specific knowledge. By combining segmentation proposals and domain-specific knowledge, annotations of unlabeled images are constructed."
}