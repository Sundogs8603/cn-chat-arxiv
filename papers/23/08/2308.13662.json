{
    "title": "Resource-Efficient Federated Learning for Heterogenous and Resource-Constrained Environments. (arXiv:2308.13662v1 [cs.LG])",
    "abstract": "Federated Learning (FL) is a privacy-enforcing sub-domain of machine learning that brings the model to the user's device for training, avoiding the need to share personal data with a central server. While existing works address data heterogeneity, they overlook other challenges in FL, such as device heterogeneity and communication efficiency. In this paper, we propose RE-FL, a novel approach that tackles computational and communication challenges in resource-constrained devices. Our variable pruning technique optimizes resource utilization by adapting pruning to each client's computational capabilities. We also employ knowledge distillation to reduce bandwidth consumption and communication rounds. Experimental results on image classification tasks demonstrate the effectiveness of our approach in resource-constrained environments, maintaining data privacy and performance while accommodating heterogeneous model architectures.",
    "link": "http://arxiv.org/abs/2308.13662",
    "context": "Title: Resource-Efficient Federated Learning for Heterogenous and Resource-Constrained Environments. (arXiv:2308.13662v1 [cs.LG])\nAbstract: Federated Learning (FL) is a privacy-enforcing sub-domain of machine learning that brings the model to the user's device for training, avoiding the need to share personal data with a central server. While existing works address data heterogeneity, they overlook other challenges in FL, such as device heterogeneity and communication efficiency. In this paper, we propose RE-FL, a novel approach that tackles computational and communication challenges in resource-constrained devices. Our variable pruning technique optimizes resource utilization by adapting pruning to each client's computational capabilities. We also employ knowledge distillation to reduce bandwidth consumption and communication rounds. Experimental results on image classification tasks demonstrate the effectiveness of our approach in resource-constrained environments, maintaining data privacy and performance while accommodating heterogeneous model architectures.",
    "path": "papers/23/08/2308.13662.json",
    "total_tokens": 840,
    "translated_title": "异构和资源受限环境中的资源高效联邦学习",
    "translated_abstract": "联邦学习 (FL) 是机器学习中的一种保护隐私的子领域，它将模型带到用户设备进行训练，避免了与中央服务器共享个人数据的需求。虽然现有的工作解决了数据异质性，但忽视了FL中的其他挑战，如设备异质性和通信效率。在本文中，我们提出了RE-FL，这是一种面向资源受限设备的新方法，解决了计算和通信挑战。我们的可变剪枝技术通过根据每个客户端的计算能力进行剪枝优化资源利用。我们还采用知识蒸馏来减少带宽消耗和通信轮数。图像分类任务的实验结果证明了我们的方法在资源受限环境中的有效性，同时满足异构模型架构的数据隐私和性能需求。",
    "tldr": "提出了一种新的资源高效联邦学习方法，通过可变剪枝技术和知识蒸馏来解决资源受限设备中的计算和通信挑战，并在保持数据隐私和性能的同时适应异构模型架构。"
}