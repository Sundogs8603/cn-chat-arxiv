{
    "title": "Surrogate-based Autotuning for Randomized Sketching Algorithms in Regression Problems. (arXiv:2308.15720v1 [cs.LG])",
    "abstract": "Algorithms from Randomized Numerical Linear Algebra (RandNLA) are known to be effective in handling high-dimensional computational problems, providing high-quality empirical performance as well as strong probabilistic guarantees. However, their practical application is complicated by the fact that the user needs to set various algorithm-specific tuning parameters which are different than those used in traditional NLA. This paper demonstrates how a surrogate-based autotuning approach can be used to address fundamental problems of parameter selection in RandNLA algorithms. In particular, we provide a detailed investigation of surrogate-based autotuning for sketch-and-precondition (SAP) based randomized least squares methods, which have been one of the great success stories in modern RandNLA. Empirical results show that our surrogate-based autotuning approach can achieve near-optimal performance with much less tuning cost than a random search (up to about 4x fewer trials of different para",
    "link": "http://arxiv.org/abs/2308.15720",
    "context": "Title: Surrogate-based Autotuning for Randomized Sketching Algorithms in Regression Problems. (arXiv:2308.15720v1 [cs.LG])\nAbstract: Algorithms from Randomized Numerical Linear Algebra (RandNLA) are known to be effective in handling high-dimensional computational problems, providing high-quality empirical performance as well as strong probabilistic guarantees. However, their practical application is complicated by the fact that the user needs to set various algorithm-specific tuning parameters which are different than those used in traditional NLA. This paper demonstrates how a surrogate-based autotuning approach can be used to address fundamental problems of parameter selection in RandNLA algorithms. In particular, we provide a detailed investigation of surrogate-based autotuning for sketch-and-precondition (SAP) based randomized least squares methods, which have been one of the great success stories in modern RandNLA. Empirical results show that our surrogate-based autotuning approach can achieve near-optimal performance with much less tuning cost than a random search (up to about 4x fewer trials of different para",
    "path": "papers/23/08/2308.15720.json",
    "total_tokens": 847,
    "translated_title": "基于替代模型的自动调优方法在回归问题中随机化草图算法的应用",
    "translated_abstract": "从随机数值线性代数(RandNLA)中提出的算法在处理高维计算问题方面表现出很好的效果，提供高质量的经验性能以及强大的概率保证。然而，它们的实际应用受到一个问题的复杂性所限制，即用户需要设置各种不同于传统NLA中使用的算法特定调参参数。本文展示了如何使用基于替代模型的自动调优方法来解决RandNLA算法中参数选择的基础性问题。具体而言，我们对基于草图和预处理(SAP)的随机化最小二乘方法进行了替代模型自动调优的详细研究，这在现代RandNLA中是一个巨大的成功案例。实证结果表明，我们的基于替代模型的自动调优方法可以以比随机搜索少约4倍的试验成本实现接近最优的性能。",
    "tldr": "本文介绍了如何使用基于替代模型的自动调优方法解决随机化草图算法中的参数选择问题，在随机数值线性代数中取得了接近最优性能的实证结果。",
    "en_tdlr": "This paper demonstrates how surrogate-based autotuning can address the problem of parameter selection in randomized sketching algorithms, achieving near-optimal performance in randomized numerical linear algebra."
}