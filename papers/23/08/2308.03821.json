{
    "title": "Distributionally Robust Classification on a Data Budget. (arXiv:2308.03821v1 [cs.CV])",
    "abstract": "Real world uses of deep learning require predictable model behavior under distribution shifts. Models such as CLIP show emergent natural distributional robustness comparable to humans, but may require hundreds of millions of training samples. Can we train robust learners in a domain where data is limited? To rigorously address this question, we introduce JANuS (Joint Annotations and Names Set), a collection of four new training datasets with images, labels, and corresponding captions, and perform a series of carefully controlled investigations of factors contributing to robustness in image classification, then compare those results to findings derived from a large-scale meta-analysis. Using this approach, we show that standard ResNet-50 trained with the cross-entropy loss on 2.4 million image samples can attain comparable robustness to a CLIP ResNet-50 trained on 400 million samples. To our knowledge, this is the first result showing (near) state-of-the-art distributional robustness on",
    "link": "http://arxiv.org/abs/2308.03821",
    "context": "Title: Distributionally Robust Classification on a Data Budget. (arXiv:2308.03821v1 [cs.CV])\nAbstract: Real world uses of deep learning require predictable model behavior under distribution shifts. Models such as CLIP show emergent natural distributional robustness comparable to humans, but may require hundreds of millions of training samples. Can we train robust learners in a domain where data is limited? To rigorously address this question, we introduce JANuS (Joint Annotations and Names Set), a collection of four new training datasets with images, labels, and corresponding captions, and perform a series of carefully controlled investigations of factors contributing to robustness in image classification, then compare those results to findings derived from a large-scale meta-analysis. Using this approach, we show that standard ResNet-50 trained with the cross-entropy loss on 2.4 million image samples can attain comparable robustness to a CLIP ResNet-50 trained on 400 million samples. To our knowledge, this is the first result showing (near) state-of-the-art distributional robustness on",
    "path": "papers/23/08/2308.03821.json",
    "total_tokens": 952,
    "translated_title": "基于数据预算的分布鲁棒分类",
    "translated_abstract": "深度学习在现实世界的应用中需要在分布转变下具有可预测的模型行为。像CLIP这样的模型展现出了与人类相媲美的自然分布鲁棒性，但可能需要数亿个训练样本。我们能否在数据有限的领域训练鲁棒的学习者？为了严格回答这个问题，我们引入了JANuS（联合注释和名称集），这是一个包含图像、标签和相应标题的四个新训练数据集，然后通过一系列精心控制的调查研究了影响图像分类鲁棒性的因素，并将这些结果与大规模元分析的发现进行了比较。通过这种方法，我们证明了在240万个图像样本的交叉熵损失上训练的标准ResNet-50可以达到与在4亿个样本上训练的CLIP ResNet-50相媲美的鲁棒性。据我们所知，这是首次展示（接近）最先进的分布鲁棒性的结果。",
    "tldr": "本研究介绍了一种基于数据预算的分布鲁棒分类方法，在有限的数据情况下，通过精心设计的训练集和控制实验，证明了在240万个图像样本上的训练可以获得与在4亿个图像样本上训练相媲美的鲁棒性。",
    "en_tdlr": "This research presents a distributionally robust classification method based on a data budget, showing that comparable robustness can be achieved with limited data through carefully designed training datasets and controlled experiments. The study demonstrates that training on 2.4 million image samples can attain similar robustness to training on 400 million samples."
}