{
    "title": "Context-Aware Planning and Environment-Aware Memory for Instruction Following Embodied Agents. (arXiv:2308.07241v2 [cs.RO] UPDATED)",
    "abstract": "Accomplishing household tasks such as 'bringing a cup of water' requires planning step-by-step actions by maintaining knowledge about the spatial arrangement of objects and the consequences of previous actions. Perception models of the current embodied AI agents, however, often make mistakes due to a lack of such knowledge but rely on imperfect learning of imitating agents or an algorithmic planner without knowledge about the changed environment by the previous actions. To address the issue, we propose CPEM (Context-aware Planner and Environment-aware Memory) to incorporate the contextual information of previous actions for planning and maintaining spatial arrangement of objects with their states (e.g., if an object has been moved or not) in an environment to the perception model for improving both visual navigation and object interaction. We observe that CPEM achieves state-of-the-art task success performance in various metrics using a challenging interactive instruction following ben",
    "link": "http://arxiv.org/abs/2308.07241",
    "context": "Title: Context-Aware Planning and Environment-Aware Memory for Instruction Following Embodied Agents. (arXiv:2308.07241v2 [cs.RO] UPDATED)\nAbstract: Accomplishing household tasks such as 'bringing a cup of water' requires planning step-by-step actions by maintaining knowledge about the spatial arrangement of objects and the consequences of previous actions. Perception models of the current embodied AI agents, however, often make mistakes due to a lack of such knowledge but rely on imperfect learning of imitating agents or an algorithmic planner without knowledge about the changed environment by the previous actions. To address the issue, we propose CPEM (Context-aware Planner and Environment-aware Memory) to incorporate the contextual information of previous actions for planning and maintaining spatial arrangement of objects with their states (e.g., if an object has been moved or not) in an environment to the perception model for improving both visual navigation and object interaction. We observe that CPEM achieves state-of-the-art task success performance in various metrics using a challenging interactive instruction following ben",
    "path": "papers/23/08/2308.07241.json",
    "total_tokens": 836,
    "translated_title": "具有环境感知记忆的上下文感知规划用于指导行为智能体",
    "translated_abstract": "完成家务任务（例如“拿一杯水”）需要通过保持对空间对象的空间布局和先前行动的结果的知识来进行逐步的规划。然而，当前的行为智能体在感知模型方面经常出错，因为缺乏这种知识，而依赖于不完美的学习的模仿智能体或者没有关于先前行动对环境变化的知识的算法规划器。为了解决这个问题，我们提出了CPEM（上下文感知规划器和环境感知记忆），将先前行动的上下文信息与环境中物体的空间布局和状态（例如物体是否被移动）结合到感知模型中，以改进视觉导航和物体交互。我们观察到，CPEM在各种度量指标上实现了最先进的任务成功性能。",
    "tldr": "这项研究提出了一种称为CPEM的系统，它利用上下文信息和环境感知记忆来改进行为智能体的感知能力，从而提高视觉导航和物体交互的效果。"
}