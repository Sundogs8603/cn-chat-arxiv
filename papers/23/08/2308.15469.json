{
    "title": "Multimodal Contrastive Learning and Tabular Attention for Automated Alzheimer's Disease Prediction. (arXiv:2308.15469v1 [cs.CV])",
    "abstract": "Alongside neuroimaging such as MRI scans and PET, Alzheimer's disease (AD) datasets contain valuable tabular data including AD biomarkers and clinical assessments. Existing computer vision approaches struggle to utilize this additional information. To address these needs, we propose a generalizable framework for multimodal contrastive learning of image data and tabular data, a novel tabular attention module for amplifying and ranking salient features in tables, and the application of these techniques onto Alzheimer's disease prediction. Experimental evaulations demonstrate the strength of our framework by detecting Alzheimer's disease (AD) from over 882 MR image slices from the ADNI database. We take advantage of the high interpretability of tabular data and our novel tabular attention approach and through attribution of the attention scores for each row of the table, we note and rank the most predominant features. Results show that the model is capable of an accuracy of over 83.8%, al",
    "link": "http://arxiv.org/abs/2308.15469",
    "context": "Title: Multimodal Contrastive Learning and Tabular Attention for Automated Alzheimer's Disease Prediction. (arXiv:2308.15469v1 [cs.CV])\nAbstract: Alongside neuroimaging such as MRI scans and PET, Alzheimer's disease (AD) datasets contain valuable tabular data including AD biomarkers and clinical assessments. Existing computer vision approaches struggle to utilize this additional information. To address these needs, we propose a generalizable framework for multimodal contrastive learning of image data and tabular data, a novel tabular attention module for amplifying and ranking salient features in tables, and the application of these techniques onto Alzheimer's disease prediction. Experimental evaulations demonstrate the strength of our framework by detecting Alzheimer's disease (AD) from over 882 MR image slices from the ADNI database. We take advantage of the high interpretability of tabular data and our novel tabular attention approach and through attribution of the attention scores for each row of the table, we note and rank the most predominant features. Results show that the model is capable of an accuracy of over 83.8%, al",
    "path": "papers/23/08/2308.15469.json",
    "total_tokens": 973,
    "translated_title": "多模态对比学习和表格注意力在自动化阿尔茨海默病预测中的应用",
    "translated_abstract": "随着神经影像学数据如MRI扫描和PET，阿尔茨海默病（AD）数据集中还包含有价值的表格数据，包括AD生物标志物和临床评估。现有的计算机视觉方法难以利用这些额外信息。为了满足这些需求，我们提出了一个多模态对比学习图像数据和表格数据的通用框架，一种用于放大和排序表格中显著特征的新颖表格注意力模块，并将这些技术应用于阿尔茨海默病预测。实验评估通过从ADNI数据库中的882个MR图像切片中检测阿尔茨海默病（AD）来展示我们框架的优势。我们利用表格数据的高可解释性和我们的新颖表格注意力方法，通过对每行的注意力分数进行归因，我们可以确定并排名最主要的特征。结果显示，该模型能够达到超过83.8%的准确率。",
    "tldr": "本论文提出了一个多模态对比学习的通用框架，结合了图像数据和表格数据，设计了一种新颖的表格注意力模块，并将这些技术应用于阿尔茨海默病的预测。实验证明了该框架的优势，并展示了其在阿尔茨海默病检测方面的高准确率。"
}