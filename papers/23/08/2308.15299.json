{
    "title": "TaskLAMA: Probing the Complex Task Understanding of Language Models. (arXiv:2308.15299v1 [cs.CL])",
    "abstract": "Structured Complex Task Decomposition (SCTD) is the problem of breaking down a complex real-world task (such as planning a wedding) into a directed acyclic graph over individual steps that contribute to achieving the task, with edges specifying temporal dependencies between them. SCTD is an important component of assistive planning tools, and a challenge for commonsense reasoning systems. We probe how accurately SCTD can be done with the knowledge extracted from Large Language Models (LLMs). We introduce a high-quality human-annotated dataset for this problem and novel metrics to fairly assess performance of LLMs against several baselines. Our experiments reveal that LLMs are able to decompose complex tasks into individual steps effectively, with a relative improvement of 15% to 280% over the best baseline. We also propose a number of approaches to further improve their performance, with a relative improvement of 7% to 37% over the base model. However, we find that LLMs still struggle ",
    "link": "http://arxiv.org/abs/2308.15299",
    "context": "Title: TaskLAMA: Probing the Complex Task Understanding of Language Models. (arXiv:2308.15299v1 [cs.CL])\nAbstract: Structured Complex Task Decomposition (SCTD) is the problem of breaking down a complex real-world task (such as planning a wedding) into a directed acyclic graph over individual steps that contribute to achieving the task, with edges specifying temporal dependencies between them. SCTD is an important component of assistive planning tools, and a challenge for commonsense reasoning systems. We probe how accurately SCTD can be done with the knowledge extracted from Large Language Models (LLMs). We introduce a high-quality human-annotated dataset for this problem and novel metrics to fairly assess performance of LLMs against several baselines. Our experiments reveal that LLMs are able to decompose complex tasks into individual steps effectively, with a relative improvement of 15% to 280% over the best baseline. We also propose a number of approaches to further improve their performance, with a relative improvement of 7% to 37% over the base model. However, we find that LLMs still struggle ",
    "path": "papers/23/08/2308.15299.json",
    "total_tokens": 922,
    "translated_title": "TaskLAMA: 探究语言模型对复杂任务理解的能力",
    "translated_abstract": "结构化复杂任务分解（SCTD）是将复杂的现实世界任务（如策划婚礼）分解为有向无环图，图中的每个步骤都是为完成任务做出贡献的，边表示它们之间的时序依赖关系。SCTD是辅助规划工具的重要组成部分，也是常识推理系统所面临的挑战。我们探索了从大型语言模型（LLMs）提取的知识能够准确地进行SCTD的程度。我们为这个问题引入了一个高质量的人工标注数据集，并使用新的指标来公平评估LLMs相对于几个基准的性能。我们的实验揭示了LLMs能够有效地将复杂任务分解为个别步骤，相对于最佳基准方法可以提升15%到280%。我们还提出了一些进一步提升性能的方法，相对于基线模型可以提升7%到37%。然而，我们发现LLMs仍然面临困难。",
    "tldr": "TaskLAMA论文研究了语言模型对复杂任务理解的能力，使用人工标注数据集和新的评估指标，实验证明LLMs能够有效地将复杂任务分解为个别步骤，并提出了进一步提升性能的方法。",
    "en_tdlr": "TaskLAMA investigates the task understanding capability of language models, with experiments demonstrating that large language models (LLMs) can effectively decompose complex tasks into individual steps and propose approaches to improve their performance."
}