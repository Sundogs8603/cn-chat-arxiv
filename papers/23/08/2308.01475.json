{
    "title": "Interpretable Machine Learning for Discovery: Statistical Challenges \\& Opportunities. (arXiv:2308.01475v1 [stat.ML])",
    "abstract": "New technologies have led to vast troves of large and complex datasets across many scientific domains and industries. People routinely use machine learning techniques to not only process, visualize, and make predictions from this big data, but also to make data-driven discoveries. These discoveries are often made using Interpretable Machine Learning, or machine learning models and techniques that yield human understandable insights. In this paper, we discuss and review the field of interpretable machine learning, focusing especially on the techniques as they are often employed to generate new knowledge or make discoveries from large data sets. We outline the types of discoveries that can be made using Interpretable Machine Learning in both supervised and unsupervised settings. Additionally, we focus on the grand challenge of how to validate these discoveries in a data-driven manner, which promotes trust in machine learning systems and reproducibility in science. We discuss validation f",
    "link": "http://arxiv.org/abs/2308.01475",
    "context": "Title: Interpretable Machine Learning for Discovery: Statistical Challenges \\& Opportunities. (arXiv:2308.01475v1 [stat.ML])\nAbstract: New technologies have led to vast troves of large and complex datasets across many scientific domains and industries. People routinely use machine learning techniques to not only process, visualize, and make predictions from this big data, but also to make data-driven discoveries. These discoveries are often made using Interpretable Machine Learning, or machine learning models and techniques that yield human understandable insights. In this paper, we discuss and review the field of interpretable machine learning, focusing especially on the techniques as they are often employed to generate new knowledge or make discoveries from large data sets. We outline the types of discoveries that can be made using Interpretable Machine Learning in both supervised and unsupervised settings. Additionally, we focus on the grand challenge of how to validate these discoveries in a data-driven manner, which promotes trust in machine learning systems and reproducibility in science. We discuss validation f",
    "path": "papers/23/08/2308.01475.json",
    "total_tokens": 801,
    "translated_title": "可解释的机器学习用于发现：统计挑战和机遇",
    "translated_abstract": "新技术导致了许多科学领域和行业的庞大、复杂的数据集。人们经常使用机器学习技术来处理、可视化和预测这些大数据，并通过可解释的机器学习模型和技术来进行数据驱动的发现。本文讨论和回顾了可解释的机器学习领域，特别关注这些技术在从大数据集中生成新知识或进行发现时的应用。我们概述了可解释的机器学习在监督和无监督场景下可以实现的发现类型。此外，我们重点讨论了如何以数据驱动的方式验证这些发现，以促进对机器学习系统的信任和科学中的可重复性。我们讨论了验证的挑战。",
    "tldr": "可解释的机器学习技术被广泛用于处理大数据集、可视化预测和数据驱动的发现，该论文回顾了这一领域并探讨了验证发现的挑战。"
}