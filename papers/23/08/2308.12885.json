{
    "title": "Collect, Measure, Repeat: Reliability Factors for Responsible AI Data Collection. (arXiv:2308.12885v1 [cs.LG])",
    "abstract": "The rapid entry of machine learning approaches in our daily activities and high-stakes domains demands transparency and scrutiny of their fairness and reliability. To help gauge machine learning models' robustness, research typically focuses on the massive datasets used for their deployment, e.g., creating and maintaining documentation for understanding their origin, process of development, and ethical considerations. However, data collection for AI is still typically a one-off practice, and oftentimes datasets collected for a certain purpose or application are reused for a different problem. Additionally, dataset annotations may not be representative over time, contain ambiguous or erroneous annotations, or be unable to generalize across issues or domains. Recent research has shown these practices might lead to unfair, biased, or inaccurate outcomes. We argue that data collection for AI should be performed in a responsible manner where the quality of the data is thoroughly scrutinized",
    "link": "http://arxiv.org/abs/2308.12885",
    "context": "Title: Collect, Measure, Repeat: Reliability Factors for Responsible AI Data Collection. (arXiv:2308.12885v1 [cs.LG])\nAbstract: The rapid entry of machine learning approaches in our daily activities and high-stakes domains demands transparency and scrutiny of their fairness and reliability. To help gauge machine learning models' robustness, research typically focuses on the massive datasets used for their deployment, e.g., creating and maintaining documentation for understanding their origin, process of development, and ethical considerations. However, data collection for AI is still typically a one-off practice, and oftentimes datasets collected for a certain purpose or application are reused for a different problem. Additionally, dataset annotations may not be representative over time, contain ambiguous or erroneous annotations, or be unable to generalize across issues or domains. Recent research has shown these practices might lead to unfair, biased, or inaccurate outcomes. We argue that data collection for AI should be performed in a responsible manner where the quality of the data is thoroughly scrutinized",
    "path": "papers/23/08/2308.12885.json",
    "total_tokens": 814,
    "translated_title": "收集，测量，重复：负责任的AI数据收集的可靠性因素",
    "translated_abstract": "机器学习方法迅速进入我们的日常活动和高风险领域，要求对其公平性和可靠性进行透明和审查。为了评估机器学习模型的健壮性，研究通常会集中在其部署所使用的大规模数据集上，例如创建和维护文件以了解其来源、开发过程和伦理考虑。然而，AI的数据收集通常仍然是一次性的实践，而且经常为特定目的或应用程序收集的数据集会被重复用于其他问题。此外，数据集的注释可能随时间不具有代表性，包含模糊或错误的注释，或者无法跨问题或领域进行泛化。最近的研究表明，这些做法可能导致不公平、偏见或不准确的结果。我们认为，AI的数据收集应该以负责任的方式进行，对数据的质量进行彻底的审查。",
    "tldr": "对于负责任的AI数据收集，需要对数据的质量进行彻底的审查，避免不公平、偏见或不准确的结果。",
    "en_tdlr": "Responsible AI data collection requires thorough scrutiny of data quality to avoid unfair, biased, or inaccurate outcomes."
}