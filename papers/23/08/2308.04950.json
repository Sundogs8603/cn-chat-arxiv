{
    "title": "Performance Analysis of Transformer Based Models (BERT, ALBERT and RoBERTa) in Fake News Detection. (arXiv:2308.04950v1 [cs.CL])",
    "abstract": "Fake news is fake material in a news media format but is not processed properly by news agencies. The fake material can provoke or defame significant entities or individuals or potentially even for the personal interests of the creators, causing problems for society. Distinguishing fake news and real news is challenging due to limited of domain knowledge and time constraints. According to the survey, the top three areas most exposed to hoaxes and misinformation by residents are in Banten, DKI Jakarta and West Java. The model of transformers is referring to an approach in the field of artificial intelligence (AI) in natural language processing utilizing the deep learning architectures. Transformers exercise a powerful attention mechanism to process text in parallel and produce rich and contextual word representations. A previous study indicates a superior performance of a transformer model known as BERT over and above non transformer approach. However, some studies suggest the performan",
    "link": "http://arxiv.org/abs/2308.04950",
    "context": "Title: Performance Analysis of Transformer Based Models (BERT, ALBERT and RoBERTa) in Fake News Detection. (arXiv:2308.04950v1 [cs.CL])\nAbstract: Fake news is fake material in a news media format but is not processed properly by news agencies. The fake material can provoke or defame significant entities or individuals or potentially even for the personal interests of the creators, causing problems for society. Distinguishing fake news and real news is challenging due to limited of domain knowledge and time constraints. According to the survey, the top three areas most exposed to hoaxes and misinformation by residents are in Banten, DKI Jakarta and West Java. The model of transformers is referring to an approach in the field of artificial intelligence (AI) in natural language processing utilizing the deep learning architectures. Transformers exercise a powerful attention mechanism to process text in parallel and produce rich and contextual word representations. A previous study indicates a superior performance of a transformer model known as BERT over and above non transformer approach. However, some studies suggest the performan",
    "path": "papers/23/08/2308.04950.json",
    "total_tokens": 924,
    "translated_title": "基于Transformer模型（BERT，ALBERT和RoBERTa）在假新闻检测中的性能分析",
    "translated_abstract": "假新闻是一种媒体格式的虚假材料，但没有经过新闻机构的适当处理。这些虚假材料可能会激起或诽谤重要实体或个人，甚至可能是创作者的个人利益，给社会带来问题。由于领域知识有限和时间限制，区分假新闻和真新闻是具有挑战性的。根据调查，受到谣言和信息误导的三个地区最多的是万丹特区、雅加达特区和西爪哇。Transformer模型是指在自然语言处理中利用深度学习架构的一种人工智能（AI）方法。Transformer模型通过强大的注意机制并行处理文本，并生成丰富和上下文相关的词表示。先前的研究表明，一种名为BERT的Transformer模型在性能上优于非Transformer方法。然而，一些研究表明性能评估和结bonclusion的实现方法之间可能存在一定的差异。",
    "tldr": "该论文分析了基于Transformer模型的BERT、ALBERT和RoBERTa在假新闻检测中的性能。研究发现，Transformer模型（特别是BERT）在处理文本上表现优异，但不同研究对性能评估和结论的实现方法存在差异。",
    "en_tdlr": "This paper analyzes the performance of transformer models (BERT, ALBERT, and RoBERTa) in fake news detection. The study finds that transformer models, particularly BERT, perform well in processing text, but there are differences in how performance evaluation and conclusions are implemented in different studies."
}