{
    "title": "What can we learn from quantum convolutional neural networks?. (arXiv:2308.16664v1 [quant-ph])",
    "abstract": "We can learn from analyzing quantum convolutional neural networks (QCNNs) that: 1) working with quantum data can be perceived as embedding physical system parameters through a hidden feature map; 2) their high performance for quantum phase recognition can be attributed to generation of a very suitable basis set during the ground state embedding, where quantum criticality of spin models leads to basis functions with rapidly changing features; 3) pooling layers of QCNNs are responsible for picking those basis functions that can contribute to forming a high-performing decision boundary, and the learning process corresponds to adapting the measurement such that few-qubit operators are mapped to full-register observables; 4) generalization of QCNN models strongly depends on the embedding type, and that rotation-based feature maps with the Fourier basis require careful feature engineering; 5) accuracy and generalization of QCNNs with readout based on a limited number of shots favor the groun",
    "link": "http://arxiv.org/abs/2308.16664",
    "context": "Title: What can we learn from quantum convolutional neural networks?. (arXiv:2308.16664v1 [quant-ph])\nAbstract: We can learn from analyzing quantum convolutional neural networks (QCNNs) that: 1) working with quantum data can be perceived as embedding physical system parameters through a hidden feature map; 2) their high performance for quantum phase recognition can be attributed to generation of a very suitable basis set during the ground state embedding, where quantum criticality of spin models leads to basis functions with rapidly changing features; 3) pooling layers of QCNNs are responsible for picking those basis functions that can contribute to forming a high-performing decision boundary, and the learning process corresponds to adapting the measurement such that few-qubit operators are mapped to full-register observables; 4) generalization of QCNN models strongly depends on the embedding type, and that rotation-based feature maps with the Fourier basis require careful feature engineering; 5) accuracy and generalization of QCNNs with readout based on a limited number of shots favor the groun",
    "path": "papers/23/08/2308.16664.json",
    "total_tokens": 946,
    "translated_title": "我们可以从量子卷积神经网络中学到什么？",
    "translated_abstract": "通过分析量子卷积神经网络（QCNNs），我们可以得出以下结论：1）通过隐藏特征映射，工作于量子数据可以被视为嵌入物理系统参数；2）对于量子相位识别，其高性能可以归因于在基态嵌入期间生成非常适合的基函数集，其中自旋模型的量子临界性导致具有快速变化特征的基函数；3）QCNN的池化层负责选择那些能够有助于形成高性能决策边界的基函数，学习过程对应于适应性测量，使得少量量子比特算符映射到整个寄存器可观测量；4）QCNN模型的泛化强烈依赖于嵌入类型，基于傅里叶基的旋转特征映射需要仔细的特征工程；5）基于有限数量的测量次数的读出的QCNN的准确性和泛化能力倾向于地面态。",
    "tldr": "通过分析量子卷积神经网络（QCNNs），我们发现它们通过隐藏特征映射嵌入物理系统参数，并且利用量子临界性生成适合的基函数集，池化层选择能够形成高性能决策边界的基函数，而模型的泛化性能依赖于嵌入类型。"
}