{
    "title": "Automated Distractor and Feedback Generation for Math Multiple-choice Questions via In-context Learning. (arXiv:2308.03234v2 [cs.CL] UPDATED)",
    "abstract": "Multiple-choice questions (MCQs) are ubiquitous in almost all levels of education since they are easy to administer, grade, and are a reliable form of assessment. An important aspect of MCQs is the distractors, i.e., incorrect options that are designed to target specific misconceptions or insufficient knowledge among students. To date, the task of crafting high-quality distractors has largely remained a labor-intensive process for teachers and learning content designers, which has limited scalability. In this work, we explore the task of automated distractor and corresponding feedback message generation in math MCQs using large language models. We establish a formulation of these two tasks and propose a simple, in-context learning-based solution. Moreover, we propose generative AI-based metrics for evaluating the quality of the feedback messages. We conduct extensive experiments on these tasks using a real-world MCQ dataset. Our findings suggest that there is a lot of room for improvem",
    "link": "http://arxiv.org/abs/2308.03234",
    "context": "Title: Automated Distractor and Feedback Generation for Math Multiple-choice Questions via In-context Learning. (arXiv:2308.03234v2 [cs.CL] UPDATED)\nAbstract: Multiple-choice questions (MCQs) are ubiquitous in almost all levels of education since they are easy to administer, grade, and are a reliable form of assessment. An important aspect of MCQs is the distractors, i.e., incorrect options that are designed to target specific misconceptions or insufficient knowledge among students. To date, the task of crafting high-quality distractors has largely remained a labor-intensive process for teachers and learning content designers, which has limited scalability. In this work, we explore the task of automated distractor and corresponding feedback message generation in math MCQs using large language models. We establish a formulation of these two tasks and propose a simple, in-context learning-based solution. Moreover, we propose generative AI-based metrics for evaluating the quality of the feedback messages. We conduct extensive experiments on these tasks using a real-world MCQ dataset. Our findings suggest that there is a lot of room for improvem",
    "path": "papers/23/08/2308.03234.json",
    "total_tokens": 928,
    "translated_title": "通过上下文学习自动生成数学多项选择题的错误选项和反馈信息",
    "translated_abstract": "多项选择题在几乎所有教育层次中都广泛使用，因为它们易于管理、评分，并且是一种可靠的评估形式。其中的关键是错误选项，即被设计来针对学生特定误解或知识不足的不正确选项。迄今为止，高质量错误选项的设计一直是教师和学习内容设计者的劳动密集型过程，限制了可扩展性。本研究探讨了使用大型语言模型在数学多项选择题中自动生成错误选项和相应反馈信息的任务。我们建立了这两个任务的公式，并提出了一种简单的基于上下文学习的解决方案。此外，我们提出了基于生成型人工智能的度量标准来评估反馈信息的质量。我们使用一个真实的多项选择题数据集对这些任务进行了大量实验。我们的研究结果表明，在这些任务中有很大的改进空间。",
    "tldr": "本论文研究了使用大型语言模型在数学多项选择题中自动生成错误选项和反馈信息的任务，提出了一种简单的解决方案，并使用基于生成型人工智能的度量标准评估了反馈信息质量。实验结果表明有很大的改进空间。",
    "en_tdlr": "This paper investigates the task of automated distractor and feedback message generation in math multiple-choice questions using large language models. It proposes a simple solution based on in-context learning and introduces generative AI-based metrics to evaluate the quality of feedback messages. The experimental results suggest that there is significant room for improvement."
}