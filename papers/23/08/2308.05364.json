{
    "title": "Machine Learning aided Computer Architecture Design for CNN Inferencing Systems. (arXiv:2308.05364v1 [cs.AR])",
    "abstract": "Efficient and timely calculations of Machine Learning (ML) algorithms are essential for emerging technologies like autonomous driving, the Internet of Things (IoT), and edge computing. One of the primary ML algorithms used in such systems is Convolutional Neural Networks (CNNs), which demand high computational resources. This requirement has led to the use of ML accelerators like GPGPUs to meet design constraints. However, selecting the most suitable accelerator involves Design Space Exploration (DSE), a process that is usually time-consuming and requires significant manual effort. Our work presents approaches to expedite the DSE process by identifying the most appropriate GPGPU for CNN inferencing systems. We have developed a quick and precise technique for forecasting the power and performance of CNNs during inference, with a MAPE of 5.03% and 5.94%, respectively. Our approach empowers computer architects to estimate power and performance in the early stages of development, reducing ",
    "link": "http://arxiv.org/abs/2308.05364",
    "context": "Title: Machine Learning aided Computer Architecture Design for CNN Inferencing Systems. (arXiv:2308.05364v1 [cs.AR])\nAbstract: Efficient and timely calculations of Machine Learning (ML) algorithms are essential for emerging technologies like autonomous driving, the Internet of Things (IoT), and edge computing. One of the primary ML algorithms used in such systems is Convolutional Neural Networks (CNNs), which demand high computational resources. This requirement has led to the use of ML accelerators like GPGPUs to meet design constraints. However, selecting the most suitable accelerator involves Design Space Exploration (DSE), a process that is usually time-consuming and requires significant manual effort. Our work presents approaches to expedite the DSE process by identifying the most appropriate GPGPU for CNN inferencing systems. We have developed a quick and precise technique for forecasting the power and performance of CNNs during inference, with a MAPE of 5.03% and 5.94%, respectively. Our approach empowers computer architects to estimate power and performance in the early stages of development, reducing ",
    "path": "papers/23/08/2308.05364.json",
    "total_tokens": 930,
    "translated_title": "机器学习辅助的卷积神经网络推理系统的计算机架构设计",
    "translated_abstract": "高效和及时计算机器学习（ML）算法对于自动驾驶、物联网（IoT）和边缘计算等新兴技术至关重要。这些系统中使用的主要ML算法之一是卷积神经网络（CNN），它需要高计算资源。为了满足设计约束，人们使用ML加速器如GPGPUs。然而，选择最合适的加速器通常涉及设计空间探索（DSE），这是一个耗时且需要大量手工努力的过程。我们的工作提出了一种加快DSE过程的方法，通过识别最适合CNN推理系统的GPGPU。我们开发了一种快速准确的技术，用于推理过程中的CNN功耗和性能预测，MAPE分别为5.03%和5.94%。我们的方法使计算机架构师能够在开发的早期估计功耗和性能，从而减少开发周期。",
    "tldr": "本研究提出了一种机器学习辅助的计算机架构设计方法，用于加快卷积神经网络推理系统的设计过程。通过快速而准确地预测CNN在推理过程中的功耗和性能，帮助计算机架构师在早期阶段进行估计，从而减少开发周期。",
    "en_tdlr": "This study proposes a machine learning aided computer architecture design method to expedite the design process of convolutional neural network inference systems. By quickly and accurately predicting the power and performance of CNN during inference, it helps computer architects estimate in the early stages and reduces the development cycle."
}