{
    "title": "From Hope to Safety: Unlearning Biases of Deep Models by Enforcing the Right Reasons in Latent Space. (arXiv:2308.09437v2 [cs.LG] UPDATED)",
    "abstract": "Deep Neural Networks are prone to learning spurious correlations embedded in the training data, leading to potentially biased predictions. This poses risks when deploying these models for high-stake decision-making, such as in medical applications. Current methods for post-hoc model correction either require input-level annotations, which are only possible for spatially localized biases, or augment the latent feature space, thereby hoping to enforce the right reasons. We present a novel method ensuring the right reasons on the concept level by reducing the model's sensitivity towards biases through the gradient. When modeling biases via Concept Activation Vectors, we highlight the importance of choosing robust directions, as traditional regression-based approaches such as Support Vector Machines tend to result in diverging directions. We effectively mitigate biases in controlled and real-world settings on the ISIC, Bone Age, ImageNet and CelebA datasets using VGG, ResNet and EfficientN",
    "link": "http://arxiv.org/abs/2308.09437",
    "context": "Title: From Hope to Safety: Unlearning Biases of Deep Models by Enforcing the Right Reasons in Latent Space. (arXiv:2308.09437v2 [cs.LG] UPDATED)\nAbstract: Deep Neural Networks are prone to learning spurious correlations embedded in the training data, leading to potentially biased predictions. This poses risks when deploying these models for high-stake decision-making, such as in medical applications. Current methods for post-hoc model correction either require input-level annotations, which are only possible for spatially localized biases, or augment the latent feature space, thereby hoping to enforce the right reasons. We present a novel method ensuring the right reasons on the concept level by reducing the model's sensitivity towards biases through the gradient. When modeling biases via Concept Activation Vectors, we highlight the importance of choosing robust directions, as traditional regression-based approaches such as Support Vector Machines tend to result in diverging directions. We effectively mitigate biases in controlled and real-world settings on the ISIC, Bone Age, ImageNet and CelebA datasets using VGG, ResNet and EfficientN",
    "path": "papers/23/08/2308.09437.json",
    "total_tokens": 920,
    "translated_title": "从期望到安全：通过在潜在空间中强制正确的原因来消除深度模型的偏见",
    "translated_abstract": "深度神经网络容易学习训练数据中潜藏的错误相关性，从而导致可能有偏见的预测。这在将这些模型部署于高风险决策场景（如医学应用）时存在风险。目前的后处理模型校正方法要么需要输入级别的注释，这只适用于局部化偏见，要么通过扩充潜在特征空间，希望能实现正确的原因。我们提出了一种新的方法，通过梯度减小模型对偏见的敏感性，从而在概念级别上确保正确的原因。当通过概念激活向量来建模偏见时，我们强调选择稳健的方向的重要性，因为传统的基于回归的方法（如支持向量机）往往会导致发散的方向。我们使用VGG、ResNet和EfficientN在ISIC、骨龄、ImageNet和CelebA数据集上在受控和真实环境中有效减轻偏见。",
    "tldr": "该论文提出了一种通过梯度减小模型对偏见的敏感性的方法，从而在概念级别上确保正确原因，有效减轻深度神经网络中的偏见。该方法在多个数据集和环境中被验证有效。",
    "en_tdlr": "This paper presents a method that reduces the sensitivity of deep neural networks towards biases through gradient descent, ensuring the right reasons at the concept level and effectively mitigating biases in various datasets and environments."
}