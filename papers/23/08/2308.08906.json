{
    "title": "Towards a Practical Defense against Adversarial Attacks on Deep Learning-based Malware Detectors via Randomized Smoothing. (arXiv:2308.08906v1 [cs.CR])",
    "abstract": "Malware detectors based on deep learning (DL) have been shown to be susceptible to malware examples that have been deliberately manipulated in order to evade detection, a.k.a. adversarial malware examples. More specifically, it has been show that deep learning detectors are vulnerable to small changes on the input file. Given this vulnerability of deep learning detectors, we propose a practical defense against adversarial malware examples inspired by randomized smoothing. In our work, instead of employing Gaussian or Laplace noise when randomizing inputs, we propose a randomized ablation-based smoothing scheme that ablates a percentage of the bytes within an executable. During training, our randomized ablation-based smoothing scheme trains a base classifier based on ablated versions of the executable files. At test time, the final classification for a given input executable is taken as the class most commonly predicted by the classifier on a set of ablated versions of the original exec",
    "link": "http://arxiv.org/abs/2308.08906",
    "context": "Title: Towards a Practical Defense against Adversarial Attacks on Deep Learning-based Malware Detectors via Randomized Smoothing. (arXiv:2308.08906v1 [cs.CR])\nAbstract: Malware detectors based on deep learning (DL) have been shown to be susceptible to malware examples that have been deliberately manipulated in order to evade detection, a.k.a. adversarial malware examples. More specifically, it has been show that deep learning detectors are vulnerable to small changes on the input file. Given this vulnerability of deep learning detectors, we propose a practical defense against adversarial malware examples inspired by randomized smoothing. In our work, instead of employing Gaussian or Laplace noise when randomizing inputs, we propose a randomized ablation-based smoothing scheme that ablates a percentage of the bytes within an executable. During training, our randomized ablation-based smoothing scheme trains a base classifier based on ablated versions of the executable files. At test time, the final classification for a given input executable is taken as the class most commonly predicted by the classifier on a set of ablated versions of the original exec",
    "path": "papers/23/08/2308.08906.json",
    "total_tokens": 883,
    "translated_title": "针对基于深度学习的恶意软件检测器的对抗攻击的实用防御方法：随机平滑化",
    "translated_abstract": "基于深度学习的恶意软件检测器对恶意软件样本的检测易受到恶意篡改的影响，即对抗性恶意软件样本。我们提出了一个实用的防御方法来对抗对抗性恶意软件样本，该方法受到随机平滑化的启发。我们使用随机剥离平滑化方案，而不是在随机化输入时使用高斯或拉普拉斯噪声，该方案剥离了可执行文件中的一定比例字节。在训练过程中，我们的随机剥离平滑化方案使用剥离版本的可执行文件来训练基分类器。在测试时，给定输入可执行文件的最终分类被视为在一组剥离版本的原始可执行文件上由分类器最常预测的类别。",
    "tldr": "这篇论文提出了一种针对深度学习恶意软件检测器对抗攻击的实用防御方法，通过随机平滑化来剥离可执行文件一定比例字节，并提出了基于剥离版本的基分类器进行训练和测试。",
    "en_tdlr": "This paper presents a practical defense against adversarial attacks on deep learning-based malware detectors, using randomized smoothing to ablate a percentage of bytes in executable files and training a base classifier based on ablated versions for testing."
}