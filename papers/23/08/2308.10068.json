{
    "title": "ILCAS: Imitation Learning-Based Configuration-Adaptive Streaming for Live Video Analytics with Cross-Camera Collaboration. (arXiv:2308.10068v2 [cs.NI] UPDATED)",
    "abstract": "The high-accuracy and resource-intensive deep neural networks (DNNs) have been widely adopted by live video analytics (VA), where camera videos are streamed over the network to resource-rich edge/cloud servers for DNN inference. Common video encoding configurations (e.g., resolution and frame rate) have been identified with significant impacts on striking the balance between bandwidth consumption and inference accuracy and therefore their adaption scheme has been a focus of optimization. However, previous profiling-based solutions suffer from high profiling cost, while existing deep reinforcement learning (DRL) based solutions may achieve poor performance due to the usage of fixed reward function for training the agent, which fails to craft the application goals in various scenarios. In this paper, we propose ILCAS, the first imitation learning (IL) based configuration-adaptive VA streaming system. Unlike DRL-based solutions, ILCAS trains the agent with demonstrations collected from th",
    "link": "http://arxiv.org/abs/2308.10068",
    "context": "Title: ILCAS: Imitation Learning-Based Configuration-Adaptive Streaming for Live Video Analytics with Cross-Camera Collaboration. (arXiv:2308.10068v2 [cs.NI] UPDATED)\nAbstract: The high-accuracy and resource-intensive deep neural networks (DNNs) have been widely adopted by live video analytics (VA), where camera videos are streamed over the network to resource-rich edge/cloud servers for DNN inference. Common video encoding configurations (e.g., resolution and frame rate) have been identified with significant impacts on striking the balance between bandwidth consumption and inference accuracy and therefore their adaption scheme has been a focus of optimization. However, previous profiling-based solutions suffer from high profiling cost, while existing deep reinforcement learning (DRL) based solutions may achieve poor performance due to the usage of fixed reward function for training the agent, which fails to craft the application goals in various scenarios. In this paper, we propose ILCAS, the first imitation learning (IL) based configuration-adaptive VA streaming system. Unlike DRL-based solutions, ILCAS trains the agent with demonstrations collected from th",
    "path": "papers/23/08/2308.10068.json",
    "total_tokens": 964,
    "translated_title": "ILCAS: 基于模仿学习的适应性配置流式传输在带有跨相机协作的实时视频分析中的应用",
    "translated_abstract": "高精度和资源密集型的深度神经网络（DNN）已经被广泛应用于实时视频分析（VA），其中相机视频通过网络流式传输到资源丰富的边缘/云服务器进行DNN推理。常见的视频编码配置（例如分辨率和帧率）已被确定为在带宽消耗和推理准确度之间取得平衡的重要因素，因此它们的调整方案一直是优化的焦点。然而，以前基于性能分析的解决方案存在高昂的性能分析成本，而现有的基于深度强化学习（DRL）的解决方案可能由于使用固定奖励函数训练代理而性能不佳，这无法在各种场景下制定应用目标。在本文中，我们提出了基于模仿学习的ILCAS适应性配置流式传输系统。与基于DRL的解决方案不同，ILCAS通过从跨相机协作中收集的演示数据来训练代理。",
    "tldr": "ILCAS是首个基于模仿学习的适应性配置流式传输系统，用于实时视频分析，并在传输过程中实现相机之间的协作。与基于深度强化学习的解决方案不同，ILCAS通过模仿学习训练代理，提高了性能表现和应用目标的多样性。"
}