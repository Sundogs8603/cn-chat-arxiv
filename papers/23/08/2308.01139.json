{
    "title": "Dynamic Privacy Allocation for Locally Differentially Private Federated Learning with Composite Objectives. (arXiv:2308.01139v1 [cs.LG])",
    "abstract": "This paper proposes a locally differentially private federated learning algorithm for strongly convex but possibly nonsmooth problems that protects the gradients of each worker against an honest but curious server. The proposed algorithm adds artificial noise to the shared information to ensure privacy and dynamically allocates the time-varying noise variance to minimize an upper bound of the optimization error subject to a predefined privacy budget constraint. This allows for an arbitrarily large but finite number of iterations to achieve both privacy protection and utility up to a neighborhood of the optimal solution, removing the need for tuning the number of iterations. Numerical results show the superiority of the proposed algorithm over state-of-the-art methods.",
    "link": "http://arxiv.org/abs/2308.01139",
    "context": "Title: Dynamic Privacy Allocation for Locally Differentially Private Federated Learning with Composite Objectives. (arXiv:2308.01139v1 [cs.LG])\nAbstract: This paper proposes a locally differentially private federated learning algorithm for strongly convex but possibly nonsmooth problems that protects the gradients of each worker against an honest but curious server. The proposed algorithm adds artificial noise to the shared information to ensure privacy and dynamically allocates the time-varying noise variance to minimize an upper bound of the optimization error subject to a predefined privacy budget constraint. This allows for an arbitrarily large but finite number of iterations to achieve both privacy protection and utility up to a neighborhood of the optimal solution, removing the need for tuning the number of iterations. Numerical results show the superiority of the proposed algorithm over state-of-the-art methods.",
    "path": "papers/23/08/2308.01139.json",
    "total_tokens": 717,
    "translated_title": "动态隐私分配用于具有复合目标的本地差分隐私联邦学习",
    "translated_abstract": "本文提出了一种针对强凸但可能非平滑问题的本地差分隐私联邦学习算法，用于保护每个工作节点的梯度，以免受诚实但好奇的服务器的泄漏。该算法在共享信息中添加人工噪声以确保隐私，并动态分配时变的噪声方差，以最小化优化错误的上界，同时符合预定义的隐私预算限制。这使得可以通过任意大的但有限次数的迭代实现隐私保护和效用，并消除了调整迭代次数的需求。数值结果显示，该算法优于现有方法。",
    "tldr": "本文提出了一种动态隐私分配的本地差分隐私联邦学习算法，可以保护梯度并最小化优化错误，同时不需要调整迭代次数。",
    "en_tdlr": "This paper proposes a locally differentially private federated learning algorithm with dynamic privacy allocation to protect gradients and minimize optimization errors without the need to tune the number of iterations."
}