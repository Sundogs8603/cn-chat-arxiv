{
    "title": "SurgicalSAM: Efficient Class Promptable Surgical Instrument Segmentation. (arXiv:2308.08746v1 [cs.CV])",
    "abstract": "The Segment Anything Model (SAM) is a powerful foundation model that has revolutionised image segmentation. To apply SAM to surgical instrument segmentation, a common approach is to locate precise points or boxes of instruments and then use them as prompts for SAM in a zero-shot manner. However, we observe two problems with this naive pipeline: (1) the domain gap between natural objects and surgical instruments leads to poor generalisation of SAM; and (2) SAM relies on precise point or box locations for accurate segmentation, requiring either extensive manual guidance or a well-performing specialist detector for prompt preparation, which leads to a complex multi-stage pipeline. To address these problems, we introduce SurgicalSAM, a novel end-to-end efficient-tuning approach for SAM to effectively integrate surgical-specific information with SAM's pre-trained knowledge for improved generalisation. Specifically, we propose a lightweight prototype-based class prompt encoder for tuning, wh",
    "link": "http://arxiv.org/abs/2308.08746",
    "context": "Title: SurgicalSAM: Efficient Class Promptable Surgical Instrument Segmentation. (arXiv:2308.08746v1 [cs.CV])\nAbstract: The Segment Anything Model (SAM) is a powerful foundation model that has revolutionised image segmentation. To apply SAM to surgical instrument segmentation, a common approach is to locate precise points or boxes of instruments and then use them as prompts for SAM in a zero-shot manner. However, we observe two problems with this naive pipeline: (1) the domain gap between natural objects and surgical instruments leads to poor generalisation of SAM; and (2) SAM relies on precise point or box locations for accurate segmentation, requiring either extensive manual guidance or a well-performing specialist detector for prompt preparation, which leads to a complex multi-stage pipeline. To address these problems, we introduce SurgicalSAM, a novel end-to-end efficient-tuning approach for SAM to effectively integrate surgical-specific information with SAM's pre-trained knowledge for improved generalisation. Specifically, we propose a lightweight prototype-based class prompt encoder for tuning, wh",
    "path": "papers/23/08/2308.08746.json",
    "total_tokens": 879,
    "translated_title": "SurgicalSAM: 高效的可提示的手术器械分割",
    "translated_abstract": "Segment Anything Model (SAM) 是一种强大的基础模型，已经彻底改变了图像分割。为了将SAM应用于手术器械分割，常见的方法是定位器械的精确点或框，并将其用作SAM的提示，以零样本方式进行。然而，我们观察到这种简单的流程存在两个问题：（1）自然物体和手术器械之间的领域差距导致SAM的泛化能力差；（2）SAM依赖于精确的点或框位置进行准确的分割，要求要么经过广泛的手动引导，要么使用性能良好的专门检测器进行提示准备，这导致了一个复杂的多阶段流程。为了解决这些问题，我们引入了SurgicalSAM，一种新的端到端高效调优方法，以有效地将手术特定信息与SAM的预训练知识相结合，以改进泛化能力。",
    "tldr": "SurgicalSAM是一种高效的手术器械分割方法，通过引入SurgicalSAM，可以有效地应用Segment Anything Model (SAM) 进行手术器械分割，解决了SAM在手术器械领域的泛化能力差和复杂多阶段流程的问题。",
    "en_tdlr": "SurgicalSAM is an efficient approach for surgical instrument segmentation that addresses the poor generalisation and complex pipeline of Segment Anything Model (SAM) by effectively integrating surgical-specific information with SAM's pre-trained knowledge."
}