{
    "title": "Bootstrapping Contrastive Learning Enhanced Music Cold-Start Matching. (arXiv:2308.02844v1 [cs.IR])",
    "abstract": "We study a particular matching task we call Music Cold-Start Matching. In short, given a cold-start song request, we expect to retrieve songs with similar audiences and then fastly push the cold-start song to the audiences of the retrieved songs to warm up it. However, there are hardly any studies done on this task. Therefore, in this paper, we will formalize the problem of Music Cold-Start Matching detailedly and give a scheme. During the offline training, we attempt to learn high-quality song representations based on song content features. But, we find supervision signals typically follow power-law distribution causing skewed representation learning. To address this issue, we propose a novel contrastive learning paradigm named Bootstrapping Contrastive Learning (BCL) to enhance the quality of learned representations by exerting contrastive regularization. During the online serving, to locate the target audiences more accurately, we propose Clustering-based Audience Targeting (CAT) th",
    "link": "http://arxiv.org/abs/2308.02844",
    "context": "Title: Bootstrapping Contrastive Learning Enhanced Music Cold-Start Matching. (arXiv:2308.02844v1 [cs.IR])\nAbstract: We study a particular matching task we call Music Cold-Start Matching. In short, given a cold-start song request, we expect to retrieve songs with similar audiences and then fastly push the cold-start song to the audiences of the retrieved songs to warm up it. However, there are hardly any studies done on this task. Therefore, in this paper, we will formalize the problem of Music Cold-Start Matching detailedly and give a scheme. During the offline training, we attempt to learn high-quality song representations based on song content features. But, we find supervision signals typically follow power-law distribution causing skewed representation learning. To address this issue, we propose a novel contrastive learning paradigm named Bootstrapping Contrastive Learning (BCL) to enhance the quality of learned representations by exerting contrastive regularization. During the online serving, to locate the target audiences more accurately, we propose Clustering-based Audience Targeting (CAT) th",
    "path": "papers/23/08/2308.02844.json",
    "total_tokens": 935,
    "translated_title": "Bootstrap对比学习增强的音乐冷启动匹配",
    "translated_abstract": "本文研究了一种称为音乐冷启动匹配的特定匹配任务。简而言之，给定一个冷启动的歌曲请求，我们希望检索到具有相似受众的歌曲，然后迅速将冷启动的歌曲推送到这些检索到的歌曲的受众中，以使其温暖起来。然而，对于这个任务几乎没有任何研究。因此，在本文中，我们将详细界定音乐冷启动匹配问题，并给出一个方案。在离线训练过程中，我们尝试基于歌曲内容特征学习高质量的歌曲表示。然而，我们发现监督信号通常遵循幂律分布，导致偏斜的表示学习。为了解决这个问题，我们提出了一种新颖的对比学习范式，称为Bootstrap对比学习（BCL），通过施加对比正则化来提高学到的表示的质量。在在线服务过程中，为了更准确地定位目标受众，我们提出了基于聚类的受众定位（CAT）方案。",
    "tldr": "本文提出了一种称为音乐冷启动匹配的任务，并提出了Bootstrap对比学习和基于聚类的受众定位方案，以增强音乐冷启动匹配的质量和准确性。",
    "en_tdlr": "This paper presents a task called Music Cold-Start Matching and proposes the use of Bootstrap Contrastive Learning and Clustering-based Audience Targeting to enhance the quality and accuracy of music cold-start matching."
}