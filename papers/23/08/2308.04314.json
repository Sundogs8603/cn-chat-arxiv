{
    "title": "Cooperative Multi-agent Bandits: Distributed Algorithms with Optimal Individual Regret and Constant Communication Costs. (arXiv:2308.04314v1 [cs.LG])",
    "abstract": "Recently, there has been extensive study of cooperative multi-agent multi-armed bandits where a set of distributed agents cooperatively play the same multi-armed bandit game. The goal is to develop bandit algorithms with the optimal group and individual regrets and low communication between agents. The prior work tackled this problem using two paradigms: leader-follower and fully distributed algorithms. Prior algorithms in both paradigms achieve the optimal group regret. The leader-follower algorithms achieve constant communication costs but fail to achieve optimal individual regrets. The state-of-the-art fully distributed algorithms achieve optimal individual regrets but fail to achieve constant communication costs. This paper presents a simple yet effective communication policy and integrates it into a learning algorithm for cooperative bandits. Our algorithm achieves the best of both paradigms: optimal individual regret and constant communication costs.",
    "link": "http://arxiv.org/abs/2308.04314",
    "context": "Title: Cooperative Multi-agent Bandits: Distributed Algorithms with Optimal Individual Regret and Constant Communication Costs. (arXiv:2308.04314v1 [cs.LG])\nAbstract: Recently, there has been extensive study of cooperative multi-agent multi-armed bandits where a set of distributed agents cooperatively play the same multi-armed bandit game. The goal is to develop bandit algorithms with the optimal group and individual regrets and low communication between agents. The prior work tackled this problem using two paradigms: leader-follower and fully distributed algorithms. Prior algorithms in both paradigms achieve the optimal group regret. The leader-follower algorithms achieve constant communication costs but fail to achieve optimal individual regrets. The state-of-the-art fully distributed algorithms achieve optimal individual regrets but fail to achieve constant communication costs. This paper presents a simple yet effective communication policy and integrates it into a learning algorithm for cooperative bandits. Our algorithm achieves the best of both paradigms: optimal individual regret and constant communication costs.",
    "path": "papers/23/08/2308.04314.json",
    "total_tokens": 863,
    "translated_title": "合作式多智能体赌博机：具有最佳个体遗憾和恒定通信成本的分布式算法",
    "translated_abstract": "最近，对合作式多智能体多臂赌博机进行了广泛研究，其中一组分布式智能体合作玩相同的多臂赌博游戏。目标是开发具有最佳群体和个体遗憾以及智能体之间通信成本低的赌博机算法。在前期工作中，使用了两种范式来解决这个问题：领导者-跟随者和完全分布式算法。在这两种范式中，以前的算法都能达到最佳群体遗憾。领导者-跟随者算法实现了恒定的通信成本，但未能达到最佳个体遗憾。目前最先进的完全分布式算法实现了最佳个体遗憾，但未能实现恒定的通信成本。本文提出了一种简单而有效的通信策略，并将其整合到合作赌博机的学习算法中。我们的算法同时实现了两种范式的最优个体遗憾和恒定通信成本。",
    "tldr": "本文提出了一种新的合作赌博机算法，实现了最佳的个体遗憾和恒定的通信成本。",
    "en_tdlr": "This paper proposes a new cooperative bandit algorithm that achieves optimal individual regret and constant communication costs."
}