{
    "title": "Backdoor Mitigation by Correcting the Distribution of Neural Activations. (arXiv:2308.09850v1 [cs.LG])",
    "abstract": "Backdoor (Trojan) attacks are an important type of adversarial exploit against deep neural networks (DNNs), wherein a test instance is (mis)classified to the attacker's target class whenever the attacker's backdoor trigger is present. In this paper, we reveal and analyze an important property of backdoor attacks: a successful attack causes an alteration in the distribution of internal layer activations for backdoor-trigger instances, compared to that for clean instances. Even more importantly, we find that instances with the backdoor trigger will be correctly classified to their original source classes if this distribution alteration is corrected. Based on our observations, we propose an efficient and effective method that achieves post-training backdoor mitigation by correcting the distribution alteration using reverse-engineered triggers. Notably, our method does not change any trainable parameters of the DNN, but achieves generally better mitigation performance than existing methods",
    "link": "http://arxiv.org/abs/2308.09850",
    "context": "Title: Backdoor Mitigation by Correcting the Distribution of Neural Activations. (arXiv:2308.09850v1 [cs.LG])\nAbstract: Backdoor (Trojan) attacks are an important type of adversarial exploit against deep neural networks (DNNs), wherein a test instance is (mis)classified to the attacker's target class whenever the attacker's backdoor trigger is present. In this paper, we reveal and analyze an important property of backdoor attacks: a successful attack causes an alteration in the distribution of internal layer activations for backdoor-trigger instances, compared to that for clean instances. Even more importantly, we find that instances with the backdoor trigger will be correctly classified to their original source classes if this distribution alteration is corrected. Based on our observations, we propose an efficient and effective method that achieves post-training backdoor mitigation by correcting the distribution alteration using reverse-engineered triggers. Notably, our method does not change any trainable parameters of the DNN, but achieves generally better mitigation performance than existing methods",
    "path": "papers/23/08/2308.09850.json",
    "total_tokens": 869,
    "translated_title": "通过修复神经激活的分布来减轻后门攻击",
    "translated_abstract": "后门（木马）攻击是针对深度神经网络的一种重要的对抗性攻击方式，当攻击者的后门触发器出现时，测试实例会被（错误）分类为攻击者的目标类。在本文中，我们揭示并分析了后门攻击的一个重要特性：成功的攻击会导致后门触发实例内部层激活的分布发生改变，与干净实例的分布不同。更重要的是，我们发现如果纠正了这种分布改变，带有后门触发器的实例将正确分类为它们原始的源类。基于我们的观察，我们提出了一种高效有效的方法，通过使用反向工程的触发器来通过纠正分布改变实现训练后的后门减轻。值得注意的是，我们的方法不改变DNN的任何可训练参数，但是相比现有方法，具有更好的减轻性能。",
    "tldr": "本文揭示了后门攻击的一个重要特性：成功的攻击会改变内部层激活的分布，我们提出了一种通过纠正分布改变实现训练后的后门减缓的方法。",
    "en_tdlr": "This paper reveals an important property of backdoor attacks: a successful attack alters the distribution of internal layer activations. The proposed method mitigates backdoors after training by correcting the distribution alteration, achieving better performance than existing methods without changing trainable parameters."
}