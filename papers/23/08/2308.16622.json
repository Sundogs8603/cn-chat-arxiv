{
    "title": "Developing a Scalable Benchmark for Assessing Large Language Models in Knowledge Graph Engineering. (arXiv:2308.16622v1 [cs.AI])",
    "abstract": "As the field of Large Language Models (LLMs) evolves at an accelerated pace, the critical need to assess and monitor their performance emerges. We introduce a benchmarking framework focused on knowledge graph engineering (KGE) accompanied by three challenges addressing syntax and error correction, facts extraction and dataset generation. We show that while being a useful tool, LLMs are yet unfit to assist in knowledge graph generation with zero-shot prompting. Consequently, our LLM-KG-Bench framework provides automatic evaluation and storage of LLM responses as well as statistical data and visualization tools to support tracking of prompt engineering and model performance.",
    "link": "http://arxiv.org/abs/2308.16622",
    "context": "Title: Developing a Scalable Benchmark for Assessing Large Language Models in Knowledge Graph Engineering. (arXiv:2308.16622v1 [cs.AI])\nAbstract: As the field of Large Language Models (LLMs) evolves at an accelerated pace, the critical need to assess and monitor their performance emerges. We introduce a benchmarking framework focused on knowledge graph engineering (KGE) accompanied by three challenges addressing syntax and error correction, facts extraction and dataset generation. We show that while being a useful tool, LLMs are yet unfit to assist in knowledge graph generation with zero-shot prompting. Consequently, our LLM-KG-Bench framework provides automatic evaluation and storage of LLM responses as well as statistical data and visualization tools to support tracking of prompt engineering and model performance.",
    "path": "papers/23/08/2308.16622.json",
    "total_tokens": 793,
    "translated_title": "在知识图谱工程中开发一个可扩展的用于评估大型语言模型的基准测试",
    "translated_abstract": "随着大型语言模型（LLMs）领域的快速发展，评估和监测其性能的迫切需求浮出水面。我们介绍了一个针对知识图谱工程（KGE）的基准测试框架，并提出了三个挑战，涉及语法和错误修正、事实提取和数据集生成。我们展示了尽管LLMs是有用的工具，但它们尚不能在零-shot提示下辅助知识图谱生成。因此，我们的LLM-KG-Bench框架提供了LLM回答的自动评估和存储，以及统计数据和可视化工具，支持提示工程和模型性能的跟踪。",
    "tldr": "本文介绍了一个基准测试框架，用于评估大型语言模型在知识图谱工程中的应用。框架包括语法和错误修正、事实提取和数据集生成三个挑战，同时也揭示了LLMs在零-shot提示下辅助知识图谱生成方面的不足。",
    "en_tdlr": "This paper presents a benchmarking framework for assessing the application of large language models in knowledge graph engineering. The framework includes three challenges: syntax and error correction, facts extraction, and dataset generation. It also reveals the limitations of LLMs in assisting knowledge graph generation with zero-shot prompting."
}