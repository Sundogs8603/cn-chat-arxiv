{
    "title": "Factor Graph Neural Networks. (arXiv:2308.00887v1 [cs.LG])",
    "abstract": "In recent years, we have witnessed a surge of Graph Neural Networks (GNNs), most of which can learn powerful representations in an end-to-end fashion with great success in many real-world applications. They have resemblance to Probabilistic Graphical Models (PGMs), but break free from some limitations of PGMs. By aiming to provide expressive methods for representation learning instead of computing marginals or most likely configurations, GNNs provide flexibility in the choice of information flowing rules while maintaining good performance. Despite their success and inspirations, they lack efficient ways to represent and learn higher-order relations among variables/nodes. More expressive higher-order GNNs which operate on k-tuples of nodes need increased computational resources in order to process higher-order tensors. We propose Factor Graph Neural Networks (FGNNs) to effectively capture higher-order relations for inference and learning. To do so, we first derive an efficient approxima",
    "link": "http://arxiv.org/abs/2308.00887",
    "context": "Title: Factor Graph Neural Networks. (arXiv:2308.00887v1 [cs.LG])\nAbstract: In recent years, we have witnessed a surge of Graph Neural Networks (GNNs), most of which can learn powerful representations in an end-to-end fashion with great success in many real-world applications. They have resemblance to Probabilistic Graphical Models (PGMs), but break free from some limitations of PGMs. By aiming to provide expressive methods for representation learning instead of computing marginals or most likely configurations, GNNs provide flexibility in the choice of information flowing rules while maintaining good performance. Despite their success and inspirations, they lack efficient ways to represent and learn higher-order relations among variables/nodes. More expressive higher-order GNNs which operate on k-tuples of nodes need increased computational resources in order to process higher-order tensors. We propose Factor Graph Neural Networks (FGNNs) to effectively capture higher-order relations for inference and learning. To do so, we first derive an efficient approxima",
    "path": "papers/23/08/2308.00887.json",
    "total_tokens": 821,
    "translated_title": "因子图神经网络",
    "translated_abstract": "在最近几年，我们见证了图神经网络（GNN）的激增，其中大多数可以以端到端的方式学习强大的表示，并在许多实际应用中取得了巨大成功。它们与概率图模型（PGM）有相似之处，但摆脱了PGM的某些限制。GNN旨在提供表达学习的有效方法，而不是计算边际或最可能的配置，因此在信息流规则的选择上具有灵活性，同时保持良好的性能。尽管它们取得了成功并带来灵感，但它们缺乏有效的方法来表示和学习变量/节点之间的高阶关系。操作在k元节点上的更具表达能力的高阶GNN需要增加的计算资源以处理高阶张量。我们提出因子图神经网络（FGNN）以有效地捕捉高阶关系以进行推理和学习。",
    "tldr": "因子图神经网络（FGNN）提供了一种有效地捕捉高阶关系的方法，可以在推理和学习中使用，具有比传统图神经网络更高的表达能力和灵活性。"
}