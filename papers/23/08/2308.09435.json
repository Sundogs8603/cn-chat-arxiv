{
    "title": "A Methodology for Generative Spelling Correction via Natural Spelling Errors Emulation across Multiple Domains and Languages. (arXiv:2308.09435v2 [cs.CL] UPDATED)",
    "abstract": "Modern large language models demonstrate impressive capabilities in text generation and generalization. However, they often struggle with solving text editing tasks, particularly when it comes to correcting spelling errors and mistypings. In this paper, we present a methodology for generative spelling correction (SC), which was tested on English and Russian languages and potentially can be extended to any language with minor changes. Our research mainly focuses on exploring natural spelling errors and mistypings in texts and studying the ways those errors can be emulated in correct sentences to effectively enrich generative models' pre-train procedure. We investigate the impact of such emulations and the models' abilities across different text domains. In this work, we investigate two spelling corruption techniques: 1) first one mimics human behavior when making a mistake through leveraging statistics of errors from particular dataset and 2) second adds the most common spelling errors,",
    "link": "http://arxiv.org/abs/2308.09435",
    "context": "Title: A Methodology for Generative Spelling Correction via Natural Spelling Errors Emulation across Multiple Domains and Languages. (arXiv:2308.09435v2 [cs.CL] UPDATED)\nAbstract: Modern large language models demonstrate impressive capabilities in text generation and generalization. However, they often struggle with solving text editing tasks, particularly when it comes to correcting spelling errors and mistypings. In this paper, we present a methodology for generative spelling correction (SC), which was tested on English and Russian languages and potentially can be extended to any language with minor changes. Our research mainly focuses on exploring natural spelling errors and mistypings in texts and studying the ways those errors can be emulated in correct sentences to effectively enrich generative models' pre-train procedure. We investigate the impact of such emulations and the models' abilities across different text domains. In this work, we investigate two spelling corruption techniques: 1) first one mimics human behavior when making a mistake through leveraging statistics of errors from particular dataset and 2) second adds the most common spelling errors,",
    "path": "papers/23/08/2308.09435.json",
    "total_tokens": 917,
    "translated_title": "通过模拟跨多个领域和语言的自然拼写错误生成拼写纠正的方法论",
    "translated_abstract": "现代大型语言模型展示了出色的文本生成和泛化能力。然而，当涉及到纠正拼写错误和打字错误时，它们通常难以解决文本编辑任务。本文提出了一种用于生成拼写纠正的方法论，该方法在英语和俄语语言上进行了测试，并且在稍作修改后可以扩展到任何语言。我们的研究主要集中在探索文本中的自然拼写错误和打字错误，并研究这些错误可以如何在正确的句子中模拟，以有效丰富生成模型的预训练过程。我们研究了这种模拟的影响和模型在不同文本领域中的能力。本文研究了两种拼写破坏技术：1）第一种通过利用特定数据集中的错误统计来模拟人类犯错误时的行为；2）第二种是添加最常见的拼写错误。",
    "tldr": "本文提出了一种用于生成拼写纠正的方法论，通过模拟文本中的自然拼写错误和打字错误，以有效丰富生成模型的预训练过程。研究结果表明，这种方法在英语和俄语语言上是可行的，并可以扩展到其他语言。",
    "en_tdlr": "We propose a methodology for generative spelling correction by emulating natural spelling errors and typing mistakes in text, which effectively enhances the pre-training process of generative models. The method has been tested on English and Russian languages and has potential for extension to other languages."
}