{
    "title": "When and How Does Known Class Help Discover Unknown Ones? Provable Understanding Through Spectral Analysis. (arXiv:2308.05017v1 [cs.LG])",
    "abstract": "Novel Class Discovery (NCD) aims at inferring novel classes in an unlabeled set by leveraging prior knowledge from a labeled set with known classes. Despite its importance, there is a lack of theoretical foundations for NCD. This paper bridges the gap by providing an analytical framework to formalize and investigate when and how known classes can help discover novel classes. Tailored to the NCD problem, we introduce a graph-theoretic representation that can be learned by a novel NCD Spectral Contrastive Loss (NSCL). Minimizing this objective is equivalent to factorizing the graph's adjacency matrix, which allows us to derive a provable error bound and provide the sufficient and necessary condition for NCD. Empirically, NSCL can match or outperform several strong baselines on common benchmark datasets, which is appealing for practical usage while enjoying theoretical guarantees.",
    "link": "http://arxiv.org/abs/2308.05017",
    "context": "Title: When and How Does Known Class Help Discover Unknown Ones? Provable Understanding Through Spectral Analysis. (arXiv:2308.05017v1 [cs.LG])\nAbstract: Novel Class Discovery (NCD) aims at inferring novel classes in an unlabeled set by leveraging prior knowledge from a labeled set with known classes. Despite its importance, there is a lack of theoretical foundations for NCD. This paper bridges the gap by providing an analytical framework to formalize and investigate when and how known classes can help discover novel classes. Tailored to the NCD problem, we introduce a graph-theoretic representation that can be learned by a novel NCD Spectral Contrastive Loss (NSCL). Minimizing this objective is equivalent to factorizing the graph's adjacency matrix, which allows us to derive a provable error bound and provide the sufficient and necessary condition for NCD. Empirically, NSCL can match or outperform several strong baselines on common benchmark datasets, which is appealing for practical usage while enjoying theoretical guarantees.",
    "path": "papers/23/08/2308.05017.json",
    "total_tokens": 964,
    "translated_title": "何时和如何通过谱分析利用已知类别帮助发现未知类别？通过可证明的谱分析理解。",
    "translated_abstract": "新颖类别发现（NCD）旨在通过利用具有已知类别的标记集合的先验知识，在未标记的集合中推断出新颖类别。尽管其重要性，但NCD缺乏理论基础。本文通过提供一个分析框架来弥补这个差距，以形式化和研究何时和如何已知类别能够帮助发现新颖类别。针对NCD问题，我们引入了一种图论表示，可以通过一种新颖的NCD谱对比损失（NSCL）进行学习。最小化这个目标等同于分解图的邻接矩阵，这使我们能够推导出可证明的误差界限，并提供NCD的充分且必要条件。在实证上，NSCL可以在常见的基准数据集上与或优于几个强基准方法，这对实际使用是有吸引力的，同时享有理论保证。",
    "tldr": "本文提出了一个分析框架来研究何时和如何利用已知类别帮助发现新颖类别，并通过引入NCD谱对比损失（NSCL）提供了可证明的误差界限和NCD的充分必要条件。实验证明NSCL可以在常见的基准数据集上与或优于几个强基准方法，具有实际使用价值且理论保证。",
    "en_tdlr": "This paper provides an analytical framework to investigate when and how known classes can help discover novel classes, and introduces the NCD Spectral Contrastive Loss (NSCL) which offers provable error bounds and sufficient and necessary conditions for NCD. Empirical results demonstrate that NSCL can outperform strong baselines on common benchmark datasets, making it both practically useful and theoretically guaranteed."
}