{
    "title": "OctoPack: Instruction Tuning Code Large Language Models",
    "abstract": "arXiv:2308.07124v2 Announce Type: replace-cross  Abstract: Finetuning large language models (LLMs) on instructions leads to vast performance improvements on natural language tasks. We apply instruction tuning using code, leveraging the natural structure of Git commits, which pair code changes with human instructions. We compile CommitPack: 4 terabytes of Git commits across 350 programming languages. We benchmark CommitPack against other natural and synthetic code instructions (xP3x, Self-Instruct, OASST) on the 16B parameter StarCoder model, and achieve state-of-the-art performance among models not trained on OpenAI outputs, on the HumanEval Python benchmark (46.2% pass@1). We further introduce HumanEvalPack, expanding the HumanEval benchmark to a total of 3 coding tasks (Code Repair, Code Explanation, Code Synthesis) across 6 languages (Python, JavaScript, Java, Go, C++, Rust). Our models, OctoCoder and OctoGeeX, achieve the best performance across HumanEvalPack among all permissive m",
    "link": "https://arxiv.org/abs/2308.07124",
    "context": "Title: OctoPack: Instruction Tuning Code Large Language Models\nAbstract: arXiv:2308.07124v2 Announce Type: replace-cross  Abstract: Finetuning large language models (LLMs) on instructions leads to vast performance improvements on natural language tasks. We apply instruction tuning using code, leveraging the natural structure of Git commits, which pair code changes with human instructions. We compile CommitPack: 4 terabytes of Git commits across 350 programming languages. We benchmark CommitPack against other natural and synthetic code instructions (xP3x, Self-Instruct, OASST) on the 16B parameter StarCoder model, and achieve state-of-the-art performance among models not trained on OpenAI outputs, on the HumanEval Python benchmark (46.2% pass@1). We further introduce HumanEvalPack, expanding the HumanEval benchmark to a total of 3 coding tasks (Code Repair, Code Explanation, Code Synthesis) across 6 languages (Python, JavaScript, Java, Go, C++, Rust). Our models, OctoCoder and OctoGeeX, achieve the best performance across HumanEvalPack among all permissive m",
    "path": "papers/23/08/2308.07124.json",
    "total_tokens": 853,
    "translated_title": "OctoPack: 使用指令调整代码的大规模语言模型",
    "translated_abstract": "在指令上进行大规模语言模型（LLMs）的微调可显著提高自然语言任务的性能。我们应用代码进行指令调整，利用Git提交的自然结构，将代码更改与人类指令配对。我们编译了CommitPack：跨350种编程语言的4TB Git提交。我们在拥有16B参数的StarCoder模型上对比CommitPack和其他自然与合成代码指令（xP3x, Self-Instruct, OASST），在HumanEval Python基准测试（46.2% pass@1）中取得了未在OpenAI输出上训练的模型中的最新性能。我们进一步推出HumanEvalPack，将HumanEval基准测试扩展到共计3个编码任务（代码修复、代码解释、代码合成）跨6种语言（Python、JavaScript、Java、Go、C ++、Rust）。我们的模型OctoCoder和OctoGeeX在HumanEvalPack中取得了所有许可模型中的最佳性能。",
    "tldr": "通过结合Git提交的自然结构，将代码更改与人类指令配对，我们提出了OctoPack，并在大规模语言模型上实现了表现最佳的指令调整方法。"
}