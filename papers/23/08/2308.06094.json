{
    "title": "Reinforcement Logic Rule Learning for Temporal Point Processes. (arXiv:2308.06094v1 [cs.LG])",
    "abstract": "We propose a framework that can incrementally expand the explanatory temporal logic rule set to explain the occurrence of temporal events. Leveraging the temporal point process modeling and learning framework, the rule content and weights will be gradually optimized until the likelihood of the observational event sequences is optimal. The proposed algorithm alternates between a master problem, where the current rule set weights are updated, and a subproblem, where a new rule is searched and included to best increase the likelihood. The formulated master problem is convex and relatively easy to solve using continuous optimization, whereas the subproblem requires searching the huge combinatorial rule predicate and relationship space. To tackle this challenge, we propose a neural search policy to learn to generate the new rule content as a sequence of actions. The policy parameters will be trained end-to-end using the reinforcement learning framework, where the reward signals can be effic",
    "link": "http://arxiv.org/abs/2308.06094",
    "context": "Title: Reinforcement Logic Rule Learning for Temporal Point Processes. (arXiv:2308.06094v1 [cs.LG])\nAbstract: We propose a framework that can incrementally expand the explanatory temporal logic rule set to explain the occurrence of temporal events. Leveraging the temporal point process modeling and learning framework, the rule content and weights will be gradually optimized until the likelihood of the observational event sequences is optimal. The proposed algorithm alternates between a master problem, where the current rule set weights are updated, and a subproblem, where a new rule is searched and included to best increase the likelihood. The formulated master problem is convex and relatively easy to solve using continuous optimization, whereas the subproblem requires searching the huge combinatorial rule predicate and relationship space. To tackle this challenge, we propose a neural search policy to learn to generate the new rule content as a sequence of actions. The policy parameters will be trained end-to-end using the reinforcement learning framework, where the reward signals can be effic",
    "path": "papers/23/08/2308.06094.json",
    "total_tokens": 854,
    "translated_title": "强化逻辑规则学习用于时间点过程",
    "translated_abstract": "我们提出了一个框架，可以逐步扩展解释性的时间逻辑规则集，以解释时间事件的发生。利用时间点过程建模和学习框架，规则内容和权重将逐渐优化，直到观测事件序列的似然性最优。所提出的算法在当前规则集权重更新的主问题和搜索并包含最佳增加似然性的新规则的子问题之间交替进行。所制定的主问题是凸的，使用连续优化相对容易求解，而子问题则需要搜索巨大的组合规则谓词和关系空间。为解决这个挑战，我们提出了一个神经搜索策略，学习生成新规则内容的一系列动作。策略参数将使用强化学习框架进行端到端训练，其中奖励信号可以高效地得到。",
    "tldr": "该论文提出了一个用于时间点过程的强化逻辑规则学习框架，利用逐步优化的方法扩展解释性的规则集来解释时间事件的发生。通过使用神经搜索策略和强化学习框架，可以高效地生成新的规则内容和权重。",
    "en_tdlr": "This paper proposes a reinforcement logic rule learning framework for temporal point processes, which incrementally expands an explanatory rule set to explain the occurrence of temporal events. By leveraging a neural search policy and reinforcement learning, new rule content and weights can be efficiently generated."
}