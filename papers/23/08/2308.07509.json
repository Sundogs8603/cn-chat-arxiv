{
    "title": "Boosting Semi-Supervised Learning by bridging high and low-confidence predictions. (arXiv:2308.07509v1 [cs.CV])",
    "abstract": "Pseudo-labeling is a crucial technique in semi-supervised learning (SSL), where artificial labels are generated for unlabeled data by a trained model, allowing for the simultaneous training of labeled and unlabeled data in a supervised setting. However, several studies have identified three main issues with pseudo-labeling-based approaches. Firstly, these methods heavily rely on predictions from the trained model, which may not always be accurate, leading to a confirmation bias problem. Secondly, the trained model may be overfitted to easy-to-learn examples, ignoring hard-to-learn ones, resulting in the \\textit{\"Matthew effect\"} where the already strong become stronger and the weak weaker. Thirdly, most of the low-confidence predictions of unlabeled data are discarded due to the use of a high threshold, leading to an underutilization of unlabeled data during training. To address these issues, we propose a new method called ReFixMatch, which aims to utilize all of the unlabeled data dur",
    "link": "http://arxiv.org/abs/2308.07509",
    "context": "Title: Boosting Semi-Supervised Learning by bridging high and low-confidence predictions. (arXiv:2308.07509v1 [cs.CV])\nAbstract: Pseudo-labeling is a crucial technique in semi-supervised learning (SSL), where artificial labels are generated for unlabeled data by a trained model, allowing for the simultaneous training of labeled and unlabeled data in a supervised setting. However, several studies have identified three main issues with pseudo-labeling-based approaches. Firstly, these methods heavily rely on predictions from the trained model, which may not always be accurate, leading to a confirmation bias problem. Secondly, the trained model may be overfitted to easy-to-learn examples, ignoring hard-to-learn ones, resulting in the \\textit{\"Matthew effect\"} where the already strong become stronger and the weak weaker. Thirdly, most of the low-confidence predictions of unlabeled data are discarded due to the use of a high threshold, leading to an underutilization of unlabeled data during training. To address these issues, we propose a new method called ReFixMatch, which aims to utilize all of the unlabeled data dur",
    "path": "papers/23/08/2308.07509.json",
    "total_tokens": 892,
    "translated_title": "通过连接高和低置信度的预测来提升半监督学习",
    "translated_abstract": "伪标签是半监督学习中的关键技术，通过训练模型为无标签数据生成人工标签，从而在监督设置下同时训练有标签和无标签数据。然而，一些研究发现伪标签方法存在三个主要问题。首先，这些方法严重依赖训练模型的预测，可能不总是准确，导致确认偏差问题。其次，训练模型可能对易学例子过拟合，忽视难学例子，从而导致“马太效应”，即强者更强，弱者更弱。第三，由于使用了高阈值，大部分无标签数据的低置信度预测被丢弃，导致训练时无标签数据的利用不足。为了解决这些问题，我们提出了一种新方法ReFixMatch，旨在充分利用所有无标签数据进行训练。",
    "tldr": "该论文提出了一种名为ReFixMatch的方法，通过连接高和低置信度的预测来解决半监督学习中的伪标签问题，并充分利用所有无标签数据进行训练。"
}