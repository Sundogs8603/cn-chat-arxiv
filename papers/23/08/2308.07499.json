{
    "title": "Detecting The Corruption Of Online Questionnaires By Artificial Intelligence. (arXiv:2308.07499v1 [cs.HC])",
    "abstract": "Online questionnaires that use crowd-sourcing platforms to recruit participants have become commonplace, due to their ease of use and low costs. Artificial Intelligence (AI) based Large Language Models (LLM) have made it easy for bad actors to automatically fill in online forms, including generating meaningful text for open-ended tasks. These technological advances threaten the data quality for studies that use online questionnaires. This study tested if text generated by an AI for the purpose of an online study can be detected by both humans and automatic AI detection systems. While humans were able to correctly identify authorship of text above chance level (76 percent accuracy), their performance was still below what would be required to ensure satisfactory data quality. Researchers currently have to rely on the disinterest of bad actors to successfully use open-ended responses as a useful tool for ensuring data quality. Automatic AI detection systems are currently completely unusab",
    "link": "http://arxiv.org/abs/2308.07499",
    "context": "Title: Detecting The Corruption Of Online Questionnaires By Artificial Intelligence. (arXiv:2308.07499v1 [cs.HC])\nAbstract: Online questionnaires that use crowd-sourcing platforms to recruit participants have become commonplace, due to their ease of use and low costs. Artificial Intelligence (AI) based Large Language Models (LLM) have made it easy for bad actors to automatically fill in online forms, including generating meaningful text for open-ended tasks. These technological advances threaten the data quality for studies that use online questionnaires. This study tested if text generated by an AI for the purpose of an online study can be detected by both humans and automatic AI detection systems. While humans were able to correctly identify authorship of text above chance level (76 percent accuracy), their performance was still below what would be required to ensure satisfactory data quality. Researchers currently have to rely on the disinterest of bad actors to successfully use open-ended responses as a useful tool for ensuring data quality. Automatic AI detection systems are currently completely unusab",
    "path": "papers/23/08/2308.07499.json",
    "total_tokens": 906,
    "translated_title": "人工智能检测在线问卷的篡改",
    "translated_abstract": "在线问卷使用众包平台招募参与者已经变得普遍，因为它们易于使用且成本低廉。基于人工智能的大型语言模型使得不良行为者能够自动填写在线表单，包括为开放性任务生成有意义的文本。这些技术进步威胁到使用在线问卷的研究的数据质量。本研究测试了人工智能生成的用于在线研究目的的文本是否可以被人类和自动人工智能检测系统检测出来。虽然人类能够正确辨别文本的作者身份（76%的准确率），但他们的表现仍然低于确保令人满意的数据质量所需的水平。目前，研究人员只能依赖不良行为者的不积极性来成功使用开放性回答作为确保数据质量的有用工具。自动人工智能检测系统目前无法使用。",
    "tldr": "这项研究发现，基于人工智能的大型语言模型使得不良行为者能够自动填写在线问卷，威胁到数据质量。目前，无法有效检测人工智能生成的文本，需要依赖不良行为者的不积极性来保证数据质量。"
}