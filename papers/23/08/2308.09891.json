{
    "title": "SwinLSTM:Improving Spatiotemporal Prediction Accuracy using Swin Transformer and LSTM. (arXiv:2308.09891v1 [cs.CV])",
    "abstract": "Integrating CNNs and RNNs to capture spatiotemporal dependencies is a prevalent strategy for spatiotemporal prediction tasks. However, the property of CNNs to learn local spatial information decreases their efficiency in capturing spatiotemporal dependencies, thereby limiting their prediction accuracy. In this paper, we propose a new recurrent cell, SwinLSTM, which integrates Swin Transformer blocks and the simplified LSTM, an extension that replaces the convolutional structure in ConvLSTM with the self-attention mechanism. Furthermore, we construct a network with SwinLSTM cell as the core for spatiotemporal prediction. Without using unique tricks, SwinLSTM outperforms state-of-the-art methods on Moving MNIST, Human3.6m, TaxiBJ, and KTH datasets. In particular, it exhibits a significant improvement in prediction accuracy compared to ConvLSTM. Our competitive experimental results demonstrate that learning global spatial dependencies is more advantageous for models to capture spatiotempo",
    "link": "http://arxiv.org/abs/2308.09891",
    "context": "Title: SwinLSTM:Improving Spatiotemporal Prediction Accuracy using Swin Transformer and LSTM. (arXiv:2308.09891v1 [cs.CV])\nAbstract: Integrating CNNs and RNNs to capture spatiotemporal dependencies is a prevalent strategy for spatiotemporal prediction tasks. However, the property of CNNs to learn local spatial information decreases their efficiency in capturing spatiotemporal dependencies, thereby limiting their prediction accuracy. In this paper, we propose a new recurrent cell, SwinLSTM, which integrates Swin Transformer blocks and the simplified LSTM, an extension that replaces the convolutional structure in ConvLSTM with the self-attention mechanism. Furthermore, we construct a network with SwinLSTM cell as the core for spatiotemporal prediction. Without using unique tricks, SwinLSTM outperforms state-of-the-art methods on Moving MNIST, Human3.6m, TaxiBJ, and KTH datasets. In particular, it exhibits a significant improvement in prediction accuracy compared to ConvLSTM. Our competitive experimental results demonstrate that learning global spatial dependencies is more advantageous for models to capture spatiotempo",
    "path": "papers/23/08/2308.09891.json",
    "total_tokens": 902,
    "translated_title": "SwinLSTM：使用Swin Transformer和LSTM提高时空预测准确性",
    "translated_abstract": "将CNN和RNN集成以捕捉时空依赖关系是时空预测任务中常用的策略。然而，CNN学习局部空间信息的属性降低了它们在捕捉时空依赖关系方面的效率，从而限制了它们的预测准确性。本文提出了一种新的循环单元SwinLSTM，它将Swin Transformer块和简化的LSTM集成在一起，将ConvLSTM中的卷积结构替换为自注意机制。此外，我们构建了一个以SwinLSTM单元为核心的时空预测网络。SwinLSTM在Moving MNIST，Human3.6m，TaxiBJ和KTH数据集上表现比最先进的方法更好，特别是在预测准确性方面有显著提高。我们的竞争性实验结果表明，学习全局空间依赖关系对于模型捕捉时空依赖关系更有优势。",
    "tldr": "SwinLSTM是一种将Swin Transformer和LSTM结合起来以提高时空预测准确性的新循环单元，在四个数据集上表现出优越的性能，特别是在预测准确性方面有显著提高。",
    "en_tdlr": "SwinLSTM is a new recurrent cell that combines Swin Transformer and LSTM to improve spatiotemporal prediction accuracy. It outperforms state-of-the-art methods on four datasets, particularly showing significant improvement in prediction accuracy."
}