{
    "title": "Heterogeneous Decentralized Machine Unlearning with Seed Model Distillation. (arXiv:2308.13269v1 [cs.LG])",
    "abstract": "As some recent information security legislation endowed users with unconditional rights to be forgotten by any trained machine learning model, personalized IoT service providers have to put unlearning functionality into their consideration. The most straightforward method to unlearn users' contribution is to retrain the model from the initial state, which is not realistic in high throughput applications with frequent unlearning requests. Though some machine unlearning frameworks have been proposed to speed up the retraining process, they fail to match decentralized learning scenarios. In this paper, we design a decentralized unlearning framework called HDUS, which uses distilled seed models to construct erasable ensembles for all clients. Moreover, the framework is compatible with heterogeneous on-device models, representing stronger scalability in real-world applications. Extensive experiments on three real-world datasets show that our HDUS achieves state-of-the-art performance.",
    "link": "http://arxiv.org/abs/2308.13269",
    "context": "Title: Heterogeneous Decentralized Machine Unlearning with Seed Model Distillation. (arXiv:2308.13269v1 [cs.LG])\nAbstract: As some recent information security legislation endowed users with unconditional rights to be forgotten by any trained machine learning model, personalized IoT service providers have to put unlearning functionality into their consideration. The most straightforward method to unlearn users' contribution is to retrain the model from the initial state, which is not realistic in high throughput applications with frequent unlearning requests. Though some machine unlearning frameworks have been proposed to speed up the retraining process, they fail to match decentralized learning scenarios. In this paper, we design a decentralized unlearning framework called HDUS, which uses distilled seed models to construct erasable ensembles for all clients. Moreover, the framework is compatible with heterogeneous on-device models, representing stronger scalability in real-world applications. Extensive experiments on three real-world datasets show that our HDUS achieves state-of-the-art performance.",
    "path": "papers/23/08/2308.13269.json",
    "total_tokens": 880,
    "translated_title": "异构分布式机器遗忘和种子模型蒸馏",
    "translated_abstract": "随着一些最近的信息安全法规赋予用户对任何经过训练的机器学习模型拥有被遗忘的无条件权利，个性化物联网服务提供商必须考虑到遗忘功能。取消学习用户贡献的最直接方法是从初始状态重新训练模型，但在频繁的遗忘请求中，这在高吞吐量应用中是不现实的。尽管提出了一些机器遗忘框架来加速重新训练过程，但它们无法适应分布式学习场景。本文中，我们设计了一个名为HDUS的分布式遗忘框架，它使用蒸馏的种子模型为所有客户端构建可擦除的集成模型。此外，该框架与异构的设备端模型兼容，具有更强的可伸缩性，适用于真实世界的应用。在三个真实数据集上的大量实验表明，我们的HDUS实现了最先进的性能。",
    "tldr": "该论文介绍了一种名为HDUS的分布式遗忘框架，使用种子模型蒸馏构建可擦除的模型集成，适用于异构的设备端模型，具有卓越的性能。",
    "en_tdlr": "This paper presents a decentralized unlearning framework called HDUS, which utilizes seed model distillation to construct erasable ensembles, compatible with heterogeneous on-device models, and achieves state-of-the-art performance."
}