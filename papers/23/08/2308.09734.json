{
    "title": "A Robust Policy Bootstrapping Algorithm for Multi-objective Reinforcement Learning in Non-stationary Environments. (arXiv:2308.09734v1 [cs.LG])",
    "abstract": "Multi-objective Markov decision processes are a special kind of multi-objective optimization problem that involves sequential decision making while satisfying the Markov property of stochastic processes. Multi-objective reinforcement learning methods address this problem by fusing the reinforcement learning paradigm with multi-objective optimization techniques. One major drawback of these methods is the lack of adaptability to non-stationary dynamics in the environment. This is because they adopt optimization procedures that assume stationarity to evolve a coverage set of policies that can solve the problem. This paper introduces a developmental optimization approach that can evolve the policy coverage set while exploring the preference space over the defined objectives in an online manner. We propose a novel multi-objective reinforcement learning algorithm that can robustly evolve a convex coverage set of policies in an online manner in non-stationary environments. We compare the prop",
    "link": "http://arxiv.org/abs/2308.09734",
    "context": "Title: A Robust Policy Bootstrapping Algorithm for Multi-objective Reinforcement Learning in Non-stationary Environments. (arXiv:2308.09734v1 [cs.LG])\nAbstract: Multi-objective Markov decision processes are a special kind of multi-objective optimization problem that involves sequential decision making while satisfying the Markov property of stochastic processes. Multi-objective reinforcement learning methods address this problem by fusing the reinforcement learning paradigm with multi-objective optimization techniques. One major drawback of these methods is the lack of adaptability to non-stationary dynamics in the environment. This is because they adopt optimization procedures that assume stationarity to evolve a coverage set of policies that can solve the problem. This paper introduces a developmental optimization approach that can evolve the policy coverage set while exploring the preference space over the defined objectives in an online manner. We propose a novel multi-objective reinforcement learning algorithm that can robustly evolve a convex coverage set of policies in an online manner in non-stationary environments. We compare the prop",
    "path": "papers/23/08/2308.09734.json",
    "total_tokens": 802,
    "translated_title": "一种适用于非静态环境中多目标强化学习的稳健策略引导算法",
    "translated_abstract": "多目标马尔可夫决策过程是一类需要满足马尔可夫随机过程特性的序贯决策问题。多目标强化学习方法通过融合强化学习和多目标优化技术来解决这个问题。然而，这些方法在处理非静态环境时适应性不足。本文引入了一种发展性优化方法，可以在线探索定义的目标偏好空间，同时演化策略覆盖集。我们提出了一种新颖的多目标强化学习算法，可以在非静态环境中稳健地在线演化一个凸覆盖策略集。",
    "tldr": "提出了一种适用于非静态环境中多目标强化学习的稳健策略引导算法，能够在线演化一个凸覆盖策略集，同时满足目标偏好空间的探索需求。",
    "en_tdlr": "This paper presents a robust policy bootstrapping algorithm for multi-objective reinforcement learning in non-stationary environments, which can evolve a convex coverage set of policies online while exploring the preference space over the defined objectives."
}