{
    "title": "A Safe Deep Reinforcement Learning Approach for Energy Efficient Federated Learning in Wireless Communication Networks",
    "abstract": "arXiv:2308.10664v3 Announce Type: replace-cross  Abstract: Progressing towards a new era of Artificial Intelligence (AI) - enabled wireless networks, concerns regarding the environmental impact of AI have been raised both in industry and academia. Federated Learning (FL) has emerged as a key privacy preserving decentralized AI technique. Despite efforts currently being made in FL, its environmental impact is still an open problem. Targeting the minimization of the overall energy consumption of an FL process, we propose the orchestration of computational and communication resources of the involved devices to minimize the total energy required, while guaranteeing a certain performance of the model. To this end, we propose a Soft Actor Critic Deep Reinforcement Learning (DRL) solution, where a penalty function is introduced during training, penalizing the strategies that violate the constraints of the environment, and contributing towards a safe RL process. A device level synchronization ",
    "link": "https://arxiv.org/abs/2308.10664",
    "context": "Title: A Safe Deep Reinforcement Learning Approach for Energy Efficient Federated Learning in Wireless Communication Networks\nAbstract: arXiv:2308.10664v3 Announce Type: replace-cross  Abstract: Progressing towards a new era of Artificial Intelligence (AI) - enabled wireless networks, concerns regarding the environmental impact of AI have been raised both in industry and academia. Federated Learning (FL) has emerged as a key privacy preserving decentralized AI technique. Despite efforts currently being made in FL, its environmental impact is still an open problem. Targeting the minimization of the overall energy consumption of an FL process, we propose the orchestration of computational and communication resources of the involved devices to minimize the total energy required, while guaranteeing a certain performance of the model. To this end, we propose a Soft Actor Critic Deep Reinforcement Learning (DRL) solution, where a penalty function is introduced during training, penalizing the strategies that violate the constraints of the environment, and contributing towards a safe RL process. A device level synchronization ",
    "path": "papers/23/08/2308.10664.json",
    "total_tokens": 844,
    "translated_title": "一种用于无线通信网络中能源高效联邦学习的安全深度强化学习方法",
    "translated_abstract": "向着人工智能（AI）赋能的无线网络新时代迈进，行业和学术界对AI的环境影响提出了关注。联邦学习（FL）作为一种关键的隐私保护的分散式AI技术已经出现。尽管目前在FL方面已经做出努力，但其环境影响仍然是一个尚未解决的问题。为了最小化FL过程的总能耗，我们提出了编排参与设备的计算和通信资源，以最小化所需的总能量，同时保证模型的一定性能。为此，我们提出了一种Soft Actor Critic Deep Reinforcement Learning (DRL)解决方案，在训练过程中引入了一种惩罚函数，惩罚违反环境约束的策略，有助于实现安全的RL过程。",
    "tldr": "提出一种新的安全深度强化学习方法，利用惩罚函数在训练时惩罚违反环境约束的策略，以确保无线通信网络中能源高效联邦学习的总能耗最小化。",
    "en_tdlr": "Introducing a novel safe deep reinforcement learning approach with a penalty function during training to penalize strategies violating environment constraints, aiming to minimize total energy consumption for energy efficient federated learning in wireless communication networks."
}