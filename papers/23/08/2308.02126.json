{
    "title": "Semantics-guided Transformer-based Sensor Fusion for Improved Waypoint Prediction. (arXiv:2308.02126v1 [cs.RO])",
    "abstract": "Sensor fusion approaches for intelligent self-driving agents remain key to driving scene understanding given visual global contexts acquired from input sensors. Specifically, for the local waypoint prediction task, single-modality networks are still limited by strong dependency on the sensitivity of the input sensor, and thus recent works promote the use of multiple sensors in fusion in feature level. While it is well known that multiple data modalities promote mutual contextual exchange, deployment to practical driving scenarios requires global 3D scene understanding in real-time with minimal computations, thus placing greater significance on training strategies given a limited number of practically usable sensors. In this light, we exploit carefully selected auxiliary tasks that are highly correlated with the target task of interest (e.g., traffic light recognition and semantic segmentation) by fusing auxiliary task features and also using auxiliary heads for waypoint prediction base",
    "link": "http://arxiv.org/abs/2308.02126",
    "context": "Title: Semantics-guided Transformer-based Sensor Fusion for Improved Waypoint Prediction. (arXiv:2308.02126v1 [cs.RO])\nAbstract: Sensor fusion approaches for intelligent self-driving agents remain key to driving scene understanding given visual global contexts acquired from input sensors. Specifically, for the local waypoint prediction task, single-modality networks are still limited by strong dependency on the sensitivity of the input sensor, and thus recent works promote the use of multiple sensors in fusion in feature level. While it is well known that multiple data modalities promote mutual contextual exchange, deployment to practical driving scenarios requires global 3D scene understanding in real-time with minimal computations, thus placing greater significance on training strategies given a limited number of practically usable sensors. In this light, we exploit carefully selected auxiliary tasks that are highly correlated with the target task of interest (e.g., traffic light recognition and semantic segmentation) by fusing auxiliary task features and also using auxiliary heads for waypoint prediction base",
    "path": "papers/23/08/2308.02126.json",
    "total_tokens": 855,
    "translated_title": "基于语义引导的基于Transformer的传感器融合方法改进航点预测",
    "translated_abstract": "对于智能自动驾驶代理来说，传感器融合方法仍然是驾驶场景理解的关键，通过从输入传感器获取的视觉全局环境。具体而言，对于局部航点预测任务，单模态网络仍然受限于对输入传感器的灵敏度的强依赖性，因此最近的工作推广了在特征级别上融合多个传感器的使用。虽然众所周知多个数据模态能促进相互的上下文交互，但在实际驾驶场景中实时进行全局三维场景理解并进行最小计算，因此在给定有限数量的可实际使用的传感器的情况下，对训练策略的重要性更加突出。在这一背景下，我们通过融合与目标任务（如交通灯识别和语义分割）高度相关的精心选取的辅助任务特征，并使用辅助头为航点预测进行了利用。",
    "tldr": "该论文提出一种基于语义引导的传感器融合方法，通过融合多个传感器的特征和使用辅助任务来改进自动驾驶代理的航点预测。",
    "en_tdlr": "This paper proposes a semantics-guided sensor fusion method that improves waypoint prediction for self-driving agents by fusing features from multiple sensors and utilizing auxiliary tasks."
}