{
    "title": "Surrogate Empowered Sim2Real Transfer of Deep Reinforcement Learning for ORC Superheat Control. (arXiv:2308.02765v1 [eess.SY])",
    "abstract": "The Organic Rankine Cycle (ORC) is widely used in industrial waste heat recovery due to its simple structure and easy maintenance. However, in the context of smart manufacturing in the process industry, traditional model-based optimization control methods are unable to adapt to the varying operating conditions of the ORC system or sudden changes in operating modes. Deep reinforcement learning (DRL) has significant advantages in situations with uncertainty as it directly achieves control objectives by interacting with the environment without requiring an explicit model of the controlled plant. Nevertheless, direct application of DRL to physical ORC systems presents unacceptable safety risks, and its generalization performance under model-plant mismatch is insufficient to support ORC control requirements. Therefore, this paper proposes a Sim2Real transfer learning-based DRL control method for ORC superheat control, which aims to provide a new simple, feasible, and user-friendly solution ",
    "link": "http://arxiv.org/abs/2308.02765",
    "context": "Title: Surrogate Empowered Sim2Real Transfer of Deep Reinforcement Learning for ORC Superheat Control. (arXiv:2308.02765v1 [eess.SY])\nAbstract: The Organic Rankine Cycle (ORC) is widely used in industrial waste heat recovery due to its simple structure and easy maintenance. However, in the context of smart manufacturing in the process industry, traditional model-based optimization control methods are unable to adapt to the varying operating conditions of the ORC system or sudden changes in operating modes. Deep reinforcement learning (DRL) has significant advantages in situations with uncertainty as it directly achieves control objectives by interacting with the environment without requiring an explicit model of the controlled plant. Nevertheless, direct application of DRL to physical ORC systems presents unacceptable safety risks, and its generalization performance under model-plant mismatch is insufficient to support ORC control requirements. Therefore, this paper proposes a Sim2Real transfer learning-based DRL control method for ORC superheat control, which aims to provide a new simple, feasible, and user-friendly solution ",
    "path": "papers/23/08/2308.02765.json",
    "total_tokens": 925,
    "translated_title": "基于模拟到真实转移学习的深度强化学习用于ORC超热控制",
    "translated_abstract": "有机朗肯循环(ORC)由于其简单的结构和易于维护，被广泛应用于工业余热回收中。然而，在过程工业的智能制造环境下，传统的基于模型的优化控制方法无法适应ORC系统中不断变化的工况或突发工作模式的改变。深度强化学习(DRL)在存在不确定性的情况下具有显著优势，它通过与环境进行交互来直接实现控制目标，而无需对受控系统进行精确建模。然而，直接将DRL应用于物理ORC系统存在不可接受的安全风险，并且在模型与实际受控环境不匹配的情况下，其泛化能力不足以支持ORC控制需求。因此，本文提出了一种基于模拟到真实转移学习的DRL控制方法，用于ORC超热控制，旨在提供一种新的简单、可行且用户友好的解决方案。",
    "tldr": "本文提出了一种基于模拟到真实转移学习的深度强化学习控制方法，用于 ORC 超热控制。该方法旨在提供一种新的简单、可行且用户友好的解决方案。",
    "en_tdlr": "This paper proposes a Sim2Real transfer learning-based deep reinforcement learning (DRL) control method for ORC superheat control. It aims to provide a new simple, feasible, and user-friendly solution."
}