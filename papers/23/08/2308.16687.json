{
    "title": "DictaBERT: A State-of-the-Art BERT Suite for Modern Hebrew. (arXiv:2308.16687v1 [cs.CL])",
    "abstract": "We present DictaBERT, a new state-of-the-art pre-trained BERT model for modern Hebrew, outperforming existing models on most benchmarks. Additionally, we release two fine-tuned versions of the model, designed to perform two specific foundational tasks in the analysis of Hebrew texts: prefix segmentation and morphological tagging. These fine-tuned models allow any developer to perform prefix segmentation and morphological tagging of a Hebrew sentence with a single call to a HuggingFace model, without the need to integrate any additional libraries or code. In this paper we describe the details of the training as well and the results on the different benchmarks. We release the models to the community, along with sample code demonstrating their use. We release these models as part of our goal to help further research and development in Hebrew NLP.",
    "link": "http://arxiv.org/abs/2308.16687",
    "context": "Title: DictaBERT: A State-of-the-Art BERT Suite for Modern Hebrew. (arXiv:2308.16687v1 [cs.CL])\nAbstract: We present DictaBERT, a new state-of-the-art pre-trained BERT model for modern Hebrew, outperforming existing models on most benchmarks. Additionally, we release two fine-tuned versions of the model, designed to perform two specific foundational tasks in the analysis of Hebrew texts: prefix segmentation and morphological tagging. These fine-tuned models allow any developer to perform prefix segmentation and morphological tagging of a Hebrew sentence with a single call to a HuggingFace model, without the need to integrate any additional libraries or code. In this paper we describe the details of the training as well and the results on the different benchmarks. We release the models to the community, along with sample code demonstrating their use. We release these models as part of our goal to help further research and development in Hebrew NLP.",
    "path": "papers/23/08/2308.16687.json",
    "total_tokens": 914,
    "translated_title": "DictaBERT: 一款用于现代希伯来语的最先进BERT套件的翻译标题",
    "translated_abstract": "我们提出了DictaBERT，这是一种用于现代希伯来语的最先进的预训练BERT模型，在大多数基准测试中表现优于现有模型。此外，我们发布了两个经过微调的模型版本，旨在执行希伯来语文本分析的两个特定基本任务：前缀分割和形态标注。这些经过微调的模型允许任何开发人员只需调用HuggingFace模型一次即可对希伯来语句子进行前缀分割和形态标注，无需集成任何额外的库或代码。在本文中，我们描述了训练的细节以及在不同基准测试上的结果。我们将这些模型与展示其使用的示例代码一起发布给社区。我们发布这些模型是为了帮助进一步促进希伯来语自然语言处理的研究和发展。",
    "tldr": "DictaBERT是一种最先进的预训练BERT模型，针对现代希伯来语，在大多数基准测试中表现优于其他模型。它还提供了两个经过微调的模型版本，可用于希伯来语文本分析中的前缀分割和形态标注任务。这些模型的发布旨在促进希伯来语自然语言处理的研究和发展。",
    "en_tdlr": "DictaBERT is a state-of-the-art pre-trained BERT model for modern Hebrew, outperforming existing models on most benchmarks. It also provides two fine-tuned versions for prefix segmentation and morphological tagging tasks in Hebrew text analysis. The release of these models aims to foster research and development in Hebrew NLP."
}