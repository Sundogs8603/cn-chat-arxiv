{
    "title": "Expressivity of Graph Neural Networks Through the Lens of Adversarial Robustness. (arXiv:2308.08173v1 [cs.LG])",
    "abstract": "We perform the first adversarial robustness study into Graph Neural Networks (GNNs) that are provably more powerful than traditional Message Passing Neural Networks (MPNNs). In particular, we use adversarial robustness as a tool to uncover a significant gap between their theoretically possible and empirically achieved expressive power. To do so, we focus on the ability of GNNs to count specific subgraph patterns, which is an established measure of expressivity, and extend the concept of adversarial robustness to this task. Based on this, we develop efficient adversarial attacks for subgraph counting and show that more powerful GNNs fail to generalize even to small perturbations to the graph's structure. Expanding on this, we show that such architectures also fail to count substructures on out-of-distribution graphs.",
    "link": "http://arxiv.org/abs/2308.08173",
    "context": "Title: Expressivity of Graph Neural Networks Through the Lens of Adversarial Robustness. (arXiv:2308.08173v1 [cs.LG])\nAbstract: We perform the first adversarial robustness study into Graph Neural Networks (GNNs) that are provably more powerful than traditional Message Passing Neural Networks (MPNNs). In particular, we use adversarial robustness as a tool to uncover a significant gap between their theoretically possible and empirically achieved expressive power. To do so, we focus on the ability of GNNs to count specific subgraph patterns, which is an established measure of expressivity, and extend the concept of adversarial robustness to this task. Based on this, we develop efficient adversarial attacks for subgraph counting and show that more powerful GNNs fail to generalize even to small perturbations to the graph's structure. Expanding on this, we show that such architectures also fail to count substructures on out-of-distribution graphs.",
    "path": "papers/23/08/2308.08173.json",
    "total_tokens": 824,
    "translated_title": "通过对抗鲁棒性研究，揭示图神经网络的表达能力",
    "translated_abstract": "我们首次对图神经网络（GNNs）进行了对抗鲁棒性研究，证明它们在表达能力上比传统的消息传递神经网络（MPNNs）更强大。具体而言，我们使用对抗鲁棒性作为一种工具来揭示它们在理论上可能和经验上实际达到的表达能力之间的显著差距。为此，我们关注GNNs计数特定的子图模式的能力，这是一种已建立的表达能力度量，将对抗鲁棒性的概念扩展到这个任务上。基于此，我们开发了高效的对抗攻击方法来进行子图计数，并展示更强大的GNNs即使在对图结构的小扰动下也无法泛化。在此基础上，我们还表明这样的架构在处理分布不一样的图时也无法计数子结构。",
    "tldr": "通过对抗鲁棒性研究，揭示了图神经网络的表达能力与传统消息传递神经网络之间的显著差距，并证明了更强大的GNNs无法泛化到小扰动的图结构和分布不一样的图。"
}