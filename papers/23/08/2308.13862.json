{
    "title": "Late Stopping: Avoiding Confidently Learning from Mislabeled Examples. (arXiv:2308.13862v1 [cs.LG])",
    "abstract": "Sample selection is a prevalent method in learning with noisy labels, where small-loss data are typically considered as correctly labeled data. However, this method may not effectively identify clean hard examples with large losses, which are critical for achieving the model's close-to-optimal generalization performance. In this paper, we propose a new framework, Late Stopping, which leverages the intrinsic robust learning ability of DNNs through a prolonged training process. Specifically, Late Stopping gradually shrinks the noisy dataset by removing high-probability mislabeled examples while retaining the majority of clean hard examples in the training set throughout the learning process. We empirically observe that mislabeled and clean examples exhibit differences in the number of epochs required for them to be consistently and correctly classified, and thus high-probability mislabeled examples can be removed. Experimental results on benchmark-simulated and real-world noisy datasets ",
    "link": "http://arxiv.org/abs/2308.13862",
    "context": "Title: Late Stopping: Avoiding Confidently Learning from Mislabeled Examples. (arXiv:2308.13862v1 [cs.LG])\nAbstract: Sample selection is a prevalent method in learning with noisy labels, where small-loss data are typically considered as correctly labeled data. However, this method may not effectively identify clean hard examples with large losses, which are critical for achieving the model's close-to-optimal generalization performance. In this paper, we propose a new framework, Late Stopping, which leverages the intrinsic robust learning ability of DNNs through a prolonged training process. Specifically, Late Stopping gradually shrinks the noisy dataset by removing high-probability mislabeled examples while retaining the majority of clean hard examples in the training set throughout the learning process. We empirically observe that mislabeled and clean examples exhibit differences in the number of epochs required for them to be consistently and correctly classified, and thus high-probability mislabeled examples can be removed. Experimental results on benchmark-simulated and real-world noisy datasets ",
    "path": "papers/23/08/2308.13862.json",
    "total_tokens": 901,
    "translated_title": "停止学习：避免自信地从错误标记的示例中学习",
    "translated_abstract": "在具有噪声标签的学习中，样本选择是一种常见的方法，通常将小损失的数据视为正确标记的数据。然而，这种方法可能无法有效地识别出具有较大损失的干净困难示例，这对于实现模型接近最优泛化性能至关重要。在本文中，我们提出了一种新的框架——停止学习，通过一个长时间的训练过程，利用深度神经网络的内在鲁棒学习能力。具体而言，停止学习通过逐渐移除高概率错误标记示例来缩小噪声数据集，同时在整个学习过程中保留大多数干净困难示例在训练集中。我们在实证中观察到错误标记和干净示例在被一致和正确分类所需的周期数方面存在差异，因此可以移除高概率错误标记示例。在基准模拟和真实世界的噪声数据集上进行的实验结果表明……",
    "tldr": "本文提出了一种新的框架，称为停止学习，通过移除高概率错误标记示例来缩小噪声数据集，同时保留大多数干净困难示例，以提高模型的最优泛化性能。",
    "en_tdlr": "This paper proposes a new framework called Late Stopping, which reduces noisy datasets by removing high-probability mislabeled examples while retaining most clean hard examples to achieve optimal generalization performance."
}