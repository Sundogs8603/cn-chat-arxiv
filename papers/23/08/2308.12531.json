{
    "title": "CARE: Co-Attention Network for Joint Entity and Relation Extraction. (arXiv:2308.12531v1 [cs.CL])",
    "abstract": "Joint entity and relation extraction is the fundamental task of information extraction, consisting of two subtasks: named entity recognition and relation extraction. Most existing joint extraction methods suffer from issues of feature confusion or inadequate interaction between two subtasks. In this work, we propose a Co-Attention network for joint entity and Relation Extraction (CARE). Our approach involves learning separate representations for each subtask, aiming to avoid feature overlap. At the core of our approach is the co-attention module that captures two-way interaction between two subtasks, allowing the model to leverage entity information for relation prediction and vice versa, thus promoting mutual enhancement. Extensive experiments on three joint entity-relation extraction benchmark datasets (NYT, WebNLG and SciERC) show that our proposed model achieves superior performance, surpassing existing baseline models.",
    "link": "http://arxiv.org/abs/2308.12531",
    "context": "Title: CARE: Co-Attention Network for Joint Entity and Relation Extraction. (arXiv:2308.12531v1 [cs.CL])\nAbstract: Joint entity and relation extraction is the fundamental task of information extraction, consisting of two subtasks: named entity recognition and relation extraction. Most existing joint extraction methods suffer from issues of feature confusion or inadequate interaction between two subtasks. In this work, we propose a Co-Attention network for joint entity and Relation Extraction (CARE). Our approach involves learning separate representations for each subtask, aiming to avoid feature overlap. At the core of our approach is the co-attention module that captures two-way interaction between two subtasks, allowing the model to leverage entity information for relation prediction and vice versa, thus promoting mutual enhancement. Extensive experiments on three joint entity-relation extraction benchmark datasets (NYT, WebNLG and SciERC) show that our proposed model achieves superior performance, surpassing existing baseline models.",
    "path": "papers/23/08/2308.12531.json",
    "total_tokens": 873,
    "translated_title": "CARE: 用于联合实体和关系抽取的共同注意力网络",
    "translated_abstract": "联合实体和关系抽取是信息抽取的基本任务，包括两个子任务：命名实体识别和关系抽取。大多数现有的联合抽取方法都存在特征混淆或两个子任务之间交互不足的问题。在这项工作中，我们提出了一种用于联合实体和关系抽取的共同注意力网络（CARE）。我们的方法涉及学习每个子任务的分离表示，旨在避免特征重叠。我们的方法的核心是共同注意力模块，它捕捉两个子任务之间的双向交互，使模型能够利用实体信息进行关系预测，反之亦然，从而促进相互增强。在三个联合实体-关系抽取基准数据集（NYT、WebNLG和SciERC）上的广泛实验表明，我们提出的模型达到了卓越的性能，超过了现有的基线模型。",
    "tldr": "本论文提出了一种用于联合实体和关系抽取的共同注意力网络（CARE），通过学习分离表示和双向交互来解决特征混淆和子任务交互不足的问题，实验表明该模型在多个基准数据集上具有优越性能。",
    "en_tdlr": "This paper proposes a Co-Attention network for joint entity and relation extraction (CARE), which addresses the issues of feature confusion and inadequate interaction between subtasks through learning separate representations and two-way interaction, and achieves superior performance on multiple benchmark datasets."
}