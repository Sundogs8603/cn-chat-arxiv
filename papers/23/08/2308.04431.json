{
    "title": "When More is Less: Incorporating Additional Datasets Can Hurt Performance By Introducing Spurious Correlations. (arXiv:2308.04431v1 [cs.LG])",
    "abstract": "In machine learning, incorporating more data is often seen as a reliable strategy for improving model performance; this work challenges that notion by demonstrating that the addition of external datasets in many cases can hurt the resulting model's performance. In a large-scale empirical study across combinations of four different open-source chest x-ray datasets and 9 different labels, we demonstrate that in 43% of settings, a model trained on data from two hospitals has poorer worst group accuracy over both hospitals than a model trained on just a single hospital's data. This surprising result occurs even though the added hospital makes the training distribution more similar to the test distribution. We explain that this phenomenon arises from the spurious correlation that emerges between the disease and hospital, due to hospital-specific image artifacts. We highlight the trade-off one encounters when training on multiple datasets, between the obvious benefit of additional data and i",
    "link": "http://arxiv.org/abs/2308.04431",
    "context": "Title: When More is Less: Incorporating Additional Datasets Can Hurt Performance By Introducing Spurious Correlations. (arXiv:2308.04431v1 [cs.LG])\nAbstract: In machine learning, incorporating more data is often seen as a reliable strategy for improving model performance; this work challenges that notion by demonstrating that the addition of external datasets in many cases can hurt the resulting model's performance. In a large-scale empirical study across combinations of four different open-source chest x-ray datasets and 9 different labels, we demonstrate that in 43% of settings, a model trained on data from two hospitals has poorer worst group accuracy over both hospitals than a model trained on just a single hospital's data. This surprising result occurs even though the added hospital makes the training distribution more similar to the test distribution. We explain that this phenomenon arises from the spurious correlation that emerges between the disease and hospital, due to hospital-specific image artifacts. We highlight the trade-off one encounters when training on multiple datasets, between the obvious benefit of additional data and i",
    "path": "papers/23/08/2308.04431.json",
    "total_tokens": 959,
    "translated_title": "当越多越少：引入额外数据集可能通过引入虚假相关性来降低性能",
    "translated_abstract": "在机器学习中，引入更多数据通常被视为提高模型性能的可靠策略；本研究挑战了这一观念，通过证明在许多情况下，引入外部数据集可能会损害所得模型的性能。通过对四个不同开源胸部X光数据集和9个不同标签的组合进行大规模经验研究，我们证明在43%的设置中，仅使用单个医院的数据进行训练的模型在两个医院上的最差组准确率都比使用两个医院的数据进行训练的模型要低。即使添加的医院使训练分布更接近测试分布，这一令人惊讶的结果仍会出现。我们解释了这种现象是由于与疾病和医院之间的虚假相关性产生，这是由于医院特定的图像伪像引起的。我们强调了在训练多个数据集时所遇到的折衷取舍，即额外数据的明显好处和虚假相关性引入的性能损失之间的平衡。",
    "tldr": "引入额外数据集可能会通过引入虚假相关性来降低性能，即使添加的数据使训练分布更接近测试分布。这种现象是由于医院特定的图像伪像引起的。这一结果挑战了常见的认为更多数据能提高模型性能的观念。"
}