{
    "title": "LimeAttack: Local Explainable Method for Textual Hard-Label Adversarial Attack. (arXiv:2308.00319v1 [cs.CL])",
    "abstract": "Natural language processing models are vulnerable to adversarial examples. Previous textual adversarial attacks adopt gradients or confidence scores to calculate word importance ranking and generate adversarial examples. However, this information is unavailable in the real world. Therefore, we focus on a more realistic and challenging setting, named hard-label attack, in which the attacker can only query the model and obtain a discrete prediction label. Existing hard-label attack algorithms tend to initialize adversarial examples by random substitution and then utilize complex heuristic algorithms to optimize the adversarial perturbation. These methods require a lot of model queries and the attack success rate is restricted by adversary initialization. In this paper, we propose a novel hard-label attack algorithm named LimeAttack, which leverages a local explainable method to approximate word importance ranking, and then adopts beam search to find the optimal solution. Extensive experi",
    "link": "http://arxiv.org/abs/2308.00319",
    "context": "Title: LimeAttack: Local Explainable Method for Textual Hard-Label Adversarial Attack. (arXiv:2308.00319v1 [cs.CL])\nAbstract: Natural language processing models are vulnerable to adversarial examples. Previous textual adversarial attacks adopt gradients or confidence scores to calculate word importance ranking and generate adversarial examples. However, this information is unavailable in the real world. Therefore, we focus on a more realistic and challenging setting, named hard-label attack, in which the attacker can only query the model and obtain a discrete prediction label. Existing hard-label attack algorithms tend to initialize adversarial examples by random substitution and then utilize complex heuristic algorithms to optimize the adversarial perturbation. These methods require a lot of model queries and the attack success rate is restricted by adversary initialization. In this paper, we propose a novel hard-label attack algorithm named LimeAttack, which leverages a local explainable method to approximate word importance ranking, and then adopts beam search to find the optimal solution. Extensive experi",
    "path": "papers/23/08/2308.00319.json",
    "total_tokens": 844,
    "translated_title": "LimeAttack: 本地可解释方法用于文本硬标签对抗性攻击",
    "translated_abstract": "自然语言处理模型容易受到对抗性样本的攻击。先前的文本对抗性攻击采用梯度或置信度分数来计算单词重要性排序，并生成对抗性样本。然而，在现实世界中，这些信息是不可用的。因此，我们将重点放在一个更现实和具有挑战性的场景上，名为硬标签攻击，其中攻击者只能查询模型并获取离散的预测标签。现有的硬标签攻击算法往往通过随机替换来初始化对抗性样本，然后利用复杂的启发式算法来优化对抗扰动。这些方法需要大量的模型查询，并且攻击成功率受到对手初始化的限制。在本文中，我们提出了一种名为LimeAttack的新型硬标签攻击算法，它利用本地可解释方法来近似单词重要性排序，然后采用波束搜索来找到最优解。",
    "tldr": "本文提出了一种名为LimeAttack的硬标签攻击算法，通过本地可解释方法来近似单词重要性排序，然后利用波束搜索找到最优解。"
}