{
    "title": "Squeeze aggregated excitation network. (arXiv:2308.13343v1 [cs.CV])",
    "abstract": "Convolutional neural networks have spatial representations which read patterns in the vision tasks. Squeeze and excitation links the channel wise representations by explicitly modeling on channel level. Multi layer perceptrons learn global representations and in most of the models it is used often at the end after all convolutional layers to gather all the information learned before classification. We propose a method of inducing the global representations within channels to have better performance of the model. We propose SaEnet, Squeeze aggregated excitation network, for learning global channelwise representation in between layers. The proposed module takes advantage of passing important information after squeeze by having aggregated excitation before regaining its shape. We also introduce a new idea of having a multibranch linear(dense) layer in the network. This learns global representations from the condensed information which enhances the representational power of the network. Th",
    "link": "http://arxiv.org/abs/2308.13343",
    "context": "Title: Squeeze aggregated excitation network. (arXiv:2308.13343v1 [cs.CV])\nAbstract: Convolutional neural networks have spatial representations which read patterns in the vision tasks. Squeeze and excitation links the channel wise representations by explicitly modeling on channel level. Multi layer perceptrons learn global representations and in most of the models it is used often at the end after all convolutional layers to gather all the information learned before classification. We propose a method of inducing the global representations within channels to have better performance of the model. We propose SaEnet, Squeeze aggregated excitation network, for learning global channelwise representation in between layers. The proposed module takes advantage of passing important information after squeeze by having aggregated excitation before regaining its shape. We also introduce a new idea of having a multibranch linear(dense) layer in the network. This learns global representations from the condensed information which enhances the representational power of the network. Th",
    "path": "papers/23/08/2308.13343.json",
    "total_tokens": 840,
    "translated_title": "Squeeze聚合激励网络",
    "translated_abstract": "卷积神经网络在视觉任务中具有空间表示能力，通过在通道水平上显式建模，Squeeze and excitation将通道级别的表示连接起来。多层感知器学习全局表示，在大多数模型中，它通常在所有卷积层之后在最后使用，以收集分类之前学到的所有信息。我们提出了一种在通道内引发全局表示以提高模型性能的方法。我们提出了SaEnet，即Squeeze聚合激励网络，用于学习层之间的全局通道表示。所提出的模块利用挤压后通过聚合激励恢复其形状之前传递重要信息的优势。我们还引入了在网络中具有多分支线性(密集)层的新思想。这个层从压缩的信息中学习全局表示，增强了网络的表征能力。",
    "tldr": "本论文提出了一种名为Squeeze聚合激励网络的新方法，用于在卷积神经网络中学习全局通道表示。该方法通过挤压和聚合激励的方式，在通道级别上连接空间表示，提高了模型性能。"
}