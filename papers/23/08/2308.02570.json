{
    "title": "Learning Implicit Entity-object Relations by Bidirectional Generative Alignment for Multimodal NER. (arXiv:2308.02570v1 [cs.LG])",
    "abstract": "The challenge posed by multimodal named entity recognition (MNER) is mainly two-fold: (1) bridging the semantic gap between text and image and (2) matching the entity with its associated object in image. Existing methods fail to capture the implicit entity-object relations, due to the lack of corresponding annotation. In this paper, we propose a bidirectional generative alignment method named BGA-MNER to tackle these issues. Our BGA-MNER consists of \\texttt{image2text} and \\texttt{text2image} generation with respect to entity-salient content in two modalities. It jointly optimizes the bidirectional reconstruction objectives, leading to aligning the implicit entity-object relations under such direct and powerful constraints. Furthermore, image-text pairs usually contain unmatched components which are noisy for generation. A stage-refined context sampler is proposed to extract the matched cross-modal content for generation. Extensive experiments on two benchmarks demonstrate that our met",
    "link": "http://arxiv.org/abs/2308.02570",
    "context": "Title: Learning Implicit Entity-object Relations by Bidirectional Generative Alignment for Multimodal NER. (arXiv:2308.02570v1 [cs.LG])\nAbstract: The challenge posed by multimodal named entity recognition (MNER) is mainly two-fold: (1) bridging the semantic gap between text and image and (2) matching the entity with its associated object in image. Existing methods fail to capture the implicit entity-object relations, due to the lack of corresponding annotation. In this paper, we propose a bidirectional generative alignment method named BGA-MNER to tackle these issues. Our BGA-MNER consists of \\texttt{image2text} and \\texttt{text2image} generation with respect to entity-salient content in two modalities. It jointly optimizes the bidirectional reconstruction objectives, leading to aligning the implicit entity-object relations under such direct and powerful constraints. Furthermore, image-text pairs usually contain unmatched components which are noisy for generation. A stage-refined context sampler is proposed to extract the matched cross-modal content for generation. Extensive experiments on two benchmarks demonstrate that our met",
    "path": "papers/23/08/2308.02570.json",
    "total_tokens": 958,
    "translated_title": "通过双向生成对齐学习隐式实体-物体关系，用于多模态NER",
    "translated_abstract": "多模态命名实体识别(MNER)面临的挑战主要有两方面: (1) 弥合文本和图像之间的语义鸿沟; (2) 匹配实体与图像中其关联的物体。现有方法无法捕捉隐含的实体-物体关系，因为缺乏相应的注释。本文提出了一种名为BGA-MNER的双向生成对齐方法来解决这些问题。我们的BGA-MNER包括针对两种模态中的实体显著内容的\\texttt{图像到文本}和\\texttt{文本到图像}生成。它通过共同优化双向重建目标来对齐隐含的实体-物体关系，在直接而强大的约束下实现对齐。此外，图像-文本对通常包含不匹配的组件，对于生成来说是噪声。我们提出了一种阶段性改进的上下文采样器，用于提取匹配的跨模态内容进行生成。在两个基准测试中进行的广泛实验证明了我们的方法。",
    "tldr": "本文提出了一种名为BGA-MNER的双向生成对齐方法，用于解决多模态命名实体识别中的两个主要挑战：语义鸿沟和实体-物体关系。实验结果表明，该方法能够有效地捕捉隐式实体-物体关系。",
    "en_tdlr": "This paper proposes a bidirectional generative alignment method named BGA-MNER to address the two main challenges in multimodal named entity recognition: semantic gap and entity-object relations. The experimental results demonstrate that the proposed method is effective in capturing implicit entity-object relations."
}