{
    "title": "Generating tabular datasets under differential privacy. (arXiv:2308.14784v1 [cs.LG])",
    "abstract": "Machine Learning (ML) is accelerating progress across fields and industries, but relies on accessible and high-quality training data. Some of the most important datasets are found in biomedical and financial domains in the form of spreadsheets and relational databases. But this tabular data is often sensitive in nature. Synthetic data generation offers the potential to unlock sensitive data, but generative models tend to memorise and regurgitate training data, which undermines the privacy goal. To remedy this, researchers have incorporated the mathematical framework of Differential Privacy (DP) into the training process of deep neural networks. But this creates a trade-off between the quality and privacy of the resulting data. Generative Adversarial Networks (GANs) are the dominant paradigm for synthesising tabular data under DP, but suffer from unstable adversarial training and mode collapse, which are exacerbated by the privacy constraints and challenging tabular data modality. This ",
    "link": "http://arxiv.org/abs/2308.14784",
    "context": "Title: Generating tabular datasets under differential privacy. (arXiv:2308.14784v1 [cs.LG])\nAbstract: Machine Learning (ML) is accelerating progress across fields and industries, but relies on accessible and high-quality training data. Some of the most important datasets are found in biomedical and financial domains in the form of spreadsheets and relational databases. But this tabular data is often sensitive in nature. Synthetic data generation offers the potential to unlock sensitive data, but generative models tend to memorise and regurgitate training data, which undermines the privacy goal. To remedy this, researchers have incorporated the mathematical framework of Differential Privacy (DP) into the training process of deep neural networks. But this creates a trade-off between the quality and privacy of the resulting data. Generative Adversarial Networks (GANs) are the dominant paradigm for synthesising tabular data under DP, but suffer from unstable adversarial training and mode collapse, which are exacerbated by the privacy constraints and challenging tabular data modality. This ",
    "path": "papers/23/08/2308.14784.json",
    "total_tokens": 898,
    "translated_title": "在差分隐私下生成表格数据集",
    "translated_abstract": "机器学习在各个领域和行业中推动了进展，但其依赖于可访问和高质量的训练数据。一些最重要的数据集以表格和关系数据库的形式出现在生物医学和金融领域。但这些表格数据通常具有敏感性质。合成数据生成可以揭示敏感数据的潜力，但生成模型往往会记忆和重复训练数据，从而破坏隐私目标。为了解决这个问题，研究人员将差分隐私（DP）的数学框架融入深度神经网络的训练过程中。但这会在生成的数据的质量和隐私之间产生权衡。生成对抗网络（GAN）是在差分隐私下合成表格数据的主要范式，但受到不稳定的对抗训练和模式坍塌的困扰，这些问题在隐私约束和复杂的表格数据模态下更加严重。",
    "tldr": "该论文研究了在差分隐私的约束下生成表格数据集的问题，通过利用生成对抗网络（GAN），它解决了训练数据的记忆重复和隐私泄露的问题，并提出了与传统方法相比更好的解决方案。",
    "en_tdlr": "This paper investigates the problem of generating tabular datasets under differential privacy. By utilizing Generative Adversarial Networks (GANs), it addresses the issues of memorizing training data and privacy leakage, and proposes a better solution compared to traditional approaches."
}