{
    "title": "Application-Oriented Benchmarking of Quantum Generative Learning Using QUARK. (arXiv:2308.04082v1 [quant-ph])",
    "abstract": "Benchmarking of quantum machine learning (QML) algorithms is challenging due to the complexity and variability of QML systems, e.g., regarding model ansatzes, data sets, training techniques, and hyper-parameters selection. The QUantum computing Application benchmaRK (QUARK) framework simplifies and standardizes benchmarking studies for quantum computing applications. Here, we propose several extensions of QUARK to include the ability to evaluate the training and deployment of quantum generative models. We describe the updated software architecture and illustrate its flexibility through several example applications: (1) We trained different quantum generative models using several circuit ansatzes, data sets, and data transformations. (2) We evaluated our models on GPU and real quantum hardware. (3) We assessed the generalization capabilities of our generative models using a broad set of metrics that capture, e.g., the novelty and validity of the generated data.",
    "link": "http://arxiv.org/abs/2308.04082",
    "context": "Title: Application-Oriented Benchmarking of Quantum Generative Learning Using QUARK. (arXiv:2308.04082v1 [quant-ph])\nAbstract: Benchmarking of quantum machine learning (QML) algorithms is challenging due to the complexity and variability of QML systems, e.g., regarding model ansatzes, data sets, training techniques, and hyper-parameters selection. The QUantum computing Application benchmaRK (QUARK) framework simplifies and standardizes benchmarking studies for quantum computing applications. Here, we propose several extensions of QUARK to include the ability to evaluate the training and deployment of quantum generative models. We describe the updated software architecture and illustrate its flexibility through several example applications: (1) We trained different quantum generative models using several circuit ansatzes, data sets, and data transformations. (2) We evaluated our models on GPU and real quantum hardware. (3) We assessed the generalization capabilities of our generative models using a broad set of metrics that capture, e.g., the novelty and validity of the generated data.",
    "path": "papers/23/08/2308.04082.json",
    "total_tokens": 818,
    "translated_title": "使用QUARK的面向应用的量子生成学习基准测试",
    "translated_abstract": "量子机器学习（QML）算法的基准测试面临着复杂性和可变性的挑战，例如模型假设、数据集、训练技术和超参数选择。QUARK框架简化和标准化了量子计算应用的基准测试研究。在这里，我们提出了几个扩展QUARK的方法，以包括评估量子生成模型的训练和部署能力。我们描述了更新后的软件架构，并通过几个示例应用说明了其灵活性：（1）我们使用多种电路假设、数据集和数据转换训练了不同的量子生成模型。（2）我们在GPU和真实的量子硬件上评估了我们的模型。（3）我们利用一系列评估指标评估了我们生成模型的泛化能力，例如生成数据的新颖性和有效性。",
    "tldr": "提出扩展QUARK框架以评估量子生成模型的训练和部署能力，并通过多个示例应用展示了其灵活性和泛化能力评估。",
    "en_tdlr": "Proposed extensions to the QUARK framework for evaluating the training and deployment of quantum generative models, demonstrated through various example applications, showcasing its flexibility and evaluation of generalization capabilities."
}