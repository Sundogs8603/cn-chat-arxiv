{
    "title": "Reinforcement Learning (RL) Augmented Cold Start Frequency Reduction in Serverless Computing. (arXiv:2308.07541v1 [cs.DC])",
    "abstract": "Function-as-a-Service is a cloud computing paradigm offering an event-driven execution model to applications. It features serverless attributes by eliminating resource management responsibilities from developers and offers transparent and on-demand scalability of applications. Typical serverless applications have stringent response time and scalability requirements and therefore rely on deployed services to provide quick and fault-tolerant feedback to clients. However, the FaaS paradigm suffers from cold starts as there is a non-negligible delay associated with on-demand function initialization. This work focuses on reducing the frequency of cold starts on the platform by using Reinforcement Learning. Our approach uses Q-learning and considers metrics such as function CPU utilization, existing function instances, and response failure rate to proactively initialize functions in advance based on the expected demand. The proposed solution was implemented on Kubeless and was evaluated usin",
    "link": "http://arxiv.org/abs/2308.07541",
    "context": "Title: Reinforcement Learning (RL) Augmented Cold Start Frequency Reduction in Serverless Computing. (arXiv:2308.07541v1 [cs.DC])\nAbstract: Function-as-a-Service is a cloud computing paradigm offering an event-driven execution model to applications. It features serverless attributes by eliminating resource management responsibilities from developers and offers transparent and on-demand scalability of applications. Typical serverless applications have stringent response time and scalability requirements and therefore rely on deployed services to provide quick and fault-tolerant feedback to clients. However, the FaaS paradigm suffers from cold starts as there is a non-negligible delay associated with on-demand function initialization. This work focuses on reducing the frequency of cold starts on the platform by using Reinforcement Learning. Our approach uses Q-learning and considers metrics such as function CPU utilization, existing function instances, and response failure rate to proactively initialize functions in advance based on the expected demand. The proposed solution was implemented on Kubeless and was evaluated usin",
    "path": "papers/23/08/2308.07541.json",
    "total_tokens": 846,
    "translated_title": "基于强化学习的无服务器计算中冷启动频率降低方法",
    "translated_abstract": "函数即服务是一种云计算范例，为应用程序提供了事件驱动执行模型。它通过从开发者那里消除资源管理责任，提供透明和按需可扩展性来实现无服务器特性。典型的无服务器应用程序对响应时间和可扩展性有严格要求，因此依赖于部署的服务为客户提供快速和容错的反馈。然而，函数即服务范例在需要按需初始化函数时存在非常可观的延迟，即冷启动问题。本研究旨在通过使用强化学习来减少平台上的冷启动频率。我们的方法使用Q学习，并考虑函数的CPU利用率、已有函数实例和响应失败率等指标，根据预期需求提前主动初始化函数。我们提出的解决方案在Kubeless上实现并进行评估。",
    "tldr": "本文提出了一种基于强化学习的方法来降低无服务器计算中的冷启动频率。通过使用Q学习和考虑多种指标，我们可以在预期需求的基础上提前初始化函数，从而减少冷启动次数。"
}