{
    "title": "Calibrated Explanations for Regression. (arXiv:2308.16245v1 [cs.LG])",
    "abstract": "Artificial Intelligence (AI) is often an integral part of modern decision support systems (DSSs). The best-performing predictive models used in AI-based DSSs lack transparency. Explainable Artificial Intelligence (XAI) aims to create AI systems that can explain their rationale to human users. Local explanations in XAI can provide information about the causes of individual predictions in terms of feature importance. However, a critical drawback of existing local explanation methods is their inability to quantify the uncertainty associated with a feature's importance. This paper introduces an extension of a feature importance explanation method, Calibrated Explanations (CE), previously only supporting classification, with support for standard regression and probabilistic regression, i.e., the probability that the target is above an arbitrary threshold. The extension for regression keeps all the benefits of CE, such as calibration of the prediction from the underlying model with confidenc",
    "link": "http://arxiv.org/abs/2308.16245",
    "context": "Title: Calibrated Explanations for Regression. (arXiv:2308.16245v1 [cs.LG])\nAbstract: Artificial Intelligence (AI) is often an integral part of modern decision support systems (DSSs). The best-performing predictive models used in AI-based DSSs lack transparency. Explainable Artificial Intelligence (XAI) aims to create AI systems that can explain their rationale to human users. Local explanations in XAI can provide information about the causes of individual predictions in terms of feature importance. However, a critical drawback of existing local explanation methods is their inability to quantify the uncertainty associated with a feature's importance. This paper introduces an extension of a feature importance explanation method, Calibrated Explanations (CE), previously only supporting classification, with support for standard regression and probabilistic regression, i.e., the probability that the target is above an arbitrary threshold. The extension for regression keeps all the benefits of CE, such as calibration of the prediction from the underlying model with confidenc",
    "path": "papers/23/08/2308.16245.json",
    "total_tokens": 779,
    "translated_title": "回归问题的校准解释",
    "translated_abstract": "人工智能（AI）通常是现代决策支持系统（DSS）的一部分。在基于AI的DSS中使用的最佳预测模型缺乏透明度。可解释的人工智能（XAI）旨在创建能够向人类用户解释其理由的AI系统。XAI中的局部解释可以提供关于个别预测的原因的信息，即特征重要性。然而，现有局部解释方法的一个关键缺点是无法量化与特征重要性相关的不确定性。本文介绍了特征重要性解释方法Calibrated Explanations（CE）的扩展，之前只支持分类，现在支持标准回归和概率回归，即目标超过任意阈值的概率。回归问题的扩展保留了CE的所有优点，例如将底层模型的预测与置信度校准。",
    "tldr": "本文介绍了一种针对回归问题的特征重要性解释方法的扩展，可以量化特征重要性的不确定性。",
    "en_tdlr": "This paper introduces an extension of a feature importance explanation method for regression problems, which can quantify the uncertainty associated with feature importance."
}