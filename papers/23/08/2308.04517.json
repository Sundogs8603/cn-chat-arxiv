{
    "title": "Capturing Spectral and Long-term Contextual Information for Speech Emotion Recognition Using Deep Learning Techniques. (arXiv:2308.04517v1 [cs.SD])",
    "abstract": "Traditional approaches in speech emotion recognition, such as LSTM, CNN, RNN, SVM, and MLP, have limitations such as difficulty capturing long-term dependencies in sequential data, capturing the temporal dynamics, and struggling to capture complex patterns and relationships in multimodal data. This research addresses these shortcomings by proposing an ensemble model that combines Graph Convolutional Networks (GCN) for processing textual data and the HuBERT transformer for analyzing audio signals. We found that GCNs excel at capturing Long-term contextual dependencies and relationships within textual data by leveraging graph-based representations of text and thus detecting the contextual meaning and semantic relationships between words. On the other hand, HuBERT utilizes self-attention mechanisms to capture long-range dependencies, enabling the modeling of temporal dynamics present in speech and capturing subtle nuances and variations that contribute to emotion recognition. By combining",
    "link": "http://arxiv.org/abs/2308.04517",
    "context": "Title: Capturing Spectral and Long-term Contextual Information for Speech Emotion Recognition Using Deep Learning Techniques. (arXiv:2308.04517v1 [cs.SD])\nAbstract: Traditional approaches in speech emotion recognition, such as LSTM, CNN, RNN, SVM, and MLP, have limitations such as difficulty capturing long-term dependencies in sequential data, capturing the temporal dynamics, and struggling to capture complex patterns and relationships in multimodal data. This research addresses these shortcomings by proposing an ensemble model that combines Graph Convolutional Networks (GCN) for processing textual data and the HuBERT transformer for analyzing audio signals. We found that GCNs excel at capturing Long-term contextual dependencies and relationships within textual data by leveraging graph-based representations of text and thus detecting the contextual meaning and semantic relationships between words. On the other hand, HuBERT utilizes self-attention mechanisms to capture long-range dependencies, enabling the modeling of temporal dynamics present in speech and capturing subtle nuances and variations that contribute to emotion recognition. By combining",
    "path": "papers/23/08/2308.04517.json",
    "total_tokens": 991,
    "translated_title": "使用深度学习技术捕捉语音情感识别中的光谱和长期上下文信息",
    "translated_abstract": "传统的语音情感识别方法，如LSTM、CNN、RNN、SVM和MLP，在捕捉序列数据中的长期依赖性、捕捉时间动态性以及捕捉多模态数据中的复杂模式和关系方面存在局限性。本研究通过提出一种组合模型，将图卷积网络（GCN）用于处理文本数据，HuBERT transformer用于分析音频信号，来解决这些问题。我们发现，GCN在利用基于图的文本表示捕捉文本数据中的长期上下文依赖和关系以及检测词之间的语境意义和语义关系方面表现出色。另一方面，HuBERT利用自注意机制捕捉长距离依赖性，能够对语音中的时间动态进行建模，并捕捉对情感识别产生贡献的微妙差异和变化。通过结合这两种方法，我们的模型能够更有效地进行语音情感识别。",
    "tldr": "本研究提出了一种使用组合模型的方法，将图卷积网络（GCN）与HuBERT transformer相结合，以捕捉语音情感识别中的光谱和长期上下文信息。GCN利用图表示文本数据，捕捉长期上下文依赖和语义关系，而HuBERT利用自注意机制捕捉长距离依赖性和语音中的时间动态。结合这两个方法可以更有效地进行情感识别。",
    "en_tdlr": "This research proposes an ensemble model that combines Graph Convolutional Networks (GCN) and HuBERT transformer to capture spectral and long-term contextual information in speech emotion recognition. GCN utilizes graph-based representations to capture long-term contextual dependencies and semantic relationships in textual data, while HuBERT utilizes self-attention mechanisms to capture long-range dependencies and temporal dynamics in speech. Combining these two methods enables more effective emotion recognition."
}