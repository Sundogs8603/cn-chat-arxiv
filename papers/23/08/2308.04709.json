{
    "title": "A Comparative Study of Open-Source Large Language Models, GPT-4 and Claude 2: Multiple-Choice Test Taking in Nephrology. (arXiv:2308.04709v1 [cs.CL])",
    "abstract": "In recent years, there have been significant breakthroughs in the field of natural language processing, particularly with the development of large language models (LLMs). These LLMs have showcased remarkable capabilities on various benchmarks. In the healthcare field, the exact role LLMs and other future AI models will play remains unclear. There is a potential for these models in the future to be used as part of adaptive physician training, medical co-pilot applications, and digital patient interaction scenarios. The ability of AI models to participate in medical training and patient care will depend in part on their mastery of the knowledge content of specific medical fields. This study investigated the medical knowledge capability of LLMs, specifically in the context of internal medicine subspecialty multiple-choice test-taking ability. We compared the performance of several open-source LLMs (Koala 7B, Falcon 7B, Stable-Vicuna 13B, and Orca Mini 13B), to GPT-4 and Claude 2 on multip",
    "link": "http://arxiv.org/abs/2308.04709",
    "context": "Title: A Comparative Study of Open-Source Large Language Models, GPT-4 and Claude 2: Multiple-Choice Test Taking in Nephrology. (arXiv:2308.04709v1 [cs.CL])\nAbstract: In recent years, there have been significant breakthroughs in the field of natural language processing, particularly with the development of large language models (LLMs). These LLMs have showcased remarkable capabilities on various benchmarks. In the healthcare field, the exact role LLMs and other future AI models will play remains unclear. There is a potential for these models in the future to be used as part of adaptive physician training, medical co-pilot applications, and digital patient interaction scenarios. The ability of AI models to participate in medical training and patient care will depend in part on their mastery of the knowledge content of specific medical fields. This study investigated the medical knowledge capability of LLMs, specifically in the context of internal medicine subspecialty multiple-choice test-taking ability. We compared the performance of several open-source LLMs (Koala 7B, Falcon 7B, Stable-Vicuna 13B, and Orca Mini 13B), to GPT-4 and Claude 2 on multip",
    "path": "papers/23/08/2308.04709.json",
    "total_tokens": 1011,
    "translated_title": "开源大型语言模型GPT-4和Claude 2的比较研究：肾病学中的多项选择题考试",
    "translated_abstract": "近年来，自然语言处理领域取得了重大突破，尤其是大型语言模型（LLM）的发展。这些LLM在各种基准测试中展示了 remarkable 能力。在医疗领域，LLM和其他未来的人工智能模型所扮演的确切角色仍不清楚。将来，这些模型有可能成为适应性医师培训、医疗协助应用和数字化患者交互场景的一部分。人工智能模型参与医学培训和患者护理的能力将部分取决于它们是否掌握特定医学领域的知识内容。本研究在内科专业多项选择题考试能力的背景下，调查了LLM的医学知识能力。我们研究了几个开源的LLM（Koala 7B、Falcon 7B、Stable-Vicuna 13B和Orca Mini 13B）与GPT-4和Claude 2的性能进行比较。",
    "tldr": "本研究比较了几个开源的大型语言模型（LLMs）和GPT-4、Claude 2在肾病学内科多项选择题考试方面的表现。这些模型在未来有潜力成为医学培训、医疗协助和患者交互的一部分。",
    "en_tdlr": "This study compares several open-source large language models (LLMs) and GPT-4, Claude 2 in the context of internal medicine subspecialty multiple-choice test-taking in nephrology. These models have the potential to be part of medical training, medical co-pilot applications, and digital patient interaction scenarios in the future."
}