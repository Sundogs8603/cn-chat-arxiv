{
    "title": "FINER: Enhancing State-of-the-art Classifiers with Feature Attribution to Facilitate Security Analysis. (arXiv:2308.05362v1 [cs.CR])",
    "abstract": "Deep learning classifiers achieve state-of-the-art performance in various risk detection applications. They explore rich semantic representations and are supposed to automatically discover risk behaviors. However, due to the lack of transparency, the behavioral semantics cannot be conveyed to downstream security experts to reduce their heavy workload in security analysis. Although feature attribution (FA) methods can be used to explain deep learning, the underlying classifier is still blind to what behavior is suspicious, and the generated explanation cannot adapt to downstream tasks, incurring poor explanation fidelity and intelligibility. In this paper, we propose FINER, the first framework for risk detection classifiers to generate high-fidelity and high-intelligibility explanations. The high-level idea is to gather explanation efforts from model developer, FA designer, and security experts. To improve fidelity, we fine-tune the classifier with an explanation-guided multi-task learn",
    "link": "http://arxiv.org/abs/2308.05362",
    "context": "Title: FINER: Enhancing State-of-the-art Classifiers with Feature Attribution to Facilitate Security Analysis. (arXiv:2308.05362v1 [cs.CR])\nAbstract: Deep learning classifiers achieve state-of-the-art performance in various risk detection applications. They explore rich semantic representations and are supposed to automatically discover risk behaviors. However, due to the lack of transparency, the behavioral semantics cannot be conveyed to downstream security experts to reduce their heavy workload in security analysis. Although feature attribution (FA) methods can be used to explain deep learning, the underlying classifier is still blind to what behavior is suspicious, and the generated explanation cannot adapt to downstream tasks, incurring poor explanation fidelity and intelligibility. In this paper, we propose FINER, the first framework for risk detection classifiers to generate high-fidelity and high-intelligibility explanations. The high-level idea is to gather explanation efforts from model developer, FA designer, and security experts. To improve fidelity, we fine-tune the classifier with an explanation-guided multi-task learn",
    "path": "papers/23/08/2308.05362.json",
    "total_tokens": 840,
    "translated_title": "FINER:利用特征归因增强先进的分类器以促进安全分析",
    "translated_abstract": "深度学习分类器在各种风险检测应用中取得了最先进的性能。它们探索丰富的语义表示，并且应该自动发现风险行为。然而，由于缺乏透明度，行为语义无法传达给下游安全专家，以减少他们在安全分析中的繁重工作量。虽然特征归因方法可用于解释深度学习，但基础分类器仍然不知道哪些行为是可疑的，并且生成的解释不能适应下游任务，导致解释的准确性和可理解性较差。在本文中，我们提出了FINER，这是第一个为风险检测分类器生成高准确性和高可理解性解释的框架。高层次的思路是汇集模型开发者、特征归因设计师和安全专家的解释工作。为了提高准确性，我们使用解释引导的多任务学习来对分类器进行微调。",
    "tldr": "本文提出了FINER，这是第一个能够生成高准确性和高可理解性解释的风险检测分类器框架。"
}