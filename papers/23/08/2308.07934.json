{
    "title": "One-bit Flip is All You Need: When Bit-flip Attack Meets Model Training. (arXiv:2308.07934v1 [cs.CR])",
    "abstract": "Deep neural networks (DNNs) are widely deployed on real-world devices. Concerns regarding their security have gained great attention from researchers. Recently, a new weight modification attack called bit flip attack (BFA) was proposed, which exploits memory fault inject techniques such as row hammer to attack quantized models in the deployment stage. With only a few bit flips, the target model can be rendered useless as a random guesser or even be implanted with malicious functionalities. In this work, we seek to further reduce the number of bit flips. We propose a training-assisted bit flip attack, in which the adversary is involved in the training stage to build a high-risk model to release. This high-risk model, obtained coupled with a corresponding malicious model, behaves normally and can escape various detection methods. The results on benchmark datasets show that an adversary can easily convert this high-risk but normal model to a malicious one on victim's side by \\textbf{flipp",
    "link": "http://arxiv.org/abs/2308.07934",
    "context": "Title: One-bit Flip is All You Need: When Bit-flip Attack Meets Model Training. (arXiv:2308.07934v1 [cs.CR])\nAbstract: Deep neural networks (DNNs) are widely deployed on real-world devices. Concerns regarding their security have gained great attention from researchers. Recently, a new weight modification attack called bit flip attack (BFA) was proposed, which exploits memory fault inject techniques such as row hammer to attack quantized models in the deployment stage. With only a few bit flips, the target model can be rendered useless as a random guesser or even be implanted with malicious functionalities. In this work, we seek to further reduce the number of bit flips. We propose a training-assisted bit flip attack, in which the adversary is involved in the training stage to build a high-risk model to release. This high-risk model, obtained coupled with a corresponding malicious model, behaves normally and can escape various detection methods. The results on benchmark datasets show that an adversary can easily convert this high-risk but normal model to a malicious one on victim's side by \\textbf{flipp",
    "path": "papers/23/08/2308.07934.json",
    "total_tokens": 996,
    "translated_title": "只需一次位翻转：当位翻转攻击遇到模型训练",
    "translated_abstract": "深度神经网络广泛部署在现实世界的设备上。对其安全性的关注引起了研究者的极大关注。最近提出了一种新的权重修改攻击称为位翻转攻击（BFA），该攻击利用内存故障注入技术，如行锤击，来攻击部署阶段的量化模型。仅通过少量的位翻转，目标模型可以被渲染为无用的随机猜测者，甚至可以植入恶意功能。在这项工作中，我们试图进一步降低位翻转的数量。我们提出了一种训练辅助的位翻转攻击，在其中，对手参与到训练阶段中，建立一个高风险的释放模型。这个高风险模型与相应的恶意模型结合，表现正常，并且可以逃避各种检测方法。在基准数据集上的实验结果表明，攻击者可以轻松地将这个高风险但正常的模型转化为受害者这边的恶意模型。",
    "tldr": "本论文介绍了一种位翻转攻击和模型训练相结合的方法，通过在训练阶段引入对手构建高风险模型，在只进行少量位翻转的情况下，将正常模型转化为恶意模型。实验结果表明，这种攻击方法可以逃避各种检测方法。",
    "en_tdlr": "This paper presents a method that combines bit flip attack and model training, where an adversary is involved in the training stage to build a high-risk model that can be converted into a malicious one with only a few bit flips. Experimental results show that this attack method can evade various detection methods."
}