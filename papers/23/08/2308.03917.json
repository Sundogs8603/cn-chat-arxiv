{
    "title": "Universal Automatic Phonetic Transcription into the International Phonetic Alphabet. (arXiv:2308.03917v1 [cs.CL])",
    "abstract": "This paper presents a state-of-the-art model for transcribing speech in any language into the International Phonetic Alphabet (IPA). Transcription of spoken languages into IPA is an essential yet time-consuming process in language documentation, and even partially automating this process has the potential to drastically speed up the documentation of endangered languages. Like the previous best speech-to-IPA model (Wav2Vec2Phoneme), our model is based on wav2vec 2.0 and is fine-tuned to predict IPA from audio input. We use training data from seven languages from CommonVoice 11.0, transcribed into IPA semi-automatically. Although this training dataset is much smaller than Wav2Vec2Phoneme's, its higher quality lets our model achieve comparable or better results. Furthermore, we show that the quality of our universal speech-to-IPA models is close to that of human annotators.",
    "link": "http://arxiv.org/abs/2308.03917",
    "context": "Title: Universal Automatic Phonetic Transcription into the International Phonetic Alphabet. (arXiv:2308.03917v1 [cs.CL])\nAbstract: This paper presents a state-of-the-art model for transcribing speech in any language into the International Phonetic Alphabet (IPA). Transcription of spoken languages into IPA is an essential yet time-consuming process in language documentation, and even partially automating this process has the potential to drastically speed up the documentation of endangered languages. Like the previous best speech-to-IPA model (Wav2Vec2Phoneme), our model is based on wav2vec 2.0 and is fine-tuned to predict IPA from audio input. We use training data from seven languages from CommonVoice 11.0, transcribed into IPA semi-automatically. Although this training dataset is much smaller than Wav2Vec2Phoneme's, its higher quality lets our model achieve comparable or better results. Furthermore, we show that the quality of our universal speech-to-IPA models is close to that of human annotators.",
    "path": "papers/23/08/2308.03917.json",
    "total_tokens": 945,
    "translated_title": "通用自动国际音标转写技术的研究",
    "translated_abstract": "本文提出了一种最先进的模型，用于将任何语言的语音转写成国际音标（IPA）。将口语转写成国际音标是语言记录过程中必不可少但耗时的工作，部分自动化这个过程有潜力极大加快濒危语言的记录速度。我们的模型类似于之前最好的语音到国际音标模型（Wav2Vec2Phoneme），基于wav2vec 2.0并通过微调预测音频输入的国际音标。我们使用来自CommonVoice 11.0的七种语言的训练数据，通过半自动转写成国际音标。虽然这个训练数据集比Wav2Vec2Phoneme的小得多，但其质量更高，使得我们的模型达到了可比较甚至更好的结果。此外，我们还展示了我们的通用语音到国际音标模型的质量接近人类注释者的水平。",
    "tldr": "本文提出了一种最先进的模型，用于将任何语言的语音转写成国际音标（IPA），部分自动化这个过程有潜力极大加快濒危语言的记录速度。虽然使用的训练数据集比之前的模型小，但质量更高并达到了相对较好的结果，还展示了模型的质量接近人类注释者的水平。",
    "en_tdlr": "This paper presents a state-of-the-art model for transcribing speech in any language into the International Phonetic Alphabet (IPA), partially automating this process has the potential to drastically speed up the documentation of endangered languages. Despite using a smaller training dataset, the model achieves comparable or better results and is shown to have a quality close to that of human annotators."
}