{
    "title": "Large Language Models on Wikipedia-Style Survey Generation: an Evaluation in NLP Concepts. (arXiv:2308.10410v2 [cs.CL] UPDATED)",
    "abstract": "Large Language Models (LLMs) have achieved significant success across various natural language processing (NLP) tasks, encompassing question-answering, summarization, and machine translation, among others. While LLMs excel in general tasks, their efficacy in domain-specific applications remains under exploration. Additionally, LLM-generated text sometimes exhibits issues like hallucination and disinformation. In this study, we assess LLMs' capability of producing concise survey articles within the computer science-NLP domain, focusing on 20 chosen topics. Automated evaluations indicate that GPT-4 outperforms GPT-3.5 when benchmarked against the ground truth. Furthermore, four human evaluators provide insights from six perspectives across four model configurations. Through case studies, we demonstrate that while GPT often yields commendable results, there are instances of shortcomings, such as incomplete information and the exhibition of lapses in factual accuracy.",
    "link": "http://arxiv.org/abs/2308.10410",
    "context": "Title: Large Language Models on Wikipedia-Style Survey Generation: an Evaluation in NLP Concepts. (arXiv:2308.10410v2 [cs.CL] UPDATED)\nAbstract: Large Language Models (LLMs) have achieved significant success across various natural language processing (NLP) tasks, encompassing question-answering, summarization, and machine translation, among others. While LLMs excel in general tasks, their efficacy in domain-specific applications remains under exploration. Additionally, LLM-generated text sometimes exhibits issues like hallucination and disinformation. In this study, we assess LLMs' capability of producing concise survey articles within the computer science-NLP domain, focusing on 20 chosen topics. Automated evaluations indicate that GPT-4 outperforms GPT-3.5 when benchmarked against the ground truth. Furthermore, four human evaluators provide insights from six perspectives across four model configurations. Through case studies, we demonstrate that while GPT often yields commendable results, there are instances of shortcomings, such as incomplete information and the exhibition of lapses in factual accuracy.",
    "path": "papers/23/08/2308.10410.json",
    "total_tokens": 919,
    "translated_title": "基于维基百科风格的调研生成的大型语言模型：在自然语言处理概念中的评估",
    "translated_abstract": "大型语言模型（LLMs）在各种自然语言处理（NLP）任务中取得了重大成功，包括问答、摘要和机器翻译等。虽然LLMs在一般任务中表现出色，但它们在特定领域应用中的效果仍在探索中。此外，LLM生成的文本有时会出现幻觉和不实信息等问题。在本研究中，我们评估了LLMs在计算机科学-NLP领域中生成简洁调研文章的能力，重点关注20个选定的主题。自动评估表明，GPT-4在与真实数据进行基准测试时优于GPT-3.5。此外，四位人类评估者从四个模型配置的六个角度提供了见解。通过案例研究，我们证明了虽然GPT通常能产生可称赞的结果，但也存在一些缺点，如信息不完整和事实准确性方面的漏洞。",
    "tldr": "本研究评估了大型语言模型在自然语言处理领域生成调研文章的效果，发现GPT-4优于GPT-3.5，并且指出了GPT在信息完整性和事实准确性方面的一些缺陷。"
}