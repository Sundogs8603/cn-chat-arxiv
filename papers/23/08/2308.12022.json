{
    "title": "Reranking Passages with Coarse-to-Fine Neural Retriever using List-Context Information. (arXiv:2308.12022v1 [cs.CL])",
    "abstract": "Passage reranking is a crucial task in many applications, particularly when dealing with large-scale documents. Traditional neural architectures are limited in retrieving the best passage for a question because they usually match the question to each passage separately, seldom considering contextual information in other passages that can provide comparison and reference information. This paper presents a list-context attention mechanism to augment the passage representation by incorporating the list-context information from other candidates. The proposed coarse-to-fine (C2F) neural retriever addresses the out-of-memory limitation of the passage attention mechanism by dividing the list-context modeling process into two sub-processes, allowing for efficient encoding of context information from a large number of candidate answers. This method can be generally used to encode context information from any number of candidate answers in one pass. Different from most multi-stage information re",
    "link": "http://arxiv.org/abs/2308.12022",
    "context": "Title: Reranking Passages with Coarse-to-Fine Neural Retriever using List-Context Information. (arXiv:2308.12022v1 [cs.CL])\nAbstract: Passage reranking is a crucial task in many applications, particularly when dealing with large-scale documents. Traditional neural architectures are limited in retrieving the best passage for a question because they usually match the question to each passage separately, seldom considering contextual information in other passages that can provide comparison and reference information. This paper presents a list-context attention mechanism to augment the passage representation by incorporating the list-context information from other candidates. The proposed coarse-to-fine (C2F) neural retriever addresses the out-of-memory limitation of the passage attention mechanism by dividing the list-context modeling process into two sub-processes, allowing for efficient encoding of context information from a large number of candidate answers. This method can be generally used to encode context information from any number of candidate answers in one pass. Different from most multi-stage information re",
    "path": "papers/23/08/2308.12022.json",
    "total_tokens": 933,
    "translated_title": "利用列表上下文信息的粗到细神经检索器对段落进行重新排序",
    "translated_abstract": "段落重新排序是许多应用程序中的关键任务，特别是在处理大规模文档时。传统的神经架构在为问题检索最佳段落方面存在限制，因为它们通常将问题与每个段落分开匹配，很少考虑其他段落中的上下文信息，而这些信息可以提供比较和参考信息。本文提出了一种列表上下文注意机制，通过将来自其他候选句子的列表上下文信息纳入段落表示中来增强段落表示。所提出的粗到细（C2F）神经检索器通过将列表上下文建模过程分为两个子过程来解决段落注意机制的内存限制问题，从而允许对大量候选答案的上下文信息进行高效编码。这种方法可以广泛用于一次性编码任意数量的候选答案的上下文信息。",
    "tldr": "本文提出了一种利用列表上下文信息的粗到细神经检索器来重新排序段落。该方法通过将其他候选句子的列表上下文信息纳入段落表示中，增强了段落表示。而且，该方法将列表上下文建模过程分为两个子过程，从而解决了段落注意机制的内存限制问题，允许高效编码大量候选答案的上下文信息。"
}