{
    "title": "HICL: Hashtag-Driven In-Context Learning for Social Media Natural Language Understanding. (arXiv:2308.09985v1 [cs.CL])",
    "abstract": "Natural language understanding (NLU) is integral to various social media applications. However, existing NLU models rely heavily on context for semantic learning, resulting in compromised performance when faced with short and noisy social media content. To address this issue, we leverage in-context learning (ICL), wherein language models learn to make inferences by conditioning on a handful of demonstrations to enrich the context and propose a novel hashtag-driven in-context learning (HICL) framework. Concretely, we pre-train a model #Encoder, which employs #hashtags (user-annotated topic labels) to drive BERT-based pre-training through contrastive learning. Our objective here is to enable #Encoder to gain the ability to incorporate topic-related semantic information, which allows it to retrieve topic-related posts to enrich contexts and enhance social media NLU with noisy contexts. To further integrate the retrieved context with the source text, we employ a gradient-based method to id",
    "link": "http://arxiv.org/abs/2308.09985",
    "context": "Title: HICL: Hashtag-Driven In-Context Learning for Social Media Natural Language Understanding. (arXiv:2308.09985v1 [cs.CL])\nAbstract: Natural language understanding (NLU) is integral to various social media applications. However, existing NLU models rely heavily on context for semantic learning, resulting in compromised performance when faced with short and noisy social media content. To address this issue, we leverage in-context learning (ICL), wherein language models learn to make inferences by conditioning on a handful of demonstrations to enrich the context and propose a novel hashtag-driven in-context learning (HICL) framework. Concretely, we pre-train a model #Encoder, which employs #hashtags (user-annotated topic labels) to drive BERT-based pre-training through contrastive learning. Our objective here is to enable #Encoder to gain the ability to incorporate topic-related semantic information, which allows it to retrieve topic-related posts to enrich contexts and enhance social media NLU with noisy contexts. To further integrate the retrieved context with the source text, we employ a gradient-based method to id",
    "path": "papers/23/08/2308.09985.json",
    "total_tokens": 973,
    "translated_title": "HICL: 基于标签驱动的社交媒体自然语言理解中的上下文学习",
    "translated_abstract": "自然语言理解（NLU）对各种社交媒体应用程序至关重要。然而，现有的NLU模型在语义学习中过于依赖上下文，导致在面对短且嘈杂的社交媒体内容时性能受损。为了解决这个问题，我们利用上下文学习（ICL），即语言模型通过有限的示例进行条件推理从而丰富上下文，并提出了一种新颖的基于标签驱动的上下文学习（HICL）框架。具体地，我们预训练一个模型＃Encoder，它通过对比学习使得基于BERT的预训练过程通过＃hashtags（用户注释的主题标签）驱动。我们的目标是使＃Encoder能够获取整合了主题相关语义信息的能力，从而使其能够检索与主题相关的帖子以丰富上下文，并通过噪声上下文增强社交媒体NLU。为了进一步将检索到的上下文与源文本整合，我们使用了一种基于梯度的方法进行标识。",
    "tldr": "本论文提出了一种基于标签驱动的上下文学习（HICL）框架，通过使用＃hashtags驱动BERT的预训练过程，使＃Encoder能够整合主题相关语义信息，丰富上下文并提升社交媒体自然语言理解的性能。",
    "en_tdlr": "This paper proposes a hashtag-driven in-context learning (HICL) framework, which utilizes #hashtags to drive the pre-training of a model called #Encoder. By incorporating topic-related semantic information, #Encoder is able to enrich contexts and improve the performance of social media natural language understanding."
}