{
    "title": "Beneficent Intelligence: A Capability Approach to Modeling Benefit, Assistance, and Associated Moral Failures through AI Systems. (arXiv:2308.00868v1 [cs.AI])",
    "abstract": "The prevailing discourse around AI ethics lacks the language and formalism necessary to capture the diverse ethical concerns that emerge when AI systems interact with individuals. Drawing on Sen and Nussbaum's capability approach, we present a framework formalizing a network of ethical concepts and entitlements necessary for AI systems to confer meaningful benefit or assistance to stakeholders. Such systems enhance stakeholders' ability to advance their life plans and well-being while upholding their fundamental rights. We characterize two necessary conditions for morally permissible interactions between AI systems and those impacted by their functioning, and two sufficient conditions for realizing the ideal of meaningful benefit. We then contrast this ideal with several salient failure modes, namely, forms of social interactions that constitute unjustified paternalism, coercion, deception, exploitation and domination. The proliferation of incidents involving AI in high-stakes domains ",
    "link": "http://arxiv.org/abs/2308.00868",
    "context": "Title: Beneficent Intelligence: A Capability Approach to Modeling Benefit, Assistance, and Associated Moral Failures through AI Systems. (arXiv:2308.00868v1 [cs.AI])\nAbstract: The prevailing discourse around AI ethics lacks the language and formalism necessary to capture the diverse ethical concerns that emerge when AI systems interact with individuals. Drawing on Sen and Nussbaum's capability approach, we present a framework formalizing a network of ethical concepts and entitlements necessary for AI systems to confer meaningful benefit or assistance to stakeholders. Such systems enhance stakeholders' ability to advance their life plans and well-being while upholding their fundamental rights. We characterize two necessary conditions for morally permissible interactions between AI systems and those impacted by their functioning, and two sufficient conditions for realizing the ideal of meaningful benefit. We then contrast this ideal with several salient failure modes, namely, forms of social interactions that constitute unjustified paternalism, coercion, deception, exploitation and domination. The proliferation of incidents involving AI in high-stakes domains ",
    "path": "papers/23/08/2308.00868.json",
    "total_tokens": 869,
    "translated_title": "仁爱智能：通过AI系统对利益、援助及相关道德失误进行建模的能力方法",
    "translated_abstract": "AI伦理学中普遍的讨论缺乏捕捉AI系统与个体互动时涌现的多样化伦理关切所需的语言和形式。借鉴Sen和Nussbaum的能力方法，我们提出一个框架，形式化了AI系统为利益相关者提供有意义的利益或援助所必需的伦理概念和权利。这些系统增强了利益相关者推进其人生计划和幸福感的能力，同时维护其基本权利。我们界定了AI系统与受其功能影响的人之间道德上可接受的互动的两个必要条件，以及实现有意义利益理想的两个充分条件。然后，我们将这个理想与几种突出的失败模式进行对比，即构成不合理的家长式主义、强迫、欺骗、剥削和支配的社交互动形式。",
    "tldr": "借鉴能力方法，研究者提出了一个框架，用于解决AI系统与个体互动时涌现的伦理问题。同时，他们也界定了道德可接受的互动条件，并对几种失败模式进行了对比分析。",
    "en_tdlr": "Drawing on the capability approach, researchers propose a framework to address ethical concerns arising from interactions between AI systems and individuals. They define morally acceptable interaction conditions and analyze several failure modes."
}