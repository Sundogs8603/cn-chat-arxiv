{
    "title": "Self-supervised Learning of Rotation-invariant 3D Point Set Features using Transformer and its Self-distillation. (arXiv:2308.04725v1 [cs.CV])",
    "abstract": "Invariance against rotations of 3D objects is an important property in analyzing 3D point set data. Conventional 3D point set DNNs having rotation invariance typically obtain accurate 3D shape features via supervised learning by using labeled 3D point sets as training samples. However, due to the rapid increase in 3D point set data and the high cost of labeling, a framework to learn rotation-invariant 3D shape features from numerous unlabeled 3D point sets is required. This paper proposes a novel self-supervised learning framework for acquiring accurate and rotation-invariant 3D point set features at object-level. Our proposed lightweight DNN architecture decomposes an input 3D point set into multiple global-scale regions, called tokens, that preserve the spatial layout of partial shapes composing the 3D object. We employ a self-attention mechanism to refine the tokens and aggregate them into an expressive rotation-invariant feature per 3D point set. Our DNN is effectively trained by u",
    "link": "http://arxiv.org/abs/2308.04725",
    "context": "Title: Self-supervised Learning of Rotation-invariant 3D Point Set Features using Transformer and its Self-distillation. (arXiv:2308.04725v1 [cs.CV])\nAbstract: Invariance against rotations of 3D objects is an important property in analyzing 3D point set data. Conventional 3D point set DNNs having rotation invariance typically obtain accurate 3D shape features via supervised learning by using labeled 3D point sets as training samples. However, due to the rapid increase in 3D point set data and the high cost of labeling, a framework to learn rotation-invariant 3D shape features from numerous unlabeled 3D point sets is required. This paper proposes a novel self-supervised learning framework for acquiring accurate and rotation-invariant 3D point set features at object-level. Our proposed lightweight DNN architecture decomposes an input 3D point set into multiple global-scale regions, called tokens, that preserve the spatial layout of partial shapes composing the 3D object. We employ a self-attention mechanism to refine the tokens and aggregate them into an expressive rotation-invariant feature per 3D point set. Our DNN is effectively trained by u",
    "path": "papers/23/08/2308.04725.json",
    "total_tokens": 946,
    "translated_title": "使用Transformer和自蒸馏的自监督学习旋转不变的3D点集特征",
    "translated_abstract": "在分析3D点集数据中，3D物体的旋转不变性是一个重要的属性。传统的具有旋转不变性的3D点集深度神经网络通常通过使用有标签的3D点集作为训练样本，通过监督学习获取准确的3D形状特征。然而，由于3D点集数据的快速增长和标注的高成本，需要一个从大量无标签的3D点集中学习旋转不变的3D形状特征的框架。本文提出了一种新颖的自监督学习框架，用于在对象级别获取准确且旋转不变的3D点集特征。我们提出的轻量级深度神经网络架构将输入的3D点集分解为多个全局尺度的区域（称为tokens），这些区域保留了构成3D对象的局部形状的空间布局。我们使用自注意机制来改进tokens，并将它们聚合成每个3D点集的表达性旋转不变特征。我们的深度神经网络通过自蒸馏机制进行有效训练。",
    "tldr": "本文提出了一种使用Transformer和自蒸馏的自监督学习框架，用于从大量无标签的3D点集中获取准确且旋转不变的3D点集特征。",
    "en_tdlr": "This paper proposes a self-supervised learning framework using Transformer and self-distillation to acquire accurate and rotation-invariant 3D point set features from numerous unlabeled 3D point sets."
}