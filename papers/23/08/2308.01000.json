{
    "title": "MDT3D: Multi-Dataset Training for LiDAR 3D Object Detection Generalization. (arXiv:2308.01000v1 [cs.CV])",
    "abstract": "Supervised 3D Object Detection models have been displaying increasingly better performance in single-domain cases where the training data comes from the same environment and sensor as the testing data. However, in real-world scenarios data from the target domain may not be available for finetuning or for domain adaptation methods. Indeed, 3D object detection models trained on a source dataset with a specific point distribution have shown difficulties in generalizing to unseen datasets. Therefore, we decided to leverage the information available from several annotated source datasets with our Multi-Dataset Training for 3D Object Detection (MDT3D) method to increase the robustness of 3D object detection models when tested in a new environment with a different sensor configuration. To tackle the labelling gap between datasets, we used a new label mapping based on coarse labels. Furthermore, we show how we managed the mix of datasets during training and finally introduce a new cross-datase",
    "link": "http://arxiv.org/abs/2308.01000",
    "context": "Title: MDT3D: Multi-Dataset Training for LiDAR 3D Object Detection Generalization. (arXiv:2308.01000v1 [cs.CV])\nAbstract: Supervised 3D Object Detection models have been displaying increasingly better performance in single-domain cases where the training data comes from the same environment and sensor as the testing data. However, in real-world scenarios data from the target domain may not be available for finetuning or for domain adaptation methods. Indeed, 3D object detection models trained on a source dataset with a specific point distribution have shown difficulties in generalizing to unseen datasets. Therefore, we decided to leverage the information available from several annotated source datasets with our Multi-Dataset Training for 3D Object Detection (MDT3D) method to increase the robustness of 3D object detection models when tested in a new environment with a different sensor configuration. To tackle the labelling gap between datasets, we used a new label mapping based on coarse labels. Furthermore, we show how we managed the mix of datasets during training and finally introduce a new cross-datase",
    "path": "papers/23/08/2308.01000.json",
    "total_tokens": 863,
    "translated_title": "MDT3D：LiDAR三维物体检测泛化的多数据集训练",
    "translated_abstract": "在单一领域的情况下，受监督的三维物体检测模型在训练数据和测试数据来自同一环境和传感器的情况下显示出越来越好的性能。然而，在实际情况中，目标领域的数据可能无法用于微调或域适应方法。事实上，使用特定点分布的源数据集训练的3D物体检测模型在泛化到未见过的数据集时显示出困难。因此，我们决定利用多个已注释的源数据集中的信息，使用我们的MDT3D方法来增加3D物体检测模型在不同传感器配置的新环境中的鲁棒性。为了解决数据集之间的标注差距，我们使用基于粗标签的新标签映射。此外，我们展示了我们如何在训练过程中处理数据集的混合，并介绍了一种新的跨数据集方法。",
    "tldr": "MDT3D方法通过利用多个已注释的源数据集，提高了受监督的LiDAR三维物体检测模型在不同传感器配置的新环境中的鲁棒性。",
    "en_tdlr": "The MDT3D method improves the robustness of supervised LiDAR 3D object detection models in new environments with different sensor configurations by leveraging information from multiple annotated source datasets."
}