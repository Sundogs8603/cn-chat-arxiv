{
    "title": "Targeted Data Augmentation for bias mitigation. (arXiv:2308.11386v1 [cs.LG])",
    "abstract": "The development of fair and ethical AI systems requires careful consideration of bias mitigation, an area often overlooked or ignored. In this study, we introduce a novel and efficient approach for addressing biases called Targeted Data Augmentation (TDA), which leverages classical data augmentation techniques to tackle the pressing issue of bias in data and models. Unlike the laborious task of removing biases, our method proposes to insert biases instead, resulting in improved performance. To identify biases, we annotated two diverse datasets: a dataset of clinical skin lesions and a dataset of male and female faces. These bias annotations are published for the first time in this study, providing a valuable resource for future research. Through Counterfactual Bias Insertion, we discovered that biases associated with the frame, ruler, and glasses had a significant impact on models. By randomly introducing biases during training, we mitigated these biases and achieved a substantial decr",
    "link": "http://arxiv.org/abs/2308.11386",
    "context": "Title: Targeted Data Augmentation for bias mitigation. (arXiv:2308.11386v1 [cs.LG])\nAbstract: The development of fair and ethical AI systems requires careful consideration of bias mitigation, an area often overlooked or ignored. In this study, we introduce a novel and efficient approach for addressing biases called Targeted Data Augmentation (TDA), which leverages classical data augmentation techniques to tackle the pressing issue of bias in data and models. Unlike the laborious task of removing biases, our method proposes to insert biases instead, resulting in improved performance. To identify biases, we annotated two diverse datasets: a dataset of clinical skin lesions and a dataset of male and female faces. These bias annotations are published for the first time in this study, providing a valuable resource for future research. Through Counterfactual Bias Insertion, we discovered that biases associated with the frame, ruler, and glasses had a significant impact on models. By randomly introducing biases during training, we mitigated these biases and achieved a substantial decr",
    "path": "papers/23/08/2308.11386.json",
    "total_tokens": 994,
    "translated_title": "解决偏见的目标数据增强",
    "translated_abstract": "公正和道德的人工智能系统的发展需要对偏见的缓解进行谨慎考虑，这个领域经常被忽视或忽略。在本研究中，我们引入了一种被称为目标数据增强 (TDA) 的新颖而高效的方法来解决偏见问题，该方法利用经典的数据增强技术来解决数据和模型中的偏见问题。与去除偏见的繁琐任务不同，我们的方法提出在训练过程中插入偏见，从而提高了性能。我们通过对两个不同的数据集进行标注来识别偏见：一个是临床皮肤病变数据集，一个是男性和女性面孔数据集。这些偏见标注首次在本研究中发布，为未来的研究提供了有价值的资源。通过对事后偏见插入进行反事实分析，我们发现与镜框、尺子和眼镜相关的偏见对模型产生了重要影响。通过在训练中随机引入偏见，我们减轻了这些偏见并实现了显著的降低。",
    "tldr": "本研究提出了一种新颖而高效的方法，通过利用数据增强技术来解决数据和模型中的偏见问题。与去除偏见不同，我们的方法建议在训练过程中插入偏见，从而提高了性能。我们还通过对两个不同的数据集进行标注来识别偏见，并发布了这些偏见标注，为未来的研究提供了有价值的资源。",
    "en_tdlr": "This study introduces a novel and efficient approach for addressing biases by leveraging data augmentation techniques. Unlike removing biases, the method proposes to insert biases during training, resulting in improved performance. The study also provides bias annotations for two diverse datasets and highlights the valuable resource for future research."
}