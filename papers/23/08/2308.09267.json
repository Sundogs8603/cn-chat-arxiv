{
    "title": "Enhancing Reasoning Capabilities of Large Language Models: A Graph-Based Verification Approach. (arXiv:2308.09267v2 [cs.AI] UPDATED)",
    "abstract": "Large Language Models (LLMs) have showcased impressive reasoning capabilities, particularly when guided by specifically designed prompts in complex reasoning tasks such as math word problems. These models typically solve tasks using a chain-of-thought approach, which not only bolsters their reasoning abilities but also provides valuable insights into their problem-solving process. However, there is still significant room for enhancing the reasoning abilities of LLMs. Some studies suggest that the integration of an LLM output verifier can boost reasoning accuracy without necessitating additional model training. In this paper, we follow these studies and introduce a novel graph-based method to further augment the reasoning capabilities of LLMs. We posit that multiple solutions to a reasoning task, generated by an LLM, can be represented as a reasoning graph due to the logical connections between intermediate steps from different reasoning paths. Therefore, we propose the Reasoning Graph ",
    "link": "http://arxiv.org/abs/2308.09267",
    "context": "Title: Enhancing Reasoning Capabilities of Large Language Models: A Graph-Based Verification Approach. (arXiv:2308.09267v2 [cs.AI] UPDATED)\nAbstract: Large Language Models (LLMs) have showcased impressive reasoning capabilities, particularly when guided by specifically designed prompts in complex reasoning tasks such as math word problems. These models typically solve tasks using a chain-of-thought approach, which not only bolsters their reasoning abilities but also provides valuable insights into their problem-solving process. However, there is still significant room for enhancing the reasoning abilities of LLMs. Some studies suggest that the integration of an LLM output verifier can boost reasoning accuracy without necessitating additional model training. In this paper, we follow these studies and introduce a novel graph-based method to further augment the reasoning capabilities of LLMs. We posit that multiple solutions to a reasoning task, generated by an LLM, can be represented as a reasoning graph due to the logical connections between intermediate steps from different reasoning paths. Therefore, we propose the Reasoning Graph ",
    "path": "papers/23/08/2308.09267.json",
    "total_tokens": 873,
    "translated_title": "提升大型语言模型的推理能力：一种基于图形验证的方法",
    "translated_abstract": "大型语言模型（LLM）展现出了令人印象深刻的推理能力，在复杂的数学问题等推理任务中，特别是在受特定设计的提示指导下。这些模型通常使用思维链的方法来解决任务，这不仅增强了它们的推理能力，还提供了宝贵的洞察力，揭示了它们的问题求解过程。然而，提升LLM的推理能力还有很大的改进空间。一些研究表明，将LLM输出验证器集成到模型中可以提高推理准确性，而无需额外进行模型训练。在本文中，我们遵循这些研究，引入了一种新颖的基于图形的方法，进一步增强LLM的推理能力。我们设想一个推理任务的多个解决方案，由LLM生成，可以由推理图表示，因为不同推理路径的中间步骤之间存在逻辑连接。因此，我们提出了推理图方法。",
    "tldr": "本研究引入了一种基于图形验证的方法，以进一步提高大型语言模型（LLM）的推理能力，通过将LLM生成的多个解决方案表示为推理图，从而增强推理能力。",
    "en_tdlr": "This study introduces a graph-based verification approach to enhance the reasoning capabilities of Large Language Models (LLMs), by representing multiple solutions generated by LLM as a reasoning graph."
}