{
    "title": "GNFactor: Multi-Task Real Robot Learning with Generalizable Neural Feature Fields. (arXiv:2308.16891v1 [cs.RO])",
    "abstract": "It is a long-standing problem in robotics to develop agents capable of executing diverse manipulation tasks from visual observations in unstructured real-world environments. To achieve this goal, the robot needs to have a comprehensive understanding of the 3D structure and semantics of the scene. In this work, we present $\\textbf{GNFactor}$, a visual behavior cloning agent for multi-task robotic manipulation with $\\textbf{G}$eneralizable $\\textbf{N}$eural feature $\\textbf{F}$ields. GNFactor jointly optimizes a generalizable neural field (GNF) as a reconstruction module and a Perceiver Transformer as a decision-making module, leveraging a shared deep 3D voxel representation. To incorporate semantics in 3D, the reconstruction module utilizes a vision-language foundation model ($\\textit{e.g.}$, Stable Diffusion) to distill rich semantic information into the deep 3D voxel. We evaluate GNFactor on 3 real robot tasks and perform detailed ablations on 10 RLBench tasks with a limited number of",
    "link": "http://arxiv.org/abs/2308.16891",
    "context": "Title: GNFactor: Multi-Task Real Robot Learning with Generalizable Neural Feature Fields. (arXiv:2308.16891v1 [cs.RO])\nAbstract: It is a long-standing problem in robotics to develop agents capable of executing diverse manipulation tasks from visual observations in unstructured real-world environments. To achieve this goal, the robot needs to have a comprehensive understanding of the 3D structure and semantics of the scene. In this work, we present $\\textbf{GNFactor}$, a visual behavior cloning agent for multi-task robotic manipulation with $\\textbf{G}$eneralizable $\\textbf{N}$eural feature $\\textbf{F}$ields. GNFactor jointly optimizes a generalizable neural field (GNF) as a reconstruction module and a Perceiver Transformer as a decision-making module, leveraging a shared deep 3D voxel representation. To incorporate semantics in 3D, the reconstruction module utilizes a vision-language foundation model ($\\textit{e.g.}$, Stable Diffusion) to distill rich semantic information into the deep 3D voxel. We evaluate GNFactor on 3 real robot tasks and perform detailed ablations on 10 RLBench tasks with a limited number of",
    "path": "papers/23/08/2308.16891.json",
    "total_tokens": 967,
    "translated_title": "GNFactor：具有可泛化神经特征场的多任务真实机器人学习",
    "translated_abstract": "在无结构的现实世界环境中，从视觉观察中开发能够执行多样化操作任务的代理机器人一直是机器人学中的一个长期问题。为了实现这个目标，机器人需要全面理解场景的三维结构和语义。在这项工作中，我们提出了GNFactor，一种用于多任务机器人操作的可视行为克隆代理，它利用可泛化神经特征场（GNF）作为重建模块，Perceiver Transformer作为决策模块，共享深度三维体素表示。为了将语义纳入三维表示，重建模块利用视觉语言基础模型（例如，稳定扩散）将丰富的语义信息提取到深度三维体素中。我们在3个真实机器人任务上评估了GNFactor，并对10个RLBench任务进行了详细的消融实验，只使用了有限数量的数据。",
    "tldr": "GNFactor是一个用于多任务机器人操作的代理方法，它利用可泛化神经特征场和Perceiver Transformer模块，以及深度三维体素表示来实现对真实世界环境中的操作任务的执行。它通过将视觉和语义信息纳入三维表示来提高场景的理解能力，并在多个任务上进行了验证。",
    "en_tdlr": "GNFactor is an agent approach for multi-task robotic manipulation that utilizes generalizable neural feature fields and Perceiver Transformer module, along with deep 3D voxel representation, to enable execution of diverse manipulation tasks in unstructured real-world environments. It improves scene understanding by incorporating visual and semantic information into the 3D representation, and has been evaluated on multiple tasks."
}