{
    "title": "Response: Emergent analogical reasoning in large language models. (arXiv:2308.16118v1 [cs.CL])",
    "abstract": "In their recent Nature Human Behaviour paper, \"Emergent analogical reasoning in large language models,\" (Webb, Holyoak, and Lu, 2023) the authors argue that \"large language models such as GPT-3 have acquired an emergent ability to find zero-shot solutions to a broad range of analogy problems.\" In this response, we provide counterexamples of the letter string analogies. In our tests, GPT-3 fails to solve even the easiest variants of the problems presented in the original paper. Zero-shot reasoning is an extraordinary claim that requires extraordinary evidence. We do not see that evidence in our experiments. To strengthen claims of humanlike reasoning such as zero-shot reasoning, it is important that the field develop approaches that rule out data memorization.",
    "link": "http://arxiv.org/abs/2308.16118",
    "context": "Title: Response: Emergent analogical reasoning in large language models. (arXiv:2308.16118v1 [cs.CL])\nAbstract: In their recent Nature Human Behaviour paper, \"Emergent analogical reasoning in large language models,\" (Webb, Holyoak, and Lu, 2023) the authors argue that \"large language models such as GPT-3 have acquired an emergent ability to find zero-shot solutions to a broad range of analogy problems.\" In this response, we provide counterexamples of the letter string analogies. In our tests, GPT-3 fails to solve even the easiest variants of the problems presented in the original paper. Zero-shot reasoning is an extraordinary claim that requires extraordinary evidence. We do not see that evidence in our experiments. To strengthen claims of humanlike reasoning such as zero-shot reasoning, it is important that the field develop approaches that rule out data memorization.",
    "path": "papers/23/08/2308.16118.json",
    "total_tokens": 831,
    "translated_title": "回应：大型语言模型中的紧急类比推理",
    "translated_abstract": "在最近的《自然人类行为》论文中，“大型语言模型中的紧急类比推理”（Webb，Holyoak和Lu，2023），作者们认为“像GPT-3这样的大型语言模型已经获得了发现广泛类比问题的零点解的紧急能力”。在本回应中，我们提供了一些字符串类比的反例。在我们的测试中，GPT-3甚至无法解决原始论文中提出的最简单的变体问题。零点推理是一个需要非常充分证据支持的非凡主张。在我们的实验中，我们没有看到这样的证据。为了加强像零点推理这样类似人类推理的主张，重要的是该领域开发出能够排除数据记忆的方法。",
    "tldr": "该论文回应了关于大型语言模型中紧急类比推理的主张，并通过提供字符串类比的反例来反驳。在测试中，GPT-3无法解决最简单的类比问题。为了加强零点推理等人类推理的主张，需要发展出排除数据记忆的方法。",
    "en_tdlr": "This response critiques the claims of emergent analogical reasoning in large language models and presents counterexamples using letter string analogies. The tests show that GPT-3 fails to solve even the simplest variants of the problems. To strengthen claims of humanlike reasoning, approaches that rule out data memorization need to be developed."
}