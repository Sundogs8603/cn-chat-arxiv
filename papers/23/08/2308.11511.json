{
    "title": "Mode Combinability: Exploring Convex Combinations of Permutation Aligned Models. (arXiv:2308.11511v1 [cs.LG])",
    "abstract": "We explore element-wise convex combinations of two permutation-aligned neural network parameter vectors $\\Theta_A$ and $\\Theta_B$ of size $d$. We conduct extensive experiments by examining various distributions of such model combinations parametrized by elements of the hypercube $[0,1]^{d}$ and its vicinity. Our findings reveal that broad regions of the hypercube form surfaces of low loss values, indicating that the notion of linear mode connectivity extends to a more general phenomenon which we call mode combinability. We also make several novel observations regarding linear mode connectivity and model re-basin. We demonstrate a transitivity property: two models re-based to a common third model are also linear mode connected, and a robustness property: even with significant perturbations of the neuron matchings the resulting combinations continue to form a working model. Moreover, we analyze the functional and weight similarity of model combinations and show that such combinations are",
    "link": "http://arxiv.org/abs/2308.11511",
    "context": "Title: Mode Combinability: Exploring Convex Combinations of Permutation Aligned Models. (arXiv:2308.11511v1 [cs.LG])\nAbstract: We explore element-wise convex combinations of two permutation-aligned neural network parameter vectors $\\Theta_A$ and $\\Theta_B$ of size $d$. We conduct extensive experiments by examining various distributions of such model combinations parametrized by elements of the hypercube $[0,1]^{d}$ and its vicinity. Our findings reveal that broad regions of the hypercube form surfaces of low loss values, indicating that the notion of linear mode connectivity extends to a more general phenomenon which we call mode combinability. We also make several novel observations regarding linear mode connectivity and model re-basin. We demonstrate a transitivity property: two models re-based to a common third model are also linear mode connected, and a robustness property: even with significant perturbations of the neuron matchings the resulting combinations continue to form a working model. Moreover, we analyze the functional and weight similarity of model combinations and show that such combinations are",
    "path": "papers/23/08/2308.11511.json",
    "total_tokens": 1033,
    "translated_title": "模式可组合性：探索排列对齐模型的凸组合",
    "translated_abstract": "我们探索了两个大小为d的排列对齐神经网络参数向量Θ_A和Θ_B的逐元素凸组合。我们通过检查由超立方体[0,1]^d及其邻域的元素参数化的各种模型组合的分布进行了广泛的实验。我们的研究结果揭示出，超立方体的广泛区域形成了低损失值的曲面，这表明线性模式连通性的概念扩展到了一个更一般的现象，我们将其称为模式可组合性。我们还对线性模式连通性和模型重排基进行了几项新颖的观察。我们展示了一个传递性质：基于一个共同的第三个模型进行重新基准的两个模型也是线性模式连通的，并且具有鲁棒性质：即使神经元匹配发生了相当大的扰动，所得到的组合仍然形成一个工作模型。此外，我们还分析了模型组合的功能和权重相似性，并表明此类组合是。。。",
    "tldr": "该论文探索了排列对齐模型的凸组合，并发现广泛的超立方体区域形成了低损失值的曲面，揭示了线性模式连通性的概念扩展到了更一般的模式可组合性现象。同时提出了一些关于线性模式连通性和模型重排基的新观察。研究还发现了模型组合具有传递性和鲁棒性质，并分析了功能和权重相似性的情况。"
}