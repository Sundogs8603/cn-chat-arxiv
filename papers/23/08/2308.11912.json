{
    "title": "Addressing Selection Bias in Computerized Adaptive Testing: A User-Wise Aggregate Influence Function Approach. (arXiv:2308.11912v1 [cs.LG])",
    "abstract": "Computerized Adaptive Testing (CAT) is a widely used, efficient test mode that adapts to the examinee's proficiency level in the test domain. CAT requires pre-trained item profiles, for CAT iteratively assesses the student real-time based on the registered items' profiles, and selects the next item to administer using candidate items' profiles. However, obtaining such item profiles is a costly process that involves gathering a large, dense item-response data, then training a diagnostic model on the collected data. In this paper, we explore the possibility of leveraging response data collected in the CAT service. We first show that this poses a unique challenge due to the inherent selection bias introduced by CAT, i.e., more proficient students will receive harder questions. Indeed, when naively training the diagnostic model using CAT response data, we observe that item profiles deviate significantly from the ground-truth. To tackle the selection bias issue, we propose the user-wise agg",
    "link": "http://arxiv.org/abs/2308.11912",
    "context": "Title: Addressing Selection Bias in Computerized Adaptive Testing: A User-Wise Aggregate Influence Function Approach. (arXiv:2308.11912v1 [cs.LG])\nAbstract: Computerized Adaptive Testing (CAT) is a widely used, efficient test mode that adapts to the examinee's proficiency level in the test domain. CAT requires pre-trained item profiles, for CAT iteratively assesses the student real-time based on the registered items' profiles, and selects the next item to administer using candidate items' profiles. However, obtaining such item profiles is a costly process that involves gathering a large, dense item-response data, then training a diagnostic model on the collected data. In this paper, we explore the possibility of leveraging response data collected in the CAT service. We first show that this poses a unique challenge due to the inherent selection bias introduced by CAT, i.e., more proficient students will receive harder questions. Indeed, when naively training the diagnostic model using CAT response data, we observe that item profiles deviate significantly from the ground-truth. To tackle the selection bias issue, we propose the user-wise agg",
    "path": "papers/23/08/2308.11912.json",
    "total_tokens": 891,
    "translated_title": "解决计算机自适应测试中的选择偏差问题：一种基于用户的聚合影响函数方法",
    "translated_abstract": "计算机自适应测试（CAT）是一种广泛使用的高效测试模式，可以根据受试者在测试领域的熟练程度进行适应。CAT需要预先训练的项目简介，因为CAT根据已注册项目的简介实时评估学生，并使用候选项目的简介选择下一个要指导的项目。然而，获取这样的项目简介是一个昂贵的过程，涉及收集大量密集的项目响应数据，然后在收集的数据上训练诊断模型。在本文中，我们探讨了利用CAT服务中收集的响应数据的可能性。我们首先展示了这带来的独特挑战，原因是CAT引入了固有的选择偏差，即熟练程度更高的学生会收到更难的问题。实际上，当使用CAT响应数据进行简单训练诊断模型时，我们观察到项目简介与实际情况显著偏离。为了解决选择偏差问题，我们提出了基于用户的聚合影响函数方法。",
    "tldr": "本文研究了计算机自适应测试中存在的选择偏差问题，并提出了一种基于用户的聚合影响函数方法来解决该问题。",
    "en_tdlr": "This paper addresses the selection bias issue in computerized adaptive testing and proposes a user-wise aggregate influence function approach to tackle the problem."
}