{
    "title": "Can Knowledge Graphs Simplify Text?. (arXiv:2308.06975v2 [cs.CL] UPDATED)",
    "abstract": "Knowledge Graph (KG)-to-Text Generation has seen recent improvements in generating fluent and informative sentences which describe a given KG. As KGs are widespread across multiple domains and contain important entity-relation information, and as text simplification aims to reduce the complexity of a text while preserving the meaning of the original text, we propose KGSimple, a novel approach to unsupervised text simplification which infuses KG-established techniques in order to construct a simplified KG path and generate a concise text which preserves the original input's meaning. Through an iterative and sampling KG-first approach, our model is capable of simplifying text when starting from a KG by learning to keep important information while harnessing KG-to-text generation to output fluent and descriptive sentences. We evaluate various settings of the KGSimple model on currently-available KG-to-text datasets, demonstrating its effectiveness compared to unsupervised text simplificat",
    "link": "http://arxiv.org/abs/2308.06975",
    "context": "Title: Can Knowledge Graphs Simplify Text?. (arXiv:2308.06975v2 [cs.CL] UPDATED)\nAbstract: Knowledge Graph (KG)-to-Text Generation has seen recent improvements in generating fluent and informative sentences which describe a given KG. As KGs are widespread across multiple domains and contain important entity-relation information, and as text simplification aims to reduce the complexity of a text while preserving the meaning of the original text, we propose KGSimple, a novel approach to unsupervised text simplification which infuses KG-established techniques in order to construct a simplified KG path and generate a concise text which preserves the original input's meaning. Through an iterative and sampling KG-first approach, our model is capable of simplifying text when starting from a KG by learning to keep important information while harnessing KG-to-text generation to output fluent and descriptive sentences. We evaluate various settings of the KGSimple model on currently-available KG-to-text datasets, demonstrating its effectiveness compared to unsupervised text simplificat",
    "path": "papers/23/08/2308.06975.json",
    "total_tokens": 859,
    "translated_title": "知识图谱能简化文本吗？",
    "translated_abstract": "知识图谱到文本生成在生成流畅且信息丰富的句子方面有了最新的改进，这些句子描述了给定的知识图谱。由于知识图谱在多个领域广泛存在且包含重要的实体关系信息，并且文本简化旨在减少文本的复杂性同时保留原始文本的意思，我们提出了KGSimple，一种新颖的无监督文本简化方法，它融入了知识图谱技术来构建简化的知识图谱路径，并生成保留原始输入意义的简明文本。通过迭代和采样的以知识图谱为基础的方法，我们的模型能够从知识图谱开始简化文本，通过学习保留重要信息并利用知识图谱到文本生成输出流畅且描述性的句子。我们在目前可用的知识图谱到文本数据集上评估了KGSimple模型的各种设置，证明了其相对于无监督文本简化的有效性。",
    "tldr": "提出了一种KGSimple方法，将知识图谱技术应用于无监督文本简化，实现从知识图谱开始生成简明文本，保留重要信息并输出流畅且描述性的句子。"
}