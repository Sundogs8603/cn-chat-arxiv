{
    "title": "GradOrth: A Simple yet Efficient Out-of-Distribution Detection with Orthogonal Projection of Gradients. (arXiv:2308.00310v1 [cs.CV])",
    "abstract": "Detecting out-of-distribution (OOD) data is crucial for ensuring the safe deployment of machine learning models in real-world applications. However, existing OOD detection approaches primarily rely on the feature maps or the full gradient space information to derive OOD scores neglecting the role of most important parameters of the pre-trained network over in-distribution (ID) data. In this study, we propose a novel approach called GradOrth to facilitate OOD detection based on one intriguing observation that the important features to identify OOD data lie in the lower-rank subspace of in-distribution (ID) data. In particular, we identify OOD data by computing the norm of gradient projection on the subspaces considered important for the in-distribution data. A large orthogonal projection value (i.e. a small projection value) indicates the sample as OOD as it captures a weak correlation of the ID data. This simple yet effective method exhibits outstanding performance, showcasing a notabl",
    "link": "http://arxiv.org/abs/2308.00310",
    "context": "Title: GradOrth: A Simple yet Efficient Out-of-Distribution Detection with Orthogonal Projection of Gradients. (arXiv:2308.00310v1 [cs.CV])\nAbstract: Detecting out-of-distribution (OOD) data is crucial for ensuring the safe deployment of machine learning models in real-world applications. However, existing OOD detection approaches primarily rely on the feature maps or the full gradient space information to derive OOD scores neglecting the role of most important parameters of the pre-trained network over in-distribution (ID) data. In this study, we propose a novel approach called GradOrth to facilitate OOD detection based on one intriguing observation that the important features to identify OOD data lie in the lower-rank subspace of in-distribution (ID) data. In particular, we identify OOD data by computing the norm of gradient projection on the subspaces considered important for the in-distribution data. A large orthogonal projection value (i.e. a small projection value) indicates the sample as OOD as it captures a weak correlation of the ID data. This simple yet effective method exhibits outstanding performance, showcasing a notabl",
    "path": "papers/23/08/2308.00310.json",
    "total_tokens": 894,
    "translated_title": "GradOrth:一种简单而高效的通过梯度正交投影进行外部分布检测的方法",
    "translated_abstract": "在现实世界的应用中，检测外部分布（OOD）数据对于确保机器学习模型的安全部署至关重要。然而，现有的OOD检测方法主要依赖于特征图或完整梯度空间信息来推导OOD分数，忽视了预训练网络中最重要的参数在内部分布（ID）数据中的作用。在本研究中，我们提出了一种名为GradOrth的新方法，以便基于一个有趣的观察结果，即用于识别OOD数据的重要特征位于内部分布（ID）数据的低秩子空间中。具体而言，我们通过计算在内部分布数据中被认为重要的子空间中的梯度投影范数来识别OOD数据。大的正交投影值（即小的投影值）表明样本为OOD，因为它捕捉到了ID数据的弱相关性。 这种简单而有效的方法表现出了出色的性能，展示了一个值得注意的创新。",
    "tldr": "GradOrth是一种简单而高效的方法，通过计算梯度在内部分布数据的低秩子空间中的投影范数来检测外部分布数据。这种方法展示了出色的性能。"
}