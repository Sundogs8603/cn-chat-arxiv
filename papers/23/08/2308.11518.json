{
    "title": "EM for Mixture of Linear Regression with Clustered Data. (arXiv:2308.11518v1 [cs.LG])",
    "abstract": "Modern data-driven and distributed learning frameworks deal with diverse massive data generated by clients spread across heterogeneous environments. Indeed, data heterogeneity is a major bottleneck in scaling up many distributed learning paradigms. In many settings however, heterogeneous data may be generated in clusters with shared structures, as is the case in several applications such as federated learning where a common latent variable governs the distribution of all the samples generated by a client. It is therefore natural to ask how the underlying clustered structures in distributed data can be exploited to improve learning schemes. In this paper, we tackle this question in the special case of estimating $d$-dimensional parameters of a two-component mixture of linear regressions problem where each of $m$ nodes generates $n$ samples with a shared latent variable. We employ the well-known Expectation-Maximization (EM) method to estimate the maximum likelihood parameters from $m$ b",
    "link": "http://arxiv.org/abs/2308.11518",
    "context": "Title: EM for Mixture of Linear Regression with Clustered Data. (arXiv:2308.11518v1 [cs.LG])\nAbstract: Modern data-driven and distributed learning frameworks deal with diverse massive data generated by clients spread across heterogeneous environments. Indeed, data heterogeneity is a major bottleneck in scaling up many distributed learning paradigms. In many settings however, heterogeneous data may be generated in clusters with shared structures, as is the case in several applications such as federated learning where a common latent variable governs the distribution of all the samples generated by a client. It is therefore natural to ask how the underlying clustered structures in distributed data can be exploited to improve learning schemes. In this paper, we tackle this question in the special case of estimating $d$-dimensional parameters of a two-component mixture of linear regressions problem where each of $m$ nodes generates $n$ samples with a shared latent variable. We employ the well-known Expectation-Maximization (EM) method to estimate the maximum likelihood parameters from $m$ b",
    "path": "papers/23/08/2308.11518.json",
    "total_tokens": 861,
    "translated_title": "EM算法在带有集群数据的线性回归混合模型中的应用",
    "translated_abstract": "现代数据驱动和分布式学习框架处理由分布在异质环境中的客户端生成的各种大规模数据。数据的异质性是扩大许多分布式学习范例的一个主要瓶颈。然而，在许多情况下，异构数据可能以具有共享结构的集群形式生成，例如在联邦学习中，一个共同的潜变量控制着客户端生成的所有样本的分布。因此，自然会问在分布式数据中如何利用潜在的集群结构来改进学习方案。在本文中，我们以估计一个具有两个分量的线性回归混合模型问题的d维参数的特例为例，其中每个节点生成具有共享潜变量的n个样本。我们使用众所周知的期望最大化（EM）方法来从m个节点中估计最大似然参数。",
    "tldr": "本文研究了在分布式数据中利用集群结构改进学习方案的问题，针对带有集群数据的线性回归混合模型，应用了期望最大化（EM）方法进行参数估计。"
}