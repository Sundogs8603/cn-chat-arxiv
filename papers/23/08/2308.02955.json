{
    "title": "An Empirical Study of AI-based Smart Contract Creation. (arXiv:2308.02955v2 [cs.SE] UPDATED)",
    "abstract": "The introduction of large language models (LLMs) like ChatGPT and Google Palm2 for smart contract generation seems to be the first well-established instance of an AI pair programmer. LLMs have access to a large number of open-source smart contracts, enabling them to utilize more extensive code in Solidity than other code generation tools. Although the initial and informal assessments of LLMs for smart contract generation are promising, a systematic evaluation is needed to explore the limits and benefits of these models. The main objective of this study is to assess the quality of generated code provided by LLMs for smart contracts. We also aim to evaluate the impact of the quality and variety of input parameters fed to LLMs. To achieve this aim, we created an experimental setup for evaluating the generated code in terms of validity, correctness, and efficiency. Our study finds crucial evidence of security bugs getting introduced in the generated smart contracts as well as the overall q",
    "link": "http://arxiv.org/abs/2308.02955",
    "context": "Title: An Empirical Study of AI-based Smart Contract Creation. (arXiv:2308.02955v2 [cs.SE] UPDATED)\nAbstract: The introduction of large language models (LLMs) like ChatGPT and Google Palm2 for smart contract generation seems to be the first well-established instance of an AI pair programmer. LLMs have access to a large number of open-source smart contracts, enabling them to utilize more extensive code in Solidity than other code generation tools. Although the initial and informal assessments of LLMs for smart contract generation are promising, a systematic evaluation is needed to explore the limits and benefits of these models. The main objective of this study is to assess the quality of generated code provided by LLMs for smart contracts. We also aim to evaluate the impact of the quality and variety of input parameters fed to LLMs. To achieve this aim, we created an experimental setup for evaluating the generated code in terms of validity, correctness, and efficiency. Our study finds crucial evidence of security bugs getting introduced in the generated smart contracts as well as the overall q",
    "path": "papers/23/08/2308.02955.json",
    "total_tokens": 842,
    "translated_title": "基于AI的智能合约创建的实证研究",
    "translated_abstract": "引入了大型语言模型（LLMs）如ChatGPT和Google Palm2用于智能合约生成似乎是第一个成熟的AI对程序员的实例。LLMs可以访问大量开源智能合约，使它们能够在Solidity中利用比其他代码生成工具更多的代码。虽然对LLMs用于智能合约生成的最初和非正式评估令人充满希望，但需要进行系统评估以探索这些模型的限制和优势。本研究的主要目标是评估LLMs生成的智能合约代码的质量。我们还旨在评估输入参数的质量和多样性对LLMs的影响。为了实现这个目标，我们创建了一个实验设置来评估生成的代码的有效性，正确性和效率。我们的研究发现在生成的智能合约中引入了关键的安全漏洞，同时也影响了整体质量。",
    "tldr": "本研究通过评估LLMs生成的智能合约代码的质量，发现了安全漏洞的重要证据，并评估了输入参数对LLMs的影响。",
    "en_tdlr": "This study evaluates the quality of code generated by LLMs for smart contracts and finds important evidence of security bugs, while also examining the impact of input parameters on LLMs."
}