{
    "title": "Conformer-based Target-Speaker Automatic Speech Recognition for Single-Channel Audio. (arXiv:2308.05218v1 [cs.SD])",
    "abstract": "We propose CONF-TSASR, a non-autoregressive end-to-end time-frequency domain architecture for single-channel target-speaker automatic speech recognition (TS-ASR). The model consists of a TitaNet based speaker embedding module, a Conformer based masking as well as ASR modules. These modules are jointly optimized to transcribe a target-speaker, while ignoring speech from other speakers. For training we use Connectionist Temporal Classification (CTC) loss and introduce a scale-invariant spectrogram reconstruction loss to encourage the model better separate the target-speaker's spectrogram from mixture. We obtain state-of-the-art target-speaker word error rate (TS-WER) on WSJ0-2mix-extr (4.2%). Further, we report for the first time TS-WER on WSJ0-3mix-extr (12.4%), LibriSpeech2Mix (4.2%) and LibriSpeech3Mix (7.6%) datasets, establishing new benchmarks for TS-ASR. The proposed model will be open-sourced through NVIDIA NeMo toolkit.",
    "link": "http://arxiv.org/abs/2308.05218",
    "context": "Title: Conformer-based Target-Speaker Automatic Speech Recognition for Single-Channel Audio. (arXiv:2308.05218v1 [cs.SD])\nAbstract: We propose CONF-TSASR, a non-autoregressive end-to-end time-frequency domain architecture for single-channel target-speaker automatic speech recognition (TS-ASR). The model consists of a TitaNet based speaker embedding module, a Conformer based masking as well as ASR modules. These modules are jointly optimized to transcribe a target-speaker, while ignoring speech from other speakers. For training we use Connectionist Temporal Classification (CTC) loss and introduce a scale-invariant spectrogram reconstruction loss to encourage the model better separate the target-speaker's spectrogram from mixture. We obtain state-of-the-art target-speaker word error rate (TS-WER) on WSJ0-2mix-extr (4.2%). Further, we report for the first time TS-WER on WSJ0-3mix-extr (12.4%), LibriSpeech2Mix (4.2%) and LibriSpeech3Mix (7.6%) datasets, establishing new benchmarks for TS-ASR. The proposed model will be open-sourced through NVIDIA NeMo toolkit.",
    "path": "papers/23/08/2308.05218.json",
    "total_tokens": 1019,
    "translated_title": "基于Conformer的单声道音频的目标说话者自动语音识别",
    "translated_abstract": "我们提出了CONF-TSASR，一种非自回归的端到端时间-频率域架构，用于单声道目标说话者自动语音识别（TS-ASR）。该模型包括基于TitaNet的说话者嵌入模块，基于Conformer的掩模以及ASR模块。这些模块在优化过程中同时进行，以转录目标说话者的语音，同时忽略其他说话者的语音。在训练中，我们使用连续时间分类（CTC）损失，并引入了一个尺度不变的谱图重构损失，以促使模型更好地将目标说话者的谱图与混合声音分离开来。在WSJ0-2mix-extr数据集上，我们获得了最先进的目标说话者词错误率（TS-WER）（4.2%）。此外，我们还首次报告了WSJ0-3mix-extr（12.4%）、LibriSpeech2Mix（4.2%）和LibriSpeech3Mix（7.6%）数据集上的TS-WER，建立了TS-ASR的新基准。我们将通过NVIDIA NeMo工具包开源提供该模型。",
    "tldr": "本论文提出了基于Conformer的单声道音频的目标说话者自动语音识别（TS-ASR）方法。该方法通过优化嵌入模块、掩模模块和ASR模块实现对目标说话者的识别，并且在多个数据集上取得了最先进的性能表现，建立了新的TS-ASR基准。",
    "en_tdlr": "This paper proposes a Conformer-based approach for single-channel audio target-speaker automatic speech recognition (TS-ASR). The method optimizes the embedding module, masking module, and ASR module to achieve target-speaker recognition and achieves state-of-the-art performance on multiple datasets, establishing new benchmarks for TS-ASR."
}