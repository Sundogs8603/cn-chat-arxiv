{
    "title": "A Probabilistic Approach to Self-Supervised Learning using Cyclical Stochastic Gradient MCMC. (arXiv:2308.01271v1 [cs.LG])",
    "abstract": "In this paper we present a practical Bayesian self-supervised learning method with Cyclical Stochastic Gradient Hamiltonian Monte Carlo (cSGHMC). Within this framework, we place a prior over the parameters of a self-supervised learning model and use cSGHMC to approximate the high dimensional and multimodal posterior distribution over the embeddings. By exploring an expressive posterior over the embeddings, Bayesian self-supervised learning produces interpretable and diverse representations. Marginalizing over these representations yields a significant gain in performance, calibration and out-of-distribution detection on a variety of downstream classification tasks. We provide experimental results on multiple classification tasks on four challenging datasets. Moreover, we demonstrate the effectiveness of the proposed method in out-of-distribution detection using the SVHN and CIFAR-10 datasets.",
    "link": "http://arxiv.org/abs/2308.01271",
    "context": "Title: A Probabilistic Approach to Self-Supervised Learning using Cyclical Stochastic Gradient MCMC. (arXiv:2308.01271v1 [cs.LG])\nAbstract: In this paper we present a practical Bayesian self-supervised learning method with Cyclical Stochastic Gradient Hamiltonian Monte Carlo (cSGHMC). Within this framework, we place a prior over the parameters of a self-supervised learning model and use cSGHMC to approximate the high dimensional and multimodal posterior distribution over the embeddings. By exploring an expressive posterior over the embeddings, Bayesian self-supervised learning produces interpretable and diverse representations. Marginalizing over these representations yields a significant gain in performance, calibration and out-of-distribution detection on a variety of downstream classification tasks. We provide experimental results on multiple classification tasks on four challenging datasets. Moreover, we demonstrate the effectiveness of the proposed method in out-of-distribution detection using the SVHN and CIFAR-10 datasets.",
    "path": "papers/23/08/2308.01271.json",
    "total_tokens": 864,
    "translated_title": "使用循环随机梯度MCMC的概率自监督学习的实用贝叶斯方法",
    "translated_abstract": "本文提出了一种利用循环随机梯度哈密顿蒙特卡洛（cSGHMC）的实用贝叶斯自监督学习方法。在该框架中，我们对自监督学习模型的参数设定先验，并使用cSGHMC近似表示多维多模态后验分布。通过探索丰富的嵌入后验分布，贝叶斯自监督学习产生了可解释性和多样性的表示。在多个下游分类任务中，通过边缘化这些表示，我们得到了显著的性能提升、校准性和外部分布检测能力。我们在四个具有挑战性的数据集上进行了多个分类任务的实验结果。此外，我们还使用SVHN和CIFAR-10数据集验证了所提出方法在外部分布检测方面的有效性。",
    "tldr": "本文提出了一种利用循环随机梯度MCMC的贝叶斯自监督学习方法，在多个下游分类任务中，通过探索丰富的嵌入后验分布，实现了显著的性能提升、校准性和外部分布检测能力。",
    "en_tdlr": "This paper proposes a Bayesian self-supervised learning method using cyclical stochastic gradient MCMC, which achieves significant performance improvement, calibration, and out-of-distribution detection in multiple downstream classification tasks by exploring an expressive posterior distribution over embeddings."
}