{
    "title": "Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models. (arXiv:2308.00675v1 [cs.CL])",
    "abstract": "Today, large language models (LLMs) are taught to use new tools by providing a few demonstrations of the tool's usage. Unfortunately, demonstrations are hard to acquire, and can result in undesirable biased usage if the wrong demonstration is chosen. Even in the rare scenario that demonstrations are readily available, there is no principled selection protocol to determine how many and which ones to provide. As tasks grow more complex, the selection search grows combinatorially and invariably becomes intractable. Our work provides an alternative to demonstrations: tool documentation. We advocate the use of tool documentation, descriptions for the individual tool usage, over demonstrations. We substantiate our claim through three main empirical findings on 6 tasks across both vision and language modalities. First, on existing benchmarks, zero-shot prompts with only tool documentation are sufficient for eliciting proper tool usage, achieving performance on par with few-shot prompts. Secon",
    "link": "http://arxiv.org/abs/2308.00675",
    "context": "Title: Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models. (arXiv:2308.00675v1 [cs.CL])\nAbstract: Today, large language models (LLMs) are taught to use new tools by providing a few demonstrations of the tool's usage. Unfortunately, demonstrations are hard to acquire, and can result in undesirable biased usage if the wrong demonstration is chosen. Even in the rare scenario that demonstrations are readily available, there is no principled selection protocol to determine how many and which ones to provide. As tasks grow more complex, the selection search grows combinatorially and invariably becomes intractable. Our work provides an alternative to demonstrations: tool documentation. We advocate the use of tool documentation, descriptions for the individual tool usage, over demonstrations. We substantiate our claim through three main empirical findings on 6 tasks across both vision and language modalities. First, on existing benchmarks, zero-shot prompts with only tool documentation are sufficient for eliciting proper tool usage, achieving performance on par with few-shot prompts. Secon",
    "path": "papers/23/08/2308.00675.json",
    "total_tokens": 861,
    "translated_title": "工具文档使得大型语言模型能够进行零-shot工具使用",
    "translated_abstract": "如今，通过提供一些工具使用的演示来教授大型语言模型（LLM）使用新工具。不幸的是，演示很难获得，并且如果选择了错误的演示，可能会导致不良的偏见使用。即使在罕见的情况下，演示是readily available的，也没有原则性的选择协议来确定提供多少个和哪些演示。随着任务变得更加复杂，选择搜索组合数的增长成为不可处理的。我们的工作提供了一种替代演示的方法：工具文档。我们主张使用工具文档来描述各个工具的使用，而不是演示。我们通过跨视觉和语言模态的6个任务上的三个主要实证发现支持我们的主张。首先，在现有的基准测试上，仅使用工具文档的零-shot提示足以引出正确的工具使用，达到了few-shot提示的性能水平。",
    "tldr": "这项工作提出了使用工具文档作为教导大型语言模型使用新工具的替代方法，并通过实证研究证明，仅使用工具文档的零-shot提示足以实现正确的工具使用。",
    "en_tdlr": "This work proposes an alternative method for teaching large language models to use new tools, using tool documentation instead of demonstrations. Empirical findings show that zero-shot prompts with only tool documentation are sufficient for achieving proper tool usage."
}