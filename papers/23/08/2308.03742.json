{
    "title": "Training BERT Models to Carry Over a Coding System Developed on One Corpus to Another",
    "abstract": "arXiv:2308.03742v2 Announce Type: replace  Abstract: This paper describes how we train BERT models to carry over a coding system developed on the paragraphs of a Hungarian literary journal to another. The aim of the coding system is to track trends in the perception of literary translation around the political transformation in 1989 in Hungary. To evaluate not only task performance but also the consistence of the annotation, moreover, to get better predictions from an ensemble, we use 10-fold crossvalidation. Extensive hyperparameter tuning is used to obtain the best possible results and fair comparisons. To handle label imbalance, we use loss functions and metrics robust to it. Evaluation of the effect of domain shift is carried out by sampling a test set from the target domain. We establish the sample size by estimating the bootstrapped confidence interval via simulations. This way, we show that our models can carry over one annotation system to the target domain. Comparisons are dra",
    "link": "https://arxiv.org/abs/2308.03742",
    "context": "Title: Training BERT Models to Carry Over a Coding System Developed on One Corpus to Another\nAbstract: arXiv:2308.03742v2 Announce Type: replace  Abstract: This paper describes how we train BERT models to carry over a coding system developed on the paragraphs of a Hungarian literary journal to another. The aim of the coding system is to track trends in the perception of literary translation around the political transformation in 1989 in Hungary. To evaluate not only task performance but also the consistence of the annotation, moreover, to get better predictions from an ensemble, we use 10-fold crossvalidation. Extensive hyperparameter tuning is used to obtain the best possible results and fair comparisons. To handle label imbalance, we use loss functions and metrics robust to it. Evaluation of the effect of domain shift is carried out by sampling a test set from the target domain. We establish the sample size by estimating the bootstrapped confidence interval via simulations. This way, we show that our models can carry over one annotation system to the target domain. Comparisons are dra",
    "path": "papers/23/08/2308.03742.json",
    "total_tokens": 858,
    "translated_title": "训练BERT模型将一个语料库上开发的编码系统传递到另一个语料库",
    "translated_abstract": "这篇论文描述了我们如何训练BERT模型将一个在匈牙利文学期刊段落上开发的编码系统传递到另一个语料库。编码系统的目的是跟踪匈牙利在1989年政治转型期间对文学翻译感知的趋势。我们使用10折交叉验证来评估任务性能和注释一致性，并通过超参数调整获得最佳结果和公平比较。为了处理标签不平衡问题，我们使用适应的损失函数和指标。通过从目标领域对抽取测试集来评估领域转移的影响。我们通过模拟估计自举置信区间来建立样本大小，展示了我们的模型可以将一个注释系统传递到目标领域。",
    "tldr": "通过训练BERT模型，成功地将一个在匈牙利文学期刊上开发的编码系统传递到另一个语料库，用以跟踪在1989年匈牙利政治转型时期的文学翻译感知趋势，并展示了模型能够处理标签不平衡问题。",
    "en_tdlr": "Successfully transferring a coding system developed on a Hungarian literary journal to another corpus using BERT models, to track trends in literary translation perception during the political transformation in 1989 in Hungary, and demonstrating the models' ability to handle label imbalance."
}