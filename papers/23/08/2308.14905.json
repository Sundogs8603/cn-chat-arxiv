{
    "title": "Neural approaches to spoken content embedding. (arXiv:2308.14905v1 [cs.CL])",
    "abstract": "Comparing spoken segments is a central operation to speech processing. Traditional approaches in this area have favored frame-level dynamic programming algorithms, such as dynamic time warping, because they require no supervision, but they are limited in performance and efficiency. As an alternative, acoustic word embeddings -- fixed-dimensional vector representations of variable-length spoken word segments -- have begun to be considered for such tasks as well. However, the current space of such discriminative embedding models, training approaches, and their application to real-world downstream tasks is limited. We start by considering ``single-view\" training losses where the goal is to learn an acoustic word embedding model that separates same-word and different-word spoken segment pairs. Then, we consider ``multi-view\" contrastive losses. In this setting, acoustic word embeddings are learned jointly with embeddings of character sequences to generate acoustically grounded embeddings o",
    "link": "http://arxiv.org/abs/2308.14905",
    "context": "Title: Neural approaches to spoken content embedding. (arXiv:2308.14905v1 [cs.CL])\nAbstract: Comparing spoken segments is a central operation to speech processing. Traditional approaches in this area have favored frame-level dynamic programming algorithms, such as dynamic time warping, because they require no supervision, but they are limited in performance and efficiency. As an alternative, acoustic word embeddings -- fixed-dimensional vector representations of variable-length spoken word segments -- have begun to be considered for such tasks as well. However, the current space of such discriminative embedding models, training approaches, and their application to real-world downstream tasks is limited. We start by considering ``single-view\" training losses where the goal is to learn an acoustic word embedding model that separates same-word and different-word spoken segment pairs. Then, we consider ``multi-view\" contrastive losses. In this setting, acoustic word embeddings are learned jointly with embeddings of character sequences to generate acoustically grounded embeddings o",
    "path": "papers/23/08/2308.14905.json",
    "total_tokens": 868,
    "translated_title": "语音内容嵌入的神经方法",
    "translated_abstract": "比较语音片段是语音处理中的核心操作。传统方法倾向于使用帧级动态规划算法（如动态时间规整），因为它们不需要监督，但在性能和效率上有局限性。作为替代，声学词嵌入——可变长度的语音词段的固定维度向量表示——开始被考虑用于这些任务。然而，当前仅限于这种鉴别性嵌入模型、训练方法以及其在实际下游任务中的应用。我们首先考虑“单视图”训练损失，目标是学习一种声学词嵌入模型，可以将相同词和不同词的语音段配对区分开。然后，我们考虑“多视图”对比损失。在这种设置中，声学词嵌入与字符序列的嵌入一起学习，以生成基于声学的嵌入。",
    "tldr": "该论文研究了语音内容嵌入的神经方法。传统方法限制了性能和效率，因此提出了声学词嵌入作为替代。论文提出了单视图和多视图训练损失的方法，并探讨了声学词嵌入在实际任务中的应用。",
    "en_tdlr": "This paper investigates neural approaches to spoken content embedding. Traditional methods have limitations in performance and efficiency, so acoustic word embeddings are proposed as an alternative. The paper presents methods for single-view and multi-view training losses, and explores the application of acoustic word embeddings in real-world tasks."
}