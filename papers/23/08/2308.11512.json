{
    "title": "L^2R: Lifelong Learning for First-stage Retrieval with Backward-Compatible Representations. (arXiv:2308.11512v1 [cs.IR])",
    "abstract": "First-stage retrieval is a critical task that aims to retrieve relevant document candidates from a large-scale collection. While existing retrieval models have achieved impressive performance, they are mostly studied on static data sets, ignoring that in the real-world, the data on the Web is continuously growing with potential distribution drift. Consequently, retrievers trained on static old data may not suit new-coming data well and inevitably produce sub-optimal results. In this work, we study lifelong learning for first-stage retrieval, especially focusing on the setting where the emerging documents are unlabeled since relevance annotation is expensive and may not keep up with data emergence. Under this setting, we aim to develop model updating with two goals: (1) to effectively adapt to the evolving distribution with the unlabeled new-coming data, and (2) to avoid re-inferring all embeddings of old documents to efficiently update the index each time the model is updated.  We firs",
    "link": "http://arxiv.org/abs/2308.11512",
    "context": "Title: L^2R: Lifelong Learning for First-stage Retrieval with Backward-Compatible Representations. (arXiv:2308.11512v1 [cs.IR])\nAbstract: First-stage retrieval is a critical task that aims to retrieve relevant document candidates from a large-scale collection. While existing retrieval models have achieved impressive performance, they are mostly studied on static data sets, ignoring that in the real-world, the data on the Web is continuously growing with potential distribution drift. Consequently, retrievers trained on static old data may not suit new-coming data well and inevitably produce sub-optimal results. In this work, we study lifelong learning for first-stage retrieval, especially focusing on the setting where the emerging documents are unlabeled since relevance annotation is expensive and may not keep up with data emergence. Under this setting, we aim to develop model updating with two goals: (1) to effectively adapt to the evolving distribution with the unlabeled new-coming data, and (2) to avoid re-inferring all embeddings of old documents to efficiently update the index each time the model is updated.  We firs",
    "path": "papers/23/08/2308.11512.json",
    "total_tokens": 961,
    "translated_title": "L^2R: 寿命学习用于具有向后兼容表示的第一阶段检索",
    "translated_abstract": "第一阶段检索是一个关键任务，旨在从大规模的文档集合中检索相关的候选文档。虽然现有的检索模型已经取得了令人瞩目的性能，但它们大多在静态数据集上进行研究，忽视了在现实世界中，Web上的数据不断增长，并可能出现分布漂移。因此，训练在静态旧数据上的检索器可能不适应新数据，并且不可避免地产生次优结果。在这项工作中，我们研究了对于第一阶段检索的寿命学习，特别关注于新出现的文档没有标签的情况下。在这种设置下，我们的目标是开发模型更新，以实现两个目标：（1）有效适应随时间推移而不断变化的分布，使用未标记的新数据，（2）避免重新推断所有旧文档的嵌入以在每次模型更新时高效地更新索引。",
    "tldr": "本论文研究了对于第一阶段检索的寿命学习，重点关注新出现的没有标签的文档。在该设置下，作者旨在通过模型更新达到两个目标：（1）有效适应不断变化的数据分布，使用未标记的新文档数据，（2）避免每次模型更新时重新计算所有旧文档的嵌入。",
    "en_tdlr": "This paper studies lifelong learning for first-stage retrieval, focusing on unlabeled emerging documents. The authors aim to achieve two goals through model updating: (1) effectively adapt to evolving data distributions using unlabeled new documents, (2) avoid recomputing embeddings for all old documents every time the model is updated."
}