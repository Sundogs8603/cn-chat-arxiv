{
    "title": "Text2KGBench: A Benchmark for Ontology-Driven Knowledge Graph Generation from Text. (arXiv:2308.02357v1 [cs.CL])",
    "abstract": "The recent advances in large language models (LLM) and foundation models with emergent capabilities have been shown to improve the performance of many NLP tasks. LLMs and Knowledge Graphs (KG) can complement each other such that LLMs can be used for KG construction or completion while existing KGs can be used for different tasks such as making LLM outputs explainable or fact-checking in Neuro-Symbolic manner. In this paper, we present Text2KGBench, a benchmark to evaluate the capabilities of language models to generate KGs from natural language text guided by an ontology. Given an input ontology and a set of sentences, the task is to extract facts from the text while complying with the given ontology (concepts, relations, domain/range constraints) and being faithful to the input sentences. We provide two datasets (i) Wikidata-TekGen with 10 ontologies and 13,474 sentences and (ii) DBpedia-WebNLG with 19 ontologies and 4,860 sentences. We define seven evaluation metrics to measure fact ",
    "link": "http://arxiv.org/abs/2308.02357",
    "context": "Title: Text2KGBench: A Benchmark for Ontology-Driven Knowledge Graph Generation from Text. (arXiv:2308.02357v1 [cs.CL])\nAbstract: The recent advances in large language models (LLM) and foundation models with emergent capabilities have been shown to improve the performance of many NLP tasks. LLMs and Knowledge Graphs (KG) can complement each other such that LLMs can be used for KG construction or completion while existing KGs can be used for different tasks such as making LLM outputs explainable or fact-checking in Neuro-Symbolic manner. In this paper, we present Text2KGBench, a benchmark to evaluate the capabilities of language models to generate KGs from natural language text guided by an ontology. Given an input ontology and a set of sentences, the task is to extract facts from the text while complying with the given ontology (concepts, relations, domain/range constraints) and being faithful to the input sentences. We provide two datasets (i) Wikidata-TekGen with 10 ontologies and 13,474 sentences and (ii) DBpedia-WebNLG with 19 ontologies and 4,860 sentences. We define seven evaluation metrics to measure fact ",
    "path": "papers/23/08/2308.02357.json",
    "total_tokens": 902,
    "translated_title": "Text2KGBench：一种从文本生成本体驱动的知识图谱的基准测试",
    "translated_abstract": "近年来，大型语言模型(LLM)和具有新兴能力的基础模型的进展已经证明可以改善许多自然语言处理任务的性能。LLM和知识图谱(KG)可以相互补充，LLM可以用于KG的构建或补全，而现有的KG可以用于不同的任务，例如使LLM的输出更易解释或进行类脑符号化的事实检查。本文提出了Text2KGBench，一种用于评估语言模型根据本体从自然语言文本中生成知识图谱的能力的基准测试。给定一个输入本体和一组句子，任务是从文本中提取事实，同时符合给定的本体(概念、关系、域/值范围约束)并忠实于输入句子。我们提供了两个数据集：(i)具有10个本体和13,474个句子的Wikidata-TekGen和(ii)具有19个本体和4,860个句子的DBpedia-WebNLG。我们定义了七个评估指标来衡量事实提取的性能。",
    "tldr": "Text2KGBench是一种用于评估语言模型根据本体从自然语言文本中生成知识图谱的能力的基准测试工具，在两个数据集上通过七个评估指标来衡量事实提取的性能。"
}