{
    "title": "Prototype Fission: Closing Set for Robust Open-set Semi-supervised Learning. (arXiv:2308.15575v1 [cs.LG])",
    "abstract": "Semi-supervised Learning (SSL) has been proven vulnerable to out-of-distribution (OOD) samples in realistic large-scale unsupervised datasets due to over-confident pseudo-labeling OODs as in-distribution (ID). A key underlying problem is class-wise latent space spreading from closed seen space to open unseen space, and the bias is further magnified in SSL's self-training loops. To close the ID distribution set so that OODs are better rejected for safe SSL, we propose Prototype Fission(PF) to divide class-wise latent spaces into compact sub-spaces by automatic fine-grained latent space mining, driven by coarse-grained labels only. Specifically, we form multiple unique learnable sub-class prototypes for each class, optimized towards both diversity and consistency. The Diversity Modeling term encourages samples to be clustered by one of the multiple sub-class prototypes, while the Consistency Modeling term clusters all samples of the same class to a global prototype. Instead of \"opening s",
    "link": "http://arxiv.org/abs/2308.15575",
    "context": "Title: Prototype Fission: Closing Set for Robust Open-set Semi-supervised Learning. (arXiv:2308.15575v1 [cs.LG])\nAbstract: Semi-supervised Learning (SSL) has been proven vulnerable to out-of-distribution (OOD) samples in realistic large-scale unsupervised datasets due to over-confident pseudo-labeling OODs as in-distribution (ID). A key underlying problem is class-wise latent space spreading from closed seen space to open unseen space, and the bias is further magnified in SSL's self-training loops. To close the ID distribution set so that OODs are better rejected for safe SSL, we propose Prototype Fission(PF) to divide class-wise latent spaces into compact sub-spaces by automatic fine-grained latent space mining, driven by coarse-grained labels only. Specifically, we form multiple unique learnable sub-class prototypes for each class, optimized towards both diversity and consistency. The Diversity Modeling term encourages samples to be clustered by one of the multiple sub-class prototypes, while the Consistency Modeling term clusters all samples of the same class to a global prototype. Instead of \"opening s",
    "path": "papers/23/08/2308.15575.json",
    "total_tokens": 973,
    "translated_title": "原型分裂：用于稳健的开放式半监督学习的封闭集合",
    "translated_abstract": "半监督学习（SSL）在现实的大规模无监督数据集中被证明容易受到来自超出分布（OOD）样本的攻击，因为过于自信地将OOD样本误判为目标分布（ID）样本。一个关键的问题是由于SSL的自我训练循环导致了来自已知分布空间的潜在空间扩散到未知分布空间，且这种偏差在SSL中会被放大。为了封闭ID分布集合，以便更好地拒绝OOD样本以实现安全的SSL，我们提出了原型分裂（PF），通过自动细粒度的潜在空间挖掘将类别的潜在空间分割为紧凑的子空间，仅依赖于粗粒度标签。具体而言，我们为每个类别形成多个独特的可学习子类别原型，优化其多样性和一致性。多样性建模项鼓励样本被聚集到多个子类别原型之一，而一致性建模项将同一类别的所有样本聚集到一个全局原型上。",
    "tldr": "本文提出了一种名为原型分裂（PF）的方法，通过自动细粒度的潜在空间挖掘将类别的潜在空间分割为紧凑的子空间，从而在半监督学习中更好地拒绝超出分布的样本。",
    "en_tdlr": "This paper proposes a method called Prototype Fission (PF) to divide class-wise latent spaces into compact sub-spaces by automatic fine-grained latent space mining, in order to better reject out-of-distribution samples in semi-supervised learning."
}