{
    "title": "Using Autoencoders and AutoDiff to Reconstruct Missing Variables in a Set of Time Series. (arXiv:2308.10496v1 [cs.LG])",
    "abstract": "Existing black box modeling approaches in machine learning suffer from a fixed input and output feature combination. In this paper, a new approach to reconstruct missing variables in a set of time series is presented. An autoencoder is trained as usual with every feature on both sides and the neural network parameters are fixed after this training. Then, the searched variables are defined as missing variables at the autoencoder input and optimized via automatic differentiation. This optimization is performed with respect to the available features loss calculation. With this method, different input and output feature combinations of the trained model can be realized by defining the searched variables as missing variables and reconstructing them. The combination can be changed without training the autoencoder again. The approach is evaluated on the base of a strongly nonlinear electrical component. It is working well for one of four variables missing and generally even for multiple missi",
    "link": "http://arxiv.org/abs/2308.10496",
    "context": "Title: Using Autoencoders and AutoDiff to Reconstruct Missing Variables in a Set of Time Series. (arXiv:2308.10496v1 [cs.LG])\nAbstract: Existing black box modeling approaches in machine learning suffer from a fixed input and output feature combination. In this paper, a new approach to reconstruct missing variables in a set of time series is presented. An autoencoder is trained as usual with every feature on both sides and the neural network parameters are fixed after this training. Then, the searched variables are defined as missing variables at the autoencoder input and optimized via automatic differentiation. This optimization is performed with respect to the available features loss calculation. With this method, different input and output feature combinations of the trained model can be realized by defining the searched variables as missing variables and reconstructing them. The combination can be changed without training the autoencoder again. The approach is evaluated on the base of a strongly nonlinear electrical component. It is working well for one of four variables missing and generally even for multiple missi",
    "path": "papers/23/08/2308.10496.json",
    "total_tokens": 930,
    "translated_title": "使用自编码器和自动微分来重构一组时间序列中的缺失变量",
    "translated_abstract": "机器学习中现有的黑盒建模方法受到固定输入和输出特征组合的限制。本文提出了一种新的方法，用于重构一组时间序列中的缺失变量。采用常规方式训练一个自编码器，将每个特征都放在两侧，然后在该训练之后固定神经网络参数。然后，将搜索的变量定义为自编码器输入处的缺失变量，并通过自动微分进行优化。这种优化是针对可用特征损失计算进行的。通过将搜索的变量定义为缺失变量并对其进行重构，可以实现训练模型的不同输入和输出特征组合。而且，无需再次训练自编码器即可更改组合。该方法在一个强非线性电子元件的基础上进行了评估。对于四个变量中的一个缺失，该方法效果良好，甚至对于多个缺失变量也有效。",
    "tldr": "本文提出了一种使用自编码器和自动微分来重构一组时间序列中缺失变量的新方法。通过训练自编码器，并在该训练之后固定神经网络参数，可以实现不同输入和输出特征组合的重构。该方法在强非线性电子元件上得到了验证，对于缺失的变量有效。",
    "en_tdlr": "This paper introduces a new approach to reconstruct missing variables in a set of time series using autoencoders and autodiff. By training the autoencoder and fixing the neural network parameters afterward, different input and output feature combinations can be reconstructed without retraining the autoencoder. The approach is validated on a strongly nonlinear electrical component and shows effectiveness in reconstructing missing variables."
}