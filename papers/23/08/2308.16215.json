{
    "title": "Deep Video Codec Control. (arXiv:2308.16215v1 [eess.IV])",
    "abstract": "Lossy video compression is commonly used when transmitting and storing video data. Unified video codecs (e.g., H.264 or H.265) remain the \\emph{de facto} standard, despite the availability of advanced (neural) compression approaches. Transmitting videos in the face of dynamic network bandwidth conditions requires video codecs to adapt to vastly different compression strengths. Rate control modules augment the codec's compression such that bandwidth constraints are satisfied and video distortion is minimized. While, both standard video codes and their rate control modules are developed to minimize video distortion w.r.t. human quality assessment, preserving the downstream performance of deep vision models is not considered. In this paper, we present the first end-to-end learnable deep video codec control considering both bandwidth constraints and downstream vision performance, while not breaking existing standardization. We demonstrate for two common vision tasks (semantic segmentation ",
    "link": "http://arxiv.org/abs/2308.16215",
    "context": "Title: Deep Video Codec Control. (arXiv:2308.16215v1 [eess.IV])\nAbstract: Lossy video compression is commonly used when transmitting and storing video data. Unified video codecs (e.g., H.264 or H.265) remain the \\emph{de facto} standard, despite the availability of advanced (neural) compression approaches. Transmitting videos in the face of dynamic network bandwidth conditions requires video codecs to adapt to vastly different compression strengths. Rate control modules augment the codec's compression such that bandwidth constraints are satisfied and video distortion is minimized. While, both standard video codes and their rate control modules are developed to minimize video distortion w.r.t. human quality assessment, preserving the downstream performance of deep vision models is not considered. In this paper, we present the first end-to-end learnable deep video codec control considering both bandwidth constraints and downstream vision performance, while not breaking existing standardization. We demonstrate for two common vision tasks (semantic segmentation ",
    "path": "papers/23/08/2308.16215.json",
    "total_tokens": 861,
    "translated_title": "深度视频编码控制",
    "translated_abstract": "丢失率视频压缩通常用于传输和存储视频数据。尽管存在进阶（神经）压缩方法，但统一视频编码器（如H.264或H.265）仍然是事实上的标准。在面对动态网络带宽条件的视频传输中，视频编码器需要适应非常不同的压缩强度。速率控制模块增强编解码器的压缩能力，以满足带宽限制并尽量减少视频失真。然而，标准视频编码器及其速率控制模块是为了最小化人类质量评估而开发的，却没有考虑保护深度视觉模型的下游性能。在本文中，我们提出了第一个端到端可学习的深度视频编码控制方法，考虑了带宽限制和下游视觉性能，并不破坏现有的标准化。我们针对两个常见的视觉任务（语义分割...",
    "tldr": "本文提出了第一个端到端可学习的深度视频编码控制方法，同时考虑了带宽限制和下游视觉性能，并在不破坏现有标准化的情况下实现了保护深度视觉模型的目标。",
    "en_tdlr": "This paper presents the first end-to-end learnable deep video codec control method, considering both bandwidth constraints and downstream vision performance, while preserving the objectives of protecting deep vision models without breaking existing standardization."
}