{
    "title": "The Bias Amplification Paradox in Text-to-Image Generation. (arXiv:2308.00755v1 [cs.LG])",
    "abstract": "Bias amplification is a phenomenon in which models increase imbalances present in the training data. In this paper, we study bias amplification in the text-to-image domain using Stable Diffusion by comparing gender ratios in training vs. generated images. We find that the model appears to amplify gender-occupation biases found in the training data (LAION). However, we discover that amplification can largely be attributed to discrepancies between training captions and model prompts. For example, an inherent difference is that captions from the training data often contain explicit gender information while the prompts we use do not, which leads to a distribution shift and consequently impacts bias measures. Once we account for various distributional differences between texts used for training and generation, we observe that amplification decreases considerably. Our findings illustrate the challenges of comparing biases in models and the data they are trained on, and highlight confounding ",
    "link": "http://arxiv.org/abs/2308.00755",
    "context": "Title: The Bias Amplification Paradox in Text-to-Image Generation. (arXiv:2308.00755v1 [cs.LG])\nAbstract: Bias amplification is a phenomenon in which models increase imbalances present in the training data. In this paper, we study bias amplification in the text-to-image domain using Stable Diffusion by comparing gender ratios in training vs. generated images. We find that the model appears to amplify gender-occupation biases found in the training data (LAION). However, we discover that amplification can largely be attributed to discrepancies between training captions and model prompts. For example, an inherent difference is that captions from the training data often contain explicit gender information while the prompts we use do not, which leads to a distribution shift and consequently impacts bias measures. Once we account for various distributional differences between texts used for training and generation, we observe that amplification decreases considerably. Our findings illustrate the challenges of comparing biases in models and the data they are trained on, and highlight confounding ",
    "path": "papers/23/08/2308.00755.json",
    "total_tokens": 878,
    "translated_title": "文本到图像生成中的偏见放大悖论",
    "translated_abstract": "偏见放大是一种模型增加训练数据中不平衡的现象。本文通过使用稳定扩散来比较训练数据与生成图像中的性别比例，研究了文本到图像领域中的偏见放大现象。我们发现模型似乎放大了训练数据中存在的性别-职业偏见。然而，我们发现放大很大程度上可以归因于训练数据和模型提示之间的差异。例如，训练数据中的标题通常包含明确的性别信息，而我们使用的提示则不包含，这导致了分布的偏移，从而影响了偏见度量。一旦我们考虑到训练和生成时使用的文本之间的各种分布差异，我们观察到放大现象大大减少。我们的发现说明了比较模型和它们所训练的数据中的偏见所面临的挑战，并且强调了混淆因素。",
    "tldr": "本文研究了文本到图像生成中的偏见放大现象，并发现其主要原因是训练数据和模型提示之间的差异。一旦考虑到各种分布差异，偏见放大现象显著减少。",
    "en_tdlr": "This paper investigates the bias amplification phenomenon in text-to-image generation and finds that it is mainly caused by discrepancies between training data and model prompts. Once accounting for various distributional differences, the bias amplification decreases considerably."
}