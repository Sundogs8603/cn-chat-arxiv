{
    "title": "DPMAC: Differentially Private Communication for Cooperative Multi-Agent Reinforcement Learning. (arXiv:2308.09902v1 [cs.LG])",
    "abstract": "Communication lays the foundation for cooperation in human society and in multi-agent reinforcement learning (MARL). Humans also desire to maintain their privacy when communicating with others, yet such privacy concern has not been considered in existing works in MARL. To this end, we propose the \\textit{differentially private multi-agent communication} (DPMAC) algorithm, which protects the sensitive information of individual agents by equipping each agent with a local message sender with rigorous $(\\epsilon, \\delta)$-differential privacy (DP) guarantee. In contrast to directly perturbing the messages with predefined DP noise as commonly done in privacy-preserving scenarios, we adopt a stochastic message sender for each agent respectively and incorporate the DP requirement into the sender, which automatically adjusts the learned message distribution to alleviate the instability caused by DP noise. Further, we prove the existence of a Nash equilibrium in cooperative MARL with privacy-pr",
    "link": "http://arxiv.org/abs/2308.09902",
    "context": "Title: DPMAC: Differentially Private Communication for Cooperative Multi-Agent Reinforcement Learning. (arXiv:2308.09902v1 [cs.LG])\nAbstract: Communication lays the foundation for cooperation in human society and in multi-agent reinforcement learning (MARL). Humans also desire to maintain their privacy when communicating with others, yet such privacy concern has not been considered in existing works in MARL. To this end, we propose the \\textit{differentially private multi-agent communication} (DPMAC) algorithm, which protects the sensitive information of individual agents by equipping each agent with a local message sender with rigorous $(\\epsilon, \\delta)$-differential privacy (DP) guarantee. In contrast to directly perturbing the messages with predefined DP noise as commonly done in privacy-preserving scenarios, we adopt a stochastic message sender for each agent respectively and incorporate the DP requirement into the sender, which automatically adjusts the learned message distribution to alleviate the instability caused by DP noise. Further, we prove the existence of a Nash equilibrium in cooperative MARL with privacy-pr",
    "path": "papers/23/08/2308.09902.json",
    "total_tokens": 882,
    "translated_title": "DPMAC：差分隐私通信在多代理强化学习中的应用",
    "translated_abstract": "通信对于人类社会和多代理强化学习(MARL)中的合作至关重要。人类在与他人交流时也希望保护自己的隐私，然而这方面的考虑在现有的MARL研究中并未得到充分考虑。因此，我们提出了差分隐私多代理通信(DPMAC)算法，通过为每个代理配备具有严格(ε,δ)-差分隐私(DP)保证的本地消息发送器来保护个体代理的敏感信息。与在隐私保护场景中常用的直接给消息加入预定义的DP噪声不同，我们为每个代理采用了一个随机消息发送器，并将DP要求融入发送器中，自动调整学习到的消息分布，从而减轻DP噪声带来的不稳定性。此外，我们证明了在具有隐私保护的合作MARL中存在纳什均衡。",
    "tldr": "DPMAC算法在多代理强化学习中应用了差分隐私通信机制，通过为每个代理配备本地消息发送器并根据差分隐私要求调整消息分布，保护了个体代理的隐私信息。",
    "en_tdlr": "DPMAC algorithm applies differentially private communication mechanism in multi-agent reinforcement learning, protecting the privacy of individual agents by equipping each agent with a local message sender and adjusting the message distribution based on differential privacy requirements."
}