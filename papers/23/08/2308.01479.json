{
    "title": "Investigating Reinforcement Learning for Communication Strategies in a Task-Initiative Setting. (arXiv:2308.01479v1 [cs.CL])",
    "abstract": "Many conversational domains require the system to present nuanced information to users. Such systems must follow up what they say to address clarification questions and repair misunderstandings. In this work, we explore this interactive strategy in a referential communication task. Using simulation, we analyze the communication trade-offs between initial presentation and subsequent followup as a function of user clarification strategy, and compare the performance of several baseline strategies to policies derived by reinforcement learning. We find surprising advantages to coherence-based representations of dialogue strategy, which bring minimal data requirements, explainable choices, and strong audit capabilities, but incur little loss in predicted outcomes across a wide range of user models.",
    "link": "http://arxiv.org/abs/2308.01479",
    "context": "Title: Investigating Reinforcement Learning for Communication Strategies in a Task-Initiative Setting. (arXiv:2308.01479v1 [cs.CL])\nAbstract: Many conversational domains require the system to present nuanced information to users. Such systems must follow up what they say to address clarification questions and repair misunderstandings. In this work, we explore this interactive strategy in a referential communication task. Using simulation, we analyze the communication trade-offs between initial presentation and subsequent followup as a function of user clarification strategy, and compare the performance of several baseline strategies to policies derived by reinforcement learning. We find surprising advantages to coherence-based representations of dialogue strategy, which bring minimal data requirements, explainable choices, and strong audit capabilities, but incur little loss in predicted outcomes across a wide range of user models.",
    "path": "papers/23/08/2308.01479.json",
    "total_tokens": 803,
    "translated_title": "在任务主动设置中研究强化学习在通信策略中的应用",
    "translated_abstract": "许多对话域需要系统向用户呈现细微差别的信息。这样的系统必须在他们说话后进行追问以解答疑问和纠正误解。在这项工作中，我们在一项引用通信任务中探索了这种互动策略。通过模拟，我们分析了初始呈现和随后追问之间的通信权衡，这是用户澄清策略的一个函数。我们将几种基线策略与强化学习得来的策略性进行了比较。我们发现，基于一致性的对话策略表示具有令人惊讶的优势，该方法要求的数据需求很小，选择解释性强，并具有强大的审计能力，但在广泛的用户模型范围内预测结果几乎没有损失。",
    "tldr": "在这项工作中，我们通过分析模拟实验，研究了在任务主动设置中应用强化学习来处理系统和用户之间的引用通信任务，并发现基于一致性的对话策略具有潜力成为有效的策略选择方法。",
    "en_tdlr": "In this work, we investigate the application of reinforcement learning in handling referential communication tasks between systems and users in a task-initiative setting. We find that coherence-based representations of dialogue strategy have the potential to be an effective strategy selection method."
}