{
    "title": "StyleInV: A Temporal Style Modulated Inversion Network for Unconditional Video Generation. (arXiv:2308.16909v1 [cs.CV])",
    "abstract": "Unconditional video generation is a challenging task that involves synthesizing high-quality videos that are both coherent and of extended duration. To address this challenge, researchers have used pretrained StyleGAN image generators for high-quality frame synthesis and focused on motion generator design. The motion generator is trained in an autoregressive manner using heavy 3D convolutional discriminators to ensure motion coherence during video generation. In this paper, we introduce a novel motion generator design that uses a learning-based inversion network for GAN. The encoder in our method captures rich and smooth priors from encoding images to latents, and given the latent of an initially generated frame as guidance, our method can generate smooth future latent by modulating the inversion encoder temporally. Our method enjoys the advantage of sparse training and naturally constrains the generation space of our motion generator with the inversion network guided by the initial fr",
    "link": "http://arxiv.org/abs/2308.16909",
    "context": "Title: StyleInV: A Temporal Style Modulated Inversion Network for Unconditional Video Generation. (arXiv:2308.16909v1 [cs.CV])\nAbstract: Unconditional video generation is a challenging task that involves synthesizing high-quality videos that are both coherent and of extended duration. To address this challenge, researchers have used pretrained StyleGAN image generators for high-quality frame synthesis and focused on motion generator design. The motion generator is trained in an autoregressive manner using heavy 3D convolutional discriminators to ensure motion coherence during video generation. In this paper, we introduce a novel motion generator design that uses a learning-based inversion network for GAN. The encoder in our method captures rich and smooth priors from encoding images to latents, and given the latent of an initially generated frame as guidance, our method can generate smooth future latent by modulating the inversion encoder temporally. Our method enjoys the advantage of sparse training and naturally constrains the generation space of our motion generator with the inversion network guided by the initial fr",
    "path": "papers/23/08/2308.16909.json",
    "total_tokens": 868,
    "translated_title": "StyleInV:一种用于无条件视频生成的时间风格调制逆向网络",
    "translated_abstract": "无条件视频生成是一项具有挑战性的任务，需要合成既连贯又持续时间较长的高质量视频。为了解决这个挑战，研究者们使用预训练的StyleGAN图像生成器进行高质量帧合成，并专注于运动生成器的设计。运动生成器通过使用重型三维卷积辨别器进行迭代训练，以确保视频生成过程中的运动连贯性。在本文中，我们引入了一种新颖的运动生成器设计，它使用了基于学习的反向网络来实现GAN。我们的方法中的编码器从编码图像到潜变量中捕捉到了丰富而平滑的先验知识，并且在给定初始生成帧的潜变量作为指导的情况下，通过在时间上调制反向编码器，我们的方法可以生成平滑的未来潜变量。我们的方法具有稀疏训练的优势，并且通过初始帧引导的反向网络有效约束了运动生成器的生成空间。",
    "tldr": "这项研究介绍了一个用于无条件视频生成的新型运动生成器设计，利用基于学习的反向网络实现了运动连贯性和生成空间的约束。",
    "en_tdlr": "This research introduces a novel motion generator design for unconditional video generation, which utilizes a learning-based inversion network to achieve motion coherence and constraints on the generation space."
}