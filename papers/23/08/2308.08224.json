{
    "title": "How To Overcome Confirmation Bias in Semi-Supervised Image Classification By Active Learning. (arXiv:2308.08224v1 [cs.LG])",
    "abstract": "Do we need active learning? The rise of strong deep semi-supervised methods raises doubt about the usability of active learning in limited labeled data settings. This is caused by results showing that combining semi-supervised learning (SSL) methods with a random selection for labeling can outperform existing active learning (AL) techniques. However, these results are obtained from experiments on well-established benchmark datasets that can overestimate the external validity. However, the literature lacks sufficient research on the performance of active semi-supervised learning methods in realistic data scenarios, leaving a notable gap in our understanding. Therefore we present three data challenges common in real-world applications: between-class imbalance, within-class imbalance, and between-class similarity. These challenges can hurt SSL performance due to confirmation bias. We conduct experiments with SSL and AL on simulated data challenges and find that random sampling does not mi",
    "link": "http://arxiv.org/abs/2308.08224",
    "context": "Title: How To Overcome Confirmation Bias in Semi-Supervised Image Classification By Active Learning. (arXiv:2308.08224v1 [cs.LG])\nAbstract: Do we need active learning? The rise of strong deep semi-supervised methods raises doubt about the usability of active learning in limited labeled data settings. This is caused by results showing that combining semi-supervised learning (SSL) methods with a random selection for labeling can outperform existing active learning (AL) techniques. However, these results are obtained from experiments on well-established benchmark datasets that can overestimate the external validity. However, the literature lacks sufficient research on the performance of active semi-supervised learning methods in realistic data scenarios, leaving a notable gap in our understanding. Therefore we present three data challenges common in real-world applications: between-class imbalance, within-class imbalance, and between-class similarity. These challenges can hurt SSL performance due to confirmation bias. We conduct experiments with SSL and AL on simulated data challenges and find that random sampling does not mi",
    "path": "papers/23/08/2308.08224.json",
    "total_tokens": 932,
    "translated_title": "如何通过主动学习克服半监督图像分类中的确认偏差",
    "translated_abstract": "我们是否需要主动学习？强大的深度半监督方法的崛起对有限标记数据设置中主动学习的可用性提出了疑问。结果表明，将半监督学习方法与随机选择进行标记相结合可以胜过现有的主动学习技术。然而，这些结果来自于在公认的基准数据集上进行的实验，可能高估了外部有效性。然而，文献中对主动半监督学习方法在实际数据场景中的性能缺乏足够的研究，这在我们的理解中存在明显的空白。因此，我们提出了三个在现实世界应用中常见的数据挑战：类间不平衡、类内不平衡和类间相似性。这些挑战可能由于确认偏差而损害半监督学习的性能。我们在模拟数据挑战上进行了半监督学习和主动学习的实验，并发现随机采样不能解决这些挑战。",
    "tldr": "本论文研究了半监督学习中的确认偏差问题，并提出了三个现实数据场景中的挑战，分别是类间不平衡、类内不平衡和类间相似性。通过在模拟数据中进行实验，发现随机采样不能解决这些挑战。",
    "en_tdlr": "This paper investigates the issue of confirmation bias in semi-supervised learning and presents three data challenges commonly encountered in real-world scenarios: between-class imbalance, within-class imbalance, and between-class similarity. Experimental results on simulated data demonstrate that random sampling is ineffective in addressing these challenges."
}