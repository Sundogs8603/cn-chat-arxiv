{
    "title": "Understanding CNN Hidden Neuron Activations using Structured Background Knowledge and Deductive Reasoning. (arXiv:2308.03999v1 [cs.LG])",
    "abstract": "A major challenge in Explainable AI is in correctly interpreting activations of hidden neurons: accurate interpretations would provide insights into the question of what a deep learning system has internally detected as relevant on the input, de-mystifying the otherwise black-box character of deep learning systems. The state of the art indicates that hidden node activations can, in some cases, be interpretable in a way that makes sense to humans, but systematic automated methods that would be able to hypothesize and verify interpretations of hidden neuron activations are underexplored. In this paper, we provide such a method and demonstrate that it provides meaningful interpretations. Our approach is based on using large-scale background knowledge approximately 2 million classes curated from the Wikipedia concept hierarchy together with a symbolic reasoning approach called Concept Induction based on description logics, originally developed for applications in the Semantic Web field. Ou",
    "link": "http://arxiv.org/abs/2308.03999",
    "context": "Title: Understanding CNN Hidden Neuron Activations using Structured Background Knowledge and Deductive Reasoning. (arXiv:2308.03999v1 [cs.LG])\nAbstract: A major challenge in Explainable AI is in correctly interpreting activations of hidden neurons: accurate interpretations would provide insights into the question of what a deep learning system has internally detected as relevant on the input, de-mystifying the otherwise black-box character of deep learning systems. The state of the art indicates that hidden node activations can, in some cases, be interpretable in a way that makes sense to humans, but systematic automated methods that would be able to hypothesize and verify interpretations of hidden neuron activations are underexplored. In this paper, we provide such a method and demonstrate that it provides meaningful interpretations. Our approach is based on using large-scale background knowledge approximately 2 million classes curated from the Wikipedia concept hierarchy together with a symbolic reasoning approach called Concept Induction based on description logics, originally developed for applications in the Semantic Web field. Ou",
    "path": "papers/23/08/2308.03999.json",
    "total_tokens": 845,
    "translated_title": "使用结构化背景知识和演绎推理理解CNN隐藏神经元激活",
    "translated_abstract": "Explainable AI中的一个主要挑战是准确解释隐藏神经元的激活：准确的解释将为深度学习系统内部检测到的输入相关内容提供洞察力，揭示深度学习系统的黑盒特性。现有技术表明，在某些情况下，隐藏节点的激活可以被人类理解，但是对隐藏神经元激活的解释进行假设和验证的系统化自动化方法尚未充分研究。在本文中，我们提供了这样一种方法，并证明它提供了有意义的解释。我们的方法基于使用大规模的背景知识，从维基百科概念层次结构中筛选出的约200万个类别，以及一个称为概念归纳的符号推理方法，这种方法最初是为语义Web领域的应用而开发的。",
    "tldr": "本文提供了一种使用结构化背景知识和演绎推理的方法，用于解释CNN隐藏神经元的激活。该方法能够提供有意义的解释，解决了深度学习系统黑盒特性的问题。"
}