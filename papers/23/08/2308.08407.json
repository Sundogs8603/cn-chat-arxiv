{
    "title": "Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities. (arXiv:2308.08407v1 [cs.LG])",
    "abstract": "Recent advancements in AI applications to healthcare have shown incredible promise in surpassing human performance in diagnosis and disease prognosis. With the increasing complexity of AI models, however, concerns regarding their opacity, potential biases, and the need for interpretability. To ensure trust and reliability in AI systems, especially in clinical risk prediction models, explainability becomes crucial. Explainability is usually referred to as an AI system's ability to provide a robust interpretation of its decision-making logic or the decisions themselves to human stakeholders. In clinical risk prediction, other aspects of explainability like fairness, bias, trust, and transparency also represent important concepts beyond just interpretability. In this review, we address the relationship between these concepts as they are often used together or interchangeably. This review also discusses recent progress in developing explainable models for clinical risk prediction, highligh",
    "link": "http://arxiv.org/abs/2308.08407",
    "context": "Title: Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities. (arXiv:2308.08407v1 [cs.LG])\nAbstract: Recent advancements in AI applications to healthcare have shown incredible promise in surpassing human performance in diagnosis and disease prognosis. With the increasing complexity of AI models, however, concerns regarding their opacity, potential biases, and the need for interpretability. To ensure trust and reliability in AI systems, especially in clinical risk prediction models, explainability becomes crucial. Explainability is usually referred to as an AI system's ability to provide a robust interpretation of its decision-making logic or the decisions themselves to human stakeholders. In clinical risk prediction, other aspects of explainability like fairness, bias, trust, and transparency also represent important concepts beyond just interpretability. In this review, we address the relationship between these concepts as they are often used together or interchangeably. This review also discusses recent progress in developing explainable models for clinical risk prediction, highligh",
    "path": "papers/23/08/2308.08407.json",
    "total_tokens": 1041,
    "translated_title": "可解释的人工智能在临床风险预测中的应用:概念、方法和方式的调查",
    "translated_abstract": "最近人工智能在医疗保健领域的应用取得了令人难以置信的成果，在诊断和疾病预测方面超越了人类性能。然而，随着人工智能模型复杂性的增加，对其不透明性、潜在偏见以及可解释性的担忧也日益增加。为了确保人们对人工智能系统的信任和可靠性，尤其是在临床风险预测模型中，可解释性变得至关重要。可解释性通常指的是人工智能系统向人类利益相关者提供其决策逻辑或决策本身的稳健解释能力。在临床风险预测中，公平性、偏见、信任和透明度等其他方面的可解释性也代表了超越可解释性本身的重要概念。在本综述中，我们探讨了这些概念之间的关系，因为它们通常一起或可互换地使用。本综述还讨论了最近在临床风险预测的可解释模型的发展进展，",
    "tldr": "这篇综述论文讨论了可解释的人工智能在临床风险预测中的应用，包括概念、方法和方式。可解释性对于确保人们对AI系统的信任和可靠性至关重要，除了解释性之外，还涉及公平性、偏见、信任和透明度等方面。该综述还讨论了近期在临床风险预测中可解释模型的进展。"
}