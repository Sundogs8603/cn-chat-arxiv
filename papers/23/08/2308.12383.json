{
    "title": "With a Little Help from your own Past: Prototypical Memory Networks for Image Captioning. (arXiv:2308.12383v1 [cs.CV])",
    "abstract": "Image captioning, like many tasks involving vision and language, currently relies on Transformer-based architectures for extracting the semantics in an image and translating it into linguistically coherent descriptions. Although successful, the attention operator only considers a weighted summation of projections of the current input sample, therefore ignoring the relevant semantic information which can come from the joint observation of other samples. In this paper, we devise a network which can perform attention over activations obtained while processing other training samples, through a prototypical memory model. Our memory models the distribution of past keys and values through the definition of prototype vectors which are both discriminative and compact. Experimentally, we assess the performance of the proposed model on the COCO dataset, in comparison with carefully designed baselines and state-of-the-art approaches, and by investigating the role of each of the proposed components",
    "link": "http://arxiv.org/abs/2308.12383",
    "context": "Title: With a Little Help from your own Past: Prototypical Memory Networks for Image Captioning. (arXiv:2308.12383v1 [cs.CV])\nAbstract: Image captioning, like many tasks involving vision and language, currently relies on Transformer-based architectures for extracting the semantics in an image and translating it into linguistically coherent descriptions. Although successful, the attention operator only considers a weighted summation of projections of the current input sample, therefore ignoring the relevant semantic information which can come from the joint observation of other samples. In this paper, we devise a network which can perform attention over activations obtained while processing other training samples, through a prototypical memory model. Our memory models the distribution of past keys and values through the definition of prototype vectors which are both discriminative and compact. Experimentally, we assess the performance of the proposed model on the COCO dataset, in comparison with carefully designed baselines and state-of-the-art approaches, and by investigating the role of each of the proposed components",
    "path": "papers/23/08/2308.12383.json",
    "total_tokens": 856,
    "translated_title": "通过过去的记忆：用于图像字幕生成的典型记忆网络",
    "translated_abstract": "图像字幕生成是一个涉及视觉和语言的任务，目前依赖于基于Transformer的架构来提取图像的语义并将其转化为语义连贯的描述。尽管成功，但注意力机制只考虑当前输入样本的投影加权求和，因此忽略了来自其他样本的相关语义信息。在本文中，我们设计了一个网络，该网络可以通过典型记忆模型在处理其他训练样本时执行注意力操作。我们的记忆通过原型向量的定义来建模过去的键和值的分布，这些原型向量既具有区分性又紧凑。在实验中，我们将所提出模型与精心设计的基准模型和最先进方法进行比较，并研究每个提出的组件的作用。",
    "tldr": "本文提出了一种典型记忆网络，用于提取图像的语义并生成语义连贯的描述。通过在处理其他训练样本时执行注意力操作，该网络能够利用先前激活的信息。实验证明，该模型在COCO数据集上的性能优于其他基准模型和最先进方法。",
    "en_tdlr": "This paper proposes a prototypical memory network for image captioning that can extract semantic information from images and generate linguistically coherent descriptions. By performing attention over activations obtained from other training samples, the network is able to utilize past information. Experimental results demonstrate that the proposed model outperforms baseline models and state-of-the-art approaches on the COCO dataset."
}