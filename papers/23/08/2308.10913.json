{
    "title": "Automated mapping of virtual environments with visual predictive coding. (arXiv:2308.10913v1 [q-bio.NC])",
    "abstract": "Humans construct internal cognitive maps of their environment directly from sensory inputs without access to a system of explicit coordinates or distance measurements. While machine learning algorithms like SLAM utilize specialized visual inference procedures to identify visual features and construct spatial maps from visual and odometry data, the general nature of cognitive maps in the brain suggests a unified mapping algorithmic strategy that can generalize to auditory, tactile, and linguistic inputs. Here, we demonstrate that predictive coding provides a natural and versatile neural network algorithm for constructing spatial maps using sensory data. We introduce a framework in which an agent navigates a virtual environment while engaging in visual predictive coding using a self-attention-equipped convolutional neural network. While learning a next image prediction task, the agent automatically constructs an internal representation of the environment that quantitatively reflects dist",
    "link": "http://arxiv.org/abs/2308.10913",
    "context": "Title: Automated mapping of virtual environments with visual predictive coding. (arXiv:2308.10913v1 [q-bio.NC])\nAbstract: Humans construct internal cognitive maps of their environment directly from sensory inputs without access to a system of explicit coordinates or distance measurements. While machine learning algorithms like SLAM utilize specialized visual inference procedures to identify visual features and construct spatial maps from visual and odometry data, the general nature of cognitive maps in the brain suggests a unified mapping algorithmic strategy that can generalize to auditory, tactile, and linguistic inputs. Here, we demonstrate that predictive coding provides a natural and versatile neural network algorithm for constructing spatial maps using sensory data. We introduce a framework in which an agent navigates a virtual environment while engaging in visual predictive coding using a self-attention-equipped convolutional neural network. While learning a next image prediction task, the agent automatically constructs an internal representation of the environment that quantitatively reflects dist",
    "path": "papers/23/08/2308.10913.json",
    "total_tokens": 824,
    "translated_title": "自动利用视觉预测编码进行虚拟环境映射",
    "translated_abstract": "人类根据感知输入直接构建对环境的内部认知地图，而不需要具有明确坐标或距离测量的系统。虽然机器学习算法如SLAM利用专门的视觉推理过程从视觉和里程计数据中识别视觉特征并构建空间地图，但大脑中认知地图的一般性表明可以使用统一的映射算法策略来泛化到听觉、触觉和语言输入。在这里，我们展示了预测编码提供了一种自然且多功能的神经网络算法，可以使用感知数据构建空间地图。我们介绍了一个框架，其中代理在虚拟环境中导航，并使用具有自我注意力的卷积神经网络进行视觉预测编码。在学习下一个图像预测任务的同时，代理会自动构建一个内部对环境的表示，定量地反映出距离等信息。",
    "tldr": "本文提出了一种利用预测编码进行虚拟环境映射的算法，该算法可以根据感知数据构建空间地图，并在不同输入模态下具有泛化能力。"
}