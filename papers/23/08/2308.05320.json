{
    "title": "Adv-Inpainting: Generating Natural and Transferable Adversarial Patch via Attention-guided Feature Fusion. (arXiv:2308.05320v1 [cs.CV])",
    "abstract": "The rudimentary adversarial attacks utilize additive noise to attack facial recognition (FR) models. However, because manipulating the total face is impractical in the physical setting, most real-world FR attacks are based on adversarial patches, which limit perturbations to a small area. Previous adversarial patch attacks often resulted in unnatural patterns and clear boundaries that were easily noticeable. In this paper, we argue that generating adversarial patches with plausible content can result in stronger transferability than using additive noise or directly sampling from the latent space. To generate natural-looking and highly transferable adversarial patches, we propose an innovative two-stage coarse-to-fine attack framework called Adv-Inpainting. In the first stage, we propose an attention-guided StyleGAN (Att-StyleGAN) that adaptively combines texture and identity features based on the attention map to generate high-transferable and natural adversarial patches. In the second",
    "link": "http://arxiv.org/abs/2308.05320",
    "context": "Title: Adv-Inpainting: Generating Natural and Transferable Adversarial Patch via Attention-guided Feature Fusion. (arXiv:2308.05320v1 [cs.CV])\nAbstract: The rudimentary adversarial attacks utilize additive noise to attack facial recognition (FR) models. However, because manipulating the total face is impractical in the physical setting, most real-world FR attacks are based on adversarial patches, which limit perturbations to a small area. Previous adversarial patch attacks often resulted in unnatural patterns and clear boundaries that were easily noticeable. In this paper, we argue that generating adversarial patches with plausible content can result in stronger transferability than using additive noise or directly sampling from the latent space. To generate natural-looking and highly transferable adversarial patches, we propose an innovative two-stage coarse-to-fine attack framework called Adv-Inpainting. In the first stage, we propose an attention-guided StyleGAN (Att-StyleGAN) that adaptively combines texture and identity features based on the attention map to generate high-transferable and natural adversarial patches. In the second",
    "path": "papers/23/08/2308.05320.json",
    "total_tokens": 974,
    "translated_title": "Adv-Inpainting:通过注意力引导的特征融合生成自然且可迁移的对抗性贴纸",
    "translated_abstract": "最初的对抗性攻击利用加性噪声攻击人脸识别模型。然而，由于在实际环境中操作整个脸部是不切实际的，大多数现实世界中的人脸识别攻击都基于对抗性贴纸，将扰动限制在一个较小的区域内。先前的对抗性贴纸攻击常常导致不自然的图案和明显的边界，容易被察觉。我们认为生成带有合理内容的对抗性贴纸会比使用加性噪声或直接从潜在空间进行采样更具有更强的迁移性。为了生成自然且高度可迁移的对抗性贴纸，我们提出了一种创新的两阶段粗到精的攻击框架，称为Adv-Inpainting。在第一阶段中，我们提出了一种注意力引导的StyleGAN（Att-StyleGAN），根据注意力图自适应地结合纹理和身份特征，生成高度可迁移和自然的对抗性贴纸。",
    "tldr": "本文提出了一种称为Adv-Inpainting的创新攻击框架，通过注意力引导的特征融合生成自然且可迁移的对抗性贴纸，相比于传统的对抗性贴纸方法，该方法在生成图案和边界方面更加自然，并具有更强的迁移性能。"
}