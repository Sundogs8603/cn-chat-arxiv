{
    "title": "Semantic Image Synthesis via Class-Adaptive Cross-Attention. (arXiv:2308.16071v1 [cs.CV])",
    "abstract": "In semantic image synthesis, the state of the art is dominated by methods that use spatially-adaptive normalization layers, which allow for excellent visual generation quality and editing versatility. Granted their efficacy, recent research efforts have focused toward finer-grained local style control and multi-modal generation. By construction though, such layers tend to overlook global image statistics leading to unconvincing local style editing and causing global inconsistencies such as color or illumination distribution shifts. Also, the semantic layout is required for mapping styles in the generator, putting a strict alignment constraint over the features. In response, we designed a novel architecture where cross-attention layers are used in place of de-normalization ones for conditioning the image generation. Our model inherits the advantages of both solutions, retaining state-of-the-art reconstruction quality, as well as improved global and local style transfer. Code and models ",
    "link": "http://arxiv.org/abs/2308.16071",
    "context": "Title: Semantic Image Synthesis via Class-Adaptive Cross-Attention. (arXiv:2308.16071v1 [cs.CV])\nAbstract: In semantic image synthesis, the state of the art is dominated by methods that use spatially-adaptive normalization layers, which allow for excellent visual generation quality and editing versatility. Granted their efficacy, recent research efforts have focused toward finer-grained local style control and multi-modal generation. By construction though, such layers tend to overlook global image statistics leading to unconvincing local style editing and causing global inconsistencies such as color or illumination distribution shifts. Also, the semantic layout is required for mapping styles in the generator, putting a strict alignment constraint over the features. In response, we designed a novel architecture where cross-attention layers are used in place of de-normalization ones for conditioning the image generation. Our model inherits the advantages of both solutions, retaining state-of-the-art reconstruction quality, as well as improved global and local style transfer. Code and models ",
    "path": "papers/23/08/2308.16071.json",
    "total_tokens": 834,
    "translated_title": "基于类自适应交叉注意力的语义图像合成",
    "translated_abstract": "在语义图像合成领域，最先进的方法主要使用空间自适应归一化层，可以实现出色的视觉生成质量和编辑灵活性。然而，这些方法往往忽略全局图像统计信息，导致局部样式编辑不真实，并引起诸如色彩或光照分布偏移等全局不一致性。此外，生成器需要语义布局来映射样式，对特征提出了严格的对齐约束。为解决这些问题，我们设计了一种新颖的架构，使用交叉注意力层代替反归一化层来调节图像生成。我们的模型继承了两种方法的优点，保持了最先进的重建质量，并且改进了全局和局部样式转移。",
    "tldr": "本文提出了一种基于类自适应交叉注意力的语义图像合成方法，通过使用交叉注意力层来调节图像生成，实现了优秀的视觉生成质量和编辑灵活性，并解决了全局样式不一致和局部样式编辑不真实的问题。"
}