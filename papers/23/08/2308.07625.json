{
    "title": "Backpropagation Path Search On Adversarial Transferability. (arXiv:2308.07625v1 [cs.CV])",
    "abstract": "Deep neural networks are vulnerable to adversarial examples, dictating the imperativeness to test the model's robustness before deployment. Transfer-based attackers craft adversarial examples against surrogate models and transfer them to victim models deployed in the black-box situation. To enhance the adversarial transferability, structure-based attackers adjust the backpropagation path to avoid the attack from overfitting the surrogate model. However, existing structure-based attackers fail to explore the convolution module in CNNs and modify the backpropagation graph heuristically, leading to limited effectiveness. In this paper, we propose backPropagation pAth Search (PAS), solving the aforementioned two problems. We first propose SkipConv to adjust the backpropagation path of convolution by structural reparameterization. To overcome the drawback of heuristically designed backpropagation paths, we further construct a DAG-based search space, utilize one-step approximation for path e",
    "link": "http://arxiv.org/abs/2308.07625",
    "context": "Title: Backpropagation Path Search On Adversarial Transferability. (arXiv:2308.07625v1 [cs.CV])\nAbstract: Deep neural networks are vulnerable to adversarial examples, dictating the imperativeness to test the model's robustness before deployment. Transfer-based attackers craft adversarial examples against surrogate models and transfer them to victim models deployed in the black-box situation. To enhance the adversarial transferability, structure-based attackers adjust the backpropagation path to avoid the attack from overfitting the surrogate model. However, existing structure-based attackers fail to explore the convolution module in CNNs and modify the backpropagation graph heuristically, leading to limited effectiveness. In this paper, we propose backPropagation pAth Search (PAS), solving the aforementioned two problems. We first propose SkipConv to adjust the backpropagation path of convolution by structural reparameterization. To overcome the drawback of heuristically designed backpropagation paths, we further construct a DAG-based search space, utilize one-step approximation for path e",
    "path": "papers/23/08/2308.07625.json",
    "total_tokens": 894,
    "translated_title": "运用反向传播路径搜索增强对抗迁移性",
    "translated_abstract": "深度神经网络容易受到对抗性样本的攻击，因此在部署之前测试模型的鲁棒性变得至关重要。基于迁移的攻击者会针对替代模型制作对抗样本，并将其转移到黑盒情况下部署的受害者模型上。为了增强对抗迁移性，基于结构的攻击者调整反向传播路径以避免攻击过度拟合替代模型。然而，现有的基于结构的攻击者未能探索卷积模块，并且启发式地修改反向传播图，导致效果有限。在本文中，我们提出了backPropagation pAth Search (PAS)，解决了上述两个问题。我们首先通过结构重参数化提出了SkipConv来调整卷积的反向传播路径。为了克服启发式设计的反向传播路径的缺点，我们进一步构建了基于有向无环图的搜索空间，并利用一步近似来实现路径的搜索。",
    "tldr": "本研究提出了一种backPropagation pAth Search (PAS)方法来增强对抗迁移性，通过调整卷积模块的反向传播路径和构建基于有向无环图的搜索空间来解决了现有基于结构攻击者的局限性。"
}