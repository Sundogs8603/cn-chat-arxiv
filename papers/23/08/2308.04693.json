{
    "title": "Evaluating and Optimizing the Effectiveness of Neural Machine Translation in Supporting Code Retrieval Models: A Study on the CAT Benchmark. (arXiv:2308.04693v1 [cs.SE])",
    "abstract": "Neural Machine Translation (NMT) is widely applied in software engineering tasks. The effectiveness of NMT for code retrieval relies on the ability to learn from the sequence of tokens in the source language to the sequence of tokens in the target language. While NMT performs well in pseudocode-to-code translation, it might have challenges in learning to translate from natural language query to source code in newly curated real-world code documentation/ implementation datasets. In this work, we analyze the performance of NMT in natural language-to-code translation in the newly curated CAT benchmark that includes the optimized versions of three Java datasets TLCodeSum, CodeSearchNet, Funcom, and a Python dataset PCSD. Our evaluation shows that NMT has low accuracy, measured by CrystalBLEU and Meteor metrics in this task. To alleviate the duty of NMT in learning complex representation of source code, we propose ASTTrans Representation, a tailored representation of an Abstract Syntax Tree",
    "link": "http://arxiv.org/abs/2308.04693",
    "context": "Title: Evaluating and Optimizing the Effectiveness of Neural Machine Translation in Supporting Code Retrieval Models: A Study on the CAT Benchmark. (arXiv:2308.04693v1 [cs.SE])\nAbstract: Neural Machine Translation (NMT) is widely applied in software engineering tasks. The effectiveness of NMT for code retrieval relies on the ability to learn from the sequence of tokens in the source language to the sequence of tokens in the target language. While NMT performs well in pseudocode-to-code translation, it might have challenges in learning to translate from natural language query to source code in newly curated real-world code documentation/ implementation datasets. In this work, we analyze the performance of NMT in natural language-to-code translation in the newly curated CAT benchmark that includes the optimized versions of three Java datasets TLCodeSum, CodeSearchNet, Funcom, and a Python dataset PCSD. Our evaluation shows that NMT has low accuracy, measured by CrystalBLEU and Meteor metrics in this task. To alleviate the duty of NMT in learning complex representation of source code, we propose ASTTrans Representation, a tailored representation of an Abstract Syntax Tree",
    "path": "papers/23/08/2308.04693.json",
    "total_tokens": 963,
    "translated_title": "评估和优化神经机器翻译在支持代码检索模型中的效果：基于CAT基准的研究",
    "translated_abstract": "神经机器翻译（NMT）在软件工程任务中得到广泛应用。NMT在代码检索中的有效性取决于从源语言的令牌序列到目标语言的令牌序列之间的学习能力。虽然NMT在伪代码到代码的翻译中表现良好，但在学习将自然语言查询翻译成新的实际代码文档/实现数据集中的源代码时可能面临挑战。在这项工作中，我们分析了NMT在新的CAT基准中进行自然语言到代码翻译的性能，该基准包括三个经过优化的Java数据集TLCodeSum、CodeSearchNet、Funcom和一个Python数据集PCSD的版本。我们的评估结果显示，NMT在这个任务中的准确性较低，通过CrystalBLEU和Meteor度量所得。为了减轻NMT在学习源代码的复杂表示方面的任务，我们提出了ASTTrans Representation，这是一种针对抽象语法树的定制表示方法。",
    "tldr": "本研究评估了神经机器翻译在支持代码检索模型中的效果，并发现NMT在自然语言到代码翻译任务中准确性较低。为了解决这个问题，我们提出了一种针对抽象语法树的定制表示方法ASTTrans Representation。",
    "en_tdlr": "This study evaluates and optimizes the effectiveness of Neural Machine Translation (NMT) in supporting code retrieval models, finding that NMT has low accuracy in translating from natural language to code. To address this, the authors propose a tailored representation called ASTTrans Representation that focuses on abstract syntax trees."
}