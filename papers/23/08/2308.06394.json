{
    "title": "Detecting and Preventing Hallucinations in Large Vision Language Models. (arXiv:2308.06394v1 [cs.CV])",
    "abstract": "Instruction tuned Large Vision Language Models (LVLMs) have made significant advancements in generalizing across a diverse set of multimodal tasks, especially for Visual Question Answering (VQA). However, generating detailed responses that are visually grounded is still a challenging task for these models. We find that even the current state-of-the-art LVLMs (InstructBLIP) still contain a staggering 30 percent of hallucinatory text in the form of non-existent objects, unfaithful descriptions, and inaccurate relationships. To address this, we introduce M-HalDetect, a {M}ultimodal {Hal}lucination {Detect}ion Dataset that can be used to train and benchmark models for hallucination detection and prevention. M-HalDetect consists of 16k fine-grained labels on VQA examples, making it the first comprehensive multi-modal hallucination detection dataset for detailed image descriptions. Unlike previous work that only consider object hallucination, we additionally annotate both entity descriptions",
    "link": "http://arxiv.org/abs/2308.06394",
    "context": "Title: Detecting and Preventing Hallucinations in Large Vision Language Models. (arXiv:2308.06394v1 [cs.CV])\nAbstract: Instruction tuned Large Vision Language Models (LVLMs) have made significant advancements in generalizing across a diverse set of multimodal tasks, especially for Visual Question Answering (VQA). However, generating detailed responses that are visually grounded is still a challenging task for these models. We find that even the current state-of-the-art LVLMs (InstructBLIP) still contain a staggering 30 percent of hallucinatory text in the form of non-existent objects, unfaithful descriptions, and inaccurate relationships. To address this, we introduce M-HalDetect, a {M}ultimodal {Hal}lucination {Detect}ion Dataset that can be used to train and benchmark models for hallucination detection and prevention. M-HalDetect consists of 16k fine-grained labels on VQA examples, making it the first comprehensive multi-modal hallucination detection dataset for detailed image descriptions. Unlike previous work that only consider object hallucination, we additionally annotate both entity descriptions",
    "path": "papers/23/08/2308.06394.json",
    "total_tokens": 858,
    "translated_title": "在大型视觉语言模型中检测和预防幻觉",
    "translated_abstract": "经过调整的大型视觉语言模型（LVLMs）在泛化跨多种多模态任务方面取得了显著进展，特别是在视觉问答（VQA）方面。然而，为这些模型生成与视觉相关的详细回答仍然是一个具有挑战性的任务。我们发现，即使是当前最先进的LVLM（InstructBLIP）仍然存在着惊人的30%的幻觉文本，包括不存在的对象、不忠实的描述和不准确的关系。为了解决这个问题，我们引入了M-HalDetect，这是一个用于训练和评估幻觉检测和预防模型的多模态幻觉检测数据集。M-HalDetect包含了16k个细粒度的VQA示例标签，是第一个用于详细图像描述的全面多模态幻觉检测数据集。与之前只考虑对象幻觉的工作不同，我们还注释了实体描述。",
    "tldr": "本论文提出了一个用于训练和评估模型的多模态幻觉检测数据集，以解决大型视觉语言模型中存在的幻觉文本问题。这是第一个用于详细图像描述的全面多模态幻觉检测数据集。"
}