{
    "title": "Exploring how a Generative AI interprets music. (arXiv:2308.00015v1 [cs.SD])",
    "abstract": "We use Google's MusicVAE, a Variational Auto-Encoder with a 512-dimensional latent space to represent a few bars of music, and organize the latent dimensions according to their relevance in describing music. We find that, on average, most latent neurons remain silent when fed real music tracks: we call these \"noise\" neurons. The remaining few dozens of latent neurons that do fire are called \"music neurons\". We ask which neurons carry the musical information and what kind of musical information they encode, namely something that can be identified as pitch, rhythm or melody. We find that most of the information about pitch and rhythm is encoded in the first few music neurons: the neural network has thus constructed a couple of variables that non-linearly encode many human-defined variables used to describe pitch and rhythm. The concept of melody only seems to show up in independent neurons for longer sequences of music.",
    "link": "http://arxiv.org/abs/2308.00015",
    "context": "Title: Exploring how a Generative AI interprets music. (arXiv:2308.00015v1 [cs.SD])\nAbstract: We use Google's MusicVAE, a Variational Auto-Encoder with a 512-dimensional latent space to represent a few bars of music, and organize the latent dimensions according to their relevance in describing music. We find that, on average, most latent neurons remain silent when fed real music tracks: we call these \"noise\" neurons. The remaining few dozens of latent neurons that do fire are called \"music neurons\". We ask which neurons carry the musical information and what kind of musical information they encode, namely something that can be identified as pitch, rhythm or melody. We find that most of the information about pitch and rhythm is encoded in the first few music neurons: the neural network has thus constructed a couple of variables that non-linearly encode many human-defined variables used to describe pitch and rhythm. The concept of melody only seems to show up in independent neurons for longer sequences of music.",
    "path": "papers/23/08/2308.00015.json",
    "total_tokens": 905,
    "translated_title": "探索生成式人工智能如何解释音乐",
    "translated_abstract": "我们使用Google的MusicVAE，一个具有512维潜在空间的变分自动编码器来表示几小节的音乐，并根据它们在描述音乐方面的相关性来组织潜在维度。我们发现，平均而言，大多数潜在神经元在输入真实音乐轨道时保持沉默：我们称之为“噪声”神经元。其余少数被激活的潜在神经元被称为“音乐”神经元。我们想知道哪些神经元携带着音乐信息以及它们编码的是哪种类型的音乐信息，即可以识别为音高、节奏或旋律的信息。我们发现，大部分关于音高和节奏的信息都被编码在前几个音乐神经元中：因此，神经网络构建了一些非线性编码许多用于描述音高和节奏的人为定义变量的变量。旋律的概念似乎只会在较长的音乐序列中出现在独立的神经元中。",
    "tldr": "使用MusicVAE解释音乐时，大部分关于音高和节奏的信息被编码在前几个音乐神经元中，而旋律的概念则表现为较长的音乐序列中的独立神经元。",
    "en_tdlr": "When using MusicVAE to interpret music, most of the information about pitch and rhythm is encoded in the first few music neurons, while the concept of melody is represented by independent neurons in longer music sequences."
}