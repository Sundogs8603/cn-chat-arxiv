{
    "title": "SODFormer: Streaming Object Detection with Transformer Using Events and Frames. (arXiv:2308.04047v1 [cs.CV])",
    "abstract": "DAVIS camera, streaming two complementary sensing modalities of asynchronous events and frames, has gradually been used to address major object detection challenges (e.g., fast motion blur and low-light). However, how to effectively leverage rich temporal cues and fuse two heterogeneous visual streams remains a challenging endeavor. To address this challenge, we propose a novel streaming object detector with Transformer, namely SODFormer, which first integrates events and frames to continuously detect objects in an asynchronous manner. Technically, we first build a large-scale multimodal neuromorphic object detection dataset (i.e., PKU-DAVIS-SOD) over 1080.1k manual labels. Then, we design a spatiotemporal Transformer architecture to detect objects via an end-to-end sequence prediction problem, where the novel temporal Transformer module leverages rich temporal cues from two visual streams to improve the detection performance. Finally, an asynchronous attention-based fusion module is p",
    "link": "http://arxiv.org/abs/2308.04047",
    "context": "Title: SODFormer: Streaming Object Detection with Transformer Using Events and Frames. (arXiv:2308.04047v1 [cs.CV])\nAbstract: DAVIS camera, streaming two complementary sensing modalities of asynchronous events and frames, has gradually been used to address major object detection challenges (e.g., fast motion blur and low-light). However, how to effectively leverage rich temporal cues and fuse two heterogeneous visual streams remains a challenging endeavor. To address this challenge, we propose a novel streaming object detector with Transformer, namely SODFormer, which first integrates events and frames to continuously detect objects in an asynchronous manner. Technically, we first build a large-scale multimodal neuromorphic object detection dataset (i.e., PKU-DAVIS-SOD) over 1080.1k manual labels. Then, we design a spatiotemporal Transformer architecture to detect objects via an end-to-end sequence prediction problem, where the novel temporal Transformer module leverages rich temporal cues from two visual streams to improve the detection performance. Finally, an asynchronous attention-based fusion module is p",
    "path": "papers/23/08/2308.04047.json",
    "total_tokens": 894,
    "translated_title": "SODFormer：使用事件和帧的Transformer进行流式目标检测",
    "translated_abstract": "DAVIS相机通过异步事件和帧的两种互补感知模态逐渐被用于解决主要的目标检测挑战（例如，快速运动模糊和低光）。然而，如何有效地利用丰富的时间线索和融合两个异构的视觉流仍然是一项具有挑战性的工作。为了解决这个问题，我们提出了一种新颖的基于Transformer的流式目标检测器，即SODFormer，它首先整合事件和帧以异步的方式连续地检测目标。我们首先构建了一个大规模的多模态神经形态目标检测数据集（即PKU-DAVIS-SOD），拥有1080.1k个手动标注。然后，我们设计了一个时空Transformer架构，通过端到端的序列预测问题来检测目标，其中新颖的时序Transformer模块利用两个视觉流的丰富时间线索来提高检测性能。最后，引入了一个异步的基于注意力的融合模块。",
    "tldr": "SODFormer是一个使用事件和帧进行流式目标检测的Transformer模型，通过设计时空Transformer架构和引入基于注意力的融合模块，实现了对目标的连续检测，提高了检测性能。"
}