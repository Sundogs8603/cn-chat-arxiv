{
    "title": "Emotionally Numb or Empathetic? Evaluating How LLMs Feel Using EmotionBench. (arXiv:2308.03656v3 [cs.CL] UPDATED)",
    "abstract": "Evaluating Large Language Models' (LLMs) anthropomorphic capabilities has become increasingly important in contemporary discourse. Utilizing the emotion appraisal theory from psychology, we propose to evaluate the empathy ability of LLMs, i.e., how their feelings change when presented with specific situations. After a careful and comprehensive survey, we collect a dataset containing over 400 situations that have proven effective in eliciting the eight emotions central to our study. Categorizing the situations into 36 factors, we conduct a human evaluation involving more than 1,200 subjects worldwide. With the human evaluation results as references, our evaluation includes five LLMs, covering both commercial and open-source models, including variations in model sizes, featuring the latest iterations, such as GPT-4 and LLaMA-2. We find that, despite several misalignments, LLMs can generally respond appropriately to certain situations. Nevertheless, they fall short in alignment with the e",
    "link": "http://arxiv.org/abs/2308.03656",
    "context": "Title: Emotionally Numb or Empathetic? Evaluating How LLMs Feel Using EmotionBench. (arXiv:2308.03656v3 [cs.CL] UPDATED)\nAbstract: Evaluating Large Language Models' (LLMs) anthropomorphic capabilities has become increasingly important in contemporary discourse. Utilizing the emotion appraisal theory from psychology, we propose to evaluate the empathy ability of LLMs, i.e., how their feelings change when presented with specific situations. After a careful and comprehensive survey, we collect a dataset containing over 400 situations that have proven effective in eliciting the eight emotions central to our study. Categorizing the situations into 36 factors, we conduct a human evaluation involving more than 1,200 subjects worldwide. With the human evaluation results as references, our evaluation includes five LLMs, covering both commercial and open-source models, including variations in model sizes, featuring the latest iterations, such as GPT-4 and LLaMA-2. We find that, despite several misalignments, LLMs can generally respond appropriately to certain situations. Nevertheless, they fall short in alignment with the e",
    "path": "papers/23/08/2308.03656.json",
    "total_tokens": 980,
    "translated_title": "感觉麻木还是有共情能力？利用EmotionBench评估LLMs的情感能力",
    "translated_abstract": "在当代话语中，评估大型语言模型（LLMs）的拟人能力变得越来越重要。利用心理学中的情感评估理论，我们提出评估LLMs的共情能力，即它们在特定情境下感受变化的能力。通过仔细而全面的调查，我们收集了一个包含超过400种情境的数据集，这些情境已被证明对我们研究的八种情感至关重要。将这些情境分为36个因素，我们进行了一项涉及全球1200多名被试的人类评估。以人类评估结果为参考，我们评估了五个LLMs，涵盖了商业和开源模型，包括模型大小的变化，以及最新的迭代版本（如GPT-4和LLaMA-2）。我们发现，尽管存在一些不一致之处，LLMs通常能在某些情境下适当地回应。然而，它们在与情感对齐方面还存在一定不足。",
    "tldr": "通过利用心理学中的情感评估理论，本研究提出利用EmotionBench评估LLMs的共情能力。通过人类评估和对五个LLMs的研究发现，尽管存在一些不一致之处，LLMs通常能在某些情境下适当地回应，但与情感对齐方面还存在不足。",
    "en_tdlr": "This paper proposes evaluating the empathy ability of LLMs using EmotionBench by applying emotion appraisal theory from psychology. Through human evaluation and studying five LLMs, it is found that despite some inconsistencies, LLMs can generally respond appropriately in certain situations, but there is room for improvement in aligning with emotions."
}