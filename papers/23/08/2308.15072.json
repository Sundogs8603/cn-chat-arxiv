{
    "title": "Advancing Adversarial Robustness Through Adversarial Logit Update. (arXiv:2308.15072v1 [cs.LG])",
    "abstract": "Deep Neural Networks are susceptible to adversarial perturbations. Adversarial training and adversarial purification are among the most widely recognized defense strategies. Although these methods have different underlying logic, both rely on absolute logit values to generate label predictions. In this study, we theoretically analyze the logit difference around successful adversarial attacks from a theoretical point of view and propose a new principle, namely Adversarial Logit Update (ALU), to infer adversarial sample's labels. Based on ALU, we introduce a new classification paradigm that utilizes pre- and post-purification logit differences for model's adversarial robustness boost. Without requiring adversarial or additional data for model training, our clean data synthesis model can be easily applied to various pre-trained models for both adversarial sample detection and ALU-based data classification. Extensive experiments on both CIFAR-10, CIFAR-100, and tiny-ImageNet datasets show ",
    "link": "http://arxiv.org/abs/2308.15072",
    "context": "Title: Advancing Adversarial Robustness Through Adversarial Logit Update. (arXiv:2308.15072v1 [cs.LG])\nAbstract: Deep Neural Networks are susceptible to adversarial perturbations. Adversarial training and adversarial purification are among the most widely recognized defense strategies. Although these methods have different underlying logic, both rely on absolute logit values to generate label predictions. In this study, we theoretically analyze the logit difference around successful adversarial attacks from a theoretical point of view and propose a new principle, namely Adversarial Logit Update (ALU), to infer adversarial sample's labels. Based on ALU, we introduce a new classification paradigm that utilizes pre- and post-purification logit differences for model's adversarial robustness boost. Without requiring adversarial or additional data for model training, our clean data synthesis model can be easily applied to various pre-trained models for both adversarial sample detection and ALU-based data classification. Extensive experiments on both CIFAR-10, CIFAR-100, and tiny-ImageNet datasets show ",
    "path": "papers/23/08/2308.15072.json",
    "total_tokens": 866,
    "translated_title": "通过对抗logit更新推进对抗鲁棒性",
    "translated_abstract": "深度神经网络容易受到对抗性扰动的影响。对抗训练和对抗净化是广泛认可的防御策略之一。尽管这些方法有不同的基本逻辑，但都依赖于绝对logit值生成标签预测。在本研究中，从理论角度对成功的对抗攻击周围的logit差异进行了理论分析，并提出了一种新的原则，即对抗logit更新(ALU)，用于推断对抗样本的标签。基于ALU，我们引入了一种新的分类范式，利用预处理和后处理的logit差异来提高模型的对抗鲁棒性。我们的清洁数据合成模型不需要对抗或额外的数据用于模型训练，可以轻松应用于各种预训练模型，用于对抗样本检测和基于ALU的数据分类。",
    "tldr": "本研究提出了一种基于对抗logit更新的新原则(ALU)，用于推断对抗样本的标签，并通过使用预处理和后处理的logit差异提高了模型的对抗鲁棒性。"
}