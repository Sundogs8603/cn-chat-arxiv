{
    "title": "Clustered Linear Contextual Bandits with Knapsacks. (arXiv:2308.10722v1 [cs.LG])",
    "abstract": "In this work, we study clustered contextual bandits where rewards and resource consumption are the outcomes of cluster-specific linear models. The arms are divided in clusters, with the cluster memberships being unknown to an algorithm. Pulling an arm in a time period results in a reward and in consumption for each one of multiple resources, and with the total consumption of any resource exceeding a constraint implying the termination of the algorithm. Thus, maximizing the total reward requires learning not only models about the reward and the resource consumption, but also cluster memberships. We provide an algorithm that achieves regret sublinear in the number of time periods, without requiring access to all of the arms. In particular, we show that it suffices to perform clustering only once to a randomly selected subset of the arms. To achieve this result, we provide a sophisticated combination of techniques from the literature of econometrics and of bandits with constraints.",
    "link": "http://arxiv.org/abs/2308.10722",
    "context": "Title: Clustered Linear Contextual Bandits with Knapsacks. (arXiv:2308.10722v1 [cs.LG])\nAbstract: In this work, we study clustered contextual bandits where rewards and resource consumption are the outcomes of cluster-specific linear models. The arms are divided in clusters, with the cluster memberships being unknown to an algorithm. Pulling an arm in a time period results in a reward and in consumption for each one of multiple resources, and with the total consumption of any resource exceeding a constraint implying the termination of the algorithm. Thus, maximizing the total reward requires learning not only models about the reward and the resource consumption, but also cluster memberships. We provide an algorithm that achieves regret sublinear in the number of time periods, without requiring access to all of the arms. In particular, we show that it suffices to perform clustering only once to a randomly selected subset of the arms. To achieve this result, we provide a sophisticated combination of techniques from the literature of econometrics and of bandits with constraints.",
    "path": "papers/23/08/2308.10722.json",
    "total_tokens": 879,
    "translated_title": "带背包的聚类线性上下文赌博机问题",
    "translated_abstract": "在这项工作中，我们研究了聚类上下文赌博机问题，其中奖励和资源消耗是聚类特定线性模型的结果。臂被分成聚类，而聚类成员对算法是未知的。在一个时间段内拉动一个臂导致奖励和对多种资源的消耗，并且任何资源的总消耗超过约束意味着算法的终止。因此，最大化总奖励需要学习关于奖励和资源消耗的模型，还有聚类成员。我们提供了一个算法，在时间段数量的子线性遗憾下实现，而不需要访问所有臂。特别是，我们表明只需要对一个随机选择的臂子集进行一次聚类就足够了。为了实现这个结果，我们提供了一种复杂的组合技术，结合了计量经济学和带约束的赌博机领域的技术。",
    "tldr": "本论文研究了带背包的聚类线性上下文赌博机问题，在不知道聚类成员的情况下，提供了一种实现子线性遗憾的算法，该算法只需对一个随机选择的臂子集进行一次聚类。"
}