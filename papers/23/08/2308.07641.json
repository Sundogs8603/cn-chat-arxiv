{
    "title": "Ternary Singular Value Decomposition as a Better Parameterized Form in Linear Mapping. (arXiv:2308.07641v1 [cs.LG])",
    "abstract": "We present a simple yet novel parameterized form of linear mapping to achieves remarkable network compression performance: a pseudo SVD called Ternary SVD (TSVD).  Unlike vanilla SVD, TSVD limits the $U$ and $V$ matrices in SVD to ternary matrices form in $\\{\\pm 1, 0\\}$. This means that instead of using the expensive multiplication instructions, TSVD only requires addition instructions when computing $U(\\cdot)$ and $V(\\cdot)$.  We provide direct and training transition algorithms for TSVD like Post Training Quantization and Quantization Aware Training respectively. Additionally, we analyze the convergence of the direct transition algorithms in theory.  In experiments, we demonstrate that TSVD can achieve state-of-the-art network compression performance in various types of networks and tasks, including current baseline models such as ConvNext, Swim, BERT, and large language model like OPT.",
    "link": "http://arxiv.org/abs/2308.07641",
    "context": "Title: Ternary Singular Value Decomposition as a Better Parameterized Form in Linear Mapping. (arXiv:2308.07641v1 [cs.LG])\nAbstract: We present a simple yet novel parameterized form of linear mapping to achieves remarkable network compression performance: a pseudo SVD called Ternary SVD (TSVD).  Unlike vanilla SVD, TSVD limits the $U$ and $V$ matrices in SVD to ternary matrices form in $\\{\\pm 1, 0\\}$. This means that instead of using the expensive multiplication instructions, TSVD only requires addition instructions when computing $U(\\cdot)$ and $V(\\cdot)$.  We provide direct and training transition algorithms for TSVD like Post Training Quantization and Quantization Aware Training respectively. Additionally, we analyze the convergence of the direct transition algorithms in theory.  In experiments, we demonstrate that TSVD can achieve state-of-the-art network compression performance in various types of networks and tasks, including current baseline models such as ConvNext, Swim, BERT, and large language model like OPT.",
    "path": "papers/23/08/2308.07641.json",
    "total_tokens": 950,
    "translated_title": "三元奇异值分解作为线性映射中更好的参数化形式",
    "translated_abstract": "我们提出了一种简单但新颖的线性映射参数化形式，称为三元奇异值分解 (TSVD)，以实现卓越的网络压缩性能。与传统的奇异值分解不同，TSVD将奇异值分解中的$U$和$V$矩阵限制为三元矩阵形式，即$\\{ \\pm 1, 0 \\}$。这意味着在计算$U(\\cdot)$和$V(\\cdot)$时，TSVD只需要加法指令，而不需要昂贵的乘法指令。我们提供了直接转换算法和训练过渡算法，如后训练量化和量化感知训练。此外，我们在理论上分析了直接转换算法的收敛性。在实验中，我们证明了TSVD在各种类型的网络和任务中都能实现最先进的网络压缩性能，包括当前的基准模型，如ConvNext、Swim、BERT以及类似OPT的大型语言模型。",
    "tldr": "本文提出了一种名为三元奇异值分解 (TSVD) 的新颖线性映射参数化形式，通过限制奇异值分解中的矩阵为三元矩阵形式，它在网络压缩性能方面表现出色。实验证明，TSVD在各种类型的网络和任务中都能实现最先进的网络压缩性能。",
    "en_tdlr": "This paper presents a novel parameterized form for linear mapping called Ternary Singular Value Decomposition (TSVD), which achieves remarkable network compression performance by limiting the matrices in SVD to ternary form. Experimental results show that TSVD outperforms other methods in network compression performance across various network types and tasks."
}