{
    "title": "Backdoor Federated Learning by Poisoning Backdoor-Critical Layers. (arXiv:2308.04466v1 [cs.CR])",
    "abstract": "Federated learning (FL) has been widely deployed to enable machine learning training on sensitive data across distributed devices. However, the decentralized learning paradigm and heterogeneity of FL further extend the attack surface for backdoor attacks. Existing FL attack and defense methodologies typically focus on the whole model. None of them recognizes the existence of backdoor-critical (BC) layers-a small subset of layers that dominate the model vulnerabilities. Attacking the BC layers achieves equivalent effects as attacking the whole model but at a far smaller chance of being detected by state-of-the-art (SOTA) defenses. This paper proposes a general in-situ approach that identifies and verifies BC layers from the perspective of attackers. Based on the identified BC layers, we carefully craft a new backdoor attack methodology that adaptively seeks a fundamental balance between attacking effects and stealthiness under various defense strategies. Extensive experiments show that ",
    "link": "http://arxiv.org/abs/2308.04466",
    "context": "Title: Backdoor Federated Learning by Poisoning Backdoor-Critical Layers. (arXiv:2308.04466v1 [cs.CR])\nAbstract: Federated learning (FL) has been widely deployed to enable machine learning training on sensitive data across distributed devices. However, the decentralized learning paradigm and heterogeneity of FL further extend the attack surface for backdoor attacks. Existing FL attack and defense methodologies typically focus on the whole model. None of them recognizes the existence of backdoor-critical (BC) layers-a small subset of layers that dominate the model vulnerabilities. Attacking the BC layers achieves equivalent effects as attacking the whole model but at a far smaller chance of being detected by state-of-the-art (SOTA) defenses. This paper proposes a general in-situ approach that identifies and verifies BC layers from the perspective of attackers. Based on the identified BC layers, we carefully craft a new backdoor attack methodology that adaptively seeks a fundamental balance between attacking effects and stealthiness under various defense strategies. Extensive experiments show that ",
    "path": "papers/23/08/2308.04466.json",
    "total_tokens": 889,
    "translated_title": "后门联邦学习：通过污染后门关键层",
    "translated_abstract": "联邦学习（FL）已被广泛应用于在分布式设备上进行敏感数据的机器学习训练。然而，分散式学习范式和FL的异质性进一步扩展了后门攻击的攻击面。现有的FL攻击和防御方法通常会关注整个模型，但没有一个方法意识到后门关键（BC）层的存在，后门关键层是指控制模型漏洞的一小部分层。攻击BC层可以达到攻击整个模型的效果，但被最先进的防御手段发现的机会要小得多。本文提出了一个从攻击者的角度识别和验证BC层的普适性方法。基于识别出的BC层，我们精心设计了一种新的后门攻击方法，根据不同的防御策略自适应地寻求攻击效果和隐蔽性之间的平衡。大量实验表明，",
    "tldr": "该论文研究了后门联邦学习中后门关键层的存在，并提出了一种针对这些层的新型后门攻击方法，旨在在各种防御策略下实现攻击效果和隐蔽性之间的平衡。",
    "en_tdlr": "This paper investigates the existence of backdoor-critical layers in backdoor federated learning and proposes a novel backdoor attack methodology targeting these layers, aiming to achieve a balance between attack effectiveness and stealthiness under various defense strategies."
}