{
    "title": "Bird's-Eye-View Scene Graph for Vision-Language Navigation. (arXiv:2308.04758v1 [cs.CV])",
    "abstract": "Vision-language navigation (VLN), which entails an agent to navigate 3D environments following human instructions, has shown great advances. However, current agents are built upon panoramic observations, which hinders their ability to perceive 3D scene geometry and easily leads to ambiguous selection of panoramic view. To address these limitations, we present a BEV Scene Graph (BSG), which leverages multi-step BEV representations to encode scene layouts and geometric cues of indoor environment under the supervision of 3D detection. During navigation, BSG builds a local BEV representation at each step and maintains a BEV-based global scene map, which stores and organizes all the online collected local BEV representations according to their topological relations. Based on BSG, the agent predicts a local BEV grid-level decision score and a global graph-level decision score, combined with a sub-view selection score on panoramic views, for more accurate action prediction. Our approach signi",
    "link": "http://arxiv.org/abs/2308.04758",
    "context": "Title: Bird's-Eye-View Scene Graph for Vision-Language Navigation. (arXiv:2308.04758v1 [cs.CV])\nAbstract: Vision-language navigation (VLN), which entails an agent to navigate 3D environments following human instructions, has shown great advances. However, current agents are built upon panoramic observations, which hinders their ability to perceive 3D scene geometry and easily leads to ambiguous selection of panoramic view. To address these limitations, we present a BEV Scene Graph (BSG), which leverages multi-step BEV representations to encode scene layouts and geometric cues of indoor environment under the supervision of 3D detection. During navigation, BSG builds a local BEV representation at each step and maintains a BEV-based global scene map, which stores and organizes all the online collected local BEV representations according to their topological relations. Based on BSG, the agent predicts a local BEV grid-level decision score and a global graph-level decision score, combined with a sub-view selection score on panoramic views, for more accurate action prediction. Our approach signi",
    "path": "papers/23/08/2308.04758.json",
    "total_tokens": 957,
    "translated_title": "鸟瞰场景图用于视觉语言导航",
    "translated_abstract": "视觉语言导航（VLN）需要一个代理根据人类指示在3D环境中导航，已经取得了显著的进展。然而，当前的代理基于全景观察构建，这限制了它们感知3D场景几何和容易导致全景视图的模糊选择能力。为了解决这些限制，我们提出了一种鸟瞰场景图（BSG），它利用多步鸟瞰表示来编码室内环境的场景布局和几何线索，在3D检测的监督下。在导航过程中，BSG在每个步骤构建一个本地鸟瞰表示，并维护一个基于鸟瞰的全局场景地图，根据它们的拓扑关系存储和组织所有在线收集的本地鸟瞰表示。基于BSG，代理预测本地鸟瞰网格级决策得分和全局图形级决策得分，结合全景视图的子视图选择得分，以实现更准确的动作预测。我们的方法",
    "tldr": "这项研究提出了一种鸟瞰场景图（BSG）用于视觉语言导航，通过使用多步鸟瞰表示来编码场景布局和几何线索，从而改进了当前全景观察的导航代理的能力，并提供了更准确的动作预测。",
    "en_tdlr": "This paper proposes a Bird's-Eye-View Scene Graph (BSG) for vision-language navigation, which improves the capability of current panoramic observation-based navigation agents by encoding scene layouts and geometric cues using multi-step bird's-eye-view representations, and provides more accurate action prediction."
}