{
    "title": "Video and Audio are Images: A Cross-Modal Mixer for Original Data on Video-Audio Retrieval. (arXiv:2308.13820v1 [cs.IR])",
    "abstract": "Cross-modal retrieval has become popular in recent years, particularly with the rise of multimedia. Generally, the information from each modality exhibits distinct representations and semantic information, which makes feature tends to be in separate latent spaces encoded with dual-tower architecture and makes it difficult to establish semantic relationships between modalities, resulting in poor retrieval performance. To address this issue, we propose a novel framework for cross-modal retrieval which consists of a cross-modal mixer, a masked autoencoder for pre-training, and a cross-modal retriever for downstream tasks.In specific, we first adopt cross-modal mixer and mask modeling to fuse the original modality and eliminate redundancy. Then, an encoder-decoder architecture is applied to achieve a fuse-then-separate task in the pre-training phase.We feed masked fused representations into the encoder and reconstruct them with the decoder, ultimately separating the original data of two mo",
    "link": "http://arxiv.org/abs/2308.13820",
    "context": "Title: Video and Audio are Images: A Cross-Modal Mixer for Original Data on Video-Audio Retrieval. (arXiv:2308.13820v1 [cs.IR])\nAbstract: Cross-modal retrieval has become popular in recent years, particularly with the rise of multimedia. Generally, the information from each modality exhibits distinct representations and semantic information, which makes feature tends to be in separate latent spaces encoded with dual-tower architecture and makes it difficult to establish semantic relationships between modalities, resulting in poor retrieval performance. To address this issue, we propose a novel framework for cross-modal retrieval which consists of a cross-modal mixer, a masked autoencoder for pre-training, and a cross-modal retriever for downstream tasks.In specific, we first adopt cross-modal mixer and mask modeling to fuse the original modality and eliminate redundancy. Then, an encoder-decoder architecture is applied to achieve a fuse-then-separate task in the pre-training phase.We feed masked fused representations into the encoder and reconstruct them with the decoder, ultimately separating the original data of two mo",
    "path": "papers/23/08/2308.13820.json",
    "total_tokens": 902,
    "translated_title": "视频和音频是图像：用于视频音频检索原始数据的跨模态混合器",
    "translated_abstract": "跨模态检索在近年来变得流行，尤其是随着多媒体的兴起。通常，每个模态的信息展现出不同的表示和语义信息，这使得特征往往处于编码为双塔结构的分离潜空间中，并且难以建立模态之间的语义关系，导致检索性能差。为了解决这个问题，我们提出了一个新的跨模态检索框架，包括一个跨模态混合器、一个用于预训练的掩模自编码器和一个用于下游任务的跨模态检索器。具体来说，我们首先采用跨模态混合器和掩模建模来融合原始模态并消除冗余。然后，在预训练阶段应用编码器-解码器架构来实现融合后分离的任务。我们将掩模融合表示馈送到编码器中，并用解码器进行重构，最终分离出两个模态的原始数据。",
    "tldr": "本文提出了一个新的跨模态检索框架，通过跨模态混合器和掩模自编码器实现了原始数据的融合和分离，解决了跨模态检索中的语义关系建立和检索性能不佳的问题。",
    "en_tdlr": "This paper proposes a novel framework for cross-modal retrieval, which addresses the issues of establishing semantic relationships and poor retrieval performance by using a cross-modal mixer and a masked autoencoder to fuse and separate the original data."
}