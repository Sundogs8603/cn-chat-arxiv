{
    "title": "3D Adversarial Augmentations for Robust Out-of-Domain Predictions. (arXiv:2308.15479v1 [cs.CV])",
    "abstract": "Since real-world training datasets cannot properly sample the long tail of the underlying data distribution, corner cases and rare out-of-domain samples can severely hinder the performance of state-of-the-art models. This problem becomes even more severe for dense tasks, such as 3D semantic segmentation, where points of non-standard objects can be confidently associated to the wrong class. In this work, we focus on improving the generalization to out-of-domain data. We achieve this by augmenting the training set with adversarial examples. First, we learn a set of vectors that deform the objects in an adversarial fashion. To prevent the adversarial examples from being too far from the existing data distribution, we preserve their plausibility through a series of constraints, ensuring sensor-awareness and shapes smoothness. Then, we perform adversarial augmentation by applying the learned sample-independent vectors to the available objects when training a model. We conduct extensive expe",
    "link": "http://arxiv.org/abs/2308.15479",
    "context": "Title: 3D Adversarial Augmentations for Robust Out-of-Domain Predictions. (arXiv:2308.15479v1 [cs.CV])\nAbstract: Since real-world training datasets cannot properly sample the long tail of the underlying data distribution, corner cases and rare out-of-domain samples can severely hinder the performance of state-of-the-art models. This problem becomes even more severe for dense tasks, such as 3D semantic segmentation, where points of non-standard objects can be confidently associated to the wrong class. In this work, we focus on improving the generalization to out-of-domain data. We achieve this by augmenting the training set with adversarial examples. First, we learn a set of vectors that deform the objects in an adversarial fashion. To prevent the adversarial examples from being too far from the existing data distribution, we preserve their plausibility through a series of constraints, ensuring sensor-awareness and shapes smoothness. Then, we perform adversarial augmentation by applying the learned sample-independent vectors to the available objects when training a model. We conduct extensive expe",
    "path": "papers/23/08/2308.15479.json",
    "total_tokens": 966,
    "translated_title": "用于鲁棒性域外预测的3D对抗增强",
    "translated_abstract": "由于真实世界的训练数据集无法正确采样基础数据分布的长尾部分，角落案例和稀有的域外样本会严重影响最先进模型的性能。对于稠密任务，例如3D语义分割，这个问题变得更加严重，因为非标准对象的点可以被错误地关联到其他类别。在这项工作中，我们着重改善对域外数据的泛化能力。我们通过增加训练集中的对抗样本来实现这一点。首先，我们学习一组向量，以对抗方式改变对象。为了防止对抗样本远离现有数据分布过远，我们通过一系列约束来保持它们的合理性，确保传感器感知和形状平滑性。然后，在训练模型时，我们将学习到的独立于样本的向量应用于可用的对象，进行对抗增强。我们进行了大量实验。",
    "tldr": "本文提出了一种用于改善模型对域外数据的泛化能力的方法，通过增加训练集中的对抗样本来实现。在3D语义分割任务中，该方法有效地防止了对非标准对象点的错误关联。这种方法通过学习一组向量来对对象进行对抗性变形，并通过约束保持它们的合理性和平滑性。",
    "en_tdlr": "This paper proposes a method to improve the generalization of models to out-of-domain data by augmenting the training set with adversarial examples. In the task of 3D semantic segmentation, this method effectively prevents misclassification of points on non-standard objects. It achieves this by learning a set of vectors for adversarial deformations of objects, and preserving their plausibility and smoothness through constraints."
}