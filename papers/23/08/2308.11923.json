{
    "title": "Audio Difference Captioning Utilizing Similarity-Discrepancy Disentanglement. (arXiv:2308.11923v1 [eess.AS])",
    "abstract": "We proposed Audio Difference Captioning (ADC) as a new extension task of audio captioning for describing the semantic differences between input pairs of similar but slightly different audio clips. The ADC solves the problem that conventional audio captioning sometimes generates similar captions for similar audio clips, failing to describe the difference in content. We also propose a cross-attention-concentrated transformer encoder to extract differences by comparing a pair of audio clips and a similarity-discrepancy disentanglement to emphasize the difference in the latent space. To evaluate the proposed methods, we built an AudioDiffCaps dataset consisting of pairs of similar but slightly different audio clips with human-annotated descriptions of their differences. The experiment with the AudioDiffCaps dataset showed that the proposed methods solve the ADC task effectively and improve the attention weights to extract the difference by visualizing them in the transformer encoder.",
    "link": "http://arxiv.org/abs/2308.11923",
    "context": "Title: Audio Difference Captioning Utilizing Similarity-Discrepancy Disentanglement. (arXiv:2308.11923v1 [eess.AS])\nAbstract: We proposed Audio Difference Captioning (ADC) as a new extension task of audio captioning for describing the semantic differences between input pairs of similar but slightly different audio clips. The ADC solves the problem that conventional audio captioning sometimes generates similar captions for similar audio clips, failing to describe the difference in content. We also propose a cross-attention-concentrated transformer encoder to extract differences by comparing a pair of audio clips and a similarity-discrepancy disentanglement to emphasize the difference in the latent space. To evaluate the proposed methods, we built an AudioDiffCaps dataset consisting of pairs of similar but slightly different audio clips with human-annotated descriptions of their differences. The experiment with the AudioDiffCaps dataset showed that the proposed methods solve the ADC task effectively and improve the attention weights to extract the difference by visualizing them in the transformer encoder.",
    "path": "papers/23/08/2308.11923.json",
    "total_tokens": 960,
    "translated_title": "利用相似性-差异解缠来进行音频差异字幕生成",
    "translated_abstract": "我们提出了音频差异字幕生成（ADC）作为音频字幕生成的新扩展任务，用于描述类似但略有差异的音频片段之间的语义差异。ADC解决了传统音频字幕生成中，对于相似音频片段生成类似字幕的问题，无法描述内容差异的情况。我们还提出了一种交叉注意力集中的Transformer编码器，通过比较一对音频片段和一种相似性-差异解缠来强调潜在空间中的差异。为了评估所提出的方法，我们构建了一个AudioDiffCaps数据集，其中包含了类似但略有差异的音频片段对以及人工标注的它们之间差异的描述。使用该数据集进行的实验证明了所提出的方法能够有效解决ADC任务，并通过在Transformer编码器中对其进行可视化来改善注意力权重以提取差异。",
    "tldr": "该论文提出了音频差异字幕生成（ADC）作为一种新的音频字幕生成扩展任务，用于描述类似但略有差异的音频片段之间的语义差异。通过引入交叉注意力集中的Transformer编码器和相似性-差异解缠，该方法有效解决了传统音频字幕生成中的差异描述问题，并利用可视化来改善注意力权重以提取差异。",
    "en_tdlr": "This paper introduces Audio Difference Captioning (ADC) as a new extension task for audio captioning, aiming to describe the semantic differences between similar but slightly different audio clips. By utilizing a cross-attention-concentrated transformer encoder and similarity-discrepancy disentanglement, the proposed method effectively solves the challenge of describing differences in conventional audio captioning, and improves attention weights for difference extraction through visualization."
}