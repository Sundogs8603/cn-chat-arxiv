{
    "title": "Towards Optimal Patch Size in Vision Transformers for Tumor Segmentation. (arXiv:2308.16598v1 [eess.IV])",
    "abstract": "Detection of tumors in metastatic colorectal cancer (mCRC) plays an essential role in the early diagnosis and treatment of liver cancer. Deep learning models backboned by fully convolutional neural networks (FCNNs) have become the dominant model for segmenting 3D computerized tomography (CT) scans. However, since their convolution layers suffer from limited kernel size, they are not able to capture long-range dependencies and global context. To tackle this restriction, vision transformers have been introduced to solve FCNN's locality of receptive fields. Although transformers can capture long-range features, their segmentation performance decreases with various tumor sizes due to the model sensitivity to the input patch size. While finding an optimal patch size improves the performance of vision transformer-based models on segmentation tasks, it is a time-consuming and challenging procedure. This paper proposes a technique to select the vision transformer's optimal input multi-resoluti",
    "link": "http://arxiv.org/abs/2308.16598",
    "context": "Title: Towards Optimal Patch Size in Vision Transformers for Tumor Segmentation. (arXiv:2308.16598v1 [eess.IV])\nAbstract: Detection of tumors in metastatic colorectal cancer (mCRC) plays an essential role in the early diagnosis and treatment of liver cancer. Deep learning models backboned by fully convolutional neural networks (FCNNs) have become the dominant model for segmenting 3D computerized tomography (CT) scans. However, since their convolution layers suffer from limited kernel size, they are not able to capture long-range dependencies and global context. To tackle this restriction, vision transformers have been introduced to solve FCNN's locality of receptive fields. Although transformers can capture long-range features, their segmentation performance decreases with various tumor sizes due to the model sensitivity to the input patch size. While finding an optimal patch size improves the performance of vision transformer-based models on segmentation tasks, it is a time-consuming and challenging procedure. This paper proposes a technique to select the vision transformer's optimal input multi-resoluti",
    "path": "papers/23/08/2308.16598.json",
    "total_tokens": 1005,
    "translated_title": "关于肿瘤分割中视觉变换器中最佳补丁尺寸的研究",
    "translated_abstract": "在肝癌的早期诊断和治疗中，转移性结直肠癌（mCRC）中的肿瘤检测起着重要作用。以完全卷积神经网络（FCNN）为主干的深度学习模型已经成为分割3D计算机断层扫描（CT）的主要模型。然而，由于卷积层的局限性，它们不能捕捉到远距离的依赖和全局语境。为了解决这个限制，引入了视觉变换器来解决FCNN的接受域的局部性。尽管变换器可以捕捉到远距离的特征，但由于对输入补丁大小的敏感性，其分割性能在各种肿瘤大小上都有所下降。虽然找到最佳补丁尺寸可以提高基于视觉变换器的模型在分割任务上的性能，但这是一个耗时且具有挑战性的过程。本文提出了一种选择视觉变换器最佳输入多分辨率的技术",
    "tldr": "本论文研究了在肿瘤分割中，视觉变换器中最佳补丁尺寸的选择。目前基于完全卷积神经网络的深度学习模型已成为主流，但由于卷积层的局限性，它们不能有效捕捉长距离依赖和全局上下文。为解决这个问题，引入了视觉变换器，但由于对输入补丁尺寸敏感，其在不同肿瘤大小上的性能下降。因此，本文提出了一种技术来选择视觉变换器的最佳输入多分辨率。"
}