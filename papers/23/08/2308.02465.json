{
    "title": "BlindSage: Label Inference Attacks against Node-level Vertical Federated Graph Neural Networks. (arXiv:2308.02465v1 [cs.LG])",
    "abstract": "Federated learning enables collaborative training of machine learning models by keeping the raw data of the involved workers private. One of its main objectives is to improve the models' privacy, security, and scalability. Vertical Federated Learning (VFL) offers an efficient cross-silo setting where a few parties collaboratively train a model without sharing the same features. In such a scenario, classification labels are commonly considered sensitive information held exclusively by one (active) party, while other (passive) parties use only their local information. Recent works have uncovered important flaws of VFL, leading to possible label inference attacks under the assumption that the attacker has some, even limited, background knowledge on the relation between labels and data. In this work, we are the first (to the best of our knowledge) to investigate label inference attacks on VFL using a zero-background knowledge strategy. To concretely formulate our proposal, we focus on Grap",
    "link": "http://arxiv.org/abs/2308.02465",
    "context": "Title: BlindSage: Label Inference Attacks against Node-level Vertical Federated Graph Neural Networks. (arXiv:2308.02465v1 [cs.LG])\nAbstract: Federated learning enables collaborative training of machine learning models by keeping the raw data of the involved workers private. One of its main objectives is to improve the models' privacy, security, and scalability. Vertical Federated Learning (VFL) offers an efficient cross-silo setting where a few parties collaboratively train a model without sharing the same features. In such a scenario, classification labels are commonly considered sensitive information held exclusively by one (active) party, while other (passive) parties use only their local information. Recent works have uncovered important flaws of VFL, leading to possible label inference attacks under the assumption that the attacker has some, even limited, background knowledge on the relation between labels and data. In this work, we are the first (to the best of our knowledge) to investigate label inference attacks on VFL using a zero-background knowledge strategy. To concretely formulate our proposal, we focus on Grap",
    "path": "papers/23/08/2308.02465.json",
    "total_tokens": 908,
    "translated_title": "BlindSage：针对节点级垂直联邦图神经网络的标签推断攻击",
    "translated_abstract": "联邦学习通过保持涉及工作方的原始数据私密性，实现机器学习模型的协作训练。其主要目标之一是提高模型的隐私性、安全性和可扩展性。垂直联邦学习（VFL）提供了一种有效的跨域设置，其中少数参与方在不共享相同特征的情况下共同训练模型。在这种情况下，分类标签通常被视为仅由一个（主动）参与方独占持有的敏感信息，而其他（被动）参与方仅使用其本地信息。最近的研究揭示了VFL的重要缺陷，可能导致在攻击者具有某些，甚至有限的标签与数据关系的背景知识的假设下发生标签推断攻击。在本文中，我们是首次（据我们所知）使用零背景知识策略研究VFL上的标签推断攻击。为了具体阐述我们的提案，我们专注于Grap的问题。",
    "tldr": "本论文研究了针对节点级垂直联邦图神经网络的标签推断攻击，利用零背景知识策略来实现攻击，并揭示了该领域内的重要问题。",
    "en_tdlr": "This paper investigates label inference attacks against node-level vertical federated graph neural networks, using a zero-background knowledge strategy, and uncovers important issues in this field."
}