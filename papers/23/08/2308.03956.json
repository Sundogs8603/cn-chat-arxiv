{
    "title": "Fixed Inter-Neuron Covariability Induces Adversarial Robustness. (arXiv:2308.03956v1 [cs.LG])",
    "abstract": "The vulnerability to adversarial perturbations is a major flaw of Deep Neural Networks (DNNs) that raises question about their reliability when in real-world scenarios. On the other hand, human perception, which DNNs are supposed to emulate, is highly robust to such perturbations, indicating that there may be certain features of the human perception that make it robust but are not represented in the current class of DNNs. One such feature is that the activity of biological neurons is correlated and the structure of this correlation tends to be rather rigid over long spans of times, even if it hampers performance and learning. We hypothesize that integrating such constraints on the activations of a DNN would improve its adversarial robustness, and, to test this hypothesis, we have developed the Self-Consistent Activation (SCA) layer, which comprises of neurons whose activations are consistent with each other, as they conform to a fixed, but learned, covariability pattern. When evaluated",
    "link": "http://arxiv.org/abs/2308.03956",
    "context": "Title: Fixed Inter-Neuron Covariability Induces Adversarial Robustness. (arXiv:2308.03956v1 [cs.LG])\nAbstract: The vulnerability to adversarial perturbations is a major flaw of Deep Neural Networks (DNNs) that raises question about their reliability when in real-world scenarios. On the other hand, human perception, which DNNs are supposed to emulate, is highly robust to such perturbations, indicating that there may be certain features of the human perception that make it robust but are not represented in the current class of DNNs. One such feature is that the activity of biological neurons is correlated and the structure of this correlation tends to be rather rigid over long spans of times, even if it hampers performance and learning. We hypothesize that integrating such constraints on the activations of a DNN would improve its adversarial robustness, and, to test this hypothesis, we have developed the Self-Consistent Activation (SCA) layer, which comprises of neurons whose activations are consistent with each other, as they conform to a fixed, but learned, covariability pattern. When evaluated",
    "path": "papers/23/08/2308.03956.json",
    "total_tokens": 973,
    "translated_title": "固定的神经元协变性引发了对抗性鲁棒性",
    "translated_abstract": "与对抗性扰动的脆弱性是深度神经网络（DNN）的一个主要缺陷，这引发了关于它们在现实世界场景中可靠性的质疑。然而，DNN被认为是模拟人类感知的，而人类感知对这种扰动具有很高的鲁棒性，这表明可能存在让人类感知具有鲁棒性但在当前DNN类别中没有表示的特征。其中一种特征是生物神经元的活动具有相关性，并且这种相关性的结构在较长时间跨度上往往是相当稳定的，即使它会影响性能和学习。我们假设将这种对激活的约束集成到DNN中会提高其对抗性鲁棒性，并为了测试这个假设，我们开发了自洽激活（SCA）层，它由激活彼此一致的神经元组成，因为它们符合固定但可以学习的协变性模式。",
    "tldr": "该论文研究了固定的神经元协变性对深度神经网络（DNN）的对抗性鲁棒性的影响，提出了自洽激活（SCA）层，其激活具有固定但可学习的协变性模式，以提高DNN的鲁棒性。",
    "en_tdlr": "This paper investigates the impact of fixed inter-neuron covariability on the adversarial robustness of Deep Neural Networks (DNNs), proposing a Self-Consistent Activation (SCA) layer with activations that conform to a fixed but learnable covariability pattern to enhance the robustness of DNNs."
}