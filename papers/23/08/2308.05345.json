{
    "title": "RTLLM: An Open-Source Benchmark for Design RTL Generation with Large Language Model. (arXiv:2308.05345v1 [cs.LG])",
    "abstract": "Inspired by the recent success of large language models (LLMs) like ChatGPT, researchers start to explore the adoption of LLMs for agile hardware design, such as generating design RTL based on natural-language instructions. However, in existing works, their target designs are all relatively simple and in a small scale, and proposed by the authors themselves, making a fair comparison among different LLM solutions challenging. In addition, many prior works only focus on the design correctness, without evaluating the design qualities of generated design RTL. In this work, we propose an open-source benchmark named RTLLM, for generating design RTL with natural language instructions. To systematically evaluate the auto-generated design RTL, we summarized three progressive goals, named syntax goal, functionality goal, and design quality goal. This benchmark can automatically provide a quantitative evaluation of any given LLM-based solution. Furthermore, we propose an easy-to-use yet surprisin",
    "link": "http://arxiv.org/abs/2308.05345",
    "context": "Title: RTLLM: An Open-Source Benchmark for Design RTL Generation with Large Language Model. (arXiv:2308.05345v1 [cs.LG])\nAbstract: Inspired by the recent success of large language models (LLMs) like ChatGPT, researchers start to explore the adoption of LLMs for agile hardware design, such as generating design RTL based on natural-language instructions. However, in existing works, their target designs are all relatively simple and in a small scale, and proposed by the authors themselves, making a fair comparison among different LLM solutions challenging. In addition, many prior works only focus on the design correctness, without evaluating the design qualities of generated design RTL. In this work, we propose an open-source benchmark named RTLLM, for generating design RTL with natural language instructions. To systematically evaluate the auto-generated design RTL, we summarized three progressive goals, named syntax goal, functionality goal, and design quality goal. This benchmark can automatically provide a quantitative evaluation of any given LLM-based solution. Furthermore, we propose an easy-to-use yet surprisin",
    "path": "papers/23/08/2308.05345.json",
    "total_tokens": 869,
    "translated_title": "RTLLM：用于大规模语言模型设计RTL生成的开源基准测试",
    "translated_abstract": "受到像ChatGPT这样的大型语言模型（LLMs）的最新成功的启发，研究人员开始探索采用LLMs进行敏捷硬件设计，例如基于自然语言指令生成设计RTL。然而，在现有的工作中，目标设计都相对简单且规模较小，并由作者自己提出，这使得在不同的LLMs解决方案之间进行公平比较具有挑战性。此外，许多先前的工作只关注设计的正确性，而没有评估生成的设计RTL的设计质量。在这项工作中，我们提出了一个名为RTLLM的开源基准测试，用于使用自然语言指令生成设计RTL。为了系统评估自动生成的设计RTL，我们总结了三个渐进目标，即语法目标、功能目标和设计质量目标。该基准测试可以自动提供对任何给定基于LLM的解决方案的定量评估。",
    "tldr": "RTLLM是一个用自然语言指令生成设计RTL的开源基准测试，旨在解决现有工作中目标设计简单且规模小的问题，并提供对基于LLM的解决方案进行设计质量的定量评估。",
    "en_tdlr": "RTLLM is an open-source benchmark for generating design RTL with natural language instructions, aiming to address the challenge of relatively simple and small-scale target designs in existing works and provide quantitative evaluation of design quality for LLM-based solutions."
}