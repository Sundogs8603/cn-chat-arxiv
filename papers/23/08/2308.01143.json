{
    "title": "ADS-Cap: A Framework for Accurate and Diverse Stylized Captioning with Unpaired Stylistic Corpora. (arXiv:2308.01143v1 [cs.CV])",
    "abstract": "Generating visually grounded image captions with specific linguistic styles using unpaired stylistic corpora is a challenging task, especially since we expect stylized captions with a wide variety of stylistic patterns. In this paper, we propose a novel framework to generate Accurate and Diverse Stylized Captions (ADS-Cap). Our ADS-Cap first uses a contrastive learning module to align the image and text features, which unifies paired factual and unpaired stylistic corpora during the training process. A conditional variational auto-encoder is then used to automatically memorize diverse stylistic patterns in latent space and enhance diversity through sampling. We also design a simple but effective recheck module to boost style accuracy by filtering style-specific captions. Experimental results on two widely used stylized image captioning datasets show that regarding consistency with the image, style accuracy and diversity, ADS-Cap achieves outstanding performances compared to various bas",
    "link": "http://arxiv.org/abs/2308.01143",
    "context": "Title: ADS-Cap: A Framework for Accurate and Diverse Stylized Captioning with Unpaired Stylistic Corpora. (arXiv:2308.01143v1 [cs.CV])\nAbstract: Generating visually grounded image captions with specific linguistic styles using unpaired stylistic corpora is a challenging task, especially since we expect stylized captions with a wide variety of stylistic patterns. In this paper, we propose a novel framework to generate Accurate and Diverse Stylized Captions (ADS-Cap). Our ADS-Cap first uses a contrastive learning module to align the image and text features, which unifies paired factual and unpaired stylistic corpora during the training process. A conditional variational auto-encoder is then used to automatically memorize diverse stylistic patterns in latent space and enhance diversity through sampling. We also design a simple but effective recheck module to boost style accuracy by filtering style-specific captions. Experimental results on two widely used stylized image captioning datasets show that regarding consistency with the image, style accuracy and diversity, ADS-Cap achieves outstanding performances compared to various bas",
    "path": "papers/23/08/2308.01143.json",
    "total_tokens": 1051,
    "translated_title": "ADS-Cap：一种基于无配对风格语料库的准确多样化的风格化字幕生成框架",
    "translated_abstract": "使用无配对风格语料库生成具有特定语言风格的与图像相关的字幕是一项具有挑战性的任务，尤其是考虑到我们期望具有各种风格模式的风格化字幕。在本文中，我们提出了一种新颖的框架来生成准确多样化的风格化字幕 (ADS-Cap)。我们的ADS-Cap首先使用对比学习模块来对齐图像和文本特征，这在训练过程中统一了配对的事实和无配对的风格语料库。然后，我们使用有条件的变分自动编码器在潜在空间中自动记忆多样化的风格模式，并通过采样增强多样性。我们还设计了一个简单但有效的复核模块，通过过滤特定风格的字幕来提高风格的准确性。在两个广泛使用的风格化图像字幕数据集上的实验结果表明，相对于各种基准方法，ADS-Cap在与图像的一致性、风格准确性和多样性方面取得了出色的性能。",
    "tldr": "本文提出了一种基于无配对风格语料库的ADS-Cap框架，用于准确多样化地生成与图像相关的风格化字幕。该框架使用对比学习模块对齐图像和文本特征，并利用条件变分自动编码器记忆多样的风格模式。实验证明，ADS-Cap在与图像的一致性、风格准确性和多样性方面表现出色。",
    "en_tdlr": "This paper presents a framework called ADS-Cap, which generates accurate and diverse stylized captions related to images using unpaired stylistic corpora. The framework aligns image and text features with a contrastive learning module and memorizes diverse stylistic patterns using a conditional variational auto-encoder. Experimental results demonstrate that ADS-Cap achieves outstanding performance in terms of consistency with the image, style accuracy, and diversity compared to various baselines."
}