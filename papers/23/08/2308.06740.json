{
    "title": "Weighted Sparse Partial Least Squares for Joint Sample and Feature Selection. (arXiv:2308.06740v1 [cs.LG])",
    "abstract": "Sparse Partial Least Squares (sPLS) is a common dimensionality reduction technique for data fusion, which projects data samples from two views by seeking linear combinations with a small number of variables with the maximum variance. However, sPLS extracts the combinations between two data sets with all data samples so that it cannot detect latent subsets of samples. To extend the application of sPLS by identifying a specific subset of samples and remove outliers, we propose an $\\ell_\\infty/\\ell_0$-norm constrained weighted sparse PLS ($\\ell_\\infty/\\ell_0$-wsPLS) method for joint sample and feature selection, where the $\\ell_\\infty/\\ell_0$-norm constrains are used to select a subset of samples. We prove that the $\\ell_\\infty/\\ell_0$-norm constrains have the Kurdyka-\\L{ojasiewicz}~property so that a globally convergent algorithm is developed to solve it. Moreover, multi-view data with a same set of samples can be available in various real problems. To this end, we extend the $\\ell_\\inft",
    "link": "http://arxiv.org/abs/2308.06740",
    "context": "Title: Weighted Sparse Partial Least Squares for Joint Sample and Feature Selection. (arXiv:2308.06740v1 [cs.LG])\nAbstract: Sparse Partial Least Squares (sPLS) is a common dimensionality reduction technique for data fusion, which projects data samples from two views by seeking linear combinations with a small number of variables with the maximum variance. However, sPLS extracts the combinations between two data sets with all data samples so that it cannot detect latent subsets of samples. To extend the application of sPLS by identifying a specific subset of samples and remove outliers, we propose an $\\ell_\\infty/\\ell_0$-norm constrained weighted sparse PLS ($\\ell_\\infty/\\ell_0$-wsPLS) method for joint sample and feature selection, where the $\\ell_\\infty/\\ell_0$-norm constrains are used to select a subset of samples. We prove that the $\\ell_\\infty/\\ell_0$-norm constrains have the Kurdyka-\\L{ojasiewicz}~property so that a globally convergent algorithm is developed to solve it. Moreover, multi-view data with a same set of samples can be available in various real problems. To this end, we extend the $\\ell_\\inft",
    "path": "papers/23/08/2308.06740.json",
    "total_tokens": 1044,
    "translated_title": "加权稀疏偏最小二乘用于联合样本和特征选择",
    "translated_abstract": "稀疏偏最小二乘（sPLS）是一种常见的数据融合降维技术，通过寻找具有最大方差的少数变量的线性组合来将数据样本从两个视图投影出来。然而，sPLS提取的是两个数据集之间的所有数据样本之间的组合，因此无法检测样本的潜在子集。为了通过识别特定的样本子集并去除异常值来扩展sPLS的应用，我们提出了一种$\\ell_\\infty/\\ell_0$-范数约束加权稀疏PLS（$\\ell_\\infty/\\ell_0$-wsPLS）方法，用于联合样本和特征选择，其中$\\ell_\\infty/\\ell_0$-范数约束用于选择样本子集。我们证明了$\\ell_\\infty/\\ell_0$-范数约束具有Kurdyka-\\L{ojasiewicz}性质，从而开发了一种全局收敛算法来解决它。此外，在各种实际问题中，多视角数据可以具有相同的样本集。为此，我们扩展了$\\ell_\\infty$-norm-wsPLS方法以适用于多视角数据。",
    "tldr": "我们提出了一种加权稀疏偏最小二乘（wsPLS）方法，用于联合样本和特征选择。该方法通过引入$\\ell_\\infty/\\ell_0$-范数约束来选择特定子集的样本，并证明了约束具有全局收敛性质。此外，我们还扩展了方法以适用于多视角数据。",
    "en_tdlr": "We propose a weighted sparse Partial Least Squares (wsPLS) method for joint sample and feature selection. The method selects a specific subset of samples by introducing $\\ell_\\infty/\\ell_0$-norm constraints and we prove the global convergence property of the constraints. Furthermore, we extend the method for multi-view data."
}