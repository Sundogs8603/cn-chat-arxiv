{
    "title": "Generalized Oversampling for Learning from Imbalanced datasets and Associated Theory. (arXiv:2308.02966v1 [stat.ML])",
    "abstract": "In supervised learning, it is quite frequent to be confronted with real imbalanced datasets. This situation leads to a learning difficulty for standard algorithms. Research and solutions in imbalanced learning have mainly focused on classification tasks. Despite its importance, very few solutions exist for imbalanced regression. In this paper, we propose a data augmentation procedure, the GOLIATH algorithm, based on kernel density estimates which can be used in classification and regression. This general approach encompasses two large families of synthetic oversampling: those based on perturbations, such as Gaussian Noise, and those based on interpolations, such as SMOTE. It also provides an explicit form of these machine learning algorithms and an expression of their conditional densities, in particular for SMOTE. New synthetic data generators are deduced. We apply GOLIATH in imbalanced regression combining such generator procedures with a wild-bootstrap resampling technique for the t",
    "link": "http://arxiv.org/abs/2308.02966",
    "context": "Title: Generalized Oversampling for Learning from Imbalanced datasets and Associated Theory. (arXiv:2308.02966v1 [stat.ML])\nAbstract: In supervised learning, it is quite frequent to be confronted with real imbalanced datasets. This situation leads to a learning difficulty for standard algorithms. Research and solutions in imbalanced learning have mainly focused on classification tasks. Despite its importance, very few solutions exist for imbalanced regression. In this paper, we propose a data augmentation procedure, the GOLIATH algorithm, based on kernel density estimates which can be used in classification and regression. This general approach encompasses two large families of synthetic oversampling: those based on perturbations, such as Gaussian Noise, and those based on interpolations, such as SMOTE. It also provides an explicit form of these machine learning algorithms and an expression of their conditional densities, in particular for SMOTE. New synthetic data generators are deduced. We apply GOLIATH in imbalanced regression combining such generator procedures with a wild-bootstrap resampling technique for the t",
    "path": "papers/23/08/2308.02966.json",
    "total_tokens": 915,
    "translated_title": "广义过采样用于从不平衡数据集中学习以及相关理论",
    "translated_abstract": "在监督学习中，经常会遇到真实的不平衡数据集。这种情况对于标准算法来说是一个学习难题。不平衡学习的研究和解决方案主要集中在分类任务上。尽管其重要性，但几乎没有关于不平衡回归的解决方案存在。在本文中，我们提出了一种基于核密度估计的数据增强程序，即GOLIATH算法，它可以用于分类和回归。这种通用方法包括两大类合成过采样方法：基于扰动的方法，如高斯噪声，以及基于插值的方法，如SMOTE。它还提供了这些机器学习算法的显式形式和它们的条件密度表达式，尤其是对于SMOTE。新的合成数据生成器被推导出来。我们将GOLIATH应用于不平衡回归，将这些生成器过程与一种野生引导重采样技术相结合。",
    "tldr": "本文提出了一种广义过采样算法GOLIATH，基于核密度估计，可用于不平衡分类和回归任务。同时提供了这些机器学习算法的显式形式和条件密度表达式，为SMOTE等新的合成数据生成器提供了理论依据。",
    "en_tdlr": "This paper proposes a generalized oversampling algorithm called GOLIATH, based on kernel density estimates, for imbalanced classification and regression tasks. It provides explicit forms and conditional density expressions for these machine learning algorithms, serving as theoretical basis for new synthetic data generators like SMOTE."
}