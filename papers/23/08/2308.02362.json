{
    "title": "Flexible Differentially Private Vertical Federated Learning with Adaptive Feature Embeddings. (arXiv:2308.02362v1 [cs.CR])",
    "abstract": "The emergence of vertical federated learning (VFL) has stimulated concerns about the imperfection in privacy protection, as shared feature embeddings may reveal sensitive information under privacy attacks. This paper studies the delicate equilibrium between data privacy and task utility goals of VFL under differential privacy (DP). To address the generality issue of prior arts, this paper advocates a flexible and generic approach that decouples the two goals and addresses them successively. Specifically, we initially derive a rigorous privacy guarantee by applying norm clipping on shared feature embeddings, which is applicable across various datasets and models. Subsequently, we demonstrate that task utility can be optimized via adaptive adjustments on the scale and distribution of feature embeddings in an accuracy-appreciative way, without compromising established DP mechanisms. We concretize our observation into the proposed VFL-AFE framework, which exhibits effectiveness against pri",
    "link": "http://arxiv.org/abs/2308.02362",
    "context": "Title: Flexible Differentially Private Vertical Federated Learning with Adaptive Feature Embeddings. (arXiv:2308.02362v1 [cs.CR])\nAbstract: The emergence of vertical federated learning (VFL) has stimulated concerns about the imperfection in privacy protection, as shared feature embeddings may reveal sensitive information under privacy attacks. This paper studies the delicate equilibrium between data privacy and task utility goals of VFL under differential privacy (DP). To address the generality issue of prior arts, this paper advocates a flexible and generic approach that decouples the two goals and addresses them successively. Specifically, we initially derive a rigorous privacy guarantee by applying norm clipping on shared feature embeddings, which is applicable across various datasets and models. Subsequently, we demonstrate that task utility can be optimized via adaptive adjustments on the scale and distribution of feature embeddings in an accuracy-appreciative way, without compromising established DP mechanisms. We concretize our observation into the proposed VFL-AFE framework, which exhibits effectiveness against pri",
    "path": "papers/23/08/2308.02362.json",
    "total_tokens": 932,
    "translated_title": "灵活的差分隐私垂直联邦学习与自适应特征嵌入",
    "translated_abstract": "垂直联邦学习（VFL）的出现引发了对隐私保护不完善的担忧，因为共享的特征嵌入可能在隐私攻击下泄露敏感信息。本文研究了VFL在差分隐私（DP）下数据隐私和任务效用目标之间的微妙平衡。为了解决现有技术的通用性问题，本文提出了一种灵活且通用的方法，将这两个目标分解并逐步解决。具体而言，我们首先通过对共享特征嵌入应用范数剪裁，得到了严格的隐私保证，该方法适用于各种数据集和模型。随后，我们证明通过对特征嵌入的尺度和分布进行自适应调整，以一种注重准确性的方式，可以优化任务效用，而不损害已建立的DP机制。我们将这一观察结果具体化为提出的VFL-AFE框架，该框架对抗了先验攻击，并显示出了有效性。",
    "tldr": "本文提出了一种灵活的差分隐私垂直联邦学习方法（VFL），通过应用范数剪裁实现了严格的隐私保证，并通过自适应调整特征嵌入的尺度和分布来优化任务效用，而不损害隐私保护。"
}