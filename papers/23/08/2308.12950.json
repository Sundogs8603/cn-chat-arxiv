{
    "title": "Code Llama: Open Foundation Models for Code. (arXiv:2308.12950v1 [cs.CL])",
    "abstract": "We release Code Llama, a family of large language models for code based on Llama 2 providing state-of-the-art performance among open models, infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks. We provide multiple flavors to cover a wide range of applications: foundation models (Code Llama), Python specializations (Code Llama - Python), and instruction-following models (Code Llama - Instruct) with 7B, 13B and 34B parameters each. All models are trained on sequences of 16k tokens and show improvements on inputs with up to 100k tokens. 7B and 13B Code Llama and Code Llama - Instruct variants support infilling based on surrounding content. Code Llama reaches state-of-the-art performance among open models on several code benchmarks, with scores of up to 53% and 55% on HumanEval and MBPP, respectively. Notably, Code Llama - Python 7B outperforms Llama 2 70B on HumanEval and MBPP, and all our models outperform every othe",
    "link": "http://arxiv.org/abs/2308.12950",
    "context": "Title: Code Llama: Open Foundation Models for Code. (arXiv:2308.12950v1 [cs.CL])\nAbstract: We release Code Llama, a family of large language models for code based on Llama 2 providing state-of-the-art performance among open models, infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks. We provide multiple flavors to cover a wide range of applications: foundation models (Code Llama), Python specializations (Code Llama - Python), and instruction-following models (Code Llama - Instruct) with 7B, 13B and 34B parameters each. All models are trained on sequences of 16k tokens and show improvements on inputs with up to 100k tokens. 7B and 13B Code Llama and Code Llama - Instruct variants support infilling based on surrounding content. Code Llama reaches state-of-the-art performance among open models on several code benchmarks, with scores of up to 53% and 55% on HumanEval and MBPP, respectively. Notably, Code Llama - Python 7B outperforms Llama 2 70B on HumanEval and MBPP, and all our models outperform every othe",
    "path": "papers/23/08/2308.12950.json",
    "total_tokens": 926,
    "translated_title": "Code Llama: 用于代码的开放基础模型",
    "translated_abstract": "我们发布了Code Llama，这是一系列基于Llama 2的用于代码的大型语言模型，具有开放模型中最先进的性能，填充功能，支持大型输入上下文，并且能够进行零-shot指令跟踪编程任务。我们提供多种版本以覆盖广泛的应用场景：基础模型（Code Llama），Python专门化模型（Code Llama-Python），以及指令跟踪模型（Code Llama-Instruct），每个模型参数分别为7B、13B和34B。所有模型都是在16k标记序列上训练的，可以改善长度不超过100k标记的输入。7B和13B的Code Llama和Code Llama-Instruct变种会根据周围内容进行填充。Code Llama在几个代码基准测试中达到了开放模型中最先进的性能，HumanEval和MBPP分别达到了53%和55%的分数。值得注意的是，Code Llama-Python 7B在HumanEval和MBPP上优于Llama 2 70B，而我们的所有模型都优于其他任何模型。",
    "tldr": "Code Llama是一系列用于代码的开放基础模型，具有最先进的性能和填充功能，支持大型输入上下文和零-shot指令跟踪能力。在多个代码基准测试中，Code Llama达到开放模型中最高的性能，同时Python专门化模型在某些测试上超越了Llama 2的70B版本。"
}