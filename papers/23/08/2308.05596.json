{
    "title": "You Only Prompt Once: On the Capabilities of Prompt Learning on Large Language Models to Tackle Toxic Content. (arXiv:2308.05596v1 [cs.CL])",
    "abstract": "The spread of toxic content online is an important problem that has adverse effects on user experience online and in our society at large. Motivated by the importance and impact of the problem, research focuses on developing solutions to detect toxic content, usually leveraging machine learning (ML) models trained on human-annotated datasets. While these efforts are important, these models usually do not generalize well and they can not cope with new trends (e.g., the emergence of new toxic terms). Currently, we are witnessing a shift in the approach to tackling societal issues online, particularly leveraging large language models (LLMs) like GPT-3 or T5 that are trained on vast corpora and have strong generalizability. In this work, we investigate how we can use LLMs and prompt learning to tackle the problem of toxic content, particularly focusing on three tasks; 1) Toxicity Classification, 2) Toxic Span Detection, and 3) Detoxification. We perform an extensive evaluation over five mo",
    "link": "http://arxiv.org/abs/2308.05596",
    "context": "Title: You Only Prompt Once: On the Capabilities of Prompt Learning on Large Language Models to Tackle Toxic Content. (arXiv:2308.05596v1 [cs.CL])\nAbstract: The spread of toxic content online is an important problem that has adverse effects on user experience online and in our society at large. Motivated by the importance and impact of the problem, research focuses on developing solutions to detect toxic content, usually leveraging machine learning (ML) models trained on human-annotated datasets. While these efforts are important, these models usually do not generalize well and they can not cope with new trends (e.g., the emergence of new toxic terms). Currently, we are witnessing a shift in the approach to tackling societal issues online, particularly leveraging large language models (LLMs) like GPT-3 or T5 that are trained on vast corpora and have strong generalizability. In this work, we investigate how we can use LLMs and prompt learning to tackle the problem of toxic content, particularly focusing on three tasks; 1) Toxicity Classification, 2) Toxic Span Detection, and 3) Detoxification. We perform an extensive evaluation over five mo",
    "path": "papers/23/08/2308.05596.json",
    "total_tokens": 914,
    "translated_title": "只需一次提示：关于大语言模型的提示学习在解决有毒内容中的能力",
    "translated_abstract": "在线有害内容的传播是一个重要问题，对在线用户体验和社会产生负面影响。受到这个问题的重要性和影响的启发，研究集中于开发解决方案来检测有毒内容，通常利用在人工注释数据集上训练的机器学习模型。虽然这些努力很重要，但这些模型通常无法很好地推广，并且无法应对新的趋势（例如，新的有毒术语的出现）。目前，我们正在目睹解决在线社会问题的方法发生变化，特别是利用像GPT-3或T5这样的大语言模型，它们在大规模语料库上进行训练，并具有很强的泛化能力。在这项工作中，我们调查了如何利用大语言模型和提示学习来解决有毒内容的问题，特别关注三个任务：1）毒性分类，2）毒性跨度检测，3）去毒化。我们对五个模型进行了广泛的评估...",
    "tldr": "本研究探讨如何利用大型语言模型和提示学习来解决在线有毒内容问题，重点关注毒性分类、毒性跨度检测和去毒化任务。",
    "en_tdlr": "This study investigates the use of large language models and prompt learning to address the issue of toxic content online, focusing on toxicity classification, toxic span detection, and detoxification tasks."
}