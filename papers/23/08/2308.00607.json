{
    "title": "Beyond One-Hot-Encoding: Injecting Semantics to Drive Image Classifiers. (arXiv:2308.00607v1 [cs.CV])",
    "abstract": "Images are loaded with semantic information that pertains to real-world ontologies: dog breeds share mammalian similarities, food pictures are often depicted in domestic environments, and so on. However, when training machine learning models for image classification, the relative similarities amongst object classes are commonly paired with one-hot-encoded labels. According to this logic, if an image is labelled as 'spoon', then 'tea-spoon' and 'shark' are equally wrong in terms of training loss. To overcome this limitation, we explore the integration of additional goals that reflect ontological and semantic knowledge, improving model interpretability and trustworthiness. We suggest a generic approach that allows to derive an additional loss term starting from any kind of semantic information about the classification label. First, we show how to apply our approach to ontologies and word embeddings, and discuss how the resulting information can drive a supervised learning process. Second",
    "link": "http://arxiv.org/abs/2308.00607",
    "context": "Title: Beyond One-Hot-Encoding: Injecting Semantics to Drive Image Classifiers. (arXiv:2308.00607v1 [cs.CV])\nAbstract: Images are loaded with semantic information that pertains to real-world ontologies: dog breeds share mammalian similarities, food pictures are often depicted in domestic environments, and so on. However, when training machine learning models for image classification, the relative similarities amongst object classes are commonly paired with one-hot-encoded labels. According to this logic, if an image is labelled as 'spoon', then 'tea-spoon' and 'shark' are equally wrong in terms of training loss. To overcome this limitation, we explore the integration of additional goals that reflect ontological and semantic knowledge, improving model interpretability and trustworthiness. We suggest a generic approach that allows to derive an additional loss term starting from any kind of semantic information about the classification label. First, we show how to apply our approach to ontologies and word embeddings, and discuss how the resulting information can drive a supervised learning process. Second",
    "path": "papers/23/08/2308.00607.json",
    "total_tokens": 839,
    "translated_title": "超越One-Hot-Encoding: 注入语义驱动图像分类器",
    "translated_abstract": "图像中包含了与现实世界本体论相关的语义信息：狗的品种具有哺乳动物的相似性，食物的图片通常在家庭环境中描述，等等。然而，在对图像分类进行机器学习模型训练时，对象类之间的相对相似性常常与One-Hot-Encoding标签配对。根据这种逻辑，如果一个图像被标记为“勺子”，那么“茶勺”和“鲨鱼”在训练损失方面是同样错误的。为了克服这个限制，我们探索了整合反映本体和语义知识的额外目标的方法，提高了模型的可解释性和可信度。我们提出了一种通用方法，可以根据与分类标签相关的任何类型的语义信息导出额外的损失项。首先，我们展示了如何将我们的方法应用于本体和词嵌入，并讨论了由此得到的信息如何驱动受监督的学习过程。其次，",
    "tldr": "本文探索了将本体和语义知识反映到图像分类器中的方法，提高了模型的可解释性和可信度。",
    "en_tdlr": "This paper explores a method of integrating ontological and semantic knowledge into image classifiers, improving model interpretability and trustworthiness."
}