{
    "title": "Data-to-text Generation for Severely Under-Resourced Languages with GPT-3.5: A Bit of Help Needed from Google Translate. (arXiv:2308.09957v1 [cs.CL])",
    "abstract": "LLMs like GPT are great at tasks involving English which dominates in their training data. In this paper, we look at how they cope with tasks involving languages that are severely under-represented in their training data, in the context of data-to-text generation for Irish, Maltese, Welsh and Breton. During the prompt-engineering phase we tested a range of prompt types and formats on GPT-3.5 and~4 with a small sample of example input/output pairs. We then fully evaluated the two most promising prompts in two scenarios: (i) direct generation into the under-resourced language, and (ii) generation into English followed by translation into the under-resourced language. We find that few-shot prompting works better for direct generation into under-resourced languages, but that the difference disappears when pivoting via English. The few-shot + translation system variants were submitted to the WebNLG 2023 shared task where they outperformed competitor systems by substantial margins in all lan",
    "link": "http://arxiv.org/abs/2308.09957",
    "context": "Title: Data-to-text Generation for Severely Under-Resourced Languages with GPT-3.5: A Bit of Help Needed from Google Translate. (arXiv:2308.09957v1 [cs.CL])\nAbstract: LLMs like GPT are great at tasks involving English which dominates in their training data. In this paper, we look at how they cope with tasks involving languages that are severely under-represented in their training data, in the context of data-to-text generation for Irish, Maltese, Welsh and Breton. During the prompt-engineering phase we tested a range of prompt types and formats on GPT-3.5 and~4 with a small sample of example input/output pairs. We then fully evaluated the two most promising prompts in two scenarios: (i) direct generation into the under-resourced language, and (ii) generation into English followed by translation into the under-resourced language. We find that few-shot prompting works better for direct generation into under-resourced languages, but that the difference disappears when pivoting via English. The few-shot + translation system variants were submitted to the WebNLG 2023 shared task where they outperformed competitor systems by substantial margins in all lan",
    "path": "papers/23/08/2308.09957.json",
    "total_tokens": 1054,
    "translated_title": "使用GPT-3.5在资源严重匮乏的语言中进行数据到文本生成:需要谷歌翻译的一点帮助",
    "translated_abstract": "LLM（语言模型，如GPT）在处理英语相关任务时表现出色，因为训练数据中英语的比例占主导地位。本文研究了在数据到文本生成任务中，它们如何应对那些在训练数据中严重不足的语言，具体包括爱尔兰语、马耳他语、威尔士语和布里多尼语。我们在GPT-3.5和GPT-4上进行了引导式工程阶段的测试，使用了一小部分示例输入/输出对的各种引导类型和格式。然后我们在两种场景中对两个最有希望的引导进行了全面评估：（i）直接生成目标语言（资源匮乏的语言），（ii）生成英语后再翻译成目标语言。我们发现，在直接生成资源匮乏的语言方面，few-shot引导效果更好，但通过英语进行中转后，这种差异消失了。我们将few-shot + 翻译系统的变体提交到了WebNLG 2023共享任务中，在所有语言中，它们的表现都比竞争系统好得多。",
    "tldr": "本文研究了在资源严重匮乏的语言中使用GPT-3.5进行数据到文本生成的任务。发现few-shot引导对于直接生成目标语言效果更好，而通过英语进行中转后，这种差异消失了。在WebNLG 2023共享任务中，这种few-shot + 翻译系统的变体在所有语言中的表现都优于竞争系统。",
    "en_tdlr": "This paper investigates the task of data-to-text generation using GPT-3.5 for severely under-resourced languages. It is found that few-shot prompting works better for direct generation into under-resourced languages, but the difference disappears when pivoting via English. The few-shot + translation system variants outperformed competitor systems in all languages in the WebNLG 2023 shared task."
}