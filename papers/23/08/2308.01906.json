{
    "title": "Reasoning in Large Language Models Through Symbolic Math Word Problems. (arXiv:2308.01906v1 [cs.CL])",
    "abstract": "Large language models (LLMs) have revolutionized NLP by solving downstream tasks with little to no labeled data. Despite their versatile abilities, the larger question of their ability to reason remains ill-understood. This paper addresses reasoning in math word problems (MWPs) by studying symbolic versions of the numeric problems, since a symbolic expression is a \"concise explanation\" of the numeric answer. We create and use a symbolic version of the SVAMP dataset and find that GPT-3's davinci-002 model also has good zero-shot accuracy on symbolic MWPs. To evaluate the faithfulness of the model's reasoning, we go beyond accuracy and additionally evaluate the alignment between the final answer and the outputted reasoning, which correspond to numeric and symbolic answers respectively for MWPs. We explore a self-prompting approach to encourage the symbolic reasoning to align with the numeric answer, thus equipping the LLM with the ability to provide a concise and verifiable reasoning and",
    "link": "http://arxiv.org/abs/2308.01906",
    "context": "Title: Reasoning in Large Language Models Through Symbolic Math Word Problems. (arXiv:2308.01906v1 [cs.CL])\nAbstract: Large language models (LLMs) have revolutionized NLP by solving downstream tasks with little to no labeled data. Despite their versatile abilities, the larger question of their ability to reason remains ill-understood. This paper addresses reasoning in math word problems (MWPs) by studying symbolic versions of the numeric problems, since a symbolic expression is a \"concise explanation\" of the numeric answer. We create and use a symbolic version of the SVAMP dataset and find that GPT-3's davinci-002 model also has good zero-shot accuracy on symbolic MWPs. To evaluate the faithfulness of the model's reasoning, we go beyond accuracy and additionally evaluate the alignment between the final answer and the outputted reasoning, which correspond to numeric and symbolic answers respectively for MWPs. We explore a self-prompting approach to encourage the symbolic reasoning to align with the numeric answer, thus equipping the LLM with the ability to provide a concise and verifiable reasoning and",
    "path": "papers/23/08/2308.01906.json",
    "total_tokens": 914,
    "translated_title": "大型语言模型通过符号化数学问题进行推理",
    "translated_abstract": "大型语言模型（LLMs）通过解决几乎没有标记数据的下游任务，改变了自然语言处理（NLP）的方式。尽管它们具有多功能的能力，但对它们的推理能力的问题仍然不太清楚。本文通过研究数学问题的符号化版本来解决数学问题的推理问题，因为符号表达是对数值答案的“简明解释”。我们创建并使用了SVAMP数据集的符号化版本，并发现GPT-3的davinci-002模型在符号化数学问题上也具有良好的零样本准确性。为了评估模型推理的准确性，我们不仅考虑准确率，还评估最终答案和推理结果之间的一致性，分别对应于数值和符号化答案的数学问题。我们探索了一种自我提示的方法，鼓励符号化推理与数值答案保持一致，从而使LLM能够提供简明且可验证的推理。",
    "tldr": "本文通过研究数学问题的符号化版本来解决大型语言模型（LLMs）的推理能力问题，该方法探索了一种自我提示的方法，鼓励符号化推理与数值答案保持一致。",
    "en_tdlr": "This paper addresses the issue of reasoning ability in large language models (LLMs) by studying symbolic versions of math word problems (MWPs). The paper explores a self-prompting approach to encourage symbolic reasoning to align with the numeric answer, thus equipping the LLM with the ability to provide concise and verifiable reasoning."
}