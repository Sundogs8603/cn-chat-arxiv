{
    "title": "Sentence-Level Multimodal and Language-Agnostic Representations. (arXiv:2308.11466v1 [cs.CL])",
    "abstract": "We introduce SONAR, a new multilingual and multimodal fixed-size sentence embedding space. Our single text encoder, covering 200 languages, substantially outperforms existing sentence embeddings such as LASER3 and LabSE on the xsim and xsim++ multilingual similarity search tasks. Speech segments can be embedded in the same SONAR embedding space using language-specific speech encoders trained in a teacher-student setting on speech transcription data. Our encoders outperform existing speech encoders on similarity search tasks. We also provide a text decoder for 200 languages, which allows us to perform text-to-text and speech-to-text machine translation, including for zero-shot language and modality combinations. Our text-to-text results are competitive compared to the state-of-the-art NLLB~1B model, despite the fixed-size bottleneck representation. Our zero-shot speech-to-text translation results compare favorably with strong supervised baselines such as Whisper.",
    "link": "http://arxiv.org/abs/2308.11466",
    "context": "Title: Sentence-Level Multimodal and Language-Agnostic Representations. (arXiv:2308.11466v1 [cs.CL])\nAbstract: We introduce SONAR, a new multilingual and multimodal fixed-size sentence embedding space. Our single text encoder, covering 200 languages, substantially outperforms existing sentence embeddings such as LASER3 and LabSE on the xsim and xsim++ multilingual similarity search tasks. Speech segments can be embedded in the same SONAR embedding space using language-specific speech encoders trained in a teacher-student setting on speech transcription data. Our encoders outperform existing speech encoders on similarity search tasks. We also provide a text decoder for 200 languages, which allows us to perform text-to-text and speech-to-text machine translation, including for zero-shot language and modality combinations. Our text-to-text results are competitive compared to the state-of-the-art NLLB~1B model, despite the fixed-size bottleneck representation. Our zero-shot speech-to-text translation results compare favorably with strong supervised baselines such as Whisper.",
    "path": "papers/23/08/2308.11466.json",
    "total_tokens": 902,
    "translated_title": "句子级多模态和语言无关表示",
    "translated_abstract": "我们引入了SONAR，一个新的多语言和多模态的定长句子嵌入空间。我们的单一文本编码器覆盖了200种语言，在xsim和xsim++多语言相似性搜索任务上明显优于现有的句子嵌入模型LASER3和LabSE。使用特定语言的语音编码器在师生设置下训练语音转录数据后，语音片段可以在同一SONAR嵌入空间中进行嵌入。我们的编码器在相似性搜索任务上优于现有的语音编码器。我们还提供了一个适用于200种语言的文本解码器，可以进行文本到文本和语音到文本的机器翻译，包括零翻译语言和模态组合。尽管存在定长瓶颈表示，我们的文本到文本结果在与最先进的NLLB~1B模型相比中具有竞争力。我们的零翻译语音到文本结果与强有力的监督基线模型Whisper相比表现良好。",
    "tldr": "这项研究引入了SONAR，一个多语言和多模态的句子嵌入空间，通过单一文本编码器在相似性搜索任务中取得显著优势，并提供了用于200种语言的文本解码器，可以进行文本到文本和语音到文本的机器翻译。这些结果相比现有模型具有竞争力，并且对语音到文本模型也取得了良好的结果。"
}