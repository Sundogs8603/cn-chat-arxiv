{
    "title": "Towards Effective Ancient Chinese Translation: Dataset, Model, and Evaluation. (arXiv:2308.00240v1 [cs.CL])",
    "abstract": "Interpreting ancient Chinese has been the key to comprehending vast Chinese literature, tradition, and civilization. In this paper, we propose Erya for ancient Chinese translation. From a dataset perspective, we collect, clean, and classify ancient Chinese materials from various sources, forming the most extensive ancient Chinese resource to date. From a model perspective, we devise Erya training method oriented towards ancient Chinese. We design two jointly-working tasks: disyllabic aligned substitution (DAS) and dual masked language model (DMLM). From an evaluation perspective, we build a benchmark to judge ancient Chinese translation quality in different scenarios and evaluate the ancient Chinese translation capacities of various existing models. Our model exhibits remarkable zero-shot performance across five domains, with over +12.0 BLEU against GPT-3.5 models and better human evaluation results than ERNIE Bot. Subsequent fine-tuning further shows the superior transfer capability o",
    "link": "http://arxiv.org/abs/2308.00240",
    "context": "Title: Towards Effective Ancient Chinese Translation: Dataset, Model, and Evaluation. (arXiv:2308.00240v1 [cs.CL])\nAbstract: Interpreting ancient Chinese has been the key to comprehending vast Chinese literature, tradition, and civilization. In this paper, we propose Erya for ancient Chinese translation. From a dataset perspective, we collect, clean, and classify ancient Chinese materials from various sources, forming the most extensive ancient Chinese resource to date. From a model perspective, we devise Erya training method oriented towards ancient Chinese. We design two jointly-working tasks: disyllabic aligned substitution (DAS) and dual masked language model (DMLM). From an evaluation perspective, we build a benchmark to judge ancient Chinese translation quality in different scenarios and evaluate the ancient Chinese translation capacities of various existing models. Our model exhibits remarkable zero-shot performance across five domains, with over +12.0 BLEU against GPT-3.5 models and better human evaluation results than ERNIE Bot. Subsequent fine-tuning further shows the superior transfer capability o",
    "path": "papers/23/08/2308.00240.json",
    "total_tokens": 973,
    "translated_title": "有效的古代汉语翻译：数据集、模型和评估",
    "translated_abstract": "解读古代汉语一直是理解中国广阔文学、传统和文明的关键。本文提出了针对古代汉语的Erya翻译模型。在数据集方面，我们从多个来源收集、清理和分类古代汉语材料，形成迄今为止最全面的古代汉语资源。从模型角度来看，我们设计了适用于古代汉语的Erya训练方法。我们设计了两个共同工作的任务：双音节对齐替换（DAS）和双层遮罩语言模型（DMLM）。从评估角度来看，我们建立了一个基准，用于在不同场景下评判古代汉语翻译质量，并评估各种现有模型的古代汉语翻译能力。我们的模型在五个领域表现出卓越的零-shot性能，对GPT-3.5模型的BLEU分数提高了+12.0，并且在人工评估结果上优于ERNIE Bot。随后的微调进一步展示了更强的迁移能力。",
    "tldr": "本论文提出了Erya模型，通过收集、清理和分类大量古代汉语材料，形成了最全面的古代汉语资源。该模型在双音节对齐替换和双层遮罩语言模型任务上表现出色，并在多个领域展示了出色的零-shot性能和迁移能力。"
}