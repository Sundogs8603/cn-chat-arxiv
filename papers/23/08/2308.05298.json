{
    "title": "Double-chain Constraints for 3D Human Pose Estimation in Images and Videos. (arXiv:2308.05298v1 [cs.CV])",
    "abstract": "Reconstructing 3D poses from 2D poses lacking depth information is particularly challenging due to the complexity and diversity of human motion. The key is to effectively model the spatial constraints between joints to leverage their inherent dependencies. Thus, we propose a novel model, called Double-chain Graph Convolutional Transformer (DC-GCT), to constrain the pose through a double-chain design consisting of local-to-global and global-to-local chains to obtain a complex representation more suitable for the current human pose. Specifically, we combine the advantages of GCN and Transformer and design a Local Constraint Module (LCM) based on GCN and a Global Constraint Module (GCM) based on self-attention mechanism as well as a Feature Interaction Module (FIM). The proposed method fully captures the multi-level dependencies between human body joints to optimize the modeling capability of the model. Moreover, we propose a method to use temporal information into the single-frame model ",
    "link": "http://arxiv.org/abs/2308.05298",
    "context": "Title: Double-chain Constraints for 3D Human Pose Estimation in Images and Videos. (arXiv:2308.05298v1 [cs.CV])\nAbstract: Reconstructing 3D poses from 2D poses lacking depth information is particularly challenging due to the complexity and diversity of human motion. The key is to effectively model the spatial constraints between joints to leverage their inherent dependencies. Thus, we propose a novel model, called Double-chain Graph Convolutional Transformer (DC-GCT), to constrain the pose through a double-chain design consisting of local-to-global and global-to-local chains to obtain a complex representation more suitable for the current human pose. Specifically, we combine the advantages of GCN and Transformer and design a Local Constraint Module (LCM) based on GCN and a Global Constraint Module (GCM) based on self-attention mechanism as well as a Feature Interaction Module (FIM). The proposed method fully captures the multi-level dependencies between human body joints to optimize the modeling capability of the model. Moreover, we propose a method to use temporal information into the single-frame model ",
    "path": "papers/23/08/2308.05298.json",
    "total_tokens": 904,
    "translated_title": "图像和视频中的3D人体姿势估计的双链约束",
    "translated_abstract": "在缺乏深度信息的2D姿势重建3D姿势尤其具有挑战性，人类运动的复杂性和多样性是主要原因。关键在于有效地建模关节之间的空间约束，以利用它们的固有相互依赖性。因此，我们提出了一种新颖的模型，称为双链图卷积变换器 (DC-GCT)，通过由局部到全局和全局到局部构成的双链设计来约束姿势，以获得适用于当前人体姿势的复杂表示。具体而言，我们结合了GCN和Transformer的优点，并基于GCN设计了基于本地约束模块 (LCM) 和基于自注意力机制的全局约束模块 (GCM)，以及特征交互模块 (FIM)。所提出的方法充分捕捉了人体关节之间的多级依赖关系，以优化模型的建模能力。此外，我们还提出了一种将时间信息引入单帧模型的方法。",
    "tldr": "DC-GCT是一种新颖的模型，通过双链设计来约束图像和视频中的3D人体姿势估计，它结合了GCN和Transformer的优点，充分捕捉了人体关节之间的多级依赖关系。"
}