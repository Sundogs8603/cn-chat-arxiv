{
    "title": "Learning to Identify Critical States for Reinforcement Learning from Videos. (arXiv:2308.07795v1 [cs.CV])",
    "abstract": "Recent work on deep reinforcement learning (DRL) has pointed out that algorithmic information about good policies can be extracted from offline data which lack explicit information about executed actions. For example, videos of humans or robots may convey a lot of implicit information about rewarding action sequences, but a DRL machine that wants to profit from watching such videos must first learn by itself to identify and recognize relevant states/actions/rewards. Without relying on ground-truth annotations, our new method called Deep State Identifier learns to predict returns from episodes encoded as videos. Then it uses a kind of mask-based sensitivity analysis to extract/identify important critical states. Extensive experiments showcase our method's potential for understanding and improving agent behavior. The source code and the generated datasets are available at https://github.com/AI-Initiative-KAUST/VideoRLCS.",
    "link": "http://arxiv.org/abs/2308.07795",
    "context": "Title: Learning to Identify Critical States for Reinforcement Learning from Videos. (arXiv:2308.07795v1 [cs.CV])\nAbstract: Recent work on deep reinforcement learning (DRL) has pointed out that algorithmic information about good policies can be extracted from offline data which lack explicit information about executed actions. For example, videos of humans or robots may convey a lot of implicit information about rewarding action sequences, but a DRL machine that wants to profit from watching such videos must first learn by itself to identify and recognize relevant states/actions/rewards. Without relying on ground-truth annotations, our new method called Deep State Identifier learns to predict returns from episodes encoded as videos. Then it uses a kind of mask-based sensitivity analysis to extract/identify important critical states. Extensive experiments showcase our method's potential for understanding and improving agent behavior. The source code and the generated datasets are available at https://github.com/AI-Initiative-KAUST/VideoRLCS.",
    "path": "papers/23/08/2308.07795.json",
    "total_tokens": 860,
    "translated_title": "从视频中学习识别强化学习的关键状态",
    "translated_abstract": "最近关于深度强化学习(DRL)的研究指出，有关好策略的算法信息可以从缺乏执行动作明确信息的离线数据中提取出来。例如，人类或机器人的视频可能传达了很多有关奖励动作序列的隐含信息，但是想要从这些视频中观察并获益的DRL机器必须首先通过自身学习来识别和认可相关的状态/动作/奖励。在不依赖于地面真值标注的情况下，我们提出了一种被称为深度状态识别器的新方法，它学习预测被编码为视频的返回值。然后，它使用一种基于掩码的敏感性分析方法来提取/识别重要的关键状态。广泛的实验展示了我们的方法在理解和改善智能体行为方面的潜力。源代码和生成的数据集可以在https://github.com/AI-Initiative-KAUST/VideoRLCS 上找到。",
    "tldr": "该论文提出了一种名为深度状态识别器的方法，能够从视频中学习识别关键状态，并预测强化学习的回报。该方法在理解和改善智能体行为方面具有潜力。",
    "en_tdlr": "This paper presents a method called Deep State Identifier, which learns to identify critical states from videos and predicts rewards in reinforcement learning. The method shows potential in understanding and improving agent behavior."
}