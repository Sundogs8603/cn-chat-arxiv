{
    "title": "VBD-MT Chinese-Vietnamese Translation Systems for VLSP 2022. (arXiv:2308.07601v1 [cs.CL])",
    "abstract": "We present our systems participated in the VLSP 2022 machine translation shared task. In the shared task this year, we participated in both translation tasks, i.e., Chinese-Vietnamese and Vietnamese-Chinese translations. We build our systems based on the neural-based Transformer model with the powerful multilingual denoising pre-trained model mBART. The systems are enhanced by a sampling method for backtranslation, which leverage large scale available monolingual data. Additionally, several other methods are applied to improve the translation quality including ensembling and postprocessing. We achieve 38.9 BLEU on ChineseVietnamese and 38.0 BLEU on VietnameseChinese on the public test sets, which outperform several strong baselines.",
    "link": "http://arxiv.org/abs/2308.07601",
    "context": "Title: VBD-MT Chinese-Vietnamese Translation Systems for VLSP 2022. (arXiv:2308.07601v1 [cs.CL])\nAbstract: We present our systems participated in the VLSP 2022 machine translation shared task. In the shared task this year, we participated in both translation tasks, i.e., Chinese-Vietnamese and Vietnamese-Chinese translations. We build our systems based on the neural-based Transformer model with the powerful multilingual denoising pre-trained model mBART. The systems are enhanced by a sampling method for backtranslation, which leverage large scale available monolingual data. Additionally, several other methods are applied to improve the translation quality including ensembling and postprocessing. We achieve 38.9 BLEU on ChineseVietnamese and 38.0 BLEU on VietnameseChinese on the public test sets, which outperform several strong baselines.",
    "path": "papers/23/08/2308.07601.json",
    "total_tokens": 803,
    "translated_title": "VBD-MT 用于VLSP 2022的中越翻译系统（arXiv:2308.07601v1 [cs.CL]）",
    "translated_abstract": "我们介绍了参加VLSP 2022机器翻译共享任务的系统。在今年的共享任务中，我们参加了中越和越中两种翻译任务。我们的系统基于基于神经网络的Transformer模型和强大的多语言去噪预训练模型mBART。系统通过采样法进行反向翻译，利用大规模可用的单语数据进行增强。此外，还采用了其他几种方法来提高翻译质量，包括集成和后处理。在公共测试集上，我们在中越翻译任务上达到了38.9 BLEU，在越中翻译任务上达到了38.0 BLEU，超过了几个强有力的基准系统。",
    "tldr": "VBD-MT是VLSP 2022中越翻译任务的系统，通过使用Transformer模型和mBART预训练模型，采用反向翻译和其他方法来提高翻译质量，在公共测试集上表现优秀。",
    "en_tdlr": "VBD-MT is a system for Chinese-Vietnamese translation in VLSP 2022, which achieves high translation quality by utilizing Transformer model, mBART pre-training model, backtranslation, and other methods, outperforming strong baselines on the public test sets."
}