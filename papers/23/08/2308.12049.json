{
    "title": "Towards Privacy-Supporting Fall Detection via Deep Unsupervised RGB2Depth Adaptation. (arXiv:2308.12049v1 [cs.CV])",
    "abstract": "Fall detection is a vital task in health monitoring, as it allows the system to trigger an alert and therefore enabling faster interventions when a person experiences a fall. Although most previous approaches rely on standard RGB video data, such detailed appearance-aware monitoring poses significant privacy concerns. Depth sensors, on the other hand, are better at preserving privacy as they merely capture the distance of objects from the sensor or camera, omitting color and texture information. In this paper, we introduce a privacy-supporting solution that makes the RGB-trained model applicable in depth domain and utilizes depth data at test time for fall detection. To achieve cross-modal fall detection, we present an unsupervised RGB to Depth (RGB2Depth) cross-modal domain adaptation approach that leverages labelled RGB data and unlabelled depth data during training. Our proposed pipeline incorporates an intermediate domain module for feature bridging, modality adversarial loss for m",
    "link": "http://arxiv.org/abs/2308.12049",
    "context": "Title: Towards Privacy-Supporting Fall Detection via Deep Unsupervised RGB2Depth Adaptation. (arXiv:2308.12049v1 [cs.CV])\nAbstract: Fall detection is a vital task in health monitoring, as it allows the system to trigger an alert and therefore enabling faster interventions when a person experiences a fall. Although most previous approaches rely on standard RGB video data, such detailed appearance-aware monitoring poses significant privacy concerns. Depth sensors, on the other hand, are better at preserving privacy as they merely capture the distance of objects from the sensor or camera, omitting color and texture information. In this paper, we introduce a privacy-supporting solution that makes the RGB-trained model applicable in depth domain and utilizes depth data at test time for fall detection. To achieve cross-modal fall detection, we present an unsupervised RGB to Depth (RGB2Depth) cross-modal domain adaptation approach that leverages labelled RGB data and unlabelled depth data during training. Our proposed pipeline incorporates an intermediate domain module for feature bridging, modality adversarial loss for m",
    "path": "papers/23/08/2308.12049.json",
    "total_tokens": 946,
    "translated_title": "通过深度无监督的RGB2Depth适应实现支持隐私的跌倒检测",
    "translated_abstract": "跌倒检测是健康监测中的重要任务，它可以触发警报并在人员跌倒时实现更快的干预。虽然大多数先前的方法都依赖于标准的RGB视频数据，但这种详细的外观感知监测存在显着的隐私问题。另一方面，深度传感器在保护隐私方面表现更好，因为它们仅捕捉物体与传感器或相机的距离，省略了颜色和纹理信息。在本文中，我们介绍了一种支持隐私的解决方案，该解决方案使得RGB训练模型可以应用于深度领域，并在测试时利用深度数据进行跌倒检测。为了实现跨模态的跌倒检测，我们提出了一种无监督的RGB到深度（RGB2Depth）跨模态领域适应方法，该方法利用有标签的RGB数据和无标签的深度数据进行训练。我们提出的技术流程包括一个中间领域模块用于特征融合，以及模态对抗性损失等。",
    "tldr": "本研究提出了一种支持隐私的跌倒检测解决方案，通过深度无监督的RGB2Depth适应实现了在深度领域中利用RGB训练模型进行跌倒检测。通过利用有标签的RGB数据和无标签的深度数据进行跨模态领域适应，实现了更好的隐私保护。"
}