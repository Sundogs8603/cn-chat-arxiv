{
    "title": "Your Negative May not Be True Negative: Boosting Image-Text Matching with False Negative Elimination. (arXiv:2308.04380v1 [cs.CV])",
    "abstract": "Most existing image-text matching methods adopt triplet loss as the optimization objective, and choosing a proper negative sample for the triplet of <anchor, positive, negative> is important for effectively training the model, e.g., hard negatives make the model learn efficiently and effectively. However, we observe that existing methods mainly employ the most similar samples as hard negatives, which may not be true negatives. In other words, the samples with high similarity but not paired with the anchor may reserve positive semantic associations, and we call them false negatives. Repelling these false negatives in triplet loss would mislead the semantic representation learning and result in inferior retrieval performance. In this paper, we propose a novel False Negative Elimination (FNE) strategy to select negatives via sampling, which could alleviate the problem introduced by false negatives. Specifically, we first construct the distributions of positive and negative samples separat",
    "link": "http://arxiv.org/abs/2308.04380",
    "context": "Title: Your Negative May not Be True Negative: Boosting Image-Text Matching with False Negative Elimination. (arXiv:2308.04380v1 [cs.CV])\nAbstract: Most existing image-text matching methods adopt triplet loss as the optimization objective, and choosing a proper negative sample for the triplet of <anchor, positive, negative> is important for effectively training the model, e.g., hard negatives make the model learn efficiently and effectively. However, we observe that existing methods mainly employ the most similar samples as hard negatives, which may not be true negatives. In other words, the samples with high similarity but not paired with the anchor may reserve positive semantic associations, and we call them false negatives. Repelling these false negatives in triplet loss would mislead the semantic representation learning and result in inferior retrieval performance. In this paper, we propose a novel False Negative Elimination (FNE) strategy to select negatives via sampling, which could alleviate the problem introduced by false negatives. Specifically, we first construct the distributions of positive and negative samples separat",
    "path": "papers/23/08/2308.04380.json",
    "total_tokens": 872,
    "translated_title": "你的负样本可能不是真正的负样本：通过消除错误负样本增强图像-文本匹配",
    "translated_abstract": "大多数现有的图像-文本匹配方法采用三元组损失作为优化目标，并选择适当的负样本以有效训练模型，例如，困难负样本能够使模型学习得更高效和有效。然而，我们观察到现有方法主要使用与锚点最相似的样本作为困难负样本，但这些样本可能并不是真正的负样本。换句话说，具有高相似度但没有与锚点配对的样本可能仍具有正面的语义关联，我们称之为错误负样本。在三元组损失中排除这些错误负样本会误导语义表示学习，并导致检索性能下降。本文提出了一种新颖的错误负样本消除（FNE）策略来通过抽样选择负样本，以缓解错误负样本引入的问题。具体而言，我们首先独立构造正样本和负样本的分布...",
    "tldr": "本文提出了一种新颖的False Negative Elimination（FNE）策略，通过抽样选择负样本来减轻图像-文本匹配中由错误负样本引入的问题，提高检索性能。"
}