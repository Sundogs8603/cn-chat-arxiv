{
    "title": "SALTTS: Leveraging Self-Supervised Speech Representations for improved Text-to-Speech Synthesis. (arXiv:2308.01018v1 [cs.CL])",
    "abstract": "While FastSpeech2 aims to integrate aspects of speech such as pitch, energy, and duration as conditional inputs, it still leaves scope for richer representations. As a part of this work, we leverage representations from various Self-Supervised Learning (SSL) models to enhance the quality of the synthesized speech. In particular, we pass the FastSpeech2 encoder's length-regulated outputs through a series of encoder layers with the objective of reconstructing the SSL representations. In the SALTTS-parallel implementation, the representations from this second encoder are used for an auxiliary reconstruction loss with the SSL features. The SALTTS-cascade implementation, however, passes these representations through the decoder in addition to having the reconstruction loss. The richness of speech characteristics from the SSL features reflects in the output speech quality, with the objective and subjective evaluation measures of the proposed approach outperforming the baseline FastSpeech2.",
    "link": "http://arxiv.org/abs/2308.01018",
    "context": "Title: SALTTS: Leveraging Self-Supervised Speech Representations for improved Text-to-Speech Synthesis. (arXiv:2308.01018v1 [cs.CL])\nAbstract: While FastSpeech2 aims to integrate aspects of speech such as pitch, energy, and duration as conditional inputs, it still leaves scope for richer representations. As a part of this work, we leverage representations from various Self-Supervised Learning (SSL) models to enhance the quality of the synthesized speech. In particular, we pass the FastSpeech2 encoder's length-regulated outputs through a series of encoder layers with the objective of reconstructing the SSL representations. In the SALTTS-parallel implementation, the representations from this second encoder are used for an auxiliary reconstruction loss with the SSL features. The SALTTS-cascade implementation, however, passes these representations through the decoder in addition to having the reconstruction loss. The richness of speech characteristics from the SSL features reflects in the output speech quality, with the objective and subjective evaluation measures of the proposed approach outperforming the baseline FastSpeech2.",
    "path": "papers/23/08/2308.01018.json",
    "total_tokens": 806,
    "translated_title": "SALTTS：利用自监督语音表示提升文本转语音的合成质量",
    "translated_abstract": "FastSpeech2试图将音调、能量和持续时间等语音方面的特征作为条件输入，但仍有提升空间。本文的一部分工作是利用各种自监督学习模型的表示来提高合成语音的质量。具体来说，我们将FastSpeech2编码器的长度调节输出通过一系列编码器层，用重构自监督学习表示的目标。在SALTTS-parallel实现中，来自第二个编码器的表示与自监督学习特征一起用于辅助重构损失。然而，在SALTTS-cascade的实现中，这些表示不仅通过解码器，还通过重构损失。自监督学习特征带来的语音特征的丰富性体现在输出语音的质量上，所提出的方法在客观和主观评估指标上优于基线的FastSpeech2。",
    "tldr": "本文利用自监督语音表示提升文本转语音的合成质量，通过重构自监督学习表示，辅助重构损失以及增加解码器的传递，实现了优于基线方法的语音合成。"
}