{
    "title": "Efficiency of First-Order Methods for Low-Rank Tensor Recovery with the Tensor Nuclear Norm Under Strict Complementarity. (arXiv:2308.01677v1 [math.OC])",
    "abstract": "We consider convex relaxations for recovering low-rank tensors based on constrained minimization over a ball induced by the tensor nuclear norm, recently introduced in \\cite{tensor_tSVD}. We build on a recent line of results that considered convex relaxations for the recovery of low-rank matrices and established that under a strict complementarity condition (SC), both the convergence rate and per-iteration runtime of standard gradient methods may improve dramatically. We develop the appropriate strict complementarity condition for the tensor nuclear norm ball and obtain the following main results under this condition: 1. When the objective to minimize is of the form $f(\\mX)=g(\\mA\\mX)+\\langle{\\mC,\\mX}\\rangle$ , where $g$ is strongly convex and $\\mA$ is a linear map (e.g., least squares), a quadratic growth bound holds, which implies linear convergence rates for standard projected gradient methods, despite the fact that $f$ need not be strongly convex. 2. For a smooth objective function,",
    "link": "http://arxiv.org/abs/2308.01677",
    "context": "Title: Efficiency of First-Order Methods for Low-Rank Tensor Recovery with the Tensor Nuclear Norm Under Strict Complementarity. (arXiv:2308.01677v1 [math.OC])\nAbstract: We consider convex relaxations for recovering low-rank tensors based on constrained minimization over a ball induced by the tensor nuclear norm, recently introduced in \\cite{tensor_tSVD}. We build on a recent line of results that considered convex relaxations for the recovery of low-rank matrices and established that under a strict complementarity condition (SC), both the convergence rate and per-iteration runtime of standard gradient methods may improve dramatically. We develop the appropriate strict complementarity condition for the tensor nuclear norm ball and obtain the following main results under this condition: 1. When the objective to minimize is of the form $f(\\mX)=g(\\mA\\mX)+\\langle{\\mC,\\mX}\\rangle$ , where $g$ is strongly convex and $\\mA$ is a linear map (e.g., least squares), a quadratic growth bound holds, which implies linear convergence rates for standard projected gradient methods, despite the fact that $f$ need not be strongly convex. 2. For a smooth objective function,",
    "path": "papers/23/08/2308.01677.json",
    "total_tokens": 1066,
    "translated_title": "利用张量核范数和严格互补性进行低秩张量恢复的一阶方法的效率",
    "translated_abstract": "我们考虑基于张量核范数诱导的球上的约束最小化的凸松弛方法，用于低秩张量恢复。我们借鉴了最近的一系列结果，这些结果考虑了用于恢复低秩矩阵的凸松弛方法，并且已经建立了在严格互补性条件下，标准梯度方法的收敛速度和每次迭代的运行时间可能显著提高。我们针对张量核范数球体开发了适当的严格互补性条件，并获得了以下主要结果：1. 当要最小化的目标具有形式$f(\\mX)=g(\\mA\\mX)+\\langle{\\mC,\\mX}\\rangle$，其中$g$是强凸函数，$\\mA$是一个线性映射（例如最小二乘法），存在二次增长界，这意味着标准投影梯度方法具有线性收敛速度，尽管$f$不一定是强凸的。2.对于光滑的目标函数，",
    "tldr": "本研究探讨了基于张量核范数的约束最小化方法在低秩张量恢复中的有效性，提出了适当的严格互补性条件，并且得到了在此条件下的主要结果：1.对于特定形式的目标函数，标准投影梯度方法具有线性收敛速度，尽管目标函数不一定是强凸的。2.对于光滑的目标函数，标准梯度方法的收敛速度和每次迭代的运行时间可能显著提高。"
}