{
    "title": "i-Align: an interpretable knowledge graph alignment model. (arXiv:2308.13755v1 [cs.AI])",
    "abstract": "Knowledge graphs (KGs) are becoming essential resources for many downstream applications. However, their incompleteness may limit their potential. Thus, continuous curation is needed to mitigate this problem. One of the strategies to address this problem is KG alignment, i.e., forming a more complete KG by merging two or more KGs. This paper proposes i-Align, an interpretable KG alignment model. Unlike the existing KG alignment models, i-Align provides an explanation for each alignment prediction while maintaining high alignment performance. Experts can use the explanation to check the correctness of the alignment prediction. Thus, the high quality of a KG can be maintained during the curation process (e.g., the merging process of two KGs). To this end, a novel Transformer-based Graph Encoder (Trans-GE) is proposed as a key component of i-Align for aggregating information from entities' neighbors (structures). Trans-GE uses Edge-gated Attention that combines the adjacency matrix and th",
    "link": "http://arxiv.org/abs/2308.13755",
    "context": "Title: i-Align: an interpretable knowledge graph alignment model. (arXiv:2308.13755v1 [cs.AI])\nAbstract: Knowledge graphs (KGs) are becoming essential resources for many downstream applications. However, their incompleteness may limit their potential. Thus, continuous curation is needed to mitigate this problem. One of the strategies to address this problem is KG alignment, i.e., forming a more complete KG by merging two or more KGs. This paper proposes i-Align, an interpretable KG alignment model. Unlike the existing KG alignment models, i-Align provides an explanation for each alignment prediction while maintaining high alignment performance. Experts can use the explanation to check the correctness of the alignment prediction. Thus, the high quality of a KG can be maintained during the curation process (e.g., the merging process of two KGs). To this end, a novel Transformer-based Graph Encoder (Trans-GE) is proposed as a key component of i-Align for aggregating information from entities' neighbors (structures). Trans-GE uses Edge-gated Attention that combines the adjacency matrix and th",
    "path": "papers/23/08/2308.13755.json",
    "total_tokens": 896,
    "translated_title": "i-Align: 一种可解释的知识图对齐模型",
    "translated_abstract": "知识图（KG）对于许多下游应用程序来说已经成为必不可少的资源。然而，它们的不完整性可能限制了它们的潜力。因此，需要进行连续维护来减轻这个问题。解决这个问题的策略之一是KG对齐，即通过合并两个或多个KG来形成一个更完整的KG。本文提出了一种可解释的KG对齐模型i-Align。与现有的KG对齐模型不同，i-Align在保持高对齐性能的同时为每个对齐预测提供解释。专家可以使用解释来检查对齐预测的正确性。因此，在维护过程中（例如两个KG的合并过程）可以保持KG的高质量。为此，本文提出了一种新颖的基于Transformer的图编码器（Trans-GE），作为i-Align的关键组成部分，用于聚合实体之间的邻居（结构）信息。Trans-GE使用边缘门控注意力来结合邻接矩阵和…（原文未完）",
    "tldr": "i-Align是一种可解释的知识图对齐模型，可以提供对每个对齐预测的解释，并保持高对齐性能，维护知识图的高质量。"
}