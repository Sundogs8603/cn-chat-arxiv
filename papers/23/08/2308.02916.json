{
    "title": "Adversarial Erasing with Pruned Elements: Towards Better Graph Lottery Ticket. (arXiv:2308.02916v2 [cs.LG] UPDATED)",
    "abstract": "Graph Lottery Ticket (GLT), a combination of core subgraph and sparse subnetwork, has been proposed to mitigate the computational cost of deep Graph Neural Networks (GNNs) on large input graphs while preserving original performance. However, the winning GLTs in exisiting studies are obtained by applying iterative magnitude-based pruning (IMP) without re-evaluating and re-considering the pruned information, which disregards the dynamic changes in the significance of edges/weights during graph/model structure pruning, and thus limits the appeal of the winning tickets. In this paper, we formulate a conjecture, i.e., existing overlooked valuable information in the pruned graph connections and model parameters which can be re-grouped into GLT to enhance the final performance. Specifically, we propose an adversarial complementary erasing (ACE) framework to explore the valuable information from the pruned components, thereby developing a more powerful GLT, referred to as the ACE-GLT. The main",
    "link": "http://arxiv.org/abs/2308.02916",
    "context": "Title: Adversarial Erasing with Pruned Elements: Towards Better Graph Lottery Ticket. (arXiv:2308.02916v2 [cs.LG] UPDATED)\nAbstract: Graph Lottery Ticket (GLT), a combination of core subgraph and sparse subnetwork, has been proposed to mitigate the computational cost of deep Graph Neural Networks (GNNs) on large input graphs while preserving original performance. However, the winning GLTs in exisiting studies are obtained by applying iterative magnitude-based pruning (IMP) without re-evaluating and re-considering the pruned information, which disregards the dynamic changes in the significance of edges/weights during graph/model structure pruning, and thus limits the appeal of the winning tickets. In this paper, we formulate a conjecture, i.e., existing overlooked valuable information in the pruned graph connections and model parameters which can be re-grouped into GLT to enhance the final performance. Specifically, we propose an adversarial complementary erasing (ACE) framework to explore the valuable information from the pruned components, thereby developing a more powerful GLT, referred to as the ACE-GLT. The main",
    "path": "papers/23/08/2308.02916.json",
    "total_tokens": 909,
    "translated_title": "利用修剪元素的对抗抹除：迈向更好的图彩票",
    "translated_abstract": "图彩票（GLT）是核心子图和稀疏子网络的组合，旨在减轻大型输入图上深度图神经网络（GNN）的计算成本，同时保持原始性能。然而，现有研究中获胜的GLT是通过应用迭代幅值修剪（IMP）而得到的，而无需重新评估和重新考虑修剪信息，这忽视了在图/模型结构修剪过程中边缘/权重重要性的动态变化，从而限制了获胜的彩票的吸引力。在本文中，我们提出了一个猜想，即修剪图连接和模型参数中存在被忽视的有价值信息，这些信息可以重新分组到GLT中以增强最终性能。具体而言，我们提出了一个对抗性补充抹除（ACE）框架，以从修剪组件中探索有价值的信息，从而开发出更强大的GLT，称为ACE-GLT。",
    "tldr": "本文介绍了一种利用对抗抹除的方法来增强图彩票的性能。通过重新考虑修剪信息中的有价值的信息，我们提出了ACE-GLT，这是一种更强大的图彩票方法。",
    "en_tdlr": "This paper proposes an adversarial erasing method to enhance the performance of Graph Lottery Tickets (GLTs). By re-considering valuable information in the pruned components, the authors introduce ACE-GLT as a more powerful approach for GLT."
}