{
    "title": "Diffusion-based Visual Counterfactual Explanations -- Towards Systematic Quantitative Evaluation. (arXiv:2308.06100v1 [cs.CV])",
    "abstract": "Latest methods for visual counterfactual explanations (VCE) harness the power of deep generative models to synthesize new examples of high-dimensional images of impressive quality. However, it is currently difficult to compare the performance of these VCE methods as the evaluation procedures largely vary and often boil down to visual inspection of individual examples and small scale user studies. In this work, we propose a framework for systematic, quantitative evaluation of the VCE methods and a minimal set of metrics to be used. We use this framework to explore the effects of certain crucial design choices in the latest diffusion-based generative models for VCEs of natural image classification (ImageNet). We conduct a battery of ablation-like experiments, generating thousands of VCEs for a suite of classifiers of various complexity, accuracy and robustness. Our findings suggest multiple directions for future advancements and improvements of VCE methods. By sharing our methodology and",
    "link": "http://arxiv.org/abs/2308.06100",
    "context": "Title: Diffusion-based Visual Counterfactual Explanations -- Towards Systematic Quantitative Evaluation. (arXiv:2308.06100v1 [cs.CV])\nAbstract: Latest methods for visual counterfactual explanations (VCE) harness the power of deep generative models to synthesize new examples of high-dimensional images of impressive quality. However, it is currently difficult to compare the performance of these VCE methods as the evaluation procedures largely vary and often boil down to visual inspection of individual examples and small scale user studies. In this work, we propose a framework for systematic, quantitative evaluation of the VCE methods and a minimal set of metrics to be used. We use this framework to explore the effects of certain crucial design choices in the latest diffusion-based generative models for VCEs of natural image classification (ImageNet). We conduct a battery of ablation-like experiments, generating thousands of VCEs for a suite of classifiers of various complexity, accuracy and robustness. Our findings suggest multiple directions for future advancements and improvements of VCE methods. By sharing our methodology and",
    "path": "papers/23/08/2308.06100.json",
    "total_tokens": 895,
    "translated_title": "基于扩散的视觉对抗性解释 - 实现系统性定量评估",
    "translated_abstract": "最新的视觉对抗性解释(VCE)方法利用深度生成模型的能力合成了高维图像的新示例，质量令人印象深刻。然而，目前很难比较这些VCE方法的性能，因为评估程序在很大程度上存在差异，通常仅限于对个别示例的可视化检查和小规模用户研究。在本工作中，我们提出了一个用于VCE方法系统性定量评估的框架和一套最小指标集。我们使用该框架探索了最新基于扩散的生成模型在自然图像分类（ImageNet）中VCE方法的某些关键设计选择的影响。我们进行了一系列类似削弱实验的测试，为各种复杂度、准确性和稳健性的分类器生成了数千个VCE。我们的研究结果对于未来改进VCE方法提供了多个方向。通过分享我们的方法论和",
    "tldr": "这项研究提出了一个用于对视觉对抗性解释方法进行系统性定量评估的框架，并在最新的生成模型中探索了关键设计选择的影响。研究结果为未来改进VCE方法指明了多个方向。",
    "en_tdlr": "This study proposes a framework for systematic quantitative evaluation of visual counterfactual explanations (VCE) methods and explores the effects of crucial design choices in the latest generative models. The findings provide directions for future improvements of VCE methods."
}