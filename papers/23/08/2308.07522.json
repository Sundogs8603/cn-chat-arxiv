{
    "title": "Finding Stakeholder-Material Information from 10-K Reports using Fine-Tuned BERT and LSTM Models. (arXiv:2308.07522v1 [cs.CL])",
    "abstract": "All public companies are required by federal securities law to disclose their business and financial activities in their annual 10-K reports. Each report typically spans hundreds of pages, making it difficult for human readers to identify and extract the material information efficiently. To solve the problem, I have fine-tuned BERT models and RNN models with LSTM layers to identify stakeholder-material information, defined as statements that carry information about a company's influence on its stakeholders, including customers, employees, investors, and the community and natural environment. The existing practice uses keyword search to identify such information, which is my baseline model. Using business expert-labeled training data of nearly 6,000 sentences from 62 10-K reports published in 2022, the best model has achieved an accuracy of 0.904 and an F1 score of 0.899 in test data, significantly above the baseline model's 0.781 and 0.749 respectively. Furthermore, the same work was r",
    "link": "http://arxiv.org/abs/2308.07522",
    "context": "Title: Finding Stakeholder-Material Information from 10-K Reports using Fine-Tuned BERT and LSTM Models. (arXiv:2308.07522v1 [cs.CL])\nAbstract: All public companies are required by federal securities law to disclose their business and financial activities in their annual 10-K reports. Each report typically spans hundreds of pages, making it difficult for human readers to identify and extract the material information efficiently. To solve the problem, I have fine-tuned BERT models and RNN models with LSTM layers to identify stakeholder-material information, defined as statements that carry information about a company's influence on its stakeholders, including customers, employees, investors, and the community and natural environment. The existing practice uses keyword search to identify such information, which is my baseline model. Using business expert-labeled training data of nearly 6,000 sentences from 62 10-K reports published in 2022, the best model has achieved an accuracy of 0.904 and an F1 score of 0.899 in test data, significantly above the baseline model's 0.781 and 0.749 respectively. Furthermore, the same work was r",
    "path": "papers/23/08/2308.07522.json",
    "total_tokens": 895,
    "translated_title": "使用经过优化的BERT和LSTM模型从10-K报告中找到利益相关方-材料信息",
    "translated_abstract": "所有上市公司都要按照联邦证券法的规定在年度10-K报告中披露其业务和财务活动。每份报告通常有数百页，使得人工读者很难高效地识别和提取重要信息。为了解决这个问题，我使用经过优化的BERT模型和带有LSTM层的循环神经网络模型来识别利益相关方-材料信息，即携带有关公司对其利益相关方（包括客户、员工、投资者以及社区和自然环境）影响的陈述。现有的方法使用关键词搜索来识别这种信息，这是我的基准模型。通过对2022年发布的62份10-K报告中近6000个句子进行业务专家标注的训练数据，最佳模型在测试数据中达到了0.904的准确率和0.899的F1分数，远高于基准模型的0.781和0.749。此外，相同的工作已经",
    "tldr": "本研究使用经过优化的BERT和LSTM模型，从上市公司的10-K报告中识别出利益相关方-材料信息，显著优于关键词搜索的基准模型。"
}