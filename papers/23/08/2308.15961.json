{
    "title": "Finding-Aware Anatomical Tokens for Chest X-Ray Automated Reporting. (arXiv:2308.15961v1 [cs.CV])",
    "abstract": "The task of radiology reporting comprises describing and interpreting the medical findings in radiographic images, including description of their location and appearance. Automated approaches to radiology reporting require the image to be encoded into a suitable token representation for input to the language model. Previous methods commonly use convolutional neural networks to encode an image into a series of image-level feature map representations. However, the generated reports often exhibit realistic style but imperfect accuracy. Inspired by recent works for image captioning in the general domain in which each visual token corresponds to an object detected in an image, we investigate whether using local tokens corresponding to anatomical structures can improve the quality of the generated reports. We introduce a novel adaptation of Faster R-CNN in which finding detection is performed for the candidate bounding boxes extracted during anatomical structure localisation. We use the resu",
    "link": "http://arxiv.org/abs/2308.15961",
    "context": "Title: Finding-Aware Anatomical Tokens for Chest X-Ray Automated Reporting. (arXiv:2308.15961v1 [cs.CV])\nAbstract: The task of radiology reporting comprises describing and interpreting the medical findings in radiographic images, including description of their location and appearance. Automated approaches to radiology reporting require the image to be encoded into a suitable token representation for input to the language model. Previous methods commonly use convolutional neural networks to encode an image into a series of image-level feature map representations. However, the generated reports often exhibit realistic style but imperfect accuracy. Inspired by recent works for image captioning in the general domain in which each visual token corresponds to an object detected in an image, we investigate whether using local tokens corresponding to anatomical structures can improve the quality of the generated reports. We introduce a novel adaptation of Faster R-CNN in which finding detection is performed for the candidate bounding boxes extracted during anatomical structure localisation. We use the resu",
    "path": "papers/23/08/2308.15961.json",
    "total_tokens": 900,
    "translated_title": "寻找感知胸部X光报告中的解剖标记",
    "translated_abstract": "放射学报告的任务包括描述和解释放射图像中的医学发现，包括其位置和外观的描述。自动化放射学报告需要将图像编码为适合输入语言模型的令牌表示。之前的方法通常使用卷积神经网络将图像编码为一系列图像级特征图表示。然而，生成的报告通常在逼真样式方面表现出众，但准确度不高。受最近在一般领域中用于图像字幕生成的工作的启发，其中每个视觉令牌对应于图像中检测到的对象，我们研究使用对应于解剖结构的局部令牌是否可以提高生成报告的质量。我们介绍了一种新颖的Faster R-CNN的适应性方法，在解剖结构定位期间为候选边界框执行了异常检测。我们使用了该结果作为令牌输入生成语言模型。",
    "tldr": "本研究探讨了使用对应于解剖结构的局部令牌能否改进自动放射学报告生成的质量。为此，我们引入了一种新颖的Faster R-CNN方法，并在解剖结构定位期间进行异常检测。实验结果表明，使用局部令牌可以提高生成报告的准确性和质量。",
    "en_tdlr": "This study investigates whether using local tokens corresponding to anatomical structures can improve the quality of automatically generated radiology reports. A novel adaptation of Faster R-CNN is introduced for anomaly detection during anatomical structure localization, and the results show improved accuracy and quality of the generated reports."
}