{
    "title": "Linking the Dynamic PicoProbe Analytical Electron-Optical Beam Line / Microscope to Supercomputers. (arXiv:2308.13701v1 [cs.DC])",
    "abstract": "The Dynamic PicoProbe at Argonne National Laboratory is undergoing upgrades that will enable it to produce up to 100s of GB of data per day. While this data is highly important for both fundamental science and industrial applications, there is currently limited on-site infrastructure to handle these high-volume data streams. We address this problem by providing a software architecture capable of supporting large-scale data transfers to the neighboring supercomputers at the Argonne Leadership Computing Facility. To prepare for future scientific workflows, we implement two instructive use cases for hyperspectral and spatiotemporal datasets, which include: (i) off-site data transfer, (ii) machine learning/artificial intelligence and traditional data analysis approaches, and (iii) automatic metadata extraction and cataloging of experimental results. This infrastructure supports expected workloads and also provides domain scientists the ability to reinterrogate data from past experiments to",
    "link": "http://arxiv.org/abs/2308.13701",
    "context": "Title: Linking the Dynamic PicoProbe Analytical Electron-Optical Beam Line / Microscope to Supercomputers. (arXiv:2308.13701v1 [cs.DC])\nAbstract: The Dynamic PicoProbe at Argonne National Laboratory is undergoing upgrades that will enable it to produce up to 100s of GB of data per day. While this data is highly important for both fundamental science and industrial applications, there is currently limited on-site infrastructure to handle these high-volume data streams. We address this problem by providing a software architecture capable of supporting large-scale data transfers to the neighboring supercomputers at the Argonne Leadership Computing Facility. To prepare for future scientific workflows, we implement two instructive use cases for hyperspectral and spatiotemporal datasets, which include: (i) off-site data transfer, (ii) machine learning/artificial intelligence and traditional data analysis approaches, and (iii) automatic metadata extraction and cataloging of experimental results. This infrastructure supports expected workloads and also provides domain scientists the ability to reinterrogate data from past experiments to",
    "path": "papers/23/08/2308.13701.json",
    "total_tokens": 884,
    "translated_title": "将动态PicoProbe分析电子光学束线/显微镜与超级计算机相连接",
    "translated_abstract": "动态PicoProbe正在Argonne国家实验室进行升级，将能够每天产生高达数百GB的数据。虽然这些数据对基础科学和工业应用都非常重要，但目前在场内的基础设施无法处理这些高容量的数据流。为解决这个问题，我们提供了一个能够支持大规模数据传输到Argonne领导计算设施相邻超级计算机的软件架构。为了准备未来的科学工作流，我们实施了两个示例用例，包括高光谱和时空数据集的（i）离场数据传输，（ii）机器学习/人工智能和传统数据分析方法，以及（iii）实验结果的自动元数据提取和编目。这种基础设施不仅支持预期工作负载，还使领域科学家能够重新查询过去实验的数据。",
    "tldr": "本文提出了将Dynamic PicoProbe的数据传输与Argonne领导计算设施相邻超级计算机相连接的软件架构，该架构支持大规模数据传输和离线数据分析，为科学家提供了查询和重新分析过去实验数据的能力。",
    "en_tdlr": "This paper presents a software architecture that connects the data transfer of Dynamic PicoProbe to neighboring supercomputers at the Argonne Leadership Computing Facility, enabling large-scale data transfer and offline data analysis, providing scientists with the capability to query and re-analyze past experimental data."
}