{
    "title": "SEA: Shareable and Explainable Attribution for Query-based Black-box Attacks. (arXiv:2308.11845v1 [cs.LG])",
    "abstract": "Machine Learning (ML) systems are vulnerable to adversarial examples, particularly those from query-based black-box attacks. Despite various efforts to detect and prevent such attacks, there is a need for a more comprehensive approach to logging, analyzing, and sharing evidence of attacks. While classic security benefits from well-established forensics and intelligence sharing, Machine Learning is yet to find a way to profile its attackers and share information about them. In response, this paper introduces SEA, a novel ML security system to characterize black-box attacks on ML systems for forensic purposes and to facilitate human-explainable intelligence sharing. SEA leverages the Hidden Markov Models framework to attribute the observed query sequence to known attacks. It thus understands the attack's progression rather than just focusing on the final adversarial examples. Our evaluations reveal that SEA is effective at attack attribution, even on their second occurrence, and is robus",
    "link": "http://arxiv.org/abs/2308.11845",
    "context": "Title: SEA: Shareable and Explainable Attribution for Query-based Black-box Attacks. (arXiv:2308.11845v1 [cs.LG])\nAbstract: Machine Learning (ML) systems are vulnerable to adversarial examples, particularly those from query-based black-box attacks. Despite various efforts to detect and prevent such attacks, there is a need for a more comprehensive approach to logging, analyzing, and sharing evidence of attacks. While classic security benefits from well-established forensics and intelligence sharing, Machine Learning is yet to find a way to profile its attackers and share information about them. In response, this paper introduces SEA, a novel ML security system to characterize black-box attacks on ML systems for forensic purposes and to facilitate human-explainable intelligence sharing. SEA leverages the Hidden Markov Models framework to attribute the observed query sequence to known attacks. It thus understands the attack's progression rather than just focusing on the final adversarial examples. Our evaluations reveal that SEA is effective at attack attribution, even on their second occurrence, and is robus",
    "path": "papers/23/08/2308.11845.json",
    "total_tokens": 975,
    "translated_title": "SEA：可共享和可解释的基于查询的黑盒攻击归因",
    "translated_abstract": "机器学习系统容易受到来自基于查询的黑盒攻击的敌对样本的攻击。尽管有各种努力来检测和防止这些攻击，但仍然需要一种更全面的方法来记录、分析和分享攻击证据。虽然经典安全领域受益于成熟的取证和情报共享技术，但机器学习领域尚未找到一种方式来对攻击者进行画像，并分享关于他们的信息。为此，本论文引入了SEA，一种新颖的机器学习安全系统，用于为取证目的表征对机器学习系统的黑盒攻击，并促进可解释的情报共享。SEA利用隐藏马尔可夫模型框架将观察到的查询序列归因于已知的攻击，因此它能够理解攻击的演变过程而不仅仅关注最终的敌对样本。我们的评估结果显示，SEA能够有效进行攻击归因，即使是对于第二次出现的攻击，也具有鲁棒性。",
    "tldr": "本论文提出了SEA，一种用于归因基于查询的黑盒攻击的机器学习安全系统，通过利用隐藏马尔可夫模型框架来理解攻击的演变过程，并有效归因攻击，即使是对于第二次出现的攻击，具有鲁棒性，旨在实现取证和人类可解释的情报共享。",
    "en_tdlr": "This paper introduces SEA, a machine learning security system for attributing query-based black-box attacks. By using the Hidden Markov Models framework to understand the progression of attacks, SEA is able to effectively attribute attacks, even on their second occurrence, and aims to achieve forensic purposes and human-explainable intelligence sharing"
}