{
    "title": "Temporal DINO: A Self-supervised Video Strategy to Enhance Action Prediction. (arXiv:2308.04589v1 [cs.CV])",
    "abstract": "The emerging field of action prediction plays a vital role in various computer vision applications such as autonomous driving, activity analysis and human-computer interaction. Despite significant advancements, accurately predicting future actions remains a challenging problem due to high dimensionality, complex dynamics and uncertainties inherent in video data. Traditional supervised approaches require large amounts of labelled data, which is expensive and time-consuming to obtain. This paper introduces a novel self-supervised video strategy for enhancing action prediction inspired by DINO (self-distillation with no labels). The Temporal-DINO approach employs two models; a 'student' processing past frames; and a 'teacher' processing both past and future frames, enabling a broader temporal context. During training, the teacher guides the student to learn future context by only observing past frames. The strategy is evaluated on ROAD dataset for the action prediction downstream task usi",
    "link": "http://arxiv.org/abs/2308.04589",
    "context": "Title: Temporal DINO: A Self-supervised Video Strategy to Enhance Action Prediction. (arXiv:2308.04589v1 [cs.CV])\nAbstract: The emerging field of action prediction plays a vital role in various computer vision applications such as autonomous driving, activity analysis and human-computer interaction. Despite significant advancements, accurately predicting future actions remains a challenging problem due to high dimensionality, complex dynamics and uncertainties inherent in video data. Traditional supervised approaches require large amounts of labelled data, which is expensive and time-consuming to obtain. This paper introduces a novel self-supervised video strategy for enhancing action prediction inspired by DINO (self-distillation with no labels). The Temporal-DINO approach employs two models; a 'student' processing past frames; and a 'teacher' processing both past and future frames, enabling a broader temporal context. During training, the teacher guides the student to learn future context by only observing past frames. The strategy is evaluated on ROAD dataset for the action prediction downstream task usi",
    "path": "papers/23/08/2308.04589.json",
    "total_tokens": 927,
    "translated_title": "Temporal DINO:一种增强动作预测的自监督视频策略",
    "translated_abstract": "行动预测的新兴领域在各种计算机视觉应用中起着重要作用，如自动驾驶、活动分析和人机交互。尽管有重大进展，但由于视频数据中固有的高维度、复杂动态和不确定性，准确预测未来动作仍然是一个具有挑战性的问题。传统的监督方法需要大量的标记数据，而获取这些数据既昂贵又耗时。本文介绍了一种受DINO（无标签的自蒸馏）启发的增强动作预测的新型自监督视频策略，称为Temporal-DINO。该策略使用两个模型：一个“学生”处理过去的帧，一个“教师”同时处理过去和未来的帧，从而实现更广泛的时间上下文。在训练过程中，教师通过仅观察过去的帧来指导学生学习未来的上下文。该策略在ROAD数据集上进行了行动预测下游任务的评估。",
    "tldr": "Temporal DINO是一种自监督视频策略，通过引入一个学生模型和一个教师模型，使得学生模型能够通过观察过去帧来学习未来帧的上下文，以增强动作预测。这种方法在行动预测任务上在ROAD数据集上进行了评估。",
    "en_tdlr": "Temporal DINO is a self-supervised video strategy that enhances action prediction by introducing a student model and a teacher model, enabling the student model to learn the future context by observing past frames. This approach is evaluated on the ROAD dataset for the action prediction task."
}