{
    "title": "Everything Perturbed All at Once: Enabling Differentiable Graph Attacks. (arXiv:2308.15614v1 [cs.LG])",
    "abstract": "As powerful tools for representation learning on graphs, graph neural networks (GNNs) have played an important role in applications including social networks, recommendation systems, and online web services. However, GNNs have been shown to be vulnerable to adversarial attacks, which can significantly degrade their effectiveness. Recent state-of-the-art approaches in adversarial attacks rely on gradient-based meta-learning to selectively perturb a single edge with the highest attack score until they reach the budget constraint. While effective in identifying vulnerable links, these methods are plagued by high computational costs. By leveraging continuous relaxation and parameterization of the graph structure, we propose a novel attack method called Differentiable Graph Attack (DGA) to efficiently generate effective attacks and meanwhile eliminate the need for costly retraining. Compared to the state-of-the-art, DGA achieves nearly equivalent attack performance with 6 times less trainin",
    "link": "http://arxiv.org/abs/2308.15614",
    "context": "Title: Everything Perturbed All at Once: Enabling Differentiable Graph Attacks. (arXiv:2308.15614v1 [cs.LG])\nAbstract: As powerful tools for representation learning on graphs, graph neural networks (GNNs) have played an important role in applications including social networks, recommendation systems, and online web services. However, GNNs have been shown to be vulnerable to adversarial attacks, which can significantly degrade their effectiveness. Recent state-of-the-art approaches in adversarial attacks rely on gradient-based meta-learning to selectively perturb a single edge with the highest attack score until they reach the budget constraint. While effective in identifying vulnerable links, these methods are plagued by high computational costs. By leveraging continuous relaxation and parameterization of the graph structure, we propose a novel attack method called Differentiable Graph Attack (DGA) to efficiently generate effective attacks and meanwhile eliminate the need for costly retraining. Compared to the state-of-the-art, DGA achieves nearly equivalent attack performance with 6 times less trainin",
    "path": "papers/23/08/2308.15614.json",
    "total_tokens": 910,
    "translated_title": "所有东西同时受扰：实现可微分的图攻击",
    "translated_abstract": "作为图表示学习的强大工具，图神经网络（GNN）在社交网络、推荐系统和在线网络服务等应用中发挥着重要作用。然而，GNN对于对抗性攻击具有脆弱性，这会显著降低其效果。最近的对抗性攻击方法借助基于梯度的元学习选取攻击得分最高的单个边进行干扰，直到达到预算限制。虽然能够有效找出易受攻击的连接，但这些方法计算成本高。通过利用连续松弛和参数化图结构，我们提出了一种称为可微分图攻击（DGA）的新攻击方法，可以有效地生成攻击，并同时消除了昂贵的重新训练过程。与最先进的方法相比，DGA在训练成本减少了6倍的情况下实现了几乎相当的攻击性能。",
    "tldr": "提出了一种称为可微分图攻击（DGA）的新攻击方法，在连续松弛和参数化图结构的基础上，通过有效生成攻击的同时消除了昂贵的重新训练过程，与最先进的方法相比具有几乎相当的攻击性能，但训练成本减少6倍。",
    "en_tdlr": "A novel attack method called Differentiable Graph Attack (DGA) is proposed, which effectively generates attacks while eliminating the need for costly retraining by leveraging continuous relaxation and parameterization of the graph structure. Compared to the state-of-the-art, DGA achieves nearly equivalent attack performance with 6 times less training cost."
}