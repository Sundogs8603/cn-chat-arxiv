{
    "title": "A Drop of Ink Makes a Million Think: The Spread of False Information in Large Language Models. (arXiv:2305.04812v2 [cs.CL] UPDATED)",
    "abstract": "Large language models (LLMs) have gained increasing prominence in artificial intelligence, making a profound impact on society and various industries like business and science. However, the presence of false information on the internet and in text corpus poses a significant risk to the reliability and safety of LLMs, underscoring the urgent need to understand the mechanisms of how false information influences the behaviors of LLMs. In this paper, we dive into this problem and investigate how false information spreads in LLMs and affects related responses. Specifically, in our series of experiments, we investigate different factors that can influence the spread of information in LLMs by comparing three degrees of information relevance (direct, indirect, and peripheral), four information source styles (Twitter, web blogs, news reports, and research papers) and two common knowledge injection paradigms (in-context injection and learning-based injection). The experimental results show that ",
    "link": "http://arxiv.org/abs/2305.04812",
    "context": "Title: A Drop of Ink Makes a Million Think: The Spread of False Information in Large Language Models. (arXiv:2305.04812v2 [cs.CL] UPDATED)\nAbstract: Large language models (LLMs) have gained increasing prominence in artificial intelligence, making a profound impact on society and various industries like business and science. However, the presence of false information on the internet and in text corpus poses a significant risk to the reliability and safety of LLMs, underscoring the urgent need to understand the mechanisms of how false information influences the behaviors of LLMs. In this paper, we dive into this problem and investigate how false information spreads in LLMs and affects related responses. Specifically, in our series of experiments, we investigate different factors that can influence the spread of information in LLMs by comparing three degrees of information relevance (direct, indirect, and peripheral), four information source styles (Twitter, web blogs, news reports, and research papers) and two common knowledge injection paradigms (in-context injection and learning-based injection). The experimental results show that ",
    "path": "papers/23/05/2305.04812.json",
    "total_tokens": 882,
    "tldr": "本文研究了虚假信息在LLM中的传播方式及其影响，通过比较不同信息相关性程度和来源风格，以及不同的知识注入范式，揭示了虚假信息如何影响LLM行为的机制。"
}