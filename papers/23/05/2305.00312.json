{
    "title": "Optimizing Privacy, Utility and Efficiency in Constrained Multi-Objective Federated Learning. (arXiv:2305.00312v1 [cs.LG])",
    "abstract": "Conventionally, federated learning aims to optimize a single objective, typically the utility. However, for a federated learning system to be trustworthy, it needs to simultaneously satisfy multiple/many objectives, such as maximizing model performance, minimizing privacy leakage and training cost, and being robust to malicious attacks. Multi-Objective Optimization (MOO) aiming to optimize multiple conflicting objectives at the same time is quite suitable for solving the optimization problem of Trustworthy Federated Learning (TFL). In this paper, we unify MOO and TFL by formulating the problem of constrained multi-objective federated learning (CMOFL). Under this formulation, existing MOO algorithms can be adapted to TFL straightforwardly. Different from existing CMOFL works focusing on utility, efficiency, fairness, and robustness, we consider optimizing privacy leakage along with utility loss and training cost, the three primary objectives of a TFL system. We develop two improved CMOF",
    "link": "http://arxiv.org/abs/2305.00312",
    "context": "Title: Optimizing Privacy, Utility and Efficiency in Constrained Multi-Objective Federated Learning. (arXiv:2305.00312v1 [cs.LG])\nAbstract: Conventionally, federated learning aims to optimize a single objective, typically the utility. However, for a federated learning system to be trustworthy, it needs to simultaneously satisfy multiple/many objectives, such as maximizing model performance, minimizing privacy leakage and training cost, and being robust to malicious attacks. Multi-Objective Optimization (MOO) aiming to optimize multiple conflicting objectives at the same time is quite suitable for solving the optimization problem of Trustworthy Federated Learning (TFL). In this paper, we unify MOO and TFL by formulating the problem of constrained multi-objective federated learning (CMOFL). Under this formulation, existing MOO algorithms can be adapted to TFL straightforwardly. Different from existing CMOFL works focusing on utility, efficiency, fairness, and robustness, we consider optimizing privacy leakage along with utility loss and training cost, the three primary objectives of a TFL system. We develop two improved CMOF",
    "path": "papers/23/05/2305.00312.json",
    "total_tokens": 1091,
    "translated_title": "在有限制的多目标联邦学习中优化隐私、效用和效率",
    "translated_abstract": "传统上，联邦学习旨在优化单个目标，通常是效用。然而，为了使联邦学习系统值得信赖，它需要同时满足多个/多个目标，例如最大化模型性能、最小化隐私泄露和训练成本，并对恶意攻击具有鲁棒性。多目标优化（MOO）旨在同时优化多个相互冲突的目标，非常适合解决值得信赖的联合学习（TFL）的优化问题。在本文中，我们将MOO和TFL统一起来，通过制定约束的多目标联合学习（CMOFL）问题来解决此问题。在这种制定下，现有的MOO算法可以直接适用于TFL。不同于现有的CMOFL作品专注于效用、效率、公平性和鲁棒性，我们考虑优化隐私泄露以及效用损失和训练成本，这是TFL系统的三个主要目标之一。我们开发了两种改进的CMOFL算法，它们返回一组平衡良好的模型，满足隐私、效用和效率。基于两个真实世界的数据集的实验表明，我们的方法在隐私、效用和效率之间的权衡方面优于现有方法。",
    "tldr": "该论文提供了一种在有限制的多目标联邦学习中优化隐私、效用和效率的方法，开发了两种改进的算法来解决隐私泄露、效用损失和训练成本等三个主要目标，并在两个真实世界的数据集上进行了实验验证，优于现有方法。",
    "en_tdlr": "This paper proposes a method to optimize privacy, utility and efficiency in constrained multi-objective federated learning, and develops two improved algorithms to solve the three primary objectives of a TFL system, including privacy leakage, utility loss and training cost, outperforming existing methods in experiments on two real-world datasets."
}