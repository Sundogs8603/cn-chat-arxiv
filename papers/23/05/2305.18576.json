{
    "title": "TreeMAN: Tree-enhanced Multimodal Attention Network for ICD Coding. (arXiv:2305.18576v1 [cs.CL])",
    "abstract": "ICD coding is designed to assign the disease codes to electronic health records (EHRs) upon discharge, which is crucial for billing and clinical statistics. In an attempt to improve the effectiveness and efficiency of manual coding, many methods have been proposed to automatically predict ICD codes from clinical notes. However, most previous works ignore the decisive information contained in structured medical data in EHRs, which is hard to be captured from the noisy clinical notes. In this paper, we propose a Tree-enhanced Multimodal Attention Network (TreeMAN) to fuse tabular features and textual features into multimodal representations by enhancing the text representations with tree-based features via the attention mechanism. Tree-based features are constructed according to decision trees learned from structured multimodal medical data, which capture the decisive information about ICD coding. We can apply the same multi-label classifier from previous text models to the multimodal re",
    "link": "http://arxiv.org/abs/2305.18576",
    "context": "Title: TreeMAN: Tree-enhanced Multimodal Attention Network for ICD Coding. (arXiv:2305.18576v1 [cs.CL])\nAbstract: ICD coding is designed to assign the disease codes to electronic health records (EHRs) upon discharge, which is crucial for billing and clinical statistics. In an attempt to improve the effectiveness and efficiency of manual coding, many methods have been proposed to automatically predict ICD codes from clinical notes. However, most previous works ignore the decisive information contained in structured medical data in EHRs, which is hard to be captured from the noisy clinical notes. In this paper, we propose a Tree-enhanced Multimodal Attention Network (TreeMAN) to fuse tabular features and textual features into multimodal representations by enhancing the text representations with tree-based features via the attention mechanism. Tree-based features are constructed according to decision trees learned from structured multimodal medical data, which capture the decisive information about ICD coding. We can apply the same multi-label classifier from previous text models to the multimodal re",
    "path": "papers/23/05/2305.18576.json",
    "total_tokens": 893,
    "translated_title": "TreeMAN：基于树增强的多模态注意力网络用于ICD编码",
    "translated_abstract": "ICD编码旨在为出院后的电子健康记录分配疾病代码，这对账单和临床统计非常重要。为了提高手动编码的效率和准确性，许多方法已被提出来自动从临床记录中预测ICD代码。然而，大多数之前的工作忽略了包含在EHR中的结构化医疗数据中的重要信息，这些信息很难从嘈杂的临床记录中捕获。在本文中，我们提出了一种Tree-enhanced Multimodal Attention Network(TreeMAN)，通过使用注意力机制，将表格特征和文本特征融合为多模态表示，并借助基于树的特征增强文本表示。基于树的特征是根据从结构化多模态医疗数据中学习的决策树构建的，它们捕捉关于ICD编码的重要信息。我们可以将先前文本模型中的相同多标签分类器应用于多模态表示。",
    "tldr": "提出了TreeMAN模型，该模型通过使用基于树的特征增强文本表示，将表格特征和文本特征融合为多模态表示以更准确地预测ICD代码。",
    "en_tdlr": "A Tree-enhanced Multimodal Attention Network (TreeMAN) model is proposed to improve the accuracy of ICD code prediction by fusing tabular and textual features into multimodal representations via an attention mechanism and enhancing the text representations with tree-based features learned from structured multimodal medical data."
}