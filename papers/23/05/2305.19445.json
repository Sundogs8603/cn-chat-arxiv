{
    "title": "A Computational Account Of Self-Supervised Visual Learning From Egocentric Object Play. (arXiv:2305.19445v1 [cs.CV])",
    "abstract": "Research in child development has shown that embodied experience handling physical objects contributes to many cognitive abilities, including visual learning. One characteristic of such experience is that the learner sees the same object from several different viewpoints. In this paper, we study how learning signals that equate different viewpoints -- e.g., assigning similar representations to different views of a single object -- can support robust visual learning. We use the Toybox dataset, which contains egocentric videos of humans manipulating different objects, and conduct experiments using a computer vision framework for self-supervised contrastive learning. We find that representations learned by equating different physical viewpoints of an object benefit downstream image classification accuracy. Further experiments show that this performance improvement is robust to variations in the gaps between viewpoints, and that the benefits transfer to several different image classificati",
    "link": "http://arxiv.org/abs/2305.19445",
    "context": "Title: A Computational Account Of Self-Supervised Visual Learning From Egocentric Object Play. (arXiv:2305.19445v1 [cs.CV])\nAbstract: Research in child development has shown that embodied experience handling physical objects contributes to many cognitive abilities, including visual learning. One characteristic of such experience is that the learner sees the same object from several different viewpoints. In this paper, we study how learning signals that equate different viewpoints -- e.g., assigning similar representations to different views of a single object -- can support robust visual learning. We use the Toybox dataset, which contains egocentric videos of humans manipulating different objects, and conduct experiments using a computer vision framework for self-supervised contrastive learning. We find that representations learned by equating different physical viewpoints of an object benefit downstream image classification accuracy. Further experiments show that this performance improvement is robust to variations in the gaps between viewpoints, and that the benefits transfer to several different image classificati",
    "path": "papers/23/05/2305.19445.json",
    "total_tokens": 835,
    "translated_title": "来自自我本体对象游戏的自监督视觉学习的计算机模型",
    "translated_abstract": "儿童发展研究表明，处理物理对象的体验对许多认知能力，包括视觉学习，有益。这种体验的一个特征是学习者从几个不同的视角看同一对象。本文研究了如何利用等同不同视角的学习信号 -- 例如将单个对象的不同视图分配相似的表示 -- 支持强大的视觉学习。我们使用了Toybox数据集，其中包含人类操作不同对象的自我中心视频，并使用计算机视觉框架进行自我监督对比学习实验。我们发现，通过等同一个对象的不同物理视角学习得到的表示有助于下游图像分类精度的提高。进一步的实验表明，这种性能提高对视角之间的差异的变化具有鲁棒性，并且这种益处能够转化到多种不同的图像分类任务中。",
    "tldr": "本文研究了如何利用等同不同视角的学习信号支持视觉学习，并发现通过等同一个对象的不同视角学习得到的表示可以提高下游图像分类精度。",
    "en_tdlr": "This paper studies how learning signals that equate different viewpoints can support visual learning, and finds that representations learned by equating different physical viewpoints of an object can improve downstream image classification accuracy."
}