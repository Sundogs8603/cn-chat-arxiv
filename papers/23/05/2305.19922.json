{
    "title": "Representation-Driven Reinforcement Learning. (arXiv:2305.19922v2 [cs.LG] UPDATED)",
    "abstract": "We present a representation-driven framework for reinforcement learning. By representing policies as estimates of their expected values, we leverage techniques from contextual bandits to guide exploration and exploitation. Particularly, embedding a policy network into a linear feature space allows us to reframe the exploration-exploitation problem as a representation-exploitation problem, where good policy representations enable optimal exploration. We demonstrate the effectiveness of this framework through its application to evolutionary and policy gradient-based approaches, leading to significantly improved performance compared to traditional methods. Our framework provides a new perspective on reinforcement learning, highlighting the importance of policy representation in determining optimal exploration-exploitation strategies.",
    "link": "http://arxiv.org/abs/2305.19922",
    "context": "Title: Representation-Driven Reinforcement Learning. (arXiv:2305.19922v2 [cs.LG] UPDATED)\nAbstract: We present a representation-driven framework for reinforcement learning. By representing policies as estimates of their expected values, we leverage techniques from contextual bandits to guide exploration and exploitation. Particularly, embedding a policy network into a linear feature space allows us to reframe the exploration-exploitation problem as a representation-exploitation problem, where good policy representations enable optimal exploration. We demonstrate the effectiveness of this framework through its application to evolutionary and policy gradient-based approaches, leading to significantly improved performance compared to traditional methods. Our framework provides a new perspective on reinforcement learning, highlighting the importance of policy representation in determining optimal exploration-exploitation strategies.",
    "path": "papers/23/05/2305.19922.json",
    "total_tokens": 818,
    "translated_title": "表示驱动的强化学习框架",
    "translated_abstract": "我们提出了一个表示驱动的强化学习框架。通过将策略表示为其期望值的估计，我们利用来自情境推断的方法来指导探索和利用。特别地，将策略网络嵌入到线性特征空间中，使我们能够将探索-利用问题重新框定为表示-利用问题，其中良好的策略表示能够实现最佳的探索。我们通过应用进化和策略梯度法来展示该框架的有效性，相比于传统方法，这些方法带来了显著的性能提升。我们的框架提供了一种强化学习的新视角，强调了策略表示在决定最佳探索-利用策略方面的重要性。",
    "tldr": "该论文提出了一个表示驱动的强化学习框架，通过在线性特征空间中嵌入策略网络，重新框定探索-利用问题为表示-利用问题，以实现最佳的探索。该框架通过应用进化和策略梯度法取得了显著的性能提升。",
    "en_tdlr": "This paper proposes a representation-driven framework for reinforcement learning, which reframes the exploration-exploitation problem as a representation-exploitation problem by embedding a policy network into a linear feature space. The effectiveness of this framework is demonstrated through its application to evolutionary and policy gradient-based approaches, leading to significantly improved performance compared to traditional methods."
}