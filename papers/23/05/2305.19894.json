{
    "title": "Med-UniC: Unifying Cross-Lingual Medical Vision-Language Pre-Training by Diminishing Bias. (arXiv:2305.19894v2 [cs.CL] UPDATED)",
    "abstract": "The scarcity of data presents a critical obstacle to the efficacy of medical visionlanguage pre-training (VLP). A potential solution lies in the combination of datasets from various language communities. Nevertheless, the main challenge stems from the complexity of integrating diverse syntax and semantics, language-specific medical terminology, and culture-specific implicit knowledge. Therefore, one crucial aspect to consider is the presence of community bias caused by different languages. This paper presents a novel framework named Unifying Cross-Lingual Medical Vision-Language Pre-Training (Med-UniC), designed to integrate multimodal medical data from the two most prevalent languages, English and Spanish. Specifically, we propose Cross-lingual Text Alignment Regularization (CTR) to explicitly unify cross-lingual semantic representations of medical reports originating from diverse language communities. CTR is optimized through latent language disentanglement, rendering our optimizatio",
    "link": "http://arxiv.org/abs/2305.19894",
    "context": "Title: Med-UniC: Unifying Cross-Lingual Medical Vision-Language Pre-Training by Diminishing Bias. (arXiv:2305.19894v2 [cs.CL] UPDATED)\nAbstract: The scarcity of data presents a critical obstacle to the efficacy of medical visionlanguage pre-training (VLP). A potential solution lies in the combination of datasets from various language communities. Nevertheless, the main challenge stems from the complexity of integrating diverse syntax and semantics, language-specific medical terminology, and culture-specific implicit knowledge. Therefore, one crucial aspect to consider is the presence of community bias caused by different languages. This paper presents a novel framework named Unifying Cross-Lingual Medical Vision-Language Pre-Training (Med-UniC), designed to integrate multimodal medical data from the two most prevalent languages, English and Spanish. Specifically, we propose Cross-lingual Text Alignment Regularization (CTR) to explicitly unify cross-lingual semantic representations of medical reports originating from diverse language communities. CTR is optimized through latent language disentanglement, rendering our optimizatio",
    "path": "papers/23/05/2305.19894.json",
    "total_tokens": 945,
    "translated_title": "Med-UniC：通过减少偏见实现跨语言医学图像-语言预训练的统一",
    "translated_abstract": "数据稀缺性对医学图像-语言预训练(VLP)的效果造成了严重障碍。解决方案可能在于结合来自各种语言社区的数据集。然而，主要挑战来自于整合不同的语法和语义、特定于语言的医学术语以及特定于文化的隐式知识的复杂性。因此，一个关键的考虑因素是由不同语言引起的社区偏见的存在。本文介绍了一种名为统一跨语言医学图像-语言预训练(Med-UniC)的新框架，旨在整合来自两种最常见语言的多模态医学数据，即英语和西班牙语。具体而言，我们提出了跨语言文本对齐规则(CTR)，明确统一来自不同语言社区的医学报告的跨语言语义表示。通过潜在语言解缠，优化CTR，使我们的优化成果。",
    "tldr": "Med-UniC是一个新的框架，旨在通过整合英语和西班牙语的跨语言医学数据，实现跨语言医学图像-语言预训练的统一。他们提出了跨语言文本对齐规则(CTR)，以明确统一来自不同语言社区的医学报告的跨语言语义表示。"
}