{
    "title": "Phonetic and Prosody-aware Self-supervised Learning Approach for Non-native Fluency Scoring. (arXiv:2305.11438v1 [cs.CL])",
    "abstract": "Speech fluency/disfluency can be evaluated by analyzing a range of phonetic and prosodic features. Deep neural networks are commonly trained to map fluency-related features into the human scores. However, the effectiveness of deep learning-based models is constrained by the limited amount of labeled training samples. To address this, we introduce a self-supervised learning (SSL) approach that takes into account phonetic and prosody awareness for fluency scoring. Specifically, we first pre-train the model using a reconstruction loss function, by masking phones and their durations jointly on a large amount of unlabeled speech and text prompts. We then fine-tune the pre-trained model using human-annotated scoring data. Our experimental results, conducted on datasets such as Speechocean762 and our non-native datasets, show that our proposed method outperforms the baseline systems in terms of Pearson correlation coefficients (PCC). Moreover, we also conduct an ablation study to better under",
    "link": "http://arxiv.org/abs/2305.11438",
    "context": "Title: Phonetic and Prosody-aware Self-supervised Learning Approach for Non-native Fluency Scoring. (arXiv:2305.11438v1 [cs.CL])\nAbstract: Speech fluency/disfluency can be evaluated by analyzing a range of phonetic and prosodic features. Deep neural networks are commonly trained to map fluency-related features into the human scores. However, the effectiveness of deep learning-based models is constrained by the limited amount of labeled training samples. To address this, we introduce a self-supervised learning (SSL) approach that takes into account phonetic and prosody awareness for fluency scoring. Specifically, we first pre-train the model using a reconstruction loss function, by masking phones and their durations jointly on a large amount of unlabeled speech and text prompts. We then fine-tune the pre-trained model using human-annotated scoring data. Our experimental results, conducted on datasets such as Speechocean762 and our non-native datasets, show that our proposed method outperforms the baseline systems in terms of Pearson correlation coefficients (PCC). Moreover, we also conduct an ablation study to better under",
    "path": "papers/23/05/2305.11438.json",
    "total_tokens": 1007,
    "translated_title": "基于音韵和韵律感知的自监督学习方法在非母语流畅度评分中的应用",
    "translated_abstract": "通过分析一系列的音韵和韵律特征，可以评估说话的流畅度/不流畅度。深度神经网络通常用于将与流畅度相关的特征映射到人类评分中。然而，深度学习模型的有效性受到标记训练样本数量的限制。为了解决这个问题，我们引入了一个基于自监督学习 (SSL) 的方法，考虑了对于流畅度评分而言的音韵和韵律感知。具体而言，我们首先使用一个重建损失函数在大量未标记的语音和文本提示上联合屏蔽音素及其持续时间来预训练模型。然后，我们使用人工注释的评分数据对预训练模型进行微调。我们的实验结果，在Speechocean762等数据集上进行，显示出我们的方法在Pearson相关系数（PCC）方面优于基线系统。此外，我们还进行了消融研究，以更好地了解我们方法的作用及效果。",
    "tldr": "本论文提出了一个基于音韵和韵律感知的自监督学习方法，用于非母语流畅度评分。通过在大量未标记的语音和文本提示上预训练模型，然后使用人工注释的评分数据进行微调，该方法在Pearson相关系数（PCC）方面优于基线系统。",
    "en_tdlr": "This paper proposes a self-supervised learning approach based on phonetic and prosodic awareness for non-native fluency scoring. By pre-training the model on a large amount of unlabeled speech and text prompts using a reconstruction loss function, and then fine-tuning it with human-annotated scoring data, the proposed method outperforms baseline systems in terms of Pearson correlation coefficients (PCC) according to experiments conducted on datasets such as Speechocean762 and non-native datasets."
}