{
    "title": "BASEN: Time-Domain Brain-Assisted Speech Enhancement Network with Convolutional Cross Attention in Multi-talker Conditions. (arXiv:2305.09994v1 [eess.AS])",
    "abstract": "Time-domain single-channel speech enhancement (SE) still remains challenging to extract the target speaker without any prior information on multi-talker conditions. It has been shown via auditory attention decoding that the brain activity of the listener contains the auditory information of the attended speaker. In this paper, we thus propose a novel time-domain brain-assisted SE network (BASEN) incorporating electroencephalography (EEG) signals recorded from the listener for extracting the target speaker from monaural speech mixtures. The proposed BASEN is based on the fully-convolutional time-domain audio separation network. In order to fully leverage the complementary information contained in the EEG signals, we further propose a convolutional multi-layer cross attention module to fuse the dual-branch features. Experimental results on a public dataset show that the proposed model outperforms the state-of-the-art method in several evaluation metrics. The reproducible code is availabl",
    "link": "http://arxiv.org/abs/2305.09994",
    "context": "Title: BASEN: Time-Domain Brain-Assisted Speech Enhancement Network with Convolutional Cross Attention in Multi-talker Conditions. (arXiv:2305.09994v1 [eess.AS])\nAbstract: Time-domain single-channel speech enhancement (SE) still remains challenging to extract the target speaker without any prior information on multi-talker conditions. It has been shown via auditory attention decoding that the brain activity of the listener contains the auditory information of the attended speaker. In this paper, we thus propose a novel time-domain brain-assisted SE network (BASEN) incorporating electroencephalography (EEG) signals recorded from the listener for extracting the target speaker from monaural speech mixtures. The proposed BASEN is based on the fully-convolutional time-domain audio separation network. In order to fully leverage the complementary information contained in the EEG signals, we further propose a convolutional multi-layer cross attention module to fuse the dual-branch features. Experimental results on a public dataset show that the proposed model outperforms the state-of-the-art method in several evaluation metrics. The reproducible code is availabl",
    "path": "papers/23/05/2305.09994.json",
    "total_tokens": 919,
    "translated_title": "采用跨通道卷积交叉注意力的基于时间域脑波辅助的语音增强网络",
    "translated_abstract": "在多说话人的情况下，时间域单通道语音增强（SE）仍然难以提取目标发言者而不具备任何先前的信息。通过听觉关注解码已经表明，听者的大脑活动包含了所关注说话者的听觉信息。因此，本文提出了一种新的基于时间域脑波辅助的SE网络（BASEN），该网络包含从听者记录的脑电图（EEG）信号，可以从单声道语音混合物中提取目标说话者。所提出的BASEN基于全卷积时间域音频分离网络。为了充分利用脑电图信号中包含的互补信息，我们进一步提出了一个卷积多层交叉注意模块，以融合双分支特征。在公共数据集上的实验结果表明，所提出的模型在多个评估度量上优于最先进的方法。代码在接受后可用。",
    "tldr": "本文提出了一种基于听者脑电图信号的语音增强网络，可以在多说话人的情况下提取目标发言者，实验结果表明其优于最先进的方法。",
    "en_tdlr": "A time-domain brain-assisted speech enhancement network (BASEN) is proposed in this paper, which incorporates electroencephalography (EEG) signals recorded from the listener to extract the target speaker from monaural speech mixtures. The proposed model outperforms the state-of-the-art method in several evaluation metrics on a public dataset."
}