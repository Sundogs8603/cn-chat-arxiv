{
    "title": "CAR: Conceptualization-Augmented Reasoner for Zero-Shot Commonsense Question Answering. (arXiv:2305.14869v2 [cs.CL] UPDATED)",
    "abstract": "The task of zero-shot commonsense question answering evaluates models on their capacity to reason about general scenarios beyond those presented in specific datasets. Existing approaches for tackling this task leverage external knowledge from CommonSense Knowledge Bases (CSKBs) by pretraining the model on synthetic QA pairs constructed from CSKBs. In these approaches, negative examples (distractors) are formulated by randomly sampling from CSKBs using fairly primitive keyword constraints. However, two bottlenecks limit these approaches: the inherent incompleteness of CSKBs limits the semantic coverage of synthetic QA pairs, and the lack of human annotations makes the sampled negative examples potentially uninformative and contradictory. To tackle these limitations above, we propose Conceptualization-Augmented Reasoner (CAR), a zero-shot commonsense question-answering framework that fully leverages the power of conceptualization. Specifically, CAR abstracts a commonsense knowledge tripl",
    "link": "http://arxiv.org/abs/2305.14869",
    "context": "Title: CAR: Conceptualization-Augmented Reasoner for Zero-Shot Commonsense Question Answering. (arXiv:2305.14869v2 [cs.CL] UPDATED)\nAbstract: The task of zero-shot commonsense question answering evaluates models on their capacity to reason about general scenarios beyond those presented in specific datasets. Existing approaches for tackling this task leverage external knowledge from CommonSense Knowledge Bases (CSKBs) by pretraining the model on synthetic QA pairs constructed from CSKBs. In these approaches, negative examples (distractors) are formulated by randomly sampling from CSKBs using fairly primitive keyword constraints. However, two bottlenecks limit these approaches: the inherent incompleteness of CSKBs limits the semantic coverage of synthetic QA pairs, and the lack of human annotations makes the sampled negative examples potentially uninformative and contradictory. To tackle these limitations above, we propose Conceptualization-Augmented Reasoner (CAR), a zero-shot commonsense question-answering framework that fully leverages the power of conceptualization. Specifically, CAR abstracts a commonsense knowledge tripl",
    "path": "papers/23/05/2305.14869.json",
    "total_tokens": 935,
    "translated_title": "CAR: 用于零样本常识问答的概念增强推理器",
    "translated_abstract": "零样本常识问答的任务评估模型在能够推理超出特定数据集的一般情景方面的能力。现有的解决这一任务的方法通过在合成的从常识知识库（CSKBs）构建的QA对上对模型进行预训练，利用从CSKBs中随机采样来构造负例（干扰项）的关键词约束。然而，这些方法存在两个瓶颈：CSKB的本质不完整限制了合成QA对的语义覆盖范围，缺乏人工注释使得采样的负例可能无信息性且相互矛盾。为了解决上述限制，我们提出了概念增强推理器（CAR），一个充分利用概念化能力的零样本常识问答框架。具体而言，CAR提取了常识知识三元组，并通过概念化语义图生成QA对，以扩展从CSKBs中选择干扰项的范围，并增强模型对常识问题的推理能力。",
    "tldr": "CAR是一个零样本常识问答框架，通过概念增强推理器来解决常识问题。它利用概念化语义图扩展了问题的语义覆盖范围，并提高了模型对常识问题的推理能力。",
    "en_tdlr": "CAR is a zero-shot commonsense question-answering framework that leverages Conceptualization-Augmented Reasoner to address common sense questions. It extends the semantic coverage of questions using conceptualization semantic graphs and enhances the model's reasoning ability for commonsense questions."
}