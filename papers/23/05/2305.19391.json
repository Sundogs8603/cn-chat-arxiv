{
    "title": "Deep Clustering with Incomplete Noisy Pairwise Annotations: A Geometric Regularization Approach. (arXiv:2305.19391v1 [cs.LG])",
    "abstract": "The recent integration of deep learning and pairwise similarity annotation-based constrained clustering -- i.e., $\\textit{deep constrained clustering}$ (DCC) -- has proven effective for incorporating weak supervision into massive data clustering: Less than 1% of pair similarity annotations can often substantially enhance the clustering accuracy. However, beyond empirical successes, there is a lack of understanding of DCC. In addition, many DCC paradigms are sensitive to annotation noise, but performance-guaranteed noisy DCC methods have been largely elusive. This work first takes a deep look into a recently emerged logistic loss function of DCC, and characterizes its theoretical properties. Our result shows that the logistic DCC loss ensures the identifiability of data membership under reasonable conditions, which may shed light on its effectiveness in practice. Building upon this understanding, a new loss function based on geometric factor analysis is proposed to fend against noisy an",
    "link": "http://arxiv.org/abs/2305.19391",
    "context": "Title: Deep Clustering with Incomplete Noisy Pairwise Annotations: A Geometric Regularization Approach. (arXiv:2305.19391v1 [cs.LG])\nAbstract: The recent integration of deep learning and pairwise similarity annotation-based constrained clustering -- i.e., $\\textit{deep constrained clustering}$ (DCC) -- has proven effective for incorporating weak supervision into massive data clustering: Less than 1% of pair similarity annotations can often substantially enhance the clustering accuracy. However, beyond empirical successes, there is a lack of understanding of DCC. In addition, many DCC paradigms are sensitive to annotation noise, but performance-guaranteed noisy DCC methods have been largely elusive. This work first takes a deep look into a recently emerged logistic loss function of DCC, and characterizes its theoretical properties. Our result shows that the logistic DCC loss ensures the identifiability of data membership under reasonable conditions, which may shed light on its effectiveness in practice. Building upon this understanding, a new loss function based on geometric factor analysis is proposed to fend against noisy an",
    "path": "papers/23/05/2305.19391.json",
    "total_tokens": 950,
    "translated_title": "带有不完整噪声配对注释的深度聚类：一种几何正则化方法",
    "translated_abstract": "近年来，深度学习和基于注释相似性对限制聚类的结合，即深度限制聚类（DCC），已被证明对于将弱监督纳入大规模数据聚类是有效的：少于1％的成对相似性注释通常可以显著提高聚类精度。然而，除了经验性成功外，对DCC缺乏理解。此外，许多DCC范例对注释噪声敏感，但具有性能保证的嘈杂DCC方法在很大程度上难以捉摸。本文首先对最近出现的DCC逻辑损失函数进行了深入研究，并表征了其理论性质。我们的结果表明，逻辑DCC损失确保在合理条件下数据成员的可识别性，这可能为其在实践中的有效性提供了启示。在此基础上，提出了一种基于几何因子分析的新损失函数，以抵御嘈杂的注释并进一步提高聚类性能。在几个数据集上的实验证明了所提出方法的有效性。",
    "tldr": "本文通过研究逻辑DCC损失函数的理论性质，提出了一种基于几何因子分析的新损失函数用以抵御嘈杂的注释并进一步提高聚类性能。",
    "en_tdlr": "This paper proposes a new loss function based on geometric factor analysis to fend against noisy annotations and improve clustering performance, building on an understanding of the theoretical properties of the logistic DCC loss."
}