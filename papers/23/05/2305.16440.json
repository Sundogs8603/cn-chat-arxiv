{
    "title": "Representation Transfer Learning via Multiple Pre-trained models for Linear Regression. (arXiv:2305.16440v1 [cs.LG])",
    "abstract": "In this paper, we consider the problem of learning a linear regression model on a data domain of interest (target) given few samples. To aid learning, we are provided with a set of pre-trained regression models that are trained on potentially different data domains (sources). Assuming a representation structure for the data generating linear models at the sources and the target domains, we propose a representation transfer based learning method for constructing the target model. The proposed scheme is comprised of two phases: (i) utilizing the different source representations to construct a representation that is adapted to the target data, and (ii) using the obtained model as an initialization to a fine-tuning procedure that re-trains the entire (over-parameterized) regression model on the target data. For each phase of the training method, we provide excess risk bounds for the learned model compared to the true data generating target model. The derived bounds show a gain in sample co",
    "link": "http://arxiv.org/abs/2305.16440",
    "context": "Title: Representation Transfer Learning via Multiple Pre-trained models for Linear Regression. (arXiv:2305.16440v1 [cs.LG])\nAbstract: In this paper, we consider the problem of learning a linear regression model on a data domain of interest (target) given few samples. To aid learning, we are provided with a set of pre-trained regression models that are trained on potentially different data domains (sources). Assuming a representation structure for the data generating linear models at the sources and the target domains, we propose a representation transfer based learning method for constructing the target model. The proposed scheme is comprised of two phases: (i) utilizing the different source representations to construct a representation that is adapted to the target data, and (ii) using the obtained model as an initialization to a fine-tuning procedure that re-trains the entire (over-parameterized) regression model on the target data. For each phase of the training method, we provide excess risk bounds for the learned model compared to the true data generating target model. The derived bounds show a gain in sample co",
    "path": "papers/23/05/2305.16440.json",
    "total_tokens": 870,
    "translated_title": "多个预训练模型的表示迁移学习在线性回归中的研究",
    "translated_abstract": "本文研究了在给定很少数样本的情况下，如何在感兴趣的数据领域（目标）上学习线性回归模型。我们提出了一种基于表示迁移的学习方法，通过提供一组在可能不同的数据领域（来源）上训练的预训练回归模型，来构建目标模型。该方法由两个阶段组成：（i）利用不同的源表示来构造适应目标数据的表示，（ii）将所得到的模型作为初始值，通过微调程序，在目标数据上重新训练整个（超参数）回归模型。对于训练方法的每个阶段，我们提供了学习模型与真实数据生成目标模型之间的超额风险限制。导出的限制显示了样本复杂度的提高。",
    "tldr": "本文提出了一种基于表示迁移的学习方法，在给定很少数样本的情况下，通过提供一组在可能不同的数据领域上训练的预训练回归模型，来构建目标模型，使用这种方法可以提高模型的样本复杂度。",
    "en_tdlr": "This paper presents a representation transfer based learning method for constructing the target model in linear regression, which is aided by pre-trained regression models trained on potentially different data domains. The proposed method consists of two phases and can improve the sample complexity of the model."
}