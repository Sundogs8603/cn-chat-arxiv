{
    "title": "Automated Few-shot Classification with Instruction-Finetuned Language Models. (arXiv:2305.12576v2 [cs.CL] UPDATED)",
    "abstract": "A particularly successful class of approaches for few-shot learning combines language models with prompts -- hand-crafted task descriptions that complement data samples. However, designing prompts by hand for each task commonly requires domain knowledge and substantial guesswork. We observe, in the context of classification tasks, that instruction finetuned language models exhibit remarkable prompt robustness, and we subsequently propose a simple method to eliminate the need for handcrafted prompts, named AuT-Few. This approach consists of (i) a prompt retrieval module that selects suitable task instructions from the instruction-tuning knowledge base, and (ii) the generation of two distinct, semantically meaningful, class descriptions and a selection mechanism via cross-validation. Over $12$ datasets, spanning $8$ classification tasks, we show that AuT-Few outperforms current state-of-the-art few-shot learning methods. Moreover, AuT-Few is the best ranking method across datasets on the",
    "link": "http://arxiv.org/abs/2305.12576",
    "context": "Title: Automated Few-shot Classification with Instruction-Finetuned Language Models. (arXiv:2305.12576v2 [cs.CL] UPDATED)\nAbstract: A particularly successful class of approaches for few-shot learning combines language models with prompts -- hand-crafted task descriptions that complement data samples. However, designing prompts by hand for each task commonly requires domain knowledge and substantial guesswork. We observe, in the context of classification tasks, that instruction finetuned language models exhibit remarkable prompt robustness, and we subsequently propose a simple method to eliminate the need for handcrafted prompts, named AuT-Few. This approach consists of (i) a prompt retrieval module that selects suitable task instructions from the instruction-tuning knowledge base, and (ii) the generation of two distinct, semantically meaningful, class descriptions and a selection mechanism via cross-validation. Over $12$ datasets, spanning $8$ classification tasks, we show that AuT-Few outperforms current state-of-the-art few-shot learning methods. Moreover, AuT-Few is the best ranking method across datasets on the",
    "path": "papers/23/05/2305.12576.json",
    "total_tokens": 842,
    "translated_title": "基于自动调优语言模型的少样本分类方法",
    "translated_abstract": "少样本学习的一类成功方法将语言模型与提示结合起来，这些提示是手工制作的任务描述，以补充数据样本。然而，为每个任务手工设计提示通常需要领域知识和大量猜测。我们观察到，在分类任务的背景下，经过指导调优的语言模型表现出了显著的提示鲁棒性，因此我们提出了一种名为AuT-Few的简单方法，以消除对手工制作提示的需求。该方法包括（i）一个从调优指令知识库中选择合适任务指令的指令检索模块，以及（ii）通过交叉验证生成两个不同的、语义有意义的类别描述和选择机制。在包括8个分类任务的12个数据集上，我们展示了AuT-Few优于当前最先进的少样本学习方法。此外，AuT-Few在数据集上是排名最高的方法。",
    "tldr": "基于自动调优语言模型的少样本分类方法AuT-Few消除了手工制作提示的需求，并在多个数据集上超越了当前最先进的少样本学习方法。",
    "en_tdlr": "The method AuT-Few, which is based on instruction-finetuned language models, eliminates the need for handcrafted prompts and outperforms the current state-of-the-art few-shot learning methods across multiple datasets."
}