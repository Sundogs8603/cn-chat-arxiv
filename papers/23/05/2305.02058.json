{
    "title": "Human Machine Co-adaption Interface via Cooperation Markov Decision Process System. (arXiv:2305.02058v1 [cs.AI])",
    "abstract": "This paper aims to develop a new human-machine interface to improve rehabilitation performance from the perspective of both the user (patient) and the machine (robot) by introducing the co-adaption techniques via model-based reinforcement learning. Previous studies focus more on robot assistance, i.e., to improve the control strategy so as to fulfill the objective of Assist-As-Needed. In this study, we treat the full process of robot-assisted rehabilitation as a co-adaptive or mutual learning process and emphasize the adaptation of the user to the machine. To this end, we proposed a Co-adaptive MDPs (CaMDPs) model to quantify the learning rates based on cooperative multi-agent reinforcement learning (MARL) in the high abstraction layer of the systems. We proposed several approaches to cooperatively adjust the Policy Improvement among the two agents in the framework of Policy Iteration. Based on the proposed co-adaptive MDPs, the simulation study indicates the non-stationary problem can",
    "link": "http://arxiv.org/abs/2305.02058",
    "context": "Title: Human Machine Co-adaption Interface via Cooperation Markov Decision Process System. (arXiv:2305.02058v1 [cs.AI])\nAbstract: This paper aims to develop a new human-machine interface to improve rehabilitation performance from the perspective of both the user (patient) and the machine (robot) by introducing the co-adaption techniques via model-based reinforcement learning. Previous studies focus more on robot assistance, i.e., to improve the control strategy so as to fulfill the objective of Assist-As-Needed. In this study, we treat the full process of robot-assisted rehabilitation as a co-adaptive or mutual learning process and emphasize the adaptation of the user to the machine. To this end, we proposed a Co-adaptive MDPs (CaMDPs) model to quantify the learning rates based on cooperative multi-agent reinforcement learning (MARL) in the high abstraction layer of the systems. We proposed several approaches to cooperatively adjust the Policy Improvement among the two agents in the framework of Policy Iteration. Based on the proposed co-adaptive MDPs, the simulation study indicates the non-stationary problem can",
    "path": "papers/23/05/2305.02058.json",
    "total_tokens": 982,
    "translated_title": "通过合作马尔可夫决策过程系统实现人机协同适应界面",
    "translated_abstract": "本文旨在通过引入基于模型的强化学习中的协同适应技术，开发一种新的人机界面，从用户（患者）和机器（机器人）双方的角度来改善康复表现。传统研究更侧重于机器人协助，即通过改善控制策略来实现按需协助的目标。本研究将机器人辅助康复的整个过程视为协同适应或相互学习过程，并强调用户对机器人的适应性。为此，我们提出了一种称为协同MDPs（CaMDPs）的模型，以基于协作多智能体强化学习（MARL）的学习速率来量化系统的高抽象层。我们提出了几种方法来协作地调整策略迭代框架中的两个代理之间的策略改进。根据我们提出的协同MDPs，仿真研究表明非平稳问题可以通过此系统解决。",
    "tldr": "本文提出了一种新的人机界面，将机器人辅助康复的整个过程视为协同适应或相互学习过程。提出了一种量化高抽象层系统学习速率的模型，并根据该模型设计了协作的策略迭代方法，通过该系统解决了非平稳问题。",
    "en_tdlr": "This paper proposes a new human-machine interface that treats the full process of robot-assisted rehabilitation as a co-adaptive or mutual learning process and emphasizes the adaptation of the user to the machine. A model based on cooperative multi-agent reinforcement learning is introduced to quantify the learning rates, and a cooperative policy iteration method is designed to solve the non-stationary problem."
}