{
    "title": "Chain of Log-Concave Markov Chains. (arXiv:2305.19473v1 [stat.ML])",
    "abstract": "Markov chain Monte Carlo (MCMC) is a class of general-purpose algorithms for sampling from unnormalized densities. There are two well-known problems facing MCMC in high dimensions: (i) The distributions of interest are concentrated in pockets separated by large regions with small probability mass, and (ii) The log-concave pockets themselves are typically ill-conditioned. We introduce a framework to tackle these problems using isotropic Gaussian smoothing. We prove one can always decompose sampling from a density (minimal assumptions made on the density) into a sequence of sampling from log-concave conditional densities via accumulation of noisy measurements with equal noise levels. This construction keeps track of a history of samples, making it non-Markovian as a whole, but the history only shows up in the form of an empirical mean, making the memory footprint minimal. Our sampling algorithm generalizes walk-jump sampling [1]. The \"walk\" phase becomes a (non-Markovian) chain of log-co",
    "link": "http://arxiv.org/abs/2305.19473",
    "context": "Title: Chain of Log-Concave Markov Chains. (arXiv:2305.19473v1 [stat.ML])\nAbstract: Markov chain Monte Carlo (MCMC) is a class of general-purpose algorithms for sampling from unnormalized densities. There are two well-known problems facing MCMC in high dimensions: (i) The distributions of interest are concentrated in pockets separated by large regions with small probability mass, and (ii) The log-concave pockets themselves are typically ill-conditioned. We introduce a framework to tackle these problems using isotropic Gaussian smoothing. We prove one can always decompose sampling from a density (minimal assumptions made on the density) into a sequence of sampling from log-concave conditional densities via accumulation of noisy measurements with equal noise levels. This construction keeps track of a history of samples, making it non-Markovian as a whole, but the history only shows up in the form of an empirical mean, making the memory footprint minimal. Our sampling algorithm generalizes walk-jump sampling [1]. The \"walk\" phase becomes a (non-Markovian) chain of log-co",
    "path": "papers/23/05/2305.19473.json",
    "total_tokens": 899,
    "translated_title": "对数凹马尔可夫链之链",
    "translated_abstract": "马尔科夫链蒙特卡罗（MCMC）是一种从未标准化密度中抽样的通用算法类。在高维情况下，MCMC面临两个众所周知的问题：(i)感兴趣的分布在由小概率块隔开的区域中集中;(ii)对数凹性的小概率块本身通常存在病态问题。我们引入了一种采用等向性高斯平滑来解决这些问题的框架。我们证明，无论密度函数的最小假设是什么，从密度函数中采样总是可以分解为通过等噪声测量的累积，从对数凹性条件密度中采样的序列。该构造跟踪了样本历史，因此作为一个整体而言是非马尔可夫的，但历史仅以经验均值的形式出现，从而保证了内存印迹的最小化。我们的采样算法推广了步行跳跃采样（1）。\"走\"阶段变成了对数凹链的(非马尔可夫)链。",
    "tldr": "该论文提出了一种新的采样算法，基于对数凹条件概率密度，使用等向性高斯平滑来解决高维下抽样难题。",
    "en_tdlr": "This paper presents a new sampling algorithm that solves the problem of sampling in high dimensions by using isotropic Gaussian smoothing based on log-concave conditional probability density."
}