{
    "title": "Prompting with Pseudo-Code Instructions. (arXiv:2305.11790v1 [cs.CL])",
    "abstract": "Prompting with natural language instructions has recently emerged as a popular method of harnessing the capabilities of large language models. Given the inherent ambiguity present in natural language, it is intuitive to consider the possible advantages of prompting with less ambiguous prompt styles, such as the use of pseudo-code.  In this paper we explore if prompting via pseudo-code instructions helps improve the performance of pre-trained language models. We manually create a dataset of pseudo-code prompts for 132 different tasks spanning classification, QA and generative language tasks, sourced from the Super-NaturalInstructions dataset. Using these prompts along with their counterparts in natural language, we study their performance on two LLM families - BLOOM and CodeGen. Our experiments show that using pseudo-code instructions leads to better results, with an average increase (absolute) of 7-16 points in F1 scores for classification tasks and an improvement (relative) of 12-38% ",
    "link": "http://arxiv.org/abs/2305.11790",
    "context": "Title: Prompting with Pseudo-Code Instructions. (arXiv:2305.11790v1 [cs.CL])\nAbstract: Prompting with natural language instructions has recently emerged as a popular method of harnessing the capabilities of large language models. Given the inherent ambiguity present in natural language, it is intuitive to consider the possible advantages of prompting with less ambiguous prompt styles, such as the use of pseudo-code.  In this paper we explore if prompting via pseudo-code instructions helps improve the performance of pre-trained language models. We manually create a dataset of pseudo-code prompts for 132 different tasks spanning classification, QA and generative language tasks, sourced from the Super-NaturalInstructions dataset. Using these prompts along with their counterparts in natural language, we study their performance on two LLM families - BLOOM and CodeGen. Our experiments show that using pseudo-code instructions leads to better results, with an average increase (absolute) of 7-16 points in F1 scores for classification tasks and an improvement (relative) of 12-38% ",
    "path": "papers/23/05/2305.11790.json",
    "total_tokens": 833,
    "translated_title": "伪代码指令提示",
    "translated_abstract": "最近，使用自然语言指令提示已成为利用大型语言模型能力的一种流行方法。鉴于自然语言中的固有歧义，因此考虑使用更少歧义的提示样式，如伪代码提示，可能具有优势。本文探讨了通过伪代码指令提示是否有助于改善预训练语言模型的性能。我们手动创建了一个包含来自Super-NaturalInstructions数据集的132个不同任务的伪代码提示数据集，涵盖分类、QA和生成语言任务。使用这些伪代码提示以及它们的自然语言对应物，在两个LLM家族-BLOOM和CodeGen上研究它们的性能。我们的实验表明，使用伪代码指令提示会带来更好的结果，对于分类任务，F1分数平均增加（绝对值）7-16分，相对改善12-38%。",
    "tldr": "本文研究了使用伪代码指令提示能否提高预训练语言模型的性能，实验证明使用伪代码提示可以在分类任务中提高7-16分，并相对改善12-38%。",
    "en_tdlr": "This paper explores whether prompting with pseudo-code instructions helps improve the performance of pre-trained language models, and experiments show that using pseudo-code prompts leads to an average increase of 7-16 points in F1 scores for classification tasks and an improvement of 12-38% relatively."
}