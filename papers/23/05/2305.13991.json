{
    "title": "Expressive Losses for Verified Robustness via Convex Combinations. (arXiv:2305.13991v1 [cs.LG])",
    "abstract": "In order to train networks for verified adversarial robustness, previous work typically over-approximates the worst-case loss over (subsets of) perturbation regions or induces verifiability on top of adversarial training. The key to state-of-the-art performance lies in the expressivity of the employed loss function, which should be able to match the tightness of the verifiers to be employed post-training. We formalize a definition of expressivity, and show that it can be satisfied via simple convex combinations between adversarial attacks and IBP bounds. We then show that the resulting algorithms, named CC-IBP and MTL-IBP, yield state-of-the-art results across a variety of settings in spite of their conceptual simplicity. In particular, for $\\ell_\\infty$ perturbations of radius $\\frac{1}{255}$ on TinyImageNet and downscaled ImageNet, MTL-IBP improves on the best standard and verified accuracies from the literature by from $1.98\\%$ to $3.92\\%$ points while only relying on single-step ad",
    "link": "http://arxiv.org/abs/2305.13991",
    "context": "Title: Expressive Losses for Verified Robustness via Convex Combinations. (arXiv:2305.13991v1 [cs.LG])\nAbstract: In order to train networks for verified adversarial robustness, previous work typically over-approximates the worst-case loss over (subsets of) perturbation regions or induces verifiability on top of adversarial training. The key to state-of-the-art performance lies in the expressivity of the employed loss function, which should be able to match the tightness of the verifiers to be employed post-training. We formalize a definition of expressivity, and show that it can be satisfied via simple convex combinations between adversarial attacks and IBP bounds. We then show that the resulting algorithms, named CC-IBP and MTL-IBP, yield state-of-the-art results across a variety of settings in spite of their conceptual simplicity. In particular, for $\\ell_\\infty$ perturbations of radius $\\frac{1}{255}$ on TinyImageNet and downscaled ImageNet, MTL-IBP improves on the best standard and verified accuracies from the literature by from $1.98\\%$ to $3.92\\%$ points while only relying on single-step ad",
    "path": "papers/23/05/2305.13991.json",
    "total_tokens": 982,
    "translated_title": "基于凸组合的表达性损失可以提高网络的对抗鲁棒性",
    "translated_abstract": "先前的工作通常通过（扰动区域的子集）的最坏情况下限，或在对抗训练之上引入可验证性来训练具有已验证鲁棒性的网络。最先进性能的关键在于所使用的损失函数的表达能力，它应该能够匹配训练后要使用的验证器的紧密度。我们形式化定义了表达力，并表明它可以通过对抗性攻击和IBP边界之间的简单凸组合来满足。然后，我们展示了所得到的算法，命名为CC-IBP和MTL-IBP，在各种设置中均可以产生最先进的结果，尽管其概念上是简单的。特别地，在TinyImageNet和缩小的ImageNet上，对于半径为$ \\frac{1} {255} $的$ \\ell_ \\infty $扰动，MTL-IBP可以将文献中最佳标准和验证准确性从$1.98\\%$提高到$3.92\\%$，同时仅依赖于单步自适应优化。",
    "tldr": "通过基于凸组合的表达性损失，可以提高网络的对抗鲁棒性，最新的算法可以获得最先进的结果；这种方法通过对抗性攻击和IBP边界之间的简单凸组合进行实现。",
    "en_tdlr": "By using expressive losses based on convex combinations, networks can achieve verified adversarial robustness, resulting in state-of-the-art performance. This is achieved through a combination of adversarial attacks and IBP bounds, and the resulting algorithm (CC-IBP and MTL-IBP) outperforms previous methods in a variety of settings."
}