{
    "title": "Statistical Inference for Fairness Auditing. (arXiv:2305.03712v1 [stat.ME])",
    "abstract": "Before deploying a black-box model in high-stakes problems, it is important to evaluate the model's performance on sensitive subpopulations. For example, in a recidivism prediction task, we may wish to identify demographic groups for which our prediction model has unacceptably high false positive rates or certify that no such groups exist. In this paper, we frame this task, often referred to as \"fairness auditing,\" in terms of multiple hypothesis testing. We show how the bootstrap can be used to simultaneously bound performance disparities over a collection of groups with statistical guarantees. Our methods can be used to flag subpopulations affected by model underperformance, and certify subpopulations for which the model performs adequately. Crucially, our audit is model-agnostic and applicable to nearly any performance metric or group fairness criterion. Our methods also accommodate extremely rich -- even infinite -- collections of subpopulations. Further, we generalize beyond subpo",
    "link": "http://arxiv.org/abs/2305.03712",
    "context": "Title: Statistical Inference for Fairness Auditing. (arXiv:2305.03712v1 [stat.ME])\nAbstract: Before deploying a black-box model in high-stakes problems, it is important to evaluate the model's performance on sensitive subpopulations. For example, in a recidivism prediction task, we may wish to identify demographic groups for which our prediction model has unacceptably high false positive rates or certify that no such groups exist. In this paper, we frame this task, often referred to as \"fairness auditing,\" in terms of multiple hypothesis testing. We show how the bootstrap can be used to simultaneously bound performance disparities over a collection of groups with statistical guarantees. Our methods can be used to flag subpopulations affected by model underperformance, and certify subpopulations for which the model performs adequately. Crucially, our audit is model-agnostic and applicable to nearly any performance metric or group fairness criterion. Our methods also accommodate extremely rich -- even infinite -- collections of subpopulations. Further, we generalize beyond subpo",
    "path": "papers/23/05/2305.03712.json",
    "total_tokens": 853,
    "translated_title": "公平性审计的统计推断方法",
    "translated_abstract": "在将黑盒模型用于高风险问题之前，评估模型在敏感子群体上的表现非常重要。本文提出了一种“公平性审计”的任务框架，并通过多重假设检验将其表述。我们展示了如何使用自举方法以统计保证的方式同时限制多个群体表现差异。我们的方法适用于几乎任何性能度量或群体公平性标准，并且可以处理非常丰富的、甚至是无限的子群体集合。此外，我们将方法推广到了多个潜在重叠标准下的模型表现审计。我们在合成和真实数据集上展示了我们方法的有效性。",
    "tldr": "本文介绍了一种公平性审计的统计推断方法，可用于评估黑盒模型在敏感子群体上的表现，并通过自举方法限制多个群体表现差异，方法通用性强且适用面广。",
    "en_tdlr": "This paper introduces a statistical inference method for fairness auditing, which can evaluate the performance of a black-box model on sensitive subpopulations and limit performance disparities using bootstrap methods. The method is applicable to various metrics and group fairness criteria and can handle rich and even infinite sets of subpopulations. The approach is also generalized to multiple potentially overlapping criteria for model performance auditing."
}