{
    "title": "Joint Learning of Policy with Unknown Temporal Constraints for Safe Reinforcement Learning. (arXiv:2305.00576v1 [eess.SY])",
    "abstract": "In many real-world applications, safety constraints for reinforcement learning (RL) algorithms are either unknown or not explicitly defined. We propose a framework that concurrently learns safety constraints and optimal RL policies in such environments, supported by theoretical guarantees. Our approach merges a logically-constrained RL algorithm with an evolutionary algorithm to synthesize signal temporal logic (STL) specifications. The framework is underpinned by theorems that establish the convergence of our joint learning process and provide error bounds between the discovered policy and the true optimal policy. We showcased our framework in grid-world environments, successfully identifying both acceptable safety constraints and RL policies while demonstrating the effectiveness of our theorems in practice.",
    "link": "http://arxiv.org/abs/2305.00576",
    "context": "Title: Joint Learning of Policy with Unknown Temporal Constraints for Safe Reinforcement Learning. (arXiv:2305.00576v1 [eess.SY])\nAbstract: In many real-world applications, safety constraints for reinforcement learning (RL) algorithms are either unknown or not explicitly defined. We propose a framework that concurrently learns safety constraints and optimal RL policies in such environments, supported by theoretical guarantees. Our approach merges a logically-constrained RL algorithm with an evolutionary algorithm to synthesize signal temporal logic (STL) specifications. The framework is underpinned by theorems that establish the convergence of our joint learning process and provide error bounds between the discovered policy and the true optimal policy. We showcased our framework in grid-world environments, successfully identifying both acceptable safety constraints and RL policies while demonstrating the effectiveness of our theorems in practice.",
    "path": "papers/23/05/2305.00576.json",
    "total_tokens": 809,
    "translated_title": "学习未知时间约束下的安全强化学习策略",
    "translated_abstract": "在许多实际应用中，强化学习算法的安全约束往往是未知的或者没有明确定义的。我们提出了一个框架，在这样的环境中同时学习安全约束和最优强化学习策略，并且有理论保证。我们的方法将逻辑约束强化学习算法与进化算法结合起来，合成信号时态逻辑(STL)规范。该框架是由定理支持的，这些定理建立了我们的联合学习过程的收敛性，并提供了发现策略与真正最优策略之间的误差界限。我们在网格世界环境中展示了我们的框架，在演示我们理论在实践中的有效性的同时，成功地确定了可接受的安全约束和强化学习策略。",
    "tldr": "基于逻辑约束强化学习算法和进化算法的信号时态逻辑规范合成框架，同时学习安全约束和最优强化学习策略，并有理论保证。",
    "en_tdlr": "A framework is proposed for jointly learning safety constraints and optimal RL policies in environments where constraints are unknown, based on logically-constrained RL algorithm and an evolutionary algorithm for synthesizing signal temporal logic specifications. The framework provides theoretical guarantees and demonstrated effectiveness in practice for identifying both acceptable safety constraints and RL policies in grid-world environments."
}