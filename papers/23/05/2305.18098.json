{
    "title": "BigTranslate: Augmenting Large Language Models with Multilingual Translation Capability over 100 Languages. (arXiv:2305.18098v2 [cs.CL] UPDATED)",
    "abstract": "Large language models (LLMs) demonstrate promising translation performance among various natural languages. However, many LLMs especially the open-sourced ones, such as BLOOM and LLaMA, are English-dominant and support only dozens of natural languages, making the potential of LLMs on language translation less explored. In this work, we present BigTranslate which adapts LLaMA that covers only 20 languages and enhances it with multilingual translation capability on more than 100 languages. BigTranslate is built upon LLaMA-13B and it is optimized in three steps. First, we continue training LLaMA with massive Chinese monolingual data. Second, we continue training the model with a large-scale parallel dataset that covers 102 natural languages. Third, we instruct-tune the foundation model with multilingual translation instructions, leading to our BigTranslate model. The preliminary experiments on multilingual translation show that BigTranslate performs comparably with ChatGPT and Google Tran",
    "link": "http://arxiv.org/abs/2305.18098",
    "context": "Title: BigTranslate: Augmenting Large Language Models with Multilingual Translation Capability over 100 Languages. (arXiv:2305.18098v2 [cs.CL] UPDATED)\nAbstract: Large language models (LLMs) demonstrate promising translation performance among various natural languages. However, many LLMs especially the open-sourced ones, such as BLOOM and LLaMA, are English-dominant and support only dozens of natural languages, making the potential of LLMs on language translation less explored. In this work, we present BigTranslate which adapts LLaMA that covers only 20 languages and enhances it with multilingual translation capability on more than 100 languages. BigTranslate is built upon LLaMA-13B and it is optimized in three steps. First, we continue training LLaMA with massive Chinese monolingual data. Second, we continue training the model with a large-scale parallel dataset that covers 102 natural languages. Third, we instruct-tune the foundation model with multilingual translation instructions, leading to our BigTranslate model. The preliminary experiments on multilingual translation show that BigTranslate performs comparably with ChatGPT and Google Tran",
    "path": "papers/23/05/2305.18098.json",
    "total_tokens": 970,
    "translated_title": "BigTranslate：通过多语言翻译增强超过100种语言的大型语言模型",
    "translated_abstract": "大型语言模型（LLM）在各种自然语言之间展示了令人期待的翻译性能。然而，许多LLM，特别是开源的，比如BLOOM和LLaMA，都以英语为主导，并且只支持几十种自然语言，使得LLM在语言翻译方面的潜力不太被探索。在这项工作中，我们介绍了BigTranslate，它采用了LLaMA模型，该模型仅覆盖20种语言，并在100多种语言上增强了其多语言翻译能力。BigTranslate是建立在LLaMA-13B之上，并通过三个步骤进行优化。首先，我们利用大规模的中文单语数据继续训练LLaMA。其次，我们使用覆盖102种自然语言的大规模平行数据集继续训练模型。第三，我们使用多语言翻译指令对基础模型进行指导微调，得到了我们的BigTranslate模型。多语言翻译的初步实验结果显示，BigTranslate与ChatGPT和谷歌翻译的性能相当。",
    "tldr": "BigTranslate是一个基于LLaMA的大型语言模型，在原有的基础上通过继续训练和指导微调实现了对100多种语言的多语言翻译能力，初步实验结果显示其性能接近于ChatGPT和谷歌翻译。",
    "en_tdlr": "BigTranslate is a large language model based on LLaMA that enhances its multilingual translation capability to over 100 languages through continued training and fine-tuning with translation instructions. Preliminary experiments show comparable performance to ChatGPT and Google Translate."
}