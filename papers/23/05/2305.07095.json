{
    "title": "Are Machine Rationales (Not) Useful to Humans? Measuring and Improving Human Utility of Free-Text Rationales. (arXiv:2305.07095v1 [cs.CL])",
    "abstract": "Among the remarkable emergent capabilities of large language models (LMs) is free-text rationalization; beyond a certain scale, large LMs are capable of generating seemingly useful rationalizations, which in turn, can dramatically enhance their performances on leaderboards. This phenomenon raises a question: can machine generated rationales also be useful for humans, especially when lay humans try to answer questions based on those machine rationales? We observe that human utility of existing rationales is far from satisfactory, and expensive to estimate with human studies. Existing metrics like task performance of the LM generating the rationales, or similarity between generated and gold rationales are not good indicators of their human utility. While we observe that certain properties of rationales like conciseness and novelty are correlated with their human utility, estimating them without human involvement is challenging. We show that, by estimating a rationale's helpfulness in ans",
    "link": "http://arxiv.org/abs/2305.07095",
    "context": "Title: Are Machine Rationales (Not) Useful to Humans? Measuring and Improving Human Utility of Free-Text Rationales. (arXiv:2305.07095v1 [cs.CL])\nAbstract: Among the remarkable emergent capabilities of large language models (LMs) is free-text rationalization; beyond a certain scale, large LMs are capable of generating seemingly useful rationalizations, which in turn, can dramatically enhance their performances on leaderboards. This phenomenon raises a question: can machine generated rationales also be useful for humans, especially when lay humans try to answer questions based on those machine rationales? We observe that human utility of existing rationales is far from satisfactory, and expensive to estimate with human studies. Existing metrics like task performance of the LM generating the rationales, or similarity between generated and gold rationales are not good indicators of their human utility. While we observe that certain properties of rationales like conciseness and novelty are correlated with their human utility, estimating them without human involvement is challenging. We show that, by estimating a rationale's helpfulness in ans",
    "path": "papers/23/05/2305.07095.json",
    "total_tokens": 963,
    "translated_title": "机器理由对人类是否有用？评估和提高自然文本理由的人类效用",
    "translated_abstract": "在大型语言模型（LMs）的显着出现能力中，自由文本理由是其中之一；超过某个规模后，大型LMs能够生成看似有用的理由，进而可以极大地增强它们在领导榜上的表现。这种现象引发了一个问题：机器生成的理由是否也能对人类有用，特别是当普通人尝试根据这些机器理由回答问题时？我们观察到现有理由的人类效用远未令人满意，并且昂贵的人类研究才能估计。现有的评估指标，如生成理由LM的任务表现或生成理由与黄金理由之间的相似性，并不能很好地表明它们的人类效用。虽然我们观察到，理由的某些属性，如简洁性和新颖性，与它们的人类效用有关，但在没有人类参与的情况下估计它们是具有挑战性的。我们展示了如何通过估计理由在回答给定问题中的有用性来提高机器生成理由的人类效用，从而解决这个问题。",
    "tldr": "该论文研究了机器产生的自然语言理由对人类是否有用，发现现有理由的人类效用远低于理想状态，并提出通过估计理由在回答给定问题中的有用性来提高机器生成理由的人类效用。",
    "en_tdlr": "This paper investigates whether machine-generated free-text rationales can be useful for humans and finds that current rationales have low human utility. The paper proposes improving the human utility of machine-generated rationales by estimating their helpfulness in answering given questions."
}