{
    "title": "Centralised rehearsal of decentralised cooperation: Multi-agent reinforcement learning for the scalable coordination of residential energy flexibility. (arXiv:2305.18875v2 [eess.SY] UPDATED)",
    "abstract": "This paper investigates how deep multi-agent reinforcement learning can enable the scalable and privacy-preserving coordination of residential energy flexibility. The coordination of distributed resources such as electric vehicles and heating will be critical to the successful integration of large shares of renewable energy in our electricity grid and, thus, to help mitigate climate change. The pre-learning of individual reinforcement learning policies can enable distributed control with no sharing of personal data required during execution. However, previous approaches for multi-agent reinforcement learning-based distributed energy resources coordination impose an ever greater training computational burden as the size of the system increases. We therefore adopt a deep multi-agent actor-critic method which uses a \\emph{centralised but factored critic} to rehearse coordination ahead of execution. Results show that coordination is achieved at scale, with minimal information and communica",
    "link": "http://arxiv.org/abs/2305.18875",
    "context": "Title: Centralised rehearsal of decentralised cooperation: Multi-agent reinforcement learning for the scalable coordination of residential energy flexibility. (arXiv:2305.18875v2 [eess.SY] UPDATED)\nAbstract: This paper investigates how deep multi-agent reinforcement learning can enable the scalable and privacy-preserving coordination of residential energy flexibility. The coordination of distributed resources such as electric vehicles and heating will be critical to the successful integration of large shares of renewable energy in our electricity grid and, thus, to help mitigate climate change. The pre-learning of individual reinforcement learning policies can enable distributed control with no sharing of personal data required during execution. However, previous approaches for multi-agent reinforcement learning-based distributed energy resources coordination impose an ever greater training computational burden as the size of the system increases. We therefore adopt a deep multi-agent actor-critic method which uses a \\emph{centralised but factored critic} to rehearse coordination ahead of execution. Results show that coordination is achieved at scale, with minimal information and communica",
    "path": "papers/23/05/2305.18875.json",
    "total_tokens": 900,
    "translated_title": "集中化协作的分散式排练：基于多智能体强化学习的住宅能量灵活性可扩展协调研究",
    "translated_abstract": "本文研究了深度多智能体强化学习如何实现住宅能量灵活性的可扩展且保护隐私的协调。分布式资源的协调，如电动汽车和供暖，将对成功整合大规模可再生能源到我们的电力网中至关重要，从而有助于减缓气候变化。预先学习每个强化学习策略可以实现分布式控制，在执行过程中不需要共享个人数据。然而，先前的多智能体强化学习方法不断增加训练计算负担，随着系统规模的增加。因此，我们采用了深度多智能体演员-评论家方法，使用“集中化但分解的评论家”在执行前进行协调排练。结果显示，协调可以在大规模情况下实现最少的信息和通讯。",
    "tldr": "本文研究了基于多智能体强化学习的住宅能量灵活性的可扩展且保护隐私的协调方法，使用“集中化但分解的评论家”在执行前进行协调排练，实现了大规模协调。",
    "en_tdlr": "This paper investigates the scalable and privacy-preserving coordination of residential energy flexibility using deep multi-agent reinforcement learning, with a \"centralised but factored critic\" approach for rehearsing coordination ahead of execution. Results show that coordination is achieved at scale with minimal information and communication required."
}