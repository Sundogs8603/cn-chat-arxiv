{
    "title": "A Survey on Intersectional Fairness in Machine Learning: Notions, Mitigation, and Challenges. (arXiv:2305.06969v1 [cs.LG])",
    "abstract": "The widespread adoption of Machine Learning systems, especially in more decision-critical applications such as criminal sentencing and bank loans, has led to increased concerns about fairness implications. Algorithms and metrics have been developed to mitigate and measure these discriminations. More recently, works have identified a more challenging form of bias called intersectional bias, which encompasses multiple sensitive attributes, such as race and gender, together. In this survey, we review the state-of-the-art in intersectional fairness. We present a taxonomy for intersectional notions of fairness and mitigation. Finally, we identify the key challenges and provide researchers with guidelines for future directions.",
    "link": "http://arxiv.org/abs/2305.06969",
    "context": "Title: A Survey on Intersectional Fairness in Machine Learning: Notions, Mitigation, and Challenges. (arXiv:2305.06969v1 [cs.LG])\nAbstract: The widespread adoption of Machine Learning systems, especially in more decision-critical applications such as criminal sentencing and bank loans, has led to increased concerns about fairness implications. Algorithms and metrics have been developed to mitigate and measure these discriminations. More recently, works have identified a more challenging form of bias called intersectional bias, which encompasses multiple sensitive attributes, such as race and gender, together. In this survey, we review the state-of-the-art in intersectional fairness. We present a taxonomy for intersectional notions of fairness and mitigation. Finally, we identify the key challenges and provide researchers with guidelines for future directions.",
    "path": "papers/23/05/2305.06969.json",
    "total_tokens": 734,
    "translated_title": "机器学习中交叉公平性调查：概念、缓解和挑战",
    "translated_abstract": "机器学习系统的广泛应用，特别是在更为决策至关重要的应用中，如刑事判决和银行贷款，引发了对公平性的更多关注。已经开发了算法和指标来缓解和衡量这些歧视。最近，一些研究发现了一种更具挑战性的偏见形式，称为交叉偏见，涵盖了多个敏感属性，例如种族和性别。在本调查中，我们回顾了交叉公平性的最新进展，提出了一个交叉公平性和缓解的分类法。最后，我们确定了关键挑战，并为未来的研究指导提供了指导方针。",
    "tldr": "本篇论文调查了机器学习中交叉公平性的最新进展，提出了分类法和缓解方法，并探讨了未来研究的挑战与方向。",
    "en_tdlr": "This survey reviews the latest progress in intersectional fairness in machine learning, proposes a taxonomy for intersectional notions of fairness and mitigation, and discusses the challenges and directions for future research."
}