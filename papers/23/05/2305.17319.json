{
    "title": "Moral Machine or Tyranny of the Majority?. (arXiv:2305.17319v1 [cs.CY])",
    "abstract": "With Artificial Intelligence systems increasingly applied in consequential domains, researchers have begun to ask how these systems ought to act in ethically charged situations where even humans lack consensus. In the Moral Machine project, researchers crowdsourced answers to \"Trolley Problems\" concerning autonomous vehicles. Subsequently, Noothigattu et al. (2018) proposed inferring linear functions that approximate each individual's preferences and aggregating these linear models by averaging parameters across the population. In this paper, we examine this averaging mechanism, focusing on fairness concerns in the presence of strategic effects. We investigate a simple setting where the population consists of two groups, with the minority constituting an {\\alpha} < 0.5 share of the population. To simplify the analysis, we consider the extreme case in which within-group preferences are homogeneous. Focusing on the fraction of contested cases where the minority group prevails, we make th",
    "link": "http://arxiv.org/abs/2305.17319",
    "context": "Title: Moral Machine or Tyranny of the Majority?. (arXiv:2305.17319v1 [cs.CY])\nAbstract: With Artificial Intelligence systems increasingly applied in consequential domains, researchers have begun to ask how these systems ought to act in ethically charged situations where even humans lack consensus. In the Moral Machine project, researchers crowdsourced answers to \"Trolley Problems\" concerning autonomous vehicles. Subsequently, Noothigattu et al. (2018) proposed inferring linear functions that approximate each individual's preferences and aggregating these linear models by averaging parameters across the population. In this paper, we examine this averaging mechanism, focusing on fairness concerns in the presence of strategic effects. We investigate a simple setting where the population consists of two groups, with the minority constituting an {\\alpha} < 0.5 share of the population. To simplify the analysis, we consider the extreme case in which within-group preferences are homogeneous. Focusing on the fraction of contested cases where the minority group prevails, we make th",
    "path": "papers/23/05/2305.17319.json",
    "total_tokens": 891,
    "translated_title": "道德机器还是多数派的暴政?",
    "translated_abstract": "随着人工智能系统越来越广泛地应用于重要领域，研究人员开始询问这些系统在伦理上具有争议的情况下应该如何行动，即在这种情况下连人类本身也没有一致共识。在道德机器项目中，研究员们众包回答了关于自主车辆的\"拦车\"问题。随后，Noothigattu等人(2018)提出了推断线性函数来近似每个个体的偏好，并通过对整个人群的参数取平均值来聚合这些线性模型。本文主要研究了这种平均机制，在存在策略效应的公平性问题方面进行了重点讨论。我们研究了一个简单的情况，其中人口分为两组，少数派的α <0.5。为简化分析，我们考虑了群体内偏好是同质的极端情况。我们聚焦于少数群体获胜的有争议情况的比例，进行分析研究。",
    "tldr": "本文研究了道德机器项目中提出的线性模型聚合机制的公平性问题，特别关注在存在策略影响的情况下少数群体是否会获胜的比例。",
    "en_tdlr": "This paper examines the fairness issues of the linear model aggregation mechanism proposed in the Moral Machine project, focusing on the proportion of contested cases where the minority group prevails, especially in the presence of strategic effects."
}