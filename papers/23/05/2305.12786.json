{
    "title": "Mitigating Data Imbalance and Representation Degeneration in Multilingual Machine Translation. (arXiv:2305.12786v2 [cs.CL] UPDATED)",
    "abstract": "Despite advances in multilingual neural machine translation (MNMT), we argue that there are still two major challenges in this area: data imbalance and representation degeneration. The data imbalance problem refers to the imbalance in the amount of parallel corpora for all language pairs, especially for long-tail languages (i.e., very low-resource languages). The representation degeneration problem refers to the problem of encoded tokens tending to appear only in a small subspace of the full space available to the MNMT model. To solve these two issues, we propose Bi-ACL, a framework that uses only target-side monolingual data and a bilingual dictionary to improve the performance of the MNMT model. We define two modules, named bidirectional autoencoder and bidirectional contrastive learning, which we combine with an online constrained beam search and a curriculum learning sampling strategy. Extensive experiments show that our proposed method is more effective both in long-tail languages",
    "link": "http://arxiv.org/abs/2305.12786",
    "context": "Title: Mitigating Data Imbalance and Representation Degeneration in Multilingual Machine Translation. (arXiv:2305.12786v2 [cs.CL] UPDATED)\nAbstract: Despite advances in multilingual neural machine translation (MNMT), we argue that there are still two major challenges in this area: data imbalance and representation degeneration. The data imbalance problem refers to the imbalance in the amount of parallel corpora for all language pairs, especially for long-tail languages (i.e., very low-resource languages). The representation degeneration problem refers to the problem of encoded tokens tending to appear only in a small subspace of the full space available to the MNMT model. To solve these two issues, we propose Bi-ACL, a framework that uses only target-side monolingual data and a bilingual dictionary to improve the performance of the MNMT model. We define two modules, named bidirectional autoencoder and bidirectional contrastive learning, which we combine with an online constrained beam search and a curriculum learning sampling strategy. Extensive experiments show that our proposed method is more effective both in long-tail languages",
    "path": "papers/23/05/2305.12786.json",
    "total_tokens": 901,
    "translated_title": "减轻多语言机器翻译中的数据不平衡和表示衰减问题",
    "translated_abstract": "尽管多语言神经机器翻译 (MNMT) 取得了进展，但我们认为在这个领域仍存在两个主要挑战：数据不平衡和表示衰减。数据不平衡问题指的是所有语言对的平行语料数量的不平衡，尤其是对于长尾语种 (即资源极度匮乏的语种)。表示衰减问题指的是编码标记趋向于仅在 MNMT 模型可用的全空间的一个小子空间中出现的问题。为了解决这两个问题，我们提出了Bi-ACL，一个只使用目标语单语数据和双语词典来改善MNMT模型性能的框架。我们定义了两个模块，名为双向自编码器和双向对比学习，它们与在线约束束搜索和课程学习采样策略相结合。大量实验证明我们提出的方法在长尾语种中更有效。",
    "tldr": "本论文提出了一种名为Bi-ACL的框架，它使用目标语单语数据和双语词典来解决多语言机器翻译中的数据不平衡和表示衰减问题。实验证明该方法在长尾语种中效果更好。"
}