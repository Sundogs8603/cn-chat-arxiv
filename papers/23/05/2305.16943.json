{
    "title": "DiffusionNAG: Predictor-guided Neural Architecture Generation with Diffusion Models. (arXiv:2305.16943v3 [cs.LG] UPDATED)",
    "abstract": "Existing NAS methods suffer from either an excessive amount of time for repetitive sampling and training of many task-irrelevant architectures. To tackle such limitations of existing NAS methods, we propose a paradigm shift from NAS to a novel conditional Neural Architecture Generation (NAG) framework based on diffusion models, dubbed DiffusionNAG. Specifically, we consider the neural architectures as directed graphs and propose a graph diffusion model for generating them. Moreover, with the guidance of parameterized predictors, DiffusionNAG can flexibly generate task-optimal architectures with the desired properties for diverse tasks, by sampling from a region that is more likely to satisfy the properties. This conditional NAG scheme is significantly more efficient than previous NAS schemes which sample the architectures and filter them using the property predictors. We validate the effectiveness of DiffusionNAG through extensive experiments in two predictor-based NAS scenarios: Trans",
    "link": "http://arxiv.org/abs/2305.16943",
    "context": "Title: DiffusionNAG: Predictor-guided Neural Architecture Generation with Diffusion Models. (arXiv:2305.16943v3 [cs.LG] UPDATED)\nAbstract: Existing NAS methods suffer from either an excessive amount of time for repetitive sampling and training of many task-irrelevant architectures. To tackle such limitations of existing NAS methods, we propose a paradigm shift from NAS to a novel conditional Neural Architecture Generation (NAG) framework based on diffusion models, dubbed DiffusionNAG. Specifically, we consider the neural architectures as directed graphs and propose a graph diffusion model for generating them. Moreover, with the guidance of parameterized predictors, DiffusionNAG can flexibly generate task-optimal architectures with the desired properties for diverse tasks, by sampling from a region that is more likely to satisfy the properties. This conditional NAG scheme is significantly more efficient than previous NAS schemes which sample the architectures and filter them using the property predictors. We validate the effectiveness of DiffusionNAG through extensive experiments in two predictor-based NAS scenarios: Trans",
    "path": "papers/23/05/2305.16943.json",
    "total_tokens": 861,
    "translated_title": "DiffusionNAG: 基于扩散模型的预测引导神经结构生成",
    "translated_abstract": "现有的神经架构搜索(NAS)方法存在着对许多与任务无关的架构进行重复采样和训练所需的过长时间的问题。为了解决这些问题，我们提出了一种从NAS转向基于扩散模型的新型条件神经结构生成(NAG)框架，命名为DiffusionNAG。具体地，我们将神经结构视为有向图，并提出了一种用于生成神经结构的图扩散模型。此外，在参数化的预测器的指导下，DiffusionNAG可以通过从更有可能满足所需特性的区域中进行采样，灵活生成具有期望特性的任务最优结构。与使用属性预测器对架构进行采样和过滤的先前NAS方案相比，这种条件NAG方案显著更高效。我们通过在两个基于预测器的NAS场景下进行大量实验验证了DiffusionNAG的有效性。",
    "tldr": "DiffusionNAG是一种基于扩散模型的神经结构生成方法，通过考虑神经结构的有向图特性，并结合参数化的预测器的指导，可以更高效地生成具有期望特性的任务最优结构。"
}