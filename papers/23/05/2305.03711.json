{
    "title": "Is dataset condensation a silver bullet for healthcare data sharing?. (arXiv:2305.03711v1 [cs.LG])",
    "abstract": "Safeguarding personal information is paramount for healthcare data sharing, a challenging issue without any silver bullet thus far. We study the prospect of a recent deep-learning advent, dataset condensation (DC), in sharing healthcare data for AI research, and the results are promising. The condensed data abstracts original records and irreversibly conceals individual-level knowledge to achieve a bona fide de-identification, which permits free sharing. Moreover, the original deep-learning utilities are well preserved in the condensed data with compressed volume and accelerated model convergences. In PhysioNet-2012, a condensed dataset of 20 samples can orient deep models attaining 80.3% test AUC of mortality prediction (versus 85.8% of 5120 original records), an inspiring discovery generalised to MIMIC-III and Coswara datasets. We also interpret the inhere privacy protections of DC through theoretical analysis and empirical evidence. Dataset condensation opens a new gate to sharing h",
    "link": "http://arxiv.org/abs/2305.03711",
    "context": "Title: Is dataset condensation a silver bullet for healthcare data sharing?. (arXiv:2305.03711v1 [cs.LG])\nAbstract: Safeguarding personal information is paramount for healthcare data sharing, a challenging issue without any silver bullet thus far. We study the prospect of a recent deep-learning advent, dataset condensation (DC), in sharing healthcare data for AI research, and the results are promising. The condensed data abstracts original records and irreversibly conceals individual-level knowledge to achieve a bona fide de-identification, which permits free sharing. Moreover, the original deep-learning utilities are well preserved in the condensed data with compressed volume and accelerated model convergences. In PhysioNet-2012, a condensed dataset of 20 samples can orient deep models attaining 80.3% test AUC of mortality prediction (versus 85.8% of 5120 original records), an inspiring discovery generalised to MIMIC-III and Coswara datasets. We also interpret the inhere privacy protections of DC through theoretical analysis and empirical evidence. Dataset condensation opens a new gate to sharing h",
    "path": "papers/23/05/2305.03711.json",
    "total_tokens": 892,
    "translated_title": "数据集压缩是医疗数据共享的银弹吗？",
    "translated_abstract": "对于医疗数据共享，保护个人信息至关重要，但目前并没有一个万无一失的方法。本文研究了一种深度学习新技术——数据集压缩，以在医疗人工智能研究中共享数据，结果表明前景广阔。压缩后的数据摘要了原始记录，不可逆地隐藏了个体级别的信息，达到了真正的去识别化，允许自由共享。此外，压缩数据中保留了原始深度学习实用程序，且数据量较小且模型收敛加速。在PhysioNet-2012中，20个样本的压缩数据能够使深度模型达到了80.3%的死亡预测测试AUC（而原始记录为5120个样本的85.8%），这一发现也适用于MIMIC-III和Coswara等数据集。我们还通过理论分析和经验证明了DC的隐私保护性。数据集压缩为共享医疗数据提供了一种新的方法，既保护了隐私又保存了实用程序。",
    "tldr": "数据集压缩为医疗数据共享提供了一种既保护了隐私又保存了实用程序的新方法。",
    "en_tdlr": "Dataset condensation provides a new approach for healthcare data sharing, which not only protects privacy but also preserves utility."
}