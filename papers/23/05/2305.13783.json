{
    "title": "Deep Reinforcement Learning-based Multi-objective Path Planning on the Off-road Terrain Environment for Ground Vehicles. (arXiv:2305.13783v1 [cs.RO])",
    "abstract": "Due to the energy-consumption efficiency between up-slope and down-slope is hugely different, a path with the shortest length on a complex off-road terrain environment (2.5D map) is not always the path with the least energy consumption. For any energy-sensitive vehicles, realizing a good trade-off between distance and energy consumption on 2.5D path planning is significantly meaningful. In this paper, a deep reinforcement learning-based 2.5D multi-objective path planning method (DMOP) is proposed. The DMOP can efficiently find the desired path with three steps: (1) Transform the high-resolution 2.5D map into a small-size map. (2) Use a trained deep Q network (DQN) to find the desired path on the small-size map. (3) Build the planned path to the original high-resolution map using a path enhanced method. In addition, the imitation learning method and reward shaping theory are applied to train the DQN. The reward function is constructed with the information of terrain, distance, border. S",
    "link": "http://arxiv.org/abs/2305.13783",
    "context": "Title: Deep Reinforcement Learning-based Multi-objective Path Planning on the Off-road Terrain Environment for Ground Vehicles. (arXiv:2305.13783v1 [cs.RO])\nAbstract: Due to the energy-consumption efficiency between up-slope and down-slope is hugely different, a path with the shortest length on a complex off-road terrain environment (2.5D map) is not always the path with the least energy consumption. For any energy-sensitive vehicles, realizing a good trade-off between distance and energy consumption on 2.5D path planning is significantly meaningful. In this paper, a deep reinforcement learning-based 2.5D multi-objective path planning method (DMOP) is proposed. The DMOP can efficiently find the desired path with three steps: (1) Transform the high-resolution 2.5D map into a small-size map. (2) Use a trained deep Q network (DQN) to find the desired path on the small-size map. (3) Build the planned path to the original high-resolution map using a path enhanced method. In addition, the imitation learning method and reward shaping theory are applied to train the DQN. The reward function is constructed with the information of terrain, distance, border. S",
    "path": "papers/23/05/2305.13783.json",
    "total_tokens": 934,
    "translated_title": "基于深度强化学习的地面车辆在越野地形环境下的多目标路径规划",
    "translated_abstract": "由于上坡和下坡之间的能耗效率差异巨大，在复杂的越野地形环境（2.5D地图）上，最短路径不一定是能耗最少的路径。对于任何能源敏感的车辆来说，实现距离和能耗在2.5D路径规划上良好的权衡具有重要意义。本文提出了一种基于深度强化学习的2.5D多目标路径规划方法（DMOP）。DMOP可以通过三个步骤高效地找到所需路径：(1)将高分辨率的2.5D地图转换为小尺寸地图。(2)使用训练好的深度Q网络（DQN）在小尺寸地图上找到所需路径。(3)使用路径增强方法将计划路径构建到原始高分辨率地图上。此外，还应用了模仿学习方法和奖励塑造理论来训练DQN。奖励函数结合了地形、距离和边界的信息。",
    "tldr": "本文提出了一种基于深度强化学习的2.5D多目标路径规划方法，可以高效地找到距离和能耗达到良好权衡的路径。",
    "en_tdlr": "This paper proposes a deep reinforcement learning-based multi-objective path planning method on 2.5D maps for ground vehicles, which efficiently finds a path with a good trade-off between distance and energy consumption."
}