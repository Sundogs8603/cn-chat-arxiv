{
    "title": "Controllable Mixed-Initiative Dialogue Generation through Prompting. (arXiv:2305.04147v1 [cs.CL])",
    "abstract": "Mixed-initiative dialogue tasks involve repeated exchanges of information and conversational control. Conversational agents gain control by generating responses that follow particular dialogue intents or strategies, prescribed by a policy planner. The standard approach has been fine-tuning pre-trained language models to perform generation conditioned on these intents. However, these supervised generation models are limited by the cost and quality of data annotation. We instead prompt large language models as a drop-in replacement to fine-tuning on conditional generation. We formalize prompt construction for controllable mixed-initiative dialogue. Our findings show improvements over fine-tuning and ground truth responses according to human evaluation and automatic metrics for two tasks: PersuasionForGood and Emotional Support Conversations.",
    "link": "http://arxiv.org/abs/2305.04147",
    "context": "Title: Controllable Mixed-Initiative Dialogue Generation through Prompting. (arXiv:2305.04147v1 [cs.CL])\nAbstract: Mixed-initiative dialogue tasks involve repeated exchanges of information and conversational control. Conversational agents gain control by generating responses that follow particular dialogue intents or strategies, prescribed by a policy planner. The standard approach has been fine-tuning pre-trained language models to perform generation conditioned on these intents. However, these supervised generation models are limited by the cost and quality of data annotation. We instead prompt large language models as a drop-in replacement to fine-tuning on conditional generation. We formalize prompt construction for controllable mixed-initiative dialogue. Our findings show improvements over fine-tuning and ground truth responses according to human evaluation and automatic metrics for two tasks: PersuasionForGood and Emotional Support Conversations.",
    "path": "papers/23/05/2305.04147.json",
    "total_tokens": 781,
    "translated_title": "通过提示实现可控的混合主动对话生成",
    "translated_abstract": "混合主动对话任务涉及重复交换信息和对话控制。会话代理通过生成响应来获得控制，这些响应按照策略规划器规定的特定对话意图或策略进行。标准方法是微调预训练的语言模型以执行基于这些意图的生成。然而，这些受监督的生成模型受数据注释成本和质量的限制。我们提出用大型语言模型作为条件生成微调的替代方案。我们为可控混合主动对话形式化提示构造。我们的研究表明，在PersuasionForGood和Emotional Support Conversations两个任务中，我们的方法在人类评估和自动指标方面均显示出比微调和真实响应更好的性能。",
    "tldr": "提出了一种新的生成方式，使用大型语言模型作为条件生成微调的替代方案，通过提示构造来实现可控的混合主动对话生成并获得了较好的性能表现。",
    "en_tdlr": "A new generation method using large language models as a drop-in replacement to fine-tuning on conditional generation is proposed to achieve controllable mixed-initiative dialogue generation through prompt construction and has shown better performance in human evaluation and automatic metrics than fine-tuning and ground truth responses in PersuasionForGood and Emotional Support Conversations tasks."
}