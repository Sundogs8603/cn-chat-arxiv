{
    "title": "Quiver: Supporting GPUs for Low-Latency, High-Throughput GNN Serving with Workload Awareness. (arXiv:2305.10863v1 [cs.DC])",
    "abstract": "Systems for serving inference requests on graph neural networks (GNN) must combine low latency with high throughout, but they face irregular computation due to skew in the number of sampled graph nodes and aggregated GNN features. This makes it challenging to exploit GPUs effectively: using GPUs to sample only a few graph nodes yields lower performance than CPU-based sampling; and aggregating many features exhibits high data movement costs between GPUs and CPUs. Therefore, current GNN serving systems use CPUs for graph sampling and feature aggregation, limiting throughput.  We describe Quiver, a distributed GPU-based GNN serving system with low-latency and high-throughput. Quiver's key idea is to exploit workload metrics for predicting the irregular computation of GNN requests, and governing the use of GPUs for graph sampling and feature aggregation: (1) for graph sampling, Quiver calculates the probabilistic sampled graph size, a metric that predicts the degree of parallelism in graph",
    "link": "http://arxiv.org/abs/2305.10863",
    "context": "Title: Quiver: Supporting GPUs for Low-Latency, High-Throughput GNN Serving with Workload Awareness. (arXiv:2305.10863v1 [cs.DC])\nAbstract: Systems for serving inference requests on graph neural networks (GNN) must combine low latency with high throughout, but they face irregular computation due to skew in the number of sampled graph nodes and aggregated GNN features. This makes it challenging to exploit GPUs effectively: using GPUs to sample only a few graph nodes yields lower performance than CPU-based sampling; and aggregating many features exhibits high data movement costs between GPUs and CPUs. Therefore, current GNN serving systems use CPUs for graph sampling and feature aggregation, limiting throughput.  We describe Quiver, a distributed GPU-based GNN serving system with low-latency and high-throughput. Quiver's key idea is to exploit workload metrics for predicting the irregular computation of GNN requests, and governing the use of GPUs for graph sampling and feature aggregation: (1) for graph sampling, Quiver calculates the probabilistic sampled graph size, a metric that predicts the degree of parallelism in graph",
    "path": "papers/23/05/2305.10863.json",
    "total_tokens": 1108,
    "translated_title": "Quiver: 基于工作负载感知的低延迟、高吞吐量的 GNN 服务支持 GPU",
    "translated_abstract": "面向图神经网络 (GNN) 的推理服务系统必须在低延迟和高吞吐量之间取得平衡，但由于采样的图节点和聚合的 GNN 特征存在偏差，系统面临不规则计算的挑战。这使得有效利用 GPU 变得具有挑战性：仅使用 GPU 对少量图节点进行采样的性能低于基于 CPU 的采样；而对许多特征进行聚合会产生 GPU 和 CPU 之间的高数据移动成本。因此，目前的 GNN 服务系统使用 CPU 进行图采样和特征聚合，限制了吞吐量。我们描述了 Quiver，一种分布式基于 GPU 的 GNN 服务系统，具有低延迟和高吞吐量。Quiver 的关键思路是利用工作负载指标来预测 GNN 请求的不规则计算，并管理 GPU 用于图采样和特征聚合：(1) 对于图采样，Quiver 计算概率采样的图大小，这是一种预测图节点采样并行度的指标；(2) 对于特征聚合，Quiver 采用列求和的方式消除数据移动成本。我们的评估表明，Quiver 在实现 94％ 的 GPU 利用率的同时，比现有的 GNN 服务系统性能提高了多达 15 倍。",
    "tldr": "Quiver 是一种分布式基于 GPU 的 GNN 服务系统，通过利用工作负载指标来预测 GNN 请求的不规则计算，并管理 GPU 用于图采样和特征聚合的优化方法，实现了低延迟和高吞吐量，比现有系统性能提高多达 15x。",
    "en_tdlr": "Quiver is a distributed GPU-based GNN serving system that achieves low-latency and high-throughput by utilizing workload metrics to predict irregular GNN computation and govern GPU usage for graph sampling and feature aggregation. Quiver outperforms existing systems by up to 15x while achieving 94% GPU utilization."
}