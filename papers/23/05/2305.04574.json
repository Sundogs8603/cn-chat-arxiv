{
    "title": "TAPS: Connecting Certified and Adversarial Training. (arXiv:2305.04574v2 [cs.LG] UPDATED)",
    "abstract": "Training certifiably robust neural networks remains a notoriously hard problem. On one side, adversarial training optimizes under-approximations of the worst-case loss, which leads to insufficient regularization for certification, while on the other, sound certified training methods optimize loose over-approximations, leading to over-regularization and poor (standard) accuracy. In this work we propose TAPS, an (unsound) certified training method that combines IBP and PGD training to yield precise, although not necessarily sound, worst-case loss approximations, reducing over-regularization and increasing certified and standard accuracies. Empirically, TAPS achieves a new state-of-the-art in many settings, e.g., reaching a certified accuracy of $22\\%$ on TinyImageNet for $\\ell_\\infty$-perturbations with radius $\\epsilon=1/255$. We make our implementation and networks public at https://github.com/eth-sri/taps.",
    "link": "http://arxiv.org/abs/2305.04574",
    "context": "Title: TAPS: Connecting Certified and Adversarial Training. (arXiv:2305.04574v2 [cs.LG] UPDATED)\nAbstract: Training certifiably robust neural networks remains a notoriously hard problem. On one side, adversarial training optimizes under-approximations of the worst-case loss, which leads to insufficient regularization for certification, while on the other, sound certified training methods optimize loose over-approximations, leading to over-regularization and poor (standard) accuracy. In this work we propose TAPS, an (unsound) certified training method that combines IBP and PGD training to yield precise, although not necessarily sound, worst-case loss approximations, reducing over-regularization and increasing certified and standard accuracies. Empirically, TAPS achieves a new state-of-the-art in many settings, e.g., reaching a certified accuracy of $22\\%$ on TinyImageNet for $\\ell_\\infty$-perturbations with radius $\\epsilon=1/255$. We make our implementation and networks public at https://github.com/eth-sri/taps.",
    "path": "papers/23/05/2305.04574.json",
    "total_tokens": 898,
    "translated_title": "TAPS: 连接认证和对抗训练",
    "translated_abstract": "训练可认证鲁棒性神经网络仍然是一个众所周知的难题。一方面，对抗训练优化最坏情况损失的欠缺逼近导致认证的正则化不足，另一方面，声音认证训练方法优化宽松的逼近，导致过度正则化和精度不佳。在这项工作中，我们提出了TAPS，一种结合了IBP和PGD训练的（不一定正确的）认证训练方法，以产生精确但不一定正确的最坏情况损失逼近，从而减少过度正则化并提高认证和标准精度。根据实验证据，TAPS在许多设置中实现了新的最先进水平，例如，在$\\ell_\\infty$扰动半径$\\epsilon=1/255$的TinyImageNet上实现了$22\\%$的认证精度。我们在https://github.com/eth-sri/taps上公开了我们的实现和网络。",
    "tldr": "TAPS是一种结合了IBP和PGD训练的认证训练方法，通过产生精确但不一定正确的最坏情况损失逼近，从而减少过度正则化，并在许多设置中实现了最先进的认证精度。"
}