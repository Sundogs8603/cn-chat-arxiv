{
    "title": "Language-universal phonetic encoder for low-resource speech recognition. (arXiv:2305.11576v1 [eess.AS])",
    "abstract": "Multilingual training is effective in improving low-resource ASR, which may partially be explained by phonetic representation sharing between languages. In end-to-end (E2E) ASR systems, graphemes are often used as basic modeling units, however graphemes may not be ideal for multilingual phonetic sharing. In this paper, we leverage International Phonetic Alphabet (IPA) based language-universal phonetic model to improve low-resource ASR performances, for the first time within the attention encoder-decoder architecture. We propose an adaptation method on the phonetic IPA model to further improve the proposed approach on extreme low-resource languages. Experiments carried out on the open-source MLS corpus and our internal databases show our approach outperforms baseline monolingual models and most state-of-the-art works. Our main approach and adaptation are effective on extremely low-resource languages, even within domain- and language-mismatched scenarios.",
    "link": "http://arxiv.org/abs/2305.11576",
    "context": "Title: Language-universal phonetic encoder for low-resource speech recognition. (arXiv:2305.11576v1 [eess.AS])\nAbstract: Multilingual training is effective in improving low-resource ASR, which may partially be explained by phonetic representation sharing between languages. In end-to-end (E2E) ASR systems, graphemes are often used as basic modeling units, however graphemes may not be ideal for multilingual phonetic sharing. In this paper, we leverage International Phonetic Alphabet (IPA) based language-universal phonetic model to improve low-resource ASR performances, for the first time within the attention encoder-decoder architecture. We propose an adaptation method on the phonetic IPA model to further improve the proposed approach on extreme low-resource languages. Experiments carried out on the open-source MLS corpus and our internal databases show our approach outperforms baseline monolingual models and most state-of-the-art works. Our main approach and adaptation are effective on extremely low-resource languages, even within domain- and language-mismatched scenarios.",
    "path": "papers/23/05/2305.11576.json",
    "total_tokens": 879,
    "translated_title": "语言通用音素编码器用于低资源语音识别",
    "translated_abstract": "多语言训练对于提高低资源语音识别有效，部分原因在于语音表示在不同语言间共享。在端到端语音识别系统中，字素通常被用作基本建模单元，然而字素可能不适用于多语言音素共享。本文中，我们利用以国际音标（IPA）为基础的语言通用音素模型来提高低资源语音识别性能，这是首次应用于注意力编码器-解码器体系架构中。我们提出了一种适应性方法，采用音标IPA模型进一步改进了所提出的方法，以应对极度低资源语言。在开源MLS语料库和内部数据库上进行的实验表明，我们的方法优于基线单语言模型和大多数最先进的工作。我们的主要方法和适应性方法适用于极度低资源语言，甚至包括领域和语言不匹配的情况。",
    "tldr": "本文利用以国际音标为基础的语言通用音素模型，为低资源语音识别提供了有效的改进方法，表现优于基线单语言模型和大多数最先进的工作。",
    "en_tdlr": "This paper proposes a language-universal phonetic model based on the International Phonetic Alphabet (IPA) to improve low-resource speech recognition, which outperforms baseline monolingual models and most state-of-the-art works. The approach and adaptation methods are effective even on extremely low-resource languages in domain- and language-mismatched scenarios."
}