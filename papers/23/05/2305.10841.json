{
    "title": "GETMusic: Generating Any Music Tracks with a Unified Representation and Diffusion Framework. (arXiv:2305.10841v1 [cs.SD])",
    "abstract": "Symbolic music generation aims to create musical notes, which can help users compose music, such as generating target instrumental tracks from scratch, or based on user-provided source tracks. Considering the diverse and flexible combination between source and target tracks, a unified model capable of generating any arbitrary tracks is of crucial necessity. Previous works fail to address this need due to inherent constraints in music representations and model architectures. To address this need, we propose a unified representation and diffusion framework named GETMusic (`GET' stands for GEnerate music Tracks), which includes a novel music representation named GETScore, and a diffusion model named GETDiff. GETScore represents notes as tokens and organizes them in a 2D structure, with tracks stacked vertically and progressing horizontally over time. During training, tracks are randomly selected as either the target or source. In the forward process, target tracks are corrupted by masking",
    "link": "http://arxiv.org/abs/2305.10841",
    "context": "Title: GETMusic: Generating Any Music Tracks with a Unified Representation and Diffusion Framework. (arXiv:2305.10841v1 [cs.SD])\nAbstract: Symbolic music generation aims to create musical notes, which can help users compose music, such as generating target instrumental tracks from scratch, or based on user-provided source tracks. Considering the diverse and flexible combination between source and target tracks, a unified model capable of generating any arbitrary tracks is of crucial necessity. Previous works fail to address this need due to inherent constraints in music representations and model architectures. To address this need, we propose a unified representation and diffusion framework named GETMusic (`GET' stands for GEnerate music Tracks), which includes a novel music representation named GETScore, and a diffusion model named GETDiff. GETScore represents notes as tokens and organizes them in a 2D structure, with tracks stacked vertically and progressing horizontally over time. During training, tracks are randomly selected as either the target or source. In the forward process, target tracks are corrupted by masking",
    "path": "papers/23/05/2305.10841.json",
    "total_tokens": 935,
    "translated_title": "GETMusic：使用统一的表示和扩散框架生成任意音乐曲目",
    "translated_abstract": "符号音乐生成旨在创建音符，为用户创作音乐提供帮助，例如从零开始生成目标乐器轨道或基于用户提供的源轨道进行创作。考虑到源轨道和目标轨道之间的多样化和灵活性组合，需要一个能够生成任意轨道的统一模型至关重要。以往的作品由于音乐表示和模型架构的固有限制而未能解决这个需求。为了解决这个问题，我们提出了一个名为GETMusic（`GET'代表GEnerate music Tracks）的统一表示和扩散框架，其中包括一种新颖的音乐表示GETScore和一个名为GETDiff的扩散型模型。GETScore将音符表示为标记，并在二维结构中井然有序地组织它们，轨道垂直堆叠并水平地随时间推进。在训练过程中，轨道随机被选为目标或源。在前向过程中，使用遮盖对目标轨道进行破坏。",
    "tldr": "GETMusic提出了一种统一的音乐生成模型，包括新颖的音乐表示GETScore和扩散模型GETDiff。GETScore使用标记表示音符，将它们有序地组织起来，而GETDiff使用遮盖对目标轨道进行破坏，能够生成任意轨道。",
    "en_tdlr": "GETMusic proposes a unified music generation model, including a novel music representation GETScore and a diffusion model GETDiff. GETScore represents notes as tokens and organizes them in an orderly manner, while GETDiff corrupts the target tracks by masking and can generate any arbitrary tracks."
}