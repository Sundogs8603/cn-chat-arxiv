{
    "title": "Addressing Parameter Choice Issues in Unsupervised Domain Adaptation by Aggregation. (arXiv:2305.01281v1 [stat.ML])",
    "abstract": "We study the problem of choosing algorithm hyper-parameters in unsupervised domain adaptation, i.e., with labeled data in a source domain and unlabeled data in a target domain, drawn from a different input distribution. We follow the strategy to compute several models using different hyper-parameters, and, to subsequently compute a linear aggregation of the models. While several heuristics exist that follow this strategy, methods are still missing that rely on thorough theories for bounding the target error. In this turn, we propose a method that extends weighted least squares to vector-valued functions, e.g., deep neural networks. We show that the target error of the proposed algorithm is asymptotically not worse than twice the error of the unknown optimal aggregation. We also perform a large scale empirical comparative study on several datasets, including text, images, electroencephalogram, body sensor signals and signals from mobile phones. Our method outperforms deep embedded valid",
    "link": "http://arxiv.org/abs/2305.01281",
    "context": "Title: Addressing Parameter Choice Issues in Unsupervised Domain Adaptation by Aggregation. (arXiv:2305.01281v1 [stat.ML])\nAbstract: We study the problem of choosing algorithm hyper-parameters in unsupervised domain adaptation, i.e., with labeled data in a source domain and unlabeled data in a target domain, drawn from a different input distribution. We follow the strategy to compute several models using different hyper-parameters, and, to subsequently compute a linear aggregation of the models. While several heuristics exist that follow this strategy, methods are still missing that rely on thorough theories for bounding the target error. In this turn, we propose a method that extends weighted least squares to vector-valued functions, e.g., deep neural networks. We show that the target error of the proposed algorithm is asymptotically not worse than twice the error of the unknown optimal aggregation. We also perform a large scale empirical comparative study on several datasets, including text, images, electroencephalogram, body sensor signals and signals from mobile phones. Our method outperforms deep embedded valid",
    "path": "papers/23/05/2305.01281.json",
    "total_tokens": 927,
    "translated_title": "通过聚合解决无监督领域适应中的参数选择问题",
    "translated_abstract": "本文研究了在无监督领域适应中选择算法超参数的问题，即在源域中有标记数据，在目标域中有来自不同输入分布的未标记数据。我们采用计算使用不同超参数的几个模型的策略，然后计算模型的线性聚合。虽然存在几个遵循这种策略的启发式方法，但是仍然缺少依赖于限制目标误差的彻底理论的方法。因此，我们提出了一种方法，将加权最小二乘法扩展到向量值函数（例如深度神经网络）。我们展示了所提出算法的目标误差渐近不劣于未知最佳聚合的两倍。我们还进行了大规模实证比较研究，包括文本、图像、脑电图、身体传感器信号和手机信号等多个数据集。我们的方法优于深度嵌入验证。",
    "tldr": "本文提出了一种使用线性聚合的方法来解决无监督领域适应中的参数选择问题，并且展示了该算法的目标误差渐近不劣于未知最佳聚合的两倍，大规模实证研究表明该方法优于深度嵌入验证。",
    "en_tdlr": "This paper proposes a method using linear aggregation to address the issue of choosing algorithm hyper-parameters in unsupervised domain adaptation, and shows that the proposed algorithm's target error is asymptotically not worse than twice the error of the unknown optimal aggregation. A large-scale empirical comparative study demonstrates that the proposed method outperforms deep embedded validation."
}