{
    "title": "AlignSTS: Speech-to-Singing Conversion via Cross-Modal Alignment. (arXiv:2305.04476v2 [eess.AS] UPDATED)",
    "abstract": "The speech-to-singing (STS) voice conversion task aims to generate singing samples corresponding to speech recordings while facing a major challenge: the alignment between the target (singing) pitch contour and the source (speech) content is difficult to learn in a text-free situation. This paper proposes AlignSTS, an STS model based on explicit cross-modal alignment, which views speech variance such as pitch and content as different modalities. Inspired by the mechanism of how humans will sing the lyrics to the melody, AlignSTS: 1) adopts a novel rhythm adaptor to predict the target rhythm representation to bridge the modality gap between content and pitch, where the rhythm representation is computed in a simple yet effective way and is quantized into a discrete space; and 2) uses the predicted rhythm representation to re-align the content based on cross-attention and conducts a cross-modal fusion for re-synthesize. Extensive experiments show that AlignSTS achieves superior performanc",
    "link": "http://arxiv.org/abs/2305.04476",
    "context": "Title: AlignSTS: Speech-to-Singing Conversion via Cross-Modal Alignment. (arXiv:2305.04476v2 [eess.AS] UPDATED)\nAbstract: The speech-to-singing (STS) voice conversion task aims to generate singing samples corresponding to speech recordings while facing a major challenge: the alignment between the target (singing) pitch contour and the source (speech) content is difficult to learn in a text-free situation. This paper proposes AlignSTS, an STS model based on explicit cross-modal alignment, which views speech variance such as pitch and content as different modalities. Inspired by the mechanism of how humans will sing the lyrics to the melody, AlignSTS: 1) adopts a novel rhythm adaptor to predict the target rhythm representation to bridge the modality gap between content and pitch, where the rhythm representation is computed in a simple yet effective way and is quantized into a discrete space; and 2) uses the predicted rhythm representation to re-align the content based on cross-attention and conducts a cross-modal fusion for re-synthesize. Extensive experiments show that AlignSTS achieves superior performanc",
    "path": "papers/23/05/2305.04476.json",
    "total_tokens": 925,
    "translated_title": "AlignSTS：通过跨模态对齐实现语音转唱",
    "translated_abstract": "语音转唱 (STS) 任务旨在在面对一个主要挑战时，生成与语音录音相对应的唱歌样本：在没有文本的情况下，目标（唱歌）音高轮廓和源（语音）内容之间的对齐难以学习。本文提出了基于显式跨模态对齐的STS模型AlignSTS，将语音变化（如音高和内容）视为不同的模态。受人类如何唱出旋律的歌词机制的启发，AlignSTS: 1）采用一种新颖的节奏适配器来预测目标节奏表示，以弥合内容和音高之间的模态差距，其中节奏表示以简单而有效的方式计算，并量化为离散空间；2）使用预测的节奏表示基于交叉注意力重新对齐内容，并进行跨模态融合重新合成。广泛的实验表明，AlignSTS取得了优越的性能。",
    "tldr": "本文提出了基于跨模态对齐的STS模型AlignSTS，通过一种新颖的节奏适配器来预测目标节奏表示以弥合内容和音高之间的模态差距，并使用交叉注意力重新对齐内容进行跨模态融合重新合成。该模型表现优异。",
    "en_tdlr": "This paper proposes AlignSTS, an STS model based on explicit cross-modal alignment, which uses a novel rhythm adaptor to predict the target rhythm representation and re-align content based on cross-attention for cross-modal fusion and re-synthesis, achieving superior performance in speech-to-singing conversion."
}