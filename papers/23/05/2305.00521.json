{
    "title": "StyleLipSync: Style-based Personalized Lip-sync Video Generation. (arXiv:2305.00521v1 [cs.CV])",
    "abstract": "In this paper, we present StyleLipSync, a style-based personalized lip-sync video generative model that can generate identity-agnostic lip-synchronizing video from arbitrary audio. To generate a video of arbitrary identities, we leverage expressive lip prior from the semantically rich latent space of a pre-trained StyleGAN, where we can also design a video consistency with a linear transformation. In contrast to the previous lip-sync methods, we introduce pose-aware masking that dynamically locates the mask to improve the naturalness over frames by utilizing a 3D parametric mesh predictor frame by frame. Moreover, we propose a few-shot lip-sync adaptation method for an arbitrary person by introducing a sync regularizer that preserves lips-sync generalization while enhancing the person-specific visual information. Extensive experiments demonstrate that our model can generate accurate lip-sync videos even with the zero-shot setting and enhance characteristics of an unseen face using a fe",
    "link": "http://arxiv.org/abs/2305.00521",
    "context": "Title: StyleLipSync: Style-based Personalized Lip-sync Video Generation. (arXiv:2305.00521v1 [cs.CV])\nAbstract: In this paper, we present StyleLipSync, a style-based personalized lip-sync video generative model that can generate identity-agnostic lip-synchronizing video from arbitrary audio. To generate a video of arbitrary identities, we leverage expressive lip prior from the semantically rich latent space of a pre-trained StyleGAN, where we can also design a video consistency with a linear transformation. In contrast to the previous lip-sync methods, we introduce pose-aware masking that dynamically locates the mask to improve the naturalness over frames by utilizing a 3D parametric mesh predictor frame by frame. Moreover, we propose a few-shot lip-sync adaptation method for an arbitrary person by introducing a sync regularizer that preserves lips-sync generalization while enhancing the person-specific visual information. Extensive experiments demonstrate that our model can generate accurate lip-sync videos even with the zero-shot setting and enhance characteristics of an unseen face using a fe",
    "path": "papers/23/05/2305.00521.json",
    "total_tokens": 854,
    "translated_title": "StyleLipSync：基于风格的个性化唇形动画视频生成",
    "translated_abstract": "本文提出了StyleLipSync，这是一种基于风格的个性化唇形动画视频生成模型，它可以从任意音频生成无关身份的唇形同步视频。为了生成任意身份的视频，我们利用了预培训的StyleGAN的语义丰富潜空间中的表达性唇部先验知识，并通过线性变换设计视频一致性。与以往的唇形同步方法不同，我们引入了姿态感知遮罩，通过逐帧利用三维参数化网格预测器动态定位遮罩，提高了帧间自然度。此外，我们还提出了一种几乎不需要数据的唇形同步适应方法，通过引入同步正则化器来保留唇形同步泛化能力，同时增强人物特定的视觉信息。广泛的实验表明，我们的模型可以生成准确的唇形同步视频，甚至可以在零样本设置下增强未见面孔的特征。",
    "tldr": "本文提出了一种基于风格的个性化唇形动画视频生成模型，可以准确地生成任意身份的唇形同步视频，且可用于增强未见面孔的特征。",
    "en_tdlr": "This paper proposes a style-based personalized lip-sync video generation model that can accurately generate lip-sync videos of arbitrary identities and enhance features of unseen faces."
}