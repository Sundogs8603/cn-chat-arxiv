{
    "title": "Target-Side Augmentation for Document-Level Machine Translation. (arXiv:2305.04505v2 [cs.CL] UPDATED)",
    "abstract": "Document-level machine translation faces the challenge of data sparsity due to its long input length and a small amount of training data, increasing the risk of learning spurious patterns. To address this challenge, we propose a target-side augmentation method, introducing a data augmentation (DA) model to generate many potential translations for each source document. Learning on these wider range translations, an MT model can learn a smoothed distribution, thereby reducing the risk of data sparsity. We demonstrate that the DA model, which estimates the posterior distribution, largely improves the MT performance, outperforming the previous best system by 2.30 s-BLEU on News and achieving new state-of-the-art on News and Europarl benchmarks. Our code is available at https://github.com/baoguangsheng/target-side-augmentation.",
    "link": "http://arxiv.org/abs/2305.04505",
    "context": "Title: Target-Side Augmentation for Document-Level Machine Translation. (arXiv:2305.04505v2 [cs.CL] UPDATED)\nAbstract: Document-level machine translation faces the challenge of data sparsity due to its long input length and a small amount of training data, increasing the risk of learning spurious patterns. To address this challenge, we propose a target-side augmentation method, introducing a data augmentation (DA) model to generate many potential translations for each source document. Learning on these wider range translations, an MT model can learn a smoothed distribution, thereby reducing the risk of data sparsity. We demonstrate that the DA model, which estimates the posterior distribution, largely improves the MT performance, outperforming the previous best system by 2.30 s-BLEU on News and achieving new state-of-the-art on News and Europarl benchmarks. Our code is available at https://github.com/baoguangsheng/target-side-augmentation.",
    "path": "papers/23/05/2305.04505.json",
    "total_tokens": 893,
    "translated_title": "面向文本级机器翻译的目标侧数据增强方法",
    "translated_abstract": "文本级机器翻译因其长输入长度和少量的训练数据而面临数据稀疏性的挑战，增加了学习虚假模式的风险。为了应对这一挑战，我们提出了一种目标侧数据增强方法，引入了一个数据增强模型来为每个源文档生成许多潜在的翻译。在这些更广泛的翻译上进行学习，一个MT模型可以学习到一个平滑的分布，从而降低数据稀疏性的风险。我们证明了后验分布估计的DA模型大大提高了MT的性能，在新闻和欧洲议会基准测试上比以前最好的系统高2.30 s-BLEU，并取得了新的最优结果。我们的代码可在 https://github.com/baoguangsheng/target-side-augmentation 找到。",
    "tldr": "本文介绍了一种目标侧数据增强方法，通过引入一个数据增强模型来为每个源文档生成潜在的翻译，从而降低了文本级机器翻译的数据稀疏性的风险，得到了比以前最好的系统高2.30 s-BLEU并在基准测试中取得了新的最优结果。",
    "en_tdlr": "This paper proposes a target-side augmentation method for document-level machine translation, which introduces a data augmentation model to generate potential translations for each source document, reducing the risk of data sparsity and achieving a 2.30 s-BLEU improvement over the previous best system, and new state-of-the-art on News and Europarl benchmarks."
}