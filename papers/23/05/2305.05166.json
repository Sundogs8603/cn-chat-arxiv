{
    "title": "E2TIMT: Efficient and Effective Modal Adapter for Text Image Machine Translation. (arXiv:2305.05166v1 [cs.CL])",
    "abstract": "Text image machine translation (TIMT) aims to translate texts embedded in images from one source language to another target language. Existing methods, both two-stage cascade and one-stage end-to-end architectures, suffer from different issues. The cascade models can benefit from the large-scale optical character recognition (OCR) and MT datasets but the two-stage architecture is redundant. The end-to-end models are efficient but suffer from training data deficiency. To this end, in our paper, we propose an end-to-end TIMT model fully making use of the knowledge from existing OCR and MT datasets to pursue both an effective and efficient framework. More specifically, we build a novel modal adapter effectively bridging the OCR encoder and MT decoder. End-to-end TIMT loss and cross-modal contrastive loss are utilized jointly to align the feature distribution of the OCR and MT tasks. Extensive experiments show that the proposed method outperforms the existing two-stage cascade models and o",
    "link": "http://arxiv.org/abs/2305.05166",
    "context": "Title: E2TIMT: Efficient and Effective Modal Adapter for Text Image Machine Translation. (arXiv:2305.05166v1 [cs.CL])\nAbstract: Text image machine translation (TIMT) aims to translate texts embedded in images from one source language to another target language. Existing methods, both two-stage cascade and one-stage end-to-end architectures, suffer from different issues. The cascade models can benefit from the large-scale optical character recognition (OCR) and MT datasets but the two-stage architecture is redundant. The end-to-end models are efficient but suffer from training data deficiency. To this end, in our paper, we propose an end-to-end TIMT model fully making use of the knowledge from existing OCR and MT datasets to pursue both an effective and efficient framework. More specifically, we build a novel modal adapter effectively bridging the OCR encoder and MT decoder. End-to-end TIMT loss and cross-modal contrastive loss are utilized jointly to align the feature distribution of the OCR and MT tasks. Extensive experiments show that the proposed method outperforms the existing two-stage cascade models and o",
    "path": "papers/23/05/2305.05166.json",
    "total_tokens": 991,
    "translated_title": "E2TIMT: 高效有效的文图机器翻译模态适配器",
    "translated_abstract": "文本图像机器翻译旨在将嵌入图像中的文本从一种源语言翻译成另一种目标语言。现有方法，无论是两阶段级联还是一级端到端架构，都存在不同的问题。级联模型可以受益于大规模的光学字符识别（OCR）和 MT 数据集，但两阶段架构则是冗余的。端到端模型是高效的，但遭受训练数据不足的困扰。因此，在本文中，我们提出了一种端到端TIMT模型，充分利用现有OCR和MT数据集中的知识，追求有效和高效的框架。更具体地说，我们建立了一个新型模态适配器，有效地连接OCR编码器和MT解码器。同时使用端到端TIMT损失和跨模态对比损失来对齐OCR和MT任务的特征分布。大量实验表明，所提出的方法在翻译质量和效率方面优于现有的两阶段级联模型和其他最先进的一级端到端模型。",
    "tldr": "本文提出了一种高效有效的文图机器翻译模态适配器，利用现有OCR和MT数据库和新型模态适配器将OCR编码器和MT解码器连接，使得端到端TIMT模型在翻译质量和效率方面优于现有的两阶段级联模型和其他最先进的一级端到端模型。",
    "en_tdlr": "This paper introduces an efficient and effective modal adapter for text image machine translation (TIMT), utilizing knowledge from existing OCR and MT datasets to connect the OCR encoder and MT decoder with a novel modal adapter. The proposed end-to-end TIMT model outperforms existing models in terms of both translation quality and efficiency."
}