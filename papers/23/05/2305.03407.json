{
    "title": "Online Gesture Recognition using Transformer and Natural Language Processing. (arXiv:2305.03407v1 [cs.CL])",
    "abstract": "The Transformer architecture is shown to provide a powerful machine transduction framework for online handwritten gestures corresponding to glyph strokes of natural language sentences. The attention mechanism is successfully used to create latent representations of an end-to-end encoder-decoder model, solving multi-level segmentation while also learning some language features and syntax rules. The additional use of a large decoding space with some learned Byte-Pair-Encoding (BPE) is shown to provide robustness to ablated inputs and syntax rules. The encoder stack was directly fed with spatio-temporal data tokens potentially forming an infinitely large input vocabulary, an approach that finds applications beyond that of this work. Encoder transfer learning capabilities is also demonstrated on several languages resulting in faster optimisation and shared parameters. A new supervised dataset of online handwriting gestures suitable for generic handwriting recognition tasks was used to succ",
    "link": "http://arxiv.org/abs/2305.03407",
    "context": "Title: Online Gesture Recognition using Transformer and Natural Language Processing. (arXiv:2305.03407v1 [cs.CL])\nAbstract: The Transformer architecture is shown to provide a powerful machine transduction framework for online handwritten gestures corresponding to glyph strokes of natural language sentences. The attention mechanism is successfully used to create latent representations of an end-to-end encoder-decoder model, solving multi-level segmentation while also learning some language features and syntax rules. The additional use of a large decoding space with some learned Byte-Pair-Encoding (BPE) is shown to provide robustness to ablated inputs and syntax rules. The encoder stack was directly fed with spatio-temporal data tokens potentially forming an infinitely large input vocabulary, an approach that finds applications beyond that of this work. Encoder transfer learning capabilities is also demonstrated on several languages resulting in faster optimisation and shared parameters. A new supervised dataset of online handwriting gestures suitable for generic handwriting recognition tasks was used to succ",
    "path": "papers/23/05/2305.03407.json",
    "total_tokens": 923,
    "translated_title": "基于Transformer和自然语言处理的在线手势识别",
    "translated_abstract": "本文使用Transformer架构为自然语言句子的字形笔画提供了强大的在线手写手势机器翻译框架。通过注意力机制，成功地利用了端到端编码器-解码器模型的潜在表示，解决了多级分割问题，同样学习了一些语言特征和句法规则。此外，使用了一些学习的Byte-Pair-Encoding（BPE）的大型解码空间，提供了对语法规则和缺损输入的鲁棒性。编码器堆栈直接获取时空数据令牌，潜在地形成了一个无限大的输入词汇表，这种方法的应用超出了本文的范围。文章还展示了编码器迁移学习的能力，可用于多种语言，结果更快的优化和共享参数。使用了一个新的在线手写手势的监督数据集，适用于通用手写识别任务。",
    "tldr": "本文研究了使用Transformer架构实现在线手势识别，并结合自然语言处理，提出一种解决多级分割问题的机器翻译框架，使用大型解码空间提高对语法规则和缺损输入的鲁棒性。实验结果表明，该方法具有良好的泛化性能，能够用于多种语言和通用手写识别任务。",
    "en_tdlr": "This paper proposes a machine transduction framework for online gesture recognition using Transformer architecture and natural language processing. By utilizing attention mechanism and a large decoding space with learned BPE, it solves multi-level segmentation and improves robustness to ablated inputs and syntax rules. The method is demonstrated to have good transfer learning capabilities and achieves promising results on a new supervised dataset for generic handwriting recognition tasks."
}