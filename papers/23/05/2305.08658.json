{
    "title": "On the connections between optimization algorithms, Lyapunov functions, and differential equations: theory and insights. (arXiv:2305.08658v1 [math.OC])",
    "abstract": "We study connections between differential equations and optimization algorithms for $m$-strongly and $L$-smooth convex functions through the use of Lyapunov functions by generalizing the Linear Matrix Inequality framework developed by Fazylab et al. in 2018. Using the new framework we derive analytically a new (discrete) Lyapunov function for a two-parameter family of Nesterov optimization methods and characterize their convergence rate. This allows us to prove a convergence rate that improves substantially on the previously proven rate of Nesterov's method for the standard choice of coefficients, as well as to characterize the choice of coefficients that yields the optimal rate. We obtain a new Lyapunov function for the Polyak ODE and revisit the connection between this ODE and the Nesterov's algorithms. In addition discuss a new interpretation of Nesterov method as an additive Runge-Kutta discretization and explain the structural conditions that discretizations of the Polyak equation",
    "link": "http://arxiv.org/abs/2305.08658",
    "context": "Title: On the connections between optimization algorithms, Lyapunov functions, and differential equations: theory and insights. (arXiv:2305.08658v1 [math.OC])\nAbstract: We study connections between differential equations and optimization algorithms for $m$-strongly and $L$-smooth convex functions through the use of Lyapunov functions by generalizing the Linear Matrix Inequality framework developed by Fazylab et al. in 2018. Using the new framework we derive analytically a new (discrete) Lyapunov function for a two-parameter family of Nesterov optimization methods and characterize their convergence rate. This allows us to prove a convergence rate that improves substantially on the previously proven rate of Nesterov's method for the standard choice of coefficients, as well as to characterize the choice of coefficients that yields the optimal rate. We obtain a new Lyapunov function for the Polyak ODE and revisit the connection between this ODE and the Nesterov's algorithms. In addition discuss a new interpretation of Nesterov method as an additive Runge-Kutta discretization and explain the structural conditions that discretizations of the Polyak equation",
    "path": "papers/23/05/2305.08658.json",
    "total_tokens": 1055,
    "translated_title": "关于优化算法、李亚普诺夫函数和微分方程的联系：理论与洞见研究",
    "translated_abstract": "本研究通过推广Fazylab等人在2018年发展的线性矩阵不等式框架，研究了用李亚普诺夫函数研究$m$-强凸和$L$-光滑函数的微分方程和优化算法之间的联系。使用新框架，我们针对一个两参数Nesterov优化方法家族的新型（离散）李亚普诺夫函数进行了解析推导，并表征了其收敛速度。这使得我们能够证明对于标准系数的Nesterov方法的先前证明速度有了明显改进，并且表征了产生最佳速度的系数选择。我们为Polyak ODE获得了新的李亚普诺夫函数，并重新审视了此ODE与Nesterov算法之间的联系。此外，讨论了将Nesterov方法解释为加性Runge-Kutta离散化的新方法，并解释了离散化Polyak方程的结构条件。",
    "tldr": "本研究在推广线性矩阵不等式框架的基础上，研究了微分方程和优化算法的联系，提出了针对一个两参数Nesterov优化方法家族新的李亚普诺夫函数并表征其收敛速度，在此基础上证明了有显著改进的Nesterov方法的收敛速度，并确定出产生最佳速度的系数选择。",
    "en_tdlr": "This study examines the connections between differential equations and optimization algorithms, using Lyapunov functions. By deriving a new Lyapunov function for a two-parameter family of Nesterov optimization methods, the study characterizes their convergence rate, improving on previously proven rates. The study also obtains a new Lyapunov function for the Polyak ODE and revisits the connection between this ODE and Nesterov's algorithms. The interpretation of Nesterov method as an additive Runge-Kutta discretization is discussed and the structural conditions of discretizations of the Polyak equation are explained."
}