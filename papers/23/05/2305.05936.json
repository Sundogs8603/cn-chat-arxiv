{
    "title": "Multi-hop Commonsense Knowledge Injection Framework for Zero-Shot Commonsense Question Answering. (arXiv:2305.05936v1 [cs.CL])",
    "abstract": "Commonsense question answering (QA) research requires machines to answer questions based on commonsense knowledge. However, this research requires expensive labor costs to annotate data as the basis of research, and models that rely on fine-tuning paradigms only apply to specific tasks, rather than learn a general commonsense reasoning ability. As a more robust method, zero-shot commonsense question answering shows a good prospect. The current zero-shot framework tries to convert triples in commonsense knowledge graphs (KGs) into QA-form samples as the pre-trained data source to incorporate commonsense knowledge into the model. However, this method ignores the multi-hop relationship in the KG, which is also an important central problem in commonsense reasoning. In this paper, we propose a novel multi-hop commonsense knowledge injection framework. Specifically, it explores multi-hop reasoning paradigm in KGs that conform to linguistic logic, and we further propose two multi-hop QA gener",
    "link": "http://arxiv.org/abs/2305.05936",
    "context": "Title: Multi-hop Commonsense Knowledge Injection Framework for Zero-Shot Commonsense Question Answering. (arXiv:2305.05936v1 [cs.CL])\nAbstract: Commonsense question answering (QA) research requires machines to answer questions based on commonsense knowledge. However, this research requires expensive labor costs to annotate data as the basis of research, and models that rely on fine-tuning paradigms only apply to specific tasks, rather than learn a general commonsense reasoning ability. As a more robust method, zero-shot commonsense question answering shows a good prospect. The current zero-shot framework tries to convert triples in commonsense knowledge graphs (KGs) into QA-form samples as the pre-trained data source to incorporate commonsense knowledge into the model. However, this method ignores the multi-hop relationship in the KG, which is also an important central problem in commonsense reasoning. In this paper, we propose a novel multi-hop commonsense knowledge injection framework. Specifically, it explores multi-hop reasoning paradigm in KGs that conform to linguistic logic, and we further propose two multi-hop QA gener",
    "path": "papers/23/05/2305.05936.json",
    "total_tokens": 1014,
    "translated_title": "多跳公共常识知识注入框架用于零样本常识问答",
    "translated_abstract": "公共常识问答研究需要机器基于常识知识回答问题。然而，这种研究需要昂贵的劳动力成本来注释数据作为研究基础，依赖fine-tuning范式的模型只适用于特定任务，无法学习一般的常识推理能力。作为一种更强大的方法，零样本常识问答显示出良好的前景。当前的零样本框架试图将常识知识图中的三元组转化为QA形式的样本，作为预训练数据源，将常识知识融入模型中。然而，此方法忽略了KG中的多跳关系，这也是常识推理中的一个重要问题。在本文中，我们提出了一种新的多跳公共常识知识注入框架。具体来说，它探索符合语言逻辑的KG中的多跳推理范式，并进一步提出了两种基于所提出的框架的多跳QA生成模式。实验表明，所提出的框架在两个零样本常识QA基准数据集上的表现优于以前的最先进模型。",
    "tldr": "本文提出了一个多跳公共常识知识注入框架用于零样本常识问答，使用符合语言逻辑的多跳推理范式，提高了对多跳关系的识别能力，并在两个基准数据集上表现出了更好的效果。",
    "en_tdlr": "This paper proposes a multi-hop commonsense knowledge injection framework for zero-shot commonsense question answering, which incorporates linguistic logic to improve the recognition of multi-hop relationships and outperforms previous state-of-the-art models on two benchmark datasets."
}