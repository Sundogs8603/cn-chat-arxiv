{
    "title": "Neural Boltzmann Machines. (arXiv:2305.08337v1 [cs.LG])",
    "abstract": "Conditional generative models are capable of using contextual information as input to create new imaginative outputs. Conditional Restricted Boltzmann Machines (CRBMs) are one class of conditional generative models that have proven to be especially adept at modeling noisy discrete or continuous data, but the lack of expressivity in CRBMs have limited their widespread adoption. Here we introduce Neural Boltzmann Machines (NBMs) which generalize CRBMs by converting each of the CRBM parameters to their own neural networks that are allowed to be functions of the conditional inputs. NBMs are highly flexible conditional generative models that can be trained via stochastic gradient descent to approximately maximize the log-likelihood of the data. We demonstrate the utility of NBMs especially with normally distributed data which has historically caused problems for Gaussian-Bernoulli CRBMs. Code to reproduce our results can be found at https://github.com/unlearnai/neural-boltzmann-machines.",
    "link": "http://arxiv.org/abs/2305.08337",
    "context": "Title: Neural Boltzmann Machines. (arXiv:2305.08337v1 [cs.LG])\nAbstract: Conditional generative models are capable of using contextual information as input to create new imaginative outputs. Conditional Restricted Boltzmann Machines (CRBMs) are one class of conditional generative models that have proven to be especially adept at modeling noisy discrete or continuous data, but the lack of expressivity in CRBMs have limited their widespread adoption. Here we introduce Neural Boltzmann Machines (NBMs) which generalize CRBMs by converting each of the CRBM parameters to their own neural networks that are allowed to be functions of the conditional inputs. NBMs are highly flexible conditional generative models that can be trained via stochastic gradient descent to approximately maximize the log-likelihood of the data. We demonstrate the utility of NBMs especially with normally distributed data which has historically caused problems for Gaussian-Bernoulli CRBMs. Code to reproduce our results can be found at https://github.com/unlearnai/neural-boltzmann-machines.",
    "path": "papers/23/05/2305.08337.json",
    "total_tokens": 887,
    "translated_title": "神经玻尔兹曼机",
    "translated_abstract": "条件生成模型能够使用上下文信息作为输入来生成新的创造性输出。条件受限波尔兹曼机(CRBM)是一类条件生成模型，其已经被证明在建模嘈杂的离散或连续数据方面特别擅长，但CRBM的表达能力有限制限制了它们的广泛采用。在这里，我们引入了神经玻尔兹曼机(NBM)，通过将每个CRBM参数转换为自己的神经网络来将CRBM推广，这些网络允许是条件输入的函数。NBM是高度灵活的条件生成模型，可以通过随机梯度下降进行训练，以近似地最大化数据的对数似然。我们展示了NBM的实用性，特别是在通常造成高斯-伯努利CRBM问题的正常分布数据方面。可以在https://github.com/unlearnai/neural-boltzmann-machines找到用于重现我们结果的代码。",
    "tldr": "发布了一种新的条件生成模型——神经玻尔兹曼机(NBM)，其可通过将CRBM参数转换为神经网络将CRBM推广，并成功地解决了高斯-伯努利CRBM在模拟正常分布数据上的限制。",
    "en_tdlr": "Neural Boltzmann Machines (NBM) is proposed as a new type of conditional generative model which generalizes Conditional Restricted Boltzmann Machines (CRBMs) by converting each CRBM parameter to its own neural network. It successfully tackles the limitation of Gaussian-Bernoulli CRBMs when modeling normally distributed data."
}