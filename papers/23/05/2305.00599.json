{
    "title": "StyleGenes: Discrete and Efficient Latent Distributions for GANs. (arXiv:2305.00599v1 [cs.CV])",
    "abstract": "We propose a discrete latent distribution for Generative Adversarial Networks (GANs). Instead of drawing latent vectors from a continuous prior, we sample from a finite set of learnable latents. However, a direct parametrization of such a distribution leads to an intractable linear increase in memory in order to ensure sufficient sample diversity. We address this key issue by taking inspiration from the encoding of information in biological organisms. Instead of learning a separate latent vector for each sample, we split the latent space into a set of genes. For each gene, we train a small bank of gene variants. Thus, by independently sampling a variant for each gene and combining them into the final latent vector, our approach can represent a vast number of unique latent samples from a compact set of learnable parameters. Interestingly, our gene-inspired latent encoding allows for new and intuitive approaches to latent-space exploration, enabling conditional sampling from our uncondit",
    "link": "http://arxiv.org/abs/2305.00599",
    "context": "Title: StyleGenes: Discrete and Efficient Latent Distributions for GANs. (arXiv:2305.00599v1 [cs.CV])\nAbstract: We propose a discrete latent distribution for Generative Adversarial Networks (GANs). Instead of drawing latent vectors from a continuous prior, we sample from a finite set of learnable latents. However, a direct parametrization of such a distribution leads to an intractable linear increase in memory in order to ensure sufficient sample diversity. We address this key issue by taking inspiration from the encoding of information in biological organisms. Instead of learning a separate latent vector for each sample, we split the latent space into a set of genes. For each gene, we train a small bank of gene variants. Thus, by independently sampling a variant for each gene and combining them into the final latent vector, our approach can represent a vast number of unique latent samples from a compact set of learnable parameters. Interestingly, our gene-inspired latent encoding allows for new and intuitive approaches to latent-space exploration, enabling conditional sampling from our uncondit",
    "path": "papers/23/05/2305.00599.json",
    "total_tokens": 929,
    "translated_title": "StyleGenes: GANs的离散高效潜在分布",
    "translated_abstract": "我们提出了一种适用于生成对抗网络（GANs）的离散潜在分布。我们从一个可学习的有限潜在组中采样，而不是从连续的先验中绘制潜在向量。然而，直接参数化这种分布会导致内存的线性增加，以确保足够的样本多样性。我们通过从生物体中获得灵感来解决这个关键问题。我们将潜在空间分成一组基因，对于每个基因，我们训练一个小的基因变体库。因此，通过独立地对每个基因采样变体，然后将它们组合成最终的潜在向量，我们的方法可以用少量的可学习参数表示大量的唯一潜在样本。有趣的是，我们基于基因的潜在编码允许新的和直观的潜在空间探索方法，使得从我们的无条件模型中进行条件采样类似于创建角色的互动游戏。",
    "tldr": "我们提出了一种离散的潜在分布来代替连续的先验分布，这种基于基因的潜在编码可以通过少量可学习参数表示大量唯一的潜在样本，并且提供了新的直观的潜在空间探索方法。",
    "en_tdlr": "We propose a discrete latent distribution for GANs, which is based on gene-inspired latent encoding to represent a vast number of unique latent samples from a compact set of learnable parameters, and enabling new and intuitive approaches to latent-space exploration."
}