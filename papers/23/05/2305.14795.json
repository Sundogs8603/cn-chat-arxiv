{
    "title": "MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions. (arXiv:2305.14795v1 [cs.CL])",
    "abstract": "The information stored in large language models (LLMs) falls out of date quickly, and retraining from scratch is often not an option. This has recently given rise to a range of techniques for injecting new facts through updating model weights. Current evaluation paradigms are extremely limited, mainly validating the recall of edited facts, but changing one fact should cause rippling changes to the model's related beliefs. If we edit the UK Prime Minister to now be Rishi Sunak, then we should get a different answer to Who is married to the British Prime Minister? In this work, we present a benchmark MQuAKE (Multi-hop Question Answering for Knowledge Editing) comprising multi-hop questions that assess whether edited models correctly answer questions where the answer should change as an entailed consequence of edited facts. While we find that current knowledge-editing approaches can recall edited facts accurately, they fail catastrophically on the constructed multi-hop questions. We thus ",
    "link": "http://arxiv.org/abs/2305.14795",
    "context": "Title: MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions. (arXiv:2305.14795v1 [cs.CL])\nAbstract: The information stored in large language models (LLMs) falls out of date quickly, and retraining from scratch is often not an option. This has recently given rise to a range of techniques for injecting new facts through updating model weights. Current evaluation paradigms are extremely limited, mainly validating the recall of edited facts, but changing one fact should cause rippling changes to the model's related beliefs. If we edit the UK Prime Minister to now be Rishi Sunak, then we should get a different answer to Who is married to the British Prime Minister? In this work, we present a benchmark MQuAKE (Multi-hop Question Answering for Knowledge Editing) comprising multi-hop questions that assess whether edited models correctly answer questions where the answer should change as an entailed consequence of edited facts. While we find that current knowledge-editing approaches can recall edited facts accurately, they fail catastrophically on the constructed multi-hop questions. We thus ",
    "path": "papers/23/05/2305.14795.json",
    "total_tokens": 1002,
    "translated_title": "MQuAKE：通过多跳问题评估语言模型中的知识编辑",
    "translated_abstract": "大型语言模型（LLM）中存储的信息很快就会过时，重新训练并非总是可行的选择。这促使人们开发了通过更新模型权重注入新事实的一系列技术。当前的评估方法非常有限，主要验证编辑事实的召回率，但更改一个事实应该会对模型的相关信念产生连锁反应。如果我们编辑英国首相为Rishi Sunak，那么对于“谁是英国首相的配偶”这个问题，我们应该得到一个不同的答案。在这项工作中，我们提出了一个基准MQuAKE（用于知识编辑的多跳问答），包括多跳问题，评估编辑后的模型是否正确回答那些因编辑事实而答案应该改变的问题。虽然我们发现当前的知识编辑方法可以准确召回已编辑的事实，但它们在构建的多跳问题上遭遇了灾难性失败。因此，我们建议对LLMs的评估必须超越简单的事实召回，并纳入更微妙的知识编辑质量评估。",
    "tldr": "本文提出了一种基准测试MQuAKE，通过多跳问题评估编辑模型是否能够正确回答因编辑事实而答案应该改变的问题。研究发现当前的知识编辑方法可以准确召回已编辑的事实，但在多跳问题上表现灾难性失败。",
    "en_tdlr": "This paper proposes a benchmark MQuAKE, which evaluates whether edited models correctly answer questions where the answer should change as a consequence of edited facts via multi-hop questions. The study finds that current knowledge-editing approaches can recall edited facts accurately, but fail catastrophically on the constructed multi-hop questions, suggesting the need for more nuanced assessments of knowledge editing quality."
}