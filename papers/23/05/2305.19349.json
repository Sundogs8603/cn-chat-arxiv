{
    "title": "On Riemannian Projection-free Online Learning. (arXiv:2305.19349v1 [cs.LG])",
    "abstract": "The projection operation is a critical component in a wide range of optimization algorithms, such as online gradient descent (OGD), for enforcing constraints and achieving optimal regret bounds. However, it suffers from computational complexity limitations in high-dimensional settings or when dealing with ill-conditioned constraint sets. Projection-free algorithms address this issue by replacing the projection oracle with more efficient optimization subroutines. But to date, these methods have been developed primarily in the Euclidean setting, and while there has been growing interest in optimization on Riemannian manifolds, there has been essentially no work in trying to utilize projection-free tools here. An apparent issue is that non-trivial affine functions are generally non-convex in such domains. In this paper, we present methods for obtaining sub-linear regret guarantees in online geodesically convex optimization on curved spaces for two scenarios: when we have access to (a) a s",
    "link": "http://arxiv.org/abs/2305.19349",
    "context": "Title: On Riemannian Projection-free Online Learning. (arXiv:2305.19349v1 [cs.LG])\nAbstract: The projection operation is a critical component in a wide range of optimization algorithms, such as online gradient descent (OGD), for enforcing constraints and achieving optimal regret bounds. However, it suffers from computational complexity limitations in high-dimensional settings or when dealing with ill-conditioned constraint sets. Projection-free algorithms address this issue by replacing the projection oracle with more efficient optimization subroutines. But to date, these methods have been developed primarily in the Euclidean setting, and while there has been growing interest in optimization on Riemannian manifolds, there has been essentially no work in trying to utilize projection-free tools here. An apparent issue is that non-trivial affine functions are generally non-convex in such domains. In this paper, we present methods for obtaining sub-linear regret guarantees in online geodesically convex optimization on curved spaces for two scenarios: when we have access to (a) a s",
    "path": "papers/23/05/2305.19349.json",
    "total_tokens": 835,
    "translated_title": "关于黎曼流形上无投影在线学习的研究",
    "translated_abstract": "投影操作是许多优化算法（例如在线梯度下降[OGD]）中强制约束和实现最优遗憾边界所必需的关键组成部分。然而，当处理高维设置或具有病态约束集时，它会受到计算复杂度限制。无投影算法通过用更有效的优化子程序取代投影预测来解决此问题。但到目前为止，这些方法主要在欧几里得设置中开发，并且虽然越来越多地关注黎曼流形上的优化，但在尝试利用无投影工具方面基本上没有工作。一个明显的问题是，在这些领域中，非平凡的仿射函数通常是非凸的。在本文中，我们提出了一种方法，在曲线空间上进行在线测地凸优化，以获得两种情况下的次线性遗憾保证：当我们访问（a）时",
    "tldr": "本文提出了一种针对非凸约束集情况下的曲线空间在线测地凸优化的无投影算法，获得了次线性遗憾保证。"
}