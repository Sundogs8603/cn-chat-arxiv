{
    "title": "Parallelized Acquisition for Active Learning using Monte Carlo Sampling. (arXiv:2305.19267v1 [stat.ML])",
    "abstract": "Bayesian inference remains one of the most important tool-kits for any scientist, but increasingly expensive likelihood functions are required for ever-more complex experiments, raising the cost of generating a Monte Carlo sample of the posterior. Recent attention has been directed towards the use of emulators of the posterior based on Gaussian Process (GP) regression combined with active sampling to achieve comparable precision with far fewer costly likelihood evaluations. Key to this approach is the batched acquisition of proposals, so that the true posterior can be evaluated in parallel. This is usually achieved via sequential maximization of the highly multimodal acquisition function. Unfortunately, this approach parallelizes poorly and is prone to getting stuck in local maxima. Our approach addresses this issue by generating nearly-optimal batches of candidates using an almost-embarrassingly parallel Nested Sampler on the mean prediction of the GP. The resulting nearly-sorted Mont",
    "link": "http://arxiv.org/abs/2305.19267",
    "context": "Title: Parallelized Acquisition for Active Learning using Monte Carlo Sampling. (arXiv:2305.19267v1 [stat.ML])\nAbstract: Bayesian inference remains one of the most important tool-kits for any scientist, but increasingly expensive likelihood functions are required for ever-more complex experiments, raising the cost of generating a Monte Carlo sample of the posterior. Recent attention has been directed towards the use of emulators of the posterior based on Gaussian Process (GP) regression combined with active sampling to achieve comparable precision with far fewer costly likelihood evaluations. Key to this approach is the batched acquisition of proposals, so that the true posterior can be evaluated in parallel. This is usually achieved via sequential maximization of the highly multimodal acquisition function. Unfortunately, this approach parallelizes poorly and is prone to getting stuck in local maxima. Our approach addresses this issue by generating nearly-optimal batches of candidates using an almost-embarrassingly parallel Nested Sampler on the mean prediction of the GP. The resulting nearly-sorted Mont",
    "path": "papers/23/05/2305.19267.json",
    "total_tokens": 985,
    "translated_title": "蒙特卡罗采样下基于高斯过程回归的主动学习中并行获取样本的研究",
    "translated_abstract": "贝叶斯推断仍然是任何科学家最重要的工具之一，但是随着越来越复杂的实验需要越来越昂贵的似然函数，生成后验概率的蒙特卡罗样本的成本也在增加。最近，基于高斯过程回归的后验近似模拟器和主动采样的结合引起了人们的关注，以实现在更少的似然函数评估的情况下获得可比较的精度。该方法的关键在于批量获取建议，以便可以并行评估真正的后验概率。这通常通过连续最大化高度多峰的获取函数来实现。不幸的是，这种方法的并行处理效果不好，容易陷入局部最大值。我们的方法通过在高斯过程回归的平均预测上进行几乎尴尬地并行分层采样来解决这个问题。因此产生的几乎排序的蒙特卡罗样本可以并行评估，从而在保持近似后验的准确性的同时实现显著加速。",
    "tldr": "本文介绍了一种基于高斯过程回归和主动采样的后验模拟器的方法，通过在均值预测上进行分级采样，在保持准确性的前提下实现了蒙特卡洛采样的并行处理，有效降低了成本。",
    "en_tdlr": "This paper presents a method for parallelized acquisition of Monte Carlo samples in active learning using Gaussian Process regression and active sampling. The method uses almost-embarrassingly parallel Nested Sampler to generate nearly-optimal batches of candidates, allowing for significant speedup while maintaining accuracy of the approximate posterior."
}