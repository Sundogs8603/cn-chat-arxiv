{
    "title": "FACTUAL: A Benchmark for Faithful and Consistent Textual Scene Graph Parsing. (arXiv:2305.17497v2 [cs.CL] UPDATED)",
    "abstract": "Textual scene graph parsing has become increasingly important in various vision-language applications, including image caption evaluation and image retrieval. However, existing scene graph parsers that convert image captions into scene graphs often suffer from two types of errors. First, the generated scene graphs fail to capture the true semantics of the captions or the corresponding images, resulting in a lack of faithfulness. Second, the generated scene graphs have high inconsistency, with the same semantics represented by different annotations.  To address these challenges, we propose a novel dataset, which involves re-annotating the captions in Visual Genome (VG) using a new intermediate representation called FACTUAL-MR. FACTUAL-MR can be directly converted into faithful and consistent scene graph annotations. Our experimental results clearly demonstrate that the parser trained on our dataset outperforms existing approaches in terms of faithfulness and consistency. This improvemen",
    "link": "http://arxiv.org/abs/2305.17497",
    "context": "Title: FACTUAL: A Benchmark for Faithful and Consistent Textual Scene Graph Parsing. (arXiv:2305.17497v2 [cs.CL] UPDATED)\nAbstract: Textual scene graph parsing has become increasingly important in various vision-language applications, including image caption evaluation and image retrieval. However, existing scene graph parsers that convert image captions into scene graphs often suffer from two types of errors. First, the generated scene graphs fail to capture the true semantics of the captions or the corresponding images, resulting in a lack of faithfulness. Second, the generated scene graphs have high inconsistency, with the same semantics represented by different annotations.  To address these challenges, we propose a novel dataset, which involves re-annotating the captions in Visual Genome (VG) using a new intermediate representation called FACTUAL-MR. FACTUAL-MR can be directly converted into faithful and consistent scene graph annotations. Our experimental results clearly demonstrate that the parser trained on our dataset outperforms existing approaches in terms of faithfulness and consistency. This improvemen",
    "path": "papers/23/05/2305.17497.json",
    "total_tokens": 893,
    "translated_title": "FACTUAL: 一个用于准确文本场景图解析的基准测试",
    "translated_abstract": "文本场景图解析在各种视觉语言应用中变得越来越重要，包括图像描述评估和图像检索。然而，将图像标题转换为场景图的现有解析器经常遭受两种类型的错误。首先，生成的场景图未能捕捉标题或相应图像的真实语义，导致缺乏准确性。其次，生成的场景图具有高度不一致性，相同的语义由不同的注释表示。为了应对这些挑战，我们提出了一个新的数据集，该数据集采用称为FACTUAL-MR的新中间表示对Visual Genome（VG）中的标题进行重新注释。 FACTUAL-MR 可以直接转换为准确和一致的场景图注释。我们的实验结果清楚地表明，在准确性和一致性方面，我们数据集上训练的解析器优于现有方法。这种改进对于需要精确的文本场景图分析的视觉语言任务具有重要意义。",
    "tldr": "研究提出了一个新数据集FACTUAL-MR，该数据集用于准确文本场景图解析，这样可以避免现有解析器出现的准确性和一致性问题，该方法在各种视觉语言任务中具有重要意义。",
    "en_tdlr": "A new dataset FACTUAL-MR is proposed for accurate textual scene graph parsing, which addresses the issues of accuracy and consistency in existing parsers. The method has significant implications for various vision-language tasks."
}