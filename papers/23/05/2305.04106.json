{
    "title": "On the Usage of Continual Learning for Out-of-Distribution Generalization in Pre-trained Language Models of Code. (arXiv:2305.04106v1 [cs.SE])",
    "abstract": "Pre-trained language models (PLMs) have become a prevalent technique in deep learning for code, utilizing a two-stage pre-training and fine-tuning procedure to acquire general knowledge about code and specialize in a variety of downstream tasks. However, the dynamic nature of software codebases poses a challenge to the effectiveness and robustness of PLMs. In particular, world-realistic scenarios potentially lead to significant differences between the distribution of the pre-training and test data, i.e., distribution shift, resulting in a degradation of the PLM's performance on downstream tasks. In this paper, we stress the need for adapting PLMs of code to software data whose distribution changes over time, a crucial problem that has been overlooked in previous works. The motivation of this work is to consider the PLM in a non-stationary environment, where fine-tuning data evolves over time according to a software evolution scenario. Specifically, we design a scenario where the model ",
    "link": "http://arxiv.org/abs/2305.04106",
    "context": "Title: On the Usage of Continual Learning for Out-of-Distribution Generalization in Pre-trained Language Models of Code. (arXiv:2305.04106v1 [cs.SE])\nAbstract: Pre-trained language models (PLMs) have become a prevalent technique in deep learning for code, utilizing a two-stage pre-training and fine-tuning procedure to acquire general knowledge about code and specialize in a variety of downstream tasks. However, the dynamic nature of software codebases poses a challenge to the effectiveness and robustness of PLMs. In particular, world-realistic scenarios potentially lead to significant differences between the distribution of the pre-training and test data, i.e., distribution shift, resulting in a degradation of the PLM's performance on downstream tasks. In this paper, we stress the need for adapting PLMs of code to software data whose distribution changes over time, a crucial problem that has been overlooked in previous works. The motivation of this work is to consider the PLM in a non-stationary environment, where fine-tuning data evolves over time according to a software evolution scenario. Specifically, we design a scenario where the model ",
    "path": "papers/23/05/2305.04106.json",
    "total_tokens": 1097,
    "translated_title": "对预训练语言模型在非平稳环境下对代码进行持续学习以实现超出分布的泛化",
    "translated_abstract": "学习预训练语言模型（PLMs）已成为深度学习代码中的普遍技术，利用两阶段的预训练和微调过程获取关于代码的通用知识并专门从事各种下游任务。然而，软件代码库的动态性对PLMs的有效性和鲁棒性构成挑战。本文强调需要调整适应代码的PLMs，适应分布会随时间变化的软件数据，这是之前的研究所忽视的一个关键问题。本文的动机是将PLM视为一个在非平稳环境下的模型，有助于模型在应对演化的软件数据时具有更好的泛化能力。",
    "tldr": "本文强调预训练语言模型需要对代码进行持续学习以适应变化的软件数据分布，使其具有更好的泛化能力。"
}