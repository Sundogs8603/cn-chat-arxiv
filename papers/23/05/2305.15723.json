{
    "title": "Learning across Data Owners with Joint Differential Privacy. (arXiv:2305.15723v1 [cs.LG])",
    "abstract": "In this paper, we study the setting in which data owners train machine learning models collaboratively under a privacy notion called joint differential privacy [Kearns et al., 2018]. In this setting, the model trained for each data owner $j$ uses $j$'s data without privacy consideration and other owners' data with differential privacy guarantees. This setting was initiated in [Jain et al., 2021] with a focus on linear regressions. In this paper, we study this setting for stochastic convex optimization (SCO). We present an algorithm that is a variant of DP-SGD [Song et al., 2013; Abadi et al., 2016] and provides theoretical bounds on its population loss. We compare our algorithm to several baselines and discuss for what parameter setups our algorithm is more preferred. We also empirically study joint differential privacy in the multi-class classification problem over two public datasets. Our empirical findings are well-connected to the insights from our theoretical results.",
    "link": "http://arxiv.org/abs/2305.15723",
    "context": "Title: Learning across Data Owners with Joint Differential Privacy. (arXiv:2305.15723v1 [cs.LG])\nAbstract: In this paper, we study the setting in which data owners train machine learning models collaboratively under a privacy notion called joint differential privacy [Kearns et al., 2018]. In this setting, the model trained for each data owner $j$ uses $j$'s data without privacy consideration and other owners' data with differential privacy guarantees. This setting was initiated in [Jain et al., 2021] with a focus on linear regressions. In this paper, we study this setting for stochastic convex optimization (SCO). We present an algorithm that is a variant of DP-SGD [Song et al., 2013; Abadi et al., 2016] and provides theoretical bounds on its population loss. We compare our algorithm to several baselines and discuss for what parameter setups our algorithm is more preferred. We also empirically study joint differential privacy in the multi-class classification problem over two public datasets. Our empirical findings are well-connected to the insights from our theoretical results.",
    "path": "papers/23/05/2305.15723.json",
    "total_tokens": 789,
    "translated_title": "利用联合差分隐私实现数据持有者之间的联合学习",
    "translated_abstract": "本文研究了一种称为联合差分隐私的隐私保护方法，其在多个数据持有者协同训练机器学习模型的场景下得到了应用。在这种场景下，对于每个数据持有者$j$，使用$j$的数据进行模型训练时不考虑隐私问题，而使用其他持有者的数据则会提供差分隐私保证。我们专注于针对随机凸优化问题展开研究，提出了一个理论上保证的算法，同时在两个公共数据集上针对多类分类问题进行了实证研究。",
    "tldr": "本文研究了利用联合差分隐私实现数据持有者之间的联合学习的方法，并针对随机凸优化问题提出了一个理论上保证的算法，在多类分类问题上也进行了实际研究。",
    "en_tdlr": "This paper studies the approach of using joint differential privacy for collaborative learning among data owners, and proposes a theoretically guaranteed algorithm for stochastic convex optimization problem, as well as conducting empirical research on multi-class classification problem."
}