{
    "title": "Which Features are Learnt by Contrastive Learning? On the Role of Simplicity Bias in Class Collapse and Feature Suppression. (arXiv:2305.16536v1 [cs.LG])",
    "abstract": "Contrastive learning (CL) has emerged as a powerful technique for representation learning, with or without label supervision. However, supervised CL is prone to collapsing representations of subclasses within a class by not capturing all their features, and unsupervised CL may suppress harder class-relevant features by focusing on learning easy class-irrelevant features; both significantly compromise representation quality. Yet, there is no theoretical understanding of \\textit{class collapse} or \\textit{feature suppression} at \\textit{test} time. We provide the first unified theoretically rigorous framework to determine \\textit{which} features are learnt by CL. Our analysis indicate that, perhaps surprisingly, bias of (stochastic) gradient descent towards finding simpler solutions is a key factor in collapsing subclass representations and suppressing harder class-relevant features. Moreover, we present increasing embedding dimensionality and improving the quality of data augmentations ",
    "link": "http://arxiv.org/abs/2305.16536",
    "context": "Title: Which Features are Learnt by Contrastive Learning? On the Role of Simplicity Bias in Class Collapse and Feature Suppression. (arXiv:2305.16536v1 [cs.LG])\nAbstract: Contrastive learning (CL) has emerged as a powerful technique for representation learning, with or without label supervision. However, supervised CL is prone to collapsing representations of subclasses within a class by not capturing all their features, and unsupervised CL may suppress harder class-relevant features by focusing on learning easy class-irrelevant features; both significantly compromise representation quality. Yet, there is no theoretical understanding of \\textit{class collapse} or \\textit{feature suppression} at \\textit{test} time. We provide the first unified theoretically rigorous framework to determine \\textit{which} features are learnt by CL. Our analysis indicate that, perhaps surprisingly, bias of (stochastic) gradient descent towards finding simpler solutions is a key factor in collapsing subclass representations and suppressing harder class-relevant features. Moreover, we present increasing embedding dimensionality and improving the quality of data augmentations ",
    "path": "papers/23/05/2305.16536.json",
    "total_tokens": 916,
    "translated_title": "对比学习学到了哪些特征？关于简易偏差在类坍塌和特征抑制中的作用",
    "translated_abstract": "对比学习具备无监督和有监督学习的表示学习技术，在有监督场景下易于坍塌同一类别内的子类表示，丢失一部分特征信息；而无监督学习则可能通过学习易于处理的类别无关特征而无视一些类别相关的复杂特征信息，这两种方法都会显著地降低表征的质量。本文提出了第一个统一严谨的框架来理解测试时的类坍塌和特征抑制产生的原因，相关分析表明，（随机）梯度下降方法偏向于寻找更简单的解决方案是导致子类表示坍塌和类别相关的复杂特征被抑制的关键因素。此外，我们利用提高嵌入维度和改进数据增强的方法来提供有效的预防措施。",
    "tldr": "对比学习是一种表示学习技术，对于有监督的情况易于产生类坍塌，无监督情况下易于抑制类别相关的复杂特征；随机梯度下降方法偏向于寻找更简单的解决方案是导致这种现象的关键因素。"
}