{
    "title": "TempoSum: Evaluating the Temporal Generalization of Abstractive Summarization. (arXiv:2305.01951v1 [cs.CL])",
    "abstract": "Recent pre-trained language models (PLMs) achieve promising results in existing abstractive summarization datasets. However, existing summarization benchmarks overlap in time with the standard pre-training corpora and finetuning datasets. Hence, the strong performance of PLMs may rely on the parametric knowledge that is memorized during pre-training and fine-tuning. Moreover, the knowledge memorized by PLMs may quickly become outdated, which affects the generalization performance of PLMs on future data. In this work, we propose TempoSum, a novel benchmark that contains data samples from 2010 to 2022, to understand the temporal generalization ability of abstractive summarization models. Through extensive human evaluation, we show that parametric knowledge stored in summarization models significantly affects the faithfulness of the generated summaries on future data. Moreover, existing faithfulness enhancement methods cannot reliably improve the faithfulness of summarization models on fu",
    "link": "http://arxiv.org/abs/2305.01951",
    "context": "Title: TempoSum: Evaluating the Temporal Generalization of Abstractive Summarization. (arXiv:2305.01951v1 [cs.CL])\nAbstract: Recent pre-trained language models (PLMs) achieve promising results in existing abstractive summarization datasets. However, existing summarization benchmarks overlap in time with the standard pre-training corpora and finetuning datasets. Hence, the strong performance of PLMs may rely on the parametric knowledge that is memorized during pre-training and fine-tuning. Moreover, the knowledge memorized by PLMs may quickly become outdated, which affects the generalization performance of PLMs on future data. In this work, we propose TempoSum, a novel benchmark that contains data samples from 2010 to 2022, to understand the temporal generalization ability of abstractive summarization models. Through extensive human evaluation, we show that parametric knowledge stored in summarization models significantly affects the faithfulness of the generated summaries on future data. Moreover, existing faithfulness enhancement methods cannot reliably improve the faithfulness of summarization models on fu",
    "path": "papers/23/05/2305.01951.json",
    "total_tokens": 914,
    "translated_title": "TempoSum：评估抽象摘要的时间泛化能力",
    "translated_abstract": "最近，预训练语言模型在现有的抽象摘要数据集中取得了有 promising 的结果。然而，现有的摘要基准与标准的预训练语料库和微调数据集在时间上重叠。因此，预训练语言模型的强大性能可能依赖于预训练和微调过程中所记忆的参数化知识。此外，预训练语言模型所记忆的知识可能很快就过时，这会影响到它们在未来数据上的泛化性能。为了了解抽象摘要模型的时间泛化能力，本文提出了 TempoSum，一个新的基准，其中包含了从 2010 年到 2022 年的数据样本。通过广泛的人类评估，我们证明了摘要模型中存储的参数化知识对未来数据上生成的摘要的准确性有显著影响。此外，现有的准确性提高方法不能可靠地提高摘要模型在未来数据上的准确性。",
    "tldr": "本篇论文提出了 TempoSum 抽象摘要的时间泛化能力基准，通过广泛的人类评估证明了摘要模型中存储的参数化知识对未来数据上生成的摘要有显著影响。",
    "en_tdlr": "This paper proposes a benchmark named TempoSum to evaluate the temporal generalization ability of abstractive summarization models. Through extensive human evaluation, the authors demonstrate that the parametric knowledge stored in summarization models significantly affects the accuracy of generated summaries on future data."
}