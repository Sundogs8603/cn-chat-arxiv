{
    "title": "Augmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In. (arXiv:2305.17331v1 [cs.CL])",
    "abstract": "Retrieval augmentation can aid language models (LMs) in knowledge-intensive tasks by supplying them with external information. Prior works on retrieval augmentation usually jointly fine-tune the retriever and the LM, making them closely coupled. In this paper, we explore the scheme of generic retrieval plug-in: the retriever is to assist target LMs that may not be known beforehand or are unable to be fine-tuned together. To retrieve useful documents for unseen target LMs, we propose augmentation-adapted retriever (AAR), which learns LM's preferences obtained from a known source LM. Experiments on the MMLU and PopQA datasets demonstrate that our AAR trained with a small source LM is able to significantly improve the zero-shot generalization of larger target LMs ranging from 250M Flan-T5 to 175B InstructGPT. Further analysis indicates that the preferences of different LMs overlap, enabling AAR trained with a single source LM to serve as a generic plug-in for various target LMs. Our code ",
    "link": "http://arxiv.org/abs/2305.17331",
    "context": "Title: Augmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In. (arXiv:2305.17331v1 [cs.CL])\nAbstract: Retrieval augmentation can aid language models (LMs) in knowledge-intensive tasks by supplying them with external information. Prior works on retrieval augmentation usually jointly fine-tune the retriever and the LM, making them closely coupled. In this paper, we explore the scheme of generic retrieval plug-in: the retriever is to assist target LMs that may not be known beforehand or are unable to be fine-tuned together. To retrieve useful documents for unseen target LMs, we propose augmentation-adapted retriever (AAR), which learns LM's preferences obtained from a known source LM. Experiments on the MMLU and PopQA datasets demonstrate that our AAR trained with a small source LM is able to significantly improve the zero-shot generalization of larger target LMs ranging from 250M Flan-T5 to 175B InstructGPT. Further analysis indicates that the preferences of different LMs overlap, enabling AAR trained with a single source LM to serve as a generic plug-in for various target LMs. Our code ",
    "path": "papers/23/05/2305.17331.json",
    "total_tokens": 1012,
    "translated_title": "基于增强的适应性检索器以通用插件的形式提高了语言模型的泛化能力",
    "translated_abstract": "检索增强可以通过提供外部信息帮助语言模型(LMs)执行知识密集的任务。检索增强的先前工作通常联合微调检索器和LM，使它们紧密耦合。在本文中，我们探索了通用检索插件的方案：检索器是要帮助目标LM的，这些LM可能事先不知道或无法一起微调。为了检索出对未见过的目标LM有用的文档，我们提出了增强适应检索器(AAR)，它从已知的源LM中学习LM的偏好。在MMLU和PopQA数据集上的实验证明，我们用小型源LM训练的AAR能够显着提高从250M Flan-T5到175B InstructGPT范围内的更大目标LM的零样本泛化。进一步的分析表明，不同LM的偏好重叠，使得以单个源LM训练的AAR能够作为各种目标LM的通用插件。我们的代码...",
    "tldr": "本文提出了增强适应检索器(AAR)的方案，通过从已知的源LM中学习LM的偏好，能够以通用插件的形式帮助目标LM在不进行微调的情况下显著提高零样本泛化能力。",
    "en_tdlr": "This paper proposes a scheme of augmentation-adapted retriever (AAR) that can help target LMs significantly improve zero-shot generalization without fine-tuning, by learning LM preferences from a known source LM. It can serve as a generic plug-in for various target LMs, as preferences of different LMs overlap. Experiments on MMLU and PopQA datasets demonstrate the effectiveness of AAR trained with a small source LM for larger target LMs ranging from 250M Flan-T5 to 175B InstructGPT."
}