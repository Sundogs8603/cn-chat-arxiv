{
    "title": "Do Models Really Learn to Follow Instructions? An Empirical Study of Instruction Tuning. (arXiv:2305.11383v1 [cs.AI])",
    "abstract": "Recent works on instruction tuning (IT) have achieved great performance with zero-shot generalizability to unseen tasks. With additional context (e.g., task definition, examples) provided to models for fine-tuning, they achieved much higher performance than untuned models. However, despite impressive performance gains, the underlying mechanism for IT to work remains understudied. In this work, we analyze how models utilize instructions during IT by comparing model training with altered vs. original instructions. Specifically, we create simplified task definitions by removing all semantic components and only leaving the output space information, and delusive examples that contain incorrect input-output mapping. Our experiments show that models trained on simplified task definition or delusive examples can achieve comparable performance to the ones trained on the original instructions and examples. Furthermore, we introduce a random baseline to perform zero-shot classification tasks, and",
    "link": "http://arxiv.org/abs/2305.11383",
    "context": "Title: Do Models Really Learn to Follow Instructions? An Empirical Study of Instruction Tuning. (arXiv:2305.11383v1 [cs.AI])\nAbstract: Recent works on instruction tuning (IT) have achieved great performance with zero-shot generalizability to unseen tasks. With additional context (e.g., task definition, examples) provided to models for fine-tuning, they achieved much higher performance than untuned models. However, despite impressive performance gains, the underlying mechanism for IT to work remains understudied. In this work, we analyze how models utilize instructions during IT by comparing model training with altered vs. original instructions. Specifically, we create simplified task definitions by removing all semantic components and only leaving the output space information, and delusive examples that contain incorrect input-output mapping. Our experiments show that models trained on simplified task definition or delusive examples can achieve comparable performance to the ones trained on the original instructions and examples. Furthermore, we introduce a random baseline to perform zero-shot classification tasks, and",
    "path": "papers/23/05/2305.11383.json",
    "total_tokens": 873,
    "tldr": "本文研究了指令微调的机制，通过比较不同的训练输入，发现模型可以在简化任务定义或包含错误示例的情况下实现与在原始指令和示例上训练的模型相当的性能。"
}