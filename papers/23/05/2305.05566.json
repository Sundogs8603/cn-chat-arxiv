{
    "title": "SMAClite: A Lightweight Environment for Multi-Agent Reinforcement Learning. (arXiv:2305.05566v1 [cs.LG])",
    "abstract": "There is a lack of standard benchmarks for Multi-Agent Reinforcement Learning (MARL) algorithms. The Starcraft Multi-Agent Challenge (SMAC) has been widely used in MARL research, but is built on top of a heavy, closed-source computer game, StarCraft II. Thus, SMAC is computationally expensive and requires knowledge and the use of proprietary tools specific to the game for any meaningful alteration or contribution to the environment. We introduce SMAClite -- a challenge based on SMAC that is both decoupled from Starcraft II and open-source, along with a framework which makes it possible to create new content for SMAClite without any special knowledge. We conduct experiments to show that SMAClite is equivalent to SMAC, by training MARL algorithms on SMAClite and reproducing SMAC results. We then show that SMAClite outperforms SMAC in both runtime speed and memory.",
    "link": "http://arxiv.org/abs/2305.05566",
    "context": "Title: SMAClite: A Lightweight Environment for Multi-Agent Reinforcement Learning. (arXiv:2305.05566v1 [cs.LG])\nAbstract: There is a lack of standard benchmarks for Multi-Agent Reinforcement Learning (MARL) algorithms. The Starcraft Multi-Agent Challenge (SMAC) has been widely used in MARL research, but is built on top of a heavy, closed-source computer game, StarCraft II. Thus, SMAC is computationally expensive and requires knowledge and the use of proprietary tools specific to the game for any meaningful alteration or contribution to the environment. We introduce SMAClite -- a challenge based on SMAC that is both decoupled from Starcraft II and open-source, along with a framework which makes it possible to create new content for SMAClite without any special knowledge. We conduct experiments to show that SMAClite is equivalent to SMAC, by training MARL algorithms on SMAClite and reproducing SMAC results. We then show that SMAClite outperforms SMAC in both runtime speed and memory.",
    "path": "papers/23/05/2305.05566.json",
    "total_tokens": 890,
    "translated_title": "SMAClite: 多智能体强化学习的轻量级环境",
    "translated_abstract": "目前缺少适用于多智能体强化学习算法的标准基准。Starcraft多智能体挑战（SMAC）已经在多智能体强化学习研究中广泛使用，但构建在重型的闭源计算机游戏StarCraft II之上。因此，SMAC的计算成本很高，需要具备关于游戏的特殊知识和使用专有工具才能对环境进行任何有意义的修改或贡献。我们介绍了SMAClite - 一个基于SMAC的挑战，不仅与Starcraft II解耦，而且是开源的，同时提供了一个框架，使得可以创建新的SMAClite内容而无需任何特殊知识。我们进行了实验，证明了通过在SMAClite上训练多智能体强化学习算法，可以复现SMAC的结果。然后我们证明，SMAClite在运行时速度和内存方面超越SMAC。",
    "tldr": "本论文介绍了SMAClite，一个轻量级的多智能体强化学习环境，解耦了原有的闭源游戏并提供了开源框架，SMAClite在运行时速度和内存方面超越了SMAC。",
    "en_tdlr": "This paper introduces SMAClite, a lightweight environment for Multi-Agent Reinforcement Learning that decouples the environment from the closed-source game StarCraft II and provides an open-source framework. SMAClite outperforms SMAC in terms of runtime speed and memory."
}