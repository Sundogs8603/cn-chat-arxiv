{
    "title": "FedHGN: A Federated Framework for Heterogeneous Graph Neural Networks. (arXiv:2305.09729v1 [cs.LG])",
    "abstract": "Heterogeneous graph neural networks (HGNNs) can learn from typed and relational graph data more effectively than conventional GNNs. With larger parameter spaces, HGNNs may require more training data, which is often scarce in real-world applications due to privacy regulations (e.g., GDPR). Federated graph learning (FGL) enables multiple clients to train a GNN collaboratively without sharing their local data. However, existing FGL methods mainly focus on homogeneous GNNs or knowledge graph embeddings; few have considered heterogeneous graphs and HGNNs. In federated heterogeneous graph learning, clients may have private graph schemas. Conventional FL/FGL methods attempting to define a global HGNN model would violate schema privacy. To address these challenges, we propose FedHGN, a novel and general FGL framework for HGNNs. FedHGN adopts schema-weight decoupling to enable schema-agnostic knowledge sharing and employs coefficients alignment to stabilize the training process and improve HGNN",
    "link": "http://arxiv.org/abs/2305.09729",
    "context": "Title: FedHGN: A Federated Framework for Heterogeneous Graph Neural Networks. (arXiv:2305.09729v1 [cs.LG])\nAbstract: Heterogeneous graph neural networks (HGNNs) can learn from typed and relational graph data more effectively than conventional GNNs. With larger parameter spaces, HGNNs may require more training data, which is often scarce in real-world applications due to privacy regulations (e.g., GDPR). Federated graph learning (FGL) enables multiple clients to train a GNN collaboratively without sharing their local data. However, existing FGL methods mainly focus on homogeneous GNNs or knowledge graph embeddings; few have considered heterogeneous graphs and HGNNs. In federated heterogeneous graph learning, clients may have private graph schemas. Conventional FL/FGL methods attempting to define a global HGNN model would violate schema privacy. To address these challenges, we propose FedHGN, a novel and general FGL framework for HGNNs. FedHGN adopts schema-weight decoupling to enable schema-agnostic knowledge sharing and employs coefficients alignment to stabilize the training process and improve HGNN",
    "path": "papers/23/05/2305.09729.json",
    "total_tokens": 1003,
    "translated_title": "FedHGN：异构图神经网络的联邦学习框架",
    "translated_abstract": "与传统GNN相比，异构图神经网络（HGNN）可以更有效地从类型化和关系化图数据中学习。由于隐私法规（例如GDPR），实际应用中的训练数据往往很少，而使用更大的参数空间可能需要更多的训练数据。联邦图学习（FGL）使多个客户端共同训练GNN而不共享本地数据。然而，现有的FGL方法主要集中在同构GNN或知识图嵌入上；很少考虑异构图和HGNN。在联邦异构图学习中，客户端可能拥有私有图模式，尝试定义全局HGNN模型的传统FL/FGL方法会侵犯模式隐私。为了解决这些挑战，我们提出了FedHGN，一种新颖的HGNN FGL框架。FedHGN采用模式权重解耦来实现独立于模式的知识共享，并采用系数对齐来稳定训练过程和提高HGNN泛化能力。我们在合成和现实数据集上进行了广泛的实验，证明了FedHGN相对于现有的最先进方法的有效性。",
    "tldr": "FedHGN是一种用于异构图神经网络的联邦学习框架，它采用模式权重解耦和系数对齐技术，使得不同客户端可以共享知识而不泄露隐私，相比于现有方法表现更加优秀。",
    "en_tdlr": "FedHGN is a federated learning framework for heterogeneous graph neural networks, which adopts schema-weight decoupling and coefficients alignment to enable knowledge sharing among clients without violating privacy. It outperforms state-of-the-art methods in terms of effectiveness."
}