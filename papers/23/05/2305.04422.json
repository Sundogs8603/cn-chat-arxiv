{
    "title": "Performance Gaps of Artificial Intelligence Models Screening Mammography -- Towards Fair and Interpretable Models. (arXiv:2305.04422v2 [eess.IV] UPDATED)",
    "abstract": "Even though deep learning models for abnormality classification can perform well in screening mammography, the demographic and imaging characteristics associated with increased risk of failure for abnormality classification in screening mammograms remain unclear. This retrospective study used data from the Emory BrEast Imaging Dataset (EMBED) including mammograms from 115,931 patients imaged at Emory University Healthcare between 2013 to 2020. Clinical and imaging data includes Breast Imaging Reporting and Data System (BI-RADS) assessment, region of interest coordinates for abnormalities, imaging features, pathologic outcomes, and patient demographics. Deep learning models including InceptionV3, VGG16, ResNet50V2, and ResNet152V2 were developed to distinguish between patches of abnormal tissue and randomly selected patches of normal tissue from the screening mammograms. The distributions of the training, validation and test sets are 29,144 (55.6%) patches of 10,678 (54.2%) patients, 9,",
    "link": "http://arxiv.org/abs/2305.04422",
    "context": "Title: Performance Gaps of Artificial Intelligence Models Screening Mammography -- Towards Fair and Interpretable Models. (arXiv:2305.04422v2 [eess.IV] UPDATED)\nAbstract: Even though deep learning models for abnormality classification can perform well in screening mammography, the demographic and imaging characteristics associated with increased risk of failure for abnormality classification in screening mammograms remain unclear. This retrospective study used data from the Emory BrEast Imaging Dataset (EMBED) including mammograms from 115,931 patients imaged at Emory University Healthcare between 2013 to 2020. Clinical and imaging data includes Breast Imaging Reporting and Data System (BI-RADS) assessment, region of interest coordinates for abnormalities, imaging features, pathologic outcomes, and patient demographics. Deep learning models including InceptionV3, VGG16, ResNet50V2, and ResNet152V2 were developed to distinguish between patches of abnormal tissue and randomly selected patches of normal tissue from the screening mammograms. The distributions of the training, validation and test sets are 29,144 (55.6%) patches of 10,678 (54.2%) patients, 9,",
    "path": "papers/23/05/2305.04422.json",
    "total_tokens": 945,
    "translated_title": "人工智能模型筛查乳腺 X 光片的性能差距 -- 迈向公平和可解释的模型",
    "translated_abstract": "尽管深度学习模型在筛查乳腺 X 光片的异常分类中表现良好，与增加异常分类失败风险相关的人口学和成像特征仍不清楚。本回顾性研究使用 Emory BrEast Imaging Dataset（EMBED）的数据，包括2013年至2020年间 Emory University Healthcare 的 115,931 名患者的乳腺 X 光片。临床和成像数据包括乳腺成像报告和数据系统（BI-RADS）评估，异常区域的兴趣点坐标，成像特征，病理结果和患者人口统计学。开发了 InceptionV3、VGG16、ResNet50V2 和 ResNet152V2 等深度学习模型，用于区分筛查乳腺 X 光片中异常组织区域和随机选择的正常组织区域。训练集、验证集和测试集的分布为 29,144（55.6%）个异常组织区域和来自 10,678（54.2%）位患者的膨胀组织区域。",
    "tldr": "该研究探讨了乳腺筛查 X 光片异常分类模型中的性能差距，尤其是与人口学和成像特征之间的关系，旨在开发公平和可解释的模型。"
}