{
    "title": "With a Little Push, NLI Models can Robustly and Efficiently Predict Faithfulness. (arXiv:2305.16819v1 [cs.CL])",
    "abstract": "Conditional language models still generate unfaithful output that is not supported by their input. These unfaithful generations jeopardize trust in real-world applications such as summarization or human-machine interaction, motivating a need for automatic faithfulness metrics. To implement such metrics, NLI models seem attractive, since they solve a strongly related task that comes with a wealth of prior research and data. But recent research suggests that NLI models require costly additional machinery to perform reliably across datasets, e.g., by running inference on a cartesian product of input and generated sentences, or supporting them with a question-generation/answering step.  In this work we show that pure NLI models _can_ outperform more complex metrics when combining task-adaptive data augmentation with robust inference procedures. We propose: (1) Augmenting NLI training data to adapt NL inferences to the specificities of faithfulness prediction in dialogue; (2) Making use of ",
    "link": "http://arxiv.org/abs/2305.16819",
    "context": "Title: With a Little Push, NLI Models can Robustly and Efficiently Predict Faithfulness. (arXiv:2305.16819v1 [cs.CL])\nAbstract: Conditional language models still generate unfaithful output that is not supported by their input. These unfaithful generations jeopardize trust in real-world applications such as summarization or human-machine interaction, motivating a need for automatic faithfulness metrics. To implement such metrics, NLI models seem attractive, since they solve a strongly related task that comes with a wealth of prior research and data. But recent research suggests that NLI models require costly additional machinery to perform reliably across datasets, e.g., by running inference on a cartesian product of input and generated sentences, or supporting them with a question-generation/answering step.  In this work we show that pure NLI models _can_ outperform more complex metrics when combining task-adaptive data augmentation with robust inference procedures. We propose: (1) Augmenting NLI training data to adapt NL inferences to the specificities of faithfulness prediction in dialogue; (2) Making use of ",
    "path": "papers/23/05/2305.16819.json",
    "total_tokens": 892,
    "translated_title": "在轻微推动下，NLI模型可以高效、稳健地预测忠实度",
    "translated_abstract": "条件语言模型仍然生成不忠实的输出，这些输出与其输入不一致。这些不忠实的生成会危及到应用程序对于真实世界的信任，例如概述或人机互动，这促使需要自动忠实性度量标准的产生。为了实施这样的标准，NLI模型似乎很有吸引力，因为它们解决一个与众多先前研究和数据相关的任务。但最近的研究表明，在跨数据集可靠执行方面，NLI模型需要昂贵的附加机器，例如在输入和生成的句子的笛卡尔积上运行推理，或通过支持问答步骤来支持它们。在这份工作中，我们展示了通过将任务自适应数据增强与稳健的推理过程相结合，纯NLI模型可以胜过更复杂的度量方法。我们提出了以下措施：（1）增加NLI培训数据，以适应对话中忠实度预测的特殊性；（2）利用推理过程。",
    "tldr": "本文证明，在任务自适应数据增强与稳健的推理过程相结合下，纯NLI模型可以胜过更复杂的度量方法。",
    "en_tdlr": "This paper proves that pure NLI models can outperform more complex metrics when combining task-adaptive data augmentation with robust inference procedures."
}