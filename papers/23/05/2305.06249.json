{
    "title": "Deep Reinforcement Learning Based Resource Allocation for Cloud Native Wireless Network. (arXiv:2305.06249v1 [cs.NI])",
    "abstract": "Cloud native technology has revolutionized 5G beyond and 6G communication networks, offering unprecedented levels of operational automation, flexibility, and adaptability. However, the vast array of cloud native services and applications presents a new challenge in resource allocation for dynamic cloud computing environments. To tackle this challenge, we investigate a cloud native wireless architecture that employs container-based virtualization to enable flexible service deployment. We then study two representative use cases: network slicing and Multi-Access Edge Computing. To optimize resource allocation in these scenarios, we leverage deep reinforcement learning techniques and introduce two model-free algorithms capable of monitoring the network state and dynamically training allocation policies. We validate the effectiveness of our algorithms in a testbed developed using Free5gc. Our findings demonstrate significant improvements in network efficiency, underscoring the potential of ",
    "link": "http://arxiv.org/abs/2305.06249",
    "context": "Title: Deep Reinforcement Learning Based Resource Allocation for Cloud Native Wireless Network. (arXiv:2305.06249v1 [cs.NI])\nAbstract: Cloud native technology has revolutionized 5G beyond and 6G communication networks, offering unprecedented levels of operational automation, flexibility, and adaptability. However, the vast array of cloud native services and applications presents a new challenge in resource allocation for dynamic cloud computing environments. To tackle this challenge, we investigate a cloud native wireless architecture that employs container-based virtualization to enable flexible service deployment. We then study two representative use cases: network slicing and Multi-Access Edge Computing. To optimize resource allocation in these scenarios, we leverage deep reinforcement learning techniques and introduce two model-free algorithms capable of monitoring the network state and dynamically training allocation policies. We validate the effectiveness of our algorithms in a testbed developed using Free5gc. Our findings demonstrate significant improvements in network efficiency, underscoring the potential of ",
    "path": "papers/23/05/2305.06249.json",
    "total_tokens": 913,
    "translated_title": "基于深度强化学习的云原生无线网络资源分配研究",
    "translated_abstract": "云原生技术革命性地改变了5G及6G通信网络，提供了前所未有的运营自动化、灵活性和适应性。然而，云原生服务和应用的广泛实现给动态云计算环境下的资源分配提出了新的挑战。为了解决这个问题，我们研究了一种使用基于容器的虚拟化实现灵活服务部署的云原生无线架构，并研究了两个代表性应用场景：网络切片和多接入边缘计算。为了优化这些场景下的资源分配，我们利用深度强化学习技术，引入了两个无模型算法，能够监控网络状态并动态训练分配策略。我们使用Free5gc开发的测试平台验证了算法的有效性。我们的实验结果表明，在提高网络效率方面，云原生技术和深度强化学习具有巨大的潜力。",
    "tldr": "本文研究了一种基于云原生无线架构的资源分配方法，针对网络切片和多接入边缘计算等场景，利用深度强化学习技术提出了两个无模型算法，能够动态训练分配策略，有效提高了网络效率。",
    "en_tdlr": "This paper proposes a resource allocation method based on cloud native wireless architecture, and introduces two model-free algorithms leveraging deep reinforcement learning techniques for dynamic training allocation policies, which significantly improve network efficiency in scenarios such as network slicing and Multi-Access Edge Computing."
}