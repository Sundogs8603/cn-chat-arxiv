{
    "title": "Beyond Confidence: Reliable Models Should Also Consider Atypicality. (arXiv:2305.18262v2 [cs.LG] UPDATED)",
    "abstract": "While most machine learning models can provide confidence in their predictions, confidence is insufficient to understand a prediction's reliability. For instance, the model may have a low confidence prediction if the input is not well-represented in the training dataset or if the input is inherently ambiguous. In this work, we investigate the relationship between how atypical(rare) a sample or a class is and the reliability of a model's predictions. We first demonstrate that atypicality is strongly related to miscalibration and accuracy. In particular, we empirically show that predictions for atypical inputs or atypical classes are more overconfident and have lower accuracy. Using these insights, we show incorporating atypicality improves uncertainty quantification and model performance for discriminative neural networks and large language models. In a case study, we show that using atypicality improves the performance of a skin lesion classifier across different skin tone groups witho",
    "link": "http://arxiv.org/abs/2305.18262",
    "context": "Title: Beyond Confidence: Reliable Models Should Also Consider Atypicality. (arXiv:2305.18262v2 [cs.LG] UPDATED)\nAbstract: While most machine learning models can provide confidence in their predictions, confidence is insufficient to understand a prediction's reliability. For instance, the model may have a low confidence prediction if the input is not well-represented in the training dataset or if the input is inherently ambiguous. In this work, we investigate the relationship between how atypical(rare) a sample or a class is and the reliability of a model's predictions. We first demonstrate that atypicality is strongly related to miscalibration and accuracy. In particular, we empirically show that predictions for atypical inputs or atypical classes are more overconfident and have lower accuracy. Using these insights, we show incorporating atypicality improves uncertainty quantification and model performance for discriminative neural networks and large language models. In a case study, we show that using atypicality improves the performance of a skin lesion classifier across different skin tone groups witho",
    "path": "papers/23/05/2305.18262.json",
    "total_tokens": 953,
    "translated_title": "超越置信度：可靠模型还应考虑非典型性",
    "translated_abstract": "大多数机器学习模型能够提供置信度以预测结果，然而，置信度无法完全理解预测的可靠性。例如，当输入在训练数据集中没有很好的表示或者输入 inherently 易混淆时，模型可能会给出较低的置信度。本研究探讨了样本或类别的非典型性与模型预测可靠性之间的关系。我们首先证明了非典型性与误校准和准确性之间的强相关性。具体而言，我们实证表明对于非典型的输入或非典型的类别，预测更加过于自信且准确性较低。利用这些发现，我们展示了如何将非典型性纳入不确定性量化和鉴别性神经网络以及大型语言模型的性能提升。在一个案例研究中，我们展示了利用非典型性如何提高不同肤色群体的皮肤病变分类器的性能。",
    "tldr": "研究发现，模型的可靠性不能仅仅依靠置信度，还应考虑预测样本或类别的非典型性，特别是对于非典型输入或类别，模型预测更过于自信且准确性较低。利用这些发现，将非典型性纳入模型可以提高不确定性量化和性能。"
}