{
    "title": "Coagent Networks: Generalized and Scaled. (arXiv:2305.09838v1 [cs.LG])",
    "abstract": "Coagent networks for reinforcement learning (RL) [Thomas and Barto, 2011] provide a powerful and flexible framework for deriving principled learning rules for arbitrary stochastic neural networks. The coagent framework offers an alternative to backpropagation-based deep learning (BDL) that overcomes some of backpropagation's main limitations. For example, coagent networks can compute different parts of the network \\emph{asynchronously} (at different rates or at different times), can incorporate non-differentiable components that cannot be used with backpropagation, and can explore at levels higher than their action spaces (that is, they can be designed as hierarchical networks for exploration and/or temporal abstraction). However, the coagent framework is not just an alternative to BDL; the two approaches can be blended: BDL can be combined with coagent learning rules to create architectures with the advantages of both approaches. This work generalizes the coagent theory and learning r",
    "link": "http://arxiv.org/abs/2305.09838",
    "context": "Title: Coagent Networks: Generalized and Scaled. (arXiv:2305.09838v1 [cs.LG])\nAbstract: Coagent networks for reinforcement learning (RL) [Thomas and Barto, 2011] provide a powerful and flexible framework for deriving principled learning rules for arbitrary stochastic neural networks. The coagent framework offers an alternative to backpropagation-based deep learning (BDL) that overcomes some of backpropagation's main limitations. For example, coagent networks can compute different parts of the network \\emph{asynchronously} (at different rates or at different times), can incorporate non-differentiable components that cannot be used with backpropagation, and can explore at levels higher than their action spaces (that is, they can be designed as hierarchical networks for exploration and/or temporal abstraction). However, the coagent framework is not just an alternative to BDL; the two approaches can be blended: BDL can be combined with coagent learning rules to create architectures with the advantages of both approaches. This work generalizes the coagent theory and learning r",
    "path": "papers/23/05/2305.09838.json",
    "total_tokens": 901,
    "translated_title": "合作智能网络：泛化和扩展",
    "translated_abstract": "强化学习中的合作智能网络为任意随机神经网络的原则性学习提供了一种强大而灵活的框架。它不仅能够异步计算网络的不同部分，还能够吸收一些反向传播不能使用的不可微组件。此外，它还可以在动作空间级别以上进行探索，即可以设计为探索和/或时态抽象的分层网络。本文将协作理论和学习规则推广到任意网络拓扑，并通过使用分布式和并行学习的高效算法来扩展它。我们在基准问题上进行了模拟，证明了该算法在性能上的显著提高。",
    "tldr": "论文提出了一种强大而灵活的合作智能网络框架，可以异步计算网络不同部分、吸收反向传播不能使用的不可微组件、探索和/或时态抽象的分层网络，并使用高效算法进行分布式和并行学习。在基准问题上的模拟表明，该算法在性能上有显著提高。",
    "en_tdlr": "This paper proposes a powerful and flexible coagent network framework that enables asynchronous computation of different parts of the network, incorporation of non-differentiable components, and exploration at levels higher than action spaces. The framework is extended to arbitrary network topologies and scaled up using efficient algorithms for distributed and parallel learning, showing significant improvements over baseline algorithms on benchmark problems."
}