{
    "title": "Are Large Language Models Fit For Guided Reading?. (arXiv:2305.10645v1 [cs.CL])",
    "abstract": "This paper looks at the ability of large language models to participate in educational guided reading. We specifically, evaluate their ability to generate meaningful questions from the input text, generate diverse questions both in terms of content coverage and difficulty of the questions and evaluate their ability to recommend part of the text that a student should re-read based on the student's responses to the questions. Based on our evaluation of ChatGPT and Bard, we report that,  1) Large language models are able to generate high quality meaningful questions that have high correlation with the input text, 2) They generate diverse question that cover most topics in the input text even though this ability is significantly degraded as the input text increases, 3)The large language models are able to generate both low and high cognitive questions even though they are significantly biased toward low cognitive question, 4) They are able to effectively summarize responses and extract a p",
    "link": "http://arxiv.org/abs/2305.10645",
    "context": "Title: Are Large Language Models Fit For Guided Reading?. (arXiv:2305.10645v1 [cs.CL])\nAbstract: This paper looks at the ability of large language models to participate in educational guided reading. We specifically, evaluate their ability to generate meaningful questions from the input text, generate diverse questions both in terms of content coverage and difficulty of the questions and evaluate their ability to recommend part of the text that a student should re-read based on the student's responses to the questions. Based on our evaluation of ChatGPT and Bard, we report that,  1) Large language models are able to generate high quality meaningful questions that have high correlation with the input text, 2) They generate diverse question that cover most topics in the input text even though this ability is significantly degraded as the input text increases, 3)The large language models are able to generate both low and high cognitive questions even though they are significantly biased toward low cognitive question, 4) They are able to effectively summarize responses and extract a p",
    "path": "papers/23/05/2305.10645.json",
    "total_tokens": 899,
    "translated_title": "大型语言模型适合指导阅读吗？",
    "translated_abstract": "本文研究了大型语言模型在教育指导阅读中的应用能力。我们具体评估了它们从输入文本中生成有意义问题的能力，生成内容涵盖和问题难度多样化的问题的能力，并评估它们根据学生对问题的回答推荐应该重新阅读的文本部分的能力。在对ChatGPT和Bard的评估中，我们报告如下结果：1）大型语言模型能够生成与输入文本高相关的高质量有意义的问题，2）它们能够生成涵盖输入文本中大多数主题的多样化问题，尽管随着输入文本的增加，这种能力显著降低，3）大型语言模型能够生成低和高认知难度的问题，尽管它们显著偏向于低认知难度的问题，4）它们能够有效地总结回答并提取应该重新阅读的部分。",
    "tldr": "本文评估大型语言模型在指导阅读中的应用能力，发现它们能够生成高质量的有意义问题，具有多样性且涵盖输入文本中大多数主题，同时能够有效地总结回答和推荐重新阅读的部分。",
    "en_tdlr": "This paper evaluates the ability of large language models to participate in guided reading, and shows that they can generate high-quality and diverse questions that cover most topics in the input text, as well as effectively summarize responses and recommend text for re-reading."
}