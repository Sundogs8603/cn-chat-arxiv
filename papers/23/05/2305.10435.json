{
    "title": "Generative Pre-trained Transformer: A Comprehensive Review on Enabling Technologies, Potential Applications, Emerging Challenges, and Future Directions. (arXiv:2305.10435v1 [cs.CL])",
    "abstract": "The Generative Pre-trained Transformer models represent a notable breakthrough in the domain of natural language processing, which is propelling us toward the development of machines that can understand and communicate using language in a manner that closely resembles that of humans. Generative Pre-trained Transformer models are based on the transformer architecture, a deep neural network designed for natural language processing tasks. Due to their impressive performance on natural language processing tasks and ability to effectively converse, Generative Pre-trained Transformer models have gained significant popularity among researchers and industrial communities, making them one of the most widely used and effective models in natural language processing and related fields, which motivated to conduct this review. This review provides a detailed overview of the Generative Pre-trained Transformer, including its architecture, working process, training procedures, enabling technologies, an",
    "link": "http://arxiv.org/abs/2305.10435",
    "context": "Title: Generative Pre-trained Transformer: A Comprehensive Review on Enabling Technologies, Potential Applications, Emerging Challenges, and Future Directions. (arXiv:2305.10435v1 [cs.CL])\nAbstract: The Generative Pre-trained Transformer models represent a notable breakthrough in the domain of natural language processing, which is propelling us toward the development of machines that can understand and communicate using language in a manner that closely resembles that of humans. Generative Pre-trained Transformer models are based on the transformer architecture, a deep neural network designed for natural language processing tasks. Due to their impressive performance on natural language processing tasks and ability to effectively converse, Generative Pre-trained Transformer models have gained significant popularity among researchers and industrial communities, making them one of the most widely used and effective models in natural language processing and related fields, which motivated to conduct this review. This review provides a detailed overview of the Generative Pre-trained Transformer, including its architecture, working process, training procedures, enabling technologies, an",
    "path": "papers/23/05/2305.10435.json",
    "total_tokens": 951,
    "translated_title": "生成的预训练变形器：启用技术、潜在应用、新兴挑战和未来方向的综述",
    "translated_abstract": "生成的预训练变形器模型代表了自然语言处理领域的一项重大突破，将我们推向开发能够像人类一样理解和使用语言进行交流的机器。生成的预训练变形器模型基于变形器架构，这是一种专门设计用于自然语言处理任务的深度神经网络。由于在自然语言处理任务上表现出色且能够有效地进行对话，生成的预训练变形器模型在研究人员和工业界社区中获得了显著的知名度，成为自然语言处理及相关领域中最广泛使用和有效的模型之一，这促使进行了本综述。本综述详细介绍了生成预训练变形器，包括其架构、工作过程、训练过程、启用技术以及在各个领域的潜在应用。同时，本综述还讨论了该模型面临的新兴挑战和局限性，并提供了未来研究的可能方向。",
    "tldr": "生成的预训练变形器是一种基于变形器架构的深度神经网络，能够在自然语言处理任务中表现出色且有效地进行对话，具有广泛的潜在应用，但仍面临新兴挑战和局限性。",
    "en_tdlr": "Generative Pre-trained Transformer is a deep neural network based on the transformer architecture, which shows impressive performance and ability to converse effectively on natural language processing tasks. It has a wide range of potential applications but still faces emerging challenges and limitations."
}