{
    "title": "When Newer is Not Better: Does Deep Learning Really Benefit Recommendation From Implicit Feedback?. (arXiv:2305.01801v1 [cs.IR])",
    "abstract": "In recent years, neural models have been repeatedly touted to exhibit state-of-the-art performance in recommendation. Nevertheless, multiple recent studies have revealed that the reported state-of-the-art results of many neural recommendation models cannot be reliably replicated. A primary reason is that existing evaluations are performed under various inconsistent protocols. Correspondingly, these replicability issues make it difficult to understand how much benefit we can actually gain from these neural models. It then becomes clear that a fair and comprehensive performance comparison between traditional and neural models is needed.  Motivated by these issues, we perform a large-scale, systematic study to compare recent neural recommendation models against traditional ones in top-n recommendation from implicit data. We propose a set of evaluation strategies for measuring memorization performance, generalization performance, and subgroup-specific performance of recommendation models. ",
    "link": "http://arxiv.org/abs/2305.01801",
    "context": "Title: When Newer is Not Better: Does Deep Learning Really Benefit Recommendation From Implicit Feedback?. (arXiv:2305.01801v1 [cs.IR])\nAbstract: In recent years, neural models have been repeatedly touted to exhibit state-of-the-art performance in recommendation. Nevertheless, multiple recent studies have revealed that the reported state-of-the-art results of many neural recommendation models cannot be reliably replicated. A primary reason is that existing evaluations are performed under various inconsistent protocols. Correspondingly, these replicability issues make it difficult to understand how much benefit we can actually gain from these neural models. It then becomes clear that a fair and comprehensive performance comparison between traditional and neural models is needed.  Motivated by these issues, we perform a large-scale, systematic study to compare recent neural recommendation models against traditional ones in top-n recommendation from implicit data. We propose a set of evaluation strategies for measuring memorization performance, generalization performance, and subgroup-specific performance of recommendation models. ",
    "path": "papers/23/05/2305.01801.json",
    "total_tokens": 882,
    "translated_title": "当新的不一定是更好的：深度学习是否真正受益于基于隐式反馈的推荐？",
    "translated_abstract": "最近几年，神经模型被多次宣传为推荐领域的最先进技术，但是多个研究表明，许多神经推荐模型的最新结果并不能可靠地复现。一个主要原因是现有的评估是在不一致的协议下进行的。因此，这些可重复性问题使人们难以了解实际上可以从这些神经模型中获得多少益处。因此，需要一个公平而全面的绩效比较来比较传统模型和神经模型。为此，我们进行了一项大规模、系统性的研究，比较了基于隐式数据的顶部推荐的最新神经推荐模型和传统模型。我们提出了一组评估策略，用于衡量推荐模型的记忆性能、泛化性能和子群特定性能。",
    "tldr": "本研究对多个神经推荐模型与传统模型进行比较，提出了一组评估策略来衡量其记忆性能、泛化性能和子群特定性能，揭示了在IMDB和Yelp数据集上，神经推荐模型与传统模型的差异性。",
    "en_tdlr": "This study compares multiple neural recommendation models against traditional ones, proposes a set of evaluation strategies for measuring memorization performance, generalization performance, and subgroup-specific performance, and reveals the differences between neural recommendation models and traditional ones on IMDB and Yelp datasets."
}