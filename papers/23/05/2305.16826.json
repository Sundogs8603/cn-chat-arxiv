{
    "title": "Prompt- and Trait Relation-aware Cross-prompt Essay Trait Scoring. (arXiv:2305.16826v1 [cs.CL])",
    "abstract": "Automated essay scoring (AES) aims to score essays written for a given prompt, which defines the writing topic. Most existing AES systems assume to grade essays of the same prompt as used in training and assign only a holistic score. However, such settings conflict with real-education situations; pre-graded essays for a particular prompt are lacking, and detailed trait scores of sub-rubrics are required. Thus, predicting various trait scores of unseen-prompt essays (called cross-prompt essay trait scoring) is a remaining challenge of AES. In this paper, we propose a robust model: prompt- and trait relation-aware cross-prompt essay trait scorer. We encode prompt-aware essay representation by essay-prompt attention and utilizing the topic-coherence feature extracted by the topic-modeling mechanism without access to labeled data; therefore, our model considers the prompt adherence of an essay, even in a cross-prompt setting. To facilitate multi-trait scoring, we design trait-similarity lo",
    "link": "http://arxiv.org/abs/2305.16826",
    "context": "Title: Prompt- and Trait Relation-aware Cross-prompt Essay Trait Scoring. (arXiv:2305.16826v1 [cs.CL])\nAbstract: Automated essay scoring (AES) aims to score essays written for a given prompt, which defines the writing topic. Most existing AES systems assume to grade essays of the same prompt as used in training and assign only a holistic score. However, such settings conflict with real-education situations; pre-graded essays for a particular prompt are lacking, and detailed trait scores of sub-rubrics are required. Thus, predicting various trait scores of unseen-prompt essays (called cross-prompt essay trait scoring) is a remaining challenge of AES. In this paper, we propose a robust model: prompt- and trait relation-aware cross-prompt essay trait scorer. We encode prompt-aware essay representation by essay-prompt attention and utilizing the topic-coherence feature extracted by the topic-modeling mechanism without access to labeled data; therefore, our model considers the prompt adherence of an essay, even in a cross-prompt setting. To facilitate multi-trait scoring, we design trait-similarity lo",
    "path": "papers/23/05/2305.16826.json",
    "total_tokens": 893,
    "translated_title": "Prompt-和Trait关系感知的跨Prompt作文Trait评分",
    "translated_abstract": "自动化作文评分（AES）的目的是对写作主题进行评分的文章，该主题定义了写作主题。大多数现有的AES系统假定对于训练中使用的相同提示评分文章，并分配仅整体分数。然而，这样的设置与实际教育情况冲突；特定提示的预分级文章缺乏，并且需要详细的子量规的Trait分数。因此，预测看不见的Prompt文章的各种Trait分数（称为跨Prompt作文Trait评分）是AES的一项挑战。在本文中，我们提出了一个强大的模型：Prompt-和Trait关系感知的跨Prompt作文Trait评分器。我们通过作文提示关注和利用由主题建模机制提取的主题连贯性特征对作文感知进行编码，而无需访问标记数据；因此，我们的模型甚至在跨Prompt设置中也考虑到作文的提示恪守。为了促进多Trait评分，我们设计了Trait相似性lo",
    "tldr": "本研究提出了一种跨Prompt的作文Trait评分模型，通过作文提示关注和Traint相似性loss，有效解决了作文提示不同的问题，提高了自动化作文评分的准确性和可靠性。",
    "en_tdlr": "This study proposes a cross-prompt essay trait scoring model that effectively solves the problem of different essay prompts by encoding prompt-aware essay representation through essay-prompt attention and trait-similarity loss, improving the accuracy and reliability of automated essay scoring."
}