{
    "title": "Can Copyright be Reduced to Privacy?",
    "abstract": "arXiv:2305.14822v2 Announce Type: replace  Abstract: There is a growing concern that generative AI models will generate outputs closely resembling the copyrighted materials for which they are trained. This worry has intensified as the quality and complexity of generative models have immensely improved, and the availability of extensive datasets containing copyrighted material has expanded. Researchers are actively exploring strategies to mitigate the risk of generating infringing samples, with a recent line of work suggesting to employ techniques such as differential privacy and other forms of algorithmic stability to provide guarantees on the lack of infringing copying. In this work, we examine whether such algorithmic stability techniques are suitable to ensure the responsible use of generative models without inadvertently violating copyright laws. We argue that while these techniques aim to verify the presence of identifiable information in datasets, thus being privacy-oriented, cop",
    "link": "https://arxiv.org/abs/2305.14822",
    "context": "Title: Can Copyright be Reduced to Privacy?\nAbstract: arXiv:2305.14822v2 Announce Type: replace  Abstract: There is a growing concern that generative AI models will generate outputs closely resembling the copyrighted materials for which they are trained. This worry has intensified as the quality and complexity of generative models have immensely improved, and the availability of extensive datasets containing copyrighted material has expanded. Researchers are actively exploring strategies to mitigate the risk of generating infringing samples, with a recent line of work suggesting to employ techniques such as differential privacy and other forms of algorithmic stability to provide guarantees on the lack of infringing copying. In this work, we examine whether such algorithmic stability techniques are suitable to ensure the responsible use of generative models without inadvertently violating copyright laws. We argue that while these techniques aim to verify the presence of identifiable information in datasets, thus being privacy-oriented, cop",
    "path": "papers/23/05/2305.14822.json",
    "total_tokens": 819,
    "translated_title": "版权是否可以简化为隐私？",
    "translated_abstract": "有人越来越担心生成式人工智能模型将产生与它们训练所依据的受版权保护的材料非常相似的产出。随着生成模型的质量和复杂性大幅提高，并且包含受版权保护材料的广泛数据集的可用性不断扩大，人们对这种担忧加剧。研究人员正在积极探索缓解生成侵权样本风险的策略，最近的一些工作建议采用差分隐私等技术和其他形式的算法稳定性来提供关于缺乏侵权复制的保证。在这项工作中，我们研究了这些算法稳定性技术是否适合确保对生成式模型的负责任使用，而不会无意中违反版权法。我们认为，尽管这些技术旨在验证数据集中可识别信息的存在，因此是面向隐私的，但它们可能存在一些仍需要解决的和版权相关的问题。",
    "tldr": "生成式人工智能模型可能违反版权法，研究人员正在探索算法稳定性技术以确保对生成模型的负责任使用。",
    "en_tdlr": "Generative AI models may infringe copyright laws, researchers are exploring algorithmic stability techniques to ensure responsible use of generative models."
}