{
    "title": "CAMEL: Co-Designing AI Models and Embedded DRAMs for Efficient On-Device Learning. (arXiv:2305.03148v1 [cs.AR])",
    "abstract": "The emergence of the Internet of Things (IoT) has resulted in a remarkable amount of data generated on edge devices, which are often processed using AI algorithms. On-device learning enables edge platforms to continually adapt the AI models to user personal data and further allows for a better service quality. However, AI training on resource-limited devices is extremely difficult because of the intensive computing workload and the significant amount of on-chip memory consumption exacted by deep neural networks (DNNs). To mitigate this, we propose to use embedded dynamic random-access memory (eDRAM) as the main storage medium of training data. Compared with static random-access memory (SRAM), eDRAM introduces more than $2\\times$ improvement on storage density, enabling reduced off-chip memory traffic. However, to keep the stored data intact, eDRAM is required to perform the power-hungry data refresh operations.  eDRAM refresh can be eliminated if the data is stored for a period of time",
    "link": "http://arxiv.org/abs/2305.03148",
    "context": "Title: CAMEL: Co-Designing AI Models and Embedded DRAMs for Efficient On-Device Learning. (arXiv:2305.03148v1 [cs.AR])\nAbstract: The emergence of the Internet of Things (IoT) has resulted in a remarkable amount of data generated on edge devices, which are often processed using AI algorithms. On-device learning enables edge platforms to continually adapt the AI models to user personal data and further allows for a better service quality. However, AI training on resource-limited devices is extremely difficult because of the intensive computing workload and the significant amount of on-chip memory consumption exacted by deep neural networks (DNNs). To mitigate this, we propose to use embedded dynamic random-access memory (eDRAM) as the main storage medium of training data. Compared with static random-access memory (SRAM), eDRAM introduces more than $2\\times$ improvement on storage density, enabling reduced off-chip memory traffic. However, to keep the stored data intact, eDRAM is required to perform the power-hungry data refresh operations.  eDRAM refresh can be eliminated if the data is stored for a period of time",
    "path": "papers/23/05/2305.03148.json",
    "total_tokens": 897,
    "translated_title": "CAMEL：面向高效设备端学习的AI模型和嵌入式DRAM的共同设计",
    "translated_abstract": "物联网的兴起导致边缘设备产生了大量数据，通常使用人工智能算法进行处理。设备端学习使边缘平台能够不断地根据用户个人数据调整AI模型，从而实现更好的服务质量。然而，在资源受限的设备上进行AI训练非常困难，因为深度神经网络（DNN）会带来密集的计算工作量和占用大量芯片内存的问题。为了缓解这个问题，我们建议使用嵌入式动态随机存取存储器（eDRAM）作为训练数据的主要存储介质。与静态随机访问存储器（SRAM）相比，eDRAM在存储密度上引入了超过2倍的改进，从而减少了芯片外存储器的流量。然而，为了保持存储的数据完整，eDRAM需要执行耗电的数据刷新操作。如果数据存储一段时间，就可以避免eDRAM刷新。",
    "tldr": "CAMEL提出了使用嵌入式DRAM作为主要存储介质的方法来解决设备端学习中存储和计算过程中占用大量内存的问题，从而使AI模型更加高效。",
    "en_tdlr": "CAMEL proposes to use embedded DRAM as the main storage medium to solve the problem of intensive memory requirement in on-device learning, making AI models more efficient."
}