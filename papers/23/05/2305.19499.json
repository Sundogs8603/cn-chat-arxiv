{
    "title": "Deep into The Domain Shift: Transfer Learning through Dependence Regularization. (arXiv:2305.19499v1 [cs.LG])",
    "abstract": "Classical Domain Adaptation methods acquire transferability by regularizing the overall distributional discrepancies between features in the source domain (labeled) and features in the target domain (unlabeled). They often do not differentiate whether the domain differences come from the marginals or the dependence structures. In many business and financial applications, the labeling function usually has different sensitivities to the changes in the marginals versus changes in the dependence structures. Measuring the overall distributional differences will not be discriminative enough in acquiring transferability. Without the needed structural resolution, the learned transfer is less optimal. This paper proposes a new domain adaptation approach in which one can measure the differences in the internal dependence structure separately from those in the marginals. By optimizing the relative weights among them, the new regularization strategy greatly relaxes the rigidness of the existing ap",
    "link": "http://arxiv.org/abs/2305.19499",
    "context": "Title: Deep into The Domain Shift: Transfer Learning through Dependence Regularization. (arXiv:2305.19499v1 [cs.LG])\nAbstract: Classical Domain Adaptation methods acquire transferability by regularizing the overall distributional discrepancies between features in the source domain (labeled) and features in the target domain (unlabeled). They often do not differentiate whether the domain differences come from the marginals or the dependence structures. In many business and financial applications, the labeling function usually has different sensitivities to the changes in the marginals versus changes in the dependence structures. Measuring the overall distributional differences will not be discriminative enough in acquiring transferability. Without the needed structural resolution, the learned transfer is less optimal. This paper proposes a new domain adaptation approach in which one can measure the differences in the internal dependence structure separately from those in the marginals. By optimizing the relative weights among them, the new regularization strategy greatly relaxes the rigidness of the existing ap",
    "path": "papers/23/05/2305.19499.json",
    "total_tokens": 1069,
    "translated_title": "基于相关性正则化的迁移学习：深入探究领域变换",
    "translated_abstract": "传统的领域自适应方法通过规范化源域（标记）中的特征和目标域（未标记）中特征之间的整体分布差异来获得可转移性。然而，它们往往无法区分领域差异是来自边缘分布还是相关结构。在许多业务和金融应用中，标记函数通常对与边缘分布变化和相关结构变化的敏感程度不同。仅仅测量整体分布差异在获得可转移性方面不够具有判别力。没有必要的结构分辨率，学到的转移效果就会不够优化。本文提出了一种新的领域适应方法，可以分别衡量内部相关结构的差异和边缘分布的差异。通过优化它们之间的相对权重，新的规范化策略大大放松了现有方法的严格性，并显著提高了转移学习性能。具体来说，本文开发了一种新的相关性正则化（DR）方法框架，其中包含一个新的相关性损失和一个融合变量。这种新方法不假设任何特定的分布形式，可以有效地处理高维数据，并可扩展到任何现有的深度转移学习方法。在实验中，DR 方法在几个基准数据集上优于现有的最先进领域适应方法。",
    "tldr": "本文提出了一种新的领域适应方法，可以分别衡量内部相关结构的差异和边缘分布的差异， significantly improves the transfer learning performance.",
    "en_tdlr": "This paper proposes a new domain adaptation approach that can separately measure the differences in internal dependence structure and marginal distributions, which significantly improves the transfer learning performance."
}