{
    "title": "GAN-MPC: Training Model Predictive Controllers with Parameterized Cost Functions using Demonstrations from Non-identical Experts. (arXiv:2305.19111v2 [cs.RO] UPDATED)",
    "abstract": "Model predictive control (MPC) is a popular approach for trajectory optimization in practical robotics applications. MPC policies can optimize trajectory parameters under kinodynamic and safety constraints and provide guarantees on safety, optimality, generalizability, interpretability, and explainability. However, some behaviors are complex and it is difficult to hand-craft an MPC objective function. A special class of MPC policies called Learnable-MPC addresses this difficulty using imitation learning from expert demonstrations. However, they require the demonstrator and the imitator agents to be identical which is hard to satisfy in many real world applications of robotics. In this paper, we address the practical problem of training Learnable-MPC policies when the demonstrator and the imitator do not share the same dynamics and their state spaces may have a partial overlap. We propose a novel approach that uses a generative adversarial network (GAN) to minimize the Jensen-Shannon di",
    "link": "http://arxiv.org/abs/2305.19111",
    "context": "Title: GAN-MPC: Training Model Predictive Controllers with Parameterized Cost Functions using Demonstrations from Non-identical Experts. (arXiv:2305.19111v2 [cs.RO] UPDATED)\nAbstract: Model predictive control (MPC) is a popular approach for trajectory optimization in practical robotics applications. MPC policies can optimize trajectory parameters under kinodynamic and safety constraints and provide guarantees on safety, optimality, generalizability, interpretability, and explainability. However, some behaviors are complex and it is difficult to hand-craft an MPC objective function. A special class of MPC policies called Learnable-MPC addresses this difficulty using imitation learning from expert demonstrations. However, they require the demonstrator and the imitator agents to be identical which is hard to satisfy in many real world applications of robotics. In this paper, we address the practical problem of training Learnable-MPC policies when the demonstrator and the imitator do not share the same dynamics and their state spaces may have a partial overlap. We propose a novel approach that uses a generative adversarial network (GAN) to minimize the Jensen-Shannon di",
    "path": "papers/23/05/2305.19111.json",
    "total_tokens": 904,
    "translated_title": "GAN-MPC:使用非相同专家的演示训练具有参数化成本函数的模型预测控制器",
    "translated_abstract": "模型预测控制（MPC）是机器人实际应用中轨迹优化的流行方法。MPC策略可以在运动动力学和安全性约束下优化轨迹参数，并在安全保障、最优性、泛化性、可解释性和说明性方面提供保证。然而，有些行为是复杂的，手工制作MPC目标函数是困难的。一种名为可学习MPC的特殊类别的MPC策略利用来自专家演示的模仿学习解决了这个问题。然而，它们要求演示者和模仿者代理相同，这在许多机器人的实际应用中很难满足。在本文中，我们解决了当演示者和模仿者没有共享相同动力学且状态空间可能部分重叠时训练可学习MPC策略的实际问题。我们提出了一种新的方法，使用生成对抗网络（GAN）来最小化Jensen-Shannon距离来进行学习。",
    "tldr": "本文提出了一种新的方法，使用GAN来训练Learnable-MPC策略，以便在演示者和模仿者代理不能相同时进行参数化的成本函数学习。",
    "en_tdlr": "This paper proposes a novel approach to train Learnable-MPC policies using GAN, which enables parameterized cost function learning when the demonstrator and imitator agents are not identical."
}