{
    "title": "Data Redaction from Conditional Generative Models. (arXiv:2305.11351v1 [cs.LG])",
    "abstract": "Deep generative models are known to produce undesirable samples such as harmful content. Traditional mitigation methods include re-training from scratch, filtering, or editing; however, these are either computationally expensive or can be circumvented by third parties. In this paper, we take a different approach and study how to post-edit an already-trained conditional generative model so that it redacts certain conditionals that will, with high probability, lead to undesirable content. This is done by distilling the conditioning network in the models, giving a solution that is effective, efficient, controllable, and universal for a class of deep generative models. We conduct experiments on redacting prompts in text-to-image models and redacting voices in text-to-speech models. Our method is computationally light, leads to better redaction quality and robustness than baseline methods while still retaining high generation quality.",
    "link": "http://arxiv.org/abs/2305.11351",
    "context": "Title: Data Redaction from Conditional Generative Models. (arXiv:2305.11351v1 [cs.LG])\nAbstract: Deep generative models are known to produce undesirable samples such as harmful content. Traditional mitigation methods include re-training from scratch, filtering, or editing; however, these are either computationally expensive or can be circumvented by third parties. In this paper, we take a different approach and study how to post-edit an already-trained conditional generative model so that it redacts certain conditionals that will, with high probability, lead to undesirable content. This is done by distilling the conditioning network in the models, giving a solution that is effective, efficient, controllable, and universal for a class of deep generative models. We conduct experiments on redacting prompts in text-to-image models and redacting voices in text-to-speech models. Our method is computationally light, leads to better redaction quality and robustness than baseline methods while still retaining high generation quality.",
    "path": "papers/23/05/2305.11351.json",
    "total_tokens": 922,
    "translated_title": "有条件生成模型中的数据编辑",
    "translated_abstract": "深度生成模型因生成不良内容而受到批评。传统的缓解方法包括重新训练、过滤或编辑；然而这些方法要么计算成本高，要么会被第三方回避。本文提出一种不同的方法，研究如何后期编辑已经训练好的条件生成模型，使其编辑掉某些条件分支，这些条件分支很可能会生成不良内容。这是通过精简模型中的条件网络来实现的，提出的解决方案既有效又高效、具有可控性和普适性，能用于一类深度生成模型。我们在文本到图像生成模型和文本到语音生成模型中进行了数据编辑实验，并表明我们的方法计算成本较低，相比基线方法具有更好的编辑质量和鲁棒性，同时仍保持高生成质量。",
    "tldr": "本文研究如何对已训练好的条件生成模型进行后期编辑，以便编辑掉某些条件分支，这些条件分支很可能会生成不良内容。通过精简模型中的条件网络实现，提出的解决方案有效、高效、具有可控性和普适性，在文本到图像和文本到语音生成模型中取得了良好效果。",
    "en_tdlr": "This paper proposes a method for post-editing trained conditional generative models to redact certain conditionals that are likely to lead to undesirable content. The method involves distilling the conditioning network in the models and is effective, efficient, controllable, and universal for a class of deep generative models. Experiments on text-to-image and text-to-speech models demonstrate that the method is computationally light, leads to better redaction quality and robustness than baseline methods while still retaining high generation quality."
}