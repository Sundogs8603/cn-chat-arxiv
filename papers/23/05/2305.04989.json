{
    "title": "Knowledge Graph Guided Semantic Evaluation of Language Models For User Trust. (arXiv:2305.04989v1 [cs.CL])",
    "abstract": "A fundamental question in natural language processing is - what kind of language structure and semantics is the language model capturing? Graph formats such as knowledge graphs are easy to evaluate as they explicitly express language semantics and structure. This study evaluates the semantics encoded in the self-attention transformers by leveraging explicit knowledge graph structures. We propose novel metrics to measure the reconstruction error when providing graph path sequences from a knowledge graph and trying to reproduce/reconstruct the same from the outputs of the self-attention transformer models. The opacity of language models has an immense bearing on societal issues of trust and explainable decision outcomes. Our findings suggest that language models are models of stochastic control processes for plausible language pattern generation. However, they do not ascribe object and concept-level meaning and semantics to the learned stochastic patterns such as those described in knowl",
    "link": "http://arxiv.org/abs/2305.04989",
    "context": "Title: Knowledge Graph Guided Semantic Evaluation of Language Models For User Trust. (arXiv:2305.04989v1 [cs.CL])\nAbstract: A fundamental question in natural language processing is - what kind of language structure and semantics is the language model capturing? Graph formats such as knowledge graphs are easy to evaluate as they explicitly express language semantics and structure. This study evaluates the semantics encoded in the self-attention transformers by leveraging explicit knowledge graph structures. We propose novel metrics to measure the reconstruction error when providing graph path sequences from a knowledge graph and trying to reproduce/reconstruct the same from the outputs of the self-attention transformer models. The opacity of language models has an immense bearing on societal issues of trust and explainable decision outcomes. Our findings suggest that language models are models of stochastic control processes for plausible language pattern generation. However, they do not ascribe object and concept-level meaning and semantics to the learned stochastic patterns such as those described in knowl",
    "path": "papers/23/05/2305.04989.json",
    "total_tokens": 932,
    "translated_title": "知识图谱指导下语言模型语义评估以提高用户信任",
    "translated_abstract": "自然语言处理中一个基本的问题是：语言模型捕捉到了什么样的语言结构和语义？像知识图谱这样的图表达形式很容易进行评估，因为它们明确地表达了语言语义和结构。本研究通过利用显式的知识图谱结构来评估Self-Attention变压器中编码的语义。我们提出了新的度量标准，通过提供从知识图谱获取的图形路径序列并尝试从Self-Attention变压器模型的输出中复制/重构同样路径来测量重构误差。语言模型的不透明性对于信任和可解释决策结果等社会问题有着巨大的影响。我们的研究发现，语言模型是概率语言模式产生的控制过程的模型，但是它们不将对象和概念级别的含义和语义赋予所学习的随机模式，例如知识图谱中所描述的模式。",
    "tldr": "本研究通过知识图谱结构评估Self-Attention变压器中编码的语义。结果显示，语言模型是概率语言模式产生的控制过程的模型，但是不将对象和概念级别的含义和语义赋予所学习的随机模式，例如知识图谱中所描述的模式。",
    "en_tdlr": "This study evaluates the semantics encoded in self-attention transformers using explicit knowledge graph structures and proposes new metrics to measure reconstruction errors. The research shows that language models are models of stochastic control processes for plausible language pattern generation but do not ascribe object and concept-level meaning and semantics to the learned stochastic patterns, such as those described in knowledge graphs."
}