{
    "title": "Sequence-to-Sequence Pre-training with Unified Modality Masking for Visual Document Understanding. (arXiv:2305.10448v1 [cs.CL])",
    "abstract": "This paper presents GenDoc, a general sequence-to-sequence document understanding model pre-trained with unified masking across three modalities: text, image, and layout. The proposed model utilizes an encoder-decoder architecture, which allows for increased adaptability to a wide range of downstream tasks with diverse output formats, in contrast to the encoder-only models commonly employed in document understanding. In addition to the traditional text infilling task used in previous encoder-decoder models, our pre-training extends to include tasks of masked image token prediction and masked layout prediction. We also design modality-specific instruction and adopt both disentangled attention and the mixture-of-modality-experts strategy to effectively capture the information leveraged by each modality. Evaluation of the proposed model through extensive experiments on several downstream tasks in document understanding demonstrates its ability to achieve superior or competitive performanc",
    "link": "http://arxiv.org/abs/2305.10448",
    "context": "Title: Sequence-to-Sequence Pre-training with Unified Modality Masking for Visual Document Understanding. (arXiv:2305.10448v1 [cs.CL])\nAbstract: This paper presents GenDoc, a general sequence-to-sequence document understanding model pre-trained with unified masking across three modalities: text, image, and layout. The proposed model utilizes an encoder-decoder architecture, which allows for increased adaptability to a wide range of downstream tasks with diverse output formats, in contrast to the encoder-only models commonly employed in document understanding. In addition to the traditional text infilling task used in previous encoder-decoder models, our pre-training extends to include tasks of masked image token prediction and masked layout prediction. We also design modality-specific instruction and adopt both disentangled attention and the mixture-of-modality-experts strategy to effectively capture the information leveraged by each modality. Evaluation of the proposed model through extensive experiments on several downstream tasks in document understanding demonstrates its ability to achieve superior or competitive performanc",
    "path": "papers/23/05/2305.10448.json",
    "total_tokens": 900,
    "translated_title": "面向视觉文档理解的统一模态掩码序列预训练",
    "translated_abstract": "本文提出了GenDoc，一种通用的序列到序列文档理解模型，使用跨三种模态的统一掩码进行预训练：文本、图像和布局。该模型采用编码器-解码器架构，与文档理解中常用的仅编码器模型相比，能够更好地适应各种产生不同输出格式的下游任务。此外，我们的预训练任务不仅包括以往编码器-解码器模型中使用的传统文本填充任务，还包括屏蔽的图像令牌预测和屏蔽的布局预测。我们设计了模态特定的指导和采用分解注意力和模态专家组合策略，以有效地捕捉每种模态所利用的信息。",
    "tldr": "本文提出了一个统一的序列到序列文档理解模型，采用跨三种模态的统一掩码进行预训练，并且结构灵活适应各种下游任务输出格式。模型采用多种任务同时预训练，而且结合分解注意力和模态专家组合策略以提高信息捕获效率。"
}