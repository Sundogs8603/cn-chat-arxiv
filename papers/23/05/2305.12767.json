{
    "title": "D$^2$TV: Dual Knowledge Distillation and Target-oriented Vision Modeling for Many-to-Many Multimodal Summarization. (arXiv:2305.12767v2 [cs.CV] UPDATED)",
    "abstract": "Many-to-many multimodal summarization (M$^3$S) task aims to generate summaries in any language with document inputs in any language and the corresponding image sequence, which essentially comprises multimodal monolingual summarization (MMS) and multimodal cross-lingual summarization (MXLS) tasks. Although much work has been devoted to either MMS or MXLS and has obtained increasing attention in recent years, little research pays attention to the M$^3$S task. Besides, existing studies mainly focus on 1) utilizing MMS to enhance MXLS via knowledge distillation without considering the performance of MMS or 2) improving MMS models by filtering summary-unrelated visual features with implicit learning or explicitly complex training objectives. In this paper, we first introduce a general and practical task, i.e., M$^3$S. Further, we propose a dual knowledge distillation and target-oriented vision modeling framework for the M$^3$S task. Specifically, the dual knowledge distillation method guara",
    "link": "http://arxiv.org/abs/2305.12767",
    "context": "Title: D$^2$TV: Dual Knowledge Distillation and Target-oriented Vision Modeling for Many-to-Many Multimodal Summarization. (arXiv:2305.12767v2 [cs.CV] UPDATED)\nAbstract: Many-to-many multimodal summarization (M$^3$S) task aims to generate summaries in any language with document inputs in any language and the corresponding image sequence, which essentially comprises multimodal monolingual summarization (MMS) and multimodal cross-lingual summarization (MXLS) tasks. Although much work has been devoted to either MMS or MXLS and has obtained increasing attention in recent years, little research pays attention to the M$^3$S task. Besides, existing studies mainly focus on 1) utilizing MMS to enhance MXLS via knowledge distillation without considering the performance of MMS or 2) improving MMS models by filtering summary-unrelated visual features with implicit learning or explicitly complex training objectives. In this paper, we first introduce a general and practical task, i.e., M$^3$S. Further, we propose a dual knowledge distillation and target-oriented vision modeling framework for the M$^3$S task. Specifically, the dual knowledge distillation method guara",
    "path": "papers/23/05/2305.12767.json",
    "total_tokens": 1067,
    "translated_title": "D$^2$TV: 双知识蒸馏和面向目标的视觉建模用于多对多多模态摘要",
    "translated_abstract": "多对多多模态摘要(M$^3$S)任务旨在生成任何语言的摘要，并使用任何语言的文档输入和相应的图像序列，其本质上包括多模态单语摘要(MMS)和多模态跨语言摘要(MXLS)任务。虽然近年来已经有很多工作致力于MMS或MXLS，并且获得了越来越多的关注，但很少有研究关注M$^3$S任务。此外，现有研究主要关注以下两个方面：1)利用MMS通过知识蒸馏来提高MXLS的性能，但忽略了MMS的性能；2)通过隐式学习或显式复杂的训练目标来改进MMS模型，以过滤与摘要无关的视觉特征。在本文中，我们首先介绍了一个通用且实用的任务，即M$^3$S。进一步，我们提出了一种用于M$^3$S任务的双知识蒸馏和面向目标的视觉建模框架。具体而言，双知识蒸馏方法确保了同时提高MMS和MXLS的性能。",
    "tldr": "这篇论文提出了一种新的多对多多模态摘要任务（M$^3$S），并提出了一种双知识蒸馏和面向目标的视觉建模框架来解决该任务，它同时提高了多模态单语摘要（MMS）和多模态跨语言摘要（MXLS）的性能。",
    "en_tdlr": "This paper proposes a new task called Many-to-many Multimodal Summarization (M$^3$S) and introduces a dual knowledge distillation and target-oriented vision modeling framework to address this task, which improves the performance of both Multimodal Monolingual Summarization (MMS) and Multimodal Cross-lingual Summarization (MXLS)."
}