{
    "title": "Query Structure Modeling for Inductive Logical Reasoning Over Knowledge Graphs. (arXiv:2305.13585v1 [cs.CL])",
    "abstract": "Logical reasoning over incomplete knowledge graphs to answer complex logical queries is a challenging task. With the emergence of new entities and relations in constantly evolving KGs, inductive logical reasoning over KGs has become a crucial problem. However, previous PLMs-based methods struggle to model the logical structures of complex queries, which limits their ability to generalize within the same structure. In this paper, we propose a structure-modeled textual encoding framework for inductive logical reasoning over KGs. It encodes linearized query structures and entities using pre-trained language models to find answers. For structure modeling of complex queries, we design stepwise instructions that implicitly prompt PLMs on the execution order of geometric operations in each query. We further separately model different geometric operations (i.e., projection, intersection, and union) on the representation space using a pre-trained encoder with additional attention and maxout lay",
    "link": "http://arxiv.org/abs/2305.13585",
    "context": "Title: Query Structure Modeling for Inductive Logical Reasoning Over Knowledge Graphs. (arXiv:2305.13585v1 [cs.CL])\nAbstract: Logical reasoning over incomplete knowledge graphs to answer complex logical queries is a challenging task. With the emergence of new entities and relations in constantly evolving KGs, inductive logical reasoning over KGs has become a crucial problem. However, previous PLMs-based methods struggle to model the logical structures of complex queries, which limits their ability to generalize within the same structure. In this paper, we propose a structure-modeled textual encoding framework for inductive logical reasoning over KGs. It encodes linearized query structures and entities using pre-trained language models to find answers. For structure modeling of complex queries, we design stepwise instructions that implicitly prompt PLMs on the execution order of geometric operations in each query. We further separately model different geometric operations (i.e., projection, intersection, and union) on the representation space using a pre-trained encoder with additional attention and maxout lay",
    "path": "papers/23/05/2305.13585.json",
    "total_tokens": 949,
    "translated_title": "基于查询结构建模的知识图谱归纳逻辑推理",
    "translated_abstract": "在不完整的知识图谱上进行逻辑推理以回答复杂的逻辑查询是一项具有挑战性的任务。随着不断演化的知识图谱中新实体和关系的出现，基于知识图谱的归纳逻辑推理已成为一个关键问题。然而，之前基于PLMs的方法难以对复杂查询进行逻辑建模，这限制了它们在相同结构内的泛化能力。在本文中，我们提出了一个基于结构建模的文本编码框架，用于在知识图谱上进行归纳逻辑推理。它使用预训练语言模型对线性化的查询结构和实体进行编码以找到答案。针对复杂查询的结构建模，我们设计了逐步指导的指令，它们隐含地提示PLMs在每个查询中执行几何操作的执行顺序。我们进一步使用预训练编码器在表示空间上单独对不同的几何操作（即投影、交集和并集）进行建模，并加入了注意力和最大输出层。",
    "tldr": "本研究提出了一种基于查询结构建模的文本编码框架，用于在不完整的知识图谱上进行归纳逻辑推理。通过针对复杂查询的结构建模和单独对不同的几何操作进行建模，它在提高泛化能力的同时实现了更准确的答案匹配。"
}