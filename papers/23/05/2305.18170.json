{
    "title": "Leveraging Training Data in Few-Shot Prompting for Numerical Reasoning. (arXiv:2305.18170v2 [cs.CL] UPDATED)",
    "abstract": "Chain-of-thought (CoT) prompting with large language models has proven effective in numerous natural language processing tasks, but designing prompts that generalize well to diverse problem types can be challenging, especially in the context of math word problem (MWP) solving. Additionally, it is common to have a large amount of training data that have a better diversity coverage but CoT annotations are not available, which limits the use of supervised learning techniques. To address these issues, we investigate two approaches to leverage the training data in a few-shot prompting scenario: dynamic program prompting and program distillation. Our approach is largely inspired by Gao et al., (2022), where they proposed to replace the CoT with the programs as the intermediate reasoning step. Such a prompting strategy allows us to accurately verify the answer correctness through program execution in MWP solving. Our dynamic program prompting involves annotating the training data by sampling ",
    "link": "http://arxiv.org/abs/2305.18170",
    "context": "Title: Leveraging Training Data in Few-Shot Prompting for Numerical Reasoning. (arXiv:2305.18170v2 [cs.CL] UPDATED)\nAbstract: Chain-of-thought (CoT) prompting with large language models has proven effective in numerous natural language processing tasks, but designing prompts that generalize well to diverse problem types can be challenging, especially in the context of math word problem (MWP) solving. Additionally, it is common to have a large amount of training data that have a better diversity coverage but CoT annotations are not available, which limits the use of supervised learning techniques. To address these issues, we investigate two approaches to leverage the training data in a few-shot prompting scenario: dynamic program prompting and program distillation. Our approach is largely inspired by Gao et al., (2022), where they proposed to replace the CoT with the programs as the intermediate reasoning step. Such a prompting strategy allows us to accurately verify the answer correctness through program execution in MWP solving. Our dynamic program prompting involves annotating the training data by sampling ",
    "path": "papers/23/05/2305.18170.json",
    "total_tokens": 788,
    "translated_title": "利用训练数据进行少样本启发式数值推理",
    "translated_abstract": "大型语言模型的CoT prompting已被证明在许多自然语言处理任务中具有高效性，但在广泛问题类型上设计能够很好概括的提示可能会具有挑战性，特别是在数学词问题 (MWP) 的解决方案中。此外，通常有大量的训练数据具有更好的多样性覆盖率，但缺乏CoT注释，这限制了监督学习技术的使用。为了解决这些问题，我们研究了两种方法，以在少数样本提示场景中利用训练数据：动态规划提示和程序蒸馏。",
    "tldr": "本文研究了两种方法来在少样本提示场景中利用有更好覆盖率的训练数据：动态规划提示和程序蒸馏。这能够在数学词问题 (MWP) 的解决方案中通过程序执行来验证答案正确性。",
    "en_tdlr": "This paper investigates two approaches to leverage training data in a few-shot prompting scenario: dynamic program prompting and program distillation. This allows for accurate verification of answer correctness through program execution in math word problem (MWP) solving."
}