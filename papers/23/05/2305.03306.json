{
    "title": "Human-centered trust framework: An HCI perspective. (arXiv:2305.03306v1 [cs.HC])",
    "abstract": "The rationale of this work is based on the current user trust discourse of Artificial Intelligence (AI). We aim to produce novel HCI approaches that use trust as a facilitator for the uptake (or appropriation) of current technologies. We propose a framework (HCTFrame) to guide non-experts to unlock the full potential of user trust in AI design. Results derived from a data triangulation of findings from three literature reviews demystify some misconceptions of user trust in computer science and AI discourse, and three case studies are conducted to assess the effectiveness of a psychometric scale in mapping potential users' trust breakdowns and concerns. This work primarily contributes to the fight against the tendency to design technical-centered vulnerable interactions, which can eventually lead to additional real and perceived breaches of trust. The proposed framework can be used to guide system designers on how to map and define user trust and the socioethical and organisational need",
    "link": "http://arxiv.org/abs/2305.03306",
    "context": "Title: Human-centered trust framework: An HCI perspective. (arXiv:2305.03306v1 [cs.HC])\nAbstract: The rationale of this work is based on the current user trust discourse of Artificial Intelligence (AI). We aim to produce novel HCI approaches that use trust as a facilitator for the uptake (or appropriation) of current technologies. We propose a framework (HCTFrame) to guide non-experts to unlock the full potential of user trust in AI design. Results derived from a data triangulation of findings from three literature reviews demystify some misconceptions of user trust in computer science and AI discourse, and three case studies are conducted to assess the effectiveness of a psychometric scale in mapping potential users' trust breakdowns and concerns. This work primarily contributes to the fight against the tendency to design technical-centered vulnerable interactions, which can eventually lead to additional real and perceived breaches of trust. The proposed framework can be used to guide system designers on how to map and define user trust and the socioethical and organisational need",
    "path": "papers/23/05/2305.03306.json",
    "total_tokens": 1021,
    "translated_title": "以人为中心的信任框架：一个人机交互的视角",
    "translated_abstract": "本文的出发点基于当前人工智能用户信任话题的讨论，旨在提出新颖的以信任为辅助的人机交互方法，从而促进当前技术的采用和应用。我们提出了一个框架（HCTFrame），以指导非专家在人工智能设计中充分利用用户信任的潜力。通过对三个文献综述的发现进行数据三角化，可消除计算机科学和人工智能话语中关于用户信任的一些误解，并进行三个案例研究，以评估心理测量量表在映射潜在用户信任破坏和担忧方面的有效性。本文主要贡献于抵制设计以技术为中心的易受攻击的交互方式的趋势，这可能最终导致更多实际和感知上的信任破裂。我们提出的框架可用于指导系统设计人员如何映射和定义用户信任以及社会伦理和组织需求。",
    "tldr": "本论文提出了以人为中心的信任框架，帮助非专家实现在人工智能设计中充分利用用户信任的潜力；相关研究发现了某些计算机科学和人工智能话语中的用户信任误解，并进行了有效性评估，该研究的主要贡献是为抵制设计以技术为中心的易受攻击的交互方式的趋势提供了指导。",
    "en_tdlr": "This paper proposes a human-centered trust framework to help non-experts unlock the full potential of user trust in AI design. Findings from data triangulation of three literature reviews help clarify misconceptions of user trust in computer science and AI discourse, and three case studies were conducted to evaluate the effectiveness of a psychometric scale. The primary contribution is to fight against the trend of designing technical-centered vulnerable interactions, and the proposed framework can guide system designers in mapping and defining user trust and socioethical and organizational needs."
}