{
    "title": "Can Self-Supervised Neural Representations Pre-Trained on Human Speech distinguish Animal Callers?. (arXiv:2305.14035v2 [cs.LG] UPDATED)",
    "abstract": "Self-supervised learning (SSL) models use only the intrinsic structure of a given signal, independent of its acoustic domain, to extract essential information from the input to an embedding space. This implies that the utility of such representations is not limited to modeling human speech alone. Building on this understanding, this paper explores the cross-transferability of SSL neural representations learned from human speech to analyze bio-acoustic signals. We conduct a caller discrimination analysis and a caller detection study on Marmoset vocalizations using eleven SSL models pre-trained with various pretext tasks. The results show that the embedding spaces carry meaningful caller information and can successfully distinguish the individual identities of Marmoset callers without fine-tuning. This demonstrates that representations pre-trained on human speech can be effectively applied to the bio-acoustics domain, providing valuable insights for future investigations in this field.",
    "link": "http://arxiv.org/abs/2305.14035",
    "context": "Title: Can Self-Supervised Neural Representations Pre-Trained on Human Speech distinguish Animal Callers?. (arXiv:2305.14035v2 [cs.LG] UPDATED)\nAbstract: Self-supervised learning (SSL) models use only the intrinsic structure of a given signal, independent of its acoustic domain, to extract essential information from the input to an embedding space. This implies that the utility of such representations is not limited to modeling human speech alone. Building on this understanding, this paper explores the cross-transferability of SSL neural representations learned from human speech to analyze bio-acoustic signals. We conduct a caller discrimination analysis and a caller detection study on Marmoset vocalizations using eleven SSL models pre-trained with various pretext tasks. The results show that the embedding spaces carry meaningful caller information and can successfully distinguish the individual identities of Marmoset callers without fine-tuning. This demonstrates that representations pre-trained on human speech can be effectively applied to the bio-acoustics domain, providing valuable insights for future investigations in this field.",
    "path": "papers/23/05/2305.14035.json",
    "total_tokens": 902,
    "translated_title": "自监督神经表示是否能够在预训练人类语音后区分动物呼叫者？",
    "translated_abstract": "自监督学习模型仅使用给定信号的内在结构，独立于声学领域，将信号转换为嵌入空间中的基本信息。这意味着这些表示的效用不仅局限于人类语音建模。本文基于此探讨了通过预训练人类语音自监督神经表示学习来分析生物声学信号的交叉可迁移性。我们使用11个预先训练的各种预训练任务的自监督模型对叫声进行辨别和检测研究，结果表明嵌入空间包含有意义的呼叫者信息，可成功区分不同狨猴叫的个体身份，而无需微调。这表明在生物声学领域，预先训练于人类语音的表示能够被有效地应用于该领域，并为该领域的未来研究提供有价值的见解。",
    "tldr": "本文研究了利用人类语音自监督神经表示学习来分析生物声学信号的交叉可迁移性，在狨猴叫声识别和检测中取得了成功，未来该方法可有效应用于该领域的研究。",
    "en_tdlr": "This paper explores the cross-transferability of self-supervised neural representations pre-trained on human speech to analyze bio-acoustic signals. The study successfully distinguishes individual identities of marmoset callers without fine-tuning, demonstrating the potential of this approach for future investigations in the field."
}