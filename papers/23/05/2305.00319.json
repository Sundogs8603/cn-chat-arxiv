{
    "title": "Learning to Re-rank with Constrained Meta-Optimal Transport. (arXiv:2305.00319v1 [cs.LG])",
    "abstract": "Many re-ranking strategies in search systems rely on stochastic ranking policies, encoded as Doubly-Stochastic (DS) matrices, that satisfy desired ranking constraints in expectation, e.g., Fairness of Exposure (FOE). These strategies are generally two-stage pipelines: \\emph{i)} an offline re-ranking policy construction step and \\emph{ii)} an online sampling of rankings step. Building a re-ranking policy requires repeatedly solving a constrained optimization problem, one for each issued query. Thus, it is necessary to recompute the optimization procedure for any new/unseen query. Regarding sampling, the Birkhoff-von-Neumann decomposition (BvND) is the favored approach to draw rankings from any DS-based policy. However, the BvND is too costly to compute online. Hence, the BvND as a sampling solution is memory-consuming as it can grow as $\\gO(N\\, n^2)$ for $N$ queries and $n$ documents.  This paper offers a novel, fast, lightweight way to predict fair stochastic re-ranking policies: Const",
    "link": "http://arxiv.org/abs/2305.00319",
    "context": "Title: Learning to Re-rank with Constrained Meta-Optimal Transport. (arXiv:2305.00319v1 [cs.LG])\nAbstract: Many re-ranking strategies in search systems rely on stochastic ranking policies, encoded as Doubly-Stochastic (DS) matrices, that satisfy desired ranking constraints in expectation, e.g., Fairness of Exposure (FOE). These strategies are generally two-stage pipelines: \\emph{i)} an offline re-ranking policy construction step and \\emph{ii)} an online sampling of rankings step. Building a re-ranking policy requires repeatedly solving a constrained optimization problem, one for each issued query. Thus, it is necessary to recompute the optimization procedure for any new/unseen query. Regarding sampling, the Birkhoff-von-Neumann decomposition (BvND) is the favored approach to draw rankings from any DS-based policy. However, the BvND is too costly to compute online. Hence, the BvND as a sampling solution is memory-consuming as it can grow as $\\gO(N\\, n^2)$ for $N$ queries and $n$ documents.  This paper offers a novel, fast, lightweight way to predict fair stochastic re-ranking policies: Const",
    "path": "papers/23/05/2305.00319.json",
    "total_tokens": 1320,
    "translated_title": "学习如何用约束元最优输运重新排序",
    "translated_abstract": "在搜索系统中，许多重新排序策略依赖于随机排名策略，编码为满足期望中所需排名约束的双重随机 (DS) 矩阵，例如曝光公平性 (FOE)。这些策略通常是两阶段管道: \\emph{i)}离线重新排序策略构建步骤和 \\emph{ii)}在线排名步骤。建立重新排序策略需要反复解决约束优化问题，每个发布的查询解决一次。因此，为任何新/未见过的查询重新计算优化过程是必要的。关于抽样，Birkhoff-von-Neumann 分解 (BvND) 是从任何基于DS的策略中抽取排名的首选方法。然而，在线计算BvND过于昂贵。因此，BvND作为采样解决方案具有内存占用量，它可以随着 $N$ 查询和 $n$ 文档的增长而增长，其时间复杂度是 $\\gO(N\\, n^2)$。本文提出了一种新颖的、快速的、轻量级的方法来预测公平随机重新排序策略: 约束元最优输运 (CMOT)。CMOT是一种在线元学习算法，可以同时解决所有离线优化问题，并创建一个低成本元模型，可以准确地预测任何新查询的重新排序策略。此外，CMOT使用一种新的采样算法，称为变分排名采样 (VARN-SAM)，它满足相同的排名约束，同时更具内存效率和更快的计算在线。实验评估显示CMOT在公平重新排序方面达到了最先进的性能，同时比其他方法更快、更可扩展。",
    "tldr": "本文提出了一种快速、轻量级的约束元最优输运算法(CMOT)，用于预测公平随机重新排序策略，并使用一种新的采样算法VARN-SAM，比Birkhoff-von-Neumann分解(BvND)更有效。实验结果显示，CMOT实现了公平重新排序的最先进性能，同时比其他方法更快且更可扩展。",
    "en_tdlr": "This paper proposes a fast and lightweight algorithm called CMOT for predicting fair stochastic re-ranking policies, and introduces a new sampling algorithm called VARN-SAM, that is more efficient than Birkhoff-von-Neumann decomposition. Experimental evaluations show that CMOT outperforms other approaches in fair re-ranking while being faster and more scalable."
}