{
    "title": "HiFA: High-fidelity Text-to-3D with Advanced Diffusion Guidance. (arXiv:2305.18766v2 [cs.CV] UPDATED)",
    "abstract": "Automatic text-to-3D synthesis has achieved remarkable advancements through the optimization of 3D models. Existing methods commonly rely on pre-trained text-to-image generative models, such as diffusion models, providing scores for 2D renderings of Neural Radiance Fields (NeRFs) and being utilized for optimizing NeRFs. However, these methods often encounter artifacts and inconsistencies across multiple views due to their limited understanding of 3D geometry. To address these limitations, we propose a reformulation of the optimization loss using the diffusion prior. Furthermore, we introduce a novel training approach that unlocks the potential of the diffusion prior. To improve 3D geometry representation, we apply auxiliary depth supervision for NeRF-rendered images and regularize the density field of NeRFs. Extensive experiments demonstrate the superiority of our method over prior works, resulting in advanced photo-realism and improved multi-view consistency.",
    "link": "http://arxiv.org/abs/2305.18766",
    "context": "Title: HiFA: High-fidelity Text-to-3D with Advanced Diffusion Guidance. (arXiv:2305.18766v2 [cs.CV] UPDATED)\nAbstract: Automatic text-to-3D synthesis has achieved remarkable advancements through the optimization of 3D models. Existing methods commonly rely on pre-trained text-to-image generative models, such as diffusion models, providing scores for 2D renderings of Neural Radiance Fields (NeRFs) and being utilized for optimizing NeRFs. However, these methods often encounter artifacts and inconsistencies across multiple views due to their limited understanding of 3D geometry. To address these limitations, we propose a reformulation of the optimization loss using the diffusion prior. Furthermore, we introduce a novel training approach that unlocks the potential of the diffusion prior. To improve 3D geometry representation, we apply auxiliary depth supervision for NeRF-rendered images and regularize the density field of NeRFs. Extensive experiments demonstrate the superiority of our method over prior works, resulting in advanced photo-realism and improved multi-view consistency.",
    "path": "papers/23/05/2305.18766.json",
    "total_tokens": 966,
    "translated_title": "HiFA: 高保真度的文本到3D图像合成及其先进的扩散引导策略",
    "translated_abstract": "通过优化3D模型，自动文本到3D合成在提升中已经取得了显著进展。现有方法通常依赖于预训练的文本到图像生成模型（如扩散模型），提供神经辐射场（NeRFs）的2D渲染得分并用于优化NeRFs。然而，由于其对3D几何的有限理解，这些方法经常遇到多个视角上的伪影和不一致现象。为了解决这些限制，我们提出了使用扩散先验重新制定优化损失的方法。此外，我们引入了一种新的训练方法，释放了扩散先验的潜力。为了提高3D几何表示，我们对NeRF渲染图像进行辅助深度监督，并规范化NeRF的密度场。大量实验证明了我们的方法优于以前的工作，产生了先进的照片真实感和改进的多视角一致性。",
    "tldr": "该论文提出了一种高保真度的文本到3D图像合成方法，并引入了先进的扩散引导策略。通过对NeRF渲染图像进行辅助深度监督和规范化密度场来提高3D几何表示。实验证明该方法优于以前的工作，产生了先进的照片真实感和改进的多视角一致性。",
    "en_tdlr": "The paper proposes a high-fidelity text-to-3D image synthesis method with advanced diffusion guidance. To improve the 3D geometry representation, auxiliary depth supervision and regularization of the density field of Neural Radiance Fields (NeRFs) are applied. Experimental results demonstrate its superiority over prior works, achieving advanced photo-realism and improved multi-view consistency."
}