{
    "title": "Satisfiability-Aided Language Models Using Declarative Prompting. (arXiv:2305.09656v1 [cs.CL])",
    "abstract": "Prior work has combined chain-of-thought prompting in large language models (LLMs) with programmatic representations to perform effective and transparent reasoning. While such an approach works very well for tasks that only require forward reasoning (e.g., straightforward arithmetic), it is less effective for constraint solving tasks that require more sophisticated planning and search. In this paper, we propose a new satisfiability-aided language modeling approach for improving the reasoning capabilities of LLMs. We use an LLM to generate a declarative task specification rather than an imperative program and leverage an off-the-shelf automated theorem prover to derive the final answer. This approach has two key advantages. The declarative specification is closer to the problem description than the reasoning steps are, so the LLM can parse it more accurately. Furthermore, by offloading the actual reasoning task to an automated theorem prover, our approach can guarantee the correctness o",
    "link": "http://arxiv.org/abs/2305.09656",
    "context": "Title: Satisfiability-Aided Language Models Using Declarative Prompting. (arXiv:2305.09656v1 [cs.CL])\nAbstract: Prior work has combined chain-of-thought prompting in large language models (LLMs) with programmatic representations to perform effective and transparent reasoning. While such an approach works very well for tasks that only require forward reasoning (e.g., straightforward arithmetic), it is less effective for constraint solving tasks that require more sophisticated planning and search. In this paper, we propose a new satisfiability-aided language modeling approach for improving the reasoning capabilities of LLMs. We use an LLM to generate a declarative task specification rather than an imperative program and leverage an off-the-shelf automated theorem prover to derive the final answer. This approach has two key advantages. The declarative specification is closer to the problem description than the reasoning steps are, so the LLM can parse it more accurately. Furthermore, by offloading the actual reasoning task to an automated theorem prover, our approach can guarantee the correctness o",
    "path": "papers/23/05/2305.09656.json",
    "total_tokens": 723,
    "translated_title": "声明提示下的可满足性辅助语言模型",
    "translated_abstract": "本文提出了一种新的可满足性辅助语言建模方法，用于提高大型语言模型的推理能力。我们使用一个大型语言模型生成一个声明性任务规范，并利用一个现成的自动定理证明器得出最终答案。该方法具有两个关键优点：第一，声明性规范比推理步骤更接近问题描述，因此大型语言模型可以更准确地解析它；第二，通过将实际推理任务委托给自动定理证明器，我们的方法可以保证正确性。",
    "tldr": "本文提出了一种利用自动定理证明器和声明性任务规范的可满足性辅助语言建模方法，可以提高大型语言模型的推理能力。",
    "en_tdlr": "This paper proposes a satisfiability-aided language modeling approach that leverages an automated theorem prover and declarative task specification to improve the reasoning capabilities of large language models."
}