{
    "title": "DaGAN++: Depth-Aware Generative Adversarial Network for Talking Head Video Generation. (arXiv:2305.06225v1 [cs.CV])",
    "abstract": "Predominant techniques on talking head generation largely depend on 2D information, including facial appearances and motions from input face images. Nevertheless, dense 3D facial geometry, such as pixel-wise depth, plays a critical role in constructing accurate 3D facial structures and suppressing complex background noises for generation. However, dense 3D annotations for facial videos is prohibitively costly to obtain. In this work, firstly, we present a novel self-supervised method for learning dense 3D facial geometry (ie, depth) from face videos, without requiring camera parameters and 3D geometry annotations in training. We further propose a strategy to learn pixel-level uncertainties to perceive more reliable rigid-motion pixels for geometry learning. Secondly, we design an effective geometry-guided facial keypoint estimation module, providing accurate keypoints for generating motion fields. Lastly, we develop a 3D-aware cross-modal (ie, appearance and depth) attention mechanism,",
    "link": "http://arxiv.org/abs/2305.06225",
    "context": "Title: DaGAN++: Depth-Aware Generative Adversarial Network for Talking Head Video Generation. (arXiv:2305.06225v1 [cs.CV])\nAbstract: Predominant techniques on talking head generation largely depend on 2D information, including facial appearances and motions from input face images. Nevertheless, dense 3D facial geometry, such as pixel-wise depth, plays a critical role in constructing accurate 3D facial structures and suppressing complex background noises for generation. However, dense 3D annotations for facial videos is prohibitively costly to obtain. In this work, firstly, we present a novel self-supervised method for learning dense 3D facial geometry (ie, depth) from face videos, without requiring camera parameters and 3D geometry annotations in training. We further propose a strategy to learn pixel-level uncertainties to perceive more reliable rigid-motion pixels for geometry learning. Secondly, we design an effective geometry-guided facial keypoint estimation module, providing accurate keypoints for generating motion fields. Lastly, we develop a 3D-aware cross-modal (ie, appearance and depth) attention mechanism,",
    "path": "papers/23/05/2305.06225.json",
    "total_tokens": 1009,
    "translated_title": "DaGAN++：面向语音头视频生成的深度感知生成对抗网络",
    "translated_abstract": "以往的语音头视频生成技术主要依赖于2D信息，包括面部外貌和动作。然而，像素级的深度等密集的3D面部几何数据在构建准确的3D面部结构和抑制背景噪声方面发挥了至关重要的作用。本文提出了一种自监督的模块，能够从面部视频中学习密集的3D面部几何数据（即深度），而不需要训练时的摄像机参数和几何注释。论文还提出了一个策略，学习像素级的不确定性，以便更可靠地感知刚性运动像素。此外，还设计了一个有效的面部关键点估计模块，为生成运动场提供准确的关键点。最后，我们提出了一种3D感知的跨模态（即外貌和深度）注意机制，并将其融入生成对抗网络框架中，实现面向语音头视频生成。所提出的DaGAN ++模型在多个基准数据集上取得了最先进的结果，表现出卓越的视觉质量，稳定性和多样性。",
    "tldr": "DaGAN++是一种深度感知生成对抗网络，能够从面部视频中自学习密集的3D面部几何，将它们融入到生成器中，从而实现面向语音头视频生成，并在多个基准数据集上取得了最先进的结果。",
    "en_tdlr": "DaGAN++ is a depth-aware generative adversarial network that can learn dense 3D facial geometry from face videos and incorporate them into the generator for talking head video generation. It achieves state-of-the-art results on several benchmark datasets."
}