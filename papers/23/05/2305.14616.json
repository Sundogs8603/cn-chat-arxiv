{
    "title": "Exploring the Grounding Issues in Image Caption. (arXiv:2305.14616v1 [cs.CL])",
    "abstract": "This paper explores the grounding issue concerning multimodal semantic representation from a computational cognitive-linguistic view. Five perceptual properties of groundedness are annotated and analyzed: Affordance, Perceptual salience, Object number, Gaze cueing, and Ecological Niche Association (ENA). We annotated selected images from the Flickr30k dataset with exploratory analyses and statistical modeling of their captions. Our findings suggest that a comprehensive understanding of an object or event requires cognitive attention, semantic distinctions in linguistic expression, and multimodal construction. During this construction process, viewers integrate situated meaning and affordance into multimodal semantics, which is consolidated into image captions used in the image-text dataset incorporating visual and textual elements. Our findings suggest that situated meaning and affordance grounding are critical for grounded natural language understanding systems to generate appropriate",
    "link": "http://arxiv.org/abs/2305.14616",
    "context": "Title: Exploring the Grounding Issues in Image Caption. (arXiv:2305.14616v1 [cs.CL])\nAbstract: This paper explores the grounding issue concerning multimodal semantic representation from a computational cognitive-linguistic view. Five perceptual properties of groundedness are annotated and analyzed: Affordance, Perceptual salience, Object number, Gaze cueing, and Ecological Niche Association (ENA). We annotated selected images from the Flickr30k dataset with exploratory analyses and statistical modeling of their captions. Our findings suggest that a comprehensive understanding of an object or event requires cognitive attention, semantic distinctions in linguistic expression, and multimodal construction. During this construction process, viewers integrate situated meaning and affordance into multimodal semantics, which is consolidated into image captions used in the image-text dataset incorporating visual and textual elements. Our findings suggest that situated meaning and affordance grounding are critical for grounded natural language understanding systems to generate appropriate",
    "path": "papers/23/05/2305.14616.json",
    "total_tokens": 816,
    "translated_title": "在图像描述中探讨对基础问题",
    "translated_abstract": "本篇论文从计算认知语言的角度探讨了多模态语义表征中的基础问题。采用了感知性、功能性、显著性、注意力和生态学多样性关联等五个基础属性进行注释和分析。通过对Flickr30k数据集中所选的图像进行探索性分析和统计建模来进行研究。研究结果表明，对一个对象或事件的全面理解需要认知注意力、语义表达的语义区分和多模态构建。在构建过程中，观察者将情境含义和功能性融入到多模态语义当中，将其巩固到包含视觉和文本元素的图像-文本数据集中的图像描述中。我们的研究结果表明，情境含义和功能性对于基础自然语言理解系统生成适当的图像描述至关重要。",
    "tldr": "该论文为我们从计算认知语言的角度出发，探讨了图像描述中的多模态语义表征中的基础问题。研究结果表明，情境含义和功能性是生成适当的图像描述的关键。",
    "en_tdlr": "This article explores the grounding issue of multimodal semantic representation in image description from a computational cognitive-linguistic perspective and finds that situational meaning and affordance are critical to generating appropriate image descriptions."
}