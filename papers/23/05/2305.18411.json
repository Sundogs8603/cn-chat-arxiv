{
    "title": "Feature-Learning Networks Are Consistent Across Widths At Realistic Scales. (arXiv:2305.18411v1 [cs.LG])",
    "abstract": "We study the effect of width on the dynamics of feature-learning neural networks across a variety of architectures and datasets. Early in training, wide neural networks trained on online data have not only identical loss curves but also agree in their point-wise test predictions throughout training. For simple tasks such as CIFAR-5m this holds throughout training for networks of realistic widths. We also show that structural properties of the models, including internal representations, preactivation distributions, edge of stability phenomena, and large learning rate effects are consistent across large widths. This motivates the hypothesis that phenomena seen in realistic models can be captured by infinite-width, feature-learning limits. For harder tasks (such as ImageNet and language modeling), and later training times, finite-width deviations grow systematically. Two distinct effects cause these deviations across widths. First, the network output has initialization-dependent variance ",
    "link": "http://arxiv.org/abs/2305.18411",
    "context": "Title: Feature-Learning Networks Are Consistent Across Widths At Realistic Scales. (arXiv:2305.18411v1 [cs.LG])\nAbstract: We study the effect of width on the dynamics of feature-learning neural networks across a variety of architectures and datasets. Early in training, wide neural networks trained on online data have not only identical loss curves but also agree in their point-wise test predictions throughout training. For simple tasks such as CIFAR-5m this holds throughout training for networks of realistic widths. We also show that structural properties of the models, including internal representations, preactivation distributions, edge of stability phenomena, and large learning rate effects are consistent across large widths. This motivates the hypothesis that phenomena seen in realistic models can be captured by infinite-width, feature-learning limits. For harder tasks (such as ImageNet and language modeling), and later training times, finite-width deviations grow systematically. Two distinct effects cause these deviations across widths. First, the network output has initialization-dependent variance ",
    "path": "papers/23/05/2305.18411.json",
    "total_tokens": 953,
    "translated_title": "特征学习网络在实际规模下具有一致性",
    "translated_abstract": "我们研究了一系列网络结构和数据集上的特征学习神经网络宽度对网络动态的影响。在训练早期，基于在线数据训练的宽网络不仅具有相同的损失曲线，而且在整个训练过程中的测试预测也是一致的。对于像CIFAR-5m这样的简单任务，这适用于具有实际宽度的网络的整个训练过程。我们还展示了模型的结构特性，包括内部表示、预激活分布、稳定性边缘现象和大学习率效应，在大宽度下是一致的。这启发了一个假设：在特征学习极限下，可以捕捉到现实模型中出现的现象。对于更难的任务（如ImageNet和语言建模）和更晚的训练时间，有限宽度的偏差会系统地增长。这些偏差是由两个不同的效应引起的。首先，网络输出具有初始化相关的方差",
    "tldr": "本研究发现宽度对于神经网络的动态没有影响，网络在早期训练中表现出一致性，对于简单任务来说这一一致性贯穿整个训练过程，且大宽度下的结构特性是一致的。这表明特征学习极限可以捕捉到现实模型中出现的现象。",
    "en_tdlr": "This study finds that width does not affect the dynamics of neural networks, which show consistency in the early stages of training and throughout for simpler tasks, and that the structural properties of networks at large widths are also consistent. This suggests that phenomena observed in realistic models can be captured by the infinite-width feature-learning limit."
}