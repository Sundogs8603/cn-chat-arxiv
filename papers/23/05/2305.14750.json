{
    "title": "Mastering the ABCDs of Complex Questions: Answer-Based Claim Decomposition for Fine-grained Self-Evaluation. (arXiv:2305.14750v1 [cs.CL])",
    "abstract": "When answering complex questions, large language models (LLMs) may produce answers that do not satisfy all criteria of the question. While existing self-evaluation techniques aim to detect if such answers are correct, these techniques are unable to determine which criteria of the question are satisfied by the generated answers. To address this issue, we propose answer-based claim decomposition (ABCD), a prompting strategy that decomposes questions into a series of true/false claims that can be used to verify which criteria of the input question an answer satisfies. Using the decomposed ABCD claims, we perform fine-grained self-evaluation. Through preliminary experiments on three datasets, including a newly-collected challenge dataset ObscureQA, we find that GPT-3.5 has some ability to determine to what extent its answer satisfies the criteria of the input question, and can give insights into the errors and knowledge gaps of the model.",
    "link": "http://arxiv.org/abs/2305.14750",
    "context": "Title: Mastering the ABCDs of Complex Questions: Answer-Based Claim Decomposition for Fine-grained Self-Evaluation. (arXiv:2305.14750v1 [cs.CL])\nAbstract: When answering complex questions, large language models (LLMs) may produce answers that do not satisfy all criteria of the question. While existing self-evaluation techniques aim to detect if such answers are correct, these techniques are unable to determine which criteria of the question are satisfied by the generated answers. To address this issue, we propose answer-based claim decomposition (ABCD), a prompting strategy that decomposes questions into a series of true/false claims that can be used to verify which criteria of the input question an answer satisfies. Using the decomposed ABCD claims, we perform fine-grained self-evaluation. Through preliminary experiments on three datasets, including a newly-collected challenge dataset ObscureQA, we find that GPT-3.5 has some ability to determine to what extent its answer satisfies the criteria of the input question, and can give insights into the errors and knowledge gaps of the model.",
    "path": "papers/23/05/2305.14750.json",
    "total_tokens": 930,
    "translated_title": "解决大语言模型在回答复杂问题时的评估问题：基于答案断言分解的细粒度自我评估方法",
    "translated_abstract": "在回答复杂问题时，大型语言模型（LLMs）可能生成的答案不能满足问题的所有标准。虽然现有的自我评估技术旨在检测这些答案是否正确，但这些技术无法确定生成的答案满足问题的哪些标准。为了解决这个问题，我们提出了答案断言分解（ABCD），这是一种提示策略，可将问题分解为一系列可以用来验证答案满足哪些问题标准的真/假断言。使用分解的ABCD断言，我们执行了细粒度的自我评估。通过对三个数据集（包括新收集的挑战数据集ObscureQA）的初步实验，我们发现GPT-3.5有一定能力确定其答案在多大程度上满足输入问题的标准，并可以提供关于模型错误和知识差距的见解。",
    "tldr": "大型语言模型（LLMs）常常不能完全回答复杂问题。我们提出基于答案断言分解的细粒度自我评估方法，以验证答案满足哪些问题标准。初步实验表明，该方法可帮助发现模型错误和知识差距。",
    "en_tdlr": "Large language models (LLMs) may struggle to fully answer complex questions. We propose answer-based claim decomposition (ABCD), a fine-grained self-evaluation method that decomposes questions into true/false claims to verify which criteria an answer satisfies. Preliminary experiments show that the ABCD method can help identify model errors and knowledge gaps."
}