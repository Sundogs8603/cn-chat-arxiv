{
    "title": "EgoHumans: An Egocentric 3D Multi-Human Benchmark. (arXiv:2305.16487v1 [cs.CV])",
    "abstract": "We present EgoHumans, a new multi-view multi-human video benchmark to advance the state-of-the-art of egocentric human 3D pose estimation and tracking. Existing egocentric benchmarks either capture single subject or indoor-only scenarios, which limit the generalization of computer vision algorithms for real-world applications. We propose a novel 3D capture setup to construct a comprehensive egocentric multi-human benchmark in the wild with annotations to support diverse tasks such as human detection, tracking, 2D/3D pose estimation, and mesh recovery. We leverage consumer-grade wearable camera-equipped glasses for the egocentric view, which enables us to capture dynamic activities like playing soccer, fencing, volleyball, etc. Furthermore, our multi-view setup generates accurate 3D ground truth even under severe or complete occlusion. The dataset consists of more than 125k egocentric images, spanning diverse scenes with a particular focus on challenging and unchoreographed multi-human ",
    "link": "http://arxiv.org/abs/2305.16487",
    "context": "Title: EgoHumans: An Egocentric 3D Multi-Human Benchmark. (arXiv:2305.16487v1 [cs.CV])\nAbstract: We present EgoHumans, a new multi-view multi-human video benchmark to advance the state-of-the-art of egocentric human 3D pose estimation and tracking. Existing egocentric benchmarks either capture single subject or indoor-only scenarios, which limit the generalization of computer vision algorithms for real-world applications. We propose a novel 3D capture setup to construct a comprehensive egocentric multi-human benchmark in the wild with annotations to support diverse tasks such as human detection, tracking, 2D/3D pose estimation, and mesh recovery. We leverage consumer-grade wearable camera-equipped glasses for the egocentric view, which enables us to capture dynamic activities like playing soccer, fencing, volleyball, etc. Furthermore, our multi-view setup generates accurate 3D ground truth even under severe or complete occlusion. The dataset consists of more than 125k egocentric images, spanning diverse scenes with a particular focus on challenging and unchoreographed multi-human ",
    "path": "papers/23/05/2305.16487.json",
    "total_tokens": 1045,
    "translated_title": "EgoHumans:一种以自我为中心的三维多人基准数据集",
    "translated_abstract": "我们提出了EgoHumans，这是一个新的视角多人视频基准数据集，旨在推进自我中心的人类三维姿态估计和跟踪的最新进展。现有的自我中心基准数据集仅捕捉单个主体或仅限于室内场景，这限制了计算机视觉算法在现实世界应用中的泛化能力。我们提出了一种新的三维捕获设定，构建了一个全面的自我中心多人基准数据集，并提供注释支持各种任务，例如人类检测、跟踪、2D/3D姿态估计和网格恢复等。我们利用带摄像头的普通眼镜进行视角捕捉，并能够捕捉诸如踢足球、击剑、排球等动态活动。此外，我们的多视角设置在严重或完全遮挡下仍能生成准确的3D基准数据。该数据集包含超过125k个自我中心图像，跨越多种场景，特别关注具有挑战性和无核编排的多人场景。",
    "tldr": "EgoHumans是一个全面的自我中心多人基准数据集，旨在推进自我中心的人类三维姿态估计和跟踪的最新进展，可以支持各种任务，包括人类检测、跟踪、2D/3D姿态估计和网格恢复等，并且能够捕捉具有挑战性和无核编排的多人场景。",
    "en_tdlr": "EgoHumans is a comprehensive egocentric multi-human benchmark dataset that aims to advance the state-of-the-art of egocentric human 3D pose estimation and tracking, supporting various tasks including human detection, tracking, 2D/3D pose estimation and mesh recovery. It enables dynamic activity capture like playing soccer, fencing, volleyball, etc., and generates accurate 3D ground truth even under severe or complete occlusion, with a particular focus on challenging and unchoreographed multi-human scenes."
}