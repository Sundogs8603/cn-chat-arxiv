{
    "title": "Towards Building the Federated GPT: Federated Instruction Tuning. (arXiv:2305.05644v1 [cs.CL])",
    "abstract": "While ``instruction-tuned\" generative large language models (LLMs) have demonstrated an impressive ability to generalize to new tasks, the training phases heavily rely on large amounts of diverse and high-quality instruction data (such as ChatGPT and GPT-4). Unfortunately, acquiring high-quality data, especially when it comes to human-written data, can pose significant challenges both in terms of cost and accessibility. Moreover, concerns related to privacy can further limit access to such data, making the process of obtaining it a complex and nuanced undertaking. Consequently, this hinders the generality of the tuned models and may restrict their effectiveness in certain contexts. To tackle this issue, our study introduces a new approach called Federated Instruction Tuning (FedIT), which leverages federated learning (FL) as the learning framework for the instruction tuning of LLMs. This marks the first exploration of FL-based instruction tuning for LLMs. This is especially important s",
    "link": "http://arxiv.org/abs/2305.05644",
    "context": "Title: Towards Building the Federated GPT: Federated Instruction Tuning. (arXiv:2305.05644v1 [cs.CL])\nAbstract: While ``instruction-tuned\" generative large language models (LLMs) have demonstrated an impressive ability to generalize to new tasks, the training phases heavily rely on large amounts of diverse and high-quality instruction data (such as ChatGPT and GPT-4). Unfortunately, acquiring high-quality data, especially when it comes to human-written data, can pose significant challenges both in terms of cost and accessibility. Moreover, concerns related to privacy can further limit access to such data, making the process of obtaining it a complex and nuanced undertaking. Consequently, this hinders the generality of the tuned models and may restrict their effectiveness in certain contexts. To tackle this issue, our study introduces a new approach called Federated Instruction Tuning (FedIT), which leverages federated learning (FL) as the learning framework for the instruction tuning of LLMs. This marks the first exploration of FL-based instruction tuning for LLMs. This is especially important s",
    "path": "papers/23/05/2305.05644.json",
    "total_tokens": 929,
    "translated_title": "为建立联邦 GPT 做出努力：联邦指令调整",
    "translated_abstract": "虽然“指令调整”生成大型语言模型（LLMs）展现出了出色的新任务概括能力，但训练阶段严重依赖于大量多样和高质量的指令数据（如ChatGPT和GPT-4）。然而，获取高质量数据，特别是人工撰写的数据，可能会面临显著的成本和可访问性方面的挑战。此外，与隐私有关的问题可能会进一步限制对这些数据的访问，使得获取数据的过程变得复杂而微妙。因此，这限制了调整模型的通用性并可能限制其在特定情境下的效果。为解决这个问题，我们的研究引入了一种新的方法，称为联邦指令调整（FedIT），它利用联邦学习（FL）作为LLMs指令调整的学习框架。这是FL在LLMs指令调整中的首次探索。这尤其重要，因为...",
    "tldr": "本文提出了一种名为Federated Instruction Tuning (FedIT)的新方法，利用联邦学习（FL）模型对LLMs进行指令调整，以解决获取高质量指令数据的挑战，从而提高调整模型的通用性和效果。",
    "en_tdlr": "This paper introduces a new approach called Federated Instruction Tuning (FedIT), which leverages federated learning (FL) as the learning framework for the instruction tuning of LLMs. FedIT is proposed to tackle the challenge of obtaining high-quality instruction data, which can limit the generality and effectiveness of the tuned models."
}