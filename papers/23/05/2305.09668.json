{
    "title": "Mean Estimation Under Heterogeneous Privacy: Some Privacy Can Be Free. (arXiv:2305.09668v1 [cs.CR])",
    "abstract": "Differential Privacy (DP) is a well-established framework to quantify privacy loss incurred by any algorithm. Traditional DP formulations impose a uniform privacy requirement for all users, which is often inconsistent with real-world scenarios in which users dictate their privacy preferences individually. This work considers the problem of mean estimation under heterogeneous DP constraints, where each user can impose their own distinct privacy level. The algorithm we propose is shown to be minimax optimal when there are two groups of users with distinct privacy levels. Our results elicit an interesting saturation phenomenon that occurs as one group's privacy level is relaxed, while the other group's privacy level remains constant. Namely, after a certain point, further relaxing the privacy requirement of the former group does not improve the performance of the minimax optimal mean estimator. Thus, the central server can offer a certain degree of privacy without any sacrifice in perform",
    "link": "http://arxiv.org/abs/2305.09668",
    "context": "Title: Mean Estimation Under Heterogeneous Privacy: Some Privacy Can Be Free. (arXiv:2305.09668v1 [cs.CR])\nAbstract: Differential Privacy (DP) is a well-established framework to quantify privacy loss incurred by any algorithm. Traditional DP formulations impose a uniform privacy requirement for all users, which is often inconsistent with real-world scenarios in which users dictate their privacy preferences individually. This work considers the problem of mean estimation under heterogeneous DP constraints, where each user can impose their own distinct privacy level. The algorithm we propose is shown to be minimax optimal when there are two groups of users with distinct privacy levels. Our results elicit an interesting saturation phenomenon that occurs as one group's privacy level is relaxed, while the other group's privacy level remains constant. Namely, after a certain point, further relaxing the privacy requirement of the former group does not improve the performance of the minimax optimal mean estimator. Thus, the central server can offer a certain degree of privacy without any sacrifice in perform",
    "path": "papers/23/05/2305.09668.json",
    "total_tokens": 898,
    "translated_title": "异构隐私下的均值估计: 部分隐私是可以免费的。",
    "translated_abstract": "差分隐私 (DP) 是一种被广泛运用用于衡量算法隐私损失的框架。传统的DP形式对所有用户强制施加一致的隐私要求，这与现实场景通常不一致，因为用户个体决定他们的隐私偏好。本文探讨了在异构DP约束下的平均数估计问题，其中每个用户可以施加自己独特的隐私水平。我们提出的算法在两组具有不同隐私级别的用户时被证明是极小化的最优的。我们的结果揭示了一个有趣的饱和现象，即在一组用户的隐私水平被放宽而另一组用户的隐私水平保持不变时发生。也就是说，在某个特定情形下，进一步放宽前一组的隐私要求并不会改善最小二乘平均数估计器的性能。因此，中央服务器可以提供一定程度的隐私而不会牺牲性能。",
    "tldr": "本文研究了在不同隐私要求下的均值估计问题，提出的算法在两组具有不同隐私级别的用户时是极小化的最优的，并揭示了一个有趣的饱和现象。",
    "en_tdlr": "This paper studies the problem of mean estimation under heterogeneous privacy constraints, where users can impose their own distinct privacy level. The proposed algorithm is shown to be minimax optimal when there are two groups of users with distinct privacy levels and reveals an interesting saturation phenomenon."
}